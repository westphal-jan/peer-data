{"id": "1605.06778", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-May-2016", "title": "openXBOW - Introducing the Passau Open-Source Crossmodal Bag-of-Words Toolkit", "abstract": "We introduce openXBOW, an open-source toolkit for the generation of bag-of-words (BoW) representations from multimodal input. In the BoW principle, word histograms were first used as features in document classification, but the idea was and can easily be adapted to, e.g., acoustic or visual low-level descriptors, introducing a prior step of vector quantisation. The openXBOW toolkit supports arbitrary numeric input features and text input and concatenates computed subbags to a final bag. It provides a variety of extensions and options. To our knowledge, openXBOW is the first publicly available toolkit for the generation of crossmodal bags-of-words. The capabilities of the tool are exemplified in two sample scenarios: time-continuous speech-based emotion recognition and sentiment analysis in tweets where improved results over other feature representation forms were observed.", "histories": [["v1", "Sun, 22 May 2016 12:14:55 GMT  (176kb,D)", "http://arxiv.org/abs/1605.06778v1", "9 pages, 1 figure, pre-print"]], "COMMENTS": "9 pages, 1 figure, pre-print", "reviews": [], "SUBJECTS": "cs.CV cs.CL cs.IR", "authors": ["maximilian schmitt", "bj\\\"orn w schuller"], "accepted": false, "id": "1605.06778"}, "pdf": {"name": "1605.06778.pdf", "metadata": {"source": "CRF", "title": "openXBOW \u2013 Introducing the Passau Open-Source Crossmodal Bag-of-Words Toolkit", "authors": ["Maximilian Schmitt", "Bj\u00f6rn W. Schuller"], "emails": ["maximilian.schmitt@uni-passau.de", "bjoern.schuller@uni-passau.de"], "sections": [{"heading": null, "text": "Keywords: sack-of-words, multimodal signal processing, histogram feature representations"}, {"heading": "1. Introduction", "text": "This year, it has reached the point where there is only one person who is capable of establishing himself at the top."}, {"heading": "2. Overview", "text": "This year it is more than ever before."}, {"heading": "3. Experiments", "text": "This section demonstrates the use of openXBOW based on two scenarios: time-continuous processing of voice input for emotion recognition and BoW processing of tweets. In fact, there are comparatively few suitable multimodal databases with acoustic, visual and text input. In this introductory article, we illustrate the principle of separate tasks for audio and text words to illustrate the principle. However, results of openXBOW with multimodal input will be shown in our future efforts."}, {"heading": "3.1 Time- and value-continuous emotion recognition from speech", "text": "This year it is more than ever before in the history of the city."}, {"heading": "3.2 Twitter sentiment analysis", "text": "This year it is more than ever before."}, {"heading": "4. Conclusions and outlook", "text": "We have presented our novel openXBOW toolkit - a first of its kind - for generating BoW representations from multimodal symbolic (including text), but also numerical (such as audio or video) information streams. In two (monomodal) examples, we have demonstrated the potential of the toolkit and the underlying BoXW principle by exceeding the current state of the art in a clearly defined, modern, language-based emotion recognition task. However, its full potential is likely to emerge once it targets actual cross-modal tasks. Likewise, it stands to reason that performance can be improved in the future by input from the visual domain, the physiological domain, and the transcribed language for emotion recognition tasks. We have also shown that our toolkit already delivers state-of-the-art results in text classification."}, {"heading": "Acknowledgments", "text": "This work was supported by the Horizon 2020 programme of the European Union under Funding Agreement No 645094 (IA SEWA) and the Seventh Framework Programme of the European Community under ERC Starting Grant No 338164 (iHEARu)."}], "references": [{"title": "k-means++: The advantages of careful seeding", "author": ["D. Arthur", "S. Vassilvitskii"], "venue": "In Proc. of the 18th annual ACM-SIAM symposium on Discrete algorithms,", "citeRegEx": "Arthur and Vassilvitskii.,? \\Q2007\\E", "shortCiteRegEx": "Arthur and Vassilvitskii.", "year": 2007}, {"title": "LIBSVM: A library for support vector machines", "author": ["C.-C. Chang", "C.-J. Lin"], "venue": "ACM Transactions on Intelligent Systems and Technology,", "citeRegEx": "Chang and Lin.,? \\Q2011\\E", "shortCiteRegEx": "Chang and Lin.", "year": 2011}, {"title": "Recent developments in openSMILE, the munich open-source multimedia feature extractor", "author": ["F. Eyben", "F. Weninger", "F. Gro\u00df", "B. Schuller"], "venue": "In Proc. of the 21st ACM International Conference on Multimedia,", "citeRegEx": "Eyben et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Eyben et al\\.", "year": 2013}, {"title": "Liblinear: A library for large linear classification", "author": ["R.-E. Fan", "K.-W. Chang", "C.-J. Hsieh", "X.-R. Wang", "C.-J. Lin"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Fan et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Fan et al\\.", "year": 2008}, {"title": "A bayesian hierarchical model for learning natural scene categories", "author": ["L. Fei-Fei", "P. Perona"], "venue": "In Computer Vision and Pattern Recognition,", "citeRegEx": "Fei.Fei and Perona.,? \\Q2005\\E", "shortCiteRegEx": "Fei.Fei and Perona.", "year": 2005}, {"title": "Bags of binary words for fast place recognition in image sequences. Robotics", "author": ["D. G\u00e1lvez-L\u00f3pez", "J.D. Tardos"], "venue": "IEEE Transactions on,", "citeRegEx": "G\u00e1lvez.L\u00f3pez and Tardos.,? \\Q2012\\E", "shortCiteRegEx": "G\u00e1lvez.L\u00f3pez and Tardos.", "year": 2012}, {"title": "Temporal acoustic words for online acoustic event detection", "author": ["R. Grzeszick", "A. Plinge", "G.A. Fink"], "venue": "In Proc. 37th German Conf. Pattern Recognition, Aachen,", "citeRegEx": "Grzeszick et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Grzeszick et al\\.", "year": 2015}, {"title": "The weka data mining software: an update", "author": ["M. Hall", "E. Frank", "G. Holmes", "B. Pfahringer", "P. Reutemann", "I.H. Witten"], "venue": "ACM SIGKDD explorations newsletter,", "citeRegEx": "Hall et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Hall et al\\.", "year": 2009}, {"title": "Multimodal assistive technologies for depression diagnosis and monitoring", "author": ["J. Joshi", "R. Goecke", "S. Alghowinem", "A. Dhall", "M. Wagner", "J. Epps", "G. Parker", "M. Breakspear"], "venue": "Journal on MultiModal User Interfaces,", "citeRegEx": "Joshi et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Joshi et al\\.", "year": 2013}, {"title": "Robust sound event classification using lbp-hog based bag-of-audio-words feature representation", "author": ["H. Lim", "M.J. Kim", "H. Kim"], "venue": "In Proc. INTERSPEECH,", "citeRegEx": "Lim et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lim et al\\.", "year": 2015}, {"title": "Coherent bag-of audio words model for efficient large-scale video copy detection", "author": ["Y. Liu", "W.-L. Zhao", "C.-W. Ngo", "C.-S. Xu", "H.-Q. Lu"], "venue": "In Proc. of the ACM International Conference on Image and Video Retrieval,", "citeRegEx": "Liu et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2010}, {"title": "Bag-of-audio-words approach for multimedia event classification", "author": ["S. Pancoast", "M. Akbacak"], "venue": "In Proc. INTERSPEECH,", "citeRegEx": "Pancoast and Akbacak.,? \\Q2012\\E", "shortCiteRegEx": "Pancoast and Akbacak.", "year": 2012}, {"title": "N-gram extension for bag-of-audio-words", "author": ["S. Pancoast", "M. Akbacak"], "venue": "In Acoustics, Speech and Signal Processing (ICASSP),", "citeRegEx": "Pancoast and Akbacak.,? \\Q2013\\E", "shortCiteRegEx": "Pancoast and Akbacak.", "year": 2013}, {"title": "Softening quantization in bag-of-audio-words", "author": ["S. Pancoast", "M. Akbacak"], "venue": "In Acoustics, Speech and Signal Processing (ICASSP),", "citeRegEx": "Pancoast and Akbacak.,? \\Q2014\\E", "shortCiteRegEx": "Pancoast and Akbacak.", "year": 2014}, {"title": "A bag-of-features approach to acoustic event detection", "author": ["A. Plinge", "R. Grzeszick", "G.A. Fink"], "venue": "In IEEE Int. Conf. on Acoustics, Speech and Signal Processing (ICASSP),", "citeRegEx": "Plinge et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Plinge et al\\.", "year": 2014}, {"title": "Detection of negative emotions in speech signals using bags-of-audio-words", "author": ["F. Pokorny", "F. Graf", "F. Pernkopf", "B. Schuller"], "venue": "In Proc. 1st International Workshop", "citeRegEx": "Pokorny et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Pokorny et al\\.", "year": 2015}, {"title": "Robust audiocodebooks for large-scale event detection in consumer videos", "author": ["S. Rawat", "P.F. Schulam", "S. Burger", "D. Ding", "Y. Wang", "F. Metze"], "venue": "In Proc. INTERSPEECH,", "citeRegEx": "Rawat et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Rawat et al\\.", "year": 2013}, {"title": "A text retrieval approach to content-based audio hashing", "author": ["M. Riley", "E. Heinen", "J. Ghosh"], "venue": "In ISMIR 2008, 9th International Conference on Music Information Retrieval,", "citeRegEx": "Riley et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Riley et al\\.", "year": 2008}, {"title": "Introducing the recola multimodal corpus of remote collaborative and affective interactions", "author": ["F. Ringeval", "A. Sonderegger", "J. Sauer", "D. Lalanne"], "venue": "In Face and Gestures", "citeRegEx": "Ringeval et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Ringeval et al\\.", "year": 2013}, {"title": "The Godfather\u201d vs. \u201cChaos\u201d: Comparing Linguistic Analysis based on Online Knowledge Sources and Bags-of-N-Grams for Movie Review Valence Estimation", "author": ["B. Schuller", "J. Schenk", "G. Rigoll", "T. Knaup"], "venue": "In Proceedings 10th International Conference on Document Analysis and Recognition,", "citeRegEx": "Schuller et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Schuller et al\\.", "year": 2009}, {"title": "Sentiment Analysis and Opinion Mining: On Optimal Parameters and Performances", "author": ["B. Schuller", "A.E.-D. Mousa", "V. Vasileios"], "venue": "WIREs Data Mining and Knowledge Discovery,", "citeRegEx": "Schuller et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Schuller et al\\.", "year": 2015}, {"title": "Discovering object categories in image collections", "author": ["J. Sivic", "B.C. Russell", "A.A. Efros", "A. Zisserman", "W.T. Freeman"], "venue": null, "citeRegEx": "Sivic et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Sivic et al\\.", "year": 2005}, {"title": "Avec 2016-depression, mood, and emotion recognition workshop and challenge", "author": ["M. Valstar", "J. Gratch", "B. Schuller", "F. Ringeval", "D. Lalanne", "M.T. Torres", "S. Scherer", "G. Stratou", "R. Cowie", "M. Pantic"], "venue": "arXiv preprint arXiv:1605.01600,", "citeRegEx": "Valstar et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Valstar et al\\.", "year": 2016}, {"title": "Topic modeling: Beyond bag-of-words", "author": ["H.M. Wallach"], "venue": "In Proceedings of the 23rd international conference on Machine learning,", "citeRegEx": "Wallach.,? \\Q2006\\E", "shortCiteRegEx": "Wallach.", "year": 2006}, {"title": "Words that Fascinate the Listener: Predicting Affective Ratings of On-Line Lectures", "author": ["F. Weninger", "P. Staudt", "B. Schuller"], "venue": "International Journal of Distance Education Technologies, Special Issue on Emotional Intelligence for Online Learning,", "citeRegEx": "Weninger et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Weninger et al\\.", "year": 2013}, {"title": "Fully Automatic Audiovisual Emotion Recognition \u2013 Voice, Words, and the Face", "author": ["M. W\u00f6llmer", "M. Kaiser", "F. Eyben", "F. Weninger", "B. Schuller", "G. Rigoll"], "venue": "Proceedings of Speech Communication; 10. ITG Symposium,", "citeRegEx": "W\u00f6llmer et al\\.,? \\Q2012\\E", "shortCiteRegEx": "W\u00f6llmer et al\\.", "year": 2012}], "referenceMentions": [{"referenceID": 25, "context": "The bag-of-words (BoW) principle is a common practice in natural language processing (NLP) (W\u00f6llmer et al., 2012; Weninger et al., 2013).", "startOffset": 91, "endOffset": 136}, {"referenceID": 24, "context": "The bag-of-words (BoW) principle is a common practice in natural language processing (NLP) (W\u00f6llmer et al., 2012; Weninger et al., 2013).", "startOffset": 91, "endOffset": 136}, {"referenceID": 23, "context": "In order to overcome this problem, n-grams have been employed, where sequences of n words or characters (ncharacter-grams) are counted instead of single words (Wallach, 2006; Schuller et al., 2009).", "startOffset": 159, "endOffset": 197}, {"referenceID": 19, "context": "In order to overcome this problem, n-grams have been employed, where sequences of n words or characters (ncharacter-grams) are counted instead of single words (Wallach, 2006; Schuller et al., 2009).", "startOffset": 159, "endOffset": 197}, {"referenceID": 4, "context": "BoW has been adopted by the visual community, where it is known under the name bag-of-visual-words (BoVW) (Fei-Fei and Perona, 2005; Sivic et al., 2005).", "startOffset": 106, "endOffset": 152}, {"referenceID": 21, "context": "BoW has been adopted by the visual community, where it is known under the name bag-of-visual-words (BoVW) (Fei-Fei and Perona, 2005; Sivic et al., 2005).", "startOffset": 106, "endOffset": 152}, {"referenceID": 11, "context": "from the audio signal, then, the LLD vectors from single frames are quantised according to a codebook (Pancoast and Akbacak, 2012).", "startOffset": 102, "endOffset": 130}, {"referenceID": 15, "context": "This codebook can be the result of either k-means clustering (Pokorny et al., 2015) or random sampling of LLD vectors (Rawat et al.", "startOffset": 61, "endOffset": 83}, {"referenceID": 16, "context": ", 2015) or random sampling of LLD vectors (Rawat et al., 2013).", "startOffset": 42, "endOffset": 62}, {"referenceID": 6, "context": "Other approaches employ expectation maximisation (EM) clustering, which leads to a soft vector quantisation step (Grzeszick et al., 2015).", "startOffset": 113, "endOffset": 137}, {"referenceID": 10, "context": "Major applications of BoAW are acoustic event detection and multimedia event detection (Liu et al., 2010; Pancoast and Akbacak, 2012; Rawat et al., 2013; Plinge et al., 2014; Lim et al., 2015) but they have also been successfully used in music information retrieval (Riley et al.", "startOffset": 87, "endOffset": 192}, {"referenceID": 11, "context": "Major applications of BoAW are acoustic event detection and multimedia event detection (Liu et al., 2010; Pancoast and Akbacak, 2012; Rawat et al., 2013; Plinge et al., 2014; Lim et al., 2015) but they have also been successfully used in music information retrieval (Riley et al.", "startOffset": 87, "endOffset": 192}, {"referenceID": 16, "context": "Major applications of BoAW are acoustic event detection and multimedia event detection (Liu et al., 2010; Pancoast and Akbacak, 2012; Rawat et al., 2013; Plinge et al., 2014; Lim et al., 2015) but they have also been successfully used in music information retrieval (Riley et al.", "startOffset": 87, "endOffset": 192}, {"referenceID": 14, "context": "Major applications of BoAW are acoustic event detection and multimedia event detection (Liu et al., 2010; Pancoast and Akbacak, 2012; Rawat et al., 2013; Plinge et al., 2014; Lim et al., 2015) but they have also been successfully used in music information retrieval (Riley et al.", "startOffset": 87, "endOffset": 192}, {"referenceID": 9, "context": "Major applications of BoAW are acoustic event detection and multimedia event detection (Liu et al., 2010; Pancoast and Akbacak, 2012; Rawat et al., 2013; Plinge et al., 2014; Lim et al., 2015) but they have also been successfully used in music information retrieval (Riley et al.", "startOffset": 87, "endOffset": 192}, {"referenceID": 17, "context": ", 2015) but they have also been successfully used in music information retrieval (Riley et al., 2008) and emotion recognition from speech (Pokorny et al.", "startOffset": 81, "endOffset": 101}, {"referenceID": 15, "context": ", 2008) and emotion recognition from speech (Pokorny et al., 2015).", "startOffset": 44, "endOffset": 66}, {"referenceID": 8, "context": ", for depression monitoring in (Joshi et al., 2013), exploiting both the audio and the video domain.", "startOffset": 31, "endOffset": 51}, {"referenceID": 5, "context": "To the knowledge of the authors, such a toolkit has not been published, so far, whereas there are already some libraries implementing BoVW, such as DBoW2 (G\u00e1lvez-L\u00f3pez and Tardos, 2012).", "startOffset": 154, "endOffset": 185}, {"referenceID": 7, "context": "\u2022 ARFF (Attribute-Relation File Format), used in the machine learning software Weka (Hall et al., 2009)", "startOffset": 84, "endOffset": 103}, {"referenceID": 1, "context": "\u2022 LIBSVM file format, used in LIBSVM (Chang and Lin, 2011) and LIBLINEAR (Fan et al.", "startOffset": 37, "endOffset": 58}, {"referenceID": 3, "context": "\u2022 LIBSVM file format, used in LIBSVM (Chang and Lin, 2011) and LIBLINEAR (Fan et al., 2008) (only output)", "startOffset": 73, "endOffset": 91}, {"referenceID": 0, "context": "For codebook generation, there are four different methods available at the time; random sampling means that the codebook vectors are picked randomly from the input LLDs, whereas random sampling++ favours far-off vectors as proposed in (Arthur and Vassilvitskii, 2007) as an improved initialisation step for kmeans, called in that case kmeans++.", "startOffset": 235, "endOffset": 267}, {"referenceID": 6, "context": "In case of nominal class labels, the codebook generation can also be done in a supervised manner, learning a codebook from all LLDs in one class separately, first, and then concatenating these codebooks to form a super-codebook (Grzeszick et al., 2015).", "startOffset": 228, "endOffset": 252}, {"referenceID": 15, "context": "In case of large LLD vectors, split vector quantisation (SVQ) can be suitable, as proposed in (Pokorny et al., 2015), where subvectors are first quantised and then the indexes of the quantised subvectors are processed in the usual scheme.", "startOffset": 94, "endOffset": 116}, {"referenceID": 13, "context": "codebook (Pancoast and Akbacak, 2014).", "startOffset": 9, "endOffset": 37}, {"referenceID": 17, "context": "For post-processing, logarithmic TF-weighting (TFlog = lg(TF+1)), and inverse documentfrequency (IDF) weighting (TFIDF = TF \u00b7 lg N DF , N: Number of instances, DF: Number of instances where the word is present) can be applied (Riley et al., 2008).", "startOffset": 226, "endOffset": 246}, {"referenceID": 18, "context": "Emotion recognition from speech has been conducted on the RECOLA (Remote Collaborative and Affective Interactions) corpus (Ringeval et al., 2013).", "startOffset": 122, "endOffset": 145}, {"referenceID": 2, "context": "The input LLDs (MFCCs 1\u201312 and log-energy) were extracted with our toolkit openSMILE (Eyben et al., 2013).", "startOffset": 85, "endOffset": 105}, {"referenceID": 22, "context": "Table 1 shows the results of BoAW for emotion recognition compared to the baseline of the AVEC 2016 challenge at ACM Multimedia 2016 (Valstar et al., 2016), which is also carried out on RECOLA under the same conditions.", "startOffset": 133, "endOffset": 155}, {"referenceID": 20, "context": "Even better performance might be achieved with more sophisticated approaches, such as long short-term memory recurrent neural networks (Schuller et al., 2015).", "startOffset": 135, "endOffset": 158}, {"referenceID": 6, "context": "Future work on openXBOW will include further soft vector quantisation techniques such as using EM clustering or non-negative matrix factorisation-based soft clustering and methods taking the order of the crossmodal words into account, such as temporal augmentation (Grzeszick et al., 2015) and n-grams for numeric features (Pancoast and Akbacak, 2013).", "startOffset": 265, "endOffset": 289}, {"referenceID": 12, "context": ", 2015) and n-grams for numeric features (Pancoast and Akbacak, 2013).", "startOffset": 41, "endOffset": 69}], "year": 2016, "abstractText": "We introduce openXBOW, an open-source toolkit for the generation of bag-of-words (BoW) representations from multimodal input. In the BoW principle, word histograms were first used as features in document classification, but the idea was and can easily be adapted to, e. g., acoustic or visual low-level descriptors, introducing a prior step of vector quantisation. The openXBOW toolkit supports arbitrary numeric input features and text input and concatenates computed subbags to a final bag. It provides a variety of extensions and options. To our knowledge, openXBOW is the first publicly available toolkit for the generation of crossmodal bags-of-words. The capabilities of the tool are exemplified in two sample scenarios: time-continuous speech-based emotion recognition and sentiment analysis in tweets where improved results over other feature representation forms were observed.", "creator": "LaTeX with hyperref package"}}}