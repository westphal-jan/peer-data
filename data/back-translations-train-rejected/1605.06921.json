{"id": "1605.06921", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-May-2016", "title": "Generative Choreography using Deep Learning", "abstract": "Recent advances in deep learning have enabled the extraction of high-level features from raw sensor data which has opened up new possibilities in many different fields, including computer generated choreography. In this paper we present a system chor-rnn for generating novel choreographic material in the nuanced choreographic language and style of an individual choreographer. It also shows promising results in producing a higher level compositional cohesion, rather than just generating sequences of movement. At the core of chor-rnn is a deep recurrent neural network trained on raw motion capture data and that can generate new dance sequences for a solo dancer. Chor-rnn can be used for collaborative human-machine choreography or as a creative catalyst, serving as inspiration for a choreographer.", "histories": [["v1", "Mon, 23 May 2016 07:36:49 GMT  (269kb)", "http://arxiv.org/abs/1605.06921v1", "This article will be presented at the 7th International Conference on Computational Creativity, ICCC2016"]], "COMMENTS": "This article will be presented at the 7th International Conference on Computational Creativity, ICCC2016", "reviews": [], "SUBJECTS": "cs.AI cs.LG cs.MM cs.NE", "authors": ["luka crnkovic-friis", "louise crnkovic-friis"], "accepted": false, "id": "1605.06921"}, "pdf": {"name": "1605.06921.pdf", "metadata": {"source": "CRF", "title": "Generative Choreography using Deep Learning", "authors": ["Luka Crnkovic-Friis", "Louise Crnkovic-Friis"], "emails": ["luka@peltarion.com", "louise@theluluartgroup.com"], "sections": [{"heading": null, "text": "Generative choreography with deep learningLuka Crnkovic-Friis Peltarionluka @ peltarion.com Louise Crnkovic-Friis The Lulu Art Grouplouise @ theluluartgroup.com"}, {"heading": "Abstract", "text": "Recent advances in deep learning have enabled the extraction of high-level features from sensor data, which has opened up new possibilities in many different areas, including computer-generated choreography. In this article, we present a system that can generate novel choreographic material in the nuanced choreographic language and style of a single choreographer. It also shows promising results in creating higher compositional cohesion rather than just motion sequences. chorus-rnn is a deep, recurring neural network trained on raw movement data that can generate new dance sequences for a solo dancer. Chorus-rnn can be used for collaborative human-machine choreography or as a creative catalyst that serves as inspiration for a choreographer."}, {"heading": "Introduction", "text": "To answer them, it is a good starting point to identify the different levels that flow into a choreographic work. A choreography can contain three basic levels of abstraction, style (the dynamic execution and expression of movement by the dancer), syntax (the choreographic language of work and the choreographer), and semantics (the general meaning or theme that binds the work into a coherent entity) (Blacking & Kealiinohomoko, 1979), all of which present unique practical and theoretical challenges to computer-generated choreography. As a syntax, the easiest way to formalize it in the form of a notation system was the logical starting point for the creation of generative choreography (Calvert, Wilke, Ryman, & Fox, 2005)."}, {"heading": "Related work", "text": "Previous work in this area has included various programmatic approaches with parameterized skeletal systems (Noll, 2013) and the use of simplified motion models combined with genetic algorithms to explore parameter space (Lapointe, 2005).Several systems have been developed as a combination of a visualization system with a selection of predefined motion materials that could be sequenced by the choreographer into longer compositions. Fully autonomous sequence generation has been largely limited to sequencing a combination of motion materials in the past (McCormick, 2015).Several proposed systems have been interactive, with one choreographer having to make a number of selections during the generation phase (Carlson, Schiphorst, & Pasquier, 2011).Artificial neural networks have been used in generative systems in the past (McCormick, 2015) but they have not been associated with deep learning and the neural network presented in this paper is neural position that is effective."}, {"heading": "Generative model", "text": "Recurrent neural networks (RNNs) are used to obtain state-of-the-art results for complex time series modeling tasks such as speech recognition and translation (Greff, Srivastava, Koutn\u00edk, Steunebrink, & Schmidhuber, 2015).Since the motion capture data is multidimensional time series, we use a deep RNN model."}, {"heading": "Long Short-Term Memory", "text": "This year, it is so far that it is only a matter of time before it is ready, until it is ready."}, {"heading": "Mixture Density LSTMs", "text": "The reason is that it's a mistake, and it's not a mistake, but a mistake, \"he said.\" I don't think it's a mistake, \"he said.\" I don't think it's a mistake, \"he said.\" I don't think it's a mistake, \"he said.\" I don't think it's a mistake. \""}, {"heading": "Training", "text": "The data collected consisted of five hours of contemporary dance motion recording material created and executed by a choreographer; the resulting data set consisted of 13.5 million spatio-temporal joint positions; we used several deep configurations, but the final topology of neural networks consisted of 3 hidden layers of 1024 neurons each (a total of approximately 21 million weights); the input data was a 75-dimensional tensor (25 joints x 3 dimensions); the model was trained for approximately 48 hours on a GPU computation server with 4 x Nvida Titan X GPUs (a total of 27 teraflops capacity); a batch size of 512 sequence parts (128 / GPU) was used with a sequence length of 1024 samples; the sequence length corresponds to the number of steps that the system is unrolled in time and, in fact, the number of layers in the steam; the number of layers in the sequence of the time (128 / GPU) is determined with a sequence length of a sample equal to the number of steps unrolled in the time of the steam; and, in fact, the number of layers in the steam length of the sequence is determined with a sample number of steps in the time (128 / 108)."}, {"heading": "Results", "text": "In fact, it is the case that most people who are able are able to determine for themselves what they want and what they do not want."}, {"heading": "Future work", "text": "The five hours of motion capture data was enough to build a proof-of-concept system, but ideally, the corpus should be larger, especially when multiple choreographers are involved; for comparison, speech recognition models use more than 100 hours of data (Andit is considered a major bottleneck in this area of research), resulting in a choreographic symbolic language; one of the most intriguing features of deep neural networks is that they build up multiple layers of abstraction inside (Hinton, 2014); and the use of a recurring autoencoder would allow us to compress significant higher-order information into a fixed tensor (Sutskever, Vinyals, & Le, 2014), which in turn would allow a symbolic language to be derived by mapping a system based on this encoding."}, {"heading": "Conclusions", "text": "This work describes a system, chorus-rnn, which is trained using a movement corpus that captures contemporary dance. It can generate novel choreographic sequences in the choreographic style represented in the corpus. Using a deep, recurring neural network, it is able to understand and generate choreography style, syntax, and to a certain extent semantics. Although it is currently limited to creating choreographies for a solo dancer, there are a number of interesting ways to explore for future work, including the possibility of tracking multiple dancers and experimenting with varying autoencoders that would enable the automatic construction of a symbolic language for movement that goes beyond a simple syntax. In addition to fully autonomous operation, chorus-rnn can be used by a choreographer as a creative catalyst or choreographic partner. We wondered if a computer could create meaningful choreographies and come up with tools that allow us to step closer to this question, or at least we can think of a new chorus."}], "references": [{"title": "Markerless Motion Capture using multiple Color-Depth Sensors. Paper presented at the VMV", "author": ["K. Berger", "K. Ruhl", "Y. Schroeder", "C. Bruemmer", "A. Scholz", "M.A. Magnor"], "venue": null, "citeRegEx": "Berger et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Berger et al\\.", "year": 2011}, {"title": "Mixture density networks", "author": ["C.M. Bishop"], "venue": null, "citeRegEx": "Bishop,? \\Q1994\\E", "shortCiteRegEx": "Bishop", "year": 1994}, {"title": "The Performing arts: music and dance: Walter de Gruyter", "author": ["J. Blacking", "J.W. Kealiinohomoko"], "venue": null, "citeRegEx": "Blacking and Kealiinohomoko,? \\Q1979\\E", "shortCiteRegEx": "Blacking and Kealiinohomoko", "year": 1979}, {"title": "The intimate act of choreography: University of Pittsburgh Pre", "author": ["L.A. Blom", "L.T. Chaplin"], "venue": null, "citeRegEx": "Blom and Chaplin,? \\Q1982\\E", "shortCiteRegEx": "Blom and Chaplin", "year": 1982}, {"title": "Applications of computers to dance", "author": ["T. Calvert", "L. Wilke", "R. Ryman", "I. Fox"], "venue": "Computer Graphics and Applications,", "citeRegEx": "Calvert et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Calvert et al\\.", "year": 2005}, {"title": "Scuddle: Generating movement catalysts for computeraided choreography", "author": ["K. Carlson", "T. Schiphorst", "P. Pasquier"], "venue": "Paper presented at the Proceedings of the Second International Conference on Computational Creativity", "citeRegEx": "Carlson et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Carlson et al\\.", "year": 2011}, {"title": "Reading dancing: Bodies and subjects in contemporary American dance", "author": ["S.L. Foster"], "venue": null, "citeRegEx": "Foster,? \\Q1986\\E", "shortCiteRegEx": "Foster", "year": 1986}, {"title": "Evaluating pointing accuracy on Kinect V2 sensor. Paper presented at the International Conference on Multimedia and Human-Computer Interaction (MHCI)", "author": ["H. F\u00fcrntratt", "H. Neuschmied"], "venue": null, "citeRegEx": "F\u00fcrntratt and Neuschmied,? \\Q2014\\E", "shortCiteRegEx": "F\u00fcrntratt and Neuschmied", "year": 2014}, {"title": "Generating sequences with recurrent neural networks", "author": ["A. Graves"], "venue": "arXiv preprint arXiv:1308.0850.", "citeRegEx": "Graves,? 2013", "shortCiteRegEx": "Graves", "year": 2013}, {"title": "Towards end-to-end speech recognition with recurrent neural networks", "author": ["A. Graves", "N. Jaitly"], "venue": "Paper presented at the Proceedings of the 31st International Conference on Machine Learning (ICML-14)", "citeRegEx": "Graves and Jaitly,? \\Q2014\\E", "shortCiteRegEx": "Graves and Jaitly", "year": 2014}, {"title": "LSTM: A search space odyssey", "author": ["K. Greff", "R.K. Srivastava", "J. Koutn\u00edk", "B.R. Steunebrink", "J. Schmidhuber"], "venue": "arXiv preprint arXiv:1503.04069", "citeRegEx": "Greff et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Greff et al\\.", "year": 2015}, {"title": "Choreo-graphics: a comparison of dance notation systems from the fifteenth century to the present", "author": ["A.H. Guest"], "venue": null, "citeRegEx": "Guest,? \\Q1998\\E", "shortCiteRegEx": "Guest", "year": 1998}, {"title": "Where do features come from", "author": ["G. Hinton"], "venue": "Cognitive science,", "citeRegEx": "Hinton,? \\Q2014\\E", "shortCiteRegEx": "Hinton", "year": 2014}, {"title": "3d depth cameras in vision: Benefits and limitations of the hardware Computer Vision and Machine Learning with RGB-D Sensors", "author": ["A. Kadambi", "A. Bhandari", "R. Raskar"], "venue": null, "citeRegEx": "Kadambi et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kadambi et al\\.", "year": 2014}, {"title": "Implementation of Human Action Recognition System Using Multiple Kinect Sensors Advances in Multimedia Information Processing--PCM", "author": ["B. Kwon", "D. Kim", "J. Kim", "I. Lee", "H. Oh", "S. . . Lee"], "venue": null, "citeRegEx": "Kwon et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kwon et al\\.", "year": 2015}, {"title": "Choreogenetics: The generation of choreographic variants through genetic mutations and selection", "author": ["Lapointe", "F.-J."], "venue": "Paper presented at the Proceedings of the 7th annual workshop on Genetic and evolutionary computation.", "citeRegEx": "Lapointe and F..J.,? 2005", "shortCiteRegEx": "Lapointe and F..J.", "year": 2005}, {"title": "Body-space-expression: The development of Rudolf Laban's movement and dance concepts (Vol", "author": ["V. Maletic"], "venue": "75): Walter de Gruyter.", "citeRegEx": "Maletic,? 1987", "shortCiteRegEx": "Maletic", "year": 1987}, {"title": "Emergent Behaviour: Learning From An Artificially Intelligent Performing", "author": ["J.H.S. McCormick", "Vincs", "Kim", "Vincent", "Jordan Beth"], "venue": null, "citeRegEx": "McCormick et al\\.,? \\Q2015\\E", "shortCiteRegEx": "McCormick et al\\.", "year": 2015}, {"title": "EARLY DIGITAL COMPUTER ART & ANIMATION AT BELL TELEPHONE LABORATORIES, INC", "author": ["A.M. Noll"], "venue": null, "citeRegEx": "Noll,? \\Q2013\\E", "shortCiteRegEx": "Noll", "year": 2013}, {"title": "Deep learning in neural networks: An overview", "author": ["J. Schmidhuber"], "venue": "Neural Networks, 61, 85-117.", "citeRegEx": "Schmidhuber,? 2015", "shortCiteRegEx": "Schmidhuber", "year": 2015}, {"title": "Sequence to sequence learning with neural networks. Paper presented at the Advances in neural information processing systems", "author": ["I. Sutskever", "O. Vinyals", "Q.V. Le"], "venue": null, "citeRegEx": "Sutskever et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 11, "context": "Although systems, such as Benesh movement notation and Labanotation have been proposed they have not been universally adopted mostly because of their steep learning curve (Guest, 1998).", "startOffset": 171, "endOffset": 184}, {"referenceID": 18, "context": "Earlier work in this field has included various programmatic approaches with parametrized skeleton systems (Noll, 2013) as well as using simplified movement models combined with genetic algorithms to explore the parameter space (Lapointe, 2005).", "startOffset": 107, "endOffset": 119}, {"referenceID": 16, "context": "The basic building block is the change of position in a 3D space (Maletic, 1987).", "startOffset": 65, "endOffset": 80}, {"referenceID": 0, "context": "Techniques for recording the movement of human body in space are called \u201cmotion capture\u201d and while here are various technical solutions at the time of writing, the most simple to use and cost effective was the Microsoft Kinect v2 sensor (Berger et al., 2011).", "startOffset": 237, "endOffset": 258}, {"referenceID": 14, "context": "Multiple sensors can be used to overcome that limitation, but it requires more complex software to combine the results (Kwon et al., 2015).", "startOffset": 119, "endOffset": 138}, {"referenceID": 19, "context": "LSTMs are stable over long training runs and can be stacked to form deeper networks without loss of stability (Schmidhuber, 2015).", "startOffset": 110, "endOffset": 129}, {"referenceID": 1, "context": "In general, it can be shown that when using a mean square error metric, the output will stagnate and converge to an average output (Bishop, 1994).", "startOffset": 131, "endOffset": 145}, {"referenceID": 1, "context": "This technique has been used successfully among other things for robotic arm control (Bishop, 1994) as well as handwriting generation (Graves, 2013).", "startOffset": 85, "endOffset": 99}, {"referenceID": 8, "context": "This technique has been used successfully among other things for robotic arm control (Bishop, 1994) as well as handwriting generation (Graves, 2013).", "startOffset": 134, "endOffset": 148}, {"referenceID": 10, "context": "(Greff et al., 2015) The neural network was trained with RMS Prop using Back Propagation Through-Time.", "startOffset": 0, "endOffset": 20}, {"referenceID": 6, "context": "Generally speaking, the semantic level is the most difficult to quantify, especially when it comes to avant-garde art as it does not follow an established form (Foster, 1986).", "startOffset": 160, "endOffset": 174}, {"referenceID": 12, "context": "As with text or image generation (Hinton, 2014), the semantic level is the last one to emerge from the training.", "startOffset": 33, "endOffset": 47}, {"referenceID": 12, "context": "Derive a choreographic symbolic language One of the most intriguing features of deep neural networks is that they internally build up multiple levels of abstraction (Hinton, 2014).", "startOffset": 165, "endOffset": 179}, {"referenceID": 14, "context": "The solution is to use multiple Kinect sensors and combine their data (Kwon et al., 2015).", "startOffset": 70, "endOffset": 89}], "year": 2016, "abstractText": "Recent advances in deep learning have enabled the extraction of high-level features from raw sensor data which has opened up new possibilities in many different fields, including computer generated choreography. In this paper we present a system chorrnn for generating novel choreographic material in the nuanced choreographic language and style of an individual choreographer. It also shows promising results in producing a higher level compositional cohesion, rather than just generating sequences of movement. At the core of chor-rnn is a deep recurrent neural network trained on raw motion capture data and that can generate new dance sequences for a solo dancer. Chor-rnn can be used for collaborative human-machine choreography or as a creative catalyst, serving as inspiration for a choreographer.", "creator": "Acrobat PDFMaker 15 for Word"}}}