{"id": "1605.06940", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-May-2016", "title": "Elastic Solver: Balancing Solution Time and Energy Consumption", "abstract": "Combinatorial decision problems arise in many different domains such as scheduling, routing, packing, bioinformatics, and many more. Despite recent advances in developing scalable solvers, there are still many problems which are often very hard to solve. Typically the most advanced solvers include elements which are stochastic in nature. If a same instance is solved many times using different seeds then depending on the inherent characteristics of a problem instance and the solver, one can observe a highly-variant distribution of times spanning multiple orders of magnitude. Therefore, to solve a problem instance efficiently it is often useful to solve the same instance in parallel with different seeds. With the proliferation of cloud computing, it is natural to think about an elastic solver which can scale up by launching searches in parallel on thousands of machines (or cores). However, this could result in consuming a lot of energy. Moreover, not every instance would require thousands of machines. The challenge is to resolve the tradeoff between solution time and energy consumption optimally for a given problem instance. We analyse the impact of the number of machines (or cores) on not only solution time but also on energy consumption. We highlight that although solution time always drops as the number of machines increases, the relation between the number of machines and energy consumption is more complicated. In many cases, the optimal energy consumption may be achieved by a middle ground, we analyse this relationship in detail. The tradeoff between solution time and energy consumption is studied further, showing that the energy consumption of a solver can be reduced drastically if we increase the solution time marginally. We also develop a prediction model, demonstrating that such insights can be exploited to achieve faster solutions times in a more energy efficient manor.", "histories": [["v1", "Mon, 23 May 2016 08:54:27 GMT  (169kb,D)", "http://arxiv.org/abs/1605.06940v1", "Keywords: Combinatorial Optimisation, Energy Minimisation, Parallel Solving"]], "COMMENTS": "Keywords: Combinatorial Optimisation, Energy Minimisation, Parallel Solving", "reviews": [], "SUBJECTS": "cs.AI cs.DC", "authors": ["barry hurley", "deepak mehta", "barry o'sullivan"], "accepted": false, "id": "1605.06940"}, "pdf": {"name": "1605.06940.pdf", "metadata": {"source": "CRF", "title": "Elastic Solver: Balancing Solution Time and Energy Consumption", "authors": ["Barry Hurley", "Deepak Mehta"], "emails": ["barry.hurley@insight-centre.org", "deepak.mehta@insight-centre.org", "barry.osullivan@insight-centre.org"], "sections": [{"heading": null, "text": "In fact, most of them are able to determine for themselves what they want and what they don't want."}, {"heading": "II. TIME VS ENERGY", "text": "This chapter analyzes the behavior of the solution time and the total energy in relation to the number of cores used can then be repeated trust. However, we assume that every physical machine is associated with a CPU core. The benchmark series includes 1676 industrial instances of combinatorial consumption of 9 years of SAT competitions, races and challenges from 2002 to 2011. Each instance was collected using MiniSat 2.0 [9] as a solver with 100 different seeds, a time span of 1 hour CPU time for each run and a limit of 2GB RAM. Performance data was collected on a cluster of Intel Xeon E5430 processors (2.66 GHz). In total, 315 weeks of CPU time were consumed to accumulate these performance data. Instances that were not resolved within the time limit over each run, or were resolved in every second over each round, resulting in a total of 902 challenging industry.When the distribution of time is used, the distribution of statistics are used."}, {"heading": "III. PREDICTING THE OPTIMAL NUMBER OF CORES", "text": "The previous sections have shown that there is no consistent number of cores to achieve the balance between energy consumption and solving time. This section shows that a predictive model can be built to exploit this knowledge and make intelligent decisions. We will develop a model for predicting the number of cores. [11] The first task is to link a set of attributes to each instance."}, {"heading": "IV. CONCLUSIONS", "text": "In this paper, we have proposed an elastic solvent that can balance solving time and energy consumption, which can be increased in the cloud environment by predicting the number of cores needed to achieve the balance between the two criteria. We have studied the behavior of solver energy consumption in many real industrial cases when different cores are used. Despite the non-trivalent relationship between solving time and energy, the prediction model is highly effective in predicting the optimal number of cores that will minimize total energy consumption."}], "references": [{"title": "Exploiting Runtime Variation in Complete Solvers", "author": ["C.P. Gomes", "A. Sabharwal"], "venue": "Handbook of Satisfiability, 2009, pp. 271\u2013288.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2009}, {"title": "Statistical regimes and runtime prediction", "author": ["B. Hurley", "B. O\u2019Sullivan"], "venue": "Proceedings of the Twenty-Fourth International Joint Conference on Artificial Intelligence, IJCAI 2015, 2015, pp. 318\u2013324.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2015}, {"title": "Heavytailed Phenomena in Satisfiability and Constraint Satisfaction Problems", "author": ["C.P. Gomes", "B. Selman", "N. Crato", "H. Kautz"], "venue": "Journal of Automated Reasoning, vol. 24, no. 1-2, pp. 67\u2013100, 2000.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2000}, {"title": "Expected Gains from Parallelizing Constraint Solving for Hard Problems", "author": ["T. Hogg", "C.P. Williams"], "venue": "Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence, pp. 331\u2013336, 1994.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1994}, {"title": "Minisat 2.2", "author": ["N. Een", "N. S\u00f6rensson"], "venue": "http://minisat.se, 2013.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2013}, {"title": "Features for SAT", "author": ["L. Xu", "F. Hutter", "H. Hoos", "K. Leyton-Brown"], "venue": "2012. [Online]. Available: http://www.cs.ubc.ca/ labs/beta/Projects/SATzilla/\\Report SAT features.pdf", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}, {"title": "Algorithm runtime prediction: Methods & evaluation", "author": ["F. Hutter", "L. Xu", "H.H. Hoos", "K. Leyton-Brown"], "venue": "Artificial Intelligence, vol. 206, pp. 79\u2013111, 2014.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2014}, {"title": "SATzilla: Portfolio-based Algorithm Selection for SAT", "author": ["L. Xu", "F. Hutter", "H.H. Hoos", "K. Leyton-Brown"], "venue": "Journal Of Artificial Intelligence Research, 2008, pp. 565\u2013 606.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2008}, {"title": "ISAC \u2013 Instance-Specific Algorithm Configuration", "author": ["S. Kadioglu", "Y. Malitsky", "M. Sellmann", "K. Tierney"], "venue": "Proceedings of the 19th European Conference on Artificial Intelligence (ECAI 2010), 2010, pp. 751\u2013756.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2010}], "referenceMentions": [{"referenceID": 0, "context": "Choices for parameters such as the search heuristics, restarting policy, and even random seed can affect the size of the search space and subsequently the time it takes to find a solution [4].", "startOffset": 188, "endOffset": 191}, {"referenceID": 1, "context": "Variable and value selection heuristics have elements which are stochastic in nature, so the slightest difference over repeated runs can magnify the performance variations [5].", "startOffset": 172, "endOffset": 175}, {"referenceID": 2, "context": "Such variations can be modelled by heavy- or fat-tailed distributions [6].", "startOffset": 70, "endOffset": 73}, {"referenceID": 0, "context": "However, the runtime distributions can be exploited, either by randomised restarting [4], or parallelisation [7].", "startOffset": 85, "endOffset": 88}, {"referenceID": 3, "context": "However, the runtime distributions can be exploited, either by randomised restarting [4], or parallelisation [7].", "startOffset": 109, "endOffset": 112}, {"referenceID": 4, "context": "0 [9] as the solver with 100 different seeds, a timeout of 1 hour CPU-time for each run, and a limit of 2GB RAM.", "startOffset": 2, "endOffset": 5}, {"referenceID": 5, "context": "We employ the state of the art collection of 138 features [10], which have been proved highly-effective in areas of runtime prediction [11], [5] and solver portfolios [12], [13].", "startOffset": 58, "endOffset": 62}, {"referenceID": 6, "context": "We employ the state of the art collection of 138 features [10], which have been proved highly-effective in areas of runtime prediction [11], [5] and solver portfolios [12], [13].", "startOffset": 135, "endOffset": 139}, {"referenceID": 1, "context": "We employ the state of the art collection of 138 features [10], which have been proved highly-effective in areas of runtime prediction [11], [5] and solver portfolios [12], [13].", "startOffset": 141, "endOffset": 144}, {"referenceID": 7, "context": "We employ the state of the art collection of 138 features [10], which have been proved highly-effective in areas of runtime prediction [11], [5] and solver portfolios [12], [13].", "startOffset": 167, "endOffset": 171}, {"referenceID": 8, "context": "We employ the state of the art collection of 138 features [10], which have been proved highly-effective in areas of runtime prediction [11], [5] and solver portfolios [12], [13].", "startOffset": 173, "endOffset": 177}], "year": 2017, "abstractText": "Combinatorial decision problems arise in many different domains such as scheduling, routing, packing, bioinformatics, and many more. Unfortunately, most of these problems are NP-complete. Despite recent advances in developing scalable solvers, there are still many problems which are often very hard to solve. Typically the most advanced solvers include elements which are stochastic in nature. If a same instance is solved many times using different seeds then depending on the inherent characteristics of a problem instance and the solver, one can observe a highly-variant distribution of times spanning multiple orders of magnitude. Therefore, to solve a problem instance efficiently it is often useful to solve the same instance in parallel with different seeds. With the proliferation of cloud computing, it is natural to think about an elastic solver which can scale up by launching searches in parallel on thousands of machines (or cores). However, this could result in consuming a lot of energy. Moreover, not every instance would require thousands of machines. The challenge is to resolve the tradeoff between solution time and energy consumption optimally for a given problem instance. We analyse the impact of the number of machines (or cores) on not only solution time but also on energy consumption. We highlight that although solution time always drops as the number of machines increases, the relation between the number of machines and energy consumption is more complicated. In many cases, the optimal energy consumption may be achieved by a middle ground, we analyse this relationship in detail. The tradeoff between the solution time and energy consumption is studied further, showing that the energy consumption of a solver can be reduced drastically if we increase the solution time marginally. We also develop a prediction model using machine learning, demonstrating that such insights can be exploited to achieve faster solutions times in a more energy efficient manor. Keywords-keywords: Combinatorial Optimisation, Energy Minimisation, Parallel Solving", "creator": "LaTeX with hyperref package"}}}