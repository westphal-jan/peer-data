{"id": "1605.07162", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-May-2016", "title": "Pure Exploration of Multi-armed Bandit Under Matroid Constraints", "abstract": "We study the pure exploration problem subject to a matroid constraint (Best-Basis) in a stochastic multi-armed bandit game. In a Best-Basis instance, we are given $n$ stochastic arms with unknown reward distributions, as well as a matroid $\\mathcal{M}$ over the arms. Let the weight of an arm be the mean of its reward distribution. Our goal is to identify a basis of $\\mathcal{M}$ with the maximum total weight, using as few samples as possible.", "histories": [["v1", "Mon, 23 May 2016 19:51:42 GMT  (39kb)", "http://arxiv.org/abs/1605.07162v1", "To appear in COLT 2016"], ["v2", "Tue, 24 May 2016 19:20:41 GMT  (50kb)", "http://arxiv.org/abs/1605.07162v2", "Accepted for presentation at Conference on Learning Theory (COLT) 2016"], ["v3", "Wed, 25 May 2016 16:03:23 GMT  (39kb)", "http://arxiv.org/abs/1605.07162v3", "Accepted for presentation at Conference on Learning Theory (COLT) 2016"]], "COMMENTS": "To appear in COLT 2016", "reviews": [], "SUBJECTS": "cs.LG cs.DS", "authors": ["lijie chen", "anupam gupta", "jian li"], "accepted": false, "id": "1605.07162"}, "pdf": {"name": "1605.07162.pdf", "metadata": {"source": "CRF", "title": "Pure Exploration of Multi-armed Bandit Under Matroid Constraints", "authors": ["Lijie Chen", "Anupam Gupta", "Jian Li"], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 160 5.07 162v 1 [cs.L G] 23 MThe problem is a significant generalization of the problem of best-k arm identification and the problem of top-k arm identification, which have attracted considerable attention in recent years. We examine both the exact and the PAC version of best-base and provide algorithms with approximately optimal sample complexity for these versions. Our results generalize and / or improve several previous results for the problem of top-k arm identification and the combinatorial problem of pure exploration when the combinatorial constraint is a matroid."}, {"heading": "1 Introduction", "text": "The stochastic, multi-armed bandit is a classic model for characterizing the problem of exploration exploitation in many decision problems in stochastic environments. Popular goals include maximizing the cumulative sum of rewards, or minimizing cumulative regret (see, for example, [CBL06, BCB12]), but in many application areas, the exploration phase and the evaluation phase are separated. Decision makers can conduct a pure exploration phase to identify an optimal (or near-optimal) solution, and then exploit it further. Such problems have received considerable attention in application domains such as medical studies such as Rob85, AB10], communications network, crowdsourcing [ZCL14, CLTL15]. In particular, the problem of identifying the best arm in a stochastic game has received considerable attention in recent years."}, {"heading": "1.1 Identifying the Exact Optimal basis", "text": "Definition 1.2. (Exact Base) Given a best-base instance S = (S, M) and a confidence level \u03b4 > 0, the goal is to output the optimal base of M (one that maximizes the difference between the individual elements) and not a gap (i.e., elements that do not belong to a base), as we can always include or ignore them without affecting the solution. We use OPT (M) to name the optimal base (as well as the optimal total weight) for matroid M. For a subset of elements F S, the constraint from M to F, and M / F the contraction of M from F (see definition 2.3)."}, {"heading": "1.2 The PAC setting", "text": "Next, we discuss our results for the PAC setting. Several concepts of approximation were used for the specific case of best-k arm when we return a set I of k arms. Kalyanakrishnan and al. [KTAS12] required that the mean of each arm in me must be at least \u00b5 [k] \u2212 \u03b5 (The Explore k metric). Zhou et al. [ZCL14] required that the mean of the average 1k-e number in me must be at least 1 k number. [i] \u2212 \u03b5; we call such a solution an average-optimal solution. Finally, we proposed [CLTL15] a stronger metric that would require the mean of the ith arm in me, for all i elements. [k] This notion, which we call optimal, extends to general matroids."}, {"heading": "1.2.1 Average-\u03b5-optimality", "text": "For this definition, we give another algorithm with lower sample complexity. Definition 1.8. (PAC-Base Avg) For a matroid M = (S, I) with cost function \u00b5: S \u2192 R +. Suppose a Base I is an average-par-optimal solution (w.r.t. \u00b5) if: 1 k) and its sample complexity at mostO (((n \u00b7 (1 + ln \u043c (M) \u2212 \u03b5.Theorem 1.9. There is an algorithm for PAC-Base Avg that can provide an average-optimal solution for S with a probability of at least 1 \u2212 \u043c, and its sample complexity is mostO ((n \u00b7 (1 + ln \u043c \u2212 1 / k) + (ln \u00b2 -1 \u2212 ln)) and its complexity is at a very narrow sample (ln \u00b2) and at a very narrow sample (ln \u00b2 -0.1) and a very narrow sample (1)."}, {"heading": "1.2.2 Prior and Our Techniques", "text": "Several previous algorithms for the PAC versions of best-1 arm and best-k arm (e.g., [KKS13, ZCL14, EDMM02]) were elimination based, roughly speaking, using the following framework: In the first round random each remaining arm Qr times, 2 and eliminate all arms whose empirical means2Typical, Qr rises exponentially with r.fall below a certain threshold. This threshold can be either a percentile, as in [EDMM02, ZCL14] or an \u03b5-optimal arm, which is achieved by some PAC algorithms, as in [KKS13]. After eliminating some arms, we proceed to the next round. Small variations to this method are possible, for example, if the number of remaining arms is not much greater than k, we can directly use the na \u0131ve uniform sampling algorithm."}, {"heading": "1.3 Other Related Work", "text": "For the PAC version of the problem, 3 Even-Dar et al. [EDMM02] provided an algorithm with sample complexity. [Far64] showed a lower limit of regret, which is also optimal. [2] ln [2] ln [3] ln [4] proved to be a lower limit of regret, even if there are only two arms. [KKS13] obtained a higher limit of regret. [4] We have a lower limit of regret. [5] ln [5] ln [5] ln [5] ln [5] -1])), even if there are only two arms. [KS13] obtained a higher limit of regret. (5) [5] We have obtained a lower limit of regret. (5) + ln [5])."}, {"heading": "2 Preliminaries", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Useful Facts about Matroids", "text": "While there are many equivalent definitions for matroids, we find this one most convenient. (Definition 2.1) We assume that the matroid M (S, I) consists of a limited number of matroids having a limited number of matroids (A). (Definition 2.1) We assume that the matroid M (S, I) consists of a limited number of matroids having a limited number of matroids (A) and a non-empty family I of the subsets of S (having a limited number of matroids) having an independent number of matroids (S, I) having an independent number of matroids (M) is an independent group of M (M), an independent group is maximum if there is no proper subset of another independent group; a maximum independent set is referred to as an independent element. (Definition 2.2)"}, {"heading": "2.2 Uniform Sampling", "text": "Algorithm 1: UniformSample (S, \u03b5, \u03b4) Data: Arm set S, error bound \u03b5, confidence level \u03b4. Result: For each arm a you output the empirical mean of p x a. 1 For each arm a x S you try \u03b5 \u2212 2 ln (2 x 3 x 1) / 2 times. Let \u00b5 a be the empirical meaning.The following problem for algorithm 1 is a direct consequence of the set A.1.1.Lemma 2.9. For each arm a x S we have this Pr [| \u00b5a \u2212 \u00b5] a x xi."}, {"heading": "3 An Optimal PAC Algorithm for the PAC-Basis Problem", "text": "In this section, we will prove Theorem 1.7 by presenting an algorithm for PAC base with optimal sample complexity, which is also a useful subprocedure for Exact base and PAC base avg."}, {"heading": "3.1 Notation", "text": "For a matroid M = (S, I) with cost function \u00b5: \u2265 S \u2192 R +, and a base I, the following statements are equivalent: 1. I am \u03b5-optimal for M with respect to \u00b5. 2. For each e-matroid M\\ I, I \u2265 \u00b5 (e) \u2212 \u03b5 blocks e. 3. For each r-matroid R, let Dr = (S\\ I) \u2265 R, let Dr = (S-approximation subset) \u2265 r + \u03b5 I \u2265 r. I \u2265 r is a basis in MDr.Proof. Apply Lemma 2.8 with the cost function \u00b5I, \u03b5, as in definition 1.5.Definition 3.2 \u2212 \u2212 Proximation Subset. Given a matroid M = (S, I) and cost function \u00b5: S \u2192 R +, let A B is an optimal subset of S. We say A is a quantitative subset of B \u2212 \u2212 \u2212 if there is an independent subset."}, {"heading": "3.2 Na\u0308\u0131ve Uniform Sampling Algorithm", "text": "We start with a uniform sampling algorithm, which examines each arm sufficiently often as a sample to ensure that the empirical means are most likely all within \u03b5 / 2 of the true means, and then output the optimal solution with respect to the empirical means. The algorithm is a useful procedure in our final algorithm. Result: A Base I in M.1 \u00b5. UniformSample (S, \u03b5, \u03b5, \u03b4) Data: A PAC-based instance S = (S, M), with rank (M) = k, approximation error \u03b5, confidence level \u03b4. Result: A Base I in M.1 \u00b5. UniformSample (S, \u03b5 / 2, \u03b4 / | S |) 2 Return The optimal solution I with respect to the empirical averages. Lemma 3.5. The Nave-I (S, \u03b5, \u043c) algorithm gives an egg-optimal solution for S with probability of at least 1 \u2212 \u00b5\u043c. The number of samples is O."}, {"heading": "3.3 Sampling and Pruning", "text": "Our optimal PAC algorithm uses the scanning and trimming technique originally developed in the celebrated work of Karger, Klein and Tarjan [KKT95], who used the technique to obtain an expected linear time algorithm for calculating the minimum voltage range. We first describe the high-level idea from [KKT95], which will be instructive for our future development. Let's say we want to find the maximum voltage tree (MST). We first construct a subgraph F by scanning each edge with the probability p; this subgraph may not be connected, so we can solve the maximum weight span of Wald I from F. The key idea is this: We can use I to process a lot of \"useless\" edges in the original graph. Formally, an edge e = (u, v) is useless if edges can be associated with greater costs in me, and v: This is because the cheapest cycle is not part of the ST."}, {"heading": "3.4 Our Optimal PAC Algorithm", "text": "s leave p = 0.01. The algorithm works as follows: If the number of arms | S | is sufficiently small, we simply execute the uniform scanning algorithm. Otherwise, we sample a subset F of S by selecting each arm independently with the probability p and selecting recursively on the substance SF = (F, MF) to find an optimal solution I, where \u03b1 = \u03b5 / 3. Next, we stitch uniformly each arm in S by calling UniformSample (S, \u03bb, p / 8k), using me to eliminate these suboptimal arms in S\\ I. Specifically, a suboptimal arm e in S."}, {"heading": "3.5 Analysis of the sample complexity", "text": "In this subsection, we will first analyze the simple case in which we are not much larger than in most cases. < < < < p > p > p > p > p > p (S, M), algorithm PAC-SamplePrune (S, M), and n =. Let's leave c1, c2 are two constants to be specified later. We will prove by induction that with a probability of at least 1 \u2212 p, PAC-SamplePrune (S, M), an optimal solution is found."}, {"heading": "4 An Algorithm for the Exact-Basis Problem", "text": "Let's now turn to the Exact Base Problem and prove Theorem 1.4. If we designate the unique optimal base by OPT and let BAD be the set of all other arms in S\\ OPT, our goal for the Exact Base Problem is to find this set of OPT with confidence, using as few samples as possible. Our Exact-ExpGap algorithm is either based on our previous PAC result for PAC base and also borrows an idea from the Exponential Gap Elimination Algorithm using [KKS13]. It runs in rounds. In each round, it tries to eliminate some arms in BAD (we call such a round an elimination round), or it inserts some arms from OPT into our solution and removes them for further consideration (we call such a round a selection round). Let Mcur give some details about these two types of rounds. Let's define the current matroid, nop the number of remaining arms in OPT."}, {"heading": "4.1 Analysis of the algorithm", "text": "We prove the most important theories of this section by extending the correctness and complexity of the individual elements. < p > p > p > p > p > p > p > p < p > p > p > p > p > p > p > p > p > p < p > p > p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p. \"p\" p \"p\" p \"p\" p \"p\" p \"p.\" p \"p\" p \"p\" p \"p.\" p \"p\" p \"p\" p. \"p\" p \"p\" p \"p.\" p. \"p\" p. \"p\" p \"p.\" p \"p\" p. \"p\" p \"p\" p \"p.\" p \"p\" p \"p."}, {"heading": "4.1.1 Analysis of Sample Complexity", "text": "To analyze the complexity of the selection round, we need to select some additional notations. Let's nropt (resp. n > r bad) select the term nopt (resp. nbad) at the beginning of the selection round (resp. the selection round). We also let Srelim specify the arm of Mcur at the end of the selection round, and Srsele specifies the arm of Mcur at the end of the selection round. We divide the arms into OPT and BAD based on their gaps, as follows: OPTs = [u] OPT | 2 \u2212 s \u2264 \"s.\" < 2 \u2212 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s, \"BADs =\" s \u00b2 s \u00b2 s. \"Furthermore, we define OPTr, s: = S r sele\" OPTs, \"i.e., the set of weapons in OPTs not in the selection round - remember that we aim to select them in a selection round.\""}, {"heading": "5 An Algorithm for PAC-Basis-Avg", "text": "In this section, we will prove Theorem 1.9 by providing an algorithm with the desired sample complexity."}, {"heading": "5.1 Building Blocks", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "1. Na\u0308\u0131ve Uniform Sampling Algorithm:", "text": "We first examine how many samples the uniform sample algorithm needs to find an average-optimal solution.The uniform sample procedure in Nave-II has a different parameter than in Nave-I. Algorithm 5: Nave-II (S, \u03b5, \u03b4) Data: A PAC base average instance S = (S, M), with rank (M) = k, approximation error \u03b5, confidence level \u03b4. Result: A basis in M.1 sample for each arm e-S for Q0 = 2\u03b5 \u2212 2 \u00b7 ln 2 (| S | k) \u03b4 / k times. Let it be its empirical mean. 2 Return The optimal solution I in terms of empirical averages. The following problem shows the performance of the above algorithm. The proof is fairly standard and can be found in the appendix."}, {"heading": "2. Elimination Procedure:", "text": "The following approach is our main component based on its empirical means. Roughly speaking, it can help us eliminate a constant fraction of the remaining arms while maintaining the value of the optimal solution. \u2212 The idea of the method is similar to PAC-SamplePrune in Section 3. It works as follows: First, a random subset F is determined by selecting each element independently with the probability p. This guarantees the additive errors for all arms in I / 5, with a probability of at least 1 \u2212 6. Then we take a uniform number Q0 = \u03b2 \u2212 2max (ln 6g, ln 200 / 2) of the samples from the other arms."}, {"heading": "5.2 Main Algorithm", "text": "In this section, we present our main algorithm for finding an average-optimal solution. The algorithm works as follows: If | S | is small enough, we simply invoke the following (Sr, MSr) -II and Lemma 5.1 can guarantee that we will find an average-optimal solution. Otherwise, we proceed in rounds (Sr, MSr) until the number of weapons is less than a certain number. Elimination guarantees that the number of weapons decreases exponentially, hence the number of samples is dominated by the first call to Elimination. In the end, we invoke Nave-II on the rest arms to find the final solution. The pseudo-code can be found in Algorithm 7.Algorithm: AvgPAC Elimination."}, {"heading": "6 Future Work", "text": "In this paper, we present near-optimal algorithms for both the exact and the PAC version of the pure exploration problem, which is highly likely to be subject to matroid constraint in a stochastic, multi-armed bandit game: Choose a basis for the matroid whose weight (the sum of expectations relative to the weapons on that basis) is as high as possible. An immediate direction for the investment is to extend our results to other polynomial-time calculable combinatorial constraints: s-t paths, comparisons (or more generally: the intersection of two matroids), etc. The model also extends to NP-hard combinatorial constraints, but there we would probably compare our solution with \u03b1-approximate solutions rather than the optimal solution. Considering nonlinear functions of the agent is another natural next step."}, {"heading": "A Preliminaries in Probability", "text": "First, we introduce the following versions of the standard Chernoff-Hoeffding distribution.Proposition A.1. Leave Xi (1 \u2264 i \u2264 n) n independent random variables with values in [0, 1].Leave X = > random variables in [0, 1].Leave X = > random variables in [0, 1].Leave X = > n random variables in [0, 1], andPr [X \u2212 E [X] \u2264 \u2212 t] \u2264 \u2212 t exp (\u2212 2t2n).2 For each t > 0, we have thatPr [X < (1 \u2212 2 \u2212 n).We have thatPr [X \u2212 p] \u2264 exp (X \u2212 X] / 2) \u2264 exp (1 + A.Y (\u2212 2t2n).2 For each other event > 0."}, {"heading": "B Missing Proofs", "text": "The proof of Proposition 1.6. Let me be a \"best-k arm\" solution. We show that it is also elementary-\u03b5-optimal (1,1). Let me be the arm with the largest mean in OPT and the arm with the largest mean in I. Let us suppose that the arm after oi and all other elements with j < i. Let P be the totality of all arms with no less than oi in terms of \u00b5I. Let us now look at the sorted list of arms according to the modified cost function of i, \u03b5. The arm ai will be after oi and all other elements with j < i. Let P consider the totality of all arms with no less than oi in terms of capability in terms of \u00b5I."}], "references": [{"title": "Best arm identification in multi-armed bandits", "author": ["Jean-Yves Audibert", "S\u00e9bastien Bubeck"], "venue": "In COLT-23th Conference on Learning Theory-2010, pages 13\u2013p,", "citeRegEx": "Audibert and Bubeck.,? \\Q2010\\E", "shortCiteRegEx": "Audibert and Bubeck.", "year": 2010}, {"title": "Regret in online combinatorial optimization", "author": ["Jean-Yves Audibert", "S\u00e9bastien Bubeck", "G\u00e1bor Lugosi"], "venue": "Mathematics of Operations Research,", "citeRegEx": "Audibert et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Audibert et al\\.", "year": 2013}, {"title": "Regret analysis of stochastic and nonstochastic multi-armed bandit problems", "author": ["S\u00e9bastien Bubeck", "Nicolo Cesa-Bianchi"], "venue": "arXiv preprint arXiv:1204.5721,", "citeRegEx": "Bubeck and Cesa.Bianchi.,? \\Q2012\\E", "shortCiteRegEx": "Bubeck and Cesa.Bianchi.", "year": 2012}, {"title": "Multiple identifications in multi-armed bandits", "author": ["S\u00e9bastien Bubeck", "Tengyao Wang", "Nitin Viswanathan"], "venue": "arXiv preprint arXiv:1205.3181,", "citeRegEx": "Bubeck et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Bubeck et al\\.", "year": 2012}, {"title": "Multiple identifications in multi-armed bandits", "author": ["S\u00e9ebastian Bubeck", "Tengyao Wang", "Nitin Viswanathan"], "venue": "In Proceedings of The 30th International Conference on Machine Learning,", "citeRegEx": "Bubeck et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bubeck et al\\.", "year": 2013}, {"title": "Prediction, learning, and games", "author": ["Nicolo Cesa-Bianchi", "G\u00e1bor Lugosi"], "venue": "Cambridge university press,", "citeRegEx": "Cesa.Bianchi and Lugosi.,? \\Q2006\\E", "shortCiteRegEx": "Cesa.Bianchi and Lugosi.", "year": 2006}, {"title": "Combinatorial bandits", "author": ["Nicolo Cesa-Bianchi", "G\u00e1bor Lugosi"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "Cesa.Bianchi and Lugosi.,? \\Q2012\\E", "shortCiteRegEx": "Cesa.Bianchi and Lugosi.", "year": 2012}, {"title": "On the optimal sample complexity for best arm identification", "author": ["Lijie Chen", "Jian Li"], "venue": "arXiv preprint arXiv:1511.03774,", "citeRegEx": "Chen and Li.,? \\Q2015\\E", "shortCiteRegEx": "Chen and Li.", "year": 2015}, {"title": "Combinatorial pure exploration of multi-armed bandits", "author": ["Shouyuan Chen", "Tian Lin", "Irwin King", "Michael R Lyu", "Wei Chen"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Chen et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2014}, {"title": "On top-k selection in multi-armed bandits and hidden bipartite graphs", "author": ["Wei Cao", "Jian Li", "Yufei Tao", "Zhize Li"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Cao et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Cao et al\\.", "year": 2015}, {"title": "Combinatorial multi-armed bandit: General framework and applications", "author": ["Wei Chen", "Yajun Wang", "Yang Yuan"], "venue": "In Proceedings of the 30th International Conference on Machine Learning,", "citeRegEx": "Chen et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2013}, {"title": "Pac bounds for multi-armed bandit and markov decision processes. In Computational Learning Theory, pages 255\u2013270", "author": ["Eyal Even-Dar", "Shie Mannor", "Yishay Mansour"], "venue": null, "citeRegEx": "Even.Dar et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Even.Dar et al\\.", "year": 2002}, {"title": "Action elimination and stopping conditions for the multi-armed bandit and reinforcement learning problems", "author": ["Eyal Even-Dar", "Shie Mannor", "Yishay Mansour"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Even.Dar et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Even.Dar et al\\.", "year": 2006}, {"title": "Asymptotic behavior of expected sample size in certain one sided tests", "author": ["RH Farrell"], "venue": "The Annals of Mathematical Statistics,", "citeRegEx": "Farrell.,? \\Q1964\\E", "shortCiteRegEx": "Farrell.", "year": 1964}, {"title": "Best arm identification: A unified approach to fixed budget and fixed confidence", "author": ["Victor Gabillon", "Mohammad Ghavamzadeh", "Alessandro Lazaric"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Gabillon et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Gabillon et al\\.", "year": 2012}, {"title": "Multi-bandit best arm identification", "author": ["Victor Gabillon", "Mohammad Ghavamzadeh", "Alessandro Lazaric", "S\u00e9bastien Bubeck"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Gabillon et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Gabillon et al\\.", "year": 2011}, {"title": "Improved learning complexity in combinatorial pure exploration bandits", "author": ["Victor Gabillon", "Alessandro Lazaric", "Mohammad Ghavamzadeh", "Ronald Ortner", "Peter Bartlett"], "venue": "In Proceedings of the 19th International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "Gabillon et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Gabillon et al\\.", "year": 2016}, {"title": "lil\u2019ucb: An optimal exploration algorithm for multi-armed bandits", "author": ["Kevin Jamieson", "Matthew Malloy", "Robert Nowak", "S\u00e9bastien Bubeck"], "venue": "COLT,", "citeRegEx": "Jamieson et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Jamieson et al\\.", "year": 2014}, {"title": "Random sampling and greedy sparsification for matroid optimization problems", "author": ["David R Karger"], "venue": "Mathematical Programming,", "citeRegEx": "Karger.,? \\Q1998\\E", "shortCiteRegEx": "Karger.", "year": 1998}, {"title": "On the complexity of best arm identification in multi-armed bandit models", "author": ["Emilie Kaufmann", "Olivier Capp\u00e9", "Aur\u00e9lien Garivier"], "venue": "arXiv preprint arXiv:1407.4443,", "citeRegEx": "Kaufmann et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kaufmann et al\\.", "year": 2014}, {"title": "Information complexity in bandit subset selection", "author": ["Emilie Kaufmann", "Shivaram Kalyanakrishnan"], "venue": "In Conference on Learning Theory, pages 228\u2013251,", "citeRegEx": "Kaufmann and Kalyanakrishnan.,? \\Q2013\\E", "shortCiteRegEx": "Kaufmann and Kalyanakrishnan.", "year": 2013}, {"title": "Almost optimal exploration in multiarmed bandits", "author": ["Zohar Karnin", "Tomer Koren", "Oren Somekh"], "venue": "In Proceedings of the 30th International Conference on Machine Learning", "citeRegEx": "Karnin et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Karnin et al\\.", "year": 2013}, {"title": "A randomized linear-time algorithm to find minimum spanning trees", "author": ["David R Karger", "Philip N Klein", "Robert E Tarjan"], "venue": "Journal of the ACM (JACM),", "citeRegEx": "Karger et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Karger et al\\.", "year": 1995}, {"title": "Pac subset selection in stochastic multi-armed bandits", "author": ["Shivaram Kalyanakrishnan", "Ambuj Tewari", "Peter Auer", "Peter Stone"], "venue": "In Proceedings of the 29th International Conference on Machine Learning", "citeRegEx": "Kalyanakrishnan et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Kalyanakrishnan et al\\.", "year": 2012}, {"title": "The sample complexity of exploration in the multiarmed bandit problem", "author": ["Shie Mannor", "John N Tsitsiklis"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Mannor and Tsitsiklis.,? \\Q2004\\E", "shortCiteRegEx": "Mannor and Tsitsiklis.", "year": 2004}, {"title": "Some aspects of the sequential design of experiments", "author": ["Herbert Robbins"], "venue": "In Herbert Robbins Selected Papers,", "citeRegEx": "Robbins.,? \\Q1985\\E", "shortCiteRegEx": "Robbins.", "year": 1985}, {"title": "Optimal pac multiple arm identification with applications to crowdsourcing", "author": ["Yuan Zhou", "Xi Chen", "Jian Li"], "venue": "In Proceedings of the 31st International Conference on Machine Learning", "citeRegEx": "Zhou et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zhou et al\\.", "year": 2014}], "referenceMentions": [], "year": 2016, "abstractText": "We study the pure exploration problem subject to a matroid constraint (Best-Basis) in a stochastic multi-armed bandit game. In a Best-Basis instance, we are given n stochastic arms with unknown reward distributions, as well as a matroid M over the arms. Let the weight of an arm be the mean of its reward distribution. Our goal is to identify a basis of M with the maximum total weight, using as few samples as possible. The problem is a significant generalization of the best arm identification problem and the top-k arm identification problem, which have attracted significant attentions in recent years. We study both the exact and PAC versions of Best-Basis, and provide algorithms with nearlyoptimal sample complexities for these versions. Our results generalize and/or improve on several previous results for the top-k arm identification problem and the combinatorial pure exploration problem when the combinatorial constraint is a matroid.", "creator": "LaTeX with hyperref package"}}}