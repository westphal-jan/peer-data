{"id": "1605.07334", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-May-2016", "title": "Near-optimal Bayesian Active Learning with Correlated and Noisy Tests", "abstract": "We consider the Bayesian active learning and experimental design problem, where the goal is to learn the value of some unknown target variable through a sequence of informative, noisy tests. In contrast to prior work, we focus on the challenging, yet practically relevant setting where test outcomes can be conditionally dependent given the hidden target variable. Under such assumptions, common heuristics, such as greedily performing tests that maximize the reduction in uncertainty of the target, often perform poorly. In this paper, we propose ECED, a novel, computationally efficient active learning algorithm, and prove strong theoretical guarantees that hold with correlated, noisy tests. Rather than directly optimizing the prediction error, at each step, ECED picks the test that maximizes the gain in a surrogate objective, which takes into account the dependencies between tests. Our analysis relies on an information-theoretic auxiliary function to track the progress of ECED, and utilizes adaptive submodularity to attain the near-optimal bound. We demonstrate strong empirical performance of ECED on two problem instances, including a Bayesian experimental design task intended to distinguish among economic theories of how people make risky decisions, and an active preference learning task via pairwise comparisons.", "histories": [["v1", "Tue, 24 May 2016 08:25:27 GMT  (3161kb,D)", "http://arxiv.org/abs/1605.07334v1", null], ["v2", "Mon, 11 Jul 2016 06:47:19 GMT  (3162kb,D)", "http://arxiv.org/abs/1605.07334v2", null]], "reviews": [], "SUBJECTS": "cs.LG cs.AI", "authors": ["yuxin chen", "s hamed hassani", "reas krause"], "accepted": false, "id": "1605.07334"}, "pdf": {"name": "1605.07334.pdf", "metadata": {"source": "CRF", "title": "Near-optimal Bayesian Active Learning with Correlated and Noisy Tests", "authors": ["Yuxin Chen", "S. Hamed Hassani"], "emails": ["yuxin.chen@inf.ethz.ch", "hamed@inf.ethz.ch", "krausea@ethz.ch"], "sections": [{"heading": "1 Introduction", "text": "This year, it has reached the stage where it will be able to take the lead."}, {"heading": "2 Preliminaries and Problem Statement", "text": ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"}, {"heading": "2.1 Special Case: The Equivalence Class Determination Problem", "text": "Notice that the optimal policy to solve the problem (2.1) is generally impracticable. (...) If the target variables are called equivalence classes, as each of these problems is a subset of root-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission-emission"}, {"heading": "4 Theoretical Analysis", "text": "We present the main idea behind demonstrating the probability of emissions, which we use to reduce the probability of emissions. In general, an effective way to relate the performance (measured in terms of the gain in the target function) of emissions calculation to the optimal policy (measured in terms of the gain in the target function of emissions calculation) is a powerful tool that makes this possible, the adaptive submodularity theory, which imposes a lower limit on the one-step greed gain against the optimal policy, since the objective function has a natural state of reduction in the observation. Unfortunately, the target function for optimization, i.e. the expected error probability of a policy, is not satisfactory to adaptive submodularity. Furthermore, it is not trivial to understand how to directly assign the two targets: the ECED target of (3.1), which we use for the selection of informative tests, reducing the probability of error."}, {"heading": "5 Experimental Results", "text": "For reasons of space, we are postponing a third case study on pool-based active learning to complementary material. The first starting point we are considering is EC2-Bayes, which uses the Bayes rule to update the edge weights in calculating the test gain (as described in \u00a7 3). Note that after observing the test result, both ECED and EC2-Bayes update the laggards according to the Bayes rule; the only difference is that they apply different strategies when selecting a test. We also compare two commonly used sequential information gathering strategies: Information Gain (IG) and Uncertainty Sampling (US), which consider the selection of tests that greedily maximize the reduction of problems to be the cause of the variability of objectives that consider VY decision (VY decision) or mystical collection of information."}, {"heading": "5.1 Preference Elicitation in Behavioral Economics", "text": "We begin by conducting experiments on a Bayesian experimental construction task aimed at distinguishing between economic theories of how people make risky decisions. In behavioral economics, several theories have been proposed to explain how people make decisions under risk and uncertainty. We test ECED on six theories of subjective evaluation of risky decisions (Wakker, 2010; Tversky & Kahneman, 1992; Sharpe, 1964), namely (1) expected benefit with constant relative risk aversion, (2) expected value, (3) prospectus theory, (4) cumulative prospectus theory, (5) weighted moments, and (6) weighted standardized moments. Decisions lie between risky lotteries, i.e. known distribution of payouts (e.g. the monetary value won or lost). A test e (L1, L2) is a pair of lotteries, and basic causes that correspond to Lv2 are the parameterized theories that predict a lottery."}, {"heading": "5.2 Preference Learning via Pairwise Comparisons", "text": "The second application looks at a comparison-based movie recommendation system that learns a user's movie preferences (e.g. the favorable genre) by sequentially showing their pairs of candidate movies and letting them choose which one they prefer. We use the MovieLens 100k dataset (Herlocker et al., 1999), which consists of a matrix of 1 to 5 ratings of 1682 movies from 943 users, and adopt the experimental setup proposed in Chen et al. (2015b). Specifically, we extract movie features by using a low approximation of the user / rating matrix of MovieLens 100k datasets by singular value resolution (SVD). We then simulate the target categories Y that a user may be interested in by dividing the film sets into t (non-overlapping) clusters in the Euclidean area."}, {"heading": "6 Related Work", "text": "Active Learning in the Theory of Statistical Learning: In most theoretical books on active learning (e.g. Dasgupta (2004b); Hanneke (2007, 2014); Balcan & Urner (2015)), the boundaries of sample complexity were characterized in terms of the structure of the hypotheses class and additional distributional complexity measures (e.g. splitting index (Dasgupta, 2004b), the coefficient of discrepancy (Hanneke, 2007), etc.); in comparison, in this paper we seek computation-efficient approaches that have been shown to compete with optimal policy. Therefore, we do not attempt to determine the behavior of optimal policy and therefore do not make assumptions about the hypotheses class. Permanent noise versus non-persistent noise. If tests with i.i.d. results can be repeated, the noisy problem can then be effectively reduced to the noise-free environment (K\u00e4\u00e4inen, 2006, Kar\u00e4uk, and Kleinberg)."}, {"heading": "7 Conclusion", "text": "We have introduced ECED, which strictly generalizes the EC2 algorithm to solve practical Bayesian problems of active learning and experimental design with correlated and loud tests. We have demonstrated that ECED enjoys strong theoretical guarantees by implementing an analytical framework based on adaptive submodularity and information theory. We have demonstrated the compelling performance of ECED on two (loud) problem cases, including an active preference learning task through paired comparisons and a Bayesian experimental design task to determine preferences in behavioral economics. We believe that our work is an important step toward understanding the theoretical aspects of complex sequential information collection problems and provides useful insights into how practical noise-control algorithms can be developed."}, {"heading": "A Table of Notations Defined in the Main Paper", "text": "We summarize the notations used in the main table in Table 1."}, {"heading": "B The Analysis Framework", "text": "In this section we provide the proofs of our theoretical results in detail. Remember that for theoretical analysis we examine the basic environment in which the test results are binary and the test noise is independent of the underlying causes (i.e. in a test e, the noise rate on the result of test e is only a function of e, but not a function of \u03b8)."}, {"heading": "B.1 The Auxiliary Function and the Proof Outline", "text": "The general idea behind our analysis is to show that by running ECED, the one-step gain in learning the target variables is significant compared to the cumulative gain of an optimal policy across K-levels (see Figure 4).In Appendix \u00a7 C, we show that when tests are selected to optimize the (reduction) expected predictive errors, we end up not being able to select some tests that have a negligible immediate gain in terms of error reduction, but are very informative in the long term. ECED circumvents such a problem by selecting tests that maximally distinguish the causes, with different targets. To analyze ECED, we need to find an auxiliary function that properly tracks the \"progress\" of the ECED algorithms; meanwhile, we should enable this auxiliary function by selecting the heuristic tests (i.e."}, {"heading": "B.3 Proof of Lemma 3: Bounding \u2206AUX against \u2206EC2 , \u2206ECED", "text": "In this section we analyze the 1-step gain in the auxiliary function 1-step = 1-step = 1-step = 1-step = 1-step = 1-step = 1-step: EC2,.Recall that we consider test results for our analysis as binary, and in the following section we assume that the result of the test e in {+, \u2212} instead of in {0, \u2212 1}, for clarity 1-step: EC2,.B.3.1 notes and the intermediate results of the Goalh: Pr [[...] q: Pr [...] Xe =] p: Xe = +] For brevity, we first define a few short-term notations to simplify our derivative. Let p, q: two distributions on both distributions."}, {"heading": "B.3.2 A Lower Bound on Term 1", "text": "Then we can Term 1 as, Term 1 =, Term 1 as, Term 1 as, Term 1 as, Term 1 as, Term 1 as, Term 1 as, Term 1 as, Term 1 as, Term 1 as, Term 1 as, Term 1 as, Term 1 as, Term 1 as, Term 1 as, Term 1 as, Term 1 as, Term 1 as, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1 as, Term 1, Term 1, Term 1 as, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 2, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term 1, Term"}, {"heading": "B.3.3 A Lower Bound on Term 2", "text": "By strong concavity of f (x) = x log 1x + (1 \u2212 x) log 11 \u2212 x we get term 2 = c \u00b2 yi \u00b2 Y (hi log 1hi + (1 \u2212 hi) log11 \u2212 h + (pi log 1pi + (1 \u2212 pi) log11 \u2212 pi) \u2212 h \u2212 (qi log 1qi + (1 \u2212 qi) log11 \u2212 qi)) footnote 3 \u2265 c \u00b7 h + h \u2212 2 \u0445 yi \u00b2 Y (pi \u2212 qi) 2 max {pi (1 \u2212 pi), qi (1 \u2212 qi)}} Inserting the definition of pi, qi from equation (B.4), we get term 2 = c \u00b7 h + h \u2212 2 \u0445 yi \u00b2 (\u03b1i \u00b2 + \u03b2ih + \u03b2i \u00b2) (1 \u2212 pi), qi (1 \u2212 pi), qi (1 \u2212 pi \u00b2 \u00b2 (B.4), we get term 2 = c \u00b7 h + h \u2212 2 \u0445 yi \u00b2 (a \u00b2) (1 \u2212 \u00b2) (1 \u2212 \u00b2 (1 \u2212 pi)"}, {"heading": "B.3.4 A Combined Lower Bound for \u2206AUX", "text": "If we now combine Equation (B.7), (B.8) and (B.9), we can obtain a lower limit for \"AUX\": \"AUX\" (1 \u2212 2) 2 h + h \u2212 \u00b7 2 \"Y\" (\u03b2\u03b1i \u2212 \u03b1\u03b2i) 2 + (1 \u2212 2) 2 h + h \u2212 2 \"Y\" (1 \u2212 2) 2 \"Y\" (1 \u2212 2) 2 \"Y\" (1 \u2212 2) 2 \"Y\" (1 \u2212 2) 2 \"Y\" (1 \u2212 2) 22 h + h \u2212 2 \"Y\" (1 \u2212 2) 2 \"Y\" (2 \u2212 2) 2 \"Y\" (1 \u2212 2 \u2212 2) 2 \"Y\" (1 \u2212 2 \u2212 2 \u2212 2) 2 \"Y\" (2 \u2212 2 \u2212 2) 2 \"(2 \u2212 2) \u2212 2 (2 \u2212 2)"}, {"heading": "B.3.5 Connecting \u2206AUX with \u2206EC2", "text": "Next, we will show that the term LB1 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 ("}, {"heading": "B.3.6 Bounding \u2206AUX against \u2206ECED", "text": "To conclude the proof for Lemma 3, we must continue to \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212"}, {"heading": "C.2 A Bad Example for the Most Informative Policy: Treasure Hunt", "text": "In this section, we provide an example of the treasure hunt, where most informative policies in relation to the underlying problems in relation to the actual cost (s / log (s)) times the optimal cost. This example is adjusted by Golovin et al. (2010), where they show that most informative policies (in relation to informative profit policy) and short-sighted policies that maximize the reduction of expected forecasting errors (in relation to the value of information policy) both perform poorly compared to EC2.Consider the problem instance in Figure 8 (a). Fix s > 0 to be some integrators, and let t = | Y | 2s reduce the expected forecasting error errors (in relation to the value of information policy). For each target yi there are two causes, i.e."}, {"heading": "D Case Study: Pool-based Active Learning for Classification", "text": "In order to demonstrate the empirical performance of ECED, we primarily have to deal with two ground-based, active classification tasks. In the active learning application, we can query sequentially from a pool of data points, and the goal is to learn a binary classifier that places a small predictive error on the invisible data points from the pool, with the smallest number of queries possible. Active Learning: Targets and Root-causes, to discredit the hypotheses, we use a noisy version of hit-and-run samplers as suggested in Chen & Krause (2013). Each hypothesis can be represented by a binary vector that displays the outcomes of all data points in education. Then, we construct an epsilonic network of hypotheses based on hypotheses."}], "references": [{"title": "Active learning\u2013modern learning theory", "author": ["Balcan", "Maria-Florina", "Urner", "Ruth"], "venue": "Encyclopedia of Algorithms,", "citeRegEx": "Balcan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Balcan et al\\.", "year": 2015}, {"title": "Extensions of generalized binary search to group identification and exponential costs", "author": ["G. Bellala", "S. Bhavnani", "C. Scott"], "venue": "In NIPS,", "citeRegEx": "Bellala et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Bellala et al\\.", "year": 2010}, {"title": "Decision trees for entity identification: Approximation algorithms and hardness results", "author": ["V.T. Chakaravarthy", "V. Pandit", "S. Roy", "P. Awasthi", "M. Mohania"], "venue": "SIGMOD/PODS,", "citeRegEx": "Chakaravarthy et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Chakaravarthy et al\\.", "year": 2007}, {"title": "Bayesian experimental design: A review", "author": ["K. Chaloner", "I. Verdinelli"], "venue": "Statistical Science,", "citeRegEx": "Chaloner and Verdinelli,? \\Q1995\\E", "shortCiteRegEx": "Chaloner and Verdinelli", "year": 1995}, {"title": "Near-optimal batch mode active learning and adaptive submodular optimization", "author": ["Chen", "Yuxin", "Krause", "Andreas"], "venue": "In ICML,", "citeRegEx": "Chen et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2013}, {"title": "Sequential information maximization: When is greedy near-optimal", "author": ["Chen", "Yuxin", "Hassani", "S. Hamed", "Karbasi", "Amin", "Krause", "Andreas"], "venue": "In COLT,", "citeRegEx": "Chen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2015}, {"title": "Submodular surrogates for value of information", "author": ["Chen", "Yuxin", "Javdani", "Shervin", "Karbasi", "Amin", "Bagnell", "James Andrew", "Srinivasa", "Siddhartha", "Krause", "Andreas"], "venue": "In AAAI,", "citeRegEx": "Chen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2015}, {"title": "Analysis of a greedy active learning strategy", "author": ["S. Dasgupta"], "venue": "In NIPS,", "citeRegEx": "Dasgupta,? \\Q2004\\E", "shortCiteRegEx": "Dasgupta", "year": 2004}, {"title": "Analysis of a greedy active learning strategy", "author": ["Dasgupta", "Sanjoy"], "venue": "In NIPS,", "citeRegEx": "Dasgupta and Sanjoy.,? \\Q2004\\E", "shortCiteRegEx": "Dasgupta and Sanjoy.", "year": 2004}, {"title": "Adaptive submodularity: Theory and applications in active learning and stochastic optimization", "author": ["Golovin", "Daniel", "Krause", "Andreas"], "venue": "JAIR,", "citeRegEx": "Golovin et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Golovin et al\\.", "year": 2011}, {"title": "Near-optimal bayesian active learning with noisy observations", "author": ["Golovin", "Daniel", "Krause", "Andreas", "Ray", "Debajyoti"], "venue": "In NIPS,", "citeRegEx": "Golovin et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Golovin et al\\.", "year": 2010}, {"title": "A bound on the label complexity of agnostic active learning", "author": ["Hanneke", "Steve"], "venue": "In ICML,", "citeRegEx": "Hanneke and Steve.,? \\Q2007\\E", "shortCiteRegEx": "Hanneke and Steve.", "year": 2007}, {"title": "An algorithmic framework for performing collaborative filtering", "author": ["Herlocker", "Jonathan L", "Konstan", "Joseph A", "Borchers", "Al", "Riedl", "John"], "venue": "In SIGIR,", "citeRegEx": "Herlocker et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Herlocker et al\\.", "year": 1999}, {"title": "Information value theory", "author": ["R.A. Howard"], "venue": "Systems Science and Cybernetics, IEEE Trans. on,", "citeRegEx": "Howard,? \\Q1966\\E", "shortCiteRegEx": "Howard", "year": 1966}, {"title": "Active learning in the non-realizable case", "author": ["K\u00e4\u00e4ri\u00e4inen", "Matti"], "venue": "In Algorithmic Learning Theory, pp", "citeRegEx": "K\u00e4\u00e4ri\u00e4inen and Matti.,? \\Q2006\\E", "shortCiteRegEx": "K\u00e4\u00e4ri\u00e4inen and Matti.", "year": 2006}, {"title": "Noisy binary search and its applications", "author": ["Karp", "Richard M", "Kleinberg", "Robert"], "venue": "In SODA,", "citeRegEx": "Karp et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Karp et al\\.", "year": 2007}, {"title": "On an optimal split tree problem", "author": ["Kosaraju", "S Rao", "Przytycka", "Teresa M", "Borgstrom", "Ryan"], "venue": "In Algorithms and Data Structures,", "citeRegEx": "Kosaraju et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Kosaraju et al\\.", "year": 1999}, {"title": "Noisy generalized binary search", "author": ["Nowak", "Robert"], "venue": "In NIPS,", "citeRegEx": "Nowak and Robert.,? \\Q2009\\E", "shortCiteRegEx": "Nowak and Robert.", "year": 2009}, {"title": "Bayesian rapid optimal adaptive design (broad): Method and application distinguishing models of risky choice", "author": ["Ray", "Debajyoti", "Golovin", "Daniel", "Krause", "Andreas", "Camerer", "Colin"], "venue": "Tech. Report,", "citeRegEx": "Ray et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Ray et al\\.", "year": 2012}, {"title": "Which uncertainty? using expert elicitation and expected value of information to design an adaptive program", "author": ["M.C. Runge", "S.J. Converse", "J.E. Lyons"], "venue": "Biological Conservation,", "citeRegEx": "Runge et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Runge et al\\.", "year": 2011}, {"title": "Active Learning", "author": ["B. Settles"], "venue": null, "citeRegEx": "Settles,? \\Q2012\\E", "shortCiteRegEx": "Settles", "year": 2012}, {"title": "Capital Asset Prices: A Theory of Market Equilibrium under Conditions of Risk", "author": ["Sharpe", "William F"], "venue": "The Journal of Finance,", "citeRegEx": "Sharpe and F.,? \\Q1964\\E", "shortCiteRegEx": "Sharpe and F.", "year": 1964}, {"title": "The optimal control of partially observable markov processes over a finite horizon", "author": ["Smallwood", "Richard D", "Sondik", "Edward J"], "venue": "Operations Research,", "citeRegEx": "Smallwood et al\\.,? \\Q1973\\E", "shortCiteRegEx": "Smallwood et al\\.", "year": 1973}, {"title": "Advances in prospect theory: Cumulative representation of uncertainty", "author": ["Tversky", "Amos", "Kahneman", "Daniel"], "venue": "Journal of Risk and Uncertainty,", "citeRegEx": "Tversky et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Tversky et al\\.", "year": 1992}, {"title": "Prospect Theory: For Risk and Ambiguity", "author": ["P.P. Wakker"], "venue": null, "citeRegEx": "Wakker,? \\Q2010\\E", "shortCiteRegEx": "Wakker", "year": 2010}], "referenceMentions": [{"referenceID": 20, "context": "The problem of optimal information gathering has been studied in the context of active learning (Dasgupta, 2004a; Settles, 2012), Bayesian experimental design (Chaloner & Verdinelli, 1995), policy making (Runge et al.", "startOffset": 96, "endOffset": 128}, {"referenceID": 19, "context": "The problem of optimal information gathering has been studied in the context of active learning (Dasgupta, 2004a; Settles, 2012), Bayesian experimental design (Chaloner & Verdinelli, 1995), policy making (Runge et al., 2011), optimal control (Smallwood & Sondik, 1973), and numerous other domains.", "startOffset": 204, "endOffset": 224}, {"referenceID": 2, "context": "Deriving the optimal testing policy is NP-hard in general (Chakaravarthy et al., 2007); however, under certain conditions, some approximation results are known.", "startOffset": 58, "endOffset": 86}, {"referenceID": 16, "context": ", in the noise-free setting), a simple greedy algorithm, namely Generalized Binary Search (GBS), is guaranteed to provide a near-optimal approximation of the optimal policy (Kosaraju et al., 1999).", "startOffset": 173, "endOffset": 196}, {"referenceID": 9, "context": "Golovin et al. (2010) then formalize this problem as an equivalence class determination problem (See \u00a72.", "startOffset": 0, "endOffset": 22}, {"referenceID": 10, "context": "When \u03b4 = 0, this problem reduces to the equivalence class determination problem (Golovin et al., 2010; Bellala et al., 2010).", "startOffset": 80, "endOffset": 124}, {"referenceID": 1, "context": "When \u03b4 = 0, this problem reduces to the equivalence class determination problem (Golovin et al., 2010; Bellala et al., 2010).", "startOffset": 80, "endOffset": 124}, {"referenceID": 10, "context": ", \u2200e, P [Xe | \u0398] \u2208 {0, 1}, this problem can be solved near-optimally by the equivalence class edge cutting (EC) algorithm (Golovin et al., 2010).", "startOffset": 122, "endOffset": 144}, {"referenceID": 10, "context": "The EC objective function is adaptive submodular, and strongly adaptive monotone (Golovin et al., 2010).", "startOffset": 81, "endOffset": 103}, {"referenceID": 13, "context": "Last, we consider myopic optimization of the decision-theoretic value of information (VOI) (Howard, 1966).", "startOffset": 91, "endOffset": 105}, {"referenceID": 24, "context": "We test ECED on six theories of subjective valuation of risky choices (Wakker, 2010; Tversky & Kahneman, 1992; Sharpe, 1964), namely (1) expected utility with constant relative risk aversion, (2) expected value, (3) prospect theory, (4) cumulative prospect theory, (5) weighted moments, and (6) weighted standardized moments.", "startOffset": 70, "endOffset": 124}, {"referenceID": 18, "context": "We employ the same set of parameters used in Ray et al. (2012) to generate tests and root-causes.", "startOffset": 45, "endOffset": 63}, {"referenceID": 12, "context": "We use the MovieLens 100k dataset (Herlocker et al., 1999), which consists of a matrix of 1 to 5 ratings of 1682 movies from 943 users, and adopt the experimental setup proposed in Chen et al.", "startOffset": 34, "endOffset": 58}, {"referenceID": 4, "context": ", 1999), which consists of a matrix of 1 to 5 ratings of 1682 movies from 943 users, and adopt the experimental setup proposed in Chen et al. (2015b). In particular, we extract movie features by computing a low-rank approximation of the user/rating matrix of the MovieLens 100k dataset through singular value decomposition (SVD).", "startOffset": 130, "endOffset": 150}, {"referenceID": 7, "context": ", Dasgupta (2004b); Hanneke (2007, 2014); Balcan & Urner (2015)), sample complexity bounds have been characterized in terms of the structure of the hypothesis class, as well as additional distribution-dependent complexity measures (e.", "startOffset": 2, "endOffset": 19}, {"referenceID": 7, "context": ", Dasgupta (2004b); Hanneke (2007, 2014); Balcan & Urner (2015)), sample complexity bounds have been characterized in terms of the structure of the hypothesis class, as well as additional distribution-dependent complexity measures (e.", "startOffset": 2, "endOffset": 64}, {"referenceID": 10, "context": ", 2015a) and strict noise assumptions (Golovin et al., 2010), more general settings, which we focus on in this paper, are much less understood.", "startOffset": 38, "endOffset": 60}, {"referenceID": 9, "context": "By adaptive submodularity of fEC2 (in the noiseless setting, see Golovin et al. (2010)), we obtain", "startOffset": 65, "endOffset": 87}, {"referenceID": 9, "context": "1 A Bad Example for GBS: Imbalanced Equivalence Classes We use the same example as provided in Golovin et al. (2010). Consider an instance with a uniform prior over n root-causes, \u03b81, .", "startOffset": 95, "endOffset": 117}, {"referenceID": 9, "context": "This example is adapted from Golovin et al. (2010), where they show that the most informative policy (referred to as the Informative Gain policy), as well as the myopic policy that greedily maximizes the reduction in the expected prediction error (referred as the Value of Information policy), both perform badly, compared with EC.", "startOffset": 29, "endOffset": 51}], "year": 2016, "abstractText": "We consider the Bayesian active learning and experimental design problem, where the goal is to learn the value of some unknown target variable through a sequence of informative, noisy tests. In contrast to prior work, we focus on the challenging, yet practically relevant setting where test outcomes can be conditionally dependent given the hidden target variable. Under such assumptions, common heuristics, such as greedily performing tests that maximize the reduction in uncertainty of the target, often perform poorly. In this paper, we propose ECED, a novel, computationally efficient active learning algorithm, and prove strong theoretical guarantees that hold with correlated, noisy tests. Rather than directly optimizing the prediction error, at each step, ECED picks the test that maximizes the gain in a surrogate objective, which takes into account the dependencies between tests. Our analysis relies on an information-theoretic auxiliary function to track the progress of ECED, and utilizes adaptive submodularity to attain the near-optimal bound. We demonstrate strong empirical performance of ECED on two problem instances, including a Bayesian experimental design task intended to distinguish among economic theories of how people make risky decisions, and an active preference learning task via pairwise comparisons.", "creator": "LaTeX with hyperref package"}}}