{"id": "1605.07722", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-May-2016", "title": "Yum-me: A Personalized Nutrient-based Meal Recommender System", "abstract": "Many ubiquitous computing projects have addressed health and wellness behaviors such as healthy eating. Healthy meal recommendations have the potential to help individuals prevent or manage conditions such as diabetes and obesity. However, learning people's food preferences and making healthy recommendations that appeal to their palate is challenging. Existing approaches either only learn high-level preferences or require a prolonged learning period. We propose Yum-me, a personalized healthy meal recommender system designed to meet individuals' health goals, dietary restrictions, and fine-grained food preferences. Marrying ideas from user preference learning and healthy eating promotion, Yum-me enables a simple and accurate food preference profiling procedure via an image-based online learning framework, and projects the learned profile into the domain of healthy food options to find ones that will appeal to the user. We present the design and implementation of Yum-me, and further discuss the most critical component of it: FoodDist, a state-of-the-art food image analysis model. We demonstrate FoodDist's superior performance through careful benchmarking, and discuss its applicability across a wide array of dietary applications. We validate the feasibility and effectiveness of Yum-me through a 60-person user study, in which Yum-me improves the recommendation acceptance rate by 42.63% over the traditional food preference survey.", "histories": [["v1", "Wed, 25 May 2016 04:13:49 GMT  (2833kb,D)", "http://arxiv.org/abs/1605.07722v1", null], ["v2", "Wed, 21 Dec 2016 14:48:18 GMT  (4275kb,D)", "http://arxiv.org/abs/1605.07722v2", null], ["v3", "Sun, 30 Apr 2017 17:43:02 GMT  (4274kb,D)", "http://arxiv.org/abs/1605.07722v3", null]], "reviews": [], "SUBJECTS": "cs.HC cs.AI cs.CV cs.IR", "authors": ["longqi yang", "cheng-kang hsieh", "hongjian yang", "nicola dell", "serge belongie", "curtis cole", "deborah estrin"], "accepted": false, "id": "1605.07722"}, "pdf": {"name": "1605.07722.pdf", "metadata": {"source": "META", "title": "Yum-me: Personalized Healthy Meal Recommender System", "authors": ["Longqi Yang", "Cheng-Kang Hsieh", "Hongjian Yang"], "emails": ["ylongqi@cs.cornell.edu", "changun@cs.ucla.edu", "hy457@cornell.edu", "nixdell@cornell.edu", "sjb344@cornell.edu", "destrin@cs.cornell.edu"], "sections": [{"heading": "ACM Classification Keywords", "text": "H.5.M. Information Interfaces and Presentation (e.g. HCI): Miscellaneous"}, {"heading": "Author Keywords", "text": "Healthy Meals Recommendation; Personalization; Visual UI; Food Preferences"}, {"heading": "INTRODUCTION", "text": "This year it is so far that it will only be a matter of time before it is ready, until it is ready."}, {"heading": "RELATED WORK", "text": "This year it is so far that it will only be a matter of time before it is so far, until it is so far."}, {"heading": "PERSONALIZED HEALTHY MEAL RECOMMENDATIONS", "text": "Our personalized healthy meal recommendation system, Yumme, works on a pre-set stock of foods and suggests articles that appeal to users and meet their health goals and dietary restrictions. A high-level overview of Yum-me's recommendation process is shown in Fig. 1 and described as follows: \u2022 Users first answer a simple survey to determine their dietary restrictions and health goals, and this information is used by Yum-me to filter food and create an initial set of recommendation candidates. \u2022 Users then use PlateClick's visual user interface [47] to express their preferences for fine-grained foods through simple food comparisons, and the preferences learned are used to further evaluate the recommendations and present them to users.We describe five key components that enable the above recommendation process: 1) large data sets for various dietary restrictions, 2) the user survey, 3) the food grain ranking, 4) Visual user preferences, and 5) Visual user interface."}, {"heading": "No restrictions, Vegetarian, Vegan, Kosher, Halal 1", "text": "For each type of diet, we pulled over 10,000 main course recipes together with their images and metadata (ingredients, nutrients, tastes, etc.) from the Yummly API [5]. The total number of recipes is about 50,000. To customize food recommendations for people with specific dietary restrictions, we filter recipes by setting the allowedDiet [] parameters in the Search API. For kosher or halal, we explicitly exclude certain ingredients. Lists of excluded ingredients are shown as below: \u2022 Pig, Rabbit, Horsemeat, Shellfish, Sharks, Octopus, Morbus Bugs Bugs Bugs Bugs Bugs Bugs Bugs Bugs Bugs Bugs Bugs Bugs Bugs Bugs Bugs Bugs. \u2022 Halal: Bloodsausage, Bloodsausage Pudding Pudding Pudding Alcohol Spirits."}, {"heading": "User survey", "text": "The purpose of the user survey is to determine nutritional limitations and health objectives at a high level. Users can define their diets1Our system is not limited to these five dietary limitations due to space constraints, and we will expand the system functionality to other categories in the future. 2We show the embedding of only two representative databases (unrestricted and vegetarian) among the above five categories, and specify their health objectives in terms of the desired amount of calories, protein and fat. We select these nutrients for their high relevance to many common health objectives, such as weight control [19], athletic performance [11], and so on. We offer three options for each of these nutrients, including reduction, maintenance, and increase. The user's dietary type is used to select the appropriate food dataset, and the foods in the dataset are further classified according to their suitability for users \"health objectives based on nutritional factors."}, {"heading": "Food suitability ranking", "text": "To measure the suitability of food, we evaluate the users in the appropriate database of healthy meals. (...) We evaluate the recipes in terms of different nutrients in ascending and descending order, so that each recipe is associated with six different values. (...) We evaluate the recipes in terms of different nutrients in ascending and descending order. (...) The final adequacy of food for each recipe is calculated as follows: u = n, a, arn, a, a and rfat, a and rfat, a and rfat, d, d (...) where users can select a specific target for each recipe. (...) The food coefficient indicator is calculated as follows: u = 1) n, a, arn, a, a, a, a, a, a, a, a and rfat, a, d (...) n, d (...) where the user is selected for each food."}, {"heading": "Preference re-ranking", "text": "In order to project this information into the area of recommendations for healthy meals, we assign the general food preferences learned by PlateClick to the preferences of the users (i.e. pi for i-M) and select the best N-points presented to the user. Note that the general food preferences learned by PlateClick can be used not only for recommendations for healthy meals, but also for other dietary applications through a similar projection scheme. To prevent repetition in the recommendation phase, we remove those food images that are already used in PlateClick. Basically, a robust functional extractor f for food is indispensable for Yum-me, since both the accuracy of the derived food preferences p = [p1,..., p | S |] and the effectiveness of PlateClick's online learning algorithm depend on a functional extractor f (xi) that can reflect the next image of the most robust feature of the application."}, {"heading": "FOODDIST", "text": "Formally, the goal of FoodDist is to learn a trait extractor (embedding) in such a way that an image x, f (x) projects it onto a N-dimensional trait vector, and the Euclidean distances between vectors reflect the similarities between food images, as Fig.3 shows. Formally, we are building FoodDist on recent advances in deep revolutionary neural networks (CNN) that provide a powerful framework for automatic trait learning. Traditional trait representations for images are largely crafted and used with trait descriptors such as SIFT (Scale Invariant Feature Transform) [32]."}, {"heading": "Learning with classification", "text": "A common method of learning a feature extractor for labeled data is to train a neural network that performs classifications (i.e. maps input to labels) and uses the output of a hidden layer as a feature representation; in particular, the use of a forward-facing deep revolutionary neural network with n layers (as shown in the upper half of Figure 4): F (x) = gn (gn \u2212 1 (.. g1 (x).)))) (3), where gi (.) represents the calculation of the i-th layer (e.g. folding, pooling, fully connected, etc.) and F (x) is the output class name. The difference between the output class name and the basic truth (i.e. the error) is propagated backwards across the entire network, from layer n to layer 1. We can take the output of the layer n \u2212 1 as a feature representation of x, which corresponds to a feature extractor as an error layer (i.e., between the layer x) and (i.e., the layer 1)."}, {"heading": "Metric Learning", "text": "Unlike the classification approach, where the Extractor feature is a by-product (1 = 2), metric learning suggests learning the distance directly from the paired input of similar and different examples (1 = 2). However, the structure of a Siamese network is similar to what is shown in Figure 4, but without a fully connected class label, 101 and Softmax Loss layers. The input of the Siamese network is a pair of food images x1, x2. Each image passes through a CNN sharing weight and the output of each network is considered a feature, i.e. f (x1) and f (x2), or f (x2). Our goal is to have a small distance value (close to 0) if x1 and x2 are similar elements; otherwise they should have a larger distance value."}, {"heading": "Performance", "text": "The classification and query of all models are summarized in Table 2 and Table 3. FoodDist leads the top four models and is significantly better than the state-of-the-art approach in both areas. For the classification task, FoodDist achieves 83.9% top-1 accuracy, which significantly exceeds the original RFDC. [10] The benchmark model and the proprietary GoogLeNet model [33]. For the on-demand task, the mAP value doubles in previous work. [47] This used the network architecture."}, {"heading": "USER STUDY", "text": "We conducted a user study to verify the effectiveness of the Yumme recommendations. We recruited 60 participants via the university mailing list, Facebook and Twitter. The goal of the user study was to compare the Yum-me recommendations with a widely used baseline approach, i.e. a traditional food preference survey. We used a study design in which each participant expressed their opinion on the meals recommended by both recommendations and compared the effectiveness of the systems per user."}, {"heading": "Study Design", "text": "The values of N and M are controlled in such a way that N = 10, M = 500 for both Yum-me and the traditional 4https: / / github.com / sh1r0 / caffe-android-libbaseline. The user study consists of three phases, as illustrated in Fig.5: (1) Each participant was asked to indicate his or her diet and health goals through our basic user survey. (2) Each participant was then asked to use PlateClick. (3) 20 meal recommendations were arranged in a random order and presented to the participant simultaneously, with 10 of these coming from Yum-me and the other 10 generated from the baseline. The participant was asked to express his or her opinion by dragging each of the 20 meals into the yummy or no-way bucket. To overcome the fact that people would tend to balance the buckets when their previous choices were shown, the meals were moved to the respective web or they were inserted into the web by the other users."}, {"heading": "Participants", "text": "The most common dietary choice among our 60 participants was No Limitations (48), followed by vegetarians (9), Halal (2) and Kosher (1). None of the participants chose vegans. Participants \"preferences in terms of nutrients are summarized in the table. 4. In terms of calories and fat, the two most important goals were reduce and maintain. In terms of proteins, participants tended to choose either gain or maintenance. In terms of health goals, the four most important decisions made by participants were Calorie preservation-preserve-fat (20), Calorie reduction-preserve-fat (10), Calorie preservation-preserve-fat (10) and Calorie reduction-increase-fat (5). Statistics are well consistent with the general health goals of the general population, i.e. people who plan to control their weight and improve their athletic performance tend to reduce their calorie intake and fat intake and increase the amount of protein."}, {"heading": "Quantitative analysis", "text": "The cumulative distribution of the acceptance rate is shown in Fig.6 and the averages per approach are shown in Table.5. The results clearly show that Yum-me significantly improves the quality of the foodstuffs presented. To further quantify the improvement through the Yumme system, we calculated the difference between the acceptance rates of the two systems, i.e. difference = Yum-me acceptance rate \u2212 baseline acceptance rate. The distribution and averages of the differences are shown in Fig.7 and Table.5. It is noteworthy that the Yum-me 5A Shapiro Wilk W test was not significant (p = 0.12), which justifies that the difference is normally distributed."}, {"heading": "Qualitative analysis", "text": "In order to understand the quality of Yum-me's personalization mechanism, we randomly select three participants with no dietary restrictions and with the health goal of reducing calories. For each of these users, we select the top 20 foods that the user likes best (derived from PlateClick). These foods played an important role in selecting the healthy meals that the user recommends. To make this relationship between these top 20 items visible, we further select two foods that are most similar to the healthy items that Yum-me has recommended to users and present three such examples in Fig.8. Intuitively, our system can recommend healthy foods that are visually similar to the foods that a user likes, but the recommended items are lower in calories due to the use of healthier ingredients or different cooking styles. These examples show how Yum-me projects users \"overall food preferences on the range of healthy options and those that users find most pleasing."}, {"heading": "Error analysis", "text": "By examining more closely the cases where our system performs relatively poorly, we observed a negative correlation between the entropy of the learned preference distribution p 7 and the improvement of Yum-me over baseline (r = \u2212 0.32, p = 0.026). This correlation suggests that if the user's preference distributions are more concentrated, the recommended meals tend to perform better. This is not too surprising, since the entropy of the preference distribution reflects roughly the degree of trust the system has in the user's preferences, where confidence is higher when entropy is lower and vice versa. Fig.9 shows the evolution of the entropy value as users make more comparisons through PlateClick. Results show that the system becomes more confident about the user's preferences when users give more feedback."}, {"heading": "CONCLUSION AND FUTURE WORK", "text": "In this paper, we propose Yum-me, a novel healthy meal recommendation that makes recommendations for healthy meals that target users \"fine-grained food preferences. We also present FoodDist, a unified best-in-class image analysis model. The results of the user study and benchmarking demonstrate the effectiveness of Yum-me and the superior performance of the FoodDist model. In the future, we can imagine that the idea of using visual similarities to preference identification may enable a broader range of applications in the Ubicomp community. (1) User-oriented nutrition profile: The fine-grained food preferences learned from Yum-me can be viewed as the general nutritional profile of each user and projected onto other areas to allow for more nutritional applications, such as appropriate dietary plans for diabetics. In addition, a personal nutritional profile can be built on this nutritional profile of multiple parts of the imPI and to allow multiple improvisations."}], "references": [{"title": "Feasibility testing of an automated image-capture method to aid dietary recall. European journal of clinical nutrition", "author": ["Lenore Arab", "Deborah Estrin", "Donnie H Kim", "Jeff Burke", "Jeff Goldman"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2011}, {"title": "Menu-match: restaurant-specific food logging from images", "author": ["Oscar Beijbom", "Neel Joshi", "Dan Morris", "Scott Saponas", "Siddharth Khullar"], "venue": "In Applications of Computer Vision (WACV),", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "Nutrition and depression: implications for improving mental health among childbearing-aged women", "author": ["Lisa M Bodnar", "Katherine L Wisner"], "venue": "Biological psychiatry 58,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2005}, {"title": "Food-101\u2013mining discriminative components with random forests", "author": ["Lukas Bossard", "Matthieu Guillaumin", "Luc Van Gool"], "venue": "In Computer Vision\u2013ECCV", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "Nutrition and sports performance", "author": ["JR Brotherhood"], "venue": "Sports Medicine 1,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1984}, {"title": "Multitask learning", "author": ["Rich Caruana"], "venue": "Machine learning 28,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1997}, {"title": "Volume estimation using food specific shape templates in mobile image-based dietary assessment", "author": ["Junghoon Chae", "Insoo Woo", "SungYe Kim", "Ross Maciejewski", "Fengqing Zhu", "Edward J Delp", "Carol J Boushey", "David S Ebert"], "venue": "In IS&T/SPIE Electronic Imaging. International Society for Optics and Photonics,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2011}, {"title": "Lunch Line: using public displays and mobile devices to encourage healthy eating in an  organization", "author": ["Kerry Shih-Ping Chang", "Catalina M Danis", "Robert G Farrell"], "venue": "In Proceedings of the 2014 ACM International Joint Conference on Pervasive and Ubiquitous Computing", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "Rethinking the mobile food journal: Exploring opportunities for lightweight photo-based capture", "author": ["Felicia Cordeiro", "Elizabeth Bales", "Erin Cherry", "James Fogarty"], "venue": "In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2015}, {"title": "Instance-aware Semantic Segmentation via Multi-task Network Cascades", "author": ["Jifeng Dai", "Kaiming He", "Jian Sun"], "venue": "arXiv preprint arXiv:1512.04412", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2015}, {"title": "Imagenet: A large-scale hierarchical image database", "author": ["Jia Deng", "Wei Dong", "Richard Socher", "Li-Jia Li", "Kai Li", "Li Fei-Fei"], "venue": "In Computer Vision and Pattern Recognition,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2009}, {"title": "Effect of diet and controlled exercise on weight loss in obese children", "author": ["Leonard H Epstein", "Rena R Wing", "Barbara C Penner", "Mary Jeanne Kress"], "venue": "The Journal of pediatrics 107,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1985}, {"title": "Content-boosted matrix factorization for recommender systems: experiments with recipe recommendation", "author": ["Peter Forbes", "Mu Zhu"], "venue": "In Proceedings of the fifth ACM conference on Recommender systems", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2011}, {"title": "Intelligent food planning: personalized recipe recommendation", "author": ["Jill Freyne", "Shlomo Berkovsky"], "venue": "In Proceedings of the 15th international conference on Intelligent user interfaces", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2010}, {"title": "A personalized recipe advice system to promote healthful choices", "author": ["Gijs Geleijnse", "Peggy Nachtigall", "Pim van Kaam", "Luci\u00ebnne Wijgergangs"], "venue": "In Proceedings of the 16th international conference on Intelligent user interfaces", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2011}, {"title": "Food image analysis: Segmentation, identification and weight estimation", "author": ["Ye He", "Chang Xu", "Neha Khanna", "Carol J Boushey", "Edward J Delp"], "venue": "In Multimedia and Expo (ICME),", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2013}, {"title": "http://goodfeli.github.io/dlbook/ Book in preparation for", "author": ["Yoshua Bengio Ian Goodfellow", "Aaron Courville"], "venue": "Deep Learning", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2016}, {"title": "Caffe: Convolutional architecture for fast feature embedding", "author": ["Yangqing Jia", "Evan Shelhamer", "Jeff Donahue", "Sergey Karayev", "Jonathan Long", "Ross Girshick", "Sergio Guadarrama", "Trevor Darrell"], "venue": "In Proceedings of the ACM International Conference on Multimedia", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2014}, {"title": "Sensing fork and persuasive game for improving eating behavior", "author": ["Azusa Kadomura", "Cheng-Yuan Li", "Yen-Chang Chen", "Hao-Hua Chu", "Koji Tsukada", "Itiro Siio"], "venue": "In Proceedings of the 2013 ACM conference on Pervasive and ubiquitous computing adjunct publication", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2013}, {"title": "Persuasive technology to improve eating behavior using a sensor-embedded fork", "author": ["Azusa Kadomura", "Cheng-Yuan Li", "Koji Tsukada", "Hao-Hua Chu", "Itiro Siio"], "venue": "In Proceedings of the 2014 ACM International Joint Conference on Pervasive and Ubiquitous Computing", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2014}, {"title": "Food image recognition with deep convolutional features", "author": ["Yoshiyuki Kawano", "Keiji Yanai"], "venue": "In Proceedings of the 2014 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct Publication", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2014}, {"title": "FoodLog: capture, analysis and retrieval of personal food images via web", "author": ["Keigo Kitamura", "Toshihiko Yamasaki", "Kiyoharu Aizawa"], "venue": "In Proceedings of the ACM multimedia 2009 workshop on Multimedia for cooking and eating activities", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2009}, {"title": "Imagenet classification with deep convolutional neural networks. In Advances in neural information processing", "author": ["Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E Hinton"], "venue": null, "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2012}, {"title": "Distinctive image features from scale-invariant keypoints", "author": ["David G Lowe"], "venue": "International journal of computer vision 60,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2004}, {"title": "Im2Calories: towards an automated mobile vision food diary", "author": ["Austin Meyers", "Nick Johnston", "Vivek Rathod", "Anoop Korattikara", "Alex Gorban", "Nathan Silberman", "Sergio Guadarrama", "George Papandreou", "Jonathan Huang", "Kevin P Murphy"], "venue": null, "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2015}, {"title": "Understanding food consumption lifecycles using wearable cameras", "author": ["Kher Hui Ng", "Victoria Shipp", "Richard Mortier", "Steve Benford", "Martin Flintham", "Tom Rodden"], "venue": "Personal and Ubiquitous Computing 19,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2015}, {"title": "Platemate: crowdsourcing nutritional analysis from food photographs", "author": ["Jon Noronha", "Eric Hysen", "Haoqi Zhang", "Krzysztof Z Gajos"], "venue": "In UIST", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2011}, {"title": "Diabetes and Healthy Eating A Systematic Review of the Literature", "author": ["Rachel Clare Povey", "David Clark-Carter"], "venue": "The Diabetes Educator 33,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2007}, {"title": "CNN features off-the-shelf: an astounding baseline for recognition", "author": ["Ali Razavian", "Hossein Azizpour", "Josephine Sullivan", "Stefan Carlsson"], "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2014}, {"title": "Young people and healthy eating: a systematic review of research on barriers and facilitators", "author": ["Jonathan Shepherd", "Angela Harden", "Rebecca Rees", "Ginny Brunton", "Jo Garcia", "Sandy Oliver", "Ann Oakley"], "venue": "Health Education Research 21,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2006}, {"title": "Very Deep Convolutional Networks for Large-Scale Image Recognition", "author": ["K. Simonyan", "A. Zisserman"], "venue": "CoRR abs/1409.1556", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2014}, {"title": "Estimating nutritional value from food images based on semantic segmentation", "author": ["Kyoko Sudo", "Kazuhiko Murasaki", "Jun Shimamura", "Yukinobu Taniguchi"], "venue": "In Proceedings of the 2014 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct Publication", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2014}, {"title": "Designing and evaluating kalas: A social navigation system for food recipes", "author": ["Martin Svensson", "Kristina H\u00f6\u00f6k", "Rickard C\u00f6ster"], "venue": "ACM Transactions on Computer-Human Interaction (TOCHI) 12,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2005}, {"title": "Feasibility of identifying eating moments from first-person images leveraging human computation", "author": ["Edison Thomaz", "Aman Parnami", "Irfan Essa", "Gregory D Abowd"], "venue": "In Proceedings of the 4th International SenseCam & Pervasive Imaging Conference", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2013}, {"title": "The use of crowdsourcing for dietary self-monitoring: crowdsourced ratings of food pictures are comparable to ratings by trained observers", "author": ["Gabrielle M Turner-McGrievy", "Elina E Helander", "Kirsikka Kaipainen", "Jose Maria Perez-Macias", "Ilkka Korhonen"], "venue": "Journal of the American Medical Informatics Association 22,", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2015}, {"title": "Recipe recommendation method by considering the user\u00e2\u0102\u0179s preference and ingredient quantity of target recipe", "author": ["Mayumi Ueda", "Syungo Asanuma", "Yusuke Miyawaki", "Shinsuke Nakajima"], "venue": "In Proceedings of the International MultiConference of Engineers and Computer Scientists,", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2014}, {"title": "Visualizing data using t-SNE", "author": ["Laurens Van der Maaten", "Geoffrey Hinton"], "venue": "Journal of Machine Learning Research", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2008}, {"title": "Deriving a recipe similarity measure for recommending healthful meals", "author": ["Youri van Pinxteren", "Gijs Geleijnse", "Paul Kamsteeg"], "venue": "In Proceedings of the 16th international conference on Intelligent user interfaces", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 2011}, {"title": "2015a. PlateClick: Bootstrapping Food Preferences Through an Adaptive Visual Interface", "author": ["Longqi Yang", "Yin Cui", "Fan Zhang", "John P Pollak", "Serge Belongie", "Deborah Estrin"], "venue": "In Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 2015}, {"title": "Beyond Classification: Latent User Interests  Profiling from Visual Contents Analysis", "author": ["Longqi Yang", "Cheng-Kang Hsieh", "Deborah Estrin"], "venue": null, "citeRegEx": "48", "shortCiteRegEx": "48", "year": 2015}, {"title": "Facial landmark detection by deep multi-task learning", "author": ["Zhanpeng Zhang", "Ping Luo", "Chen Change Loy", "Xiaoou Tang"], "venue": "In Computer Vision\u2013ECCV", "citeRegEx": "49", "shortCiteRegEx": "49", "year": 2014}], "referenceMentions": [{"referenceID": 27, "context": "Healthy eating plays a critical role in our daily well-being and is indispensable in preventing and managing conditions such as diabetes, high blood pressure, cancer, mental illnesses, asthma, etc[36, 20, 9].", "startOffset": 196, "endOffset": 207}, {"referenceID": 2, "context": "Healthy eating plays a critical role in our daily well-being and is indispensable in preventing and managing conditions such as diabetes, high blood pressure, cancer, mental illnesses, asthma, etc[36, 20, 9].", "startOffset": 196, "endOffset": 207}, {"referenceID": 29, "context": "In particular, for children and young people, the adoption of healthy dietary habits has been shown to be beneficial to early cognitive development [38].", "startOffset": 148, "endOffset": 152}, {"referenceID": 19, "context": "In the Ubicomp community, various applications designed to promote healthy behaviors, including diet, have been proposed and studied [28, 14, 27, 15].", "startOffset": 133, "endOffset": 149}, {"referenceID": 7, "context": "In the Ubicomp community, various applications designed to promote healthy behaviors, including diet, have been proposed and studied [28, 14, 27, 15].", "startOffset": 133, "endOffset": 149}, {"referenceID": 18, "context": "In the Ubicomp community, various applications designed to promote healthy behaviors, including diet, have been proposed and studied [28, 14, 27, 15].", "startOffset": 133, "endOffset": 149}, {"referenceID": 37, "context": "Among those applications, the studies and products that target healthy meal recommendations have attracted much attention in academia [46] and industry [3] alike.", "startOffset": 134, "endOffset": 138}, {"referenceID": 8, "context": "5 entries per day [16].", "startOffset": 18, "endOffset": 22}, {"referenceID": 8, "context": "It would take a non-trivial amount of time for the system to acquire sufficient amount of data to make recommendations, and the collected samples may subject to sampling biases as well [16].", "startOffset": 185, "endOffset": 189}, {"referenceID": 8, "context": "Moreover, the habit of photo food journaling is difficult to adopt and adhere to[16].", "startOffset": 80, "endOffset": 84}, {"referenceID": 38, "context": "We build upon a previously developed visual online learning framework, PlateClick[47], which learned users\u2019 fined-grained food preferences with simple pairwise comparisons between food images.", "startOffset": 81, "endOffset": 85}, {"referenceID": 22, "context": "Based on deep convolutional networks and multi-task learning [31], FoodDist is the best-of-its-kind Euclidean distance embedding for food images, in which similar food items have smaller distances while dissimilar food items have larger distances.", "startOffset": 61, "endOffset": 65}, {"referenceID": 3, "context": "We benchmark FoodDist with the Food-101 dataset [10], the largest dataset for food images.", "startOffset": 48, "endOffset": 52}, {"referenceID": 38, "context": "The results suggest the superior performance of FoodDist over prior approaches (including the one proposed in the PlateClick paper) [47, 33, 10].", "startOffset": 132, "endOffset": 144}, {"referenceID": 24, "context": "The results suggest the superior performance of FoodDist over prior approaches (including the one proposed in the PlateClick paper) [47, 33, 10].", "startOffset": 132, "endOffset": 144}, {"referenceID": 3, "context": "The results suggest the superior performance of FoodDist over prior approaches (including the one proposed in the PlateClick paper) [47, 33, 10].", "startOffset": 132, "endOffset": 144}, {"referenceID": 12, "context": "Traditional food and recipe recommendation systems learn users\u2019 dietary preferences from users\u2019 online activities, including ratings [21, 22], past recipe choices [41, 23], browsing history [44, 46, 2], etc.", "startOffset": 133, "endOffset": 141}, {"referenceID": 13, "context": "Traditional food and recipe recommendation systems learn users\u2019 dietary preferences from users\u2019 online activities, including ratings [21, 22], past recipe choices [41, 23], browsing history [44, 46, 2], etc.", "startOffset": 133, "endOffset": 141}, {"referenceID": 32, "context": "Traditional food and recipe recommendation systems learn users\u2019 dietary preferences from users\u2019 online activities, including ratings [21, 22], past recipe choices [41, 23], browsing history [44, 46, 2], etc.", "startOffset": 163, "endOffset": 171}, {"referenceID": 14, "context": "Traditional food and recipe recommendation systems learn users\u2019 dietary preferences from users\u2019 online activities, including ratings [21, 22], past recipe choices [41, 23], browsing history [44, 46, 2], etc.", "startOffset": 163, "endOffset": 171}, {"referenceID": 35, "context": "Traditional food and recipe recommendation systems learn users\u2019 dietary preferences from users\u2019 online activities, including ratings [21, 22], past recipe choices [41, 23], browsing history [44, 46, 2], etc.", "startOffset": 190, "endOffset": 201}, {"referenceID": 37, "context": "Traditional food and recipe recommendation systems learn users\u2019 dietary preferences from users\u2019 online activities, including ratings [21, 22], past recipe choices [41, 23], browsing history [44, 46, 2], etc.", "startOffset": 190, "endOffset": 201}, {"referenceID": 32, "context": "[41] built a social navigation system that recommends recipes based on the recipe choices made by different users.", "startOffset": 0, "endOffset": 4}, {"referenceID": 37, "context": "[46] proposed to learn a recipe similarity measure from crowd card-sorting and make recommendations based on the self-reported meals.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "Beyond using users\u2019 online activities, food logging and journaling learn users\u2019 real food consumption history and require users\u2019 active involvement, such as taking food images [16] or writing down ingredients and metainformation [46].", "startOffset": 176, "endOffset": 180}, {"referenceID": 37, "context": "Beyond using users\u2019 online activities, food logging and journaling learn users\u2019 real food consumption history and require users\u2019 active involvement, such as taking food images [16] or writing down ingredients and metainformation [46].", "startOffset": 229, "endOffset": 233}, {"referenceID": 38, "context": "Based on PlateClick\u2019s online learning framework [47], Yum-me infers users\u2019 preferences for each single food item among a large food dataset, and projects these preferences for general food items into the domain that meets each individual user\u2019s health goals.", "startOffset": 48, "endOffset": 52}, {"referenceID": 8, "context": "The tasks of analyzing food images are very important in many ubiquitous dietary applications that actively or passively collect food images from mobile [16] and wearable [7, 42, 34] devices.", "startOffset": 153, "endOffset": 157}, {"referenceID": 0, "context": "The tasks of analyzing food images are very important in many ubiquitous dietary applications that actively or passively collect food images from mobile [16] and wearable [7, 42, 34] devices.", "startOffset": 171, "endOffset": 182}, {"referenceID": 33, "context": "The tasks of analyzing food images are very important in many ubiquitous dietary applications that actively or passively collect food images from mobile [16] and wearable [7, 42, 34] devices.", "startOffset": 171, "endOffset": 182}, {"referenceID": 25, "context": "The tasks of analyzing food images are very important in many ubiquitous dietary applications that actively or passively collect food images from mobile [16] and wearable [7, 42, 34] devices.", "startOffset": 171, "endOffset": 182}, {"referenceID": 26, "context": "The estimation of food intake and its nutritional information is helpful to our health [35] as it provides detailed records of our dietary history.", "startOffset": 87, "endOffset": 91}, {"referenceID": 26, "context": "Previous work mainly conducted the analysis by leveraging the crowd [35, 43] and computer vision algorithms [10, 33].", "startOffset": 68, "endOffset": 76}, {"referenceID": 34, "context": "Previous work mainly conducted the analysis by leveraging the crowd [35, 43] and computer vision algorithms [10, 33].", "startOffset": 68, "endOffset": 76}, {"referenceID": 3, "context": "Previous work mainly conducted the analysis by leveraging the crowd [35, 43] and computer vision algorithms [10, 33].", "startOffset": 108, "endOffset": 116}, {"referenceID": 24, "context": "Previous work mainly conducted the analysis by leveraging the crowd [35, 43] and computer vision algorithms [10, 33].", "startOffset": 108, "endOffset": 116}, {"referenceID": 26, "context": "[35] crowdsourced nutritional analysis of food images by leveraging the wisdom of untrained crowds.", "startOffset": 0, "endOffset": 4}, {"referenceID": 34, "context": "[43] elicit the crowd to rank the healthiness of several food items and validate the results against the ground truth provided by trained observers.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "To overcome the limitations of crowds and automate the analysis process, in the computer vision and Ubicomp communities, there are numerous papers discussing algorithms for food image analysis, including classification [10, 33, 29, 8], retrieval [30], and nutrient estimation [33, 40, 13, 24].", "startOffset": 219, "endOffset": 234}, {"referenceID": 24, "context": "To overcome the limitations of crowds and automate the analysis process, in the computer vision and Ubicomp communities, there are numerous papers discussing algorithms for food image analysis, including classification [10, 33, 29, 8], retrieval [30], and nutrient estimation [33, 40, 13, 24].", "startOffset": 219, "endOffset": 234}, {"referenceID": 20, "context": "To overcome the limitations of crowds and automate the analysis process, in the computer vision and Ubicomp communities, there are numerous papers discussing algorithms for food image analysis, including classification [10, 33, 29, 8], retrieval [30], and nutrient estimation [33, 40, 13, 24].", "startOffset": 219, "endOffset": 234}, {"referenceID": 1, "context": "To overcome the limitations of crowds and automate the analysis process, in the computer vision and Ubicomp communities, there are numerous papers discussing algorithms for food image analysis, including classification [10, 33, 29, 8], retrieval [30], and nutrient estimation [33, 40, 13, 24].", "startOffset": 219, "endOffset": 234}, {"referenceID": 21, "context": "To overcome the limitations of crowds and automate the analysis process, in the computer vision and Ubicomp communities, there are numerous papers discussing algorithms for food image analysis, including classification [10, 33, 29, 8], retrieval [30], and nutrient estimation [33, 40, 13, 24].", "startOffset": 246, "endOffset": 250}, {"referenceID": 24, "context": "To overcome the limitations of crowds and automate the analysis process, in the computer vision and Ubicomp communities, there are numerous papers discussing algorithms for food image analysis, including classification [10, 33, 29, 8], retrieval [30], and nutrient estimation [33, 40, 13, 24].", "startOffset": 276, "endOffset": 292}, {"referenceID": 31, "context": "To overcome the limitations of crowds and automate the analysis process, in the computer vision and Ubicomp communities, there are numerous papers discussing algorithms for food image analysis, including classification [10, 33, 29, 8], retrieval [30], and nutrient estimation [33, 40, 13, 24].", "startOffset": 276, "endOffset": 292}, {"referenceID": 6, "context": "To overcome the limitations of crowds and automate the analysis process, in the computer vision and Ubicomp communities, there are numerous papers discussing algorithms for food image analysis, including classification [10, 33, 29, 8], retrieval [30], and nutrient estimation [33, 40, 13, 24].", "startOffset": 276, "endOffset": 292}, {"referenceID": 15, "context": "To overcome the limitations of crowds and automate the analysis process, in the computer vision and Ubicomp communities, there are numerous papers discussing algorithms for food image analysis, including classification [10, 33, 29, 8], retrieval [30], and nutrient estimation [33, 40, 13, 24].", "startOffset": 276, "endOffset": 292}, {"referenceID": 3, "context": "Most of the previous work [10] leveraged hand-crafted image features.", "startOffset": 26, "endOffset": 30}, {"referenceID": 1, "context": "However, traditional approaches were only demonstrated in special contexts, such as a specific restaurant [8] or particular type of cuisine [29] and the performances of the models might degrade when they are applied to food images in the wild.", "startOffset": 106, "endOffset": 109}, {"referenceID": 20, "context": "However, traditional approaches were only demonstrated in special contexts, such as a specific restaurant [8] or particular type of cuisine [29] and the performances of the models might degrade when they are applied to food images in the wild.", "startOffset": 140, "endOffset": 144}, {"referenceID": 5, "context": "In this paper, we designed FoodDist using deep convolutional neural network based multitask learning [12], which has been shown to be successful in improving model generalization power and performance in several applications [49, 17].", "startOffset": 101, "endOffset": 105}, {"referenceID": 40, "context": "In this paper, we designed FoodDist using deep convolutional neural network based multitask learning [12], which has been shown to be successful in improving model generalization power and performance in several applications [49, 17].", "startOffset": 225, "endOffset": 233}, {"referenceID": 9, "context": "In this paper, we designed FoodDist using deep convolutional neural network based multitask learning [12], which has been shown to be successful in improving model generalization power and performance in several applications [49, 17].", "startOffset": 225, "endOffset": 233}, {"referenceID": 3, "context": "With our proposed network structure, we show that FoodDist achieves superior performance when applied to the largest available real-world food image dataset [10], and when compared to prior approaches.", "startOffset": 157, "endOffset": 161}, {"referenceID": 38, "context": "\u2022 Users then use PlateClick\u2019s visual interface [47] to express their fine-grained food preferences through simple comparisons of food items.", "startOffset": 47, "endOffset": 51}, {"referenceID": 24, "context": "As suggested by [33], we treat the whole training set of Food-101 dataset [10] as one generic food category and sampled the same number of images (75,750) from the ImageNet dataset [18] as our nonfood category.", "startOffset": 16, "endOffset": 20}, {"referenceID": 3, "context": "As suggested by [33], we treat the whole training set of Food-101 dataset [10] as one generic food category and sampled the same number of images (75,750) from the ImageNet dataset [18] as our nonfood category.", "startOffset": 74, "endOffset": 78}, {"referenceID": 10, "context": "As suggested by [33], we treat the whole training set of Food-101 dataset [10] as one generic food category and sampled the same number of images (75,750) from the ImageNet dataset [18] as our nonfood category.", "startOffset": 181, "endOffset": 185}, {"referenceID": 30, "context": "We took the pretrained VGG CNN model [39] and replaced the final 1000 dimensional softmax with a single logistic node.", "startOffset": 37, "endOffset": 41}, {"referenceID": 17, "context": "We trained the binary classifier using the Caffe framework [26] and it reached 98.", "startOffset": 59, "endOffset": 63}, {"referenceID": 36, "context": "For each of the recipe images, we embed it into an 1000dimensional feature space using FoodDist (described later in FoodDist section) and then project all the images onto a 2-D plane using t-Distributed Stochastic Neighbor Embedding(tSNE) [45].", "startOffset": 239, "endOffset": 243}, {"referenceID": 11, "context": "We choose these nutrients for their high relevance to many common health goals, such as weight control [19], sports performance [11], etc.", "startOffset": 103, "endOffset": 107}, {"referenceID": 4, "context": "We choose these nutrients for their high relevance to many common health goals, such as weight control [19], sports performance [11], etc.", "startOffset": 128, "endOffset": 132}, {"referenceID": 38, "context": "PlateClick is a visual online learning framework proposed in [47].", "startOffset": 61, "endOffset": 65}, {"referenceID": 38, "context": "In the following, we provide a brief introduction to PlateClick\u2019s online learning algorithm; for details, see [47].", "startOffset": 110, "endOffset": 114}, {"referenceID": 23, "context": "Traditional feature representations for images are mostly hand-crafted, and were used with feature descriptors, such as SIFT (Scale Invariant Feature Transform)[32] etc.", "startOffset": 160, "endOffset": 164}, {"referenceID": 28, "context": "In contrast, deep learning adapts the features to particular image characteristics and extracts features that are most discriminative in the given task [37].", "startOffset": 152, "endOffset": 156}, {"referenceID": 16, "context": ") is roughly equivalent to a linear classifier that is built on the features f (x) [25].", "startOffset": 83, "endOffset": 87}, {"referenceID": 38, "context": "Prior work [47] used a Siamese network to learn a feature extractor for food images.", "startOffset": 11, "endOffset": 15}, {"referenceID": 16, "context": "In order to leverage the benefits of both tasks, we propose a multitask learning design [25] for FoodDist.", "startOffset": 88, "endOffset": 92}, {"referenceID": 16, "context": "The idea of multitask learning is to share part of the model across tasks so as to improve the generalization ability of the learned model [25].", "startOffset": 139, "endOffset": 143}, {"referenceID": 3, "context": "We train all the models using Food-101 training dataset, which contains 75,750 food images from 101 food categories (750 instances for each category) [10].", "startOffset": 150, "endOffset": 154}, {"referenceID": 17, "context": "We implement models using Caffe[26] and experiment two CNN architectures in our framework: AlexNet[31], which won the first place at ILSVRC2012 challenge, and VGG[39], which is the state-of-the-art CNN model.", "startOffset": 31, "endOffset": 35}, {"referenceID": 22, "context": "We implement models using Caffe[26] and experiment two CNN architectures in our framework: AlexNet[31], which won the first place at ILSVRC2012 challenge, and VGG[39], which is the state-of-the-art CNN model.", "startOffset": 98, "endOffset": 102}, {"referenceID": 30, "context": "We implement models using Caffe[26] and experiment two CNN architectures in our framework: AlexNet[31], which won the first place at ILSVRC2012 challenge, and VGG[39], which is the state-of-the-art CNN model.", "startOffset": 162, "endOffset": 166}, {"referenceID": 38, "context": "For the multitask learning framework, we sample the similar and dissimilar image pairs with 1:10 ratio from the Food-101 dataset based on the categorical labels to be consistent with the previous work[47].", "startOffset": 200, "endOffset": 204}, {"referenceID": 38, "context": "Therefore, as suggested by previous work [47, 48], We check the nearest k-neighbors of each test image, for k = 1,2, .", "startOffset": 41, "endOffset": 49}, {"referenceID": 39, "context": "Therefore, as suggested by previous work [47, 48], We check the nearest k-neighbors of each test image, for k = 1,2, .", "startOffset": 41, "endOffset": 49}, {"referenceID": 3, "context": "09% Top-1 accuracy, which significantly outperforms the original RFDC [10] model and the proprietary GoogLeNet model [33]; For the retrieval task, FoodDist doubles the mAP value reported by previous work [47] that only used the AlexNet and siamese network architecture.", "startOffset": 70, "endOffset": 74}, {"referenceID": 24, "context": "09% Top-1 accuracy, which significantly outperforms the original RFDC [10] model and the proprietary GoogLeNet model [33]; For the retrieval task, FoodDist doubles the mAP value reported by previous work [47] that only used the AlexNet and siamese network architecture.", "startOffset": 117, "endOffset": 121}, {"referenceID": 38, "context": "09% Top-1 accuracy, which significantly outperforms the original RFDC [10] model and the proprietary GoogLeNet model [33]; For the retrieval task, FoodDist doubles the mAP value reported by previous work [47] that only used the AlexNet and siamese network architecture.", "startOffset": 204, "endOffset": 208}, {"referenceID": 3, "context": "RFDC\u2217[10] 50.", "startOffset": 5, "endOffset": 9}, {"referenceID": 24, "context": "76% \u2212\u2212 GoogleLeNet\u2217[33] 79% \u2212\u2212", "startOffset": 19, "endOffset": 23}, {"referenceID": 38, "context": "Food-CNN\u2217[47] 0.", "startOffset": 9, "endOffset": 13}, {"referenceID": 24, "context": "given a query image, we find its closest neighbor in the FoodDist based on their euclidean distance, and use that neighbor\u2019s nutritional information to estimate the nutrition facts of the query image [33].", "startOffset": 200, "endOffset": 204}], "year": 2017, "abstractText": "Many ubiquitous computing projects have addressed health and wellness behaviors such as healthy eating. Healthy meal recommendations have the potential to help individuals prevent or manage conditions such as diabetes and obesity. However, learning people\u2019s food preferences and making healthy recommendations that appeal to their palate is challenging. Existing approaches either only learn high-level preferences or require a prolonged learning period. We propose Yum-me, a personalized healthy-meal recommender system designed to meet individuals\u2019 health goals, dietary restrictions, and finegrained food preferences. Marrying ideas from user preference learning and healthy eating promotion, Yum-me enables a simple and accurate food preference profiling procedure via an image-based online learning framework, and projects the learned profile into the domain of healthy food options to find ones that will appeal to the user. We present the design and implementation of Yum-me, and further discuss the most critical component of it: FoodDist, a state-of-the-art food image analysis model. We demonstrate FoodDist\u2019s superior performance through careful benchmarking, and discuss its applicability across a wide array of dietary applications. We validate the feasibility and effectiveness of Yum-me through a 60-person user study, in which Yum-me improves the recommendation acceptance rate by 42.63% over the traditional food preference survey. ACM Classification", "creator": "LaTeX with hyperref package"}}}