{"id": "1605.07774", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-May-2016", "title": "Generalized Mirror Descents in Congestion Games", "abstract": "Different types of dynamics have been studied in repeated game play, and one of them which has received much attention recently consists of those based on \"no-regret\" algorithms from the area of machine learning. It is known that dynamics based on generic no-regret algorithms may not converge to Nash equilibria in general, but to a larger set of outcomes, namely coarse correlated equilibria. Moreover, convergence results based on generic no-regret algorithms typically use a weaker notion of convergence: the convergence of the average plays instead of the actual plays. Some work has been done showing that when using a specific no-regret algorithm, the well-known multiplicative updates algorithm, convergence of actual plays to equilibria can be shown and better quality of outcomes in terms of the price of anarchy can be reached for atomic congestion games and load balancing games. Are there more cases of natural no-regret dynamics that perform well in suitable classes of games in terms of convergence and quality of outcomes that the dynamics converge to?", "histories": [["v1", "Wed, 25 May 2016 08:32:48 GMT  (41kb,D)", "https://arxiv.org/abs/1605.07774v1", null], ["v2", "Thu, 13 Oct 2016 02:51:10 GMT  (41kb,D)", "http://arxiv.org/abs/1605.07774v2", "In Artificial Intelligence, Volume 241, Dec 2016"]], "reviews": [], "SUBJECTS": "cs.GT cs.LG", "authors": ["po-an chen", "chi-jen lu"], "accepted": false, "id": "1605.07774"}, "pdf": {"name": "1605.07774.pdf", "metadata": {"source": "CRF", "title": "Generalized Mirror Descents in Congestion Games\u2217", "authors": ["Po-An Chen", "Chi-Jen Lu"], "emails": ["poanchen@nctu.edu.tw.", "cjlu@iis.sinica.edu.tw."], "sections": [{"heading": null, "text": "We answer this question positively in the Bulletin Board Model by showing that using the mirror descent algorithm, a well-known generic no-regrets algorithm, the actual games quickly lead to balances in non-atomic congestion, resulting in a family of algorithms, including the multiplicative update algorithm and the gradient descent algorithm, among many others. Furthermore, we show that our dynamics reach good limits in terms of quality of outcome in terms of the price-of-anarchy measure type with two different social costs: the average individual cost and the maximum individual cost. Finally, the bandit model considers a probably more realistic and predominant environment with only incomplete information, in which each player knows at every step only the cost of their own currently played strategy, but no cost of unplayed strategies. For the class of atomic traffic jam games, we propose a family of bandit algorithms based on the mirror algorithm."}, {"heading": "1 Introduction", "text": "In this case, it is only a matter of time before that happens."}, {"heading": "1.1 Discussion of Our Results and Techniques", "text": "It is indeed the case that we are able to set out in search of new paths to follow in order to achieve our objectives."}, {"heading": "1.2 Related Work", "text": "In fact, it is the case that most people who have entered politics in recent years are able to take responsibility for themselves. \"(S. Fischer)\" It is not as if. \"(S. Fischer)\" It is as if. \"(S. Fischer)\" It is as if. \"(S. Fischer)\" It is as if. \"(S. Fischer)\" It is as if. \"(S. Fischer)\" It is as if. \"(S. Fischer)\" It is as if. \"(S. Fischer)\" It is as if. \"(S. Fischer)\" (S. Fischer), \"(S. Fischer),\" (S. Fischer), \"(S. Fischer),\" (S. Fischer). (S. Fischer). (S. Fischer). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.)."}, {"heading": "2 Preliminaries", "text": "In this article we will first consider the non-atomic congestion caused by (N, E, (Si) i, (ce) e, where N is the amount of goods, E is the amount of corners and edges (resources), Si 2E is the collection of the allowed paths (the allowed subsets of resources) for the goods i, and ce is the cost function of edge e, which is a non-decreasing function of the load on it. A commodity is a \"pseudo-player,\" which we simply call a \"player\" in the entire discussion of non-atomic congestion games, meaning that a player himself does not act as a selfish party, but the infinitesimal function of a player is composed. We will describe it in more detail below."}, {"heading": "3 The Bulletin-Board Model", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Dynamics", "text": "We look at the attitude in which the players play the game iteratively in the following way."}, {"heading": "3.2 Convergence Results and Equilibria", "text": "Our main result in this section is the following, which shows that if each player (or agent of a player) uses such an update algorithm, the system converges quickly, in the sense that the value of the potential function \u03a6 (xt) quickly approaches the minimum speed (q) where q = arg minz \u00b2 (z).Theorem 4. Let us consider any non-atomic overload game of n players, with a potential function relating to some (R1,., Rn).Let q = (q1,., qn) = arg minz \u00b2 game of n players (z). Let us now assume that each player i starts from some initial strategy x0i, with BRi, x0i), and updates their strategy according to the rule in (5) with which it (1 / 2) is equal to."}, {"heading": "3.2.1 Proof of Theorem 7", "text": "To simplify our notation, let's use the progression vector (xt) by gt = (gt1,..) < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < <"}, {"heading": "3.2.2 Proof of Corollary 5", "text": "First, consider the case where each player plays the gradient pedigree algorithm. Note that this corresponds to the choice of Ri (ui) for each i. Then, we can show that BRi (ui, vi) is smooth for each i. Then, we can choose BRi (qi, x0i) for each i is smooth, and we can show that BRi (qi, x0i) is smooth for each i. If we use the Taylor extension together with Proposition 2, we know that for each x, x, x, x, K (x) is smooth."}, {"heading": "3.2.3 Proof of Theorem 6", "text": "Let's look at any x-K value so that any x-K value is so high that any x-K value is so high that any x-K value is so high that any x-K value is so high that any x-K value is as low as it is. Let's look at any x-K value so that any x-K value is as low as it is. Let's look at all x-K values so high that any x-K value is as low as it is. (Si value) Let's move a significant load amount from s1 to s0 and let's reduce the value substantially. (S1 value) Let's note that the cost increase to s0 and the cost reduction to s1 value is so low. (S1 value) Let's move an amount that we'll set later from s1 to s0, and let's let's have z value specify the new flow. Let's note that the cost increase to s0, and the cost reduction to both c is equal to sz-1."}, {"heading": "3.3 Social Costs", "text": "In this section we show the effects of this property on social costs. [12] Pinsker's inequality states that the total variance is above the KL divergence between two probability distributions, where the total variance can be defined as half of the 1 norm between these two distributions. Bregman divergence here is KL divergence."}, {"heading": "3.3.1 Average Individual Cost", "text": "We show that after the convergence time, the average individual costs achieved by our algorithm are only within a constant factor that differs from the optimum. Theorem 11. Each x-K solution can be designed so that each x-K solution can be used as CA (x) \u2264 \u03a6 (x) CA (x) \u2264 b a (1 + 2m\u03b5a). Proof. For each z-K solution we can use CA (z) as CA (z) = \u00b2 e (z). Under condition (4) we have yc \u2032 e (y) \u2264 e (z) = \u00b2 e (z) 0 (yce (y) \u2032 dy (e) 0 (z) + yc \u2032 e (y) dy.Under condition (4) we have yc \u00b2 e (y) yb = bab0y \u2264 b) ace (y) and thusy) b (z)."}, {"heading": "3.3.2 Maximum Individual Cost in Symmetric Games", "text": "In a symmetrical game, we can have Si = S for each i-N game. Using this property, we show that after the convergence time, the maximum individual costs achieved by our algorithm are again within a constant factor of optimum one. Theorem 12. Any x-K value that is such that any x-value (x) \u2264 (q) + \u03b5 CM (x) CM (x-value) \u2264 b (1 + 2m\u03b5.Proof. Let us consider any x-value K-value (x) \u2264 (q) + \u03b5 value. Let us leave s0 = arg-value S (x) and s1 = arg maxs-value S (x). To apply Theorem 6, we choose a player i with xi, s1 > 0; such a player must exist, otherwise there would be no load on s1 and cs1 (x) x-value. Since Si = S-value for a symmetrical game, we cannot have x-value."}, {"heading": "4 The Bandit Model", "text": "We look at the setting in which the players play the congestion game iteratively in the following way: in step t each player plays a strategy xti by selecting a path si-Si with the probability \u03c0ti, si = x-i, si-n and sending his total cash flow 1 / n through this path si. Then she gets to know the cost of this path, the iscsi (X-t) = E-si ce ('e (X-t)), where Xt is the selection vector of the players in step t. With this feedback she updates her next strategy xt + 1i in some way and then proceeds to the next step. Let's emphasize that the only information a player has access to in one step is the cost of the path she has just chosen, and she has no information about the path she has not chosen. This is known as the bandit model in the area of online learning x."}, {"heading": "4.1 Bandit Algorithms", "text": "We would like to follow the approach of Section 3.1, which has shown that when each player plays a mirror descent algorithm at their own learning rate, the common strategy profile of the players converges quickly. However, there are two major differences in our attitude that prevent us from directly applying their result. The first difference is that here we are looking at the atomic version of the Jam game, in which each player must send their entire flow to a single path, as opposed to the non-atomic version, which is considered in Section 3, in which a player can split their flow across multiple paths at each step. The second difference is that the feedback model considered in Section 3 is the simpler bulletin model, in which each player, after sending his flow in one step, can see all the costs of their permitted paths. That is, in Step t, player i is able to learn the cost (x t)."}, {"heading": "4.1.1 Updating the Strategies", "text": "With a \"good\" estimate g-i, which we will define and show how to achieve in Section 4.1.2 = \"Updates,\" we can follow Section 3.1 and take into account the following update rule for each player i's strategy for the next episode: xi-i = arg min zi-K-i \"(\u00b7) is the Bregman divergence in relation to Ri defined asBRi (ui, vi) = Ri (ui) \u2212 Ri (vi) \u2212 R is a certain regulatory function, and BRi (\u00b7) is the Bregman divergence in relation to Ri defined asBRi (ui, vi) = Ri (ui) \u2212 Ri (vi) \u2212 Ri (vi) \u2212 R is a certain regulatory function, and BRi-K is the divergence in relation to Ri defined asBRi (ui, vi).i This gives rise to a family of update rules for various decisions of Ri."}, {"heading": "4.1.2 Approximating the Gradient", "text": "This means that if we allow the S'th entry period in g'i, s denotes the s'th entry period in g'i, s denotes the s'th entry period in g'i, s denotes the s'th entry period in g'i, s denotes the s'th entry period in g'i, s denotes the series of steps in the sequence chosen by the player. This requires that the s-entry period is large enough, the entry period is needed in turns, s-entry period, s-entry period, s-entry period, s-entry period, s-entry period, s-entry period, s-entry period, s-entry period, s-entry period, s-entry period, s-entry period, s-entry period, s-entry period, s-entry period,"}, {"heading": "4.2 Convergence Results", "text": "In this section, we analyze the behavior of the system of players who adopt the algorithm described in Section 4.1. (Our main result is the following, which shows that the system actually converges quickly, in the sense that the value of the potential function of players with a potential function quickly comes close to the minimum value, with q = arg minz, K (z), and then stays close. (Theorem 17) Let us consider any atomic overload of the game by n players, with a potential function that is (\u03b1, \u03b2) -smooth, and let us leave q = arg minz, K (z). Each player updates his strategy according to the rule in (5), with the ability of n players to play with a potential function that is described (21) with the guarantee that he can make such a choice. (x2) Let us consider the strategy of players who update his strategy according to the rule in (5), with the help of i."}, {"heading": "4.2.1 Proof of Lemma 20", "text": "To simplify our notation, let us introduce the Gradient Vector Vector Vector Vector Vector Vector Vector Vector Vector Vector Vector Vector Vector Vector Vector Vector Vector Vector Vector Vector Vector Vector (Vector) Vector Vector (Vector) Vector Vector (Vector) Vector (Vector) Vector (Vector) Vector (Vector) Vector (Vector) Vector (Vector) Vector (Vector) Vector (Vector) Vector (Vector)"}, {"heading": "4.2.2 Proof of Corollary 18", "text": "In this case, the algorithm of each player becomes the gradient descent algorithm, and we can choose whether we want BRi (xi, yi) = xi \u2212 yi \u00b2 22 / 2, which gives us 4 = 21 \u221a 2\u03b7n and 0 = 7. The second example is to choose Ri (xi) = 44 s (xi, s \u2212 xi, s), and we can choose BRi (xi, yi) = 2\u03b7n1\u03b2d, which gives us 4 = 21 \u221a 2\u03b7n and 0 = 7. The second example is to choose Ri (xi) = 44 s (xi, s \u2212 xi, s \u2212 xi, s) = 2 episodes of ln (xi, s / yi, s). In this case, the algorithm of each player becomes a multiplicative algorithm."}, {"heading": "4.3 Equilibria and Social Costs", "text": "Now we will briefly discuss the implication of the guarantee \u03a6 (x\u03c4) \u2264 \u03a6 (q) + 4 given by the results in section 4.2. First, such an arrangement is an approximate equilibrium in mixed strategies, where we say that \u03c0 is a Higgs equilibrium if for each player i-N and all paths s, s-Si with xi, s > 0, E [cs (X)] \u2264 E [cs) + 4, where X must have the selected structures after x and xi = 1 n\u03c0i for all i.14. To show this, we note that from section 3.2.3 we know that any x\u0440 satisfaction of the condition (x\u0440) \u2264 (q) + 4, which must have cs (x\u0442) \u2264 cs (xtra), the classes after CS (xtra) + 8bm4. This and Proposition 1314It is an alternative way to define an approximate equilibrium. Let (yi), X \u2212 X \u2212 ii."}, {"heading": "5 Conclusions and Future Work", "text": "We show that the dynamics of mirror descent move to an approximate equilibrium in non-atomic congestion games by observing that the dynamics correspond to a mirror descent process on a convex potential function of such a game, and then prove that the process converges to a minimum of function. Furthermore, we set limits to the quality of results achieved by our dynamics in relation to two social costs: the average individual cost and the maximum individual cost. Finally, we propose a new family of bandit algorithms and show that if each player uses such an algorithm in an atomic congestion game, his actual common strategy profile quickly approaches an approximate equilibrium. There may be other no-regret algorithms or even other learning algorithms that could guarantee beautiful convergence characteristics or simply a good quality of results. There are more learning algorithms and dynamics that need to be explored in repeated games, while classes are still numerous."}, {"heading": "A Proof of Proposition 1", "text": "Consider that \"e\" is a linear function of x-K, while \"e\" is a convex function of v-R, since it is assumed that it does not decrease."}, {"heading": "B Proof of Proposition 2", "text": "Consider first-time x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x"}, {"heading": "C The No-Regret Property of Our Dynamics", "text": "We will consider such a setting where the actual cost of each edge in time step is t cte (\"e (x t), where\" e (x t) is the load of the edge in question in t. We will define a new cost function Cte (x) as follows: Cte (x): = {cte (x), if x \u2264 \"e (xt) cte (\" e (x t)))) otherwise. Among these new cost functions, the cost of each edge observed in due time, cte (\"e (x t))), would actually be the worst, and any further increase in the burden of an edge would have no effect on its cost. If this optimistic view of costs were really true, then the algorithm using bulletin board posting would function in the same way as the mirror-repentant algorithm, thus preserving no-repentance ownership."}, {"heading": "D Proof of Proposition 15", "text": "By definition, we have BRi (xi, yi) = \u2211 s xi, s ln (1 + xi, s \u2212 yi, s \u2212 yi, s) \u2264 s xi, s xi, s \u2212 yi, s = \u2211 s (xi, s \u2212 yi, s) 2 yi, s + s (xi, s \u2212 yi, s), which, using the fact that we have xi, s = 1 n = x s yi, s = s (xi, s \u2212 yi, s) 2yi, s \u2264 n xi \u2212 yi, 22 as we have yi, s \u2212 yi, s \u2212 n for each yi K-i. This shows that in each xi \u2212 yi, yi \u2012 xi \u2212 yi \u2012 22 for each xi, yi \u2012 K-i. On the other hand, in each xi, yi \u2012 Ki, xi \u2212 yi \u2012 22 \u2264 xi \u2212 yi \u2012 2BRi (xi, yi), measured by pinski quality, we have inequality."}], "references": [], "referenceMentions": [], "year": 2016, "abstractText": "<lb>Different types of dynamics have been studied in repeated game play, and one of them<lb>which has received much attention recently consists of those based on \u201cno-regret\u201d algorithms<lb>from the area of machine learning. It is known that dynamics based on generic no-regret<lb>algorithms may not converge to Nash equilibria in general, but to a larger set of outcomes,<lb>namely coarse correlated equilibria. Moreover, convergence results based on generic no-regret<lb>algorithms typically use a weaker notion of convergence: the convergence of the average plays<lb>instead of the actual plays. Some work has been done showing that when using a specific no-<lb>regret algorithm, the well-known multiplicative updates algorithm, convergence of actual plays<lb>to equilibria can be shown and better quality of outcomes in terms of the price of anarchy can be<lb>reached for atomic congestion games and load balancing games. Are there more cases of natural<lb>no-regret dynamics that perform well in suitable classes of games in terms of convergence and<lb>quality of outcomes that the dynamics converge to?<lb>We answer this question positively in the bulletin-board model by showing that when em-<lb>ploying the mirror-descent algorithm, a well-known generic no-regret algorithm, the actual plays<lb>converge quickly to equilibria in nonatomic congestion games. This gives rise to a family of al-<lb>gorithms, including the multiplicative updates algorithm and the gradient descent algorithm as<lb>well as many others. Furthermore, we show that our dynamics achieves good bounds on the<lb>outcome quality in terms of the price-of-anarchy type of measures with two different social costs:<lb>the average individual cost and the maximum individual cost.<lb>Finally, the bandit model considers a probably more realistic and prevalent setting with<lb>only partial information, in which at each time step each player only knows the cost of her<lb>own currently played strategy, but not any costs of unplayed strategies. For the class of atomic<lb>congestion games, we propose a family of bandit algorithms based on the mirror-descent algo-<lb>rithms previously presented, and show that when each player individually adopts such a bandit<lb>algorithm, their joint (mixed) strategy profile quickly converges with implications. \u2217Part of the results in this paper have appeared in preliminary form in the proceedings of AAMAS 2014 [13] and<lb>as an extended abstract in AAMAS 2015 [14].<lb>\u2020Institute of Information Management, National Chiao Tung University, Taiwan. Email: poanchen@nctu.edu.tw.<lb>Supported in part by NSC 102-2221-E-009-061-MY2.<lb>\u2021Institute of Information Science, Academia Sinica, Taiwan. Email: cjlu@iis.sinica.edu.tw. 1<lb>ar<lb>X<lb>iv<lb>:1<lb>60<lb>5.<lb>07<lb>77<lb>4v<lb>2<lb>[<lb>cs<lb>.G<lb>T<lb>]<lb>1<lb>3<lb>O<lb>ct<lb>2<lb>01<lb>6", "creator": "LaTeX with hyperref package"}}}