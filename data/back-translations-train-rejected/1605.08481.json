{"id": "1605.08481", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-May-2016", "title": "Open Problem: Best Arm Identification: Almost Instance-Wise Optimality and the Gap Entropy Conjecture", "abstract": "The best arm identification problem (BEST-1-ARM) is the most basic pure exploration problem in stochastic multi-armed bandits. The problem has a long history and attracted significant attention for the last decade. However, we do not yet have a complete understanding of the optimal sample complexity of the problem: The state-of-the-art algorithms achieve a sample complexity of $O(\\sum_{i=2}^{n} \\Delta_{i}^{-2}(\\ln\\delta^{-1} + \\ln\\ln\\Delta_i^{-1}))$ ($\\Delta_{i}$ is the difference between the largest mean and the $i^{th}$ mean), while the best known lower bound is $\\Omega(\\sum_{i=2}^{n} \\Delta_{i}^{-2}\\ln\\delta^{-1})$ for general instances and $\\Omega(\\Delta^{-2} \\ln\\ln \\Delta^{-1})$ for the two-arm instances. We propose to study the instance-wise optimality for the BEST-1-ARM problem. Previous work has proved that it is impossible to have an instance optimal algorithm for the 2-arm problem. However, we conjecture that modulo the additive term $\\Omega(\\Delta_2^{-2} \\ln\\ln \\Delta_2^{-1})$ (which is an upper bound and worst case lower bound for the 2-arm problem), there is an instance optimal algorithm for BEST-1-ARM. Moreover, we introduce a new quantity, called the gap entropy for a best-arm problem instance, and conjecture that it is the instance-wise lower bound. Hence, resolving this conjecture would provide a final answer to the old and basic problem.", "histories": [["v1", "Fri, 27 May 2016 00:23:39 GMT  (8kb)", "http://arxiv.org/abs/1605.08481v1", "To appear in COLT 2016 Open Problems"]], "COMMENTS": "To appear in COLT 2016 Open Problems", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["lijie chen", "jian li"], "accepted": false, "id": "1605.08481"}, "pdf": {"name": "1605.08481.pdf", "metadata": {"source": "CRF", "title": "Open Problem: Best Arm Identification: Almost Instance-Wise Optimality and the Gap Entropy Conjecture", "authors": ["Lijie Chen", "Jian Li"], "emails": ["CHENLJ13@MAILS.TSINGHUA.EDU.CN", "LIJIAN83@MAIL.TSINGHUA.EDU.CN"], "sections": [{"heading": null, "text": "ar Xiv: 160 5.08 481v 1 [cs.L G] 27 May 2 \u2211 n = 2 \u0445 \u2212 2 i (ln \u03b4 \u2212 1 + ln \u2206 \u2212 1 i)) (\u2206 i is the difference between the greatest mean and the highest mean), while the best known lower limit is for general instances and for the two-armed instances. We propose to examine the instance-by-instance optimality for the BEST-1 ARM problem. Previous work has shown that it is impossible to have an optimal instance algorithm for the two-armed problem. However, we suspect that the additive term \"p\" modulo \"(for the BEST-1-ARM problem is an upper and worst possible lower limit for the two-armed problem) is modulo. Furthermore, we are introducing a new problem that represents a fundamental instance for the lower instance and the lower instance for the two-armed problem."}, {"heading": "1. Introduction", "text": "In the BEST-1 ARM problem, we get n stochastic arms A1,..,. The ith arm Ai has a reward distribution Di with an unknown mean \u00b5i [0, 1]. We assume that all reward distributions are Gaussian distributions with variance 1. With each game of Ai, we can get a reward value, which is i.e. sampled by Di. Our goal is to identify the arm with the largest mean, using as few samples as possible. We assume here that the largest mean is strictly greater than the second largest (i.e., \u00b5 [1] > \u00b5 [2]), in order to ensure the uniqueness of the solution, with \u00b5 [i] denoting the ith largest mean. The problem is also referred to as a pure exploration problem in stochastic, multi-armed bandit reading. We say that an algorithm A for BEST-1 ARM is error-free, if we use the correct response \u00b5 with a probability of 1 and a \u2212 3."}, {"heading": "2. Background", "text": "Over the past decade, the BEST-1 ARM problem and its optimal sample complexity have attracted significant attention; we mention only a small subset that is most relevant to us; the current best lower limit is due to Mannor and Tsitsiklis (2004), which have shown that it requires \"intrigue\" for any \u03b4-correct algorithm for BEST-1 ARM; the research, partially supported by the National Basic Research Program of China, grants 2015CB358700, 2011CBA00300, 2011CBA00301; and the National NSFC grants 61033001, 6136003.c \u00a9 2016 L. Chen & J. Li.on) samples in anticipation. \u2212 We note that the lower limit of UCNS and the upper limit of ARNS 6136003.c \u00a9 2016 L. Farduxan grants the lower limit of the lowest limit (2016 L. & J. Lion) samples in anticipation."}, {"heading": "3. Open Problem: Almost Instance Optimality and the Gap Entropy Conjecture", "text": "We propose to study BEST-1-ARM from the perspective of instance optimality, the ultimate notion of optimality we should consider as an instance (see e.g. Fagin et al. (2003); Afshani et al. (2009). For the 2-armed cases, the KKS-JMNS bound instance O (6) is an upper limit for each instance, and the Farrell lower limit for each instance is a lower limit for the worst cases. As we have observed in (Chen and Li (2015), it is impossible to obtain an instance that is optimal even for the 2-armed cases. While observation rules out any hope for an instance of optimal algorithms for BEST-1-ARM, as we will see, it is still possible to obtain a very satisfactory response with respect to the instance optimality. Now, we formally define what is an instance smart lower limit."}, {"heading": "4. Motivation and Current Progress", "text": "In our recent work (Chen and Li (2015), we can achieve an algorithm with the following sample complexity: O (2) ln (2) ln (2) ln (1) ln (2) ln (2) ln (2) ln (2) ln (2) ln (2) ln (1) ln (2) ln (2) ln (2) ln (1) ln (2) ln (1) ln (2) ln (2) ln (2) ln (2)) ln (2)) ln (2) ln (2) ln (2) ln (2) ln (2) ln (2) ln (1)."}], "references": [{"title": "Instance-optimal geometric algorithms", "author": ["Peyman Afshani", "J\u00e9r\u00e9my Barbay", "Timothy M Chan"], "venue": "In Foundations of Computer Science,", "citeRegEx": "Afshani et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Afshani et al\\.", "year": 2009}, {"title": "On the optimal sample complexity for best arm identification", "author": ["Lijie Chen", "Jian Li"], "venue": "arXiv preprint arXiv:1511.03774,", "citeRegEx": "Chen and Li.,? \\Q2015\\E", "shortCiteRegEx": "Chen and Li.", "year": 2015}, {"title": "Optimal aggregation algorithms for middleware", "author": ["Ronald Fagin", "Amnon Lotem", "Moni Naor"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "Fagin et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Fagin et al\\.", "year": 2003}, {"title": "Asymptotic behavior of expected sample size in certain one sided tests", "author": ["RH Farrell"], "venue": "The Annals of Mathematical Statistics,", "citeRegEx": "Farrell.,? \\Q1964\\E", "shortCiteRegEx": "Farrell.", "year": 1964}, {"title": "lil\u2019ucb: An optimal exploration algorithm for multi-armed bandits", "author": ["Kevin Jamieson", "Matthew Malloy", "Robert Nowak", "S\u00e9bastien Bubeck"], "venue": null, "citeRegEx": "Jamieson et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Jamieson et al\\.", "year": 2014}, {"title": "Almost optimal exploration in multi-armed bandits", "author": ["Zohar Karnin", "Tomer Koren", "Oren Somekh"], "venue": "In Proceedings of the 30th International Conference on Machine Learning", "citeRegEx": "Karnin et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Karnin et al\\.", "year": 2013}, {"title": "The sample complexity of exploration in the multi-armed bandit problem", "author": ["Shie Mannor", "John N Tsitsiklis"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Mannor and Tsitsiklis.,? \\Q2004\\E", "shortCiteRegEx": "Mannor and Tsitsiklis.", "year": 2004}], "referenceMentions": [{"referenceID": 6, "context": "The current best lower bound is due to Mannor and Tsitsiklis (2004), who showed that for any \u03b4-correct algorithm for BEST-1-ARM, it requires \u03a9 (", "startOffset": 39, "endOffset": 68}, {"referenceID": 0, "context": ", due to Karnin et al. (2013). Jamieson et al.", "startOffset": 9, "endOffset": 30}, {"referenceID": 0, "context": "Jamieson et al. (2014) obtained a UCB-type algorithm (called lil\u2019UCB), which achieves the same sample complexity.", "startOffset": 0, "endOffset": 23}, {"referenceID": 0, "context": "Back in 1964, Farrell (1964) provided an \u03a9(\u2206\u22122 ln ln\u2206 2 ) lower bound for the two-arm cases (which matches the KKS-JMNS bound for two arms).", "startOffset": 14, "endOffset": 29}, {"referenceID": 0, "context": "Very recently, in an unpublished manuscript (Chen and Li (2015)), the authors obtained improved lower and upper bounds for BEST-1-ARM.", "startOffset": 45, "endOffset": 64}, {"referenceID": 0, "context": "Very recently, in an unpublished manuscript (Chen and Li (2015)), the authors obtained improved lower and upper bounds for BEST-1-ARM. The work lead the authors to make an intriguing conjecture which we detail in the next section. We will also state the improved bounds and their connection to the conjecture in more details. 3. Open Problem: Almost Instance Optimality and the Gap Entropy Conjecture We propose to study BEST-1-ARM from the perspective of instance optimality, the ultimate notion of optimality (see e.g., Fagin et al. (2003); Afshani et al.", "startOffset": 45, "endOffset": 542}, {"referenceID": 0, "context": "(2003); Afshani et al. (2009)).", "startOffset": 8, "endOffset": 30}, {"referenceID": 0, "context": "(2003); Afshani et al. (2009)). For the 2-arm cases, the KKS-JMNS bound O(\u2206\u22122 ln ln\u2206 2 ) is an upper bound for every instance, and the Farrell lower bound \u03a9(\u2206\u22122 ln ln\u2206 2 ) is a lower bound for the worst case instances. As we observed in (Chen and Li (2015)), it is impossible to obtain an instance optimal algorithm even for the 2-arm cases.", "startOffset": 8, "endOffset": 257}, {"referenceID": 0, "context": "(2003); Afshani et al. (2009)). For the 2-arm cases, the KKS-JMNS bound O(\u2206\u22122 ln ln\u2206 2 ) is an upper bound for every instance, and the Farrell lower bound \u03a9(\u2206\u22122 ln ln\u2206 2 ) is a lower bound for the worst case instances. As we observed in (Chen and Li (2015)), it is impossible to obtain an instance optimal algorithm even for the 2-arm cases. While the observation has ruled out any hope of an instance optimal algorithm for BEST-1-ARM, however, as we will see, it is still possible to obtain very satisfiable answer in terms of instance optimality. Now, we formally define what is an instance-wise lower bound. Clearly, two arm instances differ only by a permutation of arms should be considered as the same instance. Inspired by Afshani et al. (2009), we give the following natural definition.", "startOffset": 8, "endOffset": 752}, {"referenceID": 0, "context": "Interestingly, the formula involves an entropy term (similar entropy terms also appear in Afshani et al. (2009) for completely different problems).", "startOffset": 90, "endOffset": 112}, {"referenceID": 1, "context": "Motivation and Current Progress In our recent work (Chen and Li (2015)), we provide an algorithm with the following sample complexity:", "startOffset": 52, "endOffset": 71}, {"referenceID": 5, "context": "Consider an elimination-based algorithm (such as Karnin et al. (2013) or our algorithm).", "startOffset": 49, "endOffset": 70}, {"referenceID": 5, "context": "The algorithm in Karnin et al. (2013) used \u03b4r = O(\u03b4 \u00b7 r\u22122), and we used a better way to assign \u03b4r.", "startOffset": 17, "endOffset": 38}], "year": 2016, "abstractText": "The best arm identification problem (BEST-1-ARM) is the most basic pure exploration problem in stochastic multi-armed bandits. The problem has a long history and attracted significant attention for the last decade. However, we do not yet have a complete understanding of the optimal sample complexity of the problem: The state-of-the-art algorithms achieve a sample complexity of O( \u2211 n i=2 \u2206 i (ln \u03b4 + ln ln\u2206 i )) (\u2206i is the difference between the largest mean and the i mean), while the best known lower bound is \u03a9( \u2211n i=2 \u2206 i ln \u03b4) for general instances and \u03a9(\u2206 ln ln\u2206) for the two-arm instances. We propose to study the instance-wise optimality for the BEST-1-ARM problem. Previous work has proved that it is impossible to have an instance optimal algorithm for the 2-arm problem. However, we conjecture that modulo the additive term \u03a9(\u2206 2 ln ln\u2206 2 ) (which is an upper bound and worst case lower bound for the 2-arm problem), there is an instance optimal algorithm for BEST-1-ARM. Moreover, we introduce a new quantity, called the gap entropy for a best-arm problem instance, and conjecture that it is the instance-wise lower bound. Hence, resolving this conjecture would provide a final answer to the old and basic problem.", "creator": "LaTeX with hyperref package"}}}