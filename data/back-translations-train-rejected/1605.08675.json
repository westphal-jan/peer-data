{"id": "1605.08675", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-May-2016", "title": "Boosting Question Answering by Deep Entity Recognition", "abstract": "In this paper an open-domain factoid question answering system for Polish, RAFAEL, is presented. The system goes beyond finding an answering sentence; it also extracts a single string, corresponding to the required entity. Herein the focus is placed on different approaches to entity recognition, essential for retrieving information matching question constraints. Apart from traditional approach, including named entity recognition (NER) solutions, a novel technique, called Deep Entity Recognition (DeepER), is introduced and implemented. It allows a comprehensive search of all forms of entity references matching a given WordNet synset (e.g. an impressionist), based on a previously assembled entity library. It has been created by analysing the first sentences of encyclopaedia entries and disambiguation and redirect pages. DeepER also provides automatic evaluation, which makes possible numerous experiments, including over a thousand questions from a quiz TV show answered on the grounds of Polish Wikipedia. The final results of a manual evaluation on a separate question set show that the strength of DeepER approach lies in its ability to answer questions that demand answers beyond the traditional categories of named entities.", "histories": [["v1", "Fri, 27 May 2016 14:57:37 GMT  (378kb,D)", "http://arxiv.org/abs/1605.08675v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["piotr przyby{\\l}a"], "accepted": false, "id": "1605.08675"}, "pdf": {"name": "1605.08675.pdf", "metadata": {"source": "CRF", "title": "Boosting Question Answering by Deep Entity Recognition", "authors": ["Piotr Przyby\u0142a"], "emails": ["P.Przybyla@phd.ipipan.waw.pl"], "sections": [{"heading": "1 Introduction", "text": "In fact, it is such that most of them will be able to move into a different world, in which they are able to move, in which they are able to move, in which they move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live."}, {"heading": "2 RAFAEL", "text": "As already mentioned in the previous chapter, RAFAEL is a computer system that answers a task of Polish text-based, open-domain, factoid questions. It means that questions, knowledge base and returned answers are expressed in Polish and can belong to any area. It analyzes the knowledge base, which consists of a series of simple text documents, and provides answers (as short as possible, e.g. a personal name) that are provided with information about supporting sentences and documents. What types of queries fall into the category of factual questions? For the purpose of this study, it is understood to include the following types of answers: - Verification questions that can be answered by providing a single Boolean value (true or false), e.g.: Did Lee Oswald kill John F. Kennedy? - Option questions that require one of the available options, e.g. Which killed John F. Kennedy: Which killed John F. Kennedy: Lance Oswald or Lee Oswald?"}, {"heading": "2.1 Related work", "text": "This year, it has reached the point where it will be able to retaliate."}, {"heading": "2.2 System Architecture", "text": "A general architectural scheme of RAFAEL (Figure 1) was inspired by similar systems developed for English; for examples see works by Hovy et al. (2000) and Moldova et al. (2000). Two of the steps in the diagram concern offline processing of a knowledge base. Firstly, it is indexed by a search engine to ensure an efficient search at further stages (INDEXING). Secondly, it can be commented on with a number of tools (NLP), but this could also only happen when answering selected documents. Once the system has received a question, it is analyzed (QUESTION ANALYSIS) and converted into a data structure called a question model. One of its components, a search query, is used to find a set of documents likely to be suitable for the current problem (SEARCH). For each of the documents, all mentions that are compatible with a received question type (e.g., a sentence) are assigned to RAFAEL (a ONY REGRAGE)."}, {"heading": "2.3 Knowledge Base Processing", "text": "Knowledge Base (KB) processing consists of two elements: indexing and annotation. The first is to create an index for efficient search by means of a search engine. In the system, Lucene 3.62 is used to create two separate full-text indexes: regular and derived with a built-in pedigree for Polish, stamps (Galambos, 2001). Second, the texts go through a cascade of annotation tools, which they enrich with the following information: - Morphosyntactic interpretations (sets of tags), using Morfeusz 0.82 (Woli\u0144ski, 2006), - Tagging (selecting the most likely interpretation), using a transformation-based learning tag, PANTERA 0.9.1 (Aceda\u0144ski, 2010), - Syntactic groups (possibly nested), with syntactic and semantic heads, using a regulated Shal-Low-Parjkowski version 1.7 of Sav\u00f3rkowski (2008)."}, {"heading": "2.4 Question Analysis", "text": "The answer to this question is: \"The question about the why?\" The answer to this question is: \"The question about the why?\" The question about the why? \"The answer to the question about the why?\" The question about the why? \"The question about the why?\" The question about the why? \"The question about the why?\" The question about the why? \"The question about the why?\" The question about the why? \"The question about the why?\" The question about the why? \"The question about the why?\" The question about the why? \"The question about the why?\" The question about the why? \"The answer?\" The question about the why? \"The question about the why?\" The answer? \"The question about the why?\" The answer? \"The answer? The answer\" The question about the why? \"The answer? The answer\" The answer \"The question about the why? The question about the why? The question about the why?\" The question about the why? The question about the why? The question about the why? The question about the why? The question about the question about the why? The question about the question about the why? The question about the question about the why? The answer? The answer? The answer? The question about the question about the why? The answer?"}, {"heading": "2.5 Document Retrieval", "text": "Theoretically, we could analyze each document in a text base and find the one that is most relevant to our query. However, it would take an excessive amount of time to process the documents, most of which belong to irrelevant domains (839,269 articles in the test sentence). A search engine is used to speed up the process by selecting a set of documents and limiting any further analysis to them. As described in Section 2.3, a knowledge base would not yield results unless one uses a highly redundant KB, such as the WWW (for this type of solution see Brill et al., 2002). The problem is that an answer in the knowledge base is likely to be expressed differently from the question. Therefore, a query created directly from words of the question would not yield results, unless one uses a highly redundant KB, such as the WWW (for this kind of solution see Brill et al., 2002)."}, {"heading": "2.6 Entity Recognition", "text": "RAFAEL has two approaches to the problem: classic named entity recognition (NER) and novel deep entity recognition.Three NERs for Polish are used: NERF, Liner2 and Quant. NERF (Savary & Waszczuk, 2012) is a tool developed as part of the National Corpus of Polish project and is based on Linear Chain Random Fields (CRF). It detects 13 types of NEs that may be nested (e.g. Warsaw University).Liner2 (Marci\u0144czuk & Janicki, 2012) also uses CRFs, but distinguishes NEs from 56 types (which could be reduced to 5 in order to achieve higher precision).Annotation with both tools is done offline within KB pre-processing. In the phase currently described, it is sufficient to detect epics, with NEs being distinguished from 56 types (which could be reduced to 5)."}, {"heading": "2.7 Mention selection", "text": "This year, it has come to the point that it has never been as far as this year."}, {"heading": "3 Deep Entity Recognition", "text": "The Deep Entity Recognition method is an alternative to using the Named Entity Recognition in QS to find entities that meet question constraints. It scans a text and finds words and multi-word expressions that correspond to the entities. However, it does not assign these entities to one of several NE categories; instead, WordNet synsets are used. Therefore, named entities are more precisely distinguished (e.g. monarchs and athletes) and entities that go beyond the classical NE categories (e.g. species, events, devices) could also be recognized in a text. It does not seem possible to fulfill this task solely on features extracted from words and surrounding text (as in NER), therefore it is essential to build an entity library. Such libraries already exist (Freebase, BabelNet, DBpedia or YAGO) and could represent an alternative for BerepER, but they focus on other languages, in particular, the English language."}, {"heading": "3.1 Related work", "text": "In fact, most of them will be able to orient themselves in a different direction than in a different direction, namely the direction in which they are moving."}, {"heading": "3.2 Entity Library", "text": "This year, it has reached the point where it will be able to retaliate."}, {"heading": "3.3 Entity Recognition", "text": "< < an entity recognition step is performed within the answer process to the question and aims to select all > mentions of an entity in a given annotated document > 1. Before it begins, the entity library is read into a PATRICIA trie, a very efficient prefix tree. In this structure, each entity name becomes a key for storing a corresponding list of entities. When a document is ready for analysis, strings that match one of the keys in the trie are searched for. The last two techniques are necessary because nominal group termination often fails, especially in the case of proper names. Their rich propensity for entity in Polish (Przepi\u00f3rkowski, 2007) means that an entity is associated with an entity (Lemmata)."}, {"heading": "4 Evaluation", "text": "The evaluation of RAFAEL is typical of factoid QA systems: with a knowledge base and questions, the answers are compared with the expected answers that are prepared in advance. Section 4.1 describes the data used in this process, while Section 4.2 explains how an automatic evaluation without human work is possible."}, {"heading": "4.1 Data", "text": "The Polish Wikipedia serves as a knowledge base. It was downloaded from a project site as a single database dump on March 3, 2013, from which simple text files were extracted using Wikipedia Extractor 2.2 script5. It means that only simple text is taken into account - without lists, info boxes, tables, etc. This procedure results in a corpus of 895,486 documents containing 168,982,550 segments undergoing the annotation process, described in Section 2.3.The questions to be answered with the knowledge base come from two separate groups: 5 http: / / medialab.di.unipi.it / wiki / Wikipedia _ Extractor1. The development bases are based on 1500 (1130 after filtering 6) questions from a Polish quiz TV show called Jeden z dziesi\u0119ciu (Karzewski, 1997). It was included in previous experiments (Przybyby\u0142a, 2013b, a)."}, {"heading": "4.2 Automatic Evaluation", "text": "Thanks to the availability of the DeepER Faculty Library, it is possible to perform an automatic evaluation of the answers for all types of questions recognized by this technique (UNNAMED _ ENTITY and NAMED _ ENTITY without data, numbers and quantities). Both an expected and received answer are presented as short strings, e.g. Bronis\u0142aw Komorowski. However, it is not enough to check their exact similarity, caused by the presence of different names for an entity (Bronis\u0142aw Maria Komorowski or Komorowski), but also by rich nominal inflection (Komorowskiego, Komorowskiemu,...).In fact, we want to compare entities, not names. Therefore, deep recognition of entities here is a natural solution. To check the correctness of an answer, we use it as an input for the recognition process described in Section 3.3. Then it is sufficient to check whether the expected answer appears in any list of Komorowski."}, {"heading": "5 Results", "text": "As mentioned in the previous section, the results consist of two groups: experiments that show an influence of some aspects of the algorithm on performance, and a final assessment. Both use the Polish Wikipedia as a knowledge base, while the questions asked belong to development or assessment groups. In this section, Recall measures the percentage of questions to which RAFAEL has given an answer, while precision indicates the percentage of correctly answered questions. In analyzing the results of various unit recognition techniques, we must remember that they depend heavily on the performance of the question analysis, which is not perfect. In particular, tests show that 15.65 percent of the questions are assigned to an incorrect type, and 17.81 percent of the search results do not contain the expected document (Przyby\u0142a, 2013a). The level of unit recognition, a focal point of this work, is very unlikely to provide valid answers in these cases. However, since the expected question type and the source document in the question metadata are available, it is possible to type the ER by replacing the expected paragraph of the expected one, as the ER."}, {"heading": "5.1 Experiments", "text": "The goal of the first experiment is to test how number a of documents retrieved from the search engine and analyzed by the entity detection techniques affects performance. Question classification errors were circumvented, as described in the previous paragraph. In addition, two versions were evaluated: with and without corrections of a retrieved set of documents. This is because additional irrelevant documents usually introduce noise. However, they are useful because the increasing reminder suggests that if we have no guarantee of the presence of the expected document in a list, it retrieves easily while the precision decreases. That's because additional irrelevant documents usually introduce noise, as the increasing reminder shows."}, {"heading": "5.2 Final System Evaluation", "text": "In order to present a realistic challenge to the system, the assessment set used at that time differs significantly from that used during development (see Section 4.1). Based on the results of the experiments, a configuration for the final assessment has been worked out. All tested versions have the following features: - no corrections to the question analysis, 7 Expressed as a multiplication of the question content size. - Question classification and query generation solutions that have proven best in the previous experiments (see Section 2.4), - a retrieved set of documents containing 20 articles, - no minimal reliability, - single sentence context with title. Tested solutions differ only in terms of entity detection; RAFEL variants based on the following options are taken into account: Table 3 shows the results of the final assessment expressed as reminder, precision, F1 measurement and Mean Reciprocal Rank (MRR) 8. Standard deviations in this test set were achieved by repeating the test set."}, {"heading": "6 Discussion", "text": "This year, it is only a matter of time before there is a result in which there is a result."}, {"heading": "7 Conclusions", "text": "This paper introduces RAFAEL, a complete cross-domain question-answering system for Polish. It is able to analyze a given question, scan a large corpus, and extract an answer that is presented as a short text sequence. In its conception, emphasis was placed on techniques for detecting entities that are used to extract all entities compatible with a question from a given text. In addition to the traditional detection of named entities, which distinguishes between several broad categories of NEs, a new technique called Deep Entity Recognition (DeepER) has been proposed and implemented. It is able to find entities belonging to a particular WordNet synset, using an entity library compiled by interpreting definitions from the encyclopedia. The automatic evaluation provided by the DeepER approach has allowed to perform several final experiments, with several parameters being verified in order to accurately answer the final questions."}, {"heading": "Appendix A: Named Entity Recognition in RAFAEL", "text": "As mentioned in Section 2.6, in addition to DeepER, RAFAEL also uses traditional NERF-based solutions for the detection of units: NERF, Liner2, and Quant. Each of them uses its own typology of designated units, which covers only a portion of the types listed in Section 2.4. Table 5 shows an agreement between these types. As we can see, there are a few problems: 1. Many NERF types are not detected by either NERF or Liner2, 2. For all geographic types, NERF only has one type geogName, which can affect the precision of QA, 3. In the case of CENTURY and YEAR, NERF only recognizes a more general type expression from which it can be deduced, 4. Liner2 does not distinguish between NAME and SURNAME, which can affect the precision of QA."}, {"heading": "Acknowledgments", "text": "The study was supported by a research grant under the agreement POKL.04.01.01-00-051 / 10-00 \"Information Technologies: Research and its Interdisciplinary Applications.\" Critical reading of the manuscript by Agnieszka Mykowiecka and Aleksandra Brzezi\u0144ska is appreciated."}], "references": [{"title": "A morphosyntactic Brill Tagger for inflectional languages", "author": ["S. Aceda\u0144ski"], "venue": "In Proceedings of the 7th international conference on Advances in Natural Language Processing", "citeRegEx": "Aceda\u0144ski,? \\Q2010\\E", "shortCiteRegEx": "Aceda\u0144ski", "year": 2010}, {"title": "Using Wikipedia at the TREC QA Track", "author": ["D. Ahn", "V. Jijkoun", "G. Mishne", "K. M\u00fcller", "M. De Rijke", "S. Schlobach"], "venue": "Proceedings of The Thirteenth Text REtrieval Conference (TREC", "citeRegEx": "Ahn et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Ahn et al\\.", "year": 2004}, {"title": "Information Retrieval Using a Macedonian Test Collection for Question Answering", "author": ["J. Armenska", "A. Tomovski", "K. Zdravkova", "J. Pehcevski"], "venue": "In Proceedings of the 2nd International Conference ICT Innovations,", "citeRegEx": "Armenska et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Armenska et al\\.", "year": 2010}, {"title": "Named entity recognition in Wikipedia", "author": ["D. Balasuriya", "N. Ringland", "J. Nothman", "T. Murphy", "J.R. Curran"], "venue": "In Proceedings of the 2009 Workshop on The People\u2019s Web Meets NLP: Collaboratively Constructed Semantic Resources,", "citeRegEx": "Balasuriya et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Balasuriya et al\\.", "year": 2009}, {"title": "An analysis of the AskMSR question-answering system. In Proceedings of the ACL-02 conference on Empirical methods in natural language processing", "author": ["E. Brill", "S. Dumais", "M. Banko"], "venue": "EMNLP \u201902,", "citeRegEx": "Brill et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Brill et al\\.", "year": 2002}, {"title": "Broad-coverage sense disambiguation and information extraction with a supersense sequence tagger", "author": ["M. Ciaramita", "Y. Altun"], "venue": "In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing - EMNLP \u201906,", "citeRegEx": "Ciaramita and Altun,? \\Q2006\\E", "shortCiteRegEx": "Ciaramita and Altun", "year": 2006}, {"title": "Augmenting Wikipedia with Named Entity Tags", "author": ["W. Dakka", "S. Cucerzan"], "venue": "In Proceedings of the Third International Joint Conference on Natural Language Processing (IJCNLP", "citeRegEx": "Dakka and Cucerzan,? \\Q2008\\E", "shortCiteRegEx": "Dakka and Cucerzan", "year": 2008}, {"title": "Overview of the TREC 2007 Question Answering track", "author": ["H.T. Dang", "D. Kelly", "J. Lin"], "venue": "In Proceedings of The Sixteenth Text REtrieval Conference,", "citeRegEx": "Dang et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Dang et al\\.", "year": 2007}, {"title": "Towards the Lemmatisation of Polish Nominal Syntactic Groups Using a Shallow Grammar", "author": ["L. Deg\u00f3rski"], "venue": "Proceedings of the International Joint Conference on Security and Intelligent Information Systems,", "citeRegEx": "Deg\u00f3rski,? \\Q2012\\E", "shortCiteRegEx": "Deg\u00f3rski", "year": 2012}, {"title": "A Polish Question-Answering System for Business Information", "author": ["F. Duclaye", "J. Sitko", "P. Filoche", "O. Collin"], "venue": "In BIS 2002, 5th International Conference on Business Information Systems, Poznan\u0301,", "citeRegEx": "Duclaye et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Duclaye et al\\.", "year": 2002}, {"title": "Building Watson: An Overview of the DeepQA Project", "author": ["D.A. Ferrucci", "E. Brown", "J. Chu-carroll", "J. Fan", "D. Gondek", "A.A. Kalyanpur", "A. Lally", "J.W. Murdock", "E. Nyberg", "J. Prager", "N. Schlaefer", "C. Welty"], "venue": "AI Magazine,", "citeRegEx": "Ferrucci et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Ferrucci et al\\.", "year": 2010}, {"title": "Lemmatizer for Document Information Retrieval Systems in JAVA", "author": ["L. Galambos"], "venue": "In Proceedings of the 28th Conference on Current Trends in Theory and Practice of Informatics (SOFSEM", "citeRegEx": "Galambos,? \\Q2001\\E", "shortCiteRegEx": "Galambos", "year": 2001}, {"title": "The role of lexico-semantic feedback in open-domain textual question-answering", "author": ["S. Harabagiu", "D. Moldovan", "M. Pasca", "R. Mihalcea", "M. Surdeanu", "R. Bunescu", "R. G\u00eerju", "V. Rus", "P. Morarescu"], "venue": "In Proceedings of the 39th Annual Meeting on Association for Computational Linguistics - ACL \u201901,", "citeRegEx": "Harabagiu et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Harabagiu et al\\.", "year": 2001}, {"title": "Question Answering in Webclopedia", "author": ["E. Hovy", "L. Gerber", "U. Hermjakob", "M. Junk", "Lin", "C.-Y"], "venue": "In Proceedings of The Ninth Text REtrieval Conference (TREC", "citeRegEx": "Hovy et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Hovy et al\\.", "year": 2000}, {"title": "\u00c9tude comparative de la distribution florale dans une portion des Alpes et des Jura", "author": ["P. Jaccard"], "venue": "Bulletin del la Socie\u0301te\u0301 Vaudoise des Sciences Naturelles,", "citeRegEx": "Jaccard,? \\Q1901\\E", "shortCiteRegEx": "Jaccard", "year": 1901}, {"title": "Jeden z dziesi\u0119ciu - pytania i odpowiedzi", "author": ["M. Karzewski"], "venue": "Muza SA", "citeRegEx": "Karzewski,? \\Q1997\\E", "shortCiteRegEx": "Karzewski", "year": 1997}, {"title": "Integrating Web-based and corpus-based techniques for question answering", "author": ["B. Katz", "J. Lin", "D. Loreto", "W. Hildebrandt", "M. Bilotti", "S. Felshin", "A. Fernandes", "G. Marton", "F. Mora"], "venue": "In Proceedings of the Twelfth Text REtrieval Conference (TREC", "citeRegEx": "Katz et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Katz et al\\.", "year": 2003}, {"title": "Exploiting Wikipedia as External Knowledge for Named Entity Recognition", "author": ["J. Kazama", "K. Torisawa"], "venue": "Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning", "citeRegEx": "Kazama and Torisawa,? \\Q2007\\E", "shortCiteRegEx": "Kazama and Torisawa", "year": 2007}, {"title": "Question Answering for Not Yet Semantic Web", "author": ["M. Konop\u00edk", "O. Rohl\u00edk"], "venue": "In Proceedings of the 13th International Conference on Text, Speech and Dialogue (TSD", "citeRegEx": "Konop\u00edk and Rohl\u00edk,? \\Q2010\\E", "shortCiteRegEx": "Konop\u00edk and Rohl\u00edk", "year": 2010}, {"title": "Creating a Coreference Resolution System for Polish", "author": ["M. Kope\u0107", "M. Ogrodniczuk"], "venue": null, "citeRegEx": "Kope\u0107 and Ogrodniczuk,? \\Q2012\\E", "shortCiteRegEx": "Kope\u0107 and Ogrodniczuk", "year": 2012}, {"title": "Extracting Template for Knowledgebased Question-Answering Using Conditional Random Fields", "author": ["C. Lee", "Wang", "J.-H", "Kim", "H.-J", "Jang", "M.-G"], "venue": "In Proceedings of the 28th Annual International ACM SIGIR Workshop on MFIR, (pp. 428\u2013434)", "citeRegEx": "Lee et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Lee et al\\.", "year": 2005}, {"title": "Learning Question Classifiers", "author": ["X. Li", "D. Roth"], "venue": "In Proceedings of the 19th International Conference on Computational Linguistics (COLING-2002),", "citeRegEx": "Li and Roth,? \\Q2002\\E", "shortCiteRegEx": "Li and Roth", "year": 2002}, {"title": "Question Classification for a Croatian QA System", "author": ["T. Lombarovi\u0107", "J. \u0160najder", "B.D. Ba\u0161i\u0107"], "venue": "In Proceedings of the 14th International Conference on Text, Speech and Dialogue (TSD", "citeRegEx": "Lombarovi\u0107 et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Lombarovi\u0107 et al\\.", "year": 2011}, {"title": "Fine-grained proper noun ontologies for question answering", "author": ["G.S. Mann"], "venue": "In Proceedings of the 2002 workshop on Building and using semantic networks (SEMANET \u201902),", "citeRegEx": "Mann,? \\Q2002\\E", "shortCiteRegEx": "Mann", "year": 2002}, {"title": "Optimizing CRF-based Model for Proper Name Recognition in Polish Texts", "author": ["M. Marci\u0144czuk", "M. Janicki"], "venue": "In Proceedings of CICLing", "citeRegEx": "Marci\u0144czuk and Janicki,? \\Q2012\\E", "shortCiteRegEx": "Marci\u0144czuk and Janicki", "year": 2012}, {"title": "Open dataset for development of Polish Question Answering systems. In Proceedings of the 6th Language & Technology Conference: Human Language Technologies as a Challenge for Computer Science and Linguistics", "author": ["M. Marci\u0144czuk", "M. Ptak", "A. Radziszewski", "M. Piasecki"], "venue": "Wydawnictwo Poznan\u0301skie, Fundacja Uniwersytetu im. Adama Mickiewicza", "citeRegEx": "Marci\u0144czuk et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Marci\u0144czuk et al\\.", "year": 2013}, {"title": "Evaluation of a Baseline Information Retrieval for a Polish Open-domain Question Answering System", "author": ["M. Marci\u0144czuk", "A. Radziszewski", "M. Piasecki", "D. Piasecki", "M. Ptak"], "venue": "In Proceedings of the International Conference Recent Advances in Natural Language Processing (RANLP", "citeRegEx": "Marci\u0144czuk et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Marci\u0144czuk et al\\.", "year": 2013}, {"title": "Approaching plWordNet 2.0", "author": ["M. Maziarz", "M. Piasecki", "S. Szpakowicz"], "venue": "In Proceedings of the 6th Global Wordnet Conference", "citeRegEx": "Maziarz et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Maziarz et al\\.", "year": 2012}, {"title": "The structure and performance of an open-domain question answering system", "author": ["D. Moldovan", "S. Harabagiu", "M. Pa\u015fca", "R. Mihalcea", "R. G\u00eerju", "R. Goodrum", "V. Rus"], "venue": null, "citeRegEx": "Moldovan et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Moldovan et al\\.", "year": 2000}, {"title": "Lexical chains for question answering", "author": ["D. Moldovan", "A. Novischi"], "venue": "In Proceedings of the 19th International Conference on Computational Linguistics", "citeRegEx": "Moldovan and Novischi,? \\Q2002\\E", "shortCiteRegEx": "Moldovan and Novischi", "year": 2002}, {"title": "WhyQuestion Answering using Intra- and Inter-Sentential Causal Relations", "author": ["Oh", "J.-h", "K. Torisawa", "C. Hashimoto", "M. Sano", "S.D. Saeger", "K. Ohtake"], "venue": "In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Oh et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Oh et al\\.", "year": 2013}, {"title": "Bulgarian-english question answering: adaptation of language resources", "author": ["P. Osenova", "A. Simov", "K. Simov", "H. Tanev", "M. Kouylekov"], "venue": "Science, (pp. 458\u2013469)", "citeRegEx": "Osenova et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Osenova et al\\.", "year": 2004}, {"title": "Semantic Retrieval Approach to Factoid Question Answering for Bulgarian", "author": ["S. Peshterliev", "I. Koychev"], "venue": "In Proceedings of the 3rd International Conference on Software, Services and Semantic Technologies", "citeRegEx": "Peshterliev and Koychev,? \\Q2011\\E", "shortCiteRegEx": "Peshterliev and Koychev", "year": 2011}, {"title": "Question answering in Polish using shallow parsing", "author": ["D. Piechoci\u0144ski", "A. Mykowiecka"], "venue": "Computer Treatment of Slavic and East European Languages: Proceedings of the Third International Seminar,", "citeRegEx": "Piechoci\u0144ski and Mykowiecka,? \\Q2005\\E", "shortCiteRegEx": "Piechoci\u0144ski and Mykowiecka", "year": 2005}, {"title": "Deriving a Large Scale Taxonomy from Wikipedia", "author": ["S.P. Ponzetto", "M. Strube"], "venue": "Artificial Intelligence,", "citeRegEx": "Ponzetto and Strube,? \\Q2007\\E", "shortCiteRegEx": "Ponzetto and Strube", "year": 2007}, {"title": "Slavonic information extraction and partial parsing. In Proceedings of the Workshop on Balto-Slavonic Natural Language Processing Information Extraction and Enabling Technologies - ACL \u201907", "author": ["A. Przepi\u00f3rkowski"], "venue": null, "citeRegEx": "Przepi\u00f3rkowski,? \\Q2007\\E", "shortCiteRegEx": "Przepi\u00f3rkowski", "year": 2007}, {"title": "Powierzchniowe przetwarzanie j\u0119zyka polskiego", "author": ["A. Przepi\u00f3rkowski"], "venue": "Warszawa: Akademicka Oficyna Wydawnicza EXIT", "citeRegEx": "Przepi\u00f3rkowski,? \\Q2008\\E", "shortCiteRegEx": "Przepi\u00f3rkowski", "year": 2008}, {"title": "Narodowy Korpus J\u0119zyka Polskiego. Warszawa: Wydawnictwo Naukowe PWN", "author": ["A. Przepi\u00f3rkowski", "M. Ba\u0144ko", "R.L. G\u00f3rski", "B. Lewandowska-Tomaszczyk"], "venue": null, "citeRegEx": "Przepi\u00f3rkowski et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Przepi\u00f3rkowski et al\\.", "year": 2012}, {"title": "Issues of Polish Question Answering", "author": ["P. Przyby\u0142a"], "venue": "(ITRIA", "citeRegEx": "Przyby\u0142a,? \\Q2012\\E", "shortCiteRegEx": "Przyby\u0142a", "year": 2012}, {"title": "Question Analysis for Polish Question Answering", "author": ["P. Przyby\u0142a"], "venue": "Proceedings of the Student Research Workshop,", "citeRegEx": "Przyby\u0142a,? \\Q2013\\E", "shortCiteRegEx": "Przyby\u0142a", "year": 2013}, {"title": "Question Classification for Polish Question Answering", "author": ["P. Przyby\u0142a"], "venue": "Proceedings of the 20th International Conference on Language Processing and Intelligent Information Systems (LP&IIS", "citeRegEx": "Przyby\u0142a,? \\Q2013\\E", "shortCiteRegEx": "Przyby\u0142a", "year": 2013}, {"title": "Mining Wiki Resources for Multilingual Named Entity Recognition", "author": ["A.E. Richman", "P. Schone"], "venue": "In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics (ACL", "citeRegEx": "Richman and Schone,? \\Q2008\\E", "shortCiteRegEx": "Richman and Schone", "year": 2008}, {"title": "Automatic Assignment of Wikipedia Encyclopedic Entries to WordNet Synsets", "author": ["M. Ruiz-Casado", "E. Alfonseca", "P. Castells"], "venue": "Advances in Web Intelligence,", "citeRegEx": "Ruiz.Casado et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Ruiz.Casado et al\\.", "year": 2005}, {"title": "Populating a multilingual ontology of proper names from open sources", "author": ["A. Savary", "L. Manicki", "M. Baron"], "venue": "Journal of Language Modelling,", "citeRegEx": "Savary et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Savary et al\\.", "year": 2013}, {"title": "Narz\u0119dzia do anotacji jednostek nazewniczych", "author": ["A. Savary", "J. Waszczuk"], "venue": "In Narodowy Korpus Je\u0328zyka Polskiego [Eng.: National Corpus of Polish] (pp. 225\u2013252). Wydawnictwo Naukowe PWN", "citeRegEx": "Savary and Waszczuk,? \\Q2012\\E", "shortCiteRegEx": "Savary and Waszczuk", "year": 2012}, {"title": "Encyclopedia of Artificial Intelligence", "author": ["S.C. Shapiro"], "venue": null, "citeRegEx": "Shapiro,? \\Q1992\\E", "shortCiteRegEx": "Shapiro", "year": 1992}, {"title": "BulQA: Bulgarian\u2013bulgarian question answering at CLEF", "author": ["K. Simov", "P. Osenova"], "venue": "Proceedings of the 6th international conference on Cross-Language Evalution Forum: accessing Multilingual Information Repositories (CLEF\u201905),", "citeRegEx": "Simov and Osenova,? \\Q2005\\E", "shortCiteRegEx": "Simov and Osenova", "year": 2005}, {"title": "Dependency-Based Algorithms for Answer Validation Task in Russian Question Answering", "author": ["A. Solovyev"], "venue": "In Proceedings of the 25th International Conference on Language Processing and Knowledge in the Web (GSCL", "citeRegEx": "Solovyev,? \\Q2013\\E", "shortCiteRegEx": "Solovyev", "year": 2013}, {"title": "Socrates - a Question Answering prototype for Bulgarian", "author": ["H. Tanev"], "venue": null, "citeRegEx": "Tanev,? \\Q2004\\E", "shortCiteRegEx": "Tanev", "year": 2004}, {"title": "A proposal to automatically build and maintain gazetteers for Named Entity Recognition by using Wikipedia", "author": ["A. Toral", "R. Mu\u00f1oz"], "venue": "In Proceedings of the 11th Conference of the European Chapter of the Association", "citeRegEx": "Toral and Mu\u00f1oz,? \\Q2006\\E", "shortCiteRegEx": "Toral and Mu\u00f1oz", "year": 2006}, {"title": "Named Entity WordNet", "author": ["A. Toral", "R. Mu\u00f1oz", "M. Monachini"], "venue": "In Proceedings of the International Conference on Language Resources and Evaluation,", "citeRegEx": "Toral et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Toral et al\\.", "year": 2008}, {"title": "Developing a question answering system for the slovene language", "author": ["I. \u010ceh", "M. Ojster\u0161ek"], "venue": "WSEAS Transactions on Information Science and Applications,", "citeRegEx": "\u010ceh and Ojster\u0161ek,? \\Q2009\\E", "shortCiteRegEx": "\u010ceh and Ojster\u0161ek", "year": 2009}, {"title": "PROLOG Implementation of an Access in Polish to a Data Base. In Studia z automatyki, XII (pp. 5\u201323)", "author": ["Z. Vetulani"], "venue": null, "citeRegEx": "Vetulani,? \\Q1988\\E", "shortCiteRegEx": "Vetulani", "year": 1988}, {"title": "How to answer yes/no spatial questions using qualitative reasoning", "author": ["M. Walas"], "venue": "13th International Conference on Computational Linguistics and Intelligent Text Processing,", "citeRegEx": "Walas,? \\Q2012\\E", "shortCiteRegEx": "Walas", "year": 2012}, {"title": "Named entity recognition in a Polish question answering system", "author": ["M. Walas", "K. Jassem"], "venue": "In Intelligent Information Systems, (pp. 181\u2013191)", "citeRegEx": "Walas and Jassem,? \\Q2010\\E", "shortCiteRegEx": "Walas and Jassem", "year": 2010}, {"title": "Spatial reasoning and disambiguation in the process of knowledge acquisition. In Proceedings of the 5th Language & Technology Conference: Human Language Technologies as a Challenge for Computer Science and Linguistics, (pp. 420\u2013424)", "author": ["M. Walas", "K. Jassem"], "venue": "Fundacja Uniwersytetu im. Adama Mickiewicza", "citeRegEx": "Walas and Jassem,? \\Q2011\\E", "shortCiteRegEx": "Walas and Jassem", "year": 2011}, {"title": "Morfeusz \u2014 a Practical Tool for the Morphological Analysis of Polish", "author": ["M. Woli\u0144ski"], "venue": "Intelligent Information Processing and Web Mining (pp. 511\u2013520)", "citeRegEx": "Woli\u0144ski,? \\Q2006\\E", "shortCiteRegEx": "Woli\u0144ski", "year": 2006}, {"title": "Question Answering Using Enhanced Lexical Semantic Models", "author": ["Yih", "W.-t", "Chang", "M.-w", "C. Meek", "A. Pastusiak"], "venue": "In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Yih et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Yih et al\\.", "year": 2013}], "referenceMentions": [{"referenceID": 7, "context": "It has resulted in valuable contributions within TREC competitions (Dang et al., 2007) and, quite recently, in a system called IBM Watson (Ferrucci et al.", "startOffset": 67, "endOffset": 86}, {"referenceID": 10, "context": ", 2007) and, quite recently, in a system called IBM Watson (Ferrucci et al., 2010), successfully competing with humans in the task.", "startOffset": 59, "endOffset": 82}, {"referenceID": 43, "context": "So broadly defined task seems very hard; Shapiro (1992) describes it as AI-Complete, i.", "startOffset": 41, "endOffset": 56}, {"referenceID": 35, "context": "3) is far from trivial because of a complicated named entity inflection in Polish (typical for Slavonic languages, see (Przepi\u00f3rkowski, 2007)).", "startOffset": 119, "endOffset": 141}, {"referenceID": 38, "context": "More information about the task, including its motivation, difficulties and a feasibility study for Polish could be found in (Przyby\u0142a, 2012).", "startOffset": 125, "endOffset": 141}, {"referenceID": 51, "context": "First Polish QA attempts date back to 1985, when Vetulani (1988) presented a Polish interface to ORBIS database, containing information about the solar system.", "startOffset": 49, "endOffset": 65}, {"referenceID": 9, "context": "Another early solution, presented by Duclaye et al. (2002), could only work in a restricted domain (business information).", "startOffset": 37, "endOffset": 59}, {"referenceID": 31, "context": "Previously the same team (Osenova et al., 2004) took part in a Bulgarian-English track of the CLEF 2004, in which Bulgarian questions were answered using English texts.", "startOffset": 25, "endOffset": 47}, {"referenceID": 47, "context": "A system dealing with a subset of the TREC tasks was created for Bulgarian by Tanev (2004). His solution answers only three types of questions: Definition, Where-Is and Temporal.", "startOffset": 78, "endOffset": 91}, {"referenceID": 53, "context": "In their later works (Walas, 2012; Walas & Jassem, 2011), the team concentrated on spatial reasoning using a knowledge base encoded as a set of predicates.", "startOffset": 21, "endOffset": 56}, {"referenceID": 53, "context": "More recently, several elements of a Polish QA system called Hipisek were presented by Walas & Jassem (2010). It bases on a fairly common scheme of transforming a question into a search query and finding the most appropriate sentence, satisfying question constrains.", "startOffset": 87, "endOffset": 109}, {"referenceID": 25, "context": "The last Polish system worth mentioning has been created by Marci\u0144czuk et al. (2013). Generally, their task, called Open Domain Question Answering (ODQA), resembles what is treated here, but with one major difference.", "startOffset": 60, "endOffset": 85}, {"referenceID": 2, "context": "document retrieval for Macedonian (Armenska et al., 2010), question classification for Croatian (Lombarovi\u0107 et al.", "startOffset": 34, "endOffset": 57}, {"referenceID": 22, "context": ", 2010), question classification for Croatian (Lombarovi\u0107 et al., 2011) or answer validation for Russian (Solovyev, 2013).", "startOffset": 46, "endOffset": 71}, {"referenceID": 47, "context": ", 2011) or answer validation for Russian (Solovyev, 2013).", "startOffset": 41, "endOffset": 57}, {"referenceID": 13, "context": "A general architectural scheme of RAFAEL (figure 1) has been inspired by similar systems developed for English; for examples see works by Hovy et al. (2000) and Moldovan et al.", "startOffset": 138, "endOffset": 157}, {"referenceID": 13, "context": "A general architectural scheme of RAFAEL (figure 1) has been inspired by similar systems developed for English; for examples see works by Hovy et al. (2000) and Moldovan et al. (2000).", "startOffset": 138, "endOffset": 184}, {"referenceID": 11, "context": "62 is used to build two separate full-text indices: regular and stemmed using a built-in stemmer for Polish, Stempel (Galambos, 2001).", "startOffset": 117, "endOffset": 133}, {"referenceID": 56, "context": "82 (Woli\u0144ski, 2006),", "startOffset": 3, "endOffset": 19}, {"referenceID": 0, "context": "1 (Aceda\u0144ski, 2010),", "startOffset": 2, "endOffset": 19}, {"referenceID": 36, "context": "7 (Przepi\u00f3rkowski, 2008) with a Polish grammar, including improved version of modifications by Deg\u00f3rski (2012), enabling lemmatisation of nominal syntactic groups,", "startOffset": 2, "endOffset": 24}, {"referenceID": 8, "context": "7 (Przepi\u00f3rkowski, 2008) with a Polish grammar, including improved version of modifications by Deg\u00f3rski (2012), enabling lemmatisation of nominal syntactic groups,", "startOffset": 95, "endOffset": 111}, {"referenceID": 37, "context": "All the annotations are stored in a variant of TEI P5 standard, designed for the National Corpus of Polish (Przepi\u00f3rkowski et al., 2012).", "startOffset": 107, "endOffset": 136}, {"referenceID": 13, "context": "As noted previously, the process of annotating is not indispensable at the stage of offline KB processing; it could be as well executed only on documents returned from the search engine (for example see Webclopedia by Hovy et al. (2000) or LASSO by Moldovan et al.", "startOffset": 218, "endOffset": 237}, {"referenceID": 13, "context": "As noted previously, the process of annotating is not indispensable at the stage of offline KB processing; it could be as well executed only on documents returned from the search engine (for example see Webclopedia by Hovy et al. (2000) or LASSO by Moldovan et al. (2000)).", "startOffset": 218, "endOffset": 272}, {"referenceID": 20, "context": "Nevertheless, some (Lee et al., 2005) use solely such patterns, but need a great number of them (1,273).", "startOffset": 19, "endOffset": 37}, {"referenceID": 27, "context": "1 (Maziarz et al., 2012).", "startOffset": 2, "endOffset": 24}, {"referenceID": 12, "context": "A WordNet-assisted focus analysis was also implemented in one of solutions participating in a TREC competition (Harabagiu et al., 2001).", "startOffset": 111, "endOffset": 135}, {"referenceID": 4, "context": "Hence, a query created directly from words of the question would not yield results, unless using a highly-redundant KB, such as the WWW (for this type of solution see (Brill et al., 2002)).", "startOffset": 167, "endOffset": 187}, {"referenceID": 16, "context": "Therefore, some of the query terms should be dropped \u2013 based on their low IDF (Katz et al., 2003) or more complex heuristics (Moldovan et al.", "startOffset": 78, "endOffset": 97}, {"referenceID": 28, "context": ", 2003) or more complex heuristics (Moldovan et al., 2000).", "startOffset": 35, "endOffset": 58}, {"referenceID": 13, "context": "On the other hand, the query may be expanded with synonyms (Hovy et al., 2000) or derived morphological forms (Katz et al.", "startOffset": 59, "endOffset": 78}, {"referenceID": 16, "context": ", 2000) or derived morphological forms (Katz et al., 2003).", "startOffset": 39, "endOffset": 58}, {"referenceID": 56, "context": "The method of treating sentences as a context has gained most popularity (see work of Yih et al. (2013)), but a window of fixed size also appears in the literature; for example Katz et al.", "startOffset": 86, "endOffset": 104}, {"referenceID": 16, "context": "(2013)), but a window of fixed size also appears in the literature; for example Katz et al. (2003) used one with M=140 bytes.", "startOffset": 80, "endOffset": 99}, {"referenceID": 14, "context": "4) and an entity context (generated by the procedures in previous section), a Jaccard similarity index (Jaccard, 1901) is computed.", "startOffset": 103, "endOffset": 118}, {"referenceID": 57, "context": "A study of different techniques for sentence similarity assessment could be found in (Yih et al., 2013).", "startOffset": 85, "endOffset": 103}, {"referenceID": 1, "context": "The Jaccard index is a popular solution for sentence similarity measurement in QA (for example see a system by Ahn et al. (2004)).", "startOffset": 111, "endOffset": 129}, {"referenceID": 1, "context": "The Jaccard index is a popular solution for sentence similarity measurement in QA (for example see a system by Ahn et al. (2004)). In case of selecting relevant documents, cosine measure is also applied. Marci\u0144czuk et al. (2013) compared it to Minimal Span Weighting (MSW) and observed that the latter performs better, as it takes into account a distance between matched words.", "startOffset": 111, "endOffset": 229}, {"referenceID": 10, "context": "The refusal to answer in case of insufficient confidence plays an important role in Jeopardy!, hence in IBM Watson (Ferrucci et al., 2010), but it was also used to improve precision in other QA systems (Oh et al.", "startOffset": 115, "endOffset": 138}, {"referenceID": 30, "context": ", 2010), but it was also used to improve precision in other QA systems (Oh et al., 2013).", "startOffset": 71, "endOffset": 88}, {"referenceID": 35, "context": "The task of adaptation of such a base to another language is far from trivial, especially for Slavonic languages with complex NE inflection (Przepi\u00f3rkowski, 2007).", "startOffset": 140, "endOffset": 162}, {"referenceID": 35, "context": "The task of adaptation of such a base to another language is far from trivial, especially for Slavonic languages with complex NE inflection (Przepi\u00f3rkowski, 2007). An ontology taking into account Polish inflection (Prolexbase) has been created by Savary et al. (2013), but it contains only 40,000 names, grouped into 34 types.", "startOffset": 141, "endOffset": 268}, {"referenceID": 23, "context": "A technique of coordinating synsets assigned to a question and a possible answer emerged in a study by Mann (2002). While a question analysis there seems very similar to this work, entity library (called proper noun ontology) generation differs a lot.", "startOffset": 103, "endOffset": 115}, {"referenceID": 23, "context": "A technique of coordinating synsets assigned to a question and a possible answer emerged in a study by Mann (2002). While a question analysis there seems very similar to this work, entity library (called proper noun ontology) generation differs a lot. The author analysed 1 GB of newswire text and extracted certain expressions, e.g. \"X, such as Y\" implies that Y is an instance of X. Albeit precision of resulting base was not very good (47 per cent for non-people proper names), it led to a substantial improvement of QA performance. The idea of analysing encyclopaedic definitions to obtain this type of information already appeared, but was employed for different applications. For example, Toral & Mu\u00f1oz (2006) described a method of building a gazetteer by analysing hyperonymy branches of nouns of first sentences in Wikipedia definitions.", "startOffset": 103, "endOffset": 716}, {"referenceID": 23, "context": "A technique of coordinating synsets assigned to a question and a possible answer emerged in a study by Mann (2002). While a question analysis there seems very similar to this work, entity library (called proper noun ontology) generation differs a lot. The author analysed 1 GB of newswire text and extracted certain expressions, e.g. \"X, such as Y\" implies that Y is an instance of X. Albeit precision of resulting base was not very good (47 per cent for non-people proper names), it led to a substantial improvement of QA performance. The idea of analysing encyclopaedic definitions to obtain this type of information already appeared, but was employed for different applications. For example, Toral & Mu\u00f1oz (2006) described a method of building a gazetteer by analysing hyperonymy branches of nouns of first sentences in Wikipedia definitions. Unlike in this work, an original synset was replaced by a coarse-grained NER category. Another example of application is a NE recognizer (Kazama & Torisawa, 2007) using words from a definition as additional features for a standard CRF classifier. In their definition analysis only the last word of the first nominal group was used. Other researchers dealt with a task explicitly defined as classifying Wikipedia entries to NER categories. For example Dakka & Cucerzan (2008) addressed the problem by combining traditional text classification techniques (bag of words) with contexts of entity mentions.", "startOffset": 103, "endOffset": 1321}, {"referenceID": 42, "context": "Exploring a correspondence between Wikipedia entries and WordNet synsets found an application in automatic enriching ontologies with encyclopaedic descriptions (Ruiz-Casado et al., 2005).", "startOffset": 160, "endOffset": 186}, {"referenceID": 50, "context": "which of the meanings of Jupiter corresponds to which Wikipedia article? Others (Toral et al., 2008) concentrated on the opposite, i.", "startOffset": 80, "endOffset": 100}, {"referenceID": 3, "context": "A thorough study of this problem, presented by Balasuriya et al. (2009), utilizes features extracted from article content (bag of words), categories, keywords, inter-article and inter-language links.", "startOffset": 47, "endOffset": 72}, {"referenceID": 3, "context": "A thorough study of this problem, presented by Balasuriya et al. (2009), utilizes features extracted from article content (bag of words), categories, keywords, inter-article and inter-language links. A final annotated corpus turns out as good for NER training as a manually annotated gold standard. Finally, some researchers try to generalise NER to other categories, but keep the same machinelearning-based approach. For example, Ciaramita & Altun (2006) developed a tagger, assigning words in a text to one of 41 supersenses.", "startOffset": 47, "endOffset": 456}, {"referenceID": 42, "context": "First of all, they differ a lot from the studies that involve a definition represented with a bag of words (Dakka & Cucerzan, 2008; Ruiz-Casado et al., 2005; Balasuriya et al., 2009).", "startOffset": 107, "endOffset": 182}, {"referenceID": 3, "context": "First of all, they differ a lot from the studies that involve a definition represented with a bag of words (Dakka & Cucerzan, 2008; Ruiz-Casado et al., 2005; Balasuriya et al., 2009).", "startOffset": 107, "endOffset": 182}, {"referenceID": 3, "context": ", 2005; Balasuriya et al., 2009). Here, a certain definition structure is assumed, i.e. a series of nominal groups divided by separators. What is more, as the full stop belongs to them, the series may continue beyond a single sentence, which has improved recall in preliminary experiments. Availability of a shallow parsing layer and group lemmatisation allows to query WordNet by syntactic groups instead of single nouns, as in work of Toral & Mu\u00f1oz (2006). As word order is relatively free in Polish, a nominal group cannot be assumed to end with a noun, like Kazama & Torisawa (2007) did.", "startOffset": 8, "endOffset": 458}, {"referenceID": 3, "context": ", 2005; Balasuriya et al., 2009). Here, a certain definition structure is assumed, i.e. a series of nominal groups divided by separators. What is more, as the full stop belongs to them, the series may continue beyond a single sentence, which has improved recall in preliminary experiments. Availability of a shallow parsing layer and group lemmatisation allows to query WordNet by syntactic groups instead of single nouns, as in work of Toral & Mu\u00f1oz (2006). As word order is relatively free in Polish, a nominal group cannot be assumed to end with a noun, like Kazama & Torisawa (2007) did.", "startOffset": 8, "endOffset": 587}, {"referenceID": 35, "context": "Their rich inflection in Polish (Przepi\u00f3rkowski, 2007) means that a nominal suffix of an entity may be hard to predict.", "startOffset": 32, "endOffset": 54}, {"referenceID": 15, "context": "Development set bases on 1500 (1130 after filtering6) questions from a Polish quiz TV show, called Jeden z dziesi\u0119ciu (Karzewski, 1997).", "startOffset": 118, "endOffset": 135}, {"referenceID": 15, "context": "Development set bases on 1500 (1130 after filtering6) questions from a Polish quiz TV show, called Jeden z dziesi\u0119ciu (Karzewski, 1997). It was involved in previous experiments (Przyby\u0142a, 2013b,a). 2. Evaluation set bases on an open dataset for Polish QA systems, published by Marci\u0144czuk et al. (2013). It has been gathered from Did you know.", "startOffset": 119, "endOffset": 302}, {"referenceID": 25, "context": "(2013) and used for evaluation of a document retrieval system (Marci\u0144czuk et al., 2013).", "startOffset": 62, "endOffset": 87}, {"referenceID": 25, "context": "However, the evaluation set has been created based on questions published by Marci\u0144czuk et al. (2013) and used for evaluation of a document retrieval system (Marci\u0144czuk et al.", "startOffset": 77, "endOffset": 102}, {"referenceID": 57, "context": "There are a lot of techniques in that area, also in QA systems (see a variety of them used by Yih et al. (2013)), but their implementation in a morphologically rich language would require a thorough study.", "startOffset": 94, "endOffset": 112}], "year": 2016, "abstractText": "In this paper an open-domain factoid question answering system for Polish, RAFAEL, is presented. The system goes beyond finding an answering sentence; it also extracts a single string, corresponding to the required entity. Herein the focus is placed on different approaches to entity recognition, essential for retrieving information matching question constraints. Apart from traditional approach, including named entity recognition (NER) solutions, a novel technique, called Deep Entity Recognition (DeepER), is introduced and implemented. It allows a comprehensive search of all forms of entity references matching a given WordNet synset (e.g. an impressionist), based on a previously assembled entity library. It has been created by analysing the first sentences of encyclopaedia entries and disambiguation and redirect pages. DeepER also provides automatic evaluation, which makes possible numerous experiments, including over a thousand questions from a quiz TV show answered on the grounds of Polish Wikipedia. The final results of a manual evaluation on a separate question set show that the strength of DeepER approach lies in its ability to answer questions that demand answers beyond the traditional categories of named entities.", "creator": "LaTeX with hyperref package"}}}