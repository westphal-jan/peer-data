{"id": "1605.09088", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-May-2016", "title": "The Bayesian Linear Information Filtering Problem", "abstract": "We present a Bayesian sequential decision-making formulation of the information filtering problem, in which an algorithm presents items (news articles, scientific papers, tweets) arriving in a stream, and learns relevance from user feedback on presented items. We model user preferences using a Bayesian linear model, similar in spirit to a Bayesian linear bandit. We compute a computational upper bound on the value of the optimal policy, which allows computing an optimality gap for implementable policies. We then use this analysis as motivation in introducing a pair of new Decompose-Then-Decide (DTD) heuristic policies, DTD-Dynamic-Programming (DTD-DP) and DTD-Upper-Confidence-Bound (DTD-UCB). We compare DTD-DP and DTD-UCB against several benchmarks on real and simulated data, demonstrating significant improvement, and show that the achieved performance is close to the upper bound.", "histories": [["v1", "Mon, 30 May 2016 02:35:07 GMT  (1127kb,D)", "http://arxiv.org/abs/1605.09088v1", null], ["v2", "Sat, 22 Oct 2016 18:48:14 GMT  (1147kb,D)", "http://arxiv.org/abs/1605.09088v2", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["bangrui chen", "peter i frazier"], "accepted": false, "id": "1605.09088"}, "pdf": {"name": "1605.09088.pdf", "metadata": {"source": "META", "title": "The Bayesian Linear Information Filtering Problem", "authors": ["Bangrui Chen", "Peter Frazier"], "emails": ["BC496@CORNELL.EDU", "PF98@CORNELL.EDU"], "sections": [{"heading": "1. INTRODUCTION", "text": "In fact, most of them are able to determine for themselves what they want to do and what they want to do."}, {"heading": "2. Problem formulation", "text": "We consider the information filtering for a single user. Items arrive at the information filter system after a Poisson distribution with a rate of 0%. The nth incoming element is described by a k-dimensional feature vector Xn = (x1, n, \u00b7 \u00b7 \u00b7 \u00b7, xk, n). We assume that the system also knows the distribution of Xn. This distribution can typically be estimated from historical data. In this paper, we name the density function of the feature vector distribution as f (Xn). Let's leave the single user vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector distribution as f (Xn).Let's leave the single user vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector distribution vector vector vector vector vector vector vector distribution vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector distribution"}, {"heading": "3. Main Results", "text": "The problem described in Section 2 is a partially observable Markov decision-making process and can theoretically be solved by stochastic dynamic programming, see (Lovejoy, 1991) and (Monahan, 1982). However, the state space of this dynamic program is highly dimensioned on the belief state (k dimensions are required to represent the rear mean, and O (k2) dimensions are required for the rear covariance matrix), making its solution mathematically intractable. Instead, in this section we provide a mathematical upper limit of this problem (in Section 3.1) and develop two implementable strategies DTD-DP and DTD-UCB based on this upper limit in Section 3.2 and Section 3.3. If DTD-DP and DTD-UCB or any other implementable policy provide us with a result close to the upper limit, then we are reassured that this policy is nearly optimal."}, {"heading": "3.1. Upper bound", "text": "This upper limit is based on the idea of dividing (1) into k different \"single characteristics\" sub-problems that allow us to calculate their value efficiently. We can remember Yi n (0, 2x2i, n) when we associate politics with each characteristic that allows us to calculate its value efficiently. (0, 2x2i, n) when we associate politics with each individual characteristic. (0, 2x2i, n > 0 and in = 0 when xi, n = 0 for i = 1, 2, \u00b7 k, independently distributed across i and n. We can think of Yi n as a reward that we would have seen if Xn were equal to a unit in which we are a unit with the ith element 1 and other elements."}, {"heading": "3.2. The DTD-DP policy", "text": "The analysis in section 3.1 provides an opportunity to Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-"}, {"heading": "3.3. The DTD-UCB algorithm", "text": "In this section, we will develop a second heuristic, DTD UpperConfidence Bound (DTD-UCB) problem, which builds on the ideas underlying the DTD DP algorithm 2 The DTD DP algorithm for n = 1, 2, \u00b7 \u00b7 doDenote \u00b51.0 = Xn \u00b7 \u00b5n; Denote \u03c321.0 = XnnX T n; Calculate Q (\u00b51.0, \u03c31.0, 1, U) for U = 0, 1 given that the x trust (x | Xn) is higher; Denote E (\u00b51.0, \u03c31.0) = Q (\u00b51.0, 1, 1, 1) \u2212 Q (\u00b51.0, \u03c31.0, 0) \u2212 \u00b51.0 + c; if \u00b51.0 + \u03b1 \u00b7 E (\u00b51.0, \u03c31.0) > c thenForward the item elseDiscard the item end In DTD-DP, we will consider a single problem where we have the projection of the order \u00b5x ()."}, {"heading": "4. Numerical Experiments", "text": "In this section, we compare DTD-DP and DTD-UCB with three different benchmark algorithms and the computational upper limit of Section 3.1 using real and simulated data. Benchmark algorithms are: \u2022 Pure Exploitation: Forward the item if Xn \u00b7 \u00b5n \u2265 c.Algorithm 3 The DTD-UCB algorithm for n = 1, 2, \u00b7 \u00b7 \u00b7 doif Xn \u00b7 \u00b5n + \u03b1 \u00b7 M (Xn) \u00b7 \u221a XnXn > c thenForward the item elseDiscard the item end ifend for \u2022 Upper Confidence Bound (UCB): Forward the item if Xn \u00b7 \u00b5n + \u03b1 \u00b7 XnXTn \u2265 c. \u2022 Linear Thompson Sampling (LTS): For the ninth Item Item Xn, the item is discarded and politics becomes more unstable than politics."}, {"heading": "4.1. Yelp academic data", "text": "In this section, we compare DTD-DP and DTD-UCB with benchmarks (UCB, pure exploitation and LTS) using the Yelp academic dataset (Yelp).Our articles are companies and are described as belonging to one or more of the following six categories: restaurants, shopping, food, beauty and spas, health and medicine and nightlife. The jth business object is then represented by a 6-dimensional feature vector Xj = (x1, j, x2, j, \u00b7, x6, j) with the ith element xi, j = 1 \u2211 6i = 1 xi, j if the business object falls into the category i and xi, j = 0 otherwise.We calculate the previous distribution via the preferences of new customers using historical user ratings. For each historical user, we use linear regression to reflect the ratings of its features on the feature vectors."}, {"heading": "4.2. arXiv.org Condensed Matter Dataset", "text": "In this section, we compare DTD-DP and DTD-UCB with benchmarks based on reader data from 2014 papers submitted to the arXiv category of condensed matter. We represent each paper submitted in 2014 by a 10-dimensional vector using the latent dirichlet allocation (LDA) (Lead et al., 2003). For each user, the score is 1 when he / she clicks and otherwise the score is 0. We then calculate the user's preference vector by linear regression. Similar to Section 4.1, we randomly select the mean and sample variance of the user's preference vectors as our previous distribution parameters for each user. In our simulation, we use the real user preference vectors calculated using linear regression, as we did in Section 4.1."}, {"heading": "4.3. Simulated Data", "text": "In this section, we compare the performance of DTD-DP and DTD-UCB with three benchmark algorithms, as well as our upper limit for calculating simulated data. These simulated data are selected to provide insight into situations where UCB may perform worse and where the structure of a policy such as DTD-DP and DTD-UCB is needed to achieve near-optimal performance. We stress that it was chosen to provide insight, not to show performance on a typical real problem instance - we refer this comparison to Section 4.1 and Section 4.2. Each element is described by a 100-dimensional feature vector Xn with the following distribution: P (Xn = e1) = 100199, P (Xn = ei) = 1 199 for i = 2, \u00b7 \u00b7 \u00b7 100. Here is ex the unit vector in the xth dimension, the DD warning."}, {"heading": "5. Conclusion", "text": "We investigated the Bayesian problem of linear information filtering, providing an instance-specific calculation upper limit and a pair of new heuristic guidelines decompose-then-decide, DTD-DP and DTD-UCB. Numerical experiments show that the best of these two guidelines is typically close to the computational upper limit, exceeding several benchmarks for real and simulated data."}, {"heading": "6. Proof of Equation (2)", "text": "Lemma 1. For each of these measures we have E\u03c0 [N \u2211 n = 1 Un (Yn \u2212 c)] = \u03b3E\u03c0 [n = 1 \u03b3n \u2212 1Un (Yn \u2212 c)] (9), where \u03b3 = \u0432 + r.Proof. The proof is the same as in (Zhao & Frazier, 2014), and we cite the proof as follows. SinceE\u03c0 [n = 1 Un (Yn \u2212 c)] = E\u03c0 [n = 1 {n \u2264 N} Un (Yn \u2212 c)] = throughtN (Yn \u2212 c) [1 {n \u2264 N} Un (Yn \u2212 c)], (10), where the last equality is due to Fubini's theorem and E\u03c0 [n = 1 | 1 {n \u2264 N} Un (Yn \u2212 c) Un (Yn \u2212 c) un (Yn \u2212 c) un (Yn \u2212 c)], which we need."}], "references": [{"title": "Thompson sampling for contextual bandits with linear payoffs", "author": ["Agrawal", "Shipra", "Goyal", "Navin"], "venue": "In ICML,", "citeRegEx": "Agrawal et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Agrawal et al\\.", "year": 2013}, {"title": "Latent dirichlet allocation", "author": ["Blei", "David", "Ng", "Andrew", "Jordan", "Michael"], "venue": "In Journal of Machine Learning Research,", "citeRegEx": "Blei et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Blei et al\\.", "year": 2003}, {"title": "Information relaxations and duality in stochastic dynamic programs", "author": ["Brown", "David", "Smith", "James", "Sun", "Peng"], "venue": "Operations Research,", "citeRegEx": "Brown et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Brown et al\\.", "year": 2010}, {"title": "An optimal algorithm for linear bandits", "author": ["Cesa-Bianchi", "Nicolo", "Kakade", "Sham"], "venue": null, "citeRegEx": "Cesa.Bianchi et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Cesa.Bianchi et al\\.", "year": 2011}, {"title": "Sequential sampling with economics of selection procedures", "author": ["Chick", "Stephen", "Frazier", "Peter"], "venue": "Management Science,", "citeRegEx": "Chick et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Chick et al\\.", "year": 2012}, {"title": "Contextual bandits with linear payoff functions", "author": ["Chu", "Wei", "Li", "Lihong", "Reyzin", "Lev", "Schapire", "Robert E"], "venue": "In AISTATS,", "citeRegEx": "Chu et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Chu et al\\.", "year": 2011}, {"title": "Personalized information delivery: An analysis of information filtering methods", "author": ["Foltz", "Peter W", "Dumais", "Susan T"], "venue": "In Communications of the ACM,", "citeRegEx": "Foltz et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Foltz et al\\.", "year": 1992}, {"title": "Adaptive submodularity: Theory and applications in active learning and stochastic optimization", "author": ["Golovin", "Daniel", "Krause", "Andreas"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Golovin et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Golovin et al\\.", "year": 2011}, {"title": "Some aspects of the sequential design of experiments", "author": ["Herbert", "Robbins"], "venue": "Bulletin of the American Mathematical Society,", "citeRegEx": "Herbert and Robbins.,? \\Q1952\\E", "shortCiteRegEx": "Herbert and Robbins.", "year": 1952}, {"title": "A survey of algorithmic methods for partially observed markov decision processes", "author": ["Lovejoy", "William S"], "venue": "Annals of Operations Research,", "citeRegEx": "Lovejoy and S.,? \\Q1991\\E", "shortCiteRegEx": "Lovejoy and S.", "year": 1991}, {"title": "Optimistic bayesian sampling in contextual-bandit problems", "author": ["May", "Benedict C", "Korda", "Nathan", "Lee", "Anthony", "Leslie", "David S"], "venue": "In The Journal of Machine Learning Research,", "citeRegEx": "May et al\\.,? \\Q2012\\E", "shortCiteRegEx": "May et al\\.", "year": 2012}, {"title": "A survey of partially observable markov decision processes: Theory, models, and algorithms", "author": ["Monahan", "George"], "venue": "Management Science,", "citeRegEx": "Monahan and George.,? \\Q1982\\E", "shortCiteRegEx": "Monahan and George.", "year": 1982}, {"title": "Linearly parameterized bandits", "author": ["Rusmevichientong", "Paat", "Tsitsiklis", "John N"], "venue": "Mathematics of Operations Research,", "citeRegEx": "Rusmevichientong et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Rusmevichientong et al\\.", "year": 2010}, {"title": "Learning to optimize via information-directed sampling", "author": ["Russo", "Daniel", "Roy", "Benjamin"], "venue": "In NIPS,", "citeRegEx": "Russo et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Russo et al\\.", "year": 2014}, {"title": "Learning to optimize via posterior sampling", "author": ["Russo", "Daniel", "Roy", "Benjamin"], "venue": "Mathematics of Operations Research,", "citeRegEx": "Russo et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Russo et al\\.", "year": 2014}, {"title": "Reinforcement Learning: An Introduction", "author": ["Sutton", "Richard S", "Barto", "Andrew G"], "venue": null, "citeRegEx": "Sutton et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Sutton et al\\.", "year": 1998}, {"title": "Exploration and exploitation in adaptive filtering based on bayesian active learning", "author": ["Zhang", "Yi", "Xu", "Wei", "Callan", "Jamie"], "venue": "In ICML,", "citeRegEx": "Zhang et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2003}, {"title": "Exploration vs. exploitation in the information filtering problem", "author": ["Zhao", "Xiaoting", "Frazier", "Peter"], "venue": null, "citeRegEx": "Zhao et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zhao et al\\.", "year": 2014}, {"title": "The proof is the same as in (Zhao", "author": ["\u0393+r . Proof"], "venue": null, "citeRegEx": "Proof.,? \\Q2014\\E", "shortCiteRegEx": "Proof.", "year": 2014}], "referenceMentions": [{"referenceID": 16, "context": "(Zhang et al., 2003) studies a Bayesian decision-theoretic version of this problem in which a univariate score is observed for each item, and relevance is related to this score via logistic regression.", "startOffset": 0, "endOffset": 20}, {"referenceID": 5, "context": "Indeed, the information filtering problem we study can be seen as a special case of the (Bayesian) contextual linear multi-armed bandit problem (Agrawal & Goyal, 2013; Chu et al., 2011; May et al., 2012; Cesa-Bianchi & Kakade, 2011).", "startOffset": 144, "endOffset": 232}, {"referenceID": 10, "context": "Indeed, the information filtering problem we study can be seen as a special case of the (Bayesian) contextual linear multi-armed bandit problem (Agrawal & Goyal, 2013; Chu et al., 2011; May et al., 2012; Cesa-Bianchi & Kakade, 2011).", "startOffset": 144, "endOffset": 232}, {"referenceID": 2, "context": "This upper bound is based on the idea of dividing (1) into k different \u201csinglefeature\u201d subproblems, then performing an information relaxation (similar in spirit to (Brown et al., 2010)) in which we give the policy assigned to each single-feature subproblem additional information, which allows us to compute their value efficiently.", "startOffset": 164, "endOffset": 184}, {"referenceID": 1, "context": "We represent each paper submitted in 2014 by a 10 dimensional vector using Latent Dirichlet allocation (LDA) (Blei et al., 2003).", "startOffset": 109, "endOffset": 128}], "year": 2017, "abstractText": "We present a Bayesian sequential decisionmaking formulation of the information filtering problem, in which an algorithm presents items (news articles, scientific papers, tweets) arriving in a stream, and learns relevance from user feedback on presented items. We model user preferences using a Bayesian linear model, similar in spirit to a Bayesian linear bandit. We compute a computational upper bound on the value of the optimal policy, which allows computing an optimality gap for implementable policies. We then use this analysis as motivation in introducing a pair of new Decompose-Then-Decide (DTD) heuristic policies, DTD-Dynamic-Programming (DTD-DP) and DTD-Upper-Confidence-Bound (DTD-UCB). We compare DTD-DP and DTDUCB against several benchmarks on real and simulated data, demonstrating significant improvement, and show that the achieved performance is close to the upper bound.", "creator": "LaTeX with hyperref package"}}}