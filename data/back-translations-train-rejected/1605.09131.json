{"id": "1605.09131", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-May-2016", "title": "Classification under Streaming Emerging New Classes: A Solution using Completely Random Trees", "abstract": "This paper investigates an important problem in stream mining, i.e., classification under streaming emerging new classes or SENC. The common approach is to treat it as a classification problem and solve it using either a supervised learner or a semi-supervised learner. We propose an alternative approach by using unsupervised learning as the basis to solve this problem. The SENC problem can be decomposed into three sub problems: detecting emerging new classes, classifying for known classes, and updating models to enable classification of instances of the new class and detection of more emerging new classes. The proposed method employs completely random trees which have been shown to work well in unsupervised learning and supervised learning independently in the literature. This is the first time, as far as we know, that completely random trees are used as a single common core to solve all three sub problems: unsupervised learning, supervised learning and model update in data streams. We show that the proposed unsupervised-learning-focused method often achieves significantly better outcomes than existing classification-focused methods.", "histories": [["v1", "Mon, 30 May 2016 07:57:41 GMT  (5516kb)", "http://arxiv.org/abs/1605.09131v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["xin mu", "kai ming ting", "zhi-hua zhou"], "accepted": false, "id": "1605.09131"}, "pdf": {"name": "1605.09131.pdf", "metadata": {"source": "CRF", "title": "Classification under Streaming Emerging New Classes: A Solution using Completely Random Trees", "authors": ["Xin Mu", "Kai Ming Ting", "Zhi-Hua Zhou"], "emails": ["zhouzh@nju.edu.cn"], "sections": [{"heading": null, "text": "This year it is more than ever before."}, {"heading": "1. The intuition", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "1.1. Detecting emerging new classes", "text": "The intuition is that anomalies of known classes are at the margins of the data cloud of known classes, and that anomalies of all emerging classes are far removed from known classes. To detect new anomalies, we suggest treating cases of each new class as \"outer\" anomalies that are significantly different from instances and anomalies of known classes. The anomaly detector for the SENC problem must be able to distinguish between these two types of anomalies. The assumption is that anomalies of known classes are more \"normal\" than the \"outer\" anomalies. This is a reasonable assumption in this context, because only instances of known classes are available to train the anomaly detector.An anomaly detector often categorizes the feature space into two types of regions: anomaly and normality."}, {"heading": "1.2. Classification and efficient model update", "text": "If we treat the second sub-problem, i.e. classification, in such a way that there is no relation to the first sub-problem for the detection of new classes, then any classifier can be applied. However, in order to enable an efficient model update that allows the classification of newly discovered classes and the detection of new emerging classes in data streams, we propose an integrated approach that has a common core for both detection and classification tasks. An unattended learner iForest [LTZ08], which induces completely random trees, has enabled us to implement the integrated approach with ease, because previous work [FWYM03, LTF05] has shown that an entire ensemble of completely random trees [Zho12, Chap.3.5] can be successfully applied as powerful classifiers as an extreme case of variable-random trees [LTYZ08]."}, {"heading": "2. Related work", "text": "This year it is more than ever before in the history of the city."}, {"heading": "3. Terminology Definition", "text": "Before we present the detail of our proposed algorithm, we will list the formal definitions of many important concepts used in this paper.Definition 3.1 Classification under Streaming Emerging new Class (SENC) Problem: Given a training dataset D = {(xi, yi)} L i = 1, where xi \u00b2 R is a training instance and yi \u00b2 Y = {1, 2,..., K} is the associated class label. The goal of learning with the SENC problem is to first learn a model f with D; then f is used as a detector for emerging new classes and a classifier for known classes."}, {"heading": "4. The Proposed Algorithm", "text": "In this section, we propose an efficient algorithm for solving the SENC problem called SENCForest, which consists of SENCTrees and assigns each instance, as it appears in a data stream, a class name: Emerging New Class or one of the known classes. Instead of treating it as a classification problem, we formulate it as a new class recognition problem and solve it with an unattended anomaly detector as the basis for building SENCForest, which will eventually function as both an unattended learner and a supervised learner. We give an overview of the procedure in Section 4.1. The relevant details of the procedure are then explained in the following three sections."}, {"heading": "4.1. SENCForest: An Overview", "text": "In fact, most of them will be able to play by the rules they have established in the past."}, {"heading": "4.2. SENCForest: Training process", "text": "The idea is based on the fact that there are \"a few\" who are \"isolated.\" \"We have a different concept in anomalous detection.\" \"We have a new concept in anomalous detection.\" \"We have a new concept in anomalous detection.\" \"We have a new concept in anomalous detection.\" \"We have a new concept in anomalous detection.\" \"We have a new concept in anomalous detection.\" \"We have built a new concept in anomaly in order to isolate each instance from the rest of the training.\" \"The idea is based on the fact that anomalous classes are formed in the anomaly.\" \"It is a unique concept in anomaly detection, as each iTree is built to isolate each instance from the rest of the training.\" \"The idea is based on the fact that anomaly classes are formed in the anomaly.\" \"It is a new concept in anomaly detection.\""}, {"heading": "4.3. Deployment in data stream", "text": "Faced with a test instance x, SENCForest (x) produces a class name y (b1,.., bm, NewClass), where m is the number of known classes to date and NewClass the label for an emerging new algorithm 2 SENCTree Input: X - Input data, MinSize - Minimum internal node size Output: SENCTree1: if | < MinSize then 2: return LeafNode {| X |, F [\u00b7], r}, as defined in Section 4.2.3: else 4: let Q be a list of attributes in X 5: random select an attribute q, Q 6: random select a split point p from max and min values of attribute q in X 7: XL filter (X, q \u2264 p) 8: XR filter (X > p) 9: return inNode {Left, SENCTree class (XL), 10: Right."}, {"heading": "4.4. Model Update", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.4.1. Growing Mechanism", "text": "There are two growing mechanisms: one for the growth of a subtree in a SENCTree, and the other for the growth of multiple SENCForests.Growing a subtree in a SENCTree. Updating at each node (line 10) involves either a replacement with a newly bred subtree or a simple update of the class frequency to the new class bm + 1.Algorithm 4 Update SENCForest Input: SENCForest - existing model, B - input data Output: a new model of SENCForest1: initialize: All instances in B are assigned a new class bm + 1 2: for i = 1, z do 3: B \u00b2 2 sample (B)."}, {"heading": "4.4.3. Retiring Mechanism", "text": "A SENCForest will be retired under the following scenarios: 1. If a SENCForest is not used to predict known classes for a certain period of time, it will be eliminated for any future predictions. In other words, if a SENCForest issues \"NewClass\" for a long period of time, that SENCForest will be retired in the last time.2 If the number of SENCForests has reached the specified limit and no SENC Forest can retire on the basis of (1), the least used SENCForest will be retired in the last time.The number of known class predictions will be recorded in the data stream for each SENCForest, and the one who has made the minimum number of predictions for known classes will be identified as the least used SENCForest."}, {"heading": "5. Experiment", "text": "This section reports on the empirical evaluation we conducted to evaluate the performance of SENCForest compared to several state-of-the-art methods."}, {"heading": "5.1. Experimental Setup", "text": "This year it has come to the point that it has never come as far as this year."}, {"heading": "5.2. Empirical results", "text": "It is only a matter of time before that happens, that it happens."}, {"heading": "5.4. Multiple new classes in a period", "text": "The emergence of several new classes within a period is a challenge to the SENC problem. Although SENCForest is designed to deal with an emerging class within a period, it can still perform well by treating these emerging classes as a new class within a period. Figure 12 shows that SENCForest works even if each period has two new classes. In this stream, there are three periods; each period has 2000 instances and 4 classes (i.e. two emerging classes and two known classes). If it is important to identify each class within each period, a cluster algorithm [Agg13] can be used to achieve this goal before proceeding with model updating."}, {"heading": "6. Conclusions and future work", "text": "This work helps to break down the SENC problem into three sub-problems and postulates that the ability to effectively address the first sub-problem of the emergence of new classes is critical to the entire problem. The difficulty of the SENC problem is underlined by the inability of existing methods to satisfactorily solve it. We show that the uncontrolled, anomalous-detected approach, coupled with an integrated method that uses completely random trees, provides a complete solution to the entire SENC problem. The current classification-focused approach has failed to provide such a solution. SENCForest's strength is its ability to detect new classes with high accuracy. The use of an uncontrolled anomaly detector, with the new ability to distinguish between anomalies of known classes and instances of new classes, underscores the source of strength."}, {"heading": "7. appendices", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "7.1. Parameter settings", "text": "The parameter settings of all algorithms used in the experiments are given in Table 5. When searching for parameters, the final settings for all SVM algorithms are determined by a 10-fold cross-validation on the training set. LOF parameter search is performed as described in [DYZ14]. ECSMiner uses K-mean and K is set to 5 in the experiment."}, {"heading": "7.2. Descriptions of data sets", "text": "Synthetic: We simulate a data stream using a two-dimensional synthetic dataset as shown below. It contains 20,000 instances and has four overlapping Gaussian distributions.The first two known classes 0 5 10 1505101520XY are marked purple. In the first period, instances of class blue appear as the first new class, and in the second period, instances of class red form the second new classe.MHAR: This dataset [AGO + 12] is collected by 30 volunteers wearing a smartphone at the waist and performing 6 activities (walking, stairs, stairs, standing, sitting, lying).The embedded 3D accelerometer and 3D gyroscope of a Samsung Galaxy S2 smartphone were used to capture data at a constant rate of 50 Hz. This dataset includes 6 classes, 10299 instances and 561 attributes."}], "references": [{"title": "A survey of stream clustering algorithms. In Data Clustering: Algorithms and Applications, pages 231\u2013258", "author": ["Charu C. Aggarwal"], "venue": null, "citeRegEx": "Aggarwal.,? \\Q2013\\E", "shortCiteRegEx": "Aggarwal.", "year": 2013}, {"title": "Human activity recognition on smartphones using a multiclass hardwarefriendly support vector machine", "author": ["Davide Anguita", "Alessandro Ghio", "Luca Oneto", "Xavier Parra", "Jorge Luis ReyesOrtiz"], "venue": "In Proceedings of the 4th International Workshop on Ambient Assisted Living and Home Care,", "citeRegEx": "Anguita et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Anguita et al\\.", "year": 2012}, {"title": "Nonparametric methods in change point problems", "author": ["E Brodsky", "Boris S Darkhovsky"], "venue": null, "citeRegEx": "Brodsky and Darkhovsky.,? \\Q1993\\E", "shortCiteRegEx": "Brodsky and Darkhovsky.", "year": 1993}, {"title": "New ensemble methods for evolving data streams", "author": ["Albert Bifet", "Geoffrey Holmes", "Bernhard Pfahringer", "Richard Kirkby", "Ricard Gavald\u00e0"], "venue": "In Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "Bifet et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Bifet et al\\.", "year": 2009}, {"title": "LOF: identifying density-based local outliers", "author": ["Markus M. Breunig", "Hans-Peter Kriegel", "Raymond T. Ng", "J\u00f6rg Sander"], "venue": "In Proceedings of the 2000 ACM SIGMOD International Conference on Management of Data,", "citeRegEx": "Breunig et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Breunig et al\\.", "year": 2000}, {"title": "Detection of abrupt changes", "author": ["Mich\u00e8le Basseville", "Igor V. Nikiforov"], "venue": "Theory and application. Automatica,", "citeRegEx": "Basseville and Nikiforov.,? \\Q1996\\E", "shortCiteRegEx": "Basseville and Nikiforov.", "year": 1996}, {"title": "Anomaly detection: A survey", "author": ["Varun Chandola", "Arindam Banerjee", "Vipin Kumar"], "venue": "ACM Computing Surveys (CSUR),", "citeRegEx": "Chandola et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Chandola et al\\.", "year": 2009}, {"title": "LIBSVM: A library for support vector machines", "author": ["Chih-Chung Chang", "Chih-Jen Lin"], "venue": "ACM Trans. Intelligent Systems and Technology,", "citeRegEx": "Chang and Lin.,? \\Q2011\\E", "shortCiteRegEx": "Chang and Lin.", "year": 2011}, {"title": "Detecting bots via incremental LS-SVM learning with dynamic feature adaptation", "author": ["Feilong Chen", "Supranamaya Ranjan", "Pang-Ning Tan"], "venue": "In Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "Chen et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2011}, {"title": "An online kernel change detection algorithm", "author": ["Fr\u00e9d\u00e9ric Desobry", "Manuel Davy", "Christian Doncarli"], "venue": "IEEE Trans. Signal Processing,", "citeRegEx": "Desobry et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Desobry et al\\.", "year": 2005}, {"title": "Learning with augmented class by exploiting unlabeled data", "author": ["Qing Da", "Yang Yu", "Zhi-Hua Zhou"], "venue": "In Proceedings of the 28th AAAI Conference on Artificial Intelligence,", "citeRegEx": "Da et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Da et al\\.", "year": 2014}, {"title": "Is random model better? on its accuracy and efficiency", "author": ["Wei Fan", "Haixun Wang", "Philip S. Yu", "Sheng Ma"], "venue": "In Proceedings of the 3rd IEEE International Conference on Data Mining,", "citeRegEx": "Fan et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Fan et al\\.", "year": 2003}, {"title": "Incremental learning of boosted face detector", "author": ["Chang Huang", "Haizhou Ai", "Takayoshi Yamashita", "Shihong Lao", "Masato Kawade"], "venue": "In Proceedings of the 11th IEEE Conference on Computer Vision,", "citeRegEx": "Huang et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Huang et al\\.", "year": 2007}, {"title": "Dynamic weighted majority: An ensemble method for drifting concepts", "author": ["J Zico Kolter", "Marcus A Maloof"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Kolter and Maloof.,? \\Q2007\\E", "shortCiteRegEx": "Kolter and Maloof.", "year": 2007}, {"title": "From n to n+ 1: Multiclass transfer incremental learning", "author": ["Ilja Kuzborskij", "Francesco Orabona", "Barbara Caputo"], "venue": "In Proceedings of the 26th IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "Kuzborskij et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Kuzborskij et al\\.", "year": 2013}, {"title": "Maximizing tree diversity by building complete-random decision trees", "author": ["Fei Tony Liu", "Kai Ming Ting", "Wei Fan"], "venue": "In Proceedings of the 9th Pacific-Asia Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "Liu et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2005}, {"title": "Spectrum of variablerandom trees", "author": ["Fei Tony Liu", "Kai Ming Ting", "Yang Yu", "Zhi-Hua Zhou"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Liu et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2008}, {"title": "Isolation forest", "author": ["Fei Tony Liu", "Kai Ming Ting", "Zhi-Hua Zhou"], "venue": "In Proceedings of the 8th IEEE International Conference on Data Mining,", "citeRegEx": "Liu et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2008}, {"title": "Classification and novel class detection in concept-drifting data streams under time constraints", "author": ["M.M. Masud", "Jing Gao", "L. Khan", "Jiawei Han", "Bhavani Thuraisingham"], "venue": "IEEE Trans. Knowledge and Data Engineering,", "citeRegEx": "Masud et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Masud et al\\.", "year": 2011}, {"title": "Time-series novelty detection using one-class support vector machines", "author": ["J. Ma", "S. Perkins"], "venue": "In Proceedings of the International Joint Conference on Neural Networks,", "citeRegEx": "Ma and Perkins.,? \\Q2003\\E", "shortCiteRegEx": "Ma and Perkins.", "year": 2003}, {"title": "In defense of one-vs-all classification", "author": ["Ryan M. Rifkin", "Aldebaro Klautau"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Rifkin and Klautau.,? \\Q2004\\E", "shortCiteRegEx": "Rifkin and Klautau.", "year": 2004}, {"title": "Svms for novel class detection in bioinformatics", "author": ["Eduardo J. Spinosa"], "venue": "In III Brazilian Workshop on Bioinformatics,", "citeRegEx": "Spinosa and Carvalho.,? \\Q2004\\E", "shortCiteRegEx": "Spinosa and Carvalho.", "year": 2004}, {"title": "Toward open set recognition", "author": ["Walter J Scheirer", "Anderson de Rezende Rocha", "Archana Sapkota", "Terrance E Boult"], "venue": "IEEE Trans. Pattern Analysis and Machine Intelligence,", "citeRegEx": "Scheirer et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Scheirer et al\\.", "year": 2013}, {"title": "Estimating the support of a high-dimensional distribution", "author": ["Bernhard Sch\u00f6lkopf", "John C. Platt", "John C. Shawe-Taylor", "Alex J. Smola", "Robert C. Williamson"], "venue": "Neural Computation,", "citeRegEx": "Sch\u00f6lkopf et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Sch\u00f6lkopf et al\\.", "year": 2001}, {"title": "Cross-domain video concept detection using adaptive svms", "author": ["Jun Yang", "Rong Yan", "Alexander G Hauptmann"], "venue": "In Proceedings of the 15th international conference on Multimedia,", "citeRegEx": "Yang et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Yang et al\\.", "year": 2007}, {"title": "Hybrid decision tree", "author": ["Zhi-Hua Zhou", "Zhao-Qian Chen"], "venue": "Knowledge-based systems,", "citeRegEx": "Zhou and Chen.,? \\Q2002\\E", "shortCiteRegEx": "Zhou and Chen.", "year": 2002}, {"title": "Ensemble methods: foundations and algorithms", "author": ["Zhi-Hua Zhou"], "venue": null, "citeRegEx": "Zhou.,? \\Q2012\\E", "shortCiteRegEx": "Zhou.", "year": 2012}], "referenceMentions": [], "year": 2016, "abstractText": "This paper investigates an important problem in stream mining, i.e., classification under streaming emerging new classes or SENC. The common approach is to treat it as a classification problem and solve it using either a supervised learner or a semi-supervised learner. We propose an alternative approach by using unsupervised learning as the basis to solve this problem. The SENC problem can be decomposed into three sub problems: detecting emerging new classes, classifying for known classes, and updating models to enable classification of instances of the new class and detection of more emerging new classes. The proposed method employs completely random trees which have been shown to work well in unsupervised learning and supervised learning independently in the literature. This is the first time, as far as we know, that completely random trees are used as a single common core to solve all three sub problems: unsupervised learning, supervised learning and model update in data streams. We show that the proposed unsupervised-learningfocused method often achieves significantly better outcomes than existing classification-focused methods.", "creator": "LaTeX with hyperref package"}}}