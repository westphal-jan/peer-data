{"id": "1605.09696", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-May-2016", "title": "Generalized Multi-view Embedding for Visual Recognition and Cross-modal Retrieval", "abstract": "In this paper, the problem of multi-view embedding from different visual cues and modalities is considered. We propose a unified solution for subspace learning methods using the Rayleigh quotient, which is extensible for multiple views, supervised learning, and non-linear embeddings. Numerous methods including Canonical Correlation Analysis, Partial Least Sqaure regression and Linear Discriminant Analysis are studied using specific intrinsic and penalty graphs within the same framework. Non-linear extensions based on kernels and (deep) neural networks are derived, achieving better performance than the linear ones. Moreover, a novel variant of multi-view Linear Discriminant Analysis is proposed by taking the view difference into consideration. We demonstrate the effectiveness of the proposed multi-view embedding methods on visual object recognition and cross-modal image retrieval, and obtain superior results in both applications compared to related methods.", "histories": [["v1", "Tue, 31 May 2016 16:11:16 GMT  (8493kb,D)", "https://arxiv.org/abs/1605.09696v1", "Submitted to IEEE Transactions on Image Processing"], ["v2", "Thu, 22 Sep 2016 15:58:20 GMT  (8738kb,D)", "http://arxiv.org/abs/1605.09696v2", null], ["v3", "Thu, 31 Aug 2017 09:17:50 GMT  (7015kb,D)", "http://arxiv.org/abs/1605.09696v3", null]], "COMMENTS": "Submitted to IEEE Transactions on Image Processing", "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["guanqun cao", "alexandros iosifidis", "ke chen", "moncef gabbouj"], "accepted": false, "id": "1605.09696"}, "pdf": {"name": "1605.09696.pdf", "metadata": {"source": "CRF", "title": "Generalized Multi-view Embedding for Visual Recognition and Cross-modal Retrieval", "authors": ["Guanqun Cao", "Alexandros Iosifidis", "Ke Chen"], "emails": [], "sections": [{"heading": null, "text": "Identifying an object can benefit not only from visual features such as color, texture and shape, but also from textual annotations from different observations and languages. Thanks to the data enrichment of sensor technologies, the accuracy of image processing and recognition methods is significantly improved by taking advantage of multiview and cross-domain learning [1], [2] since the match of data samples across different characteristics is directly impracticable, subspace learning methods that learn a common feature space from multiview spaces become an effective approach to solving the problem. Numerous methods have been proposed in subspace learning. They can be grouped into three main categories based on the characteristics of machine learning: two-way learning and multiview learning; unattended learning and clear learning; and linear learning and non-linear learning."}, {"heading": "II. RELATED WORK", "text": "In this section, we will first define the general notations used throughout the essay, then briefly review the related methods for multiview learning in subspace, and discuss recent work on nonlinear methods related to nuclei and (deep) neural networks."}, {"heading": "A. Notations", "text": "We define the data matrix X = [x1, x2,.., xN], xi-RD = xi, where N is the number of samples and D is the attribute dimension. We also define Xv-RDv-N, v = 1,.., V for the attribute vectors of the vth view, and discard the index in the single view for notation simplicity. Note that the dimensionality of the different attribute spaces Dv can vary across views. The covariance matrix is a statistic commonly used in CCA and PLS. We designate X-V = Xv \u2212 1N Xv e > as the centered data matrix. The cross view covariance matrix between view i and j is then expressed as ij = 1N X-X-iX > j = 1 N Xi (I \u2212 1N e >)."}, {"heading": "B. Canonical Correlation Analysis (CCA)", "text": "Canonical Correlation Analysis (CCA) [6], [42] is a conventional statistical method that determines the maximum correlation between two sets of data X1, RD1, RD1 and X2, RD2 and N using the linear combination Y1 = W > 1 X1 and Y2 = W > 2 X2. W1 and W2 are determined by optimization: J = arg max W1, W2 corr (W > 1 X1, W > 2 X2) (4) = arg max W1, W2 W > 1 12W2 \"W > 1 11W1 \u00b7 \u221a W > 2 22W2, (5) whereas = [11] 12\u044521 \u044522] = 1N [X] 1X > 1 X 1X > 2X > 1 X 2X > 2] (6)"}, {"heading": "C. Kernel CCA", "text": "Kernel CCA finds the maximum correlation between two views after allocating them to the kernel space [22], expressed by J = arg max W1, W2 corr (W > 1 \u03a61, W > 2 \u03a62) (7) We use the kernel trick [40] and the present theorem in (2) and derive the objective function for the kernel CCA asJ = arg max A1, A2 A > 1 K1K2 A2 \u221a A > 1 K1K1 A1 \u00b7 \u221a A > 2 K2K2 A2. (8)"}, {"heading": "D. Deep CCA", "text": "Deep CCA maximizes the correlation between a pair of views by learning nonlinear representations from the input data through multiple stacked neuron layers [25], [43]. Over both networks, a linear CCA layer is added, and the inputs to the CCA layer depend on the network outputs H1 and H2. Similar to the nonlinear case in (8), a modified lens function is optimized minW1, W2 \u2212 1N Tr (W1 > H1 H > 2 W2), where W1, W2 are the projection matrices in the CCA layer and the correlated outputs are Y1 = W > 1 H1 and Y2 = W > 2 H2. A modified SGD method is developed with respect to the inputs H1 and H2 to the linear layer, which are also the outputs from the two networks. The objective function is described as Tr (W > 1 > 2 > W2) with Tr = the highest two cores (T = 1)."}, {"heading": "E. Partial Least Squares (PLS) regression", "text": "The regression of the partial smallest squares (PLS) [8] is another method for reducing the dimensionality derived from the linear combination of the input vectors X1 with the target information, which is considered as a second view X2. PLS maximizes the covariance between views by using J = arg max W1, W2 [Tr (W > 1 X1X > 2 W2)], (9) taking into account W > 1 W1 = I, W > 2 W2 = I. (10) The non-linear extensions of PLS are obtained in a similar way to those in CCA."}, {"heading": "F. Generalized Multi-view Analysis (GMA)", "text": "GMA [18] is a generalized framework that includes numerous methods for reducing dimensionality, maximizing the discriminatory information within the view, but ignoring the information between views. J = argmax WTr V \u2211 i V \u2211 i \u2211 i < j 2\u03bbijW > i XiX > j Wj + V \u2211 i = 1 \u00b5iW > i PiWi, subject to V \u2211 i W > i QiWi = I. (11) Here, both P and Q are the covariance matrices within the view. P is a square matrix and Q is a square symmetric defined matrix. In this context, we apply the Generalized Multiview Marginal Fisher Analysis (GMMFA)."}, {"heading": "G. Linear Discriminant Analysis (LDA)", "text": "The linear discriminant analysis (LDA) [11], [44] calculates the projection by maximizing the ratio between class dispersion and class dispersion. Using \u00b5c, we define the mean of the c'th class, formed from Nc samples, and \u00b5 the global mean. LDA then optimizes the following criterion: J = arg max WTr (W > P W) Tr (W > Q W), (12) where P = C \u2211 c = 1Nc (\u00b5c \u2212 \u00b5) (\u00b5c \u2212 \u00b5) > = X (C \u0445 c = 11Nc ecec > \u2212 1N e >) X >, (13) Q = N \u2211 i = 1 (xi \u2212 \u00b5c) (xi \u2212 \u00b5c) > = X (I \u2212 C \u2211 c = 1 Nc ecec >) X >. (14) Non-linear core extensions include KDA [45] and KRDA [46]."}, {"heading": "H. Multi-view Discriminant Analysis (MvDA)", "text": "MvDA [17] is the multi-view version of LDA that maximizes the ratio of the determinant of the scatter matrix between classes to the scatter matrix within the class. Its objective function is J = arg max WTr (SMB) Tr (SMW), (15) where the scatter matrix between classes isSMB = V \u2211 i = 1 V \u2211 j = 1 W > i Xi (C \u2211 c = 1 1 Nc ecec > \u2212 1 N e >) X > j Wj, (16) and the scatatrix within the class isSMW = V \u2211 i = 1 V \u0445 j = 1 W > i Xi (I \u2212 C \u0445 c = 1 Nc ecec >) X > j Wj. (17) W contains the eigenvectors of the matrix S = SMW \u2212 1SMB according to the leading d eigenvalues."}, {"heading": "III. GENERALIZED MULTI-VIEW EMBEDDING", "text": "The generalized optimization problems are described by: J = max WTr (W > PW) Tr (W > QW) (18), where P and Q describe the matrices describing the interview and intra-view covariances. (19) The above equation is in the form of the Rayleigh quotient. (22) The generalized eigenvalue systems can be reduced to a generalized eigenvalue problem. (19) The solution is given in the form of the Rayleigh quotient. (20) The generalization of eigenvalue systems is the sum of eigenvalue systems. (19) The generalization of eigenvalue systems is in the way it is presented. (20)"}, {"heading": "A. Scaling up the inter-view and intra-view covariance matrices", "text": "The idea behind Multi-View CCA (MvCCA) is to maximize the correlation between all view pairs, and its goal can be reformulated to maximize covariance between views while minimizing covariance between views in latent space. Therefore, we are looking at covariance matrices between different view representations in P and the covariance matrices of each view in Q. Multi-View PLS (MvPLS) directly maximize covariance between views. Since we also embed the target information for learning in subspace, the proposed MvPLS differs from MvCCA only in minimizing intra-view. Taking into account class discrimination, the novel modular Multiview Modular Discrimination Analysis (MvMDA) extends to separating data between views of different classes, making the data within classes compact."}, {"heading": "B. Linear subspace learning", "text": "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = ="}, {"heading": "C. Kernel-based non-linear subspace learning", "text": "The use of the kernel trick in (1) and the present theorem in (2) and (24) can be expressed as follows: Yv = A > v \u03a6 > v \u03a6v = A > v Kv. (33) The criterion for kernel multiview CCA is then J = argmax Kv, v = 1,..., VTr (V = 1 V \u2211 j 6 = i j = 1 A > i Ki LKjAj) Tr (V = 1 A > i Ki LKiAi). (34) It can easily be shown that the solution for Av is the same as (19). Kernel multiview PLS maximizes the covariance between pairs of attribute vectors in kernel space and hence the objective function isJ = argmax Kv, v = 1,..., V Tr (V = 1 V = 1 V = i Ki LKjAj)."}, {"heading": "D. Non-linear subspace learning using (deep) neural networks", "text": "Taking advantage of the non-linear mapping with neural networks by (3), (24) asYv = W > v h (Xv; Bv) = W > v Hv. (37) Since the network outputs are combined by a linear plane, as shown in Fig. 2, the parameters Bv of each network are jointly trained to achieve the optimal criterion value. After the transformation by neural networks, the projection with the linear subsurface learning from several views relating to Hv. Therefore, we need an additional optimization, which is solved by SGD. We experimented with SGD without variance limitations and found that we could achieve much better results with the projections limited to the unit variance, i.e. in Deep Multi-view CCA (DMvCCA), we have an additional optimization by SGD CCep CCep vvvvD without variance limitations and found that we could achieve much better results with the Mint A, i.e., the projections are limited to the Mint A, which we could achieve with the unity Mi."}, {"heading": "IV. EXPERIMENTS", "text": "In this section, we evaluate the multiview methods for two important multimedia applications: zero-shot detection on the Animal with Attributes (AwA) dataset and crossmodal image retrieval on Wikipedia and Microsoft COCO datasets."}, {"heading": "A. Experimental Setup", "text": "In fact, most of them will be able to play by the rules they have imposed on themselves."}, {"heading": "B. Parameter Settings", "text": "The dimensionality d in latent space is a predefined parameter. In the following section, we evaluate the effects of different d values. In the experiment, we use d = 50 for linear projections on all datasets. In Wikipedia and AwA datasets, we choose d = 150 for kernel mappings and d = 200 for the COCO dataset. To calculate the efficiency on the AwA and COCO datasets, we use an approximate RBF kernel mapping for non-linear mappings. In the RBF kernel, we define the average distance between samples from different views / modalities, which is the natural scaling factor for each dataset. In all experiments, the original training is further divided into an 80% training split and a 20% validation split."}, {"heading": "C. Experimental Results", "text": "This year it is as far as never before in the history of the Federal Republic of Germany."}, {"heading": "D. Parameter sensitivity analysis of dimension d in linear and kernel cases", "text": "The number of dimensions of feature vectors in latent space is determined by the uppermost d eigenvectors in the projection matrix and is predefined in the previous experiments. Therefore, in this section we examine the effect by the variation of d represented in figs. 8 and 9, namely in the range of {10, 20, 50, 100, 150, 200}. The performance on the Wikipedia dataset is reported both with text queries for images and with image queries for texts. Results for different view numbers are also recorded. Generally, we achieve a better query performance when d is between 50 and 150. This can be explained by the fact that the most informative eigenvectors are contained within the range. Therefore, d = 50 was chosen for multiview linear embedding in the experiments. With the exception of LMvPLS and KMvPLS, we find the majority of the methods robust to the dimensional changes in subspace."}, {"heading": "V. CONCLUSION", "text": "s method of embedding multiple views CCA, PLS, and LDA can be characterized by their specific intrinsic and streamlined graph matrices within the same frame. A new discriminatory analysis method called MvMDA was introduced by taking advantage of the distances between the class centers of different views. Meanwhile, we also examined nonlinear embedding and found implicit and explicit kernel mappings for learning from multiple views. A unified scheme for learning through neural networks was developed that combined the learned representations with a linear embedding layer, formulating the expression of stochastic gradient descent to optimize the proposed target function. We validated the formulation by performing experiments in zero-modal shooter imaging, and three-dimensional imaging."}], "references": [], "referenceMentions": [], "year": 2017, "abstractText": "In this paper, the problem of multi-view embed-<lb>ding from different visual cues and modalities is considered.<lb>We propose a unified solution for subspace learning methods<lb>using the Rayleigh quotient, which is extensible for multiple<lb>views, supervised learning, and non-linear embeddings. Numer-<lb>ous methods including Canonical Correlation Analysis, Partial<lb>Least Square regression and Linear Discriminant Analysis are<lb>studied using specific intrinsic and penalty graphs within the<lb>same framework. Non-linear extensions based on kernels and<lb>(deep) neural networks are derived, achieving better performance<lb>than the linear ones. Moreover, a novel Multi-view Modular<lb>Discriminant Analysis (MvMDA) is proposed by taking the view<lb>difference into consideration. We demonstrate the effectiveness<lb>of the proposed multi-view embedding methods on visual object<lb>recognition and cross-modal image retrieval, and obtain superior<lb>results in both applications compared to related methods.", "creator": "LaTeX with hyperref package"}}}