{"id": "1605.09757", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-May-2016", "title": "Towards ontology driven learning of visual concept detectors", "abstract": "The maturity of deep learning techniques has led in recent years to a breakthrough in object recognition in visual media. While for some specific benchmarks, neural techniques seem to match if not outperform human judgement, challenges are still open for detecting arbitrary concepts in arbitrary videos. In this paper, we propose a system that combines neural techniques, a large scale visual concepts ontology, and an active learning loop, to provide on the fly model learning of arbitrary concepts. We give an overview of the system as a whole, and focus on the central role of the ontology for guiding and bootstrapping the learning of new concepts, improving the recall of concept detection, and, on the user end, providing semantic search on a library of annotated videos.", "histories": [["v1", "Tue, 31 May 2016 18:35:44 GMT  (34kb,D)", "http://arxiv.org/abs/1605.09757v1", "unpublished"]], "COMMENTS": "unpublished", "reviews": [], "SUBJECTS": "cs.IR cs.AI cs.CV", "authors": ["sanchit arora", "chuck cho", "paul fitzpatrick", "francois scharffe"], "accepted": false, "id": "1605.09757"}, "pdf": {"name": "1605.09757.pdf", "metadata": {"source": "CRF", "title": "Towards ontology driven learning of visual concept detectors", "authors": ["Sanchit ARORA", "Chuck CHO", "Paul FITZPATRICK", "Fran\u00e7ois SCHARFFE"], "emails": ["francois.scharffe@dextro.co"], "sections": [{"heading": null, "text": "Keywords: computer vision, ontology, deep learning, neural networks, active learning"}, {"heading": "1. Introduction", "text": "In recent years, advances in the design and optimization of neural networks, combined with dedicated computer architectures through the use of GPUs, have dramatically increased the performance of computer vision systems. ILSVRC 2012 challengers Krizhevsky et al. [1] demonstrated how to design and train a neural network in the face of a large dataset of labeled images to achieve state-of-the-art classification results, and the availability of increasingly powerful hardware enabled the training of deeper and deeper neural networks [2] with corresponding performance improvements. Research efforts have resulted in multiple advances, including novel designs [3] and their combination with existing computer vision techniques such as regional suggestions [4], optical flow [5], or long-term short-term short-term memory [6], all of which accelerated the pace at which computer vision systems approach human performance. While large systems attempt to create models for a comprehensive visual concept, we take the learning approach step by step."}, {"heading": "2. A Virtuous Circle for Visual Concept Learning", "text": "This section describes the Dextro system, which can be considered as two parts that come together to form an active learning loop; the first part is the Dextro API, which allows anyone to analyze and understand their video by providing a link; the computer vision models combined with a human in the loop system analyze the video and deliver immediate results; the second part is the Dextro training system, which continues to collect training videos and uses human commentators to collect data for these videos, which are eventually used as training data for the computer vision models to expand their visual concept classification; the system is illustrated in Figure 1; the initial computer vision system begins with a limited number of visual concepts on which it is trained; and since videos are processed through the Dextro API, the model is unable to self-confidently classify the video content because its limited training sends the video to a human in the loop system."}, {"heading": "3. Ontology Driven Neural Model Learning", "text": "In fact, most people who stand up for people's rights are standing up for people's rights, violating the rights and duties of the individual who violates them and violates them. In fact, it is true that people who stand up for people's rights are violating themselves and their rights. In fact, people who stand up for people's rights are violating themselves and their rights. In fact, people who stand up for people's rights are not able to respect and respect people's rights."}, {"heading": "4. Conclusion", "text": "While the combination of numerical and symbolic techniques may be a longer-term research agenda, ontologies can bring significant improvements in the recognition of visual concepts.We have introduced a system with an active learning loop for visual concept recognition, in which ontology plays a central role in the control of the learning process.The systems presented in this essay are in the works. The learning loop for active learning of visual concepts in the neural network is in place. We are currently focused on building and integrating a comprehensive ontology that structures hundreds of concepts that our system can currently detect. In our next steps, we will use ontology to make the improvements discussed in this essay: bootstrapping model learning and controlling the categorization process using the concept hierarchy."}], "references": [{"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G. Hinton"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2012}, {"title": "Very Deep Convolutional Networks for Large-Scale Image Recognition", "author": ["Karen Simonyan", "Andrew Zisserman"], "venue": "In International Conference on Learning Representations,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2015}, {"title": "Rethinking the Inception Architecture for Computer Vision", "author": ["Christian Szegedy", "Vincent Vanhoucke", "Sergey Ioffe", "Jonathon Shlens", "Zbigniew Wojna"], "venue": "Proceedings of IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2016}, {"title": "Rich feature hierarchies for accurate object detection and semantic segmentation", "author": ["Ross Girshick", "Jeff Donahue", "Trevor Darrell", "Jitendra Malik"], "venue": "Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "Two-Stream Convolutional Networks for Action Recognition in Videos", "author": ["Karen Simonyan", "Andrew Zisserman"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "Deep Visual-Semantic Alignments for Generating Image Descriptions", "author": ["Andrej Karpathy", "Li Fei-Fei"], "venue": "Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "Exploiting Feature and Class Relationships in Video Categorization with Regularized Deep Neural Networks", "author": ["Yu-Gang Jiang", "Zuxuan Wu", "Jun Wang", "Xiangyang Xue", "Shih-Fu Chang"], "venue": "arXiv preprint arXiv:1502.07209,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2015}, {"title": "Learning Object Class Detectors from Weakly Annotated Video Computer Vision and Pattern Recognition", "author": ["A. Prest", "C. Leistner", "J. Civera", "C. Schmid", "V. Ferrari"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2012}, {"title": "UCF101: A Dataset of 101 Human Action Classes From Videos in The Wild, CRCV-TR-12-01", "author": ["Khurram Soomro", "Amir Roshan Zamir", "Mubarak Shah"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2012}, {"title": "Describing low-level image features using the COMM ontology,", "author": ["M. Vacura", "V. Svatek", "C. Saathoff", "T. Franz", "R. Troncy"], "venue": "15th IEEE International Conference on Image Processing,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2008}, {"title": "Building a Visual Ontology for Video Retrieval in Proceeding MULTIMEDIA \u201905", "author": ["L. Hollink", "M. Worring", "A. Schreiber"], "venue": "Proceedings of the 13th annual ACM international conference on Multimedia", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2005}], "referenceMentions": [{"referenceID": 0, "context": "The ILSVRC-2012 challenge winners Krizhevsky et al [1] demonstrated how given a large dataset of labeled images, one could design a neural network and train it to achieve state-of-the-art classification results.", "startOffset": 51, "endOffset": 54}, {"referenceID": 1, "context": "Availability of increasingly powerful hardware has enabled training of deeper and deeper neural networks [2] with corresponding improvements in performance.", "startOffset": 105, "endOffset": 108}, {"referenceID": 2, "context": "Research efforts have resulted in multiple advances including novel designs [3] and their combination with existing computer vision techniques like region proposals [4], optical flow [5] or long short term memories [6].", "startOffset": 76, "endOffset": 79}, {"referenceID": 3, "context": "Research efforts have resulted in multiple advances including novel designs [3] and their combination with existing computer vision techniques like region proposals [4], optical flow [5] or long short term memories [6].", "startOffset": 165, "endOffset": 168}, {"referenceID": 4, "context": "Research efforts have resulted in multiple advances including novel designs [3] and their combination with existing computer vision techniques like region proposals [4], optical flow [5] or long short term memories [6].", "startOffset": 183, "endOffset": 186}, {"referenceID": 5, "context": "Research efforts have resulted in multiple advances including novel designs [3] and their combination with existing computer vision techniques like region proposals [4], optical flow [5] or long short term memories [6].", "startOffset": 215, "endOffset": 218}, {"referenceID": 6, "context": "While data is in some cases available [7,8,9], it is in the general case difficult to find good video training material.", "startOffset": 38, "endOffset": 45}, {"referenceID": 7, "context": "While data is in some cases available [7,8,9], it is in the general case difficult to find good video training material.", "startOffset": 38, "endOffset": 45}, {"referenceID": 8, "context": "While data is in some cases available [7,8,9], it is in the general case difficult to find good video training material.", "startOffset": 38, "endOffset": 45}, {"referenceID": 9, "context": "At the time of writing, the system is implemented and includes a visual concepts ontology under construction, inspired by existing visual ontologies [10,11,12].", "startOffset": 149, "endOffset": 159}, {"referenceID": 10, "context": "At the time of writing, the system is implemented and includes a visual concepts ontology under construction, inspired by existing visual ontologies [10,11,12].", "startOffset": 149, "endOffset": 159}], "year": 2016, "abstractText": "The maturity of deep learning techniques has led in recent years to a breakthrough in object recognition in visual media. While for some specific benchmarks, neural techniques seem to match if not outperform human judgement, challenges are still open for detecting arbitrary concepts in arbitrary videos. In this paper, we propose a system that combines neural techniques, a large scale visual concepts ontology, and an active learning loop, to provide on the fly model learning of arbitrary concepts. We give an overview of the system as a whole, and focus on the central role of the ontology for guiding and bootstrapping the learning of new concepts, improving the recall of concept detection, and, on the user end, providing semantic search on a library of annotated videos.", "creator": "LaTeX with hyperref package"}}}