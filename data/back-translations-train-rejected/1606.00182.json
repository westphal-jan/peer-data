{"id": "1606.00182", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Jun-2016", "title": "On the Troll-Trust Model for Edge Sign Prediction in Social Networks", "abstract": "In the problem of edge sign classification, we are given a directed graph (representing an online social network), and our task is to predict the binary labels of the edges (i.e., the positive or negative nature of the social relationships). Many successful heuristics for this problem are based on the troll-trust features, estimating on each node the fraction of outgoing and incoming positive edges. We show that these heuristics can be understood, and rigorously analyzed, as approximators to the Bayes optimal classifier for a simple probabilistic model of the edge labels. We then show that the maximum likelihood estimator of this model approximately corresponds to the predictions of a label propagation algorithm run on a transformed version of the original social graph. Extensive experiments on a number of real-world datasets show that this algorithm is competitive against state-of-the-art classifiers in terms of both prediction performance and scalability. Finally, we show that troll-trust features can also be used to derive online learning algorithms which have theoretical guarantees even when edges are adversarially labeled.", "histories": [["v1", "Wed, 1 Jun 2016 09:16:46 GMT  (145kb,D)", "https://arxiv.org/abs/1606.00182v1", "16 pages, 1 figure, submitted to nips"], ["v2", "Thu, 2 Jun 2016 13:39:36 GMT  (145kb,D)", "http://arxiv.org/abs/1606.00182v2", "remove notice line at the bottom"], ["v3", "Fri, 17 Jun 2016 16:47:46 GMT  (144kb,D)", "http://arxiv.org/abs/1606.00182v3", "v3 minor typos"], ["v4", "Fri, 14 Oct 2016 09:39:59 GMT  (102kb,D)", "http://arxiv.org/abs/1606.00182v4", "v4: incorporate NIPS reviews and improve presentation"], ["v5", "Tue, 28 Feb 2017 21:33:41 GMT  (111kb,D)", "http://arxiv.org/abs/1606.00182v5", "v5: accepted to AISTATS 2017"]], "COMMENTS": "16 pages, 1 figure, submitted to nips", "reviews": [], "SUBJECTS": "cs.LG cs.SI", "authors": ["g\\'eraud le falher", "nicol\\`o cesa-bianchi", "claudio gentile", "fabio vitale"], "accepted": false, "id": "1606.00182"}, "pdf": {"name": "1606.00182.pdf", "metadata": {"source": "CRF", "title": "On the Troll-Trust Model for Edge Sign Prediction in Social Networks", "authors": ["G\u00e9raud Le Falher", "Nicol\u00f2 Cesa-Bianchi", "Claudio Gentile", "Fabio Vitale"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "In fact, it is the case that most of them are in a position to move to another world, in which they are able to move to another world, in which they are able to move to another world, in which they are able to move, in which they move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they, in which they live, in which they, in which they are able to move, in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they, in which they live, in which they, in which they live, in which they live, in which they live, in which they, in which they, in which they, in which they live, in which they, in which they, in which they, in which they live, in which they, in which they, in which they live, in which they, in which they, in which they, in which they, in which they are able to"}, {"heading": "1.1 Related work", "text": "The interest in signed networks can be traced back to the psychological theory of structural equilibrium [4, 12] with its weak version [10]. The advent of online signed social networks has enabled a more thorough and quantitative understanding of this phenomenon. Among the various approaches related to our work, some extend the spectral properties of a graph to the signed case in order to find good embeddings for classification [18, 33]. However, the use of the adjacent matrix usually requires a square runtime in the number of nodes, making these methods hardly scalable to large graphs. Another approach is based on mining ego networks with SVM. Although this method seems to provide good results, the runtime often makes them impractical for large real datasets. An alternative approach based only on local characteristics and proposed in an index [19] relies on the so-called status theory for predictive graphs, whereby a small problem [11] is applied in active learning."}, {"heading": "2 Notation and Preliminaries", "text": "In what follows, we make G = (V, E) be a directed graph whose edges (i, j) have a binary label (i, j). The edge label is sometimes collectively referred to as \"edge,\" while the corresponding edge label is referred to as \"edge\" (V, E, Y), where Yi, j and Eout (i) are referred to as \"edge label\" (V, E, Y). We use One (i) and Eout (i) as the label for \"edge\" (i, i), to designate the edge label \"edge\" (G) as \"edge\" (G) and \"edge\" (V, E, Y) as \"edge\" (G)."}, {"heading": "3 Generative Model for Edge Labels", "text": "We now define the stochastic generative model for edge labels that we use in the loose learning environment, in such a way that each node i-V is equipped with two latent parameters (pi, qi [0, 1], which we assume to be generated for each node i, by an independent draw from a fixed but unknown common prior distribution \u00b5 (p, q) over [0, 1] 2. Each label yi, j-1, + 1} is then generated by an independent draw from the mix of pi and qj, P (yi, j = 1) = pi + qj 2. The basic intuition is that the nature yi, j of a relationship i \u2192 j is by a mix between how many nodes i tend to resemble other people (pi), and how much part qi is empirical, that the nature i-j-i (j) is a specific, i-i-like network (1)."}, {"heading": "4 Algorithms in the Batch Setting", "text": "Since G (Y) = (V), E (Y)), we have a prediction that will give us (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D), (D)."}, {"heading": "4.1 Approximation to Maximum Likelihood via Label Propagation", "text": "For the sake of simplicity, we assume that the joint preceding distribution \u00b5 (p, q) is uniform over [0, 1] 2 = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = ="}, {"heading": "5 Algorithms in the Online Setting", "text": "For the online scenario, we have the following result.Theorem 2. There is a randomized online prediction algorithm A, whose expected error count satisfies EMA (Y) = ECG (Y) + O (\u221a | V | ECG (Y) + | V |) on each edge-designated chart G (Y) = (V, E (Y).The algorithm used in Theorem 2 is a combination of randomized weighted majority instances. Details are reported in the supplementary material.We supplement the above result by providing a lower error boundary. Like Theorem 2, the following result applies to all charts and to all label irregularity levels, such as G (Y).Theorem 3. Given each edge-designated chart G (Y) = (V, E (Y)) and each integer K \u2264 | E | 2 weeks, a randomized labeling Y = {\u2212 1,}."}, {"heading": "6 Experimental Analysis", "text": "We evaluate our label classification methods on representative real-world data sets of varying density and regularity, which show that our methods compete well with each other in both predictive and computerized performance; the first three are used as benchmarks for this task (e.g., [19, 26, 31]): In Wikipedia, there is an edge from user to user when choosing a position and against this promotion; in Slashdot, a news service and commenting website, I can label other members j as friends or opponents; and finally, in Epinion, a website where user j reviews products and another user i, we can show whether or not he j is reliable."}, {"heading": "7 Conclusions and Ongoing Research", "text": "In both cases, the underlying modeling assumption depends on trollness and (un) trustworthy prediction functions. We have introduced a simple generative model for edge labels to solve this problem as a node prediction problem that can be efficiently addressed by standard label propagation algorithms. In addition, we have investigated the problem in an (adverse) online setting that provides upper and (almost identical) lower limits to the expected number of prediction errors. Finally, we have validated our theoretical results by experimentally evaluating our methods using five real-world data sets within the small training set regime. Two interesting conclusions from our experiments are: i. Our generative model is robust as it produces optimal prediction functions that are empirically best when based on the larger set of models, such as trollness and truthfulness, which are not available in practice or alone."}, {"heading": "Acknowledgements", "text": "We would like to thank the reviewers for their comments, which have led to the improvement of the presentation of this essay."}, {"heading": "A Proofs from Section 4", "text": "The following clues are used: The following results are used in relation to the number of persons on the list of persons who are on the list of persons who are on the list of persons. (1) The following clues are used. (2) The following clues are used. (2) The following clues are used. (3) The following clues are used. (4) The clues are used. (4) The clues are used. (4) The clues are used. (4) The clues are used. (4) The clues are used. (4) The clues are used. (4) The clues are used. (4) The clues are used. (4) (4) The clues are used. (4) (4) The clues are used. (4) (4) The clues are used. (4) The clues are used. (4) (4) The clues are used. (4) The clues are used."}, {"heading": "B Proofs from Section 5", "text": "The estimated number of errors of the individual RWM instances will simply compete against the two constant experts, which will always be + 1 or always \u2212 1. Denote M (i, j) the indicator function (i, j) the indicator function (zero-one loss) of an error on edge (i, j) and then satisfy the expected number of errors of the individual RWM instances [2, 1]: [2, j] Nout (i) EM (i, Y) = out (i, Y) + O (i, Y) + O (1) and (i, j) EM (j) EM (i, j) EM (j) EM (i, Y)."}, {"heading": "C Further Experimental Results", "text": "This section contains further evidence related to the experiments in Section 6. In particular, we demonstrate experimentally the alignment between blc (tr, un) and LogReg.After training on the two characters 1 \u2212 t, r (i) and 1 \u2212 u, n (j), LogReg has learned three weights w0, w1 and w2, which allow to predict yi, j according to tosgn ((((w1 (1 \u2212 t, r (i))) + w2 (1 \u2212 u, n (j)) + w0), which can be rewritten as sgn (((1 \u2212 t, r (i)) + w \u00b2 2 (1 \u2212 u, n (j) \u2212 12 \u2212 \u03c4 \u2032), with w \u00b2 2 = w2 w1and then xi \u00b2 = \u2212 (1 2 + w0 w1)."}], "references": [{"title": "Adaptive and self-confident on-line learning algorithms", "author": ["P. Auer", "N. Cesa-Bianchi", "C. Gentile"], "venue": "J. Comput. Syst. Sci.,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2002}, {"title": "How to use expert advice", "author": ["N. Cesa-Bianchi", "Y. Freund", "D. Haussler", "D.P. Helmbold", "R.E. Schapire", "M.K. Warmuth"], "venue": "J. ACM,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1997}, {"title": "Concentration of Measure for the Analysis of Randomized Algorithms", "author": ["D.P. Dubhashi", "A. Panconesi"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2009}, {"title": "The weighted majority algorithm", "author": ["N. Littlestone", "M.K. Warmuth"], "venue": "Information and Computation,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1994}], "referenceMentions": [{"referenceID": 3, "context": "Interest in signed networks can be traced back to the psychological theory of structural balance [4, 12] with its weak version [10].", "startOffset": 97, "endOffset": 104}, {"referenceID": 2, "context": ", [3, 34, 13, 14, 7].", "startOffset": 2, "endOffset": 20}, {"referenceID": 1, "context": ", [34, 2]).", "startOffset": 2, "endOffset": 9}, {"referenceID": 0, "context": "Each node i \u2208 V is endowed with two latent parameters pi, qi \u2208 [0, 1], which we assume to be generated, for each node i, by an independent draw from a fixed but unknown joint prior distribution \u03bc(p, q) over [0, 1].", "startOffset": 63, "endOffset": 69}, {"referenceID": 0, "context": "Each node i \u2208 V is endowed with two latent parameters pi, qi \u2208 [0, 1], which we assume to be generated, for each node i, by an independent draw from a fixed but unknown joint prior distribution \u03bc(p, q) over [0, 1].", "startOffset": 207, "endOffset": 213}, {"referenceID": 0, "context": "1 Approximation to Maximum Likelihood via Label Propagation For simplicity, assume the joint prior distribution \u03bc(p, q) is uniform over [0, 1] with independent marginals, and suppose that we draw at random without replacement the training set E0 = ( (i1, j1), yi1,j1), ((i2, j2), yi2,j2), .", "startOffset": 136, "endOffset": 142}, {"referenceID": 0, "context": ", [1]), defined as", "startOffset": 2, "endOffset": 5}], "year": 2017, "abstractText": "In the problem of edge sign prediction, we are given a directed graph (representing a social network), and our task is to predict the binary labels of the edges (i.e., the positive or negative nature of the social relationships). Many successful heuristics for this problem are based on the troll-trust features, estimating at each node the fraction of outgoing and incoming positive/negative edges. We show that these heuristics can be understood, and rigorously analyzed, as approximators to the Bayes optimal classifier for a simple probabilistic model of the edge labels. We then show that the maximum likelihood estimator for this model approximately corresponds to the predictions of a Label Propagation algorithm run on a transformed version of the original social graph. Extensive experiments on a number of real-world datasets show that this algorithm is competitive against state-ofthe-art classifiers in terms of both accuracy and scalability. Finally, we show that trolltrust features can also be used to derive online learning algorithms which have theoretical guarantees even when edges are adversarially labeled.", "creator": "LaTeX with hyperref package"}}}