{"id": "1606.00372", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Jun-2016", "title": "Conversational Contextual Cues: The Case of Personalization and History for Response Ranking", "abstract": "We investigate the task of modeling open-domain, multi-turn, unstructured, multi-participant, conversational dialogue. We specifically study the effect of incorporating different elements of the conversation. Unlike previous efforts, which focused on modeling messages and responses, we extend the modeling to long context and participant's history. Our system does not rely on handwritten rules or engineered features; instead, we train deep neural networks on a large conversational dataset. In particular, we exploit the structure of Reddit comments and posts to extract 2.1 billion messages and 133 million conversations. We evaluate our models on the task of predicting the next response in a conversation, and we find that modeling both context and participants improves prediction accuracy.", "histories": [["v1", "Wed, 1 Jun 2016 18:01:14 GMT  (886kb,D)", "http://arxiv.org/abs/1606.00372v1", "10 pages, 6 figures"]], "COMMENTS": "10 pages, 6 figures", "reviews": [], "SUBJECTS": "cs.CL cs.LG", "authors": ["rami al-rfou", "marc pickett", "javier snaider", "yun-hsuan sung", "brian strope", "ray kurzweil"], "accepted": false, "id": "1606.00372"}, "pdf": {"name": "1606.00372.pdf", "metadata": {"source": "CRF", "title": "Conversational Contextual Cues: The Case of Personalization and History for Response Ranking", "authors": ["Rami Al-Rfou"], "emails": ["raykurzweil}@google.com"], "sections": [{"heading": "1 Introduction", "text": "This year it has come to the point where we are in a time in which we are in a time in which we are in a time in which we are in a time in which we are in a time in which we are in a time in which we are in a time in which we are in a time in which we are in a time in which we are in a time in which we are in a time in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which are in which we are in which we are in which we are in which we are in which we are in which we are in which we in which we are in which are in which we in which we are in which we are in which we in which are in which we are in which we in which we are in which we are in which we in which we are in which we in which we are in which we are in which we are in which are in which we are in which we in which we are in which we in which we are in which we in which we are in which we are in which we in which we are in which we are in which are in which we are in which we in which we are in which we in which we are in which we are in which we are in which we in which we are in which are in which we in which are in which we in which we in which we are in which are in which are in which we in which are in which we in which"}, {"heading": "2 Related Work", "text": "Ritter et al. (2010) proposed a data-driven approach to building dialogue systems, and they extracted 1.3 million conversations from Twitter with the goal of discovering dialogue files. Building on the distribution-specific similarities of the vector space model Frame-Work, Banchs and Li (2012) built a search engine to retrieve the most appropriate response for each input message. Other approaches focused on domain-specific tasks such as games (Narasimhan et al., 2015) and restaurants (Wen et al., 2016; Cuaya \u0301 huitl, 2016) Personalizing dialogue systems requires sufficient information from each user and a sufficient user population to define the space. Writing styles quantified by word length, verb strength, polarity, and distribution of dialogue files used for model users (Walker et al., 2012). Other efforts based on building a user profile, such as age, income, and family status."}, {"heading": "3 Reddit Dataset", "text": "Serban et al. (2015b) examined 56 data sets and found that only 9 have more than 100,000 conversations, of which only one has more than 5 million conversations, limiting the complexity and capacity of the models we can train. To target open domain conversations, we need larger data sets. So far, there have been limited efforts to exploit the rich structure of Reddit. For example, Schrading et al. (2015) extracted comments from a small number of subreddits to create a classifier that identifies domesticated content. Unlike the Ubuntu data sets, there are logs of technical chatrooms (Lowe et al., 2015), Reddit conversations tend to be more diverse in terms of topics and user backgrounds. There are more than 300,000 subforums (subreddits) with different discussion topics. Compared to Twitter, Reddit conversations we tend to comment on a natural message (we)."}, {"heading": "4 Models", "text": "We define a conversation C as a sequence of k pairs of messages and participants (authors) C \u2261 ((M1, A1), (M2, A2),.., (Mk, Ak). Here, a messageMi is a sequence of a variable number of words Mi = (wi1, wi2,.... wil). Ai andwj are random variables that record values in the user population Puser and the word vocabulary Vword.To represent messages, we use word technique via recursive or evolutionary networks for their speed and ability to scale to a dataset as large as Mdit."}, {"heading": "4.1 Response Ranking", "text": "In order to measure the effect of our characteristics on the modeling of conversations, our task is to select the best answer from a pool of random candidates. This selection process could be considered a ranking problem. There are several approaches to ranking: meaningful, pair-wise and list-wise (Liu, 2009). Kadlec et al. (2015) chose the pointwise ranking for its simplicity, and we follow the same choice for its speed advantages, which are necessary for training on hundreds of millions of examples. In the pointed ranking, we consider the compatibility of only one candidate at a time. Specifically, we learn a model that estimates the probability of a candidate being given a subset of the characteristics {I, C, A, R}. To construct the training dataset, we form pairs of characteristics and answers. For each answer occurring in the corpus, we form two pairs. The first consists of the characteristics with the observed newsponses ({I, C, A, R). In the second pair, we replace the random answer with the second one of the answers."}, {"heading": "4.2 Single-loss Network", "text": "Figure 3 shows a network concatenating the previous features to an input vector input = [I; C; A; R], followed by several hidden layers with relative nonlinearities to form a hidden layer h. Given the hidden layer h, we estimate the probability of the answer as follows: Pr (R | I, C, A) through (Wh + b) (2) Where \u03c3 is the sigmoid function \u03c3 (x) = 1 / (1 + e \u2212 x), we call this model a loss model because it allows prediction using all available information."}, {"heading": "4.3 Multi-loss Network", "text": "We can further formalize the previous single-loss model by declaring Pr (R | x) \u2248 R (R) \u2248 networks (x), where x is the input function vector. The network uses a logistic regression layer over a feeder neural network. Figure 4 shows the multi-loss architecture that could be considered a network of networks. This architecture is achieved by replicating the architecture of the single losses (network) three times for each feature. Each of the networks makes predictions based on each feature. In addition, each network produces a hidden layer (hi) that can be used in an entire network. The overall network concatenates the hidden layers from the previous networks, [h1; h2; h3] to generate a last hidden layer h4. This allows the final prediction to share all the features (hi). This network also allows us to measure the performance of each feature alone. This modular architecture facilitates the diagnosis of any possible problems during training."}, {"heading": "5 Experimental Setup", "text": "We extract 2.1 billion comments posted on the Reddit site between 2007 and 2015. We group the comments by their posting page and treat each Reddit post like a tree rooted in the title of the post. We generate a positive example from each comment in the post. Example functions are calculated by looking at the attributes of the message, its parent and ancestors in the tree. We exclude Reddit posts that have more than 1,000 comments for arithmetic reasons. Most of these large posts are \"megathreads,\" each containing hundreds of thousands of comments. We do not generate examples of comments with empty or missing input functions. We also exclude examples where the author is not in our user population or the user profile has been deleted. After filtering, there are 550 million positive examples. For each positive example, we generate a negative example by replacing the reply function with a random comment from Reddit."}, {"heading": "5.1 Vocabulary", "text": "Reddit comments are written in markdown markup language. First, we remove the markdown and then tokenize the text content. We normalize URLs and then insert the most common 200K unique items and 200K bigrams into our vocabulary. The number of least common unique items is 1229, and the least common 27670. To embed the author, we construct a user population (user) of the most frequently contributing 400K users. The least contributing user created 922 comments. This population is essentially a dictionary of usernames."}, {"heading": "5.2 Training", "text": "We set the ngram embedding and the user embedding space to 300 dimensions. The single loss model consists of one network, while the multiloss network consists of four networks. Each network consists of three hidden layers of size [500, 300, 100]. The hidden layer parameters, the ngram embedings and the user embedings are trained together, and we use stochastic gradient descent (SGD) to optimize the parameters of our models (Bottou, 1991). The derivatives are estimated using the backpropagation algorithm and the updates are applied asynchronously. The learning rate \u03b1 for SGD is set to 0.03. The models are implemented using TensorFlow (Abadi et al., 2015). Although each model is trained on 5 GPUs, the training time is still several weeks due to the data size."}, {"heading": "6 Discussion & Results", "text": "In this section, we discuss the benefits of integrating the conversation history and the history of the participants into our modelling. We compare both approaches and compare their qualities, and show a definitive model that uses both. We then show the impact of increasing the training data sets on the performance of our models."}, {"heading": "6.1 Length of the Context", "text": "How far back do we need to look to improve the quality of our ranking? To test this, we train both models discussed in Section 4 on multiple sets of data with temporally different context characteristics. Table 3 shows the precision @ 1 for both models using two different ranking tasks, the first comprising 10 candidates and the second 100 candidates. Context length 0 corresponds to the use of only the input message as a feature. Each model was trained and tested using examples that include a conversation history (context length) up to m number of messages and not necessarily all messages in the training or test contained the same length of history. First, we observe significant gains when we integrate the context feature (C). P @ 1 increases by 4-6 points the moment we include the message that preceded the input message. However, we see a decreasing return when the context increases, especially when the context is greater than 5 messages. In this case, two factors could be at work: First, the greater the number of messages we use, the greater the number of which we use in comparison, and secondly, the greater the number of messages we use in comparison, the smaller the number of which we use in comparison."}, {"heading": "6.2 Personalization", "text": "The multi-loss model improves by 5 points when 100 respondents are rated. The author vector represents longer historical information than the current conversation history. Personal history could include interests, opinions, demographics, writing style, and personality traits, which could be critical in determining whether an answer is appropriate. Finally, when we use all the traits at our disposal, we achieve a further performance improvement over all the traits used alone. This highlights that the information we gain from each trait is different."}, {"heading": "6.3 Multi-loss Vs Single-loss", "text": "The motivation behind the multi-loss model is to prevent adaptation between features (Hinton et al., 2012). In the single-loss model, the author's function could in many cases be subsumed with the input message and context. Only in subtle cases is it necessary to know the author's identity in order to determine whether the response is appropriate. This slows down the learning process of good author vectors. Therefore, the multi-loss network requires that the author vector alone should gather enough information to fulfill the prediction task. This architecture expands the idea of depth monitoring, where the accompanying objective function is introduced to train intermediate layers in a deep network (Lee et al., 2015). Note how the authoring function outperforms the context function in all tasks with the introduction of the multi-loss model. The multi-loss model is also easier to debug and investigate inthe network as each loss is not reported to us alone for the development of the network."}, {"heading": "6.4 New users", "text": "In our evaluation, we did not take into account the case of unknown users, but when our model meets a new user, we can add a randomly initialized vector as a temporary representation. As the conversation progresses, we can then refine the user vector by means of back propagation, while the other parameters of the model are fixed. This technique is similar to the strategy of the paragraph vector to deal with new paragraphs after completion of the training (Le and Mikolov, 2014)."}, {"heading": "6.5 Learning Curves", "text": "The results we have presented so far would not have been possible without the billions of examples we extracted from Reddit. It is quite clear that our models would have performed poorly given the other sets of data previously used due to their small size. Furthermore, the accuracy of the binary classifier correlates strongly with the P @ 1 of the rankings we rated. We found that the Pearson correlation between the accuracy observed on the Dev dataset and the P @ 1 of the ranking between + 0.94 and + 0.99 tested on the test dataset is both strong and positive, so we can infer future gains from enlarging the dataset on the quality of the ranking (see Figure 6b)."}, {"heading": "7 Conclusion", "text": "We train two scalable neural network models using Ngram embedding and user embedding. We measure significant improvements in selecting the next response by incorporating what has been said so far into the conversation. We study the impact of the length of the conversation history on performance. We also personalize the selection process by learning an identity trait for each user. This leads to further improvements as it models the longer history of what a user has said in all conversations. Finally, our multi-loss model shows improvements over the base model with only a loss using any subset of features."}], "references": [{"title": "Iris: a chat-oriented dialogue system based on the vector space model", "author": ["Banchs", "Li2012] Rafael E. Banchs", "Haizhou Li"], "venue": "In Proceedings of the ACL 2012 System Demonstrations,", "citeRegEx": "Banchs et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Banchs et al\\.", "year": 2012}, {"title": "Neural probabilistic language models", "author": ["Bengio et al.2006] Yoshua Bengio", "Holger Schwenk", "Jean-S\u00e9bastien Sen\u00e9cal", "Fr\u00e9deric Morin", "Jean-Luc Gauvain"], "venue": "In Innovations in Machine Learning,", "citeRegEx": "Bengio et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 2006}, {"title": "A context-aware nlp approach for noteworthiness detection in cellphone conversations", "author": ["Jose San Pedro", "Nuria Oliver"], "venue": "In COLING,", "citeRegEx": "Bonin et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bonin et al\\.", "year": 2014}, {"title": "Stochastic gradient learning in neural networks", "author": ["L\u00e9on Bottou"], "venue": "In Proceedings of NeuroN\u0131\u0302mes", "citeRegEx": "Bottou.,? \\Q1991\\E", "shortCiteRegEx": "Bottou.", "year": 1991}, {"title": "Simpleds: A simple deep reinforcement learning dialogue system", "author": ["Heriberto Cuay\u00e1huitl"], "venue": "CoRR, abs/1601.04574", "citeRegEx": "Cuay\u00e1huitl.,? \\Q2016\\E", "shortCiteRegEx": "Cuay\u00e1huitl.", "year": 2016}, {"title": "deltableu: A discriminative metric for generation tasks with intrinsically diverse targets", "author": ["Galley et al.2015] Michel Galley", "Chris Brockett", "Alessandro Sordoni", "Yangfeng Ji", "Michael Auli", "Chris Quirk", "Margaret Mitchell", "Jianfeng Gao", "Bill Dolan"], "venue": null, "citeRegEx": "Galley et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Galley et al\\.", "year": 2015}, {"title": "Improving neural networks by preventing co-adaptation of feature detectors. arXiv preprint arXiv:1207.0580", "author": ["Nitish Srivastava", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan R Salakhutdinov"], "venue": null, "citeRegEx": "Hinton et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2012}, {"title": "Convolutional neural network architectures for matching natural language sentences", "author": ["Baotian Hu", "Zhengdong Lu", "Hang Li", "Qingcai Chen"], "venue": null, "citeRegEx": "Hu et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hu et al\\.", "year": 2014}, {"title": "Improved deep learning", "author": ["Kadlec et al.2015] Rudolf Kadlec", "Martin Schmid", "Jan Kleindienst"], "venue": null, "citeRegEx": "Kadlec et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kadlec et al\\.", "year": 2015}, {"title": "Distributed representations of sentences and documents", "author": ["Le", "Mikolov2014] Quoc Le", "Tomas Mikolov"], "venue": "Proceedings of the 31st International Conference on Machine Learning", "citeRegEx": "Le et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Le et al\\.", "year": 2014}, {"title": "A diversitypromoting objective function for neural conversation models. arXiv preprint arXiv:1510.03055", "author": ["Li et al.2015] Jiwei Li", "Michel Galley", "Chris Brockett", "Jianfeng Gao", "Bill Dolan"], "venue": null, "citeRegEx": "Li et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Li et al\\.", "year": 2015}, {"title": "Learning to rank for information retrieval. Foundations and Trends in Information Retrieval, 3(3):225\u2013331", "author": ["Tie-Yan Liu"], "venue": null, "citeRegEx": "Liu.,? \\Q2009\\E", "shortCiteRegEx": "Liu.", "year": 2009}, {"title": "The ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dialogue systems. arXiv preprint arXiv:1506.08909", "author": ["Lowe et al.2015] Ryan Lowe", "Nissan Pow", "Iulian Serban", "Joelle Pineau"], "venue": null, "citeRegEx": "Lowe et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lowe et al\\.", "year": 2015}, {"title": "The parallel distributed processing approach to semantic cognition", "author": ["McClelland", "Rogers2003] James L McClelland", "Timothy T Rogers"], "venue": "Nature Reviews Neuroscience,", "citeRegEx": "McClelland et al\\.,? \\Q2003\\E", "shortCiteRegEx": "McClelland et al\\.", "year": 2003}, {"title": "Language understanding for text-based games using deep reinforcement learning", "author": ["Tejas Kulkarni", "Regina Barzilay"], "venue": "In Proceedings of the 2015 Conference on Empirical Methods in Natural", "citeRegEx": "Narasimhan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Narasimhan et al\\.", "year": 2015}, {"title": "Conversational language comprehension using integrated pattern-matching and parsing", "author": ["Kenneth Mark Colby", "William S Faught"], "venue": "Artificial Intelligence,", "citeRegEx": "Parkinson et al\\.,? \\Q1977\\E", "shortCiteRegEx": "Parkinson et al\\.", "year": 1977}, {"title": "Unsupervised modeling of twitter conversations", "author": ["Ritter et al.2010] Alan Ritter", "Colin Cherry", "Bill Dolan"], "venue": "In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics,", "citeRegEx": "Ritter et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Ritter et al\\.", "year": 2010}, {"title": "Deep learning in neural networks: An overview", "author": ["J\u00fcrgen Schmidhuber"], "venue": "Neural Networks,", "citeRegEx": "Schmidhuber.,? \\Q2015\\E", "shortCiteRegEx": "Schmidhuber.", "year": 2015}, {"title": "An analysis of domestic abuse discourse on reddit", "author": ["Cecilia Ovesdotter Alm", "Ray Ptucha", "Christopher Homan"], "venue": "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Schrading et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Schrading et al\\.", "year": 2015}, {"title": "Building end-to-end dialogue systems using generative hierarchical neural network models. arXiv preprint arXiv:1507.04808", "author": ["Alessandro Sordoni", "Yoshua Bengio", "Aaron Courville", "Joelle Pineau"], "venue": null, "citeRegEx": "Serban et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Serban et al\\.", "year": 2015}, {"title": "2015b. A survey of available corpora for building data-driven dialogue systems. arXiv preprint arXiv:1512.05742", "author": ["Ryan Lowe", "Laurent Charlin", "Joelle Pineau"], "venue": null, "citeRegEx": "Serban et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Serban et al\\.", "year": 2015}, {"title": "Neural responding machine for shorttext conversation", "author": ["Shang et al.2015] Lifeng Shang", "Zhengdong Lu", "Hang Li"], "venue": "arXiv preprint arXiv:1503.02364", "citeRegEx": "Shang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Shang et al\\.", "year": 2015}, {"title": "A neural network approach to context-sensitive generation of conversational responses", "author": ["Michel Galley", "Michael Auli", "Chris Brockett", "Yangfeng Ji", "Margaret Mitchell", "Jian-Yun Nie", "Jianfeng Gao", "Bill Dolan"], "venue": null, "citeRegEx": "Sordoni et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Sordoni et al\\.", "year": 2015}, {"title": "Sequence to sequence learning with neural networks. In Advances in neural information processing systems, pages 3104\u20133112", "author": ["Oriol Vinyals", "Quoc V Le"], "venue": null, "citeRegEx": "Sutskever et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "A neural conversational model. arXiv preprint arXiv:1506.05869", "author": ["Vinyals", "Le2015] Oriol Vinyals", "Quoc Le"], "venue": null, "citeRegEx": "Vinyals et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Vinyals et al\\.", "year": 2015}, {"title": "An annotated corpus of film dialogue for learning and characterizing character style", "author": ["Grace Lin", "Jennifer Sawyer"], "venue": null, "citeRegEx": "Walker et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Walker et al\\.", "year": 2012}, {"title": "The anatomy of ALICE", "author": ["Richard S Wallace"], "venue": null, "citeRegEx": "Wallace.,? \\Q2009\\E", "shortCiteRegEx": "Wallace.", "year": 2009}, {"title": "Elizaa computer program for the study of natural language communication between man and machine", "author": ["Joseph Weizenbaum"], "venue": "Communications of the ACM,", "citeRegEx": "Weizenbaum.,? \\Q1966\\E", "shortCiteRegEx": "Weizenbaum.", "year": 1966}, {"title": "A Network-based End-to-End Trainable Task-oriented Dialogue System. ArXiv eprints, April", "author": ["S. Young"], "venue": null, "citeRegEx": "Young.,? \\Q2016\\E", "shortCiteRegEx": "Young.", "year": 2016}, {"title": "Attention with intention for a neural network conversation model", "author": ["Yao et al.2015] Kaisheng Yao", "Geoffrey Zweig", "Baolin Peng"], "venue": "arXiv preprint arXiv:1510.08565", "citeRegEx": "Yao et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Yao et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 27, "context": "For decades, conversational agent design was dominated by systems that rely on knowledge bases and rule-based mechanisms to understand human inputs and generate reasonable responses (Weizenbaum, 1966; Parkinson et al., 1977; Wallace, 2009).", "startOffset": 182, "endOffset": 239}, {"referenceID": 15, "context": "For decades, conversational agent design was dominated by systems that rely on knowledge bases and rule-based mechanisms to understand human inputs and generate reasonable responses (Weizenbaum, 1966; Parkinson et al., 1977; Wallace, 2009).", "startOffset": 182, "endOffset": 239}, {"referenceID": 26, "context": "For decades, conversational agent design was dominated by systems that rely on knowledge bases and rule-based mechanisms to understand human inputs and generate reasonable responses (Weizenbaum, 1966; Parkinson et al., 1977; Wallace, 2009).", "startOffset": 182, "endOffset": 239}, {"referenceID": 10, "context": "Recent work in data-driven models focuses on modeling the next response as a function of the preceding message (Vinyals and Le, 2015; Li et al., 2015).", "startOffset": 111, "endOffset": 150}, {"referenceID": 16, "context": "Unlike previous efforts that used Twitter as a source of conversations (Ritter et al., 2010), Reddit does not have length constraints, allowing more natural text.", "startOffset": 71, "endOffset": 92}, {"referenceID": 1, "context": "We also jointly learn a shared word embedding space (Bengio et al., 2006) and a user embedding space.", "startOffset": 52, "endOffset": 73}, {"referenceID": 14, "context": "Other approaches focused on domain specific tasks such as games (Narasimhan et al., 2015) and restaurants (Wen et al.", "startOffset": 64, "endOffset": 89}, {"referenceID": 4, "context": ", 2015) and restaurants (Wen et al., 2016; Cuay\u00e1huitl, 2016)", "startOffset": 24, "endOffset": 60}, {"referenceID": 25, "context": "Writing styles quantified by word length, verb strength, polarity, and distribution of dialogue acts have been used to model users (Walker et al., 2012).", "startOffset": 131, "endOffset": 152}, {"referenceID": 2, "context": "Other efforts focused on building a user profile based on demographics, such as gender, income, age, and marital status (Bonin et al., 2014).", "startOffset": 120, "endOffset": 140}, {"referenceID": 23, "context": "With the introduction of the sequence-tosequence framework (Sutskever et al., 2014), many recent learning systems have used recurrent neural networks (RNNs) to generate novel responses given an input message or sentence.", "startOffset": 59, "endOffset": 83}, {"referenceID": 20, "context": "With the introduction of the sequence-tosequence framework (Sutskever et al., 2014), many recent learning systems have used recurrent neural networks (RNNs) to generate novel responses given an input message or sentence. For example, Vinyals and Le (2015) proposed using IT desk chat logs as a dataset to train LSTM network to generate new sentences.", "startOffset": 60, "endOffset": 256}, {"referenceID": 20, "context": "Sordoni et al. (2015) constructed Twitter conversations limiting the history context to one message.", "startOffset": 0, "endOffset": 22}, {"referenceID": 19, "context": "To eliminate the need for a language model, Serban et al. (2015a) tried end-to-end training on an RNN encoder-decoder network.", "startOffset": 44, "endOffset": 66}, {"referenceID": 10, "context": "Often responses gravitate to the most frequent sentences observed in the training corpus (Li et al., 2015).", "startOffset": 89, "endOffset": 106}, {"referenceID": 29, "context": "Perplexity, BLEU, and deltaBLEU, adapted from language modeling and machine translation communities, have been used for evaluating novel responses (Yao et al., 2015; Sordoni et al., 2015; Galley et al., 2015).", "startOffset": 147, "endOffset": 208}, {"referenceID": 22, "context": "Perplexity, BLEU, and deltaBLEU, adapted from language modeling and machine translation communities, have been used for evaluating novel responses (Yao et al., 2015; Sordoni et al., 2015; Galley et al., 2015).", "startOffset": 147, "endOffset": 208}, {"referenceID": 5, "context": "Perplexity, BLEU, and deltaBLEU, adapted from language modeling and machine translation communities, have been used for evaluating novel responses (Yao et al., 2015; Sordoni et al., 2015; Galley et al., 2015).", "startOffset": 147, "endOffset": 208}, {"referenceID": 21, "context": "While the search for better metrics is still on going, automatic evaluation of response generation stays an open problem (Shang et al., 2015).", "startOffset": 121, "endOffset": 141}, {"referenceID": 7, "context": "Typically, a positive response is mixed with random responses, and then the system is asked to score the right response higher than others (Hu et al., 2014; Kadlec et al., 2015).", "startOffset": 139, "endOffset": 177}, {"referenceID": 8, "context": "Typically, a positive response is mixed with random responses, and then the system is asked to score the right response higher than others (Hu et al., 2014; Kadlec et al., 2015).", "startOffset": 139, "endOffset": 177}, {"referenceID": 18, "context": "Serban et al. (2015b) surveyed 56 datasets and found that only 9 have more than 100,000 conversations, only one having more than 5 million conversations.", "startOffset": 0, "endOffset": 22}, {"referenceID": 18, "context": "For example, Schrading et al. (2015) extracted comments from a small number of subreddits to build a classifier that identifies domestic", "startOffset": 13, "endOffset": 37}, {"referenceID": 12, "context": "Unlike the Ubuntu dataset, logs of technical chat rooms (Lowe et al., 2015), Reddit conversations tend to be more diverse in regard to topics and user backgrounds.", "startOffset": 56, "endOffset": 75}, {"referenceID": 11, "context": "There are several approaches to ranking: pointwise, pairwise, and list-wise (Liu, 2009).", "startOffset": 76, "endOffset": 87}, {"referenceID": 8, "context": "Kadlec et al. (2015) chose pointwise ranking for its simplicity, and we follow the same choice for its speed benefits, which are necessary for training on hundreds of millions of examples.", "startOffset": 0, "endOffset": 21}, {"referenceID": 3, "context": "The hidden layer parameters, the ngram embeddings, and the user embeddings are trained jointly, and we use stochastic gradient descent (SGD) to optimize the parameters of our models (Bottou, 1991).", "startOffset": 182, "endOffset": 196}, {"referenceID": 6, "context": "The motivation behind the multi-loss model is to prevent adaptation between features (Hinton et al., 2012).", "startOffset": 85, "endOffset": 106}], "year": 2016, "abstractText": "We investigate the task of modeling opendomain, multi-turn, unstructured, multiparticipant, conversational dialogue. We specifically study the effect of incorporating different elements of the conversation. Unlike previous efforts, which focused on modeling messages and responses, we extend the modeling to long context and participant\u2019s history. Our system does not rely on handwritten rules or engineered features; instead, we train deep neural networks on a large conversational dataset. In particular, we exploit the structure of Reddit comments and posts to extract 2.1 billion messages and 133 million conversations. We evaluate our models on the task of predicting the next response in a conversation, and we find that modeling both context and participants improves prediction accuracy.", "creator": "LaTeX with hyperref package"}}}