{"id": "1606.00496", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Jun-2016", "title": "On the equivalence between Kolmogorov-Smirnov and ROC curve metrics for binary classification", "abstract": "Binary decisions are very common in artificial intelligence. Applying a threshold on the continuous score gives the human decider the power to control the operating point to separate the two classes. The classifier,s discriminating power is measured along the continuous range of the score by the Area Under the ROC curve (AUC_ROC) in most application fields. Only finances uses the poor single point metric maximum Kolmogorov-Smirnov (KS) distance. This paper proposes the Area Under the KS curve (AUC_KS) for performance assessment and proves AUC_ROC = 0.5 + AUC_KS, as a simpler way to calculate the AUC_ROC. That is even more important for ROC averaging in ensembles of classifiers or n fold cross-validation. The proof is geometrically inspired on rotating all KS curve to make it lie on the top of the ROC chance diagonal. On the practical side, the independent variable on the abscissa on the KS curve simplifies the calculation of the AUC_ROC. On the theoretical side, this research gives insights on probabilistic interpretations of classifiers assessment and integrates the existing body of knowledge of the information theoretical ROC approach with the proposed statistical approach based on the thoroughly known KS distribution.", "histories": [["v1", "Wed, 1 Jun 2016 23:12:53 GMT  (607kb)", "http://arxiv.org/abs/1606.00496v1", "5 pages, 5 figures"]], "COMMENTS": "5 pages, 5 figures", "reviews": [], "SUBJECTS": "cs.AI cs.CV", "authors": ["paulo j l adeodato", "s\\'ilvio b melo"], "accepted": false, "id": "1606.00496"}, "pdf": {"name": "1606.00496.pdf", "metadata": {"source": "CRF", "title": "On the equivalence between Kolmogorov-Smirnov and ROC curve metrics for binary classification", "authors": ["Paulo J. L. Adeodato", "S\u00edlvio B. Melo"], "emails": ["pjla@cin.ufpe.br", "sbm@cin.ufpe.br"], "sections": [{"heading": null, "text": "The differentiation capability of the classifier is measured along the continuous scoring range by the Area Under the ROC curve (AUC _ ROC) in most fields of application. Only the finances use the poor one-point metric Kolmogorov-Smirnov (KS) distance. This paper suggests the Area Under the KS curve (AUC _ KS) for performance evaluation and assigns AUC _ ROC = 0.5 + AUC _ KS as a simpler method for calculating AUC _ ROC. This is even more important for ROC averaging in ensembles of classifiers or the n-fold cross validation. The proof is geometrically inspired by the rotation of all KS curves to leave it lying at the top of the ROC probability diagonal. On the practical side, the independent variable Binfier is on the KS curve."}, {"heading": "1. INTRODUCTION", "text": "In the business world, one of the most common decision-making strategies for selecting suitable persons or objects for an action is to calculate them according to a given key [1], which is used in applications such as personnel selection, fraud detection and allocation of resources in public administration. Assigning them to a group of variables based on human definitions is fundamental, since it is a group of people who occupy a particular position."}, {"heading": "2. BINARY CLASSIFICATION PERFORMANCE METRICS", "text": "For a universal binary classifier to be used in a decision support system, its response should be continuous to give the decision maker the power to control the impact of the decision. Classifiers that make \"hard\" decisions by already presenting the predicted class are not the focus of this research due to their lack of control flexibility. Classifiers of interest here represent a multi-dimensional input space into a scalar (the scalar) through which the decision maker sets the decision threshold to create the two classes based on the business KPIs. For this study, the quality of the classifier is evaluated by comparing the predicted class for each sample of a test for all potential decision thresholds with the true class. Consequently, performance assessment metrics should cover at least one area of this scale in the region that is of interest for decision-making. [1] Threshold specific metrics such as error rates are not sufficient to assess the quality of these flexible classifiers."}, {"heading": "2.1 ROC Curve", "text": "The ROC curve [6] is a non-parametric performance evaluation tool that represents the trade-off between the true positive rate (TP) and the false positive rate (FP) of sample classifications based on a continuous output along all of its possible decision thresholds (the score). In the medical field, the ROC curve expresses the trade-off between sensitivity and specificity (in fact, 1 specificity) equivalent. Although the ROC curve is capable of delivering single-point and area-related performance indicators, this work focuses on the latter (AUC _ ROC), which is independent of the operating point or any other specific point. It is a performance indicator that is valid for assessing performance over the entire continuous value range [6-8]. Given the binary decision on the continuous range, the larger the AUC _ ROC, the closer the system is to the ideal classifier (AUC _ ROC = 1)."}, {"heading": "2.2 Kolmogorov-Smirnov Distribution", "text": "The Kolmogorov-Smirnov distribution was originally conceived as a hypotheses test for adjusting the distribution to data [5]. In binary classification problems, it was used as a dissimilarity metric to assess the discriminatory performance of the classifier, which measures the distance its score generates between the cumulative distribution functions (CDFs) of the two data classes [4,7], known as KS2 for this purpose (two samples). The usual metric for both purposes is the maximum vertical difference between the CDFs (Max _ KS), which is immutable to scale the score range and scale for classification comparisons. However, this is an assessment at a single operating point, which generally does not meet the needs of the applications. Thus, the first author [9] proposed to adjust the Kolmogorov-Smirnov metric for scaling that is invariable."}, {"heading": "3. THE PROOF OF EQUIVALENCE OF THE AREAS UNDER THE CURVES", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Inspiration", "text": "The research on the equivalence of surfaces was inspired both by the effectiveness of metrics in binary decision problems and by their geometric similarity, taking into account rotation and axial expansion and reduction, as illustrated in Figure 3. The conceptual equivalence between the abscissa in the KS curve (x-axis) and the random diagonal in the ROC curve was the basis of the argumentation. An important aspect that helped in the analysis was the limit case of the ideal classifier. This is the classifier that distinguishes all examples from the target class from those from those from the complementary class. It is clear that the AUC _ ROC is equal to one, while the AUC _ KS is defined by a triangle that reaches the maximum height (1), making the AUC _ KS = 0.5. However, Figure 2 shows that the AUC _ KS is defined by the non-oscillating triangle, whose asymmetry depends on the unbalance of classes."}, {"heading": "3.2 Proof of Equivalence", "text": "This year, it is time for the Presidency of the Council of the European Union to move to the EU in order to leave the Presidency of the Council of the European Union."}, {"heading": "3.3 Equivalence for the Single Point Metrics", "text": "Taking into account the same transformation matrix from the previous subsection, the single point metric corresponding to the Max _ KS2 in the ROC curve would be the maximum distance from the probability diagonal. However, since the distances are mapped orthogonally to the x-axis with a shrinkage factor \u221a 2, the Max _ KS2 projection is reduced to Max _ KS2 / \u221a 2 in the ROC curve. Conceptually, this point metric evaluates the maximum dissimilarity with the classifier, who randomly sorts samples from the test sample. Krzanowski and Hand have already demonstrated the equivalence in the value of the single point metrics [7] MVD (or Youden Index) on the ROC curve with the difference Max _ KS2 on the KS curve. Strictly speaking, however, this is not conceptually equivalent to the Max _ KS2 scale as a single point metrix. To illustrate, let us look at a scale of nine using an example of 0.2."}, {"heading": "4. CONCLUSIONS", "text": "In fact, it is the case that most of them are able to move in order to move, and that they are able to move in order to move."}, {"heading": "5. REFERENCES", "text": "[1] Provost, F. and Fawcett Kolmogorov, T. 2013. Data Science for business.O'Reilly Media Inc., Sebastopol, CA. [2] Bolton, R. J. and Hand, D. J. 2002. Statistical Fraud Detection: A Review, Extras. Sci., 17 (3), pp. 235-255.DOI = http: / / dx.doi.org / 10.1214 / ss / 1042727940. [3] West, D. 2000. Neural network credit scoring models. Computers and Operations Research, 27, pp. 1131-1152, DOI = http: / / dx.doi.org / 10.1016 / S0272727940. (99) Conover, W. J. J. 1999. Practical Nonparametric Statistics, (3rd ed.), John Wiley & Sons, New York, NY."}], "references": [{"title": "Data Science for business", "author": ["F. Provost", "T. Fawcett"], "venue": "O \u0301Reilly Media Inc.,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2013}, {"title": "Neural network credit scoring models", "author": ["D. West"], "venue": "Computers and Operations Research,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2000}, {"title": "Practical Nonparametric Statistics, (3 ed.)", "author": ["W.J. Conover"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1999}, {"title": "Sulla determinazione empirica di una legge di distribuzione", "author": ["A.N. Kolmogorov"], "venue": "Giornale dell\u2019Istituto Italiano degli Attuari,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1933}, {"title": "Robust Classification for Imprecise Environments", "author": ["F. Provost", "T. Fawcett"], "venue": "Machine Learning Journal,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2001}, {"title": "ROC Curves For Continuous Data, Chapman and Hall/CRC", "author": ["W.J. Krzanowski", "D.J. Hand"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2009}, {"title": "An introduction to ROC analysis", "author": ["T. Fawcett"], "venue": "Patt. Recognition Lett", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2006}, {"title": "The Power of Sampling and Stacking for the PAKDD-2007 Cross-Selling Problem", "author": ["P.J.L. Adeodato", "Vasconcelos", "G. C"], "venue": "Int. Jour. Data War. Mining,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2008}, {"title": "The Role of Temporal Feature Extraction and Bagging of MLP Neural Networks for Solving the WCCI 2008 Ford Classification Challenge", "author": ["P.J.L. Adeodato", "Arnaud", "A. L"], "venue": "Proceedings of the International Joint Conference on Neural Networks", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2008}, {"title": "Continuous variables segmentation and reordering for optimal performance on binary classification tasks", "author": ["P.J.L. Adeodato", "D.S.P. Salazar", "L.S. Gallindo", "A.G. S\u00e1", "S.M. Souza"], "venue": "Proceedings of the International Joint Conference on Neural Networks", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "Linear Algebra and Its Applications, 4 ed., Thomson Books/Cole", "author": ["G. Strang"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2006}, {"title": "The theory of signal detectability", "author": ["W.W. Peterson", "T.G. Birdsall", "W.C. Fox"], "venue": "Proc. of the IRE Professional Group on Information Theory", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1954}, {"title": "ROC confidence bands: an empirical evaluation", "author": ["S.A. Macskassy", "F. Provost", "S. Rosset"], "venue": "Proc. 22 international conference on Machine learning,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2005}], "referenceMentions": [{"referenceID": 0, "context": "INTRODUCTION In business, one of the most common decision strategies for selecting the eligible individuals or objects for an action is ranking them according to a classification score and choosing those above a pre-defined threshold [1].", "startOffset": 234, "endOffset": 237}, {"referenceID": 0, "context": "the classifier \u0301s technical performance but also on the business Key Performance Indicators (KPIs) [1].", "startOffset": 99, "endOffset": 102}, {"referenceID": 0, "context": "Receiver Operating Characteristics (AUC_ROC) [1] became so popular among scientists for binary classification quality assessment, instead of confusion matrix, error rates, maximum Vertical Distance of the ROC curve, maximum KolmogorovSmirnov vertical difference and all other single point specific metrics.", "startOffset": 45, "endOffset": 48}, {"referenceID": 1, "context": "Despite being used in financial applications [3] as dissimilarity metric [4] to assess continuous score classifier performance, the maximum Kolmogorov-Smirnov vertical difference (Max_KS2) is constrained to a specific point which rarely fits the business requirements.", "startOffset": 45, "endOffset": 48}, {"referenceID": 2, "context": "Despite being used in financial applications [3] as dissimilarity metric [4] to assess continuous score classifier performance, the maximum Kolmogorov-Smirnov vertical difference (Max_KS2) is constrained to a specific point which rarely fits the business requirements.", "startOffset": 73, "endOffset": 76}, {"referenceID": 3, "context": "consolidated statistical knowledge for hypothesis testing [5].", "startOffset": 58, "endOffset": 61}, {"referenceID": 4, "context": "ROC curve [6] by proving that AUC_KS = AUC_ROC \uf02d 0.", "startOffset": 10, "endOffset": 13}, {"referenceID": 0, "context": "with some advantages over one the most widely accepted performance metrics for binary classifiers (AUC_ROC) [1,7].", "startOffset": 108, "endOffset": 113}, {"referenceID": 5, "context": "with some advantages over one the most widely accepted performance metrics for binary classifiers (AUC_ROC) [1,7].", "startOffset": 108, "endOffset": 113}, {"referenceID": 0, "context": "Consequently, the performance assessment metrics should also cover at least a range of this scalar in the region of interest for decision making [1].", "startOffset": 145, "endOffset": 148}, {"referenceID": 4, "context": "1 ROC Curve The ROC Curve [6] is a non-parametric performance assessment tool that represents the compromise between the true positive rate (TP) and the false positive rate (FP) of example classifications based on a continuous output along all its possible decision", "startOffset": 26, "endOffset": 29}, {"referenceID": 4, "context": "a performance indicator valid for assessing the performance throughout the whole continuous range of scores [6-8].", "startOffset": 108, "endOffset": 113}, {"referenceID": 5, "context": "a performance indicator valid for assessing the performance throughout the whole continuous range of scores [6-8].", "startOffset": 108, "endOffset": 113}, {"referenceID": 6, "context": "a performance indicator valid for assessing the performance throughout the whole continuous range of scores [6-8].", "startOffset": 108, "endOffset": 113}, {"referenceID": 5, "context": "the ROC curve to the chance diagonal that is used as single point metric of performance assessment, which has already been proven equivalent to the Maximum Kolmogorov-Smirnov difference (Max_KS) [7].", "startOffset": 195, "endOffset": 198}, {"referenceID": 3, "context": "to data [5].", "startOffset": 8, "endOffset": 11}, {"referenceID": 2, "context": "In binary classification problems, it has been used as dissimilarity metric for assessing the classifier \u0301s discriminant power measuring the distance that its score produces between the cumulative distribution functions (CDFs) of the two data classes [4,7], known as KS2 for this purpose (two samples).", "startOffset": 251, "endOffset": 256}, {"referenceID": 5, "context": "In binary classification problems, it has been used as dissimilarity metric for assessing the classifier \u0301s discriminant power measuring the distance that its score produces between the cumulative distribution functions (CDFs) of the two data classes [4,7], known as KS2 for this purpose (two samples).", "startOffset": 251, "endOffset": 256}, {"referenceID": 7, "context": "So the first author has proposed [9] an adaptation of the", "startOffset": 33, "endOffset": 36}, {"referenceID": 8, "context": "Both KS-based metrics have also been applied to assess the quality of continuous input variables [10].", "startOffset": 97, "endOffset": 101}, {"referenceID": 9, "context": "The same author has also proposed an algorithm for input variable transformation optimization [11] based on the Max_KS2 metric.", "startOffset": 94, "endOffset": 98}, {"referenceID": 10, "context": "It should be noticed that area is invariant under this transformation, since its determinant equals one [12]:", "startOffset": 104, "endOffset": 108}, {"referenceID": 10, "context": "Therefore, lengths and angles are not invariant under this transformation (as it should be expected when anisotropic scaling and shearing are involved) [12].", "startOffset": 152, "endOffset": 156}, {"referenceID": 5, "context": "value of the single point metrics [7] MVD (or the Youden Index) on the ROC curve with the Max_KS2 difference on the KS curve.", "startOffset": 34, "endOffset": 37}, {"referenceID": 2, "context": "This result is very important once that it has put at the scientists\u2019 disposal for performance assessment of binary classification all the consolidated statistical knowledge on the KolmogorovSmirnov distribution available since 1933 [4].", "startOffset": 233, "endOffset": 236}, {"referenceID": 11, "context": "That is over 20 years before the ROC analysis had been used in telecommunications [14] and much longer before its debut in artificial intelligence.", "startOffset": 82, "endOffset": 86}, {"referenceID": 8, "context": "Despite not having a formal proof before, the first author had already detected the numerical equivalence between these metrics and had been applying the Kolmogorov-Smirnov distribution as optimization criterion for embedding statistical knowledge in variables transformations [10].", "startOffset": 277, "endOffset": 281}, {"referenceID": 4, "context": "For the ROC, one has to choose either vertical averaging or threshold averaging [6].", "startOffset": 80, "endOffset": 83}, {"referenceID": 4, "context": "Threshold averaging involves the return to the scores for thresholding at specific sample quantiles, and the calculation of error-bars in both coordinates at each point, as detailed in reference [6].", "startOffset": 195, "endOffset": 198}, {"referenceID": 12, "context": "That is a much simpler, yet precise, approach than those analysed in [15].", "startOffset": 69, "endOffset": 73}], "year": 2016, "abstractText": "Binary decisions are very common in artificial intelligence. Applying a threshold on the continuous score gives the human decider the power to control the operating point to separate the two classes. The classifier\u2019s discriminating power is measured along the continuous range of the score by the Area Under the ROC curve (AUC_ROC) in most application fields. Only finances uses the poor single point metric maximum Kolmogorov-Smirnov (KS) distance. This paper proposes the Area Under the KS curve (AUC_KS) for performance assessment and proves AUC_ROC = 0.5 + AUC_KS, as a simpler way to calculate the AUC_ROC. That is even more important for ROC averaging in ensembles of classifiers or n-fold cross-validation. The proof is geometrically inspired on rotating all KS curve to make it lie on the top of the ROC chance diagonal. On the practical side, the independent variable on the abscissa on the KS curve simplifies the calculation of the AUC_ROC. On the theoretical side, this research gives insights on probabilistic interpretations of classifiers assessment and integrates the existing body of knowledge of the information theoretical ROC approach with the proposed statistical approach based on the thoroughly known KS distribution.", "creator": "Microsoft\u00ae Word 2010"}}}