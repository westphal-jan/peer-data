{"id": "1606.00611", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Jun-2016", "title": "Recursive Autoconvolution for Unsupervised Learning of Convolutional Neural Networks", "abstract": "In visual recognition tasks, supervised learning shows excellent performance. On the other hand, unsupervised learning exploits cheap unlabeled data and can help to solve the same tasks more efficiently. We show that the recursive autoconvolutional operator, adopted from physics, boosts existing unsupervised methods to learn more powerful filters. We use a well established multilayer convolutional network and train filters layer-wise. To build a stronger classifier, we design a very light committee of SVM models. The total number of trainable parameters is also greatly reduced by using shared filters in higher layers. We evaluate our networks on the MNIST, CIFAR-10 and STL-10 benchmarks and report several state of the art results among other unsupervised methods.", "histories": [["v1", "Thu, 2 Jun 2016 10:37:46 GMT  (449kb,D)", "http://arxiv.org/abs/1606.00611v1", null], ["v2", "Sun, 26 Mar 2017 18:31:05 GMT  (321kb,D)", "http://arxiv.org/abs/1606.00611v2", "8 pages, accepted to International Joint Conference on Neural Networks (IJCNN 2017)"]], "reviews": [], "SUBJECTS": "cs.CV cs.LG cs.NE", "authors": ["boris knyazev", "erhardt barth", "thomas martinetz"], "accepted": false, "id": "1606.00611"}, "pdf": {"name": "1606.00611.pdf", "metadata": {"source": "CRF", "title": "Autoconvolution for Unsupervised Feature Learning", "authors": ["Boris Knyazev", "Erhardt Barth"], "emails": ["bknyazev@bmstu.ru", "barth@inb.uni-luebeck.de", "martinetz@inb.uni-luebeck.de", "borknyaz@gmail.com"], "sections": [{"heading": "1 Introduction", "text": "It is true that in real-world applications, it does not really matter what methods are used to achieve the desired result, but in some cases labeling can be an expensive process. On the other hand, natural data is full of abstract properties that have nothing to do with object classes. Unsupervised learning takes advantage of abundant amounts of this cheap, unlabeled data and can help perform the same tasks more efficiently. In general, unsupervised learning is important to move toward artificial intelligence [1]. Another drawback of verified methods and some of the recent unsupervised developments [2, 3, 4] is their overuse of data."}, {"heading": "2 Related Work", "text": "Unsupervised learning is often used as an additional regulator in the form of weight initializations [17] or reconstruction costs [18, 19], or as an independent visual model trained on still images [3, 14] or image sequences [5]. However, to a greater extent, our method is related to another set of work [6, 7, 9, 10, 12] and in particular [11, 4], in which filters (or some basis) are learned in layers and where no backward movement, fine-tuning or data augmentation is used. The only exceptions are [4, 2] in which image transformations are used."}, {"heading": "3 Autoconvolution", "text": "We first describe the routine for processing arbitrary discrete data on the basis of auto-evolution. It is convenient to look at auto-evolution in the frequency domain. According to the convolution theorem, for N-dimensional discrete signals X and Y, such as images (N = 2): F (X \u0445 Y) = kF (X) \u0445 F (Y), where F - the N-dimensional discrete Fourier transformation (DFT), \u0445 - the N-dimensional inverse DFT product, k - is a normalization coefficient (which is further ignored because we apply normalization thereafter). Therefore, auto-evolution is defined as X-dimensional discrete Fourier transformation (DFT), (1) where F \u2212 1 - is the N-dimensional inverse DFT. Due to the squared frequencies, phase information is mixed and the inverse operation is poorly positioned. Much work has been devoted to this problem, e.g. [23]."}, {"heading": "3.1 Recursive Autoconvolution", "text": "We adopt the recursive autoconvotive operator previously proposed in [25] by simply extending (1): Xn = Xn \u2212 1 \u0445 Xn \u2212 1 = F \u2212 1 (F (Xn \u2212 1) 2), (2) where n = [0, nmax] - an index of recursive iteration (or autoconvotional order) - if n = 0, X0 matches the input, i.e. a raw field of view. n = 1 expression (2) equals (1). In our work, we limit nmax = 4 because higher orders do not lead to better classification results.In [25], image patterns extracted with this operator are used for parametric description of images. In this work, we use extracted patterns as convolution cores, i.e. filters, because we have noticed that applying (2) with n > 1 to images sparse wavelength patterns, which are normally learned by a CNN at the first level."}, {"heading": "4 Autoconvolutional Multilayer Architecture", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Learning Filters", "text": "The basic method for unattended filter learning is chosen to be k-means as in [11, 4]. Specifically, for some layer l of an AutoCNN and for some training samples we have inputs X (l) into a subset of training samples, where Kl \u2212 1 - the number of filters (or channels) in the previous layer. To learn filters for this layer l, we take random inputs X (l), patches and filters in n-order to apply recursive auto-revolution (2), where dl - the depth of the filters is \u2264 Kl \u2212 1 due to the grouping described in Section 4.4 below. Only square inputs, patches and filters are taken into account for reasons of simplicity. To learn more powerful filters, we take results from multiple jobs (e.g. in the case n = [0, 3] we have four patches instead of 1) and combine them to form a global set of revolutionary patches."}, {"heading": "4.2 Preprocessing and Convolution", "text": "For image preprocessing, we use standard techniques such as ZCA whitening and standardization 2 with few modifications. First, we only weld colored data sets and only in the first layer because it is not useful for such clean grayscale images as in MNIST. Second, unlike [11] or [7], where global or local normalization techniques are used, we use batch standardization (i.e. the entire stack is treated as a single vector) with a typical batch size of 125 to split the data set into equal stacks."}, {"heading": "4.3 Response Rectification, Normalization and Pooling", "text": "We are experimenting with two popular rectifiers applied to filter reactions: Max (0, x) (or ReLU), which is used by default (unless otherwise stated), and Absolute Values | x |. Between layers, we are using Local Contrast Normalization (LCN), as in [4]. Subsequently, a simple Max Pooling method is used over square (ml-sized) fragmented spatial regions within a characteristic map. Furthermore, the non-linear \"Rootsift\" normalization (sign (x) \u221a | x | / \u0441\u0441\u04422) applied after pooling has been shown to be beneficial for colored datasets. This normalization and LCN are only used to report final classification results."}, {"heading": "4.4 Selecting Connections between Layers", "text": "In CNNs trained with reverse propagation, the depth dl of the filters typically corresponds to the number of filters in the previous layer, i.e. dl = Kl \u2212 1. Alternatively, connections between feature cards and filters can be sparse [13] or can be learned together with network weights [11]. For unsupervised learning methods such as k-means, it is difficult to learn discriminatory filters if dl is too high (e.g. 64 in [15]). Therefore, in this work we are following the practice established in unsupervised CNNs [11, 4] to divide feature cards into relatively small groups, so that filters D (l), Rsl \u00b7 dl \u00b7 dl \u00b7 Kl \u00b7 Kl are learned independently for each group, where dl \u2212 1 convolutions are linked for all groups, so that answers of the size al / ml \u00b7 al / ml \u00b7 ngKl are passed on to the next layer."}, {"heading": "4.5 Dimension Reduction and Classification", "text": "In this work, we first apply the main component analysis (PCA) together with whitening and then train a classifier on the projected data. For particularly large characteristics (> 30k and up to 300k in our experiments), random PCA [26] proved extremely useful.For classification, we use an SVM with the RBF kernel with a one-on-one multiclase variant (unless otherwise specified).Characteristic vectors are standardized before classification. In all experiments, the SVM regularization constant was C = 16. The width of the RBF kernel was chosen as \u03b3 = 1 / pj, where pj is the dimensionality of the projected characteristic vector, the input of the SVM (see also the next section).For better final classification results for CIFAR-10 and STL-10, we also apply a One-vs-All-GU method (very efficient)."}, {"heading": "4.6 SVM Committee", "text": "In this thesis, we form a committee of J-models with only one set of filters, so that the models in the committee are determined only by their SVM. Filters, PCA matrix and other parameters are set for all models. After the images have been processed with a learned AutoCNN, PCA is executed once and pj, j = 1,..., J first main components are selected. Subsequently, for each j, an SVM is trained on the characteristics projected onto the first main components of the pj. After all iterations j are completed, the SVM values are averaged within the committee."}, {"heading": "5 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Experimental Setup", "text": "We evaluate our method against several image classification benchmarks: MNIST [13], CIFAR-10 [14], and STL-10 [7]. To show that unattended learning is particularly effective for data sets with few training samples, such as STL-10, which has only 100 images per class, we test our method on smaller versions of MNIST and CIFAR-10, namely MNIST (100), MNIST (300), and CIFAR-10 (400), each with only 100, 300, and 400 images per class. We use the same experimental protocol as in previous work, e.g. [11, 3]: average results and their standard interpretations for the test set using 10 random subsets (folds) from the training set. For STL-10, these folds are predefined. While in previous work, all labeled training samples are typically used as blank data during unattended learning, we determine that all of the samples suggested are sufficient to confirm with most of the 10k samples."}, {"heading": "5.2 Model Parameters Validation", "text": "In fact, it is the case that most people are able to survive by themselves if they do not see themselves as being able to survive and survive by themselves, and that they are able to survive by themselves. \"(S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S."}, {"heading": "5.3 Multilayer Performance", "text": "In fact, it is that we see ourselves as being able to hold our own, that we are able to put ourselves at the top, and that we are able to hold our own, that we are able to put ourselves at the top, \"he said."}, {"heading": "6 Conclusion", "text": "The importance of unsupervised learning in visual tasks is increasing, and development is being driven by the need to make better use of vast amounts of unlabeled data. We propose a novel unsupervised learning method and report superior results on several image classification tasks among the tasks that are not based on data enlargement or supervised fine tuning. We use recursive auto-revolution and demonstrate its great utility for unsupervised learning methods such as k-means and ICA. We argue that it can be integrated into other learning methods, including recently developed Convolutionary Clustering, to enhance its performance as recursive auto-evolution uncovers complex image patterns. In addition, we significantly reduce the total number of traceable parameters through the use of common filters and propose a simple method to build a committee of SVM models. As a result, the proposed autoconvolutionary network works better than most unsupervised and multiple supervised models in different classification tasks with only a few, but also thousands of random samples."}, {"heading": "Acknowledgments", "text": "This work is supported jointly by the German Academic Exchange Service (DAAD) and the Ministry of Education and Science of the Russian Federation (project number 3708)."}], "references": [{"title": "Direct modeling of complex invariances for visual object features", "author": ["Ka Y Hui"], "venue": "In ICML,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2013}, {"title": "Discriminative unsupervised feature learning with convolutional neural networks", "author": ["Alexey Dosovitskiy", "Jost Tobias Springenberg", "Martin Riedmiller", "Thomas Brox"], "venue": "In NIPS,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2014}, {"title": "Committees of deep feedforward networks trained with few data", "author": ["Bogdan Miclut"], "venue": "In Pattern Recognition,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "Unsupervised learning of visual representations using videos", "author": ["Xiaolong Wang", "Abhinav Gupta"], "venue": "In Proceedings of the IEEE International Conference on Computer Vision,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "Simple method for high-performance digit recognition based on sparse coding", "author": ["Kai Labusch", "Erhardt Barth", "Thomas Martinetz"], "venue": "Neural Networks, IEEE Transactions on,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1985}, {"title": "An analysis of single-layer networks in unsupervised feature learning", "author": ["Adam Coates", "Andrew Y Ng", "Honglak Lee"], "venue": "In International conference on artificial intelligence and statistics,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2011}, {"title": "The importance of encoding versus training with sparse coding and vector quantization", "author": ["Adam Coates", "Andrew Y Ng"], "venue": "In ICML,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2011}, {"title": "Selecting receptive fields in deep networks", "author": ["Adam Coates", "Andrew Y Ng"], "venue": "In NIPS,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2011}, {"title": "ICA with reconstruction cost for efficient overcomplete feature learning", "author": ["Quoc V Le", "Alexandre Karpenko", "Jiquan Ngiam", "Andrew Y Ng"], "venue": "In NIPS,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2011}, {"title": "Convolutional clustering for unsupervised learning", "author": ["Aysegul Dundar", "Jonghoon Jin", "Eugenio Culurciello"], "venue": "arXiv preprint arXiv:1511.06241v2,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2016}, {"title": "Stable and efficient representation learning with nonnegativity constraints", "author": ["Tsung-Han Lin", "HT Kung"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2014}, {"title": "Gradient-based learning applied to document recognition", "author": ["Yann LeCun", "L\u00e9on Bottou", "Yoshua Bengio", "Patrick Haffner"], "venue": "Proceedings of the IEEE,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1998}, {"title": "Learning multiple layers of features from tiny", "author": ["Alex Krizhevsky", "Geoffrey Hinton"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2009}, {"title": "Stochastic pooling for regularization of deep convolutional neural networks", "author": ["Matthew D Zeiler", "Rob Fergus"], "venue": "arXiv preprint arXiv:1301.3557,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2013}, {"title": "Convolutional kernel networks", "author": ["Julien Mairal", "Piotr Koniusz", "Zaid Harchaoui", "Cordelia Schmid"], "venue": "In NIPS,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2014}, {"title": "An analysis of unsupervised pre-training in light of recent advances", "author": ["Tom Le Paine", "Pooya Khorrami", "Wei Han", "Thomas S Huang"], "venue": "arXiv preprint arXiv:1412.6597,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2014}, {"title": "Stacked what-where auto-encoders", "author": ["Junbo Zhao", "Michael Mathieu", "Ross Goroshin", "Yann Lecun"], "venue": "arXiv preprint arXiv:1506.02351,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2015}, {"title": "Semi-supervised learning with ladder networks", "author": ["Antti Rasmus", "Mathias Berglund", "Mikko Honkala", "Harri Valpola", "Tapani Raiko"], "venue": "In NIPS,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2015}, {"title": "Fast and robust fixed-point algorithms for independent component analysis", "author": ["Aapo Hyv\u00e4rinen"], "venue": "Neural Networks, IEEE Transactions on,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1999}, {"title": "Fast convolutional sparse coding", "author": ["Hilton Bristow", "Anders Eriksson", "Simon Lucey"], "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2013}, {"title": "The inversion of autoconvolution integrals", "author": ["V Dose", "Th Fauster", "H-J Gossmann"], "venue": "Journal of Computational Physics,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1981}, {"title": "On autoconvolution and regularization", "author": ["Rudolf Gorenflo", "Bernd Hofmann"], "venue": "Inverse Problems,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1994}, {"title": "Multi-scale auto-convolution for affine invariant pattern recognition", "author": ["Janne Heikkil\u00e4"], "venue": "In Pattern Recognition,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2002}, {"title": "Convolutional sparse coding for static and dynamic images analysis", "author": ["BA Knyazev", "VM Chernenkiy"], "venue": "Science & Education of Bauman MSTU/Nauka i Obrazovanie of Bauman MSTU,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2014}, {"title": "Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions", "author": ["Nathan Halko", "Per-Gunnar Martinsson", "Joel A Tropp"], "venue": "SIAM review,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2011}, {"title": "A GPU-tailored approach for training kernelized SVMs", "author": ["Andrew Cotter", "Nathan Srebro", "Joseph Keshet"], "venue": "In SIGKDD,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2011}, {"title": "Unsupervised feature learning with C-SVDDNet", "author": ["Dong Wang", "Xiaoyang Tan"], "venue": "arXiv preprint arXiv:1412.7259,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2014}, {"title": "Winner-take-all autoencoders", "author": ["Alireza Makhzani", "Brendan J Frey"], "venue": "In NIPS, pages 2773\u20132781,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2015}, {"title": "Uncertainty relation for resolution in space, spatial frequency, and orientation optimized by two-dimensional visual cortical filters", "author": ["John G Daugman"], "venue": "JOSA A,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 1985}, {"title": "VLFeat: An open and portable library of computer vision algorithms", "author": ["Andrea Vedaldi", "Brian Fulkerson"], "venue": "In Proceedings of the 18th ACM international conference on Multimedia,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2010}, {"title": "MatConvNet: Convolutional neural networks for matlab", "author": ["Andrea Vedaldi", "Karel Lenc"], "venue": "In Proceedings of the 23rd Annual ACM Conference on Multimedia Conference,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "Another drawback of supervised methods and some recent unsupervised developments [2, 3, 4] is their excessive use of data augmentation.", "startOffset": 81, "endOffset": 90}, {"referenceID": 1, "context": "Another drawback of supervised methods and some recent unsupervised developments [2, 3, 4] is their excessive use of data augmentation.", "startOffset": 81, "endOffset": 90}, {"referenceID": 2, "context": "Another drawback of supervised methods and some recent unsupervised developments [2, 3, 4] is their excessive use of data augmentation.", "startOffset": 81, "endOffset": 90}, {"referenceID": 3, "context": ", by \"watching\" videos [5].", "startOffset": 23, "endOffset": 26}, {"referenceID": 4, "context": "We improve on the previous works in which network filters (or weights) are learned layer-wise without label information [6, 7, 8, 9, 10, 11, 4, 12].", "startOffset": 120, "endOffset": 147}, {"referenceID": 5, "context": "We improve on the previous works in which network filters (or weights) are learned layer-wise without label information [6, 7, 8, 9, 10, 11, 4, 12].", "startOffset": 120, "endOffset": 147}, {"referenceID": 6, "context": "We improve on the previous works in which network filters (or weights) are learned layer-wise without label information [6, 7, 8, 9, 10, 11, 4, 12].", "startOffset": 120, "endOffset": 147}, {"referenceID": 7, "context": "We improve on the previous works in which network filters (or weights) are learned layer-wise without label information [6, 7, 8, 9, 10, 11, 4, 12].", "startOffset": 120, "endOffset": 147}, {"referenceID": 8, "context": "We improve on the previous works in which network filters (or weights) are learned layer-wise without label information [6, 7, 8, 9, 10, 11, 4, 12].", "startOffset": 120, "endOffset": 147}, {"referenceID": 9, "context": "We improve on the previous works in which network filters (or weights) are learned layer-wise without label information [6, 7, 8, 9, 10, 11, 4, 12].", "startOffset": 120, "endOffset": 147}, {"referenceID": 2, "context": "We improve on the previous works in which network filters (or weights) are learned layer-wise without label information [6, 7, 8, 9, 10, 11, 4, 12].", "startOffset": 120, "endOffset": 147}, {"referenceID": 10, "context": "We improve on the previous works in which network filters (or weights) are learned layer-wise without label information [6, 7, 8, 9, 10, 11, 4, 12].", "startOffset": 120, "endOffset": 147}, {"referenceID": 5, "context": "These methods are particularly suitable for the tasks with only few labeled training samples, such as STL-10 [7], as well as variants of MNIST [13] and CIFAR-10 [14] with smaller training sets.", "startOffset": 109, "endOffset": 112}, {"referenceID": 11, "context": "These methods are particularly suitable for the tasks with only few labeled training samples, such as STL-10 [7], as well as variants of MNIST [13] and CIFAR-10 [14] with smaller training sets.", "startOffset": 143, "endOffset": 147}, {"referenceID": 12, "context": "These methods are particularly suitable for the tasks with only few labeled training samples, such as STL-10 [7], as well as variants of MNIST [13] and CIFAR-10 [14] with smaller training sets.", "startOffset": 161, "endOffset": 165}, {"referenceID": 13, "context": "propagation on thousands of labeled samples [15, 16].", "startOffset": 44, "endOffset": 52}, {"referenceID": 14, "context": "propagation on thousands of labeled samples [15, 16].", "startOffset": 44, "endOffset": 52}, {"referenceID": 15, "context": "Unsupervised learning is used quite often as an additional regularizer in the form of weights initialization [17] or reconstruction cost [18, 19], or as an independent visual model trained on still images [3, 14] or image sequences [5].", "startOffset": 109, "endOffset": 113}, {"referenceID": 16, "context": "Unsupervised learning is used quite often as an additional regularizer in the form of weights initialization [17] or reconstruction cost [18, 19], or as an independent visual model trained on still images [3, 14] or image sequences [5].", "startOffset": 137, "endOffset": 145}, {"referenceID": 17, "context": "Unsupervised learning is used quite often as an additional regularizer in the form of weights initialization [17] or reconstruction cost [18, 19], or as an independent visual model trained on still images [3, 14] or image sequences [5].", "startOffset": 137, "endOffset": 145}, {"referenceID": 1, "context": "Unsupervised learning is used quite often as an additional regularizer in the form of weights initialization [17] or reconstruction cost [18, 19], or as an independent visual model trained on still images [3, 14] or image sequences [5].", "startOffset": 205, "endOffset": 212}, {"referenceID": 12, "context": "Unsupervised learning is used quite often as an additional regularizer in the form of weights initialization [17] or reconstruction cost [18, 19], or as an independent visual model trained on still images [3, 14] or image sequences [5].", "startOffset": 205, "endOffset": 212}, {"referenceID": 3, "context": "Unsupervised learning is used quite often as an additional regularizer in the form of weights initialization [17] or reconstruction cost [18, 19], or as an independent visual model trained on still images [3, 14] or image sequences [5].", "startOffset": 232, "endOffset": 235}, {"referenceID": 4, "context": "However, to a larger extent, our method is related to another series of works [6, 7, 8, 9, 10, 2, 12] and, in particular, [11, 4], in which filters (or some basis) are learned layer-wise and, contrary to the methods above, neither backpropagation, fine tuning nor data augmentation is used.", "startOffset": 78, "endOffset": 101}, {"referenceID": 5, "context": "However, to a larger extent, our method is related to another series of works [6, 7, 8, 9, 10, 2, 12] and, in particular, [11, 4], in which filters (or some basis) are learned layer-wise and, contrary to the methods above, neither backpropagation, fine tuning nor data augmentation is used.", "startOffset": 78, "endOffset": 101}, {"referenceID": 6, "context": "However, to a larger extent, our method is related to another series of works [6, 7, 8, 9, 10, 2, 12] and, in particular, [11, 4], in which filters (or some basis) are learned layer-wise and, contrary to the methods above, neither backpropagation, fine tuning nor data augmentation is used.", "startOffset": 78, "endOffset": 101}, {"referenceID": 7, "context": "However, to a larger extent, our method is related to another series of works [6, 7, 8, 9, 10, 2, 12] and, in particular, [11, 4], in which filters (or some basis) are learned layer-wise and, contrary to the methods above, neither backpropagation, fine tuning nor data augmentation is used.", "startOffset": 78, "endOffset": 101}, {"referenceID": 8, "context": "However, to a larger extent, our method is related to another series of works [6, 7, 8, 9, 10, 2, 12] and, in particular, [11, 4], in which filters (or some basis) are learned layer-wise and, contrary to the methods above, neither backpropagation, fine tuning nor data augmentation is used.", "startOffset": 78, "endOffset": 101}, {"referenceID": 0, "context": "However, to a larger extent, our method is related to another series of works [6, 7, 8, 9, 10, 2, 12] and, in particular, [11, 4], in which filters (or some basis) are learned layer-wise and, contrary to the methods above, neither backpropagation, fine tuning nor data augmentation is used.", "startOffset": 78, "endOffset": 101}, {"referenceID": 10, "context": "However, to a larger extent, our method is related to another series of works [6, 7, 8, 9, 10, 2, 12] and, in particular, [11, 4], in which filters (or some basis) are learned layer-wise and, contrary to the methods above, neither backpropagation, fine tuning nor data augmentation is used.", "startOffset": 78, "endOffset": 101}, {"referenceID": 9, "context": "However, to a larger extent, our method is related to another series of works [6, 7, 8, 9, 10, 2, 12] and, in particular, [11, 4], in which filters (or some basis) are learned layer-wise and, contrary to the methods above, neither backpropagation, fine tuning nor data augmentation is used.", "startOffset": 122, "endOffset": 129}, {"referenceID": 2, "context": "However, to a larger extent, our method is related to another series of works [6, 7, 8, 9, 10, 2, 12] and, in particular, [11, 4], in which filters (or some basis) are learned layer-wise and, contrary to the methods above, neither backpropagation, fine tuning nor data augmentation is used.", "startOffset": 122, "endOffset": 129}, {"referenceID": 2, "context": "The only exceptions are [4, 2], in which image transformations are used.", "startOffset": 24, "endOffset": 30}, {"referenceID": 0, "context": "The only exceptions are [4, 2], in which image transformations are used.", "startOffset": 24, "endOffset": 30}, {"referenceID": 5, "context": "In these works, learning filters with clustering methods, such as k-means, is a standard approach [7, 2, 12, 4, 11].", "startOffset": 98, "endOffset": 115}, {"referenceID": 0, "context": "In these works, learning filters with clustering methods, such as k-means, is a standard approach [7, 2, 12, 4, 11].", "startOffset": 98, "endOffset": 115}, {"referenceID": 10, "context": "In these works, learning filters with clustering methods, such as k-means, is a standard approach [7, 2, 12, 4, 11].", "startOffset": 98, "endOffset": 115}, {"referenceID": 2, "context": "In these works, learning filters with clustering methods, such as k-means, is a standard approach [7, 2, 12, 4, 11].", "startOffset": 98, "endOffset": 115}, {"referenceID": 9, "context": "In these works, learning filters with clustering methods, such as k-means, is a standard approach [7, 2, 12, 4, 11].", "startOffset": 98, "endOffset": 115}, {"referenceID": 8, "context": "Moreover, clustering methods can learn overcomplete dictionaries without additional modifications, such as done for ICA in [10].", "startOffset": 123, "endOffset": 127}, {"referenceID": 18, "context": "Nevertheless, since ICA [20] is also a common practice to learn filters, we conduct a couple of simple experiments with this method to probe our novel idea more thoroughly.", "startOffset": 24, "endOffset": 28}, {"referenceID": 4, "context": "In contrast to various coding schemes [6, 7, 8, 9, 12], popular in unsupervised learning, our forward pass is built upon a well established supervised method - a multilayer convolutional network [13] and its rectifying and pooling blocks.", "startOffset": 38, "endOffset": 54}, {"referenceID": 5, "context": "In contrast to various coding schemes [6, 7, 8, 9, 12], popular in unsupervised learning, our forward pass is built upon a well established supervised method - a multilayer convolutional network [13] and its rectifying and pooling blocks.", "startOffset": 38, "endOffset": 54}, {"referenceID": 6, "context": "In contrast to various coding schemes [6, 7, 8, 9, 12], popular in unsupervised learning, our forward pass is built upon a well established supervised method - a multilayer convolutional network [13] and its rectifying and pooling blocks.", "startOffset": 38, "endOffset": 54}, {"referenceID": 7, "context": "In contrast to various coding schemes [6, 7, 8, 9, 12], popular in unsupervised learning, our forward pass is built upon a well established supervised method - a multilayer convolutional network [13] and its rectifying and pooling blocks.", "startOffset": 38, "endOffset": 54}, {"referenceID": 10, "context": "In contrast to various coding schemes [6, 7, 8, 9, 12], popular in unsupervised learning, our forward pass is built upon a well established supervised method - a multilayer convolutional network [13] and its rectifying and pooling blocks.", "startOffset": 38, "endOffset": 54}, {"referenceID": 11, "context": "In contrast to various coding schemes [6, 7, 8, 9, 12], popular in unsupervised learning, our forward pass is built upon a well established supervised method - a multilayer convolutional network [13] and its rectifying and pooling blocks.", "startOffset": 195, "endOffset": 199}, {"referenceID": 9, "context": "Recently, this framework was successfully transfered to unsupervised learning in [11, 4].", "startOffset": 81, "endOffset": 88}, {"referenceID": 2, "context": "Recently, this framework was successfully transfered to unsupervised learning in [11, 4].", "startOffset": 81, "endOffset": 88}, {"referenceID": 9, "context": "For instance, in [11], k-means is enhanced by introducing convolutional clustering.", "startOffset": 17, "endOffset": 21}, {"referenceID": 19, "context": ", convolutional sparse coding [21].", "startOffset": 30, "endOffset": 34}, {"referenceID": 20, "context": "Autoconvolution (or self-convolution) and its properties seem to be first analyzed in physics (in spectroscopy [22]) and later in function optimization [23] as the problem of deautoconvolution arose.", "startOffset": 111, "endOffset": 115}, {"referenceID": 21, "context": "Autoconvolution (or self-convolution) and its properties seem to be first analyzed in physics (in spectroscopy [22]) and later in function optimization [23] as the problem of deautoconvolution arose.", "startOffset": 152, "endOffset": 156}, {"referenceID": 22, "context": "This operator also appeared in visual tasks to extract invariant patterns [24].", "startOffset": 74, "endOffset": 78}, {"referenceID": 23, "context": "But, to the best of our knowledge, its recursive version, used as a pillar in this work, was first suggested in [25] for parametric description of images and temporal sequences.", "startOffset": 112, "endOffset": 116}, {"referenceID": 21, "context": ", [23].", "startOffset": 2, "endOffset": 6}, {"referenceID": 23, "context": "We adopt the recursive autoconvoution operator, proposed earlier in [25] by simple extension of (1):", "startOffset": 68, "endOffset": 72}, {"referenceID": 23, "context": "In [25], image patterns extracted using this operator were used for parametric description of images.", "startOffset": 3, "endOffset": 7}, {"referenceID": 14, "context": "filters, because we noticed that applying (2) with n > 1 to images provides sparse wavelet like patterns, which are usually learned by a CNN in the first layer (see [16], Fig.", "startOffset": 165, "endOffset": 169}, {"referenceID": 3, "context": "3 or [5], Fig.", "startOffset": 5, "endOffset": 8}, {"referenceID": 9, "context": "The baseline method for unsupervised filter learning is chosen to be k-means as in [11, 4].", "startOffset": 83, "endOffset": 90}, {"referenceID": 2, "context": "The baseline method for unsupervised filter learning is chosen to be k-means as in [11, 4].", "startOffset": 83, "endOffset": 90}, {"referenceID": 1, "context": ", in case n = [0, 3] we have 4", "startOffset": 14, "endOffset": 20}, {"referenceID": 12, "context": "In this global set, all patches are first scaled to have values in the range [0,1] , then they are ZCA-whitened as in [14, 7, 9, 11, 4].", "startOffset": 118, "endOffset": 135}, {"referenceID": 5, "context": "In this global set, all patches are first scaled to have values in the range [0,1] , then they are ZCA-whitened as in [14, 7, 9, 11, 4].", "startOffset": 118, "endOffset": 135}, {"referenceID": 7, "context": "In this global set, all patches are first scaled to have values in the range [0,1] , then they are ZCA-whitened as in [14, 7, 9, 11, 4].", "startOffset": 118, "endOffset": 135}, {"referenceID": 9, "context": "In this global set, all patches are first scaled to have values in the range [0,1] , then they are ZCA-whitened as in [14, 7, 9, 11, 4].", "startOffset": 118, "endOffset": 135}, {"referenceID": 2, "context": "In this global set, all patches are first scaled to have values in the range [0,1] , then they are ZCA-whitened as in [14, 7, 9, 11, 4].", "startOffset": 118, "endOffset": 135}, {"referenceID": 9, "context": "Second, in contrast to [11] or [7], where global or local normalization techniques are used, we use batch standardization (i.", "startOffset": 23, "endOffset": 27}, {"referenceID": 5, "context": "Second, in contrast to [11] or [7], where global or local normalization techniques are used, we use batch standardization (i.", "startOffset": 31, "endOffset": 34}, {"referenceID": 2, "context": "Between layers we use local contrast normalization (LCN), as in [4].", "startOffset": 64, "endOffset": 67}, {"referenceID": 11, "context": "Alternatively, connections between feature maps and filters can also be sparse [13] or learned along with the network weights [11].", "startOffset": 79, "endOffset": 83}, {"referenceID": 9, "context": "Alternatively, connections between feature maps and filters can also be sparse [13] or learned along with the network weights [11].", "startOffset": 126, "endOffset": 130}, {"referenceID": 13, "context": ", 64 in [15]).", "startOffset": 8, "endOffset": 12}, {"referenceID": 9, "context": "Therefore, in this work, we follow the practice, established in unsupervised CNNs [11, 4], to divide feature maps into ng relatively small groups, so that filters D \u2208 Rsl\u00d7sl\u00d7dl\u00d7Kl are learned independently for each group, where dl Kl\u22121.", "startOffset": 82, "endOffset": 89}, {"referenceID": 2, "context": "Therefore, in this work, we follow the practice, established in unsupervised CNNs [11, 4], to divide feature maps into ng relatively small groups, so that filters D \u2208 Rsl\u00d7sl\u00d7dl\u00d7Kl are learned independently for each group, where dl Kl\u22121.", "startOffset": 82, "endOffset": 89}, {"referenceID": 9, "context": "Contrary to [11, 4], where feature groups are formed randomly or learned in a supervised fashion, we use the approach from [9].", "startOffset": 12, "endOffset": 19}, {"referenceID": 2, "context": "Contrary to [11, 4], where feature groups are formed randomly or learned in a supervised fashion, we use the approach from [9].", "startOffset": 12, "endOffset": 19}, {"referenceID": 7, "context": "Contrary to [11, 4], where feature groups are formed randomly or learned in a supervised fashion, we use the approach from [9].", "startOffset": 123, "endOffset": 126}, {"referenceID": 8, "context": "This way, we try to find a compromise between diversity of filters and their connectivity to each other, which is necessary to form invariant groups [10].", "startOffset": 149, "endOffset": 153}, {"referenceID": 9, "context": "But as we apply a multidictionary approach similarly to [11, 12], this is not an issue, because eventually features from all layers are concatenated and fed to a classifier.", "startOffset": 56, "endOffset": 64}, {"referenceID": 10, "context": "But as we apply a multidictionary approach similarly to [11, 12], this is not an issue, because eventually features from all layers are concatenated and fed to a classifier.", "startOffset": 56, "endOffset": 64}, {"referenceID": 9, "context": "In [11], fully connected layers with dropout are trained on top of the unsupervised features.", "startOffset": 3, "endOffset": 7}, {"referenceID": 24, "context": "For particularly large features (>30k and up to 300k in our experiments) random PCA [26] turned out to be extremely useful.", "startOffset": 84, "endOffset": 88}, {"referenceID": 25, "context": "For better final classification results for CIFAR-10 and STL-10, we also apply a one-vs-all method (we use a very efficient GPU implementation from [27]).", "startOffset": 148, "endOffset": 152}, {"referenceID": 2, "context": "A committee of models tends to give better classification results [4].", "startOffset": 66, "endOffset": 69}, {"referenceID": 11, "context": "We evaluate our method on several image classification benchmarks: MNIST [13], CIFAR-10 [14] and STL-10 [7].", "startOffset": 73, "endOffset": 77}, {"referenceID": 12, "context": "We evaluate our method on several image classification benchmarks: MNIST [13], CIFAR-10 [14] and STL-10 [7].", "startOffset": 88, "endOffset": 92}, {"referenceID": 5, "context": "We evaluate our method on several image classification benchmarks: MNIST [13], CIFAR-10 [14] and STL-10 [7].", "startOffset": 104, "endOffset": 107}, {"referenceID": 9, "context": "[11, 3]: average results, and their standard deviations on the test set using 10 random subsets (folds) from the training set, are reported.", "startOffset": 0, "endOffset": 7}, {"referenceID": 1, "context": "[11, 3]: average results, and their standard deviations on the test set using 10 random subsets (folds) from the training set, are reported.", "startOffset": 0, "endOffset": 7}, {"referenceID": 1, "context": "raw (n = 0); n = 1; n = 2; n = 3; n = [1, 3]; n = [0, 3]", "startOffset": 38, "endOffset": 44}, {"referenceID": 1, "context": "raw (n = 0); n = 1; n = 2; n = 3; n = [1, 3]; n = [0, 3]", "startOffset": 50, "endOffset": 56}, {"referenceID": 8, "context": "Nevertheless, our results without whitening and with whitening applied only to filters are very relevant in practice, because in some tasks whitening of inputs is difficult to be performed or not applicable [10], e.", "startOffset": 207, "endOffset": 211}, {"referenceID": 28, "context": "6) in the ranges pj = [50, 400] for MNIST and pj = [30, 1500] for colored datasets gains another 0.", "startOffset": 51, "endOffset": 61}, {"referenceID": 1, "context": "In all experiments with 2 layer networks, for layer 1 we use combinations n = [1, 3] for MNIST and n = [0, 4] for others, while for layer 2 we found n = [2, 3] to be optimal.", "startOffset": 78, "endOffset": 84}, {"referenceID": 2, "context": "In all experiments with 2 layer networks, for layer 1 we use combinations n = [1, 3] for MNIST and n = [0, 4] for others, while for layer 2 we found n = [2, 3] to be optimal.", "startOffset": 103, "endOffset": 109}, {"referenceID": 0, "context": "In all experiments with 2 layer networks, for layer 1 we use combinations n = [1, 3] for MNIST and n = [0, 4] for others, while for layer 2 we found n = [2, 3] to be optimal.", "startOffset": 153, "endOffset": 159}, {"referenceID": 1, "context": "In all experiments with 2 layer networks, for layer 1 we use combinations n = [1, 3] for MNIST and n = [0, 4] for others, while for layer 2 we found n = [2, 3] to be optimal.", "startOffset": 153, "endOffset": 159}, {"referenceID": 9, "context": "In previous works [11, 4], filters of higher layers are distinct for each group (learned independently), i.", "startOffset": 18, "endOffset": 25}, {"referenceID": 2, "context": "In previous works [11, 4], filters of higher layers are distinct for each group (learned independently), i.", "startOffset": 18, "endOffset": 25}, {"referenceID": 9, "context": "To exploit features from both layers, the multidictionary approach is employed as in [11, 12].", "startOffset": 85, "endOffset": 93}, {"referenceID": 10, "context": "To exploit features from both layers, the multidictionary approach is employed as in [11, 12].", "startOffset": 85, "endOffset": 93}, {"referenceID": 17, "context": "For the full tests on MNIST and CIFAR-10 we report the average for 10 independent tests (as done, for instance, in [19]) and, in addition, the results of averaging the SVM scores of all J \u00d7 10 models (denoted as \"comb\").", "startOffset": 115, "endOffset": 119}, {"referenceID": 4, "context": "Model MNIST (100) MNIST (comb) 1-2 Layer, unsupervised, no data augmentation Sparse coding (169) [6] \u2212 0.", "startOffset": 97, "endOffset": 100}, {"referenceID": 26, "context": "59 C-SVDDNet (400+multiscale+SIFT) [28] \u2212 0.", "startOffset": 35, "endOffset": 39}, {"referenceID": 27, "context": "35 CONV-WTA (128-2048) [29] 1.", "startOffset": 23, "endOffset": 27}, {"referenceID": 17, "context": "Supervised and semi-supervised state of the art Ladder Network (full cost)[19] 0.", "startOffset": 74, "endOffset": 78}, {"referenceID": 14, "context": "02 Kernel CNN (12-400) [16] 2.", "startOffset": 23, "endOffset": 27}, {"referenceID": 9, "context": "(96-1536) [11] 2.", "startOffset": 10, "endOffset": 14}, {"referenceID": 13, "context": "5 Stochastic pooling (64-64-64) [15] \u223c 4.", "startOffset": 32, "endOffset": 36}, {"referenceID": 17, "context": "The only exception seems to be Ladder Networks [19], which are much larger and deeper than our models and use a supervised cost.", "startOffset": 47, "endOffset": 51}, {"referenceID": 26, "context": "Also, in [28] better results are achieved for MNIST with a single layer, but in our experience it can be quite easy to fine tune to such a simple task.", "startOffset": 9, "endOffset": 13}, {"referenceID": 10, "context": "For STL-10 comparable results are obtained in [12, 28], however our model has several times fewer features compared to [12], while in [28] the most important model component is handcrafted SIFT features, whereas we learn features from data.", "startOffset": 46, "endOffset": 54}, {"referenceID": 26, "context": "For STL-10 comparable results are obtained in [12, 28], however our model has several times fewer features compared to [12], while in [28] the most important model component is handcrafted SIFT features, whereas we learn features from data.", "startOffset": 46, "endOffset": 54}, {"referenceID": 10, "context": "For STL-10 comparable results are obtained in [12, 28], however our model has several times fewer features compared to [12], while in [28] the most important model component is handcrafted SIFT features, whereas we learn features from data.", "startOffset": 119, "endOffset": 123}, {"referenceID": 26, "context": "For STL-10 comparable results are obtained in [12, 28], however our model has several times fewer features compared to [12], while in [28] the most important model component is handcrafted SIFT features, whereas we learn features from data.", "startOffset": 134, "endOffset": 138}, {"referenceID": 14, "context": "Our single layer model is especially effective for CIFAR-10, for which we obtain an accuracy better than in all previous multilayer unsupervised models (without data augmentation) and even better than a two layer CNN [16].", "startOffset": 217, "endOffset": 221}, {"referenceID": 1, "context": "It is also superior than many other supervised and unsupervised models, including a large 3 layer CNN in [3] (in case of full data), which relies on excessive data augmentation and a 3 layer supervised CNN [15] based on an advanced pooling scheme.", "startOffset": 105, "endOffset": 108}, {"referenceID": 13, "context": "It is also superior than many other supervised and unsupervised models, including a large 3 layer CNN in [3] (in case of full data), which relies on excessive data augmentation and a 3 layer supervised CNN [15] based on an advanced pooling scheme.", "startOffset": 206, "endOffset": 210}, {"referenceID": 6, "context": "Model CIFAR-10 (400) CIFAR-10 (comb) STL-10 1-3 Layer, unsupervised, no data augmentation Sparse coding/OMP (1600/6000) [8] 66.", "startOffset": 120, "endOffset": 123}, {"referenceID": 7, "context": "8 [9] 81.", "startOffset": 2, "endOffset": 5}, {"referenceID": 10, "context": "8 NOMP-20 (3200-6400-6400) [12] 72.", "startOffset": 27, "endOffset": 31}, {"referenceID": 26, "context": "6 C-SVDDNet (500+multiscale+SIFT) [28] \u2212 \u2212 68.", "startOffset": 34, "endOffset": 38}, {"referenceID": 9, "context": "(96-1536) [11] \u2212 \u2212 65.", "startOffset": 10, "endOffset": 14}, {"referenceID": 27, "context": "4 CONV-WTA (256-1024-4096) [29] \u2212 80.", "startOffset": 27, "endOffset": 31}, {"referenceID": 2, "context": "Supervised, semi-supervised or with data augmentation state of the art Committee of networks (300-5625) [4] \u2212 \u2212 68.", "startOffset": 104, "endOffset": 107}, {"referenceID": 0, "context": "55 View-invariant k-means (3 layers, 6400) [2] 72.", "startOffset": 43, "endOffset": 46}, {"referenceID": 1, "context": "7 Exemplar-CNN (92-256-512) [3] 77.", "startOffset": 28, "endOffset": 31}, {"referenceID": 16, "context": "3 SWWAE (8-10 layers) [18] \u2212 92.", "startOffset": 22, "endOffset": 26}, {"referenceID": 17, "context": "33 Ladder Network (\u0393-model, 7 layers) [19] 79.", "startOffset": 38, "endOffset": 42}, {"referenceID": 14, "context": "47 \u2212 \u2212 Kernel CNN (12-800+50-800) [16] \u2212 82.", "startOffset": 34, "endOffset": 38}, {"referenceID": 13, "context": "32 Stochastic pooling (64-64-64) [15] \u223c 65 84.", "startOffset": 33, "endOffset": 37}, {"referenceID": 18, "context": "For this purpose, we learned filters with ICA [20] on patches with n = 0 and n \u2265 0 (AutoCNN-ICA) using the same procedure as with k-means (see Section 4.", "startOffset": 46, "endOffset": 50}, {"referenceID": 13, "context": "Thus, for convolutional layers of our large model for CIFAR-10 Nmodel = 400\u00d7 13\u00d7 13\u00d7 3 + 160\u00d7 11\u00d7 11\u00d7 4 \u2248 280k, while in [15] it is \u2248 200k, which is smaller only because of smaller filters.", "startOffset": 121, "endOffset": 125}], "year": 2016, "abstractText": "In visual recognition tasks, supervised learning shows excellent performance. On the other hand, unsupervised learning exploits cheap unlabeled data and can help to solve the same tasks more efficiently. We show that the recursive autoconvolutional operator, adopted from physics, boosts existing unsupervised methods to learn more powerful filters. We use a well established multilayer convolutional network and train filters layer-wise. To build a stronger classifier, we design a very light committee of SVM models. The total number of trainable parameters is also greatly reduced by using shared filters in higher layers. We evaluate our networks on the MNIST, CIFAR-10 and STL-10 benchmarks and report several state of the art results among other unsupervised methods.", "creator": "LaTeX with hyperref package"}}}