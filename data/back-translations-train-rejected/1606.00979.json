{"id": "1606.00979", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Jun-2016", "title": "Question Answering over Knowledge Base with Neural Attention Combining Global Knowledge Information", "abstract": "With the rapid growth of knowledge bases (KBs) on the web, how to take full advantage of them becomes increasingly important. Knowledge base-based question answering (KB-QA) is one of the most promising approaches to access the substantial knowledge. Meantime, as the neural network-based (NN-based) methods develop, NN-based KB-QA has already achieved impressive results. However, previous work did not put emphasis on question representation, and the question is converted into a fixed vector regardless of its candidate answers. This simple representation strategy is unable to express the proper information of the question. Hence, we present a neural attention-based model to represent the questions dynamically according to the different focuses of various candidate answer aspects. In addition, we leverage the global knowledge inside the underlying KB, aiming at integrating the rich KB information into the representation of the answers. And it also alleviates the out of vocabulary (OOV) problem, which helps the attention model to represent the question more precisely. The experimental results on WEBQUESTIONS demonstrate the effectiveness of the proposed approach.", "histories": [["v1", "Fri, 3 Jun 2016 06:40:14 GMT  (297kb,D)", "http://arxiv.org/abs/1606.00979v1", null]], "reviews": [], "SUBJECTS": "cs.IR cs.AI cs.CL cs.NE", "authors": ["yuanzhe zhang", "kang liu", "shizhu he", "guoliang ji", "zhanyi liu", "hua wu", "jun zhao"], "accepted": false, "id": "1606.00979"}, "pdf": {"name": "1606.00979.pdf", "metadata": {"source": "CRF", "title": "Question Answering over Knowledge Base with Neural Attention Combining Global Knowledge Information", "authors": ["Yuanzhe Zhang", "Kang Liu", "Shizhu He", "Guoliang Ji", "Zhanyi Liu", "Hua Wu", "Jun Zhao"], "emails": ["jzhao}@nlpr.ia.ac.cn", "hua}@baidu.com"], "sections": [{"heading": "1 Introduction", "text": "In fact, most of them are able to determine for themselves what they want and what they don't want."}, {"heading": "2 Overview", "text": "The architecture of our proposed KBQA system is illustrated in Figure 1, which illustrates the basic flow of our approach. First, we identify the topic unit of the question and generate the candidates \"answers from the freebase, then we present the candidates\" answers in terms of their four aspects. Next, we use an attention-based neural network to present the question under the influence of the candidates \"response aspects. Finally, the similarity between the question and each corresponding candidate response is calculated, and the candidates with the highest score are selected as final answers. We use the freebase [Bollacker et al., 2008] as the knowledge base. It now has more than 3 billion facts and is used as a supporting KB for many QA tasks. In the freebase, the facts are represented by subject-property-object triples (s, p, o)."}, {"heading": "3 Our Approach", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Candidate Generation", "text": "Ideally, the candidate's answers should be all units of Freebase, but in practice this is time-consuming and not really necessary. For each question q, we can use the Freebase API [Bollacker et al., 2008] to identify a theme unit that could easily be understood as the main unit of the question. For example, France is the theme unit of the question \"Who is the President of France?.\" The Freebase API method is able to solve up to 86% of questions when we use the Top1 result [Yao and Van Durme, 2014]. After we get the theme unit, we collect all units directly connected to it and the units connected to 2-hop5. These units form a candidate that defines Cq."}, {"heading": "3.2 The Proposed Neural Attention Model", "text": "We represent an attention-based neural network that dynamically presents the question according to different aspects of the answer. Specifically, each aspect of the answer looks at different attention to the question and decides how the answer to the question is presented. The level of attention is used as the weight of each word in the question and could cause the following steps. We will illustrate how the system works as follows:... \", x2, xn), where we need to get the representation of each word in the question. These representations retain all the information of the question and could serve the following steps.\" The question is expressed as q = (x1, x2, xn), where xi names the ith word. As shown in Figure 2, we first look at a word that embeds the matrix Ew. Rd \u00d7 vw to get the word embeddings that are randomly initialized and updated during the training process."}, {"heading": "3.3 Combining Global Knowledge Information", "text": "In this section we will elaborate on how the global information of the KB could be used. As already mentioned, we try to take into account the complete structural information of the KB. To this end, we adopt the TransE model [Bordes et al., 2013] to represent the KB and integrate the representations into the QA training process. In the TransE model, the entities and relationships are represented by low-dimensional embeddings. The basic idea is that the relationships should be regarded as translations into the embedding space. Here, for reasons of consistency, we refer to any fact as (s, p, o), and use courage (s, p, o) to name their embeddings. The embedding of the tail entity o should be close to the embedding of the head unit s plus the embedding of the relationship p, i.e. (s + p, o). The energy of a threefold (s, p, o)."}, {"heading": "4 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Datasets", "text": "To evaluate the proposed method, we select the WEBQUESTIONS dataset [Berant et al., 2013], which contains 3,778 question-answer pairs for training and 2,032 for the test. Questions are collected via the Google Suggest API and the answers are manually labeled by Amazon MTurk. All answers come from Freebase. We use three-quarters (2,833) of the training data as a training set and the remaining quarter as a validation set. As a benchmark, the script value F1 provided by [Berant et al., 2013] is selected."}, {"heading": "4.2 Settings", "text": "The embedding size is d = 128 and the hidden unit size is 64. The margin \u03b3 is set to 0.6. Negative sample number k = 500. The TransE training process defines the embedding dimension to 128, and the mini-batch size is also 50. \u03b3k is set to 1. All these hyperparameters of the proposed network are determined according to the performance on the validation set."}, {"heading": "4.3 Results", "text": "The effectiveness of the proposed approach shows the effectiveness of the proposed approach, we compare our method with previous NN-based methods. Table 1 shows the results on WEBQUESTIONS test set. The methods listed in the table indicate all aspects of the neural network for KBQA. [Bordes et al., 2014b] applies the BOW method to obtain a single vector for our questions and answers. [Bordes et al., 2014a] further improvements in their work by proposing the concept of subgraph embeddings. Besides the response path, the subgraph contains all entities and relationships associated with the answer entity. The final vector is also achieved by the BOW strategy. [Yang et al., 2014] follows the SP-based way, but uses embeddings to map entities and relationships in KB resources, then the question can be converted into logical forms. [Yang et al., 2014] Use the SP-based way, but use embeddings to map entities and relationships in KB resources."}, {"heading": "4.4 Error Analysis", "text": "We sampled 100 imperfectly answered questions and categorized the errors in two main classes as follows: Wrong AttentionIn some cases (17 in 100 questions, 17%), we find the attention weights generated inappropriate. For example, in the question \"What are the songs Justin Bieber wrote?\" most attention is focused on \"What\" rather than \"Songs.\" We believe that this is due to the bias of the training data, and we believe that these errors could be solved by introducing more instructive training data in the future. Complex questions and labeling errors Another difficult problem are the complex questions (34%). For example: \"When was the last time that Knicks won the championship?\" is actually the question after the last championship, but the predicted answers give all championships. This is because the model cannot learn what \"Last\" means in the training process. Furthermore, the etiquette errors also affect the rating (3%). For example, \"What did John Nash teach the University?\" The answer is multiple steps? \"but the University of Princeton's methodology does not."}, {"heading": "5 Related Work", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Neural Network-based KB-QA", "text": "[Bordes et al., 2014b] first uses an NN-based method to solve the KB-QA problem. Questions and KB triples are represented by vectors in a low dimensional space, so cosine similarity could be used to find the best possible answer. BOW method is used to obtain a single vector for both questions and answers. Pair-wise training is used, and the negative examples are randomly selected from the KB facts. Also, the key idea is to include as much as information in the answer, i.e. using KB facts and some heuristic rules to generate natural language questions. [Bordes et al., 2014a] further improves their work by proposing the concept of subgraph embedding. The key idea is to include as much as information in the respondent. In addition to the answer threefold, the subgraph contains all units and relationships that are connected to the answer unit of the BOW-2014, also focused on the BOW-2014h strategy."}, {"heading": "5.2 Attention-based Model", "text": "[Bahdanau et al., 2015] apply first the attention model in the NLP. They improve the encoder decoder Neural Machine Translation (NMT) framework by learning alignment and translation together. They argue that the representation of the initial sentence by a fixed vector is unreasonable, and propose a soft alignment method that could be understood as an attention mechanism. [Luong et al., 2015] also implements the task of the sentence-level summary. They propose two attention models, i.e. a global model and a local model. The latter also indicates a small margin for manoeuvre and achieves better results. [Rush et al., 2015] implements the task of the sentence-level summary. They use a local attention-based model that generates each word of the summary depending on the input sentence. Our approach differs from previous work in that we use attention to dynamically present questions rather than the actual words."}, {"heading": "6 Conclusion", "text": "In this paper, we focus on the KB-QA task. First, we look at the impact of the different answers and their aspects in the presentation of the question and propose a novel attention-based model for KB-QA. Specifically, the attention of the answer aspect is used for every word in the question. This type of dynamic presentation is more precise and flexible. Second, we use the global KB information, which could take full advantage of the full KB and also alleviate the OOV problem. Extensive experiments show that the proposed approach could achieve a better performance compared to other state-of-the-art NN-based methods."}], "references": [{"title": "Neural machine translation by jointly learning to align and translate", "author": ["Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio"], "venue": "Proceedings of ICLR,", "citeRegEx": "Bahdanau et al.. 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "In Proceedings of EMNLP", "author": ["Jonathan Berant", "Andrew Chou", "Roy Frostig", "Percy Liang. Semantic parsing on freebase from question-answer pairs"], "venue": "pages 1533\u20131544,", "citeRegEx": "Berant et al.. 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "Freebase: a collaboratively created graph database for structuring human knowledge", "author": ["Kurt Bollacker", "Colin Evans", "Praveen Paritosh", "Tim Sturge", "Jamie Taylor"], "venue": "Proceedings of SIGMOD, pages 1247\u20131250. ACM,", "citeRegEx": "Bollacker et al.. 2008", "shortCiteRegEx": null, "year": 2008}, {"title": "In Advances in Neural Information Processing Systems 26", "author": ["Antoine Bordes", "Nicolas Usunier", "Alberto Garcia-Duran", "Jason Weston", "Oksana Yakhnenko. Translating embeddings for modeling multi-relational data"], "venue": "pages 2787\u20132795.", "citeRegEx": "Bordes et al.. 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "In Proceedings of EMNLP", "author": ["Antoine Bordes", "Sumit Chopra", "Jason Weston. Question answering with subgraph embeddings"], "venue": "pages 615\u2013620,", "citeRegEx": "Bordes et al.. 2014a", "shortCiteRegEx": null, "year": 2014}, {"title": "pages 165\u2013180", "author": ["Antoine Bordes", "Jason Weston", "Nicolas Usunier. Open question answering with weakly supervised embedding models. In Machine Learning", "Knowledge Discovery in Databases"], "venue": "Springer,", "citeRegEx": "Bordes et al.. 2014b", "shortCiteRegEx": null, "year": 2014}, {"title": "Large-scale simple question answering with memory networks", "author": ["Antoine Bordes", "Nicolas Usunier", "Sumit Chopra", "Jason Weston"], "venue": "Proceedings of ICLR,", "citeRegEx": "Bordes et al.. 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "In Proceedings of ACL", "author": ["Qingqing Cai", "Alexander Yates. Large-scale semantic parsing via schema matching", "lexicon extension"], "venue": "pages 423\u2013433,", "citeRegEx": "Cai and Yates. 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "In Proceedings of ACL and IJCNLP", "author": ["Li Dong", "Furu Wei", "Ming Zhou", "Ke Xu. Question answering over freebase with multicolumn convolutional neural networks"], "venue": "pages 260\u2013269,", "citeRegEx": "Dong et al.. 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "Transitionbased dependency parsing with stack long short-term memory", "author": ["Chris Dyer", "Miguel Ballesteros", "Wang Ling", "Austin Matthews", "Noah A Smith"], "venue": "arXiv preprint arXiv:1505.08075,", "citeRegEx": "Dyer et al.. 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "pages 1535\u20131545", "author": ["Anthony Fader", "Stephen Soderland", "Oren Etzioni. Identifying relations for open information extraction. In Proceedings of EMNLP"], "venue": "Association for Computational Linguistics,", "citeRegEx": "Fader et al.. 2011", "shortCiteRegEx": null, "year": 2011}, {"title": "In Advances in Neural Information Processing Systems", "author": ["Karl Moritz Hermann", "Tomas Kocisky", "Edward Grefenstette", "Lasse Espeholt", "Will Kay", "Mustafa Suleyman", "Phil Blunsom. Teaching machines to read", "comprehend"], "venue": "pages 1684\u20131692,", "citeRegEx": "Hermann et al.. 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "Neural computation", "author": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber. Long short-term memory"], "venue": "9(8):1735\u20131780,", "citeRegEx": "Hochreiter and Schmidhuber. 1997", "shortCiteRegEx": null, "year": 1997}, {"title": "In Proceedings of EMNLP", "author": ["Tom Kwiatkowski", "Eunsol Choi", "Yoav Artzi", "Luke Zettlemoyer. Scaling semantic parsers with on-the-fly ontology matching"], "venue": "pages 1545\u20131556,", "citeRegEx": "Kwiatkowski et al.. 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "In Proceedings of EMNLP", "author": ["Minh-Thang Luong", "Hieu Pham", "Christopher D Manning. Effective approaches to attentionbased neural machine translation"], "venue": "pages 1412\u20131421,", "citeRegEx": "Luong et al.. 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "et al", "author": ["Eric PrudHommeaux", "Andy Seaborne"], "venue": "Sparql query language for rdf. W3C recommendation, 15,", "citeRegEx": "PrudHommeaux et al.. 2008", "shortCiteRegEx": null, "year": 2008}, {"title": "A neural attention model for abstractive sentence summarization", "author": ["Alexander M Rush", "Sumit Chopra", "Jason Weston"], "venue": "pages 379\u2013389,", "citeRegEx": "Rush et al.. 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "et al", "author": ["Sainbayar Sukhbaatar", "Jason Weston", "Rob Fergus"], "venue": "End-to-end memory networks. In Advances in Neural Information Processing Systems, pages 2431\u20132439,", "citeRegEx": "Sukhbaatar et al.. 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "In Advances in neural information processing systems", "author": ["Ilya Sutskever", "Oriol Vinyals", "Quoc VV Le. Sequence to sequence learning with neural networks"], "venue": "pages 3104\u20133112,", "citeRegEx": "Sutskever et al.. 2014", "shortCiteRegEx": null, "year": 2014}, {"title": "Reasoning on the Web in the Big Data Era", "author": ["Christina Unger", "Andr\u00e9 Freitas", "Philipp Cimiano. An introduction to question answering over linked data. In Reasoning Web"], "venue": "pages 100\u2013140.", "citeRegEx": "Unger et al.. 2014", "shortCiteRegEx": null, "year": 2014}, {"title": "In Proceedings of EMNLP", "author": ["Min-Chul Yang", "Nan Duan", "Ming Zhou", "Hae-Chang Rim. Joint relational embeddings for knowledge-based question answering"], "venue": "pages 645\u2013650,", "citeRegEx": "Yang et al.. 2014", "shortCiteRegEx": null, "year": 2014}, {"title": "Information extraction over structured data: Question answering with freebase", "author": ["Xuchen Yao", "Benjamin Van Durme"], "venue": "Proceedings of ACL, pages 956\u2013966,", "citeRegEx": "Yao and Van Durme. 2014", "shortCiteRegEx": null, "year": 2014}, {"title": "In Proceedings of ACL", "author": ["Wen-tau Yih", "Xiaodong He", "Christopher Meek. Semantic parsing for single-relation question answering"], "venue": "pages 643\u2013648,", "citeRegEx": "Yih et al.. 2014", "shortCiteRegEx": null, "year": 2014}, {"title": "Semantic parsing via staged query graph generation: Question answering with knowledge base", "author": ["Wen-tau Yih", "Ming-Wei Chang", "Xiaodong He", "Jianfeng Gao"], "venue": "Proceedings of ACL and IJCNLP, pages 1321\u2013 1331,", "citeRegEx": "Yih et al.. 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars", "author": ["Luke S Zettlemoyer", "Michael Collins"], "venue": "Proceedings of UAI, pages 658\u2013666,", "citeRegEx": "Zettlemoyer and Collins. 2005", "shortCiteRegEx": null, "year": 2005}, {"title": "In Proceedings of ACLIJCNLP", "author": ["Luke S Zettlemoyer", "Michael Collins. Learning context-dependent mappings from sentences to logical form"], "venue": "pages 976\u2013984,", "citeRegEx": "Zettlemoyer and Collins. 2009", "shortCiteRegEx": null, "year": 2009}], "referenceMentions": [{"referenceID": 15, "context": "There are several tailor-made languages designed for querying KBs, such as SPARQL [PrudHommeaux et al., 2008].", "startOffset": 82, "endOffset": 109}, {"referenceID": 19, "context": "By contrast, knowledge base-based question answering (KB-QA) [Unger et al., 2014], which takes natural language as query language, is a more user-friendly solution, and has become a research focus in recent years.", "startOffset": 61, "endOffset": 81}, {"referenceID": 24, "context": ", semantic parsing-based (SP-based) [Zettlemoyer and Collins, 2005; Zettlemoyer and Collins, 2009; Kwiatkowski et al., 2013; Cai and Yates, 2013; Berant et al., 2013; Yih et al., 2015] and information retrieve-based (IR-based) [Yao and Van Durme, 2014; Bordes et al.", "startOffset": 36, "endOffset": 184}, {"referenceID": 25, "context": ", semantic parsing-based (SP-based) [Zettlemoyer and Collins, 2005; Zettlemoyer and Collins, 2009; Kwiatkowski et al., 2013; Cai and Yates, 2013; Berant et al., 2013; Yih et al., 2015] and information retrieve-based (IR-based) [Yao and Van Durme, 2014; Bordes et al.", "startOffset": 36, "endOffset": 184}, {"referenceID": 13, "context": ", semantic parsing-based (SP-based) [Zettlemoyer and Collins, 2005; Zettlemoyer and Collins, 2009; Kwiatkowski et al., 2013; Cai and Yates, 2013; Berant et al., 2013; Yih et al., 2015] and information retrieve-based (IR-based) [Yao and Van Durme, 2014; Bordes et al.", "startOffset": 36, "endOffset": 184}, {"referenceID": 7, "context": ", semantic parsing-based (SP-based) [Zettlemoyer and Collins, 2005; Zettlemoyer and Collins, 2009; Kwiatkowski et al., 2013; Cai and Yates, 2013; Berant et al., 2013; Yih et al., 2015] and information retrieve-based (IR-based) [Yao and Van Durme, 2014; Bordes et al.", "startOffset": 36, "endOffset": 184}, {"referenceID": 1, "context": ", semantic parsing-based (SP-based) [Zettlemoyer and Collins, 2005; Zettlemoyer and Collins, 2009; Kwiatkowski et al., 2013; Cai and Yates, 2013; Berant et al., 2013; Yih et al., 2015] and information retrieve-based (IR-based) [Yao and Van Durme, 2014; Bordes et al.", "startOffset": 36, "endOffset": 184}, {"referenceID": 23, "context": ", semantic parsing-based (SP-based) [Zettlemoyer and Collins, 2005; Zettlemoyer and Collins, 2009; Kwiatkowski et al., 2013; Cai and Yates, 2013; Berant et al., 2013; Yih et al., 2015] and information retrieve-based (IR-based) [Yao and Van Durme, 2014; Bordes et al.", "startOffset": 36, "endOffset": 184}, {"referenceID": 21, "context": ", 2015] and information retrieve-based (IR-based) [Yao and Van Durme, 2014; Bordes et al., 2014b; Bordes et al., 2014a; Dong et al., 2015; Bordes et al., 2015] methods.", "startOffset": 50, "endOffset": 159}, {"referenceID": 5, "context": ", 2015] and information retrieve-based (IR-based) [Yao and Van Durme, 2014; Bordes et al., 2014b; Bordes et al., 2014a; Dong et al., 2015; Bordes et al., 2015] methods.", "startOffset": 50, "endOffset": 159}, {"referenceID": 4, "context": ", 2015] and information retrieve-based (IR-based) [Yao and Van Durme, 2014; Bordes et al., 2014b; Bordes et al., 2014a; Dong et al., 2015; Bordes et al., 2015] methods.", "startOffset": 50, "endOffset": 159}, {"referenceID": 8, "context": ", 2015] and information retrieve-based (IR-based) [Yao and Van Durme, 2014; Bordes et al., 2014b; Bordes et al., 2014a; Dong et al., 2015; Bordes et al., 2015] methods.", "startOffset": 50, "endOffset": 159}, {"referenceID": 6, "context": ", 2015] and information retrieve-based (IR-based) [Yao and Van Durme, 2014; Bordes et al., 2014b; Bordes et al., 2014a; Dong et al., 2015; Bordes et al., 2015] methods.", "startOffset": 50, "endOffset": 159}, {"referenceID": 8, "context": "[Dong et al., 2015; Bordes et al., 2015] have proven that IRbased methods could acquire competitive performance compared with SP-based methods through the experiments conducted over Freebase [Bollacker et al.", "startOffset": 0, "endOffset": 40}, {"referenceID": 6, "context": "[Dong et al., 2015; Bordes et al., 2015] have proven that IRbased methods could acquire competitive performance compared with SP-based methods through the experiments conducted over Freebase [Bollacker et al.", "startOffset": 0, "endOffset": 40}, {"referenceID": 2, "context": ", 2015] have proven that IRbased methods could acquire competitive performance compared with SP-based methods through the experiments conducted over Freebase [Bollacker et al., 2008].", "startOffset": 158, "endOffset": 182}, {"referenceID": 5, "context": "Recently, with the progress of deep learning, neural network-based (NN-based) methods have been introduced to the KB-QA task [Bordes et al., 2014b].", "startOffset": 125, "endOffset": 147}, {"referenceID": 4, "context": "For example, [Bordes et al., 2014a] considers the importance of the subgraph of the candidate answers.", "startOffset": 13, "endOffset": 35}, {"referenceID": 8, "context": "[Dong et al., 2015] makes use of the context and the type of the answers.", "startOffset": 0, "endOffset": 19}, {"referenceID": 5, "context": "Existing approaches often represent a question into a single vector using a simple bag-of-words (BOW) model [Bordes et al., 2014b; Bordes et al., 2014a], whereas its relatedness to the answer end is neglected.", "startOffset": 108, "endOffset": 152}, {"referenceID": 4, "context": "Existing approaches often represent a question into a single vector using a simple bag-of-words (BOW) model [Bordes et al., 2014b; Bordes et al., 2014a], whereas its relatedness to the answer end is neglected.", "startOffset": 108, "endOffset": 152}, {"referenceID": 8, "context": "[Dong et al., 2015] represents questions using three CNNs with different parameters when dealing with different answer aspects including the answer path, the answer context and the answer type.", "startOffset": 0, "endOffset": 19}, {"referenceID": 8, "context": "Different to [Dong et al., 2015], we represent the question differently according to different answer resources, not allowing them sharing the same network as [Dong et al.", "startOffset": 13, "endOffset": 32}, {"referenceID": 8, "context": ", 2015], we represent the question differently according to different answer resources, not allowing them sharing the same network as [Dong et al., 2015] does.", "startOffset": 134, "endOffset": 153}, {"referenceID": 4, "context": ", answer path and answer context [Bordes et al., 2014a; Dong et al., 2015], to learn the representations of KB resources.", "startOffset": 33, "endOffset": 74}, {"referenceID": 8, "context": ", answer path and answer context [Bordes et al., 2014a; Dong et al., 2015], to learn the representations of KB resources.", "startOffset": 33, "endOffset": 74}, {"referenceID": 2, "context": "We utilize Freebase [Bollacker et al., 2008] as our knowledge base.", "startOffset": 20, "endOffset": 44}, {"referenceID": 2, "context": "For each question q, we can use Freebase API [Bollacker et al., 2008] to identify a topic entity, which could be simply understood as the main entity of the question.", "startOffset": 45, "endOffset": 69}, {"referenceID": 21, "context": "Freebase API method is able to resolve as many as 86% questions if we use the top1 result [Yao and Van Durme, 2014].", "startOffset": 90, "endOffset": 115}, {"referenceID": 12, "context": "Then, the embeddings are fed into a long short-term memory (LSTM) [Hochreiter and Schmidhuber, 1997] networks.", "startOffset": 66, "endOffset": 100}, {"referenceID": 18, "context": "LSTM has been proven to be effective in many natural language processing (NLP) tasks such as machine translation [Sutskever et al., 2014] and dependency parsing [Dyer et al.", "startOffset": 113, "endOffset": 137}, {"referenceID": 9, "context": ", 2014] and dependency parsing [Dyer et al., 2015], and it is adept in harnessing long sentences.", "startOffset": 31, "endOffset": 50}, {"referenceID": 0, "context": "To avoid this, we employ bidirectional LSTM as [Bahdanau et al., 2015] does, which consists of both forward and backward networks.", "startOffset": 47, "endOffset": 70}, {"referenceID": 11, "context": "The proposed attention model could also be intuitively interpreted as a re-reading mechanism [Hermann et al., 2015].", "startOffset": 93, "endOffset": 115}, {"referenceID": 3, "context": "To this end, we adopt TransE model [Bordes et al., 2013] to represent the KB, and integrate the representations into the QA training process.", "startOffset": 35, "endOffset": 56}, {"referenceID": 1, "context": "To evaluate the proposed method, we select WEBQUESTIONS [Berant et al., 2013] dataset that includes 3,778", "startOffset": 56, "endOffset": 77}, {"referenceID": 1, "context": "F1 score computed by the script provided by [Berant et al., 2013] is select as the evaluation metric", "startOffset": 44, "endOffset": 65}, {"referenceID": 5, "context": "[Bordes et al., 2014b] applies BOW method to obtain a single vector for both questions and answers.", "startOffset": 0, "endOffset": 22}, {"referenceID": 4, "context": "[Bordes et al., 2014a] further improves their work by proposing the concept of subgraph embeddings.", "startOffset": 0, "endOffset": 22}, {"referenceID": 20, "context": "[Yang et al., 2014] follows the SP-based manner, but uses embeddings to map entities and relations into KB resources, then the question can be converted into logical forms.", "startOffset": 0, "endOffset": 19}, {"referenceID": 8, "context": "[Dong et al., 2015] uses three columns of CNNs to represent questions corresponding to three aspects of the answers, namely the answer context, the answer path and the answer type.", "startOffset": 0, "endOffset": 19}, {"referenceID": 6, "context": "[Bordes et al., 2015] puts KB-QA into the memory networks [Sukhbaatar et al.", "startOffset": 0, "endOffset": 21}, {"referenceID": 17, "context": ", 2015] puts KB-QA into the memory networks [Sukhbaatar et al., 2015] framework, and achieves the state-of-the-art performance.", "startOffset": 44, "endOffset": 69}, {"referenceID": 5, "context": "Here [Bordes et al., 2014b; Bordes et al., 2014a; Bordes et al., 2015] all utilize BOW model to represent the questions, while ours takes advantage of the attention of answer aspects to dynamically represent the questions.", "startOffset": 5, "endOffset": 70}, {"referenceID": 4, "context": "Here [Bordes et al., 2014b; Bordes et al., 2014a; Bordes et al., 2015] all utilize BOW model to represent the questions, while ours takes advantage of the attention of answer aspects to dynamically represent the questions.", "startOffset": 5, "endOffset": 70}, {"referenceID": 6, "context": "Here [Bordes et al., 2014b; Bordes et al., 2014a; Bordes et al., 2015] all utilize BOW model to represent the questions, while ours takes advantage of the attention of answer aspects to dynamically represent the questions.", "startOffset": 5, "endOffset": 70}, {"referenceID": 6, "context": "Also note that [Bordes et al., 2015] uses additional training data such as Reverb [Fader et al.", "startOffset": 15, "endOffset": 36}, {"referenceID": 10, "context": ", 2015] uses additional training data such as Reverb [Fader et al., 2011] and their original dataset SimpleQuestions.", "startOffset": 53, "endOffset": 73}, {"referenceID": 8, "context": "[Dong et al., 2015] employs three fixed CNNs to represent questions, while ours is able to express the focus of each unique answer aspect in the question representation.", "startOffset": 0, "endOffset": 19}, {"referenceID": 23, "context": "It is worth noting that [Yih et al., 2015] achieves an F1 of 52.", "startOffset": 24, "endOffset": 42}, {"referenceID": 5, "context": "[Bordes et al., 2014b] first applies NN-based method to solve KB-QA problem.", "startOffset": 0, "endOffset": 22}, {"referenceID": 4, "context": "[Bordes et al., 2014a] further improves their work by proposing the concept of subgraph embeddings.", "startOffset": 0, "endOffset": 22}, {"referenceID": 22, "context": "[Yih et al., 2014] focuses on single-relation questions.", "startOffset": 0, "endOffset": 18}, {"referenceID": 20, "context": "[Yang et al., 2014] handles entity and relation mapping as joint procedures.", "startOffset": 0, "endOffset": 19}, {"referenceID": 8, "context": "The most similar work to ours is [Dong et al., 2015].", "startOffset": 33, "endOffset": 52}, {"referenceID": 0, "context": "[Bahdanau et al., 2015] first applies attention model in NLP.", "startOffset": 0, "endOffset": 23}, {"referenceID": 14, "context": "[Luong et al., 2015] is also tackling machine translation task.", "startOffset": 0, "endOffset": 20}, {"referenceID": 16, "context": "[Rush et al., 2015] implements sentence-level summarization task.", "startOffset": 0, "endOffset": 19}], "year": 2016, "abstractText": "With the rapid growth of knowledge bases (KBs) on the web, how to take full advantage of them becomes increasingly important. Knowledge basebased question answering (KB-QA) is one of the most promising approaches to access the substantial knowledge. Meantime, as the neural networkbased (NN-based) methods develop, NN-based KB-QA has already achieved impressive results. However, previous work did not put emphasis on question representation, and the question is converted into a fixed vector regardless of its candidate answers. This simple representation strategy is unable to express the proper information of the question. Hence, we present a neural attention-based model to represent the questions dynamically according to the different focuses of various candidate answer aspects. In addition, we leverage the global knowledge inside the underlying KB, aiming at integrating the rich KB information into the representation of the answers. And it also alleviates the out of vocabulary (OOV) problem, which helps the attention model to represent the question more precisely. The experimental results on WEBQUESTIONS demonstrate the effectiveness of the proposed approach.", "creator": "LaTeX with hyperref package"}}}