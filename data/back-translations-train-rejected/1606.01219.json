{"id": "1606.01219", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Jun-2016", "title": "Learning Stylometric Representations for Authorship Analysis", "abstract": "Authorship analysis (AA) is the study of unveiling the hidden properties of authors from a body of exponentially exploding textual data. It extracts an author's identity and sociolinguistic characteristics based on the reflected writing styles in the text. It is an essential process for various areas, such as cybercrime investigation, psycholinguistics, political socialization, etc. However, most of the previous techniques critically depend on the manual feature engineering process. Consequently, the choice of feature set has been shown to be scenario- or dataset-dependent. In this paper, to mimic the human sentence composition process using a neural network approach, we propose to incorporate different categories of linguistic features into distributed representation of words in order to learn simultaneously the writing style representations based on unlabeled texts for authorship analysis. In particular, the proposed models allow topical, lexical, syntactical, and character-level feature vectors of each document to be extracted as stylometrics. We evaluate the performance of our approach on the problems of authorship characterization and authorship verification with the Twitter, novel, and essay datasets. The experiments suggest that our proposed text representation outperforms the bag-of-lexical-n-grams, Latent Dirichlet Allocation, Latent Semantic Analysis, PVDM, PVDBOW, and word2vec representations.", "histories": [["v1", "Fri, 3 Jun 2016 18:42:14 GMT  (2012kb,D)", "http://arxiv.org/abs/1606.01219v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.CY cs.SI", "authors": ["steven h h ding", "benjamin c m fung", "farkhund iqbal", "william k cheung"], "accepted": false, "id": "1606.01219"}, "pdf": {"name": "1606.01219.pdf", "metadata": {"source": "CRF", "title": "Learning Stylometric Representations for Authorship Analysis", "authors": ["STEVEN H. H. DING", "BENJAMIN C. M. FUNG", "FARKHUND IQBAL", "WILLIAM K. CHEUNG"], "emails": [], "sections": [{"heading": null, "text": "0 Learning Stylometric Representations for Authorship AnalysisSTEVEN H. DING, School of Information Studies, McGill University, Canada BENJAMIN C. M. FUNG, School of Information Studies, McGill University, Canada FARKHUND IQBAL, College of Technological Innovation, Zayed University, UAE WILLIAM K. CHEUNG, Department of Computer Science, Hong Kong Baptist University, Hong KongAuthorship Analysis (AA) is the study of revealing the hidden characteristics of authors from a body of exponential use of textual data. It extracts the identity of an author and sociolinguistic characteristics based on the reflected spellings in the text. It is an essential process for various areas, such as cybercrime investigation, psycholinguistics, political socialization, etc."}, {"heading": "1. INTRODUCTION", "text": "The prevalence of computer information systems, personal computing tools, and globalizing Internet techniques have fundamentally changed our daily lives and reshaped the way we generate and process information. Countless pieces of text and documents are generated in every millisecond: this is the era of infobesity techniques. Authorship Analysis (AA) is one of the critical approaches to transforming the burden of an enormous amount of data into practical, useful knowledge. By looking at reflected linguistic paths, AA is a study to uncover the identity and sociolinguistic characteristics of an underlying author. The evolution of author analysis, supported by stylometric techniques, has a profound impact on various areas: - Cybercrime Investigation. The widespread nature of cyberspace provides an ideal anonymous channel for computer-mediated malicious activities, e.g., phishing scams, ransom messages, harassment, money laundering, illegal distribution, etc."}, {"heading": "2. MINING STYLOMETRIC REPRESENTATIONS FOR AUTHORSHIP ANALYSIS", "text": "In this section, we present the proposed models for learning stylometric representations on unlabeled training data and estimating the representations for invisible test data. First, we define several key terms and the stylometric learning problem studied. To be consistent in terminology, text data set refers to the union of available, labeled and unlabeled text; document and font sample are used interchangeably to refer to the minimal unit of text data to be analyzed. A font sample consists of a list of sentences, and a sentence consists of a sequence of lexical characters. Each lexical character has its respective POS mark in the corresponding phrase. This section corresponds to the first process of the lower flowchart in Figure 1, in which only unlabeled text data is available. In this process, we learn the representation of each selected text unit in four vectorized numerical representations or for four linguistic modalities."}, {"heading": "2.1. Joint learning model for topical modality and lexical modality", "text": "In fact, most of them are able to play by the rules that they have imposed on themselves, and they are able to play by the rules that they have imposed on themselves."}, {"heading": "2.2. The character-level modality", "text": "The typical characteristics used for the respective frequency or characteristic are used for AA studies, which have shown that they can be effective for authoring verification [Halvani and Steinebach 2014], the mapping of data and test data [Burger et al. 2011]. Sapkota et al. [2014] show that character characteristics of n-gram traits are robust and also function in conditions where training data and test data are based on different topics."}, {"heading": "2.3. The syntactic modality", "text": "This year, the time has come for an agreement to be reached, and it will only take a few days."}, {"heading": "2.4. Making the model deterministic", "text": "Deterministic and reproducible results are important prerequisites for most applications to authorship, especially in the field of forensic and linguistic cyber evidence [Iqbal et al. 2013; Ding et al. 2015]. We were unable to show that a document was authored by one author in the first pass, and later to show that it was authored by another author with the same inputs and settings in subsequent runs. Unfortunately, the proposed learning approach to stylistic representation is based on the stochastic progression algorithm, which involves a high degree of randomness. To make the proposed model deterministic, we need to implement specific modifications to the above models at the implementation level: - Initialization of the parameters to be estimated. First, we need to bring all neural network input parameters into the same point."}, {"heading": "3. EVALUATION ON UNSUPERVISED AUTHORSHIP VERIFICATION PROBLEM", "text": "In this section, we evaluate the proposed models based on the problem of authorship. However, the problem is to verify whether or not two anonymous text documents were written by the same author. In contrast to the problem of author identification, where a number of authors are available for comparison, the problem of author verification has only one target document that needs to be compared. The solution to this problem should be a trustworthy one that indicates how likely the two predefined text documents were written by the same author. Author verification is a closed classification problem and author verification is an open classification problem [Stamatos et al. 2014]. Author verification is more difficult to solve than author identification. We further divide authoring verification into two types: monitored verification and unguarded verification. In the monitored authoring problem, the data from the soil verification is available in the training set."}, {"heading": "3.1. The solution", "text": "In order to solve the problem raised with our proposed stylometric representation models, we first train the three models mentioned in Section 2 on the unlabelled text data and then estimate the stylometric representations for the two anonymous documents \u03c91, \u03c92 in the test data that have not been seen by the models so far. The verification value is a simple cosmic distance measurement between the stylometric representations of the two documents. Formally, when two anonymous documents are specified, the solution yields a similarity value: Q (\u03c91, \u03c92) = (~ enviv\u03c91) T \u00d7 v\u03c92 | ~ v\u03c91 | v\u03c92 | v \u0432v\u03c92 | v \u0432v\u03c92 | v \u0432\u0430\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0438\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441chicchicicicicicicicicicicicicicicicicicicicicicicicicicicicicicicicicicicicicicicicicicicicicicicicicicicicicicicicicicicicicicicicicicicicicicicicicicic"}, {"heading": "3.2. The English novel and essay dataset", "text": "We choose the PAN2014 verification dataset as the benchmark dataset. PAN provides a number of common tasks in digital text forensics, allowing us to compare our results directly with other studies. PAN2015 has only published the training dataset for this issue, the latest available dataset (both training and exam) for the authoring problem is PAN20142. At the time of writing, PAN2015 only published the training dataset for this issue. Currently, we focus only on English text data, although the above models can be adopted for different languages. Refer to Table I. This dataset provides both the training data and the test data. The training data consists of 300 verification cases. Each verification case consists of two document sets and one label. The label may be true, indicating that two sets of of2PAN2014 verification are."}, {"heading": "3.3. Baselines", "text": "We choose several of the most relevant approaches to compare with our proposed models of the authoring problem. - This approach represents a document as a numerical vector under a typical 302 static stylometric characteristics that have been widely studied. Table II provides a summary of these characteristics. It is shown that it is effectively coupled with classifiers for the authoring problem. This approach represents a static characteristic as the characteristics do not change across different datasets. The similarity between two documents is based on their normalized cosmic distances. - Style + [k-freq-ngram]. This approach represents a document as a numerical vector among the 302 static characteristics in Table II as well as dynamic characteristics based on the training datasets. The dynamic characteristics are constructed by selecting the top k n-grams that rank their frequency in training."}, {"heading": "3.4. Performance comparison", "text": "In this section, we present our evaluation result based on the English Authorship Verification Data Set in relation to the AUROC measurement with all of the above baselines. As indicated in Table III, our proposed modality models achieve the highest AUROC score for this authorship problem. Specifically, the first-rated model is the common learning model for lexical modality and the topical modality described in Section 2.1. This model also exceeds all the other data sets described in the Essaydataset. The second-ranked model is the lexical modality representation learned in the common learning model. Character-level modality achieves the highest score on the novel dataset. It also exceeds all of the aforementioned baselines on average. Syntactic modality does not work as well as lexical, topical and characteristic modality modality modalities, modalities that are learned at the Modacality-Level."}, {"heading": "4. EVALUATION ON AUTHORSHIP CHARACTERIZATION PROBLEM", "text": "We evaluate the proposed models against another important problem in authorship analysis: the characterization of authorship. The problem is to identify the socio-linguistic characteristics of the author based on the given text. As discussed in Section 1, it has broad applications in the fields of marketing, political socialization, digital forensics, and social networking analysis. This problem can be described as follows: For a series of labeled documents in which each document is assigned a class label, such as the gender of the author, the problem is to identify the class label for a document whose author remains unknown. A classifier is trained on the labeled documents and assigns one of the labels to the target document. All labels are considered to be non-overlapping. For example, the labels for ages 18-23 and 23 + may be. In order for the classifier to understand the text data, we must present this data in numerical form. In order for the proposed models in this paper to be able to solve this problem, we must first learn the textual data based on the text data."}, {"heading": "4.1. The Twitter characterization dataset", "text": "This data collection consists of three categories of labels and is publicly available. Due to the limitation of Twitter's policy, the actual content of tweets is not included in the data sets, but the identification numbers of Twitter users as well as their Tweet IDs are available. We recall all data that Twitter API uses according to the available information. To preprocess users \"tweets, we remove all non-ASCII characters and replace all URLs with a special lexical token. We also call up the tweets and assign POS tags for each tweet by removing the trained taggers from [Owoputi et al]. In this data set, there is other social network-based information, such as the friends of the target group tweets, etc. Since we only want to model the style of Twitter users, we are equipped with this information."}, {"heading": "5. CONCLUSIONS AND FUTURE DIRECTIONS", "text": "In this article, we present our three models for learning vectorized stylometric representations of different linguistic modalities for the analysis of authorship. To our knowledge, this is the first work that introduces the problem of learning stylometric representation into the field of authorship analysis. Our proposed models are designed to effectively capture the differences in the writing styles of different modalities when an author writes text. By using the proposed feature learning scheme, which is guided by the chosen linguistic modality, we seek to mitigate the problems associated with the feature engineering process in the current authorship study. Our experiments with the publicly available PAN 2014 and the Twitter datasets of ICWSM 2012 for the problem of authorship verification or authorship characterization problem show that our proposed models are effective and robust for both different datasets and AA problems. Our future research will focus on proposing better models for understanding and other languages."}, {"heading": "ACKNOWLEDGMENTS", "text": "The research is supported in part by the Discovery Grants (356065-2013) of the Natural Sciences and Engineering Research Council of Canada (NSERC), the Canada Research Chairs Program (950-230623) and the Research Incentive Fund Grant (RIF13059) of Zayed University."}], "references": [], "referenceMentions": [], "year": 2016, "abstractText": "Authorship analysis (AA) is the study of unveiling the hidden properties of authors from a body of exponentially exploding textual data. It extracts an author\u2019s identity and sociolinguistic characteristics based on the reflected writing styles in the text. It is an essential process for various areas, such as cybercrime investigation, psycholinguistics, political socialization, etc. However, most of the previous techniques critically depend on the manual feature engineering process. Consequently, the choice of feature set has been shown to be scenarioor dataset-dependent. In this paper, to mimic the human sentence composition process using a neural network approach, we propose to incorporate different categories of linguistic features into distributed representation of words in order to learn simultaneously the writing style representations based on unlabeled texts for authorship analysis. In particular, the proposed models allow topical, lexical, syntactical, and character-level feature vectors of each document to be extracted as stylometrics. We evaluate the performance of our approach on the problems of authorship characterization and authorship verification with the Twitter, novel, and essay datasets. The experiments suggest that our proposed text representation outperforms the bag-of-lexical-n-grams, Latent Dirichlet Allocation, Latent Semantic Analysis, PVDM, PVDBOW, and word2vec representations.", "creator": "LaTeX with hyperref package"}}}