{"id": "1606.02032", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Jun-2016", "title": "Human vs. Computer Go: Review and Prospect", "abstract": "The Google DeepMind challenge match in March 2016 was a historic achievement for computer Go development. This article discusses the development of computational intelligence (CI) and its relative strength in comparison with human intelligence for the game of Go. We first summarize the milestones achieved for computer Go from 1998 to 2016. Then, the computer Go programs that have participated in previous IEEE CIS competitions as well as methods and techniques used in AlphaGo are briefly introduced. Commentaries from three high-level professional Go players on the five AlphaGo versus Lee Sedol games are also included. We conclude that AlphaGo beating Lee Sedol is a huge achievement in artificial intelligence (AI) based largely on CI methods. In the future, powerful computer Go programs such as AlphaGo are expected to be instrumental in promoting Go education and AI real-world applications.", "histories": [["v1", "Tue, 7 Jun 2016 05:13:37 GMT  (577kb)", "http://arxiv.org/abs/1606.02032v1", "This article is with 6 pages and 3 figures. And, it is accepted and will be published in IEEE Computational Intelligence Magazine in August, 2016"]], "COMMENTS": "This article is with 6 pages and 3 figures. And, it is accepted and will be published in IEEE Computational Intelligence Magazine in August, 2016", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["chang-shing lee", "mei-hui wang", "shi-jim yen", "ting-han wei", "i-chen wu", "ping-chiang chou", "chun-hsun chou", "ming-wan wang", "tai-hsiung yang"], "accepted": false, "id": "1606.02032"}, "pdf": {"name": "1606.02032.pdf", "metadata": {"source": "CRF", "title": "Human vs. Computer Go: Review and Prospect", "authors": ["Chang-Shing Lee", "Mei-Hui Wang", "Shi-Jim Yen", "Ting-Han Wei", "I-Chen Wu", "Ping-Chiang Chou", "Chun-Hsun Chou"], "emails": [], "sections": [{"heading": null, "text": "This article discusses the evolution of computer-assisted intelligence (CI) and its relative strength compared to human intelligence for the game of Go. First, we summarize the milestones achieved for Computer Go between 1998 and 2016, followed by a brief presentation of the computer-go programs that participated in previous IEEE-CIS competitions, as well as methods and techniques used in AlphaGo. Comments from three high-level professional Go players on the five AlphaGo versus Lee Sedol games are also included. We conclude that AlphaGo versus Lee Sedol represents a tremendous achievement in artificial intelligence (AI), which is largely based on CI methods."}, {"heading": "I. Computer Go Competitions", "text": "The IEEE Computational Intelligence Society (CIS) has allowed an additional space on the board to compensate for the differences between the different playing fields. Fig. 1 shows the year and location of the conferences. Descriptions of competitions held from 1998 to 2016 are detailed in an online version of this article. Handicaps for humans versus computers 19 x 19 have decreased from 29 in 1998 to 0 in 2016. Skills of amateur players in Go are listed according to kyu (K) in the lower level, where a smaller number of players stand for stronger playing skills (with 1K being the highest qualification level), and dan (D) in the higher level, where a larger number of players stand for stronger playing skills. Professional Go players are listed entirely in dan, abbreviated by the letter P (e.g. Lee Sedol ranks 9P). At the amateur level, any difference in ranking is roughly translated."}, {"heading": "Acknowledgements", "text": "The authors would like to thank the Taiwanese Ministry of Science and Technology for their financial support under the grant MOST 105-2919-I-024-001-A1, MOST 104-2221-E-024-015 and MOST 104-2622-E-024-005-CC2. In addition, the authors would also like to thank 1) Mr. Ti-Rong Wu (National Chiao Tung University, Taiwan) for providing the resource estimate for the generation of self-play positions (see Section II); 2) Mr. Sheng-Shu Chang (President of the Click108 Company, Taiwan) for his financial support of previous Human vs. Computer Go competitions @ IEEE CIS flagship conferences; and 3) Dr. Olivier Teytaud and members of the INRIA TAO team as well as Taiwanese team members and the National Center for High-Performance Computing (NCHC) within the grant NSC 99-2923-024-Y3-003."}], "references": [{"title": "The 2010 contest: MoGoTW vs. human Go players", "author": ["M.-H. Wang", "C.-S. Lee", "Y.-L. Wang", "M.-C. Cheng", "O. Teytaud", "S.-J. Yen"], "venue": "ICGA Journal, vol. 33, no. 1, pp. 47\u201350, Mar. 2010.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2010}, {"title": "The computational intelligence of MoGo revealed in Taiwan\u2019s computer Go tournaments", "author": ["C.-S. Lee", "M.-H. Wang", "G. Chaslot", "J.-B. Hoock", "A. Rimmel", "O. Teytaud", "S.-R. Tsai", "S.-C. Hsu", "T.-P. Hong"], "venue": "IEEE Transactions on Computational Intelligence and AI in Games, vol. 1, no. 1, pp. 73\u201389, Mar. 2009.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2009}, {"title": "Current frontiers in computer Go", "author": ["A. Rimmel", "O. Teytaud", "C.-S. Lee", "S.-J. Yen", "M.-H. Wang", "S.-R. Tsai"], "venue": "IEEE Transactions on Computational Intelligence and AI in Games, vol. 2, no. 4, pp. 229\u2013238. Dec. 2010.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2010}, {"title": "The game of Go @ IEEE WCCI 2010", "author": ["C.-S. Lee", "M.-H. Wang", "O. Teytaud", "Y.-L. Wang"], "venue": "IEEE This article is accepted and will be published in IEEE Computational Intelligence Magazine in August 2016 6  Computational Intelligence Magazine, vol. 5, no. 4, pp. 6\u20137, Nov. 2010.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2016}, {"title": "Computational intelligence meets game of Go @ IEEE WCCI 2012", "author": ["C.-S. Lee", "O. Teytaud", "M.-H. Wang", "S.-J. Yen"], "venue": "IEEE Computational Intelligence Magazine, vol. 7, no. 4, pp. 10\u201312, Nov. 2012.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2012}, {"title": "T2FS-based adaptive linguistic assessment system for semantic analysis and human performance evaluation on game of Go", "author": ["C.-S. Lee", "M.-H. Wang", "M.-J. Wu", "O. Teytaud", "S.-J. Yen"], "venue": "IEEE Transactions on Fuzzy Systems, vol. 23, no. 2, pp. 400\u2013420, Apr. 2015.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "Intelligent agents for the game of Go", "author": ["J.-B. Hoock", "C.-S. Lee", "A. Rimmel", "F. Teytaud", "M.-H. Wang", "O. Teytaud"], "venue": "IEEE Computational Intelligence Magazine, vol. 5, no. 4, pp. 28\u201342, Nov. 2010.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2010}, {"title": "Human vs. computer Go: review and prospect @ IEEE CIS: integrated human and computational intelligence for future Go learning based on Google AlphaGo\u2019s historic achievement", "author": ["C.-S. Lee", "M.-H. Wang", "S.-J. Yen", "T.-H. Wei", "I.-C. Wu", "P.-C. Chou", "C.-H. Chou", "M.-W. Wang", "T.-H. Yang"], "venue": "Apr. 2016, [Online] Available: https://sites.google.com/site/nutnoaselabenglish/computergo.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2016}, {"title": "Efficient selectivity and backup operators in Monte-Carlo tree search", "author": ["R. Coulom"], "venue": "H. Jaap van den Herik, P. Ciancarini, and H. H. L. M. (Jeroen) Donkers (editors), Computers and Games, Berlin, Heidelberg, Springer, 2006, pp. 72\u201383.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2006}, {"title": "Bandit based Monte-Carlo planning", "author": ["L. Kocsis", "C. Szepesv\u00e1ri"], "venue": "Proceeding of 17th European Conference on Machine Learning (ECML 2006), Berlin, Germany, Sept. 18\u201322, 2006, pp. 282\u2013293.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2006}, {"title": "Computing Elo ratings of move patterns in the game of Go", "author": ["R. Coulom"], "venue": "Proceeding of Computer Games Workshop 2007 (CGW 2007), Amsterdam, The Netherlands, Jun. 15\u201317, 2007, pp. 113\u2013124.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2007}, {"title": "Teaching deep convolutional neural networks to play Go", "author": ["C. Clark", "A. Storkey"], "venue": "Dec. 2014, [Online] Available: http://arxiv.org/abs/1412.3409.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2014}, {"title": "Move evaluation in Go using deep convolutional neural networks", "author": ["C.J. Maddison", "A. Huang", "I. Sutskever", "D. Silver"], "venue": "Dec. 2014, [Online] Available: http://arxiv.org/abs/1412.6564.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2014}, {"title": "Mastering the game of Go with deep neural networks and tree search", "author": ["D. Silver", "A. Huang", "C.J. Maddison", "A. Guez", "L. Sifre", "G. van den Driessche", "J. Schrittwieser", "I. Antonoglou", "V. Panneershelvam", "M. Lanctot", "S. Dieleman", "D. Grewe", "J. Nham", "N. Kalchbrenner", "I. Sutskever", "T. Lillicrap", "M. Leach", "K. Kavukcuoglu", "T. Graepel", "D. Hassabis"], "venue": "Nature, vol. 529, pp. 484\u2013489, Jan. 2016.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2016}, {"title": "Human go champ beats supercomputer", "author": ["Taipei Times"], "venue": "Mar. 14, 2016, [Online] Available: http://www.taipeitimes.com/News/front/archives/2016/03/14/2003641528.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2016}, {"title": "AlphaGo versus Lee Sedol", "author": ["Wikipedia"], "venue": "Mar. 2016, [Online] Available: https://en.wikipedia.org/wiki/AlphaGo_versus_Lee_Sedol#Difficult_challenge_in_artificial_intelligence.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2016}, {"title": "Google\u2019s AI wins first game in historic match with Go champion", "author": ["Wired"], "venue": "Mar. 2016, [Online] Available: http://www.wired.com/2016/03/googles-ai-wins-first-game-historic-match-go-champion/?mbid=nl_3916.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2016}, {"title": "In two moves, AlphaGo and Lee Sedol redefined the future", "author": ["Wired"], "venue": "Mar. 2016, [Online] Available: http://www.wired.com/2016/03/two-moves-alphago-lee-sedol-redefined-future/.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2016}, {"title": "Official Google Blog: What we learned in Seoul with AlphaGo", "author": ["D. Hassabis"], "venue": "Mar. 2016 [Online] Available: https://googleblog.blogspot.tw/2016/03/what-we-learned-in-seoul-with-alphago.html?m=1.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2016}, {"title": "Sensei\u2019s library", "author": ["A. Hollosi", "M. Pahle"], "venue": "Apr. 2016, [Online] Available: http://senseis.xmp.net/.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2016}, {"title": "Computer program beats European Go champion", "author": ["F. Gobet", "M.H. Ereku"], "venue": "Feb. 2016, [Online] Available: https://www.psychologytoday.com/blog/inside-expertise/201602/computer-program-beats-european-gochampion.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2016}, {"title": "Go Ratings", "author": ["R. Coulom"], "venue": "Apr. 2016, [Online] Available: http://www.goratings.org/.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2016}], "referenceMentions": [{"referenceID": 0, "context": "The descriptions of competitions held from 1998 to 2016 are listed in detail in an online version of this article [1-8].", "startOffset": 114, "endOffset": 119}, {"referenceID": 1, "context": "The descriptions of competitions held from 1998 to 2016 are listed in detail in an online version of this article [1-8].", "startOffset": 114, "endOffset": 119}, {"referenceID": 2, "context": "The descriptions of competitions held from 1998 to 2016 are listed in detail in an online version of this article [1-8].", "startOffset": 114, "endOffset": 119}, {"referenceID": 3, "context": "The descriptions of competitions held from 1998 to 2016 are listed in detail in an online version of this article [1-8].", "startOffset": 114, "endOffset": 119}, {"referenceID": 4, "context": "The descriptions of competitions held from 1998 to 2016 are listed in detail in an online version of this article [1-8].", "startOffset": 114, "endOffset": 119}, {"referenceID": 5, "context": "The descriptions of competitions held from 1998 to 2016 are listed in detail in an online version of this article [1-8].", "startOffset": 114, "endOffset": 119}, {"referenceID": 6, "context": "The descriptions of competitions held from 1998 to 2016 are listed in detail in an online version of this article [1-8].", "startOffset": 114, "endOffset": 119}, {"referenceID": 7, "context": "The descriptions of competitions held from 1998 to 2016 are listed in detail in an online version of this article [1-8].", "startOffset": 114, "endOffset": 119}, {"referenceID": 7, "context": "computer Go competitions are listed in the online version of this article [8].", "startOffset": 74, "endOffset": 77}, {"referenceID": 0, "context": "2 [1].", "startOffset": 2, "endOffset": 5}, {"referenceID": 7, "context": "For more information, eleven programs (Aya, CGI, Coldmilk/Jimmy, Erica, Fuego, MoGo/MoGoTW, Many Faces of Go, Pachi, and Zen) from 7 countries that have participated in past IEEE CIS conferences are listed in alphabetical order in the online version of this article [8].", "startOffset": 266, "endOffset": 269}, {"referenceID": 8, "context": "MCTS was successfully applied to Go in 2006 [9, 10], leading to a significant improvement in playing skill.", "startOffset": 44, "endOffset": 51}, {"referenceID": 9, "context": "MCTS was successfully applied to Go in 2006 [9, 10], leading to a significant improvement in playing skill.", "startOffset": 44, "endOffset": 51}, {"referenceID": 10, "context": "One year later, MM was applied so that programs may recognize move patterns using supervised learning, with expert game records as the training sample [11].", "startOffset": 151, "endOffset": 155}, {"referenceID": 11, "context": "In December of 2014, two teams (one of which is the DeepMind AlphaGo team) applied DCNNs to Go independently [12, 13].", "startOffset": 109, "endOffset": 117}, {"referenceID": 12, "context": "In December of 2014, two teams (one of which is the DeepMind AlphaGo team) applied DCNNs to Go independently [12, 13].", "startOffset": 109, "endOffset": 117}, {"referenceID": 11, "context": "Clark and Storkey [12] first published a paper that applied DCNNs to Go, which, when given a game position, could estimate how expert human players respond with a prediction rate of 41%-44%, exceeding the rate of previous methods.", "startOffset": 18, "endOffset": 22}, {"referenceID": 13, "context": "To illustrate, let us consider the three main neural networks used in AlphaGo: a supervised learning (SL) policy network, a reinforcement learning (RL) policy network, and the value network [14].", "startOffset": 190, "endOffset": 194}, {"referenceID": 13, "context": "This SL process was performed with 30 million game positions, and involved 340 million training steps, taking a total of three weeks with 50 graphic processing units (GPUs) [14].", "startOffset": 173, "endOffset": 177}, {"referenceID": 13, "context": "As a side note, the distributed version of AlphaGo uses 280 GPUs [14].", "startOffset": 65, "endOffset": 69}, {"referenceID": 14, "context": "Everest\u201d of AI [15] because Go is a very complex board game that requires intuitive, creative, and strategic thinking [16].", "startOffset": 15, "endOffset": 19}, {"referenceID": 15, "context": "Everest\u201d of AI [15] because Go is a very complex board game that requires intuitive, creative, and strategic thinking [16].", "startOffset": 118, "endOffset": 122}, {"referenceID": 13, "context": "Google DeepMind introduced a new approach that combined MCTS with deep learning in their program AlphaGo [14], which subsequently broke this four-stone handicap barrier in the recent competition with Lee Sedol (9P) in Korea, in Mar.", "startOffset": 105, "endOffset": 109}, {"referenceID": 7, "context": "5, readers can refer to the online version of this article [8].", "startOffset": 59, "endOffset": 62}, {"referenceID": 19, "context": "Additionally, readers may find details for the Go terminologies used in Comments 1 and 2 at Sensei\u2019s Library [20].", "startOffset": 109, "endOffset": 113}, {"referenceID": 20, "context": "According to cognitive psychologists [21], the difference between experts (for example, Go teachers or professional Go players) and newcomers is that the former can store a variety of Go patterns in their brains, allowing them to quickly find a more precise move than the latter.", "startOffset": 37, "endOffset": 41}, {"referenceID": 13, "context": "side, the single-machine version of AlphaGo was able to win 494 games out of 495 in total, while the distributed version of AlphaGo won all games against these competing programs [14].", "startOffset": 179, "endOffset": 183}, {"referenceID": 13, "context": "The distributed version of AlphaGo had an Elo rating of 3140, the non-distributed version was at 2890, and Fan Hui was at 2908 [14].", "startOffset": 127, "endOffset": 131}, {"referenceID": 21, "context": "At the time of writing, according to an online ranking [22] curated by Go programmer and author of Crazy Stone, R\u00e9mi Coulom, distributed AlphaGo\u2019s Elo rating is 3590 (the second highest rating in the world), where Ke Jie (3624) and Lee Sedol (3525) are ranked as the first and fourth highest Elo rating in the world, respectively.", "startOffset": 55, "endOffset": 59}, {"referenceID": 21, "context": "It is worth noting that the Elo rating system computed in [22] is not exactly the same as the one used in [14].", "startOffset": 58, "endOffset": 62}, {"referenceID": 13, "context": "It is worth noting that the Elo rating system computed in [22] is not exactly the same as the one used in [14].", "startOffset": 106, "endOffset": 110}], "year": 2016, "abstractText": "The Google DeepMind challenge match in March 2016 was a historic achievement for computer Go development. This article discusses the development of computational intelligence (CI) and its relative strength in comparison with human intelligence for the game of Go. We first summarize the milestones achieved for computer Go from 1998 to 2016. Then, the computer Go programs that have participated in previous IEEE CIS competitions as well as methods and techniques used in AlphaGo are briefly introduced. Commentaries from three high-level professional Go players on the five AlphaGo versus Lee Sedol games are also included. We conclude that AlphaGo beating Lee Sedol is a huge achievement in artificial intelligence (AI) based largely on CI methods. In the future, powerful computer Go programs such as AlphaGo are expected to be instrumental in promoting Go education and AI real-world applications. I. Computer Go Competitions The IEEE Computational Intelligence Society (CIS) has funded human vs. computer Go competitions in IEEE CIS flagship conferences since 2009. Fig. 1 shows the year and the location of the conferences. The descriptions of competitions held from 1998 to 2016 are listed in detail in an online version of this article [1-8]. The handicaps for the human vs. computer 19\u00d719 game have been decreased from 29 in 1998 to 0 in 2016. The skill of amateur players in Go is ranked according to kyu (K) in the lower tier, where a smaller number stands for stronger playing skill (with 1K being the highest skill level), and dan (D) in the higher tier, where a larger number stands for stronger playing skill. Professional Go players are ranked entirely in dan, abbreviated with the letter P (e.g. Lee Sedol is ranked at 9P). In the amateur level, each difference in rank roughly translates to a single stone of handicap (H), where the weaker player is allowed to place an additional stone on the board prior to play to even out the game. The skill difference between professional ranks is much less than one stone for every rank difference. Go is typically played on 19\u00d719 size boards, but 9\u00d79 size boards are also common for beginners. The complexity of the 9\u00d79 game is far less than the standard game, and the 9\u00d79 game had been one of the interim goals for computer Go programs. Go is a game that is inherently biased for the first player to play, Black. To compensate for this first player advantage, White is awarded additional points at the end of the game, which is referred to as komi. The related statistics for the IEEE CIS human vs. computer Go competitions are listed in the online version of this article [8]. It is worth noting that with a komi of 7.5, White may end up with an advantage in both 9\u00d79 games and handicapped 19\u00d719 games, regardless of whether White is played by humans or computers. Fig. 2 shows the certificate awarded to the MoGoTW program (16cores / 48GB / 9\u00d79) by the Taiwan Go Association in 2010 for playing at a 3D amateur level * Corresponding author: Chang-Shing Lee (E-mail: leecs@mail.nutn.edu.tw). This article is accepted and will be published in IEEE Computational Intelligence Magazine in August 2016 2 [1]. In this article, we attempt to demonstrate the massive barrier that competing programs need to overcome to achieve comparable performance to AlphaGo. For more information, eleven programs (Aya, CGI, Coldmilk/Jimmy, Erica, Fuego, MoGo/MoGoTW, Many Faces of Go, Pachi, and Zen) from 7 countries that have participated in past IEEE CIS conferences are listed in alphabetical order in the online version of this article [8]. Fig. 1. Past human vs. computer Go competitions in IEEE CIS flagship conferences. Fig. 2. Amateur 3D certificate awarded to MoGoTW in 2010.", "creator": "Microsoft\u00ae Word 2013"}}}