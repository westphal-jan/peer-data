{"id": "1606.02096", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Jun-2016", "title": "Towards Playlist Generation Algorithms Using RNNs Trained on Within-Track Transitions", "abstract": "We introduce a novel playlist generation algorithm that focuses on the quality of transitions using a recurrent neural network (RNN). The proposed model assumes that optimal transitions between tracks can be modelled and predicted by internal transitions within music tracks. We introduce modelling sequences of high-level music descriptors using RNNs and discuss an experiment involving different similarity functions, where the sequences are provided by a musical structural analysis algorithm. Qualitative observations show that the proposed approach can effectively model transitions of music tracks in playlists.", "histories": [["v1", "Tue, 7 Jun 2016 11:07:56 GMT  (253kb,D)", "http://arxiv.org/abs/1606.02096v1", "4 pages, 2 figures, accepted to Workshop on Surprise, Opposition, and Obstruction in Adaptive and Personalized Systems (SOAP) 2016, Halifax, Canada"]], "COMMENTS": "4 pages, 2 figures, accepted to Workshop on Surprise, Opposition, and Obstruction in Adaptive and Personalized Systems (SOAP) 2016, Halifax, Canada", "reviews": [], "SUBJECTS": "cs.AI cs.MM cs.SD", "authors": ["keunwoo choi", "george fazekas", "mark sandler"], "accepted": false, "id": "1606.02096"}, "pdf": {"name": "1606.02096.pdf", "metadata": {"source": "CRF", "title": "Towards Playlist Generation Algorithms Using RNNs Trained on Within-Track Transitions", "authors": ["Keunwoo Choi", "Gy\u00f6rgy Fazekas", "Mark Sandler"], "emails": ["keunwoo.choi@qmul.ac.uk", "g.fazekas@qmul.ac.uk", "m.sandler@qmul.ac.uk"], "sections": [{"heading": null, "text": "CCS concepts \u2022 computer methods \u2192 neural networks; \u2022 applied computer technology \u2192 sound and music computing; keywords recurring neural networks; music playlists; music recommendations"}, {"heading": "1. INTRODUCTION", "text": "This year, it is closer than ever before in the history of the country."}, {"heading": "2. THE PROPOSED MODEL", "text": "Figure 1 illustrates the procedure for building data sets, as well as the training and prediction steps of the proposed algorithm. First, the training paths are segmented and xi, the characteristics for each segment are extracted (Fig. 1a). Then, an RNN of length N (N = 3 in the figure) is trained to learn the transitions of the sequence of feature vectors (Fig. 1b). When a start track is provided, the characteristics of the last N segments are extracted and fed into the tracked RNN to predict the feature vector xpred (Fig. 1c). The algorithm selects a track with a start segment that is most similar to Xpred."}, {"heading": "2.1 Structural Segmentation", "text": "Structural segmentation is a task that aims to find the boundaries of different segments or parts in music, such as intro, verse, bridge, choir. The most common approach is to exploit the self-similarity between the frames of the track [9]. In the experiment, we used a basic and efficient method proposed in [9]. Although the results contain some errors, the feature vector sequences based on imperfect segmentation still approach the information on how each feature changes over time in each track."}, {"heading": "2.2 Feature Extraction", "text": "The proposed algorithm can use methods of feature extraction that are relevant to the listener's musical preferences and capable of representing a musical segment, such as estimated latent features from collaborative filtering [26], tags such as genre and emotion [7], or implicit features such as the weights of the last hidden layer of a neural network classifier [12]. Using explicit terms such as genre can facilitate the explanation of the algorithm's behavior, which is important for research as well as for the listener. In the experiment, an automatic tagging algorithm is used in [5] to predict a 50-dimensional vector whose elements correspond to the probability of each tag. The tagging algorithm is based on profound revolutionary neural networks and was developed on the basis of Million Song Dataset [2]. It shows cutting-edge performance, while the tags cover the diversity of categories such as genre, instrument and epoch."}, {"heading": "2.3 RNN Model", "text": "The aim of RNN training is to predict the characteristic of the following track (xpred), which maintains consistency and fluctuations, i.e. a certain variation over the characteristics. For this purpose, a 2-layer RNN with 512 hidden units is used. LSTM units [10] are used because they represent the state of the art among RNN variants for multiple sequence modeling tasks [11]."}, {"heading": "2.4 Similarity Measure", "text": "The similarity measurement directly influences the properties of the generated playlists and should therefore be selected carefully. Using the cosine spacing may compensate for the increase in popularity and lead to more niche elements being recommended [23]. The Discounted Cumulative Gain (DCG) proved effective in our experiment. DCG is a weighted version of Cumulative Gain (CG). The CG is designed to measure the ranking quality of a retrieved list and the DCG weighting of the most important elements by discounting less relevant elements. Application of this measure was motivated by the type of feature extraction algorithm we use. As DCG high-ranking elements are weighted more strongly, it can theoretically work better."}, {"heading": "3. RESULTS AND DISCUSSION", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Configurations", "text": "For training, we used a private dataset with 28,430 commercial tracks of modern popular music, including rock, hip-hop and jazz. For testing purposes, we used 7,880 tracks from the ILM10k dataset [21] [1]. Segmentation is done using [9], which is implemented in [18]. As mentioned in Section 2, an automatic tagging algorithm was used as a feature extractor [5]. An RNN with a length of 50 is trained. We compared DCG with the cosine distance and the l2 standard for arithmetic similarity. Audio processing and RNN are implemented using Librosa [17], Keras [6] and Theano [25]. Figure 2 shows the transitions of feature vectors in three playlists, which have the same seed track but different similarity metrics. The seed track is represented by a 7-by 50 matrix, i.e., the white lines of each track."}, {"heading": "3.2 Discussions", "text": "First, we found both consistency and fluctuation in the extracted characteristics within the tracks. Generally, several characteristics show consistently large (blue) and small (red) values while the other characteristics vary. It supports the selection of characteristic extraction algorithms. However, there is room for further improvement. Second, the transitions can successfully maintain coherence within the playlists as shown in the figure. However, we noted that the model is prone to missing overall similarity in long playlists, the similarity measurement can be affected by such processes. Second, the transitions keep coherence within the playlists as shown. However, the model is prone to missing overall similarity in long playlists. It may be related to the observation that the trained RNN occasionally predict a vector that has no immediate neighbors."}, {"heading": "4. CONCLUSION", "text": "The proposed combination of RNN, track structure and DCG produced an encouraging result, showing the consistency and dynamics that are adopted in playlists within track structures. An RNN model learned the feature sequences and their predictions are successfully used to select the following tracks. Various similarity measures led to different playlists. Future work will examine advanced architectures such as bidirectional RNNNs [24] and more formal ratings. Bidirectional RNNNs can be used to create playlists that have more constraints, such as start and end tracks [8] and controllability [14]. Formal evaluations include subjective measurements, such as satisfaction and objective measurements of consistency, fluctuations and diversity."}, {"heading": "5. REFERENCES", "text": "[1] Allik, A., Fazekas, G., Barthet, M., andSaldler, F. myMoodplay: an Interactive Mood-based Music Discovery App. In Proc. of the 2nd Web Audio Conference (WAC), April 4-6, 2016, Atlanta, Georgia. (2016). [2] Bertin-Mahieux, T., D. P., Whitman, B., and Lamere, P. Die Million song dataset. In Proceedings of the 12th International Society for Music Information Retrieval Conference, ISMIR 2011, Miami, Florida, USA, October 24-28, 2011 (2011), pp. 591-596. [3] Chen, S., Moore, J. L., and Joachims, T. Playlist prediction via metric embedding. In Proceedings of the 18th ACM SIGKDD international Conference on Knowledge discovery and data mining (2012)."}], "references": [{"title": "myMoodplay: an Interactive Mood-based Music Discovery App", "author": ["A. Allik", "G. Fazekas", "M. Barthet", "M. Saldler"], "venue": "In Proc. of the 2nd Web Audio Conference (WAC), April", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2016}, {"title": "The million song dataset", "author": ["T. Bertin-Mahieux", "D.P. Ellis", "B. Whitman", "P. Lamere"], "venue": "In Proceedings of the 12th International Society for Music Information Retrieval Conference,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2011}, {"title": "Playlist prediction via metric embedding", "author": ["S. Chen", "J.L. Moore", "D. Turnbull", "T. Joachims"], "venue": "In Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining (2012),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2012}, {"title": "Understanding music playlists", "author": ["K. Choi", "G. Fazekas", "M. Sandler"], "venue": "In Proceedings of the ICML 2015: Machine Learning for Music Discovery Workshop", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2015}, {"title": "Automatic tagging using deep convolutional neural networks", "author": ["K. Choi", "G. Fazekas", "M. Sandler"], "venue": "In Proceedings of the Conference on  International Society of Music Information Retrieval,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2016}, {"title": "Keras: Deep learning library for theano and tensorflow", "author": ["F. Chollet"], "venue": "https://github.com/fchollet/keras,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "End-to-end learning for music audio", "author": ["S. Dieleman", "B. Schrauwen"], "venue": "In Acoustics, Speech and Signal Processing (ICASSP),", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "Playlist generation using start and end songs", "author": ["A. Flexer", "D. Schnitzer", "M. Gasser", "G. Widmer"], "venue": "ISMIR", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2008}, {"title": "Automatic audio segmentation using a measure of audio novelty", "author": ["J. Foote"], "venue": "In IEEE International Conference on Multimedia and Expo,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2000}, {"title": "Learning to forget: Continual prediction with lstm", "author": ["F.A. Gers", "J. Schmidhuber", "F. Cummins"], "venue": "Neural computation 12,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2000}, {"title": "Lstm: A search space odyssey", "author": ["K. Greff", "R.K. Srivastava", "J. Kout\u0144\u0131k", "B.R. Steunebrink", "J. Schmidhuber"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2015}, {"title": "Content-aware collaborative music recommendation using pre-trained neural networks", "author": ["D. Liang", "M. Zhan", "E.D.P. Ellis"], "venue": "In Proceedings of the Conference on International Society of Music Information Retrieval", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2015}, {"title": "Dj-mc: A reinforcement-learning agent for music playlist recommendation", "author": ["E. Liebman", "M. Saar-Tsechansky", "P. Stone"], "venue": "In Proceedings of the Conference on Autonomous Agents and Multiagent Systems", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2015}, {"title": "Steerable playlist generation by learning song similarity from radio station playlists", "author": ["F. Maillet", "D. Eck", "G. Desjardins", "P Lamere"], "venue": "In Proceedings of the Conference on International Society of Music Information Retrieval", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2009}, {"title": "The natural language of playlists", "author": ["B. McFee", "G.R. Lanckriet"], "venue": "In Proceedings of the Conference on International Society of Music Information Retrieval (2011),", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2011}, {"title": "Hypergraph models of playlist dialects", "author": ["B. McFee", "G.R. Lanckriet"], "venue": "In Proceedings of the Conference on International Society of Music Information Retrieval", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2012}, {"title": "librosa: Audio and music signal analysis in python", "author": ["B. McFee", "C. Raffel", "D. Liang", "D.P. Ellis", "M. McVicar", "E. Battenberg", "O. Nieto"], "venue": "In Proceedings of the 14th Python in Science Conference", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2015}, {"title": "Msaf: Music structure analysis framework", "author": ["O. Nieto", "J.P. Bello"], "venue": "In Proceedings of the Conference on International Society of Music Information Retrieval", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2015}, {"title": "A tutorial on hidden markov models and selected applications in speech recognition", "author": ["L.R. Rabiner"], "venue": "Proceedings of the IEEE 77,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1989}, {"title": "Introduction to recommender systems handbook", "author": ["F. Ricci", "L. Rokach", "B. Shapira"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2011}, {"title": "Genre-adaptive semantic computing and audio-based modelling for music mood annotation", "author": ["P. Saari", "G. Fazekas", "T. Eerola", "M. Barthet", "O. Lartillot", "M. Sandler"], "venue": "IEEE Transactions on Affective Computing (TAC)", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2015}, {"title": "Long short-term memory based recurrent neural network architectures for large vocabulary speech recognition", "author": ["H. Sak", "A. Senior", "F. Beaufays"], "venue": null, "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2014}, {"title": "Music recommender systems", "author": ["M. Schedl", "P. Knees", "B. McFee", "D. Bogdanov", "M. Kaminskas"], "venue": "In Recommender Systems Handbook. Springer,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2015}, {"title": "Bidirectional recurrent neural networks", "author": ["M. Schuster", "K.K. Paliwal"], "venue": "Signal Processing, IEEE Transactions on 45,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1997}, {"title": "Theano: A python framework for fast computation of mathematical expressions", "author": ["T.T.D. Team", "R. Al-Rfou", "G. Alain", "A. Almahairi", "C. Angermueller", "D. Bahdanau", "N. Ballas", "F. Bastien", "J. Bayer", "A Belikov"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2016}, {"title": "Deep content-based music recommendation", "author": ["A. Van den Oord", "S. Dieleman", "B. Schrauwen"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2013}], "referenceMentions": [{"referenceID": 19, "context": "This is called the cold-start problem [20].", "startOffset": 38, "endOffset": 42}, {"referenceID": 3, "context": "It is well known that unexpectedness, surprise or serendipity play an important role in the music recommendation and discovery [4].", "startOffset": 127, "endOffset": 130}, {"referenceID": 12, "context": "There have been approaches that primarily focus on the transitions of tracks [13], [3], [15].", "startOffset": 77, "endOffset": 81}, {"referenceID": 2, "context": "There have been approaches that primarily focus on the transitions of tracks [13], [3], [15].", "startOffset": 83, "endOffset": 86}, {"referenceID": 14, "context": "There have been approaches that primarily focus on the transitions of tracks [13], [3], [15].", "startOffset": 88, "endOffset": 92}, {"referenceID": 18, "context": "This has been successfully used for sequence modelling for instance in speech [19] too.", "startOffset": 78, "endOffset": 82}, {"referenceID": 15, "context": "In music computing, playlist datasets [16], [14], [3] collaboratively created for reference by DJs and listeners were used for training and evaluation of sequence modelling approaches.", "startOffset": 38, "endOffset": 42}, {"referenceID": 13, "context": "In music computing, playlist datasets [16], [14], [3] collaboratively created for reference by DJs and listeners were used for training and evaluation of sequence modelling approaches.", "startOffset": 44, "endOffset": 48}, {"referenceID": 2, "context": "In music computing, playlist datasets [16], [14], [3] collaboratively created for reference by DJs and listeners were used for training and evaluation of sequence modelling approaches.", "startOffset": 50, "endOffset": 53}, {"referenceID": 15, "context": "101k playlists in [16], the lack of audio data fundamentally limits research based on audio content analysis.", "startOffset": 18, "endOffset": 22}, {"referenceID": 21, "context": "Recently, recurrent neural networks (RNNs) have become widely used for sequence modelling in tasks such as speech recognition, substantially outperforming previous hidden Markov model-based approaches [22].", "startOffset": 201, "endOffset": 205}, {"referenceID": 9, "context": "The success of the application of RNNs largely relies on the introduction of Long Short-Term Memory (LSTM) units [10].", "startOffset": 113, "endOffset": 117}, {"referenceID": 8, "context": "The most common approach is to take advantage of self-similarity between frames of the track [9].", "startOffset": 93, "endOffset": 96}, {"referenceID": 8, "context": "In the experiment, we used a basic and efficient method that is proposed in [9].", "startOffset": 76, "endOffset": 79}, {"referenceID": 25, "context": "This includes estimated latent features from collaborative filtering [26], tags such as genre and emotion [7] or implicit features such as the weights of the last hidden layer of a neural network classifier [12].", "startOffset": 69, "endOffset": 73}, {"referenceID": 6, "context": "This includes estimated latent features from collaborative filtering [26], tags such as genre and emotion [7] or implicit features such as the weights of the last hidden layer of a neural network classifier [12].", "startOffset": 106, "endOffset": 109}, {"referenceID": 11, "context": "This includes estimated latent features from collaborative filtering [26], tags such as genre and emotion [7] or implicit features such as the weights of the last hidden layer of a neural network classifier [12].", "startOffset": 207, "endOffset": 211}, {"referenceID": 4, "context": "In the experiment, an auto tagging algorithm in [5] is used to predict a 50-dimensional vector whose elements correspond to the probability of each tag.", "startOffset": 48, "endOffset": 51}, {"referenceID": 1, "context": "The tagging algorithm is based on deep convolutional neural networks and trained on Million Song Dataset [2].", "startOffset": 105, "endOffset": 108}, {"referenceID": 9, "context": "LSTM units [10] are used as they show state-of-the-art performance among RNN variants for several sequence modelling tasks [11].", "startOffset": 11, "endOffset": 15}, {"referenceID": 10, "context": "LSTM units [10] are used as they show state-of-the-art performance among RNN variants for several sequence modelling tasks [11].", "startOffset": 123, "endOffset": 127}, {"referenceID": 22, "context": "Using the cosine distance may compensate for the popularity bias and result in recommending more niche items [23].", "startOffset": 109, "endOffset": 113}, {"referenceID": 20, "context": "We used 7,880 tracks from the ILM10k dataset for testing [21] [1].", "startOffset": 57, "endOffset": 61}, {"referenceID": 0, "context": "We used 7,880 tracks from the ILM10k dataset for testing [21] [1].", "startOffset": 62, "endOffset": 65}, {"referenceID": 8, "context": "The segmentation is performed using [9], which is implemented in [18].", "startOffset": 36, "endOffset": 39}, {"referenceID": 17, "context": "The segmentation is performed using [9], which is implemented in [18].", "startOffset": 65, "endOffset": 69}, {"referenceID": 4, "context": "As mentioned in Section 2, an automatic tagging algorithm was used as a feature extractor [5].", "startOffset": 90, "endOffset": 93}, {"referenceID": 16, "context": "Audio processing and RNN are implemented using librosa [17], Keras [6], and Theano [25].", "startOffset": 55, "endOffset": 59}, {"referenceID": 5, "context": "Audio processing and RNN are implemented using librosa [17], Keras [6], and Theano [25].", "startOffset": 67, "endOffset": 70}, {"referenceID": 24, "context": "Audio processing and RNN are implemented using librosa [17], Keras [6], and Theano [25].", "startOffset": 83, "endOffset": 87}, {"referenceID": 23, "context": "Future work will investigate advanced architectures such as bidirectional RNNs [24] and more formal assessments.", "startOffset": 79, "endOffset": 83}, {"referenceID": 7, "context": "start and end tracks [8] and steerability [14].", "startOffset": 21, "endOffset": 24}, {"referenceID": 13, "context": "start and end tracks [8] and steerability [14].", "startOffset": 42, "endOffset": 46}], "year": 2016, "abstractText": "We introduce a novel playlist generation algorithm that focuses on the quality of transitions using a recurrent neural network (RNN). The proposed model assumes that optimal transitions between tracks can be modelled and predicted by internal transitions within music tracks. We introduce modelling sequences of high-level music descriptors using RNNs and discuss an experiment involving different similarity functions, where the sequences are provided by a musical structural analysis algorithm. Qualitative observations show that the proposed approach can effectively model transitions of music tracks in playlists.", "creator": "LaTeX with hyperref package"}}}