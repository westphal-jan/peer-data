{"id": "1606.02126", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Jun-2016", "title": "Supervised Syntax-based Alignment between English Sentences and Abstract Meaning Representation Graphs", "abstract": "As alignment links are not given between English sentences and Abstract Meaning Representation (AMR) graphs in the AMR annotation, automatic alignment becomes indispensable for training an AMR parser. Previous studies formalize it as a string-to-string problem, and solve it in an unsupervised way. In this paper, we formalize it as a syntax-based alignment problem, and solve it in a supervised manner based on the syntax trees. Experiments verify the effectiveness of the proposed method.", "histories": [["v1", "Tue, 7 Jun 2016 13:00:48 GMT  (1893kb)", "https://arxiv.org/abs/1606.02126v1", null], ["v2", "Fri, 9 Sep 2016 07:26:13 GMT  (1657kb)", "http://arxiv.org/abs/1606.02126v2", "Added significance test results"], ["v3", "Mon, 12 Sep 2016 01:02:41 GMT  (1656kb)", "http://arxiv.org/abs/1606.02126v3", "Added significance test results"], ["v4", "Sat, 18 Feb 2017 01:53:58 GMT  (1780kb)", "http://arxiv.org/abs/1606.02126v4", "Updated the paper with AMR parsing results"]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["chenhui chu", "sadao kurohashi"], "accepted": false, "id": "1606.02126"}, "pdf": {"name": "1606.02126.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Sadao Kurohashi"], "emails": ["chu@pa.jst.jp,", "kuro@i.kyoto-u.ac.jp"], "sections": [{"heading": null, "text": "ar Xiv: 160 6.02 126v 4 [cs.C L] February 18, 2017Supervised Syntax-based Alignment between English Sentences and Abstract Meaning Representation GraphsChenhui Chu1 and Sadao Kurohashi2 1Japan Science and Technology Agency2Graduate School of Informatics, Kyoto University chu @ pa.jst.jp, kuro @ i.kyoto-u.ac.jpAbstractAs alignment links are not given between English Sentences and Abstract Meaning Representation (AMR) graphs in the AMR annotation, automatic alignment becomes indispensable for training an AMR parser. Previous studies formalize it as a string-to-string problem and solve it in an uncontrolled way that suffers from data economy due to the small size of training data for the English AMR alignment."}, {"heading": "1 Introduction", "text": "Abstract Meaning Representation (AMR et al.) is a gang level semantic annotation et et et al in 2015; we et al; which is always; A rooted, directed, and edge-labeled graph [Banarescu et al.) is a gang level semantic annotation et et al in Figure 1), of course $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$"}, {"heading": "2 Related Work", "text": "This means that in Figure 1 the English word \"gas\" should not be explicitly aligned with the diagram fragment. \"(t / thing: ARG2-of (p2 / price-01: AMR1). However, its criterion does not mean that the roles are explicitly assigned. [Flanigan et al., 2014] suggested a rules-based method for this kind of alignment. [Pourdamghani et al., 2014] suggested an arrangement. [Pourdamghani et al., 2014] suggested an arrangement. [Pourdamghani et al., 2014] suggested an arrangement."}, {"heading": "3 Baseline Alignment Method", "text": "The basic method we compare with is ISI alignment [Pourdamghani et al., 2014]. The ISI alignment method formalizes the English-AMR graph alignment problem as a string-to-string alignment problem by linearising an AMR graph into a string. It comprises three steps: pre-processing, string-to-string alignment, and post-processing."}, {"heading": "3.1 Preprocessing", "text": "\u2022 Linearize the AMR using an initial reversal in depth. For example, in Figure 1, the AMR graph is linearized to \"possible: domain go-01: ARG1 thing: ARG2-of price01: ARG1 gas: quant volume-quantity: quant 1: unit gallon: ARG4 money-quantity: quant 10: unit dollar.\" \u2022 Remove the tokens that are rarely matched to each other to improve precision with a small victim of the recall. On the English side, this removes stopwords such as article \"a,\" \"an,\" \"the\"; on the AMR side, special concepts and roles such as \": arg0,\" \"quant\": op1, \"which normally do not match, quotes and tags are removed. After this step, the English sentence in Figure 1\" gas could go to $10 gallon \"; the AMR is removed to\" possible: gas domain thing: quant, \"which usually does not match\" quotes and tags. \""}, {"heading": "3.2 String-to-String Alignment", "text": "Since the pre-processing step has transformed the English AMR graph alignment problem into a string-to-string alignment problem, the widely used IBM alignment models [Brown et al., 1993], which are based on token sequences, can be applied. To further improve alignment accuracy, [Pourdamghani et al., 2014] also proposed a symmetry restriction that promotes two-way parameter learning for IBM models."}, {"heading": "3.3 Postprocessing", "text": "The string-to-string adjustments are then projected back to the original English sentence and the AMR graph to obtain the English-AMR graph adjustments, which can easily be done by memorizing the corresponding symbol positions before and after pre-processing."}, {"heading": "4 Proposed Alignment Method", "text": "We use the same pipeline as [Pourdamghani et al., 2014], but formalize it as a constituency tree-based alignment problem and apply the hierarchical alignment model of [Riesa et al., 2011]. This method has been proposed for the conventional word alignment of MT, but not for the alignment of English-AMR diagrams."}, {"heading": "4.1 Constituency Trees for English and AMR", "text": "In this study, we analyze original English sentences with the Berkeley parser4 [Petrov and Klein, 2007]. We process preserved constituency trees by discarding the stopwords and replacing the leaf markers with their trunks. An example of the final tree is in Figure 2. For AMR, we convert AMRs into constituency trees using the method proposed in [Pust et al., 2015] with the following steps: \u2022 Arbitrary separation of multiple parents from each node. \u2022 Multiply the margins (scrolls) to leaves and add Preterminal X. \u2022 Restructure the tree with role labels as intermediate steps. We do not apply the reordering steps because they require adjustments. For more details of these steps, see [Pust et al., 2015]. We used the AMR for syntax tree conversion provided by [Pust al., 2015] for the English conversion of AMR trees."}, {"heading": "4.2 Hierarchical Alignment on Constituency Trees", "text": "Figure 2 shows an overview of the application of the hierarchical alignment model [Riesa et al., 2011] to our problem. The model searches hierarchically for the k-best alignment by constructing partial alignments over a target choice tree, 5 in a bottom-up manner (from nodes to roots).4https: / / github.com / slavpetrov / berkeleyparser 5The source page could be either a constituency tree or a token sequence.Each node in the tree has partial alignments sorted by alignment values. A partial alignment for a node is an alignment matrix of AMR tokens or zero, covered by the node, and it is represented as a black square. We consider only a beam size of k for partial alignments for each node, 6 to reduce compilation costs."}, {"heading": "5 Experiments", "text": "We conducted both alignment and AMR analysis experiments to verify the effectiveness of our proposed alignment method."}, {"heading": "5.1 Settings", "text": "The data used in our experiments was the Linguistic Data Consortium AMR corpus release 1.0 (LDC2014T12), which was used in our experiments. (LDC2014T12) The data we used for our training is shown in the upper ranges of Table 1. (Among the 100 development models in our study, which we compared with gold alignments, we were compared with gold alignments.) Since these 200 pairs were used for training and testing (and tuning for our proposed alignment model), we moved the 7https models in our study. / / catalog.ldc.upenn.edu / LDC2014T12 8http: / www.edu / natural-language / mt / dev-gold.txt 9http."}, {"heading": "5.2 Alignment Results", "text": "This year, it has reached the stage where it will be able to take the lead."}, {"heading": "5.3 AMR Parsing Results", "text": "The results of the AMR analysis are shown in Table 5, where \"Our split\" performance for different parsers based on our data allocation of the AMR corpus.12 For reference: we12As the parsers of [Werling et al., 2015; Zhou et al., 2016; Peng et al., 2017] are not publicly available, we could not report the performance of their parser on our data allocation. We were unable to list the parsers of [Artzi et al., 2015; Misra et al., 2016] on our allocation, and the accuracy of the analysis on the original allocation was also shown in [Pust et al., 2015; Flanigan et al., 2014; Wang et al., 2015; Zhou et al., 2016] in the \"original column\" of Table 5.13 \"[Pust et al., 2015] (Pust et al.) [Pust et al., [Pust et al., 2015].\""}, {"heading": "6 Conclusion", "text": "We improved alignment accuracy with a monitored syntax-based alignment method. We demonstrated the effectiveness of the monitored method in both alignment and AMR parsing, even if only a very small training dataset (i.e. 100 pairs) is available. In the future, we plan to first increase the number of AMR / English gold alignment pairs to train a more accurate alignment model. Secondly, we plan to improve alignment accuracy for roles. Semantic role labeling [Gildea and Jurafsky, 2000] for English sentence 13 Note that [Flanigan et al., 2014] did not specify the result of this dataset in their work. [Pust et al., 2015] reported on the alignment performance of the parser of [Flanigan et al., 2014] for this dataset that we have listed."}, {"heading": "Acknowledgments", "text": "We thank Mr. Michael Pust very much for providing the conversion code for the AMR tree in the constituency and for helping to carry out the AMR parsing experiments on his parser. We also thank Mr. Yevgeny Puzikov very much for his help in carrying out the AMR parsing experiments on the JAMR and CAMR parsers."}], "references": [{"title": "Broad-coverage ccg semantic parsing with amr", "author": ["Artzi et al", "2015] Yoav Artzi", "Kenton Lee", "Luke Zettlemoyer"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2015\\E", "shortCiteRegEx": "al. et al\\.", "year": 2015}, {"title": "Abstract meaning representation for sembanking", "author": ["Banarescu et al", "2013] Laura Banarescu", "Claire Bonial", "Shu Cai", "Madalina Georgescu", "Kira Griffitt", "Ulf Hermjakob", "Kevin Knight", "Philipp Koehn", "Martha Palmer", "Nathan Schneider"], "venue": "In Proceedings of the 7th Linguistic Annota-", "citeRegEx": "al. et al\\.,? \\Q2013\\E", "shortCiteRegEx": "al. et al\\.", "year": 2013}, {"title": "The mathematics of statistical machine translation: Parameter estimation", "author": ["Brown et al", "1993] Peter F. Brown", "Stephen A. Della Pietra", "Vincent J. Della Pietra", "Robert L. Mercer"], "venue": "Computational Linguistics,", "citeRegEx": "al. et al\\.,? \\Q1993\\E", "shortCiteRegEx": "al. et al\\.", "year": 1993}, {"title": "Smatch: an evaluation metric for semantic feature structures", "author": ["Cai", "Knight", "2013] Shu Cai", "Kevin Knight"], "venue": null, "citeRegEx": "Cai et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Cai et al\\.", "year": 2013}, {"title": "Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms", "author": ["Michael Collins"], "venue": "[Collins,", "citeRegEx": "Collins.,? \\Q2002\\E", "shortCiteRegEx": "Collins.", "year": 2002}, {"title": "A discriminative graph-based parser for the abstract meaning representation", "author": ["Flanigan et al", "2014] Jeffrey Flanigan", "Sam Thomson", "Jaime Carbonell", "Chris Dyer", "Noah A. Smith"], "venue": "In Proceedings of the 52nd Annual Meet-", "citeRegEx": "al. et al\\.,? \\Q2014\\E", "shortCiteRegEx": "al. et al\\.", "year": 2014}, {"title": "Automatic labeling of semantic roles", "author": ["Gildea", "Jurafsky", "2000] Daniel Gildea", "Daniel Jurafsky"], "venue": null, "citeRegEx": "Gildea et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Gildea et al\\.", "year": 2000}, {"title": "Neural shift-reduce ccg semantic parsing", "author": ["Misra", "Artzi", "2016] Dipendra Kumar Misra", "Yoav Artzi"], "venue": null, "citeRegEx": "Misra et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Misra et al\\.", "year": 2016}, {"title": "A systematic comparison of various statistical alignment models", "author": ["Och", "Ney", "2003] Franz Josef Och", "Hermann Ney"], "venue": "Computational Linguistics,", "citeRegEx": "Och et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Och et al\\.", "year": 2003}, {"title": "The proposition bank: An annotated corpus of semantic roles", "author": ["Palmer et al", "2005] Martha Palmer", "Daniel Gildea", "Paul Kingsbury"], "venue": "Comput. Linguist.,", "citeRegEx": "al. et al\\.,? \\Q2005\\E", "shortCiteRegEx": "al. et al\\.", "year": 2005}, {"title": "Addressing the data sparsity issue in neural amr parsing", "author": ["Peng et al", "2017] Xiaochang Peng", "Chuan Wang", "Daniel Gildea", "Nianwen Xue"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2017\\E", "shortCiteRegEx": "al. et al\\.", "year": 2017}, {"title": "Improved inference for unlexicalized parsing", "author": ["Petrov", "Klein", "2007] Slav Petrov", "Dan Klein"], "venue": null, "citeRegEx": "Petrov et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Petrov et al\\.", "year": 2007}, {"title": "Aligning english strings with abstract meaning representation graphs", "author": ["Pourdamghani et al", "2014] Nima Pourdamghani", "Yang Gao", "Ulf Hermjakob", "Kevin Knight"], "venue": "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "al. et al\\.,? \\Q2014\\E", "shortCiteRegEx": "al. et al\\.", "year": 2014}, {"title": "Parsing english into abstract meaning representation using syntax-based machine translation", "author": ["Pust et al", "2015] Michael Pust", "Ulf Hermjakob", "Kevin Knight", "Daniel Marcu", "Jonathan May"], "venue": "In Proceedings of the 2015 Confer-", "citeRegEx": "al. et al\\.,? \\Q2015\\E", "shortCiteRegEx": "al. et al\\.", "year": 2015}, {"title": "Feature-rich language-independent syntax-based alignment for statistical machine translation", "author": ["Riesa et al", "2011] Jason Riesa", "Ann Irvine", "Daniel Marcu"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2011\\E", "shortCiteRegEx": "al. et al\\.", "year": 2011}, {"title": "Boosting transition-based amr parsing with refined actions and auxiliary analyzers", "author": ["Wang et al", "2015] ChuanWang", "Nianwen Xue", "Sameer Pradhan"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2015\\E", "shortCiteRegEx": "al. et al\\.", "year": 2015}, {"title": "Robust subgraph generation improves abstract meaning representation parsing", "author": ["Werling et al", "2015] Keenon Werling", "Gabor Angeli", "Christopher D. Manning"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2015\\E", "shortCiteRegEx": "al. et al\\.", "year": 2015}, {"title": "Interpreting bleu/nist scores: How much improvement do we need to have a better system", "author": ["Zhang et al", "2004] Ying Zhang", "Stephan Vogel", "Alex Waibel"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2004\\E", "shortCiteRegEx": "al. et al\\.", "year": 2004}], "referenceMentions": [{"referenceID": 4, "context": "The weights of the features are learnt against a set of pairs with gold alignments, using the online averaged perceptron algorithm [Collins, 2002].", "startOffset": 131, "endOffset": 146}], "year": 2017, "abstractText": "As alignment links are not given between English sentences and Abstract Meaning Representation (AMR) graphs in the AMR annotation, automatic alignment becomes indispensable for training an AMR parser. Previous studies formalize it as a string-to-string problem and solve it in an unsupervised way, which suffers from data sparseness due to the small size of training data for EnglishAMR alignment. In this paper, we formalize it as a syntax-based alignment problem and solve it in a supervised manner based on syntax trees, which can address the data sparseness problem by generalizing English-AMR tokens to syntax tags. Experiments verify the effectiveness of the proposed method not only for English-AMR alignment, but also for AMR parsing.", "creator": "LaTeX with hyperref package"}}}