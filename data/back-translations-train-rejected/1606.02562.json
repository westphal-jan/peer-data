{"id": "1606.02562", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Jun-2016", "title": "DialPort: Connecting the Spoken Dialog Research Community to Real User Data", "abstract": "This paper describes a new spoken dialog portal that connects systems produced by the spoken dialog academic research community and gives them access to real users. We introduce a distributed, multi-modal, multi-agent prototype dialog framework that affords easy integration with various remote resources, ranging from end-to-end dialog systems to external knowledge APIs. To date, the DialPort portal has successfully connected to the multi-domain spoken dialog system at Cambridge University, the NOAA (National Oceanic and Atmospheric Administration) weather API and the Yelp API.", "histories": [["v1", "Wed, 8 Jun 2016 14:08:21 GMT  (8514kb,D)", "http://arxiv.org/abs/1606.02562v1", "Under Peer Review of SigDial 2016"]], "COMMENTS": "Under Peer Review of SigDial 2016", "reviews": [], "SUBJECTS": "cs.AI cs.CL", "authors": ["tiancheng zhao", "kyusong lee", "maxine eskenazi"], "accepted": false, "id": "1606.02562"}, "pdf": {"name": "1606.02562.pdf", "metadata": {"source": "CRF", "title": "DialPort: Connecting the Spoken Dialog Research Community to Real User Data", "authors": ["Tiancheng Zhao", "Kyusong Lee", "Maxine Eskenazi"], "emails": ["tianchez@cs.cmu.edu,", "max+@cs.cmu.edu,", "kyusonglee@postech.ac.kr"], "sections": [{"heading": "1 Introduction", "text": "The advent of Siri, Cortana, and other agents has piqued interest in spoken dialogue research, which has captured the imagination of many and led them to believe that talking to smart agents is useful, and the research community needs to capitalize on that interest by creating a public service that can collect real user data that can be used to make dialogue systems more robust, and it can also be used to conduct experiments in comparative studies."}, {"heading": "2 Related Work", "text": "Several SDS building industry platforms have recently become available to non-skilled developers. Microsoft Research released a Language Understanding Intelligent Service (LUIS) (Williams et al., 2015) that helps software developers create cloud-based, machine-learning language understanding models for specific application areas. Facebook is building an AI platform that helps developers create chatbots that can communicate in natural language.The HALEF (Help AssistantLanguage-Enabled and Free) framework from ETS uses various open source components to build an SDS framework that is modular and industry standard compliant (SuendermannOeft et al., 2015). Although these platforms have helped researchers build robust SDSs more efficiently, the data collected has not been shared with the academic research community. Most early SDS work focused on single domain SDS, such as bus schedules or museum environments."}, {"heading": "3 Architecture", "text": "Figure 1 shows the system architecture, which consists of three sections: UI, DialPort and Remote Agents."}, {"heading": "3.1 User Interface", "text": "The user interface is the publicly available frontend for real users3. It is responsible for both the visual and audio agents that represent each dialog system. Visually, it uses WebGL Unity 3D, which is discussed in Section 4. The audio page uses the Google Chrome Speech ASR API to convert the user's language into text, and the Google Chrome TTS API to convert the text output from DialPort to English."}, {"heading": "3.2 DialPort", "text": "DialPort is scalable and distributed.Its central message broker is ActiveMQ, a well-known open source message broker. ActiveMQ allows us to easily combine multiple components to create a larger system.Building on ActiveMQ, DialPort has four main modules: the HTTP API server, the Natural Language Understanding (NLU), the ReinForest Dialog Manager (DM) and the Natural Language Generation (NLG).With the exception of the ReinForest DM, the RESTful (Representational State Transfer) modules are web services: they do not take government information into account when processing queries. All contextual information about a dialogue is maintained by the ReinForest DM. The HTTP API server is the entrance gate to DialPort. It converts the incoming HTTP messages into proper ActiveMQ messages and sends them to the NLU. The NLU output provides a semantic framework from the original expression."}, {"heading": "3.3 Remote Agents", "text": "We define a remote agent as any external resource that can be integrated into the DialPort ecosystem. Generally, there are three types of remote agent: Audio Remote Agent, Text Remote Agent, and Knowledge Remote Agent. Audio Remote Agent: This is a self-supporting voice dialog system that only has a public audio API. Therefore, an Audio Remote Agent expects audio streaming input and returns an audio clip that contains the system's spoken response. DialPort does not currently support this type of remote agent because it is difficult to handle real-time audio streaming between remote servers, which is processed when a connection to a system of this kind is proposed. Text Remote Agent: This type of agent provides text API that inputs the latest ASR text output and returns the next system response in text form. It should be noted that even text-to-end speech systems can include remote-to-speech."}, {"heading": "4 Virtual Agent", "text": "In this section, Skylar and Jasmin are introduced. Skylar is the virtual agent for DialPort. Jasmin is the dialog system agent of Cambridge University. Both agents interact with the user via a web language interface and have 3D animated embodiments driven by Unity 3D Engineering. The way in which nonverbal expression (agent behavior) is handled is important. Users must be able to easily interpret the current and next status of the agents. DialPort uses a variety of character animations such as (a) standing, (b) listening, (c) understanding, (d) thinking and (e) speaking (Figure 2) so that users implicitly know when to speak or wait for the ASR results. In addition, the non-verbal expressions of a virtual agent indicate which agent the system believes the user is talking to."}, {"heading": "5 The ReinForest Dialog Manager", "text": "The challenges faced by the DialPort dialog manager are that 1) it needs to support simple expansion to a variety of areas and 2) it needs to support mixed initiatives and mixed (non) goal-oriented dialogs. Specifically, for these two challenges, we have developed a new dialog manager based on RavenClaw (Bohus and Rudnicky, 2003). The overview of the ReinForest DM is illustrated in Figure 3. ReinForest's core consists of two parts: the Knowledge Ontology and the Dialog Engine. Knowledge Ontology is a domain-dependent knowledge graph that allows developers to quickly code domain knowledge and relationships between different concepts. The DialPort dialog Engine is a domain-independent execution mechanism that generates the next system response given the current state of the dialog. The following sections formally define these two components."}, {"heading": "5.1 Knowledge Ontology", "text": "The basic unit of ontology is a concept that is an abstraction of knowledge. Knowledge of the weather, for example, is a concept. A concept can have a number of dependent concepts that encode the causal relationship. In the field of weather, for example, the weather concepts depend on the concept of the place and the date time. Therefore, in order to provide weather information, the system must have already acquired the values of date and place. More importantly, each remote agent is also presented as a concept. For example, the Cambridge MultiDomain Dialog System is presented as a single concept that contains information about all the areas it covers. Concept Pool: Given the definition of a concept, ReinForest allows developers to construct domain knowledge in the form of a directed acyclic graph (DAG). ReinForest also introduces the idea of a concept pool to create concept groups. Figure 4 gives a simple example of a concept pool of concept knowledge in the form of a guided acyclic graph (DAG) in which the user divides certain concepts."}, {"heading": "5.2 Dialog Engine", "text": "As shown in Figure 3, the ReinForest dialog engine is a domain-independent execution mechanism consisting of 4 modules: hierarchical pole-icy execution, faith update, tree transformation and error handling. Algorithm 1 shows the pseudo-code of the main execution loop within ReinForest. The dialog engine connects to the knowledge anontology via the dialog status s, which captures all information about the ongoing dialogs. Next, we formally define these four modules. Algorithm 1 ReinForest Main Loop while dialog.end () 6 = True dowhile dialog stack.top () \u2022 O do execute (dialog stack.pop () end, while, if the user has entered, faith update () tree transformation () error handle () end if end while end"}, {"heading": "5.3 Hierarchical Policy", "text": "Hierarchical policy has been extensively studied in the literature of both hierarchical reinforcement learning (HRL) (Dietterich, 2000; Parr and Russell, 1998; Sutton et al., 1999) and plan-based dialogue management (Bohus and Rudnicky, 2003; Bohus and Rudnicky, 2009).ReinForest's contribution is that it formalizes plan-based dialogue management in the language of HRL, which opens the possibility of applying well-established HRL algorithms to optimize the operations of the plan-based dialogue manager. We first present the notations of HRL and then define the dialogue task tree using this language. Hierarchical reinforcement learning: The mathematical framework of HRL is the Markov decision-making process (MDP).An MDP is a tuple (S, A, P, \u03b3, R) where S is a set of states."}, {"heading": "5.4 Belief Update", "text": "This component first updates the general dialog states, e.g. the number of dialog turns. It then goes through all the concepts in the knowledge ontology and checks whether the annotations in the new input match each logged-in domain / intention / entity in each concept. If a match is found, the new values are stored in the attribute map of the concept."}, {"heading": "5.5 Tree Transformation", "text": "The transformation consists of two steps: generation of the Candidate Tree and selection of the Candidate Tree. Generation of the Candidate Tree: Scans the updates made by faith update and creates a list of the Candidate Tree that can be moved to the dialog stack (the list can also be \u2205). Normally, a candidate is generated when the user explicitly requests the kind of information that is managed by another domain. Candidate Selection: The selected Candidate Tree are appended under a dialog selection agency. The dialog selection agency selects one of the trees and pushes it onto the dialog stack."}, {"heading": "5.6 Error Handling", "text": "There are two types of error handling: the handling of misunderstandings and the handling of ununderstood errors (Bohus and Rudnicky, 2003). The handling of misunderstandings is used to perform explicit or implicit confirmations about concepts in knowledge sontology. Specifically, the dialogue engine will run through all concepts in the user concept pool and select concepts that are updated but not yet based on misunderstandings. A sub-task for misunderstandings is then pushed onto the stack. The Misunderstandings sub-task chooses a built-in strategy to validate each concept. The current implementation supports two types of strategies: implicit and explicit confirmation. On the other hand, the handling of misunderstandings is activated when there are user inputs but no updating or tree transformation can be successful. ReinForest implements a wide range of strategies to handle misunderstandings that range from the simple question \"Can you repeat this?\" to an external Chat response."}, {"heading": "5.7 Execution Demonstration", "text": "Figure 5 shows a sample dialog with ReinForest. First, the dialog machine pushes the root onto the stack and asks what the user needs. After the user realizes that he is looking for weather information, he pushes the weather domain tree onto the stack. After capturing all dependent concepts, Skylar informs the user about the weather information. The user then decides to request restaurant information that is covered by the Cambridge Remote Agent so that it is pushed onto the stack. At this point, ReinForest transfers the control to Cambridge and simply calls next to the remote agent to get the next answer. When the remote agent ends his own session, Skylar takes back control and resumes the conversation."}, {"heading": "6 Non-goal-driven Dialog Manager", "text": "If a user's input cannot be handled by ReinForest, such as utterances outside the domain (e.g. \"You are intelligent\"), specific questions (e.g., who founded Microsoft?, how much is an iPhone?), failure to understand error handling policy triggers a user's non-targeted request to generate a system response. Targeted dialog systems focus on a set of pre-defined requests within the domain, non-targeted dialog systems have to deal with open domain statements that basically have unlimited user intentions. Most previous non-targeted approaches use either handmade pattern matching rules or example-based approaches that use a database manually designed by human experts. Recently, recurring neural network-based approaches based on large movie transcription corptions have been proposed (Table 2)."}, {"heading": "7 Integration Protocol", "text": "This simple integration protocol concerns the text Remote Agent and the knowledge Remote Agent. Text Remote Agent: A Text Remote Agent is a di6http: / / freebase.comalog agency that is defined in Section 5 and only needs to implement two APIs: \u2022 NewCall (id, s0): Input parameters include the user ID and the current dialog status s0. Output is the first system response. The initial state s0 allows the Remote Agent to skip redundant questions that have already been asked in the previous conversation. DialPort calls this function to initiate a new session with the Remote Agent. Also, it is up to the Remote Research Group how they use s0 so that the Remote Agent can operate completely independently. The exact format of s0 can be customized as needed."}, {"heading": "8 Current State of DialPort", "text": "The first academic system connected to DialPort comes from the University of Cambridge. In the near future, any academic system that can be connected will be welcome to join the portal. Figure 6 shows the two current agents: a butler named Skylar from the CMU and a librarian named Jasmin from Cambridge. Their appearance could change at a later date. DialPort will begin to attract users to these systems as soon as there is a series of stability tests and when several other remote agents like Yelp join in order to increase interest. Skylar from the CMU will provide information about the weather and restaurants except in Cambridge and San Francisco. Its mission is also to \"sell\" the other systems and get the user to try them. When the domain changes, a new avatar will appear and conduct the conversation. When the dialogue about the topic of the connected systems is over, the user will be returned to Skylar. The transition occurs seamlessly from the user's point of view Jasmin from the hotel, and information about the San Francisco restaurant he is speaking to is displayed in the Skylar when the San Francisco restaurant logo is displayed."}, {"heading": "9 Conclusions", "text": "In this article we described the architecture of the user interface, DialPort, virtual agents and (non) target-oriented dialog managers and reported on the current progress of the DialPort project. An important purpose of this post is to encourage our colleagues to connect their systems to DialPort so that we can help them collect real user data."}, {"heading": "10 Acknowledgements", "text": "This work was funded by the NSF grant CNS1512973. Opinions expressed in this paper do not necessarily reflect those of NSF. We would also like to thank the Dialogue Systems Group in Cambridge for their hard work in establishing the connection with DialPort."}], "references": [{"title": "Iris: a chat-oriented dialogue system based on the vector space model", "author": ["Banchs", "Li2012] Rafael E Banchs", "Haizhou Li"], "venue": "In Proceedings of the ACL 2012 System Demonstrations,", "citeRegEx": "Banchs et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Banchs et al\\.", "year": 2012}, {"title": "Ravenclaw: Dialog management using hierarchical task decomposition and an expectation agenda", "author": ["Bohus", "Rudnicky2003] Dan Bohus", "Alexander I Rudnicky"], "venue": null, "citeRegEx": "Bohus et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Bohus et al\\.", "year": 2003}, {"title": "The ravenclaw dialog management framework: Architecture and systems", "author": ["Bohus", "Rudnicky2009] Dan Bohus", "Alexander I Rudnicky"], "venue": "Computer Speech & Language,", "citeRegEx": "Bohus et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Bohus et al\\.", "year": 2009}, {"title": "Hierarchical reinforcement learning with the maxq value function decomposition", "author": ["Thomas G Dietterich"], "venue": "J. Artif. Intell. Res.(JAIR),", "citeRegEx": "Dietterich.,? \\Q2000\\E", "shortCiteRegEx": "Dietterich.", "year": 2000}, {"title": "Distributed dialogue policies for multi-domain statistical dialogue management", "author": ["Gasic et al.2015] M Gasic", "Dongho Kim", "Pirros Tsiakoulis", "Steve Young"], "venue": "In Acoustics, Speech and Signal Processing (ICASSP),", "citeRegEx": "Gasic et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Gasic et al\\.", "year": 2015}, {"title": "Multi-domain spoken dialogue system with extensibility and robustness against speech", "author": ["Naoyuki Kanda", "Mikio Nakano", "Kazuhiro Nakadai", "Hiroshi Tsujino", "Tetsuya Ogata", "Hiroshi G Okuno"], "venue": null, "citeRegEx": "Komatani et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Komatani et al\\.", "year": 2009}, {"title": "A two-stage domain selection framework for extensible multidomain spoken dialogue systems", "author": ["Nakano et al.2011] Mikio Nakano", "Shun Sato", "Kazunori Komatani", "Kyoko Matsuyama", "Kotaro Funakoshi", "Hiroshi G Okuno"], "venue": null, "citeRegEx": "Nakano et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Nakano et al\\.", "year": 2011}, {"title": "Reinforcement learning with hierarchies of machines. Advances in neural information processing systems, pages 1043\u20131049", "author": ["Parr", "Russell1998] Ronald Parr", "Stuart Russell"], "venue": null, "citeRegEx": "Parr et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Parr et al\\.", "year": 1998}, {"title": "Lets go public! taking a spoken dialog system to the real world", "author": ["Raux et al.2005] Antoine Raux", "Brian Langner", "Dan Bohus", "Alan W Black", "Maxine Eskenazi"], "venue": "In in Proc. of Interspeech", "citeRegEx": "Raux et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Raux et al\\.", "year": 2005}, {"title": "A latent semantic model with convolutional-pooling structure for information retrieval", "author": ["Shen et al.2014] Yelong Shen", "Xiaodong He", "Jianfeng Gao", "Li Deng", "Gr\u00e9goire Mesnil"], "venue": "In Proceedings of the 23rd ACM International Conference on Conference", "citeRegEx": "Shen et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Shen et al\\.", "year": 2014}, {"title": "Halef: An open-source standard-compliant telephonybased modular spoken dialog system: A review", "author": ["Vikram Ramanarayanan", "Moritz Teckenbrock", "Felix Neutatz", "Dennis Schmidt"], "venue": null, "citeRegEx": "SuendermannOeft et al\\.,? \\Q2015\\E", "shortCiteRegEx": "SuendermannOeft et al\\.", "year": 2015}, {"title": "Sequence to sequence learning with neural networks. In Advances in neural information processing systems, pages 3104\u20133112", "author": ["Oriol Vinyals", "Quoc V Le"], "venue": null, "citeRegEx": "Sutskever et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "Between mdps and semi-mdps: A framework for temporal abstraction in reinforcement learning", "author": ["Doina Precup", "Satinder Singh"], "venue": "Artificial intelligence,", "citeRegEx": "Sutton et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Sutton et al\\.", "year": 1999}, {"title": "From frequency to meaning: Vector space models of semantics", "author": ["Patrick Pantel"], "venue": "Journal of artificial intelligence research,", "citeRegEx": "Turney and Pantel,? \\Q2010\\E", "shortCiteRegEx": "Turney and Pantel", "year": 2010}, {"title": "A neural conversational model. arXiv preprint arXiv:1506.05869", "author": ["Vinyals", "Le2015] Oriol Vinyals", "Quoc Le"], "venue": null, "citeRegEx": "Vinyals et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Vinyals et al\\.", "year": 2015}, {"title": "Aiml: Artificial intelligence markup language", "author": ["Richard Wallace"], "venue": "DOI= http://www. alicebot", "citeRegEx": "Wallace,? \\Q2005\\E", "shortCiteRegEx": "Wallace", "year": 2005}, {"title": "The anatomy of ALICE", "author": ["Richard S Wallace"], "venue": null, "citeRegEx": "Wallace.,? \\Q2009\\E", "shortCiteRegEx": "Wallace.", "year": 2009}, {"title": "Fast and easy language understanding for dialog systems with microsoft language understanding intelligent service (luis)", "author": ["Eslam Kamal", "Hani Amr Mokhtar Ashour", "Jessica Miller", "Geoff Zweig"], "venue": null, "citeRegEx": "Williams et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Williams et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 8, "context": "data from the Lets Go System (Raux et al., 2005) as well as access to the system to run studies.", "startOffset": 29, "endOffset": 48}, {"referenceID": 17, "context": "Microsoft Research released Language Understanding Intelligent Service (LUIS) (Williams et al., 2015) which helps software developers create cloud-based, machine-learning powered, language understanding models for specific application domains.", "startOffset": 78, "endOffset": 101}, {"referenceID": 5, "context": "approaches usually followed a two-stage framework (Komatani et al., 2009; Nakano et al., 2011), in which the first stage classifies the domain and the second stage forwards the user\u2019s request to the relevant single-domain dialog manager.", "startOffset": 50, "endOffset": 94}, {"referenceID": 6, "context": "approaches usually followed a two-stage framework (Komatani et al., 2009; Nakano et al., 2011), in which the first stage classifies the domain and the second stage forwards the user\u2019s request to the relevant single-domain dialog manager.", "startOffset": 50, "endOffset": 94}, {"referenceID": 4, "context": "The Cambridge Multi-domain spoken dialog system in Figure 1 (Gasic et al., 2015) is one example.", "startOffset": 60, "endOffset": 80}, {"referenceID": 3, "context": "Hierarchical policy has been studied extensively in the literature of both hierarchical reinforcement learning (HRL) (Dietterich, 2000; Parr and Russell, 1998; Sutton et al., 1999) and plan-based dialog management (Bohus and Rudnicky, 2003; Bohus and Rudnicky, 2009).", "startOffset": 117, "endOffset": 180}, {"referenceID": 12, "context": "Hierarchical policy has been studied extensively in the literature of both hierarchical reinforcement learning (HRL) (Dietterich, 2000; Parr and Russell, 1998; Sutton et al., 1999) and plan-based dialog management (Bohus and Rudnicky, 2003; Bohus and Rudnicky, 2009).", "startOffset": 117, "endOffset": 180}, {"referenceID": 16, "context": "Table 2: Characteristics of systems that handle non-goal driven utterances Characteristics Main Technique Representative Systems (a) Pattern Matching high precision, fast response time, time consuming to make patterns Artificial Intelligence Markup Language (Wallace and others, 2005) Alice (Wallace, 2009)", "startOffset": 291, "endOffset": 306}, {"referenceID": 11, "context": "(c) Neural Chatbot open domain, sometimes inconsistent and ungrammatical, require large corpora sequence-to-sequence learning (Sutskever et al., 2014) CleverBot (Vinyals and Le, 2015)", "startOffset": 126, "endOffset": 150}, {"referenceID": 9, "context": "Therefore, the nonunderstanding error handling policy queries the chat bot agent with the out-of-domain user input and the example-based chat bot calculates the similarity scores using sent2vec (Shen et al., 2014)", "startOffset": 194, "endOffset": 213}], "year": 2016, "abstractText": "This paper describes a new spoken dialog portal that connects systems produced by the spoken dialog academic research community and gives them access to real users. We introduce a distributed, multi-modal, multi-agent prototype dialog framework that affords easy integration with various remote resources, ranging from endto-end dialog systems to external knowledge APIs. To date, the DialPort portal has successfully connected to the multidomain spoken dialog system at Cambridge University, the NOAA (National Oceanic and Atmospheric Administration) weather API and the Yelp API.", "creator": "LaTeX with hyperref package"}}}