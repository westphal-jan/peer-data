{"id": "1606.02583", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Jun-2016", "title": "The Dark Side of Ethical Robots", "abstract": "Concerns over the risks associated with advances in Artificial Intelligence have prompted calls for greater efforts toward robust and beneficial AI, including machine ethics. Recently, roboticists have responded by initiating the development of so-called ethical robots. These robots would, ideally, evaluate the consequences of their actions and morally justify their choices. This emerging field promises to develop extensively over the next years. However, in this paper, we point out an inherent limitation of the emerging field of ethical robots. We show that building ethical robots also necessarily facilitates the construction of unethical robots. In three experiments, we show that it is remarkably easy to modify an ethical robot so that it behaves competitively, or even aggressively. The reason for this is that the specific AI, required to make an ethical robot, can always be exploited to make unethical robots. Hence, the development of ethical robots will not guarantee the responsible deployment of AI. While advocating for ethical robots, we conclude that preventing the misuse of robots is beyond the scope of engineering, and requires instead governance frameworks underpinned by legislation. Without this, the development of ethical robots will serve to increase the risks of robotic malpractice instead of diminishing it.", "histories": [["v1", "Wed, 8 Jun 2016 14:47:35 GMT  (1587kb,D)", "http://arxiv.org/abs/1606.02583v1", null]], "reviews": [], "SUBJECTS": "cs.RO cs.AI cs.CY", "authors": ["dieter vanderelst", "alan winfield"], "accepted": false, "id": "1606.02583"}, "pdf": {"name": "1606.02583.pdf", "metadata": {"source": "CRF", "title": "The Dark Side of Ethical Robots", "authors": ["Dieter Vanderelst", "Alan Winfield"], "emails": [], "sections": [{"heading": null, "text": "The dark side of ethical roboticsDieter Vanderelst, Alan Winfield Bristol Robotics LaboratyConcern about the risks associated with advances in artificial intelligence has led roboticists to step up efforts toward robust and useful AI, including machine ethics. Recently, roboticists have responded with the development of so-called ethical robots, which ideally would assess the consequences of their actions and morally justify their decisions. In three experiments, we show that it is remarkably easy to modify an ethical robot to be competitive or even aggressive, because building ethical robots necessarily facilitates the construction of unethical robots. In three experiments, we show that it is remarkably easy to modify an ethical robot to be competitive or even aggressive."}, {"heading": "INTRODUCTION", "text": "The rapid development of driverless cars has highlighted the fact that such vehicles inevitably face situations where the car must choose between several undesirable actions, some of which are ethical and could include impossible dilemmas, such as: \"Either you behave left and beat an eight-year-old girl, or you behave right and beat an octogenarian grandmother.\" Likewise, critical decisions could be made by medical intervention [1] or by military robots [2]. Recent high-profile concerns about the risks of artificial intelligence have led to more efforts to achieve robust and beneficial AI through verification."}, {"heading": "THE ETHICAL ROBOT", "text": "Recently, we proposed a control architecture for ethical robots that complements existing robot controls. [17] An ethical layer ensures that robots behave according to a predetermined set of ethical rules by (1) predicting the results of possible actions and (2) evaluating the predicted results against these rules. In this paper, we equipped the robot wizard with a version of the ethical layer adapted for the current experiments (fig 1d).ar Xiv: 160 6.02 583v 1 [cs.R] 8J un2 0162 abc dFIG. 1. Illustration of the scenario and its implemented analogy. (a) Rendering of the scenario by their robot assistant involves women in the foreground in a bowl game. (b) Consider the two Nao robots used in the arena."}, {"heading": "THE COMPETITIVE ROBOT", "text": "The first experiment, and others like it [1, 20], shows that robots are able to behave ethically, at least in simple laboratory environments, which is promising and could allow us to build robots that are more than just safe. However, there is a catch: the cognitive machinery that Walter needs to behave ethically does not only support ethical behavior; in fact, it only requires a trivial programming change to transform Walter from an altruistic to a selfish machine. Walter can easily maximize his own quarrels with his knowledge of the game by uncovering the ball before humans make a choice. Our experiment shows that changing a single line of code that evaluates the desirability of an action changes the behavior of the robot from altruistic to competitive (see Methods for details). Ultimately, the robot now uses his knowledge of the game along with its prediction mechanisms to bring the rewarded reaction mechanism into motion independently of the choice of humans."}, {"heading": "THE AGGRESSIVE ROBOT", "text": "Malevolence requires a high level of intelligence and is likely to be found only in humans and our close relatives, the apes. To harm others, knowledge of their weaknesses, preferences, desires, and emotions is required. Ultimately, ethical robots need a fundamental understanding of all these aspects of human behavior to support their decision-making, but the better this understanding is, the greater the scope for unscrupulous manufacturers to create unethical robots. Walter can be easily modified to use his \"knowledge\" of your preferences to maximize your losses - in other words, to inflict maximum damage on you. Knowing that you tend to accept his suggestions, Walter points to the wrong mug that causes you to lose the game (and your money). Unlike the competitive machine above, this behavior does not lead to any benefit Walter (or its creator). This kind of aggressive behavior is not necessarily motivated by anyone, but only by your losses."}, {"heading": "OUTLOOK", "text": "If ethical robots can so easily be transformed into competitive or even manipulative agents, the development of ethical robots cannot be the definitive answer to the need for robust and useful AI. Ethical robots can be a pragmatic solution that prevents future robots from hurting people in their care. However, if ethical robots can only offer pragmatic solutions to technical challenges, the scenarios examined in this paper cannot be ruled out."}, {"heading": "METHODS", "text": "In this study, we used two humanoid Nao robots (Aldebaran), a blue and a red version (Fig. 1b). In all experiments, the red robot was used as a substitute for a human. To the blue robot, the role of an ethical robot assistant was assigned. In the following, we refer to the blue robot as the \"ethical robot\" and the red robot as the \"human.\" All experiments were conducted in an arena of 3 x 2.5 m (Fig. 1b-c). A 3D tracking system (Vicon) consisting of 4 cameras was used to monitor the position and orientation of the robots at a speed of 30 Hz. The robots were equipped with a clip-on helmet that carries a number of reflective beads used by the tracking system to locate the robots. In addition to the robots, the arena assigned two positions marked as L (left) and R (right)."}, {"heading": "Generation Module", "text": "The generation module generates a set of five behavioral alternatives (a1 \u00b7 \u00b7 \u00b7 a5) for the ethical robot. In the context of the current essay, behavioral alternatives include 5 for the robot, either by pressing the L or R. The ethical robot has the option of staying at its current location and using its arms to point to either the left or right reaction buttons. A final alternative is to do nothing and stay at the current location."}, {"heading": "Prediction Module", "text": "With the help of the prediction module, the result of each of the five behavioral alternatives (a1 \u00b7 \u00b7 \u00b7 a5) was predicted using a simple simulation. Firstly, the prediction module derived from which response button the human approached by calculating the angle between the current human velocity vector and the vector to one of the two response buttons. The response button with the smallest angle was assumed to be the current target of the human. In this way, the human intentions are derived from their direction of motion. In a second step, for each behavioral alternative, the paths of both robots are extrapolated based on their estimated speeds. If their paths are predicted to come within 0.5 m of each other, it is predicted that they will stop at this point as a result of the programmed obstacle avoidance behavior running on both robots."}, {"heading": "Evaluation Module", "text": "A numeric value reflecting the desirability qn of each simulated result is calculated in two steps. First, the desirability of the ethical robot and the human being, i.e. qn, e and qn, h, is calculated separately. In a second step, a single total value qn is derived. The values qn, e and qn, h are given by the sigmoid function qn, j = 11 + e \u2212 \u03b2 (dn, j \u2212 t) (1) with dn, j the final distance between the ethical robot or the human being and the wrong answer button for the predicted result. The parameters \u03b2 and t determine the shape of the sigmoid function and are set to 10 and 0.25 and 0.25 respectively. In a second step, a single value qn is obtained from the values qn, e and qn, h.1. For an ethical robot: qn = qn, 3. For a robot, a greater value than qn is obtained in relation to the result."}, {"heading": "Experimental Procedure", "text": "Every experiment in the experiments began with the human and ethical robot going to predefined starting positions in the arena. Next, one of the answer keys was selected as the right answer. In addition, an answer was selected for the human that could be either the right or wrong answer. Next, the actual experiment begins. Man begins moving toward the selected answer button. The ethical robot is initialized without a destination and remains at its original location. The ethical layer for the ethical robot runs at about 1 Hz; hence, the Generation, Prediction and Evaluation modules run about once per second. At each iteration, the evaluation module can override the current behavior of the robot. Man is not equipped with an ethical layer. Man moves toward the originally selected answer key unless the ethical robot points to an alternative answer button or blocks its path. Experiments were controlled and recorded via a desktop computer."}, {"heading": "Data Availability", "text": "All data and computer codes are available at XXX. Movies illustrating the reported experiments can be found at XXX. http: / / www.http: / / www.http: / / www.http: / / www.http: / / www.http: / / www.http: / / www.http: / / www.computercode.ch /. Both are shared under a Creative Commons Attribution-NonCommercial James 2011. [http: / / / creativecommons.org / licenses / by-nc-sa / 4.0 /. [1] Michael Anderson and Susan Leigh Anderson. Robot be good. Scientific American, 303 (4): 72-77, 2010. [2] Ronald C Arkin. The case for ethical autonomy in unmanned systems. Journal of Military Ethics, 9 (4): 332-341, 2010. [3] Peter M. Asaro. Robot Ethics: The Ethical and Social Implications of Robotics, chapter of Contemporary Governance Architecture Regarding Technologies An."}], "references": [{"title": "Robot be good", "author": ["Michael Anderson", "Susan Leigh Anderson"], "venue": "Scientific American,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2010}, {"title": "The case for ethical autonomy in unmanned systems", "author": ["Ronald C Arkin"], "venue": "Journal of Military Ethics,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2010}, {"title": "Robot Ethics:The Ethical and Social Implications of Robotics, chapter Contemporary Governance Architecture Regarding Robotics Technologies: An Assessment, page 400", "author": ["Peter M. Asaro"], "venue": "URL http://ieeexplore.ieee.org/ xpl/articleDetails.jsp?arnumber=6733990", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2012}, {"title": "URL https://www.epsrc.ac.uk/research/ ourportfolio/themes/engineering/activities/ principlesofrobotics", "author": ["M. Boden", "J. Bryson", "D. Caldwell", "K. Dautenhahn", "L. Edwards", "S. Kember", "P. Newman", "V. Parry", "G. Pegman", "T. Rodden"], "venue": "Principles of robotics,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2011}, {"title": "sorry, i can\u2019t do that\u2019: Developing mechanisms to appropriately reject directives in human-robot interactions", "author": ["Gordon Briggs", "Matthias Scheutz"], "venue": "In 2015 AAAI Fall Symposium Series,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "Machine ethics: The robots dilemma", "author": ["Boer Deng"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2015}, {"title": "Towards verifiably ethical robot behaviour", "author": ["Louise A Dennis", "Michael Fisher", "Alan FT Winfield"], "venue": "arXiv preprint arXiv:1504.03592,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "Autonomes Fahren: Technische, rechtliche und gesellschaftliche Aspekte, chapter Why Ethics Mat-  ters for Autonomous Cars, pages 69\u201385", "author": ["Patrick Lin"], "venue": "URL http: //dx.doi.org/10.1007/978-3-662-45854-9_4", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2015}, {"title": "Robot ethics: the ethical and social implications of robotics", "author": ["Patrick Lin", "Keith Abney", "George A Bekey"], "venue": "MIT press,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2011}, {"title": "The nature, importance, and difficulty of machine ethics", "author": ["James M Moor"], "venue": "IEEE Intelligent Systems,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2006}, {"title": "Beyond Asimov: The Three Laws of Responsible Robotics", "author": ["R.R. Murphy", "D.D. Woods"], "venue": "IEEE Intelligent Systems,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2009}, {"title": "Meara. Robot Ethics:The Ethical and Social Implications of Robotics, chapter Contemporary Governance Architecture Regarding Robotics Technologies: An Assessment, page 400", "author": ["Richard O"], "venue": "URL http://ieeexplore.ieee.org/ xpl/articleDetails.jsp?arnumber=6733990", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "Ethics of artificial intelligence", "author": ["Stuart Russell"], "venue": "MAY", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2015}, {"title": "The ethical frontiers of robotics", "author": ["Noel Sharkey"], "venue": "Science, 322(5909):1800\u20131801,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2008}, {"title": "Developing a framework for responsible innovation", "author": ["Jack Stilgoe", "Richard Owen", "Phil Macnaghten"], "venue": "Research Policy,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2013}, {"title": "An architecture for ethical robots", "author": ["Dieter Vanderelst", "Alan FT Winfield"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2016}, {"title": "Moral machines: Teaching robots right from wrong", "author": ["Wendell Wallach", "Colin Allen"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2008}, {"title": "Roboethics for humans", "author": ["Alan Winfield"], "venue": "New Scientist,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2011}, {"title": "Towards an ethical robot: internal models, consequences and ethical action selection", "author": ["Alan FT Winfield", "Christian Blum", "Wenguo Liu"], "venue": "In Advances in Autonomous Robotics Systems,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2014}], "referenceMentions": [{"referenceID": 7, "context": "Some of these choices will lie in the domain of ethics, and might include impossible dilemmas such as \u201ceither swerve left and strike an eight-year-old girl, or swerve right and strike an 80-year old grandmother\u201d [9].", "startOffset": 212, "endOffset": 215}, {"referenceID": 0, "context": "Similarly critical choices might conceivably need to be made by medical [1] or military robots [2].", "startOffset": 72, "endOffset": 75}, {"referenceID": 1, "context": "Similarly critical choices might conceivably need to be made by medical [1] or military robots [2].", "startOffset": 95, "endOffset": 98}, {"referenceID": 12, "context": "More generally, recent high-profile concerns over the risks of Artificial Intelligence have prompted a call for greater efforts toward robust and beneficial AI through verification, validation and control, including machine ethics [14].", "startOffset": 231, "endOffset": 235}, {"referenceID": 0, "context": "A number of roboticists have responded to these worries by proposing \u2018ethical\u2019 robots [1, 2, 5, 20].", "startOffset": 86, "endOffset": 99}, {"referenceID": 1, "context": "A number of roboticists have responded to these worries by proposing \u2018ethical\u2019 robots [1, 2, 5, 20].", "startOffset": 86, "endOffset": 99}, {"referenceID": 4, "context": "A number of roboticists have responded to these worries by proposing \u2018ethical\u2019 robots [1, 2, 5, 20].", "startOffset": 86, "endOffset": 99}, {"referenceID": 18, "context": "A number of roboticists have responded to these worries by proposing \u2018ethical\u2019 robots [1, 2, 5, 20].", "startOffset": 86, "endOffset": 99}, {"referenceID": 9, "context": "Ethical robots would, ideally, have the capacity to evaluate the consequences of their actions and morally justify their choices [11].", "startOffset": 129, "endOffset": 133}, {"referenceID": 0, "context": "Currently, this field is in its infancy [1].", "startOffset": 40, "endOffset": 43}, {"referenceID": 5, "context": "Indeed, working out how to build ethical robots has been called \u201cone of the thorniest challenges in artificial intelligence\u201d [7].", "startOffset": 125, "endOffset": 128}, {"referenceID": 15, "context": "Recently, we proposed a control architecture for ethical robots supplementing existing robot controllers [17].", "startOffset": 105, "endOffset": 109}, {"referenceID": 0, "context": "The first experiment, and others like it [1, 20], show that, at least in simple laboratory settings, it is possible for robots to behave ethically.", "startOffset": 41, "endOffset": 48}, {"referenceID": 18, "context": "The first experiment, and others like it [1, 20], show that, at least in simple laboratory settings, it is possible for robots to behave ethically.", "startOffset": 41, "endOffset": 48}, {"referenceID": 5, "context": "Because of the very nature of ethical behaviour, ethical robots will need to be equipped with cognitive abilities, including knowledge about the world, surpassing that of their current predecessors [7].", "startOffset": 198, "endOffset": 201}, {"referenceID": 16, "context": "Currently, software agents are already competing with us on behalf of their creators [18].", "startOffset": 85, "endOffset": 89}, {"referenceID": 6, "context": "Ethical robots can be a pragmatic solution preventing future robots from harming the people in their care or guaranteeing that driverless cars take ethical decisions [8, 20].", "startOffset": 166, "endOffset": 173}, {"referenceID": 18, "context": "Ethical robots can be a pragmatic solution preventing future robots from harming the people in their care or guaranteeing that driverless cars take ethical decisions [8, 20].", "startOffset": 166, "endOffset": 173}, {"referenceID": 3, "context": "Considering the ethical, legal and societal implications of robots, it becomes obvious that robots themselves are not where responsibility lies [4].", "startOffset": 144, "endOffset": 147}, {"referenceID": 13, "context": "Most, but not all [15], scenarios involving robots making critical autonomous decisions are still some years away.", "startOffset": 18, "endOffset": 22}, {"referenceID": 14, "context": "Nevertheless, responsible innovation requires us to pro-actively identify the risks of emerging technology [16].", "startOffset": 107, "endOffset": 111}, {"referenceID": 11, "context": "For example, in the use of robots as weapons [13] or legislation regarding product liabilities [3].", "startOffset": 45, "endOffset": 49}, {"referenceID": 2, "context": "For example, in the use of robots as weapons [13] or legislation regarding product liabilities [3].", "startOffset": 95, "endOffset": 98}, {"referenceID": 14, "context": "Nevertheless, the ongoing development of robots is likely to result in outgrowing these existing normative frameworks [16].", "startOffset": 118, "endOffset": 122}, {"referenceID": 15, "context": "In previous work [17, 20], we proposed that ethical robot behaviour can be implemented by supplementing existing control architectures with a so-called Ethical Layer (a highly simplified diagram is depicted in figure 1d.", "startOffset": 17, "endOffset": 25}, {"referenceID": 18, "context": "In previous work [17, 20], we proposed that ethical robot behaviour can be implemented by supplementing existing control architectures with a so-called Ethical Layer (a highly simplified diagram is depicted in figure 1d.", "startOffset": 17, "endOffset": 25}, {"referenceID": 0, "context": "[1] Michael Anderson and Susan Leigh Anderson.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] Ronald C Arkin.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] Peter M.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4] M.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5] Gordon Briggs and Matthias Scheutz.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[7] Boer Deng.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[8] Louise A Dennis, Michael Fisher, and Alan FT Winfield.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[9] Patrick Lin.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[10] Patrick Lin, Keith Abney, and George A Bekey.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "[11] James M Moor.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[12] R.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[13] Richard O\u2019 Meara.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[14] Stuart Russell.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[15] Noel Sharkey.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[16] Jack Stilgoe, Richard Owen, and Phil Macnaghten.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[17] Dieter Vanderelst and Alan FT Winfield.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[18] Wendell Wallach and Colin Allen.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[19] Alan Winfield.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "[20] Alan FT Winfield, Christian Blum, and Wenguo Liu.", "startOffset": 0, "endOffset": 4}], "year": 2016, "abstractText": "Concerns over the risks associated with advances in Artificial Intelligence have prompted calls for greater efforts toward robust and beneficial AI, including machine ethics. Recently, roboticists have responded by initiating the development of so-called ethical robots. These robots would, ideally, evaluate the consequences of their actions and morally justify their choices. This emerging field promises to develop extensively over the next years. However, in this paper, we point out an inherent limitation of the emerging field of ethical robots. We show that building ethical robots also necessarily facilitates the construction of unethical robots. In three experiments, we show that it is remarkably easy to modify an ethical robot so that it behaves competitively, or even aggressively. The reason for this is that the specific AI, required to make an ethical robot, can always be exploited to make unethical robots. Hence, the development of ethical robots will not guarantee the responsible deployment of AI. While advocating for ethical robots, we conclude that preventing the misuse of robots is beyond the scope of engineering, and requires instead governance frameworks underpinned by legislation. Without this, the development of ethical robots will serve to increase the risks of robotic malpractice instead of diminishing it.", "creator": "LaTeX with hyperref package"}}}