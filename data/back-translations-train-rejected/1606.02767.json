{"id": "1606.02767", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Jun-2016", "title": "Theoretical Robopsychology: Samu Has Learned Turing Machines", "abstract": "From the point of view of a programmer, the robopsychology is a synonym for the activity is done by developers to implement their machine learning applications. This robopsychological approach raises some fundamental theoretical questions of machine learning. Our discussion of these questions is constrained to Turing machines. Alan Turing had given an algorithm (aka the Turing Machine) to describe algorithms. If it has been applied to describe itself then this brings us to Turing's notion of the universal machine. In the present paper, we investigate algorithms to write algorithms. From a pedagogy point of view, this way of writing programs can be considered as a combination of learning by listening and learning by doing due to it is based on applying agent technology and machine learning. As the main result we introduce the problem of learning and then we show that it cannot easily be handled in reality therefore it is reasonable to use machine learning algorithm for learning Turing machines.", "histories": [["v1", "Wed, 8 Jun 2016 21:46:20 GMT  (23kb,D)", "https://arxiv.org/abs/1606.02767v1", "11 pages"], ["v2", "Thu, 23 Jun 2016 13:27:01 GMT  (23kb,D)", "http://arxiv.org/abs/1606.02767v2", "11 pages, added a missing cc* value and the appearance of Table 1 is improved"]], "COMMENTS": "11 pages", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["norbert b\\'atfai"], "accepted": false, "id": "1606.02767"}, "pdf": {"name": "1606.02767.pdf", "metadata": {"source": "CRF", "title": "Theoretical Robopsychology: Samu Has Learned Turing Machines", "authors": ["Norbert B\u00e1tfai"], "emails": ["batfai.norbert@inf.unideb.hu"], "sections": [{"heading": "1 Introduction", "text": "These are very simplified versions of the earlier habit-raising [CS14] based on examples such as SamuBrain t16d or SamuKnows t16t16e] learning projects. They are universal learning functions that will be able to speak in a natural language such as humans [Ba \u0301 t15a]. At this moment, it is just a utopian notion of the Samu project. The practical purpose of the Samu projects is to develop computer-assisted mental organs that can assist software agents to acquire higher order knowledge from their input [BB16]. The roots of this paper lie in the two new software experiments, the Samu Turing [Ba \u2012 t16c] and Samu C. Turing [Ba \u2012 t16b]. These are very simplified versions of the earlier habit-raising [CS14] based (such as SamuBrain] or Samuws 16Bt16e]."}, {"heading": "2 Notations and Technical Background", "text": "Both in this article and in our software experiments, we use the definition of the Turing machine (TM > q) introduced in [Ba \u0301 t09] and also used in [Ba \u0301 t15b], where the Turing machine is defined by a quadruple T = (Q, 0, {0, 1}, f), where f: Q \u00b7 {0, 1} \u2192 Q \u00b7 {0, 1} \u00b7 {\u2190, \u2191, \u2192} is a partial transition function and 0: Q-N is the initial state. As usual, a configuration determines the actual state of the head, the position of the head and the contents of the tape. With the notation of [Ba \u0301 t09], a configuration in the form wbefore [q > wafter, where wafter [0, 1} and q-Q.In some proofs, we use the Turing machine [wfiging machines or the blank symbol."}, {"heading": "3 Learning by Listening and Doing", "text": "In the projects Samu Turing and Samu C. Turing mentioned above, we have programmed the Samu Agent to work in a similar way to, for example, Professor James Harland in his work [Har16], where he observed and examined the configurations of Marx's and Buntrock's Busy Beaver Champion machines [MB90]. In our experiments, Agent Samu observes (hears) the successive sub-configurations of a particular Turing machine under investigation and tries to predict (do) the next rule of the machine that is being applied. From this point of view, this entire learning process can be viewed as a way of learning by listening and doing, with the listening part being the agent's sensation and doing the agent's prediction. But, of course, the question can be raised why we should use agent technology and machine learning algorithms to learn Turing machines? Our explicit answer is based on the following intuitive results, and will be found in Section 3.3."}, {"heading": "3.1 Some Intuitive Results", "text": "The numbers of two types of runtime (common time complexity and \"learning complexity,\" see figure caption for details) are not directly comparable because they use different scales to calculate the y-axis values, one of which is calculated by the number of steps of a Turing machine and the other by the number of sensory pairs of the amplifier learning device Samu C. Turing. the exact values can be found in Table 1. One of the terms of cognitive complexity defined in Fig. 3.2.3 is based on this intuitive \"learning complexity.\" In Fig. 2, the growth rate of the learning time appears to be related to runtime. It is worth comparing this with Fig. 6, where the growth rate of another (the \"self-reproducing\") complexity has already been separated from runtime."}, {"heading": "3.2 The Basic Notions of the Subject", "text": "From the observations of the two experiments above, we can build the abstract model of learning, which is called the learning problem. The learning problem of learning TMs is divided into two parts. The first is a simulation of the learning TM. The second is the actual learning problem itself. Figure 3 shows the scheme of the learning problem, where the UTM R takes the description of the machine T and an x-input from T. Then R has collected the configurations of T while simulating T with x. After the simulation, S takes the collected configurations and must try to find out what TM is actually simulating."}, {"heading": "3.2.1 The Running Problem", "text": "It is obvious that the ongoing problem trivially contains the maintenance problem. Therefore, we can note that similar undecidable statements can also be made in this case, but in this paper we focus only on holding machines. Lemma 3.2.1. Apart from the trivial case of empty tapes, the transition rule between two consecutive configurations ci and ci + 1 is clearly defined by the configurations ci and ci + 1.Proof. Suppose there are two transition rules (q, r) \u2192 (q1, d1, d1) and (q, r) \u2192 (q2, d2), where q, q2, q2, q2, the configuration Q, r, w2, w2, w2, w2, {0,}, d1, d2, q2, and then we show that q1 = q2, w2 and d2 is the configuration L."}, {"heading": "3.2.2 The Learning Problem", "text": "The previous theorem shows that there is no learning problem when we use config \u221e (or the usual) configurations, but otherwise, as shown in the following two simple examples for config2 configurations (Example 3.2.1 and 3.2.2), the applied transition rule between two consecutive configN configurations cannot be clearly determined by the configN configurations. If we use configN configurations instead of the usual or config \u221e configurations, then the Lemma 3.2.1 configuration does not apply. In the next subsection, an idea of complexity will be based precisely on this property. Example 3.2.1. Let ci = \u221e 11111 [q > 11111 \u221e be a config configuration and c, i be a-config2 configuration. Then the rules (q, 1) \u2192 (q, 1, \u2190), (q, 1, \u2192 Configuration) and (q, 1, \u2191) apply."}, {"heading": "3.2.3 Cognitive Complexities", "text": "As already mentioned in Fig. 3.1, we intuitively use the runtime of the learning machines as a measure of complexity, which can be formulated as follows: cc (T, x) = min {tS (< ci > xT) | T (x) < \u221e, S (T, x) = T}, but it does not seem very helpful because it is probably correlated with the usual time complexity of T as shown in Fig. 2. The next type of complexity says what the first finite N is for the Lemma 3.2.1 when using the configuration configuration configN. To be more precise, it is ascc * (T, x) = min {N | T (x) < rather, S (R (T, x) = T and for the configuration of Lemma 3.2.1}, which has shown a different behavior from the previous one as shown in Fig. 6. The growth rate of the investigated cc values does not refer to the number of the runtime, but rather to the Q."}, {"heading": "4 Conclusion", "text": "In this work we have started with two experimental robot programs & < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < &lt"}, {"heading": "5 Acknowledgment", "text": "The author would like to thank his students of the High Level Programming Languages course at the University of Debrecen in the spring semester 2015 / 2016 for testing the Samu projects and the members of some AI-specific communities on Facebook, Google + and Linkedin, and in particular his group DevRob2Psy at https: / / www.facebook.com / groups / devrob2psy / for their interest."}], "references": [{"title": "CoRR", "author": ["Norbert B\u00e1tfai. On the Running Time of the Shortest Programs"], "venue": "abs/0908.1159,", "citeRegEx": "B\u00e1t09", "shortCiteRegEx": null, "year": 2009}, {"title": "CoRR", "author": ["Norbert B\u00e1tfai. Conscious Machines", "Consciousness Oriented Programming"], "venue": "abs/1108.2865, 2011. http://arxiv.org/abs/", "citeRegEx": "B\u00e1t11", "shortCiteRegEx": null, "year": 1108}, {"title": "CoRR", "author": ["Norbert B\u00e1tfai. A disembodied developmental robotic agent called Samu B\u00e1tfai"], "venue": "abs/1511.02889, 2015. http://arxiv.org/abs/", "citeRegEx": "B\u00e1t15a", "shortCiteRegEx": null, "year": 1511}, {"title": "Are there intelligent Turing machines? CoRR", "author": ["Norbert B\u00e1tfai"], "venue": "abs/1503.03787,", "citeRegEx": "B\u00e1t15b", "shortCiteRegEx": null, "year": 2015}, {"title": "GitHub Project", "author": ["Norbert B\u00e1tfai. How to Become a Robopsychologist"], "venue": "https://github.com/nbatfai/Robopsychology/files/169195/ robopsychology.pdf,", "citeRegEx": "B\u00e1t16a", "shortCiteRegEx": null, "year": 2016}, {"title": "https://github", "author": ["Norbert B\u00e1tfai. Samu C. Turing. GitHub Project"], "venue": "com/nbatfai/SamuCTuring, (visited: 2016-06-04),", "citeRegEx": "B\u00e1t16b", "shortCiteRegEx": null, "year": 2016}, {"title": "https://github", "author": ["Norbert B\u00e1tfai. Samu Turing. GitHub Project"], "venue": "com/nbatfai/SamuTuring, (visited: 2016-06-04),", "citeRegEx": "B\u00e1t16c", "shortCiteRegEx": null, "year": 2016}, {"title": "GitHub Project", "author": ["Norbert B\u00e1tfai. SamuBrain"], "venue": "https://github.com/ nbatfai/SamuBrain, (visited: 2016-06-04),", "citeRegEx": "B\u00e1t16d", "shortCiteRegEx": null, "year": 2016}, {"title": "GitHub Project", "author": ["Norbert B\u00e1tfai. SamuKnows"], "venue": "https://github.com/ nbatfai/SamuKnows, (visited: 2016-06-04),", "citeRegEx": "B\u00e1t16e", "shortCiteRegEx": null, "year": 2016}, {"title": "Robopsychology Manifesto: Samu in His Prenatal Development", "author": ["Norbert B\u00e1tfai", "Ren\u00e1t\u00f3 Besenczi"], "venue": "submitted manuscript,", "citeRegEx": "BB16", "shortCiteRegEx": null, "year": 2016}, {"title": "Developmental Robotics: From Babies to Robots", "author": ["Angelo Cangelosi", "Matthew Schlesinger"], "venue": "The MIT Press,", "citeRegEx": "CS14", "shortCiteRegEx": null, "year": 2014}, {"title": "Busy Beaver Machines and the Observant Otter Heuristic (or How to Tame Dreadful Dragons)", "author": ["James Harland"], "venue": "CoRR, abs/1602.03228,", "citeRegEx": "Har16", "shortCiteRegEx": null, "year": 2016}, {"title": "Algoritmusok", "author": ["G\u00e1bor Ivanyos", "R\u00e9ka Szab\u00f3", "Lajos R\u00f3nyai"], "venue": "Typotex,", "citeRegEx": "ISR00", "shortCiteRegEx": null, "year": 2000}, {"title": "Incorporated", "author": ["Ming Li", "Paul M.B. Vit\u00e1nyi. An Introduction to Kolmogorov Complexity", "Its Applications. Springer Publishing Company"], "venue": "3 edition,", "citeRegEx": "LV08", "shortCiteRegEx": null, "year": 2008}, {"title": "Attacking the busy beaver 5", "author": ["Heiner Marxen", "J\u00fcrgen Buntrock"], "venue": "Bull EATCS, 40:247\u2013251,", "citeRegEx": "MB90", "shortCiteRegEx": null, "year": 1990}, {"title": "On computable numbers with an application to the Entscheidungsproblem", "author": ["Alan Turing"], "venue": "Proceeding of the London Mathematical Society,", "citeRegEx": "Tur36", "shortCiteRegEx": null, "year": 1936}, {"title": "editor", "author": ["John von Neumann. The general", "logical theory of automata. In L.A. Jeffress"], "venue": "Cerebral Mechanisms in Behaviour \u2013 The Hixon Symposium, pages 1\u201331. Wiley,", "citeRegEx": "vN51", "shortCiteRegEx": null, "year": 1951}], "referenceMentions": [{"referenceID": 2, "context": "Samu is a disembodied developmental robotic experiment to develop a family chatterbot agent who will be able to talk in a natural language like humans do [B\u00e1t15a].", "startOffset": 154, "endOffset": 162}, {"referenceID": 9, "context": "The practical purpose of Samu projects is to develop computational mental organs that can support software agents to acquire higher-order knowledge from their input [BB16].", "startOffset": 165, "endOffset": 171}, {"referenceID": 4, "context": "The activities have been conducted during the development of such mental organs may be considered as first efforts to create on demand the Asimovian profession called robopsychology [B\u00e1t16a].", "startOffset": 182, "endOffset": 190}, {"referenceID": 6, "context": "The roots of this paper lie in the two new software experiments Samu Turing [B\u00e1t16c] and Samu C.", "startOffset": 76, "endOffset": 84}, {"referenceID": 5, "context": "Turing [B\u00e1t16b].", "startOffset": 7, "endOffset": 15}, {"referenceID": 10, "context": "These are very simplified versions of the former habituation-sensitization [CS14] based (like for example SamuBrain [B\u00e1t16d] or SamuKnows [B\u00e1t16e]) learning projects of Samu.", "startOffset": 75, "endOffset": 81}, {"referenceID": 7, "context": "These are very simplified versions of the former habituation-sensitization [CS14] based (like for example SamuBrain [B\u00e1t16d] or SamuKnows [B\u00e1t16e]) learning projects of Samu.", "startOffset": 116, "endOffset": 124}, {"referenceID": 8, "context": "These are very simplified versions of the former habituation-sensitization [CS14] based (like for example SamuBrain [B\u00e1t16d] or SamuKnows [B\u00e1t16e]) learning projects of Samu.", "startOffset": 138, "endOffset": 146}, {"referenceID": 1, "context": "The term \u201cCOP-based\u201d (Consciousness Oriented Programming [B\u00e1t11]) means that the engine predicts its future input.", "startOffset": 57, "endOffset": 64}, {"referenceID": 2, "context": "In this case the previous output (the previous prediction) is the same as the actual input, for precise details see [B\u00e1t15a] and [BB16]).", "startOffset": 116, "endOffset": 124}, {"referenceID": 9, "context": "In this case the previous output (the previous prediction) is the same as the actual input, for precise details see [B\u00e1t15a] and [BB16]).", "startOffset": 129, "endOffset": 135}, {"referenceID": 16, "context": "to write this paper stems from the last paragraph of the work of Neumann on the general theory of automata [vN51] where Neumann had suggested that there is a complexity level above which the machines can reproduce themselves and even more complicated ones.", "startOffset": 107, "endOffset": 113}, {"referenceID": 16, "context": "Neumann investigated the self-reproducing automata [vN51] roughly a decade after Alan Turing had published his work on universal simulation theorem [Tur36].", "startOffset": 51, "endOffset": 57}, {"referenceID": 15, "context": "Neumann investigated the self-reproducing automata [vN51] roughly a decade after Alan Turing had published his work on universal simulation theorem [Tur36].", "startOffset": 148, "endOffset": 155}, {"referenceID": 9, "context": "For example, the first mental organs had learned the Conway\u2019s Game of Life [BB16] (or see the YouTube video at https://youtu.", "startOffset": 75, "endOffset": 81}, {"referenceID": 13, "context": "It should be noticed that some of them, such as the machines of Schult and Uhing or the Marxen and Buntrock\u2019s BB5 champion machine are famous in the field of the Rad\u00f3 Tibor\u2019s Busy Beaver problem [LV08].", "startOffset": 195, "endOffset": 201}, {"referenceID": 0, "context": "Throughout both this article and our software experiments we use the definition of the Turing machine (TM) that was introduced in [B\u00e1t09] and also used in [B\u00e1t15b] where the Turing machine was defined by a quadruple T = (Q, 0, {0, 1}, f) where f : Q\u00d7 {0, 1} \u2192 Q\u00d7 {0, 1} \u00d7 {\u2190, \u2191,\u2192} is a partial transition function and 0 \u2208 Q \u2282 N is the starting state.", "startOffset": 130, "endOffset": 137}, {"referenceID": 3, "context": "Throughout both this article and our software experiments we use the definition of the Turing machine (TM) that was introduced in [B\u00e1t09] and also used in [B\u00e1t15b] where the Turing machine was defined by a quadruple T = (Q, 0, {0, 1}, f) where f : Q\u00d7 {0, 1} \u2192 Q\u00d7 {0, 1} \u00d7 {\u2190, \u2191,\u2192} is a partial transition function and 0 \u2208 Q \u2282 N is the starting state.", "startOffset": 155, "endOffset": 163}, {"referenceID": 0, "context": "With the notation of [B\u00e1t09] a configuration can be written in the form wbefore[q > wafter, where wbefore, wafter \u2208 {0, 1}\u2217 and q \u2208 Q.", "startOffset": 21, "endOffset": 28}, {"referenceID": 11, "context": "Turing we programmed the Samu agent to work in a similar way as, for example, Professor James Harland did in his work [Har16] where he observed and studied the configurations of Marxen and Buntrock\u2019s Busy Beaver champion machines [MB90].", "startOffset": 118, "endOffset": 125}, {"referenceID": 14, "context": "Turing we programmed the Samu agent to work in a similar way as, for example, Professor James Harland did in his work [Har16] where he observed and studied the configurations of Marxen and Buntrock\u2019s Busy Beaver champion machines [MB90].", "startOffset": 230, "endOffset": 236}, {"referenceID": 12, "context": "The proof is divided into two parts: in the first one, we modify the usual proof of Turing\u2019s universal simulation theorem (see for example the textbook [ISR00]) to produce the sequence of configurations of T by the universal machine R.", "startOffset": 152, "endOffset": 159}, {"referenceID": 6, "context": "In this paper, we started with two developmental robotic software experiments Samu Turing [B\u00e1t16c] and Samu C.", "startOffset": 90, "endOffset": 98}, {"referenceID": 5, "context": "Turing [B\u00e1t16b] to learn how Turing ma-", "startOffset": 7, "endOffset": 15}, {"referenceID": 2, "context": "For example, we are going to investigate using Samu\u2019s neural architecture [B\u00e1t15a], Samu mental organs (like MPUs) [BB16] and deep learning to learn how TMs operate.", "startOffset": 74, "endOffset": 82}, {"referenceID": 9, "context": "For example, we are going to investigate using Samu\u2019s neural architecture [B\u00e1t15a], Samu mental organs (like MPUs) [BB16] and deep learning to learn how TMs operate.", "startOffset": 115, "endOffset": 121}, {"referenceID": 3, "context": "The combine columns show the given TM in the form of rule-index notation [B\u00e1t15b].", "startOffset": 73, "endOffset": 81}], "year": 2016, "abstractText": "From the point of view of a programmer, the robopsychology is a synonym for the activity is done by developers to implement their machine learning applications. This robopsychological approach raises some fundamental theoretical questions of machine learning. Our discussion of these questions is constrained to Turing machines. Alan Turing had given an algorithm (aka the Turing Machine) to describe algorithms. If it has been applied to describe itself then this brings us to Turing\u2019s notion of the universal machine. In the present paper, we investigate algorithms to write algorithms. From a pedagogy point of view, this way of writing programs can be considered as a combination of learning by listening and learning by doing due to it is based on applying agent technology and machine learning. As the main result we introduce the problem of learning and then we show that it cannot easily be handled in reality therefore it is reasonable to use machine learning algorithm for learning Turing machines.", "creator": "LaTeX with hyperref package"}}}