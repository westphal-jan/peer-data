{"id": "1606.02877", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Jun-2016", "title": "Understanding User Instructions by Utilizing Open Knowledge for Service Robots", "abstract": "Understanding user instructions in natural language is an active research topic in AI and robotics. Typically, natural user instructions are high-level and can be reduced into low-level tasks expressed in common verbs (e.g., `take', `get', `put'). For robots understanding such instructions, one of the key challenges is to process high-level user instructions and achieve the specified tasks with robots' primitive actions. To address this, we propose novel algorithms by utilizing semantic roles of common verbs defined in semantic dictionaries and integrating multiple open knowledge to generate task plans. Specifically, we present a new method for matching and recovering semantics of user instructions and a novel task planner that exploits functional knowledge of robot's action model. To verify and evaluate our approach, we implemented a prototype system using knowledge from several open resources. Experiments on our system confirmed the correctness and efficiency of our algorithms. Notably, our system has been deployed in the KeJia robot, which participated the annual RoboCup@Home competitions in the past three years and achieved encouragingly high scores in the benchmark tests.", "histories": [["v1", "Thu, 9 Jun 2016 09:02:16 GMT  (1038kb,D)", "http://arxiv.org/abs/1606.02877v1", null]], "reviews": [], "SUBJECTS": "cs.RO cs.AI", "authors": ["dongcai lu", "feng wu", "xiaoping chen"], "accepted": false, "id": "1606.02877"}, "pdf": {"name": "1606.02877.pdf", "metadata": {"source": "CRF", "title": "Understanding User Instructions by Utilizing Open Knowledge for Service Robots", "authors": ["Dongcai Lu", "Feng Wu", "Xiaoping Chen"], "emails": ["RoboCup@Home"], "sections": [{"heading": null, "text": "This year, we have reached the stage where a process of this kind is taking place, in which the question is to what extent it is a country in which it is a country, a country in which it is a country, a country, a country, a region and a country in which it is not a country, a country, a country, a country, a country, a country, a country, a country, a country, a city, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a"}, {"heading": "II. PROBLEM STATEMENT", "text": "Our goal is to build a universal system so that the robot can understand user instructions and provide services to the2http: / / ai.ustc.edu.cn / en / robocup / atHome / index.php 3http: / / www.robocup.org / robocup-home / Fig. 2. System Architecture.user. To this end, we need to solve the problem of creating a sequence of primitive actions that can be performed directly by a robot, with user instructions in natural language. For example, if a user says, \"Please serve me a meal,\" the robot takes the meal, puts it on a plate and places the plate on a table; if a user says, \"I'm thirsty,\" the robot takes a drink from the fridge and delivers it to the user. To achieve this, our system must be able to extract a task from a user's instruction in natural language (i.e. to know what the user has said, and to systematically answer the next task)."}, {"heading": "III. SYSTEM OVERVIEW", "text": "As we can see, the human-robot dialog system transcribes spoken expressions into text sentences and manages the dialogue with users. Each sentence in the dialog is then transferred to the processing module, which generates a sequence of primitive actions for the task expressed in natural language. Afterwards, a sequence of commands is calculated that correspond to each primitive action. Finally, the commands are executed by the robot controller module. Here, we focus on the processing module, which uses a text set as input and outputs a sequence of primitive actions that can be performed by the robot. The main components of our processing module are described in detail as follows."}, {"heading": "A. Open Knowledge", "text": "This year, it is as far as ever in the history of the city, where it is as far as never before."}, {"heading": "B. NLP Module", "text": "This module maps the user's instructions in natural language I to the OMICS tables containing tuples < Task, Steps > for task-oriented statements or tuples < Desire, Task > for request-oriented statements (see Section IV for more details).The output is a logical form L for the planning module, which contains a frame semantic representation such as: (Meta-Task Take-Taking (: Parameter Food Refrigerator).Specifically, the interpretation of I to L is done in three steps: 1) Dependency spares, which analyze the dependencies of each word in a sentence, 2) Frame semantic parsing, which identifies the frame of the verb, and 3) Semantic matching and restoring, which fills the semantic roles for a given frame. In Section V, each step is described in detail."}, {"heading": "C. Planning Module", "text": "The planning module takes the logical form of the user instruction L, the online knowledge base (e.g. Re-FrameNet, WordNet, FrameNet), the domain knowledge and the skills of the robot as input. The output of the planning module is a high-level plan for the motion planning module. We employ both global and local planners in the planning module. The global planner searches all knowledge about task division in OMICS to create a plan. However, most tasks are OMICS, cannot be broken down into primitive actions of the robot, because many steps in OMICS are designated by common verbs for which OMICS does not contain decomposition knowledge. For example, verbs such as take, place, get, and turn often occur in task steps, but there is no knowledge in OMICS about how to execute them by the robot. Therefore, a local planner based on ASP is used for planning only on the instruction itself."}, {"heading": "D. Skills and Action Model", "text": "Specifically, an action model consists of several primitive actions. Each primitive action a is defined by a set of preconditions, post conditions, and invariants, similar to the definition of a common verb in Re-FrameNet. In other words, they set conditions under which an action can be performed, conditions that apply when a task is completed, and conditions that must be fulfilled during the execution of a task. In fact, a primitive action is the formal specification of a robot skill. As we will show later, the action model is useful for our system to generate a plan that can be executed by the robot. 4 Algorithm 1 SolveTask (task t, ActionModel AM) 1: gSeen: = task / * prevent an endless recursive loop from arising in the search for itself * / 2: zero task: zero task and plans 3: if t: return zero task 5: end when 6: gSeen plans."}, {"heading": "E. Learning Module", "text": "In this module, methods such as Log Linear, Conditional Random Field (CRF), Learn from Demonstration (LfD) are used to learn the low skills of a robot. Intuitively, the more skills a robot has, the more capable it is. For example, if a robot does not know how to pour water into a cup, it cannot perform the high tasks such as \"making coffee\" (with the tuple tupel tupel < \"making coffee,\" 0. \"putting hot water in a cup,\" 1. \"pouring coffee\" >). In this paper, we assume that our robot has all the low skills necessary to complete a task specified by the user's instructions, although most skills need to be learned individually in practice. The robot skills learning methods are interesting, but outside the scope of this article. After presenting our system as a whole, we will next describe our most important algorithms for understanding the teaching."}, {"heading": "IV. UNDERSTANDING USER INSTRUCTIONS", "text": "This year it is as far as it has ever been before, until it goes to the next phase, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process."}, {"heading": "V. SEMANTIC MATCHING AND RECOVERING", "text": "We propose a three-phase procedure to translate a user statement expressed in natural language into the internal representation that can be edited by our planner. Firstly, a probabilistic syntactic parser is used to find the dependencies of the statement. Secondly, the framework of the sentence verb is identified by framesemantic parsing, assuming, without loss of generality, that each statement represents only a single task (verb). Thirdly, the semantic roles of the frame are recovered and filled as far as possible with the appropriate units occurring in the statement or its sentence context, which are represented as a meta task in the Re-FrameNet. Further details of our three-phase procedure are described below."}, {"heading": "A. Dependency Parsing", "text": "In the first phase, we use the Stanford parser [14], which produces the Stanford-type dependencies between words in a sentence. [15] These dependencies indicate the grammatical relationships between words in terms of the name of the relationship, the governor, and the dependence. [15] Figure 3 illustrates the analysis of a sentence \"Take food from the fridge.\" The edge of type dobj indicates that the noun \"food\" is the direct object of the verb \"take.\" The verb \"take\" also governs the noun \"fridge\" over the typed dependence prep of. Since the typed dependence between a verb and a noun reveals its semantic role relationship, the syntactic structure of an instruction is used for our semantic role mediation and restitution."}, {"heading": "B. Frame Semantic Parsing", "text": "Given the fact that a verb varies in different meanings, a statement can represent different meanings and can therefore be mapped to different frames in FrameNet. Thus, we propose a frame semantic parsing method to map a verb to a unique frame. Specifically, we define a frame identification model and train the model with data sets from FrameNet and OMICS as below.1) Model: In the face of a sentence x = < x1,., xn > with frame evoking verb v, we search for the most likely frame f at the frame identification stage. Let us leave F the row of candidates for frames for v, L the row of verbs found in the FrameNet annotations, and Lf-L the subversion of prohibition."}, {"heading": "C. Roles Matching and Recovering", "text": "This year, it has reached the stage where it will be able to take the lead."}, {"heading": "VI. TASK PLANNING WITH ASP", "text": "In our previous work, we proposed the OC Planner [8] based on ASP. In this approach, all kinds of knowledge are converted to ASP and then an ASP solver is applied to generate a sequence of actions. However, this work does not take into account common verbs for dealing with complex tasks. In this article, we build our planner on our previous work, but also take into account the following challenges: 1) How to define the functional knowledge of primitive actions in the action model and 2) how to convert the re-FrameNet definition of common verbs into ASP."}, {"heading": "A. Planning with Action Model", "text": "As already mentioned, we specify the capabilities of the robot in our system by an action model, i.e. a series of primitive actions that are executable for the robot. Table V shows a basic definition of the primitive actions for a typical service robot, although different types of robot may have different action models. Formally, each primitive action a is defined as a pair < pre (a), eff (a) >, with pre (a) and eff (a) being the prerequisites and effects of each. For example, moveto (obj) is a primitive action that tells the robot to move near the specified object obj. The pre- and Eff of moveto (obj) show whether the robot is near the specified object before and after the Moveto action."}, {"heading": "B. Conversion of Functional Knowledge", "text": "< < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < <"}, {"heading": "VII. EXPERIMENTS", "text": "We evaluate our system empirically with three experiments: the first experiment was designed to examine the performance of our SMR (Semantic Matching and Recovering) method, the second experiment was designed to test the performance of the entire system when using different open knowledge bases, and we analysed the most important factors that can affect performance. Finally, we will show how our approach can be used in our KeJia robot to solve problems of teaching comprehension in two domestic scenarios. Furthermore, we will present our long-term efforts to apply the proposed technique in the RoboCup @ Home competitions."}, {"heading": "A. Experiments with SMR", "text": "To test our SMR method, we collect 191,740 examples with frame semantic structures for the frame identification model from the FrameNet lexicon and 470 examples from OMICS. We then analyze each sentence through the Stanford parser. Finally, we select only those examples whose LU is a verb or verb phrase. As a result, the training data contains 70,149 examples and the test data 18,183 examples from FrameNet and 630 examples from OMICS. In our experiments, the frame identification model instantiates 76,289 binary results. Table VI shows the results on each part of the translation of hierarchical statements. Performance is defined by Precise (P), Recall (R), F1 (F) as: Precise = TP / (TP + FP), Recall = (Precise + Recall), where TP stands for the number of sentences."}, {"heading": "B. Experiments on OMICS", "text": "This year it has come to the point that it will only be a matter of time before it will happen, until it does."}, {"heading": "C. Case Study on KeJia Robot", "text": "This year, it has reached the point where it will be able to leave the country without being able to reform it."}, {"heading": "VIII. RELATED WORK", "text": "To date, many approaches to understanding instructions and task planning for service robots have been proposed in the literature. For example, several integrated systems [2], [16], [22] for understanding natural language have been introduced to enable robots to perform tasks that are given in natural language. However, they all assume that instructions are clearly defined for the areas and do not take into account the semantic disambiguity of verbs and their roles. It has been proposed to create manually environment-driven instructions for creating instructions in natural language for the actions of robots [10], [23]. However, these methods cannot be applied to a large number of tasks as each task needs to be specified manually in an environment and is not suitable for different types of robots (e.g. robots with different arm configurations). To improve generality and scalability, researchers have attempted to exploit online knowledge and learn large-scale knowledge to develop a multi-purpose system for understanding tasks."}, {"heading": "IX. CONCLUSIONS", "text": "In this article, a general-purpose system for dealing with service robots on a large scale in natural language was proposed. The key problem we have dealt with is the mapping of primitive tasks in robotic actions using semantic roles of common verbs provided by semantic dictionaries - a common resource of open knowledge in linguistics. To solve this problem, we proposed a novel approach to semantic matching and recovery. In addition, we used semantic roles of common verbs defined in semantic dictionaries to deal with sub-specifications of naturalistic language instructions in task planning. Empirical evaluation and analysis were conducted and showed good performance with two test sets consisting of 11885 user tasks and 467 user requests collected from OMICS. In addition, we developed a prototype system used on our KeJia robot and demonstrated our home techniques using two types of networking scenarios that we can use in our network tasks to improve our knowledge @ in the past three years."}], "references": [{"title": "Developing High-level Cognitive Functions for Service Robots", "author": ["X. Chen", "J. Ji", "J. Jiang", "G. Jin", "F. Wang", "J. Xie"], "venue": "Proceedings of 9th International Conference on Autonomous Agents and Multi-agent Systems, 2010.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2010}, {"title": "What to do and how to do it: Translating natural language directives into temporal and dynamic logic representation for goal management and action execution", "author": ["J. Dzifcak", "M. Scheutz", "C. Baral", "P. Schermerhorn"], "venue": "IEEE International Conference on Robotics and Automation. ICRA, 2009, pp. 4163\u20134168.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2009}, {"title": "Toward understanding natural language directions", "author": ["T. Kollar", "S. Tellex", "D. Roy", "N. Roy"], "venue": "5th ACM/IEEE International Conference on Human-Robot Interaction, 2010.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2010}, {"title": "Everything robots always wanted to know about housework (but were afraid to ask)", "author": ["D. Nyga", "M. Beetz"], "venue": "IEEE/RSJ International Conference on Intelligent Robots and Systems, 2012.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2012}, {"title": "Robobrain: Large-scale knowledge engine for robots", "author": ["A. Saxena", "A. Jain", "O. Sener", "A. Jami", "D.K. Misra", "H.S. Koppula"], "venue": "International Symposium of Robotics Research, 2014.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2014}, {"title": "Understanding natural language commands for robotic navigation and mobile manipulation", "author": ["S. Tellex", "T. Kollar", "S. Dickerson", "M. Walter", "A. Banerjee", "S. Teller", "N. Roy"], "venue": "Proceedings of National Conference on Articial Intelligence, 2011.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "Common sense data acquisition for indoor mobile robots", "author": ["R. Gupta", "M. Kochenderfer"], "venue": "Proceedings of the 19th National Conference on Artificial Intelligence, San Jose, California, USA, 2004, pp. 605\u2013610.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2004}, {"title": "Handling open knowledge for service robots", "author": ["X. Chen", "J. Ji", "Z. Sui", "J. Xie"], "venue": "Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence, 2013.  12", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2013}, {"title": "A general service list of English words: with semantic frequencies and a supplementary word-list for the writing of popular science and technology", "author": ["M.P. West"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1953}, {"title": "Tell me dave: Contextsensitive grounding of natural language to manipulation instructions", "author": ["D. Misra", "J. Sung", "K. Lee", "A. Saxena"], "venue": "The International Journal of Robotics Research, 2014.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}, {"title": "The stable model semantics for logic programming", "author": ["M. Gelfond", "V. Lifschitz"], "venue": "Proceedings of the 5th International Conference on Logic Programming. ICLP-88, 1988, pp. 1070\u20131080.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1988}, {"title": "The berkeley framenet project", "author": ["C.F. Baker", "C.J. Fillmore", "J.B. Lowe"], "venue": "Proceedings of the 17th international conference on Computational linguistics. Association for Computational Linguistics, 1998, pp. 86\u201390.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1998}, {"title": "Dictionaries for learners of english", "author": ["P. Bogaards"], "venue": "International Journal of Lexicography, vol. 9, no. 4, pp. 277\u2013320, 1996.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1996}, {"title": "Generating Typed Dependency Parses from Phrase Structure Parses", "author": ["M.-C. de Marneffe", "B. Maccartney", "C.D. Manning"], "venue": "Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC-06). Genoa, Italy: ELRA/ELDA Paris, 2006, pp. 449\u2013454.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2006}, {"title": "The Stanford typed dependencies representation", "author": ["M.-C. de Marneffe", "C.D. Manning"], "venue": "Proceedings of the COLING 2008 Workshop on Cross-framework and Cross-domain Parser Evaluation, no. ii. Manchester, UK: ACL, 2008, pp. 1\u20138.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2008}, {"title": "Robust spoken instruction understanding for HRI", "author": ["R. Cantrell", "M. Scheutz", "P. Schermerhorn", "X. Wu"], "venue": "Proceedings of the 5th ACM/IEEE International Conference on Robot Interaction, 2010.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2010}, {"title": "Learning environmental knowledge from task-based human-robot dialog", "author": ["T. Kollar", "V. Perera", "D. Nardi", "M. Veloso"], "venue": "Proc. of the IEEE International Conference on Robotics and Automation, 2013.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2013}, {"title": "AfRob: The Affordance Network Ontology for Robots", "author": ["K.M. Varadarajan", "M. Vincze"], "venue": "IEEE/RSJ International Conference on Intelligent Robots and Systems, 2012.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2012}, {"title": "Grounding Natural Language References to Unvisited and Hypothetical Locations", "author": ["T. Williams", "R. Cantrell", "G. Briggs", "P. Schermerhorn", "M. Scheutz"], "venue": "Proceedings of the Twenty-Seventh AAAI Conference on Artificial Intelligence, Bellevue, Washington, USA, 2013.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2013}, {"title": "Engineering an incremental asp solver", "author": ["M. Gebser", "R. Kaminski", "B. Kaufmann", "M. Ostrowski", "T. Schaub", "S. Thiele"], "venue": "Logic Programming. Springer, 2008, pp. 190\u2013205.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2008}, {"title": "Towards a principled solution to simulated robot soccer", "author": ["A. Bai", "F. Wu", "X. Chen"], "venue": "Proceedings of the Robot Soccer World Cup XVI Symposium (RoboCup), Mexico City, Mexico, 2012, pp. 141\u2013153.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2012}, {"title": "Temporal-logic-based reactive mission and motion planning", "author": ["H. Kress-Gazit", "G.E. Fainekos", "G.J. Pappas"], "venue": "IEEE Transactions on Robotics, vol. 25, no. 6, pp. 1370\u20131381, 2009.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2009}, {"title": "Learning spatialsemantic representations from natural language descriptions and scene classifications", "author": ["S. Hemachandra", "M. Walter", "S. Tellex", "S. Teller"], "venue": "2014 IEEE International Conference on Robotics and Automation (ICRA), 2014, pp. 2623\u20132630.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2014}, {"title": "Grounding the interaction: knowledge management for interactive robots", "author": ["S. Lemaignan"], "venue": "KI-K unstliche Intelligenz, pp. 1\u20133, 2012.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2012}, {"title": "Grounding the interaction: Anchoring situated discourse in everyday human-robot interaction", "author": ["S. Lemaignan", "R. Ros", "E. Sisbot", "R. Alami", "M. Beetz"], "venue": "International Journal of Social Robotics, vol. 4, no. 2, pp. 181\u2013199, 2012.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2012}, {"title": "Building plans for household tasks from distributed knowledge", "author": ["C. Shah", "R. Gupta"], "venue": "Proceedings of the 19th International Joint Conference on Artificial Intelligence (IJCAI 2005) Workshop on Modeling Natural Action Selection. Citeseer, 2005.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2005}, {"title": "Knowrob-mapknowledge-linked semantic object maps", "author": ["M. Tenorth", "L. Kunze", "D. Jain", "M. Beetz"], "venue": "Humanoid Robots (Humanoids), 2010 10th IEEE-RAS International Conference on. IEEE, 2010, pp. 430\u2013435.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2010}, {"title": "Putting peoples common sense into knowledge bases of household robots", "author": ["L. Kunze", "M. Tenorth", "M. Beetz"], "venue": "KI 2010: Advances in Artificial Intelligence. Springer, 2010, pp. 151\u2013159.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2010}, {"title": "Knowrob: A knowledge processing infrastructure for cognition-enabled robots", "author": ["M. Tenorth", "M. Beetz"], "venue": "The International Journal of Robotics Research, vol. 32, no. 5, pp. 566\u2013590, 2013.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2013}, {"title": "Toward open knowledge enabling for human-robot interaction", "author": ["X. Chen", "J. Xie", "J. Ji", "Z. Sui"], "venue": "Journal of Human-Robot Interaction, vol. 1, no. 2, pp. 100\u2013117, 2012.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2012}, {"title": "Understanding instructions on large scale for human-robot interaction", "author": ["J. Xie", "X. Chen"], "venue": "Proceedings of the 2014 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent  Agent Technologies (IAT)-Volume 03. IEEE Computer Society, 2014, pp. 175\u2013182.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2014}, {"title": "Multi-mode natural language processing for human-robot interaction", "author": ["J. Xie", "X. Chen", "J. Ji"], "venue": "Web Intelligence, vol. 13, no. 4. IOS Press, 2015, pp. 267\u2013278.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": ", sequence of actions) for the tasks specified in the instruction [1], [2], [3], [4], [5], [6].", "startOffset": 66, "endOffset": 69}, {"referenceID": 1, "context": ", sequence of actions) for the tasks specified in the instruction [1], [2], [3], [4], [5], [6].", "startOffset": 71, "endOffset": 74}, {"referenceID": 2, "context": ", sequence of actions) for the tasks specified in the instruction [1], [2], [3], [4], [5], [6].", "startOffset": 76, "endOffset": 79}, {"referenceID": 3, "context": ", sequence of actions) for the tasks specified in the instruction [1], [2], [3], [4], [5], [6].", "startOffset": 81, "endOffset": 84}, {"referenceID": 4, "context": ", sequence of actions) for the tasks specified in the instruction [1], [2], [3], [4], [5], [6].", "startOffset": 86, "endOffset": 89}, {"referenceID": 5, "context": ", sequence of actions) for the tasks specified in the instruction [1], [2], [3], [4], [5], [6].", "startOffset": 91, "endOffset": 94}, {"referenceID": 6, "context": "Fortunately, there is more and more common knowledge available in open resources, such as the Open Mind Indoor Common Sense (OMICS) database [7], wikihow1, WordNet, and many other digital dictionaries.", "startOffset": 141, "endOffset": 144}, {"referenceID": 7, "context": "In our previous studies [8], we found that a user instruction representing a high-level task can usually be reduced into a sequence of low-level subtasks, using hierarchical knowledge in open resources.", "startOffset": 24, "endOffset": 27}, {"referenceID": 8, "context": "level subtasks expressed in common verbs [9]).", "startOffset": 41, "endOffset": 44}, {"referenceID": 2, "context": "To avoid this challenge, most of the existing approaches [3], [4], [10] manually create a small set of handcoded robot actions for primitive tasks though their scalability (i.", "startOffset": 57, "endOffset": 60}, {"referenceID": 3, "context": "To avoid this challenge, most of the existing approaches [3], [4], [10] manually create a small set of handcoded robot actions for primitive tasks though their scalability (i.", "startOffset": 62, "endOffset": 65}, {"referenceID": 9, "context": "To avoid this challenge, most of the existing approaches [3], [4], [10] manually create a small set of handcoded robot actions for primitive tasks though their scalability (i.", "startOffset": 67, "endOffset": 71}, {"referenceID": 10, "context": "Then, we use a planner based on Answer Set Programming (ASP) [11] to exploit definitions of common verbs in terms of semantic roles and generate a plan for the task specified in the user instruction.", "startOffset": 61, "endOffset": 65}, {"referenceID": 6, "context": "OMICS [7] is an extensive collection of knowledge for indoor service robots gathered from internet users.", "startOffset": 6, "endOffset": 9}, {"referenceID": 11, "context": "It groups action verbs into Frames and specifies word definitions in terms of semantic roles called Frame Elements (FEs) for each Frame [12].", "startOffset": 136, "endOffset": 140}, {"referenceID": 8, "context": "a list of roughly 2000 most frequent English words [9].", "startOffset": 51, "endOffset": 54}, {"referenceID": 12, "context": "The GSL is taken as the defining vocabulary of dictionaries such as the Longman Dictionary of Contemporary English, based on the notion that words should be defined using \u201cterms less abstruse than the word that is to be explained\u201d [13].", "startOffset": 231, "endOffset": 235}, {"referenceID": 13, "context": "We use the Stanford parser [14] in the first phase, which produces the Stanford-typed dependencies between words in a sentence.", "startOffset": 27, "endOffset": 31}, {"referenceID": 14, "context": "These dependencies indicate the grammatical relations between words in terms of the name of relation, governor, and dependence [15].", "startOffset": 127, "endOffset": 131}, {"referenceID": 15, "context": "To address this challenge, we borrow ideas from the \u201clast objects\u201d method [16] and propose the following method: TABLE III PART OF HIERARCHY FOR take-taking.", "startOffset": 74, "endOffset": 78}, {"referenceID": 16, "context": "7Some of unspecified roles should be identified by grounding [17], [6], [18], [19], which is beyond the scope of this article.", "startOffset": 61, "endOffset": 65}, {"referenceID": 5, "context": "7Some of unspecified roles should be identified by grounding [17], [6], [18], [19], which is beyond the scope of this article.", "startOffset": 67, "endOffset": 70}, {"referenceID": 17, "context": "7Some of unspecified roles should be identified by grounding [17], [6], [18], [19], which is beyond the scope of this article.", "startOffset": 72, "endOffset": 76}, {"referenceID": 18, "context": "7Some of unspecified roles should be identified by grounding [17], [6], [18], [19], which is beyond the scope of this article.", "startOffset": 78, "endOffset": 82}, {"referenceID": 17, "context": "The high-level part of our hierarchy is similar to that of AfNet [18].", "startOffset": 65, "endOffset": 69}, {"referenceID": 7, "context": "In our previous work, we proposed the OK-planner [8] based on ASP.", "startOffset": 49, "endOffset": 52}, {"referenceID": 7, "context": "Note that the semantic representation of a user instruction can be easily converted into a ASP form [8].", "startOffset": 100, "endOffset": 103}, {"referenceID": 19, "context": "After all pieces of knowledge have been converted into the ASP rules, an ASP solver iclingo [20] \u2014 a combination of Gringo and clasp for incremental grounding and solving \u2014 is used to incrementally ground the ASP rules above and search", "startOffset": 92, "endOffset": 96}, {"referenceID": 7, "context": "for answer sets, from which a plan can be computed [8].", "startOffset": 51, "endOffset": 54}, {"referenceID": 7, "context": "Moreover, we can see that the overall performance improved when semantic roles of common verbs was used, much better than the state-of-art solution [8].", "startOffset": 148, "endOffset": 151}, {"referenceID": 20, "context": "In the RoboCup@Home competitions of the past three years, our team \u2014 WrightEagle (WE) [21] got the 1st place once and 2nd place twice.", "startOffset": 86, "endOffset": 90}, {"referenceID": 1, "context": "For instance, several integrated systems [2], [16], [22] for natural language understanding have been introduced to enable robots to complete tasks given instructions in natural language.", "startOffset": 41, "endOffset": 44}, {"referenceID": 15, "context": "For instance, several integrated systems [2], [16], [22] for natural language understanding have been introduced to enable robots to complete tasks given instructions in natural language.", "startOffset": 46, "endOffset": 50}, {"referenceID": 21, "context": "For instance, several integrated systems [2], [16], [22] for natural language understanding have been introduced to enable robots to complete tasks given instructions in natural language.", "startOffset": 52, "endOffset": 56}, {"referenceID": 9, "context": "Work have been proposed to manually create environment-driven instructions for grounding user instructions in natural language to robots\u2019 actions [10], [23].", "startOffset": 146, "endOffset": 150}, {"referenceID": 22, "context": "Work have been proposed to manually create environment-driven instructions for grounding user instructions in natural language to robots\u2019 actions [10], [23].", "startOffset": 152, "endOffset": 156}, {"referenceID": 23, "context": "[24], [25] have tried to understand and reason about knowledge around an action model using online knowledge for robots.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "[24], [25] have tried to understand and reason about knowledge around an action model using online knowledge for robots.", "startOffset": 6, "endOffset": 10}, {"referenceID": 7, "context": "It is worth pointing out that we previously proposed an integrated system [8] for our KeJia robot consisting of multi-mode NLP, integrated decision-making, and open knowledge searching.", "startOffset": 74, "endOffset": 77}, {"referenceID": 25, "context": "The first attempt to utilize OMICS to accomplish a household task is [26], which proposed a generative model based on the Markov chain techniques.", "startOffset": 69, "endOffset": 73}, {"referenceID": 26, "context": "Later on, [27], [28], [29] presented a system called KNOWROB for processing knowledge in order to achieve more flexible and general behavior.", "startOffset": 10, "endOffset": 14}, {"referenceID": 27, "context": "Later on, [27], [28], [29] presented a system called KNOWROB for processing knowledge in order to achieve more flexible and general behavior.", "startOffset": 16, "endOffset": 20}, {"referenceID": 28, "context": "Later on, [27], [28], [29] presented a system called KNOWROB for processing knowledge in order to achieve more flexible and general behavior.", "startOffset": 22, "endOffset": 26}, {"referenceID": 29, "context": "Most recently, we proposed a formal description of knowledge gaps between user instructions and local knowledge in robotic system for instruction understanding [30], [8], [31], [32].", "startOffset": 160, "endOffset": 164}, {"referenceID": 7, "context": "Most recently, we proposed a formal description of knowledge gaps between user instructions and local knowledge in robotic system for instruction understanding [30], [8], [31], [32].", "startOffset": 166, "endOffset": 169}, {"referenceID": 30, "context": "Most recently, we proposed a formal description of knowledge gaps between user instructions and local knowledge in robotic system for instruction understanding [30], [8], [31], [32].", "startOffset": 171, "endOffset": 175}, {"referenceID": 31, "context": "Most recently, we proposed a formal description of knowledge gaps between user instructions and local knowledge in robotic system for instruction understanding [30], [8], [31], [32].", "startOffset": 177, "endOffset": 181}], "year": 2016, "abstractText": "Understanding user instructions in natural language is an active research topic in AI and robotics. Typically, natural user instructions are high-level and can be reduced into low-level tasks expressed in common verbs (e.g., \u2018take\u2019, \u2018get\u2019, \u2018put\u2019). For robots understanding such instructions, one of the key challenges is to process high-level user instructions and achieve the specified tasks with robots\u2019 primitive actions. To address this, we propose novel algorithms by utilizing semantic roles of common verbs defined in semantic dictionaries and integrating multiple open knowledge to generate task plans. Specifically, we present a new method for matching and recovering semantics of user instructions and a novel task planner that exploits functional knowledge of robot\u2019s action model. To verify and evaluate our approach, we implemented a prototype system using knowledge from several open resources. Experiments on our system confirmed the correctness and efficiency of our algorithms. Notably, our system has been deployed in the KeJia robot, which participated the annual RoboCup@Home competitions in the past three years and achieved encouragingly high scores in the benchmark tests.", "creator": "LaTeX with hyperref package"}}}