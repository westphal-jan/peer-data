{"id": "1606.03143", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Jun-2016", "title": "PerSum: Novel Systems for Document Summarization in Persian", "abstract": "In this paper we explore the problem of document summarization in Persian language from two distinct angles. In our first approach, we modify a popular and widely cited Persian document summarization framework to see how it works on a realistic corpus of news articles. Human evaluation on generated summaries shows that graph-based methods perform better than the modified systems. We carry this intuition forward in our second approach, and probe deeper into the nature of graph-based systems by designing several summarizers based on centrality measures. Ad hoc evaluation using ROUGE score on these summarizers suggests that there is a small class of centrality measures that perform better than three strong unsupervised baselines.", "histories": [["v1", "Thu, 9 Jun 2016 23:32:41 GMT  (1132kb)", "http://arxiv.org/abs/1606.03143v1", "42 pages, 9 figures"]], "COMMENTS": "42 pages, 9 figures", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["saeid parvandeh", "shibamouli lahiri", "fahimeh boroumand"], "accepted": false, "id": "1606.03143"}, "pdf": {"name": "1606.03143.pdf", "metadata": {"source": "CRF", "title": "PerSum: Novel Systems for Document Summarization in Persian", "authors": ["Saeid Parvandeh", "Shibamouli Lahiri", "Fahimeh Boroumand", "Saadi Shirazi", "Omar Khayyam"], "emails": ["saeid-parvandeh@utulsa.edu,", "lahiri@umich.edu,", "f.boroomand92@gmail.com"], "sections": [{"heading": null, "text": "In this paper, we examine the problem of summarizing documents in Persian from two different angles. In our first approach, we modify a popular and much-quoted Persian framework for summarizing documents to see how it works on a realistic corpus of news articles. Human evaluation of generated summaries shows that graph-based methods work better than modified systems. We continue this intuition in our second approach and examine the nature of graph-based systems by designing multiple summaries based on central metrics. Ad-hoc evaluation using ROUGE scores on these summaries suggests that there is a small class of central metrics that work better than three strong unattended baselines. Keywords Persian language, summary, Hamshahri, Pasokh, human evaluation, ROUGE, centrality, JROUGE, particularity."}, {"heading": "1. Introduction", "text": "This year, it has reached the point where it will be able to retaliate until it is able to retaliate."}, {"heading": "2. Related Work", "text": "In fact, most of them will be able to go to another world, where they can go to another world, where they can go to another world, where they can go to another world."}, {"heading": "3. Parsumist and Its Extensions", "text": "In fact, the fact is that most of them are able to survive themselves, and that they are able to survive themselves, \"he told the German Press Agency in an interview with\" Welt am Sonntag \":\" I don't think they will be able to survive themselves. \""}, {"heading": "3.1. Preprocessing", "text": "Parsumist uses a combination of statistical, semantic, and heuristic methods. The pre-processing step consists of tokenization, stop-word removal, and conceptual mapping (i.e., mapping words and phrases to synsets). Note that tokenization of free-form Persian texts is rather trivial due to coding problems, mixed orders (i.e. the presence of mixed right-left and left-right sequences of characters), omission of Ezafe in the Ezafe construction, and irregularities in word segmentation. While Parsumist uses a homemade tokenizer, we used the tokenizer developed by Mojgan Seraji as part of the Persian language processing tool (Hal\u00e1csy et al., 2007; Seraji, 2013; Seraji, 2015). The version we used was based on a pre-processing of 2009, a pair of Ruon hierarchy."}, {"heading": "3.2. Analysis and Scoring", "text": "In fact, most of them are able to trump themselves, and they are able to trump themselves. (...) Most of them are able to trump themselves. (...) Most of them are able to trump themselves. (...) Most of them are able to trump themselves. (...) Most of them are able to trump themselves. (...) Most of them are able to trump themselves. (...) Most of them are able to trump themselves. (...) Most of them are able to trump themselves. (...) Most of them are able to trump themselves. (...) Most of them are able to trump themselves. (...) Most of them are able to trump themselves. (...)"}, {"heading": "3.3. Selection and Redundancy Checking", "text": "This year it is as far as it has ever been until the next round."}, {"heading": "3.4. Smoothing the Summary for Coherence", "text": "In fact, most of the people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to, to, to, to move, to, to, to move, to move, to, to move, to, to"}, {"heading": "3.5. Multi-Document Summarization by Parsumist", "text": "Existing literature for summarizing multiple documents prescribes two different approaches to this problem: 1) concatenate all documents and then execute the summary of a single document. 2) Generate summaries of all documents of a single document, concatenate the summaries, and then run the summary of a single document (in particular the redundancy eliminator) on that linked document to create a more compact summary. Parsumistic authors noted that there was no significant difference in performance between the two approaches. However, it should be noted that the second approach has the obvious advantage of running the redundancy eliminator twice, resulting in a more compact, coherent, and readable summary (potentially)."}, {"heading": "3.6. Evaluation of Parsumist", "text": "In fact, most of them will be able to play by the rules that they have established in recent years, and they will be able to play by the rules."}, {"heading": "4. Results from Modified Parsumist and Graph-Based Systems", "text": "In this area, we are able to look for a solution that would enable us to find a solution that would enable us to find a solution that would enable us to find a solution that would enable us to find a solution and that would enable us to find a solution that would enable us to find a solution that would enable us to find a solution that would enable us to find a solution and that would enable us to find a solution that would enable us to find a solution."}, {"heading": "4.1. Question 1: How Much do the Judges Agree?", "text": "The agreement between the annotators is very important for all summarizing systems, not only because it gives us an idea of how difficult the task is (less agreement implies greater difficulty), but also because it provides an upper limit (roof line) for the performance of a proposed computing system. We presented each human judge as a vector of 200 elements (50 topics, 4 summaries per topic) and measured the agreement between these vectors. As shown in Table 1, the three judges do indeed exhibit a very high cosmic similarity to each other. This is reassuring, but not entirely satisfactory, since the correlation between the judges is relatively low (see Tables 2-4) and statistically indistinguishable in at least one of the cases (between Judges 2 and Judges 3). This shows that the task of summarizing several documents in Persian is indeed quite difficult, and we should expect the performance of the existing summarizers to be low."}, {"heading": "4.2. Question 2: Are the Judges Biased? If yes, by How Much?", "text": "It is instructive to look into the biases of commentators and see how much each judge tends in a particular direction on the Likert scale. Also, it allows us to identify relatively lenient judges and relatively tough judges and then adjust our rating accordingly. We presented each judge as a vector of 200 elements (as before) and calculated the means and standard deviations of these vectors. Table 5 shows the results. Note that Judge 2 is the most \"lenient\" in the sense that he gave the highest scores on average. Judge 3 was the most \"stubborn\" from this perspective. Compared to each other, the judges were actually quite similar in their averages, which may indicate the presence of a central bias (more discussion below). Considering the variability, the ratings of Judge 3 are most widespread, suggesting that he had the fact that he had the most diverse tendencies of opinions."}, {"heading": "4.3. Question 3: Are the Judges Similar?", "text": "We already observed that the mean scores of all three judges were quite close to each other due to the central tendency bias. We repeated measurements of the ANOVA (also called the paired ANOVA test) to determine whether the mean scores were statistically significantly deviated.14 The results show that they did not actually differ significantly from each other (i.e. we failed to refute the null hypothesis) at 95% confidence level, i.e. the judges are similar in terms of the mean scores, which undoubtedly proves the presence of the central tendency bias as a pervasive phenomenon in our Likert Scale note."}, {"heading": "4.4. Question 4: Are the Four Systems Different from Each Other? How Different Are", "text": "Remember that we have four systems (see Section 3.3) - two based on parsumist and two graph-based. How did they compare to each other? To answer this question, we first had to perform annotator standardization.14The p-value was calculated from this site: http: / / graphpad.com / quickcalcs / PValue1.cfmRecall from Section 4.2 that our annotators tended to be distorted - they had different mean overall ratings and different standard deviations. To remove this intra-annotator value, we calculated a z-score for each annotator: x z (5), where x is a particular rating, \u00b5 is the mean of all ratings assigned by an annotator and are annotator systems, and which is the default deviation of the annotator."}, {"heading": "4.5. Question 5: Are Similar Systems Similar in Terms of Performance?", "text": "Consider two \"system clusters\": one on graph-based systems and another on parsumistic systems. Are the two graph-based systems and the two parsumist systems in themselves more similar than each other? In other words, are the clusters more closely connected than each other? To see this, we measured cosinal similarities between all pairs of system vectors (each with a length of 50 cm). Table 7 shows the results. All other pairs are between group pairs and achieve much lower cosine similarities within clusters: graph-based systems (systems 3 and 4) reach a cosine of 91% between each other, while parsumist systems (systems 1 and 2) reach a cosine of 61% between each other."}, {"heading": "4.6. Question 6: How Are the 50 Topics Different in Terms of Summarization?", "text": "In fact, most people who have been in the US for the past two decades are able to outdo themselves; most people who are in the US are able to outdo themselves; most people who are in the US are able to outdo themselves; most people who are in the US are able to outdo themselves; most people who are in the US are able to outdo themselves; most people who are in the US are able to outdo themselves; most people who are in the US have grown up in the US; most of them have grown up in the US."}, {"heading": "4.7. Question 7: Is There a Relationship Between Summarizability and Number of", "text": "Documents? We can argue that the fewer documents a topic has, the more focused (and marginal) it should be and therefore easier to summarize. In other words, there should be a reverse correlation between the number of documents and the amount of abstractability. However, the following chart (Figure 3) - where the x-axis is Hamshahri topics (sorted in descending order of abstractability) and the y-axis is the number of documents for each topic - shows that this is clearly not the case. Figure 3 shows that there is almost no correlation between the two variables. Pearson's correlation between abstractability and the number of documents was found to be 0.09, which was not only too low, but also statistically indistically indistinguishable from zero at 95% confidence level.This shows that the issue of abstractability is complex and needs further investigation. Perhaps there are other variables, such as the document length, that have a greater influence on how summaries can be graded besides the underlying documents, before we can better classify the documents."}, {"heading": "5. Centrality-Based Summarization", "text": "We have already observed that centrality-based systems perform better than parsumistic systems in a post-hoc analysis of the summary of multiple documents on the Hamshahri corpus. The next question we asked ourselves is: If we were given an annotated corpus of aggregated Persian documents, which centrality measures would perform best in summarizing single and multiple documents? To answer this question, we resorted to the recently published pasokh corpus of annotated Persian summaries (Behmadi Moghaddas et al., 2013). Note that we could have performed this analysis posthoc, but our human commentators would have to perform hundreds of system-generated summaries manually - a distinctly untenable approach. Instead, we used the popular ROUGE package (Lin, 2004) - in particular its recent Java implementation called JROUGE (Ganesan et al., 2010) - to evaluate our centrality-based systems."}, {"heading": "5.1. Centrality-Based Methods", "text": "It is not as if it were an isolated case, but it is not as if it were an isolated case. (...) It is as if it were an isolated case. (...) It is as if it were an isolated case. (...) It is as if it were an isolated case. (...) It is as if it were an isolated case. (...) It is as if it were an isolated case. (...) It is as if it were an isolated case. (...) It is as if it were an isolated case. (...) It is as if it were an isolated case. (...) It is as if it were an isolated case. (...) It is as if it were an isolated case. (...) It is as if it were an isolated case. (...) It is as if it were an isolated case."}, {"heading": "5.2. Centrality-Based Systems", "text": "This year it has come to the point that it is a purely reactionary, reactionary, reactionary, reactionary and reactionary project, in which it is a reactionary, reactionary and reactionary project."}, {"heading": "5.3. Evaluation of Centrality-Based Systems", "text": "This year it is so far that it will only take one year to move on to the next round."}, {"heading": "6. Results on the Pasokh Corpus", "text": "This year is the highest in the history of the country."}, {"heading": "7. Conclusion and Future Work", "text": "We have described three classes of novel, unsupervised systems for summarizing single and multiple documents in Persian - one based on parsumistic, one popular Persian summary, and two based on sentence networks and centrality scales. Experimental results suggest that graph-based methods perform better than parsumist methods, and there are some key metrics (strength, PageRank, eigenvector centrality, and structural diversity index) that perform better than others. Detailed human assessments (post-hoc) and assessments using the ROUGE score have been reported. There are several limitations to our study, all of which can be improved in the future: Our study does not consider the problem of supervised summarization, where an amachinated learning system is trained to identify sentences and / or other linguistic units for inclusion in the summary. Existing literature suggests that supervised systems perform better than unattended ones."}, {"heading": "8. References", "text": "In fact, most people who are able to understand the world and understand what they are doing do not know what to do, and they do not know what to do, what to do, and what to do to save the world."}], "references": [{"title": "Hamshahri: A standard Persian text collection", "author": ["A. AleAhmad", "H. Amiri", "E. Darrudi", "M. Rahgozar", "F. Oroumchian"], "venue": "Knowledge-Based Systems,", "citeRegEx": "AleAhmad et al\\.,? \\Q2009\\E", "shortCiteRegEx": "AleAhmad et al\\.", "year": 2009}, {"title": "The rush in a directed graph", "author": ["J.M. Anthonisse"], "venue": "Technical report, Stichting Mathematisch Centrum,", "citeRegEx": "Anthonisse,? \\Q1971\\E", "shortCiteRegEx": "Anthonisse", "year": 1971}, {"title": "Communication Patterns in Task-Oriented Groups", "author": ["A. Bavelas"], "venue": "The Journal of the Acoustical Society of America,", "citeRegEx": "Bavelas,? \\Q1950\\E", "shortCiteRegEx": "Bavelas", "year": 1950}, {"title": "Extractive Summarization Of Farsi Documents Based On PSO Clustering", "author": ["M. Bazghandi", "G.T. Tabrizi", "M.V. Jahan"], "venue": "International Journal of Computer Science Issues (IJCSI),", "citeRegEx": "Bazghandi et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Bazghandi et al\\.", "year": 2012}, {"title": "Pasokh: A Standard Corpus for the Evaluation of Persian Text Summarizers", "author": ["B. Behmadi Moghaddas", "M. Kahani", "S.A. Toosi", "A. Pourmasoumi", "A. Estiri"], "venue": "In Proceedings of the 3 International eConference on Computer and Knowledge Engineering (ICCKE),", "citeRegEx": "Moghaddas et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Moghaddas et al\\.", "year": 2013}, {"title": "A Method for Stemming and Eliminating Common Words for Persian Text Summarization", "author": ["M. Berenjkoob", "R. Mehri", "H. Khosravi", "M.A. Nematbakhsh"], "venue": "In Proceedings of the International Conference on Natural Language Processing and Knowledge Engineering (NLP-KE),", "citeRegEx": "Berenjkoob et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Berenjkoob et al\\.", "year": 2009}, {"title": "Axioms for Centrality", "author": ["P. Boldi", "S. Vigna"], "venue": "Internet Mathematics,", "citeRegEx": "Boldi and Vigna,? \\Q2014\\E", "shortCiteRegEx": "Boldi and Vigna", "year": 2014}, {"title": "Power and Centrality: A Family of Measures", "author": ["P. Bonacich"], "venue": "American Journal of Sociology,", "citeRegEx": "Bonacich,? \\Q1987\\E", "shortCiteRegEx": "Bonacich", "year": 1987}, {"title": "Centrality and network flow", "author": ["S.P. Borgatti"], "venue": "Social Networks,", "citeRegEx": "Borgatti,? \\Q2005\\E", "shortCiteRegEx": "Borgatti", "year": 2005}, {"title": "A Graph-theoretic perspective on centrality", "author": ["S.P. Borgatti", "M.G. Everett"], "venue": "Social Networks,", "citeRegEx": "Borgatti and Everett,? \\Q2006\\E", "shortCiteRegEx": "Borgatti and Everett", "year": 2006}, {"title": "A Comparison of Centrality Measures for Graph-Based Keyphrase Extraction", "author": ["F. Boudin"], "venue": "In Proceedings of the Sixth International Joint Conference on Natural Language Processing,", "citeRegEx": "Boudin,? \\Q2013\\E", "shortCiteRegEx": "Boudin", "year": 2013}, {"title": "A Faster Algorithm for Betweenness Centrality", "author": ["U. Brandes"], "venue": null, "citeRegEx": "Brandes,? \\Q2001\\E", "shortCiteRegEx": "Brandes", "year": 2001}, {"title": "Multimodal Distributional Semantics", "author": ["E. Bruni", "N.K. Tran", "M. Baroni"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Bruni et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bruni et al\\.", "year": 2014}, {"title": "Revealing Dimensions of Thinking in Open-Ended Self-Descriptions: An Automated Meaning Extraction Method for Natural Language", "author": ["C.K. Chung", "J.W. Pennebaker"], "venue": "Journal of Research in Personality,", "citeRegEx": "Chung and Pennebaker,? \\Q2008\\E", "shortCiteRegEx": "Chung and Pennebaker", "year": 2008}, {"title": "The igraph software package for complex network research. Inter-Journal, Complex Systems:1695", "author": ["G. Csardi", "T. Nepusz"], "venue": null, "citeRegEx": "Csardi and Nepusz,? \\Q2006\\E", "shortCiteRegEx": "Csardi and Nepusz", "year": 2006}, {"title": "SweSum \u2013 a text summarizer for Swedish. Technical Report TRITA-NA-P0015, Department of Numerical Analysis and Computing Science, Royal Institute of Technology (KTH), Stockholm, Sweden, August", "author": ["H. Dalianis"], "venue": null, "citeRegEx": "Dalianis,? \\Q2000\\E", "shortCiteRegEx": "Dalianis", "year": 2000}, {"title": "LexRank: Graph-based Lexical Centrality as Salience in Text Summarization", "author": ["G. Erkan", "D.R. Radev"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Erkan and Radev,? \\Q2004\\E", "shortCiteRegEx": "Erkan and Radev", "year": 2004}, {"title": "Papers in linguistics, 1934-1951", "author": ["J.R. Firth"], "venue": null, "citeRegEx": "Firth,? \\Q1957\\E", "shortCiteRegEx": "Firth", "year": 1957}, {"title": "Opinosis: A Graph-Based Approach to Abstractive Summarization of Highly Redundant Opinions", "author": ["K. Ganesan", "C. Zhai", "J. Han"], "venue": "In Proceedings of the 23 International Conference on Computational Linguistics (COLING", "citeRegEx": "Ganesan et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Ganesan et al\\.", "year": 2010}, {"title": "HunPos \u2013 an open source trigram tagger", "author": ["P. Hal\u00e1csy", "A. Kornai", "C. Oravecz"], "venue": "In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions,", "citeRegEx": "Hal\u00e1csy et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Hal\u00e1csy et al\\.", "year": 2007}, {"title": "FarsiSum \u2013 A Persian text summarizer, In Proceedings of the Workshop on Computational Approaches to Arabic Script-based Languages", "author": ["M. Hassel", "N. Mazdak"], "venue": "(Semitic", "citeRegEx": "Hassel and Mazdak,? \\Q2004\\E", "shortCiteRegEx": "Hassel and Mazdak", "year": 2004}, {"title": "An Automatic Linguistics Approach for Persian Document Summarization", "author": ["H. Kamyar", "M. Kahani", "M. Kamyar", "A. Poormasoomi"], "venue": "In Proceedings of the International Conference on Asian Language Processing (IALP),", "citeRegEx": "Kamyar et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Kamyar et al\\.", "year": 2011}, {"title": "Optimizing Persian Text Summarization Based on Fuzzy Logic Approach", "author": ["F. Kiyoumarsi", "F.R. Esfahani"], "venue": "In Proceedings of the International Conference on Intelligent Building and Management,", "citeRegEx": "Kiyoumarsi and Esfahani,? \\Q2011\\E", "shortCiteRegEx": "Kiyoumarsi and Esfahani", "year": 2011}, {"title": "Complexity of Word Collocation Networks: A Preliminary Structural Analysis", "author": ["S. Lahiri"], "venue": "In Proceedings of the Student Research Workshop at the 14th Conference of the European Chapter of the Association for Computational Linguistics,", "citeRegEx": "Lahiri,? \\Q2014\\E", "shortCiteRegEx": "Lahiri", "year": 2014}, {"title": "Keyword and Keyphrase Extraction Using Centrality Measures on Collocation Networks, ArXiv e-print, January", "author": ["S. Lahiri", "S. Ray Choudhury", "C. Caragea"], "venue": null, "citeRegEx": "Lahiri et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Lahiri et al\\.", "year": 2014}, {"title": "A Technique for the Measurement of Attitudes", "author": ["R. Likert"], "venue": "Archives of Psychology,", "citeRegEx": "Likert,? \\Q1932\\E", "shortCiteRegEx": "Likert", "year": 1932}, {"title": "ROUGE: A Package for Automatic Evaluation of Summaries, In Text Summarization Branches Out", "author": ["Lin", "C.-Y"], "venue": "Proceedings of the ACL-04 Workshop,", "citeRegEx": "Lin and C..Y.,? \\Q2004\\E", "shortCiteRegEx": "Lin and C..Y.", "year": 2004}, {"title": "Graph-based Natural Language Processing and Information Retrieval", "author": ["R. Mihalcea", "D. Radev"], "venue": null, "citeRegEx": "Mihalcea and Radev,? \\Q2011\\E", "shortCiteRegEx": "Mihalcea and Radev", "year": 2011}, {"title": "TextRank: Bringing Order into Texts", "author": ["R. Mihalcea", "P. Tarau"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Mihalcea and Tarau,? \\Q2004\\E", "shortCiteRegEx": "Mihalcea and Tarau", "year": 2004}, {"title": "WordNet: A Lexical Database for English", "author": ["G.A. Miller"], "venue": "Communications of the ACM,", "citeRegEx": "Miller,? \\Q1995\\E", "shortCiteRegEx": "Miller", "year": 1995}, {"title": "The Pyramid Method: Incorporating Human Content Selection Variation in Summarization Evaluation", "author": ["A. Nenkova", "R. Passonneau", "K. McKeown"], "venue": "ACM Transactions on Speech and Language Processing,", "citeRegEx": "Nenkova et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Nenkova et al\\.", "year": 2007}, {"title": "Using the Pyramid Method for generating gold standards for Persian texts", "author": ["M.J. Nia"], "venue": null, "citeRegEx": "Nia,? \\Q2013\\E", "shortCiteRegEx": "Nia", "year": 2013}, {"title": "The PageRank Citation Ranking: Bringing Order to the Web", "author": ["L. Page", "S. Brin", "R. Motwani", "T. Winograd"], "venue": "In Proceedings of the 7 International World Wide Web Conference,", "citeRegEx": "Page et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Page et al\\.", "year": 1998}, {"title": "Context-Based Persian Multi-Document Summarization (global view)", "author": ["A. Poormasoomi", "M. Kahani", "S.V. Yazdi", "H. Kamyar"], "venue": "In Proceedings of the International Conference on Asian Language Processing (IALP),", "citeRegEx": "Poormasoomi et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Poormasoomi et al\\.", "year": 2011}, {"title": "Development of a Persian Syntactic Dependency Treebank", "author": ["M.S. Rasooli", "M. Kouhestani", "A. Moloodi"], "venue": "In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,", "citeRegEx": "Rasooli et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Rasooli et al\\.", "year": 2013}, {"title": "PrePer: A Pre-processor for Persian", "author": ["M. Seraji"], "venue": "In Proceedings of the Fifth International Conference on Iranian Linguistics (ICIL5),", "citeRegEx": "Seraji,? \\Q2013\\E", "shortCiteRegEx": "Seraji", "year": 2013}, {"title": "Morphosyntactic Corpora and Tools for Persian", "author": ["M. Seraji"], "venue": "Ph.D. Thesis,", "citeRegEx": "Seraji,? \\Q2015\\E", "shortCiteRegEx": "Seraji", "year": 2015}, {"title": "A New Graph-based Algorithm for Persian Text Summarization", "author": ["H. Shakeri", "S. Gholamrezazadeh", "M. Amini Salehi", "F. Ghadamyari"], "venue": "Computer Science and Convergence,", "citeRegEx": "Shakeri et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Shakeri et al\\.", "year": 2012}, {"title": "2009a, Persian Document Summarization by Parsumist", "author": ["M. Shamsfard", "T. Akhavan", "M. Erfani Joorabchi"], "venue": "World Applied Sciences", "citeRegEx": "Shamsfard et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Shamsfard et al\\.", "year": 2009}, {"title": "2009b, Parsumist: A Persian Text Summarizer", "author": ["M. Shamsfard", "T. Akhavan", "M. Erfani Jourabchi"], "venue": "In Proceedings of the International Conference on Natural Language Processing and Knowledge Engineering (NLP-KE),", "citeRegEx": "Shamsfard et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Shamsfard et al\\.", "year": 2009}, {"title": "Persian Text Summarization", "author": ["M. Tofighy", "O. Kashefi", "A. Zamanifar", "H.H. Seyyed Javadi"], "venue": "Using Fractal Theory. Informatics Engineering and Information Science,", "citeRegEx": "Tofighy et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Tofighy et al\\.", "year": 2011}, {"title": "AHP Techniques for Persian Text Summarization", "author": ["S.M. Tofighy", "R.G. Raj", "H.H. Seyyed Javadi"], "venue": "Malaysian Journal of Computer Science,", "citeRegEx": "Tofighy et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Tofighy et al\\.", "year": 2013}, {"title": "Collective dynamics of \u2018small-world", "author": ["D.J. Watts", "S.H. Strogatz"], "venue": null, "citeRegEx": "Watts and Strogatz,? \\Q1998\\E", "shortCiteRegEx": "Watts and Strogatz", "year": 1998}, {"title": "AZOM: A Persian Structured Text Summarizer", "author": ["A. Zamanifar", "O. Kashefi"], "venue": "Natural Language Processing and Information Systems,", "citeRegEx": "Zamanifar and Kashefi,? \\Q2011\\E", "shortCiteRegEx": "Zamanifar and Kashefi", "year": 2011}, {"title": "A New Hybrid Farsi Text Summarization Technique Based on Term Co-Occurrence and Conceptual Property of the Text", "author": ["A. Zamanifar", "B. Minaei-Bidgoli", "M. Sharifi"], "venue": "In Proceedings of the Ninth ACIS International Conference on Software Engineering,", "citeRegEx": "Zamanifar et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Zamanifar et al\\.", "year": 2008}], "referenceMentions": [{"referenceID": 35, "context": "Despite having such a large speaker population and a vibrant presence in many countries, Natural Language Processing in Persian has been stymied by a lack of publicly available corpora and tools, which has only very recently started to change (Seraji, 2013; Seraji, 2015).", "startOffset": 243, "endOffset": 271}, {"referenceID": 36, "context": "Despite having such a large speaker population and a vibrant presence in many countries, Natural Language Processing in Persian has been stymied by a lack of publicly available corpora and tools, which has only very recently started to change (Seraji, 2013; Seraji, 2015).", "startOffset": 243, "endOffset": 271}, {"referenceID": 0, "context": "In our first approach, we used a well-known Persian news corpus (Hamshahri (AleAhmad et al., 2009)) to evaluate Parsumist \u2013 a popular Persian document summarization framework (Sections 3 and 4).", "startOffset": 75, "endOffset": 98}, {"referenceID": 28, "context": "In our second approach, we used centrality measures on sentence networks (similar to TextRank (Mihalcea and Tarau, 2004) and LexRank (Erkan and Radev, 2004)) to perform single and multi-document summarization on the recently released Pasokh corpus (Sections 5 and 6).", "startOffset": 94, "endOffset": 120}, {"referenceID": 16, "context": "In our second approach, we used centrality measures on sentence networks (similar to TextRank (Mihalcea and Tarau, 2004) and LexRank (Erkan and Radev, 2004)) to perform single and multi-document summarization on the recently released Pasokh corpus (Sections 5 and 6).", "startOffset": 133, "endOffset": 156}, {"referenceID": 15, "context": "It used a client-server application written in Perl, and was little more than an earlier implementation \u2013 SweSum (Dalianis, 2000) \u2013 augmented by a Persian stop word list.", "startOffset": 113, "endOffset": 129}, {"referenceID": 14, "context": "It used a client-server application written in Perl, and was little more than an earlier implementation \u2013 SweSum (Dalianis, 2000) \u2013 augmented by a Persian stop word list. No evaluation was reported in Hassel and Mazdak (2004)\u2019s study.", "startOffset": 114, "endOffset": 226}, {"referenceID": 14, "context": "It used a client-server application written in Perl, and was little more than an earlier implementation \u2013 SweSum (Dalianis, 2000) \u2013 augmented by a Persian stop word list. No evaluation was reported in Hassel and Mazdak (2004)\u2019s study. Zamanifar et al. (2008) reported the next study using lexical chains, word clustering, and a summary coefficient for each cluster.", "startOffset": 114, "endOffset": 259}, {"referenceID": 14, "context": "It used a client-server application written in Perl, and was little more than an earlier implementation \u2013 SweSum (Dalianis, 2000) \u2013 augmented by a Persian stop word list. No evaluation was reported in Hassel and Mazdak (2004)\u2019s study. Zamanifar et al. (2008) reported the next study using lexical chains, word clustering, and a summary coefficient for each cluster. Words were clustered by their co-occurrence degree assessed by a bigram language model. Results on 60 Persian news articles showed that Zamanifar et al. (2008)\u2019s approach was superior to FarsiSum (in terms of precision and recall) at compression ratios of 30%, 40%, and 50%.", "startOffset": 114, "endOffset": 526}, {"referenceID": 5, "context": "Berenjkoob et al. (2009) explored the qualitative and quantitative merits of incorporating stemming and stop word removal in Persian document summarization.", "startOffset": 0, "endOffset": 25}, {"referenceID": 29, "context": "In the preprocessing stage, stop words were removed and content words were mapped to a sense hierarchy akin to WordNet (Miller, 1995).", "startOffset": 119, "endOffset": 133}, {"referenceID": 21, "context": "Kamyar et al. (2011) were the first.", "startOffset": 0, "endOffset": 21}, {"referenceID": 21, "context": "Kiyoumarsi and Esfahani (2011) introduced fuzzy logic in Persian document summarization.", "startOffset": 0, "endOffset": 31}, {"referenceID": 21, "context": "Kiyoumarsi and Esfahani (2011) introduced fuzzy logic in Persian document summarization. They reported performance superior to four other systems in a simulation study. Zamanifar and Kashefi (2011) discussed AZOM \u2013 a summarizer that takes into account the implicit or explicit structure of a document (in terms of paragraphs, blocks, etc).", "startOffset": 0, "endOffset": 198}, {"referenceID": 21, "context": "Kiyoumarsi and Esfahani (2011) introduced fuzzy logic in Persian document summarization. They reported performance superior to four other systems in a simulation study. Zamanifar and Kashefi (2011) discussed AZOM \u2013 a summarizer that takes into account the implicit or explicit structure of a document (in terms of paragraphs, blocks, etc). AZOM performed better than two state-of-the-art approaches, and a \u201cflat summary\u201d baseline. Tofighy et al. (2011) used a more rigorous structure-based approach, leveraging block nesting and sibling blocks.", "startOffset": 0, "endOffset": 453}, {"referenceID": 3, "context": "Bazghandi et al. (2012) clustered sentences based on the semantic similarity of their content words.", "startOffset": 0, "endOffset": 24}, {"referenceID": 3, "context": "Bazghandi et al. (2012) clustered sentences based on the semantic similarity of their content words. Semantic similarity between two words was defined as a variant of their PMI (pointwise mutual information). Sentences were clustered using a particle swarm optimization (PSO) algorithm. The system achieved competitive results with traditional clustering approaches. Shakeri et al. (2012) constructed an undirected sentence network similar to LexRank", "startOffset": 0, "endOffset": 389}, {"referenceID": 16, "context": "(Erkan and Radev, 2004) and TextRank (Mihalcea and Tarau, 2004).", "startOffset": 0, "endOffset": 23}, {"referenceID": 28, "context": "(Erkan and Radev, 2004) and TextRank (Mihalcea and Tarau, 2004).", "startOffset": 37, "endOffset": 63}, {"referenceID": 41, "context": "An interesting study employing Analytical Hierarchy Process (AHP) to Persian document summarization was discussed in (Tofighy et al., 2013).", "startOffset": 117, "endOffset": 139}, {"referenceID": 16, "context": "(Erkan and Radev, 2004) and TextRank (Mihalcea and Tarau, 2004). They applied the system to ten Persian scientific papers at a compression ratio of 50%. The network-based system performed significantly better than FarsiSum against a human-generated gold standard (in terms of precision, recall, F-score, and ROUGE-1). An interesting study employing Analytical Hierarchy Process (AHP) to Persian document summarization was discussed in (Tofighy et al., 2013). The authors arranged six existing summarization features (word frequency, keywords, headline word, cue word, sentence position, and sentence length) in an AHP matrix to assess their relative importance, and to come up with an optimal selection of sentences. Results showed better F-score than FarsiSum at compression ratios of 30% and 40%. Finally, Nia (2013) did his Master\u2019s thesis in generating gold standards for Persian", "startOffset": 1, "endOffset": 819}, {"referenceID": 30, "context": "document summarization using the pyramid method (Nenkova et al., 2007).", "startOffset": 48, "endOffset": 70}, {"referenceID": 19, "context": "While Parsumist uses a home-grown tokenizer, we used the tokenizer made available by Mojgan Seraji as part of the Persian language processing toolkit she developed (Hal\u00e1csy et al., 2007; Seraji, 2013; Seraji, 2015).", "startOffset": 164, "endOffset": 214}, {"referenceID": 35, "context": "While Parsumist uses a home-grown tokenizer, we used the tokenizer made available by Mojgan Seraji as part of the Persian language processing toolkit she developed (Hal\u00e1csy et al., 2007; Seraji, 2013; Seraji, 2015).", "startOffset": 164, "endOffset": 214}, {"referenceID": 36, "context": "While Parsumist uses a home-grown tokenizer, we used the tokenizer made available by Mojgan Seraji as part of the Persian language processing toolkit she developed (Hal\u00e1csy et al., 2007; Seraji, 2013; Seraji, 2015).", "startOffset": 164, "endOffset": 214}, {"referenceID": 0, "context": "Note further that we used Hamshahri (AleAhmad et al., 2009) as our input corpus for this part, and Hamshahri is released in NCR (numeric character encoding) encoded XML format, so we needed to convert NCR into UTF-8 Unicode first.", "startOffset": 36, "endOffset": 59}, {"referenceID": 29, "context": ", a synset) in a small concept hierarchy akin to WordNet (Miller, 1995).", "startOffset": 57, "endOffset": 71}, {"referenceID": 33, "context": "Poormasoomi et al. (2011) were the first.", "startOffset": 0, "endOffset": 26}, {"referenceID": 19, "context": "Many of the features needed a part-of-speech tagger; we used Mojgan Seraji\u2019s tagger (Hal\u00e1csy et al., 2007; Seraji, 2015) for this purpose.", "startOffset": 84, "endOffset": 120}, {"referenceID": 36, "context": "Many of the features needed a part-of-speech tagger; we used Mojgan Seraji\u2019s tagger (Hal\u00e1csy et al., 2007; Seraji, 2015) for this purpose.", "startOffset": 84, "endOffset": 120}, {"referenceID": 29, "context": "Similarity between two nodes (sentences) is computed using lexical chains and a synset hierarchy akin to WordNet (Miller, 1995).", "startOffset": 113, "endOffset": 127}, {"referenceID": 12, "context": ", Bruni et al. (2014)), and is reasonably free from statistical assumptions.", "startOffset": 2, "endOffset": 22}, {"referenceID": 28, "context": "Then we followed the popular TextRank (Mihalcea and Tarau, 2004) and LexRank (Erkan and Radev, 2004) formalism that prescribed running a random walk on this sentence network, and scoring nodes by their PageRank value (Page et al.", "startOffset": 38, "endOffset": 64}, {"referenceID": 16, "context": "Then we followed the popular TextRank (Mihalcea and Tarau, 2004) and LexRank (Erkan and Radev, 2004) formalism that prescribed running a random walk on this sentence network, and scoring nodes by their PageRank value (Page et al.", "startOffset": 77, "endOffset": 100}, {"referenceID": 32, "context": "Then we followed the popular TextRank (Mihalcea and Tarau, 2004) and LexRank (Erkan and Radev, 2004) formalism that prescribed running a random walk on this sentence network, and scoring nodes by their PageRank value (Page et al., 1998).", "startOffset": 217, "endOffset": 236}, {"referenceID": 10, "context": "Please see Boudin (2013) and Lahiri et al.", "startOffset": 11, "endOffset": 25}, {"referenceID": 10, "context": "Please see Boudin (2013) and Lahiri et al. (2014) for evidence that non-PageRank centrality measures often perform as well as or better than PageRank, when it comes to keyphrase extraction.", "startOffset": 11, "endOffset": 50}, {"referenceID": 20, "context": "Parsumist was compared against \u2013 and found to perform better than \u2013 two then state-of-the-art baselines: FarsiSum (Hassel and Mazdak, 2004), and Karimi and Shamsfard\u2019s summarizer.", "startOffset": 114, "endOffset": 139}, {"referenceID": 0, "context": "Since we did not have access to the annotated gold standard data Parsumist authors generated, we instead used the Hamshahri corpus of news articles (AleAhmad et al., 2009), and evaluated our four systems (cf.", "startOffset": 148, "endOffset": 171}, {"referenceID": 28, "context": "Parsumist, as already noted, can perform multi-document summarization in this way; so can graph-based systems like TextRank (Mihalcea and Tarau, 2004) and LexRank (Erkan and Radev, 2004).", "startOffset": 124, "endOffset": 150}, {"referenceID": 16, "context": "Parsumist, as already noted, can perform multi-document summarization in this way; so can graph-based systems like TextRank (Mihalcea and Tarau, 2004) and LexRank (Erkan and Radev, 2004).", "startOffset": 163, "endOffset": 186}, {"referenceID": 25, "context": "Note that the above scheme corresponds to a Likert Scale style annotation (Likert, 1932), and is widely used in summarization research.", "startOffset": 74, "endOffset": 88}, {"referenceID": 18, "context": "Instead, we used the popular ROUGE package (Lin, 2004) \u2013 in particular, its recent Java implementation called JROUGE (Ganesan et al., 2010) \u2013 to evaluate our centrality-based systems.", "startOffset": 117, "endOffset": 139}, {"referenceID": 17, "context": "Centrality-Based Methods It is well-known in distributional semantics that a word is known by the company it keeps (Firth, 1957).", "startOffset": 115, "endOffset": 128}, {"referenceID": 23, "context": "(Lahiri, 2014)), where nodes are words and edges are word co-occurrence relationships, can succinctly and explicitly capture such dependencies.", "startOffset": 0, "endOffset": 14}, {"referenceID": 28, "context": "It has been observed (Mihalcea and Tarau, 2004) that in such networks, words with the highest centrality also happen to be the most important words (keywords) in the document.", "startOffset": 21, "endOffset": 47}, {"referenceID": 28, "context": "where nodes are sentences and edges are weighted (perhaps pruned, too) by sentence similarity, then the most important sentences in the document turn out to have highest centrality in the resulting network (Mihalcea and Tarau, 2004; Erkan and Radev, 2004).", "startOffset": 206, "endOffset": 255}, {"referenceID": 16, "context": "where nodes are sentences and edges are weighted (perhaps pruned, too) by sentence similarity, then the most important sentences in the document turn out to have highest centrality in the resulting network (Mihalcea and Tarau, 2004; Erkan and Radev, 2004).", "startOffset": 206, "endOffset": 255}, {"referenceID": 27, "context": "These two observations started the field of graph-based summarization and keyword extraction (Mihalcea and Radev, 2011).", "startOffset": 93, "endOffset": 119}, {"referenceID": 10, "context": "(Boudin, 2013; Lahiri et al., 2014)), and graph-based approaches are still being pursued by several research groups around the world.", "startOffset": 0, "endOffset": 35}, {"referenceID": 24, "context": "(Boudin, 2013; Lahiri et al., 2014)), and graph-based approaches are still being pursued by several research groups around the world.", "startOffset": 0, "endOffset": 35}, {"referenceID": 28, "context": "However, as Mihalcea and Tarau (2004) pointed out using a cognitive science argument, any network \u2013 be it words or sentences or people (social networks) \u2013 encodes a system of endorsements and", "startOffset": 12, "endOffset": 38}, {"referenceID": 8, "context": "In practice, the concept of centrality has been studied in the social sciences for several decades (Borgatti, 2005).", "startOffset": 99, "endOffset": 115}, {"referenceID": 6, "context": "As Boldi and Vigna (2014) point out, there exist at least six different categories (families) of centrality indices", "startOffset": 3, "endOffset": 26}, {"referenceID": 8, "context": "However, as Borgatti and Everett (2006) observed, most (if not all) of these indices assess a", "startOffset": 12, "endOffset": 40}, {"referenceID": 19, "context": "Sentences were extracted from the Pasokh corpus using the normalizer and tokenizer developed by Mojgan Seraji (Hal\u00e1csy et al., 2007; Seraji, 2013; Seraji, 2015), in the same spirit as Section 3.", "startOffset": 110, "endOffset": 160}, {"referenceID": 35, "context": "Sentences were extracted from the Pasokh corpus using the normalizer and tokenizer developed by Mojgan Seraji (Hal\u00e1csy et al., 2007; Seraji, 2013; Seraji, 2015), in the same spirit as Section 3.", "startOffset": 110, "endOffset": 160}, {"referenceID": 36, "context": "Sentences were extracted from the Pasokh corpus using the normalizer and tokenizer developed by Mojgan Seraji (Hal\u00e1csy et al., 2007; Seraji, 2013; Seraji, 2015), in the same spirit as Section 3.", "startOffset": 110, "endOffset": 160}, {"referenceID": 14, "context": "Centrality was computed using the igraph package (Csardi and Nepusz, 2006).", "startOffset": 49, "endOffset": 74}, {"referenceID": 42, "context": "Clustering Coefficient: density of edges among the immediate neighbors of a node (Watts and Strogatz, 1998).", "startOffset": 81, "endOffset": 107}, {"referenceID": 32, "context": "PageRank: importance of a node based on how many important nodes it is connected to (Page et al., 1998).", "startOffset": 84, "endOffset": 103}, {"referenceID": 1, "context": "Betweenness: fraction of shortest paths that pass through a node, summed over all node pairs (Anthonisse, 1971; Brandes, 2001).", "startOffset": 93, "endOffset": 126}, {"referenceID": 11, "context": "Betweenness: fraction of shortest paths that pass through a node, summed over all node pairs (Anthonisse, 1971; Brandes, 2001).", "startOffset": 93, "endOffset": 126}, {"referenceID": 2, "context": "Closeness: reciprocal of the sum of distances of all nodes to a node (Bavelas, 1950).", "startOffset": 69, "endOffset": 84}, {"referenceID": 7, "context": "Eigenvector Centrality: element of the first eigenvector of a graph adjacency matrix corresponding to a node (Bonacich, 1987).", "startOffset": 109, "endOffset": 125}, {"referenceID": 6, "context": "The above seven centrality measures touch all six different centrality families identified by Boldi and Vigna (2014), hence they may be deemed comprehensive for the purposes of our study.", "startOffset": 94, "endOffset": 117}, {"referenceID": 18, "context": "Hence, we resorted to the recently released JROUGE package written in Java (Ganesan et al., 2010).", "startOffset": 75, "endOffset": 97}, {"referenceID": 34, "context": "Dependency treebanks have been developed and are currently available for Persian (Rasooli et al., 2013; Seraji, 2015).", "startOffset": 81, "endOffset": 117}, {"referenceID": 36, "context": "Dependency treebanks have been developed and are currently available for Persian (Rasooli et al., 2013; Seraji, 2015).", "startOffset": 81, "endOffset": 117}], "year": 2016, "abstractText": "In this paper we explore the problem of document summarization in Persian language from two distinct angles. In our first approach, we modify a popular and widely cited Persian document summarization framework to see how it works on a realistic corpus of news articles. Human evaluation on generated summaries shows that graph-based methods perform better than the modified systems. We carry this intuition forward in our second approach, and probe deeper into the nature of graph-based systems by designing several summarizers based on centrality measures. Ad hoc evaluation using ROUGE score on these summarizers suggests that there is a small class of centrality measures that perform better than three strong unsupervised baselines.", "creator": "Microsoft\u00ae Word 2016"}}}