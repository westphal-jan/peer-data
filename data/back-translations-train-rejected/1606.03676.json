{"id": "1606.03676", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Jun-2016", "title": "External Lexical Information for Multilingual Part-of-Speech Tagging", "abstract": "Morphosyntactic lexicons and word vector representations have both proven useful for improving the accuracy of statistical part-of-speech taggers. Here we compare the performances of four systems on datasets covering 16 languages, two of these systems being feature-based (MEMMs and CRFs) and two of them being neural-based (bi-LSTMs). We show that, on average, all four approaches perform similarly and reach state-of-the-art results. Yet better performances are obtained with our feature-based models on lexically richer datasets (e.g. for morphologically rich languages), whereas neural-based results are higher on datasets with less lexical variability (e.g. for English). These conclusions hold in particular for the MEMM models relying on our system MElt, which benefited from newly designed features. This shows that, under certain conditions, feature-based approaches enriched with morphosyntactic lexicons are competitive with respect to neural methods.", "histories": [["v1", "Sun, 12 Jun 2016 08:06:55 GMT  (723kb,D)", "https://arxiv.org/abs/1606.03676v1", null], ["v2", "Tue, 9 Aug 2016 08:41:46 GMT  (723kb,D)", "http://arxiv.org/abs/1606.03676v2", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["beno\\^it sagot"], "accepted": false, "id": "1606.03676"}, "pdf": {"name": "1606.03676.pdf", "metadata": {"source": "CRF", "title": "External Lexical Information for Multilingual Part-of-Speech Tagging", "authors": ["Beno\u00eet Sagot"], "emails": [], "sections": [{"heading": null, "text": "IS SN 0249 -639 9IS RN INR IA / R R-- 8924 --FR + EN GRESEARCH REPORT N \u00b0 8924 June 2016Project Teams ALPAGE"}, {"heading": "External Lexical", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Information for", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Multilingual", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Part-of-Speech Tagging", "text": "Beno\u00eet Sagotar Xiv: 160 6.03 676v 2 [cs.C L] 9A ug2 016RESEARCH CENTRE PARIS - ROCQUENCOURTDomaine de Voluceau, - Rocquencourt B.P. 105 - 78153 Le Chesnay CedexExternal Lexical Information for Multilingual Part-of-Speech TaggingBeno\u00eet SagotProject teams ALPAGEResearch Report n \u00b0 8924 - June 2016 - 15 pagesAbstract: Morphosyntactic lexicons and word vector representations have both been used for improving the accuracy of statistical part-of speech taggers."}, {"heading": "External Lexical Information for Multilingual Part-of-Speech Tagging 3", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "1 Introduction", "text": "This year, it is only a matter of time before an agreement is reached."}, {"heading": "4 Sagot", "text": "Specifically, our starting point is the MElt system (Denis and Sagot, 2012), a MEMM tagging system. We first briefly describe this system and the way we have adapted it by integrating our own set of corpus-based and lexical features, and then introduce the tagging models we have trained for 16 different languages using our customized version of MElt. These models are trained using the Universal Dependencies (v1.2) of the corpus (Nivre and al., 2015), supplemented by morphosyntactic lexics. we compare the accuracy of our models with the values of the CRF-based system MarMoT (M\u00fcller et al., 2013; M\u00fcller und Sch\u00fctze, 2015), which have been retrained on the same corpus (Nivre and al., 2015), and the same external morphosyntactic lexics. We also compare our results with those of the best bidirectional LSTM models described by Plank et (2016), which have high morphosphological vectors (both)."}, {"heading": "2 MElt", "text": "In fact, most of the people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to play, to dance, to dance, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to play, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move"}, {"heading": "External Lexical Information for Multilingual Part-of-Speech Tagging 5", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Local standard features", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Contextual standard features", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Local lexical features", "text": "RR n \u00b0 8924"}, {"heading": "6 Sagot", "text": "Despite some experiments published with MElt in languages other than French (Denis and Sagot, 2012; Le Roux et al., 2012; Seddah et al., 2013a), the original set of features used by MElt (standard and lexical features) was largely designed and tested in that language, building and evaluating marker models based on a variant of the French TreeBank. Since our goal was to conduct experiments in a multilingual environment, we decided to design our own sets of features, using the standard MElt features as a starting point. With respect to the original MElt feature set, we added new ones, such as prefixes and suffixes of the following word, as well as a hybrid contextual feature provided for the following sentence by concatenating the tag (s) provided for the preceding word and the tag (s) provided by the external lexicon."}, {"heading": "3 Datasets", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Corpora", "text": "We conducted our experiments at the Universal Dependencies v1.2 Treebanks (Nivre et al., 2015), hereinafter UD1.2, from which morphosyntactically commented corpora can be extracted trivially. All UD1.2 corpora use a common tag set, the 17 universal PoS tags, 3, which is an extension of the tagset proposed by Petrov et al. (2012). 2During these tuning experiments, we used development sets to compare feature sets without using any of our models on Testsets.3http: / / universaldependencies.org / u / pos / all.htmlInria"}, {"heading": "External Lexical Information for Multilingual Part-of-Speech Tagging 7", "text": "Since our goal is to study the effects of lexical information on POS marking, we have limited our experiments to UD1.2 corpora, which cover languages for which we have morphosyntactic lexicographies and for which Plank et al. (2016) delivers results. 4 We looked at UD1.2 corpora for the following 16 languages: Bulgarian, Croatian, Czech, Danish, English, French, German, Indonesian, Italian, Norwegian, Persian, Polish, Portuguese, Slovenian, Spanish, and Swedish. Although this language list contains only one non-Indo-European (Indonesian) language, four large Indo-European subfamilies are represented (Germanic, Romansh, Slavic, Indo-Iranian). Overall, the 16 languages included in our experiments are quite diverse in typological, morphological, and syntactical terms."}, {"heading": "3.2 Lexicons", "text": "Since external lexical information about features is evaluated, there is no need for external lexicographs and commented corporations to use the same PoS inventory. Therefore, for each language, we simply extracted the PoS of each word from the corresponding lexicon based on its morphological tags, removing all information provided except its coarsest category.5 We also added entries for punctuations when the source lexicographs did not contain any. We also conducted experiments in which we retained the complete original tags provided by the lexicographs, including all morphological characteristics. On average, the results were slightly better than those presented in the essay, though not statistically significant. Furthermore, the granularity of the tag inventories in the lexicographs is varied, making it difficult to draw general conclusions about results based on complete tags. For this reason, we only report results based on (coated) items extracted from the original."}, {"heading": "4 Experiments and results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Baseline models", "text": "To evaluate the respective contributions of external lexicographs and word vector representations, we first compared the results of the three systems mentioned above when trained without such additional lexical information. Table 3 provides the results of MElt and MarMoT, which were retrained to UD1.2 corpora, together with the results published on the same corpora by Plank et al. (2016), using their best model, which was not improved by external word vector representations - i.e. the model they call ~ w + ~ c, a bi-directional LSTM that combines both word and character embeddings. These results show that Plank et al. (2016) bi-LSTM performs extremely well in only 3 of 16 datasets (Czech, French and Italian), surpassed by MarMoT and MElt only once (Indonesian)."}, {"heading": "4.2 Models enriched with external lexical information", "text": "Table 4 provides the results of four systems enriched with lexical information: The feature-based systems MElt and MarMoT, which are based on MEMMs and CRFs respectively, are supplemented by the lexical information provided by our morphosyntactic lexicographs, which is supplemented in the form of additional features, as described in Section 2 for MElt. Plank et al.4You have discarded all corpora with less than 60k tokens in the training set, possibly due to the sensitivity of the LSMTs to the size of the training set. 5For French, however, we have used the morphosyntactic variant of the lefff, which is included in the MElt distribution and which is based on a variant of the French TreeBank called FTB-UC (Candito and Crabb\u00e9, 2009).RR n \u00b0 8924"}, {"heading": "8 Sagot", "text": "The results of this study show that the representation for the frequency that the model shows does not depend on the common and rare words, but on the handling of the rare tokens. The results, which are also included in the numbers, show that all systems achieve very similar results, although discrepancies between the common and rare words can be observed."}, {"heading": "External Lexical Information for Multilingual Part-of-Speech Tagging 9", "text": "RR n \u00b0 892410 SagotInria"}, {"heading": "External Lexical Information for Multilingual Part-of-Speech Tagging 11", "text": "All words in a morphosyntactic lexicon are associated with information of equal granularity and quality, which is not the case with word representations such as polyglot. To confirm this intuition, we used a lexical wealth metric based on the type-token ratio. As this ratio is known for its sensitivity to body length, we normalized it by calculating it over the 60,000 first tokens of each training set. If this normalized type-token ratio is plotted against the difference between the results of MElt and the two Bi-LSTM-based models, the expected correlation is clearly visible (see Figure 3). This explains why MElt achieves better results on the morphologically very rich basis of STIN / Token - 0.25% compared to the average difference between MElt and normal BSTM type + 0.28% compared to normal BASKM type + 0.15 (see Figure 3)."}, {"heading": "5 Conclusion", "text": "Two conclusions can be drawn from our comparative results: First, function-based marker models appropriately enriched with external morphosyntactic lexicon show better performance on average, and word-enriched bi-LSTMs. Results per language show that the best accuracy levels are achieved with function-based models, and in particular with our improved version of the MEMM-based system MElt, on data sets with high lexical variability (in short, for morphologically rich languages), whereas neural results perform better with data sets with lower lexical variability (e.g. for English). We have only compared the contribution of morphosyntactic lexicon to function-based models (MEMMs, CRFs) and those of word vector representations with bi-LSTM-based models as reported by Plank et al (2016)."}, {"heading": "Contents", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "1 Introduction 3", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2 MElt 4", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3 Datasets 6", "text": ".........................................................................................................................."}, {"heading": "12 Sagot", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4 Experiments and results 7", "text": "4.1 Basic models............................................. 7 4.2 Models enriched with external lexical information................"}, {"heading": "5 Conclusion 11", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "External Lexical Information for Multilingual Part-of-Speech Tagging 13", "text": "Erjavec, T. (2010). Multext-east version 4: Multilingual morphosyntactic specifications, lexicons and corpora. In Proc. of LREC 2010, Valletta, Malta.Goldberg, Y., Tsarfaty, R., M., and Elhadad, M. (2009). Enhancing unlexicalized parsing performance using a wide coverage lexicon, fuzzy tag-set mapping, and em-hmm-based lexical probabilities. In Proc. of the 12th Conf. of the European Chapter of the ACL, pp. 327-335.Hagen, K. and N\u00f8klestad, A. (2010). Bruk av et norsk leksikon til tagging og andre spr\u00e5kteknologiske form\u00e5l. Lexicog. LexicoNordica, 17: 55-72. Haji\u010d, J. (2000)."}, {"heading": "14 Sagot", "text": "In Proc. of the 2013 Conf. on Empirical Methods in Natural Language Processing, pages 322-332, Seattle, Washington, USA.M\u00fcller, T. and Sch\u00fctze, H. (2015). Robust morphological tagging with word representations. In Proc. of the 2015 Conf. of the North American Chapter of the ACL: Human Language Technologies, Denver, Colorado, USA.Nivre, J. and Sch\u00fctze, H. and Sch\u00fctze, (2015). Universal dependencies 1.2. LINDAT / CLARIN digital library at the Formal and Applied Linguistics, Charles University in Prague.Oliver, A. and Tadi\u0107, M. (2004). Enlarging the Croatian morphological lexicon by automatic lexicon from raw corpora. In Proc. of LREC 2004, pages 1259-1262."}, {"heading": "External Lexical Information for Multilingual Part-of-Speech Tagging 15", "text": "Toutanova, K. and Manning, C. D. (2000). Enrichment of knowledge sources used in a maximum entropy part of the language. In Proc. of International Conf. on New Methods in Language Processing, pp. 63-70, Hong Kong, China.Zanchetta, E. and Baroni, M. (2005). Morph-it! a free corpus-based morphological resource for the Italian language. In Proc of the Corpus linguistics Conf., pp. 1-12, Birmingham, UK.RR n \u00b0 8924RESEARCH CENTRE PARIS - ROCQUENCOURTDomaine de Voluceau, - Rocquencourt B.P. 105 - 78153 Le Chesnay CedexPublisher Inria Domaine de Voluceau - Rocquencourt BP 105 - 78153 Le Chesnay Cedex inria.frISSN 0249-699"}], "references": [{"title": "Polyglot: Distributed word representations for multilingual nlp", "author": ["R. Al-Rfou", "B. Perozzi", "S. Skiena"], "venue": "Proc. of the Seventeenth Conf. on Computational Natural Language Learning, pages 183\u2013192, Sofia, Bulgaria.", "citeRegEx": "Al.Rfou et al\\.,? 2013", "shortCiteRegEx": "Al.Rfou et al\\.", "year": 2013}, {"title": "Improved Transition-based Parsing by Modeling Characters instead of Words with LSTMs", "author": ["M. Ballesteros", "C. Dyer", "N.A. Smith"], "venue": "Proc. of the 2015 Conf. on Empirical Methods in Natural Language Processing, pages 349\u2013359, Lisbon, Portugal.", "citeRegEx": "Ballesteros et al\\.,? 2015", "shortCiteRegEx": "Ballesteros et al\\.", "year": 2015}, {"title": "A neural probabilistic language model", "author": ["Y. Bengio", "R. Ducharme", "P. Vincent", "C. Janvin"], "venue": "J. Mach. Learn. Res., 3(1):1137\u20131155.", "citeRegEx": "Bengio et al\\.,? 2003", "shortCiteRegEx": "Bengio et al\\.", "year": 2003}, {"title": "The hunting of the BLARK - SALDO, a freely available lexical database for swedish language technology", "author": ["L. Borin", "M. Forsberg", "L. L\u00f6nngren"], "venue": "Resourceful language technology. Festschrift in honor of Anna S\u00e5gvall Hein, pages 21\u201332. Uppsala University, Uppsala, Sweden.", "citeRegEx": "Borin et al\\.,? 2008", "shortCiteRegEx": "Borin et al\\.", "year": 2008}, {"title": "Danish monolingual lexicon, documentation", "author": ["A. Braasch", "C. Navarretta", "S. Olsen", "B.S. Pedersen"], "venue": null, "citeRegEx": "Braasch et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Braasch et al\\.", "year": 2008}, {"title": "Estimating markov model structures", "author": ["T. Brants"], "venue": "Proc. of the 4th Conf. on Spoken Language Processing (ICSLP-96), pages 893\u2013896.", "citeRegEx": "Brants,? 1996", "shortCiteRegEx": "Brants", "year": 1996}, {"title": "TnT: A Statistical Part-of-speech Tagger", "author": ["T. Brants"], "venue": "Proc. of the Sixth Conf. on Applied Natural Language Processing, pages 224\u2013231, Seattle, Washington, USA.", "citeRegEx": "Brants,? 2000", "shortCiteRegEx": "Brants", "year": 2000}, {"title": "Improving generative statistical parsing with semi-supervised word clustering", "author": ["M. Candito", "B. Crabb\u00e9"], "venue": "Proc. of the 11th International Conf. on Parsing Technologies, pages 138\u2013 141, Paris, France.", "citeRegEx": "Candito and Crabb\u00e9,? 2009", "shortCiteRegEx": "Candito and Crabb\u00e9", "year": 2009}, {"title": "Text segmentation with character-level text embeddings", "author": ["G. Chrupa\u0142a"], "venue": "Proc. of the ICML Workshop on Deep Learning for Audio, Speech and Lang. Processing, Atlanta, Georgia, USA.", "citeRegEx": "Chrupa\u0142a,? 2013", "shortCiteRegEx": "Chrupa\u0142a", "year": 2013}, {"title": "Learning morphology with morfette", "author": ["G. Chrupa\u0142a", "G. Dinu", "J. van Genabith"], "venue": "In Proc. of the 6th Language Resource and Evaluation Conf.,", "citeRegEx": "Chrupa\u0142a et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Chrupa\u0142a et al\\.", "year": 2008}, {"title": "A unified architecture for natural language processing: Deep neural networks with multitask learning", "author": ["R. Collobert", "J. Weston"], "venue": "Proc. of the 25th International Conf. on Machine Learning, pages 160\u2013167, Helsinki, Finland.", "citeRegEx": "Collobert and Weston,? 2008", "shortCiteRegEx": "Collobert and Weston", "year": 2008}, {"title": "Evaluating the Impact of External Lexical Resources into a CRF-based Multiword Segmenter and Part-of-Speech Tagger", "author": ["M. Constant", "I. Tellier"], "venue": "Proc. of LREC\u201912, pages 646\u2013650, Istanbul, Turkey.", "citeRegEx": "Constant and Tellier,? 2012", "shortCiteRegEx": "Constant and Tellier", "year": 2012}, {"title": "Coupling an annotated corpus and a lexicon for state-of-the-art POS tagging", "author": ["P. Denis", "B. Sagot"], "venue": "Language Resources and Evaluation, 46(4):721\u2013736.", "citeRegEx": "Denis and Sagot,? 2012", "shortCiteRegEx": "Denis and Sagot", "year": 2012}, {"title": "Multext-east version 4: Multilingual morphosyntactic specifications, lexicons and corpora", "author": ["T. Erjavec"], "venue": "Proc. of LREC 2010, Valletta, Malta.", "citeRegEx": "Erjavec,? 2010", "shortCiteRegEx": "Erjavec", "year": 2010}, {"title": "Enhancing unlexicalized parsing performance using a wide coverage lexicon, fuzzy tag-set mapping, and em-hmm-based lexical probabilities", "author": ["Y. Goldberg", "R. Tsarfaty", "M. Adler", "M. Elhadad"], "venue": "Proc. of the 12th Conf. of the European Chapter of the ACL, pages 327\u2013335.", "citeRegEx": "Goldberg et al\\.,? 2009", "shortCiteRegEx": "Goldberg et al\\.", "year": 2009}, {"title": "Bruk av et norsk leksikon til tagging og andre spr\u00e5kteknologiske form\u00e5l", "author": ["K. Hagen", "A. N\u00f8klestad"], "venue": "LexicoNordica, 17:55\u201372.", "citeRegEx": "Hagen and N\u00f8klestad,? 2010", "shortCiteRegEx": "Hagen and N\u00f8klestad", "year": 2010}, {"title": "Morphological Tagging: Data vs", "author": ["J. Haji\u010d"], "venue": "Dictionaries. In Proc. of ANLP\u201900, pages 94\u2013101, Seattle, Washington, USA.", "citeRegEx": "Haji\u010d,? 2000", "shortCiteRegEx": "Haji\u010d", "year": 2000}, {"title": "MorfFlex CZ", "author": ["J. Haji\u010d", "J. Hlav\u00e1\u010dov\u00e1"], "venue": "LINDAT/CLARIN digital library at Institute of Formal and Applied Linguistics, Charles University in Prague.", "citeRegEx": "Haji\u010d and Hlav\u00e1\u010dov\u00e1,? 2013", "shortCiteRegEx": "Haji\u010d and Hlav\u00e1\u010dov\u00e1", "year": 2013}, {"title": "Long short-term memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neur. Comp., 9(8):1735\u2013 1780.", "citeRegEx": "Hochreiter and Schmidhuber,? 1997", "shortCiteRegEx": "Hochreiter and Schmidhuber", "year": 1997}, {"title": "HMM Specialization with Selective Lexicalization", "author": ["Kim", "J.-D.", "Lee", "S.-Z.", "Rim", "H.-C."], "venue": "Proc. of the join SIGDAT Conf. on Empirical Methods in Natural Lang. Processing and Very Large Corpora.", "citeRegEx": "Kim et al\\.,? 1999", "shortCiteRegEx": "Kim et al\\.", "year": 1999}, {"title": "Specifikacije za leksikon besednih oblik (kazalnik 3)", "author": ["S. Krek", "T. Erjavec", "P. Holozan"], "venue": "Technical report, Projekt Sporazumevanje v slovenskem jeziku, Ljubljana, Slovenia.", "citeRegEx": "Krek et al\\.,? 2008", "shortCiteRegEx": "Krek et al\\.", "year": 2008}, {"title": "Adding context information to part of speech tagging for dialogues", "author": ["S. K\u00fcbler", "M. Scheutz", "E. Baucom", "R. Israel"], "venue": "Proc. of the Ninth International Workshop on Treebanks and Linguistic Theories (TLT), pages 115\u2013126.", "citeRegEx": "K\u00fcbler et al\\.,? 2010", "shortCiteRegEx": "K\u00fcbler et al\\.", "year": 2010}, {"title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data", "author": ["J.D. Lafferty", "A. McCallum", "F.C.N. Pereira"], "venue": "ICML, pages 282\u2013289.", "citeRegEx": "Lafferty et al\\.,? 2001", "shortCiteRegEx": "Lafferty et al\\.", "year": 2001}, {"title": "Neural architectures for named entity recognition", "author": ["G. Lample", "M. Ballesteros", "K. Kawakami", "S. Subramanian", "C. Dyer"], "venue": "Proc. of NAACL-HLT (NAACL 2016), San Diego, California, USA.", "citeRegEx": "Lample et al\\.,? 2016", "shortCiteRegEx": "Lample et al\\.", "year": 2016}, {"title": "Statistical parsing of spanish and data driven lemmatization", "author": ["J. Le Roux", "B. Sagot", "D. Seddah"], "venue": "Proc. of the ACL 2012 Joint Workshop on Statistical Parsing and Semantic Processing of Morphologically Rich Languages (SP-Sem-MRL 2012), Jeju, Korea.", "citeRegEx": "Roux et al\\.,? 2012", "shortCiteRegEx": "Roux et al\\.", "year": 2012}, {"title": "Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation", "author": ["W. Ling", "T. Lu\u00eds", "L. Marujo", "R.F. Astudillo", "S. Amir", "C. Dyer", "A.W. Black", "I. Trancoso"], "venue": "Proc. of the 2015 Conf. on Empirical Methods in Natural Lang. Processing, pages 1520\u20131530, Lisbon, Portugal.", "citeRegEx": "Ling et al\\.,? 2015", "shortCiteRegEx": "Ling et al\\.", "year": 2015}, {"title": "Statistical decision-tree models for parsing", "author": ["D.M. Magerman"], "venue": "Proc. of the 33rd Annual Meeting on ACL, pages 276\u2013283, Cambridge, Mass., USA.", "citeRegEx": "Magerman,? 1995", "shortCiteRegEx": "Magerman", "year": 1995}, {"title": "Tagging english text with a probabilistic model", "author": ["B. Merialdo"], "venue": "Computational Linguistics, 20(2):155\u2013171.", "citeRegEx": "Merialdo,? 1994", "shortCiteRegEx": "Merialdo", "year": 1994}, {"title": "A morphological and syntactic wide-coverage lexicon for Spanish: The Leff e", "author": ["M.A. Molinero", "B. Sagot", "L. Nicolas"], "venue": "Proc. of the 7th conference on Recent Advances in Natural Language Processing (RANLP 2009), Borovets, Bulgaria.", "citeRegEx": "Molinero et al\\.,? 2009", "shortCiteRegEx": "Molinero et al\\.", "year": 2009}, {"title": "Efficient higher-order CRFs for morphological tagging", "author": ["T. M\u00fcller", "H. Schmid", "H. Sch\u00fctze"], "venue": "Proc. of the 2013 Conf. on Empirical Methods in Natural Language Processing, pages 322\u2013332, Seattle, Washington, USA.", "citeRegEx": "M\u00fcller et al\\.,? 2013", "shortCiteRegEx": "M\u00fcller et al\\.", "year": 2013}, {"title": "Robust morphological tagging with word representations", "author": ["T. M\u00fcller", "H. Sch\u00fctze"], "venue": "Proc. of the 2015 Conf. of the North American Chapter of the ACL: Human Language Technologies, Denver, Colorado, USA.", "citeRegEx": "M\u00fcller and Sch\u00fctze,? 2015", "shortCiteRegEx": "M\u00fcller and Sch\u00fctze", "year": 2015}, {"title": "Universal dependencies 1.2. LINDAT/CLARIN digital library at Institute of Formal and Applied Linguistics, Charles University in Prague", "author": ["J. Nivre", "al"], "venue": null, "citeRegEx": "Nivre and al.,? \\Q2015\\E", "shortCiteRegEx": "Nivre and al.", "year": 2015}, {"title": "Enlarging the Croatian morphological lexicon by automatic lexical acquisition from raw corpora", "author": ["A. Oliver", "M. Tadi\u0107"], "venue": "Proc. of LREC 2004, pages 1259\u20131262, Lisbon, Portugal.", "citeRegEx": "Oliver and Tadi\u0107,? 2004", "shortCiteRegEx": "Oliver and Tadi\u0107", "year": 2004}, {"title": "A universal part-of-speech tagset", "author": ["S. Petrov", "D. Das", "R. McDonald"], "venue": "Proc. of LREC 2012, Istanbul, Turkey.", "citeRegEx": "Petrov et al\\.,? 2012", "shortCiteRegEx": "Petrov et al\\.", "year": 2012}, {"title": "Multilingual Part-of-Speech Tagging with Bidirectional Long Short-Term Memory Models and Auxiliary Loss", "author": ["B. Plank", "A. S\u00f8gaard", "Y. Goldberg"], "venue": "Proc. of the 54th Annual Meeting of the ACL, Berlin, Germany. To appear.", "citeRegEx": "Plank et al\\.,? 2016", "shortCiteRegEx": "Plank et al\\.", "year": 2016}, {"title": "A Computational Lexicon of Portuguese for Automatic Text Parsing", "author": ["E. Ranchhod", "C. Mota", "J. Baptista"], "venue": "Proc. of the SIGLEX99 workshop on Standardizing Lexical Resources, College Park, Maryland, USA.", "citeRegEx": "Ranchhod et al\\.,? 1999", "shortCiteRegEx": "Ranchhod et al\\.", "year": 1999}, {"title": "A maximum entropy model for part-of-speech tagging", "author": ["A. Ratnaparkhi"], "venue": "Proc. of International Conf. on Empirical Methods in Natural Language Processing, pages 133\u2013142.", "citeRegEx": "Ratnaparkhi,? 1996", "shortCiteRegEx": "Ratnaparkhi", "year": 1996}, {"title": "Building a morphosyntactic lexicon and a pre-syntactic processing chain for Polish", "author": ["B. Sagot"], "venue": "Proc. of LTC 2005, pages 423\u2013427, Pozna\u0144, Poland.", "citeRegEx": "Sagot,? 2007", "shortCiteRegEx": "Sagot", "year": 2007}, {"title": "The Lefff , a freely available, accurate and large-coverage lexicon for french", "author": ["B. Sagot"], "venue": "Proc. of LREC 2010, Valletta, Malta.", "citeRegEx": "Sagot,? 2010", "shortCiteRegEx": "Sagot", "year": 2010}, {"title": "DeLex, a freely-avaible, large-scale and linguistically grounded morphological lexicon for German", "author": ["B. Sagot"], "venue": "Language Resources and Evaluation Conf., Reykjavik, Iceland.", "citeRegEx": "Sagot,? 2014", "shortCiteRegEx": "Sagot", "year": 2014}, {"title": "A morphological lexicon for the Persian language", "author": ["B. Sagot", "G. Walther"], "venue": "Proc. of LREC 2010, Valletta, Malta.", "citeRegEx": "Sagot and Walther,? 2010", "shortCiteRegEx": "Sagot and Walther", "year": 2010}, {"title": "Probabilistic part-of-speech tagging using decision trees", "author": ["H. Schmid"], "venue": "Proc. of International Conf. on New Methods in Language Processing, Manchester, UK.", "citeRegEx": "Schmid,? 1994", "shortCiteRegEx": "Schmid", "year": 1994}, {"title": "Data driven lemmatization and parsing of italian", "author": ["D. Seddah", "J. Le Roux", "B. Sagot"], "venue": "Magnini, B., Cutugno, F., Falcone, M., and Pianta, E., editors, Evaluation of Natural Language and Speech Tools for Italian (Revised Selected Papers), volume 7689 of Lecture Notes in Computer Science, pages 249\u2013256. Springer-Verlag, Rome, Italy.", "citeRegEx": "Seddah et al\\.,? 2013a", "shortCiteRegEx": "Seddah et al\\.", "year": 2013}, {"title": "Overview of the SPMRL 2013 shared task: A cross-framework evaluation of parsing morphologically rich languages", "author": ["D. Seddah", "R. Tsarfaty", "S. K\u00fcbler", "M. Candito", "J.D. Choi", "R. Farkas", "J. Foster", "I. Goenaga", "K. Gojenola Galletebeitia", "Y. Goldberg", "S. Green", "N. Habash", "M. Kuhlmann", "W. Maier", "J. Nivre", "A. Przepi\u00f3rkowski", "R. Roth", "W. Seeker", "Y. Versley", "V. Vincze", "M. Woli\u0144ski", "A. Wr\u00f3blewska", "E. Villemonte de La Clergerie"], "venue": "In", "citeRegEx": "Seddah et al\\.,? 2013b", "shortCiteRegEx": "Seddah et al\\.", "year": 2013}, {"title": "Enriching the knowledge sources used in a maximum entropy part-of-speech tagger", "author": ["K. Toutanova", "C.D. Manning"], "venue": "Proc. of International Conf. on New Methods in Language Processing, pages 63\u201370, Hong Kong, China.", "citeRegEx": "Toutanova and Manning,? 2000", "shortCiteRegEx": "Toutanova and Manning", "year": 2000}, {"title": "Morph-it! a free corpus-based morphological resource for the Italian language", "author": ["E. Zanchetta", "M. Baroni"], "venue": "Proc. of the Corpus linguistics Conf., pages 1\u201312, Birmingham, UK.", "citeRegEx": "Zanchetta and Baroni,? 2005", "shortCiteRegEx": "Zanchetta and Baroni", "year": 2005}], "referenceMentions": [{"referenceID": 27, "context": "A large variety of algorithms have been used, such as (in approximative chronological order) bigram and trigram hidden Markov models (Merialdo, 1994; Brants, 1996, 2000), decision trees (Schmid, 1994; Magerman, 1995), maximum entropy Markov models (MEMMs) (Ratnaparkhi, 1996) and Conditional Random Fields (CRFs) (Lafferty et al.", "startOffset": 133, "endOffset": 169}, {"referenceID": 41, "context": "A large variety of algorithms have been used, such as (in approximative chronological order) bigram and trigram hidden Markov models (Merialdo, 1994; Brants, 1996, 2000), decision trees (Schmid, 1994; Magerman, 1995), maximum entropy Markov models (MEMMs) (Ratnaparkhi, 1996) and Conditional Random Fields (CRFs) (Lafferty et al.", "startOffset": 186, "endOffset": 216}, {"referenceID": 26, "context": "A large variety of algorithms have been used, such as (in approximative chronological order) bigram and trigram hidden Markov models (Merialdo, 1994; Brants, 1996, 2000), decision trees (Schmid, 1994; Magerman, 1995), maximum entropy Markov models (MEMMs) (Ratnaparkhi, 1996) and Conditional Random Fields (CRFs) (Lafferty et al.", "startOffset": 186, "endOffset": 216}, {"referenceID": 36, "context": "A large variety of algorithms have been used, such as (in approximative chronological order) bigram and trigram hidden Markov models (Merialdo, 1994; Brants, 1996, 2000), decision trees (Schmid, 1994; Magerman, 1995), maximum entropy Markov models (MEMMs) (Ratnaparkhi, 1996) and Conditional Random Fields (CRFs) (Lafferty et al.", "startOffset": 256, "endOffset": 275}, {"referenceID": 22, "context": "A large variety of algorithms have been used, such as (in approximative chronological order) bigram and trigram hidden Markov models (Merialdo, 1994; Brants, 1996, 2000), decision trees (Schmid, 1994; Magerman, 1995), maximum entropy Markov models (MEMMs) (Ratnaparkhi, 1996) and Conditional Random Fields (CRFs) (Lafferty et al., 2001; Constant and Tellier, 2012).", "startOffset": 313, "endOffset": 364}, {"referenceID": 11, "context": "A large variety of algorithms have been used, such as (in approximative chronological order) bigram and trigram hidden Markov models (Merialdo, 1994; Brants, 1996, 2000), decision trees (Schmid, 1994; Magerman, 1995), maximum entropy Markov models (MEMMs) (Ratnaparkhi, 1996) and Conditional Random Fields (CRFs) (Lafferty et al., 2001; Constant and Tellier, 2012).", "startOffset": 313, "endOffset": 364}, {"referenceID": 19, "context": "Such lexical information can be used in the form of constraints at tagging time (Kim et al., 1999; Haji\u010d, 2000) or during the training process as additional features combined with standard features extracted from the training corpus (Chrupa\u0142a et al.", "startOffset": 80, "endOffset": 111}, {"referenceID": 16, "context": "Such lexical information can be used in the form of constraints at tagging time (Kim et al., 1999; Haji\u010d, 2000) or during the training process as additional features combined with standard features extracted from the training corpus (Chrupa\u0142a et al.", "startOffset": 80, "endOffset": 111}, {"referenceID": 9, "context": ", 1999; Haji\u010d, 2000) or during the training process as additional features combined with standard features extracted from the training corpus (Chrupa\u0142a et al., 2008; Goldberg et al., 2009; Denis and Sagot, 2012).", "startOffset": 142, "endOffset": 211}, {"referenceID": 14, "context": ", 1999; Haji\u010d, 2000) or during the training process as additional features combined with standard features extracted from the training corpus (Chrupa\u0142a et al., 2008; Goldberg et al., 2009; Denis and Sagot, 2012).", "startOffset": 142, "endOffset": 211}, {"referenceID": 12, "context": ", 1999; Haji\u010d, 2000) or during the training process as additional features combined with standard features extracted from the training corpus (Chrupa\u0142a et al., 2008; Goldberg et al., 2009; Denis and Sagot, 2012).", "startOffset": 142, "endOffset": 211}, {"referenceID": 2, "context": "In recent years, a different approach to modelling lexical information and integrating it into natural language processing systems has emerged, namely the use of vector representations for words or word sequences (Bengio et al., 2003; Collobert and Weston, 2008; Chrupa\u0142a, 2013; Ling et al., 2015; Ballesteros et al., 2015; M\u00fcller and Sch\u00fctze, 2015).", "startOffset": 213, "endOffset": 349}, {"referenceID": 10, "context": "In recent years, a different approach to modelling lexical information and integrating it into natural language processing systems has emerged, namely the use of vector representations for words or word sequences (Bengio et al., 2003; Collobert and Weston, 2008; Chrupa\u0142a, 2013; Ling et al., 2015; Ballesteros et al., 2015; M\u00fcller and Sch\u00fctze, 2015).", "startOffset": 213, "endOffset": 349}, {"referenceID": 8, "context": "In recent years, a different approach to modelling lexical information and integrating it into natural language processing systems has emerged, namely the use of vector representations for words or word sequences (Bengio et al., 2003; Collobert and Weston, 2008; Chrupa\u0142a, 2013; Ling et al., 2015; Ballesteros et al., 2015; M\u00fcller and Sch\u00fctze, 2015).", "startOffset": 213, "endOffset": 349}, {"referenceID": 25, "context": "In recent years, a different approach to modelling lexical information and integrating it into natural language processing systems has emerged, namely the use of vector representations for words or word sequences (Bengio et al., 2003; Collobert and Weston, 2008; Chrupa\u0142a, 2013; Ling et al., 2015; Ballesteros et al., 2015; M\u00fcller and Sch\u00fctze, 2015).", "startOffset": 213, "endOffset": 349}, {"referenceID": 1, "context": "In recent years, a different approach to modelling lexical information and integrating it into natural language processing systems has emerged, namely the use of vector representations for words or word sequences (Bengio et al., 2003; Collobert and Weston, 2008; Chrupa\u0142a, 2013; Ling et al., 2015; Ballesteros et al., 2015; M\u00fcller and Sch\u00fctze, 2015).", "startOffset": 213, "endOffset": 349}, {"referenceID": 30, "context": "In recent years, a different approach to modelling lexical information and integrating it into natural language processing systems has emerged, namely the use of vector representations for words or word sequences (Bengio et al., 2003; Collobert and Weston, 2008; Chrupa\u0142a, 2013; Ling et al., 2015; Ballesteros et al., 2015; M\u00fcller and Sch\u00fctze, 2015).", "startOffset": 213, "endOffset": 349}, {"referenceID": 18, "context": "Such representations, which are generally extracted from large amounts of raw text, have proved very useful for numerous tasks including PoS tagging, in particular when used in recurrent neural networks (RNNs) and more specifically in mono- or bi-directional, word-level and/or character-level long short-term memory networks (LSTMs) (Hochreiter and Schmidhuber, 1997; Ling et al., 2015; Ballesteros et al., 2015; Plank et al., 2016).", "startOffset": 334, "endOffset": 433}, {"referenceID": 25, "context": "Such representations, which are generally extracted from large amounts of raw text, have proved very useful for numerous tasks including PoS tagging, in particular when used in recurrent neural networks (RNNs) and more specifically in mono- or bi-directional, word-level and/or character-level long short-term memory networks (LSTMs) (Hochreiter and Schmidhuber, 1997; Ling et al., 2015; Ballesteros et al., 2015; Plank et al., 2016).", "startOffset": 334, "endOffset": 433}, {"referenceID": 1, "context": "Such representations, which are generally extracted from large amounts of raw text, have proved very useful for numerous tasks including PoS tagging, in particular when used in recurrent neural networks (RNNs) and more specifically in mono- or bi-directional, word-level and/or character-level long short-term memory networks (LSTMs) (Hochreiter and Schmidhuber, 1997; Ling et al., 2015; Ballesteros et al., 2015; Plank et al., 2016).", "startOffset": 334, "endOffset": 433}, {"referenceID": 34, "context": "Such representations, which are generally extracted from large amounts of raw text, have proved very useful for numerous tasks including PoS tagging, in particular when used in recurrent neural networks (RNNs) and more specifically in mono- or bi-directional, word-level and/or character-level long short-term memory networks (LSTMs) (Hochreiter and Schmidhuber, 1997; Ling et al., 2015; Ballesteros et al., 2015; Plank et al., 2016).", "startOffset": 334, "endOffset": 433}, {"referenceID": 1, "context": ", 2015; Ballesteros et al., 2015; M\u00fcller and Sch\u00fctze, 2015). Such representations, which are generally extracted from large amounts of raw text, have proved very useful for numerous tasks including PoS tagging, in particular when used in recurrent neural networks (RNNs) and more specifically in mono- or bi-directional, word-level and/or character-level long short-term memory networks (LSTMs) (Hochreiter and Schmidhuber, 1997; Ling et al., 2015; Ballesteros et al., 2015; Plank et al., 2016). Both approaches to representing lexical properties and to integrating them into a PoS tagger improve tagging results. Yet they rely on resources of different natures. The main advantage of word vectors is that they are built in an unsupervised way, only requiring large amounts of raw textual data. They also encode finer-grained information than usual morphosyntactic lexicons, most of which do not include any quantitative data, not even simple frequency information. Conversely, lexical resources often provide information about scarcely attested words, for which corpus-based approaches such as word vector representations are of limited relevance. Moreover, morphological or morphosyntactic lexicons already exist for a number of languages, including less-resourced langauges for which it might be difficult to obtain the large amounts of raw data necessary to extract word vector representations. Our main goal is therefore to compare the respective impact of external lexicons and word vector representations on the accuracy of PoS models. This question has already been investigated for 6 languages by M\u00fcller and Sch\u00fctze (2015) using the state-of-the-art CRF-based tagging system MarMoT.", "startOffset": 8, "endOffset": 1632}, {"referenceID": 12, "context": "More specifically, our starting point is the MElt system (Denis and Sagot, 2012), an MEMM tagging system.", "startOffset": 57, "endOffset": 80}, {"referenceID": 31, "context": "2) corpus set (Nivre and al., 2015), complemented by morphosyntactic lexicons.", "startOffset": 14, "endOffset": 35}, {"referenceID": 29, "context": "We compare the accuracy of our models with the scores obtained by the CRF-based system MarMoT (M\u00fcller et al., 2013; M\u00fcller and Sch\u00fctze, 2015), retrained on the same corpora and the same external morphosyntactic lexicons.", "startOffset": 94, "endOffset": 141}, {"referenceID": 30, "context": "We compare the accuracy of our models with the scores obtained by the CRF-based system MarMoT (M\u00fcller et al., 2013; M\u00fcller and Sch\u00fctze, 2015), retrained on the same corpora and the same external morphosyntactic lexicons.", "startOffset": 94, "endOffset": 141}, {"referenceID": 11, "context": "More specifically, our starting point is the MElt system (Denis and Sagot, 2012), an MEMM tagging system. We first briefly describe this system and the way we adapted it by integrating our own set of corpus-based and lexical features. We then introduce the tagging models we have trained for 16 different languages using our adapted version of MElt. These models are trained on the Universal Dependencies (v1.2) corpus set (Nivre and al., 2015), complemented by morphosyntactic lexicons. We compare the accuracy of our models with the scores obtained by the CRF-based system MarMoT (M\u00fcller et al., 2013; M\u00fcller and Sch\u00fctze, 2015), retrained on the same corpora and the same external morphosyntactic lexicons. We also compare our results to those obtained by the best bidirectional LSTM models described by Plank et al. (2016), which both make use of Polyglot word vector representations published by Al-Rfou et al.", "startOffset": 58, "endOffset": 826}, {"referenceID": 0, "context": "(2016), which both make use of Polyglot word vector representations published by Al-Rfou et al. (2013). We will show that an optimised enrichment of feature-based models with morphosyntactic lexicon results in significant accuracy gains.", "startOffset": 81, "endOffset": 103}, {"referenceID": 12, "context": "MElt (Denis and Sagot, 2012) is a tagging system based on maximum entropy Markov models (MEMM) (Ratnaparkhi, 1996), a class of discriminative models that are suitable for sequence labelling (Ratnaparkhi, 1996).", "startOffset": 5, "endOffset": 28}, {"referenceID": 36, "context": "MElt (Denis and Sagot, 2012) is a tagging system based on maximum entropy Markov models (MEMM) (Ratnaparkhi, 1996), a class of discriminative models that are suitable for sequence labelling (Ratnaparkhi, 1996).", "startOffset": 95, "endOffset": 114}, {"referenceID": 36, "context": "MElt (Denis and Sagot, 2012) is a tagging system based on maximum entropy Markov models (MEMM) (Ratnaparkhi, 1996), a class of discriminative models that are suitable for sequence labelling (Ratnaparkhi, 1996).", "startOffset": 190, "endOffset": 209}, {"referenceID": 12, "context": "The basic set of features used by MElt is given in (Denis and Sagot, 2012).", "startOffset": 51, "endOffset": 74}, {"referenceID": 12, "context": "Yet the motivation of MElt\u2019s developers was first and foremost to investigate the best way to integrate lexical information extracted from large-scale morphosyntactic lexical resources into their models, on top of the training data (Denis and Sagot, 2012).", "startOffset": 232, "endOffset": 255}, {"referenceID": 12, "context": "MElt (Denis and Sagot, 2012) is a tagging system based on maximum entropy Markov models (MEMM) (Ratnaparkhi, 1996), a class of discriminative models that are suitable for sequence labelling (Ratnaparkhi, 1996). The basic set of features used by MElt is given in (Denis and Sagot, 2012). It is a superset of the feature sets used by Ratnaparkhi (1996) and Toutanova and Manning (2000) and includes both local standard features (for example the current word itself and its prefixes and suffixes of length 1 to 4) and contextual standard features (for example the tag just assigned to the preceding word).", "startOffset": 6, "endOffset": 351}, {"referenceID": 12, "context": "MElt (Denis and Sagot, 2012) is a tagging system based on maximum entropy Markov models (MEMM) (Ratnaparkhi, 1996), a class of discriminative models that are suitable for sequence labelling (Ratnaparkhi, 1996). The basic set of features used by MElt is given in (Denis and Sagot, 2012). It is a superset of the feature sets used by Ratnaparkhi (1996) and Toutanova and Manning (2000) and includes both local standard features (for example the current word itself and its prefixes and suffixes of length 1 to 4) and contextual standard features (for example the tag just assigned to the preceding word).", "startOffset": 6, "endOffset": 384}, {"referenceID": 12, "context": "MElt (Denis and Sagot, 2012) is a tagging system based on maximum entropy Markov models (MEMM) (Ratnaparkhi, 1996), a class of discriminative models that are suitable for sequence labelling (Ratnaparkhi, 1996). The basic set of features used by MElt is given in (Denis and Sagot, 2012). It is a superset of the feature sets used by Ratnaparkhi (1996) and Toutanova and Manning (2000) and includes both local standard features (for example the current word itself and its prefixes and suffixes of length 1 to 4) and contextual standard features (for example the tag just assigned to the preceding word). In particular, with respect to Ratnaparkhi\u2019s feature set, MElt\u2019s basic feature set lifts the restriction that local standard features used to analyse the internal composition of the current word should only apply to rare words. One of the advantages of feature-based models such as MEMMs and CRFs is that complementary information can be easily added in the form of additional features. This was investigated for instance by K\u00fcbler et al. (2010), whose best-performing model for PoS tagging dialogues was obtained with a version of MElt extended with dialogue-specific features.", "startOffset": 6, "endOffset": 1049}, {"referenceID": 13, "context": "Language Source Lexicon #entries tagset size Reference Bulgarian Multext-EAST 53056 12 (Erjavec, 2010) Croatian HML 1360687 22 (Oliver and Tadi\u0107, 2004) Czech Morfflex (parts) 2094860 65 (Haji\u010d and Hlav\u00e1\u010dov\u00e1, 2013) Danish STO 566184 13 (Braasch et al.", "startOffset": 87, "endOffset": 102}, {"referenceID": 32, "context": "Language Source Lexicon #entries tagset size Reference Bulgarian Multext-EAST 53056 12 (Erjavec, 2010) Croatian HML 1360687 22 (Oliver and Tadi\u0107, 2004) Czech Morfflex (parts) 2094860 65 (Haji\u010d and Hlav\u00e1\u010dov\u00e1, 2013) Danish STO 566184 13 (Braasch et al.", "startOffset": 127, "endOffset": 151}, {"referenceID": 17, "context": "Language Source Lexicon #entries tagset size Reference Bulgarian Multext-EAST 53056 12 (Erjavec, 2010) Croatian HML 1360687 22 (Oliver and Tadi\u0107, 2004) Czech Morfflex (parts) 2094860 65 (Haji\u010d and Hlav\u00e1\u010dov\u00e1, 2013) Danish STO 566184 13 (Braasch et al.", "startOffset": 186, "endOffset": 213}, {"referenceID": 4, "context": "Language Source Lexicon #entries tagset size Reference Bulgarian Multext-EAST 53056 12 (Erjavec, 2010) Croatian HML 1360687 22 (Oliver and Tadi\u0107, 2004) Czech Morfflex (parts) 2094860 65 (Haji\u010d and Hlav\u00e1\u010dov\u00e1, 2013) Danish STO 566184 13 (Braasch et al., 2008) English EnLex 472850 22 (Sagot, 2010) French Lefff 539278 25 (Sagot, 2010) German DeLex 465434 52 (Sagot, 2014) Indonesian Kateglo 72217 118 https://github.", "startOffset": 235, "endOffset": 257}, {"referenceID": 38, "context": ", 2008) English EnLex 472850 22 (Sagot, 2010) French Lefff 539278 25 (Sagot, 2010) German DeLex 465434 52 (Sagot, 2014) Indonesian Kateglo 72217 118 https://github.", "startOffset": 32, "endOffset": 45}, {"referenceID": 38, "context": ", 2008) English EnLex 472850 22 (Sagot, 2010) French Lefff 539278 25 (Sagot, 2010) German DeLex 465434 52 (Sagot, 2014) Indonesian Kateglo 72217 118 https://github.", "startOffset": 69, "endOffset": 82}, {"referenceID": 39, "context": ", 2008) English EnLex 472850 22 (Sagot, 2010) French Lefff 539278 25 (Sagot, 2010) German DeLex 465434 52 (Sagot, 2014) Indonesian Kateglo 72217 118 https://github.", "startOffset": 106, "endOffset": 119}, {"referenceID": 45, "context": "com/ivanlanin/kateglo Italian Morph-it! 422756 31 (Zanchetta and Baroni, 2005) Norwegian OrdBank 679763 19 (Hagen and N\u00f8klestad, 2010) Persian PerLex 511840 37 (Sagot and Walther, 2010) Polish PolLex 390370 28 (Sagot, 2007) Portuguese LABEL-LEXsw 971514 29 (Ranchhod et al.", "startOffset": 50, "endOffset": 78}, {"referenceID": 15, "context": "com/ivanlanin/kateglo Italian Morph-it! 422756 31 (Zanchetta and Baroni, 2005) Norwegian OrdBank 679763 19 (Hagen and N\u00f8klestad, 2010) Persian PerLex 511840 37 (Sagot and Walther, 2010) Polish PolLex 390370 28 (Sagot, 2007) Portuguese LABEL-LEXsw 971514 29 (Ranchhod et al.", "startOffset": 107, "endOffset": 134}, {"referenceID": 40, "context": "com/ivanlanin/kateglo Italian Morph-it! 422756 31 (Zanchetta and Baroni, 2005) Norwegian OrdBank 679763 19 (Hagen and N\u00f8klestad, 2010) Persian PerLex 511840 37 (Sagot and Walther, 2010) Polish PolLex 390370 28 (Sagot, 2007) Portuguese LABEL-LEXsw 971514 29 (Ranchhod et al.", "startOffset": 160, "endOffset": 185}, {"referenceID": 37, "context": "com/ivanlanin/kateglo Italian Morph-it! 422756 31 (Zanchetta and Baroni, 2005) Norwegian OrdBank 679763 19 (Hagen and N\u00f8klestad, 2010) Persian PerLex 511840 37 (Sagot and Walther, 2010) Polish PolLex 390370 28 (Sagot, 2007) Portuguese LABEL-LEXsw 971514 29 (Ranchhod et al.", "startOffset": 210, "endOffset": 223}, {"referenceID": 35, "context": "com/ivanlanin/kateglo Italian Morph-it! 422756 31 (Zanchetta and Baroni, 2005) Norwegian OrdBank 679763 19 (Hagen and N\u00f8klestad, 2010) Persian PerLex 511840 37 (Sagot and Walther, 2010) Polish PolLex 390370 28 (Sagot, 2007) Portuguese LABEL-LEXsw 971514 29 (Ranchhod et al., 1999) Slovenian SloLeks 957525 25 (Krek et al.", "startOffset": 257, "endOffset": 280}, {"referenceID": 20, "context": ", 1999) Slovenian SloLeks 957525 25 (Krek et al., 2008) Spanish Leff e 755858 34 (Molinero et al.", "startOffset": 36, "endOffset": 55}, {"referenceID": 28, "context": ", 2008) Spanish Leff e 755858 34 (Molinero et al., 2009) Swedish Saldo 747959 38 (Borin et al.", "startOffset": 33, "endOffset": 56}, {"referenceID": 3, "context": ", 2009) Swedish Saldo 747959 38 (Borin et al., 2008)", "startOffset": 32, "endOffset": 52}, {"referenceID": 12, "context": "Despite a few experiments published with MElt on languages other than French (Denis and Sagot, 2012; Le Roux et al., 2012; Seddah et al., 2013a), the original feature set used by MElt (standard and lexical features) was designed and tested mostly on this language, by building and evaluating tagging models on a variant of the French TreeBank.", "startOffset": 77, "endOffset": 144}, {"referenceID": 42, "context": "Despite a few experiments published with MElt on languages other than French (Denis and Sagot, 2012; Le Roux et al., 2012; Seddah et al., 2013a), the original feature set used by MElt (standard and lexical features) was designed and tested mostly on this language, by building and evaluating tagging models on a variant of the French TreeBank.", "startOffset": 77, "endOffset": 144}, {"referenceID": 43, "context": "In order to select the best performing feature set, we carried out a series of experiments using the multilingual dataset provided during the SPMRL parsing shared task (Seddah et al., 2013b).", "startOffset": 168, "endOffset": 190}, {"referenceID": 31, "context": "2 treebanks (Nivre and al., 2015), hereafter UD1.", "startOffset": 12, "endOffset": 33}, {"referenceID": 31, "context": "2 treebanks (Nivre and al., 2015), hereafter UD1.2, from which morphosyntactically annotated corpora can be trivially extracted. All UD1.2 corpora use a common tag set, the 17 universal PoS tags,3 which is an extension of the tagset proposed by Petrov et al. (2012).", "startOffset": 13, "endOffset": 266}, {"referenceID": 34, "context": "2 corpora that cover languages for which we have morphosyntactic lexicons at our disposal, and for which Plank et al. (2016) provide results.", "startOffset": 105, "endOffset": 125}, {"referenceID": 34, "context": "2 corpora, together with the results publised on the same corpora by Plank et al. (2016), using their best model not enhanced by external word vector representations \u2014i.", "startOffset": 69, "endOffset": 89}, {"referenceID": 34, "context": "2 corpora, together with the results publised on the same corpora by Plank et al. (2016), using their best model not enhanced by external word vector representations \u2014i.e. the model they call ~ w +~c, which is a bidirectional LSTM that combines both word and character embeddings. These results show that Plank et al.\u2019s (2016) bi-LSTM performs extremely well, surpassed by MarMoT on only 3 out of 16 datasets (Czech, French and Italian), and by MElt only once (Indonesian).", "startOffset": 69, "endOffset": 327}, {"referenceID": 7, "context": "5However, for French, we used the morphosyntactic variant of the Lefff that is included in the MElt distribution, and which relies on a variant of the French TreeBank known as FTB-UC (Candito and Crabb\u00e9, 2009).", "startOffset": 183, "endOffset": 209}, {"referenceID": 34, "context": "MElt and MarMoT models trained without external lexicons, and Plank et al.\u2019s (2016) ~c + ~ w models, which do not make use of Polyglot embeddings.", "startOffset": 62, "endOffset": 84}, {"referenceID": 34, "context": "Model type MEMM+lexicon CRF+lexicon bi-LSTM+Polyglot FREQBIN+Polyglot System MElt MarMoT (Plank et al., 2016) overall OOV overall OOV overall OOV overall OOV Bulgarian (bg) 98.", "startOffset": 89, "endOffset": 109}, {"referenceID": 34, "context": "Table 4: Accuracy (in %) of the feature-based systems MElt and MarMoT as well as the two best LSTM-based systems by Plank et al. (2016) on UD1.", "startOffset": 116, "endOffset": 136}, {"referenceID": 32, "context": "We have only compared the contribution of morphosyntactic lexicons to feature-based models (MEMMs, CRFs) and that of word vector representations to bi-LSTM-based models as reported by Plank et al. (2016). As mentioned above, work on the contribution of word vector representations to feature-based approaches has been carried out by M\u00fcller and Sch\u00fctze (2015).", "startOffset": 184, "endOffset": 204}, {"referenceID": 29, "context": "As mentioned above, work on the contribution of word vector representations to feature-based approaches has been carried out by M\u00fcller and Sch\u00fctze (2015). However, the exploitation of existing morphosyntactic or morphological lexicons in neural models is a less studied question.", "startOffset": 128, "endOffset": 154}, {"referenceID": 23, "context": "An option would be to integrate feature-based models such as a CRF with an LSTM-based layer, following recent proposals such as the one proposed by Lample et al. (2016) for named entity recognition.", "startOffset": 148, "endOffset": 169}], "year": 2016, "abstractText": "Morphosyntactic lexicons and word vector representations have both proven useful for improving the accuracy of statistical part-of-speech taggers. Here we compare the performances of four systems on datasets covering 16 languages, two of these systems being feature-based (MEMMs and CRFs) and two of them being neural-based (bi-LSTMs). We show that, on average, all four approaches perform similarly and reach state-of-the-art results. Yet better performances are obtained with our feature-based models on lexically richer datasets (e.g. for morphologically rich languages), whereas neural-based results are higher on datasets with less lexical variability (e.g. for English). These conclusions hold in particular for the MEMM models relying on our system MElt, which benefited from newly designed features. This shows that, under certain conditions, featurebased approaches enriched with morphosyntactic lexicons are competitive with respect to neural methods. Key-words: Part-of-Speech Tagging, Feature-based models, Neural models, MEMM, CRF, biLSTM, Multilingual Analysis Utilisation d\u2019informations lexicales externes pour l\u2019annotation multilingue en parties du discours R\u00e9sum\u00e9 : Les lexiques morphosyntaxiques et les repr\u00e9sentations vectorielles des mots ont chacun montr\u00e9 leur utilit\u00e9 pour am\u00e9liorer la pr\u00e9cision d\u2019\u00e9tiqueteurs morphosyntaxiques statistiques. Nous comparons ici les performances de quatre syst\u00e8mes sur des jeux de donn\u00e9es couvrant 16 langues, deux de ces syst\u00e8mes reposant sur des traits (MEMM et CRF) et deux autres sur des approches neuronales (bi-LSTM). Nous montrons qu\u2019en moyenne les quatre approches obtiennent des performances similaires de niveau \u00e9tat-de-l\u2019art. N\u00e9anmoins, nos mod\u00e8les reposant sur des traits ont de meilleures performances sur les jeux de donn\u00e9es lexicalement plus riches (par exemple sur des langues \u00e0 morphologie riche), alors que les r\u00e9sultats obtenus par les approches neuronales sont meilleurs sur les jeux de donn\u00e9es dont la variabilit\u00e9 lexicale est moindre (par exemple pour l\u2019anglais). Ces conclusions sont vraies en particulier pour nos mod\u00e8les de type MEMM faisant usage de notre syst\u00e8me MElt, qui s\u2019appuie sur un jeu de traits renouvel\u00e9. Ceci montre que, sous certaines conditions, les approches par traits enrichies par des lexiques morphosyntaxiques sont comp\u00e9titifs par rapport aux approches neuronales. Mots-cl\u00e9s : \u00c9tiquetage en partie du discours, Mod\u00e8les reposant sur des traits, Mod\u00e8les neuronaux, MEMM, CRF, bi-LSTM, Analyse multilingue External Lexical Information for Multilingual Part-of-Speech Tagging 3", "creator": "LaTeX with hyperref package"}}}