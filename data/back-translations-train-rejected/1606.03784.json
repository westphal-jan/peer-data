{"id": "1606.03784", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Jun-2016", "title": "MITRE at SemEval-2016 Task 6: Transfer Learning for Stance Detection", "abstract": "We describe MITRE's submission to the SemEval-2016 Task 6, Detecting Stance in Tweets. This effort achieved the top score in Task A on supervised stance detection, producing an average F1 score of 67.8 when assessing whether a tweet author was in favor or against a topic. We employed a recurrent neural network initialized with features learned via distant supervision on two large unlabeled datasets. We trained embeddings of words and phrases with the word2vec skip-gram method, then used those features to learn sentence representations via a hashtag prediction auxiliary task. These sentence vectors were then fine-tuned for stance detection on several hundred labeled examples. The result was a high performing system that used transfer learning to maximize the value of the available training data.", "histories": [["v1", "Mon, 13 Jun 2016 00:12:49 GMT  (309kb,D)", "http://arxiv.org/abs/1606.03784v1", "International Workshop on Semantic Evaluation 2016"]], "COMMENTS": "International Workshop on Semantic Evaluation 2016", "reviews": [], "SUBJECTS": "cs.AI cs.CL", "authors": ["guido zarrella", "amy marsh"], "accepted": false, "id": "1606.03784"}, "pdf": {"name": "1606.03784.pdf", "metadata": {"source": "CRF", "title": "MITRE at SemEval-2016 Task 6: Transfer Learning for Stance Detection", "authors": ["Guido Zarrella", "Amy Marsh"], "emails": ["jzarrella@mitre.org", "amarsh@mitre.org"], "sections": [{"heading": "1 Introduction", "text": "This paper describes a system for automatic posture recognition in social media messages. Our approach uses a recurrent neural network initialized from pre-learned traits that are used in successive attempts to encode world knowledge through weak external supervision. Position recognition is the task of determining whether the author of a text is for or against a particular topic, while we reject texts in which no conclusion is likely. This task differs from mood analysis in that an endorsement or rejection of the viewpoint can be measured independently of an author's emotional state. In viewpoint recognition, we try to determine how an author's opinion is expressed in spontaneous, unstructured messages rather than in the explicit demands of formal opinion polls. Position clarifications are often written in visual language that can be difficult for machines to untangle. Consider the texts we do not inherit from our parents, we do not seek them from our parents, we do not have them reviewed by our parents, but rather by our children, if they are not mine and mine."}, {"heading": "2 Related Work", "text": "It is common for machine learning approaches to learn each new task from scratch, for example by randomly initializing the parameters of a neural network. This ignores any knowledge gained by similar algorithms in solving previous tasks. Transfer learning approaches, on the other hand, store the knowledge acquired in a context and apply it to other related problems. This approach is particularly attractive when there is a lack of sufficient quantity of training data labeled in domains, e.g. when there are only a few hundred known examples of a target.ar Xiv: 160 6.03 784v 1 [cs.A I] 1 3Ju n20 16A strategy for performing transfer learning consists of training the parameters of a neural network on multiple tasks: first an auxiliary task with abundant data that allows the network to identify significant features present in the corpus, then a second time on the basis of actual task data to optimize and exploit these features."}, {"heading": "3 Task and Evaluation", "text": "The task organizers provided training data in the form of 2,814 tweets on five topics, with 395 to 664 tweets sent per topic. Organizers used crowdsourcing to manually comment on these tweets. Class balance varied between topics, with some topics exhibiting significant distortions (e.g. climate change is a real concern with 4% AGAINST and 54% FAVOR), while others were more balanced (e.g. feminist movement with 49% AGAINST and 32% FAVOR). Approximately 74% of the tweets posted were rated either positive or negative, while the rest contained no conclusions. A further 1249 tweets with high labels were used as evaluation data. Systems were evaluated using the macro averages of F1 score (FAVOR) and FINAGAST (all topics)."}, {"heading": "4 System Overview", "text": "We now describe a position recognition approach that uses a recursive neural network organized into four layers of weights (Figure 1); input markers are encoded in a uniform manner so that each token is represented by a sparse binary vector that contains a single value at the index corresponding to the position of the token in the vocabulary; a sequence of these inputs is projected by a 256-dimensional embedding layer that passes into a recursive layer of 128 Long ShortTerm Memory (LSTM) units; and the final output of this recursive layer is densely connected to a 128-dimensional layer of reflected linear units formed with 90% dropouts (Srivastava et al., 2014); finally, this layer is fully connected to a three-dimensional softmax layer in which each unit represents one of the output classes ONFAR: this one does not automatically identify AVAGE or NAGE."}, {"heading": "4.1 Pre-Training the Projection Layer", "text": "The weights for the projection layer of the network were initialized using 256-dimensional word embeddings learned using the word2vec Skip-gram algorithm (Mikolov et al., 2013a). We sampled 218,179,858 tweets from Twitter's Public Streaming API in 2015 and used this unlabeled data as our training corpus. Retweets, duplicates, and non-English messages were not included in this sample. Text was depressed and tokenized to mimic the style of task data. We then used word2phrase (Mikolov et al., 2013b) twice in a row to identify phrases consisting of up to four words, e.g. by creating a single token of the phrase Global Climate Change. We then trained 256-dimensional Skip-gram embeddings for the 537,366 proximal words per 100 words, which appeared at least one of our contextual windows, and one of our contextual window."}, {"heading": "4.2 Pre-Training the Recurrent Layer", "text": "The second layer of our network consisted of 128 Long Short-Term Memory (LSTM) units (Hochreiter and Schmidhuber, 1997). This recurring layer was input into a sequence of up to 30 embedded units, each folded into its hidden state. It was initialized with weights that were pre-trained using the remote supervision of a hashtag prediction helper task. In this way, the network learned to distribute sentence representations from a dataset that contained a wide range of viewpoint explanations, rather than relying solely on the 2814 explicitly in-domain tweets. We started automatically identifying 197 hashtags relevant to the topics under consideration, such as # climatechange, # climatescam, and # gamergate. These hashtags were selected based on a nearest neighbor search for the word embedding space."}, {"heading": "5 Experiments", "text": "The system described in Section 4 was designed to determine distances to a single topic, so five different classifiers were trained, one for each of the five topics included in the evaluation; the embedding and recurring layers of each classifier were initialized using weights obtained from the pre-training process described above; the rest of the weights were randomly initialized and the network was trained with stochastic gradient descent using a learning rate of 0.015 and a dynamics of 0.9; these networks were trained using a categorical cross-entropy loss function, with the cost of each example weighted according to the prevalence of the class in the training data, giving higher weight to rare classes; the recurring networks were implemented using the Keras frameter (Chollet, 2015).The training data for each topic was mixed and divided into five blocks to allow them to cross-validate each of the networks for a different training process."}, {"heading": "6 Results", "text": "Our submission achieved an average F1 score of 67.8 in the classes FAVOR and AGAINST of the test set carried out, which contained tweets from all five areas. This was the best scoring system among the 19 submissions that were subjected to the shared task of detecting monitored positions. The same system showed an average F1 value of 71.1 when cross-validating component systems on the training set, indicating a small overmatch. There was also a moderate difference between the scores between the subjects and classes (Figure 2).A consistent observation across all topics was that the majority class, whether FAVOR or AGAINST, significantly exceeded the corresponding minority class. There was a positive correlation (R2 = 0.67) between the F1 score for a given class and the raw number of training examples representing this class.The weight pre-training and initiation regimes we applied improved the performance in the comparison of a 751 / 751 / 771 to 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 771 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751 / 751"}, {"heading": "7 Conclusion", "text": "We described a state-of-the-art system for automatically determining an author's posture based on the content of a single tweet. This approach was able to maximize the value of limited training data by transferring features from other systems trained on large, unlabeled datasets. Our results showed that hashtag predictions and tasks skipping position detection programs can lead to pre-trained features useful for position detection. Selection of domain-relevant hashtags appears to be a critical aspect of this architecture, as experiments with a larger collection of common hashtags result in significantly worse performance on the position detection task. Transfer learning does not completely eliminate the need for labeled in-domain training data. The most common use classes consistently outperformed minority classes in all metrics. It is likely that positions that are rare in this training set may also be disproportionately affected by the larger, unlabeled auxiliary task."}, {"heading": "Acknowledgments", "text": "This work was funded under the MITRE Innovation Program. Thanks to Spencer Marsh for his timely encouragement. Approved for publication; Unlimited distribution: file number 16- 1159. c \u00a9 2016 The MITRE Corporation: ALL RIGHTS RESERVED."}], "references": [{"title": "Semi-supervised sequence learning", "author": ["Dai", "Le2015] Andrew M Dai", "Quoc V Le"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Dai et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Dai et al\\.", "year": 2015}, {"title": "Learning distributed representations of sentences from unlabelled data", "author": ["Hill et al.2016] Felix Hill", "Kyunghyun Cho", "Anna Korhonen"], "venue": "arXiv preprint arXiv:1602.03483", "citeRegEx": "Hill et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Hill et al\\.", "year": 2016}, {"title": "Long short-term memory", "author": ["Hochreiter", "Schmidhuber1997] Sepp Hochreiter", "J\u00fcrgen Schmidhuber"], "venue": "Neural Computation,", "citeRegEx": "Hochreiter et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter et al\\.", "year": 1997}, {"title": "Efficient estimation of word representations in vector space", "author": ["Kai Chen", "Greg Corrado", "Jeffrey Dean"], "venue": "ICLR Workshop", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "SemEval-2016 Task 6: Detecting stance in tweets", "author": ["Svetlana Kiritchenko", "Parinaz Sobhani", "Xiaodan Zhu", "Colin Cherry"], "venue": "In Proceedings of the International Workshop on Semantic Evaluation,", "citeRegEx": "Mohammad et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Mohammad et al\\.", "year": 2016}, {"title": "Sentiment analysis: Detecting valence, emotions, and other affectual states from text", "author": ["Saif M. Mohammad"], "venue": "In Herb Meiselman,", "citeRegEx": "Mohammad.,? \\Q2016\\E", "shortCiteRegEx": "Mohammad.", "year": 2016}, {"title": "Support or oppose?: classifying positions in online debates from reply activities and opinion expressions", "author": ["Murakami", "Raymond2010] Akiko Murakami", "Rudy Raymond"], "venue": "In Proceedings of the 23rd International Conference on Computational", "citeRegEx": "Murakami et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Murakami et al\\.", "year": 2010}, {"title": "Identifying users with opposing opinions in twitter debates", "author": ["Rajadesingan", "Liu2014] Ashwin Rajadesingan", "Huan Liu"], "venue": "In Social Computing, Behavioral-Cultural Modeling and Prediction,", "citeRegEx": "Rajadesingan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Rajadesingan et al\\.", "year": 2014}, {"title": "Recognizing stances in online debates", "author": ["Somasundaran", "Wiebe2009] Swapna Somasundaran", "Janyce Wiebe"], "venue": "In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language", "citeRegEx": "Somasundaran et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Somasundaran et al\\.", "year": 2009}, {"title": "Dropout: A simple way to prevent neural networks from overfitting", "author": ["Geoffrey Hinton", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan Salakhutdinov"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Srivastava et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Srivastava et al\\.", "year": 2014}, {"title": "Get out the vote: Determining support or opposition from congressional floor-debate transcripts", "author": ["Thomas et al.2006] Matt Thomas", "Bo Pang", "Lillian Lee"], "venue": "In Proceedings of the 2006 conference on empirical methods in natural language processing,", "citeRegEx": "Thomas et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Thomas et al\\.", "year": 2006}, {"title": "Stance classification using dialogic properties of persuasion", "author": ["Pranav Anand", "Robert Abbott", "Ricky Grant"], "venue": "In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computa-", "citeRegEx": "Walker et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Walker et al\\.", "year": 2012}, {"title": "tagspace: Semantic embeddings from hashtags", "author": ["Weston et al.2014] Jason Weston", "Sumit Chopra", "Keith Adams"], "venue": "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Weston et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Weston et al\\.", "year": 2014}, {"title": "Qatar, A meeting of SIGDAT, a Special Interest Group of the ACL, pages 1822\u20131827", "author": ["Doha"], "venue": null, "citeRegEx": "2014 and Doha,? \\Q2014\\E", "shortCiteRegEx": "2014 and Doha", "year": 2014}, {"title": "How transferable are features in deep neural networks", "author": ["Jeff Clune", "Yoshua Bengio", "Hod Lipson"], "venue": null, "citeRegEx": "Yosinski et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Yosinski et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 15, "context": "Deep neural networks trained for image classification can be improved when initialized with features learned from distant tasks, for example Yosinski et al. (2014). In natural language processing domains, sentence representations learned on unlabeled data have been shown to be useful across a variety of classification and semantic similarity tasks", "startOffset": 141, "endOffset": 164}, {"referenceID": 1, "context": "(Kiros et al., 2015; Dai and Le, 2015; Hill et al., 2016).", "startOffset": 0, "endOffset": 57}, {"referenceID": 1, "context": ", 2015; Dai and Le, 2015; Hill et al., 2016). Weston et al. (2014) used a hashtag prediction task to learn sentence representations that improve a downstream content-based recommendation system.", "startOffset": 26, "endOffset": 67}, {"referenceID": 6, "context": "Previous work in stance detection is significant (Mohammad, 2016), often with a focus on analysis of congressional debates or online forums (Thomas et al.", "startOffset": 49, "endOffset": 65}, {"referenceID": 11, "context": "Previous work in stance detection is significant (Mohammad, 2016), often with a focus on analysis of congressional debates or online forums (Thomas et al., 2006; Somasundaran and Wiebe, 2009; Murakami and Raymond, 2010; Walker et al., 2012)", "startOffset": 140, "endOffset": 240}, {"referenceID": 12, "context": "Previous work in stance detection is significant (Mohammad, 2016), often with a focus on analysis of congressional debates or online forums (Thomas et al., 2006; Somasundaran and Wiebe, 2009; Murakami and Raymond, 2010; Walker et al., 2012)", "startOffset": 140, "endOffset": 240}, {"referenceID": 5, "context": "Frameworks (Mohammad et al., 2016) was a shared task organized within SemEval-2016.", "startOffset": 11, "endOffset": 34}, {"referenceID": 10, "context": "The terminal output of this recurrent layer is densely connected to a 128dimensional layer of Rectified Linear units trained with 90% dropout (Srivastava et al., 2014).", "startOffset": 142, "endOffset": 167}], "year": 2016, "abstractText": "We describe MITRE\u2019s submission to the SemEval-2016 Task 6, Detecting Stance in Tweets. This effort achieved the top score in Task A on supervised stance detection, producing an average F1 score of 67.8 when assessing whether a tweet author was in favor or against a topic. We employed a recurrent neural network initialized with features learned via distant supervision on two large unlabeled datasets. We trained embeddings of words and phrases with the word2vec skip-gram method, then used those features to learn sentence representations via a hashtag prediction auxiliary task. These sentence vectors were then finetuned for stance detection on several hundred labeled examples. The result was a high performing system that used transfer learning to maximize the value of the available training data.", "creator": "LaTeX with hyperref package"}}}