{"id": "1606.04189", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Jun-2016", "title": "Inverting face embeddings with convolutional neural networks", "abstract": "Deep neural networks have dramatically advanced the state of the art for many areas of machine learning. Recently they have been shown to have a remarkable ability to generate highly complex visual artifacts such as images and text rather than simply recognize them.", "histories": [["v1", "Tue, 14 Jun 2016 01:35:12 GMT  (6162kb,D)", "http://arxiv.org/abs/1606.04189v1", null], ["v2", "Thu, 7 Jul 2016 18:52:57 GMT  (7563kb,D)", "http://arxiv.org/abs/1606.04189v2", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG cs.NE", "authors": ["andrey zhmoginov", "mark sandler"], "accepted": false, "id": "1606.04189"}, "pdf": {"name": "1606.04189.pdf", "metadata": {"source": "CRF", "title": "Inverting face embeddings with convolutional neural networks", "authors": ["Andrey Zhmoginov", "Mark Sandler"], "emails": ["azhmogin@google.com", "sandler@google.com"], "sections": [{"heading": null, "text": "Recently, it has been shown that they have a remarkable ability to produce highly complex visual artifacts such as images and text, rather than simply recognizing them. In this work, we use neural networks to effectively reverse low-dimensional face embedding while creating realistic-looking consistent images. Our paper consists of two parts: First, we show that gradient-ascent approaches can be used to reproduce consistent images using a mission statement; second, we show that we can train a separate neural network to effectively solve the minimization problem in one pass and generate images in real time; and second, we assess the loss caused by using a neural network instead of gradient by comparing the end values of the minimized loss function."}, {"heading": "1 Introduction", "text": "Deep neural networks are an extremely powerful tool for object recognition [1, 2, 3, 4] and image segmentation [5]. More recently, they have also shown uncanny abilities to produce images [6, 7, 8]. Specifically, style transfer [9, 10], deep dreams [11], generative opposing networks [6] have all produced highly compelling results. In this work, we are investigating our ability to control the images, to produce deep neural networks. For this work, we are using FaceNet [4], a face recognition network trained to distinguish between people, as our test bed. We are looking at the problem of reversing network output or embedding vector e, i.e. with embedding vector e, we are creating a realistic face image that, after being guided through FaceNet, e. An interesting aspect of this problem is the fact that the space of different acceptable solutions is designed to generate different orientations, in particular the same person and should be different."}, {"heading": "1.1 Image Embedding Network", "text": "For our experiments, we used a Facenet model [4] that maps a 224 x 224 RGB face image to a normalized 128-dimensional \"embedding vector.\" This network was trained to embed different photos of the same person in order to be closer to each other than to another person. This network achieves a performance comparable to that of human face recognition [4]."}, {"heading": "1.2 Overview of results and paper structure", "text": "The contents of this essay can be roughly divided into two parts: First, in sections 2 and 3, we introduce a general problem of facial reconstruction and propose a loss function that allows an algorithm of gradient descent to reconstruct highly recognizable faces using only the target embedding vector. Orientation and facial expression of the produced image correspond to that of a provided model. The basic idea of the method is based on the application of additional regulation losses that force consistency and orientation of the face embedding loss. Specifically, we use the total variation loss [14] and the gradual normalization of the pyramid [15] to ensure a smooth image. We also use \"2 spacing on intermediate layers with the model to force a specific orientation and orientation of the face embedding loss. Minimization of the combined loss function is avoided by accidental or accidental mismatch."}, {"heading": "2 Face reconstruction as a minimization problem", "text": "The facial reconstructive problem of the inverse F \u2212 1) of the arbitrary E \u2212 E is generally a multifaceted problem that can only relate to a limited number of frames. \"We have two definitions of the embedding vector: an unstandardized embedding of the image could be achieved by finding an image that minimizes d [F] where d [F] R applies some metrics to the embedding space E.\" But since in the practical application of the space of all possible images P has a much larger dimension, the embedding of space F \u2212 1 (e) of the arbitrary E \u2212 R is a high diversity of space E because the space of all possible images P has a much larger dimension than that of the inverse F \u2212 1 (e) of the arbitrary E \u2212 E."}, {"heading": "3 Iterative face reconstruction", "text": "Provided that with an embedding e-E and a selected set of regularization parameters, we were able to generate realistic images that we could solve the minimization problem (1) by starting numerically with stochastic gradients Descent (SGD), Adam [16], or some other optimization method, starting from random noise or entering a mission statement in RG. Without any regularization mechanisms, the iterative process is ultimately converted to an image from a small neighborhood of the initial state. [14, 12] Performing an optimization using the regularization of the mission statement alone was also unsuccessful in reconstructing a realistic face image. A significant improvement was observed once the total regularization mechanism (2) was introduced into Eq. (see Figure 1f, 1g) The initial state of the reconstruction was also shown to play an important role in starting with a random noise pattern (see also the random one)."}, {"heading": "4 Feed-forward network for face reconstruction", "text": "Any reconstruction carried out using the methods discussed in paragraph 3 requires hundreds or even thousands of iterations. Training a neural network capable of reconstructing an image in a single operation could have a significant performance advantage. Specifically, the basic idea behind training such a network is based on using the same loss function that we used for iterative facial reconstruction. Specifically, each training step involves updating the network weights at random embedding e to minimize the loss calculated on e (1) and the image generated by the network."}, {"heading": "4.1 Feed-forward network taking embedding as an input", "text": "The feed-forward network we used for facial reconstruction took a 128-dimensional vector e as input and generated a 224 x 224 image with 3 channels (see Fig. 3a). Within the network, a fully connected layer (followed by a ReLU nonlinearity) was first used to convert the embedding vector into an 8 x 8 x 16 tensor (where 16 is the number of \"filters\"), which was then passed through a sequence of ReLU devolutions, each of which produced an input sensor of size 2n x 2n x Ln and a tensor of size 2n + 1 x 2n + 1 x Ln + 1. In our experiments, the devolution core had a size of 5 x 5 and all Ln, with the exception of the last one with L8 = 3, were equal. The final 256 x 256 x 256 net reconstructions we were able to use the same Tn + 1 x Ln + 1 x face224 and all Ln dimensions were equal to the net 224."}, {"heading": "4.2 Feed-forward network with an embedding and a guiding image as inputs", "text": "A feed network described in Abs. 4.1 can be trained to perform facial reconstructions using a row of guide images instead of one. In this case, a sparse guide image index can be passed to the network as one of its inputs. Unfortunately, due to the limited capacity of the network and the need to encode all guide images somehow in the network weights, this could only be demonstrated for a few, but not even dozens of similar guide images (taken from images of a video clip). One of the approaches to mitigate this limitation and potentially perform a face reconstruction using any guide image is based on passing the guide image as one of the inputs to the feed-shaped neural network. In our experiments, the inserted guide image was initially pushed to the size of 256 x 256 x 256 and then through a row of contiguous layers of layers of steps of 2 (see Figure 3b. 5 x x x x x x 5 x 5 x 5 x 5 x 5 x 5 x 5 x 5 x 5 x 5 x 5 x 5 x 5 x 5 x 5 x 256 x x x x x x x 5 x x x 5 x x 5 x x 5 x 5 x 5 x 5 x x 5 x 5 x 5 x x x 5 x x 5 x 5 x 5 x x 5 x 5 x x 5 x x 5 x x x 5 x 5 x 5 x x x x 5 x 5 x x 5 x 5 x 5 x x 5 x x 5 x 5 x x 5 x 5 x 5 x x x x 5 x 5 x 5 x x x 5 x 5 x 5 x x 5 x 5 x 5 x x x 5 x 5 x 5 x 5 x 5 x 5 x x x 5 x x 5 x 5 x 5 x x 5 x 5 x x 5 x x 5 x 5 x x 5 x 5 x x 5 x 5 x 5 x 5 x 5 x x 5 x 5 x x 5 x 5 x 5 x 5 x 5 x 5 x 5 x x x 5 x 5 x 5 x 5 x x 5 x x 5 x 5 x 5 x x 5 x 5 x 5 x 5 x x 5 x 5 x 5 x 5 x 5 x 5 x 5 x 5 x x 5 x 5 x 5 x x 5 x 5 x 5 x 5 x 5 x 5 x 5 x x 5 x 5 x 5 x 5 x 5 x 5 x"}, {"heading": "5 Experiments", "text": "In this section, we examine our ability to generate facial images using iterative reconstruction using SGD and feed-forward networks. Quality of reconstruction measures the quality of our loss function in the search for recognizable faces. Once we are satisfied with the loss function, i.e. we are reasonably confident that the gradient drop produces recognizable faces with such a loss function, we turn our attention to feed-forward networks that are trained to find the optimum of the same loss, but do so in a single passage. In our experiments, where we want to demonstrate the recognizability of people, we use famous people to maximize the recognizability of the reconstructed images. We use publicly available cartoon images from Ref. 17 as well as averaged images from Ref. 18."}, {"heading": "5.1 Iterative Reconstruction", "text": "For our experiments, we use pre-normalized embedding as input. Although the original FaceNet was designed to distinguish between normalized embedding and thus ignore the difference in \"2 standard, we find that optimizing a match with pre-normalized embedding yields better results. We suspect that with normalization, SGD prefers smaller embedding values that essentially lead to generic-looking image, as in Fig. 8. For our experiments, we use both '2 and Dot product. Dot product produces significantly sharper but slightly less recognizable images, as in Fig. 1. Somewhat surprisingly, with normalized' 2 distance (or uniformly normalized Dot product), results in much worse reconstructions. For the example in Fig. 1, we have used activation targets on a single interlayer."}, {"heading": "5.2 Feed-forward network", "text": "Being trained on a number of embedding and a single mission statement, the feed-forward network described in Sec. 4.1 Taking a FaceNet embedding as input and producing an image as its output, successfully converges. The images produced by the network on multiple embedding, which are never seen during training, are shown in Fig. 9. The model was observed to converge faster when the network weights were initialized as follows: The deconvolution weights were chosen to provide smooth spatial interpolation using random Xaiver filter-to-filter connections and the final deconvolution was tuned to image.It is noteworthy that seemingly similar images produced with the feed-forward network are still recognizable reconstructions of the embedding. This is a demonstration of the fact that only a subtle change in facial features is often enough to distinguish a person from others."}, {"heading": "6 Conclusions and future work", "text": "We have shown that a FaceNet embedding loss coupled with simple regulation functions can be used to successfully reconstruct realistic-looking faces. On the one hand, we can explore better regulation functions that improve the quality of the generated images and combine multiple networks to achieve more accurate control of the reconstructions. For example, it would be interesting to study the ability to control the facial expression of the generated image using a network trained to recognize facial expressions (such as anger, satisfaction, smile, etc.) On the other hand, in order to achieve rapid generation, we need to train a deep network that would solve the minimization problem in a single operation. Interestingly, we were able to achieve this without using adversarial learning. This suggests that the network does not contain enough embedding information that is produced by the network."}, {"heading": "A Gaussian activation regularizer", "text": "Instead of using a single image for all images in p, you could consider a collection of photos p, faces that contain some features such as position, pose, or facial expression."}, {"heading": "C Other approaches for improving image quality", "text": "Natural images are typically characterized by an intensity power spectrum I (fx, fy) that [19] obeys an approximate power law I (f2x + f2y) \u2212 1. The facial reconstruction algorithm could be regulated to produce images with a tuned spectrum by performing a laplac pyramid (LP) decomposition [15] of the image. Be g0 the original image, e is the \"expanding\" operator and r the \"reducing\" operator [15]. The laplac pyramid can then be defined as an image sequence Lk = gk \u2212 e gk + 1, with gk + 1 = r gk. The LP normalization regulation regulates RLP (p) = N n (p) - NL2\u03b2n) 2, (12) can then favor images with the desired power spectrum \u03b2 and a component standard NL. An alternative approach is based on the laplac normalization."}], "references": [], "referenceMentions": [], "year": 2016, "abstractText": "Deep neural networks have dramatically advanced the state of the art for many<lb>areas of machine learning. Recently they have been shown to have a remarkable<lb>ability to generate highly complex visual artifacts such as images and text rather<lb>than simply recognize them.<lb>In this work we use neural networks to effectively invert low-dimensional face<lb>embeddings while producing realistically looking consistent images. Our contri-<lb>bution is twofold, first we show that a gradient ascent style approaches can be<lb>used to reproduce consistent images, with a help of a guiding image. Second, we<lb>demonstrate that we can train a separate neural network to effectively solve the<lb>minimization problem in one pass, and generate images in real-time. We then<lb>evaluate the loss imposed by using a neural network instead of the gradient descent<lb>by comparing the final values of the minimized loss function.", "creator": "LaTeX with hyperref package"}}}