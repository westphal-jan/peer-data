{"id": "1606.04250", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Jun-2016", "title": "Experimental and causal view on information integration in autonomous agents", "abstract": "The amount of digitally available but heterogeneous information about the world is remarkable, and new technologies such as self-driving cars, smart homes or the \"internet of things\" will further increase it. In this paper we examine certain aspects of the problem of how such heterogeneous information can be harnessed by intelligent agents. We first discuss potentials and limitations of some existing approaches, followed by two investigations. The focus of the first investigation is on using the novel experimentation platform {\\em Malmo} to obtain a better understanding of the problem. The focus of the second investigation is on understanding how information about the hardware of different agents (such as self-driving cars), the agents' sensory data, and physical or causal information can be utilized for knowledge transfer between agents and subsequent more data-efficient decision making. Finally, we present some thoughts on what a general theory for the problem could look like, and formulate open questions.", "histories": [["v1", "Tue, 14 Jun 2016 08:38:18 GMT  (121kb,D)", "http://arxiv.org/abs/1606.04250v1", null], ["v2", "Fri, 26 Aug 2016 16:37:37 GMT  (122kb,D)", "http://arxiv.org/abs/1606.04250v2", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["philipp geiger", "katja hofmann", "bernhard sch\\\"olkopf"], "accepted": false, "id": "1606.04250"}, "pdf": {"name": "1606.04250.pdf", "metadata": {"source": "CRF", "title": "Experimental and causal view on information integration in autonomous agents", "authors": ["Philipp Geiger", "Katja Hofmann", "Bernhard Sch\u00f6lkopf"], "emails": ["philipp.geiger@tuebingen.mpg.de", "katja.hofmann@microsoft.com", "bs@tuebingen.mpg.de"], "sections": [{"heading": "1 Introduction", "text": "Countless heterogeneous information is recorded and interconnected, for example in self-driving cars, smart homes with household robots or the \"Internet of Things.\" Intuitively, it makes sense to design intelligent agents so that they automatically integrate all the relevant and well-structured information about their environment that is available. Various aspects of the problem of designing such agents have already been investigated. In this article, we approach the problem from two directions that, to our knowledge, have not yet been (exhaustively) investigated: through the use of Compex simulation experiments at the practical level and causal models at the more theoretical level. However, the complexity of the problem allows us to take only small steps."}, {"heading": "1.1 Main contributions", "text": "The main contribution of this paper consists of two investigations: \u2022 In Section 5, we use a simulated experimental platform to gain a better understanding of the problem of integrating heterogeneous information. \u2022 Specifically, we look at a toy scenario that captures important aspects of the general problem but can be easily implemented into this platform, and suggest and evaluate a method for doing so. \u2022 In Section 6, we examine how detailed information about the hardware of various actors (self-driving cars), their sensory data, 1 MPI for intelligent systems; E-Mail: philipp.geiger @ tuebingen.mpg.de 2 Microsoft Research; E-Mail: katja.hofmann @ microsoft.com 3 MPI for intelligent systems; E-Mail: bs @ tuebingen.mpg.deand Physical or causal information can be used for knowledge transfer between them and subsequent, more data-efficient decision-making. The common structure of both investigations is that we start with a description of a scenario that describes certain core aspects of the problem, in particular a variety of exponential issues."}, {"heading": "1.2 Structure of the paper", "text": "The rest of the paper is structured as follows: \u2022 We present the experimental platform and basic concepts in section 2. \u2022 In section 3 we formulate the problem. \u2022 In section 4 we examine the potentials and limitations of existing approaches to the problem. \u2022 In sections 5 and 6 we present our two main investigations. \u2022 In section 7 we propose potential next steps and propose open questions. \u2022 We conclude with section 8."}, {"heading": "2 Preliminaries", "text": "In fact, most of them are able to play by the rules that they have imposed on themselves, and they are able to play by the rules that they have imposed on themselves."}, {"heading": "3 Problem formulation", "text": "Let us describe in more detail the problem we are looking at in this paper: \u2022 Faced with a task T w.r.t. of a partially unknown environment E and additional heterogeneous but well-structured sources of information H (e.g. in the form of low sensory data or high-level descriptions). \u2022 Objective: Draft an Agent A who automatically uses as much relevant information from H as possible to solve T; more precisely, he should use H either to improve an explicit model of the effects of his action4, which then directs his actions, or to let his actions be guided directly by H. Note that alternatively, the problem could be formulated by letting A be just an actor and not a complete agent, and including the sensors of the agent in H. However, this could be a more precise formulation, for the sake of an intuitive terminology based on the fact that A is an agent."}, {"heading": "3.1 Example 1: sharing information between different self-driving cars", "text": "Consider self-driving cars. It is desirable that so much information about the environment can be shared with each other. By such information we mean up-to-date detailed road maps, traffic information, accident prevention information, etc. Let's assume, for example, that a self-driving car leaves the road in a difficult place because of an inappropriate action, for example, because the place has not yet been visited by self-driving cars (or has re-emerged because of a spill of oil or falling rocks). If we only look at other self-driving cars of the same hardware, that experience could be transferred directly to them by forcing them not to perform the action exactly on the spot. (i.e., for all cars of the same hardware, one could treat the experience as if it were their own and they \"learn\" from it in the usual way of reinforcement learning (RL).) However, if we assume that there are self-driving cars of different kinds, then it is not possible to transfer the experience and thus avoid further accidents, this simple way (using two robots)."}, {"heading": "3.2 Example 2: observing another agent", "text": "Consider household robots: such a robot can use its sensor to observe how people deal with doors, windows or kitchen appliances. It should be possible for household robots to learn from such experiences. For example, if a robot is able to operate the door knob in a similar way to a human, it should also open the door, enabling the robot to go into the other room (to perform a task)."}, {"heading": "3.3 Example 3: integrating high-level information", "text": "Consider an agent arriving in a city he has never been to. The goal is to get to a certain destination, say the town hall. A resident could explain the route in a simple language, with words like... \"follow this road until you get to a church, then turn right...\" Or a resident could provide a map and mark the direction.4 In this sense, at least the goal of information integration is clear: modelling the dynamics or causal structure of the agent in the vicinity. 5 Note that the problem we are formulating here does not coincide with the development of (\"strong\") artificial intelligence (AI), as defined by, for example, the Turing test, or simply based on human intelligence. We limit ourselves to information sources that are more or less well structured - either quantitative measurements with a simple and clear relationship to the physical world or information in a language that is much more restrictive than the natural language. Nevertheless, the formulated step may be considered an autonomous one of the RAIL in the local environment (it could be an autonomous step)."}, {"heading": "4 Related work: potentials and limitations", "text": "There are various lines of research dealing with major or minor aspects of the problem formulated in Section 3. Here, we will discuss the most relevant such directions that we are aware of and highlight their potentials and limitations in relation to the problem. Note that Sections 5.4 and 6.4 contain additional discussions about the benefits of our approaches in relation to these directions."}, {"heading": "4.1 Reinforcement learning", "text": "One of the most effective approaches to designing intelligent autonomous agents is reinforcement learning (RL) [13]. Rather than explicitly hard-coding every detail of an agent for each environment and target individually, an approach should be adopted that is more modular and based on learning rather than hard coding: the supervisor merely determines the reward function, and then the agent ideally uses the exploration of the unknown environment and the use of the experience gained (sensory data) to achieve a high cumulative reward. In relation to the problem we consider in this paper, RL plays a key role in integrating information in the form of recordings of an agent's own past with the same hardware. However, as mentioned in Section 3, here, unlike RL, we are looking at the problem of integrating information beyond such recordings, such as sensory data from agents with different hardware or information at higher levels such as maps."}, {"heading": "4.2 Learning from demonstrations", "text": "According to [1], in which we learn from demonstrations (LfD), a certain \"teacher\" leads a path that is recorded, and the goal is for a \"learner\" agent based on this record to derive and imitate (or use) the \"politics\" of the teacher (or the dynamics of the environment or both). Central terms used [1] to analyze and distinguish different types of LfD problems are recording, i.e., which aspects of the teacher's demonstration are measured and recorded, and the embodiment of mapping, i.e., if the recorded actions can be implemented directly by the \"learner\" and lead to similar observations to the problems recorded, or if the recordings must first be made \"meaningful\" to the learner. Our problem formulation can be regarded as a generalization of LfD."}, {"heading": "4.3 Multi-agent systems", "text": "A common approach is to re-model the collection of agents operating in a common environment as a single agent, viewing tuples of actions and observations as individual actions and observations. Learning-based methods have been extensively researched [5]. While multi-agent systems often allow the exchange and transfer of information between agents, they have certain limitations regarding the problem formulated in Section 3: Similar to LfD, they do not normally integrate superordinate sources of information (such as the map in Example 3) or explicit hardware specifications of agents (as we do in Section 6). Furthermore, it seems difficult to add agents to an environment, while our preliminary investigations in Section 6 allow for easier addition of agents."}, {"heading": "4.4 Transfer learning for agents", "text": "The problem we are looking at is related to the transfer of learning for agents. Consider, for example, [14] an example where, in the well-known example of a mountain car, experiences should be transferred even though the engine of the car is changed; this comes close to the transfer of experiences between self-driving cars, as we propose in Example 1. However, the scope of the methods examined in [14] lies in transferring observational records or things such as guidelines, value functions, etc. by means of an appropriate mapping, while the goal we are pursuing is also to integrate information that cannot normally be expressed in these terms (e.g. the map or the description of natural language in Example 3 or the observation of another agent in Example 2). Furthermore, in this essay we aim to integrate many heterogeneous sources of information, while in transfer learning, although several sources of information can be taken into account, these are generally homogeneous."}, {"heading": "4.5 Further related areas", "text": "Lately, experimenting with intelligent agents on platforms based on computer games has become popular [6]. To our knowledge, the current work is the first to use such platforms to investigate the problem of information integration or related problems such as LfD (Section 4.2). The general integration and transmission of data (not focused on intelligent agents) using causal models has been investigated by [9, 3]. Theoretical information such as the map in Example 3. Note that one difference to our method in Section 5 is that, for example, an estimate of the complete probability of transition is required, while our method only requires an idea of the dynamics at the \"low level.\" The idea of integrating superior information (also not for intelligent agents) has been investigated by [15]. The relationship between intelligent agents and causal models has been examined from a more philosophical perspective, e.g. [16]."}, {"heading": "5 Investigation 1: integration of \u201cnon-subjective\u201d information, evaluated in a simulated environment", "text": "In this section, we will discuss the following aspects of the problem formulated in Section 3: \u2022 What experiments, especially in simulated environments, can generally be conducted to gain better insights into the problem? \u2022 How can experiments (explorations) help an agent \"translate\" experiences not recorded by him into his own \"coordinate system\" and use them for (successful) decision-making? \u2022 How can partial information about the dynamics, such as a controller working locally, be merged with \"superordinate\" information such as hints on the way to a particular target position? \u2022 How can we quantify the efficiency gain from additional sources of information? The study is structured as follows: In Section 5.1, we describe the scenario, in particular the available heterogeneous information sources; in Section 5.2, we outline an information integrating agent for this scenario; then, in Section 5.3, we evaluate an adapted version of the agent in a simulated environment; and finally, in Section 5.4, we will discuss some of these aspects further."}, {"heading": "5.1 Scenario", "text": "Task. An agent A begins in an unknown landscape and the task is to arrive at a visually recognizable target position as quickly as possible = Ileq = target position. Available heterogeneous information. We assume that the following sources of information are available: \u2022 Agent L. \"s own sensory input in the form of images yt and position signal qt (which can be considered an\" interactive source of information \"as the agent can\" query \"this source through his actions) \u2022 the controller ctl, which can be seen as a summary of Agent A\" past subjective experience in relation to the invariant local \"physical laws\" of a class of environments. \u2022 a video trajectory y \u0445 0: L, which is a first-person recording of another agent with similar (but not necessarily identical) hardware running to the target in the same environment. Relation to the problem formulated in section 3."}, {"heading": "5.2 Method", "text": "First, we will outline a general method, i.e. \"software\" for A, in algorithm 1, using a (stochastic) optimization method and an image spacing dist as specified (for specific examples see below). Note that in algorithm 1 we will use E (Y | Q = q) to denote the middle image Y observed at position Q = q. Although algorithm 1 is principally applicable to the experimental setup that we will consider in section 5.3 below, we will instead evaluate algorithm 2, which is a simplified implementation of the concept, using \"teleportation,\" which allows the agent to jump directly to other positions without having to navigate there. For algorithm 2 as an optimization method, we will opt for a simple grid search. (Note: Instead, one could use gradient drop or Bayesian optimization techniques.) In addition, we will define the image spacing disparity with both a gauge (where N is followed by a lack of sharpness)."}, {"heading": "5.3 Empirical evaluation in a simulated environment", "text": "To evaluate algorithm 2, we consider three simple \"parkours\" missions in the Malm\u00f6 experimental platform, described in Section 2. These missions consist of simple maps with a special, visually recognizable position defined as the target. A brief description of the three missions is in column 2 of Table 1. We generally limit the possible actions to [\u2212 1, 1] 2, with the first dimension moving back and forth, and the second is punishing (moving sideways).The task is to reach the target position within 15 seconds in these maps.For each mission, we capture a trajectory performed by a human demonstrator [2], which solves the task. More specifically, we capture positions we perform with q, 0: L, and observations (video images) that are performed with y, 0: L. We perform algorithm 2 with input y: L and a simple proportional controller [2] (for ctl), where we perform the proportional algorithm with the previous human trajectories {2, with no human trajectories)."}, {"heading": "5.4 Discussion", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.4.1 Discussion of the experiment", "text": "Result: As Table 1 shows, algorithm 2 is successful for missions 1 and 3. In mission 2, it fails due to the repetitive structure of a wall that fills the full image observed at some point during the y-phase 1: L. This wall makes the mapping of the position for observation (video image) (local) non-injective, causing the algorithm to fail. Note that this problem could easily be solved by assuming earlier assumptions about the smoothness of q \u0445 0: L, along with the consideration of more than a minimum of Dist as a potential actual position (e.g. by Bayean optimization), or by looking for position sequences longer than 1, the y-1: L. Limitation of the experiment. However, one clear limitation of the experiment is that the human demonstrator who produced y-1: L uses the same \"hardware\" as algorithm 1, while the overarching goal of this paper is to integrate heterogeneous information."}, {"heading": "5.4.2 Theoretical analysis and insight", "text": "Assuming that there are at most N positions that the demonstrator can reach within a time step, algorithm 1 requires only about O (L \u00b7 N) steps to reach the target. Note that this theoretical analysis is supported by empirical evaluation: the trajectories of algorithm 2 - shown in Figure 2 - are approximately as long as y (L \u00b7 N) 1: L (note that the visualization does not show the local search for length N), which must be compared with an agent that does not integrate the information 1: L and therefore, in the worst case, must search all positions on the map, a number that is normally much higher than O (L \u00b7 N) (coarse O (L2)). Comparison to LfD. The task we are investigating is closely related to LfD."}, {"heading": "6 Investigation 2: integrating sensory data, hardware specifications and causal relations", "text": "In this section, we will discuss the following aspects of the problem formulated in Section 3: \u2022 How can information about the hardware specifications of different actors be used to transfer knowledge between them? \u2022 To what extent can causal models help, for example, in integrating these hardware specifications (i.e. information about the \"data-producing mechanisms\")? 8 \u2022 How can information from the \"subjective perspective\" of an agent (i.e. the relationship between his sensory measurements and his actions) be merged with information from an \"external perspective\" (i.e. that of an engineer who sees the hardware specifications of an agent).The study is structured as follows: In Section 6.1, we describe the scenario, in particular the available heterogeneous information sources; in Section 6.2, we outline an information-integrating agent for this scenario; then in Section 5.3, we outline an intuitive example of scenario and method; and finally, in Section 5.4, we discuss the advantages and limitations of our particular thinking."}, {"heading": "6.1 Scenario", "text": "We consider a scenario in which a collection of self-driving cars (one could also think of robots) operate in a common environment. (For simplicity, we assume that the number of cars is small compared to the size of the environment, so that they do not affect each other.) We assume that some hardware components of the 8-part, causal reasoning could help that in the end we can determine the causal effects of an agent on his environment, and not just the correlational information, the algorithms for agents j1: 1, description D, specifications (spectra) k, experiences (ek1: t) k that trigger."}, {"heading": "6.2 Sketch of a method", "text": "We outline a method for the described scenario in algorithm 3."}, {"heading": "6.3 A toy example", "text": "In fact, it is the case that most of us are able to survive by ourselves if we do not follow the rules. (...) In fact, it is the case that they do not follow the rules. (...) In fact, it is the case that they do not follow the rules. (...) In fact, it is the case that they do not follow the rules. (...) In fact, it is the case that they do not follow the rules. (...) It is the case that they do not follow the rules. (...) It is the case that they do not follow the rules. (...) It is the case that they do not follow the rules. (...) It is as if they obey the rules. (...) It is as if they obey the rules. (...) It is as if they obey the rules. (...) It is as if they obey the rules."}, {"heading": "6.4 Discussion", "text": "The toy example in Section 6.3 shows how, in principle, integrating heterogeneous information could help some \"targeted\" self-driving cars make better decisions in situations that are not visited by themselves but by other \"source-based\" self-driving cars. It is important to note that all the information sources listed were necessary for this: the hardware specifications are necessary to understand F (t), the experience is necessary to infer fG, and the knowledge of independence (PS that does not affect G (t)) is necessary to transfer the knowledge of the force G (t) to different positions y between the cars. Note that the above scenario cannot be addressed using conventional RL approaches, as we transfer knowledge between agents of different hardware. Furthermore, methods such as LfD or transfer learning (see Sections 4.2 and 4.4) do not generally use information about hardware specifications of agents automatically."}, {"heading": "7 Outlook: future directions and open questions", "text": "Here we outline a possible agenda for future investigations and raise interesting open questions."}, {"heading": "7.1 Potential future directions", "text": "Another important aspect is the fact that the data is nothing less than an ability to understand the world and what it is doing."}, {"heading": "7.2 Open questions", "text": "It would also be interesting to examine how the following questions could be answered: \u2022 One of the main questions that led our investigation in Section 6 can be answered as follows: While the information relevant to an agent is usually in the form of the effects of his actions in certain situations, a lot of knowledge is formulated in a non-causal form: for example, road maps in various grains for self-driving cars. \u2022 How do these two forms of information relate? Is there a standard method of translating between them? In other words, how can different forms of information be translated into a model of the dynamics of the agent in the world. \u2022 Where is the boundary between additional heterogeneous information and prior knowledge? \u2022 How can the need for information integration be balanced with privacy restrictions? For example, one can imagine cases where the assignment of the experience of a source agent to the action of a target agent is in principle quite simple, but information collected by the source agent cannot or cannot be transmitted to the other, at least not completely relevant? \u2022 How can the problem of the current information be filtered between the environment and the problem of the current information be only relevant to the problem of the environment?"}, {"heading": "8 Conclusions", "text": "In this paper, we have investigated how experiments in complex simulated environments on the one hand and causal models on the other can help solve this problem. A next step would be to conduct more complex experiments, e.g. with agents of different \"hardware.\""}, {"heading": "9 Acknowledgments", "text": "The authors thank Mathew Monfort, Nicole Beckage, Roberto Calandra, Matthew Johnson, Tim Hutton, David Bignell, Daniel Tarlow, Chris Bishop and Andrew Blake for helpful discussions."}], "references": [{"title": "A survey of robot learning from demonstration", "author": ["Brenna D. Argall", "Sonia Chernova", "Manuela Veloso", "Brett Browning"], "venue": "Robotics and Autonomous Systems,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2009}, {"title": "Feedback systems: an introduction for scientists and engineers", "author": ["Karl Johan Astr\u00f6m", "Richard M Murray"], "venue": "Princeton university press,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2010}, {"title": "Causal inference from big data: Theoretical foundations and the data-fusion problem", "author": ["Elias Bareinboim", "Judea Pearl"], "venue": "Technical report, CALIFORNIA UNIV LOS ANGELES DEPT OF COMPUTER SCI- ENCE,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2015}, {"title": "The Malmo platform for artificial intelligence experimentation", "author": ["David Bignell", "Katja Hofmann", "Tim Hutton", "Matthew Johnson"], "venue": "IJ- CAI (to appear),", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2016}, {"title": "Multi-agent reinforcement learning: An overview\u2019, in Innovations in Multi-Agent Systems and Applications-1", "author": ["Lucian Bu\u015foniu", "Robert Babu\u0161ka", "Bart De Schutter"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2010}, {"title": "Human-level control through deep reinforcement learning", "author": ["Volodymyr Mnih", "Koray Kavukcuoglu", "David Silver", "Andrei A Rusu", "Joel Veness", "Marc G Bellemare", "Alex Graves", "Martin Riedmiller", "Andreas K Fidjeland", "Georg Ostrovski"], "venue": "Nature, 518(7540),", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "Consensus and cooperation in networked multi-agent systems", "author": ["Reza Olfati-Saber", "Alex Fax", "Richard M Murray"], "venue": "Proceedings of the IEEE,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2007}, {"title": "Causality", "author": ["J. Pearl"], "venue": "Cambridge University Press", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2000}, {"title": "Transportability of causal and statistical relations: A formal approach", "author": ["Judea Pearl", "Elias Bareinboim"], "venue": "Proceedings of the Twenty- Fifth National Conference on Artificial Intelligence. AAAI Press,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2011}, {"title": "Accelerating reinforcement learning through implicit imitation", "author": ["Bob Price", "Craig Boutilier"], "venue": "J. Artif. Int. Res.,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2003}, {"title": "Causation", "author": ["P. Spirtes", "C. Glymour", "R. Scheines"], "venue": "prediction, and search, MIT, Cambridge, MA, 2nd edn.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2000}, {"title": "Multiagent systems: A survey from a machine learning perspective", "author": ["Peter Stone", "Manuela Veloso"], "venue": "Autonomous Robots,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2000}, {"title": "Transfer learning for reinforcement learning domains: A survey", "author": ["Matthew E Taylor", "Peter Stone"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2009}, {"title": "A new learning paradigm: Learning using privileged information", "author": ["Vladimir Vapnik", "Akshay Vashist"], "venue": "Neural Networks,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2009}, {"title": "Making things happen: A theory of causal explanation", "author": ["James Woodward"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2005}], "referenceMentions": [{"referenceID": 3, "context": "For the experiments in Section 5 we will use the software Malmo, a simulated environment for experimentation with intelligent agents, that was introduced recently [4].", "startOffset": 163, "endOffset": 166}, {"referenceID": 7, "context": "Mathematically, a causal model [8, 11] M over", "startOffset": 31, "endOffset": 38}, {"referenceID": 10, "context": "Mathematically, a causal model [8, 11] M over", "startOffset": 31, "endOffset": 38}, {"referenceID": 0, "context": "According to [1], in learning from demonstrations (LfD), some \u201cteacher\u201d performs a trajectory which is recorded, and the goal is that a \u201clearner\u201d agent, based on this recording, infers and imitates (or utilizes) the teacher\u2019s \u201cpolicy\u201d (or the dynamics of the environment, or both).", "startOffset": 13, "endOffset": 16}, {"referenceID": 0, "context": "Central notions that [1] uses to analyze and distinguish various types of LfD problems are the record mapping, i.", "startOffset": 21, "endOffset": 24}, {"referenceID": 9, "context": "6 Note that there is some work on learning from observations only (not actions) of a \u201cteacher\u201d [10].", "startOffset": 95, "endOffset": 99}, {"referenceID": 11, "context": "In multi-agent systems, collections of agents acting in a shared environment are studied [12].", "startOffset": 89, "endOffset": 93}, {"referenceID": 6, "context": "One important task is collaboration between agents [7].", "startOffset": 51, "endOffset": 54}, {"referenceID": 4, "context": "Learning-based methods have been extensively studied [5].", "startOffset": 53, "endOffset": 56}, {"referenceID": 12, "context": "For instance, [14] consider an example where, in the well-known mountain car example, experience should be transferred although the motor of the car is changed.", "startOffset": 14, "endOffset": 18}, {"referenceID": 12, "context": "However, the scope of methods reviewed in [14] is on transferring observationaction recordings or things such as policies, value functions etc.", "startOffset": 42, "endOffset": 46}, {"referenceID": 5, "context": "Recently, the experimentation with intelligent agents in platforms based on computer games has become popular [6].", "startOffset": 110, "endOffset": 113}, {"referenceID": 8, "context": "The general integration and transfer of data (not focused on intelligent agents) using causal models has been studied by [9, 3].", "startOffset": 121, "endOffset": 127}, {"referenceID": 2, "context": "The general integration and transfer of data (not focused on intelligent agents) using causal models has been studied by [9, 3].", "startOffset": 121, "endOffset": 127}, {"referenceID": 13, "context": ", by [15].", "startOffset": 5, "endOffset": 9}, {"referenceID": 14, "context": ", by [16].", "startOffset": 5, "endOffset": 9}, {"referenceID": 1, "context": "We run Algorithm 2 with inputs y\u2217 0:L and a simple proportional controller [2] (for ctl ), where we tuned the proportional constant manually in previous experiments (but without providing q\u2217 0:L or the actions the human demonstrator took).", "startOffset": 75, "endOffset": 78}], "year": 2017, "abstractText": "The amount of digitally available but heterogeneous information about the world is remarkable, and new technologies such as self-driving cars, smart homes or the \u201cinternet of things\u201d will further increase it. In this paper we examine certain aspects of the problem of how such heterogeneous information can be harnessed by intelligent agents. We first discuss potentials and limitations of some existing approaches, followed by two investigations. The focus of the first investigation is on using the novel experimentation platform Malmo to obtain a better understanding of the problem. The focus of the second investigation is on understanding how information about the hardware of different agents (such as self-driving cars), the agents\u2019 sensory data, and physical or causal information can be utilized for knowledge transfer between agents and subsequent more data-efficient decision making. Finally, we present some thoughts on what a general theory for the problem could look like, and formulate open questions.", "creator": "LaTeX with hyperref package"}}}