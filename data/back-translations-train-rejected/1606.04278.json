{"id": "1606.04278", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Jun-2016", "title": "Exact and efficient top-K inference for multi-target prediction by querying separable linear relational models", "abstract": "Many complex multi-target prediction problems that concern large target spaces are characterised by a need for efficient prediction strategies that avoid the computation of predictions for all targets explicitly. Examples of such problems emerge in several subfields of machine learning, such as collaborative filtering, multi-label classification, dyadic prediction and biological network inference. In this article we analyse efficient and exact algorithms for computing the top-$K$ predictions in the above problem settings, using a general class of models that we refer to as separable linear relational models. We show how to use those inference algorithms, which are modifications of well-known information retrieval methods, in a variety of machine learning settings. Furthermore, we study the possibility of scoring items incompletely, while still retaining an exact top-K retrieval. Experimental results in several application domains reveal that the so-called threshold algorithm is very scalable, performing often many orders of magnitude more efficiently than the naive approach.", "histories": [["v1", "Tue, 14 Jun 2016 09:41:27 GMT  (1024kb,D)", "http://arxiv.org/abs/1606.04278v1", null]], "reviews": [], "SUBJECTS": "cs.IR cs.LG", "authors": ["michiel stock", "krzysztof dembczynski", "bernard de baets", "willem waegeman"], "accepted": false, "id": "1606.04278"}, "pdf": {"name": "1606.04278.pdf", "metadata": {"source": "CRF", "title": "Exact and efficient top-K inference for multi-target prediction by querying separable linear relational models", "authors": ["Michiel Stock", "Bernard De Baets", "Willem Waegeman"], "emails": ["firstname.lastname@ugent.be", "krzysztof.dembczynski@cs.put.poznan.pl"], "sections": [{"heading": null, "text": "Keywords Top K retrieval \u00b7 Exact conclusion \u00b7 Precision in K \u00b7 Multi-target prediction"}, {"heading": "1 Introduction and formal problem description", "text": "This year, it is more than ever before in the history of the city in which we find ourselves."}, {"heading": "3 Application domains and relationships with SEP-LR models", "text": "In this section, we will illustrate that many multi-target prediction methods are specific instances of SEP-LR models and the conclusions discussed in the previous sections. The methods we will look at in Section 3.1 are often used in the area of Recommender Systems. The methods we will discuss in Sections 3.2 and 3.3 are used in other areas as well as in other areas, as we can guarantee that the correct Top-K prediction methods are realized based on SEP-LR models. If a non-SEP-LR model is used, the algorithms of Section 2 can be used to reduce runtime at no cost in predictive performance, as we can guarantee that the correct Top-K predictions will be realized. If a non-SEP-LR model is used, it can be considered to switch to an SEP-LR model that performs queries potentially faster."}, {"heading": "4 Experimental results", "text": "This year is the highest in the history of the country."}, {"heading": "5 Conclusions and future perspectives", "text": "In this paper, we have discussed three commonly applicable methods to find the most relevant targets across a wide range of multi-target prediction problems. Experimental results clearly confirm that the threshold algorithm is quite scalable, and often many orders of magnitude are more efficient than the naive approach. We can therefore conclude that this algorithm is very well suited to query many popular machine learning methods."}, {"heading": "Acknowledgments", "text": "Part of this work was carried out with the help of the Stevin supercomputer infrastructure of the University of Ghent, financed by the University of Ghent, the Hercules Foundation and the Flemish Government - EMI Department."}], "references": [{"title": "Fast top-k retrieval for model based recommendation", "author": ["D. Agarwal", "M. Gurevich"], "venue": "Proceedings of the Fifth ACM International Conference on Web Search and Data Mining, pp. 483\u2013492", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "Multi-label learning with millions of labels: Recommending advertiser bid phrases for web pages", "author": ["R. Agrawal", "A. Gupta", "Y. Prabhu", "M. Varma"], "venue": "Proceedings of the 22nd International Conference on World Wide Web, pp. 13\u201324", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2013}, {"title": "Flavor network and the principles of food pairing", "author": ["Y.Y. Ahn", "S.E. Ahnert", "J.P. Bagrow", "A.L. Barab\u00e1si"], "venue": "Scientific Reports 1(196)", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2011}, {"title": "Unifying collaborative and content-based filtering", "author": ["J. Basilico", "T. Hofmann"], "venue": "Proceedings of the 21st International Conference on Machine Learning, pp. 9\u201316", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2004}, {"title": "Exploiting task relatedness for multiple task learning", "author": ["S. Ben-David", "R. Schuller"], "venue": "Proceedings of the 16th Annual Conference on Computational Learning Theory and 7th Kernel Workshop, pp. 567\u2013580", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2003}, {"title": "Kernel methods for predicting protein-protein interactions", "author": ["A. Ben-Hur", "W.S. Noble"], "venue": "Bioinformatics 21(Suppl 1), i38\u201346", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2005}, {"title": "Multidimensional binary search trees used for associative searching", "author": ["J.L. Bentley"], "venue": "Communications of the ACM 18, 509\u2013517", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1975}, {"title": "Cover trees for nearest neighbor", "author": ["A. Beygelzimer", "S. Kakade", "J. Langford"], "venue": "Proceedings of the 23rd International Conference on Machine Learning, pp. 97\u2013104", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2006}, {"title": "Top-down induction of clustering trees", "author": ["H. Blockeel", "L. De Raedt", "J. Ramon"], "venue": "Proceedings of the Fifteenth International Conference on Machine Learning, pp. 55\u201363", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1998}, {"title": "Multitask learning", "author": ["R. Caruana"], "venue": "Machine learning 75, 41\u201375", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1997}, {"title": "Personalized recommendation on dynamic content using predictive bilinear models", "author": ["W. Chu", "S.T. Park"], "venue": "Proceedings of the 18th International Conference on World Wide Web, pp. 691\u2013700", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2009}, {"title": "Data-driven recipe completion using machine learning methods", "author": ["M. De Clercq", "M. Stock", "B. De Baets", "W. Waegeman"], "venue": "Trends in Food Science & Technology 49, 1\u201313", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2015}, {"title": "miRNA target prediction through modeling quantitative and qualitative miRNA binding site information in a stacked model structure", "author": ["A. De Paepe", "G. Van Peer", "M. Stock", "P.J. Volders", "J. Vandesompele", "B. De Baets", "W. Waegeman"], "venue": "Nucleic Acid Research Submitted", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2015}, {"title": "On label dependence and loss minimization in multi-label classification", "author": ["K. Dembczynski", "W. Waegeman", "W. Cheng", "E. H\u00fcllermeier"], "venue": "Machine Learning 88(1-2), 5\u201345", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2012}, {"title": "Similarity-based machine learning methods for predicting drug-target interactions: a brief review", "author": ["H. Ding", "I. Takigawa", "H. Mamitsuka", "S. Zhu"], "venue": "Briefings in Bioinformatics 14(5), 734\u201347", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2013}, {"title": "On the Nystr\u00f6m method for approximating a Gram matrix for improved kernel-based learning", "author": ["P. Drineas", "M. Mahoney"], "venue": "Journal of Machine Learning Research 6, 2153\u20132175", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2005}, {"title": "Using the triangle inequality to accelerate k-means", "author": ["C. Elkan"], "venue": "Proceedings of the 20th International Conference on Machine Learning, pp. 147\u2013153", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2003}, {"title": "Learning multiple tasks with kernel methods", "author": ["T. Evgeniou"], "venue": "Journal of Machine Learning Research 6, 615\u2013637", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2005}, {"title": "Regularized multi-task learning", "author": ["T. Evgeniou", "M. Pontil"], "venue": "Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 109\u2013117", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2004}, {"title": "Combining fuzzy information from multiple systems", "author": ["R. Fagin"], "venue": "Journal of Computer and System Sciences 58(1), 83\u201399", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1999}, {"title": "Optimal aggregation algorithms for middleware", "author": ["R. Fagin", "A. Lotem", "M. Naor"], "venue": "Journal of Computer and System Sciences 66(4), 614\u2013656", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2003}, {"title": "Querying big data: bridging theory and practice", "author": ["W. Fan", "J.P. Huai"], "venue": "Journal of Computer Science and Technology 29(5), 849\u2013869", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2014}, {"title": "Predictive indexing for fast search", "author": ["S. Goel", "J. Langford", "A. Strehl"], "venue": "Advances in Neural Information Processing Systems, pp. 505\u2013512", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2009}, {"title": "Predicting drug-target interactions from chemical and genomic kernels using Bayesian matrix factorization", "author": ["M. G\u00f6nen"], "venue": "Bioinformatics 28(18), 2304\u201310", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2012}, {"title": "The Elements of Statistical Learning", "author": ["T. Hastie", "R. Tibshirani", "J. Friedman"], "venue": "Springer Series in Statistics. Springer New York Inc., New York, NY, USA", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2001}, {"title": "Large-scale prediction of protein-protein interactions from structures", "author": ["M. Hue", "M. Riffle", "J.P. Vert", "W.S. Noble"], "venue": "BMC Bioinformatics 11(144), 1\u201310", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2010}, {"title": "A survey of top-k query processing techniques in relational database systems", "author": ["I.F. Ilyas", "G. Beskales", "M.A. Soliman"], "venue": "ACM Computing Surveys 40(4)", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2008}, {"title": "Virtual screening of GPCRs: an in silico chemogenomics approach", "author": ["L. Jacob", "B. Hoffmann", "V. Stoven", "J.P. Vert"], "venue": "BMC Bioinformatics 9(1), 1\u201316", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2008}, {"title": "Protein-ligand interaction prediction: an improved chemogenomics approach", "author": ["L. Jacob", "J.P. Vert"], "venue": "Bioinformatics 24(19), 2149\u20132156", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2008}, {"title": "A dirty model for multi-task learning", "author": ["A. Jalali", "S. Sanghavi", "P. Ravikumar", "C. Ruan"], "venue": "Neural Information Processing Symposium, pp. 964\u2013972", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2010}, {"title": "Efficient retrieval of recommendations in a matrix factorization framework", "author": ["N. Koenigstein", "P. Ram", "Y. Shavitt"], "venue": "Proceedings of the 21st ACM International Conference on Information and Knowledge Management, pp. 535\u2013544", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2012}, {"title": "A comparative study of collaborative filtering algorithms", "author": ["J. Lee", "M. Sun", "G. Lebanon"], "venue": "ACM Transactions on the Web 5(1), 1\u201327", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2011}, {"title": "Introduction to Information Retrieval", "author": ["C.D. Manning", "P. Raghavan", "H. Sch\u00fctze"], "venue": "Cambridge University Press, New York, NY, USA", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2008}, {"title": "Fast label embeddings for extremely large output spaces", "author": ["P. Mineiro", "N. Karampatziakis"], "venue": "CoRR abs/1412.6", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2014}, {"title": "Five balltree construction algorithms", "author": ["S.M. Omohundro"], "venue": "Science 51, 1\u201322", "citeRegEx": "35", "shortCiteRegEx": null, "year": 1989}, {"title": "Efficient regularized least-squares algorithms for conditional ranking on relational data", "author": ["T. Pahikkala", "A. Airola", "M. Stock", "B. De Baets", "W. Waegeman"], "venue": "Machine Learning 93(2-3), 321\u2013356", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2013}, {"title": "A two-step learning approach for solving full and almost full cold start problems in dyadic prediction", "author": ["T. Pahikkala", "M. Stock", "A. Airola", "T. Aittokallio", "B. De Baets", "W. Waegeman"], "venue": "Lecture Notes in Computer Science 8725, 517\u2013532", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2014}, {"title": "LSHTC: a benchmark for large-scale text classification", "author": ["I. Partalas", "A. Kosmopoulos", "N. Baskiotis", "T. Artieres", "G. Paliouras", "E. Gaussier", "I. Androutsopoulos", "M.R. Amini", "P. Galinari"], "venue": "submitted to CoRR pp. 1\u20139", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2015}, {"title": "Item-based collaborative filtering recommendation algorithms", "author": ["B. Sarwar", "G. Karypis", "J. Konstan", "J. Reidl"], "venue": "Proceedings of the Tenth International Conference on World Wide Web - WWW \u201901, pp. 285\u2013295. ACM Press, New York, New York, USA", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2001}, {"title": "Kernel Methods for Pattern Analysis", "author": ["J. Shawe-Taylor", "N. Cristianini"], "venue": "Cambridge University Press", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2004}, {"title": "Asymmetric lsh (ALSH) for sublinear time maximum inner product search (MIPS)", "author": ["A. Shrivastava", "P. Li"], "venue": "Advances in Neural Information Processing Systems 27, pp. 2321\u20132329", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2014}, {"title": "Improved asymmetric locality sensitive hashing (ALSH) for maximum inner product search (MIPS)", "author": ["A. Shrivastava", "P. Li"], "venue": "Proceedings of the Conference on Uncertainty in Artificial Intelligence", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2015}, {"title": "Identification of functionally related enzymes by learning-torank methods", "author": ["M. Stock", "T. Fober", "E. H\u00fcllermeier", "S. Glinca", "G. Klebe", "T. Pahikkala", "A. Airola", "B. De Baets", "W. Waegeman"], "venue": "IEEE Transactions on Computational Biology and Bioinformatics 11(6), 1157\u20131169", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2014}, {"title": "A survey of collaborative filtering techniques", "author": ["X. Su", "T.M. Khoshgoftaar"], "venue": "Advances in Artificial Intelligence 2009, 1\u201319", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2009}, {"title": "Matrix factorization and neighbor based algorithms for the netflix prize problem", "author": ["G. Tak\u00e1cs", "I. Pil\u00e1szy", "B. N\u00e9meth", "D. Tikk"], "venue": "Proceedings of the 2008 ACM conference on Recommender systems, pp. 267\u2013274. ACM Press, New York, New York, USA", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2008}, {"title": "Probabilistic principal component analysis", "author": ["M. Tipping", "C. Bishop"], "venue": "Journal of the Royal Statistical Society 3, 611\u2013622", "citeRegEx": "46", "shortCiteRegEx": null, "year": 1997}, {"title": "Multi-label classification: an overview", "author": ["G. Tsoumakas", "I. Katakis"], "venue": "International Journal of Data Warehousing & Mining 3(3), 1\u201313", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2007}, {"title": "A new pairwise kernel for biological network inference with support vector machines", "author": ["J.P. Vert", "J. Qiu", "W.S. Noble"], "venue": "BMC Bioinformatics 8(S-10), 1\u201310", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2007}, {"title": "Matrix factorization techniques for recommender systems", "author": ["C. Volinsky"], "venue": "pp. 30\u201337", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2009}, {"title": "A kernel-based framework for learning graded relations from data", "author": ["W. Waegeman", "T. Pahikkala", "A. Airola", "T. Salakoski", "M. Stock", "B. De Baets"], "venue": "IEEE Transactions on Fuzzy Systems 20(6), 1090\u20131101", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2012}, {"title": "Predicting target-ligand interactions using protein ligand-binding site and ligand substructures", "author": ["C. Wang", "J. Liu", "F. Luo", "Z. Deng", "Q.N. Hu"], "venue": "BMC Systems Biology 9(S1), S2", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2015}, {"title": "Kernel dependency estimation", "author": ["J. Weston", "O. Chapelle", "A. Elisseeff", "B. Sch\u00f6lkopf", "V. Vapnik"], "venue": "Advances in Neural Information Processing Systems, vol. 39, pp. 440\u201350", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2006}, {"title": "Drug-target interaction prediction from chemical, genomic and pharmacological data in an integrated framework", "author": ["Y. Yamanishi", "M. Kotera", "M. Kanehisa", "S. Goto"], "venue": "Bioinformatics 26(12), i246\u201354", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2010}, {"title": "Inverted files for text search engines", "author": ["J. Zobel", "A. Moffat"], "venue": "ACM Computing Surveys 38(2)", "citeRegEx": "54", "shortCiteRegEx": null, "year": 2006}], "referenceMentions": [{"referenceID": 8, "context": "[9]), Big Data problems nowadays routinely deal with very large output spaces.", "startOffset": 0, "endOffset": 3}, {"referenceID": 44, "context": "[45,49].", "startOffset": 0, "endOffset": 7}, {"referenceID": 48, "context": "[45,49].", "startOffset": 0, "endOffset": 7}, {"referenceID": 1, "context": "[2,14,47].", "startOffset": 0, "endOffset": 9}, {"referenceID": 13, "context": "[2,14,47].", "startOffset": 0, "endOffset": 9}, {"referenceID": 46, "context": "[2,14,47].", "startOffset": 0, "endOffset": 9}, {"referenceID": 3, "context": "For example, in content-based filtering, one would recommend items to users based on user profiles and side information about items [4,11].", "startOffset": 132, "endOffset": 138}, {"referenceID": 10, "context": "For example, in content-based filtering, one would recommend items to users based on user profiles and side information about items [4,11].", "startOffset": 132, "endOffset": 138}, {"referenceID": 28, "context": "on feature descriptions of proteins and ligands [29,51].", "startOffset": 48, "endOffset": 55}, {"referenceID": 50, "context": "on feature descriptions of proteins and ligands [29,51].", "startOffset": 48, "endOffset": 55}, {"referenceID": 27, "context": "[28].", "startOffset": 0, "endOffset": 4}, {"referenceID": 43, "context": "[44].", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "Existing methods for speeding up nearest neighbor search, such as [17], are hence not directly applicable to maximum inner product search.", "startOffset": 66, "endOffset": 70}, {"referenceID": 6, "context": "One approach to compute the maximum inner product would be to partition the target space using efficient data structures such as k-d trees [7], ball trees [35], cover trees [8] or branch-and-bound search techniques [31].", "startOffset": 139, "endOffset": 142}, {"referenceID": 34, "context": "One approach to compute the maximum inner product would be to partition the target space using efficient data structures such as k-d trees [7], ball trees [35], cover trees [8] or branch-and-bound search techniques [31].", "startOffset": 155, "endOffset": 159}, {"referenceID": 7, "context": "One approach to compute the maximum inner product would be to partition the target space using efficient data structures such as k-d trees [7], ball trees [35], cover trees [8] or branch-and-bound search techniques [31].", "startOffset": 173, "endOffset": 176}, {"referenceID": 30, "context": "One approach to compute the maximum inner product would be to partition the target space using efficient data structures such as k-d trees [7], ball trees [35], cover trees [8] or branch-and-bound search techniques [31].", "startOffset": 215, "endOffset": 219}, {"referenceID": 40, "context": "Recently, a locality-sensing hashing method for maximum inner product search has been developed [41,42].", "startOffset": 96, "endOffset": 103}, {"referenceID": 41, "context": "Recently, a locality-sensing hashing method for maximum inner product search has been developed [41,42].", "startOffset": 96, "endOffset": 103}, {"referenceID": 0, "context": "Another approximate method would be to cluster the queries x in several groups, for which rankings of targets y can be precomputed by means of predictive indices and related data structures [1, 23].", "startOffset": 190, "endOffset": 197}, {"referenceID": 22, "context": "Another approximate method would be to cluster the queries x in several groups, for which rankings of targets y can be precomputed by means of predictive indices and related data structures [1, 23].", "startOffset": 190, "endOffset": 197}, {"referenceID": 26, "context": "strongly related problem as (2) is often observed in information retrieval [27].", "startOffset": 75, "endOffset": 79}, {"referenceID": 53, "context": "When queries and documents have sparse representations and relevance is defined by means of cosine similarity, one can reduce the computational complexity of retrieval by using data structures such as inverted indices [54].", "startOffset": 218, "endOffset": 222}, {"referenceID": 19, "context": "In particular, we are analyzing in this paper Fagin\u2019s algorithm and extensions thereof [20].", "startOffset": 87, "endOffset": 91}, {"referenceID": 19, "context": "We show that the problem can be solved more efficiently using exact methods that are well known in database research and information retrieval, namely Fagin\u2019s algorithm [20] and the so-called threshold algorithm [21].", "startOffset": 169, "endOffset": 173}, {"referenceID": 20, "context": "We show that the problem can be solved more efficiently using exact methods that are well known in database research and information retrieval, namely Fagin\u2019s algorithm [20] and the so-called threshold algorithm [21].", "startOffset": 212, "endOffset": 216}, {"referenceID": 0, "context": ", zR belong to the interval [0, 1] and Q has to be an increasing aggregation operator, i.", "startOffset": 28, "endOffset": 34}, {"referenceID": 0, "context": "The resulting values zr do not necessarily belong to the interval [0, 1], but they can be transformed accordingly for a fixed query x and set of targets Y.", "startOffset": 66, "endOffset": 72}, {"referenceID": 20, "context": "It has been shown in [21] that the threshold algorithm is instanceoptimal, meaning that the algorithm cannot be outperformed by any other algorithm when wild guesses are not allowed.", "startOffset": 21, "endOffset": 25}, {"referenceID": 20, "context": "1 in [21] by transforming problem statement (2) to the original problem setting of Fagin, as discussed more formally above, and observing that this leads to searching for the max-", "startOffset": 5, "endOffset": 9}, {"referenceID": 20, "context": "We refer to [21] for more details.", "startOffset": 12, "endOffset": 16}, {"referenceID": 21, "context": "Sorting the lists can be done offline and parallel extensions can be easily implemented [22].", "startOffset": 88, "endOffset": 92}, {"referenceID": 20, "context": "This modification is known as the halted threshold algorithm [21].", "startOffset": 61, "endOffset": 65}, {"referenceID": 38, "context": "[39].", "startOffset": 0, "endOffset": 4}, {"referenceID": 31, "context": "This is referred to as model-based collaborative filtering and includes models such as Bayesian networks, clustering and matrix factorization methods [32].", "startOffset": 150, "endOffset": 154}, {"referenceID": 24, "context": "As a result, the connection with SEP-LR models holds for basically all matrix decomposition algorithms, inclucing non-negative matrix factorization, independent component analysis, sparse principal component analysis and singular value decomposition methods [25].", "startOffset": 258, "endOffset": 262}, {"referenceID": 13, "context": "targets, respectively [14,47].", "startOffset": 22, "endOffset": 29}, {"referenceID": 46, "context": "targets, respectively [14,47].", "startOffset": 22, "endOffset": 29}, {"referenceID": 4, "context": "Multi-task learning then further unifies those subfields, and further extends them to problems where not all targets are observed (or relevant) for all instances [5,10].", "startOffset": 162, "endOffset": 168}, {"referenceID": 9, "context": "Multi-task learning then further unifies those subfields, and further extends them to problems where not all targets are observed (or relevant) for all instances [5,10].", "startOffset": 162, "endOffset": 168}, {"referenceID": 46, "context": "This method is known as the binary relevance method in the multi-label classification community [47].", "startOffset": 96, "endOffset": 100}, {"referenceID": 51, "context": "[52]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[18,19,30].", "startOffset": 0, "endOffset": 10}, {"referenceID": 18, "context": "[18,19,30].", "startOffset": 0, "endOffset": 10}, {"referenceID": 29, "context": "[18,19,30].", "startOffset": 0, "endOffset": 10}, {"referenceID": 39, "context": "An interesting example from this point of view is the partial least squares (PLS) algorithm, which projects the features onto a lowerdimensional subspace [40].", "startOffset": 154, "endOffset": 158}, {"referenceID": 5, "context": "They are particularly popular in certain domains of bioinformatics, such as the prediction of protein-protein interactions [6,26,48], enzyme function prediction [43] and proteochemometrics [24,28,53].", "startOffset": 123, "endOffset": 132}, {"referenceID": 25, "context": "They are particularly popular in certain domains of bioinformatics, such as the prediction of protein-protein interactions [6,26,48], enzyme function prediction [43] and proteochemometrics [24,28,53].", "startOffset": 123, "endOffset": 132}, {"referenceID": 47, "context": "They are particularly popular in certain domains of bioinformatics, such as the prediction of protein-protein interactions [6,26,48], enzyme function prediction [43] and proteochemometrics [24,28,53].", "startOffset": 123, "endOffset": 132}, {"referenceID": 42, "context": "They are particularly popular in certain domains of bioinformatics, such as the prediction of protein-protein interactions [6,26,48], enzyme function prediction [43] and proteochemometrics [24,28,53].", "startOffset": 161, "endOffset": 165}, {"referenceID": 23, "context": "They are particularly popular in certain domains of bioinformatics, such as the prediction of protein-protein interactions [6,26,48], enzyme function prediction [43] and proteochemometrics [24,28,53].", "startOffset": 189, "endOffset": 199}, {"referenceID": 27, "context": "They are particularly popular in certain domains of bioinformatics, such as the prediction of protein-protein interactions [6,26,48], enzyme function prediction [43] and proteochemometrics [24,28,53].", "startOffset": 189, "endOffset": 199}, {"referenceID": 52, "context": "They are particularly popular in certain domains of bioinformatics, such as the prediction of protein-protein interactions [6,26,48], enzyme function prediction [43] and proteochemometrics [24,28,53].", "startOffset": 189, "endOffset": 199}, {"referenceID": 14, "context": "Some authors, such as [15], claim that pairwise methods in kernel form are not viable for large-scale problems as they scale O(NM) in memory and O(NM) in time complexity for most algorithms.", "startOffset": 22, "endOffset": 26}, {"referenceID": 35, "context": "For some models though, when the kernels can be factorised using the Kronecker product, the memory and time complexity reduce to O(N + M) and O(N + M), respectively, see [36,50].", "startOffset": 170, "endOffset": 177}, {"referenceID": 49, "context": "For some models though, when the kernels can be factorised using the Kronecker product, the memory and time complexity reduce to O(N + M) and O(N + M), respectively, see [36,50].", "startOffset": 170, "endOffset": 177}, {"referenceID": 36, "context": "Recently, a method called two-step regularised least squares was proposed, as an intuitive way to bring this paradigm to practice [37].", "startOffset": 130, "endOffset": 134}, {"referenceID": 45, "context": "For model-based collaborative filtering, we applied matrix factorization by means of probabilistic PCA [46], having as advantage that a computationally efficient expectation maximisation algorithm can be used.", "startOffset": 103, "endOffset": 107}, {"referenceID": 2, "context": "html 4 This dataset [3] is strictly speaking not a collaborative filtering benchmark dataset, but it can be treated using a similar workflow.", "startOffset": 20, "endOffset": 23}, {"referenceID": 11, "context": "See [12] for an recommender system built using this dataset.", "startOffset": 4, "endOffset": 8}, {"referenceID": 39, "context": "As a feature representation, we used weighted subsequence kernels [40], which define similarity between sequences based on subsequences of a fixed length.", "startOffset": 66, "endOffset": 70}, {"referenceID": 15, "context": "We performed an approximation inspired by the Nystr\u00f6m method [16], a method to approximate the decomposition of large kernel matrices.", "startOffset": 61, "endOffset": 65}, {"referenceID": 20, "context": "We can conclude that it could make sense in some cases to use the halted threshold algorithm (see [21]) which stops when the computational resources have run out (e.", "startOffset": 98, "endOffset": 102}, {"referenceID": 37, "context": "This dataset was downloaded from the Kaggle \u2018Large Scale Hierarchical Text Classification\u2019 challenge [38].", "startOffset": 101, "endOffset": 105}, {"referenceID": 32, "context": "The word counts were transformed into term frequency-inverse document frequencies [33].", "startOffset": 82, "endOffset": 86}, {"referenceID": 33, "context": "This approach is similar to that performed by [34] on this dataset.", "startOffset": 46, "endOffset": 50}, {"referenceID": 12, "context": "[13]).", "startOffset": 0, "endOffset": 4}], "year": 2016, "abstractText": "Many complex multi-target prediction problems that concern large target spaces are characterised by a need for efficient prediction strategies that avoid the computation of predictions for all targets explicitly. Examples of such problems emerge in several subfields of machine learning, such as collaborative filtering, multi-label classification, dyadic prediction and biological network inference. In this article we analyse efficient and exact algorithms for computing the top-K predictions in the above problem settings, using a general class of models that we refer to as separable linear relational models. We show how to use those inference algorithms, which are modifications of well-known information retrieval methods, in a variety of machine learning settings. Furthermore, we study the possibility of scoring items incompletely, while still retaining an exact top-K retrieval. Experimental results in several application domains reveal that the so-called threshold algorithm is very scalable, performing often many orders of magnitude more efficiently than the naive approach.", "creator": "LaTeX with hyperref package"}}}