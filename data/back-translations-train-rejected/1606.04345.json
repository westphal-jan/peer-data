{"id": "1606.04345", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Jun-2016", "title": "Digits that are not: Generating new types through deep neural nets", "abstract": "For an artificial creative agent, an essential driver of the search for novelty is a value function which is often provided by the system designer or users. We argue that an important barrier for progress in creativity research is the inability of these systems to develop their own notion of value for novelty. We propose a notion of knowledge-driven creativity that circumvent the need for an externally imposed value function, allowing the system to explore based on what it has learned from a set of referential objects. The concept is illustrated by a specific knowledge model provided by a deep generative autoencoder. Using the described system, we train a knowledge model on a set of digit images and we use the same model to build coherent sets of new digits that do not belong to known digit types.", "histories": [["v1", "Tue, 14 Jun 2016 13:29:13 GMT  (1692kb,D)", "http://arxiv.org/abs/1606.04345v1", "preprint ICCC'16, International Conference on Computational Creativity"]], "COMMENTS": "preprint ICCC'16, International Conference on Computational Creativity", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["ak{\\i}n kazak\\c{c}{\\i}and mehdi cherti", "bal\\'azs k\\'egl"], "accepted": false, "id": "1606.04345"}, "pdf": {"name": "1606.04345.pdf", "metadata": {"source": "CRF", "title": "Digits that are not: Generating new types through deep neural nets", "authors": ["Ak\u0131n Kazak\u00e7\u0131", "Mehdi Cherti", "Bal\u00e1zs K\u00e9gl"], "emails": ["akin.kazakci@mines-paristech.fr", "balazs.kegl}@gmail.com"], "sections": [{"heading": "1 Introduction", "text": "It is a commonly accepted view in creativity research that creativity is a process by which novel and valuable combinations of ideas are produced (Runco and Jaeger 2012). This view carries a tension whose essence can be expressed in the following question: How can one determine the value of something new? If a new object is substantially different from the previous objects in its category, it might be difficult to determine its value, if the value of an object can be easily determined, it might be the case that the object is not really new. Indeed, there are experimental results in which novelty is a better predictor of creativity than value (Diedrich et al. 2015) and that the brain processes novelty in a certain way (Beaucousin et al. 2011), suggesting that the relationship is far from trivial. In art, the difficulty of determining the value of an object is omnipresent. An emblematic example is Marcel Duchamp's Le Grand Verre."}, {"heading": "2 Generative models for computational creativity", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 The purpose of a generative model", "text": "In the literature of computer creativity, the exploration of the new has often been considered in the context of art (Boden and Edmonds 2009; McCormack et al. 2014). Despite different debates and nuances about terminology, such work has generally been categorized under the term generative art (or generative models). As defined by (Boden and Edmonds 2009), a generative model is essentially a rules-based system, though one whose outcome is hopefully not known in advance, for example due to non-determinism or too many degrees of freedom in the parameters of systems (see also (Galanter 2012)). A large variety of such systems has been built up, starting in the 1990s (Todd and Latham 1991; Sims 1991), based on even earlier foundations (Nees 1969; Edmonds 1969). The definition, complexity, and capabilities offered by such models have developed consistently."}, {"heading": "2.2 The knowledge of a generative system", "text": "Defining a generative model as a rules-based system (Boden and Edmonds 2009) leads to a special relationship to knowledge. It is fair to say that such formalized rules are archetypes of consolidated knowledge. If such rules are firmly programmed by the system designer into the creative agent, the system becomes an inference engine, not a creativity engine. Rules naturally anchor knowledge about a domain and its associated value system, which originates from the system designer rather than being discovered by the system designer himself. Allowing the system to learn its own rules system by examining a series of objects in a particular domain solves part of this problem: the value system becomes dependent on the learning algorithm (instead of the system designer). In our system, we use a learning mechanism in which the creative agent is forced to disassemble and reconstruct the examples he sees, ensuring that the benefits of the features and transformations that are directly embedded in the system's ability to construct rules."}, {"heading": "2.3 Knowledge-driven exploration of value", "text": "Unlike human artists, who are capable of exploring both the novel and the value of the new, such mathematical models often consider the generation of the new to be a function of value independent of the search process. Either they operate on the basis of a fixed set of evaluation criteria or they shift the evaluation to external feedback. In the first case, a typical example would be a traditional fitness function. In the second case, a typical example would be an interactive genetic algorithm (Takagi 2001) in which the information about value is provided by an oracle (e.g. a human expert). In both cases, the system becomes a construction machine in which the generation of values is handled by external mechanisms and not by the system itself. This can be regarded as a fundamental barrier to the exploration of creativity (Kazakc \u0131 2014), which we will not call an icon."}, {"heading": "3 Learning to generate", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Data-driven generative models", "text": "Unlike other computerization methods, which aim to generate new object descriptions, disciplines such as statistics and machine learning seek to establish solid foundations and formal methods for modeling a given set of object descriptions (i.e., data).These disciplines do not consider data generation as a scientific issue: the data generated in these fields are developed as fixed (given) but unknown formal tools that are scientifically and systematically researched. Indeed, generative models have a long and rich history in these fields. The goal of generative models in statistics and machine learning is the exemplary distribution of fixed but unknown probabilities p x. It is usually assumed that the algorithm generates a sample D = {x1}, generates, independently (generated), independently (generated)."}, {"heading": "3.2 Deep neural networks", "text": "In machine learning literature, the introduction of deep neural networks (DNNs) is considered a major breakthrough (LeCun, Bengio and Hinton 2015).The basic idea of a DNN is the use of multiple hidden layers. Subsequent layers edit the output of previous layers to sequentially transform the original representation of objects, with the goal of building a specific representation that is useful for a specific task (i.e., classification).Multilayer learning has dramatically improved the state of the art in many highly effective application areas, such as speech recognition, visual object recognition and natural language processing.Another useful attribute of deep neural networks is that they can learn a hierarchy of representations associated with layers of the net.In fact, a neural network with L layers can be formalized as a sequence of coders (c1,.,., cL).The representation in the first layer is < 1 = 1 and the object is gegeared (L)."}, {"heading": "3.3 Autoassociative neural nets (autoencoders)", "text": "These neural networks consist of an encoder part and a decoder part. In a certain sense, an autoencoder learns to decompose the object. Our approach is based on a particular technique described in (Bengio et al. 2013). We first learn about the input space by dissecting an auto-associative neural network (a.k.a. autoencoder) by using the objects D = {x1,. xn}, then we apply a technique that designs a generative function (simulator).Autoencoders are convenient because they are designed to obtain a representation y = c (x) of the object x and a decoder x (y)."}, {"heading": "4 Generating from the learned model", "text": "In this section, we present and comment on some experimental results. First, we provide some illustrations that give an insight into the usefulness of the representations obtained through a deep web in the search for something new. Then, we present the method by which we create new image objects, based on the formal approach described in Section 3."}, {"heading": "4.1 Searching for new types: with and without knowledge", "text": "We argued in earlier sections that the combinatorial search of objects has disadvantages over a search process driven by knowledge of the same objects obtained by the system itself. If learning is implemented through a deep neural network, this knowledge is encoded in the form of multiple layers of representations and transformations from layer to layer. To demonstrate the effect of knowledge of these search methods, we have applied x simple disturbance operations to the display space instead of the original object space. Figure 3 illustrates the results of these disturbances. In the original display space, crossover and mutation operators generate loud artifacts, and the population quickly becomes unrecognisable, which, unless the desired effect is exactly the noise, is unlikely to produce any new objects (let alone types) unless a fitness function that drives the search (which we are trying to avoid) is given. In comparison, the same operators applied to the code y that produces the deeper forms, which are apparently less loud and less coherent."}, {"heading": "4.2 Method for generating new objects from a learned model", "text": "To generate new objects in a knowledge-based way, we first train a generative autoencoder to extract properties useful for the construction of such objects. To train the autoencoder f, we use the MNIST (Lecun and Cortes 2012) dataset, which contains handwritten grayscale. It contains 70,000 images of size 28 x 28. Once the model has learned to construct objects it has seen, it has also learned useful transformations that can be queried to generate new objects. Autoassociative networks have existed since the 1980s (Rumelhart, Hinton and Williams 1986; Baldi and Hornik 1989; Kramer 1991), yet it has been discovered that they can be used to generate new objects (Bengio et al. 2013; Kamyshanska and Memisevic 2013). The procedure is the following: We start with a random image x0 = r and reconstruct it xf (x) using the network trained."}, {"heading": "4.3 Generating new types", "text": "If the generative approach is repeated from multiple random images {r1,.., rn}, the network creates different objects {x1,.., xn}. When these objects (with the original MNIST images) are projected into a two-dimensional space by stochastic embedding (van der Maaten and Hinton 2008), the space is not uniformly filled: it has dense clusters, which means that structurally similar objects tend to regroup; see Figure 5. We recover these clusters quantitatively using k-means clusters in the attribute space {y1,..., yn}. Figure 6 contains extracts from these clusters. They consist of similar symbols that form a coherent set of objects that can be perceived as new types."}, {"heading": "5 Discussion and perspectives", "text": "It is possible to compare our work with several other published results. First, the generation of new through the use of neural networks is an old idea (Todd 1992; Thaler 1998). There are two major differences between our approach and theirs. First, we have an artificial behavior that does not fit into learned categories, but creates objects with artistic value. This experimental setup is designed to provide tools to investigate how a creative agent can build an evaluation function for new types of objects. Second, we explicitly aim to establish a bi-directional link between generative models and generative models within statistics and machine models."}, {"heading": "6 Summary", "text": "The culmination of these principles is that artificial creativity can be driven by knowledge, that a machine can extract itself from a set of objects that define a domain. Faced with this knowledge, a creative agent can explore new types of objects and build its own value function through novelty. This principle is in contrast to existing systems in which the system designer or the audience imposes a value function on the system, for example through a certain fitness function. We have shown that when an artificial creative agent extracts his own domain knowledge in the form of traits that are useful for reconstructing the objects of the domain, he is able to explore novelties that go beyond the scope of what he has seen by systematically exploring unknown species."}, {"heading": "7 Acknowledgments", "text": "We thank our anonymous arbitrators for their helpful comments. This work was partially supported by the HPC Center of Champagne-Ardenne ROMEO. This work was funded by P2IO LabEx (ANR-10-LABX-0038) as part of Investissements dAvenir (ANR-11-IDEX-0003-01), managed by the French research agency ANR."}], "references": [{"title": "and Hornik", "author": ["P. Baldi"], "venue": "K.", "citeRegEx": "Baldi and Hornik 1989", "shortCiteRegEx": null, "year": 1989}, {"title": "Erp evidence of a meaningfulness impact on visual global/local processing: when meaning captures attention", "author": ["Beaucousin"], "venue": null, "citeRegEx": "Beaucousin,? \\Q2011\\E", "shortCiteRegEx": "Beaucousin", "year": 2011}, {"title": "Generalized denoising auto-encoders as generative models", "author": ["Bengio"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Bengio,? \\Q2013\\E", "shortCiteRegEx": "Bengio", "year": 2013}, {"title": "E", "author": ["M.A. Boden", "Edmonds"], "venue": "A.", "citeRegEx": "Boden and Edmonds 2009", "shortCiteRegEx": null, "year": 2009}, {"title": "and Lipson", "author": ["J. Clune"], "venue": "H.", "citeRegEx": "Clune and Lipson 2011", "shortCiteRegEx": null, "year": 2011}, {"title": "A", "author": ["J. Diedrich", "M. Benedek", "E. Jauk", "Neubauer"], "venue": "C.", "citeRegEx": "Diedrich et al. 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "A", "author": ["Gatys, L.A.", "Ecker"], "venue": "S.; and Bethge, M.", "citeRegEx": "Gatys. Ecker. and Bethge 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "Generative adversarial nets", "author": ["Goodfellow"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Goodfellow,? \\Q2014\\E", "shortCiteRegEx": "Goodfellow", "year": 2014}, {"title": "and Weil", "author": ["A. Hatchuel"], "venue": "B.", "citeRegEx": "Hatchuel and Weil 2009", "shortCiteRegEx": null, "year": 2009}, {"title": "G", "author": ["Hinton"], "venue": "E.; Osindero, S.; and Teh, Y.-W.", "citeRegEx": "Hinton. Osindero. and Teh 2006", "shortCiteRegEx": null, "year": 2006}, {"title": "K", "author": ["Jennings"], "venue": "E.", "citeRegEx": "Jennings 2010", "shortCiteRegEx": null, "year": 2010}, {"title": "and Memisevic", "author": ["H. Kamyshanska"], "venue": "R.", "citeRegEx": "Kamyshanska and Memisevic 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "Simulation of design reasoning based on ck theory: a model and an example application", "author": ["Kazakci"], "venue": "In DS 60: Proceedings of DESIGN", "citeRegEx": "Kazakci,? \\Q2010\\E", "shortCiteRegEx": "Kazakci", "year": 2010}, {"title": "M", "author": ["Kramer"], "venue": "A.", "citeRegEx": "Kramer 1991", "shortCiteRegEx": null, "year": 1991}, {"title": "and Cortes", "author": ["Y. Lecun"], "venue": "C.", "citeRegEx": "Lecun and Cortes 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "K", "author": ["J. Lehman", "Stanley"], "venue": "O.", "citeRegEx": "Lehman and Stanley 2011", "shortCiteRegEx": null, "year": 2011}, {"title": "Experiments in computational aesthetics", "author": ["Romero Machado", "P. Manaris 2008] Machado", "J. Romero", "B. Manaris"], "venue": "In The art of artificial evolution", "citeRegEx": "Machado et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Machado et al\\.", "year": 2008}, {"title": "B", "author": ["A. Makhzani", "Frey"], "venue": "J.", "citeRegEx": "Makhzani and Frey 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "Ten questions concerning generative computer art", "author": ["McCormack"], "venue": null, "citeRegEx": "McCormack,? \\Q2014\\E", "shortCiteRegEx": "McCormack", "year": 2014}, {"title": "Inceptionism: Going deeper into neural networks", "author": ["Olah Mordvintsev", "A. Tyka 2015] Mordvintsev", "C. Olah", "M. Tyka"], "venue": "Google Research Blog. Retrieved June", "citeRegEx": "Mordvintsev et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Mordvintsev et al\\.", "year": 2015}, {"title": "and Doncieux", "author": ["Mouret", "J.-B."], "venue": "S.", "citeRegEx": "Mouret and Doncieux 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "A", "author": ["Nguyen"], "venue": "M.; Yosinski, J.; and Clune, J.", "citeRegEx": "Nguyen. Yosinski. and Clune 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "R", "author": ["D.E. Rumelhart", "G.E. Hinton", "Williams"], "venue": "J.", "citeRegEx": "Rumelhart. Hinton. and Williams 1986", "shortCiteRegEx": null, "year": 1986}, {"title": "G", "author": ["M.A. Runco", "Jaeger"], "venue": "J.", "citeRegEx": "Runco and Jaeger 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "G", "author": ["R. Salakhutdinov", "Hinton"], "venue": "E.", "citeRegEx": "Salakhutdinov and Hinton 2009", "shortCiteRegEx": null, "year": 2009}, {"title": "K", "author": ["J. Secretan", "N. Beato", "D.B. D Ambrosio", "A. Rodriguez", "A. Campbell", "Stanley"], "venue": "O.", "citeRegEx": "Secretan et al. 2008", "shortCiteRegEx": null, "year": 2008}, {"title": "S", "author": ["Thaler"], "venue": "L.", "citeRegEx": "Thaler 1998", "shortCiteRegEx": null, "year": 1998}, {"title": "A", "author": ["Theis, L.", "Oord"], "venue": "v. d.; and Bethge, M.", "citeRegEx": "Theis. Oord. and Bethge 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "and Latham", "author": ["S. Todd"], "venue": "W.", "citeRegEx": "Todd and Latham 1991", "shortCiteRegEx": null, "year": 1991}, {"title": "P", "author": ["Todd"], "venue": "M.", "citeRegEx": "Todd 1989", "shortCiteRegEx": null, "year": 1989}, {"title": "P", "author": ["Todd"], "venue": "M.", "citeRegEx": "Todd 1992", "shortCiteRegEx": null, "year": 1992}, {"title": "Visualizing data using t-SNE", "author": ["van der Maaten", "L. Hinton 2008] van der Maaten", "G. Hinton"], "venue": "The Journal of Machine Learning Research", "citeRegEx": "Maaten et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Maaten et al\\.", "year": 2008}, {"title": "G", "author": ["Wiggins"], "venue": "A.", "citeRegEx": "Wiggins 2006", "shortCiteRegEx": null, "year": 2006}], "referenceMentions": [], "year": 2016, "abstractText": "For an artificial creative agent, an essential driver of the search for novelty is a value function which is often provided by the system designer or users. We argue that an important barrier for progress in creativity research is the inability of these systems to develop their own notion of value for novelty. We propose a notion of knowledge-driven creativity that circumvent the need for an externally imposed value function, allowing the system to explore based on what it has learned from a set of referential objects. The concept is illustrated by a specific knowledge model provided by a deep generative autoencoder. Using the described system, we train a knowledge model on a set of digit images and we use the same model to build coherent sets of new digits that do not belong to known", "creator": "LaTeX with hyperref package"}}}