{"id": "1606.04351", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Jun-2016", "title": "TwiSE at SemEval-2016 Task 4: Twitter Sentiment Classification", "abstract": "This paper describes the participation of the team \"TwiSE\" in the SemEval 2016 challenge. Specifically, we participated in Task 4, namely \"Sentiment Analysis in Twitter\" for which we implemented sentiment classification systems for subtasks A, B, C and D. Our approach consists of two steps. In the first step, we generate and validate diverse feature sets for twitter sentiment evaluation, inspired by the work of participants of previous editions of such challenges. In the second step, we focus on the optimization of the evaluation measures of the different subtasks. To this end, we examine different learning strategies by validating them on the data provided by the task organisers. For our final submissions we used an ensemble learning approach (stacked generalization) for Subtask A and single linear models for the rest of the subtasks. In the official leaderboard we were ranked 9/35, 8/19, 1/11 and 2/14 for subtasks A, B, C and D respectively.\\footnote{We make the code available for research purposes at \\url{", "histories": [["v1", "Tue, 14 Jun 2016 13:36:00 GMT  (24kb,D)", "http://arxiv.org/abs/1606.04351v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.IR cs.LG", "authors": ["georgios balikas", "massih-reza amini"], "accepted": false, "id": "1606.04351"}, "pdf": {"name": "1606.04351.pdf", "metadata": {"source": "CRF", "title": "TwiSE at SemEval-2016 Task 4: Twitter Sentiment Classification", "authors": ["Georgios Balikas", "Massih-Reza Amini"], "emails": ["firstnane.lastname@imag.fr"], "sections": [{"heading": "1 Introduction", "text": "Over the past decade, short-term forms of communication, such as microblogging, have become widespread and ubiquitous, with which users share a variety of information, but the information about the world around them has generated a great deal of research interest (Nakov et al., 2016; Rosenthal et al., 2015). We provide the code for research (NLP) and the Machine Learning (ML) communities, which are challenges arising from the use of slang, abbreviations, texts, etc. They pose a number of different challenges to nature. (NLP) and the Machine Learning (ML) communities."}, {"heading": "2 Feature Engineering", "text": "Our approach is based on traditional N-gram extraction and the use of sentiment lexicons that describe the sentiment polarity of unigrams and / or bigrams. We used Pythons Scikit-Learn (Pedregosa et al., 2011) and NLTK (Bird et al., 2009) for data preprocessing, purification and tokenization 3, as well as for most learning steps."}, {"heading": "2.1 Feature Extraction", "text": "Similar to (Kiritchenko et al., 2014b), we have extracted features based on the lexical content of each tweet \u2022 we have also used sentimental-specific lexicon. Features extracted for each tweet include: \u2022 N-grams with N-symbols; \u2022 # of negated exclamation marks, # of question marks, # of exclamation marks and question marks; \u2022 # of capitalized words and # of long words; \u2022 of negated contexts; negation has also affected the N-gram characteristics by transforming a word w into a negated context; # of positive emoticons and # of long words; # of negative context; negativity has also affected the characteristics of N-grams by transforming a word w into a negated context; # of positive characteristics of NEG, of positive emoticons and # of long words; # of negative context; and # of negative context by transforming a word w into a negated context; # of positive characteristics of NEG, of positive emoticons, of emoticons, of emoticons, of an emoticons, of an emoticons, of an emoticons, and of an emoticons / https."}, {"heading": "2.2 Feature Representation and Transformation", "text": "We describe the different representations of extracted N-grams and character grams that we compared as we optimized our performance in each of the subtasks of the classification. In the rest of this subsection, we refer to both N-grams and 4http: / / www.cs.cmu.edu / ark / TweetNLP / character-grams as words in the general sense of letter strings. We evaluated two ways of representing such characteristics: (i) a sack-of-words representation, i.e. for each tweet, a sparse vector of the dimension | V | is generated, where | V | is the word size, and (ii) a hashing function, i.e. a fast and space-efficient way of vectorizing characteristics, i.e. converting arbitrary characteristics into indices into a vector (Weinberger et al., 2009). We found that the performance of hashing representations was better."}, {"heading": "3 The Learning Step", "text": "After extracting the features, we experimented with several families of classifiers, such as linear models, maximum margin models, closest approaches, and trees. We evaluated their performance using data provided by the organizers, which were already divided into training, validation, and testing. Table 1 shows information about the tweets we downloaded. From the early validation programs, we found that the two most competitive models were logistic regression from the linear model family and support vector machines (SVMs) from the maximum margin model family. It should be noted that this is consistent with previous research (Mohammad et al., 2013; Bu \ufffd chner and Stein, 2015)."}, {"heading": "3.1 Subtask A", "text": "Subtask A concerns a multiclass classification problem in which the general polarity of tweets must be classified into one of three classes: \"positive,\" \"negative\" and \"neutral,\" each of which denotes the general polarity of the tweet. The rating unit used for this task is the macro F1 measurement, which is calculated only for the positive and negative classes (Nakov et al., 2016).Inspired by SemEval 2015 Task 10's Wining System (Booker and Stein, 2015), we opted for an ensemble learning approach that is calculated only for the positive and negative classes (Nakov et al., our goal is to generate a set of models that work just as well as individual models, and (ii) select a subset of models of (i) that generate different outputs and combine them with an ensemble step that will result in a lower generalization error."}, {"heading": "3.2 Subtask B", "text": "Subtask B is a binary classification problem where a tweet that you know relates to a specific topic needs to be classified to determine whether the tweet conveys a positive or negative sentiment toward the topic. The rating size proposed by the organizers for this subtask is the macro averaged callback (MaR) versus the positive or negative class. Our participation is based on a single model. We used SVMs with a linear kernel and the Liblinear Optimizer. We used the full functionality described in Section 2 after we excluded the distributed embeddings because we found in our local validation experiments that they actually impaired performance. Similar to Subtask A and due to the imbalance of the problem, we use weighting for the classes of the problem. Note that we do not consider the topic of the tweet and classify the general polarity of the tweet. Therefore, we ignore the case where each tweet consists of more than one part of the expression of the different polarities."}, {"heading": "3.3 Subtask C", "text": "Sub-task C concerns an ordinal classification problem. In this sub-task, the ordinal classification differs from the standard multiclass classification in that the classes are ordered and the error takes this order into account so that not all errors are weighted equally. In the tweet classification problem, for example, a classifier who would assign class \"1\" to an instance of class \"2\" is less punished compared to a classifier who assigns \"-1\" as a class. In this direction, the evaluation unit proposed by the organizers is the macro-averaged mean absolute error. Similar to sub-task B, we submitted the results of a single model and we classified the tweets according to their general polarity, ignoring the given topics. Instead of one of the ordinary classification methods proposed in the bibliography, we use a standardized multiclass approach."}, {"heading": "3.4 Subtask D", "text": "Sub-task D is a binary quantification problem. In view of a series of tweets that are known to relate to a specific topic, it is particularly important to estimate the distribution of tweets between the positive and negative classes. For example, since you have 100 tweets about the new iPhone, you have to estimate the fractions of positive and negative tweets. Organizers suggested a smoothed version of KullbackLeibler Divergence (KLD) as a measure of the sub-task. We use a classification and counting approach for this task (Bella et al., 2010; Forman, 2008), i.e. we first classify each of the tweets and then count the instances that belong to each class. To this end, we compare two approaches, both trained on the characteristics of Section 2, without the distributed representations: the standard multiclass SVM and a structure that SVM learns that KLD directly optimizes (Esuli and Sebastiani, 2015)."}, {"heading": "4 The evaluation framework", "text": "Before announcing the results we have received, we explain our validation strategy and the steps we have taken in aligning our models. In each of the subtasks, we have used only the data realized for the 2016 edition of the Challenge. Our validation consisted of the following steps: 1. Training based on the published training data, 2. Validation based on the validation data, 3. Re-validation in merging the test and trial data (if applicable) after retraining and validation data. For each parameter, we have selected its value by averaging the optimal parameters relative to the results of the above steps (2) and (3). It should be noted that we have relied strictly on the data published as part of the 2016 edition of SemEval; we have not used past data. We are now presenting the performance we have achieved both in our local evaluation schemes as well as in the official results of the above-mentioned data (2 steps) and the official results of the Challenge (2), as we have published the results of the organizers, the last part of the challenge, and the official results of the 3."}, {"heading": "5 Future Work", "text": "This was our first contact with the task of sentiment analysis, and we achieved satisfactory results. We relied on features proposed in previous SemEval challenges, and we examined the performance of various classification algorithms. In our future work, we will examine directions in both feature engineering and the algorithmic / learning part. First, we want to treat tweets with a finer granularity. As discussed in Section 3, we have classified the general polarity of the tweet in each of the tasks, ignoring cases where the tweets referred to two or more people. In the same line, we plan to improve our mechanism for dealing with negation. We have used a simple mechanism in which a negative context is defined as a phrase from a negative word to a punctuation mark. However, our error analysis revealed that punctuation is rarely used in tweets. Finally, we plan to investigate ways to integrate more data into our approaches, as we only use the data from this output of a comprehensive set of assessments to help us better understand the direction of a phrase."}, {"heading": "Acknowledgments", "text": "We thank the organizers of Task 4 of SemEval 2016 for providing the data, guidelines and infrastructure, as well as the anonymous reviewers for their insightful comments."}], "references": [{"title": "Quantification via probability estimators", "author": ["Bella et al.2010] Antonio Bella", "Cesar Ferri", "Jos\u00e9 Hern\u00e1ndez-Orallo", "Maria Jose Ramirez-Quintana"], "venue": "In Data Mining (ICDM),", "citeRegEx": "Bella et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Bella et al\\.", "year": 2010}, {"title": "Webis: An ensemble for twitter sentiment detection", "author": ["B\u00fcchner", "Benno Stein"], "venue": null, "citeRegEx": "B\u00fcchner et al\\.,? \\Q2015\\E", "shortCiteRegEx": "B\u00fcchner et al\\.", "year": 2015}, {"title": "On the algorithmic implementation of multiclass kernel-based vector machines", "author": ["Crammer", "Singer2002] Koby Crammer", "Yoram Singer"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Crammer et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Crammer et al\\.", "year": 2002}, {"title": "Optimizing text quantifiers for multivariate loss functions", "author": ["Esuli", "Sebastiani2015] Andrea Esuli", "Fabrizio Sebastiani"], "venue": "ACM Transactions on Knowledge Discovery from Data (TKDD),", "citeRegEx": "Esuli et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Esuli et al\\.", "year": 2015}, {"title": "Liblinear: A library for large linear classification", "author": ["Fan et al.2008] Rong-En Fan", "Kai-Wei Chang", "Cho-Jui Hsieh", "Xiang-Rui Wang", "Chih-Jen Lin"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Fan et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Fan et al\\.", "year": 2008}, {"title": "Quantifying counts and costs via classification. Data Mining and Knowledge Discovery, 17(2):164\u2013206", "author": ["George Forman"], "venue": null, "citeRegEx": "Forman.,? \\Q2008\\E", "shortCiteRegEx": "Forman.", "year": 2008}, {"title": "Tweet sentiment: From classification to quantification", "author": ["Gao", "Sebastiani2015] Wei Gao", "Fabrizio Sebastiani"], "venue": "In Proceedings of the 2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining", "citeRegEx": "Gao et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Gao et al\\.", "year": 2015}, {"title": "Part-of-speech tagging for twitter: Annotation", "author": ["Gimpel et al.2011] Kevin Gimpel", "Nathan Schneider", "Brendan O\u2019Connor", "Dipanjan Das", "Daniel Mills", "Jacob Eisenstein", "Michael Heilman", "Dani Yogatama", "Jeffrey Flanigan", "Noah A Smith"], "venue": null, "citeRegEx": "Gimpel et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Gimpel et al\\.", "year": 2011}, {"title": "Twitter sentiment classification using distant supervision", "author": ["Go et al.2009] Alec Go", "Richa Bhayani", "Lei Huang"], "venue": "CS224N Project", "citeRegEx": "Go et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Go et al\\.", "year": 2009}, {"title": "Ordinal regression methods: survey and experimental study", "author": ["M. P\u00e9rez-Ortiz", "J. S\u00e1nchez-Monedero", "F. Fernandez-Navarro", "C. Herv\u00e1s-Mart\u0131\u0301nez"], "venue": "IEEE Transactions on Knowledge and Data Engineering,", "citeRegEx": "Guti\u00e9rrez et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Guti\u00e9rrez et al\\.", "year": 2015}, {"title": "Mining and summarizing customer reviews", "author": ["Hu", "Liu2004] Minqing Hu", "Bing Liu"], "venue": "In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "Hu et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Hu et al\\.", "year": 2004}, {"title": "Aggregating local image descriptors into compact codes", "author": ["Jegou et al.2012] H. Jegou", "F. Perronnin", "M. Douze", "J. Sanchez", "P. Perez", "C. Schmid"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on,", "citeRegEx": "Jegou et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Jegou et al\\.", "year": 2012}, {"title": "Nrccanada-2014: Detecting aspects and sentiment in customer reviews", "author": ["Xiaodan Zhu", "Colin Cherry", "Saif Mohammad"], "venue": "In Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval", "citeRegEx": "Kiritchenko et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kiritchenko et al\\.", "year": 2014}, {"title": "Sentiment analysis of short informal texts", "author": ["Xiaodan Zhu", "Saif M Mohammad"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Kiritchenko et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kiritchenko et al\\.", "year": 2014}, {"title": "Multi-dimensional sentiment analysis with learned representations", "author": ["Maas et al.2011] Andrew L Maas", "Andrew Y Ng", "Christopher Potts"], "venue": null, "citeRegEx": "Maas et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Maas et al\\.", "year": 2011}, {"title": "A comparison of algorithms for maximum entropy parameter estimation", "author": ["Robert Malouf"], "venue": "In proceedings of the 6th conference on Natural language learning-Volume", "citeRegEx": "Malouf.,? \\Q2002\\E", "shortCiteRegEx": "Malouf.", "year": 2002}, {"title": "Emotions evoked by common words and phrases: Using mechanical turk to create an emotion lexicon", "author": ["Mohammad", "Turney2010] Saif M Mohammad", "Peter D Turney"], "venue": "In Proceedings of the NAACL HLT 2010 workshop on computational approaches", "citeRegEx": "Mohammad et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Mohammad et al\\.", "year": 2010}, {"title": "Nrc-canada: Building the state-of-the-art in sentiment analysis of tweets. arXiv preprint arXiv:1308.6242", "author": ["Svetlana Kiritchenko", "Xiaodan Zhu"], "venue": null, "citeRegEx": "Mohammad et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mohammad et al\\.", "year": 2013}, {"title": "SemEval-2016 task 4: Sentiment analysis in Twitter", "author": ["Nakov et al.2016] Preslav Nakov", "Alan Ritter", "Sara Rosenthal", "Veselin Stoyanov", "Fabrizio Sebastiani"], "venue": "In Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval 2016),", "citeRegEx": "Nakov et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Nakov et al\\.", "year": 2016}, {"title": "Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods", "author": ["John Platt"], "venue": "Advances in large margin classifiers,", "citeRegEx": "Platt,? \\Q1999\\E", "shortCiteRegEx": "Platt", "year": 1999}, {"title": "Sarcasm detection on twitter: A behavioral modeling approach", "author": ["Reza Zafarani", "Huan Liu"], "venue": "In Proceedings of the Eighth ACM International Conference on Web Search and Data Mining,", "citeRegEx": "Rajadesingan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Rajadesingan et al\\.", "year": 2015}, {"title": "Semeval-2015 task 10: Sentiment analysis in twitter", "author": ["Preslav Nakov", "Svetlana Kiritchenko", "Saif M Mohammad", "Alan Ritter", "Veselin Stoyanov"], "venue": "Proceedings of SemEval-2015", "citeRegEx": "Rosenthal et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Rosenthal et al\\.", "year": 2015}, {"title": "Learning sentiment-specific word embedding for twitter sentiment classification", "author": ["Tang et al.2014] Duyu Tang", "Furu Wei", "Nan Yang", "Ming Zhou", "Ting Liu", "Bing Qin"], "venue": "In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguis-", "citeRegEx": "Tang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Tang et al\\.", "year": 2014}, {"title": "Feature hashing for large scale multitask learning", "author": ["Anirban Dasgupta", "John Langford", "Alex Smola", "Josh Attenberg"], "venue": "In Proceedings of the 26th Annual International Conference on Machine Learning,", "citeRegEx": "Weinberger et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Weinberger et al\\.", "year": 2009}, {"title": "Recognizing contextual polarity in phrase-level sentiment analysis. In Proceedings of the conference on human language technology and empirical methods in natural language", "author": ["Janyce Wiebe", "Paul Hoffmann"], "venue": null, "citeRegEx": "Wilson et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Wilson et al\\.", "year": 2005}, {"title": "Dual coordinate descent methods for logistic regression and maximum entropy models", "author": ["Yu et al.2011] Hsiang-Fu Yu", "Fang-Lan Huang", "Chih-Jen Lin"], "venue": "Machine Learning,", "citeRegEx": "Yu et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Yu et al\\.", "year": 2011}, {"title": "Transforming classifier scores into accurate multiclass probability estimates", "author": ["Zadrozny", "Elkan2002] Bianca Zadrozny", "Charles Elkan"], "venue": "In Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "Zadrozny et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Zadrozny et al\\.", "year": 2002}], "referenceMentions": [{"referenceID": 18, "context": "However, information concerning one\u2019s sentiment on the world around her has attracted a lot of research interest (Nakov et al., 2016; Rosenthal et al., 2015).", "startOffset": 113, "endOffset": 157}, {"referenceID": 21, "context": "However, information concerning one\u2019s sentiment on the world around her has attracted a lot of research interest (Nakov et al., 2016; Rosenthal et al., 2015).", "startOffset": 113, "endOffset": 157}, {"referenceID": 14, "context": "the vocabulary used (slang, abbreviations, emojis) (Maas et al., 2011), the short size, and the complex linguistic phenomena such as sarcasm (Rajadesingan et al.", "startOffset": 51, "endOffset": 70}, {"referenceID": 20, "context": ", 2011), the short size, and the complex linguistic phenomena such as sarcasm (Rajadesingan et al., 2015) that often occur.", "startOffset": 78, "endOffset": 105}, {"referenceID": 18, "context": "We present, here, our participation in Task 4 of SemEval 2016 (Nakov et al., 2016), namely Senti-", "startOffset": 62, "endOffset": 82}, {"referenceID": 22, "context": "preprocessing and feature extraction step, where we implemented and tested different feature sets proposed by participants of the previous editions of SemEval challenges (Tang et al., 2014; Kiritchenko et al., 2014a), and the learning step, where we inves-", "startOffset": 170, "endOffset": 216}, {"referenceID": 7, "context": "html \u2022 Part-of-speech (POS) tags (Gimpel et al., 2011) and their occurrences partitioned regarding the positive and negative contexts.", "startOffset": 33, "endOffset": 54}, {"referenceID": 24, "context": "\u2022 manual sentiment lexicons: the Bing liu\u2019s lexicon (Hu and Liu, 2004), the NRC emotion lexicon (Mohammad and Turney, 2010), and the MPQA lexicon (Wilson et al., 2005),", "startOffset": 146, "endOffset": 167}, {"referenceID": 8, "context": "\u2022 positional sentiment lexicons: sentiment 140 lexicon (Go et al., 2009) and the Hashtag Sentiment Lexicon (Kiritchenko et al.", "startOffset": 55, "endOffset": 72}, {"referenceID": 22, "context": "For each tweet we also used the distributed representations provided by (Tang et al., 2014) using the min, max and average composition functions on the vector representations of the words of each tweet.", "startOffset": 72, "endOffset": 91}, {"referenceID": 23, "context": "turning arbitrary features into indices in a vector (Weinberger et al., 2009).", "startOffset": 52, "endOffset": 77}, {"referenceID": 11, "context": ", x \u03b1 d ) (Jegou et al., 2012).", "startOffset": 10, "endOffset": 30}, {"referenceID": 17, "context": "It is to be noted that this is in line with the previous research (Mohammad et al., 2013; B\u00fcchner and Stein, 2015).", "startOffset": 66, "endOffset": 114}, {"referenceID": 18, "context": "The evaluation measure used for the subtask is the Macro-F1 measure, calculated only for the Positive and Negative classes (Nakov et al., 2016).", "startOffset": 123, "endOffset": 143}, {"referenceID": 4, "context": "To solve the optimization problems of SVMs we used the Liblinear solvers (Fan et al., 2008).", "startOffset": 73, "endOffset": 91}, {"referenceID": 25, "context": "being a limited memory quasi Newton method for general unconstrained optimization problems (Yu et al., 2011).", "startOffset": 91, "endOffset": 108}, {"referenceID": 15, "context": "To attack the multiclass problem, we selected among the traditional one-vs-rest approach, the crammer-singer approach for SVMs (Crammer and Singer, 2002), or the multinomial approach for Logistic Regression (also known as MaxEnt classifier), where the multinomial loss is minimised across the entire probability distribution (Malouf, 2002).", "startOffset": 325, "endOffset": 339}, {"referenceID": 9, "context": "We evaluated a selection of methods described in (Pedregosa-Izquierdo, 2015) and in (Guti\u00e9rrez et al., 2015).", "startOffset": 84, "endOffset": 108}, {"referenceID": 0, "context": "We apply a classify and count approach for this task (Bella et al., 2010; Forman, 2008), that is we first classify each of the tweets and we then count the", "startOffset": 53, "endOffset": 87}, {"referenceID": 5, "context": "We apply a classify and count approach for this task (Bella et al., 2010; Forman, 2008), that is we first classify each of the tweets and we then count the", "startOffset": 53, "endOffset": 87}], "year": 2016, "abstractText": "This paper describes the participation of the team \u201cTwiSE\u201d in the SemEval 2016 challenge. Specifically, we participated in Task 4, namely \u201cSentiment Analysis in Twitter\u201d for which we implemented sentiment classification systems for subtasks A, B, C and D. Our approach consists of two steps. In the first step, we generate and validate diverse feature sets for twitter sentiment evaluation, inspired by the work of participants of previous editions of such challenges. In the second step, we focus on the optimization of the evaluation measures of the different subtasks. To this end, we examine different learning strategies by validating them on the data provided by the task organisers. For our final submissions we used an ensemble learning approach (stacked generalization) for Subtask A and single linear models for the rest of the subtasks. In the official leaderboard we were ranked 9/35, 8/19, 1/11 and 2/14 for subtasks A, B, C and D respectively.1", "creator": "LaTeX with hyperref package"}}}