{"id": "1606.04552", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Jun-2016", "title": "A New Approach to Dimensionality Reduction for Anomaly Detection in Data Traffic", "abstract": "The monitoring and management of high-volume feature-rich traffic in large networks offers significant challenges in storage, transmission and computational costs. The predominant approach to reducing these costs is based on performing a linear mapping of the data to a low-dimensional subspace such that a certain large percentage of the variance in the data is preserved in the low-dimensional representation. This variance-based subspace approach to dimensionality reduction forces a fixed choice of the number of dimensions, is not responsive to real-time shifts in observed traffic patterns, and is vulnerable to normal traffic spoofing. Based on theoretical insights proved in this paper, we propose a new distance-based approach to dimensionality reduction motivated by the fact that the real-time structural differences between the covariance matrices of the observed and the normal traffic is more relevant to anomaly detection than the structure of the training data alone. Our approach, called the distance-based subspace method, allows a different number of reduced dimensions in different time windows and arrives at only the number of dimensions necessary for effective anomaly detection. We present centralized and distributed versions of our algorithm and, using simulation on real traffic traces, demonstrate the qualitative and quantitative advantages of the distance-based subspace approach.", "histories": [["v1", "Tue, 14 Jun 2016 20:29:50 GMT  (523kb)", "http://arxiv.org/abs/1606.04552v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.CR cs.NI", "authors": ["tingshan huang", "harish sethu", "nagarajan kandasamy"], "accepted": false, "id": "1606.04552"}, "pdf": {"name": "1606.04552.pdf", "metadata": {"source": "CRF", "title": "A New Approach to Dimensionality Reduction for Anomaly Detection in Data Traffic", "authors": ["Tingshan Huang", "Harish Sethu", "Nagarajan Kandasamy"], "emails": [], "sections": [{"heading": null, "text": "In fact, it is in such a way that we are able to put ourselves in another world, in which we put ourselves in another world, in which we put ourselves in another world, in which we put ourselves in another world, in which we put ourselves in another world, in which we find ourselves in another world, in which we find ourselves in another world, in which we put ourselves in another world, in which we put ourselves in another world, in which we put ourselves in which we put ourselves in which we put ourselves in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we, in which we live, in which we, in which we live, in which we, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we, in which we live, in which we, in which we live, in which we live, in which we, in which we, in which we live, in which we live, in which we, in which we live, in which we live, in which we live, in which we, in which we live, in which we, in which we live, in which we, in which we live, in which we live, in which we live, in which we, in which we, in which we, in which we, in which we, in which we, we live, in which we, in which we, in which we live, in which we, in which we, in which we, in which we, in which we"}, {"heading": "II. PROBLEM STATEMENT AND CONTRIBUTIONS", "text": "In fact, it is so that most of them are able to outdo themselves, and that they are able to outdo themselves, \"he told the German Press Agency.\" It's not as if, \"he said,\" as if. \""}, {"heading": "III. RELATED WORK", "text": "This year, it is only a matter of time before an agreement is reached."}, {"heading": "IV. THE METRIC", "text": "Let N specify the number of characters in the dataset of interest, and let B and A specify the two N \u00b7 N covariance matrices to compare. Let a1,..., aN, and b1,.. bN specify the eigenvectors of B and B. In the following, the operator symbol \"\u00d7,\" used between two matrices or vectors, denotes the matrix product."}, {"heading": "A. The subspace distance", "text": "Describe the angle between the partial space, which is composed of the first kA main components of \u0442A, a1,.., akA and the partial space, which is composed of the first kB main components of \u0442B, b1,..., bkB. We refer to this angle between the partial spaces as the partial space distance, which has a range between 0 and 90 degrees. We have: sin \u03b8kA, kB (A, B) = \u0451TkA, kB (A, B). Therefore, TkA, kB (A, B) are the matrix norm and TkA, kB (A, B) is the part of [b1,.., bkB] orthogonal to [a1,.., akA]. Therefore, TkA, kB (A, B) = (I \u2212 kA \u00d7 a \u2032 i) [b1,]."}, {"heading": "B. The maximum subspace distance", "text": "To compare the two principal matrices, we quantify the difference between successA and successB as the maximum value of the angle \u03b8kA, kB (A, B), where 1 \u2264 kA \u2264 N and 1 \u2264 kB \u2264 N: \u03b8max = max 1 \u2264 kA, kB \u2264 N \u03b8kA, kB (A, B) (4) In this paper, we refer to \u03b8max as the maximum subspace distance, which serves as our measure for detecting anomalies and quantifying the difference between the two matrices. If kA and kB have values that maximize succakkA, kB (A, B), the two sets of main components, [a1,..., akA] and [b1,..., bkB] can be used as the distinguishing features of covariance matrices, such as the maximum subspace distances and the corresponding subspace distances as metrics."}, {"heading": "V. THE CENTRALIZED ALGORITHM", "text": "In view of the high calculation costs involved in determining the maximum partial space distance, we present in this section an algorithm that estimates the measurement quantity with sufficient accuracy for a successful anomaly. Our solution is based on four key ideas: (i) Allows kA = kB in our search for the maximum partial space distance, (ii) reduces the problem to finding only the first major component of a matrix at all times, (iii) uses the power iteration method to approximate the first major components, and finally (iv) uses heuristics to approximate the value of \u03b8max."}, {"heading": "A. The rationale behind allowing kA = kB", "text": "In the approach set out in this paper, we limit our search for \u03b8max to cases where kA = kB. Our reasoning is based on the following theorem 1. The proof for this can be found in the appendix. Theorem 1. If for some kA and kB \u03b8kA, kB (A, B) = \u03b8max, then k, 1 \u2264 k \u2264 N exists, so that \u03b8k, k (A, B) = \u03b8max.If we allow kA = kB to find the maximum partial space distance, the search space from N2 to N. We refer to the value of k, for which successk, k (A, B) is the maximum partial space distance as the optimal partial space dimension."}, {"heading": "B. Subspace distance and the projection matrix", "text": "We define a N \u00b7 N projection matrix P from {b1,.., bN} to {a1,.., aN} as: Pi, j = < ai, bj > = a \u2032 ibj (5), where < \u00b7, \u00b7 > is the point product of two vectors.According to Theorem 2 below, which we show in the appendix, the smallest singular value of its submatrix P is formed as an equation. (5) and its submatrix P1: k, 1: k has an accuracy k (P1: k, 1: k) as its smallest singular value. Theorem 2: When a N \u00b7 N matrix P is formed as an equation. (5), and its submatrix P1: k has an accuracy k (P1: k, 1: k) as its smallest singular value."}, {"heading": "C. Estimating the optimal subspace dimension", "text": "Based on our results, as they are called in theories 1-3, we develop an estimation algorithm for the optimal partial space dimension = 3. It is easy to find the optimal partial space dimension by obtaining the maximum partial space dimension..............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."}, {"heading": "D. Complexity analysis", "text": "The complexity of calculating the two sets of eigenvectors is O (N3). The complexity of calculating the distance of the partial space for each possible pair of (kA, kB) is therefore O (N5).Theorem 4 indicates the computational complexity of the GETESD algorithm. Theorem 4. The GETESD algorithm in Fig. 1 for N nodes has a computational complexity of O (N5).Theorem 4 indicates the computational complexity of the GETESD algorithm. The GETESD algorithm in Fig. 1 for N nodes has a computational complexity of O (Zk3 + k2N), where k is the calculation of the resulting effective partial space dimension and Z is the upper limit of the ESETD algorithm."}, {"heading": "VI. DISTRIBUTED ALGORITHM", "text": "When a variety of points in a network are monitored for anomalies, the data required to calculate covariance matrices must be collected at multiple nodes, some of which are geographically distant from each other. Section V's centralized algorithm would require a monitoring station to collect all the data from the collection nodes, calculate the covariance matrices, and then process the matrix flow for anomalies. In this case, the prohibitive recording and communication costs are the motivation behind our distributed algorithm to allow an estimate of the maximum subspace distance without a central station. In the distributed case, no node can have knowledge of the entire covariance matrix (which requires all data from all nodes), but each node can update and maintain its corresponding entry in the eigenvector. As a result, each node must collaborate with its neighbors to perform eigenvector / eigenvalues estimations distributed."}, {"heading": "A. Assumptions and system model", "text": "In practice, different nodes will have different numbers of characteristics to monitor. However, for simplicity and clarity, we will illustrate our distributed algorithm, assuming that there is a feature monitored at each node - so we will also assume that there are N nodes in this section. As described in Section II-2, M will indicate the number of consecutive time windows for which each of these N characteristics is sampled to calculate a covariance matrix (any two characteristics must be observed for a specified period of time to determine the correlation between them). Therefore, input to the distributed algorithm is a stream of vectors of length M, each entry being a characteristic sampled at a specified time. Collectively, these vectors form an N-M matrix, with the data collection of the n-th characteristic xn."}, {"heading": "B. Distributed power iteration method", "text": "The aim of a distributed potentiality iteration method is to collaborate in estimating the most important major component of a dataset. Figure 3 represents the pseudo-code for a centralized potentiality iteration method, which is the first major component v taking into account a covariance matrix C. The method is based on the fact that the first eigenvalue of a given matrix C can be estimated by limk \u00b2 n, where v is a random vector. For more details on the potentiality iteration method, we refer readers to [33]. In the following, we develop and describe a distributed version of the potentiality iteration method. \u2212 First, we describe how the potentiality iteration can be performed without the covariance matrix C. In the k-th step of the centralized potentiation method, the method v \u00b2 n runs."}, {"heading": "C. Evaluation of convergence and accuracy", "text": "This year, it has reached the stage where it will be able to take the lead."}, {"heading": "E. Complexity analysis", "text": "Theorem 5 below, as demonstrated in the appendix, deals with the computational complexity of the GETESDD algorithm. Theorem 5. The computational complexity of GETESD-D is O (kpM \u2206 S) for M measurements at each node, with S and p being upper limits for the number of steps required for the convergence of the average consensus and the GETESD-D methods. Note that the computational costs for calculating the covariance matrix in a central environment are O (N2M) and O (ZN2) for Z-steps of the performance method. Messages containing information about major components for all nodes would be O (N3) at best and O (N4) at worst. Theorem 6 below, also proven in the appendix, addresses the communication complexity of the GETESD-D algorithm. Theorem 6. The communication complexity of GESD-D ratio is only the mean number of notes."}, {"heading": "VII. EFFECTIVENESS OF ANOMALY DETECTION", "text": "Suppose the dimension of the data is N. Using training data, a normal subspace Uk is then constructed with the main components of the top-k-N. Since most normal traffic patterns are within the normal subspace Uk, projections of data without anomalies onto the normal subspace should retain most of the data. However, the projection of anomalous data, whose characteristics do not fully fall into the aforementioned normal subspace, would retain only a portion of the observed data. Therefore, for the purpose of anomaly detection using the variance-based subspace method, the projection residence of any length-N vector x, designated by r (x), is calculated as follows to obtain a metric of the anomaly: r (x) = (I \u2212 UkUTk) x, where I am the identity matrix. The detection process simply compares the projection residence with a predefined threshold and triggers an alarm if it is above the threshold."}, {"heading": "A. Anomaly detection using the projection residual", "text": "In fact, it is that we are able to assert ourselves, that we are able, that we are able, that we are able to hide ourselves, and that we are able, that we will be able, that we will be able, that we will be able, that we will be able."}, {"heading": "B. Hit rate and false alarm rate", "text": "In fact, it is the case that most people who are able to survive themselves are able to survive themselves, \"he told the German Press Agency in an interview with\" Welt am Sonntag \":\" I don't think they are able to survive themselves. \"He added:\" I don't think they are able to survive themselves, and that they are able to survive themselves. \"He added:\" I don't think they are able to survive themselves, and that they are able to survive themselves. \"He added:\" I don't think they are able to survive themselves, and that they are able to survive themselves. \""}, {"heading": "D. Overcoming normal traffic spoofing", "text": "In fact, the majority of people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move"}, {"heading": "E. Comparison of centralized and distributed algorithms", "text": "In this subsection, we offer a comparison between the performance of the centralized (GETESD) and distributed (GETESD-D) versions of our algorithm. Note that both versions provide the same mathematical output - that is, they achieve the same accuracy and therefore the same level of success in detecting anomalies. Table I summarizes the anomaly detection comparisons using the same workstation as Figure 10 for our simulations. For our simulations, we use synthetic networks modeled according to realistic campus-wide WiFi backbones, with N = 100 and N = 1000 and 1Gbps links. The detection time shown in Table I is the total runtime of the residual data projection vector for detection (in the distributed case, different nodes can be scattered to the response at different times)."}, {"heading": "VIII. CONCLUDING REMARKS", "text": "Given big data trends in both capture and storage, our contribution can be used in any other context of network management where this primary method of data reduction based on real-time data makes sense. In this paper, supported by theoretical analysis and simulation results using real-time traffic lanes, we have described a new distance-based approach to dimensionality reduction that offers significant advantages over previously known methods. These advantages include (i) improved adaptability to changing patterns in test data, so that we only use the number of dimensions needed at a given time, (ii) improved ability to characterize and classify attack traffic, since dimensionality reduction is based on observed traffic and is not predetermined, and (iii) improved resilience to attacks that attempt to distort normal traffic patterns. Although we have our distance-based subroughness approach based on the end-context of our contribution to anomaly detection in each network, this method may be useful in others."}, {"heading": "A. Proof of Theorem 1", "text": "The statement of the theorem is proven if \u03b8kA, kB (A, B) \u2264 \u03b8kB, kB (A, B). The proofs for each of these two cases are as follows. Case (i): Leave x a column vector of length kB. \"Using the definition of the matrix norm we have:... TkA, kB (A, B). Example (max.). Case (i):. Case (i): Leave x x x x x x x x x x x x x x x, kB = max x, x x x x x."}, {"heading": "B. Proof of Theorem 2", "text": "First of all, we use Pi, j, um Tk, k (A, B) and T \u2032 k, k (A, B) Tk, k (A, B).Tk, k (A, B) = (I \u2212 k \u2211 i = 1ai \u00b7 a \u2032 i) [b1,..., bk] = [b1,.., bk] \u2212 k [b1,.., Pi, k] \u2212 k = 1ai \u00b7 [a \u2032 ib1,.., a \u2032 ibk] = [b1,., bk] \u2212 k,., Pi, k] \u2212 k, k (A, B) Tk \u00b2, k \u00b2 (K \u00b2) \u2212 k, k (A, B) \u2212 k (A, B) = 1: k, 1: kP1, 1: kP1, 1: k \u00b2 (K), k \u00b2 (K), k \u00b2 (K \u00b2), k \u00b2 (K, K, K \u00b2), k \u00b2 (K, K \u00b2), k \u00b2 (K \u00b2) \u2212 K \u00b2 (K \u00b2), K \u00b2 (K \u00b2), K \u00b2 (K (K \u00b2) \u2212 P (K \u00b2), K \u00b2 (K \u00b2), K \u00b2 (K \u00b2), K \u00b2 (K \u00b2), K \u00b2 (K \u00b2), K \u00b2 (K \u00b2), K \u00b2 (K \u00b2, K \u00b2), K \u00b2 (K \u00b2), K \u00b2 (K (K (K), K \u00b2), K \u00b2 (K \u00b2, K (K \u00b2), K \u00b2, K \u00b2, K (K \u00b2), K \u00b2 (K (K \u00b2), K \u00b2, K \u00b2, K (K \u00b2), K \u00b2, K (K \u00b2), K \u00b2 (K \u00b2, K (K \u00b2), K (K \u00b2, K \u00b2), K (K \u00b2), K \u00b2, K (K \u00b2, K \u00b2, K (K \u00b2), K (K \u00b2), K (K (K \u00b2), K (K \u00b2), K \u00b2, K (K (K \u00b2), K (K \u00b2), K (K \u00b2), K (K (K \u00b2), K (K \u00b2), K (K \u00b2), K \u00b2, K (K (A, K \u00b2), K ("}, {"heading": "C. Proof of Theorem 3", "text": "(Let us consider a N \u00b7 N matrix P as in Eq. (5). Let us leave ui a N \u00b7 1 vector with an i-th entry that is not zero: ui (k) = {1, if k \u2032 0, if k \u2032 6 = iNow, so that pi denotes the i-th column of P, and let IN \u00b7 N denote an identity matrix of the size N \u00b7 N, then we have: u \u2032 iP \u2032 Puj = p \u2032 ipj = N \u0445 k = 1Pk, iPk, j = N \u0445 k = 1b \u2032 iaka \u2032 kbj \u2032 i (N \u0445 k = 1aka \u2032 k) bj = b \u2032 iP \u2212 \u2212 ipj = N, so we have haveu \u2032 iP \u2032 Puj = {1, if i = j = 0, if i = (9) kbj \u2032 iaka \u2032 kbj \u2032 i \u2032 i \u2032 (b \u2032 bj \u2032 kk) bj \u2032 k = 1, aka kk = 1k, then we have a \u2212 k = 1k = 1k: \u2212 i, if i = 1j i, if i = 1j: Pi), then Pj \u2032 i = 1 (b \u2032 kj \u2032 k = 1 k = 1k, \u2212 k = 1k: \u2212 k = 1k = 1k: \u2212 i)."}, {"heading": "D. Proof of Theorem 4", "text": "The proof of theorem 3 above shows that it is possible to construct a projection matrix in search of the optimum sub-space dimension. First, let us consider the computational complexity of the construction of P1: k, 1: k and P \u2032 1: k, 1: kP1: k, 1: kP1: k, 1: k with the knowledge of P \u2032 1: k \u2212 1,1: k \u2212 k and a1,..., ak, b1,..., bk. The computational complexity of u, v and c is O (kN). The construction complexity of P \u2032 1: k, 1: kP1: k, 1: k, 1: k, 1: k is O (k2). Now, the complexity of calculating the eigenvalue of P \u2032 1: k, 1: kP1: k, 1: k with the method of power siteration O (Zk2) with the number of Iterations necessary for the convergence (ltr < K < since < K)."}, {"heading": "E. Proof of Theorem 5", "text": "The mathematically most expensive part is the calculation of z (k) n. If the size of the measurements is M, the length of x \u2032 nv (k) n is also M. Assuming that the maximum degree of each node is \u2206, then the process of average consensus in S-steps has a complexity of O (\u2206 S) for each entry of x \u2032 nv (k) n. Overall, the computational complexity of the distributed iteration method for p-steps is O (pM \u2206 S). Consequently, the total computational complexity of GETESD-D using O (k) power siterations is O (kpM \u2206 S)."}, {"heading": "F. Proof of Theorem 6", "text": "We consider the number of messages a node must send when the algorithm is running. Again, let the maximum degree of each node be \u2206. Exactly at this step, the node must send its observation xn to its neighbors, resulting in communication costs of O (M \u00b2). After that, that node only needs to update its neighbors via its estimate v (k). The number of messages sent for each power siteration is O (\u2206 S). Overall, the communication complexity of the distributed power siteration method running for p steps is O (M \u00b2 + p \u00b2 S). The total communication complexity of GETESD-D using O (k) power siterations is O (kM \u00b2 + kp \u00b2 S)."}], "references": [{"title": "Network anomaly detection: Methods, systems and tools", "author": ["M. Bhuyan", "D. Bhattacharyya", "J. Kalita"], "venue": "IEEE Commun. Surveys Tuts., vol. 16, no. 1, pp. 303\u2013336, 2014.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2014}, {"title": "Beehive: Large-scale log analysis for detecting suspicious activity in enterprise networks", "author": ["T.-F. Yen", "A. Oprea", "K. Onarlioglu", "T. Leetham", "W. Robertson", "A. Juels", "E. Kirda"], "venue": "ACM Ann. Comput. Security Appl. Conf., 2013, pp. 199\u2013208.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2013}, {"title": "Principal Component Analysis, 2nd ed", "author": ["I.T. Jolliffe"], "venue": "New York: Springer,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2002}, {"title": "Diagnosing network-wide traffic anomalies", "author": ["A. Lakhina", "M. Crovella", "C. Diot"], "venue": "SIGCOMM Comput. Commun. Rev., vol. 34, no. 4, pp. 219\u2013230, Aug. 2004.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2004}, {"title": "Sensitivity of PCA for traffic anomaly detection", "author": ["H. Ringberg", "A. Soule", "J. Rexford", "C. Diot"], "venue": "SIGMETRICS Perform. Eval. Rev., vol. 35, no. 1, pp. 109\u2013120, Jun. 2007.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2007}, {"title": "Covariance-matrix modeling and detecting various flooding attacks", "author": ["D. Yeung", "S. Jin", "X. Wang"], "venue": "IEEE Trans. Syst., Man, Cybern. A, Syst., Humans, vol. 37, no. 2, pp. 157\u2013169, 2007.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2007}, {"title": "Gossip-based greedy gaussian mixture learning", "author": ["N. Vlassis", "Y. Sfakianakis", "W. Kowalczyk"], "venue": "Advances in Informatics. Springer, 2005, pp. 349\u2013359.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2005}, {"title": "Load characterization and anomaly detection for voice over IP traffic", "author": ["M. Mandjes", "I. Saniee", "A.L. Stolyar"], "venue": "IEEE Trans. Neural Netw., vol. 16, no. 5, pp. 1019\u20131026, 2005.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2005}, {"title": "Detecting VoIP calls hidden in web traffic", "author": ["E. Freire", "A. Ziviani", "R. Salles"], "venue": "IEEE Trans. Netw. Service Manag., vol. 5, no. 4, pp. 204\u2013214, December 2008.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2008}, {"title": "Locating network domain entry and exit point/path for DDoS attack traffic", "author": ["V. Thing", "M. Sloman", "N. Dulay"], "venue": "IEEE Trans. Netw. Service Manag., vol. 6, no. 3, pp. 163\u2013174, September 2009.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2009}, {"title": "A large-scale hidden semi-Markov model for anomaly detection on user browsing behaviors", "author": ["Y. Xie", "S. zheng Yu"], "venue": "IEEE/ACM Trans. Netw., vol. 17, no. 1, pp. 54\u201365, Feb 2009. 29", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2009}, {"title": "Spatio-temporal network anomaly detection by assessing deviations of empirical measures", "author": ["I. Paschalidis", "G. Smaragdakis"], "venue": "IEEE/ACM Trans. Netw., vol. 17, no. 3, pp. 685\u2013697, June 2009.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2009}, {"title": "Anomaly detection in IP networks", "author": ["M. Thottan", "C. Ji"], "venue": "IEEE Trans. Signal Process., vol. 51, no. 8, pp. 2191\u20132204, 2003.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2003}, {"title": "Mining anomalies using traffic feature distributions", "author": ["A. Lakhina", "M. Crovella", "C. Diot"], "venue": "SIGCOMM Comput. Commun. Rev., vol. 35, no. 4, pp. 217\u2013228, Aug. 2005.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2005}, {"title": "A novel covariance matrix based approach for detecting network anomalies", "author": ["M. Tavallaee", "W. Lu", "S.A. Iqbal", "A. Ghorbani"], "venue": "IEEE Commun. Netw. Services Res. Conf., 2008, pp. 75\u201381.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2008}, {"title": "Histogram-based traffic anomaly detection", "author": ["A. Kind", "M.P. Stoecklin", "X. Dimitropoulos"], "venue": "IEEE Trans. Netw. Service Manag., vol. 6, no. 2, pp. 110\u2013121, 2009.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2009}, {"title": "A distribution-based approach to anomaly detection and application to 3G mobile traffic", "author": ["A.D. Alconzo", "A. Coluccia", "F. Ricciato", "P. Romirer-Maierhofer"], "venue": "IEEE Glob. Telecom. Conf., 2009, pp. 1\u20138.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2009}, {"title": "A novel PCA-based network anomaly detection", "author": ["C. Callegari", "L. Gazzarrini", "S. Giordano", "M. Pagano", "T. Pepe"], "venue": "IEEE Intl. Conf. Commun., 2011, pp. 1\u20135.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2011}, {"title": "A comparative study of two network-based anomaly detection methods", "author": ["K. Nyalkalkar", "S. Sinha", "M. Bailey", "F. Jahanian"], "venue": "IEEE Intl. Conf. Comput. Commun. (INFOCOM), 2011, pp. 176\u2013180.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2011}, {"title": "Robust feature selection and robust PCA for Internet traffic anomaly detection", "author": ["C. Pascoal", "M.R. de Oliveira", "R. Valadas", "P. Filzmoser", "P. Salvador", "A. Pacheco"], "venue": "IEEE Intl. Conf. Comput. Commun. (INFOCOM), 2012, pp. 1755\u20131763.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2012}, {"title": "Robust PCA as bilinear decomposition with outlier-sparsity regularization", "author": ["G. Mateos", "G.B. Giannakis"], "venue": "IEEE Trans. Sig. Process., vol. 60, no. 10, pp. 5176\u20135190, 2012.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2012}, {"title": "PCA-based robust anomaly detection using periodic traffic behavior", "author": ["T. Kudo", "T. Morita", "T. Matsuda", "T. Takine"], "venue": "IEEE Intl. Conf. Commun. Wksp. (ICC), 2013, pp. 1330\u20131334.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2013}, {"title": "Dimension reduction: A guided tour", "author": ["C.J.C. Burges"], "venue": "Now Publishers, Inc.,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2010}, {"title": "Asynchronous distributed power iteration with gossip-based normalization", "author": ["M. Jelasity", "G. Canright", "K. Eng\u00f8-Monsen"], "venue": "Euro-Par 2007 Parallel Process. Springer, 2007, pp. 514\u2013525.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2007}, {"title": "Power iteration-based distributed total least squares estimation in ad hoc sensor networks", "author": ["A. Bertrand", "M. Moonen"], "venue": "IEEE Intl. Conf. Acoust., Speech, Signal Process. (ICASSP), 2012, pp. 2669\u20132672.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2012}, {"title": "Distributed principal component analysis on networks via directed graphical models", "author": ["Z. Meng", "A. Wiesel", "A.O. Hero III"], "venue": "IEEE Intl. Conf. Acoust., Speech, Signal Process. (ICASSP), 2012, pp. 2877\u20132880.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2012}, {"title": "In-network PCA and anomaly detection", "author": ["L. Huang", "X. Nguyen", "M. Garofalakis", "M.I. Jordan", "A. Joseph", "N. Taft"], "venue": "Adv. Neural Inf. Process. Sys., 2006, pp. 617\u2013624.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2006}, {"title": "Decomposable principal component analysis", "author": ["A. Wiesel", "A.O. Hero"], "venue": "IEEE Trans. Signal Process., vol. 57, no. 11, pp. 4369\u20134377, 2009.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2009}, {"title": "Randomized gossip algorithms", "author": ["S. Boyd", "A. Ghosh", "B. Prabhakar", "D. Shah"], "venue": "IEEE/ACM Trans. Netw. (TON), vol. 14, no. SI, pp. 2508\u20132530, 2006.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2006}, {"title": "Gossip algorithms for distributed signal processing", "author": ["A.G. Dimakis", "S. Kar", "J.M. Moura", "M.G. Rabbat", "A. Scaglione"], "venue": "Proc. IEEE, vol. 98, no. 11, pp. 1847\u20131864, 2010.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 1847}, {"title": "Distributed principal subspace estimation in wireless sensor networks", "author": ["L. Li", "A. Scaglione", "J.H. Manton"], "venue": "IEEE J. Sel. Topics Signal Process., vol. 5, no. 4, pp. 725\u2013738, 2011.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2011}, {"title": "Numerical methods for computing angles between linear subspaces", "author": ["A. Bj\u00f6rck", "G.H. Golub"], "venue": "Math. comput., vol. 27, no. 123, pp. 579\u2013594, 1973.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 1973}, {"title": "A fast algorithm for detecting anomalous changes in network traffic", "author": ["T. Huang", "H. Sethu", "N. Kandasamy"], "venue": "Intl. Conf. Netw. Service Manag.(CNSM), 2015.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2015}, {"title": "Adaptive sampling and statistical inference for anomaly detection", "author": ["T. Huang"], "venue": "Ph.D. dissertation, Drexel University, 2015. 30", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "INTRODUCTION Security professionals who monitor communication networks for malware, errors and intrusions are increasingly dependent on real-time detection of anomalous behavior in the data traffic [1].", "startOffset": 198, "endOffset": 201}, {"referenceID": 1, "context": "The volume of data one has to monitor and process for effective real-time management of networks and systems, however, poses significant Big Data challenges [2].", "startOffset": 157, "endOffset": 160}, {"referenceID": 2, "context": "Principal Component Analysis (PCA) is a widely used tool that allows us to derive a reduced set of the most significant uncorrelated features that are linear combinations of the original set of features [3].", "startOffset": 203, "endOffset": 206}, {"referenceID": 3, "context": "Then, a significant deviation in the projection of the N-dimensional observed data onto this k-dimensional reference (normal) subspace can be defined as an anomaly for purposes of detection [4].", "startOffset": 190, "endOffset": 193}, {"referenceID": 4, "context": "There are at least three weaknesses of the traditional variance-based subspace approach for anomaly detection: (i) the reduced number of principal components, k, is computed based on the structure of normal traffic when, actually, the structure of the changes between the observed and the normal traffic is more relevant for choosing the appropriate number of dimensions for anomaly detection; (ii) a static determination of k is inadequate at capturing real-time changes \u2014 the right number of dimensions is often different during different periods of time depending on the structure of both the normal and the observed traffic; (iii) the method allows only weak heuristics because the performance of anomaly detection is very sensitive to small changes in the number of dimensions chosen for the normal subspace [5].", "startOffset": 813, "endOffset": 816}, {"referenceID": 5, "context": "This work is additionally motivated by two observations: (i) anomalies lead to changes in the covariance matrix of the set of traffic features being monitored, and (ii) different types of anomalies cause different types of deviations in the covariance matrix allowing a categorization of the detected anomaly and an immediate prescription of actions toward threat mitigation [6].", "startOffset": 375, "endOffset": 378}, {"referenceID": 6, "context": "The participating nodes in the GETESD-D algorithm deploy the gossip-based Gaussian mixture learning mechanism to estimate principal components of the traffic features [7].", "startOffset": 167, "endOffset": 170}, {"referenceID": 7, "context": "For example, methods reported in [8] and [9] allow the detection of load anomalies in voice-over-IP traffic at the network or the application layer.", "startOffset": 33, "endOffset": 36}, {"referenceID": 8, "context": "For example, methods reported in [8] and [9] allow the detection of load anomalies in voice-over-IP traffic at the network or the application layer.", "startOffset": 41, "endOffset": 44}, {"referenceID": 9, "context": "Similarly, distributed denial-of-service (DDoS) attacks are the target of detection in [10], [11] and [12].", "startOffset": 87, "endOffset": 91}, {"referenceID": 10, "context": "Similarly, distributed denial-of-service (DDoS) attacks are the target of detection in [10], [11] and [12].", "startOffset": 93, "endOffset": 97}, {"referenceID": 11, "context": "Similarly, distributed denial-of-service (DDoS) attacks are the target of detection in [10], [11] and [12].", "startOffset": 102, "endOffset": 106}, {"referenceID": 12, "context": "or state machine modeling are reviewed in [13].", "startOffset": 42, "endOffset": 46}, {"referenceID": 3, "context": "Examples of later work on developing general anomaly detection tools include [4], [6], [12], [14]\u2013[18].", "startOffset": 77, "endOffset": 80}, {"referenceID": 5, "context": "Examples of later work on developing general anomaly detection tools include [4], [6], [12], [14]\u2013[18].", "startOffset": 82, "endOffset": 85}, {"referenceID": 11, "context": "Examples of later work on developing general anomaly detection tools include [4], [6], [12], [14]\u2013[18].", "startOffset": 87, "endOffset": 91}, {"referenceID": 13, "context": "Examples of later work on developing general anomaly detection tools include [4], [6], [12], [14]\u2013[18].", "startOffset": 93, "endOffset": 97}, {"referenceID": 17, "context": "Examples of later work on developing general anomaly detection tools include [4], [6], [12], [14]\u2013[18].", "startOffset": 98, "endOffset": 102}, {"referenceID": 5, "context": "While the covariance matrix plays a role in many anomaly detection methods, it was most directly used in [6] to detect flooding attacks based on comparisons between a covariance matrix under normal conditions (used as the reference matrix) and the observed covariance matrix.", "startOffset": 105, "endOffset": 108}, {"referenceID": 14, "context": "The covariance matrix is also used directly for anomaly detection in [15].", "startOffset": 69, "endOffset": 73}, {"referenceID": 5, "context": "Further, as opposed to methods in [6] and [15] which are based on detecting the changes in individual entries in the covariance matrix, our method is additionally able to exploit the underlying correlations between the changes in the entries to offer a more refined and a more reliable approach to anomaly detection.", "startOffset": 34, "endOffset": 37}, {"referenceID": 14, "context": "Further, as opposed to methods in [6] and [15] which are based on detecting the changes in individual entries in the covariance matrix, our method is additionally able to exploit the underlying correlations between the changes in the entries to offer a more refined and a more reliable approach to anomaly detection.", "startOffset": 42, "endOffset": 46}, {"referenceID": 3, "context": "The variance-based subspace method, based on PCA, was first proposed for anomaly detection in [4] and later improved in [14] to explore the deviation in the network-wide traffic volume and feature distributions caused by anomalies.", "startOffset": 94, "endOffset": 97}, {"referenceID": 13, "context": "The variance-based subspace method, based on PCA, was first proposed for anomaly detection in [4] and later improved in [14] to explore the deviation in the network-wide traffic volume and feature distributions caused by anomalies.", "startOffset": 120, "endOffset": 124}, {"referenceID": 3, "context": "To use this method online in real-time as described in [4], one processes each arrival of new traffic measurements using the matrix PP T , where P is composed of the top k principal components representing the normal traffic pattern.", "startOffset": 55, "endOffset": 58}, {"referenceID": 3, "context": ") The scheme proposed in [4] would separate the high-dimensional space of network traffic into two subspaces: the normal subspace and the anomalous subspace.", "startOffset": 25, "endOffset": 28}, {"referenceID": 4, "context": "The limitations of the variance-based subspace methods are discussed in [5].", "startOffset": 72, "endOffset": 75}, {"referenceID": 18, "context": "The simulation results in [19] further confirm that the effectiveness of the subspace method depends strongly on the dimension chosen for the normal subspace.", "startOffset": 26, "endOffset": 30}, {"referenceID": 19, "context": "Later work has improved upon the training process of the subspace method [20]\u2013[22], but choosing the appropriate dimension for the normal subspace has remained an unmet challenge.", "startOffset": 73, "endOffset": 77}, {"referenceID": 21, "context": "Later work has improved upon the training process of the subspace method [20]\u2013[22], but choosing the appropriate dimension for the normal subspace has remained an unmet challenge.", "startOffset": 78, "endOffset": 82}, {"referenceID": 22, "context": "The distancebased methods used in the literature also present the same challenge where the reduced number of dimensions is not adaptive to real-time data [23].", "startOffset": 154, "endOffset": 158}, {"referenceID": 23, "context": "In other related work, PCA-based methods have been decentralized for a variety of purposes including anomaly detection [24]\u2013[28].", "startOffset": 119, "endOffset": 123}, {"referenceID": 27, "context": "In other related work, PCA-based methods have been decentralized for a variety of purposes including anomaly detection [24]\u2013[28].", "startOffset": 124, "endOffset": 128}, {"referenceID": 26, "context": "A distributed framework for PCA is proposed in [27] to achieve accurate detection of network anomalies through monitoring of only the local data.", "startOffset": 47, "endOffset": 51}, {"referenceID": 27, "context": "distributed implementation of PCA is developed for decomposable Gaussian graphical models in [28] to allow decentralized anomaly detection in backbone networks.", "startOffset": 93, "endOffset": 97}, {"referenceID": 28, "context": "Distributed gossip algorithms using only local communication for subspace estimation have been used in the context of sensor networks [29]\u2013[31].", "startOffset": 134, "endOffset": 138}, {"referenceID": 30, "context": "Distributed gossip algorithms using only local communication for subspace estimation have been used in the context of sensor networks [29]\u2013[31].", "startOffset": 139, "endOffset": 143}, {"referenceID": 30, "context": "Our work in this paper extends the distributed average consensus protocol proposed in [31] to estimate the principal subspace for the context of anomaly detection in network traffic data.", "startOffset": 86, "endOffset": 90}, {"referenceID": 31, "context": "Our proposed metric of subspace distance is new, and the closest related metric in the literature is the principal angle [32].", "startOffset": 121, "endOffset": 125}, {"referenceID": 32, "context": "The GETESD algorithm achieves a significantly higher accuracy over our previous work, a heuristic [34].", "startOffset": 98, "endOffset": 102}, {"referenceID": 32, "context": "As reported in [34], the heuristic is able to estimate the subspace distance with a percentage error which frequently reaches above 1% and sometimes close to 5%.", "startOffset": 15, "endOffset": 19}, {"referenceID": 30, "context": "This routine, a straightforward extension of the distributed average consensus algorithm in [31] to accommodate for the constraints placed on row sums and column sums of W , is shown in Fig.", "startOffset": 92, "endOffset": 96}, {"referenceID": 30, "context": "Since the family of average consensus algorithms is already well-studied [31], we focus here on the distributed power iteration method assuming that the distributed average consensus method generates an answer within an error margin of 5%.", "startOffset": 73, "endOffset": 77}, {"referenceID": 13, "context": "The detection process simply compares the projection residual with a pre-defined threshold and triggers an alarm if it is above the threshold [14].", "startOffset": 142, "endOffset": 146}, {"referenceID": 33, "context": "A more detailed proof with all intermediate steps is provided in [37].", "startOffset": 65, "endOffset": 69}], "year": 2016, "abstractText": "The monitoring and management of high-volume feature-rich traffic in large networks offers significant challenges in storage, transmission and computational costs. The predominant approach to reducing these costs is based on performing a linear mapping of the data to a low-dimensional subspace such that a certain large percentage of the variance in the data is preserved in the low-dimensional representation. This variance-based subspace approach to dimensionality reduction forces a fixed choice of the number of dimensions, is not responsive to real-time shifts in observed traffic patterns, and is vulnerable to normal traffic spoofing. Based on theoretical insights proved in this paper, we propose a new distance-based approach to dimensionality reduction motivated by the fact that the real-time structural differences between the covariance matrices of the observed and the normal traffic is more relevant to anomaly detection than the structure of the training data alone. Our approach, called the distance-based subspace method, allows a different number of reduced dimensions in different time windows and arrives at only the number of dimensions necessary for effective anomaly detection. We present centralized and distributed versions of our algorithm and, using simulation on real traffic traces, demonstrate the qualitative and quantitative advantages of the distance-based subspace approach.", "creator": "LaTeX with hyperref package"}}}