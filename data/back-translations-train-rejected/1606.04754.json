{"id": "1606.04754", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jun-2016", "title": "A Correlational Encoder Decoder Architecture for Pivot Based Sequence Generation", "abstract": "Interlingua based Machine Translation (MT) aims to encode multiple languages into a common linguistic representation and then decode sentences in multiple target languages from this representation. In this work we explore this idea in the context of neural encoder decoder architectures, albeit on a smaller scale and without MT as the end goal. Specifically, we consider the case of three languages or modalities X, Z and Y wherein we are interested in generating sequences in Y starting from information available in X. However, there is no parallel training data available between X and Y but, training data is available between X &amp; Z and Z &amp; Y (as is often the case in many real world applications). Z thus acts as a pivot/bridge. An obvious solution, which is perhaps less elegant but works very well in practice is to train a two stage model which first converts from X to Z and then from Z to Y. Instead we explore an interlingua inspired solution which jointly learns to do the following (i) encode X and Z to a common representation and (ii) decode Y from this common representation. We evaluate our model on two tasks: (i) bridge transliteration and (ii) bridge captioning. We report promising results in both these applications and believe that this is a right step towards truly interlingua inspired encoder decoder architectures.", "histories": [["v1", "Wed, 15 Jun 2016 13:27:16 GMT  (1711kb,D)", "http://arxiv.org/abs/1606.04754v1", "10 pages"]], "COMMENTS": "10 pages", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["amrita saha", "mitesh m khapra", "sarath chandar", "janarthanan rajendran", "kyunghyun cho"], "accepted": false, "id": "1606.04754"}, "pdf": {"name": "1606.04754.pdf", "metadata": {"source": "CRF", "title": "A Correlational Encoder Decoder Architecture for Pivot Based Sequence Generation", "authors": ["Amrita Saha", "Mitesh M Khapra", "Sarath Chandar", "Janarthanan Rajendran", "Kyunghyun Cho"], "emails": ["amrsaha4@in.ibm.com", "mikhapra@in.ibm.com", "apsarathchandar@gmail.com", "rsdjjana@gmail.com", "kyunghyun.cho@nyu.edu"], "sections": [{"heading": "1 Introduction", "text": "It is interesting to consider the implications of this idea when it is embedded in the statistical context."}, {"heading": "2 Related Work", "text": "The encoder-based sequence generation architectures were originally used in (Cho et al., 2014; Sutskever et al., 2014) in the context of Machine Translation (MT) and were also successfully used to generate captions for images (Vinyals et al., 2015b). However, such a sequence to sequence models is often difficult to learn as they aim to encode the entire source sequence using a fixed encoder representation. Bahdanau et al. (2014) introduced attention based on models where a different representation is given to the decoder at each step by drawing attention to different parts of the input sequence. Such attention-based models are more successful than vanilla encoder models and have been successfully used for MT (Bahdanau et al., 2014), parsing (Vinyals et al., 2015a), speech recognition (Chorowski et al., 2015), image labeling."}, {"heading": "3 Models", "text": "As already mentioned, one of the aims of this work is to compare a jointly trained model with a two-stage model. We first briefly describe such a two-stage encoder architecture and then describe our model, which is based on a correlation based on a jointly trained encoder model."}, {"heading": "3.1 A two stage encoder-decoder model", "text": "A two-stage encoder decoder is a linear extension of the sequence to sequence models (Cho et al., 2014; Sutskever et al., 2014) for bridge setup. Given parallel data between XZ and ZY, a two-stage model will learn a generative model for each of the pairs independently of each other. For the purpose of this work, the source may be an image or text, but the goal is always a natural language text. To encode an image, we simply take its feature representation obtained from one of the fully interconnected layers of a neural network and run it through a feed layer. On the other hand, for encoding the source text sequence, we use a recursive neural code code that generates the text sequence, one to mark at a later date."}, {"heading": "3.2 A correlation based joint encoder-decoder model", "text": "While the above model works well in practice, it becomes cumbersome when more views are involved (e.g. when converting U to X to Y to Z. We would like to see a more elegant solution that could be scaled even if more views are involved (although for the purpose of this work, we limit ourselves to only 3 views). To this end, we propose a joint model that uses the parallel data D1 (as defined above) to learn an encoder for X and Z so that the representations of xi and zi are correlated. Additionally, and simultaneously, the model uses D2 and learns to decode yj from zj. Note that this common training has the advantage that the encoder for Z tries to maximize the model's correlation between the encoded representations and D2.After giving an intuitive explanation of the model, we now formally define the objective functions that will be used during the training. Given D1 = {xi, zi} N1i, the model attempts to maximize the correlation between the encoded representations and the encoded representations."}, {"heading": "4 Experiment 1: Bridge Transliteration", "text": "We consider the task of transliteration between two languages X and Y, when there is no direct data between them, but parallel data between X & Z and Z & Y. In the following sections we describe the data sets used for our task, the hyperparameters that are taken into account for our experiments and results."}, {"heading": "4.1 Datasets", "text": "We look at transliteration between 4 languages, namely Hindi, Kannada, Tamil and Marathi, resulting in 4C2 = 12 language pairs. However, we do not use direct parallel data between any of these languages. Instead, we use the standard data sets available between English and each of these languages, which were published as part of the NEWS 2012 Shared Task (Zhang et al., 2012). To clarify this, we construct for the task of transliteration from Hindi to Kannada D1 from the English-Hindi dataset and D2 from the English-Kannada dataset. Table 1 summarizes the size of these parallel datasets. Fortunately, the English part of the test set was common in all four language pairs mentioned in Table 1. This enabled us to easily create test sets for all 12 language pairs. For example, if hi is the transliteration of the English word file in the English-Hindi test set, and the test sliteration of the same language set we then add together the English Kannada word sets in the Kannada."}, {"heading": "4.2 Hyperparameters", "text": "For the two-stage encoder decoder model, we considered the following hyperparameters: embed size for characters (1024, 2048), rnn hidden unit size (1024, 2048), initial learning rate (0.01, 0.001), and stack size (32, 64). The numbers in brackets indicate the different values we considered for each hyperparameter. Note that the embed size and rnn size are always the same. All these parameters were adjusted independently for the two levels using their respective validation sets. For the correlated encoder decoder model, in addition to the above hyperparameters, we also had \u03bb [0.1, 1.0] as hyperparameter. Here, we adjusted the hyperparameters based on the validation sets available between ZY (since the correlated encoder can also use yi-Y decoder of zi, 1.0] as hyperparameter."}, {"heading": "4.3 Results", "text": "We compare our model with the following systems: 1. Two-stage PBSMT: Here we train two PBSMT (Koehn et al., 2003) -based transliteration systems using D1 and D2. This is an additional baseline to see how well an encoder architecture compares to a conventional PBSMT-based system. We used Moses (Koehn et al., 2007) to build our PBSMT systems. Decoder parameters were tuned using the validation kits. The language model was based on the target of the parallel corpus.2. Two-stage encoder decoder-based transliteration systems using D1 and D2, as described in Section 4.Table 2. Accuracy (% of correct transliterations) of the three systems in bridge construction was trained."}, {"heading": "5 Experiment 2: Bridge Captioning", "text": "The purpose of introducing this task is twofold: first, we believe it is important to put things in perspective and to show that the encoder decoder architectures inspired by Interlingua represent a step in the right direction, but much more work is needed when it comes to the various modalities of bridge building; second, we think that this is an important task that has not been considered in the past. We would like to formally define and report some basic data in order to motivate further research in this area; the formal task definition is as follows: Generate captions in language L1 (say French) when there is no parallel data between images and L1, but parallel data is available between image L2 (D1) and between image L1-L2 (D2), where L2 is a different language (say English). In the following section, we describe the sets used for this task, the data sets, the results, and our experiments are taken into account."}, {"heading": "5.1 Datasets", "text": "Even though we have the direct training data between Image-French, we need some test data to evaluate our model. Therefore, we use the Image-French test set recently from (Rajendran et al., 2015). To create this data, they have the 80K images from the standard segment and 40K images from the test set with the crowdsourcing on the train (118K) and the test set (1K). They then collect the translations for all the 5 captions for crowdsourcing."}, {"heading": "5.2 Hyperparameters", "text": "Our model has the following hyperparameters: embed size, stack size, hidden representation size, \u03bb and learning rate. Based on experiments with direct Image-to-English caption generation, we found that the following parameters work well: embed size = 512, stack size = 80, rnn hidden unit size = 512 and learning rate = 4e-4 with Adam (Kingma and Ba, 2014) as optimizer. We simply kept these hyperparameters and did not re-adjust them for bridge construction. We optimized the value of \u03bb by evaluating the correlation loss based on the ImageEnglish validation set. Again, we do not use Image-French data to tune hyperparameters."}, {"heading": "5.3 Results", "text": "We now present the results of our experiments, where we compare them with the following strong baselines: 5http: / / www.ibm.com / smarterplanet / us / en / ibmwatson1. Two stages: Here we use a show & tell model (Vinyals et al., 2015b) trained with D1 to generate an English caption. We then translate this caption into French using the IBM translation system described above. 2. Pseudo-Im-Fr: Here we train an Image-to French show & tell model (Vinyals et al., 2015b) by combining the images in the MSCOCO dataset with their pseudo-French captions, which are generated by translating the English captions into French (using the IBM translation system). We find that our model is unable to beat the two strong baselines described above, but still comes close to their performance."}, {"heading": "6 Conclusion", "text": "In this paper, we looked at the problem of pivot-based sequence generation. Specifically, we are interested in creating sequences in a target language based on information in a source view. However, no direct training data is available between the source and target views, but training data is available between each of these views and a pivot view. To this end, we draw inspiration from interlingua-based MT and propose a neural network-based model that explicitly maximizes the correlation between source and pivot views while learning to decode target sequences from this correlated representation. We evaluate our model based on the task of bridge transliteration and show that it exceeds a strong two-tiered baseline for many language pairs. Finally, we introduce the task of bridge generation and report promising initial results. We hope that this new task will fuel further research in this area."}], "references": [{"title": "Deep canonical correlation analysis", "author": ["Andrew et al.2013] Galen Andrew", "Raman Arora", "Jeff Bilmes", "Karen Livescu"], "venue": null, "citeRegEx": "Andrew et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Andrew et al\\.", "year": 2013}, {"title": "Neural machine translation by jointly learning to align and translate", "author": ["Kyunghyun Cho", "Yoshua Bengio"], "venue": null, "citeRegEx": "Bahdanau et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2014}, {"title": "Findings of the 2012 workshop on statistical machine translation", "author": ["Philipp Koehn", "Christof Monz", "Matt Post", "Radu Soricut", "Lucia Specia"], "venue": "In Seventh Workshop on Statistical Machine Translation,", "citeRegEx": "Callison.Burch et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Callison.Burch et al\\.", "year": 2012}, {"title": "An autoencoder approach to learning bilingual word representations", "author": ["Stanislas Lauly", "Hugo Larochelle", "Mitesh M Khapra", "Balaraman Ravindran", "Vikas Raykar", "Amrita Saha"], "venue": "Proceedings of NIPS", "citeRegEx": "Chandar et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Chandar et al\\.", "year": 2014}, {"title": "Correlational neural networks", "author": ["Mitesh M. Khapra", "Hugo Larochelle", "Balaraman Ravindran"], "venue": "Neural Computation,", "citeRegEx": "Chandar et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Chandar et al\\.", "year": 2016}, {"title": "A hierarchical phrase-based model for statistical machine translation", "author": ["David Chiang"], "venue": "ACL", "citeRegEx": "Chiang.,? \\Q2005\\E", "shortCiteRegEx": "Chiang.", "year": 2005}, {"title": "Learning phrase representations using RNN encoder-decoder for statistical machine translation", "author": ["Cho et al.2014] Kyunghyun Cho", "Bart van Merrienboer", "\u00c7aglar G\u00fcl\u00e7ehre", "Dzmitry Bahdanau", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio"], "venue": null, "citeRegEx": "Cho et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Cho et al\\.", "year": 2014}, {"title": "Attention-based models for speech recognition", "author": ["Dzmitry Bahdanau", "Dmitriy Serdyuk", "Kyunghyun Cho", "Yoshua Bengio"], "venue": "In Advances in Neural Information Processing Systems 28: Annual Conference on Neural In-", "citeRegEx": "Chorowski et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Chorowski et al\\.", "year": 2015}, {"title": "Interlingual annotation", "author": ["Dorr et al.2010] Bonnie J. Dorr", "Rebecca J. Passonneau", "David Farwell", "Rebecca Green", "Nizar Habash", "Stephen Helmreich", "Eduard H. Hovy", "Lori S. Levin", "Keith J. Miller", "Teruko Mitamura", "Owen Rambow", "Advaith Siddharthan"], "venue": null, "citeRegEx": "Dorr et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Dorr et al\\.", "year": 2010}, {"title": "Multi-language image description with neural sequence models. CoRR, abs/1510.04709", "author": ["Stella Frank", "Eva Hasler"], "venue": null, "citeRegEx": "Elliott et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Elliott et al\\.", "year": 2015}, {"title": "Neural network transduction models in transliteration generation", "author": ["Finch et al.2015] Andrew Finch", "Lemao Liu", "Xiaolin Wang", "Eiichiro Sumita"], "venue": "Proceedings of NEWS 2015 The Fifth Named Entities Workshop,", "citeRegEx": "Finch et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Finch et al\\.", "year": 2015}, {"title": "Multi-way, multilingual neural machine translation with a shared attention mechanism", "author": ["Firat et al.2016] Orhan Firat", "KyungHyun Cho", "Yoshua Bengio"], "venue": null, "citeRegEx": "Firat et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Firat et al\\.", "year": 2016}, {"title": "Multilingual models for compositional distributed semantics", "author": ["Hermann", "Blunsom2014] Karl Moritz Hermann", "Phil Blunsom"], "venue": "In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Hermann et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hermann et al\\.", "year": 2014}, {"title": "Everybody loves a rich cousin: An empirical study of transliteration through bridge languages", "author": ["A. Kumaran", "Pushpak Bhattacharyya"], "venue": "In Human Language Technologies: Conference of the North American Chapter of the As-", "citeRegEx": "Khapra et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Khapra et al\\.", "year": 2010}, {"title": "Adam: A method for stochastic optimization. CoRR, abs/1412.6980", "author": ["Kingma", "Ba2014] Diederik P. Kingma", "Jimmy Ba"], "venue": null, "citeRegEx": "Kingma et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kingma et al\\.", "year": 2014}, {"title": "Inducing Crosslingual Distributed Representations of Words", "author": ["Ivan Titov", "Binod Bhattarai"], "venue": "In Proceedings of the International Conference on Computational Linguistics (COLING)", "citeRegEx": "Klementiev et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Klementiev et al\\.", "year": 2012}, {"title": "Statistical phrase-based translation", "author": ["Koehn et al.2003] Philipp Koehn", "Franz Josef Och", "Daniel Marcu"], "venue": "In HLT-NAACL", "citeRegEx": "Koehn et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Koehn et al\\.", "year": 2003}, {"title": "Multi-task sequence to sequence learning. CoRR, abs/1511.06114", "author": ["Quoc V. Le", "Ilya Sutskever", "Oriol Vinyals", "Lukasz Kaiser"], "venue": null, "citeRegEx": "Luong et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Luong et al\\.", "year": 2015}, {"title": "Effective approaches to attention-based neural machine translation. CoRR, abs/1508.04025", "author": ["Hieu Pham", "Christopher D. Manning"], "venue": null, "citeRegEx": "Luong et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Luong et al\\.", "year": 2015}, {"title": "Multiple system combination for transliteration", "author": ["Bradley Hauer", "Mohammad Salameh", "Adam St Arnaud", "Ying Xu", "Lei Yao", "Grzegorz Kondrak"], "venue": "Proceedings of NEWS 2015 The Fifth Named Entities Workshop,", "citeRegEx": "Nicolai et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Nicolai et al\\.", "year": 2015}, {"title": "Pangloss: A machine translation project. In Human Language Technology, Proceedings of a Workshop held at Plainsboro, New Jerey", "author": ["Sergei Nirenburg"], "venue": null, "citeRegEx": "Nirenburg.,? \\Q1994\\E", "shortCiteRegEx": "Nirenburg.", "year": 1994}, {"title": "Bridge correlational neural networks for multilingual multimodal representation learning. CoRR, abs/1510.03519", "author": ["Mitesh M. Khapra", "Sarath Chandar", "Balaraman Ravindran"], "venue": null, "citeRegEx": "Rajendran et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Rajendran et al\\.", "year": 2015}, {"title": "Boosting english-chinese machine transliteration via high quality alignment and multilingual resources", "author": ["Shao et al.2015] Yan Shao", "J\u00f6rg Tiedemann", "Joakim Nivre"], "venue": "Proceedings of NEWS 2015 The Fifth Named Entities Workshop,", "citeRegEx": "Shao et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Shao et al\\.", "year": 2015}, {"title": "Sequence to sequence learning with neural networks", "author": ["Oriol Vinyals", "Quoc V. Le"], "venue": "In Advances in Neural Information Processing Systems 27: Annual Conference on Neural Information Processing Systems", "citeRegEx": "Sutskever et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "2015a. Grammar as a foreign language", "author": ["Lukasz Kaiser", "Terry Koo", "Slav Petrov", "Ilya Sutskever", "Geoffrey E. Hinton"], "venue": "In Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing", "citeRegEx": "Vinyals et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Vinyals et al\\.", "year": 2015}, {"title": "2015b. Show and tell: A neural image caption generator", "author": ["Alexander Toshev", "Samy Bengio", "Dumitru Erhan"], "venue": "In IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "Vinyals et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Vinyals et al\\.", "year": 2015}, {"title": "Pivot language approach for phrase-based statistical machine translation", "author": ["Wu", "Wang2007] Hua Wu", "Haifeng Wang"], "venue": "ACL", "citeRegEx": "Wu et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Wu et al\\.", "year": 2007}, {"title": "Show, attend and tell: Neural image caption generation with visual attention", "author": ["Xu et al.2015] Kelvin Xu", "Jimmy Ba", "Ryan Kiros", "Kyunghyun Cho", "Aaron C. Courville", "Ruslan Salakhutdinov", "Richard S. Zemel", "Yoshua Bengio"], "venue": null, "citeRegEx": "Xu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Xu et al\\.", "year": 2015}, {"title": "Report of news 2012 machine transliteration shared task", "author": ["Zhang et al.2012] Min Zhang", "Haizhou Li", "A. Kumaran", "Ming Liu"], "venue": "In Proceedings of the 4th Named Entity Workshop,", "citeRegEx": "Zhang et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2012}, {"title": "Improving pivot-based statistical machine translation by pivoting the co-occurrence count of phrase pairs", "author": ["Zhu et al.2014] Xiaoning Zhu", "Zhongjun He", "Hua Wu", "Conghui Zhu", "Haifeng Wang", "Tiejun Zhao"], "venue": "In Proceedings of the 2014 Conference on Empiri-", "citeRegEx": "Zhu et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zhu et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 20, "context": "Interlingua based MT (Nirenburg, 1994; Dorr et al., 2010) relies on the principle that every language in the world can be mapped to a common linguistic representation.", "startOffset": 21, "endOffset": 57}, {"referenceID": 8, "context": "Interlingua based MT (Nirenburg, 1994; Dorr et al., 2010) relies on the principle that every language in the world can be mapped to a common linguistic representation.", "startOffset": 21, "endOffset": 57}, {"referenceID": 16, "context": "For example, current state of the art statistical systems for MT (Koehn et al., 2003; Chiang, 2005; Luong et al., 2015b), transliteration (Finch et al.", "startOffset": 65, "endOffset": 120}, {"referenceID": 5, "context": "For example, current state of the art statistical systems for MT (Koehn et al., 2003; Chiang, 2005; Luong et al., 2015b), transliteration (Finch et al.", "startOffset": 65, "endOffset": 120}, {"referenceID": 10, "context": ", 2015b), transliteration (Finch et al., 2015; Shao et al., 2015; Nicolai et al., 2015), image captioning (Vinyals et al.", "startOffset": 26, "endOffset": 87}, {"referenceID": 22, "context": ", 2015b), transliteration (Finch et al., 2015; Shao et al., 2015; Nicolai et al., 2015), image captioning (Vinyals et al.", "startOffset": 26, "endOffset": 87}, {"referenceID": 19, "context": ", 2015b), transliteration (Finch et al., 2015; Shao et al., 2015; Nicolai et al., 2015), image captioning (Vinyals et al.", "startOffset": 26, "endOffset": 87}, {"referenceID": 27, "context": ", 2015), image captioning (Vinyals et al., 2015b; Xu et al., 2015), etc.", "startOffset": 26, "endOffset": 66}, {"referenceID": 28, "context": "For example, publicly available parallel datasets for transliteration (Zhang et al., 2012) cater to < 20 languages.", "startOffset": 70, "endOffset": 90}, {"referenceID": 11, "context": "Note that our work should not be confused with the recent work of (Firat et al., 2016), (Zoph and Knight, 2016) and (Elliott et al.", "startOffset": 66, "endOffset": 86}, {"referenceID": 9, "context": ", 2016), (Zoph and Knight, 2016) and (Elliott et al., 2015).", "startOffset": 37, "endOffset": 59}, {"referenceID": 6, "context": "Encoder decoder based architectures for sequence to sequence generation were initially proposed in (Cho et al., 2014; Sutskever et al., 2014) in the context of Machine Translation (MT) and have also been successfully used for generating captions for images (Vinyals et al.", "startOffset": 99, "endOffset": 141}, {"referenceID": 23, "context": "Encoder decoder based architectures for sequence to sequence generation were initially proposed in (Cho et al., 2014; Sutskever et al., 2014) in the context of Machine Translation (MT) and have also been successfully used for generating captions for images (Vinyals et al.", "startOffset": 99, "endOffset": 141}, {"referenceID": 1, "context": "els have been more successful than vanilla encoderdecoder models and have been used successfully for MT (Bahdanau et al., 2014), parsing (Vinyals et al.", "startOffset": 104, "endOffset": 127}, {"referenceID": 7, "context": ", 2015a), speech recognition (Chorowski et al., 2015), image captioning (Xu et al.", "startOffset": 29, "endOffset": 53}, {"referenceID": 27, "context": ", 2015), image captioning (Xu et al., 2015) among other ap-", "startOffset": 26, "endOffset": 43}, {"referenceID": 9, "context": "Encoder decoder models in a multi-source, single target setting have been explored by (Elliott et al., 2015) and (Zoph and Knight, 2016).", "startOffset": 86, "endOffset": 108}, {"referenceID": 9, "context": "Encoder decoder models in a multi-source, single target setting have been explored by (Elliott et al., 2015) and (Zoph and Knight, 2016). Specifically, Elliott et al. (2015) try to generate a German caption", "startOffset": 87, "endOffset": 174}, {"referenceID": 11, "context": "Recent work by Firat et al. (2016) explores", "startOffset": 15, "endOffset": 35}, {"referenceID": 11, "context": "However, Firat et al. (2016) focus on multi-task learning with a shared attention mechanism and the goal is to improve the MT performance for a pair of languages for which parallel data is available.", "startOffset": 9, "endOffset": 29}, {"referenceID": 13, "context": "For example (Khapra et al., 2010) use a bridge language or pivot language to do machine transliteration.", "startOffset": 12, "endOffset": 33}, {"referenceID": 29, "context": "Similarly, (Wu and Wang, 2007; Zhu et al., 2014) do pivot based machine translation.", "startOffset": 11, "endOffset": 48}, {"referenceID": 20, "context": "Lastly, we would also like to mention the work in interlingua based Machine Translation (Nirenburg, 1994; Dorr et al., 2010) which is clearly the inspiration for this work even though the focus of this work is not on MT.", "startOffset": 88, "endOffset": 124}, {"referenceID": 8, "context": "Lastly, we would also like to mention the work in interlingua based Machine Translation (Nirenburg, 1994; Dorr et al., 2010) which is clearly the inspiration for this work even though the focus of this work is not on MT.", "startOffset": 88, "endOffset": 124}, {"referenceID": 15, "context": "The idea of learning common representations for multiple views has been explored well in the past (Klementiev et al., 2012; Chandar et al., 2014; Hermann and Blunsom, 2014; Chandar et al., 2016; Rajendran et al., 2015).", "startOffset": 98, "endOffset": 218}, {"referenceID": 3, "context": "The idea of learning common representations for multiple views has been explored well in the past (Klementiev et al., 2012; Chandar et al., 2014; Hermann and Blunsom, 2014; Chandar et al., 2016; Rajendran et al., 2015).", "startOffset": 98, "endOffset": 218}, {"referenceID": 4, "context": "The idea of learning common representations for multiple views has been explored well in the past (Klementiev et al., 2012; Chandar et al., 2014; Hermann and Blunsom, 2014; Chandar et al., 2016; Rajendran et al., 2015).", "startOffset": 98, "endOffset": 218}, {"referenceID": 21, "context": "The idea of learning common representations for multiple views has been explored well in the past (Klementiev et al., 2012; Chandar et al., 2014; Hermann and Blunsom, 2014; Chandar et al., 2016; Rajendran et al., 2015).", "startOffset": 98, "endOffset": 218}, {"referenceID": 3, "context": "(Chandar et al., 2014; Chandar et al., 2016) propose correlational neural networks for common representation learning and Rajendran et al.", "startOffset": 0, "endOffset": 44}, {"referenceID": 4, "context": "(Chandar et al., 2014; Chandar et al., 2016) propose correlational neural networks for common representation learning and Rajendran et al.", "startOffset": 0, "endOffset": 44}, {"referenceID": 3, "context": "(Chandar et al., 2014; Chandar et al., 2016) propose correlational neural networks for common representation learning and Rajendran et al. (2015) propose bridge correlational", "startOffset": 1, "endOffset": 146}, {"referenceID": 21, "context": "From the point of view of representation learning, the work of Rajendran et al. (2015) is very similar to our work except that it focuses only on representation learning and does not consider the", "startOffset": 63, "endOffset": 87}, {"referenceID": 6, "context": "A two stage encoder-decoder is a straight-forward extension of sequence to sequence models (Cho et al., 2014; Sutskever et al., 2014) to the bridge setup.", "startOffset": 91, "endOffset": 133}, {"referenceID": 23, "context": "A two stage encoder-decoder is a straight-forward extension of sequence to sequence models (Cho et al., 2014; Sutskever et al., 2014) to the bridge setup.", "startOffset": 91, "endOffset": 133}, {"referenceID": 28, "context": "shared task (Zhang et al., 2012).", "startOffset": 12, "endOffset": 32}, {"referenceID": 16, "context": "SMT (Koehn et al., 2003) based transliteration systems using D1 and D2.", "startOffset": 4, "endOffset": 24}, {"referenceID": 13, "context": "This is very encouraging especially because such 2-stage approaches are considered to be very strong baselines for these tasks (Khapra et al., 2010).", "startOffset": 127, "endOffset": 148}, {"referenceID": 21, "context": "test set recently released by (Rajendran et al., 2015).", "startOffset": 30, "endOffset": 54}, {"referenceID": 21, "context": "Note that (Rajendran et al., 2015) report results for cross modal search and do not address the problem of crosslingual image captioning.", "startOffset": 10, "endOffset": 34}, {"referenceID": 21, "context": "In our model, for D1 we use the same train(118K), validation (1K) and test sets (1K) as defined in (Rajendran et al., 2015) and explained above.", "startOffset": 99, "endOffset": 123}, {"referenceID": 2, "context": "Initially we considered the corpus released as part of WMT\u201912 (Callison-Burch et al., 2012) which", "startOffset": 62, "endOffset": 91}, {"referenceID": 21, "context": "Since we did not have such a corpus at our disposal we decided to follow (Rajendran et al., 2015) and use a pseudo parallel corpus between English-French.", "startOffset": 73, "endOffset": 97}], "year": 2016, "abstractText": "Interlingua based Machine Translation (MT) aims to encode multiple languages into a common linguistic representation and then decode sentences in multiple target languages from this representation. In this work we explore this idea in the context of neural encoder decoder architectures, albeit on a smaller scale and without MT as the end goal. Specifically, we consider the case of three languages or modalities X , Z and Y wherein we are interested in generating sequences in Y starting from information available in X . However, there is no parallel training data available between X and Y but, training data is available between X & Z and Z & Y (as is often the case in many real world applications). Z thus acts as a pivot/bridge. An obvious solution, which is perhaps less elegant but works very well in practice is to train a two stage model which first converts from X to Z and then from Z to Y . Instead we explore an interlingua inspired solution which jointly learns to do the following (i) encodeX and Z to a common representation and (ii) decode Y from this common representation. We evaluate our model on two tasks: (i) bridge transliteration and (ii) bridge captioning. We report promising results in both these applications and believe that this is a right step towards truly interlingua inspired encoder decoder architectures.", "creator": "LaTeX with hyperref package"}}}