{"id": "1606.04963", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jun-2016", "title": "The Edit Distance Transducer in Action: The University of Cambridge English-German System at WMT16", "abstract": "This paper presents the University of Cambridge submission to WMT16. Motivated by the complementary nature of syntactical machine translation and neural machine translation (NMT), we exploit the synergies of Hiero and NMT in different combination schemes. Starting out with a simple neural lattice rescoring approach, we show that the Hiero lattices are often too narrow for NMT ensembles. Therefore, instead of a hard restriction of the NMT search space to the lattice, we propose to loosely couple NMT and Hiero by composition with a modified version of the edit distance transducer. The loose combination outperforms lattice rescoring, especially when using multiple NMT systems in an ensemble.", "histories": [["v1", "Wed, 15 Jun 2016 20:08:01 GMT  (420kb,D)", "http://arxiv.org/abs/1606.04963v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["felix stahlberg", "eva hasler", "bill byrne"], "accepted": false, "id": "1606.04963"}, "pdf": {"name": "1606.04963.pdf", "metadata": {"source": "CRF", "title": "The Edit Distance Transducer in Action: The University of Cambridge English-German System at WMT16", "authors": ["Felix Stahlberg"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "The results of the study show that the number of people who are able to move, to move, to move, to move, to move, to move and to move, to move, to move and to move, to move and to move, to move and to move, to move and to move, to move and to move, to move, to move and to move, to move and to move, to move and to move, to move and to move, to move and to move, to move and to move, to move and to move, to move and to move, to move, to move and to move, to move and to move, to move, to move and to move."}, {"heading": "2 Combining Hiero and NMT via Edit Distance Transducer", "text": "In contrast to the strict coupling in SGNMT, we suggest that Hiero and NMT be loosely coupled via an edit distance converter and shortest distance converter Xiv: 160 6.04 963v 1 [cs.C L] 15 Jun 2016. Loose coupling means that the NMT decoder is not limited to the Hiero grid as in previous work, but works independently of each other to create its own translation grids, which are then combined with the Hiero grids. Combination does not require exact agreement. Instead, we describe a method for combining NMT and Hiero that detects similarities between the edit distance and both the NMT and Hiero translation system values. This scheme is efficiently implemented with standard FST operations (Allauzen et al., 2007)."}, {"heading": "2.1 Composition of Finite State Transducers", "text": "The composition of two weighted converters T1, T2 (referred to as T1-T2) over a semicircle (K-T2-T2) is defined in the following (Mohri, 2004) [T1-T2] (x-y-T1 (x-z) T2 (z-y). (1) We will use this process extensively as a tool for constructing complex automats using both the NMT and the Hiero translation grids."}, {"heading": "2.2 The Edit Distance Transducer", "text": "The composition can be used together with a \"flower machine\" to calculate the edit distance between two sequences (Mohri, 2003). The edit distance converter in Figure 1 (a) transducts a sequence x to another sequence y via the alphabet {a, b} and cumulates the number of edit operations across the transitions at cost 1. In our case, x corresponds to an NMT hypothesis to be combined with a hierohypothesis. Unlike SGNMT, where we need a precise match between NMT and Hiero (up to UNKs), our edit distance-based scheme enables the combination of different hypotheses. We have replaced the standard definition of the edit distance converter (Mohri, 2003) with a finer-grained model designed to work well to combine NMT and Hiero. Instead of uniform costs, we want to reduce the cost of UNK substitutions within the MK, because we want to promote the MK substitution of the UNK."}, {"heading": "2.3 Loose Coupling of Hiero and NMT", "text": "In fact, it is not that it is a pure project, but that it is a project that is about putting people in a position to understand the world, to understand the world and to understand the world. (...) It is not that people are able to understand the world. (...) It is not that people are able to understand the world. (...) It is not that people are able to understand the world, to understand the world. (...) It is not that people are able to understand the world. (...) It is not that people are able to understand the world. (...) It is not that people are able to understand the world. (...) It is not that they are able to understand the world. (...) It is not that they are able to understand the world, to understand the world. (...) It is not that people are able to understand the world. (...) It is not that they are able to change the world, it is not that they are able to change the world. (...) It is not that they are able to change the world."}, {"heading": "3 Experimental Setup", "text": "The parallel training data includes Europarl v7, Common Crawl and News Commentary v10. Sentence pairs with sentences of more than 80 words or length ratios of more than 2.4: 1 have been deleted, as have Common Crawl sentences from other languages (Shuyo, 2010). We use news-test2014 (the filtered version) as a development set and keep news-test2015 and news-test2016 as test sets. NMT systems are built using the block framework (van Merrie \ufffd nboer et al., 2015) on the basis of the Theano library (Bastien et al., 2012) with the network architecture and hyperparameters as in (Bahdanau et al., 2015): The encoder and decoder networks consist of 1000 gated recurrent units (Cho et al., 2014). The decoder uses a single maxout (Goodfellow et al., 2013) to generate the output forward attention model described in Hieramau et al."}, {"heading": "4 Results", "text": "This year, it has reached the point where it will be able to leave the country in which it is able to retaliate."}, {"heading": "5 Conclusion and Future Work", "text": "We have presented a method based on the intersection distance that is effective in combining Hiero SMT systems with NMT ensembles. Our approach uses standard WFST operations and we have demonstrated the effectiveness of the approach with a successful WMT '16 application for English German. In the future, we plan to add back translation (Sennrich et al., 2016a) and investigate the use of character or subword-based NMT (Sennrich et al., 2016b; Chitnis and DeNero, 2015; Ling et al., 2015; Chung et al., 2016; Luong and Manning, 2016) within our combination framework."}, {"heading": "Acknowledgements", "text": "This work was supported by the UK Engineering and Physical Sciences Research Council (EPSRC grant EP / L027623 / 1)."}], "references": [{"title": "OpenFst: A general and efficient weighted finite-state transducer library", "author": ["Cyril Allauzen", "Michael Riley", "Johan Schalkwyk", "Wojciech Skut", "Mehryar Mohri."], "venue": "Implementation and Application of Automata, pages 11\u201323. Springer.", "citeRegEx": "Allauzen et al\\.,? 2007", "shortCiteRegEx": "Allauzen et al\\.", "year": 2007}, {"title": "Neural machine translation by jointly learning to align and translate", "author": ["Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio."], "venue": "ICLR.", "citeRegEx": "Bahdanau et al\\.,? 2015", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2015}, {"title": "Theano: new features and speed improvements", "author": ["Fr\u00e9d\u00e9ric Bastien", "Pascal Lamblin", "Razvan Pascanu", "James Bergstra", "Ian Goodfellow", "Arnaud Bergeron", "Nicolas Bouchard", "David Warde-Farley", "Yoshua Bengio."], "venue": "NIPS.", "citeRegEx": "Bastien et al\\.,? 2012", "shortCiteRegEx": "Bastien et al\\.", "year": 2012}, {"title": "Hierarchical phrase-based translation", "author": ["David Chiang."], "venue": "Computational Linguistics, 33(2):201\u2013228.", "citeRegEx": "Chiang.,? 2007", "shortCiteRegEx": "Chiang.", "year": 2007}, {"title": "Variablelength word encodings for neural translation models", "author": ["Rohan Chitnis", "John DeNero."], "venue": "EMNLP, pages 2088\u20132093.", "citeRegEx": "Chitnis and DeNero.,? 2015", "shortCiteRegEx": "Chitnis and DeNero.", "year": 2015}, {"title": "Learning phrase representations using RNN encoder-decoder for statistical machine translation", "author": ["Kyunghyun Cho", "Bart van Merrienboer", "Caglar Gulcehre", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio."], "venue": "EMNLP.", "citeRegEx": "Cho et al\\.,? 2014", "shortCiteRegEx": "Cho et al\\.", "year": 2014}, {"title": "A character-level decoder without explicit segmentation for neural machine translation", "author": ["Junyoung Chung", "Kyunghyun Cho", "Yoshua Bengio."], "venue": "ACL.", "citeRegEx": "Chung et al\\.,? 2016", "shortCiteRegEx": "Chung et al\\.", "year": 2016}, {"title": "Minimum Bayes risk combination of translation hypotheses from alternative morphological decompositions", "author": ["Adri\u00e0 de Gispert", "Sami Virpioja", "Mikko Kurimo", "William Byrne."], "venue": "NAACL, pages 73\u201376.", "citeRegEx": "Gispert et al\\.,? 2009", "shortCiteRegEx": "Gispert et al\\.", "year": 2009}, {"title": "Hierarchical phrase-based translation with weighted finite-state transducers and shallow-n grammars", "author": ["Adri\u00e0 de Gispert", "Gonzalo Iglesias", "Graeme Blackwood", "Eduardo R Banga", "William Byrne."], "venue": "Computational Linguistics, 36(3):505\u2013533.", "citeRegEx": "Gispert et al\\.,? 2010", "shortCiteRegEx": "Gispert et al\\.", "year": 2010}, {"title": "A post-processing system to yield reduced word error rates: Recognizer output voting error reduction (ROVER)", "author": ["Jonathan G Fiscus."], "venue": "ASRU, pages 347\u2013354.", "citeRegEx": "Fiscus.,? 1997", "shortCiteRegEx": "Fiscus.", "year": 1997}, {"title": "Minimum Bayes-risk automatic speech recognition", "author": ["Vaibhava Goel", "William J Byrne."], "venue": "Computer Speech & Language, 14(2):115\u2013135.", "citeRegEx": "Goel and Byrne.,? 2000", "shortCiteRegEx": "Goel and Byrne.", "year": 2000}, {"title": "Maxout networks", "author": ["Ian Goodfellow", "David Warde-farley", "Mehdi Mirza", "Aaron Courville", "Yoshua Bengio."], "venue": "ICML, pages 1319\u20131327.", "citeRegEx": "Goodfellow et al\\.,? 2013", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2013}, {"title": "Scalable modified Kneser-Ney language model estimation", "author": ["Kenneth Heafield", "Ivan Pouzyrevsky", "Jonathan H. Clark", "Philipp Koehn."], "venue": "ACL, pages 690\u2013696.", "citeRegEx": "Heafield et al\\.,? 2013", "shortCiteRegEx": "Heafield et al\\.", "year": 2013}, {"title": "Transducer disambiguation with sparse topological features", "author": ["Gonzalo Iglesias", "Adri\u00e0 de Gispert", "William Byrne."], "venue": "EMNLP 2015, pages 2275\u2013 2280.", "citeRegEx": "Iglesias et al\\.,? 2015", "shortCiteRegEx": "Iglesias et al\\.", "year": 2015}, {"title": "Recurrent continuous translation models", "author": ["Nal Kalchbrenner", "Phil Blunsom."], "venue": "EMNLP, page 413.", "citeRegEx": "Kalchbrenner and Blunsom.,? 2013", "shortCiteRegEx": "Kalchbrenner and Blunsom.", "year": 2013}, {"title": "Minimum Bayes-risk decoding for statistical machine translation", "author": ["Shankar Kumar", "William Byrne."], "venue": "Technical report, DTIC Document.", "citeRegEx": "Kumar and Byrne.,? 2004", "shortCiteRegEx": "Kumar and Byrne.", "year": 2004}, {"title": "Character-based neural machine translation", "author": ["Wang Ling", "Isabel Trancoso", "Chris Dyer", "Alan W Black."], "venue": "arXiv preprint arXiv:1511.04586.", "citeRegEx": "Ling et al\\.,? 2015", "shortCiteRegEx": "Ling et al\\.", "year": 2015}, {"title": "Joint decoding with multiple translation models", "author": ["Yang Liu", "Haitao Mi", "Yang Feng", "Qun Liu."], "venue": "ACL, pages 576\u2013584.", "citeRegEx": "Liu et al\\.,? 2009", "shortCiteRegEx": "Liu et al\\.", "year": 2009}, {"title": "Achieving open vocabulary neural machine translation with hybrid word-character models", "author": ["Minh-Thang Luong", "Christopher D Manning."], "venue": "ACL.", "citeRegEx": "Luong and Manning.,? 2016", "shortCiteRegEx": "Luong and Manning.", "year": 2016}, {"title": "Lattice-based minimum error rate training for statistical machine translation", "author": ["Wolfgang Macherey", "Franz Josef Och", "Ignacio Thayer", "Jakob Uszkoreit."], "venue": "EMNLP, pages 725\u2013734.", "citeRegEx": "Macherey et al\\.,? 2008", "shortCiteRegEx": "Macherey et al\\.", "year": 2008}, {"title": "On the disambiguation of weighted automata", "author": ["Mehryar Mohri", "Michael D Riley."], "venue": "Implementation and Application of Automata, pages 263\u2013 278. Springer.", "citeRegEx": "Mohri and Riley.,? 2015", "shortCiteRegEx": "Mohri and Riley.", "year": 2015}, {"title": "Edit-distance of weighted automata: General definitions and algorithms", "author": ["Mehryar Mohri."], "venue": "International Journal of Foundations of Computer Science, 14(06):957\u2013982.", "citeRegEx": "Mohri.,? 2003", "shortCiteRegEx": "Mohri.", "year": 2003}, {"title": "Weighted finite-state transducer algorithms", "author": ["Mehryar Mohri."], "venue": "An overview. In Formal Languages and Applications, pages 551\u2013563. Springer.", "citeRegEx": "Mohri.,? 2004", "shortCiteRegEx": "Mohri.", "year": 2004}, {"title": "Neural reranking improves subjective quality of machine translation: NAIST at WAT2015", "author": ["Graham Neubig", "Makoto Morishita", "Satoshi Nakamura."], "venue": "arXiv preprint arXiv:1510.05203.", "citeRegEx": "Neubig et al\\.,? 2015", "shortCiteRegEx": "Neubig et al\\.", "year": 2015}, {"title": "Improving neural machine translation models with monolingual data", "author": ["Rico Sennrich", "Barry Haddow", "Alexandra Birch."], "venue": "ACL.", "citeRegEx": "Sennrich et al\\.,? 2016a", "shortCiteRegEx": "Sennrich et al\\.", "year": 2016}, {"title": "Neural machine translation of rare words with subword units", "author": ["Rico Sennrich", "Barry Haddow", "Alexandra Birch."], "venue": "ACL.", "citeRegEx": "Sennrich et al\\.,? 2016b", "shortCiteRegEx": "Sennrich et al\\.", "year": 2016}, {"title": "Language detection library for Java", "author": ["Nakatani Shuyo."], "venue": "http://code.google.com/ p/language-detection/. [Online; accessed 1-June-2016].", "citeRegEx": "Shuyo.,? 2010", "shortCiteRegEx": "Shuyo.", "year": 2010}, {"title": "Syntactically guided neural machine translation", "author": ["Felix Stahlberg", "Eva Hasler", "Aurelien Waite", "Bill Byrne."], "venue": "ACL.", "citeRegEx": "Stahlberg et al\\.,? 2016", "shortCiteRegEx": "Stahlberg et al\\.", "year": 2016}, {"title": "Sequence to sequence learning with neural networks", "author": ["Ilya Sutskever", "Oriol Vinyals", "Quoc V Le."], "venue": "Advances in Neural Information Processing Systems, pages 3104\u20133112.", "citeRegEx": "Sutskever et al\\.,? 2014", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "Lattice minimum Bayes-risk decoding for statistical machine translation", "author": ["Roy W Tromble", "Shankar Kumar", "Franz Och", "Wolfgang Macherey."], "venue": "EMNLP, pages 620\u2013629.", "citeRegEx": "Tromble et al\\.,? 2008", "shortCiteRegEx": "Tromble et al\\.", "year": 2008}, {"title": "Blocks and fuel: Frameworks for deep learning", "author": ["Bart van Merri\u00ebnboer", "Dzmitry Bahdanau", "Vincent Dumoulin", "Dmitriy Serdyuk", "David Warde-Farley", "Jan Chorowski", "Yoshua Bengio."], "venue": "arXiv preprint arXiv:1506.00619.", "citeRegEx": "Merri\u00ebnboer et al\\.,? 2015", "shortCiteRegEx": "Merri\u00ebnboer et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 3, "context": "Previous work suggests that syntactic machine translation such as Hiero (Chiang, 2007) and Neural Machine Translation (NMT) (Kalchbrenner and Blunsom, 2013; Sutskever et al.", "startOffset": 72, "endOffset": 86}, {"referenceID": 14, "context": "Previous work suggests that syntactic machine translation such as Hiero (Chiang, 2007) and Neural Machine Translation (NMT) (Kalchbrenner and Blunsom, 2013; Sutskever et al., 2014; Cho et al., 2014; Bahdanau et al., 2015) are very different and have complementary strengths and weaknesses (Neubig et al.", "startOffset": 124, "endOffset": 221}, {"referenceID": 28, "context": "Previous work suggests that syntactic machine translation such as Hiero (Chiang, 2007) and Neural Machine Translation (NMT) (Kalchbrenner and Blunsom, 2013; Sutskever et al., 2014; Cho et al., 2014; Bahdanau et al., 2015) are very different and have complementary strengths and weaknesses (Neubig et al.", "startOffset": 124, "endOffset": 221}, {"referenceID": 5, "context": "Previous work suggests that syntactic machine translation such as Hiero (Chiang, 2007) and Neural Machine Translation (NMT) (Kalchbrenner and Blunsom, 2013; Sutskever et al., 2014; Cho et al., 2014; Bahdanau et al., 2015) are very different and have complementary strengths and weaknesses (Neubig et al.", "startOffset": 124, "endOffset": 221}, {"referenceID": 1, "context": "Previous work suggests that syntactic machine translation such as Hiero (Chiang, 2007) and Neural Machine Translation (NMT) (Kalchbrenner and Blunsom, 2013; Sutskever et al., 2014; Cho et al., 2014; Bahdanau et al., 2015) are very different and have complementary strengths and weaknesses (Neubig et al.", "startOffset": 124, "endOffset": 221}, {"referenceID": 23, "context": ", 2015) are very different and have complementary strengths and weaknesses (Neubig et al., 2015; Stahlberg et al., 2016).", "startOffset": 75, "endOffset": 120}, {"referenceID": 27, "context": ", 2015) are very different and have complementary strengths and weaknesses (Neubig et al., 2015; Stahlberg et al., 2016).", "startOffset": 75, "endOffset": 120}, {"referenceID": 23, "context": "Authors in (Neubig et al., 2015) used NMT to rescore n-best lists which were generated with a syntax-based system.", "startOffset": 11, "endOffset": 32}, {"referenceID": 17, "context": "In general, this kind of hard restriction is best avoided when combining diverse systems (Liu et al., 2009; Frederking et al., 1994).", "startOffset": 89, "endOffset": 132}, {"referenceID": 9, "context": "For example, in speech recognition, ROVER (Fiscus, 1997) is a system combination approach based on a soft voting scheme.", "startOffset": 42, "endOffset": 56}, {"referenceID": 15, "context": "In machine translation, minimum Bayes-risk (MBR) decoding (Kumar and Byrne, 2004) can be used to combine multiple systems (de Gispert et al.", "startOffset": 58, "endOffset": 81}, {"referenceID": 10, "context": "MBR also does not enforce exact agreement between systems as it distinguishes between the hypothesis space and the evidence space (Goel and Byrne, 2000; Tromble et al., 2008).", "startOffset": 130, "endOffset": 174}, {"referenceID": 29, "context": "MBR also does not enforce exact agreement between systems as it distinguishes between the hypothesis space and the evidence space (Goel and Byrne, 2000; Tromble et al., 2008).", "startOffset": 130, "endOffset": 174}, {"referenceID": 3, "context": "We find that Hiero lattices generated by grammars extracted with the usual heuristics (Chiang, 2007) do not provide enough variety to explore the full potential of neural models, especially when using NMT ensembles.", "startOffset": 86, "endOffset": 100}, {"referenceID": 0, "context": "This scheme is implemented efficiently using standard FST operations (Allauzen et al., 2007).", "startOffset": 69, "endOffset": 92}, {"referenceID": 22, "context": "The composition of two weighted transducers T1, T2 (denoted as T1 \u25e6 T2) over a semiring (K,\u2295,\u2297) is defined following (Mohri, 2004)", "startOffset": 117, "endOffset": 130}, {"referenceID": 21, "context": "Composition can be used together with a \u201cflower automaton\u201d to calculate the edit distance between two sequences (Mohri, 2003).", "startOffset": 112, "endOffset": 125}, {"referenceID": 21, "context": "We replaced the standard definition of the edit distance transducer (Mohri, 2003) by a finer-grained model designed to work well for combining NMT and Hiero.", "startOffset": 68, "endOffset": 81}, {"referenceID": 13, "context": "We keep the various costs separated by using transducers with tropical sparse tuple vector semirings (Iglesias et al., 2015).", "startOffset": 101, "endOffset": 124}, {"referenceID": 19, "context": "The sparse tuple vector semiring enables us to optimize the \u03bbparameters with LMERT (Macherey et al., 2008) on a development set.", "startOffset": 83, "endOffset": 106}, {"referenceID": 13, "context": "We could use disambiguation (Iglesias et al., 2015; Mohri and Riley, 2015) on the combined transducerC to find the best alignment for each unique NMT hypothesis.", "startOffset": 28, "endOffset": 74}, {"referenceID": 20, "context": "We could use disambiguation (Iglesias et al., 2015; Mohri and Riley, 2015) on the combined transducerC to find the best alignment for each unique NMT hypothesis.", "startOffset": 28, "endOffset": 74}, {"referenceID": 26, "context": "4:1 were deleted, as were Common Crawl sentences from other languages (Shuyo, 2010).", "startOffset": 70, "endOffset": 83}, {"referenceID": 2, "context": ", 2015) based on the Theano library (Bastien et al., 2012) with the network architecture and hyper-parameters as in (Bahdanau et al.", "startOffset": 36, "endOffset": 58}, {"referenceID": 1, "context": ", 2012) with the network architecture and hyper-parameters as in (Bahdanau et al., 2015): the encoder and decoder networks consist of 1000 gated recurrent units (Cho et al.", "startOffset": 65, "endOffset": 88}, {"referenceID": 5, "context": ", 2015): the encoder and decoder networks consist of 1000 gated recurrent units (Cho et al., 2014).", "startOffset": 80, "endOffset": 98}, {"referenceID": 11, "context": "The decoder uses a single maxout (Goodfellow et al., 2013) output layer with the feed-forward attention model described in (Bahdanau et al.", "startOffset": 33, "endOffset": 58}, {"referenceID": 1, "context": ", 2013) output layer with the feed-forward attention model described in (Bahdanau et al., 2015).", "startOffset": 72, "endOffset": 95}, {"referenceID": 12, "context": "A 5-gram language model for the Hiero system was trained on WMT16 parallel and monolingual data (Heafield et al., 2013).", "startOffset": 96, "endOffset": 119}, {"referenceID": 27, "context": "Similarly to previous work (Stahlberg et al., 2016), we observe that rescoring Hiero lattices with NMT (SGNMT) outperforms both NMT and Hiero baselines significantly on all test sets.", "startOffset": 27, "endOffset": 51}, {"referenceID": 24, "context": "1 BLEU) which do not use back-translation (Sennrich et al., 2016a).", "startOffset": 42, "endOffset": 66}, {"referenceID": 25, "context": "As in the literature, we see large variation in performance over individual NMT systems even with the same vocabulary size (Sennrich et al., 2016b), which could explain the small performance drop when increasing the vocabulary size from 50k to 60k.", "startOffset": 123, "endOffset": 147}, {"referenceID": 24, "context": "In the future, we are planning to add back-translation (Sennrich et al., 2016a) and investigate the use of character- or subword-based NMT (Sennrich et al.", "startOffset": 55, "endOffset": 79}, {"referenceID": 25, "context": ", 2016a) and investigate the use of character- or subword-based NMT (Sennrich et al., 2016b; Chitnis and DeNero, 2015; Ling et al., 2015; Chung et al., 2016; Luong and Manning, 2016) within our combination framework.", "startOffset": 68, "endOffset": 182}, {"referenceID": 4, "context": ", 2016a) and investigate the use of character- or subword-based NMT (Sennrich et al., 2016b; Chitnis and DeNero, 2015; Ling et al., 2015; Chung et al., 2016; Luong and Manning, 2016) within our combination framework.", "startOffset": 68, "endOffset": 182}, {"referenceID": 16, "context": ", 2016a) and investigate the use of character- or subword-based NMT (Sennrich et al., 2016b; Chitnis and DeNero, 2015; Ling et al., 2015; Chung et al., 2016; Luong and Manning, 2016) within our combination framework.", "startOffset": 68, "endOffset": 182}, {"referenceID": 6, "context": ", 2016a) and investigate the use of character- or subword-based NMT (Sennrich et al., 2016b; Chitnis and DeNero, 2015; Ling et al., 2015; Chung et al., 2016; Luong and Manning, 2016) within our combination framework.", "startOffset": 68, "endOffset": 182}, {"referenceID": 18, "context": ", 2016a) and investigate the use of character- or subword-based NMT (Sennrich et al., 2016b; Chitnis and DeNero, 2015; Ling et al., 2015; Chung et al., 2016; Luong and Manning, 2016) within our combination framework.", "startOffset": 68, "endOffset": 182}], "year": 2016, "abstractText": "This paper presents the University of Cambridge submission to WMT16. Motivated by the complementary nature of syntactical machine translation and neural machine translation (NMT), we exploit the synergies of Hiero and NMT in different combination schemes. Starting out with a simple neural lattice rescoring approach, we show that the Hiero lattices are often too narrow for NMT ensembles. Therefore, instead of a hard restriction of the NMT search space to the lattice, we propose to loosely couple NMT and Hiero by composition with a modified version of the edit distance transducer. The loose combination outperforms lattice rescoring, especially when using multiple NMT systems in an ensemble.", "creator": "TeX"}}}