{"id": "1606.05029", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jun-2016", "title": "No Need to Pay Attention: Simple Recurrent Neural Networks Work! (for Answering \"Simple\" Questions)", "abstract": "First-order factoid question answering assumes that the question can be answered by a single fact in a knowledge base (KB). While this does not seem like a challenging task, many recent attempts that apply either complex linguistic reasoning or deep neural networks achieve 35%-65% on benchmark sets. Our approach formulates the task as two machine learning problems: detecting the entities in the question, and classifying the question as one of the relation types in the KB. Based on this assumption of the structure, our simple yet effective approach trains two recurrent neural networks to outperform state of the art by significant margins --- relative improvement reaches 16% for WebQuestions, and surpasses 38% for SimpleQuestions.", "histories": [["v1", "Thu, 16 Jun 2016 02:20:04 GMT  (478kb,D)", "http://arxiv.org/abs/1606.05029v1", "10 pages, submitted to EMNLP 2016"], ["v2", "Fri, 28 Jul 2017 15:28:01 GMT  (42kb)", "http://arxiv.org/abs/1606.05029v2", "7 pages, to appear in EMNLP 2017"]], "COMMENTS": "10 pages, submitted to EMNLP 2016", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["ferhan ture", "oliver jojic"], "accepted": false, "id": "1606.05029"}, "pdf": {"name": "1606.05029.pdf", "metadata": {"source": "CRF", "title": "Simple and Effective Question Answering with Recurrent Neural Networks", "authors": ["Ferhan Ture", "Oliver Jojic"], "emails": ["jojic}@cable.comcast.com"], "sections": [{"heading": null, "text": "Answering factoid questions of the first order assumes that the question can be answered by a single fact in a Knowledge Base (KBS). Although this does not appear to be a challenging task, many current experiments using either complex linguistic thinking or deep neural networks achieve an accuracy of 35% to 65% on benchmark sets. Our approach formulates the task as two machine learning problems: identifying the units contained in the question and classifying the question as one of the relationship types in CBS. Based on this assumption of structure, our simple but effective approach trains two recurring neural networks to significantly exceed the state of the art - the relative improvement reaches 16% for WebQuestions and exceeds 38% for SimpleQuestions."}, {"heading": "1 Introduction", "text": "In fact, the fact is that most of them are able to save themselves, and that they are able to save themselves. (...) Most of them are able to save themselves. (...) Most of them are able to save themselves. (...) Most of them are able to save themselves. (...) Most of them are not able to save themselves. (...) Most of them are not able to save themselves. (...) Most of them are able to save themselves. (...) Most of them are able to save themselves. (...) Most of them are able to save themselves. (...) Most of them are not able to save themselves. (...) Most of them are not able to save themselves. (...) Most of them are able to save themselves. (...)"}, {"heading": "2 Related work", "text": "In fact, most of them will be able to move into a different world, in which they are able to move, in which they move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they, in which they live, in which they, in which they, in which they live, in which they, in which they live, in which they, in which they, in which they live."}, {"heading": "3 Approach", "text": "In fact, most of them will be able to move to a different world in which they are able to escape than to another world in which they are able to escape."}, {"heading": "4 Experimental Setup", "text": "In fact, it is such that most of them will be able to move into another world, in which they are able to move, in which they are able to live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live."}, {"heading": "5 Results", "text": "This year it is as far as never before in the history of the Federal Republic of Germany."}, {"heading": "6 Conclusions and Future work", "text": "We have described a simple but effective approach to answering factoid questions. We assume that firststorder QA can be reduced to two tasks, namely identifying entities and predicting relations and solutions for each with a recurrent neural network. Experimental results indicate impressive improvements over the state of the art for two commonly used QA benchmark datasets: the relative improvement in accuracy was 15.7% for WQ and 38.2% for SQ. From these very positive results, we can deduce that RNNs are very effective at tagging and classifying arbitrary text sequences. We can also argue that building a specific architecture tailored to the task has advantages over architectures that aim at making more general considerations about text (e.g. (Bordes et al., 2015; Kumar et al., 2015)). Our approach would find a non-trivial augmentation that would require us to work with both Ryan Hancher's question and other types of QS-related questions as well."}], "references": [{"title": "Semantic parsing on freebase from question-answer pairs", "author": ["Jonathan Berant", "Andrew Chou", "Roy Frostig", "Percy Liang."], "venue": "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, EMNLP 2013, 18-21 October 2013,", "citeRegEx": "Berant et al\\.,? 2013", "shortCiteRegEx": "Berant et al\\.", "year": 2013}, {"title": "Structured Retrieval for Question Answering", "author": ["Matthew W Bilotti", "Paul Ogilvie", "Jamie Callan", "Eric Nyberg."], "venue": "Proceedings of the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR \u201907, pages", "citeRegEx": "Bilotti et al\\.,? 2007", "shortCiteRegEx": "Bilotti et al\\.", "year": 2007}, {"title": "Rank Learning for Factoid Question Answering with Linguistic and Semantic Constraints", "author": ["Matthew W Bilotti", "Jonathan Elsas", "Jaime Carbonell", "Eric Nyberg."], "venue": "Proceedings of the 19th ACM International Conference on Information and Knowledge Manage-", "citeRegEx": "Bilotti et al\\.,? 2010", "shortCiteRegEx": "Bilotti et al\\.", "year": 2010}, {"title": "Question answering with subgraph embeddings", "author": ["Antoine Bordes", "Sumit Chopra", "Jason Weston."], "venue": "arXiv preprint arXiv:1406.3676.", "citeRegEx": "Bordes et al\\.,? 2014", "shortCiteRegEx": "Bordes et al\\.", "year": 2014}, {"title": "Large-scale simple question answering with memory networks", "author": ["Antoine Bordes", "Nicolas Usunier", "Sumit Chopra", "Jason Weston."], "venue": "CoRR, abs/1506.02075.", "citeRegEx": "Bordes et al\\.,? 2015", "shortCiteRegEx": "Bordes et al\\.", "year": 2015}, {"title": "Answering Questions with an N-gram Based Passage Retrieval Engine", "author": ["Davide Buscaldi", "Paolo Rosso", "Jos\u00e9 Manuel G\u00f3mezSoriano", "Emilio Sanchis."], "venue": "J. Intell. Inf. Syst., 34(2):113\u2013134, April.", "citeRegEx": "Buscaldi et al\\.,? 2010", "shortCiteRegEx": "Buscaldi et al\\.", "year": 2010}, {"title": "Large-scale semantic parsing via schema matching and lexicon extension", "author": ["Qingqing Cai", "Alexander Yates."], "venue": "ACL (1), pages 423\u2013433. Citeseer.", "citeRegEx": "Cai and Yates.,? 2013", "shortCiteRegEx": "Cai and Yates.", "year": 2013}, {"title": "A fast and accurate dependency parser using neural networks", "author": ["Danqi Chen", "Christopher D Manning."], "venue": "EMNLP, pages 740\u2013750.", "citeRegEx": "Chen and Manning.,? 2014", "shortCiteRegEx": "Chen and Manning.", "year": 2014}, {"title": "On the properties of neural machine translation: Encoder-decoder approaches", "author": ["Kyunghyun Cho", "Bart van Merri\u00ebnboer", "Dzmitry Bahdanau", "Yoshua Bengio."], "venue": "arXiv preprint arXiv:1409.1259.", "citeRegEx": "Cho et al\\.,? 2014a", "shortCiteRegEx": "Cho et al\\.", "year": 2014}, {"title": "Learning phrase representations using rnn encoder-decoder for statistical machine translation", "author": ["Kyunghyun Cho", "Bart Van Merri\u00ebnboer", "Caglar Gulcehre", "Dzmitry Bahdanau", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio."], "venue": "arXiv preprint", "citeRegEx": "Cho et al\\.,? 2014b", "shortCiteRegEx": "Cho et al\\.", "year": 2014}, {"title": "Empirical evaluation of gated recurrent neural networks on sequence modeling", "author": ["Junyoung Chung", "\u00c7aglar G\u00fcl\u00e7ehre", "KyungHyun Cho", "Yoshua Bengio."], "venue": "CoRR, abs/1412.3555.", "citeRegEx": "Chung et al\\.,? 2014", "shortCiteRegEx": "Chung et al\\.", "year": 2014}, {"title": "Natural language processing (almost) from scratch", "author": ["Ronan Collobert", "Jason Weston", "L\u00e9on Bottou", "Michael Karlen", "Koray Kavukcuoglu", "Pavel Kuksa."], "venue": "J. Mach. Learn. Res., 12:2493\u20132537, November.", "citeRegEx": "Collobert et al\\.,? 2011", "shortCiteRegEx": "Collobert et al\\.", "year": 2011}, {"title": "Question answering over freebase with multi-column convolutional neural networks", "author": ["Li Dong", "Furu Wei", "Ming Zhou", "Ke Xu."], "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference", "citeRegEx": "Dong et al\\.,? 2015", "shortCiteRegEx": "Dong et al\\.", "year": 2015}, {"title": "Finding structure in time", "author": ["Jeffrey L Elman."], "venue": "Cognitive science, 14(2):179\u2013211.", "citeRegEx": "Elman.,? 1990", "shortCiteRegEx": "Elman.", "year": 1990}, {"title": "Supervised sequence labelling with recurrent neural networks", "author": ["Alex Graves."], "venue": "Ph.D. thesis, Technical University Munich.", "citeRegEx": "Graves.,? 2008", "shortCiteRegEx": "Graves.", "year": 2008}, {"title": "Named entity recognition with long short-term memory", "author": ["James Hammerton."], "venue": "Proceedings of the seventh conference on Natural language learning at HLTNAACL 2003-Volume 4, pages 172\u2013175. Association for Computational Linguistics.", "citeRegEx": "Hammerton.,? 2003", "shortCiteRegEx": "Hammerton.", "year": 2003}, {"title": "Multiperspective sentence similarity modeling with convolutional neural networks", "author": ["Hua He", "Kevin Gimpel", "Jimmy Lin."], "venue": "Llu\u0131\u0301s M\u00e0rquez, Chris Callison-Burch, Jian Su, Daniele Pighin, and Yuval Marton, editors, Proceedings of the 2015 Conference", "citeRegEx": "He et al\\.,? 2015", "shortCiteRegEx": "He et al\\.", "year": 2015}, {"title": "Long short-term memory", "author": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber."], "venue": "Neural computation, 9(8):1735\u2013 1780.", "citeRegEx": "Hochreiter and Schmidhuber.,? 1997", "shortCiteRegEx": "Hochreiter and Schmidhuber.", "year": 1997}, {"title": "Recurrent neural network encoder with attention for community question answering", "author": ["Wei-Ning Hsu", "Yu Zhang", "James R. Glass."], "venue": "CoRR, abs/1603.07044.", "citeRegEx": "Hsu et al\\.,? 2016", "shortCiteRegEx": "Hsu et al\\.", "year": 2016}, {"title": "Bidirectional lstm-crf models for sequence tagging", "author": ["Zhiheng Huang", "Wei Xu", "Kai Yu."], "venue": "arXiv preprint arXiv:1508.01991.", "citeRegEx": "Huang et al\\.,? 2015", "shortCiteRegEx": "Huang et al\\.", "year": 2015}, {"title": "Opinion mining with deep recurrent neural networks", "author": ["Ozan Irsoy", "Claire Cardie."], "venue": "EMNLP, pages 720\u2013728.", "citeRegEx": "Irsoy and Cardie.,? 2014", "shortCiteRegEx": "Irsoy and Cardie.", "year": 2014}, {"title": "A neural network for factoid question answering over paragraphs", "author": ["Mohit Iyyer", "Jordan L. Boyd-Graber", "Leonardo Max Batista Claudino", "Richard Socher", "Hal Daum\u00e9."], "venue": "EMNLP.", "citeRegEx": "Iyyer et al\\.,? 2014", "shortCiteRegEx": "Iyyer et al\\.", "year": 2014}, {"title": "Convolutional neural networks for sentence classification", "author": ["Yoon Kim."], "venue": "arXiv preprint arXiv:1408.5882.", "citeRegEx": "Kim.,? 2014", "shortCiteRegEx": "Kim.", "year": 2014}, {"title": "Ask me anything: Dynamic memory networks for natural language processing", "author": ["Gulrajani", "Richard Socher."], "venue": "CoRR, abs/1506.07285.", "citeRegEx": "Gulrajani and Socher.,? 2015", "shortCiteRegEx": "Gulrajani and Socher.", "year": 2015}, {"title": "Twisted recurrent network for named entity recognition", "author": ["Zefu Lu", "Lei Li", "Wei Xu."], "venue": "Bay Area Machine Learning Symposium.", "citeRegEx": "Lu et al\\.,? 2015", "shortCiteRegEx": "Lu et al\\.", "year": 2015}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean."], "venue": "Advances in neural information processing systems, pages 3111\u20133119.", "citeRegEx": "Mikolov et al\\.,? 2013", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Siamese recurrent architectures for learning sentence similarity", "author": ["Jonas Mueller", "Aditya Thyagarajan."], "venue": "Dale Schuurmans and Michael P. Wellman, editors, Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, February 12-17, 2016, Phoenix,", "citeRegEx": "Mueller and Thyagarajan.,? 2016", "shortCiteRegEx": "Mueller and Thyagarajan.", "year": 2016}, {"title": "Glove: Global vectors for word representation", "author": ["Jeffrey Pennington", "Richard Socher", "Christopher D Manning."], "venue": "EMNLP, volume 14, pages 1532\u20131543.", "citeRegEx": "Pennington et al\\.,? 2014", "shortCiteRegEx": "Pennington et al\\.", "year": 2014}, {"title": "Large-scale semantic parsing without question-answer pairs", "author": ["Siva Reddy", "Mirella Lapata", "Mark Steedman."], "venue": "TACL, 2:377\u2013392.", "citeRegEx": "Reddy et al\\.,? 2014", "shortCiteRegEx": "Reddy et al\\.", "year": 2014}, {"title": "Recursive deep models for semantic compositionality over a sentiment treebank", "author": ["Richard Socher", "Alex Perelygin", "Jean Y Wu", "Jason Chuang", "Christopher D Manning", "Andrew Y Ng", "Christopher Potts."], "venue": "Proceedings of the conference on empirical meth-", "citeRegEx": "Socher et al\\.,? 2013", "shortCiteRegEx": "Socher et al\\.", "year": 2013}, {"title": "Part-of-speech tagging with bidirectional long short-term memory recurrent neural network", "author": ["Peilu Wang", "Yao Qian", "Frank K Soong", "Lei He", "Hai Zhao."], "venue": "arXiv preprint arXiv:1510.06168.", "citeRegEx": "Wang et al\\.,? 2015", "shortCiteRegEx": "Wang et al\\.", "year": 2015}, {"title": "Towards ai-complete question answering: A set of prerequisite toy tasks", "author": ["Jason Weston", "Antoine Bordes", "Sumit Chopra", "Tomas Mikolov."], "venue": "CoRR, abs/1502.05698.", "citeRegEx": "Weston et al\\.,? 2015", "shortCiteRegEx": "Weston et al\\.", "year": 2015}, {"title": "Joint relational embeddings for knowledge-based question answering", "author": ["Min-Chul Yang", "Nan Duan", "Ming Zhou", "HaeChang Rim."], "venue": "EMNLP, pages 645\u2013650.", "citeRegEx": "Yang et al\\.,? 2014", "shortCiteRegEx": "Yang et al\\.", "year": 2014}, {"title": "Question Classification Using Support Vector Machines", "author": ["Dell Zhang", "Wee Sun Lee."], "venue": "Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Informaion Retrieval, SIGIR \u201903, pages 26\u201332, New York, NY, USA.", "citeRegEx": "Zhang and Lee.,? 2003", "shortCiteRegEx": "Zhang and Lee.", "year": 2003}], "referenceMentions": [{"referenceID": 5, "context": "tic parsing), which simplifies the problem into finding the answer that best fits this representation (Buscaldi et al., 2010; Bilotti et al., 2007; Bilotti et al., 2010; Berant et al., 2013; Reddy et al., 2014).", "startOffset": 102, "endOffset": 210}, {"referenceID": 1, "context": "tic parsing), which simplifies the problem into finding the answer that best fits this representation (Buscaldi et al., 2010; Bilotti et al., 2007; Bilotti et al., 2010; Berant et al., 2013; Reddy et al., 2014).", "startOffset": 102, "endOffset": 210}, {"referenceID": 2, "context": "tic parsing), which simplifies the problem into finding the answer that best fits this representation (Buscaldi et al., 2010; Bilotti et al., 2007; Bilotti et al., 2010; Berant et al., 2013; Reddy et al., 2014).", "startOffset": 102, "endOffset": 210}, {"referenceID": 0, "context": "tic parsing), which simplifies the problem into finding the answer that best fits this representation (Buscaldi et al., 2010; Bilotti et al., 2007; Bilotti et al., 2010; Berant et al., 2013; Reddy et al., 2014).", "startOffset": 102, "endOffset": 210}, {"referenceID": 28, "context": "tic parsing), which simplifies the problem into finding the answer that best fits this representation (Buscaldi et al., 2010; Bilotti et al., 2007; Bilotti et al., 2010; Berant et al., 2013; Reddy et al., 2014).", "startOffset": 102, "endOffset": 210}, {"referenceID": 18, "context": "and Cardie, 2014; Kim, 2014; Chen and Manning, 2014), including QA (Hsu et al., 2016; Yang et al., 2014; Dong et al., 2015; Bordes et al., 2015).", "startOffset": 67, "endOffset": 144}, {"referenceID": 32, "context": "and Cardie, 2014; Kim, 2014; Chen and Manning, 2014), including QA (Hsu et al., 2016; Yang et al., 2014; Dong et al., 2015; Bordes et al., 2015).", "startOffset": 67, "endOffset": 144}, {"referenceID": 12, "context": "and Cardie, 2014; Kim, 2014; Chen and Manning, 2014), including QA (Hsu et al., 2016; Yang et al., 2014; Dong et al., 2015; Bordes et al., 2015).", "startOffset": 67, "endOffset": 144}, {"referenceID": 4, "context": "and Cardie, 2014; Kim, 2014; Chen and Manning, 2014), including QA (Hsu et al., 2016; Yang et al., 2014; Dong et al., 2015; Bordes et al., 2015).", "startOffset": 67, "endOffset": 144}, {"referenceID": 31, "context": "1 While this sounds similar to the \u201cSingle Supporting Fact\u201d task in (Weston et al., 2015), for which they report 100% accuracy, the problem becomes much more complex as the knowledge base grows to a realistic size, since the level of ambiguity increases drastically with a larger vocabulary and list of entities.", "startOffset": 68, "endOffset": 89}, {"referenceID": 6, "context": "This is the reason why we focus on well-studied, large-scale QA tasks like Free917 (Cai and Yates, 2013), WebQuestions (Be-", "startOffset": 83, "endOffset": 104}, {"referenceID": 4, "context": ", 2013) (WQ), and SimpleQuestions (Bordes et al., 2015) (SQ), that rely on Freebase as a realistic knowledge base.", "startOffset": 34, "endOffset": 55}, {"referenceID": 5, "context": "Many methods have been proposed for parsing questions, such as a pattern-based question analyzer (Buscaldi et al., 2010), combination of syntactic parsing and se-", "startOffset": 97, "endOffset": 120}, {"referenceID": 1, "context": "mantic role labeling (Bilotti et al., 2007; Bilotti et al., 2010), as well as lambda calculus (Berant et al.", "startOffset": 21, "endOffset": 65}, {"referenceID": 2, "context": "mantic role labeling (Bilotti et al., 2007; Bilotti et al., 2010), as well as lambda calculus (Berant et al.", "startOffset": 21, "endOffset": 65}, {"referenceID": 0, "context": ", 2010), as well as lambda calculus (Berant et al., 2013) and combinatory categorical grammars (CCG) (Reddy et al.", "startOffset": 36, "endOffset": 57}, {"referenceID": 28, "context": ", 2013) and combinatory categorical grammars (CCG) (Reddy et al., 2014).", "startOffset": 51, "endOffset": 71}, {"referenceID": 28, "context": "Even though Reddy et al. (2014) claim that their approach does not require as much supervision as prior work, it still relies on many Englishspecific heuristics and hand-crafted features.", "startOffset": 12, "endOffset": 32}, {"referenceID": 25, "context": "The latter can be easily trained for any language or domain in an unsupervised fashion, given a large text corpus without annotations (Mikolov et al., 2013; Pennington et al., 2014).", "startOffset": 134, "endOffset": 181}, {"referenceID": 27, "context": "The latter can be easily trained for any language or domain in an unsupervised fashion, given a large text corpus without annotations (Mikolov et al., 2013; Pennington et al., 2014).", "startOffset": 134, "endOffset": 181}, {"referenceID": 11, "context": "While many researchers have explored this space for general NLP tasks (Collobert et al., 2011), such as named entity recognition (Lu et al.", "startOffset": 70, "endOffset": 94}, {"referenceID": 24, "context": ", 2011), such as named entity recognition (Lu et al., 2015; Hammerton, 2003), sequence labeling (Graves, 2008; Chung et al.", "startOffset": 42, "endOffset": 76}, {"referenceID": 15, "context": ", 2011), such as named entity recognition (Lu et al., 2015; Hammerton, 2003), sequence labeling (Graves, 2008; Chung et al.", "startOffset": 42, "endOffset": 76}, {"referenceID": 14, "context": ", 2015; Hammerton, 2003), sequence labeling (Graves, 2008; Chung et al., 2014), part-", "startOffset": 44, "endOffset": 78}, {"referenceID": 10, "context": ", 2015; Hammerton, 2003), sequence labeling (Graves, 2008; Chung et al., 2014), part-", "startOffset": 44, "endOffset": 78}, {"referenceID": 19, "context": "of-speech tagging (Huang et al., 2015; Wang et al., 2015), chunking (Huang et al.", "startOffset": 18, "endOffset": 57}, {"referenceID": 30, "context": "of-speech tagging (Huang et al., 2015; Wang et al., 2015), chunking (Huang et al.", "startOffset": 18, "endOffset": 57}, {"referenceID": 19, "context": ", 2015), chunking (Huang et al., 2015), we are not aware of the use of RNNs to parse questions for QA.", "startOffset": 18, "endOffset": 38}, {"referenceID": 4, "context": "Memory Networks (Bordes et al., 2015) are also based on a similar principle, trying to discover supporting facts by matching the question to the compiled memory.", "startOffset": 16, "endOffset": 37}, {"referenceID": 10, "context": "Dong et al. (2015) similarly make the assumption that each question contains a target entity, and search for the best answer at most two hops away in the KB.", "startOffset": 0, "endOffset": 19}, {"referenceID": 3, "context": "Bordes et al. (2014) take advantage of the KB structure by projecting entities, relations, and subgraphs into the same latent space.", "startOffset": 0, "endOffset": 21}, {"referenceID": 33, "context": "Many researchers have shown that classifying the question into one of the pre-defined types, either based on patterns (Zhang and Lee, 2003) or a trained", "startOffset": 118, "endOffset": 139}, {"referenceID": 5, "context": "support vector machine (Buscaldi et al., 2010), improves QA accuracy.", "startOffset": 23, "endOffset": 46}, {"referenceID": 5, "context": "support vector machine (Buscaldi et al., 2010), improves QA accuracy. More recently, Iyyer et al. demonstrated the power of RNNs by treating the QuizBowl task as a classification problem (2014).", "startOffset": 24, "endOffset": 194}, {"referenceID": 21, "context": "Unlike the paragraph-long questions in the QuizBowl dataset used in (Iyyer et al., 2014), the typical factoid question contains a handful of words.", "startOffset": 68, "endOffset": 88}, {"referenceID": 4, "context": "Even though (Bordes et al., 2015) refer to firstorder factoid questions as simple questions, current approaches still struggle in accurately answering them (e.", "startOffset": 12, "endOffset": 33}, {"referenceID": 13, "context": "We modeled both problems using recurrent neural networks (RNN) (Elman, 1990).", "startOffset": 63, "endOffset": 76}, {"referenceID": 17, "context": "Certain variations of RNNs, such as long short-term memory (LSTM) (Hochreiter and Schmidhuber, 1997) and gated recurrent units (GRU) (Cho et al.", "startOffset": 66, "endOffset": 100}, {"referenceID": 8, "context": "Certain variations of RNNs, such as long short-term memory (LSTM) (Hochreiter and Schmidhuber, 1997) and gated recurrent units (GRU) (Cho et al., 2014a), also learn contextual features that are useful for the task, while learning to ignore irrelevant parts.", "startOffset": 133, "endOffset": 152}, {"referenceID": 29, "context": ", sentiment analysis (Socher et al., 2013) and machine translation (Cho et al.", "startOffset": 21, "endOffset": 42}, {"referenceID": 9, "context": ", 2013) and machine translation (Cho et al., 2014b)).", "startOffset": 32, "endOffset": 51}, {"referenceID": 3, "context": "a remedy, we follow Bordes et al. (2015), where we compare the predicted entity-relation pair to the ground truth.", "startOffset": 20, "endOffset": 41}, {"referenceID": 0, "context": "Prior work (Berant et al., 2013): lambda calculus based semantic parser 31.", "startOffset": 11, "endOffset": 32}, {"referenceID": 32, "context": "(Yang et al., 2014): entity embedding, uses Wikipedia 41.", "startOffset": 0, "endOffset": 19}, {"referenceID": 28, "context": "3 (Reddy et al., 2014): CCG-based semantic parser, uses ClueWeb 41.", "startOffset": 2, "endOffset": 22}, {"referenceID": 4, "context": "0 (Bordes et al., 2015): ensemble method, uses Paraphrase DB 42.", "startOffset": 2, "endOffset": 23}, {"referenceID": 12, "context": "9 (Dong et al., 2015): assumes entity given, CNN over Q-A pairs 45.", "startOffset": 2, "endOffset": 21}, {"referenceID": 4, "context": ", (Bordes et al., 2015; Kumar et al., 2015)).", "startOffset": 2, "endOffset": 43}], "year": 2016, "abstractText": "First-order factoid question answering assumes that the question can be answered by a single fact in a knowledge base (KB). While this does not seem like a challenging task, many recent attempts that apply either complex linguistic reasoning or deep neural networks achieve 35%\u201365% accuracy on benchmark sets. Our approach formulates the task as two machine learning problems: detecting the entities in the question, and classifying the question as one of the relation types in the KB. Based on this assumption of the structure, our simple yet effective approach trains two recurrent neural networks to outperform state of the art by significant margins \u2014 relative improvement reaches 16% for WebQuestions, and surpasses 38% for SimpleQuestions.", "creator": "TeX"}}}