{"id": "1606.05506", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Jun-2016", "title": "Learning Abstract Classes using Deep Learning", "abstract": "Humans are generally good at learning abstract concepts about objects and scenes (e.g.\\ spatial orientation, relative sizes, etc.). Over the last years convolutional neural networks have achieved almost human performance in recognizing concrete classes (i.e.\\ specific object categories). This paper tests the performance of a current CNN (GoogLeNet) on the task of differentiating between abstract classes which are trivially differentiable for humans. We trained and tested the CNN on the two abstract classes of horizontal and vertical orientation and determined how well the network is able to transfer the learned classes to other, previously unseen objects.", "histories": [["v1", "Fri, 17 Jun 2016 12:51:23 GMT  (60kb,D)", "http://arxiv.org/abs/1606.05506v1", "To be published in the proceedings of the International Conference on Bio-inspired Information and Communications Technologies 2015"]], "COMMENTS": "To be published in the proceedings of the International Conference on Bio-inspired Information and Communications Technologies 2015", "reviews": [], "SUBJECTS": "cs.CV cs.AI", "authors": ["sebastian stabinger", "antonio rodriguez-sanchez", "justus piater"], "accepted": false, "id": "1606.05506"}, "pdf": {"name": "1606.05506.pdf", "metadata": {"source": "CRF", "title": "Learning Abstract Classes using Deep Learning", "authors": ["Sebastian Stabinger", "Antonio Rodr\u00edguez-S\u00e1nchez", "Justus Piater"], "emails": ["Stabinger@uibk.ac.at", "Sanchez@uibk.ac.at", "Justus.Piater@uibk.ac.at"], "sections": [{"heading": null, "text": "Categories and Theme Descriptions I.2.10 [Vision and Scene Understanding]: Shape; I.5.4 [Applications]: Computer Vision; I.4.8 [Scene Analysis]: ShapeGeneral Terms Experimentation, Performance Keywords Deep Learning, Convolutional Neural Networks, Visual Cortex, Abstract Reasoning"}, {"heading": "1. INTRODUCTION", "text": "In recent years, the number of people who are able to do their jobs has increased significantly, by more than half; in the last ten years, the number of people who are able to do their jobs has doubled; in the last ten years, the number of people who are able to do their jobs has doubled; in the last ten years, the number of people who are able to do their jobs has doubled; in the last ten years, the number of people who are able to do their jobs has multiplied; in the last ten years, the number of people who are able to do their jobs has doubled; in the last ten years, the number of people who are able to do their jobs has increased."}, {"heading": "2. MATERIALS AND METHODS", "text": "For this work, we used the Convolutionary Neural Network GoogLeNet presented by Szegedy et al. [11], which won in ILSVRC14 in a number of categories. We slightly adapted the implementation of the Caffe [7] Deep Learning Framework to our task (i.e. the distinction between horizontal and vertical shapes).For all the experiments, we started with an initial learning rate of 0.01 and used ADAGRAD [2] to adjust the learning rate over time. We trained CNN for 1000 iterations. At that time, the loss was so small (< 0.01) that no further meaningful improvement was possible. CNN was trained 10 times on various randomly generated images to assess the mean accuracy as well as the variance for different number of training images. All the diagrams in this work show the mean accuracy as blue dots and 90% of all measurements fall within the shaded range (see Figure 2 for a test). The sample contained 250 images per class."}, {"heading": "3. EXPERIMENTS", "text": "To test how well GoogLeNet can generalize abstract classes into different shapes or representations, we use the following approach: We train GoogLeNet without pre-training on a dataset that consists of two classes, \"horizontal\" and \"vertical.\" We then test the performance of the network on a test set that contains the same two classes but is represented by different shapes or different representations (e.g. shape outline versus filled representation); and we are interested in whether CNN can distinguish the two classes and the amount of training images we need to achieve satisfactory results."}, {"heading": "3.1 Learning on Rectangles, Testing on Ellipses", "text": "We created randomly generated vertical or horizontal filled rectangles on a white background to train the network. We tested randomly generated vertical or horizontal filled ellipses (Figure 1). Figure 2 shows the accuracy of the network after 1000 iterations in relation to the number of training images used per class. CNN was able to learn and generalize the two classes more or less perfectly with about 100 training images per class. To our surprise, even 10 images per class give an average accuracy of about 90%. Predictably, the discrepancy is greater with fewer training images. It must be assumed that some images represent better representations of the classes than others. As the images are randomly generated, the quality of the entire dataset will vary more with fewer images."}, {"heading": "3.2 Learning on Outline, Testing on Filled", "text": "To test how sensitive the network is to different representations of the same shape, we trained the network for the \"horizontal\" and \"vertical\" classes of outlines of rectangles (Figure 3). We used the filled rectangles from Figure 1 for testing. Figure 4 shows that the network has much greater difficulty generalizing from outlines to filled versions of the same shape than generalizing from one filled shape to another (i.e., from rectangle to ellipse). In addition, the variance does not decrease with the number of training images. This could indicate that the network represents learning characteristics that do not capture the abstract concept, but specific information for outlines (i.e., that correspond to the training set). If CNN is able to learn abstract concepts, one reason may be that adding another outline to the training set improves accuracy. In doing so, we force the network to learn a more abstract concept."}, {"heading": "3.3 Random Shapes", "text": "We performed the last set of experiments with random shapes (Figure 6), which we created with an adapted version of the SVRT framework presented by Fleuret et al. [3] The network is able to learn the two abstract classes with these very different shapes (Figure 7) and is also able to transfer knowledge from outlines to filled shapes (Figure 9).Figure 10 shows that the network trained with random shapes is even better at recognizing the orientation of filled rectangles than the network trained on similar data sets (Figure 4 and Figure 5).As the last experiment, we investigated how well the random shapes generalize to other, textured random shapes. We used probably the most difficult test set, where texture orientation was orthogonal to orient the shape. Figure 11 shows examples of this class. The results (Figure 12) suggest that more training examples lead to differences in extreme results."}, {"heading": "4. CONCLUSION", "text": "We have shown that a state-of-the-art Convolutionary Neural Network is capable of learning abstract classes and transferring this information to other, hitherto invisible forms, but it is also obvious that current networks are sensitive to the training and test data used to determine how well knowledge transfer is functioning. Probably the best example is training on filled rectangles and testing on filled ellipses compared to training on rectangles and testing on filled rectangles. Prior to conducting experiments, it was unclear whether GoogLeNet will perform much better on the first task than on the second. Humans are generally much less affected by such representative differences and perform well on highly variable datasets, such as those seen on problem sets measuring non-verbal abstract thinking or on the bongard problems.Of course, both humans and animals already have pre-training before they are confronted with such assignments.Pre-training in the form of previously learned concepts, as well as the optimization that took place in the brain during the process."}, {"heading": "5. REFERENCES", "text": "[1] M. Bongard. Pattern Recognition. Spartan Books, 1970. [2] J. Duchi, E. Hazan, and Y. Singer. Adaptive subgradient methods for online learning and stochastic optimization. The Journal of Machine Learning Research, 12: 2121-2159, 2011. [3] F. Fleuret, T. Li, C. Dubout, E. K. Wampler, S. Yantis, and D. Geman. Comparing machines and human on a visual categorization test. Proceedings of the National Academy of Sciences, 108 (43): 17621-17625, 2011. [4] H. E. Foundalis. Phaeaco: a cognitive architecture inspired by bongard's problems. Unpublished Ph. D. Thesis, Department of Computer Science and the Cognitive Denyev Science Program. Indiana University, Bloomington, IN, 2006. [5] X. Glorot and Y. Bengio."}, {"heading": "6. APPENDIX \u2014 GOOGLENET", "text": "In this appendix, we will give a brief introduction to GoogLeNet, the revolutionary neural network used for the experiments in this paper."}, {"heading": "6.1 Inception Module", "text": "Figure 13 shows a graphical representation of a receiver module. A receiver module calculates windings with different susceptible field sizes (1 \u00d7 1, 3 \u00b7 3, 5 \u00b7 5) and 3 \u00b7 3 max pooling in parallel and concatenates all reactions to bring the output to the next layer. As this would lead to excessive amounts of parameters, 1 \u00b7 1 windings are used to reduce dimensions."}, {"heading": "6.2 GoogLeNet", "text": "GoogLeNet consists of a stack of nine receiver modules. There are three points where softmax is used to calculate the network loss: one at the end of all nine receiver modules and two after the third and sixth receiver module. The idea behind using middle layers to calculate a fault function is to promote better differentiation in lower layers and to calculate a better gradient signal. Both are required because it is a very deep network with 27 layers. For a more detailed description of the layer structure of GoogLeNet, refer to Figure 3 in the paper by Szegedy et al. [11]."}, {"heading": "6.3 Specifics of the Implementation", "text": "The implementation in the context of Caffee differs slightly from the network presented by Szegedy et al. [11]. The stochastic gradient descent with momentum is used to update the weights and the Xavier algorithm presented by Glorot et al. [5] is used to initialize the weights."}], "references": [{"title": "Pattern Recognition", "author": ["M.M. Bongard"], "venue": "Spartan Books,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1970}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["J. Duchi", "E. Hazan", "Y. Singer"], "venue": "The Journal of Machine Learning Research, 12:2121\u20132159,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2011}, {"title": "Comparing machines and humans on a visual categorization test", "author": ["F. Fleuret", "T. Li", "C. Dubout", "E.K. Wampler", "S. Yantis", "D. Geman"], "venue": "Proceedings of the National Academy of Sciences, 108(43):17621\u201317625,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2011}, {"title": "Phaeaco: a cognitive architecture inspired by bongard\u2019s problems", "author": ["H.E. Foundalis"], "venue": "Unpublished Ph. D. Thesis, Department of Computer Science and the Cognitive Science Program. Indiana University, Bloomington, IN,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2006}, {"title": "Understanding the difficulty of training deep feedforward neural networks", "author": ["X. Glorot", "Y. Bengio"], "venue": "International conference on artificial intelligence and statistics, pages 249\u2013256,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2010}, {"title": "Knowledge matters: Importance of prior information for optimization", "author": ["\u00c7. G\u00fcl\u00e7ehre", "Y. Bengio"], "venue": "arXiv preprint arXiv:1301.4083,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "Caffe: Convolutional architecture for fast feature embedding", "author": ["Y. Jia", "E. Shelhamer", "J. Donahue", "S. Karayev", "J. Long", "R. Girshick", "S. Guadarrama", "T. Darrell"], "venue": "arXiv preprint arXiv:1408.5093,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "Advances in neural information processing systems, pages 1097\u20131105,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Backpropagation applied to handwritten zip code recognition", "author": ["Y. LeCun", "B. Boser", "J.S. Denker", "D. Henderson", "R.E. Howard", "W. Hubbard", "L.D. Jackel"], "venue": "Neural computation, 1(4):541\u2013551,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1989}, {"title": "ImageNet Large Scale Visual Recognition Challenge", "author": ["O. Russakovsky", "J. Deng", "H. Su", "J. Krause", "S. Satheesh", "S. Ma", "Z. Huang", "A. Karpathy", "A. Khosla", "M. Bernstein", "A.C. Berg", "L. Fei-Fei"], "venue": "International Journal of Computer Vision (IJCV), pages 1\u201342, April", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2015}, {"title": "Going deeper with convolutions", "author": ["C. Szegedy", "W. Liu", "Y. Jia", "P. Sermanet", "S. Reed", "D. Anguelov", "D. Erhan", "V. Vanhoucke", "A. Rabinovich"], "venue": "arXiv preprint arXiv:1409.4842,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 8, "context": "[9] \u2014 have become popular for object classification.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] outperformed the state of the art methods in ILSVRC12 [10] by a wide margin in 2012.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[8] outperformed the state of the art methods in ILSVRC12 [10] by a wide margin in 2012.", "startOffset": 58, "endOffset": 62}, {"referenceID": 5, "context": "[6] who trained a CNN to recognize whether multiple presented shapes are the same.", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "The problems presented by Bongard [1] inspired us to do the research presented in this paper.", "startOffset": 34, "endOffset": 37}, {"referenceID": 3, "context": "Foundalis [4] gives a good introduction to these problems and presents a system intended to solve them computationally.", "startOffset": 10, "endOffset": 13}, {"referenceID": 2, "context": "[3] compared human performance to classical machine learning methods (Adaboost on decision stumps and Support Vector Machines) on classification tasks.", "startOffset": 0, "endOffset": 3}, {"referenceID": 10, "context": "[11].", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "We slightly adapted the implementation provided with the Caffe [7] deep learning framework to our task (i.", "startOffset": 63, "endOffset": 66}, {"referenceID": 1, "context": "01 and use ADAGRAD [2] to adapt the learning rate over time.", "startOffset": 19, "endOffset": 22}, {"referenceID": 2, "context": "[3].", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[6] also", "startOffset": 0, "endOffset": 3}], "year": 2016, "abstractText": "Humans are generally good at learning abstract concepts about objects and scenes (e.g. spatial orientation, relative sizes, etc.). Over the last years convolutional neural networks have achieved almost human performance in recognizing concrete classes (i.e. specific object categories). This paper tests the performance of a current CNN (GoogLeNet) on the task of differentiating between abstract classes which are trivially differentiable for humans. We trained and tested the CNN on the two abstract classes of horizontal and vertical orientation and determined how well the network is able to transfer the learned classes to other, previously unseen objects.", "creator": "LaTeX with hyperref package"}}}