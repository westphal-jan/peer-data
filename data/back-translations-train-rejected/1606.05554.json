{"id": "1606.05554", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Jun-2016", "title": "SMS Spam Filtering using Probabilistic Topic Modelling and Stacked Denoising Autoencoder", "abstract": "In This paper we present a novel approach to spam filtering and demonstrate its applicability with respect to SMS messages. Our approach requires minimum features engineering and a small set of la- belled data samples. Features are extracted using topic modelling based on latent Dirichlet allocation, and then a comprehensive data model is created using a Stacked Denoising Autoencoder (SDA). Topic modelling summarises the data providing ease of use and high interpretability by visualising the topics using word clouds. Given that the SMS messages can be regarded as either spam (unwanted) or ham (wanted), the SDA is able to model the messages and accurately discriminate between the two classes without the need for a pre-labelled training set. The results are compared against the state-of-the-art spam detection algorithms with our proposed approach achieving over 97% accuracy which compares favourably to the best reported algorithms presented in the literature.", "histories": [["v1", "Fri, 17 Jun 2016 15:15:18 GMT  (1802kb,D)", "http://arxiv.org/abs/1606.05554v1", "Paper was accepted to the 25th International Conference on Artificial Neural Networks (ICANN 2016)"]], "COMMENTS": "Paper was accepted to the 25th International Conference on Artificial Neural Networks (ICANN 2016)", "reviews": [], "SUBJECTS": "cs.CL cs.LG cs.NE", "authors": ["noura al moubayed", "toby breckon", "peter matthews", "a stephen mcgough"], "accepted": false, "id": "1606.05554"}, "pdf": {"name": "1606.05554.pdf", "metadata": {"source": "CRF", "title": "SMS Spam Filtering using Probabilistic Topic Modelling and Stacked Denoising Autoencoder", "authors": ["Noura Al Moubayed", "Toby Breckon", "Peter Matthews"], "emails": ["peter.matthews@durham.ac.uk", "stephen.mcgough@durham.ac.uk"], "sections": [{"heading": "1 Introduction", "text": "Short Messaging Service (SMS) applications are the most widely used applications on smartphones DA [14], where 97% of the users surveyed in the report used SMS at least once during the survey. It was expected that people worldwide send 8.3 trillion SMS messages in 2013 alone [12]. The large volume of SMS traffic opens up the possibility for spammers to switch from email to SMS spamming [7]. Previous research has shown that the most effective approach to spam filtering is to perform threat analysis at the level of message content [5]. The SMS problem is in principle very similar to email spam filtering [8,2]. However, SMS differ mainly in the nature of SMS messaging itself: 1) SMS is limited to 160 characters. 2) Users usually write an idiosyncratic language subset with abbreviations, bad spelling, SMS slang and Internet acronyms. Despite these most filters, standard functions are used extraction methods such as token-based N and token-type [6]."}, {"heading": "2 SMS Spam Filtering", "text": "The first step in a machine learning based SMS spam filter is Feature Extraction / Engineering. The classifier must effectively use this feature to distinguish between spam and ham. This is by no means a unique problem for spam filtering, but the limited text available per SMS makes the feature space sparse. This means that samples from the input area are increasingly separated, significantly reducing the data the classifier has to work with [5]. Hidalgo et al. [6] proposed the use of different features, including: normalized words, character bi- and tri-grams, and word-bigrams. A novel approach based on styleometry, i.e. statistical analysis of the linguistic style, was proposed in [15] with the aim of identifying spam messages from the style with which these messages were written. In their review of email spam filters, positive word-bags [8] were the most commonly reported in [8] the literature."}, {"heading": "3 Methods", "text": "The most commonly used methods of SMS feature extraction suffer from three main disadvantages: 1) The number of resulting features is usually high and requires the use of a feature selection method. 2) The features may be very sparse due to the limited size of SMS. 3) The features selected are usually hard-coded in the system and therefore very difficult to adapt to emerging spam patterns. To solve these problems, we have opted for the use of probabilistic topic modeling [16], a text mining technique that models latent patterns in messages that model latent patterns in text. This approach automatically identifies topics within a set of messages and assigns each message to a set of topics. The approach only requires the maximum number of topics that need to be specified. Messages are distributed over a small number of topics that minimize the effect of scarcity. The most important topic modeling can work adaptively. Topic modeling also requires only basic pre-processing data that needs to be used for automated token removal steps: Due to the most of the tokens being used."}, {"heading": "3.1 Probabilistic Topic Modeling", "text": "Topic Modelling [16] is a text mining tool that can identify latent text patterns in documents by processing large amounts of corpses regardless of the size of the individual documents. It describes in statistical terms how words in documents are generated based on a predefined number of topics using a statistical sampling method. A commonly used method of topic modeling is Latent Dirichlet Allocation (LDA) [4]. In LDA, documents are represented by a predefined number of topics where each topic is a hidden variable characterized by nominal distribution over a defined dictionary. LDA represents each document as a mixture of different topics with previous assumptions about their distribution. A topic may occur in different documents with a different probability and a word may occur in several topics with a different probability. A full description of LDA can be found in [4]."}, {"heading": "3.2 Stacked Denoising Autoencoder", "text": "The main advantage of unsupervised deep learning is that it harnesses the previously unlabeled masses of data that are easy to obtain to gain a better understanding of the emerging patterns in the data. Unsupervised deep learning is able to extract highly complex, structured data that exceeds approaches based on craftsmanship. An auto encoder (AE) consists of a visible input layer and a hidden layer. During learning, the AE goes through two phases: 1) construct the input data into the hidden layer 2) reconstruct the phase in which the hidden data is returned to the input layer. The model converges when the reconstruction error between input and output is minimal."}, {"heading": "3.3 Outlier Detection", "text": "A high RE indicates poor modeling of the input sample, while a small RE indicates an accurate representation of the input. RE between layers is only used during an unattended lecture to optimize the model parameters. In this work, we are using the entire RE in a novel way as a measurement for detecting outliers (i.e. spam). Since most of the available data is ham SDA, it is modeled more precisely than spam. In other words, spam will have higher RE than ham, making it easier to distinguish the two groups using simple linear classifiers such as FDA (Fig. 3 B)."}, {"heading": "4 Experiments and Results", "text": "The data contains 5574 messages: 747 (13.40%) marked as spam, and 4827 (86.60%) marked as ham.Initially, the text content of the messages is tokenized, and stopwords are removed. However, no parentage is applied to the data, as this affects the interpretability of the theme modeling outcomes. The pre-processed text is then used to create a dictionary and a bag of words that are passed to the LDA to generate the theme model.Ham contains a wide range of topics that are irrelevant to the distinction between spam and hamm.Therefore, only data designated as spam are used to create the theme model.A maximum of 60 topics were used, which were identified after varying the maximum number of topics between 10 and 100. After the model was built, all messages (ham and spam) were passed to the model, which generates a 60 feature vector per message, with one feature being the probability of this message."}, {"heading": "4.1 Conclusions", "text": "This paper presents a novel approach to SMS spam filtering, taking advantage of recent advances in text mining and FDA unattended outlier detection based on in-depth learning. Thematic modeling is proposed as a method of feature extraction that addresses several drawbacks of modern methods. By modeling the abstract topics responsible for generating text within a particular message, a limited number of features can be used, eliminating the need for feature selection. It also reduces scarcity in the input space, making it easier for the classifier to decipher data. The model itself is adaptive so that it can deal with emerging data patterns without the need for major redesign of the system. This, together with the ease of use and interpretability that the topic model approach provides, allows us to argue that this approach has a significant advantage in many application areas."}], "references": [{"title": "Contributions to the study of sms spam filtering: new collection and results", "author": ["T.A. Almeida", "J.M.G. Hidalgo", "A. Yamakami"], "venue": "Proceedings of the 11th ACM symposium on Document engineering. pp. 259\u2013262. ACM", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2011}, {"title": "Facing the spammers: A very effective approach to avoid junk e-mails", "author": ["T.A. Almeida", "A. Yamakami"], "venue": "Expert Systems with Applications 39(7), 6557\u20136561", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2012}, {"title": "Unsupervised feature learning and deep learning: A review and new perspectives", "author": ["Y. Bengio", "A.C. Courville", "P. Vincent"], "venue": "CoRR, abs/1206.5538 1", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "Latent dirichlet allocation", "author": ["D.M. Blei", "A.Y. Ng", "M.I. Jordan"], "venue": "the Journal of machine Learning research 3, 993\u20131022", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2003}, {"title": "Sms spam filtering: methods and data", "author": ["S.J. Delany", "M. Buckley", "D. Greene"], "venue": "Expert Systems with Applications 39(10), 9899\u20139908", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2012}, {"title": "Content based sms spam filtering", "author": ["J.M. G\u00f3mez Hidalgo", "G.C. Bringas", "E.P. S\u00e1nz", "F.C. Gar\u0107\u0131a"], "venue": "Proceedings of the 2006 ACM symposium on Document engineering. pp. 107\u2013114. ACM", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2006}, {"title": "Mobile Association (GSMA): SMS spams and mobile messaging attacks - Introduction, trends and examples", "author": ["Groupe Speciale"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2011}, {"title": "A review of machine learning approaches to spam filtering", "author": ["T.S. Guzella", "W.M. Caminhas"], "venue": "Expert Systems with Applications 36(7), 10206\u201310222", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2009}, {"title": "An assessment of case base reasoning for short text message classification", "author": ["M. Healy", "S.J. Delany", "A. Zamolotskikh"], "venue": "Conference papers. p. 42", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2004}, {"title": "A bayesian approach for text filter on 3g network", "author": ["H. Jie", "H. Bei", "P. Wenjing"], "venue": "Wireless Communications Networking and Mobile Computing (WiCOM), 2010 6th International Conference on. pp. 1\u20135. IEEE", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2010}, {"title": "Continuous Multivariate Distributions, volume 1, Models and Applications, vol", "author": ["N.L. Johnson", "S. Kotz", "N. Balakrishnan"], "venue": "59. New York: John Wiley & Sons", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2002}, {"title": "Fisher discriminant analysis with kernels", "author": ["B. Scholkopft", "K.R. Mullert"], "venue": "Neural networks for signal processing IX 1, 1", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1999}, {"title": "The smartphone difference", "author": ["A. Smith"], "venue": "Pew Research Center", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2015}, {"title": "The contribution of stylistic information to content-based mobile spam filtering", "author": ["D.N. Sohn", "J.T. Lee", "H.C. Rim"], "venue": "Proceedings of the ACL-IJCNLP 2009 Conference Short Papers. pp. 321\u2013324. Association for Computational Linguistics", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2009}, {"title": "Latent semantic analysis: a road to meaning, chapter probabilistic topic models", "author": ["M. Steyvers", "T. Griffiths"], "venue": "Laurence Erlbaum", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2007}, {"title": "Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion", "author": ["P. Vincent", "H. Larochelle", "I. Lajoie", "Y. Bengio", "P.A. Manzagol"], "venue": "The Journal of Machine Learning Research 11, 3371\u20133408", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2010}, {"title": "Filtering mobile spam by support vector machine", "author": ["Y. Xiang", "M. Chowdhury", "S. Ali"], "venue": "CSITeA\u201904: Third International Conference on Computer Sciences, Software Engineering, Information Technology, E-Business and Applications. pp. 1\u20134. International Society for Computers and Their Applications (ISCA)", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2004}], "referenceMentions": [{"referenceID": 12, "context": "Short Messaging Service (SMS) applications are the most widely used applications on smart phones [14] where 97% of surveyed users in the report used SMS at least once during the survey.", "startOffset": 97, "endOffset": 101}, {"referenceID": 6, "context": "The large volume of SMS traffic is opening up an opportunity for spammers to move from email to SMS spamming [7].", "startOffset": 109, "endOffset": 112}, {"referenceID": 4, "context": "Prior research has shown that the most effective approach for spam filtering is to perform the threat analysis on the message content level[5].", "startOffset": 139, "endOffset": 142}, {"referenceID": 7, "context": "The SMS problem is in principle very similar to email spam filtering [8,2].", "startOffset": 69, "endOffset": 74}, {"referenceID": 1, "context": "The SMS problem is in principle very similar to email spam filtering [8,2].", "startOffset": 69, "endOffset": 74}, {"referenceID": 5, "context": "Despite this most filters use standard feature extraction methods such as direct N-gram characterbased and word-based tokenisation [6].", "startOffset": 131, "endOffset": 134}, {"referenceID": 4, "context": "Supervised and unsupervised machine learning techniques are commonly trained using a collection of labelled messages of spam and non-spam (usually referred to as ham) [5].", "startOffset": 167, "endOffset": 170}, {"referenceID": 14, "context": "In this work we use a recently developed text mining method, that of probabilistic topic modelling [16], to extract the hidden topics that are statistically related to SMS.", "startOffset": 99, "endOffset": 103}, {"referenceID": 14, "context": "Topic modelling has the advantage of handling seamlessly and robustly any text size [16].", "startOffset": 84, "endOffset": 88}, {"referenceID": 15, "context": "The topics generated per SMS are then used by an unsupervised deep learning approach, stacked denoising auto-encoders (SDA) [17], to build a data model.", "startOffset": 124, "endOffset": 128}, {"referenceID": 11, "context": "A novel onset detection approach based on the built SDA model is then used to increase separation between ham and spam and finally a Fisher\u2019s linear discriminate analysis (FDA)[13] is used to classify data into spam and ham.", "startOffset": 176, "endOffset": 180}, {"referenceID": 4, "context": "This means that the samples, from the input space, are fewer and further apart, thus significantly reducing the data that the classifier has to work with [5].", "startOffset": 154, "endOffset": 157}, {"referenceID": 5, "context": "Hidalgo et al [6] suggested the use of different features including: normalised words, character bi- and tri-grams and word bi-grams.", "startOffset": 14, "endOffset": 17}, {"referenceID": 13, "context": "the statistical analysis of linguistic style, was presented in [15], with the goal of identifying spam message from the style by which those messages were written.", "startOffset": 63, "endOffset": 67}, {"referenceID": 7, "context": "In their review of email spam filtering, [8] reported that the bag of words was the most common feature used in the literature.", "startOffset": 41, "endOffset": 44}, {"referenceID": 4, "context": "The extracted features tend to be high dimensional requiring some sort of feature selection, or dimensionality reduction techniques [5,15,6].", "startOffset": 132, "endOffset": 140}, {"referenceID": 13, "context": "The extracted features tend to be high dimensional requiring some sort of feature selection, or dimensionality reduction techniques [5,15,6].", "startOffset": 132, "endOffset": 140}, {"referenceID": 5, "context": "The extracted features tend to be high dimensional requiring some sort of feature selection, or dimensionality reduction techniques [5,15,6].", "startOffset": 132, "endOffset": 140}, {"referenceID": 16, "context": "SVM [18], and unsupervised methods, e.", "startOffset": 4, "endOffset": 8}, {"referenceID": 8, "context": "k-NN [9].", "startOffset": 5, "endOffset": 8}, {"referenceID": 5, "context": "Hidalgo et al [6] evaluated a number of spam filtering methods and concluded that SVMs are the most suitable classification approaches.", "startOffset": 14, "endOffset": 17}, {"referenceID": 9, "context": "To address this issue a Bayesian approach to a Naive Bayes based classifier was used [10].", "startOffset": 85, "endOffset": 89}, {"referenceID": 14, "context": "To address these issues we have opted to use probabilistic topic modelling [16], a text mining technique that models latent patterns in the messages, that models latent patterns in the text.", "startOffset": 75, "endOffset": 79}, {"referenceID": 15, "context": "Here we use an unsupervised deep neural network: stacked denoising autoencoders [17] (SDA).", "startOffset": 80, "endOffset": 84}, {"referenceID": 14, "context": "Topic modelling [16] is a text mining tool that can identify latent text patterns in a documents contents, handling large volumes of corpuses regardless of the size of the individual documents.", "startOffset": 16, "endOffset": 20}, {"referenceID": 3, "context": "A commonly used topic modelling method is Latent Dirichlet Allocation (LDA) [4].", "startOffset": 76, "endOffset": 79}, {"referenceID": 3, "context": "A complete description of LDA can be found in [4].", "startOffset": 46, "endOffset": 49}, {"referenceID": 10, "context": "For every topic z a distribution \u03c6z on V is sampled from a known probability distribution (Dirichlet function [11]).", "startOffset": 110, "endOffset": 114}, {"referenceID": 2, "context": "of complex structured data outperforming approaches based on handcrafted features [3].", "startOffset": 82, "endOffset": 85}, {"referenceID": 2, "context": "AE normally use tied (constrained) weights for regularisation [3].", "startOffset": 62, "endOffset": 65}, {"referenceID": 15, "context": "learning the identify function, and reduce information redundancy in the input features we use a Denoising Autoencoder (DA) [17].", "startOffset": 124, "endOffset": 128}, {"referenceID": 11, "context": "In other words, spam will have higher RE than ham making it easier to discriminate the two sets (Fig 3 B) using simple linear classifiers like FDA [13].", "startOffset": 147, "endOffset": 151}, {"referenceID": 0, "context": "The SMS spam data was collected and first presented in [1].", "startOffset": 55, "endOffset": 58}, {"referenceID": 0, "context": "However to keep with the evaluation metrics reported in the literature [1] we also report the overall cross validated classification accuracy (Acc%), the Spam Caught accuracy (SC %), Blocked Ham accuracy (BH%), and Mathews Correlation Coefficient (MCC%).", "startOffset": 71, "endOffset": 74}, {"referenceID": 0, "context": "Table 1 presents our results as TM+SDA along with the commonly used methods in the literature [1] ordered by MCC%.", "startOffset": 94, "endOffset": 97}], "year": 2016, "abstractText": "In This paper we present a novel approach to spam filtering and demonstrate its applicability with respect to SMS messages. Our approach requires minimum features engineering and a small set of labelled data samples. Features are extracted using topic modelling based on latent Dirichlet allocation, and then a comprehensive data model is created using a Stacked Denoising Autoencoder (SDA). Topic modelling summarises the data providing ease of use and high interpretability by visualising the topics using word clouds. Given that the SMS messages can be regarded as either spam (unwanted) or ham (wanted), the SDA is able to model the messages and accurately discriminate between the two classes without the need for a pre-labelled training set. The results are compared against the state-of-the-art spam detection algorithms with our proposed approach achieving over 97% accuracy which compares favourably to the best reported algorithms presented in the literature.", "creator": "LaTeX with hyperref package"}}}