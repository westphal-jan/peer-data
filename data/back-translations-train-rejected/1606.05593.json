{"id": "1606.05593", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Jun-2016", "title": "Introspective Agents: Confidence Measures for General Value Functions", "abstract": "Agents of general intelligence deployed in real-world scenarios must adapt to ever-changing environmental conditions. While such adaptive agents may leverage engineered knowledge, they will require the capacity to construct and evaluate knowledge themselves from their own experience in a bottom-up, constructivist fashion. This position paper builds on the idea of encoding knowledge as temporally extended predictions through the use of general value functions. Prior work has focused on learning predictions about externally derived signals about a task or environment (e.g. battery level, joint position). Here we advocate that the agent should also predict internally generated signals regarding its own learning process - for example, an agent's confidence in its learned predictions. Finally, we suggest how such information would be beneficial in creating an introspective agent that is able to learn to make good decisions in a complex, changing world.", "histories": [["v1", "Fri, 17 Jun 2016 17:24:36 GMT  (65kb,D)", "http://arxiv.org/abs/1606.05593v1", "Accepted for presentation at the Ninth Conference on Artificial General Intelligence (AGI 2016), 4 pages, 1 figure"]], "COMMENTS": "Accepted for presentation at the Ninth Conference on Artificial General Intelligence (AGI 2016), 4 pages, 1 figure", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["craig sherstan", "adam white", "marlos c machado", "patrick m pilarski"], "accepted": false, "id": "1606.05593"}, "pdf": {"name": "1606.05593.pdf", "metadata": {"source": "CRF", "title": "Introspective Agents: Confidence Measures for General Value Functions", "authors": ["Craig Sherstan", "Adam White", "Marlos C. Machado", "Patrick M. Pilarski"], "emails": ["pilarski@ualberta.ca"], "sections": [{"heading": null, "text": "It is indeed the case that we will be able to embark on a search for new paths to follow in order to achieve our objectives."}], "references": [{"title": "Horde: A Scalable Real-time Architecture for Learning Knowledge from Unsupervised Sensorimotor Interaction Categories and Subject Descriptors", "author": ["R.S. Sutton", "J. Modayil", "M. Delp", "T. Degris", "P.M. Pilarski", "A. White", "D. Precup"], "venue": "Int. Conf. on Autonomous Agents and Multi-Agent Systems, pp. 761\u2013768", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2011}, {"title": "Multi-Timescale Nexting in a Reinforcement Learning Robot", "author": ["J. Modayil", "A. White", "R.S. Sutton"], "venue": "Adapt. Behav. 22, pp. 146\u2013160", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2014}, {"title": "Application of real-time machine learning to myoelectric prosthesis control: A case series in adaptive switching", "author": ["A.L. Edwards", "M.R. Dawson", "J.S. Hebert", "C. Sherstan", "R.S. Sutton", "K.M. Chan", "P.M. Pilarski"], "venue": "Prosthet. Orthot. Int., published online ahead of print, pp. 1\u20139", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}, {"title": "A Collaborative Approach to the Simultaneous Multi-joint Control of a Prosthetic Arm", "author": ["C. Sherstan", "J. Modayil", "P.M. Pilarski"], "venue": "Int. Conf. on Rehabilitation Robotics, pp. 13\u201318, Singapore, Singapore", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2015}, {"title": "Surfing Uncertainty: Prediction, Action, and the Embodied Mind", "author": ["A. Clark"], "venue": "Oxford University Press", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2015}, {"title": "Ensemble algorithms in reinforcement learning", "author": ["M.A. Wiering", "H. van Hasselt"], "venue": "IEEE Trans. Syst. Man, Cybern. Part B Cybern. 38, 4, pp. 930\u2013936", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2008}, {"title": "Developing a predictive approach to knowledge", "author": ["A. White"], "venue": "PhD Thesis. University of Alberta", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2015}, {"title": "Using predictive representations to improve generalization in reinforcement learning", "author": ["E.J. Rafols", "M.B. Ring", "R.S. Sutton", "B. Tanner"], "venue": "Int. Joint Conf. on Artificial Intelligence, pp. 835\u2013840", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2005}, {"title": "Better Generalization with Forecasts", "author": ["T. Schaul", "M. Ring"], "venue": "Int. Joint Conf. on Artificial Intelligence, pp. 1656\u20131662, Beijing, China", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2013}, {"title": "Predictive Representations of State", "author": ["M.L. Littman", "R.S. Sutton", "S. Singh"], "venue": "Advances in Neural Information Processing Systems 14, pp. 1555\u20131561", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2001}, {"title": "Towards Prosthetic Arms as Wearable Intelligent Robots", "author": ["C. Sherstan"], "venue": "MSc Thesis. University of Alberta", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2015}, {"title": "Interval Estimation for Reinforcement-Learning Algorithms in Continuous-State Domains", "author": ["M. White", "A. White"], "venue": "Advances in Neural Information Processing Systems 23, pp. 2433\u20132441", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2010}, {"title": "Curious model-building control systems", "author": ["J. Schmidhuber"], "venue": "IEEE Int. Joint Conf. on Neural Networks. pp. 1458\u20131463, Singapore, Singapore", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1991}], "referenceMentions": [{"referenceID": 0, "context": "Experience-grounded predictions are a powerful resource to guide decision making in environments which are too complex or dynamic to be exhaustively anticipated by an engineer [1,2].", "startOffset": 176, "endOffset": 181}, {"referenceID": 1, "context": "Experience-grounded predictions are a powerful resource to guide decision making in environments which are too complex or dynamic to be exhaustively anticipated by an engineer [1,2].", "startOffset": 176, "endOffset": 181}, {"referenceID": 0, "context": "recently introduced a generalization of value functions that makes it possible to specify general predictive questions [1].", "startOffset": 119, "endOffset": 122}, {"referenceID": 1, "context": "class of predictive questions where discounting acts as a stochastic termination function [2].", "startOffset": 90, "endOffset": 93}, {"referenceID": 1, "context": "While GVFs are relatively new, there have been several recent demonstrations of their usefulness in robot tasks, from reflexive action in mobile robots [2], to the control of prosthetic arms [3,4].", "startOffset": 152, "endOffset": 155}, {"referenceID": 2, "context": "While GVFs are relatively new, there have been several recent demonstrations of their usefulness in robot tasks, from reflexive action in mobile robots [2], to the control of prosthetic arms [3,4].", "startOffset": 191, "endOffset": 196}, {"referenceID": 3, "context": "While GVFs are relatively new, there have been several recent demonstrations of their usefulness in robot tasks, from reflexive action in mobile robots [2], to the control of prosthetic arms [3,4].", "startOffset": 191, "endOffset": 196}, {"referenceID": 4, "context": "Integrating predictions of these internal signals should improve an agent\u2019s decision making abilities towards human-level intelligence [5].", "startOffset": 135, "endOffset": 138}, {"referenceID": 5, "context": "That is, given a GVF, how confident is the agent that the learned prediction is accurate and precise? Methods such as confidence intervals or ensemble forecasting are used in many domains and may also be appropriate here [6].", "startOffset": 221, "endOffset": 224}, {"referenceID": 6, "context": "Encoding these measures as GVFs enables these internal predictions to participate in the agent\u2019s representation of state [7], which can lead to more efficient reward maximization [8,9] and more accurate prediction [10].", "startOffset": 121, "endOffset": 124}, {"referenceID": 7, "context": "Encoding these measures as GVFs enables these internal predictions to participate in the agent\u2019s representation of state [7], which can lead to more efficient reward maximization [8,9] and more accurate prediction [10].", "startOffset": 179, "endOffset": 184}, {"referenceID": 8, "context": "Encoding these measures as GVFs enables these internal predictions to participate in the agent\u2019s representation of state [7], which can lead to more efficient reward maximization [8,9] and more accurate prediction [10].", "startOffset": 179, "endOffset": 184}, {"referenceID": 9, "context": "Encoding these measures as GVFs enables these internal predictions to participate in the agent\u2019s representation of state [7], which can lead to more efficient reward maximization [8,9] and more accurate prediction [10].", "startOffset": 214, "endOffset": 218}, {"referenceID": 10, "context": "While there are many measures that could be useful for an agent in determining confidence [11], we here provide three examples which are readily represented as GVFs (see Figure 1 for examples).", "startOffset": 90, "endOffset": 94}, {"referenceID": 0, "context": "On each time step, a temporal-difference error is used to update each approximate GVF [1]; this TD error can itself be used as the cumulant of another GVF.", "startOffset": 86, "endOffset": 89}, {"referenceID": 11, "context": "The variance of a cumulant or an approximate GVF can easily be represented as the difference between two GVFs, although the process for approximating these nonstationary cumulants is somewhat more involved [12].", "startOffset": 206, "endOffset": 210}, {"referenceID": 6, "context": "In a safe environment an agent might view low confidence as an opportunity to learn more about its world [7,13].", "startOffset": 105, "endOffset": 111}, {"referenceID": 12, "context": "In a safe environment an agent might view low confidence as an opportunity to learn more about its world [7,13].", "startOffset": 105, "endOffset": 111}], "year": 2016, "abstractText": "Agents of general intelligence deployed in real-world scenarios must adapt to ever-changing environmental conditions. While such adaptive agents may leverage engineered knowledge, they will require the capacity to construct and evaluate knowledge themselves from their own experience in a bottom-up, constructivist fashion. This position paper builds on the idea of encoding knowledge as temporally extended predictions through the use of general value functions. Prior work has focused on learning predictions about externally derived signals about a task or environment (e.g. battery level, joint position). Here we advocate that the agent should also predict internally generated signals regarding its own learning process\u2014for example, an agent\u2019s confidence in its learned predictions. Finally, we suggest how such information would be beneficial in creating an introspective agent that is able to learn to make good decisions in a complex, changing world. Predictive Knowledge. The ability to autonomously construct knowledge directly from experience produced by an agent interacting with the world is a key requirement for general intelligence. One particularly promising form of knowledge that is grounded in experience is predictive knowledge\u2014here defined as a collection of multi-step predictions about observable outcomes that are contingent on different ways of behaving. Much like scientific knowledge, predictive knowledge can be maintained and updated by making a prediction, executing a procedure, and observing the outcome and updating the prediction\u2014a process completely independent of human intervention. Experience-grounded predictions are a powerful resource to guide decision making in environments which are too complex or dynamic to be exhaustively anticipated by an engineer [1,2]. A value function from the field of reinforcement learning is one way of representing predictive knowledge. Value functions are a learned or computed mapping from state to the long-term expectation of future reward. Sutton et al. recently introduced a generalization of value functions that makes it possible to specify general predictive questions [1]. These general value functions (GVFs), specify a prediction target as the expected discounted sum of future signals of interest (cumulants) observed while the agent selects actions according to some decision making policy. Temporal discounting is also generalized in GVFs from the conventional exponential weighting of future cumulants to an arbitrary, stateconditional weighting of future cumulants. This enables GVFs to specify a rich ar X iv :1 60 6. 05 59 3v 1 [ cs .A I] 1 7 Ju n 20 16", "creator": "LaTeX with hyperref package"}}}