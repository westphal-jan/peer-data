{"id": "1606.05694", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Jun-2016", "title": "DeepStance at SemEval-2016 Task 6: Detecting Stance in Tweets Using Character and Word-Level CNNs", "abstract": "This paper describes our approach for the Detecting Stance in Tweets task (SemEval-2016 Task 6). We utilized recent advances in short text categorization using deep learning to create word-level and character-level models. The choice between word-level and character-level models in each particular case was informed through validation performance. Our final system is a combination of classifiers using word-level or character-level models. We also employed novel data augmentation techniques to expand and diversify our training dataset, thus making our system more robust. Our system achieved a macro-average precision, recall and F1-scores of 0.67, 0.61 and 0.635 respectively.", "histories": [["v1", "Fri, 17 Jun 2016 22:32:50 GMT  (442kb,D)", "http://arxiv.org/abs/1606.05694v1", "SemEval 2016, San Diego, California. In Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016). San Diego, California"]], "COMMENTS": "SemEval 2016, San Diego, California. In Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016). San Diego, California", "reviews": [], "SUBJECTS": "cs.CL cs.SI", "authors": ["prashanth vijayaraghavan", "ivan sysoev", "soroush vosoughi", "deb roy"], "accepted": false, "id": "1606.05694"}, "pdf": {"name": "1606.05694.pdf", "metadata": {"source": "CRF", "title": "DeepStance at SemEval-2016 Task 6: Detecting Stance in Tweets Using Character and Word-Level CNNs", "authors": ["Prashanth Vijayaraghavan", "Ivan Sysoev", "Soroush Vosoughi"], "emails": ["pralav@mit.edu,", "isysoev@mit.edu,", "soroush@mit.edu,", "dkroy@media.mit.edu"], "sections": [{"heading": "1 Introduction", "text": "Viewpoint recognition is the task of automatically determining whether the authors of a text are against or in favour of a particular goal. Consider, for example, the following sentence: \"It was such a cold April, so much for global warming.\" The author of this sentence is most likely opposed to the concept of global warming (i.e., he does not believe in it). The work presented here is specifically aimed at detecting attitudes in tweets. The loud and idiosyncratic nature of tweets makes this a particularly difficult task. Automatic recognition of attitudes in tweets has practical applications in a number of areas. For example, it can be used as a sensor to measure Twitter users \"attitudes on various topics, such as: political topics, candidates, brand names, TV shows, etc. Extensive research has been carried out on modeling and automatic recognition of attitudes in political arenas (e.g. debates), with positive recognition being a task in it (Thomas et al, 2006 and Wiebe-Raybe, and 2009 and 2009)."}, {"heading": "2 Our Approach", "text": "We trained a different model for each of the five targets. Models for some targets used character-level Convolutionary Neural Networks (CNN), while others used word-level models. A particular target (Hillary Clinton) used a combination of character-level and word-level models. Although character-level models are robust against the idiosyncratic and noisy nature of tweets, they require a larger dataset than word-level models. Our Xiv: 160 6.05 694v 1 [cs.C L] 17 Jun 20choice between models was determined by validation performance (as explained in Section 5)."}, {"heading": "2.1 Character-Level CNN Tweet Model", "text": "It is a. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \".\" S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S \"S.\" S. \"S.\" S. \"S\" S. \"S\" S. \"S\" S. \"S\" S \"S.\" S. \"S\" S. \"S\" S. \"S\" S \"S.\" S \"S.\" S \"S.\" S \"S\" S. \"S\" S. \"S\" S. \"S\" S. \"S\" S \"S.\" S \"S.\" S \"S\" S. \"S\" S \"S\" S. \"S\" S. \"S\" S. \"S\" S. \"S\" S. \"S\" S \"S.\" S. \"S.\" S \"S\" S \"S.\" S \"S.\" S \"S\" S \"S\" S. \"S.\" S. \"S\" S \"S\" S \""}, {"heading": "2.2 Convolutional Word-Embedding Model", "text": "The Convolutionary Embedding Model (see Figure 2) assigns a d-dimensional vector to each of the n words in an input tweet, resulting in a matrix of size n x d. Each of these vectors is initialized with evenly distributed random numbers, i.e. xi-Rd. Although randomly initialized, the model will ultimately learn a search matrix R | V | \u00d7 d, in which | V | is the word size that represents the word embedding for the words in the vocabulary. We then apply a folding layer to the n \u00b7 d input matrix that takes into account all successive windows of size l and glides over the entire tweet. A filter w-Rh \u00b7 d works on the tweet to give a function card c-Rn-l + 1. We apply a max-pooling function (Collobert et al., 2011) of size p = (n \u2212 l + 1), which reduces the hierarchical size of the resulting word."}, {"heading": "3 Model Training", "text": "We trained the CharCNN model and the WordEmbedding convolutions model for different goals, selecting the best model for each of them. In our task, tweets are divided into three categories: Favor, Against, and None. We defined the Ground Truth Vector p as a single hot vector. The sizes of the fully connected layers in our CharCNN model are 1.024 and 512. Similarly, the commonly used hyperparameters of the Convolutional Word Embedding model are: l = 2, 3, 4, f = 200, d = 300, k = 256. Softmax layer picks up the output from the penultimate layers of the corresponding layers of the CharCNN technique and 512. Similarly, treat the frequently used hyperparameters of the Convolutional Word Embedding model: l = 2, 3, 4, f = 300, k = 256."}, {"heading": "4 Training Set Expansion", "text": "To form a query for the historical API, we automatically selected 40 representative hashtags for each target-attitude pair and manually filtered the resulting hashtag lists. The total number of additional tweets was 1.7 million. Since the number of collected tweets far exceeded the size of the official record, we decided to use the latter not for training purposes, but for validation purposes. For some targets (mentioned in Section 5.2), we added tweets to the collected tweets that we received by replacing some words and phrases with similar ones using Word2Vec."}, {"heading": "4.1 Identifying Representative Hashtags", "text": "We found hashtags well suited to form a data extension query. Hashtags are often used to represent a \"topic\" or \"topic\" of a tweet, thus transmitting information about both the target and the position (e.g. # stophillary2016).We measured the strength of the association between a hashtag and a particular target-attitude pair by calculating mutual information between them. More precisely, we defined two indicator variables for the occurrence of hashtags in tweets: 1. Whether the current hashtag is equal to the hashtag of interest.2. Whether the tweet has the target and the position of interest.The mutual information between two random variables is calculated as: I (X, Y) = x x, y, Y p (x) p (y) p (y) p (y) p (y) p (y).We value mutual information between our indicator variables using a Bayesian approach."}, {"heading": "4.2 Collecting and Preprocessing Tweets", "text": "As shown in Table 2, the number of tweets collected is very unevenly distributed among the target pairs, for two reasons: the unequal distribution of different positions on Twitter in general and the unequal number of representative hashtags that we were able to associate with each target pair. For example, the \"Climate Change is a Global Concern: AGAINST\" pair was only represented by 15 tweets in the training data provided, limiting us to just two representative hashtags. As our deep learning models require a balanced number of samples, we used the compensation technique described in the previous paragraph. To eliminate the possibility that the resulting classifiers would only learn the hashtags in the query, we removed these hashtags from the majority of the tweets collected and kept them in only 25% of the tweets."}, {"heading": "4.3 Augmenting Data Using Word2Vec", "text": "An exemplary application of data enhancement in NLP can be found in (Zhang and LeCun, 2015), where they used the exchange of synonyms based on the Aurus (WordNet (Fellbaum et al., 2013) to generate additional training samples. We applied the technique used by Zhang et al. (Zhang and LeCun, 2015) to our task, with the difference that we used Word2Vec (Mikolov et al., 2013) instead of a thesaurus to find similar words. The underlying intuition was that Word2Vec can provide better coverage for phrases related to our objectives. The algorithm of data augmentation is as follows. At each step, we randomly selected a tweet from the unaugmented set of phrases. We sampled a number of words / phrases that we would like to replace from a part of the augmentation parameter we replaced with Vec."}, {"heading": "5 Evaluation", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Baseline", "text": "To get a better sense of the performance of our approach, we compared the results with a simple baseline. We built a series of Naive Bayes classifiers using bag-of-word features and optimized their measurements by cross-validating the original training data 20 times. We experimented with different thresholds for the number of words to include a word in the vocabulary. We also set separate thresholds for hashtags and mentions. After selecting the most promising thresholds, priors and smoothing parameters, we executed the Naive Bayes classifiers on the test data to get the results shown in Table 3."}, {"heading": "5.2 Validation Results", "text": "The validation results influenced the choice between the word and character level for each target. Without Word2Vec magnification, the character level achieved the best performance only for the goal of \"Feminist Movement.\" When Word2Vec magnification was introduced, the character model achieved the best performance for the goal of \"Climate Change\" and the setting \"FAVOR\" for the goal of \"Hillary Clinton.\" The word level model performed better for the goals: \"Legalization of abortion,\" \"Atheism,\" and the setting \"AGAINST\" for the goal of \"Hillary Clinton.\" We were able to achieve a better average performance for the goal of \"Hillary Clinton\" by combining character level and word level with simple heuristics: Whenever sign level modeler predicts \"AGAINST,\" we resorted to the decision of the word level \"Hillary Clinton.\""}, {"heading": "5.3 SemEval Competition Results", "text": "Our model achieved a Macro F-Score of 0.6354 (placing us eighth out of 19 teams), while the most powerful model had a Macro F-Score of 0.6782. Table 5 provides detailed test data for each target and attitude."}, {"heading": "6 Discussion and Future Work", "text": "An interesting result of our work was that the character-level models performed better than the word-level models for classifying tweets (with adramatic improvements in the case of \"Hillary Clinton: FAVOR\") given sufficient data. Due to the lack of data, it was necessary to resort to data augmentation technology to generate a sufficient amount and variety of data for the character model to show its advantage. Another interesting finding from our work is the suitability of word2vec-based substitution as a data augmentation technique. As far as we know, word2vec has not been used for data augmentation in this manner to date. As can be seen in Table 5, our system did not perform particularly well for certain target pairs (e.g. atheism counters). We suspect that the reason for this is the noise and limited size of the collected training data. Therefore, we believe that the performance of the system can be improved by better data enhancement and purification techniques."}], "references": [{"title": "Natural language processing (almost) from scratch", "author": ["Pavel Kuksa"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Kuksa.,? \\Q2011\\E", "shortCiteRegEx": "Kuksa.", "year": 2011}, {"title": "Rich feature hierarchies for accurate object detection and semantic segmentation", "author": ["Jeff Donahue", "Trevor Darrell", "Jitendra Malik"], "venue": "In Proceedings of the IEEE conference on computer vision and pattern", "citeRegEx": "Girshick et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Girshick et al\\.", "year": 2014}, {"title": "Improving neural networks by preventing co-adaptation of feature detectors. arXiv preprint arXiv:1207.0580", "author": ["Nitish Srivastava", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan R Salakhutdinov"], "venue": null, "citeRegEx": "Hinton et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2012}, {"title": "Distribution of mutual information", "author": ["Marcus Hutter"], "venue": "Advances in neural information processing systems,", "citeRegEx": "Hutter.,? \\Q2002\\E", "shortCiteRegEx": "Hutter.", "year": 2002}, {"title": "Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980", "author": ["Kingma", "Ba2014] Diederik Kingma", "Jimmy Ba"], "venue": null, "citeRegEx": "Kingma et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kingma et al\\.", "year": 2014}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Support or oppose?: classifying positions in online debates from reply activities and opinion expressions", "author": ["Murakami", "Raymond2010] Akiko Murakami", "Rudy Raymond"], "venue": "In Proceedings of the 23rd International Conference on Computational", "citeRegEx": "Murakami et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Murakami et al\\.", "year": 2010}, {"title": "Recognizing stances in online debates", "author": ["Somasundaran", "Wiebe2009] Swapna Somasundaran", "Janyce Wiebe"], "venue": "In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language", "citeRegEx": "Somasundaran et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Somasundaran et al\\.", "year": 2009}, {"title": "Get out the vote: Determining support or opposition from congressional floor-debate transcripts", "author": ["Thomas et al.2006] Matt Thomas", "Bo Pang", "Lillian Lee"], "venue": "In Proceedings of the 2006 conference on empirical methods", "citeRegEx": "Thomas et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Thomas et al\\.", "year": 2006}, {"title": "Enhanced twitter sentiment classification using contextual information. In 6TH Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis (WASSA", "author": ["Helen Zhou", "Deb Roy"], "venue": null, "citeRegEx": "Vosoughi et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Vosoughi et al\\.", "year": 2015}, {"title": "Tweet2vec: Learning tweet embeddings using character-level cnn-lstm encoder-decoder", "author": ["Prashanth Vijayaraghavan", "Deb Roy"], "venue": "In Proceedings of the 39th International ACM SIGIR Conference on Research and De-", "citeRegEx": "Vosoughi et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Vosoughi et al\\.", "year": 2016}, {"title": "Text understanding from scratch. arXiv preprint arXiv:1502.01710", "author": ["Zhang", "LeCun2015] Xiang Zhang", "Yann LeCun"], "venue": null, "citeRegEx": "Zhang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 8, "context": ", debates) (Thomas et al., 2006) and on online forums (Somasundaran and Wiebe, 2009; Murakami and Raymond, 2010).", "startOffset": 11, "endOffset": 32}, {"referenceID": 9, "context": "(Vosoughi et al., 2015) for an example of a Twitter sentiment classifier).", "startOffset": 0, "endOffset": 23}, {"referenceID": 1, "context": "Character-level CNN (CharCNN) is a slight variant of the deep character level convolutional neural network introduced by Zhang et al (Zhang and LeCun, 2015), based on the success of CNNs in image recognition tasks (Girshick et al., 2014) (Hinton et al.", "startOffset": 214, "endOffset": 237}, {"referenceID": 2, "context": ", 2014) (Hinton et al., 2012).", "startOffset": 8, "endOffset": 29}, {"referenceID": 2, "context": "For regularization we apply a dropout (Hinton et al., 2012) mechanism after the first fully connected layer.", "startOffset": 38, "endOffset": 59}, {"referenceID": 3, "context": "It can be approximately computed using the formula provided in (Hutter, 2002):", "startOffset": 63, "endOffset": 77}, {"referenceID": 5, "context": "We applied the technique used by Zhang et al (Zhang and LeCun, 2015) to our task, with the difference that we used Word2Vec (Mikolov et al., 2013) instead of a thesaurus to find similar words.", "startOffset": 124, "endOffset": 146}, {"referenceID": 10, "context": ", using autoencoders for Twitter (Vosoughi et al., 2016)).", "startOffset": 33, "endOffset": 56}], "year": 2016, "abstractText": "This paper describes our approach for the Detecting Stance in Tweets task (SemEval-2016 Task 6). We utilized recent advances in short text categorization using deep learning to create word-level and character-level models. The choice between word-level and characterlevel models in each particular case was informed through validation performance. Our final system is a combination of classifiers using word-level or character-level models. We also employed novel data augmentation techniques to expand and diversify our training dataset, thus making our system more robust. Our system achieved a macro-average precision, recall and F1-scores of 0.67, 0.61 and 0.635 respectively.", "creator": "LaTeX with hyperref package"}}}