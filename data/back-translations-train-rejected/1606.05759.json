{"id": "1606.05759", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Jun-2016", "title": "Egyptian Arabic to English Statistical Machine Translation System for NIST OpenMT'2015", "abstract": "The paper describes the Egyptian Arabic-to-English statistical machine translation (SMT) system that the QCRI-Columbia-NYUAD (QCN) group submitted to the NIST OpenMT'2015 competition. The competition focused on informal dialectal Arabic, as used in SMS, chat, and speech. Thus, our efforts focused on processing and standardizing Arabic, e.g., using tools such as 3arrib and MADAMIRA. We further trained a phrase-based SMT system using state-of-the-art features and components such as operation sequence model, class-based language model, sparse features, neural network joint model, genre-based hierarchically-interpolated language model, unsupervised transliteration mining, phrase-table merging, and hypothesis combination. Our system ranked second on all three genres.", "histories": [["v1", "Sat, 18 Jun 2016 14:34:07 GMT  (26kb)", "http://arxiv.org/abs/1606.05759v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["hassan sajjad", "nadir durrani", "francisco guzman", "preslav nakov", "ahmed abdelali", "stephan vogel", "wael salloum", "ahmed el kholy", "nizar habash"], "accepted": false, "id": "1606.05759"}, "pdf": {"name": "1606.05759.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 160 6.05 759v 1 [cs.C L] 18 Jun 2016"}, {"heading": "1 Introduction", "text": "We describe the Egyptian Arabic-English Machine Translation (SMT) system of the QCN team for the NIST OpenMT '2015 evaluation campaign. The QCN team included the Qatar Computing Research Institute, Columbia University and New York University in Abu Dhabi. The OpenMT 2015 translation task challenged participants to build systems that could translate Egyptian Arabic from three different genres (SMS, chat and language) into English. Challenges presented by this multi-genre task ranged from the scarcity of parallel data for education to the heterogeneity of the source text and the heterogeneity of references. For example, much of the data provided consisted of Romanized Egyptian Arabic (aka Arabizi) rather than using the Arabic script."}, {"heading": "2 Data Preprocessing", "text": "The NIST dataset contained texts from three different genres: text messages (SMS), chat (CHT) and transcribed conversation language (CTS). We treated each of the three genres separately, i.e. we built genre-specific systems. In addition, we divided the provided training data for each genre into separate training and development sets, reserving about 3,000 sets (the number of sets roughly equals the number of sets at document level) from each set for development and using the rest for training. To evaluate the data, the organizers provided two additional sets of data: (i) an official devotion dataset (test) and (ii) a small gold dataset (TestG), which is a subset of tests."}, {"heading": "2.1 Modern Standard Arabic Preprocessing", "text": "For educational purposes, in addition to the Egyptian Arabic data (SMS, CHT, CTS) described above, some Modern Standard Arabic (MSA) data sets were provided, which consisted largely of newswire text (i.e. a different genre) and were therefore processed using a standard MSA tool: MADAMIRA in MSA mode (Pasha et al., 2014). MSA data was used to create a second phrase table that could then be combined with some of the gene-specific phrase tables. We planned to match the same morphological tokenization schemes used for Egyptian Arabic, but in the end we used only ATB segmentation for MSA. For more information on Arabic morphological challenges and tokenization schemes, see Habash (2010)."}, {"heading": "2.2 Genre-Specific Preprocessing", "text": "The Arabic side of the SMS and CHT data contained spellings and misspellings. Therefore, we normalized the spellings and standardized the spellings. Parts of the SMS and CHT data contained Romanized Arabic text (also known as Arabizi), which is written using the Roman alphabet. To homogenize the input data, we converted Arabizi to standard Arabic script (utf8). Given the conversational nature of SMS and chat, another difficulty in converting Romanized text to Arabic script was that the text was usually affected by code changes into English; therefore, it was important for us to identify the English words and not attempt to convert them into Arabic. We solved these problems with the 3ARRIB tool (Al-Badrashiny et al., 2014). On the English side of the data, there were several translation options, the first and second meanings were not provided in the rule."}, {"heading": "2.3 Egyptian Arabic Segmentation", "text": "A major problem in training an SMT system for the current edition of the task is the small size of the provided SMS, CHT and CTS data sets, which means that data economy is a serious problem. A common way to reduce it, at least on the Arabic side, where it is more severe, is to segment Arabic words into multiple tokens, e.g. by separating the main word from the attached conjunctions, pronouns, articles, etc. However, since these are separate words in English, such segmentation not only reduces scarcity, but also leads to improved word assignment into English, ultimately supporting word alignment and translation model estimates for SMT. The value of Arabic tokenization for SMT, especially under low resource conditions, has been demonstrated in the past by a number of researchers, e.g. (Badr et al., 2008; El Kholy and Habash al., 2012; ADA, Habizal, 2014; and Habizal, 2014)."}, {"heading": "2.4 Egyptian to MSA Conversion", "text": "Another way to reduce data economy is to use additional out-of-domain data, e.g. newswire; this means a double domain shift: (i) from an informal text genre to newswire and (ii) from dialectal Arabic to MSA. Although it is difficult to do anything about the domain shift, the dialectal shift is a little easier to address. Changes between dialects are often systematic and many of the differences are at the level of individual words. Previous work has shown that the conversion from Egyptian to MSA makes it easier to use MSA resources for translating dialectal Arabic (Mohamed et al., 2012; Salloum and Habash, 2011; Zbib et al al., 2012; Salloum and Habash, 2013; Sajjad et al al al al al al., 2013a; Durrani et al., MSA et al., 4a). We experimented with the system from Saad-to-Saad-3a, an Egyptian tool."}, {"heading": "3 Translation System Characteristics", "text": "We started our experiments with a strong base system that was originally designed to translate MSA into English (Sajjad et al., 2013b) and then extended it with some additional models and features (Durrani et al., 2014b). Specifically, we used minimal Bayes Risk Decoding (MBR) (Kumar and Byrne, 2004), monotonous punctuation reordering, deletion of words outside the vocabulary, operation sequence model for reordering (OSM) (Durrani et al., 2011; Durrani et al., 2013b), a smoothed BLEU + 1 version for parameter tuning (Nakov et al., 2012), etc. In light of this base system, we experimented with several further extensions that we will describe below, some of which were eventually included in our final input."}, {"heading": "3.1 Genre-Based Hierarchically-Interpolated Language Model", "text": "Initially, we experimented with building a hierarchically interpolated language model for each genre (i.e. CTS, SMS and CHT), examining the text resources available to train an English language model and dividing them into six groups: (1) Egyptian source (the landing pages of CTS, CHT and CTS training texts), (2) MSA GALE News (GALE P3 {R1, R2}, P4 {R1,2,3}), Chinese GALE (GALE P2 {BC, BC, BL, NG}), (4) MSA NEWS (newsetirr, news-par, news-trans, ISI}, (5) MSA GALE Non-News Model (GALE P1 {BLOG} P2, BC2, WEB}, four (2001) Guzi groups (2001, six)."}, {"heading": "3.2 Translation Model with Sparse Features", "text": "The next thing we experimented with were sparse features (Chiang et al., 2009), which were recently added to the Moses SMT toolkit. Specifically, we used target and source word insertion functions: (i) top 50 and (ii) all. The latter worked better and therefore we only show results for them. Results for all are shown in Table 5, where we can see that sparse features were only helpful for CHT, while they were harmful for CTS and gave mixed results for SMS. Therefore, we used them in our final system only for CHT."}, {"heading": "3.3 Class-Based Language Models", "text": "Next, we experimented with automatic word clusters, which we calculated from the source and on the landing pages of the training using mkcls. We also experimented with OSM models (Durrani et al., 2013a) via cluster IDs (Durrani et al., 2014c; Bisazza and Monz, 2014). Normally, due to the scarcity of data, the lexical OSM model falls back to context sizes of 2-3 operations, but learning sequences via cluster IDs enabled us to learn richer translations and rearrange patterns that are easier to generalize under sparse conditions. Table 6 shows the experimental results of adding a target language model and an OSM model via cluster IDs. We can see that these class-based models resulted in consistent improvements in all cases."}, {"heading": "3.4 Unsupervised Transliteration Models", "text": "One consequence of the lack of data is that at test date, the SMT system would see many unknown or non-vocabulary (OOV) words. One way to deal with them is to simply leave them unoccupied. This works reasonably well with newswire text and for languages with (roughly) the same alphabet, e.g. English and Spanish, as many OOVs are likely to be designated entities (people, places, organizations) and therefore likely to be preserved during translation. However, for languages with other scripts, such as Arabic and English, transit is not a good idea, especially if they are translated into English, since words in Arabic script do not naturally occur in English. In this case, it is much safer to just drop the OOVs, which is best done at the time of decoding; this was actually our basic strategy. A better way is to translate OOV words either during decoding or in a post-processing step (Sajad literation, unfortunately, we are not translated on this approach)."}, {"heading": "3.5 Neural Network Joint Language Model", "text": "Recently, neural networks have come back from the dead with the promise of revolutionizing NLP. Large increases in performance have already been demonstrated in speech recognition, and there have been successful applications in semantics. Most importantly for us, very significant gains in performance have also been reported for SMT using a Neural Joint Language Model or NNJM over the past year (Devlin et al., 2014). We have tried the Moses implementation of JNLM with the settings described in (Birch et al., 2014). While we have managed to achieve consistent improvements for all three genres and for both sets of tests, these gains are modest, as Table 7 shows: 0.04-0.57 BLEU points absolute, which is far removed from what was reported in (Devlin et al., 2014). It is unclear what the reasons are, but it could have to do with the small size of our training bittexts and the informal genres we have to deal with."}, {"heading": "3.6 Domain Adaptation", "text": "We experimented with different techniques for domain matching and tried to combine bio-texts from different genres, e.g. our Egyptian SMS, CHT and CTS, but also MSA news. First, we experimented with concatenating our SMS, CHT and CTS bittexts for training purposes, but then with genre-specific tuning sets; this did not work as well as some other alternatives. Next, we experimented with building separate phrase tables, an in-domain and an out-of-domain, and then (a) with phrase safeguards or (b) merging phrase tables and reordering tables as in (Nakov, 2008; Nakov and Ng, 2009; Sajjad et al., 2013b). The results of our domain matching experiments when testing SMS as a target genre are presented in Table 8. Note that test and test results differ from test G, so we are much more focused on each other."}, {"heading": "3.7 Tuning", "text": "Our phrase-based SMT system combines various features into a loglinear model. We adjust the weights for each feature of this model by optimizing BLEU (Papineni et al., 2002) on a tuning dataset from the same genre as in the test. We use PRO (Hopkins and May, 2011), but with a smoothed BLEU + 1 as proposed in (Nakov et al., 2012). We allowed the optimizer to run for up to 25 iterations and extract 1000-best lists for each iteration.The choice of tuning set has proven to have a huge impact on the quality of the parameters learned (Nakov et al., 2013a). Specifically, PRO is very sensitive to length, which in some circumstances can lead to pathological translations (Nakov et al., 2013b). As there were no official tuning sets for this year, we synthesized datasets that are CTS and SMS specific."}, {"heading": "4 Final Submission and Output Combination", "text": "We recombined hypotheses that were (a) created by our best single systems and (b) by other systems, both of which are relatively strong and can contribute diversity, e.g. by using a different word segmentation scheme. To this end, we used the Multi-Engine MT System (MEMT) (Heafield et al., 2009), which has proven effective in such a constellation and has helped to achieve state-of-the-art results in a similar competition in the past (Sajjad et al., 2013b). The results are shown in Table 10. We can see that the use of output combinations for SMS and CHT brings significant improvements. At CTS, however, BLEU fell by 0.45 points in the test. Therefore, we submitted the output combination for SMS and CHT as our primary system, but our best individual system for CTS (with D3 segmentation)."}, {"heading": "5 Conclusion", "text": "We introduced the QCN team's Egyptian Arabic-English SMT system for the NISTOpenMT '2015 evaluation campaign, covering all three genres: SMS, chat, and language.Due to the informal dialectical nature of these genres, we benefited from careful pre-processing, purification, and normalization, resulting in an improvement of up to 3 BLEU points over a strong baseline. We added a number of additional advanced features that resulted in 2.5 additional BLEU points of absolute improvement due to pre-processing. In particular, sparse features contributed 0.7 BLEU points for CHT, class-based models yielded 0.7 and 0.6 BLEU points for CHT and SMS, respectively, and NNJM yielded gains of up to 0.4 BLEU points absolute."}], "references": [{"title": "Automatic transliteration of romanized dialectal Arabic", "author": ["Ramy Eskander", "Nizar Habash", "Owen Rambow"], "venue": "In Proceedings of the Eighteenth Conference on Computational Natural Language", "citeRegEx": "Al.Badrashiny et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Al.Badrashiny et al\\.", "year": 2014}, {"title": "Unsupervised word segmentation improves dialectal Arabic to English machine translation", "author": ["Hassan Sajjad", "Alaa Khader", "Fahad Al Obaidli", "Preslav Nakov", "Stephan Vogel"], "venue": null, "citeRegEx": "Al.Mannai et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Al.Mannai et al\\.", "year": 2014}, {"title": "Segmentation for Englishto-Arabic statistical machine translation", "author": ["Badr et al.2008] Ibrahim Badr", "Rabih Zbib", "James R. Glass"], "venue": "In Proceedings of the Association for Computational Linguistics,", "citeRegEx": "Badr et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Badr et al\\.", "year": 2008}, {"title": "Edinburgh SLT and MT system description for the IWSLT 2014 evaluation", "author": ["Matthias Huck", "Nadir Durrani", "Nikolay Bogoychev", "Philipp Koehn"], "venue": "In Proceedings of the 11th International Workshop on Spo-", "citeRegEx": "Birch et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Birch et al\\.", "year": 2014}, {"title": "Class-based language modeling for translating into morphologically rich languages", "author": ["Bisazza", "Monz2014] Arianna Bisazza", "Christof Monz"], "venue": "In Proceedings of the 25th Annual Conference on Computational Linguistics,", "citeRegEx": "Bisazza et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bisazza et al\\.", "year": 2014}, {"title": "11,001 new features for statistical machine translation", "author": ["Chiang et al.2009] David Chiang", "Kevin Knight", "Wei Wang"], "venue": "In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association", "citeRegEx": "Chiang et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Chiang et al\\.", "year": 2009}, {"title": "Fast and robust neural network joint models for statistical machine translation", "author": ["Devlin et al.2014] Jacob Devlin", "Rabih Zbib", "Zhongqiang Huang", "Thomas Lamar", "Richard Schwartz", "John Makhoul"], "venue": null, "citeRegEx": "Devlin et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Devlin et al\\.", "year": 2014}, {"title": "A joint sequence translation model with integrated reordering", "author": ["Helmut Schmid", "Alexander Fraser"], "venue": "In Proceedings of the Association for Computational Linguistics: Human Language Technologies,", "citeRegEx": "Durrani et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Durrani et al\\.", "year": 2011}, {"title": "Model with minimal translation units, but decode with phrases", "author": ["Alexander Fraser", "Helmut Schmid"], "venue": "In Proceedings of the North American Chapter of the Association for Computational Linguistics: Human Lan-", "citeRegEx": "Durrani et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Durrani et al\\.", "year": 2013}, {"title": "Can Markov models over minimal translation units help phrase-based SMT", "author": ["Alexander Fraser", "Helmut Schmid", "Hieu Hoang", "Philipp Koehn"], "venue": null, "citeRegEx": "Durrani et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Durrani et al\\.", "year": 2013}, {"title": "Improving Egyptian-to-English SMT by mapping Egyptian into MSA", "author": ["Yaser Al-Onaizan", "Abraham Ittycheriah"], "venue": "In Computational Linguistics and Intelligent Text Processing,", "citeRegEx": "Durrani et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Durrani et al\\.", "year": 2014}, {"title": "Edinburgh\u2019s phrase-based machine translation systems for WMT-14", "author": ["Barry Haddow", "Philipp Koehn", "Kenneth Heafield"], "venue": "In Proceedings of the ACL 2014 Ninth Workshop on Statistical Machine Translation,", "citeRegEx": "Durrani et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Durrani et al\\.", "year": 2014}, {"title": "Investigating the usefulness of generalized word representations in SMT", "author": ["Philipp Koehn", "Helmut Schmid", "Alexander Fraser"], "venue": "In Proceedings of the 25th Annual Conference on Computational Linguistics,", "citeRegEx": "Durrani et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Durrani et al\\.", "year": 2014}, {"title": "Integrating an unsupervised transliteration model into statistical machine translation", "author": ["Hassan Sajjad", "Hieu Hoang", "Philipp Koehn"], "venue": "In Proceedings of the 15th Conference of the European Chapter of the ACL,", "citeRegEx": "Durrani et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Durrani et al\\.", "year": 2014}, {"title": "Orthographic and morphological processing for English\u2013Arabic statistical machine translation", "author": ["El Kholy", "Habash2012] Ahmed El Kholy", "Nizar Habash"], "venue": "Machine Translation,", "citeRegEx": "Kholy et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Kholy et al\\.", "year": 2012}, {"title": "QCRI at WMT12: Experiments in Spanish-English and German-English machine translation of news text", "author": ["Preslav Nakov", "Ahmed Thabet", "Stephan Vogel"], "venue": "In Proceedings of the Seventh Workshop", "citeRegEx": "Guzm\u00e1n et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Guzm\u00e1n et al\\.", "year": 2012}, {"title": "Arabic tokenization, part-ofspeech tagging and morphological disambiguation in one fell swoop", "author": ["Habash", "Rambow2005] Nizar Habash", "Owen Rambow"], "venue": "In Proceedings of the 43rd Annual Meeting on Association", "citeRegEx": "Habash et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Habash et al\\.", "year": 2005}, {"title": "MADA+TOKAN: A toolkit for Arabic tokenization, diacritization, morphological disambiguation, POS tagging, stemming and lemmatization", "author": ["Habash et al.2009] Nizar Habash", "Owen Rambow", "Ryan Roth"], "venue": null, "citeRegEx": "Habash et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Habash et al\\.", "year": 2009}, {"title": "Morphological analysis and disambiguation for dialectal Arabic", "author": ["Habash et al.2013] Nizar Habash", "Ryan Roth", "Owen Rambow", "Ramy Eskander", "Nadi Tomeh"], "venue": "In Proceedings of the 2013 Conference of the North American Chapter of the Associ-", "citeRegEx": "Habash et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Habash et al\\.", "year": 2013}, {"title": "Introduction to Arabic Natural Language Processing", "author": ["Nizar Habash"], "venue": null, "citeRegEx": "Habash.,? \\Q2010\\E", "shortCiteRegEx": "Habash.", "year": 2010}, {"title": "Machine translation system combination with flexible word ordering", "author": ["Greg Hanneman", "Alon Lavie"], "venue": "In Proceedings of the Fourth Workshop on Statistical Machine Translation,", "citeRegEx": "Heafield et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Heafield et al\\.", "year": 2009}, {"title": "Tuning as ranking", "author": ["Hopkins", "May2011] Mark Hopkins", "Jonathan May"], "venue": "In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Hopkins et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Hopkins et al\\.", "year": 2011}, {"title": "Moses: Open source toolkit for statistical machine translation", "author": ["Herbst."], "venue": "Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, ACL \u201907, pages 177\u2013180, Prague, Czech Republic.", "citeRegEx": "Herbst.,? 2007", "shortCiteRegEx": "Herbst.", "year": 2007}, {"title": "Minimum Bayes-risk decoding for statistical machine translation", "author": ["Kumar", "Byrne2004] Shankar Kumar", "William Byrne"], "venue": "In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association", "citeRegEx": "Kumar et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Kumar et al\\.", "year": 2004}, {"title": "Linguistic regularities in continuous space word representations", "author": ["Wen-tau Yih", "Geoffrey Zweig"], "venue": "In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computa-", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Transforming Standard Arabic to Colloquial Arabic", "author": ["Mohamed et al.2012] Emad Mohamed", "Behrang Mohit", "Kemal Oflazer"], "venue": "In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics", "citeRegEx": "Mohamed et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Mohamed et al\\.", "year": 2012}, {"title": "Improved statistical machine translation for resource-poor languages using related resource-rich languages", "author": ["Nakov", "Ng2009] Preslav Nakov", "Hwee Tou Ng"], "venue": "In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Pro-", "citeRegEx": "Nakov et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Nakov et al\\.", "year": 2009}, {"title": "Translating from morphologically complex languages: A paraphrase-based approach", "author": ["Nakov", "Ng2011] Preslav Nakov", "Hwee Tou Ng"], "venue": "In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Lan-", "citeRegEx": "Nakov et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Nakov et al\\.", "year": 2011}, {"title": "Improving statistical machine translation", "author": ["Nakov", "Ng2012] Preslav Nakov", "Hwee Tou Ng"], "venue": null, "citeRegEx": "Nakov et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Nakov et al\\.", "year": 2012}, {"title": "Combining word-level and character-level models for machine translation between closely-related languages", "author": ["Nakov", "Tiedemann2012] Preslav Nakov", "J\u00f6rg Tiedemann"], "venue": "In Proceedings of the 50th Annual Meeting of the Association", "citeRegEx": "Nakov et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Nakov et al\\.", "year": 2012}, {"title": "Optimizing for sentencelevel BLEU+1 yields short translations", "author": ["Nakov et al.2012] Preslav Nakov", "Francisco Guzm\u00e1n", "Stephan Vogel"], "venue": "In Proceedings of the International Conference on Computational Linguistics,", "citeRegEx": "Nakov et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Nakov et al\\.", "year": 2012}, {"title": "Parameter optimization for statistical machine translation: It pays to learn from hard examples", "author": ["Nakov et al.2013a] Preslav Nakov", "Fahad Al Obaidli", "Francisco Guzm\u00e1n", "Stephan Vogel"], "venue": null, "citeRegEx": "Nakov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Nakov et al\\.", "year": 2013}, {"title": "A tale about PRO and monsters", "author": ["Nakov et al.2013b] Preslav Nakov", "Francisco Guzm\u00e1n", "Stephan Vogel"], "venue": "In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),", "citeRegEx": "Nakov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Nakov et al\\.", "year": 2013}, {"title": "Improving English-Spanish statistical machine translation: Experiments in domain adaptation, sentence paraphrasing, tokenization, and recasing", "author": ["Preslav Nakov"], "venue": "In Proceedings of the Third Workshop on Statistical Machine Trans-", "citeRegEx": "Nakov.,? \\Q2008\\E", "shortCiteRegEx": "Nakov.", "year": 2008}, {"title": "BLEU: a method for automatic evaluation of machine translation", "author": ["Salim Roukos", "Todd Ward", "Wei-Jing Zhu"], "venue": "In Proceedings of the Association for Computational Linguistics,", "citeRegEx": "Papineni et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Papineni et al\\.", "year": 2002}, {"title": "MADAMIRA: A fast, comprehensive tool for morphological anal", "author": ["Pasha et al.2014] Arfath Pasha", "Mohamed AlBadrashiny", "Mona Diab", "Ahmed El Kholy", "Ramy Eskander", "Nizar Habash", "Manoj Pooleery", "Owen Rambow", "Ryan M Roth"], "venue": null, "citeRegEx": "Pasha et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Pasha et al\\.", "year": 2014}, {"title": "An algorithm for unsupervised transliteration mining with an application to word alignment", "author": ["Sajjad et al.2011] Hassan Sajjad", "Alexander Fraser", "Helmut Schmid"], "venue": "In Proceedings of the Association for Computational Linguistics: Human Lan-", "citeRegEx": "Sajjad et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Sajjad et al\\.", "year": 2011}, {"title": "Translating dialectal Arabic to English", "author": ["Kareem Darwish", "Yonatan Belinkov"], "venue": "In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics", "citeRegEx": "Sajjad et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Sajjad et al\\.", "year": 2013}, {"title": "QCRI at IWSLT 2013: Experiments in Arabic-English and English-Arabic spoken language translation", "author": ["Francisco Guzmn", "Preslav Nakov", "Ahmed Abdelali", "Kenton Murray", "Fahad Al Obaidli", "Stephan Vogel"], "venue": null, "citeRegEx": "Sajjad et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Sajjad et al\\.", "year": 2013}, {"title": "QCRI-MES submission at WMT13: Using transliteration mining to improve statistical machine translation", "author": ["Svetlana Smekalova", "Nadir Durrani", "Alexander Fraser", "Helmut Schmid"], "venue": null, "citeRegEx": "Sajjad et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Sajjad et al\\.", "year": 2013}, {"title": "Dialectal to standard Arabic paraphrasing to improve Arabic-English statistical machine translation", "author": ["Salloum", "Habash2011] Wael Salloum", "Nizar Habash"], "venue": "In Proceedings of the First Workshop on Algorithms and Resources for Modelling", "citeRegEx": "Salloum et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Salloum et al\\.", "year": 2011}, {"title": "Dialectal Arabic to English machine translation: Pivoting through Modern Standard Arabic", "author": ["Salloum", "Habash2013] Wael Salloum", "Nizar Habash"], "venue": "In Proceedings of the 2013 Conference of the North American Chapter of the Associ-", "citeRegEx": "Salloum et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Salloum et al\\.", "year": 2013}, {"title": "SRILM \u2013 an extensible language modeling toolkit", "author": ["Andreas Stolcke"], "venue": "In Proceedings of the International Speech Communication Association,", "citeRegEx": "Stolcke.,? \\Q2002\\E", "shortCiteRegEx": "Stolcke.", "year": 2002}, {"title": "Analyzing the use of character-level translation with sparse and noisy datasets", "author": ["Tiedemann", "Nakov2013] J\u00f6rg Tiedemann", "Preslav Nakov"], "venue": "In Proceedings of the International Conference Recent Advances in Natural Language", "citeRegEx": "Tiedemann et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Tiedemann et al\\.", "year": 2013}, {"title": "A beam-search decoder for normalization of social media text with application to machine translation", "author": ["Wang", "Ng2013] Pidong Wang", "Hwee Tou Ng"], "venue": "In Proceedings of the 2013 Conference of the North American Chapter of the Association", "citeRegEx": "Wang et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2013}, {"title": "Source language adapta", "author": ["Wang et al.2012] Pidong Wang", "Preslav Nakov", "Hwee Tou Ng"], "venue": null, "citeRegEx": "Wang et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2012}, {"title": "Machine translation of Arabic dialects", "author": ["Zbib et al.2012] Rabih Zbib", "Erika Malchiodi", "Jacob Devlin", "David Stallard", "Spyros Matsoukas", "Richard Schwartz", "John Makhoul", "Omar F. Zaidan", "Chris Callison-Burch"], "venue": "In Proceedings of the 2012 Conference", "citeRegEx": "Zbib et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Zbib et al\\.", "year": 2012}], "referenceMentions": [{"referenceID": 35, "context": ", a different genre), and thus we processed them using a standard MSA tool: MADAMIRA in MSA mode (Pasha et al., 2014).", "startOffset": 97, "endOffset": 117}, {"referenceID": 19, "context": "For more information on Arabic morphology challenges and tokenization schemes, see Habash (2010).", "startOffset": 83, "endOffset": 97}, {"referenceID": 0, "context": "We solved these issues using the 3ARRIB tool (Al-Badrashiny et al., 2014).", "startOffset": 45, "endOffset": 73}, {"referenceID": 2, "context": "tation schemes such as D3, S2 and ATB (Badr et al., 2008; Habash, 2010).", "startOffset": 38, "endOffset": 71}, {"referenceID": 19, "context": "tation schemes such as D3, S2 and ATB (Badr et al., 2008; Habash, 2010).", "startOffset": 38, "endOffset": 71}, {"referenceID": 35, "context": "For tokenization, we used MADAMIRA (Pasha et al., 2014), a fast and efficient implementation of MADA for MSA (Habash and Rambow, 2005; Habash et al.", "startOffset": 35, "endOffset": 55}, {"referenceID": 17, "context": ", 2014), a fast and efficient implementation of MADA for MSA (Habash and Rambow, 2005; Habash et al., 2009), and MADA-ARZ, a version of MADA for Egyptian Arabic (Habash et al.", "startOffset": 61, "endOffset": 107}, {"referenceID": 18, "context": ", 2009), and MADA-ARZ, a version of MADA for Egyptian Arabic (Habash et al., 2013).", "startOffset": 61, "endOffset": 82}, {"referenceID": 25, "context": "Previous work has shown that converting Egyptian to MSA makes it easier to use MSA resources for translating dialectal Arabic (Mohamed et al., 2012; Salloum and Habash, 2011; Zbib et al., 2012; Salloum and Habash, 2013; Sajjad et al., 2013a; Durrani et al., 2014a).", "startOffset": 126, "endOffset": 264}, {"referenceID": 46, "context": "Previous work has shown that converting Egyptian to MSA makes it easier to use MSA resources for translating dialectal Arabic (Mohamed et al., 2012; Salloum and Habash, 2011; Zbib et al., 2012; Salloum and Habash, 2013; Sajjad et al., 2013a; Durrani et al., 2014a).", "startOffset": 126, "endOffset": 264}, {"referenceID": 45, "context": "In general, full conversion of dialectal Arabic to MSA would require not only word-level transformations but also phrase-level ones (Wang et al., 2012), while taking context into account (Nakov and Tiedemann, 2012), and also modeling morphological phenomena (Nakov and Ng, 2011).", "startOffset": 132, "endOffset": 151}, {"referenceID": 7, "context": "monotone-at-punctuation reordering, dropping of out-of-vocabulary words, operation sequence model for reordering (OSM) (Durrani et al., 2011; Durrani et al., 2013b), a smoothed BLEU+1 version of PRO for parameter tuning (Nakov et al.", "startOffset": 119, "endOffset": 164}, {"referenceID": 28, "context": ", 2013b), a smoothed BLEU+1 version of PRO for parameter tuning (Nakov et al., 2012), etc.", "startOffset": 64, "endOffset": 84}, {"referenceID": 15, "context": "We examined the text resources that were available for training an English language model, and we split them into six groups: (1) Egyptian-source (the target sides of the CTS, CHT and CTS training bi-texts), (2) MSA GALE News (GALE P3 {R1,R2},P4{R1,2,3}), (3) Chinese GALE (GALE P2 {BC,BC,BL,NG}), (4) MSA NEWS (newsetirr, news-par, news-trans, ISI), (5) MSA GALE non-news (GALE P1 {BLOG} P2 {BC1, BC2, WEB}), and (6) Gigaword v5, split into four subgroups by year (Guzm\u00e1n et al., 2012) (1994-1997,", "startOffset": 465, "endOffset": 486}, {"referenceID": 42, "context": "We used the SRILM toolkit (Stolcke, 2002) to build", "startOffset": 26, "endOffset": 41}, {"referenceID": 5, "context": "The next thing we experimented with were sparse features (Chiang et al., 2009), which are a recent addition to the Moses SMT toolkit.", "startOffset": 57, "endOffset": 78}, {"referenceID": 24, "context": "We also tried using word2vec (Mikolov et al., 2013) for clustering, but the results did not improve any further and they were oc-", "startOffset": 29, "endOffset": 51}, {"referenceID": 36, "context": ", 2014d) based on EM as proposed in (Sajjad et al., 2011).", "startOffset": 36, "endOffset": 57}, {"referenceID": 6, "context": "Most importantly for us, last year, very sizable performance gains were also reported for SMT using a neural joint language model or NNJM (Devlin et al., 2014).", "startOffset": 138, "endOffset": 159}, {"referenceID": 3, "context": "We tried the Moses implementation of JNLM using the settings described in (Birch et al., 2014).", "startOffset": 74, "endOffset": 94}, {"referenceID": 6, "context": "57 BLEU points absolute, which is far from what was reported in (Devlin et al., 2014).", "startOffset": 64, "endOffset": 85}, {"referenceID": 33, "context": "Next, we experimented with building separate phrase tables, one in-domain and one out-of-domain, and then (a) using phrase table backoff, or (b) merging phrase tables and reordering tables as in (Nakov, 2008; Nakov and Ng, 2009; Sajjad et al., 2013b).", "startOffset": 195, "endOffset": 250}, {"referenceID": 33, "context": "merging the resulting SMS+CHT+CTS phrase table with a phrase table trained on MSA, where the two tables are merged using extra indicator features as described in (Nakov, 2008).", "startOffset": 162, "endOffset": 175}, {"referenceID": 34, "context": "We tune the weights for the individual features of that model by optimizing BLEU (Papineni et al., 2002) on a tuning dataset from the same genre as that in the test.", "startOffset": 81, "endOffset": 104}, {"referenceID": 28, "context": "(Nakov et al., 2012).", "startOffset": 0, "endOffset": 20}, {"referenceID": 20, "context": "For this purpose, we used the Multi-Engine MT system, or MEMT, (Heafield et al., 2009), which has been proven ef-", "startOffset": 63, "endOffset": 86}], "year": 2016, "abstractText": "The paper describes the Egyptian Arabicto-English statistical machine translation (SMT) system that the QCRI-ColumbiaNYUAD (QCN) group submitted to the NIST OpenMT\u20192015 competition. The competition focused on informal dialectal Arabic, as used in SMS, chat, and speech. Thus, our efforts focused on processing and standardizing Arabic, e.g., using tools such as 3arrib and MADAMIRA. We further trained a phrase-based SMT system using state-of-the-art features and components such as operation sequence model, class-based language model, sparse features, neural network joint model, genrebased hierarchically-interpolated language model, unsupervised transliteration mining, phrase-table merging, and hypothesis combination. Our system ranked second on all three genres.", "creator": "LaTeX with hyperref package"}}}