{"id": "1606.05844", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Jun-2016", "title": "Statistical Parametric Speech Synthesis Using Bottleneck Representation From Sequence Auto-encoder", "abstract": "In this paper, we describe a statistical parametric speech synthesis approach with unit-level acoustic representation. In conventional deep neural network based speech synthesis, the input text features are repeated for the entire duration of phoneme for mapping text and speech parameters. This mapping is learnt at the frame-level which is the de-facto acoustic representation. However much of this computational requirement can be drastically reduced if every unit can be represented with a fixed-dimensional representation. Using recurrent neural network based auto-encoder, we show that it is indeed possible to map units of varying duration to a single vector. We then use this acoustic representation at unit-level to synthesize speech using deep neural network based statistical parametric speech synthesis technique. Results show that the proposed approach is able to synthesize at the same quality as the conventional frame based approach at a highly reduced computational cost.", "histories": [["v1", "Sun, 19 Jun 2016 08:38:26 GMT  (475kb,D)", "http://arxiv.org/abs/1606.05844v1", "5 pages (with references)"]], "COMMENTS": "5 pages (with references)", "reviews": [], "SUBJECTS": "cs.SD cs.LG", "authors": ["sivanand achanta", "knrk raju alluri", "suryakanth v gangashetty"], "accepted": false, "id": "1606.05844"}, "pdf": {"name": "1606.05844.pdf", "metadata": {"source": "CRF", "title": "Statistical Parametric Speech Synthesis Using Bottleneck Representation From Sequence Auto-encoder", "authors": ["Sivanand Achanta", "KNRK Raju Alluri", "Suryakanth V Gangashetty"], "emails": ["sivanand.a@research.iiit.ac.in,", "raju.alluri@research.iiit.ac.in,", "svg@iiit.ac.in"], "sections": [{"heading": "1. Introduction", "text": "This year, it is as far as ever in the history of the city, where it is as far as never before."}, {"heading": "2. RNN Encoder-Decoder Model", "text": "In this section we describe the architecture of the fixed-vector encoder decoder network."}, {"heading": "2.1. ED-FVC", "text": "The block diagram of ED-FVC is shown in Fig. 1. The EDFVC architecture consists of a unidirectional RNN as encoder and decoder. The last hidden state of the encoder is taken as Initial Xiv: 160 6.05 844v 1 [cs.S D] June 19, 2016 hidden state of the decoder and also as context vector. It is this last hidden state of the encoder that we call RBN."}, {"heading": "2.1.1. SRN", "text": "In this section, we briefly look at the SRNs used in the ED-FVC network. Typically, the encoder decoder architectures use either LSTMs [9] or gated-recurrent units (GRU) [19] [11] [10] as RNN units to avoid the problem of disappearing gradients [20]. However, in this paper, we use simple RNNs. There are two reasons why SRNs can actually be preferred over LSTMs / GRUs: (1) The number of parameters in LSTM / GRU is much greater for a given hidden state than simple RNN, and (2) It is difficult to know which of these gates actually contribute to performance. Recently, there has been some work to address the latter disadvantage [21] [22], and especially in the context of SPSS in relation to RNNs."}, {"heading": "2.1.2. RNN Encoder", "text": "In our case, the encoder is a unidirectional recursive neural network. The encoder reads the entire input sequence and stores a representation in the final state vector.hft = f (Wfixt + Wfht \u2212 1) (1) Wfi, Wf are the input and recursive weight matrices corresponding to the recursive layer."}, {"heading": "2.1.3. Fixed-dimensional context vector", "text": "This context vector is used as the initial state vector s0 in the decoder, similar to [9] c = [hfTx] \u2032 s0 = c (2)"}, {"heading": "2.1.4. RNN Decoder", "text": "The decoder is also a unidirectional RNN.st = f (Wiyt \u2212 1 + Wst \u2212 1 + Wcc) yt = g (Uist + Uyt \u2212 1 + Ucc) (3) Wi, W and Wc denote the weight connections of past output, past hidden state and context levels. It should be noted that the past output yt \u2212 1 during the workout may originate either from the basic truth or from the prediction of the network itself. Similarly, Ui, U and Uc denote the weight connections of current hidden state, past output and context levels. In our case it is a linear plane."}, {"heading": "2.1.5. Back-propagation of error signal", "text": "The following equations describe the calculation of the error signal to update the weights of the encoder decoder structure. The calculation of the error signal for decoder is as follows: \u03b4yt = Dgt (Wi\u03b4st + 1 + U\u03b4yt + 1 + iyt) is = Ui\u03b4yt \u03b4st = Dft (W\u03b4st + 1 + is) (4) where iyt is the injected error signal that is yt \u2212 dt for our choice of g and the square error loss function, dt is the target output. Dgt, Dft are the derivatives of the functions at the output and hidden layers. The error signal for encoders is computed\u03b4hft = Dhft (Wf\u03b4hf (t + 1) + ihft) (5) The injected error signal for the encoder is not zero, but only in the final state Tx at all other times, and Dhft is the derivative of the function to hidden layer. This automatic error signal is then automatically returned to the original encoder architecture."}, {"heading": "3. Experiments and Results", "text": "We use a subset of the Blizzard challenge 2015 database available online for our experiments. The Blizzard challenge 2015 database contains about 4 hours of language data in each of the three Indian languages (Hindi, Tamil and Telugu) and about 2 hours of language data in each of the three other Indian languages (Marathi, Bengali and Malayalam), all recorded by professional native speakers in high-quality studio environments. We used the Telugu language record for our experiments. Published voice recordings were performed with a 5 ms image shift for all speech expressions along with their deltas and double deltas [30].50-dimensional Mel general receiver functions (MGC) and 26-dimensional band periodicities (BAP) were extracted with a 5 ms image shift."}, {"heading": "3.1. RAE based AbS experiments", "text": "The architecture the RAE was used was enc = {xL 500N}, dec = {500N xL}, where \"L\" stands for linear units and \"N\" stands for tanh units. However, the training process is schematically shown in the figure. 3, each unit along with its boundaries are delimited by dashed lines presented frames (frames indicated with fixed lines) to the RAE during the training. The mean squared error over the entire training scope is minimized. Once the training is completed, RBN features are obtained by presenting the units to the encoder and extracting the last hidden state. These RBN features along with the number of frames of the unit are stored as unit acoustic characteristics representation. Three different RAEs were trained with different characteristics. \u2022 MGC static characteristics alone (x = 50) \u2022 MGGC with delta characteristics."}, {"heading": "3.2. SPSS using RBN feature", "text": "In this section, experiments with RBN as acoustic features in a DNN-based SPSS system are explained. As a basic system, we take text and acoustic feature sequences at the frame level 2800000, 70000 and 70000 feature vectors for training, validation and testing. A 345L 1000R 1000R 50L system has been trained to predict acoustic parameters at the frame level (MGCs). For the proposed system, RBN characteristics are used corresponding to 200,000 units for the formation of another DNN. 2800000 feature vectors are reduced to approximately 200,000 feature vectors when mapping at the unit level, rather than at the frame level to a reduction factor of 14. The architecture of the DNN was 345L 1000R 1000R 500L. The predicted RBNs are then transferred to the decoder network of the traced RAE, as discussed in the previous section. The RAE trained with static MGC characteristics was used because it represented the best performance among the systems."}, {"heading": "4. Conclusions and Scope For Future Work", "text": "In this paper, we explored the possibility of compact representation of acoustic parametric sequences of units with a single vector using sequence-to-sequence auto-encoders. During compression, it was shown that this process of recurring auto-encoding does not affect speech quality. Intermediate RBN features were used as acoustic features at the unit level, which were then mapped from the text properties. It was shown that this representation significantly reduces the computational costs of text-to-speech mapping. A DNN-based SPSS system was built to show that the RBN features can actually be used as acoustic features within the SPSS framework. As the phoneme durations can be executed at the waveform level during synthesis, rather than at a high level, features such as the spectrum used in this work."}, {"heading": "5. Acknowledgements", "text": "The authors would like to thank TCS for the partial funding of the doctoral thesis of the first authors and the members of the language and vision laboratory for their participation in the hearing tested.1https: / / goo.gl / kJBGyg"}, {"heading": "6. References", "text": "In the USA, the number of people who are able to learn the language is even higher than in other countries. In the USA, the number of people who are able to learn the language is higher than in other countries. In the USA, the number of people who are able to learn the language is higher than in other countries. In the USA, the number of people who are able to learn the language is higher than in the USA. In the USA, the number of people who are able to learn the language is higher than in the USA."}], "references": [{"title": "Statistical parametric speech synthesis", "author": ["H. Zen", "K. Tokuda", "A.W. Black"], "venue": "Speech Communication, vol. 51, no. 11, pp. 1039 \u2013 1064, 2009.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2009}, {"title": "Speech parameter generation algorithms for HMM-based speech synthesis", "author": ["K. Tokuda", "T. Yoshimura", "T. Masuko", "T. Kobayashi", "T. Kitamura"], "venue": "Proc. ICASSP, 2000, pp. 1315\u20131318.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2000}, {"title": "Statistical parametric speech synthesis using deep neural networks", "author": ["H. Zen", "A. Senior", "M. Schuster"], "venue": "Proc. ICASSP, 2013, pp. 7962\u20137966.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2013}, {"title": "On the training aspects of Deep Neural Network (DNN) for parametric TTS synthesis", "author": ["Y. Qian", "Y. Fan", "W. Hu", "F.K. Soong"], "venue": "Proc. ICASSP, 2014, pp. 3829\u20133833.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2014}, {"title": "Unidirectional Long Short-Term Memory Recurrent Neural Network with Recurrent Output Layer for Low- Latency Speech Synthesis", "author": ["H. Zen", "H. Sak"], "venue": "Proc. ICASSP, 2015, pp. 4470\u2013 4474.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2015}, {"title": "TTS Synthesis with Bidirectional LSTM Based Recurrent Neural Networks", "author": ["Y. Fan", "Y. Qian", "F.-L. Xie", "F.K. Soong"], "venue": "Proc. INTERSPEECH, 2014, pp. 1964\u20131968.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}, {"title": "An investigation of recurrent neural network architectures for statistical parametric speech synthesis", "author": ["S. Achanta", "T. Godambe", "S.V. Gangashetty"], "venue": "Proc. INTERSPEECH, 2015, pp. 2524\u2013 2528.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2015}, {"title": "Sequence transduction with recurrent neural networks", "author": ["A. Graves"], "venue": "arXiv preprint arXiv:1211.3711, 2012.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Sequence to sequence learning with neural networks", "author": ["I. Sutskever", "O. Vinyals", "Q.V. Le"], "venue": "Advances in neural information processing systems, 2014, pp. 3104\u20133112.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning phrase representations using RNN encoder-decoder for statistical machine translation", "author": ["K. Cho", "B. Van Merri\u00ebnboer", "C. Gulcehre", "D. Bahdanau", "F. Bougares", "H. Schwenk", "Y. Bengio"], "venue": "arXiv preprint arXiv:1406.1078, 2014.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}, {"title": "Neural machine translation by jointly learning to align and translate", "author": ["D. Bahdanau", "K. Cho", "Y. Bengio"], "venue": "Proc. ICLR, 2014.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2014}, {"title": "Semi-supervised sequence learning", "author": ["A.M. Dai", "Q.V. Le"], "venue": "Advances in Neural Information Processing Systems, 2015, pp. 3061\u20133069.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2015}, {"title": "Multilingual language processing from bytes", "author": ["D. Gillick", "C. Brunk", "O. Vinyals", "A. Subramanya"], "venue": "CoRR, vol. abs/1512.00103, 2015. [Online]. Available: http://arxiv.org/abs/ 1512.00103", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2015}, {"title": "Classification and regression trees", "author": ["L. Breiman"], "venue": "Chapman & Hall/CRC,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1984}, {"title": "Random forests", "author": ["\u2014\u2014"], "venue": "Machine learning, vol. 45, no. 1, pp. 5\u201332, 2001.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2001}, {"title": "CLUSTERGEN: A statistical parametric synthesizer using trajectory modeling", "author": ["A.W. Black"], "venue": "Proc. ICSLP, 2006.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2006}, {"title": "Random forests for statistical speech synthesis", "author": ["A.W. Black", "P.K. Muthukumar"], "venue": "INTERSPEECH, 2015, pp. 1211\u20131215.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2015}, {"title": "Long short-term memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural Computation, vol. 9, no. 8, pp. 1735\u20131780, 1997.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1997}, {"title": "On the properties of neural machine translation: Encoder-decoder approaches", "author": ["K. Cho", "B. van Merri\u00ebnboer", "D. Bahdanau", "Y. Bengio"], "venue": "arXiv preprint arXiv:1409.1259, 2014.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning long-term dependencies with gradient descent is difficult", "author": ["Y. Bengio", "P. Simard", "P. Frasconi"], "venue": "IEEE Transactions on Neural Networks, vol. 5, no. 2, pp. 157\u2013166, 1994.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1994}, {"title": "LSTM: A search space odyssey", "author": ["K. Greff", "R.K. Srivastava", "J. Koutn\u0131\u0301k", "B.R. Steunebrink", "J. Schmidhuber"], "venue": "arXiv preprint arXiv:1503.04069, 2015.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2015}, {"title": "An empirical exploration of recurrent network architectures", "author": ["R. Jozefowicz", "W. Zaremba", "I. Sutskever"], "venue": "Proc. ICML, 2015, pp. 2342\u20132350.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2015}, {"title": "Investigating gated recurrent neural networks for speech synthesis", "author": ["Z. Wu", "S. King"], "venue": "arXiv preprint arXiv:1601.02539, 2016.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2016}, {"title": "Finding structure in time", "author": ["J.L. Elman"], "venue": "Cognitive Science, vol. 14, no. 2, pp. 179\u2013211, 1990.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1990}, {"title": "Advances in optimizing recurrent networks", "author": ["Y. Bengio", "N. Boulanger-Lewandowski", "R. Pascanu"], "venue": "Proc. ICASSP, 2013, pp. 8624\u20138628.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2013}, {"title": "A simple way to initialize recurrent networks of rectified linear units", "author": ["Q.V. Le", "N. Jaitly", "G.E. Hinton"], "venue": "arXiv preprint arXiv:1504.00941, 2015.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2015}, {"title": "Improving performance of recurrent neural network with ReLU nonlinearity", "author": ["S.S. Talathi", "A. Vartak"], "venue": "CoRR, vol. abs/1511.03771, 2015. [Online]. Available: http://arxiv.org/abs/ 1511.03771", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2015}, {"title": "Exact solutions to the nonlinear dynamics of learning in deep linear neural networks", "author": ["A.M. Saxe", "J.L. McClelland", "S. Ganguli"], "venue": "arXiv preprint arXiv:1312.6120, 2013.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2013}, {"title": "Rectified linear units improve restricted boltzmann machines", "author": ["V. Nair", "G.E. Hinton"], "venue": "Proc. ICML, 2010, pp. 807\u2013814.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2010}, {"title": "Automatic building of synthetic voices from audio books", "author": ["K. Prahallad"], "venue": "Ph.D. dissertation, Carnegie Mellon University, Pittsburgh, USA, 2010.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2010}, {"title": "Synthesizer voice quality of new languages calibrated with mean mel cepstral distortion", "author": ["J. Kominek", "T. Schultz", "A.W. Black"], "venue": "Spoken Languages Technologies for Under-Resourced Languages, 2008.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2008}, {"title": "Restructuring speech representations using a pitch-adaptive timefrequency smoothing and an instantaneous-frequency-based f0 extraction: Possible role of a repetitive structure in sounds", "author": ["H. Kawahara", "I. Masuda-Katsuse", "A. de Cheveign"], "venue": "Speech Communication, vol. 27, no. 34, pp. 187\u2013207, 1999.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 1999}], "referenceMentions": [{"referenceID": 0, "context": "There are three fundamental problems in statistical parametric speech synthesis (SPSS) that have been outlined [1], one of them is acoustic modeling.", "startOffset": 111, "endOffset": 114}, {"referenceID": 1, "context": "Traditionally hidden Markov models (HMM) were used for SPSS [2], however there is now growing interest in the community to use deep learning techniques for acoustic modeling in SPSS.", "startOffset": 60, "endOffset": 63}, {"referenceID": 2, "context": "It has been demonstrated in [3] [4] that deep neural networks (DNN) can perform better than traditional HMMs for SPSS.", "startOffset": 28, "endOffset": 31}, {"referenceID": 3, "context": "It has been demonstrated in [3] [4] that deep neural networks (DNN) can perform better than traditional HMMs for SPSS.", "startOffset": 32, "endOffset": 35}, {"referenceID": 4, "context": "Recently, DNNs have been replaced by recurrent neural networks (RNNs) [5] [6] [7] as they better capture the temporal dependencies.", "startOffset": 70, "endOffset": 73}, {"referenceID": 5, "context": "Recently, DNNs have been replaced by recurrent neural networks (RNNs) [5] [6] [7] as they better capture the temporal dependencies.", "startOffset": 74, "endOffset": 77}, {"referenceID": 6, "context": "Recently, DNNs have been replaced by recurrent neural networks (RNNs) [5] [6] [7] as they better capture the temporal dependencies.", "startOffset": 78, "endOffset": 81}, {"referenceID": 7, "context": "Thanks to the recent sequence-to-sequence learning techniques introduced in [8] [9] which allow us to map sequences of varying lengths.", "startOffset": 76, "endOffset": 79}, {"referenceID": 8, "context": "Thanks to the recent sequence-to-sequence learning techniques introduced in [8] [9] which allow us to map sequences of varying lengths.", "startOffset": 80, "endOffset": 83}, {"referenceID": 9, "context": "Typically this is achieved via neural network encoder-decoder architectures [10].", "startOffset": 76, "endOffset": 80}, {"referenceID": 8, "context": "We refer to this architecture as encoder-decoder with fixed vector context representation (EDFVC) throughout this paper [9] [10].", "startOffset": 120, "endOffset": 123}, {"referenceID": 9, "context": "We refer to this architecture as encoder-decoder with fixed vector context representation (EDFVC) throughout this paper [9] [10].", "startOffset": 124, "endOffset": 128}, {"referenceID": 10, "context": "The other is to soft-search the input features that align with the output using an alignment model [11].", "startOffset": 99, "endOffset": 103}, {"referenceID": 11, "context": "Auto-encoders using RNN encoder-decoder architecture have earlier been used for semi-supervised sequence learning and as pre-training in [12] [13].", "startOffset": 137, "endOffset": 141}, {"referenceID": 12, "context": "Auto-encoders using RNN encoder-decoder architecture have earlier been used for semi-supervised sequence learning and as pre-training in [12] [13].", "startOffset": 142, "endOffset": 146}, {"referenceID": 13, "context": "In our experiments DNN is used for the purpose of mapping text to unit-level acoustic features, although, in principle any other regression technique like classification and regression trees [14] or random forests [15] [16] [17] can be used.", "startOffset": 191, "endOffset": 195}, {"referenceID": 14, "context": "In our experiments DNN is used for the purpose of mapping text to unit-level acoustic features, although, in principle any other regression technique like classification and regression trees [14] or random forests [15] [16] [17] can be used.", "startOffset": 214, "endOffset": 218}, {"referenceID": 15, "context": "In our experiments DNN is used for the purpose of mapping text to unit-level acoustic features, although, in principle any other regression technique like classification and regression trees [14] or random forests [15] [16] [17] can be used.", "startOffset": 219, "endOffset": 223}, {"referenceID": 16, "context": "In our experiments DNN is used for the purpose of mapping text to unit-level acoustic features, although, in principle any other regression technique like classification and regression trees [14] or random forests [15] [16] [17] can be used.", "startOffset": 224, "endOffset": 228}, {"referenceID": 17, "context": "The second contribution of this paper is that, simple recurrent neural (SRN) units are used as basic RNN units as opposed to the typically used long-short term memory units (LSTM) [18] which have complicated gating mechanisms.", "startOffset": 180, "endOffset": 184}, {"referenceID": 8, "context": "Typically the encoder-decoder architectures use either LSTMs [9] or gated-recurrent units (GRU) [19] [11] [10] as RNN units, to avoid the vanishing gradients problem [20].", "startOffset": 61, "endOffset": 64}, {"referenceID": 18, "context": "Typically the encoder-decoder architectures use either LSTMs [9] or gated-recurrent units (GRU) [19] [11] [10] as RNN units, to avoid the vanishing gradients problem [20].", "startOffset": 96, "endOffset": 100}, {"referenceID": 10, "context": "Typically the encoder-decoder architectures use either LSTMs [9] or gated-recurrent units (GRU) [19] [11] [10] as RNN units, to avoid the vanishing gradients problem [20].", "startOffset": 101, "endOffset": 105}, {"referenceID": 9, "context": "Typically the encoder-decoder architectures use either LSTMs [9] or gated-recurrent units (GRU) [19] [11] [10] as RNN units, to avoid the vanishing gradients problem [20].", "startOffset": 106, "endOffset": 110}, {"referenceID": 19, "context": "Typically the encoder-decoder architectures use either LSTMs [9] or gated-recurrent units (GRU) [19] [11] [10] as RNN units, to avoid the vanishing gradients problem [20].", "startOffset": 166, "endOffset": 170}, {"referenceID": 20, "context": "Recently, there have been some works which have tried to address the latter drawback [21] [22], and specifically in the context of SPSS in [23].", "startOffset": 85, "endOffset": 89}, {"referenceID": 21, "context": "Recently, there have been some works which have tried to address the latter drawback [21] [22], and specifically in the context of SPSS in [23].", "startOffset": 90, "endOffset": 94}, {"referenceID": 22, "context": "Recently, there have been some works which have tried to address the latter drawback [21] [22], and specifically in the context of SPSS in [23].", "startOffset": 139, "endOffset": 143}, {"referenceID": 23, "context": "It has been shown in previous studies that Elman RNNs [24] work well if the initialization scheme used is more robust and gradient clipping is employed to avoid gradients overflow [25] [26] [27].", "startOffset": 54, "endOffset": 58}, {"referenceID": 24, "context": "It has been shown in previous studies that Elman RNNs [24] work well if the initialization scheme used is more robust and gradient clipping is employed to avoid gradients overflow [25] [26] [27].", "startOffset": 180, "endOffset": 184}, {"referenceID": 25, "context": "It has been shown in previous studies that Elman RNNs [24] work well if the initialization scheme used is more robust and gradient clipping is employed to avoid gradients overflow [25] [26] [27].", "startOffset": 185, "endOffset": 189}, {"referenceID": 26, "context": "It has been shown in previous studies that Elman RNNs [24] work well if the initialization scheme used is more robust and gradient clipping is employed to avoid gradients overflow [25] [26] [27].", "startOffset": 190, "endOffset": 194}, {"referenceID": 25, "context": "In [26], authors proposed to solve the vanishing gradient problem using diagonal initialization which was inspired by orthogonal initialization suggested in [28] and sparse initialization.", "startOffset": 3, "endOffset": 7}, {"referenceID": 27, "context": "In [26], authors proposed to solve the vanishing gradient problem using diagonal initialization which was inspired by orthogonal initialization suggested in [28] and sparse initialization.", "startOffset": 157, "endOffset": 161}, {"referenceID": 26, "context": "More recently [27] reports SRNs being able to memorize long-term dependencies by initializing recurrent weight matrix with a special structure and using rectified linear units [29].", "startOffset": 14, "endOffset": 18}, {"referenceID": 28, "context": "More recently [27] reports SRNs being able to memorize long-term dependencies by initializing recurrent weight matrix with a special structure and using rectified linear units [29].", "startOffset": 176, "endOffset": 180}, {"referenceID": 25, "context": "Also we note that authors in [26] suggest ReLU units with the identity initialization.", "startOffset": 29, "endOffset": 33}, {"referenceID": 8, "context": "This context vector is used as an initial state vector s0 in the decoder similar to [9]", "startOffset": 84, "endOffset": 87}, {"referenceID": 29, "context": "Phone-level alignments were performed using the EHMM tool [30].", "startOffset": 58, "endOffset": 62}, {"referenceID": 30, "context": "Usually MCD of less than 4dB is an indicator of high-quality synthesis [31].", "startOffset": 71, "endOffset": 75}, {"referenceID": 31, "context": "The output speech is synthesized using the predicted MGC, natural BAP and f0 using STRAIGHT vocoder [32].", "startOffset": 100, "endOffset": 104}], "year": 2016, "abstractText": "In this paper, we describe a statistical parametric speech synthesis approach with unit-level acoustic representation. In conventional deep neural network based speech synthesis, the input text features are repeated for the entire duration of phoneme for mapping text and speech parameters. This mapping is learnt at the frame-level which is the de-facto acoustic representation. However much of this computational requirement can be drastically reduced if every unit can be represented with a fixed-dimensional representation. Using recurrent neural network based auto-encoder, we show that it is indeed possible to map units of varying duration to a single vector. We then use this acoustic representation at unit-level to synthesize speech using deep neural network based statistical parametric speech synthesis technique. Results show that the proposed approach is able to synthesize at the same quality as the conventional frame based approach at a highly reduced computational cost.", "creator": "LaTeX with hyperref package"}}}