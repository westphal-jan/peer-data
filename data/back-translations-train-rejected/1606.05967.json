{"id": "1606.05967", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Jun-2016", "title": "A Nonparametric Bayesian Approach for Spoken Term detection by Example Query", "abstract": "State of the art speech recognition systems use data-intensive context-dependent phonemes as acoustic units. However, these approaches do not translate well to low resourced languages where large amounts of training data is not available. For such languages, automatic discovery of acoustic units is critical. In this paper, we demonstrate the application of nonparametric Bayesian models to acoustic unit discovery. We show that the discovered units are correlated with phonemes and therefore are linguistically meaningful. We also present a spoken term detection (STD) by example query algorithm based on these automatically learned units. We show that our proposed system produces a P@N of 61.2% and an EER of 13.95% on the TIMIT dataset. The improvement in the EER is 5% while P@N is only slightly lower than the best reported system in the literature.", "histories": [["v1", "Mon, 20 Jun 2016 04:06:23 GMT  (648kb)", "http://arxiv.org/abs/1606.05967v1", "interspeech 2016"]], "COMMENTS": "interspeech 2016", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["amir hossein harati nejad torbati", "joseph picone"], "accepted": false, "id": "1606.05967"}, "pdf": {"name": "1606.05967.pdf", "metadata": {"source": "CRF", "title": "A NONPARAMETRIC BAYESIAN APPROACH FOR SPOKEN TERM DETECTION BY EXAMPLE QUERY", "authors": ["Amir Hossein Harati", "Nejad Torbati", "Joseph Picone"], "emails": ["Amir.harati@gmail.com,", "joseph.picone@temple.edu", "P@N", "P@N"], "sections": [{"heading": null, "text": "This year, it has reached the stage where it will be able to take the lead."}], "references": [{"title": "Joint lexicon, acoustic unit inventory and model design", "author": ["M. Bacchiani", "M. Ostendorf"], "venue": "Speech Communication, vol. 29, no. 2\u20134, pp. 99\u2013114, 1999.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1999}, {"title": "An Acoustic Segment Modeling Approach to Automatic Language Identification", "author": ["B. Ma"], "venue": "Proceedings of INTERSPEECH, 2005, pp. 2829\u20132832.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2005}, {"title": "Lexicon-building methods for an acoustic sub-word based speech recognizer", "author": ["K. Paliwal"], "venue": "Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing, 1990, pp. 729\u2013 732.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1990}, {"title": "Nonparametric Bayesian Data Analysis", "author": ["P. Muller", "F.A. Quintana"], "venue": "Statistical Science, vol. 19, no. 1, pp. 95\u2013110, Feb. 2004.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2004}, {"title": "Applications of Dirichlet Process Mixtures to Speaker Adaptation", "author": ["A. Harati", "J. Picone", "M. Sobel"], "venue": "Proceedings of the International Conference on Acoustics, Speech and Signal Processing, 2012, pp. 4321\u20134324.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2012}, {"title": "A Sticky HDP-HMM with Application to Speaker Diarization", "author": ["E. Fox"], "venue": "The Annalas of Applied Statistics, vol. 5, no. 2A, pp. 1020\u20131056, 2011.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "Speech Acoustic Unit Segmentation Using Hierarchical Dirichlet Processes", "author": ["A. Harati", "J. Picone"], "venue": "Proceedings of INTERSPEECH, 2013, pp. 637\u2013641.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "A Left-to-Right HDP-HMM with HDPM Emissions", "author": ["A. Harati Nejad Torbati", "J. Picone", "M. Sobel"], "venue": "Proceedings of the CISS, 2014, pp. 1-6.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "A Doubly Hierarchical Dirichlet Process Hidden Markov Model with a Non-Ergodic Structure", "author": ["A. Harati", "J. Picone"], "venue": "IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol. 24, no. 1, pp. 174\u2013184, 2016.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2016}, {"title": "TIMIT Acoustic-Phonetic Continuous Speech Corpus", "author": ["J. Garofolo", "L. Lamel", "W. Fisher", "J. Fiscus", "D. Pallet", "N. Dahlgren", "V. Zue"], "venue": "The Linguistic Data Consortium Catalog, 1993.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1993}, {"title": "Unsupervised Learning of Acoustic Sub-word Units", "author": ["B. Varadarajan", "S. Khudanpur", "E. Dupoux"], "venue": "Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics Short Papers, 2008, pp. 165\u2013168.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2008}, {"title": "A Nonparametric Bayesian Approach to Acoustic Model Discovery", "author": ["C. Lee", "J. Glass"], "venue": "Proceedings of the Association for Computational Linguistics, 2012, pp. 40\u201349.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2012}, {"title": "Discovering Linguistic Structures in Speech: Models and Applications", "author": ["C. Lee"], "venue": "Massachusetts Institute of Technology, 2014.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2014}, {"title": "Dirichlet process", "author": ["Y.-W. Teh"], "venue": "Encyclopedia of Machine Learning, Springer, 2010, pp. 280\u2013287.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2010}, {"title": "The Infinite Gaussian Mixture Model", "author": ["C.E. Rasmussen"], "venue": "Proceedings of Advances in Neural Information Processing Systems, 2000, pp. 554\u2013560.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2000}, {"title": "A constructive definition of Dirichlet priors", "author": ["J. Sethuraman"], "venue": "Statistica Sinica, vol. 4, no. 2, pp. 639\u2013650, 1994.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1994}, {"title": "Hierarchical Dirichlet Processes", "author": ["Y. Teh", "M. Jordan", "M. Beal", "D. Blei"], "venue": "Journal of the American Statistical Association, vol. 101, no. 47, pp. 1566\u20131581, 2006.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2006}, {"title": "Unsupervised Spoken Keyword Spotting via Segmental DTW on Gaussian Posteriorgrams", "author": ["Y. Zhang", "J.R. Glass"], "venue": "Proceedings of the IEEE Workshop on Speech Recognition & Understanding, 2009, pp. 398\u2013403.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2009}, {"title": "Speech Recognition with Weighted Finite-State Transducers", "author": ["M. Mohri", "F. Pereira", "M. Riley"], "venue": "Springer Handbook on Speech Processing and Speech Communication, 2008, pp. 559\u2013 584.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2008}, {"title": "The Hierarchical Hidden Markov Model:Analysis and Applications", "author": ["S. Fine", "Y. Singer", "N. Tishby"], "venue": "Machine Learning, vol. 32, no. 1, pp. 41\u201362, 1998.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1998}, {"title": "Error Bounds for Convolutional Codes and an Asymptotically Optimum Decoding Algorithm", "author": ["A. Viterbi"], "venue": "IEEE Transactions on Information Theory, vol. 13, no. 2, pp. 260\u2013269, Apr. 1967.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1967}, {"title": "Dynamic Time Warping", "author": ["M. M\u00fcller"], "venue": "Information Retrieval for Music and Motion, Springer, 2007, pp. 69\u201382.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2007}, {"title": "Query-By-Example Spoken Term Detection Using Phonetic Posteriorgram Templates", "author": ["T.J. Hazen", "W. Shen", "C. White"], "venue": "Proceedings of the IEEE Workshop on Speech Recognition and Understanding, 2009, pp. 421\u2013426.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2009}, {"title": "Resource Configurable Spoken Query Detection using Deep Boltzmann Machines", "author": ["Y. Zhang", "R. Salakhutdinov", "H.-A. Chang", "J. Glass"], "venue": "Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing, 2012, pp. 5161\u20135164.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2012}, {"title": "Predicting Search Term Reliability for Spoken Term Detection Systems", "author": ["A. Harati", "J. Picone"], "venue": "International Journal of Speech Technology, vol. 17, no. 1, pp. 1\u20139, 2014.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "Most approaches to automatic discovery of acoustic units [1]-[3] do this in two steps: segmentation and clustering.", "startOffset": 57, "endOffset": 60}, {"referenceID": 2, "context": "Most approaches to automatic discovery of acoustic units [1]-[3] do this in two steps: segmentation and clustering.", "startOffset": 61, "endOffset": 64}, {"referenceID": 3, "context": "However in an NPB model [4][5], the model complexity can be inferred directly from the data.", "startOffset": 24, "endOffset": 27}, {"referenceID": 4, "context": "However in an NPB model [4][5], the model complexity can be inferred directly from the data.", "startOffset": 27, "endOffset": 30}, {"referenceID": 5, "context": "[6] used one state per speaker and demonstrated segmentation without knowing the number of speakers a priori.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "We have also previously reported on the use of a similar model for speech segmentation that achieves state of the art results [7].", "startOffset": 126, "endOffset": 129}, {"referenceID": 5, "context": "These models include a Hierarchical Dirichlet Process HMM (HDPHMM) [6] and a Doubly Hierarchical Dirichlet Process HMM (DHDPHMM) [8][9].", "startOffset": 67, "endOffset": 70}, {"referenceID": 7, "context": "These models include a Hierarchical Dirichlet Process HMM (HDPHMM) [6] and a Doubly Hierarchical Dirichlet Process HMM (DHDPHMM) [8][9].", "startOffset": 129, "endOffset": 132}, {"referenceID": 8, "context": "These models include a Hierarchical Dirichlet Process HMM (HDPHMM) [6] and a Doubly Hierarchical Dirichlet Process HMM (DHDPHMM) [8][9].", "startOffset": 132, "endOffset": 135}, {"referenceID": 9, "context": "These results include a comparison of ADU units with phonemes and a comparison of our STD by query algorithm to other unsupervised algorithms for the TIMIT dataset [10].", "startOffset": 164, "endOffset": 168}, {"referenceID": 6, "context": "Relationship to Previous Work: In [7] we have used an NPB model for speech segmentation that achieves state of the art performance for unsupervised algorithms.", "startOffset": 34, "endOffset": 37}, {"referenceID": 10, "context": "[11] proposed an algorithm to learn a speaker-dependent transducer that maps the acoustic observation to acoustic units.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "Lee & Glass [12][13] proposed a nonparametric Bayesian model based on Dirichlet process mixtures (DPMs) that jointly segments the data and discovers the acoustic units.", "startOffset": 12, "endOffset": 16}, {"referenceID": 12, "context": "Lee & Glass [12][13] proposed a nonparametric Bayesian model based on Dirichlet process mixtures (DPMs) that jointly segments the data and discovers the acoustic units.", "startOffset": 16, "endOffset": 20}, {"referenceID": 13, "context": "A Dirichlet process (DP) [14] is a discrete distribution that consists of a countably infinite number of probability masses.", "startOffset": 25, "endOffset": 29}, {"referenceID": 14, "context": "where \u03b1 is the concentration parameter, H is the base distribution, and k \u03b8 \u03b4 is the unit impulse function at \u03b8k, often referred to as an atom [15].", "startOffset": 143, "endOffset": 147}, {"referenceID": 15, "context": "The weights \u03b2k are sampled through a stick-breaking construction [16] and are denoted by \u03b2~GEM(\u03b1).", "startOffset": 65, "endOffset": 69}, {"referenceID": 14, "context": "One of the applications of a DP is to define a nonparametric prior distribution on the components of a mixture model that can be used to define a mixture model with an infinite number of mixture components [15].", "startOffset": 206, "endOffset": 210}, {"referenceID": 16, "context": "An HDP extends a DP to grouped data [17].", "startOffset": 36, "endOffset": 40}, {"referenceID": 16, "context": "One approach is to use a DP to define a mixture model for each group and to use a global DP, DP(\u03b3,H), as the common base distribution for all DPs [17].", "startOffset": 146, "endOffset": 150}, {"referenceID": 5, "context": "An HDPHMM [6] is an HMM with an unbounded number of states.", "startOffset": 10, "endOffset": 13}, {"referenceID": 5, "context": "The definition for HDPHMM is given by [6]:", "startOffset": 38, "endOffset": 41}, {"referenceID": 8, "context": "A DHDPHMM extends the definition of HDPHMM by allowing mixture components to be shared amongst different states [9].", "startOffset": 112, "endOffset": 115}, {"referenceID": 8, "context": "We have previously shown DHDPHMM can improve performance in problems such as acoustic modeling [9].", "startOffset": 95, "endOffset": 98}, {"referenceID": 17, "context": "This representation is called a posteriorgram [18].", "startOffset": 46, "endOffset": 50}, {"referenceID": 18, "context": "A transducer specifies a binary relationship for a pair of strings [19].", "startOffset": 67, "endOffset": 71}, {"referenceID": 18, "context": "A weighted transducer also assigns a weight for each pair of strings [19].", "startOffset": 69, "endOffset": 73}, {"referenceID": 6, "context": "In [7] we used HDPHMM for speech segmentation.", "startOffset": 3, "endOffset": 6}, {"referenceID": 8, "context": "In [9] we introduced a DHDPHMM that allows sharing mixture components across states.", "startOffset": 3, "endOffset": 6}, {"referenceID": 5, "context": "Learning HDPHMM and DHDPHMM models is extensively discussed in [6][9].", "startOffset": 63, "endOffset": 66}, {"referenceID": 8, "context": "Learning HDPHMM and DHDPHMM models is extensively discussed in [6][9].", "startOffset": 66, "endOffset": 69}, {"referenceID": 11, "context": "Unlike Lee & Glass [12][13] we don\u2019t utilize a speech/non-speech classifier and model everything including silence with one transducer.", "startOffset": 19, "endOffset": 23}, {"referenceID": 12, "context": "Unlike Lee & Glass [12][13] we don\u2019t utilize a speech/non-speech classifier and model everything including silence with one transducer.", "startOffset": 23, "endOffset": 27}, {"referenceID": 19, "context": "mixture model) with an HMM which transforms the model into a hierarchical HMM [21].", "startOffset": 78, "endOffset": 82}, {"referenceID": 20, "context": "To optimize (5) we can utilize the Viterbi algorithm [22].", "startOffset": 53, "endOffset": 57}, {"referenceID": 21, "context": "Use a subsequence dynamic time warping (DTW) algorithm [23] to obtain a score for each utterance.", "startOffset": 55, "endOffset": 59}, {"referenceID": 21, "context": "The distance between X and Y is defined as [23]: { } * ( , ) ( , )", "startOffset": 43, "endOffset": 47}, {"referenceID": 17, "context": "Since X and Y are posteriorgrams, this cost is defined as the dot product between them [18]: ( , ) log( ).", "startOffset": 87, "endOffset": 91}, {"referenceID": 9, "context": "Second we compare our STD-EQ algorithm with some other unsupervised algorithms on the TIMIT dataset [10].", "startOffset": 100, "endOffset": 104}, {"referenceID": 22, "context": "We report the average precision of the top N hits or P@N [24] which is computed as the ratio of correct hits for top N scores for a given keyword.", "startOffset": 57, "endOffset": 61}, {"referenceID": 17, "context": "The first row shows a system that utilizes a GMM to directly decode the posteriorgrams of the feature frames [18].", "startOffset": 109, "endOffset": 113}, {"referenceID": 23, "context": "The second row shows the result of an algorithm based on a Deep Boltzmann Machine (DBM) [25].", "startOffset": 88, "endOffset": 92}, {"referenceID": 12, "context": "The third row contains the results for the nonparametric Bayesian approaches described earlier [13].", "startOffset": 95, "endOffset": 99}, {"referenceID": 12, "context": "We can see for both HDPHMM and DHDPHMM, the EER is lower than other unsupervised models (5% improvement relative to the best system) while the P@N is only slightly lower than the NPM system in [13].", "startOffset": 193, "endOffset": 197}, {"referenceID": 24, "context": "It has been shown in [26] that in a standard STD system the quality of a search query can be predicated based on its spelling.", "startOffset": 21, "endOffset": 25}, {"referenceID": 17, "context": "System P@N EER GMM [18] 52.", "startOffset": 19, "endOffset": 23}, {"referenceID": 22, "context": "40% DBM [24] 51.", "startOffset": 8, "endOffset": 12}, {"referenceID": 12, "context": "70% NPM [13] 63.", "startOffset": 8, "endOffset": 12}, {"referenceID": 12, "context": "83% Semi-supervised triphone [13] 75.", "startOffset": 29, "endOffset": 33}], "year": 2016, "abstractText": "State of the art speech recognition systems use data-intensive context-dependent phonemes as acoustic units. However, these approaches do not translate well to low resourced languages where large amounts of training data is not available. For such languages, automatic discovery of acoustic units is critical. In this paper, we demonstrate the application of nonparametric Bayesian models to acoustic unit discovery. We show that the discovered units are correlated with phonemes and therefore are linguistically meaningful. We also present a spoken term detection (STD) by example query algorithm based on these automatically learned units. We show that our proposed system produces a P@N of 61.2% and an EER of 13.95% on the TIMIT dataset. The improvement in the EER is 5% while P@N is only slightly lower than the best reported system in the literature.", "creator": "Word"}}}