{"id": "1606.06061", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Jun-2016", "title": "Fast, Compact, and High Quality LSTM-RNN Based Statistical Parametric Speech Synthesizers for Mobile Devices", "abstract": "Acoustic models based on long short-term memory recurrent neural networks (LSTM-RNNs) were applied to statistical parametric speech synthesis (SPSS) and showed significant improvements in naturalness and latency over those based on hidden Markov models (HMMs). This paper describes further optimizations of LSTM-RNN-based SPSS for deployment on mobile devices; weight quantization, multi-frame inference, and robust inference using an {\\epsilon}-contaminated Gaussian loss function. Experimental results in subjective listening tests show that these optimizations can make LSTM-RNN-based SPSS comparable to HMM-based SPSS in runtime speed while maintaining naturalness. Evaluations between LSTM-RNN- based SPSS and HMM-driven unit selection speech synthesis are also presented.", "histories": [["v1", "Mon, 20 Jun 2016 10:54:51 GMT  (1198kb,D)", "https://arxiv.org/abs/1606.06061v1", "13 pages, 3 figures, Interspeech 2016 (accepted)"], ["v2", "Wed, 22 Jun 2016 15:11:30 GMT  (1199kb,D)", "http://arxiv.org/abs/1606.06061v2", "13 pages, 3 figures, Interspeech 2016 (accepted)"]], "COMMENTS": "13 pages, 3 figures, Interspeech 2016 (accepted)", "reviews": [], "SUBJECTS": "cs.SD cs.CL", "authors": ["heiga zen", "yannis agiomyrgiannakis", "niels egberts", "fergus henderson", "przemys{\\l}aw szczepaniak"], "accepted": false, "id": "1606.06061"}, "pdf": {"name": "1606.06061.pdf", "metadata": {"source": "CRF", "title": "Fast, Compact, and High Quality LSTM-RNN Based Statistical Parametric Speech Synthesizers for Mobile Devices", "authors": ["Heiga Zen", "Yannis Agiomyrgiannakis", "Niels Egberts", "Fergus Henderson", "Przemys\u0142aw Szczepaniak"], "emails": ["heigazen@google.com", "agios@google.com", "nielse@google.com", "fergus@google.com", "pszczepaniak@google.com"], "sections": [{"heading": null, "text": "Index terms: statistical parametric speech synthesis, recurrent neural networks."}, {"heading": "1 Introduction", "text": "Statistical parametric speech synthesis (SPSS) [1] based on artificial neural networks (ANN) has become popular in recent years in the field of text-to-speech (TTS) research [2-20]. ANN-based acoustic models provide an efficient and distributed representation of complex dependencies between linguistic and acoustic characteristics [21, 22] and show the potential for generating natural-sounding synthetic language [2, 4, 7-9]. Recurring neural networks (RNNNs) [23], especially long-term memory (LSTM) RNNNs [24], provide an elegant way to model linguistic sequence data that embodies short- and long-term correlations and have been successfully applied to acoustic modelling for SPSS [8-11]."}, {"heading": "2 Optimizing LSTM-RNN-based SPSS", "text": "Figure 1 shows the overview of the streaming synthesis architecture with unidirectional LSTM RNNNs [9]. Unlike HMM-based SPSS, which usually requires full batch processing [27], or frame lookahead [28], this architecture allows frame-synchronous streaming synthesis without frame prediction. Therefore, this architecture offers much lower latency for voice synthesis. However, there are still some drawbacks; \u2022 Disk Footprint; Although the total number of parameters in LSTM-RNN-based SPSS can be significantly lower than that of HMM-based SPSS [9], the total disk footprint of the LSTM-RNN system may be similar or slightly larger because HMM parameters can be quantified using 8-bit integrators [29]. Therefore, the reduction of LSTM-RNN system requirements is indispensable for use on mobile devices."}, {"heading": "2.1 Weight quantization", "text": "ANN weights are typically stored in 32-bit floating-point numbers, but there are significant advantages in terms of memory, disk space, and processing performance when represented with lower integer accuracy, usually achieved by quantizing ANN weights. This paper uses 8-bit quantization of ANN weights [30] to reduce the plate imprint of LSTM RNN-based acoustic and continuous models. Although it is possible to perform conclusions in 8-bit integers with quantization-aware training [30], this option is not used here; instead, weights are stored in 8-bit integers on the disk and recovered to 32-bit floating-point numbers after loading into memory."}, {"heading": "2.2 Multi-frame bundled inference", "text": "Inference of acoustic frames takes up 60-70% of the total calculations in our LSTM-RNN-based SPSS implementation. Therefore, it is desirable to reduce the number of calculations in the inference phase. In typical ANN-based SPSS, linguistic input characteristics other than state and frame positioning characteristics change constantly within a phoneme [2]. Furthermore, language is a rather stationary process at 5 ms image shift and acoustic frames change slowly between frames. Based on these characteristics of inputs and targets, this paper examines the multi-frame inference approach [31]. Figure 2 illustrates the concept of multi-frame inference. Instead of predicting an acoustic frame, several acoustic frames are predicted together at the same time. This architecture allows for a significant reduction of calculation targets while maintaining the scattering capability. However, preliminary experiments may show a sequence of variations between the synthesis of acoustic frames and input."}, {"heading": "2.3 Robust regression", "text": "It is known that learning a linear regression model with the quadratic loss function may suffer from the effect of outliers. Although ANNs formed with the quadratic loss function are not a simple linear regression model, their output layers perform a linear regression that contains activations on the last hidden layer. Therefore, ANNs formed with the quadratic loss function may be influenced by outliers. These outliers may originate from recordings, transcriptions, forced alignments, and F0 extraction errors. Using robust regression techniques such as linear regression with a heavy distribution [32] or a minimal density force divergence estimator [33] can mitigate the effect of outliers. In this paper, a simple robust regression technique is applied, which assumes that the error of a mixture of two Gaussian distributions, in particular Gaussian distributions, is a Gausal distributions-contrasted Gau\u00dfx."}, {"heading": "3 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Experimental conditions", "text": "The configuration for speech analysis stage and data preparation were the same as described in [9] except for the use of speech sampling at 22.05 kHz instead of 16 kHz and 7-band aperodities. The architecture of the acoustic LSTM RNs was 1 \u00d7 128 unit ReLU [39] layer followed by 3 \u00d7 128 cell LSTMP layers with 64 recursive projection units with a linear recursive output layer [9]. The duration of the LSTM RNN used a single layer of ReLLLU layers followed by three layers of LSTMP layers."}, {"heading": "3.2 Experimental results for optimizations", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.2.1 Weight quantization", "text": "Table 1 shows the result of the preference test compared to LSTM-RNNs with and without weight quantification, showing that the effect of quantization was negligible, and the plate imprint of the acoustic LSTM-RNN for English (NA) was reduced from 1.05 MByte to 272 KByte."}, {"heading": "3.2.2 Multi-frame inference", "text": "During the training of multi-frame LSTM RNNs, the learning rate had to be reduced (from 10 \u2212 5 to 2.5 \u00b7 10 \u2212 6) as mentioned in [31]. Table 2 shows the preference test result compared to single-frame and multi-frame inference. Note that the weights of the LSTM RNNNs were quantified to 8-bit integers. The table shows that LSTM RNN with multiframe inference and data augmentation achieved the same naturalness as LSTM RNNNs with only one frame. Compared to 1 frame, 4-frame achieved about 40% less wall time during runtime synthesis."}, {"heading": "3.2.3 -contaminated Gaussian loss function", "text": "Although c, and \u03a3 could be trained with the network weights, they were set to c = 10, = 0.1 and \u03a3 = I, both for acoustic and for duration LSTM RNNNs. Therefore, the number of parameters of the LSTM RNNs trained with the square and - contaminated Gaussian loss functions was identical. For the formation of LSTM RNNs with the -contaminated Gaussian loss function, the learning rate could be increased (from 2.5 \u00d7 10 \u2212 6 to 5 \u00d7 10 \u2212 6 for acoustic LSTM RNNNs, from 10 \u2212 6 to 5 \u00d7 10 \u2212 6 for duration LSTM RNNNNs). From a few preliminary experiments, the -contaminated Gaussian loss function was selected with a 2-block structure; 1) mel-cepstrum and aperiodicitys, 2) logF0 and pronounced / unspoken binary flag. This is comparable to the multistream function of the M44 [HM-structure] was used in the NSTM."}, {"heading": "3.3 Comparison with HMM-based SPSS", "text": "The next experiment compared HMM and LSTM-RNN-based SPSS with the optimizations described in this paper. Both HMM and LSTM-RNN-based acoustic and long-term models were quantified in 8-bit integers, using the same training data and word processing front-end modules. The average plate footprint of HMMs and LSTM-RNN models, which included both acoustic and long-term models across 6 languages, was 1560 and 454.5 KBytes, respectively. Table 4 shows the average latency (time to get the first block of sound) and the average total synthesis time (time to get all the audio) of HMM and LSTM-RNN-based SPSS systems (North American English) to synthesize a character, word, phrase, and paragraph based on a Nexus-6 phone."}, {"heading": "3.4 Comparison with concatenative TTS", "text": "The last experiment examined the HMM-controlled device selection TTS [46] and the LSTMRNN-based SPSS with the optimizations other than quantization described in this paper. Both TTS systems used the same training data and word processor front-end modules. Note that additional linguistic features, which were only available with the server-side word processor front-end modules, were used in both systems. HMM-controlled device selection systems were built from language at 16 kHz sampling [43]. Although LSTMRNs were trained on language at 22, 05 kHz sampling, language was synthesized at runtime using a resampling functionality in Vocaine [43]. These LSTMRNs had the same network architecture as the one described in the previous section. They were trained with the -configured Gamsian-Loss-Function 4 and were used."}, {"heading": "4 Conclusions", "text": "This work examined three optimizations of LSTM-RNN-based SPSS systems for use on mobile devices; 1) the quantification of LSTM-RNN weights on 8-bit integers reduced the hard disk imprint by 70%, with no significant difference in naturalness; 2) the use of multiframe inference reduced CPU usage by 40%, also with no significant difference in naturalness; 3) In training, the use of a contaminated Gaussian loss function instead of the asquared loss function to avoid excessive outlier effects was found to be beneficial, allowing an increased learning rate and an improvement in naturalness. LSTM-RNN-based SPSS systems with these optimizations also exceeded the HMM-based SPSS systems in terms of speed, latency, hard disk imprint, and naturalness on modern mobile devices."}, {"heading": "5 Acknowledgement", "text": "The authors thank Mr. Raziel Alvarez for helpful comments and discussions."}], "references": [{"title": "Statistical parametric speech synthesis", "author": ["H. Zen", "K. Tokuda", "A. Black"], "venue": "Speech Commn., vol. 51, no. 11, pp. 1039\u20131064, 2009.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2009}, {"title": "Statistical parametric speech synthesis using deep neural networks", "author": ["H. Zen", "A. Senior", "M. Schuster"], "venue": "Proc. ICASSP, 2013, pp. 7962\u20137966.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2013}, {"title": "Combining a vector space representation of linguistic context with a deep neural network for text-to-speech synthesis", "author": ["H. Lu", "S. King", "O. Watts"], "venue": "Proc. ISCA SSW8, 2013, pp. 281\u2013285.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2013}, {"title": "On the training aspects of deep neural network (DNN) for parametric TTS synthesis", "author": ["Y. Qian", "Y. Fan", "W. Hu", "F. Soong"], "venue": "Proc. ICASSP, 2014, pp. 3857\u2013 3861.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2014}, {"title": "Voice source modelling using deep neural networks for statistical parametric speech synthesis", "author": ["T. Raitio", "H. Lu", "J. Kane", "A. Suni", "M. Vainio", "S. King", "P. Alku"], "venue": "Proc. EUSIPCO, 2014, pp. 2290\u20132294.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2014}, {"title": "Modeling DCT parameterized F0 trajectory at intonation phrase level with DNN or decision tree", "author": ["X. Yin", "M. Lei", "Y. Qian", "F. Soong", "L. He", "Z.-H. Ling", "L.-R. Dai"], "venue": "Proc. Interspeech, 2014, pp. 2273\u20132277.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}, {"title": "Deep mixture density networks for acoustic modeling in statistical parametric speech synthesis", "author": ["H. Zen", "A. Senior"], "venue": "Proc. ICASSP, 2014, pp. 3872\u20133876.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "TTS synthesis with bidirectional LSTM based recurrent neural networks", "author": ["Y. Fan", "Y. Qian", "F. Soong"], "venue": "Proc. Interspeech, 2014, pp. 1964\u20131968.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "Unidirectional long short-term memory recurrent neural network with recurrent output layer for low-latency speech synthesis", "author": ["H. Zen", "H. Sak"], "venue": "Proc. ICASSP, 2015, pp. 4470\u20134474.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2015}, {"title": "Prosody contour prediction with long short-term memory, bi-directional, deep recurrent neural networks", "author": ["R. Fernandez", "A. Rendel", "B. Ramabhadran", "R. Hoory"], "venue": "Proc. Interspeech, 2014, pp. 2268\u2013272. 8", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}, {"title": "Investigating gated recurrent neural networks for speech synthesis", "author": ["Z. Wu", "S. King"], "venue": "Proc. ICASSP, 2016, pp. 5140\u20135144.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2016}, {"title": "Fusion of multiple parameterisations for DNN-based sinusoidal speech synthesis with multi-task learning", "author": ["Q. Hu", "Z. Wu", "K. Richmond", "J. Yamagishi", "Y. Stylianou", "R. Maia"], "venue": "Proc. Interspeech, 2015, pp. 854\u2013858.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2015}, {"title": "Minimum trajectory error training for deep neural networks, combined with stacked bottleneck features", "author": ["Z. Wu", "S. King"], "venue": "Proc. Interspeech, 2015.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep neural networks employing multi-task learning and stacked bottleneck features for speech synthesis", "author": ["Z. Wu", "C. Valentini-Botinhao", "O. Watts", "S. King"], "venue": "Proc. ICASSP, 2015, pp. 4460\u20134464.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2015}, {"title": "Sentence-level control vectors for deep neural network speech synthesis", "author": ["O. Watts", "Z. Wu", "S. King"], "venue": "Proc. Interspeech, 2015, pp. 2217\u20132221.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2015}, {"title": "Multi-speaker modeling and speaker adaptation for DNN-based TTS synthesis", "author": ["Y. Fan", "Y. Qian", "F. Soong", "L. He"], "venue": "Proc. ICASSP, 2015, pp. 4475\u2013 4479.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2015}, {"title": "Sequence error (SE) minimization training of neural network for voice conversion", "author": ["F.-L. Xie", "Y. Qian", "Y. Fan", "F. Soong", "H. Li"], "venue": "Proc. Interspeech, 2014, pp. 2283\u20132287.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2014}, {"title": "An investigation of implementation and performance analysis of DNN based speech synthesis system", "author": ["Z. Chen", "K. Yu"], "venue": "Proc. ICSP, 2014, pp. 577\u2013582.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2014}, {"title": "The effect of neural networks in statistical parametric speech synthesis", "author": ["K. Hashimoto", "K. Oura", "Y. Nankaku", "K. Tokuda"], "venue": "Proc. ICASSP, 2015, pp. 4455\u20134459.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2015}, {"title": "Modelling acoustic feature dependencies with artificial neural networks: Trajectory-RNADE", "author": ["B. Uria", "I. Murray", "S. Renals", "C. Valentini-Botinhao"], "venue": "Proc. ICASSP, 2015, pp. 4465\u20134469.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep learning in speech synthesis", "author": ["H. Zen"], "venue": "http://research.google.com/ pubs/archive/41539.pdf, Invited keynote given at ISCA SSW8 2013.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2013}, {"title": "From HMMs to DNNs: where do the improvements come from", "author": ["O. Watts", "G. Henter", "T. Merritt", "Z. Wu", "S. King"], "venue": "Proc. ICASSP, 2016, pp. 5505\u2013 5509.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2016}, {"title": "Static and dynamic error propagation networks with application to speech coding", "author": ["A. Robinson", "F. Fallside"], "venue": "Proc. NIPS, 1988, pp. 632\u2013641.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1988}, {"title": "Long short-term memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural Comput., vol. 9, no. 8, pp. 1735\u20131780, 1997.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1997}, {"title": "Simultaneous modeling of phonetic and prosodic parameters, and characteristic conversion for HMM-based text-to-speech systems, Ph.D", "author": ["T. Yoshimura"], "venue": "thesis, Nagoya Institute of Technology,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2002}, {"title": "Acoustic modeling for speech synthesis: from HMM to RNN", "author": ["H. Zen"], "venue": "http: //research.google.com/pubs/pub44630.html, Invited talk given at ASRU 2015. 9", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2015}, {"title": "Speech parameter generation algorithms for HMM-based speech synthesis", "author": ["K. Tokuda", "T. Yoshimura", "T. Masuko", "T. Kobayashi", "T. Kitamura"], "venue": "Proc. ICASSP, 2000, pp. 1315\u20131318.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2000}, {"title": "Vector quantization of speech spectral parameters using statistics of dynamic features", "author": ["K. Koishida", "K. Tokuda", "T. Masuko", "T. Kobayashi"], "venue": "Proc. ICSP, 1997, pp. 247\u2013252.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 1997}, {"title": "Quantized HMMs for low footprint text-to-speech synthesis", "author": ["A. Gutkin", "J. Gonzalvo", "S. Breuer", "P. Taylor"], "venue": "Proc. Interspeech, 2010, pp. 837\u2013840.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2010}, {"title": "On the efficient representation and execution of deep acoustic models", "author": ["R. Alvarez", "R. Prabhavalkar", "A. Bakhtin"], "venue": "Proc. Interspeech, 2016.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2016}, {"title": "Multiframe deep neural networks for acoustic modeling", "author": ["V. Vanhoucke", "M. Devin", "G. Heigold"], "venue": "Proc. ICASSP, 2013, pp. 7582\u20137585.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2013}, {"title": "Loss minimization and parameter estimation with heavy tails", "author": ["D. Hsu", "S. Sabato"], "venue": "arXiv:1307.1827, 2013.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 1827}, {"title": "Robust TTS duration modeling using DNNs", "author": ["G. Henter", "S. Ronanki", "O. Watts", "M. Wester", "Z. Wu", "S. King"], "venue": "Proc. ICASSP, 2016, pp. 5130\u20135134.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2016}, {"title": "A survey of sampling from contaminated distributions", "author": ["J. Tukey"], "venue": "Contributions to probability and statistics, vol. 2, pp. 448\u2013485, 1960.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 1960}, {"title": "Modelling of continuous speech observations", "author": ["A. Richter"], "venue": "Tech. Rep. Advances in Speech Processing Conference, IBM Europe Institute, 1986.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 1986}, {"title": "The acoustic modeling problem in automatic speech recognition, Ph.D", "author": ["P. Brown"], "venue": null, "citeRegEx": "36", "shortCiteRegEx": "36", "year": 1987}, {"title": "Tail distribution modelling using the Richter and power exponential distributions", "author": ["M. Gales", "P. Olsen"], "venue": "Proc. Eurospeech, 1999, pp. 1507\u20131510.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 1999}, {"title": "Probablistic modelling of F0 in unvoiced regions in HMM based speech synthesis", "author": ["K. Yu", "T. Toda", "M. G\u0103s\u0131\u0301c", "S. Keizer", "F. Mairesse", "B. Thomson", "S. Young"], "venue": "Proc. ICASSP, 2009, pp. 3773\u20133776.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2009}, {"title": "On rectified linear units for speech processing", "author": ["M. Zeiler", "M. Ranzato", "R. Monga", "M. Mao", "K. Yang", "Q.-V. Le", "P. Nguyen", "A. Senior", "V. Vanhoucke", "J. Dean", "G. Hinton"], "venue": "Proc. ICASSP, 2013, pp. 3517\u20133521.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2013}, {"title": "Long short-term memory recurrent neural network architectures for large scale acoustic modeling", "author": ["H. Sak", "A. Senior", "F. Beaufays"], "venue": "Proc. Interspeech, 2014, pp. 338\u2013342.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2014}, {"title": "Backpropagation through time: what it does and how to do it", "author": ["P. Werbos"], "venue": "Proc. IEEE, vol. 78, no. 10, pp. 1550\u20131560, 1990.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 1990}, {"title": "An empirical study of learning rates in deep neural networks for speech recognition", "author": ["A. Senior", "G. Heigold", "M. Ranzato", "K. Yang"], "venue": "Proc. ICASSP, 2013, pp. 6724\u20136728.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2013}, {"title": "Vocaine the vocoder and applications is speech synthesis", "author": ["Y. Agiomyrgiannakis"], "venue": "Proc. ICASSP, 2015, pp. 4230\u20134234. 10", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2015}, {"title": "The hidden Markov model toolkit (HTK) version 3.4", "author": ["S. Young", "G. Evermann", "M. Gales", "T. Hain", "D. Kershaw", "X.-Y. Liu", "G. Moore", "J. Odell", "D. Ollason", "D. Povey", "V. Valtchev", "P. Woodland"], "venue": "http://htk.eng.cam.ac.uk/, 2006.", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2006}, {"title": "NEON technology introduction", "author": ["V. Reddy"], "venue": "ARM Corporation, 2008.", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2008}], "referenceMentions": [{"referenceID": 0, "context": "Statistical parametric speech synthesis (SPSS) [1] based on artificial neural networks (ANN) has became popular in the text-to-speech (TTS) research area in the last few years [2\u201320].", "startOffset": 47, "endOffset": 50}, {"referenceID": 1, "context": "Statistical parametric speech synthesis (SPSS) [1] based on artificial neural networks (ANN) has became popular in the text-to-speech (TTS) research area in the last few years [2\u201320].", "startOffset": 176, "endOffset": 182}, {"referenceID": 2, "context": "Statistical parametric speech synthesis (SPSS) [1] based on artificial neural networks (ANN) has became popular in the text-to-speech (TTS) research area in the last few years [2\u201320].", "startOffset": 176, "endOffset": 182}, {"referenceID": 3, "context": "Statistical parametric speech synthesis (SPSS) [1] based on artificial neural networks (ANN) has became popular in the text-to-speech (TTS) research area in the last few years [2\u201320].", "startOffset": 176, "endOffset": 182}, {"referenceID": 4, "context": "Statistical parametric speech synthesis (SPSS) [1] based on artificial neural networks (ANN) has became popular in the text-to-speech (TTS) research area in the last few years [2\u201320].", "startOffset": 176, "endOffset": 182}, {"referenceID": 5, "context": "Statistical parametric speech synthesis (SPSS) [1] based on artificial neural networks (ANN) has became popular in the text-to-speech (TTS) research area in the last few years [2\u201320].", "startOffset": 176, "endOffset": 182}, {"referenceID": 6, "context": "Statistical parametric speech synthesis (SPSS) [1] based on artificial neural networks (ANN) has became popular in the text-to-speech (TTS) research area in the last few years [2\u201320].", "startOffset": 176, "endOffset": 182}, {"referenceID": 7, "context": "Statistical parametric speech synthesis (SPSS) [1] based on artificial neural networks (ANN) has became popular in the text-to-speech (TTS) research area in the last few years [2\u201320].", "startOffset": 176, "endOffset": 182}, {"referenceID": 8, "context": "Statistical parametric speech synthesis (SPSS) [1] based on artificial neural networks (ANN) has became popular in the text-to-speech (TTS) research area in the last few years [2\u201320].", "startOffset": 176, "endOffset": 182}, {"referenceID": 9, "context": "Statistical parametric speech synthesis (SPSS) [1] based on artificial neural networks (ANN) has became popular in the text-to-speech (TTS) research area in the last few years [2\u201320].", "startOffset": 176, "endOffset": 182}, {"referenceID": 10, "context": "Statistical parametric speech synthesis (SPSS) [1] based on artificial neural networks (ANN) has became popular in the text-to-speech (TTS) research area in the last few years [2\u201320].", "startOffset": 176, "endOffset": 182}, {"referenceID": 11, "context": "Statistical parametric speech synthesis (SPSS) [1] based on artificial neural networks (ANN) has became popular in the text-to-speech (TTS) research area in the last few years [2\u201320].", "startOffset": 176, "endOffset": 182}, {"referenceID": 12, "context": "Statistical parametric speech synthesis (SPSS) [1] based on artificial neural networks (ANN) has became popular in the text-to-speech (TTS) research area in the last few years [2\u201320].", "startOffset": 176, "endOffset": 182}, {"referenceID": 13, "context": "Statistical parametric speech synthesis (SPSS) [1] based on artificial neural networks (ANN) has became popular in the text-to-speech (TTS) research area in the last few years [2\u201320].", "startOffset": 176, "endOffset": 182}, {"referenceID": 14, "context": "Statistical parametric speech synthesis (SPSS) [1] based on artificial neural networks (ANN) has became popular in the text-to-speech (TTS) research area in the last few years [2\u201320].", "startOffset": 176, "endOffset": 182}, {"referenceID": 15, "context": "Statistical parametric speech synthesis (SPSS) [1] based on artificial neural networks (ANN) has became popular in the text-to-speech (TTS) research area in the last few years [2\u201320].", "startOffset": 176, "endOffset": 182}, {"referenceID": 16, "context": "Statistical parametric speech synthesis (SPSS) [1] based on artificial neural networks (ANN) has became popular in the text-to-speech (TTS) research area in the last few years [2\u201320].", "startOffset": 176, "endOffset": 182}, {"referenceID": 17, "context": "Statistical parametric speech synthesis (SPSS) [1] based on artificial neural networks (ANN) has became popular in the text-to-speech (TTS) research area in the last few years [2\u201320].", "startOffset": 176, "endOffset": 182}, {"referenceID": 18, "context": "Statistical parametric speech synthesis (SPSS) [1] based on artificial neural networks (ANN) has became popular in the text-to-speech (TTS) research area in the last few years [2\u201320].", "startOffset": 176, "endOffset": 182}, {"referenceID": 19, "context": "Statistical parametric speech synthesis (SPSS) [1] based on artificial neural networks (ANN) has became popular in the text-to-speech (TTS) research area in the last few years [2\u201320].", "startOffset": 176, "endOffset": 182}, {"referenceID": 20, "context": "ANN-based acoustic models offer an efficient and distributed representation of complex dependencies between linguistic and acoustic features [21, 22] and have shown the potential to produce natural sounding synthesized speech [2, 4, 7\u20139].", "startOffset": 141, "endOffset": 149}, {"referenceID": 21, "context": "ANN-based acoustic models offer an efficient and distributed representation of complex dependencies between linguistic and acoustic features [21, 22] and have shown the potential to produce natural sounding synthesized speech [2, 4, 7\u20139].", "startOffset": 141, "endOffset": 149}, {"referenceID": 1, "context": "ANN-based acoustic models offer an efficient and distributed representation of complex dependencies between linguistic and acoustic features [21, 22] and have shown the potential to produce natural sounding synthesized speech [2, 4, 7\u20139].", "startOffset": 226, "endOffset": 237}, {"referenceID": 3, "context": "ANN-based acoustic models offer an efficient and distributed representation of complex dependencies between linguistic and acoustic features [21, 22] and have shown the potential to produce natural sounding synthesized speech [2, 4, 7\u20139].", "startOffset": 226, "endOffset": 237}, {"referenceID": 6, "context": "ANN-based acoustic models offer an efficient and distributed representation of complex dependencies between linguistic and acoustic features [21, 22] and have shown the potential to produce natural sounding synthesized speech [2, 4, 7\u20139].", "startOffset": 226, "endOffset": 237}, {"referenceID": 7, "context": "ANN-based acoustic models offer an efficient and distributed representation of complex dependencies between linguistic and acoustic features [21, 22] and have shown the potential to produce natural sounding synthesized speech [2, 4, 7\u20139].", "startOffset": 226, "endOffset": 237}, {"referenceID": 8, "context": "ANN-based acoustic models offer an efficient and distributed representation of complex dependencies between linguistic and acoustic features [21, 22] and have shown the potential to produce natural sounding synthesized speech [2, 4, 7\u20139].", "startOffset": 226, "endOffset": 237}, {"referenceID": 22, "context": "Recurrent neural networks (RNNs) [23], especially long short-term memory (LSTM)RNNs [24], provide an elegant way to model speech-like sequential data that embodies short- and long-term correlations.", "startOffset": 33, "endOffset": 37}, {"referenceID": 23, "context": "Recurrent neural networks (RNNs) [23], especially long short-term memory (LSTM)RNNs [24], provide an elegant way to model speech-like sequential data that embodies short- and long-term correlations.", "startOffset": 84, "endOffset": 88}, {"referenceID": 7, "context": "They were successfully applied to acoustic modeling for SPSS [8\u201311].", "startOffset": 61, "endOffset": 67}, {"referenceID": 8, "context": "They were successfully applied to acoustic modeling for SPSS [8\u201311].", "startOffset": 61, "endOffset": 67}, {"referenceID": 9, "context": "They were successfully applied to acoustic modeling for SPSS [8\u201311].", "startOffset": 61, "endOffset": 67}, {"referenceID": 10, "context": "They were successfully applied to acoustic modeling for SPSS [8\u201311].", "startOffset": 61, "endOffset": 67}, {"referenceID": 8, "context": "proposed a streaming speech synthesis architecture using unidirectional LSTM-RNNs with a recurrent output layer [9].", "startOffset": 112, "endOffset": 115}, {"referenceID": 24, "context": "However, it was significantly slower than hidden Markov model (HMM)-based SPSS [25] in terms of real-time ratio [26].", "startOffset": 79, "endOffset": 83}, {"referenceID": 25, "context": "However, it was significantly slower than hidden Markov model (HMM)-based SPSS [25] in terms of real-time ratio [26].", "startOffset": 112, "endOffset": 116}, {"referenceID": 8, "context": "Figure 1: Overview of the streaming SPSS architecture using LSTM-RNN-based acoustic and duration models [9].", "startOffset": 104, "endOffset": 107}, {"referenceID": 8, "context": "Figure 1 shows the overview of the streaming synthesis architecture using unidirectional LSTM-RNNs [9].", "startOffset": 99, "endOffset": 102}, {"referenceID": 26, "context": "Unlike HMM-based SPSS, which usually requires utterancelevel batch processing [27] or frame lookahead [28], this architecture allows framesynchronous streaming synthesis with no frame lookahead.", "startOffset": 78, "endOffset": 82}, {"referenceID": 27, "context": "Unlike HMM-based SPSS, which usually requires utterancelevel batch processing [27] or frame lookahead [28], this architecture allows framesynchronous streaming synthesis with no frame lookahead.", "startOffset": 102, "endOffset": 106}, {"referenceID": 8, "context": "However, there are still a few drawbacks; \u2022 Disk footprint; Although the total number of parameters in LSTM-RNN-based SPSS can be significantly lower than that of HMM-based SPSS [9], the overall disk footprint of the LSTM-RNN system can be similar or slightly larger because HMM parameters can be quantized using 8-bit integers [29].", "startOffset": 178, "endOffset": 181}, {"referenceID": 28, "context": "However, there are still a few drawbacks; \u2022 Disk footprint; Although the total number of parameters in LSTM-RNN-based SPSS can be significantly lower than that of HMM-based SPSS [9], the overall disk footprint of the LSTM-RNN system can be similar or slightly larger because HMM parameters can be quantized using 8-bit integers [29].", "startOffset": 328, "endOffset": 332}, {"referenceID": 26, "context": "\u2022 Computation; With HMM-based SPSS, inference of acoustic parameters involves traversing decision trees at each HMM state and running the speech parameter generation algorithm [27].", "startOffset": 176, "endOffset": 180}, {"referenceID": 1, "context": "\u2022 Robustness; Typical ANN-based SPSS relies on fixed phoneme- or state-level alignments [2], whereas HMMs can be trained without fixed alignments using the Baum-Welch algorithm.", "startOffset": 88, "endOffset": 91}, {"referenceID": 29, "context": "This paper utilizes 8-bit quantization of ANN weights [30] to reduce the disk footprint of LSTM-RNN-based acoustic and duration models.", "startOffset": 54, "endOffset": 58}, {"referenceID": 29, "context": "Although it is possible to run inference in 8-bit integers with quantization-aware training [30], that possibility is not utilized here; instead weights are stored in 8-bit integer on disk then recovered to 32-bit floating-point numbers after loading to memory.", "startOffset": 92, "endOffset": 96}, {"referenceID": 1, "context": "In typical ANN-based SPSS, input linguistic features other than state- and frame-position features are constant within a phoneme [2].", "startOffset": 129, "endOffset": 132}, {"referenceID": 30, "context": "Based on these characteristics of inputs and targets this paper explores the multi-frame inference approach [31].", "startOffset": 108, "endOffset": 112}, {"referenceID": 31, "context": "Using robust regression techniques such as linear regression with a heavy-tailed distribution [32] or minimum density power divergence estimator [33] can relax the effect of outliers.", "startOffset": 94, "endOffset": 98}, {"referenceID": 32, "context": "Using robust regression techniques such as linear regression with a heavy-tailed distribution [32] or minimum density power divergence estimator [33] can relax the effect of outliers.", "startOffset": 145, "endOffset": 149}, {"referenceID": 33, "context": "In this work a simple robust regression technique assuming that the errors follow a mixture of two Gaussian distributions, in particular, -contaminated Gaussian distribution [34], which is a special case of the Richter distribution [35\u201337], is employed; the majority of observations are from a specified Gaussian distribution, though a small proportion are from a Gaussian distribution with much higher variance, while the two Gaussian distributions share the same mean.", "startOffset": 174, "endOffset": 178}, {"referenceID": 34, "context": "In this work a simple robust regression technique assuming that the errors follow a mixture of two Gaussian distributions, in particular, -contaminated Gaussian distribution [34], which is a special case of the Richter distribution [35\u201337], is employed; the majority of observations are from a specified Gaussian distribution, though a small proportion are from a Gaussian distribution with much higher variance, while the two Gaussian distributions share the same mean.", "startOffset": 232, "endOffset": 239}, {"referenceID": 35, "context": "In this work a simple robust regression technique assuming that the errors follow a mixture of two Gaussian distributions, in particular, -contaminated Gaussian distribution [34], which is a special case of the Richter distribution [35\u201337], is employed; the majority of observations are from a specified Gaussian distribution, though a small proportion are from a Gaussian distribution with much higher variance, while the two Gaussian distributions share the same mean.", "startOffset": 232, "endOffset": 239}, {"referenceID": 36, "context": "In this work a simple robust regression technique assuming that the errors follow a mixture of two Gaussian distributions, in particular, -contaminated Gaussian distribution [34], which is a special case of the Richter distribution [35\u201337], is employed; the majority of observations are from a specified Gaussian distribution, though a small proportion are from a Gaussian distribution with much higher variance, while the two Gaussian distributions share the same mean.", "startOffset": 232, "endOffset": 239}, {"referenceID": 0, "context": "Figure 4 illustrates -contaminated Gaussian distribution (\u03bc = [0], \u03a3 = [1], c = 10 and = 0.", "startOffset": 71, "endOffset": 74}, {"referenceID": 0, "context": "Figure 4: Plot of 1-dimensional -contaminated Gaussian distribution (\u03bc = [0], \u03a3 = [1], = 0.", "startOffset": 82, "endOffset": 85}, {"referenceID": 37, "context": "Note that the -contaminated Gaussian distribution is similar to globally tied distribution (GTD) in [38].", "startOffset": 100, "endOffset": 104}, {"referenceID": 8, "context": "The configuration for speech analysis stage and data preparation process were the same as those described in [9] except the use of speech at 22.", "startOffset": 109, "endOffset": 112}, {"referenceID": 38, "context": "The architecture of the acoustic LSTM-RNNs was 1 \u00d7 128-unit ReLU [39] layer followed by 3 \u00d7 128-cell LSTMP layers [40] with 64 recurrent projection units with a linear recurrent output layer [9].", "startOffset": 65, "endOffset": 69}, {"referenceID": 39, "context": "The architecture of the acoustic LSTM-RNNs was 1 \u00d7 128-unit ReLU [39] layer followed by 3 \u00d7 128-cell LSTMP layers [40] with 64 recurrent projection units with a linear recurrent output layer [9].", "startOffset": 114, "endOffset": 118}, {"referenceID": 8, "context": "The architecture of the acoustic LSTM-RNNs was 1 \u00d7 128-unit ReLU [39] layer followed by 3 \u00d7 128-cell LSTMP layers [40] with 64 recurrent projection units with a linear recurrent output layer [9].", "startOffset": 191, "endOffset": 194}, {"referenceID": 40, "context": "A distributed CPU implementation of mini-batch asynchronous stochastic gradient descent (ASGD)based truncated back propagation through time (BPTT) [41] algorithm was used [40].", "startOffset": 147, "endOffset": 151}, {"referenceID": 39, "context": "A distributed CPU implementation of mini-batch asynchronous stochastic gradient descent (ASGD)based truncated back propagation through time (BPTT) [41] algorithm was used [40].", "startOffset": 171, "endOffset": 175}, {"referenceID": 41, "context": "The learning rates were exponentially decreased over time [42].", "startOffset": 58, "endOffset": 62}, {"referenceID": 24, "context": "Spectral enhancement based on post-filtering in the cepstral domain [25] was applied to improve the naturalness of the synthesized speech.", "startOffset": 68, "endOffset": 72}, {"referenceID": 42, "context": "From the acoustic features, speech waveforms were synthesized using the Vocaine vocoder [43].", "startOffset": 88, "endOffset": 92}, {"referenceID": 30, "context": "5\u00d710\u22126) as mentioned in [31].", "startOffset": 24, "endOffset": 28}, {"referenceID": 43, "context": "This is similar to the multi-stream HMM structure [44] used in HMM-based speech synthesis [25].", "startOffset": 50, "endOffset": 54}, {"referenceID": 24, "context": "This is similar to the multi-stream HMM structure [44] used in HMM-based speech synthesis [25].", "startOffset": 90, "endOffset": 94}, {"referenceID": 44, "context": "Note that the execution binary was compiled for modern ARM CPUs having the NEON advanced single instruction, multiple data (SIMD) instruction set [45].", "startOffset": 146, "endOffset": 150}, {"referenceID": 27, "context": "To reduce the latency of the HMM-based SPSS system, the recursive version of the speech parameter generation algorithm [28] with 10-frame lookahead was used.", "startOffset": 119, "endOffset": 123}, {"referenceID": 42, "context": "05 kHz sampling, speech at 16 kHz sampling was synthesized at runtime using a resampling functionality in Vocaine [43].", "startOffset": 114, "endOffset": 118}], "year": 2016, "abstractText": "Acoustic models based on long short-term memory recurrent neural networks (LSTM-RNNs) were applied to statistical parametric speech synthesis (SPSS) and showed significant improvements in naturalness and latency over those based on hidden Markov models (HMMs). This paper describes further optimizations of LSTM-RNN-based SPSS for deployment on mobile devices; weight quantization, multi-frame inference, and robust inference using an -contaminated Gaussian loss function. Experimental results in subjective listening tests show that these optimizations can make LSTM-RNN-based SPSS comparable to HMM-based SPSS in runtime speed while maintaining naturalness. Evaluations between LSTM-RNNbased SPSS and HMM-driven unit selection speech synthesis are also presented.", "creator": "LaTeX with hyperref package"}}}