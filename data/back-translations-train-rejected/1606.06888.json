{"id": "1606.06888", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Jun-2016", "title": "Structure in the Value Function of Two-Player Zero-Sum Games of Incomplete Information", "abstract": "Zero-sum stochastic games provide a rich model for competitive decision making. However, under general forms of state uncertainty as considered in the Partially Observable Stochastic Game (POSG), such decision making problems are still not very well understood. This paper makes a contribution to the theory of zero-sum POSGs by characterizing structure in their value function. In particular, we introduce a new formulation of the value function for zs-POSGs as a function of the \"plan-time sufficient statistics\" (roughly speaking the information distribution in the POSG), which has the potential to enable generalization over such information distributions. We further delineate this generalization capability by proving a structural result on the shape of value function: it exhibits concavity and convexity with respect to appropriately chosen marginals of the statistic space. This result is a key pre-cursor for developing solution methods that may be able to exploit such structure. Finally, we show how these results allow us to reduce a zs-POSG to a \"centralized\" model with shared observations, thereby transferring results for the latter, narrower class, to games with individual (private) observations.", "histories": [["v1", "Wed, 22 Jun 2016 10:41:04 GMT  (64kb)", "http://arxiv.org/abs/1606.06888v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.GT", "authors": ["auke j wiggers", "frans a oliehoek", "diederik m roijers"], "accepted": false, "id": "1606.06888"}, "pdf": {"name": "1606.06888.pdf", "metadata": {"source": "CRF", "title": "Structure in the Value Function of Two-Player Zero-Sum Games of Incomplete Information", "authors": ["Auke J. Wiggers", "Diederik M. Roijers"], "emails": ["auke@scyfer.nl", "Frans.Oliehoek@liverpool.ac.uk", "diederik.roijers@cs.ox.ac.uk"], "sections": [{"heading": null, "text": "ar Xiv: 160 6.06 888v 1 [cs.A I] 2 2Ju n20 16"}, {"heading": "1 Introduction", "text": "Modeling decision-making for highly competitive environments with incomplete information is a field with many promising applications for AI, such as games such as poker [24] and security settings [8]. In highly competitive sequential games where the environment can be influenced by actions, the problem of rational behavior can be modelled as a zero-sum game of partially observable stochastic play (zs-POSG). Considering zs-POSG poses a challenge for strategic agents: they need to think about their own uncertainty about the state of the environment as well as uncertainty about the opposing agent. As this opponent seeks to minimize the reward they maximize, behavior typically requires strategically stochastic strategies. One factor that further complicates the argument is that agents affect not only their immediate rewards, but also the future state of the environment and the future observations of both agents. In this paper, we prove the existence of structural properties of OSs."}, {"heading": "2 Background", "text": "In this section, we provide the background necessary to explain our contributions. We move a discussion of the related work to Section 6, where we can more precisely point out the differences to our work. This essay focuses on zero-sum games of incomplete information, where the number of states, actions, observations, and horizons are finite. We examine games where the hidden state is static, and games with dynamic state (i.e. it changes over time). We assume that the actors remember their own past actions and observations, and assume that all elements of the game are generally known among the actors [19, chapter 5]."}, {"heading": "2.1 Zero-Sum One-Shot Games", "text": "We start with the description of one-shot (static) games.Definition 1. A normal form game (NFG) is a tuple N = < I, A, R >: \u2022 I = {1, 2} is the set of 2 strategies, \u2022 A = A1 \u00b7 A2 is the set of common actions a = < a1, a2 >, also referred to as (common) strategies, \u2022 R = {R1, R2} is the set of strategies (or \"payoff\") functions for the agents: Ri: A \u2192 R is the reward function for agents i, In the case of a zero sum NFG (zs-NFG) we have that R1 (a) = \u2212 R2 strategies a2 (or \"payoff\") functions for the agents i, we will define the following quantities (and related strategies): Definition 2. Definition is the maximum value (for agent of a game) Agent 1 for Agent 1 (NG) -1."}, {"heading": "2.2 Zero-Sum Bayesian Games", "text": "Definition 4. A zs-BG is defined as a tuple B = > < I, \u0432, A, R, \u03c3 >: \u2022 I = {1, 2} is the set of 2 agents, \u2022 B is the finite set of community types \u03b8 = < 2 > Strategies, Phenomena 2 >, \u2022 A = A1 \u00b7 A2 is the finite set of community actions a = < a1, a2 >, \u2022 R: 1 \u00b7 R is the reward function for Agent 1, \u2022 B is the probability distribution over community types. In this paper we deal with the finite zs-BGs, where the sets of actions and types are limited. A pure strategy to which we refer as a pure decision rule is an illustration of types of actions."}, {"heading": "2.3 Zero-sum POSGs", "text": "A zero sum is partially observable stochastic play (zs-POSG) > > Reward is a model for multi-agent decision-making under uncertainty in zero sequence games in which the state changes over time and the agents simultaneously select actions at each level.Definition 5. However, a finite zs-POSG is called a tuple P = < h, I, A, O, T, O, R, b0 >: \u2022 h is the horizon, \u2022 I = {1, 2} is the group of 2 agents, \u2022 S is the finite group of states s, \u2022 A = A1 \u00b7 A2 is the finite group of joint actions a = < a1, a2 >, \u2022 O = O1 \u00b7 Strategies of common strategies o = < o1 >, o2 >, \u2022 T is the transition function Pr (st + 1 | st, at), \u2022 O is the observation function Pr."}, {"heading": "3 Structure in One-Shot Value", "text": "In order to provide a definition of the value function for the sequential setting (in Section 4), we will rely on an intermediate result for the one-shot games developed in this section. In particular, we will introduce the concept of a family of zero-sum Bayesian games for which we will introduce the common type distribution as a suitable notion of \"state\" and prove that its value function has certain concave / convex properties in relation to this notion."}, {"heading": "3.1 Families of Bayesian Games", "text": "Here we look at the concept of a family of (zs) -BGs. Intuitively, different stages of a POSG are similar to a BG: Each agent has a privately observed history corresponding to his type, but the probabilities of these stories may depend on how the game was played in earlier stages. As such, we will have to think about families of BGs. Definition 6. Let F be a family of zero-sum Bayesian games, F = < I, \u0432, A, R >, is the set of Bayesian games of the form < I, \u0432, A, R > for which I, \u0432, A and R. By providing a common type distribution, F (\u03c3) indicates a certain zs-BG. We generalize (1) and (2) the best decision of (QltF) and (BRltF) as the following value: QltF (B), QltF (B), ltF (ltZ), ltZ (lt; VZ), VZ (& T), VZ ()."}, {"heading": "3.2 Concavity/Convexity of the Value Function", "text": "We saw in the previous section that the concave / convex form of the utility function expressed in the space of decision rules follows di-rectly from known results. Here, we provide a novel result: V * F has a similar concave / convex form in terms of type distributions. This is particularly important because it provides insights into how the distribution of information (in addition to the distribution of actions) affects the value of the game, which is crucial for generalizing the value in different parts of successive games. To provide this formulation, we break this element down into a marginal term, i and a conditional term."}, {"heading": "4 Structure in zs-POSG Value", "text": "Given the outcome of the one-shot games described in the previous section, we are now able to present our most important contributions: novel formulations for the value function and a generalization of the structural result of theorem 1 to the sequential setting. First, we will present a description of the rational value function based on previous common strategies."}, {"heading": "4.1 Past Joint Policies", "text": "In order to make rational decisions in phase t in the zs-POSG, it is sufficient to know the past decisions recorded in the past common policy. (To show this, the zs-POSG value function must be defined in relation to the past common policy.) The definition that follows the value achieved when all actors follow the common policy assumes that in future stages agents will act rationally, which is that the agents will follow a rational common future policy. (This means that the agents will follow a rational common future policy.) We first define the Q value function in the final phase t = h \u2212 1, and give an inductive definition of the Q value function in the preceding stages. We then define the value function in each phase."}, {"heading": "4.2 Plan-Time Sufficient Statistics", "text": "A disadvantage of the definition of the value function from the previous section is that the value in a phase t depends on all common decisions of levels 0 to t. We propose to define the value function in terms of a planned sufficient statistic that summarizes many past common policies. Furthermore, we provide formal proof that this value function has a concave / convex form in statistical space that may be exploitable.Definition 7. The plan-time sufficient statistic for a general past common policy t, assuming that b0 is known, is a distribution over common AOHs: \u03c3t (~ 1), Pr (~ 2 points) that cannot be exploited. In the collaborative Dec-POMDP statistic, the influence of the past common policy is fully recorded. We prove that this also applies to the zs-POSG case, validating the previous definition and the name \"sufficient statistics.\""}, {"heading": "4.3 Equivalence Final Stage Zero-Sum POSG and Family of Zero-Sum Bayesian Games", "text": "We have already demonstrated that the value function of a family of zeros has Bayesian Games concavity and convexity with respect to the marginal parts of the type distribution \u03c3 for the respective agent 1 and 2. We show that the output stage of the zs-POSG P, t = h \u2212 1, can be defined as a family of zs-BGs: \u2022 I = {1, 2} is the group of agents, \u2022 N = ~ h \u2212 1 is the group of joint types corresponding to the AOH incs-POSG P at stage h \u2212 1, \u2022 A is the group of joint actions in the zs-POSG P, \u2022 R (~ \u03b8h \u2212 1, a) is directly derived from the direct reward function of P (as described in Section 4.1). By the result of theorem 1 (i.e., V-F concavity and convexity within the limit of agent 1 and 2 \u2212 h is not equal to the value of the function of zs-POSG)."}, {"heading": "4.4 Concavity/Convexity of the Value Function", "text": "We continue to show that the value function has the same kind of structure for each level. Specifically, the plan-time statistics can be broken down into marginal and conditions (1), and the value function is concave into marginal space for Agent 1 (2), and convex into marginal space for Agent 2 (2). Figure 1 provides intuition about how the best response value is related to the concave / convex value function: a \"slice\" in statistical space corresponds to a single conditional space for Agent 2, 1 (2), and shows concave (convex) form of the value function, each corresponding to a partial policy of the other Agent. As we will show, each segment corresponds exactly to a conditional space for function.The best response functions in terms of ZIP and ZIP are defined as V BR1t and BR2."}, {"heading": "5 Reduction to NOSG", "text": "The application of methods that exploit the PWLC structure of the value function of Dec-POMDPs is enabled by a reduction of Dec-POMDPs. < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < <"}, {"heading": "6 Related Work", "text": "In fact, most of them are able to determine for themselves what they want to do, and they are able to determine for themselves what they want to do."}, {"heading": "7 Conclusions and Future Work", "text": "This paper presents a structural result on the form of the value function of zero-sum games with incomplete information for games with static and dynamic states, which are typically modelled as Bayesian game (BG) or partially observable stochastic game (POSG). We formally defined the value function for both types of games in the sense of an information distribution known as a sufficient plan-time statistic: a probability distribution via common sets of private information (originally used in the collaborative environment [15]). Starting from the fact that this probability distribution can be broken down into a marginal and a conditional term, we presented that in the zero-sum fall value functions of both types of games convectivity (convexity) is used in the space of marginal statistics of the maximizing (minimizing) agent for each conditional statistic (in the multi-level game), this structure of value function is used as an exploitation factor for each phase."}, {"heading": "A Appendix", "text": "11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 9, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,"}], "references": [{"title": "Optima and equilibria: an introduction to nonlinear analysis, volume 140", "author": ["Jean-Pierre Aubin"], "venue": "Springer Science & Business Media,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1998}, {"title": "Optimally solving Dec-POMDPs as continuous-state MDPs", "author": ["Jilles S. Dibangoye", "Christopher Amato", "Olivier Buffet", "Fran\u00e7ois Charpillet"], "venue": "Proceedings of the International Joint Conference on Artificial Intelligence,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2013}, {"title": "Approximate solutions for partially observable stochastic games with common payoffs", "author": ["R. Emery-Montemerlo", "G. Gordon", "J. Schneider", "S. Thrun"], "venue": "Proceedings of International Joint Conference on Autonomous Agents and Multi Agent Systems,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2004}, {"title": "Zero-sum stochastic games with partial information", "author": ["MK Ghosh", "D McDonald", "S Sinha"], "venue": "Journal of Optimization Theory and Applications,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2004}, {"title": "Interactive POMDPs: Properties and preliminary results", "author": ["Piotr J Gmytrasiewicz", "Prashant Doshi"], "venue": "Proceedings of the Third International Joint Conference on Autonomous Agents and Multiagent Systems-Volume", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2004}, {"title": "Dynamic Programming for Partially Observable Stochastic Games", "author": ["Eric A Hansen", "Daniel S. Bernstein", "Shlomo Zilberstein"], "venue": "Proceedings of the National Conference on Artificial Intelligence,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2004}, {"title": "A double oracle algorithm for zero-sum security games on graphs", "author": ["Manish Jain", "Dmytro Korzhyk", "Ond\u0159ej Van\u011bk", "Vincent Conitzer", "Michal P\u011bchou\u010dek", "Milind Tambe"], "venue": "Proceedings of the International Joint Conference on Autonomous Agents and Multi Agent Systems,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2011}, {"title": "Fast algorithms for finding randomized strategies in game trees", "author": ["Daphne Koller", "Nimrod Megiddo", "Bernhard Von Stengel"], "venue": "Proceedings of the twenty-sixth annual ACM symposium on Theory of computing,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1994}, {"title": "Point based value iteration with optimal belief compression for Dec-POMDPs", "author": ["Liam C. MacDermed", "Charles Isbell"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2013}, {"title": "The value of two-person zero-sum repeated games with lack of information on both sides", "author": ["Jean-Francois Mertens", "Shmuel Zamir"], "venue": "International Journal of Game Theory,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1971}, {"title": "Taming Decentralized POMDPs: Towards efficient policy computation for multiagent settings", "author": ["Ranjit Nair", "Milind Tambe", "Makoto Yokoo", "David Pynadath", "Stacy Marsella"], "venue": "Proceedings of the International Joint Conference on Artificial Intelligence,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2003}, {"title": "Common information based Markov perfect equilibria for Stochastic Games with asymmetric information: Finite Games", "author": ["Ashutosh Nayyar", "Abhishek Gupta", "Cedric Langbort", "Tamer Basar"], "venue": "Automatic Control, IEEE Transactions on,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Decentralized stochastic control with partial history sharing: A common information approach", "author": ["Ashutosh Nayyar", "Aditya Mahajan", "Demosthenis Teneketzis"], "venue": "IEEE Transactions on Automatic Control,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2013}, {"title": "Sufficient Plan-Time Statistics for Decentralized POMDPs", "author": ["Frans A. Oliehoek"], "venue": "Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2013}, {"title": "Dec-POMDPs as nonobservable MDPs\u2019, IAS technical report IAS-UVA-14-01, Intelligent Systems", "author": ["Frans A. Oliehoek", "Christopher Amato"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2014}, {"title": "A Vlassis, \u2018Optimal and approximate q-value functions for Decentralized POMDPs.", "author": ["Frans A Oliehoek", "Matthijs TJ Spaan", "Nikos"], "venue": "Journal of AI Research,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2008}, {"title": "Dec-POMDPs and extensive form games: equivalence of models and algorithms", "author": ["Frans A. Oliehoek", "Nikos Vlassis"], "venue": "Ias technical report IAS-UVA-06-02,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2006}, {"title": "Anytime point-based approximations for large POMDPs.", "author": ["Joelle Pineau", "Geoffrey J Gordon", "Sebastian Thrun"], "venue": "Journal of AI Research,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2006}, {"title": "Zero-sum games with \u201dalmost\u201d perfect information", "author": ["Jean-Pierre Ponssard"], "venue": "Management Science,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1975}, {"title": "Some results on zero-sum  games with incomplete information: The dependent case", "author": ["Jean-Pierre Ponssard", "Sylvain Sorin"], "venue": "International Journal of Game Theory,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1980}, {"title": "Zero-sum sequential games with incomplete information", "author": ["Jean-Pierre Ponssard", "Shmuel Zamir"], "venue": "International Journal of Game Theory,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1973}, {"title": "Computer poker: A review", "author": ["Jonathan Rubin", "Ian Watson"], "venue": "Artificial Intelligence,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2011}, {"title": "Multiagent systems: Algorithmic, game-theoretic, and logical foundations", "author": ["Yoav Shoham", "Kevin Leyton-Brown"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2008}, {"title": "Stochastic Games with incomplete information", "author": ["Sylvain Sorin"], "venue": "Stochastic Games and applications, eds., Abraham Neyman and Sylvain Sorin,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2003}, {"title": "Perseus: Randomized pointbased value iteration for POMDPs.", "author": ["Matthijs T.J. Spaan", "Nikos Vlassis"], "venue": "Journal of AI Research,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2005}, {"title": "A theory of sufficient statistics for teams", "author": ["Jeffrey Wu", "Sanjay Lall"], "venue": "Proc. of the 53rd Annual Conference on Decision and Control,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2014}], "referenceMentions": [{"referenceID": 21, "context": "Examples include games such as poker [24] and security settings [8].", "startOffset": 37, "endOffset": 41}, {"referenceID": 6, "context": "Examples include games such as poker [24] and security settings [8].", "startOffset": 64, "endOffset": 67}, {"referenceID": 13, "context": "We take inspiration from recent work for collaborative settings which has shown that it is possible to summarize the past joint policy using so called plan-time sufficient statistics [15], which", "startOffset": 183, "endOffset": 187}, {"referenceID": 1, "context": "uk can be interpreted as the belief of a special type of Partially Observable Markov Decision Process (POMDP) to which the collaborative Decentralized POMDP can be reduced [3, 10, 14].", "startOffset": 172, "endOffset": 183}, {"referenceID": 8, "context": "uk can be interpreted as the belief of a special type of Partially Observable Markov Decision Process (POMDP) to which the collaborative Decentralized POMDP can be reduced [3, 10, 14].", "startOffset": 172, "endOffset": 183}, {"referenceID": 12, "context": "uk can be interpreted as the belief of a special type of Partially Observable Markov Decision Process (POMDP) to which the collaborative Decentralized POMDP can be reduced [3, 10, 14].", "startOffset": 172, "endOffset": 183}, {"referenceID": 1, "context": "This enabled tackling these problems using solution methods for POMDPs, leading to increases in scalability [3].", "startOffset": 108, "endOffset": 111}, {"referenceID": 22, "context": ", via linear programming [25]) can be used to solve zs-BGs.", "startOffset": 25, "endOffset": 29}, {"referenceID": 7, "context": "However, such an approach does not scale well \u2014 a more efficient solution method is to convert the zs-BG to sequence form [9].", "startOffset": 122, "endOffset": 125}, {"referenceID": 7, "context": "An alternative is to converting the zs-POSG to an extensive form game (EFG) and solve it in sequence form [9].", "startOffset": 106, "endOffset": 109}, {"referenceID": 16, "context": "While this is more efficient than the NFG route, it is still intractable: the resulting EFG is huge since its size depends on the number of full histories (trajectories of joint actions, joint observations, and states) [18].", "startOffset": 219, "endOffset": 223}, {"referenceID": 13, "context": "To show this, the zs-POSG value function in terms of the past joint policy \u03c6 can be defined in terms of \u03c6 by extending the formulation by Oliehoek [15].", "startOffset": 147, "endOffset": 151}, {"referenceID": 2, "context": "Note that, even though the final stage is equal to a Family of Bayesian Games, our approach is substantially different from approaches that represent a POSG as a series of BGs [4] and derivative works [17].", "startOffset": 176, "endOffset": 179}, {"referenceID": 15, "context": "Note that, even though the final stage is equal to a Family of Bayesian Games, our approach is substantially different from approaches that represent a POSG as a series of BGs [4] and derivative works [17].", "startOffset": 201, "endOffset": 205}, {"referenceID": 17, "context": "To draw the parallel, many POMDP solution methods exploit the fact that a POMDP value function is piecewise-linear and convex (PWLC) in belief-space [20, 27] (which is similar to the statistic-space we consider), and recently", "startOffset": 149, "endOffset": 157}, {"referenceID": 24, "context": "To draw the parallel, many POMDP solution methods exploit the fact that a POMDP value function is piecewise-linear and convex (PWLC) in belief-space [20, 27] (which is similar to the statistic-space we consider), and recently", "startOffset": 149, "endOffset": 157}, {"referenceID": 1, "context": ", Dec-POMDP) case [3, 10].", "startOffset": 18, "endOffset": 25}, {"referenceID": 8, "context": ", Dec-POMDP) case [3, 10].", "startOffset": 18, "endOffset": 25}, {"referenceID": 1, "context": "5 Reduction to NOSG The application of methods that exploit the PWLC structure of the value function of Dec-POMDPs was enabled by a reduction from Dec-POMDP to a non-observable MDP (NOMDP), which is a special type of (centralized) POMDP [3, 10, 14, 16].", "startOffset": 237, "endOffset": 252}, {"referenceID": 8, "context": "5 Reduction to NOSG The application of methods that exploit the PWLC structure of the value function of Dec-POMDPs was enabled by a reduction from Dec-POMDP to a non-observable MDP (NOMDP), which is a special type of (centralized) POMDP [3, 10, 14, 16].", "startOffset": 237, "endOffset": 252}, {"referenceID": 12, "context": "5 Reduction to NOSG The application of methods that exploit the PWLC structure of the value function of Dec-POMDPs was enabled by a reduction from Dec-POMDP to a non-observable MDP (NOMDP), which is a special type of (centralized) POMDP [3, 10, 14, 16].", "startOffset": 237, "endOffset": 252}, {"referenceID": 14, "context": "5 Reduction to NOSG The application of methods that exploit the PWLC structure of the value function of Dec-POMDPs was enabled by a reduction from Dec-POMDP to a non-observable MDP (NOMDP), which is a special type of (centralized) POMDP [3, 10, 14, 16].", "startOffset": 237, "endOffset": 252}, {"referenceID": 13, "context": "The proposed plan-time statistics for Dec-POMDPs [15] precisely correspond to the belief in the centralized model.", "startOffset": 49, "endOffset": 53}, {"referenceID": 14, "context": "We do not provide the full background of the reduction for the Dec-POMDP case, but refer to [16].", "startOffset": 92, "endOffset": 96}, {"referenceID": 10, "context": "In order to avoid potential confusion, let us point out that a zsPOSG can also be converted to a best response POMDP by fixing the policies of one agent [12], which leads to a model where the information state b(s, \u03b8j) is a distribution over states and AOHs of the other agent.", "startOffset": 153, "endOffset": 157}, {"referenceID": 10, "context": "[12] leads to a single-agent model that can be used to compute a best-response, our conversion leads to a multi-agent model that can be used to compute a Nash equilibrium directly.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "A key contribution of our NOSG formulation is that it directly indicates that properties of \u2018zero-sum stochastic games with shared observations\u2019 [5] also hold for zs-POSGs.", "startOffset": 145, "endOffset": 148}, {"referenceID": 3, "context": "[5] show that, under some technical assumptions, a zsSOSG can be converted into a completely observable model (similar to the conversion of a POMDP into a belief MDP), and that, in the infinite-horizon case, both the value and a rational joint policy exists.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "However, a straightforward extension of our reduction for the case where the agents use finite-state controllers (analogous to such formulations for Dec-POMDPs [10]), would satisfy these requirements, and as such we can infer the existence of a value for such games: Corollary 1.", "startOffset": 160, "endOffset": 164}, {"referenceID": 0, "context": "The concave and convex structure we have found for the zs-POSG value function is similar to the saddle point structure associated with min-max equilibria [1].", "startOffset": 154, "endOffset": 157}, {"referenceID": 11, "context": "[13] who introduce a so-called Common Information Based Conditional Belief \u2014 a probability distribution over AOHs and the state conditioned on common information \u2014 and use it to design a dynamic-programming approach for zs-POSGs.", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "[7] present a dynamic-programming approach for finite-horizon (general sum) POSGs that iteratively constructs sets of one-step-longer (pure) policies for all agents.", "startOffset": 0, "endOffset": 3}, {"referenceID": 25, "context": "A more generalized investigation of individual statistics in decentralized settings is given by Wu & Lall [28].", "startOffset": 106, "endOffset": 110}, {"referenceID": 9, "context": "There are works from game theory literature that present structural results on the value function of so-called \u2018repeated zero-sum games with incomplete information\u2019 [11, 21, 22, 23].", "startOffset": 165, "endOffset": 181}, {"referenceID": 18, "context": "There are works from game theory literature that present structural results on the value function of so-called \u2018repeated zero-sum games with incomplete information\u2019 [11, 21, 22, 23].", "startOffset": 165, "endOffset": 181}, {"referenceID": 19, "context": "There are works from game theory literature that present structural results on the value function of so-called \u2018repeated zero-sum games with incomplete information\u2019 [11, 21, 22, 23].", "startOffset": 165, "endOffset": 181}, {"referenceID": 20, "context": "There are works from game theory literature that present structural results on the value function of so-called \u2018repeated zero-sum games with incomplete information\u2019 [11, 21, 22, 23].", "startOffset": 165, "endOffset": 181}, {"referenceID": 20, "context": "For various flavors of such games, it has been shown that the value function has a concave/convex structure: cases with incomplete information on one side [23, 26], and cases with incomplete information on both sides where \u2018observations are independent\u2019 (i.", "startOffset": 155, "endOffset": 163}, {"referenceID": 23, "context": "For various flavors of such games, it has been shown that the value function has a concave/convex structure: cases with incomplete information on one side [23, 26], and cases with incomplete information on both sides where \u2018observations are independent\u2019 (i.", "startOffset": 155, "endOffset": 163}, {"referenceID": 18, "context": ", where the distribution over joint types is a product of individual type distributions) [21] or dependent (general joint type distributions) [11, 22].", "startOffset": 89, "endOffset": 93}, {"referenceID": 9, "context": ", where the distribution over joint types is a product of individual type distributions) [21] or dependent (general joint type distributions) [11, 22].", "startOffset": 142, "endOffset": 150}, {"referenceID": 19, "context": ", where the distribution over joint types is a product of individual type distributions) [21] or dependent (general joint type distributions) [11, 22].", "startOffset": 142, "endOffset": 150}, {"referenceID": 4, "context": "A game-theoretic model that is closely related to the POSG model is the Interactive POMDP or I-POMDP [6].", "startOffset": 101, "endOffset": 104}, {"referenceID": 10, "context": "[12] (discussed in Section 5), with the difference that the state also represents which policy the other agent uses.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "We formally defined the value function for both types of games in terms of an information distribution called the sufficient plan-time statistic: a probability distribution over joint sets of private information (originally used in the collaborative setting [15]).", "startOffset": 258, "endOffset": 262}, {"referenceID": 8, "context": "We hope that this result leads to solution methods that exploit the structure of the value function at every stage, as recently such developments have been made in the field of cooperative multi-agent problems [10].", "startOffset": 210, "endOffset": 214}, {"referenceID": 8, "context": "In particular, we believe that heuristic methods that identify useful (conditional) statistics to explore, or point-based methods that iteratively select statistics to evaluate [10, 27] may be adapted for the zs-POSG case.", "startOffset": 177, "endOffset": 185}, {"referenceID": 24, "context": "In particular, we believe that heuristic methods that identify useful (conditional) statistics to explore, or point-based methods that iteratively select statistics to evaluate [10, 27] may be adapted for the zs-POSG case.", "startOffset": 177, "endOffset": 185}, {"referenceID": 13, "context": "The proof is largely identical to the proof of correctness of sufficient statistics in the collaborative setting [15].", "startOffset": 113, "endOffset": 117}], "year": 2016, "abstractText": "Zero-sum stochastic games provide a rich model for competitive decision making. However, under general forms of state uncertainty as considered in the Partially Observable Stochastic Game (POSG), such decision making problems are still not very well understood. This paper makes a contribution to the theory of zero-sum POSGs by characterizing structure in their value function. In particular, we introduce a new formulation of the value function for zs-POSGs as a function of the \u2018plan-time sufficient statistics\u2019 (roughly speaking the information distribution in the POSG), which has the potential to enable generalization over such information distributions. We further delineate this generalization capability by proving a structural result on the shape of value function: it exhibits concavity and convexity with respect to appropriately chosen marginals of the statistic space. This result is a key pre-cursor for developing solution methods that may be able to exploit such structure. Finally, we show how these results allow us to reduce a zs-POSG to a \u2018centralized\u2019 model with shared observations, thereby transferring results for the latter, narrower class, to games with individual (private) observations.", "creator": "LaTeX with hyperref package"}}}