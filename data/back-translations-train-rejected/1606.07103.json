{"id": "1606.07103", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Jun-2016", "title": "Deep Feature Fusion Network for Answer Quality Prediction in Community Question Answering", "abstract": "Community Question Answering (cQA) forums have become a popular medium for soliciting direct answers to specific questions of users from experts or other experienced users on a given topic. However, for a given question, users sometimes have to sift through a large number of low-quality or irrelevant answers to find out the answer which satisfies their information need. To alleviate this, the problem of Answer Quality Prediction (AQP) aims to predict the quality of an answer posted in response to a forum question. Current AQP systems either learn models using - a) various hand-crafted features (HCF) or b) use deep learning (DL) techniques which automatically learn the required feature representations.", "histories": [["v1", "Wed, 22 Jun 2016 20:58:08 GMT  (425kb,D)", "https://arxiv.org/abs/1606.07103v1", null], ["v2", "Sun, 26 Jun 2016 05:54:51 GMT  (305kb,D)", "http://arxiv.org/abs/1606.07103v2", "Neu-IR '16 SIGIR Workshop on Neural Information Retrieval, July 21, 2016, Pisa, Italy"]], "reviews": [], "SUBJECTS": "cs.IR cs.CL", "authors": ["sai praneeth suggu", "kushwanth n goutham", "manoj k chinnakotla", "manish shrivastava"], "accepted": false, "id": "1606.07103"}, "pdf": {"name": "1606.07103.pdf", "metadata": {"source": "CRF", "title": "Deep Feature Fusion Network for Answer Quality Prediction in Community Question Answering", "authors": ["Sai Praneeth Suggu", "Kushwanth N. Goutham", "Manoj K. Chinnakotla", "Manish Shrivastava"], "emails": ["suggusai.praneeth@research.iiit.ac.in", "kushwanth.naga@research.iiit.ac.in", "m.shrivastava@iiit.ac.in", "manojc@microsoft.com"], "sections": [{"heading": null, "text": "In this paper, we propose a novel approach to AQP, known as the \"Deep Feature Fusion Network (DFFN),\" which takes advantage of both handcrafted features and deep learning-based systems. Faced with a question-and-answer pair along with its metadata, DFFN learns independently - a) deep features using a Convolutional Neural Network (CNN) and b) calculates custom features using various external resources and then combines them with a deep neural network trained to predict the final response quality. DFFN reaches the performance of the standard SemEval-2015 and SemEval-2016 models and surpasses the baseline approaches that individually use either HCF or DL-based techniques. Keywords Community Question Answering, Answer Quality Prediction, Answer Selection, Deep Learning, Convolutional Neural Networks, Feature CoperingPermission to make digital or hard copies of these works available or for use by anyone for commercial or commercial copying purposes."}, {"heading": "21, 2016, Pisa, Italy.", "text": "c \u00a9 2016 Copyright of the owner / author."}, {"heading": "1. INTRODUCTION", "text": "The answer to this question is: \"I don't think people who are able, able, able to understand things and understand what they are doing\" The answer to this question is: \"No, I don't think so.\" The answer is: \"No, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no,"}, {"heading": "2. RELATED WORK", "text": "AQP in cQA forums has been extensively researched in the IR community. Jeon et al. [9] use non-textual features such as clicks, number of prints, number of copies, etc. to predict the quality of an answer in a cQA forum. Liu et al. [12] investigate a slightly related problem, namely predicting whether a questioner would be satisfied with the answers previously given to the given question. Burel et al. [1] have used a combination of content, user and thread-related features to predict the quality of the answer. Dalip et al. [2] propose an approach to evaluate AQP based on eight different sets of characteristics. Li et al. [11] examined the various factors such as shorter length, the author's reputation leading to a high response quality, which is evaluated by users. More recently, Tran et al. [22] they used theme models, word classifiers, and other handwritten rules for the classification of QA in QA forums, and a set of rules for a QS."}, {"heading": "3. DEEP FEATURE FUSION NETWORK (DFFN)", "text": "Figure 1 shows the architecture of our DFFN model. The input to the DFFN is the question, answer and metadata (question category, questioner, answer author, etc.) and the output is a relevance score that represents the quality of the answer. DFFN is a two-step deep neural network (NN) model. In the first stage, DFFN has two parallel CNN-based sentence models for the question and answer that are used to learn their feature representations (call it CNNFR). In parallel, DFFN also generates handmade feature representations from the questions, answer and metadata information using Wikipedia and other similarity models (call it HCFR). In the second stage, CNNFR and HCFR are merged with metadata (questioner, answer author and question category) and forwarded through a deeper neural network (NN) that predicts each of the DFN's answers in detail."}, {"heading": "3.1 Sentence Model", "text": "The sentence model projects a sentence (question / answer) into semantic space and learns a good intermediate representation of the given question / answer. The sentence model is a deep revolutionary neural network (CNN). Our CNN consists mainly of sentence matrix and multiple convolutionary, bundling and non-linear layers as shown in Figure 1. Input into the sentence matrix S is a vector of words from the sentence (question / answer) s = {w1, w2,.... w | s |}. We build the sentence matrix by mapping each word wi in the question / answer to its corresponding word embedding in d dimensions. We use GLoVE [17] based embedding of 300 dimensions to map the words in the question and answer. We limit the sentence size to a certain threshold. We ignore the words in the sentence after a certain threshold if the length of the sentence is greater than the threshold and fill zeros to the threshold of the sentence if the length is smaller than the sentence."}, {"heading": "3.2 Hand Crafted Features (HCF)", "text": "In fact, most of them will be able to move to another world, in which they will be able to move, and in which they will be able to move to another world, in which they will be able to integrate."}, {"heading": "3.3 Metadata", "text": "We observe that the category of the question plays an important role in calculating the value of the answer quality, as it is easy for some categories to write good answers and difficult for others. We also include the author information of the question and answer. We encode the question category, the questioner and the answer author using a logarithmic function and enter it as an input in the second level NN."}, {"heading": "3.4 Second Stage Neural Network", "text": "As discussed, the vector representations from the set models (540 dimensions), the feature representations from HCF (28 dimensions) and the direct inputs from metadata (33 dimensions) are combined into a single feature vector with 601 dimensions. This vector is given as input to the second level NN, which consists of fully connected layers. These layers model different interactions between the features present in the vector and finally output a score that predicts the response quality."}, {"heading": "3.5 Training", "text": "The parameters of the network are learned with the aim of maximizing the accuracy of the prediction against the target categories. In SemEval-2015, for example, the target categories in SemEval-2016 were \"good, potentially useful, bad\" and \"good, bad.\" For the training, we used the training data of the SemEval tasks 2015 [14] and 2016 [15], which consist of question, answer, metadata and their ideal quality assessment. We aligned the DFFN parameters with the cor-responding development kits of SemEval 2015 and 2016. We used Adagrad [3] to accelerate the convergence rate of stochastic gradient reduction (SGD). Given an input (p, t) where p is the predicted value of the response quality by DFFN, and t is the true label describing the response quality, we used SmoothL1 as a loss criterion that is calculated as a loss (p)."}, {"heading": "4. EXPERIMENTAL SETUP", "text": "SemEval 2016 consists of 36198 training question and answer pairs (QA) and 2440 for developers and 3270 for testing purposes. SemEval 2015 consists of 16541 training quality pairs and 1645 development and 1976 for testing purposes. To evaluate performance, we use standard evaluation metrics - Mean Average Precision (MAP), F1 Score and Accuracy. We compare our approach with the two most powerful systems from SemEval 2015 - JAIST [22] and HITSZ-ICRC [6]. JAIST and HITSZ-ICRC use handmade function-based models. We also compare with ICRCHIT [28] because it uses a purely deep learning-based model. Likewise, for SemEval 2016 we compare with the two most powerful systems - Kelp [15] and KvN [15], because we do not yet know their conference procedures accurately and because they do not represent 15 algorithms."}, {"heading": "5. RESULTS AND DISCUSSION", "text": "Table 1 shows DFFN's overall results on SemEval 2015 and SemEval 2016 datasets, which are based on similarity. DFFN performs better than the top systems in all metrics. The improvement is higher in SemEval 2015, although the task is more difficult due to lower training data and greater granularity of the target labels to be predicted. We also observe that DFFN alone performs better than a single CNN (DFFN w / o HCF) or a single handmade feature-based model alone (DFFN w / o CNN), so merging deep features and handmade features helps to increase performance. 5.1 Qualitative AnalysisIn Table 2 we present a qualitative analysis of DFFN results compared to other baselines. The first three examples are cases where we correctly predicted the target label."}, {"heading": "6. CONCLUSION", "text": "We present a novel approach, \"Deep Feature Fusion Networks (DFFN),\" which combines HCF features into a CNN model to improve prediction of response quality. DFFN enriches the feature representations learned from a CNN by introducing more similarity features that are computed using external resources such as Wikipedia, Google Cross-Lingual Dictionary (GCD), Clickthrough Data. As a result, we show that DFFN achieves state-of-the-art performance with the standard benchmark data sets SemEval-2015 and SemEval-2016, and performs better than baseline approaches using either HCF or DL-based techniques. In the future, we would like to investigate the difference between features learned through DFFN and a standalone CNN."}, {"heading": "7. REFERENCES", "text": "[1] Gre \u0301 goire Burel, Yulan He, and Harith Alani.David Hamwering of Best Answers in Online Enquiry Communities. In The Semantic Web: Research and Applications: 9th Extended Semantic Web Conference, ESWC 2012. [2] Daniel Hasan Dalip, Marcos Andre Gonc, Marco Cristo, and Pavel Calado. [3] John Duchi, Elad Hazan, and Yoram Singer. Adaptive Subgradient Methods to Learning and Stochastic Optimization. J. Mach. Learn. Res., 2011. [4] Paolo Ferragina and Ugo Scaiella. TAGME: On-the-fly Annotation of Short Text Fragments (by Wikipedia Entities) Jigene JiLi Jigene."}], "references": [{"title": "Automatic Identification of Best Answers in Online Enquiry Communities", "author": ["Gr\u00e9goire Burel", "Yulan He", "Harith Alani"], "venue": "In The Semantic Web: Research and Applications: 9th Extended Semantic Web Conference,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2012}, {"title": "Adaptive Subgradient Methods for Online Learning and Stochastic Optimization", "author": ["John Duchi", "Elad Hazan", "Yoram Singer"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2011}, {"title": "TAGME: On-the-fly Annotation of Short Text Fragments (by Wikipedia Entities)", "author": ["Paolo Ferragina", "Ugo Scaiella"], "venue": "CIKM \u201910,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2010}, {"title": "Modeling Interestingness with Deep", "author": ["Jianfeng Gao", "Patrick Pantel", "Michael Gamon", "Xiaodong He", "Li Deng", "Yelong Shen"], "venue": "Neural Networks. EMNLP,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "HITSZ-ICRC:  Exploiting Classification Approach for Answer Selection in Community Question Answering", "author": ["Yongshuai Hou", "Cong Tan", "Xiaolong Wang", "Yaoyun Zhang", "Jun Xu", "Qingcai Chen"], "venue": "SemEval", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "Recurrent Neural Network Encoder with Attention for Community Question Answering", "author": ["Wei-Ning Hsu", "Yu Zhang", "James R. Glass"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2016}, {"title": "Learning Deep Structured Semantic Models for Web Search using Clickthrough", "author": ["Po-Sen Huang", "Xiaodong He", "Jianfeng Gao", "Li Deng", "Alex Acero", "Larry Heck"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2013}, {"title": "Distributed Representations of Sentences and Documents", "author": ["Quoc V. Le", "Tomas Mikolov"], "venue": "CoRR, abs/1405.4053,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "Answer Quality Characteristics and Prediction on an Academic QA Site: A Case Study on ResearchGate", "author": ["Lei Li", "Daqing He", "Wei Jeng", "Spencer Goodwin", "Chengzhi Zhang"], "venue": "In Proceedings of the 24th International Conference on World Wide Web,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2015}, {"title": "Semeval-2015 Task 3: Answer Selection in Community Question Answering", "author": ["Preslav Nakov", "Ll\u00fa\u0131s M\u00e0rquez", "Walid Magdy", "Alessandro Moschitti", "Jim Glass", "Bilal Randeree"], "venue": "In SemEval \u201915", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2015}, {"title": "SemEval-2016 Task 3: Community Question Answering. SemEval \u201916", "author": ["Preslav Nakov", "Ll\u00fa\u0131s M\u00e0rquez", "Alessandro Moschitti", "Walid Magdy", "Hamdy Mubarak", "Abed Alhakim Freihat", "Jim Glass", "Bilal Randeree"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2016}, {"title": "QCRI: Answer Selection for Community Question Answering - Experiments for Arabic and English", "author": ["Massimo Nicosia", "Simone Filice", "Alberto Barr\u00f3n-Cede\u00f1o", "Iman Saleh", "Hamdy Mubarak", "Wei Gao", "Preslav Nakov", "Giovanni Da San Martino", "Alessandro Moschitti", "Kareem Darwish", "Ll\u00fa\u0131s M\u00e0rquez", "Shafiq Joty", "Walid Magdy"], "venue": "SemEval", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2015}, {"title": "Glove: Global Vectors for Word Representation", "author": ["Jeffrey Pennington", "Richard Socher", "Christopher D. Manning"], "venue": "In EMNLP,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2014}, {"title": "A Latent Semantic Model with Convolutional-Pooling Structure for Information Retrieval", "author": ["Yelong Shen", "Xiaodong He", "Jianfeng Gao", "Li Deng", "Gregoire Mesnil"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2014}, {"title": "JAIST: Combining multiple features for Answer Selection in Community Question Answering", "author": ["Quan Hung Tran", "Vu Tran", "Tu Vu", "Minh Nguyen", "Son Bao Pham"], "venue": "SemEval", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2015}, {"title": "Empirical Evaluation of Rectified Activations in Convolutional Network", "author": ["Bing Xu", "Naiyan Wang", "Tianqi Chen", "Mu Li"], "venue": "CoRR, abs/1505.00853,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2015}, {"title": "ECNU: Using Multiple Sources of CQA-based Information for Answers Selection and YES/NO Response Inference", "author": ["Liang Yi", "JianXiang Wang", "Man Lan"], "venue": "SemEval", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2015}, {"title": "Deep Learning for Answer Sentence  Selection", "author": ["Lei Yu", "Karl Moritz Hermann", "Phil Blunsom", "Stephen Pulman"], "venue": "CoRR, abs/1412.1632,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2014}, {"title": "ICRC-HIT: A Deep Learning based Comment Sequence Labeling System for Answer Selection Challenge", "author": ["Xiaoqiang Zhou", "Baotian Hu", "Jiaxin Lin", "Yang xiang", "Xiaolong Wang"], "venue": "SemEval", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2015}], "referenceMentions": [{"referenceID": 4, "context": "To overcome the above problems, recent approaches [6, 7, 16, 18, 22, 23, 26\u201328] have focused on automatically ranking answers for a given question based on their quality.", "startOffset": 50, "endOffset": 79}, {"referenceID": 5, "context": "To overcome the above problems, recent approaches [6, 7, 16, 18, 22, 23, 26\u201328] have focused on automatically ranking answers for a given question based on their quality.", "startOffset": 50, "endOffset": 79}, {"referenceID": 11, "context": "To overcome the above problems, recent approaches [6, 7, 16, 18, 22, 23, 26\u201328] have focused on automatically ranking answers for a given question based on their quality.", "startOffset": 50, "endOffset": 79}, {"referenceID": 14, "context": "To overcome the above problems, recent approaches [6, 7, 16, 18, 22, 23, 26\u201328] have focused on automatically ranking answers for a given question based on their quality.", "startOffset": 50, "endOffset": 79}, {"referenceID": 16, "context": "To overcome the above problems, recent approaches [6, 7, 16, 18, 22, 23, 26\u201328] have focused on automatically ranking answers for a given question based on their quality.", "startOffset": 50, "endOffset": 79}, {"referenceID": 17, "context": "To overcome the above problems, recent approaches [6, 7, 16, 18, 22, 23, 26\u201328] have focused on automatically ranking answers for a given question based on their quality.", "startOffset": 50, "endOffset": 79}, {"referenceID": 18, "context": "To overcome the above problems, recent approaches [6, 7, 16, 18, 22, 23, 26\u201328] have focused on automatically ranking answers for a given question based on their quality.", "startOffset": 50, "endOffset": 79}, {"referenceID": 9, "context": "The cQA tasks of SemEval-2015 (Task A) [14] and SemEval-2016 (Task A) [15] provide a universal benchmark for evaluating research on this problem.", "startOffset": 39, "endOffset": 43}, {"referenceID": 10, "context": "The cQA tasks of SemEval-2015 (Task A) [14] and SemEval-2016 (Task A) [15] provide a universal benchmark for evaluating research on this problem.", "startOffset": 70, "endOffset": 74}, {"referenceID": 4, "context": "Recent approaches for answer quality prediction can be categorized into - a) Hand-crafted Feature (HCF) based approaches [6, 16, 22, 23, 26] or b) Deep Learning (DL) based approaches [7, 18, 27, 28].", "startOffset": 121, "endOffset": 140}, {"referenceID": 11, "context": "Recent approaches for answer quality prediction can be categorized into - a) Hand-crafted Feature (HCF) based approaches [6, 16, 22, 23, 26] or b) Deep Learning (DL) based approaches [7, 18, 27, 28].", "startOffset": 121, "endOffset": 140}, {"referenceID": 14, "context": "Recent approaches for answer quality prediction can be categorized into - a) Hand-crafted Feature (HCF) based approaches [6, 16, 22, 23, 26] or b) Deep Learning (DL) based approaches [7, 18, 27, 28].", "startOffset": 121, "endOffset": 140}, {"referenceID": 16, "context": "Recent approaches for answer quality prediction can be categorized into - a) Hand-crafted Feature (HCF) based approaches [6, 16, 22, 23, 26] or b) Deep Learning (DL) based approaches [7, 18, 27, 28].", "startOffset": 121, "endOffset": 140}, {"referenceID": 5, "context": "Recent approaches for answer quality prediction can be categorized into - a) Hand-crafted Feature (HCF) based approaches [6, 16, 22, 23, 26] or b) Deep Learning (DL) based approaches [7, 18, 27, 28].", "startOffset": 183, "endOffset": 198}, {"referenceID": 17, "context": "Recent approaches for answer quality prediction can be categorized into - a) Hand-crafted Feature (HCF) based approaches [6, 16, 22, 23, 26] or b) Deep Learning (DL) based approaches [7, 18, 27, 28].", "startOffset": 183, "endOffset": 198}, {"referenceID": 18, "context": "Recent approaches for answer quality prediction can be categorized into - a) Hand-crafted Feature (HCF) based approaches [6, 16, 22, 23, 26] or b) Deep Learning (DL) based approaches [7, 18, 27, 28].", "startOffset": 183, "endOffset": 198}, {"referenceID": 0, "context": "[1] have used a combination of content, user and thread related features for predicting answer quality.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[11] studied the various factors such as shorter length, authors reputation which lead to a high answer quality rating as rated by peers.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[22] made use of topic models, word vectors and other hand crafted rules to train a SVM classifier for AQP.", "startOffset": 0, "endOffset": 4}, {"referenceID": 4, "context": "[6] made use of statistics like avg.", "startOffset": 0, "endOffset": 3}, {"referenceID": 17, "context": "[27] used CNN to learn a distributional sentence model for AQP from bag of words and bigram based word representations.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "al [16] have used lexical similarity between word n-grams, tree kernels, word-embeddings and other hand crafted features for AQP.", "startOffset": 3, "endOffset": 7}, {"referenceID": 5, "context": "[7] used a LSTM encoder with neural attention mechanism to auto-", "startOffset": 0, "endOffset": 3}, {"referenceID": 18, "context": "[28] used a 2-dimensional CNN to represent a question-answer pair and ranked the representations using a Recurrent Neural Network.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "We use GLoVE [17] based embeddings of 300 dimensions to map the words in the question and answer.", "startOffset": 13, "endOffset": 17}, {"referenceID": 15, "context": "We use max-pooling for the pooling layer and Randomized Leaky Rectified Linear Unit (RReLU) [25], a randomized version of leakyReLU [25], as the non-linearity layer.", "startOffset": 92, "endOffset": 96}, {"referenceID": 15, "context": "We use max-pooling for the pooling layer and Randomized Leaky Rectified Linear Unit (RReLU) [25], a randomized version of leakyReLU [25], as the non-linearity layer.", "startOffset": 132, "endOffset": 136}, {"referenceID": 2, "context": "TagMe Similarity: We extract TagMe concepts of the question and answer by mapping them to their corresponding Wikipedia page titles using TagMe [4].", "startOffset": 144, "endOffset": 147}, {"referenceID": 7, "context": "Paragraph2vec Similarity: Paragraph2Vec [10] allows to model vectors for text of any arbitrary length.", "startOffset": 40, "endOffset": 44}, {"referenceID": 6, "context": "Sent2Vec performs the mapping using the Deep Structured Semantic Model (DSSM) built using Clickthrough data [8], or the DSSM with convolutional-pooling structure (CDSSM) [5,19].", "startOffset": 108, "endOffset": 111}, {"referenceID": 3, "context": "Sent2Vec performs the mapping using the Deep Structured Semantic Model (DSSM) built using Clickthrough data [8], or the DSSM with convolutional-pooling structure (CDSSM) [5,19].", "startOffset": 170, "endOffset": 176}, {"referenceID": 13, "context": "Sent2Vec performs the mapping using the Deep Structured Semantic Model (DSSM) built using Clickthrough data [8], or the DSSM with convolutional-pooling structure (CDSSM) [5,19].", "startOffset": 170, "endOffset": 176}, {"referenceID": 9, "context": "For training, we used the training data provided in the SemEval 2015 [14] and 2016 [15] tasks which consists of question, answer, metadata along with their ideal quality rating.", "startOffset": 69, "endOffset": 73}, {"referenceID": 10, "context": "For training, we used the training data provided in the SemEval 2015 [14] and 2016 [15] tasks which consists of question, answer, metadata along with their ideal quality rating.", "startOffset": 83, "endOffset": 87}, {"referenceID": 1, "context": "We used Adagrad [3] to speed up the convergence rate of stochastic gradient descent (SGD).", "startOffset": 16, "endOffset": 19}, {"referenceID": 10, "context": "We use the SemEval 2016 [15] and SemEval 2015 [14] datasets for our experiments as it exactly matches our problem description.", "startOffset": 24, "endOffset": 28}, {"referenceID": 9, "context": "We use the SemEval 2016 [15] and SemEval 2015 [14] datasets for our experiments as it exactly matches our problem description.", "startOffset": 46, "endOffset": 50}, {"referenceID": 14, "context": "We compare our approach with the top two best performing systems from SemEval 2015 - JAIST [22] and HITSZ-ICRC [6].", "startOffset": 91, "endOffset": 95}, {"referenceID": 4, "context": "We compare our approach with the top two best performing systems from SemEval 2015 - JAIST [22] and HITSZ-ICRC [6].", "startOffset": 111, "endOffset": 114}, {"referenceID": 18, "context": "We also compare with ICRCHIT [28] as it uses a purely deep learning based model.", "startOffset": 29, "endOffset": 33}, {"referenceID": 10, "context": "Similarly, for SemEval 2016, we compare with their corresponding top two best performing systems - Kelp [15] and ConvKN [15].", "startOffset": 104, "endOffset": 108}, {"referenceID": 10, "context": "Similarly, for SemEval 2016, we compare with their corresponding top two best performing systems - Kelp [15] and ConvKN [15].", "startOffset": 120, "endOffset": 124}], "year": 2016, "abstractText": "Community Question Answering (cQA) forums have become a popular medium for soliciting direct answers to specific questions of users from experts or other experienced users on a given topic. However, for a given question, users sometimes have to sift through a large number of low-quality or irrelevant answers to find out the answer which satisfies their information need. To alleviate this, the problem of Answer Quality Prediction (AQP) aims to predict the quality of an answer posted in response to a forum question. Current AQP systems either learn models using a) various hand-crafted features (HCF) or b) use deep learning (DL) techniques which automatically learn the required feature representations. In this paper, we propose a novel approach for AQP known as -\u201cDeep Feature Fusion Network (DFFN)\u201dwhich leverages the advantages of both hand-crafted features and deep learning based systems. Given a question-answer pair along with its metadata, DFFN independently a) learns deep features using a Convolutional Neural Network (CNN) and b) computes hand-crafted features using various external resources and then combines them using a deep neural network trained to predict the final answer quality. DFFN achieves stateof-the-art performance on the standard SemEval-2015 and SemEval-2016 benchmark datasets and outperforms baseline approaches which individually employ either HCF or DL based techniques alone.", "creator": "LaTeX with hyperref package"}}}