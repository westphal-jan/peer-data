{"id": "1606.07137", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Jun-2016", "title": "Automated Extraction of Number of Subjects in Randomised Controlled Trials", "abstract": "We present a simple approach for automatically extracting the number of subjects involved in randomised controlled trials (RCT). Our approach first applies a set of rule-based techniques to extract candidate study sizes from the abstracts of the articles. Supervised classification is then performed over the candidates with support vector machines, using a small set of lexical, structural, and contextual features. With only a small annotated training set of 201 RCTs, we obtained an accuracy of 88\\%. We believe that this system will aid complex medical text processing tasks such as summarisation and question answering.", "histories": [["v1", "Wed, 22 Jun 2016 23:35:59 GMT  (35kb,D)", "http://arxiv.org/abs/1606.07137v1", "unpublished"]], "COMMENTS": "unpublished", "reviews": [], "SUBJECTS": "cs.AI cs.CL cs.IR", "authors": ["abeed sarker"], "accepted": false, "id": "1606.07137"}, "pdf": {"name": "1606.07137.pdf", "metadata": {"source": "CRF", "title": "Automated Extraction of Number of Subjects in Randomised Controlled Trials", "authors": ["Abeed Sarker"], "emails": ["abeed.sarker@asu.edu"], "sections": [{"heading": "1 Background", "text": "Research in evidence-based medicine focuses on extracting key information from medical texts and applying it to automate complex, time-consuming tasks such as summarizing, answering questions, and assessing evidence (DemnerFushman and Lin, 2007; Mishra et al., 2014; Sarker et al., 2015), but mainly due to the complex nature of the medical text, with its domain-exclusive terminologies and ontologies, task-specific information extraction is not trivial (Summerscales, 2014). Problems with content selection / information extraction may be exacerbated by the different structures of published medical texts (Amini et al., 2012). In this paper, we present an approach to automatically extract sample sizes from randomized controlled trials. Our approach consists of two steps. In the first step, integrators representing potentially small studies can be identified and then classified using SVM."}, {"heading": "2 Related Work", "text": "The primary problem faced by rule-based systems is expandability, as the number of rules in tasks such as answering questions becomes increasingly complex (e.g. Lin and DemnerFushman (2007)) Some of the specific information that was of interest to problems with information extraction are age values (values describing characteristics of the sample age), medical conditions, population groups (e.g. men, adolescents, older women), group sizes, results, etc. (Summerscales, 2014) Rule-based approaches have been extensively studied for these and simi-ar Xiv: 160 6.07 137v 1 [cs.A I] 2 2Ju n20 16lar tasks - the majority of approaches that attempt to explore lexical laws, syntactic structures and / or other lexical properties at the surface level (e.g. Summerscales et al al al al al. (2011) and Bruijn n20 16lar tasks - most approaches that attempt to study other summerlexlecal laws and / or other lexical structures in the past)."}, {"heading": "3 Methods", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Data", "text": "We collected a number of RCTs from two sources: About 200 RCTs were randomly selected from all the RCTs in the corpus proposed by Molla \u0301 and Santiago-martinez (2011), and another 200 RCTs were identified by PubMed.1 using the rules-based approach proposed by Sarker and Molla (2010). RCTs that did not involve humans were removed and a total of 251 RCTs were annotated."}, {"heading": "3.2 Candidate extraction and classification", "text": "Integers expressed in words are first converted to their numerical forms using regular expressions and a reference table. Integers smaller than 10 are discarded. Note that while there may be RCTs with less than 10 samples, we found that adding this criterion significantly reduces the number of potential false positives. 2After candidate extraction, a number of 1http: / / www.ncbi.nlm.nih.gov / pubmed was determined. [Accessed: 8-10-2015.] 2No studies with a size smaller than 10 were conducted in our sample. Characteristics are assigned to each candidate. Characteristics can be roughly categorized into three groups that look like this:"}, {"heading": "3.2.1 Contextual features", "text": "\u2022 Context terms: The only pre-processing performed in a sentence are the terms from positions n-3 to n + 3. We also integrate the full context term (from n-3 to n + 3) as a separate single attribute. All terms are pre-processed by lowercase letters and descent. \u2022 Context clusters. For each term in the context window, we introduce a cluster number representing this attribute as a attribute. The purpose of using these cluster numbers is to provide a more general representation of context terms, which we believe may be particularly useful if we have a small training set. To generate the word clusters, we use the popular word2vec tool3 (Mikolov et al., 2013). Distributed representations of the words are first learned from a large group of approximately 800,000 RCTs, which are likely to be obtained from the population."}, {"heading": "3.2.2 Lexical features", "text": "\u2022 Sentence n-gram. We generate 1, 2, 3 grams from the candidate set and use them as attributes. The text is pre-processed in the aforementioned manner before we produce the n-gram. \u2022 Indication of the year. A large number of the candidates generated by our first processing step are years (e.g. 1995, 2014, etc.). Therefore, we mark all candidates between the numerical values from 1950 to 2020 with a binary attribute indicating that the mention may be a year."}, {"heading": "3.3 Structural features", "text": "\u2022 Sentence Category. In structured abstractions from PubMed, sentences are often divided into large categories, such as methods, results, conclusions, etc. Where available, we use these categories as characteristics for candidates. \u2022 Sentence Name. Similar to categories, but the labels often represent finer-grained information (e.g. patients and methods). We use them as candidate characteristics. In addition, we identified some labels that are highly likely to be contextually associated with study sizes. \u2022 Sentence Position We added a binary feature to indicate whether the sentence associated with a candidate belongs to one of these very likely labels. \u2022 Candidate Position. We use the absolute and relative candidate positions in the sentence as numerical characteristics. \u2022 Sentence Position We use the absolute and relative sentence positions for a candidate as numerical characteristics."}, {"heading": "3.4 Classification experimental setup", "text": "We use the 201 abstracts in the training set to automatically extract the candidates, and then conduct training with these automatically extracted candidates. Note that this form of training simplifies the future creation of larger data sets (i.e. the annotator is only needed to mark the correct candidate that has been extracted as a positive label).In total, 1,530 candidates are generated from our complete training set. SVMs are set up with an RBF core and cost and gamma parameters are optimized using a grid search, using 100% of the traction rate for learning and evaluation. Parameter optimization does not take into account the accuracy of individual applicant classifications. Instead, we define the classification problem as the problem of selecting the right candidates with the restriction that only one candidate may be selected as size per abstract. In this sense, our Classified Probability Estimates generates for each candidate and selects the candidate with the highest probability within an abstract."}, {"heading": "4 Results and discussions", "text": "Table 1 shows the performance of our system on the small test set and the contributions of each type of characteristic. The best accuracy achieved on the test set is 88%. The table also shows the confidence intervals, which are quite large due to the small size of the test set. However, the best accuracy achieved on the training set using 10-fold cross-validation is 94%. The table also shows the reported performance of several systems. Surprisingly, early statistical approaches with relatively small data sets showed very good results. Newer approaches reported performance that was much lower than ours. Since all these systems were evaluated using different data sets and none of these systems is publicly available, it is not possible to analyze the reasons for the wide range of reported performance. We also conducted experiments with individual characteristics and experiments without characteristics. For these, we looked at each of the broad categories of characteristics. Table 1 shows that contextual characteristics perform best, and xalical characteristics perform poorly when structural and non-structural characteristics are removed."}, {"heading": "4.1 Error analysis", "text": "We analyzed these 6 cases and found that three of the errors were true false alarms (i.e., the wrong candidate was selected). Consider, for example, the following sentence: \"Between 1996 and 2001, 1477 patients from 70 hospitals in 14 countries...\" Due to the close mix of numbers, a number of candidates exhibit almost identical characteristics, leading to a misclassification (our classifier chose \"70\" as the size). However, the process of generating candidates is able to identify the right candidate. The three remaining misclassifications are caused by the fact that the sizes in the abstracts are not mentioned as individual numbers. Consider, for example, the following sentence: Patients... were randomized to a three-month course of treatment either with INH before meals (n = 76) or with rossiglitazone 4 mg twice a day (n = 69), so that the total number of study participants is not mentioned as a single problem."}, {"heading": "5 Conclusions", "text": "In this paper, we have presented a system for extracting sample size information from randomized controlled trials, based on a hybrid framework - rules are first applied to extract potential size candidates, and a supervised learning algorithm is then applied to select a single candidate from each document. Our approach performs well with a very small training set. Importantly, our feature-rich approach can be applied to a variety of other information extraction tasks, especially those related to size information (e.g., population recognition, intervention recognition and comparison), as such important concepts tend to occur near sizes. The intention of this approach is to function as an extensible module that can be used in complex, automated NLP tasks such as answering questions, summarizing, and evidence evaluation. In the future, we will try to use these techniques to develop a platform for extracting population size information from older people, for example, young people with diabetes."}, {"heading": "Acknowledgements", "text": "The study was partly funded by Macquarie University and CSIRO Australia during the author's PhD period."}], "references": [{"title": "Overview of the alta 2012 shared task", "author": ["Amini et al.2012] Iman Amini", "David Martinez", "Diego Molla"], "venue": "In Proceedings of the Australasian Language Technology Association Workshop", "citeRegEx": "Amini et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Amini et al\\.", "year": 2012}, {"title": "Rule-based Information Extraction is Dead! Long Live Rule-based Information Extraction System", "author": ["Yunyao Li", "Frederick R Reiss"], "venue": "In Proceedings of EMNLP2013,", "citeRegEx": "Chiticariu et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Chiticariu et al\\.", "year": 2013}, {"title": "Automated Information Extraction of Key Trial Design Elements from Clinical Trial Publications", "author": ["Simna Carini", "Svetlana Kiritchenko", "Joel Martin", "Ida Sim"], "venue": "AMIA", "citeRegEx": "Bruijn et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Bruijn et al\\.", "year": 2008}, {"title": "Answering clinical questions with knowledge-based and statistical techniques", "author": ["Demner-Fushman", "Lin2007] Dina DemnerFushman", "Jimmy Lin"], "venue": "Computational Linguistics,", "citeRegEx": "Demner.Fushman et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Demner.Fushman et al\\.", "year": 2007}, {"title": "A method of extracting the number of trial participants from abstracts describing randomized controlled trials", "author": ["Hansen", "Rasmussen2008] Marie J Hansen", "Nana O Rasmussen"], "venue": "Journal of Telemedicine and Telecare,", "citeRegEx": "Hansen et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Hansen et al\\.", "year": 2008}, {"title": "ExaCT: automatic extraction of clinical trial characteristics from journal publications", "author": ["Berry de Bruijn", "Samona Carini", "Joel Martin", "Ida Sim"], "venue": "BMC Medical Informatics and Decision Making,", "citeRegEx": "Kiritchenko et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Kiritchenko et al\\.", "year": 2010}, {"title": "Some methods for classification and analysis of multivariate observations", "author": ["J. MacQueen"], "venue": "In Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability,", "citeRegEx": "MacQueen.,? \\Q1967\\E", "shortCiteRegEx": "MacQueen.", "year": 1967}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Ilya Sutskever", "Kai Chen", "Greg Corrado", "Jeffrey Dean"], "venue": "Proceedings of NIPS", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Text summarization in the biomedical domain: A systematic review of recent research", "author": ["Mishra et al.2014] Rashmi Mishra", "Jiantao Bian", "Marcelo Fiszman", "Charlene R. Weir", "Siddhartha Jonnalagadda", "Javed Mostafa", "Guilherme Del Fiol"], "venue": null, "citeRegEx": "Mishra et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Mishra et al\\.", "year": 2014}, {"title": "Development of a corpus for evidence based medicine summarisation", "author": ["Molla", "Maria Elena Santiago-Martinez"], "venue": "In Proceedings of the Australasian Language Technology Association Workshop", "citeRegEx": "Molla et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Molla et al\\.", "year": 2011}, {"title": "A rule-based approach for automatic identification of publication types of medical papers", "author": ["Sarker", "Moll\u00e12010] Abeed Sarker", "Diego Moll\u00e1"], "venue": "In Proceedings of the 15th Australasian Document Computing Symposium,", "citeRegEx": "Sarker et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Sarker et al\\.", "year": 2010}, {"title": "Automatic evidence quality prediction to support evidence-based decision making", "author": ["Sarker et al.2015] Abeed Sarker", "Diego Moll\u00e1", "C\u00e9cile Paris"], "venue": "Artificial Intelligence in Medicine,", "citeRegEx": "Sarker et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Sarker et al\\.", "year": 2015}, {"title": "Automatic Summarization of results from clinical trials", "author": ["Shlomo Argamon", "Shangda Bai", "Jordan Hupert", "Alan Schwartz"], "venue": "In Proceedings of the 2011 IEEE Conference on Bioinformatics", "citeRegEx": "Summerscales et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Summerscales et al\\.", "year": 2011}, {"title": "Automatic Summarization of Clinical Abstracts for Evidence-based Medicine", "author": ["Rodney L Summerscales"], "venue": "Ph.D. thesis, Illinois Institute of Technology", "citeRegEx": "Summerscales.,? \\Q2014\\E", "shortCiteRegEx": "Summerscales.", "year": 2014}, {"title": "Extracting subject demographic information from abstracts of randomized clinical trial reports", "author": ["Xu et al.2007] Rong Xu", "Yael Garten", "Kaustubh S Supekar", "Amar K Das", "Russ B Altman", "Alan M Garber"], "venue": "Studies in Health Technology and Informat-", "citeRegEx": "Xu et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Xu et al\\.", "year": 2007}], "referenceMentions": [{"referenceID": 8, "context": "Natural language processing (NLP) research within the field of evidence-based medicine has focused on extracting key information from medical texts and applying them for automating complex, timeconsuming tasks such as summarisation, question answering, and evidence appraisal (DemnerFushman and Lin, 2007; Mishra et al., 2014; Sarker et al., 2015).", "startOffset": 276, "endOffset": 347}, {"referenceID": 11, "context": "Natural language processing (NLP) research within the field of evidence-based medicine has focused on extracting key information from medical texts and applying them for automating complex, timeconsuming tasks such as summarisation, question answering, and evidence appraisal (DemnerFushman and Lin, 2007; Mishra et al., 2014; Sarker et al., 2015).", "startOffset": 276, "endOffset": 347}, {"referenceID": 13, "context": "However, primarily due to the complex nature of medical text, with its domain exclusive terminologies and ontologies, extraction of task-specific information is not trivial (Summerscales, 2014).", "startOffset": 173, "endOffset": 193}, {"referenceID": 0, "context": "Problems of content selection/information extraction are perhaps further exacerbated by the varying structures of published medical texts (Amini et al., 2012).", "startOffset": 138, "endOffset": 158}, {"referenceID": 13, "context": ", males, adolescents, elderly females), group sizes, outcomes, and so on (Summerscales, 2014).", "startOffset": 73, "endOffset": 93}, {"referenceID": 1, "context": "The primary problem faced by rulebased systems is extensibility, as the number of rules can become very large, and increasingly difficult to maintain (Chiticariu et al., 2013).", "startOffset": 150, "endOffset": 175}, {"referenceID": 5, "context": "Supervised learning approaches have been shown to be more effective in the past (Hansen and Rasmussen, 2008; Kiritchenko et al., 2010), however their portability and availability for use in more complex systems have not been assessed.", "startOffset": 80, "endOffset": 134}, {"referenceID": 9, "context": ", Summerscales et al. (2011), and Bruijn et al.", "startOffset": 2, "endOffset": 29}, {"referenceID": 1, "context": "(2011), and Bruijn et al. (2008)).", "startOffset": 12, "endOffset": 33}, {"referenceID": 13, "context": "We found the manual identification of the sizes of studies relatively straightforward, as also suggested by Summerscales (2014).", "startOffset": 108, "endOffset": 128}, {"referenceID": 7, "context": "To generate the word clusters, we employ the popular word2vec tool3 (Mikolov et al., 2013).", "startOffset": 68, "endOffset": 90}, {"referenceID": 6, "context": "distributed word vectors, K-means clustering (MacQueen, 1967) is used to allocate the word vectors into 500 clusters.", "startOffset": 45, "endOffset": 61}, {"referenceID": 14, "context": "We performed this by extending the list of terms suggested by Xu et al. (2007). For each candidate, we used a binary feature to indicate if there is a population term present", "startOffset": 62, "endOffset": 79}, {"referenceID": 13, "context": "BANNER (baseline) (Summerscales, 2014) 64 .", "startOffset": 18, "endOffset": 38}], "year": 2016, "abstractText": "We present a simple approach for automatically extracting the number of subjects involved in randomised controlled trials (RCT). Our approach first applies a set of rule-based techniques to extract candidate study sizes from the abstracts of the articles. Supervised classification is then performed over the candidates with support vector machines, using a small set of lexical, structural, and contextual features. With only a small annotated training set of 201 RCTs, we obtained an accuracy of 88%. We believe that this system will aid complex medical text processing tasks such as summarisation and question answering.", "creator": "LaTeX with hyperref package"}}}