{"id": "1606.07461", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Jun-2016", "title": "Visual Analysis of Hidden State Dynamics in Recurrent Neural Networks", "abstract": "Recurrent neural networks, and in particular long short-term memory networks (LSTMs), are a remarkably effective tool for sequence modeling that learn a dense black-box hidden representation of their sequential input. Researchers interested in better understanding these models have studied the changes in hidden state representations over time and noticed some interpretable patterns but also significant noise. In this work, we present LSTMVis a visual analysis tool for recurrent neural networks with a focus on understanding these hidden state dynamics. The tool allows a user to select a hypothesis input range to focus on local state changes, to match these states changes to similar patterns in a large data set, and to align these results with domain specific structural annotations. We further show several use cases of the tool for analyzing specific hidden state properties on datasets containing nesting, phrase structure, and chord progressions, and demonstrate how the tool can be used to isolate patterns for further statistical analysis.", "histories": [["v1", "Thu, 23 Jun 2016 20:20:39 GMT  (4883kb,D)", "http://arxiv.org/abs/1606.07461v1", null], ["v2", "Mon, 30 Oct 2017 15:11:54 GMT  (6434kb,D)", "http://arxiv.org/abs/1606.07461v2", "InfoVis 2017"]], "reviews": [], "SUBJECTS": "cs.CL cs.AI cs.NE", "authors": ["hendrik strobelt", "sebastian gehrmann", "bernd huber", "hanspeter pfister", "alexander m rush"], "accepted": false, "id": "1606.07461"}, "pdf": {"name": "1606.07461.pdf", "metadata": {"source": "META", "title": "Visual Analysis of Hidden State Dynamics in  Recurrent Neural Networks ", "authors": ["Hendrik Strobelt", "Sebastian Gehrmann", "Bernd Huber", "Hanspeter Pfister"], "emails": ["rush}@seas.harvard.edu"], "sections": [{"heading": "1 INTRODUCTION", "text": "Recurring Neural Networks (RNNs) [6] have proven to be a very effective general-purpose model for recording long-term dependencies in textual applications. Recent strong empirical results suggest that internal representations learned by RNNs capture complex relationships between words within a sentence or document. While RNNs have shown clear improvements in sequence modeling, the models themselves are black boxes, and it remains unclear how a particular model represents long-distance relationships within a sequence. Typically, RNNNs contain millions of parameters and use repeated nonlinear transformations of large hidden representations under time-varying conditions, making the model of internal dependencies challenging to interpret without sophisticated mathematical tools."}, {"heading": "2 BACKGROUND: RECURRENT NEURAL NETWORKS", "text": "This year, more than ever, it will be able to retaliate."}, {"heading": "3 RELATED WORK", "text": "Understanding RNNs through visualization Our core contribution, visualizing the state dynamics of LSTM in a structured way, is inspired by previous work on conventional networks for visualizing applications [21, 28]. In linguistic tasks, visualizations have proven to be a useful tool for understanding certain aspects of LSTMs. In [17] additional visualization techniques are used to enhance the understanding of hidden states in language models. This work shows that selected cells represent clear events such as open brackets and the start of URLs, in particular the use of gradient-based scales to find important words."}, {"heading": "4 GOALS AND TASKS", "text": "Given that RNNs act as black boxes, their success leaves open the question of why they are so effective in telling the history of words. LSTMVIS focuses in particular on the dynamics of the RNN Hidden States and aims at the related question: \"What information does an RNN collect in its Hidden States?\" This question is the main objective of our project and the focus of a series of discussions. During this iterative process, we identified the following domain targets for a user of LSTMVIS: \u2022 G1 - Formulate a hypothesis of (linguistic) properties that the Hidden States could learn to capture for a particular model. This hypothesis requires an initial understanding of the Hidden State Values over time and a close reading of the original text. \u2022 G2 - Refine the hypothesis based on insights about learned textual similarities based on the dynamics of the Hidden State."}, {"heading": "5 VISUAL DESIGN", "text": "LSTMVIS supports the formulation of a hypothesis (T1, T2, G1) in the Select view (Section 5.1) and can trigger a refinement of a hypothesis (T3, T4, G2) in the Match view (Section 5.2), while remaining agnostic towards the underlying data or models (Section 5.2). We first describe the visual design and interaction paradigms used in the two views and how they facilitate domain goals, and then discuss design iterations for LSTMVIS in Section 5.4."}, {"heading": "5.1 Select View", "text": "In fact, most people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move."}, {"heading": "5.2 Match View", "text": "It is indeed very difficult to find the cause of the disease, as the disease is not yet able to contain it."}, {"heading": "5.3 Navigation Along the Time Axis", "text": "LSTMVIS provides various convenient ways to navigate to specific time steps. Buttons on the timeline can be used to move forward and backward. LSTMVIS also provides search functions to find specific phrases. Finally, the drop-down box in the top left can be used to efficiently switch between the different levels of the same model and between records (TX). Since all different levels and records can be displayed in the same way, the user can easily compare models."}, {"heading": "5.4 Design Iterations", "text": "During the course of the project, we developed seven interactive prototypes of varying complexity that highlight different aspects of the data. In this section, we present two basic design decisions that lead to the final system."}, {"heading": "5.4.1 Visual Encoding of State Dynamics", "text": "Inspired by a standard static visualization in the RNN literature, we initially encoded hidden state vectors as heatmaps along the timeline (Figure 4 (a)). This style was favored as a view of the full set of hidden states h1,..., hT. However, this approach has several disadvantages in interactive visualization. First and foremost, the heatmaps do not scale well with increasing dimensionality D of hidden state vectors. They use ineffective encoding for the most important information, i.e. hidden state values by hue. In addition, they emphasize the sequence of hidden states in each vector, but this relative sequence of abstract hidden states is not used by the model itself. Instead, we decided to consider each hidden state as data element and time steps as dimensions for each data element in a parallel coordinate plot."}, {"heading": "5.4.2 Formulating a Hypothesis", "text": "One of the challenges we faced in early design iterations was to allow the user to easily express hypotheses through selection. In Figure 4 (b), we show a preliminary design that uses a common filter method for parallel coordinates along each axis. Experimenting with this type of selection revealed two major drawbacks of this approach: First, it was very cumbersome to formulate a hypothesis for a larger range by adjusting many y-axis brush selectors at fine granularity; second, direct selection based on the hidden state values felt disconnected from the original source of information - text; and the key idea to facilitate this selection process was that the user could easily discretice the data based on a threshold and select areas directly above the words (as described in Section 5). This idea generalizes and complements the manual approaches developed in [14] to interactivity."}, {"heading": "6 USE CASES", "text": "In experiments with the system, we studied and trained many different RNN models, data sets, and tasks, including word and sign language models, neural machine translation systems, auto-encoders, summarization systems, and classifiers. In addition, we also experimented with other types of real and synthetic input data. In this section, we highlight three results that demonstrate the general applicability of LSTMVIS paradigms for the analysis of hidden states."}, {"heading": "6.1 Proof-of-Concept: Parenthesis Language", "text": "To prove the concept, we trained an LSTM as a language model based on synthetic data generated from a very simple counting language with an apendix and letter alphabet \u03a3 = {() 0 1 2 3 4}. Language is forced to match brackets, and nesting is limited to a maximum of 4 levels, with each opening bracket increasing the nesting level and each closing bracket decreasing the nesting level. Numbers are generated randomly, but are forced to specify the nesting level at their position. For example, a string in the language looks like this: where blue lines show areas of the nesting level \u2265 1. Likewise, orange and green lines show the nesting level \u2265 2 and \u2265 3. To analyze this language, we look at the states in LSTMVIS (we show the cell states of a multi-layered 2x300 LSTM model). An example of this is the free linking of NSTM models."}, {"heading": "6.2 Phrase Separation in Language Modeling", "text": "Next, we look at the case of a natural language model of the real world. For this experiment, we trained a two-layer LSTM language model with 650 hidden states on the Penn Treebank [18], which follows the medium-sized model of [27]. While the model is trained for speech modelling (predicting the next word), we were interested in seeing if it learned additional properties about the underlying language structure. To test this, we also incorporated notes into the model from Penn Treebank. We experimented with the inclusion of language components, named entities and analysed structures. Here, we focus on the case of phrase tuning. We commented on the data set of gold standard phrase junks provided by the CoNLL in 2003 for a subset of the tree base (sections 15-18), including annotations for noun phrases and verb phrases that cannot be replaced by any less common phrases."}, {"heading": "6.3 Musical Chord Progressions", "text": "For text data sets, we found that this was rarely the case with a few exceptions (quotations, parentheses, and commas), but for data sets with a more regular long-term structure, individual states could be meaningful. As a simple example, we collected a large number of songs with annotated chords for rock and pop songs, which are used as training data sets, totaling 219k chords. Subsequently, we trained an LSTM language model to predict the next chord with + 1 in the sequence due to previous chord symbols (chords are left in their raw format). When we looked at the results in LSTMVIS, we found that the recurring structure of chord gradients is strongly reflected in the hidden states. Certain states turn on at the beginning of a standard progression and remain in the rock length with general variant patterns until we reach a resolution of 3."}, {"heading": "7 IMPLEMENTATION", "text": "LSTMVIS consists of two modules, the visualization system and the RNN modeling component. Visualization is a client-server system that uses Javascript and D3 on the client side and Python, Flask, h5py and numpy on the server side. Time series data (RNN hidden states and input) are dynamically loaded through HDF5 files. Optional annotation files can be specified to map categorical data to labels (T4). New data sets can be easily added through a declarative YAML configuration file. The RNN modeling system is completely separate from visualization to allow compatibility with any Deep Learning Framework (TX). For our experiments, we used the Torch Framework and the Element RNN library [16]."}, {"heading": "8 CONCLUSION", "text": "LSTMVIS provides an interactive visualization for data analysis of recurrent neural network states. The tool is based on a two-step process in which the user can select a palette of text to represent a hypothesis on the RNN representation; the tool can then compare this selection with other examples from the dataset. The tool easily allows external annotations to verify or reject hypotheses. It requires a minimum of a time series of hidden states, making it easy to apply a wide range of visual analyses of different datasets and models, and even different tasks (language modeling, translation, etc.). To demonstrate the use of the model, we presented three case studies describing how the tool can be applied to different datasets. In the case of synthetic data, the tool clearly separates the basic structure from each other. In the case of natural language data, states are louder, but we can find clear divisions between known linguistic structures such as phrases, but also to allow for specific verbs to be used in practice."}, {"heading": "ACKNOWLEDGMENTS", "text": "This work was partially supported by the Air Force Research Laboratory and DARPA funding FA8750-12-C-0300."}], "references": [{"title": "Tensorflow: Large-scale machine learning on heterogeneous distributed systems", "author": ["M. Abadi", "A. Agarwal", "P. Barham", "E. Brevdo", "Z. Chen", "C. Citro", "G.S. Corrado", "A. Davis", "J. Dean", "M. Devin"], "venue": "arXiv preprint arXiv:1603.04467,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2016}, {"title": "Deep speech 2: End-to-end speech recognition in english and mandarin", "author": ["D. Amodei", "R. Anubhai", "E. Battenberg", "C. Case", "J. Casper", "B.C. Catanzaro", "J. Chen", "M. Chrzanowski", "A. Coates", "G. Diamos", "E. Elsen", "J. Engel", "L. Fan", "C. Fougner", "T. Han", "A.Y. Hannun", "B. Jun", "P. LeGresley", "L. Lin", "S. Narang", "A.Y. Ng", "S. Ozair", "R. Prenger", "J. Raiman", "S. Satheesh", "D. Seetapun", "S. Sengupta", "Y. Wang", "Z. Wang", "C. Wang", "B. Xiao", "D. Yogatama", "J. Zhan", "Z. Zhu"], "venue": "CoRR, abs/1512.02595,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2015}, {"title": "Neural machine translation by jointly learning to align and translate", "author": ["D. Bahdanau", "K. Cho", "Y. Bengio"], "venue": "CoRR, abs/1409.0473,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2014}, {"title": "Modeling temporal dependencies in high-dimensional sequences: Application to polyphonic music generation and transcription", "author": ["N. Boulanger-Lewandowski", "Y. Bengio", "P. Vincent"], "venue": "Proceedings of the 29th International Conference on Machine Learning, ICML 2012, Edinburgh, Scotland, UK, June 26 - July 1, 2012. icml.cc / Omnipress,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2012}, {"title": "Semi-supervised sequence learning", "author": ["A.M. Dai", "Q.V. Le"], "venue": "Advances in Neural Information Processing Systems, pp. 3079\u20133087,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2015}, {"title": "Finding structure in time", "author": ["J.L. Elman"], "venue": "Cognitive science, 14(2):179\u2013211,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1990}, {"title": "Lstm recurrent networks learn simple context-free and context-sensitive languages", "author": ["F.A. Gers", "E. Schmidhuber"], "venue": "IEEE Transactions on Neural Networks, 12(6):1333\u20131340,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2001}, {"title": "Teaching machines to read and comprehend", "author": ["K.M. Hermann", "T. Kocisk\u00fd", "E. Grefenstette", "L. Espeholt", "W. Kay", "M. Suleyman", "P. Blunsom"], "venue": "C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, eds., Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems 2015, December 7-12, 2015, Montreal, Quebec, Canada, pp. 1693\u20131701,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2015}, {"title": "Long short-term memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural computation, 9(8):1735\u20131780,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1997}, {"title": "Lingusitic analysis of multi-modal recurrent neural networks", "author": ["A. K\u00e1d\u00e1r", "G. Chrupa\u0142a", "A. Alishahi"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2015}, {"title": "Representation of linguistic form and function in recurrent neural networks", "author": ["\u00c1. K\u00e1d\u00e1r", "G. Chrupa\u0142a", "A. Alishahi"], "venue": "arXiv preprint arXiv:1602.08952,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2016}, {"title": "Recurrent continuous translation models", "author": ["N. Kalchbrenner", "P. Blunsom"], "venue": "EMNLP, vol. 3, p. 413,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2013}, {"title": "Interactive optimization for steering machine classification", "author": ["A. Kapoor", "B. Lee", "D. Tan", "E. Horvitz"], "venue": "Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pp. 1343\u20131352. ACM,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2010}, {"title": "Visualizing and understanding recurrent networks", "author": ["A. Karpathy", "J. Johnson", "F.-F. Li"], "venue": "arXiv preprint arXiv:1506.02078,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2015}, {"title": "Interacting with predictions: Visual inspection of black-box machine learning models", "author": ["J. Krause", "A. Perer", "K. Ng"], "venue": "Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems, pp. 5686\u20135697. ACM,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2016}, {"title": "Rnn: Recurrent library for torch", "author": ["N. L\u00e9onard", "S. Waghmare", "Y. Wang"], "venue": "arXiv preprint arXiv:1511.07889,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2015}, {"title": "Visualizing and understanding neural models in nlp", "author": ["J. Li", "X. Chen", "E. Hovy", "D. Jurafsky"], "venue": "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 681\u2013691. Association for Computational Linguistics, San Diego, California, June", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2016}, {"title": "Building a large annotated corpus of english: The penn treebank", "author": ["M.P. Marcus", "M.A. Marcinkiewicz", "B. Santorini"], "venue": "Computational linguistics, 19(2):313\u2013330,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1993}, {"title": "Recurrent neural network based language model", "author": ["T. Mikolov", "M. Karafi\u00e1t", "L. Burget", "J. Cernock\u1ef3", "S. Khudanpur"], "venue": "Interspeech, vol. 2, p. 3,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2010}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["T. Mikolov", "I. Sutskever", "K. Chen", "G.S. Corrado", "J. Dean"], "venue": "Advances in neural information processing systems, pp. 3111\u20133119,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2013}, {"title": "Deep inside convolutional networks: Visualising image classification models and saliency maps", "author": ["K. Simonyan", "A. Vedaldi", "A. Zisserman"], "venue": "arXiv preprint arXiv:1312.6034,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2013}, {"title": "Sequence to sequence learning with neural networks", "author": ["I. Sutskever", "O. Vinyals", "Q.V. Le"], "venue": "Advances in Neural Information Processing Systems, pp. 3104\u20133112,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2014}, {"title": "Introduction to the conll- 2003 shared task: Language-independent named entity recognition", "author": ["E.F. Tjong Kim Sang", "F. De Meulder"], "venue": "In Proceedings of the seventh conference on Natural language learning at HLT-NAACL 2003-Volume", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2003}, {"title": "Opening the black box-data driven visualization of neural networks", "author": ["F.-Y. Tzeng", "K.-L. Ma"], "venue": "VIS 05. IEEE Visualization, 2005., pp. 383\u2013390. IEEE,", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2005}, {"title": "Recurrent neural networks can learn to implement symbolsensitive counting", "author": ["P.R.J. Wiles"], "venue": "Advances in Neural Information Processing Systems 10: Proceedings of the 1997 Conference, vol. 10, p. 87. MIT Press,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 1998}, {"title": "Show, attend and tell: Neural image caption generation with visual attention", "author": ["K. Xu", "J. Ba", "R. Kiros", "K. Cho", "A.C. Courville", "R. Salakhutdinov", "R.S. Zemel", "Y. Bengio"], "venue": "F. R. Bach and D. M. Blei, eds., Proceedings of the 32nd International Conference on Machine Learning, ICML 2015, Lille, France, 6-11 July 2015, vol. 37 of JMLR Proceedings, pp. 2048\u20132057. JMLR.org,", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2015}, {"title": "Recurrent Neural Network Regularization", "author": ["W. Zaremba", "I. Sutskever", "O. Vinyals"], "venue": "arXiv:1409.2329,", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2014}, {"title": "Visualizing and understanding convolutional networks", "author": ["M.D. Zeiler", "R. Fergus"], "venue": "European Conference on Computer Vision, pp. 818\u2013833. Springer,", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 5, "context": "Recurrent neural networks (RNNs) [6] have proven to be a very effective general-purpose model for capturing long-term dependencies in textual applications.", "startOffset": 33, "endOffset": 36}, {"referenceID": 11, "context": "These improved representation have led directly to end applications in machine translation [12, 22], speech recognition [2], music generation [4], and text classification [5], among a variety of other applications.", "startOffset": 91, "endOffset": 99}, {"referenceID": 21, "context": "These improved representation have led directly to end applications in machine translation [12, 22], speech recognition [2], music generation [4], and text classification [5], among a variety of other applications.", "startOffset": 91, "endOffset": 99}, {"referenceID": 1, "context": "These improved representation have led directly to end applications in machine translation [12, 22], speech recognition [2], music generation [4], and text classification [5], among a variety of other applications.", "startOffset": 120, "endOffset": 123}, {"referenceID": 3, "context": "These improved representation have led directly to end applications in machine translation [12, 22], speech recognition [2], music generation [4], and text classification [5], among a variety of other applications.", "startOffset": 142, "endOffset": 145}, {"referenceID": 4, "context": "These improved representation have led directly to end applications in machine translation [12, 22], speech recognition [2], music generation [4], and text classification [5], among a variety of other applications.", "startOffset": 171, "endOffset": 174}, {"referenceID": 19, "context": "This representation can either be a standard fixed mapping, such as word2vec [20], or can be learned with the rest of the model.", "startOffset": 77, "endOffset": 81}, {"referenceID": 18, "context": "In this paper we will focus primarily on the task of RNN language modeling [19, 27], a core task in natural language processing.", "startOffset": 75, "endOffset": 83}, {"referenceID": 26, "context": "In this paper we will focus primarily on the task of RNN language modeling [19, 27], a core task in natural language processing.", "startOffset": 75, "endOffset": 83}, {"referenceID": 8, "context": "Finally, we note that our experiments will mainly focus on long short-term memory networks (LSTM) (hence the name LSTMVIS) [9].", "startOffset": 123, "endOffset": 126}, {"referenceID": 20, "context": "Understanding RNNs through Visualization Our core contribution, visualizing the state dynamics of LSTM in a structured way, is inspired by previous work on convolutional networks for in vision applications [21, 28].", "startOffset": 206, "endOffset": 214}, {"referenceID": 27, "context": "Understanding RNNs through Visualization Our core contribution, visualizing the state dynamics of LSTM in a structured way, is inspired by previous work on convolutional networks for in vision applications [21, 28].", "startOffset": 206, "endOffset": 214}, {"referenceID": 13, "context": "In [14], static visualization techniques are used to help understand LSTM hidden states in language models.", "startOffset": 3, "endOffset": 7}, {"referenceID": 16, "context": "In [17], additional techniques are presented, particularly the use of gradient-based saliency to find important words.", "startOffset": 3, "endOffset": 7}, {"referenceID": 9, "context": "In [10, 11], the authors show that RNNs specifically learn lexical categories and grammatical functions that carry semantic information, partially by modifying the inputs fed to the model.", "startOffset": 3, "endOffset": 11}, {"referenceID": 10, "context": "In [10, 11], the authors show that RNNs specifically learn lexical categories and grammatical functions that carry semantic information, partially by modifying the inputs fed to the model.", "startOffset": 3, "endOffset": 11}, {"referenceID": 2, "context": "In [3] attention is used for soft alignment in machine translation, in [26] attention is used to identify important aspects of an image for captioning, and in [8] attention is used to find important aspects of a document for an extraction task.", "startOffset": 3, "endOffset": 6}, {"referenceID": 25, "context": "In [3] attention is used for soft alignment in machine translation, in [26] attention is used to identify important aspects of an image for captioning, and in [8] attention is used to find important aspects of a document for an extraction task.", "startOffset": 71, "endOffset": 75}, {"referenceID": 7, "context": "In [3] attention is used for soft alignment in machine translation, in [26] attention is used to identify important aspects of an image for captioning, and in [8] attention is used to find important aspects of a document for an extraction task.", "startOffset": 159, "endOffset": 162}, {"referenceID": 23, "context": "In [24], the authors present a visualization system for feedforward neural networks with the goal of interpretation, and in [13], the authors give a user-interface for tuning the learning itself.", "startOffset": 3, "endOffset": 7}, {"referenceID": 12, "context": "In [24], the authors present a visualization system for feedforward neural networks with the goal of interpretation, and in [13], the authors give a user-interface for tuning the learning itself.", "startOffset": 124, "endOffset": 128}, {"referenceID": 14, "context": "The recent Prospector system [15] provides a general-purpose tool for practitioners to better understand their ML model and its predictions.", "startOffset": 29, "endOffset": 33}, {"referenceID": 0, "context": "There has also been work on user interfaces for constructing models such as TensorBoard [1] and the related playground for convolutional neural models playground.", "startOffset": 88, "endOffset": 91}, {"referenceID": 23, "context": "Our work is most similar in spirit to [24] in that we are mostly concerned with interpreting the hidden states of a particular model, however our specific goals and visual design are significantly different.", "startOffset": 38, "endOffset": 42}, {"referenceID": 13, "context": "This idea generalizes and adds interactivity to the manual approaches developed in [14].", "startOffset": 83, "endOffset": 87}, {"referenceID": 6, "context": "This observation simply confirms earlier observations that has demonstrate simple context-free models in RNNs and LSTMs [7, 25].", "startOffset": 120, "endOffset": 127}, {"referenceID": 24, "context": "This observation simply confirms earlier observations that has demonstrate simple context-free models in RNNs and LSTMs [7, 25].", "startOffset": 120, "endOffset": 127}, {"referenceID": 17, "context": "For this experiment we trained a 2-layer LSTM language model with 650 hidden states on the Penn Treebank [18] following the medium-sized model of [27].", "startOffset": 105, "endOffset": 109}, {"referenceID": 26, "context": "For this experiment we trained a 2-layer LSTM language model with 650 hidden states on the Penn Treebank [18] following the medium-sized model of [27].", "startOffset": 146, "endOffset": 150}, {"referenceID": 22, "context": "We annotated the dataset with the gold-standard phrase chunks provided by the CoNLL 2003 shared task [23] for a subset of the treebank (Sections 15-18).", "startOffset": 101, "endOffset": 105}, {"referenceID": 15, "context": "For our experiments we utilized the Torch framework and the Element RNN library [16].", "startOffset": 80, "endOffset": 84}], "year": 2016, "abstractText": "Recurrent neural networks, and in particular long short-term memory networks (LSTMs), are a remarkably effective tool for sequence modeling that learn a dense black-box hidden representation of their sequential input. Researchers interested in better understanding these models have studied the changes in hidden state representations over time and noticed some interpretable patterns but also significant noise. In this work, we present LSTMVIS a visual analysis tool for recurrent neural networks with a focus on understanding these hidden state dynamics. The tool allows a user to select a hypothesis input range to focus on local state changes, to match these states changes to similar patterns in a large data set, and to align these results with domain specific structural annotations. We further show several use cases of the tool for analyzing specific hidden state properties on data sets containing nesting, phrase structure, and chord progressions, and demonstrate how the tool can be used to isolate patterns for further statistical analysis.", "creator": "LaTeX with hyperref package"}}}