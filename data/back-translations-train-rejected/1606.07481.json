{"id": "1606.07481", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Jun-2016", "title": "CUNI System for WMT16 Automatic Post-Editing and Multimodal Translation Tasks", "abstract": "Neural sequence to sequence learning recently became a very promising paradigm in machine translation, achieving competitive results with statistical phrase-based systems. In this system description paper, we attempt to utilize several recently published methods used for neural sequential learning in order to build systems for WMT 2016 shared tasks of Automatic Post-Editing and Multimodal Machine Translation.", "histories": [["v1", "Thu, 23 Jun 2016 21:23:29 GMT  (2709kb,D)", "http://arxiv.org/abs/1606.07481v1", "Accepted to the First Conference of Machine Translation (WMT16)"]], "COMMENTS": "Accepted to the First Conference of Machine Translation (WMT16)", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["jind\\v{r}ich libovick\\'y", "jind\\v{r}ich helcl", "marek tlust\\'y", "pavel pecina", "ond\\v{r}ej bojar"], "accepted": false, "id": "1606.07481"}, "pdf": {"name": "1606.07481.pdf", "metadata": {"source": "CRF", "title": "CUNI System for WMT16 Automatic Post-Editing and Multimodal Translation Tasks", "authors": ["Jind\u0159ich Libovick\u00fd", "Jind\u0159ich Helcl", "Marek Tlust\u00fd", "Ond\u0159ej Bojar", "Pavel Pecina"], "emails": ["libovicky@ufal.mff.cuni.cz", "helcl@ufal.mff.cuni.cz", "tlusty@ufal.mff.cuni.cz", "bojar@ufal.mff.cuni.cz", "pecina@ufal.mff.cuni.cz"], "sections": [{"heading": "1 Introduction", "text": "Neural sequence models are currently used for a variety of tasks in Natural Language Processing, including machine translation (Sutskever et al., 2014; Bahdanau et al., 2014), text summary (Rush et al., 2015), natural language generation (Wen et al., 2015), and others. This has been made possible by the ability of recursive neural networks to model temporal structures in data, including dependencies in the case of gated networks (Hochreiter and Schmidhuber, 1997; Cho et al., 2014).The ability of deep learning models to learn dense representation of input in the form of a real vector has recently enabled researchers to combine machine vision and natural language processing in tasks that were considered extremely difficult just a few years ago. Distributed representations of words, sentences, and images can be understood as a kind of common data type for language and images within the models."}, {"heading": "2 Model Description", "text": "We use the neural translation model with attention (Bahdanau et al., 2014) and expand it with multiple encoders, see Figure 1 for an illustration. Each input set enters the system simultaneously, because it is a bidirectional RNN implementation for the i-th representation Xi = (x1i,.) (1), where the states are hji, are the linkages of outputs of the forward and backward networks after editing the j-th tokens in the respective order. The initial state of the decoder is calculated as a weighted combination of encoder encoders. The decoder is an RNN, which embedding the previously produced word as an input together with the hidden state of the previous attention."}, {"heading": "3 Automatic Post-Editing", "text": "The task of automatic post-processing (APE) is aimed at improving the quality of a machine translation system treated as a black box. An APE system input consists of two sentences - the original input sentence in the source language and the translation generated by the machine translation (MT) system. This scheme allows the use of any MT system without any prior knowledge of the system itself. The aim of this task is to make automatic corrections to the translated sentences and to generate a better translation (using the source sentence as an additional source of information).For the APE task, the organisers provided tokenised data from the IT sector (Turchi et al., 2016).The training data consists of 12,000 triplets of the source sentence, its automatic translation and a reference sentence. The reference sentences are manually post-edited automatic translations. A further 1,000 sentences have been provided for validation, and another 2,000 sentences for manual final evaluation."}, {"heading": "3.1 Related Work", "text": "In the previous year's competition (Bojar et al., 2015), most systems were based on phrase-based Statistical Machine Translation (SMT) in a monolingual environment (Simard et al., 2007). There were also several rule-based post-processing systems that benefited from the fact that errors introduced by statistical and rule-based systems are of a different kind (Rosa, 2014; Mohaghegh et al., 2013). Although the use of neural sequential models is very simple in this case to our knowledge, there were no experiments with RNNs for this task."}, {"heading": "3.2 Experiments & Results", "text": "The input sentence is fed into our system in the form of multiple input sequences, without explicitly saying which sentence is the source sentence and which is the MT output. It is up to the network to discover its best use in creating the (single) target sequence. Initial experiments showed that the network struggles to learn that one of the source sequences is almost correct (even if it shares the vocabulary and word embedding with the expected target sequence), instead the network seemed to learn to paraphrase the input. To focus the network more on editing the source sentence rather than preserving the meaning of the sentences, we presented the target sentence as a minimal sequence of editing operations necessary to turn the machine-translated sentence into reference post-processing. We expanded the vocabulary by adding two special tokens that retain and delete the source sentence, and then defined the reference as a sequence of entertaining, deleting, and placement operations themselves."}, {"heading": "4 Multimodal Translation", "text": "The aim of the multimodal translation task is to generate a caption in a target language (German), taking into account the image itself and one or more captions in the source language (English). Recent experiments by Elliott et al. (2015) showed that incorporating the information from the images can help to clearly determine the captions in the source language. Participants were provided with the Multi30k dataset (Elliott et al., 2016), which represents an extension of the Flickr30k dataset (Plummer et al., 2015). In the original dataset, 31,014 images were taken from the collections of the users of the image hosting service Flickr. Each of the images received five independent captions in English. For the Multi30k dataset, one of the English captions for each image was translated into German and five additional independent German captions were provided. The data is divided into a training set of 29,000 images, a validation test of 1,014 images and a 1,000 captions."}, {"heading": "4.1 Related Work", "text": "Although the images in ImageNet (Deng et al., 2009; Russakovsky et al., 2015) always contain a single object to be classified, the networks manage to learn a representation that can be used in many other cases, including captions that normally involve multiple objects in the image and also have to describe complex actions and spatial and temporal relationships within the image. Before CNN models, image classification was based on finding some visual primitives in the image and automatically transcribing estimated relationships between primitives. Soon after, Kiros et al. (2014) showed that the CNN features could be used in a neural language model, Vinyals et al. (2015) developed a model that uses an RNN decoder known from neuronal MT to sequence image features instead of a generational set."}, {"heading": "4.2 Phrase-Based System", "text": "For the translation task, we have trained Moses SMT (Koehn et al., 2007) with additional language models based on coarse bitoken classes. We follow the approach of Stewart et al. (2014): Based on the word alignment, each target word is linked to its aligned source word to form a bitoken (e.g. \"cat-cat\"). For unaligned target words, we create a bitoken with NULL as source word (e.g. \"becomes-NULL\"). Unaligned source words are omitted. For more than one toone alignment, we combine all aligned word pairs into one bitoken (e.g. \"hat-had + had-had-had-had-had-had\"). These word levels are then divided into coarse classes (Brown et al., 1992) and a standardized n n-gram language model is trained on these classes."}, {"heading": "4.3 Neural System", "text": "For the multimodal translation task, we combine the RNN encoders with image functions. The image functions are extracted from the 4096-dimensional penultimate layer (fc7) of the VGG-16 Imagenet network (Simonyan and Zisserman, 2014) before applying non-linearity. We determine the weights of the Convolutionary Network during the training. We do not use the attention via the image functions, so the image information is only fed into the network via the initial state. We also try a system combination and add an encoder for the phrase-based output. The SMT encoder splits the vocabulary and word embedding with the decoder. For the combination with the SMT output, we experimented with the CopyNet architecture (Gu et al., 2016) and with the coding of the sequence the sequence the same as with the APE task (see section 3.2), as we will only combine each of these five translation systems, which will have no effect on the simple sentence."}, {"heading": "4.4 Results", "text": "The results of both tasks are shown in Table 2. Our system has improved significantly since the submission of the competition, so we report on the performance of both the current system and the systems submitted. Examples of system output can be found in Figure 3.The best performance was achieved by the neural system, which combined all available inputs for both multimodal translation and translingual subtitling. Although using the image as the only source of information led to poor results, adding the image information helped to improve performance in both tasks. This supports the hypothesis that knowledge of the image can add a significant piece of information to the translation of a caption. The translingual subtitling system tended to generate very short descriptions, which were usually true statements about the images, but the sentences were often too general or lacking important information. We also had to shorten the vocabulary, whereby the vocabulary highlighting the vocabulary for both of the system expressions was weighted to the different language used in the translation output."}, {"heading": "5 Conclusion", "text": "We have shown that neural sequential models can be successfully applied to the APE task. We have also shown that information from the image can greatly help in creating a translation of a caption. However, with the limited amount of data provided, the neural system provided a performance comparable to a very well-tuned SMT system. There is still much room for improvement in performance through model ensembles or recently introduced neural sequence learning techniques. A comprehensive test of hyperparameters could also be helpful."}, {"heading": "Acknowledgment", "text": "We would like to thank Toma's Musil, Milan Straka and Ondr ej Dus ek for discussing the problem with us and for countless tips they gave us during our work. This work was funded by the European Union's Horizon 2020 research and innovation programme under funding agreement No. 645 452 (QT21) and No. 644 753 (KConnect) and the Czech Science Foundation (funding agreement No. P103 / 12 / G084). Computer resources were provided by CESNET LM2015042 under the \"Projects of major research, development and innovation infrastructures\" programme."}], "references": [{"title": "VQA: Visual question answering", "author": ["Aishwarya Agrawal", "Jiasen Lu", "Margaret Mitchell", "Dhruv Batra", "C. Lawrence Zitnick", "Devi Parikh"], "venue": "In The IEEE International Conference on Computer Vision", "citeRegEx": "Antol et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Antol et al\\.", "year": 2015}, {"title": "Neural machine translation by jointly learning to align and translate", "author": ["Kyunghyun Cho", "Yoshua Bengio"], "venue": null, "citeRegEx": "Bahdanau et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2014}, {"title": "Scheduled sampling for sequence prediction with recurrent neural networks", "author": ["Bengio et al.2015] Samy Bengio", "Oriol Vinyals", "Navdeep Jaitly", "Noam M. Shazeer"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Bengio et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 2015}, {"title": "Class-based n-gram models of natural language", "author": ["Brown et al.1992] Peter F. Brown", "Peter V. de Souza", "Robert L. Mercer", "Vincent J. Della Pietra", "Jenifer C. Lai"], "venue": "Computational Linguistics,", "citeRegEx": "Brown et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Brown et al\\.", "year": 1992}, {"title": "On the properties of neural machine translation: Encoder\u2013decoder approaches", "author": ["Cho et al.2014] Kyunghyun Cho", "Bart van Merrienboer", "Dzmitry Bahdanau", "Yoshua Bengio"], "venue": "In Proceedings of SSST-8,", "citeRegEx": "Cho et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Cho et al\\.", "year": 2014}, {"title": "Imagenet: A large-scale hierarchical image database", "author": ["Deng et al.2009] Jia Deng", "Wei Dong", "Richard Socher", "Li-Jia Li", "Kai Li", "Li Fei-Fei"], "venue": "In Computer Vision and Pattern Recognition,", "citeRegEx": "Deng et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Deng et al\\.", "year": 2009}, {"title": "Meteor 1.3: Automatic metric for reliable optimization and evaluation of machine translation systems", "author": ["Denkowski", "Lavie2011] Michael Denkowski", "Alon Lavie"], "venue": "In Proceedings of the Sixth Workshop on Statistical Machine Translation,", "citeRegEx": "Denkowski et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Denkowski et al\\.", "year": 2011}, {"title": "Multi-language image description with neural sequence models. CoRR, abs/1510.04709", "author": ["Stella Frank", "Eva Hasler"], "venue": null, "citeRegEx": "Elliott et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Elliott et al\\.", "year": 2015}, {"title": "Multi30K: Multilingual EnglishGerman Image Descriptions", "author": ["Elliott et al.2016] D. Elliott", "S. Frank", "K. Sima\u2019an", "L. Specia"], "venue": null, "citeRegEx": "Elliott et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Elliott et al\\.", "year": 2016}, {"title": "Incorporating copying mechanism in sequence-to-sequence learning. CoRR, abs/1603.06393", "author": ["Gu et al.2016] Jiatao Gu", "Zhengdong Lu", "Hang Li", "Victor O.K. Li"], "venue": null, "citeRegEx": "Gu et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Gu et al\\.", "year": 2016}, {"title": "Long short-term memory", "author": ["Hochreiter", "Schmidhuber1997] Sepp Hochreiter", "J\u00fcrgen Schmidhuber"], "venue": "Neural computation,", "citeRegEx": "Hochreiter et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter et al\\.", "year": 1997}, {"title": "Multi- and cross-modal semantics beyond vision: Grounding in auditory perception", "author": ["Kiela", "Clark2015] Douwe Kiela", "Stephen Clark"], "venue": "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Kiela et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kiela et al\\.", "year": 2015}, {"title": "Adam: A method for stochastic optimization. CoRR, abs/1412.6980", "author": ["Kingma", "Ba2014] Diederik P. Kingma", "Jimmy Ba"], "venue": null, "citeRegEx": "Kingma et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kingma et al\\.", "year": 2014}, {"title": "Multimodal neural language models", "author": ["Kiros et al.2014] Ryan Kiros", "Ruslan Salakhutdinov", "Rich Zemel"], "venue": "In Proceedings of the 31st International Conference on Machine Learning", "citeRegEx": "Kiros et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kiros et al\\.", "year": 2014}, {"title": "Moses: Open source toolkit for statistical machine translation", "author": ["Herbst"], "venue": "In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions,", "citeRegEx": "2007.,? \\Q2007\\E", "shortCiteRegEx": "2007.", "year": 2007}, {"title": "A three-layer architecture for automatic post editing system using rule-based paradigm", "author": ["Abdolhossein Sarrafzadeh", "Mehdi Mohammadi"], "venue": "In Proceedings of the 4th Workshop on South and South-", "citeRegEx": "Mohaghegh et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mohaghegh et al\\.", "year": 2013}, {"title": "BLEU: a method for automatic evaluation of machine translation", "author": ["Salim Roukos", "Todd Ward", "Wei-Jing Zhu"], "venue": "In Proceedings of the 40th annual meeting on association for computational linguistics,", "citeRegEx": "Papineni et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Papineni et al\\.", "year": 2002}, {"title": "Flickr30k entities: Collecting region-to-phrase correspondences for richer image-to-sentence models", "author": ["Liwei Wang", "Chris M Cervantes", "Juan C Caicedo", "Julia Hockenmaier", "Svetlana Lazebnik"], "venue": null, "citeRegEx": "Plummer et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Plummer et al\\.", "year": 2015}, {"title": "Sequence level training with recurrent neural networks. CoRR, abs/1511.06732", "author": ["Sumit Chopra", "Michael Auli", "Wojciech Zaremba"], "venue": null, "citeRegEx": "Ranzato et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ranzato et al\\.", "year": 2015}, {"title": "Depfix, a tool for automatic rule-based post-editing of SMT", "author": ["Rudolf Rosa"], "venue": "The Prague Bulletin of Mathematical Linguistics,", "citeRegEx": "Rosa.,? \\Q2014\\E", "shortCiteRegEx": "Rosa.", "year": 2014}, {"title": "A neural attention model for abstractive sentence summarization", "author": ["Sumit Chopra", "Jason Weston"], "venue": "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Rush et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Rush et al\\.", "year": 2015}, {"title": "Imagenet large scale visual recognition challenge", "author": ["Khosla", "Michael Bernstein"], "venue": "International Journal of Computer Vision,", "citeRegEx": "Khosla and Bernstein,? \\Q2015\\E", "shortCiteRegEx": "Khosla and Bernstein", "year": 2015}, {"title": "Rulebased translation with statistical phrase-based postediting", "author": ["Simard et al.2007] Michel Simard", "Nicola Ueffing", "Pierre Isabelle", "Roland Kuhn"], "venue": "In Proceedings of the Second Workshop on Statistical Machine Translation,", "citeRegEx": "Simard et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Simard et al\\.", "year": 2007}, {"title": "Very deep convolutional networks for large-scale image recognition. CoRR, abs/1409.1556", "author": ["Simonyan", "Zisserman2014] Karen Simonyan", "Andrew Zisserman"], "venue": null, "citeRegEx": "Simonyan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Simonyan et al\\.", "year": 2014}, {"title": "A Study of Translation Edit Rate with Targeted Human Annotation", "author": ["Bonnie Dorr", "Richard Schwartz", "Linnea Micciulla", "John Makhoul"], "venue": "In Proceedings AMTA,", "citeRegEx": "Snover et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Snover et al\\.", "year": 2006}, {"title": "Coarse split and lump bilingual language models for richer source information in SMT", "author": ["Roland Kuhn", "Eric Joanis", "George Foster"], "venue": "In Proceedings of the Eleventh Conference of the Association for Machine", "citeRegEx": "Stewart et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Stewart et al\\.", "year": 2014}, {"title": "Sequence to sequence learning with neural networks", "author": ["Oriol Vinyals", "Quoc V Le"], "venue": null, "citeRegEx": "Sutskever et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "Coverage-based neural machine translation. CoRR, abs/1601.04811", "author": ["Tu et al.2016] Zhaopeng Tu", "Zhengdong Lu", "Yang Liu", "Xiaohua Liu", "Hang Li"], "venue": null, "citeRegEx": "Tu et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Tu et al\\.", "year": 2016}, {"title": "WMT16 APE shared task data. LINDAT/CLARIN digital library at Institute of Formal and Applied Linguistics, Charles University in Prague", "author": ["Turchi et al.2016] Marco Turchi", "Rajen Chatterjee", "Matteo Negri"], "venue": null, "citeRegEx": "Turchi et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Turchi et al\\.", "year": 2016}, {"title": "Show and tell: A neural image caption generator", "author": ["Alexander Toshev", "Samy Bengio", "Dumitru Erhan"], "venue": "In IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "Vinyals et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Vinyals et al\\.", "year": 2015}, {"title": "Semantically conditioned lstm-based natural language generation for spoken dialogue systems", "author": ["Wen et al.2015] Tsung-Hsien Wen", "Milica Gasic", "Nikola Mrk\u0161i\u0107", "Pei-Hao Su", "David Vandyke", "Steve Young"], "venue": null, "citeRegEx": "Wen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wen et al\\.", "year": 2015}, {"title": "Show, attend and tell: Neural image caption generation with visual attention", "author": ["Xu et al.2015] Kelvin Xu", "Jimmy Ba", "Ryan Kiros", "Kyunghyun Cho", "Aaron C. Courville", "Ruslan Salakhutdinov", "Richard S. Zemel", "Yoshua Bengio"], "venue": null, "citeRegEx": "Xu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Xu et al\\.", "year": 2015}, {"title": "Recurrent neural network regularization. CoRR, abs/1409.2329", "author": ["Ilya Sutskever", "Oriol Vinyals"], "venue": null, "citeRegEx": "Zaremba et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zaremba et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 26, "context": "used for variety of tasks in Natural Language Processing including machine translation (Sutskever et al., 2014; Bahdanau et al., 2014), text summarization (Rush et al.", "startOffset": 87, "endOffset": 134}, {"referenceID": 1, "context": "used for variety of tasks in Natural Language Processing including machine translation (Sutskever et al., 2014; Bahdanau et al., 2014), text summarization (Rush et al.", "startOffset": 87, "endOffset": 134}, {"referenceID": 20, "context": ", 2014), text summarization (Rush et al., 2015), natural language generation (Wen et al.", "startOffset": 28, "endOffset": 47}, {"referenceID": 30, "context": ", 2015), natural language generation (Wen et al., 2015), and others.", "startOffset": 37, "endOffset": 55}, {"referenceID": 4, "context": "This was enabled by the capability of recurrent neural networks to model temporal structure in data, including the long-distance dependencies in case of gated networks (Hochreiter and Schmidhuber, 1997; Cho et al., 2014).", "startOffset": 168, "endOffset": 220}, {"referenceID": 29, "context": "This is then used in tasks like automatic image captioning (Vinyals et al., 2015; Xu et al., 2015), visual question answering (Antol et al.", "startOffset": 59, "endOffset": 98}, {"referenceID": 31, "context": "This is then used in tasks like automatic image captioning (Vinyals et al., 2015; Xu et al., 2015), visual question answering (Antol et al.", "startOffset": 59, "endOffset": 98}, {"referenceID": 0, "context": ", 2015), visual question answering (Antol et al., 2015) or in attempts to ground lexical semantics in vision (Kiela and Clark, 2015).", "startOffset": 35, "endOffset": 55}, {"referenceID": 1, "context": "We use the neural translation model with attention (Bahdanau et al., 2014) and extend it to include", "startOffset": 51, "endOffset": 74}, {"referenceID": 1, "context": "The attention is computed over each encoder separately as described by Bahdanau et al. (2014). The attention vector ai of the i-th encoder in the ar X iv :1 60 6.", "startOffset": 71, "endOffset": 94}, {"referenceID": 29, "context": "For image captioning, we do not use the attention model because of its high computational demands and rely on the basic model by Vinyals et al. (2015) instead.", "startOffset": 129, "endOffset": 151}, {"referenceID": 4, "context": "Units (Cho et al., 2014) and apply the dropout of 0.", "startOffset": 6, "endOffset": 24}, {"referenceID": 32, "context": "5 on the inputs and the outputs of the recurrent layers (Zaremba et al., 2014) and L2 regularization of 10\u22128 on all parameters.", "startOffset": 56, "endOffset": 78}, {"referenceID": 2, "context": "We experimented with recently published improvements of neural sequence to sequence learning: scheduled sampling (Bengio et al., 2015), noisy activation function (G\u00fcl\u00e7ehre et al.", "startOffset": 113, "endOffset": 134}, {"referenceID": 27, "context": ", 2016), linguistic coverage model (Tu et al., 2016).", "startOffset": 35, "endOffset": 52}, {"referenceID": 28, "context": "For the APE task, the organizers provided tokenized data from the IT domain (Turchi et al., 2016).", "startOffset": 76, "endOffset": 97}, {"referenceID": 24, "context": "The performance of the systems is measured using Translation Error Rate (Snover et al., 2006) from the manually post-edited sentences.", "startOffset": 72, "endOffset": 93}, {"referenceID": 22, "context": ", 2015), most of the systems were based on the phrase-base statistical machine translation (SMT) in a monolingual setting (Simard et al., 2007).", "startOffset": 122, "endOffset": 143}, {"referenceID": 19, "context": "There were also several rule-based post-editing systems benefiting from the fact that errors introduced by statistical and rule-based systems are of a different type (Rosa, 2014; Mohaghegh et al., 2013).", "startOffset": 166, "endOffset": 202}, {"referenceID": 15, "context": "There were also several rule-based post-editing systems benefiting from the fact that errors introduced by statistical and rule-based systems are of a different type (Rosa, 2014; Mohaghegh et al., 2013).", "startOffset": 166, "endOffset": 202}, {"referenceID": 7, "context": "Recent experiments of Elliott et al. (2015)", "startOffset": 22, "endOffset": 44}, {"referenceID": 8, "context": "Multi30k dataset (Elliott et al., 2016) which is an extension of the Flickr30k dataset (Plummer et al.", "startOffset": 17, "endOffset": 39}, {"referenceID": 17, "context": ", 2016) which is an extension of the Flickr30k dataset (Plummer et al., 2015).", "startOffset": 55, "endOffset": 77}, {"referenceID": 16, "context": "Both tasks are evaluated using the BLEU (Papineni et al., 2002) score and METEOR score (Denkowski and Lavie, 2011).", "startOffset": 40, "endOffset": 63}, {"referenceID": 5, "context": "ImageNet (Deng et al., 2009; Russakovsky et al., 2015) always contain a single object to classify, the networks manage to learn a representation that is usable in many other cases including image captioning which usually concerns multiple objects in the image and also needs to describe complex ac-", "startOffset": 9, "endOffset": 54}, {"referenceID": 1, "context": "(2015) later even improved the model by adapting the soft alignment model (Bahdanau et al., 2014) nowadays known as the attention model.", "startOffset": 74, "endOffset": 97}, {"referenceID": 2, "context": "Since then, these models have become a benchmark for works trying to improve neural sequence to sequence models (Bengio et al., 2015; G\u00fcl\u00e7ehre et al., 2016; Ranzato et al., 2015).", "startOffset": 112, "endOffset": 178}, {"referenceID": 18, "context": "Since then, these models have become a benchmark for works trying to improve neural sequence to sequence models (Bengio et al., 2015; G\u00fcl\u00e7ehre et al., 2016; Ranzato et al., 2015).", "startOffset": 112, "endOffset": 178}, {"referenceID": 11, "context": "ter Kiros et al. (2014) showed that the CNN features could be used in a neural language model, Vinyals et al.", "startOffset": 4, "endOffset": 24}, {"referenceID": 11, "context": "ter Kiros et al. (2014) showed that the CNN features could be used in a neural language model, Vinyals et al. (2015) developed a model that used an RNN decoder known from neural MT for generating captions from the image features instead of the vector encoding the source sentence.", "startOffset": 4, "endOffset": 117}, {"referenceID": 11, "context": "ter Kiros et al. (2014) showed that the CNN features could be used in a neural language model, Vinyals et al. (2015) developed a model that used an RNN decoder known from neural MT for generating captions from the image features instead of the vector encoding the source sentence. Xu et al. (2015) later even improved the model by adapting the soft alignment model (Bahdanau et al.", "startOffset": 4, "endOffset": 298}, {"referenceID": 14, "context": ", 2007) with additional language models based on coarse bitoken classes. We follow the approach of Stewart et al. (2014): Based on the word alignment, each target word", "startOffset": 2, "endOffset": 121}, {"referenceID": 3, "context": "word-level bitokens are afterwards clustered into coarse classes (Brown et al., 1992) and a standard n-gram language model is trained on these classes.", "startOffset": 65, "endOffset": 85}, {"referenceID": 3, "context": "word-level bitokens are afterwards clustered into coarse classes (Brown et al., 1992) and a standard n-gram language model is trained on these classes. Following the notation of Stewart et al. (2014), \u201c400bi\u201d indicates a LM trained on 400 bitoken classes, \u201c200bi\u201d stands for 200 bitoken classes, etc.", "startOffset": 66, "endOffset": 200}, {"referenceID": 9, "context": "For the combination with SMT output, we experimented with the CopyNet architecture (Gu et al., 2016) and with encoding the sequence the way as in the APE task (see Section 3.", "startOffset": 83, "endOffset": 100}, {"referenceID": 9, "context": "In case of system combination, more careful exploration of explicit copy mechanism as CopyNet (Gu et al., 2016) may be useful.", "startOffset": 94, "endOffset": 111}], "year": 2016, "abstractText": "Neural sequence to sequence learning recently became a very promising paradigm in machine translation, achieving competitive results with statistical phrase-based systems. In this system description paper, we attempt to utilize several recently published methods used for neural sequential learning in order to build systems for WMT 2016 shared tasks of Automatic Post-Editing and Multimodal Machine Translation.", "creator": "LaTeX with hyperref package"}}}