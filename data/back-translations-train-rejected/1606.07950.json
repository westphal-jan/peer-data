{"id": "1606.07950", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Jun-2016", "title": "Word sense disambiguation via bipartite representation of complex networks", "abstract": "In recent years, concepts and methods of complex networks have been employed to tackle the word sense disambiguation (WSD) task by representing words as nodes, which are connected if they are semantically similar. Despite the increasingly number of studies carried out with such models, most of them use networks just to represent the data, while the pattern recognition performed on the attribute space is performed using traditional learning techniques. In other words, the structural relationship between words have not been explicitly used in the pattern recognition process. In addition, only a few investigations have probed the suitability of representations based on bipartite networks and graphs (bigraphs) for the problem, as many approaches consider all possible links between words. In this context, we assess the relevance of a bipartite network model representing both feature words (i.e. the words characterizing the context) and target (ambiguous) words to solve ambiguities in written texts. Here, we focus on the semantical relationships between these two type of words, disregarding the relationships between feature words. In special, the proposed method not only serves to represent texts as graphs, but also constructs a structure on which the discrimination of senses is accomplished. Our results revealed that the proposed learning algorithm in such bipartite networks provides excellent results mostly when topical features are employed to characterize the context. Surprisingly, our method even outperformed the support vector machine algorithm in particular cases, with the advantage of being robust even if a small training dataset is available. Taken together, the results obtained here show that the proposed representation/classification method might be useful to improve the semantical characterization of written texts.", "histories": [["v1", "Sat, 25 Jun 2016 19:08:19 GMT  (1176kb,D)", "http://arxiv.org/abs/1606.07950v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["edilson a correa jr", "alneu de", "rade lopes", "diego r amancio"], "accepted": false, "id": "1606.07950"}, "pdf": {"name": "1606.07950.pdf", "metadata": {"source": "CRF", "title": "Word sense disambiguation via bipartite representation of complex networks", "authors": ["Edilson A. Correa", "Diego R. Amancio"], "emails": [], "sections": [{"heading": null, "text": "The purpose of the word sense disambiguation (WSD) is to identify the meaning of words in a given context for specific words that convey multiple meanings, a task that plays a prominent role in a variety of real-world applications, such as machine translation, word processing, and information gathering. Lately, concepts and methods of complex networks have been used to address this task by depicting words as nodes that are interconnected when they are semantically similar. Despite the increasing number of studies that are being conducted with such models, most of them use networks just to represent the data, while pattern recognition in the attribute space is performed using traditional learning techniques. In other words, the structural relationship between words has not been explicitly used in the pattern-recognition process. Moreover, few studies have examined the suitability of representations based on bipartite networks and graphs (bigraphs) that are performed for the problem, as many approaches consider all possible linkages between these two words to represent the two contexts."}, {"heading": "1. Introduction", "text": "The wording of the Declaration (WSD) has been extensively studied in the field of Natural Language Processing (NLP), which is defined as the ability to grasp human knowledge in a particular context. [3] The significance of the WSD task derives from a variety of real-world examples of use. [4] Word processing is based on the complexity involved in the representation of computer systems. [5] The importance of the WSD task derives from the fact that it is applied in a variety of real-world applications."}, {"heading": "2. Related works", "text": "The latter approach is not common in practice, since the creation of knowledge records requires time-consuming efforts, since the change of knowledge in two systems is required. In view of a document that is presented as a sequence of words, this is a complex system of words. The goal is to find a figure A of words to senses, so that A (wi), where SD (wi), where SD (wi) is used, is a set of senses that are encoded for the word wi in a dictionary D, and A (wi) is the subset of appropriate sensory perceptions of wi-T. One of the most popular approaches to addressing the WSD problem is the use of machine learning, as this task can be regarded as an overarching classification problem, where senses represent the classes [2]. The attributes used in learning methods are usually all the informative evidence derived from the topical context of the latter, and the knowledge source is not common in practice."}, {"heading": "3. Overview of the technique", "text": "This section presents approaches to the representation of local and topic-specific characteristics of target words in a bipartite heterogeneous network and introduces the algorithm Inductive Model Based onBipartite Heterogeneous Network (IMBHN), which is responsible for triggering a classification model from the structure of a bipartite network [30, 31]."}, {"heading": "3.1. Modelling word context as a bipartite heterogeneous network", "text": "Traditionally, the context of ambiguous words is represented in a vector space model, so that each target word is characterized by a vector. In this representation, each dimension of the vector corresponds to a specific characteristic. Alternatively, we can represent the data using a bipartite heterogeneous network. In this model, we focused on the analysis of local and local attributes, while the first level only includes characteristic words, the second only stores target words. As mentioned in Section 2, there are currently a variety of characteristics to tackle the WSD problem. In this essay, we focus on the analysis of local and local attributes, as such data is readily available on each corpus (or derived from it). Note that in this case we did not use knowledge data.In the proposed strategy, which is based on topical characteristics, we create a series of topical words T. Then each unique characteristic becomes a unique characteristic."}, {"heading": "3.2. Algorithm description", "text": "The IMBHN algorithm can be used in the context of any text classification task. If the goal is to classify different documents into a certain number of classes, the bifurcated network can be constructed so that nodes represent both terms and documents. In this general scenario, such a representation is used to calculate the relevance of specific terms for different document classes. Similarly, in this study we will calculate the relevance of local / current characteristics for each target word. Then, this relevance is used to calculate the proposed word senses.The proposed algorithm for finding meaning is based on a network structure with two different layers: (i) a layer representing possible characteristics (i.e. local or topical characteristics) and (ii) a layer covering all occurrences of the target word. The two layers are illustrated in Figure 1."}, {"heading": "4. Experimental Evaluation", "text": "In this section, the corpus used in the experiments is introduced and the experimental configuration of the parameters is explained. Finally, a robustness analysis is presented to investigate how the performance of the IMBHN varies with the size of the training set."}, {"heading": "4.1. Corpus", "text": "To evaluate the proposed algorithm, we used the SENSEVAL-2 [32] corpus, which includes documents from various sources, including the British National Corpus and the Penntreebank section of the Wall Street Journal. The SENSEVAL-2 corpus includes 15,225 short texts that represent the context around ambiguous words. Each word is marked with its part of the language, and the manually annotated senses of four target words are provided. Table 1 shows the number of senses and the number of instances of each word used in our experiments. In the evaluation process, these four words were considered as target words. Specifically, we removed stopwords and punctuation marks to characterize the contexts, as such elements do not convey semantic meaning and therefore do not improve the characterization of contexts."}, {"heading": "4.2. Experiment Configuration", "text": "The results of the IMBHN algorithm were compared with four inductive classification algorithms: Naive Bayes (NB) [33], J48 (C4.5 algorithm) [34], IBk (k -Nearest Neighbors) [35] and Support Vector Machine via sequential minimum optimization (SMO) [36]. The parameters of these algorithms were selected using the methodology described in [37]. For the IMBHN algorithm, we used error correction rates \u03b7 = {0.01, 0.05, 0.10, 0.50}. The number of topical features used in the experiments was | T | = {100, 200, 300}. Finally, the window size for the local features was given as \u03c9 = {1, 2}. The evaluation process was carried out by 10-fold cross-validation [38]."}, {"heading": "4.3. Results and discussion", "text": "In order to analyze the behavior and accuracy of the proposed algorithms, we first examined the WSD problem, which characterizes the context of the aforementioned datasets, and the results are evaluated over the following three years: \"It's about the way in which the results of the analysis are presented in each country.\" (\"It's about the way in which the results are presented in each country.\") \"It's about the way in which the results are presented in each country.\" (\"It's about the way in which the results are presented in each country.\" (\"It's about the way in which the results are presented in each country.\") \"(\" It's about the way in which the results in each country are presented. \")\""}, {"heading": "5. Conclusion", "text": "While methods based on deep paradigms can work well in very specific areas, statistical methods based mainly on machine learning have proven useful in performing the task of decoding the meaning of words in more general contexts. In this article, we have developed a statistical model for both representing contexts and recognizing patterns in written texts; the model depends on a two-sided network in which layers represent characteristic words and target words, i.e. words that convey two or more potential senses. We have shown that the proposed model represents significant performance, especially when contextual features are modeled via the extraction of local words to represent semantic contexts. We have also observed that our method generally works well, even when a relatively small amount of data is available for the training process. This is an important property, as it takes both time and effort to construct a corpus of words that are clearly described as biological."}, {"heading": "Acknowledgements", "text": "E.A.C. Jr. and D.R.A. acknowledge financial support from Google (Google Research Awards in Latin America grant). D.R.A. thanks the Sao Paulo Research Foundation (FAPESP) for its support (grant no. 2014 / 20830-0). A.A.L. thanks FAPESP (grant no. 2011 / 22749-8 and 2015 / 14228-9) and CNPq (Brazil) (grant no. 302645 / 2015-2)."}], "references": [{"title": "Foundations of Statistical Natural Language Processing", "author": ["C.D. Manning", "H. Sch\u00fctze"], "venue": "MIT Press, Cambridge, MA, USA", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1999}, {"title": "Word sense disambiguation: A survey", "author": ["R. Navigli"], "venue": "ACM Computing Surveys (CSUR) 41 ", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2009}, {"title": "Translation", "author": ["W. Weaver"], "venue": "Machine translation of languages 14 ", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1955}, {"title": "Commercial applications of natural language processing", "author": ["K.W. Church", "L.F. Rau"], "venue": "Communications of the ACM 38 ", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1995}, {"title": "Semeval-2007 task 08: Metonymy resolution at semeval-2007", "author": ["K. Markert", "M. Nissim"], "venue": "in: Proceedings of the 4th International Workshop on Semantic Evaluations, Association for Computational Linguistics,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2007}, {"title": "Understanding the role of conceptual relations in word sense disambiguation", "author": ["D. Fernandez-Amoros", "R. Heradio"], "venue": "Expert Systems with Applications 38 ", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2011}, {"title": "Discovering filter keywords for company name disambiguation in twitter", "author": ["D. Spina", "J. Gonzalo", "E. Amig\u00f3"], "venue": "Expert Systems with Applications 40 ", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2013}, {"title": "Identity rank: Named entity disambiguation in the news domain", "author": ["N. Fernandez", "J.A. Fisteus", "L. Sanchez", "G. Lopez"], "venue": "Expert Systems with Applications 39 ", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2012}, {"title": "O", "author": ["T. Berners-Lee", "J. Hendler"], "venue": "Lassila, et al., The semantic web, Scientific american 284 ", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2001}, {"title": "Particle competition and cooperation in networks for semi-supervised learning", "author": ["F. Breve", "L. Zhao", "M. Quiles", "W. Pedrycz", "J. Liu"], "venue": "IEEE Transactions on Knowledge and Data Engineering 24 ", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2012}, {"title": "Chaotic encryption method based on life-like cellular automata", "author": ["J. Machicao", "A.G. Marco", "O.M. Bruno"], "venue": "Expert Systems with Applications 39 ", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2012}, {"title": "L", "author": ["D.R. Amancio", "O.N. Oliveira Jr"], "venue": "d. F. Costa, Unveiling the relationship between complex networks metrics and word senses, EPL (Europhysics Letters) 98 ", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2012}, {"title": "Graph-based natural language processing and information retrieval", "author": ["R. Mihalcea", "D. Radev"], "venue": "Cambridge University Press", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2011}, {"title": "Hyperlex: lexical cartography for information retrieval", "author": ["J. V\u00e9ronis"], "venue": "Computer Speech & Language 18 ", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2004}, {"title": "Jr", "author": ["D.R. Amancio", "E.G. Altmann", "D. Rybski", "O.N. Oliveira"], "venue": "L. d. F. Costa, Probing the statistical properties of unknown texts: application to the voynich manuscript, PLoS ONE 8 ", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2013}, {"title": "Authorship attribution through function word adjacency networks", "author": ["S. Segarra", "M. Eisen", "A. Ribeiro"], "venue": "IEEE Transactions on Signal Processing 63 ", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2015}, {"title": "The complexity of chinese syntactic dependency networks", "author": ["H. Liu"], "venue": "Physica A 387 ", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2008}, {"title": "Network properties of written human language", "author": ["A.P. Masucci", "G.J. Rodgers"], "venue": "Phys. Rev. E 74 ", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2006}, {"title": "Word sense disambiguation via high order of learning in complex networks", "author": ["T.C. Silva", "D.R. Amancio"], "venue": "EPL (Europhysics Letters) 98 ", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2012}, {"title": "Discriminating word senses with tourist walks in complex networks", "author": ["T.C. Silva", "D.R. Amancio"], "venue": "Eur. Phys. J. B 86 ", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2013}, {"title": "Comparative experiments on disambiguating word senses: An illustration of the role of bias in machine learning", "author": ["R.J. Mooney"], "venue": "arXiv preprint cmp-lg/9612001 ", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1996}, {"title": "J", "author": ["G. Escudero", "L. M\u00e0rquez", "G. Rigau"], "venue": "G. Salgado, On the portability and tuning of supervised word sense disambiguation systems ", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2000}, {"title": "Analyzing natural human language from the point of view of dynamic of a complex network", "author": ["G.A. Wachs-Lopes", "P.S. Rodrigues"], "venue": "Expert Systems with Applications 45 ", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2016}, {"title": "A complex network approach to stylometry", "author": ["D.R. Amancio"], "venue": "PLoS ONE 10 ", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2015}, {"title": "O", "author": ["D.R. Amancio", "S.M. Aluisio"], "venue": "N. Oliveira Jr., L. da F. Costa, Complex networks analysis of language complexity, EPL (Europhysics Letters) 100 ", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2012}, {"title": "A simple model for self-organization of bipartite networks", "author": ["K. Sneppen", "M. Rosvall", "A. Trusina", "P. Minnhagen"], "venue": "EPL (Europhysics Letters) 67 ", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2004}, {"title": "A", "author": ["R.G. Rossi"], "venue": "de Andrade Lopes, T. de Paulo Faleiros, S. O. Rezende, Inductive model generation for text classification using a bipartite heterogeneous network, Journal of Computer Science and Technology 29 ", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2014}, {"title": "An empirical comparison of supervised learning algorithms", "author": ["R. Caruana", "A. Niculescu-Mizil"], "venue": "in: Proceedings of the 23rd International Conference on Machine Learning, ICML \u201906, ACM, New York, NY, USA", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2006}, {"title": "Programs for Machine Learning", "author": ["R. Quinlan"], "venue": null, "citeRegEx": "34", "shortCiteRegEx": "34", "year": 1993}, {"title": "Instance-based learning algorithms", "author": ["D.W. Aha", "D. Kibler", "M.K. Albert"], "venue": "Mach. Learn. 6 ", "citeRegEx": "35", "shortCiteRegEx": null, "year": 1991}, {"title": "Fast training of support vector machines using sequential minimal optimization", "author": ["J. Platt"], "venue": "in: B. Schoelkopf, C. Burges, A. Smola (Eds.), Advances in Kernel Methods - Support Vector Learning, MIT Press", "citeRegEx": "36", "shortCiteRegEx": null, "year": 1998}, {"title": "L", "author": ["D.R. Amancio", "C.H. Comin", "D. Casanova", "G. Travieso", "O.M. Bruno", "F.A. Rodrigues"], "venue": "d. F. Costa, A systematic comparison of supervised classifiers, PLoS ONE 9 ", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2014}, {"title": "A study of cross-validation and bootstrap for accuracy estimation and model selection", "author": ["R. Kohavi"], "venue": "in: Proceedings of the 14th International Joint Conference on Artificial Intelligence, IJCAI\u201995, Morgan Kaufmann Publishers Inc., San Francisco, CA, USA", "citeRegEx": "38", "shortCiteRegEx": null, "year": 1995}, {"title": "Stability of similarity measurements for bipartite networks", "author": ["J.-G. Liu", "L. Hou", "X. Pan", "Q. Guo", "T. Zhou"], "venue": "Scientific Reports 6 ", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2016}, {"title": "Complex systems: features", "author": ["C.H. Comin", "T.K.D. Peron", "F.N. Silva", "D.R. Amancio", "F.A. Rodrigues", "L.F. Costa"], "venue": "similarity and connectivity, arXiv: 1606.05400 ", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2016}, {"title": "Vertex similarity in networks", "author": ["E.A. Leicht", "P. Holme", "M.E.J. Newman"], "venue": "Phys. Rev. E 73 ", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2006}], "referenceMentions": [{"referenceID": 0, "context": "The word sense disambiguation (WSD) task has been widely studied in the field of Natural Language Processing (NLP) [1].", "startOffset": 115, "endOffset": 118}, {"referenceID": 1, "context": "This task is defined as the ability to computationally detect which sense is being conveyed in a particular context [2].", "startOffset": 116, "endOffset": 119}, {"referenceID": 2, "context": "The importance of the WSD task stems from its essential role in a variety of real world applications, such as machine translation [4], word processing [5], information retrieval and extraction [6, 7, 8, 9, 10, 11].", "startOffset": 130, "endOffset": 133}, {"referenceID": 3, "context": "The importance of the WSD task stems from its essential role in a variety of real world applications, such as machine translation [4], word processing [5], information retrieval and extraction [6, 7, 8, 9, 10, 11].", "startOffset": 151, "endOffset": 154}, {"referenceID": 4, "context": "The importance of the WSD task stems from its essential role in a variety of real world applications, such as machine translation [4], word processing [5], information retrieval and extraction [6, 7, 8, 9, 10, 11].", "startOffset": 193, "endOffset": 213}, {"referenceID": 5, "context": "The importance of the WSD task stems from its essential role in a variety of real world applications, such as machine translation [4], word processing [5], information retrieval and extraction [6, 7, 8, 9, 10, 11].", "startOffset": 193, "endOffset": 213}, {"referenceID": 6, "context": "The importance of the WSD task stems from its essential role in a variety of real world applications, such as machine translation [4], word processing [5], information retrieval and extraction [6, 7, 8, 9, 10, 11].", "startOffset": 193, "endOffset": 213}, {"referenceID": 7, "context": "The importance of the WSD task stems from its essential role in a variety of real world applications, such as machine translation [4], word processing [5], information retrieval and extraction [6, 7, 8, 9, 10, 11].", "startOffset": 193, "endOffset": 213}, {"referenceID": 8, "context": "In addition, the resolution of ambiguities plays a pivotal role in the development of the so-called semantic web [12].", "startOffset": 113, "endOffset": 117}, {"referenceID": 1, "context": "Many approaches devised to solve ambiguities in texts employ machine learning methods to automatically extract the best features in specific contexts [2].", "startOffset": 150, "endOffset": 153}, {"referenceID": 0, "context": "Popular representations are vectors of features, trees and graphs of relations between words [1].", "startOffset": 93, "endOffset": 96}, {"referenceID": 9, "context": "Although graphs have been employed in general pattern recognition methods [13, 14] and, particularly in the analysis of the semantical properties of texts in several ways [15, 16, 17, 18, 19, 20, 21], the use of network models in the learning process has been restricted to a few works (see e.", "startOffset": 74, "endOffset": 82}, {"referenceID": 10, "context": "Although graphs have been employed in general pattern recognition methods [13, 14] and, particularly in the analysis of the semantical properties of texts in several ways [15, 16, 17, 18, 19, 20, 21], the use of network models in the learning process has been restricted to a few works (see e.", "startOffset": 74, "endOffset": 82}, {"referenceID": 11, "context": "Although graphs have been employed in general pattern recognition methods [13, 14] and, particularly in the analysis of the semantical properties of texts in several ways [15, 16, 17, 18, 19, 20, 21], the use of network models in the learning process has been restricted to a few works (see e.", "startOffset": 171, "endOffset": 199}, {"referenceID": 12, "context": "Although graphs have been employed in general pattern recognition methods [13, 14] and, particularly in the analysis of the semantical properties of texts in several ways [15, 16, 17, 18, 19, 20, 21], the use of network models in the learning process has been restricted to a few works (see e.", "startOffset": 171, "endOffset": 199}, {"referenceID": 13, "context": "Although graphs have been employed in general pattern recognition methods [13, 14] and, particularly in the analysis of the semantical properties of texts in several ways [15, 16, 17, 18, 19, 20, 21], the use of network models in the learning process has been restricted to a few works (see e.", "startOffset": 171, "endOffset": 199}, {"referenceID": 14, "context": "Although graphs have been employed in general pattern recognition methods [13, 14] and, particularly in the analysis of the semantical properties of texts in several ways [15, 16, 17, 18, 19, 20, 21], the use of network models in the learning process has been restricted to a few works (see e.", "startOffset": 171, "endOffset": 199}, {"referenceID": 15, "context": "Although graphs have been employed in general pattern recognition methods [13, 14] and, particularly in the analysis of the semantical properties of texts in several ways [15, 16, 17, 18, 19, 20, 21], the use of network models in the learning process has been restricted to a few works (see e.", "startOffset": 171, "endOffset": 199}, {"referenceID": 16, "context": "Although graphs have been employed in general pattern recognition methods [13, 14] and, particularly in the analysis of the semantical properties of texts in several ways [15, 16, 17, 18, 19, 20, 21], the use of network models in the learning process has been restricted to a few works (see e.", "startOffset": 171, "endOffset": 199}, {"referenceID": 17, "context": "Although graphs have been employed in general pattern recognition methods [13, 14] and, particularly in the analysis of the semantical properties of texts in several ways [15, 16, 17, 18, 19, 20, 21], the use of network models in the learning process has been restricted to a few works (see e.", "startOffset": 171, "endOffset": 199}, {"referenceID": 18, "context": "[22, 23]).", "startOffset": 0, "endOffset": 8}, {"referenceID": 19, "context": "[22, 23]).", "startOffset": 0, "endOffset": 8}, {"referenceID": 13, "context": "in [17, 22].", "startOffset": 3, "endOffset": 11}, {"referenceID": 18, "context": "in [17, 22].", "startOffset": 3, "endOffset": 11}, {"referenceID": 1, "context": "One of the most popular approaches to tackle the WSD problem is the use of machine learning, since this task can be seen as a supervised classification problem, where senses represent the classes [2].", "startOffset": 196, "endOffset": 199}, {"referenceID": 1, "context": "This is mostly done by supervised classifiers [2].", "startOffset": 46, "endOffset": 49}, {"referenceID": 1, "context": "The set of features employed typically are chosen to characterize the context in a myriad of forms [2].", "startOffset": 99, "endOffset": 102}, {"referenceID": 20, "context": "Typical classifiers employed for this task include decision trees [24], bayesian classifiers [24, 25], neural networks [24] and support vector machines [25, 26].", "startOffset": 66, "endOffset": 70}, {"referenceID": 20, "context": "Typical classifiers employed for this task include decision trees [24], bayesian classifiers [24, 25], neural networks [24] and support vector machines [25, 26].", "startOffset": 93, "endOffset": 101}, {"referenceID": 21, "context": "Typical classifiers employed for this task include decision trees [24], bayesian classifiers [24, 25], neural networks [24] and support vector machines [25, 26].", "startOffset": 93, "endOffset": 101}, {"referenceID": 20, "context": "Typical classifiers employed for this task include decision trees [24], bayesian classifiers [24, 25], neural networks [24] and support vector machines [25, 26].", "startOffset": 119, "endOffset": 123}, {"referenceID": 21, "context": "Typical classifiers employed for this task include decision trees [24], bayesian classifiers [24, 25], neural networks [24] and support vector machines [25, 26].", "startOffset": 152, "endOffset": 160}, {"referenceID": 12, "context": "Another approach that has been used to address the WSD problem consists in the use of complex networks and graphs [16].", "startOffset": 114, "endOffset": 118}, {"referenceID": 13, "context": "For instance, the HyperLex algorithm [17] connects words co-occurring in paragraphs to establish similarity relations among words appearing in the same context.", "startOffset": 37, "endOffset": 41}, {"referenceID": 11, "context": "Using a different approach, [15] uses the local topological properties of co-occurrence networks to disambiguate target words.", "startOffset": 28, "endOffset": 32}, {"referenceID": 22, "context": "In this case, even though a significant performance has been found for particular target words, the optimal discrimination rate was obtained with traditional local features, suggesting thus that the overall discriminability could be improved upon combining features of distinct nature, as suggested by similar approaches [27, 28, 29].", "startOffset": 321, "endOffset": 333}, {"referenceID": 23, "context": "In this case, even though a significant performance has been found for particular target words, the optimal discrimination rate was obtained with traditional local features, suggesting thus that the overall discriminability could be improved upon combining features of distinct nature, as suggested by similar approaches [27, 28, 29].", "startOffset": 321, "endOffset": 333}, {"referenceID": 24, "context": "In this case, even though a significant performance has been found for particular target words, the optimal discrimination rate was obtained with traditional local features, suggesting thus that the overall discriminability could be improved upon combining features of distinct nature, as suggested by similar approaches [27, 28, 29].", "startOffset": 321, "endOffset": 333}, {"referenceID": 11, "context": "Unlike previous studies [15, 17], we disregard the links between features words in our bipartite graph representation.", "startOffset": 24, "endOffset": 32}, {"referenceID": 13, "context": "Unlike previous studies [15, 17], we disregard the links between features words in our bipartite graph representation.", "startOffset": 24, "endOffset": 32}, {"referenceID": 25, "context": "Bipartite Heterogeneous Network (IMBHN) algorithm, which is responsible for inducing a classification model from the structure of a bipartite network [30, 31].", "startOffset": 150, "endOffset": 158}, {"referenceID": 26, "context": "Bipartite Heterogeneous Network (IMBHN) algorithm, which is responsible for inducing a classification model from the structure of a bipartite network [30, 31].", "startOffset": 150, "endOffset": 158}, {"referenceID": 0, "context": "In the strategy based on local features, the weight of the links is given by the term frequency - inverse document (tf-idf) strategy [1].", "startOffset": 133, "endOffset": 136}, {"referenceID": 11, "context": "feature words [15] is not explicitly considered in our model.", "startOffset": 14, "endOffset": 18}, {"referenceID": 27, "context": "The results obtained by the IMBHN algorithm were compared with four inductive classification algorithms: Naive Bayes (NB) [33], J48 (C4.", "startOffset": 122, "endOffset": 126}, {"referenceID": 28, "context": "5 algorithm) [34], IBk (k -Nearest Neighbors) [35] and Support Vector Machine via sequential minimal optimization (SMO) [36].", "startOffset": 13, "endOffset": 17}, {"referenceID": 29, "context": "5 algorithm) [34], IBk (k -Nearest Neighbors) [35] and Support Vector Machine via sequential minimal optimization (SMO) [36].", "startOffset": 46, "endOffset": 50}, {"referenceID": 30, "context": "5 algorithm) [34], IBk (k -Nearest Neighbors) [35] and Support Vector Machine via sequential minimal optimization (SMO) [36].", "startOffset": 120, "endOffset": 124}, {"referenceID": 31, "context": "The parameters of these algorithms have been chosen using the methodology described in [37].", "startOffset": 87, "endOffset": 91}, {"referenceID": 32, "context": "The evaluation process was performed via 10-fold cross-validation [38].", "startOffset": 66, "endOffset": 70}, {"referenceID": 1, "context": "A disadvantage associated to the use of supervised methods to undertake the word sense disambiguation problem is the painstaking, time-consuming effort required to build reliable datasets [2].", "startOffset": 188, "endOffset": 191}, {"referenceID": 1, "context": "For this reason, it becomes relevant to analyze the performance of WSD systems when only a few labelled instances are available for training [2].", "startOffset": 141, "endOffset": 144}, {"referenceID": 11, "context": "texts [15], we intend to use such models to improve the characterization of the studied bipartite networks.", "startOffset": 6, "endOffset": 10}, {"referenceID": 33, "context": "The word adjacency model could be used, for example, to better represent the relationship between feature and target words by using network similarity measurements [39, 40, 41].", "startOffset": 164, "endOffset": 176}, {"referenceID": 34, "context": "The word adjacency model could be used, for example, to better represent the relationship between feature and target words by using network similarity measurements [39, 40, 41].", "startOffset": 164, "endOffset": 176}, {"referenceID": 35, "context": "The word adjacency model could be used, for example, to better represent the relationship between feature and target words by using network similarity measurements [39, 40, 41].", "startOffset": 164, "endOffset": 176}, {"referenceID": 11, "context": "We also intend to extend the present model to consider topological and dynamical measurements of word adjacency networks as local features [15].", "startOffset": 139, "endOffset": 143}], "year": 2016, "abstractText": "The word sense disambiguation (WSD) task aims at identifying the meaning of words in a given context for specific words conveying multiple meanings. This task plays a prominent role in a myriad of real world applications, such as machine translation, word processing and information retrieval. Recently, concepts and methods of complex networks have been employed to tackle this task by representing words as nodes, which are connected if they are semantically similar. Despite the increasingly number of studies carried out with such models, most of them use networks just to represent the data, while the pattern recognition performed on the attribute space is performed using traditional learning techniques. In other words, the structural relationship between words have not been explicitly used in the pattern recognition process. In addition, only a few investigations have probed the suitability of representations based on bipartite networks and graphs (bigraphs) for the problem, as many approaches consider all possible links between words. In this context, we assess the relevance of a bipartite network model representing both feature words (i.e. the words characterizing the context) and target (ambiguous) words to solve ambiguities in written texts. Here, we focus on the semantical relationships between these two type of words, disregarding the relationships between feature words. In special, the proposed method not only serves to represent texts as graphs, but also constructs a structure on which the discrimination of senses is accomplished. Our results revealed that the proposed learning algorithm in such bipartite networks provides excellent results mostly when topical features are employed to characterize the context. Surprisingly, our method even outperformed the 1 ar X iv :1 60 6. 07 95 0v 1 [ cs .C L ] 2 5 Ju n 20 16 support vector machine algorithm in particular cases, with the advantage of being robust even if a small training dataset is available. Taken together, the results obtained here show that the proposed representation/classification method might be useful to improve the semantical characterization of written texts.", "creator": "LaTeX with hyperref package"}}}