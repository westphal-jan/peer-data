{"id": "1606.07953", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Jun-2016", "title": "Bidirectional Recurrent Neural Networks for Medical Event Detection in Electronic Health Records", "abstract": "Sequence labeling for extraction of medical events and their attributes from unstructured text in Electronic Health Record (EHR) notes is a key step towards semantic understanding of EHRs. It has important applications in health informatics including pharmacovigilance and drug surveillance. The state of the art supervised machine learning models in this domain are based on Conditional Random Fields (CRFs) with features calculated from fixed context windows. In this application, we explored various recurrent neural network frameworks and show that they significantly outperformed the CRF models.", "histories": [["v1", "Sat, 25 Jun 2016 19:46:28 GMT  (794kb,D)", "http://arxiv.org/abs/1606.07953v1", "In proceedings of NAACL HLT 2016"], ["v2", "Tue, 12 Jul 2016 17:10:38 GMT  (794kb,D)", "http://arxiv.org/abs/1606.07953v2", "In proceedings of NAACL HLT 2016"]], "COMMENTS": "In proceedings of NAACL HLT 2016", "reviews": [], "SUBJECTS": "cs.CL cs.LG cs.NE", "authors": ["abhyuday jagannatha", "hong yu"], "accepted": false, "id": "1606.07953"}, "pdf": {"name": "1606.07953.pdf", "metadata": {"source": "CRF", "title": "Bidirectional RNN for Medical Event Detection in Electronic Health Records", "authors": ["Abhyuday N Jagannatha", "Hong Yu"], "emails": ["abhyuday@cs.umass.edu", "hong.yu@umassmed.edu"], "sections": [{"heading": null, "text": "Sequence tagging to extract medical events and their attributes from unstructured text in Electronic Health Record (EHR) notes is an important step in the semantic understanding of EHRs. It has important applications in health informatics, including pharmacovigilance and drug monitoring. The most advanced supervised machine learning models in this field are based on conditional random fields (CRFs) with features calculated from fixed context windows. In this application, we examined recurring neural network structures and showed that they significantly exceed CRF models."}, {"heading": "1 Introduction", "text": "It is well known that the cases mentioned are one of many that have come to the attention of the public in recent years. (...) It is not that it is a case in which it is another case. (...) It is not that it is another case. (...) It is not that it is another case. (...) It is not that it is another case. (...) It is also that it is another case. (...) It is as if it is another case. (...) It is as if it is another case. (...) It is as if it is another case. (...) It is as if it is another case. (...) It is as if it is another case. (...) It is as if it is another case. (...) It is not another case. (...) It is as if it is another case. (...) It is not another case. (...) It is not another case. (...) It is not another case."}, {"heading": "2 Related Work", "text": "Hirschcation and ADE detection is an important NLP task in biomedicine. Related existing NLP approaches can be grouped into knowledge or rules-based, monitored machine learning processes and hybrid approaches. Thus, Hazlehurst et al. (2005) developed MediClass, a knowledge-based system that uses a set of domain-specific logical rules for the extraction of medical concepts. Wang et al. (2015), Humphreys et.al. (1993) and others classify EHR notes on medical concepts into an external knowledge resource using rules-based and syntactic analytical approaches. Gurulingappa et al al al al al al al al al al. (2010) detect two medical entities (disease and adverse events) in a corpus of annotated medline abstracts. In contrast, our work uses a corpus of current medical notes and recognizes additional events and attributes."}, {"heading": "3 Dataset", "text": "The commented corpus contains 780 English EHR notes or 613,593 word marks (an average of 786 words per note) from cancer patients diagnosed with hematological malignancy. Each note has been commented on by at least two commentators with a correspondence between the commentators of 0.93 kappa.The commented events and attributes and their instances in the commented corpus are in Table 1. The commented events can be roughly divided into two groups: Medicines and Diseases. The medication group contains medicines, dosage, frequency, duration, and pathway. It corresponds to information about drug events and their attributes. The attributes (route, frequency, dosage, and duration) of a drug (drug name) occur less frequently than the drug brand name itself because only a few EHRs report complete attributes of an event. The disease group contains events related to diseases (ADE, indication, other signs of dependence on the drug or their physician) are not in the commented corpus."}, {"heading": "4 Methods", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Long Short Term Memory", "text": "This is a typical example of how the neurons are fed into the neurons at a certain point in time, and the new activation function is now fed back into the neurons. The new activation function will be: yti = \"The new activation function is now forgotten.\" The new activation function will be: yti = \"It is the new way of activation.\" The new activation function will be: yti = \"It is a new way of activation.\" (2) The previous outputs will be used as recursive connections, their current output will depend on the previous states. This property reminds you of previous information about the sequence, which makes them useful for the sequence. RNNs can be scaled back in time."}, {"heading": "4.2 Gated Recurrent Units", "text": "Gated Recurrent Unit (GRU) is another type of recurrent neural network recently proposed for Machine Translation purposes by Cho et. al. (2014). Similar to LSTMs, gated recurrent units also have an additive mechanism to update the cell state with the current update, but GRUs have a different mechanism to create the update, and the activation of the candidate is calculated based on the previous cell state and current input."}, {"heading": "4.3 The Baseline System", "text": "CRFs model the complex dependence of outputs in a sequence using Probabilistic Graphical Models. Probabilistic Graphical Models represent relationships between variables by a product of factors where each factor is influenced only by a smaller subset of variables. Particular factorization of variables provides a specific set of dependency relationships imposed on the data. In contrast to Hidden Markov models that model the common p (x, y), CRFs directly model the posterior probability p (y | x). The condition can be written as a product of factors as follows: p (y | x) = 1 Z (x) T-t = 1, yt \u2212 1, xt) (13) Here Z is the partition function used for normalization."}, {"heading": "4.4 Skip-Gram Word Embeddings", "text": "To initialize the embedding layer of the RNNs, as Mikolov et al., (2013) demonstrated, we use word embedding trained by a flat neural network, which is also used as a feature in the CRF base model. Embedding is trained on a large, unlabeled biomedical dataset compiled from three sources: English Wikipedia, an unlabeled EHR corpus, and PubMed Open Access articles. English Wikipedia consists of text extracted from all of the articles in English Wikipedia 2015. The unlabeled EHR corpus contains 99,700 electronic medical records. PubMed Open Access articles are obtained by extracting the raw text from all open PubMed articles. This combined raw text corpus contains more than 3 billion word markers. We convert all words into lowercase 200 and use a contextual window of 10 words to train an embedding layer."}, {"heading": "5 Experiments and Evaluation Metrics", "text": "In fact, it is in such a way that most people are able to feel as they are, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to"}, {"heading": "6 Results", "text": "Table 2 shows the micro averaged values for each method. All RNN models significantly exceed the baseline (CRF context) by 19%, 2%, and 11%, respectively. Compared to the base system, our best system (GRU document) improves recall (0.8126), precision (0.7938), and Fscore (0.8031) by 19%, 2%, and 11%, respectively. Clearly, the improvement in the recall contributes more to the overall increase in system performance. The performance of the various RNN models is almost similar, except for the GRU model, which shows an improvement in the Fscore of at least one percentage point over the rest. Changes (gain or loss) in the F-Score marking for each RNN model relative to the baseline CRFcontext method are shown in Figure 2."}, {"heading": "7 Discussion", "text": "This year it has come to the point that it has never come as far as this year."}, {"heading": "8 Conclusion", "text": "We have shown that RNNs models such as LSTM and GRU are valuable tools for extracting medical events and attributes from noisy text in the natural language of EHR notes. We believe that the significant improvement by gated RNN models is due to their ability to memorize information about different dependencies when needed. As mentioned in the introduction, this is very important for our task as different labels have different contextual dependencies. CRF models with handmade features such as word representation use fixed context windows and lose a lot of information during the process. RNNNs are excellent for extracting relevant patterns from sequence data. However, they do not impose explicit limitations or dependencies on the output labels. We believe that adding a probable graphical model framework for structured output predictions would further improve the performance of our system. This remains our work in the future."}, {"heading": "Acknowledgments", "text": "We thank the UMassMed review team, consisting of Elaine Freund, Wiesong Liu, and Steve Belknap, for compiling the gold standard evaluation set used in this work. We also thank the anonymous reviewers for their comments and suggestions. This work was partially supported by the National Institutes of Health (NIH) Grant 5U01CA180975. We also acknowledge the support of the United States Department of Veterans Affairs (VA) through the award 1I01HX001457. The content of this paper does not represent the views of the NIH, VA, or the United States Government."}], "references": [{"title": "Effective mapping of biomedical text to the UMLS Metathesaurus: the MetaMap program", "author": ["Alan R Aronson"], "venue": "In Proceedings of the AMIA Symposium,", "citeRegEx": "Aronson.,? \\Q2001\\E", "shortCiteRegEx": "Aronson.", "year": 2001}, {"title": "Learning long-term dependencies with gradient descent is difficult", "author": ["Bengio et al.1994] Y. Bengio", "P. Simard", "P. Frasconi"], "venue": "IEEE Transactions on Neural Networks,", "citeRegEx": "Bengio et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 1994}, {"title": "Theano: a CPU and GPU math expression compiler", "author": ["Olivier Breuleux", "Frdric Bastien", "Pascal Lamblin", "Razvan Pascanu", "Guillaume Desjardins", "Joseph Turian", "David Warde-Farley", "Yoshua Bengio"], "venue": null, "citeRegEx": "Bergstra et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Bergstra et al\\.", "year": 2010}, {"title": "On the Properties of Neural Machine Translation: Encoder-Decoder Approaches", "author": ["Cho et al.2014] Kyunghyun Cho", "Bart van Merrienboer", "Dzmitry Bahdanau", "Yoshua Bengio"], "venue": null, "citeRegEx": "Cho et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Cho et al\\.", "year": 2014}, {"title": "Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling", "author": ["Chung et al.2014] Junyoung Chung", "Caglar Gulcehre", "KyungHyun Cho", "Yoshua Bengio"], "venue": "[cs], December", "citeRegEx": "Chung et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Chung et al\\.", "year": 2014}, {"title": "Extracting the names of genes and gene products with a hidden markov model", "author": ["Collier et al.2000] N. H Collier", "C. Nobata", "J. Tshjii"], "venue": "Proceedings of the 18th International Conference on Computational Linguistics", "citeRegEx": "Collier et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Collier et al\\.", "year": 2000}, {"title": "Natural language processing (almost) from scratch", "author": ["Jason Weston", "Lon Bottou", "Michael Karlen", "Koray Kavukcuoglu", "Pavel Kuksa"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Collobert et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Collobert et al\\.", "year": 2011}, {"title": "The Unified Medical Language System", "author": ["Da et al.1993] Lindberg Da", "Humphreys Bl", "McCray At"], "venue": "Methods of information in medicine,", "citeRegEx": "Da et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Da et al\\.", "year": 1993}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["Duchi et al.2011] John Duchi", "Elad Hazan", "Yoram Singer"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Duchi et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Duchi et al\\.", "year": 2011}, {"title": "A general natural-language text processor for clinical radiology", "author": ["Friedman et al.1994] C Friedman", "P O Alderson", "J H Austin", "J J Cimino", "S B Johnson"], "venue": "Journal of the American Medical Informatics Association,", "citeRegEx": "Friedman et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Friedman et al\\.", "year": 1994}, {"title": "An Empirical Evaluation of Resources for the Identification of Diseases and Adverse Effects in Biomedical Literature", "author": ["Roman Klinger", "Martin Hofmann-Apitius", "Juliane Fluck"], "venue": null, "citeRegEx": "Gurulingappa et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Gurulingappa et al\\.", "year": 2010}, {"title": "Methods for Identifying Suicide or Suicidal Ideation in EHRs", "author": ["Haerian et al.2012] K Haerian", "H Salmasian", "C Friedman"], "venue": "AMIA Annual Symposium Proceedings,", "citeRegEx": "Haerian et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Haerian et al\\.", "year": 2012}, {"title": "MediClass: A System for Detecting and Classifying Encounter-based Clinical Events in Any Electronic Medical Record", "author": ["H. Robert Frost", "Dean F. Sittig", "Victor J. Stevens"], "venue": "Journal of the American Medical", "citeRegEx": "Hazlehurst et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Hazlehurst et al\\.", "year": 2005}, {"title": "Overview of BioCreAtIvE: critical assessment of information extraction for biology", "author": ["A. Yeh", "C. Blaschke", "A. Valencia"], "venue": "BMC Bioinformatics,", "citeRegEx": "Hirschman et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Hirschman et al\\.", "year": 2005}, {"title": "Long Short-Term Memory", "author": ["Hochreiter", "Schmidhuber1997] Sepp Hochreiter", "Jrgen Schmidhuber"], "venue": "Neural Computation,", "citeRegEx": "Hochreiter et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter et al\\.", "year": 1997}, {"title": "Gradient Flow in Recurrent Nets: the Difficulty of Learning Long-Term Dependencies", "author": ["Yoshua Bengio", "Paolo Frasconi", "Jrgen Schmidhuber"], "venue": null, "citeRegEx": "Hochreiter et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Hochreiter et al\\.", "year": 2001}, {"title": "Bidirectional LSTM-CRF Models for Sequence Tagging", "author": ["Huang et al.2015] Zhiheng Huang", "Wei Xu", "Kai Yu"], "venue": null, "citeRegEx": "Huang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Huang et al\\.", "year": 2015}, {"title": "An Empirical Exploration of Recurrent Network Architectures", "author": ["Wojciech Zaremba", "Ilya Sutskever"], "venue": null, "citeRegEx": "Jozefowicz et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Jozefowicz et al\\.", "year": 2015}, {"title": "Overview of BioNLP\u201909 shared task on event extraction", "author": ["J. D Kim", "T. Ohta", "S. Pyysalo", "Y. Kano", "J. Tsujii"], "venue": "In Proceedings of the Workshop on BioNLP: Shared Task,", "citeRegEx": "Kim et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Kim et al\\.", "year": 2009}, {"title": "Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data", "author": ["Andrew McCallum", "Fernando C.N. Pereira"], "venue": "In Proceedings of the Eighteenth International Conference on Machine", "citeRegEx": "Lafferty et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Lafferty et al\\.", "year": 2001}, {"title": "Extracting Medication Information from Patient Discharge Summaries", "author": ["Li et al.2009] Z Li", "Y Cao", "L Antieau", "S Agarwal", "Q Zhang", "H Yu"], "venue": "In Third i2b2 Shared-Task Workshop", "citeRegEx": "Li et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Li et al\\.", "year": 2009}, {"title": "Lancet: a high precision medication event extraction system for clinical text", "author": ["Z. Li", "F. Liu", "L. Antieau", "Y. Cao", "H. Yu"], "venue": "Journal of the American Medical Informatics Association,", "citeRegEx": "Li et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Li et al\\.", "year": 2010}, {"title": "Maximum Entropy Markov Models for Information Extraction and Segmentation", "author": ["Dayne Freitag", "Fernando C.N. Pereira"], "venue": "In Proceedings of the Seventeenth International Conference on Machine Learning,", "citeRegEx": "McCallum et al\\.,? \\Q2000\\E", "shortCiteRegEx": "McCallum et al\\.", "year": 2000}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Ilya Sutskever", "Kai Chen", "Greg S. Corrado", "Jeff Dean"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "CRFsuite: a fast implementation of Conditional Random Fields (CRFs)", "author": ["Naoaki Okazaki"], "venue": null, "citeRegEx": "Okazaki.,? \\Q2007\\E", "shortCiteRegEx": "Okazaki.", "year": 2007}, {"title": "Automatically Recognizing Medication and Adverse Event Information From Food and Drug Administrations", "author": ["Steven M Belknap", "Zuofeng Li", "Nadya Frid", "Dennis P West", "Hong Yu"], "venue": null, "citeRegEx": "Ramesh et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Ramesh et al\\.", "year": 2014}, {"title": "Evaluating the state of the art in disorder recognition and normalization of the clini", "author": ["Nomie Elhadad", "Brett R. South", "David Martinez", "Lee Christensen", "Amy Vogel", "Hanna Suominen", "Wendy W. Chapman", "Guergana Savova"], "venue": null, "citeRegEx": "Pradhan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Pradhan et al\\.", "year": 2014}, {"title": "A novel method of adverse event detection can accurately identify venous thromboembolisms (VTEs) from narrative electronic health record", "author": ["Aman D. Verma", "Tewodros Eguale", "Todd C. Lee", "David L. Buckeridge"], "venue": null, "citeRegEx": "Rochefort et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Rochefort et al\\.", "year": 2015}, {"title": "Dropout: A Simple Way to Prevent Neural Networks from Overfitting", "author": ["Geoffrey Hinton", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan Salakhutdinov"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "Srivastava et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Srivastava et al\\.", "year": 2014}, {"title": "Recognizing and Encoding Disorder Concepts in Clinical Text using Machine Learning and Vector Space Model. 00004", "author": ["Tang et al.2013] Buzhou Tang", "Yonghui Wu", "Min Jiang", "Joshua C. Denny", "Hua Xu"], "venue": null, "citeRegEx": "Tang et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Tang et al\\.", "year": 2013}, {"title": "Medical Synonym Extraction with Concept Space Models", "author": ["Wang et al.2015] Chang Wang", "Liangliang Cao", "Bowen Zhou"], "venue": null, "citeRegEx": "Wang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2015}, {"title": "MedEx: a medication information extraction system for clinical narratives", "author": ["H. Xu", "S.P. Stenner", "S. Doan", "K.B. Johnson", "L.R. Waitman", "J.C. Denny"], "venue": "J Am Med Inform Assoc,", "citeRegEx": "Xu et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Xu et al\\.", "year": 2010}], "referenceMentions": [{"referenceID": 11, "context": "Rule-based and learning-based approaches have been developed to identify and extract information from EHR notes (Haerian et al., 2012), (Xu et al.", "startOffset": 112, "endOffset": 134}, {"referenceID": 31, "context": ", 2012), (Xu et al., 2010), (Friedman et al.", "startOffset": 9, "endOffset": 26}, {"referenceID": 9, "context": ", 2010), (Friedman et al., 1994), (Aronson, 2001), (Polepalli Ramesh et al.", "startOffset": 9, "endOffset": 32}, {"referenceID": 0, "context": ", 1994), (Aronson, 2001), (Polepalli Ramesh et al.", "startOffset": 9, "endOffset": 24}, {"referenceID": 19, "context": "Learningbased approaches use sequence labeling algorithms like Conditional Random Fields (Lafferty et al., 2001), Hidden Markov Models (Collier et al.", "startOffset": 89, "endOffset": 112}, {"referenceID": 22, "context": "2000), and Max-entropy Markov Models (McCallum et al., 2000).", "startOffset": 37, "endOffset": 60}, {"referenceID": 1, "context": "Traditionally, recurrent neural networks have been hard to train through Back-Propagation, because learning long term dependencies using simple recurrent neurons lead to problems like exploding or vanishing gradients (Bengio et al., 1994), (Hochreiter et al.", "startOffset": 217, "endOffset": 238}, {"referenceID": 15, "context": ", 1994), (Hochreiter et al., 2001).", "startOffset": 9, "endOffset": 34}, {"referenceID": 12, "context": "For example, Hazlehurst et al. (2005) developed MediClass, a knowledge-based system that deploys a set of domain-specific logical rules for", "startOffset": 13, "endOffset": 38}, {"referenceID": 29, "context": "Wang et al. (2015) , Humphreys et.", "startOffset": 0, "endOffset": 19}, {"referenceID": 29, "context": "Wang et al. (2015) , Humphreys et.al. (1993) and others map EHR notes to medical concepts to an external knowledge resource using hybrid rule-based and syntactic parsing approaches.", "startOffset": 0, "endOffset": 45}, {"referenceID": 10, "context": "Gurulingappa et al. (2010) detect", "startOffset": 0, "endOffset": 27}, {"referenceID": 11, "context": "Haerian et al. (2012) applied distance supervision to identify terms (e.", "startOffset": 0, "endOffset": 22}, {"referenceID": 11, "context": "Haerian et al. (2012) applied distance supervision to identify terms (e.g., including \u201csuicidal\u201d, \u201cself harm\u201d, and \u201cdiphenhydramine overdose\u201d) associated with suicide events. Zuofeng Li et al. (2010) extracted medication information using CRFs.", "startOffset": 0, "endOffset": 200}, {"referenceID": 18, "context": "Many named entity recognition systems in the biomedical domain have been driven by the Shared tasks of BioNLP (Kim et al., 2009), BioCreAtivE", "startOffset": 110, "endOffset": 128}, {"referenceID": 13, "context": "(Hirschman et al., 2005) i2b2 shared NLP tasks (Li et al.", "startOffset": 0, "endOffset": 24}, {"referenceID": 20, "context": ", 2005) i2b2 shared NLP tasks (Li et al., 2009) and ShARe/CLEF evaluation tasks (Pradhan et al.", "startOffset": 30, "endOffset": 47}, {"referenceID": 26, "context": ", 2009) and ShARe/CLEF evaluation tasks (Pradhan et al., 2014).", "startOffset": 40, "endOffset": 62}, {"referenceID": 13, "context": "(Hirschman et al., 2005) i2b2 shared NLP tasks (Li et al., 2009) and ShARe/CLEF evaluation tasks (Pradhan et al., 2014). The best performing clinical NLP systems for named entity recognition includes Tang et al (2013) which applied CRF and structured SVM.", "startOffset": 1, "endOffset": 218}, {"referenceID": 16, "context": "Later, Huang et al. (2015) achieved comparable or better scores using", "startOffset": 7, "endOffset": 27}, {"referenceID": 1, "context": "Bengio et al. (1994) showed that learning long term depen-", "startOffset": 0, "endOffset": 21}, {"referenceID": 15, "context": "This is mainly because the back-propagating error can frequently \u201cblow-up\u201d or explode which makes convergence infeasible, or it can vanish which renders the network incapable of learning long term dependencies (Hochreiter et al., 2001).", "startOffset": 210, "endOffset": 235}, {"referenceID": 4, "context": "Recent experiments (Chung et al., 2014), (Jozefowicz et al.", "startOffset": 19, "endOffset": 39}, {"referenceID": 17, "context": ", 2014), (Jozefowicz et al., 2015) comparing both these architectures", "startOffset": 9, "endOffset": 34}, {"referenceID": 23, "context": "We use skip-gram word embeddings trained through a shallow neural network as shown by Mikolov et al., (2013) to initialize the embedding layer of the RNNs.", "startOffset": 86, "endOffset": 109}, {"referenceID": 28, "context": "We also use dropout (Srivastava et al., 2014) as an additional measure to avoid over-fitting.", "startOffset": 20, "endOffset": 45}, {"referenceID": 8, "context": "We use AdaGrad (Duchi et al., 2011) to optimize the net-", "startOffset": 15, "endOffset": 35}, {"referenceID": 24, "context": "We use CRFsuite (Okazaki, 2007) for implementing the CRF tagger.", "startOffset": 16, "endOffset": 31}, {"referenceID": 2, "context": "Lasagne1 is a machine learning library focused towards neural networks that is build on top of Theano (Bergstra et al., 2010).", "startOffset": 102, "endOffset": 125}], "year": 2017, "abstractText": "Sequence labeling for extraction of medical events and their attributes from unstructured text in Electronic Health Record (EHR) notes is a key step towards semantic understanding of EHRs. It has important applications in health informatics including pharmacovigilance and drug surveillance. The state of the art supervised machine learning models in this domain are based on Conditional Random Fields (CRFs) with features calculated from fixed context windows. In this application, we explored recurrent neural network frameworks and show that they significantly outperformed the CRF models.", "creator": "LaTeX with hyperref package"}}}