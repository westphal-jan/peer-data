{"id": "1606.08821", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Jun-2016", "title": "Generation and Pruning of Pronunciation Variants to Improve ASR Accuracy", "abstract": "Speech recognition, especially name recognition, is widely used in phone services such as company directory dialers, stock quote providers or location finders. It is usually challenging due to pronunciation variations. This paper proposes an efficient and robust data-driven technique which automatically learns acceptable word pronunciations and updates the pronunciation dictionary to build a better lexicon without affecting recognition of other words similar to the target word. It generalizes well on datasets with various sizes, and reduces the error rate on a database with 13000+ human names by 42%, compared to a baseline with regular dictionaries already covering canonical pronunciations of 97%+ words in names, plus a well-trained spelling-to-pronunciation (STP) engine.", "histories": [["v1", "Tue, 28 Jun 2016 18:44:38 GMT  (480kb,D)", "http://arxiv.org/abs/1606.08821v1", "Interspeech 2016"]], "COMMENTS": "Interspeech 2016", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["zhenhao ge", "aravind ganapathiraju", "ananth n iyer", "scott a randal", "felix i wyss"], "accepted": false, "id": "1606.08821"}, "pdf": {"name": "1606.08821.pdf", "metadata": {"source": "CRF", "title": "Generation and Pruning of Pronunciation Variants to Improve ASR Accuracy", "authors": ["Zhenhao Ge", "Aravind Ganapathiraju", "Ananth N. Iyer", "Scott A. Randal", "Felix I. Wyss"], "emails": ["felix.wyss}@inin.com"], "sections": [{"heading": "1. Introduction", "text": "In fact, it is that we are able to assert ourselves, that we are able, that we are able to hide ourselves, and that we are able, that we are able to hide ourselves."}, {"heading": "2. Data", "text": "This work used the ININ company directory database, which contains human names (concatenation of 2.3 or 4 words), which were intentionally collected from two phases of pronunciation (training) and accuracy (testing), sharing the same pool of 13,875 names, and Tab. 1 lists statistics and basic accuracy. Names were pronounced in English by speakers from several regions and countries, asking them to read a list of native and non-native names with random repetitions, and then segmenting the audio into recordings of individual names. Reducing the name error rate (NER) from Phase 1 to Phase 2 was mainly due to the fact that the latter were recorded in cleaner channels with lower packet losses and better methods of creating corpus. Recognition is usually more difficult when grammar size increases, as names are denser in the pronunciation space and can be more easily confused with others."}, {"heading": "3. Overview of Grammar-based ASR", "text": "Grammar-based ASR is used to recognize input language as one of the entries specified in the grammar file. For example, if the grammar contains different names, the input language Xiv will be: 160 6.08 821v 1 [cs.C L] June 28, 2016 recognized as one of the most likely names or the system reports \"no match\" if it does not have a name. In this thesis, Interaction Speech Recognition (HMM-GMM) was used, a grammatics-based ASR developed by ININ. Fig. 1 illustrates the main components with both acoustic and linguistic resources. The acoustic information is modeled as the Hidden Markov Model-Gaussian Mixture Model (HMM-GMM). The front end of this system uses MelFrequency Cepstral Coefficient (MFCCs), which have been transformed using Linear Discriminant Analysis (LDA). The language resource is used as a prediction according to the language specification of the RGS."}, {"heading": "4. Preliminaries", "text": "In order to better describe the pronunciation acquisition algorithm in paragraph 5, three preliminary related concepts are presented in this section, including a) confusion matrix, b) pronunciation space and distance, and c) generation of candidate debates."}, {"heading": "4.1. Confusion Matrix", "text": "The value M (pi, pj) serves as a similarity measurement between the phonemes pi and pj. The smaller the value, the more similar they are. It takes into account both acoustic and linguistic similarities and is formulated as follows: M (pi, pj) = Macoustic (pi, pj) \u00b7 Mlinguistic (pi, pj) (1) In order to construct macoustic, phonematic similarities, a linguistics was performed on the Wall Street Journal (WSJ) corpus to find the average probability of recognizing phonemes pi as pj. These values were then symbologically inversed and normalized so that the diagonal values in Macoustic are all zeros. Mlinguistic matrix is a symmetric binary matrix in which Mlinguistic pi (pi, prij, although they are similar only in the confusion between j and ib)."}, {"heading": "4.2. Pronunciation Space and Distance Measurement", "text": "The pronunciation space is spanned by all possible pronunciations (phoneme sequences). Sequences are considered points in this space and the \"distances\" between them are calculated using a confusion matrix M. The distance d (Pi, Pj) between two pronunciations Pi = [p1, p2,..., pM] and Pj = [q1, q2,..., qN], where M, N are the lengths of the phonemes, is measured using Levenshtein distance with dynamic programming [9]. Subsequently, it is normalized by the maximum length of these two, i.e. d (Pi, Pj) = C (M, N) / max {M, N}. For a database with grammar size G, a G \u00b7 G name spacing matrix N is calculated before learning the pronunciation, with N (s, t) indicating the distance between the names Ns and Nt."}, {"heading": "4.3. Generation of Candidate Pronunciations", "text": "In fact, it is such that it is a matter of a way in which most people are able to move into another world, in which they are able to integrate themselves, in which they are able to integrate themselves, and in which they are able to change the world, in which they live, in which they are able to live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they are able, in which they are able to"}, {"heading": "5. Pronunciation Learning Algorithm", "text": "Pronunciation learning aims to find a better alternative pronunciation for misrecognized names through a pronunciation generation and truncation process that maximizes the accuracy of a regional name set including the target name Nt and its nearby similar nameNc. Learning is performed for all misrecognized names, but only on a word basis, on the misrecognized words in the misrecognized names. The following subsections first introduce the main word learning algorithm and then address the key components."}, {"heading": "5.1. Algorithm Outline", "text": "1. Set the phoneme search radius r0 and the upper limits to the number of total pronunciations per name K1 and per word K2.2. Perform the baseline name recognition and collect all incorrectly recognized name examples in De. 3. Find nameNt with error cases in De for each target: a. Calculate the PCan with r0 and the range dt in Equation. (2) to find the corresponding regional name set Dr. b. For each incorrectly recognized word instance find Wt (i), find the best pronunciation P \u0445 (i) using hierarchical pronunciation and get the accuracy increment A (i) to Dr by inserting P (i) into the dictionary. c. Sort P (i) by A (i) and stick to K1 pronunciations in P1."}, {"heading": "5.2. Hierarchical Pronunciation Determination", "text": "Generally speaking, a grammatical ASR input test called NBase uses the same method as a comparison with other words (see Figure 2a). However, if NHyp has multiple pronunciations that are actually used to generate SHyp, the highest pronunciation is not provided for the decoding efficiency (Figure 2a) (Figure 2b). By providing a massive number of PCs for an ASR with a single grammar (grammar contains only one nameNt), only the highest hypothesized score S is provided and the associated best pronunciation M is not provided. To find out P from PCan, hierarchical pronunciation with PCan segmentation is used by determining its phoneme one at a time. For simplification, an ex-www.inininin.com \u00a9 2012 Interactive Intelligence Group Inc.ample is used to determine P."}, {"heading": "6. Optimization in Implementation", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.1. Search Radius Reduction", "text": "If too many alternatives are generated for a given word due to the phoneme sequence length M > Mmax, step 3b of sec. 5.1 triggers a reduction in the search radius to reduce the computational costs by reducing the phoneme search radius from r0 to Mmax \u2212 1M \u2212 1 r0. For example, word desjardins with PBase = [d eh s zh aa r d iy n z] have a long word with M = 10, and phonemes {eh, s, zh, aa, iy, z} each have more than 5 phoneme candidates. The total number of PCan is 4,536,000, which takes much longer to learn than normal words. In DTrain there are less than 20% of the words that triggered this. However, the average word pronunciation length has been reduced from 20,204 to 11,941. Both r0 and Mmax in are experimentally determined, here r0 = 3 and Mmax = 6."}, {"heading": "6.2. Phoneme Determination Order Optimization", "text": "In {NM, NM \u2212 1,.., N1} the number of phoneme candidates for phonemes {pM, pM \u2212 1,..., p1} is given in the PBase. Fig. 3 shows that the phonemes are determined in the natural order of Nm, such as p3 \u2192 p2 \u2192 p1, and the total number of processed PCs is LNatural = 26. However, if they are determined in the descending order of Nm, such as p2 \u2192 p3 \u2192 p1 (N2 = 4 \u2265 N3 = 2 \u2265 N1 = 2), then the number of processed PCs is minimized to LDescend = 22 < LNatural = 26 (Fig. 4). In general, it can be mathematically proven that LDescend \u2264 LNatural is \u2264 LAscend."}, {"heading": "7. Results and Conclusions", "text": "The improvement of baseline varies according to the experimental settings, e.g. 1) how difficult the database is (percentage of rare words); 2) the record and grammar quantities; 3) the quality of the audio recording and 4) the acoustic modeling in Tab. 1 contain 13.4% rare words (4.6% native, 8.8% non-native); Tab. 5 and Fig. 5 already show the baselines with competing accuracies, as the dictionaries contain canonical pronunciations of 97% + words, and the rest is generated from a well-trained STP with perfect accuracy."}, {"heading": "8. References", "text": "[1] Y. Gao, B. Ramabhadran, J. Chen, M. Picheny et al., \"Innova-tive approaches for large vocabulary name recognition,\" in: ICASSP 2001, vol. 1. IEEE, 2001, pp. 53-56. [2] I. Badr, \"Pronunciation learning for automatic speech recognition,\" Dissertation, Massachusetts Institute of Technology, 2011. [3] H. Y. Chan and R. Rosenfeld, \"Discriminative pronunciation learning for speech recognition for resource languages,\" in: Proceedings of the 2nd ACM Symposium on Computing for Development. ACM, 2012, p. 12. [4] F. Beaufays, A. Sankar, S. Williams, and M. Weintraub, \"Learning name pronunciations in automatic speech recognition systems,\" in: Tools with Artificial Intelligence 2003. Proceedings. 15th IEEE International Conference, 2003, pp. 233-240. [B. Rebell, H. Heuvel et Proceal for Development, \"Automatic speech recognition systems,\" 2nd IEEE International Conference, 2003, pp. 233-240."}], "references": [{"title": "Innovative approaches for large vocabulary name recognition", "author": ["Y. Gao", "B. Ramabhadran", "J. Chen", "M. Picheny"], "venue": "ICASSP 2001, vol. 1. IEEE, 2001, pp. 53\u201356.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2001}, {"title": "Pronunciation learning for automatic speech recognition", "author": ["I. Badr"], "venue": "Ph.D. dissertation, Massachusetts Institute of Technology, 2011.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2011}, {"title": "Discriminative pronunciation learning for speech recognition for resource scarce languages", "author": ["H.Y. Chan", "R. Rosenfeld"], "venue": "Proceedings of the 2nd ACM Symposium on Computing for Development. ACM, 2012, p. 12.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "Learning name pronunciations in automatic speech recognition systems", "author": ["F. Beaufays", "A. Sankar", "S. Williams", "M. Weintraub"], "venue": "Tools with Artificial Intelligence 2003. Proceedings. 15th IEEE International Conference, 2003, pp. 233\u2013240.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2003}, {"title": "Improving proper name recognition by means of automatically learned pronunciation variants", "author": ["B. R\u00e9veil", "J. Martens", "H. Van Den Heuvel"], "venue": "Speech Communication, vol. 54, no. 3, pp. 321\u2013340, 2012.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2012}, {"title": "Mispronunciation detection for language learning and speech recognition adaptation", "author": ["Z. Ge"], "venue": "Ph.D. Dissertation, Purdue University West Lafayette, 2013.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "CMU pronouncing dictionary @ONLINE", "author": ["R. Doe"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2013}, {"title": "Measuring dialect pronunciation differences using levenshtein distance", "author": ["W.J. Heeringa"], "venue": "Ph.D. dissertation, Citeseer, 2004.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2004}], "referenceMentions": [{"referenceID": 0, "context": "Many techniques have been tried to address this challenge, such as weighted speaker clustering, massive adaptation, and adaptive pronunciation modeling [1].", "startOffset": 152, "endOffset": 155}, {"referenceID": 1, "context": "There are various ways to learn pronunciations [2, 3] and here we propose a novel efficient algorithm.", "startOffset": 47, "endOffset": 53}, {"referenceID": 2, "context": "There are various ways to learn pronunciations [2, 3] and here we propose a novel efficient algorithm.", "startOffset": 47, "endOffset": 53}, {"referenceID": 3, "context": "used probability models to suggest alternative pronunciations by changing one phoneme at a time [4].", "startOffset": 96, "endOffset": 99}, {"referenceID": 4, "context": "adds pronunciation variants to a baseline lexicon using multiple phoneme-to-phoneme (P2P) converters with different features and rules [5].", "startOffset": 135, "endOffset": 138}, {"referenceID": 5, "context": "The work was initiated during the first author\u2019s internship at Interactive Intelligence (ININ) [6], and later improved in terms of accuracy, efficiency and flexibility.", "startOffset": 95, "endOffset": 98}, {"referenceID": 6, "context": "This work used the Arpabet phoneme set of 39 phonemes [8] to construct a 39\u00d7 39 confusion matrixM.", "startOffset": 54, "endOffset": 57}, {"referenceID": 0, "context": "pm in PBase(M = 3) p3 = p p2 = ey p1 = n Number of candidates Nm N3 = 2 N2 = 4 N1 = 2 Candidate index nm n3 \u2208 [0, 1] n2 \u2208 [0, 3] n1 \u2208 [0, 1]", "startOffset": 110, "endOffset": 116}, {"referenceID": 2, "context": "pm in PBase(M = 3) p3 = p p2 = ey p1 = n Number of candidates Nm N3 = 2 N2 = 4 N1 = 2 Candidate index nm n3 \u2208 [0, 1] n2 \u2208 [0, 3] n1 \u2208 [0, 1]", "startOffset": 122, "endOffset": 128}, {"referenceID": 0, "context": "pm in PBase(M = 3) p3 = p p2 = ey p1 = n Number of candidates Nm N3 = 2 N2 = 4 N1 = 2 Candidate index nm n3 \u2208 [0, 1] n2 \u2208 [0, 3] n1 \u2208 [0, 1]", "startOffset": 134, "endOffset": 140}, {"referenceID": 7, "context": ", qN ], where M,N are the lengths of phoneme sequences, is measured using Levenshtein distance with Dynamic Programming [9].", "startOffset": 120, "endOffset": 123}, {"referenceID": 3, "context": "[4] achieved ERR 40% with 1600 names, compared to a baseline letter-to-phone pronunciation engine.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5], whose ERR was close to 40% with 3540 names spoken by speakers from 5 different language origins, our dataset may not have such diversity but we achieved much higher ERR of around 58% for a similar grammar size.", "startOffset": 0, "endOffset": 3}], "year": 2016, "abstractText": "Speech recognition, especially name recognition, is widely used in phone services such as company directory dialers, stock quote providers or location finders. It is usually challenging due to pronunciation variations. This paper proposes an efficient and robust data-driven technique which automatically learns acceptable word pronunciations and updates the pronunciation dictionary to build a better lexicon without affecting recognition of other words similar to the target word. It generalizes well on datasets with various sizes, and reduces the error rate on a database with 13000+ human names by 42%, compared to a baseline with regular dictionaries already covering canonical pronunciations of 97%+ words in names, plus a well-trained spelling-to-pronunciation (STP) engine.", "creator": "LaTeX with hyperref package"}}}