{"id": "1606.09370", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Jun-2016", "title": "Relation extraction from clinical texts using domain invariant convolutional neural network", "abstract": "In recent years extracting relevant information from biomedical and clinical texts such as research articles, discharge summaries, or electronic health records have been a subject of many research efforts and shared challenges. Relation extraction is the process of detecting and classifying the semantic relation among entities in a given piece of texts. Existing models for this task in biomedical domain use either manually engineered features or kernel methods to create feature vector. These features are then fed to classifier for the prediction of the correct class. It turns out that the results of these methods are highly dependent on quality of user designed features and also suffer from curse of dimensionality. In this work we focus on extracting relations from clinical discharge summaries. Our main objective is to exploit the power of convolution neural network (CNN) to learn features automatically and thus reduce the dependency on manual feature engineering. We evaluate performance of the proposed model on i2b2-2010 clinical relation extraction challenge dataset. Our results indicate that convolution neural network can be a good model for relation exaction in clinical text without being dependent on expert's knowledge on defining quality features.", "histories": [["v1", "Thu, 30 Jun 2016 07:10:07 GMT  (148kb,D)", "http://arxiv.org/abs/1606.09370v1", "This paper has been accepted in ACL BioNLP 2016 Workshop"]], "COMMENTS": "This paper has been accepted in ACL BioNLP 2016 Workshop", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["sunil kumar sahu", "ashish anand", "krishnadev oruganty", "mahanandeeshwar gattu"], "accepted": false, "id": "1606.09370"}, "pdf": {"name": "1606.09370.pdf", "metadata": {"source": "CRF", "title": "Relation extraction from clinical texts using domain invariant convolutional neural network", "authors": ["Sunil Kumar Sahu", "Ashish Anand", "Krishnadev Oruganty", "Mahanandeeshwar Gattu"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "In fact, most of them will be able to move into a different world, in which they are able to move, in which they move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they, in which they live, in which they, in which they, in which they live, in which they, in which they live, in which they, in which they, in which they, in which they live."}, {"heading": "2 Related Research", "text": "Most of the participants in this challenge used assistive vector machines (SVM) with manually designed functions (Uzuner et al., 2010). The model proposed by Rink et al. (2011) took first place in this task, in which six classes of characteristics were used, namely context characteristics, similarity characteristics, Wikipedia characteristics, individual concept characteristics and environmental characteristics. They formulated the extraction task as a multiclass classification problem and SVM with linear cores used for classification. Rosario and Hearst (2004) used various graphical and neural network models. They used a variety of lexical, semantic and syntactic characteristics for classification."}, {"heading": "3 CNN for Clinical Relation Extraction", "text": "The proposed model, which is based on CNN, is first summarized in the next section and described in more detail in later sections."}, {"heading": "3.1 Model Architecture", "text": "The proposed model architecture is shown in Figure 1, which takes a complete set of entities mentioned as input and prints a probability vector corresponding to all possible relationship types. Each attribute has a vector representation that is randomly initialized, except for the word embedding function. For word embedding, we used pre-formed word vectors (TH et al., 2015) that we learned on Pubmed articles using the word2vec tool (Mikolov et al., 2013b).The embedding layer maps each attribute value with its corresponding feature vectors and concatenates them. To obtain local characteristics from each part of the set, we used several filters of different length (Kim et al., 2014) in all possible continuous n-grams of the set, where n is the length of the filter (we have four filters with constant length shown in Figure 1). We use maximum summary of all characteristics over time, through the global filter."}, {"heading": "3.2 Feature Layer", "text": "We represent each word in a sentence with 6 individual characteristics, namely word itself (W), distance from the first unit (P1), distance from the second unit (P2), parts of the speech day of the word (PoS), chunk day of the word (Chunk) and entity type (T). Each characteristic is briefly described below: 1. W: Exact word appeared in the sentence. 2. P1: Distance from the first element in terms of the number of words (Collobert and Weston, 2008). For example, in our previous example [S1] It is at \u2212 3 distance and Prevent is at + 2 distance from the first element Lexis. This value would be zero for all words that are part of the first element. 3. P2: Similar to P1, but considered distance from the second element. 4. PoS: Parts of the speech day of the considered word as Dentity. \u2212 We use Genia Tagger1 to get Pos. 5. Chunk: Chunk day of the considered word."}, {"heading": "3.3 Embedding Layer", "text": "In the reference or embedding layer, each character value is mapped to its vector representation using the character embedding matrix. Suppose M i-Rn-N is the character embedding matrix for ith characters (here n stands for dimension of character embedding and N for number of possible values or dictionary size for ith characters) Each column of M i is the vector of the corresponding value ith characters. The mapping can be done by taking the product of a hot vector of the character value with its embedding matrix (Collobert and Weston, 2008). Suppose a (i) j is the only hot vector for ith characters: f (i) j = M i a (i) j (1) xi = f (i) 1... f (i) 2.... f (i) 6 (2)."}, {"heading": "3.4 Convolution Layer", "text": "Consider x1x2..... xm is the sequence of character vectors of a set, where xi-Rd is a vector obtained by concatenating all character vectors of the ith word. Let's leave xi: i + j represents the concatenation of character vectors of xi..... xi + j character vectors. Suppose there is a filter parameterized by the weight vector w-Rcd, where c is the length of the filter (in Figure 1 the filter length is three), then the output sequence of the fold layer would be behi = f (w \u00b7 xi: i + c \u2212 1 + b) (3), where i = 1, 2,.. m \u2212 c + 1,. Point product, f corrects linear unit (ReLu) and b-R is one-sided, c is one-sided, all learning parameters are w = 1 and \u2212 m."}, {"heading": "3.5 Max Pooling Layer", "text": "The output of the length of the folding layer (m \u2212 c + 1) varies according to the number of words m in the sentence. We applied max pooling (Collobert and Weston, 2008) to obtain global fixed length characteristics for an entire sentence. Intuition behind the use of max pooling is to consider only the most useful feature from an entire sentence. z = max 1 \u2264 i \u2264 (m \u2212 c + 1) [hi] (4) We have just explained the process of extracting a feature from an entire sentence with a filter. In Figure 1, we extracted four features with four filters of the same length three. In our experiment, we used several such filters of different length (Kim, 2014; Yin und Schtze, 2015). The aim of using different length filters is to adjust the context in different window sizes around the words."}, {"heading": "3.6 Fully Connected Layer", "text": "The output of the max pooling layer is sequence z came with different filters. We call this global feature because it came out by putting max over the entire set. To make classifiers over extracted global feature, we used fully connected feed layer. Let's suppose zi-Rl is output of the max pooling layer for whole filters, then the output of the fully connected layer would be beo (i) = W ozi + bo (5) Here W o-R [r] \u00b7 l and bo-R [r] are neural network parameters and [r] denotes the number of classes."}, {"heading": "3.7 Softmax Layer", "text": "At the output level, we used Softmax classifiers, for which objective function would be the minimization of Li = \u2212 log (eo (i) yi \u0445 \u0418j e (i) j) (6) for the ith set. In this case, yi is the correct relationship class."}, {"heading": "3.8 Implementation", "text": "We experiment with filter lengths in two different test settings. In the first setting, we use 100 different filters of fixed length in the wave layer, while in another set of experiments, we use different length filters, but 100 different filters for each different length. So, in the first setting, we get 100 characteristics after maximum pooling, while in the second, we get 100 times the number of different length filter characteristics. To regulate (Srivastava et al., 2014), we follow (Kim, 2014) and use exposure techniques in the output of the maximum pooling layer. Exposers prevent the co-adjustment of hidden units by randomly dropping some nodes. We set this value to 0.5 during training and 1 during testing. We use the Adam technique (Kingma and Ba, 2014) to optimize our loss function. Entire neural network parameters and feature vectors are updated during training."}, {"heading": "4 Dataset and Experimental Settings", "text": "In recent years, several challenges have been organized to extract information from clinical texts (Uzuner et al., 2007; Uzuner et al., 2011; Uzuner et al., 2010; Sun et al., 2013). i2b2 has published datasets for the extraction of clinical concepts, as part of the i2b2-2010 shared task. This dataset was collected from three different hospitals and commented manually by physicians to identify problems, treatments and test units, and eight relationship types among themselves. These relationships caused medical problems (TrCP), treatment was performed by patients who had a medical problem (TrCP), treatments were improved or cured."}, {"heading": "5 Results and Discussion", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Influence of filter lengths", "text": "We combined the training and test data and performed a fivefold cross-validation of the available limited i2b2 dataset for all our evaluations. First, we evaluate the influence of filter lengths. We experiment with selecting the filter length using all characteristics. Results as an average of the fivefold experiment are shown in Table 2.In the case of a single filter, the results show that increasing the filter length generally tends to improve performance. Using a single filter, the best performance was achieved with an F1 value of 70.43% by using the filter length of 6. However, further increasing the filter length did not improve the result. Intuitively, it also seems that selecting a filter length that is too small or too large may not be a good option. Filter length indicates the window size to capture context characteristics. It is reasonable to expect that a filter length that is too small (window size) not enough good context characteristics and a filter length that is too large may not capture sufficiently, noise or noise-related filters that we use to improve the result."}, {"heading": "5.2 Classwise Performance", "text": "We took the best combination of filter lengths and looked at class performance. Results are in Table 3.We see from the results that as the number of training examples increases (see Table 1), so does the performance of the model. ClassTeRP has the maximum number of training examples and the model achieved a reasonably good F1 value. On the other hand, the model may not have been able to learn well for the relation classes TeCP and TrCP, which have a relatively lower number of training examples."}, {"heading": "5.3 Contribution of Each Features", "text": "To examine the contribution of each feature to the end result, we gradually insert a feature into our model and compare performance. Table 4 shows the results obtained. First, we only use random vector representation (RV) along with entity types (T) (first row in the table) as the baseline for our comparison. Adding position features (second row) led to an increase in memory by about 15%, 7% in precision, and 11.7% in entity types (fourth row). However, while POS and chunk features were improved by 4.3% and 1.3%, precision was reduced by 3.6%. In the second group of experiments, we first use pre-trained word vectors along with entity types (fourth row) and later repeat the similar experiments as before. Again, the inclusion of position features resulted in an improvement of memory by more than 14% and F1 value by about 11%. This clearly indicates that the decision of text plays a relative role in the interaction of the word characteristics."}, {"heading": "5.4 Comparison with Feature Based Method", "text": "We could not directly compare our results with the results obtained on the i2b2 dataset because we did not have the full dataset. We built a linear SVM classifier that used features similar to those defined in previous studies (Rink et al., 2011) as the starting point for comparison. The following features are used for each instance: \u2022 Every word between relation parameters \u2022 Every PoS tag between relation parameters. We used Genia tag for PoS \u2022 Every bigram between relation parameters \u2022 Every word that precedes the first and second argument \u2022 All three words that follow the first and second argument \u2022 Sequence of chunk tags between relation parameters. We used Genia tag for chunktags \u2022 Word order between relation parameters \u2022 First and second argument (problem, treatment and test) \u2022 Order of argument types appeared in the sentence \u2022 Distance between two arguments in terms of the number of words presence of characters \u2022 Only punctuated between these attributes for each argument."}, {"heading": "6 Conclusion", "text": "In this paper, we present a new framework based on CNN to extract relationships between clinical units in clinical texts, and the proposed model has shown better performance by using only a small fraction of the features compared to the SVM-based base model. Our results suggest that CNN is able to learn global traits that can capture contextual traits fairly well, thus contributing to improved performance."}, {"heading": "Acknowledgments", "text": "We would like to thank the i2b2 National Center for Biomedical Computing, which is funded by U54LM008748, for providing the clinical records originally created for the Shared Tasks for Challenges in NLP for Clinical Data organized by Dr. Ozlem Uzuner, i2b2 and SUNY."}], "references": [{"title": "A neural probabilistic language model", "author": ["Bengio et al.2003] Yoshua Bengio", "R\u00e9jean Ducharme", "Pascal Vincent", "Christian Janvin"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "Bengio et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 2003}, {"title": "Extraction of relations between genes and diseases from text and large-scale data analysis: implications for translational research", "author": ["Bravo et al.2015] \u00c0lex Bravo", "Janet Pi\u00f1ero", "N\u00faria Queralt-Rosinach", "Michael Rautschka", "Laura I Furlong"], "venue": null, "citeRegEx": "Bravo et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Bravo et al\\.", "year": 2015}, {"title": "Extraction of semantic biomedical relations from text using conditional random fields", "author": ["Mathaeus Dejori", "Martin Stetter", "Volker Tresp", "Hans-Peter Kriegel"], "venue": "BMC bioinformatics,", "citeRegEx": "Bundschus et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Bundschus et al\\.", "year": 2008}, {"title": "Integrating co-occurrence statistics with information extraction for robust retrieval of protein interactions from medline", "author": ["Raymond Mooney", "Arun Ramani", "Edward Marcotte"], "venue": null, "citeRegEx": "Bunescu et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Bunescu et al\\.", "year": 2006}, {"title": "A unified architecture for natural language processing: Deep neural networks with multitask learning", "author": ["Collobert", "Weston2008] Ronan Collobert", "Jason Weston"], "venue": "In Proceedings of the 25th international conference on Machine learning,", "citeRegEx": "Collobert et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Collobert et al\\.", "year": 2008}, {"title": "Natural language processing (almost) from scratch", "author": ["Jason Weston", "L\u00e9on Bottou", "Michael Karlen", "Koray Kavukcuoglu", "Pavel Kuksa"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "Collobert et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Collobert et al\\.", "year": 2011}, {"title": "Dependency tree kernels for relation extraction", "author": ["Culotta", "Sorensen2004] Aron Culotta", "Jeffrey Sorensen"], "venue": "In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics,", "citeRegEx": "Culotta et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Culotta et al\\.", "year": 2004}, {"title": "Classifying relations by ranking with convolutional neural networks", "author": ["Bing Xiang", "Bowen Zhou"], "venue": "In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics", "citeRegEx": "Santos et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Santos et al\\.", "year": 2015}, {"title": "Semeval-2010 task 8: Multi-way classification", "author": ["Su Nam Kim", "Zornitsa Kozareva", "Preslav Nakov", "Diarmuid \u00d3 S\u00e9aghdha", "Sebastian Pad\u00f3", "Marco Pennacchiotti", "Lorenza Romano", "Stan Szpakowicz"], "venue": null, "citeRegEx": "Hendrickx et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Hendrickx et al\\.", "year": 2009}, {"title": "Relation extraction using support vector machine", "author": ["Gumwon Hong"], "venue": "In Natural Language Processing\u2013IJCNLP", "citeRegEx": "Hong.,? \\Q2005\\E", "shortCiteRegEx": "Hong.", "year": 2005}, {"title": "Convolutional neural network architectures for matching natural language sentences", "author": ["Hu et al.2014] Baotian Hu", "Zhengdong Lu", "Hang Li", "Qingcai Chen"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Hu et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hu et al\\.", "year": 2014}, {"title": "A convolutional neural network for modelling sentences", "author": ["Edward Grefenstette", "Phil Blunsom"], "venue": "arXiv preprint arXiv:1404.2188", "citeRegEx": "Kalchbrenner et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kalchbrenner et al\\.", "year": 2014}, {"title": "Deep visual-semantic alignments for generating image descriptions", "author": ["Karpathy", "Fei-Fei2014] Andrej Karpathy", "Li Fei-Fei"], "venue": "arXiv preprint arXiv:1412.2306", "citeRegEx": "Karpathy et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Karpathy et al\\.", "year": 2014}, {"title": "Convolutional neural networks for sentence classification", "author": ["Yoon Kim"], "venue": "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Kim.,? \\Q2014\\E", "shortCiteRegEx": "Kim.", "year": 2014}, {"title": "Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980", "author": ["Kingma", "Ba2014] Diederik Kingma", "Jimmy Ba"], "venue": null, "citeRegEx": "Kingma et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kingma et al\\.", "year": 2014}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["Ilya Sutskever", "Geoffrey E Hinton"], "venue": null, "citeRegEx": "Krizhevsky et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "A shallow parser based on closed-class words to capture relations in biomedical text", "author": ["Leroy et al.2003] Gondy Leroy", "Hsinchun Chen", "Jesse D Martinez"], "venue": "Journal of biomedical Informatics,", "citeRegEx": "Leroy et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Leroy et al\\.", "year": 2003}, {"title": "Kernel-based learning for biomedical relation extraction", "author": ["Li et al.2008] Jiexun Li", "Zhu Zhang", "Xin Li", "Hsinchun Chen"], "venue": "Journal of the American Society for Information Science and Technology,", "citeRegEx": "Li et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Li et al\\.", "year": 2008}, {"title": "Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781", "author": ["Kai Chen", "Greg Corrado", "Jeffrey Dean"], "venue": null, "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Hybrid methods for improving information", "author": ["Anne-Laure Ligozat", "Asma Ben Abacha", "Delphine Bernhard", "Bruno Cartoni", "Louise Del\u00e9ger", "Brigitte Grau", "Sophie Rosset", "Pierre Zweigenbaum", "Cyril Grouin"], "venue": null, "citeRegEx": "Minard et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Minard et al\\.", "year": 2011}, {"title": "Multi-class svm for relation extraction from clinical reports", "author": ["Anne-Laure Ligozat", "Brigitte Grau"], "venue": "In RANLP,", "citeRegEx": "Minard et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Minard et al\\.", "year": 2011}, {"title": "Distant supervision for relation extraction without labeled data", "author": ["Mintz et al.2009] Mike Mintz", "Steven Bills", "Rion Snow", "Dan Jurafsky"], "venue": "In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International", "citeRegEx": "Mintz et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Mintz et al\\.", "year": 2009}, {"title": "Bidirectional incremental parsing for automatic pathway identification with combinatory categorial grammar", "author": ["Park et al.2001] Jong C Park", "Hyun Sook Kim", "Jung-Jae Kim"], "venue": "In Pacific Symposium on Biocomputing,", "citeRegEx": "Park et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Park et al\\.", "year": 2001}, {"title": "Tree kernel-based proteinprotein interaction extraction from biomedical literature", "author": ["Qian", "Zhou2012] Longhua Qian", "Guodong Zhou"], "venue": "Journal of Biomedical Informatics,", "citeRegEx": "Qian et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Qian et al\\.", "year": 2012}, {"title": "Modeling relations and their mentions without labeled text", "author": ["Limin Yao", "Andrew McCallum"], "venue": "In Machine Learning and Knowledge Discovery in Databases,", "citeRegEx": "Riedel et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Riedel et al\\.", "year": 2010}, {"title": "Automatic extraction of relations between medical concepts in clinical texts", "author": ["Rink et al.2011] Bryan Rink", "Sanda Harabagiu", "Kirk Roberts"], "venue": "Journal of the American Medical Informatics Association,", "citeRegEx": "Rink et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Rink et al\\.", "year": 2011}, {"title": "Applying umls for distantly supervised relation detection", "author": ["Roller", "Stevenson2014] Roland Roller", "Mark Stevenson"], "venue": "In Proceedings of the 5th International Workshop on Health Text Mining and Information Analysis (Louhi),", "citeRegEx": "Roller et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Roller et al\\.", "year": 2014}, {"title": "Classifying semantic relations in bioscience texts", "author": ["Rosario", "Hearst2004] Barbara Rosario", "Marti A. Hearst"], "venue": "In Proceedings of the 42Nd Annual Meeting on Association for Computational Linguistics,", "citeRegEx": "Rosario et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Rosario et al\\.", "year": 2004}, {"title": "Enhancing biomedical text summarization using semantic relation extraction", "author": ["Shang et al.2011] Yue Shang", "Yanpeng Li", "Hongfei Lin", "Zhihao Yang"], "venue": "PLoS ONE,", "citeRegEx": "Shang et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Shang et al\\.", "year": 2011}, {"title": "Predicting online doctor ratings from user reviews using convolutional neural networks", "author": ["Samarth Tripathi", "Sunil K Sahu", "Sudhanshu Mittal", "Ashish Anand"], "venue": "International Journal of Machine Learning and Computing,", "citeRegEx": "Sharma et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Sharma et al\\.", "year": 2016}, {"title": "Relationship extraction methods based on co-occurrence in web pages and files", "author": ["Song et al.2011] Qiang Song", "Yousuke Watanabe", "Haruo Yokota"], "venue": "In Proceedings of the 13th International Conference on Information Integration and Web-based Applica-", "citeRegEx": "Song et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Song et al\\.", "year": 2011}, {"title": "Dropout: A simple way to prevent neural networks from overfitting", "author": ["Geoffrey Hinton", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan Salakhutdinov"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Srivastava et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Srivastava et al\\.", "year": 2014}, {"title": "Biobibliometrics: information retrieval and visualization from co-occurrences of gene names in medline abstracts", "author": ["Stapley", "Benoit2000] Benjamin J Stapley", "Gerry Benoit"], "venue": "In Pac Symp Biocomput,", "citeRegEx": "Stapley et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Stapley et al\\.", "year": 2000}, {"title": "Evaluating temporal relations in clinical text: 2012 i2b2 challenge", "author": ["Sun et al.2013] Weiyi Sun", "Anna Rumshisky", "Ozlem Uzuner"], "venue": "Journal of the American Medical Informatics Association,", "citeRegEx": "Sun et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Sun et al\\.", "year": 2013}, {"title": "Evaluating distributed word representations for capturing semantics of biomedical concepts", "author": ["TH et al.2015] MUNEEB TH", "Sunil Sahu", "Ashish Anand"], "venue": "In Proceedings of BioNLP", "citeRegEx": "TH et al\\.,? \\Q2015\\E", "shortCiteRegEx": "TH et al\\.", "year": 2015}, {"title": "Automatic extraction of protein interactions from scientific", "author": ["Thomas et al.2000] James Thomas", "David Milward", "Christos Ouzounis", "Stephen Pulman", "Mark Carroll"], "venue": "In Pacific symposium on biocomputing,", "citeRegEx": "Thomas et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Thomas et al\\.", "year": 2000}, {"title": "Evaluating the state-of-the-art in automatic de-identification", "author": ["Uzuner et al.2007] \u00d6zlem Uzuner", "Yuan Luo", "Peter Szolovits"], "venue": "Journal of the American Medical Informatics Association,", "citeRegEx": "Uzuner et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Uzuner et al\\.", "year": 2007}, {"title": "Identifying patient smoking status from medical discharge records", "author": ["Uzuner et al.2008] \u00d6zlem Uzuner", "Ira Goldstein", "Yuan Luo", "Isaac Kohane"], "venue": "Journal of the American Medical Informatics Association,", "citeRegEx": "Uzuner et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Uzuner et al\\.", "year": 2008}, {"title": "Extracting medication information from clinical text", "author": ["Uzuner et al.2010] \u00d6zlem Uzuner", "Imre Solti", "Eithon Cadag"], "venue": "Journal of the American Medical Informatics Association,", "citeRegEx": "Uzuner et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Uzuner et al\\.", "year": 2010}, {"title": "Bootstrapping Relation Extraction from Semantic Seeds", "author": ["Fei-Yu Xu"], "venue": "Ph.D. thesis,", "citeRegEx": "Xu.,? \\Q2008\\E", "shortCiteRegEx": "Xu.", "year": 2008}, {"title": "Kernel methods for relation extraction", "author": ["Chinatsu Aone", "Anthony Richardella"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Zelenko et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Zelenko et al\\.", "year": 2003}, {"title": "Relation classification via convolutional deep neural network", "author": ["Zeng et al.2014] Daojian Zeng", "Kang Liu", "Siwei Lai", "Guangyou Zhou", "Jun Zhao"], "venue": "COLING", "citeRegEx": "Zeng et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zeng et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 29, "context": "These relations are important for other upper level NLP tasks and also in biomedical and clinical research (Shang et al., 2011).", "startOffset": 107, "endOffset": 127}, {"referenceID": 3, "context": "In co-occurrence analysis it is assumed that if two entities are coming together in many sentences, their must be a relation between them (Bunescu et al., 2006; Song et al., 2011).", "startOffset": 138, "endOffset": 179}, {"referenceID": 31, "context": "In co-occurrence analysis it is assumed that if two entities are coming together in many sentences, their must be a relation between them (Bunescu et al., 2006; Song et al., 2011).", "startOffset": 138, "endOffset": 179}, {"referenceID": 36, "context": "Rule based methods are another commonly adapted methods for relation extraction task (Thomas et al., 2000; Park et al., 2001; Leroy et al., 2003).", "startOffset": 85, "endOffset": 145}, {"referenceID": 23, "context": "Rule based methods are another commonly adapted methods for relation extraction task (Thomas et al., 2000; Park et al., 2001; Leroy et al., 2003).", "startOffset": 85, "endOffset": 145}, {"referenceID": 16, "context": "Rule based methods are another commonly adapted methods for relation extraction task (Thomas et al., 2000; Park et al., 2001; Leroy et al., 2003).", "startOffset": 85, "endOffset": 145}, {"referenceID": 40, "context": "Bootstrapping method (Xu, 2008) is used to improve the performance of rule based methods.", "startOffset": 21, "endOffset": 31}, {"referenceID": 40, "context": "Bootstrapping uses small number of known relation pair of each relation type as a seed and use these seeds to search patterns in huge unannotated text (Xu, 2008) in iterative fashion.", "startOffset": 151, "endOffset": 161}, {"referenceID": 22, "context": "Distantly supervised method uses large knowledge base such as UMLS or Freebase as an input and extract patterns from huge corpus for all pair of relations present in knowledge base (Mintz et al., 2009; Riedel et al., 2010; Roller and Stevenson, 2014).", "startOffset": 181, "endOffset": 250}, {"referenceID": 25, "context": "Distantly supervised method uses large knowledge base such as UMLS or Freebase as an input and extract patterns from huge corpus for all pair of relations present in knowledge base (Mintz et al., 2009; Riedel et al., 2010; Roller and Stevenson, 2014).", "startOffset": 181, "endOffset": 250}, {"referenceID": 9, "context": "Feature based methods use sentences with predefined entities to construct feature vector through feature extraction (Hong, 2005; Minard et al., 2011b; Rink et al., 2011).", "startOffset": 116, "endOffset": 169}, {"referenceID": 26, "context": "Feature based methods use sentences with predefined entities to construct feature vector through feature extraction (Hong, 2005; Minard et al., 2011b; Rink et al., 2011).", "startOffset": 116, "endOffset": 169}, {"referenceID": 41, "context": "Kernel methods are extension of feature based methods which utilize kernel functions to exploit rich syntactic information such as parse trees (Zelenko et al., 2003; Culotta and Sorensen, 2004; Qian and Zhou, 2012; Zeng et al., 2014).", "startOffset": 143, "endOffset": 233}, {"referenceID": 42, "context": "Kernel methods are extension of feature based methods which utilize kernel functions to exploit rich syntactic information such as parse trees (Zelenko et al., 2003; Culotta and Sorensen, 2004; Qian and Zhou, 2012; Zeng et al., 2014).", "startOffset": 143, "endOffset": 233}, {"referenceID": 0, "context": "Further often these methods lead to huge number of features and may get affected from curse of dimensionality issues (Bengio et al., 2003; Collobert et al., 2011).", "startOffset": 117, "endOffset": 162}, {"referenceID": 5, "context": "Further often these methods lead to huge number of features and may get affected from curse of dimensionality issues (Bengio et al., 2003; Collobert et al., 2011).", "startOffset": 117, "endOffset": 162}, {"referenceID": 15, "context": "Convolution neural network has shown to be a powerful model for image processing, computer vision (Krizhevsky et al., 2012; Karpathy and Fei-Fei, 2014) and subsequently in natural language processing it has given state of the art results in different tasks such as sentence classification (Kim, 2014; Kalchbrenner et al.", "startOffset": 98, "endOffset": 151}, {"referenceID": 13, "context": ", 2012; Karpathy and Fei-Fei, 2014) and subsequently in natural language processing it has given state of the art results in different tasks such as sentence classification (Kim, 2014; Kalchbrenner et al., 2014; Hu et al., 2014; Sharma et al., 2016), relation classification (Zeng et al.", "startOffset": 173, "endOffset": 249}, {"referenceID": 11, "context": ", 2012; Karpathy and Fei-Fei, 2014) and subsequently in natural language processing it has given state of the art results in different tasks such as sentence classification (Kim, 2014; Kalchbrenner et al., 2014; Hu et al., 2014; Sharma et al., 2016), relation classification (Zeng et al.", "startOffset": 173, "endOffset": 249}, {"referenceID": 10, "context": ", 2012; Karpathy and Fei-Fei, 2014) and subsequently in natural language processing it has given state of the art results in different tasks such as sentence classification (Kim, 2014; Kalchbrenner et al., 2014; Hu et al., 2014; Sharma et al., 2016), relation classification (Zeng et al.", "startOffset": 173, "endOffset": 249}, {"referenceID": 30, "context": ", 2012; Karpathy and Fei-Fei, 2014) and subsequently in natural language processing it has given state of the art results in different tasks such as sentence classification (Kim, 2014; Kalchbrenner et al., 2014; Hu et al., 2014; Sharma et al., 2016), relation classification (Zeng et al.", "startOffset": 173, "endOffset": 249}, {"referenceID": 42, "context": ", 2016), relation classification (Zeng et al., 2014; dos Santos et al., 2015) and semantic role labeling (Collobert et al.", "startOffset": 33, "endOffset": 77}, {"referenceID": 5, "context": ", 2015) and semantic role labeling (Collobert et al., 2011).", "startOffset": 35, "endOffset": 59}, {"referenceID": 26, "context": "Current state of the art methods heavily depend on manual feature engineering and use hundreds of thousands of features (Minard et al., 2011b; Rink et al., 2011).", "startOffset": 120, "endOffset": 161}, {"referenceID": 39, "context": "Most of the participants in this challenge used support vector machine (SVM) with manually designed features (Uzuner et al., 2010).", "startOffset": 109, "endOffset": 130}, {"referenceID": 26, "context": "Model proposed by Rink et al. (2011) had first place in this task, which used six classes of features namely, context features, similarity features, nested related relation features, Wikipedia features, single concept features and vicinity features.", "startOffset": 18, "endOffset": 37}, {"referenceID": 17, "context": "Li et al. (2008) proposed kernel methods for relation extraction between entities in MEDLINE R \u00a9 articles.", "startOffset": 0, "endOffset": 17}, {"referenceID": 2, "context": "Conditional random field (CRF) has been used for relation extraction between disease treatment and gene by (Bundschus et al., 2008).", "startOffset": 107, "endOffset": 131}, {"referenceID": 1, "context": "Recently Bravo et al. (2015) proposed a system for identifying association between drug disease and target in EU-ADR dataset (van Mulligen et al.", "startOffset": 9, "endOffset": 29}, {"referenceID": 42, "context": "In contrast to above methods recently there are few work applying convolution neural network based models (Zeng et al., 2014; dos Santos et al., 2015) for relation classification in SemEval 2010 relation classification dataset (Hendrickx et al.", "startOffset": 106, "endOffset": 150}, {"referenceID": 8, "context": ", 2015) for relation classification in SemEval 2010 relation classification dataset (Hendrickx et al., 2009).", "startOffset": 84, "endOffset": 108}, {"referenceID": 35, "context": "For word embedding, we used pretrained word vector (TH et al., 2015) learned on Pubmed articles using word2vec tool (Mikolov et al.", "startOffset": 51, "endOffset": 68}, {"referenceID": 13, "context": "In order to get local features from each part of the sentence we have used multiple filters of different lengths (Kim, 2014) in all possible continuous n-gram of the sentence, where n is the length of filter (We have shown four filters with constant length three in the figure 1).", "startOffset": 113, "endOffset": 124}, {"referenceID": 35, "context": ", 2013a) on huge Pubmed open source articles (TH et al., 2015).", "startOffset": 45, "endOffset": 62}, {"referenceID": 13, "context": "In our experiment we use multiple such filters of variable length (Kim, 2014; Yin and Schtze, 2015).", "startOffset": 66, "endOffset": 99}, {"referenceID": 32, "context": "For regularization (Srivastava et al., 2014), we follow (Kim, 2014) and use dropout technique in output of max pooling layer.", "startOffset": 19, "endOffset": 44}, {"referenceID": 13, "context": ", 2014), we follow (Kim, 2014) and use dropout technique in output of max pooling layer.", "startOffset": 19, "endOffset": 30}, {"referenceID": 37, "context": "In recent years several challenges have been organized to automatically extract information from clinical texts (Uzuner et al., 2007; Uzuner et al., 2008; Uzuner et al., 2011; Uzuner et al., 2010; Sun et al., 2013).", "startOffset": 112, "endOffset": 214}, {"referenceID": 38, "context": "In recent years several challenges have been organized to automatically extract information from clinical texts (Uzuner et al., 2007; Uzuner et al., 2008; Uzuner et al., 2011; Uzuner et al., 2010; Sun et al., 2013).", "startOffset": 112, "endOffset": 214}, {"referenceID": 39, "context": "In recent years several challenges have been organized to automatically extract information from clinical texts (Uzuner et al., 2007; Uzuner et al., 2008; Uzuner et al., 2011; Uzuner et al., 2010; Sun et al., 2013).", "startOffset": 112, "endOffset": 214}, {"referenceID": 34, "context": "In recent years several challenges have been organized to automatically extract information from clinical texts (Uzuner et al., 2007; Uzuner et al., 2008; Uzuner et al., 2011; Uzuner et al., 2010; Sun et al., 2013).", "startOffset": 112, "endOffset": 214}, {"referenceID": 26, "context": "In our experiment we assume that entities and their types are already known like other existing works (Rink et al., 2011; Minard et al., 2011a; Minard et al., 2011b).", "startOffset": 102, "endOffset": 165}, {"referenceID": 26, "context": "We build a linear SVM classifier using similar features as defined in earlier studies (Rink et al., 2011) as a baseline for comparison.", "startOffset": 86, "endOffset": 105}], "year": 2016, "abstractText": "In recent years extracting relevant information from biomedical and clinical texts such as research articles, discharge summaries, or electronic health records have been a subject of many research efforts and shared challenges. Relation extraction is the process of detecting and classifying the semantic relation among entities in a given piece of texts. Existing models for this task in biomedical domain use either manually engineered features or kernel methods to create feature vector. These features are then fed to classifier for the prediction of the correct class. It turns out that the results of these methods are highly dependent on quality of user designed features and also suffer from curse of dimensionality. In this work we focus on extracting relations from clinical discharge summaries. Our main objective is to exploit the power of convolution neural network (CNN) to learn features automatically and thus reduce the dependency on manual feature engineering. We evaluate performance of the proposed model on i2b2-2010 clinical relation extraction challenge dataset. Our results indicate that convolution neural network can be a good model for relation exaction in clinical text without being dependent on expert\u2019s knowledge on defining quality features.", "creator": "LaTeX with hyperref package"}}}