{"id": "1606.09521", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Jun-2016", "title": "Probabilistic Reasoning in the Description Logic ALCP with the Principle of Maximum Entropy (Full Version)", "abstract": "A central question for knowledge representation is how to encode and handle uncertain knowledge adequately. We introduce the probabilistic description logic ALCP that is designed for representing context-dependent knowledge, where the actual context taking place is uncertain. ALCP allows the expression of logical dependencies on the domain and probabilistic dependencies on the possible contexts. In order to draw probabilistic conclusions, we employ the principle of maximum entropy. We provide reasoning algorithms for this logic, and show that it satisfies several desirable properties of probabilistic logics.", "histories": [["v1", "Thu, 30 Jun 2016 14:49:01 GMT  (27kb)", "http://arxiv.org/abs/1606.09521v1", "Full version of paper accepted at the Tenth International Conference on Scalable Uncertainty Management (SUM 2016)"]], "COMMENTS": "Full version of paper accepted at the Tenth International Conference on Scalable Uncertainty Management (SUM 2016)", "reviews": [], "SUBJECTS": "cs.AI cs.LO", "authors": ["rafael pe\\~naloza", "nico potyka"], "accepted": false, "id": "1606.09521"}, "pdf": {"name": "1606.09521.pdf", "metadata": {"source": "CRF", "title": "Probabilistic Reasoning in the Description Logic ALCP with the Principle of Maximum Entropy", "authors": ["Rafael Pe\u00f1aloza", "Nico Potyka"], "emails": ["rafael.penaloza@unibz.it", "npotyka@uni-osnabrueck.de"], "sections": [{"heading": null, "text": "ar Xiv: 160 6.09 521v 1 [cs.A I] 3 0Ju n"}, {"heading": "1 Introduction", "text": "A fundamental element of any intelligent application is the storage and manipulation of knowledge from the application domain. Logically based knowledge forms such as Description Logic (DLs) provide a clear syntax and unambiguous semantics that guarantee the accuracy of the results obtained. In particular, they are inadequate for dealing with the many areas of application."}, {"heading": "2 Maximum Entropy", "text": "We begin by focusing on the basic concepts of probability constraints, models, and the principle of maximum entropy. Let's be a propositional language constructed via a finite signature (L), i.e., a set of probability variables that are considered in the usual way. An L interpretation v is a truth assignment of probability variables in sig (L). A probability distribution over L is a function P: Int (L) \u2192 1), where the satisfaction of a formula to L is defined by an L interpretation v (L) (denotet v) is defined as usual. A probability distribution over L is a function P: Int (L) \u2192 [1], where the satisfaction v) P (v) = 1. Probability distributions are extended to arbitrary L-formulas."}, {"heading": "4 Computing Beliefs", "text": "In this section we show how to calculate faith intervals."}, {"heading": "5 Properties", "text": "We explore some properties of probability logic (22).First, we show that ALCP is invariant in language and representation (1). (1) D: 1) D: 1) D: 1) D: 1 (2) D: 1) D: 1 (2) D: 1 (2) D: 1) D: 1) D: 1) D: 2 (2) D: 2 (2) D: 2 (2) D: 2 (2) D: 2 (2) D: 2 (2) D: 2 (2) D: 2 (2) D: 2 (2) D: 2 (2) D: 2 (2) D: 2 (2) D: 2 (2) D: 2 (2) D: 2 (2) D: 2 (2) D: 2: D: 2 (2) D: 2 (2) D: 2 (2) D: 2 (2) D: 2 (2) D: 2 (2) D: 2 (2) D: 2 (2) D: 2 (2) D: 2 (2) D: 2 (2) D: 2 (2) D: 3 (2) D: 2 (2) (2) D: 2) (2) D: 2 (2) D: 2 (2) D: 2 (2) D: 2) (2) D: 2 (2) (2) D: 2 (2) D: 2 (2) D: 2) (2) D: 2 (2) D: 2 (2) D: 2 (2) D: 2 (2) (2) (2) D: 2 (2) D: 2 (2) (2) D: 2 (2) D: D: 2 (2) (2 (2) D: D: 2 (2) (2: D: 2) (2) (2) D: 2 (2: D: D: 2) (2) (2) (2) (2: D: 2) (2: D: 2) (2: D: 2) (2) (2) (2: D: D: 2) (2) D: D: 2 (2) (2) (2) (2) (2) (2: D: 2) (2) (2: D:"}, {"heading": "6 Related Work", "text": "Relational probabilistic logic approaches can be roughly divided into those that look at probability distributions over the domain, those that look at probability distributions over possible worlds, and those that combine both ideas. [10] Our framework belongs to the second group. Maximum entropy reasoning in propositional probabilistic logic has been extensively discussed, for example, in [13,22], and various extensions of first-class languages have been considered in recent years [3, 4, 14, 15]. In this work, the domain is limited to a limited number of constants or limited to the limit. We circumvent the need by combining a classical first-order logic with a boundless domain with a probabilistic logic with a fixed domain. Many probabilistic DLs have also been considered in recent decades [16, 18, 19]. Our approach is closest to Bayesian DLs [5, 6] and disposed [25]. The biggest difference from the first ALCALK probability distribution is that we require only a full distributional DLP, but only the ALCALCALK."}, {"heading": "7 Conclusions", "text": "We introduced the probabilistic DL ALCP, which expands the classical DL ALC with the ability to express and argue uncertain contextual knowledge defined by the principle of maximum entropy. Effective reasoning methods were developed using the decoupling between the logical and probabilistic components of ALCP KBs. We also investigated the properties of this logic in relation to other probabilistic logics. We plan to extend this work in several directions. Instead of first looking at the ME model, we could think about all probability distributions similar to our probabilistic limitations [12, 17, 20]. This leads to greater intervals in general. A smaller interval is preferable as it corresponds to a more precise degree of belief. However, if all probability distributions are used, the size of the interval can be a good indicator of the variation of possible beliefs in our query."}, {"heading": "Appendix: Proofs", "text": "Theorem K = (R, T) is a model for each model of PMI (I). Then each model (I) is such that PMER (v) > 0, Tv is consistent.Proof.For the \"if\" direction, let v1,.., vn \"Int (L) be all the L-Interpretations such that PMER (vi) > 0, 1 \u2264 i \u2264 n. Then, for each i, 1 \u2264 i \u2264 n the induced TBox Tvi has a classic model Ii = (\u2206 Ii, \u00b7 Ii), by assumption. It is easy to verify that the ALCP interpretation P = (I, PI) defines byI = {Ji = (i, vi) and PI (Ji) = PMER (vi) for all i (I)."}], "references": [{"title": "The Description Logic Handbook: Theory, Implementation, and Applications", "author": ["F. Baader", "D. Calvanese", "D.L. McGuinness", "D. Nardi", "Patel-Schneider", "P.F. (eds."], "venue": "Cambridge University Press, 2nd edn.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2007}, {"title": "Context-dependent views to axioms and consequences of semantic web ontologies", "author": ["F. Baader", "M. Knechtel", "R. Pe\u00f1aloza"], "venue": "J. of Web Semantics 12\u201313, 22\u201340", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2012}, {"title": "Maximum entropy inference with quantified knowledge", "author": ["O. Barnett", "J.B. Paris"], "venue": "Logic Journal of the IGPL 16(1), 85\u201398", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2008}, {"title": "Extending and completing probabilistic knowledge and beliefs without bias", "author": ["C. Beierle", "G. Kern-Isberner", "M. Finthammer", "N. Potyka"], "venue": "KI 29(3), 255\u2013262", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2015}, {"title": "The Bayesian description logic BEL", "author": ["I.I. Ceylan", "R. Pe\u00f1aloza"], "venue": "Proc. of IJCAR 2014. LNCS, vol. 8562, pp. 480\u2013494. Springer", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2014}, {"title": "Tractable reasoning with Bayesian description logics", "author": ["C. d\u2019Amato", "N. Fanizzi", "T. Lukasiewicz"], "venue": "Proc. SUM 2008. LNCS, vol. 5291, pp. 146\u2013159. Springer", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2008}, {"title": "Towards classifying propositional probabilistic logics", "author": ["G. De Bona", "F.G. Cozman", "M. Finger"], "venue": "J. of Applied Logic 12(3), 349\u2013368", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "Markov Logic: An Interface Layer for Artificial Intelligence", "author": ["P.M. Domingos", "D. Lowd"], "venue": "Synthesis Lectures on Artificial Intelligence and Machine Learning, Morgan & Claypool Publishers", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2009}, {"title": "ExpTime tableaux for ALC", "author": ["F.M. Donini", "F. Massacci"], "venue": "Artificial Intelligence 124(1), 87\u2013138", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2000}, {"title": "An analysis of first-order logics of probability", "author": ["J.Y. Halpern"], "venue": "Artificial Intelligence 46, 311\u2013350", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1990}, {"title": "Representation dependence in probabilistic inference", "author": ["J.Y. Halpern", "D. Koller"], "venue": "JAIR pp. 319\u2013356", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2004}, {"title": "Merging the local and global approaches to probabilistic satisfiability", "author": ["P. Hansen", "S. Perron"], "venue": "Intern. J. of Approx. Reasoning 47(2), 125 \u2013 140", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2008}, {"title": "Conditionals in nonmonotonic reasoning and belief revision", "author": ["G. Kern-Isberner"], "venue": "Springer, LNAI 2087", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2001}, {"title": "Novel semantical approaches to relational probabilistic conditionals", "author": ["G. Kern-Isberner", "M. Thimm"], "venue": "Proc. KR 2010. pp. 382\u2013391. AAAI Press", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2010}, {"title": "Combining probabilistic logic programming with the power of maximum entropy", "author": ["G. Kern-Isberner", "T. Lukasiewicz"], "venue": "Artif. Intell. 157(1-2), 139\u2013202", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2004}, {"title": "A hybrid method for probabilistic satisfiability", "author": ["P. Klinov", "B. Parsia"], "venue": "Proc. CADE 2011. LNCS, vol. 6803, pp. 354\u2013368. Springer", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2011}, {"title": "Probabilistic deduction with conditional constraints over basic events", "author": ["T. Lukasiewicz"], "venue": "JAIR 10, 380\u2013391", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1999}, {"title": "Managing uncertainty and vagueness in description logics for the semantic web", "author": ["T. Lukasiewicz", "U. Straccia"], "venue": "J. of Web Semantics 6(4), 291\u2013308", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2008}, {"title": "Probabilistic description logics for subjective uncertainty", "author": ["C. Lutz", "L. Schr\u00f6der"], "venue": "Proc. KR 2010. AAAI Press", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2010}, {"title": "Probabilistic logic", "author": ["N.J. Nilsson"], "venue": "Artificial Intelligence 28, 71\u201388", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1986}, {"title": "Numerical Optimization", "author": ["J. Nocedal", "S.J. Wright"], "venue": "Springer, 2nd edn.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2006}, {"title": "The uncertain reasoner\u2019s companion \u2013 A mathematical perspective", "author": ["J. Paris"], "venue": "Cambridge University Press", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1994}, {"title": "Reasoning over linear probabilistic knowledge bases with priorities", "author": ["N. Potyka"], "venue": "Proc. SUM 2015. vol. 9310, pp. 121\u2013136. Springer", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2015}, {"title": "Relationships between semantics for relational probabilistic conditional logics", "author": ["N. Potyka"], "venue": "Computational Models of Rationality, Essays dedicated to Gabriele Kern-Isberner. pp. 332\u2013347. College Publications", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2016}, {"title": "Epistemic and statistical probabilistic ontologies", "author": ["F. Riguzzi", "E. Bellodi", "E. Lamma", "R. Zese"], "venue": "Proc. URSW-12. vol. 900, pp. 3\u201314. CEUR-WS", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2012}, {"title": "Attributive concept descriptions with complements", "author": ["M. Schmidt-Schau\u00df", "G. Smolka"], "venue": "Artif. Intell. 48(1), 1\u201326", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1991}, {"title": "Information theory and network coding", "author": ["R.W. Yeung"], "venue": "Springer Science & Business Media", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2008}], "referenceMentions": [{"referenceID": 0, "context": "Logic-based knowledge representation languages such as description logics (DLs) [1] provide a clear syntax and unambiguous semantics that guarantee the correctness of the results obtained.", "startOffset": 80, "endOffset": 83}, {"referenceID": 2, "context": ", [3, 15, 20]).", "startOffset": 2, "endOffset": 13}, {"referenceID": 14, "context": ", [3, 15, 20]).", "startOffset": 2, "endOffset": 13}, {"referenceID": 19, "context": ", [3, 15, 20]).", "startOffset": 2, "endOffset": 13}, {"referenceID": 17, "context": "In particular, several probabilistic DLs have been developed [18, 19].", "startOffset": 61, "endOffset": 69}, {"referenceID": 18, "context": "In particular, several probabilistic DLs have been developed [18, 19].", "startOffset": 61, "endOffset": 69}, {"referenceID": 4, "context": "To handle probabilistic knowledge, many approaches require a complete definition of joint probability distributions (JPD) [5, 6, 8, 16, 25].", "startOffset": 122, "endOffset": 139}, {"referenceID": 5, "context": "To handle probabilistic knowledge, many approaches require a complete definition of joint probability distributions (JPD) [5, 6, 8, 16, 25].", "startOffset": 122, "endOffset": 139}, {"referenceID": 7, "context": "To handle probabilistic knowledge, many approaches require a complete definition of joint probability distributions (JPD) [5, 6, 8, 16, 25].", "startOffset": 122, "endOffset": 139}, {"referenceID": 15, "context": "To handle probabilistic knowledge, many approaches require a complete definition of joint probability distributions (JPD) [5, 6, 8, 16, 25].", "startOffset": 122, "endOffset": 139}, {"referenceID": 24, "context": "To handle probabilistic knowledge, many approaches require a complete definition of joint probability distributions (JPD) [5, 6, 8, 16, 25].", "startOffset": 122, "endOffset": 139}, {"referenceID": 21, "context": "One approach to avoid a full JPD specification was proposed by Paris [22]: the user gives a partial specification through a set of probabilistic constraints and the partial knowledge is completed by means of the principle of maximum entropy.", "startOffset": 69, "endOffset": 73}, {"referenceID": 25, "context": "To facilitate the understanding of our approach, we focus on the DL ALC [26] as a prototypical example of a knowledge representation language, and propositional probabilistic constraints as the framework for expressing uncertainty.", "startOffset": 72, "endOffset": 76}, {"referenceID": 0, "context": "In the worst-case, we get the trivial interval [0, 1], in the best case, we get a point probability where the upper and lower bounds coincide.", "startOffset": 47, "endOffset": 53}, {"referenceID": 0, "context": "A probability distribution over L is a function P : Int(L) \u2192 [0, 1] where \u2211", "startOffset": 61, "endOffset": 67}, {"referenceID": 16, "context": "For instance, probabilistic conditionals (\u03c8 | \u03c6)[l, u] are satisfied iff l \u00b7 P (\u03c6) \u2264 P (\u03c8 \u2227 \u03c6) \u2264 u \u00b7 P (\u03c6) [17].", "startOffset": 107, "endOffset": 111}, {"referenceID": 23, "context": "Sometimes P (\u03c6) > 0 is demanded, but strict inequalities are computationally difficult and the semantical differences are negligible in many cases, see [24] for a thorough discussion.", "startOffset": 152, "endOffset": 156}, {"referenceID": 26, "context": ", [27] for a more detailed discussion of these issues.", "startOffset": 2, "endOffset": 6}, {"referenceID": 21, "context": "A complete characterization of maximum entropy for the purpose of uncertain reasoning can be found in [22].", "startOffset": 102, "endOffset": 106}, {"referenceID": 20, "context": ", [21] for more details on these techniques.", "startOffset": 2, "endOffset": 6}, {"referenceID": 0, "context": "For a deeper introduction to classical ALC, see [1].", "startOffset": 48, "endOffset": 51}, {"referenceID": 0, "context": "The probability distribution P : Int(L) \u2192 [0, 1] induced by P is defined by P(v) := \u2211", "startOffset": 42, "endOffset": 48}, {"referenceID": 1, "context": "Notice first that subsumption and non-subsumption are monotonic consequences in the sense of [2]; that is, if an ALC TBox T entails the subsumption C \u2291 D, then every superset of T also entails this consequence.", "startOffset": 93, "endOffset": 96}, {"referenceID": 1, "context": "Thus, the consequence formulas from Definition 21 are in fact the socalled boundaries from [2].", "startOffset": 91, "endOffset": 94}, {"referenceID": 8, "context": "This approach requires 2 calls to a standard ALC reasoner, and each of these calls runs in exponential time on |T | [9].", "startOffset": 116, "endOffset": 119}, {"referenceID": 21, "context": "We now investigate some properties of probabilistic logics [22].", "startOffset": 59, "endOffset": 63}, {"referenceID": 10, "context": "For instance, in [11] a very different notion is considered, where the language and the knowledge base are changed simultaneously.", "startOffset": 17, "endOffset": 21}, {"referenceID": 21, "context": "As demonstrated by Paris in [22], measuring the difference between probabilistic knowledge bases is subtle and is best addressed by comparing knowledge bases extensionally; i.", "startOffset": 28, "endOffset": 32}, {"referenceID": 9, "context": "Relational probabilistic logical approaches can be roughly divided into those that consider probability distributions over the domain, those that consider probability distributions over possible worlds and those that combine both ideas [10].", "startOffset": 236, "endOffset": 240}, {"referenceID": 12, "context": ", in [13,22], and various extensions to first-order languages have been considered in recent years [3, 4, 14, 15].", "startOffset": 5, "endOffset": 12}, {"referenceID": 21, "context": ", in [13,22], and various extensions to first-order languages have been considered in recent years [3, 4, 14, 15].", "startOffset": 5, "endOffset": 12}, {"referenceID": 2, "context": ", in [13,22], and various extensions to first-order languages have been considered in recent years [3, 4, 14, 15].", "startOffset": 99, "endOffset": 113}, {"referenceID": 3, "context": ", in [13,22], and various extensions to first-order languages have been considered in recent years [3, 4, 14, 15].", "startOffset": 99, "endOffset": 113}, {"referenceID": 13, "context": ", in [13,22], and various extensions to first-order languages have been considered in recent years [3, 4, 14, 15].", "startOffset": 99, "endOffset": 113}, {"referenceID": 14, "context": ", in [13,22], and various extensions to first-order languages have been considered in recent years [3, 4, 14, 15].", "startOffset": 99, "endOffset": 113}, {"referenceID": 15, "context": "Many probabilistic DLs have also been considered in the last decades [16, 18, 19].", "startOffset": 69, "endOffset": 81}, {"referenceID": 17, "context": "Many probabilistic DLs have also been considered in the last decades [16, 18, 19].", "startOffset": 69, "endOffset": 81}, {"referenceID": 18, "context": "Many probabilistic DLs have also been considered in the last decades [16, 18, 19].", "startOffset": 69, "endOffset": 81}, {"referenceID": 4, "context": "Our approach is closest to Bayesian DLs [5, 6] and disponte [25].", "startOffset": 40, "endOffset": 46}, {"referenceID": 5, "context": "Our approach is closest to Bayesian DLs [5, 6] and disponte [25].", "startOffset": 40, "endOffset": 46}, {"referenceID": 24, "context": "Our approach is closest to Bayesian DLs [5, 6] and disponte [25].", "startOffset": 60, "endOffset": 64}, {"referenceID": 11, "context": "First, instead of considering the ME-model, we could reason over all probability distributions that satisfy our probabilistic constraints similar to [12, 17, 20].", "startOffset": 149, "endOffset": 161}, {"referenceID": 16, "context": "First, instead of considering the ME-model, we could reason over all probability distributions that satisfy our probabilistic constraints similar to [12, 17, 20].", "startOffset": 149, "endOffset": 161}, {"referenceID": 19, "context": "First, instead of considering the ME-model, we could reason over all probability distributions that satisfy our probabilistic constraints similar to [12, 17, 20].", "startOffset": 149, "endOffset": 161}, {"referenceID": 3, "context": "In some applications it is also useful to allow more expressive propositional or relational context languages like those proposed in [4, 7, 15, 23].", "startOffset": 133, "endOffset": 147}, {"referenceID": 6, "context": "In some applications it is also useful to allow more expressive propositional or relational context languages like those proposed in [4, 7, 15, 23].", "startOffset": 133, "endOffset": 147}, {"referenceID": 14, "context": "In some applications it is also useful to allow more expressive propositional or relational context languages like those proposed in [4, 7, 15, 23].", "startOffset": 133, "endOffset": 147}, {"referenceID": 22, "context": "In some applications it is also useful to allow more expressive propositional or relational context languages like those proposed in [4, 7, 15, 23].", "startOffset": 133, "endOffset": 147}], "year": 2016, "abstractText": "A central question for knowledge representation is how to encode and handle uncertain knowledge adequately. We introduce the probabilistic description logic ALCP that is designed for representing context-dependent knowledge, where the actual context taking place is uncertain. ALCP allows the expression of logical dependencies on the domain and probabilistic dependencies on the possible contexts. In order to draw probabilistic conclusions, we employ the principle of maximum entropy. We provide reasoning algorithms for this logic, and show that it satisfies several desirable properties of probabilistic logics.", "creator": "LaTeX with hyperref package"}}}