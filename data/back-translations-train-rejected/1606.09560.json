{"id": "1606.09560", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Jun-2016", "title": "Neural Network-based Word Alignment through Score Aggregation", "abstract": "We present a simple neural network for word alignment that builds source and target word window representations to compute alignment scores for sentence pairs. To enable unsupervised training, we use an aggregation operation that summarizes the alignment scores for a given target word. A soft-margin objective increases scores for true target words while decreasing scores for target words that are not present. Compared to the popular Fast Align model, our approach improves alignment accuracy by 7 AER on English-Czech, by 6 AER on Romanian-English and by 1.7 AER on English-French alignment.", "histories": [["v1", "Thu, 30 Jun 2016 16:32:00 GMT  (91kb,D)", "http://arxiv.org/abs/1606.09560v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["joel legrand", "michael auli", "ronan collobert"], "accepted": false, "id": "1606.09560"}, "pdf": {"name": "1606.09560.pdf", "metadata": {"source": "CRF", "title": "Neural Network-based Word Alignment through Score Aggregation", "authors": ["Jo\u00ebl Legrand", "Michael Auli", "Ronan Collobert"], "emails": [], "sections": [{"heading": null, "text": "We introduce a simple neural word alignment network that builds up source and target window representations to calculate alignment values for sentence pairs. To enable unattended training, we use an aggregation operation that summarizes alignment values for a given target word. A soft margin target increases the values for real target words while reducing the values for non-existing target words. Compared to the popular Fast Align model, our approach improves alignment accuracy by 7 AER in English, 6 AER in Romanian-English, and 1.7 AER in English-French."}, {"heading": "1 Introduction", "text": "Word alignment is the task of finding the match between source and target words in a sentence that are translations from each other. Generative models for this task (Brown et al., 1990; Och and Ney, 2003; Vogel et al., 1996) still form the basis for many machine translation systems (Koehn et al., 2003; Chiang, 2007). Recent neural approaches include Yang et al. (2013), which introduce a forward-looking network model trained on alignments generated by a traditional generative model, which treats potentially faulty alignments as oversight. Tamura et al. (2014) sidesteps this problem by negative sampling to form a recursive-neural network based on data. They optimize a global loss that requires costly beam search to approximate the sum across all alignments."}, {"heading": "2 Aggregation Model", "text": "In the following, we will consider a target-source sentence pair (e, f), with e = (e1,..., e | e |) and f = (f1,.., f | f | |). Words are represented by fj and ei, which are indexes in source and target dictionaries. For simplicity, we assume that word indexes are the only feature of our architecture. Faced with a source word fj and a target word ei, our architecture embeds a window (size d f winar Xiv: 160 6.09 560v 1 [cs.C L] 30 Jun 2016 or dewin) around each of these words in a demb-dimensional vector space. The embedding operation is performed with two different neural networks: nete ([e] dewin i), Rdemband netf ([f] dfwin j), specifying the window operator as [x] alai / 2, a high-quality word (ei)."}, {"heading": "2.1 Unsupervised Training", "text": "In this paper, we are looking at an uncontrolled constellation where the alignment is not known at the time of training, so we cannot minimize or maximize matching scores (1) in a direct way. Instead, we are looking at the aggregated matching scores above the source sentence for a target word ei: saggr (i, f) = | f | Aggr j = 1 s (i, j), (2) where Aggr is an aggregation operator (\u00a7 2.2). Let's look at a matching (positive) sentence pair (e +, f) and a negative sentence pair (e \u2212, f). If we look at a word with index i + in the positive target sentence, we want to maximize the aggregated score saggr (i +, f) (1 \u2264 i + \u2264 | e + |) because we know that it should be aligned to at least one source word."}, {"heading": "2.2 Choosing the Aggregation", "text": "The aggregation operation (2) is only present during the training and serves as a filter aimed at explaining a particular target word ei by one or more source words. If we had the word alignments, we would add fj to the source words that are consistent with ei. However, in our setup alignments are not available at the time of training, so we have to rely on what the model has learned so far to filter the source words. We consider the following strategies: \u2022 Sum: ignore the knowledge learned so far and assign the same weight to all source words fj to ei.2 In this case, the aggregation is written as: saggr (i, f) = | f | j max = 1 s (i, j). \u2022 Max: promote the best aligned source word fj according to what the model has learned so far. In this case, the aggregation is written as: saggr (i, f) = f | j max = 1 source words (weights similar to LSE)."}, {"heading": "2.3 Decoding", "text": "At test date, we align each target word ei with the source word fj for which the matching score s (i, j) in (1) is highest. 3 However, not every target word is aligned, so we only consider alignments with a matching score above a threshold: s (i, j) > \u00b5 \u2212 (ei) + \u03b1\u03c3 \u2212 (ei), (5) 2This can be seen from the observation that the gradients are the same for all source words. 3This can cause a source word to be aligned with multiple target words. Where \u03b1 is a tunable hyperparameter, and \u00b5 \u2212 (ei) = E {e \u00b2 k = ei \u00b2 e, f \u00b2 j \u00b2 f \u00b2 is [s (k, j \u2212)] the expectation for all training sets containing the word ei, and all words f \u00b2 \u2212 j that belong to a corresponding negative source sentence f \u00b2 \u2212 (ei)."}, {"heading": "3 Neural Network Architecture", "text": "Our model consists of two revolutionary neural networks, net and netf, as shown in (1), both of which have the same shape, so we can only detail the target architecture."}, {"heading": "3.1 Word embeddings", "text": "The individual features [e] d e wini are embedded in a detemb-dimensional vector space via a searchable operation first introduced in Bengio et al. (2000): xei = LTW e ([e] dewin i) = (LTW e (ei \u2212 dewin / 2),..., LTW e (ei + dewin / 2)), where the search table with index k returns the smallest column of the parameter matrix W e: LTW e (k) = W e \u2022, k. The matrix W e is of size | Ve | \u00d7 deemb, where Ve is the target vocabulary and deemb is the word embed size for the target words."}, {"heading": "3.2 Convolutional layers", "text": "The word embedding output from the lookup table is concatenated and passed through two successive 1-D folding layers. Folds use a step size of one and extract context properties for each word. Core sizes ke1 and k e 2 determine the size of the window dewin = k e 1 + k e 2 \u2212 1 over which the characters of nete are extracted. To get windows around each word, we add (ke1 + k e 2) / 2 \u2212 1 padding words at the beginning and end of each sentence. The first layer cnne applies the linear transformationM e, 1 exactly ke2 times to consecutive size ranges ke1 to the d e winning words in a specific window: cnne (xei) = M e, 1 LTW e ([e] ke1 i \u2212 a)... LTW e ([e] ke1 i + a), where a = bk stretches e 2, c \u00b7 e (e) x (e) is the first layer."}, {"heading": "3.3 Additional Features", "text": "In addition to the raw word indices, we look at two other discrete features that have been treated in the same way as word attributes by adding an additional search table for each of these attributes; the output of all search word indices has been concatenated and fed into the two-tiered neural network architecture (6); the distance to the diagonal; this function can be calculated for one target word ei and one source word fj: diag (i, j) = closest network structures, since it encodes relative position information that needs to be encoded only once; if we used the absolute position instead, we would have to encode that information on both the source and target pages; word pairs that are good translations of each other; & & & < < Words that need to be encoded only once. If we use the absolute position instead, we would have to encode that information both on the source and on the destination pages."}, {"heading": "4 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Datasets", "text": "We use the Anglo-French Hansards corpus as distributed by the joint task NAACL 2003 (Mihalcea and Pedersen, 2003), which contains 1.1 million set pairs and the test and validation sets contain 447 and 37 examples, respectively. We also evaluate the Romanian-English set of joint task ACL 2005 (Martin et al., 2005), which includes 48K set pairs for training, 248 for testing and 17 for validation. For English Czech experiments, we use the WMT news commentary corpus for training (150K set pairs) and a set of 515 sets for testing (Bojar and Prokopova, 2006)."}, {"heading": "4.2 Evaluation", "text": "Our models are evaluated in terms of precision, recall, F-measure and alignment error rate (AER). We train models in each language direction and symmetrize the resulting alignments either by the intersection or the Grow-Diag-Final-and-Heuristic (Och and Ney, 2003; Koehn et al., 2003). We validate the choice of symmetry heuristics for each language pair and select the best for each model taking into account the above two types as well as Grow-Diag-Final and Grow Diagram. Additionally, we train phrase-based machine translation models with our alignments using the popular Moses toolkit (Koehn et al., 2007). For English-French, we train on the News Commentary v10, for English-Czech on the News Comment Corpus v11 and for Romanian-English on the Europarl Corpus v8. We have adapted our models to English from the WT2015 WT results for English and for French as well as for Romanian-MIBM."}, {"heading": "4.3 Setup", "text": "The core sizes of the source network netf (\u00b7) are set to ke1 = k e > 2 = 3 for all language pairs; the core sizes of the source network netf (\u00b7) are set to kf1 = k f 2 = 3 for Romanian-English and English-Czech; and for English-French we use kf1 = k f 2 = 1. The number of hidden units is dehu = d f hu = 256 and demb is set to 256; the source words Vf and Target Ve dictionaries consist of the 30K most common words for English, French and Romanian, and 80K for Czech; all other words are mapped to a unique UNK token \u2212 igling; the word embedding the sizes deemb and d f emb, as well as the char-n-gram embedding size is 128; for LSE we use r = 1 in (4).We initialize the word embedding with a simple PCA, the matrix is put together."}, {"heading": "4.4 Results", "text": "First, we examine various options for the aggregation operator (\u00a7 2.2), followed by ablation to examine the effects of the various additional features (\u00a7 3.3). Next, we compare the Fast Align baseline. Finally, we evaluate our orientations within a complete translation system for all language pairs."}, {"heading": "4.4.1 Aggregation operation", "text": "Table 1 shows that the LogSumExp (LSE) aggregator performs best in all datasets for each direction and in the symmetric environment using Grow Diag Final Heuristics. All results are based on a single model trained with the \"distance to diagonal\" feature detailed above. 4 We therefore use LSE for the remaining experiments."}, {"heading": "4.4.2 Additional features", "text": "Table 2 shows the effect of the different input characteristics. Both the POS and the distance to the diagonal characteristic greatly improve accuracy. Position information about the \"distance to the diagonal\" characteristic is helpful for all language pairs, and the POS information is more effective for Romanian English and English-Czech, which contain morphologically rich languages."}, {"heading": "4.4.3 Comparison with the baseline", "text": "In the following results, we refer to our model as NNSA (Neural Network Score Aggregation). Based on Anglo-French data (Table 3), our model exceeds the baseline in each language direction by 1.7 AER (from 11.4 to 9.7), and with an individual model we exceed it by 1.2 AER (from 11.4 to 10.2). Note that the choice of symmetrical heuristics significantly influences the accuracy of both the baseline and NNSA.4We use the kernel sizes ke1 = ke2 = 3 and k f 1 = k f 2 = 1 for all language pairs in this experiment.In Romanian-English (Table 4), our model also exceeds the baseline in both directions. Adding ensembles further improves the accuracy and leads to a significant improvement of 6 AER over the best symmetrized baseline result (from 32 to 26) and the better symmetrical result to the Czech baseline (5)."}, {"heading": "4.4.4 BLEU evaluation", "text": "Table 6 presents the BLEU evaluation of our alignments. For each language pair, we select the best alignment model described in Tables 3, 4, and 5, and match the training data. We use the alignments to break through the standard phrase-based training pipeline based on these alignments. Our BLEU results show the average BLEU score and standard deviation for five passes of training with minimal error rate (MERT; Och 2003). Our alignments achieve slightly better results for Romanian-English and English-Czech, while catching up with Fast Align in English-French translation."}, {"heading": "5 Analysis", "text": "In this section, we will analyze the word representations learned through our model. We will first focus on the source representations: in a source window, we will obtain their distribution representation and then calculate the Euclidean distance to all other source windows in the training corpus. Table 7 shows the closest windows for two source windows; the closest windows tend to have similar meanings. Then, we will analyze the relationship between source and target representations: In one source window, we will calculate the alignment values for all targets in the training corpus. Table 8 shows for two source windows which target words have the greatest alignment values. The example of \"working together\" is particularly interesting because the aligned target words collabore, coordone's and concerte's work together, coordinated and coordinated, meaning that they all have the same meaning as the source window phrase."}, {"heading": "6 Conclusion", "text": "Our model calculates alignment values as point products between representations of windows around source and target words. We apply an aggregation process borrowed from computer vision literature to enable unattended training; the aggregation process acts as a filter on alignment values and allows us to determine which source words explain a given target term; we improve on Fast Align, a popular IBM Model 2 loglinear repair parameterization (Dyer et al., 2013) by up to 6 AER in Romanian, 7 AER in English-Czech, and 1.7 AER in English-French. In addition, we evaluated our model as part of a complete machine translation pipeline and showed that our alignments are better or equivalent compared to Fast Align in terms of BLEU."}], "references": [{"title": "A Neural Probabilistic Language Model", "author": ["Yoshua Bengio", "R\u00e9jean Ducharme", "Pascal Vincent"], "venue": "In NIPS,", "citeRegEx": "Bengio et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 2000}, {"title": "CzechEnglish Word Alignment", "author": ["Ond\u0159ej Bojar", "Magdalena Prokopov\u00e1"], "venue": "In Proceedings of the Fifth International Conference on Language Resources and Evaluation", "citeRegEx": "Bojar and Prokopov\u00e1.,? \\Q2006\\E", "shortCiteRegEx": "Bojar and Prokopov\u00e1.", "year": 2006}, {"title": "Hierarchical Phrase-Based Translation", "author": ["David Chiang"], "venue": "Computational Linguistics,", "citeRegEx": "Chiang.,? \\Q2007\\E", "shortCiteRegEx": "Chiang.", "year": 2007}, {"title": "A simple, fast, and effective reparameterization of IBM Model 2", "author": ["Chris Dyer", "Victor Chahuneau", "Noah A. Smith"], "venue": "In Proc. of NAACL,", "citeRegEx": "Dyer et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Dyer et al\\.", "year": 2013}, {"title": "Statistical Phrase-based Translation", "author": ["Philipp Koehn", "Franz J. Och", "Daniel Marcu"], "venue": "In Proc. of NAACL,", "citeRegEx": "Koehn et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Koehn et al\\.", "year": 2003}, {"title": "Open source toolkit for statistical machine translation", "author": ["Herbst. Moses"], "venue": "In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, ACL", "citeRegEx": "Moses,? \\Q2007\\E", "shortCiteRegEx": "Moses", "year": 2007}, {"title": "Word Embeddings through Hellinger PCA", "author": ["R\u00e9mi Lebret", "Ronan Collobert"], "venue": "In Proc. of EACL,", "citeRegEx": "Lebret and Collobert.,? \\Q2014\\E", "shortCiteRegEx": "Lebret and Collobert.", "year": 2014}, {"title": "Word Alignment For Languages With Scarce Resources", "author": ["Joel Martin", "Rada Mihalcea", "Ted Pedersen"], "venue": "In Proc. of WPT,", "citeRegEx": "Martin et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Martin et al\\.", "year": 2005}, {"title": "Automatic evaluation and uniform filter cascades for inducing n-best translation lexicons", "author": ["Dan I. Melamed"], "venue": "In Third Workshop on Very Large Corpora,", "citeRegEx": "Melamed.,? \\Q1995\\E", "shortCiteRegEx": "Melamed.", "year": 1995}, {"title": "An Evaluation Exercise for Word Alignment", "author": ["Rada Mihalcea", "Ted Pedersen"], "venue": "In Proc. of WPT,", "citeRegEx": "Mihalcea and Pedersen.,? \\Q2003\\E", "shortCiteRegEx": "Mihalcea and Pedersen.", "year": 2003}, {"title": "Efficient higher-order CRFs for morphological tagging", "author": ["Thomas Mueller", "Helmut Schmid", "Hinrich Sch\u00fctze"], "venue": "In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Mueller et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mueller et al\\.", "year": 2013}, {"title": "A Systematic Comparison of Various Statistical Alignment Models", "author": ["Franz J. Och", "Hermann Ney"], "venue": "Computational Linguistics,", "citeRegEx": "Och and Ney.,? \\Q2003\\E", "shortCiteRegEx": "Och and Ney.", "year": 2003}, {"title": "Minimum error rate training in statistical machine translation", "author": ["Franz Josef Och"], "venue": "In Proc of ACL,", "citeRegEx": "Och.,? \\Q2003\\E", "shortCiteRegEx": "Och.", "year": 2003}, {"title": "From Image-level to Pixel-level Labeling with Convolutional Networks", "author": ["Pedro O. Pinheiro", "Ronan Collobert"], "venue": "In Proc. of CVPR,", "citeRegEx": "Pinheiro and Collobert.,? \\Q2015\\E", "shortCiteRegEx": "Pinheiro and Collobert.", "year": 2015}, {"title": "Recurrent Neural Networks for Word Alignment Model", "author": ["Akihiro Tamura", "Taro Watanabe", "Eiichiro Sumita"], "venue": "In Proc. of ACL,", "citeRegEx": "Tamura et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Tamura et al\\.", "year": 2014}, {"title": "HMM-Based Word Alignment in Statistical Translation", "author": ["Stephan Vogel", "Hermann Ney", "Christoph Tillmann"], "venue": "In Proc. of COLING,", "citeRegEx": "Vogel et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Vogel et al\\.", "year": 1996}, {"title": "Word Alignment Modeling with Context Dependent Deep Neural Network", "author": ["Nan Yang", "Shujie Liu", "Mu Li", "Ming Zhou", "Nenghai Yu"], "venue": "In Proc. of ACL,", "citeRegEx": "Yang et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Yang et al\\.", "year": 2013}], "referenceMentions": [{"referenceID": 11, "context": "Generative models for this task (Brown et al., 1990; Och and Ney, 2003; Vogel et al., 1996) still form the basis for many machine translation systems (Koehn et al.", "startOffset": 32, "endOffset": 91}, {"referenceID": 15, "context": "Generative models for this task (Brown et al., 1990; Och and Ney, 2003; Vogel et al., 1996) still form the basis for many machine translation systems (Koehn et al.", "startOffset": 32, "endOffset": 91}, {"referenceID": 4, "context": ", 1996) still form the basis for many machine translation systems (Koehn et al., 2003; Chiang, 2007).", "startOffset": 66, "endOffset": 100}, {"referenceID": 2, "context": ", 1996) still form the basis for many machine translation systems (Koehn et al., 2003; Chiang, 2007).", "startOffset": 66, "endOffset": 100}, {"referenceID": 15, "context": "Recent neural approaches include Yang et al. (2013) who introduce a feed-forward networkbased model trained on alignments that were generated by a traditional generative model.", "startOffset": 33, "endOffset": 52}, {"referenceID": 14, "context": "Tamura et al. (2014) sidesteps this issue by negative sampling to train a recurrent-neural network on unlabeled data.", "startOffset": 0, "endOffset": 21}, {"referenceID": 13, "context": "The model can be easily trained on unlabeled data via a novel but simple aggregation operation which has been successfully applied in the computer vision literature (Pinheiro and Collobert, 2015).", "startOffset": 165, "endOffset": 195}, {"referenceID": 0, "context": "1 Word embeddings The discrete features [e] e win i are embedded into a demb-dimensional vector space via a lookuptable operation as first introduced in Bengio et al. (2000):", "startOffset": 153, "endOffset": 174}, {"referenceID": 8, "context": "Part-of-speech Words pairs that are good translations of each other are likely to carry the same part of speech in both languages (Melamed, 1995).", "startOffset": 130, "endOffset": 145}, {"referenceID": 9, "context": "We use the English-French Hansards corpus as distributed by the NAACL 2003 shared task (Mihalcea and Pedersen, 2003).", "startOffset": 87, "endOffset": 116}, {"referenceID": 7, "context": "We also evaluate on the Romanian-English dataset of the ACL 2005 shared task (Martin et al., 2005) comprising 48K sentence pairs for training, 248 for testing and 17 for validation.", "startOffset": 77, "endOffset": 98}, {"referenceID": 1, "context": "For EnglishCzech experiments, we use the WMT news commentary corpus for training (150K sentence pairs) and a set of 515 sentences for testing (Bojar and Prokopov\u00e1, 2006).", "startOffset": 142, "endOffset": 169}, {"referenceID": 11, "context": "We train models in each language direction and then symmetrize the resulting alignments using either the intersection or the grow-diag-final-and heuristic (Och and Ney, 2003; Koehn et al., 2003).", "startOffset": 155, "endOffset": 194}, {"referenceID": 4, "context": "We train models in each language direction and then symmetrize the resulting alignments using either the intersection or the grow-diag-final-and heuristic (Och and Ney, 2003; Koehn et al., 2003).", "startOffset": 155, "endOffset": 194}, {"referenceID": 3, "context": "We compare our model to Fast Align, a popular log-linear reparameterization of IBM Model 2 (Dyer et al., 2013).", "startOffset": 91, "endOffset": 110}, {"referenceID": 6, "context": "We initialize the word embeddings with a simple PCA computed over the matrix of word cooccurrence counts (Lebret and Collobert, 2014).", "startOffset": 105, "endOffset": 133}, {"referenceID": 10, "context": "For part of speech tagging we used the Stanford parser on English-French data, and MarMoT (Mueller et al., 2013) for Romanian-English as well as English-Czech.", "startOffset": 90, "endOffset": 112}, {"referenceID": 3, "context": "On English-French data (Table 3) our model outperforms the baseline (Dyer et al., 2013) in each individual language direction as well as for the symmetrized setting.", "startOffset": 68, "endOffset": 87}, {"referenceID": 3, "context": "We improve over Fast Align, a popular loglinear reparameterization of IBM Model 2 (Dyer et al., 2013) by up to 6 AER on RomanianEnglish, 7 AER on English-Czech data and 1.", "startOffset": 82, "endOffset": 101}], "year": 2016, "abstractText": "We present a simple neural network for word alignment that builds source and target word window representations to compute alignment scores for sentence pairs. To enable unsupervised training, we use an aggregation operation that summarizes the alignment scores for a given target word. A soft-margin objective increases scores for true target words while decreasing scores for target words that are not present. Compared to the popular Fast Align model, our approach improves alignment accuracy by 7 AER on EnglishCzech, by 6 AER on Romanian-English and by 1.7 AER on English-French alignment.", "creator": "LaTeX with hyperref package"}}}