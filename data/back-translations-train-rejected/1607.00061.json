{"id": "1607.00061", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Jun-2016", "title": "Towards A Virtual Assistant That Can Be Taught New Tasks In Any Domain By Its End-Users", "abstract": "The challenge stated in the title can be divided into two main problems. The first problem is to reliably mimic the way that users interact with user interfaces. The second problem is to build an instructible agent, i.e. one that can be taught to execute tasks expressed as previously unseen natural language commands. This paper proposes a solution to the second problem, a system we call Helpa. End-users can teach Helpa arbitrary new tasks whose level of complexity is similar to the tasks available from today's most popular virtual assistants. Teaching Helpa does not involve any programming. Instead, users teach Helpa by providing just one example of a command paired with a demonstration of how to execute that command. Helpa does not rely on any pre-existing domain-specific knowledge. It is therefore completely domain-independent. Our usability study showed that end-users can teach Helpa many new tasks in less than a minute each, often much less.", "histories": [["v1", "Thu, 30 Jun 2016 22:04:26 GMT  (70kb,D)", "http://arxiv.org/abs/1607.00061v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["i dan melamed", "nobal b niraula"], "accepted": false, "id": "1607.00061"}, "pdf": {"name": "1607.00061.pdf", "metadata": {"source": "CRF", "title": "Towards A Virtual Assistant That Can Be Taught New Tasks In Any Domain By Its End-Users", "authors": ["I. Dan Melamed", "Nobal B. Niraula"], "emails": ["lastname@microsoft.com", "nbnraula@memphis.edu"], "sections": [{"heading": "1 Introduction", "text": "In fact, most people who are able to survive themselves are also able to survive themselves. Most people who are able to survive themselves are able to survive themselves. Most of them are able to survive themselves. Most of them are able to survive themselves. Most of them are able to survive themselves. Most of them are able to survive themselves. Most of them are able to survive themselves. Most of them are able to survive themselves. Most of them are able to survive themselves. Most of them are able to survive themselves. Most of them are able to survive themselves. Most of them are able to survive themselves. Most of them are able to survive themselves. Most of them are able to survive themselves. Most of them are able to survive themselves."}, {"heading": "2 The Instructible Agent (IA) Problem", "text": "The IA problem is to build a system that can correctly execute a task that is expressed as a previously invisible command in the natural language. We will leave aside the question of what counts as a natural language by accepting any string as a command. It is more difficult to operationalize the notion of executing a task. Each PBD system interacts with a specific user interface (UI). It records the actions of the user in that user interface when a user demonstrates a new task for him to learn. It mimics the actions of the user in that user interface to perform tasks he has learned. Reliable interaction with a user interface in that way is a challenging problem (e.g. see [10]). The current work makes no attempt to solve it. Rather, we abstract the notion of task execution into a data structure that we call a \"UI script.\" We assume that if a UI records a user's two actions, the result of a PD is a script."}, {"heading": "3 Helpa", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Model", "text": "This year it has come to the point that it has never come as far as this year."}, {"heading": "3.2 System Architecture and Components", "text": "There are two operating modes: learning and execution, illustrated in Figures 2 and 3, respectively. In both figures, dashed lines delineate the boundary of the Helpa system, and numbers indicate the sequence of events. Both modes use a database of tasks in which each record consists of a command template, a program, and a variable binding function. Tasks are created in learning mode and executed in execution. The user initiates the learning mode by starting the UI recorder (1). The user then delivers a sample command (2) and demonstrates how to execute the command (3a). During the demo, the recorder is executed transparently for the user and for the UI. It records all relevant actions and responses from the UI (3b). When the user stops the recorder (4), the recorder writes a UI script (5)."}, {"heading": "3.3 Limitations", "text": "t even know that \"April 4, 2016\" is the same as \"04 / 04 / 16.\" 11 Even knowing how to run \"Find X\" does not help Helpa run \"Search for X.\" For the learner to work, the variable values in the command must be identical to the values in the UI script. 11 The literature offers a variety of techniques to overcome this limitation. For example, we could use statistical rewriting generations [13] to proactively expand a newly derived command template into a number of possible rewrites and store them all in the task database associated with the same task."}, {"heading": "4 Usability Study", "text": "Our working hypothesis in building Helpa was that in the vast majority of cases learning to predict non-branched programs using natural voice commands does not require domain knowledge and only the most rudimentary NLP. Our usability study was designed to test this hypothesis in terms of Helpa task fulfillment rates for users who were not involved in the development of Helpa. We also wanted to measure how long it takes for users to teach Helpa new tasks."}, {"heading": "4.1 Design of the Study", "text": "In fact, it is the case that most of them are able to survive themselves without there being a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process, a process in which there is a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process and a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, a process, and a process, a process, a process, a process, a process, a process, a process, and a process, a process, a process, a process, a process, a process,"}, {"heading": "4.2 Results", "text": "Most of them made an unexpected number of attempts that they could not handle. For example, in the middle of our study, a new type of pop-up advertising was launched that often prevented BRAP from playing a UI script to completion; the other 44% of failures (about 7% of all attempts) occurred when a student did not follow the instructions; and the instruction that users did not follow a new type of pop-up advertising resulted in BRAP performing a UI script to completion."}, {"heading": "5 Conclusions", "text": "Virtual assistants (VAs) have become very popular, but not nearly as popular as they might be. We suspect that one of the main reasons for their slow adoption is that users are unable to customize them. Our instructible agent (IA) Helpa offers users a way to customize their VAs, not only in terms of what tasks the VA can perform, but also in terms of the commands used to trigger those tasks, and the way the tasks are performed. To promote research on the subject, we share the data set that came out of our usability study.Since Helpa has been successful for most users on most websites, we maintain that Helpa can learn many non-related tasks without the involvement of its creators. Since Helpa does not have 17 Tables 2 and 1 both sorted by the measure in Column G.domain-specific knowledge of any kind, we maintain that it has near-complete coverage of tasks that programs cannot branch out."}, {"heading": "Appendix A: Instructions Given to Study Subjects", "text": "It is as it is, that it is able to unite to save the world."}, {"heading": "Appendix B: Examples of Command Templates", "text": "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _"}], "references": [{"title": "Plow: A collaborative task learning agent", "author": ["J. Allen", "N. Chambers", "G. Ferguson", "L. Galescu", "H. Jung", "M. Swift", "W. Taysom"], "venue": "Proceedings of the 22nd National Conference on Artificial Intelligence. pp. 1514\u20131519. AAAI Press", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2007}, {"title": "Representation learning: A review and new perspectives", "author": ["Y. Bengio", "A.C. Courville", "P. Vincent"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell. 35(8), 1798\u20131828", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2013}, {"title": "Reinforcement learning for mapping instructions to actions", "author": ["S.R.K. Branavan", "H. Chen", "L.S. Zettlemoyer", "R. Barzilay"], "venue": "Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP. pp. 82\u201390. Association for Computational Linguistics", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2009}, {"title": "Programming by Abstract Demonstration", "author": ["G.A. Curry"], "venue": "Ph.D. thesis, University of Washington", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1978}, {"title": "Watch what I Do: Programming by Demonstration", "author": ["A. Cypher", "D. Halbert"], "venue": "MIT Press", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1993}, {"title": "No Code Required: Giving Users Tools to Transform the Web", "author": ["A. Cypher", "M. Dontcheva", "T. Lau", "J. Nichols"], "venue": "Morgan Kaufmann Publishers Inc.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2010}, {"title": "Dimensions of complexity in learning from interactive instruction", "author": ["S.B. Huffman", "J.E. Laird"], "venue": "Proceedings of Cooperative Intelligent Robotics in Space III, SPIE Volume 1829", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1992}, {"title": "Version space algebra and its application to programming by demonstration", "author": ["T.A. Lau", "P. Domingos", "D.S. Weld"], "venue": "Proceedings of the Seventeenth International Conference on Machine Learning (ICML 2000). pp. 527\u2013534", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2000}, {"title": "Fine-grained entity recognition", "author": ["X. Ling", "D.S. Weld"], "venue": "Proceedings of the 26th AAAI Conference on Artificial Intelligence", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2012}, {"title": "Forms2dialog: Automatic dialog generation for web tasks", "author": ["N.B. Niraula", "A. Stent", "H. Jung", "G. di Fabbrizio", "I.D. Melamed", "V. Rus"], "venue": "Proceedings of the Spoken Language Technology Workshop", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}, {"title": "Editing by Example", "author": ["R. Nix"], "venue": "Ph.D. thesis, Yale University", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1983}, {"title": "Computational logic: The unification computation", "author": ["A.J. Robinson"], "venue": "Machine Intelligence 6, 63\u201372", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1971}, {"title": "Application-driven statistical paraphrase generation", "author": ["S. Zhao", "X. Lan", "T. Liu", "S. Li"], "venue": "Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP. pp. 834\u2013842. Association for Computational Linguistics", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2009}], "referenceMentions": [{"referenceID": 3, "context": "Their efforts comprise a body of work most commonly referred to as \u201cprogramming by demonstration\u201d (PBD)[4].", "startOffset": 103, "endOffset": 106}, {"referenceID": 4, "context": ", see [5,6] and references therein).", "startOffset": 6, "endOffset": 11}, {"referenceID": 5, "context": ", see [5,6] and references therein).", "startOffset": 6, "endOffset": 11}, {"referenceID": 0, "context": "For example, the PLOW system [1] is powerful enough to learn programs with variables, loops, and subroutines.", "startOffset": 29, "endOffset": 32}, {"referenceID": 6, "context": "Following [7], we shall refer to the teachable component of a VA as an instructible agent (IA), and the challenge of building an IA as the IA problem.", "startOffset": 10, "endOffset": 13}, {"referenceID": 9, "context": ", see [10]).", "startOffset": 6, "endOffset": 10}, {"referenceID": 2, "context": "[3] studied a special case of this problem where the natural language input explicitly referred to every user action in the UI script.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] and others have studied a related but different problem where the goal was to predict programs from program traces.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": ", [2]).", "startOffset": 2, "endOffset": 5}, {"referenceID": 10, "context": ", [11]).", "startOffset": 2, "endOffset": 6}, {"referenceID": 11, "context": "This kind of matching is a special case of unification, for which efficient algorithms exist [12].", "startOffset": 93, "endOffset": 97}, {"referenceID": 12, "context": "For example, we could use statistical paraphrase generation [13] to proactively expand a newly inferred command template into a set of possible paraphrases, and store them all in the task database linked to the same task.", "startOffset": 60, "endOffset": 64}, {"referenceID": 8, "context": ", [9]).", "startOffset": 2, "endOffset": 5}], "year": 2016, "abstractText": "The challenge stated in the title can be divided into two main problems. The first problem is to reliably mimic the way that users interact with user interfaces. The second problem is to build an instructible agent, i.e. one that can be taught to execute tasks expressed as previously unseen natural language commands. This paper proposes a solution to the second problem, a system we call Helpa. End-users can teach Helpa arbitrary new tasks whose level of complexity is similar to the tasks available from today\u2019s most popular virtual assistants. Teaching Helpa does not involve any programming. Instead, users teach Helpa by providing just one example of a command paired with a demonstration of how to execute that command. Helpa does not rely on any pre-existing domain-specific knowledge. It is therefore completely domain-independent. Our usability study showed that end-users can teach Helpa many new tasks in less than a minute each, often much less.", "creator": "LaTeX with hyperref package"}}}