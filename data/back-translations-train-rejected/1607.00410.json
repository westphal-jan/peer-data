{"id": "1607.00410", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Jul-2016", "title": "Domain Adaptation for Neural Networks by Parameter Augmentation", "abstract": "We propose a simple domain adaptation method for neural networks in a supervised setting. Supervised domain adaptation is a way of improving the generalization performance on the target domain by using the source domain dataset, assuming that both of the datasets are labeled. Recently, recurrent neural networks have been shown to be successful on a variety of NLP tasks such as caption generation; however, the existing domain adaptation techniques are limited to (1) tune the model parameters by the target dataset after the training by the source dataset, or (2) design the network to have dual output, one for the source domain and the other for the target domain. Reformulating the idea of the domain adaptation technique proposed by Daume (2007), we propose a simple domain adaptation method, which can be applied to neural networks trained with a cross-entropy loss. On captioning datasets, we show performance improvements over other domain adaptation methods.", "histories": [["v1", "Fri, 1 Jul 2016 21:24:21 GMT  (282kb,D)", "http://arxiv.org/abs/1607.00410v1", "9 page. To appear in the first ACL Workshop on Representation Learning for NLP"]], "COMMENTS": "9 page. To appear in the first ACL Workshop on Representation Learning for NLP", "reviews": [], "SUBJECTS": "cs.CL cs.AI cs.LG", "authors": ["yusuke watanabe", "kazuma hashimoto", "yoshimasa tsuruoka"], "accepted": false, "id": "1607.00410"}, "pdf": {"name": "1607.00410.pdf", "metadata": {"source": "CRF", "title": "Domain Adaptation for Neural Networks by Parameter Augmentation", "authors": ["Yusuke Watanabe", "SONY", "Konan Minato-ku", "Kazuma Hashimoto", "Yoshimasa Tsuruoka"], "emails": ["YusukeB.Watanabe@jp.sony.com", "hassy@logos.t.u-tokyo.ac.jp", "tsuruoka@logos.t.u-tokyo.ac.jp"], "sections": [{"heading": "1 Introduction", "text": "We want to use the information source label to improve the performance of a new (target) domain by using a dataset from the original (source) domain. Let's say that as a source domain dataset we have a specific target domain consisting of everyday images and each image has captions. Let's also say that we want to generate captions for exotic kitchens that are rare in the target domain. Generally, it is very expensive to create a new corpus for the target domain, i.e., the inclusion and labeling of Thoseimages. The research question is how we can use the source domain Dataset to improve performance in the target domain."}, {"heading": "2 Related Work", "text": "There are several recent studies in which methods of domain adjustment are applied to deep neural networks. However, few studies focus on improving fine-tuning and dual output methods in the monitored environment. Sun et al. (2015) have proposed an unattended domain adjustment method and apply it to the characteristics of deep neural networks. Their idea is to minimize domain shifts by aligning the secondary statistics of source and target distributions. In our environment, it is not necessarily true that there is agreement between source and target input distributions, and therefore we cannot expect their method to work well. Wen et al. (2016) have proposed a method to generate natural language for multiple domains of spoken dialogue systems. They improve the fine-tuning method by pre-tracking synthesized data. However, the synthesis protocol is only applicable to the spoken dialogue system."}, {"heading": "3 Domain adaptation and language generation", "text": "Let X be the set of inputs = = certain functions and Y the outputs. We have a source domain Dataset Ds, which is sampled by some distribution Ds \u2212 \u2212 In addition, we have a target domain Dataset Dt, which is sampled by another distribution Dt. As we look at the monitored settings, each element of the datasets assumes that there is a connection between the source and destination distributions, and thus that it can use the information from the source domain Dataset (x, y).The goal of the domain adaptation is to learn a function f: X \u2192 Y, which models the input-output relationship of Dt. We implicitly assume that there is a connection between the source domain and the target distributions, and thus can use the information from the source domain Dataset. In the case of the caption element of an image, the image generator is a word (or image) generated by a word (image)."}, {"heading": "4 Domain adaptation for language generation", "text": "This section examines standard adaptation techniques that are applicable to neural language generation. The next section compares the performance of these methods."}, {"heading": "4.1 Standard and baseline methods", "text": "A trivial method of domain adjustment is simply ignoring the source data set and training the model using only the target data set; this method is hereinafter referred to as TGTONLY. This is a baseline, and any meaningful method must beat it. Another trivial method is SRCONLY, which uses only the source data set for training. Typically, the source data set is larger than the target, and this method sometimes works better than TGTONLY. Another method is ALL, which combines the source and target data set and uses it for training. Although this method uses all the data, the training criteria force the model to work well on both domains, and therefore performance on the target domain is not necessarily high. 1An approach widely used in the neural network community is FINETUNE. We train the model with the source data set first, and then use it as the starting parameter for training."}, {"heading": "4.2 Revisiting the feature augmentation method", "text": "Before we proceed with our new method, we will describe the method of the feature augmentation (thumb, 2007) from our perspective. Let us start with the method of the feature augmentation. Here we will consider the domain adaptation of a binary classification problem. Let us assume that we define SVM models for the source and target domains separately. The objective functions have the form of 1ns (x, y) - Ds max (0, 1 \u2212 y (wTs) - max (x)))) - + \u03bb - D (x) - max (x, y) - Dt max (0 \u2212 y (wTt) - max (0, 1 \u2212 y (x)) - x \u2212 y (wTs) - 2 (wTs) - if \u2212 x \u2212 is the feature vector and ws \u2212 wt - max (x) - Dt max (0 \u2212 y) - max (wTt) - max (0 \u2212 y (wTt) - max (0, y (wTs) - x \u2212 y) - x \u2212 y (wTs) - 2 (wTs) - 2 (wTs) - 2 (wTs) - 2 (wTs) - if \u2212 x - x - is the feature vector and ws \u2212 wt - are the SVM parameters. In the feature augmentation method, the parameters are the parameters, the parameters become the parameters of the parameters of ws = (x, wTs, y, wTs, y, wTs,), (wTs,),"}, {"heading": "4.3 Proposed method", "text": "Although the above formalization applies to an SVM that has the quadratic cost of the parameters, we can apply the idea to the logarithmic probability case. In the case of the RNN language generation, the loss function of each output is a quadratic entropy that applies to the softmax output \u2212 logps (y | y1,.., yt \u2212 1, x) = \u2212 logZ (ws; h), (3) where Z is the partition function and h is the hidden state of the LSTM calculated by y0., yt \u2212 1 and x. Again, we decompose the word output parameters as ws = \u03b8g + \u03b8g \u2212 s. Since logZ is convex in relation to the partition function, we can easily show that the equation (3) above is \u2212 equitable Tg, yh + 12 logZ (x) \u2212 equitable."}, {"heading": "5 Experiments", "text": "We have conducted domain adaptation experiments on the following three sets of data: the first experiment focuses on the situation in which domain adaptation is useful; the second experiment demonstrates the benefits of domain adaptation in both directions: from source to target and target to source; and the third experiment demonstrates an improvement in another metric. Although our method is applicable to any neural network with cross-entropy loss, all experiments use label generation models because it is one of the most successful applications of neural networks in NLP."}, {"heading": "5.1 Adaptation to food domain captioning", "text": "This experiment highlights a typical scenario in which adaptation to the world is useful. Suppose we have a large dataset of images that come from everyday life, but we want to generate high-quality captions for more specialized areas such as sports and exotic nutrition. We use domain adaptation methods to improve the terms of the target. To simulate the scenario, we divide the Microsoft datasets into food and non-food. The MS COCO dataset contains about 80K images for training and validation."}, {"heading": "5.2 Adaptation between MS COCO and Flickr30K", "text": "Flickr30K2We use scripts in https: / / github.com / tylin / is another captioning dataset, consisting of 30K images, and each image has five captions (Young et al., 2014). Although the formats of the data sets are almost the same, the model trained by MS COCO dataset does not work well for the Flickr 30K dataset and vice versa. Word distributions of captions vary considerably. If we ignore words with less than 30 counts, MS COCO has 3,655 words and Flicker30K has 2732 words; and only 1,486 words are shared. Also, the average lengths of captions are different. The average length of captions in Flickr30K is 12.3, while that of MS COCO is 10.5.The first result is the domain adaptation from MS COCO to Flickr30K."}, {"heading": "5.3 Answer sentence selection", "text": "In this experiment, we used the subtitle model as an affinity measure for images and sets. An example of the question is in Table 7. We downloaded 610 questions from http: / / www.english-test.net / toeic / listening /. Our approach is to select the most likely choice underlying the image based on subtitle models. We trained subtitle models with the images and correct answers from the training set. Since the TOEIC record is small, domain matching can be of great benefit. We compared the domain matching methods to the percentage of correct answers. The source data set is 40K samples from MS COCO and the target data set is the TOEIC record. We split the TOEIC record into 400 samples for training and 210 samples for the test.The percentage of correct answers for each method is better than the comparison method, as all other methods are summarized in the table."}, {"heading": "6 Conclusion and Future Work", "text": "We have proposed a new method for the supervised domain fitting of neural networks. In subtitling data sets, we have shown that the method outperforms other standard fitting methods applicable to neural networks.The proposed method merely disassembles the output word parameters, where other parameters, such as word embedding, are completely distributed across the domains.Expanding the parameters in the other part of the network would be an interesting direction for future work."}], "references": [{"title": "Neural machine translation by jointly learning to align and translate", "author": ["Kyunghyun Cho", "Yoshua Bengio"], "venue": "In Proceedings of the 3rd International Conference on Learning Representations (ICLR)", "citeRegEx": "Bahdanau et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2015}, {"title": "Natural language processing (almost) from scratch", "author": ["Jason Weston", "L Bottou"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Collobert et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Collobert et al\\.", "year": 2011}, {"title": "Frustratingly easy domain adaptation", "author": ["Hal Daum\u00e9", "III"], "venue": "In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics (ACL),", "citeRegEx": "Daum\u00e9 and III.,? \\Q2007\\E", "shortCiteRegEx": "Daum\u00e9 and III.", "year": 2007}, {"title": "Convolutional neural networks for sentence classification", "author": ["Yoon Kim"], "venue": "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Kim.,? \\Q2014\\E", "shortCiteRegEx": "Kim.", "year": 2014}, {"title": "Adam: A method for stochastic optimization", "author": ["Kingma", "Ba2015] Diederik Kingma", "Jimmy Ba"], "venue": "In Proceedings of the 3rd International Conference on Learning Representations (ICLR)", "citeRegEx": "Kingma et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kingma et al\\.", "year": 2015}, {"title": "Microsoft coco: Common objects in context", "author": ["Lin et al.2014] Tsung-Yi Lin", "Michael Maire", "Serge Belongie", "James Hays", "Pietro Perona", "Deva Ramanan", "Piotr Doll\u00e1r", "C Lawrence Zitnick"], "venue": "In Proceedings of the European Conference on Com-", "citeRegEx": "Lin et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Lin et al\\.", "year": 2014}, {"title": "Recurrent neural network based language model", "author": ["Martin Karafi\u00e1t", "Lukas Burget", "Jan Cernock\u1ef3", "Sanjeev Khudanpur"], "venue": "In INTERSPEECH,", "citeRegEx": "Mikolov et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2010}, {"title": "Wordnet: a lexical database for english", "author": ["Gerge A. Miller"], "venue": "Communications of The ACM,", "citeRegEx": "Miller.,? \\Q1995\\E", "shortCiteRegEx": "Miller.", "year": 1995}, {"title": "How transferable are neural networks in nlp applications? arXiv preprint arXiv:1603.06111", "author": ["Mou et al.2016] Lili Mou", "Zhao Meng", "Rui Yan", "Ge Li", "Yan Xu", "Lu Zhang", "Zhi Jin"], "venue": null, "citeRegEx": "Mou et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Mou et al\\.", "year": 2016}, {"title": "Return of frustratingly easy domain adaptation", "author": ["Sun et al.2015] Baochen Sun", "Jiashi Feng", "Kate Saenko"], "venue": "In Proceedings of the 29th AAAI Conference on Artificial Intelligence", "citeRegEx": "Sun et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Sun et al\\.", "year": 2015}, {"title": "Going deeper with convolutions", "author": ["Wei Liu", "Yangqing Jia", "Pierre Sermanet", "Scott Reed", "Dragomir Anguelov", "Dumitru Erhan", "Vincent Vanhoucke", "Andrew Rabinovich"], "venue": null, "citeRegEx": "Szegedy et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Szegedy et al\\.", "year": 2015}, {"title": "Cider: Consensus-based image description evaluation", "author": ["C Lawrence Zitnick", "Devi Parikh"], "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "Vedantam et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Vedantam et al\\.", "year": 2015}, {"title": "Translating videos to natural language using deep recurrent neural networks", "author": ["Huijuan Xu", "Jeff Donahue", "Marcus Rohrbach", "Raymond Mooney", "Kate Saenko"], "venue": null, "citeRegEx": "Venugopalan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Venugopalan et al\\.", "year": 2015}, {"title": "2015a. Grammar as a foreign language", "author": ["\u0141ukasz Kaiser", "Terry Koo", "Slav Petrov", "Ilya Sutskever", "Geoffrey Hinton"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Vinyals et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Vinyals et al\\.", "year": 2015}, {"title": "2015b. Show and tell: A neural image caption generator", "author": ["Alexander Toshev", "Samy Bengio", "Dumitru Erhan"], "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "Vinyals et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Vinyals et al\\.", "year": 2015}, {"title": "Multi-domain neural network language generation for spoken dialogue systems", "author": ["Wen et al.2016] Tsung-Hsien Wen", "Milica Gasic", "Nikola Mrksic", "Lina M Rojas-Barahona", "Pei-Hao Su", "David Vandyke", "Steve Young"], "venue": null, "citeRegEx": "Wen et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Wen et al\\.", "year": 2016}, {"title": "Show, attend and tell: Neural image caption generation with visual attention", "author": ["Xu et al.2015] Kelvin Xu", "Jimmy Ba", "Ryan Kiros", "Aaron Courville", "Ruslan Salakhutdinov", "Richard Zemel", "Yoshua Bengio"], "venue": null, "citeRegEx": "Xu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Xu et al\\.", "year": 2015}, {"title": "Multi-task cross-lingual sequence tagging from scratch", "author": ["Yang et al.2016] Zhilin Yang", "Ruslan Salakhutdinov", "William Cohen"], "venue": "arXiv preprint arXiv:1603.06270", "citeRegEx": "Yang et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Yang et al\\.", "year": 2016}, {"title": "From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions", "author": ["Young et al.2014] Peter Young", "Alice Lai", "Micah Hodosh", "Julia Hockenmaier"], "venue": null, "citeRegEx": "Young et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Young et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 6, "context": "Recently, Recurrent Neural Networks (RNNs) have been successfully applied to various tasks in the field of natural language processing (NLP), including language modeling (Mikolov et al., 2010), caption generation (Vinyals et al.", "startOffset": 170, "endOffset": 192}, {"referenceID": 8, "context": "For neural networks, there are two standard methods for supervised domain adaptation (Mou et al., 2016).", "startOffset": 85, "endOffset": 103}, {"referenceID": 12, "context": "The first method is fine tuning: we first train the model with the source dataset and then tune it with the target domain dataset (Venugopalan et al., 2015; Kim, 2014).", "startOffset": 130, "endOffset": 167}, {"referenceID": 3, "context": "The first method is fine tuning: we first train the model with the source dataset and then tune it with the target domain dataset (Venugopalan et al., 2015; Kim, 2014).", "startOffset": 130, "endOffset": 167}, {"referenceID": 1, "context": "ging and named-entity recognition (Collobert et al., 2011; Yang et al., 2016).", "startOffset": 34, "endOffset": 77}, {"referenceID": 17, "context": "ging and named-entity recognition (Collobert et al., 2011; Yang et al., 2016).", "startOffset": 34, "endOffset": 77}, {"referenceID": 16, "context": "We also note that there are extensions of the models with attentions (Xu et al., 2015; Bahdanau et al., 2015), but the forms of the cost functions are the same.", "startOffset": 69, "endOffset": 109}, {"referenceID": 0, "context": "We also note that there are extensions of the models with attentions (Xu et al., 2015; Bahdanau et al., 2015), but the forms of the cost functions are the same.", "startOffset": 69, "endOffset": 109}, {"referenceID": 5, "context": "The MS COCO dataset contains approximately 80K images for training and 40K images for validation; each image has 5 captions (Lin et al., 2014).", "startOffset": 124, "endOffset": 142}, {"referenceID": 7, "context": "The score is computed based on wordnet similarities (Miller, 1995).", "startOffset": 52, "endOffset": 66}, {"referenceID": 10, "context": "The image features are computed by the trained GoogLeNet and all the LSTMs have a single layer with 300 hidden units (Szegedy et al., 2015).", "startOffset": 117, "endOffset": 139}, {"referenceID": 11, "context": "Note that the CIDEr scores correlate with human evaluations better than BLEU and METOR scores (Vedantam et al., 2015).", "startOffset": 94, "endOffset": 117}, {"referenceID": 18, "context": "is another captioning dataset, consisting of 30K images, and each image has five captions (Young et al., 2014).", "startOffset": 90, "endOffset": 110}], "year": 2016, "abstractText": "We propose a simple domain adaptation method for neural networks in a supervised setting. Supervised domain adaptation is a way of improving the generalization performance on the target domain by using the source domain dataset, assuming that both of the datasets are labeled. Recently, recurrent neural networks have been shown to be successful on a variety of NLP tasks such as caption generation; however, the existing domain adaptation techniques are limited to (1) tune the model parameters by the target dataset after the training by the source dataset, or (2) design the network to have dual output, one for the source domain and the other for the target domain. Reformulating the idea of the domain adaptation technique proposed by Daum\u00e9 (2007), we propose a simple domain adaptation method, which can be applied to neural networks trained with a cross-entropy loss. On captioning datasets, we show performance improvements over other domain adaptation methods.", "creator": "LaTeX with hyperref package"}}}