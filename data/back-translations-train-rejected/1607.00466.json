{"id": "1607.00466", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Jul-2016", "title": "Outlier absorbing based on a Bayesian approach", "abstract": "The presence of outliers is prevalent in machine learning applications and may produce misleading results. In this paper a new method for dealing with outliers and anomal samples is proposed. To overcome the outlier issue, the proposed method combines the global and local views of the samples. By combination of these views, our algorithm performs in a robust manner. The experimental results show the capabilities of the proposed method.", "histories": [["v1", "Sat, 2 Jul 2016 04:48:59 GMT  (651kb)", "http://arxiv.org/abs/1607.00466v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["parsa bagherzadeh", "hadi sadoghi yazdi"], "accepted": false, "id": "1607.00466"}, "pdf": {"name": "1607.00466.pdf", "metadata": {"source": "CRF", "title": "Outlier absorbing based on a Bayesian approach", "authors": ["Parsa Bagherzadeh", "Hadi Sadoghi Yazdi"], "emails": ["parsa.bagherzadeh@stu.um.ac.ir", "h-sadoghi@um.ac.ir"], "sections": [{"heading": null, "text": "This year, it will be able to fix and fix the mentioned bugs."}, {"heading": "II. THE PROPOSED METHOD", "text": "In this section, we present our proposed outlier absorption method, which combines the local and global information from the sample for more robust results."}, {"heading": "A. Notations", "text": "(1) If a sample x is loud, it is desirable to estimate x as a new noise-free instance. Let x, k be the set of all k closest neighborhoods and xkNi be the closest neighbors of instance xi. Let's also assume that b-ix is the set of all samples except the ith instance and c-ix, k is the set of all k closest neighborhoods except the k closest neighbors of the ith instance."}, {"heading": "B. Markovian-like assumption", "text": "Markovian assumption applies to states in which a sequence of states occurs temporally, so that the probability of being in a state at the time t is given only to its previous state, not to all previous states in the sequence. In other words, if a state xt \u2212 1 explicitly contains the information of other states {xt \u2212 2, xt \u2212 2,...}, these states can be ignored. This property applies if the states have a temporal character. We are looking for the same property if the states have a spatial nature. Similar to the Markovian assumption, it is reasonable for a set of samples S1 to contain the information of another set S2 to ignore sentence S2."}, {"heading": "C. Problem formulation", "text": "Leave f (x), k), k), k), k), k), k), k), k), k), k (x), k (x), k), k (x), k (x), k (x), x (x), x (x), x (x), x (x), x (x), x (x), x (x), x (x), x (x), x (x), x (x), x (x), x (x), x (x), x (x), x (x), x (x), x (x), x (x), x (x), x (x), x (x), x (x), x (x), x (x), x (x), x (x), x (x), x (x), x (x), x, x (x), x, x (x), x (x), x (x), x (x), x (x), x (x), x (x), x (x), x (x (x), x (x), x (x), x (x), x (x), x (x (x), x (x), x (x), x (x), x, x (x), x (x), x (x), x (x), x, x (x (x), x (x), x, x (x), x (x), x, x (x), x, x, x (x), x, x (x), x, x (x), x, x (x, x), x, x (x, x (x), x, x, x, x, x, x (x, x, x, x, x, x (x), x, x, x (x, x (x), x (x x), x, x, x, x, x, x, x, x, x, x, x (x (x), x, x x, x, x, x, x, x, x, x, x, x, x, x, x (x"}, {"heading": "III. EXPERIMENTAL RESULTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Artificial Data sets", "text": "We have applied the proposed method to two artificial datasets: First, the method is applied to a Gaussian distribution, then the case of the nonlinear distribution.1) Gaussian distribution: To evaluate the proposed method, different portions of outliers are added to the proposed dataset. 150 cases originating from a Gaussian distribution (Fig. 2.a). These outliers are obtained by adding Gaussian noise to randomly selected samples. Evaluation of the proposed method occurs in the presence of outliers with different percentages, including 5%, 10%, 15% and 20%. A demonstration of the case of 10% outliers is shown in Fig. 2.2) Nonlinear distributions: A difficult case of outlier detection problems is the case of nonliner data. An example of a nonliner distribution is shown in Fig. 3. As our experiments show, the proposed method of outlier absorption is also robust for this type of distributions."}, {"heading": "B. Real world data set", "text": "In order to have a more realistic evaluation of the proposed method, it should be tested on real q data. Pen-digit data sets starting from an UCI dataset are selected for evaluation [7].1) Evaluation metric: The goal of a denociation method is to restore the real distribution of data from the noisy one. Therefore, the resulting distribution should be close to the real distribution. To measure the difference between the resulting distribution and the real distribution, divergence is used. Divergence distance measures the similarity of two probability distributions [15].Dpq = E {ln p (x) q (x)} = p (x) \u2212 ln p (x) q (x) q (x) \u2212 dx (17) similar discussion applies to the class expec2Dqp = E {ln q (x) p (x) p (x)."}, {"heading": "IV. CONCLUSION", "text": "In this paper, a new method for dealing with outliers was proposed: The poropsised method uses local and global information to solve the outlier problem. As the experimental results showed, the combination leads to a more robust method for dealing with outliers. For future work, we plan to extend our work to multi-class classifications."}], "references": [{"title": "Outliers in Statistical Data, 3rd edn", "author": ["V. Barnett", "T. Lewis"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1994}, {"title": "Introduction to data mining", "author": ["T Pang-Ning", "M Steinbach", "V Kumar"], "venue": "Library of Congress,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2006}, {"title": "Robustness of regularized linear classification methods in text categorization", "author": ["J Zhang", "Y Yang"], "venue": "Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2003}, {"title": "Efficient Algorithms for Mining Outliers from Large Data Sets", "author": ["S. Ramaswamy", "R. Rastogi", "K. Shim"], "venue": "Proceedings of the ACM SIGMOD Conference on Management of Data, Dallas,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2000}, {"title": "Detecting Graph-Based Spatial Outliers: Algorithms and Applications", "author": ["S. Shekhar", "C. Lu", "P. Zhang"], "venue": "Proceedings of the Seventh ACM SIGKDD Interna- tional Conference on Knowledge Discovery and Data Mining", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2001}, {"title": "A Survey of Outlier Detection Methodoligies", "author": ["V. Hodge", "J. Austin"], "venue": "Artificial Intelligence Review,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2004}, {"title": "UCI Repository of machine learning databases", "author": ["C Blake", "CJ Merz"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1998}, {"title": "Support Vector Method for Novelty Detection", "author": ["B Schlkopf", "RC Williamson", "AJ Smola", "J Shawe-Taylor", "JC Platt"], "venue": "In: NIPS,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1999}, {"title": "Support vector novelty detection applied to jet engine vibration spectra", "author": ["P Hayton", "B Schlkopf", "L Tarassenko", "P Anuzis"], "venue": "In: NIPS,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2000}, {"title": "Classification in the presence of label noise: a survey", "author": ["B Frnay", "M Verleysen"], "venue": "Neural Networks and Learning Systems, IEEE Transactions on 25:845-869", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "The effect of errors in diagnosis and measurement on the estimation of the probability of an event Journal of the American Statistical Association", "author": ["JE Michalek", "RC Tripathi"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1980}, {"title": "The efficiency of logistic regression compared to normal discriminant analysis under class-conditional classification noise Journal of Multivariate Analysis", "author": ["Y Bi", "DR Jeske"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2010}, {"title": "Identifying mislabeled training data", "author": ["CE Brodley", "MA Friedl"], "venue": "Journal of Artificial Intelligence", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1999}, {"title": "Pattern recognition.", "author": ["Theodoridis", "Sergios", "Konstantinos Koutroumbas"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2003}], "referenceMentions": [{"referenceID": 1, "context": "In other cases, the data may be contaminated by external sources and not indicating their real value [2].", "startOffset": 101, "endOffset": 104}, {"referenceID": 0, "context": "Another outlier definition from [1] is: A sample (or subset of samples) which appears to be inconsistent with the rest of that data set.", "startOffset": 32, "endOffset": 35}, {"referenceID": 10, "context": "The most significant consequence of label noise is degradation of classification performance [12], [13].", "startOffset": 93, "endOffset": 97}, {"referenceID": 11, "context": "The most significant consequence of label noise is degradation of classification performance [12], [13].", "startOffset": 99, "endOffset": 103}, {"referenceID": 2, "context": "In [3] SVMs, ridge regression, and logistic regressions are tested is the presence of outliers.", "startOffset": 3, "endOffset": 6}, {"referenceID": 9, "context": "The presence of outliers also increases the required number of instances for learning, as well as the complexity of models [11].", "startOffset": 123, "endOffset": 127}, {"referenceID": 12, "context": "In [14] it is shown that the removal of outliers reduces the number of support vectors.", "startOffset": 3, "endOffset": 7}, {"referenceID": 5, "context": "There are various methods for detection of outliers [6].", "startOffset": 52, "endOffset": 55}, {"referenceID": 3, "context": "introduced an optimized k-NN to produce a ranked list of potential outliers [4].", "startOffset": 76, "endOffset": 79}, {"referenceID": 4, "context": "introduced an approach for traffic monitoring which views the outlier issue from a topologically perspective [5].", "startOffset": 109, "endOffset": 112}, {"referenceID": 6, "context": "Pen digit data set as of one UCI data sets is choosed for the evaluation [7].", "startOffset": 73, "endOffset": 76}, {"referenceID": 13, "context": "Divergence distance measures the similarity of two probability distributions [15].", "startOffset": 77, "endOffset": 81}], "year": 2016, "abstractText": "The presence of outliers is prevalent in machine learning applications and may produce misleading results. In this paper a new method for dealing with outliers and anomal samples is proposed. To overcome the outlier issue, the proposed method combines the global and local views of the samples. By combination of these views, our algorithm performs in a robust manner. The experimental results show the capabilities of the proposed method.", "creator": "LaTeX with hyperref package"}}}