{"id": "1607.00474", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Jul-2016", "title": "Adaptive Neighborhood Graph Construction for Inference in Multi-Relational Networks", "abstract": "A neighborhood graph, which represents the instances as vertices and their relations as weighted edges, is the basis of many semi-supervised and relational models for node labeling and link prediction. Most methods employ a sequential process to construct the neighborhood graph. This process often consists of generating a candidate graph, pruning the candidate graph to make a neighborhood graph, and then performing inference on the variables (i.e., nodes) in the neighborhood graph. In this paper, we propose a framework that can dynamically adapt the neighborhood graph based on the states of variables from intermediate inference results, as well as structural properties of the relations connecting them. A key strength of our framework is its ability to handle multi-relational data and employ varying amounts of relations for each instance based on the intermediate inference results. We formulate the link prediction task as inference on neighborhood graphs, and include preliminary results illustrating the effects of different strategies in our proposed framework.", "histories": [["v1", "Sat, 2 Jul 2016 07:41:45 GMT  (643kb,D)", "http://arxiv.org/abs/1607.00474v1", "Presented at SIGKDD 12th International Workshop on Mining and Learning with Graphs (MLG'16)"]], "COMMENTS": "Presented at SIGKDD 12th International Workshop on Mining and Learning with Graphs (MLG'16)", "reviews": [], "SUBJECTS": "cs.SI cs.AI cs.LG", "authors": ["shobeir fakhraei", "dhanya sridhar", "jay pujara", "lise getoor"], "accepted": false, "id": "1607.00474"}, "pdf": {"name": "1607.00474.pdf", "metadata": {"source": "META", "title": "Adaptive Neighborhood Graph Construction for Inference in Multi-Relational Networks", "authors": ["Shobeir Fakhraei", "Dhanya Sridhar", "Jay Pujara", "Lise Getoor"], "emails": ["shobeir@cs.umd.edu", "dsridhar@ucsc.edu", "jay@cs.umd.edu", "getoor@soe.ucsc.edu"], "sections": [{"heading": "1. INTRODUCTION", "text": "This year, it will be able to fix and fix the mentioned bugs."}, {"heading": "2. GENERAL PROBLEM STATEMENT", "text": "Let candidate diagram be represented by Gc, < X, R >, where vertices q = n data points xi = [x1i,.., x p \u2212 1 i, yi], and y represent the set of all names (y = {y1,.., yn}) where a subset is observed (yo) and others are not observed (yu), and edges R are a set of relationships rxi, xj (e.g. paired similarities or connections in the social network) that connect pairs of data points xi and xj, based on some notion of affinity. Graph-based method generally assumes that for two data points xi and xj connected to each other in this candidate diagram, their labels yi and yj are close together, the strength of this assumption being the value or weight of the models associated with the relationship kxi, xj.which perform a collective inference."}, {"heading": "3. PROPOSED GENERAL FRAMEWORK", "text": "The maximization of the target in (1) is a non-convex combinatorial optimization problem. Consequently, we divide this target into three parts: one part to name the instance (Xn) with unknown names that require more evidence, another part to activate or select more relationships for these nominated instances (Rs), and the third part to collectively derive all unknown names for the instances based on the results from the two previous steps. To achieve this, we introduce a nominating method that is designed so that Xn = \u03b7 (X, y, u, q\u03b7) and | Xn | \u2264 q\u03b7, where q\u03b7 indicates the nominating rate. Note that nomination and activation methods each have their own quotas that we can set."}, {"heading": "4. HINGE-LOSS MRFS", "text": "The methods introduced in this paper generally apply to most neighborhood graph-based probability models, which collectively infer all unknown variables. A particular model of interest in this work is an instance of continuously evaluated Markov Random Field Models (MRFs) with a strongly convex MAP inference objective function, known as Hinge-Loss Markov random fields (HL-MRFs) [5]. An HL-MRF is a continuously evaluated Markov network in which the potential hinge functions of the variables are. Our choice of HL-MRFs stems from technical considerations: MAP inference in HL-MRFs is proven and empirically efficient, in theory growing O (N3) with the number of potentials, N, but in practice often time passes. Models built using HL-MRFs achieve state-of-art performance for a variety of applications, including drug prediction."}, {"heading": "4.1 MAP Inference", "text": "Formally, the MAP inference target is the formarg max yu [0,1] n1 Z exp (\u2212 M \u2211 r = 1\u03c9r\u03c6r (yu, X, yo)) (4) \u2261 arg min yum \u0445 r = 1\u03c9r max {lr (yu, X, yo), 0} (5) HL-MRFs have an advantage over other Markov networks because the MAP problem can be solved precisely and in polynomial time as a convex optimization problem. There are many standard solutions to convex optimization, such as interiorpoint methods, but here we use the remarkable method Alternating Direction Method of Multiples (ADMM) [11]. The ADMM algorithm uses consensus optimization to divide the MAP problem into independent sub-problems."}, {"heading": "4.2 Maximum Likelihood Parameter Learning", "text": "Each logical rule in PSL that specifies a series of hinged loss potentials when ground has a corresponding weight point. The vector of weights \u03c9 are the parameters of an HL-MRF model and can be learned from training data. The canonical approach to the parameter estimation is the maximum probability estimate (MLE), which maximizes the log probability of training data. The partial derivation of an HL-MRF with respect to any aspect r is the LogP (yu | X, yo), where gr is the basis of rule r on training data and E\u03c9 is the expectation of HL-MRF distribution parameters parameterized by \u043c. Intuitively, the gradient compares the expected sum of potentials defined by the actual sum based on training data."}, {"heading": "5. METHODS", "text": "We use HL-MRFs for inference and parameter learning of our framework. In this section, we discuss our approach to the nomination and activation method and explain how we effectively use optimization conditions and model parameters in our proposed methods."}, {"heading": "5.1 Nominating Instances", "text": "The nominating phase of our framework selects instances that can benefit from additional evidence. The process of nominating instances is similar to the problem of active learning [12], where instances are marked on the basis of a utility function. However, unlike active learning, the nomination does not acquire labels, but selects those instances for which we are establishing new relationships in the neighborhood. Our general framework is compatible with any nominating techniques that allow us to take advantage of the diverse active learning strategies that have been developed over the past decades. In addition, our choice of HL-MRFs for modeling inference problems provides the ability to use unique nomination strategies that integrate partial inference outcomes and the model state. Here, we present nomination strategies that use inference context and model characteristics to choose inferences. 5.1.1 Model-Aware Nomination Probabilistic models that use a neighborhood diagram-rich set of structural relationships between instances that may be useful in nominstances."}, {"heading": "5.2 Activating Relations", "text": "In the relation activation step, we select a subset of relationships Rs from the candidate diagram Gc to capture Gn in the neighbourhood diagram. Formally, the activated relationships Rs = \u03c4 (Xn, Gn, q\u043d, \u03c9) are each determined by the function \u03c4 in view of the nominated instances and the set of all relationships R. In addition to considering the weight or value of each relation edge Rkxi, xj, we design a ranking relationship based on structural properties of the neighbourhood diagram. At a high level, we use several characteristics to evaluate each Rkxi, xj and select the uppermost qp relationships based on their combined results. In addition to the edge weight characteristics x x, we introduce characteristics that use x\u03b1 relationships to rkxi, xj, xj. Intuitively, these structural characteristics measure the informativeness of a relationship to several unknown instances, and their ability to prove effectively by grace. First, we define two additional structural characteristics together with the relationship structure."}, {"heading": "6. GRAPH-BASED LINK PREDICTION", "text": "While the framework proposed in the paper is generally applicable to all neighborhood diagrams, we focus our arguments on the predictive task \u03b2 > 1,4. Deriving information about linkages from this is the basis for many machine learning and data science tasks. Link predictions, such as predicting which drug agents in a social network become friends or which authors quote each other in a scholar network; recommendation systems, such as predicting which article or object is more relevant to a user; or biological predictions, such as which two drugs interact with each other or which drug-effective examples of linkages in different networks. If the derived labels are binary characteristics, such as predicting a click on the task is often referred to as a link prediction, and if the labeling is continuous or multi-value, such as predicting the closely related task is often referred to as a link regression [14].To apply a neighborhood diagram < the candidate task for a node diagram should be used."}, {"heading": "7. EXPERIMENTAL VALIDATION", "text": "In this section, we present preliminary results of the main components of our framework, activation and nomination methods, based on a link prediction dataset. In this dataset, we have two types of nodes (drugs and targets), and the task is to determine the similarities between nodes and partially observed interactions (i.e. nodes) between them, in order to predict the interactions provided in the network. We use a 10-fold cross-validation for our experiments, in which we hold 10% of the observed nodes (i.e. positive class) and use the rest as an observed instance to predict their values. In addition, we stitch 10% of the missing or missing nodes (i.e. negative class) and include them in each held fold. Due to the high-class imbalance in link prediction tasks, the most meaningful measurement is the precision and memory of the minority positive class (the presence of nodes) and incorporate them into each held fold."}, {"heading": "7.1 Dataset", "text": "In this data set, we want to predict new interactions between drug compounds and target proteins. We follow the link prediction modeling approach proposed in Section 6 and by Fakhraei et al. [2]. We use known interactions and biologically relevant similarity relationships to predict heldout interactions. We describe the interactions and similarities used for our experimental evaluation. 7.1.1 Drug-target interactions The drug-target interactions are derived from Drugbank, KEGG Drug, Drug Combination Database (DCB) and Matador. The data set contains 1,306 known interactions between 315 drugs and 250 targets. We use five types of similarities between each drug pair and three types of similarities for each target pair of goals. We describe each shortly following detail, refer to [2] the data set, which includes the relationship between positive class (i.e., presence = 1) and negative class, i.e."}, {"heading": "7.2 Results", "text": "It is important to note that this baseline does not have a nomination rate and basically nominates all instances to obtain more relationships at each step. However, our nomination method is limited by a quota and cannot explore the space as freely as the selected baseline. Figure 3a shows the performance of only the average weighted Lagrange Multiplier (AWL) nomination method with a quota of 10% compared to the baseline of the drug target interaction dataset. In this setting, the limitation of the search space by the AWL nomination method improves link prediction. It is also noteworthy that the number of selected similarities at each step is lower than the base method due to the use of the nomination method. Figure 3b shows the performance of only the activation method compared to the base method. In this setting, although all instances were nominated to obtain more relationships, the similarities were rated with higher activation values."}, {"heading": "8. DISCUSSION AND CONCLUSION", "text": "In this paper, we highlight the limitations of the sequential construction of neighborhood graphs and introduce a general unified framework for the dynamic construction of multirelational neighborhood graphs during inference. We base our dynamic construction of neighborhood graphs on the states of variables from intermediate inference results, the structural properties of the relationships connecting them, and weight parameters learned through the model. We then formulate the general task of link prediction as inference on neighborhood graphs, and present initial results based on a drug-target interaction network that shows the effectiveness of our methods. In future work, we plan to expand our studies to include experiments with more data sets with different characteristics, experiments with different learning situations of parameters, and consideration of additional methods for the components of our framework such as value-oriented and probable nomination methods, and labeling and other structural activation methods."}, {"heading": "Acknowledgements", "text": "This work is partially supported by the National Science Foundation (NSF) under contract number IIS0746930. Any opinions, findings, conclusions or recommendations expressed in this material are those of the author (s) and do not necessarily reflect the views of the supporting institution (s)."}], "references": [{"title": "Graph construction and b-matching for semi-supervised learning", "author": ["Tony Jebara", "Jun Wang", "Shih-Fu Chang"], "venue": "In Proceedings of the 26th Annual International Conference on Machine Learning,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2009}, {"title": "Network-based drug-target interaction prediction with probabilistic soft logic", "author": ["Shobeir Fakhraei", "Bert Huang", "Louiqa Raschid", "Lise Getoor"], "venue": "IEEE/ACM Transactions on Computational Biology and Bioinformatics,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2014}, {"title": "Some new directions in graph-based semi-supervised learning", "author": ["Xiaojin Zhu", "Andrew B Goldberg", "Tushar Khot"], "venue": "In Multimedia and Expo,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2009}, {"title": "Collective classification of network data", "author": ["Ben London", "Lise Getoor"], "venue": "Data Classification: Algorithms and Applications. CRC Press,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2013}, {"title": "Hinge-loss markov random fields and probabilistic soft logic", "author": ["Stephen H Bach", "Matthias Broecheler", "Bert Huang", "Lise Getoor"], "venue": "arXiv preprint arXiv:1505.04406,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "A probabilistic approach for collective similarity-based drug-drug interaction prediction", "author": ["Dhanya Sridhar", "Shobeir Fakhraei", "Lise Getoor"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2016}, {"title": "Hyper: A flexible and extensible probabilistic framework for hybrid recommender systems", "author": ["Pigi Kouki", "Shobeir Fakhraei", "James Foulds", "Magdalini Eirinaki", "Lise Getoor"], "venue": "In 9th ACM Conference on Recommender Systems (RecSys). ACM,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2015}, {"title": "Learning latent engagement patterns of students in online courses", "author": ["Arti Ramesh", "Dan Goldwasser", "Bert Huang", "Hal Daume III", "Lise Getoor"], "venue": "In Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence. AAAI Press,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}, {"title": "Knowledge graph identification", "author": ["Jay Pujara", "Hui Miao", "Lise Getoor", "William Cohen"], "venue": "In International Semantic Web Conference (ISWC),", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2013}, {"title": "Collective spammer detection in evolving multi-relational social networks", "author": ["Shobeir Fakhraei", "James Foulds", "Madhusudana Shashanka", "Lise Getoor"], "venue": "In ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD). ACM, ACM Press,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2015}, {"title": "Distributed optimization and statistical learning via the alternating direction method of multipliers", "author": ["S. Boyd", "N. Parikh", "E. Chu", "B. Peleato", "J. Eckstein"], "venue": "Foundations and Trends Machine Learning,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2011}, {"title": "Active learning", "author": ["Burr Settles"], "venue": "Synthesis Lectures on Artificial Intelligence and Machine Learning,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2012}, {"title": "Budgeted online collective inference", "author": ["Jay Pujara", "Ben London", "Lise Getoor"], "venue": "In Uncertainty in Artificial Intelligence,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2015}, {"title": "Relational learning via collective matrix factorization", "author": ["Ajit P Singh", "Geoffrey J Gordon"], "venue": "In Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2008}, {"title": "Link propagation: A fast semi-supervised learning algorithm for link prediction", "author": ["Hisashi Kashima", "Tsuyoshi Kato", "Yoshihiro Yamanishi", "Masashi Sugiyama", "Koji Tsuda"], "venue": "In SDM,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2009}], "referenceMentions": [{"referenceID": 0, "context": "Most methods that make predictions based on a neighborhood graph can be characterized in terms of three basic operations [1]: Candidate graph Generation, Selection and Inference.", "startOffset": 121, "endOffset": 124}, {"referenceID": 0, "context": "Examples of these methods that are often considered a pre-processing step to inference include knearest neighbors, -neighborhood selection, and b-matching [1].", "startOffset": 155, "endOffset": 158}, {"referenceID": 1, "context": "[2] show this negative effect in a drug target prediction setting.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "Methods such as Mincut, graph random walk, Gaussian random fields, local and global consistency, spectral graph transducer, manifold regularization, and label propagation are examples that perform inference on the neighborhood graph [3].", "startOffset": 233, "endOffset": 236}, {"referenceID": 3, "context": "Models that perform collective inference [4] based on both known and unknown labels find an optimal state of all unknowns variables by optimizing an objective function f over all target variables yu and jointly assigning values to all of them.", "startOffset": 41, "endOffset": 44}, {"referenceID": 4, "context": "One particular model of interest in this paper is an instance of continuous-valued Markov random field models (MRFs) with a strongly convex MAP inference objective function, known as hinge-loss Markov random fields (HL-MRFs) [5].", "startOffset": 225, "endOffset": 228}, {"referenceID": 1, "context": "Models built using HL-MRFs have achieves state-of-the-art performance for a variety of applications including drug target prediction [2], drug interaction prediction [6] recommender systems [7], student engagement analysis [8], knowledge graph identification [9], and social spammer detection [10].", "startOffset": 133, "endOffset": 136}, {"referenceID": 5, "context": "Models built using HL-MRFs have achieves state-of-the-art performance for a variety of applications including drug target prediction [2], drug interaction prediction [6] recommender systems [7], student engagement analysis [8], knowledge graph identification [9], and social spammer detection [10].", "startOffset": 166, "endOffset": 169}, {"referenceID": 6, "context": "Models built using HL-MRFs have achieves state-of-the-art performance for a variety of applications including drug target prediction [2], drug interaction prediction [6] recommender systems [7], student engagement analysis [8], knowledge graph identification [9], and social spammer detection [10].", "startOffset": 190, "endOffset": 193}, {"referenceID": 7, "context": "Models built using HL-MRFs have achieves state-of-the-art performance for a variety of applications including drug target prediction [2], drug interaction prediction [6] recommender systems [7], student engagement analysis [8], knowledge graph identification [9], and social spammer detection [10].", "startOffset": 223, "endOffset": 226}, {"referenceID": 8, "context": "Models built using HL-MRFs have achieves state-of-the-art performance for a variety of applications including drug target prediction [2], drug interaction prediction [6] recommender systems [7], student engagement analysis [8], knowledge graph identification [9], and social spammer detection [10].", "startOffset": 259, "endOffset": 262}, {"referenceID": 9, "context": "Models built using HL-MRFs have achieves state-of-the-art performance for a variety of applications including drug target prediction [2], drug interaction prediction [6] recommender systems [7], student engagement analysis [8], knowledge graph identification [9], and social spammer detection [10].", "startOffset": 293, "endOffset": 297}, {"referenceID": 4, "context": "Finally, HL-MRFs are easily specified through probabilistic soft logic (PSL) [5], a probabilistic programming language with a first-order logic-like syntax.", "startOffset": 77, "endOffset": 80}, {"referenceID": 0, "context": "where the entries of target variables yu and observed variables X and yo are in [0, 1], \u03c9 is a vector of weight parameters, Z is a normalization constant, and", "startOffset": 80, "endOffset": 86}, {"referenceID": 0, "context": "arg max yu\u2208[0,1]n 1 Z exp ( \u2212 M \u2211", "startOffset": 11, "endOffset": 16}, {"referenceID": 10, "context": "There are many off-the-shelf convex optimization solvers such as interiorpoint methods, but here we use the notable Alternating Direction Method of Multiples algorithm (ADMM) [11].", "startOffset": 175, "endOffset": 179}, {"referenceID": 4, "context": "For full details on consensus optimization with ADMM for HL-MRF MAP inference, see [5].", "startOffset": 83, "endOffset": 86}, {"referenceID": 4, "context": "Gradient descent is performed using the structured voted perceptron algorithm [5].", "startOffset": 78, "endOffset": 81}, {"referenceID": 11, "context": "The process of nominating instances is similar to the problem of active learning [12], where instances are labeled based on a utility function.", "startOffset": 81, "endOffset": 85}, {"referenceID": 12, "context": "[13], which derives features for instance selection from the optimization process underlying inference.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13] observe that model structure (in our setting, relations between instances in the neighborhood graph) translate directly into optimization terms in the inference objective.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "The methods we present identify features from the popular consensus optimization algorithm, the alternating direction method of multipliers (ADMM) [11].", "startOffset": 147, "endOffset": 151}, {"referenceID": 12, "context": "The average weighted Lagrange multiplier (AWL) [13], measures the overall discrepancy between the local and consensus copies of the label:", "startOffset": 47, "endOffset": 51}, {"referenceID": 13, "context": "When the inferred labels are binary such as click prediction the task is often called link prediction, and when the label is continuous or multi-valued such as ratings prediction the closely related task is often called link regression [14].", "startOffset": 236, "endOffset": 240}, {"referenceID": 1, "context": "Similarities can be extracted from multiple sources, for example, based on chemical structures of the drugs, or nucleotide sequence of the targets [2].", "startOffset": 147, "endOffset": 150}, {"referenceID": 14, "context": "[15] use the Kronecker sum and product to derive similarities between links, and Fakhraei et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 1, "context": "[2] use triadic closure principles and define the similarities between links", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "This model achieves state-of-the-art performance in various domains such as drug-target interaction prediction [2], drug-drug interaction prediction [6], and hybrid recommender systems [7].", "startOffset": 111, "endOffset": 114}, {"referenceID": 5, "context": "This model achieves state-of-the-art performance in various domains such as drug-target interaction prediction [2], drug-drug interaction prediction [6], and hybrid recommender systems [7].", "startOffset": 149, "endOffset": 152}, {"referenceID": 6, "context": "This model achieves state-of-the-art performance in various domains such as drug-target interaction prediction [2], drug-drug interaction prediction [6], and hybrid recommender systems [7].", "startOffset": 185, "endOffset": 188}, {"referenceID": 1, "context": "[2].", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "For full details, refer to [2].", "startOffset": 27, "endOffset": 30}], "year": 2016, "abstractText": "A neighborhood graph, which represents the instances as vertices and their relations as weighted edges, is the basis of many semi-supervised and relational models for node labeling and link prediction. Most methods employ a sequential process to construct the neighborhood graph. This process often consists of generating a candidate graph, pruning the candidate graph to make a neighborhood graph, and then performing inference on the variables (i.e., nodes) in the neighborhood graph. In this paper, we propose a framework that can dynamically adapt the neighborhood graph based on the states of variables from intermediate inference results, as well as structural properties of the relations connecting them. A key strength of our framework is its ability to handle multi-relational data and employ varying amounts of relations for each instance based on the intermediate inference results. We formulate the link prediction task as inference on neighborhood graphs, and include preliminary results illustrating the effects of different strategies in our proposed framework.", "creator": "LaTeX with hyperref package"}}}