{"id": "1608.04468", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Aug-2016", "title": "Unbiased Learning-to-Rank with Biased Feedback", "abstract": "Implicit feedback (e.g., clicks, dwell times, etc.) is an abundant source of data in human-interactive systems. While implicit feedback has many advantages (e.g., it is inexpensive to collect, user centric, and timely), its inherent biases are a key obstacle to its effective use. For example, position bias in search rankings strongly influences how many clicks a result receives, so that directly using click data as a training signal in Learning-to-Rank (LTR) methods yields sub-optimal results. To overcome this bias problem, we present a counterfactual inference framework that provides the theoretical basis for unbiased LTR via Empirical Risk Minimization despite biased data. Using this framework, we derive a Propensity-Weighted Ranking SVM for discriminative learning from implicit feedback, where click models take the role of the propensity estimator. In contrast to most conventional approaches to de-bias the data using click models, this allows training of ranking functions even in settings where queries do not repeat. Beyond the theoretical support, we show empirically that the proposed learning method is highly effective in dealing with biases, that it is robust to noise and propensity model misspecification, and that it scales efficiently. We also demonstrate the real-world applicability of our approach on an operational search engine, where it substantially improves retrieval performance.", "histories": [["v1", "Tue, 16 Aug 2016 02:56:24 GMT  (55kb,D)", "http://arxiv.org/abs/1608.04468v1", null]], "reviews": [], "SUBJECTS": "cs.IR cs.LG", "authors": ["thorsten joachims", "adith swaminathan", "tobias schnabel"], "accepted": false, "id": "1608.04468"}, "pdf": {"name": "1608.04468.pdf", "metadata": {"source": "CRF", "title": "Unbiased Learning-to-Rank with Biased Feedback", "authors": ["Thorsten Joachims", "Adith Swaminathan", "Tobias Schnabel"], "emails": ["tj@cs.cornell.edu", "adith@cs.cornell.edu", "tbs49@cornell.edu"], "sections": [{"heading": "1. INTRODUCTION", "text": "This year it is more than ever before."}, {"heading": "2. RELATED WORK", "text": "This year, the time has come for us to be able to try to find a solution that we are able to find, that we are able to find a solution."}, {"heading": "3. FULL-INFO LEARNING TO RANK", "text": "Before deriving our approach to LTR from biased implicit feedback, we first examine the conventional problem of LTR from editorial judgments. In conventional LTR, we obtain a sample X of i.i.d. queries xi (x), for which we assume the relevance (x, y) of all documents y that are known. Since all relevance is assumed to be known, we call this the full-information setting. The relevance can be used to calculate the loss (y | x) (e.g. negative DCG) of all rankings for queries y. Aggregating the losses of individual rankings by taking into account the expectation of the query distribution, we can define the overall risk of a ranking system S that initiates rankings S (x) asR (S). (x) | x) dP (x) are relevant rankings that S (x)."}, {"heading": "4. PARTIAL-INFO LEARNING TO RANK", "text": "The question that arises is to what extent it is actually about a way in which it is about the question, to what extent it is about a way in which it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question is about the question, to what is about the question, to what is about the question to what extent it is about the question, to what is about the question is about the question, to what is about the question to what is about the question, to what is about the question is about the question to what is about the question, to what is about the question to what is about the question, to what is about the question to what is about the question, to what is about the question to what is about the question to what is about the question, to what is about the question to what is about the question, to what is about the question to what extent it is about the question to what is about the question, to what is about the question to what is about the question to what extent it is about the question, to what is about the question to what is about the question to what is about the question is about the question, to what is about the question to what is about the question, to what is about the question to what is about the question to what is about the question, to what is about the question to what is about the question to what is about the question, to what is to what"}, {"heading": "5. FEEDBACK PROPENSITY MODELS", "text": "In section 4 we have shown that the relevance signal ri, the observation pattern oi and the inclinations of the observations Q (oi (y) = 1 | xi, y-i, ri) are the key components for an unbiased LTR from biased observation feedback. We now outline how these variables can be extracted and modeled in a typical search engine application."}, {"heading": "5.1 Position-Based Propensity Model", "text": "In this model, the examination depends only on the ranking of the y results (i.e., we consider a simple test model analogous to [17], where a click on a search result depends on the probability that a user examines a result (i.e., ei (y)) and then decides to click on it (i.e., we consider a simple test model analogous to [17], where a click on a search result depends on the probability that a user examines a result (i.e., ei (y)) and then decides to click on it (i.e., we consider it relevant) in the following way: P (ei (y) = 1 | y (y).P (y) = 1 | i (y), ei (y) = 1).In this model, the examination depends only on the ranking of y in y."}, {"heading": "5.2 Incorporating Click Noise", "text": "In Section 5.1, we assume that clicks reveal the true ri of the user in a deterrent manner based on previous events, which is clearly unrealistic. In addition to stochasticity in the examination distribution P (ei (y) = 1 | rank (y | y), we now also consider noise in the distribution that generates the clicks. In particular, we no longer require a relevant result to be clicked on with probability 1 and an irrelevant result to be clicked with probability 0 \u2212 \u2212 r, but instead for 1 \u2265 + > \u2212 0, P (ci (y) = 1 | ri (y) = 1, oi (y) = 1, P (ci) = 1 | ri (y) = 0, oi (y) = 1. The first line means that users click on a relevant result that only has probability +, while the second line means that users click on an irrelevant result with probability \u2212."}, {"heading": "5.3 Propensity Estimation", "text": "As a final step in defining the click-tendency model, we must address the question of how to estimate its parameters (i.e. the vector of the examination probabilities pr) for a particular search engine. The following shows that we can obtain estimates based on data from a simple intervention similar to [27], but without the strong negative effects of presenting uniformly random results for some users. This also applies to the metric Click @ 1 proposed by [3]. First, note that it is sufficient to estimate the pr intervention up to a positive multiplicative constant, since such a constant does not change how the IPS estimator (5) orders different systems. Therefore, we only need to estimate how much pr changes relative to pk for a \"limit value.\" This suggests that the following experimental intervention is sufficient to estimate pr: Before presenting the user with the ranking, we swap the result to rank k with the result to rank."}, {"heading": "5.4 Alternative Feedback Propensity Models", "text": "The click-bias model we define above is probably one of the simplest models to use for inclination modelling in the LTR, and there is a wide scope for extensions. Firstly, one could expand the model by including other biases, such as trust bias [11], which affects the perceived relevance of a result based on its ranking position. This can be captured by including click probabilities to position P (ci (y) = 1 | ri (y), ei (y) = 1, rank (y). We have already investigated that the model can be expanded to confidence bias, but it is omitted due to space constraints. Furthermore, it is possible to model calibration distortions [30] by replacing it with a regression function. Secondly, we suspect that a wide range of other click models (e.g. cascade model [5] and other explicit biases 30]."}, {"heading": "6. PROPENSITY-WEIGHTED SVM-RANK", "text": "We now derive a specific learning method that implements a trend-weighted LTR function based on SVM rank [9, 10], but we suspect that the trend-weighted versions of other LTR methods can be derived as well. Consider a set of n examples of the following form. For each query-result formula (xj, yj) clicked, we calculate the inclination qi = Q (oi (y) = 1 | xi, y, i, ri) of the click according to our click-tendency model. We also capture the candidate Yj of all results for query xj. Typically, Yj contains a few hundred documents - selected from a level-one marker [26] - that we aim to create a ranking order. Note that each click generates a separate training example, even if multiple clicks occur for the same query x."}, {"heading": "7. EMPIRICAL EVALUATION", "text": "In evaluating our approach empirically, we take a two-pronged approach: First, we use synthetically generated click data to examine the behavior of our methods across the spectrum of presentation distortions, click noise, and tilt errors; second, we examine the applicability of our approach in the real world by evaluating real click logs from live traffic in an operational search engine."}, {"heading": "7.1 Synthetic Data Experiments", "text": "In order to explore the full range of bias and noise images, we have to deal with the data we derived from the period before the financial crisis. (...) We have to deal with the effects of the crisis. (...) We have to deal with the effects of the crisis. (...) We have to deal with the consequences of the crisis. (...) We have to deal with the consequences of the crisis. (...) We have to deal with the consequences of the crisis. (...) We have to deal with the consequences of the crisis. (...) We have to deal with the consequences of the crisis. (...) We have to deal with the problems. (...) We have to deal with the consequences of the crisis. (...) We have to deal with the consequences of the crisis. (...) We have to deal with the consequences of the crisis. (...) We have to deal with the problems. (...) We have to solve the problems. (...) We have to solve the problems. (... We have to solve them. (...) We have to solve them. (... We have to solve them. (... We have to solve them. (... We have to solve them.) We have to. (... We have to solve them. (... We have to.) We have to solve them. (... We have to. (... We have to solve them. (... We have.) We have to solve them. (... We have to solve them. (... We have.) We have to solve them. (... We have to solve them. (... We have.) We have to solve them. (... We have to solve them. (we have to solve them.) We have to solve them."}, {"heading": "7.2 How does ranking performance scale with training set size?", "text": "The resulting learning curves are shown in Figure 1, and the performance of S0 is given as a baseline. Click data have presentation distortions according to (2) with (1) and noise \u2212 = 0.1. For small data sets, the results are averaged over 5 draws of click data, which is in stark contrast to naive SVM rankings, which do not take into account the bias in the data and do not achieve this level of performance. Furthermore, Naive SVM-Rank cannot make effective use of additional data and its learning curve is essentially flat."}, {"heading": "7.3 How much presentation bias can be tolerated?", "text": "Figure 2 shows that inverse weighting of the propensity SVM rank is advantageous whenever there is a significant bias. Furthermore, increasing the amount of training data by a factor of 5 further improves the propensity SVM rank, while the added training data does not affect the na\u00efve SVM rank. This is consistent with our arguments in Section 4 - more training data does not help when bias dominates the estimation error, but it can reduce estimation errors from variance in the unbiased risk estimate of the propensity SVM rank."}, {"heading": "7.4 How robust are the methods to click noise?", "text": "Figure 3 shows that Propensity SVM-Rank also has a significant advantage in terms of noise. Increasing the noise level from \u2212 0 to 0.3 (resulting in click data accounting for 59.8% of all clicks on irrelevant documents), Propensity SVM-Rank increasingly outperforms Naive SVM-Rank. Again, the impartiality of the empirical risk estimate allows Propensity SVM-Rank to benefit from more data."}, {"heading": "7.5 How robust is Propensity SVM-Rank to misspecified propensities?", "text": "In practice, however, inclinations need to be estimated and are subject to model assumptions. We are now evaluating how robust propensity SVM rank is against incorrectly stated inclinations. Figure 4 shows the performance of the Propensity SVM rank when the training data is generated with \u03b7 = 1, but the inclinations used by the Propensity SVM rank are incorrectly specified using the \u03b7 given in the x-axis of the chart. Figure 4 shows that even incorrectly stated inclinations can result in a significant improvement over naive ignoring bias, as long as the misreading is \"conservative\" - i.e., overestimating small inclinations is tolerable (what happens when bias < 1), but underestimating small inclinations can be harmful (what happens when bias is considered as such)."}, {"heading": "7.6 Real-World Experiment", "text": "This year, it is so far that it will be able to put itself at the top, \"he said.\" It's too early to say what we're going to do, \"he said.\" It's too early to say, \"he said.\" But it's too early to find a solution. \""}, {"heading": "8. CONCLUSIONS", "text": "Based on counterfactual modeling techniques from causal conclusions, we present a theoretically based Empirical Risk Minimization Framework for LTR. We support this framework with a PropensityWeighted Ranking SVM and provide extensive empirical evidence that the resulting learning method is robust against selection distortions, noise and model misspecifications. Furthermore, our real-world experiments in a live search engine show that the approach leads to significant improvements without heuristic or manual intervention in the learning process."}, {"heading": "9. FUTURE RESEARCH", "text": "Beyond the specific learning methods and inclination models we propose, this paper could have an even greater impact on its theoretical contribution to the development of the general counterfactual model for LTR, thereby articulating the key components required for LTR under distorted feedback. Firstly, the insight that inclination estimates are critical for ERM learning opens up a broad field of research for the development of better inclination models. Secondly, the theory shows that LTR methods should optimize inclination-weighted ERM targets, which raises the question of which other learning methods outside of the SVM ranking can be adapted to the Propensity ERM approach. Thirdly, we suspect that an inclination-weighted ERM approach can also be developed for targeted LTR methods, with techniques from [19] and possibly even for listing LTR. Beyond learning from implicit feedback, inclination-weighted ERM techniques could prove useful for manual measurement by means of IR optimization even."}, {"heading": "10. ACKNOWLEDGMENTS", "text": "This work was partially supported by the NSF Awards IIS-1247637, IIS-1513692, IIS-1615706 and a gift from Bloomberg. We thank Maarten de Rijke, Alexey Borisov, Artem Grotov and Yuning Mao for valuable feedback and discussions."}, {"heading": "11. REFERENCES", "text": "In Proceedings of the 25th International Conference on World Wide Web, pp. 531-541, 2016. [2] O. Chapelle, T. Joachims, F. Radlinski, and Y. Yue. Large-scale validation and analysis of interleaved search evaluation. [1-6: 41, 2012.] O. Chapelle, and Y. Yue. International network click model for web search ranking. In International Conference on World Wide Web (WWWW), pp. 1-10. ACM, 2009. [4] A. Chuklin, I. Markov, and M. de Rijke. Click Models for Web Search. Synthesis Lectures on Information Concepts, Retrieval, and Services. Morgan Claypool Publishers, 2015."}], "references": [{"title": "A neural click model for web search", "author": ["A. Borisov", "I. Markov", "M. de Rijke", "P. Serdyukov"], "venue": "In Proceedings of the 25th International Conference on World Wide Web,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2016}, {"title": "Large-scale validation and analysis of interleaved search evaluation", "author": ["O. Chapelle", "T. Joachims", "F. Radlinski", "Y. Yue"], "venue": "ACM Transactions on Information Systems (TOIS),", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "A dynamic bayesian network click model for web search ranking", "author": ["O. Chapelle", "Y. Zhang"], "venue": "In International Conference on World Wide Web (WWW),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2009}, {"title": "Click Models for Web Search. Synthesis Lectures on Information Concepts, Retrieval, and Services", "author": ["A. Chuklin", "I. Markov", "M. de Rijke"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2015}, {"title": "An experimental comparison of click position-bias models", "author": ["N. Craswell", "O. Zoeter", "M. Taylor", "B. Ramsey"], "venue": "In International Conference on Web Search and Data Mining (WSDM),", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2008}, {"title": "Reusing historical interaction data for faster online learning to rank for ir", "author": ["K. Hofmann", "A. Schuth", "S. Whiteson", "M. de Rijke"], "venue": "In International Conference on Web Search and Data Mining (WSDM),", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2013}, {"title": "A generalization of sampling without replacement from a finite universe", "author": ["D.G. Horvitz", "D.J. Thompson"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1952}, {"title": "Causal Inference for Statistics, Social, and Biomedical Sciences", "author": ["G. Imbens", "D. Rubin"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "Optimizing search engines using clickthrough data", "author": ["T. Joachims"], "venue": "In ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD),", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2002}, {"title": "Training linear SVMs in linear time", "author": ["T. Joachims"], "venue": "In ACM SIGKDD International Conference On Knowledge Discovery and Data Mining (KDD),", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2006}, {"title": "Evaluating the accuracy of implicit feedback from clicks and query reformulations in web search", "author": ["T. Joachims", "L. Granka", "B. Pan", "H. Hembrooke", "F. Radlinski", "G. Gay"], "venue": "ACM Transactions on Information Systems (TOIS),", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2007}, {"title": "Unbiased offline evaluation of contextual-bandit-based news article recommendation algorithms", "author": ["L. Li", "W. Chu", "J. Langford", "X. Wang"], "venue": "In International Conference on Web Search and Data Mining (WSDM),", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2011}, {"title": "Statistical Analysis with Missing Data", "author": ["R.J.A. Little", "D.B. Rubin"], "venue": "John Wiley,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2002}, {"title": "Learning to rank for information retrieval", "author": ["T.-Y. Liu"], "venue": "Foundations and Trends in Information Retrieval,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2009}, {"title": "Learning socially optimal information systems from egoistic users", "author": ["K. Raman", "T. Joachims"], "venue": "In European Conference on Machine Learning (ECML),", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2013}, {"title": "Stable coactive learning via perturbation", "author": ["K. Raman", "T. Joachims", "P. Shivaswamy", "T. Schnabel"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2013}, {"title": "Predicting clicks: Estimating the click-through rate for new ads", "author": ["M. Richardson", "E. Dominowska", "R. Ragno"], "venue": "In International Conference on World Wide Web (WWW),", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2007}, {"title": "The central role of the propensity score in observational studies for causal effects", "author": ["P.R. Rosenbaum", "D.B. Rubin"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1983}, {"title": "Unbiased comparative evaluation of ranking functions", "author": ["T. Schnabel", "A. Swaminathan", "P. Frazier", "T. Joachims"], "venue": "In ACM International Conference on the Theory of Information Retrieval (ICTIR),", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2016}, {"title": "Recommendations as treatments: Debiasing learning and evaluation", "author": ["T. Schnabel", "A. Swaminathan", "A. Singh", "N. Chandak", "T. Joachims"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2016}, {"title": "Multileave gradient descent for fast online learning to rank", "author": ["A. Schuth", "H. Oosterhuis", "S. Whiteson", "M. de Rijke"], "venue": "In International Conference on Web Search and Data Mining (WSDM),", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2016}, {"title": "Report on the need for and provision of an \u201cideal\u201d information retrieval test collection", "author": ["K. Sparck-Jones", "C.J.V. Rijsbergen"], "venue": null, "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1975}, {"title": "Learning from logged implicit exploration data", "author": ["A.L. Strehl", "J. Langford", "L. Li", "S. Kakade"], "venue": "In Proceedings of the 24th Annual Conference on Neural Information Processing Systems,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2010}, {"title": "Batch learning from logged bandit feedback through counterfactual risk minimization", "author": ["A. Swaminathan", "T. Joachims"], "venue": "Journal of Machine Learning Research (JMLR),", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2015}, {"title": "Statistical Learning Theory", "author": ["V. Vapnik"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1998}, {"title": "A cascade ranking model for efficient ranked retrieval", "author": ["L. Wang", "J.J. Lin", "D. Metzler"], "venue": "In ACM Conference on Research and Development in Information Retrieval (SIGIR),", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2011}, {"title": "Learning to rank with selection bias in personal search", "author": ["X. Wang", "M. Bendersky", "D. Metzler", "M. Najork"], "venue": "In ACM Conference on Research and Development in Information Retrieval (SIGIR)", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2016}, {"title": "Beyond ranking: Optimizing whole-page presentation", "author": ["Y. Wang", "D. Yin", "L. Jie", "P. Wang", "M. Yamada", "Y. Chang", "Q. Mei"], "venue": "In Proceedings of the Ninth ACM International Conference on Web Search and Data Mining, WSDM \u201916,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2016}, {"title": "Interactively optimizing information retrieval systems as a dueling bandits problem", "author": ["Y. Yue", "T. Joachims"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2009}, {"title": "Beyond position bias: examining result attractiveness as a source of presentation bias in clickthrough data", "author": ["Y. Yue", "R. Patel", "H. Roehrig"], "venue": "In International Conference on World Wide Web (WWW),", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2010}], "referenceMentions": [{"referenceID": 10, "context": "In particular, the order of presentation has a strong influence on where users click [11].", "startOffset": 85, "endOffset": 89}, {"referenceID": 8, "context": "Second, treating clicks as preferences between clicked and skipped documents has been found to be accurate [9, 11], but it can only infer preferences that oppose the presented order.", "startOffset": 107, "endOffset": 114}, {"referenceID": 10, "context": "Second, treating clicks as preferences between clicked and skipped documents has been found to be accurate [9, 11], but it can only infer preferences that oppose the presented order.", "startOffset": 107, "endOffset": 114}, {"referenceID": 8, "context": "This again leads to severely biased data, and learning algorithms trained with these preferences tend to reverse the presented order unless additional heuristics are used [9].", "startOffset": 171, "endOffset": 174}, {"referenceID": 3, "context": "Third, probabilistic click models (see [4]) have been used to model how users produce clicks, and they can take position and context biases into account.", "startOffset": 39, "endOffset": 42}, {"referenceID": 15, "context": "Fourth, allowing the LTR algorithm to randomize what is presented to the user, like in online learning algorithms [16, 6] and batch learning from bandit feedback (BLBF) [24] can overcome the problem of bias in click data in a principled manner.", "startOffset": 114, "endOffset": 121}, {"referenceID": 5, "context": "Fourth, allowing the LTR algorithm to randomize what is presented to the user, like in online learning algorithms [16, 6] and batch learning from bandit feedback (BLBF) [24] can overcome the problem of bias in click data in a principled manner.", "startOffset": 114, "endOffset": 121}, {"referenceID": 23, "context": "Fourth, allowing the LTR algorithm to randomize what is presented to the user, like in online learning algorithms [16, 6] and batch learning from bandit feedback (BLBF) [24] can overcome the problem of bias in click data in a principled manner.", "startOffset": 169, "endOffset": 173}, {"referenceID": 7, "context": "By drawing on counterfactual estimation techniques from causal inference [8], we first develop a provably unbiased estimator for evaluating ranking performance using biased feedback data.", "startOffset": 73, "endOffset": 76}, {"referenceID": 4, "context": "For example, in a cascade model [5], users are assumed to sequentially go down a ranking and click on a document if it is relevant.", "startOffset": 32, "endOffset": 35}, {"referenceID": 8, "context": "Learning from these relative preferences lowers the impact of some biases [9].", "startOffset": 74, "endOffset": 77}, {"referenceID": 4, "context": "Other click models ([5, 3, 1], also see [4]) have been proposed, and are trained to maximize log-likelihood of observed clicks.", "startOffset": 20, "endOffset": 29}, {"referenceID": 2, "context": "Other click models ([5, 3, 1], also see [4]) have been proposed, and are trained to maximize log-likelihood of observed clicks.", "startOffset": 20, "endOffset": 29}, {"referenceID": 0, "context": "Other click models ([5, 3, 1], also see [4]) have been proposed, and are trained to maximize log-likelihood of observed clicks.", "startOffset": 20, "endOffset": 29}, {"referenceID": 3, "context": "Other click models ([5, 3, 1], also see [4]) have been proposed, and are trained to maximize log-likelihood of observed clicks.", "startOffset": 40, "endOffset": 43}, {"referenceID": 14, "context": "For instance, randomizing documents across all ranks lets us learn unbiased relevances for each document, and swapping neighboring pairs of documents [15] lets us learn reliable pairwise preferences.", "startOffset": 150, "endOffset": 154}, {"referenceID": 1, "context": "Similarly, randomized interleaving can detect preferences between different rankers reliably [2].", "startOffset": 93, "endOffset": 96}, {"referenceID": 28, "context": "Different from online learning via bandit algorithms and interleaving [29, 21], batch learning from bandit feedback (BLBF) [24] still uses randomization during feedback collection, and then performs offline learning.", "startOffset": 70, "endOffset": 78}, {"referenceID": 20, "context": "Different from online learning via bandit algorithms and interleaving [29, 21], batch learning from bandit feedback (BLBF) [24] still uses randomization during feedback collection, and then performs offline learning.", "startOffset": 70, "endOffset": 78}, {"referenceID": 23, "context": "Different from online learning via bandit algorithms and interleaving [29, 21], batch learning from bandit feedback (BLBF) [24] still uses randomization during feedback collection, and then performs offline learning.", "startOffset": 123, "endOffset": 127}, {"referenceID": 17, "context": "Our approach uses inverse propensity scoring (IPS), originally employed in causal inference from observational studies [18], and more recently also in whole page optimization [28], IR evaluation with manual judgments [19], and recommender evaluation [12, 20].", "startOffset": 119, "endOffset": 123}, {"referenceID": 27, "context": "Our approach uses inverse propensity scoring (IPS), originally employed in causal inference from observational studies [18], and more recently also in whole page optimization [28], IR evaluation with manual judgments [19], and recommender evaluation [12, 20].", "startOffset": 175, "endOffset": 179}, {"referenceID": 18, "context": "Our approach uses inverse propensity scoring (IPS), originally employed in causal inference from observational studies [18], and more recently also in whole page optimization [28], IR evaluation with manual judgments [19], and recommender evaluation [12, 20].", "startOffset": 217, "endOffset": 221}, {"referenceID": 11, "context": "Our approach uses inverse propensity scoring (IPS), originally employed in causal inference from observational studies [18], and more recently also in whole page optimization [28], IR evaluation with manual judgments [19], and recommender evaluation [12, 20].", "startOffset": 250, "endOffset": 258}, {"referenceID": 19, "context": "Our approach uses inverse propensity scoring (IPS), originally employed in causal inference from observational studies [18], and more recently also in whole page optimization [28], IR evaluation with manual judgments [19], and recommender evaluation [12, 20].", "startOffset": 250, "endOffset": 258}, {"referenceID": 4, "context": "We use randomized interventions similar to [5, 23, 27] to estimate propensities in a position discount model.", "startOffset": 43, "endOffset": 54}, {"referenceID": 22, "context": "We use randomized interventions similar to [5, 23, 27] to estimate propensities in a position discount model.", "startOffset": 43, "endOffset": 54}, {"referenceID": 26, "context": "We use randomized interventions similar to [5, 23, 27] to estimate propensities in a position discount model.", "startOffset": 43, "endOffset": 54}, {"referenceID": 26, "context": "Unlike the uniform ranking randomization of [27] (with its high performance impact) or swapping adjacent pairs as in [5], we swap documents in different ranks to the top position randomly as in [23].", "startOffset": 44, "endOffset": 48}, {"referenceID": 4, "context": "Unlike the uniform ranking randomization of [27] (with its high performance impact) or swapping adjacent pairs as in [5], we swap documents in different ranks to the top position randomly as in [23].", "startOffset": 117, "endOffset": 120}, {"referenceID": 22, "context": "Unlike the uniform ranking randomization of [27] (with its high performance impact) or swapping adjacent pairs as in [5], we swap documents in different ranks to the top position randomly as in [23].", "startOffset": 194, "endOffset": 198}, {"referenceID": 26, "context": "Finally, our approach is similar in spirit to [27], where propensity-weighting is used to correct for selection bias when discarding queries without clicks during learning-torank.", "startOffset": 46, "endOffset": 50}, {"referenceID": 26, "context": "using appropriate click models to estimate the propensity of each click rather than the propensity for a query to receive a click as in [27].", "startOffset": 136, "endOffset": 140}, {"referenceID": 24, "context": "A common learning strategy is Empirical Risk Minimization (ERM) [25], which corresponds to picking the system \u015c \u2208 S that optimizes the empirical risk", "startOffset": 64, "endOffset": 68}, {"referenceID": 13, "context": "There are several LTR algorithms that follow this approach (see [14]), and we use SVM-Rank [9] as a representative algorithm in this paper.", "startOffset": 64, "endOffset": 68}, {"referenceID": 8, "context": "There are several LTR algorithms that follow this approach (see [14]), and we use SVM-Rank [9] as a representative algorithm in this paper.", "startOffset": 91, "endOffset": 94}, {"referenceID": 21, "context": "First, since it is clearly impossible to get explicit judgments for all documents, pooling techniques [22] are used such that only the most promising documents are judged.", "startOffset": 102, "endOffset": 106}, {"referenceID": 12, "context": "In particular, implicit feedback is distorted by presentation bias, and it is not missing completely at random [13].", "startOffset": 111, "endOffset": 115}, {"referenceID": 18, "context": "It closely follows [19], which unifies several prior works on evaluating information retrieval systems.", "startOffset": 19, "endOffset": 23}, {"referenceID": 6, "context": "Using this counterfactual modeling setup, we can get an unbiased estimate of \u2206(y|xi, ri) for any new ranking y (typically different from the presented ranking \u0233i) via the inverse propensity scoring (IPS) estimator [7, 18, 8]", "startOffset": 214, "endOffset": 224}, {"referenceID": 17, "context": "Using this counterfactual modeling setup, we can get an unbiased estimate of \u2206(y|xi, ri) for any new ranking y (typically different from the presented ranking \u0233i) via the inverse propensity scoring (IPS) estimator [7, 18, 8]", "startOffset": 214, "endOffset": 224}, {"referenceID": 7, "context": "Using this counterfactual modeling setup, we can get an unbiased estimate of \u2206(y|xi, ri) for any new ranking y (typically different from the presented ranking \u0233i) via the inverse propensity scoring (IPS) estimator [7, 18, 8]", "startOffset": 214, "endOffset": 224}, {"referenceID": 7, "context": ", unconfoundedness, see [8]).", "startOffset": 24, "endOffset": 27}, {"referenceID": 24, "context": "Finally, using standard results from statistical learning theory [25], consistency of the empirical risk paired with capacity control implies consistency also for ERM.", "startOffset": 65, "endOffset": 69}, {"referenceID": 16, "context": "For simplicity, we consider a straightforward examination model analogous to [17], where a click on a search result depends on the probability that a user examines a result (i.", "startOffset": 77, "endOffset": 81}, {"referenceID": 10, "context": "These examination probabilities can model presentation bias documented in eye-tracking studies [11], where users are more likely to see results at the top of the ranking than those further down.", "startOffset": 95, "endOffset": 99}, {"referenceID": 26, "context": "The following shows that we can get estimates using data from a simple intervention similar to [27], but without the strong negative impact of presenting uniformly random results to some users.", "startOffset": 95, "endOffset": 99}, {"referenceID": 2, "context": "This also relates to the Click@1 metric proposed by [3].", "startOffset": 52, "endOffset": 55}, {"referenceID": 26, "context": "This swap-intervention experiment is of much lower impact than the uniform randomization proposed in [27] for a different propensity estimation problem, and careful consideration of which rank k to choose can further reduce impact of the swap experiment.", "startOffset": 101, "endOffset": 105}, {"referenceID": 10, "context": "First, one could extend the model by incorporating other biases, for example, trust bias [11] which affects perceived relevance of a result based on its position in the ranking.", "startOffset": 89, "endOffset": 93}, {"referenceID": 29, "context": "Furthermore, it is possible to model saliency biases [30] by replacing the pr with a regression function.", "startOffset": 53, "endOffset": 57}, {"referenceID": 4, "context": ", cascade model [5] and others [5, 3, 1, 4]) can be adapted as propensity models.", "startOffset": 16, "endOffset": 19}, {"referenceID": 4, "context": ", cascade model [5] and others [5, 3, 1, 4]) can be adapted as propensity models.", "startOffset": 31, "endOffset": 43}, {"referenceID": 2, "context": ", cascade model [5] and others [5, 3, 1, 4]) can be adapted as propensity models.", "startOffset": 31, "endOffset": 43}, {"referenceID": 0, "context": ", cascade model [5] and others [5, 3, 1, 4]) can be adapted as propensity models.", "startOffset": 31, "endOffset": 43}, {"referenceID": 3, "context": ", cascade model [5] and others [5, 3, 1, 4]) can be adapted as propensity models.", "startOffset": 31, "endOffset": 43}, {"referenceID": 19, "context": "For example, the feedback may be explicit star ratings in a movie recommendation system, and the propensities may be the results of self-selection by the users as in [20].", "startOffset": 166, "endOffset": 170}, {"referenceID": 8, "context": "It is based on SVM-Rank [9, 10], but we conjecture that propensity-weighted versions of other LTR methods can be derived as well.", "startOffset": 24, "endOffset": 31}, {"referenceID": 9, "context": "It is based on SVM-Rank [9, 10], but we conjecture that propensity-weighted versions of other LTR methods can be derived as well.", "startOffset": 24, "endOffset": 31}, {"referenceID": 25, "context": "Typically, Yj contains a few hundred documents \u2013 selected by a stage-one ranker [26] \u2013 that we aim to rerank.", "startOffset": 80, "endOffset": 84}, {"referenceID": 9, "context": "We can solve this type of Quadratic Program efficiently via a one-slack formulation [10], and we are using SVMRank with appropriate modifications to include IPS weights 1/qj .", "startOffset": 84, "endOffset": 88}, {"referenceID": 8, "context": "It is equivalent to a standard ranking SVM [9], but is most easily explained as equivalent to Propensity SVM-Rank with all qj set to 1.", "startOffset": 43, "endOffset": 46}, {"referenceID": 22, "context": "This can be remedied using techniques like \u201cpropensity clipping\u201d [23], where small propensities are clipped to some threshold value \u03c4 to trade bias for variance.", "startOffset": 65, "endOffset": 69}, {"referenceID": 1, "context": "We fielded these learnt weight vectors in two online interleaving experiments [2], the first comparing Propensity SVM-Rank against Prod and the second comparing Propensity SVM-Rank against Naive SVM-Rank.", "startOffset": 78, "endOffset": 81}, {"referenceID": 18, "context": "Third, we conjecture that a Propensity ERM approach can be developed also for pointwise LTR methods using techniques from [19], and possibly even for listwise LTR.", "startOffset": 122, "endOffset": 126}, {"referenceID": 18, "context": "First, they can eliminate pooling bias, since the use of sampling during judgment elicitation puts us in a controlled setting where propensities are known (and can be optimized [19]) by design.", "startOffset": 177, "endOffset": 181}], "year": 2016, "abstractText": "Implicit feedback (e.g., clicks, dwell times, etc.) is an abundant source of data in human-interactive systems. While implicit feedback has many advantages (e.g., it is inexpensive to collect, user centric, and timely), its inherent biases are a key obstacle to its effective use. For example, position bias in search rankings strongly influences how many clicks a result receives, so that directly using click data as a training signal in Learning-to-Rank (LTR) methods yields sub-optimal results. To overcome this bias problem, we present a counterfactual inference framework that provides the theoretical basis for unbiased LTR via Empirical Risk Minimization despite biased data. Using this framework, we derive a Propensity-Weighted Ranking SVM for discriminative learning from implicit feedback, where click models take the role of the propensity estimator. In contrast to most conventional approaches to de-bias the data using click models, this allows training of ranking functions even in settings where queries do not repeat. Beyond the theoretical support, we show empirically that the proposed learning method is highly effective in dealing with biases, that it is robust to noise and propensity model misspecification, and that it scales efficiently. We also demonstrate the real-world applicability of our approach on an operational search engine, where it substantially improves retrieval performance.", "creator": "LaTeX with hyperref package"}}}