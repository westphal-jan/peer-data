{"id": "1608.05243", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Aug-2016", "title": "Multilingual Modal Sense Classification using a Convolutional Neural Network", "abstract": "Modal sense classification (MSC) is a special WSD task that depends on the meaning of the proposition in the modal's scope. We explore a CNN architecture for classifying modal sense in English and German. We show that CNNs are superior to manually designed feature-based classifiers and a standard NN classifier. We analyze the feature maps learned by the CNN and identify known and previously unattested linguistic features. We benchmark the CNN on a standard WSD task, where it compares favorably to models using sense-disambiguated target vectors.", "histories": [["v1", "Thu, 18 Aug 2016 11:41:45 GMT  (197kb)", "http://arxiv.org/abs/1608.05243v1", "Final version, accepted at the 1st Workshop on Representation Learning for NLP, held in conjunction with ACL 2016"]], "COMMENTS": "Final version, accepted at the 1st Workshop on Representation Learning for NLP, held in conjunction with ACL 2016", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["ana marasovi\\'c", "anette frank"], "accepted": false, "id": "1608.05243"}, "pdf": {"name": "1608.05243.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["marasovic@cl.uni-heidelberg.de", "frank@cl.uni-heidelberg.de"], "sections": [{"heading": null, "text": "ar Xiv: 160 8.05 243v 1 [cs.C L] 18 Aug 201 6"}, {"heading": "1 Introduction", "text": "Fact recognition (de Marneffe et al., 2012; Lee et al., 2015) is a sub-task in information extraction that distinguishes facts from hypotheses and speculations, expressed by signals of modality, most prominently modal verbs and adverbs. Modal verbs, however, are ambiguous between an epistemic sense (possibility) and non-epistemic deontic (permission / obligation) or dynamic (ability) senses, as in: He could be at home (epistemic), you can type now (deontic) and only John can solve this problem (ability). Modal Sense Classification (MSC) is a special case of sensual disambiguation, which is also relevant in areas of dialogue and planning recognition in AI, as well as in novel tasks such as argumentation mining. Prior work (Ruppenhofer and Rehbein, 2012; Zhou et al., 2015) deals with the task of beating neuralisms modularity, even if we have difficulty conceiving the multificiency of classification."}, {"heading": "2 Prior and related work", "text": "In fact, it is as if most people are able to determine for themselves what they want and what they do not. (...) It is not as if people are able to understand the things they do. (...) It is not as if they do it. (...) It is as if they do it. (...) It is as if they do it. (...) It is as if they do it. (...) It is as if they do it. (...) It is as if they do it. (...) It is as if they do it. (...) It is as if they do it. \"(...) It is as if they do it. (...) It is as if they do it. (...) It is as if they do it. (...) It is as if they do it. (...) It is as if they do it. (...) It is as if they do it."}, {"heading": "3 A CNN for modal sense classification", "text": "In fact, you have to be able to put yourself in another world, in which you can put yourself in another world, in which you can put yourself in another world."}, {"heading": "4 Modal sense classification", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Data", "text": "The aforementioned suggestions from around 1900 to 1900 were called \"insufficient\" and \"insufficient\" by the authors of the study dealing with the subject. (afu) \"We have been able to defuse the situation.\" (afu) \"We have done it.\" (afu) \"We have done it.\" (afu) \"We have done it.\" (afu) \"We have done it.\" (afu) \"We have done it.\" (afu) \"We have done it.\" (afu) \"We have done it.\" (afu) \"We have done it.\" (afu) \"We have done it.\" (afu) \"We have done it.\" (afu) \"We have done it.\" (afu) \"We have done it.\" (afu) \"We have done it.\" afu. \"afu.\" afu. \"afu\" We have done it. \"(afu)\" We have done it. \"afu.\" afu \"We have done it.\" afu. \"afu\" We have done it. \"afu.\" afu. \"afu have done it.\" (afu) \"We have done it.\" afu. \"afu.\" afu have done it. \""}, {"heading": "4.2 Experimental settings", "text": "We have reimplemented their Maximum Entropy Classifier (henceforth MaxEnt) and based it on their balanced and unbalanced mix of MPQA and EPOS.8 As in Z +, we train independent classifiers for each modal verb on their respective educational data.9 For evaluation, we perform a 5-fold cross-validation as in Z +. Each wrinkle for education includes a stratified section of 80% of MPQA data together7For example, we replace crop with you in You Could Like, which could be taken from you to get a taste of it.8We omit a small number of instances. 9This applies to all of our MPQA experiments."}, {"heading": "4.3 Model variations", "text": "We limited our model to a one-dimensional CNN architecture. Following the advice in Zhang and Wallace (2015), we used the following setting: ReLU (rectified linear unit) as activation function, filter region sizes of 3, 4 and 5 with 100 indicators each, dropouts hold probability of 0.5, l2 regulation coefficient of 10 \u2212 3, number of iterations of 100111 and minibatch size of 50. Training is performed using Adam optimization algorithms (Kingma and Ba, 2014) with learning rate of 10 \u2212 4. Filter weights are initialized using Glorot-Bengio strategy (Glorot and Bengio, 2010). We experimented with some parameter variations (with nested CV), but did not find consistently better results."}, {"heading": "4.4 Results", "text": "In Table 2, we report on the results for CNN-EB and CNN-EU with different input representations. Balanced education yields the best (can, could) or equally good results (can, must, should). Could be the only case in which large performance differences are balanced depending on the choice of embedding. However, for the selection of static or coordinated versions of vectors, it is advantageous if unbalanced education, which has dependence-based vectors of CNN balanced performance differences. Large differences in results for the selection of embedding methods are no longer advantageous. In Table 3, we report on the overall results for CNNEB and CNN-EU compared to baselines. As representations for the NN and CNN, we have chosen, for each modal verb, the type of embedding that provides the best results (Table 2) 16.For each training data set that is significantly higher than the results of the CNN-EU."}, {"heading": "4.5 Semantic feature detectors", "text": "In fact, it is such that most of them will be able to move into a different world, in which they are able to live, in which they want to live, in which they want to live, in which they want to live, in which they want to live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they, in which they, in which they live, in which they, in which they, in which they live, in which they live."}, {"heading": "5 Word sense disambiguation", "text": "For comparison, we chose the SensEval-3 lexical sample datasets (Mihalcea et al., 2004), which were recently used in Rothe and Schuetze (2015).The training data ranges from 14 to 263 instances. Sense labels of test instances of a given target word are predicted, using sense-specific embeddings and an NN architecture, respectively, (cf. Section 2).22 We set the same standards as for MSC, except for mini-batch size and region. Since the training data for some words are below 50 instances, mini-batch size is specified."}, {"heading": "6 Conclusion and future work", "text": "We used the same architecture for a standard WSD task and achieved competitive results compared to a system that uses more comprehensive embedding information.24Achieved using R & S. Our single-layer CNN architecture outperforms strong baselines and state-of-the-art MSC in English, including an NNN and MaxEnt model, and proves particularly robust in cross-genre classification. We applied the CNN model to a dataset of modest size obtained using cross-lingual projection techniques, the CNN-G classifier outperforms a NN model many times over. Our approach is easy to generalize to novel languages, without the need for lengthy and resource-intensive feature engineering. By analyzing acquired feature maps, we have proven that CNN has both known and novel features for MSC.The appeal of the CNN framework lies in its ability to learn textual (without using window tactile features) as well as in generalizing them."}, {"heading": "Acknowledgments", "text": "We thank Mengfei Zhou for her support in German body building. This work was supported by the Deutsche Forschungsgemeinschaft (German Research Foundation) within the framework of the Research Training Group \"Adaptive Processing of Information from Heterogeneous Sources\" (AIPHES) under funding number RTG 1994 / 1."}], "references": [{"title": "A Modality Lexicon and its use in Automatic Tagging", "author": ["Baker et al.2010] Kathryn Baker", "Michael Bloodgood", "Bonnie J Dorr", "Nathaniel W Filardo", "Lori Levin", "Christine Piatko"], "venue": "In Proceedings of LREC,", "citeRegEx": "Baker et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Baker et al\\.", "year": 2010}, {"title": "Assessing the impact of frame semantics on textual entailment", "author": ["Marco Pennacchiotti", "Stefan Thater", "Manfred Pinkal"], "venue": "Natural Langugae Engineering,", "citeRegEx": "Burchardt et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Burchardt et al\\.", "year": 2009}, {"title": "Natural language processing (almost) from scratch", "author": ["Jason Weston", "L\u00e9on Bottou", "Michael Karlen", "Koray Kavukcuoglu", "Pavel Kuksa"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Collobert et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Collobert et al\\.", "year": 2011}, {"title": "Did It Happen? The Pragmatic Complexity of Veridicality Assessment", "author": ["Christopher D. Manning", "Christopher Potts"], "venue": "Computational Linguistics,", "citeRegEx": "Marneffe et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Marneffe et al\\.", "year": 2012}, {"title": "The mcnemar test for binary matched-pairs data: mid-p and asymptotic are better than exact conditional", "author": ["Stian Lydersen", "Petter Laake"], "venue": "BMC medical research methodology,", "citeRegEx": "Fagerland et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Fagerland et al\\.", "year": 2013}, {"title": "Understanding the difficulty of training deep feedforward neural networks", "author": ["Glorot", "Bengio2010] Xavier Glorot", "Yoshua Bengio"], "venue": "In International conference on artificial intelligence and statistics,", "citeRegEx": "Glorot et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Glorot et al\\.", "year": 2010}, {"title": "MASC: The manually annotated sub-corpus of American English", "author": ["Ide et al.2008] Nancy Ide", "Collin Baker", "Christiane Fellbaum", "Charles Fillmore"], "venue": "In Proceedings of the Sixth International Conference on Language Resources and Evaluation", "citeRegEx": "Ide et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Ide et al\\.", "year": 2008}, {"title": "A convolutional neural network for modelling sentences", "author": ["Edward Grefenstette", "Phil Blunsom"], "venue": "In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Kalchbrenner et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kalchbrenner et al\\.", "year": 2014}, {"title": "Convolutional neural networks for sentence classification", "author": ["Yoon Kim"], "venue": "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Kim.,? \\Q2014\\E", "shortCiteRegEx": "Kim.", "year": 2014}, {"title": "Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980", "author": ["Kingma", "Ba2014] Diederik Kingma", "Jimmy Ba"], "venue": null, "citeRegEx": "Kingma et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kingma et al\\.", "year": 2014}, {"title": "Event detection and factuality assessment with non-expert supervision", "author": ["Lee et al.2015] Kenton Lee", "Yoav Artzi", "Yejin Choi", "Luke Zettlemoyer"], "venue": "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Lee et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lee et al\\.", "year": 2015}, {"title": "Dependency-based word embeddings", "author": ["Levy", "Goldberg2014] Omer Levy", "Yoav Goldberg"], "venue": "ACL", "citeRegEx": "Levy et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Levy et al\\.", "year": 2014}, {"title": "The Senseval-3 English lexical sample task", "author": ["Mihalcea et al.2004] R. Mihalcea", "T. Chklovski", "A. Kilgarriff"], "venue": "In Proceedings of SENSEVAL-3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text [CD-ROM],", "citeRegEx": "Mihalcea et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Mihalcea et al\\.", "year": 2004}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Statistical modality tagging from rule-based annotations", "author": ["Michael Bloodgood", "Mona Diab", "Bonnie Dorr", "Lori Levin", "Christine D. Piatko", "Owen Rambow", "Benjamin Van Durme"], "venue": null, "citeRegEx": "Prabhakaran et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Prabhakaran et al\\.", "year": 2012}, {"title": "Germeval-2014: Nested named entity recognition with neural networks", "author": ["Reimers et al.2014] Nils Reimers", "Judith EckleKohler", "Carsten Schnober", "Jungi Kim", "Iryna Gurevych"], "venue": "In Gertrud Faa\u00df and Josef Ruppenhofer,", "citeRegEx": "Reimers et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Reimers et al\\.", "year": 2014}, {"title": "Autoextend: Extending word embeddings to embeddings for synsets and lexemes", "author": ["Rothe", "Sch\u00fctze2015] Sascha Rothe", "Hinrich Sch\u00fctze"], "venue": "In Proceedings of the 53rd Annual Meeting of the Association", "citeRegEx": "Rothe et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Rothe et al\\.", "year": 2015}, {"title": "Yes we can !? Annotating the senses of English modal verbs", "author": ["Ruppenhofer", "Rehbein2012] Josef Ruppenhofer", "Ines Rehbein"], "venue": "In Proceedings of the LREC 2012 Conference,", "citeRegEx": "Ruppenhofer et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Ruppenhofer et al\\.", "year": 2012}, {"title": "Recursive deep models for semantic compositionality over a sentiment treebank", "author": ["Alex Perelygin", "Jean Wu", "Jason Chuang", "Christopher D. Manning", "Andrew Ng", "Christopher Potts"], "venue": null, "citeRegEx": "Socher et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Socher et al\\.", "year": 2013}, {"title": "Semi-supervised word sense disambiguation using word embeddings in general and specific domains", "author": ["Taghipour", "Ng2015] Kaveh Taghipour", "Hwee Tou Ng"], "venue": "In The 2015 Annual Conference of the North American Chapter", "citeRegEx": "Taghipour et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Taghipour et al\\.", "year": 2015}, {"title": "Parallel Data, Tools and Interfaces in OPUS", "author": ["J\u00f6rg Tiedemann"], "venue": null, "citeRegEx": "Tiedemann.,? \\Q2012\\E", "shortCiteRegEx": "Tiedemann.", "year": 2012}, {"title": "Visualizing data using t-sne", "author": ["Van der Maaten", "Geoffrey Hinton"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Maaten et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Maaten et al\\.", "year": 2008}, {"title": "Annotating expressions", "author": ["Wiebe et al.2005] Janyce Wiebe", "Theresa Wilson", "Claire Cardie"], "venue": null, "citeRegEx": "Wiebe et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Wiebe et al\\.", "year": 2005}, {"title": "A sensitivity analysis of (and practitioners\u2019 guide to) convolutional neural networks for sentence classification", "author": ["Zhang", "Wallace2015] Ye Zhang", "Byron C. Wallace"], "venue": "Technical report, University of Texas", "citeRegEx": "Zhang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2015}, {"title": "It makes sense: A wide-coverage word sense disambiguation system for free text", "author": ["Zhong", "Ng2010] Zhi Zhong", "Hwee Tou Ng"], "venue": "In Proceedings of the ACL 2010 System Demonstrations,", "citeRegEx": "Zhong et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Zhong et al\\.", "year": 2010}, {"title": "Word sense disambiguation improves information retrieval", "author": ["Zhong", "Ng2012] Zhi Zhong", "Hwee Tou Ng"], "venue": "In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),", "citeRegEx": "Zhong et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Zhong et al\\.", "year": 2012}, {"title": "Semantically Enriched Models for Modal Sense Classification", "author": ["Zhou et al.2015] Mengfei Zhou", "Anette Frank", "Annemarie Friedrich", "Alexis Palmer"], "venue": "In Proceedings of the EMNLP 2015 Workshop LSDSem: Linking Models of Lexical,", "citeRegEx": "Zhou et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Zhou et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 10, "context": "Factuality recognition (de Marneffe et al., 2012; Lee et al., 2015) is a subtask in information extraction that differentiates facts from hypotheses and speculation, expressed through signals of", "startOffset": 23, "endOffset": 67}, {"referenceID": 26, "context": "Prior work (Ruppenhofer and Rehbein, 2012; Zhou et al., 2015) addressed the task with featurebased classification.", "startOffset": 11, "endOffset": 61}, {"referenceID": 8, "context": "Kim (2014)); (ii) we show that automatically learned features in a CNN outperform manually designed features for difficult modal verbs and novel genres; (iii) we demonstrate that the CNN approach can be generalized across languages, by adapting the model to German.", "startOffset": 0, "endOffset": 11}, {"referenceID": 22, "context": "R&R induced modal sense classifiers from manual annotations on the MPQA corpus (Wiebe et al., 2005) using word-based and syntactic features.", "startOffset": 79, "endOffset": 99}, {"referenceID": 25, "context": "1 We compare to prior work in Ruppenhofer and Rehbein (2012) and followup work in Zhou et al. (2015) (henceforth, R&R and Z+).", "startOffset": 82, "endOffset": 101}, {"referenceID": 0, "context": "These senses correspond to (Baker et al., 2010)\u2019s modal categories (with deontic split into requirement and permissive), and R&Rs inventory, with regrouping of concessive, conditional and circumstantial, cf.", "startOffset": 27, "endOffset": 47}, {"referenceID": 0, "context": "These senses correspond to (Baker et al., 2010)\u2019s modal categories (with deontic split into requirement and permissive), and R&Rs inventory, with regrouping of concessive, conditional and circumstantial, cf. Zhou et al. (2015).", "startOffset": 28, "endOffset": 227}, {"referenceID": 14, "context": "Prabhakaran et al. (2012) observe strong cross-genre effects and missing generalization capacities when applying their modality classifier to out-of-domain genres.", "startOffset": 0, "endOffset": 26}, {"referenceID": 18, "context": "By contrast, recursive neural networks (Socher et al., 2013) take parsed input, recursively generate representations for intermediate phrases, and perform classification on the basis of the full sentence representation.", "startOffset": 39, "endOffset": 60}, {"referenceID": 7, "context": "Kalchbrenner et al. (2014) construct a dynamic CNN that builds on unparsed input and achieves performance beyond strong baselines for sentiment and question type classification.", "startOffset": 0, "endOffset": 27}, {"referenceID": 1, "context": "Also, FrameNet\u2019s frame-to-frame relations are known to lack coverage (Burchardt et al., 2009).", "startOffset": 69, "endOffset": 93}, {"referenceID": 13, "context": "word2vec (Mikolov et al., 2013) or dependency-based (Levy and Goldberg, 2014) embeddings.", "startOffset": 9, "endOffset": 31}, {"referenceID": 7, "context": "We thus cast MSC as a semantic sentence classification task in a CNN architecture, adopting the one-layer CNN model of Kim (2014), a variant of Collobert et al.", "startOffset": 119, "endOffset": 130}, {"referenceID": 2, "context": "We thus cast MSC as a semantic sentence classification task in a CNN architecture, adopting the one-layer CNN model of Kim (2014), a variant of Collobert et al. (2011). Unlike Kim (2014) we will use only one channel, but experiment with various types of word vectors.", "startOffset": 144, "endOffset": 168}, {"referenceID": 2, "context": "We thus cast MSC as a semantic sentence classification task in a CNN architecture, adopting the one-layer CNN model of Kim (2014), a variant of Collobert et al. (2011). Unlike Kim (2014) we will use only one channel, but experiment with various types of word vectors.", "startOffset": 144, "endOffset": 187}, {"referenceID": 2, "context": "(Collobert et al., 2011) is applied over a single feature map that extracts the maximum value \u0109 = max{c\u0303}, which represents the chosen feature for this feature map.", "startOffset": 0, "endOffset": 24}, {"referenceID": 2, "context": "(Collobert et al., 2011) is applied over a single feature map that extracts the maximum value \u0109 = max{c\u0303}, which represents the chosen feature for this feature map. Like Kim (2014) we don\u2019t use just one filter as described, but multiple filters with different region sizes n, resulting in multiple feature maps.", "startOffset": 1, "endOffset": 181}, {"referenceID": 7, "context": "Kalchbrenner et al. (2014) present n-grams of different feature detectors that capture positive or negative sentiment phrases, and also more abstract semantic categories, such as negation or degree particles (\u2019too\u2019) that are relevant in compositional sentiment detection.", "startOffset": 0, "endOffset": 27}, {"referenceID": 6, "context": "2) MASC A subset of the multi-genre corpus MASC (Ide et al., 2008), consisting of 19 genres", "startOffset": 48, "endOffset": 66}, {"referenceID": 20, "context": "Europarl and OpenSubtitles corpora of OPUS (Tiedemann, 2012) by projecting modal sense categories from English to German, using selected modal sense identifying English paraphrases.", "startOffset": 43, "endOffset": 60}, {"referenceID": 13, "context": "Word embeddings In the first and third experimental setting we investigate the impact of static and tuned versions of different word vectors: word2vec (Mikolov et al., 2013), dependencybased (Levy and Goldberg, 2014) and randomly initialized embeddings.", "startOffset": 151, "endOffset": 173}, {"referenceID": 15, "context": "We used publicly available word2vec vectors that were trained on Google News for English12 and various datasets for German (Reimers et al., 2014)13, as well as English dependency-based vectors trained on Wikipedia14 .", "startOffset": 123, "endOffset": 145}, {"referenceID": 4, "context": "(Fagerland et al., 2013) with p <0.", "startOffset": 0, "endOffset": 24}, {"referenceID": 12, "context": "As benchmark corpus we chose the SensEval-3 lexical sample data set (Mihalcea et al., 2004), which was recently applied in Rothe and Sch\u00fctze (2015) (henceforth R&S) and Taghipour and Ng (2015), using sense-specific embeddings and a NN architecture, respectively (cf.", "startOffset": 68, "endOffset": 91}, {"referenceID": 12, "context": "As benchmark corpus we chose the SensEval-3 lexical sample data set (Mihalcea et al., 2004), which was recently applied in Rothe and Sch\u00fctze (2015) (henceforth R&S) and Taghipour and Ng (2015), using sense-specific embeddings and a NN architecture, respectively (cf.", "startOffset": 69, "endOffset": 148}, {"referenceID": 12, "context": "As benchmark corpus we chose the SensEval-3 lexical sample data set (Mihalcea et al., 2004), which was recently applied in Rothe and Sch\u00fctze (2015) (henceforth R&S) and Taghipour and Ng (2015), using sense-specific embeddings and a NN architecture, respectively (cf.", "startOffset": 69, "endOffset": 193}], "year": 2016, "abstractText": "Modal sense classification (MSC) is a special WSD task that depends on the meaning of the proposition in the modal\u2019s scope. We explore a CNN architecture for classifying modal sense in English and German. We show that CNNs are superior to manually designed feature-based classifiers and a standard NN classifier. We analyze the feature maps learned by the CNN and identify known and previously unattested linguistic features. We benchmark the CNN on a standard WSD task, where it compares favorably to models using sense-disambiguated target vectors.", "creator": "LaTeX with hyperref package"}}}