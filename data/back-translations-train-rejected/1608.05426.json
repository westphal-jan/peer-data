{"id": "1608.05426", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Aug-2016", "title": "A Strong Baseline for Learning Cross-Lingual Word Embeddings from Sentence Alignments", "abstract": "While cross-lingual word embeddings have been studied extensively in recent years, the qualitative differences between the different algorithms remains vague. We observe that whether or not an algorithm uses a particular feature set (sentence IDs) accounts for a significant performance gap among these algorithms. This feature set is also used by traditional alignment algorithms, such as IBM Model-1, which demonstrate similar performance to state-of-the-art embedding algorithms on a variety of benchmarks. Overall, we observe that different algorithmic approaches for utilizing the sentence ID feature space result in similar performance. This paper draws both empirical and theoretical parallels between the embedding and alignment literature, and suggests that adding additional sources of information, which go beyond the traditional signal of bilingual sentence-aligned corpora, is an appealing approach for substantially improving crosslingual word embeddings.", "histories": [["v1", "Thu, 18 Aug 2016 20:27:46 GMT  (24kb)", "http://arxiv.org/abs/1608.05426v1", null], ["v2", "Mon, 9 Jan 2017 20:49:18 GMT  (28kb)", "http://arxiv.org/abs/1608.05426v2", "EACL 2017"]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["omer levy", "ers s{\\o}gaard", "yoav goldberg"], "accepted": false, "id": "1608.05426"}, "pdf": {"name": "1608.05426.pdf", "metadata": {"source": "CRF", "title": "Reconsidering Cross-lingual Word Embeddings", "authors": ["Omer Levy"], "emails": ["omerlevy@gmail.com", "soegaard@hum.ku.dk", "yoav.goldberg@gmail.com"], "sections": [{"heading": null, "text": "ar Xiv: 160 8.05 426v 1 [cs.C L] 18 Aug 201 6While cross-language word embedding has been extensively studied in recent years, the qualitative differences between the different algorithms remain vague. We observe that whether or not an algorithm uses a particular feature set (set IDs) is responsible for a significant performance gap between these algorithms. This feature set is also used by traditional alignment algorithms such as IBM Model-1, which perform similarly to modern embedding algorithms on a variety of benchmarks. Overall, we observe that different algorithmic approaches to the use of the set ID feature space lead to similar performance. This paper draws both empirical and theoretical parallels between embedding and embedding of words and suggests that the addition of additional information sources that go beyond the traditional signal of bilingual sentence-aligned corpora is a considerably improving the opposite approach."}, {"heading": "1 Introduction", "text": "These vectors can be used to enhance monolingual word similarity (Faruqui and Dyer, 2014) or to support translingual transfer (Gouws and S\u00f8gaard, 2015).In this paper, we focus on the second (translingual) aspect of these embeddings and try to determine what makes some embedding approaches better than others on a range of translation-oriented benchmarks. We observe that the top embedding algorithms share the same underlying feature space - sentence IDs - while their different algorithmic approaches seem to have a negligible impact on performance. We also note that several statistical algorithms, such as IBM Model-1 (Brown et al., 1993), operate under the same data assumptions."}, {"heading": "2 Background: Cross-lingual Embeddings", "text": "The first category assumes word-level alignments, in the form of bilingual dictionaries (Mikolov et al., 2013a; Xiao and Guo, 2014) or automatically generated word alignments (Klementiev et al., 2012; Zou et al., 2013; Faruqui and Dyer, 2014). Sizable bilingual dictionaries are not available for many language pairs, and the quality of automatic word alignment greatly influences the quality of embeddings. It is also unclear whether the embedding process provides significant added value beyond the original word alignments (Zou et al., 2013). The second category makes for a much weaker sentence, document-level alignments, and uses comparable texts in different languages (not necessarily translations) such as Wikipedia articles or news reports of the same event."}, {"heading": "3 Which Features Make Better Cross-lingual Embeddings?", "text": "We group state-of-the-art lingual embedding algorithms according to their features and compare their performance against two lingual benchmarks: text alignment and bilingual dictionary induction. We hope to find out which features are more meaningful."}, {"heading": "3.1 Features of Sentence-aligned Data", "text": "We observe that linguistic embedding typically uses parallel corpora in one of two ways: source + target language words Each word w is represented with all other words that appeared with it in the same sentence (source language words) and with all words that contained sentences in the target language aimed at sentences in which the word w occurred (target language words).This representation also stores the number of times each pair of words w and each feature (context) word f occurred. These features are analogous to those used by Vulic and Moens (2016) for document-oriented data, and can be constructed in a similar way: create a pseudo-bilingual sentence from each aligned sentence and consider all other words in that sentence as its characteristics for each word in question. BilBOWA (Gouws et al., 2015) also uses a similar set of features, but limits the source-language words to those that appear within a certain distance of that word and slightly differ in that sentence."}, {"heading": "3.2 Experiment Setup", "text": "We use the four algorithms mentioned in \u00a7 3.1: BilBOWA (Gouws et al., 2015), BWESkipGram (Vulic \u0301 and Moens, 2016), Bilingual Autoencoders (Chandar et al., 2014), and Inverted Index (S\u00f8gaard et al., 2015). While both BWE-SkipGram and Inverted Index were originally trained on documentary data, we apply it to sentence alignment data. Data Christodouloupoulos and Steedman (2015) collected translations of the Bible (or parts thereof) into over 100 languages, naturally aligned on book, chapter, and verse total. This word allows us to evaluate methods in many different languages while controlling the size of the training. The corpus was decapitalized and tokenized by using white spaces after punctuation."}, {"heading": "3.3 Results", "text": "Table 1 shows that algorithms based on the Sentence ID attribute space consistently perform better than those using source + target words. We suspect that the source + target attribute could capture more information than is actually required for translation, such as syntagmatic or topical similarities between words (e.g. \"dog\" or \"cattery\"), which could be distracting for cross-language tasks such as word alignment and bilingual dictionary induction. The fact that the best inverse AER characteristics are about 50% calls into question the ability to actually use these embeddings in a real scenario, and could therefore provide a cleaner translation-oriented signal. It is important to note that these results are quite poor in absolute terms. The fact that the best inverse AER characteristics are about 50% calls into question the ability to actually use these embeddings in a real scenario."}, {"heading": "4 Comparing Cross-lingual Embeddings with Traditional Alignment Methods", "text": "In particular, the cube coefficient (Och and Ney, 2003), which is often used as a starting point for more complex alignment methods, measures the linguistic similarity of words based on the number of aligned sentences in which they occurred. IBM Model-1 (Brown et al., 1993) also makes exactly the same data assumptions as other sentence ID methods. Therefore, it makes sense to use the cube similarity and the translation probabilities derived from IBM Model-1 as baseline values for lingual embeddings that use sentence identities.From Table 2, we learn that the existing embedding methods are not really better than IBM Model-1. In fact, their average performance is even slightly lower than that of Model-1. Although bilingual autoencoders, Inverted Index and Model-1 reflect completely different algorithmic approaches (or: neural sentence networks that indicate the difference between sentence and matrix, that the overall performance of EM-1 is not significantly lower than the performance."}, {"heading": "5 Generalized Dice", "text": "In this section we show that the cube coefficient (Och and Ney, 2003) can be considered a point product between two word vectors represented above the set ID attribute. After providing some background information, we will demonstrate the mathematical connection between the cube and the word attribute matrix. Then, we will introduce a new variant of cube, SID-SGNS, which works on an equal footing with Model-1 and the other embedding algorithms. This variant is able to seamlessly utilize the multilingual nature of set IDs, giving it a small but significant advantage over Model-1."}, {"heading": "5.1 Word-Feature Matrices", "text": "In word similarity literature, it is common to present words as real-valued vectors and to calculate their \"semantic\" similarity to vector similarity metrics, such as the cosine of two vectors. These word vectors are traditionally derived from sparse word-attribute matrices, either by making the rows of the matrix as-is (also known as \"explicit\" representation) or by making a low-dimensional representation # by matrix factorization (Turney and Pantel, 2010). Many modern methods, such as those in word2vec (Mikolov et al., 2013b), generate vectors by factorizing word-attribute matrices, but without explicitly displaying these matrices. Formally, we are given a vocabulary of words VW and a feature space (\"Vocabulary of Characteristics\")."}, {"heading": "5.2 Reinterpreting the Dice Coefficient", "text": "In statistical machine translation, the cube coefficient is commonly used as the basis for word alignment i = word alignment i (Och and Ney, 2003). Since sentence-oriented data (ws, wt) provide a numerical measure of how likely two words - a source-language word ws and a target-language word wt - are each the translation of the other (ws, wt): Cube (ws, wt) = 2 \u00d7 S (ws, wt) S (ws, p) \u00b7 S (4), where S (\u00b7) is the number of aligned sentences in the data in which both arguments occur. 3A function with a wildcard should be interpreted as the sum of all possible instances, e.g. I (w, w) = x I (w, x).4For reasons of consistency with the state of the art, we refer to this algorithm as SGNS (skip-grams with negative sampling), even when applied without the skip-mark."}, {"heading": "5.3 SGNS with Sentence IDs", "text": "The cube coefficient seems to be a particularly naive variant of matrix-based methods that use set IDs. For example, the inverted index (S\u00f8gaard et al., 2015), which uses SVD via IDF, followed by L2 normalization (instead of L1 normalization), shows significantly better performance. We propose to use a third variant, set ID SGNS (SID-SGNS), which simply applies SGNS (Mikolov et al., 2013b) to the word sentence ID matrix. Table 3 compares its performance (bilingual SID-SGNS) with the other methods and shows that this algorithm actually behaves similarly to other set ID-based methods. Similar results are observed for other variants, such as SVD via positive PMI (not shown)."}, {"heading": "5.4 Embedding Multiple Languages", "text": "An elegant feature of the Sentence ID feature set is that it is a truly interlingual representation, which means that multiple languages can be represented in the same matrix before they are factorized. This raises a question: Does dimension reduction through a multilingual matrix produce better interlingual vectors than it does through a bilingual matrix? We test our hypothesis by comparing the performance of embeddings trained with SID-SGNS across all 57 languages of the Bible Corpus with the performance of previously used bilingual embeddings, consistently improving performance across all development benchmarks and delivering an average performance increase of 4.69% (Table 3). With this advantage, SID-SGNS achieves significantly better performance than the other methods based on multilingual embeddings."}, {"heading": "6 Data Paradigms", "text": "To compare the data paradigms, we use the same algorithm, SID-SGNS, on document IDs from Wikipedia. [6] We use the bilingual version for both types of data to control external effects. In the evaluation, we use a common vocabulary for both sentence alignments and document-oriented embeddings (their intersections). Table 4 shows that the use of sentence IDs from the Bible usually surpasses Wikipedia. This remarkable result, where a small number of parallel sentences is sufficient to surpass one of the largest collections of multilingual texts available, suggests that document-oriented data is an inferior paradigm for translation-related tasks such as word alignment and dictionary induction."}, {"heading": "7 Conclusions", "text": "In this paper, we draw both empirical and theoretical parallels between modern cross-language word embedding and traditional alignment algorithms. Our results suggest that newer cross-language word embedding algorithms, in addition to faster algorithms and more compact representations.6 We use the word-document matrix created by S\u00f8gaard et al. (2015), which contains only a subset of our target languages: English, French and Spain.better than traditional methods.However, the introduction of our new multilingual signal significantly improves performance. Therefore, we assume that the information in bilingual, sentence-oriented data has been thoroughly elaborated by existing methods, and suggest that future work will explore additional sources of information in order to make significant progress."}], "references": [{"title": "The mathematics of statistical machine translation: Parameter estimation", "author": ["Brown et al.1993] Peter F Brown", "Vincent J Della Pietra", "Stephen A Della Pietra", "Robert L Mercer"], "venue": "Computational Linguistics,", "citeRegEx": "Brown et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Brown et al\\.", "year": 1993}, {"title": "Word alignment for english-turkish language pair", "author": ["Cakmak et al.2012] Talha Cakmak", "S\u00fcleyman Acar", "G\u00fclsen Eyrigit"], "venue": null, "citeRegEx": "Cakmak et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Cakmak et al\\.", "year": 2012}, {"title": "An autoencoder approach to learning bilingual word representations", "author": ["Stanislas Lauly", "Hugo Larochelle", "Mitesh Khapra", "Balaraman Ravindran", "Vikas C Raykar", "Amrita Saha"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "Chandar et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Chandar et al\\.", "year": 2014}, {"title": "A massively parallel corpus: The bible in 100 languages. Language Resources and Evaluation, 49(2):375\u2013395", "author": ["Christodouloupoulos", "Mark Steedman"], "venue": null, "citeRegEx": "Christodouloupoulos et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Christodouloupoulos et al\\.", "year": 2015}, {"title": "Improving vector space word representations using multilingual correlation", "author": ["Faruqui", "Dyer2014] Manaal Faruqui", "Chris Dyer"], "venue": "In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics,", "citeRegEx": "Faruqui et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Faruqui et al\\.", "year": 2014}, {"title": "Simple task-specific bilingual word embeddings", "author": ["Gouws", "S\u00f8gaard2015] Stephan Gouws", "Anders S\u00f8gaard"], "venue": "In Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,", "citeRegEx": "Gouws et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Gouws et al\\.", "year": 2015}, {"title": "Bilbowa: Fast bilingual distributed representations without word alignments", "author": ["Gouws et al.2015] Stephan Gouws", "Yoshua Bengio", "Greg Corrado"], "venue": "In Proceedings of the 32nd International Conference on Machine Learning, ICML 2015,", "citeRegEx": "Gouws et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Gouws et al\\.", "year": 2015}, {"title": "Building a golden collection of parallel multi-language word alignments", "author": ["Graca et al.2008] Joao Graca", "Joana Pardal", "Lu\u0131\u0301sa Coheur", "Diamantino Caseiro"], "venue": null, "citeRegEx": "Graca et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Graca et al\\.", "year": 2008}, {"title": "Multilingual Distributed Representations without Word Alignment", "author": ["Hermann", "Blunsom2014] Karl Moritz Hermann", "Phil Blunsom"], "venue": "In Proceedings of ICLR,", "citeRegEx": "Hermann et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hermann et al\\.", "year": 2014}, {"title": "A gold standard for englishswedish word alignment", "author": ["Holmqvist", "Ahrenberg2011] Maria Holmqvist", "Lars Ahrenberg"], "venue": "NODALIDA", "citeRegEx": "Holmqvist et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Holmqvist et al\\.", "year": 2011}, {"title": "Inducing crosslingual distributed representations of words", "author": ["Ivan Titov", "Binod Bhattarai"], "venue": "In Proceedings of COLING", "citeRegEx": "Klementiev et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Klementiev et al\\.", "year": 2012}, {"title": "Europarl: A parallel corpus for statistical machine translation", "author": ["Philipp Koehn"], "venue": "In MT Summit,", "citeRegEx": "Koehn.,? \\Q2005\\E", "shortCiteRegEx": "Koehn.", "year": 2005}, {"title": "Statistical Machine Translation", "author": ["Philipp Koehn"], "venue": null, "citeRegEx": "Koehn.,? \\Q2010\\E", "shortCiteRegEx": "Koehn.", "year": 2010}, {"title": "Guidelines for word aligment evaluation and manual alignment", "author": ["Adria de Gispert", "Rafael Banchs", "Jose Marino"], "venue": "Language Resources and Evaluation,", "citeRegEx": "Lambert et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Lambert et al\\.", "year": 2005}, {"title": "Neural word embeddings as implicit matrix factorization", "author": ["Levy", "Goldberg2014] Omer Levy", "Yoav Goldberg"], "venue": "In Advances in Neural Information Processing Systems 27: Annual Conference on Neural Information Processing Systems", "citeRegEx": "Levy et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Levy et al\\.", "year": 2014}, {"title": "Improving distributional similarity with lessons learned from word embeddings", "author": ["Levy et al.2015] Omer Levy", "Yoav Goldberg", "Ido Dagan"], "venue": "Transactions of the Association for Computational Linguistics,", "citeRegEx": "Levy et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Levy et al\\.", "year": 2015}, {"title": "Bilingual word representations with monolingual quality in mind", "author": ["Hieu Pham", "Christopher Manning"], "venue": "In Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,", "citeRegEx": "Luong et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Luong et al\\.", "year": 2015}, {"title": "An evaluation exercise for word alignment", "author": ["Mihalcea", "Pedersen2003] Rada Mihalcea", "Ted Pedersen"], "venue": "In HLT-NAACL", "citeRegEx": "Mihalcea et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Mihalcea et al\\.", "year": 2003}, {"title": "Exploiting similarities among languages for machine translation", "author": ["Quoc V Le", "Ilya Sutskever"], "venue": "arXiv preprint arXiv:1309.4168", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Ilya Sutskever", "Kai Chen", "Gregory S. Corrado", "Jeffrey Dean"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "A systematic comparison of various statistical alignment models", "author": ["Och", "Ney2003] Franz Josef Och", "Hermann Ney"], "venue": "Computational Linguistics,", "citeRegEx": "Och et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Och et al\\.", "year": 2003}, {"title": "The Word-Space Model", "author": ["Magnus Sahlgren"], "venue": null, "citeRegEx": "Sahlgren.,? \\Q2006\\E", "shortCiteRegEx": "Sahlgren.", "year": 2006}, {"title": "Inverted indexing for cross-lingual nlp", "author": ["\u017deljko Agi\u0107", "H\u00e9ctor Mart\u0131\u0301nez Alonso", "Barbara Plank", "Bernd Bohnet", "Anders Johannsen"], "venue": "In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),", "citeRegEx": "S\u00f8gaard et al\\.,? \\Q2015\\E", "shortCiteRegEx": "S\u00f8gaard et al\\.", "year": 2015}, {"title": "From frequency to meaning: Vector space models of semantics", "author": ["Turney", "Pantel2010] Peter D. Turney", "Patrick Pantel"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Turney et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Turney et al\\.", "year": 2010}, {"title": "Bilingual distributed word representations from document-aligned comparable data", "author": ["Vuli\u0107", "Moens2016] Ivan Vuli\u0107", "Marie-Francine Moens"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Vuli\u0107 et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Vuli\u0107 et al\\.", "year": 2016}, {"title": "Distributed word representation learning for cross-lingual dependency parsing", "author": ["Xiao", "Guo2014] Min Xiao", "Yuhong Guo"], "venue": "In Proceedings of the Eighteenth Conference on Computational Natural Language Learning,", "citeRegEx": "Xiao et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Xiao et al\\.", "year": 2014}, {"title": "Bilingual word embeddings for phrase-based machine translation", "author": ["Zou et al.2013] Will Y. Zou", "Richard Socher", "Daniel Cer", "Christopher D. Manning"], "venue": "In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Zou et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Zou et al\\.", "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "We also notice that several statistical alignment algorithms, such as IBM Model-1 (Brown et al., 1993), operate under the same data assumptions.", "startOffset": 82, "endOffset": 102}, {"referenceID": 10, "context": ", 2013a; Xiao and Guo, 2014) or automatically produced word alignments (Klementiev et al., 2012; Zou et al., 2013; Faruqui and Dyer, 2014).", "startOffset": 71, "endOffset": 138}, {"referenceID": 26, "context": ", 2013a; Xiao and Guo, 2014) or automatically produced word alignments (Klementiev et al., 2012; Zou et al., 2013; Faruqui and Dyer, 2014).", "startOffset": 71, "endOffset": 138}, {"referenceID": 26, "context": "It is also unclear whether the embedding process provides significant added value beyond the initial word alignments (Zou et al., 2013).", "startOffset": 117, "endOffset": 135}, {"referenceID": 22, "context": "Algorithms in this category try to leverage massive amounts of data to make up for the lack of lower-level alignments (S\u00f8gaard et al., 2015; Vuli\u0107 and Moens, 2016).", "startOffset": 118, "endOffset": 163}, {"referenceID": 21, "context": "We focus on this third category, because it does not require the strict assumption of word-aligned data (which is difficult to obtain), while still providing a cleaner and more accurate signal than document-level alignments (which have been shown, in monolingual data, to capture mainly syntagmatic relations (Sahlgren, 2006)).", "startOffset": 309, "endOffset": 325}, {"referenceID": 5, "context": "Recently, a simpler model, BilBOWA (Gouws et al., 2015), showed similar performance without using a hidden sentence-representation layer, giving it a dramatic speed advantage over its predecessors.", "startOffset": 35, "endOffset": 55}, {"referenceID": 7, "context": ", 2013a; Xiao and Guo, 2014) or automatically produced word alignments (Klementiev et al., 2012; Zou et al., 2013; Faruqui and Dyer, 2014). Sizable bilingual dictionaries are not available for many language pairs, and the quality of automatic word alignment greatly affects the quality of the embeddings. It is also unclear whether the embedding process provides significant added value beyond the initial word alignments (Zou et al., 2013). The second category makes a much weaker assumption, document-level alignments, and uses comparable texts in different languages (not necessarily translations) such as Wikipedia articles or news reports of the same event. Algorithms in this category try to leverage massive amounts of data to make up for the lack of lower-level alignments (S\u00f8gaard et al., 2015; Vuli\u0107 and Moens, 2016). Algorithms in the third category take the middle ground; they use sentence-level alignments, common in legal translations and religious texts. Also known as \u201cparallel corpora\u201d, sentence-aligned data maps each sentence (as a whole) to its translation. We focus on this third category, because it does not require the strict assumption of word-aligned data (which is difficult to obtain), while still providing a cleaner and more accurate signal than document-level alignments (which have been shown, in monolingual data, to capture mainly syntagmatic relations (Sahlgren, 2006)). Algorithms that rely on sentence-aligned data typically create intermediate sentence representations from each sentence\u2019s constituent words. Hermann and Blunsom (2014) proposed a deep neural model, BiCVM, which compared the two sentence representations at the final layer, while Chandar et al.", "startOffset": 72, "endOffset": 1575}, {"referenceID": 2, "context": "Hermann and Blunsom (2014) proposed a deep neural model, BiCVM, which compared the two sentence representations at the final layer, while Chandar et al. (2014) proposed a shallower autoencoder-based model, representing both source and target language sentences as the same intermediate sentence vector.", "startOffset": 138, "endOffset": 160}, {"referenceID": 2, "context": "Hermann and Blunsom (2014) proposed a deep neural model, BiCVM, which compared the two sentence representations at the final layer, while Chandar et al. (2014) proposed a shallower autoencoder-based model, representing both source and target language sentences as the same intermediate sentence vector. Recently, a simpler model, BilBOWA (Gouws et al., 2015), showed similar performance without using a hidden sentence-representation layer, giving it a dramatic speed advantage over its predecessors. BilBOWA is essentially an extension of skip-grams with negative sampling (SGNS) (Mikolov et al., 2013b), which simultaneously optimizes each word\u2019s similarity to its inter-lingual context (words that appeared in the aligned target language sentence) and its intra-lingual context (as in the original monolingual model). Luong et al. (2015) proposed a similar SGNS-based model over the same features.", "startOffset": 138, "endOffset": 841}, {"referenceID": 5, "context": "BilBOWA (Gouws et al., 2015) also uses a similar set of features, but restricts the source language words to those that appeared within a certain distance from the word in question, and defines a slightly different interaction with target language words.", "startOffset": 8, "endOffset": 28}, {"referenceID": 2, "context": "This approach is implicitly used by Chandar et al. (2014), who encode the bag-of-words representation of two parallel sentences into the same vector.", "startOffset": 36, "endOffset": 58}, {"referenceID": 2, "context": "This approach is implicitly used by Chandar et al. (2014), who encode the bag-of-words representation of two parallel sentences into the same vector. Thus, each word is not matched directly to another word (as in the previous feature space), but rather used to create the sentence\u2019s language-independent representation; this is analogous to matching a word with a sentence ID. S\u00f8gaard et al. (2015) use similar features, document IDs, for leveraging comparable Wikipedia articles in different languages.", "startOffset": 36, "endOffset": 399}, {"referenceID": 5, "context": "1: BilBOWA (Gouws et al., 2015), BWESkipGram (Vuli\u0107 and Moens, 2016), Bilingual Autoencoders (Chandar et al.", "startOffset": 11, "endOffset": 31}, {"referenceID": 2, "context": ", 2015), BWESkipGram (Vuli\u0107 and Moens, 2016), Bilingual Autoencoders (Chandar et al., 2014), and Inverted Index (S\u00f8gaard et al.", "startOffset": 69, "endOffset": 91}, {"referenceID": 22, "context": ", 2014), and Inverted Index (S\u00f8gaard et al., 2015).", "startOffset": 28, "endOffset": 50}, {"referenceID": 7, "context": "We use 16 manually annotated word alignment datasets \u2013 Hansards2 and data from four other sources (Graca et al., 2008; Lambert et al., 2005; Mihalcea and Pedersen, 2003; Holmqvist and Ahrenberg, 2011; Cakmak et al., 2012) \u2013 as well as 16 bilingual dictionaries from Wiktionary.", "startOffset": 98, "endOffset": 221}, {"referenceID": 13, "context": "We use 16 manually annotated word alignment datasets \u2013 Hansards2 and data from four other sources (Graca et al., 2008; Lambert et al., 2005; Mihalcea and Pedersen, 2003; Holmqvist and Ahrenberg, 2011; Cakmak et al., 2012) \u2013 as well as 16 bilingual dictionaries from Wiktionary.", "startOffset": 98, "endOffset": 221}, {"referenceID": 1, "context": "We use 16 manually annotated word alignment datasets \u2013 Hansards2 and data from four other sources (Graca et al., 2008; Lambert et al., 2005; Mihalcea and Pedersen, 2003; Holmqvist and Ahrenberg, 2011; Cakmak et al., 2012) \u2013 as well as 16 bilingual dictionaries from Wiktionary.", "startOffset": 98, "endOffset": 221}, {"referenceID": 0, "context": "In the word alignment benchmark, each word in a given source language sentence is aligned with the most similar target language word from the target language sentence \u2013 this is exactly the same greedy decoding algorithm that is implemented in IBM Model-1 (Brown et al., 1993).", "startOffset": 255, "endOffset": 275}, {"referenceID": 0, "context": "In the word alignment benchmark, each word in a given source language sentence is aligned with the most similar target language word from the target language sentence \u2013 this is exactly the same greedy decoding algorithm that is implemented in IBM Model-1 (Brown et al., 1993). If a source language word is out of vocabulary, it is not aligned with anything, whereas target language out-of-vocabulary words are given a default minimal similarity score, and never aligned to any candidate source language word in practice. We use the inverse of alignment error rate (1-AER) as described in Koehn (2010) to measure performance, where higher scores mean better alignments.", "startOffset": 256, "endOffset": 601}, {"referenceID": 14, "context": "Hyperparameters Levy et al. (2015) exposed a collection of hyperparameters that affect the performance of monolingual embeddings.", "startOffset": 16, "endOffset": 35}, {"referenceID": 2, "context": "(Chandar et al., 2014)) used an even smaller dataset (the first 10K sentences in Europarl (Koehn, 2005)).", "startOffset": 0, "endOffset": 22}, {"referenceID": 11, "context": ", 2014)) used an even smaller dataset (the first 10K sentences in Europarl (Koehn, 2005)).", "startOffset": 75, "endOffset": 88}, {"referenceID": 0, "context": "IBM Model-1 (Brown et al., 1993) also makes exactly the same data assumptions as other sentence-ID methods.", "startOffset": 12, "endOffset": 32}, {"referenceID": 22, "context": "For example, Inverted Index (S\u00f8gaard et al., 2015)), which uses SVD over IDF followed by L2 normalization (instead of L1 normalization), shows significantly better performance.", "startOffset": 28, "endOffset": 50}, {"referenceID": 22, "context": "We observed a similar increase in performance when applying the multi-lingual signal to S\u00f8gaard et al.\u2019s (2015) IDF-based method and to SVD over positive PMI.", "startOffset": 88, "endOffset": 112}, {"referenceID": 22, "context": "Our results suggest that apart from faster algorithms and more compact representations, recent cross-lingual word embedding algorithms are still unable to We use the word-document matrix mined by S\u00f8gaard et al. (2015), which contains only a subset of our target languages: English, French, and Spanish.", "startOffset": 196, "endOffset": 218}], "year": 2016, "abstractText": "While cross-lingual word embeddings have been studied extensively in recent years, the qualitative differences between the different algorithms remains vague. We observe that whether or not an algorithm uses a particular feature set (sentence IDs) accounts for a significant performance gap among these algorithms. This feature set is also used by traditional alignment algorithms, such as IBM Model-1, which demonstrate similar performance to state-of-the-art embedding algorithms on a variety of benchmarks. Overall, we observe that different algorithmic approaches for utilizing the sentence ID feature space result in similar performance. This paper draws both empirical and theoretical parallels between the embedding and alignment literature, and suggests that adding additional sources of information, which go beyond the traditional signal of bilingual sentence-aligned corpora, is an appealing approach for substantially improving crosslingual word embeddings.", "creator": "LaTeX with hyperref package"}}}