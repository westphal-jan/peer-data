{"id": "1608.05675", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Aug-2016", "title": "lpopt: A Rule Optimization Tool for Answer Set Programming", "abstract": "State-of-the-art answer set programming (ASP) solvers rely on a program called a grounder to convert non-ground programs containing variables into variable-free, propositional programs. The size of this grounding depends heavily on the size of the non-ground rules, and thus, reducing the size of such rules is a promising approach to improve solving performance. To this end, in this paper we announce lpopt, a tool that decomposes large logic programming rules into smaller rules that are easier to handle for current solvers. The tool is specifically tailored to handle the standard syntax of the ASP language (ASP-Core) and makes it easier for users to write efficient and intuitive ASP programs, which would otherwise often require significant hand-tuning by expert ASP engineers. It is based on an idea proposed by Morak and Woltran (2012) that we extend significantly in order to handle the full ASP syntax, including complex constructs like aggregates, weak constraints, and arithmetic expressions. We present the algorithm, the theoretical foundations on how to treat these constructs, as well as an experimental evaluation showing the viability of our approach.", "histories": [["v1", "Fri, 19 Aug 2016 17:20:03 GMT  (269kb,D)", "https://arxiv.org/abs/1608.05675v1", "Pre-proceedings paper presented at the 26th International Symposium on Logic-Based Program Synthesis and Transformation (LOPSTR 2016), Edinburgh, Scotland UK, 6-8 September 2016 (arXiv:1608.02534), 14 pages, LaTeX, 2 figures"], ["v2", "Tue, 23 Aug 2016 07:59:54 GMT  (269kb,D)", "http://arxiv.org/abs/1608.05675v2", "Pre-proceedings paper presented at the 26th International Symposium on Logic-Based Program Synthesis and Transformation (LOPSTR 2016), Edinburgh, Scotland UK, 6-8 September 2016 (arXiv:1608.02534), 14 pages, LaTeX, 2 figures"]], "COMMENTS": "Pre-proceedings paper presented at the 26th International Symposium on Logic-Based Program Synthesis and Transformation (LOPSTR 2016), Edinburgh, Scotland UK, 6-8 September 2016 (arXiv:1608.02534), 14 pages, LaTeX, 2 figures", "reviews": [], "SUBJECTS": "cs.LO cs.AI cs.PL", "authors": ["manuel bichler", "michael morak", "stefan woltran"], "accepted": false, "id": "1608.05675"}, "pdf": {"name": "1608.05675.pdf", "metadata": {"source": "META", "title": "lpopt: A Rule Optimization Tool for Answer Set Programming Author=Manuel Bichler, Michael Morak, and Stefan Woltran", "authors": ["Manuel Bichler", "Michael Morak", "Stefan Woltran"], "emails": ["surname@dbai.tuwien.ac.at"], "sections": [{"heading": "1 Introduction", "text": "This year, it is more than ever before in the history of the city in which we find ourselves."}, {"heading": "2 Preliminaries", "text": "We define two pairs of separate sets of symbols: a set of constants and a set of variables. Different constants represent different values (unambiguous denomination assumption). By X we denote sequences (or, with slight misuse of notation, sentences) of variables X1,.., Xk with k > 0. We write p / n for the fact that p is a n-like predicate. A term is a constant or variable. An atomic formula a over S (called S-atom) has the form p (t), where p / t is a sequence of terms."}, {"heading": "3 Rule Decomposition", "text": "This section describes the theoretical basis for our rule-breaking approach. First, we recall the algorithm [18] and then describe how it can be extended to handle three of the most important extensions of the ASP language, namely arithmetic expressions, aggregates, and weak constraints (i.e. optimization instructions) as defined in the ASP core language standard [10]. As shown in Example 1, rules that are intuitive to write and read are not necessarily the most efficient to evaluate in practice. ASP solvers generally struggle with rules that contain many variables because they are based on a grounding approach: First, the grounding of a logic program is calculated from a grounding approach. In the worst case, according to the definition in Section 2, the size of the grounding can be exponential in the number of variables because they rely on a grounding approach."}, {"heading": "3.1 Decomposition of Simple Rules", "text": "In general, the approach is Yn (n), where the tree decomposition of a rule (s), and then divides the rule into several, smaller rules after that decomposition. (n) At worst, this decomposition may not change the rule at all, in practice it is often the case that large rules can be very well divided. (n) The big rule in Example 1 will be affordable for such decomposition. (n) Let's briefly look at the algorithms from [18], which we will call the lpopt algorithm. (n) For a given rule, the algorithm will work as follows: 1. Comment a tree decomposition T = (T) of the minimum width, where all the variables are contained in its root node. (2) For each node n, let Tempn be a fresh predicate, and the same for each variable X and predicate domX."}, {"heading": "3.2 Treating Arithmetic Expressions", "text": "Arithmetic expressions are atoms of the form X = \u0432 (Y), i.e. an equality with a variable (or constant number) X on the left, and an expression on the right, where each mathematical expression uses the variables of Y, constant numbers, and the arithmetic connectives \"+\" -, \"\" *, \"and\" /. \"In addition to positive and negative fields, a \u03c0 rule can also contain a set of such arithmetic expressions that describe a relationship between variables with obvious meanings. Clearly, in order to adapt the rule-splitting approach to these, it is easy to expand the definition of the graph representation of populations to simply include a clique between all variables occurring together in an arithmetic expression. The lpopt algorithm then works as described above up to step 2. However, a problem may arise if a domain is dictated in step 3 of the lpopt algorithm."}, {"heading": "3.3 Treating Weak Constraints", "text": "As defined in [10], a weak constraint \u03c0 [k: t] is a constraint \u03c0 commented with a term k representing a weight and a sequence of terms t occurring in \u03c0. The intended meaning is that each answer sentence I is commented by a total weight w (I), which is the sum of all k for each tuple of constants c, which realize t in I and satisfy the body of \u03c0. Such a weak constraint can be easily dissected by replacing \u03c0 [k: t] with the rule \u03c0 \u2032 = temperature (k, t) \u2190 B (\u03c0), where temperature is a fresh predicate, and the weak constraint \u0438 temp (k, t) [k: t]. Finally, the lpopt algorithm is then applied to rule \u03c0 \u2032. This makes it possible to apply our rule-breaking approach also in an optimization context (i.e., where the problem for the solver is to find optimal answers to its weight)."}, {"heading": "3.4 Treating Aggregate Expressions", "text": "An aggregated expression as defined in [10] is an expression of the forms 4 # agg [4] term [4].aggregated expression is an expression of the forms 4 # agg [4] term [4].aggregated expression is an expression of summa, count, max, and min; t = < t1,. aggregated expression is a set of letters, arithmetic expressions, and aggregated expressions called aggregated bodies. Aggregates may appear in rules or recursively in other aggregates, with the following semantic meaning: In view of an interpretation that I interpret for any valid substitution, s (X) I take the tuple of the constants s (t)."}, {"heading": "3.5 Correctness", "text": "The correctness of the above extensions of the original algorithm results from the same arguments that prove the correctness of the original algorithm proposed in [18], trivially, from the construction of arithmetic expressions and security. Note that for domain predicates of variable X, we explicitly select a set of atoms that make the variable safe, and that such a set always exists because the original rule is safe. For the first two (namely, weak constraints and aggregated expressions), the only thing that needs to be investigated is the first step: the replacement of (part of) the body by a temporary predicate. However, the correctness of this set is easy to detect. Instead of making all connections within the weak constraint or aggregation, we perform the connection in a new, separate rule, and project only relevant variables into a temporary predicate. The weak constraint or aggregation then needs to be taken into account, as all connections within the weak constraint or aggregation, or aggregation, we only make the preliminary ones, as the others do not play a role in the predicate."}, {"heading": "3.6 Further Language Extensions", "text": "The ASP Core Language Specification [10] and the Gringo Grounder1 allow, in addition to various extensions that are equivalent to syntactic sugar, further constructs such as variable pooling, aggregates with several solids or with upper and lower boundaries in the same expression. These constructs make the above explanations unnecessarily tedious. Theoretically, however, all these additional constructs can be normalized to one of the forms discussed in the previous subsections. In addition, as we will see in the next section, we have implemented the lpopt algorithm to directly handle all common ASP language constructs and certain other additions such as variable pooling. Further details on this general approach and the exact but tedious details of the algorithm can be found in [4]."}, {"heading": "4 Implementation", "text": "This year it is more than ever before."}, {"heading": "5 Experimental Evaluation", "text": "This year, the time has come for you to be able to leave the country in which you are."}, {"heading": "6 Conclusions", "text": "In this article, we present an algorithm based on a prototype from [18] that allows the decomposition of large logical programming rules into smaller ones that programmers can better handle on the current state of the art. Our implementation covers the entire ASP Core 2 language [10]. Benchmark results show that our rule decomposition algorithm can significantly improve the solution performance in practice, even for comprehensively hand-tuned ASP programs. Future work includes the direct implementation of this approach in modern grounding systems such as the Gringo-Grounder used in our benchmarks, as well as the further refinement of the algorithm in the selection of domain predicateoms, as discussed at the end of Section 5. Recognition. Supported by the Austrian Science Fund (FWF): Y698, P25607."}], "references": [{"title": "WASP: A native ASP solver based on constraint learning", "author": ["M. Alviano", "C. Dodaro", "W. Faber", "N. Leone", "F. Ricca"], "venue": "Proc. LPNMR. pp", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2013}, {"title": "The disjunctive datalog system DLV", "author": ["M. Alviano", "W. Faber", "N. Leone", "S. Perri", "G. Pfeifer", "G. Terracina"], "venue": "Datalog Reloaded. Revised Selected Papers. pp", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2010}, {"title": "Complexity of finding embeddings in a k-tree", "author": ["S. Arnborg", "D.G. Corneil", "A. Proskurowski"], "venue": "SIAM J. Algeb. Discr. Meth. 8(2),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1987}, {"title": "Optimizing non-ground answer set programs via rule decomposition", "author": ["M. Bichler"], "venue": "BSc Thesis, TU Wien. http://dbai.tuwien.ac.at/proj/lpopt", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2015}, {"title": "The power of non-ground rules in answer set programming", "author": ["M. Bichler", "M. Morak", "S. Woltran"], "venue": "Proc. ICLP", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2016}, {"title": "A linear-time algorithm for finding tree-decompositions of small treewidth", "author": ["H.L. Bodlaender"], "venue": "SIAM J. Comput", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1996}, {"title": "Answer set programming at a glance", "author": ["G. Brewka", "T. Eiter", "M. Truszczynski"], "venue": "Commun. ACM 54(12),", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2011}, {"title": "GRAPPA: A semantical framework for graph-based argument processing", "author": ["G. Brewka", "S. Woltran"], "venue": "Proc. ECAI. pp", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "ASP-Core-2 Input Language Format v2.03c", "author": ["F. Calimeri", "W. Faber", "M. Gebser", "G. Ianni", "R. Kaminski", "T. Krennwallner", "N. Leone", "F. Ricca", "T. Schaub"], "venue": "https://www", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2013}, {"title": "Design and results of the fifth answer set programming competition", "author": ["F. Calimeri", "M. Gebser", "M. Maratea", "F. Ricca"], "venue": "Artif. Intell", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2015}, {"title": "Smodels - A system for computing answer sets of logic programs with aggregates", "author": ["I. Elkabani", "E. Pontelli", "T.C. Son"], "venue": "Proc. LPNMR. pp", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2005}, {"title": "Answer Set Solving in Practice", "author": ["M. Gebser", "R. Kaminski", "B. Kaufmann", "T. Schaub"], "venue": "Synthesis Lectures on Artificial Intelligence and Machine Learning,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "Conflict-driven answer set solving: From theory to practice", "author": ["M. Gebser", "B. Kaufmann", "T. Schaub"], "venue": "Artif. Intell. 187,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2012}, {"title": "The stable model semantics for logic programming", "author": ["M. Gelfond", "V. Lifschitz"], "venue": "Proc. ICLP/SLP. pp. 1070\u20131080", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1988}, {"title": "A System for Advanced Graphical Argumentation Formalisms", "author": ["G. Hei\u00dfenberger"], "venue": "Master\u2019s thesis, TU Wien (2016),", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2016}, {"title": "Stable Models and an Alternative Logic Programming Paradigm", "author": ["V.W. Marek", "M. Truszczy\u0144ski"], "venue": "The Logic Programming Paradigm \u2013 A 25-Year Perspective, pp. 375\u2013398. Springer", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1999}, {"title": "Preprocessing of complex non-ground rules in answer set programming", "author": ["M. Morak", "S. Woltran"], "venue": "Proc. ICLP. pp", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2012}], "referenceMentions": [{"referenceID": 13, "context": "Answer set programming (ASP) [15,17,8,13] is a well-established logic programming paradigm based on the stable model semantics of logic programs.", "startOffset": 29, "endOffset": 41}, {"referenceID": 15, "context": "Answer set programming (ASP) [15,17,8,13] is a well-established logic programming paradigm based on the stable model semantics of logic programs.", "startOffset": 29, "endOffset": 41}, {"referenceID": 6, "context": "Answer set programming (ASP) [15,17,8,13] is a well-established logic programming paradigm based on the stable model semantics of logic programs.", "startOffset": 29, "endOffset": 41}, {"referenceID": 11, "context": "Answer set programming (ASP) [15,17,8,13] is a well-established logic programming paradigm based on the stable model semantics of logic programs.", "startOffset": 29, "endOffset": 41}, {"referenceID": 12, "context": "[14,1,12,2]\u2014have made huge strides in efficiency.", "startOffset": 0, "endOffset": 11}, {"referenceID": 0, "context": "[14,1,12,2]\u2014have made huge strides in efficiency.", "startOffset": 0, "endOffset": 11}, {"referenceID": 10, "context": "[14,1,12,2]\u2014have made huge strides in efficiency.", "startOffset": 0, "endOffset": 11}, {"referenceID": 1, "context": "[14,1,12,2]\u2014have made huge strides in efficiency.", "startOffset": 0, "endOffset": 11}, {"referenceID": 16, "context": "This tool, based on an idea proposed for very simple ASP programs in [18], uses the concept of tree decompositions of rules to split them into smaller chunks.", "startOffset": 69, "endOffset": 73}, {"referenceID": 8, "context": "We then extend the algorithm to handle the entire standardized ASP language [10], and also introduce new optimizations for complex language constructs such as weak constraints, arithmetic expressions, and aggregates.", "startOffset": 76, "endOffset": 80}, {"referenceID": 16, "context": "\u2013 we extend, on a theoretical basis, the lpopt algorithm proposed in [18] to the full syntax of the ASP language according to the ASP-Core-2 language specification [10];", "startOffset": 69, "endOffset": 73}, {"referenceID": 8, "context": "\u2013 we extend, on a theoretical basis, the lpopt algorithm proposed in [18] to the full syntax of the ASP language according to the ASP-Core-2 language specification [10];", "startOffset": 164, "endOffset": 168}, {"referenceID": 2, "context": "To decide whether a graph has treewidth at most k is NP-complete [3].", "startOffset": 65, "endOffset": 68}, {"referenceID": 5, "context": "For an arbitrary but fixed k however, this problem can be solved (and a tree decomposition constructed) in linear time [6].", "startOffset": 119, "endOffset": 122}, {"referenceID": 16, "context": "First, we recall the algorithm from [18], and then describe how it can be extended to handle three of the main extensions of the ASP language, namely arithmetic expressions, aggregates, and weak constraints (i.", "startOffset": 36, "endOffset": 40}, {"referenceID": 8, "context": "optimization statements), as defined in the ASP-Core language standard [10].", "startOffset": 71, "endOffset": 75}, {"referenceID": 16, "context": "One way to do this is the rule decomposition approach, first proposed in [18], which we will briefly recall next.", "startOffset": 73, "endOffset": 77}, {"referenceID": 16, "context": "Generally speaking, the approach in [18] computes the tree decomposition of a rule, and then splits the rule up into multiple, smaller rules according to this decomposition.", "startOffset": 36, "endOffset": 40}, {"referenceID": 16, "context": "Let us briefly recall the algorithm from [18] which we will refer to as the lpopt algorithm.", "startOffset": 41, "endOffset": 45}, {"referenceID": 16, "context": "When the above algorithm is applied to all rules in \u03a0 , resulting in a logic program lpopt(\u03a0) as stated in [18], the answer sets of \u03a0 are preserved in the following way: when all temporary atoms are removed, each answer set of lpopt(\u03a0) coincides with exactly one answer set from the original program \u03a0 .", "startOffset": 107, "endOffset": 111}, {"referenceID": 16, "context": "Theorem 1 ([18]).", "startOffset": 11, "endOffset": 15}, {"referenceID": 16, "context": "As [18] demonstrates, this decomposition approach already has a significant impact on the size of the grounding in practical instances.", "startOffset": 3, "endOffset": 7}, {"referenceID": 8, "context": "However, the ASP language standard [10] extends the ASP language with other useful constructs that the lpopt algorithm proposed in [18] cannot handle.", "startOffset": 35, "endOffset": 39}, {"referenceID": 16, "context": "However, the ASP language standard [10] extends the ASP language with other useful constructs that the lpopt algorithm proposed in [18] cannot handle.", "startOffset": 131, "endOffset": 135}, {"referenceID": 9, "context": "the encodings used in recent ASP competitions [11], a large majority use such constructs.", "startOffset": 46, "endOffset": 50}, {"referenceID": 8, "context": "The conditions for safety of rules with arithmetic expressions are defined in the ASP language specification [10].", "startOffset": 109, "endOffset": 113}, {"referenceID": 8, "context": "As defined in [10], a weak constraint \u03c0[k : t] is a constraint \u03c0 annotated with a term k representing a weight and a sequence of terms t occurring in \u03c0.", "startOffset": 14, "endOffset": 18}, {"referenceID": 8, "context": "An aggregate expression, as defined in [10], is an expression of the form", "startOffset": 39, "endOffset": 43}, {"referenceID": 16, "context": "The correctness of the above extensions to the original algorithm follows by the same arguments that prove the correctness of the original algorithm proposed in [18], and trivially from the construction for arithmetic expressions and safety.", "startOffset": 161, "endOffset": 165}, {"referenceID": 16, "context": "Finally, the original algorithm from [18] extended to handle arithmetic expressions, for which correctness has already been established, is then applied to this new, separate rule.", "startOffset": 37, "endOffset": 41}, {"referenceID": 8, "context": "The ASP-Core language specification [10], as well as the gringo grounder1, allow further constructs like variable pooling, aggregates with multiple bodies, or with upper and lower bounds in the same expression, in addition to various extensions that amount to syntactic sugar.", "startOffset": 36, "endOffset": 40}, {"referenceID": 3, "context": "More details about this general approach, and the exact, but more tedious, algorithm details, can be found in [4].", "startOffset": 110, "endOffset": 113}, {"referenceID": 8, "context": "lpopt accepts as its input any form of ASP program that follows the ASP input language specification laid out in [10].", "startOffset": 113, "endOffset": 117}, {"referenceID": 12, "context": "One established solver that we will use in the next section for our experimental evaluation is clasp [14].", "startOffset": 101, "endOffset": 105}, {"referenceID": 3, "context": "Full benchmark results for the entire dataset can be found in [4].", "startOffset": 62, "endOffset": 65}, {"referenceID": 14, "context": "For example, in [16] ASP rewritings for several problems from the abstract argumentation domain, proposed in [9], are implemented.", "startOffset": 16, "endOffset": 20}, {"referenceID": 7, "context": "For example, in [16] ASP rewritings for several problems from the abstract argumentation domain, proposed in [9], are implemented.", "startOffset": 109, "endOffset": 112}, {"referenceID": 4, "context": "Another example is [5], where multiple rewritings for \u03a32 P and \u03a3 3 P-hard problems are proposed and then benchmarked, again showcasing that without lpopt these rewritings could not be solved by current ASP solvers in all but the most simple cases.", "startOffset": 19, "endOffset": 22}, {"referenceID": 16, "context": "In this paper, we present an algorithm, based on a prototype from [18], that allows the decomposition of large logic programming rules into smaller ones that current state-ofthe-art answer set programming solvers are better equipped to handle.", "startOffset": 66, "endOffset": 70}, {"referenceID": 8, "context": "Our implementation handles the entire ASP-Core-2 language [10].", "startOffset": 58, "endOffset": 62}], "year": 2016, "abstractText": "State-of-the-art answer set programming (ASP) solvers rely on a program called a grounder to convert non-ground programs containing variables into variable-free, propositional programs. The size of this grounding depends heavily on the size of the non-ground rules, and thus, reducing the size of such rules is a promising approach to improve solving performance. To this end, in this paper we announce lpopt, a tool that decomposes large logic programming rules into smaller rules that are easier to handle for current solvers. The tool is specifically tailored to handle the standard syntax of the ASP language (ASP-Core) and makes it easier for users to write efficient and intuitive ASP programs, which would otherwise often require significant hand-tuning by expert ASP engineers. It is based on an idea proposed by Morak and Woltran (2012) that we extend significantly in order to handle the full ASP syntax, including complex constructs like aggregates, weak constraints, and arithmetic expressions. We present the algorithm, the theoretical foundations on how to treat these constructs, as well as an experimental evaluation showing the viability of our approach.", "creator": "LaTeX with hyperref package"}}}