{"id": "1608.06007", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Aug-2016", "title": "Distributed Probabilistic Bisection Search using Social Learning", "abstract": "We present a novel distributed probabilistic bisection algorithm using social learning with application to target localization. Each agent in the network first constructs a query about the target based on its local information and obtains a noisy response. Agents then perform a Bayesian update of their beliefs followed by a local averaging of the log beliefs. This two stage algorithm consisting of repeated querying and averaging runs until convergence. We derive bounds on the rate of convergence of the beliefs at the correct target location. Numerical simulations show that our method outperforms current state of the art methods.", "histories": [["v1", "Sun, 21 Aug 2016 22:14:48 GMT  (30kb)", "http://arxiv.org/abs/1608.06007v1", "5 Pages, Submitted to ICASSP 2017"], ["v2", "Wed, 28 Dec 2016 02:17:22 GMT  (30kb)", "http://arxiv.org/abs/1608.06007v2", "5 Pages, Accepted to ICASSP 2017"]], "COMMENTS": "5 Pages, Submitted to ICASSP 2017", "reviews": [], "SUBJECTS": "cs.SI cs.LG cs.MA", "authors": ["athanasios tsiligkaridis", "theodoros tsiligkaridis"], "accepted": false, "id": "1608.06007"}, "pdf": {"name": "1608.06007.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Theodoros Tsiligkaridis"], "emails": ["atsili@bu.edu", "ttsili@ll.mit.edu"], "sections": [{"heading": null, "text": "ar Xiv: 160 8.06 007v 1 [cs.S I] 2 1A ug2 01Index Terms - Probabilistic bisection, consensus, decentralized estimation, convergence rate, faith sharing"}, {"heading": "1. INTRODUCTION", "text": "We consider the problem of distributed bisection search with a network of agents. This problem has applications to stochastic root finding algorithms, distributed group testing, object tracking with cameras, and localization in sensor networks. The agents are connected by a topology, and sequential search for the unknown target X *. Each agent forms a query Zi, t = I (X *, Si, t) for some subset Si, t * X based on its local information about the destination and receives a loud response, Yi, t + 1, which he uses to update his belief. After this stage, the agents average their log beliefs with their neighbors. Since this process is repeated after several iterations, the agents convert to the correct consensus.Prior work on distributed signal processing includes the consensus literature [1, 2]. Extensions to consensus plus innovations include algorithms with applications for detecting and estimating the problems ynasze."}, {"heading": "2. PROBLEM FORMULATION", "text": "For concreteness, we focus on the one-dimensional case, i.e, X = [0, 1]. In this case, the query sets Si, t take the form of an interval [0, X, i, t] in which X, i, t are the query points. The answer to the query Zi, t = I (X, x, p) is modelled as a binary symmetric channel [8, 10, 11] and is defined by: Yi, t + 1 = {Zi, t w.p 1 \u2212 1 \u2212 Zi, t w.p, iWe define pi, t (x) as posterior distribution to the target space X = [0, 1] for time. We also designate the corresponding CDF as Fi, t (x) = x0 pi pi, t (u) du. The post-rior distributions at the time are measurable."}, {"heading": "3. PERFORMANCE ANALYSIS", "text": "In this section, we define a lower boundary at the back of the distribution boundary pi, t (x) at the finish line. Our result shows that for large t pi, t (X), t (X), p (n), p (1), p (2), p (1), p (1), p (1), p (1), p (1), p (1), p (1), p (1), p (1), p (1), p (1), p (1), p (1), p (1), p (1), p (1), p (1), p (1), p (1), p (1), p (1), p (1), p (1), p (1), p (1), p (1), p (1), p, p (1), p, p (1), p, p (1), p (1), p, p (1), p, p (1), p (1), p (1), p, p (1), p (1, p, p, p (1), p (1), p, p (1, p, p (1), p, p (1), p, p (1, p, p, p (1), p, p (1, p, p, p (1), p, p (1), p (1, p, p, p (1), p, p (1, p, p (1), p, p (1), p (1, p (1), p (1, p, p, p (1), p (1, p, p (1), p, p (1, p, p (1), p (1), p, p (1, p (1), p (1, p, p (1), p, p (1, p (1, p, p (1), p, p, p (1, p, p (1), p (1, p, p, p (1), p (1, p, p, p (1), p, p (1, p, p, p, p ("}, {"heading": "4. SIMULATIONS", "text": "In order to validate and strengthen the previous performance analysis, simulations are performed to show that the proposed method performs better than the proposed consensus of belief approach of [11] and in the case of no interagent collaboration. We randomly generate an irreducible N \u00b7 N adjacency matrix, which represents a random geometric graph [15] (see Figure 1). In this setup, N = 20 and 18 agents have high error probabilities (i = 0.40), while the remaining 2 have low error probabilities (i = 0.05). The low error agents are those with the highest two vi's, so that they can positively affect the high error nodes around them. Figure 1 shows the 2 low error nodes and their connections in blue together with the other nodes and their connections in black. Figure 2 shows the average network Mean Squared Error (MSE), N N, N, N, N, N, N, N, N, N, N, N, N, N, N, N, N, N, N, N, N, N, N, N, N, N, N, N, N, N."}, {"heading": "5. CONCLUSION", "text": "In this thesis, we proposed a new distributed probabilistic bisection algorithm for target localization and derived a lower limit for convergence rate. Through analysis and simulation, we show that our proposed method achieves better results in terms of convergence rate and MSE than other state-of-the-art methods. For future work, a more refined and rigorous analysis of the convergence rate for the periodic case can be pursued."}, {"heading": "6. REFERENCES", "text": "[1] S. Boyd, A. Ghosh, B. Prabhakar, and D. Shah, \"Randomized Gossip Algorithms,\" IEEE Transactions on Information Theory, vol. 52, no. 6, pp. 2508-2530, June 2006. [2] A. Dimakis, S. Kar, J. M. Moura, M. G. Rabbat, and A. Scaglione, \"Gossip Algorithms for Distributed Signal Processing,\" Proceedings of the IEEE, vol. 98, pp. 1847-1864, November 2010. [3] S. Kar and J. M. F. Moura, \"Convergence Rate Analysis of Distributed Gossip (Linear Parameter) Estimation: Fundamental Limits and Tradeoffs,\" IEEE Journal of Selected Topics in Signal Processing, vol. 5, no."}], "references": [{"title": "Randomized Gossip Algorithms", "author": ["S. Boyd", "A. Ghosh", "B. Prabhakar", "D. Shah"], "venue": "IEEE Transactions on Information Theory, vol. 52, no. 6, pp. 2508\u20132530, June 2006.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2006}, {"title": "Gossip Algorithms for Distributed Signal Processing", "author": ["A. Dimakis", "S. Kar", "J.M.F. Moura", "M.G. Rabbat", "A. Scaglione"], "venue": "Proceedings of the IEEE, vol. 98, no. 11, pp. 1847\u20131864, November 2010.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1847}, {"title": "Convergence Rate Analysis of Distributed Gossip (Linear Parameter) Estimation: Fundamental Limits and Tradeoffs", "author": ["S. Kar", "J.M.F. Moura"], "venue": "IEEE Journal of Selected Topics in Signal Processing, vol. 5, no. 4, pp. 674\u2013690, August 2011.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2011}, {"title": "Distributed Parameter Estimation in Sensor Networks: Nonlinear Observation Models and Imperfect Communication", "author": ["S. Kar", "J.M.F. Moura", "K. Ramanan"], "venue": "IEEE Transactions on Information Theory, vol. 58, no. 6, pp. 3575\u20133605, June 2012.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2012}, {"title": "Social Learning and Distributed Hypothesis Testing", "author": ["A. Lalitha", "T. Javidi", "A. Sarwate"], "venue": "ArXiv e-prints, Oct. 2014.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2014}, {"title": "Nonasymptotic Convergence Rates for Cooperative Learning over Time-Varying Directed Graphs", "author": ["A. Nedic", "A. Olshevsky", "C.A. Uribe"], "venue": "Proceedings of the American Control Conference (ACC), Chicago, IL, July 2015.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "Sequential Transmission Using Noiseless Feedback", "author": ["M. Horstein"], "venue": "IEEE Transactions on Information Theory, vol. 9, no. 3, pp. 136\u2013143, July 1963.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1963}, {"title": "Twenty Questions with noise: Bayes optimal policies for entropy loss", "author": ["B. Jedynak", "P.I. Frazier", "R. Sznitman"], "venue": "Journal of Applied Probability, vol. 49, pp. 114\u2013136, 2012.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Bisection Search with Noisy Responses", "author": ["R. Waeber", "P.I. Frazier", "S.G. Henderson"], "venue": "Journal of Control Optimization, vol. 53, no. 3, pp. 2261\u20132279, 2013.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2013}, {"title": "Collaborative 20 Questions for Target Localization", "author": ["T. Tsiligkaridis", "B.M. Sadler", "A.O. Hero III"], "venue": "IEEE Transactions on Information Theory, vol. 60, no. 4, pp. 2233\u20132352, April 2014.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}, {"title": "On Decentralized Estimation with Active Queries", "author": ["T. Tsiligkaridis", "B.M. Sadler", "A.O. Hero III"], "venue": "IEEE Transactions on Signal Processing, vol. 63, no. 10, pp. 2610\u20132622, May 2015.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2015}, {"title": "Asynchronous Decentralized Algorithms for the Noisy 20 Questions Problem", "author": ["T. Tsiligkaridis"], "venue": "Proceedings of the IEEE International Symposium on Information Theory (ISIT), Barcelona, Spain, July 2016.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2016}, {"title": "Introduction to Stochastic Processes", "author": ["P.G. Hoel", "S.C. Port", "C.J. Stone"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1972}, {"title": "The Capacity of Wireless Networks", "author": ["P. Gupta", "P.R. Kumar"], "venue": "IEEE Transactions on Information Theory, vol. 46, no. 2, pp. 388\u2013404, March 2000.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2000}], "referenceMentions": [{"referenceID": 0, "context": "Prior work on distributed signal processing includes the consensus literature [1, 2].", "startOffset": 78, "endOffset": 84}, {"referenceID": 1, "context": "Prior work on distributed signal processing includes the consensus literature [1, 2].", "startOffset": 78, "endOffset": 84}, {"referenceID": 2, "context": "Several such works on distributed estimation include that of [3, 4] in which they show distributed estimators are consistent and asymptotically normal.", "startOffset": 61, "endOffset": 67}, {"referenceID": 3, "context": "Several such works on distributed estimation include that of [3, 4] in which they show distributed estimators are consistent and asymptotically normal.", "startOffset": 61, "endOffset": 67}, {"referenceID": 4, "context": "In similar spirit, [5, 6] studied the problem of distributed detection and proved convergence rates on the rate of learning the correct hypothesis.", "startOffset": 19, "endOffset": 25}, {"referenceID": 5, "context": "In similar spirit, [5, 6] studied the problem of distributed detection and proved convergence rates on the rate of learning the correct hypothesis.", "startOffset": 19, "endOffset": 25}, {"referenceID": 6, "context": "The PBA was first introduced by Horstein [7].", "startOffset": 41, "endOffset": 44}, {"referenceID": 7, "context": "[8], and the convergence rate of the single-agent PBA was shown to be exponential in Waeber, et al, [9].", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[8], and the convergence rate of the single-agent PBA was shown to be exponential in Waeber, et al, [9].", "startOffset": 100, "endOffset": 103}, {"referenceID": 9, "context": "The PBA was generalized in [10] to multiple agents using a centralized controller strategy, and in [11, 12] using a decentralized algorithm based on belief consensus.", "startOffset": 27, "endOffset": 31}, {"referenceID": 10, "context": "The PBA was generalized in [10] to multiple agents using a centralized controller strategy, and in [11, 12] using a decentralized algorithm based on belief consensus.", "startOffset": 99, "endOffset": 107}, {"referenceID": 11, "context": "The PBA was generalized in [10] to multiple agents using a centralized controller strategy, and in [11, 12] using a decentralized algorithm based on belief consensus.", "startOffset": 99, "endOffset": 107}, {"referenceID": 9, "context": "In [10, 11, 12], the convergence analysis showed that all agents reach consensus to the true target.", "startOffset": 3, "endOffset": 15}, {"referenceID": 10, "context": "In [10, 11, 12], the convergence analysis showed that all agents reach consensus to the true target.", "startOffset": 3, "endOffset": 15}, {"referenceID": 11, "context": "In [10, 11, 12], the convergence analysis showed that all agents reach consensus to the true target.", "startOffset": 3, "endOffset": 15}, {"referenceID": 4, "context": "First, we first derive a social learning algorithm (inspired by the work of Lalitha, et al, [5]).", "startOffset": 92, "endOffset": 95}, {"referenceID": 10, "context": "Finally, we show using simulations, that our proposed algorithm outperforms the case of no collaboration and improves the distributed bisection search algorithm presented in Tsiligkaridis, et al, [11].", "startOffset": 196, "endOffset": 200}, {"referenceID": 0, "context": "e, X = [0, 1].", "startOffset": 7, "endOffset": 13}, {"referenceID": 7, "context": "The response to the query Zi,t = I(X \u2208 Si,t) is modeled as a binary symmetric channel [8, 10, 11] and is given by:", "startOffset": 86, "endOffset": 97}, {"referenceID": 9, "context": "The response to the query Zi,t = I(X \u2208 Si,t) is modeled as a binary symmetric channel [8, 10, 11] and is given by:", "startOffset": 86, "endOffset": 97}, {"referenceID": 10, "context": "The response to the query Zi,t = I(X \u2208 Si,t) is modeled as a binary symmetric channel [8, 10, 11] and is given by:", "startOffset": 86, "endOffset": 97}, {"referenceID": 0, "context": "\u01ebi We define pi,t(x) as the posterior distribution on the target space X = [0, 1] for agent i at time t.", "startOffset": 75, "endOffset": 81}, {"referenceID": 10, "context": "where v is the normalized left eigenvector of A which corresponds to the unit eigenvalue 2 and C(\u01ebi) is the capacity of 1We remark that the normalizing factor here \u222b 1 0 pi,t(x)li(x, yi,t+1)dx is equal to 1/2 [11].", "startOffset": 209, "endOffset": 213}, {"referenceID": 12, "context": "7 from [14]:", "startOffset": 7, "endOffset": 11}, {"referenceID": 4, "context": "The values of v represent a centrality measure and the magnitude of social influence of an agent i [5].", "startOffset": 99, "endOffset": 102}, {"referenceID": 10, "context": "To validate and strengthen the preceding performance analysis, simulations are performed to show that the proposed method achieves better performance than the belief consensus approach of [11] and the case of no inter-agent collaboration.", "startOffset": 188, "endOffset": 192}, {"referenceID": 13, "context": "We randomly generate an irreducible N \u00d7 N adjacency matrix, modeling a random geometric graph [15] (see Figure 1).", "startOffset": 94, "endOffset": 98}, {"referenceID": 10, "context": "We observe that our proposed method outperforms the belief consensus approach of [11] and the case of no collaboration.", "startOffset": 81, "endOffset": 85}, {"referenceID": 10, "context": "In terms of worst case MSE, our proposed method remains robust while that of [11] converges slower and the method with no collaboration, has not converged after 75 time steps.", "startOffset": 77, "endOffset": 81}, {"referenceID": 10, "context": "Average (top) and worst-case (bottom) MSE performance for our proposed social learning algorithm, the belief consensus approach of [11], and the case of no collaboration.", "startOffset": 131, "endOffset": 135}], "year": 2017, "abstractText": "We present a novel distributed probabilistic bisection algorithm using social learning with application to target localization. Each agent in the network first constructs a query about the target based on its local information and obtains a noisy response. Agents then perform a Bayesian update of their beliefs followed by a local averaging of the log beliefs. This two stage algorithm consisting of repeated querying and averaging runs until convergence. We derive bounds on the rate of convergence of the beliefs at the correct target location. Numerical simulations show that our method outperforms current state of the art methods.", "creator": "LaTeX with hyperref package"}}}