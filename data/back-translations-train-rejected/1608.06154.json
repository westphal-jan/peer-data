{"id": "1608.06154", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Aug-2016", "title": "Multi-Sensor Prognostics using an Unsupervised Health Index based on LSTM Encoder-Decoder", "abstract": "Many approaches for estimation of Remaining Useful Life (RUL) of a machine, using its operational sensor data, make assumptions about how a system degrades or a fault evolves, e.g., exponential degradation. However, in many domains degradation may not follow a pattern. We propose a Long Short Term Memory based Encoder-Decoder (LSTM-ED) scheme to obtain an unsupervised health index (HI) for a system using multi-sensor time-series data. LSTM-ED is trained to reconstruct the time-series corresponding to healthy state of a system. The reconstruction error is used to compute HI which is then used for RUL estimation. We evaluate our approach on publicly available Turbofan Engine and Milling Machine datasets. We also present results on a real-world industry dataset from a pulverizer mill where we find significant correlation between LSTM-ED based HI and maintenance costs.", "histories": [["v1", "Mon, 22 Aug 2016 12:59:31 GMT  (1237kb,D)", "http://arxiv.org/abs/1608.06154v1", "Presented at 1st ACM SIGKDD Workshop on Machine Learning for Prognostics and Health Management, San Francisco, CA, USA, 2016. 10 pages"]], "COMMENTS": "Presented at 1st ACM SIGKDD Workshop on Machine Learning for Prognostics and Health Management, San Francisco, CA, USA, 2016. 10 pages", "reviews": [], "SUBJECTS": "cs.LG cs.AI", "authors": ["pankaj malhotra", "vishnu tv", "anusha ramakrishnan", "gaurangi anand", "lovekesh vig", "puneet agarwal", "gautam shroff"], "accepted": false, "id": "1608.06154"}, "pdf": {"name": "1608.06154.pdf", "metadata": {"source": "CRF", "title": "Multi-Sensor Prognostics using an Unsupervised Health Index based on LSTM Encoder-Decoder", "authors": ["Pankaj Malhotra", "Anusha Ramakrishnan", "Gaurangi Anand", "Lovekesh Vig", "Puneet Agarwal", "Gautam Shroff"], "emails": ["anusha.ramakrishnan}@tcs.com", "gautam.shroff}@tcs.com"], "sections": [{"heading": "1. INTRODUCTION", "text": "This year, it is closer than ever before in the history of the country."}, {"heading": "2. APPROACH OVERVIEW", "text": "We consider the scenario in which historical instances of a system with multi-sensor data measurements are available until the end of life. The goal is to estimate the RUL of a currently operational instance of the system for which multi-sensor data is available until the end of life. Formally, we consider a series of train examples U of a system. For each instance, we consider a multivariate time series of sensor measurements X (u) = [x (u) 1 x (u) 2... x (u) L (u)] with L (u) cycles in which the last cycle corresponds to the end of life, we consider each point x (u) t) x (u) x (Rm) as a m-dimensional vector corresponding to the measurements for m-sensors in the time instance t. The sensor data are normalized so that the sensor value x (u) tj in the time t (u) tj \u2212 \u00b5j can be transformed in time."}, {"heading": "3. LINEAR REGRESSION BASED", "text": "HEALTH INDICATION ESTIMATIONLet H (u) = [h (u) 1 h (u) 2... h (u) L (u)] represent the HI curve H (u) for example u, where each point h (u) t, L (u) is the total number of cycles. We assume 0 \u2264 h (u) t \u2264 1, s.t. if u is in good health h (u) t = 1, and if u is below an acceptable level (e.g. close to failure) h (u) t = 0.Our goal is to construct a mapping: z (u) t (u) t s.t.f.A. (z (u) t = \u03b8 T (u) t + \u03b80 (1), where the HI h (u) t is calculated from the derived sensor values z (u) t at a given time."}, {"heading": "3.1 Domain-specific target HI curves", "text": "In contrast to the exponential HI curve, which uses the entire time series of the linear regression model (LR) (Equation 1), the parameters 2001 and 2001 are usually estimated by assuming a mathematical form for target H (u), with an exponential function being the most common and successfully used target HI curve (e.g. [10, 33, 40, 29, 6]) that assumes the HI at the time t, e.g. u ash (u) t = 1 \u2212 exp (log (\u03b2). (L (u) \u2212 t) (1 \u2212 \u03b2).L (u)), t (\u03b2.L (u), (1 \u2212 \u03b2).L (u)]]. (2) 0 < \u03b2 < < 1. 1. The initial and final fraction of the cycles are assigned values of 1 and 0, respectively the intersections of 1 \u2212 \u03b2 (1 \u2212 \u03b2).Another possible assumption is that the target values correspond to the HI and the interference conditions of 1 and 1."}, {"heading": "4. LSTM-ED BASED TARGET HI CURVE", "text": "We learn an LSTM-ED model to reconstruct the time series of the traction instances during normal operation. For example, any sub-sequence corresponding to the beginning of fewer cycles, if the system is assumed to be in a healthy state, can be used to learn the model. The reconstruction model is then used to reconstruct all sub-sequences for all traction instances, and the pointed reconstruction error is used to obtain an HI target curve for each example. We briefly describe the LSTM unit and the LSTM-ED-based reconstruction model, and then explain how the reconstruction errors derived from this model are used to obtain the HI target curves."}, {"heading": "4.1 LSTM unit", "text": "An LSTM unit is a recursive unit that uses the input, the hidden state activation at \u2212 1 and the memory cell activation ct \u2212 1 to calculate the hidden state activation at time t. It uses a combination of a memory cell c and three types of gates: input gate i, forget gate f and output gate o to determine whether the input must be stored (using input gate), when the previous memory content must be retained (forget gate) and when the memory content must be output (using output gate). Many variants and extensions of the original LSTM unit, as introduced in [14], exist. We use the one as described in [42]. Consider Tn1, n2: Rn1 \u2192 Rn2 is an affine transformation of the form z 7 \u2192 Wz + b for matrix and vector b of corresponding dimensions. The values for input gate, vergigate, output gate 7, and output gate \u2212 t are a \u2212 t for matrix matrix and vector b \u2212 t."}, {"heading": "4.2 Reconstruction Model", "text": "We consider sliding windows to obtain L \u2212 l \u2212 1 sub-sequences for a pull instance with L cycles. LSTM-ED is trained to reconstruct the normal (healthy) sub-sequences of length l from all training instances. LSTM encoder learns a fixed length vector representation of the input time series and the LSTM decoder uses this representation to reconstruct the time series based on the current hidden state and the value predicted in the previous time step. In the face of a time series Z = [z1 z2... zl] a (E) t is the hidden state of the encoder at the time t for each t value {1, 2, l}, where a (E) t sequence Rc, c is the number of LSTM units in the hidden layer of the encoder. The encoder and decoder are trained together to reconstruct the time series in reverse order."}, {"heading": "4.3 Reconstruction Error based Target HI", "text": "A dot zt in a time series Z is part of multiplexed, overlapping subsequences and is therefore predicted by multiple subsequences Z (j, l) containing j = t \u2212 l + 1, t \u2212 l + 2,..., t. Therefore, each dot in the original time series is predicted for a trajectory instance as often as the number of subsequences it is contained in (l times for each dot except for dot zt with t < l or t > L \u2212 l, which are predicted less often).An average of all predictions for a dot is assumed to be the final prediction for that dot. The difference between actual and predicted values for a dot is used for that dot as an unnormalised HI. Error e (u) t is normalized to obtain the target HI h (u) t as: h (u) t = e (u) M \u2212 e (u) m (7)."}, {"heading": "5. RUL ESTIMATION USING HI CURVE MATCHING", "text": "Similar to [39, 40], the HI curve for a test instance is compared by various factors such as the consistency of the HI curves for all traction instance. (HI curve for a test instance is compared with the HI curve for a traction instance. (HI curve for a test instance is compared with the HI curve for a traction instance by varying the time delay.) The time delay corresponding to the minimum Euclidean distance between the HI curves of the train and the test instance is shown. For a given time delay, the number of remaining cycles for the traction instance after the last cycle of the test instance is the RUL estimate for the test instance. Let us be a test instance and u a trace instance. Similar to [29, 9, 13] we consider the following scenarios for curve adjustment based on the RUL estimate."}, {"heading": "6. EXPERIMENTAL EVALUATION", "text": "We evaluate our approach using two publicly available datasets: C-MAPSS Turbofan Engine Dataset [33] and Milling Machine Dataset [1], and a real dataset from a pulverizing mill. For the first two datasets, the truth of the soil in the sense of the RUL is known, and we use RUL estimates to measure the effectiveness of our algorithm (see Section 6.1). The pulverizing mill is repaired in time (see Section 3), and therefore the truth of the soil in relation to the actual RUL is not available. We therefore draw a comparison between the health index and the maintenance costs of the mills. For the first two datasets, we use different HI target curves to learn the LR model (see Section 3): LR-Lin and LR-Exp models assume a linear and exponential form for the HI target curves. LR-ED1 and LR-2 will use different HI target curves to learn the LR model (see Section 3)."}, {"heading": "6.1 Performance metrics considered", "text": "Several metrics have been proposed to evaluate the performance of forecasting models [32]. We measure performance in terms of timeliness score (S), accuracy (A), Mean Absolute Error (MAE), Mean Squared Error (MSE) and Mean Absolute Percentage Error (MAPE1 and MAPE2), as in Eqs. 11-15. Score S used to measure the performance of a model is given by the following yardsticks: S = N."}, {"heading": "6.2 C-MAPSS Turbofan Engine Dataset", "text": "The data set contains measurements for 24 sensors (3 operating settings sensors, 21 dependent sensors) for 100 motors until an error threshold is reached, i.e., until the end of life in the train FD001.txt. Similar data is provided for 100 test motors in the test FD001.txt, where the time series for motors are throttled some time before failure. The task is to predict RUL for these 100 motors. Actual RUL values are provided in RUL FD001.txt. There are a total of 20,631 cycles for training motors, and 13096 cycles for initial wear. We use different wear degrees for these motors."}, {"heading": "6.3 Milling Machine Dataset", "text": "This data set presents the wear measurements of a laboratory experiment. The wear is measured for 16 cases with different number of runs of different duration. (The wear is measured after runs, but not necessarily after each run.) The data contains measurements for 10 variables (3 operating condition variables, 6 dependencies, 0 0.1 0.2 0.3 0.4 0.6 0.7 0.8 0.9 percent of the entire life cycle that has passed 0.00.51.01.52.0Re cons tr uctio n Er ro r (a) Recon. Material 1 \u2212 44 \u2212 34 Error (R) 24 \u2212 14 \u2212 4 16 36 Error (R) 0501001502000500505050No. of i nsta nces (b) PCA1 Material-1 \u2212 44 \u2212 34 Error (R)."}, {"heading": "6.4 Pulverizer Mill Dataset", "text": "This data set consists of measurements for 6 sensors (e.g. with vibrations, feeder speed, etc.) for more than three years of operation of a mill. The data correspond to sensor measurements that occur every half hour between four consecutive scheduled maintenance errors M0, M1, M2 and M3, s.t. the operating period between two maintenance works is approximately one year. Costs incurred for all scheduled maintenance and unexpected maintenance work are considered as a partial sequence. Apart from these scheduled maintenance errors, maintenance work is performed whenever the mill develops an unexpected fault that impairs its normal operation."}, {"heading": "7. RELATED WORK", "text": "The reason for this is that most people are able to help themselves when they do not feel able to solve their problems. (...) The reason for this is that people are able to solve their problems. (...) The reason for this is that people are able to solve their problems. (...) The reason for this is that people are able to solve their problems. (...) The reason for this is that people are able to solve their problems. (...) The reason for this is that people are able to solve their problems. (...) The world \"The world\" The world \"The world\" The world \"The world,\" in the world. \"(...) The world\" The world. \"(...) The world.\" (...) The world. \"The world.\" (...) The world. \"(...) The world.\" (...) The. \"The world.\" (... \"The.\" (...) The world. \"(...\" The. \""}, {"heading": "8. DISCUSSION", "text": "We have proposed an unattended approach to estimating the health index (HI) of a system based on time series data with multiple sensors, using time series data that correspond to the healthy behavior of the system to learn a reconstruction model based on the LSTM encoder decoder (LSTM-ED), and then showing how the unattended HI can be used to estimate the remaining lifetime of the system rather than relying on degradation models based on domain knowledge. Overall, the proposed approach shows promising results and in some cases performs better than models based on health degradation assumptions of data sets from the Turbofan Engine and Milling Machine. While models based on assumptions such as exponential health degradation cannot adjust to a particular behavior, the LSTM-ED-based HI uses the time history of sensor measurements to predict the HI at a particular point in a pulse stage data based on the correlation of an STED."}, {"heading": "9. REFERENCES", "text": "[1] A. Agogino and K. G\u00f6bel. Milling data set. BESTlab, UC Berkeley, 2007. [2] G. Anand, A. H. Kazmi, P. Malhotra, L. Vig, P. Agarwal, and G. Shroff. Deep temporal characteristics to predict repeat buyers. In NIPS 2015 Workshop: Machine Learning for eCommerce, 2015. [3] G. S. Babu, P. Zhao, and X.-L. Li. Deep convolutional neural network based regression approach for estimation of remaining useful life. In Database Systems for Applications. Springer, 2016. [4] S. Bengio, O. Vinyals, N. Goetz, and N. Shazeer. Scheduled sampling for sequence prediction with recurrent neural networks. In Advances in Neural Information Processing Systems, 2015. [5] F. Cadini, E. Zio, D. Avram."}, {"heading": "A. BENCHMARKS ON TURBOFAN ENGINE DATASET", "text": "It is not the first time that the EU Commission has taken such a step."}], "references": [{"title": "Milling data set", "author": ["A. Agogino", "K. Goebel"], "venue": "BEST lab, UC Berkeley,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2007}, {"title": "Deep temporal features to predict repeat buyers", "author": ["G. Anand", "A.H. Kazmi", "P. Malhotra", "L. Vig", "P. Agarwal", "G. Shroff"], "venue": "In NIPS 2015 Workshop: Machine Learning for eCommerce,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2015}, {"title": "Deep convolutional neural network based regression approach for estimation of remaining useful life", "author": ["G.S. Babu", "P. Zhao", "X.-L. Li"], "venue": "In Database Systems for Advanced Applications", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2016}, {"title": "Scheduled sampling for sequence prediction with recurrent neural networks", "author": ["S. Bengio", "O. Vinyals", "N. Jaitly", "N. Shazeer"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2015}, {"title": "Model-based monte carlo state estimation for condition-based component replacement", "author": ["F. Cadini", "E. Zio", "D. Avram"], "venue": "Reliability Engg. & System Safety,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2009}, {"title": "Comparison of sensors and methodologies for effective prognostics on railway turnout systems", "author": ["F. Camci", "O.F. Eker", "S. Ba\u015fkan", "S. Konur"], "venue": "Proceedings of the Institution of Mechanical Engineers, Part F: Journal of Rail and Rapid Transit,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2016}, {"title": "Anomaly detection in ecg time signals via deep long short-term memory networks", "author": ["S. Chauhan", "L. Vig"], "venue": "In Data Science and Advanced Analytics (DSAA),", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2015}, {"title": "Learning phrase representations using rnn encoder-decoder for statistical machine translation", "author": ["K. Cho", "B. Van Merri\u00ebnboer", "C. Gulcehre", "D. Bahdanau", "F. Bougares", "H. Schwenk", "Y. Bengio"], "venue": "arXiv preprint arXiv:1406.1078,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}, {"title": "Merging data sources to predict remaining useful life\u2013an automated method to identify prognostic parameters", "author": ["J.B. Coble"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2010}, {"title": "Nist/sematech e-handbook of statistical methods", "author": ["C. Croarkin", "P. Tobias"], "venue": "NIST/SEMATECH,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2006}, {"title": "Applying outbreak detection algorithms to prognostics", "author": ["A. Dubrawski", "M. Baysek", "M.S. Mikus", "C. McDaniel", "B. Mowry", "L. Moyer", "J. Ostlund", "N. Sondheimer", "T. Stewart"], "venue": "In AAAI Fall Symposium on Artificial Intelligence for Prognostics,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2007}, {"title": "A novel connectionist system for unconstrained handwriting recognition", "author": ["A. Graves", "M. Liwicki", "S. Fern\u00e1ndez", "R. Bertolami", "H. Bunke", "J. Schmidhuber"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2009}, {"title": "Recurrent neural networks for remaining useful life estimation", "author": ["F.O. Heimes"], "venue": "In International Conference on Prognostics and Health Management,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2008}, {"title": "Long short-term memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural computation,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1997}, {"title": "Particle filter-based prognostics: Review, discussion and perspectives", "author": ["M. Jouin", "R. Gouriveau", "D. Hissel", "M.-C. P\u00e9ra", "N. Zerhouni"], "venue": "Mechanical Systems and Signal Processing,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2015}, {"title": "Rul prediction based on a new similarity-instance based approach", "author": ["R. Khelif", "S. Malinowski", "B. Chebel-Morello", "N. Zerhouni"], "venue": "In IEEE International Symposium on Industrial Electronics,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2014}, {"title": "Enhanced trajectory based similarity prediction with uncertainty quantification", "author": ["J. Lam", "S. Sankararaman", "B. Stewart"], "venue": "PHM 2014,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2014}, {"title": "An adaptive recurrent neural network for remaining useful life prediction of lithium-ion batteries", "author": ["J. Liu", "A. Saxena", "K. Goebel", "B. Saha", "W. Wang"], "venue": "Technical report, DTIC Document,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2010}, {"title": "Optimize the signal quality of the composite health index via data fusion for degradation modeling and prognostic analysis", "author": ["K. Liu", "A. Chehade", "C. Song"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2015}, {"title": "A data-level fusion model for developing composite health indices for degradation modeling and prognostic analysis", "author": ["K. Liu", "N.Z. Gebraeel", "J. Shi"], "venue": "Automation Science and Engineering, IEEE Transactions on,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2013}, {"title": "Lstm-based encoder-decoder for multi-sensor anomaly detection", "author": ["P. Malhotra", "A. Ramakrishnan", "G. Anand", "L. Vig", "P. Agarwal", "G. Shroff"], "venue": "33rd International Conference on Machine Learning, Anomaly Detection Workshop. arXiv preprint arXiv:1607.00148,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2016}, {"title": "Long short term memory networks for anomaly detection in time series", "author": ["P. Malhotra", "L. Vig", "G. Shroff", "P. Agarwal"], "venue": "In ESANN, 23rd European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2015}, {"title": "A novel approach for automatic acoustic novelty detection using a denoising autoencoder with bidirectional lstm neural networks", "author": ["E. Marchi", "F. Vesperini", "F. Eyben", "S. Squartini", "B. Schuller"], "venue": "In Acoustics, Speech and Signal Processing (ICASSP). IEEE,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2015}, {"title": "Data-driven prognostic method based on bayesian approaches for direct remaining useful life prediction", "author": ["A. Mosallam", "K. Medjaher", "N. Zerhouni"], "venue": "Journal of Intelligent Manufacturing,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2014}, {"title": "Component based data-driven prognostics for complex systems: Methodology and applications", "author": ["A. Mosallam", "K. Medjaher", "N. Zerhouni"], "venue": "In Reliability Systems Engineering (ICRSE),", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2015}, {"title": "Application of stochastic filtering for lifetime prediction", "author": ["E. My\u00f6tyri", "U. Pulkkinen", "K. Simola"], "venue": "Reliability Engineering & System Safety,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2006}, {"title": "A modified echo state network based remaining useful life estimation approach", "author": ["Y. Peng", "H. Wang", "J. Wang", "D. Liu", "X. Peng"], "venue": "In IEEE Conference on Prognostics and Health Management (PHM),", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2012}, {"title": "Robust performance degradation assessment methods for enhanced rolling element bearing prognostics", "author": ["H. Qiu", "J. Lee", "J. Lin", "G. Yu"], "venue": "Advanced Engineering Informatics,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2003}, {"title": "Investigating computational geometry for failure prognostics in presence of imprecise health indicator: Results and comparisons on c-mapss datasets", "author": ["E. Ramasso"], "venue": "Europen Confernce of the Prognostics and Health Management Society.,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2014}, {"title": "Joint prediction of continuous and discrete states in time-series based on belief functions", "author": ["E. Ramasso", "M. Rombaut", "N. Zerhouni"], "venue": "Cybernetics, IEEE Transactions on,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2013}, {"title": "Performance benchmarking and analysis of prognostic methods for cmapss datasets", "author": ["E. Ramasso", "A. Saxena"], "venue": "Int. J. Progn. Health Manag,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2014}, {"title": "Metrics for evaluating performance of prognostic techniques", "author": ["A. Saxena", "J. Celaya", "E. Balaban", "K. Goebel", "B. Saha", "S. Saha", "M. Schwabacher"], "venue": "In Prognostics and health management,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2008}, {"title": "Damage propagation modeling for aircraft engine run-to-failure simulation", "author": ["A. Saxena", "K. Goebel", "D. Simon", "N. Eklund"], "venue": "In Prognostics and Health Management,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2008}, {"title": "Sequence to sequence learning with neural networks", "author": ["I. Sutskever", "O. Vinyals", "Q.V. Le"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2014}, {"title": "Cnc machine tool\u2019s wear diagnostic and prognostic by using dynamic bayesian networks", "author": ["D. Tobon-Mejia", "K. Medjaher", "N. Zerhouni"], "venue": "Mechanical Systems and Signal Processing,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2012}, {"title": "Prognostics and health management: A review on data driven approaches", "author": ["K.L. Tsui", "N. Chen", "Q. Zhou", "Y. Hai", "W. Wang"], "venue": "Mathematical Problems in Engineering,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2015}, {"title": "Fault prognostics using dynamic wavelet neural networks", "author": ["P. Wang", "G. Vachtsevanos"], "venue": "AI EDAM,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2001}, {"title": "A generic probabilistic framework for structural health prognostics and uncertainty management", "author": ["P. Wang", "B.D. Youn", "C. Hu"], "venue": "Mechanical Systems and Signal Processing,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2012}, {"title": "Trajectory similarity based prediction for remaining useful life estimation", "author": ["T. Wang"], "venue": "PhD thesis, University of Cincinnati,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2010}, {"title": "A similarity-based prognostics approach for remaining useful life estimation of engineered systems", "author": ["T. Wang", "J. Yu", "D. Siegel", "J. Lee"], "venue": "In Prognostics and Health Management, International Conference on. IEEE,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2008}, {"title": "Ode-augmented training improves anomaly detection in sensor data from machines", "author": ["M. Yadav", "P. Malhotra", "L. Vig", "K. Sriram", "G. Shroff"], "venue": "In NIPS Time Series Workshop. arXiv preprint arXiv:1605.01534,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2015}, {"title": "Recurrent neural network regularization", "author": ["W. Zaremba", "I. Sutskever", "O. Vinyals"], "venue": "arXiv preprint arXiv:1409.2329,", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2014}], "referenceMentions": [{"referenceID": 28, "context": "Extrapolation of HI is used for prediction of RUL [29, 24, 25].", "startOffset": 50, "endOffset": 62}, {"referenceID": 23, "context": "Extrapolation of HI is used for prediction of RUL [29, 24, 25].", "startOffset": 50, "endOffset": 62}, {"referenceID": 24, "context": "Extrapolation of HI is used for prediction of RUL [29, 24, 25].", "startOffset": 50, "endOffset": 62}, {"referenceID": 4, "context": "Apart from the health index (HI) based approach as described above, mathematical models of the underlying physical system, fault propagation models and conventional reliability models have also been used for RUL estimation [5, 26].", "startOffset": 223, "endOffset": 230}, {"referenceID": 25, "context": "Apart from the health index (HI) based approach as described above, mathematical models of the underlying physical system, fault propagation models and conventional reliability models have also been used for RUL estimation [5, 26].", "startOffset": 223, "endOffset": 230}, {"referenceID": 27, "context": "Data-driven models which use readings of sensors carrying degradation or wear information such as vibration in a bearing have been effectively used to build RUL estimation models [28, 29, 37].", "startOffset": 179, "endOffset": 191}, {"referenceID": 28, "context": "Data-driven models which use readings of sensors carrying degradation or wear information such as vibration in a bearing have been effectively used to build RUL estimation models [28, 29, 37].", "startOffset": 179, "endOffset": 191}, {"referenceID": 36, "context": "Data-driven models which use readings of sensors carrying degradation or wear information such as vibration in a bearing have been effectively used to build RUL estimation models [28, 29, 37].", "startOffset": 179, "endOffset": 191}, {"referenceID": 39, "context": "Any new instance is then compared with these trends and the most similar trends are used to estimate the RUL [40].", "startOffset": 109, "endOffset": 113}, {"referenceID": 11, "context": "LSTM networks are recurrent neural network models that have been successfully used for many sequence learning and temporal modeling tasks [12, 2] such as handwriting recognition, speech recognition, sentiment analysis, and customer behavior prediction.", "startOffset": 138, "endOffset": 145}, {"referenceID": 1, "context": "LSTM networks are recurrent neural network models that have been successfully used for many sequence learning and temporal modeling tasks [12, 2] such as handwriting recognition, speech recognition, sentiment analysis, and customer behavior prediction.", "startOffset": 138, "endOffset": 145}, {"referenceID": 7, "context": "A variant of LSTM networks, LSTM encoder-decoder (LSTM-ED) model has been successfully used for sequence-to-sequence learning tasks [8, 34, 4] like machine translation, natural language generation and reconstruction, parsing, and image captioning.", "startOffset": 132, "endOffset": 142}, {"referenceID": 33, "context": "A variant of LSTM networks, LSTM encoder-decoder (LSTM-ED) model has been successfully used for sequence-to-sequence learning tasks [8, 34, 4] like machine translation, natural language generation and reconstruction, parsing, and image captioning.", "startOffset": 132, "endOffset": 142}, {"referenceID": 3, "context": "A variant of LSTM networks, LSTM encoder-decoder (LSTM-ED) model has been successfully used for sequence-to-sequence learning tasks [8, 34, 4] like machine translation, natural language generation and reconstruction, parsing, and image captioning.", "startOffset": 132, "endOffset": 142}, {"referenceID": 20, "context": "LSTM Encoder-decoder based approaches have been proposed for anomaly detection [21, 23].", "startOffset": 79, "endOffset": 87}, {"referenceID": 22, "context": "LSTM Encoder-decoder based approaches have been proposed for anomaly detection [21, 23].", "startOffset": 79, "endOffset": 87}, {"referenceID": 13, "context": "Based on similar ideas, we use Long Short-Term Memory [14] Encoder-Decoder (LSTM-ED) for RUL estimation.", "startOffset": 54, "endOffset": 58}, {"referenceID": 38, "context": "(Note: When multiple modes of normal operation exist, each point can normalized based on the \u03bcj and \u03c3j for that mode of operation, as suggested in [39].", "startOffset": 147, "endOffset": 151}, {"referenceID": 38, "context": "As in [39, 24, 25], we use Principal Components Analysis to obtain derived sensors from the normalized sensor data with reduced linear correlations between them.", "startOffset": 6, "endOffset": 18}, {"referenceID": 23, "context": "As in [39, 24, 25], we use Principal Components Analysis to obtain derived sensors from the normalized sensor data with reduced linear correlations between them.", "startOffset": 6, "endOffset": 18}, {"referenceID": 24, "context": "As in [39, 24, 25], we use Principal Components Analysis to obtain derived sensors from the normalized sensor data with reduced linear correlations between them.", "startOffset": 6, "endOffset": 18}, {"referenceID": 38, "context": "The approach can be easily extended to multiple operating regimes scenario by treating data for each regime separately (similar to [39, 17]), as described in one of our case studies on milling machine dataset in Section 6.", "startOffset": 131, "endOffset": 139}, {"referenceID": 16, "context": "The approach can be easily extended to multiple operating regimes scenario by treating data for each regime separately (similar to [39, 17]), as described in one of our case studies on milling machine dataset in Section 6.", "startOffset": 131, "endOffset": 139}, {"referenceID": 9, "context": "[10, 33, 40, 29, 6]), which assumes the HI at time t for instance u as", "startOffset": 0, "endOffset": 19}, {"referenceID": 32, "context": "[10, 33, 40, 29, 6]), which assumes the HI at time t for instance u as", "startOffset": 0, "endOffset": 19}, {"referenceID": 39, "context": "[10, 33, 40, 29, 6]), which assumes the HI at time t for instance u as", "startOffset": 0, "endOffset": 19}, {"referenceID": 28, "context": "[10, 33, 40, 29, 6]), which assumes the HI at time t for instance u as", "startOffset": 0, "endOffset": 19}, {"referenceID": 5, "context": "[10, 33, 40, 29, 6]), which assumes the HI at time t for instance u as", "startOffset": 0, "endOffset": 19}, {"referenceID": 37, "context": "[38]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "Many variants and extensions to the original LSTM unit as introduced in [14] exist.", "startOffset": 72, "endOffset": 76}, {"referenceID": 41, "context": "We use the one as described in [42].", "startOffset": 31, "endOffset": 35}, {"referenceID": 33, "context": "The encoder and decoder are jointly trained to reconstruct the time-series in reverse order (similar to [34]), i.", "startOffset": 104, "endOffset": 108}, {"referenceID": 38, "context": "RUL ESTIMATION USING HI CURVE MATCHING Similar to [39, 40], the HI curve for a test instance u\u2217 is compared to the HI curves of all the train instances u \u2208 U .", "startOffset": 50, "endOffset": 58}, {"referenceID": 39, "context": "RUL ESTIMATION USING HI CURVE MATCHING Similar to [39, 40], the HI curve for a test instance u\u2217 is compared to the HI curves of all the train instances u \u2208 U .", "startOffset": 50, "endOffset": 58}, {"referenceID": 28, "context": "Similar to [29, 9, 13], we take into account the following scenarios for curve matching based RUL estimation: 1) Varying initial health across instances: The initial health of an instance varies depending on various factors such as the inherent inconsistencies in the manufacturing process.", "startOffset": 11, "endOffset": 22}, {"referenceID": 8, "context": "Similar to [29, 9, 13], we take into account the following scenarios for curve matching based RUL estimation: 1) Varying initial health across instances: The initial health of an instance varies depending on various factors such as the inherent inconsistencies in the manufacturing process.", "startOffset": 11, "endOffset": 22}, {"referenceID": 12, "context": "Similar to [29, 9, 13], we take into account the following scenarios for curve matching based RUL estimation: 1) Varying initial health across instances: The initial health of an instance varies depending on various factors such as the inherent inconsistencies in the manufacturing process.", "startOffset": 11, "endOffset": 22}, {"referenceID": 32, "context": "We evaluate our approach on two publicly available datasets: C-MAPSS Turbofan Engine Dataset [33] and Milling Machine Dataset [1], and a real world dataset from a pulverizer mill.", "startOffset": 93, "endOffset": 97}, {"referenceID": 0, "context": "We evaluate our approach on two publicly available datasets: C-MAPSS Turbofan Engine Dataset [33] and Milling Machine Dataset [1], and a real world dataset from a pulverizer mill.", "startOffset": 126, "endOffset": 129}, {"referenceID": 39, "context": "2 with \u03b2 = 5% as suggested in [40, 39, 29].", "startOffset": 30, "endOffset": 42}, {"referenceID": 38, "context": "2 with \u03b2 = 5% as suggested in [40, 39, 29].", "startOffset": 30, "endOffset": 42}, {"referenceID": 28, "context": "2 with \u03b2 = 5% as suggested in [40, 39, 29].", "startOffset": 30, "endOffset": 42}, {"referenceID": 31, "context": "Several metrics have been proposed for evaluating the performance of prognostics models [32].", "startOffset": 88, "endOffset": 92}, {"referenceID": 32, "context": "We consider the first dataset from the simulated turbofan engine data [33] (NASA Ames Prognostics Data Repository).", "startOffset": 70, "endOffset": 74}, {"referenceID": 32, "context": "We use \u03c41 = 13, \u03c42 = 10 as proposed in [33].", "startOffset": 39, "endOffset": 43}, {"referenceID": 28, "context": "We also provide comparison with RULCLIPPER (RC) [29] which (to the best of our knowledge) has the best performance in terms of timeliness S, accuracy A, MAE, and MSE [31] reported in the literature on the turbofan dataset considered and four other turbofan engine datasets (Note: Unlike RC, we learn the parameters of the model on a validation set rather than test set.", "startOffset": 48, "endOffset": 52}, {"referenceID": 30, "context": "We also provide comparison with RULCLIPPER (RC) [29] which (to the best of our knowledge) has the best performance in terms of timeliness S, accuracy A, MAE, and MSE [31] reported in the literature on the turbofan dataset considered and four other turbofan engine datasets (Note: Unlike RC, we learn the parameters of the model on a validation set rather than test set.", "startOffset": 166, "endOffset": 170}, {"referenceID": 28, "context": "10, see [29] for details).", "startOffset": 8, "endOffset": 12}, {"referenceID": 30, "context": "It is to be noted that the comparison is not exhaustive as a survey of approaches for the turbofan engine dataset since [31] is not available.", "startOffset": 120, "endOffset": 124}, {"referenceID": 8, "context": "We consider mean and standard deviation of each run (9000 values) for the 6 sensors to obtain 2 derived sensors per sensor (similar to [9]).", "startOffset": 135, "endOffset": 138}, {"referenceID": 5, "context": "As can be noted, most of the RUL prediction errors (around 70%) lie in the ranges [-4, 6] and [-3, 1] for material types 1 and 2, respectively.", "startOffset": 82, "endOffset": 89}, {"referenceID": 0, "context": "As can be noted, most of the RUL prediction errors (around 70%) lie in the ranges [-4, 6] and [-3, 1] for material types 1 and 2, respectively.", "startOffset": 94, "endOffset": 101}, {"referenceID": 10, "context": "[11, 35]).", "startOffset": 0, "endOffset": 8}, {"referenceID": 34, "context": "[11, 35]).", "startOffset": 0, "endOffset": 8}, {"referenceID": 24, "context": "[25] presents an unsupervised approach which does not assume a form for the HI curve and uses discrete Bayesian Filter to recursively estimate the health index values, and then use the k-NN classifier to find the most similar offline models.", "startOffset": 0, "endOffset": 4}, {"referenceID": 30, "context": "Recent review of statistical methods is available in [31, 36, 15].", "startOffset": 53, "endOffset": 65}, {"referenceID": 35, "context": "Recent review of statistical methods is available in [31, 36, 15].", "startOffset": 53, "endOffset": 65}, {"referenceID": 14, "context": "Recent review of statistical methods is available in [31, 36, 15].", "startOffset": 53, "endOffset": 65}, {"referenceID": 39, "context": "We use HI Trajectory Similarity Based Prediction (TSBP) for RUL estimation similar to [40] with the key difference being that the model proposed in [40] relies on exponential assumption to learn a regression model for HI estimation, whereas our approach uses LSTM-ED based HI to learn the regression model.", "startOffset": 86, "endOffset": 90}, {"referenceID": 39, "context": "We use HI Trajectory Similarity Based Prediction (TSBP) for RUL estimation similar to [40] with the key difference being that the model proposed in [40] relies on exponential assumption to learn a regression model for HI estimation, whereas our approach uses LSTM-ED based HI to learn the regression model.", "startOffset": 148, "endOffset": 152}, {"referenceID": 28, "context": "Similarly, [29] proposes RULCLIPPER (RC) which to the best of our knowledge has shown the best performance on C-MAPSS when compared to various approaches evaluated using the dataset [31].", "startOffset": 11, "endOffset": 15}, {"referenceID": 30, "context": "Similarly, [29] proposes RULCLIPPER (RC) which to the best of our knowledge has shown the best performance on C-MAPSS when compared to various approaches evaluated using the dataset [31].", "startOffset": 182, "endOffset": 186}, {"referenceID": 38, "context": "Another variant of TSBP [39] directly uses multiple PCA sensors for multi-dimensional curve matching which is used for RUL estimation, whereas we obtain a univariate HI by taking a weighted combination of the PCA sensors learnt", "startOffset": 24, "endOffset": 28}, {"referenceID": 19, "context": "Similarly, [20, 19] learn a composite health index based on the exponential assumption.", "startOffset": 11, "endOffset": 19}, {"referenceID": 18, "context": "Similarly, [20, 19] learn a composite health index based on the exponential assumption.", "startOffset": 11, "endOffset": 19}, {"referenceID": 2, "context": "[3, 27, 13, 18]): very recently, deep Convolutional Neural Networks have been proposed in [3] and shown to outperform regression methods based on Multi-Layer Perceptrons, Support Vector Regression and Relevance Vector Regression to directly estimate the RUL (see Table 4 for performance comparison with our approach on the Turbofan Engine dataset).", "startOffset": 0, "endOffset": 15}, {"referenceID": 26, "context": "[3, 27, 13, 18]): very recently, deep Convolutional Neural Networks have been proposed in [3] and shown to outperform regression methods based on Multi-Layer Perceptrons, Support Vector Regression and Relevance Vector Regression to directly estimate the RUL (see Table 4 for performance comparison with our approach on the Turbofan Engine dataset).", "startOffset": 0, "endOffset": 15}, {"referenceID": 12, "context": "[3, 27, 13, 18]): very recently, deep Convolutional Neural Networks have been proposed in [3] and shown to outperform regression methods based on Multi-Layer Perceptrons, Support Vector Regression and Relevance Vector Regression to directly estimate the RUL (see Table 4 for performance comparison with our approach on the Turbofan Engine dataset).", "startOffset": 0, "endOffset": 15}, {"referenceID": 17, "context": "[3, 27, 13, 18]): very recently, deep Convolutional Neural Networks have been proposed in [3] and shown to outperform regression methods based on Multi-Layer Perceptrons, Support Vector Regression and Relevance Vector Regression to directly estimate the RUL (see Table 4 for performance comparison with our approach on the Turbofan Engine dataset).", "startOffset": 0, "endOffset": 15}, {"referenceID": 2, "context": "[3, 27, 13, 18]): very recently, deep Convolutional Neural Networks have been proposed in [3] and shown to outperform regression methods based on Multi-Layer Perceptrons, Support Vector Regression and Relevance Vector Regression to directly estimate the RUL (see Table 4 for performance comparison with our approach on the Turbofan Engine dataset).", "startOffset": 90, "endOffset": 93}, {"referenceID": 12, "context": "Similarly, Recurrent Neural Network has been used to directly estimate the RUL [13] from the time-series of sensor readings.", "startOffset": 79, "endOffset": 83}, {"referenceID": 26, "context": "To the best of our knowledge, our LSTM Encoder-Decoder based approach performs significantly better than Echo State Network [27] and deep CNN based approaches [3] (refer Table 4).", "startOffset": 124, "endOffset": 128}, {"referenceID": 2, "context": "To the best of our knowledge, our LSTM Encoder-Decoder based approach performs significantly better than Echo State Network [27] and deep CNN based approaches [3] (refer Table 4).", "startOffset": 159, "endOffset": 162}, {"referenceID": 22, "context": "Reconstruction models based on denoising autoencoders [23] have been proposed for novelty/anomaly detection but have not been evaluated for RUL estimation task.", "startOffset": 54, "endOffset": 58}, {"referenceID": 21, "context": "LSTM networks have been used for anomaly/fault detection [22, 7, 41], where deep LSTM networks are used to learn prediction models for the normal time-series.", "startOffset": 57, "endOffset": 68}, {"referenceID": 6, "context": "LSTM networks have been used for anomaly/fault detection [22, 7, 41], where deep LSTM networks are used to learn prediction models for the normal time-series.", "startOffset": 57, "endOffset": 68}, {"referenceID": 40, "context": "LSTM networks have been used for anomaly/fault detection [22, 7, 41], where deep LSTM networks are used to learn prediction models for the normal time-series.", "startOffset": 57, "endOffset": 68}], "year": 2016, "abstractText": "Many approaches for estimation of Remaining Useful Life (RUL) of a machine, using its operational sensor data, make assumptions about how a system degrades or a fault evolves, e.g., exponential degradation. However, in many domains degradation may not follow a pattern. We propose a Long Short Term Memory based Encoder-Decoder (LSTM-ED) scheme to obtain an unsupervised health index (HI) for a system using multi-sensor time-series data. LSTM-ED is trained to reconstruct the time-series corresponding to healthy state of a system. The reconstruction error is used to compute HI which is then used for RUL estimation. We evaluate our approach on publicly available Turbofan Engine and Milling Machine datasets. We also present results on a real-world industry dataset from a pulverizer mill where we find significant correlation between LSTM-ED based HI and maintenance costs.", "creator": "LaTeX with hyperref package"}}}