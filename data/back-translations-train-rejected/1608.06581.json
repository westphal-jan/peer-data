{"id": "1608.06581", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Aug-2016", "title": "Fathom: Reference Workloads for Modern Deep Learning Methods", "abstract": "Deep learning has been popularized by its recent successes on challenging artificial intelligence problems. One of the reasons for its dominance is also an ongoing challenge: the need for immense amounts of computational power. Hardware architects have responded by proposing a wide array of promising ideas, but to date, the majority of the work has focused on specific algorithms in somewhat narrow application domains. While their specificity does not diminish these approaches, there is a clear need for more flexible solutions. We believe the first step is to examine the characteristics of cutting edge models from across the deep learning community.", "histories": [["v1", "Tue, 23 Aug 2016 17:11:07 GMT  (688kb,D)", "http://arxiv.org/abs/1608.06581v1", "Proceedings of the IEEE International Symposium on Workload Characterization, 2016"]], "COMMENTS": "Proceedings of the IEEE International Symposium on Workload Characterization, 2016", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["robert adolf", "saketh rama", "brandon reagen", "gu-yeon wei", "david brooks"], "accepted": false, "id": "1608.06581"}, "pdf": {"name": "1608.06581.pdf", "metadata": {"source": "CRF", "title": "Fathom: Reference Workloads for Modern Deep Learning Methods", "authors": ["Robert Adolf", "Saketh Rama", "Brandon Reagen", "David Brooks"], "emails": [], "sections": [{"heading": null, "text": "In fact, most of them are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move and to move."}, {"heading": "II. MOTIVATION: THE TIP OF THE ICEBERG", "text": "In fact, it is the case that most people who are able to move to another world go to another world in which they cannot find themselves. In fact, it is the case that they are able to change the world, and that they are able to change the world. In fact, it is the case that they are able to change and change the world, that they are able to immerse themselves in a new world."}, {"heading": "III. DESIGN AND IMPLEMENTATION CRITERIA", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Choose meaningful models", "text": "The first question is how to select the right models that reflect the state of the art. We believe that this workload should have three characteristics: representativeness, diversity, and impact. The first is clear: our decisions should reflect the best of what the deep learning community has devised. Since there are easily dozens of models that could legitimately claim this status, the need to limit the size of the set to a manageable number implies the need for diversity: each model should bring something unique to the table. Finally, the effect is the extent to which a particular technique has changed the landscape of deep learning research. Since we cannot predict the state of the field in five years, we will instead try to choose methods that have taught basic lessons for the work thereafter - lessons that will remain relevant to future models.An important note is that we are not trying to pre- or post-processing steps either based on the input data or the results of the model - lessons that will remain relevant to future models."}, {"heading": "B. Faithfully reproduce the original work", "text": "The vast majority of research work makes concerted efforts to describe its topology and hyperparameters in the name of reproducibility, and many groups have chosen to place reference implementations online. This is because reproducing deep learning experiments can be difficult; small changes in the choice of tuning parameters or data preparation can result in large differences in results. Therefore, when creating implementations for our selected models, we adopt an existing implementation, if one is available, translate one from another source language, if not, or create and validate an implementation based on descriptions from the original paper. All eight Fathom workloads have been rewritten to adhere to a standard model interface, expose information to our profiling tools, and remove preprocessing or extransient logging operations. Similar reproducibility concerns also apply to data sources. Whenever possible, we use test data where it is not the same as other school data and where possible."}, {"heading": "C. Leverage a modern deep learning framework", "text": "These frameworks offer two major advantages: First, they abstract the underlying hardware interface away from the programmer. High-performance code is difficult and time-consuming to write, whether it is vectorized or not. Second, they provide libraries with useful cores, supported by a multitude of people, that act as productivity multipliers, especially in a fast-moving environment. These frameworks have changed the development landscape, largely for the better, and it is not possible to create a realistic set of deep learning processes without holding them accountable."}, {"heading": "IV. THE FATHOM WORKLOADS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Sequence-to-Sequence Translation", "text": "seq2seq is a recurring neural network for machine translation solutions [43]. Developed at Google in 2014, the technique uses a multi-layered pipeline of long-term short-term memory neurons (LSTM) to extract the meaning of a sentence and then transmit it into another language. [4] The neural core network consists of three seven-neuron layers through which word marks flow unidirectionally, and also uses an attention-based model for context tracking in the original sentence [4]. Sequence sequence translation has achieved the highest precision, but its effect is largely based on its elegance and flexibility. It is a canonical example of a recurring \"encoder decoder\" model, a technique that transforms an input into a vector in high-dimensional space known as embedding."}, {"heading": "End-to-End Memory Networks", "text": "Storage networks [46] are one of two recent attempts to decouple state and structure in a neural network. The development of storage networks stemmed from the difficulty that state neurons have in detecting long-term dependencies. Facebook's AI research group solved this problem by connecting an indirectly addressable memory to a neural network, resulting in a model that can explicitly store and retrieve information. End-to-end storage networks [42] are an extension that eliminates the need for input notes and dramatically streamlines training."}, {"heading": "Deep Speech", "text": "Deep Speech was Baidu Research's attempt to develop a scalable speech recognition model [25], consisting of five fully interconnected layers of 2,048 neurons, each with a bidirectional recurring layer. Deep Speech is a pure deep-learning algorithm, since it uses spectrograms directly as input and learns to transcribe phonemes (as opposed to a hand-tuned acoustic model or HMM as a pre-processing stage); its connectionist time classification (CTC) loss function can learn from unsegmented data, significantly reducing the cost of generating training data [23]. Deep Speech also stood out for its emphasis on efficiency: the researchers explicitly designed the model to work well on a GPU. We implemented the Deep Speech architecture with smaller windows and embedding sizes to account for differences in the TIMIT dataset [22]."}, {"heading": "Variational Autoencoder", "text": "Autoencoders are a flexible, unattended model that is often used to reduce dimensionality, to extract features, or to generate data. [28] The basic assumption is that there is a compact representation of all realistic inputs (so-called embedding) that can be used both to analyze and synthesize data. Variational autoencoders, invented in 2013 by Kingma and Welling, make statistical assumptions about the properties of this embedding in order to learn to efficiently reconstruct their inputs [32]. These models are somewhat unique in that they require stochastic scanning as part of inference and not just training."}, {"heading": "Residual Networks", "text": "Remaining networks were a milestone in enabling very deep neural networks [27]. In 2015, researchers from Microsoft Research Asia were confronted with the phenomenon that increasing the depth of a model degrades both training and validation errors; their solution was to add additional identity links over each pair of revolutionary layers and effectively train these layers for the difference between input and output; this tactic enabled them to train models with over 150 layers of depth, almost seven times greater than the previous state of the art, and they won all five ILSVRC 2015 competitions."}, {"heading": "VGG-19", "text": "vgg is an implementation of the 19-layer revolutionary network developed by the visual geometry group at Oxford [41]. AlexNet's success inspired deeper revolutionary networks, and VGG was one such derivative. Simonyan and Zisserman's key finding was that more layers of smaller revolutionary filters were easier to train, a technique that dramatically improved both accuracy (it won the ILSVRC localization task and came second in the classification task against a much more complex Google entry) and the number of parameters to learn."}, {"heading": "AlexNet", "text": "AlexNet [33] was a turning point for the deep learning community. Although it is now overshadowed by more advanced models, the original model made several significant contributions. Above all, it showed that an automatically trained neural network could significantly outperform hand-tuned image classifiers. It also introduced dropouts as a regulatory mechanism and showcased the computing power of GPUs. While much of the architecture community already works with AlexNet, its inclusion contributes both to continuity (allowing a degree of comparability with previous work) and to a reference point for the other models in Fathom."}, {"heading": "Deep Reinforcement Learning", "text": "Unlike supervised algorithms, the Deep Q Learning algorithm improves its chosen actions by receiving in-game feedback, not by observing perfect play. At the heart of the method is a Convolutionary Network that selects actions with 2-3 Convolutionary Layers and 2-3 Dense Layers. The model bypassed historical difficulties in extending neural networks to decoupled feedback with innovative strategies such as experience repetition. We use the same Atari emulation environment that drove the original implementation, the Arcade Learning Environment [5]."}, {"heading": "V. UNDERSTANDING THE PERFORMANCE CHARACTERISTICS OF DEEP LEARNING WORKLOADS", "text": "These models are designed as tools for architects, and appropriate tools require skill and understanding to apply them effectively. This section is intended to build the foundation of this understanding in two ways: First, we want to give architects an intuition about the behavior of workloads in the field of deep learning. For example, it is important to understand where time is actually spent and what relationships exist between a particular model and the hardware on which it runs. Second, we want to provide a quantitative basis on which the community can build. There is a lot of folklore around deep learning, and numbers are a good way to start clearing away some of it."}, {"heading": "A. Measurement and analysis in a deep learning framework", "text": "This year it is more than ever before."}, {"heading": "B. Operation type profiling", "text": "The most fundamental question is where the time is spent. Many architects already have a feeling for it, but their views are often contradictory."}, {"heading": "C. Performance similarity", "text": "The mechanism is simple: each profile (a single line in Figure 3) is interpreted as a vector in high-dimensional space. Paired similarity can be calculated with cosmic similarity, and we use the inverse form (1 \u2212 A \u00b7 B | | B |) as a distance metric. We can then use agglomerative clusters with centric linkages to understand their relationships - that is, we greedily group the next two vectors, calculate their centric shape, and repeat them until we have a single, global cluster. Figure 4 presents a visual representation of the hierarchical clustering generated by this process. The X-axis position of a linkage between two workloads (or two clusters of workloads) is used as a direct measure of the cosmic distance between them."}, {"heading": "D. Training and inference", "text": "The vast majority of deep learning systems use a variant of gradient parentage and reverse propagation, which can be seen in different phases: in the run-up phase, the model functions are used to calculate an output value from a given input; in the return phase, the system is evaluated according to a number of criteria (a loss function); in the run-up phase, the system is calculated the partial derivation of the loss function in relation to this parameter; these flow parameters are used to minimize the value of the loss function."}, {"heading": "E. Parallelism and operation balance", "text": "This year it has come to the point that it has never come as far as this year."}, {"heading": "VI. RELATED WORK", "text": "The three most relevant are, first and foremost, the methods mentioned, but also the methods used to study the behaviour of a participant. Newfangled nets are used to some extent in benchmarks, and their attraction extends to the use of machines in infinite quantities."}, {"heading": "VII. CONCLUSION", "text": "Fathom aims to establish a standard for researchers to quantify better hardware and systems for deep learning. Fathom alleviates the burden of workload selection by assembling eight modern deep learning models into a single, unified package with a unified interface. We also provide insights, including how similar the eight different models are, where the cycles are spent, and how optimizations (e.g. parallel execution) shift performance bottlenecks, giving researchers direction to focus on the important issues."}, {"heading": "ACKNOWLEDGEMENTS", "text": "This work was partially supported by C-FAR, one of six STARnet centers, a program of the Semiconductor Research Corporation sponsored by MARCO and DARPA, and partially supported by DARPA under contract number: HR001113-C-0022. This research was partially funded by the U.S. Government. The views and conclusions contained in this document are those of the authors and should not be interpreted to represent official U.S. government policy, either explicitly or implicitly."}], "references": [{"title": "TensorFlow: Largescale machine learning on heterogeneous distributed systems", "author": ["M. Abadi", "A. Agarwal", "P. Barham", "E. Brevdo", "Z. Chen", "C. Citro", "G.S. Corrado", "A. Davis", "J. Dean", "M. Devin", "S. Ghemawat", "I. Goodfellow", "A. Harp", "G. Irving", "M. Isard", "Y. Jia", "R. Jozefowicz", "L. Kaiser", "M. Kudlur", "J. Levenberg", "D. Man\u00e9", "R. Monga", "S. Moore", "D. Murray", "C. Olah", "M. Schuster", "J. Shlens", "B. Steiner", "I. Sutskever", "K. Talwar", "P. Tucker", "V. Vanhoucke", "V. Vasudevan", "F. Vi\u00e9gas", "O. Vinyals", "P. Warden", "M. Wattenberg", "M. Wicke", "Y. Yu", "X. Zheng"], "venue": "arXiv, 1603.04467", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2016}, {"title": "Deep speech 2: End-to-end speech recognition in English and Mandarin", "author": ["D. Amodei", "R. Anubhai", "E. Battenberg", "C. Case", "J. Casper", "B. Catanzaro", "J. Chen", "M. Chrzanowski", "A. Coates", "G. Diamos", "E. Elsen", "J. Engel", "L. Fan", "C. Fougner", "T. Han", "A. Hannun", "B. Jun", "P. LeGresley", "L. Lin", "S. Narang", "A. Ng", "S. Ozair", "R. Prenger", "J. Raiman", "S. Satheesh", "D. Seetapun", "S. Sengupta", "Y. Wang", "Z. Wang", "C. Wang", "B. Xiao", "D. Yogatama", "J. Zhan", "Z. Zhu"], "venue": "arXiv, 1512.02595", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}, {"title": "Neural machine translation by jointly learning to align and translate", "author": ["D. Bahdanau", "K. Cho", "Y. Bengio"], "venue": "International Conference on Learning Representations, ICLR", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2015}, {"title": "The arcade learning environment: An evaluation platform for general agents", "author": ["M.G. Bellemare", "Y. Naddaf", "J. Veness", "M. Bowling"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2013}, {"title": "et al", "author": ["J. Bergstra", "F. Bastien", "O. Breuleux", "P. Lamblin", "R. Pascanu", "O. Delalleau", "G. Desjardins", "D. Warde-Farley", "I. Goodfellow", "A. Bergeron"], "venue": "Theano: Deep learning on GPUs with python. In NIPS BigLearning Workshop", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "Findings of the 2009 workshop on statistical machine translation", "author": ["C. Callison-Burch", "P. Koehn", "C. Monz", "J. Schroeder"], "venue": "Proceedings of the Fourth Workshop on Statistical Machine Translation", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2009}, {"title": "A dynamically configurable coprocessor for convolutional neural networks", "author": ["S. Chakradhar", "M. Sankaradas", "V. Jakkula", "S. Cadambi"], "venue": "Proceedings of the 37th International Symposium on Computer Architecture, ISCA", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2010}, {"title": "BenchNN: On the broad potential application scope of hardware neural network accelerators", "author": ["T. Chen", "Y. Chen", "M. Duranton", "Q. Guo", "A. Hashmi", "M. Lipasti", "A. Nere", "S. Qiu", "M. Sebag", "O. Temam"], "venue": "International Symposium on Workload Characterization, IISWC", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2012}, {"title": "DianNao: A small-footprint high-throughput accelerator for ubiquitous machine-learning", "author": ["T. Chen", "Z. Du", "N. Sun", "J. Wang", "C. Wu", "Y. Chen", "O. Temam"], "venue": "Proceedings of the Nineteenth International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}, {"title": "DaDianNao: A machine-learning supercomputer", "author": ["Y. Chen", "T. Luo", "S. Liu", "S. Zhang", "L. He", "J. Wang", "L. Li", "T. Chen", "Z. Xu", "N. Sun", "O. Temam"], "venue": "Proceedings of the 47th International Symposium on Microarchitecture", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2014}, {"title": "Eyeriss: An energy-efficient reconfigurable accelerator for deep convolutional neural networks", "author": ["Y.-H. Chen", "T. Krishna", "J. Emer", "V. Sze"], "venue": "International Solid-State Circuits Conference, ISSCC", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2016}, {"title": "cuDNN: Efficient primitives for deep learning", "author": ["S. Chetlur", "C. Woolley", "P. Vandermersch", "J. Cohen", "J. Tran", "B. Catanzaro", "E. Shelhamer"], "venue": "arXiv, 1410.0759", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2014}, {"title": "PRIME: A novel processing-in-memory architecture for neural network computation in reram-based main memory", "author": ["P. Chi", "S. Li", "C. Xu", "T. Zhang", "J. Zhao", "T. Liu", "Y. Wang", "Y. Xie"], "venue": "Proceedings of the 43rd International Symposium on Computer Architecture, ISCA", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2016}, {"title": "Keras: Theano-based deep learning library", "author": ["F. Chollet"], "venue": "https://keras.io", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2015}, {"title": "Torch: a modular machine learning software library", "author": ["R. Collobert", "S. Bengio", "J. Mari\u00e9thoz"], "venue": "Technical report, Idiap Research Institute", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2002}, {"title": "Large-scale deep learning for intelligent computer systems", "author": ["J. Dean"], "venue": "BayLearn keynote speech", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2015}, {"title": "Large scale distributed deep networks", "author": ["J. Dean", "G.S. Corrado", "R. Monga", "K. Chen", "M. Devin", "Q.V. Le", "M.Z. Mao", "M. Ranzato", "A. Senior", "P. Tucker", "K. Yang", "A.Y. Ng"], "venue": "Advances in Neural Information Processing Systems, NIPS", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2012}, {"title": "ImageNet: A large-scale hierarchical image database", "author": ["J. Deng", "W. Dong", "R. Socher", "L.-J. Li", "K. Li", "L. Fei-Fei"], "venue": "Proceedings of the Conference on Computer Vision and Pattern Recognition, CVPR", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2009}, {"title": "ShiDianNao: Shifting vision processing closer to the sensor", "author": ["Z. Du", "R. Fasthuber", "T. Chen", "P. Ienne", "L. Li", "T. Luo", "X. Feng", "Y. Chen", "O. Temam"], "venue": "Proceedings of the 42nd International Symposium on Computer Architecture, ISCA", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2015}, {"title": "TIMIT acoustic-phonetic continuous speech corpus", "author": ["J.S. Garofolo", "L.F. Lamel", "W.M. Fisher", "J.G. Fiscus", "D.S. Pallett"], "venue": "LDC93S1", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1993}, {"title": "Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks", "author": ["A. Graves", "S. Fern\u00e1ndez", "F. Gomez", "J. Schmidhuber"], "venue": "Proceedings of the 23rd international Conference on Machine learning, ICML", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2006}, {"title": "EIE: Efficient inference engine on compressed deep neural network", "author": ["S. Han", "X. Liu", "H. Mao", "J. Pu", "A. Pedram", "M. Horowitz", "W. Dally"], "venue": "Proceedings of the 43rd International Symposium on Computer Architecture, ISCA", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2016}, {"title": "Deep speech: Scaling up end-to-end speech recognition", "author": ["A. Hannun", "C. Case", "J. Casper", "B. Catanzaro", "G. Diamos", "E. Elsen", "R. Prenger", "S. Satheesh", "S. Sengupta", "A. Coates", "A.Y. Ng"], "venue": "arXiv, 1412.5567", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2015}, {"title": "DjiNN and tonic: DNN as a service and its implications for future warehouse scale computers", "author": ["J. Hauswald", "Y. Kang", "M.A. Laurenzano", "Q. Chen", "C. Li", "T. Mudge", "R.G. Dreslinski", "J. Mars", "L. Tang"], "venue": "Proceedings of the 42nd International Symposium on Computer Architecture, ISCA", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep residual learning for image recognition", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "arXiv, 1512.03385", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2015}, {"title": "Reducing the dimensionality of data with neural networks", "author": ["G.E. Hinton", "R.R. Salakhutdinov"], "venue": "Science, 313(5786):504\u2013507", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2006}, {"title": "Caffe: Convolutional architecture for fast feature embedding", "author": ["Y. Jia", "E. Shelhamer", "J. Donahue", "S. Karayev", "J. Long", "R. Girshick", "S. Guadarrama", "T. Darrell"], "venue": "Proceedings of the International Conference on Multimedia", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2014}, {"title": "Google supercharges machine learning tasks with TPU custom chip", "author": ["N. Jouppi"], "venue": "https://cloudplatform.googleblog.com/2016/05/ Google-supercharges-machine-learning-tasks-with-custom-chip.html", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2016}, {"title": "Deep visual-semantic alignments for generating image descriptions", "author": ["A. Karpathy", "L. Fei-Fei"], "venue": "Proceedings of the Conference on Computer Vision and Pattern Recognition, CVPR", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2015}, {"title": "Stochastic gradient VB and the variational auto-encoder", "author": ["D.P. Kingma", "M. Welling"], "venue": "Second International Conference on Learning Representations, ICLR", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2014}, {"title": "ImageNet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "Advances in neural information processing systems, NIPS", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2012}, {"title": "The MNIST database of handwritten digits", "author": ["Y. LeCun", "C. Cortes", "C.J. Burges"], "venue": "http://yann.lecun.com/exdb/mnist/", "citeRegEx": "34", "shortCiteRegEx": null, "year": 1998}, {"title": "PuDianNao: A polyvalent machine learning accelerator", "author": ["D. Liu", "T. Chen", "S. Liu", "J. Zhou", "S. Zhou", "O. Teman", "X. Feng", "X. Zhou", "Y. Chen"], "venue": "Proceedings of the Twentieth International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2015}, {"title": "Playing atari with deep reinforcement learning", "author": ["V. Mnih", "K. Kavukcuoglu", "D. Silver", "A. Graves", "I. Antonoglou", "D. Wierstra", "M. Riedmiller"], "venue": "NIPS Deep Learning Workshop", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2013}, {"title": "et al", "author": ["V. Mnih", "K. Kavukcuoglu", "D. Silver", "A.A. Rusu", "J. Veness", "M.G. Bellemare", "A. Graves", "M. Riedmiller", "A.K. Fidjeland", "G. Ostrovski"], "venue": "Human-level control through deep reinforcement learning. Nature, 518(7540):529\u2013533", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2015}, {"title": "Accelerating deep convolutional neural networks using specialized hardware", "author": ["K. Ovtcharov", "O. Ruwase", "J.-Y. Kim", "J. Fowers", "K. Strauss", "E.S. Chung"], "venue": "http://research.microsoft.com/apps/pubs/default. aspx?id=240715", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2015}, {"title": "Minerva: Enabling lowpower", "author": ["B. Reagen", "P. Whatmough", "R. Adolf", "S. Rama", "H. Lee", "S.K. Lee", "J.M. Hern\u00e1ndez-Lobato", "G.-Y. Wei", "D. Brooks"], "venue": "highly-accurate deep neural network accelerators. In Proceedings of the 43rd International Symposium on Computer Architecture, ISCA", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2016}, {"title": "ISAAC: A convolutional neural network accelerator with in-situ analog arithmetic in crossbars", "author": ["A. Shafiee", "A. Nag", "N. Muralimanohar", "R. Balasubramonian", "J. Strachan", "M. Hu", "R.S. Williams", "V. Srikumar"], "venue": "Proceedings of the 43rd International Symposium on Computer Architecture, ISCA", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2016}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["K. Simonyan", "A. Zisserman"], "venue": "arXiv, 1409.1556", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2014}, {"title": "End-to-end memory networks", "author": ["S. Sukhbaatar", "A. Szlam", "J. Weston", "R. Fergus"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2015}, {"title": "Sequence to sequence learning with neural networks", "author": ["I. Sutskever", "O. Vinyals", "Q.V. Le"], "venue": "Advances in neural information processing systems, NIPS", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2014}, {"title": "CortexSuite: A synthetic brain benchmark suite", "author": ["S. Thomas", "C. Gohkale", "E. Tanuwidjaja", "T. Chong", "D. Lau", "S. Garcia", "M.B. Taylor"], "venue": "International Symposium on Workload Characterization, IISWC", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2014}, {"title": "Towards AI-complete question answering: A set of prerequisite toy tasks", "author": ["J. Weston", "A. Bordes", "S. Chopra", "T. Mikolov"], "venue": "arXiv, 1502.05698", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2015}, {"title": "Memory networks", "author": ["J. Weston", "S. Chopra", "A. Bordes"], "venue": "arXiv, 1410.3916", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2014}, {"title": "Neural acceleration for GPU throughput processors", "author": ["A. Yazdanbakhsh", "J. Park", "H. Sharma", "P. Lotfi-Kamran", "H. Esmaeilzadeh"], "venue": "Proceedings of the 48th International Symposium on Microarchitecture, MICRO", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2015}, {"title": "Optimizing FPGA-based accelerator design for deep convolutional neural networks", "author": ["C. Zhang", "P. Li", "G. Sun", "Y. Guan", "B. Xiao", "J. Cong"], "venue": "23rd International Symposium on Field-Programmable Gate Arrays, FPGA", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2015}], "referenceMentions": [{"referenceID": 8, "context": "The architecture community has begun to respond in force: A host of new hardware designs have been proposed [10], [12], [24], [39], and several are beginning to transition into production [30], [38].", "startOffset": 108, "endOffset": 112}, {"referenceID": 10, "context": "The architecture community has begun to respond in force: A host of new hardware designs have been proposed [10], [12], [24], [39], and several are beginning to transition into production [30], [38].", "startOffset": 114, "endOffset": 118}, {"referenceID": 21, "context": "The architecture community has begun to respond in force: A host of new hardware designs have been proposed [10], [12], [24], [39], and several are beginning to transition into production [30], [38].", "startOffset": 120, "endOffset": 124}, {"referenceID": 36, "context": "The architecture community has begun to respond in force: A host of new hardware designs have been proposed [10], [12], [24], [39], and several are beginning to transition into production [30], [38].", "startOffset": 126, "endOffset": 130}, {"referenceID": 27, "context": "The architecture community has begun to respond in force: A host of new hardware designs have been proposed [10], [12], [24], [39], and several are beginning to transition into production [30], [38].", "startOffset": 188, "endOffset": 192}, {"referenceID": 35, "context": "The architecture community has begun to respond in force: A host of new hardware designs have been proposed [10], [12], [24], [39], and several are beginning to transition into production [30], [38].", "startOffset": 194, "endOffset": 198}, {"referenceID": 6, "context": "Category Feature [8] [9] [10] [11] [12] [14] [21] [24] [26] [35] [38] [39] [40] [44] [47] [49] Fathom", "startOffset": 17, "endOffset": 20}, {"referenceID": 7, "context": "Category Feature [8] [9] [10] [11] [12] [14] [21] [24] [26] [35] [38] [39] [40] [44] [47] [49] Fathom", "startOffset": 21, "endOffset": 24}, {"referenceID": 8, "context": "Category Feature [8] [9] [10] [11] [12] [14] [21] [24] [26] [35] [38] [39] [40] [44] [47] [49] Fathom", "startOffset": 25, "endOffset": 29}, {"referenceID": 9, "context": "Category Feature [8] [9] [10] [11] [12] [14] [21] [24] [26] [35] [38] [39] [40] [44] [47] [49] Fathom", "startOffset": 30, "endOffset": 34}, {"referenceID": 10, "context": "Category Feature [8] [9] [10] [11] [12] [14] [21] [24] [26] [35] [38] [39] [40] [44] [47] [49] Fathom", "startOffset": 35, "endOffset": 39}, {"referenceID": 12, "context": "Category Feature [8] [9] [10] [11] [12] [14] [21] [24] [26] [35] [38] [39] [40] [44] [47] [49] Fathom", "startOffset": 40, "endOffset": 44}, {"referenceID": 18, "context": "Category Feature [8] [9] [10] [11] [12] [14] [21] [24] [26] [35] [38] [39] [40] [44] [47] [49] Fathom", "startOffset": 45, "endOffset": 49}, {"referenceID": 21, "context": "Category Feature [8] [9] [10] [11] [12] [14] [21] [24] [26] [35] [38] [39] [40] [44] [47] [49] Fathom", "startOffset": 50, "endOffset": 54}, {"referenceID": 23, "context": "Category Feature [8] [9] [10] [11] [12] [14] [21] [24] [26] [35] [38] [39] [40] [44] [47] [49] Fathom", "startOffset": 55, "endOffset": 59}, {"referenceID": 32, "context": "Category Feature [8] [9] [10] [11] [12] [14] [21] [24] [26] [35] [38] [39] [40] [44] [47] [49] Fathom", "startOffset": 60, "endOffset": 64}, {"referenceID": 35, "context": "Category Feature [8] [9] [10] [11] [12] [14] [21] [24] [26] [35] [38] [39] [40] [44] [47] [49] Fathom", "startOffset": 65, "endOffset": 69}, {"referenceID": 36, "context": "Category Feature [8] [9] [10] [11] [12] [14] [21] [24] [26] [35] [38] [39] [40] [44] [47] [49] Fathom", "startOffset": 70, "endOffset": 74}, {"referenceID": 37, "context": "Category Feature [8] [9] [10] [11] [12] [14] [21] [24] [26] [35] [38] [39] [40] [44] [47] [49] Fathom", "startOffset": 75, "endOffset": 79}, {"referenceID": 41, "context": "Category Feature [8] [9] [10] [11] [12] [14] [21] [24] [26] [35] [38] [39] [40] [44] [47] [49] Fathom", "startOffset": 80, "endOffset": 84}, {"referenceID": 44, "context": "Category Feature [8] [9] [10] [11] [12] [14] [21] [24] [26] [35] [38] [39] [40] [44] [47] [49] Fathom", "startOffset": 85, "endOffset": 89}, {"referenceID": 45, "context": "Category Feature [8] [9] [10] [11] [12] [14] [21] [24] [26] [35] [38] [39] [40] [44] [47] [49] Fathom", "startOffset": 90, "endOffset": 94}, {"referenceID": 1, "context": "learning algorithm requires at least 10 exaflops to converge [3].", "startOffset": 61, "endOffset": 64}, {"referenceID": 15, "context": "Jeff Dean recently noted that research productivity is inversely proportional to the turnaround time of a deep learning experiment: while 1\u2013 4 days is \u201ctolerable\u201d, \u201cprogress stalls\u201d on the order of weeks, and month-long experiments are not worth running [18].", "startOffset": 254, "endOffset": 258}, {"referenceID": 30, "context": "[33]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "the state of the art for both speech recognition and language modeling, recurrent neural networks appeared just twice: a heavily modified version of Karpathy and Li\u2019s NeuralTalk work [31] in Han et al.", "startOffset": 183, "endOffset": 187}, {"referenceID": 21, "context": "[24] and a slightly-dated restricted Boltzmann machine in Thomas et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 41, "context": "[44].", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "So, for instance, since we cannot train Deep Speech on Baidu\u2019s massive, private collection of recorded utterances, we substitute the widely cited TIMIT corpus [22].", "startOffset": 159, "endOffset": 163}, {"referenceID": 14, "context": "Consider four most widely used frameworks: Torch [16], a general machine", "startOffset": 49, "endOffset": 53}, {"referenceID": 0, "context": "learning library written in Lua; TensorFlow [2], the dataflowbased second generation of Google\u2019s DistBelief system [19]; Theano [6], a symbolic mathematics package originally from Universit\u00e9 de Montr\u00e9al; and Caffe [29], Berkeley\u2019s deep learning library with a JSON frontend and C++ backend.", "startOffset": 44, "endOffset": 47}, {"referenceID": 16, "context": "learning library written in Lua; TensorFlow [2], the dataflowbased second generation of Google\u2019s DistBelief system [19]; Theano [6], a symbolic mathematics package originally from Universit\u00e9 de Montr\u00e9al; and Caffe [29], Berkeley\u2019s deep learning library with a JSON frontend and C++ backend.", "startOffset": 115, "endOffset": 119}, {"referenceID": 4, "context": "learning library written in Lua; TensorFlow [2], the dataflowbased second generation of Google\u2019s DistBelief system [19]; Theano [6], a symbolic mathematics package originally from Universit\u00e9 de Montr\u00e9al; and Caffe [29], Berkeley\u2019s deep learning library with a JSON frontend and C++ backend.", "startOffset": 128, "endOffset": 131}, {"referenceID": 26, "context": "learning library written in Lua; TensorFlow [2], the dataflowbased second generation of Google\u2019s DistBelief system [19]; Theano [6], a symbolic mathematics package originally from Universit\u00e9 de Montr\u00e9al; and Caffe [29], Berkeley\u2019s deep learning library with a JSON frontend and C++ backend.", "startOffset": 214, "endOffset": 218}, {"referenceID": 11, "context": "the cuDNN package [13].", "startOffset": 18, "endOffset": 22}, {"referenceID": 13, "context": "This similarity is so strong, in fact, that automatic translators exist for taking a model in one framework and emitting one in another [48], [17] and wrapper interfaces exist for automatically generating a model in several output frameworks [15].", "startOffset": 242, "endOffset": 246}, {"referenceID": 40, "context": "seq2seq is recurrent neural network for solving machine translation [43].", "startOffset": 68, "endOffset": 72}, {"referenceID": 2, "context": "based model for keeping track of context in the original sentence [4].", "startOffset": 66, "endOffset": 69}, {"referenceID": 43, "context": "Memory networks [46] are one of two recent efforts to decouple state from structure in a neural network.", "startOffset": 16, "endOffset": 20}, {"referenceID": 40, "context": "seq2seq 2014 [43] Recurrent 7 Supervised WMT-15 [7] Direct language-to-language sentence translation.", "startOffset": 13, "endOffset": 17}, {"referenceID": 5, "context": "seq2seq 2014 [43] Recurrent 7 Supervised WMT-15 [7] Direct language-to-language sentence translation.", "startOffset": 48, "endOffset": 51}, {"referenceID": 39, "context": "memnet 2015 [42] Memory Network 3 Supervised bAbI [45] Facebook\u2019s memory-oriented neural system.", "startOffset": 12, "endOffset": 16}, {"referenceID": 42, "context": "memnet 2015 [42] Memory Network 3 Supervised bAbI [45] Facebook\u2019s memory-oriented neural system.", "startOffset": 50, "endOffset": 54}, {"referenceID": 22, "context": "speech 2014 [25] Recurrent, Full 5 Supervised TIMIT [22] Baidu\u2019s speech recognition engine.", "startOffset": 12, "endOffset": 16}, {"referenceID": 19, "context": "speech 2014 [25] Recurrent, Full 5 Supervised TIMIT [22] Baidu\u2019s speech recognition engine.", "startOffset": 52, "endOffset": 56}, {"referenceID": 29, "context": "autoenc 2014 [32] Full 3 Unsupervised MNIST [34] Variational autoencoder.", "startOffset": 13, "endOffset": 17}, {"referenceID": 31, "context": "autoenc 2014 [32] Full 3 Unsupervised MNIST [34] Variational autoencoder.", "startOffset": 44, "endOffset": 48}, {"referenceID": 24, "context": "residual 2015 [27] Convolutional 34 Supervised ImageNet [20] Image classifier from Microsoft Research Asia.", "startOffset": 14, "endOffset": 18}, {"referenceID": 17, "context": "residual 2015 [27] Convolutional 34 Supervised ImageNet [20] Image classifier from Microsoft Research Asia.", "startOffset": 56, "endOffset": 60}, {"referenceID": 38, "context": "vgg 2014 [41] Convolutional, Full 19 Supervised ImageNet [20] Image classifier demonstrating the power of small convolutional filters.", "startOffset": 9, "endOffset": 13}, {"referenceID": 17, "context": "vgg 2014 [41] Convolutional, Full 19 Supervised ImageNet [20] Image classifier demonstrating the power of small convolutional filters.", "startOffset": 57, "endOffset": 61}, {"referenceID": 30, "context": "alexnet 2012 [33] Convolutional, Full 5 Supervised ImageNet [20] Image classifier.", "startOffset": 13, "endOffset": 17}, {"referenceID": 17, "context": "alexnet 2012 [33] Convolutional, Full 5 Supervised ImageNet [20] Image classifier.", "startOffset": 60, "endOffset": 64}, {"referenceID": 33, "context": "deepq 2013 [36] Convolutional, Full 5 Reinforcement Atari ALE [5] Atari-playing neural network from DeepMind.", "startOffset": 11, "endOffset": 15}, {"referenceID": 3, "context": "deepq 2013 [36] Convolutional, Full 5 Reinforcement Atari ALE [5] Atari-playing neural network from DeepMind.", "startOffset": 62, "endOffset": 65}, {"referenceID": 39, "context": "End-to-end memory networks [42] are an extension which removes the need for type annotations on inputs and dramatically streamlines training.", "startOffset": 27, "endOffset": 31}, {"referenceID": 22, "context": "Deep Speech was Baidu Research\u2019s attempt at a scalable speech recognition model [25].", "startOffset": 80, "endOffset": 84}, {"referenceID": 20, "context": "Its connectionist temporal classification (CTC) loss function can learn from unsegmented data, significantly reducing the cost of producing training data [23].", "startOffset": 154, "endOffset": 158}, {"referenceID": 19, "context": "sizes to account for differences in the TIMIT dataset [22].", "startOffset": 54, "endOffset": 58}, {"referenceID": 25, "context": "Autoencoders are a flexible, unsupervised model often used for dimensionality reduction, feature extraction, or generating data [28].", "startOffset": 128, "endOffset": 132}, {"referenceID": 29, "context": "Variational autoencoders, invented by Kingma and Welling in 2013, make a statistical assumptions about the properties of this embedding in order to learn to efficiently reconstruct their inputs [32].", "startOffset": 194, "endOffset": 198}, {"referenceID": 24, "context": "Residual networks were a landmark in enabling very deep neural networks [27].", "startOffset": 72, "endOffset": 76}, {"referenceID": 38, "context": "vgg is an implementation of the 19-layer convolutional network developed by the visual geometry group at Oxford [41].", "startOffset": 112, "endOffset": 116}, {"referenceID": 30, "context": "AlexNet [33] was a watershed event for the deep learning community.", "startOffset": 8, "endOffset": 12}, {"referenceID": 33, "context": "DeepMind startled the AI community in 2013 with a deep reinforcement learning system that learned to win dozens of Atari games solely from pixels and scores, sometimes beating human experts [36], [37].", "startOffset": 190, "endOffset": 194}, {"referenceID": 34, "context": "DeepMind startled the AI community in 2013 with a deep reinforcement learning system that learned to win dozens of Atari games solely from pixels and scores, sometimes beating human experts [36], [37].", "startOffset": 196, "endOffset": 200}, {"referenceID": 3, "context": "We leverage the same Atari emulation environment which powered the original implementation, the Arcade Learning Environment [5].", "startOffset": 124, "endOffset": 127}, {"referenceID": 2, "context": "The elementwise multiplications in seq2seq are a result of the LSTM neurons, and the data movement operations are part of the attention-based encoder/decoder it uses [4].", "startOffset": 166, "endOffset": 169}, {"referenceID": 41, "context": "CortexSuite [44] is thematically based on the application areas surrounding perception and cognition, but it largely contains conventional algorithms.", "startOffset": 12, "endOffset": 16}, {"referenceID": 7, "context": "BenchNN [9] uses machine learning methods to approximate", "startOffset": 8, "endOffset": 11}, {"referenceID": 23, "context": "DjiNN and Tonic [26] is perhaps the most similar benchmark suite.", "startOffset": 16, "endOffset": 20}, {"referenceID": 0, "context": "The two most prominent exceptions are TensorBoard and EEG, both Google-developed tools for TensorFlow [2].", "startOffset": 102, "endOffset": 105}], "year": 2016, "abstractText": "Deep learning has been popularized by its recent successes on challenging artificial intelligence problems. One of the reasons for its dominance is also an ongoing challenge: the need for immense amounts of computational power. Hardware architects have responded by proposing a wide array of promising ideas, but to date, the majority of the work has focused on specific algorithms in somewhat narrow application domains. While their specificity does not diminish these approaches, there is a clear need for more flexible solutions. We believe the first step is to examine the characteristics of cutting edge models from across the deep learning community. Consequently, we have assembled Fathom: a collection of eight archetypal deep learning workloads for study. Each of these models comes from a seminal work in the deep learning community, ranging from the familiar deep convolutional neural network of Krizhevsky et al., to the more exotic memory networks from Facebook\u2019s AI research group. Fathom has been released online, and this paper focuses on understanding the fundamental performance characteristics of each model. We use a set of application-level modeling tools built around the TensorFlow deep learning framework in order to analyze the behavior of the Fathom workloads. We present a breakdown of where time is spent, the similarities between the performance profiles of our models, an analysis of behavior in inference and training, and the effects of parallelism on scaling.", "creator": "LaTeX with hyperref package"}}}