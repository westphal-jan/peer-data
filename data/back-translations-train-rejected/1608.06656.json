{"id": "1608.06656", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Aug-2016", "title": "Lexical Query Modeling in Session Search", "abstract": "Lexical query modeling has been the leading paradigm for session search. In this paper, we analyze TREC session query logs and compare the performance of different lexical matching approaches for session search. Naive methods based on term frequency weighing perform on par with specialized session models. In addition, we investigate the viability of lexical query models in the setting of session search. We give important insights into the potential and limitations of lexical query modeling for session search and propose future directions for the field of session search.", "histories": [["v1", "Tue, 23 Aug 2016 21:07:50 GMT  (1297kb,D)", "http://arxiv.org/abs/1608.06656v1", "ICTIR2016, Proceedings of the 2nd ACM International Conference on the Theory of Information Retrieval. 2016"]], "COMMENTS": "ICTIR2016, Proceedings of the 2nd ACM International Conference on the Theory of Information Retrieval. 2016", "reviews": [], "SUBJECTS": "cs.IR cs.CL", "authors": ["christophe van gysel", "evangelos kanoulas", "maarten de rijke"], "accepted": false, "id": "1608.06656"}, "pdf": {"name": "1608.06656.pdf", "metadata": {"source": "CRF", "title": "Lexical Query Modeling in Session Search", "authors": ["Christophe Van Gysel", "Evangelos Kanoulas", "Maarten de Rijke"], "emails": ["cvangysel@uva.nl", "e.kanoulas@uva.nl", "derijke@uva.nl", "permissions@acm.org."], "sections": [{"heading": "1. INTRODUCTION", "text": "In fact, most people who are able to put themselves in the world, put themselves in the world, put themselves in the world, put themselves in the world, put themselves in the world, in the world, in the world in which they live, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the, in the world, in the world, in the world, in the world, in the world, in the, in the, in the world, in the world, in the world,"}, {"heading": "2. LEXICAL MATCHING FOR SESSIONS", "text": "We define a search session s as a sequence of n interactions (qi, ri) between user and search engine in which the search for a specific search term consists of the terms i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i,"}, {"heading": "3. EXPERIMENTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Benchmarks", "text": "We evaluate the lexical query modeling methods listed in Section 2 of the Session Search Task (G1) of the TREC Session Line from 2011 to 2014. [15] We report on the performance of each track output independently and on the track aggregation. In a query, the task is to improve query performance through prior queries and user interactions with the query system. To achieve this, we first retrieve the 2,000 most relevant documents for the given query and then rearrange these documents using the methods described in Section 2. We use the subsets \"Category B\" of ClueWeb09 (2011 / 2012) and ClueWeb12 (2013 / 2014) as document collections. Both collections consist of approximately 50 million documents. Spam documents are removed before indexing by filtering documents with results (GroupX or Fusion) below 70 [4]. Table 1 shows an overview of benchmarks and document collections."}, {"heading": "3.2 Evaluation measures", "text": "In order to measure the effectiveness of the query, we report on Normalized Discounted Cumulative Gain at rank 10 (NDCG @ 10) in addition to the Mean Reciprocal Rank (MRR). Relevance assessments of the tracks have been switched from topic-centered to session-centered according to the mappings provided by the track organizers. 2 evaluation benchmarks are then calculated using the official TREC evaluation tool, trec _ eval.3."}, {"heading": "3.3 Systems under comparison", "text": "We compare the lexical query model methods outlined in \u00a7 2. All methods calculate the weights for lexical units (e.g. uniigram terms) on a session basis, construct a structured Indri query [13], and ask the document collection using pyndri.4 For a fair comparison, we use Indris standard smoothing configuration (i.e., Dirichlet smoothing with \u00b5 = 2500) and uniform query aggregation for all methods (unlike the smoothing used for QCM in [16]), which allows us to separate query aggregation techniques from query model approaches in the case of session searches. For Nugget, we use the standard parameter configuration (ksnippet = 10, junction = 0.97, kanchor = 5 and \u03b2 = 0.1), applying the strict expansion methods. We report the performance of Nugget on the external kernel level (1) with a click on R001 and R001 (1) (1)."}, {"heading": "3.4 Ideal lexical term weighting", "text": "Inspired by Bendersky et al. [1], we optimize NDCG @ 10 for each session by means of a grid search across the term weight space. We sweep the weight of each term between \u2212 1.0 and 1.0 (including) with steps of 0.1, resulting in a total of 21 weight assignments per term. Due to the exponential time complexity of the grid search, we limit our analysis to 230 sessions with 7 unique query terms or less (see Table 1). This experiment will tell us the maximum achievable query performance during the session search only based on the reweighted lexical terms."}, {"heading": "4. RESULTS & DISCUSSION", "text": "In this area, we are able to analyze and analyze the results of previous years."}, {"heading": "5. CONCLUSIONS", "text": "This is due to the fact that shorter sessions play a greater role in session minutes. At longer sessions, specialized models are able to exploit session history more effectively; future work should focus on creating benchmarks consisting of longer sessions with complex information needs; perhaps more importantly, we should look at the viability of lexical query matching pages in session search; there is still much room for improvement by re-weighting query terms; How-5An open-source implementation of our testbed for evaluating session search is available at https: / / github.com / cvangysel. ever, the query / document mismatch is common in session search and methods restricted to lexical query modeling face a very strict performance ceiling. Future work should focus on better lexical query models for session search, in addition to setic matching and tracking mismatch."}], "references": [{"title": "Effective query formulation with multiple information sources", "author": ["M. Bendersky", "D. Metzler", "W.B. Croft"], "venue": "In SIGIR,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2012}, {"title": "Modeling the impact of short- and long-term behavior on search personalization", "author": ["P.N. Bennett", "R.W. White", "W. Chu", "S.T. Dumais", "P. Bailey", "F. Borisyuk", "X. Cui"], "venue": "In SIGIR,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "Overview of the trec 2014 session track", "author": ["B. Carterette", "E. Kanoulas", "M.M. Hall", "P.D. Clough"], "venue": "In TREC,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2014}, {"title": "Efficient and effective spam filtering and re-ranking for large web datasets", "author": ["G.V. Cormack", "M.D. Smucker", "C.L. Clarke"], "venue": "Information retrieval,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2011}, {"title": "Do you want to take notes?: identifying research missions in yahoo! search pad", "author": ["D. Donato", "F. Bonchi", "T. Chi", "Y. Maarek"], "venue": "In WWW,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2010}, {"title": "Effective structured query formulation for session search", "author": ["D. Guan", "H. Yang", "N. Goharian"], "venue": "Techn. report,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2012}, {"title": "Struggling or exploring?: disambiguating long search sessions", "author": ["A. Hassan", "R.W. White", "S.T. Dumais", "Y.-M. Wang"], "venue": "In WSDM,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "Modeling and analysis of cross-session search tasks", "author": ["A. Kotov", "P.N. Bennett", "R.W. White", "S.T. Dumais", "J. Teevan"], "venue": "In SIGIR,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2011}, {"title": "Semantic matching in search", "author": ["H. Li", "J. Xu"], "venue": "Found. & Tr. in Information Retrieval,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "Modeling rich interactions in session search - georgetown university at trec 2014 session track", "author": ["J. Luo", "X. Dong", "H. Yang"], "venue": "Techn. report,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "Win-win search: Dual-agent stochastic game in session search", "author": ["J. Luo", "S. Zhang", "H. Yang"], "venue": "In SIGIR,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "Session search by direct policy learning", "author": ["J. Luo", "X. Dong", "H. Yang"], "venue": "In ICTIR,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2015}, {"title": "Combining the language model and inference network approaches to retrieval", "author": ["D. Metzler", "W.B. Croft"], "venue": "IPM, 40(5):735\u2013750,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2004}, {"title": "Toward whole-session relevance: exploring intrinsic diversity in web search", "author": ["K. Raman", "P.N. Bennett", "K. Collins-Thompson"], "venue": "In SIGIR,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2013}, {"title": "The query change model: Modeling session search as a markov decision process", "author": ["H. Yang", "D. Guan", "S. Zhang"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2015}], "referenceMentions": [{"referenceID": 6, "context": "Many complex information seeking tasks, such as planning a trip or buying a car, cannot sufficiently be expressed in a single query [7].", "startOffset": 132, "endOffset": 135}, {"referenceID": 13, "context": "These multi-faceted tasks are exploratory, comprehensive, survey-like or comparative in nature [14] and require multiple search iterations to be adequately answered [8].", "startOffset": 95, "endOffset": 99}, {"referenceID": 7, "context": "These multi-faceted tasks are exploratory, comprehensive, survey-like or comparative in nature [14] and require multiple search iterations to be adequately answered [8].", "startOffset": 165, "endOffset": 168}, {"referenceID": 4, "context": "[5] note that 10% of the user sessions (more than 25% of query volume) consists of such complex information needs.", "startOffset": 0, "endOffset": 3}, {"referenceID": 14, "context": "[16] introduce the Query Change Model (QCM), which uses lexical editing changes between consecutive queries in addition to query terms occurring in previously retrieved documents, to improve session search.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "Query models are then linearly combined for every document, based on query recency [16] or document satisfaction [3, 10], into a session-wide lexical query", "startOffset": 83, "endOffset": 87}, {"referenceID": 2, "context": "Query models are then linearly combined for every document, based on query recency [16] or document satisfaction [3, 10], into a session-wide lexical query", "startOffset": 113, "endOffset": 120}, {"referenceID": 9, "context": "Query models are then linearly combined for every document, based on query recency [16] or document satisfaction [3, 10], into a session-wide lexical query", "startOffset": 113, "endOffset": 120}, {"referenceID": 2, "context": "However, there has been a clear trend towards the use of supervised learning [3, 12, 16] and external data sources [6, 11].", "startOffset": 77, "endOffset": 88}, {"referenceID": 11, "context": "However, there has been a clear trend towards the use of supervised learning [3, 12, 16] and external data sources [6, 11].", "startOffset": 77, "endOffset": 88}, {"referenceID": 14, "context": "However, there has been a clear trend towards the use of supervised learning [3, 12, 16] and external data sources [6, 11].", "startOffset": 77, "endOffset": 88}, {"referenceID": 5, "context": "However, there has been a clear trend towards the use of supervised learning [3, 12, 16] and external data sources [6, 11].", "startOffset": 115, "endOffset": 122}, {"referenceID": 10, "context": "However, there has been a clear trend towards the use of supervised learning [3, 12, 16] and external data sources [6, 11].", "startOffset": 115, "endOffset": 122}, {"referenceID": 5, "context": "[6] perform lexical query expansion by adding higherorder n-grams to queries by mining document snippets.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] expand document representations by including incoming anchor", "startOffset": 0, "endOffset": 3}, {"referenceID": 11, "context": "[12] introduce a linear point-wise learning-to-rank model that predicts relevance given a document and query change features.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "The use of machine-learned ranking and the expansion of query and document representations is meant to address a specific instance of a wider problem in information retrieval, namely the query document mismatch [9].", "startOffset": 211, "endOffset": 214}, {"referenceID": 5, "context": "Existing session search methods [6, 16] can be expressed in this formalism as follows: Term frequency (TF) Terms in a query are weighted according to their frequency in the query (i.", "startOffset": 32, "endOffset": 39}, {"referenceID": 14, "context": "Existing session search methods [6, 16] can be expressed in this formalism as follows: Term frequency (TF) Terms in a query are weighted according to their frequency in the query (i.", "startOffset": 32, "endOffset": 39}, {"referenceID": 2, "context": "Using the last query corresponds to the official baseline of the TREC Session track [3].", "startOffset": 84, "endOffset": 87}, {"referenceID": 5, "context": "Nugget Nugget [6] is a method for effective structured query formulation for session search.", "startOffset": 14, "endOffset": 17}, {"referenceID": 14, "context": "Query Change Model (QCM) QCM [16] uses syntactic editing changes between consecutive queries in addition to query changes and previous SERPs to enhance session search.", "startOffset": 29, "endOffset": 33}, {"referenceID": 3, "context": "Spam documents are removed before indexing by filtering out documents with scores (GroupX and Fusion, respectively) below 70 [4].", "startOffset": 125, "endOffset": 128}, {"referenceID": 12, "context": ", unigram terms) on a per-session basis, construct a structured Indri query [13] and query the document collection using pyndri.", "startOffset": 76, "endOffset": 80}, {"referenceID": 14, "context": ", Dirichlet smoothing with \u03bc = 2500) and uniform query aggregation for all methods (different from the smoothing used for QCM in [16]).", "startOffset": 129, "endOffset": 133}, {"referenceID": 11, "context": "For QCM, we use the parameter configuration as described in [12, 16]: \u03b1 = 2.", "startOffset": 60, "endOffset": 68}, {"referenceID": 14, "context": "For QCM, we use the parameter configuration as described in [12, 16]: \u03b1 = 2.", "startOffset": 60, "endOffset": 68}, {"referenceID": 0, "context": "[1], we optimize NDCG@10 for every session using a grid search over the term weight space.", "startOffset": 0, "endOffset": 3}, {"referenceID": 11, "context": "[12] on the 2012 and 2013 tracks.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "This aggregated representation naturally emphasizes important theme terms of the session, which is a key component in the QCM [16].", "startOffset": 126, "endOffset": 130}, {"referenceID": 1, "context": "[2] note that users tend to reformulate and adapt their information needs based on observed results and this is essentially the observation upon which QCM builds.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "However, the other half of the performance gap cannot be bridged using lexical matching only, but instead requires a notion of semantic matching [9].", "startOffset": 145, "endOffset": 148}], "year": 2016, "abstractText": "Lexical query modeling has been the leading paradigm for session search. In this paper, we analyze TREC session query logs and compare the performance of different lexical matching approaches for session search. Naive methods based on term frequency weighing perform on par with specialized session models. In addition, we investigate the viability of lexical query models in the setting of session search. We give important insights into the potential and limitations of lexical query modeling for session search and propose future directions for the field of session search.", "creator": "LaTeX with hyperref package"}}}