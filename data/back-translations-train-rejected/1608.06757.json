{"id": "1608.06757", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Aug-2016", "title": "Robust Named Entity Recognition in Idiosyncratic Domains", "abstract": "Named entity recognition often fails in idiosyncratic domains. That causes a problem for depending tasks, such as entity linking and relation extraction. We propose a generic and robust approach for high-recall named entity recognition. Our approach is easy to train and offers strong generalization over diverse domain-specific language, such as news documents (e.g. Reuters) or biomedical text (e.g. Medline). Our approach is based on deep contextual sequence learning and utilizes stacked bidirectional LSTM networks. Our model is trained with only few hundred labeled sentences and does not rely on further external knowledge. We report from our results F1 scores in the range of 84-94% on standard datasets.", "histories": [["v1", "Wed, 24 Aug 2016 09:06:14 GMT  (157kb,D)", "http://arxiv.org/abs/1608.06757v1", "8 pages, 1 figure"]], "COMMENTS": "8 pages, 1 figure", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["sebastian arnold", "felix a gers", "torsten kilias", "alexander l\\\"oser"], "accepted": false, "id": "1608.06757"}, "pdf": {"name": "1608.06757.pdf", "metadata": {"source": "CRF", "title": "Robust Named Entity Recognition in Idiosyncratic Domains", "authors": ["Sebastian Arnold", "Felix A. Gers", "Torsten Kilias", "Alexander L\u00f6ser"], "emails": ["sarnold@beuth-hochschule.de", "gers@beuth-hochschule.de", "tkilias@beuth-hochschule.de", "aloeser@beuth-hochschule.de"], "sections": [{"heading": "1 Introduction", "text": "In fact, most people are able to decide for themselves what they want and what they want."}, {"heading": "2 Related Work", "text": "Named entity recognition. The task of NER has been extensively studied with different evaluation in the last decades: MUC-6, MUC-7, CoNLL2002, CoNLL2003 and ACE. The standard approach to NER is the application of discriminative tagging (Collins, 2002) to the task of NER (McCallum and Li, 2003), often with linear chain Conditional Random Field (CRF), Hidden Markov (HMM) or Maximum Entropy Hidden Markov Models (MEMM). Later, Bengio et al. (2003) used continuous-space language models, where type-to-vector word mappings can be learned backpropagation. Mikolov et al. (2013) achieves a more effective vector representation using the skip-gram model. We optimize the likelihood of tokens over a window surrounding a given token."}, {"heading": "3 Robust Contextual Word Labeling", "text": "Figure 1 illustrates an example of the sequential conversion of a sentence into labels. We define each sentence in a document as a sequence of words: w = (w0, w1,.., wn), e.g. w0 = aspirin. We define a mention as the longest possible range of adjacent characters that refer to a unit or relevant concept of a real object, such as aspirin (ASA). We also assume that mentions are neither recursive nor overlapping. To encode the limits of the mention span, we adapt the idea of Ramshaw and Marcus (1995), which was adopted as the BIO2 standard in the joint task of CoNLLL2003 (Tjong Kim Sang and De Meulder, 2003). We assign labels {B, I, O} to each token to mark beginning, inside and outside of a mention from left to right, e.g. we use a sequence of labels containing a B together."}, {"heading": "3.1 Robust Word Encoding Methods", "text": "We have shown that most errors related to callbacks are caused by misspellings, POS errors, invisible words, and irregular contexts. Therefore, we generalize our model in three layers: robust word coding, word context, and contextual sequence labeling. Dictionary hashing to overcome spelling errors suffers from sparse training, especially in the case of non-literal words, spelling errors, and uppercase errors. The word model by Mikro et al. (2013) generalizes the use of rare words in idiosyncratic domains or for misspelled words, as no vector representation is learned in practice."}, {"heading": "3.2 Deep Contextual Sequence Learning", "text": "With sparse training data in the idiosyncratic domain, we expect input data with high variance. Therefore, we need a strong generalization for the syntactic and semantic representation of language. In order to achieve the high performance of 80-90% NER F1, extensive context-sensitive information is indispensable. We apply the computational model of recursive neural networks, in particular short-term memory networks (LSTMs) (Hochreiter and Schmidhuber, 1997; Gers et al., 2002) to the problem of sequence marking. Like neural forward networks, LSTMs are able to learn complex parameters by means of gradient derivation, but include additional recursive connections between cells to influence weight updates via adjacent time steps. With their ability to memorize words and forget over time, LSTMs have proven to process context-sensitive sequential data well (Berve, 2012, Lipton, and 2015)."}, {"heading": "3.3 Implementation of NER Components", "text": "To show the effects of our bidirectional LSTM model, we measure the annotation performance on three different neural network configurations. We implement all components using the Deeplearning4j framework4. For pre-processing (sentence and word tokenization) we use Stanford CoreNLP5 (Manning et al., 2014). We test the sequence marker with three input encodings: \u2022 DICT: We build a dictionary of all words in the corpus and generate the input vector with 1-hot encoding for each word \u2022 EMB: We use the GoogleNews word2vecembeddings, which encode each word as a vector of size 300 \u2022 TRI: we implement letter trigram word hash-ing, as in Section 3.1.4http: / deeplearning4.org, version 0.4-rc3.9-SNAPSHOT 5version We evaluate all network types with three different sets of tokits."}, {"heading": "4 Evaluation", "text": "We evaluate nine configurations of our model against five gold standard evaluation data sets. We show that combining letter-trigram word-hashing with bidirectional LSTM delivers the best results and outperforms sequence learners based on dictionaries or word2vec. To highlight the generalization of our model to idiosyncratic domains, we perform tests on common type data sets as well as specialized medical documents. We compare our system on these data sets with specialized state-of-the-art systems."}, {"heading": "4.1 Evaluation Set Up", "text": "To show the effectiveness of the components, we evaluate different configurations of this configuration with 2000 random sentences from the remaining set. Deeplearning4j with nd4j-x86 backend is used to train the TRI + BLSTM configuration on a standard Intel i7 4-core notebook at 2.8GHz for about 50 minutes. We use GENIA terminology annotations 3.02, which cover linguistic expressions of units we use for training. GENIA corpus (Ohta et al., 2002) contains biomedical summaries from the PubMed database. We use GENIA terminology annotations 3.02, which cover linguistic expressions of units of interest in molecular biology (e.g. proteins, genes and cells."}, {"heading": "4.2 Measurements", "text": "For a more detailed system error analysis, also used by Ling et al. (2015), we measure the performance of annotations using zero-point style F1 annotations. We measure the overall performance of annotations using the evaluation yardsticks defined by Cornolti et al. (2013), which are also used by Ling et al. (2015). Let D be a set of annotated documents in the gold standard, with annotations G = [Gd | d] having a total number of N = G | examples. Each mention of G is defined by starting position b and the end position in source document d. To quantify the performance of the system, we compare G with the set of predicted annotations P = [Pd]."}, {"heading": "4.3 Evaluation Results", "text": "This year it has come to the point that it will only be a matter of time before it will happen, until it does."}, {"heading": "4.4 Discussion and Error Analysis", "text": "This year, it has reached the point where it will be able to retaliate."}, {"heading": "5 Summary", "text": "Ling et al. (2015) show that the task of NERs is not clearly defined and rather depends on a specific problem context. In contrast, most NERS approaches are trained specifically on fixed datasets in batch mode. Worse, they often suffer from poor memory (Pink et al., 2014). Ideally, one could personalize the task of recognizing designated units, concepts or phrases according to the specific problem. \"Personalizing\" and adapting such annotators should be done with very limited human labeling effort, especially for idiosyncratic areas with sparse training data. Our work follows this line. From our results, we report F1 values ranging from 84-94% when using bidirectional multilayered LSTMs, letter-trigram word-hashing and surface shape characteristics on only a few hundred training examples. This work is only a preliminary step toward the vision of personalizing annotation guidelines for NERS, which will focus on important areas of our future work such as health care, LERS et."}], "references": [{"title": "Discriminative Training Methods for Hidden Markov Models: Theory and Experiments with Perceptron Algorithms", "author": ["Michael Collins"], "venue": "In EMNLP\u201902,", "citeRegEx": "Collins.,? \\Q2002\\E", "shortCiteRegEx": "Collins.", "year": 2002}, {"title": "A Framework for Benchmarking Entity-Annotation Systems", "author": ["Paolo Ferragina", "Massimiliano Ciaramita"], "venue": "In WWW\u201913,", "citeRegEx": "Cornolti et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Cornolti et al\\.", "year": 2013}, {"title": "Entityclassifier. eu: Real-Time Classification of Entities in Text with Wikipedia", "author": ["Dojchinovski", "Kliegr2013] Milan Dojchinovski", "Tom\u00e1\u0161 Kliegr"], "venue": "In Machine Learning and Knowledge Discovery in Databases,", "citeRegEx": "Dojchinovski et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Dojchinovski et al\\.", "year": 2013}, {"title": "TAGME: On-the-fly Annotation of Short Text Fragments (by Wikipedia Entities)", "author": ["Ferragina", "Scaiella2010] Paolo Ferragina", "Ugo Scaiella"], "venue": "In CIKM\u201910,", "citeRegEx": "Ferragina et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Ferragina et al\\.", "year": 2010}, {"title": "Exploiting Context for Biomedical Entity Recognition: from Syntax to the Web", "author": ["Finkel et al.2004] Jenny Finkel", "Shipra Dingare", "Huy Nguyen", "Malvina Nissim", "Christopher Manning", "Gail Sinclair"], "venue": "In JNLPBA\u201904,", "citeRegEx": "Finkel et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Finkel et al\\.", "year": 2004}, {"title": "Learning Context Sensitive Languages with LSTM Trained with Kalman Filters", "author": ["Gers et al.2002] Felix Gers", "Juan Antonio Perez-Ortiz", "Douglas Eck", "J\u00fcrgen Schmidhuber"], "venue": null, "citeRegEx": "Gers et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Gers et al\\.", "year": 2002}, {"title": "Supervised Sequence Labelling with Recurrent Neural Networks, volume 385", "author": ["Alex Graves"], "venue": null, "citeRegEx": "Graves.,? \\Q2012\\E", "shortCiteRegEx": "Graves.", "year": 2012}, {"title": "Evaluating Entity Linking with Wikipedia", "author": ["Hachey et al.2013] Ben Hachey", "Will Radford", "Joel Nothman", "Matthew Honnibal", "James R. Curran"], "venue": "Artificial intelligence,", "citeRegEx": "Hachey et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Hachey et al\\.", "year": 2013}, {"title": "Long Short-Term Memory", "author": ["Hochreiter", "Schmidhuber1997] Sepp Hochreiter", "J\u00fcrgen Schmidhuber"], "venue": "Neural Computation,", "citeRegEx": "Hochreiter et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter et al\\.", "year": 1997}, {"title": "KORE: Keyphrase Overlap Relatedness for Entity Disambiguation", "author": ["Stephan Seufert", "Dat Ba Nguyen", "Martin Theobald", "Gerhard Weikum"], "venue": "In CIKM\u201912,", "citeRegEx": "Hoffart et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Hoffart et al\\.", "year": 2012}, {"title": "Learning Deep Structured Semantic Models for Web Search using Clickthrough Data", "author": ["Huang et al.2013] Po-Sen Huang", "Xiaodong He", "Jianfeng Gao", "Li Deng", "Alex Acero", "Larry Heck"], "venue": "In CIKM\u201913,", "citeRegEx": "Huang et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Huang et al\\.", "year": 2013}, {"title": "External Knowledge and Query Strategies in Active Learning: a Study in Clinical Information Extraction", "author": ["Laurianne Sitbon", "Guido Zuccon", "Anthony Nguyen"], "venue": "In CIKM\u201915,", "citeRegEx": "Kholghi et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kholghi et al\\.", "year": 2015}, {"title": "Introduction to the Bio-Entity Recognition Task at JNLPBA", "author": ["Kim et al.2004] Jin-Dong Kim", "Tomoko Ohta", "Yoshimasa Tsuruoka", "Yuka Tateisi", "Nigel Collier"], "venue": "In JNLPBA\u201904,", "citeRegEx": "Kim et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Kim et al\\.", "year": 2004}, {"title": "Fine-Grained Entity Recognition", "author": ["Ling", "Weld2012] Xiao Ling", "Daniel S. Weld"], "venue": null, "citeRegEx": "Ling et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Ling et al\\.", "year": 2012}, {"title": "Design Challenges for Entity Linking", "author": ["Ling et al.2015] Xiao Ling", "Sameer Singh", "Daniel S Weld"], "venue": null, "citeRegEx": "Ling et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ling et al\\.", "year": 2015}, {"title": "A Critical Review of Recurrent Neural Networks for Sequence Learning", "author": ["Lipton", "Berkowitz2015] Zachary C. Lipton", "John Berkowitz"], "venue": null, "citeRegEx": "Lipton et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lipton et al\\.", "year": 2015}, {"title": "The Stanford CoreNLP Natural Language Processing Toolkit", "author": ["Mihai Surdeanu", "John Bauer", "Jenny Finkel", "Steven J. Bethard", "David McClosky"], "venue": "In ACL System Demonstrations,", "citeRegEx": "Manning et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Manning et al\\.", "year": 2014}, {"title": "Early Results for Named Entity Recognition with Conditional Random Fields, Feature Induction and Web-enhanced Lexicons", "author": ["McCallum", "Li2003] Andrew McCallum", "Wei Li"], "venue": "CONLL", "citeRegEx": "McCallum et al\\.,? \\Q2003\\E", "shortCiteRegEx": "McCallum et al\\.", "year": 2003}, {"title": "DBpedia Spotlight: Shedding Light on the Web of Documents", "author": ["Max Jakob", "Andr\u00e9s Garcia-Silva", "Christian Bizer"], "venue": "I-Semantics", "citeRegEx": "Mendes et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Mendes et al\\.", "year": 2011}, {"title": "Efficient Estimation of Word Representations in Vector Space", "author": ["Kai Chen", "Greg Corrado", "Jeffrey Dean"], "venue": null, "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Entity Linking meets Word Sense Disambiguation: a Unified Approach", "author": ["Moro et al.2014] Andrea Moro", "Alessandro Raganato", "Roberto Navigli"], "venue": null, "citeRegEx": "Moro et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Moro et al\\.", "year": 2014}, {"title": "The GENIA Corpus: An Annotated Research Abstract Corpus in Molecular Biology Domain", "author": ["Ohta et al.2002] Tomoko Ohta", "Yuka Tateisi", "JinDong Kim"], "venue": "In International Conference on Human Language Technology Research", "citeRegEx": "Ohta et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Ohta et al\\.", "year": 2002}, {"title": "Analysing Recall Loss in Named Entity Slot Filling", "author": ["Pink et al.2014] Glen Pink", "Joel Nothman", "James R. Curran"], "venue": "In EMNLP\u201914,", "citeRegEx": "Pink et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Pink et al\\.", "year": 2014}, {"title": "Effective Named Entity Recognition for Idiosyncratic Web Collections", "author": ["Gianluca Demartini", "Philippe Cudr\u00e9-Mauroux"], "venue": "In WWW\u201914,", "citeRegEx": "Prokofyev et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Prokofyev et al\\.", "year": 2014}, {"title": "Text chunking using transformation-based learning", "author": ["Ramshaw", "Marcus1995] Lance A. Ramshaw", "Mitchell P. Marcus"], "venue": "In WVLC\u201995. ACL", "citeRegEx": "Ramshaw et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Ramshaw et al\\.", "year": 1995}, {"title": "The Distributional Hypothesis", "author": ["Magnus Sahlgren"], "venue": "Italian Journal of Linguistics,", "citeRegEx": "Sahlgren.,? \\Q2008\\E", "shortCiteRegEx": "Sahlgren.", "year": 2008}, {"title": "Biomedical Named Entity Recognition Using Conditional Random Fields and Rich Feature Sets", "author": ["Burr Settles"], "venue": "In JNLPBA\u201904,", "citeRegEx": "Settles.,? \\Q2004\\E", "shortCiteRegEx": "Settles.", "year": 2004}, {"title": "Entity Linking with a Knowledge Base: Issues, Techniques, and Solutions", "author": ["Shen et al.2015] Wei Shen", "Jianyong Wang", "Jiawei Han"], "venue": "IEEE Transactions on Knowledge and Data Engineering,", "citeRegEx": "Shen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Shen et al\\.", "year": 2015}, {"title": "Ensemble Learning for Named Entity Recognition", "author": ["Speck", "Ngomo2014] Ren\u00e9 Speck", "AxelCyrille Ngonga Ngomo"], "venue": "In ISWC\u201914,", "citeRegEx": "Speck et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Speck et al\\.", "year": 2014}, {"title": "Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition", "author": ["Tjong Kim Sang", "Fien De Meulder"], "venue": "In CoNLL\u201903,", "citeRegEx": "Sang et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Sang et al\\.", "year": 2003}, {"title": "GERBIL: General Entity Annotator Benchmarking Framework", "author": ["Roberto Navigli", "Francesco Piccinno", "Giuseppe Rizzo", "Harald Sack", "Ren\u00e9 Speck", "Rapha\u00ebl Troncy", "J\u00f6rg Waitelonis", "Lars Wesemann."], "venue": "WWW\u201915, pages 1133\u20131143,", "citeRegEx": "Navigli et al\\.,? 2015", "shortCiteRegEx": "Navigli et al\\.", "year": 2015}, {"title": "Learning with the Web: Spotting Named Entities on the Intersection of NERD and Machine Learning", "author": ["Giuseppe Rizzo", "Rapha\u00ebl Troncy"], "venue": "In #MSM\u201913,", "citeRegEx": "Erp et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Erp et al\\.", "year": 2013}, {"title": "Exploring Deep Knowledge Resources in Biomedical Name Recognition", "author": ["Zhou", "Su2004] GuoDong Zhou", "Jian Su"], "venue": "In JNLPBA\u201904,", "citeRegEx": "Zhou et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Zhou et al\\.", "year": 2004}], "referenceMentions": [{"referenceID": 7, "context": "In these scenarios, NER recall is critical, as candidates that are never generated can not be recovered later (Hachey et al., 2013).", "startOffset": 110, "endOffset": 131}, {"referenceID": 23, "context": "First, the language used in the documents is often idiosyncratic and cannot be effectively identified by standard natural language processing (NLP) tools (Prokofyev et al., 2014).", "startOffset": 154, "endOffset": 178}, {"referenceID": 14, "context": "Third, applications vary greatly and we cannot standardize annotation guidelines to meet all of their requirements (Ling et al., 2015).", "startOffset": 115, "endOffset": 134}, {"referenceID": 20, "context": "Pink et al. (2014) show that NER components can reduce the search space for slot filling tasks by 99.", "startOffset": 0, "endOffset": 19}, {"referenceID": 21, "context": "Consider the following example taken from the biomedical GENIA corpus (Ohta et al., 2002), with underlined named entity mentions:", "startOffset": 70, "endOffset": 89}, {"referenceID": 13, "context": "Ling et al. (2015) point out common errors of NER systems, which yield non-recognized mentions (false negatives), invalid detections (false positives), wrong boundaries (e.", "startOffset": 0, "endOffset": 19}, {"referenceID": 0, "context": "The standard approach to NER is the application of discriminative tagging (Collins, 2002) to the task of NER (McCallum and Li, 2003), often with linear chain Conditional Random Field (CRF), Hidden Markov (HMM) or Maximum Entropy Hidden Markov Models (MEMM).", "startOffset": 74, "endOffset": 89}, {"referenceID": 0, "context": "The standard approach to NER is the application of discriminative tagging (Collins, 2002) to the task of NER (McCallum and Li, 2003), often with linear chain Conditional Random Field (CRF), Hidden Markov (HMM) or Maximum Entropy Hidden Markov Models (MEMM). Later, Bengio et al. (2003) used continuous-space language models, where type-to-vector word mappings can be learned using backpropagation.", "startOffset": 75, "endOffset": 286}, {"referenceID": 0, "context": "The standard approach to NER is the application of discriminative tagging (Collins, 2002) to the task of NER (McCallum and Li, 2003), often with linear chain Conditional Random Field (CRF), Hidden Markov (HMM) or Maximum Entropy Hidden Markov Models (MEMM). Later, Bengio et al. (2003) used continuous-space language models, where type-to-vector word mappings can be learned using backpropagation. Mikolov et al. (2013) achieved a more effective vector representation using the skip-gram model.", "startOffset": 75, "endOffset": 420}, {"referenceID": 27, "context": "Named entity linking is the task to match textual mentions of named entities to a knowledge base (Shen et al., 2015).", "startOffset": 97, "endOffset": 116}, {"referenceID": 7, "context": "As a result, the recall from the underlying NER system constitutes an upper bound for entity linking accuracy (Hachey et al., 2013).", "startOffset": 110, "endOffset": 131}, {"referenceID": 7, "context": "As a result, the recall from the underlying NER system constitutes an upper bound for entity linking accuracy (Hachey et al., 2013). Moreover, Pink et al. (2014) show that \u201cstate-of-the-art systems are substantially limited by low recall\u201d and don\u2019t perform well especially on idiosyncratic data while Prokofyev et al.", "startOffset": 111, "endOffset": 162}, {"referenceID": 7, "context": "As a result, the recall from the underlying NER system constitutes an upper bound for entity linking accuracy (Hachey et al., 2013). Moreover, Pink et al. (2014) show that \u201cstate-of-the-art systems are substantially limited by low recall\u201d and don\u2019t perform well especially on idiosyncratic data while Prokofyev et al. (2014) highlight that terms with high novelty or high specificity cannot efficiently be linked by current systems.", "startOffset": 111, "endOffset": 325}, {"referenceID": 20, "context": "We distinguish between three broad categories for generating candidate entities: Babelfy (Moro et al., 2014), Entityclassifier.", "startOffset": 89, "endOffset": 108}, {"referenceID": 18, "context": "eu (Dojchinovski and Kliegr, 2013), DBpedia Spotlight (Mendes et al., 2011) or TagMe2 (Ferragina and Scaiella, 2010) spot noun chunks and filter them with dictionaries, often derived from Wikipedia.", "startOffset": 54, "endOffset": 75}, {"referenceID": 16, "context": "Stanford NER (Manning et al., 2014) or LingPipe1 utilize discriminative tagging approaches.", "startOffset": 13, "endOffset": 35}, {"referenceID": 12, "context": "It is trained on the GENIA-based BioNLP/NLPBA 2004 data set (Kim et al., 2004) that includes named entity recognition for biomedical text.", "startOffset": 60, "endOffset": 78}, {"referenceID": 4, "context": "The system of Finkel et al. (2004) uses a MEMM.", "startOffset": 14, "endOffset": 35}, {"referenceID": 4, "context": "The system of Finkel et al. (2004) uses a MEMM. Settles (2004) use CRF classifiers with syntactical features and synset dictionaries.", "startOffset": 14, "endOffset": 63}, {"referenceID": 19, "context": "For example, the word2vec model of Mikolov et al. (2013) generalizes insufficiently for rare words in idiosyncratic domains or for misspelled words, since for these words no vector representation is learned at training time.", "startOffset": 35, "endOffset": 57}, {"referenceID": 10, "context": "We use letter-trigram word hashing as introduced by Huang et al. (2013). This technique goes beyond words and generates word vectors as a composite of discriminative three-letter \u201csyllables\u201d, that might also include misspellings.", "startOffset": 52, "endOffset": 72}, {"referenceID": 5, "context": "We apply the computational model of recurrent neural networks, in particular long short-term memory networks (LSTMs) (Hochreiter and Schmidhuber, 1997; Gers et al., 2002) to the problem of sequence labeling.", "startOffset": 117, "endOffset": 170}, {"referenceID": 6, "context": "With their ability to memorize and forget over time, LSTMs have proven to generalize context-sensitive sequential data well (Graves, 2012; Lipton and Berkowitz, 2015).", "startOffset": 124, "endOffset": 166}, {"referenceID": 16, "context": "For preprocessing (sentence and word tokenization), we use Stanford CoreNLP5 (Manning et al., 2014).", "startOffset": 77, "endOffset": 99}, {"referenceID": 21, "context": "The GENIA Corpus (Ohta et al., 2002) contains biomedical abstracts from the PubMed database.", "startOffset": 17, "endOffset": 36}, {"referenceID": 12, "context": "CoNLL2003 (Kim et al., 2004) is a standard NER dataset based on the Reuters RCV1 news corpus.", "startOffset": 10, "endOffset": 28}, {"referenceID": 9, "context": "Additionally, we test on the complete KORE50 (Hoffart et al., 2012), ACE2004 (Mitchell et al.", "startOffset": 45, "endOffset": 67}, {"referenceID": 1, "context": "We measure the overall performance of mention annotation using the evaluation measures defined by Cornolti et al. (2013), which are also used by Ling et al.", "startOffset": 98, "endOffset": 121}, {"referenceID": 1, "context": "We measure the overall performance of mention annotation using the evaluation measures defined by Cornolti et al. (2013), which are also used by Ling et al. (2015). Let D be a set of documents with gold standard mention annotations G = {Gd | d \u2208 D} with a total of N = |G| examples.", "startOffset": 98, "endOffset": 164}, {"referenceID": 4, "context": "6 Finkel et al. (2004) MEMM 71.", "startOffset": 2, "endOffset": 23}, {"referenceID": 4, "context": "6 Finkel et al. (2004) MEMM 71.6 68.6 70.1 Settles et al. (2004) CRF 70.", "startOffset": 2, "endOffset": 65}, {"referenceID": 12, "context": "Table 3 shows the results of biomedical entity recognition compared to the participants of the JNLPBA 2004 bio-entity recognition task (Kim et al., 2004).", "startOffset": 135, "endOffset": 153}, {"referenceID": 25, "context": "These groups encode strong syntagmatic word relations (Sahlgren, 2008) that can be leveraged to resolve word sense and homonyms from sentence context.", "startOffset": 54, "endOffset": 70}, {"referenceID": 25, "context": "Orthogonal to the previous problem, different words in a paradigmatic relation (Sahlgren, 2008) can occur in the same context (e.", "startOffset": 79, "endOffset": 95}, {"referenceID": 11, "context": "The detection of specific types can be realized by training multiple independent models on a selection of labels per type and nesting the resulting annotations using a longest-span semantic type heuristic (Kholghi et al., 2015).", "startOffset": 205, "endOffset": 227}, {"referenceID": 22, "context": "Worse, they often suffer from poor recall (Pink et al., 2014).", "startOffset": 42, "endOffset": 61}, {"referenceID": 14, "context": "This work is only a preliminary step towards the vision of personalizing annotation guidelines for NER (Ling et al., 2015).", "startOffset": 103, "endOffset": 122}], "year": 2016, "abstractText": "Named entity recognition often fails in idiosyncratic domains. That causes a problem for depending tasks, such as entity linking and relation extraction. We propose a generic and robust approach for high-recall named entity recognition. Our approach is easy to train and offers strong generalization over diverse domainspecific language, such as news documents (e.g. Reuters) or biomedical text (e.g. Medline). Our approach is based on deep contextual sequence learning and utilizes stacked bidirectional LSTM networks. Our model is trained with only few hundred labeled sentences and does not rely on further external knowledge. We report from our results F1 scores in the range of 84\u201394% on standard datasets.", "creator": "LaTeX with hyperref package"}}}