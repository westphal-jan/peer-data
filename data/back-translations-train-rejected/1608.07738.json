{"id": "1608.07738", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Aug-2016", "title": "Testing APSyn against Vector Cosine on Similarity Estimation", "abstract": "In Distributional Semantic Models (DSMs), Vector Cosine is widely used to estimate similarity between word vectors, although this measure was noticed to suffer from several shortcomings. The recent literature has proposed other methods which attempt to mitigate such biases. In this paper, we intend to investigate APSyn, a measure that computes the extent of the intersection between the most associated contexts of two target words, weighting it by context relevance. We evaluated this metric in a similarity estimation task on several popular test sets, and our results show that APSyn is in fact highly competitive, even with respect to the results reported in the literature for word embeddings. On top of it, APSyn addresses some of the weaknesses of Vector Cosine, performing well also on genuine similarity estimation.", "histories": [["v1", "Sat, 27 Aug 2016 19:57:55 GMT  (52kb,D)", "https://arxiv.org/abs/1608.07738v1", "8 pages, 1 figure, 4 tables, PACLIC, cosine, vectors, DSMs"], ["v2", "Wed, 5 Oct 2016 10:46:25 GMT  (52kb,D)", "http://arxiv.org/abs/1608.07738v2", "8 pages, 1 figure, 4 tables, PACLIC, cosine, vectors, DSMs"]], "COMMENTS": "8 pages, 1 figure, 4 tables, PACLIC, cosine, vectors, DSMs", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["enrico santus", "emmanuele chersoni", "alessandro lenci", "chu-ren huang", "philippe blache"], "accepted": false, "id": "1608.07738"}, "pdf": {"name": "1608.07738.pdf", "metadata": {"source": "CRF", "title": "Testing APSyn against Vector Cosine on Similarity Estimation", "authors": ["Enrico Santus", "Emmanuele Chersoni", "Alessandro Lenci", "Chu-Ren Huang", "Philippe Blache"], "emails": ["emmanuelechersoni}@gmail.com", "alessandro.lenci@unipi.it", "churen.huang@polyu.edu.hk", "blache@lpl-aix.fr"], "sections": [{"heading": "1 Introduction", "text": "In fact, most people are able to understand themselves and understand what they are doing. (...) Most people in the world do not know what they are doing. (...) They do not know what they are doing. (...) They do not know what they are doing. (...) They do not know what they are doing. (...) They do not know what they are doing. (...) They do not know what they are doing. (...) They do not know what they are doing. (...) They do not know what they are doing. (...) They do not know what they are doing. (...) They do not know what they are doing. (...) They do. (...) They do. (...). (). (). (). (). (). (). (). (). (). (). (). (). (). (). (). (). (). (). (). (). () Most people. ().). (). (). ().). (). ().). ().). ().). (). ().). ().). ().).). (). ().). (). ().). ().). (). ().). ()."}, {"heading": "2 Background", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 DSMs, Measures of Association and Dimensionality Reduction", "text": "Based on large prefabricated corpora, a matrix M (m \u00b7 n) is constructed in which each line is a vector representing a target word in a vocabulary of size m, and each column is one of the n potential contexts (Turney and Pantel, 2010; Levy et al., 2015). The vector dimensions are counters that record how often the contexts with the target words occur simultaneously. As the raw frequency is highly distorted, most DSMs have taken more sophisticated association measures, such as Positive PMI (PPMI; Church and Hanks, 1990; Bullinaria and Levy et al., 2015) and Local Mutual Information (LMI; Evert, 2005). PPMI compares the observed common probability of w and c entering with their probability of entering."}, {"heading": "2.2 Similarity Measures", "text": "Vector Cosine, by far the most common distributional similarity metric (Turney and Pantel, 2010; Landauer and Dumais, 1997; Jarmasz and Szpakowicz, 2004; Mikolov et al., 2013; Levy et al., 2015), sees the normalized correlation between the dimensions of two word vectors, w1 and w2, giving a value between -1 and 1. It is described by the following equation: \"It is a value of 1 to 2.\" (f1i \u00d7 f2i \u221a ni = 1 f1i \"),\" it is a value of 1 to 2. \"(3), where fix is the i-th dimension in the vector x. Despite its extensive use, Vector Cosine has recently been criticized for its hyper sensitivity to functions with high values and for the inability to identify the actual function intersection (Li and Han, 2013)."}, {"heading": "2.3 Datasets", "text": "For our evaluation, we used three widely used datasets: WordSim-353 (Finkelstein et al., 2001), MEN (Bruni et al., 2014), SimLex-999 (Hill et al., 2015). These datasets have a different history, but all of them consist of pairs of words with an associated score that should represent either word associations or word similarities. WordSim-353 (Finkelstein et al., 2001) was proposed as a word similarity dataset, of which 353 pairs with notes ranging from 0 to 10. However, Hill et al. (2015) claimed that the instructions given to the commentators were ambiguous in terms of similarity and association, so that subjects are assigned high similarity values related only by frequent associations (e.g. coffee and cup; film and theater)."}, {"heading": "2.4 State of the Art Vector Space Models", "text": "To compare our results with state-of-the-art DSMs, we report on the results of Vector Cosines, which were calculated on the basis of the neural language models (NLM) used by Hill et al. (2015), which used the code used by the original authors (or directly the embeddings). As we trained our models on almost the same corpora used by Hill et al., the results are completely comparable.The three models with which we compare our results are: i) the Collobert and Weston Convolutionary Neural Network (2008), which was trained on 852 million words of Wikipedia; ii) the neural network of Huang et al. (2012), which was trained on 990 million words of Wikipedia; and iii) the word2vec of Mikolov et al. (2013), which was trained on 1000 million words of Wikipedia and on the RCV Vol. 1 Corpus (Lewis et al., 2004)."}, {"heading": "3 Experiments", "text": "In this section, we describe our experiments, starting with the training corpora (Section 3.1), through the implementation of 28 DSMs (Section 3.2), the application and evaluation of measures (Section 3.3), through to performance analysis (Section 3.4) and the scalability test (Section 3.5)."}, {"heading": "3.1 Corpora and Preprocessing", "text": "For our experiments we used two different corpora: the RCV Vol. 1 (Lewis et al., 2004) and the Wikipedia corpus (Baroni et al., 2009) with 150 and 820 million words respectively. RCV Vol. 1 and Wikipedia were automatically marked with the POS tagger described in Dell'Orletta (2009) and the TreeTagger (Schmid, 1994)."}, {"heading": "3.2 DSMs", "text": "For our experiments, we implemented twenty-eight DSMs, but for space reasons, only sixteen of them are listed in the tables, all containing the pos-marked target words used in the three datasets (i.e. MEN, WordSim-353, and SimLex-999), and the pos-marked contexts with a frequency of over 100 in the two corporas. As contexts, we considered the substantive words (i.e. nouns, verbs, and adjectives) within a window of 2, 3, and 5, although the latter was abandoned due to its poor performance. As for SVD factoring, we found that the best results were always obtained when the number of latent dimensions was between 300 and 500. We report here only the values for k = 300, since 300 is one of the most common choices for the dimensionality of SVD-reduced spaces and it is always close to an optimal value for the parameter. Fourteen of twenty-eight models of twenty-eight were used for the Creliality of one of the SVD spaces, and for the other dimensions of one of the V1 spaces were developed during the V1 of the SVD."}, {"heading": "3.3 Measuring Word Similarity and Relatedness", "text": "Considering the 28 DSMs, we have measured the vector cosine and APSyn between the words in the test pairs for each dataset. Spearman correlation between our results and the gold standard was then calculated for each model and is presented in Table 1 and Table 2. Specifically, Table 1 describes the performance on SimLex-999, WordSim-353 and MEN for the measurements applied on the models RCV Vol. 1. Table 2 describes the performance of the measurements on the three datasets for the Wikipedia models instead. At the same time, Table 3 and Table 4 describe the performance of the measurements on the models RCV Vol. 1 and Wikipedia tested on the subsets of WordSim-353 extracted by Agirre et al. (2009)."}, {"heading": "3.4 Performance Analysis", "text": "In fact, most of them are able to trump themselves, and they are able to trump themselves. (...) Most of them are able to trump themselves. (...) Most of them are not able to trump themselves. (...) Most of them are not able to trump themselves. (...) Most of them are not able to trump themselves. (...) Most of them are able to trump themselves. (...) Most of them are not able to trump themselves. (...) Most of them are not able to trump themselves. (...) Most of them are able to trump themselves. (...) Most of them are able to trump themselves. (...) Most of them are able to trump themselves."}, {"heading": "3.5 Scalability", "text": "To evaluate the scalability of APSyn, we conducted a pilot test on WordSim-353 and MEN using the same corpus used by Baroni et al. (2014) and consisting of about 2.8B words (i.e. about three times Wikipedia and nearly 20 times RCV1). The best values were obtained with APSyn, N = 1000, for a 2-window PPMI weighted DSM. In such a setting, we get a Spearman correlation of 0.72 for WordSim and 0.77 for MEN. These results are much higher than those of Baroni et al. (2014) for the numbered models (i.e. 0.62 for WordSim and 0.72 for MEN) and slightly lower than those for the predictive models (i.e. 0.75 for WordSim and 0.80 for MEN)."}, {"heading": "4 Conclusions", "text": "In this paper, we presented the first systematic evaluation of APSyn by comparing it to Vector Cosine in the task of identifying word similarities. We developed twenty-eight number-based DSMs, each of which implements different hyperparameters. PPMI proved to be the most efficient association variable: it works particularly well with Vector Cosine when combined with SVD, and it increases APSyn. APSyn, despite its conceptual simplicity, showed extremely promising results. It outperforms Vector Cosine in almost all contexts except when used on a PPMI-weighted SVD-reduced DSM. Even in this case, its performance is very competitive. Interestingly, our best models achieve results comparable - or even better - to those used by Hill et al. (2015) for the state of word similarities."}, {"heading": "Acknowledgments", "text": "This work is partially supported by the HK PhD Fellowship Scheme under PF12-13656. Emmanuele Chersoni's research is funded by a scholarship from the University Foundation A * MIDEX. Thanks to Davis Ozols for the support with R."}], "references": [{"title": "The wacky wide web: a", "author": ["Eros Zanchetta"], "venue": null, "citeRegEx": "Zanchetta.,? \\Q2009\\E", "shortCiteRegEx": "Zanchetta.", "year": 2009}, {"title": "Indexing by latent semantic analysis", "author": ["Scott Deerwester", "Susan T Dumais", "George W Furnas", "Thomas K Landauer", "Richard Harshman."], "venue": "Journal of the American society for information science, 41(6):391.", "citeRegEx": "Deerwester et al\\.,? 1990", "shortCiteRegEx": "Deerwester et al\\.", "year": 1990}, {"title": "Ensemble system for part-ofspeech tagging", "author": ["Felice DellOrletta."], "venue": "Proceedings of EVALITA, 9.", "citeRegEx": "DellOrletta.,? 2009", "shortCiteRegEx": "DellOrletta.", "year": 2009}, {"title": "Encyclopedia of distances", "author": ["Michel Marie Deza", "Elena Deza."], "venue": "Springer.", "citeRegEx": "Deza and Deza.,? 2009", "shortCiteRegEx": "Deza and Deza.", "year": 2009}, {"title": "Improving zero-shot learning by mitigating the hubness problem", "author": ["Georgiana Dinu", "Angeliki Lazaridou", "Marco Baroni"], "venue": "arXiv preprint arXiv:1603.09054.", "citeRegEx": "Dinu et al\\.,? 2014", "shortCiteRegEx": "Dinu et al\\.", "year": 2014}, {"title": "The statistics of word cooccurrences: word pairs and collocations", "author": ["Stefan Evert"], "venue": null, "citeRegEx": "Evert.,? \\Q2005\\E", "shortCiteRegEx": "Evert.", "year": 2005}, {"title": "Problems With Evaluation of Word Embeddings Using Word Similarity Tasks", "author": ["Manaal Faruqui", "Yulia Tsvetkov", "Pushpendre Ratogi", "Chris Dyer."], "venue": "arXiv preprint arXiv:1301.3781..", "citeRegEx": "Faruqui et al\\.,? 2016", "shortCiteRegEx": "Faruqui et al\\.", "year": 2016}, {"title": "WordNet", "author": ["Christiane Fellbaum."], "venue": "Wiley Online Library.", "citeRegEx": "Fellbaum.,? 1998", "shortCiteRegEx": "Fellbaum.", "year": 1998}, {"title": "Placing search in context: The concept revisited", "author": ["Lev Finkelstein", "Evgeniy Gabrilovich", "Yossi Matias", "Ehud Rivlin", "Zach Solan", "Gadi Wolfman", "Eytan Ruppin."], "venue": "Proceedings of the 10th international conference on World Wide Web, pages 406\u2013414. ACM.", "citeRegEx": "Finkelstein et al\\.,? 2001", "shortCiteRegEx": "Finkelstein et al\\.", "year": 2001}, {"title": "Cognitive economy and the role of representation in on-line learning", "author": ["David Finton."], "venue": "Doctoral dissertation. University of Wisconsin-Madison.", "citeRegEx": "Finton.,? 2002", "shortCiteRegEx": "Finton.", "year": 2002}, {"title": "Papers in linguistics, 19341951", "author": ["John Rupert Firth."], "venue": "Oxford University Press.", "citeRegEx": "Firth.,? 1957", "shortCiteRegEx": "Firth.", "year": 1957}, {"title": "Distributional structure", "author": ["Zellig S Harris."], "venue": "Word, 10(2-3):146\u2013162.", "citeRegEx": "Harris.,? 1954", "shortCiteRegEx": "Harris.", "year": 1954}, {"title": "Simlex-999: Evaluating semantic models with (genuine) similarity estimation", "author": ["Felix Hill", "Roi Reichart", "Anna Korhonen."], "venue": "Computational Linguistics.", "citeRegEx": "Hill et al\\.,? 2015", "shortCiteRegEx": "Hill et al\\.", "year": 2015}, {"title": "Improving word representations via global context and multiple word prototypes", "author": ["Eric H Huang", "Richard Socher", "Christopher D Manning", "Andrew Y Ng."], "venue": "Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-", "citeRegEx": "Huang et al\\.,? 2012", "shortCiteRegEx": "Huang et al\\.", "year": 2012}, {"title": "Rogets thesaurus and semantic similarity1", "author": ["Mario Jarmasz", "Stan Szpakowicz."], "venue": "Recent Advances in Natural Language Processing III: Selected Papers from RANLP, 2003:111.", "citeRegEx": "Jarmasz and Szpakowicz.,? 2004", "shortCiteRegEx": "Jarmasz and Szpakowicz.", "year": 2004}, {"title": "A systematic study of semantic vector space model parameters", "author": ["Douwe Kiela", "Stephen Clark."], "venue": "Proceedings of the 2nd Workshop on Continuous Vector Space Models and their Compositionality (CVSC) at EACL, pages 21\u201330.", "citeRegEx": "Kiela and Clark.,? 2014", "shortCiteRegEx": "Kiela and Clark.", "year": 2014}, {"title": "A solution to plato\u2019s problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge", "author": ["Thomas K Landauer", "Susan T Dumais."], "venue": "Psychological review, 104(2):211.", "citeRegEx": "Landauer and Dumais.,? 1997", "shortCiteRegEx": "Landauer and Dumais.", "year": 1997}, {"title": "An introduction to latent semantic analysis", "author": ["Thomas K Landauer", "Peter W Foltz", "Darrell Laham."], "venue": "Discourse processes, 25(2-3):259\u2013284.", "citeRegEx": "Landauer et al\\.,? 1998", "shortCiteRegEx": "Landauer et al\\.", "year": 1998}, {"title": "Improving distributional similarity with lessons learned from word embeddings", "author": ["Omer Levy", "Yoav Goldberg", "Ido Dagan."], "venue": "Transactions of the Association for Computational Linguistics, 3:211\u2013225.", "citeRegEx": "Levy et al\\.,? 2015", "shortCiteRegEx": "Levy et al\\.", "year": 2015}, {"title": "Rcv1: A new benchmark collection for text categorization research", "author": ["David D Lewis", "Yiming Yang", "Tony G Rose", "Fan Li."], "venue": "The Journal of Machine Learning Research, 5:361\u2013397.", "citeRegEx": "Lewis et al\\.,? 2004", "shortCiteRegEx": "Lewis et al\\.", "year": 2004}, {"title": "Distance weighted cosine similarity measure for text classification", "author": ["Baoli Li", "Liping Han"], "venue": "Intelligent Data Engineering and Automated Learning -IDEAL", "citeRegEx": "Li and Han.,? \\Q2013\\E", "shortCiteRegEx": "Li and Han.", "year": 2013}, {"title": "Efficient estimation of word representations in vector space", "author": ["Tomas Mikolov", "Kai Chen", "Greg Corrado", "Jeffrey Dean."], "venue": "arXiv preprint arXiv:1301.3781.", "citeRegEx": "Mikolov et al\\.,? 2013", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "On the existence of obstinate results in vector space models", "author": ["Milos Radovanovic", "Alexandros Nanopoulos", "Mirjana Ivanovic."], "venue": "Proceedings of SIGIR:186-193.", "citeRegEx": "Radovanovic et al\\.,? 2010", "shortCiteRegEx": "Radovanovic et al\\.", "year": 2010}, {"title": "An introduction to random indexing", "author": ["Magnus Sahlgren."], "venue": "Methods and applications of semantic indexing workshop at the 7th international conference on terminology and knowledge engineering, TKE, volume 5.", "citeRegEx": "Sahlgren.,? 2005", "shortCiteRegEx": "Sahlgren.", "year": 2005}, {"title": "The distributional hypothesis", "author": ["Magnus Sahlgren."], "venue": "Italian Journal of Linguistics, 20(1):33\u201354.", "citeRegEx": "Sahlgren.,? 2008", "shortCiteRegEx": "Sahlgren.", "year": 2008}, {"title": "Unsupervised Measure of Word Similarity: How to Outperform Co-Occurrence and Vector Cosine in VSMs", "author": ["Enrico Santus", "Tin-Shing Chiu", "Qin Lu", "Alessandro Lenci", "Chu-ren Huang."], "venue": "arXiv preprint arXiv:1603.09054.", "citeRegEx": "Santus et al\\.,? 2016", "shortCiteRegEx": "Santus et al\\.", "year": 2016}, {"title": "What a Nerd! Beating Students and Vector Cosine in the ESL and TOEFL Datasets", "author": ["Enrico Santus", "Tin-Shing Chiu", "Qin Lu", "Alessandro Lenci", "Chu-ren Huang."], "venue": "Proceedings of LREC.", "citeRegEx": "Santus et al\\.,? 2016", "shortCiteRegEx": "Santus et al\\.", "year": 2016}, {"title": "Probabilistic part-of-speech tagging using decision trees", "author": ["Helmut Schmid."], "venue": "Proceedings of the international conference on new methods in language processing, volume 12, pages 44\u201349. Citeseer.", "citeRegEx": "Schmid.,? 1994", "shortCiteRegEx": "Schmid.", "year": 1994}, {"title": "Evaluation methods for unsupervised word embeddings", "author": ["Tobias Schnabel", "Igor Labutov", "David Mimmo", "Thorsten Joachims."], "venue": "Proceedings of EMNLP.", "citeRegEx": "Schnabel et al\\.,? 2015", "shortCiteRegEx": "Schnabel et al\\.", "year": 2015}, {"title": "Structure and process in semantic memory: A featural model for semantic decisions", "author": ["Edward Smith", "Edward Shoben", "Lance Rips."], "venue": "Psychological Review, 81(3).", "citeRegEx": "Smith et al\\.,? 1974", "shortCiteRegEx": "Smith et al\\.", "year": 1974}, {"title": "Word representations: a simple and general method for semi-supervised learning", "author": ["Joseph Turian", "Lev Ratinov", "Yoshua Bengio."], "venue": "Proceedings of the 48th annual meeting of the association for computational linguistics, pages 384\u2013394. Association for Computa-", "citeRegEx": "Turian et al\\.,? 2010", "shortCiteRegEx": "Turian et al\\.", "year": 2010}, {"title": "From frequency to meaning: Vector space models of semantics", "author": ["Peter D Turney", "Patrick Pantel."], "venue": "Journal of artificial intelligence research, 37(1):141\u2013 188.", "citeRegEx": "Turney and Pantel.,? 2010", "shortCiteRegEx": "Turney and Pantel.", "year": 2010}, {"title": "Mining the web for synonyms: Pmi-ir versus lsa on toefl", "author": ["Peter D Turney"], "venue": null, "citeRegEx": "Turney.,? \\Q2001\\E", "shortCiteRegEx": "Turney.", "year": 2001}], "referenceMentions": [{"referenceID": 11, "context": "Most of the current approaches to word similarity estimation rely on some version of the Distributional Hypothesis (DH), which claims that words occurring in the same contexts tend to have similar meanings (Harris, 1954; Firth, 1957; Sahlgren, 2008).", "startOffset": 206, "endOffset": 249}, {"referenceID": 10, "context": "Most of the current approaches to word similarity estimation rely on some version of the Distributional Hypothesis (DH), which claims that words occurring in the same contexts tend to have similar meanings (Harris, 1954; Firth, 1957; Sahlgren, 2008).", "startOffset": 206, "endOffset": 249}, {"referenceID": 24, "context": "Most of the current approaches to word similarity estimation rely on some version of the Distributional Hypothesis (DH), which claims that words occurring in the same contexts tend to have similar meanings (Harris, 1954; Firth, 1957; Sahlgren, 2008).", "startOffset": 206, "endOffset": 249}, {"referenceID": 31, "context": "tween targets and their linguistic contexts (Turney and Pantel, 2010).", "startOffset": 44, "endOffset": 69}, {"referenceID": 18, "context": "or its variants (Church and Hanks, 1990; Bullinaria and Levy, 2012; Levy et al., 2015), have been adopted to normalize these values.", "startOffset": 16, "endOffset": 86}, {"referenceID": 16, "context": "Also, these models have exploited the power of dimensionality reduction techniques, such as Singular Value Decomposition (SVD; Landauer and Dumais, 1997) and", "startOffset": 121, "endOffset": 153}, {"referenceID": 23, "context": "Random Indexing (Sahlgren, 2005).", "startOffset": 16, "endOffset": 32}, {"referenceID": 30, "context": "These first-generation models are currently referred to as count-based, as distinguished from the contextpredicting ones, which have been recently proposed in the literature (Bengio et al., 2006; Collobert and Weston, 2008; Turian et al., 2010; Huang et al., 2012; Mikolov et al., 2013).", "startOffset": 174, "endOffset": 286}, {"referenceID": 13, "context": "These first-generation models are currently referred to as count-based, as distinguished from the contextpredicting ones, which have been recently proposed in the literature (Bengio et al., 2006; Collobert and Weston, 2008; Turian et al., 2010; Huang et al., 2012; Mikolov et al., 2013).", "startOffset": 174, "endOffset": 286}, {"referenceID": 21, "context": "These first-generation models are currently referred to as count-based, as distinguished from the contextpredicting ones, which have been recently proposed in the literature (Bengio et al., 2006; Collobert and Weston, 2008; Turian et al., 2010; Huang et al., 2012; Mikolov et al., 2013).", "startOffset": 174, "endOffset": 286}, {"referenceID": 20, "context": "(Li and Han, 2013; Faruqui et al., 2016), such as a bias towards features with higher values and the inability of considering how many features are actually shared by the vectors.", "startOffset": 0, "endOffset": 40}, {"referenceID": 6, "context": "(Li and Han, 2013; Faruqui et al., 2016), such as a bias towards features with higher values and the inability of considering how many features are actually shared by the vectors.", "startOffset": 0, "endOffset": 40}, {"referenceID": 3, "context": "Even though other measures have been proposed in the literature (Deza and Deza, 2009), Vector Cosine is", "startOffset": 64, "endOffset": 85}, {"referenceID": 31, "context": "still by far the most popular one (Turney and Pantel, 2010).", "startOffset": 34, "endOffset": 59}, {"referenceID": 25, "context": "However, in a recent paper of Santus et al. (2016b), the authors have claimed that Vector Cosine is outperformed by APSyn (Average Precision for Synonymy), a metric based on the extent of the intersection between the most salient contexts of two target words.", "startOffset": 30, "endOffset": 52}, {"referenceID": 8, "context": "uation of APSyn, testing it on the most popular test sets for similarity estimation - namely WordSim-353 (Finkelstein et al., 2001), MEN (Bruni et al.", "startOffset": 105, "endOffset": 131}, {"referenceID": 12, "context": ", 2014) and SimLex-999 (Hill et al., 2015).", "startOffset": 23, "endOffset": 42}, {"referenceID": 12, "context": "The results are also discussed in relation to the state-of-the-art DSMs, as reported in Hill et al. (2015). In such comparison,", "startOffset": 88, "endOffset": 107}, {"referenceID": 32, "context": "Finally, considering the debate about the ability of DSMs to calculate genuine similarity as opposed to word relatedness (Turney, 2001; Agirre et al., 2009; Hill et al., 2015), we test the ability of the models to quantify genuine semantic similarity.", "startOffset": 121, "endOffset": 175}, {"referenceID": 12, "context": "Finally, considering the debate about the ability of DSMs to calculate genuine similarity as opposed to word relatedness (Turney, 2001; Agirre et al., 2009; Hill et al., 2015), we test the ability of the models to quantify genuine semantic similarity.", "startOffset": 121, "endOffset": 175}, {"referenceID": 31, "context": "Starting from large preprocessed corpora, a matrix M(m\u00d7n) is built, in which each row is a vector representing a target word in a vocabulary of size m, and each column is one of the n potential contexts (Turney and Pantel, 2010; Levy et al., 2015).", "startOffset": 203, "endOffset": 247}, {"referenceID": 18, "context": "Starting from large preprocessed corpora, a matrix M(m\u00d7n) is built, in which each row is a vector representing a target word in a vocabulary of size m, and each column is one of the n potential contexts (Turney and Pantel, 2010; Levy et al., 2015).", "startOffset": 203, "endOffset": 247}, {"referenceID": 5, "context": "2015) and Local Mutual Information (LMI; Evert, 2005).", "startOffset": 35, "endOffset": 53}, {"referenceID": 1, "context": "Since target words may occur in hundreds of thousands contexts, most of which are not informative, methods for dimensionality reduction have been investigated, such as truncated SVD (Deerwester et al., 1990; Landauer and Dumais, 1997; Turney and Pantel, 2010; Levy et al., 2015).", "startOffset": 182, "endOffset": 278}, {"referenceID": 16, "context": "Since target words may occur in hundreds of thousands contexts, most of which are not informative, methods for dimensionality reduction have been investigated, such as truncated SVD (Deerwester et al., 1990; Landauer and Dumais, 1997; Turney and Pantel, 2010; Levy et al., 2015).", "startOffset": 182, "endOffset": 278}, {"referenceID": 31, "context": "Since target words may occur in hundreds of thousands contexts, most of which are not informative, methods for dimensionality reduction have been investigated, such as truncated SVD (Deerwester et al., 1990; Landauer and Dumais, 1997; Turney and Pantel, 2010; Levy et al., 2015).", "startOffset": 182, "endOffset": 278}, {"referenceID": 18, "context": "Since target words may occur in hundreds of thousands contexts, most of which are not informative, methods for dimensionality reduction have been investigated, such as truncated SVD (Deerwester et al., 1990; Landauer and Dumais, 1997; Turney and Pantel, 2010; Levy et al., 2015).", "startOffset": 182, "endOffset": 278}, {"referenceID": 18, "context": "SVD has been regarded as a method for noise reduction and for the discovery of latent dimensions of meaning, and it has been shown to improve similarity measurements when combined with PPMI (Bullinaria and Levy, 2012; Levy et al., 2015).", "startOffset": 190, "endOffset": 236}, {"referenceID": 29, "context": "with the results of behavioural studies, which supported feature saliency (Smith et al., 1974).", "startOffset": 74, "endOffset": 94}, {"referenceID": 31, "context": "Vector Cosine, by far the most common distributional similarity metric (Turney and Pantel, 2010; Landauer and Dumais, 1997; Jarmasz and Szpakowicz, 2004; Mikolov et al., 2013; Levy et al., 2015), looks at the normalized correlation between the di-", "startOffset": 71, "endOffset": 194}, {"referenceID": 16, "context": "Vector Cosine, by far the most common distributional similarity metric (Turney and Pantel, 2010; Landauer and Dumais, 1997; Jarmasz and Szpakowicz, 2004; Mikolov et al., 2013; Levy et al., 2015), looks at the normalized correlation between the di-", "startOffset": 71, "endOffset": 194}, {"referenceID": 14, "context": "Vector Cosine, by far the most common distributional similarity metric (Turney and Pantel, 2010; Landauer and Dumais, 1997; Jarmasz and Szpakowicz, 2004; Mikolov et al., 2013; Levy et al., 2015), looks at the normalized correlation between the di-", "startOffset": 71, "endOffset": 194}, {"referenceID": 21, "context": "Vector Cosine, by far the most common distributional similarity metric (Turney and Pantel, 2010; Landauer and Dumais, 1997; Jarmasz and Szpakowicz, 2004; Mikolov et al., 2013; Levy et al., 2015), looks at the normalized correlation between the di-", "startOffset": 71, "endOffset": 194}, {"referenceID": 18, "context": "Vector Cosine, by far the most common distributional similarity metric (Turney and Pantel, 2010; Landauer and Dumais, 1997; Jarmasz and Szpakowicz, 2004; Mikolov et al., 2013; Levy et al., 2015), looks at the normalized correlation between the di-", "startOffset": 71, "endOffset": 194}, {"referenceID": 20, "context": "Despite its extensive usage, Vector Cosine has been recently criticized for its hyper sensibility to features with high values and for the inability of identifying the actual feature intersection (Li and Han, 2013; Schnabel et al., 2015).", "startOffset": 196, "endOffset": 237}, {"referenceID": 28, "context": "Despite its extensive usage, Vector Cosine has been recently criticized for its hyper sensibility to features with high values and for the inability of identifying the actual feature intersection (Li and Han, 2013; Schnabel et al., 2015).", "startOffset": 196, "endOffset": 237}, {"referenceID": 20, "context": "ple by Li and Han (2013), the Vector Cosine for the toy-vectors a = [1, 2, 0] and b = [0, 1, 0] (i.", "startOffset": 7, "endOffset": 25}, {"referenceID": 20, "context": "ple by Li and Han (2013), the Vector Cosine for the toy-vectors a = [1, 2, 0] and b = [0, 1, 0] (i.e. 0.8944) is unexpectedly higher than the one for a and c = [2, 1, 0] (i.e. 0.8000), and even higher than the one for the toy-vectors a and d = [1, 2, 1] (i.e. 0.6325), which instead share a larger feature intersection. Since the Vector Cosine is a distance measure, it is also subject to the hubness problem, which was shown by Radovanovic et al. (2010) to be an inherent property of data distributions in highdimensional vector space.", "startOffset": 7, "endOffset": 455}, {"referenceID": 4, "context": "the fact that vectors with high frequency tend to get high scores with a large number of other vectors, thus becoming universal nearest neighbours (Dinu et al., 2014; Schnabel et al., 2015; Faruqui et al., 2016).", "startOffset": 147, "endOffset": 211}, {"referenceID": 28, "context": "the fact that vectors with high frequency tend to get high scores with a large number of other vectors, thus becoming universal nearest neighbours (Dinu et al., 2014; Schnabel et al., 2015; Faruqui et al., 2016).", "startOffset": 147, "endOffset": 211}, {"referenceID": 6, "context": "the fact that vectors with high frequency tend to get high scores with a large number of other vectors, thus becoming universal nearest neighbours (Dinu et al., 2014; Schnabel et al., 2015; Faruqui et al., 2016).", "startOffset": 147, "endOffset": 211}, {"referenceID": 16, "context": "(2016b), and it was shown to outperform the vector cosine on the TOEFL (Landauer and Dumais, 1997) and on the ESL (Turney, 2001)", "startOffset": 71, "endOffset": 98}, {"referenceID": 32, "context": "(2016b), and it was shown to outperform the vector cosine on the TOEFL (Landauer and Dumais, 1997) and on the ESL (Turney, 2001)", "startOffset": 114, "endOffset": 128}, {"referenceID": 24, "context": "com/esantus/APSyn has been recently introduced in Santus et al. (2016a) and Santus et al.", "startOffset": 50, "endOffset": 72}, {"referenceID": 24, "context": "com/esantus/APSyn has been recently introduced in Santus et al. (2016a) and Santus et al. (2016b), and it was shown to outperform the vector cosine on the TOEFL (Landauer and Dumais, 1997) and on the ESL (Turney, 2001)", "startOffset": 50, "endOffset": 98}, {"referenceID": 25, "context": "Santus et al. (2016a) have also used LMI instead of PPMI as", "startOffset": 0, "endOffset": 22}, {"referenceID": 8, "context": "For our evaluation, we used three widely popular datasets: WordSim-353 (Finkelstein et al., 2001),", "startOffset": 71, "endOffset": 97}, {"referenceID": 12, "context": ", 2014), SimLex-999 (Hill et al., 2015).", "startOffset": 20, "endOffset": 39}, {"referenceID": 8, "context": "WordSim-353 (Finkelstein et al., 2001) was proposed as a word similarity dataset containing 353 pairs annotated with scores between 0 and 10.", "startOffset": 12, "endOffset": 38}, {"referenceID": 8, "context": "WordSim-353 (Finkelstein et al., 2001) was proposed as a word similarity dataset containing 353 pairs annotated with scores between 0 and 10. However, Hill et al. (2015) claimed that the instructions to the annotators were ambiguous with respect to similarity and association, so that the subjects assigned high similarity", "startOffset": 13, "endOffset": 170}, {"referenceID": 12, "context": "similarity and association), Hill et al. (2015) argue that these gold standards still carry the scores they had in WordSim-353, which are known to be ambiguous in this regard.", "startOffset": 29, "endOffset": 48}, {"referenceID": 12, "context": "similarity and association), Hill et al. (2015) argue that these gold standards still carry the scores they had in WordSim-353, which are known to be ambiguous in this regard. The MEN Test Collection (Bruni et al., 2014) includes 3,000 word pairs divided in two sets (one for training and one for testing) together with human judgments, obtained through Amazon Mechanical Turk. The construction was performed by asking subjects to rate which pair - among two of them was the more related one (i.e. the most associated). Every pairs-couple was proposed only once, and a final score out of 50 was attributed to each pair, according to how many times it was rated as the most related. According to Hill et al. (2015), the major weakness of this dataset is that it does not encode word similarity, but a more general notion of association.", "startOffset": 29, "endOffset": 714}, {"referenceID": 12, "context": "similarity and association), Hill et al. (2015) argue that these gold standards still carry the scores they had in WordSim-353, which are known to be ambiguous in this regard. The MEN Test Collection (Bruni et al., 2014) includes 3,000 word pairs divided in two sets (one for training and one for testing) together with human judgments, obtained through Amazon Mechanical Turk. The construction was performed by asking subjects to rate which pair - among two of them was the more related one (i.e. the most associated). Every pairs-couple was proposed only once, and a final score out of 50 was attributed to each pair, according to how many times it was rated as the most related. According to Hill et al. (2015), the major weakness of this dataset is that it does not encode word similarity, but a more general notion of association. SimLex-999 is the dataset introduced by Hill et al. (2015) to address the above mentioned criticisms of", "startOffset": 29, "endOffset": 895}, {"referenceID": 12, "context": "Hill et al. (2015) claim that differently from other datasets, SimLex-999 interannotator agreement has not been surpassed by any automatic approach.", "startOffset": 0, "endOffset": 19}, {"referenceID": 12, "context": "In order to compare our results with state-of-the-art DSMs, we report the scores for the Vector Cosines calculated on the neural language models (NLM) by Hill et al. (2015), who used the code (or directly the", "startOffset": 154, "endOffset": 173}, {"referenceID": 19, "context": "1 Corpus (Lewis et al., 2004).", "startOffset": 9, "endOffset": 29}, {"referenceID": 13, "context": "The three models we compare our results to are: i) the convolutional neural network of Collobert and Weston (2008), which was trained on 852 million words of Wikipedia; ii) the neural network of Huang et al. (2012), which was trained on 990 million words of Wikipedia; and iii) the word2vec of Mikolov et al.", "startOffset": 195, "endOffset": 215}, {"referenceID": 13, "context": "The three models we compare our results to are: i) the convolutional neural network of Collobert and Weston (2008), which was trained on 852 million words of Wikipedia; ii) the neural network of Huang et al. (2012), which was trained on 990 million words of Wikipedia; and iii) the word2vec of Mikolov et al. (2013), which was trained on 1000 million words of Wikipedia and on the RCV Vol.", "startOffset": 195, "endOffset": 316}, {"referenceID": 20, "context": "In the bottom the performance of the state-of-the-art model of Mikolov et al. (2013), as reported in Hill et al.", "startOffset": 63, "endOffset": 85}, {"referenceID": 12, "context": "(2013), as reported in Hill et al. (2015).", "startOffset": 23, "endOffset": 42}, {"referenceID": 19, "context": "1 (Lewis et al., 2004) and the Wikipedia corpus (Baroni et al.", "startOffset": 2, "endOffset": 22}, {"referenceID": 27, "context": "with the POS tagger described in Dell\u2019Orletta (2009) and with the TreeTagger (Schmid, 1994).", "startOffset": 77, "endOffset": 91}, {"referenceID": 12, "context": "In the bottom the performance of the state-of-the-art models of Collobert and Weston (2008), Huang et al. (2012), Mikolov et al.", "startOffset": 93, "endOffset": 113}, {"referenceID": 12, "context": "In the bottom the performance of the state-of-the-art models of Collobert and Weston (2008), Huang et al. (2012), Mikolov et al. (2013), as reported in Hill et al.", "startOffset": 93, "endOffset": 136}, {"referenceID": 12, "context": "(2013), as reported in Hill et al. (2015).", "startOffset": 23, "endOffset": 42}, {"referenceID": 12, "context": "For the sake of comparison, we also report the results of the state-of-the-art DSMs mentioned in Hill et al. (2015) (see Section 2.", "startOffset": 97, "endOffset": 116}, {"referenceID": 15, "context": "(2015)\u2019s claim that no evidence supports the hypothesis that smaller context windows improve the ability of models to capture similarity (Agirre et al., 2009; Kiela and Clark, 2014), we need to mention that window 5", "startOffset": 137, "endOffset": 181}, {"referenceID": 12, "context": "On top of it, despite Hill et al. (2015)\u2019s claim that no evidence supports the hypothesis that smaller context windows improve the ability of models to capture similarity (Agirre et al.", "startOffset": 22, "endOffset": 41}, {"referenceID": 28, "context": "With reference to the hubness effect, we have conducted a pilot study inspired to the one carried out by Schnabel et al. (2015), using the words of the SimLex-999 dataset as query words and collecting", "startOffset": 105, "endOffset": 128}, {"referenceID": 22, "context": "APSyn does not seem to be able to overcome such bias, which seems to be in fact an inherent property of the DSMs (Radovanovic et al., 2010).", "startOffset": 113, "endOffset": 139}, {"referenceID": 32, "context": "Finally, few words need to be spent with regard to the ability of calculating genuine similarity, as distinguished from word relatedness (Turney, 2001; Agirre et al., 2009; Hill et al., 2015).", "startOffset": 137, "endOffset": 191}, {"referenceID": 12, "context": "Finally, few words need to be spent with regard to the ability of calculating genuine similarity, as distinguished from word relatedness (Turney, 2001; Agirre et al., 2009; Hill et al., 2015).", "startOffset": 137, "endOffset": 191}, {"referenceID": 12, "context": ", 2009; Hill et al., 2015). Table 3 and Table 4 show the Spearman correlation scores for the two measures calculated on the models respectively trained on RCV1 and Wikipedia, tested on the subsets of WordSim-353 extracted by Agirre et al. (2009). It can be easily noticed that our best models work better on the similarity subset.", "startOffset": 8, "endOffset": 246}, {"referenceID": 12, "context": "Interestingly, our best models achieve results that are comparable to - or even better than - those reported by Hill et al. (2015) for the stateof-the-art word embeddings models.", "startOffset": 112, "endOffset": 131}], "year": 2016, "abstractText": "In Distributional Semantic Models (DSMs), Vector Cosine is widely used to estimate similarity between word vectors, although this measure was noticed to suffer from several shortcomings. The recent literature has proposed other methods which attempt to mitigate such biases. In this paper, we intend to investigate APSyn, a measure that computes the extent of the intersection between the most associated contexts of two target words, weighting it by context relevance. We evaluated this metric in a similarity estimation task on several popular test sets, and our results show that APSyn is in fact highly competitive, even with respect to the results reported in the literature for word embeddings. On top of it, APSyn addresses some of the weaknesses of Vector Cosine, performing well also on genuine similarity estimation.", "creator": "TeX"}}}