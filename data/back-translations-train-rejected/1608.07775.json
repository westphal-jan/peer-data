{"id": "1608.07775", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Aug-2016", "title": "Hierarchical Attention Model for Improved Machine Comprehension of Spoken Content", "abstract": "Multimedia or spoken content presents more attractive information than plain text content, but the former is more difficult to display on a screen and be selected by a user. As a result, accessing large collections of the former is much more difficult and time-consuming than the latter for humans. It's therefore highly attractive to develop machines which can automatically understand spoken content and summarize the key information for humans to browse over. In this endeavor, a new task of machine comprehension of spoken content was proposed recently. The initial goal was defined as the listening comprehension test of TOEFL, a challenging academic English examination for English learners whose native languages are not English. An Attention-based Multi-hop Recurrent Neural Network (AMRNN) architecture was also proposed for this task, which considered only the sequential relationship within the speech utterances. In this paper, we propose a new Hierarchical Attention Model (HAM), which constructs multi-hopped attention mechanism over tree-structured rather than sequential representations for the utterances. Improved comprehension performance robust with respect to ASR errors were obtained.", "histories": [["v1", "Sun, 28 Aug 2016 06:48:14 GMT  (302kb,D)", "https://arxiv.org/abs/1608.07775v1", null], ["v2", "Sat, 1 Oct 2016 03:19:40 GMT  (302kb,D)", "http://arxiv.org/abs/1608.07775v2", "Copyright 2016 IEEE. Published in the 2016 IEEE Workshop on Spoken Language Technology (SLT 2016)"], ["v3", "Sun, 1 Jan 2017 12:17:13 GMT  (302kb,D)", "http://arxiv.org/abs/1608.07775v3", "Copyright 2016 IEEE. Published in the 2016 IEEE Workshop on Spoken Language Technology (SLT 2016)"]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["wei fang", "jui-yang hsu", "hung-yi lee", "lin-shan lee"], "accepted": false, "id": "1608.07775"}, "pdf": {"name": "1608.07775.pdf", "metadata": {"source": "CRF", "title": "HIERARCHICAL ATTENTION MODEL FOR IMPROVED MACHINE COMPREHENSION OF SPOKEN CONTENT", "authors": ["Wei Fang", "Jui-Yang Hsu", "Hung-yi Lee", "Lin-Shan Lee"], "emails": ["b02901054@ntu.edu.tw,", "b02901085@ntu.edu.tw,", "hungyilee@ntu.edu.tw,", "lslee@gate.sinica.edu.tw"], "sections": [{"heading": null, "text": "Index Terms - Answering spoken questions, TOEFL, Deep Learning, Attention Model"}, {"heading": "1. INTRODUCTION", "text": "In fact, it is the case that most of them are able to abide by the rules that they have imposed on themselves, and that they are able to abide by the rules that they have imposed on themselves. (...) In fact, it is the case that they are able to break the rules. (...) In fact, it is the case that they are able to break the rules. (...) In fact, it is the case that they are able to break the rules. (...)"}, {"heading": "2. TASK DESCRIPTION AND CONTRIBUTIONS", "text": "In this thesis, we take the TOEFL Hearing Comprehension Test as a corpus for experiments [1]. TOEFL tests the knowledge and skills of academic English for global English learners whose native languages are not English. Each sample problem consists of an audio story and a question with four possible answers, among which one or two are correct. An example is shown in Fig. 1. The machine must select the correct answer (s) from the four choices. The questions here are not very simple, because the answer cannot be found simply by adjusting the question and the choices without understanding the story. For example, there are questions relating to the core of the story or the conclusion to the conversation. So this is a relatively challenging task for the state-of-the-art spoken language understanding technologies, and the suggested approaches should be general enough to tackle different types of questions.In this work, we propose a hierarchical attention model (HAM) to construct tree-structured sentences."}, {"heading": "3.1. Tree-LSTM", "text": "Two variants of tree LSTM can be used: Child-Sum TreeLSTM = Child-LSTM = Child-Sum-LSTM = Child-LSTM = Child-LSTM (used here due to its relatively compact structure) The dependency tree structure of a sentence \"Conventions may vary\" is shown on the left side of Figure 3, in which each node corresponds to a word (node main word) in the reasoning for the judgement. Tree-LSTM creates a vector representation for each node in dependency stree1 based on the vector representations of its child nodes as in the right part of Figure 3. Each node j has a hidden state hj as vector representation and a number of memory cells cj. Similar to the standard LSTM [22], it has the input gates ij and output gates oj for the cells."}, {"heading": "3.2. Story and Question Modules", "text": "The Story module and the Question module generate representations for the sentences in the story or in the question with the tree-LSTM, as explained in section 3.1. In the Story module, the hidden vectors for all nodes in the tree structures of each sentence in the story are stored for future use. On the other hand, the Question module creates the hidden states of the root nodes, VSi, the tree LSTMs for the sentences Si in question 2. The Question-Vector VQ is the sum of VSi for all Si in a question to be used below."}, {"heading": "3.3. Memory Module", "text": "It consists of two components: the attention mechanism and the multihopping. Attention mechanism is shown in Fig. 4. Let O = {o1, o2,..., oT} be the set of vector representations for the story. There are two different ways to get these vectors: \u2022 Phrase level: O = {o1, o2,..., oT}, where each ot is the hidden state of a node in the tree LSTM of the sentences, or each ot is a phrase. Thus, T is much greater than the number of sentences in the story. This is shown in the lower part of Fig. 4. \u2022 Sentence level: O = {o1, o2,..., oT}, where each ot represents the hidden state of the root node of the tree LSTM."}, {"heading": "3.4. Answer Module", "text": "The answer module encodes the answer selection in choice vectors VCi. Cosine-like similarities between the output of the memory module qn and the choice vectors VCi result in the predicted choice distribution p.The target distribution p is defined as: pi = {1 N, if choice i is a correct answer 0, otherwise (12) for 1 \u2264 i \u2264 K. The KL divergence between p and p \u0430 is assumed as a cost function for the training. Decisions with topN values are selected for a question with N answers."}, {"heading": "4. EXPERIMENTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1. Experimental Setup", "text": "The TOEFL listening comprehension test included a total of 963 problems with a train / developer / test split of 717 / 124 / 122. There were two versions of each story, manual and ASR transcriptions, the latter being determined using CMU sphinx detection [23] with a word error rate of 34.32%. The size of the hidden layer for Tree-LSTM [20] and the memory module embedding size were both 75. AdaGrad [24] was used with an initial learning rate of 0.002."}, {"heading": "4.2. Baselines", "text": "We compared the proposed model with several baselines as summarized below, the first two being trivial baselines, while the rest had neural approaches. In the trivial baselines, we used pre-trained GloVe [25] vectors to get the vector representation for each word. (a) Questions and decisions could be represented as a fixed vector by forming the word vectors. (b) Slide the vector representations between two sentences. (a) Question / Choice similarity [1]: With the vector representations for the election / question after the election, the most similar to the question was chosen. (b) Slide window of vector representations was used."}, {"heading": "4.3. Results", "text": "We used accuracy (percentage of correctly answered questions) as our evaluation metric 2.5. The models were trained on manual transcriptions of the stories and questions / answers of the training and tested on the manual (column labeled \"manual\") and ASR transcriptions (column labeled \"ASR\") of the test set. The results are in Table 1 and (b) are trivial baselines; the middle section (c) are neural networks based on baselines; while the lower section (g1) - (g4) are for the proposed HAM with varying hop and attention levels. Due to the not negligible performance models for all neural networks based baselines, for fair comparisons, we reported on the mean accuracy of the accuracy of the accuracy of the accuracy of the accuracy (g4)."}, {"heading": "4.4. Analysis", "text": "The question is: \"What is the radiation budget?\" And the right choice is: \"The balance between incoming and reflecting solar energy has been chosen.\" The same question arises for the model, which in Node 1 sets the key terms for defining the radiation budget, such as sunlight, transmission, and reflection."}, {"heading": "7. REFERENCES", "text": "[1] B.-H. Tseng, S.-S. Shen, H.-Y. Lee, and L.-S. Lee, \"Towards machine learning comprehension of spoken content: Initial toefl listening comprehension test by machine,\" in INTERSPEECH, 2016. [2] P. R. C. i Umbert, J. Turmo Borra, and L. M. Villodre, \"Spoken question answer,\" [3] P. R. R. i Umbert, Factoid question answering for spoken documents, Ph.D. thesis, Universitat Polite, Cnica de Catalunya, 2012. [4] S.-R. Shiang, H.-Y. Lee, and L.-S. Lee, \"Xien question answering using tree-structured random fields and double-layered random walk.,\" in INTERSPEECH, 2014, pp. 263-267. [5] B. Hixon, P. Clark, and H. Hajishirzi, and H.."}], "references": [{"title": "Towards machine learning comprehension of spoken content: Initial toefl listening comprehension test by machine", "author": ["B.-H. Tseng", "S.-S. Shen", "H.-Y. Lee", "L.-S. Lee"], "venue": "INTERSPEECH, 2016.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2016}, {"title": "Spoken question answering", "author": ["P.R.C. i Umbert", "J. Turmo Borr\u00e0s", "L.M. Villodre"], "venue": ".", "citeRegEx": "2", "shortCiteRegEx": null, "year": 0}, {"title": "Factoid question answering for spoken documents", "author": ["P.R.C. i Umbert"], "venue": "Ph.D. thesis, Universitat Polite\u0300cnica de Catalunya,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2012}, {"title": "Spoken question answering using tree-structured conditional random fields and two-layer random walk", "author": ["S.-R. Shiang", "H.-Y. Lee", "L.-S. Lee"], "venue": "INTERSPEECH, 2014, pp. 263\u2013267.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning knowledge graphs for question answering through conversational dialog", "author": ["B. Hixon", "P. Clark", "H. Hajishirzi"], "venue": "Proceedings of the the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Denver, Colorado, USA, 2015.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2015}, {"title": "Sibyl, a factoid question-answering system for spoken documents", "author": ["P.R. Comas", "J. Turmo", "L. M\u00e0rquez"], "venue": "ACM Transactions on Information Systems (TOIS), vol. 30, no. 3, pp. 19, 2012.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2012}, {"title": "Overview of qast 2008", "author": ["J. Turmo", "P.R. Comas", "S. Rosset", "L. Lamel", "N. Moreau", "D. Mostefa"], "venue": "Workshop of the Cross-Language Evaluation Forum for European Languages. Springer, 2008, pp. 314\u2013324.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2008}, {"title": "Question answering with subgraph embeddings", "author": ["A. Bordes", "S. Chopra", "J. Weston"], "venue": "arXiv preprint arXiv:1406.3676, 2014.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "A factoid question answering system using answer pattern matching", "author": ["N.P. Er", "I. Cicekli"], "venue": "IJCNLP, 2013, pp. 854\u2013858.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2013}, {"title": "A neural network for factoid question answering over paragraphs", "author": ["M. Iyyer", "J.L. Boyd-Graber", "L.M.B. Claudino", "R. Socher", "H. Daum\u00e9 III"], "venue": "EMNLP, 2014, pp. 633\u2013644.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}, {"title": "Open question answering over curated and extracted knowledge bases", "author": ["A. Fader", "L. Zettlemoyer", "O. Etzioni"], "venue": "Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2014, pp. 1156\u20131165.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2014}, {"title": "Movieqa: Understanding stories in movies through question-answering", "author": ["M. Tapaswi", "Y. Zhu", "R. Stiefelhagen", "A. Torralba", "R. Urtasun", "S. Fidler"], "venue": "CoRR, vol. abs/1512.02902, 2015.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2015}, {"title": "Large-scale simple question answering with memory networks", "author": ["A. Bordes", "N. Usunier", "S. Chopra", "J. Weston"], "venue": "CoRR, vol. abs/1506.02075, 2015.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2015}, {"title": "Ask me anything: Dynamic memory networks for natural language processing", "author": ["A. Kumar", "O. Irsoy", "J. Su", "J. Bradbury", "R. English", "B. Pierce", "P. Ondruska", "I. Gulrajani", "R. Socher"], "venue": "CoRR, vol. abs/1506.07285, 2015.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2015}, {"title": "Dynamic memory networks for visual and textual question answering", "author": ["C. Xiong", "S. Merity", "R. Socher"], "venue": "CoRR, vol. abs/1603.01417, 2016.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2016}, {"title": "Teaching machines to read and comprehend", "author": ["K.M. Hermann", "T. Kocisk\u00fd", "E. Grefenstette", "L. Espeholt", "W. Kay", "M. Suleyman", "P. Blunsom"], "venue": "CoRR, vol. abs/1506.03340, 2015.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2015}, {"title": "Memory networks", "author": ["J. Weston", "S. Chopra", "A. Bordes"], "venue": "CoRR, vol. abs/1410.3916, 2014.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2014}, {"title": "Weakly supervised memory networks", "author": ["S. Sukhbaatar", "A. Szlam", "J. Weston", "R. Fergus"], "venue": "CoRR, vol. abs/1503.08895, 2015.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2015}, {"title": "Speech recognition with deep recurrent neural networks", "author": ["A. Graves", "A.-R. Mohamed", "G.E. Hinton"], "venue": "CoRR, vol. abs/1303.5778, 2013.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2013}, {"title": "Improved semantic representations from tree-structured long shortterm memory networks", "author": ["K.S. Tai", "R. Socher", "C.D. Manning"], "venue": "CoRR, vol. abs/1503.00075, 2015.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2015}, {"title": "A fast and accurate dependency parser using neural networks", "author": ["D. Chen", "C.D. Manning"], "venue": "EMNLP, 2014, pp. 740\u2013750.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2014}, {"title": "Long short-term memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural Comput., vol. 9, no. 8, pp. 1735\u20131780, Nov. 1997.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1997}, {"title": "Sphinx-4: A flexible open source framework for speech recognition", "author": ["W. Walker", "P. Lamere", "P. Kwok", "B. Raj", "R. Singh", "E. Gouvea", "P. Wolf", "J. Woelfel"], "venue": "Tech. Rep., Mountain View, CA, USA, 2004.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2004}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["J. Duchi", "E. Hazan", "Y. Singer"], "venue": "Journal of Machine Learning Research, vol. 12, no. Jul, pp. 2121\u20132159, 2011.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2011}, {"title": "Glove: Global vectors for word representation", "author": ["J. Pennington", "R. Socher", "C.D. Manning"], "venue": "EMNLP, vol. 14, pp. 1532\u201343, 2014.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2014}, {"title": "Maintaining stream statistics over sliding windows", "author": ["M. Datar", "A. Gionis", "P. Indyk", "R. Motwani"], "venue": "SIAM J. Comput., vol. 31, no. 6, pp. 1794\u20131813, June 2002.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1813}], "referenceMentions": [{"referenceID": 0, "context": "An initial attempt towards the above goal of machine comprehension of spoken content was presented recently in an initial task [1], Story", "startOffset": 127, "endOffset": 130}, {"referenceID": 0, "context": "An Attention-based Multi-hop Recurrent Neural Network (AMRNN) framework for the above TOEFL task was proposed, and encouraging initial results were reported recently [1].", "startOffset": 166, "endOffset": 169}, {"referenceID": 1, "context": "The listening comprehension task considered here is highly related to Spoken Question Answering (SQA) [2, 3].", "startOffset": 102, "endOffset": 108}, {"referenceID": 2, "context": "The listening comprehension task considered here is highly related to Spoken Question Answering (SQA) [2, 3].", "startOffset": 102, "endOffset": 108}, {"referenceID": 3, "context": "SQA usually worked with ASR transcripts of the spoken content, and used information retrieval (IR) techniques [4] or relied on knowledge bases [5] to find the proper answer.", "startOffset": 110, "endOffset": 113}, {"referenceID": 4, "context": "SQA usually worked with ASR transcripts of the spoken content, and used information retrieval (IR) techniques [4] or relied on knowledge bases [5] to find the proper answer.", "startOffset": 143, "endOffset": 146}, {"referenceID": 5, "context": "Sibyl [6] is a factoid SQA system, while Question Answering in Speech Transcripts (QAST) [7] has been a wellknown evaluation program for years.", "startOffset": 6, "endOffset": 9}, {"referenceID": 6, "context": "Sibyl [6] is a factoid SQA system, while Question Answering in Speech Transcripts (QAST) [7] has been a wellknown evaluation program for years.", "startOffset": 89, "endOffset": 92}, {"referenceID": 7, "context": "On the other hand, most Question Answering works focused on understanding text documents [8\u201311].", "startOffset": 89, "endOffset": 95}, {"referenceID": 8, "context": "On the other hand, most Question Answering works focused on understanding text documents [8\u201311].", "startOffset": 89, "endOffset": 95}, {"referenceID": 9, "context": "On the other hand, most Question Answering works focused on understanding text documents [8\u201311].", "startOffset": 89, "endOffset": 95}, {"referenceID": 10, "context": "On the other hand, most Question Answering works focused on understanding text documents [8\u201311].", "startOffset": 89, "endOffset": 95}, {"referenceID": 11, "context": "Even though MovieQA [12] tried to answer questions related to movies, they only used the text and images in the movies.", "startOffset": 20, "endOffset": 24}, {"referenceID": 12, "context": "On the other hand, neural models have been extensively explored for question answering tasks [13\u201316].", "startOffset": 93, "endOffset": 100}, {"referenceID": 13, "context": "On the other hand, neural models have been extensively explored for question answering tasks [13\u201316].", "startOffset": 93, "endOffset": 100}, {"referenceID": 14, "context": "On the other hand, neural models have been extensively explored for question answering tasks [13\u201316].", "startOffset": 93, "endOffset": 100}, {"referenceID": 15, "context": "On the other hand, neural models have been extensively explored for question answering tasks [13\u201316].", "startOffset": 93, "endOffset": 100}, {"referenceID": 16, "context": "Specifically, reasoning systems incorporating memory and attention mechanisms such as the Memory Network (MemNN) [17] were shown to be very successful, and the End-to-end Memory Network (MemN2N) [18], a variant of MemNN, can be trained end-to-end without labeled supporting facts.", "startOffset": 113, "endOffset": 117}, {"referenceID": 17, "context": "Specifically, reasoning systems incorporating memory and attention mechanisms such as the Memory Network (MemNN) [17] were shown to be very successful, and the End-to-end Memory Network (MemN2N) [18], a variant of MemNN, can be trained end-to-end without labeled supporting facts.", "startOffset": 195, "endOffset": 199}, {"referenceID": 0, "context": "The Attention-based Multi-hop Recurrent Neural Network (AMRNN) mentioned above in the previous work [1] utilizes the attention mechanism with recurrent neural networks (RNN) [19] to construct sentence representations considering the word order, but didn\u2019t take the syntactic structure of sentences into account yet.", "startOffset": 100, "endOffset": 103}, {"referenceID": 18, "context": "The Attention-based Multi-hop Recurrent Neural Network (AMRNN) mentioned above in the previous work [1] utilizes the attention mechanism with recurrent neural networks (RNN) [19] to construct sentence representations considering the word order, but didn\u2019t take the syntactic structure of sentences into account yet.", "startOffset": 174, "endOffset": 178}, {"referenceID": 19, "context": "Recently, tree-structured models [20] obtained from the syntactic structures of the sentences were shown to be able to produce more robust representations and capture better semantics in certain tasks.", "startOffset": 33, "endOffset": 37}, {"referenceID": 0, "context": "In this paper, we take the TOEFL listening comprehension test as the corpus for experiments [1].", "startOffset": 92, "endOffset": 95}, {"referenceID": 0, "context": "The experiments showed improved performance over existing baselines including the previous work using AMRNN [1].", "startOffset": 108, "endOffset": 111}, {"referenceID": 21, "context": "Just as the standard LSTM [22], it has the input gates ij and output gates oj for the memory cells, and the forget gates fjk that controls the information flowing in from its child node k.", "startOffset": 26, "endOffset": 30}, {"referenceID": 20, "context": "1Dependency parses produced by the Stanford Neural Network Dependency Parser [21].", "startOffset": 77, "endOffset": 81}, {"referenceID": 22, "context": "The latter was obtained using CMU Sphinx recognizer [23] with a word error rate of 34.", "startOffset": 52, "endOffset": 56}, {"referenceID": 19, "context": "The size of the hidden layer for Tree-LSTM [20] and the embedding size of the memory module were both 75.", "startOffset": 43, "endOffset": 47}, {"referenceID": 23, "context": "AdaGrad [24] was used with an initial learning rate of 0.", "startOffset": 8, "endOffset": 12}, {"referenceID": 24, "context": "In the trivial baselines, we used pre-trained GloVe [25] vectors to obtain the vector representation for each word.", "startOffset": 52, "endOffset": 56}, {"referenceID": 0, "context": "(a) Question/choice similarity [1]: With the vector representations for the choices/question mentioned above, the choice most similar to the question was selected.", "startOffset": 31, "endOffset": 34}, {"referenceID": 11, "context": "(b) Sliding window of utterances [12, 26]: We slid a window of 5 utterances over the story, and chose the window the most similar to the question as the related information in the story.", "startOffset": 33, "endOffset": 41}, {"referenceID": 25, "context": "(b) Sliding window of utterances [12, 26]: We slid a window of 5 utterances over the story, and chose the window the most similar to the question as the related information in the story.", "startOffset": 33, "endOffset": 41}, {"referenceID": 15, "context": "(c) Deep LSTM Reader (DLR) [16]: We fed the story followed by the question into a Deep LSTM encoder to obtain the representation of each story/question pair.", "startOffset": 27, "endOffset": 31}, {"referenceID": 17, "context": "(d) End-to-end Memory Network (MemN2N) [18]: We slightly modified the original MemN2N to adapt to this task.", "startOffset": 39, "endOffset": 43}, {"referenceID": 0, "context": "(e) Attention-based Multi-hop Recurrent Neural Network (AMRNN) [1]: This is the approach used by the previous work.", "startOffset": 63, "endOffset": 66}, {"referenceID": 19, "context": "(f) Tree-LSTM [20]: Similar to the proposed HAM but without attention.", "startOffset": 14, "endOffset": 18}, {"referenceID": 0, "context": "3The previous work [1] showed that AMRNN outperformed MemN2N in which 10 models with random initialization were trained, and the best on the development set was used for testing.", "startOffset": 19, "endOffset": 22}, {"referenceID": 0, "context": "We thank Bo-Hsiang Tseng for assistance with providing us the TOEFL listening comprehension dataset and the detailed statistics of AMRNN [1], and Juei-Yu Chang, An Huang, YuAn Chen and Ping-Hsuan Tsai for labeling the 3 different types of questions in the testing set.", "startOffset": 137, "endOffset": 140}], "year": 2017, "abstractText": "Multimedia or spoken content presents more attractive information than plain text content, but the former is more difficult to display on a screen and be selected by a user. As a result, accessing large collections of the former is much more difficult and time-consuming than the latter for humans. It\u2019s therefore highly attractive to develop machines which can automatically understand spoken content and summarize the key information for humans to browse over. In this endeavor, a new task of machine comprehension of spoken content was proposed recently. The initial goal was defined as the listening comprehension test of TOEFL, a challenging academic English examination for English learners whose native languages are not English. An Attention-based Multi-hop Recurrent Neural Network (AMRNN) architecture was also proposed for this task, which considered only the sequential relationship within the speech utterances. In this paper, we propose a new Hierarchical Attention Model (HAM), which constructs multi-hopped attention mechanism over tree-structured rather than sequential representations for the utterances. Improved comprehension performance robust with respect to ASR errors were obtained.", "creator": "LaTeX with hyperref package"}}}