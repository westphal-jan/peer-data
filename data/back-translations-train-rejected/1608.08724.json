{"id": "1608.08724", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-Aug-2016", "title": "A Programming Language With a POMDP Inside", "abstract": "We present POAPS, a novel planning system for defining Partially Observable Markov Decision Processes (POMDPs) that abstracts away from POMDP details for the benefit of non-expert practitioners. POAPS includes an expressive adaptive programming language based on Lisp that has constructs for choice points that can be dynamically optimized. Non-experts can use our language to write adaptive programs that have partially observable components without needing to specify belief/hidden states or reason about probabilities. POAPS is also a compiler that defines and performs the transformation of any program written in our language into a POMDP with control knowledge. We demonstrate the generality and power of POAPS in the rapidly growing domain of human computation by describing its expressiveness and simplicity by writing several POAPS programs for common crowdsourcing tasks.", "histories": [["v1", "Wed, 31 Aug 2016 04:25:45 GMT  (237kb,D)", "http://arxiv.org/abs/1608.08724v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.PL", "authors": ["christopher h lin", "mausam", "daniel s weld"], "accepted": false, "id": "1608.08724"}, "pdf": {"name": "1608.08724.pdf", "metadata": {"source": "CRF", "title": "A Programming Language With a POMDP Inside", "authors": ["Christopher H. Lin", "Daniel S. Weld"], "emails": ["chrislin@cs.washington.edu", "mausam@cse.iitd.ac.in", "weld@cs.washington.edu"], "sections": [{"heading": null, "text": "Categories and Theme Descriptions I.2 [Artificial Intelligence]: Programming Languages and SoftwaresGeneral Terms Algorithms, Language Tags POMDPs, Planning, Decision Theory, Adaptive Programming, Crowdsourcing"}, {"heading": "1. INTRODUCTION", "text": "eSi rf\u00fc ide eeisrrrrteeeeVrlrrrteeeeeeeeeeVnlrlrrteeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeerrrrrrteeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeerrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrteeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee"}, {"heading": "2. RELATED WORK", "text": "Various languages have been proposed in the literature to represent POMDPs, several of which are declarative representations that ask the user to explicitly declare each component (state, actions, etc.) of a POMDP. Examples are the Cassandra-style format 1, the probabilistic PDDL [24], and the RDDL [20]. Several procedural languages have also been developed, including A2BL [22], ALisp [2] and the simultaneous ALisp [14], Hierarchical Abstract Machines (HAMs) [17], and Programmable Hierarchical Abstract Machines (PHAMs) [1]. All of these representations allow the user to provide control knowledge in the form of a procedural program for an existing and explicitly specified MDP program. In other words, when writing an ALisp program, one must additionally define an MDP program that is bound to and explicitly limited to an MDP program."}, {"heading": "3. CROWDSOURCING BACKGROUND", "text": "An example of a simple workflow is the labeling workflow described in the introduction (Figure 1). Another example of a workflow is the iterative enhancement workflow [13]. Suppose a requester wants to create an artifact, such as a text description of an image. In the iterative enhancement workflow, he first hires an employee to improve an existing caption, then asks several workers to vote on whether the new caption is better than the old caption. Finally, he repeats the process until he is satisfied with the caption. Previous work has handcrafted a POMDP for this particular workflow to make dynamic decisions, such as when to vote and when to stop, which has significant savings over static guidelines. [8] Our system would allow these applicants, who are probably not experts, to write a program for this particular workflow that then implicitly controls a workflow and optimizes others."}, {"heading": "4. PRIMITIVES", "text": "To interpret a program like iterative enhancement as POMDP, POAPS requires mathematical models for function calls, such as the one that hires a worker to improve an artifact. POAPS asks experts to define primitives to speed up this process. \u2022 A primitive is a set of ten x < D, R, B, T, O, I, C, DU, RU, F >, where: \u2022 D = D1 \u00d7. \u00b7 Dn is a set of domain states. \u2022 R is a set of domain states. \u2022 B is a set of observations. \u2022 T: D \u00b7 R \u2192 0, 1] is a transitional function. \u2022 O: R \u00d7 B \u2192 [0, 1] is an observation function. \u2022 I is an n-dimensional indicator vector that indicates which of the Di are observable. \u2022 C: D \u2192 R + is a cost function."}, {"heading": "5. THE LANGUAGE", "text": "We define a POAPS program as a function definition written in the POAPS language. The POAPS language is an extension of Lisp because Lisp is both easy to write and easy to interpret. It takes a variable number of arguments, each of which is a Lisp-S expression. When used in a program, it describes a selection point in the program, which means that POAPS decides in runtime the optimal argument expression to execute. As function calls are interpreted, we first emphasize an unknowledgeable user, POAPS behaves just like an ordinary programming language."}, {"heading": "6. THE COMPILER", "text": "Before delving into the technical details of the compiler, we simply ask about the user's budget. The whole point of converting a POAPS application program into a POMDP is to allow for the construction of an optimal policy for the program, but this requires an optimization criterion. Since optimization is different for each user, we need the flexibility to construct different user functions or goals for individual users. In light of these challenges, we assume that executing a primitive incurs costs defined by the primitive, but that an externally provided mechanism for the goal or utility elicitation is used (e.g. [6]) to objectively run the overall program. For example, looking at the election program of Figure 1. It might cost $0.05 to execute the crowd-vote primitive, but learning a given target accuracy of the user to conduct the program requires additional information."}, {"heading": "6.1 Step 1: Creation of a State Space S", "text": "Let X (p) = {arg1,.., argn} be the set of all arguments of p. To construct S (p), the compiler must know the state space of each argument. Let X (p) = {arg1,.., argn} be the set of all arguments of p. To construct S (p), the compiler must know the state space of each argument. The state space of an argument argi is defined by the domain state space Di of the primitives using argi. Next, we must define state variables for all subexpressions in p. A program p in our language can be considered an evaluation tree of expressions. Thus, Figure 4 shows the corresponding tree for the improvement program (Figure 2). To remember all state variables necessary for controlling in p, we have a state variable for each subexpression in p. We call this state space R (p). Let F (p) be the set of POAPS programs corresponding to the user-defined functions called in p. Then we misuse notation for understanding."}, {"heading": "6.2 Step 2: Construction of a HAM", "text": "The second step in the compilation is to construct the machine state space by constructing a HAM [17] M (p) given p and S (p). The HAM states are used in our constructed POMDP as observable state variables that represent the current program counter. Each HAM state represents the evaluation of an expression. In other words, the HAM states will be the part of the POMDP that says where in the evaluation tree we stand for a program. The five states of an HAM are action, call, dial, start, and stop. The callers represent a call to a custom function. They will execute the corresponding HAM states. The states can transition to one of many HAMs. Stop states mean the end of the execution of an HAM and return control to the next state."}, {"heading": "6.3 Step 3: Putting It All Together", "text": "If one lets S (M (p)) denote the number of states of a HAM M (p), the estate space of the POMDP (M \u0445 S) (p) that we construct, as S (p) = S (p) \u00b7 StatesOf (M (p)), the actions depend only on the current, fully observable machine state. In any machine state that is not a choice state, the agent can only perform one action. If the machine state is a choice state, the actions are the branches of the choice state. We define the transition function T (s, a, s) of (M) S (p) so that the values are passed correctly between states to enforce a semantics in which everything is calculated according to the price of the value. The observation function O (s, \"o) is simple. Observations are received only in two scenarios. Firstly, observations can be performed when performing a primitive and they are defined by the primitive."}, {"heading": "7. OPTIMALITY", "text": "We now show that the POMDP that we are constructing is correct, since its optimal policy leads to the optimal implementation of its corresponding program. (LEMMA 1) For each POMDP (M-S) (p) for a program p, let us consider C as a set of states of faith that are the states of faith in which the machine component of any possible world state is an electoral node. There exists a semi-MDP (m-S) (p) for a state c, so that an optimal political equation for (m-S) (p) corresponds to an optimal policy for (M-S) (p). In this sense, the local equation of states of faith (m-S) is reinforced simply by mapping states of faith that are not within the scope of their individual, standard measures. PROOF. Consider the faith MDP that corresponds to (M-S) (p). Let us consider the states that are not optimal beliefs that are not optimal policies to remove these states that are not optimal policies for MDP."}, {"heading": "8. MONTE CARLO PLANNING", "text": "We solve the POMDP when a user executes a program. The POMDP we construct can potentially have many unreachable states. (b) We do not want to construct the entire state space or the complete matrix representation of the transition and observation functions, as these can be very large or infinite. Therefore, we opt for the use of RTDP methods to solve the POMDP. (3) While we are trying to use an UCT-based solver, POMCP (without a rollout policy) 4 [21], we find that the value function can take an extraordinary amount of time to convert. Instead, we modify RTDP-Bel [3] to create C-RTDP, an algorithm similar to HAMQ learning that takes advantage of the fact that the actual complexity of the POMDP is determined by the number of selection points. (C-RTDP-Bel modifies the RTDP-Bel, [3] to create an algorithm similar to HAMQ-Learning, which takes advantage of the fact that the actual complexity of the POMDP is determined by the number of selection points.)"}, {"heading": "9. PROOF-OF-CONCEPT", "text": "As proof of the concept that POAPS can execute programs, we implement the POAPS system and write down the voting program from launch. We also implement a target identification module. The primitive crowd vote has a cost of 1 cent and we set a target accuracy of 90%. We run the program on Mechanical Turk with 1100 tasks to detect named entities. Each task to detect named entities begins with providing the worker with a body of text and an entity, such as \"Washington led the troops into battle.\" Then it uses Wikification [16, 19] to find a number of possible Wikipedia articles describing the entity, such as \"Washington (State)\" and \"George Washington,\" and asks the worker to select the article that best describes the entity. POAPS achieves an overall accuracy of 87.73% at an average cost of 4.33 cents. This result is consistent with those used in POAPS [7] and our experts can implement in a summary of the problem."}, {"heading": "10. A LARGER EXAMPLE", "text": "In fact, the majority of people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move"}, {"heading": "11. CONCLUSION", "text": "We have introduced POAPS, a system that provides a language for writing decision-making that provides an abstraction from POMDPs. Knowledge of POMDPs is not a prerequisite for using decision theories in everyday applications. In particular, the states and dynamics of POMDPs are hidden from users. We have shown how crowdsourcing experts can use POAPS to build and optimally control many of their workflows. We have implemented POAPS and conducted a proof-of-concept experiment that shows that POAPS can run the tuning program in Figure 1 and achieve results comparable to a problem-specific POMDP written by experts. The complete POAPS system that we have built will be available on the authors \"websites."}, {"heading": "12. FUTURE WORK", "text": "In fact, most people who are able to move are able to move, to move, to move and to move, to move, to move, to move, to move, to move and to move, to move, to move, to move, to move and to move."}, {"heading": "13. REFERENCES", "text": "[1] D. Andre and S. J. Russell. Programmable reinforcementlearning agents. In NIPS, 2001. [2] D. Andre and S. J. Russell. State abstraction forprogrammable reinforcement agents. In AAAI, 2002. [3] A. G. Barto, S. J. Bradtke, and S. P. Singh. Learning to actusing real-time dynamic programming. Artificial Intelligence, 72: 81-138, 1995. [4] M. S. Bernstein, G. Little, R. C. Miller, B. Hartmann, M. S. Ackerman, D. R. Karger, D. Crowell, and K. Panovich. Soylent.: A word processor with a crowd inside. In UIST, 2010. C. Boutilier, R. Reiter, M. Soutchanski, and S. Thrun. Decision-theoretic, high-level agent ming in the situation calculus. In AAAAAI, 2000."}], "references": [{"title": "Programmable reinforcement learning agents", "author": ["D. Andre", "S.J. Russell"], "venue": "In NIPS,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2001}, {"title": "State abstraction for programmable reinforcement learning agents", "author": ["D. Andre", "S.J. Russell"], "venue": "In AAAI,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2002}, {"title": "Learning to act using real-time dynamic programming", "author": ["A.G. Barto", "S.J. Bradtke", "S.P. Singh"], "venue": "Artificial Intelligence,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1995}, {"title": "Soylent: A word processor with a crowd inside", "author": ["M.S. Bernstein", "G. Little", "R.C. Miller", "B. Hartmann", "M.S. Ackerman", "D.R. Karger", "D. Crowell", "K. Panovich"], "venue": "In UIST,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2010}, {"title": "Decision-theoretic, high-level agent programming in the situation calculus", "author": ["C. Boutilier", "R. Reiter", "M. Soutchanski", "S. Thrun"], "venue": "In AAAI,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2000}, {"title": "Making rational decisions using adaptive utility elicitation", "author": ["U. Chajewska", "D. Koller", "R. Parr"], "venue": "In AAAI,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2000}, {"title": "Pomdp-based control of workflows for crowdsourcing", "author": ["P. Dai", "C.H. Lin", "Mausam", "D.S. Weld"], "venue": "Artificial Intelligence,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2013}, {"title": "Decision-theoretic control of crowd-sourced workflows", "author": ["P. Dai", "Mausam", "D.S. Weld"], "venue": "In AAAI,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "Hierarchical reinforcement learning with the maxq value function decomposition", "author": ["T.G. Dietterich"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2000}, {"title": "Equivalence notions and model minimization in markov decision processes", "author": ["R. Givan", "T. Dean", "M. Greig"], "venue": "Artificial Intelligence,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2003}, {"title": "Combining human and machine intelligence in large-scale crowdsourcing", "author": ["E. Kamar", "S. Hacker", "E. Horvitz"], "venue": "In AAMAS,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2012}, {"title": "Dynamically switching between synergistic workflows for crowdsourcing", "author": ["C.H. Lin", "Mausam", "D.S. Weld"], "venue": "In AAAI,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2012}, {"title": "Turkit: tools for iterative tasks on mechanical turk", "author": ["G. Little", "L.B. Chilton", "M. Goldman", "R.C. Miller"], "venue": "In KDD-HCOMP,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2009}, {"title": "Concurrent hierarchical reinforcement learning", "author": ["B. Marthi", "S. Russell", "D. Latham", "C. Guestrin"], "venue": "In IJCAI,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2005}, {"title": "Bellman equations for stochastic programs", "author": ["D. McAllester"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1999}, {"title": "Learning to link with wikipedia", "author": ["D. Milne", "I.H. Witten"], "venue": "In Proceedings of the ACM Conference on Information and Knowledge Management,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2008}, {"title": "Reinforcement learning with hierarachies of machines", "author": ["R. Parr", "S. Russell"], "venue": "In NIPS,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1998}, {"title": "Robust learning for adaptive programs by leveraging program structure", "author": ["J. Pinto", "A. Fern", "T. Bauer", "M. Erwig"], "venue": "In ICMLA,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2010}, {"title": "Local and global algorithms for disambiguation to wikipedia", "author": ["L. Ratinov", "D. Roth", "D. Downey", "M. Anderson"], "venue": "In Proceedings of the Annual Meeting of the Association of Computational Linguistics,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2011}, {"title": "Relational dynamic influence diagram language (rddl): Language description", "author": ["S. Sanner"], "venue": "Technical report, NICTA and the Australian National University,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2011}, {"title": "Monte-carlo planning in large pomdps", "author": ["D. Silver", "J. Veness"], "venue": "In NIPS,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2010}, {"title": "Towards adaptive programming: Integrating reinforcement learning into a programming language", "author": ["C. Simpkins", "S. Bhat", "C.I. Jr.", "M. Mateas"], "venue": "In OOPSLA,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2008}, {"title": "Human intelligence needs artificial intelligence", "author": ["D.S. Weld", "Mausam", "P. Dai"], "venue": "In HCOMP,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2011}, {"title": "Ppddl1.0: The language for the probabilistic part of ipc-4", "author": ["H.L.S. Younes", "M.L. Littman"], "venue": "In IPC,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2004}], "referenceMentions": [{"referenceID": 22, "context": "Those who would greatly like access to such tools, like many in the crowdsourcing community [23] for example, must either resort to sub-optimal techniques that use approximate heuristics or hire a planning expert to formally define and solve their domain-specific problems.", "startOffset": 92, "endOffset": 96}, {"referenceID": 1, "context": "Like many previous approaches to proceduralizing decision processes[2, 5, 18], we create a language that includes choice points, which allow the system to make optimal decisions adaptively.", "startOffset": 67, "endOffset": 77}, {"referenceID": 4, "context": "Like many previous approaches to proceduralizing decision processes[2, 5, 18], we create a language that includes choice points, which allow the system to make optimal decisions adaptively.", "startOffset": 67, "endOffset": 77}, {"referenceID": 17, "context": "Like many previous approaches to proceduralizing decision processes[2, 5, 18], we create a language that includes choice points, which allow the system to make optimal decisions adaptively.", "startOffset": 67, "endOffset": 77}, {"referenceID": 7, "context": "Instead of hiring a planning expert to handcraft a custom POMDP for this simple voting problem [8, 11], users, and in particular, non-experts, should be able to write a very simple program that abstracts away from state variables and probabilities: either ask another worker for another label and recurse, or return the label with the most number of votes.", "startOffset": 95, "endOffset": 102}, {"referenceID": 10, "context": "Instead of hiring a planning expert to handcraft a custom POMDP for this simple voting problem [8, 11], users, and in particular, non-experts, should be able to write a very simple program that abstracts away from state variables and probabilities: either ask another worker for another label and recurse, or return the label with the most number of votes.", "startOffset": 95, "endOffset": 102}, {"referenceID": 23, "context": "Examples include Cassandra-style format , Probabilistic PDDL [24], and RDDL [20].", "startOffset": 61, "endOffset": 65}, {"referenceID": 19, "context": "Examples include Cassandra-style format , Probabilistic PDDL [24], and RDDL [20].", "startOffset": 76, "endOffset": 80}, {"referenceID": 21, "context": "Several procedural languages have also been developed including ABL [22], ALisp [2] and concurrent ALisp [14], Hierarchical Abstract Machines (HAMs) [17], and Programmable Hierarchical Abstract Machines (PHAMs) [1].", "startOffset": 68, "endOffset": 72}, {"referenceID": 1, "context": "Several procedural languages have also been developed including ABL [22], ALisp [2] and concurrent ALisp [14], Hierarchical Abstract Machines (HAMs) [17], and Programmable Hierarchical Abstract Machines (PHAMs) [1].", "startOffset": 80, "endOffset": 83}, {"referenceID": 13, "context": "Several procedural languages have also been developed including ABL [22], ALisp [2] and concurrent ALisp [14], Hierarchical Abstract Machines (HAMs) [17], and Programmable Hierarchical Abstract Machines (PHAMs) [1].", "startOffset": 105, "endOffset": 109}, {"referenceID": 16, "context": "Several procedural languages have also been developed including ABL [22], ALisp [2] and concurrent ALisp [14], Hierarchical Abstract Machines (HAMs) [17], and Programmable Hierarchical Abstract Machines (PHAMs) [1].", "startOffset": 149, "endOffset": 153}, {"referenceID": 0, "context": "Several procedural languages have also been developed including ABL [22], ALisp [2] and concurrent ALisp [14], Hierarchical Abstract Machines (HAMs) [17], and Programmable Hierarchical Abstract Machines (PHAMs) [1].", "startOffset": 211, "endOffset": 214}, {"referenceID": 4, "context": "DTGolog [5] is a situation calculus-based procedural language that can both define decision problems (by defining a set of axioms) and specify control.", "startOffset": 8, "endOffset": 11}, {"referenceID": 14, "context": "Stochastic Programs (SP) [15] provide a language for experts to write world models and primitive actions and then compose those primitive actions to create control policies for the corresponding world model.", "startOffset": 25, "endOffset": 29}, {"referenceID": 17, "context": "org The work on adaptive programs [18] allows non-expert users to quickly construct observable decision processes by writing programs that can contain optimizable choice points.", "startOffset": 34, "endOffset": 38}, {"referenceID": 12, "context": "Another example of a workflow is the iterative improvement workflow [13].", "startOffset": 68, "endOffset": 72}, {"referenceID": 7, "context": "Previous work has hand-crafted a POMDP for this particular workflow in order to make dynamic decisions like when to vote and when to stop, showing significant savings over static policies [8].", "startOffset": 188, "endOffset": 191}, {"referenceID": 0, "context": "\u2022 T : D \u00d7R \u2192 [0, 1] is a transition function.", "startOffset": 13, "endOffset": 19}, {"referenceID": 0, "context": "\u2022 O : R\u00d7 \u03a9\u2192 [0, 1] is an observation function.", "startOffset": 12, "endOffset": 18}, {"referenceID": 0, "context": "We define D = R = [0, 1] to represent the hidden quality of the artifact.", "startOffset": 18, "endOffset": 24}, {"referenceID": 1, "context": "Following previous work [2, 5, 18], we add the special form (choose <exp0> <exp1> .", "startOffset": 24, "endOffset": 34}, {"referenceID": 4, "context": "Following previous work [2, 5, 18], we add the special form (choose <exp0> <exp1> .", "startOffset": 24, "endOffset": 34}, {"referenceID": 17, "context": "Following previous work [2, 5, 18], we add the special form (choose <exp0> <exp1> .", "startOffset": 24, "endOffset": 34}, {"referenceID": 0, "context": "The second POAPS value can be thought of as some unobservable measure of the quality of the text q \u2208 [0, 1].", "startOffset": 101, "endOffset": 107}, {"referenceID": 0, "context": "When c-imp is called, in addition to returning an improved string, a POAPS value q\u2032 \u2208 [0, 1] is also returned with probabilities defined by T .", "startOffset": 86, "endOffset": 92}, {"referenceID": 5, "context": "[6]) is used to guide the overall program objective.", "startOffset": 0, "endOffset": 3}, {"referenceID": 16, "context": "Construct a Hierarchical Abstract Machine (HAM) [17]M(p) by evaluating the program under a set of operational semantics.", "startOffset": 48, "endOffset": 52}, {"referenceID": 16, "context": "Following the insights of [17], mergeM(p) with S(p) to cre-", "startOffset": 26, "endOffset": 30}, {"referenceID": 16, "context": "The second step in the compilation process is to construct the machine state space by constructing a HAM [17]M(p) given p and S(p).", "startOffset": 105, "endOffset": 109}, {"referenceID": 16, "context": "These states were not necessary in [17] because their world was fully observable.", "startOffset": 35, "endOffset": 39}, {"referenceID": 9, "context": "M and (m\u25e6s)(p) are stochastically bisimilar [10] (we map each history to its corresponding belief state), and the optimal policy of (m \u25e6 s)(p) corresponds to that of (M \u25e6 S)(p) (Lemma 1), so the optimal policy for (M \u25e6 S)(p) can be used as an optimal policy forM (Lemma 1).", "startOffset": 44, "endOffset": 48}, {"referenceID": 8, "context": "This theorem also affirms that an optimal policy for our constructed POMDP is not just a \u201crecursively optimal\u201d [9] policy.", "startOffset": 111, "endOffset": 114}, {"referenceID": 20, "context": "While we try using a UCT-based solver, POMCP (without a rollout policy) 4 [21], we find that the value function can take an extraordinary amount of time to converge.", "startOffset": 74, "endOffset": 78}, {"referenceID": 2, "context": "Instead, we modify RTDP-Bel [3] to create C-RTDP, an algorithm similar to HAMQ-learning [17] that takes advantage of the fact that the actual complexity of the POMDP is determined by the number of choice points.", "startOffset": 28, "endOffset": 31}, {"referenceID": 16, "context": "Instead, we modify RTDP-Bel [3] to create C-RTDP, an algorithm similar to HAMQ-learning [17] that takes advantage of the fact that the actual complexity of the POMDP is determined by the number of choice points.", "startOffset": 88, "endOffset": 92}, {"referenceID": 15, "context": "\u201d Then it uses Wikification [16, 19] to find a set of possible Wikipedia articles describing the entity, such as \u201cWashington (state)\u201d and \u201cGeorge Washington,\u201d and asks workers to choose the article that best describes the entity.", "startOffset": 28, "endOffset": 36}, {"referenceID": 18, "context": "\u201d Then it uses Wikification [16, 19] to find a set of possible Wikipedia articles describing the entity, such as \u201cWashington (state)\u201d and \u201cGeorge Washington,\u201d and asks workers to choose the article that best describes the entity.", "startOffset": 28, "endOffset": 36}, {"referenceID": 6, "context": "This result is consistent with those in [7], showing that our general purpose implementation can perform at par compared to an expert-written problem-specific POMDP, suggesting the value of our system to end-users.", "startOffset": 40, "endOffset": 43}, {"referenceID": 3, "context": "We demonstrate the versatility of our paradigm by writing find-fix-verify [4], a more complex and popular workflow that can be used for crowdsourcing edits to text.", "startOffset": 74, "endOffset": 77}], "year": 2016, "abstractText": "We present POAPS, a novel planning system for defining PartiallyObservable Markov Decision Processes (POMDPs) that abstracts away from POMDP details for the benefit of non-expert practitioners. POAPS includes an expressive adaptive programming language based on Lisp that has constructs for choice points that can be dynamically optimized. Non-experts can use our language to write adaptive programs that have partially observable components without needing to specify belief/hidden states or reason about probabilities. POAPS is also a compiler that defines and performs the transformation of any program written in our language into a POMDP with control knowledge. We demonstrate the generality and power of POAPS in the rapidly growing domain of human computation by describing its expressiveness and simplicity by writing several POAPS programs for common crowdsourcing tasks.", "creator": "LaTeX with hyperref package"}}}