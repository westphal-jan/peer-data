{"id": "1608.08898", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-Aug-2016", "title": "A High Speed Multi-label Classifier based on Extreme Learning Machines", "abstract": "In this paper a high speed neural network classifier based on extreme learning machines for multi-label classification problem is proposed and dis-cussed. Multi-label classification is a superset of traditional binary and multi-class classification problems. The proposed work extends the extreme learning machine technique to adapt to the multi-label problems. As opposed to the single-label problem, both the number of labels the sample belongs to, and each of those target labels are to be identified for multi-label classification resulting in in-creased complexity. The proposed high speed multi-label classifier is applied to six benchmark datasets comprising of different application areas such as multi-media, text and biology. The training time and testing time of the classifier are compared with those of the state-of-the-arts methods. Experimental studies show that for all the six datasets, our proposed technique have faster execution speed and better performance, thereby outperforming all the existing multi-label clas-sification methods.", "histories": [["v1", "Wed, 31 Aug 2016 14:56:12 GMT  (423kb)", "http://arxiv.org/abs/1608.08898v1", "12 pages, 2 figures, 10 tables"]], "COMMENTS": "12 pages, 2 figures, 10 tables", "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.NE", "authors": ["meng joo er", "rajasekar venkatesan", "ning wang"], "accepted": false, "id": "1608.08898"}, "pdf": {"name": "1608.08898.pdf", "metadata": {"source": "CRF", "title": "A High Speed Multi-label Classifier based on Extreme Learning Machines", "authors": ["Ning Wang", "Meng Joo Er", "Rajasekar Venkatesan"], "emails": [], "sections": [{"heading": null, "text": "Meng Joo Er is a Chair at the Marine Engineering College, Dalian Maritime University, Dalian 116026, China, and works with Rajasekar Venkatesan at the School of Electrical and Electronics Engineering, NTU, Singapore; Ning Wang at the Marine Engineering College, Dalian Maritime University, Dalian 116026, China. Multi-label classification learning machines are proposed and discussed. Multi-label classification is a superset of traditional double and multi-class classification problems. The proposed work extends the extreme learning machine technology to adapt to multi-label problems. In contrast to the multi-label problem, both the number of labels to which the sample belongs and each of these multi-label target labels must be identified for multi-label classification, leading to increased complexity. The proposed high-speed multi-label classifier will include six test method sets that already include multiple-time classifications, such as multi-time classification."}, {"heading": "1 Introduction", "text": "In recent years, the problem of multi-label classification has become much more important, motivated by increasing fields of application such as text categorization [1-5], marketing, music categorization, emotion, genomics, medical diagnosis [6], image and video categorization, etc. The recent realization of the ubiquity of multi-label prediction tasks in the real world has attracted increased attention [7]. Classification in machine learning is defined as \"In view of a number of training examples composed of pairs {xi, yi}, find a function f (x) that maps each attribute vector xi to its associated class yi, i = 1,2,...., n, where n is the total number of training patterns.\" These classification problems are referred to as single-label classification. Single-label classification problems involve mapping each of the input vectors to its unique target class."}, {"heading": "2 Multi-label Classifier", "text": "The definition of multi-level learning according to [15] is: \"In view of a training set, the goal of multi-level learning is to produce a multi-level classifier h: X \u2192 Y that optimizes some specific evaluation functions or loss functions.\" Let's specify the probability that the initial sample will be assigned to a class from a pool of M target classes. For classification techniques such as binary and multi-level classifications, the following equality condition applies. (1) This equality does not apply to multi-level problems, as each sample may have more than one target class. It can also be seen that the binary classification problems, which include multi-level problems and ordinal regression problems, are specific instances of multi-level learning. (1) This equality does not apply to multi-level categorizations, as each group may have more than one target class."}, {"heading": "3 Proposed Approach", "text": "The key advantage of the ELM is that there are the smallest number of parameters that can be adjusted, and it can be trained at very high speed.The traditional BP network must be initialized to perform the classification [19-22].The most important steps in extending the ELM to multi-level problems are in the pre-processing and post-processing of data. In multi-level problems, each input pattern can belong to one or more examples. The number of input examples is not previously known."}, {"heading": "4 Experimentation", "text": "The number of labels, the number of labels that have multiple labels, the average number of labels that correspond to a given sample varies between different datasets. Two datasets are available in the literature to quantitatively measure the multi-labelness of a dataset: Label Cardinality (LC) and Label Density (LD). Consider N training samples and the datasets are of the form (xi, yi) in which the input data and yi the target label are set. The target label is a subset of labels from the label space with M elements, which is the data set as Y L, L = 2... asdinality 4.1 Label Cardinality."}, {"heading": "5 Results and Discussions", "text": "In this section, the results of the proposed method are discussed and compared with the existing methods, and the results of the proposed method are evaluated in terms of consistency, performance and speed."}, {"heading": "5.1 Consistency", "text": "The proposed algorithm should provide consistent results with minimal variance. Since the proposed algorithm is an ELM-based algorithm, it is of crucial importance to evaluate the consistency of the proposed technique, since the initial weights are randomly assigned. The unique feature of the multi-label classification is the possibility of partial correctness of the classifier, i.e. one or more of the multiple labels that include the sample instance and / or the number of labels, can be partially correctly identified. Therefore, the calculation of the error rate for multiple labeling problems is not the same as for conventional binary or multiclass problems. In order to quantitatively measure the correctative correctability of the classifier, the Hamming Performance Metric is used to evaluate the consistency of the proposed method (a 5-fold and a 10-fold cross-validation of the Hamming Consistency), 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.000- 0.0"}, {"heading": "5.2 Performance Metrics", "text": "As already indicated, the unique feature of multi-label classification is the possibility of partial correctness of the classifier. Therefore, a series of quantitative performance evaluation metrics is used to validate the performance of the multi-label classifier. Power metrics are hammering of loss, accuracy, precision, recall and F1 measurement. A comparison of power metrics such as hammering of loss, precision, recall, accuracy and F1 measurement of the proposed technique is presented in Tables 4-8. The performance of state-of-the-art techniques is adapted from [18]. Tables show that the proposed method works consistently well across all data sets. In most cases, the proposed method outperforms all existing methods and remains one of the leading classification techniques in other cases."}, {"heading": "5.3 Speed", "text": "The performance of the proposed method in terms of execution speed is evaluated by comparing the training time and the test time of the applied algorithm. The proposed method is applied to 6 sets of data in different areas with a wide range of label density and label cardinality, and the training time and test time are compared with other state-of-the-art techniques. The comparison table of training time and test time is given in Tables 9 and 10. In summary, the proposed method exceeds all existing multi-level learning techniques in terms of training and test time by several orders of magnitude. The results show that the proposed method is the fastest multi-level classifier compared to current state-of-the-art techniques. The speed of the proposed classifier is many times higher than the existing methods. Also, from the comparison results of other performance metrics such as hammering losses, accuracy, memory and F1 measurement, it can be seen that the proposed method remains one of the top positions in each case, exceeding the most important F1 formula during the other five terms proposed."}, {"heading": "6 Conclusion", "text": "The proposed high-speed multi-label classifier operates at both high speed and high accuracy. It should be noted that there is currently no extremely machine-assisted multi-label classifier in the literature, and the proposed method is applied to 6 benchmark datasets of different ranges and a wide range of label density and label cardinality; the results are compared with 9 state-of-the-art multi-label classifiers. Results show that the proposed method exceeds all state-of-the-art methods in terms of speed and remains one of the top techniques in terms of other performance indicators. Therefore, the proposed ELM-based multi-label classifier may be a better alternative for a wide range of multi-label classifier techniques to achieve greater accuracy and very high speed."}, {"heading": "Acknowledgements", "text": "This work is supported by the National Natural Science Foundation of P.R. China (under grants 51009017 and 51379002), Applied Basic Research Funds from the Ministry of Transportation of P.R. China (under grants 2012-329-225-060), China Postdoctoral Science Foundation (under grants 2012M520629), Program for Liaoning Excellent Talents in University (under grants LJQ2013055), and the second author thanks Nanyang Technological University for supporting this work by providing NTU RSS."}], "references": [{"title": "A Preliminary approach to the multi-label classification problem of Portuguese juridical documents", "author": ["T. Gonclaves", "P. Quaresma"], "venue": "Progress in Artificial Intelligence,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2003}, {"title": "Text categorization with support vector machines: Learning with many relevant features", "author": ["T. Joachims"], "venue": "Nedellec C, Rouveirol C (Ed.), ECML, LNCS,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1998}, {"title": "Evaluation of Two Systems on Multi-class Multi-label document classification", "author": ["X. Luo", "A.N. Zincir Heywood"], "venue": "ISMIS 2005, LNCS (LNAI),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2005}, {"title": "Experiments with multi-label text classifier on the Reuters collection", "author": ["D. Tikk", "G Biro"], "venue": "Proceedings of the International Conference on Computational Cybernetics (ICCC 2003),", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2003}, {"title": "Multi-label informed latent semantic indexing", "author": ["K. Yu", "S. Yu", "V. Tresp"], "venue": "Proceedings of the 28th annual international ACM SIGIR conference on Research and Development in information retrieval,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2005}, {"title": "Mining Multi-label Data\u201d, Data Mining and Knowledge Discovery Handbook", "author": ["G. Tsoumakas", "I. Katakis", "I. Vlahavas"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2010}, {"title": "A Tutorial on Multi-label Classification Techniques", "author": ["A.C. de Carvalho", "A.A. Freitas"], "venue": "Foundations of Computational Intelligence,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2009}, {"title": "A kernel method for multi-labelled classification", "author": ["A. Elisseeff", "J. Weston"], "venue": "Neural Information Processing Systems, NIPS,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2001}, {"title": "A k-nearest neighbour based algorithm for multi-label classification", "author": ["M.L. Zhang", "Z.H. Zhou"], "venue": "Proceedings of the 1st IEEE international Conference on Granular Computing, Beijing,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2005}, {"title": "Brouwn, \u201cMulti-label semantic scene classification", "author": ["M. Boutell", "X. Shen", "C.J. Luo"], "venue": "Technical Report,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2003}, {"title": "Multi-label machine learning and its application to semantic scene classification. Storage and Retrieval Methods and Applications for Multimedia", "author": ["X. Shen", "M. Boutell", "J. Luo", "C. Brown"], "venue": "Yeung MM, Lienhart RW, Li CS (Ed.), Proceedings of the SPIE,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2003}, {"title": "Efficient Approximation Algorithms for Multi-label Map Labelling", "author": ["B. Zhu", "C.K. Poon"], "venue": "Algorithms and Computation,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1999}, {"title": "ML-kNN: A lazy learning approach to multi-label learning", "author": ["M.L. Zhang", "Z.H. Zhou"], "venue": "Pattern Recognition,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2007}, {"title": "Sorower, \"A literature survey on algorithms for multi-label learning.", "author": ["S. M"], "venue": "Oregon State University, Corvallis,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2010}, {"title": "Kernel methods for multi-labelled classification and categorical regression problems", "author": ["A. Elisseeff", "J. Weston J"], "venue": "Technical Report, BIOwulf Technologies,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2001}, {"title": "Multi-label Classification: An Overview", "author": ["G. Tsoumakas", "I. Katakis"], "venue": "International Journal of Data Warehousing and Mining,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2007}, {"title": "An extensive experimental comparison of methods for multi-label learning", "author": ["G. Madjarov", "D. Kocev", "D. Gjorgjevikj", "S. Dzeroski"], "venue": "Pattern Recognition,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2012}, {"title": "A novel extreme learning control framework of unmanned surface vehicles", "author": ["N. Wang", "J.C. Sun", "M.J. Er", "Y.C. Liu"], "venue": "IEEE Transactions on Cybernetics, Accepted for Publication,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2015}, {"title": "Generalized single-hidden layer feedforward networks for regression problems", "author": ["N. Wang", "M.J. Er", "M. Han"], "venue": "IEEE Transactions on Neural Networks and Learning Systems,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2015}, {"title": "Extreme learning machines: a survey,", "author": ["G.B. Huang", "D.H. Wang", "Y. Lan"], "venue": "International Journal of Machine Learning and Cybernetics,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2011}, {"title": "Extreme learning machine: algorithm, theory and applications", "author": ["S. Ding", "H. Zhao", "Y. Zhang", "X. Xu", "R. Nie"], "venue": "Artificial Intelligence Review,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2013}, {"title": "Analyzing the Influence of Cardinality and Density", "author": ["F.C. Bernardini", "R.B. da Silva", "E.M. Meza", "R. das Ostras\u2013RJ\u2013Brazil"], "venue": "Characteristics on Multi-Label Learning\u201d,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2009}], "referenceMentions": [{"referenceID": 0, "context": "In recent years, the problem of multi-label classification is gaining much importance motivated by increasing application areas such as text categorization [1-5], marketing, music categorization, emotion, genomics, medical diagnosis [6], image and video categorization, etc.", "startOffset": 156, "endOffset": 161}, {"referenceID": 1, "context": "In recent years, the problem of multi-label classification is gaining much importance motivated by increasing application areas such as text categorization [1-5], marketing, music categorization, emotion, genomics, medical diagnosis [6], image and video categorization, etc.", "startOffset": 156, "endOffset": 161}, {"referenceID": 2, "context": "In recent years, the problem of multi-label classification is gaining much importance motivated by increasing application areas such as text categorization [1-5], marketing, music categorization, emotion, genomics, medical diagnosis [6], image and video categorization, etc.", "startOffset": 156, "endOffset": 161}, {"referenceID": 3, "context": "In recent years, the problem of multi-label classification is gaining much importance motivated by increasing application areas such as text categorization [1-5], marketing, music categorization, emotion, genomics, medical diagnosis [6], image and video categorization, etc.", "startOffset": 156, "endOffset": 161}, {"referenceID": 4, "context": "In recent years, the problem of multi-label classification is gaining much importance motivated by increasing application areas such as text categorization [1-5], marketing, music categorization, emotion, genomics, medical diagnosis [6], image and video categorization, etc.", "startOffset": 156, "endOffset": 161}, {"referenceID": 5, "context": "Recent realization of the omnipresence of multi-label prediction tasks in real world problems has drawn increased research attention [7].", "startOffset": 133, "endOffset": 136}, {"referenceID": 6, "context": ",n, where n is the total number of training samples\u201d [8].", "startOffset": 53, "endOffset": 56}, {"referenceID": 7, "context": "By the recent advancements in technology, the application areas of multi-label classifiers spread across various domains such as text categorization, bioinformatics [9-10], medical diagnosis, scene classification [11-12], map labeling [13],", "startOffset": 165, "endOffset": 171}, {"referenceID": 8, "context": "By the recent advancements in technology, the application areas of multi-label classifiers spread across various domains such as text categorization, bioinformatics [9-10], medical diagnosis, scene classification [11-12], map labeling [13],", "startOffset": 165, "endOffset": 171}, {"referenceID": 9, "context": "By the recent advancements in technology, the application areas of multi-label classifiers spread across various domains such as text categorization, bioinformatics [9-10], medical diagnosis, scene classification [11-12], map labeling [13],", "startOffset": 213, "endOffset": 220}, {"referenceID": 10, "context": "By the recent advancements in technology, the application areas of multi-label classifiers spread across various domains such as text categorization, bioinformatics [9-10], medical diagnosis, scene classification [11-12], map labeling [13],", "startOffset": 213, "endOffset": 220}, {"referenceID": 11, "context": "By the recent advancements in technology, the application areas of multi-label classifiers spread across various domains such as text categorization, bioinformatics [9-10], medical diagnosis, scene classification [11-12], map labeling [13],", "startOffset": 235, "endOffset": 239}, {"referenceID": 12, "context": "Multi-label problems are more difficult and more complex compared to single-label problems due to its generality [14].", "startOffset": 113, "endOffset": 117}, {"referenceID": 13, "context": "The definition for multi-label learning as given by [15] is; \u201cGiven a training set, S = (xi, yi), 1 \u2264 i \u2264 n, consisting of n training instances, (xi \u03b5 X, yi \u03b5 Y) drawn from an unknown distribution D, the goal of multi-label learning is to produce a multi-label classifier h:X\u2192Y that optimizes some specific evaluation function or loss function\u201d.", "startOffset": 52, "endOffset": 56}, {"referenceID": 14, "context": "Also, it can be seen that the binary classification problems, the multi-class problems and ordinal regression problems are specific instances of the multi-label problems with the number of labels corresponding to each data sample restricted to 1 [16].", "startOffset": 246, "endOffset": 250}, {"referenceID": 15, "context": "Earlier categorization of the multi-label (ML) methods [17] classify the methods into two categories, namely, Problem Transformation (PT) and Algorithm Adaptation (AA)", "startOffset": 55, "endOffset": 59}, {"referenceID": 16, "context": "This categorization is extended to include a third category of methods by Gjorgji Madjarov et al [18] called Ensemble methods (EN).", "startOffset": 97, "endOffset": 101}, {"referenceID": 5, "context": "Several review articles are available in the literature that describe various methods available for multi-label classification [7,8,15,17,18].", "startOffset": 127, "endOffset": 141}, {"referenceID": 6, "context": "Several review articles are available in the literature that describe various methods available for multi-label classification [7,8,15,17,18].", "startOffset": 127, "endOffset": 141}, {"referenceID": 13, "context": "Several review articles are available in the literature that describe various methods available for multi-label classification [7,8,15,17,18].", "startOffset": 127, "endOffset": 141}, {"referenceID": 15, "context": "Several review articles are available in the literature that describe various methods available for multi-label classification [7,8,15,17,18].", "startOffset": 127, "endOffset": 141}, {"referenceID": 16, "context": "Several review articles are available in the literature that describe various methods available for multi-label classification [7,8,15,17,18].", "startOffset": 127, "endOffset": 141}, {"referenceID": 16, "context": "As adapted from [18], an overview of multi-label methods available in the literature is given in Fig.", "startOffset": 16, "endOffset": 20}, {"referenceID": 16, "context": "2, adapted from [18].", "startOffset": 16, "endOffset": 20}, {"referenceID": 17, "context": "On the other hand, in ELM, the initial weights and the hidden layer bias can be selected at random and the network can be trained for the output weights in order to perform the classification [19-22].", "startOffset": 192, "endOffset": 199}, {"referenceID": 18, "context": "On the other hand, in ELM, the initial weights and the hidden layer bias can be selected at random and the network can be trained for the output weights in order to perform the classification [19-22].", "startOffset": 192, "endOffset": 199}, {"referenceID": 19, "context": "The theory and mathematics behind the ELM have been extensively discussed in [23-25] and hence are not re-stated here.", "startOffset": 77, "endOffset": 84}, {"referenceID": 20, "context": "The theory and mathematics behind the ELM have been extensively discussed in [23-25] and hence are not re-stated here.", "startOffset": 77, "endOffset": 84}, {"referenceID": 15, "context": "1 [17] Label Cardinality of the dataset is the average number of labels of the examples in the dataset.", "startOffset": 2, "endOffset": 6}, {"referenceID": 15, "context": "2 [17] Label Density of the dataset is the average number of labels of the examples in the dataset divided by |L|.", "startOffset": 2, "endOffset": 6}, {"referenceID": 12, "context": "The properties of two datasets have same label cardinality, but different label density can vary significantly and may result in different behavior of the training algorithm [14].", "startOffset": 174, "endOffset": 178}, {"referenceID": 21, "context": "The influence of label density and label cardinality on multi-label learning is analyzed by Flavia et al in 2013 [26].", "startOffset": 113, "endOffset": 117}, {"referenceID": 16, "context": "The performance of state-of-the-art techniques is adapted from [18].", "startOffset": 63, "endOffset": 67}], "year": 2015, "abstractText": "In this paper a high speed neural network classifier based on extreme learning machines for multi-label classification problem is proposed and discussed. Multi-label classification is a superset of traditional binary and multiclass classification problems. The proposed work extends the extreme learning machine technique to adapt to the multi-label problems. As opposed to the singlelabel problem, both the number of labels the sample belongs to, and each of those target labels are to be identified for multi-label classification resulting in increased complexity. The proposed high speed multi-label classifier is applied to six benchmark datasets comprising of different application areas such as multimedia, text and biology. The training time and testing time of the classifier are compared with those of the state-of-the-arts methods. Experimental studies show that for all the six datasets, our proposed technique have faster execution speed and better performance, thereby outperforming all the existing multi-label classification methods.", "creator": "Microsoft\u00ae Word 2013"}}}