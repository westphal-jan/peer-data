{"id": "1609.01933", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Sep-2016", "title": "Sentiment Classification of Food Reviews", "abstract": "Sentiment analysis of reviews is a popular task in natural language processing. In this work, the goal is to predict the score of food reviews on a scale of 1 to 5 with two recurrent neural networks that are carefully tuned. As for baseline, we train a simple RNN for classification. Then we extend the baseline to GRU. In addition, we present two different methods to deal with highly skewed data, which is a common problem for reviews. Models are evaluated using accuracies.", "histories": [["v1", "Wed, 7 Sep 2016 10:59:58 GMT  (1036kb)", "http://arxiv.org/abs/1609.01933v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["hua feng", "ruixi lin"], "accepted": false, "id": "1609.01933"}, "pdf": {"name": "1609.01933.pdf", "metadata": {"source": "CRF", "title": "Sentiment Classification of Food Reviews", "authors": ["Hua Feng", "Ruixi Lin"], "emails": ["rlin2@stanford.edu", "fengh15@stanford.edu"], "sections": [{"heading": "2 Problem Statement", "text": "To predict the perceptions of reviews, we mark each review with a rating from the evaluator indicating the opinion of the evaluator. Our task is to predict the rating of an evaluator on a scale of 1 to 5, with 1 indicating that the evaluator strongly disapproves of the food he or she mentions in the review, and 5 indicating that the user likes the food very much."}, {"heading": "3 Related Work", "text": "Conventional approaches to sentiment analysis use the number of words or frequencies in the text to which an expert assigns a sentiment value [1]. These approaches ignore the sequence of words. A recursive neural network (RNN) [2] can be used to sequence data of varying lengths, which is natural for sentiment analysis tasks where the input sentence is seen as a sequence of tokens. Recent work examines the neural network of gated recurrent units (GRU) [3] in the task of sentiment classification. GRUs are a special case of the neural network architecture Long Short Term (LSTM). GRUs are effective in this task because they can remember long time dependencies. In addition, GRUs are quicker to train and converge than LSTM networks."}, {"heading": "4 Dataset", "text": "We are working on the dataset of Amazon Fine Food Reviews [4], which contains 568,454 reviews; the dataset consists of a single CSV file containing the product Ids, reviewer Ids, the reviews indicated by the reviewers (rating between 1 and 5), the timestamp for each review, a brief summary for each review and the text of the reviews. We extract the columns of the reviews and review texts as our labels and raw materials. Sample reviews with different ratings are shown below: review result product came labeled as Jumbo salted peanuts... 1 the peanuts were actually small sized unsalted. Not sure if this was a mistake or the seller intended to present the product as \"Jumbo.\" I have purchased several of the vitality preserved dog food 5 products and have found them all to be of good quality."}, {"heading": "5 Mathematical Formulations", "text": "5 M o d i f i e d R e c u r r n t J e u r a l N e t w o r k (R N N) Our version of RNN is a slightly modified version of the standard RNN. Instead of delivering the classification prediction at each word, we build the model to output prediction at the end of each epoch. We make this modification to lessen the influence of frequent words on prediction and backward propagation. Let T represent the number of steps, for each epoch slice (#),..., (#) the prediction is defined as: #,"}, {"heading": "6 Experiments & Results", "text": "We evaluate both resampling methods. We implement the simple RNN, the modified RNN and a GRU with Python tensor flow and measure the traction, validation and accuracy of each classifier we build. We visualize the hidden layer weights to see how the hidden units behave and adjust hyperparameters to improve accuracy. 6. 1 D a t a P re - p ro c e s i n g 6. 1 S a m p l i n g m e h o d 1: re m o v e a l d a t a f ro m t c l a s sSince the main source of the data skews is the highest scoring class, which has about ten times as many ratings as any of the other classes, we use a simple method to avoid the problem."}, {"heading": "6 .2 Im p lem en ta t io n o f R N N", "text": "Word vectors are initialized as random values evenly distributed over [-1, 1]. To ensure that sentences of 8 words come from the same review within each epoch intersection, we set the reviews to 88 words at the beginning of each review. Zero padding is performed at the beginning of each review, because if zero padding occurs at the end, the back propagation encounters several identical hidden layers before it spreads to an actual word, causing more serious gradient problems., 11, 13, (=) and > are updated during the training process and applied during validation and verification. L is the embedding matrix for words. The last predicted class for each review is the class with the maximum value in the review elements, where goodness is the output at the end of the corresponding review (EOS)."}, {"heading": "6 .3 Im p lem en ta t io n o f G R U", "text": "For GRU, we use the same dataset, the same number of steps, and the same initialization strategy of word vectors as RNN. Training is applied to datasets with / without zero padding.L, () () (),,,, z r rW W U U U U and W are updated during the training process and applied in validation and verification. L is the embedding matrix for words. The output prediction at the end of each review is used as the final prediction of each class, just like RNN, to provide a fair comparison of performance."}, {"heading": "6 .4 H yp er-P aram eters Tu n in g", "text": "In order to set and find the right hyperparameters for our model, we divide our data into three groups: a training set, a validation set for cross-validation, and a test set used as final predictive values. In this section, we describe how we performed our tuning and recorded the accuracies depending on it. For each of the models, learning rate, L2 regularization weight, and dropout value must be matched. Due to time and computational resource constraints, we did not match some parameters such as hidden layer size and could not iteratively optimize the parameters that would have led to the optimal setting. Instead, we set some parameters to reasonable values and match the others. The following figures show the tuning results. The optimal parameters we found for our models are as follows: RNN, 4 classes (lr = 10) B, l2 = 0.009, dropout classes (GR = 0.009)."}, {"heading": "6 .5 A ccu rac ie s", "text": "After adjusting the hyperparameters, we use the optimal set of hyperparameters to train and test our model and evaluate performance by accuracy. Accuracy is calculated by the number of correctly labeled reviews over the total number of reviews, with the predicted label at the end of a review considered to be the final predicted label for that review. For our specific data, we did not find any work on the same problem, so we do not have the state-of-the-art result. For comparison purposes, we also train RNN models with output in each step and GRU models without zero padding.In the 4-class prediction task, the best model in our experiment is the modified RNN. Our slightly modified RNN exceeds the original RNN, which is output in each step, in the 5-class prediction task. In the 5-class prediction task, RNN and GRU achieve comparable accuracies, while RNN slightly exceeds the original RNN, which is output in each step."}, {"heading": "6 .6 Vi su a l i za t io n o f H id d en L a y er Weig h t s", "text": "In order to demonstrate the effect of the training under different strategies, we present in this section the visualization of a hidden layer in the first and last epoch. For our modified RNN, the hidden layers for different classes in epoch 0 (shown in Figure 4 (a)) look quite similar, since the word vectors are randomly initialized. However, in the last epoch of the training, the hidden layers differ significantly under different labels. For example, hidden layers under 3- and 4-star ratings have higher values around the 40th dimension than hidden layers under 1 and 2 star.F i g u r e 4 (a).F i g u u u r 4 (a).H i d e d e e d e e e e e c h h e r R N e e n r N a t a t e e e e e a t a t e."}, {"heading": "7 Conclusion", "text": "In this paper, we present various neural network approaches, including 2 versions of RNN and GRU for sentiment classification on the Amazon Fine Food Reviews dataset, achieving 68.75% test accuracy on the 4-class classification task and 51.74% on the 5-class classification task on the test set. In our experiment, we found that adding zeros to ratings proves useful and the zeros approaches outperform the approaches we implement. Future work could focus on trying more RNN models, such as tuning the bidirectional RNN and other parameters such as hidden layer size and number of steps. R e e re re c e s [1] Bo, P. (2008) Opinion Mining and Sentiment Analysis, Foundations and Trends in Information retrieval, 2 (1-2): pp."}], "references": [{"title": "Opinion Mining and Sentiment Analysis, Foundations and trends", "author": ["P. Bo"], "venue": "in information retrieval,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2008}, {"title": "Recurrent neural network based language model", "author": ["T. Mikolov", "M. Karafi\u00e1t", "L. Burget", "J. Cernock\u00fd", "Khudanpur", "September"], "venue": "In INTERSPEECH,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2010}, {"title": "Gated feedback recurrent neural networks. arXiv preprint arXiv:1502.02367", "author": ["J. Chung", "C. Gulcehre", "K. Cho", "Y. Bengio"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2015}, {"title": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "author": ["J.J. McAuley", "Leskovec", "May"], "venue": "In Proceedings of the 22nd international conference on World Wide Web (pp. 897-908)", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2013}, {"title": "Lecture Notes: Part IV. CS224D: Deep Learning for NLP", "author": ["M. Mohammadi", "R. Mundra", "R. Socher"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "3 Related Work Traditional approaches on sentiment analysis use word count or frequencies in the text which are assigned sentiment value by expert[1].", "startOffset": 146, "endOffset": 149}, {"referenceID": 1, "context": "A recurrent neural network (RNN)[2] can be used for sequence labeling on sequential data of variable length, which is natural for sentiment analysis tasks where the input sentence is viewed as a sequence of tokens.", "startOffset": 32, "endOffset": 35}, {"referenceID": 2, "context": "network(GRU)[3] on the task of sentiment classification.", "startOffset": 12, "endOffset": 15}, {"referenceID": 3, "context": "4 Dataset We work on the Amazon Fine Food Reviews dataset[4] which contains 568,454 reviews.", "startOffset": 57, "endOffset": 60}, {"referenceID": 4, "context": "2 G a t e d R e c u r re n t U n i t s The mathematical formulation of GRU at each time step is defined as follows[5]:", "startOffset": 114, "endOffset": 117}, {"referenceID": 0, "context": "2 Im p lem en ta t io n o f R N N Word vectors are initialized as random values uniformly distributed between [-1, 1].", "startOffset": 110, "endOffset": 117}, {"referenceID": 0, "context": "R e f e re n c e s [1] Bo, P.", "startOffset": 19, "endOffset": 22}, {"referenceID": 1, "context": "1561/1500000011 [2] Mikolov, T.", "startOffset": 16, "endOffset": 19}, {"referenceID": 2, "context": "[3] Chung, J.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4] McAuley, J.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5] Mohammadi, M.", "startOffset": 0, "endOffset": 3}], "year": 2016, "abstractText": "Sentiment analysis of reviews is a popular task in natural language processing. In this work, the goal is to predict the score of food reviews on a scale of 1 to 5 with two recurrent neural networks that are carefully tuned. As for baseline, we train a simple RNN for classification. Then we extend the baseline to modified RNN and GRU. In addition, we present two different methods to deal with highly skewed data, which is a common problem for reviews. Models are evaluated using accuracies. 1 Introduction Binary classification of sentiment on reviews are an increasingly popular task in NLP. Instead of classifying positive reviews and negative reviews, we classify reviews into extremely negative, negative, neutral, positive, and extremely positive classes directly from the reviewer\u2019s score on a topic. We train a simple RNN classifier, a modified RNN classifier and a GRU classifier. Our analysis could be a useful tool to help restaurants better understand reviewers\u2019 sentiment about food, and can be used for other tasks such as recommender systems. 2 Problem Statement In order to predict sentiments of reviews, we label each review with a reviewer\u2019s score indicating the sentiment of the reviewer. Our task is to predict a reviewer\u2019s score on a scale of 1 to 5, where 1 indicates the reviewer extremely dislikes the food he or she mentions in the review and 5 indicates the user likes the food a lot. 3 Related Work Traditional approaches on sentiment analysis use word count or frequencies in the text which are assigned sentiment value by expert[1]. These approaches disregard the order of words. A recurrent neural network (RNN)[2] can be used for sequence labeling on sequential data of variable length, which is natural for sentiment analysis tasks where the input sentence is viewed as a sequence of tokens. Recent works explore the Gated Recurrent Units neural network(GRU)[3] on the task of sentiment classification. GRUs are a special case of the Long Short-Term(LSTM) neural network architecture. GRUs are effective in this task because of their ability to remember long time dependencies. Furthermore, GRUs are faster to train and converge than LSTM networks. 4 Dataset We work on the Amazon Fine Food Reviews dataset[4] which contains 568,454 reviews. The dataset consists of a single CSV file, which includes the ids of the products, ids of the reviewers, the scores(rating between 1 and 5) given by the reviewers, the timestamp for each review, a brief summary for each review, and the text of the reviews. We extract the columns of scores and review texts as our labels and raw inputs. Sample reviews with different scores are shown below: Review Score Product arrived labeled as Jumbo Salted Peanuts... 1 the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\". I have bought several of the Vitality canned dog food 5 products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than most. In order to perform mini-batch training for the neural network models, we want tokens within each slice of epoch to come from the same review. To make this happen, we need to compensate reviews with <unk>s to the maximum length of all reviews. To introduce as fewer <unk>s as possible, we do not want the reviews differ greatly in length. In this case, we would like to keep only reviews of similar lengths. We need to determine the range of lengths of reviews. In our analysis of the original dataset, we found that the average length of reviews is 80, so we choose reviews between 75 and 87 tokens and generate a dataset of 34,091 reviews. Another problem with the dataset is that the reviews are skewed towards higher scores, especially towards the highest score, which is 5. In the 34,091 reviews, 3,550 reviews are labeled with 1, 2,085 reviews are labeled with 2, 2,844 are labeled with 3, while 4,971 reviews are labeled with 4 and an even larger volume of 20,641 reviews are labeled with 5. As is shown in figure 1, score-2 class has the lowest number of reviews, which may lead to difficulty in predicting score-2. Score-5 class has the highest number of reviews as expected, which is around ten times of that of score-2 class. To take care of the skewedness issue, we introduce two resampling methods to produce a more balanced dataset. The methods will be discussed in section 6. Figure 1: Number of reviews of each score in the Amazon Food Reviews dataset. 5 Mathematical Formulations 5 . 1 M o d i f i e d R e c u r re n t N e u r a l N e t w o r k ( R N N ) Our version of RNN is a slightly modified version of the standard RNN. Instead of providing classification prediction at each word, we build the model to output prediction at the end of each epoch slice. We make this modification in order to reduce the influence of frequent words on the prediction and backpropagation. Let T represents the number of steps, For each epoch slice x(#), ... , x(#'()*) , the forward propagation is defined as: h #', = \t\r  \u03c3 W 11 h #',)* \t\r  + W 13 x #', + \t\r  b* \t\r   (1) y(#'()*)/( = softmax(W = h #'()* + \t\r  b>) (2) Where k = 0, 1,...T-1, x(#',) is the word vector embedding for the (t+k) th word in the review, h #', is the (t+k)th hidden layer and y(#'()*)/( is the prediction output at the (t+T-1)/T th epoch slice. Details of implementation can be seen in section 6.2. Cross-entropy error is used as loss function, the expression for a corpus size of K is as follow: / / ( ) , , 1 1 1 ( ) log( ) T K T K C Kt t c t c t t c T T J J y y K K \u03b8 = = = = \u2212 = \u2212 \u2211 \u2211\u2211 (3) Where T is the number of steps, C is the total number of class and t y is the one hot vector representation of the label at t-th epoch slice and , t c y is its element in class c. 5 . 2 G a t e d R e c u r re n t U n i t s The mathematical formulation of GRU at each time step is defined as follows[5]: ( ) ( ) ( ) ( ) ( 1) ( ) ( ) ( ) ( ) ( 1)", "creator": "Word"}}}