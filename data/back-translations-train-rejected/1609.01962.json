{"id": "1609.01962", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Sep-2016", "title": "Using Gaussian Processes for Rumour Stance Classification in Social Media", "abstract": "Social media tend to be rife with rumours while new reports are released piecemeal during breaking news. Interestingly, one can mine multiple reactions expressed by social media users in those situations, exploring their stance towards rumours, ultimately enabling the flagging of highly disputed rumours as being potentially false. In this work, we set out to develop an automated, supervised classifier that uses multi-task learning to classify the stance expressed in each individual tweet in a rumourous conversation as either supporting, denying or questioning the rumour. Using a classifier based on Gaussian Processes, and exploring its effectiveness on two datasets with very different characteristics and varying distributions of stances, we show that our approach consistently outperforms competitive baseline classifiers. Our classifier is especially effective in estimating the distribution of different types of stance associated with a given rumour, which we set forth as a desired characteristic for a rumour-tracking system that will warn both ordinary users of Twitter and professional news practitioners when a rumour is being rebutted.", "histories": [["v1", "Wed, 7 Sep 2016 12:33:02 GMT  (57kb,D)", "http://arxiv.org/abs/1609.01962v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.IR cs.SI", "authors": ["michal lukasik", "kalina bontcheva", "trevor cohn", "arkaitz zubiaga", "maria liakata", "rob procter"], "accepted": false, "id": "1609.01962"}, "pdf": {"name": "1609.01962.pdf", "metadata": {"source": "CRF", "title": "Using Gaussian Processes for Rumour Stance Classification in Social Media", "authors": ["MICHAL LUKASIK", "KALINA BONTCHEVA", "TREVOR COHN", "ARKAITZ ZUBIAGA", "MARIA LIAKATA"], "emails": [], "sections": [{"heading": null, "text": "Using the Gaussian Processes for Rumour Stance Classification in Social MediaMICHAL LUKASIK, University of Sheffield KALINA BONTCHEVA, University of Sheffield TREVOR COHN, University of Melbourne ARKAITZ ZUBIAGA, University of Warwick MARIA LIAKATA, University of Warwick ROB PROCTER, University of WarwickSocial media tend to be brimming with rumors, while new reports are released piecemeal during news delivery. Interestingly, you can query multiple responses from social media users in these situations, examine their attitude to rumors, and ultimately allow the spouting of highly controversial rumors as potentially false. In this work, we have set out to develop an automated, monitored classifier that uses multi-task learning to classify the attitudes expressed in each tweet in a rumor conversation in such a way that rumor is either supported, denied, or challenged."}, {"heading": "1. INTRODUCTION", "text": "There is an increasing need to interpret and handle rumors that spread quickly through social media, where new reports are published and often have an unspecified status at the time of publication."}, {"heading": "2. RELATED WORK", "text": "This section provides a more in-depth motivation for the task of detecting rumors and an overview of the state of the art and its limitations. However, let us first introduce the formal definition of a rumor."}, {"heading": "2.1. Rumour Definition", "text": "There have been several attempts to define rumors in the literature, most of which are complementary, with slight variations depending on the context of their analyses; the core concept on which most researchers agree is in line with the definition provided by important dictionaries, such as Oxford English Dictionary1, which defines a rumor as \"a story currently circulating or a report of uncertain or dubious truth.\" Researchers have long studied the properties of rumors to understand their diffusion patterns and distinguish them from other types of information that people usually share [Donovan 2007]; Allport and Postman [Rumport and Postman 1947] claimed that rumors spread due to two factors: people want to find meaning in things and, when confronted with ambiguity, people try to find meaning by telling stories. The latter factor also explains why rumors tend to change over time, becoming shorter, and we view these factors as uncertain."}, {"heading": "2.2. Descriptive Analysis of Rumours in Social Media", "text": "A particularly influential piece of work in the field of rumor analysis on social media is that of Mendoza et al. [Mendoza et al. 2010]. By manually analyzing the data of the 2010 earthquake in Chile, the authors selected 7 confirmed truths and 7 false rumors, each of which consists of almost 1000 tweets or more. The veracity of the stories selected was confirmed by the use of reliable sources. Each tweet from each of the news articles was manually classified into one of the following categories: affirmation, denial, questioning, unknown or unrelated to celebrities. Thus, each tweet was classified according to the position in which it was the topic. The study showed that a much higher percentage of tweets about false rumors is shown to deny the respective rumors (about 50%), in contrast to rumors that later proved to be true, where only 0.3% of the tweets were denials. Based on this, authors claimed that rumors can be proven by aggregate analyses."}, {"heading": "2.3. Rumour Stance Classification", "text": "They have introduced a system that analyzes a series of tweets related to a specific topic predefined by the user. Your system would then classify each of the tweets as supportive, denying or questioning rumors. We have adopted this scheme in terms of the different types of attitudes in the work that we report here. However, their work ended with the merging of denying and questioning tweets for each rumor into a single class that transforms it into a 2-way classification problem that supports rumors against denying-questioning. Instead, we keep these classes separate and follow Procter et al., we perform a 3-way classification by [Zubiaga et al. 2014]. Another important feature that distinguishes Qazvinian et al's work from our work is that it supports and denies long-standing rumors, such as the fact that many people suspect whether Barack Obama is a Muslim or not."}, {"heading": "3. PROBLEM DEFINITION: TWEET LEVEL RUMOUR STANCE CLASSIFICATION", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1. Definition of the Task", "text": "Individual tweets can discuss the same rumor in different ways, with each user expressing his or her own attitude toward the rumor. In this scenario, we define the classification task of the rumor attitude at the Twitter level as that where a classifier must determine the attitude of each tweet toward the rumor. Specifically, given the tweet ti, the classifier must determine which of the defined tasks Y = \"support, deny, question\" applies to the tweet. Here, we define the task as a supervised classification problem where the classifier is formed from a designated group of tweets and applied to tweets to a new, invisible group of rumors."}, {"heading": "3.2. Problem formulation", "text": "Let R be a series of rumors, each of which consists of tweets discussing it. Each tweet is classified as supportive, denied or questioned in relation to its rumor: y (ti) {s, d, q}. We formulate the problem in two different settings. First, we consider the setting Leave One Out (LOO), which means that for each rumor R we construct the test set equal to Tr and the training set equal to T\\ Tr. This is the most difficult scenario in which the test set contains a completely invisible rumor. Second, the setting is Leave Part Out (LPO). In this formulation, a very small number of initial tweets from the target rumor are added to the training set {tr1, \u00b7 rn, trrk}."}, {"heading": "3.3. Datasets", "text": "We have used two recent datasets from our previous work for our study, both of which are adapted to our needs. We do not use the datasets of [Qazvinian et al. 2011] given that there is a different type of annotation limited to two categories of annotations. The reason we use the two datasets separately is that they have very different characteristics. Instead, our experiments allow us to assess the ability of our classifier to deal with these different characteristics. 3.1. England riots dataset dataset consists of several rumors circulating on Twitter (see Table II). The datasets were collected by assigning a long set of keywords associated with the event. The dataset-dataset-dataset-dataset-dataset-dataset-dataset-datasets are used as support, questioned, questioned, questioned, questioned, or denied."}, {"heading": "4. EXPERIMENT SETTINGS", "text": "This section describes the characteristics and evaluation standards used in our experiments to classify attitudes at the tweet level."}, {"heading": "4.1. Classifiers", "text": "We start by describing the classifiers we use for our experiments, including the Gaussian processes, as well as a number of competitive base classifiers that we use for comparisons. Gaussian processes are a successful, non-parametric machine learning system that has proven to be good for a number of NLP problems that often surpass other state-of-the-art methods [Cohn and Specia 2013; Lampos et al. 2014; Beck et al. 2014; Preotiuc-Pietro et al. 2015].A Gaussian Process defines an earlier mode of operation that, when combined with the probability of data points, leads to a posterior function that explains the data. The key concept is a core function that specifies how the outputs function correctly as a function of input."}, {"heading": "4.2. Features", "text": "All words have been converted to lowercase letters; stopwords have been removed; all emoticons have been replaced by Words4; and they have been performed. In addition, several incidents of a character have been replaced by a double occurrence [Agarwal et al. 2011] to correct misspellings and lengths, e.g. looool. All punctuations have also been removed, except for., and?, which we consider important to express emotions. Finally, usernames have been removed as they tend to be rumour-specific, i.e., very few users comment on the text data we use to represent the resulting words (BOW) and replace all words with their brown clusters."}, {"heading": "4.3. Evaluation Measures", "text": "Accuracy is often considered an appropriate evaluation metric to judge a classifier's performance on a multi-stage classification task = F1 classification task. However, in our case, the classes are clearly unbalanced, with different tendencies to one of the classes in each of the rumors. We argue that in these scenarios, the only evaluation based on accuracy is insufficient and further measurements are needed to account for the imbalance in the category. This is particularly necessary in our case, since a classifier that always predicts the majority class in an unbalanced dataset will achieve high accuracy even if the classifier is useless in practice. To address this, we use both microaveraged and macro-averaged F1 values."}, {"heading": "5. RESULTS", "text": "First, we look at the results for each set of data individually, then we complement the analysis by aggregating the results from both sets of data, leading to a better understanding of the performance of our classifiers in classifying rumors."}, {"heading": "5.1. Comparison of Classifiers", "text": "In fact, most of them are able to survive themselves if they do not see themselves able to survive themselves, \"he told the German Press Agency in an interview with\" Welt am Sonntag \":\" I don't think they are able to survive themselves. \""}, {"heading": "5.2. Analysing the Performance of the Best-Performing Classifiers", "text": "We delve into the results of the most powerful classifiers, namely GP-ICM, MaxEnt, and RF, when looking at their class performance, which will help us understand when they do well and where GP-ICM stands out and achieves the best results. Tables VI and VII show per class F1 measures for the three most powerful classifiers for the English Riots dataset and PHEME dataset respectively, and they also show statistics on the misclassifications that the classifiers have made in terms of percentage deviations from the other classes. Looking at class performance analysis, we find that GP-ICM performance varies when looking at Precision and Recall. However, GP-ICM performs best in all dataset class pairs when it comes to either Precision or Recall, with Zucision or Recall being considered the best value, although never in either category."}, {"heading": "6. DISCUSSION", "text": "This year it has come to the point that it will be able to put itself at the top, \"he said.\" We have to put ourselves at the top, \"he said.\" We are able to get angry, \"he said,\" but we have to be able to hide. \""}, {"heading": "7. CONCLUSIONS", "text": "Social media is becoming an increasingly important tool for maintaining social resilience: individuals use it to express opinions and follow events as they unfold; news media use it as a source to inform their coverage of these events; and government agencies, such as the emergency services, use it to gather information to help in decision-making and advise the public on how to respond [Procter et al. 2013a]. While previous research suggests that mechanisms to detect false rumors are implicitly used in the way people use social media [Procter et al. 2013b], it is nonetheless crucial to investigate whether there are ways that computerized tools can help accelerate these mechanisms, so that misinformation and disinformation can be addressed more quickly, and the benefits of social media to society are perceived [Derczynski et al. 2015] as the first step toward achieving this goal, this paper has presented the problem of classifying the various types of social media."}, {"heading": "ACKNOWLEDGMENTS", "text": "This work is partially supported by the European Union under Funding Agreement 611233 PHEME. The work was carried out using the GPy toolkit [GPy Authors 2015], using Queen Mary's MidPlus computing facilities, supported by QMUL Research-IT and funded by the EPSRC Scholarship EP / K000128 / 1."}], "references": [{"title": "Sentiment Analysis of Twitter Data", "author": ["Apoorv Agarwal", "Boyi Xie", "Ilia Vovsha", "Owen Rambow", "Rebecca Passonneau."], "venue": "Proceedings of the Workshop on Languages in Social Media (LSM \u201911). 30\u201338.", "citeRegEx": "Agarwal et al\\.,? 2011", "shortCiteRegEx": "Agarwal et al\\.", "year": 2011}, {"title": "The psychology of rumor", "author": ["G.W. Allport", "L. Postman."], "venue": "Journal of Clinical Psychology (1947).", "citeRegEx": "Allport and Postman.,? 1947", "shortCiteRegEx": "Allport and Postman.", "year": 1947}, {"title": "Kernels for Vector-Valued Functions: A Review", "author": ["Mauricio A. \u00c1lvarez", "Lorenzo Rosasco", "Neil D. Lawrence."], "venue": "Found. Trends Mach. Learn. 4, 3 (2012), 195\u2013266.", "citeRegEx": "\u00c1lvarez et al\\.,? 2012", "shortCiteRegEx": "\u00c1lvarez et al\\.", "year": 2012}, {"title": "Joint Emotion Analysis via Multi-task Gaussian Processes", "author": ["Daniel Beck", "Trevor Cohn", "Lucia Specia."], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP \u201914). 1798\u20131803.", "citeRegEx": "Beck et al\\.,? 2014", "shortCiteRegEx": "Beck et al\\.", "year": 2014}, {"title": "Predicting information credibility in time-sensitive social media", "author": ["Carlos Castillo", "Marcelo Mendoza", "Barbara Poblete."], "venue": "Internet Research 23, 5 (2013), 560\u2013588.", "citeRegEx": "Castillo et al\\.,? 2013", "shortCiteRegEx": "Castillo et al\\.", "year": 2013}, {"title": "Modelling Annotator Bias with Multi-task Gaussian Processes: An Application to Machine Translation Quality Estimation", "author": ["Trevor Cohn", "Lucia Specia."], "venue": "51st Annual Meeting of the Association for Computational Linguistics (ACL \u201913). 32\u201342.", "citeRegEx": "Cohn and Specia.,? 2013", "shortCiteRegEx": "Cohn and Specia.", "year": 2013}, {"title": "Rumor, gossip and urban legends", "author": ["Nicholas DiFonzo", "Prashant Bordia."], "venue": "Diogenes 54, 1 (2007), 19\u201335.", "citeRegEx": "DiFonzo and Bordia.,? 2007", "shortCiteRegEx": "DiFonzo and Bordia.", "year": 2007}, {"title": "How idle is idle talk? One hundred years of rumor research", "author": ["Pamela Donovan."], "venue": "Diogenes 54, 1 (2007), 59\u201382.", "citeRegEx": "Donovan.,? 2007", "shortCiteRegEx": "Donovan.", "year": 2007}, {"title": "GPy: A Gaussian process framework in Python", "author": ["The GPy authors."], "venue": "http://github.com/ SheffieldML/GPy. (2015).", "citeRegEx": "authors.,? 2015", "shortCiteRegEx": "authors.", "year": 2015}, {"title": "Analyzing Rumors, Gossip, and Urban Legends Through Their Conversational Properties", "author": ["Bernard Guerin", "Yoshihiko Miyazaki."], "venue": "The Psychological Record: Vol. 56: Iss. 1, Article 2. (2006).", "citeRegEx": "Guerin and Miyazaki.,? 2006", "shortCiteRegEx": "Guerin and Miyazaki.", "year": 2006}, {"title": "TISoN: Trust Inference in Trust-Oriented Social Networks", "author": ["Sana Hamdi", "Alda Lopes Gancarski", "Amel Bouzeghoub", "Sadok Ben Yahia."], "venue": "ACM Transactions on Information Systems (TOIS) 34, 3 (2016), 17.", "citeRegEx": "Hamdi et al\\.,? 2016", "shortCiteRegEx": "Hamdi et al\\.", "year": 2016}, {"title": "Rumor Identification and Belief Investigation on Twitter", "author": ["Sardar Hamidian", "Mona T Diab."], "venue": "Proceedings of NAACL-HLT. 3\u20138.", "citeRegEx": "Hamidian and Diab.,? 2016", "shortCiteRegEx": "Hamidian and Diab.", "year": 2016}, {"title": "Predicting and Characterising User Impact on Twitter", "author": ["Vasileios Lampos", "Nikolaos Aletras", "Daniel Preotiuc-Pietro", "Trevor Cohn."], "venue": "Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics (EACL\u201914). 405\u2013413.", "citeRegEx": "Lampos et al\\.,? 2014", "shortCiteRegEx": "Lampos et al\\.", "year": 2014}, {"title": "Misinformation and its correction continued influence and successful debiasing", "author": ["Stephan Lewandowsky", "Ullrich KH Ecker", "Colleen M Seifert", "Norbert Schwarz", "John Cook."], "venue": "Psychological Science in the Public Interest 13, 3 (2012), 106\u2013131.", "citeRegEx": "Lewandowsky et al\\.,? 2012", "shortCiteRegEx": "Lewandowsky et al\\.", "year": 2012}, {"title": "Semi-Supervised Learning for Natural Language", "author": ["Percy Liang."], "venue": "Ph.D. Dissertation. Department of Electrical Engineering and Computer Science at the Massachusetts Institute of Technology.", "citeRegEx": "Liang.,? 2005", "shortCiteRegEx": "Liang.", "year": 2005}, {"title": "Real-time Rumor Debunking on Twitter", "author": ["Xiaomo Liu", "Armineh Nourbakhsh", "Quanzhi Li", "Rui Fang", "Sameena Shah."], "venue": "Proceedings of the 24th ACM International on Conference on Information and Knowledge Management (CIKM \u201915). ACM, New York, NY, USA, 1867\u20131870. DOI:http://dx.doi.org/10.1145/2806416.2806651", "citeRegEx": "Liu et al\\.,? 2015", "shortCiteRegEx": "Liu et al\\.", "year": 2015}, {"title": "Re-using an Argument Corpus to Aid in the Curation of Social Media Collections", "author": ["Clare Llewellyn", "Claire Grover", "Jon Oberlander", "Ewan Klein."], "venue": "Proceedings of the Ninth International Conference on Language Resources and Evaluation (26-31) (LREC\u201914). 462\u2013468.", "citeRegEx": "Llewellyn et al\\.,? 2014", "shortCiteRegEx": "Llewellyn et al\\.", "year": 2014}, {"title": "Classifying Tweet Level Judgements of Rumours in Social Media", "author": ["Michal Lukasik", "Trevor Cohn", "Kalina Bontcheva."], "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, EMNLP 2015, Lisbon, Portugal, September 17-21, 2015. 2590\u2013 2595. http://aclweb.org/anthology/D/D15/D15-1311.pdf", "citeRegEx": "Lukasik et al\\.,? 2015a", "shortCiteRegEx": "Lukasik et al\\.", "year": 2015}, {"title": "Point Process Modelling of Rumour Dynamics in Social Media", "author": ["Michal Lukasik", "Trevor Cohn", "Kalina Bontcheva."], "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing, ACL 2015. 518\u2013523. http://aclweb.org/anthology/P/P15/P15-2085.pdf", "citeRegEx": "Lukasik et al\\.,? 2015b", "shortCiteRegEx": "Lukasik et al\\.", "year": 2015}, {"title": "Detect Rumors Using Time Series of Social Context Information on Microblogging Websites", "author": ["Jing Ma", "Wei Gao", "Zhongyu Wei", "Yueming Lu", "Kam-Fai Wong."], "venue": "Proceedings of the 24th ACM International on Conference on Information and Knowledge Management (CIKM \u201915). ACM, New York, NY, USA, 1751\u20131754. DOI:http://dx.doi.org/10.1145/2806416.2806607", "citeRegEx": "Ma et al\\.,? 2015", "shortCiteRegEx": "Ma et al\\.", "year": 2015}, {"title": "Twitter under crisis: Can we trust what we RT", "author": ["Marcelo Mendoza", "Barbara Poblete", "Carlos Castillo."], "venue": "1st Workshop on Social Media Analytics (SOMA\u201910). 71\u201379.", "citeRegEx": "Mendoza et al\\.,? 2010", "shortCiteRegEx": "Mendoza et al\\.", "year": 2010}, {"title": "Geoparsing and geosemantics for social media: spatio-temporal grounding of content propagating rumours to support trust and veracity analysis during breaking news", "author": ["Stuart E Middleton", "Vadims Krivcovs."], "venue": "ACM Transactions on Information Systems 34, 3 (2016), 1\u201327.", "citeRegEx": "Middleton and Krivcovs.,? 2016", "shortCiteRegEx": "Middleton and Krivcovs.", "year": 2016}, {"title": "Efficient estimation of word", "author": ["Tomas Mikolov", "Kai Chen", "Greg Corrado", "Jeffrey Dean"], "venue": null, "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Expectation-propagation for the Generative Aspect Model", "author": ["Thomas Minka", "John Lafferty."], "venue": "Proceedings of the Conference on Uncertainty in Artificial Intelligence (UAI\u201902). 352\u2013359.", "citeRegEx": "Minka and Lafferty.,? 2002", "shortCiteRegEx": "Minka and Lafferty.", "year": 2002}, {"title": "Improved part-of-speech tagging for online conversational text with word clusters", "author": ["Olutobi Owoputi", "Chris Dyer", "Kevin Gimpel", "Nathan Schneider", "Noah A. Smith."], "venue": "Proceedings of NAACL. 380\u2013390.", "citeRegEx": "Owoputi et al\\.,? 2013", "shortCiteRegEx": "Owoputi et al\\.", "year": 2013}, {"title": "Overview of the Special Issue on Trust and Veracity of Information in Social Media", "author": ["Symeon Papadopoulos", "Kalina Bontcheva", "Eva Jaho", "Mihai Lupu", "Carlos Castillo."], "venue": "ACM Transactions on Information Systems (TOIS) 34, 3 (2016), 14.", "citeRegEx": "Papadopoulos et al\\.,? 2016", "shortCiteRegEx": "Papadopoulos et al\\.", "year": 2016}, {"title": "An analysis of the user occupational class through Twitter content", "author": ["Daniel Preotiuc-Pietro", "Vasileios Lampos", "Nikolaos Aletras."], "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing, ACL 2015. 1754\u2013 1764. http://aclweb.org/anthology/P/P15/P15-1169.pdf", "citeRegEx": "Preotiuc.Pietro et al\\.,? 2015", "shortCiteRegEx": "Preotiuc.Pietro et al\\.", "year": 2015}, {"title": "Cantijoch. 2013a. Reading the riots: What were the Police doing on Twitter", "author": ["Rob Procter", "Jeremy Crump", "Susanne Karstedt", "Alex Voss", "Marta"], "venue": "Policing and society 23,", "citeRegEx": "Procter et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Procter et al\\.", "year": 2013}, {"title": "Reading the riots on Twitter: methodological innovation for the analysis of big data", "author": ["Rob Procter", "Farida Vis", "Alex Voss."], "venue": "International journal of social research methodology 16, 3 (2013), 197\u2013214.", "citeRegEx": "Procter et al\\.,? 2013b", "shortCiteRegEx": "Procter et al\\.", "year": 2013}, {"title": "Rumor Has It: Identifying Misinformation in Microblogs", "author": ["Vahed Qazvinian", "Emily Rosengren", "Dragomir R. Radev", "Qiaozhu Mei."], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP \u201911). 1589\u20131599.", "citeRegEx": "Qazvinian et al\\.,? 2011", "shortCiteRegEx": "Qazvinian et al\\.", "year": 2011}, {"title": "Gaussian Processes for Machine Learning (Adaptive Computation and Machine Learning)", "author": ["Carl Edward Rasmussen", "Christopher K.I. Williams."], "venue": "The MIT Press.", "citeRegEx": "Rasmussen and Williams.,? 2005", "shortCiteRegEx": "Rasmussen and Williams.", "year": 2005}, {"title": "The psychology of rumor", "author": ["Ralph L. Rosnow."], "venue": "American Psychologist, Vol 46(5) (1991), 484\u2013496.", "citeRegEx": "Rosnow.,? 1991", "shortCiteRegEx": "Rosnow.", "year": 1991}, {"title": "Improvised News: A Sociological Study of Rumor", "author": ["Tamotsu Shibutani."], "venue": "Social Research 36(1) (1969), 169\u2013171.", "citeRegEx": "Shibutani.,? 1969", "shortCiteRegEx": "Shibutani.", "year": 1969}, {"title": "Microblog Analysis as a Programme of Work", "author": ["Peter Tolmie", "Rob Procter", "Mark Rouncefield", "Maria Liakata", "Arkaitz Zubiaga."], "venue": "arXiv preprint arXiv:1511.03193 (2015).", "citeRegEx": "Tolmie et al\\.,? 2015", "shortCiteRegEx": "Tolmie et al\\.", "year": 2015}, {"title": "Digital Wildfires: propagation, verification, regulation, and responsible innovation", "author": ["Helena Webb", "Pete Burnap", "Rob Procter", "Omer Rana", "Bernd Carsten Stahl", "Matthew Williams", "William Housley", "Adam Edwards", "Marina Jirotka."], "venue": "ACM Transactions on Information Systems (TOIS) 34, 3 (2016), 15.", "citeRegEx": "Webb et al\\.,? 2016", "shortCiteRegEx": "Webb et al\\.", "year": 2016}, {"title": " Unconfirmed: Classifying Rumor Stance in Crisis-Related Social Media Messages", "author": ["Li Zeng", "Kate Starbird", "Emma S Spiro."], "venue": "Tenth International AAAI Conference on Web and Social Media.", "citeRegEx": "Zeng et al\\.,? 2016", "shortCiteRegEx": "Zeng et al\\.", "year": 2016}, {"title": "Early Detection of Rumors in Social Media from Enquiry Posts", "author": ["Zhe Zhao", "Paul Resnick", "Qiaozhu Mei."], "venue": "International World Wide Web Conference Committee (IW3C2).", "citeRegEx": "Zhao et al\\.,? 2015", "shortCiteRegEx": "Zhao et al\\.", "year": 2015}, {"title": "Analysing How People Orient to and Spread Rumours in Social Media by Looking at Conversational Threads", "author": ["Arkaitz Zubiaga", "Maria Liakata", "Rob Procter", "Geraldine Wong Sak Hoi", "Peter Tolmie."], "venue": "PLoS ONE 11, 3 (03 2016), 1\u201329. DOI:http://dx.doi.org/10.1371/journal.pone.0150989", "citeRegEx": "Zubiaga et al\\.,? 2016", "shortCiteRegEx": "Zubiaga et al\\.", "year": 2016}, {"title": "D2.1 Development of an Annotation Scheme for Social Media Rumours", "author": ["Arkaitz Zubiaga", "Peter Tolmie", "Maria Liakata", "Rob Procter"], "venue": "PHEME deliverable", "citeRegEx": "Zubiaga et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zubiaga et al\\.", "year": 2014}, {"title": "D2.4 Qualitative Analysis of Rumours, Sources, and Diffusers across Media and Languages", "author": ["Arkaitz Zubiaga", "Peter Tolmie", "Maria Liakata", "Rob Procter"], "venue": "Technical Report. University of Warwick", "citeRegEx": "Zubiaga et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Zubiaga et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 13, "context": "Previous research has posited the damage that the diffusion of false rumours can cause in society, and that corrections issued by news organisations or state agencies such as the police may not necessarily achieve the desired effect sufficiently quickly [Lewandowsky et al. 2012; Procter et al. 2013a].", "startOffset": 254, "endOffset": 301}, {"referenceID": 20, "context": "Examples of rumours that were later disproven, after being widely circulated, include a 2010 earthquake in Chile, where rumours of a volcano eruption and a tsunami warning in Valparaiso spawned on Twitter [Mendoza et al. 2010].", "startOffset": 205, "endOffset": 226}, {"referenceID": 28, "context": "Another example is the England riots in 2011, where false rumours claimed that rioters were going to attack Birmingham\u2019s Children\u2019s Hospital and that animals had escaped from London Zoo [Procter et al. 2013b].", "startOffset": 186, "endOffset": 208}, {"referenceID": 37, "context": "Previous work by ourselves and others has argued that looking at how users in social media orient to rumours is a crucial first step towards making an informed judgement on the veracity of a rumourous report [Zubiaga et al. 2016; Tolmie et al. 2015; Mendoza et al. 2010].", "startOffset": 208, "endOffset": 270}, {"referenceID": 33, "context": "Previous work by ourselves and others has argued that looking at how users in social media orient to rumours is a crucial first step towards making an informed judgement on the veracity of a rumourous report [Zubiaga et al. 2016; Tolmie et al. 2015; Mendoza et al. 2010].", "startOffset": 208, "endOffset": 270}, {"referenceID": 20, "context": "Previous work by ourselves and others has argued that looking at how users in social media orient to rumours is a crucial first step towards making an informed judgement on the veracity of a rumourous report [Zubiaga et al. 2016; Tolmie et al. 2015; Mendoza et al. 2010].", "startOffset": 208, "endOffset": 270}, {"referenceID": 28, "context": "manually analysed the stance expressed by users in social media towards rumours [Procter et al. 2013b].", "startOffset": 80, "endOffset": 102}, {"referenceID": 36, "context": "\u2014 It can help detect rumours and flag them as such more quickly [Zhao et al. 2015].", "startOffset": 64, "endOffset": 82}, {"referenceID": 15, "context": "\u2014 Aggregate stance information and dynamics over time can be leveraged for rumour veracity classification [Derczynski et al. 2015; Liu et al. 2015].", "startOffset": 106, "endOffset": 147}, {"referenceID": 29, "context": "[Qazvinian et al. 2011]), while others being rule-based and thus with unclear generalisability to new rumours [Zhao et al.", "startOffset": 0, "endOffset": 23}, {"referenceID": 36, "context": "2011]), while others being rule-based and thus with unclear generalisability to new rumours [Zhao et al. 2015].", "startOffset": 92, "endOffset": 110}, {"referenceID": 17, "context": "This article substantially extends our earlier short paper [Lukasik et al. 2015a], fistly by using a second dataset, which enables us to test the generalisability of our results.", "startOffset": 59, "endOffset": 81}, {"referenceID": 37, "context": "More specifically, following [Zubiaga et al. 2016], we regard a rumour in the context of breaking news, as a \u201ccirculating story of questionable veracity, which is apparently credible but hard to verify, and produces sufficient skepticism and/or anxiety so as to motivate finding out the actual truth\u201d.", "startOffset": 29, "endOffset": 50}, {"referenceID": 20, "context": "[Mendoza et al. 2010].", "startOffset": 0, "endOffset": 21}, {"referenceID": 25, "context": "Recent research put together in a special issue on rumours and social media [Papadopoulos et al. 2016] also shows the increasing interest of the scientific community in the topic.", "startOffset": 76, "endOffset": 102}, {"referenceID": 34, "context": "[Webb et al. 2016] proposed an agenda for research that establishes an interdisciplinary methodology to explore in", "startOffset": 0, "endOffset": 18}, {"referenceID": 10, "context": "The contribution of [Hamdi et al. 2016] to rumour resolution is to build an automated system that rates the level of trust of users in social media, hence enabling to get rid of users with low reputation.", "startOffset": 20, "endOffset": 39}, {"referenceID": 28, "context": "[Procter et al. 2013b].", "startOffset": 0, "endOffset": 22}, {"referenceID": 33, "context": "into the conversational characteristics of microblogging [Tolmie et al. 2015] has motivated our research into automating stance classification as a methodology for accelerating this process.", "startOffset": 57, "endOffset": 77}, {"referenceID": 29, "context": "[Qazvinian et al. 2011] conducted early work on rumour stance classification.", "startOffset": 0, "endOffset": 23}, {"referenceID": 38, "context": ", we conduct a 3-way classification [Zubiaga et al. 2014].", "startOffset": 36, "endOffset": 57}, {"referenceID": 15, "context": "[Liu et al. 2015] introduce rule-based methods for stance classification, which were shown to outperform the approach by [Qazvinian et al.", "startOffset": 0, "endOffset": 17}, {"referenceID": 29, "context": "2015] introduce rule-based methods for stance classification, which were shown to outperform the approach by [Qazvinian et al. 2011].", "startOffset": 109, "endOffset": 132}, {"referenceID": 36, "context": "Similarly, [Zhao et al. 2015] use regular expressions instead of an automated method for rumour stance classification.", "startOffset": 11, "endOffset": 29}, {"referenceID": 35, "context": "[Zeng et al. 2016], who explored the use of three different classifiers for automated rumour stance classification on unseen rumours.", "startOffset": 0, "endOffset": 18}, {"referenceID": 36, "context": "Lastly, researchers [Zhao et al. 2015; Ma et al. 2015] have focused on the related task of detecting rumours in social media.", "startOffset": 20, "endOffset": 54}, {"referenceID": 19, "context": "Lastly, researchers [Zhao et al. 2015; Ma et al. 2015] have focused on the related task of detecting rumours in social media.", "startOffset": 20, "endOffset": 54}, {"referenceID": 36, "context": "using pattern-based rumour detection [Zhao et al. 2015].", "startOffset": 37, "endOffset": 55}, {"referenceID": 29, "context": "We do not use the dataset by [Qazvinian et al. 2011] given that it uses a different annotation scheme limited to two categories of stances.", "startOffset": 29, "endOffset": 52}, {"referenceID": 28, "context": "The dataset was analysed and annotated manually as supporting, questioning, or denying a rumour, by a team of social scientists studying the role of social media during the riots [Procter et al. 2013b].", "startOffset": 179, "endOffset": 201}, {"referenceID": 20, "context": "As can be seen from the dataset overview in Table II, different rumours exhibit varying proportions of supporting, denying and questioning tweets, which was also observed in other studies of rumours [Mendoza et al. 2010; Qazvinian et al. 2011].", "startOffset": 199, "endOffset": 243}, {"referenceID": 29, "context": "As can be seen from the dataset overview in Table II, different rumours exhibit varying proportions of supporting, denying and questioning tweets, which was also observed in other studies of rumours [Mendoza et al. 2010; Qazvinian et al. 2011].", "startOffset": 199, "endOffset": 243}, {"referenceID": 28, "context": "The seven rumours were as follows [Procter et al. 2013b]:", "startOffset": 34, "endOffset": 56}, {"referenceID": 12, "context": "Gaussian Processes are a Bayesian non-parametric machine learning framework that has been shown to work well for a range of NLP problems, often beating other state-of-the-art methods [Cohn and Specia 2013; Lampos et al. 2014; Beck et al. 2014; Preotiuc-Pietro et al. 2015].", "startOffset": 183, "endOffset": 272}, {"referenceID": 3, "context": "Gaussian Processes are a Bayesian non-parametric machine learning framework that has been shown to work well for a range of NLP problems, often beating other state-of-the-art methods [Cohn and Specia 2013; Lampos et al. 2014; Beck et al. 2014; Preotiuc-Pietro et al. 2015].", "startOffset": 183, "endOffset": 272}, {"referenceID": 26, "context": "Gaussian Processes are a Bayesian non-parametric machine learning framework that has been shown to work well for a range of NLP problems, often beating other state-of-the-art methods [Cohn and Specia 2013; Lampos et al. 2014; Beck et al. 2014; Preotiuc-Pietro et al. 2015].", "startOffset": 183, "endOffset": 272}, {"referenceID": 26, "context": "We choose this method due to interpretability of results, similar to recent work on occupational class classification [Preotiuc-Pietro et al. 2015].", "startOffset": 118, "endOffset": 147}, {"referenceID": 2, "context": "alisation Model (ICM; [\u00c1lvarez et al. 2012]).", "startOffset": 22, "endOffset": 43}, {"referenceID": 3, "context": "This model has already been applied successfully to NLP regression problems [Beck et al. 2014] and it can also be applied to classification ones.", "startOffset": 76, "endOffset": 94}, {"referenceID": 35, "context": "The selection of these baselines is in line with the classifiers used in recent research on stance classification [Zeng et al. 2016], who found that random forests, followed by logistic regression, performed best.", "startOffset": 114, "endOffset": 132}, {"referenceID": 0, "context": "In addition, multiple occurrences of a character were replaced with a double occurrence [Agarwal et al. 2011], to correct for misspellings and lengthenings, e.", "startOffset": 88, "endOffset": 109}, {"referenceID": 17, "context": "In previous work it has been shown that Brown clusters yield better performance than directly using the BOW features [Lukasik et al. 2015a].", "startOffset": 117, "endOffset": 139}, {"referenceID": 24, "context": "In our experiments, the clusters used were obtained using 1000 clusters acquired from a large scale Twitter corpus [Owoputi et al. 2013], from which we can learn Brown clusters aimed at representing a generalisable Twitter vocabulary.", "startOffset": 115, "endOffset": 136}, {"referenceID": 16, "context": "Retweets are removed from the training set to prevent bias [Llewellyn et al. 2014].", "startOffset": 59, "endOffset": 82}, {"referenceID": 22, "context": "During the experimentation process, we also tested additional features, including the use of the bag of words instead of the Brown clusters, as well as using word embeddings trained from the training sets [Mikolov et al. 2013].", "startOffset": 205, "endOffset": 226}, {"referenceID": 37, "context": "This is a known problem in rumour diffusion, as previous studies have found that people barely deny or question rumours but generally tend to support them irrespective of their actual veracity value [Zubiaga et al. 2016].", "startOffset": 199, "endOffset": 220}, {"referenceID": 28, "context": "While previous research has suggested that mechanisms for exposing false rumours are implicit in the ways in which people use social media [Procter et al. 2013b], it is nevertheless critically important to explore if there are ways in which computational tools can help to accelerate these mechanisms so that misinformation and disinformation can be targeted more rapidly, and the benefits of social media to society maintained [Derczynski et al.", "startOffset": 139, "endOffset": 161}, {"referenceID": 18, "context": "For example, the rumour diffusion patterns [Lukasik et al. 2015b] may be a useful cue for stance classification.", "startOffset": 43, "endOffset": 65}], "year": 2016, "abstractText": "Social media tend to be rife with rumours while new reports are released piecemeal during breaking news. Interestingly, one can mine multiple reactions expressed by social media users in those situations, exploring their stance towards rumours, ultimately enabling the flagging of highly disputed rumours as being potentially false. In this work, we set out to develop an automated, supervised classifier that uses multi-task learning to classify the stance expressed in each individual tweet in a rumourous conversation as either supporting, denying or questioning the rumour. Using a classifier based on Gaussian Processes, and exploring its effectiveness on two datasets with very different characteristics and varying distributions of stances, we show that our approach consistently outperforms competitive baseline classifiers. Our classifier is especially effective in estimating the distribution of different types of stance associated with a given rumour, which we set forth as a desired characteristic for a rumour-tracking system that will warn both ordinary users of Twitter and professional news practitioners when a rumour is being rebutted.", "creator": "LaTeX with hyperref package"}}}