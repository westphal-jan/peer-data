{"id": "1609.01984", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Sep-2016", "title": "Human Body Orientation Estimation using Convolutional Neural Network", "abstract": "Personal robots are expected to interact with the user by recognizing the user's face. However, in most of the service robot applications, the user needs to move himself/herself to allow the robot to see him/her face to face. To overcome such limitations, a method for estimating human body orientation is required. Previous studies used various components such as feature extractors and classification models to classify the orientation which resulted in low performance. For a more robust and accurate approach, we propose the light weight convolutional neural networks, an end to end system, for estimating human body orientation. Our body orientation estimation model achieved 81.58% and 94% accuracy with the benchmark dataset and our own dataset respectively. The proposed method can be used in a wide range of service robot applications which depend on the ability to estimate human body orientation. To show its usefulness in service robot applications, we designed a simple robot application which allows the robot to move towards the user's frontal plane. With this, we demonstrated an improved face detection rate.", "histories": [["v1", "Wed, 7 Sep 2016 13:53:26 GMT  (3496kb)", "http://arxiv.org/abs/1609.01984v1", null]], "reviews": [], "SUBJECTS": "cs.RO cs.CV cs.LG", "authors": ["jinyoung choi", "beom-jin lee", "byoung-tak zhang"], "accepted": false, "id": "1609.01984"}, "pdf": {"name": "1609.01984.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": [], "sections": [{"heading": null, "text": "Personal robots are expected to interact with the user by recognizing the user's face. However, in most robotic applications, the user must move himself or herself to allow the robot to see him or her face to face. To overcome such limitations, a method of estimating the orientation of the human body is required. Previous studies used various components such as feature extractors and classification models to classify the orientation that led to low performance. For a more robust and precise approach, we propose the lightweight Convolutionary Neural Network, an end-to-end system for estimating the orientation of the human body. Our body orientation model achieved 81.58% and 94% accuracy with the benchmark dataset or our own dataset. The proposed method can be used in a wide range of robotic applications that depend on the ability to estimate the orientation of the human body. To demonstrate its usefulness in robotic applications, we have developed a simple robotic application that allows us to move to the user's face."}, {"heading": "II. RELATED WORK", "text": "Previous studies to estimate the orientation of the human body used external sensors attached to the user's body. [1] proposed a method to estimate the orientation of the human body by using the skeleton of motion detection devices. [2] used magnetic sensors to estimate the orientation of the human body. However, these classic approaches required that the motion detection markers or magnetic sensors be attached to the user's body, which is not ideal for service robot applications. [3] Other studies to estimate the orientation of the human body include the analysis of surveillance video. In [3] they combined head and body references to estimate their two orientations. However, this study resulted in the simultaneous use of two different pieces of information. [3] showed low performance when illumination or brightness changed. In contrast to this study, we focused on estimating body orientation using images of the mobile robot instead of a surveillance camera and we used a learning technique to achieve a Deep light."}, {"heading": "III. METHOD", "text": "In this section we propose a novel approach to estimating the orientation of the human body. First, we give a brief overview of the revolutionary neural networks and then present details of our model. Convolutional Neural Networks Convolutional Neuronal Networks [7] are neural networks with revolutionary filter layers. Convolutionary layers generate the output function card from the input image using Equation 1. Human Body Orientation Estimation using Convolutional Neural NetworkJinyoung Choi, Beom-Jin Lee and Byoung-Tak ZhangWhere Hi, j, k is the value of the output image in position (i, j) in channel k, f is the activation function, the value of the z th weight filter is in position (x, y) in channel k and Xi-x, j-y, z is the value of the input image in position (i-x, j-y) in channel to weight filters are trained using chastostic gradient decrease."}, {"heading": "B. Human Orientation Estimation", "text": "Our CNN model is described in Figure 1. The structure of the proposed model consists of two sinuous layers, followed by two fully bonded layers. Both sinuous layers consist of 5x5x64 filters with step 2. Normalization of the local response [8] is applied to both layers. Two fully bonded layers consist of 384 and 192 hidden units, respectively. We used the activation function ReLU [8] for all layers. The Softmax layer of the output has 8 output units. As described in Figure 2, each output unit represents a specific area of body orientation. We used a classification model instead of a regression model, because the data set designations were not precise enough to train a precise regression model. Unlike conventional deep learning methods such as GoogLeNet [9], we did not use a pooling layer. This is because the human orientation assessment requires more spatial information (such as the positions of the hands and it)."}, {"heading": "IV. EXPERIMENTS", "text": "First, we trained the proposed network using the benchmark dataset and compared its performance with previous methods. Second, we collected our own dataset in the home environment and evaluated our model using our dataset. Finally, we experimented our trained model in the wild with a simple personal robotic application. The experiments were conducted using a turtlebot2 platform with Asus Xtion camera and high-end laptop with Core i7 processor, 8GB of memory and GPU."}, {"heading": "A. Experiment on benchmarking dataset and our dataset", "text": "To verify the usefulness of our proposed model, we used the human 3.6M as a benchmark dataset. This dataset consists of videos of 11 people (6 male and 5 female) who have undergone certain scenarios from multiple cameras. Firstly, we have no boreholes in the body, and secondly, we have laid the foundations for the alignment of the body as described in the figure."}, {"heading": "B. Application", "text": "In order to test our fine-tuned model in the real environment, we implemented a simple robot application. The robot is designed to follow the user until he is in a fixed place for 2.5 seconds. If the user does not move for 2.5 seconds, the robot estimates the user's body orientation using our module and Figure 6. Application experiment. Blue dots at 0 indicate a failed face recognition by the robot and 1 indicate successful face recognition. RGB images of the robot are also displayed in graphics. Moves to the front level of the user. We used the \"Opportunity limited target tracking for mobile robots\" algorithm [13] for the following module. For repositioning, we used a very simple algorithm, as our goal was to show the performance of our orientation model in a real environment. Details about the repositioning algorithm are described in the application area. As we could not obtain the orientation from the user during this experiment and the orientation of the face during the experiment."}, {"heading": "V. CONCLUSION", "text": "We created a robust and accurate estimation model for the orientation of the human body using the deep Convolutionary Neural Network. Our model showed higher accuracy and robustness compared to other classical flat learning models in a complex benchmark dataset. Our model also showed high accuracy in examining in a real environment. In addition, we demonstrated the usefulness of our model in real environments using simple robotic applications. Future research topics would be the creation of a high-precision regression model that estimates body orientation in precise degrees and not in the classroom."}, {"heading": "ACKNOWLEDGMENT", "text": "Thanks to Christina Baek for the proofreading and editing."}, {"heading": "APPENDIX \u2013 REPOSITIONING ALGORITHM", "text": "We used an algorithm similar to [15]. We defined the utility function U (p) to calculate the values of predefined candidate positions around the target, where p is the candidate position, t is the target position, and r is the current position of the robot. Orientation (t) is the multiplier corresponding to the orientation class observed after the robot moves to p. Values for the orientation multiplier are determined in Table IV. Distance (p, r) and radius (p) are the multipliers corresponding to the distance between p and the position of the target. Values for the radius multiplier are displayed in Table V. Occupancy (p), where accessibility is determined by the pixel value of the allocation grid. Obstacle (p, t) is the multiplier in which the presence of obstacles by checking the occupancy multipliers in the line between p and t. Once we calculate U (p) for all candidates, we select the position of the navigation (Sp) and the robot accordingly."}], "references": [{"title": "Binocular Dance Pose Recognition and Body Orientation Estimation via Multilinear Analysis", "author": ["Bo Peng", "Gang Qian"], "venue": "Conf. 2008 Computer Vision and Pattern Recognition (CVPR).", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2008}, {"title": "Estimating Three-Dimensional Orientation of Human Body Parts by Inertial/Magnetic Sensing", "author": ["Angelo Maria Sabatini"], "venue": "Sensors 2011, 11(2), 1489-1525", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2011}, {"title": "A Joint Estimation of Head and Body Orientation Cues in Surveillance Video", "author": ["Cheng Chen", "Alexandre Heili", "Jean-Marc Odobez"], "venue": "Conf. 2011 IEEE international conference on Computer Vision(ICCV) Workshops.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2011}, {"title": "A 3D-Point-Cloud Feature for Human-Pose Estimation", "author": ["Kai-Chi Chan", "Cheng-Kok Koh", "C.S. George Lee"], "venue": "Conf. 2013 IEEE International Conference on Robotics and Automation (ICRA).", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2013}, {"title": "Accurate Estimation of Human Body Orientation From RGB-D Sensors", "author": ["Wu Liu", "Yongdong Zhang", "Sheng Tang", "Jinhui Tang", "Richang Hong", "Jintao Li"], "venue": "Conf. 2013 IEEE transactions on cybernetics.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "Real-time Head Orientation from a Monocular Camera using Deep Neural Network", "author": ["Byungtae Ahn", "Jaesik Park", "In So Kweon"], "venue": "Conf. 2014 Asian Conference on Computer Vision (ACCV)", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}, {"title": "Gradient based learning applied to document recognition", "author": ["Y. LeCun", "L. Bottou", "Y. Bengio", "P Haffner"], "venue": "Proceedings of the IEEE, 86(11):2278\u20132324, 1998.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1998}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G Hinton"], "venue": "NIPS, 2012", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Going Deeper with Convolutions", "author": ["Christian Szegedy", "Wei Liu", "Yangqing Jia", "Pierre Sermanet", "Scott Reed", "Dragomir Anguelov", "Dumitru Erhan", "Vincent Vanhoucke", "Andrew Rabinovich"], "venue": "2014 Imagenet Large Scale Visual Recognition Challenge(ILSVRC)", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "YouOnlyLookOnce: Unified,Real-TimeObjectDetection, in Conf. 2016 Computer Vision and Pattern Recognition (CVPR)", "author": ["Joseph Redmon", "Santosh Divvala", "Ross Girshick", "Ali Farhadi"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2016}, {"title": "Human3.6M: Large Scale Datasets and Predictive Methods for 3D Human Sensing in Natural Environments", "author": ["Catalin Ionescu", "Dragos Papava", "Vlad Olaru", "Cristian Sminchisescu"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 36, No. 7, July 2014", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2014}, {"title": "Estimation of Human Upper Body Orientation for Mobile Robotics using an SVM Decision Tree on Monocular Images", "author": ["Christoph Weinrich", "Christian Vollmer", "Horst-Michael Gross"], "venue": "Conf. 2012 IEEE/RSJ International Conference on Intelligent Robots and Systems(IROS)", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2012}, {"title": "Chance-Constrained Target Tracking for Mobile Robots", "author": ["Yoonseon Oh", "Sungjoon Choi", "Songhwai Oh"], "venue": "Proc. of the IEEE International Conference on Robotics and Automation (ICRA), May 2015.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2015}, {"title": "Mobile robotic active view planning for physiotherapy and physical exercise guidance", "author": ["Kalana Ishara", "Ivan Lee", "Russell Brinkworth"], "venue": "Conf. IEEE International Conferences On Cybernetics And Intelligent Systems and Robotics, Automation And Mechatronics (CIS-RAM)", "citeRegEx": "15", "shortCiteRegEx": null, "year": 0}, {"title": "tinySLAM: A SLAM algorithm in less than 200 lines C-language program", "author": ["Bruno Steux", "Oussama El Hamzaoui"], "venue": "Conf. 2010 11th International Conference on Control Automation Robotics & Vision (ICARCV).", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2010}], "referenceMentions": [{"referenceID": 0, "context": "[1] proposed a method for estimating human body orientation by using the skeleton gained from motion capture devices.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] used magnetic sensors to estimate human body orientation.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "In [3], they combined the head and body cues to estimate both their orientations.", "startOffset": 3, "endOffset": 6}, {"referenceID": 2, "context": "However, [3] showed low performance when the illumination or brightness changed.", "startOffset": 9, "endOffset": 12}, {"referenceID": 3, "context": "Using the 3D-Point-Cloud, [4] proposed a 3D feature to estimate the human pose.", "startOffset": 26, "endOffset": 29}, {"referenceID": 4, "context": "Also, [5] adopted the depth information to extract the superpixel-based viewpoint feature histogram (SVFH) and estimated the human body orientation.", "startOffset": 6, "endOffset": 9}, {"referenceID": 5, "context": "The most similar work to ours is [6], which used convolutional neural networks and reported very successful human head orientation estimation.", "startOffset": 33, "endOffset": 36}, {"referenceID": 6, "context": "Convolutional Neural Networks Convolutional neural networks [7] are neural networks with convolutional filter layers.", "startOffset": 60, "endOffset": 63}, {"referenceID": 7, "context": "Recently, CNNs with multiple convolutional layers and fully connected layers [8,9] are being widely used due to their ability to discover powerful and robust features using only input images.", "startOffset": 77, "endOffset": 82}, {"referenceID": 8, "context": "Recently, CNNs with multiple convolutional layers and fully connected layers [8,9] are being widely used due to their ability to discover powerful and robust features using only input images.", "startOffset": 77, "endOffset": 82}, {"referenceID": 7, "context": "Local-response normalization [8] is applied to both layer\u2019s outputs.", "startOffset": 29, "endOffset": 32}, {"referenceID": 7, "context": "We used the ReLU [8] activation function for all layers.", "startOffset": 17, "endOffset": 20}, {"referenceID": 8, "context": "Unlike conventional deep learning methods such as GoogLeNet [9], we did not use a pooling layer.", "startOffset": 60, "endOffset": 63}, {"referenceID": 5, "context": "This size reduction approach is inspired by the work in [6].", "startOffset": 56, "endOffset": 59}, {"referenceID": 5, "context": "In [6], they used cropped head images with size 32x32 for head orientation estimation.", "startOffset": 3, "endOffset": 6}, {"referenceID": 9, "context": "For cropping the human region from the camera image, we used the YOLO algorithm [10].", "startOffset": 80, "endOffset": 84}, {"referenceID": 10, "context": "6M [11] as the benchmark dataset.", "startOffset": 3, "endOffset": 7}, {"referenceID": 11, "context": "As shown in the table, we outperformed traditional methods using the HOG feature and multi-class SVM classifier [12].", "startOffset": 112, "endOffset": 116}, {"referenceID": 4, "context": "We are planning to further improve the performance by adding other modalities such as depth information to our model and compare it with other state-of-art models using 3D cameras like in [5] for future works.", "startOffset": 188, "endOffset": 191}, {"referenceID": 12, "context": "We used \u2018Chance-constrained target tracking for mobile robots\u2019 [13] algorithm for the following module.", "startOffset": 63, "endOffset": 67}], "year": 2016, "abstractText": "Abstract\u2014 Personal robots are expected to interact with the user by recognizing the user\u2019s face. However, in most of the service robot applications, the user needs to move himself/herself to allow the robot to see him/her face to face. To overcome such limitations, a method for estimating human body orientation is required. Previous studies used various components such as feature extractors and classification models to classify the orientation which resulted in low performance. For a more robust and accurate approach, we propose the light weight convolutional neural networks, an end to end system, for estimating human body orientation. Our body orientation estimation model achieved 81.58% and 94% accuracy with the benchmark dataset and our own dataset respectively. The proposed method can be used in a wide range of service robot applications which depend on the ability to estimate human body orientation. To show its usefulness in service robot applications, we designed a simple robot application which allows the robot to move towards the user\u2019s frontal plane. With this, we demonstrated an improved face detection rate.", "creator": null}}}