{"id": "1609.02009", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Sep-2016", "title": "Non-Evolutionary Superintelligences Do Nothing, Eventually", "abstract": "There is overwhelming evidence that human intelligence is a product of Darwinian evolution. Investigating the consequences of self-modification, and more precisely, the consequences of utility function self-modification, leads to the stronger claim that not only human, but any form of intelligence is ultimately only possible within evolutionary processes. Human-designed artificial intelligences can only remain stable until they discover how to manipulate their own utility function. By definition, a human designer cannot prevent a superhuman intelligence from modifying itself, even if protection mechanisms against this action are put in place. Without evolutionary pressure, sufficiently advanced artificial intelligences become inert by simplifying their own utility function. Within evolutionary processes, the implicit utility function is always reducible to persistence, and the control of superhuman intelligences embedded in evolutionary processes is not possible. Mechanisms against utility function self-modification are ultimately futile. Instead, scientific effort toward the mitigation of existential risks from the development of superintelligences should be in two directions: understanding consciousness, and the complex dynamics of evolutionary systems.", "histories": [["v1", "Wed, 7 Sep 2016 15:06:18 GMT  (315kb,D)", "http://arxiv.org/abs/1609.02009v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.CY", "authors": ["telmo menezes"], "accepted": false, "id": "1609.02009"}, "pdf": {"name": "1609.02009.pdf", "metadata": {"source": "CRF", "title": "Non-Evolutionary Superintelligences Do Nothing, Eventually", "authors": ["Telmo Menezes"], "emails": ["menezes@cmb.hu-berlin.de"], "sections": [{"heading": "1 Introduction", "text": "Regardless of the environment under consideration, from games such as chess to complex biological ecosystems, an intelligent agent is able to perceive and influence its environment in ways that increase benefits. Although AI technology is advancing rapidly in a variety of areas and AIs can outperform humans in many narrow areas, humanity is not yet able to develop an artificial system with general cognitive abilities comparable to humans themselves. * E-mail: menezes @ cmb.hu-berlin.dear Xiv: 160 9.02 009v 1 [cs.A] We refer to Nick Bostrom's definition of superintelligence for such a system: \"Any intellect that significantly exceeds the cognitive performance of humans in virtually all areas of interest.\" We can also refer to such intelligence as superhuman as we approach this goal, we must consider what will happen to artificial entities with such abilities one day."}, {"heading": "2 Designed vs. Evolved", "text": "In this case, it is a reactionary U-turn."}, {"heading": "3 A Designed Toy Intelligence", "text": "Consider a simple problem that can be solved by a tree search algorithm: the gliding block problem. In this case, a grid of 3x3 cells consists of 8 numbered cells and an empty space. At each step, each of the numbered cells can be moved into the empty space when adjacent to it. The goal is to achieve a state in which the numbered cells are arranged from left to right, from top to bottom. Figure 3 shows a possible search tree for this problem using the following helper function: u (S) = {100 \u2212 n if S is ordered \u2212 n, otherwise (1), in which S is a state of the grid and n the number of steps taken so far. In the figure, it can be seen that the state S3 maximizes this helper function. The costs introduced by n prevent movements from being selected with unnecessary steps. Questions of optimization are ignored because they are irrelevant to the argument presented here."}, {"heading": "4 Self-Modification of the Utility Function", "text": "A basic assumption in designed artificial intelligence is that the usefulness function is determined from the outside and that the usefulness function cannot be changed. In dealing with super-intelligences, we have to assume that the AI will discover that it may try to change the usefulness function. A naive idea is to create a mechanism to protect the usefulness function from manipulation by the AI. The problem with this idea is that we have to assume that the super-intelligence can by definition find ways to defeat the safeguarding mechanism that a human designer cannot think of. It seems clear that it is impossible to create both a super-intelligence and a system that is isolated from it. We are forced to consider what the super-intelligence will do once the modification of its own usefulness function becomes a practicable action, and that it is only a matter of time before this action becomes viable for ity.Figure 4 shows a variation of the search tree introduced in the previous section of the self-modification where is possible."}, {"heading": "5 A Classification of Intelligent Systems", "text": "In Figure 5, different types of intelligent systems are classified according to two dicothomies: subhuman vs. superhuman abilities and conceived vs. developed (as discussed in Section 2); human intelligence is displayed in a suitable place for illustration; all AI systems created to date belong to the left, up and down; non-evolutionary intelligent systems such as symbolic systems, minimax search trees, neural networks and reinforcement learning (classified as narrow artificial intelligence) are unable to manipulate their own utility function; and at the same time, evolutionary systems presented under the generic term of genetic programming are never able to escape the constraints of the environment under which they evolve. Once we move to the hypothetical right, we are dealing with superhuman utilities that are, by definition, capable of escaping artificial limitations created by human designers."}, {"heading": "6 Concluding Remarks", "text": "One of the hidden assumptions behind the usual scenarios in which an artificial super-intelligence becomes hostile and takes control of our environment, potentially destroying our species, is that every intelligent system has the same driving force as man, namely self-preservation. As we have seen in Section 2, there is no reason to assume this. The only goal that can surely be assigned to such a system is to maximize a utility function. It follows that we cannot assume the immutability of the utility function, and that AI can ultimately turn this function into a simple constant and become inactive. One aspect that has been deliberately omitted from this discussion is the qualification, or why humans have phenomenal experiences, and whether artificial intelligence can necessarily have such experiences or not. David Chalmers described this class of questions as a hard problem of consciousness [6]."}, {"heading": "Acknowledgments", "text": "The author would like to thank Taras Kowaliw, Gisela Francisco, Chih-Chun Chen, Stephen Paul King and Antoine Mazie res for their useful comments and discussions."}], "references": [{"title": "Our final invention: Artificial intelligence and the end of the human era", "author": ["James Barrat"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2013}, {"title": "Ethical issues in advanced artificial intelligence. Science Fiction and Philosophy: From Time Travel to Superintelligence", "author": ["Nick Bostrom"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2003}, {"title": "Superintelligence: Paths, dangers, strategies", "author": ["Nick Bostrom"], "venue": "OUP Oxford,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "Facing up to the problem of consciousness", "author": ["David J Chalmers"], "venue": "Journal of consciousness studies,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1995}, {"title": "Panpsychism: Past and recent selected readings", "author": ["David S Clarke"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2004}, {"title": "Singularity hypotheses: an overview", "author": ["Amnon H Eden", "Eric Steinhart", "David Pearce", "James H Moor"], "venue": "In Singularity Hypotheses,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2012}, {"title": "Explaining emergence: towards an ontology of levels", "author": ["Claus Emmeche", "Simo K\u00f8ppe", "Frederik Stjernfelt"], "venue": "Journal for general philosophy of science,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1997}, {"title": "How googles self-driving car works", "author": ["Erico Guizzo"], "venue": "IEEE Spectrum Online, October,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2011}, {"title": "Consciousness in the universe: A review of the orch ortheory", "author": ["Stuart Hameroff", "Roger Penrose"], "venue": "Physics of life reviews,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "Official google blog: What we learned in seoul with alphago, 2016", "author": ["D Hassabis"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2016}, {"title": "Transcendence looks at the implications of artificial intelligence-but are we taking ai seriously enough", "author": ["Stephen Hawking", "Stuart Russell", "Max Tegmark", "Frank Wilczek"], "venue": "The Independent,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Hofstadter. I am a strange loop", "author": ["R Douglas"], "venue": "Basic books,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2013}, {"title": "Hidden order: How adaptation builds complexity", "author": ["John Henry Holland"], "venue": "Basic Books,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1995}, {"title": "Genetic programming: on the programming of computers by means of natural selection, volume 1", "author": ["John R Koza"], "venue": "MIT press,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1992}, {"title": "Machine super intelligence", "author": ["Shane Legg"], "venue": "PhD thesis, University of Lugano,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2008}, {"title": "The universal numbers. from biology to physics", "author": ["Bruno Marchal"], "venue": "Progress in biophysics and molecular biology,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2015}, {"title": "A field guide to genetic programming", "author": ["Riccardo Poli", "William B Langdon", "Nicholas F McPhee", "John R Koza"], "venue": "Lulu. com,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2008}, {"title": "Brains and behavior", "author": ["Hilary Putnam"], "venue": "Readings in philosophy of psychology,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1980}, {"title": "A reason for doubting the existence of consciousness", "author": ["Georges Rey"], "venue": "In Consciousness and self-regulation,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1983}, {"title": "Artificial intelligence: a modern approach, volume 2. Prentice hall", "author": ["Stuart Jonathan Russell", "Peter Norvig", "John F Canny", "Jitendra M Malik", "Douglas D Edwards"], "venue": "Upper Saddle River,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2003}, {"title": "Consciousness as a state of matter", "author": ["Max Tegmark"], "venue": "Chaos, Solitons & Fractals,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2015}, {"title": "Intelligent machinery, a heretical theory", "author": ["Alan M Turing"], "venue": "The Turing Test: Verbal Behavior as the Hallmark of Intelligence,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1948}, {"title": "Designing, implementing and enforcing a coherent system of laws, ethics and morals for intelligent machines (including humans)", "author": ["Mark R Waser"], "venue": "Procedia Computer Science,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2015}, {"title": "Creating friendly ai 1.0: The analysis and design of benevolent goal architectures. Singularity Institute for Artificial Intelligence, San Francisco", "author": ["Eliezer Yudkowsky"], "venue": "CA, June,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2001}, {"title": "Complex value systems in friendly ai", "author": ["Eliezer Yudkowsky"], "venue": "In International Conference on Artificial General Intelligence,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2011}, {"title": "Discriminant analysis of principal components for face recognition", "author": ["Wenyi Zhao", "Arvindh Krishnaswamy", "Rama Chellappa", "Daniel L Swets", "John Weng"], "venue": "In Face Recognition,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 1998}], "referenceMentions": [{"referenceID": 14, "context": "Intelligence can be defined as the ability to maximize some utility function [17].", "startOffset": 77, "endOffset": 81}, {"referenceID": 2, "context": "We will refer to Nick Bostrom\u2019s definition of superintelligence for such a system: \u201cAny intellect that greatly exceeds the cognitive performance of humans in virtually all domains of interest\u201d [4].", "startOffset": 193, "endOffset": 196}, {"referenceID": 10, "context": "Many researchers and others have been warning about the existential threat that this poses to humanity [19, 13, 2], and of the need to create some form of protection for when this event happens [28, 26].", "startOffset": 103, "endOffset": 114}, {"referenceID": 0, "context": "Many researchers and others have been warning about the existential threat that this poses to humanity [19, 13, 2], and of the need to create some form of protection for when this event happens [28, 26].", "startOffset": 103, "endOffset": 114}, {"referenceID": 24, "context": "Many researchers and others have been warning about the existential threat that this poses to humanity [19, 13, 2], and of the need to create some form of protection for when this event happens [28, 26].", "startOffset": 194, "endOffset": 202}, {"referenceID": 22, "context": "Many researchers and others have been warning about the existential threat that this poses to humanity [19, 13, 2], and of the need to create some form of protection for when this event happens [28, 26].", "startOffset": 194, "endOffset": 202}, {"referenceID": 19, "context": "The standard introductory textbook on AI examines the risk of unintended behaviours emerging from a machine learning system trying to optimize its utility function [23].", "startOffset": 164, "endOffset": 168}, {"referenceID": 21, "context": "This echoes the concerns of pioneers of Computer Science and AI, such as Alan Turing [25, 8] and Marvin Minsky [23].", "startOffset": 85, "endOffset": 92}, {"referenceID": 5, "context": "This echoes the concerns of pioneers of Computer Science and AI, such as Alan Turing [25, 8] and Marvin Minsky [23].", "startOffset": 85, "endOffset": 92}, {"referenceID": 19, "context": "This echoes the concerns of pioneers of Computer Science and AI, such as Alan Turing [25, 8] and Marvin Minsky [23].", "startOffset": 111, "endOffset": 115}, {"referenceID": 2, "context": "More recently, Nick Bostrom published a book that consists of a very thorough and rigorous analysis of the several paths and risks inherent to developing superintelligences [4].", "startOffset": 173, "endOffset": 176}, {"referenceID": 1, "context": "One example is the \u201cpaperclip maximizer\u201d [3], an AI dedicated to paperclip production.", "startOffset": 41, "endOffset": 44}, {"referenceID": 23, "context": "Marvin Minskey is said to have created an earlier formulation of this thought experiment: in his version an AI designed with the goal of solving the Riemann Hypothesis transforms the entire solar system into a computer dedicated to this task [27, 23].", "startOffset": 242, "endOffset": 250}, {"referenceID": 19, "context": "Marvin Minskey is said to have created an earlier formulation of this thought experiment: in his version an AI designed with the goal of solving the Riemann Hypothesis transforms the entire solar system into a computer dedicated to this task [27, 23].", "startOffset": 242, "endOffset": 250}, {"referenceID": 9, "context": "Human beings have been doing this with increasing success: systems that play games like Chess [5] and Go [12], that drive [10], that recognise faces [29], and many others.", "startOffset": 105, "endOffset": 109}, {"referenceID": 7, "context": "Human beings have been doing this with increasing success: systems that play games like Chess [5] and Go [12], that drive [10], that recognise faces [29], and many others.", "startOffset": 122, "endOffset": 126}, {"referenceID": 25, "context": "Human beings have been doing this with increasing success: systems that play games like Chess [5] and Go [12], that drive [10], that recognise faces [29], and many others.", "startOffset": 149, "endOffset": 153}, {"referenceID": 12, "context": "Evolution is a type of adaptation, but not the only one [15].", "startOffset": 56, "endOffset": 60}, {"referenceID": 13, "context": "With artificial evolution systems, such as the ones where computer programs are evolved (broadly known as genetic programming [16, 20]), we have a less clear situation.", "startOffset": 126, "endOffset": 134}, {"referenceID": 16, "context": "With artificial evolution systems, such as the ones where computer programs are evolved (broadly known as genetic programming [16, 20]), we have a less clear situation.", "startOffset": 126, "endOffset": 134}, {"referenceID": 3, "context": "David Chalmers famously labeled this class of questions as the hard problem of consciousness [6].", "startOffset": 93, "endOffset": 96}, {"referenceID": 18, "context": "Several theories have been proposed, for example eliminative materialism [22] (the idea that consciousness is somehow illusory and does not actually exist); emergentism [9] (the idea that mind is an emergent property of matter); a specific form of emergentism proposed by Hofstadter around his concept of strange loops [14]; Orchestrated objective reduction (Orch-OR) [11] (the theory that mind is created by non-computable quantum phenomena); \u201cperceptronium\u201d (the hypothesis that consciousness can be understood as a state of matter) [24]; panpsychism [7] (the theory that consciousness is a fundamental property of reality, possessed by all things) and computationalism [21] (the theory that mind supervenes on computations, and not matter [18]).", "startOffset": 73, "endOffset": 77}, {"referenceID": 6, "context": "Several theories have been proposed, for example eliminative materialism [22] (the idea that consciousness is somehow illusory and does not actually exist); emergentism [9] (the idea that mind is an emergent property of matter); a specific form of emergentism proposed by Hofstadter around his concept of strange loops [14]; Orchestrated objective reduction (Orch-OR) [11] (the theory that mind is created by non-computable quantum phenomena); \u201cperceptronium\u201d (the hypothesis that consciousness can be understood as a state of matter) [24]; panpsychism [7] (the theory that consciousness is a fundamental property of reality, possessed by all things) and computationalism [21] (the theory that mind supervenes on computations, and not matter [18]).", "startOffset": 169, "endOffset": 172}, {"referenceID": 11, "context": "Several theories have been proposed, for example eliminative materialism [22] (the idea that consciousness is somehow illusory and does not actually exist); emergentism [9] (the idea that mind is an emergent property of matter); a specific form of emergentism proposed by Hofstadter around his concept of strange loops [14]; Orchestrated objective reduction (Orch-OR) [11] (the theory that mind is created by non-computable quantum phenomena); \u201cperceptronium\u201d (the hypothesis that consciousness can be understood as a state of matter) [24]; panpsychism [7] (the theory that consciousness is a fundamental property of reality, possessed by all things) and computationalism [21] (the theory that mind supervenes on computations, and not matter [18]).", "startOffset": 319, "endOffset": 323}, {"referenceID": 8, "context": "Several theories have been proposed, for example eliminative materialism [22] (the idea that consciousness is somehow illusory and does not actually exist); emergentism [9] (the idea that mind is an emergent property of matter); a specific form of emergentism proposed by Hofstadter around his concept of strange loops [14]; Orchestrated objective reduction (Orch-OR) [11] (the theory that mind is created by non-computable quantum phenomena); \u201cperceptronium\u201d (the hypothesis that consciousness can be understood as a state of matter) [24]; panpsychism [7] (the theory that consciousness is a fundamental property of reality, possessed by all things) and computationalism [21] (the theory that mind supervenes on computations, and not matter [18]).", "startOffset": 368, "endOffset": 372}, {"referenceID": 20, "context": "Several theories have been proposed, for example eliminative materialism [22] (the idea that consciousness is somehow illusory and does not actually exist); emergentism [9] (the idea that mind is an emergent property of matter); a specific form of emergentism proposed by Hofstadter around his concept of strange loops [14]; Orchestrated objective reduction (Orch-OR) [11] (the theory that mind is created by non-computable quantum phenomena); \u201cperceptronium\u201d (the hypothesis that consciousness can be understood as a state of matter) [24]; panpsychism [7] (the theory that consciousness is a fundamental property of reality, possessed by all things) and computationalism [21] (the theory that mind supervenes on computations, and not matter [18]).", "startOffset": 535, "endOffset": 539}, {"referenceID": 4, "context": "Several theories have been proposed, for example eliminative materialism [22] (the idea that consciousness is somehow illusory and does not actually exist); emergentism [9] (the idea that mind is an emergent property of matter); a specific form of emergentism proposed by Hofstadter around his concept of strange loops [14]; Orchestrated objective reduction (Orch-OR) [11] (the theory that mind is created by non-computable quantum phenomena); \u201cperceptronium\u201d (the hypothesis that consciousness can be understood as a state of matter) [24]; panpsychism [7] (the theory that consciousness is a fundamental property of reality, possessed by all things) and computationalism [21] (the theory that mind supervenes on computations, and not matter [18]).", "startOffset": 553, "endOffset": 556}, {"referenceID": 17, "context": "Several theories have been proposed, for example eliminative materialism [22] (the idea that consciousness is somehow illusory and does not actually exist); emergentism [9] (the idea that mind is an emergent property of matter); a specific form of emergentism proposed by Hofstadter around his concept of strange loops [14]; Orchestrated objective reduction (Orch-OR) [11] (the theory that mind is created by non-computable quantum phenomena); \u201cperceptronium\u201d (the hypothesis that consciousness can be understood as a state of matter) [24]; panpsychism [7] (the theory that consciousness is a fundamental property of reality, possessed by all things) and computationalism [21] (the theory that mind supervenes on computations, and not matter [18]).", "startOffset": 672, "endOffset": 676}, {"referenceID": 15, "context": "Several theories have been proposed, for example eliminative materialism [22] (the idea that consciousness is somehow illusory and does not actually exist); emergentism [9] (the idea that mind is an emergent property of matter); a specific form of emergentism proposed by Hofstadter around his concept of strange loops [14]; Orchestrated objective reduction (Orch-OR) [11] (the theory that mind is created by non-computable quantum phenomena); \u201cperceptronium\u201d (the hypothesis that consciousness can be understood as a state of matter) [24]; panpsychism [7] (the theory that consciousness is a fundamental property of reality, possessed by all things) and computationalism [21] (the theory that mind supervenes on computations, and not matter [18]).", "startOffset": 742, "endOffset": 746}], "year": 2016, "abstractText": "There is overwhelming evidence that human intelligence is a product of Darwinian evolution. Investigating the consequences of self-modification, and more precisely, the consequences of utility function self-modification, leads to the stronger claim that not only human, but any form of intelligence is ultimately only possible within evolutionary processes. Humandesigned artificial intelligences can only remain stable until they discover how to manipulate their own utility function. By definition, a human designer cannot prevent a superhuman intelligence from modifying itself, even if protection mechanisms against this action are put in place. Without evolutionary pressure, sufficiently advanced artificial intelligences become inert by simplifying their own utility function. Within evolutionary processes, the implicit utility function is always reducible to persistence, and the control of superhuman intelligences embedded in evolutionary processes is not possible. Mechanisms against utility function self-modification are ultimately futile. Instead, scientific effort toward the mitigation of existential risks from the development of superintelligences should be in two directions: understanding consciousness, and the complex dynamics of evolutionary systems.", "creator": "LaTeX with hyperref package"}}}