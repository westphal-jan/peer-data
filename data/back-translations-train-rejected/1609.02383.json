{"id": "1609.02383", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Sep-2016", "title": "Improved Optimistic Mirror Descent for Sparsity and Curvature", "abstract": "Online Convex Optimization plays a key role in large scale machine learning. Early approaches to this problem were conservative, in which the main focus was protection against the worst case scenario. But recently several algorithms have been developed for tightening the regret bounds in easy data instances such as sparsity, predictable sequences, and curved losses. In this work we unify some of these existing techniques to obtain new update rules for the cases when these easy instances occur together. First we analyse an adaptive and optimistic update rule which achieves tighter regret bound when the loss sequence is sparse and predictable. Then we explain an update rule that dynamically adapts to the curvature of the loss function and utilizes the predictable nature of the loss sequence as well. Finally we extend these results to composite losses.", "histories": [["v1", "Thu, 8 Sep 2016 11:52:05 GMT  (18kb)", "http://arxiv.org/abs/1609.02383v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["parameswaran kamalaruban"], "accepted": false, "id": "1609.02383"}, "pdf": {"name": "1609.02383.pdf", "metadata": {"source": "CRF", "title": "Improved Optimistic Mirror Descent for Sparsity and Curvature", "authors": ["Parameswaran Kamalaruban"], "emails": ["kamalaruban.parameswaran@data61.csiro.au"], "sections": [{"heading": null, "text": "The question of the causes and causes of the excrescences of the real real real real real real real real real real real real real real real real real real real real real real real real real real real real real real real real real real real real real real real real real real real real real real real real \"real real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"real\" real \"\" real \"real\" \"real\" \"real\" \"\" \"\" \"real\" \"\" \"\" \"\" \"\" \"\" \"\" real \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"real\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\""}], "references": [{"title": "Mirror descent and nonlinear projected subgradient methods for convex optimization", "author": ["Amir Beck", "Marc Teboulle"], "venue": "Operations Research Letters,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2003}, {"title": "On the generalization ability of on-line learning algorithms", "author": ["Nicolo Cesa-Bianchi", "Alex Conconi", "Claudio Gentile"], "venue": "Information Theory, IEEE Transactions on,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2004}, {"title": "Online optimization with gradual variations", "author": ["Chao-Kai Chiang", "Tianbao Yang", "Chia-Jung Lee", "Mehrdad Mahdavi", "Chi-Jen Lu", "Rong Jin", "Shenghuo Zhu"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2012}, {"title": "Proximal regularization for online and batch learning", "author": ["Chuong B Do", "Quoc V Le", "Chuan-Sheng Foo"], "venue": "In Proceedings of the 26th Annual International Conference on Machine Learning,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2009}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["John Duchi", "Elad Hazan", "Yoram Singer"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2011}, {"title": "Logarithmic regret algorithms for online convex optimization", "author": ["Elad Hazan", "Amit Agarwal", "Satyen Kale"], "venue": "Machine Learning,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2007}, {"title": "Extracting certainty from uncertainty: Regret bounded by variation in costs", "author": ["Elad Hazan", "Satyen Kale"], "venue": "Machine learning,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "Adaptive online gradient descent", "author": ["Elad Hazan", "Alexander Rakhlin", "Peter L Bartlett"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2007}, {"title": "On the generalization ability of online strongly convex programming algorithms", "author": ["ShamMKakade", "Ambuj Tewari"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2009}, {"title": "Analysis techniques for adaptive online learning", "author": ["H Brendan McMahan"], "venue": "arXiv preprint arXiv:1403.3465,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "Accelerating optimization via adaptive prediction", "author": ["Mehryar Mohri", "Scott Yang"], "venue": "arXiv preprint arXiv:1509.05760,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2015}, {"title": "Online-batch strongly convex multi kernel learning", "author": ["Francesco Orabona", "Luo Jie", "Barbara Caputo"], "venue": "In Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2010}, {"title": "Online learning with predictable sequences", "author": ["Alexander Rakhlin", "Karthik Sridharan"], "venue": "arXiv preprint arXiv:1208.3728,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2012}, {"title": "Online learning and online convex optimization", "author": ["Shai Shalev-Shwartz"], "venue": "Foundations and Trends R  \u00a9 in Machine Learning,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2011}, {"title": "On the universality of online mirror descent", "author": ["Nati Srebro", "Karthik Sridharan", "Ambuj Tewari"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2011}], "referenceMentions": [{"referenceID": 13, "context": "[15] provides a detailed analysis of the OCO problem setting and discusses several applications of this paradigm - online regression, prediction with expert advice, and online ranking.", "startOffset": 0, "endOffset": 4}, {"referenceID": 4, "context": "[6] replaces the single static regularizer in the standard mirror descent update 1 by a data dependent sequence of regularizers.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[4, 14] have shown that an optimistic prediction g\u0303t+1 of the next gradient gt+1 at time t can be used to achieve tighter regret bounds in the case where the loss functions are generated by some predictable process e.", "startOffset": 0, "endOffset": 7}, {"referenceID": 12, "context": "[4, 14] have shown that an optimistic prediction g\u0303t+1 of the next gradient gt+1 at time t can be used to achieve tighter regret bounds in the case where the loss functions are generated by some predictable process e.", "startOffset": 0, "endOffset": 7}, {"referenceID": 5, "context": "When the loss functions are uniformly exp-concave or strongly convex, O(logT ) regret bounds are achieved with appropriate choice of regularizers [7, 9].", "startOffset": 146, "endOffset": 152}, {"referenceID": 7, "context": "When the loss functions are uniformly exp-concave or strongly convex, O(logT ) regret bounds are achieved with appropriate choice of regularizers [7, 9].", "startOffset": 146, "endOffset": 152}, {"referenceID": 7, "context": "In that case [9] proposed an algorithm that can adapt to the convexity of the loss functions, and achieves O( \u221a T ) regret bounds for arbitrary convex losses and O(logT ) for uniformly strong-convex losses.", "startOffset": 13, "endOffset": 16}, {"referenceID": 9, "context": "Even though [11] has shown equivalence between mirror descent and a variant of FTRL (namely FTRLProx) algorithms with adaptive regularizers, no such mapping is available between optimistic mirror descent and optimistic FTRL updates.", "startOffset": 12, "endOffset": 16}, {"referenceID": 10, "context": "Recently [12] have combined adaptive FTRL and optimistic FTRL updates to achieve tighter regret bounds for sparse and predictable sequences.", "startOffset": 9, "endOffset": 13}, {"referenceID": 10, "context": "We obtained a factor of \u221a 2 improvement in the regret bound compared to that of [12], because in their regret analysis they could not apply the strong FTRL lemma from [11].", "startOffset": 80, "endOffset": 84}, {"referenceID": 9, "context": "We obtained a factor of \u221a 2 improvement in the regret bound compared to that of [12], because in their regret analysis they could not apply the strong FTRL lemma from [11].", "startOffset": 167, "endOffset": 171}, {"referenceID": 7, "context": "In this case we achieve tighter logarithmic regret bound without a priori knowledge about the lower bound on the strong-convexity parameters, in similar spirit of [9].", "startOffset": 163, "endOffset": 166}, {"referenceID": 14, "context": "The following proposition [16, 1] is handy in deriving explicit update rules for mirror descent algorithms that we have presented in this work.", "startOffset": 26, "endOffset": 33}, {"referenceID": 0, "context": "The following proposition [16, 1] is handy in deriving explicit update rules for mirror descent algorithms that we have presented in this work.", "startOffset": 26, "endOffset": 33}, {"referenceID": 2, "context": "3 Adaptive and Optimistic Mirror Descent When the sequences are predictable [4] proposed that making an optimistic prediction of xt+1 at time t itself using the optimistic prediction g\u0303t+1(g1, .", "startOffset": 76, "endOffset": 79}, {"referenceID": 6, "context": "prediction choices of g\u0303t+1 = 1 t \u2211t s=1 gs and g\u0303t+1 = gt, we obtain the variance bound [8] and the path length bound [4] respectively.", "startOffset": 89, "endOffset": 92}, {"referenceID": 2, "context": "prediction choices of g\u0303t+1 = 1 t \u2211t s=1 gs and g\u0303t+1 = gt, we obtain the variance bound [8] and the path length bound [4] respectively.", "startOffset": 119, "endOffset": 122}, {"referenceID": 2, "context": "The following lemma is a generalization of Lemma 5 from [4] for time varying norms, which gives a bound on the instantaneous linear regret of Algorithm 1.", "startOffset": 56, "endOffset": 59}, {"referenceID": 2, "context": "The following lemma is already proven by [4] and used in the proof of our Theorem 8.", "startOffset": 41, "endOffset": 44}, {"referenceID": 2, "context": "First we recover the non-adaptive optimistic mirror descent [4] and its regret bound as a corollary of Theorem 4.", "startOffset": 60, "endOffset": 63}, {"referenceID": 4, "context": "By leveraging the techniques from [6] we can adaptively construct regularizers based on the observed data.", "startOffset": 34, "endOffset": 37}, {"referenceID": 4, "context": "The regret bound obtained in the above corollary is much tighter than that of [6] and [4] when the sequence of loss functions are sparse and predictable.", "startOffset": 78, "endOffset": 81}, {"referenceID": 2, "context": "The regret bound obtained in the above corollary is much tighter than that of [6] and [4] when the sequence of loss functions are sparse and predictable.", "startOffset": 86, "endOffset": 89}, {"referenceID": 4, "context": "Even when the loss sequence is completely unpredictable, the above bound is not much worse than a constant factor of the bound in [6].", "startOffset": 130, "endOffset": 133}, {"referenceID": 7, "context": "1 from [9] for the Optimistic Mirror Descent, this inherits the properties mentioned there such as : rt\u2019s can be chosen without the knowledge of uniform lower bound on Ht\u2019s, and O(logT ) bound can be achieved even when some Ht \u2264 0 as long as H1:t t > 0.", "startOffset": 7, "endOffset": 10}, {"referenceID": 3, "context": "Now instead of running Algorithm 1 on the observed sequence of ft\u2019s, we use the modified sequence of loss functions of the form f\u0303t(x) := ft(x) + \u03bbt 2 \u2016x\u2212 x\u0302t\u2016 , \u03bbt \u2265 0, (8) which is already considered in [5] for the non-optimistic mirror descent case.", "startOffset": 205, "endOffset": 208}, {"referenceID": 3, "context": "Also note that \u2202f\u0303t(x\u0302t) = \u2202ft(x\u0302t) because the gradient of \u2016x\u2212 x\u0302t\u2016 is 0 when evaluated at x\u0302t [5].", "startOffset": 96, "endOffset": 99}, {"referenceID": 7, "context": "Based on the online balancing heuristic approach [9], the positive solution of 2R\u03bb1:t = 3 \u2016gt\u2212g\u0303t\u20162\u2217 H1:t+\u03bb1:t is given by \u03bbt = \u221a", "startOffset": 49, "endOffset": 52}, {"referenceID": 7, "context": "1 from [9] we obtain the following regret bound for Algorithm 2.", "startOffset": 7, "endOffset": 10}], "year": 2016, "abstractText": "Online Convex Optimization plays a key role in large scale machine learning. Early approaches to this problem were conservative, in which the main focus was protection against the worst case scenario. But recently several algorithms have been developed for tightening the regret bounds in easy data instances such as sparsity, predictable sequences, and curved losses. In this work we unify some of these existing techniques to obtain new update rules for the cases when these easy instances occur together. First we analyse an adaptive and optimistic update rule which achieves tighter regret bound when the loss sequence is sparse and predictable. Then we explain an update rule that dynamically adapts to the curvature of the loss function and utilizes the predictable nature of the loss sequence as well. Finally we extend these results to composite losses.", "creator": "LaTeX with hyperref package"}}}