{"id": "1609.02489", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Sep-2016", "title": "Fashion DNA: Merging Content and Sales Data for Recommendation and Article Mapping", "abstract": "We present a method to determine Fashion DNA, coordinate vectors locating fashion items in an abstract space. Our approach is based on a deep neural network architecture that ingests curated article information such as tags and images, and is trained to predict sales for a large set of frequent customers. In the process, a dual space of customer style preferences naturally arises. Interpretation of the metric of these spaces is straightforward: The product of Fashion DNA and customer style vectors yields the forecast purchase likelihood for the customer-item pair, while the angle between Fashion DNA vectors is a measure of item similarity. Importantly, our models are able to generate unbiased purchase probabilities for fashion items based solely on article information, even in absence of sales data, thus circumventing the \"cold-start problem\" of collaborative recommendation approaches. Likewise, it generalizes easily and reliably to customers outside the training set. We experiment with Fashion DNA models based on visual and/or tag item data, evaluate their recommendation power, and discuss the resulting article similarities.", "histories": [["v1", "Thu, 8 Sep 2016 16:48:20 GMT  (7601kb,D)", "http://arxiv.org/abs/1609.02489v1", "10 pages, 13 figures. Paper presented at the workshop \"Machine Learning Meets Fashion,\" KDD 2016 Conference, San Francisco, USA, March 14, 2016"]], "COMMENTS": "10 pages, 13 figures. Paper presented at the workshop \"Machine Learning Meets Fashion,\" KDD 2016 Conference, San Francisco, USA, March 14, 2016", "reviews": [], "SUBJECTS": "cs.IR cs.LG", "authors": ["christian bracher", "sebastian heinz", "roland vollgraf"], "accepted": false, "id": "1609.02489"}, "pdf": {"name": "1609.02489.pdf", "metadata": {"source": "CRF", "title": "Fashion DNA: Merging Content and Sales Data for Recommendation and Article Mapping", "authors": ["Christian Bracher", "Sebastian Heinz", "Roland Vollgraf"], "emails": ["roland.vollgraf}@zalando.de"], "sections": [{"heading": null, "text": "CCS concepts \u2022 information systems \u2192 recommendation systems; content analysis and feature selection; \u2022 human-centered computing \u2192 collaborative filtering; \u2022 computing methods \u2192 neural networks; keywords fashion data, neural networks, recommendations"}, {"heading": "1. INTRODUCTION", "text": "In fact, it is so that most of them are able to survive themselves by blaming themselves and others. (...) Most of them are not able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are not able to survive themselves. (...)"}, {"heading": "2. THE FASHION DNA MODEL", "text": "We will now proceed to describe the design of the network that produces the fashion DNA. It will take images and / or write information about items and try to predict their probability of purchase for a group of regular customers. After the training, item fDNA will be extracted from the internal activation of the network."}, {"heading": "2.1 Input data", "text": "For our experiments, we selected a \"standard\" set of 1.33 million items on sale at Zalando in 2011-2016, mainly clothing, footwear and accessories, but also cosmetics and household goods. A JPEG image of the size 177 x 256 was available for each of these items (some items had to be adapted to fit this format), most of which depict the item on a neutral white background; some were worn by one model. In addition, we used up to six \"expert labels\" to describe each item. These labels were selected to represent different qualities of the item in question: in addition to the brand and main colour, they form the product group (coding silhouette, gender, age and function), samples and labels for the retail price and fabric composition. Price labels were proposed using K-middle labels [4] of the manufacturer's logarithm (MRPs)."}, {"heading": "2.2 Purchase matrix", "text": "The fashion DNA model is trained and evaluated on the basis of purchase information supplied by us in the form of a sparse Boolean matrix indicating the items purchased by a group of 30,000 people who are among Zalando's top customers. Their probability of purchase, averaged across all customer-SKU combinations, was pavg = 1.14 \u00b7 10 \u2212 4, which corresponds to 150 orders per customer in the standard SKU rate. We instruct the network to predict these purchases by assigning a probability of a \"match\" between item and customer. As we are interested in generalizing these predictions for the many Zalando customers who are not included in the selection, we divide the base of 30,000 customers 9: 1 into a training set Jt = 27,000 customers and a validation set Jv = 3,000 customers, taking care that the purchase frequency distributions in the two groups are aligned."}, {"heading": "2.3 Mathematical model", "text": "A possible strategy for solving a referral problem is through logistic factorization [7], [8] of the purchase matrix [U]. Following this strategy, the probability pij = P (\u043fij = 1) = \u03c3 (fi \u00b7 wj + bj) is defined, (1) where the customer p.S (x) = [1 + exp (\u2212 x)] \u2212 1 is the logistic function. Furthermore, fi is a factor associated with SKU i, a factor and bj is a scalar associated with the customer p.S During the training we are set up with the segment of the purchase matrix, the quantities fi, wj and bj of logistic validation so that the (mean) cross entropy lossLtt = \u2212 1NtKt (i).S It is a Jt (1 \u2212)."}, {"heading": "2.4 Neural network architecture", "text": "We experimented with three different multi-layer neural network models (DNNs) that transform attribute and / or visual item information into fDNA. The width of their output layers defines the dimension d of fashion DNA space (in our case d = 256), which then enters the logistic regression layer (Figures 2 and 3).2.4.1 Attribute-based model Here, we used only the six attributes listed in Table 1 as input data. As described in Section 2.1, these \"expert\" tags were combined into a sparse, hot-coded vector that was delivered to a four-layer, fully networked deep neural network with steadily decreasing layer size. Activation was made non-linear by standard ReLUs, and we used outputs to achieve excessive address adjustment. The output yields \"attribute DNA,\" based only on visual image-based six days, 2.2-based information."}, {"heading": "3. FDNA-BASED RECOMMENDATIONS", "text": "A central goal of Fashion DNA is to match items with potential buyers. Remember that the network gives a sales probability pij for each pair of items i and customer j, so it is natural to rank the probabilities by item number for a particular customer to make a personalized recommendation, or to rank them by customer to find likely potential buyers for a fashion item. In this section, we examine the properties of fDNA-based product recommendations for customers."}, {"heading": "3.1 Probability distribution", "text": "The predicted probabilities cover a surprisingly wide range: The least likely customer-article matches are assigned probabilities pij < 10 \u2212 12, which are too low to be empirically confirmed, while the classifier for probable pairings can be exceptionally sure, with pij approaching 50%. To be valuable, quantitative recommendations must be unbiased: The predicted probability pij should accurately reflect the observed chance of selling the item to the customer. Since sales are binary events, comparing the probability to the truth on the ground requires the aggregation of many customer-article pairs with similar predicted probabilities to evaluate the accuracy of the prediction. Since the average probability of an article-customer agreement is low (in the order of only 10 \u2212 4 even for the frequent buyers included here), comparisons are compromised by static noise, unless large sample sizes are used. Fortunately, our model shows that our customers \"respective fashion combinations are largely blank in our model 109 and 104 of the other models."}, {"heading": "3.2 Recommendation quality", "text": "In fact, it is such that most of us are able to trump ourselves, and do so in the way they do it: in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, they do it, in the way they do it, in the way they do it, they do it, in the way they do it, they do it, in the way they do it, they do it, they do it, they do it, they do, they do it, they do it, they do it, they do it, they do, they do it, they do it, they do it, they do, they do it, they do it, they do it, they do it, they do it, they do it, they do"}, {"heading": "3.3 A Case Study", "text": "To illustrate, we now present the leading recommendations for validating items for a sample of frequent customers, a member of the training set, and compare the results of the three previously introduced fashion DNA models. (For space reasons, we are discussing only a single case. However, our observations are generally valid.) Figure 10 shows the top 20 recommended fashion items for the attribute-based model (top row), the image-based model (second highest row), and the combination model (third row). The estimated probability of purchase decreases from left to right, with the first choice being more than 10%; the mean probability of sale for the items on display is about 5%. For contrast, we also show the items deemed least likely in the combination model (fourth row), where the model estimates a negligible chance of sale (about 10-8%). Actual consumer purchases take place in the lower rows."}, {"heading": "4. EXPLORING ARTICLE SIMILARITY", "text": "As explained in section 2, a central tenet of our approach is the mapping of articles i to vectors fi in a FashionDNA space. Each metric in this space naturally defines a distance measure Dik between fashion item pairs. Cosine similarity is a simple choice that works well in practice: Dik = 1 \u2212 fi \u00b7 fk \u221a | fi | 2 | fk | 2. (4) Each fDNA model produces its own geometric structure that emphasizes various aspects of similarity."}, {"heading": "4.1 Next Neighbor Items", "text": "When selecting a sample item (here a maternity dress and a bow tie), we determine its angular distances (4) from the standard items and select the nearest neighbors based on the three fDNA models. They are shown in Figure 11. Both items result in a heterogeneous mix of items that hides the underlying abstract similarity: the closest neighbors of the dress all share the same brand, and in the case of the bow tie, the men's accessories offered by different luxury brands are found. In the image-based fDNA, the visual similarity is of paramount importance; the search identifies many dresses that are aligned in a similar way in color and style. The same analysis for the fly reveals the risks underlying the visual strategy: Here, the algorithm selects completely disjointed objects that look superficially similar, such as bras bras and a dog tag. In both cases, the most reasonable results are obtained by the combined brand selection that is found in the proximity of the garment."}, {"heading": "4.2 Large-Scale Structure", "text": "While the number of fashion items offered by Zalando is huge from a human perspective, they barely cover the 256-dimensional fDNA space. To visualize the layout of the SKUs on a larger scale, we resort to dimensional reduction techniques and find that t-SNE (stochastic embedding) is a suitable tool [11] to reveal the structure hidden in the data. The resulting maps are quite fascinating descriptions of a model landscape that combines hierarchical order at multiple levels with flowing transitions. Figure 12 shows such a map, which comes from the catalog of 4,096 randomly drawn items (subject to the weak limitation that the items are sold at least 10 times to our 100,000 most frequent customers). As the underlying model, we have used the combined attribute image fDNA. A glance at the map already shows the presence of ordered clusters, but much more interesting detail is revealed in the close-up study."}, {"heading": "5. CONCLUSIONS", "text": "In this paper, we introduced the concept of Fashion DNA, a mapping of fashion items on vectors that use deep neural networks optimized to predict purchases for a large group of customers. Based on item characteristics, our approach is capable of bypassing the cold start problem and making item recommendations even without prior purchase records. Likewise, the model is flexible enough to generate comparable quality sales predictions for validation customers. We have shown that an fDNA model is well generalizable based on item attributes and images and proposes relevant items to buyers. The combination of item and sales information imprints a wealth of structures on the item distribution in the fDNA space. We plan to enrich the model with additional types of fashion-related data such as reviews, reviews, sensations and social media that require extensions of the deep network that we will experiment with in order to address the lack of information, for example, by adding additional types of fashion-related data such as ratings, sensations and social media that will require extensions of the deep network that are more natural to the information available to the language with which many elements are available."}, {"heading": "6. ACKNOWLEDGMENTS", "text": "We thank Urs Bergmann for the valuable comment on this essay."}, {"heading": "7. REFERENCES", "text": "[1] R. Bell, Y. Koren, and C. Volinsky. Modeling relations at multiple scales to improve accuracy of large commender systems. In Proceedings of the 13th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD '07, pp. 95-104, New York, NY, USA, 2007. [2] P. Flach, J. Herna \u0301 ndez-Orallo, and C. Ferri. A coherent interpretation of AUC as a measure of aggregated classification performance. In Proceedings of the 28th International Conference on Machine Learning (ICML-11), pp. 657-664, 2011. [3] D. Goldberg, D. Nichols, B. M. Oki, and D. Terry. Using collaborative filtering to weave an information tapestry."}], "references": [{"title": "Modeling relationships at multiple scales to improve accuracy of large recommender systems", "author": ["R. Bell", "Y. Koren", "C. Volinsky"], "venue": "Proceedings of the 13th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD \u201907, pages 95\u2013104, New York, NY, USA", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2007}, {"title": "A coherent interpretation of AUC as a measure of aggregated classification performance", "author": ["P. Flach", "J. Hern\u00e1ndez-Orallo", "C. Ferri"], "venue": "Proceedings of the 28 International Conference on Machine Learning (ICML\u201311), pages 657\u2013664", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2011}, {"title": "Using collaborative filtering to weave an information tapestry", "author": ["D. Goldberg", "D. Nichols", "B.M. Oki", "D. Terry"], "venue": "Communications of the ACM, 35(12):61\u201370", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1992}, {"title": "The Elements of Statistical Learning: Data Mining", "author": ["T. Hastie", "R. Tibshirani", "J.H. Friedman"], "venue": "Inference, and Prediction (2nd ed.). Springer, New York", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2009}, {"title": "Learning deep structured semantic models for web search using clickthrough data", "author": ["P.-S. Huang", "X. He", "J. Gao", "L. Deng", "A. Acero", "L. Heck"], "venue": "Proceedings of the 22nd ACM International Conference on Information and Knowledge Management (CIKM), pages 2333\u20132338", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "Caffe: Convolutional architecture for fast feature embedding", "author": ["Y. Jia", "E. Shelhamer", "J. Donahue", "S. Karayev", "J. Long", "R. Girshick", "S. Guadarrama", "T. Darrell"], "venue": "arXiv preprint arXiv:1408.5093", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}, {"title": "Logistic matrix factorization for implicit feedback data", "author": ["C. Johnson"], "venue": "NIPS Workshop on Distributed Matrix Computations", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "Matrix factorization techniques for recommender systems", "author": ["Y. Koren", "R. Bell", "C. Volinsky"], "venue": "IEEE Computer, pages 42\u201349", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2009}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "Advances in neural information processing systems, pages 1097\u20131105", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2012}, {"title": "Methods and metrics for cold-start recommendations", "author": ["A.I. Schein", "A. Popescul", "L.H. Ungar", "D.M. Pennock"], "venue": "Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrieval, pages 253\u2013260", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2002}, {"title": "Visualizing data using t-SNE", "author": ["L. van der Maaten", "G. Hinton"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2008}], "referenceMentions": [{"referenceID": 2, "context": "Collaborative-filtering based recommender systems [3, 1] suffer from the \u201ccold-start problem\u201d [10]: Individual predictions for new customers and articles cannot be calculated in ar X iv :1 60 9.", "startOffset": 50, "endOffset": 56}, {"referenceID": 0, "context": "Collaborative-filtering based recommender systems [3, 1] suffer from the \u201ccold-start problem\u201d [10]: Individual predictions for new customers and articles cannot be calculated in ar X iv :1 60 9.", "startOffset": 50, "endOffset": 56}, {"referenceID": 9, "context": "Collaborative-filtering based recommender systems [3, 1] suffer from the \u201ccold-start problem\u201d [10]: Individual predictions for new customers and articles cannot be calculated in ar X iv :1 60 9.", "startOffset": 94, "endOffset": 98}, {"referenceID": 3, "context": "Price labels were created using k\u2013means clustering [4] of the logarithm of manufacturer suggested prices (MSRPs).", "startOffset": 51, "endOffset": 54}, {"referenceID": 6, "context": "A possible strategy to solve a recommender problem is by logistic factorization [7], [8] of the purchase matrix \u03a0.", "startOffset": 80, "endOffset": 83}, {"referenceID": 7, "context": "A possible strategy to solve a recommender problem is by logistic factorization [7], [8] of the purchase matrix \u03a0.", "startOffset": 85, "endOffset": 88}, {"referenceID": 4, "context": "We remark that \u201cdeep structured semantic models\u201d [5] solve problems similar to the one studied here.", "startOffset": 49, "endOffset": 52}, {"referenceID": 8, "context": "1 for details) into an eight-layer convolutional neural network based on the AlexNet architecture [9], resulting in \u201cimage fDNA.", "startOffset": 98, "endOffset": 101}, {"referenceID": 5, "context": "All three models were implemented in the Caffe framework [6] and used to generate fDNA vectors for the standard SKU set, with corresponding customer weights and biases.", "startOffset": 57, "endOffset": 60}, {"referenceID": 3, "context": "A common technique to analyze the performance of such a binary classifier with variable threshold is ROC analysis [4].", "startOffset": 114, "endOffset": 117}, {"referenceID": 1, "context": "As overall higher true positive rates indicate a more discriminating recommender, the area under the ROC curve (AUC score) is a simple indicator of the relative performance of the underlying model [2], with AUC = 1.", "startOffset": 197, "endOffset": 200}, {"referenceID": 10, "context": "In order to visualize the arrangement of SKUs on a larger scale, we resort to dimensionality reduction techniques, and find that t\u2013SNE (stochastic neighborhood embedding) is a suitable tool [11] to reveal the structure hidden in the data.", "startOffset": 190, "endOffset": 194}], "year": 2016, "abstractText": "We present a method to determine Fashion DNA, coordinate vectors locating fashion items in an abstract space. Our approach is based on a deep neural network architecture that ingests curated article information such as tags and images, and is trained to predict sales for a large set of frequent customers. In the process, a dual space of customer style preferences naturally arises. Interpretation of the metric of these spaces is straightforward: The product of Fashion DNA and customer style vectors yields the forecast purchase likelihood for the customer\u2013item pair, while the angle between Fashion DNA vectors is a measure of item similarity. Importantly, our models are able to generate unbiased purchase probabilities for fashion items based solely on article information, even in absence of sales data, thus circumventing the \u201ccold\u2013start problem\u201d of collaborative recommendation approaches. Likewise, it generalizes easily and reliably to customers outside the training set. We experiment with Fashion DNA models based on visual and/or tag item data, evaluate their recommendation power, and discuss the resulting article similarities.", "creator": "LaTeX with hyperref package"}}}