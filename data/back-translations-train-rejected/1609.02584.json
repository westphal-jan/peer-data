{"id": "1609.02584", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Sep-2016", "title": "Towards Better Response Times and Higher-Quality Queries in Interactive Knowledge Base Debugging", "abstract": "Many AI applications rely on knowledge encoded in a locigal knowledge base (KB). The most essential benefit of such logical KBs is the opportunity to perform automatic reasoning which however requires a KB to meet some minimal quality criteria such as consistency. Without adequate tool assistance, the task of resolving such violated quality criteria in a KB can be extremely hard, especially when the problematic KB is large and complex. To this end, interactive KB debuggers have been introduced which ask a user queries whether certain statements must or must not hold in the intended domain. The given answers help to gradually restrict the search space for KB repairs.", "histories": [["v1", "Thu, 8 Sep 2016 20:48:32 GMT  (493kb,D)", "http://arxiv.org/abs/1609.02584v1", null], ["v2", "Tue, 30 May 2017 09:57:45 GMT  (525kb,D)", "http://arxiv.org/abs/1609.02584v2", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["patrick rodler"], "accepted": false, "id": "1609.02584"}, "pdf": {"name": "1609.02584.pdf", "metadata": {"source": "CRF", "title": "Towards Better Response Times and Higher-Quality Queries in Interactive Knowledge Base Debugging", "authors": ["Patrick Rodler"], "emails": ["patrick.rodler@aau.at"], "sections": [{"heading": null, "text": "This year it is more than ever before."}, {"heading": "1 Introduction 5", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2 Preliminaries 10", "text": "2.1 Prerequisites.......................................................... 10 2.2 Knowledge Base Debugging: Basics..........................................."}, {"heading": "3 Query Computation 21", "text": ".)......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."}, {"heading": "1 Introduction", "text": "This year, it is more than ever before in the history of the country in which it is a country, in which it is a country, in which it is a country, in which it is a country."}, {"heading": "2 Preliminaries", "text": "In this section we guide the reader through the basics of (interactive) KB debugging, list the assumptions made and illustrate the concepts using several examples."}, {"heading": "2.1 Assumptions", "text": "The techniques described in this paper are applicable to any logical knowledge representation formalism L for which the sequence relationship (L1) is monotonous: is given when a new logical formula is added to a KB KL, implicit knowledge cannot be invalidated, i.e. KL | = \u03b1L implies that KL, (L2) is idempotent: is given when implicit knowledge is explicitly added to a KB KL, i.e. KL | = \u03b1L and KL does not imply new impact assessments of KB, i.e. (L4) impact assessment methods for deciding on consistency and calculating logical impact assessments of a KB and (L3) extensive: is given when each logical formula contains itself, i.e. {\u03b1L} | = \u03b1L is available for all \u03b1L, and for (L4) impact assessment methods for deciding consistency and calculating logical consequence of a KB, whereby there is a logical sequence calculator \u03b1\u03b2L [where there is a logical sequence calculator of a KB]."}, {"heading": "2.2 Knowledge Base Debugging: Basics", "text": "In fact, most people are able to recognize themselves and understand what they are doing."}, {"heading": "2.3 Interactive Knowledge Base Debugging: Basics", "text": "This year it is more than ever before."}, {"heading": "3 Query Computation", "text": "In this section, we will explain the implementation of the CALCQUERY function in Algorithm 1. < Q = > Q = > Measurands for two different quantitative quantities each, which we have already used in work on KB debugging [26, 27, 21], which can be used in the CALCQUERY function to establish the quality of queries (Section 3.2.2). (Section 3.2.3), 3. Introduction of a new RIO measurand (initially presented in [21]), which provides various general active learning variables [25] for use within the CALCALCQUERY function in the context of KB debugging, addresses the problem that the number of queries a user has to answer) of existing quantities strongly depends on the quality of the error information originally given (Section 3.2.4), 4. Study of all the measured quantities discussed (i.e. functions) in relation to their optimal values (i.e."}, {"heading": "3.1 Related Work", "text": "D & & & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; S & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D & 160; D"}, {"heading": "3.2 Active Learning in Interactive Debugging", "text": "This year it is more than ever before."}, {"heading": "3.2.1 Query Quality Measures: Preliminaries and Definitions", "text": "In the following we discuss different measurement quantities for the quantum selection. Here we withdraw to general active learning strategies. 3rd Q = Q = Q = Q = Q Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q"}, {"heading": "3.2.2 Existing Active Learning Measures for KB Debugging", "text": "The best QENT query after ENT has the property to maximize the gain of information or to minimize the expected entropy in the series of leading diagnoses after QENT."}, {"heading": "3.2.3 New Active Learning Measures for KB Debugging", "text": "Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q"}, {"heading": "3.2.4 Risk-Optimized Active Learning Measure", "text": "This year, the number of people living in the US is many times higher than in previous years."}, {"heading": "3.2.5 Summary", "text": "In fact, the fact is that most of them are able to survive themselves, and that they are able to survive themselves, \"he said in an interview with the\" New York Times. \""}, {"heading": "3.3 Q-Partition Requirements Selection", "text": "In this section, we enumerate and discuss the qualitative requirements rm, which can be derived for all quantitative quality measures discussed. \"(Q) These requirements provide the basis for building efficient search strategies for the optimal qpartition P, which are not derived from a precalculation of a pool of the qpartitions (cf. the discussion on page 22) and are described by the QPARTITIONREQSELECTION function in Algorithm 2 on page 22. The function QPARTITIONREQSELECTION in Algorithm 2 is described by Table 9. It outlines a series of requirements rm that must be considered for a q-partition P to be optimal. (some quantitative quality measures m as input.) This is the function that can be imagined as a simple reference in this table, since a certain measure m as input. The table summarizes the results obtained in Sections 3.2.2 and 3.3."}, {"heading": "3.4 Finding Optimal Q-Partitions", "text": "In this section we will discuss the implementation of the function FINDQPARTITION of algorithm 2, which provides an (almost) optimal q partition for some requirements rm, a probability measurement p, and the set of leading diagnoses D. To this end, we derive systematic search methods. According to [23], a search problem is defined by a starting state, a successor function (which returns all direct succession states of a state), path costs, and a target test. In our case, a state of a qPartition P and a successor state of a q partition P \u2032, which results from P by minimal changes, are determined by the respective optimality criteria given by the requirements rm. We consider a q partition as a target state of the search if it satisfies the requirements rm sufficiently. In other words, we specify an optimality threshold t in advance and consider a state as optimal if its distance to the fulfillment of the target (D) is measured as (D) > (D)."}, {"heading": "3.4.1 Canonical Queries and Q-Partitions", "text": "In the context of these q partitions, it is possible that the construction or verification of a q partition requires a query (cf. Definition 8), it becomes obvious that the specification of a \"canonical\" query is desirable in order to develop a time-saving and space-saving search method, which must minimize the potential size of the search tree. To this end, a key idea for hiding these q partitions in the search is the optimal one."}, {"heading": "3.4.2 Search Completeness Using Only Canonical Q-Partitions", "text": "In the light of the previous example, the question arises whether Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q"}, {"heading": "3.4.3 The Search for Q-Partitions", "text": "\",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \".,\" \",\" \",\" \",\" \".,\" \",\" \".,\" \",\" \"\"., \"\" \".,\" \"\"., \"\" \"\": \",\" \"\" \":\", \"\" \":\"., \"\" \":\", \"\": \".,\" \":\": \",\" \":\": \",\" \":\": \".,\" \":\": \",\": \":\", \":\": \",\": \":\", \":\": \",\": \":\", \":\": \",\": \":\", \":\": \",\": \":\", \":\": \":\"., \":\": \":\": \":\" I, \":\": \":\": \",\": \":\": \":\": \",\": \":\": \":\": \",\": \":\": \",\": \":\": \":\": \",\": \":\": \":\": \",\": \":\": \":\": \",\": \":\", \":\": \":\", \":\": \",\": \":\", \":\", \":\": \",\": \":\", \":\", \":\", \":\", \":\": \",\": \",\": \",\": \",\", \":\", \":\", \":\", \":\", \":\", \":\", \",\": \":\", \",\": \":\", \",\": \",\", \",\": \",\", \":\": \",\", \":\": \",\", \",\": \",\", \":\", \",\", \",\": \",\", \",\": \",\", \",\": \",\": \",\","}, {"heading": "3.4.4 Q-Partition Successor Computation", "text": "Before describing the successor function for D + -D, we consider the following remark: Q = > Q = = Q = = Q. \"We would like to emphasize that the favorable property D0 (Q) = D + D (K) = D (K) = D (K) = D (K) = D (K) = D (K) = D (K) = D (K) = D (K) = D (K) = D (K) = D (K) = D (K) = D (K) = D (K) = D (K) = D (K) = K (K) = D (K) = D (K) = D = D) = D (K) = D (K) = D (K) (K) = D (D) (D) (D) (D) (K) = D) (D) (D) (D) (D) = D) (D) (D) (D) (K) = D (K) = D (K)."}, {"heading": "3.5 Finding Optimal Queries Given an Optimal Q-Partition", "text": "In fact, it is so that most of us are able to abide by the rules which they have imposed on themselves. (...) In fact, it is so that they are able to determine themselves. (...) In fact, it is so that they are able to determine themselves. (...) \"In fact, it is so that they are able to determine themselves.\" (...) \"It is so.\" (...) \"It is so.\" (...) \"It is so.\" (...) \"It is so.\" (...) \"It is so.\" (...) \"It.\" (...). \"(.\" It. \"(.)\" (It.) \"(It.\" (It.). \"(It.).\" (It.). (It.) \"(It. (It.). (It.)\" (It. (It.). (It.) \"(It. (It.). (It. (It.). (It.). (It. (It.). (It.). (It. (It.). (It.). (It. (It.). (It.). (It. (It.). (It.). (It.). (It. (It.). (It.)"}, {"heading": "3.6 Query Enrichment", "text": "So far, we have explained how we can recognize and realize their own mistakes. Instead, it might be easier to substantiate an error that refers to answering questions that relate to answering questions: \"Q.\" \"Q.\" \"Q.\" \"Q.\" \"Q.\" \"Q.\" \"Q.\" \".\" \"\" Q. \"\". \"\" \".\" \"\". \"\" \".\" \"\" \".\" \"\". \"\" \"\". \"\" \"\".. \"\" \"\" \"\".. \"\" \"\". \"\". \"\". \"\" \".\" \"\". \"\". \"\" \".\" \"\" \".\" \"\" \".\" \"\" \"\". \"\" \"\". \"\" \".\" \"\". \"\" \".\" \"\". \"\". \".\" \".\". \".\". \"\". \".\". \"\". \"\". \".\". \"\" \".\" \".\" \"\" \".\". \".\" \".\". \".\" \".\" \"\" \"\" \"\". \"\". \"\" \".\". \"\" \".\". \"\" \"\" \".\". \".\". \"\". \"\" \"\" \".\" \"\" \"\". \".\" \"\". \".\". \".\" \".\". \"\" \".\" \".\". \"\" \"\" \"\". \".\". \"\". \".\". \".\". \".\". \".\" \".\". \"\" \".\". \"\" \".\". \".\" \"\". \"\". \".\". \"\". \".\". \"\" \".\". \"\". \".\". \".\". \".\" \"\" \".\". \"\". \".\". \"\". \".\". \".\" \"\" \".\" \"\". \"\". \"\" \"\" \"\". \"\" \".\" \".\" \".\". \"\". \".\". \"\" \".\" \"\". \".\". \"\". \".\" \".\". \".\" \"\". \".\" \"\". \"\" \"\". \".\" \"\". \".\". \""}, {"heading": "3.7 Query Optimization", "text": "In fact, most of us are able to go in search of a solution that we can take into our own hands."}, {"heading": "4 Summary and Conclusion", "text": "This year, it is closer than ever before in the history of the country."}], "references": [{"title": "eds.): The Description Logic Handbook: Theory, Implementation, and Applications", "author": ["F. Baader", "D. Calvanese", "D.L. McGuinness", "D. Nardi", "P.F. Patel-Schneider"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2007}, {"title": "What you always wanted to know about Datalog (and never dared to ask)", "author": ["S. Ceri", "G. Gottlob", "L. Tanca"], "venue": "IEEE Transactions on Knowledge and Data Engineering", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1989}, {"title": "A General Diagnosis Method for Ontologies", "author": ["G. Friedrich", "K. Shchekotykhin"], "venue": "Proceedings of the 4th International Semantic Web Conference (ISWC", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2005}, {"title": "OWL 2: The next step for OWL", "author": ["B.C. Grau", "I. Horrocks", "B. Motik", "B. Parsia", "P.F. Patel-Schneider", "U. Sattler"], "venue": "Web Semantics: Science, Services and Agents on the World Wide Web", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2008}, {"title": "Laconic and Precise Justifications in OWL", "author": ["M. Horridge", "B. Parsia", "U. Sattler"], "venue": "Proceedings of the 7th International Semantic Web Conference (ISWC", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2008}, {"title": "Extracting justifications from BioPortal ontologies", "author": ["M. Horridge", "B. Parsia", "U. Sattler"], "venue": "Proceedings of the 11th International Semantic Web Conference (ISWC", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2012}, {"title": "QUICKXPLAIN: Preferred Explanations and Relaxations for Over-Constrained Problems", "author": ["U. Junker"], "venue": "Proceedings of the Nineteenth National Conference on Artificial Intelligence, Sixteenth Conference on Innovative Applications of Artificial Intelligence", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2004}, {"title": "Finding all Justifications of OWL DL Entailments", "author": ["A. Kalyanpur", "B. Parsia", "M. Horridge", "E. Sirin"], "venue": "ISWC 2007 + ASWC 2007. LNCS,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2007}, {"title": "Debugging Unsatisfiable Classes in OWL Ontologies", "author": ["A. Kalyanpur", "B. Parsia", "E. Sirin", "J. Hendler"], "venue": "Web Semantics: Science, Services and Agents on the World Wide Web 3(4),", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2005}, {"title": "Reducibility among combinatorial problems", "author": ["R.M. Karp"], "venue": "Complexity of Computer Computations pp", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1972}, {"title": "SRIQ and SROIQ are harder than SHOIQ", "author": ["Y. Kazakov"], "venue": "Proceedings of the 21st Workshop of Description Logics", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2008}, {"title": "The incredible ELK", "author": ["Y. Kazakov", "M. Kr\u00f6tzsch", "F. Siman\u010d\u00edk"], "venue": "Journal of automated reasoning 53(1),", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2014}, {"title": "Diagnosing multiple faults", "author": ["J. de Kleer", "B.C. Williams"], "venue": "Artificial Intelligence", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1987}, {"title": "A complete anytime algorithm for number partitioning", "author": ["R.E. Korf"], "venue": "Artificial Intelligence", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1998}, {"title": "OWL 2 Web Ontology Language Structural Specification and Functional-Style Syntax", "author": ["B. Motik", "P.F. Patel-Schneider", "B. Parsia"], "venue": "W3C recommendation pp", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2009}, {"title": "Linear and Nonlinear Programming. (The McGraw-Hill Companies, Inc", "author": ["S.G. Nash", "A. Sofer"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1996}, {"title": "Debugging OWL ontologies", "author": ["B. Parsia", "E. Sirin", "A. Kalyanpur"], "venue": "Proceedings of the 14th international conference on World Wide Web", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2005}, {"title": "OWL Web Ontology Language Semantics and Abstract Syntax", "author": ["P.F. Patel-Schneider", "P. Hayes", "I Horrocks"], "venue": "W3C recommendation", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2004}, {"title": "A Theory of Diagnosis from First Principles", "author": ["R. Reiter"], "venue": "Artificial Intelligence 32(1),", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1987}, {"title": "Interactive Debugging of Knowledge Bases", "author": ["P. Rodler"], "venue": "Ph.D. thesis, Alpen-Adria Universita\u0308t Klagenfurt", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2015}, {"title": "RIO: Minimizing User Interaction in Ontology Debugging", "author": ["P. Rodler", "K. Shchekotykhin", "P. Fleiss", "G. Friedrich"], "venue": "Web Reasoning and Rule Systems, Lecture Notes in Computer Science,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2013}, {"title": "Top-down induction of decision trees classifiers \u2013 a survey", "author": ["L. Rokach", "O. Maimon"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2005}, {"title": "Artificial Intelligence: A Modern Approach", "author": ["S.J. Russell", "P. Norvig"], "venue": "Pearson Education,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2010}, {"title": "Debugging Incoherent Terminologies", "author": ["S. Schlobach", "Z. Huang", "R. Cornet", "F. Harmelen"], "venue": "Journal of Automated Reasoning 39(3),", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2007}, {"title": "Query strategy for sequential ontology debugging", "author": ["K. Shchekotykhin", "G. Friedrich"], "venue": "Proceedings of the 9th International Semantic Web Conference (ISWC", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2010}, {"title": "Interactive Ontology Debugging: Two Query Strategies for Efficient Fault Localization", "author": ["K. Shchekotykhin", "G. Friedrich", "P. Fleiss", "P. Rodler"], "venue": "Web Semantics: Science, Services and Agents on the World Wide Web 12-13,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2012}, {"title": "Sequential diagnosis of high cardinality faults in knowledge-bases by direct diagnosis generation", "author": ["K. Shchekotykhin", "G. Friedrich", "P. Rodler", "P. Fleiss"], "venue": "Proceedings of the 21st European Conference on Artificial Intelligence (ECAI", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2014}, {"title": "Debugging OWL Ontologies - A Reality Check", "author": ["H. Stuckenschmidt"], "venue": "Proceedings of the 6th International Workshop on Evaluation of Ontology-based Tools and the Semantic Web Service Challenge (EON)", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2008}], "referenceMentions": [{"referenceID": 23, "context": "To cope with such faulty KBs (violating test cases and/or requirements), diverse systems for KB debugging [24, 8, 3, 5] have been developed.", "startOffset": 106, "endOffset": 119}, {"referenceID": 7, "context": "To cope with such faulty KBs (violating test cases and/or requirements), diverse systems for KB debugging [24, 8, 3, 5] have been developed.", "startOffset": 106, "endOffset": 119}, {"referenceID": 2, "context": "To cope with such faulty KBs (violating test cases and/or requirements), diverse systems for KB debugging [24, 8, 3, 5] have been developed.", "startOffset": 106, "endOffset": 119}, {"referenceID": 4, "context": "To cope with such faulty KBs (violating test cases and/or requirements), diverse systems for KB debugging [24, 8, 3, 5] have been developed.", "startOffset": 106, "endOffset": 119}, {"referenceID": 9, "context": "the Hitting Set Problem [10] for localization of possible KB repairs or the SAT Problem [10] for reasoning and consistency checking (in case of a Propositional Logic KB, worse for more expressive logics, e.", "startOffset": 24, "endOffset": 28}, {"referenceID": 9, "context": "the Hitting Set Problem [10] for localization of possible KB repairs or the SAT Problem [10] for reasoning and consistency checking (in case of a Propositional Logic KB, worse for more expressive logics, e.", "startOffset": 88, "endOffset": 92}, {"referenceID": 3, "context": "the Web Ontology Language OWL 2, for which reasoning is 2-NEXPTIME-complete [4, 11]), the usage of such non-interactive systems is often problematic.", "startOffset": 76, "endOffset": 83}, {"referenceID": 10, "context": "the Web Ontology Language OWL 2, for which reasoning is 2-NEXPTIME-complete [4, 11]), the usage of such non-interactive systems is often problematic.", "startOffset": 76, "endOffset": 83}, {"referenceID": 27, "context": "This is substantiated by [29] where several (non-interactive) debugging systems were put to the test using faulty real-world KBs.", "startOffset": 25, "endOffset": 29}, {"referenceID": 24, "context": "For example, in [26] a sample study of real-world KBs revealed that the number of different (set-)minimal diagnoses might exceed thousand by far (1782 minimal diagnoses for a KB with only 1300 formulas).", "startOffset": 16, "endOffset": 20}, {"referenceID": 20, "context": "Additionally, fault meta information might be misleading [21, 27] resulting in completely unreasonable solutions proposed by the system.", "startOffset": 57, "endOffset": 65}, {"referenceID": 25, "context": "Additionally, fault meta information might be misleading [21, 27] resulting in completely unreasonable solutions proposed by the system.", "startOffset": 57, "endOffset": 65}, {"referenceID": 24, "context": "As a remedy for this dilemma, interactive KB debugging systems [26, 27, 21, 20, 28] were proposed.", "startOffset": 63, "endOffset": 83}, {"referenceID": 25, "context": "As a remedy for this dilemma, interactive KB debugging systems [26, 27, 21, 20, 28] were proposed.", "startOffset": 63, "endOffset": 83}, {"referenceID": 20, "context": "As a remedy for this dilemma, interactive KB debugging systems [26, 27, 21, 20, 28] were proposed.", "startOffset": 63, "endOffset": 83}, {"referenceID": 19, "context": "As a remedy for this dilemma, interactive KB debugging systems [26, 27, 21, 20, 28] were proposed.", "startOffset": 63, "endOffset": 83}, {"referenceID": 26, "context": "As a remedy for this dilemma, interactive KB debugging systems [26, 27, 21, 20, 28] were proposed.", "startOffset": 63, "endOffset": 83}, {"referenceID": 19, "context": "Figure 1: The principle of interactive KB debugging [20].", "startOffset": 52, "endOffset": 56}, {"referenceID": 19, "context": "the reader is referred to [20].", "startOffset": 26, "endOffset": 30}, {"referenceID": 8, "context": "6] [9]).", "startOffset": 3, "endOffset": 6}, {"referenceID": 26, "context": "4% reported in [28]) of overall debugging costs, it is material to reduce the number of reasoner calls in order to achieve a performance gain in KB debugging.", "startOffset": 15, "endOffset": 19}, {"referenceID": 25, "context": "Whereas in literature only three measures, namely split-in-half, entropy and RIO [27, 21, 20, 28, 26], have been analyzed and discussed, we investigate eight further (active learning [25]) measures that might be favorably employed in interactive debuggers and deduce heuristics from them.", "startOffset": 81, "endOffset": 101}, {"referenceID": 20, "context": "Whereas in literature only three measures, namely split-in-half, entropy and RIO [27, 21, 20, 28, 26], have been analyzed and discussed, we investigate eight further (active learning [25]) measures that might be favorably employed in interactive debuggers and deduce heuristics from them.", "startOffset": 81, "endOffset": 101}, {"referenceID": 19, "context": "Whereas in literature only three measures, namely split-in-half, entropy and RIO [27, 21, 20, 28, 26], have been analyzed and discussed, we investigate eight further (active learning [25]) measures that might be favorably employed in interactive debuggers and deduce heuristics from them.", "startOffset": 81, "endOffset": 101}, {"referenceID": 26, "context": "Whereas in literature only three measures, namely split-in-half, entropy and RIO [27, 21, 20, 28, 26], have been analyzed and discussed, we investigate eight further (active learning [25]) measures that might be favorably employed in interactive debuggers and deduce heuristics from them.", "startOffset": 81, "endOffset": 101}, {"referenceID": 24, "context": "Whereas in literature only three measures, namely split-in-half, entropy and RIO [27, 21, 20, 28, 26], have been analyzed and discussed, we investigate eight further (active learning [25]) measures that might be favorably employed in interactive debuggers and deduce heuristics from them.", "startOffset": 81, "endOffset": 101}, {"referenceID": 6, "context": "Finally, we show how a well-known divide-and-conquer technique [7] can be adapted to compute a set-minimal reduction of the enriched query (keeping the q-partition and optimality w.", "startOffset": 63, "endOffset": 66}, {"referenceID": 1, "context": "3 Examples of logics that comply with these requirements include, but are not restricted to Propositional Logic, Datalog [2], (decidable fragments of) First-order Predicate Logic, The Web Ontology Language (OWL [18], OWL 2 [4, 15]), sublanguages thereof such as the OWL 2 EL Profile (with polynomial time reasoning complexity [12]) or various Description Logics [1].", "startOffset": 121, "endOffset": 124}, {"referenceID": 17, "context": "3 Examples of logics that comply with these requirements include, but are not restricted to Propositional Logic, Datalog [2], (decidable fragments of) First-order Predicate Logic, The Web Ontology Language (OWL [18], OWL 2 [4, 15]), sublanguages thereof such as the OWL 2 EL Profile (with polynomial time reasoning complexity [12]) or various Description Logics [1].", "startOffset": 211, "endOffset": 215}, {"referenceID": 3, "context": "3 Examples of logics that comply with these requirements include, but are not restricted to Propositional Logic, Datalog [2], (decidable fragments of) First-order Predicate Logic, The Web Ontology Language (OWL [18], OWL 2 [4, 15]), sublanguages thereof such as the OWL 2 EL Profile (with polynomial time reasoning complexity [12]) or various Description Logics [1].", "startOffset": 223, "endOffset": 230}, {"referenceID": 14, "context": "3 Examples of logics that comply with these requirements include, but are not restricted to Propositional Logic, Datalog [2], (decidable fragments of) First-order Predicate Logic, The Web Ontology Language (OWL [18], OWL 2 [4, 15]), sublanguages thereof such as the OWL 2 EL Profile (with polynomial time reasoning complexity [12]) or various Description Logics [1].", "startOffset": 223, "endOffset": 230}, {"referenceID": 11, "context": "3 Examples of logics that comply with these requirements include, but are not restricted to Propositional Logic, Datalog [2], (decidable fragments of) First-order Predicate Logic, The Web Ontology Language (OWL [18], OWL 2 [4, 15]), sublanguages thereof such as the OWL 2 EL Profile (with polynomial time reasoning complexity [12]) or various Description Logics [1].", "startOffset": 326, "endOffset": 330}, {"referenceID": 0, "context": "3 Examples of logics that comply with these requirements include, but are not restricted to Propositional Logic, Datalog [2], (decidable fragments of) First-order Predicate Logic, The Web Ontology Language (OWL [18], OWL 2 [4, 15]), sublanguages thereof such as the OWL 2 EL Profile (with polynomial time reasoning complexity [12]) or various Description Logics [1].", "startOffset": 362, "endOffset": 365}, {"referenceID": 23, "context": "5Coherency was originally defined for Description Logic (DL) KBs [24, 17] and postulates that there is no concept C in a DL KB KDL such that KDL |= C v \u22a5.", "startOffset": 65, "endOffset": 73}, {"referenceID": 16, "context": "5Coherency was originally defined for Description Logic (DL) KBs [24, 17] and postulates that there is no concept C in a DL KB KDL such that KDL |= C v \u22a5.", "startOffset": 65, "endOffset": 73}, {"referenceID": 19, "context": "[20] Given a DPI \u3008K,B,P ,N \u3009R, the task is to find a maximal solution KB w.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "Please notice that due to the restriction on canonical solution KBs we use a definition of a diagnosis in this work that is less general than the one given in [20] (but still does not affect the set of diagnoses w.", "startOffset": 159, "endOffset": 163}, {"referenceID": 18, "context": "\u3008K,B,P ,N \u3009R, the size of which is in general O(2|K|) (if all subsets of the KB K are investigated), can be reduced to a great extent by exploiting the notion of a conflict set [19, 13, 27].", "startOffset": 177, "endOffset": 189}, {"referenceID": 12, "context": "\u3008K,B,P ,N \u3009R, the size of which is in general O(2|K|) (if all subsets of the KB K are investigated), can be reduced to a great extent by exploiting the notion of a conflict set [19, 13, 27].", "startOffset": 177, "endOffset": 189}, {"referenceID": 25, "context": "\u3008K,B,P ,N \u3009R, the size of which is in general O(2|K|) (if all subsets of the KB K are investigated), can be reduced to a great extent by exploiting the notion of a conflict set [19, 13, 27].", "startOffset": 177, "endOffset": 189}, {"referenceID": 2, "context": "[3] A (minimal) diagnosis w.", "startOffset": 0, "endOffset": 3}, {"referenceID": 19, "context": "As described comprehensively in [20], this might be accomplished by the usage of a hitting set tree (originally due to Reiter [19]) along with a method such as QuickXPlain (originally due to Junker [7]).", "startOffset": 32, "endOffset": 36}, {"referenceID": 18, "context": "As described comprehensively in [20], this might be accomplished by the usage of a hitting set tree (originally due to Reiter [19]) along with a method such as QuickXPlain (originally due to Junker [7]).", "startOffset": 126, "endOffset": 130}, {"referenceID": 6, "context": "As described comprehensively in [20], this might be accomplished by the usage of a hitting set tree (originally due to Reiter [19]) along with a method such as QuickXPlain (originally due to Junker [7]).", "startOffset": 198, "endOffset": 201}, {"referenceID": 19, "context": "For details we want to refer the reader to [20].", "startOffset": 43, "endOffset": 47}, {"referenceID": 24, "context": "For example, a sample study of real-world KBs [26] detected 1782 different minimal diagnoses for a KB with only 1300 formulas.", "startOffset": 46, "endOffset": 50}, {"referenceID": 25, "context": "\u3008K,B,P ,N \u3009R [27].", "startOffset": 13, "endOffset": 17}, {"referenceID": 25, "context": "[27, 21, 26], a q-partition is often simply referred to as partition.", "startOffset": 0, "endOffset": 12}, {"referenceID": 20, "context": "[27, 21, 26], a q-partition is often simply referred to as partition.", "startOffset": 0, "endOffset": 12}, {"referenceID": 24, "context": "[27, 21, 26], a q-partition is often simply referred to as partition.", "startOffset": 0, "endOffset": 12}, {"referenceID": 12, "context": "Note that the UPDATEDPI function subsumes further operations which we do not consider in detail such as the (Bayesian) update [13] of the probability measure p based on the new information given by the answered query (see [20, Sec.", "startOffset": 126, "endOffset": 130}, {"referenceID": 24, "context": "discuss and study existing quantitative measures m already used in works on KB debugging [26, 27, 21] that can be employed in the CALCQUERY function in order to establish the goodness of queries (Section 3.", "startOffset": 89, "endOffset": 101}, {"referenceID": 25, "context": "discuss and study existing quantitative measures m already used in works on KB debugging [26, 27, 21] that can be employed in the CALCQUERY function in order to establish the goodness of queries (Section 3.", "startOffset": 89, "endOffset": 101}, {"referenceID": 20, "context": "discuss and study existing quantitative measures m already used in works on KB debugging [26, 27, 21] that can be employed in the CALCQUERY function in order to establish the goodness of queries (Section 3.", "startOffset": 89, "endOffset": 101}, {"referenceID": 20, "context": "introduce a new measure RIO (first presented in [21]) that is embedded in a reinforcement learning scheme and particularly tackles the problem that the performance (i.", "startOffset": 48, "endOffset": 52}, {"referenceID": 25, "context": "derive improved versions from some query quality measures \u2013 including those used in [27, 21, 26] \u2013 to overcome shortcomings unveiled in the conducted in-depth theoretical evaluations (Sections 3.", "startOffset": 84, "endOffset": 96}, {"referenceID": 20, "context": "derive improved versions from some query quality measures \u2013 including those used in [27, 21, 26] \u2013 to overcome shortcomings unveiled in the conducted in-depth theoretical evaluations (Sections 3.", "startOffset": 84, "endOffset": 96}, {"referenceID": 24, "context": "derive improved versions from some query quality measures \u2013 including those used in [27, 21, 26] \u2013 to overcome shortcomings unveiled in the conducted in-depth theoretical evaluations (Sections 3.", "startOffset": 84, "endOffset": 96}, {"referenceID": 24, "context": "Existing works [26, 21], on the other hand, do not exploit qualitative requirements rm but rely on the measure m using more or less a brute-force method for query selection.", "startOffset": 15, "endOffset": 23}, {"referenceID": 20, "context": "Existing works [26, 21], on the other hand, do not exploit qualitative requirements rm but rely on the measure m using more or less a brute-force method for query selection.", "startOffset": 15, "endOffset": 23}, {"referenceID": 25, "context": "In [27], qualitative requirements rm were already exploited together with the CKK algorithm [14] for the Two-Way Number Partitioning Problem9 to accelerate the search for a (nearly) optimal query w.", "startOffset": 3, "endOffset": 7}, {"referenceID": 13, "context": "In [27], qualitative requirements rm were already exploited together with the CKK algorithm [14] for the Two-Way Number Partitioning Problem9 to accelerate the search for a (nearly) optimal query w.", "startOffset": 92, "endOffset": 96}, {"referenceID": 25, "context": "Apart from that, we derive qualitative requirements for various other measures which are not addressed in [27].", "startOffset": 106, "endOffset": 110}, {"referenceID": 24, "context": "8] proposes and analyzes an improved variant of the basic query computation methods employed by [26, 21].", "startOffset": 96, "endOffset": 104}, {"referenceID": 20, "context": "8] proposes and analyzes an improved variant of the basic query computation methods employed by [26, 21].", "startOffset": 96, "endOffset": 104}, {"referenceID": 13, "context": "9Given a set of numbers, the Two-Way Number Partitioning Problem is to divide them into two subsets, so that the sum of the numbers in each subset are as nearly equal as possible [14].", "startOffset": 179, "endOffset": 183}, {"referenceID": 19, "context": "Building on the ideas of [20], e.", "startOffset": 25, "endOffset": 29}, {"referenceID": 24, "context": "Contrary to the works [26, 21, 20] which rely on a PS scenario, thus requiring the precomputation of a pool of queries (or q-partitions), we implement an approach that unites characteristics of QS and PS.", "startOffset": 22, "endOffset": 34}, {"referenceID": 20, "context": "Contrary to the works [26, 21, 20] which rely on a PS scenario, thus requiring the precomputation of a pool of queries (or q-partitions), we implement an approach that unites characteristics of QS and PS.", "startOffset": 22, "endOffset": 34}, {"referenceID": 19, "context": "Contrary to the works [26, 21, 20] which rely on a PS scenario, thus requiring the precomputation of a pool of queries (or q-partitions), we implement an approach that unites characteristics of QS and PS.", "startOffset": 22, "endOffset": 34}, {"referenceID": 20, "context": "[21] and Section 3.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13, 27]) or other criteria (cf.", "startOffset": 0, "endOffset": 8}, {"referenceID": 25, "context": "[13, 27]) or other criteria (cf.", "startOffset": 0, "endOffset": 8}, {"referenceID": 12, "context": "Moreover, we define according to [13, 27, 21, 20]", "startOffset": 33, "endOffset": 49}, {"referenceID": 25, "context": "Moreover, we define according to [13, 27, 21, 20]", "startOffset": 33, "endOffset": 49}, {"referenceID": 20, "context": "Moreover, we define according to [13, 27, 21, 20]", "startOffset": 33, "endOffset": 49}, {"referenceID": 19, "context": "Moreover, we define according to [13, 27, 21, 20]", "startOffset": 33, "endOffset": 49}, {"referenceID": 19, "context": "for some set of diagnoses X, with assuming that for X := D this sum is equal to 1 [20] (this can always be achieved by normalizing each diagnosis probability p(D) forD \u2208 D, i.", "startOffset": 82, "endOffset": 86}, {"referenceID": 19, "context": "[20]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "4 and 9] and [13].", "startOffset": 13, "endOffset": 17}, {"referenceID": 24, "context": "2, we present and discuss two query quality measures that have already been extensively analyzed in (debugging) literature [26, 27, 21, 20], which we will use in the example.", "startOffset": 123, "endOffset": 139}, {"referenceID": 25, "context": "2, we present and discuss two query quality measures that have already been extensively analyzed in (debugging) literature [26, 27, 21, 20], which we will use in the example.", "startOffset": 123, "endOffset": 139}, {"referenceID": 20, "context": "2, we present and discuss two query quality measures that have already been extensively analyzed in (debugging) literature [26, 27, 21, 20], which we will use in the example.", "startOffset": 123, "endOffset": 139}, {"referenceID": 19, "context": "2, we present and discuss two query quality measures that have already been extensively analyzed in (debugging) literature [26, 27, 21, 20], which we will use in the example.", "startOffset": 123, "endOffset": 139}, {"referenceID": 24, "context": "Also in the field of interactive ontology debugging, two active learning measures have been adopted [26, 27, 21] and shown to clearly outperform a (non-active) random strategy of selecting the next query [27].", "startOffset": 100, "endOffset": 112}, {"referenceID": 25, "context": "Also in the field of interactive ontology debugging, two active learning measures have been adopted [26, 27, 21] and shown to clearly outperform a (non-active) random strategy of selecting the next query [27].", "startOffset": 100, "endOffset": 112}, {"referenceID": 20, "context": "Also in the field of interactive ontology debugging, two active learning measures have been adopted [26, 27, 21] and shown to clearly outperform a (non-active) random strategy of selecting the next query [27].", "startOffset": 100, "endOffset": 112}, {"referenceID": 25, "context": "Also in the field of interactive ontology debugging, two active learning measures have been adopted [26, 27, 21] and shown to clearly outperform a (non-active) random strategy of selecting the next query [27].", "startOffset": 204, "endOffset": 208}, {"referenceID": 0, "context": "Let q be a fixed number in [0, 1] and let Q be a set of queries where each query Q \u2208 Q satisfies p(D(Q)) = q.", "startOffset": 27, "endOffset": 33}, {"referenceID": 12, "context": "In [13] it was shown that ENT(Q) can be equivalently transformed into \uf8ee\uf8f0 \u2211", "startOffset": 3, "endOffset": 7}, {"referenceID": 25, "context": "As a consequence, SPL is generally inferior to ENT for good estimates and superior to ENT for misleading probabilities, as experiments conducted in [27, 21] indicate.", "startOffset": 148, "endOffset": 156}, {"referenceID": 20, "context": "As a consequence, SPL is generally inferior to ENT for good estimates and superior to ENT for misleading probabilities, as experiments conducted in [27, 21] indicate.", "startOffset": 148, "endOffset": 156}, {"referenceID": 20, "context": "Before we introduce our new measure RIO (first presented in [21]) for query selection in", "startOffset": 60, "endOffset": 64}, {"referenceID": 25, "context": "In fact, the H measure is only a slight modification of the ENT measure [27] and both measures coincide for queries Q satisfying D(Q) = \u2205.", "startOffset": 72, "endOffset": 76}, {"referenceID": 21, "context": "Moreover, EMCa0 is equal to the Gini Index [22], a frequently adopted (information) gain measure in decision tree learning.", "startOffset": 43, "endOffset": 47}, {"referenceID": 25, "context": "The fundamental difference between ENT and SPL concerning the number of queries to a user required during a debugging session is witnessed by experiments conducted in [27, 26, 21].", "startOffset": 167, "endOffset": 179}, {"referenceID": 24, "context": "The fundamental difference between ENT and SPL concerning the number of queries to a user required during a debugging session is witnessed by experiments conducted in [27, 26, 21].", "startOffset": 167, "endOffset": 179}, {"referenceID": 20, "context": "The fundamental difference between ENT and SPL concerning the number of queries to a user required during a debugging session is witnessed by experiments conducted in [27, 26, 21].", "startOffset": 167, "endOffset": 179}, {"referenceID": 20, "context": "Compared to the usage of the more appropriate measure among {ENT,SPL} in a particular debugging scenario, the reliance upon the worse measure among {ENT,SPL} amounted to several hundred percent of time or effort overhead for the interacting user on average and even reached numbers higher than 2000% [21].", "startOffset": 300, "endOffset": 304}, {"referenceID": 22, "context": "According to [23], a search problem is defined by an initial state, a successor function (that returns all direct successor states of a state), path costs and a goal test.", "startOffset": 13, "endOffset": 17}, {"referenceID": 25, "context": "[27]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "[8] Let K be a KB and \u03b1 an axiom, both over L.", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "mC\u3008K,B,P,N \u3009R = {\u30081, 3\u3009 , \u30081, 4\u3009 , \u30082, 3\u3009 , \u30085\u3009} and the set of minimal diagnoses (minimal hitting sets of mC\u3008K,B,P,N \u3009R ) mD\u3008K,B,P,N \u3009R = {D1,D2,D3} = {[1, 2, 5], [1, 3, 5], [3, 4, 5]}.", "startOffset": 153, "endOffset": 162}, {"referenceID": 1, "context": "mC\u3008K,B,P,N \u3009R = {\u30081, 3\u3009 , \u30081, 4\u3009 , \u30082, 3\u3009 , \u30085\u3009} and the set of minimal diagnoses (minimal hitting sets of mC\u3008K,B,P,N \u3009R ) mD\u3008K,B,P,N \u3009R = {D1,D2,D3} = {[1, 2, 5], [1, 3, 5], [3, 4, 5]}.", "startOffset": 153, "endOffset": 162}, {"referenceID": 4, "context": "mC\u3008K,B,P,N \u3009R = {\u30081, 3\u3009 , \u30081, 4\u3009 , \u30082, 3\u3009 , \u30085\u3009} and the set of minimal diagnoses (minimal hitting sets of mC\u3008K,B,P,N \u3009R ) mD\u3008K,B,P,N \u3009R = {D1,D2,D3} = {[1, 2, 5], [1, 3, 5], [3, 4, 5]}.", "startOffset": 153, "endOffset": 162}, {"referenceID": 0, "context": "mC\u3008K,B,P,N \u3009R = {\u30081, 3\u3009 , \u30081, 4\u3009 , \u30082, 3\u3009 , \u30085\u3009} and the set of minimal diagnoses (minimal hitting sets of mC\u3008K,B,P,N \u3009R ) mD\u3008K,B,P,N \u3009R = {D1,D2,D3} = {[1, 2, 5], [1, 3, 5], [3, 4, 5]}.", "startOffset": 164, "endOffset": 173}, {"referenceID": 2, "context": "mC\u3008K,B,P,N \u3009R = {\u30081, 3\u3009 , \u30081, 4\u3009 , \u30082, 3\u3009 , \u30085\u3009} and the set of minimal diagnoses (minimal hitting sets of mC\u3008K,B,P,N \u3009R ) mD\u3008K,B,P,N \u3009R = {D1,D2,D3} = {[1, 2, 5], [1, 3, 5], [3, 4, 5]}.", "startOffset": 164, "endOffset": 173}, {"referenceID": 4, "context": "mC\u3008K,B,P,N \u3009R = {\u30081, 3\u3009 , \u30081, 4\u3009 , \u30082, 3\u3009 , \u30085\u3009} and the set of minimal diagnoses (minimal hitting sets of mC\u3008K,B,P,N \u3009R ) mD\u3008K,B,P,N \u3009R = {D1,D2,D3} = {[1, 2, 5], [1, 3, 5], [3, 4, 5]}.", "startOffset": 164, "endOffset": 173}, {"referenceID": 2, "context": "mC\u3008K,B,P,N \u3009R = {\u30081, 3\u3009 , \u30081, 4\u3009 , \u30082, 3\u3009 , \u30085\u3009} and the set of minimal diagnoses (minimal hitting sets of mC\u3008K,B,P,N \u3009R ) mD\u3008K,B,P,N \u3009R = {D1,D2,D3} = {[1, 2, 5], [1, 3, 5], [3, 4, 5]}.", "startOffset": 175, "endOffset": 184}, {"referenceID": 3, "context": "mC\u3008K,B,P,N \u3009R = {\u30081, 3\u3009 , \u30081, 4\u3009 , \u30082, 3\u3009 , \u30085\u3009} and the set of minimal diagnoses (minimal hitting sets of mC\u3008K,B,P,N \u3009R ) mD\u3008K,B,P,N \u3009R = {D1,D2,D3} = {[1, 2, 5], [1, 3, 5], [3, 4, 5]}.", "startOffset": 175, "endOffset": 184}, {"referenceID": 4, "context": "mC\u3008K,B,P,N \u3009R = {\u30081, 3\u3009 , \u30081, 4\u3009 , \u30082, 3\u3009 , \u30085\u3009} and the set of minimal diagnoses (minimal hitting sets of mC\u3008K,B,P,N \u3009R ) mD\u3008K,B,P,N \u3009R = {D1,D2,D3} = {[1, 2, 5], [1, 3, 5], [3, 4, 5]}.", "startOffset": 175, "endOffset": 184}, {"referenceID": 5, "context": "For instance, a comprehensive study [6] on entailments and justifications dealing with a large corpus of real-world KBs (ontologies) from the Bioportal Repository14 reveals that the probability for a q-partition to be non-canonical can be rated pretty low in the light of the sophisticated requirements enumerated by Propositions 51 and 52.", "startOffset": 36, "endOffset": 39}, {"referenceID": 25, "context": "[27, 21], the number of canonical q-partitions considered this way will prove to be still large enough to identify (nearly) optimal q-partitions (and queries) for all discussed measures, as our preliminary experiments (still unpublished) suggest.", "startOffset": 0, "endOffset": 8}, {"referenceID": 20, "context": "[27, 21], the number of canonical q-partitions considered this way will prove to be still large enough to identify (nearly) optimal q-partitions (and queries) for all discussed measures, as our preliminary experiments (still unpublished) suggest.", "startOffset": 0, "endOffset": 8}, {"referenceID": 22, "context": "According to [23], a search problem can be described by giving the initial state, a successor function16 enumerating all direct neighbor states of a given state, the step/path costs from a given state to a successor state, some heuristics which should estimate the remaining effort (or: additional steps) towards a goal state from some given state, and the goal test which determines whether a given state is a goal state or not.", "startOffset": 13, "endOffset": 17}, {"referenceID": 25, "context": "[27]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "At first sight, we might simply choose to employ the same approach that has been exploited in [20, 21, 27].", "startOffset": 94, "endOffset": 106}, {"referenceID": 20, "context": "At first sight, we might simply choose to employ the same approach that has been exploited in [20, 21, 27].", "startOffset": 94, "endOffset": 106}, {"referenceID": 25, "context": "At first sight, we might simply choose to employ the same approach that has been exploited in [20, 21, 27].", "startOffset": 94, "endOffset": 106}, {"referenceID": 6, "context": "This approach involves the usage of a modification of an algorithm called QuickXPlain (QX for short; originally due to [7]19) which implements a divide-and-conquer strategy with regular calls to a reasoning service to find one set-minimal subsetQ\u2032 (of generally exponentially many) of a given query Q such that P(Q\u2032) = P(Q).", "startOffset": 119, "endOffset": 122}, {"referenceID": 18, "context": "1] and originally [19]).", "startOffset": 18, "endOffset": 22}, {"referenceID": 25, "context": "[27, 21]).", "startOffset": 0, "endOffset": 8}, {"referenceID": 20, "context": "[27, 21]).", "startOffset": 0, "endOffset": 8}, {"referenceID": 19, "context": "[20, 21, 27]), one has little influence on the properties of a query that is returned.", "startOffset": 0, "endOffset": 12}, {"referenceID": 20, "context": "[20, 21, 27]), one has little influence on the properties of a query that is returned.", "startOffset": 0, "endOffset": 12}, {"referenceID": 25, "context": "[20, 21, 27]), one has little influence on the properties of a query that is returned.", "startOffset": 0, "endOffset": 12}, {"referenceID": 0, "context": "one might calculate all formulas of the form A B for propositional variablesA,B and logical operators \u2208 {\u2192,\u2194}, and for Description Logics [1], e.", "startOffset": 138, "endOffset": 141}, {"referenceID": 6, "context": "6, we can apply a modified version of the QX algorithm [7].", "startOffset": 55, "endOffset": 58}, {"referenceID": 19, "context": "8] (the MINQ algorithm is stated as part of Algorithm 4 on page 103 in [20]).", "startOffset": 71, "endOffset": 75}, {"referenceID": 19, "context": "To make this paper self-contained, we quote the relevant explanatory text regarding MINQ from [20] next.", "startOffset": 94, "endOffset": 98}, {"referenceID": 19, "context": "), MINQ as described in [20] does not yet satisfy requirements (2.", "startOffset": 24, "endOffset": 28}], "year": 2017, "abstractText": "Many artificial intelligence applications rely on knowledge about a relevant real-world domain that is encoded in a knowledge base (KB) by means of some logical knowledge representation language. The most essential benefit of such logical KBs is the opportunity to perform automatic reasoning to derive implicit knowledge or to answer complex queries about the modeled domain. The feasibility of meaningful reasoning requires a KB to meet some minimal quality criteria such as consistency or coherency. Without adequate tool assistance, the task of resolving such violated quality criteria in a KB can be extremely hard, especially when the problematic KB is complex, large in size, developed by multiple people or generated by means of some automatic systems. To this end, interactive KB debuggers have been introduced which solve soundness, completeness and scalability problems of non-interactive debugging systems. User interaction takes place in the form of queries asked to a person, e.g. a domain expert. A query is a number of (logical) statements and the user is asked whether these statements must or must not hold in the intended domain that should be modeled by the KB. To construct a query, a minimal set of two solution candidates, i.e. possible KB repairs, must be available. After the answer to a query is known, the search space for solutions is pruned. Iteration of this process until there is only a single solution candidate left yields a repaired KB which features exactly the semantics desired and expected by the user. Existing interactive debuggers often rely on a pool-based strategy for query computation. A pool of query candidates is precomputed, from which the best (or a sufficiently good) candidate according to some query quality criterion is selected to be shown to the user. This often leads to the generation of many unnecessary query candidates and thus to a high number of expensive calls to logical reasoning services. Such an overhead can have a severe impact on the response time of the interactive debugger, i.e. the time between two consecutive queries. The actual problem of this approach is the quantitative nature of the query quality functions used to assess the goodness of queries. These functions more or less provide only a black-box to use in a trial-and-error search for acceptable queries. We tackle this issue by an in-depth mathematical analysis of diverse quantitative active learning query selection measures published in literature in order to determine qualitative criteria that make a query favorable from the viewpoint of a given measure. These qualitative criteria are our key to devise efficient heuristic query search methods. This proposed approach involves a three-staged optimization of a query. For the first stage, we introduce a new, theoretically well-founded and sound method for query generation that works completely without the use of logical reasoners. This method is based on the notion of canonical queries. Together with the developed heuristics, it enables to compute an (arbitrarily near to) optimal canonical query w.r.t. a given quality measure, e.g. information gain. For one canonical query, in general, multiple queries with the same quality w.r.t. the measure exist. To this end, we show that a hitting set tree search (second stage) can be employed to extract the best query among these w.r.t. additional criteria such as minimum cardinality or best understandability for 1 ar X iv :1 60 9. 02 58 4v 1 [ cs .A I] 8 S ep 2 01 6 the user. This search does not rely on logical reasoners either. With existing methods, the extraction of such queries is not (reasonably) possible. They can just calculate any set-minimal query. Consequently, this work for the first time proposes algorithms that enable a completely reasonerfree query generation for interactive KB debugging while at the same time guaranteeing optimality conditions of the generated query that existing methods cannot realize. In the third query optimization stage, which is optional, the one already computed query which optimizes a given quality measure and some of the additional criteria, can be enriched by further logical statements of very simple and easily conceivable form and afterwards be minimized again. The reason of these optional steps, involving altogether only a polynomial number of reasoner calls, can be the simplification of the statements comprised in the query. The new approach we propose for accomplishing this improves the existing algorithm for query minimization insofar as it guarantees the finding of the query that is easiest to answer for the interacting user under plausible assumptions. Furthermore, we study different relations between diverse active learning measures, e.g. superiority and equivalence relations. The obtained picture gives a hint about which measures are more favorable in which situation or which measures always lead to the same outcomes, based on given types of queries.", "creator": "LaTeX with hyperref package"}}}