{"id": "1609.02727", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Sep-2016", "title": "Detecting Singleton Review Spammers Using Semantic Similarity", "abstract": "Online reviews have increasingly become a very important resource for consumers when making purchases. Though it is becoming more and more difficult for people to make well-informed buying decisions without being deceived by fake reviews. Prior works on the opinion spam problem mostly considered classifying fake reviews using behavioral user patterns. They focused on prolific users who write more than a couple of reviews, discarding one-time reviewers. The number of singleton reviewers however is expected to be high for many review websites. While behavioral patterns are effective when dealing with elite users, for one-time reviewers, the review text needs to be exploited. In this paper we tackle the problem of detecting fake reviews written by the same person using multiple names, posting each review under a different name. We propose two methods to detect similar reviews and show the results generally outperform the vectorial similarity measures used in prior works. The first method extends the semantic similarity between words to the reviews level. The second method is based on topic modeling and exploits the similarity of the reviews topic distributions using two models: bag-of-words and bag-of-opinion-phrases. The experiments were conducted on reviews from three different datasets: Yelp (57K reviews), Trustpilot (9K reviews) and Ott dataset (800 reviews).", "histories": [["v1", "Fri, 9 Sep 2016 09:58:45 GMT  (1532kb,D)", "http://arxiv.org/abs/1609.02727v1", "6 pages, WWW 2015"]], "COMMENTS": "6 pages, WWW 2015", "reviews": [], "SUBJECTS": "cs.CL cs.LG", "authors": ["vlad sandulescu", "martin ester"], "accepted": false, "id": "1609.02727"}, "pdf": {"name": "1609.02727.pdf", "metadata": {"source": "CRF", "title": "Detecting Singleton Review Spammers Using Semantic Similarity", "authors": ["Vlad Sandulescu", "Martin Ester"], "emails": ["vlad.sandulescu@gmail.com", "ester@cs.sfu.cs"], "sections": [{"heading": null, "text": "Categories and Subject Descriptors I.7.0 [Document and Text Processing]: General; J.4 [Computer Applications]: Social and Behavioral SciencesKeywords opinion spam; fake review detection; semantic similarity; aspect-based opinion mining; latent dirichlet allocation * This paper extends some of the results of the author's (unpublished) MSc dissertation. [16] Copyright rests with the International World Wide Web Conference Committee (IW3C2). IW3C2 reserves the right to provide a hyperlink to the author's website if the material is used in electronic media. WWW '15 Companion, May 18-22, 2015, Florence, Italy. ACM 978-1-4503-3473-0 / 15 / 05. http: / / dx.doi.org / 10.1145 / 2740908.2742570."}, {"heading": "1. INTRODUCTION", "text": "In fact, most of them are able to determine for themselves what they want and what they want."}, {"heading": "2. RELATED WORK", "text": "In fact, most of them will be able to abide by the rules that they have imposed on themselves, and they will be able to understand the rules that they have imposed on themselves."}, {"heading": "3. MODELS AND EXPERIMENTAL SETUP", "text": "In this section, we first give an overview of the vector, semantic similarity and LDA models and describe the similarity measures actually used. We then present the evaluation data sets and the review text pre-processing steps for the selected models."}, {"heading": "3.1 Vectorial and semantic similarity measures", "text": "In fact, it is the case that most people are in a position to decide whether they will be able to move to another world, or whether they will be able to move to another world, or whether they will be able to move to another world, in which they are able to live, in which they are able to change the world, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they are able to decide, in which they are able to decide whether they are able to move, in which they are able to move, in which they are able to move, in which they are able to put themselves, in"}, {"heading": "3.2 LDA model", "text": "These are statistical models where each document is considered to be a mixture of latent topics, each of which contributes to the document with specific proportions. [1] These models have received increasing attention because they do not require manually labeled data to work, although they perform best when trained on large datasets. In fact, evaluations are short documents and can be abstracted as a mixture of latent topics.The topics can be equivalent to the evaluation aspects, so that the extraction of aspects can become a topic modeling problem. it should then be possible to detect opinion spam by comparing the similarity of the underlying topic distributions of evaluation aspects to a fixed spam threshold. Since [10] the topics can refer to both aspects - laptop, screen and sensations - expensive, broken. Multiple LDA-based models have been proposed by the JDA class to the J9, which also has evaluated OS, common aspect, <"}, {"heading": "3.3 Datasets and text preprocessing", "text": "We combed through Yelp and built a dataset of 57K reviews from 660 New York restaurants, and considered Yelp's recommended reviews (unfiltered) to be truthful and the unrecommended (filtered) to be spam. Several well-known studies considered Yelp's filtered reviews to be fake and unfiltered reviews to be truthful [13, 14]. We balanced the Yelp dataset so that each company would have an equal number of recommended and unrecommended reviews. The Trustpilot dataset of 9K called English reviews was kindly shared with us by the company. It contains 4- and 5-star reviews from 130 companies, only one-time reviews. There is already a balance between truthful and fake reviews. The company has been filtering fake reviews for several years, so we assumed that their detection mechanisms provide pretty good results. The Ott dataset contains 800 reviews that are truthful and publicly available."}, {"heading": "4. RESULTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Semantic similarity - Yelp", "text": "Figure 1 shows the classification performance for Yelp ratings based on the Cosine Measurement (green), its variations (including and without Lemmatization), and the Semantic Measurement (black). Of the vectorial measures, the cosine similarity to restricted POS tags and Lemmatization achieves the highest precision at a threshold of 0.75. Intuition that the values should become more accurate as the threshold is raised is borne out by the results. Accuracy is 90% when the similarity threshold is 0.8, as shown in Figure 1a. The semantic measure is generally very narrow and achieves greater precision than the vectorial measures above a threshold of 0.8. Above such thresholds, the recall is low, so the total value of the F1 value shown in Figure 1b is low."}, {"heading": "4.2 Semantic similarity - Trustpilot", "text": "The evaluation of the Trustpilot classification performance is shown in Figure 2. The semantic similarity method once again showed better overall results compared to the cosine baseline. Its accuracy follows a smoother rise toward higher thresholds and follows the cosine baseline closer than the Yelp ratings. The recall of the semantic method is also significantly higher than the other methods. At similarity thresholds above 0.7, a precision of over 80% is achieved and is above 90% above the 0.85 threshold. Although the cosine performed better with lemmatization than without lemmatization, it reasonably achieved lower precision. One possible explanation for why the recall and F1 rating are higher for Trustpilot than for Yelp could be that the opinion spammers targeting Trustpilot are not as professional. They do not make an effort to write more elaborate reviews by using the honest repetition styles more resembling the product when they are not recommended to repeat or replicate many of the same words."}, {"heading": "4.3 Distribution of reviews in Ott dataset", "text": "The purpose of this research is to detect forged ratings written by the same person under multiple names, so we did not consider it useful to run the classifier based on the semantic similarity of the Ott dataset due to the way it was created. However, since the paper [15] received significant quotes, we were curious to see if semantic similarity and cosine similarity derivatives would capture differences in the two valuation distributions across the dataset. We calculated the paired similarity between truthful and forged ratings across the dataset and plotted the cumulative distribution functions (CDF) of both in Figure 3. They show the amount of content similarities for the truthful / forged ratings separately, as well as the position and boundaries for each type and the gaps between the two curves. Regardless of the type of similarity used, vector or semantic curves clearly show the truthful gap (blue)."}, {"heading": "4.4 Bag-of-words LDA model", "text": "IR10 refers to a 10-topic LDA model, IR30 to a 30-topic model, and so on. The classifier performs best in terms of accuracy on 30 topics for both Yelp and Trustpilot records. For Yelp, IR30 exhibits a smoother increase, achieving 65% accuracy on a 0.6 threshold, and peaks at 80% on a 0.9 similarity threshold. For 10 topics, it climbs to more than 60% accuracy. The F1 score shows that 10 topics overall are better than 30, but the difference in accuracy between the two curves is significant. It does not perform well when a greater number of topics have been used. Figure 5a shows the accuracy corresponding to each value of the spam threshold for Trustpilot records."}, {"heading": "4.5 Bag-of-opinion-phrases LDA model", "text": "For the sack-of-words approach, the classifier performs worse the more topics are used, but intuitively it makes more sense if the number of topics achieves better topic separation using opinion phrases. As a result, ratings that mention the same aspects and feelings are rated higher in terms of the similarity of their topic distributions; the model performs worse in the Trustpilot dataset because there is more or less flat precision regardless of the number of topics, so we did not draw the results; the poor performance may be a result of the data set being much smaller than Yelp and plus, while Trustpilot ratings are generally much shorter; and opinion phrases lead to topic economy even more than single words. In the sack-of-words approach, the granularity of the topics is not high enough, as both authors tend to have the same aspects."}, {"heading": "5. CONCLUSIONS", "text": "We proposed two new approaches to the problem of detecting opinion spam: The first detection method is based on semantic similarity, which WordNet uses to calculate the relationship between words. We also introduced variants of cosinal similarity, which were used along with the simple cosinal measure as a basis for comparison. Experimental results showed that semantic similarity can surpass the vector model in detecting spam ratings and can capture more subtle textual cues. The precision of the rating classifier showed high results, and given the similarity threshold, it can be dynamically altered, making the method practicable for a production detection system. We also proposed a method for detecting opinion spam, using more recent research results, which aimed to extract product aspects from short texts such as user opinions and forums. We experimented with a bag-of-word model, which would match the number of phrases used for only a small number of subjects, and increased the number of the number of phrases used."}, {"heading": "6. REFERENCES", "text": "[1] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latentdirichlet Allokation. Journal of Machine Learning Research, 2003. [2] A. Budanitsky. Lexical semantic relatedness, and its application in natural language processing. 1999. [3] I. Dagan, L. Lee, and F. C. Pereira. Similarity-based models of word cooccurrence probabilities. Machine Learning, 1999. [4] G. Fei, A. Mukherjee, B. Liu, M. Castellanos, and R. Ghosh. Exploiting burstiness in reviews of spammer cooccurence probabilities."}], "references": [{"title": "Latent dirichlet allocation", "author": ["D.M. Blei", "A.Y. Ng", "M.I. Jordan"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2003}, {"title": "Lexical semantic relatedness and its application in natural language processing", "author": ["A. Budanitsky"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1999}, {"title": "Similarity-based models of word cooccurrence probabilities", "author": ["I. Dagan", "L. Lee", "F.C. Pereira"], "venue": "Machine Learning,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1999}, {"title": "Exploiting burstiness in reviews for review spammer detection", "author": ["G. Fei", "A. Mukherjee", "B. Liu", "M. Hsu", "M. Castellanos", "R. Ghosh"], "venue": "In AAAI,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2013}, {"title": "Distributional footprints of deceptive product reviews", "author": ["S. Feng", "L. Xing", "A. Gogar", "Y. Choi"], "venue": "In ICWSM,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2012}, {"title": "Opinion spam and analysis", "author": ["N. Jindal", "B. Liu"], "venue": "In WSDM,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2008}, {"title": "Detecting product review spammers using rating behaviors", "author": ["E.-P. Lim", "V.-A. Nguyen", "N. Jindal", "B. Liu", "H.W. Lauw"], "venue": "In CIKM,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2010}, {"title": "Corpus-based and knowledge-based measures of text semantic similarity", "author": ["R. Mihalcea", "C. Corley", "C. Strapparava"], "venue": "In AAAI,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2006}, {"title": "On the design of LDA models for aspect-based opinion mining", "author": ["S. Moghaddam", "M. Ester"], "venue": "In CIKM,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2012}, {"title": "Aspect based opinion mining in online reviews", "author": ["S.A. Moghaddam"], "venue": "Ph.D. thesis, Simon Fraser University,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2013}, {"title": "Spotting opinion spammers using behavioral footprints", "author": ["A. Mukherjee", "A. Kumar", "B. Liu", "J. Wang", "M. Hsu", "M. Castellanos", "R. Ghosh"], "venue": "In KDD,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2013}, {"title": "Spotting fake reviewer groups in consumer reviews", "author": ["A. Mukherjee", "B. Liu", "N. Glance"], "venue": "In WWW,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2012}, {"title": "Fake review detection: Classification and analysis of real and pseudo reviews", "author": ["A. Mukherjee", "V. Venkataraman", "B. Liu", "N. Glance"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2013}, {"title": "What yelp fake review filter might be doing", "author": ["A. Mukherjee", "V. Venkataraman", "B. Liu", "N. Glance"], "venue": "In ICWSM,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2013}, {"title": "Finding deceptive opinion spam by any stretch of the imagination", "author": ["M. Ott", "Y. Choi", "C. Cardie", "J.T. Hancock"], "venue": "In HLT,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2011}, {"title": "Opinion spam detection through semantic similarity. MSc thesis (Unpublished)", "author": ["V. Sandulescu"], "venue": "Technical University of Denmark,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2014}, {"title": "Feature-rich part-of-speech tagging with a cyclic dependency network", "author": ["K. Toutanova", "D. Klein", "C.D. Manning", "Y. Singer"], "venue": "In NAACL,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2003}, {"title": "Review spam detection via time series pattern discovery", "author": ["S. Xie", "G. Wang", "S. Lin", "P.S. Yu"], "venue": "In WWW Companion,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2012}, {"title": "User judgements of document similarity", "author": ["M. Zengin", "B. Carterette"], "venue": "Citeseer,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2013}], "referenceMentions": [{"referenceID": 15, "context": "\u2217This paper extends some of the results from the author\u2019s MSc thesis (Unpublished) [16].", "startOffset": 83, "endOffset": 87}, {"referenceID": 4, "context": "The behavioral models have shown good standalone results, while linguistic models, based on cosine similarity or n-grams, were less precise, although they did bring small improvements to the overall model accuracy when added on top of the behavioral features, see [5, 6, 7, 11, 12, 13, 14, 15].", "startOffset": 264, "endOffset": 293}, {"referenceID": 5, "context": "The behavioral models have shown good standalone results, while linguistic models, based on cosine similarity or n-grams, were less precise, although they did bring small improvements to the overall model accuracy when added on top of the behavioral features, see [5, 6, 7, 11, 12, 13, 14, 15].", "startOffset": 264, "endOffset": 293}, {"referenceID": 6, "context": "The behavioral models have shown good standalone results, while linguistic models, based on cosine similarity or n-grams, were less precise, although they did bring small improvements to the overall model accuracy when added on top of the behavioral features, see [5, 6, 7, 11, 12, 13, 14, 15].", "startOffset": 264, "endOffset": 293}, {"referenceID": 10, "context": "The behavioral models have shown good standalone results, while linguistic models, based on cosine similarity or n-grams, were less precise, although they did bring small improvements to the overall model accuracy when added on top of the behavioral features, see [5, 6, 7, 11, 12, 13, 14, 15].", "startOffset": 264, "endOffset": 293}, {"referenceID": 11, "context": "The behavioral models have shown good standalone results, while linguistic models, based on cosine similarity or n-grams, were less precise, although they did bring small improvements to the overall model accuracy when added on top of the behavioral features, see [5, 6, 7, 11, 12, 13, 14, 15].", "startOffset": 264, "endOffset": 293}, {"referenceID": 12, "context": "The behavioral models have shown good standalone results, while linguistic models, based on cosine similarity or n-grams, were less precise, although they did bring small improvements to the overall model accuracy when added on top of the behavioral features, see [5, 6, 7, 11, 12, 13, 14, 15].", "startOffset": 264, "endOffset": 293}, {"referenceID": 13, "context": "The behavioral models have shown good standalone results, while linguistic models, based on cosine similarity or n-grams, were less precise, although they did bring small improvements to the overall model accuracy when added on top of the behavioral features, see [5, 6, 7, 11, 12, 13, 14, 15].", "startOffset": 264, "endOffset": 293}, {"referenceID": 14, "context": "The behavioral models have shown good standalone results, while linguistic models, based on cosine similarity or n-grams, were less precise, although they did bring small improvements to the overall model accuracy when added on top of the behavioral features, see [5, 6, 7, 11, 12, 13, 14, 15].", "startOffset": 264, "endOffset": 293}, {"referenceID": 18, "context": "The authors of [19] concluded that human judgment used to detect semantic similarity of web document does not correlate well with cosine similarity.", "startOffset": 15, "endOffset": 19}, {"referenceID": 17, "context": "This assumption is based on studies which used real-life commercial reviews, such as [18], who observed that over 90% of the reviewers of resellerratings.", "startOffset": 85, "endOffset": 89}, {"referenceID": 14, "context": "We make an important assumption, also noted in [15]: spammers have a limited imagination when it comes down to writing completely new details in every review.", "startOffset": 47, "endOffset": 51}, {"referenceID": 7, "context": "It proposes a method which uses the knowledge-based semantic similarity measure described in [8].", "startOffset": 93, "endOffset": 96}, {"referenceID": 9, "context": "We used two models, a bag-of-words which included a restricted set of POSs and a bag-of-opinionphrases model described in [10].", "startOffset": 122, "endOffset": 126}, {"referenceID": 5, "context": "The opinion spam problem was first formulated by Jindal and Liu in the context of product reviews [6].", "startOffset": 98, "endOffset": 101}, {"referenceID": 4, "context": "The first study to tackle the opinion spam as a distributional anomaly was described in [5].", "startOffset": 88, "endOffset": 91}, {"referenceID": 3, "context": "Another detection method which relied on behavioral user features and discarded singleton reviewers is described in [4].", "startOffset": 116, "endOffset": 119}, {"referenceID": 6, "context": "This method, as well as the ones described in [7, 11, 12] can only detect fake reviews written by elite users on a review platform but exploiting review posting bursts is an intuitive way to obtain smaller time windows where suspicious activity occurs, similar to [5].", "startOffset": 46, "endOffset": 57}, {"referenceID": 10, "context": "This method, as well as the ones described in [7, 11, 12] can only detect fake reviews written by elite users on a review platform but exploiting review posting bursts is an intuitive way to obtain smaller time windows where suspicious activity occurs, similar to [5].", "startOffset": 46, "endOffset": 57}, {"referenceID": 11, "context": "This method, as well as the ones described in [7, 11, 12] can only detect fake reviews written by elite users on a review platform but exploiting review posting bursts is an intuitive way to obtain smaller time windows where suspicious activity occurs, similar to [5].", "startOffset": 46, "endOffset": 57}, {"referenceID": 4, "context": "This method, as well as the ones described in [7, 11, 12] can only detect fake reviews written by elite users on a review platform but exploiting review posting bursts is an intuitive way to obtain smaller time windows where suspicious activity occurs, similar to [5].", "startOffset": 264, "endOffset": 267}, {"referenceID": 14, "context": "The authors of [15] employed crowdsourcing through the Amazon Mechanical Turk (AMT) to create a gold-standard fake reviews dataset.", "startOffset": 15, "endOffset": 19}, {"referenceID": 12, "context": "The ability of models evaluated only against the artificially obtained AMT dataset have been proven to not generalize to real life scenarios, as proven in [13].", "startOffset": 155, "endOffset": 159}, {"referenceID": 14, "context": "This study attempted to recreate the model of [15] and evaluate it on Yelp reviews, assuming that Yelp had perfected its fraud detection algorithms in its decade of existence.", "startOffset": 46, "endOffset": 50}, {"referenceID": 11, "context": "[12] were the first to try to solve the problem of opinion spam resulted from a group collaboration between multiple spammers.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "In [11], the same authors built an unsupervised model which used the same behavioral features from [12, 13] and exploited the distributional divergence between honest users and spammers in terms of their behavioral footprints.", "startOffset": 3, "endOffset": 7}, {"referenceID": 11, "context": "In [11], the same authors built an unsupervised model which used the same behavioral features from [12, 13] and exploited the distributional divergence between honest users and spammers in terms of their behavioral footprints.", "startOffset": 99, "endOffset": 107}, {"referenceID": 12, "context": "In [11], the same authors built an unsupervised model which used the same behavioral features from [12, 13] and exploited the distributional divergence between honest users and spammers in terms of their behavioral footprints.", "startOffset": 99, "endOffset": 107}, {"referenceID": 13, "context": "In [14] the authors made an interesting observation in their study: the spammers caught by Yelp\u2019s filter seem to have \u201doverdone faking\u201d in their attempt to sound more genuine.", "startOffset": 3, "endOffset": 7}, {"referenceID": 17, "context": "The only study which specifically targets singleton reviewers is [18].", "startOffset": 65, "endOffset": 69}, {"referenceID": 4, "context": "They also claim, similarly to [5], that a flow of fake reviews coming from a hired spammer distorts the usual distribution of ratings for a product.", "startOffset": 30, "endOffset": 33}, {"referenceID": 1, "context": "According to [2], there are a few notable approaches to measure semantic relatedness and many of them are based on WordNet.", "startOffset": 13, "endOffset": 16}, {"referenceID": 7, "context": "The authors of [8] proposed a method to extend the wordto-word similarity inside WordNet to the document level and proved their method outperformed the existing vectorial approaches.", "startOffset": 15, "endOffset": 18}, {"referenceID": 0, "context": "They are explained more thoroughly in [1].", "startOffset": 38, "endOffset": 41}, {"referenceID": 9, "context": "As [10] notes, the topics may refer to both aspects - laptop, screen and sentiments - expensive, broken.", "startOffset": 3, "endOffset": 7}, {"referenceID": 8, "context": "Several LDA-based models have been proposed by [9] which also evaluated which technique, frequent nouns, POS patterns or opinion phrases (<aspect,sentiment> pairs) performs best.", "startOffset": 47, "endOffset": 50}, {"referenceID": 2, "context": "The JS measure can be rewritten in the form of equation 4, in order to decrease computational time for large vocabularies, as mentioned by [3].", "startOffset": 139, "endOffset": 142}, {"referenceID": 12, "context": "Several well known studies have considered Yelp\u2019s filtered reviews as fake and unfiltered ones as truthful [13, 14].", "startOffset": 107, "endOffset": 115}, {"referenceID": 13, "context": "Several well known studies have considered Yelp\u2019s filtered reviews as fake and unfiltered ones as truthful [13, 14].", "startOffset": 107, "endOffset": 115}, {"referenceID": 14, "context": "The Ott dataset contains 800 reviews, balanced between truthful and fake and is publicly available [15].", "startOffset": 99, "endOffset": 103}, {"referenceID": 16, "context": "We removed stopwords from all the reviews and used a POS tagger [17] to tokenize the reviews and extract only some POSs for further processing.", "startOffset": 64, "endOffset": 68}, {"referenceID": 13, "context": "It appears the Yelp spammers are doing a good job blending in with the honest reviewers, as it was also signaled in [14].", "startOffset": 116, "endOffset": 120}, {"referenceID": 14, "context": "However, since the paper [15] has received considerable citations, we were curious whether semantic similarity and cosine similarity derivatives would capture differences in the two review distributions across the entire dataset.", "startOffset": 25, "endOffset": 29}], "year": 2016, "abstractText": "Online reviews have increasingly become a very important resource for consumers when making purchases. Though it is becoming more and more difficult for people to make wellinformed buying decisions without being deceived by fake reviews. Prior works on the opinion spam problem mostly considered classifying fake reviews using behavioral user patterns. They focused on prolific users who write more than a couple of reviews, discarding one-time reviewers. The number of singleton reviewers however is expected to be high for many review websites. While behavioral patterns are effective when dealing with elite users, for one-time reviewers, the review text needs to be exploited. In this paper we tackle the problem of detecting fake reviews written by the same person using multiple names, posting each review under a different name. We propose two methods to detect similar reviews and show the results generally outperform the vectorial similarity measures used in prior works. The first method extends the semantic similarity between words to the reviews level. The second method is based on topic modeling and exploits the similarity of the reviews topic distributions using two models: bag-of-words and bag-of-opinionphrases. The experiments were conducted on reviews from three different datasets: Yelp (57K reviews), Trustpilot (9K reviews) and Ott dataset (800 reviews).", "creator": "LaTeX with hyperref package"}}}