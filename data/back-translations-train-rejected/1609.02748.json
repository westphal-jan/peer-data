{"id": "1609.02748", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Sep-2016", "title": "INSIGHT-1 at SemEval-2016 Task 5: Deep Learning for Multilingual Aspect-based Sentiment Analysis", "abstract": "This paper describes our deep learning-based approach to multilingual aspect-based sentiment analysis as part of SemEval 2016 Task 5. We use a convolutional neural network (CNN) for both aspect extraction and aspect-based sentiment analysis. We cast aspect extraction as a multi-label classification problem, outputting probabilities over aspects parameterized by a threshold. To determine the sentiment towards an aspect, we concatenate an aspect vector with every word embedding and apply a convolution over it. Our constrained system (unconstrained for English) achieves competitive results across all languages and domains, placing first or second in 5 and 7 out of 11 language-domain pairs for aspect category detection (slot 1) and sentiment polarity (slot 3) respectively, thereby demonstrating the viability of a deep learning-based approach for multilingual aspect-based sentiment analysis.", "histories": [["v1", "Fri, 9 Sep 2016 11:23:51 GMT  (98kb)", "https://arxiv.org/abs/1609.02748v1", "Published in Proceedings of SemEval-2016, 7 pages"], ["v2", "Thu, 22 Sep 2016 10:04:18 GMT  (98kb)", "http://arxiv.org/abs/1609.02748v2", "Published in Proceedings of SemEval-2016, 7 pages"]], "COMMENTS": "Published in Proceedings of SemEval-2016, 7 pages", "reviews": [], "SUBJECTS": "cs.CL cs.LG", "authors": ["sebastian ruder", "parsa ghaffari", "john g breslin"], "accepted": false, "id": "1609.02748"}, "pdf": {"name": "1609.02748.pdf", "metadata": {"source": "CRF", "title": "INSIGHT-1 at SemEval-2016 Task 5: Deep Learning for Multilingual Aspect-based Sentiment Analysis", "authors": ["Sebastian Ruder", "Parsa Ghaffari", "John G. Breslin"], "emails": ["firstname.lastname@insight-centre.org", "firstname@aylien.com"], "sections": [{"heading": null, "text": "ar Xiv: 160 9.02 748v 2 [cs.C L] 22 SE"}, {"heading": "1 Introduction", "text": "As access to the Internet increases, more and more people express their opinions online in a variety of languages. Sentiment analysis (Liu, 2012) allows us to derive superficial insights from these opinions in terms of their overall polarity. However, often, in reviews, people do not express their opinions to the company as a whole, but rather refer to specific aspects such as service in a restaurant.Aspect-based sentiment analysis allows us to go deeper and determine the mood toward such aspects of a company. Previous research in aspect-based sentiment analysis has largely focused on the English language, while SemEval 2016 Task 5 (Pontiki et al., 2016) provides a forum for multilingual aspect-based sentiment analysis.Recently, deep learning approaches have shown remarkable results for text classification and sentiment analysis (Kim, 2014). A cascade of non-linearity allows them to delineate features such as sensibility modeling."}, {"heading": "2 Related work", "text": "Aspect-based sentiment analysis has traditionally been divided into aspect extraction and sentiment analysis. Previous approaches to aspect extraction framed the task as a multi-class classification problem and relied predominantly on CRS, which used a wealth of common features, such as NER, POS tagging, analysis, semantic analysis, vocabulary, and domain-dependent approaches, such as word clusters derived from Amazon and Yelp data, while earlier approaches to sentiment analysis focused mainly on the subtask of sentiment analysis: Tang et al. (2015) use a target-dependent LSTM to determine sentiment toward a target word, while Nguyen et al. (2015) and Shirai (2015) use a recursive learning-based network that has both dependence on the electorate and dependence on previous models."}, {"heading": "3 Model", "text": "The model architecture we use is an extension of the CNN structure used by Collobert et al. (2011), which has been successfully used by many others (Kim, 2014).The model takes as input a text that is augmented to the length n. We represent the text as a summary of its word embedding x1: n, where xi-Rk is the k-dimensional vector of the i-word in the text. The curved layer pushes filters of different window sizes over the input embedding. Each filter with the weights w-Rhk creates a new feature ci for a window of h-words corresponding to the following operation: ci = f (w-xi: i + h \u2212 1 + b) (1) Note: b-R is a distorted term and f is a non-linear function, ReLU (Nair and Hinton, 2010) creates a new feature ci for a window of h-words corresponding to the following operation ci = h \u2212 1 + b) (1), 1 (1) that 1 (1), 1 (1), 1 (1) (1) (1) (1) (1) (1) (1), 1) (1) (1) (1), 1) (1) (1) (1) (1), 1) (1) (1), 1) (1) (1) (1)."}, {"heading": "4 Methodology", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Preprocessing", "text": "In preparation for the previous step, we also segment the corpus using the mmseg Python library. Listing 1: Sample sentence with aspect and sentiment annotations for English laptop domain 1 < s e n t e c e i d = \"347: 0\" > 2 < t e x t > I b o u g h t i t f o r a l e a l y a l s o and i t s AMAZING. < / t e x t > 3 < Op in io n s > 4 < Op in io n c a c e > i g o r y = \"LAPTOP # PRICE\" p o l a l i t < t o s i v \"/ > 5 < Op in io n c > o g > o PLAP # p # p = 6 p # p / e\" p p p p p / p > p p / p p p p > p / p p p > p > p > p / p / p"}, {"heading": "4.2 Hyperparameters", "text": "We use this to optimize hyperparameters by randomly searching across a wide range of values. For tasks as well as for all languages and domains, we use the following hyperparameters similar to those of Kim (2014): mini-batch size of 10, maximum sentence length of 100 tokens, word embed size of 300, drop-out rate of 0.5 and 100 filter cards. We use filter lengths of 3, 4 and 5 and 4, 5 and 6 for spectral extraction or aspect-based sentiment analysis, as these provide good results for the task at hand. English word embeddings are initialized with 300-dimensional GloVe vectors (Pennington et al., 2014), which are trained on 840B tokens of the Common Crawl corpus for unrestricted submission. Word embeddings for limited submission, for all other languages, and for words not included in the pre-batch rule."}, {"heading": "4.3 Aspect Category Detection", "text": "To extract aspects such as LAPTOP # PRICE and LAPTOP # GENERAL from sentences such as Listing 1, we eject aspect extraction as a multi-level classification problem and train a Convolutionary Neural Network (CNN) to output probability distributions across aspects, minimizing crossentropy loss. To model the multi-level output as a probability distribution, we define an aspect a of the probability distribution p for a sentence s (a | s) = 1 / n when an aspect appears in s and n contains aspects, otherwise p (a | s) = 0. We define a threshold f and discard all aspects with p (a | s) < f. After training, we select f to maximize the F1 score on the validation set.We observe that aspect distributions vary significantly depending on domain and language. Thus, the English laptop domain contains 82 aspects, while the rantdomain contains only 13 aspects."}, {"heading": "4.4 Sentiment Polarity", "text": "To obtain the aspect vector, we follow an approach similar to that of Socher et al. (2013) to represent named entities: we divide each aspect into its constituent aspects, e.g. RESTAURANT # GENERAL, in general. We embed the tokens of all aspects in an embedding space. We then seek the embedding of each aspect into its constituent elements to retrieve the aspect vector. Thus, the model should learn that aspects that share the same essence, e.g. a restaurant, correlate without forming multiple tierized models to classify between entities (restaurant) and attributes (general)."}, {"heading": "SP REST 61.370 70.588 5/9", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5 Evaluation", "text": "We participated in Slot 1: Aspect Category Detection and Slot 3: Sentiment Polarity for all areas and languages. We report on the results of aspect extraction in Table 1 and aspect-based mood analysis in Table 2."}, {"heading": "5.1 Aspect Category Detection", "text": "Although our system uses only the input set as data, it is able to achieve competitive performance in extracting multilingual aspects, placing first or second in 5 out of 11 language domain pairs. However, for English, Spanish, French and Turkish, the difference in terms of the most powerful system still remains large. We observe that initializing the system with pre-trained embeddings for general purposes causes a significant performance boost that is most pronounced in the domain domain domain. Consequently, we assume that the easiest way to overcome this performance difference is to initialize the system with embeddings trained on a large monolingual corpus in the target language. The inclusion of high-performance systems of domain information used in the domain domain domain domain domain (Pontiki et al., 2015) by pre-training on a large domain corpus, such as the dataset that is part of the Yelp multilingual function, may further enhance the use of the current characteristics of a large domain function, such as the one currently published by the Yelp Challeng.In terms of a large data challenge, for example, the threshold function should only be applied under a large domain feature."}, {"heading": "5.2 Sentiment Polarity", "text": "We report convincing results for multilingual aspect-based sentiment analysis and rank first or second in 7 out of 11 language domain pairs. Here, too, the performance difference is greatest compared to the most powerful system for English, Spanish, French and Turkish. To mitigate this, pre-trained word embedding as described in 5.1 can be used. However, without relying on dependency and constituency trees (Nguyen and Shirai, 2015) or position information (Tang et al., 2015), the model is unable to reliably triangulate aspects, especially in sentences with 2https: / / www.yelp.com / dataset _ challenge"}, {"heading": "DU PHNS 83.333 83.333 1/3", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "CH CAME 78.170 80.457 2/5", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "CH PHNS 72.401 73.346 2/5", "text": "The simple concatenation of each word vector with the aspect vector does not seem to give the model enough expressiveness to model truly aspect-dependent feelings. Formation of the model to link different surface shapes with their aspect instances should help to improve this."}, {"heading": "6 Conclusion", "text": "In this paper, we presented an in-depth learning-based approach to aspect-based sentiment analysis, using a Convolutionary Neural Network for aspect extraction and sentiment analysis as part of our submission to SemEval-2016 Task 5. We have shown compelling results in a multilingual environment that is particularly suited for neural networks due to its language and domain independence. We have evaluated our model and outlined weaknesses and potential future improvements."}, {"heading": "Acknowledgments", "text": "This project is the result of research carried out with financial support from the Irish Research Council (IRC) under grant number EBPPG / 2014 / 30 and with Aylien Ltd as Enterprise Partner. This publication is the result of research supported in part by a Science Foundation Ireland (SFI) research grant under grant number SFI / 12 / RC / 2289."}], "references": [{"title": "Koray Kavukcuoglu", "author": ["Ronan Collobert", "Jason Weston", "Leon Bottou", "Michael Karlen"], "venue": "and Pavel Kuksa.", "citeRegEx": "Collobert et al.2011", "shortCiteRegEx": null, "year": 2011}, {"title": "Convolutional Neural Networks for Sentence Classification", "author": ["Yoon Kim"], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Kim.,? \\Q2014\\E", "shortCiteRegEx": "Kim.", "year": 2014}, {"title": "Sentiment Analysis and Opinion Mining", "author": ["Bing Liu"], "venue": "Synthesis Lectures on Human Language Technologies,", "citeRegEx": "Liu.,? \\Q2012\\E", "shortCiteRegEx": "Liu.", "year": 2012}, {"title": "Rectified Linear Units Improve Restricted Boltzmann Machines", "author": ["Nair", "Hinton2010] Vinod Nair", "Geoffrey E Hinton"], "venue": "Proceedings of the 27th International Conference on Machine Learning,", "citeRegEx": "Nair et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Nair et al\\.", "year": 2010}, {"title": "PhraseRNN : Phrase Recursive Neural Network for Aspect-based Sentiment Analysis", "author": ["Nguyen", "Shirai2015] Thien Hai Nguyen", "Kiyoaki Shirai"], "venue": null, "citeRegEx": "Nguyen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Nguyen et al\\.", "year": 2015}, {"title": "Richard Socher", "author": ["Jeffrey Pennington"], "venue": "and Christopher D Manning.", "citeRegEx": "Pennington et al.2014", "shortCiteRegEx": null, "year": 2014}, {"title": "Ion Androutsopoulos", "author": ["Maria Pontiki", "Dimitrios Galanis", "John Pavlopoulos", "Haris Papageorgiou"], "venue": "and Suresh Manandhar.", "citeRegEx": "Pontiki et al.2014", "shortCiteRegEx": null, "year": 2014}, {"title": "Suresh Manandhar", "author": ["Maria Pontiki", "Dimitris Galanis", "Haris Papageorgiou"], "venue": "and Ion Androutsopoulos.", "citeRegEx": "Pontiki et al.2015", "shortCiteRegEx": null, "year": 2015}, {"title": "Jim\u00e9nez-Zafra, and G\u00fcl\u015fen Eryi\u011fit", "author": ["Marianna Apidianaki", "Xavier Tannier", "Natalia Loukachevitch", "Evgeny Kotelnikov", "Nuria Bel", "Salud Mar\u00eda"], "venue": null, "citeRegEx": "Apidianaki et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Apidianaki et al\\.", "year": 2016}, {"title": "and Andrew Y", "author": ["Richard Socher", "Danqi Chen", "Christopher D. Manning"], "venue": "Ng.", "citeRegEx": "Socher et al.2013", "shortCiteRegEx": null, "year": 2013}, {"title": "Ting Liu", "author": ["Duyu Tang", "Furu Wei", "Nan Yang", "Ming Zhou"], "venue": "and Bing Qin.", "citeRegEx": "Tang et al.2014", "shortCiteRegEx": null, "year": 2014}, {"title": "Xiaocheng Feng", "author": ["Duyu Tang", "Bing Qin"], "venue": "and Ting Liu.", "citeRegEx": "Tang et al.2015", "shortCiteRegEx": null, "year": 2015}, {"title": "Zhi-hua Zhou", "author": ["Min-ling Zhang"], "venue": "and Senior Member.", "citeRegEx": "Zhang et al.2006", "shortCiteRegEx": null, "year": 2006}], "referenceMentions": [], "year": 2016, "abstractText": "This paper describes our deep learningbased approach to multilingual aspectbased sentiment analysis as part of SemEval 2016 Task 5. We use a convolutional neural network (CNN) for both aspect extraction and aspect-based sentiment analysis. We cast aspect extraction as a multi-label classification problem, outputting probabilities over aspects parameterized by a threshold. To determine the sentiment towards an aspect, we concatenate an aspect vector with every word embedding and apply a convolution over it. Our constrained system (unconstrained for English) achieves competitive results across all languages and domains, placing first or second in 5 and 7 out of 11 language-domain pairs for aspect category detection (slot 1) and sentiment polarity (slot 3) respectively, thereby demonstrating the viability of a deep learning-based approach for multilingual aspect-based sentiment analysis.", "creator": "LaTeX with hyperref package"}}}