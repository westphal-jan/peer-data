{"id": "1609.03157", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Sep-2016", "title": "A centralized reinforcement learning method for multi-agent job scheduling in Grid", "abstract": "One of the main challenges in Grid systems is designing an adaptive, scalable, and model-independent method for job scheduling to achieve a desirable degree of load balancing and system efficiency. Centralized job scheduling methods have some drawbacks, such as single point of failure and lack of scalability. Moreover, decentralized methods require a coordination mechanism with limited communications. In this paper, we propose a multi-agent approach to job scheduling in Grid, named Centralized Learning Distributed Scheduling (CLDS), by utilizing the reinforcement learning framework. The CLDS is a model free approach that uses the information of jobs and their completion time to estimate the efficiency of resources. In this method, there are a learner agent and several scheduler agents that perform the task of learning and job scheduling with the use of a coordination strategy that maintains the communication cost at a limited level. We evaluated the efficiency of the CLDS method by designing and performing a set of experiments on a simulated Grid system under different system scales and loads. The results show that the CLDS can effectively balance the load of system even in large scale and heavy loaded Grids, while maintains its adaptive performance and scalability.", "histories": [["v1", "Sun, 11 Sep 2016 13:03:21 GMT  (558kb)", "http://arxiv.org/abs/1609.03157v1", null]], "reviews": [], "SUBJECTS": "cs.DC cs.AI", "authors": ["milad moradi"], "accepted": false, "id": "1609.03157"}, "pdf": {"name": "1609.03157.pdf", "metadata": {"source": "CRF", "title": "A centralized reinforcement learning method for multi-agent job scheduling in Grid", "authors": ["Milad Moradi"], "emails": ["mmoradi.research@gmail.com"], "sections": [{"heading": null, "text": "This year, more than ever before in the history of the country in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is not a country, but in which it is a country, a country, a city and a country."}, {"heading": "A. Centralized learning method", "text": "In this type of learning, there is no explicit communication between the agents, and each agent learns independently of the local and local reward. However, this strategy can lead to an anomalous reward q reward q reward, as there is no communication between the agents and they have no real view of the system. In this case, the agents learn according to their local information and a coordination mechanism seems to be required. To address the above problem, the scheduler agents submit their local rewards to a learner agent. At each time step, the learner agent collects the rewards and updates a service table that maintains the efficiency of resource selection. Then, the learning agent sends the updated service table to the scheduler agents, and the planners make their resource allocation decisions according to the service table. Below, each step of the learning process is thoroughly explained."}, {"heading": "B. Multi-agent job scheduling", "text": "This year, it will be able to resolve the problems mentioned before they get to grips with them."}], "references": [{"title": "Issues in multiagent resource allocation", "author": ["Y. Chevaleyre", "P.E. Dunne", "U. Endriss", "J. Lang", "M. Lemaitre", "N. Maudet"], "venue": "Informatica, vol. 30, 2006.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2006}, {"title": "A novel multi-agent reinforcement learning approach for job scheduling in Grid computing", "author": ["J. Wu", "X. Xu", "P. Zhang", "C. Liu"], "venue": "Future Generation Computer Systems, vol. 27, pp. 430-439, 2011.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2011}, {"title": "A new mechanism for resource monitoring in grid computing", "author": ["W.-C. Chung", "R.-S. Chang"], "venue": "Future Generation Computer Systems, vol. 25, pp. 1-7, 2009.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2009}, {"title": "Distributed computing in practice: the Condor experience", "author": ["D. Thain", "T. Tannenbaum", "M. Livny"], "venue": "Concurrency and computation: practice and experience, vol. 17, pp. 323-356, 2005.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2005}, {"title": "Adaptive computing on the grid using AppLeS", "author": ["F. Berman", "R. Wolski", "H. Casanova", "W. Cirne", "H. Dail", "M. Faerman"], "venue": "Parallel and Distributed Systems, IEEE Transactions on, vol. 14, pp. 369-382, 2003.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2003}, {"title": "Condor-G: A computation management agent for multiinstitutional grids", "author": ["J. Frey", "T. Tannenbaum", "M. Livny", "I. Foster", "S. Tuecke"], "venue": "Cluster Computing, vol. 5, pp. 237-246, 2002.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2002}, {"title": "A self-organizing flock of condors", "author": ["A.R. Butt", "R. Zhang", "Y.C. Hu"], "venue": "Proceedings of the 2003 ACM/IEEE conference on Supercomputing, 2003, p. 42.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2003}, {"title": "A hybrid reinforcement learning approach to autonomic resource allocation", "author": ["G. Tesauro", "N.K. Jong", "R. Das", "M.N. Bennani"], "venue": "Autonomic Computing, 2006. ICAC'06. IEEE International Conference on, 2006, pp. 65-73.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2006}, {"title": "A reinforcement learning approach to dynamic resource allocation", "author": ["D. Vengerov"], "venue": "Engineering Applications of Artificial Intelligence, vol. 20, pp. 383-390, 2007.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2007}, {"title": "A Multi-Agent Learning Approach to Online Distributed Resource Allocation", "author": ["C. Zhang", "V.R. Lesser", "P.J. Shenoy"], "venue": "IJCAI, 2009, pp. 361-366.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2009}, {"title": "Improving reliability in resource management through adaptive reinforcement learning for distributed systems", "author": ["M. Hussin", "N.A.W.A. Hamid", "K.A. Kasmiran"], "venue": "Journal of Parallel and Distributed Computing, vol. 75, pp. 93-100, 2015.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2015}, {"title": "Fuzzy scheduling with swarm intelligence-based knowledge acquisition for grid computing", "author": ["S. Garc\u00eda-Gal\u00e1n", "R. Prado", "J.M. Exposito"], "venue": "Engineering Applications of Artificial Intelligence, vol. 25, pp. 359-375, 2012.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2012}, {"title": "Adaptive load balancing: A study in multi-agent learning", "author": ["A. Schaerf", "Y. Shoham", "M. Tennenholtz"], "venue": "Journal of artificial intelligence research, pp. 475-500, 1995.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1995}, {"title": "Scheduling resources in multiuser, heterogeneous, computing environments with SmartNet", "author": ["R.F. Freund", "M. Gherrity", "S. Ambrosius", "M. Campbell", "M. Halderman", "D. Hensgen"], "venue": "Heterogeneous Computing Workshop, 1998.(HCW 98) Proceedings. 1998 Seventh, 1998, pp. 184-199.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1998}], "referenceMentions": [{"referenceID": 0, "context": "It addresses the problem of distributing a number of items among a number of agents [1].", "startOffset": 84, "endOffset": 87}, {"referenceID": 1, "context": "Grid computing delivers a set of capabilities including aggregation, selection and sharing a number of heterogeneous resources that are distributed among geographically diverse locations [2].", "startOffset": 187, "endOffset": 190}, {"referenceID": 2, "context": "When an applicable policy is used for resource allocation, Grid system achieves the speedup in job processing and provides high-quality services to users [3].", "startOffset": 154, "endOffset": 157}, {"referenceID": 1, "context": "One of the key issues in Grid systems is load balancing that is defined as completing all the jobs at hand as soon as possible [2].", "startOffset": 127, "endOffset": 130}, {"referenceID": 3, "context": "As centralized scheduling systems, which also known as traditional systems, we can point to PBS [4], SGE [5] and Condor [6].", "startOffset": 120, "endOffset": 123}, {"referenceID": 4, "context": "Most of decentralized schedulers, like AppleS [7] or Condor-G [8], may encounter many synchronization problems in resource management.", "startOffset": 46, "endOffset": 49}, {"referenceID": 5, "context": "Most of decentralized schedulers, like AppleS [7] or Condor-G [8], may encounter many synchronization problems in resource management.", "startOffset": 62, "endOffset": 65}, {"referenceID": 6, "context": "In order to tackle these problems, some scheduling methods were proposed based on coordination mechanisms, like Condor Flock P2P [9].", "startOffset": 129, "endOffset": 132}, {"referenceID": 7, "context": "[11] propose a hybrid scheduling approach that benefits from the advantages of both queuing and reinforcement learning models, in open-loop and closed-loop traffics.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "In [12], a general framework is proposed to perform dynamic resource allocation among multiple entities.", "startOffset": 3, "endOffset": 7}, {"referenceID": 9, "context": "[13] present a multi-agent learning algorithm for optimizing online resource allocation in cluster networks.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "A hybrid resource management method is proposed in [14] to improve the system reliability in Grid and Cloud computing.", "startOffset": 51, "endOffset": 55}, {"referenceID": 11, "context": "In a previous work [15], a meta-scheduler is presented for job scheduling in computational Grids.", "startOffset": 19, "endOffset": 23}, {"referenceID": 1, "context": "[2] propose a distributed learning algorithm called Ordinal Sharing Learning (OSL) based on the reinforcement learning framework.", "startOffset": 0, "endOffset": 3}, {"referenceID": 12, "context": "Before introducing our proposed method, we describe a general job scheduling model in Grid, which has been widely used in the literature to assess job scheduling algorithms [16].", "startOffset": 173, "endOffset": 177}, {"referenceID": 12, "context": "In general, the problem of decentralized job scheduling in Grids, can be modeled using a multi-agent job scheduling system [16].", "startOffset": 123, "endOffset": 127}, {"referenceID": 0, "context": ", rM} is a set of resources, P:A\u00d7N\u2192[0, 1] is a job submission function, S:A\u00d7N\u2192R is a probabilistic job size function, C:A\u00d7N\u2192R is a probabilistic capacity function, and JSR is a job scheduling rule [2].", "startOffset": 35, "endOffset": 41}, {"referenceID": 1, "context": ", rM} is a set of resources, P:A\u00d7N\u2192[0, 1] is a job submission function, S:A\u00d7N\u2192R is a probabilistic job size function, C:A\u00d7N\u2192R is a probabilistic capacity function, and JSR is a job scheduling rule [2].", "startOffset": 197, "endOffset": 200}, {"referenceID": 1, "context": "One of the reinforcement learning strategies for multiagent job scheduling is based on multiple independent learners [2].", "startOffset": 117, "endOffset": 120}, {"referenceID": 13, "context": "Least Load Selection (LLS), Random Selection (RS), and Decentralized Min-Min Selection (DMMS) [17].", "startOffset": 94, "endOffset": 98}, {"referenceID": 1, "context": "There is a metric, named Average Load of Resources (ALoR) [2], for evaluating the performance of Grid job scheduling methods.", "startOffset": 58, "endOffset": 61}, {"referenceID": 1, "context": "For each resource, the processing capacity is determined as the inverse of CPU time required to perform a job of a unit length [2].", "startOffset": 127, "endOffset": 130}, {"referenceID": 1, "context": "Considering the above assumptions, the ALoR is defined as follows [2]:", "startOffset": 66, "endOffset": 69}], "year": 2016, "abstractText": "One of the main challenges in Grid systems is designing an adaptive, scalable, and model-independent method for job scheduling to achieve a desirable degree of load balancing and system efficiency. Centralized job scheduling methods have some drawbacks, such as single point of failure and lack of scalability. Moreover, decentralized methods require a coordination mechanism with limited communications. In this paper, we propose a multi-agent approach to job scheduling in Grid, named Centralized Learning Distributed Scheduling (CLDS), by utilizing the reinforcement learning framework. The CLDS is a model free approach that uses the information of jobs and their completion time to estimate the efficiency of resources. In this method, there are a learner agent and several scheduler agents that perform the task of learning and job scheduling with the use of a coordination strategy that maintains the communication cost at a limited level. We evaluated the efficiency of the CLDS method by designing and performing a set of experiments on a simulated Grid system under different system scales and loads. The results show that the CLDS can effectively balance the load of system even in large scale and heavy loaded Grids, while maintains its adaptive performance and scalability.", "creator": "Microsoft\u00ae Word 2013"}}}