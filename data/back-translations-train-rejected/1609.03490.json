{"id": "1609.03490", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Sep-2016", "title": "Transfer String Kernel for Cross-Context DNA-Protein Binding Prediction", "abstract": "Through sequence-based classification, this paper tries to accurately predict the DNA binding sites of transcription factors (TFs) in an unannotated cellular context. Related methods in the literature fail to perform such predictions accurately, since they do not consider sample distribution shift of sequence segments from an annotated (source) context to an unannotated (target) context. We, therefore, propose a method called \"Transfer String Kernel\" (TSK) that achieves improved prediction of transcription factor binding site (TFBS) using knowledge transfer via cross-context sample adaptation. TSK maps sequence segments to a high-dimensional feature space using a discriminative mismatch string kernel framework. In this high-dimensional space, labeled examples of the source context are re-weighted so that the revised sample distribution matches the target context more closely. We have experimentally verified TSK for TFBS identifications on fourteen different TFs under a cross-organism setting. We find that TSK consistently outperforms the state-of the-art TFBS tools, especially when working with TFs whose binding sequences are not conserved across contexts. We also demonstrate the generalizability of TSK by showing its cutting-edge performance on a different set of cross-context tasks for the MHC peptide binding predictions.", "histories": [["v1", "Mon, 12 Sep 2016 17:16:24 GMT  (2504kb)", "http://arxiv.org/abs/1609.03490v1", "To be published in IEEE/ACM Transactions on Computational Biology and Bioinformatics"]], "COMMENTS": "To be published in IEEE/ACM Transactions on Computational Biology and Bioinformatics", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["ritambhara singh", "jack lanchantin", "gabriel robins", "yanjun qi"], "accepted": false, "id": "1609.03490"}, "pdf": {"name": "1609.03490.pdf", "metadata": {"source": "CRF", "title": "Transfer String Kernel for Cross-Context DNA-Protein Binding Prediction", "authors": ["Ritambhara Singh", "Jack Lanchantin", "Yanjun Qi"], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 160 9.03 490v 1 [cs.L G] 12 Sep 2016 1Index Terms - Machine Learning, Bioinformatics, Support Vector Machines, Domain Adaptation, String Classification, String KernelThis paper is originally published in IEEE / ACM Transactions on Computational Biology and Bioinformatics. Code available at github.com / QData / TransferStringKernel."}, {"heading": "1 INTRODUCTION", "text": "This year, as never before in the history of a country in which it is a country in which it is a country in which it is a country in which it is a country, a country in which it is a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country"}, {"heading": "2 METHODS: TRANSFER STRING KERNEL (TSK)", "text": "We propose a learning method called the Transfer String Kernel (TSK), which performs cross-context \"knowledge transfer\" and uses available TF binding marks from a source context to discriminate against TFBS for the same specific TF in an uncommented target context.3 We will now discuss various components of our approach. Table 1 contains a list of notation symbols used in this section."}, {"heading": "2.1 Basic Tasks: A family of sequence classification tasks", "text": "The sequence-based TFBS prediction problem can be cast as a string classification problem. For a particular TF of interest (x, y) on a particular genome under a particular cellular context, the task aims to classify a DNA sequence segment as potential TFBS or a non-binding background site (see a sequence label pair (x, y) in Figure 1 (b)). Looking at multiple TFs and different cellular contexts (Figure 1 (a)), this represents a family of sequence classification problems. In Figure 1 (b), for example, we train a string classifier using tagged segments (obtained from ChIP-seq) of TF _ 1 from the source context. The classifier is then used to predict potential TFBS locations of the same TF (TF _ 1) in the target context. This means that we are working with different TFx families based on different classification tasks."}, {"heading": "2.2 Basic Model: Mismatch String Kernels with SVM", "text": "The key idea of the string kernels is to apply a function \u03c6 () that maps sequences of arbitrary length into a vector attribute space of fixed length. In this space, a standard classifier can usually be applied like a support vector engine (SVM) [11]. [12] The kernel version SVMs calculate the decision function for an input sample x as, f (x) = i (x) = i, x) + b (3) string kernel [5] [12], implicitly an inner product in the mapped attribute space (x) as: K (x) = i, x) = < \u03c6 (x) > (4), where x = (s1)."}, {"heading": "2.3 Proposed Model: Transfer String Kernel", "text": "\"It's about the deviation between source and target samples in our application.\" (bit.ly / PSDK) \"It's about the deviation between source and target samples in our application.\" (bit.ly) \"It's about the deviation between source and target samples in our application.\" (bit.ly) \"It's about the deviation between source and target domains.\" (bit.ly) \"It's about the deviation between source context and target context.\" (bit.c) \"It's about the deviation from the source context.\" (bit.c) \"It's about the deviation from the source context.\" (bit.c) \"It's about the deviation from the source context.\" (bit.c) \"It's about the deviation from the source context.\" (bit.c) \"It's about the deviation from the source context.\""}, {"heading": "2.4 Connecting to Previous Studies", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.4.1 Sequence-motif based TFBS prediction tools", "text": "Transcription factors influence gene expression by binding to specific DNA sequences in a genomic region. Accurate models for identifying and describing the binding sites of TFs are therefore crucial for understanding cells. Previous techniques included many sequence-based computational approaches that typically used position-based sequence information to predict TFBS. Based on a number of known transcription factor binding sites (TFBS) for a particular TF, binding preference is generally represented in the form of a position weight matrix (PWM) [14], [15] (also called position-specific scoring matrix) derived from a position frequency matrix (PFM). A PFM is essentially a sequence table summarizing the number of each nucleoid observed at each position of a set of matrix TFs [15] of a position frequency (also called position frequency)."}, {"heading": "2.4.2 String Classification", "text": "Our formulation of the TFBS prediction belongs to a general category of \"string classification.\" Various methods have already been proposed to solve string classification, including generative (e.g. Hidden Markov Models HMMs) and discriminatory approaches. Among the discriminatory approaches, string kernel methods provide some of the 5 most accurate results, such as for remote protein folding and homology detection [5]. Apart from the sequence kernel [5] and (k, m) mismatch string kernels introduced in the previous section include (but are not limited to): (1) The closed kernel computes the dot product of (unrelated) k-mer numbers with gaps allowed between the elements. (2) General substring kernel similarity (16) measures the similarity between the sequences and the sequences based on the co-occurrence (e.g. substrings)."}, {"heading": "2.4.3 Domain Transfer for Genome Sequence Mining", "text": "In this context, it should be noted that this is not a purely formal measure, but a measure aimed at fulfilling the condition that the condition for achieving the objective is fulfilled."}, {"heading": "2.4.4 Covariate Shift & Domain Adaptation", "text": "This year, it has reached the point where there is only one person who is able to establish himself in the region."}, {"heading": "2.4.5 Sequence-based Prediction of peptide binding to MHC", "text": "As mentioned in the introduction, the proposed TSK method is general for all cross-domain sequence modeling problems. We are implementing TSK on another sequence-based bioinformatics task for peptide binding and comparing TSK with state-of-the-art tools on benchmark datasets. The first machine learning competition in immunology (2011) [47] compared various computer-based algorithms for classifying peptide bonds with non-binding sites for multiple MHC molecules. They used experimental labels of peptide binding from three classes of MHC molecules in humans as a performance measure. In 2012, the second machine learning competition in immunology [48] increased the number of experimental datasets for both human and mouse molecules, providing training and test data for both types. The task was formulated so that elated peptides (naturally processed by MHC) are used as a performance measure."}, {"heading": "3 EXPERIMENTAL SETUP", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 TFBS Prediction Task", "text": "For the evaluation, we selected a family of cross-genome TFBS prediction tasks, which transfer knowledge from the mouse genome to the human genome, which is the translational research situation. For a specific TF, we train a TSK model using existing ChIP-seq TFBS data from a specific cell type of the mouse genome (source) and perform TFBS predictions of the same cell type on the human genome (target)."}, {"heading": "3.2 Datasets", "text": "However, the ENCODE [1] database contains only 14 ChIPseq-TF experiments available for both types. Therefore, we use these 14 available ChIP-seq datasets for our cross-context predictions. The cell type for each of the different TFs belongs to normal blood tissue because it has the maximum number of common TF experiments in the two genomes."}, {"heading": "3.2.1 Sequence selection method", "text": "To select training and test sequences from the ENCODE database, we use the \"tip-centric standard\" described in [52]. According to this standard, each ChIPseq region has a single central position representing a positive binding point for a particular TF, and all other genomic positions are negative locations. Consequently, for positive sequences, we use the 100 nucleotides that surround each top position. In the absence of experimental evidence of where the negative \"tip\" is located, we randomly select 100 basepair-length subsequences from the genomic regions where 7positive ChIP seq TFBS tips are missing 2. Coordinates of the TFBS top positions are derived from the ChIP-seq data available in the ENCODE repository [1]."}, {"heading": "3.3 Setup", "text": "Our experiments include a few important data and hyperparameters to optimize them: A, T, C, G. The number of source samples (s): For each of the 14 TFs, we use their top 500 sequences (s). For each TFS task, we select 500 negative samples (s)."}, {"heading": "3.4 Evaluation Metric", "text": "Our investigation of TSK focuses on the SVM [53] [54] classification system. SVM is known to provide state-of-the-art for many applications [11], including a large number of achievements in mathematical biology [55]. Binary SVM learn a real-value function that assigns a continuous score to each segment of the candidate sequence based on the marked source set. Larger scores correspond to more confident predictions than the positive class. As a result, we evaluate all candidate samples within the target set using SVM prediction values. This, of course, results in using the Area Under Curve (AUC) Score (from the Receiver Operating Characteric (ROC) Curve as our most important evaluation parameter. The area below the ROC curve (AUC) is commonly used as a summary measure of the diagnostic accuracy of TSK (AUC)."}, {"heading": "3.5 Baseline approaches used for comparison", "text": "For TFBS prediction tasks, we compare TSK with the following baselines: 1) SK: represents the (k, m) mismatch kernel implementation customized from [12]. In addition, we performed a spectrum kernel and found that its performance is worse than (k, m) mismatch SK (see Section 4.1) 2) MEME: is the state-of-the-art TFBS prediction tool that evaluates each sequence for potential TF-binding events based on Position Weight Matrices (PWMs). PWMs are obtained from source sequences using the MEME-ChIP [56] motif detection algorithm, and then these motifs are used to evaluate individual target sequences using the AMA tool [57]. These tools are part of the MEME suite [58]. 3) CISF: CISFINDER [59] is another state-of-the-art toolbox used to search for the FMS for the exhaustive TBS and a DNA detection module."}, {"heading": "3.6 MHC PB Prediction Task", "text": "To demonstrate the generalization of our model, we are implementing TSK to another set of cross-contextual prediction tasks: predicting MHC proteins from mice to humans. Mouse and human data sets are provided by Machine Learning Competition in Immunology 2012 [48]. Human target data sets have peptide bindings (PBs) for 5 different MHC molecules: HLA-A0201, HLA-B0702, HLA-B4403, HLA-B5301 and HLA-5701; while we select H2-Kb PB data for the source domain, this results in 5 different PB prediction tasks. Details of these data sets are presented in Table 3. Important data statistics and hyperparameters of this task are listed as follows: 0.50.550.650.70.750.80.80.850.CF text MEISK-SKA Sv 14 Context"}, {"heading": "4 RESULTS", "text": "4.1 Selection of the basic kernel: (k, m) -incongruence kernel We choose (k, m) -incongruence kernel because it allows incongruence kernel during k-mer matching of biological sequences. Such sequences tend to mutate such as substitutions, insertions or deletions. In Table 4 we present average AUC values of 14 TF tasks for both (k, m) incongruence kernel and spectrum kernel. As expected, the inexact 9 0.5 0.55 0.6 0.65 0.7HLA-A0201 HLA-B0702 HLA-4403 HLA-B5301 HLA-B5701A UC Sc oreTSK SKFig. 4: Comparison with AUC values above 5 tasks of MHC peptide binding (PB).We use mouse data sets as source and human data sets as target. TSK exceeds SK in 4 of 5 cases."}, {"heading": "4.2 Evaluation of performance: TSK successfully transfers knowledge across different species", "text": "Table 5 presents the test results from different approaches to cross-context TFBS predictions of 14 selected TFs. For each TF, we trained on TFBS data from the mouse genome (source) and test data from the human genome (target). We select k = 10 and m = 1 for SK and TSK based on validation set performance (details in Section 4.3). TSK exceeds SK and two PWM baselines for most cases and is generally robust for unbalanced datasets (when r = 1: 2 and 1: 3). Position Weight / frequency matrix-based approaches, MEME and CISFINDER, also for three TFs (USF2, RAD21 and SMC3). However, their performance is worse than SK and TSK for the majority of TFs. MEME and CISFINDER also exhibit higher variance."}, {"heading": "4.3 Hyperparameter Selection: k = 10 and m = 1 gives the best performance for TFBS prediction", "text": "(k, m) mismatch string kernel requires the matching of two hyperparameters: k and m. Here is k the length of k-mer or substrings compared in kernel calculations, and m is the number of allowed mismatches. We looked at k, 8, 10, 12} and m, 1, 2, 3. Figure 2 shows the effect of different k and m parameters based on the average AUC values (for 14 TF tasks) from the validation of all three data ratios considered. The combination (k = 10, m = 1) achieves the best average AUC results for validation sets. We observe that TSK always exceeds basic SK in validation for any given ratio. We also find that the value k > 10 decreases the performance of SK and TSK."}, {"heading": "4.4 Same context versus cross-context: Prediction of TFBS within the target context is easier than cross-context", "text": "To justify the importance of domain matching, we also evaluate basic methods from the point of view that train and test are within the same target domain, i.e. both training and testing are performed on human TFBS datasets 4. In Figure 3, the predictive power of SK, measured by the average AUC test value for 14 TF tasks, decreases in cross-context setting (compared to predicting from the same context). However, it is worth noting that basic SK MEME and CISF exceed TFBS when working within the same domain."}, {"heading": "4.5 TSK is generalizable to other sequence-based prediction tasks", "text": "In addition to TFBS prediction, we successfully implement TSK for predicting PB to the MHC-I complex by transferring knowledge between species. Similar to TFBS prediction, we use the mouse (source) dataset to train our model and then perform predictions (validation and verification) on the human (target) dataset, i.e. a useful translational setting. Our results suggest that TSK can be generalized for any cross-context task that involves sequence-based classification. \u2022 Hyperparameter selection: Hyperparameter tuning provided the most powerful hyperparameters that were different across 5 tasks."}, {"heading": "5 DISCUSSION", "text": "Most previous calculation tools for predicting TFBS use the same distribution across target and source contexts. However, we have shown that it is beneficial to consider the distribution techniques, and the proposed TSK method improves the performance of sequence-driven TFBS predictions by taking into account differences between the underlying sample distributions and applying knowledge transfer from source to target context. We have also investigated the issue of unbalanced (positive to negative) data in the target domain to ensure a realistic and robust TFBS prediction. Our experimental results suggest that TSK overall improves the performance of string TFBS predictions. \u2022 TSK and SK exceed the state of the art, the weight / frequency of matrix-based TFBS tools, especially for less conserved TFS tools, and can easily be used as supplementary tools to the latter models of TSK."}, {"heading": "ACKNOWLEDGMENTS", "text": "The authors thank Dr. Mazhar Adli (Department of Biochemistry and Molecular Genetics, University of Virginia) for helpful discussions throughout the course of the project. FUNDING This work was supported by the National Science Foundation as part of the NSF CAREER Award No. 1453580. Any opinions, findings and conclusions or recommendations expressed in this material are those of the author (s) and do not necessarily reflect those of the National Science Foundation."}], "references": [{"title": "An integrated encyclopedia of dna elements in the human genome", "author": ["E.P. Consortium"], "venue": "Nature, vol. 489, no. 7414, pp. 57\u201374, 2012.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "A census of human transcription factors: function, expression and evolution", "author": ["J.M. Vaquerizas", "S.K. Kummerfeld", "S.A. Teichmann", "N.M. Luscombe"], "venue": "Nature Reviews Genetics, vol. 10, no. 4, pp. 252\u2013263, 2009.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2009}, {"title": "Evolution of transcription factor binding sites in mammalian gene regulatory regions: conservation and turnover", "author": ["E.T. Dermitzakis", "A.G. Clark"], "venue": "Molecular biology and evolution, vol. 19, no. 7, pp. 1114\u20131121, 2002.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2002}, {"title": "Chip\u2013seq: advantages and challenges of a maturing technology", "author": ["P.J. Park"], "venue": "Nature Reviews Genetics, vol. 10, no. 10, pp. 669\u2013680, 2009.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2009}, {"title": "Fast string kernels using inexact matching for protein sequences", "author": ["C. Leslie", "R. Kuang"], "venue": "The Journal of Machine Learning Research, vol. 5, pp. 1435\u20131455, 2004.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2004}, {"title": "Sequence and chromatin determinants of cell-type\u2013specific transcription factor binding", "author": ["A. Arvey", "P. Agius", "W.S. Noble", "C. Leslie"], "venue": "Genome research, vol. 22, no. 9, pp. 1723\u20131734, 2012.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2012}, {"title": "The evolution of gene regulation by transcription factors and micrornas", "author": ["K. Chen", "N. Rajewsky"], "venue": "Nature Reviews Genetics, vol. 8, no. 2, pp. 93\u2013103, 2007.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2007}, {"title": "Analysis of kernel mean matching under covariate shift", "author": ["Y.-l. Yu", "C. Szepesv\u00e1ri"], "venue": "Proceedings of the 29th International Conference on Machine Learning (ICML-12), 2012, pp. 607\u2013614.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Covariate shift by kernel mean matching", "author": ["A. Gretton", "A. Smola", "J. Huang", "M. Schmittfull", "K. Borgwardt", "B. Sch\u00f6lkopf"], "venue": "Dataset shift in machine learning, vol. 3, no. 4, p. 5, 2009.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2009}, {"title": "An empirical analysis of domain adaptation algorithms for genomic sequence analysis", "author": ["G. Schweikert", "G. R\u00e4tsch", "C. Widmer", "B. Sch\u00f6lkopf"], "venue": "Advances in Neural Information Processing Systems, 2009, pp. 1433\u20131440.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2009}, {"title": "Scalable algorithms for string kernels with inexact matching.", "author": ["P.P. Kuksa", "P.-H. Huang", "V. Pavlovic"], "venue": "in NIPS,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2008}, {"title": "A survey on transfer learning", "author": ["S.J. Pan", "Q. Yang"], "venue": "Knowledge and Data Engineering, IEEE Transactions on, vol. 22, no. 10, pp. 1345\u20131359, 2010.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2010}, {"title": "Modeling the specificity of protein-dna interactions", "author": ["G.D. Stormo"], "venue": "Quantitative Biology, vol. 1, no. 2, pp. 115\u2013130, 2013.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}, {"title": "Jaspar 2014: an extensively expanded and updated open-access database of transcription factor binding profiles", "author": ["A. Mathelier", "X. Zhao", "A.W. Zhang", "F. Parcy", "R. Worsley-Hunt", "D.J. Arenillas", "S. Buchman", "C.-y. Chen", "A. Chou", "H. Ienasescu"], "venue": "Nucleic acids research, p. gkt997, 2013.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2013}, {"title": "Fast kernels for string and tree matching", "author": ["S. Vishwanathan", "A.J. Smola"], "venue": "Kernel methods in computational biology, pp. 113\u2013130, 2004.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2004}, {"title": "Profile-based string kernels for remote homology detection and motif extraction", "author": ["R. Kuang", "E. Ie", "K. Wang", "K. Wang", "M. Siddiqi", "Y. Freund", "C. Leslie"], "venue": "Journal of bioinformatics and computational biology, vol. 3, no. 03, pp. 527\u2013550, 2005.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2005}, {"title": "Cluster kernels for semisupervised learning", "author": ["O. Chapelle", "J. Weston", "B. Sch\u00f6lkopf"], "venue": "Advances in neural information processing systems, 2002, pp. 585\u2013592.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2002}, {"title": "A unified architecture for natural language processing: Deep neural networks with multitask learning", "author": ["R. Collobert", "J. Weston"], "venue": "Proceedings of the 25th international conference on Machine learning. ACM, 2008, pp. 160\u2013167.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2008}, {"title": "A unified multitask architecture for predicting local protein properties", "author": ["Y. Qi", "M. Oja", "J. Weston", "W.S. Noble"], "venue": "PloS one, vol. 7, no. 3, p. e32235, 2012.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2012}, {"title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data", "author": ["J. Lafferty", "A. McCallum", "F.C. Pereira"], "venue": "2001.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2001}, {"title": "A survey of transfer and multitask learning in bioinformatics", "author": ["Q. Xu", "Q. Yang"], "venue": "Journal of Computing Science and Engineering, vol. 5, no. 3, pp. 257\u2013268, 2011.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2011}, {"title": "Information-theoretical learning of discriminative clusters for unsupervised domain adaptation", "author": ["Y. Shi", "F. Sha"], "venue": "arXiv preprint arXiv:1206.6438, 2012.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2012}, {"title": "Domain adaptation for object recognition: An unsupervised approach", "author": ["R. Gopalan", "R. Li", "R. Chellappa"], "venue": "Computer Vision (ICCV), 2011 IEEE International Conference on. IEEE, 2011, pp. 999\u20131006.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2011}, {"title": "Importance-weighted least-squares probabilistic classifier for covariate shift adaptation with application to human activity recognition", "author": ["H. Hachiya", "M. Sugiyama", "N. Ueda"], "venue": "Neurocomputing, vol. 80, pp. 93\u2013101, 2012.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2012}, {"title": "Domain invariant transfer kernel learning", "author": ["M. Long", "J. Wang", "J. Sun", "P.S. Yu"], "venue": "2015.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2015}, {"title": "Application of covariate shift adaptation techniques in brain\u2013computer interfaces", "author": ["Y. Li", "H. Kambara", "Y. Koike", "M. Sugiyama"], "venue": "Biomedical Engineering, IEEE Transactions on, vol. 57, no. 6, pp. 1318\u20131324, 2010.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2010}, {"title": "Improving predictive inference under covariate shift by weighting the log-likelihood function", "author": ["H. Shimodaira"], "venue": "Journal of statistical planning and inference, vol. 90, no. 2, pp. 227\u2013244, 2000.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2000}, {"title": "Correcting sample selection bias in maximum entropy density estimation", "author": ["M. Dud\u00edk", "S.J. Phillips", "R.E. Schapire"], "venue": "Advances in neural information processing systems, 2005, pp. 323\u2013330.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2005}, {"title": "Correcting sample selection bias by unlabeled data", "author": ["J. Huang", "A.J. Smola", "A. Gretton", "K.M. Borgwardt", "B. Sch\u00f6lkopf"], "venue": "Advances in neural information processing systems, vol. 19, p. 601, 2007.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2007}, {"title": "Covariate shift in hilbert space: A solution via sorrogate kernels", "author": ["K. Zhang", "V. Zheng", "Q. Wang", "J. Kwok", "Q. Yang", "I. Marsic"], "venue": "Proceedings of the 30th International Conference on Machine Learning, 2013, pp. 388\u2013395.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2013}, {"title": "Covariate shift adaptation by importance weighted cross validation", "author": ["M. Sugiyama", "M. Krauledat", "K.-R. M\u00fcller"], "venue": "The Journal of Machine Learning Research, vol. 8, pp. 985\u20131005, 2007.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2007}, {"title": "Direct density ratio estimation for large-scale covariate shift adaptation.", "author": ["Y. Tsuboi", "H. Kashima", "S. Hido", "S. Bickel", "M. Sugiyama"], "venue": "Information and Media Technologies,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2009}, {"title": "A least-squares approach to direct importance estimation", "author": ["T. Kanamori", "S. Hido", "M. Sugiyama"], "venue": "The Journal of Machine Learning Research, vol. 10, pp. 1391\u20131445, 2009.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2009}, {"title": "Relative density-ratio estimation for robust distribution comparison", "author": ["M. Yamada", "T. Suzuki", "T. Kanamori", "H. Hachiya", "M. Sugiyama"], "venue": "Neural computation, vol. 25, no. 5, pp. 1324\u20131370, 2013.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2013}, {"title": "Learning bounds for importance weighting", "author": ["C. Cortes", "Y. Mansour", "M. Mohri"], "venue": "Advances in neural information processing systems, 2010, pp. 442\u2013450.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2010}, {"title": "No bias left behind: Covariate shift adaptation for discriminative 3d pose estimation", "author": ["M. Yamada", "L. Sigal", "M. Raptis"], "venue": "Computer Vision\u2013ECCV 2012. Springer, 2012, pp. 674\u2013687.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2012}, {"title": "Distance metric learning under covariate shift", "author": ["B. Cao", "X. Ni", "J.-T. Sun", "G. Wang", "Q. Yang"], "venue": "IJCAI Proceedings-International Joint Conference on Artificial Intelligence, vol. 22, no. 1, 2011, p. 1204.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2011}, {"title": "Discriminative learning under covariate shift", "author": ["S. Bickel", "M. Br\u00fcckner", "T. Scheffer"], "venue": "The Journal of Machine Learning Research, vol. 10, pp. 2137\u20132155, 2009.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2009}, {"title": "Doubly robust covariate shift correction", "author": ["S.J. Reddi", "B. P\u00f3czos", "A. Smola"], "venue": "2014.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2014}, {"title": "Frustratingly easy domain adaptation", "author": ["III H. Daum\u00e9"], "venue": "arXiv preprint arXiv:0907.1815, 2009.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 1815}, {"title": "Domain adaptation via transfer component analysis", "author": ["S.J. Pan", "I.W. Tsang", "J.T. Kwok", "Q. Yang"], "venue": "Neural Networks, IEEE Transactions on, vol. 22, no. 2, pp. 199\u2013210, 2011.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2011}, {"title": "Bregman divergence-based regularization for transfer subspace learning", "author": ["S. Si", "D. Tao", "B. Geng"], "venue": "Knowledge and Data Engineering, IEEE Transactions on, vol. 22, no. 7, pp. 929\u2013942, 2010.", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2010}, {"title": "Low-rank transfer subspace learning", "author": ["M. Shao", "C. Castillo", "Z. Gu", "Y. Fu"], "venue": "Data Mining (ICDM), 2012 IEEE 12th International Conference on. IEEE, 2012, pp. 1104\u20131109.", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2012}, {"title": "Domain generalization via invariant feature representation", "author": ["K. Muandet", "D. Balduzzi", "B. Sch\u00f6lkopf"], "venue": "arXiv preprint arXiv:1301.2115, 2013.  12", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2013}, {"title": "Subspace alignment for domain adaptation", "author": ["B. Fernando", "A. Habrard", "M. Sebban", "T. Tuytelaars"], "venue": "arXiv preprint arXiv:1409.5241, 2014.", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2014}, {"title": "Machine learning competition in immunology\u2013prediction of hla class i binding peptides", "author": ["G.L. Zhang", "H.R. Ansari", "P. Bradley", "G.C. Cawley", "T. Hertz", "X. Hu", "N. Jojic", "Y. Kim", "O. Kohlbacher", "O. Lund"], "venue": "Journal of immunological methods, vol. 374, no. 1, pp. 1\u20134, 2011.", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2011}, {"title": "Mhc-np: Predicting peptides naturally processed by the mhc", "author": ["S. Gigu\u00e8re", "A. Drouin", "A. Lacoste", "M. Marchand", "J. Corbeil", "F. Laviolette"], "venue": "Journal of immunological methods, vol. 400, pp. 30\u201336, 2013.", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2013}, {"title": "Oligo kernels for datamining on biological sequences: a case study on prokaryotic translation initiation sites", "author": ["P. Meinicke", "M. Tech", "B. Morgenstern", "R. Merkl"], "venue": "BMC bioinformatics, vol. 5, no. 1, p. 169, 2004.", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2004}, {"title": "Toward more accurate pan-specific mhc-peptide binding prediction: a review of current methods and tools", "author": ["L. Zhang", "K. Udaka", "H. Mamitsuka", "S. Zhu"], "venue": "Briefings in bioinformatics, vol. 13, no. 3, pp. 350\u2013364, 2012.", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2012}, {"title": "Epigenetic priors for identifying active transcription factor binding sites", "author": ["G. Cuellar-Partida", "F.A. Buske", "R.C. McLeay", "T. Whitington", "W.S. Noble", "T.L. Bailey"], "venue": "Bioinformatics, vol. 28, no. 1, pp. 56\u201362, 2012.", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2012}, {"title": "Making large scale svm learning practical", "author": ["T. Joachims"], "venue": "Universit\u00e4t Dortmund, Tech. Rep., 1999.", "citeRegEx": "53", "shortCiteRegEx": null, "year": 1999}, {"title": "Advances in kernel methods: support vector learning", "author": ["B. Sch\u00f6lkopf", "C.J. Burges"], "venue": "MIT press,", "citeRegEx": "54", "shortCiteRegEx": "54", "year": 1999}, {"title": "Kernel methods in computational biology", "author": ["B. Sch\u00f6lkopf", "K. Tsuda", "J.-P. Vert"], "venue": "MIT press,", "citeRegEx": "55", "shortCiteRegEx": "55", "year": 2004}, {"title": "Meme-chip: motif analysis of large dna datasets", "author": ["P. Machanick", "T.L. Bailey"], "venue": "Bioinformatics, vol. 27, no. 12, pp. 1696\u20131697, 2011.", "citeRegEx": "56", "shortCiteRegEx": null, "year": 2011}, {"title": "Assigning roles to dna regulatory motifs using comparative genomics", "author": ["F.A. Buske", "M. Bod\u00e9n", "D.C. Bauer", "T.L. Bailey"], "venue": "Bioinformatics, vol. 26, no. 7, pp. 860\u2013866, 2010.", "citeRegEx": "57", "shortCiteRegEx": null, "year": 2010}, {"title": "Meme suite: tools for motif discovery and searching", "author": ["T.L. Bailey", "M. Boden", "F.A. Buske", "M. Frith", "C.E. Grant", "L. Clementi", "J. Ren", "W.W. Li", "W.S. Noble"], "venue": "Nucleic acids research, vol. 37, pp. W202\u2013W208, 2009.", "citeRegEx": "58", "shortCiteRegEx": null, "year": 2009}, {"title": "Exhaustive search for over-represented dna sequence motifs with cisfinder", "author": ["A.A. Sharov", "M.S. Ko"], "venue": "DNA research, vol. 16, no. 5, pp. 261\u2013273, 2009.", "citeRegEx": "59", "shortCiteRegEx": null, "year": 2009}, {"title": "Galaxy: a comprehensive approach for supporting accessible, reproducible, and transparent computational research in the life sciences", "author": ["J. Goecks", "A. Nekrutenko", "J. Taylor", "T.G. Team"], "venue": "Genome Biol, vol. 11, no. 8, p. R86, 2010.", "citeRegEx": "60", "shortCiteRegEx": null, "year": 2010}, {"title": "Galaxy: A web-based genome analysis tool for experimentalists", "author": ["D. Blankenberg", "G.V. Kuster", "N. Coraor", "G. Ananda", "R. Lazarus", "M. Mangan", "A. Nekrutenko", "J. Taylor"], "venue": "Current protocols in molecular biology, pp. 19\u2013 10, 2010.", "citeRegEx": "61", "shortCiteRegEx": null, "year": 2010}], "referenceMentions": [{"referenceID": 0, "context": "As an important application of sequence based mining, the task of predicting Transcription Factor Binding Sites (TFBSs) on genomes has attracted much attention over the years [1].", "startOffset": 175, "endOffset": 178}, {"referenceID": 1, "context": "While many TFs are highly conserved among different species [2], conservation of their binding sequence is low [3].", "startOffset": 60, "endOffset": 63}, {"referenceID": 2, "context": "While many TFs are highly conserved among different species [2], conservation of their binding sequence is low [3].", "startOffset": 111, "endOffset": 114}, {"referenceID": 3, "context": "Owing to the development of chromatin immunoprecipitation and massively parallel DNA sequencing (ChIP-seq) technologies [4], maps of genome-wide binding sites are currently available for multiple TFs in a few cell types across human and mouse genomes via the ENCODE [1] database.", "startOffset": 120, "endOffset": 123}, {"referenceID": 0, "context": "Owing to the development of chromatin immunoprecipitation and massively parallel DNA sequencing (ChIP-seq) technologies [4], maps of genome-wide binding sites are currently available for multiple TFs in a few cell types across human and mouse genomes via the ENCODE [1] database.", "startOffset": 266, "endOffset": 269}, {"referenceID": 4, "context": "String kernel techniques under the support vector machine (SVM) classification framework have been successfully used for detecting patterns of DNA or protein sequences before [5].", "startOffset": 175, "endOffset": 178}, {"referenceID": 5, "context": "Recently, [6] extended this discriminative SK+SVM classification", "startOffset": 10, "endOffset": 13}, {"referenceID": 5, "context": "Their results [6] have suggested that traditional motif-driven approaches (details in Section 2.", "startOffset": 14, "endOffset": 17}, {"referenceID": 5, "context": "Despite the exciting aforementioned framework [6], one shortcoming remains significant: this method assumes that the source and target samples are drawn from the same probability distribution.", "startOffset": 46, "endOffset": 49}, {"referenceID": 6, "context": "This also connects to observations in the literature that the TFBS sequences have low conservation across species even though many TF proteins are conserved across large evolutionary distances [7].", "startOffset": 193, "endOffset": 196}, {"referenceID": 7, "context": "When implementing cross context prediction, it is desirable to design algorithms that remain effective under such distribution shifts [8].", "startOffset": 134, "endOffset": 137}, {"referenceID": 8, "context": "While the problem may be unsolvable if the source and target distributions share nothing in common, recent machine learning studies [9] have provided effective adaptation for closely related distributions.", "startOffset": 132, "endOffset": 135}, {"referenceID": 5, "context": "Biologically, this also makes sense since closely related cell contexts should have similar gene regulation processes and similar TFBS sequence patterns [6].", "startOffset": 153, "endOffset": 156}, {"referenceID": 8, "context": "its distribution more closely matches that of the target data [9].", "startOffset": 62, "endOffset": 65}, {"referenceID": 9, "context": "This connects to a more general machine-learning topic called domain adaptation [10] (discussed in Section 2.", "startOffset": 80, "endOffset": 84}, {"referenceID": 4, "context": "String kernels [5] [12], implicitly compute an inner product in the mapped feature space \u03c6(x) as:", "startOffset": 15, "endOffset": 18}, {"referenceID": 10, "context": "String kernels [5] [12], implicitly compute an inner product in the mapped feature space \u03c6(x) as:", "startOffset": 19, "endOffset": 23}, {"referenceID": 4, "context": "The string kernel using this representation is called spectrum kernel [5], where the spectrum representation counts the occurrences of each nucleotide k-mer in a DNA sequence segment.", "startOffset": 70, "endOffset": 73}, {"referenceID": 10, "context": "In string kernels, this is typically achieved by using different families of mismatches [12].", "startOffset": 88, "endOffset": 92}, {"referenceID": 10, "context": "We use the concept of (k,m)-mismatch string kernels [12] (illustrated in Figure 1(c)), which considers k-mer counts with m inexact matching of k-mers (e.", "startOffset": 52, "endOffset": 56}, {"referenceID": 4, "context": "Researchers have proposed various strategies [5], [12] to address these computational difficulties.", "startOffset": 45, "endOffset": 48}, {"referenceID": 10, "context": "Researchers have proposed various strategies [5], [12] to address these computational difficulties.", "startOffset": 50, "endOffset": 54}, {"referenceID": 10, "context": "We adopt a statistical strategy from [12] that provides linear-time string kernel computations and scales well with dictionary size and input length.", "startOffset": 37, "endOffset": 41}, {"referenceID": 9, "context": "To consider the variation between source and target samples in our application, domain adaptation [10], [13] serves as a natural candidate to tackle this computational challenge.", "startOffset": 98, "endOffset": 102}, {"referenceID": 11, "context": "To consider the variation between source and target samples in our application, domain adaptation [10], [13] serves as a natural candidate to tackle this computational challenge.", "startOffset": 104, "endOffset": 108}, {"referenceID": 8, "context": "TSK revises the (k,m)-mismatch string kernel framework using a \u201cKernel Mean Matching\u201d (KMM) strategy [9] in order to perform knowledge transfer.", "startOffset": 101, "endOffset": 104}, {"referenceID": 8, "context": "Specifically, TSK adapts string kernel under the \u201ccovariate shift\u201d assumption [9].", "startOffset": 78, "endOffset": 81}, {"referenceID": 7, "context": "The key to correcting this type of sampling bias is to estimate the \u201cimportance weight\u201d for each source sample [8]:", "startOffset": 111, "endOffset": 114}, {"referenceID": 8, "context": "Equation 9 involves a quadratic program which can be efficiently solved using the interior point methods or any other subsequent procedures such as projected gradient optimization method [9].", "startOffset": 187, "endOffset": 190}, {"referenceID": 12, "context": "Relying on a set of known transcription factor binding sites (TFBSs) for a given TF, the binding preference is generally represented in the form of a position weight matrix (PWM) [14], [15] (also called positionspecific scoring matrix) derived from a position frequency matrix (PFM).", "startOffset": 179, "endOffset": 183}, {"referenceID": 13, "context": "Relying on a set of known transcription factor binding sites (TFBSs) for a given TF, the binding preference is generally represented in the form of a position weight matrix (PWM) [14], [15] (also called positionspecific scoring matrix) derived from a position frequency matrix (PFM).", "startOffset": 185, "endOffset": 189}, {"referenceID": 5, "context": "[6] have suggested that traditional motif-driven approaches are not always sufficient to accurately account for celltype specific binding profiles.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "most accurate results, such as for remote protein fold and homology detections [5], [12].", "startOffset": 79, "endOffset": 82}, {"referenceID": 10, "context": "most accurate results, such as for remote protein fold and homology detections [5], [12].", "startOffset": 84, "endOffset": 88}, {"referenceID": 4, "context": "Aside from spectrum kernel [5] and (k,m)mismatch string kernel [12] introduced in the previous section, a few other notable string kernels include (but are not limited to): (1) The gapped kernel calculates dot-product of (non-contiguous) k-mer counts with gaps allowed between elements.", "startOffset": 27, "endOffset": 30}, {"referenceID": 10, "context": "Aside from spectrum kernel [5] and (k,m)mismatch string kernel [12] introduced in the previous section, a few other notable string kernels include (but are not limited to): (1) The gapped kernel calculates dot-product of (non-contiguous) k-mer counts with gaps allowed between elements.", "startOffset": 63, "endOffset": 67}, {"referenceID": 14, "context": "(2) More generally, the substring kernel [16] measures similarity between sequences based on common co-occurrence of exact sub-patterns (e.", "startOffset": 41, "endOffset": 45}, {"referenceID": 15, "context": "(3) The profile kernel [17] uses the notion of similarity based on a probabilistic model (e.", "startOffset": 23, "endOffset": 27}, {"referenceID": 16, "context": "(4) Under the semi-supervised setting, the so-called \u201csequence neighborhood\u201d kernel or \u201ccluster\u201d kernel [18] proposes a semi-supervised extension of string kernel, which replaces every sequence with a set of \u201csimilar\u201d (neighboring) sequences and a new representation is obtained by averaging representations of these neighboring sequences found in the unlabeled data using a certain sequence similarity measure.", "startOffset": 104, "endOffset": 108}, {"referenceID": 17, "context": "Many successful works in the field of natural language processing [19] belong to this category in which each position of input sequences can be annotated with tags indicating parts of speech, named entities, semantic roles, etc.", "startOffset": 66, "endOffset": 70}, {"referenceID": 18, "context": "Popular bioinformatics tasks predicting proteins\u2019 local functional properties [20] have been modeled as a labeling or tagging of amino acids on proteins.", "startOffset": 78, "endOffset": 82}, {"referenceID": 19, "context": "Multiple classic machine learning methods have been benchmark tools for sequence tagging, like conditional random field [21].", "startOffset": 120, "endOffset": 124}, {"referenceID": 7, "context": "the case of TSK) [8].", "startOffset": 17, "endOffset": 20}, {"referenceID": 7, "context": "This problem has been investigated in both statistics and machine learning under various assumptions [8].", "startOffset": 101, "endOffset": 104}, {"referenceID": 7, "context": "A number of previous methods have been proposed to estimate the \u201cimportance weight\u201d \u03b2 from finite samples, including kernel mean matching (KMM), logistic regression, KL importance estimation and many others [8].", "startOffset": 207, "endOffset": 210}, {"referenceID": 11, "context": "More generally, TSK belongs to topics of domain adaptation and transfer learning [13] [10], where one aims to use data or models of a well-analyzed source domain to obtain or refine models for a less analyzed target domain.", "startOffset": 81, "endOffset": 85}, {"referenceID": 9, "context": "More generally, TSK belongs to topics of domain adaptation and transfer learning [13] [10], where one aims to use data or models of a well-analyzed source domain to obtain or refine models for a less analyzed target domain.", "startOffset": 86, "endOffset": 90}, {"referenceID": 11, "context": "For such scenarios, knowledge transfer will potentially improve the performance of learning by avoiding or reducing the expensive data-labeling efforts [13].", "startOffset": 152, "endOffset": 156}, {"referenceID": 20, "context": "Transfer learning can help in reusing knowledge from annotated datasets to new domains [22], reducing the knowledge gap of labeled data due to heterogenous variations.", "startOffset": 87, "endOffset": 91}, {"referenceID": 9, "context": "For example, one previous study [10] explored \u201cdomain adaptation\u201d strategies for a task of sequence-based prediction for acceptor splice sites.", "startOffset": 32, "endOffset": 36}, {"referenceID": 21, "context": "By exploiting labeled training samples from a different but related source domain, a variety of previous studies have demonstrated its effectiveness on multiple applications including sentiment analysis [23], object classification [24], activity recognition [25], text categorization [26] and Brain-computer interface (BCI) tasks [27].", "startOffset": 203, "endOffset": 207}, {"referenceID": 22, "context": "By exploiting labeled training samples from a different but related source domain, a variety of previous studies have demonstrated its effectiveness on multiple applications including sentiment analysis [23], object classification [24], activity recognition [25], text categorization [26] and Brain-computer interface (BCI) tasks [27].", "startOffset": 231, "endOffset": 235}, {"referenceID": 23, "context": "By exploiting labeled training samples from a different but related source domain, a variety of previous studies have demonstrated its effectiveness on multiple applications including sentiment analysis [23], object classification [24], activity recognition [25], text categorization [26] and Brain-computer interface (BCI) tasks [27].", "startOffset": 258, "endOffset": 262}, {"referenceID": 24, "context": "By exploiting labeled training samples from a different but related source domain, a variety of previous studies have demonstrated its effectiveness on multiple applications including sentiment analysis [23], object classification [24], activity recognition [25], text categorization [26] and Brain-computer interface (BCI) tasks [27].", "startOffset": 284, "endOffset": 288}, {"referenceID": 25, "context": "By exploiting labeled training samples from a different but related source domain, a variety of previous studies have demonstrated its effectiveness on multiple applications including sentiment analysis [23], object classification [24], activity recognition [25], text categorization [26] and Brain-computer interface (BCI) tasks [27].", "startOffset": 330, "endOffset": 334}, {"referenceID": 26, "context": "Covariate shift assumes that the marginal distributions of the source and target instances differ while the conditional distribution of the target output remains the same across domains [28].", "startOffset": 186, "endOffset": 190}, {"referenceID": 27, "context": "For instance, the authors of [29] propose density estimators that incorporate sample selection bias to adapt two distributions.", "startOffset": 29, "endOffset": 33}, {"referenceID": 8, "context": "The Kernel Mean Matching (KMM) method [9], [30] then learns the weights by matching the distributions in", "startOffset": 38, "endOffset": 41}, {"referenceID": 28, "context": "The Kernel Mean Matching (KMM) method [9], [30] then learns the weights by matching the distributions in", "startOffset": 43, "endOffset": 47}, {"referenceID": 29, "context": "a RKHS, with a recent extension [31] developing surrogate-kernel based kernel matching.", "startOffset": 32, "endOffset": 36}, {"referenceID": 30, "context": "Later, [32], [33] propose to minimize the Kullback-Leibler divergence between the target distribution and the weighted source distribution.", "startOffset": 7, "endOffset": 11}, {"referenceID": 31, "context": "Later, [32], [33] propose to minimize the Kullback-Leibler divergence between the target distribution and the weighted source distribution.", "startOffset": 13, "endOffset": 17}, {"referenceID": 23, "context": "Several recent papers [25], [34], [35] aim to estimate the optimal weights by solving least-square based formulations.", "startOffset": 22, "endOffset": 26}, {"referenceID": 32, "context": "Several recent papers [25], [34], [35] aim to estimate the optimal weights by solving least-square based formulations.", "startOffset": 28, "endOffset": 32}, {"referenceID": 33, "context": "Several recent papers [25], [34], [35] aim to estimate the optimal weights by solving least-square based formulations.", "startOffset": 34, "endOffset": 38}, {"referenceID": 34, "context": "Furthermore, theoretical analysis of this type of domain adaptation has been studied by [36].", "startOffset": 88, "endOffset": 92}, {"referenceID": 31, "context": "Several existing machine learning methods have been explored in this framework, such as importance-weighted logistic regression [33],", "startOffset": 128, "endOffset": 132}, {"referenceID": 30, "context": "importance-weighted kernel regression [32], importance-weighted Gaussian processes [37], and the so-called consistent distance metric learning method [38].", "startOffset": 38, "endOffset": 42}, {"referenceID": 35, "context": "importance-weighted kernel regression [32], importance-weighted Gaussian processes [37], and the so-called consistent distance metric learning method [38].", "startOffset": 83, "endOffset": 87}, {"referenceID": 36, "context": "importance-weighted kernel regression [32], importance-weighted Gaussian processes [37], and the so-called consistent distance metric learning method [38].", "startOffset": 150, "endOffset": 154}, {"referenceID": 37, "context": "For instance, the authors of [39] propose a discriminative learning based adaptation that trains an integrated model to obtain both importance weights and the classifier at the same time.", "startOffset": 29, "endOffset": 33}, {"referenceID": 38, "context": "As another example, a so-called doubly robust covariate shift correction method [40] first trains an non-", "startOffset": 80, "endOffset": 84}, {"referenceID": 21, "context": "For example, [23], [41] propose novel feature representations for the domain adaptation purpose.", "startOffset": 13, "endOffset": 17}, {"referenceID": 39, "context": "For example, [23], [41] propose novel feature representations for the domain adaptation purpose.", "startOffset": 19, "endOffset": 23}, {"referenceID": 40, "context": "Transfer component analysis [42] was introduced to find low dimensional representations in RHKS where the target and source domains are similar.", "startOffset": 28, "endOffset": 32}, {"referenceID": 41, "context": "The authors of [43] try to learn a linear subspace that is suitable for knowledge transfer by minimizing Bregman divergence between target and source distributions in this subspace.", "startOffset": 15, "endOffset": 19}, {"referenceID": 42, "context": "A related study [44] transforms target samples such that they are a linear combination of basis from the source domain.", "startOffset": 16, "endOffset": 20}, {"referenceID": 43, "context": "More recently, [45] learns a domain-invariant data transformation to minimize differences between source and target distributions while preserving functional relations between data and labels.", "startOffset": 15, "endOffset": 19}, {"referenceID": 44, "context": "Furthermore, the authors of [46] propose to identify subspaces that align to the eigenspaces of the target and source domains.", "startOffset": 28, "endOffset": 32}, {"referenceID": 45, "context": "The first machine learning competition in Immunology (2011) [47] compared various computational algorithms for classifying peptide binding versus non-binding sites for multiple MHC molecules.", "startOffset": 60, "endOffset": 64}, {"referenceID": 46, "context": "For peptide-protein interaction prediction, relative positions of amino acids and their physiochemical properties play a very important role [49].", "startOffset": 141, "endOffset": 145}, {"referenceID": 47, "context": "The oligo kernel proposed by [50], takes the relative positions into consideration by assigning a weight to each common k-mer based on their relative position in the two peptide sequences.", "startOffset": 29, "endOffset": 33}, {"referenceID": 46, "context": "For the 2012 Machine Learning Competition in Immunology for peptide binding prediction, [49] showed that their Generic String (GS) kernel gave state-of-the-art performance when implemented on the datasets provided by the competition from [51].", "startOffset": 88, "endOffset": 92}, {"referenceID": 48, "context": "For the 2012 Machine Learning Competition in Immunology for peptide binding prediction, [49] showed that their Generic String (GS) kernel gave state-of-the-art performance when implemented on the datasets provided by the competition from [51].", "startOffset": 238, "endOffset": 242}, {"referenceID": 0, "context": "The ENCODE [1] database, however, contains only 14 ChIPseq TF experiments that are available for both species.", "startOffset": 11, "endOffset": 14}, {"referenceID": 49, "context": "To select training and testing sequences from the ENCODE database, we use the \u201cpeak-centric standard\u201d as described in [52].", "startOffset": 118, "endOffset": 122}, {"referenceID": 0, "context": "Coordinates of TFBS peak positions are obtained from the ChIP-seq data available in the ENCODE repository [1].", "startOffset": 106, "endOffset": 109}, {"referenceID": 50, "context": "Our investigation of TSK focuses on the SVM [53] [54] classifier framework.", "startOffset": 44, "endOffset": 48}, {"referenceID": 51, "context": "Our investigation of TSK focuses on the SVM [53] [54] classifier framework.", "startOffset": 49, "endOffset": 53}, {"referenceID": 52, "context": "SVMs are known to provide state-of-the-art performance for many applications [11], including a large number of successes in computational biology [55].", "startOffset": 146, "endOffset": 150}, {"referenceID": 10, "context": "1) SK: represents the (k,m)-mismatch kernel implementation adapted from [12].", "startOffset": 72, "endOffset": 76}, {"referenceID": 53, "context": "The PWMs are obtained from source sequences using motif discovery algorithm MEME-ChIP [56] and then these motifs are used for scoring individual target sequences using AMA tool [57].", "startOffset": 86, "endOffset": 90}, {"referenceID": 54, "context": "The PWMs are obtained from source sequences using motif discovery algorithm MEME-ChIP [56] and then these motifs are used for scoring individual target sequences using AMA tool [57].", "startOffset": 177, "endOffset": 181}, {"referenceID": 55, "context": "These tools are part of the MEME-Suite [58].", "startOffset": 39, "endOffset": 43}, {"referenceID": 56, "context": "3) CISF: CISFINDER [59] is another state-of-the-art toolbox for TFBS detection that uses an exhaustive search for DNA motifs and outputs a Position Frequency Matrix (PFM).", "startOffset": 19, "endOffset": 23}, {"referenceID": 10, "context": "\u2022 Baselines: Since no runnable tools exist for both oligo kernels and GS kernels, we use (k,m)-mismatch kernels from [12] as a baseline.", "startOffset": 117, "endOffset": 121}, {"referenceID": 57, "context": "For these sequences, a phyloP score for each nucleotide (total of 200,000) is calculated using the Galaxy tool [60], [61], [62].", "startOffset": 111, "endOffset": 115}, {"referenceID": 58, "context": "For these sequences, a phyloP score for each nucleotide (total of 200,000) is calculated using the Galaxy tool [60], [61], [62].", "startOffset": 117, "endOffset": 121}, {"referenceID": 46, "context": "Moreover, our mismatch SK baseline outperforms Generic String Kernel [49] on 4 out of 5 tasks, making it a good choice for implementation of TSK on this type of task.", "startOffset": 69, "endOffset": 73}, {"referenceID": 46, "context": "In this setting, our basic SK model (blue bars) gives good performance and even outperforms GS kernel [49], the best team for 2012 competition citemlcompimmune.", "startOffset": 102, "endOffset": 106}], "year": 2016, "abstractText": "Through sequence-based classification, this paper tries to accurately predict the DNA binding sites of transcription factors (TFs) in an unannotated cellular context. Related methods in the literature fail to perform such predictions accurately, since they do not consider sample distribution shift of sequence segments from an annotated (source) context to an unannotated (target) context. We, therefore, propose a method called \u201cTransfer String Kernel\u201d (TSK) that achieves improved prediction of transcription factor binding site (TFBS) using knowledge transfer via cross-context sample adaptation. TSK maps sequence segments to a high-dimensional feature space using a discriminative mismatch string kernel framework. In this high-dimensional space, labeled examples of the source context are re-weighted so that the revised sample distribution matches the target context more closely. We have experimentally verified TSK for TFBS identifications on fourteen different TFs under a cross-organism setting. We find that TSK consistently outperforms the state-of-the-art TFBS tools, especially when working with TFs whose binding sequences are not conserved across contexts. We also demonstrate the generalizability of TSK by showing its cutting-edge performance on a different set of cross-context tasks for the MHC peptide binding predictions.", "creator": "dvips(k) 5.991 Copyright 2011 Radical Eye Software"}}}