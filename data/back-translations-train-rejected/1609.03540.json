{"id": "1609.03540", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Sep-2016", "title": "ZaliQL: A SQL-Based Framework for Drawing Causal Inference from Big Data", "abstract": "Causal inference from observational data is a subject of active research and development in statistics and computer science. Many toolkits have been developed for this purpose that depends on statistical software. However, these toolkits do not scale to large datasets. In this paper we describe a suite of techniques for expressing causal inference tasks from observational data in SQL. This suite supports the state-of-the-art methods for causal inference and run at scale within a database engine. In addition, we introduce several optimization techniques that significantly speedup causal inference, both in the online and offline setting. We evaluate the quality and performance of our techniques by experiments of real datasets.", "histories": [["v1", "Mon, 12 Sep 2016 19:24:14 GMT  (359kb,D)", "https://arxiv.org/abs/1609.03540v1", null], ["v2", "Tue, 13 Sep 2016 01:59:05 GMT  (819kb)", "http://arxiv.org/abs/1609.03540v2", null]], "reviews": [], "SUBJECTS": "cs.DB cs.AI cs.LG cs.PF", "authors": ["babak salimi", "dan suciu"], "accepted": false, "id": "1609.03540"}, "pdf": {"name": "1609.03540.pdf", "metadata": {"source": "CRF", "title": "ZaliQL: A SQL-Based Framework for Drawing Causal Inference from Big Data", "authors": ["Babak Salimi"], "emails": ["suciu}@cs.washington.edu"], "sections": [{"heading": null, "text": "ar Xiv: 160 9.03 540v 2 [cs.D B] 13 SE"}, {"heading": "1 Introduction", "text": "This year, it has come to the point that it has never come as far as it has this year."}, {"heading": "2 Background: Causality Inference in Statistics", "text": "The basic causal model in statistics is referred to as the Neyman-Rubin causal model (NRCM). (This framework considers causal effects as comparisons between potential outcomes defined on the same units. This section describes the basic random.Average Treatment Effect (ATE) In the NRCM we are given a table R (T, X, Y (0), Y (1) with N rows as units, indexed by i = 1.. N; see Table 2. The binary attribute T is referred to as treatment assignment (T = 1 means that the unit has been subjected to control); X is a vector of attributes referred to as covariates, unaffected by treatment; and the two attributes Y (1) represent potential outcomes: Y (1) is the result of the unit when it is subjected to treatment."}, {"heading": "B defines perfectly balanced groups, then the treatment assignment is strongly ignorable within each group.", "text": "Proving the overlap of the theorem is trivial, we show unconfounddess = B = B. Abbreviation: Y = (0), Y (1), we have to prove: if (a) (Y-T | X = x) and (b) (X-T | B (X) = b), then4 (Y-T | B (X) = b). (a) implies that E [T-Y] = x] and also E [T-Y = y, X = x, X = x, B = x, B = b, B = b, B = x, B = b = b, since B is a function of X. (b) implies X = x = x = E [T | X] = x = x, B = b = b =. Hence E [T | Y] = y, B = b = b = b = b = b."}, {"heading": "3 Basic Techniques", "text": "In this section, we look at the matching and subclassification techniques used in causal inference and propose several relational encodings, discussing their advantages and disadvantages. Historically, matching was introduced before subclassification, so we present it in this order. Today, subclassification is the dominant technique: we will discuss optimizations for subclassification in the next section. We will consider a single relationship R (ID, T, X, Y), where ID is an integer primary key, T and X respectively denote the treatment and covariant attributes described in the NRCM (see section 2), and Y represent the available result, i.e. Y = Y (z) for iff T = e.g. For each matching method, we define a view of R so that the extension of the view of each instance of R computes a corresponding subset of the instance (ventiv)."}, {"heading": "3.1 Nearest Neighbor Matching", "text": "There are some rules for selecting calibers (see above). (see below) This method selects the closest control unit for each treated unit and can be performed with or without a replacement. (see below) However, this method is helpful in settings where few control units are available. (see below) Complex conclusions are required to estimate the causal effect. (see below) In practice, the balance is usually performed without a replacement. (see above) This method is helpful in settings where there are few control units. (see below) Since the control units are no longer independent, it is necessary to estimate the causal effect. (see below) The balance is usually performed without a replacement. (see below) The risk of bad matches is in the foreground when the next neighbor is."}, {"heading": "3.2 Subclassification", "text": "It is simply that most people who are able to move are able to do so without being afraid that they are able to move."}, {"heading": "4 Optimization Techniques", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 CEM on Base Relations", "text": "All toolkits designed for causal conclusions assume that input is a single table. However, in the real world, the data is normalized and stored in multiple tables connected by key / forgiveness keys. Thus, an analyst can typically integrate tables to construct a single table that contains all the intergradients needed to perform causal analyses. The fact that the data is scattered across multiple tables raises the question of whether we can move the appropriate methods to normalized databases. If so, we must ask ourselves whether we can use this property to optimize the cost of performing matching classes. Integrating tables are inevitable for propensity score matching. For example, we assume that we have two tables R (T, x, y, z) and S (v). To estimate the propensity of each class in a logistics unit, we can assume that such a unit-matching ratio is unavoidable."}, {"heading": "4.2 Multiple Treatment Effect", "text": "In practice, however, it is necessary to study and quantify the causal effects of several treatments. For example, it is possible to determine the cost of several treatments. Subsequently, we consider the relationship between the individual treatments as a single relation. It is about the way in which the individual treatments are disconnected from each other. It is about the way in which the individual treatments are disconnected from each other. It is about the way in which the individual treatments are disconnected from each other. It is about the way in which the individual treatments are disconnected from each other. It is about the way in which the individual treatments are disconnected from each other."}, {"heading": "5 Experimental Results", "text": "We have implemented the basic techniques in Sec. 3 and the optimizations in Sec. 4 in a system called ZaliQL. In this section, experiments are presented that use the evaluation algorithm 2 Database Preparation1: Let T1... Tk be a series of treatments, and XTi be a vector of covariants associated with Ti. 2: Apply the algorithm 1 to partition the treatments in S1... Sk with XSi = Tj. SiXTj and X \u2032 Si = Tj Si XTj. 3: Partially materialize C, the cube on X1.. Xk to answer group questions for each group Si. 4: Perform covariate factoring using C and materialize PSi. 5: How to materialize for each PSi partial Ci, the cube on X1.. Xk to answer group Si. 4: Perform covariate factoring using Si."}, {"heading": "5.1 Setup", "text": "This is because the number of unemployed has risen by more than half in the last ten years."}, {"heading": "5.2 Results", "text": "In fact, most of us have no idea what we are going to do. (...) Most of us have no idea what we are going to do. (...) Most of us have no idea what we are going to do. (...) Most of us have no idea what they are going to do. (...) Most of us have no idea what they are going to do. (...) Most of us have no idea what they are going to do. (...) Most of us have no idea what they are going to do. (...) We have no idea what they are going to do. \"(...)\" We have no idea. \"(...)\" We have no idea. \"(...) Most of us have no idea what they are going to do. (...)"}, {"heading": "6 Related work and conclusion", "text": "The simple nature of the RNCM and its adherence to some statistical assumptions make it more attractive to researchers. Therefore, it is the prominent approach in social sciences, biostatistics, political science, economics and other disciplines. Many toolkits are designed to perform occasional conclusions within this framework, which depends on statistical software such as SAS, SPSS or R projects. However, these toolkits do not scale to large data sets. This work presents ZaliQL, an SQL-based framework for causal conclusions that addresses the scaling problem with existing tools. ZaliQL supports state-of-the-art methods for causal conclusions and runs on a large scale within a database construction. Causality has been extensively studied in databases [20.21.29.32,31,34,33]. We note that this work line differs from the present work in the sense that it aims to identify causes for observed data transmission."}], "references": [{"title": "A survey of heuristics for the weighted matching problem", "author": ["D. Avis"], "venue": "Networks, 13(4):475\u2013493,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1983}, {"title": "et al", "author": ["M. Bal"], "venue": "Total delay impact study. In NEXTOR Research Symposium, Washington DC.,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2010}, {"title": "The effectiveness of adjustment by subclassification in removing bias in observational studies", "author": ["W.G. Cochran"], "venue": "Biometrics, pages 295\u2013313,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1968}, {"title": "Covariate selection for the nonparametric estimation of an average treatment effect", "author": ["X. De Luna", "I. Waernbaum", "T.S. Richardson"], "venue": "Biometrika, page asr041,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2011}, {"title": "Causal effects in nonexperimental studies: Reevaluating the evaluation of training programs", "author": ["R.H. Dehejia", "S. Wahba"], "venue": "Journal of the American statistical Association, 94(448):1053\u20131062,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1999}, {"title": "The design of experiments", "author": ["R.A. Fisher"], "venue": "Oliver and Boyd, Oxford, England,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1935}, {"title": "Comparison of multivariate matching methods: Structures, distances, and algorithms", "author": ["X.S. Gu", "P.R. Rosenbaum"], "venue": "Journal of Computational and Graphical Statistics, 2(4):405\u2013420,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1993}, {"title": "On the completeness of the semigraphoid axioms for deriving arbitrary from saturated conditional independence statements", "author": ["M. Gyssens", "M. Niepert", "D.V. Gucht"], "venue": "Inf. Process. Lett., 114(11):628\u2013633,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2014}, {"title": "Matching as nonparametric preprocessing for reducing model dependence in parametric causal inference", "author": ["D.E. Ho", "K. Imai", "G. King", "E.A. Stuart"], "venue": "Political analysis, 15(3):199\u2013236,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2007}, {"title": "Statistics and causal inference", "author": ["P.W. Holland"], "venue": "Journal of the American statistical Association, 81(396):945\u2013960,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1986}, {"title": "Statistics and causal inference", "author": ["P.W. Holland"], "venue": "Journal of the American Statistical Association, 81(396):pp. 945\u2013960,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1986}, {"title": "Causal inference without balance checking: Coarsened exact matching", "author": ["S.M. Iacus", "G. King", "G. Porro"], "venue": "Political analysis, page mpr013,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2011}, {"title": "et al", "author": ["D. Janzin"], "venue": "Quantifying causal influences. The Annals of Statistics, 41(5):2324\u20132358,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2013}, {"title": "Why propensity scores should not be used for matching", "author": ["G. King", "R. Nielsen"], "venue": "Working Paper, 378,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2016}, {"title": "Efficient processing of window functions in analytical sql queries", "author": ["V. Leis", "K. Kundhikanjana", "A. Kemper", "T. Neumann"], "venue": "Proceedings of the VLDB Endowment, 8(10):1058\u20131069,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2015}, {"title": "Selecting an appropriate caliper can be essential for achieving good balance with propensity score matching", "author": ["M. Lunt"], "venue": "American journal of epidemiology, 179(2):226\u2013235,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "Causality in databases", "author": ["A. Meliou", "W. Gatterbauer", "J. Halpern", "C. Koch", "K.F. Moore", "D. Suciu"], "venue": "IEEE Data Engineering Bulletin, Sept.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2010}, {"title": "The complexity of causality and responsibility for query answers and non-answers", "author": ["A. Meliou", "W. Gatterbauer", "K.F. Moore", "D. Suciu"], "venue": "Proc. VLDB Endow. (PVLDB), 4(1):34\u201345,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2010}, {"title": "PostGIS in action", "author": ["R.O. Obe", "L.S. Hsu"], "venue": "Manning Publications Co.,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2015}, {"title": "Probabilistic reasoning in intelligent systems: networks of plausible inference", "author": ["J. Pearl"], "venue": "Morgan Kaufmann Publishers Inc., San Francisco, CA, USA,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1988}, {"title": "Causality: models, reasoning, and inference", "author": ["J. Pearl"], "venue": "Cambridge University Press,", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2000}, {"title": "Causation, Prediction and Search", "author": ["C.G. Peter Spirtes", "R. Scheines"], "venue": "MIT Press,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2001}, {"title": "Observational studies", "author": ["P.R. Rosenbaum"], "venue": "In Observational Studies, pages 1\u201317. Springer,", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2002}, {"title": "The central role of the propensity score in observational studies for causal effects", "author": ["P.R. Rosenbaum", "D.B. Rubin"], "venue": "Biometrika, 70(1):pp. 41\u201355,", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1983}, {"title": "Reducing bias in observational studies using subclassification on the propensity score", "author": ["P.R. Rosenbaum", "D.B. Rubin"], "venue": "Journal of the American statistical Association, 79(387):516\u2013524,", "citeRegEx": "28", "shortCiteRegEx": null, "year": 1984}, {"title": "A formal approach to finding explanations for database queries", "author": ["S. Roy", "D. Suciu"], "venue": "SIGMOD,", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2014}, {"title": "Causal inference using potential outcomes", "author": ["D.B. Rubin"], "venue": "Journal of the American Statistical Association, 100(469):322\u2013331,", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2005}, {"title": "den Broeck", "author": ["B. Salimi", "L. Bertossi", "D. Suciu", "G. Va"], "venue": "Quantifying causal effects on query answering in databases. In TaPP,", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2016}, {"title": "From causes for database queries to repairs and model-based diagnosis and back", "author": ["B. Salimi", "L.E. Bertossi"], "venue": "In ICDT, pages 342\u2013362,", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2015}, {"title": "Query-answer causality in databases: Abductive diagnosis and view updates", "author": ["B. Salimi", "L.E. Bertossi"], "venue": "In Proceedings of the UAI 2015 Workshop on Advances in Causal Inference co-located with the 31st Conference on Uncertainty in Artificial Intelligence (UAI 2015), Amsterdam, The Netherlands, July 16, 2015., pages 76\u2013 85,", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2015}, {"title": "Causes for query answers from databases, datalog abduction and view-updates: The presence of integrity constraints", "author": ["B. Salimi", "L.E. Bertossi"], "venue": "In Proceedings of the Twenty-Ninth International Florida Artificial Intelligence Research Society Conference, FLAIRS 2016, Key Largo, Florida, May 16-18, 2016., pages 674\u2013679,", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2016}, {"title": "Learning linear regression models over factorized joins", "author": ["M. Schleich", "D. Olteanu", "R. Ciucanu"], "venue": "In ACM SIGMOD,", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2016}, {"title": "Advanced data analysis from an elementary point of view", "author": ["C. Shalizi"], "venue": "Cambridge University Press,", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2012}, {"title": "Matching methods for causal inference: A review and a look forward", "author": ["E.A. Stuart"], "venue": "Statistical science, 25(1):1,", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2010}], "referenceMentions": [{"referenceID": 5, "context": "Causal inference has been studied extensively in statistics and computer science [9,30,13,24,25].", "startOffset": 81, "endOffset": 96}, {"referenceID": 26, "context": "Causal inference has been studied extensively in statistics and computer science [9,30,13,24,25].", "startOffset": 81, "endOffset": 96}, {"referenceID": 9, "context": "Causal inference has been studied extensively in statistics and computer science [9,30,13,24,25].", "startOffset": 81, "endOffset": 96}, {"referenceID": 20, "context": "Causal inference has been studied extensively in statistics and computer science [9,30,13,24,25].", "startOffset": 81, "endOffset": 96}, {"referenceID": 21, "context": "Causal inference has been studied extensively in statistics and computer science [9,30,13,24,25].", "startOffset": 81, "endOffset": 96}, {"referenceID": 1, "context": "Flight delays pose a serious and widespread problem in the United States and significantly strain on the national air travel system, costing society many billions of dollars each year [3].", "startOffset": 184, "endOffset": 187}, {"referenceID": 32, "context": "It is known that David Hume (1711-1776), a Scottish philosopher, who gave the first explicit definition of causation in terms of counterfactuals, was heavily influenced by al-Ghzali\u2019s conception of causality [36].", "startOffset": 208, "endOffset": 212}, {"referenceID": 10, "context": "(1), and is called the fundamental problem of causal inference [14].", "startOffset": 63, "endOffset": 67}, {"referenceID": 11, "context": "Name \u03b4(xi, xj) = Comments Coarsened distance 0 if C(xi) = C(xj) Where C(x) is a function that coarsen \u221e if C(xi) 6= C(xj) a vector of continues covariate [15] Propensity score |E(xi) \u2212 E(xj)| where E(x) = Pr(T = 1|X = x) distance (PS) is the propensity score [27] Mahalanobis Distance (MD) (xi \u2212 xj)\u03a3(xi \u2212 xj) where \u03a3 = covariance matrix [37]", "startOffset": 154, "endOffset": 158}, {"referenceID": 23, "context": "Name \u03b4(xi, xj) = Comments Coarsened distance 0 if C(xi) = C(xj) Where C(x) is a function that coarsen \u221e if C(xi) 6= C(xj) a vector of continues covariate [15] Propensity score |E(xi) \u2212 E(xj)| where E(x) = Pr(T = 1|X = x) distance (PS) is the propensity score [27] Mahalanobis Distance (MD) (xi \u2212 xj)\u03a3(xi \u2212 xj) where \u03a3 = covariance matrix [37]", "startOffset": 259, "endOffset": 263}, {"referenceID": 33, "context": "Name \u03b4(xi, xj) = Comments Coarsened distance 0 if C(xi) = C(xj) Where C(x) is a function that coarsen \u221e if C(xi) 6= C(xj) a vector of continues covariate [15] Propensity score |E(xi) \u2212 E(xj)| where E(x) = Pr(T = 1|X = x) distance (PS) is the propensity score [27] Mahalanobis Distance (MD) (xi \u2212 xj)\u03a3(xi \u2212 xj) where \u03a3 = covariance matrix [37]", "startOffset": 338, "endOffset": 342}, {"referenceID": 23, "context": "Here, the statistics literature makes the following weaker assumption [27]:", "startOffset": 70, "endOffset": 74}, {"referenceID": 23, "context": "Rosenbaum and Rubin [27] gave an elegant characterization of the functions B that define strongly ignorable groups, which we review here.", "startOffset": 20, "endOffset": 24}, {"referenceID": 13, "context": "However, in practice the propensity score E is not available directly, instead needs to be learned from the data using logistic regression, and this leads to several problems [17].", "startOffset": 175, "endOffset": 179}, {"referenceID": 23, "context": "Matching We briefly describe matching following [27].", "startOffset": 48, "endOffset": 52}, {"referenceID": 7, "context": "1]; see [11] for a discussion.", "startOffset": 8, "endOffset": 12}, {"referenceID": 3, "context": "One caveat is that one should not include attributes that are themselves affected by the treatment; the principled method for choosing the covariates is based on graphical models [7].", "startOffset": 179, "endOffset": 182}, {"referenceID": 23, "context": "However, matching have several nice properties that makes it more appealing in practice (see, [27]).", "startOffset": 94, "endOffset": 98}, {"referenceID": 23, "context": "The most common matching method is that of k : 1 nearest neighbor matching (NNM) [27,12,37].", "startOffset": 81, "endOffset": 91}, {"referenceID": 8, "context": "The most common matching method is that of k : 1 nearest neighbor matching (NNM) [27,12,37].", "startOffset": 81, "endOffset": 91}, {"referenceID": 33, "context": "The most common matching method is that of k : 1 nearest neighbor matching (NNM) [27,12,37].", "startOffset": 81, "endOffset": 91}, {"referenceID": 4, "context": "However, since control units are no longer independent, complex inference is required to estimate the causal effect [8].", "startOffset": 116, "endOffset": 119}, {"referenceID": 15, "context": ", [19]).", "startOffset": 2, "endOffset": 6}, {"referenceID": 15, "context": ", [19]).", "startOffset": 2, "endOffset": 6}, {"referenceID": 14, "context": "Note that window functions are typically implemented in DBMS using a sort algorithm, and even more efficient algorithms have been recently proposed [18].", "startOffset": 148, "endOffset": 152}, {"referenceID": 6, "context": "The latter is called optimal matching [10].", "startOffset": 38, "endOffset": 42}, {"referenceID": 0, "context": "[2]), however we prove a NLOGSPACE lower bound:", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "fact, it is known that it does not in general perform any better than the greedy NNM (discussed next) in terms of reducing degree of covariate imbalance [10].", "startOffset": 153, "endOffset": 157}, {"referenceID": 0, "context": "This algorithm can return a maximal matching that is at least 1 2 -optimal [2].", "startOffset": 75, "endOffset": 78}, {"referenceID": 13, "context": "However, it has been the subject of some recent criticisms [17].", "startOffset": 59, "endOffset": 63}, {"referenceID": 13, "context": "In observational settings, we typically have only one sample, so other matching methods dominate propensity score matching [17].", "startOffset": 123, "endOffset": 127}, {"referenceID": 22, "context": "This has been shown to exhibit some odd behavior when covariates are not normally distributed, when there are relatively large number of covariates, or there are dichotomous covariates [26].", "startOffset": 185, "endOffset": 189}, {"referenceID": 18, "context": ", [22]).", "startOffset": 2, "endOffset": 6}, {"referenceID": 2, "context": "The use of subclassification for matching can be traced back to [4], which examined this method on a single covariate (age), investigating the relationship between lung cancer and smoking.", "startOffset": 64, "endOffset": 67}, {"referenceID": 2, "context": "It is shown that using just five subclasses based on univariate continues covariates or propensity score removes over 90% of covariates imbalance [4,28].", "startOffset": 146, "endOffset": 152}, {"referenceID": 24, "context": "It is shown that using just five subclasses based on univariate continues covariates or propensity score removes over 90% of covariates imbalance [4,28].", "startOffset": 146, "endOffset": 152}, {"referenceID": 23, "context": "We assumed that R includes another attribute ps for the propensity score of each unit; the value of ps needs to be learned from the data, using logistic regression [27].", "startOffset": 164, "endOffset": 168}, {"referenceID": 11, "context": "Coarsening Exact Matching (CEM) This method as proposed recently in [15], is a particular form of subclassification in which the vector of covariates X is coarsened according to a set of user-defined cutpoints or any automatic discretization algorithm.", "startOffset": 68, "endOffset": 72}, {"referenceID": 11, "context": "Several benefits of CEM has been proposed in [15].", "startOffset": 45, "endOffset": 49}, {"referenceID": 11, "context": "It has been argued that methods violating the congruous principle may lead to less robust inference with sub-optimal and highly counterintuitive properties [15].", "startOffset": 156, "endOffset": 160}, {"referenceID": 31, "context": "While the weights of the expression may be learned without joining the tables, using techniques such as [35], the integrated table is required to impute the leaned model with the covariate values of each unit to estimate its propensity score.", "startOffset": 104, "endOffset": 108}, {"referenceID": 12, "context": "Note that causal effect is not subadditive [16].", "startOffset": 43, "endOffset": 47}, {"referenceID": 3, "context": "To obtain quality answers for each treatment, we used graphical models to identify a minimum number of covariate attributes to ensure unconfoundedness, because minimizing the number of covariates has been shown to increase the precision of the matching estimators [7].", "startOffset": 264, "endOffset": 267}, {"referenceID": 20, "context": "The tool finds a minimal subset of variables X that forms a d-separation [24] of the treatment T from the effect Y (meaning: all paths from T to Y go through some variable in X).", "startOffset": 73, "endOffset": 77}, {"referenceID": 16, "context": "Causality has been studied extensively in databases [20,21,29,32,31,34,33].", "startOffset": 52, "endOffset": 74}, {"referenceID": 17, "context": "Causality has been studied extensively in databases [20,21,29,32,31,34,33].", "startOffset": 52, "endOffset": 74}, {"referenceID": 25, "context": "Causality has been studied extensively in databases [20,21,29,32,31,34,33].", "startOffset": 52, "endOffset": 74}, {"referenceID": 28, "context": "Causality has been studied extensively in databases [20,21,29,32,31,34,33].", "startOffset": 52, "endOffset": 74}, {"referenceID": 27, "context": "Causality has been studied extensively in databases [20,21,29,32,31,34,33].", "startOffset": 52, "endOffset": 74}, {"referenceID": 30, "context": "Causality has been studied extensively in databases [20,21,29,32,31,34,33].", "startOffset": 52, "endOffset": 74}, {"referenceID": 29, "context": "Causality has been studied extensively in databases [20,21,29,32,31,34,33].", "startOffset": 52, "endOffset": 74}], "year": 2016, "abstractText": "Causal inference from observational data is a subject of active research and development in statistics and computer science. Many toolkits have been developed for this purpose that depends on statistical software. However, these toolkits do not scale to large datasets. In this paper we describe a suite of techniques for expressing causal inference tasks from observational data in SQL. This suite supports the state-ofthe-art methods for causal inference and run at scale within a database engine. In addition, we introduce several optimization techniques that significantly speedup causal inference, both in the online and offline setting. We evaluate the quality and performance of our techniques by experiments of real datasets.", "creator": "LaTeX with hyperref package"}}}