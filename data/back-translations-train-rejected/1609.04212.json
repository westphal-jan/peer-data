{"id": "1609.04212", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Sep-2016", "title": "Formalizing Neurath's Ship: Approximate Algorithms for Online Causal Learning", "abstract": "Higher-level cognition depends on the ability to learn models of the world. We can characterize this at the computational level as a structure-learning problem with the goal of best identifying the prevailing causal relationships among a set of relata. However, the computational cost of performing exact Bayesian inference over causal models grows rapidly as the number of relata increases. This implies that the cognitive processes underlying causal learning must be substantially approximate. A powerful class of approximations that focuses on the sequential absorption of successive inputs is captured by the Neurath's ship metaphor in philosophy of science, where theory change is cast as a stochastic and gradual process shaped as much by people's limited willingness to abandon their current theory when considering alternatives as by the ground truth they hope to approach. Inspired by this metaphor and by algorithms for approximating Bayesian inference in machine learning, we propose an algorithmic-level model of causal structure learning under which learners represent only a single global hypothesis that they update locally as they gather evidence. We propose a related scheme for understanding how, under these limitations, learners choose informative interventions that manipulate the causal system to help elucidate its workings. We find support for our approach in the analysis of four experiments.", "histories": [["v1", "Wed, 14 Sep 2016 10:44:51 GMT  (4891kb,D)", "https://arxiv.org/abs/1609.04212v1", null], ["v2", "Thu, 8 Dec 2016 00:16:28 GMT  (4129kb,D)", "http://arxiv.org/abs/1609.04212v2", null], ["v3", "Fri, 26 May 2017 16:45:06 GMT  (4157kb,D)", "http://arxiv.org/abs/1609.04212v3", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["neil r bramley", "peter dayan", "thomas l griffiths", "david a lagnado"], "accepted": false, "id": "1609.04212"}, "pdf": {"name": "1609.04212.pdf", "metadata": {"source": "CRF", "title": "Formalizing Neurath\u2019s Ship: Approximate Algorithms for Online Causal Learning", "authors": ["Neil R. Bramley", "Peter Dayan", "Thomas L. Griffiths", "David A. Lagnado"], "emails": ["neil.bramley@ucl.ac.uk"], "sections": [{"heading": null, "text": "This year it is so far that it will only be a matter of time before it is so far, until it is so far."}, {"heading": "A computational-level framework for active structure learning", "text": "Before presenting our theoretical framework, we explain our analysis of the problem of structural learning at the computational level, which can be divided into three related elements: (1) the presentation of causal models (2) the implementation of conclusions on possible models in the light of given evidence (observations and results of interventions) and (3) the selection of interventions to collect more evidence and support this conclusion."}, {"heading": "Representation", "text": "We use a standard representation for causal models - the parameterized directed acyclic diagram (Pearl, 2000, see Figure 1a). Nodes represent variables (i.e. the components of a causal system); arrows represent causal relationships; and parameters encode the combined influence of parents (the source of an arrow) on children (the goal of the arrow) 1. Such diagrams can represent continuous variables and any form of causal relationship; but here we focus on binary {0 = absent, 1 = present} variables and assume that generative relationships exist - meaning that the presence of a cause increases the likelihood that the effect can also be represented. 21The following standard diagram nomenclatures often refer to the space between a pair of nodes in a model as an \"edge,\" so that an acyclic causal model defines x as one of three states: forward, backward or inactive."}, {"heading": "Inference", "text": "Each causal model of VariablesX, with its strengths and background parameters w, has a probability for each date d = {x}. z, propagandistic information from the variables fixed by intervention to the others (see Figure 1b). The space of all possible interventions C is composed of all possible combinations of fixed and unfixed variables, and for each intervention the possible data Dc is composed of all combinations of absent / present variables. We use Pearl's Operator (Pearl, 2000) to determine what is fixed on a particular test. Do [x = 1, y = 0] means a variable x \"off\" and variable \"off,\" with all other variables free of Vary4. Interventions allow a learner to override the normal flow of causal influences in a system, which includes possible influences on other components and potential influences between others."}, {"heading": "Choosing interventions", "text": "It is clear that different interventions can lead to different outcomes, which in turn have different probabilities under different models. This means that the interventions are valuable for identifying the true model, which depends heavily on the hypothesis of space and procedure. For example, it is not diagnostic if one is primarily unsure whether there will be an intervention, because one is primarily unsure whether there will be an intervention; the value of an intervention can be quantified in relation to a notion of uncertainty; we can define the value of an intervention as an expected reduction in the true model after we have outcome.5 To calculate this expectation, we must be average, prospective, 5strict and not optimal, because planning can be several steps ahead."}, {"heading": "Approximating with a few hypotheses", "text": "A common approach to situations where a buttock cannot be evaluated in a closed manner is to maintain a manageable number of individual hypotheses or \"particles\" (Liu & Chen, 1998), with weights corresponding to their relative probabilities, and the particle ensemble then acts as an approximation of the desired distribution; sophisticated reweighting and re-sampling samples can then filter the overall ensemble as the data is observed, with Bayesian conclusions approaching; these \"particle filtering methods\" have been used to explain how humans and other animals can approach the solutions to complex problems of probable conclusions; in associative learning (Courville & Daw, 2007), in categorization (Sanborn, Griffiths, & Navarro, 2010) and in binary decision-making (Vul, Goodman, Griffiths, & Tenenbaum, 2009) it has been suggested that people's beliefs actually hold on to a particular subactuality, such as a subactuality of population, and why, during frequent subactuality decisions)."}, {"heading": "Sequential local search", "text": "The idea is that people who are able to survive themselves are also able to survive themselves, the idea is that people who are able to survive themselves are able to survive themselves, the idea is that people who are able to survive themselves are able to survive themselves, the idea is that people who are able to survive themselves are able to survive themselves, the idea is that people who are able to survive themselves are able to survive themselves, the idea is that people who are able to survive themselves are able to survive themselves, the idea is that people who are able to survive themselves are able to survive themselves."}, {"heading": "Search length", "text": "It is reasonable to assume that the number of search steps k that a learner performs will be variable, but that their search capacity will be relatively stable. Therefore, we assume that the learner searches for k steps with each update, with k taken from a Poisson distribution with an average \u03bb [0, \u221e]. Thus, the value of \u03bb determines how sequentially dependent a learner's faith sequences are. A large \u03bb codes a tendency to shift beliefs far in order to take into account the newest dataDtr at the expense of the older data - which are stored only at the place of the previous bt \u2212 1 - while a moderate \u03bb indicates a reasonable trade-off between the initial state and new evidence, and a small \u043c conservatism, i.e. the failure to shift beliefs sufficiently to take into account the newest data.7"}, {"heading": "Putting these together", "text": "This year it is more than ever before."}, {"heading": "The two stages of the schema", "text": "The idea that learners focus on solving local rather than global uncertainties results in a meta-problem of choosing what to focus on next, with intervention choice being a two-step process. We write L for putting together all possible priorities and L for the subset of options the learner will consider at a given time, such as the state of a particular edge or the effects of a particular variable. The procedure is: Level 1 - Selection of a local focus according to - Level 2 Selection of an informative test relating to the chosen focus ltent learners may differ in the issues they consider, meaning that the different types and combinations of local focuses may include. We formalize the two stages of the scheme and then propose three types of local focuses that learners might consider in their L option, which differ in terms of which and how many alternatives. As mentioned above, we assume that the learner has an actualized ability to appreciate their local confidence."}, {"heading": "Edges", "text": "In view of Neurath's framework, it would be obvious for the learners to try to distinguish alternatives that differ with respect to a single edge (Figure 3a), i.e. those that they would consider during a single update step. For a selected edge, Exy, we can then consider a learner's goal as maximizing his requirements with respect to \"H\" (Exy | Et \u2212 1\\ xy, d, w; c) (10) (see Appendix A for the full local entropy equation). Note that Equation 10 is a refinement of Equation 7 in the case of focusing on one edge, from bt \u2212 1 the learner only needs to have a condition for the other edges, Et \u2212 1\\ xy. This goal leads to a preference for determining one of the nodes of the target edge \"to\" while the other remains free, and depending on the other connections in bt \u2212 1, one prefers either determining the other variable \"from\" or \"is equal to\" (from \").\""}, {"heading": "Effects", "text": "A commonly suggested heuristic for efficient search in the deterministic domains is to ask for the dimension that best divides the hypotheses space and eliminates, on average, the greatest possible number of options, variously known as \"constraint-seeking\" (Ruggeri & Lombrozo, 2014) or \"the split half heuristic\" (Nelson, Divjak, Gudmundsdottir, Martignon, & Meder, 2014). In the case of determining the true deterministic (wS = 1 and wB = 0) causal model of N variables through interventions, it turns out that the best split is achieved by querying the effects of a randomly selected variable, essentially asking the question: \"What does x do?\" (Figure 3a) 9. Formally, we could consider this question as the question of which other variables (if any) are derivatives of the x in the true model."}, {"heading": "Confirmation", "text": "Another form of local testing is the search for evidence that would confirm or disprove the current hypothesis, against a single alternative \"zero\" hypothesis. Evidence gathering is a pervasive psychological phenomenon (Klayman & Ha, 1989; Nickerson, 1998) Although the search for confirmation is widely touted as biased, it can also be considered optimal, for example, under deterministic or sparse hypotheses in which causal spaces or high-level priors (Austerweil & Griffiths, 2011; Navarro & Perfors, 2011)."}, {"heading": "Implications of the schema", "text": "This means that we will be able to solve the problems by solving them by solving them by solving them by solving them by solving them by solving them by solving them by solving them by solving them by solving them by solving them by solving them by solving them by solving them by solving them by solving them by solving them by solving them by solving them by solving them by solving them by solving them by solving them by solving them by solving them by solving them by solving them by solving them by solving them by solving them by solving them by solving them by solving them by solving them by solving them by solving them by solving them by solving them by solving them by solving them."}, {"heading": "Bramley, Lagnado, and Speekenbrink (2015)", "text": "In Bramley, Lagnado and Speekenbrink (2015), participants with five probable causal systems interacted with 3 variables (see Figure 4a) and repeatedly selected interventions (or tests) in which any number of variables is either \"on\" or \"off,\" while the rest can vary freely. Subjects, together with the parameters of the true underlying causal model, collectively selected the data they saw. In this experiment, wS was always 1. After each test, participants registered their best guesses about the underlying structure. They were encouraged to give their best guesses about the structure by getting a bonus for each causal relationship (or non-relationship) at the end. There were three conditions: no information (N = 79) was executed first; after finding that a significant minority of participants had randomly performed state information (N = 30), they added a button that could skip over the most important task (the 11) and N was unable to select the most important ones themselves."}, {"heading": "Comparing judgment patterns", "text": "We compared the performance of the participants at Bramley, Lagnado and Speekenbrink (2015) with that of several simulated learners. Posterior draws a new sample from the back for each judgment. Random simply draws a random graph on each judgment. Neurath's ship follows the procedure detailed in the previous section, starting with its previous judgment (bt \u2212 1, or an unconnected model at t = 1) and reconsiders one edge after another based on the evidence collected since its last change Dtr for a small number of steps after observing each result. We illustrate this with a simulation with a short average search length of 1.5 and a behavior of 10 corresponding moderate ridges. Neurate rod samples remain at the previous judgment with the probability of 1 \u2212 P (Dt | bt \u2212 1w; Ct) or alternatively samples from the rear area. The simple advocate always adds edges from each intervened line to all activated and shifted them from the rear line."}, {"heading": "Comparing intervention patterns", "text": "This year, we will be able to look for a solution that we are able to find, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution. \""}, {"heading": "Motivating the new experiments", "text": "Dre rf\u00fc ide eeisrteeSrteee\u00fcgr rf\u00fc eid rf\u00fc ide rf\u00fc nlrf\u00fc rf\u00fc eeisrgtee\u00fceGsrrrteeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeerrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrsrsrsrsrsrsrrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrrsrsrsrsrsrrrrsrrrrrsrsrrreeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeersrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrrrsrsrsrrsrrrrrrrrrrsrrrrsrsrrrsrsrsrrsrsrrrrrrsrsrrrrsrsrsrrs"}, {"heading": "Methods", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Participants", "text": "120 participants (68 male, mean \u00b1 SD age 33 \u00b1 9) were recruited by Amazon Mechanical Turk14, who divided randomly, so that 30 of them were performed under 4 conditions each. They received $1.50 and a bonus of 10c per correctly identified connection in a randomly selected test for each problem (max = $6.00, mean \u00b1 SD $3.7 \u00b1 0.65). The task took an average of 44 \u00b1 40 minutes."}, {"heading": "Design", "text": "This study included the five 3-variable problems in Bramley, Lagnado and Speekenbrink (2015) plus five other 4-variable problems (see Figure 4a), which illustrated three key types of causal structure: forks (divergent connections), chains (sequential connections) and colliders (converging connections), within which there were two different levels of causal strength wS [.9, 0.75] and two different levels of background noise wB [.1,.25], which caused 2 x 2 = 4 between subjects. Thus, for example, in state wS =.9; wB =.1 the causal systems were relatively reliable, with nodes rarely activated without an active parent intervening or causing them."}, {"heading": "Procedure", "text": "The task interface was similar to that in Bramley, Lagnado and Speekenbrink (2015), where each device was presented as several gray circles on a white background (see Figure 6), participants were told that the circles were components of a causal system of binary variables, but no further occlusion stories were given. Initially, all the components were inactive and no connection was marked between them. Participants performed tests by clicking on the components by \"fixing,\" \"fixing\" and \"free\" them in one of three states, then clicking on \"test\" and observing what happened to the \"freely variable\" components as a result. Observations were temporary activity (graphically, activated components would become green and wobble).As in Bramley, Lagnado, and Speekenbrink (2015), participants registered their best guesses about the underlying structure after each test. They did this by clicking between the components to either choose not to connect, or to make a connection or not connect."}, {"heading": "Results and discussion", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Judgments", "text": "Despite significantly greater noise and complexity than Bramley, Lagnado and Speekenbrink (2015), participants performed significantly better than chance in all four conditions (compared to the random performance of 13, participants significantly differed in t-test with p <.001 for all four conditions) and significantly worse than an optimal observer Bayes (p <.001 for all four conditions, Figure 7a). Performance decreased as background noise increased wB F (1, 118) = 4.3, \u03b72 =.04, p =.04. Assessment accuracy was no lower in four compared to three variable problems t (238) = 0.76, p = 0.44. Table 1 shows no relationship to the strength of wS F (1, 118) = 2.7, \u03b72 =.04, p = 0.1. Assessment accuracy was no lower in four compared to variable problems t (238) = 0.44, p = 0.44."}, {"heading": "Sequential dependence", "text": "Table 2 summarizes the number of changes (additions, distances, or reversals of edges) that the participants made between each judgement in all experiments. Looking at the table and Figure 7b, in the rare cases where the simple endorser method would trigger a cycle (0.4% of the studies), the edges were left in their original state. See participants \"assessments (both high and low) show a pattern of rapidly decreasing probability of greater processing distances, imitated by both Neurath's ship and simple endorsement simulations. In contrast, random or posterior samples lead to very different signatures with larger jumps, which are more likely. Simulations simulated by Neurath's ship and simple endorsement distances were on average more dependent on the participants, but have the expected decreasing form. Remaining sample leads to a different pattern with a maximum zero change, but a peak value of 34 percent, but with a very close to the end value of a 34 percent."}, {"heading": "Interventions", "text": "In fact, it is as if most of them are able to abide by the rules that they have imposed on themselves. (...) In fact, it is as if they are able to abide by the rules. (...) It is not as if they are able to understand the rules. (...) It is not as if they are able to obey the rules. (...) It is as if they are able to obey the rules. (...) It is as if they are able to obey the rules. (...) It is not as if they are able to obey the rules. \"(...) It is as if they are able to obey the rules. (...) It is as if they are able to obey the rules. (...) It is as if they are able to abide by the rules. (...) It is as if they are able to obey the rules. (...)"}, {"heading": "Methods", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Participants", "text": "111 UCL graduates (mean age 18.7 \u00b1 0.9 years, 22 male) took part in Experiment 2 as part of a course. They were encouraged to be exact using randomly selected studies, as before, but this time with the possibility of winning Amazon vouchers instead of money. Participants were randomly divided into 8 groups of medium size 13.8 \u00b1 3.4, each of which had a different condition regarding the value of w and the way in which they had registered their responses."}, {"heading": "Design and procedure", "text": "The question that the participants in experiment 1 asked themselves was, \"The connections do not always work,\" and \"sometimes components can be activated by chance.\" To assess the extent of the different reporting conditions, lower sequential dependencies were investigated in Bramley, Lagnado, and Speekenbrink in relation to experiments 1, but only said, \"The connections do not always work,\" and components can be activated by chance. \"To assess the extent of the different reporting conditions, participants did not have to change anything if they had the same judgment as in experiments 1 and 2."}, {"heading": "Results and discussion", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Judgments", "text": "As in the experiments in which the participants were trained on w, the accuracy was significantly higher than chance in all conditions (all 8 t statistics > 6.1 all p-values < 0.001) and below-average performance of a Bayes optimal observer who observed the same data as them. As the noise was not specified, we examined several reasonable predictions on w (always assuming that wS and wB were independent) when we made a uniform prediction that made no assumptions about either wS or wB (UU) where the uniform (0, 1) 2. We also looked at a strongly uniform (SU) variant, the following one (Yeung & Griffiths, 2011), expected causes to be reliable - wS Beta (2, 10), but no assumptions about background noise - wB (wB) uniform (0, 1) 2. We also looked at a strongly uniform (SU) variant following on the Yeung & Griffiths, 2011, which had high expectations of reliability."}, {"heading": "Additional measures", "text": "The participants \"edge confidence assessments increased significantly over the course of studies \u03c72 (1) = 2060, \u03b2 =.04, SE =.0008, p <.001, from.57 \u00b1.20 in the first study to.78 \u00b1.19 in the final study. The probability of changing an edge at the next stage correlated slightly inversely with the students\" reported confidence in this edge \u03c72 (1) = 67, \u03b2 = \u2212.03, SE =.004, p <.001. The reported edge confidence correlated to both the conditional probability of the edge states and the rest of the current model rcond =.20 and the marginal probability of the edge state in full posterior under the UU before rmar =.17, but these correlations did not differ significantly from each other. As predicted, the reported result forecasts were more closely linked to the predictive distribution among the most recent structural judgement of the participants: 1 < < < < < < < < < < < or < 1 = 10; < < < < < < or < 10)"}, {"heading": "Interventions", "text": "The overall distribution of intervention options was broadly similar to that of the other experiments (Figure 11). However, \"one-on-one\" interventions were most frequently chosen and accounted for 39% of the selections. However, in contrast to the previous experiments and consistent with edge-focused learning, the limited \"one-on-one\" interventions were almost as common as individual \"one-on-one\" interventions and accounted for 38% of the tests, compared to 12% over 3-variable problems in Experiment 1. The intervention selection and informativeness of the intervention sequences did not closely correspond to global expectations or a single type of local focus, but could be consistent with a mix of locally impact-focused, edge-focused and confirmation-focused queries."}, {"heading": "Free explanations", "text": "For device 7, the participants provided free explanations of their intervention decisions on each of their six tests. The overall distribution of intervention decisions did not differ significantly from the original presentation of the chain (device 3) \u03c72 = 31, p = 0.21, suggesting that the different response format did not affect the participants \"intervention decisions. To assess what the explanations tell us about the participants\" intervention decisions, we asked two independent coders to categorize the free answers into 8 categories, which were selected in a partially data-driven, partially hypothesis-driven way: 1. A first group of categories were selected with the aim of differentiating the approximations of global strategies introduced in a local uncertainty scheme, such as Uncertain Sampling or expected information maximization. 2. Subset of data was then reviewed and the categories were refined to differentiate their responses with minimal membership. The eight resulting categories were 1. The participants simply wanted to learn via a specific connection."}, {"heading": "Summary of Experiments", "text": "In all of these experiments, participants were clearly able to generate plausible causal models, but they also did so suboptimally."}, {"heading": "Modeling individual behavior", "text": "In all three experiments examined, we found a qualitative agreement, both between the ship simulations of our neurath and the participants \"assessments, and between the two-stage local intervention scheme and the participants\" interventions. However, both simple endorsement and win-stay-lose samples also seemed to do a good job in collecting qualitative assessment patterns. To quantify which of these models better describes participants \"behavior, we adjusted the models to the data and evaluated their competence relative to win-stage, lose-sample and simple endorsement. By adjusting the models separately to individual participants, we also evaluated individual differences in learning behavior, thus gaining a finer picture of the processes involved."}, {"heading": "Judgments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Models", "text": "We compared six models to the participants, the three process models we looked at in the Neurath's Ship (NS) experiment (SO), single endorsers (SE), win-stay, lose-sample (WSLS), alonside an efficient Bayesian learner (Rational), and two zero models Baseline and NS-R. For NS, we adjust three parameters: 1. An average search parameter leads to a probability parameter that updates the probability of searching for different lengths k on each belief. 2. A search behavior parameter controls how strongly the learner moves toward the probable state for an edge, if we remember that it leads to a probability matching, while such a model leads to deterministic mountaineering and random local processing).3. A lapse parameter controls a mixture between model predictions and a uniform distribution.Inclusion of the last parameter in Equation 5, this led to the following equations."}, {"heading": "Evaluation", "text": "To compare these models quantitatively, we used the maximum probability optimization implemented by R's optimization function to adjust the model separately to each of the 370 participants in all three experiments. 18 We used the Bayesian information criterion (BIC, Schwarz, 1978) to compare the models while taking into account their different number of parameters. Baseline acts as a zero model for calculating BICs and pseudo-R2s (Dobson, 2010) for the other models. In Bramley, Lagnado and Speekenbrink (2015), participants were not forced to immediately select something for each edge, though they could not return to \"unspecified\" thereafter, and they could also respond with cyclic causal models if they wanted to. Therefore, we matched only the 75% of the tests in which participants reported a fully specified non-cyclical belief, using the bt \u2212 1 as the non-related model to the first fully specified judgement, as we did with others."}, {"heading": "Results and discussion", "text": "The results of the model match all models: WSLS - 102, NS 85, SE 80 - The lowest total BIC question (93381) with the SE in second place (94326), followed by 18In Appendix B we offer additional details on how the models actually fit. WSLS with (97643), then NS-RE (101837), Rational (1207209) and finally Baseline with (149313). NS was also the most suitable model for Bramley, Lagnado and Speekenbrink with (2015) and Experiment 1, which won the participants in Experiment 2. Thus, all three heuristics essentially beat an exact Bayesian inference of judgment, but Neurath's ship, with its ability to capture a staggered dependence on previous beliefs, essentially surpassed WSLS, and heuristics SE to a lesser degree."}, {"heading": "Interventions", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Models", "text": "We compared our local model of intervention choice (Section 4) with a globally focused model and a baseline model, each with a probability of intervention choice depending on Dtr, Ctr, and bt \u2212 1. We compared the overall distribution of participants \"intervention selection and final performance with edge-focused, effect-focused, and validated focused tests. We found that none of these models were very similar to participants\" response patterns alone, but the overall distributions were consistent with a mix of different types of local tests. This was also supported by the free-response coding in Experiment 2, which showed that participants would typically select a mixture of specific edges, effects of specific variables, and confirmation of the current hypothesis. Therefore, we looked at four locally driven intervention models, one for each of the three foci, plus a mixture."}, {"heading": "Evaluation", "text": "To compare the model predictions of the choice of local focus according to the self-statements of the participants in problem 7 in experiment 2, we calculated the probability of each prediction of local focus in each test by calculating P (c | l, \u03b7, bt \u2212 1, w) for each of the local focus (s) we considered, using a fixed common \u03b7 = 20 to capture strong but non-deterministic preferences for the most useful intervention (s), and then calculating for each data point ct which assigned lt the most likely intervention that the participant actually chose. Figure 14 shows the most likely focus of the participants \"intervention choice in the final problem against the code assigned to their free answers."}, {"heading": "Results and discussion", "text": "The mixed local focus model was the most suitable model across the three experiments with the lowest overall selection of BICs of 97757, followed by effects then by the global focused model, then by edges and finally by confirmation and then baseline. However, there were a lot of individual variations suggesting that a single model did not capture the population well. However, more participants were best described by an effect focus (121) than by a mixed focus (77), but each model received some support with 58, 43, 36 and 35 individuals who each fit best by global, confirmation-focused and edge-focused models. Furthermore, the effect focus overall was the most suitable model in Bramley, Lagnado and Speekenbrink (2015), where participants had a strong tendency to fix a single variable at a given time. As shown in Table 5, mixed the overall matching model for experiments 1 and 2 was the best, and the majority of participants were most likely to have matched unfocused models for one of the 277 / 370 local problems."}, {"heading": "General Discussion", "text": "We studied how people manage to identify causal models despite their limited computational resources. In three experiments, we found that participants \"assessments partially reflected true posterior behavior while exhibiting sequential dependencies. In addition, participants\" intervention decisions reflected average expected information, but insufficiently responded to the evidence already observed and were consistent with local focus. We were able to capture participants \"assessment patterns by assuming that they maintained a single causal model rather than a full distribution. We suggested that participants considered local changes to improve the ability of their single model to explain the latest data, and compared them to two other suggestions, one based on the idea that participants occasionally revert to the full posterior judgment pattern, and the other, a heuristic model based on ignoring the possibility of indirect effects, while all three of our suggestions had the best fit."}, {"heading": "Limitations of Neurath\u2019s ship", "text": "Like any theory, Neurath's ship was assessed against a set of assumptions, some of which we are discussing here."}, {"heading": "Measurement effects", "text": "In this context, it should be noted that solving the problems is not a fundamental change in learning processes. To mitigate the problems of these problems, we both encouraged the participants to make their best and most recent guesses at any point during the task, and examined various reporting conditions to explore the impact of the approaches on the learning process. In Bramley, Lagnado and Speekenbrink (2015) and the state in Experiment 2, participants were able to leave parts of their hypothesis intact if they did not want to change them, resulting in minimal invasiveness that caused the learner to reconsider an edge they would not otherwise have done, just because they were at the expense of mixing real incremental changes in response to laziness."}, {"heading": "Acyclicity", "text": "In Bramley, Lagnado, and Speekenbrink (2015), cyclic graphs were quite a rare choice (where participants were allowed to draw them), and so we simply chose to exclude them from the instructions of later experiments. However, in tasks where humans draw causal models of real phenomena, they often draw cyclic or reciprocal relationships (Kim & Ahn, 2002; Nikolic & Lagnado, 2015), and many real processes are characterized by bidirectional causality, such as supply and demand in economics or homeostasis in biological systems. There are various ways to depict dynamic systems. One suggestion is the dynamic Bayesian network (Dean & Kanazawa, 1989), which \"unfolds\" the dynamic structures of the interference chain to form a regular acyclic network with causal influences over time."}, {"heading": "Evaluation of evidence", "text": "Another pragmatic limitation of the current modelling was the assumption of the noise-intensive mode of operation for the true underlying causal models. While we were careful to train participants in the sources of noise both in experiments and in the exact values in Bramley, Lagnado and Speekenbrink (2015), our own previous work suggests that people have easier ways of assessing the number of surprising results under each model - for example, in Bramley, Dayan and Lagnado (2015) - that participants \"judgments could be captured by lumping the sources of noise into one pot and counting only the number of surprising results under each model. One possibility is that people actually made probability estimates by simulation using an internal causal model. Thus, one could perform mental intervention by activating a component of one's own internal causal model and keeping track of the expanding variables."}, {"heading": "Antifoundationalism", "text": "The core of Neurath's ship is the strong assumption that humans consider only one global hypothesis and make local changes within that framework, which is the \"anti-foundationalism\" captured by the Duhem-Quine thesis - any local theoretical claim is necessarily supported by the surrounding assumptions, but this may be too strong for some of the simpler problems we were looking at here, as the worlds were small and limited enough for some people to think at the global level; for the three variable problems in particular, some participants may have been able to consider alternatives at the level of the whole model and thus be able to switch from the common cause to the chain, etc., in a single step; while the judgments of the participants showed a high sequential dependence, they occasionally abruptly changed their model; the theory of unexpected uncertainty (Yu & Dayan, 2003) and the substantial work on variable tasks (Speekenbrink, 2010 \"s existing ship anchoring) may have brought them consistently to the forefront of their predicament."}, {"heading": "Selective memory", "text": "We assumed that the participants \"judgement updates were based on the most recent data Dtr collected since the last time they changed their hypothesis. This is quite economical in the current context, since the learner rarely has to store more than a few tests worth of evidence. It also captures the idea of semantization - that the more episodic evidence is included in his hypothesis, the more certain it is to forget it. However, the particular choice of Dtr is certainly a simplification. People often remember evidence from the time before their last change and do not store current evidence, especially when their beliefs have solidified. They could also collect summary evidence at the level of individual edges, for example, by counting how often pairs of components activate together, or by remembering evidence about some components, but not others, or they only store evidence when they are surprising under the current model. To adapt the models, it was necessary to make simplistic assumptions, the form of remembering everything between the house and your trust in some half-house hypothesis."}, {"heading": "Alternative approximations and representations", "text": "This year it is so far that it will only be a matter of time before it is so far, until it is so far."}, {"heading": "The navy of one", "text": "In fact, it is the case that most of us are able to move into another world, in which they are able to move, in which they move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they, in which they live, in which they, in which they live, in which they, in which they live, in which they, in which they, in which they are able to move, in which they are able to move, in which they are able to move, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they, in which they live, in which they, in which they live, in which they live, in which they, in which they, in which they live, in which they live, in which they, in which they live, in which they, in which they live, in which they, in which they, in which they live, in which they, in which they, in which they, in which they, in which they are able to move, in which they, in which they are able"}, {"heading": "Scope of the theory", "text": "We modeled causal change of belief as a process of gradually actualizing a single representation through local conditional processing. Although we have chosen to focus on causal structural conclusions within the causal Bayes network, there is no reason why this approach should be limited to this area. By using the ship metaphor Neuraths to provide an intuitive answer to how humans circumvent the intractability of rational theory formation (van Rooij et al., 2014), we can begin to develop more realistic models of how humans generate the theories they do and how and why they get stuck. We could explain the induction and adaptation of many of the rich representations used in cognition by analogous processes."}, {"heading": "Conclusions", "text": "In this paper, we proposed a new model of causal theory change based on an old idea from the philosophy of science - that learners cannot maintain a distribution of all possible beliefs, and therefore must rely on sequential local changes in a single representation to update beliefs in order to incorporate new evidence. We showed that we can well represent participants \"assessment processes in three experiments, and argued that our model provides a flexible candidate to explain how complex representations can be formed in cognition. We also analyzed participants\" information-gathering behavior and found that it is consistent with the thesis that learners focus on solving manageable areas of local uncertainty rather than global uncertainty, recognizing their learning limitations. Together, these representations show how people manage to construct rich, causally structured representations through their interactions with a complex noisy world."}, {"heading": "A Formal specification of the models", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Representation and inference", "text": "A noise OR parameterized causal model m over variable X, with strength and background parameters wS and wB assign to each date (a complete observation or the result of an intervention) d a probability as a product of the probability of each variable that was not interfered with the states of its parents P (d | m, w) = result of a complete observation X (x | dpa (x), w) (22) P (x | dpa (x), w) = x + (1 \u2212 2x) (1 \u2212 wB) (1 \u2212 wS) (1 \u2212 wS).P (x) y (23), where pa (x) denotes the parents of variable x in the causal model (see Figure 1 for an example). We can therefore calculate the posterior probability of the model m \u00b2 M over a series of models (m) (otherwise P (m) and data D = {di} associated with interventions C = {ci}."}, {"heading": "Intervention choice", "text": "The value of an intervention can be quantified in relation to an idea of uncertainty. Here, we take the Shannon entropy (Shannon, 1951), for which the uncertainty in a distribution over causal models M is assumed to be H (M) = \u2212 experiential value m (m) log2 P (m) log2 P (m) (26), let us take H (M | d, w; c) for the reduction of uncertainty derived from foreseen P (M | d, w; c) logP (m | d, w; 27) logP (m | d, w; 27) logP (m | 27) logP (m | d, w; 27) after the execution of the intervention c (M | d, w; c) logP (m | d, w; c) logP (m) logP (m | d, w; 27) logP (m) logP (d, w; 27) after the execution of the intervention c (m | d, w; c) the value of an intervention as an expected reduction of uncertainty according to its outcome."}, {"heading": "An algorithmic-level model of sequential belief change", "text": "Let E be an adjacency matrix so that the upper triangle in which Eij (if i < j \u2264 N) stands represents the state of the edge i \u2212 j in a causal model m. Each model m \u00b2 M corresponds to a setting for all eij where i < j \u2264 N, to one of the three edge states e \u00b2 1: i \u00b2 j, 0: i = j, \u2212 1: i \u00b2 j}. Starting with each hypothesis and iterative sampling of the edge states P (Eij | E\\ ij, Dtr, w; Eidie & Mukherjee, 2011), the following equation is: P (Eij = e\\ ij, w; Ctr) = P (Eij = e\\ ij, w; E\\ ij) = P (Eij = e\\ ij, e\\ ij), Dtr, w\\ ij, w, w."}, {"heading": "A distribution over search lengths", "text": "We assume that for each update the length of the search k of the learner is drawn from a Poisson distribution with an average \u03bb [0, \u221e] P (k) = \u03bbke \u2212 \u03bbk! (33)"}, {"heading": "Putting these together", "text": "To calculate the probability distribution of the new faith bt (dt, bt \u2212 1 search behavior \u03c9) and a chain of length k, we first construct the transition matrix R\u03c9t for the Markov search string by averaging the conditional distributions associated with the selection of each edge, weighted by the probability of selecting this edge b. By raising this transition matrix to power k (i.e. some search length) and selecting the line corresponding to the initial faith [(Rorizon) k \u2212 1, we obtain the probability of accepting each new faith bt (see Figure 2 for a visualization) as a new faith b (see Figure 2 for a visualization) at the end of the k length of the search term P (Bt | Dtr, bt \u2212 1, \u043c, k; Ctr) as a new faith bt (see Figure 2 for a visualization)."}, {"heading": "A local uncertainty schema", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Edge focus", "text": "Compared to a focus on an edge Exy, intervention values were calculated on the basis of expected information as in Appendix A, but assuming a previous entropy as that of an even distribution across the three possible edge statesH (Exy | E\\ xy) = \u2212 3 (13 log21 3) (37) and the calculation of posterior entropy for the possible results d \u0192D usingH (Exy | E\\ xy, d, w; c) = \u2212 \u2211 z = \u2212 1,0,1} P (Exy = z | E\\ xy, d, w; c) log2 P (Exy = z | E\\ xy, d, w; c) (38)"}, {"heading": "Effect focus entropy", "text": "Relating to the focus on the effects of variables x, intervention values were calculated using expected information as in Appendix A, but using previous entropy, calculated by subdividing a uniform predecessor model M into groups of models Mo (z), each of the progeny propositions z'De (x) H (De (x))) = \u2212 \u2211 z'De (x) \u0445 m'Mo (z) 1 | M | log2 \u0445 m'Mo (z) 1 | M | (39) posterior entropies were then calculated by calculating the probabilities of the elements in each Mo (z) P (m | d, w; c) (40)"}, {"heading": "Confirmation focus entropy", "text": "In order to focus on the distinction between current bt hypothesis and zero b0 hypothesis, the intervention values were calculated on the basis of the aforementioned expected information, but the previous entropy was always based on a uniform prediction across the two hypotheses H ({bt, b0}) = \u2212 2 (12 log21 2) (41) and the posterior entropy was calculated using H ({bt, b0} | d, w; c) = \u2212 \u2211 z \u00b2 P (bz | d, w; c) \u0445 z \u00b2 P (bz, w; c) \u0445 z \u00b2 P (b z \u00b2 | d, w; c) \u04320, t \u00b2 P (b \u00b2 | d, w; c) (42)."}, {"heading": "B Additional modeling details", "text": "The maximum probability was determined by repeating all the optimizations with a range of randomly selected starting parameters. k For averaging different values of k in the faith models, we capped k at 50 and renormalized the distribution so that P (k \u2265 0 \u0445 k \u2264 50) = 1. This made a negligible difference to the adjustments, since the probabilities of P (Bt | dr, bt \u2212 1, \u03c9, k; Ctr) for values of k N (where N is the number of variables) were very similar. To give participants the opportunity to occasionally miss the concentration or forget the result of a test, we added a lapse parameter - i.e. a parametric set of decision noise, i.e. a parametric set of simplicity, so that the probability that a random comes to a mixture of data is not guaranteed that the results of any model will be unpredicted, but that we will have an unforeseen effect on each other city."}, {"heading": "Marginalization", "text": "For all the modelling in Experiment 3, we had to determine a mean value over the unknown noise w. Therefore, we recorded 1000 evenly distributed wS and wB samples and determined these in the calculation of boundary probabilities and background probabilities. These boundary and background probabilities were used for the calculation of expected information gain values."}, {"heading": "Evaluating fits", "text": "Baseline acts as a zero model for calculating BICs (Schwarz, 1978) and pseudo-R2s (Dobson, 2010) for all other models."}], "references": [], "referenceMentions": [], "year": 2017, "abstractText": "Author note: Neil R. Bramley, Department of Experimental Psychology, University College London; Peter Dayan, Gatsby Computational Neuroscience Unit, University College London; Thomas L. Griffiths, Department of Psychology, University of California Berkeley; David A. Lagnado, Department of Experimental Psychology, University College London. This research was supported in part by an Economic and Social Research Council UK grant (RES 062330004). Correspondence concerning this article should be addressed to: 201, 26 Bedford Way, University College London, London, UK,WC1H 0DS, Email: neil.bramley@ucl.ac.uk . Experiment 2 previously appeared in a conference paper presented at The 37th Annual Conference of The Cognitive Science Society (Bramley, Dayan, & Lagnado, 2015). A preprint of the current manuscript was made available on arXiv on September 17th 2016 here: https://arxiv .org/abs/1609.04212.", "creator": "LaTeX with hyperref package"}}}