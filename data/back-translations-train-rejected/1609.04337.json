{"id": "1609.04337", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Sep-2016", "title": "Quick and energy-efficient Bayesian computing of binocular disparity using stochastic digital signals", "abstract": "Reconstruction of the tridimensional geometry of a visual scene using the binocular disparity information is an important issue in computer vision and mobile robotics, which can be formulated as a Bayesian inference problem. However, computation of the full disparity distribution with an advanced Bayesian model is usually an intractable problem, and proves computationally challenging even with a simple model. In this paper, we show how probabilistic hardware using distributed memory and alternate representation of data as stochastic bitstreams can solve that problem with high performance and energy efficiency. We put forward a way to express discrete probability distributions using stochastic data representations and perform Bayesian fusion using those representations, and show how that approach can be applied to diparity computation. We evaluate the system using a simulated stochastic implementation and discuss possible hardware implementations of such architectures and their potential for sensorimotor processing and robotics.", "histories": [["v1", "Wed, 14 Sep 2016 16:41:31 GMT  (3301kb,D)", "https://arxiv.org/abs/1609.04337v1", "Preprint of article submitted for publication in International Journal of Approximate Reasoning and accepted pending minor revisions"], ["v2", "Mon, 31 Oct 2016 15:36:01 GMT  (5037kb,D)", "http://arxiv.org/abs/1609.04337v2", "Preprint of article submitted for publication in International Journal of Approximate Reasoning and accepted pending minor revisions"]], "COMMENTS": "Preprint of article submitted for publication in International Journal of Approximate Reasoning and accepted pending minor revisions", "reviews": [], "SUBJECTS": "cs.CV cs.AI", "authors": ["alexandre coninx", "pierre bessi\\`ere", "jacques droulez"], "accepted": false, "id": "1609.04337"}, "pdf": {"name": "1609.04337.pdf", "metadata": {"source": "CRF", "title": "Quick and energy-efficient Bayesian computing of binocular disparity using stochastic digital signals", "authors": ["Alexandre Coninxa", "Pierre Bessi\u00e8re", "Jacques Droulez"], "emails": ["alexandre.coninx@isir.upmc.fr"], "sections": [{"heading": null, "text": "Reconstructing the three-dimensional geometry of a visual scene using binocular disparity information is an important problem in computer vision and mobile robotics, which can be formulated as a Bayesian inference problem. However, calculating the full disparity distribution with an advanced Bayesian model is usually a persistent problem and proves to be mathematically difficult even with a simple model. In this paper, we show how probable hardware with distributed memory and alternative representation of data as stochastic bitstreams can solve this problem with high performance and energy efficiency. We propose a way to express discrete probability distributions using stochastic data representations and perform Bayesian fusion with these representations, and show how this approach can be applied to disparity calculations. We evaluate the system using a simulated stochastic implementation and discuss possible hardware implementations of such architectures and their potential for sensory processing, imbotic and energy saving:"}, {"heading": "1. Introduction", "text": "This year, it is closer than ever before in the history of the country."}, {"heading": "2. Previous work", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1. Hardware stochastic computing", "text": "The general idea of stochastic computations with time coding can be traced back to the groundbreaking work of Neumann [13] and Gaines [14], who emphasized the interest of such data representations, but their approaches were not widely pursued due to the rapid development of more efficient deterministic computers. Recently, the idea of developing hardware has been pursued by several teams, more specifically sensor-imotor and cognitive systems."}, {"heading": "2.2. Disparity computation", "text": "Since it provides a way to estimate depth information using data from standard digital cameras, the problem of binocular disparity has received widespread attention since the early days of computer vision. Existing approaches have been summarized in reviews [2, 3] that show that most methods follow the same general structure, which can be divided into three steps: 1. Calculating a matching value associated with each possible pair of matching pixels is a measure of disparity: the less likely the pixels are to match, the higher it is. Costs are calculated locally, typically by comparing the brightness or color of individual pixels. The most common matching costs are the square difference in pixel values [2], but some other techniques process the image using operators such as the gradient [23] or using banks of linear spatial filters [24]. The use of an optional cost aggregation that performs a spatial aggregation."}, {"heading": "2.2.1. Bayesian disparity computation", "text": "Several of the existing works [6, 7] use the Bayesian sequential frame to describe this process. For example, Belhumeur [6] proposes to reconstruct the scene geometry S from the left and right images Il and Ir using a Bayesian model: P (S | Il, Ir), P (S) \u00b7 P (Il, Ir | S) (1), with P (S) being a prior indication of the expected shape (smooth, etc.) of the world, and P (Il, Ir | S) a data term calculated from the matching costs. Thus, the calculation of P (Il, Ir | S) corresponds to the matching cost calculation step, there is no cost aggregation step, and the calculation and integration of the previous one forms the optimization step. Belhumeur uses square difference to calculate the costs, and proposes three increasingly complex world models to define the previous one, but the calculation of the full posteriality probability distribution shows max (D1)."}, {"heading": "2.2.2. Supervised techniques", "text": "The development of public image pairs with a disparity base such as the KITTI dataset [4] or the Middlebury dataset [5] has made it possible to treat disparity calculations as a supervised machine learning problem. Some algorithms use deep Convolutionary Networks to determine the appropriate costs [25, 26], and perform cost aggregation and optimization using other techniques, which currently occupy the top of the KITTI ranking. Although they are extremely precise in benchmarks, their efficiency depends on the existence of a relevant supervised training dataset, they are also very computationally intensive, use high-end CPUs and GPUs, and sometimes require several minutes of processing time per frame. These features would make the application of these techniques difficult in a mobile robotics context."}, {"heading": "2.2.3. Sampling approach", "text": "One approach that is directly relevant to our positioning is the method proposed by Jonas et al. [17] as an application of his aforementioned hardware architecture to approximate conclusion, modelling the disparity distribution using a Markov random field and using a hardware architecture using Gibbs scanning to capture the posterior distribution. Although this approach is efficient and allows to use a computationally intensive Bayesian disparity model with global optimization, it uses a unique, centralized pseudo-random number generator as a source of entropy and lacks some features of our system, such as the high parallelism and robust calculation of full disparity with a very low number of clock cycles."}, {"heading": "3. Bayesian disparity computation model", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1. Overview", "text": "The aim of the disparity calculation is to estimate the three-dimensional geometry of a visual scene from two corrected images of two identical cameras with a focal length f removed from a known base distance B. If an object is projected into the image plane of the left camera Il at position x and into the image plane of the right camera Ir at position x \u2212 d, its depth Z can be calculated from the camera2http: / / www.cvlibs.net / datasets / kitti / eval _ scene _ flow.php? benchmark = stereo, consulted 24 / 03 / 2016, with Z = B \u00b7 fd (see Figure 1). The aim of a disparity algorithm is therefore to identify suitable pixels in the two images in order to calculate the disparity."}, {"heading": "3.2. Model description", "text": "As already mentioned in Section 2.2.1, the main obstacle to calculating complete disparity distributions is the very high cardinality of the distribution under consideration. (This is the very high cardinality of the distribution under consideration: integrating smoothness into the probable model requires performing inferences to size distributions (as is the case in [6], where Npixel is the number of pixels in the domain on which the optimization is performed). If the optimization is performed on the entire image or on whole rows or columns (as is the case in [6]), the problem becomes completely intractable, but even smaller integration neighbors are problematic, to avoid this problem, we will all perform spatial information integration as image processing operations, and then perform only the preprocessed operations. Therefore, our stereo matching method relies on preprocessing images using linear conversion filters to extract relevant features."}, {"heading": "4. Stochastic implementation of the model", "text": "Previous work [22] has shown that naive Bayesian fusion of stochastic machines could be performed. In this section we will describe this structure of a Bayesian machine constructed as a matrix of stochastic operators and explain how it can be used to implement the probable binocular disparity calculation described in Section 3.2."}, {"heading": "4.1. Stochastic Bayesian fusion", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1.1. Probabilities as stochastic bitstreams", "text": "Our stochastic computational architecture represents data using stochastic bit streams. Stochastic bit streams are random digital binary signals that express a probability value (p value) in relation to the bits set to 1 in a given signal (Fig. 2a). Therefore, the generation of a stochastic bit stream b to encode probability p is done using a random generator that outputs random bits with a probability p. Conversely, extracting the p value from b and storing it as a floating point or fixed point number requires the integration of information from b over a longer period of time to count the proportion of bits to 1, with the accuracy of the recovered p value increasing with the integration time. If two probability values p1 and p2 are encoded by two uncorrelated stochastic bit streams b1 and b2, and these two signals are entered into a logical AND gate [P] [P] = 1 = 1 (s1) (1 = 1)."}, {"heading": "4.1.2. Representation of discrete random variables: the stochastic bus", "text": "A discrete random variable V with cardinality M can be maximized by a series of M stochastic bit streams b1,.., bM, which we call a stochastic bus of width M. The j-th bit stream bj encodes a probability pj = C \u00b7 P ([V = Vj]). A useful choice isCmax = 1max jP ([V = Vj]), which makes it possible to represent the most probable values of encryption and processing, V is j P ([V = Vj]). a useful choice isCmax = 1max jP (V = Vj)."}, {"heading": "4.1.3. Bayesian inference with stochastic bitstreams: the Bayesian machine", "text": "One of the most common Bayesian computational techniques is naive Bayesian fusion [27]: the calculation of the posterior probability distribution on a sought-after variable S, the knowledge of a prior distribution P (S), and the conditional distributions P (Ki | S) on some known variables K1,..., KN. If the Ki variables are conditionally independent of S, the inference is calculated by: P (S | K1,., KN) = 1Z P (S) N = 1 P (Ki | S) (5), where Z is a normalization constant. This distribution can be calculated using stochastic bit streams by using both the previous P (S) and the data conditions P (Ki | S) with stochastic buses of width M, according to the cardinality of S. i."}, {"heading": "4.2. Stochastic disparity computation", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.2.1. General description", "text": "The architecture described in Section 4.1 can be used to implement the disparity calculation model described in Section 3. The search variable is the disparity D, which incorporates values in J0; DmaxK and therefore has cardinality Dmax + 1, and the data expressions are the three probability values derived from the luminous disparity characteristics 3 to Eq.We will therefore use such a matrix of stochastic operators with N = 3 and M = Dmax + 1 to calculate a stochastic bus representation of the posterior disparity representation. In the following, we will use a uniform disparity before (P ([D = d]) = 1Dmax + 1, and the complete disparity distribution for a pixel can be efficiently represented by a stochastic bus, where all signals are constant equal to 1 (C0 = Dmax + 1). Each of the data expressions is integrated as described in Section 4.1 above, and the complete disparity distribution for a pixel can be clearly represented by a counter-parity (if the disparity can be estimated from the first parity in Section 4)."}, {"heading": "4.2.2. Processing of occlusions and low-contrast areas", "text": "In fact, it is as if most people are able to surpass themselves, and that they do not. (...) It is not as if they would do it. (...) It is as if they would do it. (...) It is as if they would do it. (...) It is as if they would do it. (...) It is as if they would do it. (...) It is as if they would do it. (...) It is as if they do it. (...) It is as if they would do it. (...) It is as if they would do it. (...) It is as if they would do it. (...) It is as if they do it. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (It is. (...) It is. (...) It is. (It is. (...) It is. (It is. (...) It is. (It is. (...) It is. (It is. (...) It is. (it is. (It is. (It is.) It is. (It is. (it.) It is. (It is. (it.) It is. (It is. (it.) It is. (It is. (It is. (it.) It is. (it. (It is.) It is. (it. (it. (it.) It is. (it. (it. (it.) It is. (it.) It is. (it. (it. (it.) It is. (it. (it.). (it is."}, {"heading": "5. Stochastic model evaluation", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1. Model implementation", "text": "To evaluate the benefits of using a stochastic disparity calculation system, we will compare two implementations of the same Bayesian disparity algorithm described in Section 3.2. \u2022 A reference implementation that performs the calculation as floating-point operations. \u2022 A simulated stochastic implementation that uses pseudo-random number generators (PRNG) and bitwise Boolean logic operations to simulate the behavior of the Bayean machine, as in Section 4.2.Both implementations are written in C + + and run on a desktop computer running a 64-bit Intel Xeon E3-1271 v3. The reference implementation uses FPU calculations with 64-bit floating-point numbers. The simulated stochastic implementation uses the Mersenne Twister 19937 PRNG of the GNU implementation of C + 11 to perform stochastic operation with bit-streams, and the bitlight-64 probabilities."}, {"heading": "5.2. Results", "text": "The reference implementation ran in approximately 1.25 seconds per frame, which is the order of magnitude of the \"fast\" state-of-the-art disparity algorithms. Simulated stochastic implementation ran in 25 to 110 seconds per frame (depending on the frame and the size of the output counters).This low performance is due to the effort involved in simulating stochastic machines with non-stochastic hardware; the performance of the stochastic system is better estimated by the number of simulated clock cycles used to calculate a frame (see below)."}, {"heading": "5.2.1. Dataset and model parameters", "text": "We collected stereo image pairs with a PointGrey BumbleBee2 BB2-03S2C25 wide-angle color stereoscope camera with focal length f = 2.5mm, baseline spacing B = 120mm and resolution 640 \u00d7 480 at 25 frames per second. Images were corrected using Triclops \"proprietary PointGrey middleware. The camera was mounted on a TurtleBot 2 mobile robotic base, which was manually controlled in an office environment to collect data. A total of 6301 images were taken, corresponding to 4 minutes and 10 seconds of video frame. Captured 24-bit color images were converted to 8-bit brightness images, with pixel values in J0; 255K. Preprocessing described in section 3.2 therefore generates function cards with pixel values in J0; 255K for the average filter and J \u2212 127; 127K for the gradients, with a minimum of impairment, which was easily matched to a minimum of 80, where a minimum of impairment could be found."}, {"heading": "5.2.2. Disparity computation accuracy", "text": "One feature of stochastic computation using stochastic bitstreams is progressive precision: the longer the information from a bitstream is integrated, the more accurate the corresponding p-value can be estimated. In the context of the stochastic bus frame described in Section 4.1.2, this means that the precision increases with the size of the counters used: the higher the maximum value of the counters, the closer the resulting distribution will be. Therefore, we used the simulated stochastic conversion with variable counters to quantify it. The stochastic disparity processor described in Section 4.2 provides two functions: the detection of no-match pixels and the calculation of the disparity distribution based on no-match pixels. \""}, {"heading": "6. Discussion: speed, energy and hardware implementation considerations", "text": "This year it is as far as never before in the history of the Federal Republic of Germany."}, {"heading": "7. Conclusion", "text": "We have presented an architecture to calculate a class of Bayesian inference problems using probabilistic hardware using stochastic bitstreams, and have evaluated this system in simulation using binocular disparity computation as an example, demonstrating high performance and energy efficiency. Although the work described in this paper uses simulations of hypothetical stochastic machines using experimental hardware, and thus can only provide rough estimates of the performance of these systems, we believe that these results clearly highlight the potential of Bayesian computation using stochastic bitstreams for sensor-imotor processing, especially in applications with tight computer and energy resources such as mobile robotics, embedded systems, or distributed sensors. The proposed architecture allows for solving many sensory fusion and processing problems, resulting in complete distributions expressed as bus stochastic bitstreams, with low power consumption and reduced computer resources."}, {"heading": "Acknowledgements", "text": "This work was carried out within the framework of the EU Future and Emerging Technologies BAMBI project [FP7-ICT-2013- C, project number 618024] and partly supported by ANR Labex SMART [ANR-11-LABX-65]."}], "references": [{"title": "Are we ready for Autonomous Driving? The \\textsc{KITTI} Vision Benchmark Suite", "author": ["A. Geiger", "P. Lenz", "R. Urtasun"], "venue": "Computer Vision and Pattern Recognition) ", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "A taxonomy and evaluation of dense two-frame stereo correspondence algorithms", "author": ["D. Scharstein", "R. Szeliski"], "venue": "International Journal of Computer Vision 47 ", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2002}, {"title": "Review of Stereo Vision Algorithms: From Software to Hardware", "author": ["N. Lazaros", "G.C. Sirakoulis", "A. Gasteratos"], "venue": "International Journal of Optomechatronics 2 ", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2008}, {"title": "Vision meets robotics: The KITTI dataset", "author": ["a. Geiger", "P. Lenz", "C. Stiller", "R. Urtasun"], "venue": "The International Journal of Robotics Research", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2013}, {"title": "High-resolution stereo datasets with subpixelaccurate ground truth", "author": ["D. Scharstein", "H. Hirschm\u00fcller", "Y. Kitajima", "G. Krathwohl", "N. Ne\u0161i\u0107", "X. Wang", "P. Westling"], "venue": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) 8753 ", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2014}, {"title": "A Bayesian Approach to Binocular Stereopsis", "author": ["P.N. Belhumeur"], "venue": "International Journal of Computer Vision 19 ", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1996}, {"title": "Statistical model of color and disparity with application to Bayesian stereopsis", "author": ["C.C. Su", "A.C. Bovik", "L.K. Cormack"], "venue": "Proceedings of the IEEE Southwest Symposium on Image Analysis and Interpretation ", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2012}, {"title": "Bayesian Occupancy Filtering for Multitarget Tracking: An Automotive Application", "author": ["C. Coue", "C. Pradalier", "C. Laugier", "T. Fraichard", "P. Bessiere"], "venue": "The International Journal of Robotics Research 25 ", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2006}, {"title": "Probabilistic Robotics", "author": ["S. Thrun", "W. Burgard", "D. Fox"], "venue": "MIT Press", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2005}, {"title": "Programmation Bay\u00e9sienne des Robots", "author": ["O. Lebeltel"], "venue": "Ph.D. thesis, Universit\u00e9 de Grenoble", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2006}, {"title": "Probabilistic Reasoning and Decision Making in Sensory-Motor Systems", "author": ["P. Bessi\u00e8re", "C. Laugier", "R. Siegwart"], "venue": "volume 46 of Springer Tracts in Advanced Robotics, Springer Berlin Heidelberg, Berlin, Heidelberg", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2008}, {"title": "Brief Survey on Computational Solutions for Bayesian Inference", "author": ["J.D. Alves", "J.F. Ferreira", "J. Lobo", "J. Dias"], "venue": "in: Workshop on Unconventional computing for Bayesian inference at IROS2015, Hamburg", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2015}, {"title": "Probabilistic logics and the synthesis of reliable organisms from unreliable components, 1956", "author": ["J. Von Neumann"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1956}, {"title": "Stochastic computing systems", "author": ["B. Gaines"], "venue": "Advances in information systems science ", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1969}, {"title": "Analog Logic : Continuous-Time Analog Circuits for Statistical Signal Processing", "author": ["B. Vigoda"], "venue": "Ph.D. thesis, Massachusetts Institute of Technology", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2003}, {"title": "Natively Probabilistic Computation", "author": ["V. Mansinghka"], "venue": "Ph.D. thesis, Massachusetts Institute of Technology", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2009}, {"title": "M", "author": ["E. Jonas", "J.B. Tenenbaum"], "venue": "a. Wilson, Stochastic Architectures for Probabilistic Computation by, Ph.D. thesis, Massachssets Institute of Technology", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2014}, {"title": "Self-Similar Magneto-Electric Nanocircuit Technology for Probabilistic Inference Engines", "author": ["S. Khasanvis", "M. Li", "M. Rahman", "M. Salehi-Fashami", "A.K. Biswas", "J. Atulasimha", "S. Bandyopadhyay", "C.A. Moritz"], "venue": "IEEE Transactions on Nanotechnology 14 ", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2015}, {"title": "Fast Exact Bayesian Inference for High-Dimensional Models", "author": ["J.F. Ferreira", "P. Lanillos", "J. Dias"], "venue": "in: Workshop on Unconventional computing for Bayesian inference (UCBI), IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2015}, {"title": "A", "author": ["C.S. Thakur", "S. Afshar", "R.M. Wang", "T.J. Hamilton", "J. Tapson"], "venue": "van Schaik, Bayesian Estimation and Inference using Stochastic Hardware, Frontiers in Neuroscience 10 ", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2016}, {"title": "Bayesian Inference With Muller C-Elements", "author": ["J.S. Friedman", "L.E. Calvet", "P. Bessiere", "J. Droulez", "D. Querlioz"], "venue": "IEEE Transactions on Circuits and Systems I: Regular Papers In Press ", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2016}, {"title": "Stochastic Bayesian Computation for Autonomous Robot Sensorimotor Systems", "author": ["M. Faix", "J. Lobo", "R. Laurent", "D. Vaufreydaz", "E. Mazer"], "venue": "in: Proceedings of the IROS2015 workshop on Unconventional computing for Bayesian inference", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2015}, {"title": "Matching images by comparing their gradient fields", "author": ["D. Scharstein"], "venue": "Proceedings of 12th International Conference on Pattern Recognition 1 ", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1994}, {"title": "A Computational framework for determining stereo correspondence from a set of linear spatial filters", "author": ["D.G. Jones", "J. Malik"], "venue": "Image and Vision Computing 10 ", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1992}, {"title": "Computing the Stereo Matching Cost with a Convolutional Neural Network", "author": ["J. \u017dbontar", "Y. LeCun"], "venue": "arXiv preprint arXiv:1409.4326 ", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2014}, {"title": "A Large Dataset to Train Convolutional Networks for Disparity", "author": ["N. Mayer", "E. Ilg", "P. H\u00e4usser", "P. Fischer", "D. Cremers", "A. Dosovitskiy", "T. Brox"], "venue": "Optical Flow, and Scene Flow Estimation, Technical Report, arXiv preprint 1512.02134", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2015}, {"title": "Bayesian Programming", "author": ["P. Bessi\u00e8re", "J.-M. Ahuactzin", "K. Mekhnacha", "E. Mazer"], "venue": "Chapman and Hall/CRC", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2013}, {"title": "Spin torque nanodevices for bio-inspired computing", "author": ["N. Locatelli", "A. Mizrahi", "A. Accioly", "D. Querlioz", "J.-V. Kim", "V. Cros", "J. Grollier"], "venue": "in: 2014 14th International Workshop on Cellular Nanoscale Networks and their Applications (CNNA), volume 1, IEEE", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2014}, {"title": "Spintronic Devices as Key Elements for Energy-Efficient Neuroinspired Architectures", "author": ["N. Locatelli", "A.F. Vincent", "A. Mizrahi", "J.S. Friedman", "D. Vodenicarevic", "J.-V. Kim", "J.-O. Klein", "W. Zhao", "J. Grollier", "D. Querlioz"], "venue": "Proceedings of the 2015 Design, Automation & Test in Europe Conference & Exhibition 1 ", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2015}, {"title": "Review of IEF\u2019s work - Modelling of superparamagnetic MTJs", "author": ["D. Querlioz"], "venue": "in: BAMBI-FET second year annual meeting, Paris", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2016}, {"title": "Bayesian Sensor Fusion with Fast and Low Power Stochastic 23  Circuits", "author": ["A. Coninx", "R. Laurent", "M.A. Aslam", "P. Bessi\u00e8re", "J. Lobo", "E. Mazer", "J. Droulez"], "venue": "in: Proceedings of the first IEEE International Conference on Rebooting Computing (ICRC) [In press], IEEE Computer Society, San Diego, CA", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2016}, {"title": "Using Occupancy Grids for Mobile Robot Perception and Navigation", "author": ["A. Elfes"], "venue": "IEEE Computer 22 ", "citeRegEx": "32", "shortCiteRegEx": null, "year": 1989}, {"title": "Learning occupancy grid maps with forward sensor models", "author": ["S. Thrun"], "venue": "Autonomous Robots 15 ", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2003}], "referenceMentions": [{"referenceID": 0, "context": "Using two cameras in a stereoscopic setup to reconstruct the tridimensional geometry of a visual scene, in a way similar to that performed by human stereopsis, is an important issue in computer vision, with major applications to autonomous robotics (and more specifically autonomous driving [1]).", "startOffset": 291, "endOffset": 294}, {"referenceID": 1, "context": "That issue has been an active research topic since at least 40 years, and a wide range of methods and algorithms have been proposed [2, 3] and evaluated on standardized benchmarks [4, 5].", "startOffset": 132, "endOffset": 138}, {"referenceID": 2, "context": "That issue has been an active research topic since at least 40 years, and a wide range of methods and algorithms have been proposed [2, 3] and evaluated on standardized benchmarks [4, 5].", "startOffset": 132, "endOffset": 138}, {"referenceID": 3, "context": "That issue has been an active research topic since at least 40 years, and a wide range of methods and algorithms have been proposed [2, 3] and evaluated on standardized benchmarks [4, 5].", "startOffset": 180, "endOffset": 186}, {"referenceID": 4, "context": "That issue has been an active research topic since at least 40 years, and a wide range of methods and algorithms have been proposed [2, 3] and evaluated on standardized benchmarks [4, 5].", "startOffset": 180, "endOffset": 186}, {"referenceID": 5, "context": "Several works have shown that the binocular disparity computation can efficiently be formulated as a Bayesian inference problem [6, 7].", "startOffset": 128, "endOffset": 134}, {"referenceID": 6, "context": "Several works have shown that the binocular disparity computation can efficiently be formulated as a Bayesian inference problem [6, 7].", "startOffset": 128, "endOffset": 134}, {"referenceID": 7, "context": "Such probabilistic representations can also directly be used by Bayesian mapping and navigation methods such as the Bayesian occupation filter [8], and more generally by probabilistic and Bayesian robotics techniques [9, 10, 11].", "startOffset": 143, "endOffset": 146}, {"referenceID": 8, "context": "Such probabilistic representations can also directly be used by Bayesian mapping and navigation methods such as the Bayesian occupation filter [8], and more generally by probabilistic and Bayesian robotics techniques [9, 10, 11].", "startOffset": 217, "endOffset": 228}, {"referenceID": 9, "context": "Such probabilistic representations can also directly be used by Bayesian mapping and navigation methods such as the Bayesian occupation filter [8], and more generally by probabilistic and Bayesian robotics techniques [9, 10, 11].", "startOffset": 217, "endOffset": 228}, {"referenceID": 10, "context": "Such probabilistic representations can also directly be used by Bayesian mapping and navigation methods such as the Bayesian occupation filter [8], and more generally by probabilistic and Bayesian robotics techniques [9, 10, 11].", "startOffset": 217, "endOffset": 228}, {"referenceID": 11, "context": "More specifically, the BAMBI project is a research effort to develop stochastic machines implementing Bayesian inference (Bayesian machines) [12].", "startOffset": 141, "endOffset": 145}, {"referenceID": 12, "context": "The general idea of stochastic computations with temporal coding can be traced back to the seminal works of Von Neumann [13] and Gaines [14] who highlighted the interest of such data representations, but their approaches were not widely pursued due to the rapid development of more efficient deterministic computers.", "startOffset": 120, "endOffset": 124}, {"referenceID": 13, "context": "The general idea of stochastic computations with temporal coding can be traced back to the seminal works of Von Neumann [13] and Gaines [14] who highlighted the interest of such data representations, but their approaches were not widely pursued due to the rapid development of more efficient deterministic computers.", "startOffset": 136, "endOffset": 140}, {"referenceID": 14, "context": "The idea of developing hardware dedicated to bayesian reasoning has recently been pursued by several teams [15, 16, 17], exploring different computational paradigms to perform probabilistic inference.", "startOffset": 107, "endOffset": 119}, {"referenceID": 15, "context": "The idea of developing hardware dedicated to bayesian reasoning has recently been pursued by several teams [15, 16, 17], exploring different computational paradigms to perform probabilistic inference.", "startOffset": 107, "endOffset": 119}, {"referenceID": 16, "context": "The idea of developing hardware dedicated to bayesian reasoning has recently been pursued by several teams [15, 16, 17], exploring different computational paradigms to perform probabilistic inference.", "startOffset": 107, "endOffset": 119}, {"referenceID": 15, "context": "To address the problem of approximate inference Mansinghka [16] uses sampling methods for approximate inference and in a similar way, Jonas designed Markov Chain Monte Carlo based algorithms to provide a representation of probability distributions as sets of samplers [17].", "startOffset": 59, "endOffset": 63}, {"referenceID": 16, "context": "To address the problem of approximate inference Mansinghka [16] uses sampling methods for approximate inference and in a similar way, Jonas designed Markov Chain Monte Carlo based algorithms to provide a representation of probability distributions as sets of samplers [17].", "startOffset": 268, "endOffset": 272}, {"referenceID": 14, "context": "Vigoda [15] designed architectures based on probabilities represented by analog signals, and used the message passing algorithm to compute exact inference.", "startOffset": 7, "endOffset": 11}, {"referenceID": 17, "context": "More recently, a research project conducted at the Nanoscale Computing Fabrics Laboratory has led to the design of an unconventional hardware architecture based on electro-magnetic computations to perform inference on Bayesian Network models [18].", "startOffset": 242, "endOffset": 246}, {"referenceID": 18, "context": "[19] also showed that exact inference can be efficiently computed using GPU hardware for some high-dimensional problems.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[20] is quite similar to ours: they use stochastic bitstreams and target special inference problems.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "In the framework of the BAMBI project, another stochastic architecture has been proposed to perform naive Bayesian fusion using Muller C-Elements [21], which achieves exact inference with normalization for binary random variables, but create harmful correlations in the stochastic signals and can\u2019t be easily extended to non-binary discrete distributions.", "startOffset": 146, "endOffset": 150}, {"referenceID": 21, "context": "Other recent work conducted within the BAMBI project have proposed using digital signals with temporal coding to perform Bayesian inference, and a proof-of-concept to solve a simple sensorimotor problem has been put forward [22].", "startOffset": 224, "endOffset": 228}, {"referenceID": 1, "context": "been summarized in reviews [2, 3], which show that most methods follow the same general structure which can be divided in three steps:", "startOffset": 27, "endOffset": 33}, {"referenceID": 2, "context": "been summarized in reviews [2, 3], which show that most methods follow the same general structure which can be divided in three steps:", "startOffset": 27, "endOffset": 33}, {"referenceID": 1, "context": "The most common matching cost is the squared difference of pixel values [2], but some other techniques preprocess the image with operators such as the gradient [23] or use banks of linear spatial filters [24].", "startOffset": 72, "endOffset": 75}, {"referenceID": 22, "context": "The most common matching cost is the squared difference of pixel values [2], but some other techniques preprocess the image with operators such as the gradient [23] or use banks of linear spatial filters [24].", "startOffset": 160, "endOffset": 164}, {"referenceID": 23, "context": "The most common matching cost is the squared difference of pixel values [2], but some other techniques preprocess the image with operators such as the gradient [23] or use banks of linear spatial filters [24].", "startOffset": 204, "endOffset": 208}, {"referenceID": 5, "context": "[6]), using techniques such as dynamic programming, in which cases it can complement or replace cost aggregation.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "Several of the existing works [6, 7] use the Bayesian inference framework to describe this process.", "startOffset": 30, "endOffset": 36}, {"referenceID": 6, "context": "Several of the existing works [6, 7] use the Bayesian inference framework to describe this process.", "startOffset": 30, "endOffset": 36}, {"referenceID": 5, "context": "For example, Belhumeur [6] proposes to reconstruct the scene geometry S from the left and right images Il and Ir using a Bayesian model:", "startOffset": 23, "endOffset": 26}, {"referenceID": 3, "context": "The development of public image pairs datasets provided with a disparity baseline such as the KITTI dataset [4] or the Middlebury dataset [5] have made it possible to treat disparity computation as a supervised machine learning problem.", "startOffset": 108, "endOffset": 111}, {"referenceID": 4, "context": "The development of public image pairs datasets provided with a disparity baseline such as the KITTI dataset [4] or the Middlebury dataset [5] have made it possible to treat disparity computation as a supervised machine learning problem.", "startOffset": 138, "endOffset": 141}, {"referenceID": 24, "context": "Some algorithms use deep convolutional networks to learn the matching cost [25, 26], and perform cost aggregation and optimization using other techniques.", "startOffset": 75, "endOffset": 83}, {"referenceID": 25, "context": "Some algorithms use deep convolutional networks to learn the matching cost [25, 26], and perform cost aggregation and optimization using other techniques.", "startOffset": 75, "endOffset": 83}, {"referenceID": 16, "context": "[17] as an application of his aforementioned hardware architecture for approximate inference.", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "If the optimization is performed on the whole image or on entire rows or columns (as is the case in [6]) the problem becomes completely intractable, but even smaller integration neighborhoods are problematic.", "startOffset": 100, "endOffset": 103}, {"referenceID": 23, "context": "Other algorithms have used such convolution filters for disparity computation [24], although they process the feature information from those filter in a different way.", "startOffset": 78, "endOffset": 82}, {"referenceID": 24, "context": "The relevance of using such linear spatial filters as a preprocessing step is also highlighted by recent works using deep neural networks to compute disparity [25, 26], which use a convolutional layer (with filters trained through supervised learning) as their input.", "startOffset": 159, "endOffset": 167}, {"referenceID": 25, "context": "The relevance of using such linear spatial filters as a preprocessing step is also highlighted by recent works using deep neural networks to compute disparity [25, 26], which use a convolutional layer (with filters trained through supervised learning) as their input.", "startOffset": 159, "endOffset": 167}, {"referenceID": 5, "context": "Those costs are used to compute probabilistic likelihood functions similar to those used by Belhumeur [6], and those likelihood terms are then combined using naive Bayesian fusion.", "startOffset": 102, "endOffset": 105}, {"referenceID": 21, "context": "Previous work [22] has shown that naive Bayesian fusion could be performed by stochastic machines.", "startOffset": 14, "endOffset": 18}, {"referenceID": 26, "context": "One of the most common Bayesian computing techniques is naive Bayesian fusion [27] : computing the posterior probability distribution on a searched variable S, knowing a prior distribution P (S) and the conditional distributions P (Ki|S) on some known variables K1, .", "startOffset": 78, "endOffset": 82}, {"referenceID": 27, "context": "But recent advances in new nanodevices based on spintronics, such as the superparamagnetic tunnel junction (SMTJ) [28, 29], bear the promise that such generators could be available in the short or medium term.", "startOffset": 114, "endOffset": 122}, {"referenceID": 28, "context": "But recent advances in new nanodevices based on spintronics, such as the superparamagnetic tunnel junction (SMTJ) [28, 29], bear the promise that such generators could be available in the short or medium term.", "startOffset": 114, "endOffset": 122}, {"referenceID": 29, "context": "Those components can be built with CMOS technology using an area equivalent to 12 bytes of SRAM [30], making them suitable to large scale integration with the other components needed to build the stochastic machines described above.", "startOffset": 96, "endOffset": 100}, {"referenceID": 30, "context": "A partial implementation of our Bayesian Machine infrastructure using FPGA systems has been demonstrated [31], and further research will also integrate the technology developed by teams working on stochastic signal generator devices.", "startOffset": 105, "endOffset": 109}, {"referenceID": 31, "context": "Efforts will also be dedicated to extending the breadth of the computations implemented by stochastic bitstream based systems, combining the disparity computation to other sensory computations (such as optical flow) to create an occupancy map, using and extending existing Bayesian spatial cognition algorithms [32, 33, 8] which could then be used for obstacle avoidance and robot navigation, paving the way to a completely stochastic robot sensorimotor controller.", "startOffset": 311, "endOffset": 322}, {"referenceID": 32, "context": "Efforts will also be dedicated to extending the breadth of the computations implemented by stochastic bitstream based systems, combining the disparity computation to other sensory computations (such as optical flow) to create an occupancy map, using and extending existing Bayesian spatial cognition algorithms [32, 33, 8] which could then be used for obstacle avoidance and robot navigation, paving the way to a completely stochastic robot sensorimotor controller.", "startOffset": 311, "endOffset": 322}, {"referenceID": 7, "context": "Efforts will also be dedicated to extending the breadth of the computations implemented by stochastic bitstream based systems, combining the disparity computation to other sensory computations (such as optical flow) to create an occupancy map, using and extending existing Bayesian spatial cognition algorithms [32, 33, 8] which could then be used for obstacle avoidance and robot navigation, paving the way to a completely stochastic robot sensorimotor controller.", "startOffset": 311, "endOffset": 322}], "year": 2016, "abstractText": "Reconstruction of the tridimensional geometry of a visual scene using the binocular disparity information is an important issue in computer vision and mobile robotics, which can be formulated as a Bayesian inference problem. However, computation of the full disparity distribution with an advanced Bayesian model is usually an intractable problem, and proves computationally challenging even with a simple model. In this paper, we show how probabilistic hardware using distributed memory and alternate representation of data as stochastic bitstreams can solve that problem with high performance and energy efficiency. We put forward a way to express discrete probability distributions using stochastic data representations and perform Bayesian fusion using those representations, and show how that approach can be applied to diparity computation. We evaluate the system using a simulated stochastic implementation and discuss possible hardware implementations of such architectures and their potential for sensorimotor processing and robotics.", "creator": "LaTeX with hyperref package"}}}