{"id": "1609.04909", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Sep-2016", "title": "An Iterative Transfer Learning Based Ensemble Technique for Automatic Short Answer Grading", "abstract": "Automatic short answer grading (ASAG) techniques are designed to automatically assess short answers to questions in natural language, having a length of a few words to a few sentences. Supervised ASAG techniques have been demonstrated to be effective but suffer from a couple of key practical limitations. They are greatly reliant on instructor provided model answers and need labeled training data in the form of graded student answers for every assessment task. To overcome these, in this paper, we introduce an ASAG technique with two novel features. We propose an iterative technique on an ensemble of (a) a text classifier of student answers and (b) a classifier using numeric features derived from various similarity measures with respect to model answers. Second, we employ canonical correlation analysis based transfer learning on a common feature representation to build the classifier ensemble for questions having no labelled data. The proposed technique handsomely beats all winning supervised entries on the SCIENTSBANK dataset from the Student Response Analysis task of SemEval 2013. Additionally, we demonstrate generalizability and benefits of the proposed technique through evaluation on multiple ASAG datasets from different subject topics and standards.", "histories": [["v1", "Fri, 16 Sep 2016 04:58:54 GMT  (2515kb,D)", "https://arxiv.org/abs/1609.04909v1", null], ["v2", "Mon, 19 Sep 2016 01:28:17 GMT  (2510kb,D)", "http://arxiv.org/abs/1609.04909v2", null], ["v3", "Mon, 21 Nov 2016 13:44:09 GMT  (1442kb,D)", "http://arxiv.org/abs/1609.04909v3", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["shourya roy", "himanshu s bhatt", "y narahari"], "accepted": false, "id": "1609.04909"}, "pdf": {"name": "1609.04909.pdf", "metadata": {"source": "CRF", "title": "An Iterative Transfer Learning Based Ensemble Technique for Automatic Short Answer Grading", "authors": ["Shourya Roy", "Himanshu S. Bhatt"], "emails": ["shourya.roy@xerox.com", "himanshu.bhatt@xerox.com", "hari@csa.iisc.ernet.in"], "sections": [{"heading": null, "text": "This year, more than ever before in the history of the country in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a city and in which it is a country, in which it is a city and in which it is a country, in which it is a city and in which it is a country."}, {"heading": "II. PRIOR ART", "text": "Two recent surveys by Burrows et. al. [3] and Roy et. al. [15] provide comprehensive insights into past research at ASAG. In this section we discuss relevant topics for our technology, i.e. supervised ASAG, transfer learning and transfer learning for ASAG."}, {"heading": "A. Supervised ASAG", "text": "Most previous work in supervised ASAG systems was based on the approach of designing novel tasks and datasets of specific features for feeding into standard classification and regression algorithms. Sukkarieh used features based on lexical constructs such as the presence / absence of concepts, although the order in which concepts appear, etc. [16], [17]; CAM (Content Assessment Module) used types of overlaps, including word unigrams and n-grams, 1quoting from a recent survey paper [3], [Finally, regarding the effectiveness of the results in Table 7,] the meaningful comparisons that can be made are limited as the majority of the assessments were performed in a bubble. The datasets common between two or more publications are relatively rare. \"noun-phrase chunks, portions of the speech [18]; Madnani measurement systems are applied to individual measurement machines (often used as a BLUGE)."}, {"heading": "B. Transfer Learning", "text": "Much of the specialized literature on domain adaptation deals with techniques based on the representation of common features [9], [10], [28]. The intuitive idea behind most of these techniques is to learn a transformed attribute space in which source and target domain instances follow a similar distribution. Consequently, a standard supervised learning algorithm can be trained on the former (projected source domain instances) to predict the latter (projected target domain instances). Structural correspondence learning (SCL) [9], one of the most commonly used techniques, aims to learn the coexistence between traits that express similar meaning in different domains. In 2008, Pan et. al. [29] proposed a method for reducing dimensionality, maximum Mean Discrepancy Embedding, to identify a common latent space."}, {"heading": "C. Transfer Learning and ASAG", "text": "Heilman and Madnani discussed the use of domain adjustments for ASAG [12], using the technique of [10] to support generalization across questions and domains, retaining multiple copies with potentially different weight for each feature: a generic copy, a domain-specific copy, and an item-specific copy. To answer a new question, only the generic features become active, but for answers to questions in the training data, all copies of the feature would be active and contribute to the score. Apparently, for their submission to the SRA challenge, they used function copies only for a subset of features. Phandi et. al. proposed a novel domain adjustment technique that uses Bajesian linear ridge regression 4We to render learning and domain adjustments interchangeable in this paper, ignoring subtle but irrelevant differences."}, {"heading": "III. OUR APPROACH", "text": "In this section, we will explain the proposed technique in an intuitive way before formally describing the same in the next step. Following the transfer of learning terminology, we will refer to the questions for which graded answers are available as source questions and questions for which no graded answers are available as target questions. Philosophy of our algorithm is the gradual transfer of knowledge from a source to a target question, while we use a group of two classifiers to predict student outcomes. The first classifier is a text classifier based on a common common representation: We model ASAG as an overarching learning task in which we use a group of two classifiers to predict student outcomes. In the ensemble, the first classifier is a model of student responses trained on a bag of words (BoW). It is trained on the corpus of student responses and does not require a model response. The second classifier is based on the similarity of student responses."}, {"heading": "B. The Technique", "text": "This year we have it in our hands, as we have experienced it in the past, \"he told the Deutsche Presse-Agentur in an interview with\" Welt am Sonntag \":\" It is not as if we have been able to change the world, as if we have been able to change the world. \"(S. S. S. S. S. S. S. S. S. S. S. S. S. S. S.), S. S. S. S. S. S. S. S. S. (S. S. S.), S. S. S. S. S. (S. S. S.), S. S. S. S. (S.), S. S. S. (S.), S. S. (S.), S. (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.) (S.). (S.). (S.). (S.). (S.). (S.) (S.). (S.). (S.). (S.). (S.). (S.) (S.). (S.). (S.). (S.). (S. (S.). (S.). (S. (S.). (S.). (S. (S.). (S.) (S.). (S. (S.). (S. (S.). (S.). (S. (S.). (S. (S. (S.) (S.). (S. (S.) (S. (S.) (S. (S.). (S.). (S.) (S. (S. (S.) (S. (S. (S.). (S. (S.) (S. (S. (S.). (S.) (S. (S.) (S. (. (S.) (S.) (S. (S.). (. (. (S.). (. (.) (. (. (. (. (. (.) (.) (. (.) ("}, {"heading": "IV. EXPERIMENTAL EVALUATION", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Datasets", "text": "In fact, the recent survey results in Section II ([3], [15]) have highlighted the need for the exchange of datasets and structured assessments of techniques in multiple datasets, which are part of the Student Response Analysis (SRA) in the Semantic Evaluation (SemEval) in the 2013 workshops as well as the Standards (High School and College).SE2013 These datasets are part of the Student Response Analysis (SRA) in the Semantic Evaluation (SemEvaluation) in the workshops of 2013."}, {"heading": "B. Performance Metrics", "text": "Most ASAG datasets (in our case CSD, X-CSD and RCD) have ordinal class markers, so we used the mean absolute error (MAE) for quantitative evaluation. MAE for a question is the absolute difference between the basic truth and the predicted values averaged across all students. The SE2013 dataset has nominal class markers. If you follow the evaluation yardsticks used in the SRA task, ti and yi are the basic truths and predicted values of the student's answer. In order to report the overall performance of a dataset, MAE values are averaged for all questions. Following the evaluation yardsticks used in the SRA task, we report on two confusion matrix-based evaluation metrics, namely the macro averages F1 (= 1 / Nc).u The average class is included."}, {"heading": "C. Quantitative Results", "text": "This year, it is more than ever before in the history of the city, where it has gone down in history as never before."}, {"heading": "V. CONCLUSION", "text": "In this paper, we presented a novel ASAG technique based on an ensemble of texts and a numerical classifier of complementary nature, which used a canonical correlation analysis-based transfer learning technique to set in motion an iterative algorithm to obtain the overall ensemble for target questions without requiring labeled data. We demonstrated the effectiveness of the proposed technique by empirically evaluating several sets of data from different disciplines and standards. In the future, we intend to conduct studies comparing different techniques of feature representation with the state of the art in the supervised ASAG. Furthermore, it will be interesting to compare in-depth learning techniques with heavy feature engineering-based approaches prevailing in this work. Another interesting question that arose is that certain types of questions may be easier to transfer recipients than others. If so, how do we then characterize those based on questions and model answers? Finally, through this work, we have introduced the ASAG's Applicant Learning Potential to a new direction."}], "references": [{"title": "A review of computer-assisted assessment", "author": ["G. Conole", "B. Warburton"], "venue": "Research in learning technology, vol. 13, no. 1, 2005.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2005}, {"title": "A Review of Automatically Scorable Constructed-response Item Types for Large-scale Assessment", "author": ["M.E. Martinez", "R.E. Bennett"], "venue": "ETS Research Report Series, vol. 1992, no. 2, pp. i\u201334, 1992.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1992}, {"title": "The Eras and Trends of Automatic Short Answer Grading", "author": ["S. Burrows", "I. Gurevych", "B. Stein"], "venue": "International Journal of Artificial Intelligence in Education, vol. 25, no. 1, pp. 60\u2013117, 2015.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}, {"title": "Text-to-text semantic similarity for automatic short answer grading", "author": ["M. Mohler", "R. Mihalcea"], "venue": "Proceedings of the Conference of the European Chapter of the Association for Computational Linguistics (EACL), 2009, pp. 567\u2013575.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2009}, {"title": "Effective Tutorial Feedback for Explanation Questions: A Dataset and Baselines.", "author": ["M. Dzikovska", "R.D. Nielsen", "C. Brew", "\u201cTowards"], "venue": "Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT),", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2012}, {"title": "Term-weighting Approaches in Automatic Text Retrieval", "author": ["G. Salton", "C. Buckley"], "venue": "Information Processing and Management, vol. 24, no. 5, pp. 513\u2013523, 1988.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1988}, {"title": "Effective Feature Integration for Automated Short Answer Scoring", "author": ["K. Sakaguchi", "M. Heilman", "N. Madnani"], "venue": "Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL- HLT), 2015, pp. 1049\u20131054.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2015}, {"title": "A survey on transfer learning", "author": ["S.J. Pan", "Q. Yang"], "venue": "IEEE Transactions on Knowledge and Data Engineering, vol. 22, no. 10, pp. 1345\u2013 1359, 2010.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2010}, {"title": "Domain Adaptation with Structural Correspondence Learning", "author": ["J. Blitzer", "R. McDonald", "F. Pereira"], "venue": "Proceedings of Conference on Empirical Methods in Natural Language Processing (EMNLP), 2006, pp. 120\u2013128.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2006}, {"title": "Frustratingly Easy Domain Adaptation", "author": ["III H. Daum\u00e9"], "venue": "arXiv preprint arXiv:0907.1815. [Online]. Available: https://arxiv.org/abs/0907.1815", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1815}, {"title": "An Iterative Similarity based Adaptation Technique for Cross-domain Text Classification.", "author": ["H.S. Bhatt", "D. Semwal", "S. Roy"], "venue": "Proceedings of the Conference of Natural Language and Learning (CoNLL),", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2015}, {"title": "ETS: Domain Adaptation and Stacking for Short Answer Scoring", "author": ["M. Heilman", "N. Madnani"], "venue": "Proceedings of the 2nd joint conference on lexical and computational semantics, vol. 2, 2013, pp. 275\u2013279.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2013}, {"title": "SemEval-2013 task 7: The Joint Student Response Analysis and 8th Recognizing Textual Entailment Challenge", "author": ["M.O. Dzikovska", "R.D. Nielsen", "C. Brew", "C. Leacock", "D. Giampiccolo", "L. Bentivogli", "P. Clark", "I. Dagan", "H.T. Dang"], "venue": "DTIC Document, Tech. Rep., 2013.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2013}, {"title": "Learning to Grade Short Answer Questions using Semantic Similarity Measures and Dependency Graph Alignments.", "author": ["M. Mohler", "R.C. Bunescu", "R. Mihalcea"], "venue": "Proceedings of the Conference of the Association for Computational Linguistics (ACL),", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2011}, {"title": "A Perspective on Computer Assisted Assessment Techniques for Short Free-Text Answers", "author": ["S. Roy", "Y. Narahari", "O.D. Deshmukh"], "venue": "Proceedings of the International Conference on Computer Assisted Assessment (CAA). Springer, 2015, pp. 96\u2013109.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2015}, {"title": "Using a MaxEnt Classifier for the Automatic Content Scoring of Free-text Responses", "author": ["J.Z. Sukkarieh", "A. Mohammad-Djafari", "J.-F. o. Bercher", "P. Bessie \u0301 re"], "venue": "Proceedings of the AIP Conference American Institute of Physics, vol. 1305, no. 1, 2011, p. 41.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2011}, {"title": "c-rater: Automatic Content Scoring for Short Constructed Responses.", "author": ["J.Z. Sukkarieh", "J. Blackmore"], "venue": "Proceedings of the International Florida Artificial Intelligence Research Society Conference (FLAIRS),", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2009}, {"title": "Diagnosing Meaning Errors in Short Answers to Reading Comprehension Questions", "author": ["S. Bailey", "D. Meurers"], "venue": "Proceedings of the Third Workshop on Innovative Use of NLP for Building Educational Applications (EANL), 2008, pp. 107\u2013115.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2008}, {"title": "Automated Scoring of a Summary Writing Task Designed to Measure Reading Comprehension", "author": ["N. Madnani", "J. Burstein", "J. Sabatini", "T. O\u2019Reilly"], "venue": "Proceedings of the 8th workshop on innovative use of nlp for building educational applications, 2013, pp. 163\u2013168.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2013}, {"title": "A Taxonomy of Questions for Question Generation", "author": ["R.D. Nielsen", "J. Buckingham", "G. Knoll", "B. Marsh", "L. Palen"], "venue": "Proceedings of the Workshop on the Question Generation Shared Task and Evaluation Challenge, 2008.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2008}, {"title": "Using the text to evaluate short answers for reading comprehension exercises", "author": ["A. Horbach", "A. Palmer", "M. Pinkal"], "venue": "Second Joint Conference on Lexical and Computational Semantics (* SEM), vol. 1, 2013, pp. 286\u2013295.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2013}, {"title": "Automatic Short Answer Marking", "author": ["S.G. Pulman", "J.Z. Sukkarieh"], "venue": "Proceedings of the Second Workshop on Building Educational Applications Using NLP (EdAppsNLP), 2005, pp. 9\u201316.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2005}, {"title": "Information Extraction and Machine Learning: Auto-Marking Short Free Text Responses to Science Questions.", "author": ["J.Z. Sukkarieh", "S.G. Pulman"], "venue": "ser. Frontiers in Artificial Intelligence and Applications (AIED),", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2005}, {"title": "SOFTCARDINALITY: Hierarchical Text Overlap for Student Response Analysis", "author": ["S. Jimenez", "C. Becerra", "A. Gelbukh"], "venue": "Proceedings of the 2nd joint conference on lexical and computational semantics, vol. 2, 2013, pp. 280\u2013284.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2013}, {"title": "Celi: EDITS and Generic Text Pair Classification", "author": ["M. Kouylekov", "L. Dini", "A. Bosca", "M. Trevisan"], "venue": "Proceedings of the 2nd joint conference on lexical and computational semantics, vol. 2, 2013, pp. 592\u2013597.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2013}, {"title": "CoMeT: Integrating Different Levels of Linguistic Modeling for Meaning Assessment", "author": ["N. Ott", "R. Ziai", "M. Hahn", "D. Meurers"], "venue": "Proceedings of the 2nd joint conference on lexical and computational semantics, vol. 2, 2013, pp. 608\u2013616.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2013}, {"title": "UKP-BIU: Similarity and Entailment Metrics for Student Response Analysis", "author": ["T. Zesch", "O. Levy", "I. Gurevych", "I. Dagan"], "venue": "Proceedings of the joint conference on lexical and computational semantics, vol. 2, 2013, pp. 285\u2013289.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2013}, {"title": "Cross-domain Sentiment Classification via Spectral Feature Alignment", "author": ["S.J. Pan", "X. Ni", "J.-T. Sun", "Q. Yang", "Z. Chen"], "venue": "Proceedings of International Conference on World Wide Web, 2010, pp. 751\u2013760.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2010}, {"title": "Transfer Learning via Dimensionality Reduction.", "author": ["S.J. Pan", "J.T. Kwok", "Q. Yang"], "venue": "Proceedings of AAAI Conference on Artificial Intelligence,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2008}, {"title": "Information-theoretic coclustering", "author": ["I.S. Dhillon", "S. Mallela", "D.S. Modha"], "venue": "Proceedings of International Conference on Knowledge Discovery and Data Mining, 2003, pp. 89\u201398.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2003}, {"title": "Boosting for Transfer Learning", "author": ["W. Dai", "Q. Yang", "G.-R. Xue", "Y. Yu"], "venue": "Proceedings of International Conference on Machine Learning (ICML), 2007, pp. 193\u2013200.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2007}, {"title": "Recognizing Actions across Cameras by Exploring the Correlated Subspace", "author": ["C. Huang", "Y. Yeh", "Y.F. Wang"], "venue": "Proceedings of European  Conference on Computer Vision- Workshops and Demonstrations, 2012, pp. 342\u2013351.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2012}, {"title": "Heterogeneous Domain Adaptation and Classification by Exploiting the Correlation Subspace", "author": ["Y. Yeh", "C. Huang", "Y.F. Wang"], "venue": "IEEE Transactions on Image Processing, vol. 23, no. 5, pp. 2009\u20132018, 2014.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2009}, {"title": "Flexible Domain Adaptation for Automated Essay Scoring Using Correlated Linear Regression.", "author": ["P. Phandi", "K.M.A. Chai", "H.T. Ng"], "venue": "Proceedings of the Conference on Empirical Methods on Natural Language Processing (EMNLP),", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2015}, {"title": "Bayesian Supervised Domain Adaptation for Short Text Similarity", "author": ["M.A. Sultan", "J. Boyd-Graber", "T. Sumner"], "venue": "Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL- HLT), 2016.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2016}, {"title": "WordNet: A Lexical Database for English", "author": ["G.A. Miller"], "venue": "Communications of the ACM, vol. 38, no. 11, pp. 39\u201341, 1995.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 1995}, {"title": "Semantic Similarity Based on Corpus Statistics and Lexical Taxonomy", "author": ["J.J. Jiang", "D.W. Conrath"], "venue": "Proceedings of the International Conference on Research in Computational Linguistics, 1997, pp. 19\u201333.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 1997}, {"title": "An Introduction to Latent Semantic Analysis", "author": ["T.K. Landauer", "P.W. Foltz", "D. Laham"], "venue": "Discourse Processes, vol. 25, pp. 259\u2013284, 1998.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 1998}, {"title": "Efficient Estimation of Word Representations in Vector Space", "author": ["T. Mikolov", "K. Chen", "G. Corrado", "J. Dean"], "venue": "arXiv preprint arXiv:1301.3781. [Online]. Available: https://arxiv.org/abs/1301.3781", "citeRegEx": "39", "shortCiteRegEx": null, "year": 1301}, {"title": "Combining labeled and unlabeled data with co-training", "author": ["A. Blum", "T. Mitchell"], "venue": "Proceedings of Conference on Learning Theory, 1998, pp. 92\u2013100.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 1998}, {"title": "Beetle II: A System for Tutoring and Computational Linguistics Experimentation.", "author": ["M.O. Dzikovska", "J.D. Moore", "N.B. Steinhauser", "G.E. Campbell", "E. Farrow", "C.B. Callaway"], "venue": "Proceedings of the Conference of the Association for Computational Linguistics (ACL),", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2010}, {"title": "Annotating Students\u2019 Understanding of Science Concepts", "author": ["R.D. Nielsen", "W. Ward", "J.H. Martin", "M. Palmer"], "venue": "Proceedings of the Sixth International Language Resources and Evaluation (LREC), 2008.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2008}], "referenceMentions": [{"referenceID": 0, "context": "Prior work reported in many papers has questioned the effectiveness of such questions to assess knowledge, scholarship, and depth of understanding gathered by students [1], [2].", "startOffset": 168, "endOffset": 171}, {"referenceID": 1, "context": "Prior work reported in many papers has questioned the effectiveness of such questions to assess knowledge, scholarship, and depth of understanding gathered by students [1], [2].", "startOffset": 173, "endOffset": 176}, {"referenceID": 2, "context": "This paper dwells on a computational technique for automatically grading such answers and particularly focuses on short answers which are a few words to a few sentences long (everything in between fill-in-the-gap and essay type answers [3]).", "startOffset": 236, "endOffset": 239}, {"referenceID": 4, "context": "the raw number of overlapping words, F1 score, Lesk score and cosine score between student and model answers as features [5].", "startOffset": 121, "endOffset": 124}, {"referenceID": 5, "context": "The first classifier is a text classifier trained using the classical TFIDF representation [6] of bag-of-words (BoW) features ar X iv :1 60 9.", "startOffset": 91, "endOffset": 94}, {"referenceID": 3, "context": "TABLE I EXAMPLES OF QUESTIONS, MODEL ANSWERS, AND STUDENT ANSWERS WITH INSTRUCTOR GIVEN SCORES FROM AN UNDERGRADUATE COMPUTER SCIENCE COURSE [4]", "startOffset": 141, "endOffset": 144}, {"referenceID": 6, "context": "While stacking of classifiers has been used in ASAG [7] towards \u201cone-", "startOffset": 52, "endOffset": 55}, {"referenceID": 7, "context": "Two domains, commonly referred to as source (with labeled data; typically aplenty) and target (with less or no labelled data), are said to be different if they have different feature spaces or different marginal probability distributions [8].", "startOffset": 238, "endOffset": 241}, {"referenceID": 8, "context": "In such cases, transfer learning techniques have been shown to be effective (to reduce new labeling efforts) for various tasks such as sentiment classification [9], named entity recognition (NER) [10] and social", "startOffset": 160, "endOffset": 163}, {"referenceID": 9, "context": "In such cases, transfer learning techniques have been shown to be effective (to reduce new labeling efforts) for various tasks such as sentiment classification [9], named entity recognition (NER) [10] and social", "startOffset": 196, "endOffset": 200}, {"referenceID": 10, "context": "media analytics [11].", "startOffset": 16, "endOffset": 20}, {"referenceID": 11, "context": "Surprisingly, we found only one prior work [12] where domain adaptation was used for ASAG based on the technique proposed in [10].", "startOffset": 43, "endOffset": 47}, {"referenceID": 9, "context": "Surprisingly, we found only one prior work [12] where domain adaptation was used for ASAG based on the technique proposed in [10].", "startOffset": 125, "endOffset": 129}, {"referenceID": 11, "context": "We empirically demonstrate superior performance of the proposed method in comparison to [12] on the dataset released by [13] for the joint task of student response analysis in SemEval 2013 Task 7.", "startOffset": 88, "endOffset": 92}, {"referenceID": 12, "context": "We empirically demonstrate superior performance of the proposed method in comparison to [12] on the dataset released by [13] for the joint task of student response analysis in SemEval 2013 Task 7.", "startOffset": 120, "endOffset": 124}, {"referenceID": 13, "context": "quantitative analysis on the dataset collected as a part of an undergraduate computer science course [14] towards bringing out insights on why and when transfer learning in ASAG produces superior performance.", "startOffset": 101, "endOffset": 105}, {"referenceID": 2, "context": "[3]", "startOffset": 0, "endOffset": 3}, {"referenceID": 14, "context": "[15] provide comprehensive views of prior research in ASAG.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[16], [17]; CAM (Content Assessment Module) used types of overlap including word unigrams and n-grams,", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[16], [17]; CAM (Content Assessment Module) used types of overlap including word unigrams and n-grams,", "startOffset": 6, "endOffset": 10}, {"referenceID": 2, "context": "1Quoting from a recent survey paper [3], \u201c[Finally, concerning the effectiveness scores in Table 7,] the meaningful comparisons that can be performed are limited, as the majority of evaluations have been performed in a bubble.", "startOffset": 36, "endOffset": 39}, {"referenceID": 17, "context": "\u201d noun-phrase chunks, parts of speech [18]; Madnani et.", "startOffset": 38, "endOffset": 42}, {"referenceID": 18, "context": "applied BLEU score (commonly used for evaluating machine translation systems), ROUGE (a recall based metric that measures the lexical and phrasal overlap between two pieces of text) for summary assessment [19] and Nielsen et.", "startOffset": 205, "endOffset": 209}, {"referenceID": 19, "context": "used carefully crafted lexical and syntactic features [20].", "startOffset": 54, "endOffset": 58}, {"referenceID": 20, "context": "demonstrated an interesting variation for assessment of reading comprehension questions where they used the original reading text as a feature [21].", "startOffset": 143, "endOffset": 147}, {"referenceID": 21, "context": "and annotated answers [22], [23].", "startOffset": 22, "endOffset": 26}, {"referenceID": 22, "context": "and annotated answers [22], [23].", "startOffset": 28, "endOffset": 32}, {"referenceID": 12, "context": "[13] floated a task, \u201cStudent Response Analysis\u201d (SRA) in the Semantic Evaluation (SemEval) workshop in 2013, where participating teams had to categorize student answers into 2-,3- and 5-way categorization.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "discussed and compared submissions from 9 participating teams [13].", "startOffset": 62, "endOffset": 66}, {"referenceID": 23, "context": "The trend of feature design continued with most submissions [24],", "startOffset": 60, "endOffset": 64}, {"referenceID": 24, "context": "[25] employing various text similarity based features which were heavily tuned towards the dataset (with more emphasis on winning the task and less on generalizability).", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "Multiple participants [12], [26], [27] used some form of \u201cone-shot\u201d system combination approach, with several components feeding into a final decision made by a stacked classifier.", "startOffset": 22, "endOffset": 26}, {"referenceID": 25, "context": "Multiple participants [12], [26], [27] used some form of \u201cone-shot\u201d system combination approach, with several components feeding into a final decision made by a stacked classifier.", "startOffset": 28, "endOffset": 32}, {"referenceID": 26, "context": "Multiple participants [12], [26], [27] used some form of \u201cone-shot\u201d system combination approach, with several components feeding into a final decision made by a stacked classifier.", "startOffset": 34, "endOffset": 38}, {"referenceID": 6, "context": "built on their submission and employed the idea of stacking on a reading comprehension dataset [7].", "startOffset": 95, "endOffset": 98}, {"referenceID": 2, "context": "both the recent survey papers [3], [15] who have independently emphasized the importance of sharing of data and ushered in the era of evolution in ASAG.", "startOffset": 30, "endOffset": 33}, {"referenceID": 14, "context": "both the recent survey papers [3], [15] who have independently emphasized the importance of sharing of data and ushered in the era of evolution in ASAG.", "startOffset": 35, "endOffset": 39}, {"referenceID": 3, "context": "textual representation (along the lines of unsupervised ASAG pioneered by [4]).", "startOffset": 74, "endOffset": 77}, {"referenceID": 7, "context": "Transfer learning [8] in text analysis (a.", "startOffset": 18, "endOffset": 21}, {"referenceID": 8, "context": "body of domain adaptation literature are around techniques which are based on learning common feature representation [9], [10], [28].", "startOffset": 117, "endOffset": 120}, {"referenceID": 9, "context": "body of domain adaptation literature are around techniques which are based on learning common feature representation [9], [10], [28].", "startOffset": 122, "endOffset": 126}, {"referenceID": 27, "context": "body of domain adaptation literature are around techniques which are based on learning common feature representation [9], [10], [28].", "startOffset": 128, "endOffset": 132}, {"referenceID": 8, "context": "Structural Correspondence Learning (SCL) [9], being one of the most widely used techniques, aims to learn the co-occurrence between features expressing similar meaning in different domains.", "startOffset": 41, "endOffset": 44}, {"referenceID": 28, "context": "[29]", "startOffset": 0, "endOffset": 4}, {"referenceID": 29, "context": "A similar approach, based on co-clustering [30] was proposed by Dai et al.", "startOffset": 43, "endOffset": 47}, {"referenceID": 30, "context": "[31] to leverage common words as bridge between two domains.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "Daum\u00e9 [10] proposed a heuristic based non-", "startOffset": 6, "endOffset": 10}, {"referenceID": 31, "context": "In this work, we used a classical feature mapping technique, canonical correlation analysis [32], [33], towards learning a joint subspace where both the source and target domains features are mapped to have maximum correlation.", "startOffset": 92, "endOffset": 96}, {"referenceID": 32, "context": "In this work, we used a classical feature mapping technique, canonical correlation analysis [32], [33], towards learning a joint subspace where both the source and target domains features are mapped to have maximum correlation.", "startOffset": 98, "endOffset": 102}, {"referenceID": 11, "context": "Heilman and Madnani discussed about the use of domain adaptation for ASAG [12] by applying the technique from [10] to support generalization across questions and domains.", "startOffset": 74, "endOffset": 78}, {"referenceID": 9, "context": "Heilman and Madnani discussed about the use of domain adaptation for ASAG [12] by applying the technique from [10] to support generalization across questions and domains.", "startOffset": 110, "endOffset": 114}, {"referenceID": 33, "context": "for a related task of automated essay scoring [34].", "startOffset": 46, "endOffset": 50}, {"referenceID": 34, "context": "[35] proposed a hierarchical Bayesian model for domain adaptation of short text where they mentioned possible application to short answer grading.", "startOffset": 0, "endOffset": 4}, {"referenceID": 31, "context": "For numeric features, we used the classical canonical correlation analysis (CCA) [32], [33] which aims to obtain a joint correlation subspace such that the projected features from the source and target domains are maximally correlated, as shown in Eq 1.", "startOffset": 81, "endOffset": 85}, {"referenceID": 32, "context": "For numeric features, we used the classical canonical correlation analysis (CCA) [32], [33] which aims to obtain a joint correlation subspace such that the projected features from the source and target domains are maximally correlated, as shown in Eq 1.", "startOffset": 87, "endOffset": 91}, {"referenceID": 12, "context": "Many of such features are discussed in [13] (and the references there in); however, we restricted our proposed technique to general similarity based features rather than using features tailored for specific datasets.", "startOffset": 39, "endOffset": 43}, {"referenceID": 35, "context": "measures based on Wordnet [36].", "startOffset": 26, "endOffset": 30}, {"referenceID": 3, "context": "For each word in student answer, maximum word-to-word similarity scores are obtained with respect to words in model answers which are then summed up and normalized by the length of the two responses as described by Mohler and Mihalcea [4].", "startOffset": 235, "endOffset": 238}, {"referenceID": 36, "context": "the measure proposed by Jiang and Conrath (JC) [37] and Shortest Path (SP).", "startOffset": 47, "endOffset": 51}, {"referenceID": 37, "context": "(LSA) [38] trained on a Wikipedia dump.", "startOffset": 6, "endOffset": 10}, {"referenceID": 38, "context": "We also use the recently popular word2vec tool (W2V) [39] to obtain vector representation of words which are trained on 100 billion words of Google news dataset", "startOffset": 53, "endOffset": 57}, {"referenceID": 39, "context": "proach similar to the classical co-training algorithm proposed by Blum and Mitchell [40].", "startOffset": 84, "endOffset": 88}, {"referenceID": 2, "context": "In fact, the recent survey papers referred to in Section II ([3], [15]) have emphasized the need for sharing of datasets and structured evaluations of", "startOffset": 61, "endOffset": 64}, {"referenceID": 14, "context": "In fact, the recent survey papers referred to in Section II ([3], [15]) have emphasized the need for sharing of datasets and structured evaluations of", "startOffset": 66, "endOffset": 70}, {"referenceID": 12, "context": "shop in 2013 [13].", "startOffset": 13, "endOffset": 17}, {"referenceID": 40, "context": "The task released two datasets: BEETLE data, based on transcripts of students interacting with BEETLE II tutorial dialogue system [41], and SCIENTSBANK data based on the corpus of student answers to assessment questions collected by [42].", "startOffset": 130, "endOffset": 134}, {"referenceID": 41, "context": "The task released two datasets: BEETLE data, based on transcripts of students interacting with BEETLE II tutorial dialogue system [41], and SCIENTSBANK data based on the corpus of student answers to assessment questions collected by [42].", "startOffset": 233, "endOffset": 237}, {"referenceID": 3, "context": "CSD:6 This is one of the earliest ASAG datasets comprising of a set of questions, model answers and student answers taken from an undergraduate computer science course [4].", "startOffset": 168, "endOffset": 171}, {"referenceID": 13, "context": "X-CSD:7 This is an extended version of CSD with 87 questions from the same course [14].", "startOffset": 82, "endOffset": 86}, {"referenceID": 12, "context": "the macroaverage F1 (= 1/Nc \u2211 c F1(c)) and weighted average F1 (= 1/N \u2211 c |c|\u00d7F1(c)) as described in the end-of-workshop report [13].", "startOffset": 128, "endOffset": 132}, {"referenceID": 11, "context": "TECHNIQUE (ETS1 AND ETS2 ) [12] AND THE BEST PERFORMANCE OBTAINED IN THE SRA TASK.", "startOffset": 27, "endOffset": 31}, {"referenceID": 12, "context": "EXISTING RESULTS ARE FROM [13].", "startOffset": 26, "endOffset": 30}, {"referenceID": 12, "context": "As described in [13], we ignore the \u2018nondomain\u2019 class as it is severely underrepresented and report macro-averaged F1 over 4 classes for consistent comparison.", "startOffset": 16, "endOffset": 20}, {"referenceID": 11, "context": "1) Aggregate Results: Table III shows performance of the proposed technique on SE2013 dataset against the entry \u201cETS\u201d [12] (the only ASAG technique based on transfer learning as", "startOffset": 118, "endOffset": 122}, {"referenceID": 12, "context": "reviewed in Section II-C) as well as the best performances obtained for the SRA task in SemEval workshop reported in [13].", "startOffset": 117, "endOffset": 121}], "year": 2016, "abstractText": "Automatic short answer grading (ASAG) techniques are designed to automatically assess short answers to questions in natural language, having a length of a few words to a few sentences. Supervised ASAG techniques have been demonstrated to be effective but suffer from a couple of key practical limitations. They are greatly reliant on instructor provided model answers and need labeled training data in the form of graded student answers for every assessment task. To overcome these, in this paper, we introduce an ASAG technique with two novel features. We propose an iterative technique on an ensemble of (a) a text classifier of student answers and (b) a classifier using numeric features derived from various similarity measures with respect to model answers. Second, we employ canonical correlation analysis based transfer learning on a common feature representation to build the classifier ensemble for questions having no labelled data. The proposed technique handsomely beats all winning supervised entries on the SCIENTSBANK dataset from the \u201cStudent Response Analysis\u201d task of SemEval 2013. Additionally, we demonstrate generalizability and benefits of the proposed technique through evaluation on multiple ASAG datasets from different subject topics and standards.", "creator": "LaTeX with hyperref package"}}}