{"id": "1609.05123", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Sep-2016", "title": "Learning Opposites Using Neural Networks", "abstract": "Many research works have successfully extended algorithms such as evolutionary algorithms, reinforcement agents and neural networks using \"opposition-based learning\" (OBL). Two types of the \"opposites\" have been defined in the literature, namely \\textit{type-I} and \\textit{type-II}. The former are linear in nature and applicable to the variable space, hence easy to calculate. On the other hand, type-II opposites capture the \"oppositeness\" in the output space. In fact, type-I opposites are considered a special case of type-II opposites where inputs and outputs have a linear relationship. However, in many real-world problems, inputs and outputs do in fact exhibit a nonlinear relationship. Therefore, type-II opposites are expected to be better in capturing the sense of \"opposition\" in terms of the input-output relation. In the absence of any knowledge about the problem at hand, there seems to be no intuitive way to calculate the type-II opposites. In this paper, we introduce an approach to learn type-II opposites from the given inputs and their outputs using the artificial neural networks (ANNs). We first perform \\emph{opposition mining} on the sample data, and then use the mined data to learn the relationship between input $x$ and its opposite $\\breve{x}$. We have validated our algorithm using various benchmark functions to compare it against an evolving fuzzy inference approach that has been recently introduced. The results show the better performance of a neural approach to learn the opposites. This will create new possibilities for integrating oppositional schemes within existing algorithms promising a potential increase in convergence speed and/or accuracy.", "histories": [["v1", "Fri, 16 Sep 2016 16:19:56 GMT  (208kb,D)", "http://arxiv.org/abs/1609.05123v1", "To appear in proceedings of the 23rd International Conference on Pattern Recognition (ICPR 2016), Cancun, Mexico, December 2016"]], "COMMENTS": "To appear in proceedings of the 23rd International Conference on Pattern Recognition (ICPR 2016), Cancun, Mexico, December 2016", "reviews": [], "SUBJECTS": "cs.LG cs.NE", "authors": ["shivam kalra", "aditya sriram", "shahryar rahnamayan", "h r tizhoosh"], "accepted": false, "id": "1609.05123"}, "pdf": {"name": "1609.05123.pdf", "metadata": {"source": "CRF", "title": "LEARNING OPPOSITES USING NEURAL NETWORKS", "authors": ["Shivam Kalra", "Aditya Sriram", "Shahryar Rahnamayan", "H.R. Tizhoosh"], "emails": [], "sections": [{"heading": "1. INTRODUCTION", "text": "A large number of problems in engineering and science are unapproachable because they are able to find solutions in the desired way - this is fleeting and uncertain. Many heuristic methods exist to accelerate the convergence rate of the aforementioned algorithms. Opposite Based Computing (OBC) is one such method that Tizhoosh sets in motion."}, {"heading": "2. BACKGROUND REVIEW", "text": "This year it has come to the point that it has never come as far as this year."}, {"heading": "3. THE IDEA", "text": "In fact, it is such that most people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to move, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to move, to fight, to move, to move, to move, to move, to move, to move, to move, to fight, to move, to fight, to fight, to move, to fight, to move, to fight, to move, to fight, to fight, to move, to move, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move,"}, {"heading": "4. LEARNING OPPOSITES", "text": "In fact, it is such that it is a way of acting, in which one sees oneself in a position to be in, in which one sees oneself in a position, in which one is in a position, in which one is in a position to be in a position, in which one is in a position to be in a position, in a position to be in a position, in which one is in a position to be in a position, in a position to be in a position, in which one is in a position, in which one is in a position, in a position to be in a position, in which one is in a position, in which one is in a position, in which one is in a position, in which one is in a position, in which one is in a position, in which one is in a position, in which one is in a position, in which one is in which one is in a position, in which one is in which one is in a position, in which one is in which one is in which one is in which one is in which one is in which one is in which one is in which one is in which one is in which one is in which one is in which one is in which one is in which one is in which one is in which one is in which one is in which one is in which one is in which one is in which one is in which one is in which one is in which one is in which is in which one is in which one is in which is in which one is in which one is in which is in which one is in which is in which one in which one is in which one is in which is in which is in which one is in which is in which one is in which is in which one is in which is in which one in which one in which is in which is in which is in which one is in which is in which is in which one in which one is in which is in which is in which one in which is in which is in which one in which one is in which one in which is in which is in which is in which one is in which is in which one in which is in which is in which one in which is in which one is in which is in which one in which is in which is in which is in which one is in which is in which one is in which is in which is in which is in which is in which is in which"}, {"heading": "5. EXPERIMENTS AND RESULTS", "text": "We have conducted two series of experiments to test the various aspects of our algorithm, including - opposition mining, learning type II using ANN and predictive accuracy of the trained ANN model versus the developing fuzzy rules model. The experiments deal with the approximation accuracy of type II opposites and the application of type II opposites for some standard optimization scenarios. To compare the approximation accuracy, we used the 8 benchmark functions to generate the data required for opposition mining and the subsequent formation of ANN and developing fuzzy rules models; which are derived from [3]. It is important to note that the benchmark function was deliberately kept simple and largely monotonous in defined areas in order to avoid the surjective relationship of inputs and their (quasi-) opposites during the phase of opposition mining, which would be incompatible with any non-compromised type II function, however, by making it possible to implement the most practical learning algorithms required in order to extract the data."}, {"heading": "5.1. Comparing with Evolving Fuzzy Rules", "text": "The results for 8 benchmark functions (used in [3]) are summarized in Table 1. Green cells represent the performance of ANN is statistically significant with 95% confidence (unless otherwise stated), while red cells show the importance of an evolving, fuzzy rule-based approach to the respective oppositional scheme. Gray cells represent the best results obtained with any method or oppositional scheme applied for a given benchmark function. It is important to note that the error in the approximation of type II to x-II is inferred by comparing the value of the function at approximate equivalent xII and the true equivalent of function y-II with given input x. It is important to note that y-II can be calculated if input x, oppositional scheme Ti and function f are known: error (x-II), error (y-II), error (y-II) - and true equivalent value of function y-II - x (f)."}, {"heading": "5.2. Optimization Problems", "text": "In this experiment we have three standard optimization functions, which can be found in the literature of global optimization - namely in the way they can be found in the real world, and in the way they can be found in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world in the real world, in the real world, in the real world in the real world, in the real world, in the real world in the real world, in the real world in the real world, in the real world, in the real world in the real world, in the real world, in the real world in the real world, in the real world, in the real world in the real world, in the real world, in the real world in the real world, in the real world, in the real world, in the real world in the real world, in the real world, in the real world, in the real world, in the real world in the real world, in the real world, in the real world, in the real world in the real world, in the real world, in the real world, in the real world in the real world, in the real world, in the real world, in the real world in the real world, in the real world, in the real world, in the real world in the real world, in the real world, in the real world, in the real world, in the real"}, {"heading": "6. CONCLUSION", "text": "Ten years after the introduction of oppositional learning, the full potential of type II opposites is still largely unknown. In this paper, we present a method for learning type II opposites with ANNs. The basic idea in this paper is to use the (quasi) opposing data from oppositional mining to learn the relationship between input x and its type II versus x-II using neural networks. We tested the proposed algorithms with various benchmark functions and compared them with the existing fuzzy rule-based approach. We demonstrated the correctness of the basic message of the OBL scheme by using type II opposites on three of the famous global optimization problems. One of the biggest hurdles to existing type II approximation methods (including the one proposed in this paper) is that the function in question is highly non-monotonous or periodic in nature. Under these circumstances, the relationship between x and x-II surjective and any continuous learning mechanism is caused and makes it difficult for any such discontinuity to integrate in the mining algorithm."}, {"heading": "7. REFERENCES", "text": "[1] H. R. Tizhoosh, \"Opposition-based learning on: a new scheme for machine intelligence,\" in Zero. IEEE, 2005, pp. 695-701. [2] S. Rahnamayan, H. R. Tizhoosh, and M. Salama, \"Opposition-based differential evolution,\" Evolutionary Computation, IEEE Transactions on, vol. 12, no. 1, pp. 64-79, 2008. [3] H. R. Tizhoosh and S. Rahnamayan \"Learning-based opposites with evolving rules,\" in Fuzzy Systems, IEEE Transactions on, vol. 12, no. IEEE International Conference on. IEEE, 2015, pp. 1-8. F. S. Al-Qunaieer, H. R. Tizhoosh Tizhoosh, and S. Rahnamayan rules. Opposition-based computinga survey, \"in Neural Networks (IJCNN), The 2010 International Joint Conference on."}], "references": [{"title": "Opposition-based learning: a new scheme for machine intelligence", "author": ["H.R. Tizhoosh"], "venue": "null. IEEE, 2005, pp. 695\u2013701.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2005}, {"title": "Opposition-based differential evolution", "author": ["S. Rahnamayan", "H.R. Tizhoosh", "M. Salama"], "venue": "Evolutionary Computation, IEEE Transactions on, vol. 12, no. 1, pp. 64\u201379, 2008.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2008}, {"title": "Learning opposites with evolving rules", "author": ["H.R. Tizhoosh", "S. Rahnamayan"], "venue": "Fuzzy Systems (FUZZ- 5  To appear in proceedings of the 23rd International Conference on Pattern Recognition (ICPR 2016), Cancun, Mexico, December 2016 IEEE), 2015 IEEE International Conference on. IEEE, 2015, pp. 1\u20138.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2016}, {"title": "Opposition based computinga survey", "author": ["F.S. Al-Qunaieer", "H.R. Tizhoosh", "S. Rahnamayan"], "venue": "Neural Networks (IJCNN), The 2010 International Joint Conference on. IEEE, 2010, pp. 1\u20137.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2010}, {"title": "Reinforcement learning based on actions and opposite actions", "author": ["H.R. Tizhoosh"], "venue": "Int. Conf. on Artificial Intelligence and Machine Learning, 2005, p. 9498.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2005}, {"title": "Opposition-based reinforcement learning in the management of water resources", "author": ["M. Mahootchi", "H. Tizhoosh", "K. Ponnambalam"], "venue": "Approximate Dynamic Programming and Reinforcement Learning, 2007. AD- PRL 2007. IEEE International Symposium on. IEEE, 2007, pp. 217\u2013224.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2007}, {"title": "Opposition-based reinforcement learning", "author": ["H.R. Tizhoosh"], "venue": "JACIII, vol. 10, no. 4, pp. 578\u2013585, 2006.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2006}, {"title": "Oppositional extension of reinforcement learning techniques", "author": ["M. Mahootchi", "H.R. Tizhoosh", "K. Ponnambalam"], "venue": "Information Sciences, vol. 275, pp. 101\u2013114, 2014.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "Opposition-based differential evolution algorithms", "author": ["S. Rahnamayan", "H.R. Tizhoosh", "M. Salama"], "venue": "Evolutionary Computation, 2006. CEC 2006. IEEE Congress on. IEEE, 2006, pp. 2010\u20132017.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2006}, {"title": "Type-ii opposition-based differential evolution", "author": ["H. Salehinejad", "S. Rahnamayan", "H.R. Tizhoosh"], "venue": "Evolutionary Computation (CEC), 2014 IEEE Congress on. IEEE, 2014, pp. 1768\u20131775.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}, {"title": "A novel population initialization method for accelerating evolutionary algorithms", "author": ["S. Rahnamayan", "H.R. Tizhoosh", "M.M. Salama"], "venue": "Computers & Mathematics with Applications, vol. 53(10), pp. 1605\u20131614, 2007.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2007}, {"title": "Image thresholding using micro opposition-based differential evolution (micro-ode)", "author": ["S. Rahnamayan", "H.R. Tizhoosh"], "venue": "IEEE World Congress on Computational Intelligence Evolutionary Computation, 2008, pp. 1409\u20131416.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2008}, {"title": "A novel swarm model with quasi-oppositional particle", "author": ["C. Zhang", "Z. Ni", "Z. Wu", "L. Gu"], "venue": "Information Technology and Applications, 2009. IFITA\u201909. International Forum on, vol. 1, 2009, pp. 325\u2013330.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2009}, {"title": "Opposition based initialization in particle swarm optimization (o-pso)", "author": ["H. Jabeen", "Z. Jalil", "A.R. Baig"], "venue": "Proceedings of the 11th Annual Conference Companion on Genetic and Evolutionary Computation Conference: Late Breaking Papers, 2009, pp. 2047\u20132052.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2009}, {"title": "A multi-start opposition-based particle swarm optimization algorithm with adaptive velocity for bound constrained global optimization", "author": ["M. Kaucic"], "venue": "Journal of Global Optimization, vol. 55(1), pp. 165\u2013188, 2013.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2013}, {"title": "Improved opposition-based pso for feedforward neural network training", "author": ["M. Rashid", "A.R. Baig"], "venue": "Information Science and Applications (ICISA), International Conference on, 2010, pp. 1\u20136.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2010}, {"title": "Hiopga: a new hybrid metaheuristic algorithm to train feedforward neural networks for prediction", "author": ["M. Yaghini", "M.M. Khoshraftar", "M. Fallahi"], "venue": "Proceedings of the International Conference on Data Mining, 2011, pp. 18\u201321.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2011}, {"title": "A review of opposition-based learning from 2005 to 2012", "author": ["Q. Xu", "L. Wang", "N. Wang", "X. Hei", "L. Zhao"], "venue": "Engineering Applications of Artificial Intelligence, vol. 29, pp. 1\u201312, 2014.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2014}, {"title": "A diversity maintaining population-based incremental learning algorithm", "author": ["M. Ventresca", "H.R. Tizhoosh"], "venue": "Information Sciences, vol. 178(21), pp. 4038\u20134056, 2008.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2008}, {"title": "Evolving fuzzy classifiers using different model architectures", "author": ["P. Angelov", "E. Lughofer", "X. Zhou"], "venue": "Fuzzy Sets and Systems, vol. 159(23), pp. 3160\u20133182, 2008.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2008}, {"title": "Evolving fuzzy-rule-based classifiers from data streams", "author": ["P.P. Angelov", "X. Zhou"], "venue": "Fuzzy Systems, IEEE Transactions on, vol. 16, no. 6, pp. 1462\u20131475, 2008.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2008}, {"title": "On-line identification of computationally undemanding evolving fuzzy models", "author": ["J.-C. de Barros", "A.L. Dexter"], "venue": "Fuzzy sets and systems, vol. 158(18), pp. 1997\u2013 2012, 2007.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1997}, {"title": "On-line evolving image classifiers and their application to surface inspection", "author": ["E. Lughofer"], "venue": "Image and Vision Computing, vol. 28(7), pp. 1065\u20131079, 2010.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2010}, {"title": "Evolving fuzzy image segmentation", "author": ["A.A. Othman", "H.R. Tizhoosh"], "venue": "Fuzzy Systems, IEEE International Conference on, 2011, pp. 1603\u20131609.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2011}, {"title": "Efisevolving fuzzy image segmentation", "author": ["A.A. Othman", "H.R. Tizhoosh", "F. Khalvati"], "venue": "Fuzzy Systems, IEEE Transactions on, vol. 22(1), pp. 72\u201382, 2014.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning polynomials with neural networks", "author": ["A. Andoni", "R. Panigrahy", "G. Valiant", "L. Zhang"], "venue": "Proceedings of the 31st International Conference on Machine Learning (ICML-14), 2014, pp. 1908\u20131916. 6", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "Opposite Based Computing (OBC) is one such heuristic method introduced by Tizhoosh in [1].", "startOffset": 86, "endOffset": 89}, {"referenceID": 1, "context": "Opposition-based Differential Evolution (ODE), however, seems to be the most successful oppositional inspired algorithm so far [2].", "startOffset": 127, "endOffset": 130}, {"referenceID": 2, "context": "Tizhoosh and Rahnamayan [3] introduced the idea of \u201copposition mining\u201d and evolving rules to capture oppositeness in dynamic environments.", "startOffset": 24, "endOffset": 27}, {"referenceID": 2, "context": "Finally, Section 5 provides experimental results and analysis and also a comparison of the proposed ANN approach with the evolving fuzzy inference systems, a method recently proposed in [3].", "startOffset": 186, "endOffset": 189}, {"referenceID": 0, "context": "Roughly 10 years ago, the idea of opposition-based learning (OBL) was introduced as a generic framework to improve existing learning and optimization algorithms [1].", "startOffset": 161, "endOffset": 164}, {"referenceID": 3, "context": "This approach has received a modest but growing attention by the research community resulting in improving diverse optimization and learning techniques published in several hundred papers [4].", "startOffset": 188, "endOffset": 191}, {"referenceID": 4, "context": "A few algorithms have been reported to employ \u201coppositeness\u201d in their processing, including reinforcement learning [5, 6, 7, 8], evolutionary algorithms [9, 10, 11, 12], swarm-based methods [13, 14, 15], and neural networks [16, 17, 18].", "startOffset": 115, "endOffset": 127}, {"referenceID": 5, "context": "A few algorithms have been reported to employ \u201coppositeness\u201d in their processing, including reinforcement learning [5, 6, 7, 8], evolutionary algorithms [9, 10, 11, 12], swarm-based methods [13, 14, 15], and neural networks [16, 17, 18].", "startOffset": 115, "endOffset": 127}, {"referenceID": 6, "context": "A few algorithms have been reported to employ \u201coppositeness\u201d in their processing, including reinforcement learning [5, 6, 7, 8], evolutionary algorithms [9, 10, 11, 12], swarm-based methods [13, 14, 15], and neural networks [16, 17, 18].", "startOffset": 115, "endOffset": 127}, {"referenceID": 7, "context": "A few algorithms have been reported to employ \u201coppositeness\u201d in their processing, including reinforcement learning [5, 6, 7, 8], evolutionary algorithms [9, 10, 11, 12], swarm-based methods [13, 14, 15], and neural networks [16, 17, 18].", "startOffset": 115, "endOffset": 127}, {"referenceID": 8, "context": "A few algorithms have been reported to employ \u201coppositeness\u201d in their processing, including reinforcement learning [5, 6, 7, 8], evolutionary algorithms [9, 10, 11, 12], swarm-based methods [13, 14, 15], and neural networks [16, 17, 18].", "startOffset": 153, "endOffset": 168}, {"referenceID": 9, "context": "A few algorithms have been reported to employ \u201coppositeness\u201d in their processing, including reinforcement learning [5, 6, 7, 8], evolutionary algorithms [9, 10, 11, 12], swarm-based methods [13, 14, 15], and neural networks [16, 17, 18].", "startOffset": 153, "endOffset": 168}, {"referenceID": 10, "context": "A few algorithms have been reported to employ \u201coppositeness\u201d in their processing, including reinforcement learning [5, 6, 7, 8], evolutionary algorithms [9, 10, 11, 12], swarm-based methods [13, 14, 15], and neural networks [16, 17, 18].", "startOffset": 153, "endOffset": 168}, {"referenceID": 11, "context": "A few algorithms have been reported to employ \u201coppositeness\u201d in their processing, including reinforcement learning [5, 6, 7, 8], evolutionary algorithms [9, 10, 11, 12], swarm-based methods [13, 14, 15], and neural networks [16, 17, 18].", "startOffset": 153, "endOffset": 168}, {"referenceID": 12, "context": "A few algorithms have been reported to employ \u201coppositeness\u201d in their processing, including reinforcement learning [5, 6, 7, 8], evolutionary algorithms [9, 10, 11, 12], swarm-based methods [13, 14, 15], and neural networks [16, 17, 18].", "startOffset": 190, "endOffset": 202}, {"referenceID": 13, "context": "A few algorithms have been reported to employ \u201coppositeness\u201d in their processing, including reinforcement learning [5, 6, 7, 8], evolutionary algorithms [9, 10, 11, 12], swarm-based methods [13, 14, 15], and neural networks [16, 17, 18].", "startOffset": 190, "endOffset": 202}, {"referenceID": 14, "context": "A few algorithms have been reported to employ \u201coppositeness\u201d in their processing, including reinforcement learning [5, 6, 7, 8], evolutionary algorithms [9, 10, 11, 12], swarm-based methods [13, 14, 15], and neural networks [16, 17, 18].", "startOffset": 190, "endOffset": 202}, {"referenceID": 15, "context": "A few algorithms have been reported to employ \u201coppositeness\u201d in their processing, including reinforcement learning [5, 6, 7, 8], evolutionary algorithms [9, 10, 11, 12], swarm-based methods [13, 14, 15], and neural networks [16, 17, 18].", "startOffset": 224, "endOffset": 236}, {"referenceID": 16, "context": "A few algorithms have been reported to employ \u201coppositeness\u201d in their processing, including reinforcement learning [5, 6, 7, 8], evolutionary algorithms [9, 10, 11, 12], swarm-based methods [13, 14, 15], and neural networks [16, 17, 18].", "startOffset": 224, "endOffset": 236}, {"referenceID": 17, "context": "A few algorithms have been reported to employ \u201coppositeness\u201d in their processing, including reinforcement learning [5, 6, 7, 8], evolutionary algorithms [9, 10, 11, 12], swarm-based methods [13, 14, 15], and neural networks [16, 17, 18].", "startOffset": 224, "endOffset": 236}, {"referenceID": 17, "context": "The convergence would be significantly faster towards the optimal solution if these random initializations are close to the result [18].", "startOffset": 131, "endOffset": 135}, {"referenceID": 18, "context": "On the contrary, if the initial estimates are far from the optimal solution \u2013 in the opposite corner of the search space, for instance, then convergence to the ideal solution will take considerably more time or can be left intractable [19].", "startOffset": 235, "endOffset": 239}, {"referenceID": 0, "context": "Hence, there is a need to look simultaneously for a candidate solution in both current and opposite directions to increase the convergence speed \u2013 a learning mechanism denoted as \u201copposition-based learning\u201d [1].", "startOffset": 207, "endOffset": 210}, {"referenceID": 3, "context": "in [4].", "startOffset": 3, "endOffset": 6}, {"referenceID": 2, "context": "Tizhoosh and Rahnamayan introduced the idea of opposition mining as an approach to approximate type-II opposites for training the learning algorithms using fuzzy inference systems (FIS) with evolving rules in [3].", "startOffset": 209, "endOffset": 212}, {"referenceID": 19, "context": "Evolving FIS has received much attention lately [20, 21] which is now being used for modeling nonlinear dynamic systems [22] and image classification and segmentation [23, 24, 25].", "startOffset": 48, "endOffset": 56}, {"referenceID": 20, "context": "Evolving FIS has received much attention lately [20, 21] which is now being used for modeling nonlinear dynamic systems [22] and image classification and segmentation [23, 24, 25].", "startOffset": 48, "endOffset": 56}, {"referenceID": 21, "context": "Evolving FIS has received much attention lately [20, 21] which is now being used for modeling nonlinear dynamic systems [22] and image classification and segmentation [23, 24, 25].", "startOffset": 120, "endOffset": 124}, {"referenceID": 22, "context": "Evolving FIS has received much attention lately [20, 21] which is now being used for modeling nonlinear dynamic systems [22] and image classification and segmentation [23, 24, 25].", "startOffset": 167, "endOffset": 179}, {"referenceID": 23, "context": "Evolving FIS has received much attention lately [20, 21] which is now being used for modeling nonlinear dynamic systems [22] and image classification and segmentation [23, 24, 25].", "startOffset": 167, "endOffset": 179}, {"referenceID": 24, "context": "Evolving FIS has received much attention lately [20, 21] which is now being used for modeling nonlinear dynamic systems [22] and image classification and segmentation [23, 24, 25].", "startOffset": 167, "endOffset": 179}, {"referenceID": 2, "context": "Type-II opposites [Adopted from [3]].", "startOffset": 32, "endOffset": 35}, {"referenceID": 25, "context": "Neural networks with sufficient number of hidden layers can learn any bounded degree polynomials with good accuracy [26].", "startOffset": 116, "endOffset": 120}, {"referenceID": 2, "context": "For comparing the approximation accuracy, we used the 8 benchmark functions for generating the data required for the opposition-mining and subsequent training of ANN and evolving fuzzy rules models; which are taken from [3].", "startOffset": 220, "endOffset": 223}, {"referenceID": 2, "context": "We compared the results against the recently published ones by approximating type-II using evolving fuzzy rules [3].", "startOffset": 112, "endOffset": 115}, {"referenceID": 2, "context": "The results for 8 benchmark functions (used in [3]) are summarized in Table 1.", "startOffset": 47, "endOffset": 50}, {"referenceID": 2, "context": "In this experiment, we test three standard optimization functions which are commonly used in literature of global optimization \u2013 Ackely, Bulkin and Booth functions [3].", "startOffset": 164, "endOffset": 167}], "year": 2016, "abstractText": "Many research works have successfully extended algorithms such as evolutionary algorithms, reinforcement agents and neural networks using \u201copposition-based learning\u201d (OBL). Two types of the \u201copposites\u201d have been defined in the literature, namely type-I and type-II. The former are linear in nature and applicable to the variable space, hence easy to calculate. On the other hand, type-II opposites capture the \u201coppositeness\u201d in the output space. In fact, type-I opposites are considered a special case of type-II opposites where inputs and outputs have a linear relationship. However, in many real-world problems, inputs and outputs do in fact exhibit a nonlinear relationship. Therefore, type-II opposites are expected to be better in capturing the sense of \u201copposition\u201d in terms of the input-output relation. In the absence of any knowledge about the problem at hand, there seems to be no intuitive way to calculate the type-II opposites. In this paper, we introduce an approach to learn type-II opposites from the given inputs and their outputs using the artificial neural networks (ANNs). We first perform opposition mining on the sample data, and then use the mined data to learn the relationship between input x and its opposite x\u0306. We have validated our algorithm using various benchmark functions to compare it against an evolving fuzzy inference approach that has been recently introduced. The results show the better performance of a neural approach to learn the opposites. This will create new possibilities for integrating oppositional schemes within existing algorithms promising a potential increase in convergence speed and/or accuracy.", "creator": "LaTeX with hyperref package"}}}