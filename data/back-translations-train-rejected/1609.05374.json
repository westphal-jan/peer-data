{"id": "1609.05374", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Sep-2016", "title": "Online Learning of Combinatorial Objects via Extended Formulation", "abstract": "The convex hull of $n$-symbol Huffman trees is known to have exponentially many facets/constraints. This makes the standard on-line learning techniques for learning Huffman trees impractical, since they use multiplicative updates followed by projections to satisfy all of the constraints. However, there are general extended formulation techniques that encode the convex hull of Huffman trees as a polytope in a higher dimensional space with only polynomially many facets. This extended formulation methodology can also be used to encode the $n$-element permutahedron in $O(n \\log n)$ dimensions with only a polynomial number of facets. We develop a general technique for converting these extended formulations into efficient on-line algorithms with good relative loss bounds. The resulting algorithms have nearly the same regret bounds as state of the art algorithms for permutations, and are the first efficient algorithms for the on-line learning of Huffman trees.", "histories": [["v1", "Sat, 17 Sep 2016 18:38:46 GMT  (26kb)", "http://arxiv.org/abs/1609.05374v1", null], ["v2", "Tue, 21 Feb 2017 19:51:28 GMT  (218kb,D)", "http://arxiv.org/abs/1609.05374v2", null], ["v3", "Thu, 6 Apr 2017 16:28:45 GMT  (262kb,D)", "http://arxiv.org/abs/1609.05374v3", null], ["v4", "Thu, 8 Jun 2017 01:49:06 GMT  (218kb,D)", "http://arxiv.org/abs/1609.05374v4", null], ["v5", "Mon, 30 Oct 2017 20:33:11 GMT  (40kb)", "http://arxiv.org/abs/1609.05374v5", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["holakou rahmanian", "s v n vishwanathan", "david p helmbold"], "accepted": false, "id": "1609.05374"}, "pdf": {"name": "1609.05374.pdf", "metadata": {"source": "CRF", "title": "Extended Formulation for Online Learning of Combinatorial Objects", "authors": ["Holakou Rahmanian"], "emails": ["holakou@ucsc.edu", "vishy@ucsc.edu", "dph@ucsc.edu"], "sections": [{"heading": null, "text": "ar Xiv: 160 9.05 374v 1 [cs.L G"}, {"heading": "1 Introductions", "text": "This year is the highest in the history of the country."}, {"heading": "2 Related Work", "text": "The implicit representations for structured concepts (sometimes referred to as \"indirect representations\") have been used for a variety of problems [7, 8, 16, 18, 19]. In the case of permutations [9, 21] and component backups [13], the implicit representations seem to be more in agreement with the combinatorial structure than the explicit representation, which not only allows a shortened runtime, but also the proof of better limits. Our more general methodology with extended formulations also has this advantage, though perhaps to a lesser extent than the permutation-specific algorithms. As in [21], the loss family provided for in our approach is linear over the representation of first-order objects [4]. Specifically, for permutations of n items [permutations of n items] we work with vectors v Rn, in which each of the elements of {1, 2,]."}, {"heading": "3 Extended Formulation", "text": "There are many combinatorial objects whose polytopia cannot be described other than to use exponentially many facets in their original space (see [17]). In order to have more efficient algorithms, there have been several efforts in the field of combinatorial optimization to describe this polytopic in some other spaces. In recent years, the concept of depicting this polytopic as a linear projection of a higher-dimensional polyhedron - known as an extended formulation - has attracted considerable attention. There are many combinatorial objects whose associated polyhedrons can be described by projections of higher-dimensional polyhedrons with a small number of facets compared to the original space. See [11] for some of the tools for constructing such extended formulations. In the following subsections, we will first give an overview of the work of Kaibel and Pashkovich [12] and then extract the formulation that fits our methodology."}, {"heading": "3.1 Constructing Extended Formulation from Reflection Relations", "text": "The basic idea is to start with a corner of the polytope (e.g. a permutation) and then create a sequence of reflections through hyperplanes (e.g. swapping a pair of elements) so that each corner of the polytope can be created by applying a sub-sequence of reflections into the canonical corner. Convex hull is then created by allowing for \"partial reflections\" (i.e. the entire line segment that connects the original point and its reflection); each point in the convex hull is then generated by a sequence of partial reflections and can be encoded by a sequence of variables indicating how much of each reflection has been used. Indeed, there is no need to start with a single corner; one could consider the entire binding as input by the sequence of (partial) reflections."}, {"heading": "3.2 Extended Formulation of Objects Closed under Re-Ordering", "text": "Suppose we want an extended formulation for the class of combination objects that are in a relationship between the individual areas. (note) Suppose we want an extended formulation for the class of combination objects that are in a different relationship. (note) Note: Huffman trees and - trivial - permutations belong to an extended form of extended formulation in this particular case. (note) First, we find the additional qualities associated with this reflection relationship. (note) Specifically, it is assumed that the reflection relationship of trees through this reflection relationship and the extended form of the extended formulation must fall into the form of extended formulation in this particular case. (note) Note: We assume that the reflection relationship of trees goes through this reflection relationship and the extended form of the extended formulation. (note)"}, {"heading": "3.3 Combinatorial Polytope Description in Augmented Formulation", "text": "Although the polytopic can now be described with the polynomial number of facets in the extended formulation x-X, it is not natural to define linear loss via the elements of x. However, one can associate the original formulation v-V with the extended formulation x-X, so that it is possible not only to efficiently describe the polytopic, but also to provide significant losses such as the average code length and the sum of completion times in Huffman trees or permutations. Thus, given a loss vector [0, 1] n defined via V, we can work with (V, X) as shown in the left column of the table. Furthermore, to have the convenience of working with affine subspaces2, we add a positive slip vector to transform all inequalities into equations. Consequently, we define the extended formulation space W (see the right column of Table 1)."}, {"heading": "4 Algorithm", "text": "In this section, we propose our Extended-Learn algorithm, discuss its technical steps and prove its remorse limits. The main idea of our algorithm is to maintain a distribution across all instances of the objects by using an evolving point wt = (vt, xt, \u03bbt) in the extended formulation space W by experimenting t = 1,.., T. \u2212 The main structure of Extended-Learn is shown in Algorithm 1. \u2212 Similar to [13], our algorithm consists of three main technical parts: 1. Prediction: prediction with an instance t \u2212 1,. \u2212 H such that E [\u03b3t \u2212 1] = vt \u2212 12. Update: The mixture wt \u2212 1 is multiplicable after w \u2212 1 after the loss caused. 3. Forecast: project the updated mixture w \u2212 1 after polytopy W and get w.In the prediction step discussed in trade, we draw an instance that makes the loss multiplicable."}, {"heading": "4.1 Prediction", "text": "In this subsection we describe how to predict an instance with an instance in such a way that it has the same expected value as the mixture vector whose traces we track. First, we propose an algorithm to decompose any mixing point into a convex combination of instances. Despite its inefficiency, it leads us to another algorithm that efficiently produces correct predictions.Inefficient decomposition The decomposition algorithm is shown in Algortihm 2. The main idea of the algorithm is to exploit the notion of partial swaps in the comparators that correspond to the reflective relationships in our extended formulation. In other words, in each comparator we want to decompose based on the extent to which we have used swap capacity.It can be shown that algorithm 2, despite its inefficiency, results in valid convex combinations of instances (see Appendix for proof of Lemma 1.) (i)"}, {"heading": "4.2 Projection", "text": "Formally, the problem is to find the \u2206 projection of the multiplicatively updated p back to the fixed W: P \u2206 W (p) = argmin q \u0445 W (q | | p) (3), where \u2206 (\u00b7 | \u00b7) is the unnormalized relative entropy. Note that W is an intersection of affinity subspaces denoted by m + n constraints of equality in Ax + \u03bb = b and Mx + c = v in C1... Since the nonnegativity constraints are already contained in the definition of \u0445, it is possible to solve (3) by simply using iterative \u0445 projections 4 [2]. Starting from p0 = p iteratively3Mi, we denote the swap action associated with the ith reflection relationship. 4In [9] Sinkhorn balancing is used for the projection, which is also a special case of iterative Bregman projection."}, {"heading": "4.3 Regret Bounds", "text": "On the basis of the vectors wt-W generated by the algorithm, we can prove the following cumulative remorse limits: Lemma 3. E [T-T = 1\u03b3t-1 \u00b7 \u0445t] \u2264 \u03b7min \u03b3-H-T = 1-0-0-1 \u2212 e \u2212 \u03b7, in which there is a good starting point w0 in W, so that the divergences are correspondingly limited (shown in the appendix). Lemma 4. Let us assume that we work with m reflection relations. Let us also assume that the associated network does not have a good starting point w0 in W, so that the divergences are correspondingly limited (shown in the appendix). Let us assume that we work with m reflection relations. Let us assume that the associated network does not have a redundant comparator. Let us assume that n-T-m-n2, there is 5 q-W-n, so that we have a mutation for all p-W cases."}, {"heading": "5 Comparisons and Conclusion", "text": "Table 2 provides a comparison of the limits of regret for the new extended-learn algorithms q, previous permutation algorithms and the hedge algorithm [5], which inefficiently maintains an explicit weight for each of the exponential in n logn permutations or trees. Compared to the state of the art implicit algorithms PermELearn [9] and PermutahedLearn [21], we assume that the general extended-learn method loss of [21], which has a range of [0, n2] per attempt. Compared to the generic explicit hedge algorithms PermELearn [9] and PermutahedLearn [21], the general extended-learn methodology has a small additional penalty of regret log (s)."}, {"heading": "6 Appendix", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.1 Structure of Inequality Constraints in Extended Formulation", "text": "Lemma 6. If M is the matrix of affin transformation corresponding to m reflection relations, we have: A = Tri (MTM) + I, b = \u2212 MTc, in which Tri (\u00b7) is a function of quadratic matrices occupying the upper triangular part of the input, including the diagonal, with zeros. Let vk be the vector in V after you have traversed the kth reflection relationship. Note also the kth column of M of Mk. Note that v0 = c and vk = c + \u2211 k i = 1 Mixi. Let Mk = er \u2212 es. Then with (2) you get the inequality associated with the kth row of Ax \u2264 b, as below: xk \u2264 vk \u2212 1s \u2212 vk \u2212 1r = \u2212 MTk vk \u2212 MTk \u2212 1 = \u2212 MTk \u2212 1 = \u2212 MTk \u2212 1 = \u2212 MTk \u2212 Miltk = &ltk = 1ltk; MTxi = <"}, {"heading": "6.2 Proof of Lemma 1", "text": "We prove that at the end of the ith iteration of ExtendedDecomposition S is the correct decomposition for xi = [x1... xi 0.. 0]. The term becomes for i = m as a result of this statement. We prove the statement by induction. The basic case i = 0 is actually true, because S was initialized to {(c, 1)} and we have v0 = Mx0 + c = c. Let us now consider that at the end of the (k \u2212 1) th iteration we have the correct decomposition, namely vk \u2212 1 = \u03b3 p\u03b3. \u2212 k\u03b3 \u2212 kp \u2212 k. Suppose that the kth comparator is applied to the rth and sth elements. Thus, the kth column from M to Mk = er \u2212 es. Now, according to (2), the swap capacitance at the kth comparator is p\u03b3 \u2212 kp \u2212 kp = vk \u2212 k."}, {"heading": "6.3 Proof of Lemma 2", "text": "Evidence. For each comparator in the network, the extended prediction algorithm defines the distribution below for the action of the comparator i: P (actioni) = {pi actioni = swap 1 \u2212 pi actioni = passFrom Lemma 1 it is easy to see that the distribution of a given instance is drawn as follows: P (\u03b3) = m \u0412i = 1P (actioni) That is, the distribution across instances is separated into individual actions of the swap / pass by the network of comparators independently of each other. Thus, one can draw an instance according to the distribution by simply conducting independent Bernoulli studies related to the comparators. It is also easy to see that the temporal complexity of the algorithm O (m) is because one only needs to perform m Bernoulli studies."}, {"heading": "6.4 Projection onto Each Constraint", "text": "Any polytopic restriction in the extended formulation is of the form aTw = a0. Formally, the projection w * of a Givepunts w on this restriction is the solution as follows: argmin aTw * = a0 * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *"}, {"heading": "6.5 Proof of Lemma 3", "text": "The proof. Assuming that w = (v, x, \u03bb), \u03b8 = (\u03b3, x\u03b8, \u03bb\u03b8) and L = (, 0,0): (1 \u2212 e \u2212 \u03b7) vt \u2212 1 \u00b7 \u0432 t = (1 \u2212 e \u2212 \u03b7) wt \u2212 1 \u00b7 Lt \u2264 \u2211 iwt \u2212 1i (1 \u2212 e \u2212 \u03b7 L t i) = \u0432 (\u03b8 | | wt \u2212 1) \u2212 \u0445 (\u03b8 | w \u00b2 t \u2212 1) + \u03b7 \u00b7 Lt \u2264 (\u03b8 | wt \u2212 1) \u2212 \u0445 (\u03b8 | wt) + \u03b7 \u00b7. The first inequality results from 1 \u2212 e \u2212 \u03b7x (1 \u2212 e \u2212 \u03b7) x for x [0 \u2212 1] as done in [15]. The second inequality is a result of the generalized pythagorean theorem [10], since wt is a Bregman projection of w \u00b2 t \u2212 1 into the convex formula W, which contains no effective effects. By summing up the 2001 \u00b7 t = T \u00b7 T (T \u00b7 t = 1)."}, {"heading": "6.6 Proof of Lemma 4", "text": "Proof. According to the definition, we will bind every term of the above expression. First of all, let us note that for any point (v, x, \u03bb) we have the following values: p = p log pi Sp \u2264 log (n + 2 m) \u2212 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 p = p log pi Sp \u2264 log (n + 2 m) \u2212 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2"}, {"heading": "6.7 Proof of Theorem 5", "text": "Proof. The first part is the direct sequence of lemas 3 and 4: E [T \u2211 t = 1\u03b3t \u2212 1 \u00b7 \u0439t] \u2264 \u03b7min GP-H \u0445 T = 1 GP-T + 16mn logn1 \u2212 e \u2212 \u03b7Let Lbest = min-T = min-H-T = 1 GP-T-T. We can vote \u03b7 as instructed in term 4 in [5]: E [T-T-T = 1\u03b3t \u2212 1 \u00b7 0] \u2212 min-HT-T-T-T-T-T-T-T-T-T-2Lbest 16mn lognApplied Lbest \u2264 Tn2 and m = O (n log n) (by selecting a suitable sorting network [1]) into the above inequality, we will achieve the desired result."}], "references": [{"title": "The relaxation method of finding the common point of convex sets and its application to the solution of problems in convex programming", "author": ["Lev M Bregman"], "venue": "USSR computational mathematics and mathematical physics,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1967}, {"title": "Prediction, learning, and games", "author": ["Nicolo Cesa-Bianchi", "G\u00e1bor Lugosi"], "venue": "Cambridge university press,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2006}, {"title": "Group representations in probability and statistics", "author": ["Persi Diaconis"], "venue": "Lecture Notes-Monograph Series,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1988}, {"title": "A decision-theoretic generalization of on-line learning and an application to boosting", "author": ["Yoav Freund", "Robert E Schapire"], "venue": "Journal of computer and system sciences,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1997}, {"title": "Smallest compact formulation for the permutahedron", "author": ["Michel X Goemans"], "venue": "Mathematical Programming,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "Direct and indirect algorithms for on-line learning of disjunctions", "author": ["David P Helmbold", "Sandra Panizza", "Manfred K Warmuth"], "venue": "Theoretical Computer Science,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2002}, {"title": "Predicting nearly as well as the best pruning of a decision tree", "author": ["David P Helmbold", "Robert E Schapire"], "venue": "Machine Learning,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1997}, {"title": "Learning permutations with exponential weights", "author": ["David P Helmbold", "Manfred K Warmuth"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2009}, {"title": "Tracking the best linear predictor", "author": ["Mark Herbster", "Manfred K Warmuth"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2001}, {"title": "Extended formulations in combinatorial optimization", "author": ["Volker Kaibel"], "venue": "arXiv preprint arXiv:1104.1023,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2011}, {"title": "Constructing extended formulations from reflection relations", "author": ["Volker Kaibel", "Kanstantsin Pashkovich"], "venue": "In Facets of Combinatorial Optimization,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "Optimum follow the leader algorithm", "author": ["Dima Kuzmin", "Manfred K Warmuth"], "venue": "In Learning Theory,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2005}, {"title": "The weighted majority algorithm", "author": ["Nick Littlestone", "Manfred K Warmuth"], "venue": "Information and computation,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1994}, {"title": "Efficient learning with virtual threshold gates", "author": ["Wolfgang Maass", "Manfred K Warmuth"], "venue": "Information and Computation,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1998}, {"title": "On the convex hull of huffman trees", "author": ["Jean-Fran\u00e7ois Maurras", "Thanh Hai Nguyen", "Viet Hung Nguyen"], "venue": "Electronic Notes in Discrete Mathematics,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2010}, {"title": "Predicting nearly as well as the best pruning of a planar decision graph", "author": ["Eiji Takimoto", "Manfred K Warmuth"], "venue": "Theoretical Computer Science,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2002}, {"title": "Path kernels and multiplicative updates", "author": ["Eiji Takimoto", "Manfred K Warmuth"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2003}, {"title": "Randomized online pca algorithms with regret bounds that are logarithmic in the dimension", "author": ["Manfred K Warmuth", "Dima Kuzmin"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2008}, {"title": "Online linear optimization over permutations", "author": ["Shota Yasutake", "Kohei Hatano", "Shuji Kijima", "Eiji Takimoto", "Masayuki Takeda"], "venue": "In Algorithms and Computation,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2011}], "referenceMentions": [{"referenceID": 14, "context": "Abstract The convex hull of n-symbol Huffman trees is known to have exponentially many facets/constraints [17].", "startOffset": 106, "endOffset": 110}, {"referenceID": 12, "context": "One way to create algorithms for these combinatorial problems is to use one of the well-known socalled \u201cexperts algorithms\u201d like weighted majority [15] or hedge [5] with each combinatorial object treated as an \u201cexpert\u201d.", "startOffset": 147, "endOffset": 151}, {"referenceID": 3, "context": "One way to create algorithms for these combinatorial problems is to use one of the well-known socalled \u201cexperts algorithms\u201d like weighted majority [15] or hedge [5] with each combinatorial object treated as an \u201cexpert\u201d.", "startOffset": 161, "endOffset": 164}, {"referenceID": 7, "context": "In addition to subsets, such work includes permutations [9, 21], paths [14, 19], and k-sets [20].", "startOffset": 56, "endOffset": 63}, {"referenceID": 18, "context": "In addition to subsets, such work includes permutations [9, 21], paths [14, 19], and k-sets [20].", "startOffset": 56, "endOffset": 63}, {"referenceID": 11, "context": "In addition to subsets, such work includes permutations [9, 21], paths [14, 19], and k-sets [20].", "startOffset": 71, "endOffset": 79}, {"referenceID": 16, "context": "In addition to subsets, such work includes permutations [9, 21], paths [14, 19], and k-sets [20].", "startOffset": 71, "endOffset": 79}, {"referenceID": 17, "context": "In addition to subsets, such work includes permutations [9, 21], paths [14, 19], and k-sets [20].", "startOffset": 92, "endOffset": 96}, {"referenceID": 10, "context": "Section 3 explains the extended formulation used in our setting by reviewing the work by Kaibel and Pashkovich [12].", "startOffset": 111, "endOffset": 115}, {"referenceID": 1, "context": "2 Related Work On-line learning is a rich and vibrant area, see [3] for a textbook treatment.", "startOffset": 64, "endOffset": 67}, {"referenceID": 5, "context": "The implicit representations for structured concepts (sometimes called \u2018indirect representations\u2019) have been used for a variety of problems [7, 8, 16, 18, 19].", "startOffset": 140, "endOffset": 158}, {"referenceID": 6, "context": "The implicit representations for structured concepts (sometimes called \u2018indirect representations\u2019) have been used for a variety of problems [7, 8, 16, 18, 19].", "startOffset": 140, "endOffset": 158}, {"referenceID": 13, "context": "The implicit representations for structured concepts (sometimes called \u2018indirect representations\u2019) have been used for a variety of problems [7, 8, 16, 18, 19].", "startOffset": 140, "endOffset": 158}, {"referenceID": 15, "context": "The implicit representations for structured concepts (sometimes called \u2018indirect representations\u2019) have been used for a variety of problems [7, 8, 16, 18, 19].", "startOffset": 140, "endOffset": 158}, {"referenceID": 16, "context": "The implicit representations for structured concepts (sometimes called \u2018indirect representations\u2019) have been used for a variety of problems [7, 8, 16, 18, 19].", "startOffset": 140, "endOffset": 158}, {"referenceID": 7, "context": "In the case of permutations [9, 21] and component hedge [13] the implicit representations seem to be better matched with the combinatorial structure than the explicit representation, allowing not only decreased running time but also the proof of better bounds.", "startOffset": 28, "endOffset": 35}, {"referenceID": 18, "context": "In the case of permutations [9, 21] and component hedge [13] the implicit representations seem to be better matched with the combinatorial structure than the explicit representation, allowing not only decreased running time but also the proof of better bounds.", "startOffset": 28, "endOffset": 35}, {"referenceID": 18, "context": "As in [21], the loss family provided in our approach is linear over the first order representation of the objects [4].", "startOffset": 6, "endOffset": 10}, {"referenceID": 2, "context": "As in [21], the loss family provided in our approach is linear over the first order representation of the objects [4].", "startOffset": 114, "endOffset": 117}, {"referenceID": 7, "context": "In contrast, [9] works with the second order representation, and consequently losses, which is a more general loss family (See [21] for comparison).", "startOffset": 13, "endOffset": 16}, {"referenceID": 18, "context": "In contrast, [9] works with the second order representation, and consequently losses, which is a more general loss family (See [21] for comparison).", "startOffset": 127, "endOffset": 131}, {"referenceID": 4, "context": "There have been several works aimed at efficiently describing the polytope of different combinatorial objects like permutations [6] and Huffman trees [17].", "startOffset": 128, "endOffset": 131}, {"referenceID": 14, "context": "There have been several works aimed at efficiently describing the polytope of different combinatorial objects like permutations [6] and Huffman trees [17].", "startOffset": 150, "endOffset": 154}, {"referenceID": 9, "context": "Discovered by the combinatorial optimization community, extended formulation, on which our results rely, is a general methodology to nicely describe combinatorial polyhedra [11, 12].", "startOffset": 173, "endOffset": 181}, {"referenceID": 10, "context": "Discovered by the combinatorial optimization community, extended formulation, on which our results rely, is a general methodology to nicely describe combinatorial polyhedra [11, 12].", "startOffset": 173, "endOffset": 181}, {"referenceID": 14, "context": "see [17]).", "startOffset": 4, "endOffset": 8}, {"referenceID": 9, "context": "See [11] for some of the tools for constructing such extended formulations.", "startOffset": 4, "endOffset": 8}, {"referenceID": 10, "context": "In the following subsections, we first overview the work by Kaibel and Pashkovich [12], and then extract the formulation fitting to our methodology.", "startOffset": 82, "endOffset": 86}, {"referenceID": 10, "context": "1 Constructing Extended Formulation from Reflection Relations One of the tools to construct polynomial size extended formulations is the framework developed by [12] using reflection relations.", "startOffset": 160, "endOffset": 164}, {"referenceID": 10, "context": "This framework provides an inductive construction of higher dimensional polytopes via sequence of reflection relations (see Theorem 1 in [12]).", "startOffset": 137, "endOffset": 141}, {"referenceID": 10, "context": "Theorem 1 in [12] provides the sufficient conditions for the correctness of this procedure.", "startOffset": 13, "endOffset": 17}, {"referenceID": 10, "context": "For Huffman trees, however, the sequence of comparators used in the inductive step consists of two sweeps of the elements to bubble-out the two largest elements which are associated with the two deepest leaves in the tree [12].", "startOffset": 222, "endOffset": 226}, {"referenceID": 10, "context": "Similarly, by using an arbitrary sorting network along with some additional comparators and simple linear maps, an extended formulation for Huffman trees can also be built (See Theorem 7 in [12]).", "startOffset": 190, "endOffset": 194}, {"referenceID": 7, "context": "Efficient Prediction In order to achieve efficiency, despite the vastly common idea in the literature [9, 13, 20, 21], one can avoid decomposition and do prediction directly.", "startOffset": 102, "endOffset": 117}, {"referenceID": 17, "context": "Efficient Prediction In order to achieve efficiency, despite the vastly common idea in the literature [9, 13, 20, 21], one can avoid decomposition and do prediction directly.", "startOffset": 102, "endOffset": 117}, {"referenceID": 18, "context": "Efficient Prediction In order to achieve efficiency, despite the vastly common idea in the literature [9, 13, 20, 21], one can avoid decomposition and do prediction directly.", "startOffset": 102, "endOffset": 117}, {"referenceID": 0, "context": "Since the non-negativity constraints are already in the definition of \u2206, it is possible to solve (3) by simply using iterative \u2206-projections 4 [2].", "startOffset": 143, "endOffset": 146}, {"referenceID": 7, "context": "In [9] Sinkhorn balancing is used for projection which is also a special case of iterative Bregman projection", "startOffset": 3, "endOffset": 6}, {"referenceID": 0, "context": "It is proved [2] that pk converges to the unique solution of (3).", "startOffset": 13, "endOffset": 16}, {"referenceID": 7, "context": "Although the iterative projection is only guaranteed to enter the simplex in the limit, the approaches in [9, 13] provide ways to overcome this issue.", "startOffset": 106, "endOffset": 113}, {"referenceID": 3, "context": "5 Comparisons and Conclusion Table 2 contains a comparison of the regret bounds for the new Extended-Learn algorithm, previous algorithms for permutations, and the hedge algorithm [5] which inefficiently maintains an explicit weight for each of the exponential in n logn permutations or trees.", "startOffset": 180, "endOffset": 183}, {"referenceID": 18, "context": "Using loss vectors from the general unit cube, for permutations we assume the scheduling loss from [21] that has range [0, n] per trial.", "startOffset": 99, "endOffset": 103}, {"referenceID": 7, "context": "When compared with the state of the art implicit algorithms PermELearn [9] and PermutahedLearn [21], the general Extended-Learn methodology has a small additional regret bound penalty of \u221a", "startOffset": 71, "endOffset": 74}, {"referenceID": 18, "context": "When compared with the state of the art implicit algorithms PermELearn [9] and PermutahedLearn [21], the general Extended-Learn methodology has a small additional regret bound penalty of \u221a", "startOffset": 95, "endOffset": 99}], "year": 2017, "abstractText": "The convex hull of n-symbol Huffman trees is known to have exponentially many facets/constraints [17]. This makes the standard on-line learning techniques for learning Huffman trees impractical, since they use multiplicative updates followed by projections to satisfy all of the constraints. However, there are general extended formulation techniques that encode the convex hull of Huffman trees as a polytope in a higher dimensional space with only polynomially many facets. This extended formulation methodology can also be used to encode the n-element permutahedron in O(n log n) dimensions with only a polynomial number of facets. We develop a general technique for converting these extended formulations into efficient on-line algorithms with good relative loss bounds. The resulting algorithms have nearly the same regret bounds as state of the art algorithms for permutations, and are the first efficient algorithms for the on-line learning of Huffman trees.", "creator": "LaTeX with hyperref package"}}}