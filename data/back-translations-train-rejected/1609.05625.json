{"id": "1609.05625", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Sep-2016", "title": "The MGB-2 Challenge: Arabic Multi-Dialect Broadcast Media Recognition", "abstract": "This paper describes the Arabic Multi-Genre Broadcast (MGB-2) Challenge for SLT-2016. Unlike last year's English MGB Challenge, which focused on recognition of diverse TV genres, this year, the challenge has an emphasis on handling the diversity in dialect in Arabic speech. Audio data comes from 19 distinct programmes from the Aljazeera Arabic TV channel between March 2005 and December 2015. Programmes are split into three groups: conversations, interviews, and reports. A total of 1,200 hours have been released with lightly supervised transcriptions for the acoustic modelling. For language modelling, we made available over 110M words crawled from Aljazeera Arabic website Aljazeera.net for a 10 year duration 2000-2011. Two lexicons have been provided, one phoneme based and one grapheme based. Finally, two tasks were proposed for this year's challenge: standard speech transcription, and word alignment. This paper describes the task data and evaluation process used in the MGB challenge, and summarises the results obtained.", "histories": [["v1", "Mon, 19 Sep 2016 07:57:35 GMT  (1215kb,D)", "https://arxiv.org/abs/1609.05625v1", null], ["v2", "Sun, 14 May 2017 13:32:12 GMT  (1215kb,D)", "http://arxiv.org/abs/1609.05625v2", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["ahmed ali", "peter bell", "james glass", "yacine messaoui", "hamdy mubarak", "steve renals", "yifan zhang"], "accepted": false, "id": "1609.05625"}, "pdf": {"name": "1609.05625.pdf", "metadata": {"source": "CRF", "title": "THE MGB-2 CHALLENGE: ARABIC MULTI-DIALECT BROADCAST MEDIA RECOGNITION", "authors": ["Ahmed Ali", "Peter Bell", "James Glass", "Yacine Messaoui", "Hamdy Mubarak", "Steve Renals", "Yifan Zhang"], "emails": ["mgb-admin@inf.ed.ac.uk"], "sections": [{"heading": null, "text": "Index terms - speech recognition, transmission language, transcription, multi-genre, alignment"}, {"heading": "1. INTRODUCTION", "text": "The second round of the Multi-Genre Broadcast MGB [1] challenge consisted of a controlled assessment of the Arabic language for text transcription and a supervised alignment of text by recording Aljazeera television channels. This year, MGB-2 used a multi-dialect dataset spanning more than 10 years of Arabic broadcasts. To this end, the total amount of language data searched by Aljazeera using the QCRI Advanced Transcription System (QATS) [2] amounted to approximately 3,000 hours of broadcasts with a duration of between 3 and 45 minutes. To this end, we used only those programs with transcription on their Arabic website Aljazeera.net. The authors listed alphabetically. Text transcriptions did not contain any time information. The quality of the transcription varied significantly: the most difficult were conversation programs in which language and dialectical usage overlapped. The Arabic transcriptions did not contain any temporal information either."}, {"heading": "2. MGB-2 CHALLENGE DATA", "text": "The Arabic MGB-2 Challenge used more than 1200 hours of broadcast videos recorded between 2005 and 2015 by the Arabic television station Aljazeera. These programs were transcribed manually, but not literally. In some cases, the transcript includes rewording, elimination of repetitions or summaries of what was said, e.g. in cases of overlapping speech. We found that the quality of the transcription varied significantly."}, {"heading": "2.1. Metadata challenges", "text": "Most, but not all, of the recorded programs contained the following metadata: program name, episode title, moderator Xiv: 160 9.05 625v 2 [cs.C L] May 14 2Name, guest name, speaker name, date and topic. The duration of an episode is typically 20-50 minutes, and the recorded programs can be divided into three broad categories; conversation (63%), in which a moderator talks current affairs to more than one guest; interview (19%), in which a moderator talks to a guest; and report (18%), such as news or documentaries. Conversational language, which includes the use of multiple dialects and overlapping speakers, is a challenging condition and is the typical scenario for political debates and talk show programs. Much of the recorded data used in MGB-2 was modern standard Arabic (MSA): We estimate that more than 70% of the speech included in the MDA section \"Arabic\" is not included."}, {"heading": "2.2. Data Processing and Light Alignment", "text": "In this context, it is also worth mentioning the fact that the two cases are purely theoretical, and that it is not a purely theoretical problem, but a purely theoretical problem, and that it is a purely theoretical problem."}, {"heading": "2.3. Lexicon", "text": "Two dictionaries were made available to the participants of the challenge: a graphics-based dictionary 2 with more than 900K entries in the ratio 1: 1 mapping and a phoneme dictionary 3 with more than 500K words on average with 1: 4 mappings using our previous Vowelization to Phonetization (V2P) pipeline [3]. Participants could also select any dictionary outside of the resources provided."}, {"heading": "2.4. Further Data Improvement", "text": "We found that the silence information emanating from the ASR system was in some cases inaccurate and could lead to poor segmentation, mainly because the silence model in the ASR base system [2] acted as a garbage model, absorbing non-linguistic noise and sometimes overlapping language. A number of approaches could potentially improve segmentation: a) run an ASR system with separate models for silence and non-linguistic noise; b) use an externally trained Voice Activation Detection (VAD) system and apply it to silence; c) train and use a separate model for overlap detection; d) apply a word algorithm to get better timing for each word that uses the text of each program to build an In-Domain LM. We would not expect better segmentation to have a major impact on the quality of the ASR training data."}, {"heading": "3. EVALUATION TASKS", "text": "The MGB-2 Challenge consisted of two evaluation tasks, transcription and alignment, each of which required only the above-mentioned acoustic and linguistic training data. To facilitate comparability, participants had no opportunity to add additional training data to the evaluation, and the use of the other resources provided (e.g. dictionary) was optional."}, {"heading": "3.1. Speech-to-text transcription", "text": "This is a standard language transcription task performed on a collection of entire television programs from different Arabic dialectical programs on the Aljazeera TV channel. Scoring required ASR output with word-level timings. Segments of overlapping speech were rated but not included in the main list. Overlapping speech was defined to minimize the remote regions - as far as possible at the segment level. Since the training data comes from only 19 series, some programs from the same series appeared in training, development and evaluation data. Each show in the development and evaluation group was processed independently, so that no linkage between shows was given. Data was carefully selected to cover different genres and be diverse among the five dialects. Development and evaluation came from the last month of 2015 so as not to be seen in the training data. The duration of each file was between 20 minutes and 50 minutes with a total duration of 10 hours."}, {"heading": "3.2. Alignment", "text": "In this task, participants were given a token version of the transcription, as published on the transmitter's website, with no time specification, and the task was to match the given transcription at word level with the spoken tone. Often, the original transcription deviates from the actual words spoken. Evaluation was done using a precision / retrieval measure, derived from the automatic alignment of a careful manual transcription. A word is considered to match if both start and end times are within a 100-millisecond window of the corresponding reference word. For more details on the alignment rating, click here [1]."}, {"heading": "4. BASELINE SYSTEM", "text": "The basic system included data pre-processing, data selection, acoustic modeling (AM) and speech modeling (LM), as well as decoding, allowing participants to focus on more advanced aspects of ASR and LM modeling. A Kaldi toolkit [4] was used for MGB2 and the SRILM toolkit [5] for speech modeling. The base system was trained for 250 hours using training data from 500 episodes. This system uses a standard MFCC multi-pass decoding: \u2022 The first pass is GMM FMLLR with 5,000 bound states and a total of 100K gaussies. \u2022 The second pass is trained using the MPE DNN sequence with four hidden layers and 1024 neurons per shift. \u2022 A three-gram language model is trained on normalizing the text version (overlapping the 250 hours of basic data)."}, {"heading": "5. SUBMITTED SYSTEMS AND RESULTS", "text": "In fact, the majority of them will be able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight."}, {"heading": "6. CONCLUSIONS AND FUTURE CHALLENGES", "text": "The MGB-2 challenge continued efforts to use fixed training sets for acoustic modeling and speech modeling training to build a full speech recognition system. This year, the focus was on Arabic with a multidialectical challenge. More than 1200 hours of easily monitored transcription were shared by Aljazeera TV programs, along with more than 110 million words from the Aljazeera.net web archive. We reached a broad range of participants from 13 teams. In voice modeling, the focus was on combining RNN with n-gram-based text. Both graphs and phoneme units were studied. The second task involves combining multiple deep and sequential neural network modeling for acoustic modeling. In voice modeling, the focus was on combining RNN with n-gram-based text. Both graphs and phoneme units were studied."}, {"heading": "7. REFERENCES", "text": "[1] Peter Bell, MJF Gales, Thomas Hain, Jonathan Kilgour, Pierre Lanchantin, Xunying Liu, Andrew McParland, Steve Renals, Oscar Saz, Mirjam Wester, et al. The mgb challenge: Evaluating multi-genre broadcast media recognition. In 2015 IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU), pp. 687-693. IEEE, 2015. [2] Ahmed Ali, Yifan Zhang, and Stephan Vogel. QCRI advanced transcription ssystem (QATS). In SLT, 2014. [3] Ahmed Ali, Yifan Zhang, Patrick Cardinal, Najim Dahak, Stephan Vogel, and Jim Glass. A complete kaldi recipe for building Arabic speech recognition systems. In SLT, 2014. [4] Daniel Povey, Arnab Ghoshal, Gilles Boulianne, Lukas Burget, Ondrej Glembek, Nagendra Goytok, Mirkantin Schwarz."}], "references": [{"title": "The mgb challenge: Evaluating multi-genre broadcast media recognition", "author": ["Peter Bell", "MJF Gales", "Thomas Hain", "Jonathan Kilgour", "Pierre Lanchantin", "Xunying Liu", "Andrew McParland", "Steve Renals", "Oscar Saz", "Mirjam Wester"], "venue": "IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU),", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "QCRI advanced transcription ssystem (QATS)", "author": ["Ahmed Ali", "Yifan Zhang", "Stephan Vogel"], "venue": "In SLT,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2014}, {"title": "A complete kaldi recipe for building arabic speech recognition systems", "author": ["Ahmed Ali", "Yifan Zhang", "Patrick Cardinal", "Najim Dahak", "Stephan Vogel", "Jim Glass"], "venue": "In SLT,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2014}, {"title": "The kaldi speech recognition toolkit. In IEEE 2011 workshop on automatic speech recognition and understanding, number EPFL-CONF-192584", "author": ["Daniel Povey", "Arnab Ghoshal", "Gilles Boulianne", "Lukas Burget", "Ondrej Glembek", "Nagendra Goel", "Mirko Hannemann", "Petr Motlicek", "Yanmin Qian", "Petr Schwarz"], "venue": "IEEE Signal Processing Society,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2011}, {"title": "Srilm-an extensible language modeling toolkit", "author": ["Andreas Stolcke"], "venue": "In Interspeech,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2002}, {"title": "Lightly supervised recognition for automatic alignment of large coherent speech recordings", "author": ["Norbert Braunschweiler", "Mark JF Gales", "Sabine Buchholz"], "venue": "In IN- TERSPEECH,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2010}, {"title": "Improving the arabic pronunciation dictionary for phone and word recognition with linguistically-based pronunciation rules. In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 397\u2013405", "author": ["Fadi Biadsy", "Nizar Habash", "Julia Hirschberg"], "venue": "Association for Computational Linguistics,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2009}], "referenceMentions": [{"referenceID": 0, "context": "The second round of the Multi-Genre Broadcast MGB [1] challenge is a controlled evaluation of Arabic speech to text transcription, as well as supervised word alignment using Aljazeera TV channel recordings.", "startOffset": 50, "endOffset": 53}, {"referenceID": 1, "context": "The total amount of speech data crawled from Aljazeera using the QCRI Advanced Transcription System (QATS)[2] was about 3,000 hours of broadcast programs, whose durations ranged from 3\u201345 minutes.", "startOffset": 106, "endOffset": 109}, {"referenceID": 2, "context": "All programs were aligned using the QCRI Arabic LVCSR system [3], which is grapheme-", "startOffset": 61, "endOffset": 64}, {"referenceID": 5, "context": "As shown in [6] and based on the Smith\u2013Waterman algorithm1, we used to identify matching sequences by performing local sequence alignment to determine similar regions between two strings.", "startOffset": 12, "endOffset": 15}, {"referenceID": 2, "context": "Two lexicons were made available for participants in the challenge: A grapheme-based lexicon2 and with more than 900K entries 1:1 mapping, and phoneme lexicon3 with more than 500K words average with 1:4 mappings using our previous Vowelization to Phonetization (V2P) pipeline [3].", "startOffset": 276, "endOffset": 279}, {"referenceID": 1, "context": "This was mainly because the silence model in the basline ASR system [2] acted as a garbage model, absorbing non-speech noise and sometimes overlapping speech.", "startOffset": 68, "endOffset": 71}, {"referenceID": 0, "context": "More details about alignment scoring can be found here [1].", "startOffset": 55, "endOffset": 58}, {"referenceID": 3, "context": "A Kaldi toolkit [4] recipe was made available for the MGB2, and for language modelling the SRILM [5] toolkit was used.", "startOffset": 16, "endOffset": 19}, {"referenceID": 4, "context": "A Kaldi toolkit [4] recipe was made available for the MGB2, and for language modelling the SRILM [5] toolkit was used.", "startOffset": 97, "endOffset": 100}, {"referenceID": 6, "context": "[7] with an average 1.", "startOffset": 0, "endOffset": 3}], "year": 2017, "abstractText": "This paper describes the Arabic Multi-Genre Broadcast (MGB-2) Challenge for SLT-2016. Unlike last year\u2019s English MGB Challenge, which focused on recognition of diverse TV genres, this year, the challenge has an emphasis on handling the diversity in dialect in Arabic speech. Audio data comes from 19 distinct programmes from the Aljazeera Arabic TV channel between March 2005 and December 2015. Programmes are split into three groups: conversations, interviews, and reports. A total of 1,200 hours have been released with lightly supervised transcriptions for the acoustic modelling. For language modelling, we made available over 110M words crawled from Aljazeera Arabic website Aljazeera.net for a 10 year duration 2000-2011. Two lexicons have been provided, one phoneme based and one grapheme based. Finally, two tasks were proposed for this year\u2019s challenge: standard speech transcription, and word alignment. This paper describes the task data and evaluation process used in the MGB challenge, and summarises the results obtained.", "creator": "TeX"}}}