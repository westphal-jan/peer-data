{"id": "1609.05960", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Sep-2016", "title": "Incremental Sampling-based Motion Planners Using Policy Iteration Methods", "abstract": "Recent progress in randomized motion planners has led to the development of a new class of sampling-based algorithms that provide asymptotic optimality guarantees, notably the RRT* and the PRM* algorithms. Careful analysis reveals that the so-called \"rewiring\" step in these algorithms can be interpreted as a local policy iteration (PI) step (i.e., a local policy evaluation step followed by a local policy improvement step) so that asymptotically, as the number of samples tend to infinity, both algorithms converge to the optimal path almost surely (with probability 1). Policy iteration, along with value iteration (VI) are common methods for solving dynamic programming (DP) problems. Based on this observation, recently, the RRT$^{\\#}$ algorithm has been proposed, which performs, during each iteration, Bellman updates (aka \"backups\") on those vertices of the graph that have the potential of being part of the optimal path (i.e., the \"promising\" vertices). The RRT$^{\\#}$ algorithm thus utilizes dynamic programming ideas and implements them incrementally on randomly generated graphs to obtain high quality solutions. In this work, and based on this key insight, we explore a different class of dynamic programming algorithms for solving shortest-path problems on random graphs generated by iterative sampling methods. These class of algorithms utilize policy iteration instead of value iteration, and thus are better suited for massive parallelization. Contrary to the RRT* algorithm, the policy improvement during the rewiring step is not performed only locally but rather on a set of vertices that are classified as \"promising\" during the current iteration. This tends to speed-up the whole process. The resulting algorithm, aptly named Policy Iteration-RRT$^{\\#}$ (PI-RRT$^{\\#}$) is the first of a new class of DP-inspired algorithms for randomized motion planning that utilize PI methods.", "histories": [["v1", "Mon, 19 Sep 2016 22:36:03 GMT  (1151kb,D)", "http://arxiv.org/abs/1609.05960v1", null]], "reviews": [], "SUBJECTS": "cs.RO cs.AI cs.SY", "authors": ["oktay arslan", "panagiotis tsiotras"], "accepted": false, "id": "1609.05960"}, "pdf": {"name": "1609.05960.pdf", "metadata": {"source": "CRF", "title": "Incremental Sampling-based Motion Planners Using Policy Iteration Methods", "authors": ["Oktay Arslan", "Panagiotis Tsiotras", "Daniel Guggenheim"], "emails": ["oktay.arslan@jpl.nasa.gov", "tsiotras@gatech.edu"], "sections": [{"heading": null, "text": "The RRT # algorithm has been proposed, which performs Bellman updates (also known as \"backups\") to those vertices of the graph that have the potential to be part of the optimal path (i.e. the \"promising\" vertices) during each iteration. Therefore, the RRT # algorithm uses ideas of dynamic programming and progressively converts them to randomly generated diagrams to obtain high-quality solutions. In this work, and on the basis of this key insight, we examine another class of dynamic programming algorithms to solve problems with the shortest paths to random diagrams generated by iterative sampling methods. This class of algorithms uses policy iteration instead of value iteration and is therefore better suited for massive parallelization. Unlike the RRT algorithm, improving policy during the switch step is not only performed locally, but rather on the basis of a series of vertices that are graded \"highly during the current iteration.\""}, {"heading": "1 Introduction", "text": "It poses several challenges due to the high dimensionality of the (continuous) search space, the complex geometry of unknown impracticable regions, the possibility of continuous scope for action, and the existence of differential constraints [21]. However, a commonly used approach to solving this problem is to form a diagram by uniform or non-uniform discrediting of the underlying continuous search spaces and employing one of the popular graph-based search methods (e.g. A, Dijkstra) to find a cost-effective discrete path between the initial and the last points. Oktay Arslan conducts these two phenomena during his doctoral thesis as a robotics PhD student while at the Georgia Institute of Technology, Atlanta, GA 30332-0150, USA.ar Xiv: 160 9.05 960v 1 [cs.R Oapproaches essentially as abstractions of the underlying problem and hence the quality of the solution depends on the level and the underlying problem."}, {"heading": "2 Problem Formulation and Notation", "text": "Let's configure (search) space, which is assumed as an open subset of Rd, as d + N with d + 2. The obstacle region and the target region are designated by Xobs and Xgoal, respectively as closed sets. The (open) neighborhood of a state x is the open sphere of radius r > 0 centered on x, that is, Br (x) x = {x). The initial configuration of the robot is designated by xinit Xfree. The (open) neighborhood of a state x is the open sphere of radius r > 0 centered on x, that is, Br (x) x. \""}, {"heading": "3 Overview of Dynamic Programming", "text": "Dynamic programming solves sequential decision problems that have a finite number of steps. (With respect to DP notation, our system has the following equation x (x, u) (4), in which the cost function is defined asg (x, u) = c (x, f (x, u)). (5) In the face of a sequential decision problem of form (4) - (5) it is known that the optimal cost function leads to the satisfaction of the following Bellman equation: J (x) = inf u-U (x, u) + J procedure (f (x, u) + J policy x (x), x). (6) The result of the previous optimization results in an optimal policy x-M, that is, it is an optimal interpretation (x)."}, {"heading": "4 Random Geometric Graphs", "text": "This year it is so far that it will only be a matter of time before it is ready, until it is ready."}, {"heading": "5 Proposed Approach", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 From RRGs to DP", "text": "Let G = (V, E) denote the graph constructed by the RRG algorithm in some iteration, where V and E are finite sets of vertices or edges, respectively. Based on the previous discussion, G is associated and all edge costs are positive, meaning that the cost of all cycles in G is positive. Using the notation introduced in Section 2, we can define the sequential decision system (4) on this graph, where x \u2032 ig succ (G, x) and transition costs are as in (5). As soon as a policy \u00b5 is given (optimal or not), there is a unique x \u00b2 succ (G, x), so that x \u2032 = f (x, \u00b5 (x), is designated as the parent of x. Accordingly, x is the child of x \u2032 within the framework of the policy \u00b5. Conversely, a superior mapping for each node in G defines a policy. Note that each node may have a single parent among a given policy, but may have several costs."}, {"heading": "5.2 DP Algorithms for Sampling-based Planners", "text": "The sampling-based motion planner which utilises VI, i.e., RRT #, was presented in [2]. The RRT # algorithm implements the Gauss-Seidel version of the VI algorithm and provides a sequential implementation. In this thesis, we pursue the same idea and propose a sampling-based algorithm that implements the PI algorithm as shown in Figure 1. The body of the PI-RRT # algorithm is close to algorithm 1. The algorithm initializes the graph in line 2 and gradually builds up the graph of xgoal towards xinit. The algorithm includes a new vertex and a few new edges in the existing graph. If this new information has the potential to improve the existing policy, then a slightly modified PI algorithm is called in the wake of the replan process. Specifically, and for the sake of numerical efficiency, the policy is shown as only one part of the potential."}, {"heading": "6 Theoretical Analysis", "text": "The main purpose of this section is to show that the proposed PI-RRT # algorithm inherits the positive properties of the RRG and RRT \u00b2 algorithms and is therefore asymptotically optimal, almost certainly. The result is trivial if iteration on all vertices of the current graph Gk at the kth. Ideal and for the sake of numerical efficiency, we want to push policy improvement only on those vertices that have the potential to be part of the optimal solution, and only on those vertices that may not have the potential to be part of the optimal solution. Ideally, and for the sake of numerical efficiency, we would like policy improvement to be based only on those vertices that have the potential of the optimal solution, and only on those vertices that require more detailed analysis, since we have an estimate of this set of (so-called promising) vertices."}, {"heading": "7 Numerical Simulations", "text": "The goal was to find the shortest way to minimize the Euclidean distance from a starting point to a target point. Results were averaged over 100 studies and each study was conducted for 10,000 trial series. No vertex rejection rule is applied during the enlargement process. We then calculated the total time required to complete a study and the time spent on non-planning (sampling, extension, etc.) and the planning-related algorithm procedures, separately."}, {"heading": "8 Conclusion", "text": "We show that a connection between DP and RRGs can produce different types of sample-based motion planning algorithms that use ideas from dynamic programming, which ensures asymptotic optimality (with a probability of one) because the number of samples tends to be infinite. Applying policy iteration instead of value iteration during the recovery step can offer several advantages, such as fully parallel implementation, avoiding sorting and maintaining a queue of all samples in the diagram, etc. We have implemented these ideas in the replanning step of the RRT # algorithm. The proposed PIRRT # algorithm can be massively paralleled, which can be exploited by taking advantage of the latest computational and technological advances in the GPUs. This is part of the ongoing work."}], "references": [{"title": "Machine Learning and Dynamic Programming Algorithms for Motion Planning and Control", "author": ["O. Arslan"], "venue": "PhD Thesis, Georgia Institute of Technology,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "Use of relaxation methods in sampling-based algorithms for optimal motion planning", "author": ["O. Arslan", "P. Tsiotras"], "venue": "In IEEE International Conference on Robotics and Automation,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2013}, {"title": "Dynamic programming guided exploration for sampling-based motion planning algorithms", "author": ["O. Arslan", "P. Tsiotras"], "venue": "In IEEE International Conference on Robotics and Automation,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2015}, {"title": "Dynamic programming principles for sampling-based motion planners", "author": ["O. Arslan", "P. Tsiotras"], "venue": "IEEE International Conference on Robotics and Automation,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2015}, {"title": "Abstract Dynamic Programming", "author": ["D. Bertsekas"], "venue": "Athena Scientific,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2013}, {"title": "Dynamic Programming and Optimal Control, volume 1", "author": ["D.P. Bertsekas"], "venue": "Athena Scientific,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2000}, {"title": "A note on two problems in connexion with graphs", "author": ["E.W. Dijkstra"], "venue": "Numerische Mathematik,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1959}, {"title": "Batch informed trees (BIT*): Sampling-based optimal planning via the heuristically guided search of implicit random geometric graphs", "author": ["J.D. Gammell", "S.S. Srinivasa", "T.D. Barfoot"], "venue": "In IEEE International Conference on Robotics and Automation,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "A formal basis for the heuristic determination of minimum cost paths", "author": ["P.E. Hart", "N.J. Nilsson", "B. Raphael"], "venue": "IEEE Transactions on Systems Science and Cybernetics,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1968}, {"title": "Fast marching tree: A fast marching samplingbased method for optimal motion planning in many dimensions", "author": ["L. Janson", "E. Schmerling", "A. Clark", "M. Pavone"], "venue": "The International Journal of Robotics Research,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2015}, {"title": "Optimal kinodynamic motion planning using incremental sampling-based methods", "author": ["S. Karaman", "E. Frazzoli"], "venue": "In IEEE Conference on Decision and Control,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2010}, {"title": "Sampling-based algorithms for optimal motion planning", "author": ["S. Karaman", "E. Frazzoli"], "venue": "The International Journal of Robotics Research,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2011}, {"title": "Probabilistic roadmaps for path planning in high-dimensional configuration spaces", "author": ["L.E. Kavraki", "P. \u0160vestka", "J.-C. Latombe", "M.H. Overmars"], "venue": "IEEE Transactions on Robotics and Automation,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1996}, {"title": "Planning Algorithms", "author": ["S.M. LaValle"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2006}, {"title": "Rapidly-exploring random trees: Progress and prospects", "author": ["S.M. Lavalle", "Kuffner J. J"], "venue": "In Algorithmic and Computational Robotics: New Directions,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2001}, {"title": "Randomized kinodynamic planning", "author": ["S.M. LaValle", "J.J. Kuffner"], "venue": "The International Journal of Robotics Research (IJRR),", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2001}, {"title": "RRTx: Real-time motion planning/replanning for environments with unpredictable obstacles", "author": ["M. Otte", "E. Frazzoli"], "venue": "In Algorithmic Foundations of Robotics XI,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2015}, {"title": "C-FOREST: Parallel shortest-path planning with super linear speedup", "author": ["Michael Otte", "Nikolaus Correll"], "venue": "IEEE Transactions on Robotics,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2013}, {"title": "Heuristics : Intelligent Search Strategies for Computer Problem Solving", "author": ["J. Pearl"], "venue": "Addison-Wesley Pub. Co,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1984}, {"title": "Random Geometric Graphs", "author": ["M.D. Penrose"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2003}, {"title": "Complexity of the movers problem and generalizations extended abstract", "author": ["J.H. Reif"], "venue": "In IEEE Symposium on Foundations of Computer Science (FOCS),", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1979}], "referenceMentions": [{"referenceID": 20, "context": "It poses several challenges due to the high-dimensionality of the (continuous) search space, the complex geometry of unknown infeasible regions, the possibility of a continuous action space, and the presence of differential constraints [21].", "startOffset": 236, "endOffset": 240}, {"referenceID": 6, "context": "Despite this drawback, representing the robot motion planning problem as a graph search problem has several merits, especially since heuristic graph search-based methods provide strong theoretical guarantees such as completeness, optimality, or bounded suboptimality [7, 9, 19].", "startOffset": 267, "endOffset": 277}, {"referenceID": 8, "context": "Despite this drawback, representing the robot motion planning problem as a graph search problem has several merits, especially since heuristic graph search-based methods provide strong theoretical guarantees such as completeness, optimality, or bounded suboptimality [7, 9, 19].", "startOffset": 267, "endOffset": 277}, {"referenceID": 18, "context": "Despite this drawback, representing the robot motion planning problem as a graph search problem has several merits, especially since heuristic graph search-based methods provide strong theoretical guarantees such as completeness, optimality, or bounded suboptimality [7, 9, 19].", "startOffset": 267, "endOffset": 277}, {"referenceID": 12, "context": "Such planners, notably, PRM [13] and RRT [15, 16, 14], have been proven to be successful in solving many high-dimensional real-world planning problems.", "startOffset": 28, "endOffset": 32}, {"referenceID": 14, "context": "Such planners, notably, PRM [13] and RRT [15, 16, 14], have been proven to be successful in solving many high-dimensional real-world planning problems.", "startOffset": 41, "endOffset": 53}, {"referenceID": 15, "context": "Such planners, notably, PRM [13] and RRT [15, 16, 14], have been proven to be successful in solving many high-dimensional real-world planning problems.", "startOffset": 41, "endOffset": 53}, {"referenceID": 13, "context": "Such planners, notably, PRM [13] and RRT [15, 16, 14], have been proven to be successful in solving many high-dimensional real-world planning problems.", "startOffset": 41, "endOffset": 53}, {"referenceID": 11, "context": "However, the resulting paths could be arbitrarily suboptimal [12].", "startOffset": 61, "endOffset": 65}, {"referenceID": 11, "context": "Recently, asymptotically optimal variants of these algorithms, such as PRM\u2217 and RRT\u2217 have been proposed [12], in order to remedy the undesirable behavior of the original RRT-like algorithms.", "startOffset": 104, "endOffset": 108}, {"referenceID": 11, "context": "The seminal work of [12] has sparked a renewed interest to asymptotically optimal probabilistic, samplingbased motion planners.", "startOffset": 20, "endOffset": 24}, {"referenceID": 11, "context": "Several variants have been proposed that utilize the original ideas of [12]; a partial list includes [2, 3, 1, 10, 17].", "startOffset": 71, "endOffset": 75}, {"referenceID": 1, "context": "Several variants have been proposed that utilize the original ideas of [12]; a partial list includes [2, 3, 1, 10, 17].", "startOffset": 101, "endOffset": 118}, {"referenceID": 2, "context": "Several variants have been proposed that utilize the original ideas of [12]; a partial list includes [2, 3, 1, 10, 17].", "startOffset": 101, "endOffset": 118}, {"referenceID": 0, "context": "Several variants have been proposed that utilize the original ideas of [12]; a partial list includes [2, 3, 1, 10, 17].", "startOffset": 101, "endOffset": 118}, {"referenceID": 9, "context": "Several variants have been proposed that utilize the original ideas of [12]; a partial list includes [2, 3, 1, 10, 17].", "startOffset": 101, "endOffset": 118}, {"referenceID": 16, "context": "Several variants have been proposed that utilize the original ideas of [12]; a partial list includes [2, 3, 1, 10, 17].", "startOffset": 101, "endOffset": 118}, {"referenceID": 1, "context": "The recently proposed RRT algorithm, for instance, utilizes a Gauss-Seidel version of asynchronous value iteration [2, 3] to speed up the convergence of RRT\u2217.", "startOffset": 115, "endOffset": 121}, {"referenceID": 2, "context": "The recently proposed RRT algorithm, for instance, utilizes a Gauss-Seidel version of asynchronous value iteration [2, 3] to speed up the convergence of RRT\u2217.", "startOffset": 115, "endOffset": 121}, {"referenceID": 9, "context": "Extensions based on similar ideas as the RRT algorithm include the FMT* algorithm [10], the RRTx algorithm [17], and the BIT* algorithm [8].", "startOffset": 82, "endOffset": 86}, {"referenceID": 16, "context": "Extensions based on similar ideas as the RRT algorithm include the FMT* algorithm [10], the RRTx algorithm [17], and the BIT* algorithm [8].", "startOffset": 107, "endOffset": 111}, {"referenceID": 7, "context": "Extensions based on similar ideas as the RRT algorithm include the FMT* algorithm [10], the RRTx algorithm [17], and the BIT* algorithm [8].", "startOffset": 136, "endOffset": 139}, {"referenceID": 3, "context": "Some preliminary results were presented in [4].", "startOffset": 43, "endOffset": 46}, {"referenceID": 5, "context": "Second, for a given graph, determination of the optimal policy is obtained after a finite number of iterations since the policy space is finite [6].", "startOffset": 144, "endOffset": 147}, {"referenceID": 5, "context": "Furthermore, an improper policy has finite cost, starting from every initial state, if and only if all the cycles of the corresponding graph have non-negative cost [6].", "startOffset": 164, "endOffset": 167}, {"referenceID": 4, "context": "Convergence of the DP algorithms is proven if the graph is connected and the costs of all its cycles are positive [5].", "startOffset": 114, "endOffset": 117}, {"referenceID": 4, "context": "The generated sequence converges to the optimal cost function due to contraction property of the Bellman operator T [5].", "startOffset": 116, "endOffset": 119}, {"referenceID": 10, "context": "All these questions have been addressed in a series of recent papers [11, 12] so we will not elaborate further on the graph construction.", "startOffset": 69, "endOffset": 77}, {"referenceID": 11, "context": "All these questions have been addressed in a series of recent papers [11, 12] so we will not elaborate further on the graph construction.", "startOffset": 69, "endOffset": 77}, {"referenceID": 5, "context": "For more details, the interested reader can peruse [6] or [20].", "startOffset": 51, "endOffset": 54}, {"referenceID": 19, "context": "For more details, the interested reader can peruse [6] or [20].", "startOffset": 58, "endOffset": 62}, {"referenceID": 19, "context": "If the connection radius is chosen less than the critical value r\u2217, then, multiple disconnected clusters occur almost surely as n goes to infinity [20].", "startOffset": 147, "endOffset": 151}, {"referenceID": 11, "context": "Recently, novel connections have been made between motion planning algorithms and the theory of random geometric graphs [12].", "startOffset": 120, "endOffset": 124}, {"referenceID": 11, "context": "The authors in [12] showed that the RRG algorithm yields a consisted discretization of the underlying continuous configuration space, i.", "startOffset": 15, "endOffset": 19}, {"referenceID": 1, "context": ", RRT, was presented in [2].", "startOffset": 24, "endOffset": 27}, {"referenceID": 17, "context": "Such heuristics, have been previously used to focus the search of sampling-based planner, see for example [18, 2].", "startOffset": 106, "endOffset": 113}, {"referenceID": 1, "context": "Such heuristics, have been previously used to focus the search of sampling-based planner, see for example [18, 2].", "startOffset": 106, "endOffset": 113}, {"referenceID": 5, "context": "If the algorithm terminates after more than or equal to N (xinit) policy improvement steps, then optimality follows directly from Lemma 5, since the Replan procedure is thus guaranteed to terminate after a finite number of policy improvement steps, owing to the properties of policy iteration and the fact that the policy space is finite [6].", "startOffset": 338, "endOffset": 341}], "year": 2016, "abstractText": "Recent progress in randomized motion planners has led to the development of a new class of samplingbased algorithms that provide asymptotic optimality guarantees, notably the RRT\u2217 and the PRM\u2217 algorithms. Careful analysis reveals that the so-called \u201crewiring\u201d step in these algorithms can be interpreted as a local policy iteration (PI) step (i.e., a local policy evaluation step followed by a local policy improvement step) so that asymptotically, as the number of samples tend to infinity, both algorithms converge to the optimal path almost surely (with probability 1). Policy iteration, along with value iteration (VI) are common methods for solving dynamic programming (DP) problems. Based on this observation, recently, the RRT algorithm has been proposed, which performs, during each iteration, Bellman updates (aka\u201cbackups\u201d) on those vertices of the graph that have the potential of being part of the optimal path (i.e., the \u201cpromising\u201d vertices). The RRT algorithm thus utilizes dynamic programming ideas and implements them incrementally on randomly generated graphs to obtain high quality solutions. In this work, and based on this key insight, we explore a different class of dynamic programming algorithms for solving shortest-path problems on random graphs generated by iterative sampling methods. These class of algorithms utilize policy iteration instead of value iteration, and thus are better suited for massive parallelization. Contrary to the RRT\u2217 algorithm, the policy improvement during the rewiring step is not performed only locally but rather on a set of vertices that are classified as \u201cpromising\u201d during the current iteration. This tends to speed-up the whole process. The resulting algorithm, aptly named Policy Iteration-RRT (PI-RRT) is the first of a new class of DP-inspired algorithms for randomized motion planning that utilize PI methods.", "creator": "LaTeX with hyperref package"}}}