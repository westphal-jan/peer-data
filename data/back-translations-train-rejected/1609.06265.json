{"id": "1609.06265", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Sep-2016", "title": "An Ensemble Blocking Scheme for Entity Resolution of Large and Sparse Datasets", "abstract": "Entity Resolution, also called record linkage or deduplication, refers to the process of identifying and merging duplicate versions of the same entity into a unified representation. The standard practice is to use a Rule based or Machine Learning based model that compares entity pairs and assigns a score to represent the pairs' Match/Non-Match status. However, performing an exhaustive pair-wise comparison on all pairs of records leads to quadratic matcher complexity and hence a Blocking step is performed before the Matching to group similar entities into smaller blocks that the matcher can then examine exhaustively. Several blocking schemes have been developed to efficiently and effectively block the input dataset into manageable groups. At CareerBuilder (CB), we perform deduplication on massive datasets of people profiles collected from disparate sources with varying informational content. We observed that, employing a single blocking technique did not cover the base for all possible scenarios due to the multi-faceted nature of our data sources. In this paper, we describe our ensemble approach to blocking that combines two different blocking techniques to leverage their respective strengths.", "histories": [["v1", "Tue, 20 Sep 2016 17:44:28 GMT  (1088kb)", "http://arxiv.org/abs/1609.06265v1", null], ["v2", "Wed, 21 Sep 2016 00:26:17 GMT  (1088kb)", "http://arxiv.org/abs/1609.06265v2", null]], "reviews": [], "SUBJECTS": "cs.AI cs.DB", "authors": ["janani balaji", "faizan javed", "mayank kejriwal", "chris min", "sam sander", "ozgur ozturk"], "accepted": false, "id": "1609.06265"}, "pdf": {"name": "1609.06265.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Mayank Kejriwal", "Chris Min", "Sam Sander", "Ozgur Ozturk"], "emails": ["ozgur.ozturk}@careerbuilder.com", "mayankkejriwal@utexas.edu"], "sections": [{"heading": null, "text": "This year it is more than ever before in the history of the city."}], "references": [{"title": "Febrl: A freely available record linkage system with a graphical user interface", "author": ["P. Christen"], "venue": "Proceedings of the Second Australasian Workshop on Health Data and Knowledge Management - Volume 80, HDKM \u201908, 17\u201325. Darlinghurst, Australia, Australia: Australian Computer So-", "citeRegEx": "Christen,? 2008", "shortCiteRegEx": "Christen", "year": 2008}, {"title": "A survey of indexing techniques for scalable record linkage and deduplication", "author": ["P. Christen"], "venue": "IEEE Trans. on Knowl. and Data Eng. 24(9):1537\u20131555.", "citeRegEx": "Christen,? 2012", "shortCiteRegEx": "Christen", "year": 2012}, {"title": "Duplicate record detection: A survey", "author": ["A.K. Elmagarmid", "P.G. Ipeirotis", "V.S. Verykios"], "venue": "IEEE Trans. on Knowl. and Data Eng. 19(1):1\u201316.", "citeRegEx": "Elmagarmid et al\\.,? 2007", "shortCiteRegEx": "Elmagarmid et al\\.", "year": 2007}, {"title": "Corleone: Hands-off crowdsourcing for entity matching", "author": ["C. Gokhale", "S. Das", "A. Doan", "J.F. Naughton", "N. Rampalli", "J. Shavlik", "X. Zhu"], "venue": "Proceedings of the 2014 ACM SIGMOD International Conference on Management of Data, SIGMOD \u201914, 601\u2013612. New York, NY, USA:", "citeRegEx": "Gokhale et al\\.,? 2014", "shortCiteRegEx": "Gokhale et al\\.", "year": 2014}, {"title": "Human-powered blocking in entity resolution: A feasibility study", "author": ["W. Li", "J. Lee", "D. Lee"], "venue": "KDD Int\u2019l Workshop on Multimodal Crowd Sensing (CrowdSens), KDD \u201914, 1\u20137.", "citeRegEx": "Li et al\\.,? 2014", "shortCiteRegEx": "Li et al\\.", "year": 2014}, {"title": "Dynamic record blocking: Efficient linking of massive databases in mapreduce", "author": ["W. McNeill", "H. Kardes", "A. Borthwick"], "venue": "QDB 2012.", "citeRegEx": "McNeill et al\\.,? 2012", "shortCiteRegEx": "McNeill et al\\.", "year": 2012}, {"title": "A blocking framework for entity resolution in highly heterogeneous information spaces", "author": ["G. Papadakis", "E. Ioannou", "T. Palpanas", "C. Niedere", "W. Nejdl"], "venue": "IEEE Transactions on Knowledge and Data Engineering 25(12):2665\u2013 2682.", "citeRegEx": "Papadakis et al\\.,? 2013", "shortCiteRegEx": "Papadakis et al\\.", "year": 2013}], "referenceMentions": [{"referenceID": 1, "context": "Surveys of well-known blocking techniques such as sorted neighborhood and canopy clustering (among others) can be found in (Christen 2012) (Elmagarmid, Ipeirotis, and Verykios 2007).", "startOffset": 123, "endOffset": 138}, {"referenceID": 3, "context": "Corleone (Gokhale et al. 2014) leverages human-powered blocking via crowdsourced active learning to learn blocking rules.", "startOffset": 9, "endOffset": 30}, {"referenceID": 6, "context": "Attribute Clustering (AC) blocking (Papadakis et al. 2013) is an unsupervised technique that addresses the issue of efficiency vs effectiveness in large datasets.", "startOffset": 35, "endOffset": 58}, {"referenceID": 6, "context": "Our approach is similar to (Papadakis et al. 2013) in that we define a blocking framework which leverages multiple blocking algorithms.", "startOffset": 27, "endOffset": 50}, {"referenceID": 6, "context": "While the AC blocking method (Papadakis et al. 2013) uses a bag-oftokens approach to tokenize the entities, in doing so, the blocks are often proliferated with spurious pairs.", "startOffset": 29, "endOffset": 52}, {"referenceID": 0, "context": "The synthetic datasets (Febrl 1-3) were generated by the Febrl (Christen 2008) tool.", "startOffset": 63, "endOffset": 78}], "year": 2016, "abstractText": "Entity Resolution, also called record linkage or deduplication, refers to the process of identifying and merging duplicate versions of the same entity into a unified representation. The standard practice is to use a Rule based or Machine Learning based model that compares entity pairs and assigns a score to represent the pairs\u2019 Match/Non-Match status. However, performing an exhaustive pair-wise comparison on all pairs of records leads to quadratic matcher complexity and hence a Blocking step is performed before the Matching to group similar entities into smaller blocks that the matcher can then examine exhaustively. Several blocking schemes have been developed to efficiently and effectively block the input dataset into manageable groups. At CareerBuilder (CB), we perform deduplication on massive datasets of people profiles collected from disparate sources with varying informational content. We observed that, employing a single blocking technique did not cover the base for all possible scenarios due to the multi-faceted nature of our data sources. In this paper, we describe our ensemble approach to blocking that combines two different blocking techniques to leverage their respective strengths.", "creator": "Word"}}}