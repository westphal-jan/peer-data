{"id": "1609.06375", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Sep-2016", "title": "A Theory of Interactive Debugging of Knowledge Bases in Monotonic Logics", "abstract": "A broad variety of knowledge-based applications such as recommender, expert, planning or configuration systems usually operate on the basis of knowledge represented by means of some logical language. Such a logical knowledge base (KB) enables intelligent behavior of such systems by allowing them to automatically reason, answer queries of interest or solve complex real-world problems. Nowadays, where information acquisition comes at low costs and often happens automatically, the applied KBs are continuously growing in terms of size, information content and complexity. These developments foster the emergence of errors in these KBs and thus pose a significant challenge on all people and tools involved in KB evolution, maintenance and application.", "histories": [["v1", "Tue, 20 Sep 2016 22:31:38 GMT  (854kb,D)", "http://arxiv.org/abs/1609.06375v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["patrick rodler"], "accepted": false, "id": "1609.06375"}, "pdf": {"name": "1609.06375.pdf", "metadata": {"source": "CRF", "title": "A Theory of Interactive Debugging of Knowledge Bases in Monotonic Logics", "authors": ["Patrick Rodler"], "emails": ["patrick.rodler@aau.at"], "sections": [{"heading": null, "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "1 Introduction 1", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2 Preliminaries 13", "text": "2.1 Assumptions......................................................................................................................"}, {"heading": "3 Knowledge Base Debugging 19", "text": "3.1............................................................"}, {"heading": "4 Diagnosis Computation 28", "text": "4.1. Conflict Sets vs. Justifications. 4.2. Relation Between Conflict Sets and Diagnostics. 354.3.1. Computation. A Minimal Conflict Set. 32. 4.3. Methods for Diagnosis. Computation. 29 4.2. Relation Between Conflict Sets and Diagnostics. 354.3.1. Computation. A Minimal Conflict Set. 32. 4.3. Methods. Diagnosis. Computation."}, {"heading": "5 Interactive Knowledge Base Debugging 75", "text": "The number of unemployed in Germany increased slightly compared to the previous year, while the number of unemployed in Germany rose slightly compared to the previous year."}, {"heading": "6 Iterative Diagnosis Computation 121", "text": "6.1. STATICHS: A Static Iterative Diagnosis. Computation Algorithm..... 121. 6.1.2. Algorithm. 1216.1.1. Overview and Intuition................... 124............ 121........ Going...... Intuition........ 1276.2. DYNAMICHS: A. Dynamic Iterative Diagnosis. Examples."}, {"heading": "7 Related Work 168", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "8 Summary and Future Work 171", "text": "The vast majority of respondents are of the opinion that the vast majority of respondents is of the opinion that the vast majority of respondents is the vast majority of the vast majority of the vast majority of the vast majority of the vast majority of the vast majority of the vast majority of the vast majority of the vast majority of the vast majority of the vast majority of the vast majority of the vast majority of the vast majority of the vast majority of the vast majority of the vast majority is the vast majority of the vast majority of the vast majority of the vast majority of the vast majority of the vast majority of the vast majority of the vast majority of the vast majority of the vast majority of the vast majority of the vast majority of the vast majority of the vast majority of the vast majority of the vast majority of the vast majority of the vast majority."}, {"heading": "2.1 Assumptions", "text": "The techniques described in this paper are applicable to any logical knowledge representation formalism L, for which the condition relation 1. monotonous: is given, when a new logical formula is added to a KB KL, no condition of the KB can be invalidated, i.e. KL | = \u03b1L implies that KL \u0441\u03b2L | = \u03b1L, 2. idempotent: is given when implicit knowledge is explicitly added to a KB KL, i.e. KL | = \u03b1L and KL \u03b2L implies KL | = \u03b2L, and 3. is given when each logical formula implies itself, i.e. {\u03b1L} | = \u03b1L for all \u03b1L, and for which 4. method of reasoning exists to decide on the consistency and calculation of logical conditions of a KB."}, {"heading": "2.2 Considered Logics", "text": "This year it is so far that it will be able to convert the aforementioned brainconsecrated brainconsecrated brainconsecrated brainconsecrated brainconsecrated hirnrrteeSe to eren. iSe \"s rf\u00fc ide hirngee\u00fccsrlteeBnltee\u00fccnllteeSe, so tlrsrrrrrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrrsrrrsrrrsrsrsrrrsrrrrrsrrrrrsrrrrsrrrrrrsrrrrrrrrrrrrsrrrrrrrrrrrrsrrrrrsrrrrrrrrrrrrrrrrrrrsrrrrrrrrrrrrrrrrrrrrrrrrrrrrsrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr"}, {"heading": "2.3 Notational Remarks", "text": "In fact, we will be able to hold our own, we will be able to hold our own, we will be able to put ourselves in the lead."}, {"heading": "3.1 Parsimonious Knowledge Base Debugging", "text": "Why are minimum diagnoses interesting? First, the number of minimum diagnoses w.r.t. a DPI w.w.KPI collects all the information that explains the undesirable characteristics, i.e. the violation of requirements or test cases, the DPI. In other words, the minimum diagnoses represent all the subset-minimal possibilities to modify a minimum diagnosis. < K, to find the minimum diagnosis in a way that has brought it to a valid diagnostic solution of KPI (e.g. by simply deleting a minimum diagnosis from the KPI in the trivial case). By monotonicity of logic L, any superset of a minimum diagnosis w.r.t. a DPI is a diagnosis w.r.t. That is, aD < K, B, P, N > R can be easily reconstructed. mD < K, B, N > R. However, there is no evidence (in relation to specific test requirements and minimum cases) that would justify the selection of a DPI."}, {"heading": "3.2 Background Knowledge", "text": "In fact, it is a way in which people in the USA, in Europe, in the USA, in Europe, in Europe, in the USA, in Europe, in the USA, in Europe, in the USA, in the USA, in the USA, in the USA, in Europe, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the"}, {"heading": "4.1 Conflict Sets versus Justifications", "text": "The concept of conflict is closely related to the concept of justification [25, 26, 27, 23, 24, 28], which is often used in the field of the semantic web (cf. Section 2.2) to find minimal explanations for certain contexts in DL ontologies. [4] or MUPS (Minimal Unfiability Preserving Sub-TBoxes) [68], where the latter term is used predominantly in the context of ontology, the concept of conflict is set, on the other hand, it was adopted mainly in the diagnostic community [60, 44, 57, 87, 17]. In this section we want to establish a relationship between these two widely used tools of definition."}, {"heading": "4.2 The Relation between Conflict Sets and Diagnoses", "text": "< K, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S"}, {"heading": "4.3 Methods for Diagnosis Computation", "text": "Two common methods for calculating the (minimum) diagnoses [74, 63] are the QuickXPlain algorithm [36] (abbreviated QX) and a Hit Set search tree [60, 22] (abbreviated HS), which serves as a deterministic method for calculating a minimum conflict set w.r.t. a given DPI < K, B, P, N > R per call. Since a diagnosis is a set of all minimum conflict sets, more than a minimum conflict set is generally required to calculate a diagnosis. However, due to its determinism, QX always calculates the same minimum conflict set for the same input DPI. Thus, in order to calculate different (or all) minimum conflict sets, the input to QX must be varied accordingly. This can be done by using HS, which serves as a search tree to systematically and successively explore all minimum conflict sets, etc."}, {"heading": "4.3.1 Computation of a Minimal Conflict Set", "text": "The QX algorithms take a DPI < Korig, Borig, P, N > R using some monotonic logic L as input and return of a minimum conflict. < Korig, Borig, P, N > R as output if a particular conflict exists for the DPI, and \"no conflict\" otherwise.Monotonic properties are essentially not applied to find a minimum subset of Xmin for an input set X that has a specific conflict with completely different characteristics such as propositional dissatisfaction or overstressability. The only postulated precondition for QX is that a monotonic property is a monotonic property. A property is monotonic property that returns a binary function only if the property for the input set 1 and 0 DIAGNOSCOMPUMPUPATIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONI"}, {"heading": "4.3.2 Correctness of Conflict Set Computation", "text": "This section is dedicated to proving the veracity of algorithm 1. & < KPI > > returns of QX through various terms, which are eventually exploited to determine the overall soundness of QX.The QX algorithm accepts a DPI < Korig, Borig, P, N > R via some monotonous L language as input and return of a minimal conflict sentence C Korig w.r.t. < Korig, Borig, P, N > R as output. First, the algorithm checks whether Korig is a valid conflict."}, {"heading": "4.4 Hitting Set Tree Based Diagnosis Computation", "text": "This year, it is more than ever before in the history of the country in which it is a country, in which it is a country, in which it is not a country, but in which it is a country, a country, a city and a country."}, {"heading": "4.5 Diagnosis Probability Space", "text": "The induction of a probability range [15] via diagnoses facilitates the inclusion of well-established probability theories in the process of KB debugging. < D = > Q = > Q = > Q = > Q = < D = max. (see Chapter 5) The true diagnosis is hereinafter referred to as Dt. The probability range of all diagnoses. From the perspective of probability theory, a diagnosis can be regarded as an atomic event within a probability range < D, p > probability is defined as: \u2022 the sample space consisting of all possible diagnoses w.r.t. a DPI < K, B, P, N > R that a diagnosis can be regarded as an atomic event within a probability range < D, B, P, p >."}, {"heading": "4.5.1 Construction of a Probability Space", "text": "This year it is more than ever before."}, {"heading": "4.5.2 Using Probabilities for Diagnosis Computation", "text": "In fact, it is the case that most of us are able to abide by the rules that they have imposed on themselves. (...) In fact, it is the case that they are able to abide by the rules. (...) In fact, it is the case that they are able to abide by the rules. (...) In fact, it is the case that they are able to abide by the rules. (...) In fact, it is the case that they are able to abide by the rules. (...) In fact, it is as if they are abiding by the rules. \"(...)"}, {"heading": "4.5.3 Correctness of Weighted Diagnosis Computation", "text": "First, we show the completeness of the algorithm 2 and create some nodes that are only able to make a diagnosis once a year. < K, P, N > R, N > R, Dcalc, N > R, N > R, K > R, B > R, K > R, K > R, Dcalc, N > R, N > R, D, D, D > R, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, R, K, K, R, R, R, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, R, K, R, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, R, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K, K,"}, {"heading": "4.5.4 Using Probabilities to Compute Minimum Cardinality Diagnoses", "text": "The function p: K \u2192 (0, 0.5) can be defined in such a way that first the minimum cardinality is determined instead of the maximum probability diagnosis. For this purpose p () is specified as the fixed point function, which maps each formula ax-K to one and the same constant value p (ax): = c, where c is any real number, so that 0 < c < 0.5, e.g. c: = 0.3. That diagnoses are found in this setting in the order of the ascending cardinality is a simple sequence of sequence 4.7.Example 4.7 Let us now examine how such formulas and diagnostic probabilities would be constructed for the DPI example shown in Table 4.1. Suppose that the formula K in the DPI was formulated by a single user u, for whom the personal error probabilities of the syntactic elements K-K are represented in the first series of Table 4.4 as the last tactical probability."}, {"heading": "4.6 Non-Interactive Debugging Algorithm", "text": "The algorithm requires the input of all the parameters required by algorithm 2 and an additional parameter to obtain an automatic (true) or manual (false) diagnosis. If the automatic (false) diagnosis of algorithm 3 (algorithm 2) is related to the parameters provided, the user will be able to select the diagnosis manually. Alternatively, the system calls HS (algorithm 2) with the parameters as they are available, but with the number of minimal diagnoses returned by HS, only the most likely minimum diagnosis of the user who can select the diagnosis manually in D. Alternatively, the system HS will use the parameters provided."}, {"heading": "5.1 User Interaction", "text": "The idea of interactive KB debugging is to consult a user iteratively and ask him to provide additional information about the desired and undesirable effects of the correct KB. Thus, the principle of interactive KB debugging is based on that of sequential diagnostics, proposed by [44] as an iterative way to locate the faulty components (among an initially large set of possibilities) in faulty digital circuits by performing repeated (highly informative) measurements. We have shown in our previous work how sequential diagnoses can be applied to KBs (ontologies). In our approach, selecting what (a pool of possible) to ask a next user is an active learning approach."}, {"heading": "5.1.1 Queries", "text": "In this case, it is only one of many. < D > K > K > K > K > K > K > K > K > K > K & K \". K & K & K\". K & K \". K & K\". K & K \". K & K\". K & K \". K & K\". K & K \". K & K\". K & K \". K & K\". K & K \". K & K\". K & K \". K & K\". K & K \". K & K\". K & K \".K\". K & K \".K\".K \". K\".K \".K\". K \"K\".K \"K\". K \"K\" K \".K\" K \"K\".K \"K\" K \".K\" K \".K\".K. K \".K\".K \".K. K\" K. K \"K\" K \"K\".K \"K\" K \"K\".K \"K\" K \"K\".K \"K\" K \"K\".K \"K\" K \"K\" K \".K\" K \"K\" K \"K\".K \"K\" K \"K\" K \"K\".K \"K\" K \"K\" K \"K\".K \"K\" K \"K\" K \"K\" K \".K\" K \"K\" K \"K\" K \".K\" K \"K\" K \"K\" K \"K\" K \"K\".K \"K\" K \"K\" K \"K\" K \"K\" K \"K\" K \".K\" K \"K\" K \"K\" K \"K\" K \".K\" K \"K\" K \"K\" K \"K\" K \"K\" K. K \"K\" K \"K\" K \"K\" K \"K\" K \"K\" K \"K. K\" K \"K\" K \"K\" K \"K\" K \"K\" K \"K\" K \"K\" K \"K\".K \"K\" K \"K\" K \"K\" K \"K\" K \"K.\" K \"K\" K \"K\" K \"K\" K \"K\" K \"K\" K \"K\" K \"K\" K \"K\" K"}, {"heading": "5.1.2 Leading Diagnoses", "text": "The query generation requires a pre-calculated set of minimum diagnoses D'mD < K, B, P, N > R, which serves as a representative for all minimum diagnoses mD < K, B, P, N > R. As previously mentioned, the calculation of the entire set mD < K, B, P, N > R is generally not traceable within a reasonable time. Normally, D is defined as a set of highly probable or minimal diagnoses, the response of which allows a distinction to be made between diagnoses in mD < K, P, N > R. < K, B, N > R [74]. Leading diagnoses D are then evaluated to determine a query Q whose response allows a distinction to be made between diagnoses in mD < K, B, P, N > R. That is, a subset of mD < K, B, P, N > R, which is \"incompatible.\""}, {"heading": "5.1.3 Q-Partitions", "text": "K & # 160; K & # 160; K & # 160; K & # 160; K & # 160; K & # 160; K & # 160; K & # 160; K & # 160; K & # 160; K & # 160; K & # 160; K & # 160; K & # 160; K & # 160; K & # 160; K & # 160; K & # 160; K & # 160; K & # 160; K & # 160; K & # 160; K & # 160; K & # 160; K & # 160; K & # 160; K & # 160; K & # 160; K; K & # 160; K; K; K & # 160; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; 160; K; K; K; K; K; K; 160; K; K; K; K; 160; K; K; K; 160; K; K; K; 160; K; K; K; K; 160; K; K; K; K; 160; K; K; K; K; 160; K; K; K; K; K; K; 160; K; K; K; K; K; K; K; and 160; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; and 160; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; 160; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; 160; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K; K;"}, {"heading": "5.1.4 Interpretation of Q-Partitions", "text": "Da K \"i die L\u00f6sung KB (together with B.\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"Q\" Q \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \""}, {"heading": "5.1.5 The Relation between a Query and its Q-Partition", "text": "The following statement shows the relationship between a query and its q partition and provides a criterion enabling it to check whether a set of logical formulas is a query. < K, B, P, N > R is a query. < K, B, P, D, P, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D"}, {"heading": "5.1.6 Existence of Queries", "text": "& & & # 160; & & & # 160; & # 160; & & # 160; & & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & & # 160; & & & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & & & # 160; & & & & # 160; & & & & & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & & # 160; & & & & # 160; & & & & & # 160; & & & & & & # 160; & & & & & & & & # 160; & & & & & & & & & # 160; & & & & & & & & # 160; & & & & & & & & # 160; & & & & & & # 160; & & & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & & # 160; & & & # 160; & & & # 160; & & & & # 160; & & & & & # 160; & & & # 160; & & & # 160; & & & # 160; & & & & # 160; & & & & & & & # 160; & & & & & & # 160; & & & & # 160; & & & & & & & & & & # 160; & & & & & & & & & # 160; & & & & & & & & & & & & # 160; & & & & & & & & & # 160; & & & & & & & & & & & & & # 160; & & & & & & & & & & & & # 160; & & & & & & & & & & & & & & # 160; & & & & & & & & & & & & & & & # 160; & & & & & & & & & & & & & & & & & & & & & &"}, {"heading": "5.2 Query Generation", "text": "This year, the number of unemployed people slipping into unemployment has skyrocketed, while the number of unemployed people has skyrocketed, skyrocketed."}, {"heading": "5.2.1 Generation of a Pool of Queries", "text": "The main function GETPOOLOFQUERIES of the algorithms 4, B, B, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q, Q,"}, {"heading": "5.2.2 Discussion of Query Pool Generation", "text": "The question that arises in this context is whether it is a question of a way and a way in which it is a question of a way in which people are able to understand the world, in which they are able to understand the world, in which they are able to understand the world, in which they are able to understand the world, in which they are able to understand the world, in which they are able to understand the world, in which they are able to understand the world, in which they are able to understand the world, in which they are able to understand the world, in which they are able to understand the world, in which they are able to understand the world, in which they are able to understand the world, in which they are able to understand the world, in which they are able to understand, in which they are able to understand, in which they are able to understand the world, in which they are able to understand the world, in which they are able to understand the world, in which they are able to understand the world, in which they are able to understand the world, in which they are able to understand the world, in which they are able to understand, in which they are able to understand the world in which they are able to understand, in which they are able to understand, in which they are able to understand the world in which they are able to understand, in which they are able to understand, in which they are able to understand the world in which they are able to understand, in which they are able to understand, in which they are able to understand, in which they are able to understand the world in which they are able to understand, in which they are able to understand, in which they are able to understand, in which they are able to understand, in which they are able to understand, in which they are able to understand, in which they are able to understand, in which they are able to understand, in which they are able to understand, in which they are able to understand, in which they are able to understand, in which they are able to understand, in which they are able to understand, in which they are able to understand, in which they are able to understand, in which they are able to understand, in which they are able to understand, in which they are able to understand, in which they are able to understand, in which they are able to understand, in which they are able to understand, in which they are able to understand"}, {"heading": "5.2.3 Minimization of Queries", "text": "In this case, the monotonous property is not the imperfection of a part of the QX, but the imperfection of a part of the QX, the QX, the MINQ, the MINQ, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI, the QI"}, {"heading": "5.2.4 Soundness of Query Minimization", "text": "The Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q"}, {"heading": "5.2.5 Complexity of Query Pool Generation", "text": "The question that arises is to what extent it is in fact a problem for which there is no solution. (...) The question is whether there is a solution at all. (...) The question is to what extent there is a solution at all. (...) The question is to what extent there is a solution at all. (...) The question is only to what extent there is a solution. (...) The question is only to what extent it is a solution. (...) The question is to what extent it is a solution. (...) The question is only to what extent it is a solution. (...) The question is only to what extent it is a solution. (...) The question is to what extent it is a solution. (...) The question is to what extent it is a solution. (...) The question is to what extent it is a solution. (...) The question is only to what extent it is a solution. (...) The question is to what extent it is a solution."}, {"heading": "5.2.6 Shortcomings of Query Pool Generation", "text": "This year, as never before in the history of a country in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country"}, {"heading": "5.2.7 Correctness of Query Pool Generation", "text": "The following statement confirms the correctness of algorithm 4, i.e. the function GETPOOLOFQUERIES > Q > Q > Q = Q Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q"}, {"heading": "5.3 An Algorithm for Interactive Knowledge Base Debugging", "text": "In this section, we will describe an algorithm for interactive KB debugging (algorithm 5) that implements all the functionality required by an interactive debugging system. All other algorithms presented so far will be subroutines of algorithm 5 that will be called either directly or indirectly by it. Before explaining and discussing algorithm 5 in detail, we will give the reader a rough and informal overview of the input, output, and actions of the algorithm in the following section to make it easier to digest the details of the algorithm. Note 5.11 Note: When we speak of input DPI in the following, we refer to the input DPI < K, B, P, N > R provided as input to algorithm 5, we mean the current DPI < K, B, P, P, P, P where P \"and N,\" with P \"all positive and negative test cases added to PI input, not by current DPI execution < B, not by current DPI, DPI."}, {"heading": "5.3.1 Interactive Debugging Algorithm: Overview", "text": "Input: A permissible DPI and some meta-information, where the latter consists of \u2022 error probabilities of syntactic elements present in the KB, CHAPTER 5. INTERACTIVE KNOWLEDGE BASE DEBUGGING 103 \u2022 a minimum and desired number of leading diagnoses, \u2022 a desired maximum response time (time between two consecutive queries that are presented to the user), \u2022 a maximum error tolerance (roughly speaking, the likelihood that an undesired solution KB is presented as a result), \u2022 a measure for selecting the query within a given set of queries, \u2022 a parameter that determines the size of the calculated pool of queries in each iteration and \u2022 a parameter that indicates the way in which the specified set tree is used for calculating the leading leading leading leading leading leading leading diagnostics (determines which query is the best query within a given set of queries)."}, {"heading": "5.3.2 Interactive Debugging Algorithm: Detailed Description", "text": "To describe the detailed process of algorithm 5, we first characterize the input arguments, output, and meaning of the variables used, and then provide a step-by-step textual description of the actions that the algorithm performs. Chapter 5. INTERACTIVE Knowledge BASE DEBUGGING 104"}, {"heading": "5.3.2.1 Input Arguments", "text": "This is the best way in which the PSD-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-"}, {"heading": "5.3.2.2 Output", "text": "The results of the algorithms 5 (Dmax) can be explained as follows: < D (max) -K (max) -K (max) -K (max) -K (max) -K (max) -K (max) -K (max) -K (max) -K (max) -K (max) -K (max) -K (max) -K (max) -K (max) -K (max) -K (max) -K (max) -K (max) -D (max) -K (max) -D) -D (D) -D (D) -K) -K (max) -K (max) -K) -K (max) -K (max) -K) -D (max) -K (max) -K (max) max (K) -K () -K) -K (max) -K (max) -K (D) -K (max) -K (max) -K (D) -K (max) -K (max) -K (K) -K (max) -K (max) -K (max) -K (D) -K (max) -K (max)."}, {"heading": "5.3.2.3 Variables", "text": "The diagnostic systems used by him are the following: \"D,\" \"D,\" \"D,\" \"D,\" \"D,\" \"D,\" \"D,\" \"D,\" \"D,\" \"D,\" \"D,\" \"D,\" \"D,\" \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \"\", \",\" \",\", \",\", \",\" \",\", \",\" \",\", \",\", \"\", \",\", \"\", \",\", \",\" \",\", \"\", \"\", \",\" \",\" \",\", \",\" \",\", \",\" \",\", \"\" \",\", \",\" \"\" \",\", \"\", \",\" \",\" \",\", \"\" \",\", \",\" \",\", \"\" \",\", \"\", \",\" \"\" \",\", \",\" \"\", \",\", \"\", \""}, {"heading": "5.3.2.4 Algorithm Walkthrough", "text": "In the first four lines, variable declarations are placed (arranged lists). < < K > F > F > F > F > F > F > F > F > F > F < K > F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"F\" F \"\" F \"F\" F \"\" \"F\" F \"\" F \"F\" F \"F\" F \"F\" F \"F\" F \""}, {"heading": "5.3.3 Query Selection Measures", "text": "In this section, we give a brief introduction to some user efforts during the interactive KB definition."}, {"heading": "5.3.4 Interactive Debugging Algorithm: Correctness", "text": "In this section, we prove the correctness of Proposition 5.16 on page 105 by using the results of Sections 6.1.2 and 6.2.2, which provide evidence of the correctness (soundness, completeness, and optimality) of the STATICHS and DYNAMICHS: Proof of Proposition 5.16 methods. First, we argue why Algorithm 5 must be terminated. Terminates the function GETFORMULA PROBS on line 5, since it applies formulas 4.2 and 4.7."}, {"heading": "6.1 STATICHS: A Static Iterative Diagnosis Computation Algorithm", "text": "As the name suggests, STATICHS (Algorithm 7) is a method that solves the problem of interactive static KB debugging defined by Problem Definition 5.2 when used for the leading diagnostic calculation in Algorithm 5. STATICHS is a solid, complete and optimal solution to the interactive static KB debugging problem."}, {"heading": "6.1.1 Overview and Intuition", "text": "The STATICHS algorithms are strongly related to the non-interactive creation of algorithms in several phases. (See algorithm 2) In each of these phases of execution of algorithms 5, which are able to capture new test cases, it is necessary to redefine the individual diagnoses in the individual phases of the diagnostic and diagnostic processes in the individual phases of the diagnostic and diagnostic processes (and thus also the diagnostic and diagnostic processes), i.e. all minimum conflict sets are calculated w.r.The introduction of new diagnoses, which are not minimum diagnoses, which are not minimum diagnoses w.r.t. the entry of new test cases to the DPI is prohibited by new test cases to the DPI (cf.).So what STATICHS is gradually building up as a subroutine of algorithm 5, is the standard (non-active) HS."}, {"heading": "6.1.2 Algorithm Walkthrough", "text": "In fact, it is such that it is a way, as it has been in recent years in the USA, in Europe, in the USA, in Europe, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in"}, {"heading": "6.1.3 STATICHS: Examples", "text": "The first example shows the similarities and differences between the use of STATICHS (within algorithm 5) and HS (within algorithm 3), as it presents the application of STATICHS using the same example of DPI (see Table 4.1) used to demonstrate the functionality of HS in Examples 4.8 and 4.9. At the same time, the first example provides evidence that solving the problem of Interactive Static KB Debugging can be more efficient than solving the problem of Interactive Dynamic KB Debugging in terms of the number of responses required by an interacting user. This will be explained in more detail in Section 6.3.The second example will deepen the reader's understanding of the way STATICHS is used."}, {"heading": "6.2 DYNAMICHS: A Dynamic Iterative Diagnosis Computation Algorithm", "text": "As the name suggests, DYNAMICHS (algorithm 8) is a method that solves the problem of interactive dynamic KB debugging defined by problem definition 5.1 when used for the leading diagnostic calculation in algorithm 5. DYNAMICHS is a solid, complete and optimal solution to the problem of interactive dynamic KB debugging."}, {"heading": "6.2.1 Overview and Intuition", "text": "Dre rf\u00fc ide rf\u00fc ide rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die"}, {"heading": "6.2.2 Algorithm Walkthrough", "text": "When the DYNAMICHS (algorithm 8) is called for the first time in algorithm 5, the input parameters Ccalc, DX, D, P and N (both) are called for the first time in algorithm 5. < D, D, D, D, D, D, D, D, D, D, DYNAMICHS, D, D, DYNAMICHS, DYNAMICHS, DYNAMICHS, DYNAMICHS, DYNAMICHS, DYNAMICHS, DYNAMICHS, DYNAMICHS, DYNAMICHS, DYNAMICHS, DYNAMICHS, DYY, DY, DY, DYNY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY, DY,"}, {"heading": "6.2.3 DYNAMICHS: Examples", "text": "In this section, we will give two examples of how interactive DPI debugging works using DYNAMICHS = 6.1 = > q.E (algorithm 5 with parameter mode = dynamic). < 3) The first example shows the similarities and differences between the use of DYNAMICHS (within algorithm 5) and HS (within algorithm 3), as it is the application of STATICHS to the same DPI example (see Table 4.1) that was used to show the functionality of HS in Examples 4.8 and 4.9. At the same time, the first example will provide evidence that solving the problem of interactive dynamic KB debugging may be less efficient than solving the problem of interactive KB debugging in terms of the number of interacting responses needed by an interacting user. This example will be explained in more detail in Section 6.3.3.The second example will deepen our understanding of how DYNAMS works."}, {"heading": "6.3 Discussion of Iterative Diagnosis Computation", "text": "In this section, we want to analyze the characteristics and differences between STATICHS and DYNAMICHS in a minimal mode, which means a minimum satisfaction of the cases we have already shown in previous sections, and in addition, we want to shed light on some other interesting aspects of these iterative diagnostic methods within the framework of interactive CBS debugging (algorithm 5).The first row of the table was detected by Proposition 5.16 on page 105. The results given by the second row of the table are substantially corroborated by the fourth row of the table (STATICHS) and 6.2. \"We discussed in Section 6.1.1 that algorithm 5 with mode = static can artificially fix the search space for possible solutions. This is an inherited property of the interactive static KB debugging problem that the algorithms seek to solve."}], "references": [{"title": "Constraint-based Debugging of Spreadsheets", "author": ["R. Abreu", "A. Riboira", "F. Wotawa"], "venue": "In: CIbSE. pp", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2012}, {"title": "Pushing the EL envelope", "author": ["F. Baader", "S. Brandt", "C. Lutz"], "venue": "In: IJCAI. pp", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2005}, {"title": "eds.): The Description Logic Handbook: Theory, Implementation, and Applications", "author": ["F. Baader", "D. Calvanese", "D.L. McGuinness", "D. Nardi", "P.F. Patel-Schneider"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2007}, {"title": "Axiom Pinpointing in General Tableaux", "author": ["F. Baader", "R. Penaloza"], "venue": "Journal of Logic and Computation", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2008}, {"title": "On the relative expressiveness of description logics and predicate logics", "author": ["A. Borgida"], "venue": "Artificial Intelligence 82(1-2),", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1996}, {"title": "The computational complexity of abduction", "author": ["T. Bylander", "D. Allemang", "M. Tanner", "J. Josephson"], "venue": "Artificial Intelligence", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1991}, {"title": "Sources of error in syllogistic reasoning", "author": ["J. Ceraso", "A. Provitera"], "venue": "Cognitive Psychology 2(4),", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1971}, {"title": "What you always wanted to know about Datalog (and never dared to ask)", "author": ["S. Ceri", "G. Gottlob", "L. Tanca"], "venue": "IEEE Transactions on Knowledge and Data Engineering", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1989}, {"title": "R.C.T.: Symbolic Logic and Mechanical Theorem Proving", "author": ["C.L. Chang", "Lee"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1973}, {"title": "An unsolvable problem of elementary number theory", "author": ["A. Church"], "venue": "American Journal of Mathematics pp", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1936}, {"title": "Pattern-based OWL Ontology Debugging Guidelines", "author": ["O. Corcho", "C. Roussey", "Vilches Bl\u00e1zquez", "L. Manuel", "I. P\u00e9rez"], "venue": "(eds.) Workshop on Ontology Patterns (WOP 2009), collocated with the 8th International Semantic Web Conference (ISWC", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2009}, {"title": "Fixed-parameter tractability and completeness I: Basic results", "author": ["R.G. Downey", "M.R. Fellows"], "venue": "SIAM Journal on Computing", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1995}, {"title": "A Decomposition-Based Approach to OWL DL Ontology Diagnosis", "author": ["J. Du", "G. Qi", "J.Z. Pan", "Y.D. Shen"], "venue": "Proceedings of 23rd IEEE International Conference on Tools with Artificial Intelligence. pp", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2011}, {"title": "Probability: Theory and Examples, Fourth Edition", "author": ["R. Durrett"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2010}, {"title": "Final results of the Ontology Alignment Evaluation Initiative", "author": ["J. Euzenat", "A. Ferrara", "W.R. van Hage", "L. Hollink", "C. Meilicke", "A. Nikolov", "D. Ritze", "F. Scharffe", "P. Shvaiko", "H. Stuckenschmidt", "O. Sv\u00e1b-Zamazal", "C.T. dos Santos"], "venue": "Proceedings of the 6th International Workshop on Ontology Matching", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2011}, {"title": "Consistency-based diagnosis of configuration knowledge bases", "author": ["A. Felfernig", "G. Friedrich", "D. Jannach", "M. Stumptner"], "venue": "Artificial Intelligence 152(2),", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2004}, {"title": "An efficient diagnosis algorithm for inconsistent constraint sets. Artificial Intelligence for Engineering Design, Analysis and Manufacturing", "author": ["A. Felfernig", "M. Schubert", "C. Zehentner"], "venue": "(Jun", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2011}, {"title": "A General Diagnosis Method for Ontologies", "author": ["G. Friedrich", "K. Shchekotykhin"], "venue": "Proceedings of the 4th International Semantic Web Conference (ISWC", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2005}, {"title": "Model-based diagnosis of hardware designs", "author": ["G. Friedrich", "M. Stumptner", "F. Wotawa"], "venue": "Artif. Intell. 111(1-2),", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1999}, {"title": "OWL 2: The next step for OWL", "author": ["B.C. Grau", "I. Horrocks", "B. Motik", "B. Parsia", "P.F. Patel-Schneider", "U. Sattler"], "venue": "Web Semantics: Science, Services and Agents on the World Wide Web", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2008}, {"title": "A correction to the algorithm in Reiter\u2019s theory of diagnosis", "author": ["R. Greiner", "B. Smith", "R. Wilkerson"], "venue": "Artificial Intelligence 41(1),", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1989}, {"title": "Justification based Explanation in Ontologies", "author": ["M. Horridge"], "venue": "Ph.D. thesis,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2011}, {"title": "The cognitive complexity of OWL justifications", "author": ["M. Horridge", "S. Bail", "B. Parsia"], "venue": "Proceedings of the 10th International Semantic Web Conference (ISWC", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2011}, {"title": "Laconic and Precise Justifications in OWL", "author": ["M. Horridge", "B. Parsia", "U. Sattler"], "venue": "Proceedings of the 7th International Semantic Web Conference (ISWC", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2008}, {"title": "Lemmas for Justifications in OWL. In: Proceedings of the 22nd Workshop of Description Logics DL2009", "author": ["M. Horridge", "B. Parsia", "U. Sattler"], "venue": "CEUR Workshop Proceedings", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2009}, {"title": "Justification Oriented Proofs in OWL", "author": ["M. Horridge", "B. Parsia", "U. Sattler"], "venue": "Proceedings of the 9th International Semantic Web Conference (ISWC", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2010}, {"title": "Extracting justifications from BioPortal ontologies", "author": ["M. Horridge", "B. Parsia", "U. Sattler"], "venue": "Proceedings of the 11th International Semantic Web Conference (ISWC", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2012}, {"title": "Justification Masking in Ontologies", "author": ["M. Horridge", "B. Parsia", "U. Sattler"], "venue": "Thirteenth International Conference on the Principles of Knowledge Representation and Reasoning", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2012}, {"title": "CODI: Combinatorial Optimization for Data Integration - Results for OAEI", "author": ["J. Huber", "T. Sztyler", "J. Noessner", "C. Meilicke"], "venue": "Proceedings of the 6th International Workshop on Ontology Matching", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2011}, {"title": "Recommender Systems: An Introduction", "author": ["D. Jannach", "M. Zanker", "A. Felfernig", "G. Friedrich"], "venue": null, "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2010}, {"title": "Ontology Matching with Semantic Verification", "author": ["Y.R. Jean-Mary", "E.P. Shironoshita", "M.R. Kabuka"], "venue": "Web Semantics: Science, Services and Agents on the World Wide Web", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2009}, {"title": "Logmap: Logic-based and scalable ontology matching", "author": ["E. Jim\u00e9nez-Ruiz", "B.C. Grau"], "venue": "Proceedings of the 10th International Semantic Web Conference (ISWC", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2011}, {"title": "Large-scale interactive ontology matching: Algorithms and implementation", "author": ["E. Jim\u00e9nez-Ruiz", "B.C. Grau", "Y. Zhou", "I. Horrocks"], "venue": "Proceedings of 20th European Conference on Artificial Intelligence", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2012}, {"title": "Deductive reasoning", "author": ["P.N. Johnson-Laird"], "venue": "Annual review of psychology 50,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 1999}, {"title": "QUICKXPLAIN: Preferred Explanations and Relaxations for Over-Constrained Problems", "author": ["U. Junker"], "venue": "Proceedings of the Nineteenth National Conference on Artificial Intelligence, Sixteenth Conference on Innovative Applications of Artificial Intelligence", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2004}, {"title": "Debugging and Repair of OWL Ontologies", "author": ["A. Kalyanpur"], "venue": "Ph.D. thesis, University of Maryland,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2006}, {"title": "Finding all Justifications of OWL DL Entailments", "author": ["A. Kalyanpur", "B. Parsia", "M. Horridge", "E. Sirin"], "venue": "ISWC 2007 + ASWC 2007. LNCS,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2007}, {"title": "Repairing Unsatisfiable Concepts in OWL Ontologies", "author": ["A. Kalyanpur", "B. Parsia", "E. Sirin", "B. Cuenca-Grau"], "venue": "The Semantic Web: Research and Applications, 3rd European Semantic Web Conference,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2006}, {"title": "Swoop: A Web Ontology Editing Browser", "author": ["A. Kalyanpur", "B. Parsia", "E. Sirin", "B.C. Grau", "J. Hendler"], "venue": "J. Web Sem", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2006}, {"title": "Debugging Unsatisfiable Classes in OWL Ontologies", "author": ["A. Kalyanpur", "B. Parsia", "E. Sirin", "J. Hendler"], "venue": "Web Semantics: Science, Services and Agents on the World Wide Web 3(4),", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2005}, {"title": "SRIQ and SROIQ are harder than SHOIQ", "author": ["Y. Kazakov"], "venue": "Proceedings of the 21st Workshop of Description Logics", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2008}, {"title": "The incredible ELK", "author": ["Y. Kazakov", "M. Kr\u00f6tzsch", "F. Siman\u010d\u00edk"], "venue": "Journal of automated reasoning 53(1),", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2014}, {"title": "Diagnosing multiple faults", "author": ["J. de Kleer", "B.C. Williams"], "venue": "Artificial Intelligence", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 1987}, {"title": "Logik f\u00fcr Informatiker", "author": ["M. Kreuzer", "S. K\u00fchling"], "venue": "Pearson Studium, Mu\u0308nchen, Germany", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2006}, {"title": "Alignment Incoherence in Ontology Matching", "author": ["C. Meilicke"], "venue": "Ph.D. thesis, Universita\u0308t Mannheim", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 2011}, {"title": "An Efficient Method for Computing Alignment Diagnoses", "author": ["C. Meilicke", "H. Stuckenschmidt"], "venue": "Proceedings of the 3rd International Conference on Web Reasoning and Rule Systems", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 2009}, {"title": "Repairing Ontology Mappings", "author": ["C. Meilicke", "H. Stuckenschmidt", "A. Tamilin"], "venue": "Proceedings of the 22nd National Conference on Artificial intelligence -", "citeRegEx": "48", "shortCiteRegEx": "48", "year": 2007}, {"title": "Introduction to Mathematical Logic, Fifth Edition", "author": ["E. Mendelson"], "venue": null, "citeRegEx": "49", "shortCiteRegEx": "49", "year": 2009}, {"title": "OWL 2 Web Ontology Language Structural Specification and Functional-Style Syntax", "author": ["B. Motik", "P.F. Patel-Schneider", "B. Parsia"], "venue": "W3C recommendation pp", "citeRegEx": "50", "shortCiteRegEx": "50", "year": 2009}, {"title": "YAM++ - A combination of graph matching and machine learning approach to ontology alignment task", "author": ["D. Ngo", "Z. Bellahsene"], "venue": "Journal of Web Semantics - The Semantic Web Challenge", "citeRegEx": "51", "shortCiteRegEx": "51", "year": 2011}, {"title": "Interactive Ontology Revision", "author": ["N. Nikitina", "S. Rudolph", "B. Glimm"], "venue": "Web Semantics: Science, Services and Agents on the World Wide Web 12-13,", "citeRegEx": "52", "shortCiteRegEx": "52", "year": 2012}, {"title": "A framework for ontology evolution in collaborative environments", "author": ["N.F. Noy", "A. Chugh", "W. Liu", "M.A. Musen"], "venue": "Proceedings of the 5th International Semantic Web Conference", "citeRegEx": "53", "shortCiteRegEx": "53", "year": 2006}, {"title": "Creating Semantic Web Contents with Prot\u00e9g\u00e9-2000", "author": ["N.F. Noy", "M. Sintek", "S. Decker", "M. Crub\u00e9zy", "R.W. Fergerson", "M.A. Musen"], "venue": "IEEE Intelligent Systems", "citeRegEx": "54", "shortCiteRegEx": "54", "year": 2000}, {"title": "Debugging OWL ontologies", "author": ["B. Parsia", "E. Sirin", "A. Kalyanpur"], "venue": "Proceedings of the 14th international conference on World Wide Web", "citeRegEx": "55", "shortCiteRegEx": "55", "year": 2005}, {"title": "OWL Web Ontology Language Semantics and Abstract Syntax", "author": ["P.F. Patel-Schneider", "P. Hayes", "I Horrocks"], "venue": "W3C recommendation", "citeRegEx": "56", "shortCiteRegEx": "56", "year": 2004}, {"title": "Model-Based Diagnosis or Reasoning from First Principles", "author": ["B. Peischl", "F. Wotawa"], "venue": "IEEE Intelligent Systems", "citeRegEx": "57", "shortCiteRegEx": "57", "year": 2003}, {"title": "Induction of Decision Trees", "author": ["J.R. Quinlan"], "venue": "Machine Learning 1(1),", "citeRegEx": "58", "shortCiteRegEx": "58", "year": 1986}, {"title": "OWL Pizzas: Practical Experience of Teaching OWL-DL: Common Errors & Common Patterns", "author": ["A. Rector", "N. Drummond", "M. Horridge", "J. Rogers", "H. Knublauch", "R. Stevens", "H. Wang", "C. Wroe"], "venue": "Engineering Knowledge in the Age of the SemanticWeb 14th International Conference,", "citeRegEx": "59", "shortCiteRegEx": "59", "year": 2004}, {"title": "A Theory of Diagnosis from First Principles", "author": ["R. Reiter"], "venue": "Artificial Intelligence 32(1),", "citeRegEx": "60", "shortCiteRegEx": "60", "year": 1987}, {"title": "KOSIMap: Use of Description Logic Reasoning to Align Heterogeneous Ontologies", "author": ["Q. Reul", "J.Z. Pan"], "venue": "Proceedings of the 23rd International Workshop on Description Logics DL2010", "citeRegEx": "61", "shortCiteRegEx": "61", "year": 2010}, {"title": "RIO: Minimizing User Interaction in Debugging of Aligned Ontologies", "author": ["P. Rodler", "K. Shchekotykhin", "P. Fleiss", "G. Friedrich"], "venue": "Proceedings of the 7th International Workshop on Ontology Matching", "citeRegEx": "62", "shortCiteRegEx": "62", "year": 2012}, {"title": "RIO: Minimizing User Interaction in Ontology Debugging", "author": ["P. Rodler", "K. Shchekotykhin", "P. Fleiss", "G. Friedrich"], "venue": "Web Reasoning and Rule Systems, Lecture Notes in Computer Science,", "citeRegEx": "63", "shortCiteRegEx": "63", "year": 2013}, {"title": "A catalogue of OWL ontology antipatterns", "author": ["C. Roussey", "O. Corcho", "L.M. Vilches-Bl\u00e1zquez"], "venue": "In: International Conference On Knowledge Capture. pp. 205\u2013206", "citeRegEx": "64", "shortCiteRegEx": "64", "year": 2009}, {"title": "Artificial Intelligence: A Modern Approach", "author": ["S.J. Russell", "P. Norvig"], "venue": "Pearson Education,", "citeRegEx": "65", "shortCiteRegEx": "65", "year": 2010}, {"title": "Enumerating Minimally Revised Specifications Using Dualization", "author": ["K. Satoh", "T. Uno"], "venue": "New Frontiers in Artificial Intelligence, Lecture Notes in Computer Science,", "citeRegEx": "66", "shortCiteRegEx": "66", "year": 2006}, {"title": "Which Kind of Module Should I Extract", "author": ["U. Sattler", "T. Schneider", "M. Zakharyaschev"], "venue": "Proceedings of the 22nd International Workshop on Description Logics. CEUR Workshop Proceedings,", "citeRegEx": "67", "shortCiteRegEx": "67", "year": 2009}, {"title": "Debugging Incoherent Terminologies", "author": ["S. Schlobach", "Z. Huang", "R. Cornet", "F. Harmelen"], "venue": "Journal of Automated Reasoning 39(3),", "citeRegEx": "68", "shortCiteRegEx": "68", "year": 2007}, {"title": "Subsumption in KL-ONE is undecidable", "author": ["M. Schmidt-Schau\u00df"], "venue": "Proceedings of the 1st International Conference on Principles of Knowledge Representation and Reasoning", "citeRegEx": "69", "shortCiteRegEx": "69", "year": 1989}, {"title": "Abductive and default reasoning: A computational core", "author": ["B. Selman", "H.L. Levesque"], "venue": "Proceedings of the 8th National Conference on Artificial Intelligence pp", "citeRegEx": "70", "shortCiteRegEx": "70", "year": 1989}, {"title": "Direct computation of diagnoses for ontology alignment", "author": ["K. Shchekotykhin", "P. Fleiss", "P. Rodler", "G. Friedrich"], "venue": "Proceedings of the 7th International Workshop on Ontology Matching", "citeRegEx": "72", "shortCiteRegEx": "72", "year": 2012}, {"title": "Query strategy for sequential ontology debugging", "author": ["K. Shchekotykhin", "G. Friedrich"], "venue": "Proceedings of the 9th International Semantic Web Conference (ISWC", "citeRegEx": "73", "shortCiteRegEx": "73", "year": 2010}, {"title": "Interactive Ontology Debugging: Two Query Strategies for Efficient Fault Localization", "author": ["K. Shchekotykhin", "G. Friedrich", "P. Fleiss", "P. Rodler"], "venue": "Web Semantics: Science, Services and Agents on the World Wide Web 12-13,", "citeRegEx": "74", "shortCiteRegEx": "74", "year": 2012}, {"title": "On Computing Minimal Conflicts for Ontology Debugging", "author": ["K. Shchekotykhin", "G. Friedrich", "D. Jannach"], "venue": "MBS 2008 - Workshop on Model-Based Systems", "citeRegEx": "75", "shortCiteRegEx": "75", "year": 2008}, {"title": "Sequential diagnosis of high cardinality faults in knowledge-bases by direct diagnosis generation", "author": ["K. Shchekotykhin", "G. Friedrich", "P. Rodler", "P. Fleiss"], "venue": "Proceedings of the 21st European Conference on Artificial Intelligence (ECAI", "citeRegEx": "76", "shortCiteRegEx": "76", "year": 2014}, {"title": "HermiT : A Highly-Efficient OWL Reasoner", "author": ["R. Shearer", "B. Motik", "I. Horrocks"], "venue": "Proc. of the 5th Int. Workshop on OWL: Experiences and Directions (OWLED 2008 EU)", "citeRegEx": "77", "shortCiteRegEx": "77", "year": 2008}, {"title": "Pellet: A practical OWL-DL reasoner", "author": ["E. Sirin", "B. Parsia", "B.C. Grau", "A. Kalyanpur", "Y. Katz"], "venue": "Web Semantics: Science, Services and Agents on the World Wide Web 5(2),", "citeRegEx": "78", "shortCiteRegEx": "78", "year": 2007}, {"title": "Detecting and locating faults in the control software of autonomous mobile robots", "author": ["G. Steinbauer", "F. Wotawa"], "venue": "IJCAI International Joint Conference on Artificial Intelligence. pp", "citeRegEx": "79", "shortCiteRegEx": "79", "year": 2005}, {"title": "Robust Plan Execution Using Model-Based Reasoning", "author": ["G. Steinbauer", "F. Wotawa"], "venue": "Advanced Robotics 23(10),", "citeRegEx": "80", "shortCiteRegEx": "80", "year": 2009}, {"title": "Debugging OWL Ontologies - A Reality Check", "author": ["H. Stuckenschmidt"], "venue": "Proceedings of the 6th International Workshop on Evaluation of Ontology-based Tools and the Semantic Web Service Challenge (EON)", "citeRegEx": "81", "shortCiteRegEx": "81", "year": 2008}, {"title": "A Modularization-Based Approach to Finding All Justifications for OWL DL Entailments", "author": ["B. Suntisrivaraporn", "G. Qi", "Q. Ji", "P. Haase"], "venue": "Proceedings of the 7th International Semantic Web Conference (ISWC", "citeRegEx": "82", "shortCiteRegEx": "82", "year": 2008}, {"title": "OntoEdit: Collaborative Ontology Development for the Semantic Web", "author": ["Y. Sure", "M. Erdmann", "J. Angele", "S. Staab", "R. Studer", "D. Wenke"], "venue": "Proceedings of the 1st International Semantic Web Conference (ISWC", "citeRegEx": "83", "shortCiteRegEx": "83", "year": 2002}, {"title": "FaCT++ description logic reasoner: System description", "author": ["D. Tsarkov", "I. Horrocks"], "venue": "Proc. of the Int. Joint Conf. on Automated Reasoning (IJCAR", "citeRegEx": "84", "shortCiteRegEx": "84", "year": 2006}, {"title": "WebProt\u00e9g\u00e9: A Collaborative Ontology Editor and Knowledge Acquisition Tool for the Web", "author": ["T. Tudorache", "C. Nyulas", "N.F. Noy", "M.A. Musen"], "venue": "Semantic Web 4(1),", "citeRegEx": "85", "shortCiteRegEx": "85", "year": 2013}, {"title": "On Computable Numbers, with an Application to the Entscheidungsproblem", "author": ["A.M. Turing"], "venue": "Proceedings of the London Mathematical Society", "citeRegEx": "86", "shortCiteRegEx": "86", "year": 1937}, {"title": "Model-Based Debugging or How to Diagnose Programs Automatically", "author": ["F. Wotawa", "M. Stumptner", "W. Mayer"], "venue": "Developments in Applied Artificial Intelligence, Lecture Notes in Computer Science,", "citeRegEx": "87", "shortCiteRegEx": "87", "year": 2002}], "referenceMentions": [{"referenceID": 8, "context": "Most artificial intelligence applications rely on knowledge that is encoded in a knowledge base (KB) by means of some logical knowledge representation language such as propositional logic [10], datalog [9], first-order logic (FOL) [10], The Web Ontology Language (OWL [56], OWL 2 [21, 50]) or description logic (DL) [3].", "startOffset": 188, "endOffset": 192}, {"referenceID": 7, "context": "Most artificial intelligence applications rely on knowledge that is encoded in a knowledge base (KB) by means of some logical knowledge representation language such as propositional logic [10], datalog [9], first-order logic (FOL) [10], The Web Ontology Language (OWL [56], OWL 2 [21, 50]) or description logic (DL) [3].", "startOffset": 202, "endOffset": 205}, {"referenceID": 8, "context": "Most artificial intelligence applications rely on knowledge that is encoded in a knowledge base (KB) by means of some logical knowledge representation language such as propositional logic [10], datalog [9], first-order logic (FOL) [10], The Web Ontology Language (OWL [56], OWL 2 [21, 50]) or description logic (DL) [3].", "startOffset": 231, "endOffset": 235}, {"referenceID": 54, "context": "Most artificial intelligence applications rely on knowledge that is encoded in a knowledge base (KB) by means of some logical knowledge representation language such as propositional logic [10], datalog [9], first-order logic (FOL) [10], The Web Ontology Language (OWL [56], OWL 2 [21, 50]) or description logic (DL) [3].", "startOffset": 268, "endOffset": 272}, {"referenceID": 19, "context": "Most artificial intelligence applications rely on knowledge that is encoded in a knowledge base (KB) by means of some logical knowledge representation language such as propositional logic [10], datalog [9], first-order logic (FOL) [10], The Web Ontology Language (OWL [56], OWL 2 [21, 50]) or description logic (DL) [3].", "startOffset": 280, "endOffset": 288}, {"referenceID": 48, "context": "Most artificial intelligence applications rely on knowledge that is encoded in a knowledge base (KB) by means of some logical knowledge representation language such as propositional logic [10], datalog [9], first-order logic (FOL) [10], The Web Ontology Language (OWL [56], OWL 2 [21, 50]) or description logic (DL) [3].", "startOffset": 280, "endOffset": 288}, {"referenceID": 2, "context": "Most artificial intelligence applications rely on knowledge that is encoded in a knowledge base (KB) by means of some logical knowledge representation language such as propositional logic [10], datalog [9], first-order logic (FOL) [10], The Web Ontology Language (OWL [56], OWL 2 [21, 50]) or description logic (DL) [3].", "startOffset": 316, "endOffset": 319}, {"referenceID": 66, "context": "it would violate the requirement coherency (which has originally been defined for DL KBs [68, 55].", "startOffset": 89, "endOffset": 97}, {"referenceID": 53, "context": "it would violate the requirement coherency (which has originally been defined for DL KBs [68, 55].", "startOffset": 89, "endOffset": 97}, {"referenceID": 22, "context": "Faults in KBs may, for instance, arise because human reasoning is simply overstrained [24, 26].", "startOffset": 86, "endOffset": 94}, {"referenceID": 24, "context": "Faults in KBs may, for instance, arise because human reasoning is simply overstrained [24, 26].", "startOffset": 86, "endOffset": 94}, {"referenceID": 51, "context": "Another reason for the non-compliance with the mentioned quality criteria imposed on KBs might be that multiple (independently working) editors contribute to the development of the KB [53] which may lead to contradictory formulas.", "startOffset": 184, "endOffset": 188}, {"referenceID": 31, "context": "[33, 51, 32], to generate (parts of) KBs can further exacerbate the task of KB quality assurance [46, 16].", "startOffset": 0, "endOffset": 12}, {"referenceID": 49, "context": "[33, 51, 32], to generate (parts of) KBs can further exacerbate the task of KB quality assurance [46, 16].", "startOffset": 0, "endOffset": 12}, {"referenceID": 30, "context": "[33, 51, 32], to generate (parts of) KBs can further exacerbate the task of KB quality assurance [46, 16].", "startOffset": 0, "endOffset": 12}, {"referenceID": 44, "context": "[33, 51, 32], to generate (parts of) KBs can further exacerbate the task of KB quality assurance [46, 16].", "startOffset": 97, "endOffset": 105}, {"referenceID": 14, "context": "[33, 51, 32], to generate (parts of) KBs can further exacerbate the task of KB quality assurance [46, 16].", "startOffset": 97, "endOffset": 105}, {"referenceID": 6, "context": "Moreover, as studies in cognitive psychology [8, 35] attest, humans make systematic errors while formulating or interpreting logical formulas.", "startOffset": 45, "endOffset": 52}, {"referenceID": 33, "context": "Moreover, as studies in cognitive psychology [8, 35] attest, humans make systematic errors while formulating or interpreting logical formulas.", "startOffset": 45, "endOffset": 52}, {"referenceID": 57, "context": "These observations are confirmed by [59, 64] which present common faults people make when developing a KB (ontology).", "startOffset": 36, "endOffset": 44}, {"referenceID": 62, "context": "These observations are confirmed by [59, 64] which present common faults people make when developing a KB (ontology).", "startOffset": 36, "endOffset": 44}, {"referenceID": 66, "context": "Given a set of requirements to the KB and sets of test cases, KB debugging methods [68, 38, 19, 25] can localize a (potential) fault by computing a subset D of the formulas in the KB K called a diagnosis.", "startOffset": 83, "endOffset": 99}, {"referenceID": 36, "context": "Given a set of requirements to the KB and sets of test cases, KB debugging methods [68, 38, 19, 25] can localize a (potential) fault by computing a subset D of the formulas in the KB K called a diagnosis.", "startOffset": 83, "endOffset": 99}, {"referenceID": 17, "context": "Given a set of requirements to the KB and sets of test cases, KB debugging methods [68, 38, 19, 25] can localize a (potential) fault by computing a subset D of the formulas in the KB K called a diagnosis.", "startOffset": 83, "endOffset": 99}, {"referenceID": 23, "context": "Given a set of requirements to the KB and sets of test cases, KB debugging methods [68, 38, 19, 25] can localize a (potential) fault by computing a subset D of the formulas in the KB K called a diagnosis.", "startOffset": 83, "endOffset": 99}, {"referenceID": 71, "context": "[74, 23]) within the debugging system.", "startOffset": 0, "endOffset": 8}, {"referenceID": 21, "context": "[74, 23]) within the debugging system.", "startOffset": 0, "endOffset": 8}, {"referenceID": 66, "context": "[68, 23, 41]) attempt to exploit internal modifications of the reasoner for debugging purposes; in other words, the sources of problems (e.", "startOffset": 0, "endOffset": 12}, {"referenceID": 21, "context": "[68, 23, 41]) attempt to exploit internal modifications of the reasoner for debugging purposes; in other words, the sources of problems (e.", "startOffset": 0, "endOffset": 12}, {"referenceID": 39, "context": "[68, 23, 41]) attempt to exploit internal modifications of the reasoner for debugging purposes; in other words, the sources of problems (e.", "startOffset": 0, "endOffset": 12}, {"referenceID": 21, "context": "contradictory formulas) in the KB are computed as a direct consequence of reasoning [23].", "startOffset": 84, "endOffset": 88}, {"referenceID": 39, "context": "The advantages of a black-box approach over a glass-box approach are the lower memory consumption and better performance [41] of the reasoner and the reasoner independence of the debugging method.", "startOffset": 121, "endOffset": 125}, {"referenceID": 70, "context": "For example, in [73] a sample study of real-world KBs revealed that the number", "startOffset": 16, "endOffset": 20}, {"referenceID": 78, "context": "Moreover, [81] has put several (non-interactive) debugging systems to the test using a test set of faulty (incoherent OWL) real-world KBs which were partly designed by humans and partly by the application of automatic systems.", "startOffset": 10, "endOffset": 14}, {"referenceID": 58, "context": "The proposed approaches to interactive KB debugging in this work follow the standard model-based diagnosis (MBD) technique [60, 44].", "startOffset": 123, "endOffset": 131}, {"referenceID": 42, "context": "The proposed approaches to interactive KB debugging in this work follow the standard model-based diagnosis (MBD) technique [60, 44].", "startOffset": 123, "endOffset": 131}, {"referenceID": 76, "context": "MBD has been successfully applied to a great variety of problems in various fields such as robotics [79], planning [80], debugging of software programs [87], configuration problems [17], hardware designs [20], constraint satisfaction problems and spreadsheets [1].", "startOffset": 100, "endOffset": 104}, {"referenceID": 77, "context": "MBD has been successfully applied to a great variety of problems in various fields such as robotics [79], planning [80], debugging of software programs [87], configuration problems [17], hardware designs [20], constraint satisfaction problems and spreadsheets [1].", "startOffset": 115, "endOffset": 119}, {"referenceID": 84, "context": "MBD has been successfully applied to a great variety of problems in various fields such as robotics [79], planning [80], debugging of software programs [87], configuration problems [17], hardware designs [20], constraint satisfaction problems and spreadsheets [1].", "startOffset": 152, "endOffset": 156}, {"referenceID": 15, "context": "MBD has been successfully applied to a great variety of problems in various fields such as robotics [79], planning [80], debugging of software programs [87], configuration problems [17], hardware designs [20], constraint satisfaction problems and spreadsheets [1].", "startOffset": 181, "endOffset": 185}, {"referenceID": 18, "context": "MBD has been successfully applied to a great variety of problems in various fields such as robotics [79], planning [80], debugging of software programs [87], configuration problems [17], hardware designs [20], constraint satisfaction problems and spreadsheets [1].", "startOffset": 204, "endOffset": 208}, {"referenceID": 0, "context": "MBD has been successfully applied to a great variety of problems in various fields such as robotics [79], planning [80], debugging of software programs [87], configuration problems [17], hardware designs [20], constraint satisfaction problems and spreadsheets [1].", "startOffset": 260, "endOffset": 263}, {"referenceID": 5, "context": "An MBD problem can be modeled as an abduction problem [7], i.", "startOffset": 54, "endOffset": 57}, {"referenceID": 5, "context": "It was proven in [7] that the computation of the first explanation (minimal diagnosis) is in P.", "startOffset": 17, "endOffset": 20}, {"referenceID": 68, "context": "Incorporating the necessary reasoning costs and assuming consistency a minimal requirement to the correct KB, the finding of the first explanation (minimal diagnosis) is already NP-hard even for propositional KBs [70] (since propositional satisfiability checking is NP-complete).", "startOffset": 213, "endOffset": 217}, {"referenceID": 19, "context": "The worst case complexity for the debugging of KBs formulated over more expressive logics such as OWL 2 (reasoning is 2-NExpTimecomplete [21, 42]) will be of course even worse.", "startOffset": 137, "endOffset": 145}, {"referenceID": 40, "context": "The worst case complexity for the debugging of KBs formulated over more expressive logics such as OWL 2 (reasoning is 2-NExpTimecomplete [21, 42]) will be of course even worse.", "startOffset": 137, "endOffset": 145}, {"referenceID": 61, "context": "in our previous works [63, 74, 76] that for many real-world KBs interactive KB debugging is feasible in reasonable time, despite high (or intractable) worst case reasoning costs and the intractable complexity of the abduction (i.", "startOffset": 22, "endOffset": 34}, {"referenceID": 71, "context": "in our previous works [63, 74, 76] that for many real-world KBs interactive KB debugging is feasible in reasonable time, despite high (or intractable) worst case reasoning costs and the intractable complexity of the abduction (i.", "startOffset": 22, "endOffset": 34}, {"referenceID": 73, "context": "in our previous works [63, 74, 76] that for many real-world KBs interactive KB debugging is feasible in reasonable time, despite high (or intractable) worst case reasoning costs and the intractable complexity of the abduction (i.", "startOffset": 22, "endOffset": 34}, {"referenceID": 24, "context": "To get a more concrete idea of these assumptions, the reader is invited to think about whether the following first-order KB K is consistent (a similar example is discussed in [26]):", "startOffset": 175, "endOffset": 179}, {"referenceID": 24, "context": "The observations made in [26] concerning a slight modification K\u2032 of the KB K extracted from a real-world KB confirm this assumption.", "startOffset": 25, "endOffset": 29}, {"referenceID": 21, "context": "[23, 37]).", "startOffset": 0, "endOffset": 8}, {"referenceID": 35, "context": "[23, 37]).", "startOffset": 0, "endOffset": 8}, {"referenceID": 78, "context": "This has also been found in [81].", "startOffset": 28, "endOffset": 32}, {"referenceID": 46, "context": "Here, both ontologies are considered correct and diagnoses are only allowed to include elements of the alignment [48].", "startOffset": 113, "endOffset": 117}, {"referenceID": 71, "context": "Our previous works on the topic [74, 73, 63, 19, 76] are more application-oriented and thus abstract from some details and omit some of the proofs in favor of comprehensive evaluations of the presented strategies.", "startOffset": 32, "endOffset": 52}, {"referenceID": 70, "context": "Our previous works on the topic [74, 73, 63, 19, 76] are more application-oriented and thus abstract from some details and omit some of the proofs in favor of comprehensive evaluations of the presented strategies.", "startOffset": 32, "endOffset": 52}, {"referenceID": 61, "context": "Our previous works on the topic [74, 73, 63, 19, 76] are more application-oriented and thus abstract from some details and omit some of the proofs in favor of comprehensive evaluations of the presented strategies.", "startOffset": 32, "endOffset": 52}, {"referenceID": 17, "context": "Our previous works on the topic [74, 73, 63, 19, 76] are more application-oriented and thus abstract from some details and omit some of the proofs in favor of comprehensive evaluations of the presented strategies.", "startOffset": 32, "endOffset": 52}, {"referenceID": 73, "context": "Our previous works on the topic [74, 73, 63, 19, 76] are more application-oriented and thus abstract from some details and omit some of the proofs in favor of comprehensive evaluations of the presented strategies.", "startOffset": 32, "endOffset": 52}, {"referenceID": 71, "context": "The investigated methods for query computation have been used in [74, 63, 73, 76] too, but have not been addressed in depth in these works.", "startOffset": 65, "endOffset": 81}, {"referenceID": 61, "context": "The investigated methods for query computation have been used in [74, 63, 73, 76] too, but have not been addressed in depth in these works.", "startOffset": 65, "endOffset": 81}, {"referenceID": 70, "context": "The investigated methods for query computation have been used in [74, 63, 73, 76] too, but have not been addressed in depth in these works.", "startOffset": 65, "endOffset": 81}, {"referenceID": 73, "context": "The investigated methods for query computation have been used in [74, 63, 73, 76] too, but have not been addressed in depth in these works.", "startOffset": 65, "endOffset": 81}, {"referenceID": 34, "context": "\u2022 We give a formal proof of the soundness of an algorithm QX (based on [36]) for the detection of a minimal conflict set in a KB and we show the correctness (completeness, soundness, optimality) of a hitting set tree algorithm HS (based on [60]) for finding minimal diagnoses in a KB in bestfirst order (i.", "startOffset": 71, "endOffset": 75}, {"referenceID": 58, "context": "\u2022 We give a formal proof of the soundness of an algorithm QX (based on [36]) for the detection of a minimal conflict set in a KB and we show the correctness (completeness, soundness, optimality) of a hitting set tree algorithm HS (based on [60]) for finding minimal diagnoses in a KB in bestfirst order (i.", "startOffset": 240, "endOffset": 244}, {"referenceID": 42, "context": "used in [44, 60, 74, 63] and the latter i.", "startOffset": 8, "endOffset": 24}, {"referenceID": 58, "context": "used in [44, 60, 74, 63] and the latter i.", "startOffset": 8, "endOffset": 24}, {"referenceID": 71, "context": "used in [44, 60, 74, 63] and the latter i.", "startOffset": 8, "endOffset": 24}, {"referenceID": 61, "context": "used in [44, 60, 74, 63] and the latter i.", "startOffset": 8, "endOffset": 24}, {"referenceID": 23, "context": "in [25, 26, 27, 23, 24, 29, 82, 37, 47, 67, 52].", "startOffset": 3, "endOffset": 47}, {"referenceID": 24, "context": "in [25, 26, 27, 23, 24, 29, 82, 37, 47, 67, 52].", "startOffset": 3, "endOffset": 47}, {"referenceID": 25, "context": "in [25, 26, 27, 23, 24, 29, 82, 37, 47, 67, 52].", "startOffset": 3, "endOffset": 47}, {"referenceID": 21, "context": "in [25, 26, 27, 23, 24, 29, 82, 37, 47, 67, 52].", "startOffset": 3, "endOffset": 47}, {"referenceID": 22, "context": "in [25, 26, 27, 23, 24, 29, 82, 37, 47, 67, 52].", "startOffset": 3, "endOffset": 47}, {"referenceID": 27, "context": "in [25, 26, 27, 23, 24, 29, 82, 37, 47, 67, 52].", "startOffset": 3, "endOffset": 47}, {"referenceID": 79, "context": "in [25, 26, 27, 23, 24, 29, 82, 37, 47, 67, 52].", "startOffset": 3, "endOffset": 47}, {"referenceID": 35, "context": "in [25, 26, 27, 23, 24, 29, 82, 37, 47, 67, 52].", "startOffset": 3, "endOffset": 47}, {"referenceID": 45, "context": "in [25, 26, 27, 23, 24, 29, 82, 37, 47, 67, 52].", "startOffset": 3, "endOffset": 47}, {"referenceID": 65, "context": "in [25, 26, 27, 23, 24, 29, 82, 37, 47, 67, 52].", "startOffset": 3, "endOffset": 47}, {"referenceID": 50, "context": "in [25, 26, 27, 23, 24, 29, 82, 37, 47, 67, 52].", "startOffset": 3, "endOffset": 47}, {"referenceID": 26, "context": "[28]) implies the efficiency of conflict set computation for the same set of KBs.", "startOffset": 0, "endOffset": 4}, {"referenceID": 71, "context": "One that is guaranteed to reduce the number of remaining solutions after a query is answered and one that features more powerful pruning techniques than our previously published algorithms [74, 63] (an evaluation that compares the overall efficiency of our previous algorithms with the ones proposed in this work must still be conducted and is part of our future research).", "startOffset": 189, "endOffset": 197}, {"referenceID": 61, "context": "One that is guaranteed to reduce the number of remaining solutions after a query is answered and one that features more powerful pruning techniques than our previously published algorithms [74, 63] (an evaluation that compares the overall efficiency of our previous algorithms with the ones proposed in this work must still be conducted and is part of our future research).", "startOffset": 189, "endOffset": 197}, {"referenceID": 58, "context": "to stick to \u201cThe Principle of Parsimony\u201d [60, 7].", "startOffset": 41, "endOffset": 48}, {"referenceID": 5, "context": "to stick to \u201cThe Principle of Parsimony\u201d [60, 7].", "startOffset": 41, "endOffset": 48}, {"referenceID": 23, "context": "Subsequently, we derive the relationship between a conflict set and the notion of a justification (a minimal set of formulas necessary for a particular entailment to hold) which is well-known and frequently used, especially in the field of DL [25, 26, 27, 23, 24, 28].", "startOffset": 243, "endOffset": 267}, {"referenceID": 24, "context": "Subsequently, we derive the relationship between a conflict set and the notion of a justification (a minimal set of formulas necessary for a particular entailment to hold) which is well-known and frequently used, especially in the field of DL [25, 26, 27, 23, 24, 28].", "startOffset": 243, "endOffset": 267}, {"referenceID": 25, "context": "Subsequently, we derive the relationship between a conflict set and the notion of a justification (a minimal set of formulas necessary for a particular entailment to hold) which is well-known and frequently used, especially in the field of DL [25, 26, 27, 23, 24, 28].", "startOffset": 243, "endOffset": 267}, {"referenceID": 21, "context": "Subsequently, we derive the relationship between a conflict set and the notion of a justification (a minimal set of formulas necessary for a particular entailment to hold) which is well-known and frequently used, especially in the field of DL [25, 26, 27, 23, 24, 28].", "startOffset": 243, "endOffset": 267}, {"referenceID": 22, "context": "Subsequently, we derive the relationship between a conflict set and the notion of a justification (a minimal set of formulas necessary for a particular entailment to hold) which is well-known and frequently used, especially in the field of DL [25, 26, 27, 23, 24, 28].", "startOffset": 243, "endOffset": 267}, {"referenceID": 26, "context": "Subsequently, we derive the relationship between a conflict set and the notion of a justification (a minimal set of formulas necessary for a particular entailment to hold) which is well-known and frequently used, especially in the field of DL [25, 26, 27, 23, 24, 28].", "startOffset": 243, "endOffset": 267}, {"referenceID": 34, "context": "Having deduced all relevant characteristics of (minimal) conflict sets, we proceed to give a description of a method (QX, Algorithm 1) due to [36] which was originally presented as a method for finding preferred explanations (conflicts) in over-constrained CSPs, but can also be employed for an efficient computation of a minimal conflict set w.", "startOffset": 142, "endOffset": 146}, {"referenceID": 58, "context": "Having at our disposal a proven sound method for generation of a minimal conflict set, we continue with the delineation of a hitting set tree algorithm similar to the one originally presented in [60] which enables the computation of different minimal conflict sets by means of successive calls to QX, each time given an (adequately) modified DPI.", "startOffset": 195, "endOffset": 199}, {"referenceID": 61, "context": "Finally, some query selection measures are discussed [63, 74] (Section 5.", "startOffset": 53, "endOffset": 61}, {"referenceID": 71, "context": "Finally, some query selection measures are discussed [63, 74] (Section 5.", "startOffset": 53, "endOffset": 61}, {"referenceID": 43, "context": "[45]), wellformed formula (e.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "[10]), (logical) sentence or axiom (e.", "startOffset": 0, "endOffset": 4}, {"referenceID": 63, "context": "[65]) and axiom (in most of the description logic literature, e.", "startOffset": 0, "endOffset": 4}, {"referenceID": 2, "context": "[3]).", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "Whereas we assume the reader to be familiar with FOL and PL (a good introduction to PL and FOL can be found in [10]), we will give a short introduction to DL.", "startOffset": 111, "endOffset": 115}, {"referenceID": 47, "context": "[49]; the original works are [11, 86]) that FOL is not decidable in general, i.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "[49]; the original works are [11, 86]) that FOL is not decidable in general, i.", "startOffset": 29, "endOffset": 37}, {"referenceID": 83, "context": "[49]; the original works are [11, 86]) that FOL is not decidable in general, i.", "startOffset": 29, "endOffset": 37}, {"referenceID": 2, "context": "For instance, a DL language allowing the formalism of equality role-value-maps which facilitates the expression of concepts like \u201cpersons whose co-workers coincide with their relatives\u201d can be proven undecidable [3, 69].", "startOffset": 212, "endOffset": 219}, {"referenceID": 67, "context": "For instance, a DL language allowing the formalism of equality role-value-maps which facilitates the expression of concepts like \u201cpersons whose co-workers coincide with their relatives\u201d can be proven undecidable [3, 69].", "startOffset": 212, "endOffset": 219}, {"referenceID": 19, "context": "Property 4 is satisfied, for example, for the DL language SROIQ which is the logical underpinning of OWL 2 [21].", "startOffset": 107, "endOffset": 111}, {"referenceID": 40, "context": "However, the complexity (2-NEXPTIME-complete [42]) of logical reasoning is intractable in the worst case for this language which implies the intractability of our methods in the worst case.", "startOffset": 45, "endOffset": 49}, {"referenceID": 73, "context": "Nevertheless, other DL languages applied with similar systems as those described in this paper have been showing reasonable performance [76, 63, 74].", "startOffset": 136, "endOffset": 148}, {"referenceID": 61, "context": "Nevertheless, other DL languages applied with similar systems as those described in this paper have been showing reasonable performance [76, 63, 74].", "startOffset": 136, "endOffset": 148}, {"referenceID": 71, "context": "Nevertheless, other DL languages applied with similar systems as those described in this paper have been showing reasonable performance [76, 63, 74].", "startOffset": 136, "endOffset": 148}, {"referenceID": 1, "context": "One example is the OWL 2 EL profile which enables polynomial time reasoning [2].", "startOffset": 76, "endOffset": 79}, {"referenceID": 41, "context": "For this language, the efficient reasoning service ELK has been presented by [43].", "startOffset": 77, "endOffset": 81}, {"referenceID": 63, "context": "For FOL, datalog is an example of a decidable sublanguage where reasoning is efficient [65].", "startOffset": 87, "endOffset": 91}, {"referenceID": 4, "context": "Further, restricted sublanguages of FOL can often be translated to some DL language wherefore DL positive results concerning the decidability of reasoning as well as complexity results can be adopted for these restricted FOL languages [3, chapter 4] [6].", "startOffset": 250, "endOffset": 253}, {"referenceID": 48, "context": "The standard knowledge representation formalism for ontologies is OWL 2 [50, 21] which relies on DL.", "startOffset": 72, "endOffset": 80}, {"referenceID": 19, "context": "The standard knowledge representation formalism for ontologies is OWL 2 [50, 21] which relies on DL.", "startOffset": 72, "endOffset": 80}, {"referenceID": 2, "context": "Description Logic (DL) [3] is a family of knowledge representation languages with a formal logic-based semantics that are designed to represent knowledge about a domain in form of concept descriptions.", "startOffset": 23, "endOffset": 26}, {"referenceID": 0, "context": "For example, let L := [1, 3, 4, 2] be an ordered list; then L\u2229{1, 2, 3} yields the set {1, 2, 3}.", "startOffset": 22, "endOffset": 34}, {"referenceID": 2, "context": "For example, let L := [1, 3, 4, 2] be an ordered list; then L\u2229{1, 2, 3} yields the set {1, 2, 3}.", "startOffset": 22, "endOffset": 34}, {"referenceID": 3, "context": "For example, let L := [1, 3, 4, 2] be an ordered list; then L\u2229{1, 2, 3} yields the set {1, 2, 3}.", "startOffset": 22, "endOffset": 34}, {"referenceID": 1, "context": "For example, let L := [1, 3, 4, 2] be an ordered list; then L\u2229{1, 2, 3} yields the set {1, 2, 3}.", "startOffset": 22, "endOffset": 34}, {"referenceID": 63, "context": "[65]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "[9]).", "startOffset": 0, "endOffset": 3}, {"referenceID": 42, "context": "[44]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "7] [7].", "startOffset": 3, "endOffset": 6}, {"referenceID": 58, "context": "\u3008K,B,P ,N \u3009R the size of which is in general O(2|K|) (if all subsets of the KB K are investigated) can be reduced to a great extent by exploiting the notion of a conflict set [60, 44, 74].", "startOffset": 175, "endOffset": 187}, {"referenceID": 42, "context": "\u3008K,B,P ,N \u3009R the size of which is in general O(2|K|) (if all subsets of the KB K are investigated) can be reduced to a great extent by exploiting the notion of a conflict set [60, 44, 74].", "startOffset": 175, "endOffset": 187}, {"referenceID": 71, "context": "\u3008K,B,P ,N \u3009R the size of which is in general O(2|K|) (if all subsets of the KB K are investigated) can be reduced to a great extent by exploiting the notion of a conflict set [60, 44, 74].", "startOffset": 175, "endOffset": 187}, {"referenceID": 23, "context": "The notion of a conflict set is closely related to the notion of a justification [25, 26, 27, 23, 24, 28] which is frequently adopted in the field of the Semantic Web (cf.", "startOffset": 81, "endOffset": 105}, {"referenceID": 24, "context": "The notion of a conflict set is closely related to the notion of a justification [25, 26, 27, 23, 24, 28] which is frequently adopted in the field of the Semantic Web (cf.", "startOffset": 81, "endOffset": 105}, {"referenceID": 25, "context": "The notion of a conflict set is closely related to the notion of a justification [25, 26, 27, 23, 24, 28] which is frequently adopted in the field of the Semantic Web (cf.", "startOffset": 81, "endOffset": 105}, {"referenceID": 21, "context": "The notion of a conflict set is closely related to the notion of a justification [25, 26, 27, 23, 24, 28] which is frequently adopted in the field of the Semantic Web (cf.", "startOffset": 81, "endOffset": 105}, {"referenceID": 22, "context": "The notion of a conflict set is closely related to the notion of a justification [25, 26, 27, 23, 24, 28] which is frequently adopted in the field of the Semantic Web (cf.", "startOffset": 81, "endOffset": 105}, {"referenceID": 26, "context": "The notion of a conflict set is closely related to the notion of a justification [25, 26, 27, 23, 24, 28] which is frequently adopted in the field of the Semantic Web (cf.", "startOffset": 81, "endOffset": 105}, {"referenceID": 35, "context": "Thus, the paradigm of a justification can be a useful aid in the debugging of faulty ontologies [37].", "startOffset": 96, "endOffset": 100}, {"referenceID": 3, "context": "Note that sometimes justifications are referred to as MinAs (Minimal Axiom Sets) [4] or MUPS (Minimal Unsatisfiability Preserving Sub-TBoxes) [68] where the latter term is mostly used in the context of ontology debugging.", "startOffset": 81, "endOffset": 84}, {"referenceID": 66, "context": "Note that sometimes justifications are referred to as MinAs (Minimal Axiom Sets) [4] or MUPS (Minimal Unsatisfiability Preserving Sub-TBoxes) [68] where the latter term is mostly used in the context of ontology debugging.", "startOffset": 142, "endOffset": 146}, {"referenceID": 58, "context": "The notion of a (minimal) conflict set, on the other hand, has been mainly adopted in the Diagnosis community [60, 44, 57, 87, 17].", "startOffset": 110, "endOffset": 130}, {"referenceID": 42, "context": "The notion of a (minimal) conflict set, on the other hand, has been mainly adopted in the Diagnosis community [60, 44, 57, 87, 17].", "startOffset": 110, "endOffset": 130}, {"referenceID": 55, "context": "The notion of a (minimal) conflict set, on the other hand, has been mainly adopted in the Diagnosis community [60, 44, 57, 87, 17].", "startOffset": 110, "endOffset": 130}, {"referenceID": 84, "context": "The notion of a (minimal) conflict set, on the other hand, has been mainly adopted in the Diagnosis community [60, 44, 57, 87, 17].", "startOffset": 110, "endOffset": 130}, {"referenceID": 15, "context": "The notion of a (minimal) conflict set, on the other hand, has been mainly adopted in the Diagnosis community [60, 44, 57, 87, 17].", "startOffset": 110, "endOffset": 130}, {"referenceID": 35, "context": "For example, the author of [37] i.", "startOffset": 27, "endOffset": 31}, {"referenceID": 35, "context": "terminology of [37, 23], A would be called a purely derived unsatisfiable concept whereas B would be called a root unsatisfiable concept.", "startOffset": 15, "endOffset": 23}, {"referenceID": 21, "context": "terminology of [37, 23], A would be called a purely derived unsatisfiable concept whereas B would be called a root unsatisfiable concept.", "startOffset": 15, "endOffset": 23}, {"referenceID": 35, "context": "Therefore, [37] proposes to resolve root unsatisfiable concepts first since this might resolve some (purely) derived concepts as well, as in this example.", "startOffset": 11, "endOffset": 15}, {"referenceID": 36, "context": "[38] Let K be a KB and \u03b1 a formula, both over L.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[19] A (minimal) diagnosis w.", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "Hence, the set of all minimal diagnoses mD\u3008K,B,P,N \u3009R = {D1,D2,D3} = {[1], [2], [5, 7]} is obtained by computing all minimal hitting sets of mC\u3008K,B,P,N \u3009R = {C1, C2} (cf.", "startOffset": 70, "endOffset": 73}, {"referenceID": 1, "context": "Hence, the set of all minimal diagnoses mD\u3008K,B,P,N \u3009R = {D1,D2,D3} = {[1], [2], [5, 7]} is obtained by computing all minimal hitting sets of mC\u3008K,B,P,N \u3009R = {C1, C2} (cf.", "startOffset": 75, "endOffset": 78}, {"referenceID": 5, "context": "Hence, the set of all minimal diagnoses mD\u3008K,B,P,N \u3009R = {D1,D2,D3} = {[1], [2], [5, 7]} is obtained by computing all minimal hitting sets of mC\u3008K,B,P,N \u3009R = {C1, C2} (cf.", "startOffset": 80, "endOffset": 86}, {"referenceID": 0, "context": "D1 = [1, 2] D2 = [1, 4] D3 = [1, 6] D4 = [2, 3, 5] D5 = [2, 3, 6] D6 = [2, 3, 8] D7 = [2, 4, 6] D8 = [2, 4, 8] D9 = [3, 5, 6] D10 = [4, 5]", "startOffset": 5, "endOffset": 11}, {"referenceID": 1, "context": "D1 = [1, 2] D2 = [1, 4] D3 = [1, 6] D4 = [2, 3, 5] D5 = [2, 3, 6] D6 = [2, 3, 8] D7 = [2, 4, 6] D8 = [2, 4, 8] D9 = [3, 5, 6] D10 = [4, 5]", "startOffset": 5, "endOffset": 11}, {"referenceID": 0, "context": "D1 = [1, 2] D2 = [1, 4] D3 = [1, 6] D4 = [2, 3, 5] D5 = [2, 3, 6] D6 = [2, 3, 8] D7 = [2, 4, 6] D8 = [2, 4, 8] D9 = [3, 5, 6] D10 = [4, 5]", "startOffset": 17, "endOffset": 23}, {"referenceID": 3, "context": "D1 = [1, 2] D2 = [1, 4] D3 = [1, 6] D4 = [2, 3, 5] D5 = [2, 3, 6] D6 = [2, 3, 8] D7 = [2, 4, 6] D8 = [2, 4, 8] D9 = [3, 5, 6] D10 = [4, 5]", "startOffset": 17, "endOffset": 23}, {"referenceID": 0, "context": "D1 = [1, 2] D2 = [1, 4] D3 = [1, 6] D4 = [2, 3, 5] D5 = [2, 3, 6] D6 = [2, 3, 8] D7 = [2, 4, 6] D8 = [2, 4, 8] D9 = [3, 5, 6] D10 = [4, 5]", "startOffset": 29, "endOffset": 35}, {"referenceID": 4, "context": "D1 = [1, 2] D2 = [1, 4] D3 = [1, 6] D4 = [2, 3, 5] D5 = [2, 3, 6] D6 = [2, 3, 8] D7 = [2, 4, 6] D8 = [2, 4, 8] D9 = [3, 5, 6] D10 = [4, 5]", "startOffset": 29, "endOffset": 35}, {"referenceID": 1, "context": "D1 = [1, 2] D2 = [1, 4] D3 = [1, 6] D4 = [2, 3, 5] D5 = [2, 3, 6] D6 = [2, 3, 8] D7 = [2, 4, 6] D8 = [2, 4, 8] D9 = [3, 5, 6] D10 = [4, 5]", "startOffset": 41, "endOffset": 50}, {"referenceID": 2, "context": "D1 = [1, 2] D2 = [1, 4] D3 = [1, 6] D4 = [2, 3, 5] D5 = [2, 3, 6] D6 = [2, 3, 8] D7 = [2, 4, 6] D8 = [2, 4, 8] D9 = [3, 5, 6] D10 = [4, 5]", "startOffset": 41, "endOffset": 50}, {"referenceID": 1, "context": "D1 = [1, 2] D2 = [1, 4] D3 = [1, 6] D4 = [2, 3, 5] D5 = [2, 3, 6] D6 = [2, 3, 8] D7 = [2, 4, 6] D8 = [2, 4, 8] D9 = [3, 5, 6] D10 = [4, 5]", "startOffset": 56, "endOffset": 65}, {"referenceID": 2, "context": "D1 = [1, 2] D2 = [1, 4] D3 = [1, 6] D4 = [2, 3, 5] D5 = [2, 3, 6] D6 = [2, 3, 8] D7 = [2, 4, 6] D8 = [2, 4, 8] D9 = [3, 5, 6] D10 = [4, 5]", "startOffset": 56, "endOffset": 65}, {"referenceID": 4, "context": "D1 = [1, 2] D2 = [1, 4] D3 = [1, 6] D4 = [2, 3, 5] D5 = [2, 3, 6] D6 = [2, 3, 8] D7 = [2, 4, 6] D8 = [2, 4, 8] D9 = [3, 5, 6] D10 = [4, 5]", "startOffset": 56, "endOffset": 65}, {"referenceID": 1, "context": "D1 = [1, 2] D2 = [1, 4] D3 = [1, 6] D4 = [2, 3, 5] D5 = [2, 3, 6] D6 = [2, 3, 8] D7 = [2, 4, 6] D8 = [2, 4, 8] D9 = [3, 5, 6] D10 = [4, 5]", "startOffset": 71, "endOffset": 80}, {"referenceID": 2, "context": "D1 = [1, 2] D2 = [1, 4] D3 = [1, 6] D4 = [2, 3, 5] D5 = [2, 3, 6] D6 = [2, 3, 8] D7 = [2, 4, 6] D8 = [2, 4, 8] D9 = [3, 5, 6] D10 = [4, 5]", "startOffset": 71, "endOffset": 80}, {"referenceID": 6, "context": "D1 = [1, 2] D2 = [1, 4] D3 = [1, 6] D4 = [2, 3, 5] D5 = [2, 3, 6] D6 = [2, 3, 8] D7 = [2, 4, 6] D8 = [2, 4, 8] D9 = [3, 5, 6] D10 = [4, 5]", "startOffset": 71, "endOffset": 80}, {"referenceID": 1, "context": "D1 = [1, 2] D2 = [1, 4] D3 = [1, 6] D4 = [2, 3, 5] D5 = [2, 3, 6] D6 = [2, 3, 8] D7 = [2, 4, 6] D8 = [2, 4, 8] D9 = [3, 5, 6] D10 = [4, 5]", "startOffset": 86, "endOffset": 95}, {"referenceID": 3, "context": "D1 = [1, 2] D2 = [1, 4] D3 = [1, 6] D4 = [2, 3, 5] D5 = [2, 3, 6] D6 = [2, 3, 8] D7 = [2, 4, 6] D8 = [2, 4, 8] D9 = [3, 5, 6] D10 = [4, 5]", "startOffset": 86, "endOffset": 95}, {"referenceID": 4, "context": "D1 = [1, 2] D2 = [1, 4] D3 = [1, 6] D4 = [2, 3, 5] D5 = [2, 3, 6] D6 = [2, 3, 8] D7 = [2, 4, 6] D8 = [2, 4, 8] D9 = [3, 5, 6] D10 = [4, 5]", "startOffset": 86, "endOffset": 95}, {"referenceID": 1, "context": "D1 = [1, 2] D2 = [1, 4] D3 = [1, 6] D4 = [2, 3, 5] D5 = [2, 3, 6] D6 = [2, 3, 8] D7 = [2, 4, 6] D8 = [2, 4, 8] D9 = [3, 5, 6] D10 = [4, 5]", "startOffset": 101, "endOffset": 110}, {"referenceID": 3, "context": "D1 = [1, 2] D2 = [1, 4] D3 = [1, 6] D4 = [2, 3, 5] D5 = [2, 3, 6] D6 = [2, 3, 8] D7 = [2, 4, 6] D8 = [2, 4, 8] D9 = [3, 5, 6] D10 = [4, 5]", "startOffset": 101, "endOffset": 110}, {"referenceID": 6, "context": "D1 = [1, 2] D2 = [1, 4] D3 = [1, 6] D4 = [2, 3, 5] D5 = [2, 3, 6] D6 = [2, 3, 8] D7 = [2, 4, 6] D8 = [2, 4, 8] D9 = [3, 5, 6] D10 = [4, 5]", "startOffset": 101, "endOffset": 110}, {"referenceID": 2, "context": "D1 = [1, 2] D2 = [1, 4] D3 = [1, 6] D4 = [2, 3, 5] D5 = [2, 3, 6] D6 = [2, 3, 8] D7 = [2, 4, 6] D8 = [2, 4, 8] D9 = [3, 5, 6] D10 = [4, 5]", "startOffset": 116, "endOffset": 125}, {"referenceID": 4, "context": "D1 = [1, 2] D2 = [1, 4] D3 = [1, 6] D4 = [2, 3, 5] D5 = [2, 3, 6] D6 = [2, 3, 8] D7 = [2, 4, 6] D8 = [2, 4, 8] D9 = [3, 5, 6] D10 = [4, 5]", "startOffset": 116, "endOffset": 125}, {"referenceID": 3, "context": "D1 = [1, 2] D2 = [1, 4] D3 = [1, 6] D4 = [2, 3, 5] D5 = [2, 3, 6] D6 = [2, 3, 8] D7 = [2, 4, 6] D8 = [2, 4, 8] D9 = [3, 5, 6] D10 = [4, 5]", "startOffset": 132, "endOffset": 138}, {"referenceID": 22, "context": "[24]) and (3) to assess that there are no further minimal conflict sets w.", "startOffset": 0, "endOffset": 4}, {"referenceID": 36, "context": "4) for the systematic computation of different minimal conflict sets, or other mechanisms such as the ALL_JUST_ALG presented in [38] which computes all justifications for some particular entailment (but, some post-processing of the justifications is necessary to obtain minimal conflict sets, cf.", "startOffset": 128, "endOffset": 132}, {"referenceID": 22, "context": "Problem (2) and its complexity for humans has been studied in [24] with a focus on justifications in DL or OWL KBs.", "startOffset": 62, "endOffset": 66}, {"referenceID": 22, "context": "1, the cognitive complexity model proposed by [24] applies also to minimal conflict sets.", "startOffset": 46, "endOffset": 50}, {"referenceID": 25, "context": "Ways to facilitate the understanding of justifications for humans (that might be successfully applied also to conflict sets) have been addressed in [27, 26, 25].", "startOffset": 148, "endOffset": 160}, {"referenceID": 24, "context": "Ways to facilitate the understanding of justifications for humans (that might be successfully applied also to conflict sets) have been addressed in [27, 26, 25].", "startOffset": 148, "endOffset": 160}, {"referenceID": 23, "context": "Ways to facilitate the understanding of justifications for humans (that might be successfully applied also to conflict sets) have been addressed in [27, 26, 25].", "startOffset": 148, "endOffset": 160}, {"referenceID": 38, "context": "Moreover, there is an ontology editing browser SWOOP [40] equipped with a strikeout feature [37] that highlights parts of justifications that are relevant for the entailment by striking out all irrelevant parts.", "startOffset": 53, "endOffset": 57}, {"referenceID": 35, "context": "Moreover, there is an ontology editing browser SWOOP [40] equipped with a strikeout feature [37] that highlights parts of justifications that are relevant for the entailment by striking out all irrelevant parts.", "startOffset": 92, "endOffset": 96}, {"referenceID": 71, "context": "Two common methods employed for the computation of (minimal) diagnoses [74, 63] are the QuickXPlain algorithm [36] (in short QX) and a hitting set search tree [60, 22] (in short HS).", "startOffset": 71, "endOffset": 79}, {"referenceID": 61, "context": "Two common methods employed for the computation of (minimal) diagnoses [74, 63] are the QuickXPlain algorithm [36] (in short QX) and a hitting set search tree [60, 22] (in short HS).", "startOffset": 71, "endOffset": 79}, {"referenceID": 34, "context": "Two common methods employed for the computation of (minimal) diagnoses [74, 63] are the QuickXPlain algorithm [36] (in short QX) and a hitting set search tree [60, 22] (in short HS).", "startOffset": 110, "endOffset": 114}, {"referenceID": 58, "context": "Two common methods employed for the computation of (minimal) diagnoses [74, 63] are the QuickXPlain algorithm [36] (in short QX) and a hitting set search tree [60, 22] (in short HS).", "startOffset": 159, "endOffset": 167}, {"referenceID": 20, "context": "Two common methods employed for the computation of (minimal) diagnoses [74, 63] are the QuickXPlain algorithm [36] (in short QX) and a hitting set search tree [60, 22] (in short HS).", "startOffset": 159, "endOffset": 167}, {"referenceID": 36, "context": "Another approach for computing a minimal conflict set (or justification) is the \u201cexpand-and-shrink\u201d algorithm presented in [38].", "startOffset": 123, "endOffset": 127}, {"referenceID": 72, "context": "However, empirical evaluations and a theoretical analysis of the best and worst case complexity of the \u201cexpand-and-shrink\u201d method compared to QX performed in [75] revealed that the latter is preferable over the former.", "startOffset": 158, "endOffset": 162}, {"referenceID": 64, "context": "One common method is to avoid the indirection of diagnosis computation via minimal conflict sets and use algorithms that determine diagnoses directly [66], i.", "startOffset": 150, "endOffset": 154}, {"referenceID": 12, "context": "This approach has been applied for the non-interactive debugging of ontologies [14] and constraints [18].", "startOffset": 79, "endOffset": 83}, {"referenceID": 16, "context": "This approach has been applied for the non-interactive debugging of ontologies [14] and constraints [18].", "startOffset": 100, "endOffset": 104}, {"referenceID": 73, "context": "In our previous work, we adopted such a direct technique for the interactive debugging of KBs [76].", "startOffset": 94, "endOffset": 98}, {"referenceID": 34, "context": "[36] Let \u3008K,B,P ,N \u3009R be a DPI and the function SPLIT (line 13", "startOffset": 0, "endOffset": 4}, {"referenceID": 34, "context": "[36] LetK1,K2 be a partition ofK.", "startOffset": 0, "endOffset": 4}, {"referenceID": 58, "context": "One way to compute minimal diagnoses from minimal conflict sets is to use a hitting set tree algorithm which was originally proposed by Reiter [60].", "startOffset": 143, "endOffset": 147}, {"referenceID": 17, "context": "In this work we describe methods for non-interactive and interactive diagnosis computation based on the ones used in [19, 73, 74] which are closely related to the", "startOffset": 117, "endOffset": 129}, {"referenceID": 70, "context": "In this work we describe methods for non-interactive and interactive diagnosis computation based on the ones used in [19, 73, 74] which are closely related to the", "startOffset": 117, "endOffset": 129}, {"referenceID": 71, "context": "In this work we describe methods for non-interactive and interactive diagnosis computation based on the ones used in [19, 73, 74] which are closely related to the", "startOffset": 117, "endOffset": 129}, {"referenceID": 58, "context": "a breadth-first search strategy as described in [60].", "startOffset": 48, "endOffset": 52}, {"referenceID": 58, "context": "So, we next provide formal definitions of a (partial) HS-tree and a (partial) pruned HS-tree based on the definitions given in [60].", "startOffset": 127, "endOffset": 131}, {"referenceID": 58, "context": "1 Notice that we use a definition of a pruned HS-tree that slightly differs from the definition given in [60] in that we inherently assume that only minimal conflict sets w.", "startOffset": 105, "endOffset": 109}, {"referenceID": 58, "context": "Therefore we could omit the last rule in the definition of [60].", "startOffset": 59, "endOffset": 63}, {"referenceID": 20, "context": "one and the same DPI [22].", "startOffset": 21, "endOffset": 25}, {"referenceID": 13, "context": "The induction of a probability space [15] over diagnoses facilitates incorporation of well-established probability theoretic methods into the process of KB debugging; for example, a Bayesian approach [74, 63, 44] for identifying the true diagnosis, i.", "startOffset": 37, "endOffset": 41}, {"referenceID": 71, "context": "The induction of a probability space [15] over diagnoses facilitates incorporation of well-established probability theoretic methods into the process of KB debugging; for example, a Bayesian approach [74, 63, 44] for identifying the true diagnosis, i.", "startOffset": 200, "endOffset": 212}, {"referenceID": 61, "context": "The induction of a probability space [15] over diagnoses facilitates incorporation of well-established probability theoretic methods into the process of KB debugging; for example, a Bayesian approach [74, 63, 44] for identifying the true diagnosis, i.", "startOffset": 200, "endOffset": 212}, {"referenceID": 42, "context": "The induction of a probability space [15] over diagnoses facilitates incorporation of well-established probability theoretic methods into the process of KB debugging; for example, a Bayesian approach [74, 63, 44] for identifying the true diagnosis, i.", "startOffset": 200, "endOffset": 212}, {"referenceID": 0, "context": "p : E \u2192 [0, 1] such that \u2211 \u03c9\u2208\u03a9 p({\u03c9}) = 1 which means \u2211 D\u2208aD\u3008K,B,P,N\u3009R p({D}) = 1.", "startOffset": 8, "endOffset": 14}, {"referenceID": 52, "context": "Examples of such KB (ontology) developing environments are Prot\u00e9g\u00e9 [54], Web Prot\u00e9g\u00e9 [85], SWOOP [40], OntoEdit [83] or KAON24.", "startOffset": 67, "endOffset": 71}, {"referenceID": 82, "context": "Examples of such KB (ontology) developing environments are Prot\u00e9g\u00e9 [54], Web Prot\u00e9g\u00e9 [85], SWOOP [40], OntoEdit [83] or KAON24.", "startOffset": 85, "endOffset": 89}, {"referenceID": 38, "context": "Examples of such KB (ontology) developing environments are Prot\u00e9g\u00e9 [54], Web Prot\u00e9g\u00e9 [85], SWOOP [40], OntoEdit [83] or KAON24.", "startOffset": 97, "endOffset": 101}, {"referenceID": 80, "context": "Examples of such KB (ontology) developing environments are Prot\u00e9g\u00e9 [54], Web Prot\u00e9g\u00e9 [85], SWOOP [40], OntoEdit [83] or KAON24.", "startOffset": 112, "endOffset": 116}, {"referenceID": 71, "context": "On the positive side, utilization of such empirical data can yield to fault information that is very well tailored for the user and that can imply a significant reduction of computation time and user effort necessary for debugging of the KB at hand [74].", "startOffset": 249, "endOffset": 253}, {"referenceID": 57, "context": "Ad (c): A common fault pattern [59, 12, 39], also called anti-pattern, refers to a set of formulas that either leads to an inconsistency (logical anti-pattern) or corresponds to a potential modeling error that \u2013 alone \u2013 does not lead to a inconsistency or incoherency (non-logical anti-pattern), but still might become a source of inconsistency if merged with other formulas (cf.", "startOffset": 31, "endOffset": 43}, {"referenceID": 10, "context": "Ad (c): A common fault pattern [59, 12, 39], also called anti-pattern, refers to a set of formulas that either leads to an inconsistency (logical anti-pattern) or corresponds to a potential modeling error that \u2013 alone \u2013 does not lead to a inconsistency or incoherency (non-logical anti-pattern), but still might become a source of inconsistency if merged with other formulas (cf.", "startOffset": 31, "endOffset": 43}, {"referenceID": 37, "context": "Ad (c): A common fault pattern [59, 12, 39], also called anti-pattern, refers to a set of formulas that either leads to an inconsistency (logical anti-pattern) or corresponds to a potential modeling error that \u2013 alone \u2013 does not lead to a inconsistency or incoherency (non-logical anti-pattern), but still might become a source of inconsistency if merged with other formulas (cf.", "startOffset": 31, "endOffset": 43}, {"referenceID": 23, "context": "The length of formulas could be defined similarly as in [25] which provides such a definition for DL languages.", "startOffset": 56, "endOffset": 60}, {"referenceID": 71, "context": "Moreover, experiments in our previous work [74] have manifested that fault information of only \u201caverage\u201d quality most often leads to a better performance than no fault information.", "startOffset": 43, "endOffset": 47}, {"referenceID": 61, "context": "Apart from that, we have suggested a reinforcement learning \u201cplug-in\u201d to a debugger which could successfully mitigate the negative effect of low-quality fault information and in many cases, in spite of the low-quality fault information, even led to lower resource consumption (user, time) than a debugger without this plug-in using good fault information [63].", "startOffset": 355, "endOffset": 359}, {"referenceID": 37, "context": "[39]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "Let p : K \u2192 [0, 1] be some function that assigns to each ax \u2208 K some p(ax ) \u2208 [0, 1].", "startOffset": 12, "endOffset": 18}, {"referenceID": 0, "context": "Let p : K \u2192 [0, 1] be some function that assigns to each ax \u2208 K some p(ax ) \u2208 [0, 1].", "startOffset": 78, "endOffset": 84}, {"referenceID": 0, "context": "Then, we denote by pnodes : 2K \u2192 [0, 1] the function that assigns to each node nd \u2286 K some pnodes(nd) \u2208 [0, 1] which is obtained by means of Formula 4.", "startOffset": 33, "endOffset": 39}, {"referenceID": 0, "context": "Then, we denote by pnodes : 2K \u2192 [0, 1] the function that assigns to each node nd \u2286 K some pnodes(nd) \u2208 [0, 1] which is obtained by means of Formula 4.", "startOffset": 104, "endOffset": 110}, {"referenceID": 0, "context": "Let \u3008K,B,P ,N \u3009R be an admissible DPI and let w : K \u2192 [0, 1] be a weight function which assigns a weight to each node n \u2286 K with the property that w(n1) > w(n2) if n1 \u2282 n2.", "startOffset": 54, "endOffset": 60}, {"referenceID": 0, "context": "So, the output is the set of all minimal diagnoses mD\u3008K,B,P,N \u3009R = {[1], [2], [5, 7]}.", "startOffset": 68, "endOffset": 71}, {"referenceID": 1, "context": "So, the output is the set of all minimal diagnoses mD\u3008K,B,P,N \u3009R = {[1], [2], [5, 7]}.", "startOffset": 73, "endOffset": 76}, {"referenceID": 5, "context": "So, the output is the set of all minimal diagnoses mD\u3008K,B,P,N \u3009R = {[1], [2], [5, 7]}.", "startOffset": 78, "endOffset": 84}, {"referenceID": 0, "context": "2 would be constructed and the output would be D = {D1} = {[1]} containing just the first found and thus most probable minimal diagnosis w.", "startOffset": 59, "endOffset": 62}, {"referenceID": 0, "context": "Note that D1 = [1] and D2 = [2] (which is not computed) have equal probability and whether the one or the other is computed first depends only on the ordering of equally probable (in this case: equal cardinality) nodes in Q.", "startOffset": 15, "endOffset": 18}, {"referenceID": 1, "context": "Note that D1 = [1] and D2 = [2] (which is not computed) have equal probability and whether the one or the other is computed first depends only on the ordering of equally probable (in this case: equal cardinality) nodes in Q.", "startOffset": 28, "endOffset": 31}, {"referenceID": 35, "context": "Please notice that the internal \u201cflat\u201d representation used by Algorithm 2 which does not store a tree but only the set of open and closed nodes differs from the standard tree representation [37, 19, 82, 60] we use to depict the hitting set tree graphically in Figure 4.", "startOffset": 190, "endOffset": 206}, {"referenceID": 17, "context": "Please notice that the internal \u201cflat\u201d representation used by Algorithm 2 which does not store a tree but only the set of open and closed nodes differs from the standard tree representation [37, 19, 82, 60] we use to depict the hitting set tree graphically in Figure 4.", "startOffset": 190, "endOffset": 206}, {"referenceID": 79, "context": "Please notice that the internal \u201cflat\u201d representation used by Algorithm 2 which does not store a tree but only the set of open and closed nodes differs from the standard tree representation [37, 19, 82, 60] we use to depict the hitting set tree graphically in Figure 4.", "startOffset": 190, "endOffset": 206}, {"referenceID": 58, "context": "Please notice that the internal \u201cflat\u201d representation used by Algorithm 2 which does not store a tree but only the set of open and closed nodes differs from the standard tree representation [37, 19, 82, 60] we use to depict the hitting set tree graphically in Figure 4.", "startOffset": 190, "endOffset": 206}, {"referenceID": 1, "context": "This already leads to the finding of the first minimal diagnosis D1 = [2] after overall computation time of 0.", "startOffset": 70, "endOffset": 73}, {"referenceID": 1, "context": "As a next step, again the first and thus best open node {2, 5} is chosen from Q and labeled by \u00d7(\u2283D1) which means that the corresponding path is closed since it is a superset of an already found minimal diagnosis, namely D1 = [2].", "startOffset": 226, "endOffset": 229}, {"referenceID": 1, "context": "1 seconds execution time is the set of minimal diagnoses D = {[2], [5, 7]} which is a proper subset of all minimal diagnoses D\u3008K,B,P,N \u3009R = {[1], [2], [5, 7]}.", "startOffset": 62, "endOffset": 65}, {"referenceID": 5, "context": "1 seconds execution time is the set of minimal diagnoses D = {[2], [5, 7]} which is a proper subset of all minimal diagnoses D\u3008K,B,P,N \u3009R = {[1], [2], [5, 7]}.", "startOffset": 67, "endOffset": 73}, {"referenceID": 0, "context": "1 seconds execution time is the set of minimal diagnoses D = {[2], [5, 7]} which is a proper subset of all minimal diagnoses D\u3008K,B,P,N \u3009R = {[1], [2], [5, 7]}.", "startOffset": 141, "endOffset": 144}, {"referenceID": 1, "context": "1 seconds execution time is the set of minimal diagnoses D = {[2], [5, 7]} which is a proper subset of all minimal diagnoses D\u3008K,B,P,N \u3009R = {[1], [2], [5, 7]}.", "startOffset": 146, "endOffset": 149}, {"referenceID": 5, "context": "1 seconds execution time is the set of minimal diagnoses D = {[2], [5, 7]} which is a proper subset of all minimal diagnoses D\u3008K,B,P,N \u3009R = {[1], [2], [5, 7]}.", "startOffset": 151, "endOffset": 157}, {"referenceID": 70, "context": "For instance, [73] reported on one DPI where computation of all minimal diagnoses, 1782 in number, is feasible.", "startOffset": 14, "endOffset": 18}, {"referenceID": 0, "context": "For our example DPI, a user getting the output D = mD\u3008K,B,P,N \u3009R = {[1], [2], [5, 7]} with the computed probabilities p([1]) = 12%, p([2]) = 60% and p([5, 7]) = 28% might decide to just inspect the diagnoses that make the most probable 80% fraction of diagnoses.", "startOffset": 68, "endOffset": 71}, {"referenceID": 1, "context": "For our example DPI, a user getting the output D = mD\u3008K,B,P,N \u3009R = {[1], [2], [5, 7]} with the computed probabilities p([1]) = 12%, p([2]) = 60% and p([5, 7]) = 28% might decide to just inspect the diagnoses that make the most probable 80% fraction of diagnoses.", "startOffset": 73, "endOffset": 76}, {"referenceID": 5, "context": "For our example DPI, a user getting the output D = mD\u3008K,B,P,N \u3009R = {[1], [2], [5, 7]} with the computed probabilities p([1]) = 12%, p([2]) = 60% and p([5, 7]) = 28% might decide to just inspect the diagnoses that make the most probable 80% fraction of diagnoses.", "startOffset": 78, "endOffset": 84}, {"referenceID": 0, "context": "For our example DPI, a user getting the output D = mD\u3008K,B,P,N \u3009R = {[1], [2], [5, 7]} with the computed probabilities p([1]) = 12%, p([2]) = 60% and p([5, 7]) = 28% might decide to just inspect the diagnoses that make the most probable 80% fraction of diagnoses.", "startOffset": 120, "endOffset": 123}, {"referenceID": 1, "context": "For our example DPI, a user getting the output D = mD\u3008K,B,P,N \u3009R = {[1], [2], [5, 7]} with the computed probabilities p([1]) = 12%, p([2]) = 60% and p([5, 7]) = 28% might decide to just inspect the diagnoses that make the most probable 80% fraction of diagnoses.", "startOffset": 134, "endOffset": 137}, {"referenceID": 5, "context": "For our example DPI, a user getting the output D = mD\u3008K,B,P,N \u3009R = {[1], [2], [5, 7]} with the computed probabilities p([1]) = 12%, p([2]) = 60% and p([5, 7]) = 28% might decide to just inspect the diagnoses that make the most probable 80% fraction of diagnoses.", "startOffset": 151, "endOffset": 157}, {"referenceID": 1, "context": "In this case, either [2] or [5, 7] would be selected, which corresponds to a wrong choice in case E \u2192 G should be entailed be the resulting solution KB after integration with the background KB B.", "startOffset": 21, "endOffset": 24}, {"referenceID": 5, "context": "In this case, either [2] or [5, 7] would be selected, which corresponds to a wrong choice in case E \u2192 G should be entailed be the resulting solution KB after integration with the background KB B.", "startOffset": 28, "endOffset": 34}, {"referenceID": 42, "context": "Thus, the principle of interactive KB debugging is based on that of Sequential Diagnosis which has been suggested by [44] as an iterative way to localize the faulty components (among an initially large set of possibilities) in malfunctioning digital circuits by performing repeated (most informative) measurements.", "startOffset": 117, "endOffset": 121}, {"referenceID": 70, "context": "We have shown in our previous works [73, 74] how sequential diagnosis can be applied to KBs (ontologies).", "startOffset": 36, "endOffset": 44}, {"referenceID": 71, "context": "We have shown in our previous works [73, 74] how sequential diagnosis can be applied to KBs (ontologies).", "startOffset": 36, "endOffset": 44}, {"referenceID": 42, "context": "1Note that the minimal a-posteriori expected entropy of solution candidate probabilities as a means to select the best next measurement as used in [44] is only one of many possible active learning strategies [71].", "startOffset": 147, "endOffset": 151}, {"referenceID": 71, "context": "\u3008K,B,P ,N \u3009R [74].", "startOffset": 13, "endOffset": 17}, {"referenceID": 61, "context": "3 and [63, 73, 74] for details.", "startOffset": 6, "endOffset": 18}, {"referenceID": 70, "context": "3 and [63, 73, 74] for details.", "startOffset": 6, "endOffset": 18}, {"referenceID": 71, "context": "3 and [63, 73, 74] for details.", "startOffset": 6, "endOffset": 18}, {"referenceID": 71, "context": "[74, 63, 73], a q-partition is often simply referred to as partition.", "startOffset": 0, "endOffset": 12}, {"referenceID": 61, "context": "[74, 63, 73], a q-partition is often simply referred to as partition.", "startOffset": 0, "endOffset": 12}, {"referenceID": 70, "context": "[74, 63, 73], a q-partition is often simply referred to as partition.", "startOffset": 0, "endOffset": 12}, {"referenceID": 71, "context": "With Algorithm 4, similar versions of which can be found in [74, 63], we present a way to compute a pool QP of queries and associated q-partitions w.", "startOffset": 60, "endOffset": 68}, {"referenceID": 61, "context": "With Algorithm 4, similar versions of which can be found in [74, 63], we present a way to compute a pool QP of queries and associated q-partitions w.", "startOffset": 60, "endOffset": 68}, {"referenceID": 0, "context": "D = mD\u3008K,B,P,N \u3009R = {D1,D2,D3,D4} = {[1], [3], [4, 5], [2, 4]}.", "startOffset": 37, "endOffset": 40}, {"referenceID": 2, "context": "D = mD\u3008K,B,P,N \u3009R = {D1,D2,D3,D4} = {[1], [3], [4, 5], [2, 4]}.", "startOffset": 42, "endOffset": 45}, {"referenceID": 3, "context": "D = mD\u3008K,B,P,N \u3009R = {D1,D2,D3,D4} = {[1], [3], [4, 5], [2, 4]}.", "startOffset": 47, "endOffset": 53}, {"referenceID": 1, "context": "D = mD\u3008K,B,P,N \u3009R = {D1,D2,D3,D4} = {[1], [3], [4, 5], [2, 4]}.", "startOffset": 55, "endOffset": 61}, {"referenceID": 3, "context": "D = mD\u3008K,B,P,N \u3009R = {D1,D2,D3,D4} = {[1], [3], [4, 5], [2, 4]}.", "startOffset": 55, "endOffset": 61}, {"referenceID": 3, "context": "For our manual construction, let S = {D3,D4} = {[4, 5], [2, 4]}.", "startOffset": 48, "endOffset": 54}, {"referenceID": 1, "context": "For our manual construction, let S = {D3,D4} = {[4, 5], [2, 4]}.", "startOffset": 56, "endOffset": 62}, {"referenceID": 3, "context": "For our manual construction, let S = {D3,D4} = {[4, 5], [2, 4]}.", "startOffset": 56, "endOffset": 62}, {"referenceID": 75, "context": "For this purpose, DL and OWL reasoners, respectively, such as Pellet [78], HermiT [77], FaCT++ [84] or KAON25 could be used with their classification and realization reasoning services.", "startOffset": 69, "endOffset": 73}, {"referenceID": 74, "context": "For this purpose, DL and OWL reasoners, respectively, such as Pellet [78], HermiT [77], FaCT++ [84] or KAON25 could be used with their classification and realization reasoning services.", "startOffset": 82, "endOffset": 86}, {"referenceID": 81, "context": "For this purpose, DL and OWL reasoners, respectively, such as Pellet [78], HermiT [77], FaCT++ [84] or KAON25 could be used with their classification and realization reasoning services.", "startOffset": 95, "endOffset": 99}, {"referenceID": 39, "context": "What militates for such a black-box approach is the generality and independence of a particular logic (for which an adequate glass-box reasoner exists), the easier implementation of the debugging system and potential performance issues with a glass-box approach [41].", "startOffset": 262, "endOffset": 266}, {"referenceID": 71, "context": "[74, 63]).", "startOffset": 0, "endOffset": 8}, {"referenceID": 61, "context": "[74, 63]).", "startOffset": 0, "endOffset": 8}, {"referenceID": 0, "context": "this DPI were given by mC\u3008K,B,P,N \u3009R = {C1, C2} = {\u30081, 3, 4\u3009 , \u30081, 2, 3, 5\u3009} as well as mD\u3008K,B,P,N \u3009R = {D1,D2,D3,D4} = {[1], [3], [4, 5], [2, 4]}.", "startOffset": 121, "endOffset": 124}, {"referenceID": 2, "context": "this DPI were given by mC\u3008K,B,P,N \u3009R = {C1, C2} = {\u30081, 3, 4\u3009 , \u30081, 2, 3, 5\u3009} as well as mD\u3008K,B,P,N \u3009R = {D1,D2,D3,D4} = {[1], [3], [4, 5], [2, 4]}.", "startOffset": 126, "endOffset": 129}, {"referenceID": 3, "context": "this DPI were given by mC\u3008K,B,P,N \u3009R = {C1, C2} = {\u30081, 3, 4\u3009 , \u30081, 2, 3, 5\u3009} as well as mD\u3008K,B,P,N \u3009R = {D1,D2,D3,D4} = {[1], [3], [4, 5], [2, 4]}.", "startOffset": 131, "endOffset": 137}, {"referenceID": 1, "context": "this DPI were given by mC\u3008K,B,P,N \u3009R = {C1, C2} = {\u30081, 3, 4\u3009 , \u30081, 2, 3, 5\u3009} as well as mD\u3008K,B,P,N \u3009R = {D1,D2,D3,D4} = {[1], [3], [4, 5], [2, 4]}.", "startOffset": 139, "endOffset": 145}, {"referenceID": 3, "context": "this DPI were given by mC\u3008K,B,P,N \u3009R = {C1, C2} = {\u30081, 3, 4\u3009 , \u30081, 2, 3, 5\u3009} as well as mD\u3008K,B,P,N \u3009R = {D1,D2,D3,D4} = {[1], [3], [4, 5], [2, 4]}.", "startOffset": 139, "endOffset": 145}, {"referenceID": 8, "context": "This could be accomplished, for example, by some resolution-based reasoning procedure [10].", "startOffset": 86, "endOffset": 90}, {"referenceID": 1, "context": "This holds due to the construction of Q6 as UD \\ D4 = {1, 2, 3, 4, 5} \\ [2, 4] = {1, 3, 5} (recall that we use squared brackets to denote diagnoses in spite of the fact that these are sets, cf.", "startOffset": 72, "endOffset": 78}, {"referenceID": 3, "context": "This holds due to the construction of Q6 as UD \\ D4 = {1, 2, 3, 4, 5} \\ [2, 4] = {1, 3, 5} (recall that we use squared brackets to denote diagnoses in spite of the fact that these are sets, cf.", "startOffset": 72, "endOffset": 78}, {"referenceID": 11, "context": "In other words, minus reasoning time, the generation of a pool of queries is a fixed parameter tractable problem [13] in the context of interactive KB debugging.", "startOffset": 113, "endOffset": 117}, {"referenceID": 71, "context": "a certain quantitative measure qsm() such as information gain [74, 63] by calculating a (generally exponentially large) pool QP of queries in a first stage, whereupon qsm(Q) \u2208 R is evaluated for Q \u2208 QP until the one Q\u2217 with optimal qsm(Q\u2217) is found and selected as the query to be asked to the user.", "startOffset": 62, "endOffset": 70}, {"referenceID": 61, "context": "a certain quantitative measure qsm() such as information gain [74, 63] by calculating a (generally exponentially large) pool QP of queries in a first stage, whereupon qsm(Q) \u2208 R is evaluated for Q \u2208 QP until the one Q\u2217 with optimal qsm(Q\u2217) is found and selected as the query to be asked to the user.", "startOffset": 62, "endOffset": 70}, {"referenceID": 71, "context": "in interactive debugging scenarios [74, 63, 73].", "startOffset": 35, "endOffset": 47}, {"referenceID": 61, "context": "in interactive debugging scenarios [74, 63, 73].", "startOffset": 35, "endOffset": 47}, {"referenceID": 70, "context": "in interactive debugging scenarios [74, 63, 73].", "startOffset": 35, "endOffset": 47}, {"referenceID": 71, "context": "A similar strategy called CKK has been employed in [74] for the information gain measure (see Section 5.", "startOffset": 51, "endOffset": 55}, {"referenceID": 0, "context": "\u2022 a maximum fault tolerance \u03c3 \u2208 [0, 1] and \u2022 a mode mode \u2208 {static, dynamic} that determines the used method for diagnosis computation.", "startOffset": 32, "endOffset": 38}, {"referenceID": 71, "context": "Diverse measures that can be used as a qsm() function in this algorithm have been discussed and evaluated within the scope of interactive KB debugging in literature [74, 63] (for details see Section 5.", "startOffset": 165, "endOffset": 173}, {"referenceID": 61, "context": "Diverse measures that can be used as a qsm() function in this algorithm have been discussed and evaluated within the scope of interactive KB debugging in literature [74, 63] (for details see Section 5.", "startOffset": 165, "endOffset": 173}, {"referenceID": 61, "context": "An example of a qsm() strategy using one such metric, namely the ratio of leading diagnoses invalidated by a test case, can be found in [63].", "startOffset": 136, "endOffset": 140}, {"referenceID": 42, "context": "[44])", "startOffset": 0, "endOffset": 4}, {"referenceID": 71, "context": "In this section, we give a brief introduction to some query selection measures qsm() that have been suggested and evaluated in literature within the scope of KB or ontology debugging [74, 63].", "startOffset": 183, "endOffset": 191}, {"referenceID": 61, "context": "In this section, we give a brief introduction to some query selection measures qsm() that have been suggested and evaluated in literature within the scope of KB or ontology debugging [74, 63].", "startOffset": 183, "endOffset": 191}, {"referenceID": 71, "context": "In our previous work [74], we have discussed entropy-based (ENT()) and split-in-half (SPL()) query selection measures.", "startOffset": 21, "endOffset": 25}, {"referenceID": 42, "context": "As shown in [44], this leads to the definition", "startOffset": 12, "endOffset": 16}, {"referenceID": 61, "context": "For scenarios where a-priori probabilities are vague, we have presented another more complex query selection measure RIO() in [63] which uses a reinforcement learning strategy to constantly adapt some \u201crisk\u201d parameter that indicates the current amount of trust in the probabilities.", "startOffset": 126, "endOffset": 130}, {"referenceID": 71, "context": "High trust in the probabilities means usage of ENT() which can exploit high quality fault information well as demonstrated in the experiments conducted in [74], whereas low trust involves selection of queries that guarantee a higher worst case invalidation rate, i.", "startOffset": 155, "endOffset": 159}, {"referenceID": 0, "context": "In this vein, first [1] and then [2] are identified as minimal diagnoses w.", "startOffset": 20, "endOffset": 23}, {"referenceID": 1, "context": "In this vein, first [1] and then [2] are identified as minimal diagnoses w.", "startOffset": 33, "endOffset": 36}, {"referenceID": 0, "context": "Since DX\u222aDcalc = \u2205\u222a{[1], [2]} has a cardinality of nmin = nmax = 2, the stop criterion of STATICHS causes it to terminate and return \u3008Dcalc \u222aDX,Ccalc,Q,D\u00d7\u3009 = \u3008{[1], [2]} , {\u30081, 2, 5\u3009} , [{5}], \u2205\u3009 (because DX and D\u00d7 are initially empty sets), as shown in the upper right column in Figure 6.", "startOffset": 20, "endOffset": 23}, {"referenceID": 1, "context": "Since DX\u222aDcalc = \u2205\u222a{[1], [2]} has a cardinality of nmin = nmax = 2, the stop criterion of STATICHS causes it to terminate and return \u3008Dcalc \u222aDX,Ccalc,Q,D\u00d7\u3009 = \u3008{[1], [2]} , {\u30081, 2, 5\u3009} , [{5}], \u2205\u3009 (because DX and D\u00d7 are initially empty sets), as shown in the upper right column in Figure 6.", "startOffset": 25, "endOffset": 28}, {"referenceID": 0, "context": "Since DX\u222aDcalc = \u2205\u222a{[1], [2]} has a cardinality of nmin = nmax = 2, the stop criterion of STATICHS causes it to terminate and return \u3008Dcalc \u222aDX,Ccalc,Q,D\u00d7\u3009 = \u3008{[1], [2]} , {\u30081, 2, 5\u3009} , [{5}], \u2205\u3009 (because DX and D\u00d7 are initially empty sets), as shown in the upper right column in Figure 6.", "startOffset": 160, "endOffset": 163}, {"referenceID": 1, "context": "Since DX\u222aDcalc = \u2205\u222a{[1], [2]} has a cardinality of nmin = nmax = 2, the stop criterion of STATICHS causes it to terminate and return \u3008Dcalc \u222aDX,Ccalc,Q,D\u00d7\u3009 = \u3008{[1], [2]} , {\u30081, 2, 5\u3009} , [{5}], \u2205\u3009 (because DX and D\u00d7 are initially empty sets), as shown in the upper right column in Figure 6.", "startOffset": 165, "endOffset": 168}, {"referenceID": 0, "context": "Then, in Algorithm 5, outside of the STATICHS procedure, the first query Q1 = {E \u2192 \u00acA} is computed from the leading diagnoses set {[1], [2]}.", "startOffset": 131, "endOffset": 134}, {"referenceID": 1, "context": "Then, in Algorithm 5, outside of the STATICHS procedure, the first query Q1 = {E \u2192 \u00acA} is computed from the leading diagnoses set {[1], [2]}.", "startOffset": 136, "endOffset": 139}, {"referenceID": 0, "context": "The q-partition P(Q1) associated withQ1 is \u3008{[1]} , {[2]}, \u2205\u3009.", "startOffset": 45, "endOffset": 48}, {"referenceID": 1, "context": "The q-partition P(Q1) associated withQ1 is \u3008{[1]} , {[2]}, \u2205\u3009.", "startOffset": 53, "endOffset": 56}, {"referenceID": 0, "context": "Thence, the set Dout is calculated from P(Q1) as D(Q1) = {[1]} (due to negative answer, cf.", "startOffset": 58, "endOffset": 61}, {"referenceID": 1, "context": "6), deleted from DX := DX \u222aDcalc to yield DX = {[2]} and added to D\u00d7 to yield D\u00d7 = {[1]}.", "startOffset": 48, "endOffset": 51}, {"referenceID": 0, "context": "6), deleted from DX := DX \u222aDcalc to yield DX = {[2]} and added to D\u00d7 to yield D\u00d7 = {[1]}.", "startOffset": 84, "endOffset": 87}, {"referenceID": 0, "context": "Whereas the branches with edge labels {5, 1} and {5, 2} correspond to proper supersets of the minimal diagnoses [1] and [2], respectively, w.", "startOffset": 112, "endOffset": 115}, {"referenceID": 1, "context": "Whereas the branches with edge labels {5, 1} and {5, 2} correspond to proper supersets of the minimal diagnoses [1] and [2], respectively, w.", "startOffset": 120, "endOffset": 123}, {"referenceID": 5, "context": "the input DPI \u3008K,B,P ,N \u3009R and are thus closed by the non-minimality criterion tested in the SLABEL function, the branch with edge labels {5, 7} is identified as a minimal diagnosis D3 := [5, 7] w.", "startOffset": 188, "endOffset": 194}, {"referenceID": 0, "context": "Further, let the user have extracted term and logical construct probabilities pK\u0303\u222aK(ax ) \u2208 [0, 1] for ax \u2208 K for auth from this data.", "startOffset": 91, "endOffset": 97}, {"referenceID": 0, "context": "This function pK\u0303\u222aK : K\u0303 \u222a K \u2192 [0, 1] is then provided as an input to Algorithm 5.", "startOffset": 31, "endOffset": 37}, {"referenceID": 0, "context": "Since STATICHS always treats the first node of Q next, it identifies the first minimal diagnosis D1 := [1, 4] w.", "startOffset": 103, "endOffset": 109}, {"referenceID": 3, "context": "Since STATICHS always treats the first node of Q next, it identifies the first minimal diagnosis D1 := [1, 4] w.", "startOffset": 103, "endOffset": 109}, {"referenceID": 0, "context": "In steps 4 \u00a9 and 8 \u00a9, two further minimal diagnoses D2 := [1, 6] and D3 := [5, 4] are detected.", "startOffset": 58, "endOffset": 64}, {"referenceID": 4, "context": "In steps 4 \u00a9 and 8 \u00a9, two further minimal diagnoses D2 := [1, 6] and D3 := [5, 4] are detected.", "startOffset": 58, "endOffset": 64}, {"referenceID": 3, "context": "In steps 4 \u00a9 and 8 \u00a9, two further minimal diagnoses D2 := [1, 6] and D3 := [5, 4] are detected.", "startOffset": 75, "endOffset": 81}, {"referenceID": 0, "context": "From this set of leading diagnoses DX := DX \u222a Dcalc, the probability measure pD : DX \u2192 [0, 1] is computed by the function GETPROBDIST (cf.", "startOffset": 87, "endOffset": 93}, {"referenceID": 1, "context": "In the same fashion, further node labelings are conducted in iteration 2 until |DX \u222a Dcalc| = | {D1,D2} \u222a {[2, 1]} | = 3 = nmin = nmax holds again.", "startOffset": 107, "endOffset": 113}, {"referenceID": 0, "context": "In the same fashion, further node labelings are conducted in iteration 2 until |DX \u222a Dcalc| = | {D1,D2} \u222a {[2, 1]} | = 3 = nmin = nmax holds again.", "startOffset": 107, "endOffset": 113}, {"referenceID": 1, "context": "Moreover, we want to point out that another minimal diagnosis (D4 = [2, 4, 6]) is found in iteration 2 before D5 is detected.", "startOffset": 68, "endOffset": 77}, {"referenceID": 3, "context": "Moreover, we want to point out that another minimal diagnosis (D4 = [2, 4, 6]) is found in iteration 2 before D5 is detected.", "startOffset": 68, "endOffset": 77}, {"referenceID": 4, "context": "Moreover, we want to point out that another minimal diagnosis (D4 = [2, 4, 6]) is found in iteration 2 before D5 is detected.", "startOffset": 68, "endOffset": 77}, {"referenceID": 0, "context": "Iteration 1 \u3009 DX \u222aDcalc = \u2205 \u222a {D1,D2} = {[1], [2]} Q = [{5}] Ccalc = {\u30081, 2, 5\u3009} D\u00d7 = \u2205", "startOffset": 41, "endOffset": 44}, {"referenceID": 1, "context": "Iteration 1 \u3009 DX \u222aDcalc = \u2205 \u222a {D1,D2} = {[1], [2]} Q = [{5}] Ccalc = {\u30081, 2, 5\u3009} D\u00d7 = \u2205", "startOffset": 46, "endOffset": 49}, {"referenceID": 1, "context": "Iteration 2 \u3009 DX \u222aDcalc = {D2} \u222a {D3} = {[2], [5, 7]}", "startOffset": 41, "endOffset": 44}, {"referenceID": 5, "context": "Iteration 2 \u3009 DX \u222aDcalc = {D2} \u222a {D3} = {[2], [5, 7]}", "startOffset": 46, "endOffset": 52}, {"referenceID": 0, "context": "D\u00d7 = {D1} = {[1]}", "startOffset": 13, "endOffset": 16}, {"referenceID": 5, "context": "Iteration 3 \u3009 DX \u222aDcalc = {D3} \u222a \u2205 = {[5, 7]}", "startOffset": 38, "endOffset": 44}, {"referenceID": 0, "context": "D\u00d7 = {D1,D2} = {[1], [2]}", "startOffset": 16, "endOffset": 19}, {"referenceID": 1, "context": "D\u00d7 = {D1,D2} = {[1], [2]}", "startOffset": 21, "endOffset": 24}, {"referenceID": 0, "context": "D X \u222a D c a lc = \u2205 \u222a {D 1 ,D 2 ,D 3 } = { 1 ,4 ], [1 ,6 ], [5 ,4 ]} , Q = [{ 5 ,6 } ,{ 2 ,4 ,6 } ,{ 1 ,2 } ,{ 2 ,1 } ,{ 2 ,3 } ,{ 5 ,2 } ,{ 2 ,4 ,1 } ,{ 2 ,4 ,5 } ,{ 2 ,4 ,8 } , D \u00d7 = \u2205", "startOffset": 50, "endOffset": 57}, {"referenceID": 4, "context": "D X \u222a D c a lc = \u2205 \u222a {D 1 ,D 2 ,D 3 } = { 1 ,4 ], [1 ,6 ], [5 ,4 ]} , Q = [{ 5 ,6 } ,{ 2 ,4 ,6 } ,{ 1 ,2 } ,{ 2 ,1 } ,{ 2 ,3 } ,{ 5 ,2 } ,{ 2 ,4 ,1 } ,{ 2 ,4 ,5 } ,{ 2 ,4 ,8 } , D \u00d7 = \u2205", "startOffset": 50, "endOffset": 57}, {"referenceID": 3, "context": "D X \u222a D c a lc = \u2205 \u222a {D 1 ,D 2 ,D 3 } = { 1 ,4 ], [1 ,6 ], [5 ,4 ]} , Q = [{ 5 ,6 } ,{ 2 ,4 ,6 } ,{ 1 ,2 } ,{ 2 ,1 } ,{ 2 ,3 } ,{ 5 ,2 } ,{ 2 ,4 ,1 } ,{ 2 ,4 ,5 } ,{ 2 ,4 ,8 } , D \u00d7 = \u2205", "startOffset": 59, "endOffset": 66}, {"referenceID": 0, "context": "D X \u222a D c a lc = {D 1 ,D 2 } \u222a {D 5 } = { 1 ,4 ], [1 ,6 ], [2 ,1 ]} , Q = [{ 2 ,4 ,6 } ,{ 2 ,3 } ,{ 5 ,2 } ,{ 2 ,4 ,1 } ,{ 5 ,6 ,1 } ,{ 2 ,4 ,5 } ,{ 5 ,6 ,3 } , D \u00d7 = {D 3 ,D 4 } = { 5 ,4 ], [2 ,4 ,6 ]}", "startOffset": 50, "endOffset": 57}, {"referenceID": 4, "context": "D X \u222a D c a lc = {D 1 ,D 2 } \u222a {D 5 } = { 1 ,4 ], [1 ,6 ], [2 ,1 ]} , Q = [{ 2 ,4 ,6 } ,{ 2 ,3 } ,{ 5 ,2 } ,{ 2 ,4 ,1 } ,{ 5 ,6 ,1 } ,{ 2 ,4 ,5 } ,{ 5 ,6 ,3 } , D \u00d7 = {D 3 ,D 4 } = { 5 ,4 ], [2 ,4 ,6 ]}", "startOffset": 50, "endOffset": 57}, {"referenceID": 1, "context": "D X \u222a D c a lc = {D 1 ,D 2 } \u222a {D 5 } = { 1 ,4 ], [1 ,6 ], [2 ,1 ]} , Q = [{ 2 ,4 ,6 } ,{ 2 ,3 } ,{ 5 ,2 } ,{ 2 ,4 ,1 } ,{ 5 ,6 ,1 } ,{ 2 ,4 ,5 } ,{ 5 ,6 ,3 } , D \u00d7 = {D 3 ,D 4 } = { 5 ,4 ], [2 ,4 ,6 ]}", "startOffset": 59, "endOffset": 66}, {"referenceID": 0, "context": "D X \u222a D c a lc = {D 1 ,D 2 } \u222a {D 5 } = { 1 ,4 ], [1 ,6 ], [2 ,1 ]} , Q = [{ 2 ,4 ,6 } ,{ 2 ,3 } ,{ 5 ,2 } ,{ 2 ,4 ,1 } ,{ 5 ,6 ,1 } ,{ 2 ,4 ,5 } ,{ 5 ,6 ,3 } , D \u00d7 = {D 3 ,D 4 } = { 5 ,4 ], [2 ,4 ,6 ]}", "startOffset": 59, "endOffset": 66}, {"referenceID": 1, "context": "D X \u222a D c a lc = {D 1 ,D 2 } \u222a {D 5 } = { 1 ,4 ], [1 ,6 ], [2 ,1 ]} , Q = [{ 2 ,4 ,6 } ,{ 2 ,3 } ,{ 5 ,2 } ,{ 2 ,4 ,1 } ,{ 5 ,6 ,1 } ,{ 2 ,4 ,5 } ,{ 5 ,6 ,3 } , D \u00d7 = {D 3 ,D 4 } = { 5 ,4 ], [2 ,4 ,6 ]}", "startOffset": 191, "endOffset": 201}, {"referenceID": 3, "context": "D X \u222a D c a lc = {D 1 ,D 2 } \u222a {D 5 } = { 1 ,4 ], [1 ,6 ], [2 ,1 ]} , Q = [{ 2 ,4 ,6 } ,{ 2 ,3 } ,{ 5 ,2 } ,{ 2 ,4 ,1 } ,{ 5 ,6 ,1 } ,{ 2 ,4 ,5 } ,{ 5 ,6 ,3 } , D \u00d7 = {D 3 ,D 4 } = { 5 ,4 ], [2 ,4 ,6 ]}", "startOffset": 191, "endOffset": 201}, {"referenceID": 4, "context": "D X \u222a D c a lc = {D 1 ,D 2 } \u222a {D 5 } = { 1 ,4 ], [1 ,6 ], [2 ,1 ]} , Q = [{ 2 ,4 ,6 } ,{ 2 ,3 } ,{ 5 ,2 } ,{ 2 ,4 ,1 } ,{ 5 ,6 ,1 } ,{ 2 ,4 ,5 } ,{ 5 ,6 ,3 } , D \u00d7 = {D 3 ,D 4 } = { 5 ,4 ], [2 ,4 ,6 ]}", "startOffset": 191, "endOffset": 201}, {"referenceID": 1, "context": "D \u00d7 = {D 3 ,D 4 ,D 2 ,D 5 ,D 6 ,D 7 ,D 8 ,D 9 ,D 1 0 } = { 5 ,4 ], [2 ,4 ,6 ], [1 ,6 ], [2 ,1 ], [2 ,4 ,8 ], [5 ,6 ,3 ], [2 ,3 ,6 ], [2 ,3 ,8 ], [5 ,2 ,3 ]} ,", "startOffset": 67, "endOffset": 77}, {"referenceID": 3, "context": "D \u00d7 = {D 3 ,D 4 ,D 2 ,D 5 ,D 6 ,D 7 ,D 8 ,D 9 ,D 1 0 } = { 5 ,4 ], [2 ,4 ,6 ], [1 ,6 ], [2 ,1 ], [2 ,4 ,8 ], [5 ,6 ,3 ], [2 ,3 ,6 ], [2 ,3 ,8 ], [5 ,2 ,3 ]} ,", "startOffset": 67, "endOffset": 77}, {"referenceID": 4, "context": "D \u00d7 = {D 3 ,D 4 ,D 2 ,D 5 ,D 6 ,D 7 ,D 8 ,D 9 ,D 1 0 } = { 5 ,4 ], [2 ,4 ,6 ], [1 ,6 ], [2 ,1 ], [2 ,4 ,8 ], [5 ,6 ,3 ], [2 ,3 ,6 ], [2 ,3 ,8 ], [5 ,2 ,3 ]} ,", "startOffset": 67, "endOffset": 77}, {"referenceID": 0, "context": "D \u00d7 = {D 3 ,D 4 ,D 2 ,D 5 ,D 6 ,D 7 ,D 8 ,D 9 ,D 1 0 } = { 5 ,4 ], [2 ,4 ,6 ], [1 ,6 ], [2 ,1 ], [2 ,4 ,8 ], [5 ,6 ,3 ], [2 ,3 ,6 ], [2 ,3 ,8 ], [5 ,2 ,3 ]} ,", "startOffset": 79, "endOffset": 86}, {"referenceID": 4, "context": "D \u00d7 = {D 3 ,D 4 ,D 2 ,D 5 ,D 6 ,D 7 ,D 8 ,D 9 ,D 1 0 } = { 5 ,4 ], [2 ,4 ,6 ], [1 ,6 ], [2 ,1 ], [2 ,4 ,8 ], [5 ,6 ,3 ], [2 ,3 ,6 ], [2 ,3 ,8 ], [5 ,2 ,3 ]} ,", "startOffset": 79, "endOffset": 86}, {"referenceID": 1, "context": "D \u00d7 = {D 3 ,D 4 ,D 2 ,D 5 ,D 6 ,D 7 ,D 8 ,D 9 ,D 1 0 } = { 5 ,4 ], [2 ,4 ,6 ], [1 ,6 ], [2 ,1 ], [2 ,4 ,8 ], [5 ,6 ,3 ], [2 ,3 ,6 ], [2 ,3 ,8 ], [5 ,2 ,3 ]} ,", "startOffset": 88, "endOffset": 95}, {"referenceID": 0, "context": "D \u00d7 = {D 3 ,D 4 ,D 2 ,D 5 ,D 6 ,D 7 ,D 8 ,D 9 ,D 1 0 } = { 5 ,4 ], [2 ,4 ,6 ], [1 ,6 ], [2 ,1 ], [2 ,4 ,8 ], [5 ,6 ,3 ], [2 ,3 ,6 ], [2 ,3 ,8 ], [5 ,2 ,3 ]} ,", "startOffset": 88, "endOffset": 95}, {"referenceID": 1, "context": "D \u00d7 = {D 3 ,D 4 ,D 2 ,D 5 ,D 6 ,D 7 ,D 8 ,D 9 ,D 1 0 } = { 5 ,4 ], [2 ,4 ,6 ], [1 ,6 ], [2 ,1 ], [2 ,4 ,8 ], [5 ,6 ,3 ], [2 ,3 ,6 ], [2 ,3 ,8 ], [5 ,2 ,3 ]} ,", "startOffset": 97, "endOffset": 107}, {"referenceID": 3, "context": "D \u00d7 = {D 3 ,D 4 ,D 2 ,D 5 ,D 6 ,D 7 ,D 8 ,D 9 ,D 1 0 } = { 5 ,4 ], [2 ,4 ,6 ], [1 ,6 ], [2 ,1 ], [2 ,4 ,8 ], [5 ,6 ,3 ], [2 ,3 ,6 ], [2 ,3 ,8 ], [5 ,2 ,3 ]} ,", "startOffset": 97, "endOffset": 107}, {"referenceID": 6, "context": "D \u00d7 = {D 3 ,D 4 ,D 2 ,D 5 ,D 6 ,D 7 ,D 8 ,D 9 ,D 1 0 } = { 5 ,4 ], [2 ,4 ,6 ], [1 ,6 ], [2 ,1 ], [2 ,4 ,8 ], [5 ,6 ,3 ], [2 ,3 ,6 ], [2 ,3 ,8 ], [5 ,2 ,3 ]} ,", "startOffset": 97, "endOffset": 107}, {"referenceID": 4, "context": "D \u00d7 = {D 3 ,D 4 ,D 2 ,D 5 ,D 6 ,D 7 ,D 8 ,D 9 ,D 1 0 } = { 5 ,4 ], [2 ,4 ,6 ], [1 ,6 ], [2 ,1 ], [2 ,4 ,8 ], [5 ,6 ,3 ], [2 ,3 ,6 ], [2 ,3 ,8 ], [5 ,2 ,3 ]} ,", "startOffset": 109, "endOffset": 119}, {"referenceID": 2, "context": "D \u00d7 = {D 3 ,D 4 ,D 2 ,D 5 ,D 6 ,D 7 ,D 8 ,D 9 ,D 1 0 } = { 5 ,4 ], [2 ,4 ,6 ], [1 ,6 ], [2 ,1 ], [2 ,4 ,8 ], [5 ,6 ,3 ], [2 ,3 ,6 ], [2 ,3 ,8 ], [5 ,2 ,3 ]} ,", "startOffset": 109, "endOffset": 119}, {"referenceID": 1, "context": "D \u00d7 = {D 3 ,D 4 ,D 2 ,D 5 ,D 6 ,D 7 ,D 8 ,D 9 ,D 1 0 } = { 5 ,4 ], [2 ,4 ,6 ], [1 ,6 ], [2 ,1 ], [2 ,4 ,8 ], [5 ,6 ,3 ], [2 ,3 ,6 ], [2 ,3 ,8 ], [5 ,2 ,3 ]} ,", "startOffset": 121, "endOffset": 131}, {"referenceID": 2, "context": "D \u00d7 = {D 3 ,D 4 ,D 2 ,D 5 ,D 6 ,D 7 ,D 8 ,D 9 ,D 1 0 } = { 5 ,4 ], [2 ,4 ,6 ], [1 ,6 ], [2 ,1 ], [2 ,4 ,8 ], [5 ,6 ,3 ], [2 ,3 ,6 ], [2 ,3 ,8 ], [5 ,2 ,3 ]} ,", "startOffset": 121, "endOffset": 131}, {"referenceID": 4, "context": "D \u00d7 = {D 3 ,D 4 ,D 2 ,D 5 ,D 6 ,D 7 ,D 8 ,D 9 ,D 1 0 } = { 5 ,4 ], [2 ,4 ,6 ], [1 ,6 ], [2 ,1 ], [2 ,4 ,8 ], [5 ,6 ,3 ], [2 ,3 ,6 ], [2 ,3 ,8 ], [5 ,2 ,3 ]} ,", "startOffset": 121, "endOffset": 131}, {"referenceID": 1, "context": "D \u00d7 = {D 3 ,D 4 ,D 2 ,D 5 ,D 6 ,D 7 ,D 8 ,D 9 ,D 1 0 } = { 5 ,4 ], [2 ,4 ,6 ], [1 ,6 ], [2 ,1 ], [2 ,4 ,8 ], [5 ,6 ,3 ], [2 ,3 ,6 ], [2 ,3 ,8 ], [5 ,2 ,3 ]} ,", "startOffset": 133, "endOffset": 143}, {"referenceID": 2, "context": "D \u00d7 = {D 3 ,D 4 ,D 2 ,D 5 ,D 6 ,D 7 ,D 8 ,D 9 ,D 1 0 } = { 5 ,4 ], [2 ,4 ,6 ], [1 ,6 ], [2 ,1 ], [2 ,4 ,8 ], [5 ,6 ,3 ], [2 ,3 ,6 ], [2 ,3 ,8 ], [5 ,2 ,3 ]} ,", "startOffset": 133, "endOffset": 143}, {"referenceID": 6, "context": "D \u00d7 = {D 3 ,D 4 ,D 2 ,D 5 ,D 6 ,D 7 ,D 8 ,D 9 ,D 1 0 } = { 5 ,4 ], [2 ,4 ,6 ], [1 ,6 ], [2 ,1 ], [2 ,4 ,8 ], [5 ,6 ,3 ], [2 ,3 ,6 ], [2 ,3 ,8 ], [5 ,2 ,3 ]} ,", "startOffset": 133, "endOffset": 143}, {"referenceID": 1, "context": "D \u00d7 = {D 3 ,D 4 ,D 2 ,D 5 ,D 6 ,D 7 ,D 8 ,D 9 ,D 1 0 } = { 5 ,4 ], [2 ,4 ,6 ], [1 ,6 ], [2 ,1 ], [2 ,4 ,8 ], [5 ,6 ,3 ], [2 ,3 ,6 ], [2 ,3 ,8 ], [5 ,2 ,3 ]} ,", "startOffset": 145, "endOffset": 155}, {"referenceID": 2, "context": "D \u00d7 = {D 3 ,D 4 ,D 2 ,D 5 ,D 6 ,D 7 ,D 8 ,D 9 ,D 1 0 } = { 5 ,4 ], [2 ,4 ,6 ], [1 ,6 ], [2 ,1 ], [2 ,4 ,8 ], [5 ,6 ,3 ], [2 ,3 ,6 ], [2 ,3 ,8 ], [5 ,2 ,3 ]} ,", "startOffset": 145, "endOffset": 155}, {"referenceID": 0, "context": "\u3008K,B,P ,N \u3009R and three successor nodes, namely nd1 := [1], nd2 := [2] as well as nd3 := [5] with nd1.", "startOffset": 54, "endOffset": 57}, {"referenceID": 1, "context": "\u3008K,B,P ,N \u3009R and three successor nodes, namely nd1 := [1], nd2 := [2] as well as nd3 := [5] with nd1.", "startOffset": 66, "endOffset": 69}, {"referenceID": 0, "context": "In this vein, first [1] and then [2] are identified as minimal diagnoses w.", "startOffset": 20, "endOffset": 23}, {"referenceID": 1, "context": "In this vein, first [1] and then [2] are identified as minimal diagnoses w.", "startOffset": 33, "endOffset": 36}, {"referenceID": 0, "context": "Since Dcalc = {[1], [2]} has a cardinality of nmin = nmax = 2, the stop criterion of DYNAMICHS causes it to terminate and return \u3008Dcalc,Q,Ccalc,Q,D\u00d7,D\u2283,Qdup\u3009 = \u3008 {[1], [2]}, [[5]], {\u30081, 2, 5\u3009}, \u2205, \u2205, []\u3009, as shown in the upper right column in Figure 6.", "startOffset": 15, "endOffset": 18}, {"referenceID": 1, "context": "Since Dcalc = {[1], [2]} has a cardinality of nmin = nmax = 2, the stop criterion of DYNAMICHS causes it to terminate and return \u3008Dcalc,Q,Ccalc,Q,D\u00d7,D\u2283,Qdup\u3009 = \u3008 {[1], [2]}, [[5]], {\u30081, 2, 5\u3009}, \u2205, \u2205, []\u3009, as shown in the upper right column in Figure 6.", "startOffset": 20, "endOffset": 23}, {"referenceID": 0, "context": "Since Dcalc = {[1], [2]} has a cardinality of nmin = nmax = 2, the stop criterion of DYNAMICHS causes it to terminate and return \u3008Dcalc,Q,Ccalc,Q,D\u00d7,D\u2283,Qdup\u3009 = \u3008 {[1], [2]}, [[5]], {\u30081, 2, 5\u3009}, \u2205, \u2205, []\u3009, as shown in the upper right column in Figure 6.", "startOffset": 163, "endOffset": 166}, {"referenceID": 1, "context": "Since Dcalc = {[1], [2]} has a cardinality of nmin = nmax = 2, the stop criterion of DYNAMICHS causes it to terminate and return \u3008Dcalc,Q,Ccalc,Q,D\u00d7,D\u2283,Qdup\u3009 = \u3008 {[1], [2]}, [[5]], {\u30081, 2, 5\u3009}, \u2205, \u2205, []\u3009, as shown in the upper right column in Figure 6.", "startOffset": 168, "endOffset": 171}, {"referenceID": 0, "context": "Then, in Algorithm 5, outside of the DYNAMICHS procedure, the first query Q1 = {E \u2192 \u00acA} is computed from the leading diagnoses set {[1], [2]}.", "startOffset": 132, "endOffset": 135}, {"referenceID": 1, "context": "Then, in Algorithm 5, outside of the DYNAMICHS procedure, the first query Q1 = {E \u2192 \u00acA} is computed from the leading diagnoses set {[1], [2]}.", "startOffset": 137, "endOffset": 140}, {"referenceID": 0, "context": "The q-partition P(Q1) associated with Q1 is \u3008{[1]} , {[2]} , \u2205\u3009.", "startOffset": 46, "endOffset": 49}, {"referenceID": 1, "context": "The q-partition P(Q1) associated with Q1 is \u3008{[1]} , {[2]} , \u2205\u3009.", "startOffset": 54, "endOffset": 57}, {"referenceID": 0, "context": "Thence, the set Dout is calculated from P(Q1) as D(Q1) = {[1]} (due to negative answer, cf.", "startOffset": 58, "endOffset": 61}, {"referenceID": 1, "context": "6), deleted from DX := DX \u222aDcalc to yield DX = {[2]} and added to D\u00d7 to yield D\u00d7 = {[1]}.", "startOffset": 48, "endOffset": 51}, {"referenceID": 0, "context": "6), deleted from DX := DX \u222aDcalc to yield DX = {[2]} and added to D\u00d7 to yield D\u00d7 = {[1]}.", "startOffset": 84, "endOffset": 87}, {"referenceID": 1, "context": "Namely, first (step 5 \u00a9) the node [2] is directly labeled by valid (line 8) since it is a known minimal diagnosis w.", "startOffset": 34, "endOffset": 37}, {"referenceID": 0, "context": "the current DPI and three further nodes ([5, 1], [5, 2] and [5, 7], all with nd.", "startOffset": 41, "endOffset": 47}, {"referenceID": 1, "context": "the current DPI and three further nodes ([5, 1], [5, 2] and [5, 7], all with nd.", "startOffset": 49, "endOffset": 55}, {"referenceID": 5, "context": "the current DPI and three further nodes ([5, 1], [5, 2] and [5, 7], all with nd.", "startOffset": 60, "endOffset": 66}, {"referenceID": 0, "context": "Now, [5, 1] (first-in-first-out) is the foremost node in Q and is thus processed next and found to be a minimal diagnosis w.", "startOffset": 5, "endOffset": 11}, {"referenceID": 1, "context": "diagnoses Dcalc = {[2], [5, 1]}.", "startOffset": 19, "endOffset": 22}, {"referenceID": 0, "context": "diagnoses Dcalc = {[2], [5, 1]}.", "startOffset": 24, "endOffset": 30}, {"referenceID": 0, "context": "1 where the node {5, 1} never became part of Q in STATICHS due to the existence of a minimal diagnosis [1] w.", "startOffset": 103, "endOffset": 106}, {"referenceID": 0, "context": "the current DPI if all (known) diagnoses (here, only [1]) that are proper subsets of it have already been pruned.", "startOffset": 53, "endOffset": 56}, {"referenceID": 0, "context": "This leading diagnosis [5, 1] is also the reason why the second query Q2 = {E \u2192 G} is different from the second query (Y \u2192 \u00acA) calculated in Example 6.", "startOffset": 23, "endOffset": 29}, {"referenceID": 1, "context": "1) is answered negatively and Q3 is added to N \u2032 yielding the current DPI \u3008K,B,P ,N \u222a {Q1, Q2, Q3}\u3009R, the UPDATETREE function not only prunes [2] = D2 \u2208 D\u00d7 and adds [5, 7] = D4 \u2208 DX to Q as we delineated above for the first query Q1, but adds [5, 2] \u2208 D\u2283 to Q as well.", "startOffset": 142, "endOffset": 145}, {"referenceID": 5, "context": "1) is answered negatively and Q3 is added to N \u2032 yielding the current DPI \u3008K,B,P ,N \u222a {Q1, Q2, Q3}\u3009R, the UPDATETREE function not only prunes [2] = D2 \u2208 D\u00d7 and adds [5, 7] = D4 \u2208 DX to Q as we delineated above for the first query Q1, but adds [5, 2] \u2208 D\u2283 to Q as well.", "startOffset": 165, "endOffset": 171}, {"referenceID": 1, "context": "1) is answered negatively and Q3 is added to N \u2032 yielding the current DPI \u3008K,B,P ,N \u222a {Q1, Q2, Q3}\u3009R, the UPDATETREE function not only prunes [2] = D2 \u2208 D\u00d7 and adds [5, 7] = D4 \u2208 DX to Q as we delineated above for the first query Q1, but adds [5, 2] \u2208 D\u2283 to Q as well.", "startOffset": 243, "endOffset": 249}, {"referenceID": 1, "context": "The reason for that is the deletion of the minimal diagnosis [2] w.", "startOffset": 61, "endOffset": 64}, {"referenceID": 1, "context": "the last-but-one DPI \u3008K,B,P ,N \u222a {Q1, Q2}\u3009R wherefore the last evidence for the non-minimality of node [5, 2] has been deleted.", "startOffset": 103, "endOffset": 109}, {"referenceID": 1, "context": "Hence, the status of [5, 2] as a non-minimal diagnosis is no more justified wherefore it must be added to the queue to preserve the completeness of the algorithm w.", "startOffset": 21, "endOffset": 27}, {"referenceID": 1, "context": "And, indeed, [5, 2] is identified as minimal diagnosis (D5) in iteration 4.", "startOffset": 13, "endOffset": 19}, {"referenceID": 5, "context": "\u2022 In this example, the same minimal diagnosis [5, 7] is used to compute the finally returned solution KB as in Example 6.", "startOffset": 46, "endOffset": 52}, {"referenceID": 5, "context": "The only difference between both outputs is that the KB (K \\ [5, 7]) \u222a Q4 returned by DYNAMICHS in this example contains the new positive test case Q4 \u2208 P \u2032.", "startOffset": 61, "endOffset": 67}, {"referenceID": 0, "context": "Iteration 1 \u3009 Dcalc = {D1,D2} = {[1], [2]}", "startOffset": 33, "endOffset": 36}, {"referenceID": 1, "context": "Iteration 1 \u3009 Dcalc = {D1,D2} = {[1], [2]}", "startOffset": 38, "endOffset": 41}, {"referenceID": 1, "context": "\u2022 replace by \u30082, 5\u3009 all node labels in the tree that are proper supersets of \u30082, 5\u3009 \u21d2 D\u2283 = \u2205, Ccalc = {\u30082, 5\u3009}, Q = [[2], [5]], Qdup = [], \u3009 1 \u00a9 \u3008 A1, 2, 5 \u3009C", "startOffset": 117, "endOffset": 120}, {"referenceID": 1, "context": "Iteration 2 \u3009 Dcalc = {D2,D3} = {[2], [5, 1]}", "startOffset": 33, "endOffset": 36}, {"referenceID": 0, "context": "Iteration 2 \u3009 Dcalc = {D2,D3} = {[2], [5, 1]}", "startOffset": 38, "endOffset": 44}, {"referenceID": 1, "context": "Q = [[5, 2], [5, 7]]", "startOffset": 5, "endOffset": 11}, {"referenceID": 5, "context": "Q = [[5, 2], [5, 7]]", "startOffset": 13, "endOffset": 19}, {"referenceID": 1, "context": "QRC (D3): QX(\u3008{2, 7} ,B,P ,N \u222a {Q1, Q2}\u3009) = \u30082, 7\u3009 \u21d2 PRUNE: \u30081, 2, 7\u3009 \u2192 \u30082, 7\u3009 \u21d2 D\u2283 = \u2205, Ccalc = {\u30082, 5\u3009 , \u30082, 7\u3009} Q = [[2], [5, 2], [5, 7]], Qdup = [] \u3009 1 \u00a9\u30082, 5\u3009", "startOffset": 120, "endOffset": 123}, {"referenceID": 1, "context": "QRC (D3): QX(\u3008{2, 7} ,B,P ,N \u222a {Q1, Q2}\u3009) = \u30082, 7\u3009 \u21d2 PRUNE: \u30081, 2, 7\u3009 \u2192 \u30082, 7\u3009 \u21d2 D\u2283 = \u2205, Ccalc = {\u30082, 5\u3009 , \u30082, 7\u3009} Q = [[2], [5, 2], [5, 7]], Qdup = [] \u3009 1 \u00a9\u30082, 5\u3009", "startOffset": 125, "endOffset": 131}, {"referenceID": 5, "context": "QRC (D3): QX(\u3008{2, 7} ,B,P ,N \u222a {Q1, Q2}\u3009) = \u30082, 7\u3009 \u21d2 PRUNE: \u30081, 2, 7\u3009 \u2192 \u30082, 7\u3009 \u21d2 D\u2283 = \u2205, Ccalc = {\u30082, 5\u3009 , \u30082, 7\u3009} Q = [[2], [5, 2], [5, 7]], Qdup = [] \u3009 1 \u00a9\u30082, 5\u3009", "startOffset": 133, "endOffset": 139}, {"referenceID": 1, "context": "Iteration 3 \u3009 Dcalc = {D2,D4} = {[2], [5, 7]}", "startOffset": 33, "endOffset": 36}, {"referenceID": 5, "context": "Iteration 3 \u3009 Dcalc = {D2,D4} = {[2], [5, 7]}", "startOffset": 38, "endOffset": 44}, {"referenceID": 1, "context": "Ccalc = {\u30082, 5\u3009 , \u30082, 7\u3009} D\u2283 = {[5, 2]}", "startOffset": 32, "endOffset": 38}, {"referenceID": 1, "context": "QRC (D2): QX(\u3008{5} ,B,P ,N \u222a {Q1, Q2, Q3}\u3009) = \u30085\u3009 \u21d2 PRUNE: \u30082, 5\u3009 \u2192 \u30085\u3009 \u21d2 D\u2283 = \u2205, Ccalc = {\u30085\u3009 , \u30082, 7\u3009} Q = [[5, 2], [5, 7]], Qdup = [] \u3009 1 \u00a9 \u3008 A2, 5 \u3009C", "startOffset": 109, "endOffset": 115}, {"referenceID": 5, "context": "QRC (D2): QX(\u3008{5} ,B,P ,N \u222a {Q1, Q2, Q3}\u3009) = \u30085\u3009 \u21d2 PRUNE: \u30082, 5\u3009 \u2192 \u30085\u3009 \u21d2 D\u2283 = \u2205, Ccalc = {\u30085\u3009 , \u30082, 7\u3009} Q = [[5, 2], [5, 7]], Qdup = [] \u3009 1 \u00a9 \u3008 A2, 5 \u3009C", "startOffset": 117, "endOffset": 123}, {"referenceID": 5, "context": "Iteration 4 \u3009 Dcalc = {D4,D5} = {[5, 7], [5, 2]}", "startOffset": 33, "endOffset": 39}, {"referenceID": 1, "context": "Iteration 4 \u3009 Dcalc = {D4,D5} = {[5, 7], [5, 2]}", "startOffset": 41, "endOffset": 47}, {"referenceID": 5, "context": "QRC (D5): QX(\u3008{7} ,B,P \u222a {Q4} ,N \u222a {Q1, Q2, Q3}\u3009) = \u30087\u3009 \u21d2 PRUNE: \u30082, 7\u3009 \u2192 \u30087\u3009 \u21d2 D\u2283 = \u2205, Ccalc = {\u30085\u3009 , \u30087\u3009} Q = [[5, 7]], Qdup = [] \u3009 1 \u00a9\u30085\u3009", "startOffset": 113, "endOffset": 119}, {"referenceID": 5, "context": "Iteration 5 \u3009 Dcalc = {D4} = {[5, 7]}", "startOffset": 30, "endOffset": 36}, {"referenceID": 0, "context": "3, pK\u0303\u222aK : K\u0303\u222aK \u2192 [0, 1] is given such that pK(ax ) for ax \u2208 K resulting from the application of GETAXIOMSPROBS is as given by Table 6.", "startOffset": 18, "endOffset": 24}, {"referenceID": 0, "context": "As outlined by the numbers i \u00a9 indicating at which point in time a node is labeled, the root node (initially the empty set) is labeled first by C1 := \u30081, 2, 5\u3009 and three successor nodes, namely nd1 := [1], nd2 := [2] as well as nd3 := [5] with nd1.", "startOffset": 201, "endOffset": 204}, {"referenceID": 1, "context": "As outlined by the numbers i \u00a9 indicating at which point in time a node is labeled, the root node (initially the empty set) is labeled first by C1 := \u30081, 2, 5\u3009 and three successor nodes, namely nd1 := [1], nd2 := [2] as well as nd3 := [5] with nd1.", "startOffset": 213, "endOffset": 216}, {"referenceID": 0, "context": "That is, the node [1] with pnodes([1]) = 0.", "startOffset": 18, "endOffset": 21}, {"referenceID": 0, "context": "That is, the node [1] with pnodes([1]) = 0.", "startOffset": 34, "endOffset": 37}, {"referenceID": 1, "context": "41 (as opposed to the nodes [2] and [5] with 0.", "startOffset": 28, "endOffset": 31}, {"referenceID": 0, "context": "The DLABEL procedure, after checking whether [1] is a non-minimal diagnosis w.", "startOffset": 45, "endOffset": 48}, {"referenceID": 0, "context": "\u3008K,B,P ,N \u3009R (check is negative), computes another minimal conflict set C2 := \u30082, 4, 6\u3009 such that [1] \u2229 C2 = \u2205 (C2 is not hit by the node [1]) to constitute a label for node [1].", "startOffset": 98, "endOffset": 101}, {"referenceID": 0, "context": "\u3008K,B,P ,N \u3009R (check is negative), computes another minimal conflict set C2 := \u30082, 4, 6\u3009 such that [1] \u2229 C2 = \u2205 (C2 is not hit by the node [1]) to constitute a label for node [1].", "startOffset": 138, "endOffset": 141}, {"referenceID": 0, "context": "\u3008K,B,P ,N \u3009R (check is negative), computes another minimal conflict set C2 := \u30082, 4, 6\u3009 such that [1] \u2229 C2 = \u2205 (C2 is not hit by the node [1]) to constitute a label for node [1].", "startOffset": 174, "endOffset": 177}, {"referenceID": 0, "context": "The successor nodes [1, 2], [1, 4] and [1, 6] of [1] are generated and added to the list Q in a way that the sorting of Q in descending order of pnodes() is maintained.", "startOffset": 20, "endOffset": 26}, {"referenceID": 1, "context": "The successor nodes [1, 2], [1, 4] and [1, 6] of [1] are generated and added to the list Q in a way that the sorting of Q in descending order of pnodes() is maintained.", "startOffset": 20, "endOffset": 26}, {"referenceID": 0, "context": "The successor nodes [1, 2], [1, 4] and [1, 6] of [1] are generated and added to the list Q in a way that the sorting of Q in descending order of pnodes() is maintained.", "startOffset": 28, "endOffset": 34}, {"referenceID": 3, "context": "The successor nodes [1, 2], [1, 4] and [1, 6] of [1] are generated and added to the list Q in a way that the sorting of Q in descending order of pnodes() is maintained.", "startOffset": 28, "endOffset": 34}, {"referenceID": 0, "context": "The successor nodes [1, 2], [1, 4] and [1, 6] of [1] are generated and added to the list Q in a way that the sorting of Q in descending order of pnodes() is maintained.", "startOffset": 39, "endOffset": 45}, {"referenceID": 4, "context": "The successor nodes [1, 2], [1, 4] and [1, 6] of [1] are generated and added to the list Q in a way that the sorting of Q in descending order of pnodes() is maintained.", "startOffset": 39, "endOffset": 45}, {"referenceID": 0, "context": "The successor nodes [1, 2], [1, 4] and [1, 6] of [1] are generated and added to the list Q in a way that the sorting of Q in descending order of pnodes() is maintained.", "startOffset": 49, "endOffset": 52}, {"referenceID": 0, "context": "Since [1, 4] (0.", "startOffset": 6, "endOffset": 12}, {"referenceID": 3, "context": "Since [1, 4] (0.", "startOffset": 6, "endOffset": 12}, {"referenceID": 0, "context": "28) as well as [1, 6] (0.", "startOffset": 15, "endOffset": 21}, {"referenceID": 4, "context": "28) as well as [1, 6] (0.", "startOffset": 15, "endOffset": 21}, {"referenceID": 1, "context": "27) have a larger probability (as per pnodes()) than the nodes [2] (0.", "startOffset": 63, "endOffset": 66}, {"referenceID": 0, "context": "25), Q is given by [[1, 4], [1, 6], [2], [5], [1, 2]] when it comes to the processing of the next node.", "startOffset": 20, "endOffset": 26}, {"referenceID": 3, "context": "25), Q is given by [[1, 4], [1, 6], [2], [5], [1, 2]] when it comes to the processing of the next node.", "startOffset": 20, "endOffset": 26}, {"referenceID": 0, "context": "25), Q is given by [[1, 4], [1, 6], [2], [5], [1, 2]] when it comes to the processing of the next node.", "startOffset": 28, "endOffset": 34}, {"referenceID": 4, "context": "25), Q is given by [[1, 4], [1, 6], [2], [5], [1, 2]] when it comes to the processing of the next node.", "startOffset": 28, "endOffset": 34}, {"referenceID": 1, "context": "25), Q is given by [[1, 4], [1, 6], [2], [5], [1, 2]] when it comes to the processing of the next node.", "startOffset": 36, "endOffset": 39}, {"referenceID": 0, "context": "25), Q is given by [[1, 4], [1, 6], [2], [5], [1, 2]] when it comes to the processing of the next node.", "startOffset": 46, "endOffset": 52}, {"referenceID": 1, "context": "25), Q is given by [[1, 4], [1, 6], [2], [5], [1, 2]] when it comes to the processing of the next node.", "startOffset": 46, "endOffset": 52}, {"referenceID": 0, "context": "Since DYNAMICHS always treats the first node of Q next, it identifies the first minimal diagnoses D1 := [1, 4] andD2 := [1, 6] w.", "startOffset": 104, "endOffset": 110}, {"referenceID": 3, "context": "Since DYNAMICHS always treats the first node of Q next, it identifies the first minimal diagnoses D1 := [1, 4] andD2 := [1, 6] w.", "startOffset": 104, "endOffset": 110}, {"referenceID": 0, "context": "Since DYNAMICHS always treats the first node of Q next, it identifies the first minimal diagnoses D1 := [1, 4] andD2 := [1, 6] w.", "startOffset": 120, "endOffset": 126}, {"referenceID": 4, "context": "Since DYNAMICHS always treats the first node of Q next, it identifies the first minimal diagnoses D1 := [1, 4] andD2 := [1, 6] w.", "startOffset": 120, "endOffset": 126}, {"referenceID": 1, "context": "At step 5 \u00a9, when node [2] is processed, a minimal conflict set C3 := \u30081, 3, 4\u3009 is computed and set as a label for [2], giving rise to the generation of three further nodes [2, 1], [2, 3] and [2, 4], all with ndi.", "startOffset": 23, "endOffset": 26}, {"referenceID": 1, "context": "At step 5 \u00a9, when node [2] is processed, a minimal conflict set C3 := \u30081, 3, 4\u3009 is computed and set as a label for [2], giving rise to the generation of three further nodes [2, 1], [2, 3] and [2, 4], all with ndi.", "startOffset": 115, "endOffset": 118}, {"referenceID": 1, "context": "At step 5 \u00a9, when node [2] is processed, a minimal conflict set C3 := \u30081, 3, 4\u3009 is computed and set as a label for [2], giving rise to the generation of three further nodes [2, 1], [2, 3] and [2, 4], all with ndi.", "startOffset": 173, "endOffset": 179}, {"referenceID": 0, "context": "At step 5 \u00a9, when node [2] is processed, a minimal conflict set C3 := \u30081, 3, 4\u3009 is computed and set as a label for [2], giving rise to the generation of three further nodes [2, 1], [2, 3] and [2, 4], all with ndi.", "startOffset": 173, "endOffset": 179}, {"referenceID": 1, "context": "At step 5 \u00a9, when node [2] is processed, a minimal conflict set C3 := \u30081, 3, 4\u3009 is computed and set as a label for [2], giving rise to the generation of three further nodes [2, 1], [2, 3] and [2, 4], all with ndi.", "startOffset": 181, "endOffset": 187}, {"referenceID": 2, "context": "At step 5 \u00a9, when node [2] is processed, a minimal conflict set C3 := \u30081, 3, 4\u3009 is computed and set as a label for [2], giving rise to the generation of three further nodes [2, 1], [2, 3] and [2, 4], all with ndi.", "startOffset": 181, "endOffset": 187}, {"referenceID": 1, "context": "At step 5 \u00a9, when node [2] is processed, a minimal conflict set C3 := \u30081, 3, 4\u3009 is computed and set as a label for [2], giving rise to the generation of three further nodes [2, 1], [2, 3] and [2, 4], all with ndi.", "startOffset": 192, "endOffset": 198}, {"referenceID": 3, "context": "At step 5 \u00a9, when node [2] is processed, a minimal conflict set C3 := \u30081, 3, 4\u3009 is computed and set as a label for [2], giving rise to the generation of three further nodes [2, 1], [2, 3] and [2, 4], all with ndi.", "startOffset": 192, "endOffset": 198}, {"referenceID": 0, "context": "For, there is already a node [1, 2] corresponding to the set {1, 2} in Q.", "startOffset": 29, "endOffset": 35}, {"referenceID": 1, "context": "For, there is already a node [1, 2] corresponding to the set {1, 2} in Q.", "startOffset": 29, "endOffset": 35}, {"referenceID": 1, "context": "Due to the test performed in line 20, this duplicate node [2, 1] is assigned to the list Qdup which is expressed in the figure by dup.", "startOffset": 58, "endOffset": 64}, {"referenceID": 0, "context": "Due to the test performed in line 20, this duplicate node [2, 1] is assigned to the list Qdup which is expressed in the figure by dup.", "startOffset": 58, "endOffset": 64}, {"referenceID": 0, "context": "Hence, the nodes [1, 2] and [2, 1] are regarded as duplicates.", "startOffset": 17, "endOffset": 23}, {"referenceID": 1, "context": "Hence, the nodes [1, 2] and [2, 1] are regarded as duplicates.", "startOffset": 17, "endOffset": 23}, {"referenceID": 1, "context": "Hence, the nodes [1, 2] and [2, 1] are regarded as duplicates.", "startOffset": 28, "endOffset": 34}, {"referenceID": 0, "context": "Hence, the nodes [1, 2] and [2, 1] are regarded as duplicates.", "startOffset": 28, "endOffset": 34}, {"referenceID": 1, "context": "Nevertheless, ndi := [2, 1] (with ndi.", "startOffset": 21, "endOffset": 27}, {"referenceID": 0, "context": "Nevertheless, ndi := [2, 1] (with ndi.", "startOffset": 21, "endOffset": 27}, {"referenceID": 0, "context": "cs = [\u30081, 2, 5\u3009 , \u30081, 3, 4\u3009]) must not be completely deleted as it might be the case that (some successor node of) ndj := [1, 2] (with ndj .", "startOffset": 122, "endOffset": 128}, {"referenceID": 1, "context": "cs = [\u30081, 2, 5\u3009 , \u30081, 3, 4\u3009]) must not be completely deleted as it might be the case that (some successor node of) ndj := [1, 2] (with ndj .", "startOffset": 122, "endOffset": 128}, {"referenceID": 1, "context": "Thence, only [2, 3] and [2, 4] are added to Q as successor nodes of the processed node [2].", "startOffset": 13, "endOffset": 19}, {"referenceID": 2, "context": "Thence, only [2, 3] and [2, 4] are added to Q as successor nodes of the processed node [2].", "startOffset": 13, "endOffset": 19}, {"referenceID": 1, "context": "Thence, only [2, 3] and [2, 4] are added to Q as successor nodes of the processed node [2].", "startOffset": 24, "endOffset": 30}, {"referenceID": 3, "context": "Thence, only [2, 3] and [2, 4] are added to Q as successor nodes of the processed node [2].", "startOffset": 24, "endOffset": 30}, {"referenceID": 1, "context": "Thence, only [2, 3] and [2, 4] are added to Q as successor nodes of the processed node [2].", "startOffset": 87, "endOffset": 90}, {"referenceID": 1, "context": "25 and the three new nodes [5, 2], [5, 4] as well as [5, 6] are generated and assigned to Q at step 7 \u00a9.", "startOffset": 27, "endOffset": 33}, {"referenceID": 3, "context": "25 and the three new nodes [5, 2], [5, 4] as well as [5, 6] are generated and assigned to Q at step 7 \u00a9.", "startOffset": 35, "endOffset": 41}, {"referenceID": 4, "context": "25 and the three new nodes [5, 2], [5, 4] as well as [5, 6] are generated and assigned to Q at step 7 \u00a9.", "startOffset": 53, "endOffset": 59}, {"referenceID": 1, "context": "Then, the fourth minimal conflict set C4 := \u30081, 5, 6, 8\u3009 is computed to label the node [2, 4] with pnodes([2, 4]) = 0.", "startOffset": 87, "endOffset": 93}, {"referenceID": 3, "context": "Then, the fourth minimal conflict set C4 := \u30081, 5, 6, 8\u3009 is computed to label the node [2, 4] with pnodes([2, 4]) = 0.", "startOffset": 87, "endOffset": 93}, {"referenceID": 1, "context": "Then, the fourth minimal conflict set C4 := \u30081, 5, 6, 8\u3009 is computed to label the node [2, 4] with pnodes([2, 4]) = 0.", "startOffset": 106, "endOffset": 112}, {"referenceID": 3, "context": "Then, the fourth minimal conflict set C4 := \u30081, 5, 6, 8\u3009 is computed to label the node [2, 4] with pnodes([2, 4]) = 0.", "startOffset": 106, "endOffset": 112}, {"referenceID": 1, "context": "18 and the four new nodes [2, 4, 1], [2, 4, 5], [2, 4, 6] as well as [2, 4, 8] are generated", "startOffset": 26, "endOffset": 35}, {"referenceID": 3, "context": "18 and the four new nodes [2, 4, 1], [2, 4, 5], [2, 4, 6] as well as [2, 4, 8] are generated", "startOffset": 26, "endOffset": 35}, {"referenceID": 0, "context": "18 and the four new nodes [2, 4, 1], [2, 4, 5], [2, 4, 6] as well as [2, 4, 8] are generated", "startOffset": 26, "endOffset": 35}, {"referenceID": 1, "context": "18 and the four new nodes [2, 4, 1], [2, 4, 5], [2, 4, 6] as well as [2, 4, 8] are generated", "startOffset": 37, "endOffset": 46}, {"referenceID": 3, "context": "18 and the four new nodes [2, 4, 1], [2, 4, 5], [2, 4, 6] as well as [2, 4, 8] are generated", "startOffset": 37, "endOffset": 46}, {"referenceID": 1, "context": "18 and the four new nodes [2, 4, 1], [2, 4, 5], [2, 4, 6] as well as [2, 4, 8] are generated", "startOffset": 48, "endOffset": 57}, {"referenceID": 3, "context": "18 and the four new nodes [2, 4, 1], [2, 4, 5], [2, 4, 6] as well as [2, 4, 8] are generated", "startOffset": 48, "endOffset": 57}, {"referenceID": 4, "context": "18 and the four new nodes [2, 4, 1], [2, 4, 5], [2, 4, 6] as well as [2, 4, 8] are generated", "startOffset": 48, "endOffset": 57}, {"referenceID": 1, "context": "18 and the four new nodes [2, 4, 1], [2, 4, 5], [2, 4, 6] as well as [2, 4, 8] are generated", "startOffset": 69, "endOffset": 78}, {"referenceID": 3, "context": "18 and the four new nodes [2, 4, 1], [2, 4, 5], [2, 4, 6] as well as [2, 4, 8] are generated", "startOffset": 69, "endOffset": 78}, {"referenceID": 6, "context": "18 and the four new nodes [2, 4, 1], [2, 4, 5], [2, 4, 6] as well as [2, 4, 8] are generated", "startOffset": 69, "endOffset": 78}, {"referenceID": 3, "context": "At step 9 \u00a9, the third minimal diagnosis D3 := [5, 4] w.", "startOffset": 47, "endOffset": 53}, {"referenceID": 0, "context": "the set of leading diagnoses Dcalc = {[1, 4], [1, 6], [5, 4]}.", "startOffset": 38, "endOffset": 44}, {"referenceID": 3, "context": "the set of leading diagnoses Dcalc = {[1, 4], [1, 6], [5, 4]}.", "startOffset": 38, "endOffset": 44}, {"referenceID": 0, "context": "the set of leading diagnoses Dcalc = {[1, 4], [1, 6], [5, 4]}.", "startOffset": 46, "endOffset": 52}, {"referenceID": 4, "context": "the set of leading diagnoses Dcalc = {[1, 4], [1, 6], [5, 4]}.", "startOffset": 46, "endOffset": 52}, {"referenceID": 3, "context": "the set of leading diagnoses Dcalc = {[1, 4], [1, 6], [5, 4]}.", "startOffset": 54, "endOffset": 60}, {"referenceID": 3, "context": "In this case D\u00d7 = {D3} = {[5, 4]} since D3 is the only minimal diagnosis that has been ruled out by the most recently added positive test case Q1.", "startOffset": 26, "endOffset": 32}, {"referenceID": 3, "context": "{1, 2, 6} = (\u30081, 2, 5\u3009 \u222a \u30082, 4, 6\u3009) \\ [5, 4].", "startOffset": 38, "endOffset": 44}, {"referenceID": 0, "context": "Notice that only one call of the DLABEL procedure is required in the second iteration (for node [1, 2]) due to the test in line 8 of DYNAMICHS which is positive forD1 andD2 (sinceD1,D2 \u2208 DX).", "startOffset": 96, "endOffset": 102}, {"referenceID": 1, "context": "Notice that only one call of the DLABEL procedure is required in the second iteration (for node [1, 2]) due to the test in line 8 of DYNAMICHS which is positive forD1 andD2 (sinceD1,D2 \u2208 DX).", "startOffset": 96, "endOffset": 102}, {"referenceID": 0, "context": "F} is added to the positive test cases resulting in the DPI \u3008K,B,P \u222a {Q1, Q2} ,N \u3009R, the UPDATETREE function causes the pruning of two further nodes (D2 = [1, 6] and D4 = [1, 2]) leading to the continuance of only a single node (D1 = [1, 4]) in the memory of DYNAMICHS (see the picture with caption \u2019Updated Tree\u2019 in Figure 6.", "startOffset": 155, "endOffset": 161}, {"referenceID": 4, "context": "F} is added to the positive test cases resulting in the DPI \u3008K,B,P \u222a {Q1, Q2} ,N \u3009R, the UPDATETREE function causes the pruning of two further nodes (D2 = [1, 6] and D4 = [1, 2]) leading to the continuance of only a single node (D1 = [1, 4]) in the memory of DYNAMICHS (see the picture with caption \u2019Updated Tree\u2019 in Figure 6.", "startOffset": 155, "endOffset": 161}, {"referenceID": 0, "context": "F} is added to the positive test cases resulting in the DPI \u3008K,B,P \u222a {Q1, Q2} ,N \u3009R, the UPDATETREE function causes the pruning of two further nodes (D2 = [1, 6] and D4 = [1, 2]) leading to the continuance of only a single node (D1 = [1, 4]) in the memory of DYNAMICHS (see the picture with caption \u2019Updated Tree\u2019 in Figure 6.", "startOffset": 171, "endOffset": 177}, {"referenceID": 1, "context": "F} is added to the positive test cases resulting in the DPI \u3008K,B,P \u222a {Q1, Q2} ,N \u3009R, the UPDATETREE function causes the pruning of two further nodes (D2 = [1, 6] and D4 = [1, 2]) leading to the continuance of only a single node (D1 = [1, 4]) in the memory of DYNAMICHS (see the picture with caption \u2019Updated Tree\u2019 in Figure 6.", "startOffset": 171, "endOffset": 177}, {"referenceID": 0, "context": "F} is added to the positive test cases resulting in the DPI \u3008K,B,P \u222a {Q1, Q2} ,N \u3009R, the UPDATETREE function causes the pruning of two further nodes (D2 = [1, 6] and D4 = [1, 2]) leading to the continuance of only a single node (D1 = [1, 4]) in the memory of DYNAMICHS (see the picture with caption \u2019Updated Tree\u2019 in Figure 6.", "startOffset": 234, "endOffset": 240}, {"referenceID": 3, "context": "F} is added to the positive test cases resulting in the DPI \u3008K,B,P \u222a {Q1, Q2} ,N \u3009R, the UPDATETREE function causes the pruning of two further nodes (D2 = [1, 6] and D4 = [1, 2]) leading to the continuance of only a single node (D1 = [1, 4]) in the memory of DYNAMICHS (see the picture with caption \u2019Updated Tree\u2019 in Figure 6.", "startOffset": 234, "endOffset": 240}, {"referenceID": 0, "context": "6 that there can be only a single minimal diagnosis [1, 4] w.", "startOffset": 52, "endOffset": 58}, {"referenceID": 3, "context": "6 that there can be only a single minimal diagnosis [1, 4] w.", "startOffset": 52, "endOffset": 58}, {"referenceID": 0, "context": "Therefore, the third iteration of DYNAMICHS terminates due to Q = [] and returns the singleton set Dcalc = {[1, 4]}.", "startOffset": 108, "endOffset": 114}, {"referenceID": 3, "context": "Therefore, the third iteration of DYNAMICHS terminates due to Q = [] and returns the singleton set Dcalc = {[1, 4]}.", "startOffset": 108, "endOffset": 114}, {"referenceID": 0, "context": "Consequently, the probability pD([1, 4]) = 1 wherefore Algorithm 5 also stops executing and returns (K \\ [1, 4]) \u222a p1 \u222a Q1 \u222a Q2 as the (exact) solution to the Interactive Dynamic KB Debugging problem for the DPI \u3008K,B,P ,N \u3009R.", "startOffset": 33, "endOffset": 39}, {"referenceID": 3, "context": "Consequently, the probability pD([1, 4]) = 1 wherefore Algorithm 5 also stops executing and returns (K \\ [1, 4]) \u222a p1 \u222a Q1 \u222a Q2 as the (exact) solution to the Interactive Dynamic KB Debugging problem for the DPI \u3008K,B,P ,N \u3009R.", "startOffset": 33, "endOffset": 39}, {"referenceID": 0, "context": "Consequently, the probability pD([1, 4]) = 1 wherefore Algorithm 5 also stops executing and returns (K \\ [1, 4]) \u222a p1 \u222a Q1 \u222a Q2 as the (exact) solution to the Interactive Dynamic KB Debugging problem for the DPI \u3008K,B,P ,N \u3009R.", "startOffset": 105, "endOffset": 111}, {"referenceID": 3, "context": "Consequently, the probability pD([1, 4]) = 1 wherefore Algorithm 5 also stops executing and returns (K \\ [1, 4]) \u222a p1 \u222a Q1 \u222a Q2 as the (exact) solution to the Interactive Dynamic KB Debugging problem for the DPI \u3008K,B,P ,N \u3009R.", "startOffset": 105, "endOffset": 111}, {"referenceID": 0, "context": "Dcalc = {D1,D2,D3} = {[1, 4], [1, 6], [5, 4]}", "startOffset": 22, "endOffset": 28}, {"referenceID": 3, "context": "Dcalc = {D1,D2,D3} = {[1, 4], [1, 6], [5, 4]}", "startOffset": 22, "endOffset": 28}, {"referenceID": 0, "context": "Dcalc = {D1,D2,D3} = {[1, 4], [1, 6], [5, 4]}", "startOffset": 30, "endOffset": 36}, {"referenceID": 4, "context": "Dcalc = {D1,D2,D3} = {[1, 4], [1, 6], [5, 4]}", "startOffset": 30, "endOffset": 36}, {"referenceID": 3, "context": "Dcalc = {D1,D2,D3} = {[1, 4], [1, 6], [5, 4]}", "startOffset": 38, "endOffset": 44}, {"referenceID": 4, "context": "Q = [[5, 6], [2, 4, 6], [1, 2], [2, 3], [5, 2],", "startOffset": 5, "endOffset": 11}, {"referenceID": 1, "context": "Q = [[5, 6], [2, 4, 6], [1, 2], [2, 3], [5, 2],", "startOffset": 13, "endOffset": 22}, {"referenceID": 3, "context": "Q = [[5, 6], [2, 4, 6], [1, 2], [2, 3], [5, 2],", "startOffset": 13, "endOffset": 22}, {"referenceID": 4, "context": "Q = [[5, 6], [2, 4, 6], [1, 2], [2, 3], [5, 2],", "startOffset": 13, "endOffset": 22}, {"referenceID": 0, "context": "Q = [[5, 6], [2, 4, 6], [1, 2], [2, 3], [5, 2],", "startOffset": 24, "endOffset": 30}, {"referenceID": 1, "context": "Q = [[5, 6], [2, 4, 6], [1, 2], [2, 3], [5, 2],", "startOffset": 24, "endOffset": 30}, {"referenceID": 1, "context": "Q = [[5, 6], [2, 4, 6], [1, 2], [2, 3], [5, 2],", "startOffset": 32, "endOffset": 38}, {"referenceID": 2, "context": "Q = [[5, 6], [2, 4, 6], [1, 2], [2, 3], [5, 2],", "startOffset": 32, "endOffset": 38}, {"referenceID": 1, "context": "Q = [[5, 6], [2, 4, 6], [1, 2], [2, 3], [5, 2],", "startOffset": 40, "endOffset": 46}, {"referenceID": 1, "context": "[2, 4, 1], [2, 4, 5], [2, 4, 8]]", "startOffset": 0, "endOffset": 9}, {"referenceID": 3, "context": "[2, 4, 1], [2, 4, 5], [2, 4, 8]]", "startOffset": 0, "endOffset": 9}, {"referenceID": 0, "context": "[2, 4, 1], [2, 4, 5], [2, 4, 8]]", "startOffset": 0, "endOffset": 9}, {"referenceID": 1, "context": "[2, 4, 1], [2, 4, 5], [2, 4, 8]]", "startOffset": 11, "endOffset": 20}, {"referenceID": 3, "context": "[2, 4, 1], [2, 4, 5], [2, 4, 8]]", "startOffset": 11, "endOffset": 20}, {"referenceID": 1, "context": "[2, 4, 1], [2, 4, 5], [2, 4, 8]]", "startOffset": 22, "endOffset": 31}, {"referenceID": 3, "context": "[2, 4, 1], [2, 4, 5], [2, 4, 8]]", "startOffset": 22, "endOffset": 31}, {"referenceID": 6, "context": "[2, 4, 1], [2, 4, 5], [2, 4, 8]]", "startOffset": 22, "endOffset": 31}, {"referenceID": 1, "context": "Qdup = [[2, 1]] \u3008Q1,P(Q1)\u3009 = \u3008{B v K} , \u3008{D1,D2} , {D3} , \u2205\u3009\u3009", "startOffset": 8, "endOffset": 14}, {"referenceID": 0, "context": "Qdup = [[2, 1]] \u3008Q1,P(Q1)\u3009 = \u3008{B v K} , \u3008{D1,D2} , {D3} , \u2205\u3009\u3009", "startOffset": 8, "endOffset": 14}, {"referenceID": 0, "context": "\u2022 replace by \u30081\u3009 all node labels in the tree that are proper supersets of \u30081\u3009 \u21d2 D\u2283 = \u2205, Ccalc = {\u30081\u3009 , \u30082, 4, 6\u3009}, Q = [[1, 4], [1, 6], [1, 2]], Qdup = [] \u3009", "startOffset": 120, "endOffset": 126}, {"referenceID": 3, "context": "\u2022 replace by \u30081\u3009 all node labels in the tree that are proper supersets of \u30081\u3009 \u21d2 D\u2283 = \u2205, Ccalc = {\u30081\u3009 , \u30082, 4, 6\u3009}, Q = [[1, 4], [1, 6], [1, 2]], Qdup = [] \u3009", "startOffset": 120, "endOffset": 126}, {"referenceID": 0, "context": "\u2022 replace by \u30081\u3009 all node labels in the tree that are proper supersets of \u30081\u3009 \u21d2 D\u2283 = \u2205, Ccalc = {\u30081\u3009 , \u30082, 4, 6\u3009}, Q = [[1, 4], [1, 6], [1, 2]], Qdup = [] \u3009", "startOffset": 128, "endOffset": 134}, {"referenceID": 4, "context": "\u2022 replace by \u30081\u3009 all node labels in the tree that are proper supersets of \u30081\u3009 \u21d2 D\u2283 = \u2205, Ccalc = {\u30081\u3009 , \u30082, 4, 6\u3009}, Q = [[1, 4], [1, 6], [1, 2]], Qdup = [] \u3009", "startOffset": 128, "endOffset": 134}, {"referenceID": 0, "context": "\u2022 replace by \u30081\u3009 all node labels in the tree that are proper supersets of \u30081\u3009 \u21d2 D\u2283 = \u2205, Ccalc = {\u30081\u3009 , \u30082, 4, 6\u3009}, Q = [[1, 4], [1, 6], [1, 2]], Qdup = [] \u3009", "startOffset": 136, "endOffset": 142}, {"referenceID": 1, "context": "\u2022 replace by \u30081\u3009 all node labels in the tree that are proper supersets of \u30081\u3009 \u21d2 D\u2283 = \u2205, Ccalc = {\u30081\u3009 , \u30082, 4, 6\u3009}, Q = [[1, 4], [1, 6], [1, 2]], Qdup = [] \u3009", "startOffset": 136, "endOffset": 142}, {"referenceID": 0, "context": "Iteration 2 \u3009 Dcalc = {D1,D2,D4} = {[1, 4], [1, 6], [1, 2]}", "startOffset": 36, "endOffset": 42}, {"referenceID": 3, "context": "Iteration 2 \u3009 Dcalc = {D1,D2,D4} = {[1, 4], [1, 6], [1, 2]}", "startOffset": 36, "endOffset": 42}, {"referenceID": 0, "context": "Iteration 2 \u3009 Dcalc = {D1,D2,D4} = {[1, 4], [1, 6], [1, 2]}", "startOffset": 44, "endOffset": 50}, {"referenceID": 4, "context": "Iteration 2 \u3009 Dcalc = {D1,D2,D4} = {[1, 4], [1, 6], [1, 2]}", "startOffset": 44, "endOffset": 50}, {"referenceID": 0, "context": "Iteration 2 \u3009 Dcalc = {D1,D2,D4} = {[1, 4], [1, 6], [1, 2]}", "startOffset": 52, "endOffset": 58}, {"referenceID": 1, "context": "Iteration 2 \u3009 Dcalc = {D1,D2,D4} = {[1, 4], [1, 6], [1, 2]}", "startOffset": 52, "endOffset": 58}, {"referenceID": 0, "context": "QRC (D2): QX(\u3008{2, 4} ,B,P \u222a {Q1, Q2} ,N \u3009) = \u30084\u3009 \u21d2 PRUNE: \u30082, 4, 6\u3009 \u2192 \u30084\u3009 \u21d2 D\u2283 = \u2205, Ccalc = {\u30081\u3009 , \u30084\u3009} Q = [[1, 4]], Qdup = [] \u3009 1 \u00a9\u30081\u3009", "startOffset": 109, "endOffset": 115}, {"referenceID": 3, "context": "QRC (D2): QX(\u3008{2, 4} ,B,P \u222a {Q1, Q2} ,N \u3009) = \u30084\u3009 \u21d2 PRUNE: \u30082, 4, 6\u3009 \u2192 \u30084\u3009 \u21d2 D\u2283 = \u2205, Ccalc = {\u30081\u3009 , \u30084\u3009} Q = [[1, 4]], Qdup = [] \u3009 1 \u00a9\u30081\u3009", "startOffset": 109, "endOffset": 115}, {"referenceID": 0, "context": "Iteration 3 \u3009 Dcalc = {D1} = {[1, 4]}", "startOffset": 30, "endOffset": 36}, {"referenceID": 3, "context": "Iteration 3 \u3009 Dcalc = {D1} = {[1, 4]}", "startOffset": 30, "endOffset": 36}, {"referenceID": 0, "context": "nd is redundant 96: for node\u2190 Dup[1], .", "startOffset": 33, "endOffset": 36}, {"referenceID": 58, "context": "non-leaf) nodes and the adherence to the \u201cstandard\u201d pruning rules [60] as per Definition 4.", "startOffset": 66, "endOffset": 70}, {"referenceID": 70, "context": "To the best of our knowledge no interactive KB debugging methods that ask a user automatically selected queries have been proposed to repair faulty (monotonic) KBs so far (except for our own previous works [73, 74, 63, 76]).", "startOffset": 206, "endOffset": 222}, {"referenceID": 71, "context": "To the best of our knowledge no interactive KB debugging methods that ask a user automatically selected queries have been proposed to repair faulty (monotonic) KBs so far (except for our own previous works [73, 74, 63, 76]).", "startOffset": 206, "endOffset": 222}, {"referenceID": 61, "context": "To the best of our knowledge no interactive KB debugging methods that ask a user automatically selected queries have been proposed to repair faulty (monotonic) KBs so far (except for our own previous works [73, 74, 63, 76]).", "startOffset": 206, "endOffset": 222}, {"referenceID": 73, "context": "To the best of our knowledge no interactive KB debugging methods that ask a user automatically selected queries have been proposed to repair faulty (monotonic) KBs so far (except for our own previous works [73, 74, 63, 76]).", "startOffset": 206, "endOffset": 222}, {"referenceID": 66, "context": "Non-interactive debugging methods for KBs (ontologies) are introduced in [68, 38, 19].", "startOffset": 73, "endOffset": 85}, {"referenceID": 36, "context": "Non-interactive debugging methods for KBs (ontologies) are introduced in [68, 38, 19].", "startOffset": 73, "endOffset": 85}, {"referenceID": 17, "context": "Non-interactive debugging methods for KBs (ontologies) are introduced in [68, 38, 19].", "startOffset": 73, "endOffset": 85}, {"referenceID": 37, "context": "Ranking of diagnoses and proposing a \u201cbest\u201d diagnosis is presented in [39].", "startOffset": 70, "endOffset": 74}, {"referenceID": 37, "context": "In general, the work of [39] can be combined with the approaches presented in our work as ranks of logical formulas can be taken into account together with other observations for calculating the prior probabilities of minimal diagnoses (see Section 4.", "startOffset": 24, "endOffset": 28}, {"referenceID": 56, "context": "The idea of selecting the next query based on certain query selection measures was exploited in the generation of decisions trees [58] and for selecting measurements in the model-based diagnosis of circuits [44] (in both works, the minimal expected entropy measure was used).", "startOffset": 130, "endOffset": 134}, {"referenceID": 42, "context": "The idea of selecting the next query based on certain query selection measures was exploited in the generation of decisions trees [58] and for selecting measurements in the model-based diagnosis of circuits [44] (in both works, the minimal expected entropy measure was used).", "startOffset": 207, "endOffset": 211}, {"referenceID": 70, "context": "We extended these methods to query selection in the domain of KB debugging [73] and devised further query selection measures [74, 63].", "startOffset": 75, "endOffset": 79}, {"referenceID": 71, "context": "We extended these methods to query selection in the domain of KB debugging [73] and devised further query selection measures [74, 63].", "startOffset": 125, "endOffset": 133}, {"referenceID": 61, "context": "We extended these methods to query selection in the domain of KB debugging [73] and devised further query selection measures [74, 63].", "startOffset": 125, "endOffset": 133}, {"referenceID": 44, "context": "An approach for the debugging of faulty aligned KBs (ontologies) was proposed by [46].", "startOffset": 81, "endOffset": 85}, {"referenceID": 44, "context": "Definition 18 in [46]).", "startOffset": 17, "endOffset": 21}, {"referenceID": 60, "context": "We have already shown in [62, 72] that our systems can also be applied for fault localization in aligned KBs.", "startOffset": 25, "endOffset": 33}, {"referenceID": 69, "context": "We have already shown in [62, 72] that our systems can also be applied for fault localization in aligned KBs.", "startOffset": 25, "endOffset": 33}, {"referenceID": 44, "context": "The work of [46] describes approximate algorithms for computing a \u201clocal optimal diagnosis\u201d and complete methods to discover a \u201cglobal optimal diagnosis\u201d.", "startOffset": 12, "endOffset": 16}, {"referenceID": 44, "context": "[46] demonstrates techniques for the manual revision of the alignment as a procedure independent from debugging.", "startOffset": 0, "endOffset": 4}, {"referenceID": 34, "context": "We rely on a divide-and-conquer algorithm [36] for the identification of a minimal conflict set C \u2286 A1,2 (in [46] C is called a MIPS, cf.", "startOffset": 42, "endOffset": 46}, {"referenceID": 44, "context": "We rely on a divide-and-conquer algorithm [36] for the identification of a minimal conflict set C \u2286 A1,2 (in [46] C is called a MIPS, cf.", "startOffset": 109, "endOffset": 113}, {"referenceID": 17, "context": "[19, 68]).", "startOffset": 0, "endOffset": 8}, {"referenceID": 66, "context": "[19, 68]).", "startOffset": 0, "endOffset": 8}, {"referenceID": 44, "context": "The \u201cshrink\u201d strategy applied in [46] (which is similar to the \u201cexpandand-shrink\u201d method used in [38]), on the other hand, requires a worst case number of O(|A1,2|) calls to such a function.", "startOffset": 33, "endOffset": 37}, {"referenceID": 36, "context": "The \u201cshrink\u201d strategy applied in [46] (which is similar to the \u201cexpandand-shrink\u201d method used in [38]), on the other hand, requires a worst case number of O(|A1,2|) calls to such a function.", "startOffset": 97, "endOffset": 101}, {"referenceID": 72, "context": "Empirical evaluations and a theoretical analysis of the best and worst case complexity of the \u201cexpand-and-shrink\u201d method compared to the divide-and-conquer method performed in [75] revealed that the latter is preferable over the former.", "startOffset": 176, "endOffset": 180}, {"referenceID": 44, "context": "It should be noted that a similar divide-and-conquer method as used in our work could most probably be also plugged into the system in [46] instead of the \u201cshrink\u201d method.", "startOffset": 135, "endOffset": 139}, {"referenceID": 28, "context": "There are some ontology matchers which incorporate alignment repair features: CODI [30], YAM++ [51], ASMOV [32] and KOSIMap [61], for instance, employ logic-based techniques to search for a set of predefined \u201canti-patterns\u201d which must not occur in the aligned ontology, either to avoid inconsistencies or incoherencies or to eliminate unwanted or redundant entailments.", "startOffset": 83, "endOffset": 87}, {"referenceID": 49, "context": "There are some ontology matchers which incorporate alignment repair features: CODI [30], YAM++ [51], ASMOV [32] and KOSIMap [61], for instance, employ logic-based techniques to search for a set of predefined \u201canti-patterns\u201d which must not occur in the aligned ontology, either to avoid inconsistencies or incoherencies or to eliminate unwanted or redundant entailments.", "startOffset": 95, "endOffset": 99}, {"referenceID": 30, "context": "There are some ontology matchers which incorporate alignment repair features: CODI [30], YAM++ [51], ASMOV [32] and KOSIMap [61], for instance, employ logic-based techniques to search for a set of predefined \u201canti-patterns\u201d which must not occur in the aligned ontology, either to avoid inconsistencies or incoherencies or to eliminate unwanted or redundant entailments.", "startOffset": 107, "endOffset": 111}, {"referenceID": 59, "context": "There are some ontology matchers which incorporate alignment repair features: CODI [30], YAM++ [51], ASMOV [32] and KOSIMap [61], for instance, employ logic-based techniques to search for a set of predefined \u201canti-patterns\u201d which must not occur in the aligned ontology, either to avoid inconsistencies or incoherencies or to eliminate unwanted or redundant entailments.", "startOffset": 124, "endOffset": 128}, {"referenceID": 32, "context": "Another ontology matcher, LogMap 2 [34], provides integrated debugging features and the opportunity for a user to interact during this process.", "startOffset": 35, "endOffset": 39}, {"referenceID": 50, "context": "An interactive technique similar to our approaches was presented in [52], where a user is successively asked single KB formulas (ontology axioms) in order to obtain a partition of a given ontology into a set of desired or correct and a set of undesired or incorrect formulas.", "startOffset": 68, "endOffset": 72}, {"referenceID": 50, "context": "Whereas our strategies aim at finding a parsimonious solution involving minimal change to the given faulty KB in order to repair it, the method proposed in [52] pursues a (potentially) more invasive approach to KB quality assurance, namely a (reasoner-supported) exhaustive manual inspection of (parts of) a KB.", "startOffset": 156, "endOffset": 160}, {"referenceID": 50, "context": "Another difference of our approach compared to the one suggested in [52] is the type of queries asked to the user and the way these are selected.", "startOffset": 68, "endOffset": 72}, {"referenceID": 50, "context": "KB formulas) in [52] are known in advance and the challenge is to figure out the best ordering of formulas to be assessed by the user.", "startOffset": 16, "endOffset": 20}, {"referenceID": 50, "context": "the minimal expected entropy in the set of leading diagnoses after a query has been answered), the authors in [52] employ \u201cimpact measures\u201d which, roughly speaking,", "startOffset": 110, "endOffset": 114}, {"referenceID": 78, "context": "Non-interactive debugging systems published in research literature often cannot localize all possible faults (incompleteness), suggest the deletion or modification of unnecessarily large parts of the KB (nonminimality), return incorrect solutions which lead to a repaired KB not satisfying the imposed quality requirements (unsoundness) or suffer from poor scalability due to the inherent complexity of the KB debugging problem [81].", "startOffset": 428, "endOffset": 432}, {"referenceID": 71, "context": "in interactive debugging scenarios [74, 63, 73].", "startOffset": 35, "endOffset": 47}, {"referenceID": 61, "context": "in interactive debugging scenarios [74, 63, 73].", "startOffset": 35, "endOffset": 47}, {"referenceID": 70, "context": "in interactive debugging scenarios [74, 63, 73].", "startOffset": 35, "endOffset": 47}, {"referenceID": 71, "context": "A similar strategy called CKK has been employed in [74] for the information gain measure qsm() := ENT() (see Section 5.", "startOffset": 51, "endOffset": 55}, {"referenceID": 22, "context": "It is planned to gather corresponding data about different users in the scope of a user study and to utilize the results to achieve a model of \u201cquery hardness\u201d (by sticking to a similar overall methodology as used in [24]) in order to come up with strategies for the determination of minimal queries that are easily understood.", "startOffset": 217, "endOffset": 221}, {"referenceID": 29, "context": ", how many of the formulas originally authored by a person have been corrected by other persons of higher educational level) or provenance information regarding terms occurring in the query (who has authored most of the formulas in which these terms occur?) in order to learn an \u201cexpert model\u201d and use it to devise some kind of recommender system [31] that suggests which person to ask a particular query.", "startOffset": 347, "endOffset": 351}, {"referenceID": 82, "context": "An example of a system which enables the remote collaborative development of KBs (ontologies) and also provides logs of interesting usage data such as formula change logs and provenance information is Web Prot\u00e9g\u00e9 [85].", "startOffset": 213, "endOffset": 217}], "year": 2016, "abstractText": "iv", "creator": "LaTeX with hyperref package"}}}