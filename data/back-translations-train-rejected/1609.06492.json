{"id": "1609.06492", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Sep-2016", "title": "Document Image Coding and Clustering for Script Discrimination", "abstract": "The paper introduces a new method for discrimination of documents given in different scripts. The document is mapped into a uniformly coded text of numerical values. It is derived from the position of the letters in the text line, based on their typographical characteristics. Each code is considered as a gray level. Accordingly, the coded text determines a 1-D image, on which texture analysis by run-length statistics and local binary pattern is performed. It defines feature vectors representing the script content of the document. A modified clustering approach employed on document feature vector groups documents written in the same script. Experimentation performed on two custom oriented databases of historical documents in old Cyrillic, angular and round Glagolitic as well as Antiqua and Fraktur scripts demonstrates the superiority of the proposed method with respect to well-known methods in the state-of-the-art.", "histories": [["v1", "Wed, 21 Sep 2016 10:52:03 GMT  (1315kb,D)", "http://arxiv.org/abs/1609.06492v1", "8 pages, 4 figures, 2 tables"]], "COMMENTS": "8 pages, 4 figures, 2 tables", "reviews": [], "SUBJECTS": "cs.CV cs.AI cs.CL cs.LG cs.NE", "authors": ["darko brodic", "alessia amelio", "zoran n milivojevic", "milena jevtic"], "accepted": false, "id": "1609.06492"}, "pdf": {"name": "1609.06492.pdf", "metadata": {"source": "CRF", "title": "Document Image Coding and Clustering for Script Discrimination", "authors": ["Darko Brodi\u0107", "Alessia Amelio", "Zoran N. Milivojevi\u0107", "Milena Jevti\u0107"], "emails": ["mjevtic}@tf.bor.ac.rs", "aamelio@dimes.unical.it", "zoran.milivojevic@vtsnis.edu.rs"], "sections": [{"heading": null, "text": "Keywords: historical documents, feature extraction, script recognition, clustering"}, {"heading": "1 Introduction", "text": "Script recognition has a great importance in document image analysis and optical character recognition [1]. Typically, it represents a process of automatic recognition of the font by the computer in scanned documents [2]. This process usually reduces the number of different symbol classes that are then eligible for classification [3]. The suggested script recognition methods have been classified as global or local [1]. Global methods divide the image of the document into larger blocks that are normalized and cleansed of noise. Then, statistical or frequency domain analysis is applied to the blocks. On the contrary, local methods divide the document image into small blocks of text, so-called connected components, on which feature analysis, i.e. black pixel runs, is applied [4]. This last method is used by Xiv (the corresponding author) ar: 160 9.06 492v 1 [cs.C V] 2much more computationally weight than one global but one but one, apt is to deal."}, {"heading": "2 Script Coding", "text": "The encoding phase transforms the script into a uniformly encoded text subject to feature extraction. It consists of two main steps: (i) mapping the text into an image based on typographical characteristics by applying line segmentation, blob extraction, blob heights and center recognition; (ii) extracting features from the image based on run lengths and local binary pattern analysis."}, {"heading": "2.1 Mapping based on typographical features", "text": "First, the text of the document is transformed into a 1-D image based on its typographic characteristics. Text is segmented into lines of text using the horizontal projection profile and is used to determine a central reference line for each line of text. On the basis of these extracted characteristics, a delimiter box is traced back to each blob, i.e. to each letter. This step of the algorithm is represented on a short medieval document from the Balkan region in ancient Cyrillic font. Boundary box heights and center positions can determine the categorization of the corresponding blob into the following classes [6]: (i) base letters (0), (ii) ascender letters (1), (ii) gradations (2) and (iv) full text (3). In Figure 2, the classification based on a typographic letter (0), (ii) ascender letter (1), (1) ascender letter (1) is transformed into a certain 1-D image."}, {"heading": "2.2 Feature extraction", "text": "Texture is used to calculate statistical measures useful for differentiating the images. Scroll length analysis can be applied to the obtained 1-D image to generate a feature vector of 11 elements representing the document. It calculates the following characteristics: (i) short-term highlighting (SRE), (ii) long-term highlighting (LRE), (iii) grey inhomogeneity (GLN), (iv) short-term highlighting (RP) [8], (vi) low grayscale highlighting (LGRE) and (vii) high grayscale highlighting (HGRE) [9], (viii) short-term grayscale highlighting (SRLGE), (ix) short-term high grayscale highlighting (SRHGE), (SRHGE) low grayscale highlighting (LBP), long-term grayscale highlighting (LBP) and (LBP)."}, {"heading": "3 Clustering Analysis", "text": "Distinction of attribute vectors representing documents in different scripts is accomplished by extending the Genetic Algorithms (nj =) Image Clustering for Document Analysis (GA-ICDA) method [14]. GA-ICDA is a bottom-up evolutionary strategy for which the document database is represented as a weighted graph G = (V, E, W). Nodes V correspond to documents and edges E to weighted connections, where W is the set of weights that models the affinity degree between the nodes. A node v-V is connected to a subset of its h-nearest adjacent nodes. Nodes V = {nnhv (1), Node E to weighted connections, where W is the set of weights. They represent the k documents that are most similar to the document of that node. Similarity is based on the L1 standard of the corresponding characteristics vectors, while h-parameter affects the size of the neighborhood."}, {"heading": "4 Experimental Results", "text": "The proposed method is based on two complex tailor-made databases. The first is a collection of labels from the Balkan region, hand-engraved in stone and hand-printed on paper in ancient Cyrillic, square and round Glagolitic fonts. The database contains 5 labels in ancient Cyrillic, 10 labels in square and 5 labels in round Glagolitic fonts, for a total of 20 labels. The second database consists of 100 historical German documents, mainly from the poems J. W. von Goethes, written in antiqua and fracture fonts. The experiment consists of the use of the modified GA-ICDA on the run length and ALBP feature vectors calculated from the documents in the two databases to test the effectiveness in correct differentiation of script types. A comparison is carried out between GA-ICDA with modification and other 4 cluster methods."}, {"heading": "5 Conclusions", "text": "A modified version of the GA-ICDA method was applied to feature vectors for distinguishing documents based on typeface typology. An extensive experiment with two complex databases of historical documents proved the effectiveness of the proposed method. Future work will extend the experiment to large data sets of labels engraved on different materials such as bronze, and compare the method with other classification algorithms."}], "references": [{"title": "Script recognition A review", "author": ["D. Ghosh", "T. Dube", "A. Shivaprasad"], "venue": "IEEE Trans. Pattern Analysis and Machine Intelligence, vol.32, no.12, pp.2142-2161", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2010}, {"title": "Indian script character recognition: A survey", "author": ["U. Pal", "B.B. Chaudhuri"], "venue": "Pattern Recognition, vol.37, no.9, pp.1887-1899", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2004}, {"title": "Twenty years of document image analysis in PAMI", "author": ["N. Nagy"], "venue": "IEEE Trans. Pattern Analysis and Machine Intelligence, vol.22, no.1, pp.38-62", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2000}, {"title": "A generalised framework for script identification", "author": ["G.D. Joshi", "S. Garg", "J. Sivaswamy"], "venue": "International Journal of Document Analysis and Recognition, vol.10, no.2, pp.55-68", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2007}, {"title": "Language determination: Natural language processing from scanned document images", "author": ["P. Sibun", "A.L. Spitz"], "venue": "Proc. of the 4th Conference on Applied Natural Language Processing, Las Vegas, USA, pp.423-433", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1995}, {"title": "Optical font recognition using typographical features", "author": ["A.W. Zramdini", "R. Ingold"], "venue": "IEEE Trans. Pattern Analysis and Machine Intelligence, vol.20, no.8, pp.877-882", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1998}, {"title": "An approach to the script discrimination in the Slavic documents", "author": ["D. Brodi\u0107", "Z.N. Milivojevi\u0107", "\u010c.A. Maluckov"], "venue": "Soft Computing, vol.19, no.9, pp.2655-2665", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2015}, {"title": "Texture analysis using gray level run lengths", "author": ["M.M. Galloway"], "venue": "Computer, Graphics and Image Processing, vol.4, no.2, pp.172-179", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1975}, {"title": "Use of gray value distribution of run lengths for texture analysis", "author": ["A. Chu", "C.M. Sehgal", "J.F. Greenleaf"], "venue": "Pattern Recognition Letters, vol.11, no.6, pp.415-419", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1990}, {"title": "Image characterizations based on joint gray-level run-length distributions", "author": ["B.R. Dasarathy", "E.B. Holder"], "venue": "Pattern Recognition Letters, vol.12, no.8, pp.497-502", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1991}, {"title": "A comparative study of texture measures with classification based on featured distributions", "author": ["T. Ojala", "M. Pietikainen", "D. Harwood"], "venue": "Pattern Recognition, vol.29, no.1, pp.51-59", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1996}, {"title": "Feature extraction based on co-occurrence of adjacent local binary patterns", "author": ["R. Nosaka", "Y. Ohkawa", "K. Fukui"], "venue": "Proc. of the 5th Pacific Rim Symposium on Image and Video Technology, Gwanju, South Korea, pp.82-91", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2011}, {"title": "Classification of the scripts in medieval documents from Balkan region by run-length texture analysis", "author": ["D. Brodi\u0107", "A. Amelio", "Z.N. Milivojevi\u0107"], "venue": "Proc. of the 22nd Conference on Neural Information Processing, Istanbul, Turkey, pp.442-450", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2015}, {"title": "Characterization and distinction between closely related south Slavic languages on the example of Serbian and Croatian", "author": ["D. Brodi\u0107", "A. Amelio", "Z.N. Milivojevi\u0107"], "venue": "Proc. of the 16th International Conference on Computer Analysis of Images and Patterns, Valletta, Malta, pp.654- 666", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2015}, {"title": "Mining Text Data", "author": ["C.C. Aggarwal", "C. Zhai"], "venue": "Springer USA", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2012}, {"title": "Recent Developments in Document Clustering", "author": ["N.O. Andrews", "E.A. Fox"], "venue": "Tech. rep., Computer Science, Virginia Tech.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2007}], "referenceMentions": [{"referenceID": 0, "context": "Script recognition has a great importance in document image analysis and optical character recognition [1].", "startOffset": 103, "endOffset": 106}, {"referenceID": 1, "context": "Typically, it represents a process of automatic recognition of script by computer in scanned documents [2].", "startOffset": 103, "endOffset": 106}, {"referenceID": 2, "context": "This process usually reduces the number of different symbol classes, which is then considered for classification [3].", "startOffset": 113, "endOffset": 116}, {"referenceID": 0, "context": "The proposed methods for script recognition have been classified as global or local ones [1].", "startOffset": 89, "endOffset": 92}, {"referenceID": 3, "context": ", black pixel runs, is applied [4].", "startOffset": 31, "endOffset": 34}, {"referenceID": 0, "context": "In any case, previously proposed methods reach an accuracy in script identification between 85% and 95% [1].", "startOffset": 104, "endOffset": 107}, {"referenceID": 4, "context": "Furthermore, it maps the connected components of the text to only 4 different codes similarly as in [5], which used character code shapes.", "startOffset": 100, "endOffset": 103}, {"referenceID": 5, "context": "Bounding box heights and center point locations can determine the categorization of the corresponding blobs into the following classes [6]: (i) base letter (0), (ii) ascender letter (1), (iii) descendent letter (2), and (iv) full letter (3).", "startOffset": 135, "endOffset": 138}, {"referenceID": 6, "context": "In fact, the following mapping is realized: base letter to 0, ascender letter to 1, descendent letter to 2, and full letter to 3 [7].", "startOffset": 129, "endOffset": 132}, {"referenceID": 7, "context": "It computes the following features: (i) short run emphasis (SRE), (ii) long run emphasis (LRE), (iii) gray-level non-uniformity (GLN), (iv) run length non-uniformity (RLN), (v) run percentage (RP) [8], (vi) low gray-level run emphasis (LGRE) and (vii) high graylevel run emphasis (HGRE) [9], (viii) short run low gray-level emphasis (SRLGE), (ix) short run high gray-level emphasis (SRHGE), (x) long run low gray-level emphasis (LRLGE), and (xi) long run high gray-level emphasis (LRHGE) [10].", "startOffset": 197, "endOffset": 200}, {"referenceID": 8, "context": "It computes the following features: (i) short run emphasis (SRE), (ii) long run emphasis (LRE), (iii) gray-level non-uniformity (GLN), (iv) run length non-uniformity (RLN), (v) run percentage (RP) [8], (vi) low gray-level run emphasis (LGRE) and (vii) high graylevel run emphasis (HGRE) [9], (viii) short run low gray-level emphasis (SRLGE), (ix) short run high gray-level emphasis (SRHGE), (x) long run low gray-level emphasis (LRLGE), and (xi) long run high gray-level emphasis (LRHGE) [10].", "startOffset": 287, "endOffset": 290}, {"referenceID": 9, "context": "It computes the following features: (i) short run emphasis (SRE), (ii) long run emphasis (LRE), (iii) gray-level non-uniformity (GLN), (iv) run length non-uniformity (RLN), (v) run percentage (RP) [8], (vi) low gray-level run emphasis (LGRE) and (vii) high graylevel run emphasis (HGRE) [9], (viii) short run low gray-level emphasis (SRLGE), (ix) short run high gray-level emphasis (SRHGE), (x) long run low gray-level emphasis (LRLGE), and (xi) long run high gray-level emphasis (LRHGE) [10].", "startOffset": 488, "endOffset": 492}, {"referenceID": 10, "context": "Local Binary Pattern (LBP) analysis can be suitable to obtain only 4 different features from 00 to 11, if the document is represented by 4 gray level images [11].", "startOffset": 157, "endOffset": 161}, {"referenceID": 11, "context": "Hence, LBP is extended to Adjacent Local Binary Pattern (ALBP) [12], which is the horizontal co-occurrence of LBP.", "startOffset": 63, "endOffset": 67}, {"referenceID": 12, "context": "It determines 16 features from 0000 to 1111, from which the histogram is computed as a 16-dimensional feature vector [13].", "startOffset": 117, "endOffset": 121}, {"referenceID": 13, "context": "Discrimination of feature vectors representing documents in different scripts is performed by an extension of Genetic Algorithms Image Clustering for Document Analysis (GA-ICDA) method [14].", "startOffset": 185, "endOffset": 189}, {"referenceID": 14, "context": "A comparison is performed between GA-ICDA with modification and other 4 clustering methods: the base version of GA-ICDA, Complete Linkage Hierarchical clustering, Self-Organizing-Map (SOM) and K-Means, well-known for document categorization [15].", "startOffset": 241, "endOffset": 245}, {"referenceID": 15, "context": "Precision, Recall, F-Measure (computed for each script class) and Normalized Mutual Information (NMI) are adopted as performance measures for clustering evaluation [16].", "startOffset": 164, "endOffset": 168}], "year": 2016, "abstractText": "The paper introduces a new method for discrimination of documents given in different scripts. The document is mapped into a uniformly coded text of numerical values. It is derived from the position of the letters in the text line, based on their typographical characteristics. Each code is considered as a gray level. Accordingly, the coded text determines a 1-D image, on which texture analysis by run-length statistics and local binary pattern is performed. It defines feature vectors representing the script content of the document. A modified clustering approach employed on document feature vector groups documents written in the same script. Experimentation performed on two custom oriented databases of historical documents in old Cyrillic, angular and round Glagolitic as well as Antiqua and Fraktur scripts demonstrates the superiority of the proposed method with respect to well-known methods in the state-of-the-art.", "creator": "LaTeX with hyperref package"}}}