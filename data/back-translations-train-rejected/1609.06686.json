{"id": "1609.06686", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Sep-2016", "title": "Character-level and Multi-channel Convolutional Neural Networks for Large-scale Authorship Attribution", "abstract": "Convolutional neural networks (CNNs) have demonstrated superior capability for extracting information from raw signals in computer vision. Recently, character-level and multi-channel CNNs have exhibited excellent performance for sentence classification tasks. We apply CNNs to large-scale authorship attribution, which aims to determine an unknown text's author among many candidate authors, motivated by their ability to process character-level signals and to differentiate between a large number of classes, while making fast predictions in comparison to state-of-the-art approaches. We extensively evaluate CNN-based approaches that leverage word and character channels and compare them against state-of-the-art methods for a large range of author numbers, shedding new light on traditional approaches. We show that character-level CNNs outperform the state-of-the-art on four out of five datasets in different domains. Additionally, we present the first application of authorship attribution to reddit.", "histories": [["v1", "Wed, 21 Sep 2016 19:08:15 GMT  (335kb,D)", "http://arxiv.org/abs/1609.06686v1", "9 pages, 5 figures, 3 tables"]], "COMMENTS": "9 pages, 5 figures, 3 tables", "reviews": [], "SUBJECTS": "cs.CL cs.LG", "authors": ["sebastian ruder", "parsa ghaffari", "john g breslin"], "accepted": false, "id": "1609.06686"}, "pdf": {"name": "1609.06686.pdf", "metadata": {"source": "CRF", "title": "Character-level and Multi-channel Convolutional Neural Networks for Large-scale Authorship Attribution", "authors": ["Sebastian Ruder", "Parsa Ghaffari", "John G. Breslin"], "emails": ["sebastian.ruder@insight-centre.org", "john.breslin@insight-centre.org", "sebastian@aylien.com", "parsa@aylien.com"], "sections": [{"heading": "1 Introduction", "text": "State-of-the-art methods of author assignment, which aim to determine the author of an unknown text among a number of author candidates, rely on low-level information such as character-n-grams (Frantzeskou and Stamatos, 2007). Recent approaches (Koppel et al., 2011) focus on large-scale author attributions for thousands of authors, but are expensive during prediction, which is a deficit in online scenarios for author attribution purposes (Seroussi et al., 2011). At the same time, revolutionary neural networks (CNNs et al., 2016) have achieved remarkable successes in computer vision (Krizhevsky et al, 2012) and speech recognition (Abdel-Hamid al, 2012)."}, {"heading": "2 Related work", "text": "Our work is inspired by two neural network architectures: multi-channel CNNs and character-level CNNs. Multi-channel CNNs are ubiquitous in areas where input can be naturally divided into different channels, such as color channels in computer vision, wavelengths in speech recognition (Hoshen et al., 2014). Natural voice input is typically in the form of tokens or characters. Kim (2014) observed that a static word channel is able to encode general semantic similarities, while a non-static channel can be fine-tuned to the task and performance on some datasets is improved. Character-level CNNs have shown that traditional classification methods are surpassed on large datasets (Zhang et al., 2015), but their CNNs require tens of thousands of performance examples and thousands of training periods, whereas our datasets only contain a few hundred examples per class."}, {"heading": "3 Model", "text": "The model architecture we use is an extension of the CNN structure used by Collobert et al. (2011). Its variant with two word embedding channels used by Kim (2014) is shown in Figure 1. The model takes as input a text that is added to the length n. For the character embedding channel, we represent the text as a concatenation of its character embedding z1: m, where zi Rk is the k-dimensional vector of the i-th character in the text andm is the character length of the text, while for the word embedding channel, we represent the text as a concatenation of its word embedding z1: m, where zi Rk is the k-dimensional vector of the i-th character in the text andm is the character length of the text, while for the word embedding channel we represent the text as a concatenation of its word embedding channels."}, {"heading": "4 Datasets", "text": "We name our models based on the following data sets, which cover a wide range of styles and domains: The Enron e-mail record contains approximately 0.5 million e-mails from predominantly senior managers of Enron4, organized in different folders. We extract e-mails from the SENT and SENT ITEMS folders as they contain outgoing traffic. We remove all e-mails except the e-mail body and discard e-mails containing less than 10 tokens, leaving 80,852 e-mails from 144 authors. The IMDb62 record contains 62,000 movie ratings from 62 productive users of the Internet movie database. The data set is provided upon request by Seroussi et al. (2011). The blog record contains 681,288 blog posts from 19,320 bloggers, which were shared by Schler et al. (2005) of blogger.com in August 2004u.Suzedcer to establish the data set, Twitter Influx."}, {"heading": "5 Experimental setup", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Model variations", "text": "We are testing variations of our model that use different combinations of input channels along with a single-layer CNN.10 \u2022 CNN Word: a CNN with a non-static word embedding channel, in which the vectors are modified during training using back propagation. This is the classic word used by CNN, for example, by Collobert et al. (2011). \u2022 CNN Sign: a CNN with a non-static word embedding channel. A variant with more than one revolutionary layer is used by Zhang et al. (2015). \u2022 CNN Word Word Word Word Word: a CNN with a static and a non-static word embedding channel. This is the multi-channel CNN suggested by Kim (2014). \u2022 CNN Word Character Char: a hybrid channel CNN with a non-static word and a non-static character channel. \u2022 CNN Word Word Word Char: a CNN with a static and a non-static character channel."}, {"heading": "5.2 Comparison methods", "text": "We compare four state-of-the-art methods of author assignment: \u2022 SVM + Stems: an SVM classifier that distinguishes authors by stems rather than by bag (Allison and Guthrie, 2008). Features are additionally weighted with tf-idf and scaled so that they have uniform variation. \u2022 SCAP: the Source Code Author Profile (SCAP) method (Frantzeskou and Stamatos, 2007) determines authorship based on the intersection of the most common n-grams of an unknown text and the profile of an author, i.e. the concentration of the known texts of an author. \u2022 Imposters: the Imposters Method (Koppel et al., 2011) is based on the intuition that the profile of an unknown text is probably the most similar to the unknown text and profile of an author."}, {"heading": "5.3 Hyperparameters and training", "text": "Since author assignment algorithms must be able to handle a large number of authors, we conduct experiments for a wide range of author numbers. For each number of authors, we select the subset of texts that belong to the n most authors with the most documents in the record. Note that while we scale the number of authors, decrease the number of documents per author, and identify prominent authors, it turns into the scenario of identifying authors with only a few samples. We do not balance the number of training documents to maintain the unbalanced distribution common in the real world. As the pro-life of most of the most modern author assignment methods makes 10-fold cross-validation prohibitively expensive, we allocate 10% as a layered test set. We keep the test set constant and use seed to reduce randomness in comparison. We continue to use 10% of each training set as a layered development set."}, {"heading": "6 Results and discussion", "text": "We evaluate all algorithms of all 62 authors for the IMDb dataset and 10 and 50 authors for all other datasets, respectively. Results of our CNN models against the comparison methods are listed in Table 3. Additionally, we evaluate the best CNNs against the best comparison method in Table 3, SCAP for a larger number of authors. We show results for all 144 authors for the email dataset in Figure 2 and results for up to 1,000 authors for the blogs, Twitter and reddit datasets in Figure 3, 4 and 5."}, {"heading": "6.1 Domain", "text": "The Corpus domain has a major impact on the performance of a model and often requires domain-specific feature engineering (Stamatos, 2009). Word-based methods such as SVM + Stems, LDAH-S, 12We use the same vocabulary as Zhang et al. (2015), but distinguish between lower and upper case letters, and tangle all numbers into one, as both measures increase performance. CNN word, CNN word domains where current information is discriminatory, such as e-mails, movie reviews, and blogs, but they perform comparatively poorly for short message domains such as Twitter and Reddit, with time-increased methods providing a significant performance boost. Past studies (Stamatos, 2009; Schwartz et al., 2013) have highlighted challenges for short text author attribution, such as the number of authors, the size of training capacities, and the size of test documents.Twitter's generally impressive values reflect the two-domain, which are a true one domain."}, {"heading": "6.2 CNNs", "text": "All of our CNN variants consistently outperform most traditional methods of author mapping. Even CNN words that use only word embedding are significantly better than most comparison methods. In addition, CNNs demonstrate the ability to handle the class imbalance inherent in real-world applications (Stamatos, 2007) by significantly outperforming the comparison methods on all data sets with unbalanced numbers per author (see Table 1). In the email domain, CNNs outperform comparison methods by more than 6%. For 10 authors and SCAP by more than 16%. We assume that these large performance differences lie in the fact that CNNs are able to pay particular attention to structural measures such as greetings, farewells, and signatures (de Vel et al., 2001). Differences for the IMDb domain are less pronounced, as authors would generally repeat similar movies by discriminating certain words or characters."}, {"heading": "6.3 Traditional methods", "text": "Similar to Frantzeskou and Stamatos (2007), we find that increasing the profile size of an author's concatenated known texts continuously increases the performance of n-gram-based similarity methods, i.e. SCAP and imposters. However, the optimal profile size for our records, 14,000, is significantly higher than previous values reported for this hyperparameter (Layton et al., 2010), suggesting that larger areas should be considered in future research. We found that limiting vocabulary size by selecting only 30,000 space-free characters n-grams for the imposters method has generally increased performance, since frequency is the most important criterion for selecting characteristics in authorship mapping (Stamatos, 2009). Although we are improving the performance of imposters on the IMDb datasets, which are better than Seroussi et al (2011), by using characters suitable hyper parameters, we are able to achieve the 130,000 recently suggested values, rather than the 13,000 we are able to render them."}, {"heading": "7 Conclusion", "text": "In this paper, we applied CNNs at the character level to large-scale author attributions; we analyzed combinations of different CNN input channels extensively; we introduced a novel model that combines character and word channels to use both stylistic and current information; we compared CNNs with modern methods for a variety of author numbers, shedding new light on traditional approaches; we presented current results for four out of five datasets in different domains; and we introduced two new Twitter and editing datasets that we provide for further research; 14 We apply them to a larger number of authors and obtain similar results. Note that, unlike Koppel et al. (2011) and Seroussi et al. (2011), we evaluate them using F1, which punishes poor memory."}, {"heading": "Acknowledgments", "text": "This publication is the result of research supported by the Irish Research Council's grant number EBPPG / 2014 / 30 with Aylien Ltd. as Enterprise Partner and the grant number SFI / 12 / RC / 2289 of the Science Foundation Ireland (SFI)."}], "references": [{"title": "Applying Authorship Analysis to Extremist-Group Web Forum Messages", "author": ["Ahmed Abbasi", "Hsinchun Chen."], "venue": "Intelligent Systems, IEEE, 20(5):67\u2013", "citeRegEx": "Abbasi and Chen.,? 2005", "shortCiteRegEx": "Abbasi and Chen.", "year": 2005}, {"title": "Applying convolutional neural networks concepts to hybrid NN-HMM model for speech recognition", "author": ["Ossama Abdel-Hamid", "Abdel Rahman Mohamed", "Hui Jiang", "Gerald Penn."], "venue": "IEEE International Conference on Acoustics, Speech and Signal Pro-", "citeRegEx": "Abdel.Hamid et al\\.,? 2012", "shortCiteRegEx": "Abdel.Hamid et al\\.", "year": 2012}, {"title": "Authorship Attribution of E-Mail: Comparing Classifiers over a New Corpus for Evaluation", "author": ["B Allison", "L Guthrie."], "venue": "LREC.", "citeRegEx": "Allison and Guthrie.,? 2008", "shortCiteRegEx": "Allison and Guthrie.", "year": 2008}, {"title": "Natural Language Processing (almost) from Scratch", "author": ["Ronan Collobert", "Jason Weston", "Leon Bottou", "Michael Karlen", "Koray Kavukcuoglu", "Pavel Kuksa."], "venue": "Journal of Machine Learning Research, 12(Aug):2493\u20132537.", "citeRegEx": "Collobert et al\\.,? 2011", "shortCiteRegEx": "Collobert et al\\.", "year": 2011}, {"title": "Mining e-mail content for author identification forensics", "author": ["O. de Vel", "a. Anderson", "M. Corney", "G. Mohay"], "venue": "ACM SIGMOD Record,", "citeRegEx": "Vel et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Vel et al\\.", "year": 2001}, {"title": "Identifying authorship by byte-level n-grams: The source code author profile (scap) method", "author": ["G Frantzeskou", "E Stamatatos."], "venue": "International Journal of Digital Evidence, 6(1):1\u201318.", "citeRegEx": "Frantzeskou and Stamatatos.,? 2007", "shortCiteRegEx": "Frantzeskou and Stamatatos.", "year": 2007}, {"title": "Speech Acoustic Modeling From Raw Multichannel Waveforms", "author": ["Yedid Hoshen", "Ron J Weiss", "Kevin W Wilson."], "venue": "pages 2\u20136.", "citeRegEx": "Hoshen et al\\.,? 2014", "shortCiteRegEx": "Hoshen et al\\.", "year": 2014}, {"title": "Character-Aware Neural Language Models", "author": ["Yoon Kim", "Yacine Jernite", "David Sontag", "Alexander M. Rush."], "venue": "AAAI.", "citeRegEx": "Kim et al\\.,? 2016", "shortCiteRegEx": "Kim et al\\.", "year": 2016}, {"title": "Convolutional Neural Networks for Sentence Classification", "author": ["Yoon Kim."], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 1746\u20131751.", "citeRegEx": "Kim.,? 2014", "shortCiteRegEx": "Kim.", "year": 2014}, {"title": "A Multiplicative Model for Learning Distributed Text-Based Attribute Representations", "author": ["Ryan Kiros", "Rs Zemel", "Ruslan Salakhutdinov."], "venue": "NIPS.", "citeRegEx": "Kiros et al\\.,? 2014", "shortCiteRegEx": "Kiros et al\\.", "year": 2014}, {"title": "Authorship attribution in the wild", "author": ["Moshe Koppel", "Jonathan Schler", "Shlomo Argamon."], "venue": "Language Resources and Evaluation, 45(1):83\u201394.", "citeRegEx": "Koppel et al\\.,? 2011", "shortCiteRegEx": "Koppel et al\\.", "year": 2011}, {"title": "ImageNet Classification with Deep Convolutional Neural Networks", "author": ["Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E Hinton."], "venue": "Advances In Neural Information Processing Systems, pages 1\u20139.", "citeRegEx": "Krizhevsky et al\\.,? 2012", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "Authorship attribution for twitter in 140 characters or less", "author": ["Robert Layton", "Paul Watters", "Richard Dazeley."], "venue": "Cybercrime and Trustworthy Computing Workshop (CTC), IEEE, pages 1\u20138.", "citeRegEx": "Layton et al\\.,? 2010", "shortCiteRegEx": "Layton et al\\.", "year": 2010}, {"title": "Unsupervised authorship analysis of phishing webpages", "author": ["Robert Layton", "Paul Watters", "Richard Dazeley."], "venue": "2012 International Symposium on Communications and Information Technologies, ISCIT 2012, (October):1104\u20131109.", "citeRegEx": "Layton et al\\.,? 2012", "shortCiteRegEx": "Layton et al\\.", "year": 2012}, {"title": "Distributed Representations of Words and Phrases and their Compositionality", "author": ["Tomas Mikolov", "Kai Chen", "Greg Corrado", "Jeffrey Dean."], "venue": "NIPS, pages 1\u20139.", "citeRegEx": "Mikolov et al\\.,? 2013", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Rectified Linear Units Improve Restricted Boltzmann Machines", "author": ["Vinod Nair", "Geoffrey E Hinton."], "venue": "Proceedings of the 27th International Conference on Machine Learning, (3):807\u2013814.", "citeRegEx": "Nair and Hinton.,? 2010", "shortCiteRegEx": "Nair and Hinton.", "year": 2010}, {"title": "Glove: Global Vectors for Word Representation", "author": ["Jeffrey Pennington", "Richard Socher", "Christopher D. Manning."], "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, pages 1532\u20131543.", "citeRegEx": "Pennington et al\\.,? 2014", "shortCiteRegEx": "Pennington et al\\.", "year": 2014}, {"title": "Who wrote the Web? Revisiting influential author identification research applicable to information retrieval", "author": ["Timo Sommer", "Michael Tr\u00e4ger", "Sebastian Wilhelm", "Benno Stein", "Efstathios Stamatatos", "Matthias Hagen"], "venue": null, "citeRegEx": "Sommer et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Sommer et al\\.", "year": 2016}, {"title": "Boosting Named Entity Recognition with Neural Character Embeddings", "author": ["Cicero Nogueira Dos Santos", "Victor Guimar\u00e3es."], "venue": "Proceedings of NEWS 2015 The Fifth Named Entities Workshop.", "citeRegEx": "Santos and Guimar\u00e3es.,? 2015", "shortCiteRegEx": "Santos and Guimar\u00e3es.", "year": 2015}, {"title": "Learning Character-level Representations for Part-ofSpeech Tagging", "author": ["CD Santos", "B Zadrozny."], "venue": "Proceedings of the 31st International Conference on Machine Learning, ICML14(2011):1818\u20131826.", "citeRegEx": "Santos and Zadrozny.,? 2014", "shortCiteRegEx": "Santos and Zadrozny.", "year": 2014}, {"title": "Not All Character N -grams Are Created Equal: A Study in Authorship Attribution", "author": ["Upendra Sapkota", "Steven Bethard", "Thamar Solorio."], "venue": "Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the", "citeRegEx": "Sapkota et al\\.,? 2015", "shortCiteRegEx": "Sapkota et al\\.", "year": 2015}, {"title": "Effects of Age and Gender on Blogging", "author": ["Jonathan Schler", "Moshe Koppel", "Shlomo Argamon", "James Pennebaker."], "venue": "AAAI Spring Symposium: Computational Approaches to Analyzing Weblogs, pages 199\u2013205.", "citeRegEx": "Schler et al\\.,? 2005", "shortCiteRegEx": "Schler et al\\.", "year": 2005}, {"title": "Authorship Attribution of MicroMessages", "author": ["Roy Schwartz", "Oren Tsur", "Ari Rappoport", "Moshe Koppel."], "venue": "Empirical Methods in Natural Language Processing, pages 1880\u20131891.", "citeRegEx": "Schwartz et al\\.,? 2013", "shortCiteRegEx": "Schwartz et al\\.", "year": 2013}, {"title": "Authorship Attribution with Latent Dirichlet Allocation", "author": ["Yanir Seroussi", "Ingrid Zukerman", "Fabian Bohnert."], "venue": "Proceedings of the Fifteenth Conference on Computational Natural Language Learning, (June):181\u2013189.", "citeRegEx": "Seroussi et al\\.,? 2011", "shortCiteRegEx": "Seroussi et al\\.", "year": 2011}, {"title": "Author identification using imbalanced and limited training texts", "author": ["Efstathios Stamatatos."], "venue": "Proceedings - International Workshop on Database and Expert Systems Applications, DEXA, pages 237\u2013241.", "citeRegEx": "Stamatatos.,? 2007", "shortCiteRegEx": "Stamatatos.", "year": 2007}, {"title": "A Survey of Modern Authorship Attribution Methods", "author": ["Efstathios Stamatatos."], "venue": "Journal of the American Society for Information Science and Technology, 60(3):538\u2013556.", "citeRegEx": "Stamatatos.,? 2009", "shortCiteRegEx": "Stamatatos.", "year": 2009}, {"title": "Sparse, Contextually Informed Models for Irony Detection: Exploiting User Communities, Entities and Sentiment", "author": ["Byron C. Wallace", "Do Kook Choe", "Eugene Charniak."], "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational", "citeRegEx": "Wallace et al\\.,? 2015", "shortCiteRegEx": "Wallace et al\\.", "year": 2015}, {"title": "ADADELTA: An Adaptive Learning Rate Method", "author": ["Matthew D. Zeiler."], "venue": "arXiv preprint arXiv:1212.5701.", "citeRegEx": "Zeiler.,? 2012", "shortCiteRegEx": "Zeiler.", "year": 2012}, {"title": "Character-level Convolutional Networks for Text Classification", "author": ["Xiang Zhang", "Junbo Zhao", "Yann LeCun."], "venue": "Advances in Neural Information Processing Systems, pages 649\u2013657.", "citeRegEx": "Zhang et al\\.,? 2015", "shortCiteRegEx": "Zhang et al\\.", "year": 2015}, {"title": "Aligning Books and Movies: Towards Story-like Visual Explanations by Watching Movies and Reading Books", "author": ["Yukun Zhu", "Ryan Kiros", "Richard Zemel", "Ruslan Salakhutdinov", "Raquel Urtasun", "Antonio Torralba", "Sanja Fidler."], "venue": "Proceedings", "citeRegEx": "Zhu et al\\.,? 2015", "shortCiteRegEx": "Zhu et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 5, "context": "State-of-the-art methods in authorship attribution, which aims to determine an unknown text\u2019s author among a set of candidate authors, rely on low-level information such as character n-grams (Frantzeskou and Stamatatos, 2007).", "startOffset": 191, "endOffset": 225}, {"referenceID": 10, "context": "Recent approaches (Koppel et al., 2011) focus on largescale authorship attribution for thousands of authors, but are expensive during prediction, which is a deficit in on-line scenarios for purposes of targeted marketing, copyright enforcement, writing support, and search relevance, among others (Potthast et al.", "startOffset": 18, "endOffset": 39}, {"referenceID": 23, "context": "Furthermore, besides stylistic information, word-level topical information has been shown to be relevant for authorship attribution (Seroussi et al., 2011).", "startOffset": 132, "endOffset": 155}, {"referenceID": 11, "context": "Simultaneously, convolutional neural networks (CNNs) have achieved remarkable successes in computer vision (Krizhevsky et al., 2012) and speech recognition (Abdel-Hamid et al.", "startOffset": 107, "endOffset": 132}, {"referenceID": 1, "context": ", 2012) and speech recognition (Abdel-Hamid et al., 2012) and have been found particularly suitable for extract-", "startOffset": 31, "endOffset": 57}, {"referenceID": 3, "context": "They have also been shown to be effective for various NLP tasks (Collobert et al., 2011) and have achieved state-of-the-art in several sentence classification tasks (Kim, 2014).", "startOffset": 64, "endOffset": 88}, {"referenceID": 8, "context": ", 2011) and have achieved state-of-the-art in several sentence classification tasks (Kim, 2014).", "startOffset": 84, "endOffset": 95}, {"referenceID": 14, "context": "works and CNNs in NLP perform convolutions on the word level using pre-trained word embeddings (Mikolov et al., 2013).", "startOffset": 95, "endOffset": 117}, {"referenceID": 28, "context": "Recent approaches employ convolutions over characters (Zhang et al., 2015).", "startOffset": 54, "endOffset": 74}, {"referenceID": 25, "context": "We apply CNNs to the task of authorship attribution for four reasons: a) They have been shown to be excellent at leveraging character-level signals, which have been found to be indicative of authorial style (Stamatatos, 2009); b) they have excelled at differentiating between a large number of classes (Krizhevsky et al.", "startOffset": 207, "endOffset": 225}, {"referenceID": 11, "context": "We apply CNNs to the task of authorship attribution for four reasons: a) They have been shown to be excellent at leveraging character-level signals, which have been found to be indicative of authorial style (Stamatatos, 2009); b) they have excelled at differentiating between a large number of classes (Krizhevsky et al., 2012), which is key for large-scale authorship attribution; c) prediction is fast; and d) a combination of word and character input channels enables them to take topical information into account.", "startOffset": 302, "endOffset": 327}, {"referenceID": 6, "context": "puter vision, wave lengths in speech recognition (Hoshen et al., 2014).", "startOffset": 49, "endOffset": 70}, {"referenceID": 6, "context": "puter vision, wave lengths in speech recognition (Hoshen et al., 2014). Natural language input is typically single-channel in the form of tokens or characters. Kim (2014) observe that a static word channel is able to encode general semantic similar-", "startOffset": 50, "endOffset": 171}, {"referenceID": 28, "context": "outperform traditional classification methods on large-scale datasets (Zhang et al., 2015).", "startOffset": 70, "endOffset": 90}, {"referenceID": 7, "context": "morphemes) to which word-level CNNs are blind: Kim et al. (2016) feed the output of a character-level CNN to a recurrent neural language model and improve performance particularly for morphologically rich languages.", "startOffset": 47, "endOffset": 65}, {"referenceID": 18, "context": "Santos and Zadrozny (2014) use a CNN that associates a character embedding produced by a CNN for each word with its word representation to improve POS tagging performance for English and Portuguese, while Santos and Guimar\u00e3es (2015) use the same network to boost results for named entity recognition.", "startOffset": 205, "endOffset": 233}, {"referenceID": 25, "context": "The key notion behind statistical authorship attribution is that measuring textual features enables distinction between texts written by different authors (Stamatatos, 2009).", "startOffset": 155, "endOffset": 173}, {"referenceID": 20, "context": "(Sapkota et al., 2015), and character and word n-grams (Schwartz et al.", "startOffset": 0, "endOffset": 22}, {"referenceID": 22, "context": ", 2015), and character and word n-grams (Schwartz et al., 2013).", "startOffset": 40, "endOffset": 63}, {"referenceID": 9, "context": "cused on modeling an author\u2019s style: Kiros et al. (2014) condition word embeddings on attributes such as style and predict an author\u2019s age, gender, and industry.", "startOffset": 37, "endOffset": 57}, {"referenceID": 9, "context": "cused on modeling an author\u2019s style: Kiros et al. (2014) condition word embeddings on attributes such as style and predict an author\u2019s age, gender, and industry. Zhu et al. (2015) transform image captions into book sentences by subtract-", "startOffset": 37, "endOffset": 180}, {"referenceID": 10, "context": "culate pairwise distances between feature subsets (Koppel et al., 2011).", "startOffset": 50, "endOffset": 71}, {"referenceID": 5, "context": "Simultaneously, character ngrams have proven to be the single most successful feature (Frantzeskou and Stamatatos, 2007).", "startOffset": 86, "endOffset": 120}, {"referenceID": 5, "context": "Simultaneously, character ngrams have proven to be the single most successful feature (Frantzeskou and Stamatatos, 2007). Finally, Potthast et al. (2016) compare traditional approaches on small datasets, while we evaluate state-of-the-art as well as CNN-based methods for thousands of authors, thereby moving a step closer to the goal of authorship attribution at web-scale.", "startOffset": 87, "endOffset": 154}, {"referenceID": 3, "context": "The model architecture we use is an extension of the CNN structure used by Collobert et al. (2011). Its variant with two word embedding channels used by Kim (2014) is depicted in Figure 1.", "startOffset": 75, "endOffset": 99}, {"referenceID": 3, "context": "The model architecture we use is an extension of the CNN structure used by Collobert et al. (2011). Its variant with two word embedding channels used by Kim (2014) is depicted in Figure 1.", "startOffset": 75, "endOffset": 164}, {"referenceID": 7, "context": "Figure 1: Multi-channel CNN with two word channels from Kim et al. (2014)", "startOffset": 56, "endOffset": 74}, {"referenceID": 15, "context": "Note that b \u2208 R is a bias term and f is a nonlinear function, ReLU (Nair and Hinton, 2010) in our case.", "startOffset": 67, "endOffset": 90}, {"referenceID": 3, "context": "Max-over-time pooling (Collobert et al., 2011) in turn condenses this feature vector to its most important feature by taking its maximum value and naturally deals with variable input lengths.", "startOffset": 22, "endOffset": 46}, {"referenceID": 7, "context": "Using low-dimensional character embeddings as in Kim et al. (2016) decreased performance.", "startOffset": 49, "endOffset": 67}, {"referenceID": 23, "context": "The dataset is made available by Seroussi et al. (2011) on request.", "startOffset": 33, "endOffset": 56}, {"referenceID": 21, "context": "The Blog authorship dataset contains 681,288 blog posts of 19,320 bloggers gathered by Schler et al. (2005) from blogger.", "startOffset": 87, "endOffset": 108}, {"referenceID": 3, "context": "by Collobert et al. (2011).", "startOffset": 3, "endOffset": 27}, {"referenceID": 8, "context": "This is the multi-channel CNN proposed by Kim (2014).", "startOffset": 42, "endOffset": 53}, {"referenceID": 12, "context": "The dataset collected by Layton et al. (2010) is no longer available.", "startOffset": 25, "endOffset": 46}, {"referenceID": 16, "context": "with 300-dimensional GloVe vectors (Pennington et al., 2014) trained on 840B tokens of the Common Crawl corpus11.", "startOffset": 35, "endOffset": 60}, {"referenceID": 2, "context": "\u2022 SVM+Stems: an SVM classifier, which distinguishes authors based on word stems rather than bag-of-words (Allison and Guthrie, 2008).", "startOffset": 105, "endOffset": 132}, {"referenceID": 5, "context": "file (SCAP) method (Frantzeskou and Stamatatos, 2007) determines authorship based on the intersection of the most frequent character n-grams of an unknown text and an author\u2019s profile, i.", "startOffset": 19, "endOffset": 53}, {"referenceID": 10, "context": "\u2022 Imposters: the Imposters Method (Koppel et al., 2011) is based on the intuition that the profile of an unknown text\u2019s author is likely to be most similar to the unknown text most often as the feature set varies.", "startOffset": 34, "endOffset": 55}, {"referenceID": 23, "context": "\u2022 LDAH-S: LDA Hellinger Single-Document, the top-performing method of Seroussi et al. (2011) uses Hellinger distance between the LDA topic distributions for an unknown text and an author\u2019s profile as a measure for authorship.", "startOffset": 70, "endOffset": 93}, {"referenceID": 2, "context": "Results for SVM+Stems have been reported on the Email dataset (Allison and Guthrie, 2008) and results for Imposters and LDAH-S have been reported on the IMDb62 and Blog dataset (Seroussi", "startOffset": 62, "endOffset": 89}, {"referenceID": 27, "context": "update rule (Zeiler, 2012) as it allows us to pay special attention to infrequent features that can be, however, highly indicative of certain authors.", "startOffset": 12, "endOffset": 26}, {"referenceID": 25, "context": "The corpus domain has a big impact on a model\u2019s performance and often requires domain-specific feature engineering (Stamatatos, 2009).", "startOffset": 115, "endOffset": 133}, {"referenceID": 28, "context": "We use the same vocabulary as Zhang et al. (2015), but distinguish between lower-case and upper-case characters and convolve all numbers into one as both measures increase performance.", "startOffset": 30, "endOffset": 50}, {"referenceID": 25, "context": "Past studies (Stamatatos, 2009; Schwartz et al., 2013) highlighted challenges for short text authorship attribution, such as the number of authors, the training set size, and the size of the test document.", "startOffset": 13, "endOffset": 54}, {"referenceID": 22, "context": "Past studies (Stamatatos, 2009; Schwartz et al., 2013) highlighted challenges for short text authorship attribution, such as the number of authors, the training set size, and the size of the test document.", "startOffset": 13, "endOffset": 54}, {"referenceID": 26, "context": "with the community; posts thus often reflect the character of the thread rather than the character of the user and often contain stylistically conspicuous features such as irony (Wallace et al., 2015).", "startOffset": 178, "endOffset": 200}, {"referenceID": 24, "context": "Moreover, CNNs show aptitude to handle the class imbalance problem (Stamatatos, 2007) inherent in real-world applications by significantly outperforming the comparison methods on all datasets with imbalanced numbers of documents per author (see Table 1) in line with findings by Potthast et al.", "startOffset": 67, "endOffset": 85}, {"referenceID": 24, "context": "Moreover, CNNs show aptitude to handle the class imbalance problem (Stamatatos, 2007) inherent in real-world applications by significantly outperforming the comparison methods on all datasets with imbalanced numbers of documents per author (see Table 1) in line with findings by Potthast et al. (2016).", "startOffset": 68, "endOffset": 302}, {"referenceID": 0, "context": "For this reason, they are particularly suited for conducting a large or recurring number of predictions in on-line scenarios such as attributing messages to known terrorists (Abbasi and Chen, 2005).", "startOffset": 174, "endOffset": 197}, {"referenceID": 5, "context": "Similarly to Frantzeskou and Stamatatos (2007), we find that increasing the profile size of an author\u2019s concatenated known texts consistently increases performance for n-gram based similarity", "startOffset": 13, "endOffset": 47}, {"referenceID": 12, "context": "The optimal profile size for our datasets, 14,000, however, is considerably higher than past values reported for this hyperparameter (Layton et al., 2010) (Layton et al.", "startOffset": 133, "endOffset": 154}, {"referenceID": 13, "context": ", 2010) (Layton et al., 2012), suggesting that larger ranges should be considered in future research.", "startOffset": 8, "endOffset": 29}, {"referenceID": 25, "context": "We have found that restricting the vocabulary size by selecting only the 30,000 most frequent space-free character n-grams for the Imposters method generally increased performance as frequency is the most important criterion for selecting features in authorship attribution (Stamatatos, 2009).", "startOffset": 274, "endOffset": 292}, {"referenceID": 23, "context": "13 Even though we improve performance for Imposters on the IMDb dataset in comparison to Seroussi et al. (2011) by selecting appropriate hyperparameters, we are unable to achieve competitive scores using the more recently proposed authorship attribution methods, Imposters", "startOffset": 89, "endOffset": 112}, {"referenceID": 28, "context": "To mitigate this deficit, CNNs can a) be made more expressive by adding more layers (Zhang et al., 2015); or b) can be interpolated with n-grams that capture clear n-gram-author corre-", "startOffset": 84, "endOffset": 104}, {"referenceID": 10, "context": "Note that we evaluate \u2013 in contrast to Koppel et al. (2011) and Seroussi et al.", "startOffset": 39, "endOffset": 60}, {"referenceID": 10, "context": "Note that we evaluate \u2013 in contrast to Koppel et al. (2011) and Seroussi et al. (2011) \u2013 using F1, which penalizes low recall.", "startOffset": 39, "endOffset": 87}], "year": 2016, "abstractText": "Convolutional neural networks (CNNs) have demonstrated superior capability for extracting information from raw signals in computer vision. Recently, characterlevel and multi-channel CNNs have exhibited excellent performance for sentence classification tasks. We apply CNNs to large-scale authorship attribution, which aims to determine an unknown text\u2019s author among many candidate authors, motivated by their ability to process characterlevel signals and to differentiate between a large number of classes, while making fast predictions in comparison to state-ofthe-art approaches. We extensively evaluate CNN-based approaches that leverage word and character channels and compare them against state-of-the-art methods for a large range of author numbers, shedding new light on traditional approaches. We show that character-level CNNs outperform the state-of-the-art on four out of five datasets in different domains. Additionally, we present the first application of authorship attribution to reddit. Finally, we release our new reddit and Twitter datasets for further research.", "creator": "LaTeX with hyperref package"}}}