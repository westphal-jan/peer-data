{"id": "1609.06694", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Sep-2016", "title": "PixelNet: Towards a General Pixel-level Architecture", "abstract": "We explore architectures for general pixel-level prediction problems, from low-level edge detection to mid-level surface normal estimation to high-level semantic segmentation. Convolutional predictors, such as the fully-convolutional network (FCN), have achieved remarkable success by exploiting the spatial redundancy of neighboring pixels through convolutional processing. Though computationally efficient, we point out that such approaches are not statistically efficient during learning precisely because spatial redundancy limits the information learned from neighboring pixels. We demonstrate that (1) stratified sampling allows us to add diversity during batch updates and (2) sampled multi-scale features allow us to explore more nonlinear predictors (multiple fully-connected layers followed by ReLU) that improve overall accuracy. Finally, our objective is to show how a architecture can get performance better than (or comparable to) the architectures designed for a particular task. Interestingly, our single architecture produces state-of-the-art results for semantic segmentation on PASCAL-Context, surface normal estimation on NYUDv2 dataset, and edge detection on BSDS without contextual post-processing.", "histories": [["v1", "Wed, 21 Sep 2016 19:32:46 GMT  (2485kb,D)", "http://arxiv.org/abs/1609.06694v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["aayush bansal", "xinlei chen", "bryan russell", "abhinav gupta", "deva ramanan"], "accepted": false, "id": "1609.06694"}, "pdf": {"name": "1609.06694.pdf", "metadata": {"source": "CRF", "title": "PixelNet: Towards a General Pixel-Level Architecture", "authors": ["Aayush Bansal", "Xinlei Chen", "Bryan Russell", "Abhinav Gupta", "Deva Ramanan"], "emails": [], "sections": [{"heading": null, "text": "We study architectures for general prediction problems at the pixel level, from low-level edge detection to normal mid-level surface estimation [4] to high-level semantic segmentation. Convolutionary predictions such as the Fullyconvolutional Network (FCN) have achieved remarkable success by exploiting the spatial redundancy of adjacent pixels through revolutionary processing. Although computationally efficient, we point out that such approaches to learning are not statistically efficient precisely because spatial redundancy limits the information gained from adjacent pixels. Finally, we show that (1) layered sampling allows us to add diversity during batch updates, and (2) sampled multi-scale functions allow us to explore more nonlinear predictors (multiple fully connected layers followed by ReLU) that improve overall accuracy. Finally, our goal is to show how an architecture can achieve better performance than a specific architectural object of interest (4) for high-level architectures."}, {"heading": "1. Introduction", "text": "This year, more than ever before in the history of the country in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is not a country, but in which it is a country, a country, a city and a country."}, {"heading": "2. Background", "text": "We deal with the pixel-by-pixel prediction problem, where we try to predict outputs Y. For pixel position p, the output can include binary Yp responses (e.g., edge detection), multi-level prediction properties (e.g., semantic segmentation), or real answers to the surface of normal predictions. There is a rich prediction art in modeling this prediction problem using hand-crafted features (representative examples include [1, 11, 16, 29, 59, 61, 66, 72]. Convolutionary prediction: We explore spatially invariant predictors of tighter, p (X), which are end-to-end tractable parameters."}, {"heading": "3. Approach", "text": "This chapter describes our approach to predicting pixels, which is an efficient method for predicting predictions in the previous sections. We've got to deal first with our pixelated prediction architecture, and then we're going to have to deal with the question, how it's going to deal with answering questions in terms of the way it's going to deal with the way it's going to deal with the way it's going to deal with the way it's going to deal with the way it's going to deal with the way it's going to deal with the way it's going to deal with the way it's going to deal with the way it's going to deal with the way it's going to deal with the way it's going to deal with and the way it's going to deal with and the way it's going to deal with and the way it's going to deal with and the way it's going to deal with it and the way it's going to deal with it and the way it's going to deal with it and the way it's going to deal with it and the way it's going to deal with it and the way it's going to deal with it's going to deal with it and the way it's going to deal with it and the way it's going to deal with it's going to deal with it and the way it's going to deal with it's going to deal with it and the way it's going to deal with it's going to deal with it and the way it's going to deal with it's going to deal with it's going to deal with and the way it's going to deal with and the way it's going to deal with it's going to deal with and the way it's going to deal with it's going to deal with it's going to deal with it and the way it's going to deal with it's going to deal with it's going to deal with and the way it's going to deal with it's going to deal with it and the way it's going to deal with the way it's going to deal with the way it's going to deal with and the way it's going to deal with the way it's going to deal with it's going to deal with the way it's going to deal with it's going to deal with it's going to deal with it's going to deal with and the way it's going to deal with and the way it's going to deal with it's going to deal with"}, {"heading": "4. Experiments", "text": "In this section we describe our experimental evaluation. We apply our architecture (with minor modifications) to the high-level task of semantic segmentation and the low-level task of edge recognition. We show state-of-the-art results on PASCAL context [53] (without contextual post-processing), compete performance on PASCAL VOC 2012 [21], and promote the state of the art on the BSDS benchmark [2]. We also perform a diagnostic evaluation of the effect of sampling and other hyperparameters / design choices.Default Network: As with other methods [13, 48, 71] we fine-tune a VGG-16 network [63]. VGG-16 has 13 con-1We briefly present the results of normal surface estimation in this paper. Let's refer to [4] for more detailed, more complex layers and three fully connected (fc) layers."}, {"heading": "4.1. Semantic Segmentation", "text": "This year, it is as far as ever in the history of the city, where it is as far as never before in the history of the city."}, {"heading": "4.2. Surface Normal Estimation", "text": "The PixelNet architecture was first proposed in our paper [4] to align 2D-to-3D models using normal surface estimation. Here, we extract some of the results from [4] to show the effectiveness of this architecture for the mean task of 4Per-class performance available at http: / / host.robots.ox. The criteria introduced by Fouhey et al. [25] are used to compare our approach [4] with previous work [19, 25]. Six statistics are calculated on the angular error between the predicted normal values and depth-based normal values - mean, median, RMSE, 11.25 \u043c, 22.5 \u043c, and 30 \u043c - using the standards of Ladicky et al. [42] as opposed to the normal values where these standards are calculated from depth."}, {"heading": "4.3. Edge Detection", "text": "This year it has come to the point that it will only be a matter of time before it will happen, until it does."}, {"heading": "5. Discussion", "text": "We have described a revolutionary pixel architecture that, with minor modifications, results in state-of-the-art accuracy on various high-level, middle-level [4] and low-level tasks [71] that are already used in each batch, so performance gains are unlikely due to label realignment. We have performed a vanilla version of our approach to depth assessment [4] and achieved near state-of-the-art performance (on the NYU-v2 depth dataset) with a simple scale invariant loss function [20]. We will add the results of depth assessment after a more careful analysis in a later version [4] and edge dataset. Our results are enabled by careful analysis of computational and statistical considerations."}], "references": [{"title": "Semantic segmentation using regions and parts", "author": ["P. Arbel\u00e1ez", "B. Hariharan", "C. Gu", "S. Gupta", "L. Bourdev", "J. Malik"], "venue": "CVPR. IEEE,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "Contour detection and hierarchical image segmentation", "author": ["P. Arbelaez", "M. Maire", "C. Fowlkes", "J. Malik"], "venue": "TPAMI,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2011}, {"title": "A database and evaluation methodology for optical flow", "author": ["S. Baker", "D. Scharstein", "J. Lewis", "S. Roth", "M.J. Black", "R. Szeliski"], "venue": "IJCV, 92(1),", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2011}, {"title": "Marr Revisited: 2D-3D model alignment via surface normal prediction", "author": ["A. Bansal", "B. Russell", "A. Gupta"], "venue": "CVPR,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2016}, {"title": "The fast bilateral solver", "author": ["J.T. Barron", "B. Poole"], "venue": "CoRR, abs/1511.03296,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2015}, {"title": "Insideoutside net: Detecting objects in context with skip pooling and recurrent neural networks", "author": ["S. Bell", "C.L. Zitnick", "K. Bala", "R. Girshick"], "venue": "arXiv preprint arXiv:1512.04143,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "Neural networks for pattern recognition", "author": ["C.M. Bishop"], "venue": "Oxford university press,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1995}, {"title": "Sgd-qn: Careful quasi-newton stochastic gradient descent", "author": ["A. Bordes", "L. Bottou", "P. Gallinari"], "venue": "JMLR, 10,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2009}, {"title": "Large-scale machine learning with stochastic gradient descent", "author": ["L. Bottou"], "venue": "Proceedings of COMPSTAT\u20192010, pages 177\u2013186. Springer,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2010}, {"title": "Scene labeling with lstm recurrent neural networks", "author": ["W. Byeon", "T.M. Breuel", "F. Raue", "M. Liwicki"], "venue": "CVPR,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2015}, {"title": "Semantic segmentation with second-order pooling", "author": ["J. Carreira", "R. Caseiro", "J. Batista", "C. Sminchisescu"], "venue": "ECCV.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2012}, {"title": "Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs", "author": ["L. Chen", "G. Papandreou", "I. Kokkinos", "K. Murphy", "A.L. Yuille"], "venue": "CoRR, abs/1606.00915,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2016}, {"title": "Semantic image segmentation with deep convolutional nets and fully connected CRFs", "author": ["L.-C. Chen", "G. Papandreou", "I. Kokkinos", "K. Murphy", "A.L. Yuille"], "venue": "ICLR,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2015}, {"title": "Large scale distributed deep networks", "author": ["J. Dean", "G. Corrado", "R. Monga", "K. Chen", "M. Devin", "M. Mao", "A. Senior", "P. Tucker", "K. Yang", "Q.V. Le"], "venue": "In NIPS,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2012}, {"title": "Deep generative image models using a laplacian pyramid of adversarial networks", "author": ["E.L. Denton", "S. Chintala", "R. Fergus"], "venue": "In NIPS,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2015}, {"title": "Structured forests for fast edge detection", "author": ["P. Doll\u00e1r", "C. Zitnick"], "venue": "ICCV,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2013}, {"title": "Fast edge detection using structured forests", "author": ["P. Doll\u00e1r", "C.L. Zitnick"], "venue": "TPAMI, 37(8),", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2015}, {"title": "Flownet: Learning optical flow with convolutional networks", "author": ["A. Dosovitskiy", "P. Fischer", "E. Ilg", "P. H\u00e4usser", "C. Hazrba", "V. Golkov", "P. v.d. Smagt", "D. Cremers", "T. Brox"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2015}, {"title": "Predicting depth, surface normals and semantic labels with a common multi-scale convolutional architecture", "author": ["D. Eigen", "R. Fergus"], "venue": "ICCV,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2015}, {"title": "Depth map prediction from a single image using a multi-scale deep network", "author": ["D. Eigen", "C. Puhrsch", "R. Fergus"], "venue": "NIPS,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}, {"title": "The PASCAL Visual Object Classes (VOC) Challenge", "author": ["M. Everingham", "L. Van Gool", "C.K.I. Williams", "J. Winn", "A. Zisserman"], "venue": "IJCV,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2010}, {"title": "Learning hierarchical features for scene labeling", "author": ["C. Farabet", "C. Couprie", "L. Najman", "Y. LeCun"], "venue": "TPAMI, 35(8),", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2013}, {"title": "Efficient graphbased image segmentation", "author": ["P.F. Felzenszwalb", "D.P. Huttenlocher"], "venue": "IJCV, 59(2),", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2004}, {"title": "Flownet: Learning optical flow with convolutional networks", "author": ["P. Fischer", "A. Dosovitskiy", "E. Ilg", "P. H\u00e4usser", "C. Haz\u0131rba\u015f", "V. Golkov", "P. van der Smagt", "D. Cremers", "T. Brox"], "venue": "arXiv preprint arXiv:1504.06852,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2015}, {"title": "Data-driven 3D primitives for single image understanding", "author": ["D.F. Fouhey", "A. Gupta", "M. Hebert"], "venue": "ICCV,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2013}, {"title": "Fast r-cnn", "author": ["R. Girshick"], "venue": "ICCV,", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2015}, {"title": "Rich feature hierarchies for accurate object detection and semantic segmentation", "author": ["R. Girshick", "J. Donahue", "T. Darrell", "J. Malik"], "venue": "CVPR,", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2014}, {"title": "Using k-poselets for detecting people and localizing their keypoints", "author": ["G. Gkioxari", "B. Hariharan", "R. Girshick", "J. Malik"], "venue": null, "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2014}, {"title": "Decomposing a scene into geometric and semantically consistent regions", "author": ["S. Gould", "R. Fulton", "D. Koller"], "venue": "ICCV. IEEE,", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2009}, {"title": "Oriented edge forests for boundary detection", "author": ["S. Hallman", "C.C. Fowlkes"], "venue": "CVPR,", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2015}, {"title": "Hypercolumns for object segmentation and fine-grained localization", "author": ["B. Hariharan", "P. Arbel\u00e1ez", "R. Girshick", "J. Malik"], "venue": "CVPR,", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep residual learning for image recognition", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "arXiv preprint arXiv:1512.03385,", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2015}, {"title": "Densebox: Unifying landmark localization with end to end object detection", "author": ["L. Huang", "Y. Yang", "Y. Deng", "Y. Yu"], "venue": "arXiv preprint arXiv:1509.04874,", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2015}, {"title": "Pixel-wise deep learning for contour detection", "author": ["J.-J. Hwang", "T.-L. Liu"], "venue": "arXiv preprint arXiv:1504.01989,", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2015}, {"title": "Natural Image Statistics: A Probabilistic Approach to Early Computational Vision., volume 39", "author": ["A. Hyv\u00e4rinen", "J. Hurri", "P.O. Hoyer"], "venue": "Springer Science & Business Media,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2009}, {"title": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "author": ["S. Ioffe", "C. Szegedy"], "venue": "D. Blei and F. Bach, editors, Proceedings of the 32nd International Conference on Machine Learning (ICML-15), pages 448\u2013456. JMLR Workshop and Conference Proceedings,", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2015}, {"title": "Crisp boundary detection using pointwise mutual information", "author": ["P. Isola", "D. Zoran", "D. Krishnan", "E.H. Adelson"], "venue": "Computer Vision\u2013ECCV 2014, pages 799\u2013814. Springer,", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2014}, {"title": "Caffe: Convolutional architecture for fast feature embedding", "author": ["Y. Jia", "E. Shelhamer", "J. Donahue", "S. Karayev", "J. Long", "R. Girshick", "S. Guadarrama", "T. Darrell"], "venue": "ACMMM,", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2014}, {"title": "Visual boundary prediction: A deep neural prediction network and quality dissection", "author": ["J.J. Kivinen", "C.K. Williams", "N. Heess", "D. Technologies"], "venue": "AISTATS, volume 1, page 9,", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2014}, {"title": "Efficient inference in fully connected crfs with gaussian edge potentials", "author": ["P. Kr\u00e4henb\u00fchl", "V. Koltun"], "venue": "NIPS,", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2011}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "NIPS,", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2012}, {"title": "Discriminatively trained dense surface normal estimation", "author": ["L. Ladicky", "B. Zeisl", "M. Pollefeys"], "venue": "ECCV,", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2014}, {"title": "Efficient backprop", "author": ["Y.A. LeCun", "L. Bottou", "G.B. Orr", "K.-R. M\u00fcller"], "venue": "Neural networks: Tricks of the trade, pages 9\u201348. Springer,", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2012}, {"title": "Sketch tokens: A learned mid-level representation for contour and object detection", "author": ["J. Lim", "C. Zitnick", "P. Doll\u00e1r"], "venue": "CVPR,", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2013}, {"title": "Nonparametric scene parsing via label transfer", "author": ["C. Liu", "J. Yuen", "A. Torralba"], "venue": "TPAMI, 33(12),", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2011}, {"title": "Parsenet: Looking wider to see better", "author": ["W. Liu", "A. Rabinovich", "A.C. Berg"], "venue": "arXiv preprint arXiv:1506.04579,", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2015}, {"title": "Fully convolutional networks for semantic segmentation", "author": ["J. Long", "E. Shelhamer", "T. Darrell"], "venue": "CoRR, abs/1411.4038,", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2014}, {"title": "Fully convolutional models for semantic segmentation", "author": ["J. Long", "E. Shelhamer", "T. Darrell"], "venue": "CVPR,", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2015}, {"title": "A real-time algorithm for signal analysis with the help of the wavelet transform", "author": ["J.M.M. Holschneider", "R. Kronland-Martinet", "P. Tchamitchian"], "venue": "Wavelets, Time-Frequency Methods and Phase Space, pages 289\u2013297,", "citeRegEx": "49", "shortCiteRegEx": null, "year": 1989}, {"title": "Learning to detect natural image boundaries using local brightness, color, and texture cues", "author": ["D.R. Martin", "C.C. Fowlkes", "J. Malik"], "venue": "TPAMI, 26(5),", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2004}, {"title": "Multidigit recognition using a space displacement neural network", "author": ["O. Matan", "C.J. Burges", "Y. LeCun", "J.S. Denker"], "venue": "NIPS, pages 488\u2013495,", "citeRegEx": "51", "shortCiteRegEx": null, "year": 1991}, {"title": "Feedforward semantic segmentation with zoom-out features", "author": ["M. Mostajabi", "P. Yadollahpour", "G. Shakhnarovich"], "venue": "CVPR, pages 3376\u20133385,", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2015}, {"title": "The role of context for object detection and semantic segmentation in the wild", "author": ["R. Mottaghi", "X. Chen", "X. Liu", "N.-G. Cho", "S.-W. Lee", "S. Fidler", "R. Urtasun", "A. Yuille"], "venue": "CVPR,", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2014}, {"title": "Stacked hierarchical labeling", "author": ["D. Munoz", "J.A. Bagnell", "M. Hebert"], "venue": "Computer Vision\u2013ECCV 2010, pages 57\u201370. Springer,", "citeRegEx": "54", "shortCiteRegEx": null, "year": 2010}, {"title": "Learning deconvolution network for semantic segmentation", "author": ["H. Noh", "S. Hong", "B. Han"], "venue": "ICCV,", "citeRegEx": "55", "shortCiteRegEx": null, "year": 2015}, {"title": "Recurrent convolutional neural networks for scene parsing", "author": ["P.H. Pinheiro", "R. Collobert"], "venue": "ICML,", "citeRegEx": "56", "shortCiteRegEx": null, "year": 2014}, {"title": "Postal address block location using a convolutional locator network", "author": ["J.C. Platt", "R. Wolf"], "venue": "NIPS,", "citeRegEx": "57", "shortCiteRegEx": null, "year": 1993}, {"title": "Learning to parse images of articulated bodies", "author": ["D. Ramanan"], "venue": "NIPS.", "citeRegEx": "58", "shortCiteRegEx": null, "year": 2007}, {"title": "Associative hierarchical crfs for object class image segmentation", "author": ["C. Russell", "P. Kohli", "P.H. Torr"], "venue": "In ICCV. IEEE,", "citeRegEx": "59", "shortCiteRegEx": "59", "year": 2009}, {"title": "3-d depth reconstruction from a single still image", "author": ["A. Saxena", "S.H. Chung", "A.Y. Ng"], "venue": "IJCV, 76(1),", "citeRegEx": "60", "shortCiteRegEx": null, "year": 2008}, {"title": "Textonboost for image understanding: Multi-class object recognition and segmentation by jointly modeling texture, layout, and context", "author": ["J. Shotton", "J. Winn", "C. Rother", "A. Criminisi"], "venue": "Int. Journal of Computer Vision (IJCV), January", "citeRegEx": "61", "shortCiteRegEx": null, "year": 2009}, {"title": "Indoor segmentation and support inference from rgbd images", "author": ["N. Silberman", "D. Hoiem", "P. Kohli", "R. Fergus"], "venue": "ECCV,", "citeRegEx": "62", "shortCiteRegEx": null, "year": 2012}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["K. Simonyan", "A. Zisserman"], "venue": "CoRR, abs/1409.1556,", "citeRegEx": "63", "shortCiteRegEx": null, "year": 2014}, {"title": "Dropout: A simple way to prevent neural networks from overfitting", "author": ["N. Srivastava", "G. Hinton", "A. Krizhevsky", "I. Sutskever", "R. Salakhutdinov"], "venue": "JMLR, 15(1),", "citeRegEx": "64", "shortCiteRegEx": null, "year": 2014}, {"title": "Superparsing: scalable nonparametric image parsing with superpixels", "author": ["J. Tighe", "S. Lazebnik"], "venue": "Computer Vision\u2013 ECCV 2010, pages 352\u2013365. Springer,", "citeRegEx": "65", "shortCiteRegEx": null, "year": 2010}, {"title": "Auto-context and its application to highlevel vision tasks and 3d brain image segmentation", "author": ["Z. Tu", "X. Bai"], "venue": "TPAMI, 32(10),", "citeRegEx": "66", "shortCiteRegEx": null, "year": 2010}, {"title": "Visual tracking with fully convolutional networks", "author": ["L. Wang", "W. Ouyang", "X. Wang", "H. Lu"], "venue": "ICCV,", "citeRegEx": "67", "shortCiteRegEx": null, "year": 2015}, {"title": "Designing deep networks for surface normal estimation", "author": ["X. Wang", "D. Fouhey", "A. Gupta"], "venue": "CVPR,", "citeRegEx": "68", "shortCiteRegEx": null, "year": 2015}, {"title": "Discriminatively trained sparse code gradients for contour detection", "author": ["R. Xiaofeng", "L. Bo"], "venue": "NIPS,", "citeRegEx": "69", "shortCiteRegEx": null, "year": 2012}, {"title": "Convolutional pseudo-prior for structured labeling", "author": ["S. Xie", "X. Huang", "Z. Tu"], "venue": "arXiv preprint arXiv:1511.07409,", "citeRegEx": "70", "shortCiteRegEx": null, "year": 2015}, {"title": "Holistically-nested edge detection", "author": ["S. Xie", "Z. Tu"], "venue": "ICCV,", "citeRegEx": "71", "shortCiteRegEx": null, "year": 2015}, {"title": "Describing the scene as a whole: Joint object detection, scene classification and semantic segmentation", "author": ["J. Yao", "S. Fidler", "R. Urtasun"], "venue": "CVPR. IEEE,", "citeRegEx": "72", "shortCiteRegEx": null, "year": 2012}, {"title": "Multi-scale context aggregation by dilated convolutions", "author": ["F. Yu", "V. Koltun"], "venue": "ICLR,", "citeRegEx": "73", "shortCiteRegEx": null, "year": 2016}, {"title": "Conditional random fields as recurrent neural networks", "author": ["S. Zheng", "S. Jayasumana", "B. Romera-Paredes", "V. Vineet", "Z. Su", "D. Du", "C. Huang", "P.H. Torr"], "venue": "ICCV,", "citeRegEx": "74", "shortCiteRegEx": null, "year": 2015}], "referenceMentions": [{"referenceID": 70, "context": "Note how our approach recovers the fine details missing in the ground truth segmentation (left), and achieves state-of-the-art on edge detection [71].", "startOffset": 145, "endOffset": 149}, {"referenceID": 3, "context": "We explore architectures for general pixel-level prediction problems, from low-level edge detection to mid-level surface normal estimation [4] to high-level semantic segmentation.", "startOffset": 139, "endOffset": 142}, {"referenceID": 3, "context": "Interestingly, our single architecture produces state-of-the-art results for semantic segmentation on PASCAL-Context, surface normal estimation [4] on NYUDv2 dataset, and edge detection on BSDS without contextual post-processing.", "startOffset": 144, "endOffset": 147}, {"referenceID": 15, "context": "These include low-level tasks such as edge detection [16, 50, 71] and optical flow [3, 18], mid-level tasks such as depth/normal recovery [4, 19, 20, 60, 68], and high-level tasks such as keypoint prediction [28, 58], object detection [33], and semantic segmentation [13, 22, 31, 48, 52, 61].", "startOffset": 53, "endOffset": 65}, {"referenceID": 49, "context": "These include low-level tasks such as edge detection [16, 50, 71] and optical flow [3, 18], mid-level tasks such as depth/normal recovery [4, 19, 20, 60, 68], and high-level tasks such as keypoint prediction [28, 58], object detection [33], and semantic segmentation [13, 22, 31, 48, 52, 61].", "startOffset": 53, "endOffset": 65}, {"referenceID": 70, "context": "These include low-level tasks such as edge detection [16, 50, 71] and optical flow [3, 18], mid-level tasks such as depth/normal recovery [4, 19, 20, 60, 68], and high-level tasks such as keypoint prediction [28, 58], object detection [33], and semantic segmentation [13, 22, 31, 48, 52, 61].", "startOffset": 53, "endOffset": 65}, {"referenceID": 2, "context": "These include low-level tasks such as edge detection [16, 50, 71] and optical flow [3, 18], mid-level tasks such as depth/normal recovery [4, 19, 20, 60, 68], and high-level tasks such as keypoint prediction [28, 58], object detection [33], and semantic segmentation [13, 22, 31, 48, 52, 61].", "startOffset": 83, "endOffset": 90}, {"referenceID": 17, "context": "These include low-level tasks such as edge detection [16, 50, 71] and optical flow [3, 18], mid-level tasks such as depth/normal recovery [4, 19, 20, 60, 68], and high-level tasks such as keypoint prediction [28, 58], object detection [33], and semantic segmentation [13, 22, 31, 48, 52, 61].", "startOffset": 83, "endOffset": 90}, {"referenceID": 3, "context": "These include low-level tasks such as edge detection [16, 50, 71] and optical flow [3, 18], mid-level tasks such as depth/normal recovery [4, 19, 20, 60, 68], and high-level tasks such as keypoint prediction [28, 58], object detection [33], and semantic segmentation [13, 22, 31, 48, 52, 61].", "startOffset": 138, "endOffset": 157}, {"referenceID": 18, "context": "These include low-level tasks such as edge detection [16, 50, 71] and optical flow [3, 18], mid-level tasks such as depth/normal recovery [4, 19, 20, 60, 68], and high-level tasks such as keypoint prediction [28, 58], object detection [33], and semantic segmentation [13, 22, 31, 48, 52, 61].", "startOffset": 138, "endOffset": 157}, {"referenceID": 19, "context": "These include low-level tasks such as edge detection [16, 50, 71] and optical flow [3, 18], mid-level tasks such as depth/normal recovery [4, 19, 20, 60, 68], and high-level tasks such as keypoint prediction [28, 58], object detection [33], and semantic segmentation [13, 22, 31, 48, 52, 61].", "startOffset": 138, "endOffset": 157}, {"referenceID": 59, "context": "These include low-level tasks such as edge detection [16, 50, 71] and optical flow [3, 18], mid-level tasks such as depth/normal recovery [4, 19, 20, 60, 68], and high-level tasks such as keypoint prediction [28, 58], object detection [33], and semantic segmentation [13, 22, 31, 48, 52, 61].", "startOffset": 138, "endOffset": 157}, {"referenceID": 67, "context": "These include low-level tasks such as edge detection [16, 50, 71] and optical flow [3, 18], mid-level tasks such as depth/normal recovery [4, 19, 20, 60, 68], and high-level tasks such as keypoint prediction [28, 58], object detection [33], and semantic segmentation [13, 22, 31, 48, 52, 61].", "startOffset": 138, "endOffset": 157}, {"referenceID": 27, "context": "These include low-level tasks such as edge detection [16, 50, 71] and optical flow [3, 18], mid-level tasks such as depth/normal recovery [4, 19, 20, 60, 68], and high-level tasks such as keypoint prediction [28, 58], object detection [33], and semantic segmentation [13, 22, 31, 48, 52, 61].", "startOffset": 208, "endOffset": 216}, {"referenceID": 57, "context": "These include low-level tasks such as edge detection [16, 50, 71] and optical flow [3, 18], mid-level tasks such as depth/normal recovery [4, 19, 20, 60, 68], and high-level tasks such as keypoint prediction [28, 58], object detection [33], and semantic segmentation [13, 22, 31, 48, 52, 61].", "startOffset": 208, "endOffset": 216}, {"referenceID": 32, "context": "These include low-level tasks such as edge detection [16, 50, 71] and optical flow [3, 18], mid-level tasks such as depth/normal recovery [4, 19, 20, 60, 68], and high-level tasks such as keypoint prediction [28, 58], object detection [33], and semantic segmentation [13, 22, 31, 48, 52, 61].", "startOffset": 235, "endOffset": 239}, {"referenceID": 12, "context": "These include low-level tasks such as edge detection [16, 50, 71] and optical flow [3, 18], mid-level tasks such as depth/normal recovery [4, 19, 20, 60, 68], and high-level tasks such as keypoint prediction [28, 58], object detection [33], and semantic segmentation [13, 22, 31, 48, 52, 61].", "startOffset": 267, "endOffset": 291}, {"referenceID": 21, "context": "These include low-level tasks such as edge detection [16, 50, 71] and optical flow [3, 18], mid-level tasks such as depth/normal recovery [4, 19, 20, 60, 68], and high-level tasks such as keypoint prediction [28, 58], object detection [33], and semantic segmentation [13, 22, 31, 48, 52, 61].", "startOffset": 267, "endOffset": 291}, {"referenceID": 30, "context": "These include low-level tasks such as edge detection [16, 50, 71] and optical flow [3, 18], mid-level tasks such as depth/normal recovery [4, 19, 20, 60, 68], and high-level tasks such as keypoint prediction [28, 58], object detection [33], and semantic segmentation [13, 22, 31, 48, 52, 61].", "startOffset": 267, "endOffset": 291}, {"referenceID": 47, "context": "These include low-level tasks such as edge detection [16, 50, 71] and optical flow [3, 18], mid-level tasks such as depth/normal recovery [4, 19, 20, 60, 68], and high-level tasks such as keypoint prediction [28, 58], object detection [33], and semantic segmentation [13, 22, 31, 48, 52, 61].", "startOffset": 267, "endOffset": 291}, {"referenceID": 51, "context": "These include low-level tasks such as edge detection [16, 50, 71] and optical flow [3, 18], mid-level tasks such as depth/normal recovery [4, 19, 20, 60, 68], and high-level tasks such as keypoint prediction [28, 58], object detection [33], and semantic segmentation [13, 22, 31, 48, 52, 61].", "startOffset": 267, "endOffset": 291}, {"referenceID": 60, "context": "These include low-level tasks such as edge detection [16, 50, 71] and optical flow [3, 18], mid-level tasks such as depth/normal recovery [4, 19, 20, 60, 68], and high-level tasks such as keypoint prediction [28, 58], object detection [33], and semantic segmentation [13, 22, 31, 48, 52, 61].", "startOffset": 267, "endOffset": 291}, {"referenceID": 12, "context": "Neural networks with convolutional output predictions, also called Fully Convolutional Networks (FCNs) [13, 48, 51, 57], appear to be a promising architecture in this direction.", "startOffset": 103, "endOffset": 119}, {"referenceID": 47, "context": "Neural networks with convolutional output predictions, also called Fully Convolutional Networks (FCNs) [13, 48, 51, 57], appear to be a promising architecture in this direction.", "startOffset": 103, "endOffset": 119}, {"referenceID": 50, "context": "Neural networks with convolutional output predictions, also called Fully Convolutional Networks (FCNs) [13, 48, 51, 57], appear to be a promising architecture in this direction.", "startOffset": 103, "endOffset": 119}, {"referenceID": 56, "context": "Neural networks with convolutional output predictions, also called Fully Convolutional Networks (FCNs) [13, 48, 51, 57], appear to be a promising architecture in this direction.", "startOffset": 103, "endOffset": 119}, {"referenceID": 8, "context": ") [9].", "startOffset": 2, "endOffset": 5}, {"referenceID": 42, "context": "samples is random permutation of the training data, which can significantly improve learnability [43].", "startOffset": 97, "endOffset": 101}, {"referenceID": 34, "context": "It is well known that pixels in a given image are highly correlated and not independent [35].", "startOffset": 88, "endOffset": 92}, {"referenceID": 47, "context": "with deconvolution [48, 71] or interpolation [13]), sampling only requires ondemand computation of a sparse set of sampled features, therefore saving time and space during training (see Section 3).", "startOffset": 19, "endOffset": 27}, {"referenceID": 70, "context": "with deconvolution [48, 71] or interpolation [13]), sampling only requires ondemand computation of a sparse set of sampled features, therefore saving time and space during training (see Section 3).", "startOffset": 19, "endOffset": 27}, {"referenceID": 12, "context": "with deconvolution [48, 71] or interpolation [13]), sampling only requires ondemand computation of a sparse set of sampled features, therefore saving time and space during training (see Section 3).", "startOffset": 45, "endOffset": 49}, {"referenceID": 30, "context": "The reduction in space and time allows us to explore more advanced architectures than prior work [31, 48], which tend to use pixel-wise linear predictors defined over multi-scale \u201chypercolumn\u201d features extracted from multiple layers of the network.", "startOffset": 97, "endOffset": 105}, {"referenceID": 47, "context": "The reduction in space and time allows us to explore more advanced architectures than prior work [31, 48], which tend to use pixel-wise linear predictors defined over multi-scale \u201chypercolumn\u201d features extracted from multiple layers of the network.", "startOffset": 97, "endOffset": 105}, {"referenceID": 70, "context": "A good example is edge detection, where only 10% of the ground truth are positive [71].", "startOffset": 82, "endOffset": 86}, {"referenceID": 26, "context": "Inspired by [27], we demonstrate that a biased sample toward positives can greatly help the performance.", "startOffset": 12, "endOffset": 16}, {"referenceID": 1, "context": "We show state-of-the-art results for edge detection on BSDS [2], out-performing the holistically-nested edge detection (HED) system of Xie et al.", "startOffset": 60, "endOffset": 63}, {"referenceID": 70, "context": "[71].", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "We also show competitive results for semantic segmentation on the PASCAL VOC-2012 [21], and more challenging PASCAL Context dataset where we achieve state of the art performance without contextual post processing [13].", "startOffset": 82, "endOffset": 86}, {"referenceID": 12, "context": "We also show competitive results for semantic segmentation on the PASCAL VOC-2012 [21], and more challenging PASCAL Context dataset where we achieve state of the art performance without contextual post processing [13].", "startOffset": 213, "endOffset": 217}, {"referenceID": 3, "context": "Finally, [4] showed state-of-the-art performance for surface normal estimation using the same architecture.", "startOffset": 9, "endOffset": 12}, {"referenceID": 0, "context": "There is rich prior art in modeling this prediction problem using hand-designed features (representative examples include [1, 11, 16, 29, 45, 54, 59, 61, 65, 66, 72]).", "startOffset": 122, "endOffset": 165}, {"referenceID": 10, "context": "There is rich prior art in modeling this prediction problem using hand-designed features (representative examples include [1, 11, 16, 29, 45, 54, 59, 61, 65, 66, 72]).", "startOffset": 122, "endOffset": 165}, {"referenceID": 15, "context": "There is rich prior art in modeling this prediction problem using hand-designed features (representative examples include [1, 11, 16, 29, 45, 54, 59, 61, 65, 66, 72]).", "startOffset": 122, "endOffset": 165}, {"referenceID": 28, "context": "There is rich prior art in modeling this prediction problem using hand-designed features (representative examples include [1, 11, 16, 29, 45, 54, 59, 61, 65, 66, 72]).", "startOffset": 122, "endOffset": 165}, {"referenceID": 44, "context": "There is rich prior art in modeling this prediction problem using hand-designed features (representative examples include [1, 11, 16, 29, 45, 54, 59, 61, 65, 66, 72]).", "startOffset": 122, "endOffset": 165}, {"referenceID": 53, "context": "There is rich prior art in modeling this prediction problem using hand-designed features (representative examples include [1, 11, 16, 29, 45, 54, 59, 61, 65, 66, 72]).", "startOffset": 122, "endOffset": 165}, {"referenceID": 58, "context": "There is rich prior art in modeling this prediction problem using hand-designed features (representative examples include [1, 11, 16, 29, 45, 54, 59, 61, 65, 66, 72]).", "startOffset": 122, "endOffset": 165}, {"referenceID": 60, "context": "There is rich prior art in modeling this prediction problem using hand-designed features (representative examples include [1, 11, 16, 29, 45, 54, 59, 61, 65, 66, 72]).", "startOffset": 122, "endOffset": 165}, {"referenceID": 64, "context": "There is rich prior art in modeling this prediction problem using hand-designed features (representative examples include [1, 11, 16, 29, 45, 54, 59, 61, 65, 66, 72]).", "startOffset": 122, "endOffset": 165}, {"referenceID": 65, "context": "There is rich prior art in modeling this prediction problem using hand-designed features (representative examples include [1, 11, 16, 29, 45, 54, 59, 61, 65, 66, 72]).", "startOffset": 122, "endOffset": 165}, {"referenceID": 71, "context": "There is rich prior art in modeling this prediction problem using hand-designed features (representative examples include [1, 11, 16, 29, 45, 54, 59, 61, 65, 66, 72]).", "startOffset": 122, "endOffset": 165}, {"referenceID": 50, "context": "The family of fully-convolutional and skip networks [51, 57] are illustrative examples that have been successfully applied to, e.", "startOffset": 52, "endOffset": 60}, {"referenceID": 56, "context": "The family of fully-convolutional and skip networks [51, 57] are illustrative examples that have been successfully applied to, e.", "startOffset": 52, "endOffset": 60}, {"referenceID": 70, "context": ", edge detection [71] and semantic segmentation [10, 13, 22, 24, 48, 46, 52, 55, 56].", "startOffset": 17, "endOffset": 21}, {"referenceID": 9, "context": ", edge detection [71] and semantic segmentation [10, 13, 22, 24, 48, 46, 52, 55, 56].", "startOffset": 48, "endOffset": 84}, {"referenceID": 12, "context": ", edge detection [71] and semantic segmentation [10, 13, 22, 24, 48, 46, 52, 55, 56].", "startOffset": 48, "endOffset": 84}, {"referenceID": 21, "context": ", edge detection [71] and semantic segmentation [10, 13, 22, 24, 48, 46, 52, 55, 56].", "startOffset": 48, "endOffset": 84}, {"referenceID": 23, "context": ", edge detection [71] and semantic segmentation [10, 13, 22, 24, 48, 46, 52, 55, 56].", "startOffset": 48, "endOffset": 84}, {"referenceID": 47, "context": ", edge detection [71] and semantic segmentation [10, 13, 22, 24, 48, 46, 52, 55, 56].", "startOffset": 48, "endOffset": 84}, {"referenceID": 45, "context": ", edge detection [71] and semantic segmentation [10, 13, 22, 24, 48, 46, 52, 55, 56].", "startOffset": 48, "endOffset": 84}, {"referenceID": 51, "context": ", edge detection [71] and semantic segmentation [10, 13, 22, 24, 48, 46, 52, 55, 56].", "startOffset": 48, "endOffset": 84}, {"referenceID": 54, "context": ", edge detection [71] and semantic segmentation [10, 13, 22, 24, 48, 46, 52, 55, 56].", "startOffset": 48, "endOffset": 84}, {"referenceID": 55, "context": ", edge detection [71] and semantic segmentation [10, 13, 22, 24, 48, 46, 52, 55, 56].", "startOffset": 48, "endOffset": 84}, {"referenceID": 12, "context": ", bilateral smoothing with fully-connected Gaussian CRFs [13, 40, 74] or bilateral solvers [5], dilated spatial convolutions [73], LSTMs [10], and convolutional pseudo priors [70].", "startOffset": 57, "endOffset": 69}, {"referenceID": 39, "context": ", bilateral smoothing with fully-connected Gaussian CRFs [13, 40, 74] or bilateral solvers [5], dilated spatial convolutions [73], LSTMs [10], and convolutional pseudo priors [70].", "startOffset": 57, "endOffset": 69}, {"referenceID": 73, "context": ", bilateral smoothing with fully-connected Gaussian CRFs [13, 40, 74] or bilateral solvers [5], dilated spatial convolutions [73], LSTMs [10], and convolutional pseudo priors [70].", "startOffset": 57, "endOffset": 69}, {"referenceID": 4, "context": ", bilateral smoothing with fully-connected Gaussian CRFs [13, 40, 74] or bilateral solvers [5], dilated spatial convolutions [73], LSTMs [10], and convolutional pseudo priors [70].", "startOffset": 91, "endOffset": 94}, {"referenceID": 72, "context": ", bilateral smoothing with fully-connected Gaussian CRFs [13, 40, 74] or bilateral solvers [5], dilated spatial convolutions [73], LSTMs [10], and convolutional pseudo priors [70].", "startOffset": 125, "endOffset": 129}, {"referenceID": 9, "context": ", bilateral smoothing with fully-connected Gaussian CRFs [13, 40, 74] or bilateral solvers [5], dilated spatial convolutions [73], LSTMs [10], and convolutional pseudo priors [70].", "startOffset": 137, "endOffset": 141}, {"referenceID": 69, "context": ", bilateral smoothing with fully-connected Gaussian CRFs [13, 40, 74] or bilateral solvers [5], dilated spatial convolutions [73], LSTMs [10], and convolutional pseudo priors [70].", "startOffset": 175, "endOffset": 179}, {"referenceID": 14, "context": "Because such features may miss low-level details, numerous approaches have built predictors based on multiscale features extracted from multiple layers of a CNN [15, 19, 20, 22, 56, 68].", "startOffset": 161, "endOffset": 185}, {"referenceID": 18, "context": "Because such features may miss low-level details, numerous approaches have built predictors based on multiscale features extracted from multiple layers of a CNN [15, 19, 20, 22, 56, 68].", "startOffset": 161, "endOffset": 185}, {"referenceID": 19, "context": "Because such features may miss low-level details, numerous approaches have built predictors based on multiscale features extracted from multiple layers of a CNN [15, 19, 20, 22, 56, 68].", "startOffset": 161, "endOffset": 185}, {"referenceID": 21, "context": "Because such features may miss low-level details, numerous approaches have built predictors based on multiscale features extracted from multiple layers of a CNN [15, 19, 20, 22, 56, 68].", "startOffset": 161, "endOffset": 185}, {"referenceID": 55, "context": "Because such features may miss low-level details, numerous approaches have built predictors based on multiscale features extracted from multiple layers of a CNN [15, 19, 20, 22, 56, 68].", "startOffset": 161, "endOffset": 185}, {"referenceID": 67, "context": "Because such features may miss low-level details, numerous approaches have built predictors based on multiscale features extracted from multiple layers of a CNN [15, 19, 20, 22, 56, 68].", "startOffset": 161, "endOffset": 185}, {"referenceID": 30, "context": "Hariharan et al [31] use the evocative term \u201chypercolumns\u201d to refer to features extracted from multiple layers that correspond to the same pixel.", "startOffset": 16, "endOffset": 20}, {"referenceID": 47, "context": "Prior techniques for up-sampling include shift and stitch [48], converting convolutional filters to dilation operations [13] (inspired by the algorithme \u00e0 trous [49]), and deconvolution/unpooling [24, 48, 55].", "startOffset": 58, "endOffset": 62}, {"referenceID": 12, "context": "Prior techniques for up-sampling include shift and stitch [48], converting convolutional filters to dilation operations [13] (inspired by the algorithme \u00e0 trous [49]), and deconvolution/unpooling [24, 48, 55].", "startOffset": 120, "endOffset": 124}, {"referenceID": 48, "context": "Prior techniques for up-sampling include shift and stitch [48], converting convolutional filters to dilation operations [13] (inspired by the algorithme \u00e0 trous [49]), and deconvolution/unpooling [24, 48, 55].", "startOffset": 161, "endOffset": 165}, {"referenceID": 23, "context": "Prior techniques for up-sampling include shift and stitch [48], converting convolutional filters to dilation operations [13] (inspired by the algorithme \u00e0 trous [49]), and deconvolution/unpooling [24, 48, 55].", "startOffset": 196, "endOffset": 208}, {"referenceID": 47, "context": "Prior techniques for up-sampling include shift and stitch [48], converting convolutional filters to dilation operations [13] (inspired by the algorithme \u00e0 trous [49]), and deconvolution/unpooling [24, 48, 55].", "startOffset": 196, "endOffset": 208}, {"referenceID": 54, "context": "Prior techniques for up-sampling include shift and stitch [48], converting convolutional filters to dilation operations [13] (inspired by the algorithme \u00e0 trous [49]), and deconvolution/unpooling [24, 48, 55].", "startOffset": 196, "endOffset": 208}, {"referenceID": 47, "context": "FCNs [48] point out that linear prediction can be efficiently implemented in a coarse-to-fine manner by upsampling coarse predictions (with deconvolution) rather than upsampling coarse features.", "startOffset": 5, "endOffset": 9}, {"referenceID": 12, "context": "DeepLab [13] incorporates filter dilation and applies similar deconvolution and linear-weighted fusion, in addition to reducing the dimensionality of the fully-connected layers to reduce memory footprint.", "startOffset": 8, "endOffset": 12}, {"referenceID": 45, "context": "ParseNet [46] added spatial context for a layer\u2019s responses by average pooling the feature responses, followed by normalization and concatenation.", "startOffset": 9, "endOffset": 13}, {"referenceID": 70, "context": "HED [71] output edge predictions from intermediates layers, which are deeply supervised, and fuses the predictions by linear weighting.", "startOffset": 4, "endOffset": 8}, {"referenceID": 51, "context": "Importantly, [52] and [22] are noteable exceptions to the linear trend in that non-linear predictors g are used.", "startOffset": 13, "endOffset": 17}, {"referenceID": 21, "context": "Importantly, [52] and [22] are noteable exceptions to the linear trend in that non-linear predictors g are used.", "startOffset": 22, "endOffset": 26}, {"referenceID": 51, "context": "This does pose difficulties during learning - [52] precomputes and stores superpixel feature map due to memory constraints, and so cannot be trained end-to-end.", "startOffset": 46, "endOffset": 50}, {"referenceID": 8, "context": "We refer the reader to [9] for an excellent introduction.", "startOffset": 23, "endOffset": 26}, {"referenceID": 13, "context": "Though naturally a sequential algorithm that processes one data example at a time, much recent work focuses on mini-batch methods that can exploit parallelism in GPU architectures [14] or clusters [14].", "startOffset": 180, "endOffset": 184}, {"referenceID": 13, "context": "Though naturally a sequential algorithm that processes one data example at a time, much recent work focuses on mini-batch methods that can exploit parallelism in GPU architectures [14] or clusters [14].", "startOffset": 197, "endOffset": 201}, {"referenceID": 7, "context": "One general theme is efficient online approximation of second-order methods [8], which can model correlations between input features.", "startOffset": 76, "endOffset": 79}, {"referenceID": 35, "context": "Batch normalization [36] computes correlation statistics between samples in a batch, producing noticeable improvements in convergence speed.", "startOffset": 20, "endOffset": 24}, {"referenceID": 6, "context": "We learn a nonlinear predictor f\u03b8,p = g(hp) implemented as a multi-layer perception (MLP) [7] defined over hypercolumn features.", "startOffset": 90, "endOffset": 93}, {"referenceID": 37, "context": "To compute this set, we introduce a new multi-scale sampling layer (in Caffe [38]) that directly extracts the 4 convolutional features corresponding to the 4 discrete locations in ci closest to pixel position pj , and then computes ci(pj) via bilinear interpolation \u201con the fly\u201d.", "startOffset": 77, "endOffset": 81}, {"referenceID": 47, "context": "Approaches based on FCN [48] include features for all pixels from an image in a mini-batch.", "startOffset": 24, "endOffset": 28}, {"referenceID": 35, "context": "batch normalization [36], residual learning [32], etc).", "startOffset": 20, "endOffset": 24}, {"referenceID": 31, "context": "batch normalization [36], residual learning [32], etc).", "startOffset": 44, "endOffset": 48}, {"referenceID": 30, "context": "Comparison with prior art: Unlike previous approaches (such as hypercolumns [31] and FCN [48]), our approach sub-samples hypercolumn features from convolutional layers without any up-sampling.", "startOffset": 76, "endOffset": 80}, {"referenceID": 47, "context": "Comparison with prior art: Unlike previous approaches (such as hypercolumns [31] and FCN [48]), our approach sub-samples hypercolumn features from convolutional layers without any up-sampling.", "startOffset": 89, "endOffset": 93}, {"referenceID": 70, "context": "For contrast, Xie and Tu [71] required significant modifications (such as deep supervision) to make FCNs applicable for low-level edge detection.", "startOffset": 25, "endOffset": 29}, {"referenceID": 47, "context": "[48] argued against sampling and showed how the convergence is slowed when sampling few pixels.", "startOffset": 0, "endOffset": 4}, {"referenceID": 30, "context": "Not only the convergence, a linear predictor may require normalization/scaling, and careful hand-tuning for different tasks (as done in [31, 48]) as features across different convolutional layers lie in different dynamic ranges.", "startOffset": 136, "endOffset": 144}, {"referenceID": 47, "context": "Not only the convergence, a linear predictor may require normalization/scaling, and careful hand-tuning for different tasks (as done in [31, 48]) as features across different convolutional layers lie in different dynamic ranges.", "startOffset": 136, "endOffset": 144}, {"referenceID": 52, "context": "We show state-of-the-art1 results on PASCAL-Context [53] (without requiring contextual postprocessing), competitive performance on PASCAL VOC 2012 [21], and advance the state of the art on the BSDS benchmark [2].", "startOffset": 52, "endOffset": 56}, {"referenceID": 20, "context": "We show state-of-the-art1 results on PASCAL-Context [53] (without requiring contextual postprocessing), competitive performance on PASCAL VOC 2012 [21], and advance the state of the art on the BSDS benchmark [2].", "startOffset": 147, "endOffset": 151}, {"referenceID": 1, "context": "We show state-of-the-art1 results on PASCAL-Context [53] (without requiring contextual postprocessing), competitive performance on PASCAL VOC 2012 [21], and advance the state of the art on the BSDS benchmark [2].", "startOffset": 208, "endOffset": 211}, {"referenceID": 12, "context": "Default network: As with other methods [13, 48, 71], we fine-tune a VGG-16 network [63].", "startOffset": 39, "endOffset": 51}, {"referenceID": 47, "context": "Default network: As with other methods [13, 48, 71], we fine-tune a VGG-16 network [63].", "startOffset": 39, "endOffset": 51}, {"referenceID": 70, "context": "Default network: As with other methods [13, 48, 71], we fine-tune a VGG-16 network [63].", "startOffset": 39, "endOffset": 51}, {"referenceID": 62, "context": "Default network: As with other methods [13, 48, 71], we fine-tune a VGG-16 network [63].", "startOffset": 83, "endOffset": 87}, {"referenceID": 3, "context": "Refer to [4] for more details.", "startOffset": 9, "endOffset": 12}, {"referenceID": 47, "context": "Following [48], we transform the last two fc layers to convolutional filters2, and add them to the set of convolutional features that can be aggregated into our multi-scale hypercolumn descriptor.", "startOffset": 10, "endOffset": 14}, {"referenceID": 40, "context": "We define a MLP over hypercolumn features with 3 fully-connected (fc) layers of size 4, 096 followed by ReLU [41] activations, where the last layer outputs predictions for K classes (with a softmax/cross-entropy loss).", "startOffset": 109, "endOffset": 113}, {"referenceID": 37, "context": "Default training: For all the experiments we used the publicly available Caffe library [38].", "startOffset": 87, "endOffset": 91}, {"referenceID": 63, "context": "We make use of ImageNet-pretrained values for all convolutional layers, but train our MLP layers \u201cfrom scratch\u201d with Gaussian initialization (\u03c3 = 10\u22123) and dropout [64].", "startOffset": 164, "endOffset": 168}, {"referenceID": 1, "context": "The PASCAL-Context dataset [2] augments the original sparse set of PASCAL VOC 2010 segmentation annotations [21] (defined for 20 categories) to pixel labels for the whole scene.", "startOffset": 27, "endOffset": 30}, {"referenceID": 20, "context": "The PASCAL-Context dataset [2] augments the original sparse set of PASCAL VOC 2010 segmentation annotations [21] (defined for 20 categories) to pixel labels for the whole scene.", "startOffset": 108, "endOffset": 112}, {"referenceID": 1, "context": "Though all the analysis in this paper are shown on PASCAL Context dataset [2], we also evaluated our approach on the standard PASCAL VOC-2012 dataset [21] to compare with a wide variety of approaches.", "startOffset": 74, "endOffset": 77}, {"referenceID": 20, "context": "Though all the analysis in this paper are shown on PASCAL Context dataset [2], we also evaluated our approach on the standard PASCAL VOC-2012 dataset [21] to compare with a wide variety of approaches.", "startOffset": 150, "endOffset": 154}, {"referenceID": 47, "context": "We show qualitative outputs in Figure 3 and compare against FCN-8s [48].", "startOffset": 67, "endOffset": 71}, {"referenceID": 30, "context": "Most existing architectures combining different conv layers [31, 48] are equivalent to a linear model (fc1), while networks that operate on modified features (e.", "startOffset": 60, "endOffset": 68}, {"referenceID": 47, "context": "Most existing architectures combining different conv layers [31, 48] are equivalent to a linear model (fc1), while networks that operate on modified features (e.", "startOffset": 60, "endOffset": 68}, {"referenceID": 45, "context": "normalization [46], rescaling [6]) can be viewed as employing a single (designed) intermediate layer.", "startOffset": 14, "endOffset": 18}, {"referenceID": 5, "context": "normalization [46], rescaling [6]) can be viewed as employing a single (designed) intermediate layer.", "startOffset": 30, "endOffset": 33}, {"referenceID": 47, "context": "This is consistent with [48]\u2019s observation that random sampling of patches during training can slow convergence.", "startOffset": 24, "endOffset": 28}, {"referenceID": 47, "context": "We posit that such careful initialization and training schemes (like stage-wise training [48], `2 normalization [46] or deep supervision [71]) are needed to train such networks.", "startOffset": 89, "endOffset": 93}, {"referenceID": 45, "context": "We posit that such careful initialization and training schemes (like stage-wise training [48], `2 normalization [46] or deep supervision [71]) are needed to train such networks.", "startOffset": 112, "endOffset": 116}, {"referenceID": 70, "context": "We posit that such careful initialization and training schemes (like stage-wise training [48], `2 normalization [46] or deep supervision [71]) are needed to train such networks.", "startOffset": 137, "endOffset": 141}, {"referenceID": 45, "context": "Past work [46] argues that convolutional features from different", "startOffset": 10, "endOffset": 14}, {"referenceID": 63, "context": "We can see that with more dimensions the network tends to learn better, potentially because it can capture more information (and with drop-out alleviating over-fitting [64]).", "startOffset": 168, "endOffset": 172}, {"referenceID": 47, "context": "For example, a single-scale FCN-32s [48], without any low-level layers, can already achieve 35.", "startOffset": 36, "endOffset": 40}, {"referenceID": 46, "context": "FCN-8s [47] 46.", "startOffset": 7, "endOffset": 11}, {"referenceID": 47, "context": "5 FCN-8s [48] 50.", "startOffset": 9, "endOffset": 13}, {"referenceID": 11, "context": "8 DeepLab (v2 [12]) - 37.", "startOffset": 14, "endOffset": 18}, {"referenceID": 11, "context": "DeepLab (v2) + CRF [12] - 39.", "startOffset": 19, "endOffset": 23}, {"referenceID": 73, "context": "6 CRF-RNN [74] - 39.", "startOffset": 10, "endOffset": 14}, {"referenceID": 45, "context": "3 ParseNet [46] - 40.", "startOffset": 11, "endOffset": 15}, {"referenceID": 69, "context": "4 ConvPP-8 [70] - 41.", "startOffset": 11, "endOffset": 15}, {"referenceID": 11, "context": "Note that while most recent approaches spatial context postprocessing [12, 46, 70, 74], we focus on the FCN [48] per-pixel predictor as most approaches are its descendants.", "startOffset": 70, "endOffset": 86}, {"referenceID": 45, "context": "Note that while most recent approaches spatial context postprocessing [12, 46, 70, 74], we focus on the FCN [48] per-pixel predictor as most approaches are its descendants.", "startOffset": 70, "endOffset": 86}, {"referenceID": 69, "context": "Note that while most recent approaches spatial context postprocessing [12, 46, 70, 74], we focus on the FCN [48] per-pixel predictor as most approaches are its descendants.", "startOffset": 70, "endOffset": 86}, {"referenceID": 73, "context": "Note that while most recent approaches spatial context postprocessing [12, 46, 70, 74], we focus on the FCN [48] per-pixel predictor as most approaches are its descendants.", "startOffset": 70, "endOffset": 86}, {"referenceID": 47, "context": "Note that while most recent approaches spatial context postprocessing [12, 46, 70, 74], we focus on the FCN [48] per-pixel predictor as most approaches are its descendants.", "startOffset": 108, "endOffset": 112}, {"referenceID": 47, "context": "Even with reduced scale, we are able to obtain a similar IU achieved by FCN-8s [48], without any extra modeling of context [13, 46, 70, 74].", "startOffset": 79, "endOffset": 83}, {"referenceID": 12, "context": "Even with reduced scale, we are able to obtain a similar IU achieved by FCN-8s [48], without any extra modeling of context [13, 46, 70, 74].", "startOffset": 123, "endOffset": 139}, {"referenceID": 45, "context": "Even with reduced scale, we are able to obtain a similar IU achieved by FCN-8s [48], without any extra modeling of context [13, 46, 70, 74].", "startOffset": 123, "endOffset": 139}, {"referenceID": 69, "context": "Even with reduced scale, we are able to obtain a similar IU achieved by FCN-8s [48], without any extra modeling of context [13, 46, 70, 74].", "startOffset": 123, "endOffset": 139}, {"referenceID": 73, "context": "Even with reduced scale, we are able to obtain a similar IU achieved by FCN-8s [48], without any extra modeling of context [13, 46, 70, 74].", "startOffset": 123, "endOffset": 139}, {"referenceID": 12, "context": "5\u00d7 its original size), whereas most prior work [13, 46, 48, 74] use multiple scales from full-resolution images.", "startOffset": 47, "endOffset": 63}, {"referenceID": 45, "context": "5\u00d7 its original size), whereas most prior work [13, 46, 48, 74] use multiple scales from full-resolution images.", "startOffset": 47, "endOffset": 63}, {"referenceID": 47, "context": "5\u00d7 its original size), whereas most prior work [13, 46, 48, 74] use multiple scales from full-resolution images.", "startOffset": 47, "endOffset": 63}, {"referenceID": 73, "context": "5\u00d7 its original size), whereas most prior work [13, 46, 48, 74] use multiple scales from full-resolution images.", "startOffset": 47, "endOffset": 63}, {"referenceID": 11, "context": "Note our pixel-wise predictions do not make use of contextual postprocessing (even outperforming some methods that postprocesses FCNs to do so [12, 74]).", "startOffset": 143, "endOffset": 151}, {"referenceID": 73, "context": "Note our pixel-wise predictions do not make use of contextual postprocessing (even outperforming some methods that postprocesses FCNs to do so [12, 74]).", "startOffset": 143, "endOffset": 151}, {"referenceID": 47, "context": "We compared our speed, model size, and memory usage of our network to FCN [48] (same architecture) in Table 4.", "startOffset": 74, "endOffset": 78}, {"referenceID": 30, "context": "7% for Hypercolumns [31], 62% for FCN [48], 67% for DeepLab (without CRF) [13] etc.", "startOffset": 20, "endOffset": 24}, {"referenceID": 47, "context": "7% for Hypercolumns [31], 62% for FCN [48], 67% for DeepLab (without CRF) [13] etc.", "startOffset": 38, "endOffset": 42}, {"referenceID": 12, "context": "7% for Hypercolumns [31], 62% for FCN [48], 67% for DeepLab (without CRF) [13] etc.", "startOffset": 74, "endOffset": 78}, {"referenceID": 51, "context": "Our performance on VOC-2012 is similar to Mostajabi et al [52] despite the fact we use information from only 6 layers while they used information from all the layers.", "startOffset": 58, "endOffset": 62}, {"referenceID": 51, "context": "Finally, the use of super-pixels in [52] inhibit capturing detailed segmentation mask (and rather gives \u201cblobby\u201d output), and it is computationally less-tractable to use their approach for per-pixel optimization as information for each pixel would be required to be stored on disk.", "startOffset": 36, "endOffset": 40}, {"referenceID": 3, "context": "PixelNet architecture was first proposed in our work [4] on 2D-to-3D model alignment via surface normal estimation.", "startOffset": 53, "endOffset": 56}, {"referenceID": 3, "context": "Here we extract some of the results from [4] to show the effectiveness of this architecture for the mid-level task of", "startOffset": 41, "endOffset": 44}, {"referenceID": 47, "context": "FCN-32s [48] 4,096 1 50,176 2,056 570 20.", "startOffset": 8, "endOffset": 12}, {"referenceID": 47, "context": "0 FCN-8s [48] 4,864 1 50,176 2,010 518 19.", "startOffset": 9, "endOffset": 13}, {"referenceID": 47, "context": "We compared our network with FCN [48] where a deconvolution layer is used to upsample the result in various settings.", "startOffset": 33, "endOffset": 37}, {"referenceID": 47, "context": "Note that besides FCN-8s and FCN-32s here we first compute the upsampled feature map, then apply the classifiers for FCN [48] due to the additional fc layers.", "startOffset": 121, "endOffset": 125}, {"referenceID": 24, "context": "[25] 35.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "E-F (AlexNet) [19] 23.", "startOffset": 14, "endOffset": 18}, {"referenceID": 18, "context": "E-F (VGG-16) [19] 20.", "startOffset": 13, "endOffset": 17}, {"referenceID": 3, "context": "Ours [4] 19.", "startOffset": 5, "endOffset": 8}, {"referenceID": 3, "context": "NYUv2 surface normal prediction from [4].", "startOffset": 37, "endOffset": 40}, {"referenceID": 61, "context": "The NYU Depth v2 dataset [62] is used to evaluate the surface normal maps.", "startOffset": 25, "endOffset": 29}, {"referenceID": 24, "context": "[25] is used to compare our approach [4] against prior work [19, 25].", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "[25] is used to compare our approach [4] against prior work [19, 25].", "startOffset": 37, "endOffset": 40}, {"referenceID": 18, "context": "[25] is used to compare our approach [4] against prior work [19, 25].", "startOffset": 60, "endOffset": 68}, {"referenceID": 24, "context": "[25] is used to compare our approach [4] against prior work [19, 25].", "startOffset": 60, "endOffset": 68}, {"referenceID": 41, "context": "[42] as ground truth (Note that these normals are computed from depth data obtained using kinect).", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "Table 5 compares our approach [4] with previous state-of-the-art approaches.", "startOffset": 30, "endOffset": 33}, {"referenceID": 3, "context": "Please refer to [4] for more details on surface normal estimation.", "startOffset": 16, "endOffset": 19}, {"referenceID": 1, "context": "The standard dataset for edge detection is BSDS500 [2], which consists of 200 training, 100 validation, and 200 testing images.", "startOffset": 51, "endOffset": 54}, {"referenceID": 70, "context": "We use the same augmented data (rotation, flipping, totaling 9600 images without resizing) used to train the state-of-the-art Holistically-nested edge detector (HED) [71].", "startOffset": 166, "endOffset": 170}, {"referenceID": 1, "context": "Human [2] .", "startOffset": 6, "endOffset": 9}, {"referenceID": 22, "context": "580 Felz-Hutt [23] .", "startOffset": 14, "endOffset": 18}, {"referenceID": 1, "context": "gPb-owt-ucm [2] .", "startOffset": 12, "endOffset": 15}, {"referenceID": 43, "context": "696 Sketch Tokens [44] .", "startOffset": 18, "endOffset": 22}, {"referenceID": 68, "context": "780 SCG [69] .", "startOffset": 8, "endOffset": 12}, {"referenceID": 36, "context": "PMI [37] .", "startOffset": 4, "endOffset": 8}, {"referenceID": 16, "context": "SE-Var [17] .", "startOffset": 7, "endOffset": 11}, {"referenceID": 29, "context": "803 OEF [30] .", "startOffset": 8, "endOffset": 12}, {"referenceID": 38, "context": "DeepNets [39] .", "startOffset": 9, "endOffset": 13}, {"referenceID": 33, "context": "758 CSCNN [34] .", "startOffset": 10, "endOffset": 14}, {"referenceID": 70, "context": "798 HED [71] .", "startOffset": 8, "endOffset": 12}, {"referenceID": 70, "context": "833 HED [71] (Updated version) .", "startOffset": 8, "endOffset": 12}, {"referenceID": 70, "context": "811 HED merging [71] (Updated version) .", "startOffset": 16, "endOffset": 20}, {"referenceID": 1, "context": "Evaluation on BSDS [2].", "startOffset": 19, "endOffset": 22}, {"referenceID": 70, "context": "Due to the highly skewed class distribution, we also normalized the gradients for positives and negatives in each batch (as in [71]).", "startOffset": 127, "endOffset": 131}, {"referenceID": 15, "context": "We apply standard non-maximal suppression and thinning technique using the code provided by [16].", "startOffset": 92, "endOffset": 96}, {"referenceID": 47, "context": "Whereas uniform sampling sufficed for semantic segmentation [48], we found the extreme rarity of positive pixels in edge detection required focused sampling of positives.", "startOffset": 60, "endOffset": 64}, {"referenceID": 25, "context": "Two obvious approaches are uniform and balanced sampling with an equal ratio of positives and negatives (shown to be useful for object detection [26]).", "startOffset": 145, "endOffset": 149}, {"referenceID": 1, "context": "Results on BSDS [2].", "startOffset": 16, "endOffset": 19}, {"referenceID": 70, "context": "5Note that simple class balancing [71] in each batch is already used, so the performance gain is unlikely from label re-balancing.", "startOffset": 34, "endOffset": 38}, {"referenceID": 70, "context": "Notice that our approach generates more semantic edges for zebra, eagle, and giraffe compared to HED [71].", "startOffset": 101, "endOffset": 105}, {"referenceID": 3, "context": "art accuracy on diverse high-level, mid-level [4], and lowlevel tasks.", "startOffset": 46, "endOffset": 49}, {"referenceID": 19, "context": "6We ran a vanilla version of our approach for depth estimation, and achieved near state-of-the-art performance (on NYU-v2 depth dataset) with a simple scale-invariant loss function [20].", "startOffset": 181, "endOffset": 185}, {"referenceID": 3, "context": "mation [4], and edge datasets.", "startOffset": 7, "endOffset": 10}], "year": 2016, "abstractText": "We explore architectures for general pixel-level prediction problems, from low-level edge detection to mid-level surface normal estimation [4] to high-level semantic segmentation. Convolutional predictors, such as the fullyconvolutional network (FCN), have achieved remarkable success by exploiting the spatial redundancy of neighboring pixels through convolutional processing. Though computationally efficient, we point out that such approaches are not statistically efficient during learning precisely because spatial redundancy limits the information learned from neighboring pixels. We demonstrate that (1) stratified sampling allows us to add diversity during batch updates and (2) sampled multi-scale features allow us to explore more nonlinear predictors (multiple fully-connected layers followed by ReLU) that improve overall accuracy. Finally, our objective is to show how a architecture can get performance better than (or comparable to) the architectures designed for a particular task. Interestingly, our single architecture produces state-of-the-art results for semantic segmentation on PASCAL-Context, surface normal estimation [4] on NYUDv2 dataset, and edge detection on BSDS without contextual post-processing. * indicates equal contribution; first two authors listed in alphabetical order.", "creator": "LaTeX with hyperref package"}}}