{"id": "1609.06838", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Sep-2016", "title": "Deep-Learned Collision Avoidance Policy for Distributed Multi-Agent Navigation", "abstract": "High-speed, low-latency obstacle avoidance that is insensitive to sensor noise is essential for enabling multiple decentralized robots to function reliably in cluttered and dynamic environments. While other distributed multi-agent collision avoidance systems exist, these systems require online geometric optimization where tedious parameter tuning and perfect sensing are necessary.", "histories": [["v1", "Thu, 22 Sep 2016 07:05:56 GMT  (2126kb,D)", "https://arxiv.org/abs/1609.06838v1", null], ["v2", "Thu, 6 Jul 2017 07:41:45 GMT  (2244kb,D)", "http://arxiv.org/abs/1609.06838v2", null]], "reviews": [], "SUBJECTS": "cs.AI cs.CV cs.RO", "authors": ["pinxin long", "wenxi liu", "jia pan"], "accepted": false, "id": "1609.06838"}, "pdf": {"name": "1609.06838.pdf", "metadata": {"source": "CRF", "title": "Deep-Learned Collision Avoidance Policy for Distributed Multi-Agent Navigation", "authors": ["Pinxin Long", "Wenxi Liu", "Jia Pan"], "emails": ["pinxinlong@gmail.com)", "wenxi.liu@hotmail.com)", "pan@cityu.edu.hk)"], "sections": [{"heading": null, "text": "This is a way in which other distributed multi-agent collision avoidance systems exist, these systems require online geometric optimization where tedious parameters tuning and perfect sensor technology are essential to allow multiple decentralized robots to function reliably in crowded and dynamic environments. We present a novel end-to-end framework to generate reactive collision avoidance policies for efficient distributed multi-agent navigation. Our method formulates a navigation strategy for an agent as deep neural network mapping from the observed noisy sensor measurements to the agent's steering commands in terms of velocity motion. We train the network on a large amount of collision avoidance data collected by repeatedly running a multi-agent simulator with different parameters."}, {"heading": "II. RELATED WORK", "text": "In this section we give a brief overview of previous work on collision avoidance for multi-agent navigation and machine learning for multi-agent systems."}, {"heading": "A. Collision Avoidance for Multi-Agent Navigation", "text": "Many approaches have been proposed, including techniques based on potential fields [8], local fields with variable resolution [9], dynamic windows [10] and speed barriers [1], [2], [11]. These approaches include the Optimal Reciprocal Collision Avoidance (ORCA) navigation system, which is a successful speed-based approach to avoiding collisions with other moving agents and obstacles. ORCA is popular for its two properties in mass simulation and multiagent systems. Firstly, it provides a sufficient requirement for multiple robots to avoid collisions with each other and can therefore guarantee collision-free navigation; secondly, it is a fully distributed method where robots do not share knowledge and can therefore be easily scaled to handle large systems with many robots."}, {"heading": "B. Machine Learning for Multi-Agent Systems", "text": "The collaborative approach to multi-agent decision-making [13] - [16] proposed by Kretzschmar, formulated as the Multi-Agent Markov Decision Processes (MDP) problem, enables agents to learn a policy, i.e. mapping agent states to measures based on the rewards achieved when interacting with the environment. In these methods, each independent agent must build an MDP model using repeated offline simulation and then use model-based reinforcement learning to calculate an optimal policy. An online multi-agent policy adaptation approach is proposed by Godoy et al. [17], which is based on multi-armed bandits, who use an online learning framework to plan the space of preferred speeds and then project these speeds onto collision-free cities using ORCA, for example, their method still provides the perfect sensitivity assumption and requires parameter-controlled adaptation of ORCA strategies."}, {"heading": "III. PROBLEM FORMULATION", "text": "The multi-agent navigation problem can be formally defined as follows: We take as a set of n decision makers sharing a 2D environment consisting of obstacles. For simplicity, we assume that the geometric shape of each agent ai (1 \u2264 i \u2264 n) is modeled as a disc with a fixed radius rai. In addition, the dynamics of the agent ai is assumed to be holonomic, i.e. it can move in any direction in the 2D workspace. Each agent sets a continuous cycle of scanning and action with a timeframe. During each cycle, the agent ai calculates a local trajectory that starts from its current position in pai and has the slightest deviation from a preferred velocity vprefai. The preferred velocity speed is used to guide the agent toward its destination gai when achieving progress. In a scenario without static obstacles, vprefai can directly point the city to a static obstacle scene."}, {"heading": "IV. LEARNING-BASED COLLISION AVOIDANCE", "text": "We begin this section by testing the ORCA algorithm, which, with suitably tuned parameters, is capable of generating locally collision-free motion for multiple actors. Next, we describe in detail how the ORCA algorithm can be used to generate a large training dataset for learning a robust collision avoidance policy for a deep neural network."}, {"heading": "A. A Recap of ORCA", "text": "In short, ORCA performs two steps to determine a collision avoidance velocity v + ai for an agent ai. Firstly, it calculates a series of velocities that form the permitted velocity space for the agent, i.e. if the agent ai chooses a velocity within that space, it will not collide with other agents within a time horizon. The permitted velocity set is called ORCA\u03c4ai. Next, among these permitted velocities, the agent selects the collision avoidance velocity as the velocity that is within the permitted velocity range but comes closest to its current preferred velocity vprefai, i.e. v + ai = argmin v."}, {"heading": "B. Dataset", "text": "The formation of deep neural networks requires a considerable body of all agents moving around the city. [We have the data from the real world that we have in the real world]. [We have the data from the real world that we have in the real world and in the real world in the real world that we live in.] We have the data from the real world that we have in the real world. [We have the data from the real world that we have in the real world and in the real world in the real world that we live in.] We have the data from the real world that we have in the real world and in the real world. [We have the data from the real world that we have in the real world.] We do not have the absolute position of agents important for the realized collision. We then stamp their preferred velocity vprefA along a random direction. We generate a few agents within the radius NEIGHBORIST environment."}, {"heading": "C. Collision Avoidance Network", "text": "The hacu-eaJnlhsrdcnlhsAeae\u00fcgmnn nvo der eeisrsn-eaJnlhsdcnlhsAeaeetnlrsrgneaePnr-eaJnlhsrsdcnlhsrteeaeaeaeaeoiSrpnlhc ni der eeisn-eaeaeaeaeaJnlrmnlhsdcnlhsAeaeaeaeaeaeaeaeaeaeaeaeaeaeaeaeaeaeaeaeaeaeaeaeaeaeuuuuuuuuugnnlrmnlnlnln nln nI \"s,\" so the hsci-eaeaeaeaeaeaeaeaeaeaeaeaeaeaeeaeaeaeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee"}, {"heading": "V. EXPERIMENTS AND RESULTS", "text": "This section presents experiments and results of the proposed framework. We evaluated this framework in various simulated scenarios and compared it with ORCA. We also tested our method on a real multi-robot system."}, {"heading": "A. Experiment Setup", "text": "1) Scenarios: We have evaluated our learned strategies against six different scenarios with different numbers of agents (as shown in Figure 7). Note that the test scenarios have 3 obstacles and 1 obstacle have static obstacles that never appear in any data collection scenarios for the training of CANet. Furthermore, the trained politicians achieve the collision speed in a random manner, their performance is averaged over 20 simulations. We have compared the performance of the learned policy with the ORCA policy. Most parameters of the ORCA policy are set to achieve the same values as in the data generation for the learned policy (as in Section IV-B1), but we have some parameters to optimize the ORCA policy."}, {"heading": "B. Quantitative Comparisons", "text": "In Figures 9 and 10, we measure two metrics - the total travel time and the total distance travelled - to assess the performance of our approach and the ORCA. We can observe that the ORCA policy provides a better or comparable performance in terms of navigation time and length compared to the ORCA policy with PROTECTRADIUS = 0.5. In most scenarios, the ORCA policy with PROTECTRADIUS = 0.2 is shorter than the policy learned. This is because the ORCA policy with PROTECTRADIUS = 0.2 is very aggressive and allows a small safe margin during navigation, as shown in Table II. Both our learned policy and the ORCA policy with PROTECTRADIUS = 0.5 try to maintain a sufficiently large margin with related agents / obstacles."}, {"heading": "C. Generalization", "text": "An interesting phenomenon in the use of learned policy is that in a highly symmetrical scenario such as Circle, agents present certain cooperative behaviors because all agents apply the same learned policy. For example, Figure 1b shows cooperative rotation behavior, in which agents begin to rotate at the same rate when they are close to each other. Whereas for ORCA (as shown in Figure 1a), each agent passes the central area on its own without any collective behavior, and some agents make jerky movements. Good generalization ability is another remarkable feature of our methodology. The performance of learned policy in scenarios with static obstacles shows that it can be well generalized to deal with previously invisible situations. In addition, we also evaluate the learned policy in the Circle scenario with four different sized agents. Figure 12a, agents of the same size have identical paths because they follow the same strategy to avoid collision with each other."}, {"heading": "VI. CONCLUSION AND LIMITATIONS", "text": "This work is our first step towards a policy of reactive collision avoidance for efficient and safe multi-agent navigation. By carefully designing the data collection process and using an end-to-end learning framework, our method can learn a policy of deep neural networks for collision avoidance, which has an advantage over the state-of-the-art ORCA policy in terms of ease of use (no parameter optimization), success rate and navigation performance. In addition, although we are trained using data sets with only identical moving agents, our learned policy generalizes well to various invisible situations, including agents of different sizes and scenarios with static obstacles. The proposed method has some limitations. First, we are currently forming a vanilla multilayer perceptron as collision avoidance policy. As can be seen from the classification accuracy, the model does not fully match the training data (the accuracy of the training units is about 64%), so there is still great potential for adding a model of dynamic improvement while we do not have more training systems."}], "references": [{"title": "Reciprocal velocity obstacles for real-time multi-agent navigation", "author": ["J. Van den Berg", "M. Lin", "D. Manocha"], "venue": "IEEE International Conference on Robotics and Automation, 2008, pp. 1928\u20131935.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2008}, {"title": "The hybrid reciprocal velocity obstacle", "author": ["J. Snape", "J. van den Berg", "S.J. Guy", "D. Manocha"], "venue": "IEEE Transactions on Robotics, vol. 27, no. 4, pp. 696\u2013706, 2011.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2011}, {"title": "Multi-robot collision avoidance with localization uncertainty", "author": ["D. Hennes", "D. Claes", "W. Meeussen", "K. Tuyls"], "venue": "International Conference on Autonomous Agents and Multiagent Systems-Volume 1, 2012, pp. 147\u2013 154.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2012}, {"title": "Generalized reciprocal collision avoidance", "author": ["D. Bareiss", "J. van den Berg"], "venue": "The International Journal of Robotics Research, vol. 34, no. 12, pp. 1501\u20131514, 2015.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2015}, {"title": "Implicit coordination in crowded multi-agent navigation", "author": ["J. Godoy", "I. Karamouzas", "S.J. Guy", "M. Gini"], "venue": "Thirtieth AAAI Conference on Artificial Intelligence, 2016.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2016}, {"title": "Collision avoidance under bounded localization uncertainty", "author": ["D. Claes", "D. Hennes", "K. Tuyls", "W. Meeussen"], "venue": "2012 IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE, 2012, pp. 1192\u2013 1198.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2012}, {"title": "Potential field methods and their inherent limitations for mobile robot navigation", "author": ["Y. Koren", "J. Borenstein"], "venue": "IEEE International Conference on Robotics and Automation, 1991, pp. 1398\u20131404.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1991}, {"title": "Parallelized egocentric fields for autonomous navigation", "author": ["M. Kapadia", "S. Singh", "W. Hewlett", "G. Reinman", "P. Faloutsos"], "venue": "The Visual Computer, vol. 28, no. 12, pp. 1209\u20131227, 2012.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2012}, {"title": "The dynamic window approach to collision avoidance", "author": ["D. Fox", "W. Burgard", "S. Thrun"], "venue": "IEEE Robotics Automation Magazine, vol. 4, no. 1, pp. 23\u201333, 1997.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1997}, {"title": "Motion planning in dynamic environments using velocity obstacles", "author": ["P. Fiorini", "Z. Shiller"], "venue": "The International Journal of Robotics Research, vol. 17, no. 7, pp. 760\u2013772, 1998.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1998}, {"title": "Filling in the blanks: reconstructing microscopic crowd motion from multiple disparate noisy sensors", "author": ["S. Yoon", "M. Kapadia", "P. Sahu", "V. Pavlovic"], "venue": "2016 IEEE Winter Applications of Computer Vision Workshops (WACVW). IEEE, 2016, pp. 1\u20139.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2016}, {"title": "Reinforcement learning in the multi-robot domain", "author": ["M.J. Matari\u0107"], "venue": "Robot colonies. Springer, 1997, pp. 73\u201383.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1997}, {"title": "Multiagent systems: A survey from a machine learning perspective", "author": ["P. Stone", "M. Veloso"], "venue": "Autonomous Robots, vol. 8, no. 3, pp. 345\u2013383, 2000.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2000}, {"title": "Multiagent reinforcement learning for multi-robot systems: A survey", "author": ["E. Yang", "D. Gu"], "venue": "tech. rep, Tech. Rep., 2004.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2004}, {"title": "Cooperative multi-agent learning: The state of the art", "author": ["L. Panait", "S. Luke"], "venue": "Autonomous agents and multi-agent systems, vol. 11, no. 3, pp. 387\u2013434, 2005.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2005}, {"title": "Adaptive learning for multi-agent navigation", "author": ["J.E. Godoy", "I. Karamouzas", "S.J. Guy", "M. Gini"], "venue": "International Conference on Autonomous Agents and Multiagent Systems, 2015, pp. 1577\u20131585.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2015}, {"title": "Socially compliant mobile robot navigation via inverse reinforcement learning", "author": ["H. Kretzschmar", "M. Spies", "C. Sprunk", "W. Burgard"], "venue": "The International Journal of Robotics Research, p. to appear, 2016.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2016}, {"title": "Generating a multiplicity of policies for agent steering in crowd simulation", "author": ["C.D. Boatright", "M. Kapadia", "J.M. Shapira", "N.I. Badler"], "venue": "Computer Animation and Virtual Worlds, vol. 26, no. 5, pp. 483\u2013494, 2015.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2015}, {"title": "Point set registration: Coherent point drift", "author": ["A. Myronenko", "X. Song"], "venue": "IEEE transactions on pattern analysis and machine intelligence, vol. 32, no. 12, pp. 2262\u20132275, 2010.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2010}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "Advances in Neural Information Processing Systems, 2012, pp. 1097\u20131105.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2012}, {"title": "Deep speech 2: End-to-end speech recognition in english and mandarin", "author": ["D. Amodei", "R. Anubhai", "E. Battenberg", "C. Case", "J. Casper", "B. Catanzaro", "J. Chen", "M. Chrzanowski", "A. Coates", "G. Diamos"], "venue": "arXiv:1512.02595, 2015.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2015}, {"title": "Robust optimization for deep regression", "author": ["V. Belagiannis", "C. Rupprecht", "G. Carneiro", "N. Navab"], "venue": "IEEE International Conference on Computer Vision, 2015, pp. 2830\u20132838.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "Among extensive work addressing this problem, the velocity-based approaches [1]\u2013[5] have gained in popularity due to their robustness and ability to guarantee local collision-free motion for many agents in a cluttered workspace.", "startOffset": 76, "endOffset": 79}, {"referenceID": 3, "context": "Among extensive work addressing this problem, the velocity-based approaches [1]\u2013[5] have gained in popularity due to their robustness and ability to guarantee local collision-free motion for many agents in a cluttered workspace.", "startOffset": 80, "endOffset": 83}, {"referenceID": 1, "context": ", an overhead motion capture system) to monitor the positions of all agents [3], [5], or using an inter-agent commu-", "startOffset": 76, "endOffset": 79}, {"referenceID": 3, "context": ", an overhead motion capture system) to monitor the positions of all agents [3], [5], or using an inter-agent commu-", "startOffset": 81, "endOffset": 84}, {"referenceID": 2, "context": "nication protocol for sharing position and velocity information among nearby agents [4], [6], [7].", "startOffset": 84, "endOffset": 87}, {"referenceID": 4, "context": "nication protocol for sharing position and velocity information among nearby agents [4], [6], [7].", "startOffset": 89, "endOffset": 92}, {"referenceID": 5, "context": "nication protocol for sharing position and velocity information among nearby agents [4], [6], [7].", "startOffset": 94, "endOffset": 97}, {"referenceID": 6, "context": "fields [8], local variable-resolution fields [9], dynamic windows [10], and velocity obstacles [1], [2], [11].", "startOffset": 7, "endOffset": 10}, {"referenceID": 7, "context": "fields [8], local variable-resolution fields [9], dynamic windows [10], and velocity obstacles [1], [2], [11].", "startOffset": 45, "endOffset": 48}, {"referenceID": 8, "context": "fields [8], local variable-resolution fields [9], dynamic windows [10], and velocity obstacles [1], [2], [11].", "startOffset": 66, "endOffset": 70}, {"referenceID": 0, "context": "fields [8], local variable-resolution fields [9], dynamic windows [10], and velocity obstacles [1], [2], [11].", "startOffset": 95, "endOffset": 98}, {"referenceID": 9, "context": "fields [8], local variable-resolution fields [9], dynamic windows [10], and velocity obstacles [1], [2], [11].", "startOffset": 105, "endOffset": 109}, {"referenceID": 1, "context": ", [3], [5]) have many parameters that are difficult to tune.", "startOffset": 2, "endOffset": 5}, {"referenceID": 3, "context": ", [3], [5]) have many parameters that are difficult to tune.", "startOffset": 7, "endOffset": 10}, {"referenceID": 2, "context": "[4] and Claes et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[7] extended the ORCA paradigm with an inter-agent communication protocol for sharing knowledge about agents\u2019 positions and velocities.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "A one-way communication scheme is also introduced in [6] to coordinate the movement of agents in a crowd scenario.", "startOffset": 53, "endOffset": 56}, {"referenceID": 1, "context": "Other approaches [3], [5] avoided the difficulty in sensing uncertainty by using an overhead motion capture system to obtain the global position observation for all agents.", "startOffset": 17, "endOffset": 20}, {"referenceID": 3, "context": "Other approaches [3], [5] avoided the difficulty in sensing uncertainty by using an overhead motion capture system to obtain the global position observation for all agents.", "startOffset": 22, "endOffset": 25}, {"referenceID": 10, "context": "[12] used multiple visual sensors to track individuals\u2019 trajectories in", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "Reinforcement learning has been widely used for the multiagent decision making [13]\u2013[16], which is formulated as a multi-agent Markov Decision Processes (MDP) problem.", "startOffset": 79, "endOffset": 83}, {"referenceID": 14, "context": "Reinforcement learning has been widely used for the multiagent decision making [13]\u2013[16], which is formulated as a multi-agent Markov Decision Processes (MDP) problem.", "startOffset": 84, "endOffset": 88}, {"referenceID": 15, "context": "[17], which originates from multi-arm bandits.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[18] first infers the internal goals of other agents, then plans a set of jointly possible paths for all neighboring agents in the shared environment.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[19] train a set of machinelearned policies by decomposing possible scenarios an agent may encounter into steering contexts.", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "In a scenario without static obstacles, v ai can directly point toward gai ; in a scene with static obstacles, v ai may point toward a closest node in a precomputed roadmap [1].", "startOffset": 173, "endOffset": 176}, {"referenceID": 0, "context": "In previous work such as [1], [2], the observation oai consists of the nearby agents\u2019 positions, velocities and shapes.", "startOffset": 25, "endOffset": 28}, {"referenceID": 0, "context": "agents, while such knowledge is usually necessary for previous approaches [1]\u2013[3], [5], [17].", "startOffset": 74, "endOffset": 77}, {"referenceID": 1, "context": "agents, while such knowledge is usually necessary for previous approaches [1]\u2013[3], [5], [17].", "startOffset": 78, "endOffset": 81}, {"referenceID": 3, "context": "agents, while such knowledge is usually necessary for previous approaches [1]\u2013[3], [5], [17].", "startOffset": 83, "endOffset": 86}, {"referenceID": 15, "context": "agents, while such knowledge is usually necessary for previous approaches [1]\u2013[3], [5], [17].", "startOffset": 88, "endOffset": 92}, {"referenceID": 18, "context": "infer these neighboring agents\u2019 velocities by performing a non-rigid point cloud matching between the current scan and the scan in previous time step using the coherent point drift algorithm [20] implemented with the fast Gauss Transform.", "startOffset": 191, "endOffset": 195}, {"referenceID": 19, "context": "As shown in [21], [22], data augmentation technologies can moderate over-fitting and improve the generalization capability of the learned policy.", "startOffset": 12, "endOffset": 16}, {"referenceID": 20, "context": "As shown in [21], [22], data augmentation technologies can moderate over-fitting and improve the generalization capability of the learned policy.", "startOffset": 18, "endOffset": 22}, {"referenceID": 21, "context": "We choose to not model the computation of collision avoidance velocity as a regression problem because the l2 loss function for regression tasks usually is more fragile to outliers [23].", "startOffset": 181, "endOffset": 185}], "year": 2017, "abstractText": "High-speed, low-latency obstacle avoidance that is insensitive to sensor noise is essential for enabling multiple decentralized robots to function reliably in cluttered and dynamic environments. While other distributed multi-agent collision avoidance systems exist, these systems require online geometric optimization where tedious parameter tuning and perfect sensing are necessary. We present a novel end-to-end framework to generate reactive collision avoidance policy for efficient distributed multi-agent navigation. Our method formulates an agent\u2019s navigation strategy as a deep neural network mapping from the observed noisy sensor measurements to the agent\u2019s steering commands in terms of movement velocity. We train the network on a large number of frames of collision avoidance data collected by repeatedly running a multi-agent simulator with different parameter settings. We validate the learned deep neural network policy in a set of simulated and real scenarios with noisy measurements and demonstrate that our method is able to generate a robust navigation strategy that is insensitive to imperfect sensing and works reliably in all situations. We also show that our method can be well generalized to scenarios that do not appear in our training data, including scenes with static obstacles and agents with different sizes. Videos are available at https://sites.google.com/view/deepmaca.", "creator": "LaTeX with hyperref package"}}}