{"id": "1609.07495", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Sep-2016", "title": "A Rotation Invariant Latent Factor Model for Moveme Discovery from Static Poses", "abstract": "We tackle the problem of learning a rotation invariant latent factor model when the training data is comprised of lower-dimensional projections of the original feature space. The main goal is the discovery of a set of 3-D bases poses that can characterize the manifold of primitive human motions, or movemes, from a training set of 2-D projected poses obtained from still images taken at various camera angles. The proposed technique for basis discovery is data-driven rather than hand-designed. The learned representation is rotation invariant, and can reconstruct any training instance from multiple viewing angles. We apply our method to modeling human poses in sports (via the Leeds Sports Dataset), and demonstrate the effectiveness of the learned bases in a range of applications such as activity classification, inference of dynamics from a single frame, and synthetic representation of movements.", "histories": [["v1", "Fri, 23 Sep 2016 20:00:23 GMT  (3323kb,D)", "http://arxiv.org/abs/1609.07495v1", "Long version of the paper accepted at the IEEE ICDM 2016 conference. 10 pages, 9 figures, 1 table. Project page:this http URL"]], "COMMENTS": "Long version of the paper accepted at the IEEE ICDM 2016 conference. 10 pages, 9 figures, 1 table. Project page:this http URL", "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["matteo ruggero ronchi", "joon sik kim", "yisong yue"], "accepted": false, "id": "1609.07495"}, "pdf": {"name": "1609.07495.pdf", "metadata": {"source": "CRF", "title": "A Rotation Invariant Latent Factor Model for Moveme Discovery from Static Poses", "authors": ["Matteo Ruggero Ronchi", "Joon Sik Kim", "Yisong Yue"], "emails": ["yyue}@caltech.edu"], "sections": [{"heading": null, "text": "This year, the time has come for an agreement to be reached in just a few days."}, {"heading": "A. Basic Notation and Framework", "text": "In this work, we focus on learning from two-dimensional projections of three-dimensional human poses, but it is easy to generalize them to other settings. We obtain a training set S = {(x j, y j)} nj = 1 of n two-dimensional poses, where x and y correspond to the image coordinates of the postural joints from the observed viewing angle, see Fig. 2. Let us designate S = < 2d \u00b7 n the dataset matrix composed of k latent factors, where 2d is the dimensionality of the projected space (twice the number of joints d for two-dimensional projections). Our goal is to learn a base pose composed of k latent factors and a coefficient matrix V = < k \u00b7 n, so that each training example can be represented as a linear combination: s = U \u00b7 vj + s, (1) where s represents the \"middle\" pose."}, {"heading": "B. Baselines", "text": "To the best of our knowledge, no existing approach addresses the problem of learning a rotationally invariant basis for modeling human movements. Previous work focuses either on learning base poses only from frontal angles or by extensively manually creating a predefined set of poses [14], [16]. As such, we develop our approach by building on classic baselines such as the SVD, which we briefly describe here. Singular Value Decomposition: The example in (1) is the most basic form of a latent factor model. If the training goal is to minimize the square reconstruction error of the training data, then the solution can be restored using SVD, even for natural surfaces [26]. The base matrix U and the coefficient matrix V correspond (up to scaling) to the left and right singular vectors of the center data matrix Sc = (S \u2212 s)."}, {"heading": "C. Rotation-Invariant Latent Factor Model", "text": "Our goal is to develop a latent factor model that can learn a global representation of the basics from different angles. To simplify this, we limit ourselves to settings where there are only differences in the angle of view and assume that there is no variation in the angle of inclination (i.e., all horizontal views). To this end, we propose both a 2-D model and a 3-D model that can be used depending on the quality and quantity of the additional information available during training time. For some applications, it may be sufficient to use the 2-D model, but the 3-D model is generally better able to capture the desired properties."}, {"heading": "D. Training Details", "text": "Initialization: Our approaches require an initial estimate of the viewing angle for each training instance, and the fundamentals represent U. For angle initialization, we show in our experiments (Section IV-B4) that we only need a fairly rough prediction of the viewing angle (e.g. in quadrants).The 2-D latency factor model fundamentals show that U is uniformly initialized between -1 and 1, while for the 3-D model we use a commercially available pose estimator [16] and initialize U as left singular vectors of the average centered 3-D value obtained by SVD. Optimization: For both models, we optimize equivalent (4) using alternating stochastic downward gradient direction, divided into two phases: \u2022 Representation actualization: we use standard stochastic downward direction to update U and V while simultaneously fixing the 3-D model."}, {"heading": "A. Dataset and Additional Annotations", "text": "We use the Leeds Sports Dataset (LSP) [32] for our experiments. LSP consists of 2000 images containing a single person performing one of eight sports (athletics, badminton, baseball, gymnastics, parkour, football, tennis, volleyball), which are commented on with the x, y location and a visibility flag for 14 joints of the human body. Exemplary images and annotations are shown in Figures 1, 2 and 8. Sports activities are particularly well suited to this study as they represent characteristic movements that divide the trajectories of body parts, allowing an investigation of the basics of common sport. As part of pre-processing, we normalize all poses in the dataset by modifying each bone to calculate the average bone length over all training distances. [15] We discard \"gymnastics\" and \"parkour\" from our analysis because they have few examples and do not represent the class poses exclusively along the pan angle."}, {"heading": "B. Empirical Results", "text": "In fact, most of us are able to put ourselves in a different world, in which they are able to live, in which they are able to live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they, in which they are able to put themselves into another world, in which they are able, in which they live, in which they live in which they live, in which they live in which they live in which they live, in which they live in which they live, in which they live in which they live, in which they live in which they live, in which they live in which they live, in which they live in which they live, in which they live in which they live, in which they live in which they live, in which they live in which they live, in which they live, in which they live in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live,"}], "references": [{"title": "Limits of movement in the human knee. effect of sectioning the posterior cruciate ligament and posterolateral structures.", "author": ["E.S. Grood", "S.F. Stowers", "F.R. Noyes"], "venue": "J Bone Joint Surg Am, vol. 70,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1988}, {"title": "A three-dimensional multivariate model of passive human joint torques and articular boundaries", "author": ["H. Hatze"], "venue": "Clinical Biomechanics, vol. 12, no. 2, pp. 128\u2013135, 1997.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1997}, {"title": "Toward a science of computational ethology", "author": ["D.J. Anderson", "P. Perona"], "venue": "Neuron, vol. 84, no. 1, pp. 18\u201331, 2014.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning and recognizing human dynamics in video sequences", "author": ["C. Bregler"], "venue": "Computer Vision and Pattern Recognition, 1997. Proceedings., 1997 IEEE Computer Society Conference on. IEEE, 1997, pp. 568\u2013574.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1997}, {"title": "A survey on vision-based human action recognition", "author": ["R. Poppe"], "venue": "Image and vision computing, vol. 28, no. 6, pp. 976\u2013990, 2010.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2010}, {"title": "Machine recognition of human activities: A survey", "author": ["P. Turaga", "R. Chellappa", "V.S. Subrahmanian", "O. Udrea"], "venue": "Circuits and Systems for Video Technology, IEEE Transactions on, vol. 18, no. 11, pp. 1473\u2013 1488, 2008.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2008}, {"title": "Octopamine in male aggression of drosophila", "author": ["S.C. Hoyer", "A. Eckart", "A. Herrel", "T. Zars", "S.A. Fischer", "S.L. Hardie", "M. Heisenberg"], "venue": "Current Biology, vol. 18, no. 3, pp. 159\u2013167, 2008.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2008}, {"title": "2d human pose estimation: New benchmark and state of the art analysis", "author": ["M. Andriluka", "L. Pishchulin", "P. Gehler", "B. Schiele"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2014.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "Describing common human visual actions in images", "author": ["M.R. Ronchi", "P. Perona"], "venue": "Proceedings of the British Machine Vision Conference (BMVC 2015). BMVA Press, September 2015, pp. 52.1\u201352.12.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2015}, {"title": "Visual genome: Connecting language and vision using crowdsourced dense image annotations", "author": ["R. Krishna", "Y. Zhu", "O. Groth", "J. Johnson", "K. Hata", "J. Kravitz", "S. Chen", "Y. Kalantidis", "L.-J. Li", "D.A. Shamma", "M. Bernstein", "L. Fei-Fei"], "venue": "2016. [Online]. Available: http://arxiv.org/abs/1602.07332", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2016}, {"title": "Does human action recognition benefit from pose estimation?.", "author": ["A. Yao", "J. Gall", "G. Fanelli", "L.J. Van Gool"], "venue": "in BMVC,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2011}, {"title": "Predicting object dynamics in scenes", "author": ["D. Fouhey", "C. Zitnick"], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2014, pp. 2019\u20132026.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2014}, {"title": "Computer animation: algorithms and techniques", "author": ["R. Parent"], "venue": "Newnes,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "Reconstructing 3d human pose from 2d image landmarks", "author": ["V. Ramakrishna", "T. Kanade", "Y. Sheikh"], "venue": "Computer Vision\u2013ECCV 2012. Springer, 2012, pp. 573\u2013586.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2012}, {"title": "Pose locality constrained representation for 3d human pose reconstruction", "author": ["X. Fan", "K. Zheng", "Y. Zhou", "S. Wang"], "venue": "Computer Vision\u2013 ECCV 2014. Springer, 2014, pp. 174\u2013188.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2014}, {"title": "Pose-conditioned joint angle limits for 3d human pose reconstruction", "author": ["I. Akhter", "M.J. Black"], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2015, pp. 1446\u20131455.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2015}, {"title": "Robust face landmark estimation under occlusion", "author": ["X. Burgos-Artizzu", "P. Perona", "P. Doll\u00e1r"], "venue": "Proceedings of the IEEE International Conference on Computer Vision, 2013, pp. 1513\u20131520.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2013}, {"title": "Articulated pose estimation by a graphical model with image dependent pairwise relations", "author": ["X. Chen", "A.L. Yuille"], "venue": "Advances in Neural Information Processing Systems, 2014, pp. 1736\u20131744.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2014}, {"title": "Action recognition from a distributed representation of pose and appearance", "author": ["S. Maji", "L. Bourdev", "J. Malik"], "venue": "Computer Vision and Pattern Recognition (CVPR), 2011 IEEE Conference on. IEEE, 2011, pp. 3177\u2013 3184.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2011}, {"title": "Efficient posebased action recognition", "author": ["A. Eweiwi", "M.S. Cheema", "C. Bauckhage", "J. Gall"], "venue": "Computer Vision\u2013ACCV 2014. Springer, 2014, pp. 428\u2013443.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}, {"title": "Modeling mutual context of object and human pose in human-object interaction activities", "author": ["B. Yao", "L. Fei-Fei"], "venue": "Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on. IEEE, 2010, pp. 17\u201324.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2010}, {"title": "Activation in human mt/mst by static images with implied motion", "author": ["Z. Kourtzi", "N. Kanwisher"], "venue": "Journal of cognitive neuroscience, vol. 12, no. 1, pp. 48\u201355, 2000.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2000}, {"title": "Sparse coding for learning interpretable spatio-temporal primitives", "author": ["T. Kim", "G. Shakhnarovich", "R. Urtasun"], "venue": "Advances in neural information processing systems, 2010, pp. 1117\u20131125.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2010}, {"title": "Poselet key-framing: A model for human activity recognition", "author": ["M. Raptis", "L. Sigal"], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2013, pp. 2650\u20132657.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2013}, {"title": "Matrix factorization techniques for recommender systems", "author": ["Y. Koren", "R. Bell", "C. Volinsky"], "venue": "Computer, no. 8, pp. 30\u201337, 2009.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2009}, {"title": "Face recognition using eigenfaces", "author": ["M.A. Turk", "A.P. Pentland"], "venue": "Computer Vision and Pattern Recognition, 1991. Proceedings CVPR\u201991., IEEE Computer Society Conference on. IEEE, 1991, pp. 586\u2013591.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1991}, {"title": "Latent semantic analysis", "author": ["S.T. Dumais"], "venue": "Annual review of information science and technology, vol. 38, no. 1, pp. 188\u2013230, 2004.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2004}, {"title": "Learning fine-grained spatial models for dynamic sports play prediction", "author": ["Y. Yue", "P. Lucey", "P. Carr", "A. Bialkowski", "I. Matthews"], "venue": "IEEE International Conference on Data Mining (ICDM), December 2013.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2013}, {"title": "Representation learning: A review and new perspectives", "author": ["Y. Bengio", "A. Courville", "P. Vincent"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on, vol. 35, no. 8, pp. 1798\u20131828, 2013.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1828}, {"title": "Online dictionary learning for sparse coding", "author": ["J. Mairal", "F. Bach", "J. Ponce", "G. Sapiro"], "venue": "Proceedings of the 26th annual international conference on machine learning. ACM, 2009, pp. 689\u2013696.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2009}, {"title": "Deep manifold traversal: Changing labels with convolutional features", "author": ["J.R. Gardner", "M.J. Kusner", "Y. Li", "P. Upchurch", "K.Q. Weinberger", "J.E. Hopcroft"], "venue": "arXiv preprint arXiv:1511.06421, 2015.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2015}, {"title": "Clustered pose and nonlinear appearance models for human pose estimation", "author": ["S. Johnson", "M. Everingham"], "venue": "Proceedings of the British Machine Vision Conference, 2010, doi:10.5244/C.24.12.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2010}, {"title": "A fast iterative shrinkage-thresholding algorithm for linear inverse problems", "author": ["A. Beck", "M. Teboulle"], "venue": "SIAM journal on imaging sciences, vol. 2, no. 1, pp. 183\u2013202, 2009.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2009}, {"title": "A rotation invariant latent factor model for moveme discovery from static poses", "author": ["M.R. Ronchi", "J.S. Kim", "Y. Yue"], "venue": "http://www.vision. caltech.edu/\u223cmronchi/projects/RotationInvariantMovemes/, 2016.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2016}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "Advances in neural information processing systems, 2012, pp. 1097\u20131105.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2012}, {"title": "An introduction to total least squares", "author": ["P.P. de Groen"], "venue": "arXiv preprint math/9805076, 1998.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 1998}, {"title": "Visualizing data using t-sne", "author": ["L. Van der Maaten", "G. Hinton"], "venue": "Journal of Machine Learning Research, vol. 9, no. 2579-2605, p. 85, 2008.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2008}, {"title": "Microsoft coco: Common objects in context", "author": ["T.-Y. Lin", "M. Maire", "S. Belongie", "J. Hays", "P. Perona", "D. Ramanan", "P. Doll\u00e1r", "C.L. Zitnick"], "venue": "Computer Vision\u2013ECCV 2014. Springer, 2014, pp. 740\u2013 755.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "One of the main difficulties of studying human movement is that it is a priori unrestricted, except for physically imposed joint angle limits which have been studied in medical text books, typically for a limited number of configurations [1], [2].", "startOffset": 238, "endOffset": 241}, {"referenceID": 1, "context": "One of the main difficulties of studying human movement is that it is a priori unrestricted, except for physically imposed joint angle limits which have been studied in medical text books, typically for a limited number of configurations [1], [2].", "startOffset": 243, "endOffset": 246}, {"referenceID": 2, "context": "Furthermore, human movement may be distinguished into movemes, actions, and activities [3], [4] depending on structure, complexity, and duration.", "startOffset": 87, "endOffset": 90}, {"referenceID": 3, "context": "Furthermore, human movement may be distinguished into movemes, actions, and activities [3], [4] depending on structure, complexity, and duration.", "startOffset": 92, "endOffset": 95}, {"referenceID": 4, "context": "Extensive studies have been carried out on human action and activity recognition [5], [6], however little attention has been paid to movemes since human behaviour is difficult to analyze S U V =", "startOffset": 81, "endOffset": 84}, {"referenceID": 5, "context": "Extensive studies have been carried out on human action and activity recognition [5], [6], however little attention has been paid to movemes since human behaviour is difficult to analyze S U V =", "startOffset": 86, "endOffset": 89}, {"referenceID": 7, "context": "Thus, finding a basis representation using such training data can prove extremely valuable, given the number of image datasets (as opposed to video or mo-cap data) that are currently being collected with a focus on common activities [8]\u2013[10].", "startOffset": 233, "endOffset": 236}, {"referenceID": 9, "context": "Thus, finding a basis representation using such training data can prove extremely valuable, given the number of image datasets (as opposed to video or mo-cap data) that are currently being collected with a focus on common activities [8]\u2013[10].", "startOffset": 237, "endOffset": 241}, {"referenceID": 6, "context": "1The extent in time and complexity of human motion is not directly observable in still images but requires videos of humans involved in activities which cannot be recorded extensively without legal or ethical issues, as opposed to fly or mouse behaviour which is very well documented [7].", "startOffset": 284, "endOffset": 287}, {"referenceID": 10, "context": "Activity recognition; a compact representation such as the proposed one can be used in addition to the feature representation of state of the art methods for activity recognition, favoring both the performance [11], and the interpretability of results.", "startOffset": 210, "endOffset": 214}, {"referenceID": 11, "context": "This allows to predict the future dynamic of an action [12], or morph a pose into another from a single frame, by observing the dynamics of the movemes which better describe the captured pose.", "startOffset": 55, "endOffset": 59}, {"referenceID": 12, "context": "Computer graphics animation; many animation systems are still based on key-framing and in-betweening [13]: master animators draw the key frames of a sequence to be animated and assistant animators complete the intermediate frames by inferring the movements occurring between the keys.", "startOffset": 101, "endOffset": 105}, {"referenceID": 13, "context": "3-D pose estimation; a sparse overcomplete dictionary of human poses has been used effectively for the reconstruction of 3-D human pose given its 2-D joint locations from a single frame image [14]\u2013[16].", "startOffset": 192, "endOffset": 196}, {"referenceID": 15, "context": "3-D pose estimation; a sparse overcomplete dictionary of human poses has been used effectively for the reconstruction of 3-D human pose given its 2-D joint locations from a single frame image [14]\u2013[16].", "startOffset": 197, "endOffset": 201}, {"referenceID": 16, "context": "The first one is estimation: given a picture containing a person, the goal is to predict the location of a predefined set of joints of its body, either in the 2-D image [17], [18] or in the 3-D space [14]\u2013[16].", "startOffset": 169, "endOffset": 173}, {"referenceID": 17, "context": "The first one is estimation: given a picture containing a person, the goal is to predict the location of a predefined set of joints of its body, either in the 2-D image [17], [18] or in the 3-D space [14]\u2013[16].", "startOffset": 175, "endOffset": 179}, {"referenceID": 13, "context": "The first one is estimation: given a picture containing a person, the goal is to predict the location of a predefined set of joints of its body, either in the 2-D image [17], [18] or in the 3-D space [14]\u2013[16].", "startOffset": 200, "endOffset": 204}, {"referenceID": 15, "context": "The first one is estimation: given a picture containing a person, the goal is to predict the location of a predefined set of joints of its body, either in the 2-D image [17], [18] or in the 3-D space [14]\u2013[16].", "startOffset": 205, "endOffset": 209}, {"referenceID": 18, "context": "The second line of investigation uses pose as a form of contextual information that can be combined with objects\u2019 category and location in an image to obtain higher performance for activity recognition through a joint learning procedure [19]\u2013[21].", "startOffset": 237, "endOffset": 241}, {"referenceID": 20, "context": "The second line of investigation uses pose as a form of contextual information that can be combined with objects\u2019 category and location in an image to obtain higher performance for activity recognition through a joint learning procedure [19]\u2013[21].", "startOffset": 242, "endOffset": 246}, {"referenceID": 21, "context": "Other people investigated this problem: it is known that dynamic information can be recovered from static images of humans engaged in activities [22], and similar representations for action recognition have been learned using video data [23], [24].", "startOffset": 145, "endOffset": 149}, {"referenceID": 22, "context": "Other people investigated this problem: it is known that dynamic information can be recovered from static images of humans engaged in activities [22], and similar representations for action recognition have been learned using video data [23], [24].", "startOffset": 237, "endOffset": 241}, {"referenceID": 23, "context": "Other people investigated this problem: it is known that dynamic information can be recovered from static images of humans engaged in activities [22], and similar representations for action recognition have been learned using video data [23], [24].", "startOffset": 243, "endOffset": 247}, {"referenceID": 24, "context": "Latent Factor Models and Representation Learning: We build upon a long line of research in latent factor models, first popularized for collaborative filtering problems in content recommendation [25].", "startOffset": 194, "endOffset": 198}, {"referenceID": 25, "context": "Applications include modeling variations of faces [26], document and text analysis [27], and behavior patterns in sports [28], amongst many others.", "startOffset": 50, "endOffset": 54}, {"referenceID": 26, "context": "Applications include modeling variations of faces [26], document and text analysis [27], and behavior patterns in sports [28], amongst many others.", "startOffset": 83, "endOffset": 87}, {"referenceID": 27, "context": "Applications include modeling variations of faces [26], document and text analysis [27], and behavior patterns in sports [28], amongst many others.", "startOffset": 121, "endOffset": 125}, {"referenceID": 28, "context": "Our approach can be viewed as a form of representation learning, which includes methods such as deep neural networks and dictionary learning [29], [30].", "startOffset": 141, "endOffset": 145}, {"referenceID": 29, "context": "Our approach can be viewed as a form of representation learning, which includes methods such as deep neural networks and dictionary learning [29], [30].", "startOffset": 147, "endOffset": 151}, {"referenceID": 30, "context": "One of the benefits of representation learning is the ability to smoothly traverse the representation space [31], which in our setting translates to learning movemes as transitions between poses.", "startOffset": 108, "endOffset": 112}, {"referenceID": 13, "context": "Previous work is focused on either learning bases poses only from frontal viewing angles or by extensive manual crafting of a predefined set of poses [14], [16].", "startOffset": 150, "endOffset": 154}, {"referenceID": 15, "context": "Previous work is focused on either learning bases poses only from frontal viewing angles or by extensive manual crafting of a predefined set of poses [14], [16].", "startOffset": 156, "endOffset": 160}, {"referenceID": 25, "context": "When the training objective is to minimize the squared reconstruction error of the training data, then the solution can be recovered via SVD, also used for eigenfaces [26].", "startOffset": 167, "endOffset": 171}, {"referenceID": 31, "context": "The joint annotations from an image in LSP [32], and their displacement from the mean pose, which we use to encode movemes.", "startOffset": 43, "endOffset": 47}, {"referenceID": 15, "context": "The 2-D latent factor model bases poses U are initialized uniformly between -1 and 1, while for the 3-D model we use an off-the-shelf pose estimator [16] and initialize U as the left singular vectors of the mean centered 3-D pose data, obtained through SVD.", "startOffset": 149, "endOffset": 153}, {"referenceID": 32, "context": "Because we employ an L1 regularization penalty, we use the standard soft-thresholding technique [33].", "startOffset": 96, "endOffset": 100}, {"referenceID": 31, "context": "We use the Leeds Sports Dataset (LSP) [32] for our experiments.", "startOffset": 38, "endOffset": 42}, {"referenceID": 14, "context": "As part of preprocessing, we normalize all the poses in the dataset by modifying each bone to have the average bone length computed over all the training instances [15].", "startOffset": 164, "endOffset": 168}, {"referenceID": 33, "context": "2The angle annotations for LSP, annotator agreement statistics, and details about the Amazon Mechanical Turk GUI are available at the project page [34].", "startOffset": 147, "endOffset": 151}, {"referenceID": 34, "context": "Finally, the obtained feature representation is complementary to other representations, such as the hidden layer activations of a convolutional neural network [35], and we wish to investigate in future work the performance obtained by their combination.", "startOffset": 159, "endOffset": 163}, {"referenceID": 35, "context": "One straightforward way to find the sequence in which a set of poses lies in the manifold, is to look at the coefficient of their projection along the \u201ctotal least squares\u201d line fit [36] of the corresponding columns in the matrix V.", "startOffset": 182, "endOffset": 186}, {"referenceID": 36, "context": "Each pose in LSP is mapped in the human motion space through the coefficients of the corresponding column of V and then projected in two-dimensions using t-SNE [37].", "startOffset": 160, "endOffset": 164}, {"referenceID": 37, "context": "Other possible extensions of our work are: learning to morph actions and synthesize unseen actions from the set of extracted movemes; inferring the location of occluded or missing joints based on the position of the visible ones; applying these techniques to large-scale datasets [38] in conjunction with fine grained annotations of the performed actions [9], [10] to gain new insights on the structure, complexity, and duration of human behaviour.", "startOffset": 280, "endOffset": 284}, {"referenceID": 8, "context": "Other possible extensions of our work are: learning to morph actions and synthesize unseen actions from the set of extracted movemes; inferring the location of occluded or missing joints based on the position of the visible ones; applying these techniques to large-scale datasets [38] in conjunction with fine grained annotations of the performed actions [9], [10] to gain new insights on the structure, complexity, and duration of human behaviour.", "startOffset": 355, "endOffset": 358}, {"referenceID": 9, "context": "Other possible extensions of our work are: learning to morph actions and synthesize unseen actions from the set of extracted movemes; inferring the location of occluded or missing joints based on the position of the visible ones; applying these techniques to large-scale datasets [38] in conjunction with fine grained annotations of the performed actions [9], [10] to gain new insights on the structure, complexity, and duration of human behaviour.", "startOffset": 360, "endOffset": 364}], "year": 2016, "abstractText": "We tackle the problem of learning a rotation invariant latent factor model when the training data is comprised of lower-dimensional projections of the original feature space. The main goal is the discovery of a set of 3-D bases poses that can characterize the manifold of primitive human motions, or movemes, from a training set of 2-D projected poses obtained from still images taken at various camera angles. The proposed technique for basis discovery is data-driven rather than handdesigned. The learned representation is rotation invariant, and can reconstruct any training instance from multiple viewing angles. We apply our method to modeling human poses in sports (via the Leeds Sports Dataset), and demonstrate the effectiveness of the learned bases in a range of applications such as activity classification, inference of dynamics from a single frame, and synthetic representation of movements.", "creator": "LaTeX with hyperref package"}}}