{"id": "1609.08221", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Sep-2016", "title": "Simultaneous Low-rank Component and Graph Estimation for High-dimensional Graph Signals: Application to Brain Imaging", "abstract": "We propose an algorithm to uncover the intrinsic low-rank component of a high-dimensional, graph-smooth and grossly-corrupted dataset, under the situations that the underlying graph is unknown. Based on a model with a low-rank component plus a sparse perturbation, and an initial graph estimation, our proposed algorithm simultaneously learns the low-rank component and refines the graph. Our evaluations using synthetic and real brain imaging data in unsupervised and supervised classification tasks demonstrate encouraging performance.", "histories": [["v1", "Mon, 26 Sep 2016 23:24:27 GMT  (542kb,D)", "https://arxiv.org/abs/1609.08221v1", "Submitted to ICASSP 2017"], ["v2", "Mon, 9 Jan 2017 03:23:43 GMT  (1172kb,D)", "http://arxiv.org/abs/1609.08221v2", "Accepted by ICASSP 2017"]], "COMMENTS": "Submitted to ICASSP 2017", "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["rui liu", "hossein nejati", "ngai-man cheung"], "accepted": false, "id": "1609.08221"}, "pdf": {"name": "1609.08221.pdf", "metadata": {"source": "CRF", "title": "SIMULTANEOUS LOW-RANK COMPONENT AND GRAPH ESTIMATION FOR HIGH-DIMENSIONAL GRAPH SIGNALS: APPLICATION TO BRAIN IMAGING", "authors": ["Liu Rui", "Hossein Nejati", "Seyed Hamid Safavi", "Ngai-Man Cheung"], "emails": [], "sections": [{"heading": null, "text": "Index Terms - Graph Signal Processing, Low Rank, Dimensionality Reduction, Graph Learning, Brain Imaging"}, {"heading": "1. INTRODUCTION", "text": "We look at the problem of discovering the intrinsic low ranking component of a highly complex dataset. We continue to focus on data based on a particular graph, and the data changes smoothly between the connected wells. We propose an algorithm to estimate the low ranking component of the data, with the graph simultaneously and iteratively refining the graph. We propose an algorithm that supports the graph premise."}, {"heading": "1.1. Related Work", "text": "This work is inspired by [2]. While the focus of [2] is to learn connectivity graph topology, its algorithm also values a noise-free version of the input data as a by-product. Gaussian noise model and Frobenius standard optimization are used in [2]. Therefore, their work is suitable for problems when noise is small. In our work, one can assume a model with a low component plus a sparse perturbation, and a first graph estimate we take the idea of an incremental refinement of the underlying connectivity curve, thereby achieving lower values."}, {"heading": "2. SIMULTANEOUS LOW RANK AND GRAPH ESTIMATION", "text": "We assume that the data matrix that is of primary interest in this paper, and M0 that is the data matrix of primary interest, is a perturbation matrix. We assume that M0 can have an arbitrarily large size, but its support is sparse. (PCA) is the most popular technique for determining the low-rank component with application domains ranging from images, videos, web content to network analysis. (PCA) is the most common method for determining the low-rank component."}, {"heading": "3. LEARNING ALGORITHM", "text": "We propose to solve the problem in Eq (4) with an alternating minimization scheme, where we fix one or two variables at each step and update the other variable.In the first step, for a given \u03a6f, we solve the following optimization problem with ADMM [10] in relation to L and M. It means that we calculate the low-rank matrix: minimize L, M, L and M, which means that based on the low-rank matrix that we obtained in the previous step, the graph is updated. Minimize (LT\u0445fL) + \u03b2, L and M are fixed and we solve the following optimization problem in relation to f, which means that based on the low-rank matrix that we obtained in the previous step, they update the graph. Minimize (LT\u0445fL) + \u03b2, L (2Fl), L (1), L (1), L (2), L (L)."}, {"heading": "4. EXPERIMENT", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1. Synthetic Experiment", "text": "In this synthetic experiment, we create low-grade, graphically smooth, and grossly corrupt data. (We create synthetic data with the following model: X = L0 + M0 (12), where L0-Rp \u00b7 n is a low-ranking matrix with rank r and M0 is the sparse matrix. We create L0 as a product L0 = PYT, where P-Rp \u00b7 r and Y-Rn \u00b7 r. L0 is also graphically smooth and is generated as follows. The (bottom truth) graph consists of p-nodes, where each pair of nodes has a probability of q to be connected to each other. The edge weights between different nodes are drawn uniformly from 0 to 1 and displayed in a symmetrical adjacance matrix W. We calculate the laplactic matrix-Rp-f method and calculate the eigenvectors and eigenvalues of f-Rp. The eigenvectors corresponding to the uppermost values are selected as columns."}, {"heading": "4.2. Brain Imaging Data Experiment", "text": "We also apply our proposed method to a high-dimensional brain imaging dataset to extract the brain connectivity graph and the low approximation to high dimensionality, which is useful for brain imaging studies: due to the high dimensionality of the data, the low signal-to-noise ratio, and the small number of samples available, it is difficult to estimate the low approximation in these studies. Here, the brain imaging dataset used includes a series of magnetoencephalography (MEG) signal recordings of brain activity in response to two categories of visual stimuli: 320 facial images and 192 non-facial images. These images were randomly selected and passively displayed without a task, and 16 subjects were asked to simply fix in the center of the image. All images were normalized for size and brightness among other factors, and displayed once for 300 ms each with random intervals of stimulus delay intervals from 1500 to 1000."}, {"heading": "4.2.1. Initial graph matrix", "text": "In the proposed method, a suitable starting point is important for solving the optimization problem. Therefore, we initialize three different types of connectivity graphs of the brain: structural connectivity, functional connectivity, and effective connectivity. Structural connectivity shows the anatomical structure in the brain; functional connectivity quantifies functional dependencies between different brain regions; and effective connectivity shows directed or causal relationships between different brain regions [7]. In this work, we use coherence connectivity, functional connectivity, and quantification of oscillatory interdependence between different brain regions [16]. It is the frequency domain analogous to the crosscorrelation coefficient."}, {"heading": "4.2.2. Brain Imaging Data Experiment Results", "text": "To evaluate the performance of the proposed method, we use a supervised classifier, SVM = \u03b2 complement to this step, to classify our results into face and non-face classes. We compare these methods on the basis of their classification accuracy and the compatibility of their connectivity graph matrix with the underlying neuroscientific findings on proposed cortical regions involving facial processing. MEG and EEG components corresponding to face / non-face differentiation were measured at latencies of about 100 ms and more reliably at 170 ms (also known as N170 markers, reported at about 145ms in MEG studies), by visual stimulus onset (e.g. see [28, 29, 30, 31]). In this experiment, we select data from two time slots, namely 96ms to 105ms and 141ms after stimulus representation, to compare our automatic assessment with related neuroscience literature."}, {"heading": "5. CONCLUSION", "text": "We propose an algorithm for simultaneously learning the low-level component and the graph. It is suitable for cases where the disturbances of the low-level components are coarse but sparse. We demonstrated that the proposed method is competitive in both synthetic data and brain imaging data. Our method performs well in both low-level approximation and graph estimation. Furthermore, if applied to brain imaging data, our method could restore a connectivity graph that is more compatible with neuroscience literature and indicates its better appreciation of the true underlying graph. Future work will apply the proposed algorithm to other high-dimensional data [32]."}, {"heading": "6. REFERENCES", "text": "[1] David Shuman, Sunil K Narang, Pascal Frossard, Antonio Ortega, Pierre Vandergheynst, et al., \"The emerging field of signal processing on graphs: Extending high-dimensional data analysis to networks and other irregular domains,\" Signal Processing Magazine, IEEE, vol. 30, no. 3, pp. James, 2015. [2] Xiaowen Dong, Dorina Thanou, Pascal Frossard, and Pierre Vandergheynst, Gillacian matrix learning for smooth graph signal representation, in Proc. ICASSP, 2015. [3] Eduardo Pavez and Antonio Ortega \"Generalized laplacian precision matrix estimation for graph signal processing,\" in Proc. ICASSP, 2016] Vassilis Kalofolias, \"How to learn a graph from smooth signals,\" in AISTATS 2016, 2016."}], "references": [{"title": "The emerging field of signal processing on graphs: Extending high-dimensional data analysis to networks and other irregular domains", "author": ["David Shuman", "Sunil K Narang", "Pascal Frossard", "Antonio Ortega", "Pierre Vandergheynst"], "venue": "Signal Processing Magazine, IEEE, vol. 30, no. 3, pp. 83\u201398, 2013.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2013}, {"title": "Laplacian matrix learning for smooth graph signal representation", "author": ["Xiaowen Dong", "Dorina Thanou", "Pascal Frossard", "Pierre Vandergheynst"], "venue": "Proc. ICASSP, 2015.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2015}, {"title": "Generalized laplacian precision matrix estimation for graph signal processing", "author": ["Eduardo Pavez", "Antonio Ortega"], "venue": "Proc. ICASSP, 2016.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2016}, {"title": "How to learn a graph from smooth signals", "author": ["Vassilis Kalofolias"], "venue": "AISTATS 2016, 2016.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2016}, {"title": "Neural correlates of the food/nonfood visual distinction", "author": ["Kleovoulos Tsourides", "Shahriar Shariat", "Hossein Nejati", "Tapan K Gandhi", "Annie Cardinaux", "Christopher T Simons", "Ngai-Man Cheung", "Vladimir Pavlovic", "Pawan Sinha"], "venue": "Biological Psychology, 2016.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2016}, {"title": "Towards perception awareness: Perceptual event detection for brain computer interfaces", "author": ["H. Nejati", "K. Tsourides", "V. Pomponiu", "E.C. Ehrenberg", "Ngai-Man Cheung", "P. Sinha"], "venue": "EMBC2015, Aug 2015, pp. 1480\u20131483.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "Complex brain networks: graph theoretical analysis of structural and functional systems", "author": ["Ed Bullmore", "Olaf Sporns"], "venue": "Nature Reviews Neuroscience, vol. 10, no. 3, pp. 186\u2013198, 2009.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2009}, {"title": "Cross-correlation: an fmri signal-processing strategy", "author": ["James S Hyde", "Andrzej Jesmanowicz"], "venue": "NeuroImage, vol. 62, no. 2, pp. 848\u2013851, 2012.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Beta oscillations in a largescale sensorimotor cortical network: directional influences revealed by granger causality", "author": ["Andrea Brovelli", "Mingzhou Ding", "Anders Ledberg", "Yonghong Chen", "Richard Nakamura", "Steven L Bressler"], "venue": "Proceedings of the National Academy of Sciences of the United States of America, vol. 101, no. 26, pp. 9849\u20139854, 2004.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2004}, {"title": "Distributed optimization and statistical learning via the alternating direction method of multipliers", "author": ["Stephen Boyd", "Neal Parikh", "Eric Chu", "Borja Peleato", "Jonathan Eckstein"], "venue": "Foundations and Trends in Machine Learning, vol. 3, no. 1, pp. 1\u2013122, 2011.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2011}, {"title": "A graph theoretical regression model for brain connectivity learning of alzheimer\u2019s disease", "author": ["Chenhui Hu", "Lin Cheng", "Jorge Sepulcre", "Georges El Fakhri", "Yue M. Lu", "Quanzheng Li"], "venue": "ISBI2013, San Francisco, CA, 7-11 Apr. 2013.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2013}, {"title": "Graph-Laplacian PCA: Closed-form solution and robustness", "author": ["Bo Jiang", "Chris Ding", "Bin Luo", "Jin Tang"], "venue": "CVPR, 2013, pp. 3490\u201334968.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2013}, {"title": "Robust principal component analysis on graphs", "author": ["Nauman Shahid", "Vassilis Kalofolias", "Xavier Bresson", "Michael Bronstein", "Pierre Vandergheynst"], "venue": "Proceedings of International Conference on Computer Vision, Santiago, Chile, 2015, pp. 2812\u20132820.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2015}, {"title": "Fast robust PCA on graphs", "author": ["Nauman Shahid", "Nathanael Perraudin", "Vassilis Kalofolias", "Gilles Puy", "Pierre Vandergheynst"], "venue": "arXiv:1507.08173v2 [cs.CV] 25 Jan 2016, pp. 1\u201317, 2016.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2016}, {"title": "Graph frequency analysis of brain signals", "author": ["Weiyu Huang", "Leah Goldsberry", "Nicholas F Wymbs", "Scott T Grafton", "Danielle S Bassett", "Alejandro Ribeiro"], "venue": "arXiv preprint arXiv:1512.00037v2, 2016.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2016}, {"title": "Dimensionality reduction of brain imaging data using graph signal processing", "author": ["Liu Rui", "Hossein Nejati", "Ngai-Man Cheung"], "venue": "ICIP. IEEE, 2016, pp. 1329\u20131333.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2016}, {"title": "Anatomically-adapted graph wavelets for improved group-level fmri activation mapping", "author": ["Hamid Behjat", "Nora Leonardi", "Leif S\u00f6rnmo", "Dimitri Van De Ville"], "venue": "NeuroImage, vol. 123, pp. 185\u2013199, 2015.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2015}, {"title": "Multiresolution graph fourier transform for compression of piecewise smooth images", "author": ["Wei Hu", "Gene Cheung", "Antonio Ortega", "Oscar C Au"], "venue": "Image Processing, IEEE Transactions on, vol. 24, no. 1, pp. 419\u2013433, 2015.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2015}, {"title": "Spectral anomaly detection using graph-based filtering for wireless sensor networks", "author": ["Hilmi E Egilmez", "Antonio Ortega"], "venue": "ICASSP. IEEE, 2014, pp. 1085\u20131089.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "Inference of mobility patterns via spectral graph wavelets", "author": ["Xiaowen Dong", "Antonio Ortega", "Pascal Frossard", "Pierre Vandergheynst"], "venue": "ICASSP. IEEE, 2013, pp. 3118\u20133122.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2013}, {"title": "A complex network based feature extraction for image retrieval", "author": ["Jieqi Kang", "Shan Lu", "Weibo Gong", "Patrick A Kelly"], "venue": "ICIP. IEEE, 2014, pp. 2051\u20132055.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2014}, {"title": "Laplacian eigenmaps for dimensionality reduction and data representation", "author": ["M. Belkin", "P. Niyogi"], "venue": "Neural Computation, vol. 15, no. 6, pp. 1373\u20131396, 2003.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2003}, {"title": "Locality preserving projection", "author": ["Xiaofei He", "Partha Niyogi"], "venue": "Proceedings of NIPS, 2003.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2003}, {"title": "Graph embedding and extensions: a general framework for dimensionality reduction", "author": ["Shuicheng Yan", "Dong Xu", "Benyu Zhang", "Stephen Lin"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, 2007.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2007}, {"title": "Robust principal component analysis", "author": ["Emmanuel J. Cand\u00e8s", "Xiaodong Li", "Yi Ma", "John Wright"], "venue": "Journal of the ACM, vol. 58, no. 3, pp. 11:1\u201311:37, May 2011.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2011}, {"title": "Learning laplacian matrix in smooth graph signal representations", "author": ["Xiaowen Dong", "Dorina Thanou", "Pascal Frossard", "Pierre Vandergheynst"], "venue": "arXiv preprint arXiv:1406.7842v3, 2014.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2014}, {"title": "Whole brain functional connectivity using phase locking measures of resting state magnetoencephalography", "author": ["Benjamin T Schmidt", "Avniel S Ghuman", "Theodore J Huppert"], "venue": "Front. Neurosci, vol. 8, no. 141, pp. 10\u20133389, 2014.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2014}, {"title": "Visual neurones responsive to faces", "author": ["David I. Perrett", "Amanda J. Mistlin", "Andrew J. Chitty"], "venue": "Trends in Neurosciences, vol. 10, no. 9, pp. 358 \u2013 364, 1987.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 1987}, {"title": "Speed of processing in the human visual system", "author": ["S. Thorpe", "D. Fize", "C. Marlot"], "venue": "Nature, vol. 381, no. 6582, pp. 520\u20132, 1996.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1996}, {"title": "Stages of processing in face perception: an MEG study", "author": ["Jia Liu", "Alison Harris", "Nancy Kanwisher"], "venue": "Nature neuroscience, vol. 5, no. 9, pp. 910\u2013916, Sept. 2002.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2002}, {"title": "Face-selective cells in the temporal cortex of monkeys", "author": ["R. Desimone"], "venue": "Journal of Cognitive Neuroscience, vol. 3, no. 1, pp. 1\u20138, Jan. 2006.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2006}, {"title": "An analytical model for synthesis distortion estimation in 3d video", "author": ["Lu Fang", "Ngai-Man Cheung", "D Tian", "A Vetro", "H Sun", "O Au"], "venue": "IEEE Transactions on Image Processing, vol. 23, no. 1, pp. 185\u2013199, 2014.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "We further focus on data that resides on a certain graph and the data changes smoothly between the connected vertices [1].", "startOffset": 118, "endOffset": 121}, {"referenceID": 1, "context": "In many problems, the underlying graph is unknown or inexact [2, 3, 4].", "startOffset": 61, "endOffset": 70}, {"referenceID": 2, "context": "In many problems, the underlying graph is unknown or inexact [2, 3, 4].", "startOffset": 61, "endOffset": 70}, {"referenceID": 3, "context": "In many problems, the underlying graph is unknown or inexact [2, 3, 4].", "startOffset": 61, "endOffset": 70}, {"referenceID": 4, "context": "In many cases, the task is to find the spatiotemporal neural signature of a task, by performing classification on cortical activations evoked by different stimuli [5, 6].", "startOffset": 163, "endOffset": 169}, {"referenceID": 5, "context": "In many cases, the task is to find the spatiotemporal neural signature of a task, by performing classification on cortical activations evoked by different stimuli [5, 6].", "startOffset": 163, "endOffset": 169}, {"referenceID": 6, "context": "Note that it has been recognized that there are patterns of anatomical links, or statistical dependencies or causal interactions between distinct units within a nervous system [7].", "startOffset": 176, "endOffset": 179}, {"referenceID": 7, "context": "Some techniques have also been developed to estimate this brain connectivity graph [8, 9].", "startOffset": 83, "endOffset": 89}, {"referenceID": 8, "context": "Some techniques have also been developed to estimate this brain connectivity graph [8, 9].", "startOffset": 83, "endOffset": 89}, {"referenceID": 9, "context": "Specifically, our contributions are: (i) based on a model with a low-rank component plus a sparse perturbation, and an initial graph estimation, we propose an algorithm to simultaneously learn the lowrank component and the graph; (ii) we derive the learning steps using ADMM [10]; (iii) we evaluate the algorithm using synthetic and real brain imaging data in a supervised classification task.", "startOffset": 275, "endOffset": 279}, {"referenceID": 1, "context": "This work is inspired by [2].", "startOffset": 25, "endOffset": 28}, {"referenceID": 1, "context": "While the focus of [2] is to learn the connectivity graph topology, their algorithm also estimates some noise-free version of the input data as by-product.", "startOffset": 19, "endOffset": 22}, {"referenceID": 1, "context": "Gaussian noise model and Frobenius norm optimization are employed in [2].", "startOffset": 69, "endOffset": 72}, {"referenceID": 1, "context": "In our work, starting from a model with a low-rank component plus a sparse perturbation, and an initial graph estimation, we adopt the idea of [2] to incrementally refine the underlying connectivity graph, thereby better low-rank estimation of the data can be obtained.", "startOffset": 143, "endOffset": 146}, {"referenceID": 1, "context": "In addition to [2], learning a graph from smooth signals has attracted a fair amount of interests recently [3, 4].", "startOffset": 15, "endOffset": 18}, {"referenceID": 2, "context": "In addition to [2], learning a graph from smooth signals has attracted a fair amount of interests recently [3, 4].", "startOffset": 107, "endOffset": 113}, {"referenceID": 3, "context": "In addition to [2], learning a graph from smooth signals has attracted a fair amount of interests recently [3, 4].", "startOffset": 107, "endOffset": 113}, {"referenceID": 10, "context": "Estimation of the brain connectivity graph using a Gaussian noise model has been proposed in [11].", "startOffset": 93, "endOffset": 97}, {"referenceID": 11, "context": "On the other hand, focusing on low-rank estimation, some works have proposed to incorporate spectral graph regularization [12, 13, 14].", "startOffset": 122, "endOffset": 134}, {"referenceID": 12, "context": "On the other hand, focusing on low-rank estimation, some works have proposed to incorporate spectral graph regularization [12, 13, 14].", "startOffset": 122, "endOffset": 134}, {"referenceID": 13, "context": "On the other hand, focusing on low-rank estimation, some works have proposed to incorporate spectral graph regularization [12, 13, 14].", "startOffset": 122, "endOffset": 134}, {"referenceID": 14, "context": "In [15], graph Fourier transform is applied to decompose brain signals into low, medium, and high frequency components for analysis of functional brain networks properties.", "startOffset": 3, "endOffset": 7}, {"referenceID": 15, "context": "[16] uses the eigenvectors of the graph Laplacian to approximate the intrinsic subspace of high-dimensional brain imaging data.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[17] presents a graph based framework for fMRI brain activation mapping.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "Graph signal processing has also been shown to be useful in image compression [18], temperature data [2], wireless sensor data [19].", "startOffset": 78, "endOffset": 82}, {"referenceID": 1, "context": "Graph signal processing has also been shown to be useful in image compression [18], temperature data [2], wireless sensor data [19].", "startOffset": 101, "endOffset": 104}, {"referenceID": 18, "context": "Graph signal processing has also been shown to be useful in image compression [18], temperature data [2], wireless sensor data [19].", "startOffset": 127, "endOffset": 131}, {"referenceID": 19, "context": "A few signal features motivated by graph signal processing have also been proposed [20, 21].", "startOffset": 83, "endOffset": 91}, {"referenceID": 20, "context": "A few signal features motivated by graph signal processing have also been proposed [20, 21].", "startOffset": 83, "endOffset": 91}, {"referenceID": 21, "context": "Laplacian of the sample affinity graphs [22, 23, 24] These methods are geometrically motivated, aim to preserve the local structures of the data, and involve different algorithms compared to our work.", "startOffset": 40, "endOffset": 52}, {"referenceID": 22, "context": "Laplacian of the sample affinity graphs [22, 23, 24] These methods are geometrically motivated, aim to preserve the local structures of the data, and involve different algorithms compared to our work.", "startOffset": 40, "endOffset": 52}, {"referenceID": 23, "context": "Laplacian of the sample affinity graphs [22, 23, 24] These methods are geometrically motivated, aim to preserve the local structures of the data, and involve different algorithms compared to our work.", "startOffset": 40, "endOffset": 52}, {"referenceID": 24, "context": "[25] addressed the first issue by designing Robust PCA, which is robust to outliers by directly recovering the low-rank matrix L from the grossly corrupted X:", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": ", the graph is estimated from the noisy data itself [13, 14]).", "startOffset": 52, "endOffset": 60}, {"referenceID": 13, "context": ", the graph is estimated from the noisy data itself [13, 14]).", "startOffset": 52, "endOffset": 60}, {"referenceID": 9, "context": "At the first step, for a given \u03a6f , we solve the following optimization problem using ADMM[10] with respect to L and M.", "startOffset": 90, "endOffset": 94}, {"referenceID": 25, "context": "We compare the proposed method, GL-SigRep[26], RPCAG[13], RPCA[25], and PCA on the data to estimate the low rank matrix and the graph matrix.", "startOffset": 41, "endOffset": 45}, {"referenceID": 12, "context": "We compare the proposed method, GL-SigRep[26], RPCAG[13], RPCA[25], and PCA on the data to estimate the low rank matrix and the graph matrix.", "startOffset": 52, "endOffset": 56}, {"referenceID": 24, "context": "We compare the proposed method, GL-SigRep[26], RPCAG[13], RPCA[25], and PCA on the data to estimate the low rank matrix and the graph matrix.", "startOffset": 62, "endOffset": 66}, {"referenceID": 13, "context": "All the methods are initialized with the same feature similarity graph (consider each row of X as a node) computed using the procedure in [14] with a K-nearest neighbor strategy (K = 10).", "startOffset": 138, "endOffset": 142}, {"referenceID": 6, "context": "Structural connectivity shows the anatomical structure in the brain; functional connectivity quantifies functional dependencies between different brain regions; and effective connectivity shows directed or causal relationship between different brain regions [7].", "startOffset": 258, "endOffset": 261}, {"referenceID": 15, "context": "In this paper we use a coherence connectivity, a functional connectivity, quantifying oscillatory interdependency between different brain regions [16].", "startOffset": 146, "endOffset": 150}, {"referenceID": 26, "context": "Given two series of signals at, bt and a frequency f , the first step is to spectrally decompose the signal at target f to obtain the instantaneous phase at each time point [27].", "startOffset": 173, "endOffset": 177}, {"referenceID": 27, "context": "see [28, 29, 30, 31]).", "startOffset": 4, "endOffset": 20}, {"referenceID": 28, "context": "see [28, 29, 30, 31]).", "startOffset": 4, "endOffset": 20}, {"referenceID": 29, "context": "see [28, 29, 30, 31]).", "startOffset": 4, "endOffset": 20}, {"referenceID": 30, "context": "see [28, 29, 30, 31]).", "startOffset": 4, "endOffset": 20}, {"referenceID": 28, "context": "see [29, 31]).", "startOffset": 4, "endOffset": 12}, {"referenceID": 30, "context": "see [29, 31]).", "startOffset": 4, "endOffset": 12}, {"referenceID": 27, "context": "In several studies such as [28, 30], the fusiform gyrus (at the occipitotemporal region) are suggested for processing face perception during about 145ms after presentation of a face image stimuli, also known as N170 marker (named after its first discovery at 170ms in EEG studies).", "startOffset": 27, "endOffset": 35}, {"referenceID": 29, "context": "In several studies such as [28, 30], the fusiform gyrus (at the occipitotemporal region) are suggested for processing face perception during about 145ms after presentation of a face image stimuli, also known as N170 marker (named after its first discovery at 170ms in EEG studies).", "startOffset": 27, "endOffset": 35}, {"referenceID": 31, "context": "Future work applies the proposed algorithm for other high-dimensional data [32].", "startOffset": 75, "endOffset": 79}], "year": 2017, "abstractText": "We propose an algorithm to uncover the intrinsic low-rank component of a high-dimensional, graph-smooth and grossly-corrupted dataset, under the situations that the underlying graph is unknown. Based on a model with a low-rank component plus a sparse perturbation, and an initial graph estimation, our proposed algorithm simultaneously learns the low-rank component and refines the graph. The refined graph improves the effectiveness of the graph smoothness constraint and increases the accuracy of the low-rank estimation. We derive the learning steps using ADMM. Our evaluations using synthetic and real brain imaging data in a supervised classification task demonstrate encouraging performance.", "creator": "LaTeX with hyperref package"}}}