{"id": "1609.08264", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Sep-2016", "title": "Top-N Recommendation on Graphs", "abstract": "Recommender systems play an increasingly important role in online applications to help users find what they need or prefer. Collaborative filtering algorithms that generate predictions by analyzing the user-item rating matrix perform poorly when the matrix is sparse. To alleviate this problem, this paper proposes a simple recommendation algorithm that fully exploits the similarity information among users and items and intrinsic structural information of the user-item matrix. The proposed method constructs a new representation which preserves affinity and structure information in the user-item rating matrix and then performs recommendation task. To capture proximity information about users and items, two graphs are constructed. Manifold learning idea is used to constrain the new representation to be smooth on these graphs, so as to enforce users and item proximities. Our model is formulated as a convex optimization problem, for which we need to solve the well-known Sylvester equation only. We carry out extensive empirical evaluations on six benchmark datasets to show the effectiveness of this approach.", "histories": [["v1", "Tue, 27 Sep 2016 05:45:03 GMT  (95kb,D)", "http://arxiv.org/abs/1609.08264v1", "CIKM 2016"]], "COMMENTS": "CIKM 2016", "reviews": [], "SUBJECTS": "cs.IR cs.AI", "authors": ["zhao kang", "chong peng", "ming yang", "qiang cheng"], "accepted": false, "id": "1609.08264"}, "pdf": {"name": "1609.08264.pdf", "metadata": {"source": "CRF", "title": "Top-N Recommendation on Graphs", "authors": ["Zhao Kang", "Chong Peng", "Ming Yang", "Qiang Cheng"], "emails": ["qcheng}@siu.edu"], "sections": [{"heading": null, "text": "Keywords Top-N recommendation; laplactic graph; collaborative filtering"}, {"heading": "1. INTRODUCTION", "text": "In many applications, recommendation systems have become increasingly indispensable. However, collaborative filtering (CF) based methods are a fundamental building block in many recommendation systems. CF based recommendation systems predict the ratings of items that are evaluated by a user based on the ratings of items previously evaluated by other users that are most similar to the target user. However, CF-based methods can be categorized into memory-based methods [21] and model-based methods suggested by users [14, 15]. The former includes two popular methods, user-oriented [9] and item-oriented, e.g. ItemKNN [6], depending on whether the TheACM ISBN 978-1-4503-4503 methods proposed by users are used. The former has two popular methods, user-oriented [9] and item-oriented, e.g., ItemKNN [6] depending on whether these user-oriented methods are predicted in B504504503-ISN."}, {"heading": "2. DEFINITIONS AND NOTATIONS", "text": "Let U = {u1, u2,..., to} and T = {t1, t2,..., tn} represent the quantities of all users or all articles respectively. The entire set of user article purchases / reviews is represented by the user article matrix X of size m \u00b7 n. Element xij is 1 or a positive value if user ui has ever bought / rated article tj, otherwise it is marked as 0. The i-th line of X denotes the purchase / rating history of user ui on all articles. The j-th column of X is the purchase / rating history of all users on article tj."}, {"heading": "3. PROPOSED MODEL", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 User and Item Graphs", "text": "It is based on the well-known manifold premise [18]: If two data points such as xi and xj are manifold in the geodesic distance on the data, then their corresponding representations yi and yj are also close to each other. In practice, it is difficult to estimate the global manifold structure of the data due to the insufficient number of samples and the high dimensionality of the ambient space. Therefore, many methods resort to local manifold structures."}, {"heading": "3.2 Model", "text": "The last two terms measure the smoothness of the predicted ratings on the graph structures and encourage the ratings of nodes with affinity to be similar. They can mitigate the problem of data sparseness to some extent. If the article neighbourhood information is not available, neighbourhood information of the user could exist, vice versa. Parameters \u03b1 and \u03b2 align the equilibrium between the reconstruction error and the regulations of diagrams. By setting the derivation of the objective function from (2) to zero with respect to Y, we have (\u03b2Lr + I) Y + \u03b1Y Lc = X. (3) Equation (3) is the well-known Sylvester equation, the costs O (m3) or O (n3) for a general situation (X) or extremely solvable packages (are not available in rule O)."}, {"heading": "4. CONNECTION TO EXISTING WORK", "text": "To the best of our knowledge, there are very few studies on the Laplazian graph in the context of the task of recommendation. Graph regulates the weighted non-negative matrix factorization (GWNMF) [7] to include the neighborhood information in an MF approach. It solves the following problem in U, V, M (X \u2212 UV T), 2F + \u03b1Tr (U T LrU) + \u03b2Tr (V T LcV) s.t. U \u2265 0, (4), where M is an indicator matrix. U and V T are located in latent spaces whose dimensionality is usually specified by an additional parameter. The latent factors are generally not obvious and may not necessarily be interpretable or intuitively understandable. Here (4) both the user and the item representation must be learned in the latent spaces. In our approach we only need to learn a representation, and therefore the learning process is simplified."}, {"heading": "5. EXPERIMENTAL EVALUATION", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Datasets", "text": "Table 1 shows the characteristics of the datasets. Delicious, lastfm and BX have only implicit feedback. Delicious comes in particular from the bookmarking and tagging information1, in which each URL was bookmarked by at least 3 users. Lastfm represents music artists listening to information2, in which each music artist was listened to by at least 10 users and each user listened to at least 5 artists. BX is derived from Book Crossing dataset 3, so only implicit interactions were included and each book was read by at least 10 users. FilmTrust, Netflix and Yahoo! dataset contain multi-value ratings. Specifically, FilmTrust is a dataset that swirls through the entire FilmTrust website.4 Netflix is derived from Netflix price datasat5 and each user rated at least 10 movies. The Yahoo! dataset is a subset that is rated by Yahoo! Movies Users. 6 In this dataset, each user rated at least 5 and each movie was rated by each user."}, {"heading": "5.2 Evaluation Methodology", "text": "In order to make a fair comparison, we follow the data set preparation approach used by SLIM [17] and use 5-fold cross-validation. For each convolution, one data set is divided into training and test sets by randomly selecting one entry for each user outside of the zero point and inserting it into the test set while the remaining data is used for training. Subsequently, a ranking of the size N items is created for each user. Afterwards, we evaluate the method by comparing the ranking of the recommended items with the item in the test set. In the results presented in this essay, N is equal by default to 10. For Top N recommendations, the most direct and meaningful indicators are hit rate (HR) and average mutual hit rank (ARHR) [6], as it is only important to users whether a short recommendation list contains the interesting items or not, instead of a very long recommendation list."}, {"heading": "6. EXPERIMENTAL RESULTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.1 Top-N Recommendation Performance", "text": "We use 5-fold cross-validation to select parameters for all competing methods and their best performance in Table 2. It is evident that the HR improvements achieved with our method over the next best scheme (i.e. SLIM) on lastfm, Yahoo, BX, FilmTrust datasets are quite size.7 For Delicious and Netflix datasets, our 1http: / / www.delicious.com 2 http: / / www.last.fm 3http: / / www.informatik.uni-freiburg.de / cziegler / BX / 4http: / www.librec.net / datasets.html 5http: / / www.netflixprize.com / 6http: / / webscope.sandbox.yahoo.com / catalog.php? datatype = r 7Code is available at http: / / www.librec.net / datasets.html: / github.com / sckangz / CIKM16is close to the best performance between most of the other W.e. -1 methods, there is no difference in most of the 10 cases."}, {"heading": "6.2 Parameter Effects", "text": "Figure 2 shows the effects of different alpha and \u03b2 values on HR and ARHR for FilmTrust and Yahoo datasets. The search for \u03b1 ranges from 1e-6 to 1e-2 with dots of {1e-6, 1e-5, 1e-4, 1e-3, 1e-2}, the search for \u03b2 of {1e-6, 1e-4, 1e-2}. As can be seen from all numbers, our algorithm behaves well over a wide range of alpha and \u03b2 values. HR and ARHR share the same trend with different alpha and \u03b2 values. Especially when \u03b1 is small, HR and ARHR both rise with \u03b1. After a certain point they begin to decline. At FilmTrust, the performance with \u03b2 = 0.01 is very stable in relation to \u03b1. This indicates that the user resembles the similarity of the FilmTrust dataset."}, {"heading": "6.3 Matrix Reconstruction", "text": "To show how our method reconstructs the user item matrix, we compare it to the method of the next best performance, SLIM, on FilmTrust. The density of FilmTrust is 1.14% and the mean for these non-zero elements is 2,998. The reconstructed matrix X-SLIM of SLIM has a density of 83.21%. For these 1.14% non-zero entries in X, X-SLIM recovers 99.69% of them and their mean is 1,686. In contrast, the reconstructed matrix of our proposed algorithm has a density of 91.7%. For these 1.14% non-zero entries in X, our method recovers all of them with an average of 2,975. These facts suggest that our method reconstructs X better than SLIM. In other words, SLIM loses too much information. This seems to explain the superior performance of our method. In fact, the above analysis corresponds to the two widely used pre-obtained accuracies: This LIM reconstructs better than SLIM."}, {"heading": "6.4 Graph Construction", "text": "10 50 200 500 800 k0.30.350.40.450.50.550.60.650.7A, in fact, acyHR ARHRFigure 3: Influence of neighborhood size k on recommendation accuracy for FilmTrust datasets. As we discussed earlier, similarity is an important component of graph construction. In many recommendation algorithms, similarity calculation is critical for recommendation quality [8]. To demonstrate the importance of similarity metrics, we use the cosine coefficient instead of the Jaccard coefficient to measure similarity in binary datasets. We compare the results in Table 3. As demonstrated, for load fm datasets, HR and ARHR increase after we adopt the cosmic similarity. However, for Delicious and BX datasets, the Jaccard coefficient works better. Therefore, the difference in end results may be large for certain datasets with different similarity scales."}, {"heading": "6.5 Effects of User and Item Graphs", "text": "We use FilmTrust and Yahoo data sets as examples to show the impact of user and item charts. Table 4 summarizes the HR values obtained with user charts, item charts, and user and item charts. It shows that we are able to achieve the best performance when we combine user and item charts. Thus, user and item neighborhood information can alleviate the problem of data economy by using structural information more comprehensively, which in turn improves recommendation accuracy."}, {"heading": "7. CONCLUSION", "text": "We reconstruct the user item matrix by fully exploiting the similarity information between users and items at the same time. Furthermore, the reconstructed data matrix also respects the diverse structure of the user item matrix. We conduct a comprehensive series of experiments and compare our method with other state-of-the-art Top N recommendation algorithms, and the results show that the proposed algorithm works effectively. Due to the simplicity of our model, there is much room for improvement. For example, our model can be easily expanded by using graph representation to include ancillary information (e.g. user demographic information, item genre, social trust network). In some cases, external information is more informative than neighbourhood information."}, {"heading": "8. ACKNOWLEDGMENTS", "text": "This work is supported by the US National Science Foundation under Grant IIS 1218712, the National Natural Science Foundation of China under Grant 11241005 and the Shanxi Scholarship Council of China 2015-093. Q. Cheng is the corresponding author."}, {"heading": "9. REFERENCES", "text": "[1] G. Adomavicius and A. Tuzhilin have spoken out against the nextgeneration of recommendor systems: An overview of the state of art and its possible extensions. Knowledge and Data Engineering, IEEE Transactions on, 17 (6): 734-749, 2005. [2] P. Benner, R.-C. Li, and N. Truhar. On the other hand, the method for collaborative equations. Journal of Computational and Applied Mathematics, 233 (4): 1035-1045, F. Cacheda, V. Carneiro, D. Fern\u00e1ndez, and V. Formoso. Comparison of Collaborative Filtering Algorithms: Limitations of current techniques and Applied Mathematics, 233 (4)."}], "references": [{"title": "Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions", "author": ["G. Adomavicius", "A. Tuzhilin"], "venue": "Knowledge and Data Engineering, IEEE Transactions on, 17(6):734\u2013749,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2005}, {"title": "On the adi method for sylvester equations", "author": ["P. Benner", "R.-C. Li", "N. Truhar"], "venue": "Journal of Computational and Applied Mathematics, 233(4):1035\u20131045,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2009}, {"title": "Comparison of collaborative filtering algorithms: Limitations of current techniques and proposals for scalable, high-performance recommender systems", "author": ["F. Cacheda", "V. Carneiro", "D. Fern\u00e1ndez", "V. Formoso"], "venue": "ACM Transactions on the Web, 5(1):2,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2011}, {"title": "Graph regularized nonnegative matrix factorization for data representation", "author": ["D. Cai", "X. He", "J. Han", "T.S. Huang"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on, 33(8):1548\u20131560,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2011}, {"title": "Performance of recommender algorithms on top-n recommendation tasks", "author": ["P. Cremonesi", "Y. Koren", "R. Turrin"], "venue": "RecSys, pages 39\u201346. ACM,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2010}, {"title": "Item-based top-n recommendation algorithms", "author": ["M. Deshpande", "G. Karypis"], "venue": "ACM Transactions on Information Systems (TOIS), 22(1):143\u2013177,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2004}, {"title": "Collaborative filtering: Weighted nonnegative matrix factorization incorporating user and item graphs", "author": ["Q. Gu", "J. Zhou", "C.H. Ding"], "venue": "SDM, pages 199\u2013210. SIAM,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2010}, {"title": "A novel bayesian similarity measure for recommender systems", "author": ["G. Guo", "J. Zhang", "N. Yorke-Smith"], "venue": "IJCAI, pages 2619\u20132625. AAAI Press,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2013}, {"title": "An algorithmic framework for performing collaborative filtering", "author": ["J.L. Herlocker", "J.A. Konstan", "A. Borchers", "J. Riedl"], "venue": "SIGIR, pages 230\u2013237. ACM,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1999}, {"title": "Collaborative filtering for implicit feedback datasets", "author": ["Y. Hu", "Y. Koren", "C. Volinsky"], "venue": "ICDM, pages 263\u2013272. IEEE,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2008}, {"title": "A new simplex sparse learning model to measure data similarity for clustering", "author": ["J. Huang", "F. Nie", "H. Huang"], "venue": "Proceedings of the 24th International Conference on Artificial Intelligence, pages 3569\u20133575. AAAI Press,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2015}, {"title": "Top-n recommendation with novel rank approximation", "author": ["Z. Kang", "Q. Cheng"], "venue": "SDM, pages 126\u2013134. SIAM,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2016}, {"title": "Robust subspace clustering via tighter rank approximation", "author": ["Z. Kang", "C. Peng", "Q. Cheng"], "venue": "CIKM, pages 393\u2013401. ACM,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2015}, {"title": "Top-n recommender system via matrix completion", "author": ["Z. Kang", "C. Peng", "Q. Cheng"], "venue": "Thirtieth AAAI Conference on Artificial Intelligence,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2016}, {"title": "Efficient retrieval of recommendations in a matrix factorization framework", "author": ["N. Koenigstein", "P. Ram", "Y. Shavitt"], "venue": "CIKM, pages 535\u2013544. ACM,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2012}, {"title": "A new user similarity model to improve the accuracy of collaborative filtering", "author": ["H. Liu", "Z. Hu", "A. Mian", "H. Tian", "X. Zhu"], "venue": "Knowledge-Based Systems, 56:156\u2013166,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2014}, {"title": "Slim: Sparse linear methods for top-n recommender systems", "author": ["X. Ning", "G. Karypis"], "venue": "ICDM, pages 497\u2013506. IEEE,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2011}, {"title": "Locality preserving projections", "author": ["X. Niyogi"], "venue": "NIPS, volume 16, page 153. MIT,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2004}, {"title": "Bpr: Bayesian personalized ranking from implicit feedback", "author": ["S. Rendle", "C. Freudenthaler", "Z. Gantner", "L. Schmidt-Thieme"], "venue": "UAI, pages 452\u2013461. AUAI Press,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2009}, {"title": "Nonlinear dimensionality reduction by locally linear embedding", "author": ["S.T. Roweis", "L.K. Saul"], "venue": "Science, 290(5500):2323\u20132326,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2000}, {"title": "Item-based collaborative filtering recommendation algorithms", "author": ["B. Sarwar", "G. Karypis", "J. Konstan", "J. Riedl"], "venue": "WWW, pages 285\u2013295. ACM,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2001}], "referenceMentions": [{"referenceID": 0, "context": "Recommender systems have become increasingly indispensable in many applications [1].", "startOffset": 80, "endOffset": 83}, {"referenceID": 20, "context": "CF based methods can be classified into memory-based methods [21] and model-based methods [14, 15].", "startOffset": 61, "endOffset": 65}, {"referenceID": 13, "context": "CF based methods can be classified into memory-based methods [21] and model-based methods [14, 15].", "startOffset": 90, "endOffset": 98}, {"referenceID": 14, "context": "CF based methods can be classified into memory-based methods [21] and model-based methods [14, 15].", "startOffset": 90, "endOffset": 98}, {"referenceID": 8, "context": "The former includes two popular methods, user-oriented [9] and item-oriented, e.", "startOffset": 55, "endOffset": 58}, {"referenceID": 5, "context": ", ItemKNN [6], depending on whether the", "startOffset": 10, "endOffset": 13}, {"referenceID": 2, "context": "However, it suffers from several problems, including data sparsity, cold start and data correlation [3], as users typically rate only a small portion of the available items, and they also tend to rate similar items closely.", "startOffset": 100, "endOffset": 103}, {"referenceID": 4, "context": ", PureSVD [5] and weighted regularized MF (WRMF) [10], are very popular due to their capability of capturing the implicit relationships among items and their outstanding performance.", "startOffset": 10, "endOffset": 13}, {"referenceID": 9, "context": ", PureSVD [5] and weighted regularized MF (WRMF) [10], are very popular due to their capability of capturing the implicit relationships among items and their outstanding performance.", "startOffset": 49, "endOffset": 53}, {"referenceID": 6, "context": "Because the rating matrix is sparse, the factorization of the user-item matrix may lead to inferior solutions [7].", "startOffset": 110, "endOffset": 113}, {"referenceID": 12, "context": "By learning an aggregation coefficient matrix [13], recently, sparse linear method (SLIM) [17] has been proposed and shown to be effective.", "startOffset": 46, "endOffset": 50}, {"referenceID": 16, "context": "By learning an aggregation coefficient matrix [13], recently, sparse linear method (SLIM) [17] has been proposed and shown to be effective.", "startOffset": 90, "endOffset": 94}, {"referenceID": 11, "context": "However, it just captures relations between items that have been co-purchased/co-rated by at least one user [12].", "startOffset": 108, "endOffset": 112}, {"referenceID": 18, "context": "For instance, BPRMF and BPRKNN [19] have been demonstrated to be effective for implicit feedback datasets.", "startOffset": 31, "endOffset": 35}, {"referenceID": 19, "context": "To preserve local geometric and discriminating structures embedded in a high-dimensional space, numerous manifold learning methods, such as locally linear embedding (LLE) [20], locality preserving projection (LPP) [18], have been proposed.", "startOffset": 171, "endOffset": 175}, {"referenceID": 17, "context": "To preserve local geometric and discriminating structures embedded in a high-dimensional space, numerous manifold learning methods, such as locally linear embedding (LLE) [20], locality preserving projection (LPP) [18], have been proposed.", "startOffset": 214, "endOffset": 218}, {"referenceID": 3, "context": "In recent years, graph regularization based nonnegative matrix factorization [4] of data representation has been developed to remedy the failure in representing geometric structures in data.", "startOffset": 77, "endOffset": 80}, {"referenceID": 17, "context": "It is based on the well known manifold assumption [18]: If two data points such as xi and xj are close in the geodesic distance on the data manifold, then their corresponding representations yi and yj are also close to each other.", "startOffset": 50, "endOffset": 54}, {"referenceID": 17, "context": "Much effort on manifold learning [18] has shown that local geometric structures of the data manifold can be effectively modeled through a nearest neighbor graph on sampled data points.", "startOffset": 33, "endOffset": 37}, {"referenceID": 20, "context": "There exist a number of different similarity metrics in the literature [21], e.", "startOffset": 71, "endOffset": 75}, {"referenceID": 1, "context": "But in our situation, X is usually extremely sparse, and Lr and Lc can also be sparse, especially for large m and n, so the cost can be O(m) or O(n), or sometimes even as low as O(m) or O(n) [2].", "startOffset": 191, "endOffset": 194}, {"referenceID": 6, "context": "Graph regularized weighted nonnegative matrix factorization (GWNMF) [7] was proposed to incorporate the neighborhood information in a MF approach.", "startOffset": 68, "endOffset": 71}, {"referenceID": 16, "context": "For fair comparison, we follow the dataset preparation approach used by SLIM [17] and adopt the 5-fold cross validation.", "startOffset": 77, "endOffset": 81}, {"referenceID": 5, "context": "For Top-N recommendation, the most direct and meaningful metrics are hit-rate (HR) and the average reciprocal hit-rank (ARHR) [6], since the users only care if a short recommendation list contains the items of interest or not rather than a very long recommendation list.", "startOffset": 126, "endOffset": 129}, {"referenceID": 7, "context": "In many recommendation algorithms, the similarity computation is crucial to the recommendation quality [8].", "startOffset": 103, "endOffset": 106}, {"referenceID": 5, "context": "For example, it has been reported that normalizing the similarity scores can improve the performance [6].", "startOffset": 101, "endOffset": 104}, {"referenceID": 15, "context": ", [16], which may be also exploited.", "startOffset": 2, "endOffset": 6}, {"referenceID": 10, "context": "Another important parameter is the neighborhood size k, which cannot be known a priori [11].", "startOffset": 87, "endOffset": 91}], "year": 2016, "abstractText": "Recommender systems play an increasingly important role in online applications to help users find what they need or prefer. Collaborative filtering algorithms that generate predictions by analyzing the user-item rating matrix perform poorly when the matrix is sparse. To alleviate this problem, this paper proposes a simple recommendation algorithm that fully exploits the similarity information among users and items and intrinsic structural information of the user-item matrix. The proposed method constructs a new representation which preserves affinity and structure information in the user-item rating matrix and then performs recommendation task. To capture proximity information about users and items, two graphs are constructed. Manifold learning idea is used to constrain the new representation to be smooth on these graphs, so as to enforce users and item proximities. Our model is formulated as a convex optimization problem, for which we need to solve the well known Sylvester equation only. We carry out extensive empirical evaluations on six benchmark datasets to show the effectiveness of this approach.", "creator": "LaTeX with hyperref package"}}}