{"id": "1609.08359", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Sep-2016", "title": "emoji2vec: Learning Emoji Representations from their Description", "abstract": "Many current natural language processing applications for social media rely on representation learning and utilize pre-trained word embeddings. There currently exist several publicly-available, pre-trained sets of word embeddings, but they contain few or no emoji representations even as emoji usage in social media has increased. In this paper we release emoji2vec, pre-trained embeddings for all Unicode emoji which are learned from their description in the Unicode emoji standard. The resulting emoji embeddings can be readily used in downstream social natural language processing applications alongside word2vec. We demonstrate, for the downstream task of sentiment analysis, that emoji embeddings learned from short descriptions outperforms a skip-gram model trained on a large collection of tweets, while avoiding the need for contexts in which emoji need to appear frequently in order to estimate a representation.", "histories": [["v1", "Tue, 27 Sep 2016 11:32:25 GMT  (2655kb,D)", "http://arxiv.org/abs/1609.08359v1", "7 pages, 4 figures, 1 table, In Proceedings of the 4th International Workshop on Natural Language Processing for Social Media at EMNLP 2016 (SocialNLP at EMNLP 2016)"], ["v2", "Sun, 20 Nov 2016 22:43:46 GMT  (2655kb,D)", "http://arxiv.org/abs/1609.08359v2", "7 pages, 4 figures, 1 table, In Proceedings of the 4th International Workshop on Natural Language Processing for Social Media at EMNLP 2016 (SocialNLP at EMNLP 2016)"]], "COMMENTS": "7 pages, 4 figures, 1 table, In Proceedings of the 4th International Workshop on Natural Language Processing for Social Media at EMNLP 2016 (SocialNLP at EMNLP 2016)", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["ben eisner", "tim rockt\\\"aschel", "isabelle augenstein", "matko bo\\v{s}njak", "sebastian riedel"], "accepted": false, "id": "1609.08359"}, "pdf": {"name": "1609.08359.pdf", "metadata": {"source": "CRF", "title": "emoji2vec: Learning Emoji Representations from their Description", "authors": ["Ben Eisner", "Tim Rockt\u00e4schel"], "emails": ["beisner@princeton.edu", "t.rocktaschel@ucl.ac.uk", "i.augenstein@ucl.ac.uk", "m.bosnjak@ucl.ac.uk", "s.riedel@ucl.ac.uk"], "sections": [{"heading": null, "text": "Many current applications for natural language processing on social media rely on learning representation and using pre-trained word embeddings. There are currently several publicly available, pre-trained sets of word embeddings, but they contain few or no emoji representations, even though emoji usage on social media has increased. In this post, we publish emoji2vec, pre-trained embeddings for all Unicode emojis that learn from their description in the Unicode emoji standard.1 The resulting emoji embeddings can easily be used in downstream natural language processing applications alongside word2vec. We show for the downstream task of mood analysis that emoji embeddings learned from short descriptions outperform a skip model trained on a large collection of tweets, while we avoid contexts where emojis often need to appear to assess representation."}, {"heading": "1 Introduction", "text": "The Oxford Dictionary named 2015 the1http: / / www.unicode.org / emoji / charts / full-emoji-list.htmlyear of the emoji, citing an increase in use of over 800% during the year of the year, and elected the \"Face with Tears of Joy'emoji () as the Word of the Year. In this letter, over 10% of Twitter posts and over 50% of text on Instagram contain one or more emojis (Cruse, 2015).2 Due to their popularity and wide use, they have been the subject of much formal and informal research in language and social communication, as well as in natural language processing (NLP).In the context of social sciences, research has focused on emoji use as a means of expressing emotions on platforms that we have found as universals."}, {"heading": "2 Related Work", "text": "The first research to be conducted in this direction was an informal blog post by the Instagram Data Team in 2015 (Dimson, 2015), which generated vector embedding for emojis that are similar to emojis that are based on skipping programs by training the entire corpus of Instagram posts. Their research provided valuable insights into the use of emojis on Instagram and showed that distributed representations can help understand the emojis semantics in everyday use. The second post, which is closest to ours, was introduced by (Barbieri et al., 2016), which trained emojis embeddings from a large Twitter dataset of over 100 million English tweets using the method of skipping programs in everyday use (Mikolov et al., 2013a). These pre-rehearsed emoji representations resulted in increased accuracy in a similarity task and a meaningful compilation of emoji training."}, {"heading": "3 Method", "text": "Our method maps emoji symbols in the same space as the 300-dimensional embeddings of Google News word2vec. Thus, the resulting Emoji2vec embeddings can be used in addition to 300-dimensional embeddings of word2vec in any application. For this purpose, we search emoji, their name and keyword phrases from the Unicode emoji list and obtain 6088 descriptions of 1661 emoji symbols. Figure 1 shows an example of an unusual emoji."}, {"heading": "3.1 Model", "text": "We train emoji embeddings with a simple method. For each training example, which consists of an emoji and a sequence of words w1,.., wN describing this emoji, we take the sum of the individual word vectors in the descriptive phrase as contained in Google News word2vec word2vec embeddingsvj = N \u2211 k = 1 wkwo wk is the word2vec vector for word wk if this vector exists (otherwise we drop the summand) and vj is the vector representation of the description. For each emoji in our training set, we define a traceable vector xi and model the probability of a match between the emoji representation xi and its description representation vj using the sigmoid of the dot product of the two representations \u03c3 (xTi vj).For training, we use the logistic vector xi (i, j yilog = Tyij \u2212 (Tyij \u2212 1)."}, {"heading": "3.2 Optimization", "text": "Our model was implemented in TensorFlow (Abadi et al., 2015) and optimized with stochastic gradient descent with Adam (Kingma and Ba, 2015) as optimizer. Since we do not observe negative training examples (invalid descriptions of emojis do not appear in the original training set), we randomly perform descriptions of emojis as negative instances to increase generalization performance (i.e. lead to an inappropriate description). One of the parameters of our model is the ratio of negative to positive samples; we found that one positive example per negative example yielded the best results. We stopped a protracted development and found 80 epochs of training to achieve the best results. As we train only on emojis and our method is simple and cheap, training takes less than 3 minutes on a 2013 MacBook Pro."}, {"heading": "4 Evaluation", "text": "We evaluate our approach quantitatively using an intrinsic (emoji description classification) and extrinsic (Twitter mood analysis) task. In addition, we perform a qualitative analysis by visualizing the emoji embedding space learned and examining emoji analogy examples."}, {"heading": "4.1 Emoji-Description Classification", "text": "To analyze how well our method models the distribution of correct emoji descriptions, we have created a manually labeled test set that includes pairs of emojis and phrases and a label for them. For example, our test set includes the example: {\"cry,\" true} and the example {\"fish,\" false}. If a classifier sets the above prediction at 0.5 to determine a positive or negative correlation, we get an accuracy of 85.5% for classifying whether an emoji description pair is valid or not. By varying the threshold used for this classifier, we get a receiver characteristic (Figure 4.1) with an area below the curve of 0.933, showing the high quality of the learned emoji representations."}, {"heading": "4.2 Sentiment Analysis on Tweets", "text": "As a downstream task, we compare the accuracy of the sentiment classification of tweets for different classifiers with three different sets of pre-trained Word embeddings: (1) the original word2vec embeddings of Google News, (2) word2vec supplemented by emoji embeddings trained by Barbieri et al. (2016) and (3) word2vec supplemented by emoji2vec embeddings with Unicode descriptions. We use the current data set from Kralj Novak et al. (2015), which consists of over 67k manually labelled English tweets for positive, neutral or negative moods. In both the training set and the test set, 46% of tweets are labelled as neutral, 29% as positive and 25% as negative. To calculate the feature vectors for the training, we summed up the vectors corresponding to each word or emoji in the text of the tweet as better labelled."}, {"heading": "4.3 t-SNE Visualization", "text": "To gain further insight, we project the learned emoji embedding into two-dimensional space using t-SNE (Maaten and Hinton, 2008), a method that projects high-dimensional embedding into a low-dimensional space while trying to preserve relative distances. We perform this projection of emoji representation into two-dimensional space.Figure 4.3 shows a number of remarkable semantic clusters indicating that the vectors we train have accurately captured some of the semantic properties of the emoji. For example, all flag symbols are grouped at the bottom and many smiley faces in the middle. Other prominent emoji clusters include fruits, astrological symbols, animals, vehicles, or families. On the other hand, symbolic representations of numbers in the embedding space are not properly unraveled and indicate limitations of our simple model. A two-dimensional projection is convenient from the point of view of visualization, and certainly shows that some of the emoji embedding space are similar to each other intuitively."}, {"heading": "4.4 Analogy Task", "text": "A well-known characteristic of word2vec is that trained embeddings with this method capture meaningful linear relationships between words directly in the vector space to a certain extent. For example, the vector representation of \"king\" minus \"man\" plus \"woman\" is the closest to \"queen\" (Mikolov et al., 2013b). Word embeddings have often been evaluated using such word analogy tasks (Levy and Goldberg, 2014). Unfortunately, due to the small number and semantically different emoji categories, it is difficult to create such an analogy task for emoji. Nevertheless, we have collected some intuitive examples in Figure 4. We have found the next five emojis for each query."}, {"heading": "5 Conclusion", "text": "Since pre-existing word embeddings such as Google News word2vec embeddings or GloVe do not provide emoji embeddings, we have released emoji2vec - embeddings of 1661 emoji symbols. Instead of running word2vec's Skip-gram model on a large collection of emojis and their contexts that appear in tweets, emoji2vec is trained directly on Unicode descriptions of emojis. The resulting emoji embeddings can be used to augment any downstream task currently used by word2vec embeddings, and could prove particularly useful for social NLP tasks where emojis are commonly used (e.g. Twitter, Instagram, etc.). Despite the fact that our model is simpler and is trained on much less data, we (Barbieri et al., 2016) are not exceeding the task of wort2veji embeddings and symbols based on our Twitter embeddings approach, as it is based directly on Twitter embeddings."}], "references": [{"title": "TensorFlow: Large-Scale Machine Learning", "author": ["Mart\u0131n Abadi", "Ashish Agarwal", "Paul Barham", "Eugene Brevdo", "Zhifeng Chen", "Craig Citro", "Greg S Corrado", "Andy Davis", "Jeffrey Dean", "Matthieu Devin"], "venue": null, "citeRegEx": "Abadi et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Abadi et al\\.", "year": 2015}, {"title": "Stance Detection with Bidirectional Conditional Encoding", "author": ["Isabelle Augenstein", "Tim Rockt\u00e4schel", "Andreas Vlachos", "Kalina Bontcheva."], "venue": "Proceedings of EMLNP.", "citeRegEx": "Augenstein et al\\.,? 2016", "shortCiteRegEx": "Augenstein et al\\.", "year": 2016}, {"title": "What does this Emoji Mean? A Vector Space Skip-Gram Model for Twitter Emojis", "author": ["Francesco Barbieri", "Francesco Ronzano", "Horacio Saggion."], "venue": "Proceedings of LREC, May.", "citeRegEx": "Barbieri et al\\.,? 2016", "shortCiteRegEx": "Barbieri et al\\.", "year": 2016}, {"title": "Emoji usage in TV conversation", "author": ["Joe Cruse"], "venue": null, "citeRegEx": "Cruse.,? \\Q2015\\E", "shortCiteRegEx": "Cruse.", "year": 2015}, {"title": "Tweet2Vec: Character-Based Distributed Representations for Social Media", "author": ["Bhuwan Dhingra", "Zhong Zhou", "Dylan Fitzpatrick", "Michael Muehl", "William Cohen."], "venue": "Proceedings of ACL, pages 269\u2013274.", "citeRegEx": "Dhingra et al\\.,? 2016", "shortCiteRegEx": "Dhingra et al\\.", "year": 2016}, {"title": "Machine Learning for Emoji Trends", "author": ["Thomas Dimson."], "venue": "http://instagram-", "citeRegEx": "Dimson.,? 2015", "shortCiteRegEx": "Dimson.", "year": 2015}, {"title": "Liblinear: A library for large linear classification", "author": ["Rong-En Fan", "Kai-Wei Chang", "Cho-Jui Hsieh", "XiangRui Wang", "Chih-Jen Lin."], "venue": "Journal of machine learning research, 9(Aug):1871\u20131874.", "citeRegEx": "Fan et al\\.,? 2008", "shortCiteRegEx": "Fan et al\\.", "year": 2008}, {"title": "Entity Extraction, Linking, Classification, and Tagging for Social Media: A", "author": ["Abhishek Gattani", "Digvijay S Lamba", "Nikesh Garera", "Mitul Tiwari", "Xiaoyong Chai", "Sanjib Das", "Sri Subramaniam", "Anand Rajaraman", "Venky Harinarayan", "AnHai Doan"], "venue": null, "citeRegEx": "Gattani et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Gattani et al\\.", "year": 2013}, {"title": "Learning to Understand Phrases by Embedding the Dictionary", "author": ["Felix Hill", "Kyunghyun Cho", "Anna Korhonen", "Yoshua Bengio."], "venue": "TACL.", "citeRegEx": "Hill et al\\.,? 2016", "shortCiteRegEx": "Hill et al\\.", "year": 2016}, {"title": "Random decision forests", "author": ["Tin Kam Ho."], "venue": "Document Analysis and Recognition, 1995., Proceedings of the Third International Conference on, volume 1, pages 278\u2013282. IEEE.", "citeRegEx": "Ho.,? 1995", "shortCiteRegEx": "Ho.", "year": 1995}, {"title": "Characterising the inventive appropriation of emoji as relationally meaningful in mediated close personal relationships", "author": ["Ryan Kelly", "Leon Watts."], "venue": "Experiences of Technology Appropriation: Unanticipated Users, Usage, Circumstances, and Design.", "citeRegEx": "Kelly and Watts.,? 2015", "shortCiteRegEx": "Kelly and Watts.", "year": 2015}, {"title": "Adam: A Method for Stochastic Optimization", "author": ["Diederik Kingma", "Jimmy Ba."], "venue": "Proceedings of ICLR.", "citeRegEx": "Kingma and Ba.,? 2015", "shortCiteRegEx": "Kingma and Ba.", "year": 2015}, {"title": "Sentiment of Emojis", "author": ["Petra Kralj Novak", "Jasmina Smailovi\u0107", "Borut Sluban", "Igor Mozeti\u010d."], "venue": "PLoS ONE, 10(12):1\u201322, 12.", "citeRegEx": "Novak et al\\.,? 2015", "shortCiteRegEx": "Novak et al\\.", "year": 2015}, {"title": "Emoji, Emoji, What for Art Thou? Harlot: A Revealing Look at the Arts of Persuasion", "author": ["Lisa Lebduska"], "venue": null, "citeRegEx": "Lebduska.,? \\Q2014\\E", "shortCiteRegEx": "Lebduska.", "year": 2014}, {"title": "Linguistic Regularities in Sparse and Explicit Word Representations", "author": ["Omer Levy", "Yoav Goldberg."], "venue": "Proceedings of ConLL, pages 171\u2013180.", "citeRegEx": "Levy and Goldberg.,? 2014", "shortCiteRegEx": "Levy and Goldberg.", "year": 2014}, {"title": "Visualizing data using t-sne", "author": ["Laurens van der Maaten", "Geoffrey Hinton."], "venue": "Journal of Machine Learning Research, 9(Nov):2579\u20132605.", "citeRegEx": "Maaten and Hinton.,? 2008", "shortCiteRegEx": "Maaten and Hinton.", "year": 2008}, {"title": "Distributed Representations of Words and Phrases and their Compositionality", "author": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean."], "venue": "Proceedings of NIPS, pages 3111\u20133119.", "citeRegEx": "Mikolov et al\\.,? 2013a", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Linguistic Regularities in Continuous Space Word Representations", "author": ["Tomas Mikolov", "Wen-tau Yih", "Geoffrey Zweig."], "venue": "Proceedings of NAACLHLT, pages 746\u2013751.", "citeRegEx": "Mikolov et al\\.,? 2013b", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Blissfully happy\u201d or \u201cready to fight\u201d: Varying Interpretations of Emoji", "author": ["Hannah Miller", "Jacob Thebault-Spieker", "Shuo Chang", "Isaac Johnson", "Loren Terveen", "Brent Hecht."], "venue": "Proceedings of ICWSM.", "citeRegEx": "Miller et al\\.,? 2016", "shortCiteRegEx": "Miller et al\\.", "year": 2016}, {"title": "Emoticon style: Interpreting differences in emoticons across cultures", "author": ["Jaram Park", "Vladimir Barash", "Clay Fink", "Meeyoung Cha."], "venue": "ICWSM.", "citeRegEx": "Park et al\\.,? 2013", "shortCiteRegEx": "Park et al\\.", "year": 2013}, {"title": "Glove: Global Vectors for Word Representation", "author": ["Jeffrey Pennington", "Richard Socher", "Christopher Manning."], "venue": "Proceedings of EMNLP, pages 1532\u2013 1543, October.", "citeRegEx": "Pennington et al\\.,? 2014", "shortCiteRegEx": "Pennington et al\\.", "year": 2014}, {"title": "Named Entity Recognition in Tweets: An Experimental Study", "author": ["Alan Ritter", "Sam Clark", "Mausam", "Oren Etzioni."], "venue": "Proceedings of EMNLP, pages 1524\u20131534.", "citeRegEx": "Ritter et al\\.,? 2011", "shortCiteRegEx": "Ritter et al\\.", "year": 2011}, {"title": "SemEval-2015 Task 10: Sentiment Analysis in Twitter", "author": ["Sara Rosenthal", "Preslav Nakov", "Svetlana Kiritchenko", "Saif Mohammad", "Alan Ritter", "Veselin Stoyanov."], "venue": "Proceedings of the SemEval, pages 451\u2013 463.", "citeRegEx": "Rosenthal et al\\.,? 2015", "shortCiteRegEx": "Rosenthal et al\\.", "year": 2015}, {"title": "Learning Sentiment-Specific Word Embedding for Twitter Sentiment Classification", "author": ["Duyu Tang", "Furu Wei", "Nan Yang", "Ming Zhou", "Ting Liu", "Bing Qin."], "venue": "Proceedings of ACL, pages 1555\u20131565.", "citeRegEx": "Tang et al\\.,? 2014", "shortCiteRegEx": "Tang et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 3, "context": "As of this writing, over 10% of Twitter posts and over 50% of text on Instagram contain one or more emoji (Cruse, 2015).", "startOffset": 106, "endOffset": 119}, {"referenceID": 13, "context": "(Lebduska, 2014) showed that emoji are culturally and contextually bound, and are open to reinterpretation and misinterpretation, a result confirmed by (Miller et al.", "startOffset": 0, "endOffset": 16}, {"referenceID": 18, "context": "(Lebduska, 2014) showed that emoji are culturally and contextually bound, and are open to reinterpretation and misinterpretation, a result confirmed by (Miller et al., 2016).", "startOffset": 152, "endOffset": 173}, {"referenceID": 9, "context": "Interestingly, Kelly and Watts (2015) found that although essentially thought of as means of expressing emotions, emoji have been adopted as tools to express relationally useful roles in conversation.", "startOffset": 15, "endOffset": 38}, {"referenceID": 21, "context": "Concurrently we observe an increased interest in natural language processing on social media data (Ritter et al., 2011; Gattani et al., 2013; Rosenthal et al., 2015).", "startOffset": 98, "endOffset": 165}, {"referenceID": 7, "context": "Concurrently we observe an increased interest in natural language processing on social media data (Ritter et al., 2011; Gattani et al., 2013; Rosenthal et al., 2015).", "startOffset": 98, "endOffset": 165}, {"referenceID": 22, "context": "Concurrently we observe an increased interest in natural language processing on social media data (Ritter et al., 2011; Gattani et al., 2013; Rosenthal et al., 2015).", "startOffset": 98, "endOffset": 165}, {"referenceID": 16, "context": "Such systems often rely on pre-trained word embeddings that can for instance be obtained from word2vec (Mikolov et al., 2013a) or GloVe (Pennington et al.", "startOffset": 103, "endOffset": 126}, {"referenceID": 20, "context": ", 2013a) or GloVe (Pennington et al., 2014).", "startOffset": 18, "endOffset": 43}, {"referenceID": 5, "context": "The first research done in this direction was an informal blog post by the Instagram Data Team in 2015 (Dimson, 2015).", "startOffset": 103, "endOffset": 117}, {"referenceID": 2, "context": "The second contribution, closest to ours, was introduced by (Barbieri et al., 2016).", "startOffset": 60, "endOffset": 83}, {"referenceID": 16, "context": "They trained emoji embeddings from a large Twitter dataset of over 100 million English tweets using the skip-gram method (Mikolov et al., 2013a).", "startOffset": 121, "endOffset": 144}, {"referenceID": 2, "context": "The second contribution, closest to ours, was introduced by (Barbieri et al., 2016). They trained emoji embeddings from a large Twitter dataset of over 100 million English tweets using the skip-gram method (Mikolov et al., 2013a). These pre-trained emoji representations led to increased accuracy on a similarity task, and a meaningful clustering of the emoji embedding space. While this method is able to learn robust representations for frequently-used emoji, representations of less frequent emoji are estimated rather poorly or not available at all. In fact, only around 700 emoji can be found in Barbieri et al. (2016)\u2019s corpus, while there is support of over 1600 emoji in the Unicode standard.", "startOffset": 61, "endOffset": 624}, {"referenceID": 8, "context": "In addition, our work relates to the work of Hill et al. (2016) who built word representations for words and concepts based on their description in a dictionary.", "startOffset": 45, "endOffset": 64}, {"referenceID": 8, "context": "In addition, our work relates to the work of Hill et al. (2016) who built word representations for words and concepts based on their description in a dictionary. Similarly to their approach, we build representations for emoji based on their descriptions and keyword phrases. Some of the limitations of our work are evident in the work of Park et al. (2013) who showed that different cultural phenomena and languages may coopt conventional emoji sentiment.", "startOffset": 45, "endOffset": 357}, {"referenceID": 0, "context": "Our model is implemented in TensorFlow (Abadi et al., 2015) and optimized using stochastic gradient descent with Adam (Kingma and Ba, 2015) as optimizer.", "startOffset": 39, "endOffset": 59}, {"referenceID": 11, "context": ", 2015) and optimized using stochastic gradient descent with Adam (Kingma and Ba, 2015) as optimizer.", "startOffset": 66, "endOffset": 87}, {"referenceID": 2, "context": "As downstream task we compare the accuracy of sentiment classification of tweets for various classifiers with three different sets of pre-trained word embeddings: (1) the original Google News word2vec embeddings, (2) word2vec augmented with emoji embeddings trained by Barbieri et al. (2016), and (3) word2vec augmented with emoji2vec trained from Unicode descriptions.", "startOffset": 269, "endOffset": 292}, {"referenceID": 2, "context": "As downstream task we compare the accuracy of sentiment classification of tweets for various classifiers with three different sets of pre-trained word embeddings: (1) the original Google News word2vec embeddings, (2) word2vec augmented with emoji embeddings trained by Barbieri et al. (2016), and (3) word2vec augmented with emoji2vec trained from Unicode descriptions. We use the recent dataset by Kralj Novak et al. (2015), which consists of over 67k English tweets labelled manually for positive, neutral, or negative sentiment.", "startOffset": 269, "endOffset": 425}, {"referenceID": 2, "context": "Furthermore, we find that emoji2vec generally outperforms the emoji embeddings trained by Barbieri et al. (2016), despite being trained on much less data using a simple model.", "startOffset": 90, "endOffset": 113}, {"referenceID": 15, "context": "To gain further insights, we project the learned emoji embeddings into two-dimensional space using t-SNE (Maaten and Hinton, 2008).", "startOffset": 105, "endOffset": 130}, {"referenceID": 17, "context": "For instance, it holds that the vector representation of \u2019king\u2019 minus \u2019man\u2019 plus \u2019woman\u2019 is closest to \u2019queen\u2019 (Mikolov et al., 2013b).", "startOffset": 111, "endOffset": 134}, {"referenceID": 14, "context": "Word embeddings have commonly been evaluated on such word analogy tasks (Levy and Goldberg, 2014).", "startOffset": 72, "endOffset": 97}, {"referenceID": 2, "context": "Despite the fact that our model is simpler and trained on much less data, we outperform (Barbieri et al., 2016) on the task of Twitter sentiment analysis.", "startOffset": 88, "endOffset": 111}, {"referenceID": 2, "context": "5 Google News + (Barbieri et al., 2016) 58.", "startOffset": 16, "endOffset": 39}, {"referenceID": 2, "context": "1 Google News + (Barbieri et al., 2016) 52.", "startOffset": 16, "endOffset": 39}, {"referenceID": 2, "context": "1 Google News + (Barbieri et al., 2016) 52.", "startOffset": 16, "endOffset": 39}, {"referenceID": 2, "context": "2 Google News + (Barbieri et al., 2016) 53.", "startOffset": 16, "endOffset": 39}, {"referenceID": 9, "context": "Table 1: Three-way classification accuracy on the Twitter sentiment analysis corpus using Random Forrests (Ho, 1995) and Linear", "startOffset": 106, "endOffset": 116}, {"referenceID": 6, "context": "SVM (Fan et al., 2008) classifier with different word embeddings.", "startOffset": 4, "endOffset": 22}], "year": 2016, "abstractText": "Many current natural language processing applications for social media rely on representation learning and utilize pre-trained word embeddings. There currently exist several publicly-available, pre-trained sets of word embeddings, but they contain few or no emoji representations even as emoji usage in social media has increased. In this paper we release emoji2vec, pre-trained embeddings for all Unicode emoji which are learned from their description in the Unicode emoji standard.1 The resulting emoji embeddings can be readily used in downstream social natural language processing applications alongside word2vec. We demonstrate, for the downstream task of sentiment analysis, that emoji embeddings learned from short descriptions outperforms a skip-gram model trained on a large collection of tweets, while avoiding the need for contexts in which emoji need to appear frequently in order to estimate a representation.", "creator": "TeX"}}}