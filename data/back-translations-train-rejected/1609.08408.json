{"id": "1609.08408", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Sep-2016", "title": "Deep learning for detection of bird vocalisations", "abstract": "This work focuses on reliable detection of bird sound emissions as recorded in the open field. Acoustic detection of avian sounds can be used for the automatized monitoring of multiple bird taxa and querying in long-term recordings for species of interest for researchers, conservation practitioners, and decision makers. Recordings in the wild can be very noisy due to the exposure of the microphones to a large number of audio sources originating from all distances and directions, the number and identity of which cannot be known a-priori. The co-existence of the target vocalizations with abiotic interferences in an unconstrained environment is inefficiently treated by current approaches of audio signal enhancement. A technique that would spot only bird vocalization while ignoring other audio sources is of prime importance. These difficulties are tackled in this work, presenting a deep autoencoder that maps the audio spectrogram of bird vocalizations to its corresponding binary mask that encircles the spectral blobs of vocalizations while suppressing other audio sources. The procedure requires minimum human attendance, it is very fast during execution, thus suitable to scan massive volumes of data, in order to analyze them, evaluate insights and hypotheses, identify patterns of bird activity that, hopefully, finally lead to design policies on biodiversity issues.", "histories": [["v1", "Sun, 25 Sep 2016 15:56:06 GMT  (1171kb)", "http://arxiv.org/abs/1609.08408v1", null]], "reviews": [], "SUBJECTS": "cs.SD cs.LG", "authors": ["ilyas potamitis"], "accepted": false, "id": "1609.08408"}, "pdf": {"name": "1609.08408.pdf", "metadata": {"source": "CRF", "title": "Deep learning for detection of bird vocalisations", "authors": ["Ilyas Potamitis"], "emails": ["potamitis@staff.teicrete.gr"], "sections": [{"heading": null, "text": "This year, more than ever before in the history of a country in which it is a country, in which it is a country in which it is a country, in which it is a country, in which it is a country, in a country, in a city, in a city, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a city, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a city, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country"}, {"heading": "II. BIRD VOCALIZATIONS AND THE SPECTROGRAM", "text": "This year, it is only a matter of time before the first three to five years arrive."}, {"heading": "III. DEEP LEARNING AS APPLIED TO SPECTROGRAM IMAGES", "text": "The basic structure of the deep-rooted network, which is able to move, is able to see three variations in terms of the number of layers used, and one version with the more advanced and award-winning species. In the case of speculation, one must be careful about the exchange methods used."}, {"heading": "IV. EVALUATION", "text": "The cube coefficient can be used to compare the pixel-by-pixel agreement between a predicted segmentation and its corresponding basic truth. the cube coefficient is the quotient of similarity and ranges from 0 to 1. It can be considered a measure of similarity over projects. the loss function is only the minus value of the cube coefficient with the additions of a smoothing factor inserted into the denominator. The score in Table I is the mean of the cube coefficients of the images in the weighting set. In this paragraph we will only comment on the predictive results relating to audio scenes that we found interesting. All test audits were excluded from the test set. In Fig. 6 you can see that the lower frequencies of the spectrum (Fig. 6 below) are quite strongly suppressed, while the structure of noise is not usually suppressed by 7."}, {"heading": "VI. CONCLUSION", "text": "[23] comprehensively describes the challenges of our time in terms of bird detection, and this work, too, recognizes the need to process large amounts of locally recorded audio data to extract the information needed to make decisions about biodiversity issues. We present a generic approach to bird detection that crawls over a large number of recordings overnight to examine the underlying bioacoustic activity, the basic idea being that there is something in common between X-ray images, ultrasonic electron microscopy, and spectrograms, all of which are 2D representations where the target appears as a block that stands out from its background, and therefore the very successful paradigm of deep learning, with all its variations, is a choice that needs to be studied. It is in the future to examine how extensible our approach is to address finer questions such as: can we quantify the network of U-learning for all kinds of interfering birds?"}, {"heading": "ACKNOWLEDGMENTS", "text": "We appreciate the support of NVIDIA Corporation with the donation of a TITAN-X GPU, which is partially used for this research. We use the ceramic learning library [24] in CUDA-CuDNN GPU mode. Python code in Anaconda Python 2.7.11 runs in Ubuntu environment and the Linux version of Matlab 2014b. We recognize the use of fragments of the code of U-net on the Internet, and in several programming languages such as: http: / lmb.informatik.uni-freiburg.de / people / u-net / ua."}], "references": [{"title": "Bird Songs: Biological Themes and variations", "author": ["C. Catchpole", "P. Slater"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2008}, {"title": "Bird calls: a cornucopia for communication", "author": ["P. Marler"], "venue": "Nature's Music: The Science of Birdsong, edited by P. Marler and H. Slabbekoorn, Chap. 5, pp. 132\u2013177. New York, NY: Elsevier Academic Press, 2004.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2004}, {"title": "Avian bioacoustics, Handbook of the Birds of the World, vol. 6: Mousebirds to Hornbills", "author": ["L. Baptista", "D. Kroodsma"], "venue": "Lynx Editions,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2001}, {"title": "Sensor network for the monitoring of ecosystem: Bird species recognition", "author": ["J. Cai", "D. Ee", "B. Pham", "P. Roe", "J. Zhang"], "venue": "3rd International Conference on Intelligent Sensors, Sensor Networks and Information, (2008), pp. 293\u2013298.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2008}, {"title": "Automatic bird sound detection in long real-field recordings: Applications and tools", "author": ["I. Potamitis", "S. Ntalampiras", "O Jahn", "K. Riede"], "venue": "Applied Acoustics, Volume", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "Towards Automatic Large-Scale Identification of Birds in Audio Recordings, Experimental IR Meets Multilinguality, Multimodality, and Interaction, Volume 9283 of the series Lecture Notes in Computer Science", "author": ["M Lasseck"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "Automatic detection and recognition of tonal bird sounds in noisy environments", "author": ["P. Jancovic", "M. Kokuer"], "venue": "Journal of Advanced Signal Processing, 2011, 1\u201310, (2011)", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2011}, {"title": "Automated recognition of bird song elements from continuous recordings using dynamic time warping and hidden Markov models: a comparative study", "author": ["J. Kogan", "D. Margoliash"], "venue": "Journal of the Acoustical Society of America, 103(4), 2185\u20132196, 1998.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1998}, {"title": "An automated acoustic system to monitor and classify birds", "author": ["C. Kwan", "K. Ho", "G. Mei", "Y. Li", "Z. Ren", "R. Xu", "Y. Zhang", "D. Lao", "M. Stevenson", "V. Stanford", "C. Rochet"], "venue": "EURASIP Journal on Applied Signal Processing, Article ID 96706, 2006.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2006}, {"title": "Bird species recognition using support vector machines", "author": ["S. Fagerlund"], "venue": "EURASIP Journal on Applied Signal Processing, Article ID 38637, 2007.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2007}, {"title": "Automated species recognition of antbirds in a Mexican rainforest using hidden Markov models", "author": ["V. Trifa", "A. Kirschel", "C.E. Taylor", "E.E. Vallejo"], "venue": "Journal of the Acoustical Society of America, 123(4), 2424-2431, 2008.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2008}, {"title": "A Framework for Bioacoustic Vocalization Analysis Using Hidden Markov Models, Algorithms", "author": ["Y. Ren", "M. Johnson", "P. Clemins", "M. Darre", "S. Glaeser", "T. Osiejuk"], "venue": "Algorithms 2(4), 1410-1428, 2009.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2009}, {"title": "Multi-Label Classifier Chains for Bird Sound", "author": ["F. Briggs", "X. Fern", "J. Irvine"], "venue": "Proceedings of the 30th International Conference on Machine Learning, Atlanta, Georgia,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2013}, {"title": "Acoustic classification of multiple simultaneous bird species: A multi-instance multi-label approach", "author": ["F. Briggs", "B. Lakshminarayanan", "L. Neal", "R X. Fern", "S. Raich", "Hadley", "M. Betts"], "venue": "The Journal of the Acoustical Society of America, 131:4640, 2012.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2012}, {"title": "Automatic Classification of a Taxon-Rich Community Recorded in the Wild", "author": ["I Potamitis"], "venue": "PLoS ONE 9(5):", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2014}, {"title": "Unsupervised dictionary extraction of bird vocalisations and new tools on assessing and visualising bird activity", "author": ["I. Potamitis"], "venue": "Ecological Informatics,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2015}, {"title": "Automatic Segmentation and Deep Learning of Bird Sounds Experimental IR Meets Multilinguality, Multimodality, and Interaction, Volume 9283 of the series Lecture Notes in Computer Science", "author": ["Hendrik Vincent Koops", "Jan van Balen", "Frans Wiering"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2015}, {"title": "U-net: Convolutional networks for biomedical image segmentation. In: Medical Image Computing and Computer-Assisted Intervention\u2013MICCAI", "author": ["O. Ronneberger", "P. Fischer", "T. Brox"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2015}, {"title": "A toolbox for animal call recognition", "author": ["M. Towsey"], "venue": "Bioacoustics, vol. 21, no. 2, pp. 107\u2013125, 2012.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2012}, {"title": "Bird acoustic activity detection based on morphological filtering of the spectrogram", "author": ["A.G. de Oliveira"], "venue": "Applied Acoustics, vol. 98, pp. 34\u201342, 2015.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2015}, {"title": "Bird detection in audio: a survey and a challenge", "author": ["Dan Stowell", "Mike Wood", "Yannis Stylianou", "Herv\u00e9 Glotin"], "venue": "[cs.SD],", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2016}], "referenceMentions": [{"referenceID": 0, "context": "Birds use acoustic vocalization as a very efficient way to communicate as the sound does not require visual contact between emitter and receiver individuals, can travel over long distances, and can carry the information content under low visibility conditions, such as in dense vegetation and during night time hours [1].", "startOffset": 317, "endOffset": 320}, {"referenceID": 1, "context": "gun shooting) [2-3].", "startOffset": 14, "endOffset": 19}, {"referenceID": 2, "context": "gun shooting) [2-3].", "startOffset": 14, "endOffset": 19}, {"referenceID": 3, "context": "Modern models are powered by solar energy, equipped with large storage capacity, carry weather-proof normal and ultrasound microphones, and some of them are equipped with wireless transmission capabilities [4].", "startOffset": 206, "endOffset": 209}, {"referenceID": 4, "context": "Pattern recognition of bird sounds has a long history and many pattern recognition approaches [5-16] have been applied to the problem of automatic bird detection and identification.", "startOffset": 94, "endOffset": 100}, {"referenceID": 5, "context": "Pattern recognition of bird sounds has a long history and many pattern recognition approaches [5-16] have been applied to the problem of automatic bird detection and identification.", "startOffset": 94, "endOffset": 100}, {"referenceID": 6, "context": "Pattern recognition of bird sounds has a long history and many pattern recognition approaches [5-16] have been applied to the problem of automatic bird detection and identification.", "startOffset": 94, "endOffset": 100}, {"referenceID": 7, "context": "Pattern recognition of bird sounds has a long history and many pattern recognition approaches [5-16] have been applied to the problem of automatic bird detection and identification.", "startOffset": 94, "endOffset": 100}, {"referenceID": 8, "context": "Pattern recognition of bird sounds has a long history and many pattern recognition approaches [5-16] have been applied to the problem of automatic bird detection and identification.", "startOffset": 94, "endOffset": 100}, {"referenceID": 9, "context": "Pattern recognition of bird sounds has a long history and many pattern recognition approaches [5-16] have been applied to the problem of automatic bird detection and identification.", "startOffset": 94, "endOffset": 100}, {"referenceID": 10, "context": "Pattern recognition of bird sounds has a long history and many pattern recognition approaches [5-16] have been applied to the problem of automatic bird detection and identification.", "startOffset": 94, "endOffset": 100}, {"referenceID": 11, "context": "Pattern recognition of bird sounds has a long history and many pattern recognition approaches [5-16] have been applied to the problem of automatic bird detection and identification.", "startOffset": 94, "endOffset": 100}, {"referenceID": 12, "context": "Pattern recognition of bird sounds has a long history and many pattern recognition approaches [5-16] have been applied to the problem of automatic bird detection and identification.", "startOffset": 94, "endOffset": 100}, {"referenceID": 13, "context": "Pattern recognition of bird sounds has a long history and many pattern recognition approaches [5-16] have been applied to the problem of automatic bird detection and identification.", "startOffset": 94, "endOffset": 100}, {"referenceID": 14, "context": "Pattern recognition of bird sounds has a long history and many pattern recognition approaches [5-16] have been applied to the problem of automatic bird detection and identification.", "startOffset": 94, "endOffset": 100}, {"referenceID": 15, "context": "Pattern recognition of bird sounds has a long history and many pattern recognition approaches [5-16] have been applied to the problem of automatic bird detection and identification.", "startOffset": 94, "endOffset": 100}, {"referenceID": 16, "context": "The reported literature on the application of Deep learning networks on bird audio recordings is surprisingly sparse [17].", "startOffset": 117, "endOffset": 121}, {"referenceID": 17, "context": "This work introduces a special type of deep learning networks named auto-encoders and the Unet in particular [18].", "startOffset": 109, "endOffset": 113}, {"referenceID": 17, "context": "In [18] a network had been trained end-to-end from very few images and outperformed the prior best method, winning by a large margin including other types of convolutional networks on a cell tracking challenge competition.", "startOffset": 3, "endOffset": 7}, {"referenceID": 17, "context": "The training data in [18] are extracted manually.", "startOffset": 21, "endOffset": 25}, {"referenceID": 13, "context": "[14] as an example of a different to ours approach that requires manual tagging of spectral blobs), but would be highly unpractical for bird vocalizations appearing in an abundance of data.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "We need a generic tool, as is the case in [19], to segment bird vocalizations without requiring the manual, laborious tagging of thousands of audio spectrograms to their detail.", "startOffset": 42, "endOffset": 46}, {"referenceID": 5, "context": "In this work, we use a modified version of [6] to extract automatically the mask of the spectrogram of a bird recording.", "startOffset": 43, "endOffset": 46}, {"referenceID": 0, "context": "In difference to calls, songs are longer, acoustically more complex, and often have a modular structure [1-3].", "startOffset": 104, "endOffset": 109}, {"referenceID": 1, "context": "In difference to calls, songs are longer, acoustically more complex, and often have a modular structure [1-3].", "startOffset": 104, "endOffset": 109}, {"referenceID": 2, "context": "In difference to calls, songs are longer, acoustically more complex, and often have a modular structure [1-3].", "startOffset": 104, "endOffset": 109}, {"referenceID": 5, "context": "in [6].", "startOffset": 3, "endOffset": 6}, {"referenceID": 19, "context": "All these different processing stages are standard in image processing and have as a result the removal of background and extraction of spectral blobs [20].", "startOffset": 151, "endOffset": 155}, {"referenceID": 5, "context": "The binary mask as introduced in [6] is composed of the following stages (see Fig.", "startOffset": 33, "endOffset": 36}, {"referenceID": 5, "context": "(Left) segmentation based on a modified method of Lasseck in [6], (Right) Segmentation method based on the original version in [6].", "startOffset": 61, "endOffset": 64}, {"referenceID": 5, "context": "(Left) segmentation based on a modified method of Lasseck in [6], (Right) Segmentation method based on the original version in [6].", "startOffset": 127, "endOffset": 130}, {"referenceID": 5, "context": "(Left) Spectrogram, (Right) Binary mask produced by a modified version of [6].", "startOffset": 74, "endOffset": 77}, {"referenceID": 5, "context": "(Left) Spectrogram, (Right) Binary mask corresponding to the spectrogram on the left produced by [6].", "startOffset": 97, "endOffset": 100}, {"referenceID": 17, "context": "et al as presented in [18]).", "startOffset": 22, "endOffset": 26}, {"referenceID": 5, "context": "Other accurate classification procedures applied to bird recognition as in [6], and [14-15] do not scale well as the number of recordings increases to the order of tens- to hundreds of thousands 15 sec clips as they need to extract first the features of the test dataset before they classify it.", "startOffset": 75, "endOffset": 78}, {"referenceID": 13, "context": "Other accurate classification procedures applied to bird recognition as in [6], and [14-15] do not scale well as the number of recordings increases to the order of tens- to hundreds of thousands 15 sec clips as they need to extract first the features of the test dataset before they classify it.", "startOffset": 84, "endOffset": 91}, {"referenceID": 14, "context": "Other accurate classification procedures applied to bird recognition as in [6], and [14-15] do not scale well as the number of recordings increases to the order of tens- to hundreds of thousands 15 sec clips as they need to extract first the features of the test dataset before they classify it.", "startOffset": 84, "endOffset": 91}, {"referenceID": 5, "context": "The predicted blobs are smoother compared to segmentation method of [6] (see Fig.", "startOffset": 68, "endOffset": 71}, {"referenceID": 5, "context": "(Left) Spectrogram, (Middle), Segmentation using modified [6], (Right) Predicted Binary mask using Unet2.", "startOffset": 58, "endOffset": 61}, {"referenceID": 5, "context": "(Left) Spectrogram, (Middle), Segmentation using [6], (Right) Predicted Binary mask using U-net2.", "startOffset": 49, "endOffset": 52}, {"referenceID": 5, "context": "7 we are interested in visualizing the benefit of using a U-net compared to the automatic segmentation in [6].", "startOffset": 106, "endOffset": 109}, {"referenceID": 20, "context": "In [23], the challenges of our time related to bird detection are thoroughly presented.", "startOffset": 3, "endOffset": 7}], "year": 2016, "abstractText": "This work focuses on reliable detection of bird sound emissions as recorded in the open field. Acoustic detection of avian sounds can be used for the automatized monitoring of multiple bird taxa and querying in long-term recordings for species of interest for researchers, conservation practitioners, and decision makers. Recordings in the wild can be very noisy due to the exposure of the microphones to a large number of audio sources originating from all distances and directions, the number and identity of which cannot be known a-priori. The co-existence of the target vocalizations with abiotic interferences in an unconstrained environment is inefficiently treated by current approaches of audio signal enhancement. A technique that would spot only bird vocalization while ignoring other audio sources is of prime importance. These difficulties are tackled in this work, presenting a deep autoencoder that maps the audio spectrogram of bird vocalizations to its corresponding binary mask that encircles the spectral blobs of vocalizations while suppressing other audio sources. The procedure requires minimum human attendance, it is very fast during execution, thus suitable to scan massive volumes of data, in order to analyze them, evaluate insights and hypotheses, identify patterns of bird activity that, hopefully, finally lead to design policies on biodiversity issues.", "creator": "Microsoft\u00ae Word 2013"}}}