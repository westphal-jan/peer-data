{"id": "1609.08419", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Sep-2016", "title": "Decision Making Based on Cohort Scores for Speaker Verification", "abstract": "Decision making is an important component in a speaker verification system. For the conventional GMM-UBM architecture, the decision is usually conducted based on the log likelihood ratio of the test utterance against the GMM of the claimed speaker and the UBM. This single-score decision is simple but tends to be sensitive to the complex variations in speech signals (e.g. text content, channel, speaking style, etc.). In this paper, we propose a decision making approach based on multiple scores derived from a set of cohort GMMs (cohort scores). Importantly, these cohort scores are not simply averaged as in conventional cohort methods; instead, we employ a powerful discriminative model as the decision maker. Experimental results show that the proposed method delivers substantial performance improvement over the baseline system, especially when a deep neural network (DNN) is used as the decision maker, and the DNN input involves some statistical features derived from the cohort scores.", "histories": [["v1", "Tue, 27 Sep 2016 13:29:12 GMT  (1477kb,D)", "http://arxiv.org/abs/1609.08419v1", "APSIPA ASC 2016"]], "COMMENTS": "APSIPA ASC 2016", "reviews": [], "SUBJECTS": "cs.SD cs.AI cs.LO", "authors": ["lantian li", "renyu wang", "gang wang", "caixia wang", "thomas fang zheng"], "accepted": false, "id": "1609.08419"}, "pdf": {"name": "1609.08419.pdf", "metadata": {"source": "CRF", "title": "Decision Making Based on Cohort Scores for Speaker Verification", "authors": ["Lantian Li", "Renyu Wang", "Gang Wang", "Caixia Wang", "Thomas Fang Zheng"], "emails": ["fzheng@tsinghua.edu.cn"], "sections": [{"heading": null, "text": "This year, it is only a matter of time before agreement is reached."}, {"heading": "II. COHORT-BASED DECISION MAKING FRAMEWORK", "text": "In a typical GMM-UBM loudspeaker verification system, the score probability ratio of a test expression is calculated over the GMM of the claimed loudspeaker model and the UBM. Then, the probability ratio is compared with a predefined threshold. If it is higher than the threshold, the test expression is accepted, otherwise rejected. We argue that this naive decision-making approach is unreliable and less robust because this probability ratio only describes the distance between the claimed GMM and the UBM and does not use the world speakers and the corresponding score information. Therefore, we are designing a cohort-based decision framework as shown in Figure 1. This framework consists of three parts: cohort selection, feature design, and discriminatory model training."}, {"heading": "A. Cohort selection", "text": "To measure the distances between the Gaussian mixture models, we chose a weighted K-L distance given by: D (\u03bb1, \u03bb2) = M \u2211 i = 1 wiKL (N 1 i, N 2 i) (1) KL (N1, N2) = 12 (\u00b51 \u2212 \u00b52) T (\u03a3 \u2212 11 \u2212 \u03a3 \u2212 1 2) (\u00b51 \u2212 \u00b52) (2), where \u03bb1 and \u03bb2 are two Gaussian mixture models, and wi is the weight of the Gaussian component. Note that for a quick calculation, only the mean parameters in the GMM-MAP process are adjusted, while the weights and variances of the Gaussian component are the same, and wi is the weight of the Gaussian component."}, {"heading": "B. Feature design", "text": "Once the cohort models (CGMMs) have been determined, a set of cohort values is calculated based on the alleged loudspeakers GMM, UBM and CGMMs for each expression of the test. We will try to use these cohort results to explore potential knowledge and design more differentiated features based on true and deceptive loudspeaker models. In this part, three cohort-based score characteristics are discussed. 1) Cohort-based score normalization: The inspiration for this feature comes from conventional score normalization techniques [10]. For a poster feature vector X, the normalized score L \u03bb (X) = L\u03bb (X) \u2212 microceptor receptor (4), where a claimed loudspeaker model is represented, and microreceptor is estimated from the cohort results. 2) Ranking: The composition of the test position is a cohort position K for each cohort, which is the size K for each cohort."}, {"heading": "C. Discriminative model training", "text": "Based on these characteristics, which are derived from the cohort values, discriminatory models (e.g. support vector engine (SVM) and deep neural networks (DNNs) can be optimized directly in relation to the task of speaker verification, i.e. the decision for a real / deceptive speaker."}, {"heading": "III. EXPERIMENTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Database", "text": "The experiments are carried out on a database called \"CSLTDSDB\" (Digit String Database), jointly created by CSLT (Center for Speech and Language Technologies), Tsinghua University and Beijing d-Ear Technologies, Co. Ltd. The text of all recordings is the text-based numerical sequence. The recordings were made with various mobile microphones sampled at 16 kHz with 16-bit precision. \u2022 Training kit: It contains an approximate size of 1 GB of data (about 200 men and 200 women) recorded in an ordinary office environment and is used for UBM training. \u2022 Development kit: It contains 280 written digits with 145 speakers and 2 874 test statements. And it is used for cohort selection and feature design. \u2022 Rating set: It includes 92 speakers. For each speaker, there are text-based digits with a total length of about 40 seconds for each speaker model, and 16-220 for each speaker model."}, {"heading": "B. Experimental setup", "text": "The acoustic feature was the conventional 39-dimensional Mel Frequency Receiver Coefficients (MFCC), which included 13-dimensional static components plus the derivatives of first and second order. UBM consisted of 256 Gaussian components and was trained with the training set. Note that this setting is \"almost\" optimal in our experiments, i.e. the use of additional Gaussian components cannot improve system performance, and the starting point of the GMM-UBM system on the evaluation set was 1.621% in terms of EER (Equal Error Rate). In addition, 280 loudspeaker GMMs from UBM were adapted, and the Kmeans algorithm was used to group the 280 loudspeaker GMMs into a suitable cohort. Fig. 2 presents the function between the number of clusters and cluster costs J. It can be observed that if the number of clusters exceeds 10, the cluster costs have already been converted to a suitable cohort."}, {"heading": "C. Feature design", "text": "1) Cohort-based Score Normalization: According to Eq.4, the normalized score was calculated for each test, and the system performance was 1.639% in the EER. It shows reasonable performance and can be considered an available score property.2) Rank Position: From Figure 3, we have observed that this ranking position has some distinctness; almost all probability values of the real loudspeaker GMMs are in the first place, while for high-stacker loudspeaker models the ranking distribution fulfills a Gaussian distribution approximately with the mean of 5.3) Rank Differences: To give an intuitive understanding of the discriminatory ability of this feature, the rank of the score differences of all T-SNE tests [14] is displayed in a two-dimensional space. As shown in Figure 4.there is a clear non-linear boundary between real loudspeaker models and high-stack loudspeaker models. That is, this \"Rank of Score Differences\" shows strong discrimination against loudspeaker models."}, {"heading": "D. Discriminative model training", "text": "With these cohort-based score characteristics, discriminatory models can be optimized for distinguishing the real / fraudulent speakers. In this work, both the SVM and DNN models were trained as decision makers for the Speaker Verification System1) SVM-based scoring: The SVMs were trained for each cohort-based score function using the linear kernel function. Results are presented in Table I under condition C1-C3. Note that \"norm\" is \"cohort-based scoring normalization,\" r-pos is \"the ranking position,\" r-diff \"is the\" ranking order of score differences, \"and that related characteristics are selected as input of the SVMs.2) DNN-based scoring characteristics: The DNN models were trained with these cohort-based score characteristics, and the decision was made by logistic regression models on the soft-max Core-optimization structure of the DNM, so that you can tune the features."}, {"heading": "IV. CONCLUSIONS", "text": "This paper presents a decision-making method based on cohort values rather than the traditional single decision outcome. Some potential discriminatory characteristics are embedded in cohort outcomes, and then more powerful discriminatory models are formed as decision makers. Experimental results show that the proposed \"rank of score differences\" with SVM / DNN-based scoring models can achieve stable and better system performance than the GMM-UBM baseline. Furthermore, a combination scheme is proposed to further improve system performance."}, {"heading": "ACKNOWLEDGMENT", "text": "This work is supported by the National Natural Science Foundation of China under grant numbers 61371136 and 61271389, and was also supported by China's National Basic Research Programme (973 Program) under grant number 2013CB329302."}], "references": [{"title": "Speaker verification using adapted Gaussian mixture models", "author": ["D.A. Reynolds", "T.F. Quatieri", "R.B. Dunn"], "venue": "Digital Signal Processing, vol. 10, no. 1-3, pp. 19\u201341, 2000.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2000}, {"title": "Joint factor analysis versus eigenchannels in speaker recognition", "author": ["P. Kenny", "G. Boulianne", "P. Ouellet", "P. Dumouchel"], "venue": "IEEE Transactions on Audio, Speech, and Language Processing, vol. 15, no. 4, pp. 1435\u20131447, 2007.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2007}, {"title": "Front-end factor analysis for speaker verification", "author": ["N. Dehak", "P. Kenny", "R. Dehak", "P. Dumouchel", "P. Ouellet"], "venue": "IEEE Transactions on Audio, Speech, and Language Processing, vol. 19, no. 4, pp. 788\u2013798, 2011.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2011}, {"title": "Within-class covariance normalization for svm-based speaker recognition", "author": ["A.O. Hatch", "S.S. Kajarekar", "A. Stolcke"], "venue": "Proc. INTER- SPEECH\u201906, 2006.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2006}, {"title": "Support vector machines using gmm supervectors for speaker verification", "author": ["W.M. Campbell", "D.E. Sturim", "D.A. Reynolds"], "venue": "Signal Processing Letters, vol. 13, no. 5, pp. 308\u2013311, 2006.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2006}, {"title": "Probabilistic linear discriminant analysis for inferences about identity", "author": ["S.J. Prince", "J.H. Elder"], "venue": "ICCV\u201907. IEEE, 2007, pp. 1\u20138.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2007}, {"title": "Deep neural networks for extracting baum-welch statistics for speaker recognition", "author": ["P. Kenny", "V. Gupta", "T. Stafylakis", "P. Ouellet", "J. Alam"], "venue": "Odyseey\u20192014. Odyssey, 2014.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "Deep neural networks for small footprint text-dependent speaker verification", "author": ["V. Ehsan", "L. Xin", "E. McDermott", "I.L. Moreno", "J. Gonzalez- Dominguez"], "venue": "IEEE International Conference on Acoustic, Speech and Signal Processing (ICASSP),2014. IEEE, 2014, pp. 4052\u2013 4056.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "Speaker recognition: A tutorial", "author": ["J.P. Campbell Jr"], "venue": "Proceedings of the IEEE, vol. 85, no. 9, pp. 1437\u20131462, 1997.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1997}, {"title": "Score normalization for text-independent speaker verification systems", "author": ["R. Auckenthaler", "M. Carey", "H. Lloyd-Thomas"], "venue": "Digital Signal Processing, vol. 10, no. 1-3, pp. 42\u201354, 2000.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2000}, {"title": "Impostor cohort selection for score normalisation in speaker verification", "author": ["R.A. Finan", "R.I. Damperb", "A.T. Sapeluk"], "venue": "Pattern Recognition Letters, vol. 18, no. 9, 1997.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1997}, {"title": "The use of cohort normalized scores for speaker verification", "author": ["A.E. Rosenberg", "J. DeLong", "C.-H. Lee", "B.-H. Juang", "F.K. Soong"], "venue": "ICSLP\u201992, 1992, pp. 4052\u20134056.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1992}, {"title": "Vector quantization", "author": ["R. Gray"], "venue": "IEEE Assp Magazine, vol. 1, no. 2, pp. 4\u201329, 1994.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1994}, {"title": "Visualizing data using t-sne", "author": ["L. v. d. Maaten", "G. Hinton"], "venue": "Machine Learning Research, 2008.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2008}], "referenceMentions": [{"referenceID": 0, "context": "After decades of research, lots of popular speaker verification approaches have been proposed, such as Gaussian mixture model-universal background model (GMM-UBM) [1], joint factor analysis (JFA) [2] and its \u2018simplified\u2019 version, the i-vector model [3].", "startOffset": 163, "endOffset": 166}, {"referenceID": 1, "context": "After decades of research, lots of popular speaker verification approaches have been proposed, such as Gaussian mixture model-universal background model (GMM-UBM) [1], joint factor analysis (JFA) [2] and its \u2018simplified\u2019 version, the i-vector model [3].", "startOffset": 196, "endOffset": 199}, {"referenceID": 2, "context": "After decades of research, lots of popular speaker verification approaches have been proposed, such as Gaussian mixture model-universal background model (GMM-UBM) [1], joint factor analysis (JFA) [2] and its \u2018simplified\u2019 version, the i-vector model [3].", "startOffset": 249, "endOffset": 252}, {"referenceID": 3, "context": "Accompanied with these models, various back-end techniques have also been proposed to promote the discriminative capability for speakers, such as within-class covariance normalization (WCCN) [4], nuisance attribute projection (NAP) [5] and probabilistic LDA (PLDA) [6], etc.", "startOffset": 191, "endOffset": 194}, {"referenceID": 4, "context": "Accompanied with these models, various back-end techniques have also been proposed to promote the discriminative capability for speakers, such as within-class covariance normalization (WCCN) [4], nuisance attribute projection (NAP) [5] and probabilistic LDA (PLDA) [6], etc.", "startOffset": 232, "endOffset": 235}, {"referenceID": 5, "context": "Accompanied with these models, various back-end techniques have also been proposed to promote the discriminative capability for speakers, such as within-class covariance normalization (WCCN) [4], nuisance attribute projection (NAP) [5] and probabilistic LDA (PLDA) [6], etc.", "startOffset": 265, "endOffset": 268}, {"referenceID": 6, "context": "Recently, deep learning has been applied to speaker verification and gained much interest [7], [8].", "startOffset": 90, "endOffset": 93}, {"referenceID": 7, "context": "Recently, deep learning has been applied to speaker verification and gained much interest [7], [8].", "startOffset": 95, "endOffset": 98}, {"referenceID": 8, "context": "Within a speaker verification system, decision making is an important component [9].", "startOffset": 80, "endOffset": 83}, {"referenceID": 9, "context": "Most of the normalization approaches, according to [10], can be explained using the Bayes\u2019 theorem.", "startOffset": 51, "endOffset": 55}, {"referenceID": 10, "context": "These cohort scores then replace the UBM to normalize the score of the test utterance against the claimed speaker [11], [12].", "startOffset": 114, "endOffset": 118}, {"referenceID": 11, "context": "These cohort scores then replace the UBM to normalize the score of the test utterance against the claimed speaker [11], [12].", "startOffset": 120, "endOffset": 124}, {"referenceID": 12, "context": "A vector quantization (VQ) method [13] based on the Kmeans algorithm was utilized to conduct the speaker model clustering.", "startOffset": 34, "endOffset": 38}, {"referenceID": 9, "context": "1) Cohort-based score normalization: The inspiration of this feature comes from the conventional score normalization techniques [10].", "startOffset": 128, "endOffset": 132}, {"referenceID": 13, "context": "3) Rank of score differences: To provide an intuitive understanding of the discriminative capability of this feature, the rank of score differences of all the test trials are plotted in a two-dimensional space via T-SNE [14].", "startOffset": 220, "endOffset": 224}], "year": 2016, "abstractText": "Decision making is an important component in a speaker verification system. For the conventional GMM-UBM architecture, the decision is usually conducted based on the log likelihood ratio of the test utterance against the GMM of the claimed speaker and the UBM. This single-score decision is simple but tends to be sensitive to the complex variations in speech signals (e.g. text content, channel, speaking style, etc.). In this paper, we propose a decision making approach based on multiple scores derived from a set of cohort GMMs (cohort scores). Importantly, these cohort scores are not simply averaged as in conventional cohort methods; instead, we employ a powerful discriminative model as the decision maker. Experimental results show that the proposed method delivers substantial performance improvement over the baseline system, especially when a deep neural network (DNN) is used as the decision maker, and the DNN input involves some statistical features derived from the cohort scores.", "creator": "LaTeX with hyperref package"}}}