{"id": "1609.08439", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Sep-2016", "title": "Model-based Test Generation for Robotic Software: Automata versus Belief-Desire-Intention Agents", "abstract": "Robotic code needs to be verified to ensure its safety and functional correctness, especially when the robot is interacting with people. Testing the real code in simulation is a viable option. It reduces the costs of experiments and provides detail that is lost when using formal methods. However, generating tests that cover interesting scenarios, while executing most of the code, is a challenge amplified by the complexity of the interactions between the environment and the software. Model-based test generation methods can automate otherwise manual processes and facilitate reaching rare scenarios during testing. In this paper, we compare the use of Belief-Desire-Intention (BDI) agents as models for test generation, with more conventional, model-based test generation, that exploits automata and model checking techniques, and random test generation methods, in terms of practicality, performance, scalability, and exploration (`coverage'). Simulators and automated testbenches were implemented in Robot Operating System (ROS) and Gazebo, for testing the code of two robots, BERT2 in a cooperative manufacture (table assembly) task, and Tiago as a home care assistant. The results highlight the clear advantages of using BDI agents for test generation, compared to random and conventional automata-based approaches. BDI agents naturally emulate the agency present in Human-Robot Interaction (HRI). They are thus more expressive and scale well in HRI applications.", "histories": [["v1", "Fri, 16 Sep 2016 14:07:28 GMT  (741kb,D)", "https://arxiv.org/abs/1609.08439v1", "arXiv admin note: text overlap witharXiv:1603.00656"], ["v2", "Mon, 12 Dec 2016 11:23:48 GMT  (371kb,D)", "http://arxiv.org/abs/1609.08439v2", "arXiv admin note: text overlap witharXiv:1603.00656"]], "COMMENTS": "arXiv admin note: text overlap witharXiv:1603.00656", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["dejanira araiza-illan", "anthony g pipe", "kerstin eder"], "accepted": false, "id": "1609.08439"}, "pdf": {"name": "1609.08439.pdf", "metadata": {"source": "CRF", "title": "Model-based Test Generation for Robotic Software: Automata versus Belief-Desire-Intention Agents", "authors": ["Dejanira Araiza-Illan", "Anthony G. Pipe", "Kerstin Eder"], "emails": ["dejanira.araizaillan@bristol.ac.uk", "tony.pipe@brl.ac.uk", "kerstin.eder@bristol.ac.uk"], "sections": [{"heading": "1 INTRODUCTION", "text": "As robot software developers, we must demonstrate the safety and functionality of robots that interact closely with humans if these technologies are to become commercial products automatically [14]. Beyond eliminating runtime errors, a robot code must be verified and validated at the functional level, in terms of hardware and other software components, and interactions with the environment, including humans. The interaction of all these elements introduces complexity and conversion, and thus the possibility of unexpected and undesirable behaviors [19, 4]. Robot behavior and control code have been verified through model verification, either by creating an abstract model of code or behavior (as in [30]), or by automated translations from code, often limited to a limited subset of language, into models or model verification languages (as in [7]). These models may require subsequent abstraction processes to enable verification of the original code [23]."}, {"heading": "2 RELATED WORK", "text": "In our previous paper, we presented a simulation method to test real, high-level robot control codes in an effective and scalable manner. [4] However, automation of the test process and systematic exploration of the code within HRI scenarios have been replaced by a method that drives the generation of tests. [5] In this paper, we demonstrated how a test generator, a self-control scenario, and a coverage scenario can be integrated into a simulation system."}, {"heading": "3 CASE STUDIES", "text": "Our two case studies are a cooperative production scenario and a simple home care scenario."}, {"heading": "3.1 Cooperative Manufacturing Task", "text": "We used the scenario we used in [3], where a human and a robot work together to build a table. BERT2 [17], the robot, when asked, should pass the legs to the person, one by one. The robot then picks up a leg, and signals for the human to take it. Humans give another voice command indicating the willingness to leave the leg or not. The robot then picks up a leg to bring it to the man."}, {"heading": "3.2 Home Care Assistant", "text": "The robot is responsible for taking care of a person with reduced mobility by bringing food to the table (\"food\"), clearing the table (\"clean\"), checking the refrigerator door (\"refrigerator\") and checking the taps (\"sink\"). Whenever the person asks the robot to execute a command that is not in the list of known, the robot will not move. The robot will move to a default location called \"recharge,\" and should stay there until the person asks it to do otherwise. We assume that the robot will not ask the robot to perform more than three feasible tasks within a 10-minute interval."}, {"heading": "3.3 Simulator in ROS and Gazebo", "text": "A simulation in Gazebo is controlled by the code on one side and by the code on the other. Simulators for both scenarios are available. (A driver, a checker and a coverage) They have been extended from the ROS infrastructure. (4, 5) We implement the requirements in the two case studies. (4) We are able to change the processes in the region. (5)"}, {"heading": "4 MODEL-BASED TEST GENERATION", "text": "We describe two types of model-based test generation using BDI agents [3] and the verification of TA models [4, 5], along with a baseline: pseudo-andom test generation. In model-based approaches, a model of the system or its requirements is first compiled and then examined to create tests. We use model-based approaches to create abstract tests that indirectly stimulate the code of the robot in the simulation by stimulating the environment with which the code interacts, rather than directly stimulating the code."}, {"heading": "4.1 BDI Agent Models and Exploration", "text": "BDI is an intelligent or rational agent architecture for multi-agent systems. BDI agents model human practical thinking in terms of \"beliefs\" (knowledge of the world and the agents), \"desires\" (goals to be met), and \"intentions\" (plans to be executed to achieve the goals according to available knowledge). [8] Recently, we have shown that BDI agents are well suited to make rational, human-like decisions in HRI for test generation purposes [3]. We employed the Jason interpreter, whereby agents are expressed in the AgentSpeak language. An agent is defined by initial beliefs (initial knowledge) and desires (initial goals), and a library of \"plans\" (actions to be taken to fulfil desires, according to beliefs). A plan has a \"head\" formed by an expression of beliefs (a \"context\") that serves as a guard for the planning, selection of actions or a set of actions."}, {"heading": "4.1.1 Model for the Cooperative Manufacturing Task", "text": "The model consists of four agents: the robot code, the human code, the sensors (as a single agent) and the verification agent. The verification agent causes the human agent to send activation signals to both the robot code (voice commands) and the sensor agent. There are a total of 38 possible beliefs for the verification agent, including, for example, the requirement of 1 to 4 legs, measurements for the three sensors per leg and human boredom. The sensor agent transmits readings of 1 or 1. The code agent of the robot has a structure similar to the FSM in the real code and only interacts with the human and the sensor agent through beliefs."}, {"heading": "4.1.2 Model for the Home Care Assistant", "text": "Our model consists of five agents: the robot code, the human code, the dog code, the sensor (to avoid collisions) and the verification agent. The verification agent selects the requirements that the human agent transmits to the robot code agent, one by one. The dog agent can decide whether or not to collide with TIAGo. This is then perceived by the sensor agent who transmits this information to the robot code agent. The robot code agent is based on an FSM similar to the one used in the real code. There are five possible beliefs for the verification agent to control the human, with the four available requests and another representing each other invalid request."}, {"heading": "4.2 Timed Automata Models and Model Checking", "text": "Model verification is the exhaustive research of a model to determine whether a logical property is met or not. Traces of examples or counter-examples are provided as evidence of satisfaction or proof of a violation. Model verification applied to models of code or high-level system functionality of the robot can be used for model-based test generation, in which these traces are used to derive tests [15, 29].In [4, 5] we modeled HRI in the sense of TA for the model tester UPPAAL9. Non-determinism enables detection of uncertainty in human actions and sensor errors by selecting various transitions in the machine. Since robots that interact with humans are intended to fulfill targets in a limited time, the timing counters in the TA allow an emulation of these timing thresholds. The execution of these machines is synchronized by communication events, and \"waking\" or conditions to deflect the transition from a sufficient state to a different system event, in accordance with the logic of the TA and AL."}, {"heading": "4.2.1 Model for the Cooperative Manufacturing Task", "text": "Our model consists of 6 TA, the human, the robot code, the sensors and the human choice of view, pressure and location. While the human automaton executes the activation signals (voice commands), the gaze, pressure and positioning automats select the inputs for the sensors non-deterministically (via variables).The automaton reads the variables as 1 or 1, which are then read by the automated code processor of the robot to decide whether a leg should be released or not. The latter has a structure similar to the FSM in the real code."}, {"heading": "4.2.2 Model for the Home Care Assistant", "text": "Our model consists of 4 TA, the human, the robot code, the sensor and the dog. The automatic sensor determines whether the dog is in collision distance or not, depending on the choice of the dog automaton. The human automaton determines the type of requests for the automated code of the robot, one by one. The automated code of the robot, which is similar in structure to the FSMs in the code, executes the requests of the human, taking into account the sensor values in order to avoid collisions."}, {"heading": "4.3 Baseline: Pseudorandom Test Generation", "text": "As a starting point for comparisons, we used a pseudorandom abstract test generator [4, 5], which randomly concatenates selected sequences from a list of specified \"actions,\" the length of which is also chosen pseudorandom. For example, in the home care scenario, sequences from available requests such as \"request food\" or \"request cleanliness\" are compiled. In the production scenario, human actions such as \"activate robot\" or \"select view as OK\" are available to be included in sequences."}, {"heading": "5 EXPERIMENTS AND RESULTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Experimental setup", "text": "Simulator and Testbench were implemented in ROS Indigo and Gazebo 2.2.5. The tests were run on a PC with Intel i5-3230M 2.60 GHz CPU, 8 GB RAM and Ubuntu 14.04. We used Jason 1.4.2 for the BDI models and UPPAAL 4.1.19 for the model validation. All simulators, code and test generation models used in the experiments, as well as the associated tests and results data are available online."}, {"heading": "5.1.1 Cooperative Manufacturing Assistant", "text": "For the TA model verification described in Section 4.2, we manually generated 91 TCTL properties, for which sample tracks were automatically generated and abstract tests extracted, covering all vision, pressure and position sensor reading combinations, requests from 1 to 4 legs, the human who is bored, and the timing of the robot while waiting for a signal. Using the BDI-based method, we generated 131 abstract tests (out of a possible total of 238) by setting conditions for beliefs covering the same elements as the TCTL properties and more, i.e. a variety of valid human and robotic actions, and an orchestration of the rarest events, such as the correct execution of 4 legs. The generator automatically examines the restricted beliefs individually via the multi-agent system, following the procedure explained in Section 4.1. In addition, we generated 160 tests of pseudo-specific location, each of which were explained from a human task in Section 3.2."}, {"heading": "5.1.2 Home Care Assistant", "text": "With the BDI agents, we created 62 abstract tests by selecting beliefs from a possible total of 25 random samples to cover the same requirement combinations as the model check. We discarded 12 tests to obtain a total of 50, as some of the tests were quite similar (e.g. combinations of invalid commands). Finally, we created 50 abstract tests pseudorandom, as explained in Section 4.3. As before, each abstract test was pseudorandom (at least once in the case of model check) from valid areas, using the test number as seed for a total of 50 different concrete tests for each method. Each test ran for a maximum of 700 seconds."}, {"heading": "5.2 Code Coverage Results", "text": "We expected that the BDI-based method would quickly produce a large number of tests with high test coverage, and that both model-based methods would outperform pseudorandom test generation in terms of test coverage. Figures 2 and 3 show the code coverage percentage that each test produced achieves, and the cumulative test coverage for both scenarios. In the production scenario (Figure 2), tests with BDI agents quickly achieved a high level of coverage (at 92% of cumulative test coverage), and a large number achieved the highest possible test coverage (92%), exceeding the tests generated by pseudorandom and model review of TA in terms of coverage efficiency and effectiveness. In the home care scenario (Figure 3), tests created with BDI agents achieved the highest coverage results (86%), with tests performed by model review of TA and pseudorandal."}, {"heading": "5.3 Assertion Coverage Results", "text": "One of our motives for comparing the test generation methods was to determine whether model-based methods would produce tests that would achieve higher performance coverage than pseudo-andome test generation. As the models reflect functional requirements, we expected them to generate more frequent tests that would trigger performance monitoring. While this section focuses on performance monitoring, the purpose of the tests is to identify breaches of the requirements. We evaluate the effectiveness of the tests in terms of their ability to find errors from triggering performance monitors. The results of the performance monitoring are in Table 1. We recorded the number of tests for which the requirement was met (P), not met (F) or not checked (NC). In the manufacturing scenario, requirements 1 to 3 are breached as the robot sometimes does not decide whether to release a leg or not within the specified time threshold. These errors were largely detected in the model-based tests, as expected, and in the case of tests created by BDI only, the requirement of 3."}, {"heading": "6 160 0 0 160 0 0 160 0 0", "text": "These tests exceeded those generated by pseudo-andomatic and TA model verification, i.e. they were most effective in detecting requirement violations. In the home care scenario, requirement violations were found in all test generation methods. If the robot collides with the dog, the collision causes the robot to fall over without recovery, preventing the robot from meeting the current and any subsequent requirement, as reflected in the results of requirements 1, 2 and 4. Claim 3 is not met because a speed limit in the motion control of the robot base is not enforced. As a result of failure depending on collisions with the dog, the overall results of performance coverage are low and quite similar for all test generation methods."}, {"heading": "5.4 Cross-Product Functional Coverage Results", "text": "We expected that model-based methods would achieve more cross-product items than pseudorandom test generations, i.e. that they would cover more cross-product, especially for the production scenario, since 4 successful leg passes are difficult to achieve. Table 2 shows the coverage results for attainable combinations of human robot behavior as described in Section 3.3. Results for the production scenario show that due to the complexity of the interaction protocol to activate the robot, as expected, it is difficult to achieve some of the coverage points with pseudorandom generation tests. Tests with BDI agents covered all items, and similar to the tests generated by the TA model review, demonstrating their cross-product coverage effectiveness. In the home care scenario, the coverage results for all three methods were similar due to two factors. First, the system glitches in collisions were present and the test failed both to meet their cross-mission requirements, which were not applicable to a prior set of Item."}, {"heading": "5.5 Discussion", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.5.1 Exploration", "text": "In response to our first research question, the presented results show that BDI-based tests perform better than traditional automaton model testing and that they outperform the pseudo-andom generation tests in terms of achieving a high degree of code, assertion and cross-product coverage quickly, i.e. effectiveness and efficiency of coverage. BDI-based tests also detected requirement violations in the manufacturing task that tests of other methods did not find, i.e. they were more effective in identifying errors."}, {"heading": "5.5.2 Performance", "text": "A comparison of the effort to create the different models, the resulting model size, and the time for model research to create tests is for a robotician with similar training using Jason and UPPAAL in Table 3. Creating automatons in UPPAAL required more effort than creating the BDI agents in Jason. The syntax of the BDI agents provides a more rational and intuitive structure that enables the creation of an HRI protocol with less effort than setting automatons variables, guards, and transitions manually. Defining BDI beliefs is also more intuitive than specifying TCTL properties, as the latter must take into account all variables and states of the model. We have limited the runtime of the BDI model manually, and the time could have been further reduced. However, the model verification variations vary by characteristics; they are unpredictable and cannot be controlled as part of the test process."}, {"heading": "5.5.3 Practicality and Transferability", "text": "Our results show that BDI agents are applicable to different HRI scenarios, as our two case studies show. BDI agents model a HRI task with human action and rational thinking. They are naturally programmed by defining action plans. Compared to the model review, we do not need to formulate temporal logical accessibility characteristics, which requires a good understanding of formal logic and greater manual effort. Furthermore, the construction of automata such as TA for larger case studies requires several abstraction cycles to address the problem of state explosion [30]."}, {"heading": "5.5.4 Limitations", "text": "In this paper, the two case studies serve to illustrate our comparison of the use of BDI agents instead of model-based test generation. Further validation of our results requires industrial codes and more abundant HRI case studies. Other coverage metrics could be used to add additional comparative dimensions to system exploration during the test, such as FSM states or transitions, using the FSM structure of part of the code. Nevertheless, our approach is not dictated by the structuring of the code as FSMs or the use of SMACH. Finally, all approaches presented in this paper implement offline test generation, i.e. the tests are calculated prior to simulation, which is appropriate if the models of the system and the environment do not change. For robots learning and adapting in changing environments, online test generation techniques are required."}, {"heading": "6 CONCLUSIONS AND FUTURE WORK", "text": "In this paper, we compared two model-based approaches of the test generation in the context of HRI scenarios: BDI agents and model test machines in terms of exploration (coverage), performance, practicality and portability. We also compared both methods with the pseudorandom test generation as a starting point. The test generation methods were applied to two case studies, a collaborative manufacturing task and a home care scenario, for which a high-level robot control code was tested in ROS and Gazebo simulators, using a cover-driven automated test stand [4, 5]. We found that BDI agents allow realistic, human-like stimuli while facilitating the generation of complex interactions between the robot and its environment. Tests created with BDI agents work similar to tests generated by TA in terms of long-range model testing (code, assertions and cross-product), which are more generative and better than those generated."}], "references": [{"title": "Rigorous design of robot software: A formal component-based approach", "author": ["Tesnim Abdellatif", "Saddek Bensalem", "Jacques Combaz", "Lavindra de Silva", "Felix Ingrand"], "venue": "Robotics and Autonomous Systems,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2012}, {"title": "Situation Coverage \u2013 A Coverage Criterion for Testing Autonomous Robots", "author": ["Rob Alexander", "Heather Hawkins", "Drew Rae"], "venue": "Technical report,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2015}, {"title": "Intelligent agent-based stimulation for testing robotic software in human-robot interactions", "author": ["D. Araiza-Illan", "A.G. Pipe", "K. Eder"], "venue": "In Proceedings of the 3rd Workshop on Model-Driven Robot Software Engineering (MORSE),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2016}, {"title": "Coverage-driven verification \u2014 an approach to verify code for robots that directly interact with humans", "author": ["D. Araiza-Illan", "D. Western", "K. Eder", "A. Pipe"], "venue": "In Proc. HVC,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2015}, {"title": "Systematic and realistic testing in simulation of control code for robots in collaborative human-robot interactions", "author": ["D. Araiza-Illan", "D. Western", "K. Eder", "A. Pipe"], "venue": "In Proc. TAROS,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2016}, {"title": "Model checking AgentSpeak", "author": ["R.H. Bordini", "M. Fisher", "C. Pardavila", "M. Wooldridge"], "venue": "In Proc. AAMAS,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2003}, {"title": "Verifying multi-agent programs by model checking", "author": ["Rafael H. Bordini", "Michael Fisher", "Willem Visser", "Michael Wooldridge"], "venue": "Journal of Autonomous Agents and Multi-Agent Systems,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2006}, {"title": "Programming Multi-Agent Systems in AgentSpeak using Jason", "author": ["R.H. Bordini", "J.F. H\u00fcbner", "M. Wooldridge"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2007}, {"title": "The SMACH High-Level Executive", "author": ["Jonathan Boren", "Steve Cousins"], "venue": "IEEE Robotics & Automation Magazine,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2010}, {"title": "Progress on the state explosion problem in model checking", "author": ["Edmund Clarke", "Orna Grumberg", "Somesh Jha", "Yuan Lu", "Helmut Veith"], "venue": "In Informatics. 10 Years Back. 10 Years Ahead,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2000}, {"title": "Counterexample-guided abstraction refinement for symbolic model checking", "author": ["Edmund Clarke", "Orna Grumberg", "Somesh Jha", "Yuan Lu", "Helmut Veith"], "venue": "Journal of the ACM,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2003}, {"title": "Practical verification of decision-making in agent-based autonomous", "author": ["Louise A. Dennis", "Michael Fisher", "Nicholas K. Lincoln", "Alexei Lisitsa", "Sandor M. Veres"], "venue": "systems. Automated,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2016}, {"title": "A survey on model-based testing approaches: A systematic review", "author": ["Arilo C. Dias Neto", "Rajesh Subramanyan", "Marlon Vieira", "Guilherme H. Travassos"], "venue": "In Proc. WEASELTech,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2007}, {"title": "Towards the safety of human-in-the-loop robotics: Challenges and opportunities for safety assurance of robotic co-workers", "author": ["K.I. Eder", "C. Harper", "U.B. Leonards"], "venue": "In Proc. IEEE ROMAN,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "Testing with model checkers: a survey", "author": ["Gordon Fraser", "Franz Wotawa", "Paul E. Ammann"], "venue": "Software Testing, Verification and Reliability,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2009}, {"title": "Sampling-based algorithm for testing and validating robot controllers", "author": ["J. Kim", "J.M. Esposito", "R.V. Kumar"], "venue": "International Journal of Robotics Research,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2006}, {"title": "The BERT2 infrastructure: An integrated system for the study of human-robot interaction", "author": ["A. Lenz", "S. Skachek", "K. Hamann", "J. Steinwender", "A.G. Pipe", "C. Melhuish"], "venue": "In Proc. IEEE-RAS Humanoids,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2010}, {"title": "Model-based testing of autonomous systems based on Coloured Petri Nets", "author": ["R. Lill", "F. Saglietti"], "venue": "In Proc. ARCS,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2012}, {"title": "A concept for testing robustness and safety of the context-aware behaviour of autonomous systems", "author": ["Z. Micskei", "Z. Szatm\u00e1ri", "J. Ol\u00e1h", "I. Majzik"], "venue": "In Proc. KES- AMSTA,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2012}, {"title": "Testing robot controllers using constraint programming and continuous integration", "author": ["M. Mossige", "A. Gotlieb", "H. Meling"], "venue": "Information and Software Technology,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2014}, {"title": "Fast abstract: Stochastic model- based testing for human-robot interaction", "author": ["Akbar Siami Namin", "Barbara Millet", "Mohan Sridharan"], "venue": "In Proc. ISSRE,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2010}, {"title": "A survey of combinatorial testing", "author": ["C. Nie", "H. Leung"], "venue": "ACM Computing Surveys,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2011}, {"title": "Model-based real-time testing of drone autopilots", "author": ["Andrea Patelli", "Luca Mottola"], "venue": "In Proc. DroNet,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2016}, {"title": "Multilevel testing of control software for teams of autonomous mobile robots", "author": ["S. Petters", "D. Thomas", "M. Friedmann", "O. von Stryk"], "venue": "In Proc. SIMPAR,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2008}, {"title": "Framework using ROS and SimTwo simulator for realistic test of mobile robot controllers", "author": ["T. Pinho", "A.P. Moreira", "J. Boaventura-Cunha"], "venue": "In Proc. CON- TROLO,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2014}, {"title": "Functional Verification Coverage Measurement and Analysis", "author": ["Andrew Pizialli"], "venue": null, "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2008}, {"title": "A systematic review of state-based test", "author": ["Muhammad Shafique", "Yvan Labiche"], "venue": "tools. International Journal on Software Tools for Technology Transfer,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2015}, {"title": "Towards reliable code generation with an open tool: Evolutions of the Gene-Auto toolset", "author": ["A. Toom", "N. Izerrouken", "T. Naks", "M. Pantel", "O. Ssi Yan Kai"], "venue": "In Proc. ERTS,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2010}, {"title": "A taxonomy of model-based testing approaches", "author": ["M. Utting", "A. Pretschner", "B. Legeard"], "venue": "Software Testing, Verification and Reliability,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2012}, {"title": "Formal verification of an autonomous personal robotic assistant", "author": ["Matt Webster", "Clare Dixon", "Michael Fisher", "Maha Salem", "Joe Saunders", "Kheng Lee Koay", "Kerstin Dautenhahn"], "venue": "In Proc. AAAI FVHMS", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2014}], "referenceMentions": [{"referenceID": 13, "context": "As robot software designers, we must demonstrate the safety and functional soundness of robots that interact closely with people, if these technologies are to become viable commercial products [14].", "startOffset": 193, "endOffset": 197}, {"referenceID": 18, "context": "The interaction of all these elements introduces complexity and concurrency, and thus the possibility of unexpected and undesirable behaviours [19, 4].", "startOffset": 143, "endOffset": 150}, {"referenceID": 3, "context": "The interaction of all these elements introduces complexity and concurrency, and thus the possibility of unexpected and undesirable behaviours [19, 4].", "startOffset": 143, "endOffset": 150}, {"referenceID": 29, "context": "Robot high-level behaviours and control code have been verified via model checking, either by hand-crafting an abstract model of the code or behaviours (as in [30]), or by automated translations from code, often restricted to a limited subset of the language, into models or model checking languages (as in [7]).", "startOffset": 159, "endOffset": 163}, {"referenceID": 6, "context": "Robot high-level behaviours and control code have been verified via model checking, either by hand-crafting an abstract model of the code or behaviours (as in [30]), or by automated translations from code, often restricted to a limited subset of the language, into models or model checking languages (as in [7]).", "startOffset": 307, "endOffset": 310}, {"referenceID": 9, "context": "These models might require subsequent abstraction processes [10] that remove detail from the original code, to make verification feasible [23].", "startOffset": 60, "endOffset": 64}, {"referenceID": 22, "context": "These models might require subsequent abstraction processes [10] that remove detail from the original code, to make verification feasible [23].", "startOffset": 138, "endOffset": 142}, {"referenceID": 10, "context": "the model needs to be demonstrated, for the verification results to be considered truthful (as it is done in counter-example guided abstraction refinement [11]).", "startOffset": 155, "endOffset": 159}, {"referenceID": 23, "context": "An advantage of testing is that realistic components, such as emulated or real hardware (hardware-in-the-loop) and users (human-in-the-loop) can be added to the testing environment [24, 20, 25].", "startOffset": 181, "endOffset": 193}, {"referenceID": 19, "context": "An advantage of testing is that realistic components, such as emulated or real hardware (hardware-in-the-loop) and users (human-in-the-loop) can be added to the testing environment [24, 20, 25].", "startOffset": 181, "endOffset": 193}, {"referenceID": 24, "context": "An advantage of testing is that realistic components, such as emulated or real hardware (hardware-in-the-loop) and users (human-in-the-loop) can be added to the testing environment [24, 20, 25].", "startOffset": 181, "endOffset": 193}, {"referenceID": 14, "context": "They have been used for model-based test generation [15], reducing the need for writing tests manually.", "startOffset": 52, "endOffset": 56}, {"referenceID": 28, "context": "In model-based testing, a model of the system under test or the testing goals is derived first, followed by its traversal to generate tests based on witness traces or paths [29].", "startOffset": 173, "endOffset": 177}, {"referenceID": 1, "context": "The generated tests were run in a simulation of the scenarios, to gather statistics on coverage of code (executed lines), safety and functional requirements (monitored during execution), and combinations of human-robot actions (denominated cross-product, Cartesian product, or situational coverage [2, 5]).", "startOffset": 298, "endOffset": 304}, {"referenceID": 4, "context": "The generated tests were run in a simulation of the scenarios, to gather statistics on coverage of code (executed lines), safety and functional requirements (monitored during execution), and combinations of human-robot actions (denominated cross-product, Cartesian product, or situational coverage [2, 5]).", "startOffset": 298, "endOffset": 304}, {"referenceID": 3, "context": "In our previous work, we presented a simulation-based method to test real, high-level robot control code in an effective and scalable manner [4, 5].", "startOffset": 141, "endOffset": 147}, {"referenceID": 4, "context": "In our previous work, we presented a simulation-based method to test real, high-level robot control code in an effective and scalable manner [4, 5].", "startOffset": 141, "endOffset": 147}, {"referenceID": 25, "context": "Automation of the testing process and a systematic exploration of the code under test within HRI scenarios was achieved through Coverage-Driven Verification (CDV), a method that guides the generation of tests, according to feedback from coverage metrics [26].", "startOffset": 254, "endOffset": 258}, {"referenceID": 3, "context": "In [4, 5], we illustrated how a CDV testbench, comprising a test generator, driver, self-checker and coverage collector, can be integrated into a simulator running in the Robot Operating System (ROS) framework and Gazebo.", "startOffset": 3, "endOffset": 9}, {"referenceID": 4, "context": "In [4, 5], we illustrated how a CDV testbench, comprising a test generator, driver, self-checker and coverage collector, can be integrated into a simulator running in the Robot Operating System (ROS) framework and Gazebo.", "startOffset": 3, "endOffset": 9}, {"referenceID": 15, "context": "set of inputs for a controller [16], or generating a timing sequence for activating individual controllers [20].", "startOffset": 31, "endOffset": 35}, {"referenceID": 19, "context": "set of inputs for a controller [16], or generating a timing sequence for activating individual controllers [20].", "startOffset": 107, "endOffset": 111}, {"referenceID": 21, "context": "For these applications, random data generation or sampling [22] might suffice to explore the state space or data ranges [16], along with alternatives such as constraint solving or optimization techniques [20].", "startOffset": 59, "endOffset": 63}, {"referenceID": 15, "context": "For these applications, random data generation or sampling [22] might suffice to explore the state space or data ranges [16], along with alternatives such as constraint solving or optimization techniques [20].", "startOffset": 120, "endOffset": 124}, {"referenceID": 19, "context": "For these applications, random data generation or sampling [22] might suffice to explore the state space or data ranges [16], along with alternatives such as constraint solving or optimization techniques [20].", "startOffset": 204, "endOffset": 208}, {"referenceID": 14, "context": "Sophisticated model-based approaches, such as those presented in this paper, offer a practical and viable solution for complex test generation problems [15, 29, 13].", "startOffset": 152, "endOffset": 164}, {"referenceID": 28, "context": "Sophisticated model-based approaches, such as those presented in this paper, offer a practical and viable solution for complex test generation problems [15, 29, 13].", "startOffset": 152, "endOffset": 164}, {"referenceID": 12, "context": "Sophisticated model-based approaches, such as those presented in this paper, offer a practical and viable solution for complex test generation problems [15, 29, 13].", "startOffset": 152, "endOffset": 164}, {"referenceID": 3, "context": "A two layered approach is proposed in [4, 5].", "startOffset": 38, "endOffset": 44}, {"referenceID": 4, "context": "A two layered approach is proposed in [4, 5].", "startOffset": 38, "endOffset": 44}, {"referenceID": 26, "context": "Many languages and formalisms have been proposed for generic software model-based test generation [27], e.", "startOffset": 98, "endOffset": 102}, {"referenceID": 17, "context": "UML and process algebras for concurrency [18], or Lustre and MATLAB/Simulink for data flow [29].", "startOffset": 41, "endOffset": 45}, {"referenceID": 28, "context": "UML and process algebras for concurrency [18], or Lustre and MATLAB/Simulink for data flow [29].", "startOffset": 91, "endOffset": 95}, {"referenceID": 20, "context": "Their suitability for the HRI domain, in terms of capturing realistic and uncertain environments with people, is yet to be determined [21].", "startOffset": 134, "endOffset": 138}, {"referenceID": 7, "context": "BDI agents [8] have been used successfully to model decision making in autonomous robots [12].", "startOffset": 11, "endOffset": 14}, {"referenceID": 11, "context": "BDI agents [8] have been used successfully to model decision making in autonomous robots [12].", "startOffset": 89, "endOffset": 93}, {"referenceID": 2, "context": "In [3], we have shown how to use BDI agents for model-based test generation.", "startOffset": 3, "endOffset": 6}, {"referenceID": 0, "context": "a functional modular description in [1]), as in modelbased software engineering, the verification of the software with respect to functional requirements captured in the model can be performed at design time.", "startOffset": 36, "endOffset": 39}, {"referenceID": 27, "context": "However, mechanisms such as certified code generators are needed to ensure the code is equivalent to the model and thus meets its requirements [28].", "startOffset": 143, "endOffset": 147}, {"referenceID": 2, "context": "We used the scenario we presented in [3], where a human and a robot collaborate to jointly assemble a table.", "startOffset": 37, "endOffset": 40}, {"referenceID": 16, "context": "The robot, BERT2 [17], should, when asked, hand over legs to the person, one at a time.", "startOffset": 17, "endOffset": 21}, {"referenceID": 2, "context": "For this paper, the code and simulator in [3] were slightly modified.", "startOffset": 42, "endOffset": 45}, {"referenceID": 8, "context": "The code was structured as a finite-state machine (FSM) using SMACH [9].", "startOffset": 68, "endOffset": 71}, {"referenceID": 2, "context": "We considered the following selected set of safety and functional requirements from [3] and the standards ISO 13482 (personal care robots), ISO 15066 (collaborative robots) and ISO 10218 (industrial robots):", "startOffset": 84, "endOffset": 87}, {"referenceID": 3, "context": "CDV testbench components (a driver, a checker, and coverage collection) were extended from the ROS infrastructure previously developed in [4, 5], for each case study.", "startOffset": 138, "endOffset": 144}, {"referenceID": 4, "context": "CDV testbench components (a driver, a checker, and coverage collection) were extended from the ROS infrastructure previously developed in [4, 5], for each case study.", "startOffset": 138, "endOffset": 144}, {"referenceID": 25, "context": "This provides branch coverage [26].", "startOffset": 30, "endOffset": 34}, {"referenceID": 3, "context": "We used our previously proposed two-tiered test generation process [4], where abstract tests in the form of timed sequences are generated first, and then valid data is instantiated.", "startOffset": 67, "endOffset": 70}, {"referenceID": 4, "context": "Example tests can be found in [5, 3].", "startOffset": 30, "endOffset": 36}, {"referenceID": 2, "context": "Example tests can be found in [5, 3].", "startOffset": 30, "endOffset": 36}, {"referenceID": 3, "context": "We instantiated and extended our previous implementations of test generation by pseudorandom sampling, model checking TA [4, 5] and BDI agents [3], for the case studies in this paper.", "startOffset": 121, "endOffset": 127}, {"referenceID": 4, "context": "We instantiated and extended our previous implementations of test generation by pseudorandom sampling, model checking TA [4, 5] and BDI agents [3], for the case studies in this paper.", "startOffset": 121, "endOffset": 127}, {"referenceID": 2, "context": "We instantiated and extended our previous implementations of test generation by pseudorandom sampling, model checking TA [4, 5] and BDI agents [3], for the case studies in this paper.", "startOffset": 143, "endOffset": 146}, {"referenceID": 2, "context": "We describe two types of model-based test generation, using BDI agents [3] and model checking TA [4, 5], along with a baseline: pseudorandom test generation.", "startOffset": 71, "endOffset": 74}, {"referenceID": 3, "context": "We describe two types of model-based test generation, using BDI agents [3] and model checking TA [4, 5], along with a baseline: pseudorandom test generation.", "startOffset": 97, "endOffset": 103}, {"referenceID": 4, "context": "We describe two types of model-based test generation, using BDI agents [3] and model checking TA [4, 5], along with a baseline: pseudorandom test generation.", "startOffset": 97, "endOffset": 103}, {"referenceID": 7, "context": "BDI agents model human practical reasoning, in terms of \u2018beliefs\u2019 (knowledge about the world and the agents), \u2018desires\u2019 (goals to fulfil), and \u2018intentions\u2019 (plans to execute in order to achieve the goals, according to the available knowledge) [8].", "startOffset": 243, "endOffset": 246}, {"referenceID": 2, "context": "Recently, we have shown that BDI agents are well suited to model rational, human-like decision making in HRI, for test generation purposes [3].", "startOffset": 139, "endOffset": 142}, {"referenceID": 7, "context": "New beliefs appear during the agents\u2019 execution, can be sent by other agents, or are a result of the execution of plans (self-beliefs) [8].", "startOffset": 135, "endOffset": 138}, {"referenceID": 2, "context": "We reused the BDI model in [3], with minor modifications.", "startOffset": 27, "endOffset": 30}, {"referenceID": 14, "context": "Model checking applied to models of the code or high-level system functionality can be exploited for model-based test generation, where these traces are used to derive tests [15, 29].", "startOffset": 174, "endOffset": 182}, {"referenceID": 28, "context": "Model checking applied to models of the code or high-level system functionality can be exploited for model-based test generation, where these traces are used to derive tests [15, 29].", "startOffset": 174, "endOffset": 182}, {"referenceID": 3, "context": "In [4, 5], we modelled HRI in terms of TA for the model checker UPPAAL.", "startOffset": 3, "endOffset": 9}, {"referenceID": 4, "context": "In [4, 5], we modelled HRI in terms of TA for the model checker UPPAAL.", "startOffset": 3, "endOffset": 9}, {"referenceID": 3, "context": "As a baseline for comparisons we employed a pseudorandom abstract test generator [4, 5].", "startOffset": 81, "endOffset": 87}, {"referenceID": 4, "context": "As a baseline for comparisons we employed a pseudorandom abstract test generator [4, 5].", "startOffset": 81, "endOffset": 87}, {"referenceID": 2, "context": "by using machine learning techniques for the selection of the best belief sets in terms of achieved coverage [3], at the cost of increased computational effort.", "startOffset": 109, "endOffset": 112}, {"referenceID": 5, "context": "In addition, BDI models can also be explored via model checking [6], instead of using verification agents as we propose here.", "startOffset": 64, "endOffset": 67}, {"referenceID": 29, "context": "In addition, constructing automata, such as TA, for larger case studies requires several cycles of abstraction to manage the state-space explosion problem [30].", "startOffset": 155, "endOffset": 159}, {"referenceID": 3, "context": "The test generation methods were applied to two case studies, a cooperative manufacturing task, and a home care scenario, for which high-level robot control code was tested in ROS and Gazebo simulators using a coverage-driven automated testbench [4, 5].", "startOffset": 246, "endOffset": 252}, {"referenceID": 4, "context": "The test generation methods were applied to two case studies, a cooperative manufacturing task, and a home care scenario, for which high-level robot control code was tested in ROS and Gazebo simulators using a coverage-driven automated testbench [4, 5].", "startOffset": 246, "endOffset": 252}], "year": 2016, "abstractText": "Robotic code needs to be verified to ensure its safety and functional correctness, especially when the robot is interacting with people. Testing real code in simulation is a viable option. However, generating tests that cover rare scenarios, as well as exercising most of the code, is a challenge amplified by the complexity of the interactions between the environment and the software. Model-based test generation methods can automate otherwise manual processes and facilitate reaching rare scenarios during testing. In this paper, we compare using BeliefDesire-Intention (BDI) agents as models for test generation with more conventional automata-based techniques that exploit model checking, in terms of practicality, performance, transferability to different scenarios, and exploration (\u2018coverage\u2019), through two case studies: a cooperative manufacturing task, and a home care scenario. The results highlight the advantages of using BDI agents for test generation. BDI agents naturally emulate the agency present in Human-Robot Interactions (HRIs), and are thus more expressive than automata. The performance of the BDI-based test generation is at least as high, and the achieved coverage is higher or equivalent, compared to test generation based on model checking automata.", "creator": "LaTeX with hyperref package"}}}