{"id": "1609.08445", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Sep-2016", "title": "AP16-OL7: A Multilingual Database for Oriental Languages and A Language Recognition Baseline", "abstract": "We present the AP16-OL7 database which was released as the training and test data for the oriental language recognition (OLR) challenge on APSIPA 2016. Based on the database, a baseline system was constructed on the basis of the i-vector model. We report the baseline results evaluated in various metrics defined by the AP16-OLR evaluation plan and demonstrate that AP16-OL7 is a reasonable data resource for multilingual research.", "histories": [["v1", "Tue, 27 Sep 2016 13:50:13 GMT  (664kb,D)", "http://arxiv.org/abs/1609.08445v1", "APSIPA ASC 2016"]], "COMMENTS": "APSIPA ASC 2016", "reviews": [], "SUBJECTS": "cs.CL cs.AI", "authors": ["dong wang", "lantian li", "difei tang", "qing chen"], "accepted": false, "id": "1609.08445"}, "pdf": {"name": "1609.08445.pdf", "metadata": {"source": "CRF", "title": "AP16-OL7: A Multilingual Database for Oriental Languages and A Language Recognition Baseline", "authors": ["Dong Wang", "Lantian Li", "Difei Tang", "Qing Chen"], "emails": ["wangdong99@mails.tsinghua.edu.cn", "lilt13@mails.tsinghua.edu.cn", "tangdifei@speechocean.com", "chenqing@speechocean.com"], "sections": [{"heading": null, "text": "In recent years, the number of unemployed in the United States has multiplied, and the number of unemployed in the United States has multiplied in recent years."}, {"heading": "II. DATABASE PROFILE", "text": "The AP16-OL7 database was originally created by Speechocean Targeting for various speech processing tasks (mainly 1https: / / mc.manuscriptcentral.com / tallip 2https: / / www.iarpa.gov / index.php / research-programs / babel 3http: / / www.ntt-at.com / product / speech2002 / ar Xiv: 160 9.08 445v 1 [cs.C L] September 27, 2016 Speech Recognition) The entire database comprises seven sets of data, each of which is in a specific language. The seven languages are: Mandarin, Cantonese, Indo-Chinese, Japanese, Russian, Korean, Vietnamese. The data volume for each language is approximately 10 hours of speech recognition, recorded by 24 speakers (12 males and 12 females), and each speaker recorded approximately 300 reading-style expressions. The signals were recorded by mobile phones, OLCLES database consisting of a sampling of 16kz and a samplification of each Korean language, each of which consists of a string of 18 strings."}, {"heading": "III. AP16-OLR CHALLENGE", "text": "Based on the AP16-OL7 database, we call the challenge of Oriental Speech Recognition (OLR).5 According to the definition of NIST LRE15 [11], the task of the challenge is defined as follows: taking into account a language segment and a language hypothesis (i.e. a target language of interest that needs to be recognized), the task is to decide whether this target language was actually spoken in the given segment (yes or no), based on an automated analysis of the data contained in the segment. The AP16-OLR evaluation plan also follows the principles of NIST LRE15: 4http: / / speechocean.com 5http: / / cslt.riit.tsinghua.edu.cn / mediawiki / index.php / ASR-events-AP16-detailsit focuses on the narrowly defined condition and does not allow additional training materials other than AP16-OL7. The evaluation details are described as follows."}, {"heading": "A. System input/output", "text": "The input into the OLR system is a set of language segments in unknown languages (but within the 7 languages of AP16OL7). The task of the OLR system is to determine the confidence that a language is contained in a language segment. Specifically, the OLR system returns a score vector for each language segment from < '1,' 2, '2,' 7 >, where \"i represents the confidence that language i is spoken in the language segment.\" Each score \"i is interpreted as follows: If\" i \u2265 0, then the decision would be that language i is included in the segment, otherwise not. Scores should be comparable across languages and segments. This is in accordance with the principle of LRE15, but differs from that of LRE09 [12], where an explicit decision is required for each trial. In summary, the output of an OLR input will be a text file in which each line contains a language segment plus a score vector for this segment... 2... 0.1... 0.1... 0.1 0.1... 0.1 0.1 0.1"}, {"heading": "B. Test condition", "text": "\u2022 No additional training materials may be used. \u2022 All studies should be edited. Results of lost studies are treated as -inf. \u2022 Each test segment should be edited independently of each other. Knowledge from other test segments should not be used (e.g. scoring of all test segments). \u2022 Speakers \"information should not be used. \u2022 Listening to language segments is not permitted."}, {"heading": "C. Evaluation metrics", "text": "As in LRE15, the AP16-OLR challenge chooses Cavg as the principal evaluation metric. First, define the paired loss, which comprises the missing and false alarm probabilities for a particular target / non-target language pair: C (Lt, Ln) = PTargetPMiss (Lt) + (1 \u2212 PTarget) PFA (Lt, Ln), where Lt and Ln are the target and non-target languages respectively; PMiss and PFA are the missing and false alarm probabilities, respectively. Ptarget is the previous probability for the target language set to 0.5 in the evaluation, and then the principal metric Cavg is defined as the average of the above-mentioned paired performance: Cavg = 1N, Lt PTarget \u00b7 PMiss (Lt) + Ln PNon \u2212 Target \u00b7 PFA (Lt, Ln), where N is the number of languages and PNon \u2212 Target = (1 \u2212 PTarget) / N (1) \u2212 1."}, {"heading": "IV. BASELINE RESULTS", "text": "We present basic language recognition systems based on the i-vector model and evaluate performance against the metrics defined by the AP16-OLR challenge. The purpose of these experiments is not to present a competitive template, but to show that the AP16-OL7 database is a reasonable data resource for performing speech recognition research."}, {"heading": "A. Experimental setup", "text": "The baseline system was constructed on the basis of the i-vector model [13], [14]. The static acoustic characteristics included 19-dimensional Mel frequency receiver coefficients (MFCCs) and log energy. These static characteristics were amplified by their first and second order derivatives, resulting in 60-dimensional feature vectors. UBM comprised 2 048 Gaussian components and the dimensionality of the i-vectors was 400. Linear discrimination analysis (LDA) was used to promote language-related information. The dimensionality of the LDA projection space was set to 6. With the i-vectors (either original or after LDA transformation), the score of a track in a particular language can be easily calculated, since the cosinal distance between the test i-vector and the mean i-vector of the training segments belonging to that language is called vectors."}, {"heading": "C. Performance results", "text": "The primary evaluation variable in AP16-OLR is Cavg. In addition, we also present performance in terms of equal error rate (EER), minimum detection cost function (minDCF), detection error compromise (DET) and identification rate (IDR). These metrics evaluate the system from different perspectives and provide a complete picture of the verification / identification capability of the base system.1) Cavg results: Cavg results are presented in Table II. \"Linear,\" \"Poly\" (grade = 3) and \"L vector\" present the results with the cosine distance score; \"i-vector SVM\" and \"L-Vecotr-SVM\" present the results with SVM-based scoring. \"Linear,\" Poly \"(grade = 3) and\" RBF \"represent the results with the cosine distance score;\" i-vector SVM \"and\" SVM \"represent the SVM-Votoring results with the SVM-Votr."}, {"heading": "D. DET curve", "text": "The DET curve is another popular method for evaluating verification systems. Compared to Cavg, EER and minDCF, the DET curve represents performance at all operating points and can therefore evaluate a verification system in a more systematic way. Experimental results are presented in Fig. 3. The black circles represent the place where the minDCFs are obtained. Here, too, similar conclusions can be drawn to those of Cavg, EER and minDCF. 1) IDR results: Note that in the OLR challenge, the target languages are known in the past and the confidence values are comparable across all languages. This means that OLR can be treated as a language identification task where the language that scores the highest in a track is considered as an identification result. In such an identification task, IDR is a widely used metric [16] that treats errors equally in all languages."}, {"heading": "V. CONCLUSIONS", "text": "We presented the data profile of the AP16-OL7 database, which was published in support of the AP16-OLR challenge at APSIPA 2016. The evaluation rules of the challenge were described and a basic system was introduced. We show that the AP16-OL7 database is a suitable data source for speech recognition research."}, {"heading": "ACKNOWLEDGMENT", "text": "This work was supported by the National Science Foundation of China (NSFC) as part of Project No. 61371136 and MESTDC PhD Foundation Project No. 20130002120011 and supported by SpeechOcean."}], "references": [{"title": "The languages of China", "author": ["S.R. Ramsey"], "venue": "Princeton University Press", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1987}, {"title": "The languages of Japan", "author": ["M. Shibatani"], "venue": "Cambridge University Press", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1990}, {"title": "The Russian language in the twentieth century", "author": ["B. Comrie", "G. Stone", "M. Polinsky"], "venue": "Oxford University Press", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1996}, {"title": "Areal linguistics and mainland southeast asia,", "author": ["N.J. Enfield"], "venue": "Annual Review of Anthropology,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2005}, {"title": "Multilingual speech databases at ldc,", "author": ["J.J. Godfrey"], "venue": "Proceedings of the workshop on Human Language Technology. Association for Computational Linguistics,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1994}, {"title": "Globalphone: a multilingual speech and text database developed at karlsruhe university.", "author": ["T. Schultz"], "venue": "in INTERSPEECH,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2002}, {"title": "Speechdat-car", "author": ["A. Moreno", "B. Lindberg", "C. Draxler", "G. Richard", "K. Choukri", "S. Euler", "J. Allen"], "venue": "a large speech database for automotive environments.\u201d in LREC", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2000}, {"title": "Speechdat-e: five eastern european speech databases for voice-operated teleservices completed.", "author": ["H. van den Heuvel", "J. Boudy", "Z. Bakcsi", "J. Cernock\u1ef3", "V. Galunov", "J. Kochanina", "W. Majewski", "P. Pollak", "M. Rusko", "J. Sadowski"], "venue": "INTERSPEECH,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2001}, {"title": "L", "author": ["P. Roach", "S. Arnfield", "W.J. Barry", "J. Baltova", "M. Boldea", "A. Fourcin", "W. Gonet", "R. Gubrynowicz", "E. Hallum"], "venue": "Lamel et al., \u201cBabel: an eastern european multi-language database.\u201d in ICSLP, vol. 96", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1996}, {"title": "and P", "author": ["N. Dehak", "P.G. Kenny", "R. Dehak", "P. Dumouchel"], "venue": "Ouellet, \u201cFront-end factor analysis for speaker verification,\u201d IEEE Transactions on Audio, Speech, and Language Processing, vol. 19, no. 4, pp. 788\u2013 798", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2011}, {"title": "and R", "author": ["N. Dehak", "P.A. Torres-Carrasquillo", "D.A. Reynolds"], "venue": "Dehak, \u201cLanguage recognition via i-vectors and dimensionality reduction,\u201d in INTERSPEECH", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2011}, {"title": "Visualizing data using t-sne,", "author": ["L. v. d. Maaten", "G. Hinton"], "venue": "Machine Learning Research,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2008}, {"title": "and F", "author": ["B. Yin", "E. Ambikairajah"], "venue": "Chen, \u201cHierarchical language identification based on automatic language clustering.\u201d in INTERSPEECH", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2007}], "referenceMentions": [{"referenceID": 0, "context": ", Russian) [2], [3], [4].", "startOffset": 11, "endOffset": 14}, {"referenceID": 1, "context": ", Russian) [2], [3], [4].", "startOffset": 16, "endOffset": 19}, {"referenceID": 2, "context": ", Russian) [2], [3], [4].", "startOffset": 21, "endOffset": 24}, {"referenceID": 3, "context": "For example, many languages in the so-called Mainland Southeast Asia (MSEA) linguistic area posses a particular syllable structure that involves monosyllabic morphemes, lexical tone, a fairly large inventory of consonants [5].", "startOffset": 222, "endOffset": 225}, {"referenceID": 4, "context": "For example, polyphone [6], globalPhone [7], NTT multilingual database3, SPEECHDATCAR [8],Speechdat-E [9], Babel [10], and the multilingual databases created by the new Babel project.", "startOffset": 23, "endOffset": 26}, {"referenceID": 5, "context": "For example, polyphone [6], globalPhone [7], NTT multilingual database3, SPEECHDATCAR [8],Speechdat-E [9], Babel [10], and the multilingual databases created by the new Babel project.", "startOffset": 40, "endOffset": 43}, {"referenceID": 6, "context": "For example, polyphone [6], globalPhone [7], NTT multilingual database3, SPEECHDATCAR [8],Speechdat-E [9], Babel [10], and the multilingual databases created by the new Babel project.", "startOffset": 86, "endOffset": 89}, {"referenceID": 7, "context": "For example, polyphone [6], globalPhone [7], NTT multilingual database3, SPEECHDATCAR [8],Speechdat-E [9], Babel [10], and the multilingual databases created by the new Babel project.", "startOffset": 102, "endOffset": 105}, {"referenceID": 8, "context": "For example, polyphone [6], globalPhone [7], NTT multilingual database3, SPEECHDATCAR [8],Speechdat-E [9], Babel [10], and the multilingual databases created by the new Babel project.", "startOffset": 113, "endOffset": 117}, {"referenceID": 9, "context": "The baseline system was constructed based on the i-vector model [13], [14].", "startOffset": 64, "endOffset": 68}, {"referenceID": 10, "context": "The baseline system was constructed based on the i-vector model [13], [14].", "startOffset": 70, "endOffset": 74}, {"referenceID": 11, "context": "Visualization with T-SNE [15]", "startOffset": 25, "endOffset": 29}, {"referenceID": 11, "context": "To provide an intuitive understanding of the discriminative capability of i-vectors on languages, the i-vectors of all the segments in the test set are plotted in a two-dimensional space via T-SNE [15].", "startOffset": 197, "endOffset": 201}, {"referenceID": 12, "context": "For such an identification task, IDR is a widely used metric [16], which treats errors on all languages equally serious.", "startOffset": 61, "endOffset": 65}], "year": 2016, "abstractText": "We present the AP16-OL7 database which was released as the training and test data for the oriental language recognition (OLR) challenge on APSIPA 2016. Based on the database, a baseline system was constructed on the basis of the i-vector model. We report the baseline results evaluated in various metrics defined by the AP16-OLR evaluation plan and demonstrate that AP16-OL7 is a reasonable data resource for multilingual research.", "creator": "LaTeX with hyperref package"}}}