{"id": "1609.08663", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Sep-2016", "title": "Learning Genomic Representations to Predict Clinical Outcomes in Cancer", "abstract": "Genomics are rapidly transforming medical practice and basic biomedical research, providing insights into disease mechanisms and improving therapeutic strategies, particularly in cancer. The ability to predict the future course of a patient's disease from high-dimensional genomic profiling will be essential in realizing the promise of genomic medicine, but presents significant challenges for state-of-the-art survival analysis methods. In this abstract we present an investigation in learning genomic representations with neural networks to predict patient survival in cancer. We demonstrate the advantages of this approach over existing survival analysis methods using brain tumor data.", "histories": [["v1", "Tue, 27 Sep 2016 20:53:16 GMT  (150kb,D)", "http://arxiv.org/abs/1609.08663v1", "ICLR 2016 Workshop Track- May 2nd 2016 International Conference on Learning Representations"]], "COMMENTS": "ICLR 2016 Workshop Track- May 2nd 2016 International Conference on Learning Representations", "reviews": [], "SUBJECTS": "cs.NE cs.LG", "authors": ["safoora yousefi", "congzheng song", "nelson nauata", "lee cooper"], "accepted": false, "id": "1609.08663"}, "pdf": {"name": "1609.08663.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Safoora Yousefi", "Congzheng Song", "Nelson Nauata", "Lee Cooper"], "emails": ["lee.cooper}@emory.edu"], "sections": [{"heading": "1 INTRODUCTION", "text": "In the treatment of cancer, genomic analysis of a tissue biopsy can reveal specific molecular weaknesses that can be matched to targeted therapies, or to predict the future behavior of a patient's disease and expected survival in order to better inform clinical interventions, including surgery and radiotherapy. Although genomic analysis generates rich high-dimensional signals containing hundreds to hundreds of thousands of variables, typically only multiple variables are used to predict a specific cancer type. Typically, these variables are used to assign patients to discrete disease classes or \"subtypes\" associated with response to specific therapies or varying degrees of disease aggressiveness. Learning the underlying latent prognostic variables from high-dimensional genomic profiles can extract additional predictive value from unused disease classes or \"subtypes\" that are critical to realizing promising genomic medicine."}, {"heading": "2 BACKGROUND AND RELATED WORK", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 HAZARD MODELS AND LIKELIHOOD FUNCTIONS", "text": "Survival analysis involves predicting the time of an event of interest that is often death or disease progression in cancer. It differs from the usual regression due to incomplete observation, where a death or relapse event is not observed during or before the last encounter with the patient. These censored observations provide crucial information and often represent an important population of long-term survivors or treatment recipients to be included in the model. The most commonly used regression method for survival analysis is the Cox proportional hazard Xiv: 160 9.08 663v 1 [cs.N E] 27 Sep 2016 Model proposed by Cox (1972)."}, {"heading": "2.2 RELATED WORKS", "text": "Attempts were made to introduce successful machine learning algorithms such as random forests into survival analysis (Ishwaran et al., 2008). Deep learning techniques were used for cancer diagnosis using genomic data and medical images, such as Fakoor et al. (2013) and Esteva et al. (2008). To the best of my knowledge, representation learning techniques were not applied to predicting survival using genomic data, and previous work investigating neural networks for survival analysis dealt with low dimensional data and different cost functions (Lisboa et al., 2003)."}, {"heading": "3 SURVIVAL PREDICTION NEURAL NETWORK", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 PRETRAINING AND FINE-TUNING", "text": "In this thesis, we trained an autoencoder to represent genomic data and refine this representation based on a partial Log-Cox probability. In the training, we used stacked, denotizing autoencoders proposed in Vincent et al. (2008). We trained the auto encoders based on 183-dimensional genomic characteristics, then added a risk output level as shown in Figure 1. We used survival times and censorship status to calculate the probability of the Cox sub-protocol according to Equation 2 and to differentiate it in relation to X: \u2202 l (\u03b2, X) \u2202 Xi = ci\u03b2 \u2212 \u2211 j-U: i Rj \u03b2eXi\u03b2 \u0445 k Rj e Xk\u03b2 (5), where ci is 1 if sample i is not censored and is otherwise 0, and \u03b2 denotes the parameters of the risk prediction layer. This derivation is then propagated back through the network to refine the learned representation specifically for the task of survival analysis."}, {"heading": "3.2 MODEL SELECTION", "text": "The formation of a neural network involves many hyperparameters: type of nonlinearity used, number of layers, number of hidden units in each layer, learning rates for pre-training, and fine-tuning and regulation parameters. As this is the first paper to use deep neural networks for survival analysis, we have not been able to check the existing literature for a conventional selection of hyperparameters. Unlike areas such as image classification, no rule of thumb has been developed for setting hyperparameters in survival analysis. Therefore, we used Bayesian optimization (MartinezCantin, 2014) with Gauss to reduce the number of objective functional evaluations required to achieve a decent selection of hyperparameters. Shallower networks show superior performance in our experiments compared to deeper architectures. This could be justified by the small number of training samples (628) and the scarcity of labels within the available samples, each of which consists of an average of 250."}, {"heading": "3.3 EVALUATION", "text": "Due to the small size of the available training data, the performance of the model could depend significantly on the subdivision of the data into testing and training processes. To mitigate this, we sampled 10 times from the data set to have 10 permutations of the same data set. Subsequently, in each of the 10 data sets, we used the first 70% of the data for training, half of the remaining 30% of the data for model selection and the other half for model evaluation. We selected the learning rate and elasticity mesh mix coefficient for regulated Cox regression (Hastie & Qian (2014)) to represent the model's generalization error. The exact same setting was used for coordinating and evaluating hyperparameters for competing methods. We selected the learning rate and elasticity network coefficient for regulated Cox regression (Hastie & Qian (2014)), based on the performance of the same validation sets we used for the networks."}, {"heading": "ACKNOWLEDGMENTS", "text": "This work was supported by grants from the US Public Health Service National Institutes of Health (NIH) K22LM011576-03 and U24CA194362-01."}], "references": [{"title": "Regression models and life tables (with discussion)", "author": ["David R Cox"], "venue": "Journal of the Royal Statistical Society,", "citeRegEx": "Cox.,? \\Q1972\\E", "shortCiteRegEx": "Cox.", "year": 1972}, {"title": "Using deep learning to enhance cancer diagnosis and classification", "author": ["Rasool Fakoor", "Faisal Ladhak", "Azade Nazi", "Manfred Huber"], "venue": "In The 30th International Conference on Machine Learning (ICML 2013),WHEALTH workshop,", "citeRegEx": "Fakoor et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Fakoor et al\\.", "year": 2013}, {"title": "Glmnet vignette", "author": ["Trevor Hastie", "Junyang Qian"], "venue": "Technical report, Technical report,", "citeRegEx": "Hastie and Qian.,? \\Q2014\\E", "shortCiteRegEx": "Hastie and Qian.", "year": 2014}, {"title": "Random survival forests", "author": ["Hemant Ishwaran", "Udaya B Kogalur", "Eugene H Blackstone", "Michael S Lauer"], "venue": "The annals of applied statistics,", "citeRegEx": "Ishwaran et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Ishwaran et al\\.", "year": 2008}, {"title": "A bayesian neural network approach for modelling censored data with an application to prognosis after surgery for breast cancer", "author": ["Paulo JG Lisboa", "H Wong", "P Harris", "Ric Swindell"], "venue": "Artificial intelligence in medicine,", "citeRegEx": "Lisboa et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Lisboa et al\\.", "year": 2003}, {"title": "Bayesopt: A bayesian optimization library for nonlinear optimization, experimental design and bandits", "author": ["Ruben Martinez-Cantin"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Martinez.Cantin.,? \\Q2014\\E", "shortCiteRegEx": "Martinez.Cantin.", "year": 2014}, {"title": "On ranking in survival analysis: Bounds on the concordance index", "author": ["Harald Steck", "Balaji Krishnapuram", "Cary Dehing-oberije", "Philippe Lambin", "Vikas C Raykar"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Steck et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Steck et al\\.", "year": 2008}, {"title": "Extracting and composing robust features with denoising autoencoders", "author": ["Pascal Vincent", "Hugo Larochelle", "Yoshua Bengio", "Pierre-Antoine Manzagol"], "venue": "In Proceedings of the 25th international conference on Machine learning,", "citeRegEx": "Vincent et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Vincent et al\\.", "year": 2008}, {"title": "Regularization and variable selection via the elastic net", "author": ["Hui Zou", "Trevor Hastie"], "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology),", "citeRegEx": "Zou and Hastie.,? \\Q2005\\E", "shortCiteRegEx": "Zou and Hastie.", "year": 2005}], "referenceMentions": [{"referenceID": 0, "context": "model proposed by Cox (1972). At time t, the hazard for a sample with covariates x is given by the following hazard function: \u03bb(t|x) = \u03bb0(t)e, (1) where \u03bb0(t) is baseline hazard.", "startOffset": 18, "endOffset": 29}, {"referenceID": 6, "context": "But recent studies show that optimizing the cox partial likelihood is equivalent to optimizing CI (Steck et al., 2008).", "startOffset": 98, "endOffset": 118}, {"referenceID": 3, "context": "Efforts have been made to introduce successful machine learning algorithms such as random forests to survival analysis (Ishwaran et al., 2008).", "startOffset": 119, "endOffset": 142}, {"referenceID": 4, "context": "To the best of our knowledge, representation learning techniques have not been applied to survival prediction from genomic data, and the previous work investigating neural networks for survival analysis dealt with low dimensional data and different cost functions (Lisboa et al., 2003).", "startOffset": 264, "endOffset": 285}, {"referenceID": 1, "context": "Deep learning techniques have been employed for cancer diagnosis using genomic data and medical images, such as Fakoor et al. (2013) and Esteva et al.", "startOffset": 112, "endOffset": 133}, {"referenceID": 0, "context": "1 PRETRAINING AND FINE-TUNING In this work we trained an autoencoder to represent genomic data and fine tune this representation using partial log Cox likelihood. In training, we employ stacked denoising autoencoders proposed in Vincent et al. (2008). We train the auto-encoders using 183-dimensional genomic features, then we add a risk prediction output layer as shown in Figure 1-a.", "startOffset": 147, "endOffset": 251}, {"referenceID": 0, "context": "We picked the learning rate and elastic-net mixture coefficient for regularized Cox regression (Hastie & Qian (2014)) based on performance on the same validation sets we used for the neural networks.", "startOffset": 80, "endOffset": 117}], "year": 2016, "abstractText": "Genomics are rapidly transforming medical practice and basic biomedical research, providing insights into disease mechanisms and improving therapeutic strategies, particularly in cancer. The ability to predict the future course of a patient\u2019s disease from high-dimensional genomic profiling will be essential in realizing the promise of genomic medicine, but presents significant challenges for state-of-the-art survival analysis methods. In this abstract we present an investigation in learning genomic representations with neural networks to predict patient survival in cancer. We demonstrate the advantages of this approach over existing survival analysis methods using brain tumor data.", "creator": "LaTeX with hyperref package"}}}