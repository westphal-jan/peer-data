{"id": "1609.09028", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Sep-2016", "title": "Stance Classification in Rumours as a Sequential Task Exploiting the Tree Structure of Social Media Conversations", "abstract": "Rumour stance classification, the task that determines if each tweet in a collection discussing a rumour is supporting, denying, questioning or simply commenting on the rumour, has been attracting substantial interest. Here we introduce a novel approach that makes use of the sequence of transitions observed in tree-structured conversation threads in Twitter. The conversation threads are formed by harvesting users' replies to one another, which results in a nested tree-like structure. Previous work addressing stance classification task in Twitter has treated each tweet as a separate unit. Here we analyse tweets by virtue of their position in a sequence and test two sequential classifiers, Linear-Chain CRF and Tree CRF, each of which makes different assumptions about the conversation structure. We experiment with eight Twitter datasets, collected during breaking news, and show that exploiting the sequential structure of Twitter conversations achieves significant improvements over the non-sequential methods. Our work is the first to model Twitter conversations as a tree structure in this manner, introducing a novel way of tackling NLP tasks on Twitter conversations.", "histories": [["v1", "Wed, 28 Sep 2016 18:24:12 GMT  (334kb,D)", "https://arxiv.org/abs/1609.09028v1", "COLING 2016"], ["v2", "Tue, 11 Oct 2016 11:54:36 GMT  (334kb,D)", "http://arxiv.org/abs/1609.09028v2", "COLING 2016"]], "COMMENTS": "COLING 2016", "reviews": [], "SUBJECTS": "cs.CL cs.SI", "authors": ["arkaitz zubiaga", "elena kochkina", "maria liakata", "rob procter", "michal lukasik"], "accepted": false, "id": "1609.09028"}, "pdf": {"name": "1609.09028.pdf", "metadata": {"source": "CRF", "title": "Stance Classification in Rumours as a Sequential Task Exploiting the Tree Structure of Social Media Conversations", "authors": ["Arkaitz Zubiaga", "Elena Kochkina", "Maria Liakata", "Rob Procter", "Michal Lukasik"], "emails": ["a.zubiaga@warwick.ac.uk", "e.kochkina@warwick.ac.uk", "m.liakata@warwick.ac.uk", "rob.procter@warwick.ac.uk", "m.lukasik@sheffield.ac.uk"], "sections": [{"heading": "1 Introduction", "text": "While Twitter is a generous source of news reports that exceed even the news media (Kwak et al., 2010), there is also the caveat that some of these reports are still rumors at the time of posting tweets and therefore have yet to be verified and confirmed (Mendoza et al., 2010; Procter et al., 2013b; Procter et al., 2013a). The purpose of the rumor classification is to assist in this verification process by determining the type of support expressed in other tweets that discuss the same rumor (Qazvinian et al., 2011). Aggregating the attitudes of multiple tweets discussing a rumor may then be of help to determine its likely reliability, which - among other advantages - allows the flagging of highly contentious rumors that are likely to be false."}, {"heading": "2 Related Work", "text": "However, interest in this issue has increased considerably, while the line of research initiated by Qazvinian et al. (2011), which is being driven by Qazvinian et al. (2011), is very different from the line of rumors discussed in this paper. They perform a 2-way classification of each tweet as supporting or denying a long-standing rumor, such as the controversial assumptions that Barack Obama is supposedly Muslim. Authors use tweets observed in the past to train a classifier, which is then applied to new tweets that discuss the same rumor. In recent work, rule-based methods have been used as a means to improve the performance of Qazvinian et al. (2011) Baseline is the approach followed by Liu et al. (2015), which has introduced a simple rules-based method that considers the presence of positive or negative words in a tweet."}, {"heading": "3 Stance classification using the conversational structure of Twitter threads", "text": "Thus, the task of classifying rumors is to determine the type of support that each individual post expresses toward the disputed veracity of a rumor = 1.1. The task is particularly interesting in the context of Twitter, where unconfirmed reports of breaking news are continually posted and discussed as they unfold. Originally, this problem was tackled as a dual task of classifying tweets, where each tweet is classified as supportive or denying rumor. However, recent research (Procter et al., 2013b) has found that this categorization is insufficient to cover all different kinds of responses to rumors, and a broader, 4-way classification task is available instead. The argument behind this is that users on social media do not necessarily express a clear inclination to support or deny a rumor, but can also be skeptical by asking questions about it or commenting on the rumor that has nothing to do with its disputed veracity. The four categories in the expanded classification scheme include questioning the support, questioning the support, and questioning the support."}, {"heading": "4 Dataset", "text": "Most of the tweets in this dataset include tree-based conversations triggered by a tweet about a rumor (source text) and nested responses that further discuss the rumor circulated by the source text (replies to tweets). Details of how the note was crowdsourced can be found in tweets in Zubiaga et al. (2015). The annotation scheme used by the authors is slightly different from the one we need for our purposes so that we can adapt it to our needs, as follows. The source text of a conversation is originally commented as supportive or denial, and any subsequent tweet is deemed agreed, contradicted, appealing for more information (query), or commenting on the comments related to the source text."}, {"heading": "5 Experiment Design", "text": "In this section, we describe the classifiers, characteristics, and evaluation standards that we have used in our experiments."}, {"heading": "5.1 Classifiers", "text": "We use CRF as a structured classifier to model sequences that are also observed in other areas. CRF allows us to model the conversation as a graph that is treated as a sequence of distances that also allows us to assess the usefulness of tweets in order to classify the conversation structure for the conversation. Unlike conventional classifiers for this task, which select a label for each input device (e.g. a tweet), CRF also looks at the neighbors of each unit that have the probabilities of transitions of label pairs that are followed by each other. Input for CRF is a graph G = (V, E), where in our case each of the wells V is a tweet, and the edges E are relationships of tweets that replicate each other. Hence, which has a data sequence X as input, CRF gives a sequence of labels Y (Lafferty et) where the output depends."}, {"heading": "5.2 Features", "text": "We use four types of characteristics to represent the tweets. Note that all are local characteristics extracted from the tweet itself \u2022 independently of the rest of the conversation, allowing us to focus on our comparison of how the use of the sequential structure affects the results.Characteristic Type # 1: Lexicon. \u2022 Word Embeddings: a 300-dimensional vector that determines the vector representations of the words in the tweet using Word2Vec (Mikolov et al., 2013).The Word2Vec model for each of the eight folds is trained from the collection of tweets referring to the seven events in the training set, so that the event (and vocabulary) in the test sentence is unknown. \u2022 Part of the speech (POS) tags: a vector where each characteristic represents the number of occurrences of ofa-type POS tag in the tweet. The vector is non-binding: the binary event, the vocabulary in the training, and the binary in the training."}, {"heading": "5.3 Evaluation Measures", "text": "Given that the classes are clearly unbalanced in our case, a rating based solely on accuracy may well be sufficient to capture competitive performance outside the majority class. To account for the imbalance between categories, we use both micro-averaged and macro-averaged F1 values. Note that the micro-averaged F1 value corresponds to the accuracy measurement, while the macro-averaged F1 value supplements this value by measuring the performance that assigns the same weight to each category."}, {"heading": "6 Results", "text": "In fact, the majority-class performance of the classifier has only been marginally outperformed by other classifiers when we look at this rating, which is why we advocate a rating based on macroeconomic ratings of the results of Formula 1 ratings, in terms of the ability of classifiers to produce an output that better matches the distribution of classes. Interestingly, we observe that conditional classifiers (i.e. MaxEnt, Linear CRF, and Tree CRF) are much better than the rest of macroeconomic ratings that are tailored only to the distribution of classes."}, {"heading": "7 Conclusions", "text": "We have introduced a novel method to address the task of classifying rumors, where a classifier must determine whether each tweet supports, disputes, questions, or comments the truthfulness of a rumor. We have dismantled the sequential structure of Twitter conversations in the form of users \"responses to each other, and expanded existing approaches that treat each tweet as a separate entity. We have used two different sequential classifiers: a linear CRF modeling of tree-structured conversations divided into branches, and a tree CRF modeling them as a graph that encompasses the entire tree. These classifiers have been compared to the non-sequentially equivalent equivalent classifier of Maximum Entropy, as well as other base classifiers that are associated with breaking news. While previous work has considered the tweet as a single entity, we have shown that the use of discursive properties of interactions within Twitter can lead to significant improvements in superstructured probabilities."}, {"heading": "Acknowledgments", "text": "This work was supported by the PHEME FP7 project (grant no. 611233), which used Queen Mary's MidPlus computing equipment supported by QMUL Research-IT and funded by the EPSRC funding programme EP / K000128 / 1."}], "references": [{"title": "How can you say such things?!?: Recognizing disagreement in informal political argument", "author": ["Abbott et al.2011] Rob Abbott", "Marilyn Walker", "Pranav Anand", "Jean E Fox Tree", "Robeson Bowmani", "Joseph King"], "venue": "In Proceedings of the Workshop on Languages in Social Media,", "citeRegEx": "Abbott et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Abbott et al\\.", "year": 2011}, {"title": "TwitIE: An open-source information extraction pipeline for microblog text", "author": ["Leon Derczynski", "Adam Funk", "Mark A. Greenwood", "Diana Maynard", "Niraj Aswani"], "venue": "In Proceedings of the International Conference on Recent Advances", "citeRegEx": "Bontcheva et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bontcheva et al\\.", "year": 2013}, {"title": "Exploiting conversational features to detect high-quality blog comments", "author": ["Giuseppe Carenini", "Gabriel Murray", "Shafiq Joty"], "venue": "In Advances in Artificial Intelligence,", "citeRegEx": "FitzGerald et al\\.,? \\Q2011\\E", "shortCiteRegEx": "FitzGerald et al\\.", "year": 2011}, {"title": "Rumor identification and belief investigation on twitter", "author": ["Hamidian", "Diab2016] Sardar Hamidian", "Mona T Diab"], "venue": "In Proceedings of NAACL-HLT,", "citeRegEx": "Hamidian et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Hamidian et al\\.", "year": 2016}, {"title": "What is twitter, a social network or a news media", "author": ["Kwak et al.2010] Haewoon Kwak", "Changhyun Lee", "Hosung Park", "Sue Moon"], "venue": "In Proceedings of the 19th international conference on World wide web,", "citeRegEx": "Kwak et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Kwak et al\\.", "year": 2010}, {"title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data", "author": ["Andrew McCallum", "Fernando Pereira"], "venue": "In Proceedings of the eighteenth international conference on machine learning, ICML,", "citeRegEx": "Lafferty et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Lafferty et al\\.", "year": 2001}, {"title": "Real-time rumor debunking on twitter", "author": ["Liu et al.2015] Xiaomo Liu", "Armineh Nourbakhsh", "Quanzhi Li", "Rui Fang", "Sameena Shah"], "venue": "In Proceedings of the 24th ACM International on Conference on Information and Knowledge Management,", "citeRegEx": "Liu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2015}, {"title": "Classifying tweet level judgements of rumours in social media", "author": ["Trevor Cohn", "Kalina Bontcheva"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Lukasik et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lukasik et al\\.", "year": 2015}, {"title": "2016a. Using gaussian processes for rumour stance classification in social media", "author": ["Kalina Bontcheva", "Trevor Cohn", "Arkaitz Zubiaga", "Maria Liakata", "Rob Procter"], "venue": "arXiv preprint arXiv:1609.01962", "citeRegEx": "Lukasik et al\\.,? \\Q1962\\E", "shortCiteRegEx": "Lukasik et al\\.", "year": 1962}, {"title": "2016b. Hawkes processes for continuous time sequence classification: an application to rumour stance classification in twitter", "author": ["P.K. Srijith", "Duy Vu", "Kalina Bontcheva", "Arkaitz Zubiaga", "Trevor Cohn"], "venue": "In Proceedings of the 54th Meeting of the Association for Computational Linguistics,", "citeRegEx": "Lukasik et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Lukasik et al\\.", "year": 2016}, {"title": "Semeval-2015 task 3: Answer selection in community question answering", "author": ["James Glass", "Walid Magdy", "Alessandro Moschitti", "Preslav Nakov", "Bilal Randeree"], "venue": "Proceedings of SemEval", "citeRegEx": "M\u00e0rquez et al\\.,? \\Q2015\\E", "shortCiteRegEx": "M\u00e0rquez et al\\.", "year": 2015}, {"title": "Twitter under crisis: can we trust what we rt", "author": ["Barbara Poblete", "Carlos Castillo"], "venue": "In Proceedings of the first workshop on social media analytics,", "citeRegEx": "Mendoza et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Mendoza et al\\.", "year": 2010}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Semeval-2016 task 6: Detecting stance in tweets", "author": ["Svetlana Kiritchenko", "Parinaz Sobhani", "Xiaodan Zhu", "Colin Cherry"], "venue": "In Proceedings of the International Workshop on Semantic Evaluation, SemEval,", "citeRegEx": "Mohammad et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Mohammad et al\\.", "year": 2016}, {"title": "Pystruct: learning structured prediction in python", "author": ["M\u00fcller", "Behnke2014] Andreas C M\u00fcller", "Sven Behnke"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "M\u00fcller et al\\.,? \\Q2014\\E", "shortCiteRegEx": "M\u00fcller et al\\.", "year": 2014}, {"title": "Cantijoch. 2013a. Reading the riots: What were the police doing on twitter", "author": ["Procter et al.2013a] Rob Procter", "Jeremy Crump", "Susanne Karstedt", "Alex Voss", "Marta"], "venue": "Policing and society,", "citeRegEx": "Procter et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Procter et al\\.", "year": 2013}, {"title": "Reading the riots on twitter: methodological innovation for the analysis of big data", "author": ["Procter et al.2013b] Rob Procter", "Farida Vis", "Alex Voss"], "venue": "International journal of social research methodology,", "citeRegEx": "Procter et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Procter et al\\.", "year": 2013}, {"title": "Rumor has it: Identifying misinformation in microblogs", "author": ["Emily Rosengren", "Dragomir R Radev", "Qiaozhu Mei"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Qazvinian et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Qazvinian et al\\.", "year": 2011}, {"title": "Finding problem solving threads in online forum", "author": ["Qu", "Liu2011] Zhonghua Qu", "Yang Liu"], "venue": "In Proceedings of IJCNLP,", "citeRegEx": "Qu et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Qu et al\\.", "year": 2011}, {"title": "Unsupervised modeling of twitter conversations", "author": ["Ritter et al.2010] Alan Ritter", "Colin Cherry", "Bill Dolan"], "venue": "In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics,", "citeRegEx": "Ritter et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Ritter et al\\.", "year": 2010}, {"title": "I couldnt agree more: The role of conversational structure in agreement and disagreement detection in online discussions", "author": ["Rosenthal", "McKeown2015] Sara Rosenthal", "Kathleen McKeown"], "venue": "In 16th Annual Meeting of the Special Interest Group on Discourse and Dialogue,", "citeRegEx": "Rosenthal et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Rosenthal et al\\.", "year": 2015}, {"title": "An introduction to conditional random fields", "author": ["Sutton", "McCallum2011] Charles Sutton", "Andrew McCallum"], "venue": "Machine Learning,", "citeRegEx": "Sutton et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Sutton et al\\.", "year": 2011}, {"title": "Microblog analysis as a programme", "author": ["Tolmie et al.2015] Peter Tolmie", "Rob Procter", "Mark Rouncefield", "Maria Liakata", "Arkaitz Zubiaga"], "venue": null, "citeRegEx": "Tolmie et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Tolmie et al\\.", "year": 2015}, {"title": "Detection of agreement and disagreement in broadcast conversations", "author": ["Wen Wang", "Sibel Yaman", "Kristin Precoda", "Colleen Richey", "Geoffrey Raymond"], "venue": "In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers-Volume", "citeRegEx": "Wang et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2011}, {"title": "unconfirmed: Classifying rumor stance in crisis-related social media messages", "author": ["Zeng et al.2016] Li Zeng", "Kate Starbird", "Emma S Spiro"], "venue": "In Tenth International AAAI Conference on Web and Social Media", "citeRegEx": "Zeng et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Zeng et al\\.", "year": 2016}, {"title": "Enquiring minds: Early detection of rumors in social media from enquiry posts", "author": ["Zhao et al.2015] Zhe Zhao", "Paul Resnick", "Qiaozhu Mei"], "venue": "In Proceedings of the 24th International Conference on World Wide Web,", "citeRegEx": "Zhao et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Zhao et al\\.", "year": 2015}, {"title": "Crowdsourcing the annotation of rumourous conversations in social media", "author": ["Maria Liakata", "Rob Procter", "Kalina Bontcheva", "Peter Tolmie"], "venue": "In Proceedings of the 24th International Conference on World Wide Web,", "citeRegEx": "Zubiaga et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Zubiaga et al\\.", "year": 2015}, {"title": "Analysing how people orient to and spread rumours in social media by looking at conversational threads", "author": ["Maria Liakata", "Rob Procter", "Geraldine Wong Sak Hoi", "Peter Tolmie"], "venue": "PLoS ONE,", "citeRegEx": "Zubiaga et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Zubiaga et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 4, "context": "While Twitter is a generous source of reports of breaking news, outpacing even news outlets (Kwak et al., 2010), it also comes with the caveat that some of those reports are still rumours at the time of posting and so are yet to be verified and corroborated (Mendoza et al.", "startOffset": 92, "endOffset": 111}, {"referenceID": 11, "context": ", 2010), it also comes with the caveat that some of those reports are still rumours at the time of posting and so are yet to be verified and corroborated (Mendoza et al., 2010; Procter et al., 2013b; Procter et al., 2013a).", "startOffset": 154, "endOffset": 222}, {"referenceID": 17, "context": "The rumour stance classification task intends to assist in this verification process by determining the type of support expressed in different tweets discussing the same rumour (Qazvinian et al., 2011).", "startOffset": 177, "endOffset": 201}, {"referenceID": 27, "context": "However, such approaches ignore the additional context and knowledge that can be gained from the structure of Twitter interactions within conversational threads (Zubiaga et al., 2016; Procter et al., 2013b; Tolmie et al., 2015).", "startOffset": 161, "endOffset": 227}, {"referenceID": 22, "context": "However, such approaches ignore the additional context and knowledge that can be gained from the structure of Twitter interactions within conversational threads (Zubiaga et al., 2016; Procter et al., 2013b; Tolmie et al., 2015).", "startOffset": 161, "endOffset": 227}, {"referenceID": 16, "context": "Following early work by Qazvinian et al. (2011) introducing the task of rumour stance classification for tweets, interest in this problem has increased substantially.", "startOffset": 24, "endOffset": 48}, {"referenceID": 16, "context": "Following early work by Qazvinian et al. (2011) introducing the task of rumour stance classification for tweets, interest in this problem has increased substantially. However, the line of research initiated by Qazvinian et al. (2011) is significantly different to the one tackled in this paper.", "startOffset": 24, "endOffset": 234}, {"referenceID": 16, "context": "Following early work by Qazvinian et al. (2011) introducing the task of rumour stance classification for tweets, interest in this problem has increased substantially. However, the line of research initiated by Qazvinian et al. (2011) is significantly different to the one tackled in this paper. They perform 2-way classification of each tweet as supporting or denying a long-standing rumour, such as disputed beliefs that Barack Obama is reportedly Muslim. The authors use tweets observed in the past to train a classifier, which is then applied to new tweets discussing the same rumour. In recent work, rule-based methods have been put forward as a way to improve on the performance of the Qazvinian et al. (2011) baseline.", "startOffset": 24, "endOffset": 715}, {"referenceID": 6, "context": "This is the approach followed by Liu et al. (2015), who introduced a simple rule-based method that looks for the presence of positive or negative words in a tweet.", "startOffset": 33, "endOffset": 51}, {"referenceID": 6, "context": "This is the approach followed by Liu et al. (2015), who introduced a simple rule-based method that looks for the presence of positive or negative words in a tweet. One draw back of such rule-based approaches is that they may not generalise to new, unseen rumours. Similarly, Hamidian and Diab (2016) have recently studied the extent to which a model trained from historical tweets can be used for classifying new tweets discussing the same rumour.", "startOffset": 33, "endOffset": 300}, {"referenceID": 6, "context": "This is the approach followed by Liu et al. (2015), who introduced a simple rule-based method that looks for the presence of positive or negative words in a tweet. One draw back of such rule-based approaches is that they may not generalise to new, unseen rumours. Similarly, Hamidian and Diab (2016) have recently studied the extent to which a model trained from historical tweets can be used for classifying new tweets discussing the same rumour. While Zhao et al. (2015) did not study stance classification, they showed that tweets that trigger questioning responses from others are likely to report disputed rumours, which reinforces the motivation of our work of determining the stance of tweets to then deal with rumours.", "startOffset": 33, "endOffset": 473}, {"referenceID": 13, "context": "Classification of stance towards a target on Twitter has been addressed in SemEval-2016 task 6 (Mohammad et al., 2016).", "startOffset": 95, "endOffset": 118}, {"referenceID": 7, "context": "As far as we know, only Lukasik et al. (2015; 2016a; 2016b) have tackled stance classification in the context of breaking news applied to new rumours. Lukasik et al. (2015; 2016a) used Gaussian Processes to perform 3-way stance classification into supporting, denying or questioning, while comments where not considered as part of the task. Lukasik et al. (2016b) did include comments to perform 4-way stance classification; they used Hawkes Processes to exploit the temporal sequence", "startOffset": 24, "endOffset": 364}, {"referenceID": 24, "context": "(Zeng et al., 2016) has also performed stance classification for rumours around breaking news, but overlapping rumours were used for training and testing.", "startOffset": 0, "endOffset": 19}, {"referenceID": 27, "context": "Second, recent research has posited that a 4-way classification is needed to capture responses seen in the unfolding of breaking news (Procter et al., 2013b; Zubiaga et al., 2016).", "startOffset": 134, "endOffset": 179}, {"referenceID": 15, "context": "Second, recent research has posited that a 4-way classification is needed to capture responses seen in the unfolding of breaking news (Procter et al., 2013b; Zubiaga et al., 2016). Moving away from the 2-way classification above, which is somewhat limited for our purposes, we adopt this expanded scheme including tweets that are supporting, denying, querying or commenting rumours. This adds two more categories to the scheme used in early work, where tweets would only support or deny a rumour. Moreover, our approach takes into account the interaction between users on social media, whether it is about appealing for more information in order to corroborate a rumourous post (querying) or to say something that does not contribute to the resolution of the rumour\u2019s veracity (commenting). Finally, instead of dealing with tweets as single units in isolation, we exploit the conversational structure of Twitter replies, building a classifier that learns the dynamics of stance in tree-structured conversational threads. The closest work when it comes to exploiting conversational structure in tweets is that of Ritter et al. (2010) who modelled linear sequences of replies in Twitter conversations with Hidden Markov Models for dialogue act tagging, but the structure of the tree as a whole was not exploited.", "startOffset": 135, "endOffset": 1133}, {"referenceID": 10, "context": "This was later further studied in a SemEval shared task, where each post in a forum thread had to also be classified as good, potential or bad (M\u00e0rquez et al., 2015).", "startOffset": 143, "endOffset": 165}, {"referenceID": 6, "context": "A work that is related is that of Lukasik et al. (2016b), who exploited the temporal sequence of tweets, although the conversational structure was ignored and each tweet was treated as a separate unit.", "startOffset": 34, "endOffset": 57}, {"referenceID": 6, "context": "A work that is related is that of Lukasik et al. (2016b), who exploited the temporal sequence of tweets, although the conversational structure was ignored and each tweet was treated as a separate unit. In other domains where debates or conversations are involved, the sequence of responses has been exploited to make the most of the evolving discourse and perform an improved classification of each individual post after learning the structure and dynamics of the conversation as a whole. For instance, Qu and Liu (2011) found Hidden Markov Models to be an effective approach to classify threads in on-line fora as successfully solving or not the question raised in the initial post.", "startOffset": 34, "endOffset": 521}, {"referenceID": 2, "context": "FitzGerald et al. (2011) used a linear-chain CRF to identify high-quality comments in threads responding to blog posts.", "startOffset": 0, "endOffset": 25}, {"referenceID": 23, "context": "CRF has also been used to detect agreement and disagreement between speakers in broadcast debates (Wang et al., 2011), which our task differs from in that it solely focuses on text.", "startOffset": 98, "endOffset": 117}, {"referenceID": 0, "context": "To classify agreement between question-answer (Q-A) message pairs in fora, Abbott et al. (2011) used Naive Bayes as the classifier, and Rosenthal and McKeown (2015) used a logistic regression classifier.", "startOffset": 75, "endOffset": 96}, {"referenceID": 0, "context": "To classify agreement between question-answer (Q-A) message pairs in fora, Abbott et al. (2011) used Naive Bayes as the classifier, and Rosenthal and McKeown (2015) used a logistic regression classifier.", "startOffset": 75, "endOffset": 165}, {"referenceID": 22, "context": "Moreover, within this task we propose leveraging conversation structure as one of the main features that characterise social media (Tolmie et al., 2015).", "startOffset": 131, "endOffset": 152}, {"referenceID": 27, "context": "We use the PHEME rumour dataset associated with eight events corresponding to breaking news stories (Zubiaga et al., 2016), which provide tweet-level annotations for stance1.", "startOffset": 100, "endOffset": 122}, {"referenceID": 26, "context": "We use the PHEME rumour dataset associated with eight events corresponding to breaking news stories (Zubiaga et al., 2016), which provide tweet-level annotations for stance1. Tweets in this dataset include tree-structured conversations, which are initiated by a tweet about a rumour (source tweet) and nested replies that further discuss the rumour circulated by the source tweet (replying tweets). Details on how the annotation was conducted through crowdsourcing can be found in Zubiaga et al. (2015).", "startOffset": 101, "endOffset": 503}, {"referenceID": 5, "context": "Hence, having a data sequence X as input, CRF outputs a sequence of labels Y (Lafferty et al., 2001), where the output of each element yi will not only depend on its features, but also on the probabilities of other labels surrounding it.", "startOffset": 77, "endOffset": 100}, {"referenceID": 12, "context": "\u2022 Word Embeddings: a vector with 300 dimensions averaging vector representations of the words in the tweet using Word2Vec (Mikolov et al., 2013).", "startOffset": 122, "endOffset": 144}, {"referenceID": 1, "context": "The vector is then composed of the numbers of occurrences of different POS tags in the tweet, parsed using Twitie (Bontcheva et al., 2013).", "startOffset": 114, "endOffset": 138}, {"referenceID": 7, "context": "For comparison with the state-of-the-art stance classification approach by Lukasik et al. (2016b), we present results broken down by event in Table 4, both for their approach based on Hawkes Processes as well as our Tree CRF approach.", "startOffset": 75, "endOffset": 98}, {"referenceID": 7, "context": "For comparison with the state-of-the-art stance classification approach by Lukasik et al. (2016b), we present results broken down by event in Table 4, both for their approach based on Hawkes Processes as well as our Tree CRF approach. Note that Lukasik et al. (2016b) only tested their approach on four of the events, and therefore performance scores for the rest of the events are not shown.", "startOffset": 75, "endOffset": 268}, {"referenceID": 7, "context": "Table 4: Micro- and Macro-F1 performance results broken down by event, along with a comparison with the results obtained by Lukasik et al. (2016b)\u2019s state-of-the-art approach based on Hawkes Processes, where available.", "startOffset": 124, "endOffset": 147}], "year": 2016, "abstractText": "Rumour stance classification, the task that determines if each tweet in a collection discussing a rumour is supporting, denying, questioning or simply commenting on the rumour, has been attracting substantial interest. Here we introduce a novel approach that makes use of the sequence of transitions observed in tree-structured conversation threads in Twitter. The conversation threads are formed by harvesting users\u2019 replies to one another, which results in a nested tree-like structure. Previous work addressing the stance classification task has treated each tweet as a separate unit. Here we analyse tweets by virtue of their position in a sequence and test two sequential classifiers, Linear-Chain CRF and Tree CRF, each of which makes different assumptions about the conversational structure. We experiment with eight Twitter datasets, collected during breaking news, and show that exploiting the sequential structure of Twitter conversations achieves significant improvements over the non-sequential methods. Our work is the first to model Twitter conversations as a tree structure in this manner, introducing a novel way of tackling NLP tasks on Twitter conversations.", "creator": "LaTeX with hyperref package"}}}