{"id": "1609.09226", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Sep-2016", "title": "ICE: Information Credibility Evaluation on Social Media via Representation Learning", "abstract": "With the rapid growth of social media, rumors are also spreading widely on social media and bring harm to people's daily life. Nowadays, information credibility evaluation has drawn attention from academic and industrial communities. Current methods mainly focus on feature engineering and achieve some success. However, feature engineering based methods require a lot of labor and cannot fully reveal the underlying relations among data. In our viewpoint, the key elements of user behaviors for evaluating credibility are concluded as \"who\", \"what\", \"when\", and \"how\". These existing methods cannot model the correlation among different key elements during the spreading of microblogs. In this paper, we propose a novel representation learning method, Information Credibility Evaluation (ICE), to learn representations of information credibility on social media. In ICE, latent representations are learnt for modeling user credibility, behavior types, temporal properties, and comment attitudes. The aggregation of these factors in the microblog spreading process yields the representation of a user's behavior, and the aggregation of these dynamic representations generates the credibility representation of an event spreading on social media. Moreover, a pairwise learning method is applied to maximize the credibility difference between rumors and non-rumors. To evaluate the performance of ICE, we conduct experiments on a Sina Weibo data set, and the experimental results show that our ICE model outperforms the state-of-the-art methods.", "histories": [["v1", "Thu, 29 Sep 2016 07:04:28 GMT  (287kb,D)", "http://arxiv.org/abs/1609.09226v1", "IEEE Transactions on Information Forensics and Security (TIFS), under review"], ["v2", "Fri, 30 Sep 2016 01:20:32 GMT  (354kb,D)", "http://arxiv.org/abs/1609.09226v2", "IEEE Transactions on Information Forensics and Security (TIFS), under review"], ["v3", "Mon, 10 Oct 2016 02:06:51 GMT  (286kb,D)", "http://arxiv.org/abs/1609.09226v3", "IEEE Transactions on Information Forensics and Security (TIFS), under review"], ["v4", "Mon, 24 Oct 2016 07:32:16 GMT  (286kb,D)", "http://arxiv.org/abs/1609.09226v4", "IEEE Transactions on Information Forensics and Security (TIFS), under review"]], "COMMENTS": "IEEE Transactions on Information Forensics and Security (TIFS), under review", "reviews": [], "SUBJECTS": "cs.SI cs.AI", "authors": ["qiang liu", "shu wu", "feng yu", "liang wang", "tieniu tan"], "accepted": false, "id": "1609.09226"}, "pdf": {"name": "1609.09226.pdf", "metadata": {"source": "CRF", "title": "ICE: Information Credibility Evaluation on Social Media via Representation Learning", "authors": ["Qiang Liu", "Shu Wu", "Feng Yu", "Liang Wang"], "emails": ["tnt}@nlpr.ia.ac.cn."], "sections": [{"heading": null, "text": "In fact, most of them are able to survive on their own."}, {"heading": "II. RELATED WORK", "text": "In this section, we discuss some related work, including social media credibility testing, presentation learning, and truth-telling."}, {"heading": "A. Credibility Evaluation on Social Media", "text": "Most methods are based on artificial characteristics, some of which evaluate the credibility of a single microblog [3] [27] or a single image [10], some of which evaluate the credibility of information at the event level to determine whether an event is a rumor or a non-rumor [11] [31] [16] [42] [22], where each event consists of several microblogs. News Credibility Propagation (NewsCP) [14] examines how to act at the event level of credibility from the microblogging level, and presents a graphical optimization method that incorporates other conflict points into the model [15]. Some works recognize rumors based on dynamic characteristics. For example, the Periodic External Shocks (PES) model [16] examines how ordinary structural features and user functions function, and designs temporal characteristics according to characteristics that spread over time."}, {"heading": "B. Representation Learning", "text": "In the meantime, the network has drawn much attention to the investigation of nodes [12] or the diffusion of information. In the meantime, the network models have taken a random path [13] and linking to the representation methods is also important for the modelling of user behaviours. Contextual Operating Tensor (COT) [13] and CARS2 [13] have a linkage of user behaviours."}, {"heading": "C. Truth Discovery", "text": "Finding the truth refers to the problem of finding the truth with contradictory information, which was first dealt with in complex social media. Finding the truth can be considered as a way of assessing the credibility of information. Finding the truth evaluates the credibility mainly on the basis of information from different sources. Finding the truth is usually based on Bayesian algorithms or graphical learning algorithms based on inventory data or flight data [17] [33]. And Semi-Supervised Truth Discovery (SSTF) [39] investigates the problem of semi-supervised graph learning using a small set of basic truth data to assess the credibility. Finding the truth is an unsupervised or semi-supervised method of finding the truth with contradictory information and assessing the credibility of information [17]. Finding the truth is mainly based on the evaluated credibility aggregated from various sources of information, usually referring to users who share information with contradictory information and are not suitable for most types of social media and are not complex to say in most cases."}, {"heading": "III. DATA", "text": "In this section, we present our data set. Given the lack of public rumor records, we gathered a microblog record of rumors and non-rumors from Sina Weibo, the largest social media in China. To sift through rumors, we gathered some suspicious rumors, i.e. some microblogs with rumors that were reported, from the Sina Weibo Misinformation Management Center. We extracted keywords from these rumor grains and retrieved rumor microblogs with those keywords. Then we identified the starting point of a rumor, i.e. the first microblog about the rumor, and collected all the following microblogs. For each microblog, we collected its reposting information, commented information, and the corresponding user profile. To sift through non-rumors, we gathered some hot topics on Sina Weibo and used the same strategy as for rumors to search for relevant information about the non-rubrics."}, {"heading": "IV. THE ICE MODEL", "text": "In this section we first formulate the problem, then we detail the proposed ICE model, and finally we present the paired learning procedure for the ICE model."}, {"heading": "A. Problem Formulation", "text": "The problem we have examined in this paper can be formulated in mathematics as follows: Suppose a series of events is called E = {e1, e2,..., en} and is the credibility score of the corresponding event ei. sei = 0 means event ei is a rumor and sei = 1 means event ei is a non-rumor. The microblogs of the event ei can be called Mei = {mei1, m ei 2,..., m ei nei}, where nei is the number of microblogs of that event. All microblogs can be written as M = {Me1, Me2,..., men}. Each microblogmeij consists of four elements \"who,\" \"what,\" \"how\" and \"when,\" which are called ueij, b ei j, c ei j, c j and t ei j. ueij is the corresponding user of the microblog, b ei j is the behavioral styling (posting or reposting of this work), which describes the settings of the user or the social media object since the beginning or the task."}, {"heading": "B. Proposed Model", "text": "It is necessary for a model that is based on the credibility of the user (who), behaviors (what), comment settings (how) and dynamic properties (when). We start first with user information and behavioral information. User information tells us the characteristics and credibility of a user. Behavior information tells us the type of behavior, i.e., the posting or translation of blog information. In addition, the combination of these two information shows \"who did what.\" Mathematically, for the j-th microblog meij of the event egg, the representation of this microblog with the user ueij and the behavior of asReij can be written."}, {"heading": "C. User Representation Generation", "text": "For learning user representations, i.e., \"who,\" in the ICE model, it would be desirable if we could learn a unique latent vector for each user to capture its characteristics and credibility. However, according to Table I, each user provides an average of only two microblogs that cannot provide enough information to directly learn a latent representation for each user. Instead, we can learn embedding rich functions for users.These functions, which are contained in the Weibo dataset, are gender, number of followers, number of microblogs and verified or not. Then, users can be formed based on the above characteristics. For user u, we have a feature vector Fu-Rf, which is constructed asFu = [F gender u, F follower u, F follower, F follower, F verified u] T. Both Fgenderu and F verified u have two bits. Gender-Rf (1) means that we will differentiate between gender and Fu."}, {"heading": "D. Nonlinear Interpolation for Generating Time-Specific Matrices", "text": "In ICE, we use time-specific matrices \u2212 to capture the properties of the dynamic behavior of users, i.e., \"when,\" in the information distribution. However, if we learn a unique matrix for each possible continuous time interval, the ICE model faces the problem of data sparseness. Therefore, as in [20], it is not plausible to divide the time interval evenly. Instead, our partition confirms a log2 distribution. Only the matrices of the upper and lower limits of the corresponding bins are learned in our model. For time intervals in a timebin, their transition matrices can be calculated using a nonlinear interpolation (T2). \u2212 A time-specific matrix Tt for time interval can be represented as Tt = (U gt2 = gtU gt2 gtloding) and a lower one (T2 loding) as Tt."}, {"heading": "E. Pair-wise Learning", "text": "Here we present the following objective function: J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J J = J = J = J = J"}, {"heading": "V. EXPERIMENTS", "text": "In this section, we conduct empirical experiments to demonstrate the effectiveness of the ICE model on the Sina Weibo dataset. First, we present the settings of our experiments, then we compare the ICE model with the most modern basic methods, then we examine the performance of the ICE model with different parameters and under different situations, and finally, we analyze the scalability of the ICE model."}, {"heading": "A. Experimental Settings", "text": "We randomly use 60% of the events (rumors or non-rumors) in the dataset for training, 30% for testing, and the remaining 10% data as validation parameters, i.e. the dimensionality of the latent representations and the regulation parameters. In addition, we have several evaluation yardsticks for the contents of our experiments: Accuracy, Precision, Recall, Recall, and F1 Score. Accuracy is a standard measurement for classification tasks that is evaluated based on the percentage of correctly predicted rumors and non-rumors. Precision, Recall, and F1 Score are widely used measurements for classification tasks that are calculated according to the correctly predicted rumors or non-rumors. The larger the values of the above evaluation yardsticks, the better the performance."}, {"heading": "B. Performance Comparison", "text": "In order to investigate the performance of ICE and compared to other methods, we conduct experiments on the Weibo data sets and report on the accuracy, precision, precision and precision recall curves of these methods.Table II illustrates the performance comparison with dimensionality d = 87. In addition, the results of Accuracy, Precision, Precision and F1 scores are evaluated, which could indicate that the social characteristics are more important than the content characteristics of NewsCP-Social. Meanwhile, we can see that the performance of NewsCP-Social is better than that of NewsCP-Social content. This could indicate that social characteristics are more important for evaluating credibility. Both types of characteristics, NewsCP achieves great improvements and has a satisfactory performance. Then, EP improves the performance of NewsCP-Social."}, {"heading": "D. Performance Under Different Situations", "text": "We have shown that the proposed ICE model can outperform the state-of-the-art methods. In addition, we will investigate whether ICE can outperform the methods compared in some specific situations. We divide our data by topic and popularity, and the results are shown by Accuracy under different situations in Table III. Distribution of the different situations is shown in Figure 9. By topic of the events we first divide into five categories: Society, Life, Politics, Politics and Entertainment, as shown in Figure 9 (a). Topic \"Society\" talks about all kinds of things happening around us, topic \"Life\" contains life skills such as health tips, topic \"Politics\" means news about newly published policies, topic \"Politics\" and topic \"Entertainment\" means news about movies, music and sports. \"Table III shows the accuracy of the different methods on the five topics."}, {"heading": "E. Scalability Analysis", "text": "In addition to analyzing the effectiveness of ICE, we also examine the scalability of the ICE model with different parts of the Weibo dataset. The model is implemented with Python8 and Theano9. The code is executed on a computer with a 4 core 2.5 GHz CPU and 16 GB RAM, and the GPU model is NVIDIA Tesla K20Xm. On the Weibo dataset, we measure the corresponding time cost of an iteration in both the training and testing process. Figure 10 shows the time consumption with different portions of the entire dataset. We can observe that both the training and the test time consumption of ICE are linear in terms of the size of the dataset. This shows the scalability of ICE. Our proposed model can not only reach the state of 8https: / / www.python.org /. 9http: / / deeplearning.net / software / theano /.of-the-art-preseason, but also effectively run on large-area data."}, {"heading": "VI. SYSTEM", "text": "Instead of using the ICE model only in academic data sets and research papers, it is critical to develop a real-time rating system for the credibility of information on social media and apply our proposed model to real-world applications. Therefore, based on our model and the Sina Weibo data set, we have built a Network Information Credibility Evaluation (NICE) system [35]. NICE is a web-based system that can automatically search for online information from Sina Weibo and evaluate the credibility of online information users are requesting.Figure 11 illustrates the flow chart of the NICE system. Via the system, a user can enter a query to retrieve the related information. If a user's query matches rumors in the Weibo data set, users can immediately identify the rumor. Otherwise, NICE will search the real-time information from social media, i.e. the user can select a microblog to evaluate the information based on the microblog belonging to the system."}, {"heading": "VII. CONCLUSIONS AND FUTURE WORK", "text": "In this work, to evaluate the credibility of information on social media, a new method was proposed, namely ICE. ICE aims to learn dynamic representations for microblogs that describe events that occur on social media. Learning is based on the credibility of users, behavioral types, temporal characteristics and comment settings. Aggregating these key factors makes the dynamic and collective representation of microblogs and aggregation of representations of all microblogs during information dissemination possible to generate the credibility representation of events on social media. Experiments conducted with a real data set searched by Sina Weibo show that ICE significantly outperforms the most modern methods. In the future, we can further investigate the following directions: First, content information was not taken into account in ICE when learning credibility representations. We plan to analyze the event content and extract key elements therein in order to determine the likelihood of the event based on a large-scale web news platform, for example, to predict a secondary event, and other information about our model."}], "references": [{"title": "Representation learning: A review and new perspectives", "author": ["Y. Bengio", "A. Courville", "P. Vincent"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2013}, {"title": "Learning social network embeddings for predicting information diffusion", "author": ["S. Bourigault", "C. Lagnier", "S. Lamprier", "L. Denoyer", "P. Gallinari"], "venue": "In Proceedings of the 7th ACM international conference on Web search and data mining,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2014}, {"title": "Information credibility on twitter", "author": ["C. Castillo", "M. Mendoza", "B. Poblete"], "venue": "In Proceedings of the 20th international conference on World wide web,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2011}, {"title": "Libsvm: a library for support vector machines", "author": ["C.-C. Chang", "C.-J. Lin"], "venue": "ACM Transactions on Intelligent Systems and Technology (TIST),", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2011}, {"title": "Rumor, gossip and urban legends", "author": ["N. DiFonzo", "P. Bordia"], "venue": "Diogenes,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2007}, {"title": "A multi-view deep learning approach for cross domain user modeling in recommendation systems", "author": ["A.M. Elkahky", "Y. Song", "X. He"], "venue": "In Proceedings of the 24th International Conference on World Wide Web,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "Personalized ranking metric embedding for next new poi recommendation", "author": ["S. Feng", "X. Li", "Y. Zeng", "G. Cong", "Y.M. Chee", "Q. Yuan"], "venue": "In Proceedings of the 24th International Conference on Artificial Intelligence,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2015}, {"title": "Crowdsourcing credibility: The impact of audience feedback on web page credibility", "author": ["K.D. Giudice"], "venue": "Proceedings of the American Society for Information Science and Technology,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "node2vec: Scalable feature learning for networks", "author": ["A. Grover", "J. Leskovec"], "venue": "In Proceedings of the 22nd ACM International Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2016}, {"title": "Faking sandy: characterizing and identifying fake images on twitter during hurricane sandy", "author": ["A. Gupta", "H. Lamba", "P. Kumaraguru", "A. Joshi"], "venue": "In Proceedings of the 22nd international conference on World Wide Web companion,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2013}, {"title": "Evaluating event credibility on twitter", "author": ["M. Gupta", "P. Zhao", "J. Han"], "venue": "In Proceedings of the 12th SIAM International Conference on Data Mining,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2012}, {"title": "Learning latent representations of nodes for classifying in heterogeneous social networks", "author": ["Y. Jacob", "L. Denoyer", "P. Gallinari"], "venue": "In Proceedings of the 7th ACM international conference on Web search and data mining,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2014}, {"title": "Misinformation propagation in the age of twitter", "author": ["F. Jin", "W. Wang", "L. Zhao", "E. Dougherty", "Y. Cao", "C.-T. Lu", "N. Ramakrishnan"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "News credibility evaluation on microblog with a hierarchical propagation model", "author": ["Z. Jin", "J. Cao", "Y.-G. Jiang", "Y. Zhang"], "venue": "In Data Mining (ICDM),", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "News verification by exploiting conflicting social viewpoints in microblogs", "author": ["Z. Jin", "J. Cao", "Y. Zhang", "J. Luo"], "venue": "In Proceedings of the 30th AAAI Conference on Artificial Intelligence,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2016}, {"title": "Prominent features of rumor propagation in online social media", "author": ["S. Kwon", "M. Cha", "K. Jung", "W. Chen", "Y. Wang"], "venue": "In Data Mining (ICDM),", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2013}, {"title": "Truth finding on the deep web: Is the problem solved", "author": ["X. Li", "X.L. Dong", "K. Lyons", "W. Meng", "D. Srivastava"], "venue": "Proceedings of the VLDB Endowment,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2012}, {"title": "Collaborative prediction for multientity interaction with hierarchical representation", "author": ["Q. Liu", "S. Wu", "L. Wang"], "venue": "In Proceedings of the 24th ACM International on Conference on Information and Knowledge Management,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2015}, {"title": "Cot: Contextual operating tensor for context-aware recommender systems", "author": ["Q. Liu", "S. Wu", "L. Wang"], "venue": "In Proceedings of the 29th AAAI Conference on Artificial Intelligence,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2015}, {"title": "Predicting the next location: A recurrent model with spatial and temporal contexts", "author": ["Q. Liu", "S. Wu", "L. Wang", "T. Tan"], "venue": "In Proceedings of the 30th AAAI Conference on Artificial Intelligence,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2016}, {"title": "A convolutional click prediction model", "author": ["Q. Liu", "F. Yu", "S. Wu", "L. Wang"], "venue": "In Proceedings of the 24th ACM International on Conference on Information and Knowledge Management,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2015}, {"title": "Detect rumors using time series of social context information on microblogging websites", "author": ["J. Ma", "W. Gao", "Z. Wei", "Y. Lu", "K.-F. Wong"], "venue": "In Proceedings of the 24th ACM International on Conference on Information and Knowledge Management,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2015}, {"title": "Recurrent neural network based language model", "author": ["T. Mikolov", "M. Karafi\u00e1t", "L. Burget", "J. Cernock\u1ef3", "S. Khudanpur"], "venue": "In INTERSPEECH,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2010}, {"title": "Extensions of recurrent neural network language model", "author": ["T. Mikolov", "S. Kombrink", "L. Burget", "J.H. \u010cernock\u1ef3", "S. Khudanpur"], "venue": "In Acoustics, Speech and Signal Processing (ICASSP),", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2011}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["T. Mikolov", "I. Sutskever", "K. Chen", "G.S. Corrado", "J. Dean"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2013}, {"title": "Deepwalk: Online learning of social representations", "author": ["B. Perozzi", "R. Al-Rfou", "S. Skiena"], "venue": "In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2014}, {"title": "Rumor has it: Identifying misinformation in microblogs", "author": ["V. Qazvinian", "E. Rosengren", "D.R. Radev", "Q. Mei"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2011}, {"title": "Bpr: Bayesian personalized ranking from implicit feedback", "author": ["S. Rendle", "C. Freudenthaler", "Z. Gantner", "L. Schmidt-Thieme"], "venue": "In Proceedings of the twenty-fifth conference on uncertainty in artificial intelligence,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2009}, {"title": "Audience-aware credibility: From understanding audience to establishing credible blogs", "author": ["S.Y. Rieh", "G.Y. Jeon", "J.Y. Yang", "C. Lampe"], "venue": "In Proceedings of the 8th International Conference on Weblogs and Social Media. AAAI Press,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2014}, {"title": "Cars2: Learning context-aware representations for context-aware recommendations", "author": ["Y. Shi", "A. Karatzoglou", "L. Baltrunas", "M. Larson", "A. Hanjalic"], "venue": "In Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2014}, {"title": "Detecting event rumors on sina weibo automatically", "author": ["S. Sun", "H. Liu", "J. He", "X. Du"], "venue": "In Web Technologies and Applications,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2013}, {"title": "Line: Large-scale information network embedding", "author": ["J. Tang", "M. Qu", "M. Wang", "M. Zhang", "J. Yan", "Q. Mei"], "venue": "In Proceedings of the 24th International Conference on World Wide Web,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2015}, {"title": "Truth discovery algorithms: An experimental evaluation", "author": ["D.A. Waguih", "L. Berti-Equille"], "venue": "arXiv preprint arXiv:1409.6428,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2014}, {"title": "Learning hierarchical representation model for next basket recommendation", "author": ["P. Wang", "J. Guo", "Y. Lan", "J. Xu", "S. Wan", "X. Cheng"], "venue": "In Proceedings of the 38th International ACM SIGIR conference on Research and Development in Information Retrieval,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2015}, {"title": "Information credibility evaluation on social media", "author": ["S. Wu", "Q. Liu", "Y. Liu", "L. Wang", "T. Tan"], "venue": "In Proceedings of the 30th AAAI Conference on Artificial Intelligence,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2016}, {"title": "Contextual operation for recommender systems", "author": ["S. Wu", "Q. Liu", "L. Wang", "T. Tan"], "venue": "Knowledge and Data Engineering, IEEE Transactions on,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2016}, {"title": "Collaborative denoising auto-encoders for top-n recommender systems", "author": ["Y. Wu", "C. DuBois", "A.X. Zheng", "M. Ester"], "venue": "In Proceedings of the Ninth ACM International Conference on Web Search and Data Mining,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2016}, {"title": "Truth discovery with multiple conflicting information providers on the web. Knowledge and Data Engineering", "author": ["X. Yin", "J. Han", "P.S. Yu"], "venue": "IEEE Transactions on,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2008}, {"title": "Semi-supervised truth discovery", "author": ["X. Yin", "W. Tan"], "venue": "In Proceedings of the 20th international conference on World wide web,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2011}, {"title": "A dynamic recurrent model for next basket recommendation", "author": ["F. Yu", "Q. Liu", "S. Wu", "L. Wang", "T. Tan"], "venue": "In Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2016}, {"title": "Deep learning over multi-field categorical data - - A case study on user response prediction", "author": ["W. Zhang", "T. Du", "J. Wang"], "venue": "In Proceedings of the 38th European Conference on Information Retrieval,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2016}, {"title": "Enquiring minds: Early detection of rumors in social media from enquiry posts", "author": ["Z. Zhao", "P. Resnick", "Q. Mei"], "venue": "In Proceedings of the 24th International Conference on World Wide Web,", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2015}], "referenceMentions": [{"referenceID": 4, "context": "A rumor is an unverified and instrumentally relevant statement of information spreading among people [5].", "startOffset": 101, "endOffset": 104}, {"referenceID": 2, "context": "Most of the methods are based on content information and source credibility at the microblog level [3][27][10] or event (containing a group of microblogs) level [16][42][22].", "startOffset": 99, "endOffset": 102}, {"referenceID": 26, "context": "Most of the methods are based on content information and source credibility at the microblog level [3][27][10] or event (containing a group of microblogs) level [16][42][22].", "startOffset": 102, "endOffset": 106}, {"referenceID": 9, "context": "Most of the methods are based on content information and source credibility at the microblog level [3][27][10] or event (containing a group of microblogs) level [16][42][22].", "startOffset": 106, "endOffset": 110}, {"referenceID": 15, "context": "Most of the methods are based on content information and source credibility at the microblog level [3][27][10] or event (containing a group of microblogs) level [16][42][22].", "startOffset": 161, "endOffset": 165}, {"referenceID": 41, "context": "Most of the methods are based on content information and source credibility at the microblog level [3][27][10] or event (containing a group of microblogs) level [16][42][22].", "startOffset": 165, "endOffset": 169}, {"referenceID": 21, "context": "Most of the methods are based on content information and source credibility at the microblog level [3][27][10] or event (containing a group of microblogs) level [16][42][22].", "startOffset": 169, "endOffset": 173}, {"referenceID": 13, "context": "Some research also studies the aggregation of credibility from the microblog level to the event level [14].", "startOffset": 102, "endOffset": 106}, {"referenceID": 15, "context": "On the contrary, considering dynamic information, some work designs temporal features based on prorogation properties over time [16] or trains a model with features generated from different time periods [22].", "startOffset": 128, "endOffset": 132}, {"referenceID": 21, "context": "On the contrary, considering dynamic information, some work designs temporal features based on prorogation properties over time [16] or trains a model with features generated from different time periods [22].", "startOffset": 203, "endOffset": 207}, {"referenceID": 7, "context": "Some works also take usage of users\u2019 feedbacks (comments and attitudes) to evaluate credibility [8][29].", "startOffset": 96, "endOffset": 99}, {"referenceID": 28, "context": "Some works also take usage of users\u2019 feedbacks (comments and attitudes) to evaluate credibility [8][29].", "startOffset": 99, "endOffset": 103}, {"referenceID": 41, "context": "The Enquiry Post (EP) model [42] takes out signal tweets, which indicates users\u2019 suspicious attitudes for detecting rumors and achieves satisfactory performance.", "startOffset": 28, "endOffset": 32}, {"referenceID": 2, "context": "First, these methods based on feature engineering require great labor for designing features [3].", "startOffset": 93, "endOffset": 96}, {"referenceID": 2, "context": "Normally, the higher the credibility of a user, the higher the credibility of information it creates [3].", "startOffset": 101, "endOffset": 104}, {"referenceID": 12, "context": "However, some studies [13] point out that a great amount of users with high credibility on social media would repost and share misinformation unintentionally.", "startOffset": 22, "endOffset": 26}, {"referenceID": 7, "context": "Users on social media can express their attitudes and collective intelligence can be gathered to help us evaluate the credibility of information [8].", "startOffset": 145, "endOffset": 148}, {"referenceID": 0, "context": "tion learning [1] is showing a promising performance in a variety of applications, such as word embedding [23][24][25], network embedding [2][9][26][32], and user representations [6][7][18][19].", "startOffset": 14, "endOffset": 17}, {"referenceID": 22, "context": "tion learning [1] is showing a promising performance in a variety of applications, such as word embedding [23][24][25], network embedding [2][9][26][32], and user representations [6][7][18][19].", "startOffset": 106, "endOffset": 110}, {"referenceID": 23, "context": "tion learning [1] is showing a promising performance in a variety of applications, such as word embedding [23][24][25], network embedding [2][9][26][32], and user representations [6][7][18][19].", "startOffset": 110, "endOffset": 114}, {"referenceID": 24, "context": "tion learning [1] is showing a promising performance in a variety of applications, such as word embedding [23][24][25], network embedding [2][9][26][32], and user representations [6][7][18][19].", "startOffset": 114, "endOffset": 118}, {"referenceID": 1, "context": "tion learning [1] is showing a promising performance in a variety of applications, such as word embedding [23][24][25], network embedding [2][9][26][32], and user representations [6][7][18][19].", "startOffset": 138, "endOffset": 141}, {"referenceID": 8, "context": "tion learning [1] is showing a promising performance in a variety of applications, such as word embedding [23][24][25], network embedding [2][9][26][32], and user representations [6][7][18][19].", "startOffset": 141, "endOffset": 144}, {"referenceID": 25, "context": "tion learning [1] is showing a promising performance in a variety of applications, such as word embedding [23][24][25], network embedding [2][9][26][32], and user representations [6][7][18][19].", "startOffset": 144, "endOffset": 148}, {"referenceID": 31, "context": "tion learning [1] is showing a promising performance in a variety of applications, such as word embedding [23][24][25], network embedding [2][9][26][32], and user representations [6][7][18][19].", "startOffset": 148, "endOffset": 152}, {"referenceID": 5, "context": "tion learning [1] is showing a promising performance in a variety of applications, such as word embedding [23][24][25], network embedding [2][9][26][32], and user representations [6][7][18][19].", "startOffset": 179, "endOffset": 182}, {"referenceID": 6, "context": "tion learning [1] is showing a promising performance in a variety of applications, such as word embedding [23][24][25], network embedding [2][9][26][32], and user representations [6][7][18][19].", "startOffset": 182, "endOffset": 185}, {"referenceID": 17, "context": "tion learning [1] is showing a promising performance in a variety of applications, such as word embedding [23][24][25], network embedding [2][9][26][32], and user representations [6][7][18][19].", "startOffset": 185, "endOffset": 189}, {"referenceID": 18, "context": "tion learning [1] is showing a promising performance in a variety of applications, such as word embedding [23][24][25], network embedding [2][9][26][32], and user representations [6][7][18][19].", "startOffset": 189, "endOffset": 193}, {"referenceID": 18, "context": "For the sake of modeling elaborate interactions among different features, other features such as \u201cwhat\u201d, \u201chow\u201d, and \u201cwhen\u201d are represented as operating matrices [19].", "startOffset": 161, "endOffset": 165}, {"referenceID": 2, "context": "Some of them evaluate the credibility of a single microblog [3][27] or a single image [10].", "startOffset": 60, "endOffset": 63}, {"referenceID": 26, "context": "Some of them evaluate the credibility of a single microblog [3][27] or a single image [10].", "startOffset": 63, "endOffset": 67}, {"referenceID": 9, "context": "Some of them evaluate the credibility of a single microblog [3][27] or a single image [10].", "startOffset": 86, "endOffset": 90}, {"referenceID": 10, "context": "Some of them evaluate information credibility at the event level to distinguish whether an event is a rumor or a non-rumor [11][31][16][42][22], where each event consists of several microblogs.", "startOffset": 123, "endOffset": 127}, {"referenceID": 30, "context": "Some of them evaluate information credibility at the event level to distinguish whether an event is a rumor or a non-rumor [11][31][16][42][22], where each event consists of several microblogs.", "startOffset": 127, "endOffset": 131}, {"referenceID": 15, "context": "Some of them evaluate information credibility at the event level to distinguish whether an event is a rumor or a non-rumor [11][31][16][42][22], where each event consists of several microblogs.", "startOffset": 131, "endOffset": 135}, {"referenceID": 41, "context": "Some of them evaluate information credibility at the event level to distinguish whether an event is a rumor or a non-rumor [11][31][16][42][22], where each event consists of several microblogs.", "startOffset": 135, "endOffset": 139}, {"referenceID": 21, "context": "Some of them evaluate information credibility at the event level to distinguish whether an event is a rumor or a non-rumor [11][31][16][42][22], where each event consists of several microblogs.", "startOffset": 139, "endOffset": 143}, {"referenceID": 13, "context": "News Credibility Propagation (NewsCP) [14] studies how to aggregate credibility from the microblog level to the event level and presents a graph optimization method, which has further incorporated conflict viewpoints in the model [15].", "startOffset": 38, "endOffset": 42}, {"referenceID": 14, "context": "News Credibility Propagation (NewsCP) [14] studies how to aggregate credibility from the microblog level to the event level and presents a graph optimization method, which has further incorporated conflict viewpoints in the model [15].", "startOffset": 230, "endOffset": 234}, {"referenceID": 15, "context": "For instance, the Periodic External Shocks (PES) model [16] uses ordinary structural features and user features and designs temporal features according to the properties of information spreading over time.", "startOffset": 55, "endOffset": 59}, {"referenceID": 21, "context": "The Dynamic Series-Time Structure (DSTS) [22] generates content-, user-, and diffusion-based features in different time periods during information spreading and uses all these features to train a model.", "startOffset": 41, "endOffset": 45}, {"referenceID": 7, "context": "Some works also take usage of users feedbacks to evaluate credibility [8][29].", "startOffset": 70, "endOffset": 73}, {"referenceID": 28, "context": "Some works also take usage of users feedbacks to evaluate credibility [8][29].", "startOffset": 73, "endOffset": 77}, {"referenceID": 41, "context": "The EP model [42] extracts signal tweets that indicate users suspicious attitudes for detecting rumors and achieves satisfactory performance.", "startOffset": 13, "endOffset": 17}, {"referenceID": 0, "context": "Nowadays, representation learning [1] has been extensively studied in different areas.", "startOffset": 34, "endOffset": 37}, {"referenceID": 24, "context": "In natural language processing, learning embeddings [25] is a hot topic, where recurrent neural networks [23][24] are widely applied.", "startOffset": 52, "endOffset": 56}, {"referenceID": 22, "context": "In natural language processing, learning embeddings [25] is a hot topic, where recurrent neural networks [23][24] are widely applied.", "startOffset": 105, "endOffset": 109}, {"referenceID": 23, "context": "In natural language processing, learning embeddings [25] is a hot topic, where recurrent neural networks [23][24] are widely applied.", "startOffset": 109, "endOffset": 113}, {"referenceID": 11, "context": "In web mining, learning network embedding has drawn great attention for studying node classification [12] or information diffusion [2].", "startOffset": 101, "endOffset": 105}, {"referenceID": 1, "context": "In web mining, learning network embedding has drawn great attention for studying node classification [12] or information diffusion [2].", "startOffset": 131, "endOffset": 134}, {"referenceID": 25, "context": "Recently, network embedding models have incorporated random walk [26][9] and second-order connection in the representation learning methods [32].", "startOffset": 65, "endOffset": 69}, {"referenceID": 8, "context": "Recently, network embedding models have incorporated random walk [26][9] and second-order connection in the representation learning methods [32].", "startOffset": 69, "endOffset": 72}, {"referenceID": 31, "context": "Recently, network embedding models have incorporated random walk [26][9] and second-order connection in the representation learning methods [32].", "startOffset": 140, "endOffset": 144}, {"referenceID": 18, "context": "Contextual Operating Tensor (COT) [19][36] and CARS2 [30] study context-aware user representations for recommendation.", "startOffset": 34, "endOffset": 38}, {"referenceID": 35, "context": "Contextual Operating Tensor (COT) [19][36] and CARS2 [30] study context-aware user representations for recommendation.", "startOffset": 38, "endOffset": 42}, {"referenceID": 29, "context": "Contextual Operating Tensor (COT) [19][36] and CARS2 [30] study context-aware user representations for recommendation.", "startOffset": 53, "endOffset": 57}, {"referenceID": 17, "context": "Hierarchical Interaction Representation (HIR) [18] studies joint representations of entities, e.", "startOffset": 46, "endOffset": 50}, {"referenceID": 5, "context": "Some works [6][37][41] utilize deep neural networks for better user modeling.", "startOffset": 11, "endOffset": 14}, {"referenceID": 36, "context": "Some works [6][37][41] utilize deep neural networks for better user modeling.", "startOffset": 14, "endOffset": 18}, {"referenceID": 40, "context": "Some works [6][37][41] utilize deep neural networks for better user modeling.", "startOffset": 18, "endOffset": 22}, {"referenceID": 20, "context": "Convolutional Click Prediction Model (CCPM) [21] applies convolutional neural networks in predicting clicking behaviors of users.", "startOffset": 44, "endOffset": 48}, {"referenceID": 33, "context": "Hierarchical Representation Model (HRM) [34] and Dynamic Recurrent Basket Model (DREAM)[40] learn the representation of behaviors of a user in a short period for better recommendation.", "startOffset": 40, "endOffset": 44}, {"referenceID": 39, "context": "Hierarchical Representation Model (HRM) [34] and Dynamic Recurrent Basket Model (DREAM)[40] learn the representation of behaviors of a user in a short period for better recommendation.", "startOffset": 87, "endOffset": 91}, {"referenceID": 0, "context": "Nowadays, representation learning [1] has been extensively studied in different areas.", "startOffset": 34, "endOffset": 37}, {"referenceID": 24, "context": "In natural language processing, learning embedding [25] is a hot topic, where recurrent neural networks [23][24] are widely applied.", "startOffset": 51, "endOffset": 55}, {"referenceID": 22, "context": "In natural language processing, learning embedding [25] is a hot topic, where recurrent neural networks [23][24] are widely applied.", "startOffset": 104, "endOffset": 108}, {"referenceID": 23, "context": "In natural language processing, learning embedding [25] is a hot topic, where recurrent neural networks [23][24] are widely applied.", "startOffset": 108, "endOffset": 112}, {"referenceID": 11, "context": "In web mining, learning network embedding has drawn great attention for studying node classification [12] or information diffusion [2].", "startOffset": 101, "endOffset": 105}, {"referenceID": 1, "context": "In web mining, learning network embedding has drawn great attention for studying node classification [12] or information diffusion [2].", "startOffset": 131, "endOffset": 134}, {"referenceID": 25, "context": "Recently, network embedding models have incorporated random walk [26][9] and second-order connection in the representation learning methods [32].", "startOffset": 65, "endOffset": 69}, {"referenceID": 8, "context": "Recently, network embedding models have incorporated random walk [26][9] and second-order connection in the representation learning methods [32].", "startOffset": 69, "endOffset": 72}, {"referenceID": 31, "context": "Recently, network embedding models have incorporated random walk [26][9] and second-order connection in the representation learning methods [32].", "startOffset": 140, "endOffset": 144}, {"referenceID": 18, "context": "The contextual operating tensor (COT) [19][36] and CARS2 [30] study context-aware user representations for recommendation.", "startOffset": 38, "endOffset": 42}, {"referenceID": 35, "context": "The contextual operating tensor (COT) [19][36] and CARS2 [30] study context-aware user representations for recommendation.", "startOffset": 42, "endOffset": 46}, {"referenceID": 29, "context": "The contextual operating tensor (COT) [19][36] and CARS2 [30] study context-aware user representations for recommendation.", "startOffset": 57, "endOffset": 61}, {"referenceID": 17, "context": "Hierarchical Interaction Representation (HIR) [18] studies joint representations of entities, e.", "startOffset": 46, "endOffset": 50}, {"referenceID": 5, "context": "Some works [6][37][41] use deep neural networks for better user modeling.", "startOffset": 11, "endOffset": 14}, {"referenceID": 36, "context": "Some works [6][37][41] use deep neural networks for better user modeling.", "startOffset": 14, "endOffset": 18}, {"referenceID": 40, "context": "Some works [6][37][41] use deep neural networks for better user modeling.", "startOffset": 18, "endOffset": 22}, {"referenceID": 20, "context": "The convolutional click prediction model (CCPM) [21] applies convolutional neural networks in predicting clicking behaviors of users.", "startOffset": 48, "endOffset": 52}, {"referenceID": 33, "context": "The hierarchical representation model (HRM) [34] and the dynamic recurrent basket model (DREAM) [40] learn the representation of behaviors of a user in a short period for better recommendation.", "startOffset": 44, "endOffset": 48}, {"referenceID": 39, "context": "The hierarchical representation model (HRM) [34] and the dynamic recurrent basket model (DREAM) [40] learn the representation of behaviors of a user in a short period for better recommendation.", "startOffset": 96, "endOffset": 100}, {"referenceID": 37, "context": "Truth discovery refers to the problem of finding the truth with conflicting information, which has been first addressed in [38].", "startOffset": 123, "endOffset": 127}, {"referenceID": 16, "context": "Truth discovery methods are usually based on Bayesian algorithms or graph learning algorithms on stock data or flight data [17][33].", "startOffset": 123, "endOffset": 127}, {"referenceID": 32, "context": "Truth discovery methods are usually based on Bayesian algorithms or graph learning algorithms on stock data or flight data [17][33].", "startOffset": 127, "endOffset": 131}, {"referenceID": 38, "context": "And Semi-Supervised Truth Discovery (SSTF) [39] studies the problem with semi-supervised graph learning with a small set of ground truth data to help evaluating credibility.", "startOffset": 43, "endOffset": 47}, {"referenceID": 16, "context": "Truth discovery is an unsupervised or semi-supervised method to find the truth with conflicting information and make an evaluation of information credibility [17].", "startOffset": 158, "endOffset": 162}, {"referenceID": 24, "context": "We first found several typical suspicion words then train wrod2vec6 [25] on our data set and found dozens of words similar with the typical suspicion words according to their embedding distance.", "startOffset": 68, "endOffset": 72}, {"referenceID": 19, "context": "Therefore, as in [20], we use a similar strategy for generating time-specific matrices.", "startOffset": 17, "endOffset": 21}, {"referenceID": 27, "context": "Similar to [28], our basic assumption is that the credibility of a non-rumor is larger than that of a rumor.", "startOffset": 11, "endOffset": 15}, {"referenceID": 13, "context": "\u2022 News Credibility Propagation (NewsCP) [14] studies how to aggregate credibility from microblogs to events based on a graph optimization method.", "startOffset": 40, "endOffset": 44}, {"referenceID": 3, "context": "The classifier we use for each microblog is the widely-used Support Vector Machine (SVM), which is implemented via libSVM7 [4].", "startOffset": 123, "endOffset": 126}, {"referenceID": 41, "context": "\u2022 The Enquiry Post (EP) model [42] is proposed mainly based on signal tweets.", "startOffset": 30, "endOffset": 34}, {"referenceID": 3, "context": "html list to identify signal tweets and then apply libSVM [4] for information credibility evaluation.", "startOffset": 58, "endOffset": 61}, {"referenceID": 34, "context": "Thus, based on our model and the Sina Weibo data set, we built a Network Information Credibility Evaluation (NICE) system [35].", "startOffset": 122, "endOffset": 126}], "year": 2017, "abstractText": "With the rapid growth of social media, rumors are also spreading widely on social media and bring harm to people\u2019s daily life. Nowadays, information credibility evaluation has drawn attention from academic and industrial communities. Current methods mainly focus on feature engineering and achieve some success. However, feature engineering based methods require a lot of labor and cannot fully reveal the underlying relations among data. In our viewpoint, the key elements of user behaviors for evaluating credibility are concluded as who, what, when, and how. These existing methods cannot model the correlation among different key elements during the spreading of microblogs. In this paper, we propose a novel representation learning method, Information Credibility Evaluation (ICE), to learn representations of information credibility on social media. In ICE, latent representations are learnt for modeling user credibility, behavior types, temporal properties, and comment attitudes. The aggregation of these factors in the microblog spreading process yields the representation of a users behavior, and the aggregation of these dynamic representations generates the credibility representation of an event spreading on social media. Moreover, a pairwise learning method is applied to maximize the credibility difference between rumors and non-rumors. To evaluate the performance of ICE, we conduct experiments on a Sina Weibo data set, and the experimental results show that our ICE model outperforms the state-of-the-art methods.", "creator": "LaTeX with hyperref package"}}}