{"id": "1609.09748", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Sep-2016", "title": "Characterization of experts in crowdsourcing platforms", "abstract": "Crowdsourcing platforms enable to propose simple human intelligence tasks to a large number of participants who realise these tasks. The workers often receive a small amount of money or the platforms include some other incentive mechanisms, for example they can increase the workers reputation score, if they complete the tasks correctly. We address the problem of identifying experts among participants, that is, workers, who tend to answer the questions correctly. Knowing who are the reliable workers could improve the quality of knowledge one can extract from responses. As opposed to other works in the literature, we assume that participants can give partial or incomplete responses, in case they are not sure that their answers are correct. We model such partial or incomplete responses with the help of belief functions, and we derive a measure that characterizes the expertise level of each participant. This measure is based on precise and exactitude degrees that represent two parts of the expertise level. The precision degree reflects the reliability level of the participants and the exactitude degree reflects the knowledge level of the participants. We also analyze our model through simulation and demonstrate that our richer model can lead to more reliable identification of experts.", "histories": [["v1", "Fri, 30 Sep 2016 14:23:42 GMT  (345kb,D)", "http://arxiv.org/abs/1609.09748v1", "in The 4th International Conference on Belief Functions, Sep 2016, Prague, Czech Republic"]], "COMMENTS": "in The 4th International Conference on Belief Functions, Sep 2016, Prague, Czech Republic", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["amal ben rjab", "mouloud kharoune", "zoltan miklos", "arnaud martin"], "accepted": false, "id": "1609.09748"}, "pdf": {"name": "1609.09748.pdf", "metadata": {"source": "CRF", "title": "Characterization of experts in crowdsourcing platforms", "authors": ["Amal Ben Rjab", "Mouloud Kharoune", "Zoltan Miklos", "Arnaud Martin"], "emails": ["benrjabamal.ihec@gmail.com", "Mouloud.Kharoune@univ-rennes1.fr", "zoltan.miklos@irisa.fr", "Arnaud.Martin@univ-rennes1.fr"], "sections": [{"heading": null, "text": "Key words: Crowdsourcing, Expert, Competence Level, Accuracy and Precision Level."}, {"heading": "1 Introduction", "text": "In fact, most people who are able to move are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance,"}, {"heading": "2 Expert identification in the context of crowdsourcing", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Notions of an expert", "text": "An expert in crowdsourcing is the one who provides a large number of correct, complete and reliable answers. The one who has acquired a range of knowledge and skills in a particular area. He can extract knowledge and relevant answers with minimal cognitive effort. In crowdsourcing platforms, he is identified by the precision and accuracy of the answers, the ability to recognize tasks a priori, the knowledge, skills and the level of learning."}, {"heading": "2.2 Expert identification methods", "text": "Assessing the quality of workers and identifying experts in the field of crowdsourcing is a constant problem. Many authors have found that randomness is a good choice [10] and others have found that defining a good strategy for selecting experts is more interesting [4]. Several studies have examined this area, but essentially there are two basic approaches to identifying the experts: Use \"golden\" data: Give participants the questions we already know, and identify the workers who give the right answers as experts. Use multiple workers: Give each participant a score that represents their qualities and abilities. In this context, Ipeirotis et al. improved the Expectation Maximization Algorithm (EM) to generate a scalar score that represents the quality of each worker. [6] suggested evaluating the participants on the basis of the labels. [7] Based on the behavioral observation to identify user types of workers, one proposed to classify the algorithm of 8 [1]."}, {"heading": "3 Identification of the experts", "text": "We would like to identify the experts in a crowdsourcing platform. We assume that the questions (tasks) and a list of available answers of the crowdworkers would greatly facilitate the identification of experts. Therefore, we develop new techniques - based on the theory of belief functions - to calculate the accuracy and precision of the answers. We use the following formalism. we take note of the answers that rUj proposes from each participant Uj with a mass of beliefs. Each answer is specific to each question Qk (k = {1, \u00b7, K}), which has a specific differentiating framework."}, {"heading": "3.1 Exactitude degree", "text": "The degree of accuracy is based on the average of the distance between the answer proposed by the participants to the kest question and all the answers of the other participants to the kest question, e.g.: m\u0442kU\u03b5s \u2212 1 (X) = 1s \u2212 1 s = 1 mj (X) (2) The distance is then calculated from the distance from Jousselme [13]: dJ (m \u0439kUi, m\u0441kU\u03b5s \u2212 1). According to this distance, we calculate the degree of accuracy for each participant Uj as follows: IEUj = 1 \u2212 1r (Uj) K \u0445 k = 1 d\u0441kUj (3) The assumption behind this method is the majority of participants who give a correct answer. This assumption is currently made in information fusion and crowdsourcing.The degree of accuracy can be used to identify the experts for this purpose."}, {"heading": "3.2 Precision degree", "text": "We remember that we allow participants to give partial answers, which are crucial for calculating the degree of precision. We cannot define the usual response model (i.e. the employee must give a complete answer). We observe the degree of specificity of the mass function m \u0435k Uj. This degree of specificity is defined by [14] as follows: \u0441\u0442 kUj = 1 \u2212 \u2211 X-2\u0441km\u044f kUj (X) log2 (| X |) log2 (| k |) (4) This degree of specificity makes it possible to translate the level of precision of each answer independently of the answers of the other participant. In order to measure the degree of precision of each participant IPUj, we propose to calculate the average of the degrees of specificity for all kth questions."}, {"heading": "3.3 Global degree", "text": "To achieve a global degree, we combine both degrees in one degree for each participant. The global degree is given by a weighted average as follows: GDUj = \u03b2UjIEUj + (1 \u2212 \u03b2Uj) IPUj (6) The weight \u03b2Uj is introduced to give each degree more or less meaning. In the following, we do not make any difference between the participants in quantity."}, {"heading": "4 Experimentation", "text": "Below, we will generate some mass functions to evaluate our approach in the context where there is no use of gold data. We will generate three types of participants; the experts are the ones who provide precise and accurate answers; in mass generation, a singleton is expected to give the correct answer; but if the expert is not completely sure, ignorance is also a central element; the imprecise experts are the ones who provide precise but inaccurate answers to mass functions that give correct answers to the correct question; the right singleton can be in a disjunction and ignorance can also be a focal element; the ignorants (sometimes referred to as spammers) are those who give random answers to mass functions that were taken randomly. To verify the efficiency of our approach, we will do several experiments with 100 participants, 100 questions where each experiment is repeated; the precision or the degree of accuracy alone is not enough to accurately identify the experts, and at the same time, the accuracy of the global equation (6) enables us to precisely and the equation."}, {"heading": "5 Conclusion", "text": "We introduced a new method of characterizing the experts in a crowdsourcing platform by applying the belief function theory to improve the quality of the data that could be obtained from such platforms. We used a model in which the crowdworkers were allowed to skip a question or provide partial solutions. Based on a belief model of the participants \"answers, we calculated two complementary degrees: an accuracy level translates the participants\" knowledge level and a precision level reflects their reliability level. We demonstrated the ability of this degree to help identify experts, and we demonstrated the interest of the belief function theory compared to probability theory."}], "references": [{"title": "The rise of crowdsourcing,", "author": ["J. Howe"], "venue": "Wired magazine,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2006}, {"title": "The future of crowd work,", "author": ["A. Kittur", "J.V. Nickerson", "M. Bernstein", "E. Gerber", "A. Shaw", "J. Zimmerman", "M. Lease", "J. Horton"], "venue": "Proceedings of the 2013 conference on Computer supported cooperative work. ACM,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2013}, {"title": "What can crowdsourcing do for decision support?", "author": ["C.-M. Chiu", "T.-P. Liang", "E. Turban"], "venue": "Decision Support Systems,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2014}, {"title": "Quality management on amazon mechanical turk,", "author": ["P.G. Ipeirotis", "F. Provost", "J. Wang"], "venue": "Proceedings of the ACM SIGKDD workshop on human computation", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2010}, {"title": "Caract\u00e9risation dexperts dans les plate-formes de crowdsourcing,", "author": ["A.B. Rjab", "M. Kharoune", "Z. Miklos", "A. Martin", "B.B. Yaghlane"], "venue": "e\u0300me Conference sur la Logique Floue et ses Applications (LFA), Poitiers, France,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "Quality control of crowd labeling through expert evaluation,", "author": ["F.K. Khattak", "A. Salleb-Aouissi"], "venue": "Proceedings of the NIPS 2nd Workshop on Computational Social Science and the Wisdom of Crowds,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2011}, {"title": "Worker types and personality traits in crowdsourcing relevance labels,", "author": ["G. Kazai", "J. Kamps", "N. Milic-Frayling"], "venue": "Proceedings of the 20th ACM international conference on Information and knowledge management", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2011}, {"title": "Telling experts from spammers: expertise ranking in folksonomies,", "author": ["M.G. Noll", "C.-m. Au Yeung", "N. Gibbins", "C. Meinel", "N. Shadbolt"], "venue": "Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval. ACM,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2009}, {"title": "Worker evaluation in crowdsourcing: Gold data or-multipleworkers?", "author": ["P. Ipeirotis"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2010}, {"title": "Upper and lower probabilities induced by a multivalued mapping,", "author": ["A.P. Dempster"], "venue": "The annals of mathematical statistics,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1967}, {"title": "A mathematical theory of evidence", "author": ["G. Shafer"], "venue": "Princeton university press Princeton,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1976}, {"title": "Contradiction measures and specificity degrees of basic belief assignments,", "author": ["F. Smarandache", "A. Martin", "C. Osswald"], "venue": "in International Conference on Information Fusion, Chicago,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2011}], "referenceMentions": [{"referenceID": 0, "context": "Crowdsourcing is term for \u201cthe act of a company or institution taking a function once performed by employees and outsourcing it to an undefined (and generally large) network of people in the form of an open call\u201d [1].", "startOffset": 213, "endOffset": 216}, {"referenceID": 1, "context": "It is also considered as a style of future work [2] that can be crucial for example in the context of decision support [3].", "startOffset": 48, "endOffset": 51}, {"referenceID": 2, "context": "It is also considered as a style of future work [2] that can be crucial for example in the context of decision support [3].", "startOffset": 119, "endOffset": 122}, {"referenceID": 3, "context": "The absence of quality control of participants (and their responses) reduces the efficiency of these platforms [4].", "startOffset": 111, "endOffset": 114}, {"referenceID": 4, "context": "One often refers to a participant who gives exact and precise answers as an expert [5].", "startOffset": 83, "endOffset": 86}, {"referenceID": 3, "context": "Several works [4] [6\u20138] were proposed to identify the experts in this context.", "startOffset": 14, "endOffset": 17}, {"referenceID": 5, "context": "Several works [4] [6\u20138] were proposed to identify the experts in this context.", "startOffset": 18, "endOffset": 23}, {"referenceID": 6, "context": "Several works [4] [6\u20138] were proposed to identify the experts in this context.", "startOffset": 18, "endOffset": 23}, {"referenceID": 7, "context": "Several works [4] [6\u20138] were proposed to identify the experts in this context.", "startOffset": 18, "endOffset": 23}, {"referenceID": 8, "context": "Some works use first \u201cgold\u201d data on which real answers are known [9].", "startOffset": 65, "endOffset": 68}, {"referenceID": 3, "context": "is a good choice [10] and others found that establishing a good strategy for selecting experts is more interesting [4].", "startOffset": 115, "endOffset": 118}, {"referenceID": 3, "context": "improved in [4] the expectation maximization algorithm (EM) to generate a scalar score representing the quality of each worker.", "startOffset": 12, "endOffset": 15}, {"referenceID": 5, "context": "[6] proposed an evaluation of the participants by the set of labels.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[7] based on behavioral observation to define a typology of workers.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] proposed an algorithm based on the graphs (SPEAR) to classify the users and to identify the experts.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "We proposed an identification of experts with using the theory of belief functions [11,12] which represents a mathematical theory for representing imperfect information and gives a complete framework to model the participant\u2019s answers.", "startOffset": 83, "endOffset": 90}, {"referenceID": 10, "context": "We proposed an identification of experts with using the theory of belief functions [11,12] which represents a mathematical theory for representing imperfect information and gives a complete framework to model the participant\u2019s answers.", "startOffset": 83, "endOffset": 90}, {"referenceID": 11, "context": "It is defined by [14] as follows:", "startOffset": 17, "endOffset": 21}], "year": 2016, "abstractText": "Crowdsourcing platforms enable to propose simple human intelligence tasks to a large number of participants who realise these tasks. The workers often receive a small amount of money or the platforms include some other incentive mechanisms, for example they can increase the workers reputation score, if they complete the tasks correctly. We address the problem of identifying experts among participants, that is, workers, who tend to answer the questions correctly. Knowing who are the reliable workers could improve the quality of knowledge one can extract from responses. As opposed to other works in the literature, we assume that participants can give partial or incomplete responses, in case they are not sure that their answers are correct. We model such partial or incomplete responses with the help of belief functions, and we derive a measure that characterizes the expertise level of each participant. This measure is based on precise and exactitude degrees that represent two parts of the expertise level. The precision degree reflects the reliability level of the participants and the exactitude degree reflects the knowledge level of the participants. We also analyze our model through simulation and demonstrate that our richer model can lead to more reliable identification of experts.", "creator": "LaTeX with hyperref package"}}}