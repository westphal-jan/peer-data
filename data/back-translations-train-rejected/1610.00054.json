{"id": "1610.00054", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Sep-2016", "title": "Outlier Detection from Network Data with Subnetwork Interpretation", "abstract": "Detecting a small number of outliers from a set of data observations is always challenging. This problem is more difficult in the setting of multiple network samples, where computing the anomalous degree of a network sample is generally not sufficient. In fact, explaining why the network is exceptional, expressed in the form of subnetwork, is also equally important. In this paper, we develop a novel algorithm to address these two key problems. We treat each network sample as a potential outlier and identify subnetworks that mostly discriminate it from nearby regular samples. The algorithm is developed in the framework of network regression combined with the constraints on both network topology and L1-norm shrinkage to perform subnetwork discovery. Our method thus goes beyond subspace/subgraph discovery and we show that it converges to a global optimum. Evaluation on various real-world network datasets demonstrates that our algorithm not only outperforms baselines in both network and high dimensional setting, but also discovers highly relevant and interpretable local subnetworks, further enhancing our understanding of anomalous networks.", "histories": [["v1", "Fri, 30 Sep 2016 23:13:28 GMT  (2051kb,D)", "http://arxiv.org/abs/1610.00054v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["xuan-hong dang", "arlei silva", "ambuj singh", "ananthram swami", "prithwish basu"], "accepted": false, "id": "1610.00054"}, "pdf": {"name": "1610.00054.pdf", "metadata": {"source": "CRF", "title": "Outlier Detection from Network Data with Subnetwork Interpretation", "authors": ["Xuan-Hong Dang", "Arlei Silva", "Ambuj Singh", "Ananthram Swami", "Prithwish Basu"], "emails": ["xdang@cs.ucsb.edu", "arlei@cs.ucsb.edu", "ambuj@cs.ucsb.edu", "ananthram.swami.civ@mail.mil", "pbasu@bbn.com"], "sections": [{"heading": null, "text": "This year, it has come to the point that it will only be once before there is such a process, in which there is such a process."}, {"heading": "II. PROBLEM SETTING", "text": "Definition 1: A network sample is a triple Nk = (Vk, Ek, F), where Vk = {v1, v2,.., vn} is a set of nodes, Ek Vk \u00b7 Vk is a set of undirected edges, and F is a function that labels each node with a real number. Let DB = {N1, N2,.., Nm} be a network dataset consisting of m network samples. We focus on a family of networks whose topologies are relatively stable across different network instances. Thus, human subjects generally have similar gene networks with the same number of genes. However, the expression level of each individual gene may vary from subject to subject. Likewise, different snapshots taken from a traffic network often have the same network topology, while traffic conditions on each road segment may vary from snapshot to snapshot. When dismantling remote networks from a database, we compute the total number of network samples for each network, with each network striving for the highest dataset count."}, {"heading": "III. REGRESSION ON NETWORKS", "text": "As mentioned in the previous section, our goal is not only to calculate the outlier degree for each network sample, but also to discover a small set of subnets as explanations for each outlier candidate network. In this section, we formulate the regression problem solely on the basis of the values associated with the nodes of the network, while the network topology is in the next section. We consider each network as a potential outlier, while comparing its properties against its nearby networks (based on some network distance measurements, e.g. cosmic distance between the nodes [13]). Therefore, a network topology can be more of a local outlier than a global outlier, since both the network distribution and the outliers themselves can be heterogeneous and no canonical form is given for distribution."}, {"heading": "IV. ROLE OF NETWORK TOPOLOGY", "text": "Our formulation in Eq. (2) gives us a regression form to predict No as an outlier candidate based on the local state values associated with network nodes. (2) However, it does not take into account whether the network information and the essential information in most relevant sub-networks, which are no exception, are interlinked. (Therefore, we should add the network structure information as a condition in a road segment (node). Intuitively, it is likely that the nearby road segments will also be affected, thereby reflecting their coefficients in w's entries. (For example, if an overload has occurred in a road segment, it is likely that the nearby road segments will be affected, leading to a region of the network. In the direction of modeling this network, we first explain a graph that generalizes the network topology of both networks and follows their neighboring networks as: Definition 2: Bo, Dp."}, {"heading": "V. OPTIMIZATION", "text": "In solving the objective function in Eq. (11) it is possible to note that it is closely related to the dual form of SVM with the square function of loss [20,34]: arg min. (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12).). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12). (12. (12). (12. (12). (12). (12). (12. (12). (12. (12). (12. (12). (12. (12). (12). (12). (12. (12). (12). (12). (12. (12). (12). (12. (12). (12). (12). (12. (12). (12). ("}, {"heading": "VI. ANALYSIS AND DISCUSSION", "text": "The complexity is briefly analyzed as follows: We call our algorithm ODeSM, which stands for Outlier Log Detection with Subgraph Mining. Its complexity is briefly analyzed as follows: Search for adjacent networks and upsampling therefore takes O (nm2) as the number of network samples and n as the number of nodes. The calculation of S and the inversion of H are both dependent on the number of non-zero entries in w, which is significantly reduced after each iteration. If d specify this number, then S O (d2 log d) calculates due to its own decomposition, while the inversion of H takes a similar time. The check step (1 \u2212 yi) is significantly reduced after each iteration. (13) s second term takes O (nd). Due to its reliability to the Newton method, ODeSM requires only a few iterations (usually \u2264 10) to achieve its convergent solution."}, {"heading": "VII. EXPERIMENTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Methodology", "text": "We compare the performance of our ODesM algorithm with techniques both in network studies and in high-dimensional studies. Specifically, it is compared with the following techniques: (1) Netspot [7] without time constraints, so that it can detect network regions from each individual network; (2) HiCS [22], which searches for outliers by high-contrast subspaces for high-dimensional data; (3) ABOD [25], which detects outliers by varying the angles between vector triples; (4) ODesMw / o, a variant of our method that does not exploit network regulation; the parameter setting for ODesM and ODesMw / o follows the discussion in Section VI, while for Netspot we specify the number of failures h = 10 as suggested in [7]. For HiCS, we select all settings as proposed by the authors [22] and adopt LOF as its core algorithm. ABOD is a parameter-free technique that we can use on the basis of a polykernel parameter."}, {"heading": "B. CMUFace graph data", "text": "In fact, it is as if most people who stand up for the rights of women and men have to put themselves at the centre. (...) It is not as if they want to put themselves at the centre. (...) It is not as if they want to put themselves at the centre. (...) It is not as if they want to put themselves at the centre. (...) It is as if they want to put themselves at the centre. \"(...) It is not as if they want to put themselves at the centre. (...) It is as if they want to put themselves at the centre. (...). (...) It is not as if they want to put themselves at the centre.\" (...) It is as if they put themselves at the centre. (...) It is as if they do not want to put themselves at the centre. (...) It is not as if they want to put themselves at the centre. (...) It is as if they do not want to put themselves at the centre. (...)"}, {"heading": "C. Biological PPI network", "text": "The second dataset we use for evaluation is the liver metastasis in humans [23] with the gene network derived from protein protein interaction. Values associated with nodes are the gene expression values. The dataset contains 7, 383 genes and 251, 916 edges collected from 101 healthy subjects who are considered inlying network samples, and 15 diseased subjects who are considered outliers.Outlier identification: We show in Fig.4 the ROC curve of all algorithms on the liver dataset. The performance of our ODesM method is competitive to the HiCS and both are better than the remaining diagrams. Netspot also performs well on this dataset as differentiates itself by its 0.76 AUC value and marginally better than ODesMw / o. Recall that each network sample of this dataset contains a large number of nodes, and both are better than the remaining subsubsubsubsubsubsubCUM-like subMace is better."}, {"heading": "D. Road traffic networks", "text": "The last three years have shown that we are able to change and change the world, and that we are able to change the world, \"he said in an interview with the\" New York Times. \"\" We have to be able to change the world, \"he told the German Press Agency.\" We have to be able to change the world. \""}, {"heading": "VIII. RELATED WORK", "text": "In the second category, the attributes associated with the nodes and edges are also available. Therefore, in the third category, not only abnormal network structures are searched for, but also network affiliations."}, {"heading": "IX. CONCLUSIONS", "text": "The algorithm was developed within the framework of network regression in combination with the constraints of network topology and the shrinkage of the L1 standard to distinguish outlier networks from their adjacent regular network samples. Therefore, our algorithm goes beyond subspace learning and methods of detecting subgraphs by directly learning the most discriminatory subnetworks to justify the exceptional properties of an anomalous network.The evaluation of various real network datasets showed that our novel algorithm not only exceeded existing techniques, but also uncovered highly relevant and interpretable local subnetworks.As a future work, we would like to extend our research to dealing with databases with very large networks. Obviously, the direct application of ODesM may not necessarily be highly scalable, as analyzed in Section VI. How can we deal with very large networks by applying network compression, which allows us to combine topologies with very large networks."}], "references": [{"title": "Event detection in social streams", "author": ["C.C. Aggarwal", "K. Subbian"], "venue": "SDM", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "Outlier detection in graph streams", "author": ["C.C. Aggarwal", "Y. Zhao", "P.S. Yu"], "venue": "ICDE, pages 399\u2013409", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2011}, {"title": "oddball: Spotting anomalies in weighted graphs", "author": ["L. Akoglu", "M. McGlohon", "C. Faloutsos"], "venue": "PAKDD", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2010}, {"title": "Graph based anomaly detection and description: a survey", "author": ["L. Akoglu", "H. Tong", "D. Koutra"], "venue": "DMKD", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2015}, {"title": "Local graph partitioning using pagerank vectors", "author": ["R. Andersen", "F.R.K. Chung", "K.J. Lang"], "venue": "FOCS", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2006}, {"title": "A study of the behavior of several methods for balancing machine learning training data", "author": ["G. Batista"], "venue": "ACM SIGKDD Explorations Newsletter,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2004}, {"title": "Netspot: Spotting significant anomalous regions on dynamic networks", "author": ["P. Bogdanov"], "venue": "In SDM,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2013}, {"title": "Mining heavy subgraphs in time-evolving networks", "author": ["P. Bogdanov", "M. Mongiov\u00ec", "A.K. Singh"], "venue": "ICDM", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2011}, {"title": "Convex Optimization", "author": ["S. Boyd", "L. Vandenberghe"], "venue": "Cambridge University Press", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2004}, {"title": "LOF: identifying density-based local outliers", "author": ["M.M. Breunig"], "venue": "In SIGMOD,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2000}, {"title": "Community-based anomaly detection in evolutionary networks", "author": ["Z. Chen", "W. Hendrix", "N.F. Samatova"], "venue": "JIIS", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2012}, {"title": "Discriminative features for identifying and interpreting outliers", "author": ["X.H. Dang"], "venue": "In ICDE,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2014}, {"title": "Discriminative subnetworks with regularized spectral learning for global-state network data", "author": ["X.H. Dang", "A.K. Singh", "P. Bogdanov", "H. You", "B. Hsu"], "venue": "ECML", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2014}, {"title": "Intrusion as (anti)social communication: characterization and detection", "author": ["Q. Ding"], "venue": "In KDD,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2012}, {"title": "Discovering structural anomalies in graph-based data", "author": ["W. Eberle", "L.B. Holder"], "venue": "ICDM workshop", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2007}, {"title": "On community outliers and their efficient detection in information networks", "author": ["J. Gao"], "venue": "In KDD,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2010}, {"title": "Integrating community matching and outlier detection for mining evolutionary community outliers", "author": ["M. Gupta", "J. Gao", "Y. Sun", "J. Han"], "venue": "KDD", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2012}, {"title": "The Elements of Statistical Learning. Data Mining, Inference, and Prediction", "author": ["T. Hastie"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2009}, {"title": "It\u2019s who you know: graph mining using recursive structural features", "author": ["K. Henderson"], "venue": "In KDD,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2011}, {"title": "A dual coordinate descent method for largescale linear SVM", "author": ["C. Hsieh"], "venue": "In ICML,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2008}, {"title": "Building support vector machines with reduced classifier complexity", "author": ["S. Keerthi", "O. Chapelle", "D. DeCoste"], "venue": "JMLR", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2006}, {"title": "Hics: High contrast subspaces for density-based outlier ranking", "author": ["F. Keller", "E. M\u00fcller", "K. B\u00f6hm"], "venue": "ICDE", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2012}, {"title": "Whole genome analysis for liver metastasis gene signatures in colorectal cancer", "author": ["D.H. Ki"], "venue": "Int J Cancer,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2007}, {"title": "Outlier detection in arbitrarily oriented subspaces", "author": ["H. Kriegel", "P. Kr\u00f6ger", "E. Schubert", "A. Zimek"], "venue": "ICDM", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2012}, {"title": "Angle-based outlier detection in high-dimensional data", "author": ["H. Kriegel", "M. Schubert", "A. Zimek"], "venue": "SIGKDD", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2008}, {"title": "Explaining outliers by subspace separability", "author": ["B. Micenkov\u00e1", "R.T. Ng", "X.H. Dang", "I. Assent"], "venue": "ICDM", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2013}, {"title": "Scalable anomaly ranking of attributed neighborhoods", "author": ["B. Perozzi", "L. Akoglu"], "venue": "SDM", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2016}, {"title": "Focused clustering and outlier detection in large attributed graphs", "author": ["B. Perozzi"], "venue": "In KDD,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2014}, {"title": "An efficient implementation of an active set method for svms", "author": ["K. Scheinberg"], "venue": "JMRL", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2006}, {"title": "Fast optimization methods for L1 regularization: A comparative study and two new approaches", "author": ["M.W. Schmidt", "G. Fung", "R. Rosales"], "venue": "ECML", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2007}, {"title": "Learning with Kernels: Support Vector Machines", "author": ["B. Scholkopf", "A.J. Smola"], "venue": "Regularization, Optimization, and Beyond. MIT Press, Cambridge, MA, USA", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2001}, {"title": "The emerging field of signal processing on graphs", "author": ["D.I. Shuman"], "venue": "IEEE Signal Process. Mag.,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2013}, {"title": "Neighborhood formation and anomaly detection in bipartite graphs", "author": ["J. Sun"], "venue": "In ICDM,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2005}, {"title": "A review of optimization methodologies in support vector machines", "author": ["J. Taylor", "S. Sun"], "venue": "Neurocomput.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2011}, {"title": "Efficient aggregation for graph summarization", "author": ["Y. Tian"], "venue": "In SIGMOD,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2008}, {"title": "A reduction of the elastic net to SVM with an application to GPU computing", "author": ["Q. Zhou"], "venue": "In AAAI,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2015}, {"title": "A survey on unsupervised outlier detection in high-dimensional numerical data", "author": ["A. Zimek"], "venue": "Statistical Analysis and Data Mining,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2012}], "referenceMentions": [{"referenceID": 3, "context": "Detecting and characterizing exceptional patterns is an important task in many domains ranging from fraud detection, environmental surveillance, to various health care applications [4,37].", "startOffset": 181, "endOffset": 187}, {"referenceID": 36, "context": "Detecting and characterizing exceptional patterns is an important task in many domains ranging from fraud detection, environmental surveillance, to various health care applications [4,37].", "startOffset": 181, "endOffset": 187}, {"referenceID": 36, "context": "Although identifying anomalous subjects has been widely studied in high dimensional data [37] and recently extended to the network context [4], the problem remains very challenging.", "startOffset": 89, "endOffset": 93}, {"referenceID": 3, "context": "Although identifying anomalous subjects has been widely studied in high dimensional data [37] and recently extended to the network context [4], the problem remains very challenging.", "startOffset": 139, "endOffset": 142}, {"referenceID": 18, "context": "In the network setting, most existing works focus on searching individual nodes [19], or groups of linked nodes [15] whose structures or behaviors are irregular.", "startOffset": 80, "endOffset": 84}, {"referenceID": 14, "context": "In the network setting, most existing works focus on searching individual nodes [19], or groups of linked nodes [15] whose structures or behaviors are irregular.", "startOffset": 112, "endOffset": 116}, {"referenceID": 6, "context": "Other recent studies have extended the scope of analysis to evolving networks [7,17], but the focus is on event/change detection where the temporal dimension is a key factor for defining outliers.", "startOffset": 78, "endOffset": 84}, {"referenceID": 16, "context": "Other recent studies have extended the scope of analysis to evolving networks [7,17], but the focus is on event/change detection where the temporal dimension is a key factor for defining outliers.", "startOffset": 78, "endOffset": 84}, {"referenceID": 11, "context": "Although the outlierness of a network sample can be quantified via the outlier degree, such a single measure only bears limited explanatory information [12,26] since it lacks the capability of showing in what data view, i.", "startOffset": 152, "endOffset": 159}, {"referenceID": 25, "context": "Although the outlierness of a network sample can be quantified via the outlier degree, such a single measure only bears limited explanatory information [12,26] since it lacks the capability of showing in what data view, i.", "startOffset": 152, "endOffset": 159}, {"referenceID": 22, "context": "However, the gene pathway (local subnetwork) that causes the disease can vary from subject to subject due to the complexity of the disease [23], or even depending on different stages of the disease.", "startOffset": 139, "endOffset": 143}, {"referenceID": 17, "context": "It can be shown that the combined objective function has a form closely related to the dual SVM [18,20], which can be further optimized in the primal form using Newton\u2019s method.", "startOffset": 96, "endOffset": 103}, {"referenceID": 19, "context": "It can be shown that the combined objective function has a form closely related to the dual SVM [18,20], which can be further optimized in the primal form using Newton\u2019s method.", "startOffset": 96, "endOffset": 103}, {"referenceID": 12, "context": "cosine distance between node values [13]).", "startOffset": 36, "endOffset": 40}, {"referenceID": 9, "context": "Therefore, a network sample can be a local outlier rather than a global one [10,37], as both network distribution and the outliers themselves can be heterogeneous and one should not presume any canonical form for the distribution.", "startOffset": 76, "endOffset": 83}, {"referenceID": 36, "context": "Therefore, a network sample can be a local outlier rather than a global one [10,37], as both network distribution and the outliers themselves can be heterogeneous and one should not presume any canonical form for the distribution.", "startOffset": 76, "endOffset": 83}, {"referenceID": 17, "context": "It is worth mentioning that in a conventional case, one can constrain |w|1 \u2264 c [18] for a non-negative constant c.", "startOffset": 79, "endOffset": 83}, {"referenceID": 17, "context": "(1) resembles the form of Lasso regression [18].", "startOffset": 43, "endOffset": 47}, {"referenceID": 5, "context": "In dealing with this issue, we adopt a simple approach of upsampling the outlier candidate in order to ensure that the data become balanced [6].", "startOffset": 140, "endOffset": 143}, {"referenceID": 29, "context": "The solution is at best only suboptimal using methods like sub-gradient [30], in which each component of w is optimized individually and in sequence.", "startOffset": 72, "endOffset": 76}, {"referenceID": 29, "context": "We thus handle the L1-norm in a more general setting [30] by representing w using two nonnegative variables w and w\u2212, that are respectively defined as w = max(0,w) and w\u2212 = \u2212min(0,w).", "startOffset": 53, "endOffset": 57}, {"referenceID": 8, "context": "Therefore, in order to ensure that only subnetworks with the most explanatory information are used for No, this constraint should always be tight [9,36].", "startOffset": 146, "endOffset": 152}, {"referenceID": 35, "context": "Therefore, in order to ensure that only subnetworks with the most explanatory information are used for No, this constraint should always be tight [9,36].", "startOffset": 146, "endOffset": 152}, {"referenceID": 17, "context": "where, like the classical ridge regression [18], we add a small amount of L2-norm regularization in order to improve the stability of solutions when n m.", "startOffset": 43, "endOffset": 47}, {"referenceID": 19, "context": "(11), it is possible to note that it is closely related to the dual form of the SVM with the squared loss function [20,34]:", "startOffset": 115, "endOffset": 122}, {"referenceID": 33, "context": "(11), it is possible to note that it is closely related to the dual form of the SVM with the squared loss function [20,34]:", "startOffset": 115, "endOffset": 122}, {"referenceID": 19, "context": "(12) should be understood as the Lagrange multipliers (often denoted by \u03b1 in [20,34]).", "startOffset": 77, "endOffset": 84}, {"referenceID": 33, "context": "(12) should be understood as the Lagrange multipliers (often denoted by \u03b1 in [20,34]).", "startOffset": 77, "endOffset": 84}, {"referenceID": 19, "context": "(11) using several available techniques like coordinate descent [20], internal point [31] or active set method [29].", "startOffset": 64, "endOffset": 68}, {"referenceID": 30, "context": "(11) using several available techniques like coordinate descent [20], internal point [31] or active set method [29].", "startOffset": 85, "endOffset": 89}, {"referenceID": 28, "context": "(11) using several available techniques like coordinate descent [20], internal point [31] or active set method [29].", "startOffset": 111, "endOffset": 115}, {"referenceID": 20, "context": "Therefore, a more practical approach is to consider such a quadratic programming problem in the primal form of an unconstrained problem [21,34] as follows:", "startOffset": 136, "endOffset": 143}, {"referenceID": 33, "context": "Therefore, a more practical approach is to consider such a quadratic programming problem in the primal form of an unconstrained problem [21,34] as follows:", "startOffset": 136, "endOffset": 143}, {"referenceID": 8, "context": "At each iteration of Newton\u2019s method, we update w\u0303 to w\u0303 \u2212 \u03b7H\u22121g where \u03b7 is the learning rate found through the line search technique [9].", "startOffset": 134, "endOffset": 137}, {"referenceID": 9, "context": "For the outlier score of No, denoted by OS(No), we follow a similar approach as [10] but computing it only in the subspace spanned by the explanatory subnetworks.", "startOffset": 80, "endOffset": 84}, {"referenceID": 9, "context": "We therefore employ the best-effort-approach that follows the strategy developed in [10,37].", "startOffset": 84, "endOffset": 91}, {"referenceID": 36, "context": "We therefore employ the best-effort-approach that follows the strategy developed in [10,37].", "startOffset": 84, "endOffset": 91}, {"referenceID": 9, "context": "30}, similar to the range chosen in [10], and \u03bb1 = {0.", "startOffset": 36, "endOffset": 40}, {"referenceID": 6, "context": "Specifically, it is compared against the following techniques: (1) Netspot [7] without temporal constraint so allowing it to uncover network regions from each individual network; (2) HiCS [22] that seeks outliers through contrast subspaces for high dimensional data; (3) ABOD [25] which discovers outliers via variance of angles between vector triples; (4) ODesMw/o, a variant of our method that does not exploit network regularization.", "startOffset": 75, "endOffset": 78}, {"referenceID": 21, "context": "Specifically, it is compared against the following techniques: (1) Netspot [7] without temporal constraint so allowing it to uncover network regions from each individual network; (2) HiCS [22] that seeks outliers through contrast subspaces for high dimensional data; (3) ABOD [25] which discovers outliers via variance of angles between vector triples; (4) ODesMw/o, a variant of our method that does not exploit network regularization.", "startOffset": 188, "endOffset": 192}, {"referenceID": 24, "context": "Specifically, it is compared against the following techniques: (1) Netspot [7] without temporal constraint so allowing it to uncover network regions from each individual network; (2) HiCS [22] that seeks outliers through contrast subspaces for high dimensional data; (3) ABOD [25] which discovers outliers via variance of angles between vector triples; (4) ODesMw/o, a variant of our method that does not exploit network regularization.", "startOffset": 276, "endOffset": 280}, {"referenceID": 6, "context": "The parameter setting for ODesM and ODesMw/o follows the discussion in Section VI, while for Netspot, we set the number of failures h = 10 as suggested in [7].", "startOffset": 155, "endOffset": 158}, {"referenceID": 21, "context": "For HiCS, we choose all settings as suggested by the authors [22] and adopt LOF as its core algorithm.", "startOffset": 61, "endOffset": 65}, {"referenceID": 31, "context": "Though images do not originally involve explicit network structures, studying them as graphs has been extensively studied and deemed advantageous [32].", "startOffset": 146, "endOffset": 150}, {"referenceID": 31, "context": "Following [32], we first down-sample the number of pixels to 50% and construct a common network topology relying on the remaining pixels.", "startOffset": 10, "endOffset": 14}, {"referenceID": 22, "context": "The second dataset we use for evaluation is the Liver metastasis in human [23] with the gene network derived from the protein-protein interaction.", "startOffset": 74, "endOffset": 78}, {"referenceID": 22, "context": "5) are particularly interesting since they are in agreement with the ones found in [23] and have been reported to be involved in liver metastasis.", "startOffset": 83, "endOffset": 87}, {"referenceID": 9, "context": "As discussed in Section VI, we select a range of values for K and \u03bb1 and apply the best-effort-approach [10,37] to compute outlierness for each network sample.", "startOffset": 104, "endOffset": 111}, {"referenceID": 36, "context": "As discussed in Section VI, we select a range of values for K and \u03bb1 and apply the best-effort-approach [10,37] to compute outlierness for each network sample.", "startOffset": 104, "endOffset": 111}, {"referenceID": 2, "context": "Outlier detection from network data can generally be divided into two categories: those addressing plain networks [3,14] and those focusing on attributed networks [16, 28].", "startOffset": 114, "endOffset": 120}, {"referenceID": 13, "context": "Outlier detection from network data can generally be divided into two categories: those addressing plain networks [3,14] and those focusing on attributed networks [16, 28].", "startOffset": 114, "endOffset": 120}, {"referenceID": 15, "context": "Outlier detection from network data can generally be divided into two categories: those addressing plain networks [3,14] and those focusing on attributed networks [16, 28].", "startOffset": 163, "endOffset": 171}, {"referenceID": 27, "context": "Outlier detection from network data can generally be divided into two categories: those addressing plain networks [3,14] and those focusing on attributed networks [16, 28].", "startOffset": 163, "endOffset": 171}, {"referenceID": 2, "context": "In the first category, only information about the network topology is available and most studies adopt structurebased [3,14] and community-based methods [33] to spot nodes or small groups of nodes that have abnormal connectivity patterns.", "startOffset": 118, "endOffset": 124}, {"referenceID": 13, "context": "In the first category, only information about the network topology is available and most studies adopt structurebased [3,14] and community-based methods [33] to spot nodes or small groups of nodes that have abnormal connectivity patterns.", "startOffset": 118, "endOffset": 124}, {"referenceID": 32, "context": "In the first category, only information about the network topology is available and most studies adopt structurebased [3,14] and community-based methods [33] to spot nodes or small groups of nodes that have abnormal connectivity patterns.", "startOffset": 153, "endOffset": 157}, {"referenceID": 15, "context": "Discovering outlying patterns therefore seeks not only abnormal connectivity structure but also coherence of network attributes [16,28].", "startOffset": 128, "endOffset": 135}, {"referenceID": 27, "context": "Discovering outlying patterns therefore seeks not only abnormal connectivity structure but also coherence of network attributes [16,28].", "startOffset": 128, "endOffset": 135}, {"referenceID": 26, "context": "Network properties like normality [27], conductance [5] and Oddball [3] are often employed to quantify the internal consistency and external separability (collectively anomalous degree) of a set of nodes (local communities).", "startOffset": 34, "endOffset": 38}, {"referenceID": 4, "context": "Network properties like normality [27], conductance [5] and Oddball [3] are often employed to quantify the internal consistency and external separability (collectively anomalous degree) of a set of nodes (local communities).", "startOffset": 52, "endOffset": 55}, {"referenceID": 2, "context": "Network properties like normality [27], conductance [5] and Oddball [3] are often employed to quantify the internal consistency and external separability (collectively anomalous degree) of a set of nodes (local communities).", "startOffset": 68, "endOffset": 71}, {"referenceID": 0, "context": "Several recent studies [1,7,11,17] developed for dynamic networks are closer to ours.", "startOffset": 23, "endOffset": 34}, {"referenceID": 6, "context": "Several recent studies [1,7,11,17] developed for dynamic networks are closer to ours.", "startOffset": 23, "endOffset": 34}, {"referenceID": 10, "context": "Several recent studies [1,7,11,17] developed for dynamic networks are closer to ours.", "startOffset": 23, "endOffset": 34}, {"referenceID": 16, "context": "Several recent studies [1,7,11,17] developed for dynamic networks are closer to ours.", "startOffset": 23, "endOffset": 34}, {"referenceID": 10, "context": "In [11], the authors present 6 types of community-based outliers including shrink, grow, 0.", "startOffset": 3, "endOffset": 7}, {"referenceID": 0, "context": "In [1], the temporal distribution of the number of messages exchanged in a social network (like Twitter) is used as means to detect abnormal events.", "startOffset": 3, "endOffset": 6}, {"referenceID": 7, "context": "Authors in [8] introduce a novel problem of mining a heaviest dynamic subgraph (HDS) in a time evolving network.", "startOffset": 11, "endOffset": 14}, {"referenceID": 6, "context": "This study is recently extended in [7] to the NetSpot technique that enables the mining of multiple HDSs.", "startOffset": 35, "endOffset": 38}, {"referenceID": 6, "context": "NetSpot approximates HDSs via a local search approach and it alleviates the local optimal solutions via exploring a large range of neighborhood search [7].", "startOffset": 151, "endOffset": 154}, {"referenceID": 1, "context": "Other studies [2] monitor global network parameters/probabilities to detect events/changes while those developed in [17] attempt to spot anomalous nodes and edges.", "startOffset": 14, "endOffset": 17}, {"referenceID": 16, "context": "Other studies [2] monitor global network parameters/probabilities to detect events/changes while those developed in [17] attempt to spot anomalous nodes and edges.", "startOffset": 116, "endOffset": 120}, {"referenceID": 36, "context": "Outlier detection in high dimensional spaces [37] can also be conceptually related to our studies.", "startOffset": 45, "endOffset": 49}, {"referenceID": 21, "context": "Two popular approaches to deal with this problem are from subspace sampling [22] and subspace projection [24].", "startOffset": 76, "endOffset": 80}, {"referenceID": 23, "context": "Two popular approaches to deal with this problem are from subspace sampling [22] and subspace projection [24].", "startOffset": 105, "endOffset": 109}, {"referenceID": 34, "context": "To deal with very large networks, we could apply network compression [35] that allows us to summarize both network topology and signals on the nodes.", "startOffset": 69, "endOffset": 73}], "year": 2016, "abstractText": "Detecting a small number of outliers from a set of data observations is always challenging. This problem is more difficult in the setting of multiple network samples, where computing the anomalous degree of a network sample is generally not sufficient. In fact, explaining why the network is exceptional, expressed in the form of subnetwork, is also equally important. In this paper, we develop a novel algorithm to address these two key problems. We treat each network sample as a potential outlier and identify subnetworks that mostly discriminate it from nearby regular samples. The algorithm is developed in the framework of network regression combined with the constraints on both network topology and L1-norm shrinkage to perform subnetwork discovery. Our method thus goes beyond subspace /subgraph discovery and we show that it converges to a global optimum. Evaluation on various real-world network datasets demonstrates that our algorithm not only outperforms baselines in both network and high dimensional setting, but also discovers highly relevant and interpretable local subnetworks, further enhancing our understanding of anomalous networks.", "creator": "LaTeX with hyperref package"}}}