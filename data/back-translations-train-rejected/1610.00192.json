{"id": "1610.00192", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Oct-2016", "title": "A large scale study of SVM based methods for abstract screening in systematic reviews", "abstract": "A major task in systematic reviews is abstract screening, i.e., excluding, often hundreds or thousand of, irrelevant citations returned from a database search based on titles and abstracts. Thus, a systematic review platform that can automate the abstract screening process is of huge importance. Several methods have been proposed for this task. However, it is very hard to clearly understand the applicability of these methods in a systematic review platform because of the following challenges: (1) the use of non-overlapping metrics for the evaluation of the proposed methods, (2) usage of features that are very hard to collect, (3) using a small set of reviews for the evaluation, and (4) no solid statistical testing or equivalence grouping of the methods. In this paper, we use feature representation that can be extracted per citation. We evaluate SVM-based methods (commonly used) on a large set of reviews ($61$) and metrics ($11$) to provide equivalence grouping of methods based on a solid statistical test. Our analysis also includes a strong variability of the metrics using $500$x$2$ cross validation. While some methods shine for different metrics and for different datasets, there is no single method that dominates the pack. Furthermore, we observe that in some cases relevant (included) citations can be found after screening only 15-20% of them via a certainty based sampling. A few included citations present outlying characteristics and can only be found after a very large number of screening steps. Finally, we present an ensemble algorithm for producing a $5$-star rating of citations based on their relevance. Such algorithm combines the best methods from our evaluation and through its $5$-star rating outputs a more easy-to-consume prediction.", "histories": [["v1", "Sat, 1 Oct 2016 21:11:38 GMT  (122kb)", "https://arxiv.org/abs/1610.00192v1", null], ["v2", "Thu, 13 Oct 2016 12:56:11 GMT  (122kb)", "http://arxiv.org/abs/1610.00192v2", null]], "reviews": [], "SUBJECTS": "cs.IR cs.LG", "authors": ["tanay kumar saha", "mourad ouzzani", "hossam m hammady", "ahmed k elmagarmid"], "accepted": false, "id": "1610.00192"}, "pdf": {"name": "1610.00192.pdf", "metadata": {"source": "CRF", "title": "A large scale study of SVM based methods for abstract screening in systematic reviews*", "authors": ["Tanay Kumar Saha"], "emails": ["tksaha@iupui.edu", "aelmagarmid}@qf.org.qa"], "sections": [{"heading": null, "text": "iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii"}, {"heading": "II. RELATED WORK", "text": "We divide this work into four groups: 1) Work on \"Abstract Screening\" methods, 2) Discussion on \"Data Imbalance,\" as this is one of the main problems in Abstract1 http: / / rayan.qcri.org / Aspect Related StudiesFeature Space Representation Uni, Bigram, MeSH [9], LDA [10], Uni + Cite [11] Algorithm SVM [12], [13], Other [14] Cross Validation 5 \u00d7 2 [9], [11], [13], [15], [16], 10-fold [17] No. of Reviews used 15 [11], [15], [16], [16], 6 [12], 6 [12], 18-fold [17] Statistical Testing Post-hoc paired Wilcoxon Test [9], 3-17, [16] 17."}, {"heading": "A. Abstract Screening", "text": "Much of the research to date has focused on the automation of the abstract screening process [9], [11] - [13], [15], [16]. An alternative to MeSH terms is to extract latent topics from the titles along with the abstracts and use them as characteristics [12]. Other methods [11], [15] use external information as characteristics, such as quotations and codes. Methodologically, SVM-based learning algorithms are frequently used [9], [13], [15]. According to a recent study [14], systematic reviews have proposed 13 different types of algorithms, including SVM, Decision Trees, Naive Bayes, k-next neighbor, and neuronal networks."}, {"heading": "B. Data imbalance", "text": "The data imbalance in the supervised classification is a well-studied problem [19] - [23]. Two different types of approaches have been proposed for its solution: The first focuses on the conception of loss functions: KLD [24], square mean [25], cost sensitiveclassification [26], mean average precision [27], random forest [28] with metacost and AUC [19]. The second type generates synthetic data to artificially balance the relationship between marked relevant and irrelevant citations. Examples of such methods are borderline SMOTE [29], safe-levelSMOTE [30] and oversampling of the minority class with the support of the majority class. The authors in [31] - [33] use probability calibration techniques. In this paper, we evaluate the algorithmic approaches rather than the data-centric approaches or methods based on probability calibration, which is always too intensive to validate data."}, {"heading": "C. Active Learning", "text": "Since systematic checks are carried out in batches, the problem of abstract screening can be modeled as an example of active learning in batch mode. Online learning trains the classifier after adding each quote, while Batch Mode Active Learning (BAL) does the same after adding batch quotes. However, BAL has no theoretical guarantee in comparison to online learning [34], [35]. The task of BAL is to select batches with informative samples (quotes) that would help to learn a better classification model. There are two popular methods for selecting the samples: (1) certainty-based and (2) uncertainty-based. In safety-based methods, \"safety-based\" samples are selected to train the classifier, while in uncertainty-based methods \"unsafe\" are selected. In the sample-based methods, a large number of uncertainty metrics were suggested [38, 37, 39] least trust [37]."}, {"heading": "D. Linear Review", "text": "A very similar review system popular with law firms is Technology Assisted Linear Review (TAR) [42] - [46]. The main objectives of both review systems are very similar. TAR is used to save lawyers time sifting through relevant documents rather than looking for irrelevant documents. In general, the number of documents compared to the same is huge (millions) during systematic review, so active learning is becoming a popular method. However, unlike systematic reviews, TAR researchers are interested in finding a good stabilization point - a point at which classifier training should be stopped. In addition, TAR considers a recall of at least 75% acceptable, while systematic reviews are 95% - 100% desirable."}, {"heading": "III. METHOD", "text": "For abstract screening, we have Title (Ti) and Abstract (Ai) for a set of n quotations, C = {CTi, Ai} 1 \u2264 i \u2264 n. We represent each quote, CTi, Ai as a tuple < xCi, yCi >: xCi is a d-dimensional feature space representation of the quote, and yCi * {+ 1, \u2212 1} is a binary label indicating whether Ci is relevant or not. Additionally, we use the following notations throughout the essay: We use L and U for the labeled or unlabeled quotations, F () to represent features for a set of quotations, h for the hypothesis or hyper level learned through training at L, and l (w) for the latent space representation for a particular word, w. In this section, we describe the feature space representation and the methods for evaluating an automated abstract screening system."}, {"heading": "A. Feature Space Representation", "text": "For Word2Vec [48], we use the model on the entire set of quotations (summaries and titles) available in an existing systematic verification platform. We use Gensim [49] package with the following parameters: the number of contextual words as 5, the minimum number of words as 15, and the number of dimensions in latent space as 500. Thus, for each word in the set of all available words (wi-W), we learn a 500-dimensional latent spatial representation. Some query results from the trained model are presented in Table II. We can conclude that the model captures the latent similarities between different bio-medical terms. For example, the cosmic similarity between \"liver\" and \"cirrhosis\" is a norm."}, {"heading": "B. Algorithms", "text": "In Table III we outline the different algorithms we use in our comparison along with their parameters, loss functions and the identifier to represent each algorithm. Table VI uses the identifiers as opposed to the name of the methods. For example, the first line in Table III refers to a method identified by Id 1, which uses SVMperf with b = 0 and AUC as the loss function. We use three types of SVM: (1) inductive (2) transductive and (3) SVM for multivariate power. Inductive SVM learns a hypothesis, h induced by F (L). Transductive SVM answers the most general question: What information do we get from the study of F (U) and how can we use it? It also uses the idea of equivalence classes: Two functions from the hypothesis space H belong to the simulation equivalence class F (F) if they both classify the instances of F (U) and F (L) in the same way."}, {"heading": "C. Tuning the cost parameter and setting the threshold", "text": "For the inductive and transductive SVM methods, the standard cost parameter, referred to as c, is calculated as follows: b = \u2211 1 \u2264 i \u2264 | L | \u0433xCi \u0445 | L | c = 1.0 b \u0445 bThe sum of all 2-standard feature vectors is divided by the number of instances in F (L) to b. Finally, the fraction 1.0b \u0445 b in SVM costs results in the following ratio: # of irrelevant # of relevant. The ratio distorts the hypothesis learner (traction algorithm) to punish errors in the minority class J (relevant class) times more than in the majority class. Furthermore, we follow the recommendation for the error loss function of [19] to determine the cost parameter for SVMperf: SVMperf (c) = SVM (c) \u00d7 # of instances. The motivation to use these values is to make our results more reproducible. To evaluate the reproducibility of this method, it is important to verify the most important values (SVM)."}, {"heading": "IV. EXPERIMENTAL RESULTS", "text": "We run all our experiments on a computer with a 24-core Intel XEON X5650 2.6 Ghz processor running CentOS 6.7. For each dataset (described in the next section) we perform a 500 x 2-fold cross-validation for each method to analyze the variability. In the n x k-fold cross-validation we divide the data into k-blocks; the k-th block becomes the test block and the rest becomes the training data and we repeat this process n-times. The division is done by layering. So for 500 x 2 we divide each dataset into two blocks and then use each block once as a training and once as a test. We repeat this process 500 times."}, {"heading": "A. Datasets", "text": "In Table III-C, all publicly available reviews start with C (Cohen), while reviews from our system start with P (Private). In the table, we provide three statistics about the review - the total number of citations, the total number of relevant citations, and the prevalence (ratio of relevance to the total number of citations).We divide reviews into three prevalence groups: (1) Low (0.22% to 5.92%) (2) Average (6.79% to 13.07%) and (3) High (13.45% to 40.08%).This allows us to examine the behavior of the performance indicators discussed later within each group. It also helps us present our results in a detailed manner. Data sets for each group are sorted by their prevalence."}, {"heading": "B. Performance Metrics", "text": "The first four measurements (Recall, Precision, F-Measure, and Accuracy) depend on a threshold and are often used to evaluate automated abstract screening methods. ROC and AUPRC are independent of thresholds and are often used for binary classification problems with data imbalances. We add two more measurements: (1) arithmetic mean of LRp and LRn. The square mean error is the square root of the arithmetic mean of the squares of LRp and LRn. In active learning settings, Burden, utility, and yield are commonly used. For more detailed / vgleps: 1V3V5V5V5VWWWW5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W5W"}, {"heading": "C. Statistical Test", "text": "We have 18 different methods (Table III) and three prevalence groups: (1) Low prevalence, (2) Medium prevalence and (3) High prevalence. We want to compare the methods based on the data sets of a particular prevalence group on a particular measure. Our goal is to generalize the results of a larger population of possible data sets located within a defined prevalence group. To be more precise, the model resembles y = mx + c, where x is a variable and m, c are the constants. In this model, DATA and METHOD can mimic x and c. We fit the model into a linear regression frame and perform a statistical analysis of variance."}, {"heading": "D. Performance comparison", "text": "In Table VI we present our results (in the first three ranks / groups), in relation to the metrics we define in Table V, for all methods on all data sets. Datasets are grouped by their prevalence, as we have explained earlier. However, the results, for each metric and prevalence, are presented as equivalence groups based on statistical tests (\u03b1 = 0.05). All methods using the UniBi, WORD2VEC ROW, and WORD2VEC COLUMN functions have an identification as 1 \u2212 11 is specific to SVM Transduction), 21 \u2212 25 and 31 \u2212 35 respectively (Table III).We first analyze the metrics that depend on a threshold. For Precision (Precision), cost-sensitive SVM (7, where 7 was used as an identifier for cost-sensitive SVM, SVM in Table III)."}, {"heading": "E. Experiment in an active learning setting", "text": "Therefore, an active learning approach has the potential to achieve better results [12]. We use the SVMperf (AUC) method (21) for this experiment, as it is the most powerful method in terms of AUC metrics in all three prevalence groups (Table VI). First, we randomly select 5 relevant and 45 irrelevant quotations from the entire sentence, and then learn a hyperplane. We calculate the distance (score) from the hyperplane for each of the blank distances and evaluate them on the basis of this score. We select the top 50 from the ranked citations to retrain the model along with the existing citations. We repeat this experiment 500 times and take the average. The goal of this experiment is to see: If a particular user labels 50 high-level citations per batch, what is the percentage of total citations that the user searches to get all relevant citations?"}, {"heading": "VI. CONCLUSIONS AND FUTURE WORK", "text": "A key task in this process is to sift through hundreds to thousands of citations and identify relevant studies for further analysis. In this paper, we have examined the most popular classification methods used in this task. We focus on the methods that better fit the constraints of a practical abstract screening system. In total, we report on 18 methods for a very large number of evaluations (61) using 11 metrics. There is no single \"winner\" or best method - different methods perform well for different prevalence groups and for different metrics. We also observe that in an active learning environment, a very large proportion of the citations contained with SVMperf (AUC) seems to be a good choice that outperforms the other methods in five metrics, but does not perform well for a few other metrics. We also observe that a very large proportion of the citations contained can be easily found with few iterations, as one or two citations exhibit certain behavior and many more iterations are needed."}], "references": [{"title": "A method for assessing the quality of a randomized control trial", "author": ["T.C. Chalmers", "H. Smith", "B. Blackburn", "B. Silverman", "B. Schroeder", "D. Reitman", "A. Ambroz"], "venue": "Controlled clinical trials, vol. 2, no. 1, pp. 31\u201349, 1981.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1981}, {"title": "Systematic reviews and meta-analyses", "author": ["L.S. Uman"], "venue": "Journal of the Canadian Academy of Child and Adolescent Psychiatry, vol. 20, no. 1, p. 57, 2011.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2011}, {"title": "Learnability of bipartite ranking functions", "author": ["S. Agarwal", "D. Roth"], "venue": "Learning Theory. Springer, 2005, pp. 16\u201331.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2005}, {"title": "Robust reductions from ranking to classification", "author": ["M.-F. Balcan", "N. Bansal", "A. Beygelzimer", "D. Coppersmith", "J. Langford", "G.B. Sorkin"], "venue": "Machine learning, vol. 72, no. 1-2, pp. 139\u2013153, 2008.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2008}, {"title": "Using text mining for study identification in systematic reviews: a systematic review of current approaches", "author": ["A. OMara-Eves", "J. Thomas", "J. McNaught", "M. Miwa", "S. Ananiadou"], "venue": "Systematic reviews, vol. 4, no. 1, p. 1, 2015.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "Evaluating and maintaining classification algorithms", "author": ["T. Raeder"], "venue": "University of Notre Dame,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2012}, {"title": "Consequences of variability in classifier performance estimates", "author": ["T. Raeder", "T.R. Hoens", "N.V. Chawla"], "venue": "2010 IEEE 10th International Conference on Data Mining (ICDM), 2010, pp. 421\u2013430.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2010}, {"title": "A prospective evaluation of an automated classification system to support evidence-based medicine and systematic review", "author": ["K. Ambert"], "venue": "vol. 2010, p. 121, 2010.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2010}, {"title": "Supporting systematic reviews using lda-based document representations", "author": ["Y. Mo", "G. Kontonatsios", "S. Ananiadou"], "venue": "Systematic reviews, vol. 4, no. 1, p. 1, 2015.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning to identify relevant studies for systematic reviews using random forest and external information", "author": ["M. Khabsa", "A. Elmagarmid", "I. Ilyas", "H. Hammady", "M. Ouzzani"], "venue": "Machine Learning, pp. 1\u201318, 2015.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2015}, {"title": "Reducing systematic review workload through certainty-based screening", "author": ["M. Miwa", "J. Thomas", "A. OMara-Eves", "S. Ananiadou"], "venue": "Journal of biomedical informatics, vol. 51, pp. 242\u2013253, 2014.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2014}, {"title": "Studying the potential impact of automated document classification on scheduling a systematic review update", "author": ["A.M. Cohen", "K. Ambert", "M. McDonagh"], "venue": "BMC medical informatics and decision making, vol. 12, no. 1, p. 1, 2012.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2012}, {"title": "A critical analysis of studies that address the use of text mining for citation screening in systematic reviews", "author": ["B.K. Olorisade", "E. De Quincey", "O. Brereton", "P. Andras"], "venue": "2016.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2016}, {"title": "Optimizing feature representation for automated systematic review work prioritization", "author": ["A.M. Cohen"], "venue": "AMIA annual symposium proceedings, vol. 2008, 2008, p. 121.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2008}, {"title": "Reducing workload in systematic review preparation using automated citation classification", "author": ["A.M. Cohen", "W.R. Hersh", "K. Peterson", "P.-Y. Yen"], "venue": "Journal of the American Medical Informatics Association, vol. 13, no. 2, pp. 206\u2013219, 2006.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2006}, {"title": "Machine learning methods in systematic reviews: identifying quality improvement intervention evaluations", "author": ["S. Hempel", "K.D. Shetty", "P.G. Shekelle", "L.V. Rubenstein", "M.S. Danz", "B. Johnsen", "S.R. Dalal"], "venue": "2012.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2012}, {"title": "Active learning for biomedical citation screening", "author": ["B.C. Wallace", "K. Small", "C.E. Brodley", "T.A. Trikalinos"], "venue": "Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining, 2010, pp. 173\u2013182.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2010}, {"title": "A support vector method for multivariate performance measures", "author": ["T. Joachims"], "venue": "Proceedings of the 22nd international conference on Machine learning, 2005, pp. 377\u2013384.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2005}, {"title": "Transductive inference for text classification using support vector machines", "author": ["\u2014\u2014"], "venue": "ICML, vol. 99, 1999, pp. 200\u2013209.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1999}, {"title": "PEGASOS: Primal estimated sub-gradient solver for svm", "author": ["S. Shalev-Shwartz", "Y. Singer", "N. Srebro", "A. Cotter"], "venue": "Mathematical programming, vol. 127, no. 1, pp. 3\u201330, 2011.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2011}, {"title": "Data classification: algorithms and applications", "author": ["C.C. Aggarwal"], "venue": "CRC Press,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2014}, {"title": "Probabilistic models for text mining", "author": ["Y. Sun", "H. Deng", "J. Han"], "venue": "Mining Text Data. Springer, 2012, pp. 259\u2013295.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2012}, {"title": "Optimizing text quantifiers for multivariate loss functions", "author": ["A. Esuli", "F. Sebastiani"], "venue": "ACM Transactions on Knowledge Discovery from Data (TKDD), vol. 9, no. 4, p. 27, 2015.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2015}, {"title": "A quadratic mean based supervised learning model for managing data skewness.", "author": ["W. Liu", "S. Chawla"], "venue": "in SDM,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2011}, {"title": "The foundations of cost-sensitive learning", "author": ["C. Elkan"], "venue": "International joint conference on artificial intelligence, vol. 17, no. 1, 2001, pp. 973\u2013 978.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2001}, {"title": "A support vector method for optimizing average precision", "author": ["Y. Yue", "T. Finley", "F. Radlinski", "T. Joachims"], "venue": "Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval, 2007, pp. 271\u2013278.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2007}, {"title": "Using random forest to learn imbalanced data", "author": ["C. Chen", "A. Liaw", "L. Breiman"], "venue": "University of California, Berkeley, 2004.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2004}, {"title": "Borderline-SMOTE: a new oversampling method in imbalanced data sets learning", "author": ["H. Han", "W.-Y. Wang", "B.-H. Mao"], "venue": "Advances in intelligent computing, 2005, pp. 878\u2013887.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2005}, {"title": "Safelevel-SMOTE: Safe-level-synthetic minority over-sampling technique for handling the class imbalanced problem", "author": ["C. Bunkhumpornpat", "K. Sinapiromsaran", "C. Lursinsap"], "venue": "Advances in knowledge discovery and data mining, 2009, pp. 475\u2013482.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2009}, {"title": "Improving class probability estimates for imbalanced data", "author": ["B.C. Wallace", "I.J. Dahabreh"], "venue": "Knowledge and Information Systems, vol. 41, no. 1, pp. 33\u201352, 2014.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2014}, {"title": "Class probability estimates are unreliable for imbalanced data (and how to fix them)", "author": ["\u2014\u2014"], "venue": "12th International Conference on Data Mining, 2012, pp. 695\u2013704.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2012}, {"title": "Predicting good probabilities with supervised learning", "author": ["A. Niculescu-Mizil", "R. Caruana"], "venue": "Proceedings of the 22nd international conference on Machine learning, 2005, pp. 625\u2013632.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2005}, {"title": "Support vector machine active learning with application to text classification", "author": ["S. Tong", "D. Koller"], "venue": "vol. 2, 2001, pp. 45\u201366.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2001}, {"title": "Theory of active learning", "author": ["S. Hanneke"], "venue": "2014.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2014}, {"title": "Committee-based sampling for training probabilistic classifiers", "author": ["I. Dagan", "S.P. Engelson"], "venue": "Proceedings of the Twelfth International Conference on Machine Learning, 1995, pp. 150\u2013157.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 1995}, {"title": "Active hidden markov models for information extraction", "author": ["T. Scheffer", "C. Decomain", "S. Wrobel"], "venue": "Advances in Intelligent Data Analysis. Springer, 2001, pp. 309\u2013318.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2001}, {"title": "Reducing labeling effort for structured prediction tasks", "author": ["A. Culotta", "A. McCallum"], "venue": "AAAI, 2005, pp. 746\u2013751.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2005}, {"title": "Query by committee", "author": ["H.S. Seung", "M. Opper", "H. Sompolinsky"], "venue": "Proceedings of the fifth annual workshop on Computational learning theory. ACM, 1992, pp. 287\u2013294.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 1992}, {"title": "Noisy generalized binary search", "author": ["R. Nowak"], "venue": "Advances in neural information processing systems, 2009, pp. 1366\u20131374.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2009}, {"title": "Certainty-enhanced active learning for improving imbalanced data classification", "author": ["J. Fu", "S. Lee"], "venue": "Data Mining Workshops (ICDMW), 2011 IEEE 11th International Conference on. IEEE, 2011, pp. 405\u2013 412.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2011}, {"title": "Document categorization in legal electronic discovery: computer classification vs. manual review", "author": ["H.L. Roitblat", "A. Kershaw", "P. Oot"], "venue": "Journal of the American Society for Information Science and Technology, vol. 61, no. 1, pp. 70\u201380, 2010.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2010}, {"title": "The challenge and promise of predictive coding for privilege", "author": ["M. Gabriel", "C. Paskach", "D. Sharpe"], "venue": "ICAIL 2013 DESI V Workshop, 2013.", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2013}, {"title": "Predictive coding: Explanation and analysis of judicial impact and acceptance compared to established e-commerce methodology", "author": ["D.W. Henry"], "venue": "http://www.dwhenry.com/files/Predictive%20Coding.pdf, [Online;Accessed 23-June-2015].", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2015}, {"title": "Technology-assisted review in e-discovery can be more effective and more efficient than exhaustive manual review", "author": ["M.R. Grossman", "G.V. Cormack"], "venue": "Rich. JL & Tech., vol. 17, p. 1, 2010.", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2010}, {"title": "The grossman-cormack glossary of technologyassisted review", "author": ["C. GLOSSARY"], "venue": "Federal Courts Law Review, vol. 7, no. 1, 2013.", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2013}, {"title": "Batch-mode active learning for technology-assisted review", "author": ["T.K. Saha", "M. Al Hasan", "C. Burgess", "M.A. Habib", "J. Johnson"], "venue": "Big Data (Big Data), 2015 IEEE International Conference on. IEEE, 2015, pp. 1134\u20131143.", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2015}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["T. Mikolov", "I. Sutskever", "K. Chen", "G.S. Corrado", "J. Dean"], "venue": "Advances in neural information processing systems, 2013, pp. 3111\u20133119.", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2013}, {"title": "Software Framework for Topic Modelling with Large Corpora", "author": ["R. \u0158eh\u016f\u0159ek", "P. Sojka"], "venue": "Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks. ELRA, 2010, pp. 45\u201350.", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2010}, {"title": "Training linear svms in linear time", "author": ["T. Joachims"], "venue": "Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2006, pp. 217\u2013226.", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2006}, {"title": "RMEQ: A tool for computing equivalence groups in repeated measures studies. in: Linking literature", "author": ["AM M.S. Cohen"], "venue": "Information and Knowledge for Biology: Proceedings of the BioLINK2008 Workshop, 2008.", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2008}], "referenceMentions": [{"referenceID": 0, "context": "Randomized controlled trials (RCTs) are a key component of medical research and by far the best way of achieving results that can genuinely increase our knowledge about treatment effectiveness [1].", "startOffset": 193, "endOffset": 196}, {"referenceID": 1, "context": "and then based on full texts of a subset thereof, assessing their methodological qualities, data extraction and synthesis, and finally reporting the conclusions on the review question [3].", "startOffset": 184, "endOffset": 187}, {"referenceID": 2, "context": "Generating a clear bipartition is a quite difficult task [4] and a common measure of success in such scenario is the area under the ROC curve (AUC).", "startOffset": 57, "endOffset": 60}, {"referenceID": 3, "context": "However, the optimization techniques based on the AUC can be reduced to binary classification [5] methods under specific settings.", "startOffset": 94, "endOffset": 97}, {"referenceID": 4, "context": "It is worth mentioning that a recent systematic review of current approaches in abstract screening [6] reported that among the 69 publications it surveyed, only 22 report about Recall, 18 report about Precision, and 10 about AUC.", "startOffset": 99, "endOffset": 102}, {"referenceID": 5, "context": "Moreover, recent works [7], [8] suggest studying the variability of the reported metrics and advocate using a large number of repetitions (500\u00d7 2) to make the conclusions more reproducible.", "startOffset": 23, "endOffset": 26}, {"referenceID": 6, "context": "Moreover, recent works [7], [8] suggest studying the variability of the reported metrics and advocate using a large number of repetitions (500\u00d7 2) to make the conclusions more reproducible.", "startOffset": 28, "endOffset": 31}, {"referenceID": 7, "context": "Feature Space Representation Uni, Bigram, MeSH [9], LDA [10], Uni + Cite [11]", "startOffset": 47, "endOffset": 50}, {"referenceID": 8, "context": "Feature Space Representation Uni, Bigram, MeSH [9], LDA [10], Uni + Cite [11]", "startOffset": 56, "endOffset": 60}, {"referenceID": 9, "context": "Feature Space Representation Uni, Bigram, MeSH [9], LDA [10], Uni + Cite [11]", "startOffset": 73, "endOffset": 77}, {"referenceID": 10, "context": "Algorithm SVM Based [12], [13], Others [14]", "startOffset": 20, "endOffset": 24}, {"referenceID": 11, "context": "Algorithm SVM Based [12], [13], Others [14]", "startOffset": 26, "endOffset": 30}, {"referenceID": 12, "context": "Algorithm SVM Based [12], [13], Others [14]", "startOffset": 39, "endOffset": 43}, {"referenceID": 7, "context": "Cross Validation 5\u00d72 [9], [11], [13], [15], [16], 10-fold [17]", "startOffset": 21, "endOffset": 24}, {"referenceID": 9, "context": "Cross Validation 5\u00d72 [9], [11], [13], [15], [16], 10-fold [17]", "startOffset": 26, "endOffset": 30}, {"referenceID": 11, "context": "Cross Validation 5\u00d72 [9], [11], [13], [15], [16], 10-fold [17]", "startOffset": 32, "endOffset": 36}, {"referenceID": 13, "context": "Cross Validation 5\u00d72 [9], [11], [13], [15], [16], 10-fold [17]", "startOffset": 38, "endOffset": 42}, {"referenceID": 14, "context": "Cross Validation 5\u00d72 [9], [11], [13], [15], [16], 10-fold [17]", "startOffset": 44, "endOffset": 48}, {"referenceID": 15, "context": "Cross Validation 5\u00d72 [9], [11], [13], [15], [16], 10-fold [17]", "startOffset": 58, "endOffset": 62}, {"referenceID": 9, "context": "of Reviews used 15 [11], [15], [16], 6 [12], 18 [9], 3 [18], 1 [17]", "startOffset": 19, "endOffset": 23}, {"referenceID": 13, "context": "of Reviews used 15 [11], [15], [16], 6 [12], 18 [9], 3 [18], 1 [17]", "startOffset": 25, "endOffset": 29}, {"referenceID": 14, "context": "of Reviews used 15 [11], [15], [16], 6 [12], 18 [9], 3 [18], 1 [17]", "startOffset": 31, "endOffset": 35}, {"referenceID": 10, "context": "of Reviews used 15 [11], [15], [16], 6 [12], 18 [9], 3 [18], 1 [17]", "startOffset": 39, "endOffset": 43}, {"referenceID": 7, "context": "of Reviews used 15 [11], [15], [16], 6 [12], 18 [9], 3 [18], 1 [17]", "startOffset": 48, "endOffset": 51}, {"referenceID": 16, "context": "of Reviews used 15 [11], [15], [16], 6 [12], 18 [9], 3 [18], 1 [17]", "startOffset": 55, "endOffset": 59}, {"referenceID": 15, "context": "of Reviews used 15 [11], [15], [16], 6 [12], 18 [9], 3 [18], 1 [17]", "startOffset": 63, "endOffset": 67}, {"referenceID": 7, "context": "Statistical Testing Post-hoc paired Wilcoxon test [9], Rank Group [11]", "startOffset": 50, "endOffset": 53}, {"referenceID": 9, "context": "Statistical Testing Post-hoc paired Wilcoxon test [9], Rank Group [11]", "startOffset": 66, "endOffset": 70}, {"referenceID": 7, "context": "Reported Metric AUC [9], [11], Utility [12], Burden [12], Yield [12], WSS [11], Precision [13], Recall [11], F1 [13]", "startOffset": 20, "endOffset": 23}, {"referenceID": 9, "context": "Reported Metric AUC [9], [11], Utility [12], Burden [12], Yield [12], WSS [11], Precision [13], Recall [11], F1 [13]", "startOffset": 25, "endOffset": 29}, {"referenceID": 10, "context": "Reported Metric AUC [9], [11], Utility [12], Burden [12], Yield [12], WSS [11], Precision [13], Recall [11], F1 [13]", "startOffset": 39, "endOffset": 43}, {"referenceID": 10, "context": "Reported Metric AUC [9], [11], Utility [12], Burden [12], Yield [12], WSS [11], Precision [13], Recall [11], F1 [13]", "startOffset": 52, "endOffset": 56}, {"referenceID": 10, "context": "Reported Metric AUC [9], [11], Utility [12], Burden [12], Yield [12], WSS [11], Precision [13], Recall [11], F1 [13]", "startOffset": 64, "endOffset": 68}, {"referenceID": 9, "context": "Reported Metric AUC [9], [11], Utility [12], Burden [12], Yield [12], WSS [11], Precision [13], Recall [11], F1 [13]", "startOffset": 74, "endOffset": 78}, {"referenceID": 11, "context": "Reported Metric AUC [9], [11], Utility [12], Burden [12], Yield [12], WSS [11], Precision [13], Recall [11], F1 [13]", "startOffset": 90, "endOffset": 94}, {"referenceID": 9, "context": "Reported Metric AUC [9], [11], Utility [12], Burden [12], Yield [12], WSS [11], Precision [13], Recall [11], F1 [13]", "startOffset": 103, "endOffset": 107}, {"referenceID": 11, "context": "Reported Metric AUC [9], [11], Utility [12], Burden [12], Yield [12], WSS [11], Precision [13], Recall [11], F1 [13]", "startOffset": 112, "endOffset": 116}, {"referenceID": 4, "context": "FOR MORE DETAILS ABOUT ALGORITHMS USED IN SYSTEMATIC REVIEWS PLEASE CONSULT [6], [14], AND FOR METRIC USAGE [6]", "startOffset": 76, "endOffset": 79}, {"referenceID": 12, "context": "FOR MORE DETAILS ABOUT ALGORITHMS USED IN SYSTEMATIC REVIEWS PLEASE CONSULT [6], [14], AND FOR METRIC USAGE [6]", "startOffset": 81, "endOffset": 85}, {"referenceID": 4, "context": "FOR MORE DETAILS ABOUT ALGORITHMS USED IN SYSTEMATIC REVIEWS PLEASE CONSULT [6], [14], AND FOR METRIC USAGE [6]", "startOffset": 108, "endOffset": 111}, {"referenceID": 7, "context": "A large body of past research has focused on automating the abstract screening process [9], [11]\u2013[13], [15], [16].", "startOffset": 87, "endOffset": 90}, {"referenceID": 9, "context": "A large body of past research has focused on automating the abstract screening process [9], [11]\u2013[13], [15], [16].", "startOffset": 92, "endOffset": 96}, {"referenceID": 11, "context": "A large body of past research has focused on automating the abstract screening process [9], [11]\u2013[13], [15], [16].", "startOffset": 97, "endOffset": 101}, {"referenceID": 13, "context": "A large body of past research has focused on automating the abstract screening process [9], [11]\u2013[13], [15], [16].", "startOffset": 103, "endOffset": 107}, {"referenceID": 14, "context": "A large body of past research has focused on automating the abstract screening process [9], [11]\u2013[13], [15], [16].", "startOffset": 109, "endOffset": 113}, {"referenceID": 13, "context": "In terms of feature representation, most of the existing approaches [15], [16] use unigram, bigram, and MeSH (Medical Subject Headings).", "startOffset": 68, "endOffset": 72}, {"referenceID": 14, "context": "In terms of feature representation, most of the existing approaches [15], [16] use unigram, bigram, and MeSH (Medical Subject Headings).", "startOffset": 74, "endOffset": 78}, {"referenceID": 10, "context": "An alternative to the MeSH terms is extracting LDA based latent topics from the titles along with the abstracts and using them as features [12].", "startOffset": 139, "endOffset": 143}, {"referenceID": 9, "context": "Other methods [11], [15] utilize external information as features, such as citations and cocitations.", "startOffset": 14, "endOffset": 18}, {"referenceID": 13, "context": "Other methods [11], [15] utilize external information as features, such as citations and cocitations.", "startOffset": 20, "endOffset": 24}, {"referenceID": 7, "context": "In terms of methods, SVM-based learning algorithms are commonly used [9], [13], [15].", "startOffset": 69, "endOffset": 72}, {"referenceID": 11, "context": "In terms of methods, SVM-based learning algorithms are commonly used [9], [13], [15].", "startOffset": 74, "endOffset": 78}, {"referenceID": 13, "context": "In terms of methods, SVM-based learning algorithms are commonly used [9], [13], [15].", "startOffset": 80, "endOffset": 84}, {"referenceID": 12, "context": "According to a recent study [14], 13 different types of algorithms have been proposed in systematic reviews including SVM, Decision Trees, Naive Bayes, k-nearest neighbor, and neural networks.", "startOffset": 28, "endOffset": 32}, {"referenceID": 17, "context": "SVM [19] can learn faster than SVM.", "startOffset": 4, "endOffset": 8}, {"referenceID": 18, "context": "On the other hand, as Transductive learning [20] takes both the labeled and unlabeled citations into account, the corresponding learning algorithm is slower than SVM [19].", "startOffset": 44, "endOffset": 48}, {"referenceID": 17, "context": "On the other hand, as Transductive learning [20] takes both the labeled and unlabeled citations into account, the corresponding learning algorithm is slower than SVM [19].", "startOffset": 166, "endOffset": 170}, {"referenceID": 17, "context": "Data imbalance in supervised classification is a well studied problem [19]\u2013[23].", "startOffset": 70, "endOffset": 74}, {"referenceID": 21, "context": "Data imbalance in supervised classification is a well studied problem [19]\u2013[23].", "startOffset": 75, "endOffset": 79}, {"referenceID": 22, "context": "The first focuses on designing loss functions: KLD [24], Quadratic Mean [25], Cost sensitive", "startOffset": 51, "endOffset": 55}, {"referenceID": 23, "context": "The first focuses on designing loss functions: KLD [24], Quadratic Mean [25], Cost sensitive", "startOffset": 72, "endOffset": 76}, {"referenceID": 24, "context": "classification [26], Mean Average Precision [27], Random Forest [28] with meta-cost, and AUC [19].", "startOffset": 15, "endOffset": 19}, {"referenceID": 25, "context": "classification [26], Mean Average Precision [27], Random Forest [28] with meta-cost, and AUC [19].", "startOffset": 44, "endOffset": 48}, {"referenceID": 26, "context": "classification [26], Mean Average Precision [27], Random Forest [28] with meta-cost, and AUC [19].", "startOffset": 64, "endOffset": 68}, {"referenceID": 17, "context": "classification [26], Mean Average Precision [27], Random Forest [28] with meta-cost, and AUC [19].", "startOffset": 93, "endOffset": 97}, {"referenceID": 27, "context": "The example of such methods are Borderline-SMOTE [29], Safe-levelSMOTE [30], and oversampling of the minority class along with undersampling the majority class.", "startOffset": 49, "endOffset": 53}, {"referenceID": 28, "context": "The example of such methods are Borderline-SMOTE [29], Safe-levelSMOTE [30], and oversampling of the minority class along with undersampling the majority class.", "startOffset": 71, "endOffset": 75}, {"referenceID": 29, "context": "The authors in [31]\u2013 [33] use probability calibration techniques.", "startOffset": 15, "endOffset": 19}, {"referenceID": 31, "context": "The authors in [31]\u2013 [33] use probability calibration techniques.", "startOffset": 21, "endOffset": 25}, {"referenceID": 32, "context": "However, BAL does not have any theoretical guarantee compared to online learning [34], [35].", "startOffset": 81, "endOffset": 85}, {"referenceID": 33, "context": "However, BAL does not have any theoretical guarantee compared to online learning [34], [35].", "startOffset": 87, "endOffset": 91}, {"referenceID": 34, "context": "In the uncertainty sampling-based methodologies, a large number of uncertainty metrics have been proposed; examples include entropy [36], smallest-margin [37], least confidence [38], committee disagreement [39], and version space reduction [34], [40].", "startOffset": 132, "endOffset": 136}, {"referenceID": 35, "context": "In the uncertainty sampling-based methodologies, a large number of uncertainty metrics have been proposed; examples include entropy [36], smallest-margin [37], least confidence [38], committee disagreement [39], and version space reduction [34], [40].", "startOffset": 154, "endOffset": 158}, {"referenceID": 36, "context": "In the uncertainty sampling-based methodologies, a large number of uncertainty metrics have been proposed; examples include entropy [36], smallest-margin [37], least confidence [38], committee disagreement [39], and version space reduction [34], [40].", "startOffset": 177, "endOffset": 181}, {"referenceID": 37, "context": "In the uncertainty sampling-based methodologies, a large number of uncertainty metrics have been proposed; examples include entropy [36], smallest-margin [37], least confidence [38], committee disagreement [39], and version space reduction [34], [40].", "startOffset": 206, "endOffset": 210}, {"referenceID": 32, "context": "In the uncertainty sampling-based methodologies, a large number of uncertainty metrics have been proposed; examples include entropy [36], smallest-margin [37], least confidence [38], committee disagreement [39], and version space reduction [34], [40].", "startOffset": 240, "endOffset": 244}, {"referenceID": 38, "context": "In the uncertainty sampling-based methodologies, a large number of uncertainty metrics have been proposed; examples include entropy [36], smallest-margin [37], least confidence [38], committee disagreement [39], and version space reduction [34], [40].", "startOffset": 246, "endOffset": 250}, {"referenceID": 10, "context": "Using \u201cmost uncertain\u201d samples based on these metrics improve the quality of the classifier to find the best separating hyperplane, and thus to improve its accuracy in classifying new instances [12].", "startOffset": 194, "endOffset": 198}, {"referenceID": 39, "context": "On the other hand, certainty based methods have also been shown to be effective to carry out active learning on imbalanced data sets, as demonstrated in [41].", "startOffset": 153, "endOffset": 157}, {"referenceID": 40, "context": "A very similar review system that is popular among law firms is Technology assisted Linear Review (TAR) [42]\u2013[46].", "startOffset": 104, "endOffset": 108}, {"referenceID": 44, "context": "A very similar review system that is popular among law firms is Technology assisted Linear Review (TAR) [42]\u2013[46].", "startOffset": 109, "endOffset": 113}, {"referenceID": 46, "context": "For Word2Vec [48], we train the model on the entire set of citations (abstracts and titles) available in an existing systematic review platform.", "startOffset": 13, "endOffset": 17}, {"referenceID": 47, "context": "We use Gensim [49] package with the following parameters: the number of context words as 5, the min word count as 15 and the number of dimensions in the latent space as 500.", "startOffset": 14, "endOffset": 18}, {"referenceID": 17, "context": "On the other hand, SVM is an implementation of the Support Vector Machine (SVM) formulation for optimizing multivariate performance measures [19].", "startOffset": 141, "endOffset": 145}, {"referenceID": 48, "context": "It exploits the alternative structural formulation of the SVM optimization problem for conventional binary classification with error rate [50].", "startOffset": 138, "endOffset": 142}, {"referenceID": 17, "context": "Furthermore, we follow the recommendation for error loss function from [19] to set the cost parameter for SVM :", "startOffset": 71, "endOffset": 75}, {"referenceID": 14, "context": "Among the 61 reviews, 15 reviews are publicly available from [16] and the rest of the 46 reviews are collected from a deployed platform for producing systematic reviews.", "startOffset": 61, "endOffset": 65}, {"referenceID": 4, "context": "To be self contained, we reproduce the metric table from [6].", "startOffset": 57, "endOffset": 60}, {"referenceID": 49, "context": "So, we model the problem similar to [51]:", "startOffset": 36, "endOffset": 40}, {"referenceID": 10, "context": "Hence, an active learning approach has the potential to achieve better results [12].", "startOffset": 79, "endOffset": 83}, {"referenceID": 16, "context": "We use \u03b2 = 19 in our experimental evaluations following the suggestion from [18].", "startOffset": 76, "endOffset": 80}], "year": 2016, "abstractText": "A major task in systematic reviews is abstract screening, i.e., excluding, often hundreds or thousand of, irrelevant citations returned from a database search based on titles and abstracts. Thus, a systematic review platform that can automate the abstract screening process is of huge importance. Several methods have been proposed for this task. However, it is very hard to clearly understand the applicability of these methods in a systematic review platform because of the following challenges: (1) the use of non-overlapping metrics for the evaluation of the proposed methods, (2) usage of features that are very hard to collect, (3) using a small set of reviews for the evaluation, and (4) no solid statistical testing or equivalence grouping of the methods. In this paper, we use feature representation that can be extracted per citation. We evaluate SVM based methods (commonly used) on a large set of reviews (61) and metrics (11) to provide equivalence grouping of methods based on a solid statistical test. Our analysis also includes a strong variability of the metrics using 500x2 cross validation. While some methods shine for different metrics and for different datasets, there is no single method that dominates the pack. Furthermore, we observe that in some cases relevant (included) citations can be found after screening only 15-20% of them via a certainty based sampling. A few included citations present outlying characteristics and can only be found after a very large number of screening steps. Finally, we present an ensemble algorithm for producing a 5star rating of citations based on their relevance. Such algorithm combines the best methods from our evaluation and through its 5-star rating outputs a more easy-to-consume prediction.", "creator": "gnuplot 5.0 patchlevel 1"}}}