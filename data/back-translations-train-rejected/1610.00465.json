{"id": "1610.00465", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Oct-2016", "title": "Can Evolutionary Sampling Improve Bagged Ensembles?", "abstract": "Perturb and Combine (P&amp;C) group of methods generate multiple versions of the predictor by perturbing the training set or construction and then combining them into a single predictor (Breiman, 1996b). The motive is to improve the accuracy in unstable classification and regression methods. One of the most well known method in this group is Bagging. Arcing or Adaptive Resampling and Combining methods like AdaBoost are smarter variants of P&amp;C methods. In this extended abstract, we lay the groundwork for a new family of methods under the P&amp;C umbrella, known as Evolutionary Sampling (ES). We employ Evolutionary algorithms to suggest smarter sampling in both the feature space (sub-spaces) as well as training samples. We discuss multiple fitness functions to assess ensembles and empirically compare our performance against randomized sampling of training data and feature sub-spaces.", "histories": [["v1", "Mon, 3 Oct 2016 09:53:06 GMT  (38kb)", "http://arxiv.org/abs/1610.00465v1", "3 pages, 1 table, Data Efficient Machine Learning Workshop (DEML'16), ICML"]], "COMMENTS": "3 pages, 1 table, Data Efficient Machine Learning Workshop (DEML'16), ICML", "reviews": [], "SUBJECTS": "cs.LG cs.AI", "authors": ["harsh nisar", "bhanu pratap singh rawat"], "accepted": false, "id": "1610.00465"}, "pdf": {"name": "1610.00465.pdf", "metadata": {"source": "META", "title": "Can Evolutionary Sampling Improve Bagged Ensembles?", "authors": ["Harsh Nisar", "Bhanu Pratap Singh"], "emails": ["NISAR.HARSH@GMAIL.COM", "BHANUPRATAP.MNIT@GMAIL.COM"], "sections": [{"heading": null, "text": "ar Xiv: 161 0.00 465v 1 [cs.L G] 3O ct2 016"}, {"heading": "1. Introduction", "text": "There has been remarkable work in understanding the theoretical foundations of boat band aggregation and what makes it such a powerful method (Domingos, 1997; Buchlmann & Yu, 2002).In traditional bagging, each training example is sampled with replacement and probability 1N. Adap-tive resampling and combining (arcing) techniques that modify the probability of each training example based on heuristics have also been developed and widely used (Freund et al., 1996; Breiman, 1999b).Random subspace methods, also known as attribute bagging, refer to the creation of ensembles of predictors based on randomly selected subsets of overall characteristics, that is, predictions of the 33rd International Conference on Machine Learning, New York, NY, Sub."}, {"heading": "2. Algorithm", "text": "Evolutionary calculation techniques develop a population of solution variables (bootstrapped training sets in our case) to optimize toward a specific criterion; the fittest offshoot across all generations is considered the optimal solution; in Evolutionary Sampling (ES), we followed a standard genetic algorithm; first, a population of multiple ensembles is randomly generated multiple times from the training data; each ensemble (henceforth referred to as an individual) in a generation is evaluated based on a fitness function; Fit individuals are selected for the next generation; then crossover is applied to a fixed percentage of individuals, with two individuals exchanging their predictors; then a fixed percentage of individuals not affected by crossover is subjected to a random mutation; randomly selected member records from the selected person have deleted, replaced, or inserted some of their rows / functions."}, {"heading": "3. Experiment", "text": "We conduct experiments on two variants of sampling: subsampling and sub-spacing. Sub-sampling works on sampling examples, while sub-spacing works on generating multiple feature sets. We conduct our experiments on 4 benchmark datasets [see Table 2]. We compare the mean angular error of the first-generation individual (FI) with the Hall of Fame (best individual) after 30 generations. We assume that the first-generation individual is representative of an ensemble that randomly pricks its rows or features as in traditional bagging. We try to analyze whether IT is able to develop better ensembles based on random samples. We consistently use an untrimmed Decision Tree regressor with a maximum depth that is arbitrarily set at 5."}, {"heading": "4. Results and conclusion", "text": "A 50% win ratio would indicate that the performance of the ensemble after performing ES is better than its random counterpart only half as long. The average error rate between the two methods is the same. If the p-value is less than a threshold, then we discard the null hypothesis of equal averages. FEMPO and FEGT are equally better than their random counterparts. Although the win rates are lower in many cases, it could be that the algorithm is initialized with an optimal combination and sampling. FEMPO and FEGT are equally better than their random counterparts."}], "references": [{"title": "Bias, variance, and arcing classifiers", "author": ["Breiman", "Leo"], "venue": "1996b. Breiman, Leo. Out-of-bag estimation", "citeRegEx": "Breiman and Leo.,? \\Q1996\\E", "shortCiteRegEx": "Breiman and Leo.", "year": 1996}, {"title": "Pasting small votes for classification in large", "author": ["Citeseer", "1996c. Breiman", "Leo"], "venue": null, "citeRegEx": "Citeseer et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Citeseer et al\\.", "year": 1996}, {"title": "Using adaptive bagging to debias regressions", "author": ["Breiman", "Leo"], "venue": "Technical report, Technical Report 547, Statistics Dept. UCB,", "citeRegEx": "Breiman and Leo.,? \\Q1999\\E", "shortCiteRegEx": "Breiman and Leo.", "year": 1999}, {"title": "Analyzing bagging", "author": ["B\u00fcchlmann", "Peter", "Yu", "Bin"], "venue": "Annals of Statistics, pp", "citeRegEx": "B\u00fcchlmann et al\\.,? \\Q2002\\E", "shortCiteRegEx": "B\u00fcchlmann et al\\.", "year": 2002}, {"title": "Why does bagging work? a bayesian account and its implications", "author": ["Domingos", "Pedro M"], "venue": "In KDD,", "citeRegEx": "Domingos and M.,? \\Q1997\\E", "shortCiteRegEx": "Domingos and M.", "year": 1997}, {"title": "DEAP: Evolutionary algorithms made easy", "author": ["Fortin", "F\u00e9lix-Antoine", "De Rainville", "Fran\u00e7ois-Michel", "Gardner", "Marc-Andr\u00e9", "Parizeau", "Marc", "Gagn\u00e9", "Christian"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Fortin et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Fortin et al\\.", "year": 2012}, {"title": "Experiments with a new boosting algorithm", "author": ["Freund", "Yoav", "Schapire", "Robert E"], "venue": "In ICML,", "citeRegEx": "Freund et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Freund et al\\.", "year": 1996}, {"title": "Ensemble learning for free with evolutionary algorithms", "author": ["Gagn\u00e9", "Christian", "Sebag", "Michele", "Schoenauer", "Marc", "Tomassini", "Marco"], "venue": "In Proceedings of the 9th annual conference on Genetic and evolutionary computation,", "citeRegEx": "Gagn\u00e9 et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Gagn\u00e9 et al\\.", "year": 2007}, {"title": "The random subspace method for constructing decision forests", "author": ["Ho", "Tin Kam"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on,", "citeRegEx": "Ho and Kam.,? \\Q1998\\E", "shortCiteRegEx": "Ho and Kam.", "year": 1998}, {"title": "Measures of diversity in classifier ensembles and their relationship with the ensemble accuracy", "author": ["Kuncheva", "Ludmila I", "Whitaker", "Christopher J"], "venue": "Machine learning,", "citeRegEx": "Kuncheva et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Kuncheva et al\\.", "year": 2003}, {"title": "Bagging by design (on the suboptimality of bagging)", "author": ["Papakonstantinou", "Periklis A", "Xu", "Jia", "Cao", "Zhu"], "venue": "In AAAI, pp. 2041\u20132047,", "citeRegEx": "Papakonstantinou et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Papakonstantinou et al\\.", "year": 2014}, {"title": "An analysis of diversity measures", "author": ["Tang", "E Ke", "Suganthan", "Ponnuthurai N", "Yao", "Xin"], "venue": "Machine Learning,", "citeRegEx": "Tang et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Tang et al\\.", "year": 2006}], "referenceMentions": [{"referenceID": 6, "context": "Adaptive Resampling and Combining (Arcing) techniques which modify the probability of each training example being sampled based on heuristics have also been developed and widely used (Freund et al., 1996; Breiman, 1999b).", "startOffset": 183, "endOffset": 220}, {"referenceID": 6, "context": "Error based resampling algorithms which try to set the train-set error to zero (Freund et al., 1996), designed bagged ensembles with minimal intersection (Papakonstantinou et al.", "startOffset": 79, "endOffset": 100}, {"referenceID": 10, "context": ", 1996), designed bagged ensembles with minimal intersection (Papakonstantinou et al., 2014), diversity and uncorrelated errors (Kuncheva & Whitaker, 2003; Tang et al.", "startOffset": 61, "endOffset": 92}, {"referenceID": 11, "context": ", 2014), diversity and uncorrelated errors (Kuncheva & Whitaker, 2003; Tang et al., 2006), importance sampling (Breiman, 1999a) etc.", "startOffset": 43, "endOffset": 89}, {"referenceID": 7, "context": "Evolutionary computation has been used for selection of different predictors to be part of an ensemble (Gagn\u00e9 et al., 2007) and also for the selection of the most suitable machine learning pipeline for a classification problem (Olson et al.", "startOffset": 103, "endOffset": 123}, {"referenceID": 5, "context": "We\u2019ve used the Python package DEAP (Fortin et al., 2012) to implement ES.", "startOffset": 35, "endOffset": 56}], "year": 2016, "abstractText": "Perturb and Combine (P&C) group of methods generate multiple versions of the predictor by perturbing the training set or construction and then combining them into a single predictor (Breiman, 1996b). The motive is to improve the accuracy in unstable classification and regression methods. One of the most well known method in this group is Bagging. Arcing or Adaptive Resampling and Combining methods like AdaBoost are smarter variants of P&C methods. In this extended abstract, we lay the groundwork for a new family of methods under the P&C umbrella, known as Evolutionary Sampling (ES). We employ Evolutionary algorithms to suggest smarter sampling in both the feature space (sub-spaces) as well as training samples. We discuss multiple fitness functions to assess ensembles and empirically compare our performance against randomized sampling of training data and feature subspaces.", "creator": "LaTeX with hyperref package"}}}