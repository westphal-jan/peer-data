{"id": "1610.00842", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Oct-2016", "title": "Chinese Event Extraction Using DeepNeural Network with Word Embedding", "abstract": "A lot of prior work on event extraction has exploited a variety of features to represent events. Such methods have several drawbacks: 1) the features are often specific for a particular domain and do not generalize well; 2) the features are derived from various linguistic analyses and are error-prone; and 3) some features may be expensive and require domain expert. In this paper, we develop a Chinese event extraction system that uses word embedding vectors to represent language, and deep neural networks to learn the abstract feature representation in order to greatly reduce the effort of feature engineering. In addition, in this framework, we leverage large amount of unlabeled data, which can address the problem of limited labeled corpus for this task. Our experiments show that our proposed method performs better compared to the system using rich language features, and using unlabeled data benefits the word embeddings. This study suggests the potential of DNN and word embedding for the event extraction task.", "histories": [["v1", "Tue, 4 Oct 2016 04:56:23 GMT  (90kb,D)", "http://arxiv.org/abs/1610.00842v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["yandi xia", "yang liu"], "accepted": false, "id": "1610.00842"}, "pdf": {"name": "1610.00842.pdf", "metadata": {"source": "CRF", "title": "Chinese Event Extraction Using Deep Neural Network with Word Embedding", "authors": ["Yandi Xia"], "emails": ["yandixia@hlt.utdallas.edu", "yangl@hlt.utdallas.edu"], "sections": [{"heading": "1 Introduction", "text": "It is a complicated task, which also includes many subtasks. However, in this paper we focus on trigger identification on the KIMO website. It is often the first step of an event extraction system. It identifies the words that most explicitly indicate the occurrence of events. In this sentence, for example, the acquisition of KIMO websites is announced. \"Acquisition\" is an event that triggers one of the subtypes of BUSINESS events, and it triggers one of the subtypes of events - merge-org event.There are some trends in event extraction research in recent years. First, much previous work has focused on the exploitation of rich linguistic features such as syntax, part-of-speech (POS), named entities, etc."}, {"heading": "2 Event Trigger Identification", "text": "In the following, the two methods we use to identify event triggers are presented."}, {"heading": "2.1 Baseline", "text": "Following the work of (Chen and Ji, 2009; Chen and NG, 2012), we are building the feature-based base system. As observed in (Chen and Ji, 2009), there is a significant proportion of segmentation errors due to the low performance of the Chinese word segmentation tool and the ambiguity in human annotations. Therefore, we model it as a sequence labeling task and use the BIO encoding method (each character starts either inside or outside a trigger word). As for the features, both works have done a lot in the feature analysis, so we adopt most of their features listed below: \u2022 Lexic features: current character; the characters surrounding it; current POS; and the POS that surrounds it; the combination of the current character and its POS. \u2022 Syntactic features: Depth of the current character in the parse tree; path from the current node to the root; the phrase structure that we use from the parent node; the current Xraphrase structure; and the current parental node type."}, {"heading": "2.2 DNN Model", "text": "We followed the work of (Collobert et al., 2011) and designed a similar DNN architecture as in Figure 1. In view of the word segmentation problem in Chinese, we also choose the window-based character stream as input. Here, we model the input character as its index in the character dictionary. The first level is a lookup table whose entries are word embedding vectors. We then bundle these selected vectors and pass them to the hidden layers. In the hidden layers, we use non-linear tanh as an activation function. At the top of the structure, we set Softmax to output the probabilities of the character as part of a trigger. Note in this method that we do not use linguistically motivated features. Input in this DNN is only word embedding vector.All weights in the DNN, including the word embedding of vectors, are automatically trained in the propagation process using the algorithm."}, {"heading": "2.3 Using Unlabeled Data", "text": "Unlabeled data contains a lot of abstract syntax and semantic information, which can be very useful for NLP tasks. To take advantage of unlabeled data (just Chinese sentences, no event labels), we first use the RNN-based word2vec toolkit, from which we build the initial word vector dictionary as a pre-training. These vectors will then act like part of the DNN weights and change their values in the monitored learning progress through backpropagation."}, {"heading": "3 Experiments", "text": "The corpus we use is ACE 2005 Chinese Corpus. There are 633 documents in the corpus. We randomly select 66 documents as test data and 567 documents as training data, which are similar to (Chen and Ji, 2009). For the performance metric, we use precision, recall and F1 score. If the offset and word length of the identified character piece matches exactly the gold value, we consider that the corresponding trigger is correctly identified. The unlabeled data we use comes from (Graff and Chen, 2005). It contains 2,466,840 Chinese Newswire documents, totaling 3.9 GB. We use 100K documents from them. Table 1 shows the trigger identification results for various methods. For the baseline system with the ME classifier, we show two results. We use the named entities derived from the Stanford CoreNLP tool, and the other floor labels."}, {"heading": "4 Conclusions and Future Work", "text": "In this paper, we used word embedding to represent Chinese characters, and our results in the task of identifying event triggers show that this represents a better representation than language-specific characteristics of humans. We also show that the combination of word embedding and DNN exceeds the classifier, which is based on a large number of linguistic characteristics, and that this framework can effectively improve the performance of the system through unlabeled data. This is the first study to look at deep learning and word embedding for Chinese event extraction. In our current work, we use a relatively small character window as DNN input, and for future work, we plan to find a way to model longer contexts in DNN for event extraction. In addition, we will use CNN and RNN architecture for this task."}, {"heading": "Acknowledgments", "text": "It is not the first time that the EU Commission has taken such a step."}], "references": [{"title": "The stages of event extraction", "author": ["David Ahn"], "venue": "In Proceedings of the Workshop on Annotating and Reasoning about Time and Events,", "citeRegEx": "Ahn.,? \\Q2006\\E", "shortCiteRegEx": "Ahn.", "year": 2006}, {"title": "Event extraction for balkan languages", "author": ["H Ali"], "venue": "EACL", "citeRegEx": "Ali.,? \\Q2014\\E", "shortCiteRegEx": "Ali.", "year": 2014}, {"title": "Theano: new features and speed improvements", "author": ["Pascal Lamblin", "Razvan Pascanu", "James Bergstra", "Ian J. Goodfellow", "Arnaud Bergeron", "Nicolas Bouchard", "Yoshua Bengio"], "venue": null, "citeRegEx": "Bastien et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Bastien et al\\.", "year": 2012}, {"title": "Language specific issue and feature exploration in chinese event extraction", "author": ["Chen", "Ji2009] Zheng Chen", "Heng Ji"], "venue": "In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter", "citeRegEx": "Chen et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2009}, {"title": "Joint modeling for chinese event extraction with rich linguistic features", "author": ["Chen", "NG2012] Chen Chen", "V Incent NG"], "venue": "COLING. Citeseer", "citeRegEx": "Chen et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2012}, {"title": "Natural language processing (almost) from scratch", "author": ["Jason Weston", "L\u00e9on Bottou", "Michael Karlen", "Koray Kavukcuoglu", "Pavel Kuksa"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Collobert et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Collobert et al\\.", "year": 2011}, {"title": "Bootstrapped training of event extraction classifiers", "author": ["Huang", "Riloff2012] Ruihong Huang", "Ellen Riloff"], "venue": "In Proceedings of the 13th Conference of the European Chapter of the Association", "citeRegEx": "Huang et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Huang et al\\.", "year": 2012}, {"title": "Improving text normalization via unsupervised model and discriminative reranking", "author": ["Li", "Liu2014] Chen Li", "Yang Liu"], "venue": "In Proceedings of ACL", "citeRegEx": "Li et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Li et al\\.", "year": 2014}, {"title": "Improving named entity recognition in tweets via detecting non-standard words", "author": ["Li", "Liu2015a] Chen Li", "Yang Liu"], "venue": "In Proceedings of ACL", "citeRegEx": "Li et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Li et al\\.", "year": 2015}, {"title": "2015b. Joint pos tagging and text normalization for informal text", "author": ["Li", "Liu2015b] Chen Li", "Yang Liu"], "venue": "In Proceedings of IJCAI", "citeRegEx": "Li et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Li et al\\.", "year": 2015}, {"title": "Employing event inference to improve semi-supervised chinese event extraction", "author": ["Li et al.2014] Peifeng Li", "Qiaoming Zhu", "Guodong Zhou"], "venue": "Proceedings of COLING", "citeRegEx": "Li et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Li et al\\.", "year": 2014}, {"title": "Using external resources and joint learning for bigram weighting in ilp-based multidocument summarization", "author": ["Chen Li", "Yang Liu", "Lin Zhao"], "venue": "In Proceedings of NAACL-HLT,", "citeRegEx": "Li et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Li et al\\.", "year": 2015}, {"title": "Filtered ranking for bootstrapping in event extraction", "author": ["Liao", "Grishman2010] Shasha Liao", "Ralph Grishman"], "venue": "In Proceedings of the 23rd International Conference on Computational Linguistics,", "citeRegEx": "Liao et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Liao et al\\.", "year": 2010}, {"title": "Deep learning for character-based information extraction", "author": ["Qi et al.2014] Yanjun Qi", "Sujatha G Das", "Ronan Collobert", "Jason Weston"], "venue": "In Advances in Information Retrieval,", "citeRegEx": "Qi et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Qi et al\\.", "year": 2014}, {"title": "Unsupervised techniques for extracting and clustering complex events in news", "author": ["Rusu et al.2014] Delia Rusu", "James Hodson", "Anthony Kimball"], "venue": "ACL", "citeRegEx": "Rusu et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Rusu et al\\.", "year": 2014}, {"title": "Deep learning for nlp (without magic)", "author": ["Yoshua Bengio", "Christopher D Manning"], "venue": "In Tutorial Abstracts of ACL", "citeRegEx": "Socher et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Socher et al\\.", "year": 2012}, {"title": "Adding semantic roles to the chinese treebank", "author": ["Xue", "Palmer2009] Nianwen Xue", "Martha Palmer"], "venue": "Natural Language Engineering,", "citeRegEx": "Xue et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Xue et al\\.", "year": 2009}, {"title": "Deep learning for chinese word segmentation and pos tagging", "author": ["Zheng et al.2013] Xiaoqing Zheng", "Hanyang Chen", "Tianyu Xu"], "venue": "In EMNLP,", "citeRegEx": "Zheng et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Zheng et al\\.", "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "In ACE, event extraction includes four sub-tasks (Ahn, 2006; Grishman et al., 2005): event trigger identification, trigger type classification, argument identification, and argument role classification.", "startOffset": 49, "endOffset": 83}, {"referenceID": 0, "context": "In English corpus, the earliest work on ACE corpus (Ahn, 2006) also designed a lot of features for this task and set the baseline of English event extraction.", "startOffset": 51, "endOffset": 62}, {"referenceID": 1, "context": "(Liao and Grishman, 2010; Ali, 2014; Li et al., 2014), unsupervised learning (Rusu et al.", "startOffset": 0, "endOffset": 53}, {"referenceID": 7, "context": "(Liao and Grishman, 2010; Ali, 2014; Li et al., 2014), unsupervised learning (Rusu et al.", "startOffset": 0, "endOffset": 53}, {"referenceID": 14, "context": ", 2014), unsupervised learning (Rusu et al., 2014), and distantly supervised learning (Reschke et al.", "startOffset": 31, "endOffset": 50}, {"referenceID": 5, "context": "After Collobert et al. (2011) and Socher et al.", "startOffset": 6, "endOffset": 30}, {"referenceID": 5, "context": "After Collobert et al. (2011) and Socher et al. (2012) brought up a unified deep structure for NLP tasks, much work using this combination has", "startOffset": 6, "endOffset": 55}, {"referenceID": 5, "context": "Collobert et al. (2011) showed great performance in tasks such as part-ofspeech-tagging, chunking, named entity recognition, and semantic role labeling with one", "startOffset": 0, "endOffset": 24}, {"referenceID": 13, "context": "Qi et al. (2014) and Zheng et al.", "startOffset": 0, "endOffset": 17}, {"referenceID": 13, "context": "Qi et al. (2014) and Zheng et al. (2013) adopted this structure for Chinese NLP tasks, and beat the state-of-the-art performance in word segmen-", "startOffset": 0, "endOffset": 41}, {"referenceID": 7, "context": "In addition, Li et al. (2015) applied word embedding on two large corpus, one is a set of news articles and the other is their corresponding summaries.", "startOffset": 13, "endOffset": 30}, {"referenceID": 5, "context": "We followed the work of (Collobert et al., 2011) and designed a similar DNN architecture, as shown in Figure 1.", "startOffset": 24, "endOffset": 48}, {"referenceID": 2, "context": "The DNN tool we use is python based software Theano (Bastien et al., 2012).", "startOffset": 52, "endOffset": 74}], "year": 2016, "abstractText": "A lot of prior work on event extraction has exploited a variety of features to represent events. Such methods have several drawbacks: 1) the features are often specific for a particular domain and do not generalize well; 2) the features are derived from various linguistic analyses and are error-prone; and 3) some features may be expensive and require domain expert. In this paper, we develop a Chinese event extraction system that uses word embedding vectors to represent language, and deep neural networks to learn the abstract feature representation in order to greatly reduce the effort of feature engineering. In addition, in this framework, we leverage large amount of unlabeled data, which can address the problem of limited labeled corpus for this task. Our experiments show that our proposed method performs better compared to the system using rich language features, and using unlabeled data benefits the word embeddings. This study suggests the potential of DNN and word embedding for the event extraction task.", "creator": "LaTeX with hyperref package"}}}