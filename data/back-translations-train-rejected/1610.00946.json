{"id": "1610.00946", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Oct-2016", "title": "Micro-Data Learning: The Other End of the Spectrum", "abstract": "Many fields are now snowed under with an avalanche of data, which raises considerable challenges for computer scientists. Meanwhile, robotics (among other fields) can often only use a few dozen data points because acquiring them involves a process that is expensive or time-consuming. How can an algorithm learn with only a few data points?", "histories": [["v1", "Tue, 4 Oct 2016 12:29:05 GMT  (324kb)", "http://arxiv.org/abs/1610.00946v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["jean-baptiste mouret"], "accepted": false, "id": "1610.00946"}, "pdf": {"name": "1610.00946.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": [], "sections": [{"heading": null, "text": "ERCIM NEWS 107 October 201618"}, {"heading": "Special Theme: Machine Learning", "text": "In this context, it should be noted that the case concerns a case where a person residing in another country is not a person but a person residing in another country, but a person residing in another country."}, {"heading": "Micro-Data Learning:", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "The Other End of the Spectrum", "text": "By Jean-Baptiste Mouret (Inria) Many fields are now littered with an avalanche of data that poses significant challenges for computer scientists. Meanwhile, robotics (among other fields) can often only use a few dozen data points because it involves a process that is costly or time-consuming. How can an algorithm learn with only a few data points? Amount of data. For example, DeepMind's AlphaGo player uses a record of 38 millionaire positions, and the deep amplification that experiments from the same team use to learn the equivalent of 38 days to play Atari 2600 video games. Robotics is at the opposite end of the spectrum: it is difficult to do more than a few dozen studies. Learning with such a small amount of data is what we call \"microdata learning.\""}, {"heading": "Please contact:", "text": "Jean-Baptiste Mouret Inria, France jean-baptiste.mouret @ inria.frAfter a history spanning five decades, general artificial intelligence is still out of reach. Machine learning has common roots with AI research, but focuses on more achievable goals and has achieved enormous success in many fields of application. Likewise, a universal quantum computer is still far ahead in the distant future: the criterion for this machine is the ability to simulate an arbitrary closed quantum system. Nevertheless, the use of quantum information processing is spreading: two notable examples are quantum distribution systems and quantum random generators. Recently, there has been an increase in interest in the intersection of machine learning and quantum information processing. The combination of ideas from these two fields leads to enormous benefits for both. We are working on several topics in this area between ICFO-The Institute of Photonic Sciences, the Autonomous University of Barcelona, and the University of Basque Country, with the highest algorithms of the University of Spain."}, {"heading": "Making Learning Physical: Machine Intelligence", "text": "and Quantum Resources by Peter Wittek (ICFO-The Institute of Photonic Sciences and University of Bor\u00e5s) It is not just machine learning that is advancing rapidly: Quantum information processing has undergone several breakthroughs in recent years. Theoretically, quantum protocols can provide an exponential acceleration of certain learning algorithms, but even contemporary implementations are showing remarkable results - this new field is called quantum machine learning."}], "references": [{"title": "Taking the human out of the loop: A review of bayesian optimization", "author": ["B. Shahriari"], "venue": "Proc. of the IEEE,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2016}, {"title": "Gaussian processes for data-efficient learning in robotics and control", "author": ["M.P. Deisenroth", "D. Fox", "C.E. Rasmussen"], "venue": "IEEE Trans. on Pattern Analysis and Machine Intelligence,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2016}], "referenceMentions": [{"referenceID": 0, "context": "Bayesian optimisation [1] is such a data-efficient algorithm that has recently attracted a lot of interest in the machine learning community.", "startOffset": 22, "endOffset": 25}, {"referenceID": 1, "context": "This is a very effective approach for learning control strategies in robotics; for example, the Pilco algorithm can learn to balance a non-actuated pole on an actuated moving cart in 15-20 seconds (about 3-5 trials) [2].", "startOffset": 216, "endOffset": 219}, {"referenceID": 0, "context": "If the robot is damaged, the learning algorithm, which is a derivative of Bayesian optimisation [1], exploits this prior knowledge to choose the best trials.", "startOffset": 96, "endOffset": 99}, {"referenceID": 1, "context": "The subsequent challenge is to exploit more knowledge from the trials [2] and select the next trials while taking the context into account (e.", "startOffset": 70, "endOffset": 73}, {"referenceID": 0, "context": "eu References: [1] B.", "startOffset": 15, "endOffset": 18}, {"referenceID": 1, "context": "[2] M.", "startOffset": 0, "endOffset": 3}], "year": 2016, "abstractText": "Watching a child learn reveals how well humans can learn: a child may only need a few examples of a concept to \u201clearn it\u201d. By contrast, the impressive results achieved with modern machine learning (in particular, by deep learning) are made possible largely by the use of huge datasets. For instance, the ImageNet database used in image recognition contains about 1.2 million labelled examples; DeepMinds's AlphaGo used more than 38 million positions to train their algorithm to play Go; and the same company used more than 38 days of play to train a neural network to play Atari 2600 games, such as Space Invaders or Breakout.", "creator": "Preview"}}}