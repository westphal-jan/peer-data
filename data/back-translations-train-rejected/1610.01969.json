{"id": "1610.01969", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Oct-2016", "title": "DeepDGA: Adversarially-Tuned Domain Generation and Detection", "abstract": "Many malware families utilize domain generation algorithms (DGAs) to establish command and control (C&amp;C) connections. While there are many methods to pseudorandomly generate domains, we focus in this paper on detecting (and generating) domains on a per-domain basis which provides a simple and flexible means to detect known DGA families. Recent machine learning approaches to DGA detection have been successful on fairly simplistic DGAs, many of which produce names of fixed length. However, models trained on limited datasets are somewhat blind to new DGA variants.", "histories": [["v1", "Thu, 6 Oct 2016 17:50:27 GMT  (453kb,D)", "http://arxiv.org/abs/1610.01969v1", null]], "reviews": [], "SUBJECTS": "cs.CR cs.AI", "authors": ["hyrum s", "erson", "jonathan woodbridge", "bobby filar"], "accepted": false, "id": "1610.01969"}, "pdf": {"name": "1610.01969.pdf", "metadata": {"source": "META", "title": "DeepDGA: Adversarially-Tuned Domain Generation and Detection", "authors": ["Hyrum S. Anderson", "Jonathan Woodbridge"], "emails": ["hyrum@endgame.com", "jwoodbridge@endgame.com", "bfilar@endgame.com"], "sections": [{"heading": null, "text": "This year is the highest in the history of the country."}, {"heading": "II. BACKGROUND", "text": "In this section, we first give a brief overview of common DGA algorithms, approaches to machine learning recognition, and then background information on neural network architectures that we use in our neural language model for domain generation."}, {"heading": "A. Domain Generation Algorithms", "text": "Domain generation algorithms are used by many strains of malware for C & C, including ransomware such as Cryptolocker [9], [10] and Cryptowall [11], banking trojans such as Hesperbot [12], and information stewards such as Ramnit [13]. Partly, this paper compares DeepDGA with character-based DGA algorithms reproduced from published literature. Traditional DGA techniques vary in complexity from random approaches to those that attempt to imitate characters or word distributions in real domains. For example, the ramnit DGA generates domain names using a combination of multiplies, divided and modulated starting with a random seed [13]."}, {"heading": "B. DGA detection algorithms", "text": "It's the question of whether it's about a way, in which it's about a way, in which it's about a way, in which it's about a way, how it's about a way, how it's about a way, how it's about a way, how it's about a way, how it's about a way, how it's about a way, how it's about a way, how it's about a way, how it's about a way, how it's about a way, how it's about a way, how it's about a way, how it's about a way, how it's about a way, how it's about a way, how it's about a way, how it's about a way, how it's about a way, and a way, and a way, and a way, and a way, and a way, and a way, and a way, and a way, and a way, and a way, and a way, and a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way,"}, {"heading": "C. Adversarial Examples and Generative Adversarial Networks", "text": "Previous work has shown that many machine learning models, including modern neural network architectures, are susceptible to conflicting examples [2], [1]. In particular, [1] introduced the method of rapid gradient signs to systematically detect conflicting examples by disrupting a known \"good\" sample x by a small amount \u0394x = characters (\u0432 xJ (\u03b8, x, y), where \u03b8 represents the model parameters, and J the cost of classifying x as class y.Separately [7], generative contrarian networks proposed a framework for generating artificial samples taken from the same distribution as the training dataset. Generative contrarian networks include a model pair - a generator and a discriminator - competing in a series of contrary rounds. In the context of our application, the generator learns to generate new artificial domain names, and the detector subsequently learns to distinguish the artificial domains of the generator from the true domain."}, {"heading": "D. Recurrent Neural Network", "text": "The key advantage of RNNs is that they integrate contextual (state) information into their mapping from input to output. That is, the output of a single RNN cell is a function of the input layer and previous RNN activations. Due to the long chains of operations introduced by including self-recurrent connections, the output of a traditional RNN can decrease exponentially over time (or, more rarely, explode catastrophically) the output of RNN cell data into the output quantity of a traditional RNN cell."}, {"heading": "E. Highway Networks", "text": "Highway networks have recently been proposed as a natural extension of gated memory networks such as the LSTM unit into feedback networks [23]. Highway layers allow the training of deep networks by transferring some dimensions of the input directly to the output through the use of gates. Specifically, the output y of a single highway layer is the fundamentally convex combination of raw input x and transformed input g (Wx + b) with a vector parameter t [0, 1] d: y = t \u00b7 g (Wx + b) + (1 \u2212 t) \u00b7 x, with activation function. In addition to learning weights W and bias b, a highway layer also learns the gating parameters during training."}, {"heading": "III. METHOD", "text": "In this section, we describe our neural language architecture and the training mechanism of the DGA. In a first step, we learn to represent valid domain names using an autoencoder architecture shown in Figure 2 (a) and described in detail in Section III-A. Then, we use the encoder (which accepts a domain name and outputs a domain embedding) as a discrimination model, and the decoder (which accepts a domain embedding and outputs a domain name) as a generative model, as shown in Figure 2 (b) and described in detail in Section III-B."}, {"heading": "A. Autoencoder", "text": "In fact, the fact is that most of them are not a mere formation, but a group of people who are able to hide themselves."}, {"heading": "B. Generative Adversarial Network", "text": "It is not only the way in which people in the individual countries of the world in which they move, but also the way in which they move in the world, and the way in which they move in the world, and the way in which they move in the world, in which they move in the world, in which they live, in which they live, in which they live, in which they live, in which they live in the world and in the world, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, they live, in which they live, in which they live, in which they live, in which they live, in which they live, they live, in which they live, in which they live, in which they live, in which they live, they live, in which they live, in which they live, in which they live, in which they"}, {"heading": "IV. EXPERIMENTAL SETUP", "text": "We implement our architecture in Python using Keras [26]. We train the auto encoder on the Alexa Top 1M dataset. We also train the GAN to distinguish the Alexa Top 1M domains from pseudo-domains generated by the first half (encoder) of the auto encoder. We found that only a few contrarian rounds were needed to learn appropriate generator weights when using standard Keras learning rates (Adam optimizer) and batch sizes of 128. Similarly, we use numpy.random.multinomial to determine the output results using the common seed.Although the GAN framework ensures that we are maximally interested in determining the dectorGA's ability to detect. We also train the GAN to distinguish the Alexa Top 1M domains from pseudo-domains generated by the first half (encoder) of the auto encoder. We found that only a few contrary rounds were required to learn appropriate generator weights when using standard keras learning rates (Adam optimizer) and batch sizes of 128."}, {"heading": "V. RESULTS", "text": "The autoencoder was pre-trained for 300 epochs, with each epoch randomly sampling 256K domains from the Alexa Top 1M, and a batch size of 128. Pre-training lasted approximately 14 hours on a single NVIDIA Titan X GPU. Following pre-training, we generated 12,800 samples against the detector in each opposing round. Each round took approximately 7 minutes on the GPU. The results of the training are detailed in the following sub-sections."}, {"heading": "A. Autoencoder results", "text": "Given a domain as input, the autoencoder generates a multinomial distribution over the possible characters (results) from which a domain can be scanned. For example, some domains scanned from the output of the autoencoder (removing the TLD) are not perfectly reconstructed in Table II. The autoencoder does not reconstruct the input due to stochastic scanning of the multinomial distributions to select each domain sign using independent drawings, and insufficient model capacity (e.g. strong model distortions) to express all character combinations of domains in the Alexa 1M tip. However, since we do not actually want to generate domain names in the Alexa 1M tip, but names from the same (or similar) generative distribution, the reconstructions are quite sufficient."}, {"heading": "B. GAN results", "text": "Figure 3 shows Receiver Operating Characteristic (ROC) curves of a random forest classifier after each of four opposing rounds. The classifier is trained on DeepDGA-generated domains as malicious and the Alexa Top 10K as benign. This deterioration is due to the ability to generate domains that create confusion for the classifier. Training on these domains allows us to increase the number of opposing rounds with an apparent asymptote. This deterioration is due to the ability to create confusion."}, {"heading": "C. Hardening a machine learning model", "text": "We show that by supplementing a training set with counterexamples generated by the GAN, a model can be hardened against DGA families that are not observed in the training set. Specifically, we trained the random forest model using a holiday-in-a-family-out strategy, where an entire DGA family is offered for validation while the random forest model is trained on the remaining nine families. Top Alexa 10K are included in the training set, and the next Alexa 10K is included in the holdout set. This base result is compared with a hardened result, where 10K DeepDGA samples are attached to the 9 families plus Alexa training sets. In each case, we report the true positive rate (TPR) with a fixed false positive rate (FPR) of 1%. This usually required different thresholds for baseline and hardened models."}, {"heading": "VI. DISCUSSION", "text": "We have shown that the conflicting examples are shared between both the deep learning detector model - for which they have been explicitly optimized to circumvent them - and a random forest model, demonstrating at a key point of information security in [2], [1] that conflicting examples can be shared between different models. Training a GAN to generate these examples requires considerable skill to prevent common error modes. We have proposed novel history regulation, neural layers (box layer and principal axis box layer), and more frequent auto-encoder pre-training to simplify the generator's learning task. Following our experiments [25], other strategies for training GANs have been proposed, which we will leave to future work. Furthermore, we have shown that augmenting a training set with DeepDGA counterexamples, a random forest classifier against DGA families, hardens the ability to work during the actual training, which was not observed during the actual training."}], "references": [{"title": "Explaining and harnessing adversarial examples", "author": ["I.J. Goodfellow", "J. Shlens", "C. Szegedy"], "venue": "arXiv preprint arXiv:1412.6572, 2014.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2014}, {"title": "Intriguing properties of neural networks", "author": ["C. Szegedy", "W. Zaremba", "I. Sutskever", "J. Bruna", "D. Erhan", "I. Goodfellow", "R. Fergus"], "venue": "arXiv preprint arXiv:1312.6199, 2013.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2013}, {"title": "From throw-away traffic to bots: detecting the rise of DGA-based malware", "author": ["M. Antonakakis", "R. Perdisci", "Y. Nadji", "N. Vasiloglou", "S. Abu-Nimeh", "W. Lee", "D. Dagon"], "venue": "P21st USENIX Security Symposium (USENIX Security 12), pp. 491\u2013506, 2012.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "Detecting algorithmically generated malicious domain names", "author": ["S. Yadav", "A.K.K. Reddy", "A. Reddy", "S. Ranjan"], "venue": "Proc. 10th ACM SIGCOMM conference on Internet measurement, pp. 48\u201361, ACM, 2010.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2010}, {"title": "Detecting algorithmically generated domain-flux attacks with DNS traffic analysis", "author": ["S. Yadav", "A.K.K. Reddy", "A.N. Reddy", "S. Ranjan"], "venue": "Networking, IEEE/ACM Transactions on, vol. 20, no. 5, pp. 1663\u20131677, 2012.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2012}, {"title": "Challenges in experimenting with botnet detection systems", "author": ["A.J. Aviv", "A. Haeberlen"], "venue": "CSET, 2011.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "Generative adversarial nets", "author": ["I. Goodfellow", "J. Pouget-Abadie", "M. Mirza", "B. Xu", "D. Warde-Farley", "S. Ozair", "A. Courville", "Y. Bengio"], "venue": "Advances in Neural Information Processing Systems, pp. 2672\u20132680, 2014.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "Distillation as a defense to adversarial perturbations against deep neural networks", "author": ["N. Papernot", "P. McDaniel", "X. Wu", "S. Jha", "A. Swami"], "venue": "Proceedings of the 37th IEEE Symposium on Security and Privacy, 2015.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2015}, {"title": "Cryptolocker victims to get files back for free", "author": ["M. Ward"], "venue": "BBC News, August, vol. 6, 2014.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Ransomware: Emergence of the cyberextortion menace", "author": ["N. Hampton", "Z.A. Baig"], "venue": "Australian Information Security Management Conference, 2015.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2015}, {"title": "Hesperbot-A new, advanced banking trojan in the wild", "author": ["A. Cherepanov", "R. Lipovsky"], "venue": "2013.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2013}, {"title": "End-to-end analysis of a domain generating algorithm malware family.", "author": ["J. Geffner"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2013}, {"title": "Phoenix: DGAbased botnet tracking and intelligence", "author": ["S. Schiavoni", "F. Maggi", "L. Cavallaro", "S. Zanero"], "venue": "Detection of intrusions and malware, and vulnerability assessment, pp. 192\u2013211, Springer, 2014.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2014}, {"title": "An application of recurrent nets to phone probability estimation", "author": ["A.J. Robinson"], "venue": "Neural Networks, IEEE Transactions on, vol. 5, no. 2, pp. 298\u2013305, 1994.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1994}, {"title": "Recurrent neural network based language model", "author": ["T. Mikolov", "M. Karafi\u00e1t", "L. Burget", "J. Cernock\u1ef3", "S. Khudanpur"], "venue": "INTERSPEECH, vol. 2, p. 3, 2010.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2010}, {"title": "Sequence transduction with recurrent neural networks", "author": ["A. Graves"], "venue": "arXiv preprint arXiv:1211.3711, 2012.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2012}, {"title": "Advances in optimizing recurrent networks", "author": ["Y. Bengio", "N. Boulanger-Lewandowski", "R. Pascanu"], "venue": "Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference on, pp. 8624\u2013 8628, IEEE, 2013.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2013}, {"title": "Long short-term memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural computation, vol. 9, no. 8, pp. 1735\u20131780, 1997.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1997}, {"title": "Learning to forget: Continual prediction with LSTM", "author": ["F.A. Gers", "J. Schmidhuber", "F. Cummins"], "venue": "Neural computation, vol. 12, no. 10, pp. 2451\u20132471, 2000.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2000}, {"title": "Learning precise timing with LSTM recurrent networks", "author": ["F.A. Gers", "N.N. Schraudolph", "J. Schmidhuber"], "venue": "J. Machine Learning Research, vol. 3, pp. 115\u2013143, 2003.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2003}, {"title": "Highway networks", "author": ["R.K. Srivastava", "K. Greff", "J. Schmidhuber"], "venue": "arXiv preprint arXiv:1505.00387, 2015.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2015}, {"title": "Character-aware neural language models", "author": ["Y. Kim", "Y. Jernite", "D. Sontag", "A.M. Rush"], "venue": "arXiv preprint arXiv:1508.06615, 2015.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2015}, {"title": "Improved techniques for training gans", "author": ["T. Salimans", "I. Goodfellow", "W. Zaremba", "V. Cheung", "A. Radford", "X. Chen"], "venue": "arXiv preprint arXiv:1606.03498, 2016.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2016}], "referenceMentions": [{"referenceID": 0, "context": "While this expert-guided process may always exist, we test a key thesis of [1]: adversarial examples1\u2014artificial samples which a machine learning model misidentifies\u2014can be discovered automatically and used to augment a training dataset to harden", "startOffset": 75, "endOffset": 78}, {"referenceID": 1, "context": "1In this paper, we employ a significantly broader meaning of adversarial examples as originally used in [2], [1].", "startOffset": 104, "endOffset": 107}, {"referenceID": 0, "context": "1In this paper, we employ a significantly broader meaning of adversarial examples as originally used in [2], [1].", "startOffset": 109, "endOffset": 112}, {"referenceID": 1, "context": "While this thesis has been confirmed generally [2], [1], we propose a novel framework for generating these adversarial examples using a generative adversarial network for a natural languagebased domain generation algorithm (DGA) detector.", "startOffset": 47, "endOffset": 50}, {"referenceID": 0, "context": "While this thesis has been confirmed generally [2], [1], we propose a novel framework for generating these adversarial examples using a generative adversarial network for a natural languagebased domain generation algorithm (DGA) detector.", "startOffset": 52, "endOffset": 55}, {"referenceID": 2, "context": "Previous works include using a Hidden Markov Model (HMM) framework to model the generating distribution of several DGA families as well as \u201cnormal\u201c domains [3], and making bulk predictions on large sets of domains using clustering as a filtering technique [4], [5].", "startOffset": 156, "endOffset": 159}, {"referenceID": 3, "context": "Previous works include using a Hidden Markov Model (HMM) framework to model the generating distribution of several DGA families as well as \u201cnormal\u201c domains [3], and making bulk predictions on large sets of domains using clustering as a filtering technique [4], [5].", "startOffset": 256, "endOffset": 259}, {"referenceID": 4, "context": "Previous works include using a Hidden Markov Model (HMM) framework to model the generating distribution of several DGA families as well as \u201cnormal\u201c domains [3], and making bulk predictions on large sets of domains using clustering as a filtering technique [4], [5].", "startOffset": 261, "endOffset": 264}, {"referenceID": 5, "context": "Many methods require contextual information separate from the domain name itself [6].", "startOffset": 81, "endOffset": 84}, {"referenceID": 6, "context": "This explicit optimization is done using a DGA language model generator coupled with a DGA detector in a GAN [7].", "startOffset": 109, "endOffset": 112}, {"referenceID": 7, "context": "A similar adversarial approach was previously explored by [8] to generate synthetic samples for malware classification based on the DREBIN Android malware dataset.", "startOffset": 58, "endOffset": 61}, {"referenceID": 8, "context": "Domain generation algorithms are used by many strains of malware for C&C, including ransomware like cryptolocker [9], [10] and cryptowall [11], banking trojans, such as hesperbot [12], and information stealers, such as ramnit [13].", "startOffset": 113, "endOffset": 116}, {"referenceID": 9, "context": "Domain generation algorithms are used by many strains of malware for C&C, including ransomware like cryptolocker [9], [10] and cryptowall [11], banking trojans, such as hesperbot [12], and information stealers, such as ramnit [13].", "startOffset": 138, "endOffset": 142}, {"referenceID": 10, "context": "Domain generation algorithms are used by many strains of malware for C&C, including ransomware like cryptolocker [9], [10] and cryptowall [11], banking trojans, such as hesperbot [12], and information stealers, such as ramnit [13].", "startOffset": 179, "endOffset": 183}, {"referenceID": 11, "context": "On the other hand, suppobox creates domains by concatenating two pseudorandomly chosen English dictionary words [14].", "startOffset": 112, "endOffset": 116}, {"referenceID": 3, "context": "Authors in [4], [5] detect DGAs by using both unigram and bigram statistics of domain clusters.", "startOffset": 11, "endOffset": 14}, {"referenceID": 4, "context": "Authors in [4], [5] detect DGAs by using both unigram and bigram statistics of domain clusters.", "startOffset": 16, "endOffset": 19}, {"referenceID": 2, "context": "Authors in [3] apply a similar clustering process to classify domains with unsuccessful DNS resolutions.", "startOffset": 11, "endOffset": 14}, {"referenceID": 12, "context": "Authors in [15] also present a DGA classifier with the intention of classifying individual domains.", "startOffset": 11, "endOffset": 15}, {"referenceID": 2, "context": "In our experiments, we leverage a random forest classifier trained on features defined in [3], [4], [5], [15].", "startOffset": 90, "endOffset": 93}, {"referenceID": 3, "context": "In our experiments, we leverage a random forest classifier trained on features defined in [3], [4], [5], [15].", "startOffset": 95, "endOffset": 98}, {"referenceID": 4, "context": "In our experiments, we leverage a random forest classifier trained on features defined in [3], [4], [5], [15].", "startOffset": 100, "endOffset": 103}, {"referenceID": 12, "context": "In our experiments, we leverage a random forest classifier trained on features defined in [3], [4], [5], [15].", "startOffset": 105, "endOffset": 109}, {"referenceID": 2, "context": "We do not implement the full system as defined in [3], [4], [5] as it is based on domain clustering and our intent is to classify DGAs on a per-domain basis.", "startOffset": 50, "endOffset": 53}, {"referenceID": 3, "context": "We do not implement the full system as defined in [3], [4], [5] as it is based on domain clustering and our intent is to classify DGAs on a per-domain basis.", "startOffset": 55, "endOffset": 58}, {"referenceID": 4, "context": "We do not implement the full system as defined in [3], [4], [5] as it is based on domain clustering and our intent is to classify DGAs on a per-domain basis.", "startOffset": 60, "endOffset": 63}, {"referenceID": 12, "context": "The full system in [15] is not evaluated as they use contextual features such as IP addresses.", "startOffset": 19, "endOffset": 23}, {"referenceID": 1, "context": "Previous work discovered that many machine learning models, including modern neural network architectures, are vulnerable to adversarial examples[2], [1].", "startOffset": 145, "endOffset": 148}, {"referenceID": 0, "context": "Previous work discovered that many machine learning models, including modern neural network architectures, are vulnerable to adversarial examples[2], [1].", "startOffset": 150, "endOffset": 153}, {"referenceID": 0, "context": "Notably, [1] introduced the fast gradient sign method to systematically discover adversarial examples by perturbing a known \u201cgood\u201d sample x by a small amount \u2206x = sign (\u2207xJ (\u03b8,x, y)), where \u03b8 represents the model parameters, and J is the cost incurred for classifying x as class y.", "startOffset": 9, "endOffset": 12}, {"referenceID": 6, "context": "Separately, [7] proposed generative adversarial networks as a framework for generating artificial samples that are drawn from the same distribution as the training dataset.", "startOffset": 12, "endOffset": 15}, {"referenceID": 13, "context": "In a variety of natural language tasks, recurrent neural networks (RNNs) have been used to capture meaningful temporal relationships among tokens in a sequence [16], [17], [18], [19].", "startOffset": 160, "endOffset": 164}, {"referenceID": 14, "context": "In a variety of natural language tasks, recurrent neural networks (RNNs) have been used to capture meaningful temporal relationships among tokens in a sequence [16], [17], [18], [19].", "startOffset": 166, "endOffset": 170}, {"referenceID": 15, "context": "In a variety of natural language tasks, recurrent neural networks (RNNs) have been used to capture meaningful temporal relationships among tokens in a sequence [16], [17], [18], [19].", "startOffset": 172, "endOffset": 176}, {"referenceID": 16, "context": "In a variety of natural language tasks, recurrent neural networks (RNNs) have been used to capture meaningful temporal relationships among tokens in a sequence [16], [17], [18], [19].", "startOffset": 178, "endOffset": 182}, {"referenceID": 17, "context": "The problem of vanishing gradients is a key motivation behind the application of the Long Short-Term Memory (LSTM) cell [20], [21], [22], which consists of a state that can be read, written or reset via a set of programmable gates.", "startOffset": 120, "endOffset": 124}, {"referenceID": 18, "context": "The problem of vanishing gradients is a key motivation behind the application of the Long Short-Term Memory (LSTM) cell [20], [21], [22], which consists of a state that can be read, written or reset via a set of programmable gates.", "startOffset": 126, "endOffset": 130}, {"referenceID": 19, "context": "The problem of vanishing gradients is a key motivation behind the application of the Long Short-Term Memory (LSTM) cell [20], [21], [22], which consists of a state that can be read, written or reset via a set of programmable gates.", "startOffset": 132, "endOffset": 136}, {"referenceID": 20, "context": "Highway networks were recently proposed as a natural extension of gated memory networks like the LSTM unit to feedforward networks [23].", "startOffset": 131, "endOffset": 135}, {"referenceID": 0, "context": "Concretely, the output y of a single highway layers is the elementwise convex combination of the raw input x and the transformed input g(Wx + b) with a vector parameter t \u2208 [0, 1]:", "startOffset": 173, "endOffset": 179}, {"referenceID": 21, "context": "The character-level encoder shown in Figure 2(a) is loosely inspired by the neural language framework of [24], and the decoder is loosely a mirror image of the encoder.", "startOffset": 105, "endOffset": 109}, {"referenceID": 21, "context": "modeling in [24]), where weights are shared across time-steps, to the input of an LSTM, which accumulates state over the sequence and returns the final emission from the accumulated state as the domain name embedding.", "startOffset": 12, "endOffset": 16}, {"referenceID": 6, "context": "Generative Adversarial Networks, first introduced in [7] for image classification, train two models: A generative model that seeks to create synthetic data based on samples from the true data distribution with added added noise as an input.", "startOffset": 53, "endOffset": 56}, {"referenceID": 0, "context": "However, rather than passing this result a \u2208 [0, 1] to the output, we instead use a as a parameterization of a vector that lives within an axis-aligned box, and pass", "startOffset": 45, "endOffset": 51}, {"referenceID": 6, "context": "Then, we roughly follow the GAN training procedure introduced in [7], in which the discriminative and generative model compete in adversarial rounds.", "startOffset": 65, "endOffset": 68}, {"referenceID": 6, "context": "In a slight departure from [7], we regularize the discriminative model by training not only on the most recently-generated samples from the generative model, but a sampled history of domain names from both the current and previous adversarial rounds.", "startOffset": 27, "endOffset": 30}, {"referenceID": 22, "context": "Subsequent to our experiments, authors in [25] proposed minibatch discrimination as another way to prevent this common failure mode.", "startOffset": 42, "endOffset": 46}, {"referenceID": 2, "context": "So, to measure detectability of the DGA, we measure detection rates using a random forest DGA classifier that uses manually-crafted domain name features defined in [3], [4], [5], [15].", "startOffset": 164, "endOffset": 167}, {"referenceID": 3, "context": "So, to measure detectability of the DGA, we measure detection rates using a random forest DGA classifier that uses manually-crafted domain name features defined in [3], [4], [5], [15].", "startOffset": 169, "endOffset": 172}, {"referenceID": 4, "context": "So, to measure detectability of the DGA, we measure detection rates using a random forest DGA classifier that uses manually-crafted domain name features defined in [3], [4], [5], [15].", "startOffset": 174, "endOffset": 177}, {"referenceID": 12, "context": "So, to measure detectability of the DGA, we measure detection rates using a random forest DGA classifier that uses manually-crafted domain name features defined in [3], [4], [5], [15].", "startOffset": 179, "endOffset": 183}, {"referenceID": 12, "context": "Note that for the n-gram normality score, we use n = 3, n = 4 and n = 5 as three distinct features as opposed to n = 1, n = 2 and n = 3 as in [15] since the larger n-gram size performed better in preliminary experiments.", "startOffset": 142, "endOffset": 146}, {"referenceID": 1, "context": "It has previously been shown that adversarial examples may be shared across different machine learning models [2], Fig.", "startOffset": 110, "endOffset": 113}, {"referenceID": 0, "context": "[1].", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "This demonstrates in an information security setting a key point in [2], [1]: that adversarial examples may be shared across different models.", "startOffset": 68, "endOffset": 71}, {"referenceID": 0, "context": "This demonstrates in an information security setting a key point in [2], [1]: that adversarial examples may be shared across different models.", "startOffset": 73, "endOffset": 76}, {"referenceID": 22, "context": "Subsequent to our experiments, [25] proposed other strategies for training GANs, which we leave to future work.", "startOffset": 31, "endOffset": 35}], "year": 2016, "abstractText": "Many malware families utilize domain generation algorithms (DGAs) to establish command and control (C&C) connections. While there are many methods to pseudorandomly generate domains, we focus in this paper on detecting (and generating) domains on a per-domain basis which provides a simple and flexible means to detect known DGA families. Recent machine learning approaches to DGA detection have been successful on fairly simplistic DGAs, many of which produce names of fixed length. However, models trained on limited datasets are somewhat blind to new DGA variants. In this paper, we leverage the concept of generative adversarial networks to construct a deep learning based DGA that is designed to intentionally bypass a deep learning based detector. In a series of adversarial rounds, the generator learns to generate domain names that are increasingly more difficult to detect. In turn, a detector model updates its parameters to compensate for the adversarially generated domains. We test the hypothesis of whether adversarially generated domains may be used to augment training sets in order to harden other machine learning models against yet-to-be-observed DGAs. We detail solutions to several challenges in training this character-based generative adversarial network (GAN). In particular, our deep learning architecture begins as a domain name auto-encoder (encoder + decoder) trained on domains in the Alexa one million. Then the encoder and decoder are reassembled competitively in a generative adversarial network (detector + generator), with novel neural architectures and training strategies to improve convergence. Results show that domains generated from a GAN to bypass the GAN\u2019s detector also bypass a random forest classifier that leverages hand-crafted features. Conversely, by augmenting the training set with these adversarial examples, the random forest classifier is able to detect with greater efficacy DGA malware families not seen during training.", "creator": "LaTeX with hyperref package"}}}