{"id": "1610.02493", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Oct-2016", "title": "A Semantic Analyzer for the Comprehension of the Spontaneous Arabic Speech", "abstract": "This work is part of a large research project entitled \"Or\\'eodule\" aimed at developing tools for automatic speech recognition, translation, and synthesis for Arabic language. Our attention has mainly been focused on an attempt to improve the probabilistic model on which our semantic decoder is based. To achieve this goal, we have decided to test the influence of the pertinent context use, and of the contextual data integration of different types, on the effectiveness of the semantic decoder. The findings are quite satisfactory.", "histories": [["v1", "Sat, 8 Oct 2016 06:33:35 GMT  (406kb)", "http://arxiv.org/abs/1610.02493v1", "Advances in Computer Science and Engineering. 12 pages 6 figures"]], "COMMENTS": "Advances in Computer Science and Engineering. 12 pages 6 figures", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["mourad mars", "mounir zrigui", "mohamed belgacem", "anis zouaghi"], "accepted": false, "id": "1610.02493"}, "pdf": {"name": "1610.02493.pdf", "metadata": {"source": "CRF", "title": "A Semantic Analyzer for the Comprehension of the Spontaneous Arabic Speech", "authors": ["Mourad Mars", "Mounir Zrigui", "Mohamed Belgacem", "Anis Zouaghi"], "emails": ["Mohamed.belgacem}@e.u-grenoble3.fr", "Mounir.zrigui@fsm.rnu.tn", "Anis.zouaghi@riadi.rnu.tn"], "sections": [{"heading": null, "text": "The aim was to develop tools for automatic speech recognition, translation and synthesis for the Arabic language. Our main focus was on trying to improve the probability model on which our semantic decoder is based. To achieve this goal, we decided to test the influence of the respective context use and the contextual data integration of different types on the effectiveness of the semantic decoder and the results are quite satisfactory."}, {"heading": "1. Introduction", "text": "Our work fits within the framework of the automatic understanding of Arabic. The use of statistical models for speech recognition and speech comprehension [1] [2] has the advantage of greatly reducing the reliance on human expertise, and they can also be applied to other areas such as multilingual applications [3]. Automatic assignment to each word of the recognized utterance of the right group of FSe (semantic feature) [4] based on such models generally requires context analysis. Contextual information plays an important role in selecting the appropriate FSe. These pieces of information save difficulties in interpreting ambiguities and improve the performance of the comprehension system of [6] [10]. By default, the decoding of the meaning of the word is generated by analyzing the context that precedes it or / and immediately follows it. However, in the case of understanding spontaneous Arabic words, this is not always optimal. In fact, we have a prediction rate of 57% and 48.6% of the second word selection (the rate for the second word selection is not taken into account)."}, {"heading": "2. The Difficulties of the Semantic Decoding of the Spontaneous Arabic Speech", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1. Varieties of the Spoken Arabic Language", "text": "Arabic is the sixth most widely spoken language in the world, with about 250 million speakers. For historical and ideological reasons, this language represents a hierarchy of varieties: - Modern Standard Arabic: It is the written language of literature and the press, witch is usually spoken on the radio, at conferences and at official speeches in all Arabic countries. Standard Arabic is learned at school. - Intermediate Arabic: It is a simplified alternative to standard Arabic and the well-formed dialectic Arabic. It rejects its lexicon from both dialect and standard Arabic. Currently, this alternative is increasing. It is increasingly used in studies and in the media. It allows for approximation to the illiterate and the native language of the people. - Dialectical Arabic: It is another alternative to classical Arabic. It is mainly oral; it is the language of daily conversation. Each Arabic country has its own dialect. Although there are several dialects, mutual understanding between the different countries is possible."}, {"heading": "2.2. Particularities of Arabic Language", "text": "The automatic understanding of the natural language is a very difficult task. The main difficulties associated with the automatic processing of the spontaneous Arabic language are: - The non-vocalization of the majority of Arabic texts in books and newspapers makes the training task more complicated when using a probabilistic model. On a semantic level, the automatic recognition of the meaning of a non-vocalised word is very ambiguous. - An Arabic word, for example, can have three possible interpretations according to its vocabulary. It can mean a school or a teacher (female) or a scholar (past part of the lesson). This problem is similar to the ambiguity resulting from homonyms in other languages. - An Arabic word can express an entire French or English expression. For example, the word expressed in English may have you seen. Thus, the automatic interpretation of such words requires their preliminary segmentation, which is not an easy task. - The connection without space of the coordinating conjunction \"and\" to the words. It is quite difficult to distinguish the connection between a letter (for example)."}, {"heading": "3. The Proposed Approach for the Semantic Decoding of Arabic Speech", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1. The Conventional Methods Used", "text": "Several methods for the semantic analysis of spontaneous language have been proposed in the literature, some using HMM (such as [3], [6]), others using neural networks ([9], [10]), n-gram models ([12]), calculation ([13]), or even logic (14]. The table shows the most important formalisms used for understanding language, their advantages and disadvantages (the list is not exhaustive because the space is empty)."}, {"heading": "3.2. The Characteristics of our Approach", "text": "This year, it is more than ever before in the history of the city."}, {"heading": "3.3. The Semantic Analyzing Principle", "text": "As shown in Figure 3, the semantic decoding of an enunciation before processing is based on the probable language model of [23] and on the semantic lexicon. The probable model contributes to the selection of the FSe to be applied to words of enunciation in order to be interpreted, and the semantic lexicon describes the meaning of each word by a group of FSe and a group of Fsy. From the decoded encoding, its meaning is derived by filling the attributes of the identified diagram with the corresponding values. During the integration phase, we considered a labeled and pre-processed corpus to estimate the probable model parameters. The pre-processing of the representing corpus application allowed us to simplify the complexity and reduce the size of the probable model."}, {"heading": "4. Extraction of the Pertinent Context for Semantic Decoding", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1. The Extraction Principle", "text": "In order to determine the group of the FSe to which the word Mi belongs, we use only the group of the relevant FSe in our probability model. Thus, in order to identify the semantic class Ci to which the word Mi belongs, we consider in the equation E1 the two semantic classes CP i-1 and CP i-2 of the two FSe, the two words with the strongest semantic affinity to Mi. Likewise, in the equation E1 we consider only the group FSePi = {CPi, TMPi}, which has been assigned to the word with the strongest semantic affinity to Mi. To achieve this goal, we have relied on the concept of average mutual information, which helps to calculate the degree of the correlation of 24 words."}, {"heading": "4.2. Calculation of the Semantic Affinity", "text": "Consider a recognized utterance E = M1 M2 Mn / Mi Edj (Edj) Edj (Mi-K..., ME-1 ME1, \"MEK} the group of words surrounding the word Mi is interpreted by looking at a window of K size. Since our model only considers the correct context (see note 1) of Mi for the choice of the word Mi (see note 1) of Mi for the choice of the semantic affinity between Mi and its context, the group ME is thus set to MEd = {M1, M2\" Mi-1} (K is variable), which is the group of words before Wed. Now, to find the strongest semantic affinity between Mi and its context, we start calculating the average mutual information between Mi and each of the words belonging to MEd. Remark 1. The Arabic language is written from right to left."}, {"heading": "5. Application of the Model and Results", "text": "To assess the quality of our decoder, we have calculated the percentage of FSe correctly assigned using the following formula: Rerror = Ninc / N 100.Where, Ninc is the number of incorrectly assigned FSe, and N is the total number of FSe assigned by an expert to the test corpus. N is equal to 500 in this test. Figures 5 and 6 respectively show the influence of: - The relevant context on the interpretation result in relation to models that have a fixed and pre-determined history.- And the different types of contextual information and the context length on the interpretation results. The following Figures 5 and 6 respectively show the impact of tactical texts on: - The relevant context on the interpretation result in relation to models that have a fixed and pre-defined history.- And the different types of contextual information and the context length on the interpretation results."}, {"heading": "6. Conclusion", "text": "In this thesis, we have presented a semantic analyzer based on a hybrid language model that helps to integrate lexical, semantic and illocutionary context data at the same time. Furthermore, it does not only have to take into account relevant FSe in word history. To achieve this goal, we have developed a method based on the average reciprocal concept of information. The results are satisfactory. In the near future, we will evaluate our model by comparing it with the so-called remote models or with the models obtained by a linear combination of well-known language models such as the maximum of entropy. We also hope to define an ungrammatical gradient that makes it possible to evaluate the syntactic complexity of a statement and then select the appropriate model to apply."}], "references": [{"title": "Robust analysis of spoken input combining statistical and knowledge-based information sources", "author": ["R. Cattoni", "M. Federico", "A. Lavie"], "venue": "ASRU, Trento", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2001}, {"title": "Estimation de probabilit\u00e9 non param\u00e9trique pour la reconnaissance markovienne de la parole", "author": ["F. Lef\u00e8vre"], "venue": "Th\u00e8se de l'Universit\u00e9 Pierre et Marie Curie", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2000}, {"title": "Compr\u00e9hension automatique de la parole spontan\u00e9e", "author": ["W. Minker"], "venue": "L!Harmattan, Paris", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1999}, {"title": "Une structure s\u00e9mantique pour l!interpr\u00e9tation des \u00e9nonc\u00e9s", "author": ["A. Zouaghi", "M. Zrigui", "M. Ben Ahmed"], "venue": "JEP-TALN, F\u00e8s", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2004}, {"title": "Un \u00e9tiqueteur s\u00e9mantique des \u00e9nonc\u00e9s en langue arabe", "author": ["A. Zouaghi", "M. Zrigui", "M. Ben Ahmed"], "venue": "RECITAL, Dourdan", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2005}, {"title": "Compr\u00e9hension robuste de la parole spontan\u00e9e dans le dialogue oral homme-machine \" D\u00e9codage conceptuel stochastique", "author": ["C. Bousquet-Vernhettes"], "venue": "Th\u00e8se de l!universit\u00e9 de Toulouse III", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2002}, {"title": "L!\u00e9tiquetage morpho-syntaxique: comment lever l!ambigu\u00eft\u00e9 dans les textes arabes non voyell\u00e9s ", "author": ["N. Chaabene", "L. Belguith"], "venue": "Journ\u00e9es scientifiques des jeunes chercheurs en g\u00e9nie \u00e9lectrique et informatique, Mahdia, Tunisie", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2003}, {"title": "Natural Language Understanding Using Statistical Machine Translation", "author": ["K. Macherey", "F.J. Och", "H. Ney"], "venue": "European conference on speech communication and technology, Aalborg", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2001}, {"title": "Parsec: a structured connexionist parsing system for spoken language", "author": ["A.N. Jain", "A. Waibel", "D.S. Touretzky"], "venue": "International Conference on Acoustics, Speech and Signal Processing, San Francisco,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1992}, {"title": "Un syst\u00e8me de compr\u00e9hension automatique de la parole pour l!interrogation orale d!une base de donn\u00e9es de bourse", "author": ["S. Jamoussi", "K. Sma\u00efli", "D. Fohr", "J.P. Haton"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2004}, {"title": "Linguistic Analysis in a Slovenian information retrieval system for flight services", "author": ["K. Pepelnjak", "J. Gros", "F. Mihelic", "N. Pave\"ic"], "venue": "Workshop on Spoken Dialogue Systems, Vigso, Danemark", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1995}, {"title": "Comparing grammar-based and robust approaches to speech understanding: a case study", "author": ["S. Knight", "G. Gorell", "M. Rayner", "D. Milward", "R. Koeling", "I. Lewin"], "venue": "European conference on speech communication and technology, Aalborg, Danemark,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2001}, {"title": "Combining Syntax and Pragmatic Knowledge for the Understanding of Spontaneous Spoken Sentences", "author": ["J. Villaneau", "Antoine J.Y.", "O. Ridoux"], "venue": "Logical Aspects of Computational Linguistic, Croisic, France", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2001}, {"title": "A Cooperative Spoken Dialogue System Based on a Rational Agent Model: A First Implementation on the AGS Application", "author": ["D. Sadek", "P. Bretier", "V. Cadoret", "A. Cozannet", "P. Dupont", "A. Ferrieux", "F. Panaget"], "venue": "Workshop on Spoken Dialogue Systems,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1995}, {"title": "Arabic morphological analysis on the Internet", "author": ["K.R. Beesely"], "venue": "International Conference on Multi-Lingual Computing, Cambridge", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1998}, {"title": "A major offshoot of the Dinar-MBC project: AraParse, a morphosyntactic analyzer for unvowelled Arabic texts", "author": ["R. Ouersighni"], "venue": "ACL/EACL01: Conference of the European Chapter, Workshop: Arabic Language Processing: Status and Prospects", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2001}, {"title": "A Compositional Approach Towards Semantic Representation and Construction of ARABIC", "author": ["B. Haddad", "M. Yaseen"], "venue": "LACL, Bordeaux, France", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2005}, {"title": "http://search2.computer.org/advanced/Author_Result.jsp?qtype=3&select=50&qOpt1=DC_ CREATOR&sortOrder=d&queryName=Mohamed%20Tayeb%20Laskri: Generation of the Sense of a Sentence in Arabic Language with a Connectionist Approach, AICCSA'01", "author": ["K. Meftouh", "M.T. Laskri"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2001}, {"title": "A Logical Meaning Representation for Arabic (LMRA)", "author": ["B. AL-Johar", "J. McGregor"], "venue": "Proceedings of the 15th National Computer Conference, Riyadh, Saudi Arabia", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1997}, {"title": "analyseur morphologique pour l'arabe", "author": ["Mourad Mars", "Mohamed Belgacem", "Mounir Zrigui", "Georges Antoniadis."], "venue": "CITALA 07. Rabat Maroc", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2007}, {"title": "Compr\u00e9hension automatique de la langue arabe", "author": ["C. Manka\u00ef Naanaa"], "venue": "Application: Le syst\u00e8me Al Biruni. Th\u00e8se de l!universit\u00e9 de Tunis", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1996}, {"title": "Head-Driven Phrase Structure Grammar", "author": ["C. Pollard", "I. Sag"], "venue": "University of Chicago Press, Chicago", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1994}, {"title": "A statistical model for semantic decoding of Arabic language statements", "author": ["A. Zouaghi", "M. Zrigui", "M. Ben Ahmed"], "venue": "Proceedings of NODALIDA, Joensuu, Finland", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2005}, {"title": "Adaptive statistical language modelling: A maximum entropy approach", "author": ["R. Rosenfeld"], "venue": "Thesis at Carnegie Mellon University,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1994}, {"title": "Robust parsing for spoken language systems", "author": ["S. Seneff"], "venue": "Proceedings of ICASSP", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1992}, {"title": "Quand le TAL robuste s!attaque au langage parl\u00e9: analyze incr\u00e9mentale pour la compr\u00e9hension de la parole spontan\u00e9e", "author": ["Antoine", "J-Y.", "J. Goulian", "J. Villaneau"], "venue": "Proceedings of TALN, Batz-sur-Mer, France", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2003}], "referenceMentions": [{"referenceID": 0, "context": "The use of statistical models for the speech recognition and comprehension [1] [2], have the merit to strongly reduce the resort to human expertise.", "startOffset": 75, "endOffset": 78}, {"referenceID": 1, "context": "The use of statistical models for the speech recognition and comprehension [1] [2], have the merit to strongly reduce the resort to human expertise.", "startOffset": 79, "endOffset": 82}, {"referenceID": 2, "context": "They can also be applied to other fields such as multilingual applications [3].", "startOffset": 75, "endOffset": 78}, {"referenceID": 3, "context": "The automatic association with each word of the recognized utterance of the proper group of FSe (Semantic Feature) [4] based on such models generally requires the analysis of the context.", "startOffset": 115, "endOffset": 118}, {"referenceID": 5, "context": "These pieces of information spare the trouble of interpretation ambiguities and improve the performance of the comprehension system of [6] [10].", "startOffset": 135, "endOffset": 138}, {"referenceID": 9, "context": "These pieces of information spare the trouble of interpretation ambiguities and improve the performance of the comprehension system of [6] [10].", "startOffset": 139, "endOffset": 143}, {"referenceID": 7, "context": "- An Arabic word may express a whole French or English expression [8].", "startOffset": 66, "endOffset": 69}, {"referenceID": 8, "context": "Even some graphemes can\u007ft be considered during the pronunciation [9].", "startOffset": 65, "endOffset": 68}, {"referenceID": 2, "context": "Some use the HMM (such as [3], [8], [6]), others the neuronal", "startOffset": 26, "endOffset": 29}, {"referenceID": 7, "context": "Some use the HMM (such as [3], [8], [6]), others the neuronal", "startOffset": 31, "endOffset": 34}, {"referenceID": 5, "context": "Some use the HMM (such as [3], [8], [6]), others the neuronal", "startOffset": 36, "endOffset": 39}, {"referenceID": 8, "context": "networks ([9], [10]), the n-grams language models ([11], [12]), the -calculus ([13]), or also logics ([14]).", "startOffset": 10, "endOffset": 13}, {"referenceID": 9, "context": "networks ([9], [10]), the n-grams language models ([11], [12]), the -calculus ([13]), or also logics ([14]).", "startOffset": 15, "endOffset": 19}, {"referenceID": 10, "context": "networks ([9], [10]), the n-grams language models ([11], [12]), the -calculus ([13]), or also logics ([14]).", "startOffset": 51, "endOffset": 55}, {"referenceID": 11, "context": "networks ([9], [10]), the n-grams language models ([11], [12]), the -calculus ([13]), or also logics ([14]).", "startOffset": 57, "endOffset": 61}, {"referenceID": 12, "context": "networks ([9], [10]), the n-grams language models ([11], [12]), the -calculus ([13]), or also logics ([14]).", "startOffset": 79, "endOffset": 83}, {"referenceID": 13, "context": "networks ([9], [10]), the n-grams language models ([11], [12]), the -calculus ([13]), or also logics ([14]).", "startOffset": 102, "endOffset": 106}, {"referenceID": 14, "context": "During the last two decades the efforts were rather concentrated on the realization of the morphological and syntactic analyzers for Arabic ([15], [16], [20]etc).", "startOffset": 141, "endOffset": 145}, {"referenceID": 15, "context": "During the last two decades the efforts were rather concentrated on the realization of the morphological and syntactic analyzers for Arabic ([15], [16], [20]etc).", "startOffset": 147, "endOffset": 151}, {"referenceID": 19, "context": "During the last two decades the efforts were rather concentrated on the realization of the morphological and syntactic analyzers for Arabic ([15], [16], [20]etc).", "startOffset": 153, "endOffset": 157}, {"referenceID": 16, "context": "In spite of the importance of the representation and of the semantic analysis for the realization of any comprehension system, there are only some works in this field which are interested in the processing of Arabic language (such as [17], [18], [19], [21]).", "startOffset": 234, "endOffset": 238}, {"referenceID": 17, "context": "In spite of the importance of the representation and of the semantic analysis for the realization of any comprehension system, there are only some works in this field which are interested in the processing of Arabic language (such as [17], [18], [19], [21]).", "startOffset": 240, "endOffset": 244}, {"referenceID": 18, "context": "In spite of the importance of the representation and of the semantic analysis for the realization of any comprehension system, there are only some works in this field which are interested in the processing of Arabic language (such as [17], [18], [19], [21]).", "startOffset": 246, "endOffset": 250}, {"referenceID": 20, "context": "In spite of the importance of the representation and of the semantic analysis for the realization of any comprehension system, there are only some works in this field which are interested in the processing of Arabic language (such as [17], [18], [19], [21]).", "startOffset": 252, "endOffset": 256}, {"referenceID": 20, "context": "Al Biruni system [21] for example, is based on a combination of the Fillmore case grammar formalism and of the Mel'cuk sense-text theory, for the semantic analysis, the representation of the Arab text and the handling of its representation.", "startOffset": 17, "endOffset": 21}, {"referenceID": 16, "context": "As for [17], he uses the unification grammar HDPSG of [22] which allows the integration of syntactic and semantic knowledge in the same grammar, in order to lead to a deep analysis.", "startOffset": 7, "endOffset": 11}, {"referenceID": 21, "context": "As for [17], he uses the unification grammar HDPSG of [22] which allows the integration of syntactic and semantic knowledge in the same grammar, in order to lead to a deep analysis.", "startOffset": 54, "endOffset": 58}, {"referenceID": 2, "context": "HMM [3], [6] , [8] speech Existence of powerful algorithms (such as Viterbi and A*) allowing to determine the optimal solution.", "startOffset": 4, "endOffset": 7}, {"referenceID": 5, "context": "HMM [3], [6] , [8] speech Existence of powerful algorithms (such as Viterbi and A*) allowing to determine the optimal solution.", "startOffset": 9, "endOffset": 12}, {"referenceID": 7, "context": "HMM [3], [6] , [8] speech Existence of powerful algorithms (such as Viterbi and A*) allowing to determine the optimal solution.", "startOffset": 15, "endOffset": 18}, {"referenceID": 8, "context": "Neuronal Networks [9], [10]", "startOffset": 18, "endOffset": 21}, {"referenceID": 9, "context": "Neuronal Networks [9], [10]", "startOffset": 23, "endOffset": 27}, {"referenceID": 17, "context": "[18] Writing and speech Capacity of generalization and flexibility.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "HDPSG [17] Writing Allows an explicit integration in only one structure, the different linguistic analysis levels: phonetic, syntactic, and semantic.", "startOffset": 6, "endOffset": 10}, {"referenceID": 2, "context": "Case frames [3] [21] speech Authorizes the treatment of the sentences without respecting grammatical rules and requires less expertise in linguistics.", "startOffset": 12, "endOffset": 15}, {"referenceID": 20, "context": "Case frames [3] [21] speech Authorizes the treatment of the sentences without respecting grammatical rules and requires less expertise in linguistics.", "startOffset": 16, "endOffset": 20}, {"referenceID": 3, "context": "- A man/machine co-operation method based on corpus analysis (see figure 1): for building up our structure of sense representation SRS such as it is defined in [4], we developed a method based on a corpus analysis to extract significant words, reference words and semantic classes of the application, and on man-machine co-operation for word\u007fs interpretation.", "startOffset": 160, "endOffset": 163}, {"referenceID": 22, "context": "As shown in figure 3, the semantic decoding of the pre-processing utterance is based on the probabilistic language model of [23] and on semantic lexicon.", "startOffset": 124, "endOffset": 128}, {"referenceID": 23, "context": "To achieve this goal, we have relied on the concept of average mutual information [24] which helps to calculate the correlation degree of two given words.", "startOffset": 82, "endOffset": 86}, {"referenceID": 22, "context": "Here below the formula of average mutual information IMm [23]:", "startOffset": 57, "endOffset": 61}, {"referenceID": 24, "context": "In order to solve this problem, some systems combine a deep syntactic analysis with a selective analysis such as the TINA system of [25].", "startOffset": 132, "endOffset": 136}, {"referenceID": 25, "context": "Other systems use the analyzes strategies of NLP robust [26].", "startOffset": 56, "endOffset": 60}], "year": 2016, "abstractText": "This work is part of a large research project entitled \"Or\u00e9odule\" aimed at developing tools for automatic speech recognition, translation, and synthesis for Arabic language. Our attention has mainly been focused on an attempt to improve the probabilistic model on which our semantic decoder is based. To achieve this goal, we have decided to test the influence of the pertinent context use, and of the contextual data integration of different types, on the effectiveness of the semantic decoder. The findings are quite satisfactory.", "creator": "PDFCreator Version 1.6.2(Infix Pro)"}}}