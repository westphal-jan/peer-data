{"id": "1610.02876", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Oct-2016", "title": "Heuristic Approaches for Generating Local Process Models through Log Projections", "abstract": "Local Process Model (LPM) discovery is focused on the mining of a set of process models where each model describes the behavior represented in the event log only partially, i.e. subsets of possible events are taken into account to create so-called local process models. Often such smaller models provide valuable insights into the behavior of the process, especially when no adequate and comprehensible single overall process model exists that is able to describe the traces of the process from start to end. The practical application of LPM discovery is however hindered by computational issues in the case of logs with many activities (problems may already occur when there are more than 17 unique activities). In this paper, we explore three heuristics to discover subsets of activities that lead to useful log projections with the goal of speeding up LPM discovery considerably while still finding high-quality LPMs. We found that a Markov clustering approach to create projection sets results in the largest improvement of execution time, with discovered LPMs still being better than with the use of randomly generated activity sets of the same size. Another heuristic, based on log entropy, yields a more moderate speedup, but enables the discovery of higher quality LPMs. The third heuristic, based on the relative information gain, shows unstable performance: for some data sets the speedup and LPM quality are higher than with the log entropy based method, while for other data sets there is no speedup at all.", "histories": [["v1", "Mon, 10 Oct 2016 12:12:46 GMT  (757kb,D)", "http://arxiv.org/abs/1610.02876v1", "paper accepted and to appear in the proceedings of the IEEE Symposium on Computational Intelligence and Data Mining (CIDM), special session on Process Mining, part of the Symposium Series on Computational Intelligence (SSCI)"]], "COMMENTS": "paper accepted and to appear in the proceedings of the IEEE Symposium on Computational Intelligence and Data Mining (CIDM), special session on Process Mining, part of the Symposium Series on Computational Intelligence (SSCI)", "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.DB", "authors": ["niek tax", "natalia sidorova", "wil m p van der aalst", "reinder haakma"], "accepted": false, "id": "1610.02876"}, "pdf": {"name": "1610.02876.pdf", "metadata": {"source": "CRF", "title": "Heuristic Approaches for Generating Local Process Models through Log Projections", "authors": ["Niek Tax", "Natalia Sidorova", "Wil M. P. van der Aalst", "Reinder Haakma"], "emails": ["n.tax@tue.nl", "n.sidorova@tue.nl", "w.m.p.v.d.aalst@tue.nl", "reinder.haakma@philips.com"], "sections": [{"heading": null, "text": "This year it is as far as never before in the history of the Federal Republic of Germany."}, {"heading": "II. PRELIMINARIES", "text": "In this section, we present concepts used in later sections of this paper. < X \u0445 denotes the number of all sequences over a set of X and \"X.\" < B > p > p > p is the number of all sequences. < P > is the empty sequence and the number of sequences recorded in each sequence. < A > P is the event e in an event log the occurrence of an activity. We call a sequence of events, the L a, L and L is a finite multiset of tracks. For example, the event log is L = [< a, b > 2, < b, c > 3] b, a, c > 3] b, c > 2 events, c < a, c > and three occurrences."}, {"heading": "III. LOCAL PROCESS MODELS AND THEIR RANKINGS", "text": "The quality of an LPM model is calculated by segmenting tracks from a log into sequences from the LPM protocol.... the number of events in sequences from the log into sequences from the LPM protocol is maximized: The higher the number of events in segments, the greater the proportion of tracks in the log explained by the LPM. The ranking of local process models is based on a weighted average of five quality criteria in a range from zero to one, as described in [8]: Support The frequency of behavior described by the LPMin in the event log, i.e. the number of track segments in the log that match the LPM models."}, {"heading": "IV. DISCOVERING LOG PROJECTION SETS", "text": "Local Process Models (LPM) contain only a subset of the activities of the protocol, and each LPM can in principle be detected on any projection of the protocol containing the activities used in this protocol. In this section we describe three heuristics for detecting projection sets - subsets of activities used for projecting the protocol. Each described heuristics takes an event log as input and generates a series of projection sets. These projection sets could potentially overlap, which is a desired property, since interesting patterns could exist within a set of activities {A, B, C, D}, as well as within a set of activities {A, B, C, E}, and detection on both subsets may be faster than detection once on {A, B, C, D, E}. None of the projection sets in this set is a subset of another projection set to avoid duplication, as each individual LPM detected on a particular projection set may also be detected on top of a projection set."}, {"heading": "A. An approach based on Markov clustering", "text": "Markov Clustering [10], [11] is a fast and scalable graph clustering algorithm based on the simulation of the flow in graphs. Markov Clustering's main intuition is that the probability of transition between two members of the same cluster is higher than the probability of transition between two nodes located in different clusters. Markov Clustering takes as its input a Markov matrix, i.e. a matrix that describes the probabilities of transition in a Markov chain. We create a matrix M that represents the interconnectedness of two activities by using the directly following and immediately preceding ratios: Mi, j = \u221a dpr (i, j, L) 2 + dfr (j, i, L) 2, using the L2 norm of clustering and the ratio directly following."}, {"heading": "B. Log entropy based approach", "text": "Another approach to generating projection sets is to form groups of activities in such a way that the categorical probability distributions about activities that precede or follow an activity in the projected protocols reach their peak, i.e. far away from the discrete uniform distribution. On the other hand, if the occurrence of activity a conveys information about the next event and, for example, makes it very likely that another activity b is to be observed next, the activities in the projection set can probably be related somehow. We use the standard entropy function via the categorical probability distribution X via | X elements: H (X) = projected x \u00b7 log2 (x). We calculate the total entropy Ent (L) of the protocol statistics as: entropy (L) = projected projection L (H)."}, {"heading": "C. Maximal Relative Information Gain based approach", "text": "A more local perspective on the entropy-based projection quantity discovery would be to compare a projection quantity with the projection quantity of the previous time step (instead of the original protocol).We add an activity to a projection quantity if it greatly reduces the entropy of at least one of the categorical probability distributions over subsequent or preceding activities, even if the entropy of other categorical probability distributions could increase.The underlying intuition is that any decrease in the entropy of a categorical probability distribution over subsequent or preceding activities indicates that a pattern is strengthened by adding this activity and that an LPM could potentially be found. We define the maximum relative information gain (MRIG) of projection quantity A over the projection quantity B, with A-B, to event protocol L, to event protocol L, MRIG (A, B, L) as the maximum information gain over the projection quantity B over the projection quantity B, to the event protocostatic L, to the event log L, to reduce the maximum information gain over the statistical codification of the statistic L."}, {"heading": "V. EXPERIMENTAL SETUP", "text": "Fig. 2 provides an overview of the methodology for evaluating projection sets and discovery methods. We evaluate their quality by comparing the quality of Local Process Models (LPMs), which are determined by the projection sets they generate with the quality of the LPMs discovered on the same log without the use of projections. First, we apply the LPM discovery to the original, unprojected event log L, which results in the \"ideal\" top k of the LPMs. Then, we apply one of the projection set methods to event log L, which results in a set Q of the projection sets. On each of the projected event logs in L Q, we apply LPM Discovery, which leads to | Q | k LPMs. We select the unique best LPMs from them in terms of the weighted average over the quality criteria. We compare the \"ideal\" sets of LPMs with the projections in L Q, which will result in | Q | k LPMs. From them, we select the best LPMs in terms of the weighted average over the quality criteria. We compare the \"ideal\" sets of LPMs with the projections in L Q, \"if the projection table is clearly matched with the projection activity of the LPM,\" if any LPMs detected for the projection table is good."}, {"heading": "A. Metrics for Comparison of Local Process Model Rankings", "text": "A more nuanced way of comparing is to look at the weighted averages of the LPMs in the \"ideal\" ranking, and the underlying intuition is that it is less severe not to be able to find LPMs from the \"ideal\" top-k, if the alternatively found LPMs are also of good quality, i.e. just below the top-k. In addition, the absence of the top-rated LPMs is heavier than the absence of the lower LPMs. For this reason, we use the Discounted Cumulative Gain (NDCG @ k) [12], one of the most commonly used metrics for evaluating a ranking with an \"ideal\" ranking of the LPMs in the field of information retrieval [14], which gives more weight to Discounted Dain (NDCG @) than the lower parts of the ranking."}, {"heading": "B. Data Sets for Projection Discovery Experiments", "text": "This year, it has reached the point where it will be able to put itself at the top without being able to put itself at the top."}, {"heading": "VI. RESULTS & DISCUSSION", "text": "Fig. 4 shows the results of the evaluation with the five evaluation datasets and Table II shows the acceleration of the projection based on LPM discovery. Acceleration mainly depends on the size of the projection datasets. Note that we do not compare the calculation time of discovered and randomly generated projections, as both consist of equally large projections. The time needed to discover the projection dataset is included in the calculation time shown in Table II, but the projection time is negligible compared to the time required to discover LPM discoveries. Each dark grass bar in Fig. 4 represents the performance based on the column of the projection dataset discovery method discovery time."}, {"heading": "VII. RELATED WORK", "text": "The task of discovering projections plays an important role in the area of decomposed process discovery and conformity control. Decomposed process discovery aims at dividing the activities into the event log so that after applying process discoveries to each partition of the events, the start-to-end process model can be constructed by dividing it among the individual partitions. [19] An approach has been introduced to decomposing process mining by priming a maximum decomposition of a causal dependency, where the activities end in a cluster with each edge in causal dependence. Hompes et al describe an approach to making more coarse-grained activity clusters by balancing the clusters of maximum decomposition."}, {"heading": "VIII. CONCLUSION & FUTURE WORK", "text": "We investigated three different heuristics for detecting projection sets to accelerate the discovery of the Local Process Model. These heuristics allow the discovery of LPMs from event logs where it is mathematically impossible to find LPMs from the complete set of activities in the log. All three provide better results than random projections on a variety of data sets. Projection discoveries based on the Markov cluster result in the highest acceleration, while higher quality LPMs can be detected from a projection discovery based on log statistical entropy. The projection detection approach based on the maximum relative information increase shows an unstable performance with the highest quality gain in LPM compared to random projections on some event logs, while we cannot detect a projection smaller than the complete set of activities on some other event logs. In fact, we would like to examine properties of event logs that can serve as a prediction for this relative performance."}], "references": [{"title": "On generation of time-based label refinements", "author": ["N. Tax", "E. Alasgarov", "N. Sidorova", "R. Haakma"], "venue": "Proceedings of the 25th International Workshop on Concurrency, Specification and Programming. CEUR- WS.org, 2016, pp. 25\u201336.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2016}, {"title": "Application of process mining in healthcare \u2013 a case study in a dutch hospital", "author": ["R.S. Mans", "M.H. Schonenberg", "M. Song", "W.M.P. van der Aalst", "P.J.M. Bakker"], "venue": "International Joint Conference on Biomedical Engineering Systems and Technologies. Springer, 2008, pp. 425\u2013438.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2008}, {"title": "Discovering block-structured process models from event logs-a constructive approach", "author": ["S.J.J. Leemans", "D. Fahland", "W.M.P. van der Aalst"], "venue": "International Conference on Applications and Theory of Petri Nets and Concurrency. Springer Berlin Heidelberg, 2013, pp. 311\u2013329.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2013}, {"title": "Process discovery using integer linear programming", "author": ["J.M.E.M. van der Werf", "B.F. van Dongen", "C.A.J. Hurkens", "A. Serebrenik"], "venue": "International Conference on Applications and Theory of Petri Nets. Springer, 2008, pp. 368\u2013387.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2008}, {"title": "User-guided discovery of declarative process models", "author": ["F.M. Maggi", "A.J. Mooij", "W.M.P. van der Aalst"], "venue": "Computational Intelligence and Data Mining, 2011 IEEE Symposium on. IEEE, 2011, pp. 192\u2013199.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "Mining the organisational perspective in agile business processes", "author": ["S. Sch\u00f6nig", "C. Cabanillas", "S. Jablonski", "J. Mendling"], "venue": "International Conference on Enterprise, Business-Process and Information Systems Modeling. Springer, 2015, pp. 37\u201352.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2015}, {"title": "Mining Local Process Models", "author": ["N. Tax", "N. Sidorova", "R. Haakma", "W.M.P. van der Aalst"], "venue": "ArXiv:1606.06066, 2016.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2016}, {"title": "MIMIC II: a massive temporal ICU patient database to support research in intelligent patient monitoring", "author": ["M. Saeed", "C. Lieu", "G. Raber", "R.G. Mark"], "venue": "Computers in Cardiology, 2002. IEEE, 2002, pp. 641\u2013 644.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2002}, {"title": "Graph clustering via a discrete uncoupling process", "author": ["S. van Dongen"], "venue": "SIAM Journal on Matrix Analysis and Applications, vol. 30, no. 1, pp. 121\u2013141, 2008.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2008}, {"title": "Graph clustering by flow simulation", "author": ["\u2014\u2014"], "venue": "Ph.D. dissertation, University of Utrecht, Utrecht, May 2000.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2000}, {"title": "Cumulated gain-based evaluation of IR techniques", "author": ["K. J\u00e4rvelin", "J. Kek\u00e4l\u00e4inen"], "venue": "ACM Transactions on Information Systems, vol. 20, no. 4, pp. 422\u2013446, 2002.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2002}, {"title": "Learning to rank using gradient descent", "author": ["C. Burges", "T. Shaked", "E. Renshaw", "A. Lazier", "M. Deeds", "N. Hamilton", "G. Hullender"], "venue": "Proceedings of the 22nd International Conference on Machine Learning. ACM, 2005, pp. 89\u201396.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2005}, {"title": "A cross-benchmark comparison of 87 learning to rank methods", "author": ["N. Tax", "S. Bockting", "D. Hiemstra"], "venue": "Information Processing & Management, vol. 51, no. 6, pp. 757\u2013772, 2015.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2015}, {"title": "Accurate activity recognition in a home setting", "author": ["T. van Kasteren", "A. Noulas", "G. Englebienne", "B. Kr\u00f6se"], "venue": "Proceedings of the 10th International Conference on Ubiquitous Computing. ACM, 2008, pp. 1\u20139.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2008}, {"title": "Analysis of human behavior recognition algorithms based on acceleration data", "author": ["B. Bruno", "F. Mastrogiovanni", "A. Sgorbissa", "T. Vernazza", "R. Zaccaria"], "venue": "Robotics and Automation, 2013 IEEE International Conference on. IEEE, 2013, pp. 1602\u20131607.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2013}, {"title": "The national exposure research laboratory\u2019s consolidated human activity database", "author": ["T. McCurdy", "G. Glen", "L. Smith", "Y. Lakkadi"], "venue": "Journal of Exposure Analysis and Environmental Epidemiology, vol. 10, no. 6, pp. 566\u2013578, 2000.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2000}, {"title": "Activity recognition using hybrid generative/discriminative models on home environments using binary sensors", "author": ["F.J. Ord\u00f3nez", "P. de Toledo", "A. Sanchis"], "venue": "Sensors, vol. 13, no. 5, pp. 5460\u20135477, 2013.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2013}, {"title": "Decomposing Petri nets for process mining: A generic approach", "author": ["W.M.P. van der Aalst"], "venue": "Distributed and Parallel Databases, vol. 31, no. 4, pp. 471\u2013507, 2013.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2013}, {"title": "Finding suitable activity clusters for decomposed process discovery", "author": ["B.F.A. Hompes", "H.M.W. Verbeek", "W.M.P. van der Aalst"], "venue": "Data-Driven Process Discovery and Analysis. Springer, 2014, pp. 32\u201357.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}, {"title": "Process discovery and conformance checking using passages", "author": ["W.M.P. van der Aalst", "H.M.W. Verbeek"], "venue": "Fundamenta Informaticae, vol. 131, no. 1, pp. 103\u2013138, 2014.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2014}, {"title": "Single-entry single-exit decomposed conformance checking", "author": ["J. Munoz-Gama", "J. Carmona", "W.M.P. Van Der Aalst"], "venue": "Information Systems, vol. 46, pp. 102\u2013122, 2014.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2014}, {"title": "Divide-and-conquer strategies for process mining", "author": ["J. Carmona", "J. Cortadella", "M. Kishinevsky"], "venue": "Business Process Management. Springer, 2009, pp. 327\u2013343.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2009}, {"title": "Projection approaches to process mining using region-based techniques", "author": ["J. Carmona"], "venue": "Data Mining and Knowledge Discovery, vol. 24, no. 1, pp. 218\u2013246, 2012.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2012}, {"title": "Discovery of frequent episodes in event logs", "author": ["M. Leemans", "W.M.P. van der Aalst"], "venue": "Data-Driven Process Discovery and Analysis. Springer, 2014, pp. 1\u201331.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "An example of such a domain is human behavior [2], with events registered e.", "startOffset": 46, "endOffset": 49}, {"referenceID": 1, "context": "Another application domain, where the variability in the process is often large is the medical workflows of patient care [3].", "startOffset": 121, "endOffset": 124}, {"referenceID": 2, "context": "[4], [5]) often fail to generate insightful models on such event logs and generate process models in which any sequence of events is allowed, often referred to as the flower model.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4], [5]) often fail to generate insightful models on such event logs and generate process models in which any sequence of events is allowed, often referred to as the flower model.", "startOffset": 5, "endOffset": 8}, {"referenceID": 4, "context": "[6], [7]).", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[6], [7]).", "startOffset": 5, "endOffset": 8}, {"referenceID": 6, "context": "Richer models of unstructured processes can be discovered using Local Process Model (LPM) discovery [8].", "startOffset": 100, "endOffset": 103}, {"referenceID": 7, "context": "1 shows some of the LPMs discovered on the log extracted from MIMIC-II [9], a medical database containing 147461 logged medical procedure events from 1734 activities for 28280 patients collected between 2001 and 2008 from multiple intensive care units (ICUs) in the USA.", "startOffset": 71, "endOffset": 74}, {"referenceID": 6, "context": "1 cannot be discovered using the bruteforce approach described in [8].", "startOffset": 66, "endOffset": 69}, {"referenceID": 6, "context": "The ranking of Local Process Models is based on a weighted average over five quality criteria in a zero to one range, as described in [8]:", "startOffset": 134, "endOffset": 137}, {"referenceID": 6, "context": "In [8] we developed an incremental procedure for building LPMs, starting from models with two activities, and recursively extending them to more activities.", "startOffset": 3, "endOffset": 6}, {"referenceID": 8, "context": "Markov clustering [10], [11] is a fast and scalable clustering algorithm for graphs that is based on simulation of flow in graphs.", "startOffset": 18, "endOffset": 22}, {"referenceID": 9, "context": "Markov clustering [10], [11] is a fast and scalable clustering algorithm for graphs that is based on simulation of flow in graphs.", "startOffset": 24, "endOffset": 28}, {"referenceID": 9, "context": "The inflation parameter of the Markov clustering algorithm is known to be the main parameter in determining the granularity of the clustering obtained [11] with Markov clustering.", "startOffset": 151, "endOffset": 155}, {"referenceID": 10, "context": "For this reason, we use Normalized Discounted Cumulative Gain (NDCG@k) [12], [13], one of the most widely used metrics for evaluation of a ranking with an \u201cideal\u201d ranking in the field of Information Retrieval [14], that gives more weight to the top of the rankings than to the lower parts of the rankings.", "startOffset": 71, "endOffset": 75}, {"referenceID": 11, "context": "For this reason, we use Normalized Discounted Cumulative Gain (NDCG@k) [12], [13], one of the most widely used metrics for evaluation of a ranking with an \u201cideal\u201d ranking in the field of Information Retrieval [14], that gives more weight to the top of the rankings than to the lower parts of the rankings.", "startOffset": 77, "endOffset": 81}, {"referenceID": 12, "context": "For this reason, we use Normalized Discounted Cumulative Gain (NDCG@k) [12], [13], one of the most widely used metrics for evaluation of a ranking with an \u201cideal\u201d ranking in the field of Information Retrieval [14], that gives more weight to the top of the rankings than to the lower parts of the rankings.", "startOffset": 209, "endOffset": 213}, {"referenceID": 13, "context": "For the Van Kasteren data set [15] we show and discuss the ranking of LPMs for which we aim to speed up discovery through projections.", "startOffset": 30, "endOffset": 34}, {"referenceID": 14, "context": "[16] data set is a public collection of labeled wrist-worn accelerometer recordings.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "3) CHAD Data Set: The CHAD database [17] consists of 22 exposure and time-use studies that have been consolidated in a consistent format.", "startOffset": 36, "endOffset": 40}, {"referenceID": 16, "context": "4) Ordonez A Data Set: The Ordonez [18] data set consists of ADL events that are performed by two users in their own homes, recorded through smart home sensors.", "startOffset": 35, "endOffset": 39}, {"referenceID": 13, "context": "[15].", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "3 shows the first five elements of the Local Process Model ranking discovered on one of the data sets (Van Kasteren [15]).", "startOffset": 116, "endOffset": 120}, {"referenceID": 17, "context": "In [19] an approach was introduced to decompose process mining by using a maximal decomposition of a causal dependency graph, where the activities associated with each edge in the causal dependency graph end up in one cluster.", "startOffset": 3, "endOffset": 7}, {"referenceID": 18, "context": "[20] describe an approach to make more coarse-grained activity clusters by recombining the clusters of the maximal decomposition by balancing three quality criteria: cohesion, coupling, and balance.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "Van der Aalst and Verbeek [21] introduced a", "startOffset": 26, "endOffset": 30}, {"referenceID": 20, "context": "[22] proposed a decomposed conformance checking approach that discovers clusters of activities based on identifying Single-Entry Single-", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "[23] describe an approach to generate overlap-", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "In a more recent paper Carmona [24]", "startOffset": 31, "endOffset": 35}, {"referenceID": 23, "context": "The episode miner [25] is a related technique to LPM discovery, which discovers patterns that are less expressive (i.", "startOffset": 18, "endOffset": 22}], "year": 2016, "abstractText": "Local Process Model (LPM) discovery is focused on the mining of a set of process models where each model describes the behavior represented in the event log only partially, i.e. subsets of possible events are taken into account to create socalled local process models. Often such smaller models provide valuable insights into the behavior of the process, especially when no adequate and comprehensible single overall process model exists that is able to describe the traces of the process from start to end. The practical application of LPM discovery is however hindered by computational issues in the case of logs with many activities (problems may already occur when there are more than 17 unique activities). In this paper, we explore three heuristics to discover subsets of activities that lead to useful log projections with the goal of speeding up LPM discovery considerably while still finding high-quality LPMs. We found that a Markov clustering approach to create projection sets results in the largest improvement of execution time, with discovered LPMs still being better than with the use of randomly generated activity sets of the same size. Another heuristic, based on log entropy, yields a more moderate speedup, but enables the discovery of higher quality LPMs. The third heuristic, based on the relative information gain, shows unstable performance: for some data sets the speedup and LPM quality are higher than with the log entropy based method, while for other data sets there is no speedup at all.", "creator": "LaTeX with hyperref package"}}}