{"id": "1610.03106", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Oct-2016", "title": "Supervised Term Weighting Metrics for Sentiment Analysis in Short Text", "abstract": "Term weighting metrics assign weights to terms in order to discriminate the important terms from the less crucial ones. Due to this characteristic, these metrics have attracted growing attention in text classification and recently in sentiment analysis. Using the weights given by such metrics could lead to more accurate document representation which may improve the performance of the classification. While previous studies have focused on proposing or comparing different weighting metrics at two-classes document level sentiment analysis, this study propose to analyse the results given by each metric in order to find out the characteristics of good and bad weighting metrics. Therefore we present an empirical study of fifteen global supervised weighting metrics with four local weighting metrics adopted from information retrieval, we also give an analysis to understand the behavior of each metric by observing and analysing how each metric distributes the terms and deduce some characteristics which may distinguish the good and bad metrics. The evaluation has been done using Support Vector Machine on three different datasets: Twitter, restaurant and laptop reviews.", "histories": [["v1", "Mon, 10 Oct 2016 21:52:47 GMT  (2464kb,D)", "http://arxiv.org/abs/1610.03106v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.IR cs.LG", "authors": ["hussam hamdan", "patrice bellot", "frederic bechet"], "accepted": false, "id": "1610.03106"}, "pdf": {"name": "1610.03106.pdf", "metadata": {"source": "CRF", "title": "Supervised Term Weighting Metrics for Sentiment Analysis in Short Text", "authors": ["Hussam Hamdan", "Patrice Bellot", "Frederic Bechet"], "emails": ["hussam.hamdan@lsis.org", "patrice.bellot@lsis.org", "frederic.bechet@lif.univ-mrs.fr"], "sections": [{"heading": "1 Introduction", "text": "This year, it has reached the stage where it will be able to take the lead."}, {"heading": "2 Research Objectives", "text": "To our knowledge, all of these studies have either compared some existing metrics or proposed a new one. However, they have not analyzed these metrics, they have not provided mathematical analysis or statistical analysis that could explain why one particular metric may be more useful than the others. In this study, we aim to understand why some metrics deliver good results and others do not. Mathematical analysis cannot give us a reasonable explanation. It seems that all metrics depend on the same components, but each metric presents them with its own method. Therefore, we propose to statistically analyze the metrics by examining how each metric distributes the words in the corpus and trying to derive some characteristics of the metrics that deliver good and bad results. Thus, with a metric and a corpus, we can estimate whether it is good or bad, depending on how it distributes the corpus."}, {"heading": "3 Related Work", "text": "A lot of term weighting methods have been proposed for information retrieval, all based on Salton's definition (Salton and Buckley, 1988), where term weighting is function of three factors: term frequency, inverse document frequency, and normalization. While term weighting methods are unsupervised in information retrieval, many supervised methods have been proposed in text classification, they have proven their efficiency in many studies (Debole and Sebastiani, 2003; Forman, 2003; Ren and Sohrab, 2013; Savoy, 2013; Sebastiani, 2002).Supervised classification methods have been reported for sentiment analysis, early work by Pang et al. (2002) that SVM outperforms other classifiers and binary term representation f."}, {"heading": "4 Term Weighting Metrics", "text": "In this section, we describe the weighting indicators for sentiment analysis. First, we describe the set of documents with D = {d1, d2,.., dn}, the set of classes C = {c1, c2,.., cm}, F = {f1, f2,..., fr} is the vocabulary defined in D. Document dj is represented by a sack-of-words vector: dj = (w1j, w2j,..., wlj), where wij stands for the weight of characteristics fi in document dj. In our weighting methods, wij is defined as a function of three factors: local weight, global weight and normalization factor. The final weight will be the product of these three components: wij = local weight."}, {"heading": "4.1 Local Weight", "text": "The local weighting of the term results from the frequency of the term within the document. Table 1 shows four local weighting indicators proposed in connection with information retrieval."}, {"heading": "4.2 Global Weight", "text": "The first and second, which can be found in the USA and other European countries, is found in the USA. (The second and third) The second and third, which can be found in the USA, is to be found in the USA. (The third and fourth) The third and fourth, which can be found in the USA. (The third and fourth) The third and fourth, which can be found in the USA, is to be found in the USA. (The third and fourth) The third and fourth, the third and fourth, can be found in the USA. (The third and fourth in the USA) The first and fourth in the USA, the second and fourth in the USA, the third and third in the USA, the third in the USA, the third in the USA, the third and fourth in the USA. (The third and fourth in the USA) The third and fourth in the USA. (The third and fourth in the USA) The third and fourth in the USA. (The third and fourth in the USA) The third and fourth in the USA."}, {"heading": "4.3 Normalization", "text": "The normalization of the document length adjusts the term score in order to normalize the influence of the document length on the document classification. The most well-known normalization factor in information retrieval is cosinal normalization, in which each term score is divided by the square root of the sum of all squared term values within the document.cosine = \u221a w2f1 + w 2 f2 +... + wfm 2"}, {"heading": "4.4 Score Aggregation", "text": "For each term in the corpus, we need a score as a weighting for that term. We can use various aggregation functions such as max, min, sum or weighted summary. In this study, we choose the maximum function that takes into account the maximum value of the term versus classes, this function reinforces the important terms in each class. If a term is important in a positive class or negative or neutral, it is more important to give it a high score. You can think about other functions, such as the score of the term in a negative class, positive or neutral, but we think that the maximum value is the best, as it has been widely applied. And the sum function may not be efficient if the metrics produce negative and positive values, including the weighted sum that takes into account the probability of the class, but this probability has already been taken into account within the majority of the redundancy, and therefore a metric one can arise."}, {"heading": "5 Datasets", "text": "In this section, we describe the three sets of data we used to evaluate the weighting metrics of the term: the first is extracted from Twitter, the second and third sets consist of restaurant or laptop ratings."}, {"heading": "5.1 Twitter Dataset", "text": "This dataset consists of Twitter messages compiled for SemEval-2013 Task 2 and SemEval-2014 Task 9. Participants were provided with a script for downloading 10,882 tweets commented on by their polarities (positive, negative, neutral), which will be provided for the SemEval workshop 2014, the task being to determine whether the tweet is positive, negative or neutral. Statistics on this dataset are listed in Table 3 # pos, # neg, # again, # total, lAvg: the number of positive documents, the number of neutral documents, the total number of documents, the average length of the document (the average number of tokens in the document)."}, {"heading": "5.2 Restaurant and Laptop Reviews Datasets", "text": "The second data set comes from restaurant and laptop ratings provided by SemEval 2015 ABSA organizers (Pontiki et al., 2015), where each rating consists of several sets and each set can contain multiple opinion target expressions. Statistics on these data sets are shown in Table 3."}, {"heading": "6 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.1 Experiment Setup", "text": "We only use unigrams as traits without root or word spacing for the three datasets, all terms are used regardless of their occurrence in the corpus. Support Vector Machine (SVM) is used as classifier, SVM was widely used in sentiment classification because its performance outperforms other machine learners (Pang et al., 2002). We trained an L2-regulated linear L2 loss SVM using the implementation of LIBLINEAR (Fan et al., 2008), where all parameters are set to their default values. L2-regulated and L2-loss provide higher performance than other regulation techniques and were used in most previous studies. For each dataset, we first tokenized the text to obtain the terms, then assigned a score with each metric for each term, with four classifiers trained for each dataset \u2212 for each global metric value, i.e. one globalizer for each local classifier."}, {"heading": "6.2 Experiment Evaluations", "text": "This year it will be so far that it will be able to use the mentionlcihsrcnlrVo rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf"}, {"heading": "7 Conclusion and Future Work", "text": "We have studied fifteen different metrics of global weighting and four local metrics, using three metrics for evaluation. While our experimental results show that these metrics improve polarity classification, there is no best choice for all metrics, several global metrics seem to work well with all metrics such as rf, kl, wllr and the local metrics, especially tf and atf. We have analyzed how each metric distributes the corpus to derive the characteristics of the good and bad metrics. We have found that the bad metrics tend to have a narrow distribution with an average close to zero, but we have not been able to derive some common characteristics among the metrics that provide the best results. In future work, we will examine the normalization and the combination of the metrics of the term weighting."}], "references": [{"title": "Feature selection for text classification with N\u00e4\u0131ve Bayes", "author": ["J. Chen", "H. Huang", "S. Tian", "Y. Qu"], "venue": "Expert Systems with Applications,", "citeRegEx": "Chen et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2009}, {"title": "Word Association Norms, Mutual Information, and Lexicography", "author": ["K.W. Church", "P. Hanks"], "venue": null, "citeRegEx": "Church and Hanks,? \\Q1990\\E", "shortCiteRegEx": "Church and Hanks", "year": 1990}, {"title": "Supervised Term Weighting for Automated Text Categorization", "author": ["F. Debole", "F. Sebastiani"], "venue": "In Proceedings of the 2003 ACM Symposium on Applied Computing,", "citeRegEx": "Debole and Sebastiani,? \\Q2003\\E", "shortCiteRegEx": "Debole and Sebastiani", "year": 2003}, {"title": "A study of supervised term weighting scheme for sentiment analysis", "author": ["Deng", "Z.-H", "Luo", "K.-H", "Yu", "H.-L"], "venue": "Expert Systems with Applications,", "citeRegEx": "Deng et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Deng et al\\.", "year": 2014}, {"title": "LIBLINEAR: A Library for Large Linear Classification", "author": ["Fan", "R.-E", "Chang", "K.-W", "Hsieh", "C.-J", "Wang", "X.-R", "Lin"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Fan et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Fan et al\\.", "year": 2008}, {"title": "An Extensive Empirical Study of Feature Selection Metrics for Text Classification", "author": ["G. Forman"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Forman,? \\Q2003\\E", "shortCiteRegEx": "Forman", "year": 2003}, {"title": "Combining supervised term-weighting metrics for SVM text classification with extended term representation", "author": ["M. Haddoud", "A. Mokhtari", "T. Lecroq", "S. Abdedd\u00e4\u0131m"], "venue": "Knowledge and Information Systems,", "citeRegEx": "Haddoud et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Haddoud et al\\.", "year": 2016}, {"title": "The Impact of Z score on Twitter Sentiment Analysis", "author": ["H. Hamdan", "P. Bellot", "F. Bechet"], "venue": "Proceedings of the Eighth International Workshop on Semantic Evaluation (SemEval", "citeRegEx": "Hamdan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hamdan et al\\.", "year": 2014}, {"title": "Supervised and Traditional Term Weighting Methods for Automatic Text Categorization", "author": ["M. Lan", "C.L. Tan", "J. Su", "Y. Lu"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell.,", "citeRegEx": "Lan et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Lan et al\\.", "year": 2009}, {"title": "Delta TFIDF: An Improved Feature Space for Sentiment Analysis", "author": ["J. Martineau", "T. Finin"], "venue": "In ICWSM,", "citeRegEx": "Martineau and Finin,? \\Q2009\\E", "shortCiteRegEx": "Martineau and Finin", "year": 2009}, {"title": "SemEval-2013 Task 2: Sentiment Analysis in Twitter", "author": ["P. Nakov", "S. Rosenthal", "Z. Kozareva", "V. Stoyanov", "A. Ritter", "T. Wilson"], "venue": "In Second Joint Conference on Lexical and Computational Semantics (*SEM),", "citeRegEx": "Nakov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Nakov et al\\.", "year": 2013}, {"title": "Feature Selection, Perceptron Learning, and a Usability Case Study for Text Categorization", "author": ["H.T. Ng", "W.B. Goh", "K.L. Low"], "venue": "In Proceedings of the 20th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,", "citeRegEx": "Ng et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Ng et al\\.", "year": 1997}, {"title": "Comparison of Feature Selection Methods for Sentiment Analysis", "author": ["C. Nicholls", "F. Song"], "venue": "Advances in Artificial Intelligence,", "citeRegEx": "Nicholls and Song,? \\Q2010\\E", "shortCiteRegEx": "Nicholls and Song", "year": 2010}, {"title": "Text Classification from Labeled and Unlabeled Documents Using EM", "author": ["K. Nigam", "A.K. McCallum", "S. Thrun", "T. Mitchell"], "venue": "Machine Learning,", "citeRegEx": "Nigam et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Nigam et al\\.", "year": 2000}, {"title": "A Study of Information Retrieval Weighting Schemes for Sentiment Analysis", "author": ["G. Paltoglou", "M. Thelwall"], "venue": "In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Paltoglou and Thelwall,? \\Q2010\\E", "shortCiteRegEx": "Paltoglou and Thelwall", "year": 2010}, {"title": "Thumbs Up?: Sentiment Classification Using Machine Learning Techniques", "author": ["B. Pang", "L. Lee", "S. Vaithyanathan"], "venue": "In Proceedings of the ACL-02 Conference on Empirical Methods in Natural Language Processing - Volume 10,", "citeRegEx": "Pang et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Pang et al\\.", "year": 2002}, {"title": "SemEval-2015 Task 12: Aspect Based Sentiment Analysis", "author": ["M. Pontiki", "D. Galanis", "H. Papageogiou", "S. Manandhar", "I. Androutsopoulos"], "venue": "Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval", "citeRegEx": "Pontiki et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Pontiki et al\\.", "year": 2015}, {"title": "Relative discrimination criterion - A novel feature ranking method for text data", "author": ["A. Rehman", "K. Javed", "H.A. Babri", "M. Saeed"], "venue": "Expert Systems with Applications,", "citeRegEx": "Rehman et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Rehman et al\\.", "year": 2015}, {"title": "Class-indexing-based term weighting for automatic text classification", "author": ["F. Ren", "M.G. Sohrab"], "venue": "Information Sciences,", "citeRegEx": "Ren and Sohrab,? \\Q2013\\E", "shortCiteRegEx": "Ren and Sohrab", "year": 2013}, {"title": "Term-weighting approaches in automatic text retrieval", "author": ["G. Salton", "C. Buckley"], "venue": "Information Processing & Management,", "citeRegEx": "Salton and Buckley,? \\Q1988\\E", "shortCiteRegEx": "Salton and Buckley", "year": 1988}, {"title": "Authorship Attribution Based on Specific Vocabulary", "author": ["J. Savoy"], "venue": "Transactions on Information Systems (TOIS),", "citeRegEx": "Savoy,? \\Q2012\\E", "shortCiteRegEx": "Savoy", "year": 2012}, {"title": "Feature Selections for Authorship Attribution", "author": ["J. Savoy"], "venue": "In Proceedings of the 28th Annual ACM Symposium on Applied Computing,", "citeRegEx": "Savoy,? \\Q2013\\E", "shortCiteRegEx": "Savoy", "year": 2013}, {"title": "Machine Learning in Automated Text Categorization", "author": ["F. Sebastiani"], "venue": "Computing Surveys (CSUR),", "citeRegEx": "Sebastiani,? \\Q2002\\E", "shortCiteRegEx": "Sebastiani", "year": 2002}, {"title": "Term-relevance Computations and Perfect Retrieval Performance", "author": ["Shaw", "W.M. Jr."], "venue": "IInformation Processing and Management,", "citeRegEx": "Shaw and Jr.,? \\Q1995\\E", "shortCiteRegEx": "Shaw and Jr.", "year": 1995}, {"title": "Categorical Proportional Difference: A Feature Selection Method for Text Categorization", "author": ["M. Simeon", "R. Hilderman"], "venue": "In Proceedings of the 7th Australasian Data Mining Conference - Volume 87,", "citeRegEx": "Simeon and Hilderman,? \\Q2008\\E", "shortCiteRegEx": "Simeon and Hilderman", "year": 2008}, {"title": "Reducing Over-Weighting in Supervised Term Weighting for Sentiment Analysis", "author": ["H. Wu", "X. Gu"], "venue": "COLING", "citeRegEx": "Wu and Gu,? \\Q2014\\E", "shortCiteRegEx": "Wu and Gu", "year": 2014}, {"title": "A Comparative Study on Feature Selection in Text Categorization", "author": ["Y. Yang", "J.O. Pedersen"], "venue": "In Proceedings of the Fourteenth International Conference on Machine Learning,", "citeRegEx": "Yang and Pedersen,? \\Q1997\\E", "shortCiteRegEx": "Yang and Pedersen", "year": 1997}], "referenceMentions": [{"referenceID": 9, "context": "Some metrics have been adopted from information retrieval such as DeltaIDF (Martineau and Finin, 2009; Paltoglou and Thelwall, 2010), later on several metrics have been proposed involving those adopted from information theory and widely used in text classification such as information gain and Mutual Information (Deng et al.", "startOffset": 75, "endOffset": 132}, {"referenceID": 14, "context": "Some metrics have been adopted from information retrieval such as DeltaIDF (Martineau and Finin, 2009; Paltoglou and Thelwall, 2010), later on several metrics have been proposed involving those adopted from information theory and widely used in text classification such as information gain and Mutual Information (Deng et al.", "startOffset": 75, "endOffset": 132}, {"referenceID": 3, "context": "Some metrics have been adopted from information retrieval such as DeltaIDF (Martineau and Finin, 2009; Paltoglou and Thelwall, 2010), later on several metrics have been proposed involving those adopted from information theory and widely used in text classification such as information gain and Mutual Information (Deng et al., 2014).", "startOffset": 313, "endOffset": 332}, {"referenceID": 12, "context": "In sentiment analysis, the early work by Pang et al. (2002) reported that binary weight schema outperforms the term frequency.", "startOffset": 41, "endOffset": 60}, {"referenceID": 3, "context": "Some metrics have been adopted from information retrieval such as DeltaIDF (Martineau and Finin, 2009; Paltoglou and Thelwall, 2010), later on several metrics have been proposed involving those adopted from information theory and widely used in text classification such as information gain and Mutual Information (Deng et al., 2014). Recently, Wu and Gu (2014) also tested several methods adopted from information retrieval and information theory, they also proposed a new metric called natural entropy (ne) inspired from information theory.", "startOffset": 314, "endOffset": 361}, {"referenceID": 14, "context": "This general definition of term weight is used in (Paltoglou and Thelwall, 2010).", "startOffset": 50, "endOffset": 80}, {"referenceID": 3, "context": "While Deng et al. (2014); Wu and Gu (2014) considered that a supervised term weighting schema based on two basic factors: Importance of a Term in a Document (ITD) and Importance of a Term for expressing Sentiment (ITS), the ITD is exactly the local factor, ITS is the global factor in the general definition of term weighting.", "startOffset": 6, "endOffset": 25}, {"referenceID": 3, "context": "While Deng et al. (2014); Wu and Gu (2014) considered that a supervised term weighting schema based on two basic factors: Importance of a Term in a Document (ITD) and Importance of a Term for expressing Sentiment (ITS), the ITD is exactly the local factor, ITS is the global factor in the general definition of term weighting.", "startOffset": 6, "endOffset": 43}, {"referenceID": 10, "context": "Theses metrics are evaluated on three datasets provided in SemEval tasks: Sentiment Analysis in Twitter (Nakov et al., 2013) and Aspect-Based Sentiment Analysis (Pontiki et al.", "startOffset": 104, "endOffset": 124}, {"referenceID": 16, "context": ", 2013) and Aspect-Based Sentiment Analysis (Pontiki et al., 2015).", "startOffset": 44, "endOffset": 66}, {"referenceID": 19, "context": "A lot of term weighting methods have been proposed for Information Retrieval, all based on Salton\u2019s definition (Salton and Buckley, 1988) where term weight is function of three factors: term frequency, inverse document frequency, and normalization.", "startOffset": 111, "endOffset": 137}, {"referenceID": 2, "context": "While the term weighting methods in Information Retrieval are unsupervised, many supervised methods have been proposed in Text Classification, they have proved their efficiency in many studies (Debole and Sebastiani, 2003; Forman, 2003; Ren and Sohrab, 2013; Savoy, 2013; Sebastiani, 2002).", "startOffset": 193, "endOffset": 289}, {"referenceID": 5, "context": "While the term weighting methods in Information Retrieval are unsupervised, many supervised methods have been proposed in Text Classification, they have proved their efficiency in many studies (Debole and Sebastiani, 2003; Forman, 2003; Ren and Sohrab, 2013; Savoy, 2013; Sebastiani, 2002).", "startOffset": 193, "endOffset": 289}, {"referenceID": 18, "context": "While the term weighting methods in Information Retrieval are unsupervised, many supervised methods have been proposed in Text Classification, they have proved their efficiency in many studies (Debole and Sebastiani, 2003; Forman, 2003; Ren and Sohrab, 2013; Savoy, 2013; Sebastiani, 2002).", "startOffset": 193, "endOffset": 289}, {"referenceID": 21, "context": "While the term weighting methods in Information Retrieval are unsupervised, many supervised methods have been proposed in Text Classification, they have proved their efficiency in many studies (Debole and Sebastiani, 2003; Forman, 2003; Ren and Sohrab, 2013; Savoy, 2013; Sebastiani, 2002).", "startOffset": 193, "endOffset": 289}, {"referenceID": 22, "context": "While the term weighting methods in Information Retrieval are unsupervised, many supervised methods have been proposed in Text Classification, they have proved their efficiency in many studies (Debole and Sebastiani, 2003; Forman, 2003; Ren and Sohrab, 2013; Savoy, 2013; Sebastiani, 2002).", "startOffset": 193, "endOffset": 289}, {"referenceID": 12, "context": "Supervised classification methods have been widely used for sentiment analysis, early work by Pang et al. (2002) reported that SVM outperforms other classifiers and the binary term representation also outperforms term frequency.", "startOffset": 94, "endOffset": 113}, {"referenceID": 8, "context": "Recently, research has focused on more efficient term weighting methods to improve the performance of sentiment analysis, Martineau and Finin (2009) proposed Delta tf*idf in which the final term weight is the difference between tf*idf in positive class and negative class, their experiments have been done on two-class classification.", "startOffset": 122, "endOffset": 149}, {"referenceID": 8, "context": "Recently, research has focused on more efficient term weighting methods to improve the performance of sentiment analysis, Martineau and Finin (2009) proposed Delta tf*idf in which the final term weight is the difference between tf*idf in positive class and negative class, their experiments have been done on two-class classification. Later on, Paltoglou and Thelwall (2010) studied some variants of the classic tf*idf schema adapted to sentiment analysis which provides significant improvement in terms of accuracy.", "startOffset": 122, "endOffset": 375}, {"referenceID": 3, "context": "Deng et al. (2014) presented several supervised weighting metrics adopted from information theory and TC.", "startOffset": 0, "endOffset": 19}, {"referenceID": 3, "context": "Deng et al. (2014) presented several supervised weighting metrics adopted from information theory and TC. Wu and Gu (2014) reviewed several existing weighting metrics in SA, they found that existing methods suffer from over-weighting, thus they proposed two regularization techniques, singular term cutting and bias term in addition to a new weighting metric called natural entropy (ne) adopted from information theory.", "startOffset": 0, "endOffset": 123}, {"referenceID": 12, "context": "Document Frequency Difference was proposed to automatically identify the words which are more useful for classifying sentiment (Nicholls and Song, 2010).", "startOffset": 127, "endOffset": 152}, {"referenceID": 11, "context": "Document Frequency Difference was proposed to automatically identify the words which are more useful for classifying sentiment (Nicholls and Song, 2010). Savoy (2013) combined different weighting metrics to select the most important features.", "startOffset": 128, "endOffset": 167}, {"referenceID": 11, "context": "Document Frequency Difference was proposed to automatically identify the words which are more useful for classifying sentiment (Nicholls and Song, 2010). Savoy (2013) combined different weighting metrics to select the most important features. Rehman et al. (2015) have proposed a new feature ranking metric termed as relative discrimination criterion (RDC), which takes document frequencies for each term count of a term into account while estimating the usefulness of a term.", "startOffset": 128, "endOffset": 264}, {"referenceID": 6, "context": "Haddoud et al. (2016) have studied 96 term-weighting metrics, and among them 80 metrics have not been used.", "startOffset": 0, "endOffset": 22}, {"referenceID": 9, "context": "Delta Smoothed IDF (dsidf) dsidf boosts the importance of terms that are unevenly distributed between one category and other categories and discounts evenly distributed words, the original version Delta TF-IDF is presented in (Martineau and Finin, 2009),", "startOffset": 226, "endOffset": 253}, {"referenceID": 14, "context": "the smoothed version seems to be more efficient (Paltoglou and Thelwall, 2010).", "startOffset": 48, "endOffset": 78}, {"referenceID": 14, "context": "Delta BM25 IDF (dbidf) dbidf is a variant of the dsidf metric, BM25-IDF variant is used instead of classical IDF (Paltoglou and Thelwall, 2010).", "startOffset": 113, "endOffset": 143}, {"referenceID": 8, "context": "Relevance Frequency (rf) rf boosts the terms which have high frequency in the positive category, that helps in selecting the positive samples from the negative ones Lan et al. (2009).", "startOffset": 165, "endOffset": 183}, {"referenceID": 26, "context": "Information Gain (ig) ig Yang and Pedersen (1997) tries to find out how well each single feature separates the given dataset.", "startOffset": 25, "endOffset": 50}, {"referenceID": 1, "context": "Pairwise Mutual Information (pmi) pmi is a measure of association used in information theory and statistics, it measures how much the feature associates with the class (Church and Hanks, 1990).", "startOffset": 168, "endOffset": 192}, {"referenceID": 25, "context": "Natural Entropy (ne) The basics beyond ne (Wu and Gu, 2014) is the more uneven the distribution of documents where a feature occurs, the larger the weight of this feature is.", "startOffset": 42, "endOffset": 59}, {"referenceID": 26, "context": "Chi Square \u03c7 (chi) chi (Yang and Pedersen, 1997) measures the lack of independence between the feature and the category, the higher value of the \u03c7, the closer relationship the feature and the class have.", "startOffset": 23, "endOffset": 48}, {"referenceID": 11, "context": "NGL Coefficient (ngl) ngl is a variant of the Chi square metric (Ng et al., 1997).", "startOffset": 64, "endOffset": 81}, {"referenceID": 0, "context": "Class Discrimination Measure (cdm) cdm measures the difference between the distribution of the feature in one class and other classes (Chen et al., 2009).", "startOffset": 134, "endOffset": 153}, {"referenceID": 24, "context": "Categorical Proportional Difference (cpd) cpd is a ratio that considers the number of documents of a category in which the feature occurs and the number of documents from other categories in which the feature also occurs (Simeon and Hilderman, 2008).", "startOffset": 221, "endOffset": 249}, {"referenceID": 7, "context": "Multinomial Z Score (zd) zd supposes that a feature follows binomial distribution, calculates Z transformation for a feature in each class, zd boosts the highly unevenly distributed features among the classes, it gives high positive score for a feature in the class where it is highly frequent and negative score in the class where it rarely appears (Hamdan et al., 2014; Savoy, 2012).", "startOffset": 350, "endOffset": 384}, {"referenceID": 20, "context": "Multinomial Z Score (zd) zd supposes that a feature follows binomial distribution, calculates Z transformation for a feature in each class, zd boosts the highly unevenly distributed features among the classes, it gives high positive score for a feature in the class where it is highly frequent and negative score in the class where it rarely appears (Hamdan et al., 2014; Savoy, 2012).", "startOffset": 350, "endOffset": 384}, {"referenceID": 13, "context": "Weighted Log Likelihood Ratio(wllr) wllr is a measure of how dissimilar are the distribution of the feature given the category and the distribution of the feature given the other categories (Nigam et al., 2000).", "startOffset": 190, "endOffset": 210}, {"referenceID": 16, "context": "The second dataset is extracted from restaurant and laptop reviews, provided by SemEval 2015 ABSA organizers (Pontiki et al., 2015) where each review is composed of several sentences and each sentence may contain several Opinion Target Expressions.", "startOffset": 109, "endOffset": 131}, {"referenceID": 15, "context": "Support Vector Machine (SVM) is used as classifier, SVM has been widely used in sentiment classification because its performance exceeds other machine learners (Pang et al., 2002).", "startOffset": 160, "endOffset": 179}, {"referenceID": 4, "context": "We trained a L2-regularized L2-loss linear SVM using the implementation of LIBLINEAR (Fan et al., 2008) where all parameters are set to their default values.", "startOffset": 85, "endOffset": 103}, {"referenceID": 25, "context": "Thus, a metric with a narrow distribution and a mean value close to zero seems to be a bad one, therefore we can give an explanation of why the bias term has been efficient in (Wu and Gu, 2014) where the authors found that adding a bias", "startOffset": 176, "endOffset": 193}], "year": 2016, "abstractText": "Term weighting metrics assign weights to terms in order to discriminate the important terms from the less crucial ones. Due to this characteristic, these metrics have attracted growing attention in text classification and recently in sentiment analysis. Using the weights given by such metrics could lead to more accurate document representation which may improve the performance of the classification. While previous studies have focused on proposing or comparing different weighting metrics at two-classes document level sentiment analysis, this study propose to analyse the results given by each metric in order to find out the characteristics of good and bad weighting metrics. Therefore we present an empirical study of fifteen global supervised weighting metrics with four local weighting metrics adopted from information retrieval, we also give an analysis to understand the behavior of each metric by observing and analysing how each metric distributes the terms and deduce some characteristics which may distinguish the good and bad metrics. The evaluation has been done using Support Vector Machine on three different datasets: Twitter, restaurant and laptop reviews.", "creator": "LaTeX with hyperref package"}}}