{"id": "1610.03120", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Oct-2016", "title": "Correlation-Based Method for Sentiment Classification", "abstract": "The classic supervised classification algorithms are efficient, but time-consuming, complicated and not interpretable, which makes it difficult to analyze their results that limits the possibility to improve them based on real observations. In this paper, we propose a new and a simple classifier to predict a sentiment label of a short text. This model keeps the capacity of human interpret-ability and can be extended to integrate NLP techniques in a more interpretable way. Our model is based on a correlation metric which measures the degree of association between a sentiment label and a word. Ten correlation metrics are proposed and evaluated intrinsically. And then a classifier based on each metric is proposed, evaluated and compared to the classic classification algorithms which have proved their performance in many studies. Our model outperforms these algorithms with several correlation metrics.", "histories": [["v1", "Mon, 10 Oct 2016 22:35:21 GMT  (904kb,D)", "http://arxiv.org/abs/1610.03120v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.IR", "authors": ["hussam hamdan"], "accepted": false, "id": "1610.03120"}, "pdf": {"name": "1610.03120.pdf", "metadata": {"source": "CRF", "title": "Correlation-Based Method for Sentiment Classification", "authors": ["Hussam Hamdan"], "emails": ["Hussam.Hamdan@lip6.fr"], "sections": [{"heading": "1 Introduction", "text": "This year it is so far that it will be able to reset the mentionlcihsrcsrteeSi rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rfu the rf\u00fc the rf\u00fc the rfu the rf\u00fc the rfu the rfu the rfu the rfu the rfu the rfu the rfu the rfu the rfu the rfu the r"}, {"heading": "2 Related Work", "text": "In the sensation analysis, some metrics were used in two scenarios: (1) to measure the previous polarity of the words to use for sensation classification or sensation dictionary construction; (2) to calculate a term weight to incorporate into the document representation for SVM classifiers; the first scenario was used in an unattended context, but the second is supervised; the early work (Turney, 2002) estimated the sensation orientation (SO) of the extracted phrases using the Pointwise Mutual Information (PMI); the sensation orientation of a phrase is based on its association with the positive reference word \"excellent\" and the negative word \"poor.\" Authors in (Turney and Littman, 2003) used SO to calculate the sensation orientation of a given word; they calculated the metric based on its strength with the positive reference word \"excellent,\" with \"excellent strength,\" a \"good sentence.\""}, {"heading": "3 Correlation Metrics", "text": "The correlation metrics measures the degree of association with positive, negative and neutral feeling. (That's why it's come so far.) (That's why it's come so far.) (That's why it's come so far. (That's why it's come so far.) (That's why it's come so far.) (That's why it's come so far.) (That's why it's come so far.) (It's why it's come so far.) (It's why it's come so far.) (It's why it's come so far.) (It's why it's come so far.) (It's why it's come so far.) (It's why it's come so far.) (It's why it's come so far.)"}, {"heading": "4 Correlation-Based Model", "text": "In this section, we present our model, which directly relates each short instance of text to a sentiment label. As a short instance of text designated by s relates to a sentiment label sl, we can measure the final polarity value of a short text as the sum value of its words based on the correlation of the words that overlap in the training sentence and the sentence s. Thus, for each correlation metric that measures the degree of association of each word with each sentiment label, we calculate the final polarity value of a short text as the sum value of its words. To calculate the sum point number of a sentence in a sentiment label or class i, we add the score of the sentence words happy, then the sentence is associated with the sentiment label that has the highest sum number of points. To calculate the sum point number of a sentence in a sentiment label or class i, we add the score of the sentence words. The correlation between s and splanned metric is calculated from positive metric (core =) as (crik = (i), (0,i)."}, {"heading": "5 Experiments and Evaluations", "text": "To test our proposed model, we perform two types of evaluations: intrinsic and extrinsic. For intrinsic evaluation, we test the performance of the proposed correlation metrics, so we compare the degree of previous polarity with a manually annotated list of Twitter terms. To test our model, an extrinsic evaluation is performed using two short text datasets in which we calculate the correlation values based on the training set of each dataset."}, {"heading": "5.1 Training and Testing Data", "text": "We used two sets of data, the first of which comes from Twitter, which was provided in SemEval 2013 for subdivision B of Mood Analysis on Twitter (Nakov et al., 2013). Participants received training tests with positive, negative or neutral comments. We downloaded these tweets with the specified script. We received 9646 tweets, the entire training set is used for training. The test data set provided in SemEval 2015, with approximately 2390 tweets (Rosenthal et al., 2015), is used to evaluate our system. The second data set comes from laptop views provided by SemEval 2015 ABSA organizers (Pontiki et al., 2015), where each review consists of several sets and participants are asked to recognize the polarity of each broadcast. Table 1 shows the distribution of each label in each data set."}, {"heading": "5.2 Correlation Metrics Evaluation", "text": "A ranking of Twitter terms derived from human annotations was provided by the organizers of SemEval-2015 (Rosenthal et al., 2015), the original ranking contains 1315 terms, we used only 552 terms that exist in our training dataset. We first calculate the value of each term as a result of correlation with positive mood minus the value of correlation with the negative and neural terms, and then compare this ranking with the human commented. Kendall's tau and Spearman are used as metrics to compare the rankings. Table 2 shows the results for each metric with Kendall and Spearman. Kl gives the highest correlation 64% followed by cpd and rf 44%, then or r metrically with 43% with Kendall's Tau.Note that multiple metrics provide the same results, so that kmi, zd. Therefore, we measure the correlation between each pair, followed by cpd and rf 44%, then consider the same correlation with Kendall's Taurus, each yielding 43% with several metrical results, zd."}, {"heading": "5.3 Correlation-Based Model Evaluation", "text": "In fact, most of us are able to play by the rules we have set ourselves, \"he said in an interview with Welt am Sonntag newspaper."}, {"heading": "6 Conclusion", "text": "In this paper, we presented ten correlation metrics for measuring the correlation between words and sentiment labels, and then proposed a classification model based on correlation metrics; we evaluated the metrics per se based on a ranking of Twitter terms, and the proposed model was evaluated based on two short sets of text data from Twitter and laptop reviews; the proposed model appears to provide good results, outperforming some classical monitored algorithms with some correlation metrics; the results of the model can be interpreted and analyzed to improve it in a smart way; in the next paper, we plan to explore how we can combine the NLP techniques in our model to take into account negation, reversaries, and modifiers; and we plan to combine noisy marked or unmarked data that can help to obtain more robust correlation values."}], "references": [{"title": "Word association norms, mutual information, and lexicography", "author": ["Church", "Patrick Hanks"], "venue": null, "citeRegEx": "Church et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Church et al\\.", "year": 1990}, {"title": "A study of supervised term weighting scheme for sentiment analysis", "author": ["Deng et al.2014] Zhi-Hong Deng", "Kun-Hu Luo", "Hong-Liang Yu"], "venue": null, "citeRegEx": "Deng et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Deng et al\\.", "year": 2014}, {"title": "Twitter sentiment classification using distant supervision", "author": ["Go et al.2009] Alec Go", "Richa Bhayani", "Lei Huang"], "venue": null, "citeRegEx": "Go et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Go et al\\.", "year": 2009}, {"title": "The impact of z score on twitter sentiment analysis", "author": ["Hamdan et al.2014] Hussam Hamdan", "Patrice Bellot", "Frederic Bechet"], "venue": "Proceedings of the Eighth International Workshop on Semantic Evaluation (SemEval", "citeRegEx": "Hamdan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hamdan et al\\.", "year": 2014}, {"title": "Sentiment lexiconbased features for sentiment analysis in short text", "author": ["Hamdan et al.2015] Hussam Hamdan", "Patrice Bellot", "Frederic Bechet"], "venue": "Proceeding of the 16th International Conference on Intelligent Text Processing and Computa-", "citeRegEx": "Hamdan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Hamdan et al\\.", "year": 2015}, {"title": "Supervised and traditional term weighting methods for automatic text categorization", "author": ["Lan et al.2009] Man Lan", "Chew Lim Tan", "Jian Su", "Yue Lu"], "venue": null, "citeRegEx": "Lan et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Lan et al\\.", "year": 2009}, {"title": "Delta TFIDF: An improved feature space for sentiment analysis", "author": ["Martineau", "Finin2009] Justin Martineau", "Tim Finin"], "venue": null, "citeRegEx": "Martineau et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Martineau et al\\.", "year": 2009}, {"title": "NRCCanada: Building the state-of-the-art in sentiment analysis of tweets", "author": ["Svetlana Kiritchenko", "Xiaodan Zhu"], "venue": "Proceedings of the International Workshop on Semantic Evaluation,", "citeRegEx": "Mohammad et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mohammad et al\\.", "year": 2013}, {"title": "emotional tweets. In *SEM 2012: The First Joint Conference on Lexical and Computational Semantics Volume 1: Proceedings of the main conference and the shared task, and Volume", "author": ["Saif Mohammad"], "venue": "Proceedings of the Sixth In-", "citeRegEx": "Mohammad.,? \\Q2012\\E", "shortCiteRegEx": "Mohammad.", "year": 2012}, {"title": "SemEval-2013 task 2: Sentiment analysis in twitter", "author": ["Nakov et al.2013] Preslav Nakov", "Sara Rosenthal", "Zornitsa Kozareva", "Veselin Stoyanov", "Alan Ritter", "Theresa Wilson"], "venue": "In Second Joint Conference on Lexical and Computational Semantics (*SEM),", "citeRegEx": "Nakov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Nakov et al\\.", "year": 2013}, {"title": "Feature selection, perceptron learning, and a usability case study for text categorization", "author": ["Ng et al.1997] Hwee Tou Ng", "Wei Boon Goh", "Kok Leong Low"], "venue": "In Proceedings of the 20th Annual International ACM SIGIR Conference on Research and", "citeRegEx": "Ng et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Ng et al\\.", "year": 1997}, {"title": "Text classification from labeled and unlabeled documents using EM", "author": ["Nigam et al.2000] Kamal Nigam", "Andrew Kachites McCallum", "Sebastian Thrun", "Tom Mitchell"], "venue": null, "citeRegEx": "Nigam et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Nigam et al\\.", "year": 2000}, {"title": "A study of information retrieval weighting schemes for sentiment analysis", "author": ["Paltoglou", "Thelwall2010] Georgios Paltoglou", "Mike Thelwall"], "venue": "In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Paltoglou et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Paltoglou et al\\.", "year": 2010}, {"title": "Thumbs up?: Sentiment classification using machine learning techniques", "author": ["Pang et al.2002] Bo Pang", "Lillian Lee", "Shivakumar Vaithyanathan"], "venue": "In Proceedings of the ACL-02 Conference on Empirical Methods in Natural Language Processing", "citeRegEx": "Pang et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Pang et al\\.", "year": 2002}, {"title": "SemEval-2015 task 12: Aspect based sentiment analysis", "author": ["Dimitrios Galanis", "Haris Papageogiou", "Suresh Manandhar", "Ion Androutsopoulos"], "venue": "Proceedings of the 9th International Workshop on Semantic Evalu-", "citeRegEx": "Pontiki et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Pontiki et al\\.", "year": 2015}, {"title": "SemEval-2015 task 10: Sentiment analysis in twitter", "author": ["Preslav Nakov", "Svetlana Kiritchenko", "Saif M. Mohammad", "Alan Ritter", "Veselin Stoyanov"], "venue": "In Proceedings of the 9th International Workshop on Semantic", "citeRegEx": "Rosenthal et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Rosenthal et al\\.", "year": 2015}, {"title": "Term-relevance computations and perfect retrieval performance", "author": ["W.M. Shaw", "Jr."], "venue": null, "citeRegEx": "Shaw and Jr.,? \\Q1995\\E", "shortCiteRegEx": "Shaw and Jr.", "year": 1995}, {"title": "Categorical proportional difference: A feature selection method for text categorization", "author": ["Simeon", "Hilderman2008] Mondelle Simeon", "Robert Hilderman"], "venue": "In Proceedings of the 7th Australasian Data Mining Conference - Volume", "citeRegEx": "Simeon et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Simeon et al\\.", "year": 2008}, {"title": "Measuring praise and criticism: Inference of semantic orientation from association", "author": ["Turney", "Littman2003] Peter D. Turney", "Michael L. Littman"], "venue": null, "citeRegEx": "Turney et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Turney et al\\.", "year": 2003}, {"title": "Thumbs up or thumbs down?: Semantic orientation applied to unsupervised classification of reviews", "author": ["Peter D. Turney"], "venue": "In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics,", "citeRegEx": "Turney.,? \\Q2002\\E", "shortCiteRegEx": "Turney.", "year": 2002}, {"title": "Reducing over-weighting in supervised term weighting for sentiment analysis", "author": ["Wu", "Gu2014] Haibing Wu", "Xiaodong Gu"], "venue": "COLING", "citeRegEx": "Wu et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Wu et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 19, "context": "The early work (Turney, 2002) estimated the sentiment orientation (SO) of the extracted phrases using the Pointwise Mutual Information (PMI).", "startOffset": 15, "endOffset": 29}, {"referenceID": 8, "context": "In (Mohammad, 2012) Authors collected a set of 775,000 tweets to generate a large word-sentiment association lexicon; a tweet was considered positive if it has one of 32 positive hashtagged seed words, and negative if it has one of 36 negative hashtagged seed words; the association score for a term was calculated using SO.", "startOffset": 3, "endOffset": 19}, {"referenceID": 7, "context": "Authors in (Mohammad et al., 2013) used similar method on the sentiment140 corpus (Go et al.", "startOffset": 11, "endOffset": 34}, {"referenceID": 2, "context": ", 2013) used similar method on the sentiment140 corpus (Go et al., 2009), a collection of", "startOffset": 55, "endOffset": 72}, {"referenceID": 13, "context": "(Pang et al., 2002) reported that binary weight schema provides good accuracy with SVM, recent research has focused on more complex weighting schema which called supervised weighting metrics ,as they exploit the categorical information,", "startOffset": 0, "endOffset": 19}, {"referenceID": 1, "context": "on several metrics have been proposed involving those adopted from information theory and widely used in text classification such as IG (information gain), MI (Mutual Information) (Deng et al., 2014).", "startOffset": 180, "endOffset": 199}, {"referenceID": 3, "context": "Some research has used some metrics as Z score for feature extraction as in (Hamdan et al., 2014).", "startOffset": 76, "endOffset": 97}, {"referenceID": 4, "context": "Therefore, authors in (Hamdan et al., 2015) have used the dfc and dfc\u0304 for discriminating the positive words from the negative ones; if dfc>dfc\u0304 then the word is considered positive else it is considered negative.", "startOffset": 22, "endOffset": 43}, {"referenceID": 5, "context": "The basic idea of rf is to boost the higher frequency terms in the positive category than in the negative one, that helps in selecting the positive samples from the negative ones (Lan et al., 2009).", "startOffset": 179, "endOffset": 197}, {"referenceID": 3, "context": "Suppose that the feature follows multinomial distribution over the classes, zd calculates Z transformation for a feature in each class, zd boosts the highly unevenly distributed features among the classes, it gives high positive score for a feature in the class where it is highly frequent and negative score in the class where it rarely appears (Hamdan et al., 2014).", "startOffset": 346, "endOffset": 367}, {"referenceID": 11, "context": "tribution of the feature given the category and the distribution of the feature given the other categories (Nigam et al., 2000).", "startOffset": 107, "endOffset": 127}, {"referenceID": 10, "context": "(Ng et al., 1997).", "startOffset": 0, "endOffset": 17}, {"referenceID": 9, "context": "We have used two data sets, the first one is extracted from Twitter which has been provided in SemEval 2013 for subtask B of sentiment analysis in Twitter (Nakov et al., 2013).", "startOffset": 155, "endOffset": 175}, {"referenceID": 15, "context": "The test data set provided in SemEval-2015 containing about 2390 tweets (Rosenthal et al., 2015) is used for evaluating our system.", "startOffset": 72, "endOffset": 96}, {"referenceID": 14, "context": "views, provided by SemEval 2015 ABSA organizers (Pontiki et al., 2015) where each review is composed of several sentences, the participants are asked to detect the polarity of each senetce.", "startOffset": 48, "endOffset": 70}, {"referenceID": 15, "context": "A ranked list of twitter terms obtained from human annotations was provided by SemEval-2015 organizers (Rosenthal et al., 2015), the original ranked list contains 1315 terms, we used only 552 terms which exist in our training", "startOffset": 103, "endOffset": 127}], "year": 2016, "abstractText": "The classic supervised classification algorithms are efficient, but time-consuming, complicated and not interpretable, which makes it difficult to analyze their results that limits the possibility to improve them based on real observations. In this paper, we propose a new and a simple classifier to predict a sentiment label of a short text. This model keeps the capacity of human interpret-ability and can be extended to integrate NLP techniques in a more interpretable way. Our model is based on a correlation metric which measures the degree of association between a sentiment label and a word. Ten correlation metrics are proposed and evaluated intrinsically. And then a classifier based on each metric is proposed, evaluated and compared to the classic classification algorithms which have proved their performance in many studies. Our model outperforms these algorithms with several correlation metrics.", "creator": "LaTeX with hyperref package"}}}