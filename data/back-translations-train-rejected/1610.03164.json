{"id": "1610.03164", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Oct-2016", "title": "Navigational Instruction Generation as Inverse Reinforcement Learning with Neural Machine Translation", "abstract": "Modern robotics applications that involve human-robot interaction require robots to be able to communicate with humans seamlessly and effectively. Natural language provides a flexible and efficient medium through which robots can exchange information with their human partners. Significant advancements have been made in developing robots capable of interpreting free-form instructions, but less attention has been devoted to endowing robots with the ability to generate natural language. We propose a navigational guide model that enables robots to generate natural language instructions that allow humans to navigate a priori unknown environments. We first decide which information to share with the user according to their preferences, using a policy trained from human demonstrations via inverse reinforcement learning. We then \"translate\" this information into a natural language instruction using a neural sequence-to-sequence model that learns to generate free-form instructions from natural language corpora. We evaluate our method on a benchmark route instruction dataset and achieve a BLEU score of 72.18% when compared to human-generated reference instructions. We additionally conduct navigation experiments with human participants that demonstrate that our method generates instructions that people follow as accurately and easily as those produced by humans.", "histories": [["v1", "Tue, 11 Oct 2016 02:47:09 GMT  (1754kb,D)", "http://arxiv.org/abs/1610.03164v1", null]], "reviews": [], "SUBJECTS": "cs.RO cs.AI cs.CL cs.LG", "authors": ["andrea f daniele", "mohit bansal", "matthew r walter"], "accepted": false, "id": "1610.03164"}, "pdf": {"name": "1610.03164.pdf", "metadata": {"source": "META", "title": "Navigational Instruction Generation as Inverse Reinforcement Learning with Neural Machine Translation", "authors": ["Andrea F. Daniele", "Mohit Bansal", "Matthew R. Walter"], "emails": ["afdaniele@ttic.edu", "mbansal@cs.unc.edu", "mwalter@ttic.edu"], "sections": [{"heading": null, "text": "In fact, it is such that most people will be able to move into another world, in which they are able to move, in which they are able to move, in which they move, in which they move, in which they move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they, in which they, in which they live, in which they, in which they live, in which they live, in which they, in which they, in which they live, in which they, in which they live, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, live in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, live, in which they, in which they, in which they, in which they, in which they, in fact, in which they, in fact, in which they, live, in which they, in which they, in which they, in which they, in fact, are able to move, are able to move, in which they, are able to move, in which they, are able to move, in which they, in which they, in which they, in which they, in which they, in which they, in which they, are able to move, in which they, move, in which they, in which they, in which they"}, {"heading": "II. RELATED WORK", "text": "In fact, most people would rather understand the way in which people give instructions than see physical objects and places as intuitive landmarks (as opposed to the quantified distances that are typical of GPS-based navigation systems).These studies have shown that people prefer instructions to give instructions, which in turn give instructions, and that they prefer physical objects and places. (As opposed to the quantified distances that are typical of GPS-based navigation systems.) Based on these studies, much of the existing research is focused on generating route instructions that are designed to emulate the way people compose navigation instructions.) Look et al. [36] compose route instructions based on a set of templates and rules of application based on a body of human instructions. Look 37] improves this work by incorporating human cognitive instructions."}, {"heading": "III. TASK DEFINITION", "text": "We are looking at the problem of generating instructions in natural language that allow the human being to navigate in environments a priori unknown to him. As with the broader class of language generation problems, this task requires deciding what information to convey to the user (content selection) in such a way that it is correct (e.g. consistent with what is currently visible to the user in the environment), not excessively wordy (i.e. that the user can easily interpret and remember the instructions), and unambiguous. The task then requires transmitting this information via language so that the sentence is syntactically correct, its semantics are in line with the intended message, and it is natural and formless. Formally, looking at a map of the environment and a desired path, the task is to produce a natural language instruction that guides the user along the path. The map m takes the form of a hybrid path-forming metric topology representation."}, {"heading": "IV. MODEL", "text": "Considering a map and a path, our framework (Fig. 2) performs a content selection to decide which information to share with the human follower, and then performs surface realization to generate a lesson in natural language according to this selected content. Our method learns to perform content selection and surface realization from human demonstrations in order to produce instructions similar to those generated by humans."}, {"heading": "A. Compound Action Specifications", "text": "To bridge the gap between the low level of input paths and natural speech output, we encode paths using a formal language based on intermediate logic. Specifically, we use the Compound Action Specification (CAS) representation [39], which provides a formal abstraction of navigation commands for hybrid metric-topological-semantic maps like ours. CAS language consists of five actions (e.g. Travel, Rotate, Face, Verify, and Find), each of which is associated with a number of attributes that together define specific commands (e.g. Travel, Remove, Rotate). We distinguish between CAS structures, which are statements where the attributes are left blank (e.g. Rotate (Direction = None), defining a class of statements), and CAS commands that correspond to instantiated statements with the attributes to specific values (e.g. Rotate (Direction = Left)."}, {"heading": "B. Content Selection", "text": "There are many ways to compile a CAS specification of the desired path that are generally difficult to define, both in terms of the type of information that is transmitted (e.g., references to distances and physical landmarks), and in terms of the specific way in which that information is used (e.g., the preference of visible landmarks over distances).Our goal is to learn these preferences from a dataset of instructions generated by humans (e.g., the preference of visible landmarks over distances).MDP with Inverse Reinforcement Learning: Similarly, we formulate the problem of content selection as a Markov decision process (MDP) with the goal of identifying an information policy that maximizes long-term cumulative rewards in accordance with human preferences."}, {"heading": "C. Surface Realization", "text": "After identifying a number of CAS commands suitable for the given path, our method then proceeds to generate the corresponding natural language route statement. We formulate this problem as one of the \"translations\" of the instructions into the formal CAS language, without the need for specific characteristics, resources, or templates. [40, 4, 41] Similar models of the reverse task of speech comprehension as a machine translation problem. [1] Sequence-to-sequence model: We formulate the problem of the generation of natural language routes as a consequence of a probable model P (1: T x1: N) in which we understand the language (1, 2,.) is the sequence-to-sequence model."}, {"heading": "V. EXPERIMENTAL SETUP", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Dataset", "text": "In fact, it is the case that we will be able to form a new government in the next two years that is able to form a new government, \"he said.\" We must be able to form a new government, \"he added.\" We must be able to form a new government, \"he said.\" We must be able to form a new government, \"he said.\" We must be able to form a new government, \"he said.\" We must be able to form a new government, \"he said."}, {"heading": "C. Automatic Evaluation", "text": "To the best of our knowledge, we are the first to use the SAIL dataset for the purpose of compiling route instructions. Consequently, we evaluate our method by comparing our generated instructions with a reference set of man-made commands from the SAIL dataset using the BLEU score (a 4-gram matching-based precision) [45]. To this end, for each pair of commands (c (i), q (i)))) in the validation set, we first feed the c (i) command set into our model to obtain the generated instructions, and secondly use the command and command set pairs (i) or the hypothesis for calculating the 4-gram BLEU score. We consider both the average of BLEU values at the individual set level (macro-average precision) and at the full-corpus level (microaverage precision)."}, {"heading": "D. Human Evaluation", "text": "The use of the BLEU score indicates the similarity between instructions generated by our method and those produced by humans, but it does not provide a complete measurement of the quality of the instructions (e.g. instructions that are correct but different in prose receive a low BLEU score). In an effort to further evaluate the accuracy and applicability of our method, we conducted a series of human evaluation experiments in which we asked 42 newcomers to Amazon Mechanical Turk (21 women and 21 men aged 18-64, all native English speakers) to follow natural language instructions randomly selected from two equally large groups of instructions generated by our method and by humans for 50 different paths of varying length. Paths and the corresponding human-generated instructions were randomly sampled from the SAIL test kit."}, {"heading": "VI. RESULTS", "text": "We evaluate the performance of our architecture by evaluating the generated instructions with the 4 gram BLEU score, which is commonly used as an automatic evaluation mechanism for machine translation. Compared to human-generated instructions, our method on the validation rate achieves sentences and corpus values of BLEU values of 74.67% and 60.10%, respectively. On the test set, the method achieves sentences and corpus values of BLEU values of 72.18% and 45.39%, respectively. Fig. 1Verifyvalue.Path side.Rightschein.Honeycomyou should have the olive corridor on the right, which shows an example of directions created by our system for a given map and path."}, {"heading": "A. Aligner Ablation", "text": "Our model uses an aligner to learn to focus on specific CAS tokens that are relevant to words in the output statement. We evaluate the aligner's contribution by implementing and training an alternative model in which the last hidden state of the encoder is fed to the decoder. Table I compares the performance of the two models on the original validation set. Including an aligner results in a slight increase in the BLEU score of the generated statements relative to the human-provided references, and is also useful for visualizing the inner workings of our model (as shown below). In addition, we find empirically that the aligner improves our model's ability to learn the connection between CAS elements and words in the output, resulting in better instructions."}, {"heading": "B. Language Model Ablation", "text": "In practice, the language model trained on large amounts of English data helps to remove grammatically incorrect sentences generated by the sequence-to-sequence model trained only on the smaller pair-by-pair data set. Table II presents two statement candidates generated by our encoder-aligner decoder model for two different CAS commands. Our language model succeeds in assigning a high degree of perplexity to the wrong statements, with the instruction chosen being grammatically correct."}, {"heading": "C. Aligner Visualization", "text": "Figure 5 shows thermal images that visualize the alignment between an input of a CAS command for surface realization (left) and the generated route instruction (top) for two different scenarios from the SAIL validation set. Visualizations show that our method learns to match elements of the formal CAS command with the corresponding words in the generated guide. For example, the network learns the relationship between the honeycomb floor and its color (top), that \"bank\" refers to sofa objects (bottom), and that the phrase \"you should have\" refers to a verification action (top)."}, {"heading": "D. Human Evaluation", "text": "We evaluate the accuracy with which people follow the instructions with respect to the distance between the goals (i.e., the last pose of the goal) and the position of the participant when he reaches the goal. Results show that the participants have reached the desired position."}, {"heading": "VII. CONCLUSION", "text": "We presented a model for generating natural language related to the provision of indoor directions that uses a structured approach to generate clear, easy-to-remember, and grammatically correct directions for people. Currently, our model generates directions in natural language for the shortest route to the destination. However, there are situations where a longer path can provide directions that are easier to follow [47] or increase the likelihood of achieving the goal [22]. Another interesting direction for future work would be to integrate a model of instruction trailers [41] into our architecture to learn how to generate directions that are easier to follow. Such an approach would make it possible to train the model in a reinforcement learning environment where the performance of the task is directly optimized."}, {"heading": "VIII. ACKNOWLEDGEMENTS", "text": "We thank NVIDIA Corporation for donating the Titan X GPU used for this research."}, {"heading": "APPENDIX A MDP FEATURE REPRESENTATION", "text": "We use 14 contexts as attributes for paths and 9 instruction properties as attributes for CAS structures. For each demonstration, map and path are represented by a single binary vector of 14 elements (indicating which contexts are active and which are not), while the instruction is represented by an integer vector of 9 elements. Lists of the contexts and instruction properties we use in our model are shown in Table III and IV, respectively."}, {"heading": "APPENDIX B HUMAN SUBJECTS EVALUATION", "text": "We evaluated the accuracy and quality of our prepared instructions through a series of experiments in which human participants were asked to navigate a three-dimensional virtual environment according to the route directions provided. Participants were recruited using the crowd-sourced Amazonas Mechanical Turk platform and completed a total of 511 experiments. We omitted those experiments for which the participant answered \"no\" or \"do not reject the instructions\" to the question \"Are you a native English speaker?\" as they were included as a prerequisite for participation. This procedure resulted in a total of 42 participants (21 women and 21 men aged 18-64) and a total of 441 experiments. We did not omit experiments based on the participants \"performance or the answers they gave to questions regarding demographic information."}], "references": [{"title": "From knowledge to words to wayfinding: Issues in the production and comprehension of route directions", "author": ["G.L. Allen"], "venue": "Proc. Int\u2019l Conf. on Spatial Information Theory (COSIT), pages 363\u2013 372,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1997}, {"title": "Rhetorical robots: Making robots more effective speakers using linguistic cues of expertise", "author": ["S. Andrist", "E. Spannan", "B. Mutlu"], "venue": "Proc. ACM/IEEE Int\u2019l. Conf. on Human-Robot Interaction (HRI), pages 341\u2013348, Tokyo, Japan, March", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2013}, {"title": "A simple domainindependent probabilistic approach to generation", "author": ["G. Angeli", "P. Liang", "D. Klein"], "venue": "Proc. Conf. on Empirical Methods in Natural Language Processing (EMNLP), pages 502\u2013512,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2010}, {"title": "Weakly supervised learning of semantic parsers for mapping instructions to actions", "author": ["Y. Artzi", "L. Zettlemoyer"], "venue": "Trans. Assoc. for Computational Linguistics, 1:49\u201362,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2013}, {"title": "Neural machine translation by jointly learning to align and translate", "author": ["D. Bahdanau", "K. Cho", "Y. Bengio"], "venue": "CoRR, abs/1409.0473,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2014}, {"title": "Collective content selection for concept-to-text generation", "author": ["R. Barzilay", "M. Lapata"], "venue": "Proc. Human Language Technology Conf. and the Conf. on Empirical Methods in Natural Language Processing (HLT/EMNLP), pages 331\u2013338,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2005}, {"title": "Catching the drift: Probabilistic content models, with applications to generation and summarization", "author": ["R. Barzilay", "L. Lee"], "venue": "arXiv preprint cs/0405039,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2004}, {"title": "Learning to sportscast: a test of grounded language acquisition", "author": ["D.L. Chen", "R.J. Mooney"], "venue": "Proc. Int\u2019l Conf. on Machine Learning (ICML), pages 128\u2013135,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2008}, {"title": "Learning to interpret natural language navigation instructions from observations", "author": ["D.L. Chen", "R.J. Mooney"], "venue": "Proc. Nat\u2019l Conf. on Artificial Intelligence (AAAI), pages 859\u2013865, San Francisco, CA, August", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2011}, {"title": "On the performance of hierarchical distributed correspondence graphs for efficient symbol grounding of robot instructions", "author": ["I. Chung", "O. Propp", "M.R. Walter", "T.M. Howard"], "venue": "Proc. IEEE/RSJ Int\u2019l Conf. on Intelligent Robots and Systems (IROS), Hamburg, Germany, October", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2015}, {"title": "Multimodal interaction with an autonomous forklift", "author": ["A. Correa", "M.R. Walter", "L. Fletcher", "J. Glass", "S. Teller", "R. Davis"], "venue": "Proc. ACM/IEEE Int\u2019l. Conf. on Human-Robot Interaction (HRI), pages 243\u2013250, Osaka, Japan, March", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2010}, {"title": "Generating adaptive route instructions using hierarchical reinforcement learning", "author": ["H. Cuay\u00e1huitl", "N. Dethlefs", "L. Frommberger", "K.-F. Richter", "J. Bateman"], "venue": "Proc. Int\u2019l Conf. on Spatial Cognition, pages 319\u2013334,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2010}, {"title": "Generating and evaluating landmark-based navigation instructions in virtual environments", "author": ["A.C. Curry", "D. Gkatzia", "V. Rieser"], "venue": "Proc. Europ. Workshop on Natural Language Generation (ENLG), pages 90\u201394, Brighton, UK, September", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2015}, {"title": "Using natural language generation in automatic route", "author": ["R. Dale", "S. Geldof", "J.-P. Prost"], "venue": "J. Research and Practice in Information Technology, 37(1):89,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2005}, {"title": "Clarifying commands with information-theoretic human-robot dialog", "author": ["R. Deits", "S. Tellex", "P. Thaker", "D. Simeonov", "T. Kollar", "N. Roy"], "venue": "J. of Human-Robot Interaction, 2(2):58\u2013 79,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2013}, {"title": "The role of trust in automation reliance", "author": ["M.T. Dzindolet", "S.A. Peterson", "R.A. Pomranky", "L.G. Pierce", "H.P. Beck"], "venue": "Int\u2019l J. of Human-Computer Studies, 58(6):697\u2013718, June", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2003}, {"title": "Collaboration, dialogue, and human-robot interaction", "author": ["T. Fong", "C. Thorpe", "C. Baur"], "venue": "Int\u2019l Symp. of Robotics Research (ISRR), Lorne, Victoria, Autralia, November", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2001}, {"title": "DART: A particle-based method for generating easy-to-follow directions", "author": ["R. Goeddel", "E. Olson"], "venue": "Proc. IEEE/RSJ Int\u2019l  Conf. on Intelligent Robots and Systems (IROS), pages 1213\u2013 1219,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2012}, {"title": "Speech recognition with deep recurrent neural networks", "author": ["A. Graves", "M. Abdel-rahman", "G. Hinton"], "venue": "Proc. IEEE Int\u2019l Conf. on Acoustics, Speech and Signal Processing (ICASSP), pages 6645\u20136649,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2013}, {"title": "Can robots be teammates?: Benchmarks in human-robot teams", "author": ["V. Groom", "C. Nass"], "venue": "Interaction Studies, 8(3):483\u2013500,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2007}, {"title": "Collaborative systems", "author": ["B.J. Grosz"], "venue": "AI Magazine, 17(2):67\u201385,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1996}, {"title": "Algorithms for reliable navigation and wayfinding", "author": ["S. Haque", "L. Kulik", "A. Klippel"], "venue": "Spatial Cognition V Reasoning, Action, Interaction, pages 308\u2013326.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2006}, {"title": "Humanoid robots as a passive-social medium: A field experiment at a train station", "author": ["K. Hayaski", "D. Sakamoto", "T. Kanda", "M. Shiomi", "S. Koizumi", "H. Ishiguru", "T. Ogasawara", "N. Hagita"], "venue": "Proc. ACM/IEEE Int\u2019l. Conf. on Human-Robot Interaction (HRI), pages 137\u2013144, Arlington, VA, March", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2007}, {"title": "Information-theoretic dialog to improve spatial-semantic representations", "author": ["S. Hemachandra", "M. Walter"], "venue": "Proc. IEEE/RSJ Int\u2019l Conf. on Intelligent Robots and Systems (IROS), Hamburg, Germany, October", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2015}, {"title": "Long short-term memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural Computation, 9(8):1735\u20131780,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 1997}, {"title": "A natural language planner interface for mobile manipulators", "author": ["T. Howard", "S. Tellex", "N. Roy"], "venue": "Proc. IEEE Int\u2019l Conf. on Robotics and Automation (ICRA),", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2014}, {"title": "The impact of culture and recipient perspective on direction giving in the service of wayfinding", "author": ["A.M. Hund", "M. Schmettow", "M.L. Noordzij"], "venue": "J. of Environmental Psychology, 32(4): 327\u2013336,", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2012}, {"title": "Interactive robots as social partners and peer tutors for children: A field trial", "author": ["T. Kanda", "T. Hirano", "D. Eaton", "H. Ishiguro"], "venue": "J. Human-Computer Interaction, 19(1):61\u201384, June", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2004}, {"title": "Generative alignment and semantic parsing for learning from ambiguous supervision", "author": ["J. Kim", "R.J. Mooney"], "venue": "Proc. Int\u2019l Conf. on Computational Linguistics, pages 543\u2013551,", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2010}, {"title": "Adam: A method for stochastic optimization", "author": ["D. Kingma", "J. Ba"], "venue": "arXiv preprint arXiv:1412.6980,", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2014}, {"title": "Toward understanding natural language directions", "author": ["T. Kollar", "S. Tellex", "D. Roy", "N. Roy"], "venue": "Proc. ACM/IEEE Int\u2019l. Conf. on Human-Robot Interaction (HRI), pages 259\u2013266,", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2010}, {"title": "Unsupervised concept-to-text generation with hypergraphs", "author": ["I. Konstas", "M. Lapata"], "venue": "Proc. Conf. of the North American Chapter of the Assoc. for Computational Linguistics (NAACL), pages 752\u2013761,", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2012}, {"title": "Indirect object search based on qualitative spatial relations", "author": ["L. Kunze", "K. Kumar", "N. Hawes"], "venue": "Proc. IEEE Int\u2019l Conf. on Robotics and Automation (ICRA),", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2014}, {"title": "Route description interpretation on automatically labeled robot maps", "author": ["C. Landsiedel", "R.D. Nijs", "K. Khnlenz", "D. Wollherr", "M. Buss"], "venue": "Proc. IEEE Int\u2019l Conf. on Robotics and Automation (ICRA),", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2013}, {"title": "Learning semantic correspondences with less supervision", "author": ["P. Liang", "M.I. Jordan", "D. Klein"], "venue": "Proc. Assoc. for Computational Linguistics (ACL), pages 91\u201399,", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2009}, {"title": "A location representation for generating descriptive walking directions", "author": ["G. Look", "B. Kottahachchi", "R. Laddaga", "H. Shrobe"], "venue": "Proc. Int\u2019l Conf. on Intelligent User Interfaces (IUI), pages 122\u2013129,", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2005}, {"title": "Cognitively-inspired direction giving", "author": ["G.W.K. Look"], "venue": "PhD thesis, Massachusetts Institute of Technology,", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2008}, {"title": "Elements of good route directions in familiar and unfamiliar environments", "author": ["K.L. Lovelace", "M. Hegarty", "D.R. Montello"], "venue": "Int\u2019l Conf. on Spatial Information Theory, pages 65\u201382,", "citeRegEx": "38", "shortCiteRegEx": null, "year": 1999}, {"title": "Walk the  talk: Connecting language, knowledge, and action in route instructions", "author": ["M. MacMahon", "B. Stankiewicz", "B. Kuipers"], "venue": "Proc. Nat\u2019l Conf. on Artificial Intelligence (AAAI),", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2006}, {"title": "Following directions using statistical machine translation", "author": ["C. Matuszek", "D. Fox", "K. Koscher"], "venue": "Proc. ACM/IEEE Int\u2019l. Conf. on Human-Robot Interaction (HRI), pages 251\u2013258, Osaka, Japan, March", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2010}, {"title": "Listen, attend, and walk: Neural mapping of navigational instructions to action sequences", "author": ["H. Mei", "M. Bansal", "M.R. Walter"], "venue": "Proc. Nat\u2019l Conf. on Artificial Intelligence (AAAI),", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2016}, {"title": "What to talk about and how? Selective generation using lstms with coarse-to-fine alignment", "author": ["H. Mei", "M. Bansal", "M.R. Walter"], "venue": "Proc. Conf. of the North American Chapter of the Assoc. for Computational Linguistics (NAACL),", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2016}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["T. Mikolov", "J. Dean"], "venue": "Advances in neural information processing systems,", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2013}, {"title": "Learning to give route directions from human demonstrations", "author": ["S. Oswald", "H. Kretzschmar", "W. Burgard", "C. Stachniss"], "venue": "Proc. IEEE Int\u2019l Conf. on Robotics and Automation (ICRA), pages 3303\u20133308,", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2014}, {"title": "BLEU: A method for automatic evaluation of machine translation", "author": ["K. Papineni", "S. Roukos", "T. Ward", "W.-J. Zhu"], "venue": "Proc. Assoc. for Computational Linguistics (ACL), pages 311\u2013 318,", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2002}, {"title": "Sorry dave, I\u2019m afraid I can\u2019t do that: Explaining unachievable robot tasks using natural language", "author": ["V. Raman", "C. Lignos", "C. Finucane", "K.C.T. Lee", "M. Marcus", "H. Kress-Gazit"], "venue": "Proc. Robotics: Science and Systems (RSS), Berlin, Germany, June", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2013}, {"title": "Simplest instructions: Finding easy-to-describe routes for navigation", "author": ["K.-F. Richter", "M. Duckham"], "venue": "Geographic information science, pages 274\u2013289.", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2008}, {"title": "Effective task training strategies for human and robot instructors", "author": ["A. Saupp\u00e9", "B. Mutlu"], "venue": "Autonomous Robots, 39(3):313\u2013 329, October", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2015}, {"title": "Clair and M", "author": ["A. St"], "venue": "Matari\u0107. How robot verbal feedback can improve team performance in human-robot task collaborations. In Proc. ACM/IEEE Int\u2019l. Conf. on Human-Robot Interaction (HRI), pages 213\u2013220, Portland, OR, March", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2015}, {"title": "Report on the second challenge on generating instructions in virtual environments (GIVE-2.5)", "author": ["K. Striegnitz", "A. Denis", "A. Gargett", "K. Garoufi", "A. Koller", "M. Theune"], "venue": "In Proc. Europ. Workshop on Natural Language Generation (ENGL),", "citeRegEx": "50", "shortCiteRegEx": "50", "year": 2011}, {"title": "LSTM neural networks for language modeling", "author": ["M. Sundermeyer", "R. Schl\u00fcter", "H. Ney"], "venue": "Proc. of Interspeech, pages  194\u2013197,", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2012}, {"title": "Sequence to sequence learning with neural networks", "author": ["I. Sutskever", "O. Vinyals", "Q.V. Le"], "venue": "CoRR, abs/1409.3215,", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2014}, {"title": "Understanding natural language commands for robotic navigation and mobile manipulation", "author": ["S. Tellex", "T. Kollar", "S. Dickerson", "M.R. Walter", "A.G. Banerjee", "S. Teller", "N. Roy"], "venue": "Proc. Nat\u2019l Conf. on Artificial Intelligence (AAAI), pages 1507\u20131514, San Francisco, CA, August", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2011}, {"title": "Toward information theoretic human-robot dialog", "author": ["S. Tellex", "P. Thaker", "R. Deits", "D. Simeonov", "T. Kollar", "N. Roy"], "venue": "Proc. Robotics: Science and Systems (RSS), Sydney, Australia, July", "citeRegEx": "54", "shortCiteRegEx": null, "year": 2012}, {"title": "Asking for help using inverse semantics", "author": ["S. Tellex", "R. Knepper", "A. Li", "D. Rus", "N. Roy"], "venue": "Proc. Robotics: Science and Systems (RSS), Berkeley, CA, July", "citeRegEx": "55", "shortCiteRegEx": null, "year": 2014}, {"title": "How a robot should give advice", "author": ["C. Torrey", "S.R. Fussell", "S. Kiesler"], "venue": "Proc. ACM/IEEE Int\u2019l. Conf. on Human-Robot Interaction (HRI), pages 275\u2013282, Tokyo, Japan, March", "citeRegEx": "56", "shortCiteRegEx": null, "year": 2013}, {"title": "SPoT: A trainable sentence planner", "author": ["M.A. Walker", "O. Rambow", "M. Rogati"], "venue": "Proc. Conf. of the North American Chapter of the Assoc. for Computational Linguistics (NAACL), Pittsburgh, PA, June", "citeRegEx": "57", "shortCiteRegEx": null, "year": 2001}, {"title": "Landmarks as beacons and associative cues: their role in route learning", "author": ["D. Waller", "Y. Lippa"], "venue": "Memory & Cognition, 35(5): 910\u2013924,", "citeRegEx": "58", "shortCiteRegEx": null, "year": 2007}, {"title": "Robotic etiquette: Results from user studies involving a fetch and carry task", "author": ["M.L. Walters", "K. Dautenhahn", "S.N. Woods", "K.L. Koay"], "venue": "Proc. ACM/IEEE Int\u2019l. Conf. on Human- Robot Interaction (HRI), pages 317\u2013324, Arlington, VA, March", "citeRegEx": "59", "shortCiteRegEx": null, "year": 2007}, {"title": "Trust calibration within a human-robot team: Comparing automatically generated explanations", "author": ["N. Wang", "D.V. Pynadath", "S.G. Hill"], "venue": "Proc. ACM/IEEE Int\u2019l. Conf. on Human-Robot Interaction (HRI), Christchurch, New Zealand, March", "citeRegEx": "60", "shortCiteRegEx": null, "year": 2016}, {"title": "Turn left at the church, or three miles north: A study of direction giving and sex differences", "author": ["S.L. Ward", "N. Newcombe", "W.F. Overton"], "venue": "Environment Behavior, 18(2):192\u2013213,", "citeRegEx": "61", "shortCiteRegEx": null, "year": 1986}, {"title": "Generation by inverting a semantic parser that uses statistical machine translation", "author": ["Y.W. Wong", "R.J. Mooney"], "venue": "Proc. Conf. of the North American Chapter of the Assoc. for Computational Linguistics \u2013 Human Language Technologies (NAACL HLT), pages 172\u2013179,", "citeRegEx": "62", "shortCiteRegEx": null, "year": 2007}, {"title": "Maximum entropy inverse reinforcement learning", "author": ["B.D. Ziebart", "A. Maas", "J.A. Bagnell", "A.K. Dey"], "venue": "Proc. Nat\u2019l Conf. on Artificial Intelligence (AAAI), pages 1433\u20131438, Chicago, IL, July", "citeRegEx": "63", "shortCiteRegEx": null, "year": 2008}], "referenceMentions": [{"referenceID": 58, "context": "Robots are increasingly being used as our partners, working with and alongside people, whether it is serving as assistants in our homes [59], transporting cargo in warehouses [11], helping students with language learning in the classroom [28], and acting as guides in public spaces [23].", "startOffset": 136, "endOffset": 140}, {"referenceID": 10, "context": "Robots are increasingly being used as our partners, working with and alongside people, whether it is serving as assistants in our homes [59], transporting cargo in warehouses [11], helping students with language learning in the classroom [28], and acting as guides in public spaces [23].", "startOffset": 175, "endOffset": 179}, {"referenceID": 27, "context": "Robots are increasingly being used as our partners, working with and alongside people, whether it is serving as assistants in our homes [59], transporting cargo in warehouses [11], helping students with language learning in the classroom [28], and acting as guides in public spaces [23].", "startOffset": 238, "endOffset": 242}, {"referenceID": 22, "context": "Robots are increasingly being used as our partners, working with and alongside people, whether it is serving as assistants in our homes [59], transporting cargo in warehouses [11], helping students with language learning in the classroom [28], and acting as guides in public spaces [23].", "startOffset": 282, "endOffset": 286}, {"referenceID": 20, "context": "In order for humans and robots to work together effectively, robots must be able to communicate with their human partners in order to establish a shared understanding of the collaborative task and to coordinate their efforts [21, 17, 49, 48].", "startOffset": 225, "endOffset": 241}, {"referenceID": 16, "context": "In order for humans and robots to work together effectively, robots must be able to communicate with their human partners in order to establish a shared understanding of the collaborative task and to coordinate their efforts [21, 17, 49, 48].", "startOffset": 225, "endOffset": 241}, {"referenceID": 48, "context": "In order for humans and robots to work together effectively, robots must be able to communicate with their human partners in order to establish a shared understanding of the collaborative task and to coordinate their efforts [21, 17, 49, 48].", "startOffset": 225, "endOffset": 241}, {"referenceID": 47, "context": "In order for humans and robots to work together effectively, robots must be able to communicate with their human partners in order to establish a shared understanding of the collaborative task and to coordinate their efforts [21, 17, 49, 48].", "startOffset": 225, "endOffset": 241}, {"referenceID": 39, "context": "or more robots to navigate throughout the building searching for occupants [40, 53, 41].", "startOffset": 75, "endOffset": 87}, {"referenceID": 52, "context": "or more robots to navigate throughout the building searching for occupants [40, 53, 41].", "startOffset": 75, "endOffset": 87}, {"referenceID": 40, "context": "or more robots to navigate throughout the building searching for occupants [40, 53, 41].", "startOffset": 75, "endOffset": 87}, {"referenceID": 53, "context": ", to clarify which hallway the user was referring to) [54, 15, 46, 55, 24].", "startOffset": 54, "endOffset": 74}, {"referenceID": 14, "context": ", to clarify which hallway the user was referring to) [54, 15, 46, 55, 24].", "startOffset": 54, "endOffset": 74}, {"referenceID": 45, "context": ", to clarify which hallway the user was referring to) [54, 15, 46, 55, 24].", "startOffset": 54, "endOffset": 74}, {"referenceID": 54, "context": ", to clarify which hallway the user was referring to) [54, 15, 46, 55, 24].", "startOffset": 54, "endOffset": 74}, {"referenceID": 23, "context": ", to clarify which hallway the user was referring to) [54, 15, 46, 55, 24].", "startOffset": 54, "endOffset": 74}, {"referenceID": 19, "context": "The user\u2019s ability to trust their robotic partners is also integral to effective collaboration [20], and a robot\u2019s ability to generate natural language explanations Input: map and path", "startOffset": 95, "endOffset": 99}, {"referenceID": 15, "context": ", \u201cI have inspected two rooms\u201d) and decision-making processes have been shown to help establish trust [16, 2, 60].", "startOffset": 102, "endOffset": 113}, {"referenceID": 1, "context": ", \u201cI have inspected two rooms\u201d) and decision-making processes have been shown to help establish trust [16, 2, 60].", "startOffset": 102, "endOffset": 113}, {"referenceID": 59, "context": ", \u201cI have inspected two rooms\u201d) and decision-making processes have been shown to help establish trust [16, 2, 60].", "startOffset": 102, "endOffset": 113}, {"referenceID": 17, "context": "This specific problem has previously been considered by the robotics community [18, 44] and is important for human-robot collaborative tasks, such as search-and-rescue, exploration, and surveillance [33], and for robotic assistants, such as those that serve as guides in museums, offices, and other public spaces.", "startOffset": 79, "endOffset": 87}, {"referenceID": 43, "context": "This specific problem has previously been considered by the robotics community [18, 44] and is important for human-robot collaborative tasks, such as search-and-rescue, exploration, and surveillance [33], and for robotic assistants, such as those that serve as guides in museums, offices, and other public spaces.", "startOffset": 79, "endOffset": 87}, {"referenceID": 32, "context": "This specific problem has previously been considered by the robotics community [18, 44] and is important for human-robot collaborative tasks, such as search-and-rescue, exploration, and surveillance [33], and for robotic assistants, such as those that serve as guides in museums, offices, and other public spaces.", "startOffset": 199, "endOffset": 203}, {"referenceID": 57, "context": "In contrast, studies have shown that people prefer route instructions that reference physical, salient landmarks in the environment [58].", "startOffset": 132, "endOffset": 136}, {"referenceID": 60, "context": "However, no standard exists with regards to what and how these landmarks should be selected, as these depend on the nature of the environment and the demographics of the follower [61, 27].", "startOffset": 179, "endOffset": 187}, {"referenceID": 26, "context": "However, no standard exists with regards to what and how these landmarks should be selected, as these depend on the nature of the environment and the demographics of the follower [61, 27].", "startOffset": 179, "endOffset": 187}, {"referenceID": 55, "context": "Studies show that language generated by a robot is most effective when it emulates the communication style that people use [56].", "startOffset": 123, "endOffset": 127}, {"referenceID": 24, "context": "Our model takes the form of an encoderaligner-decoder architecture that first encodes the formal path specification with a recurrent neural network using long shortterm memory (LSTM-RNN) [25].", "startOffset": 187, "endOffset": 191}, {"referenceID": 38, "context": "We evaluate our method on the benchmark SAIL dataset of human-generated route instructions [39].", "startOffset": 91, "endOffset": 95}, {"referenceID": 60, "context": "Early work in this area focuses on understanding the way in which humans generate natural language route instructions [61, 1, 38] and the properties that make \u201cgood\u201d instructions easier for people to follow [36, 47, 58].", "startOffset": 118, "endOffset": 129}, {"referenceID": 0, "context": "Early work in this area focuses on understanding the way in which humans generate natural language route instructions [61, 1, 38] and the properties that make \u201cgood\u201d instructions easier for people to follow [36, 47, 58].", "startOffset": 118, "endOffset": 129}, {"referenceID": 37, "context": "Early work in this area focuses on understanding the way in which humans generate natural language route instructions [61, 1, 38] and the properties that make \u201cgood\u201d instructions easier for people to follow [36, 47, 58].", "startOffset": 118, "endOffset": 129}, {"referenceID": 35, "context": "Early work in this area focuses on understanding the way in which humans generate natural language route instructions [61, 1, 38] and the properties that make \u201cgood\u201d instructions easier for people to follow [36, 47, 58].", "startOffset": 207, "endOffset": 219}, {"referenceID": 46, "context": "Early work in this area focuses on understanding the way in which humans generate natural language route instructions [61, 1, 38] and the properties that make \u201cgood\u201d instructions easier for people to follow [36, 47, 58].", "startOffset": 207, "endOffset": 219}, {"referenceID": 57, "context": "Early work in this area focuses on understanding the way in which humans generate natural language route instructions [61, 1, 38] and the properties that make \u201cgood\u201d instructions easier for people to follow [36, 47, 58].", "startOffset": 207, "endOffset": 219}, {"referenceID": 49, "context": "Based on these studies, much of the existing research on generating route instructions involves the use of handcrafted rules that are designed to emulate the manner in which people compose navigation instructions [50, 13].", "startOffset": 213, "endOffset": 221}, {"referenceID": 12, "context": "Based on these studies, much of the existing research on generating route instructions involves the use of handcrafted rules that are designed to emulate the manner in which people compose navigation instructions [50, 13].", "startOffset": 213, "endOffset": 221}, {"referenceID": 35, "context": "[36] compose route instructions using a set of templates and application rules engineered based upon a corpus of humangenerated route instructions.", "startOffset": 0, "endOffset": 4}, {"referenceID": 36, "context": "Look [37] improves upon this work by incorporating human cognitive spatial models to generate high-level route overviews that augment turn-by-turn directions.", "startOffset": 5, "endOffset": 9}, {"referenceID": 13, "context": "[14] analyze a dataset of route instructions composed by people to derive a set of handdesigned rules that mimic the content and style of human directions.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "Goeddel and Olson [18] describe a particle filterbased method that employs a generative model of direction following to produce templated instructions that maximize the likelihood of reaching the desired destination.", "startOffset": 18, "endOffset": 22}, {"referenceID": 26, "context": "The challenge with instruction generation systems that rely upon hand-crafted rules is that is difficult to design a policy that generalizes to a wide variety of scenarios and followers, whose preferences vary depending on such factors as their cultural background [27] and gender [61].", "startOffset": 265, "endOffset": 269}, {"referenceID": 60, "context": "The challenge with instruction generation systems that rely upon hand-crafted rules is that is difficult to design a policy that generalizes to a wide variety of scenarios and followers, whose preferences vary depending on such factors as their cultural background [27] and gender [61].", "startOffset": 281, "endOffset": 285}, {"referenceID": 11, "context": "[12] seek to improve upon this using reinforcement learning with hand-crafted reward functions that model the length of the instructions and the likelihood that they will confuse a follower.", "startOffset": 0, "endOffset": 4}, {"referenceID": 43, "context": "[44] model the problem of deciding what to include in the instruction (i.", "startOffset": 0, "endOffset": 4}, {"referenceID": 39, "context": "Statistical methods primarily formulate the problem of converting instructions to actions as either a semantic parsing task [40, 9, 4] or as a symbol grounding problem [31, 53, 34, 26, 10].", "startOffset": 124, "endOffset": 134}, {"referenceID": 8, "context": "Statistical methods primarily formulate the problem of converting instructions to actions as either a semantic parsing task [40, 9, 4] or as a symbol grounding problem [31, 53, 34, 26, 10].", "startOffset": 124, "endOffset": 134}, {"referenceID": 3, "context": "Statistical methods primarily formulate the problem of converting instructions to actions as either a semantic parsing task [40, 9, 4] or as a symbol grounding problem [31, 53, 34, 26, 10].", "startOffset": 124, "endOffset": 134}, {"referenceID": 30, "context": "Statistical methods primarily formulate the problem of converting instructions to actions as either a semantic parsing task [40, 9, 4] or as a symbol grounding problem [31, 53, 34, 26, 10].", "startOffset": 168, "endOffset": 188}, {"referenceID": 52, "context": "Statistical methods primarily formulate the problem of converting instructions to actions as either a semantic parsing task [40, 9, 4] or as a symbol grounding problem [31, 53, 34, 26, 10].", "startOffset": 168, "endOffset": 188}, {"referenceID": 33, "context": "Statistical methods primarily formulate the problem of converting instructions to actions as either a semantic parsing task [40, 9, 4] or as a symbol grounding problem [31, 53, 34, 26, 10].", "startOffset": 168, "endOffset": 188}, {"referenceID": 25, "context": "Statistical methods primarily formulate the problem of converting instructions to actions as either a semantic parsing task [40, 9, 4] or as a symbol grounding problem [31, 53, 34, 26, 10].", "startOffset": 168, "endOffset": 188}, {"referenceID": 9, "context": "Statistical methods primarily formulate the problem of converting instructions to actions as either a semantic parsing task [40, 9, 4] or as a symbol grounding problem [31, 53, 34, 26, 10].", "startOffset": 168, "endOffset": 188}, {"referenceID": 40, "context": "[41] learn to translate natural language instructions to action sequences via an end-to-end fashion using an encoderaligner-decoder architecture.", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "Barzilay and Lee [7] perform content selection on collections of unannotated documents for the sake of text summarization.", "startOffset": 17, "endOffset": 20}, {"referenceID": 5, "context": "Barzilay and Lapata [6] formulate content selection as a collective classification problem, simultaneously optimizing local label assignments and their pairwise relations.", "startOffset": 20, "endOffset": 23}, {"referenceID": 34, "context": "[35] consider the related problem of aligning elements of a database to textual description clauses.", "startOffset": 0, "endOffset": 4}, {"referenceID": 56, "context": "[57] perform surface realization via sentence planners that can be trained to generate sentences for dialogue and context planning.", "startOffset": 0, "endOffset": 4}, {"referenceID": 61, "context": "Wong and Mooney [62] effectively invert a semantic parser to generate natural language sentences from formal meaning representations using synchronous context-free grammars.", "startOffset": 16, "endOffset": 20}, {"referenceID": 7, "context": "Rather than consider individual sub-problems, recent work focuses on solving selective generation via a single framework [8, 29, 3, 32, 42].", "startOffset": 121, "endOffset": 139}, {"referenceID": 28, "context": "Rather than consider individual sub-problems, recent work focuses on solving selective generation via a single framework [8, 29, 3, 32, 42].", "startOffset": 121, "endOffset": 139}, {"referenceID": 2, "context": "Rather than consider individual sub-problems, recent work focuses on solving selective generation via a single framework [8, 29, 3, 32, 42].", "startOffset": 121, "endOffset": 139}, {"referenceID": 31, "context": "Rather than consider individual sub-problems, recent work focuses on solving selective generation via a single framework [8, 29, 3, 32, 42].", "startOffset": 121, "endOffset": 139}, {"referenceID": 41, "context": "Rather than consider individual sub-problems, recent work focuses on solving selective generation via a single framework [8, 29, 3, 32, 42].", "startOffset": 121, "endOffset": 139}, {"referenceID": 2, "context": "[3] model content selection and surface realization as local decision problems via log-linear models and employ templates for generation.", "startOffset": 0, "endOffset": 3}, {"referenceID": 41, "context": "[42] formulate selective generation as an end-toend learning problem and propose a recurrent neural network encoder-aligner-decoder model that jointly learns to perform content selection and surface realization from database-text pairs.", "startOffset": 0, "endOffset": 4}, {"referenceID": 38, "context": "The dataset that we use for training, validation, and testing comes from the benchmark SAIL corpus [39].", "startOffset": 99, "endOffset": 103}, {"referenceID": 38, "context": "Specifically, we use the Compound Action Specification (CAS) representation [39], which provides a formal abstraction of navigation commands for hybrid metric-topologic-semantic maps such as ours.", "startOffset": 76, "endOffset": 80}, {"referenceID": 38, "context": "For each English instruction \u039b) in the dataset, we generate the corresponding CAS command c using the MARCO architecture [39].", "startOffset": 121, "endOffset": 125}, {"referenceID": 38, "context": "[39].", "startOffset": 0, "endOffset": 4}, {"referenceID": 57, "context": ", favoring visible landmarks over distances) [58], yet the specific nature of this information depends upon the environment and the followers\u2019 demographics [61, 27].", "startOffset": 45, "endOffset": 49}, {"referenceID": 60, "context": ", favoring visible landmarks over distances) [58], yet the specific nature of this information depends upon the environment and the followers\u2019 demographics [61, 27].", "startOffset": 156, "endOffset": 164}, {"referenceID": 26, "context": ", favoring visible landmarks over distances) [58], yet the specific nature of this information depends upon the environment and the followers\u2019 demographics [61, 27].", "startOffset": 156, "endOffset": 164}, {"referenceID": 43, "context": "[44], we formulate the content selection problem as a Markov decision process (MDP) with a goal of then identifying an information selection policy that maximizes long-term cumulative reward consistent with human preferences (Fig.", "startOffset": 0, "endOffset": 4}, {"referenceID": 62, "context": "Specifically, we learn a policy using the maximum entropy formulation of IRL [63], which models user actions as a distribution over paths parameterized as a log-linear model P (a; \u03b8) \u221d e\u2212\u03b8\u03be(a), where \u03be(a) is a feature vector defined over actions.", "startOffset": 77, "endOffset": 81}, {"referenceID": 62, "context": "[63].", "startOffset": 0, "endOffset": 4}, {"referenceID": 43, "context": "Rather than choosing the nearest match, which may result in an inconsistent CAS structure, we retrieve the kc nearest neighbors from the database using a weighted distance in terms of mutual information [44] that expresses the importance of different CAS features based upon the context.", "startOffset": 203, "endOffset": 207}, {"referenceID": 39, "context": "1Related work [40, 4, 41] similarly models the inverse task of language understanding as a machine translation problem.", "startOffset": 14, "endOffset": 25}, {"referenceID": 3, "context": "1Related work [40, 4, 41] similarly models the inverse task of language understanding as a machine translation problem.", "startOffset": 14, "endOffset": 25}, {"referenceID": 40, "context": "1Related work [40, 4, 41] similarly models the inverse task of language understanding as a machine translation problem.", "startOffset": 14, "endOffset": 25}, {"referenceID": 42, "context": "We transform each token xi into a ke\u2212dimensional binary vector using a word embedding representation [43].", "startOffset": 101, "endOffset": 105}, {"referenceID": 51, "context": "the neural encoder, which has been demonstrated to improve performance for other neural translation tasks [52].", "startOffset": 106, "endOffset": 110}, {"referenceID": 18, "context": "[19], \uf8ec\uf8ec\uf8ed ij f j oj g j \uf8f7\uf8f7\uf8f8 = \uf8ec\uf8ec\uf8ed \u03c3 \u03c3", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "where T e is an affine transformation, \u03c3 is the logistic sigmoid that restricts its input to [0, 1], ij , f e j , and o e j are the input, output, and forget gates of the LSTM, respectively, and cj is the memory cell activation vector.", "startOffset": 93, "endOffset": 99}, {"referenceID": 4, "context": "We employ an alignment mechanism [5] (Fig.", "startOffset": 33, "endOffset": 36}, {"referenceID": 50, "context": "We formulate this LM as an LSTM-RNN [51] that assigns a perplexity score to each of the corresponding instructions.", "startOffset": 36, "endOffset": 40}, {"referenceID": 38, "context": "[39].", "startOffset": 0, "endOffset": 4}, {"referenceID": 2, "context": "2This phenomenon has been observed by others [3, 42], and we attribute it to training the model in a greedy fashion.", "startOffset": 45, "endOffset": 52}, {"referenceID": 41, "context": "2This phenomenon has been observed by others [3, 42], and we attribute it to training the model in a greedy fashion.", "startOffset": 45, "endOffset": 52}, {"referenceID": 29, "context": "We train our model using Adam [30] for optimization.", "startOffset": 30, "endOffset": 34}, {"referenceID": 44, "context": "Consequently, we evaluate our method by comparing our generated instructions with a reference set of human-generated commands from the SAIL dataset using the BLEU score (a 4-gram matching-based precision) [45].", "startOffset": 205, "endOffset": 209}, {"referenceID": 8, "context": "3We note that the d = 0 accuracy for the human-generated instructions is consistent with that reported elsewhere [9].", "startOffset": 113, "endOffset": 116}, {"referenceID": 46, "context": "Nevertheless, there are situations in which a longer path may afford instructions that are more straightforward [47] or that increase the likelihood of reaching the destination [22].", "startOffset": 112, "endOffset": 116}, {"referenceID": 21, "context": "Nevertheless, there are situations in which a longer path may afford instructions that are more straightforward [47] or that increase the likelihood of reaching the destination [22].", "startOffset": 177, "endOffset": 181}, {"referenceID": 40, "context": "Another interesting direction for a future work would be to involve the integration of a model of instruction followers [41] with our architecture in an effort to learn to generate instructions that are easier to follow.", "startOffset": 120, "endOffset": 124}], "year": 2016, "abstractText": "Modern robotics applications that involve humanrobot interaction require robots to be able to communicate with humans seamlessly and effectively. Natural language provides a flexible and efficient medium through which robots can exchange information with their human partners. Significant advancements have been made in developing robots capable of interpreting free-form instructions, but less attention has been devoted to endowing robots with the ability to generate natural language. We propose a navigational guide model that enables robots to generate natural language instructions that allow humans to navigate a priori unknown environments. We first decide which information to share with the user according to their preferences, using a policy trained from human demonstrations via inverse reinforcement learning. We then \u201ctranslate\u201d this information into a natural language instruction using a neural sequence-tosequence model that learns to generate free-form instructions from natural language corpora. We evaluate our method on a benchmark route instruction dataset and achieve a BLEU score of 72.18% when compared to human-generated reference instructions. We additionally conduct navigation experiments with human participants that demonstrate that our method generates instructions that people follow as accurately and easily as those produced by humans.", "creator": "LaTeX with hyperref package"}}}