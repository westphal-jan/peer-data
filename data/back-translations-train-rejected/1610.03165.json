{"id": "1610.03165", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Oct-2016", "title": "Long Short-Term Memory based Convolutional Recurrent Neural Networks for Large Vocabulary Speech Recognition", "abstract": "Long short-term memory (LSTM) recurrent neural networks (RNNs) have been shown to give state-of-the-art performance on many speech recognition tasks, as they are able to provide the learned dynamically changing contextual window of all sequence history. On the other hand, the convolutional neural networks (CNNs) have brought significant improvements to deep feed-forward neural networks (FFNNs), as they are able to better reduce spectral variation in the input signal. In this paper, a network architecture called as convolutional recurrent neural network (CRNN) is proposed by combining the CNN and LSTM RNN. In the proposed CRNNs, each speech frame, without adjacent context frames, is organized as a number of local feature patches along the frequency axis, and then a LSTM network is performed on each feature patch along the time axis. We train and compare FFNNs, LSTM RNNs and the proposed LSTM CRNNs at various number of configurations. Experimental results show that the LSTM CRNNs can exceed state-of-the-art speech recognition performance.", "histories": [["v1", "Tue, 11 Oct 2016 02:48:13 GMT  (596kb)", "http://arxiv.org/abs/1610.03165v1", "Published in INTERSPEECH 2015, September 6-10, 2015, Dresden, Germany"]], "COMMENTS": "Published in INTERSPEECH 2015, September 6-10, 2015, Dresden, Germany", "reviews": [], "SUBJECTS": "cs.CL cs.NE", "authors": ["xiangang li", "xihong wu"], "accepted": false, "id": "1610.03165"}, "pdf": {"name": "1610.03165.pdf", "metadata": {"source": "CRF", "title": "Long Short-Term Memory based Convolutional Recurrent Neural Networks for Large Vocabulary Speech Recognition", "authors": ["Xiangang Li", "Xihong Wu"], "emails": ["wxh}@cis.pku.edu.cn"], "sections": [{"heading": null, "text": "ar Xiv: 161 0.03 165v 1 [cs.C L] 11 Oct 201 6"}, {"heading": "1. Introduction", "text": "In fact, most of them will be able to play by the rules they have established in the past."}, {"heading": "2. Review of LSTM RNNs and CNNs", "text": "In order to present the proposed network architecture, the conventional LSTM and CNN architectures for acoustic modelling are first presented."}, {"heading": "2.1. LSTM RNNs for acoustic modeling", "text": "In modern feed-forward neural networks (FFNNs) based on hybrid acoustic problems (Whyxt = 1), acoustic context windows from 11 to 31 frames are typically used as inputs; the cyclic connections in RNNNs utilize a self-learned amount of time contexts, which in principle makes them better suited for acoustic modeling; the RNN-HMM hybrids have been studied for almost twenty years (e.g. [21] [22] [23]), and it has been shown that they recently.Given an input speech sequence x = (x1, x2,. xT), a conventional RNN calculates the hidden vector sequenceh = (h1, h2,., hT) and output vector sequence y = (y1, y2, yT)."}, {"heading": "2.2. CNNs for acoustic modeling", "text": "CNN is able to model local frequency structures by applying linear revolutionary filters to the local feature patches, which represent a limited bandwidth of the entire speech spectrum. To represent voice input in a frequency scale that can be divided into a number of local bands, CNN always uses the filter bank features as inputs for acoustic modeling. Assuming that the entire input feature is organized as J local patches and each patch has xj (j = 1,.., J) s frequency bands, the equations of the revolutionary layer can be described as follows: hj = \u03b8 (Wxj + b), (j = 1,., J) (9) Where it is the activation function, hj is the revolutionary layer of the output vector of the jth feature patch. For each feature patch, the revolutionary filter can represent the epinput weights in the notch and in the notch."}, {"heading": "3. LSTM based convolutional recurrent neural networks", "text": "In fact, it is a reactionary project that is able to retaliate and retaliate."}, {"heading": "4. Experiments and discussion", "text": "We train and compare FFNNs, LSTM RNNNs and the proposed LSTM CRNNs on a major speech recognition task - HKUST Conversational Voice Recognition in Mandarin Chinese [33]. The corpus (LDC2005S15, LDC2005T32) is collected and transcribed by the Hong Kong University of Science and Technology (HKUST), which includes 150 hours of speeches and 873 calls in the training set and 24 calls in the development set. In our experiments, approximately 3 hours of speeches were randomly selected from the training set used as the validation kit for network training. The original development kit in the corpus was used as an ASR test kit that is not used in training or in the determination processes to determine hyperparameters."}, {"heading": "4.1. Experimental setup", "text": "The speech in the corpus is represented with 25ms frames of log filter bank coefficients of the Mel scale (including the energy value), together with their first and second order temporal derivatives. FFNs use concatenated features constructed by concatenating the current frame with 5 frames in its left and right context. Inputs to the LSTM RNNNs and LSTM CRNNNNs are only the current frames (not a window of frames). A trigram language model calculated using all acoustic model training transcriptions is used in all experiments. Hybrid approach [2] is used, in which the outputs of the neural networks are converted as pseudo-probabilities into hidden Markov models (HMM)."}, {"heading": "4.2. Baseline systems", "text": "First, FFNNNs and LSTM RNNNs are configured as base layers at different numbers of configurations, and the results are summarized in Table 1 and Table 2. It is worth noting that we found that appropriate more senons would lead to performance improvements. Thus, in this paper, we have 5529 senons versus 3302 senons in [19] [39], resulting in slightly better experimental results than in [19]. In Table 1, \"4 \u00d7 ReLU2000\" network has 4 hidden layers and each layer has 2000 ReLU [40] [41], and \"4 \u00d7 Maxout800G3\" network has 4 hidden layers and each layer has 800 maxout units [42] [43], with group size 3. CNN, referred to as \"2 \u00d7 Conv + 3 \u00d7 LU750 M networks with LU750-M layers and 3 LU750 layers has 2-pooling layers and 3-pooling layers."}, {"heading": "4.3. Results of CLSTMs", "text": "Since pooling is a very important concept in the CNNs, we compared the models with and without pooling for the proposed CLSTMs, which have no discernible performance differences. However, since the models with the pooling layer have a lower number of parameters than those without pooling layer, we can increase the number of LSTM cells, and the pooling size is 3."}, {"heading": "5. Conclusions", "text": "In this paper, an LSTM-based architecture of the Convolutional Recurrent Neural Network (CRNN) is proposed for acoustic modeling by combining the CNNs and LSTM RNNNs, which is constructed by replacing the filter in conventional CNNs with a recursive filter, in particular an LSTM-based filter. The proposed network can be considered as an introduction of the dynamically changing context window in the LSTM network into conventional CNNs, or as an introduction of the inventory of frequency shift embedded in the conventional structure of LSTM RNNNs. In other words, the proposed network contains revolutionary operations along the frequency axis and recursive operations along the time axes. We have empirically evaluated the proposed network against FFNNN and LSTM networks using a large vocabulary task. In the experiments, different configurations for the structional improvement of the STNN networks were compared to the proposed improvements in the CRN."}, {"heading": "6. References", "text": "[1] A. Mohamed, G. Dahl, and G. Hinton, \"Acoustic modeling usingdeep belief networks,\" IEEE Trans. Audio Speech Lang. Processing, vol. 20, pp. 14-22, 2012. [2] G. Dahl, D. Yu, L. Deng, and A. Acero, \"Context-dependent pretrained deep neural networks for large-vocabulary speech recognition,\" IEEE Trans. Audio Speech Lang. Processing, vol. 20, pp. 30-42, 2012. [3] G. Hinton, L. Deng, D. Yu, G. Dahl, A. Mohamed, N. Jaitly, A. Senior, V. Vanhoucke, P. Nguyen, T. Kingsbury \"Deep neural networks for acoustic modeling in speech recognition: the shared views of four research groups,\" IEEE Signal Processing Mag, vol. 29, pp."}], "references": [{"title": "Acoustic modeling using deep belief networks", "author": ["A. Mohamed", "G. Dahl", "G. Hinton"], "venue": "IEEE Trans. Audio Speech Lang. Processing, vol. 20, pp. 14\u201322, 2012.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "Context-dependent pretrained deep neural networks for large-vocabulary speech recognition", "author": ["G. Dahl", "D. Yu", "L. Deng", "A. Acero"], "venue": "IEEE Trans. Audio Speech Lang. Processing, vol. 20, pp. 30\u201342, 2012.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2012}, {"title": "Deep neural networks for acoustic modeling in speech recognition: the shared views of four research groups", "author": ["G. Hinton", "L. Deng", "D. Yu", "G. Dahl", "A. Mohamed", "N. Jaitly", "A. Senior", "V. Vanhoucke", "P. Nguyen", "T. Sainath", "B. Kingsbury"], "venue": "IEEE Signal Processing Mag., vol. 29, pp. 82\u201397, 2012.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "Lattice-based optimization of sequence classification criteria for neural-network acoustic modeling", "author": ["B. Kingsbury"], "venue": "ICASSP, 2009, pp. 3761\u20133764.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2009}, {"title": "Scalable minimum bayes risk training of deep neural network acoustic models using distributed hessian-free optimization", "author": ["B. Kingsbury", "T. Sainath", "H. Soltau"], "venue": "Interspeech, 2012, pp. 10\u201313.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2012}, {"title": "Sequencediscriminative training of deep neural networks", "author": ["K. Vesel\u00fd", "A. Ghoshal", "L. Burget", "D. Povey"], "venue": "Interspeech, 2013, pp. 2345\u20132349.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "Applying convolutional neural networks concepts to hybrid nn-hmm model for speech recognition", "author": ["O. Abdel-Hamid", "A. Mohamed", "H. Jiang", "G. Penn"], "venue": "ICASSP, 2012, pp. 4277\u20134280.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2012}, {"title": "Speech recognition with deep recurrent neural networks", "author": ["A. Graves", "A. Mohamed", "G. Hinton"], "venue": "ICASSP, 2013, pp. 6645\u2013 6649.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2013}, {"title": "Long short-term memory recurrent neural network architectures for large scale acoustic modeling", "author": ["H. Sak", "A. Senior", "F. Beaufays"], "venue": "Interspeech, 2014, pp. 338\u2013342.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Speaker adaptation of neural network acoustic models using i-vectors", "author": ["G. Saon", "H. Soltau", "D. Nahamoo", "M. Picheny"], "venue": "ASRU, 2013, pp. 55\u201359.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2013}, {"title": "Fast speaker adaptation of hybrid nn/hmm model for speech recognition based on discriminative learning of speaker code", "author": ["O. Abdel-Hamid", "H. Jiang"], "venue": "ICASSP, 2013, pp. 7942\u20137946.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2013}, {"title": "Convolutional neural networks for speech recognition", "author": ["O. Abdel-Hamid", "A. Mohamed", "H. Jiang", "L. Deng", "G. Penn", "D. Yu"], "venue": "IEEE/ACM Trans. Audio Speech Lang. Processing, vol. 22, pp. 1533\u20131545, 2014.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2014}, {"title": "Deep convolutional neural networks for lvcsr", "author": ["T. Sainath", "A. Mohamed", "B. Kingsbury", "B. Ramabhadran"], "venue": "ICASSP, 2013.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2013}, {"title": "Improvements to deep convolutional neural networks for lvcsr", "author": ["T. Sainath", "B. Kingsbury", "A. Mohamed", "G. Dahl", "G. Saon", "H. Soltau", "T. Beran", "A. Aravkin", "B. Ramabhadran"], "venue": "2013, arXiv:1309.1501.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}, {"title": "Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural network", "author": ["A. Graves", "S. Fern\u00e1ndez", "F. Gomez", "J. Schmidhuber"], "venue": "ICML, 2006, pp. 369\u2013376.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2006}, {"title": "Robust speech recognition using long short-term memory recurrent neural networks for hybrid acoustic modelling", "author": ["J. Geiger", "Z. Zhang", "F. Weninger", "B. Schuller", "G. Rigoll"], "venue": "Interspeech, 2014, pp. 631\u2013635.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2014}, {"title": "Hybrid speech recognition with deep bidirectional lstm", "author": ["A. Graves", "N. Jaitly", "A. Mohamed"], "venue": "ASRU, 2013, pp. 273\u2013278.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2013}, {"title": "Long short-term memory based recurrent neural network architectures for large vocabulary speech recognition", "author": ["H. Sak", "A. Senior", "F. Beaufays"], "venue": "2014, arXiv:1402.1128.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2014}, {"title": "Constructing long short-term memory based deep recurrent neural network for large vocabulary speech recognition", "author": ["X. Li", "X. Wu"], "venue": "ICASSP, 2015.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2015}, {"title": "Sequence discriminative distributed training of long short-term memory recurrent neural networks", "author": ["H. Sak", "O. Vinyals", "G. Heigold", "A. Senior", "E. McDermott", "R. Monga", "M. Mao"], "venue": "Interspeech, 2014, pp. 1209\u20131213.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}, {"title": "An application of recurrent nets to phoneme probability estimation", "author": ["A. Robinson"], "venue": "IEEE Trans. Neural Networks, vol. 5, pp. 298\u2013 305, 1994.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1994}, {"title": "Revisiting recurrent neural networks for robust asr", "author": ["O. Vinyals", "S. Ravuri", "D. Povey"], "venue": "ICASSP, 2012, pp. 4085\u20134088.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2012}, {"title": "Sequence classification using the high-level features extracted from deep neural networks", "author": ["L. Deng", "J. Chen"], "venue": "ICASSP, 2014, pp. 6844\u20136848.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning long-term dependencies with gradient descent is difficult", "author": ["Y. Bengio", "P. Simard", "P. Frasconi"], "venue": "IEEE Trans. Neural Networks, vol. 5, pp. 157\u2013166, 1994.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1994}, {"title": "Long short-term memory", "author": ["S. Hochreiter", "J. Schimidhuber"], "venue": "Neural Computation, vol. 9, pp. 1735\u20131780, 1997.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 1997}, {"title": "Learning to forget: Continual prediction with lstm", "author": ["F. Gers", "J. Schmidhuber", "F. Cummins"], "venue": "Neural Computation, vol. 12, pp. 2451\u20132471, 2000.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2000}, {"title": "Learning precise timing with lstm recurrent networks", "author": ["F. Gers", "N. Schraudolph", "J. Schmidhuber"], "venue": "Journal of Machine Learning Research, vol. 3, pp. 115\u2013143, 2003.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2003}, {"title": "Convolutional neural networks applied to house numbers digit classification", "author": ["P. Sermanet", "S. Chintala", "Y. LeCun"], "venue": "ICPR, 2012, pp. 3288\u20133291.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2012}, {"title": "Stochastic pooling for regularization of deep convolutional neural networks", "author": ["M. Zeiler", "R. Fergus"], "venue": "ICLR, 2013.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2013}, {"title": "Network in network", "author": ["M. Lin", "Q. Chen", "Y.S."], "venue": "ICLR, 2014.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2014}, {"title": "Multi-dimensional recurrent neural networks", "author": ["A. Graves", "S. Fern\u00e1ndez", "J. Schmidhuber"], "venue": "International Conference on Artificial Neural Networks, 2007.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2007}, {"title": "Convolutional lstm networks for subcellular localization of proteins", "author": ["S. Sonderby", "C. Sonderby", "H. Nielsen", "O. Winther"], "venue": "2015, arXiv:1503.01919.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2015}, {"title": "Hkust/mts: A very large scale mandarin telephone speech corpus", "author": ["Y. Liu", "P. Fung", "Y. Yang", "C. Cieri", "S. Huang", "D. Graff"], "venue": "ISCSLP, 2006, pp. 724\u2013735.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2006}, {"title": "Long short-term memory recurrent neural network architectures for large scale acoustic modeling", "author": ["H. Sak", "A. Senior", "F. Beaufays"], "venue": "Interspeech, 2014, pp. 338\u2013342.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2014}, {"title": "An efficient gradient-based algorithm for online training of recurrent neural network trajectories", "author": ["R. Williams", "J. Peng"], "venue": "Neural Computation, vol. 2, pp. 490\u2013501, 1990.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 1990}, {"title": "Asynchronous peer-topeer data mining with stochastic gradient descent", "author": ["R. Orm\u00e1ndi", "I. Heged\u00fcs", "M. Jelasity"], "venue": "Lecture Notes in Computer Science, pp. 528\u2013540, 2011.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2011}, {"title": "Asynchronous stochastic gradient descent for dnn training", "author": ["S. Zhang", "C. Zhang", "Z. You", "R. Zheng", "B. Xu"], "venue": "ICASSP, 2013, pp. 6660\u20136663.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2013}, {"title": "On the difficulty of training recurrent neural networks", "author": ["R. Pascanu", "Y. Bengio"], "venue": "2012, arXiv:1211.5063.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2012}, {"title": "Improving long short-term memory networks using maxout units for large vocabulary speech recognition", "author": ["X. Li", "X. Wu"], "venue": "ICASSP, 2015.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2015}, {"title": "On rectified linear units for speech processing", "author": ["M. Zeiler", "M. Ranzato", "R. Monga", "M. Mao", "K. Yang", "Q. Le", "P. Nguyen", "A. Senior", "V. Vanhouche", "J. Dean", "G. Hinton"], "venue": "ICASSP, 2013, pp. 3517\u20133521.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2013}, {"title": "Improving deep neural networks for lvcsr using rectified linear units and dropout", "author": ["G. Dahl", "T. Sainath", "G. Hinton"], "venue": "ICASSP, 2013, pp. 8609\u20138613.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2013}, {"title": "Deep maxout neural networks for speech recognition", "author": ["M. Cai", "Y. Shi", "J. Liu"], "venue": "ASRU, 2013, pp. 291\u2013296.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2013}, {"title": "Deep maxout networks for low resource speech recognition", "author": ["Y. Miao", "S. Rawat", "F. Metze"], "venue": "ASRU, 2013, pp. 398\u2013403.", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "[1][2][3]).", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[1][2][3]).", "startOffset": 3, "endOffset": 6}, {"referenceID": 2, "context": "[1][2][3]).", "startOffset": 6, "endOffset": 9}, {"referenceID": 3, "context": "[4][5][6]), the network architectures (e.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[4][5][6]), the network architectures (e.", "startOffset": 3, "endOffset": 6}, {"referenceID": 5, "context": "[4][5][6]), the network architectures (e.", "startOffset": 6, "endOffset": 9}, {"referenceID": 6, "context": "[7][8][9]), and speaker adaptive methods (e.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[7][8][9]), and speaker adaptive methods (e.", "startOffset": 3, "endOffset": 6}, {"referenceID": 8, "context": "[7][8][9]), and speaker adaptive methods (e.", "startOffset": 6, "endOffset": 9}, {"referenceID": 9, "context": "[10][11]), and have been shown to give significant performance improvements.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[10][11]), and have been shown to give significant performance improvements.", "startOffset": 4, "endOffset": 8}, {"referenceID": 6, "context": "[7] proposed to apply CNNs in the frequency domain to explicitly normalize speech spectral features to achieve frequency invariance and enforce locality of features, which have shown that further error rate reduction could be obtained comparing to the fully-connected DNNs on the phoneme recognition task.", "startOffset": 0, "endOffset": 3}, {"referenceID": 11, "context": "Subsequently, researchers have applied this idea on large vocabulary speech recognition tasks [12][13][14].", "startOffset": 94, "endOffset": 98}, {"referenceID": 12, "context": "Subsequently, researchers have applied this idea on large vocabulary speech recognition tasks [12][13][14].", "startOffset": 98, "endOffset": 102}, {"referenceID": 13, "context": "Subsequently, researchers have applied this idea on large vocabulary speech recognition tasks [12][13][14].", "startOffset": 102, "endOffset": 106}, {"referenceID": 7, "context": "[8] proposed to use stacked bidirectional LSTM network trained with connectionist temporal classification (CTC) [15] for phoneme recognition.", "startOffset": 0, "endOffset": 3}, {"referenceID": 14, "context": "[8] proposed to use stacked bidirectional LSTM network trained with connectionist temporal classification (CTC) [15] for phoneme recognition.", "startOffset": 112, "endOffset": 116}, {"referenceID": 15, "context": "Subsequently, LSTM RNNs have been successfully applied and shown to give state-of-the-art performance on robust speech recognition task [16], and many large vocabulary speech recognition tasks [9][17][18][19][20].", "startOffset": 136, "endOffset": 140}, {"referenceID": 8, "context": "Subsequently, LSTM RNNs have been successfully applied and shown to give state-of-the-art performance on robust speech recognition task [16], and many large vocabulary speech recognition tasks [9][17][18][19][20].", "startOffset": 193, "endOffset": 196}, {"referenceID": 16, "context": "Subsequently, LSTM RNNs have been successfully applied and shown to give state-of-the-art performance on robust speech recognition task [16], and many large vocabulary speech recognition tasks [9][17][18][19][20].", "startOffset": 196, "endOffset": 200}, {"referenceID": 17, "context": "Subsequently, LSTM RNNs have been successfully applied and shown to give state-of-the-art performance on robust speech recognition task [16], and many large vocabulary speech recognition tasks [9][17][18][19][20].", "startOffset": 200, "endOffset": 204}, {"referenceID": 18, "context": "Subsequently, LSTM RNNs have been successfully applied and shown to give state-of-the-art performance on robust speech recognition task [16], and many large vocabulary speech recognition tasks [9][17][18][19][20].", "startOffset": 204, "endOffset": 208}, {"referenceID": 19, "context": "Subsequently, LSTM RNNs have been successfully applied and shown to give state-of-the-art performance on robust speech recognition task [16], and many large vocabulary speech recognition tasks [9][17][18][19][20].", "startOffset": 208, "endOffset": 212}, {"referenceID": 6, "context": "In the literatures, most CNNs were applied on the frequency domain, and the variability along the time axis is handled by the fixed long time contextual window [7][12][13].", "startOffset": 160, "endOffset": 163}, {"referenceID": 11, "context": "In the literatures, most CNNs were applied on the frequency domain, and the variability along the time axis is handled by the fixed long time contextual window [7][12][13].", "startOffset": 163, "endOffset": 167}, {"referenceID": 12, "context": "In the literatures, most CNNs were applied on the frequency domain, and the variability along the time axis is handled by the fixed long time contextual window [7][12][13].", "startOffset": 167, "endOffset": 171}, {"referenceID": 20, "context": "[21][22][23]), and have been shown to give the state-ofthe-art performance on many ASR tasks by introducing LSTM RNNs recently.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "[21][22][23]), and have been shown to give the state-ofthe-art performance on many ASR tasks by introducing LSTM RNNs recently.", "startOffset": 4, "endOffset": 8}, {"referenceID": 22, "context": "[21][22][23]), and have been shown to give the state-ofthe-art performance on many ASR tasks by introducing LSTM RNNs recently.", "startOffset": 8, "endOffset": 12}, {"referenceID": 23, "context": "However, RNNs are hard to be trained properly due to the vanishing gradient and exploding gradient problems as described in [24].", "startOffset": 124, "endOffset": 128}, {"referenceID": 24, "context": "To address these problems, long short-term memory (LSTM) is proposed [25].", "startOffset": 69, "endOffset": 73}, {"referenceID": 24, "context": "The modern LSTM RNN architecture [25][26][27] is shown in Figure 1.", "startOffset": 33, "endOffset": 37}, {"referenceID": 25, "context": "The modern LSTM RNN architecture [25][26][27] is shown in Figure 1.", "startOffset": 37, "endOffset": 41}, {"referenceID": 26, "context": "The modern LSTM RNN architecture [25][26][27] is shown in Figure 1.", "startOffset": 41, "endOffset": 45}, {"referenceID": 8, "context": "Besides, the LSTM Projected (LSTMP) network is proposed in [9][18], which has a separate linear projection layer after the LSTM layer, and yield improved performance on a large vocabulary speech recognition task.", "startOffset": 59, "endOffset": 62}, {"referenceID": 17, "context": "Besides, the LSTM Projected (LSTMP) network is proposed in [9][18], which has a separate linear projection layer after the LSTM layer, and yield improved performance on a large vocabulary speech recognition task.", "startOffset": 62, "endOffset": 66}, {"referenceID": 13, "context": "Usually, the max pooling function can be used as the pooling strategy, and in literature [14], variants of pooling functions, such as the lp pooling [28], stochastic pooling [29] were also evaluated.", "startOffset": 89, "endOffset": 93}, {"referenceID": 27, "context": "Usually, the max pooling function can be used as the pooling strategy, and in literature [14], variants of pooling functions, such as the lp pooling [28], stochastic pooling [29] were also evaluated.", "startOffset": 149, "endOffset": 153}, {"referenceID": 28, "context": "Usually, the max pooling function can be used as the pooling strategy, and in literature [14], variants of pooling functions, such as the lp pooling [28], stochastic pooling [29] were also evaluated.", "startOffset": 174, "endOffset": 178}, {"referenceID": 29, "context": "In addition, a structure called \u201cNetwork In Network\u201d (NIN) is proposed in [30] to enhance model for local patches within the receptive field, which replace the filters in conventional CNNs with a \u201cmicro network\u201d, such as a multilayer perceptron consisting of multiple fully connected layers with nonlinear activation functions.", "startOffset": 74, "endOffset": 78}, {"referenceID": 30, "context": "A similar network architecture to CLSTM is the multidimensional LSTM [31].", "startOffset": 69, "endOffset": 73}, {"referenceID": 31, "context": "Another related work is introduced in [32] on biological sequence data analyzing, where the network architecture is a 1-dimensional convolutional layer followed by an LSTM layer, a fully connected layer and a final softmax layer, which can be understood as the stack of convolutional layer and LSTM layer.", "startOffset": 38, "endOffset": 42}, {"referenceID": 32, "context": "We train and compare FFNNs, LSTM RNNs and the proposed LSTM CRNNs on a large vocabulary speech recognition task the HKUST Mandarin Chinese conversational telephone speech recognition [33].", "startOffset": 183, "endOffset": 187}, {"referenceID": 1, "context": "The hybrid approach [2][34] is used, in which the neural networks\u2019 outputs are converted as pseudo likelihood as the state output probability in hidden Markov model (HMM) framework.", "startOffset": 20, "endOffset": 23}, {"referenceID": 33, "context": "The hybrid approach [2][34] is used, in which the neural networks\u2019 outputs are converted as pseudo likelihood as the state output probability in hidden Markov model (HMM) framework.", "startOffset": 23, "endOffset": 27}, {"referenceID": 34, "context": "In the training, the truncated back-propagation though time (BPTT) learning algorithm [35] is adopted.", "startOffset": 86, "endOffset": 90}, {"referenceID": 35, "context": "In order to train these networks on multi-GPU devices, asynchronous stochastic gradient descent [36][37] is adopted.", "startOffset": 96, "endOffset": 100}, {"referenceID": 36, "context": "In order to train these networks on multi-GPU devices, asynchronous stochastic gradient descent [36][37] is adopted.", "startOffset": 100, "endOffset": 104}, {"referenceID": 37, "context": "The strategy introduced in [38] is applied to scale down the gradients.", "startOffset": 27, "endOffset": 31}, {"referenceID": 18, "context": "Thus, in this paper, we have 5529 senones against 3302 senones in [19][39], leading to slightly better experimental results than that in [19][39].", "startOffset": 66, "endOffset": 70}, {"referenceID": 38, "context": "Thus, in this paper, we have 5529 senones against 3302 senones in [19][39], leading to slightly better experimental results than that in [19][39].", "startOffset": 70, "endOffset": 74}, {"referenceID": 18, "context": "Thus, in this paper, we have 5529 senones against 3302 senones in [19][39], leading to slightly better experimental results than that in [19][39].", "startOffset": 137, "endOffset": 141}, {"referenceID": 38, "context": "Thus, in this paper, we have 5529 senones against 3302 senones in [19][39], leading to slightly better experimental results than that in [19][39].", "startOffset": 141, "endOffset": 145}, {"referenceID": 39, "context": "In Table 1, \u201c4\u00d7ReLU2000\u201d network has 4 hidden layers and each layer has 2000 rectified linear units (ReLU) [40][41], and \u201c4\u00d7Maxout800G3\u201d network has 4 hidden layers and each layer has 800 maxout units [42][43], where the group size is 3.", "startOffset": 107, "endOffset": 111}, {"referenceID": 40, "context": "In Table 1, \u201c4\u00d7ReLU2000\u201d network has 4 hidden layers and each layer has 2000 rectified linear units (ReLU) [40][41], and \u201c4\u00d7Maxout800G3\u201d network has 4 hidden layers and each layer has 800 maxout units [42][43], where the group size is 3.", "startOffset": 111, "endOffset": 115}, {"referenceID": 41, "context": "In Table 1, \u201c4\u00d7ReLU2000\u201d network has 4 hidden layers and each layer has 2000 rectified linear units (ReLU) [40][41], and \u201c4\u00d7Maxout800G3\u201d network has 4 hidden layers and each layer has 800 maxout units [42][43], where the group size is 3.", "startOffset": 201, "endOffset": 205}, {"referenceID": 42, "context": "In Table 1, \u201c4\u00d7ReLU2000\u201d network has 4 hidden layers and each layer has 2000 rectified linear units (ReLU) [40][41], and \u201c4\u00d7Maxout800G3\u201d network has 4 hidden layers and each layer has 800 maxout units [42][43], where the group size is 3.", "startOffset": 205, "endOffset": 209}, {"referenceID": 18, "context": "Besides, based on the research in [19], LSTM based deep RNNs are constructed.", "startOffset": 34, "endOffset": 38}, {"referenceID": 8, "context": "Literatures [9][18] have proposed the LSTMP to make more effective use of model parameters to train acoustic models.", "startOffset": 12, "endOffset": 15}, {"referenceID": 17, "context": "Literatures [9][18] have proposed the LSTMP to make more effective use of model parameters to train acoustic models.", "startOffset": 15, "endOffset": 19}, {"referenceID": 12, "context": "Besides, multiple convolutional layers can also improve CNNs [13][14].", "startOffset": 61, "endOffset": 65}, {"referenceID": 13, "context": "Besides, multiple convolutional layers can also improve CNNs [13][14].", "startOffset": 65, "endOffset": 69}, {"referenceID": 19, "context": "Future work includes training the CLTSM CRNNs using sequence discriminative training criterion [20] and experiments on a larger corpus.", "startOffset": 95, "endOffset": 99}], "year": 2016, "abstractText": "Long short-term memory (LSTM) recurrent neural networks (RNNs) have been shown to give state-of-the-art performance on many speech recognition tasks, as they are able to provide the learned dynamically changing contextual window of all sequence history. On the other hand, the convolutional neural networks (CNNs) have brought significant improvements to deep feed-forward neural networks (FFNNs), as they are able to better reduce spectral variation in the input signal. In this paper, a network architecture called as convolutional recurrent neural network (CRNN) is proposed by combining the CNN and LSTM RNN. In the proposed CRNNs, each speech frame, without adjacent context frames, is organized as a number of local feature patches along the frequency axis, and then a LSTM network is performed on each feature patch along the time axis. We train and compare FFNNs, LSTM RNNs and the proposed LSTM CRNNs at various number of configurations. Experimental results show that the LSTM CRNNs can exceed stateof-the-art speech recognition performance.", "creator": "LaTeX with hyperref package"}}}