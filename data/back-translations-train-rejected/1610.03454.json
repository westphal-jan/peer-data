{"id": "1610.03454", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Oct-2016", "title": "Deep Variational Canonical Correlation Analysis", "abstract": "We present deep variational canonical correlation analysis (VCCA), a deep multi-view learning model that extends the latent variable model interpretation of linear CCA~\\citep{BachJordan05a} to nonlinear observation models parameterized by deep neural networks (DNNs). Marginal data likelihood as well as inference are intractable under this model. We derive a variational lower bound of the data likelihood by parameterizing the posterior density of the latent variables with another DNN, and approximate the lower bound via Monte Carlo sampling. Interestingly, the resulting model resembles that of multi-view autoencoders~\\citep{Ngiam_11b}, with the key distinction of an additional sampling procedure at the bottleneck layer. We also propose a variant of VCCA called VCCA-private which can, in addition to the \"common variables\" underlying both views, extract the \"private variables\" within each view. We demonstrate that VCCA-private is able to disentangle the shared and private information for multi-view data without hard supervision.", "histories": [["v1", "Tue, 11 Oct 2016 18:22:05 GMT  (8089kb,D)", "http://arxiv.org/abs/1610.03454v1", null], ["v2", "Mon, 14 Nov 2016 16:29:11 GMT  (1906kb,D)", "http://arxiv.org/abs/1610.03454v2", "In submission to ICLR 2017"], ["v3", "Sat, 25 Feb 2017 03:39:12 GMT  (2897kb,D)", "http://arxiv.org/abs/1610.03454v3", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["weiran wang", "xinchen yan", "honglak lee", "karen livescu"], "accepted": false, "id": "1610.03454"}, "pdf": {"name": "1610.03454.pdf", "metadata": {"source": "CRF", "title": "Deep Variational Canonical Correlation Analysis", "authors": ["Weiran Wang", "Honglak Lee", "Karen Livescu"], "emails": ["weiranwang@ttic.edu", "honglak@eecs.umich.edu", "klivescu@ttic.edu"], "sections": [{"heading": "1 Introduction", "text": "The aim is to learn useful features of each view using complementary information contained in the views. The intuition underlying this setting is that the learned features can help uncover the common sources of variation in the views, which can, however, be helpful for exploratory analysis or for downstream tasks. A classic approach in this environment is canonical correlation analysis (CCA, Hotelling, 1936) and its nonlinear extensions, including nuclear expansion (KCCA, Lai and Fyfe, 2000; Akaho, 2001; Bach and Jordan, 2002) and deep neural networking (DNN) of the extension (DCCA, Andrew et al, 2013; Wang et al., 2015b) projects two random vectors x (Rdx and y, Rdy) into a lower subspace, so that the projections are maximally correlated."}, {"heading": "2 Variational CCA", "text": "The probable latent variable model of CCA (Bach and Jordan, 2005) defines the following common distribution over the random variables (x, y): p (x, y, z) = p (x) p (x) p (y) p (y) p (y) = p (x) p (x, y) dz (x, y) dz (2) The assumption underlying this model is that the latent variables z (x) p (x) p (p) p (x) p (x) p (x) p (z) and p (y) x (z) x (z) x) x have a limited representational force. In this paper, we consider nonlinear observation models p) p."}, {"heading": "2.1 Extracting private variables", "text": "One potential disadvantage of this model is that it is a common variable that can be generated by the views themselves, which can be too restrictive in practice. In other words, there may be large variations in the input space that cannot be explained by the common variables, making the objective variables difficult to optimize. It may then be advantageous to model the private variables within the individual views. In other words, there may be large variations in the input space that cannot be explained by the common variables."}, {"heading": "3 Related work", "text": "Recently, there has been a lot of interest in unmonitored deep generative models (Kingma and Welling, 2014; Rezende et al., 2014; Goodfellow et al., 2014; Gregor et al., 2015; Makhzani et al., 2016; Burda et al., 2016; Alain et al., 2016). A common motivation behind these models is that the generative models can capture rich distributions for complex inputs with the meaningfulness of DNNs. Furthermore, if we are able to generate realistic samples from the learned distribution, we can conclude that we have discovered the underlying structure of the data that allows us to reduce sample complexity for learning for downstream tasks. However, previous models have largely focused on data from a single point of view. Here, we focus on the multiview setting, where multiple views of the data are available for functional extraction, but only a view of the test time is available (in downstream tasks)."}, {"heading": "4 Experimental results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Noisy MNIST dataset", "text": "We first demonstrate our algorithms on the noise MNIST database projected by Wang et al. (2015b), which is generated using the MNIST database (LeCun et al., 1998), which consists of 28 x 28 grayscales, with 60K / 10K images for training / testing. We first capture the pixel values in the range [0, 1], then randomly rotate the images from [\u2212 \u03c0 / 4] and the resulting images are used as inputs. For each view, we randomly select an image of the same identity (0-9), add independent random noise scanned from [0, 1] to each pixel, and truncate the pixel end values to [0, 1] to get the corresponding view."}, {"heading": "4.2 XRMB speech-articulation dataset", "text": "Our data set is the Wisconsin X-ray microbeam (XRMB) corpus (Westbury, 1994), which contains simultaneously recorded speech and articulation measurements from 47 American English teachers. We follow the setup of Wang et al. (2015a, b) and use the learned features for speaker-independent phonetic recognition. The two input views are standard 39D acoustic features (13 MFCCs) along with their first and second derivatives and 16D articulation features (horizontal / vertical displacement of 8 pellets attached to several parts of the vocal tract), each of which associates a 7-frame window to integrate context information. As in previous work, the XRMB speakers are divided into disjoint sets of 35 / 8 / 2 speakers."}, {"heading": "5 Conclusions", "text": "We have proposed a variational canonical correlation analysis (VCCA), an in-depth generative method for learning the representation of Multiview. Our method embodies a natural idea for multiview learning: The multiple views can be generated from a small set of common latent variables. VCCA is parameterized by DNNs and can be efficiently trained by back-propagation and is therefore scalable. We have also shown that by modelling private variables specific to each view, the VCCA private variable can potentially better untangle common / common variables and provide higher-quality reconstructions / examples. In the future, we will also investigate other earlier distributions, such as mixtures of casters or discrete random variables, which amplify the cluster effect in latent space and are in turn more suitable for discriminatory downstream tasks. We will also examine other observational models, including replacing the auto-textual encoversaries of the target structure of Goodfellow in 2014, which could have a stronger adjacent network structure;"}], "references": [{"title": "A kernel method for canonical correlation analysis", "author": ["Shotaro Akaho"], "venue": "In Proceedings of the International Meeting of the Psychometric Society (IMPS2001),", "citeRegEx": "Akaho.,? \\Q2001\\E", "shortCiteRegEx": "Akaho.", "year": 2001}, {"title": "GSNs: Generative stochastic networks", "author": ["Guillaume Alain", "Yoshua Bengio", "Li Yao", "Jason Yosinski", "Eric Thibodeau-Laufer", "Saizheng Zhang", "Pascal Vincent"], "venue": "Information and Inference,", "citeRegEx": "Alain et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Alain et al\\.", "year": 2016}, {"title": "Deep canonical correlation analysis", "author": ["Galen Andrew", "Raman Arora", "Jeff Bilmes", "Karen Livescu"], "venue": "In Proc. of the 30th Int. Conf. Machine Learning (ICML", "citeRegEx": "Andrew et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Andrew et al\\.", "year": 2013}, {"title": "Kernel independent component analysis", "author": ["Francis R. Bach", "Michael I. Jordan"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Bach and Jordan.,? \\Q2002\\E", "shortCiteRegEx": "Bach and Jordan.", "year": 2002}, {"title": "A probabilistic interpretation of canonical correlation analysis", "author": ["Francis R. Bach", "Michael I. Jordan"], "venue": "Technical Report 688,", "citeRegEx": "Bach and Jordan.,? \\Q2005\\E", "shortCiteRegEx": "Bach and Jordan.", "year": 2005}, {"title": "Importance weighted autoencoders", "author": ["Yuri Burda", "Roger Grosse", "Ruslan Salakhutdinov"], "venue": null, "citeRegEx": "Burda et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Burda et al\\.", "year": 2016}, {"title": "InfoGAN: Interpretable representation learning by information maximizing generative adversarial nets", "author": ["Xi Chen", "Yan Duan", "Rein Houthooft", "John Schulman", "Ilya Sutskever", "Pieter Abbeel"], "venue": "[cs.LG],", "citeRegEx": "Chen et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2016}, {"title": "Generative adversarial nets. In Advances in Neural Information Processing Systems (NIPS), pages 2672\u20132680", "author": ["Ian Goodfellow", "Jean Pouget-Abadie", "Mehdi Mirza", "Bing Xu", "David Warde-Farley", "Sherjil Ozair", "Aaron Courville", "Yoshua Bengio"], "venue": null, "citeRegEx": "Goodfellow et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2014}, {"title": "DRAW: A recurrent neural network for image generation", "author": ["Karol Gregor", "Ivo Danihelka", "Alex Graves", "Danilo Jimenez Rezende", "Daan Wierstra"], "venue": "In Proc. of the 32st Int. Conf. Machine Learning (ICML", "citeRegEx": "Gregor et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Gregor et al\\.", "year": 2015}, {"title": "Multilingual distributed representations without word alignment", "author": ["Karl Moritz Hermann", "Phil Blunsom"], "venue": "In Proc. of the 2nd Int. Conf. Learning Representations (ICLR 2014),", "citeRegEx": "Hermann and Blunsom.,? \\Q2014\\E", "shortCiteRegEx": "Hermann and Blunsom.", "year": 2014}, {"title": "Tandem connectionist feature extraction for conventional HMM systems", "author": ["Hynek Hermansky", "Daniel P.W. Ellis", "Sangita Sharma"], "venue": "In Proc. of the IEEE Int. Conf. Acoustics, Speech and Sig. Proc", "citeRegEx": "Hermansky et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Hermansky et al\\.", "year": 2000}, {"title": "Relations between two sets of variates", "author": ["Harold Hotelling"], "venue": "Biometrika, 28(3/4):321\u2013377,", "citeRegEx": "Hotelling.,? \\Q1936\\E", "shortCiteRegEx": "Hotelling.", "year": 1936}, {"title": "Factorized latent spaces with structured sparsity. In Advances in Neural Information Processing Systems (NIPS), pages 982\u2013990", "author": ["Yangqing Jia", "Mathieu Salzmann", "Trevor Darrell"], "venue": null, "citeRegEx": "Jia et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Jia et al\\.", "year": 2010}, {"title": "ADAM: A method for stochastic optimization", "author": ["Diederik Kingma", "Jimmy Ba"], "venue": "In Proc. of the 3rd Int. Conf. Learning Representations (ICLR 2015),", "citeRegEx": "Kingma and Ba.,? \\Q2015\\E", "shortCiteRegEx": "Kingma and Ba.", "year": 2015}, {"title": "Auto-encoding variational Bayes", "author": ["Diederik P. Kingma", "Max Welling"], "venue": "[stat.ML],", "citeRegEx": "Kingma and Welling.,? \\Q2014\\E", "shortCiteRegEx": "Kingma and Welling.", "year": 2014}, {"title": "Bayesian canonical correlation analysis", "author": ["Arto Klami", "Seppo Virtanen", "Samuel Kaski"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Klami et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Klami et al\\.", "year": 2013}, {"title": "Kernel and nonlinear canonical correlation analysis", "author": ["P.L. Lai", "C. Fyfe"], "venue": "Int. J. Neural Syst.,", "citeRegEx": "Lai and Fyfe.,? \\Q2000\\E", "shortCiteRegEx": "Lai and Fyfe.", "year": 2000}, {"title": "Gradient-based learning applied to document recognition", "author": ["Yann LeCun", "L\u00e9on Bottou", "Yoshua Bengio", "Patrick Haffner"], "venue": "Proc. IEEE,", "citeRegEx": "LeCun et al\\.,? \\Q1998\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 1998}, {"title": "Deep multilingual correlation for improved word embeddings. In The 2015 Conference of the North American Chapter of the Association for Computational Linguistics - Human Language Technologies (NAACL-HLT", "author": ["Ang Lu", "Weiran Wang", "Mohit Bansal", "Kevin Gimpel", "Karen Livescu"], "venue": null, "citeRegEx": "Lu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lu et al\\.", "year": 2015}, {"title": "Adversarial autoencoders", "author": ["Alireza Makhzani", "Jonathon Shlens", "Navdeep Jaitly", "Ian Goodfellow"], "venue": "In Proc. of the 4th Int. Conf. Learning Representations (ICLR", "citeRegEx": "Makhzani et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Makhzani et al\\.", "year": 2016}, {"title": "Nonlinear feature extraction using generalized canonical correlation analysis", "author": ["Thomas Melzer", "Michael Reiter", "Horst Bischof"], "venue": "In Proc. of the 11th Int. Conf. Artificial Neural Networks", "citeRegEx": "Melzer et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Melzer et al\\.", "year": 2001}, {"title": "Shared kernel information embedding for discriminative inference", "author": ["Roland Memisevic", "Leonid Sigal", "David J. Fleet"], "venue": "IEEE Trans. Pattern Analysis and Machine Intelligence,", "citeRegEx": "Memisevic et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Memisevic et al\\.", "year": 2012}, {"title": "Multimodal deep learning", "author": ["Jiquan Ngiam", "Aditya Khosla", "Mingyu Kim", "Juhan Nam", "Honglak Lee", "Andrew Ng"], "venue": "In Proc. of the 28th Int. Conf. Machine Learning (ICML", "citeRegEx": "Ngiam et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Ngiam et al\\.", "year": 2011}, {"title": "The Kaldi speech recognition toolkit", "author": ["Daniel Povey", "Arnab Ghoshal", "Gilles Boulianne", "Lukas Burget", "Ondrej Glembek", "Nagendra Goel", "Mirko Hannemann", "Petr Motlicek", "Yanmin Qian", "Petr Schwarz", "Jan Silovsky", "Georg Stemmer", "Karel Vesely"], "venue": "In Proc. of the 2011 IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU", "citeRegEx": "Povey et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Povey et al\\.", "year": 2011}, {"title": "Stochastic backpropagation and approximate inference in deep generative models", "author": ["Danilo Jimenez Rezende", "Shakir Mohamed", "Daan Wierstra"], "venue": "In Proc. of the 31st Int. Conf. Machine Learning (ICML", "citeRegEx": "Rezende et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Rezende et al\\.", "year": 2014}, {"title": "Factorized orthogonal latent spaces", "author": ["Mathieu Salzmann", "Carl Henrik Ek", "Raquel Urtasun", "Trevor Darrell"], "venue": "In Proc. of the 13th Int. Workshop on Artificial Intelligence and Statistics (AISTATS", "citeRegEx": "Salzmann et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Salzmann et al\\.", "year": 2010}, {"title": "Improved multimodal deep learning with variation of information", "author": ["Kihyuk Sohn", "Wenling Shang", "Honglak Lee"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Sohn et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sohn et al\\.", "year": 2014}, {"title": "Multimodal learning with deep boltzmann machines", "author": ["Nitish Srivastava", "Ruslan Salakhutdinov"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Srivastava and Salakhutdinov.,? \\Q2014\\E", "shortCiteRegEx": "Srivastava and Salakhutdinov.", "year": 2014}, {"title": "Dropout: A simple way to prevent neural networks from overfitting", "author": ["Nitish Srivastava", "Geoffrey E. Hinton", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan R. Salakhutdinov"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Srivastava et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Srivastava et al\\.", "year": 2014}, {"title": "Visualizing data using t-SNE", "author": ["Laurens J.P. van der Maaten", "Geoffrey E. Hinton"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Maaten and Hinton.,? \\Q2008\\E", "shortCiteRegEx": "Maaten and Hinton.", "year": 2008}, {"title": "Bayesian CCA via group sparsity", "author": ["Seppo Virtanen", "Arto Klami", "Samuel Kaski"], "venue": "In Proc. of the 28th Int. Conf. Machine Learning (ICML", "citeRegEx": "Virtanen et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Virtanen et al\\.", "year": 2011}, {"title": "Variational Bayesian approach to canonical correlation analysis", "author": ["Chong Wang"], "venue": "IEEE Trans. Neural Networks,", "citeRegEx": "Wang.,? \\Q2007\\E", "shortCiteRegEx": "Wang.", "year": 2007}, {"title": "Large-scale approximate kernel canonical correlation analysis", "author": ["Weiran Wang", "Karen Livescu"], "venue": "In Proc. of the 4th Int. Conf. Learning Representations (ICLR 2016),", "citeRegEx": "Wang and Livescu.,? \\Q2016\\E", "shortCiteRegEx": "Wang and Livescu.", "year": 2016}, {"title": "Unsupervised learning of acoustic features via deep canonical correlation analysis", "author": ["Weiran Wang", "Raman Arora", "Karen Livescu", "Jeff Bilmes"], "venue": "In Proc. of the IEEE Int. Conf. Acoustics, Speech and Sig. Proc. (ICASSP\u201915),", "citeRegEx": "Wang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2015}, {"title": "On deep multi-view representation learning", "author": ["Weiran Wang", "Raman Arora", "Karen Livescu", "Jeff Bilmes"], "venue": "In Proc. of the 32st Int. Conf. Machine Learning (ICML", "citeRegEx": "Wang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2015}, {"title": "X-Ray Microbeam Speech Production", "author": ["John R. Westbury"], "venue": "Database User\u2019s Handbook Version", "citeRegEx": "Westbury.,? \\Q1994\\E", "shortCiteRegEx": "Westbury.", "year": 1994}, {"title": "Deep correlation for matching images and text", "author": ["Fei Yan", "Krystian Mikolajczyk"], "venue": "In Proc. of the 2015 IEEE Computer Society Conf. Computer Vision and Pattern Recognition", "citeRegEx": "Yan and Mikolajczyk.,? \\Q2015\\E", "shortCiteRegEx": "Yan and Mikolajczyk.", "year": 2015}, {"title": "The HTK book version 2.2", "author": ["Steve J. Young", "Dan Kernshaw", "Julian Odell", "Dave Ollason", "Valtcho Valtchev", "Phil Woodland"], "venue": "Technical report, Entropic,", "citeRegEx": "Young et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Young et al\\.", "year": 1999}], "referenceMentions": [{"referenceID": 4, "context": "Abstract We present deep variational canonical correlation analysis (VCCA), a deep multi-view learning model that extends the latent variable model interpretation of linear CCA (Bach and Jordan, 2005) to nonlinear observation models parameterized by deep neural networks (DNNs).", "startOffset": 177, "endOffset": 200}, {"referenceID": 22, "context": "Interestingly, the resulting model resembles that of multi-view autoencoders (Ngiam et al., 2011), with the key distinction of an additional sampling procedure at the bottleneck layer.", "startOffset": 77, "endOffset": 97}, {"referenceID": 0, "context": "A classical approach in this setting is canonical correlation analysis (CCA, Hotelling, 1936) and its nonlinear extensions, including the kernel extension (KCCA, Lai and Fyfe, 2000; Akaho, 2001; Melzer et al., 2001; Bach and Jordan, 2002) and the deep neural network (DNN) extension (DCCA, Andrew et al.", "startOffset": 155, "endOffset": 238}, {"referenceID": 20, "context": "A classical approach in this setting is canonical correlation analysis (CCA, Hotelling, 1936) and its nonlinear extensions, including the kernel extension (KCCA, Lai and Fyfe, 2000; Akaho, 2001; Melzer et al., 2001; Bach and Jordan, 2002) and the deep neural network (DNN) extension (DCCA, Andrew et al.", "startOffset": 155, "endOffset": 238}, {"referenceID": 3, "context": "A classical approach in this setting is canonical correlation analysis (CCA, Hotelling, 1936) and its nonlinear extensions, including the kernel extension (KCCA, Lai and Fyfe, 2000; Akaho, 2001; Melzer et al., 2001; Bach and Jordan, 2002) and the deep neural network (DNN) extension (DCCA, Andrew et al.", "startOffset": 155, "endOffset": 238}, {"referenceID": 4, "context": "There is a probabilistic latent variable model interpretation of linear CCA (Bach and Jordan, 2005) as shown in Figure 1.", "startOffset": 76, "endOffset": 99}, {"referenceID": 0, "context": "A classical approach in this setting is canonical correlation analysis (CCA, Hotelling, 1936) and its nonlinear extensions, including the kernel extension (KCCA, Lai and Fyfe, 2000; Akaho, 2001; Melzer et al., 2001; Bach and Jordan, 2002) and the deep neural network (DNN) extension (DCCA, Andrew et al., 2013; Wang et al., 2015b). CCA projects two random vectors x \u2208 Rx and y \u2208 Ry into a lower-dimensional subspace so that the projections are maximally correlated. There is a probabilistic latent variable model interpretation of linear CCA (Bach and Jordan, 2005) as shown in Figure 1. Assume that x and y are linear functions of some lower-dimensional random variable z \u2208 Rz , where dz \u2264 min(dx, dy). When the prior distribution of the latent variable p(z) and the conditional distributions p(x|z) and p(y|z) are all Gaussian, Bach and Jordan (2005) showed that E[z|x] (resp.", "startOffset": 182, "endOffset": 853}, {"referenceID": 4, "context": "Figure 1: Probabilistic interpretation of CCA (Bach and Jordan, 2005).", "startOffset": 46, "endOffset": 69}, {"referenceID": 18, "context": "DCCA has achieved good performance in the multi-view representation learning setting across different domains (Wang et al., 2015b,a; Lu et al., 2015; Yan and Mikolajczyk, 2015).", "startOffset": 110, "endOffset": 176}, {"referenceID": 36, "context": "DCCA has achieved good performance in the multi-view representation learning setting across different domains (Wang et al., 2015b,a; Lu et al., 2015; Yan and Mikolajczyk, 2015).", "startOffset": 110, "endOffset": 176}, {"referenceID": 22, "context": "Interestingly, VCCA is related to multiview autoencoders (Ngiam et al., 2011), with the key distinctions of additional regularization on the posterior distribution and the sampling procedure at the bottleneck layer.", "startOffset": 57, "endOffset": 77}, {"referenceID": 17, "context": ", 2015b,a; Lu et al., 2015; Yan and Mikolajczyk, 2015). However, a disadvantage of DCCA is that it directly looks for DNNs that can map inputs into the low-dimensional space, without a model for generating samples from the latent space. Although Wang et al. (2015b)\u2019s deep canonically correlated autoencoders (DCCAE) model optimizes the combination of the autoencoder objective (reconstruction errors) and the canonical correlation objective, the authors found that in practice, the canonical correlation term tends to dominate the reconstruction error terms in the DCCAE objective when tuning performance for a downstream task (especially when the inputs are noisy), and as a result the inputs are not reconstructed well.", "startOffset": 11, "endOffset": 266}, {"referenceID": 4, "context": "The probabilistic latent variable model of CCA (Bach and Jordan, 2005) defines the following joint distribution over the random variables (x,y):", "startOffset": 47, "endOffset": 70}, {"referenceID": 14, "context": "Inspired by Kingma and Welling (2014)\u2019s work on variational autoencoders (VAE), we approximate p\u03b8(z|x) with the conditional density q\u03c6(z|x;\u03c6z), where \u03c6z is the collection of parameters of another DNN.", "startOffset": 12, "endOffset": 38}, {"referenceID": 22, "context": "which is the objective of the multi-view autoencoder (Ngiam et al., 2011).", "startOffset": 53, "endOffset": 73}, {"referenceID": 13, "context": "We apply the ADAM algorithm (Kingma and Ba, 2015) for optimizing our objectives.", "startOffset": 28, "endOffset": 49}, {"referenceID": 14, "context": "Recently, there has been much interest in unsupervised deep generative models (Kingma and Welling, 2014; Rezende et al., 2014; Goodfellow et al., 2014; Gregor et al., 2015; Makhzani et al., 2016; Burda et al., 2016; Alain et al., 2016).", "startOffset": 78, "endOffset": 235}, {"referenceID": 24, "context": "Recently, there has been much interest in unsupervised deep generative models (Kingma and Welling, 2014; Rezende et al., 2014; Goodfellow et al., 2014; Gregor et al., 2015; Makhzani et al., 2016; Burda et al., 2016; Alain et al., 2016).", "startOffset": 78, "endOffset": 235}, {"referenceID": 7, "context": "Recently, there has been much interest in unsupervised deep generative models (Kingma and Welling, 2014; Rezende et al., 2014; Goodfellow et al., 2014; Gregor et al., 2015; Makhzani et al., 2016; Burda et al., 2016; Alain et al., 2016).", "startOffset": 78, "endOffset": 235}, {"referenceID": 8, "context": "Recently, there has been much interest in unsupervised deep generative models (Kingma and Welling, 2014; Rezende et al., 2014; Goodfellow et al., 2014; Gregor et al., 2015; Makhzani et al., 2016; Burda et al., 2016; Alain et al., 2016).", "startOffset": 78, "endOffset": 235}, {"referenceID": 19, "context": "Recently, there has been much interest in unsupervised deep generative models (Kingma and Welling, 2014; Rezende et al., 2014; Goodfellow et al., 2014; Gregor et al., 2015; Makhzani et al., 2016; Burda et al., 2016; Alain et al., 2016).", "startOffset": 78, "endOffset": 235}, {"referenceID": 5, "context": "Recently, there has been much interest in unsupervised deep generative models (Kingma and Welling, 2014; Rezende et al., 2014; Goodfellow et al., 2014; Gregor et al., 2015; Makhzani et al., 2016; Burda et al., 2016; Alain et al., 2016).", "startOffset": 78, "endOffset": 235}, {"referenceID": 1, "context": "Recently, there has been much interest in unsupervised deep generative models (Kingma and Welling, 2014; Rezende et al., 2014; Goodfellow et al., 2014; Gregor et al., 2015; Makhzani et al., 2016; Burda et al., 2016; Alain et al., 2016).", "startOffset": 78, "endOffset": 235}, {"referenceID": 27, "context": "Our work is also related to the deep multi-view probabilistic models based on restricted Boltzmann machines (Srivastava and Salakhutdinov, 2014; Sohn et al., 2014).", "startOffset": 108, "endOffset": 163}, {"referenceID": 26, "context": "Our work is also related to the deep multi-view probabilistic models based on restricted Boltzmann machines (Srivastava and Salakhutdinov, 2014; Sohn et al., 2014).", "startOffset": 108, "endOffset": 163}, {"referenceID": 31, "context": "On the other hand, there is a rich literature in modeling multi-view data using the same or similar graphical models behind VCCA/VCCA-private (Wang, 2007; Jia et al., 2010; Salzmann et al., 2010; Virtanen et al., 2011; Memisevic et al., 2012; Klami et al., 2013).", "startOffset": 142, "endOffset": 262}, {"referenceID": 12, "context": "On the other hand, there is a rich literature in modeling multi-view data using the same or similar graphical models behind VCCA/VCCA-private (Wang, 2007; Jia et al., 2010; Salzmann et al., 2010; Virtanen et al., 2011; Memisevic et al., 2012; Klami et al., 2013).", "startOffset": 142, "endOffset": 262}, {"referenceID": 25, "context": "On the other hand, there is a rich literature in modeling multi-view data using the same or similar graphical models behind VCCA/VCCA-private (Wang, 2007; Jia et al., 2010; Salzmann et al., 2010; Virtanen et al., 2011; Memisevic et al., 2012; Klami et al., 2013).", "startOffset": 142, "endOffset": 262}, {"referenceID": 30, "context": "On the other hand, there is a rich literature in modeling multi-view data using the same or similar graphical models behind VCCA/VCCA-private (Wang, 2007; Jia et al., 2010; Salzmann et al., 2010; Virtanen et al., 2011; Memisevic et al., 2012; Klami et al., 2013).", "startOffset": 142, "endOffset": 262}, {"referenceID": 21, "context": "On the other hand, there is a rich literature in modeling multi-view data using the same or similar graphical models behind VCCA/VCCA-private (Wang, 2007; Jia et al., 2010; Salzmann et al., 2010; Virtanen et al., 2011; Memisevic et al., 2012; Klami et al., 2013).", "startOffset": 142, "endOffset": 262}, {"referenceID": 15, "context": "On the other hand, there is a rich literature in modeling multi-view data using the same or similar graphical models behind VCCA/VCCA-private (Wang, 2007; Jia et al., 2010; Salzmann et al., 2010; Virtanen et al., 2011; Memisevic et al., 2012; Klami et al., 2013).", "startOffset": 142, "endOffset": 262}, {"referenceID": 17, "context": "The dataset is generated using the MNIST dataset (LeCun et al., 1998), which consists of 28\u00d7 28 grayscale digit images, with 60K/10K images for training/testing.", "startOffset": 49, "endOffset": 69}, {"referenceID": 26, "context": "1 Noisy MNIST dataset We first demonstrate our algorithms on the noisy MNIST dataset used by Wang et al. (2015b). The dataset is generated using the MNIST dataset (LeCun et al.", "startOffset": 93, "endOffset": 113}, {"referenceID": 2, "context": ", 2011), deep CCA (DCCA, Andrew et al., 2013), deep canonically correlated autoencoders (DCCAE, Wang et al., 2015b), and the constrastive loss of Hermann and Blunsom (2014). We use DNNs with 3 hidden layers of 1024 ReLU units each to parameterize the conditional distributions: q\u03c6(z|x), p\u03b8(x|z), p\u03b8(y|z) in VCCA, and additionally q\u03c6(hx|x) and q\u03c6(hy|y) in VCCA-private.", "startOffset": 25, "endOffset": 173}, {"referenceID": 2, "context": ", 2011), deep CCA (DCCA, Andrew et al., 2013), deep canonically correlated autoencoders (DCCAE, Wang et al., 2015b), and the constrastive loss of Hermann and Blunsom (2014). We use DNNs with 3 hidden layers of 1024 ReLU units each to parameterize the conditional distributions: q\u03c6(z|x), p\u03b8(x|z), p\u03b8(y|z) in VCCA, and additionally q\u03c6(hx|x) and q\u03c6(hy|y) in VCCA-private. The capacities of these networks are the same as those of their counterparts in DCCA and DCCAE from Wang et al. (2015b). The reconstruction networks p\u03b8(x|z) or p\u03b8(x|z,hx) model each pixel of x as an independent Bernoulli variable and parameterize its mean (using a sigmoid activation); p\u03b8(y|z) and p\u03b8(y|z,hy) model y with diagonal Gaussians and parameterize the mean (using a sigmoid activation) and standard deviation for each pixel dimension.", "startOffset": 25, "endOffset": 489}, {"referenceID": 28, "context": "The effect of dropout We add dropout (Srivastava et al., 2014) to all intermediate layers and the input layers and find it to be very useful in our models, with most of the gain coming from dropout applied to the samples of z, hx and hy.", "startOffset": 37, "endOffset": 62}, {"referenceID": 35, "context": "Our dataset is the Wisconsin X-ray microbeam (XRMB) corpus (Westbury, 1994), which contains simultaneously recorded speech and articulatory measurements from 47 American English speakers.", "startOffset": 59, "endOffset": 75}, {"referenceID": 10, "context": "All learned feature types are used in a \u201ctandem\u201d speech recognition approach (Hermansky et al., 2000), i.", "startOffset": 77, "endOffset": 101}, {"referenceID": 23, "context": "The mean phone error rates (PER) over 6 folds obtained with different features are 2As in Wang and Livescu (2016), we use the Kaldi speech recognition toolkit (Povey et al., 2011) for feature extraction and recognition with hidden Markov models.", "startOffset": 159, "endOffset": 179}, {"referenceID": 37, "context": "(2015a,b) (who instead used the HTK toolkit (Young et al., 1999)) for the same types of features, but the relative merits of different types of features are consistent.", "startOffset": 44, "endOffset": 64}, {"referenceID": 10, "context": "All learned feature types are used in a \u201ctandem\u201d speech recognition approach (Hermansky et al., 2000), i.e., they are appended to the original 39D features and used in a standard hidden Markov model (HMM)-based recognizer with Gaussian mixture observation distributions. Each method uses up to 3 ReLU hidden layers, each of 1024 units, for the projection mappings. For VCCA/VCCA-private, we use isotropic Gaussian observation models for each view, with the standard deviation tuned by grid search. The mean phone error rates (PER) over 6 folds obtained with different features are 2As in Wang and Livescu (2016), we use the Kaldi speech recognition toolkit (Povey et al.", "startOffset": 78, "endOffset": 612}, {"referenceID": 7, "context": "We will also explore other observation models, including replacing the auto-encoder objective with that of adversarial networks (Goodfellow et al., 2014; Makhzani et al., 2016; Chen et al., 2016), which may have stronger empirical performance.", "startOffset": 128, "endOffset": 195}, {"referenceID": 19, "context": "We will also explore other observation models, including replacing the auto-encoder objective with that of adversarial networks (Goodfellow et al., 2014; Makhzani et al., 2016; Chen et al., 2016), which may have stronger empirical performance.", "startOffset": 128, "endOffset": 195}, {"referenceID": 6, "context": "We will also explore other observation models, including replacing the auto-encoder objective with that of adversarial networks (Goodfellow et al., 2014; Makhzani et al., 2016; Chen et al., 2016), which may have stronger empirical performance.", "startOffset": 128, "endOffset": 195}], "year": 2017, "abstractText": "We present deep variational canonical correlation analysis (VCCA), a deep multi-view learning model that extends the latent variable model interpretation of linear CCA (Bach and Jordan, 2005) to nonlinear observation models parameterized by deep neural networks (DNNs). Marginal data likelihood as well as inference are intractable under this model. We derive a variational lower bound of the data likelihood by parameterizing the posterior density of the latent variables with another DNN, and approximate the lower bound via Monte Carlo sampling. Interestingly, the resulting model resembles that of multi-view autoencoders (Ngiam et al., 2011), with the key distinction of an additional sampling procedure at the bottleneck layer. We also propose a variant of VCCA called VCCA-private which can, in addition to the \u201ccommon variables\u201d underlying both views, extract the \u201cprivate variables\u201d within each view. We demonstrate that VCCA-private is able to disentangle the shared and private information for multi-view data without hard supervision.", "creator": "LaTeX with hyperref package"}}}