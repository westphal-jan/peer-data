{"id": "1610.03585", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Oct-2016", "title": "A Paradigm for Situated and Goal-Driven Language Learning", "abstract": "A distinguishing property of human intelligence is the ability to flexibly use language in order to communicate complex ideas with other humans in a variety of contexts. Research in natural language dialogue should focus on designing communicative agents which can integrate themselves into these contexts and productively collaborate with humans. In this abstract, we propose a general situated language learning paradigm which is designed to bring about robust language agents able to cooperate productively with humans.", "histories": [["v1", "Wed, 12 Oct 2016 02:45:45 GMT  (14kb,D)", "http://arxiv.org/abs/1610.03585v1", "5 pages, submitted to Machine Intelligence @ NIPS workshop"]], "COMMENTS": "5 pages, submitted to Machine Intelligence @ NIPS workshop", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["jon gauthier", "igor mordatch"], "accepted": false, "id": "1610.03585"}, "pdf": {"name": "1610.03585.pdf", "metadata": {"source": "CRF", "title": "A Paradigm for Situated and Goal-Driven Language Learning", "authors": ["Jon Gauthier", "Igor Mordatch"], "emails": ["jon@gauthiers.net", "mordatch@openai.com"], "sections": [{"heading": "A Paradigm for Situated and Goal-Driven Language Learning", "text": "Jon Gauthier1,2jon @ gauthiers.netIgor Mordatch1,3mordatch @ openai.com1OpenAI 2Stanford NLP Group 3UC BerkeleyA characteristic feature of human intelligence is the ability to use language flexibly to communicate complex ideas with other people in a variety of contexts. Research into dialogue with natural language should focus on designing communicative agents that can integrate into these contexts and work productively with people. In this summary, we propose a general situated paradigm of language learning designed to produce robust language agents capable of working productively with people. This dialogue paradigm is based on a utilitarian definition of language comprehension. Language is one of several tools that an agent can use to achieve goals in his or her environment. We say an agent \"understands\" language only when he or she is able to use language productively to achieve these goals."}, {"heading": "The environment", "text": "We propose an end-to-end learning environment with multilinguistic agents who are each able to define their own internal goals, and plan to achieve these goals. Each agent may also have different capacities to observe or act in that environment, and their goals are grounded, non-linguistic goals: for example, to reach a desired location, manipulate objects in the environment, or transfer a piece of information.2 (We will discuss the problem of non-linguistic grounding in detail in the next paragraph.) Some representatives of the fixed language in the environment speak an existing conventional language (e.g. English), and other learning agents are instructed to learn that language together while solving other goals in the environment. Agents are assigned difficult (possibly different) tasks, while our motivation here is similar to that of Dagan et al. (2006), which fragments the negative effects of a community that extends across different isolated application-specific tasks, and proposes the uniform task."}, {"heading": "Environment grounding", "text": "It is imperative that our language learning agents are grounded in a world that is not just linguistic; this grounding can be physical - agents embodied in the real world, for example - or virtual. It is this grounding that enables us to evaluate agents in a way that does not prioritize language as the only goal. Grounding imposes additional responsibilities on the agent, such as competent recognition and acting in the world, but this should be viewed as an opportunity rather than a problem. As we discuss in the following paragraphs, a grounded agent can use his experience in his environment to develop better language models and also use his language to better argue about his environment. This grounded environment is designed to produce agents with comprehensive predictive models of the world that combine linguistic knowledge with more general intelligent behavior."}, {"heading": "3 Much of the recent novel work in dialogue-based learning (Fleischman and Roy, 2005; Vogel et al., 2014;", "text": "Wang et al., 2016; Weston, 2016) and multi-agent communication (Lazaridou et al., 2016; Andreas and Klein,"}, {"heading": "2016; Foerster et al., 2016; Sukhbaatar et al., 2016) can be fit into the paradigm described so far. This paper is", "text": "Consider the following purely text-based interaction in the style of Mikolov et al. (2015) between a learning aid A and an omniscient remedy B that lies in a simulated physical world: B: Carrying a box of eggs and having to lay them down. A: Is there a table nearby? B: There is a table on the left. A: I put the box on the table. B: The box slips off the table and the eggs break open. [The table is missing a leg and tilted when the box is laid down.] The agent could have avoided this disaster if it had queried to find out that the table was missing a leg before it was placed on it."}, {"heading": "Conclusion", "text": "This paradigm centers on a utilitarian definition of language understanding, which equates language understanding with the ability to cooperate with other language users in real-world environments, a position that degrades language from its position as a separate task to be solved to one of several communicative tools that agents could use to achieve their goals in the real world. Although this paradigm already captures a small portion of recent work in dialogue, it has not received the overall focus it deserves in the research communities of natural language processing and machine learning."}, {"heading": "Acknowledgments", "text": "The authors would like to thank their colleagues from OpenAI and Stanford for their useful comments and criticisms."}], "references": [{"title": "Reasoning About Pragmatics with Neural Listeners and Speakers", "author": ["Jacob Andreas", "Dan Klein"], "venue": "[cs],", "citeRegEx": "Andreas and Klein.,? \\Q2016\\E", "shortCiteRegEx": "Andreas and Klein.", "year": 2016}, {"title": "Intelligence without representation", "author": ["Rodney Brooks"], "venue": "Artificial Intelligence,", "citeRegEx": "Brooks.,? \\Q1991\\E", "shortCiteRegEx": "Brooks.", "year": 1991}, {"title": "Whatever next? predictive brains, situated agents, and the future of cognitive science", "author": ["Andy Clark"], "venue": "Behavioral and Brain Sciences, 36(03):181\u2013204,", "citeRegEx": "Clark.,? \\Q2013\\E", "shortCiteRegEx": "Clark.", "year": 2013}, {"title": "The pascal recognising textual entailment challenge", "author": ["Ido Dagan", "Oren Glickman", "Bernardo Magnini"], "venue": "In Proceedings of the First International Conference on Machine Learning Challenges: Evaluating Predictive Uncertainty Visual Object Classification, and Recognizing Textual Entailment,", "citeRegEx": "Dagan et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Dagan et al\\.", "year": 2006}, {"title": "Proceedings of the Ninth Conference on Computational Natural Language Learning (CoNLL-2005), chapter Intentional Context in Situated Natural Language Learning, pages 104\u2013111", "author": ["Michael Fleischman", "Deb Roy"], "venue": "Association for Computational Linguistics,", "citeRegEx": "Fleischman and Roy.,? \\Q2005\\E", "shortCiteRegEx": "Fleischman and Roy.", "year": 2005}, {"title": "Learning to Communicate to Solve Riddles with Deep Distributed Recurrent Q-Networks", "author": ["Jakob N. Foerster", "Yannis M. Assael", "Nando de Freitas", "Shimon Whiteson"], "venue": "[cs],", "citeRegEx": "Foerster et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Foerster et al\\.", "year": 2016}, {"title": "Iterated learning and the evolution of language", "author": ["Simon Kirby", "Tom Griffiths", "Kenny Smith"], "venue": "Current Opinion in Neurobiology,", "citeRegEx": "Kirby et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kirby et al\\.", "year": 2014}, {"title": "Building machines that learn and think like people", "author": ["Brenden M. Lake", "Tomer D. Ullman", "Joshua B. Tenenbaum", "Samuel J. Gershman"], "venue": "CoRR, abs/1604.00289,", "citeRegEx": "Lake et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Lake et al\\.", "year": 2016}, {"title": "Towards Multi-Agent Communication-Based Language Learning", "author": ["Angeliki Lazaridou", "Nghia The Pham", "Marco Baroni"], "venue": "[cs],", "citeRegEx": "Lazaridou et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Lazaridou et al\\.", "year": 2016}, {"title": "A Roadmap towards Machine Intelligence", "author": ["Tomas Mikolov", "Armand Joulin", "Marco Baroni"], "venue": "[cs],", "citeRegEx": "Mikolov et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2015}, {"title": "Iterated learning: A framework for the emergence of language", "author": ["Kenneth Smith", "Simon Kirby", "Henry Brighton"], "venue": "Artificial Life, 9(4):371\u2013386,", "citeRegEx": "Smith et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Smith et al\\.", "year": 2003}, {"title": "Grounding language through evolutionary language games. In Language Grounding in Robots, pages 1\u201322", "author": ["Luc Steels"], "venue": "URL http://link.springer.com/ chapter/10.1007/978-1-4614-3064-3_1", "citeRegEx": "Steels.,? \\Q2012\\E", "shortCiteRegEx": "Steels.", "year": 2012}, {"title": "Learning Multiagent Communication with Backpropagation", "author": ["Sainbayar Sukhbaatar", "Arthur Szlam", "Rob Fergus"], "venue": "[cs],", "citeRegEx": "Sukhbaatar et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Sukhbaatar et al\\.", "year": 2016}, {"title": "Learning to reason pragmatically with cognitive limitations", "author": ["Adam Vogel", "Andr\u00e9s G\u00f3mez Emilsson", "Michael C. Frank", "Dan Jurafsky", "Christopher Potts"], "venue": "In Proceedings of the 36th Annual Meeting of the Cognitive Science Society,", "citeRegEx": "Vogel et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Vogel et al\\.", "year": 2014}, {"title": "Learning language games through interaction. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2368\u20132378, Berlin, Germany, August 2016", "author": ["Sida I. Wang", "Percy Liang", "Christopher D. Manning"], "venue": "Association for Computational Linguistics. URL http://www.aclweb. org/anthology/P16-1224", "citeRegEx": "Wang et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2016}, {"title": "Dialog-based language learning", "author": ["Jason Weston"], "venue": "arXiv preprint arXiv:1604.06045,", "citeRegEx": "Weston.,? \\Q2016\\E", "shortCiteRegEx": "Weston.", "year": 2016}], "referenceMentions": [{"referenceID": 10, "context": "A related line of work in evolutionary linguistics constructs a similar language learning scenario entirely without fixed-language agents (Smith et al., 2003; Steels, 2012; Kirby et al., 2014).", "startOffset": 138, "endOffset": 192}, {"referenceID": 11, "context": "A related line of work in evolutionary linguistics constructs a similar language learning scenario entirely without fixed-language agents (Smith et al., 2003; Steels, 2012; Kirby et al., 2014).", "startOffset": 138, "endOffset": 192}, {"referenceID": 6, "context": "A related line of work in evolutionary linguistics constructs a similar language learning scenario entirely without fixed-language agents (Smith et al., 2003; Steels, 2012; Kirby et al., 2014).", "startOffset": 138, "endOffset": 192}, {"referenceID": 3, "context": "Our motivation here is similar to that of Dagan et al. (2006), who recognized the negative effects of a community fragmented across different isolated application-specific tasks, and suggested the unified task of recognizing textual entailment (RTE) as a solution.", "startOffset": 42, "endOffset": 62}, {"referenceID": 7, "context": "By design, we do not separate the activity of language model construction from many other intelligent predictive activities \u2014 whether physical (predicting physical behavior of objects), psychological (modeling the beliefs and intentions of other agents), or social (understanding group membership and group-level action) (Lake et al., 2016; Clark, 2013).", "startOffset": 321, "endOffset": 353}, {"referenceID": 2, "context": "By design, we do not separate the activity of language model construction from many other intelligent predictive activities \u2014 whether physical (predicting physical behavior of objects), psychological (modeling the beliefs and intentions of other agents), or social (understanding group membership and group-level action) (Lake et al., 2016; Clark, 2013).", "startOffset": 321, "endOffset": 353}, {"referenceID": 1, "context": ", 2016; Clark, 2013). While early instantiations of this environment will limit the complexity necessary for the agents to model, we expect all of these different factors to eventually be relevant in a comprehensive learning environment. Mikolov et al. (2015) make a similar argument for grounding, but arrive at an environment in which perception and action is mediated only through a linguistic channel.", "startOffset": 8, "endOffset": 260}, {"referenceID": 4, "context": "3 Much of the recent novel work in dialogue-based learning (Fleischman and Roy, 2005; Vogel et al., 2014; Wang et al., 2016; Weston, 2016) and multi-agent communication (Lazaridou et al.", "startOffset": 59, "endOffset": 138}, {"referenceID": 13, "context": "3 Much of the recent novel work in dialogue-based learning (Fleischman and Roy, 2005; Vogel et al., 2014; Wang et al., 2016; Weston, 2016) and multi-agent communication (Lazaridou et al.", "startOffset": 59, "endOffset": 138}, {"referenceID": 14, "context": "3 Much of the recent novel work in dialogue-based learning (Fleischman and Roy, 2005; Vogel et al., 2014; Wang et al., 2016; Weston, 2016) and multi-agent communication (Lazaridou et al.", "startOffset": 59, "endOffset": 138}, {"referenceID": 15, "context": "3 Much of the recent novel work in dialogue-based learning (Fleischman and Roy, 2005; Vogel et al., 2014; Wang et al., 2016; Weston, 2016) and multi-agent communication (Lazaridou et al.", "startOffset": 59, "endOffset": 138}, {"referenceID": 8, "context": ", 2016; Weston, 2016) and multi-agent communication (Lazaridou et al., 2016; Andreas and Klein, 2016; Foerster et al., 2016; Sukhbaatar et al., 2016) can be fit into the paradigm described so far.", "startOffset": 52, "endOffset": 149}, {"referenceID": 0, "context": ", 2016; Weston, 2016) and multi-agent communication (Lazaridou et al., 2016; Andreas and Klein, 2016; Foerster et al., 2016; Sukhbaatar et al., 2016) can be fit into the paradigm described so far.", "startOffset": 52, "endOffset": 149}, {"referenceID": 5, "context": ", 2016; Weston, 2016) and multi-agent communication (Lazaridou et al., 2016; Andreas and Klein, 2016; Foerster et al., 2016; Sukhbaatar et al., 2016) can be fit into the paradigm described so far.", "startOffset": 52, "endOffset": 149}, {"referenceID": 12, "context": ", 2016; Weston, 2016) and multi-agent communication (Lazaridou et al., 2016; Andreas and Klein, 2016; Foerster et al., 2016; Sukhbaatar et al., 2016) can be fit into the paradigm described so far.", "startOffset": 52, "endOffset": 149}, {"referenceID": 9, "context": "Consider the following text-only interaction in the style of Mikolov et al. (2015) between a learning agent A and omniscient agent B, situated in some simulated physical world:", "startOffset": 61, "endOffset": 83}], "year": 2016, "abstractText": "A distinguishing property of human intelligence is the ability to flexibly use language in order to communicate complex ideas with other humans in a variety of contexts. Research in natural language dialogue should focus on designing communicative agents which can integrate themselves into these contexts and productively collaborate with humans. In this abstract, we propose a general situated language learning paradigm which is designed to bring about robust language agents able to cooperate productively with humans. This dialogue paradigm is built on a utilitarian definition of language understanding. Language is one of multiple tools which an agent may use to accomplish goals in its environment. We say an agent \u201cunderstands\u201d language only when it is able to use language productively to accomplish these goals. Under this definition, an agent\u2019s communication success reduces to its success on tasks within its environment. This setup contrasts with many conventional natural language tasks, which maximize linguistic objectives derived from static datasets. Such applications often make the mistake of reifying language as an end in itself. The tasks prioritize an isolated measure of linguistic intelligence (often one of linguistic competence, in the sense of Chomsky (1965)), rather than measuring a model\u2019s effectiveness in real-world scenarios. Our utilitarian definition is motivated by recent successes in reinforcement learning methods. In a reinforcement learning setting, agents maximize success metrics on real-world tasks, without requiring direct supervision of linguistic behavior.", "creator": "LaTeX with hyperref package"}}}