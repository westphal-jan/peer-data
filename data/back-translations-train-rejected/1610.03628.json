{"id": "1610.03628", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Oct-2016", "title": "RetiNet: Automatic AMD identification in OCT volumetric data", "abstract": "Optical Coherence Tomography (OCT) provides a unique ability to image the eye retina in 3D at micrometer resolution and gives ophthalmologist the ability to visualize retinal diseases such as Age-Related Macular Degeneration (AMD). While visual inspection of OCT volumes remains the main method for AMD identification, doing so is time consuming as each cross-section within the volume must be inspected individually by the clinician. In much the same way, acquiring ground truth information for each cross-section is expensive and time consuming. This fact heavily limits the ability to acquire large amounts of ground truth, which subsequently impacts the performance of learning-based methods geared at automatic pathology identification. To avoid this burden, we propose a novel strategy for automatic analysis of OCT volumes where only volume labels are needed. That is, we train a classifier in a semi-supervised manner to conduct this task. Our approach uses a novel Convolutional Neural Network (CNN) architecture, that only needs volume-level labels to be trained to automatically asses whether an OCT volume is healthy or contains AMD. Our architecture involves first learning a cross-section pathology classifier using pseudo-labels that could be corrupted and then leverage these towards a more accurate volume-level classification. We then show that our approach provides excellent performances on a publicly available dataset and outperforms a number of existing automatic techniques.", "histories": [["v1", "Wed, 12 Oct 2016 07:56:24 GMT  (6351kb,D)", "http://arxiv.org/abs/1610.03628v1", "14 pages, 10 figures, Code available"]], "COMMENTS": "14 pages, 10 figures, Code available", "reviews": [], "SUBJECTS": "cs.CV cs.LG cs.NE", "authors": ["stefanos apostolopoulos", "carlos ciller", "sandro i de zanet", "sebastian wolf", "raphael sznitman"], "accepted": false, "id": "1610.03628"}, "pdf": {"name": "1610.03628.pdf", "metadata": {"source": "CRF", "title": "RetiNet: Automatic AMD identification in OCT volumetric data", "authors": ["S. Apostolopoulos"], "emails": ["firstname.lastname@artorg.unibe.ch"], "sections": [{"heading": null, "text": "Keywords - Optical Coherence Tomography (OCT), Convolutional Neural Networks (CNN), AgeRelated Macular Degeneration (AMD), Pathology, Ophthalmology, Machine Learning"}, {"heading": "1 Introduction", "text": "At its core is the use of infrared interferometry on the image through tissues to characterize anatomical structures beyond their surface. Given their simplicity, affordability and safety, it is no surprise that their use is widespread for both diagnosis and treatment of diseases. Similarly, their use has become more important in other medical fields such as histopathology and skin cancer analysis [2].In fact, with the ability to depict the posterior part of the eye in 3D (e.g. the retina), OCT imaging is now available for the visualization of most retinal layers [3, 4] and more significant, numerous pathological markers, such as intraretinal fluid, drusen or cysts [5, 6]."}, {"heading": "2 Related Work", "text": "In fact, it is such that most of them are able to survive themselves without there being a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is"}, {"heading": "3 Our Approach", "text": "The overarching goal of this work is to automatically assess whether an OCT volume contains AMD. The biggest challenges in addressing this problem are the fact that (1) relatively few volumes are typically available for training classification models, even though the volumes are large (e.g. 500 x 1000 x 100 pixels) and (2) that labels that indicate the presence of pathologies are available only at the volume level and not at the cross-sectional level. In order to perform an effective volume classification, we will take a Deep CNN approach and describe our novel architecture in the following section. Generally, our approach is based on a three-step process. The first is an OCT-specific normalization and data augmentation strategy for OCT volumes to improve overall generalization and classification performance. Here, we reduce the image dimension and smooth OCT scans to regulate the data. Similarly, we use symmetry to effectively expand the data."}, {"heading": "3.1 Notation and formulation", "text": "Without loss of universality, we assume that our training data V = {V1,..., VN} consist of N OCT volumes. Each volume Vn has the dimension {W \u00b7 H \u00b7 D} = V, where a B-scan cross-section consists of a W \u00b7 D image, where D is the depth of the penetrating OCT light source. For a volume Vn, we refer to Bhn, h = 1,..., H, as the h-th B-scan in the volume. Each volume in Vn is associated with a class name Yn, {0, 1} = Y in such a way that 0 corresponds to the control volumes and 1 pathological volumes (i.e. AMD). Our goal is to learn a classification function f: V \u2192 Y based on the available training set and the labels. It is important that we assume that there is no information on the labels of Bhn, as these are expensive to collect."}, {"heading": "3.2 Data preprocessing", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.2.1 Normalization", "text": "As can be seen in Figure 2 (top row), there is both high variability in the positions of Bhn in terms of anatomy as well as distortion of the retina layers. In particular, the retina layers may be inclined, shifted vertically, distorted due to the acquisition process and varying intensity. In addition, significant portions of the Bhn images contain little informative content, such as the area above the ILM and the BM layer underneath. This is due to the OCT imaging device and consists of either noise or regions that are too deep for the OCT laser to penetrate. As such, significant portions of the Bhn images contain little informative content, such as the area above the ILM contains more compact and consistent sets of images, which we are interested in normalizing and reducing the size of the OCT volume. Unfortunately, we can simply cut off any B-scan, as the retina would be poorly suited, as this is the most informative and resistive of the retines and would remove the result."}, {"heading": "3.2.2 Data augmentation", "text": "In particular, we use the bilateral symmetry of the eye to effectively double the number of samples. The resulting samples are biologically plausible, i.e. the papilla, fovea and vessels remain in the right places relative to each other and eliminate latent sample distortions due to different counts of the left and right eye in the dataset."}, {"heading": "3.3 B-scan classification with weak labels: RetiNet B", "text": "Remember that our data is volumetric by nature, and that the amount of data available is relatively small. In this challenging learning context, we will first learn features that are efficient for recognizing typical 2D OCT structures by learning to \"classify\" B-scans. While our labels are only at volume level, we suggest learning a B-scan classifier by using approximately correct or \"weak\" labels to do so. Specifically, we will let Y-scans be considered weak labels for B-scans. Note that the Y-labels indicate the absence of an AMD diagnosis. Individual B-scan sections should be free. Conversely, the volumes of subjects diagnosed with AMD will contain a number of control or non-pathological B-scans."}, {"heading": "3.4 Volume classification: RetiNet C", "text": "As we will show later in our experiments, the performance of the aforementioned network is limited because it has to learn from weak labels and does not use volumetric information to make a final decision. Furthermore, it is not possible to test whether the classification is actually correct, since the true label per B-scan is not known. Therefore, we move on to a second stage in which we attempt to classify the complete C-scan in one setting. Our proposed network is in Fig. 3. Instead of specifying each Bhn as the input channel, our network takes as input a vertical image of stacked B-scan, Mn, where Mn = B1n... Bhn, resulting in an image in size {w \u00d7 Dh}. Based on the learned FEATURE layers from the previous section, we include them in our new network, as they are invariant to the size of the input, and ideally they have recognized the anatomical and pathological structures as relevant."}, {"heading": "4 Evaluation", "text": "We compare our approach with a range of existing, state-of-the-art baselines drawn from both the literature on AMD disease identification and the more general computer vision literature. We also provide qualitative results of our methodology that illustrate the different activation maps of our network and show how the different stages of our approach benefit overall performance."}, {"heading": "4.1 Data set", "text": "Our method has been trained and evaluated using Duke University's publicly available dataset [5], which has been provided to provide methods for defining quantitative indicators of the presence of moderate AMD. This dataset contains 384 spectral domain OCT volumes, of which 269 volumes are from subjects with moderate AMD, while the remaining 115 volumes were collected from healthy subjects. All scans are centered on the foveal pit. Each volume is imaged with 1000 A-scans per B-scan and 100 B-scans per band, resulting in volume dimensions of 100 x 1000 x 500 px3. Generally, the volumes are not isotropic."}, {"heading": "4.2 Baselines", "text": "To illustrate how each part of the strategy affects overall performance, and to compare how our approach evolves against other existing techniques in the literature, we now outline a number of baselines to which we directly compare: - VGG19: is the 19-layer variant of the in-depth approach to image classification set forth in [44]. We prepared this network based on a fully networked dataset and refined the resulting filters with the OCT dataset, modifying the receptive field of the network to achieve our B-scan resolution of 384x298 and replacing the classification layer with a fully networked layer."}, {"heading": "4.3 Experimental setup", "text": "We divided the data set into five randomized, equally sized subsets, using four for training and one for testing, for a total of five cross-validations per network. All methods were trained on the same partitions with the same folds. Random seed was maintained throughout all runs to all dataset-dependent bias.0.00.00 0.10 0.15 0.20 0.250.75Weak BSL2D (AUC = 0.978) 0.00 0.02 0.04 0.08 0,100.00.00 0.10 0.15 0.250.75Weak BSL2D (AUC = 0.978) We trained each network for a maximum of 100 epochs per fold, using early stops with a patience of 15 epochs to avoid overmatches [47, 48]. We relied on the adadelta algorithm [49] to optimize the parameters of each network."}, {"heading": "4.4 RetiNet characterization", "text": "Do you see what the future of humanity is like? \"he asked in an interview with\" Welt am Sonntag. \""}, {"heading": "4.5 Baseline comparison", "text": "Fig. 6 outlines the performance of RetiNet C and the baseline methods in terms of ROC, as well as FNR / FPR. Across both metrics, RetiNet C appears to be these baselinees.A number of interesting conclusions can additionally be drawn from these results.First, DenseNet is very similar to both VGG19 and ResNet, although it is trained from the ground up and converges very fast. Both VGG19 and ResNet could not be trained from the ground up.0 10 30 50 60 70Epochs10 \u2212 410 \u2212 1100Lo \u2212 1100Lo resNet retiNet VGG19 vienna150 20 40 70 70Epochs10 \u2212 410 \u2212 1epochs10 \u2212 410% -1109% -1209% -9159"}, {"heading": "5 Conclusions", "text": "In this article, we have proposed a new strategy for automatically identifying AMD in OCT volumes. Our strategy is advantageous because it requires only volume-level labels as opposed to cross-sectional labels, which makes it much easier to train from a more fundamental acquisition point.Our approach includes a novel two-step deep learning architecture that focuses on domain-specific learning characteristics in the first phase and then focuses on the task of volume classification in the second phase.We validated our approach using publicly available OCT data and compared the performance of our method with both OCT techniques and computer vision literature. We showed that our approach not only performs well in ROC performance, but also performs well in terms of a more clinically relevant metric. However, our method still has difficulty identifying mild AMD cases, as shown in Figure 8 (e), where we will be able to distinguish between the evolution of the disease and the disease where it is visible in this sense and in others."}], "references": [{"title": "Optical coherence tomography in dermatology : a review", "author": ["J. Welzel"], "venue": "Skin Res Technol., vol. 7, no. 1, pp. 1\u20139, 2001.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2001}, {"title": "Retinal Imaging and Image Analysis", "author": ["M.D. Abramoff", "M.K. Garvin", "M. Sonka"], "venue": "IEEE Transactions on Medical Imaging, vol. 3, no. 1, pp. 169\u2013208, 2010.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2010}, {"title": "Quantitative classification of eyes with and without intermediate age-related macular degeneration using optical coherence tomography", "author": ["S. Farsiu", "S.J. Chiu", "R.V. O\u2019Connell", "F.A. Folgar", "E. Yuan", "J.A. Izatt", "C.A. Toth"], "venue": "Ophthalmology, vol. 121, no. 1, pp. 162\u2013172, 2014.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2014}, {"title": "Age-Related Macular Degeneration", "author": ["R.D. Jager", "W.F. Mieler", "J.W. Miller"], "venue": "The New England Journal of Medicine, vol. 358, no. 24, pp. 2606\u20132617, 2008.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2008}, {"title": "Global prevalence and major risk factors of diabetic retinopathy", "author": ["J.W.Y. Yau", "S.L. Rogers", "R. Kawasaki", "E.L. Lamoureux", "J.W. Kowalski", "T. Bek", "S.-J. Chen", "J.M. Dekker", "A. Fletcher", "J. Grauslund", "S. Haffner", "R.F. Hamman", "M.K. Ikram", "T. Kayama", "B.E.K. Klein", "R. Klein", "S. Krishnaiah", "K. Mayurasakorn", "J.P. O\u2019Hare", "T.J. Orchard", "M. Porta", "M. Rema", "M.S. Roy", "T. Sharma", "J. Shaw", "H. Taylor", "J.M. Tielsch", "R. Varma", "J.J. Wang", "N. Wang", "S. West", "L. Xu", "M. Yasuda", "X. Zhang", "P. Mitchell", "T.Y. Wong"], "venue": "Diabetes Care, vol. 35, no. 3, pp. 556\u2013 564, 2012.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2012}, {"title": "Global prevalence of age-related macular degeneration and disease burden projection for 2020 and 2040: A systematic review and meta-analysis", "author": ["W.L. Wong", "X. Su", "X. Li", "C.M.G. Cheung", "R. Klein", "C.Y. Cheng", "T.Y. Wong"], "venue": "The Lancet Global Health, vol. 2, no. 2, pp. e106\u2013e116, 2014.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "Age-related macular degeneration is the leading cause of blindness", "author": ["N. Bressler"], "venue": "JAMA, vol. 291, no. 15, pp. 1900\u20131901, 2004.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1900}, {"title": "Early detection and treatment of neovascular age-related macular degeneration.", "author": ["N.M. Bressler"], "venue": "The Journal of the American Board of Family Practice / American Board of Family Practice,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2002}, {"title": "Diabetic retinopathy and diabetic macular edema: Pathophysiology, screening, and novel therapies", "author": ["T.A. Ciulla", "A.G. Amador", "B. Zinman"], "venue": "Diabetes Care, vol. 26, no. 9, pp. 2653\u2013 2664, 2003.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2003}, {"title": "Guidelines for the management of neovascular age-related macular degeneration by the European Society of Retina Specialists (EURETINA)", "author": ["U. Schmidt-Erfurth", "V. Chong", "A. Loewenstein", "M. Larsen", "E. Souied", "R. Schlingemann", "B. Eldem", "J. Mones", "G. Richard", "F. Bandello", "S. European Society of Retina"], "venue": "Br J Ophthalmol, vol. 98, no. 9, pp. 1144\u20131167, 2014.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2014}, {"title": "Speckle reduction in optical coherence tomography images by use of a spatially adaptive wavelet filter", "author": ["D.C. Adler", "T.H. Ko", "J.G. Fujimoto"], "venue": "Opt. Lett., vol. 29, no. 24, pp. 2878\u20132880, Dec 2004.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2004}, {"title": "Image denoising with block-matching and 3D filtering", "author": ["K. Dabov", "A. Foi"], "venue": "Electronic Imaging, vol. 6064, pp. 1\u201312, 2006.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2006}, {"title": "Nonlocal Transform- Domain Filter for Volumetric Data Denoising and Reconstruction", "author": ["M. Maggioni", "V. Katkovnik", "K. Egiazarian", "S. Member", "A. Foi"], "venue": "IEEE Transactions on Image Processing, vol. 22, no. 1, pp. 119\u2013133, 2013.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2013}, {"title": "Ultrahigh-resolution, high-speed, Fourier domain optical coherence tomography and methods for dispersion compensation", "author": ["M. Wojtkowski", "V.J. Srinivasan", "T.H. Ko", "J.G. Fujimoto", "A. Kowalczyk", "J.S. Duker", "D.J. Fujimoto JG", "Kowalczyk A"], "venue": "Optics Express, vol. 12, no. 11, p. 2404, 2004.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2004}, {"title": "Correction of motion artifacts and scanning beam distortions in 3D ophthalmic optical coherence tomography imaging", "author": ["R.J. Zawadzki", "A.R. Fuller", "S.S. Choi", "D.F. Wiley", "B. Hamann", "J.S. Werner"], "venue": "Ophthalmic Technologies XVII, vol. 6426, no. x, p. 42607, 2007.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2007}, {"title": "Motion correction in optical coherence tomography volumes on a per A-scan basis using orthogonal scan patterns.", "author": ["M.F. Kraus", "B. Potsaid", "M.A. Mayer", "R. Bock", "B. Baumann", "J.J. Liu", "J. Hornegger", "J.G. Fujimoto"], "venue": "Biomedical optics express,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2012}, {"title": "Averaging techniques for OCT imaging", "author": ["M. Szkulmowski", "M. Wojtkowski"], "venue": "Opt Express, vol. 21, no. 8, pp. 9757\u20139773, 2013.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2013}, {"title": "Motion artefact correction in retinal optical coherence tomography using local symmetry", "author": ["A. Montuoro", "J. Wu", "S. Waldstein", "B. Gerendas", "G. Langs", "C. Simader", "U. Schmidt-Erfurth"], "venue": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), 2014.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2014}, {"title": "Automatic estimation of noise parameters in Fourier-domain optical coherence tomography cross sectional images using statistical information", "author": ["P. Steiner", "J.H. Kowal", "B. Pova\u017eay", "C. Meier", "R. Sznitman"], "venue": "Applied Optics, vol. 54, no. 12, pp. 3650\u20133657, 2015.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2015}, {"title": "Imaging thermal expansion and retinal tissue changes during photocoagulation by high speed OCT", "author": ["H.H. M\u00fcller", "L. Ptaszynski", "K. Schlott", "C. Debbeler", "M. Bever", "S. Koinzer", "R. Birngruber", "R. Brinkmann", "G. H\u00fcttmann"], "venue": "Biomedical Optics Express, vol. 3, no. 5, p. 1025, 2012.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2012}, {"title": "Time-Resolved Ultra-High Resolution Optical Coherence Tomography for Real-Time Monitoring of Selective Retina Therapy", "author": ["P. Steiner", "A. Ebneter", "L.E. Berger", "M. Zinkernagel", "C. Meier", "J.H. Kowal", "C. Framme", "R. Brinkmann", "S. Wolf", "R. Sznitman"], "venue": "Investigative Ophthalmology and Visual Science, vol. 56, pp. 6654\u20136662, 2015.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2015}, {"title": "Automatic assessment of time-resolved oct images for selective retina therapy", "author": ["S. Zbinden", "\u015e.S. Kucur", "P. Steiner", "S. Wolf", "R. Sznitman"], "venue": "International Journal of Computer Assisted Radiology and Surgery, vol. 11, no. 6, pp. 863\u2013871, 2016. [Online]. Available: http://dx.doi.org/10.1007/s11548-016-1383-6", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2016}, {"title": "Microscope-integrated intraoperative OCT with electrically tunable focus and heads-up display for imaging of ophthalmic surgical maneuvers", "author": ["Y.K. Tao", "S.K. Srivastava", "J.P. Ehlers", "C. Clinic"], "venue": "Biomed Opt Express., vol. 5, no. 6, pp. 1342\u20131350, 2014.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2014}, {"title": "Automated stereo vision instrument tracking for intraoperative OCT guided anterior segment ophthalmic surgical maneuvers.", "author": ["M.T. El-Haddad", "Y.K. Tao"], "venue": "Biomedical optics express,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2015}, {"title": "Threedimensional analysis of retinal layer texture: Identification of fluid-filled regions in SD-OCT of the macula", "author": ["G. Quellec", "K. Lee", "M. Dolejsi", "M.K. Garvin", "M.D. Abr\u00e0moff", "M. Sonka"], "venue": "IEEE Transactions on Medical Imaging, vol. 29, no. 6, pp. 1321\u20131330, 2010.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2010}, {"title": "Validated automatic segmentation of AMD pathology including drusen and geographic atrophy in SD- OCT images", "author": ["S.J. Chiu", "J.A. Izatt", "R.V. O\u2019Connell", "K.P. Winter", "C.A. Toth", "S. Farsiu"], "venue": "Investigative Ophthalmology and Visual Science, vol. 53, no. 1, pp. 53\u201361, 2012.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2012}, {"title": "Graph-based multi-surface segmentation of OCT data using trained hard and soft constraints", "author": ["P.A. Dufour", "L. Ceklic", "H. Abdillahi", "S. Schroder", "S. De Zanet", "U. Wolf-Schnurrbusch", "J. Kowal"], "venue": "IEEE Transactions on Medical Imaging, vol. 32, no. 3, pp. 531\u2013543, 2013.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2013}, {"title": "Vendor Independent Cyst Segmentation in Retinal SD-OCT Volumes using a Combination of Multiple Scale Convolutional Neural Networks", "author": ["F.G. Venhuizen", "M.J.J.P.V. Grinsven", "C.B. Hoyng"], "venue": "Medical Image Computing and Computer Assisted Intervention - Challenge on Retinal Cyst Segmentation, 2015.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2015}, {"title": "Predicting Semantic Descriptions from Medical Images with Convolutional Neural Networks", "author": ["T. Schlegl", "S.M. Waldstein", "U.M. Schmidt-erfurth"], "venue": "Information Processing in Medical Imaging, 2015, pp. 437\u2013448.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2015}, {"title": "Automated macular pathology diagnosis in retinal OCT images using multi-scale spatial pyramid with local binary patterns", "author": ["Y.-Y. Liu", "M. Chen", "H. Ishikawa", "G. Wollstein", "J.S. Schuman", "J.M. Rehg"], "venue": "Medical Image Computing and Computer-Assisted Intervention\u2013 MICCAI 2010. Springer, 2010, pp. 1\u20139.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2010}, {"title": "Automated age-related macular degeneration classification in oct using unsupervised feature learning", "author": ["F.G. Venhuizen", "B. van Ginneken", "B. Bloemen", "M.J.J.P. van Grinsven", "R. Philipsen", "C. Hoyng", "T. Theelen", "C.I. Snchez"], "venue": "Proc. SPIE, vol. 9414, 2015, pp. 94 141I\u201394 141I\u20137.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2015}, {"title": "Classification of SD-OCT Volumes using Local Binary Patterns: Experimental Validation for DME Detection", "author": ["G. Lemaitre", "M. Rastgoo", "J. Massich", "C.Y. Cheung", "Y. Wong", "E. Lamoureux", "D. Milea", "M. Fabrice", "G. Lemaitre", "M. Rastgoo", "J. Massich", "C.Y. Cheung", "T.Y. Wong", "G. Lema"], "venue": "Journal of Ophthalmology, vol. 6, 2016.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2016}, {"title": "A non-local algorithm for image denoising", "author": ["A. Buades", "B. Coll", "J.-M.J.-M. Morel"], "venue": "Computer Vision and Pattern Recognition, 2005. CVPR 2005. IEEE Computer Society Conference on, vol. 2, no. 0, pp. 60\u201365 vol. 2, 2005.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2005}, {"title": "Scale-space and edge detection using anisotropic diffusion", "author": ["P. Perona", "J. Malik"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 12, no. 7, pp. 629\u2013639, 1990.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 1990}, {"title": "Random Sample Consensus: A Paradigm for Model Fitting with Applicatlons to Image Analysis and Automated Cartography", "author": ["M.A. Fischler", "R.C. Bolles"], "venue": "Communications of the ACM, vol. 24, no. 6, pp. 381 \u2013 395, 1981. [Online]. Available: http://dx.doi.org/10.1145/358669.358692", "citeRegEx": "39", "shortCiteRegEx": null, "year": 1981}, {"title": "Best practices for convolutional neural networks applied to visual document analysis", "author": ["P.Y. Simard", "D. Steinkraus", "J.C. Platt"], "venue": "Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings., vol. 1, no. Icdar, pp. 958\u2013963, 2003. [Online]. Available: http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1227801", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2003}, {"title": "ImageNet Classification with Deep Convolutional Neural Networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "Advances In Neural Information Processing Systems, pp. 1\u20139, 2012.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2012}, {"title": "Understanding the difficulty of training deep feedforward neural networks", "author": ["X. Glorot", "Y. Bengio"], "venue": "Proceedings of the 13th International Conference on Artificial Intelligence and Statistics (AISTATS), vol. 9, pp. 249\u2013256, 2010.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2010}, {"title": "Extreme learning machine: Theory and applications", "author": ["G.-B. Huang", "Q.-y. Zhu", "C.-k. Siew", "G.-b. H. \u00c3", "Q.-y. Zhu", "C.-k. Siew", "G.-B. Huang", "Q.-y. Zhu", "C.-k. Siew"], "venue": "Neurocomputing, vol. 70, no. 1-3, pp. 489\u2013501, 2006. 13  (a) True positive  (b) True positive (c) True negative  (d) True negative (e) False positive  (f) False negative Figure 8: Example B-scans from correctly and incorrectly classified volumes. While (a-d) show correctly identified cases, (e-f) are incorrectly classified. Surprisingly, our approach correctly identifies (d) as non-AMD, even though it illustrates an epiretinal membrane and vitreoretinal traction, neither of which is AMD.", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2006}, {"title": "Very Deep Convolutional Networks for Large-Scale Image Recognition", "author": ["K. Simonyan", "A. Zisserman"], "venue": "ArXiv preprint arXiv:1409.1556, pp. 1\u201314, 2015.", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep Residual Learning for Image Recognition", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "Arxiv.Org, vol. 7, no. 3, pp. 171\u2013180, 2015.", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2015}, {"title": "Densely Connected Convolutional Networks", "author": ["G. Huang", "Z. Liu", "K.Q. Weinberger"], "venue": "ArXiv preprint, pp. 1\u201312, 2016.", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2016}, {"title": "Automatic early stopping using cross validation: Quantifying the criteria", "author": ["L. Prechelt"], "venue": "Neural Networks, vol. 11, no. 4, pp. 761\u2013767, 1998.", "citeRegEx": "47", "shortCiteRegEx": null, "year": 1998}, {"title": "Exploring Strategies for Training Deep Neural Networks", "author": ["H. Larochelle", "Y. Bengio", "J. Louradour", "P. Lamblin"], "venue": "Journal of Machine Learning Research, vol. 1, pp. 1\u201340, 2009.", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2009}, {"title": "ADADELTA: An Adaptive Learning Rate Method", "author": ["M.D. Zeiler"], "venue": "arXiv, p. 6, 2012. [Online]. Available: http://arxiv.org/abs/1212.5701 14", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2012}], "referenceMentions": [{"referenceID": 0, "context": "Similarly, its use has gained traction in other medical fields such as for histopathology and skin cancer analysis [2].", "startOffset": 115, "endOffset": 118}, {"referenceID": 1, "context": "the retina) at micrometer resolution, OCT imaging now allows for visualization of most retinal layers [3, 4] and more importantly, numerous pathological markers, such as intraretinal fluid, drusens or cysts [5, 6].", "startOffset": 102, "endOffset": 108}, {"referenceID": 2, "context": "the retina) at micrometer resolution, OCT imaging now allows for visualization of most retinal layers [3, 4] and more importantly, numerous pathological markers, such as intraretinal fluid, drusens or cysts [5, 6].", "startOffset": 207, "endOffset": 213}, {"referenceID": 3, "context": "the retina) at micrometer resolution, OCT imaging now allows for visualization of most retinal layers [3, 4] and more importantly, numerous pathological markers, such as intraretinal fluid, drusens or cysts [5, 6].", "startOffset": 207, "endOffset": 213}, {"referenceID": 2, "context": "7% of the world population and 159 million people worldwide, respectively [5, 7, 8].", "startOffset": 74, "endOffset": 83}, {"referenceID": 4, "context": "7% of the world population and 159 million people worldwide, respectively [5, 7, 8].", "startOffset": 74, "endOffset": 83}, {"referenceID": 5, "context": "7% of the world population and 159 million people worldwide, respectively [5, 7, 8].", "startOffset": 74, "endOffset": 83}, {"referenceID": 6, "context": "Moreover, these pathologies are the major cause of blindness in developed countries [9].", "startOffset": 84, "endOffset": 87}, {"referenceID": 5, "context": "Alarmingly, the number of people with either of these diseases is projected to skyrocket, with AMD affecting an estimated 196 million people by 2020 and 288 million people by 2040 [8].", "startOffset": 180, "endOffset": 183}, {"referenceID": 7, "context": "While OCT has gained significant importance in recent years for AMD and DR screening [11, 12], the process to do so remains time consuming however.", "startOffset": 85, "endOffset": 93}, {"referenceID": 8, "context": "While OCT has gained significant importance in recent years for AMD and DR screening [11, 12], the process to do so remains time consuming however.", "startOffset": 85, "endOffset": 93}, {"referenceID": 9, "context": "In this context, automated algorithms for pathology identification in OCT volumes would be of great benefit for clinicians and ophthalmologists, as access to OCT devices becomes common and nation-wide screening programs commence [13].", "startOffset": 229, "endOffset": 233}, {"referenceID": 10, "context": "Some of these have included: techniques for image denoising [14, 15, 16], strategies for improved image reconstruction [17, 18, 19, 20, 21, 22], dosimetry laser control systems [23, 24, 25] or instrument detection during surgical procedures [26, 27].", "startOffset": 60, "endOffset": 72}, {"referenceID": 11, "context": "Some of these have included: techniques for image denoising [14, 15, 16], strategies for improved image reconstruction [17, 18, 19, 20, 21, 22], dosimetry laser control systems [23, 24, 25] or instrument detection during surgical procedures [26, 27].", "startOffset": 60, "endOffset": 72}, {"referenceID": 12, "context": "Some of these have included: techniques for image denoising [14, 15, 16], strategies for improved image reconstruction [17, 18, 19, 20, 21, 22], dosimetry laser control systems [23, 24, 25] or instrument detection during surgical procedures [26, 27].", "startOffset": 60, "endOffset": 72}, {"referenceID": 13, "context": "Some of these have included: techniques for image denoising [14, 15, 16], strategies for improved image reconstruction [17, 18, 19, 20, 21, 22], dosimetry laser control systems [23, 24, 25] or instrument detection during surgical procedures [26, 27].", "startOffset": 119, "endOffset": 143}, {"referenceID": 14, "context": "Some of these have included: techniques for image denoising [14, 15, 16], strategies for improved image reconstruction [17, 18, 19, 20, 21, 22], dosimetry laser control systems [23, 24, 25] or instrument detection during surgical procedures [26, 27].", "startOffset": 119, "endOffset": 143}, {"referenceID": 15, "context": "Some of these have included: techniques for image denoising [14, 15, 16], strategies for improved image reconstruction [17, 18, 19, 20, 21, 22], dosimetry laser control systems [23, 24, 25] or instrument detection during surgical procedures [26, 27].", "startOffset": 119, "endOffset": 143}, {"referenceID": 16, "context": "Some of these have included: techniques for image denoising [14, 15, 16], strategies for improved image reconstruction [17, 18, 19, 20, 21, 22], dosimetry laser control systems [23, 24, 25] or instrument detection during surgical procedures [26, 27].", "startOffset": 119, "endOffset": 143}, {"referenceID": 17, "context": "Some of these have included: techniques for image denoising [14, 15, 16], strategies for improved image reconstruction [17, 18, 19, 20, 21, 22], dosimetry laser control systems [23, 24, 25] or instrument detection during surgical procedures [26, 27].", "startOffset": 119, "endOffset": 143}, {"referenceID": 18, "context": "Some of these have included: techniques for image denoising [14, 15, 16], strategies for improved image reconstruction [17, 18, 19, 20, 21, 22], dosimetry laser control systems [23, 24, 25] or instrument detection during surgical procedures [26, 27].", "startOffset": 119, "endOffset": 143}, {"referenceID": 19, "context": "Some of these have included: techniques for image denoising [14, 15, 16], strategies for improved image reconstruction [17, 18, 19, 20, 21, 22], dosimetry laser control systems [23, 24, 25] or instrument detection during surgical procedures [26, 27].", "startOffset": 177, "endOffset": 189}, {"referenceID": 20, "context": "Some of these have included: techniques for image denoising [14, 15, 16], strategies for improved image reconstruction [17, 18, 19, 20, 21, 22], dosimetry laser control systems [23, 24, 25] or instrument detection during surgical procedures [26, 27].", "startOffset": 177, "endOffset": 189}, {"referenceID": 21, "context": "Some of these have included: techniques for image denoising [14, 15, 16], strategies for improved image reconstruction [17, 18, 19, 20, 21, 22], dosimetry laser control systems [23, 24, 25] or instrument detection during surgical procedures [26, 27].", "startOffset": 177, "endOffset": 189}, {"referenceID": 22, "context": "Some of these have included: techniques for image denoising [14, 15, 16], strategies for improved image reconstruction [17, 18, 19, 20, 21, 22], dosimetry laser control systems [23, 24, 25] or instrument detection during surgical procedures [26, 27].", "startOffset": 241, "endOffset": 249}, {"referenceID": 23, "context": "Some of these have included: techniques for image denoising [14, 15, 16], strategies for improved image reconstruction [17, 18, 19, 20, 21, 22], dosimetry laser control systems [23, 24, 25] or instrument detection during surgical procedures [26, 27].", "startOffset": 241, "endOffset": 249}, {"referenceID": 24, "context": "More specific to pathology identification, various groups have explored automatic detection of retinal pathologies using machine learning techniques, either focusing on segmentation of relevant pathological markers [28, 29, 30, 31, 32] or classification of 2D B-scans or 3D Cscans [33, 34, 32, 35, 36].", "startOffset": 215, "endOffset": 235}, {"referenceID": 25, "context": "More specific to pathology identification, various groups have explored automatic detection of retinal pathologies using machine learning techniques, either focusing on segmentation of relevant pathological markers [28, 29, 30, 31, 32] or classification of 2D B-scans or 3D Cscans [33, 34, 32, 35, 36].", "startOffset": 215, "endOffset": 235}, {"referenceID": 26, "context": "More specific to pathology identification, various groups have explored automatic detection of retinal pathologies using machine learning techniques, either focusing on segmentation of relevant pathological markers [28, 29, 30, 31, 32] or classification of 2D B-scans or 3D Cscans [33, 34, 32, 35, 36].", "startOffset": 215, "endOffset": 235}, {"referenceID": 27, "context": "More specific to pathology identification, various groups have explored automatic detection of retinal pathologies using machine learning techniques, either focusing on segmentation of relevant pathological markers [28, 29, 30, 31, 32] or classification of 2D B-scans or 3D Cscans [33, 34, 32, 35, 36].", "startOffset": 215, "endOffset": 235}, {"referenceID": 28, "context": "More specific to pathology identification, various groups have explored automatic detection of retinal pathologies using machine learning techniques, either focusing on segmentation of relevant pathological markers [28, 29, 30, 31, 32] or classification of 2D B-scans or 3D Cscans [33, 34, 32, 35, 36].", "startOffset": 215, "endOffset": 235}, {"referenceID": 29, "context": "More specific to pathology identification, various groups have explored automatic detection of retinal pathologies using machine learning techniques, either focusing on segmentation of relevant pathological markers [28, 29, 30, 31, 32] or classification of 2D B-scans or 3D Cscans [33, 34, 32, 35, 36].", "startOffset": 281, "endOffset": 301}, {"referenceID": 28, "context": "More specific to pathology identification, various groups have explored automatic detection of retinal pathologies using machine learning techniques, either focusing on segmentation of relevant pathological markers [28, 29, 30, 31, 32] or classification of 2D B-scans or 3D Cscans [33, 34, 32, 35, 36].", "startOffset": 281, "endOffset": 301}, {"referenceID": 30, "context": "More specific to pathology identification, various groups have explored automatic detection of retinal pathologies using machine learning techniques, either focusing on segmentation of relevant pathological markers [28, 29, 30, 31, 32] or classification of 2D B-scans or 3D Cscans [33, 34, 32, 35, 36].", "startOffset": 281, "endOffset": 301}, {"referenceID": 31, "context": "More specific to pathology identification, various groups have explored automatic detection of retinal pathologies using machine learning techniques, either focusing on segmentation of relevant pathological markers [28, 29, 30, 31, 32] or classification of 2D B-scans or 3D Cscans [33, 34, 32, 35, 36].", "startOffset": 281, "endOffset": 301}, {"referenceID": 2, "context": "Using a publicly available OCT dataset [5], we show that our approach is highly effective at separating AMD", "startOffset": 39, "endOffset": 42}, {"referenceID": 30, "context": "[35] regions of interest are automatically extracted around the center of each C-scan via an intensity threshold.", "startOffset": 0, "endOffset": 4}, {"referenceID": 2, "context": "[5], who developed a semi-automatic classification method for AMD patients.", "startOffset": 0, "endOffset": 3}, {"referenceID": 11, "context": "Each B-scan was first resized to a resolution of 246x256 pixels, denoised using the Block Matching and 3D filtering (BM3D) algorithm [15] and then flattened.", "startOffset": 133, "endOffset": 137}, {"referenceID": 31, "context": "More recently, Lemaitre et al [36] followed in the direction of Liu et al.", "startOffset": 30, "endOffset": 34}, {"referenceID": 29, "context": "[33], by extracting 2D and 3D Local Binary Patterns (LBP) features from a set of 16 healthy and 16 patients suffering from DME.", "startOffset": 0, "endOffset": 4}, {"referenceID": 32, "context": "B-scans were denoised using the non-local means (NLM) algorithm [37] and flattened.", "startOffset": 64, "endOffset": 68}, {"referenceID": 28, "context": "[32] employed a 2D patch-based Convolutional Neural Network (CNN) to classify retinal tissue into Intra-retinal Cysts (IRC), Subretinal Fluid (SRF) and healthy categories, while providing information to the location of the pathology.", "startOffset": 0, "endOffset": 4}, {"referenceID": 33, "context": "To do so, we first detect the BM layer by applying an anisotropic filter on B n using 200 diffusion iterations [38]", "startOffset": 111, "endOffset": 115}, {"referenceID": 34, "context": "For this reason, we fit a secondorder polynomial model to the noisy responses using RANSAC outlier detection [39].", "startOffset": 109, "endOffset": 113}, {"referenceID": 35, "context": "We use data augmentation to increase the number of samples in our training dataset and reduce overfitting [40, 41].", "startOffset": 106, "endOffset": 114}, {"referenceID": 36, "context": "We use data augmentation to increase the number of samples in our training dataset and reduce overfitting [40, 41].", "startOffset": 106, "endOffset": 114}, {"referenceID": 37, "context": "To train this network, we first begin by initializing all layer parameters randomly using Glorot Uniform sampling [42].", "startOffset": 114, "endOffset": 118}, {"referenceID": 38, "context": "We then make use of Extreme Learning [43], as it has been shown to increase regularization by forcing the convolutional layers to map to a broader features space.", "startOffset": 37, "endOffset": 41}, {"referenceID": 2, "context": "Our method was trained and evaluated on the publicly available dataset from Duke University [5].", "startOffset": 92, "endOffset": 95}, {"referenceID": 39, "context": "- VGG19: is the 19-layer variant of the deep CNN approach for image classification described in [44].", "startOffset": 96, "endOffset": 100}, {"referenceID": 40, "context": "[45].", "startOffset": 0, "endOffset": 4}, {"referenceID": 41, "context": "[46], which extends the residual network concept using a complete graph of skip connections.", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "[32], which we re-implemented and trained on the OCT dataset.", "startOffset": 0, "endOffset": 4}, {"referenceID": 38, "context": "3 learned with Extreme Learning [43].", "startOffset": 32, "endOffset": 36}, {"referenceID": 42, "context": "We trained each network for a maximum of 100 epochs per fold, using early stopping with a patience of 15 epochs to avoid over-fitting [47, 48].", "startOffset": 134, "endOffset": 142}, {"referenceID": 43, "context": "We trained each network for a maximum of 100 epochs per fold, using early stopping with a patience of 15 epochs to avoid over-fitting [47, 48].", "startOffset": 134, "endOffset": 142}, {"referenceID": 44, "context": "We relied on the adadelta algorithm [49] to optimize the parameters of each network.", "startOffset": 36, "endOffset": 40}, {"referenceID": 28, "context": "2DSeg was optimized by minimizing the mean squared error, as described in [32].", "startOffset": 74, "endOffset": 78}, {"referenceID": 28, "context": "[32].", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "This is consistent with authors conclusion as well [32].", "startOffset": 51, "endOffset": 55}, {"referenceID": 2, "context": "[5], which achieved an AUC of 99.", "startOffset": 0, "endOffset": 3}, {"referenceID": 30, "context": "[35] which achieved an AUC of 98.", "startOffset": 0, "endOffset": 4}], "year": 2016, "abstractText": "Optical Coherence Tomography (OCT) provides a unique ability to image the eye retina in 3D at micrometer resolution and gives ophthalmologist the ability to visualize retinal diseases such as Age-Related Macular Degeneration (AMD). While visual inspection of OCT volumes remains the main method for AMD identification, doing so is time consuming as each cross-section within the volume must be inspected individually by the clinician. In much the same way, acquiring ground truth information for each cross-section is expensive and time consuming. This fact heavily limits the ability to acquire large amounts of groundtruth, which subsequently impacts the performance of learning-based methods geared at automatic pathology identification. To avoid this burden, we propose a novel strategy for automatic analysis of OCT volumes where only volume labels are needed. That is, we train a classifier in a semi-supervised manner to conduct this task. Our approach uses a novel Convolutional Neural Network (CNN) architecture, that only needs volume-level labels to be trained to automatically asses whether an OCT volume is healthy or contains AMD. Our architecture involves first learning a cross-section pathology classifier using pseudo-labels that could be corrupted and then leverage these towards a more accurate volume-level classification. We then show that our approach provides excellent performances on a publicly available dataset and outperforms a number of existing automatic techniques. keywords \u2014 Optical Coherence Tomography (OCT), Convolutional Neural Networks (CNN), AgeRelated Macular Degeneration (AMD), pathology identification, ophthalmology, machine learning", "creator": "LaTeX with hyperref package"}}}