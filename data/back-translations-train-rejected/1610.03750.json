{"id": "1610.03750", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Oct-2016", "title": "Semi-supervised Discovery of Informative Tweets During the Emerging Disasters", "abstract": "The first objective towards the effective use of microblogging services such as Twitter for situational awareness during the emerging disasters is discovery of the disaster-related postings. Given the wide range of possible disasters, using a pre-selected set of disaster-related keywords for the discovery is suboptimal. An alternative that we focus on in this work is to train a classifier using a small set of labeled postings that are becoming available as a disaster is emerging. Our hypothesis is that utilizing large quantities of historical microblogs could improve the quality of classification, as compared to training a classifier only on the labeled data. We propose to use unlabeled microblogs to cluster words into a limited number of clusters and use the word clusters as features for classification. To evaluate the proposed semi-supervised approach, we used Twitter data from 6 different disasters. Our results indicate that when the number of labeled tweets is 100 or less, the proposed approach is superior to the standard classification based on the bag or words feature representation. Our results also reveal that the choice of the unlabeled corpus, the choice of word clustering algorithm, and the choice of hyperparameters can have a significant impact on the classification accuracy.", "histories": [["v1", "Wed, 12 Oct 2016 15:26:30 GMT  (1140kb,D)", "http://arxiv.org/abs/1610.03750v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.SI", "authors": ["shanshan zhang", "slobodan vucetic"], "accepted": false, "id": "1610.03750"}, "pdf": {"name": "1610.03750.pdf", "metadata": {"source": "CRF", "title": "Semi-supervised Discovery of Informative Tweets During the Emerging Disasters", "authors": ["Shanshan Zhang", "Slobodan Vucetic"], "emails": ["zhang.shanshan@temple.edu", "vucetic@temple.edu"], "sections": [{"heading": null, "text": "CCS concepts \u2022 information systems \u2192 data analysis; keywords semi-supervised learning; Twitter; crisis management"}, {"heading": "1. INTRODUCTION", "text": "This year it has come to the point that it will only be a matter of time before it will happen, until it does."}, {"heading": "2. METHODOLOGY", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Problem Setup", "text": "Suppose we get a corpus of n documents labeled Dtrain = {(d1, y1), (d2, y2),..., (dn, yn)} and each document di is converted into a feature vector xi-Rm. For example, we could use the word string representation, where the feature vector xi in a vocabulary V is a binary vector of length | V | whose j-th element indicates whether the j. word from the vocabulary is present or not in the document di. By a slight extension, n-grams, part-of-speech tags, designated units or word clusters could also be used for feature representations of documents. The label yi of the document di is a binary variable indicating whether it is disaster-related or not, where yi = 1 indicates that the document is disaster-related and yi = 0 indicates that it is not a feature representation of documents. The label yi of the document di is a binary variable indicating whether it is disaster-related or not, where yi = 1 indicates that the document is catastrophe-related and yi = 0 indicates that it is not, we refer to the documents that we {are also a corpus, we refer to the documents that are not)."}, {"heading": "2.2 Feature Selection Filters", "text": "The aim of feature selection is to reduce the dimensionality of the feature vector. Feature selection filters are the simplest class of such algorithms, which attempt to select only a subset of the most informative features and remove the rest by calculating the score of each feature, which measures how strong its correlation with the classification label is. Only the K features with the highest score are preserved. There are many known scoring functions [9], among which the \u03c72 statistic and the Pointwise Mutual Information (PMI) are very popular for text classification. In this essay, we use the PMI score, which is defined as follows: score (t) = PMI (t, pos) \u2212 PMI (t, neg) = log2 p (t | pos) p (t | neg) (1), where p (t | pos) is the probability that feature appears in the positive class, feature (t), and the probability (neg) of the feature appearing in the negative class."}, {"heading": "2.3 Word Clusters as Features", "text": "Given these clusters, each di document is converted into a binary feature vector xi of length K, the j-th element of which xij is equal to one if one of the words from the j-th cluster is present in the document, and zero if not. To create the clusters, we rely on the corpus of unlabeled documents Dunl = {d1, d2,..., dN}. Given the corpus, we will evaluate two types of generation of word clusters, such as next.Brown Clustering (BC) [3]. This is a traditional algorithm for word clustering. It is a hierarchical clustering algorithm that assigns a single cluster to each word and by merging the two clusters that result in the smallest reduction of global mutual information."}, {"heading": "3. EXPERIMENTS AND EVALUATION", "text": "The goal of our experimental evaluation is to get an insight into the performance of the proposed semi-supervised approach, which uses a blank document corpus to create word clusters and trains a classifier on a small labeled document corpus in which the word clusters are used as features."}, {"heading": "3.1 Data Set", "text": "For our experiments, we used CrisisLexT6 data described in [8]. It is a collection of tweets referring to 6 natural disasters that occurred between October 2012 and July 2013: Sandy Hurricane (SH), Boston Bombings (BB), Oklahoma Tornado (OT), West Taxas Explosion (WE), Alberta Floods (AF), Queensland Floods (QF).For each disaster, the same number of tweets were selected using two different methods.One method was based on a pre-defined set of keywords suitable for a particular disaster, another method was based on the selection of geocoded tweets that originated in the affected areas during the onset of a disaster.The collected tweets were designated as a disaster or non-disaster by 100 workers from Crowdflower. Of the 60,000 Twitter IDs of tweets provided by the authors with a positive designation [8], we were only able to distort 70% of these tweets from the affected areas.The collected tweets are described by 100 workers from Crowdflower as a disaster or non-disaster related methodology. Of the 60,000 Twitter IDs of tweets provided by the authors with a positive designation [7], we were able to compile 70% of these tweets from the high-level tweets, and we will summarize their distribution based on the basic IDs based on the table of 1.Ds, which we will compile their statistical criteria in the table below."}, {"heading": "3.2 Experiment Design", "text": "In recent years, the number of people living in the US has multiplied, both in the US and in Europe."}, {"heading": "3.3 Results", "text": "This year, we will be able to put ourselves at the top, \"he said in an interview with\" Welt am Sonntag. \""}, {"heading": "4. CONCLUSION", "text": "In this paper, we addressed the problem of retrieving disaster-related tweets shortly after a disaster occurs. To address this problem, we proposed a semi-monitored approach that can use a large, unlabeled corpus of tweets to create word clusters and use them as classification characteristics. Our experiments with Twitter data from 6 disasters strongly suggest that in most cases, the proposed semi-monitored approach could lead to improved accuracy compared to the traditional, monitored learning approach, which uses trait selection on the word characteristics. Our study also provides useful insights into different modeling options when using the proposed approach. While \"the bigger the better\" is usually true in data science in this application, a careful look at the results also reveals that \"one size does not fit all\" and that many modeling options have different effects on different types of disasters."}, {"heading": "ACKNOWLEDGEMENTS", "text": "This work was supported by the NSF scholarship CNS-1461932."}], "references": [{"title": "Twitcident: fighting fire with information from social web streams", "author": ["F. Abel", "C. Hauff", "G.-J. Houben", "R. Stronkman", "K. Tao"], "venue": "In Proceedings of the 21st International Conference on World Wide Web,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2012}, {"title": "Tweedr: Mining twitter to inform disaster response", "author": ["Z. Ashktorab", "C. Brown", "M. Nandi", "A. Culotta"], "venue": "Proc. of ISCRAM,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2014}, {"title": "Class-based n-gram models of natural language", "author": ["P.F. Brown", "P.V. Desouza", "R.L. Mercer", "V.J.D. Pietra", "J.C. Lai"], "venue": "Computational linguistics,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1992}, {"title": "Processing social media messages in mass emergency: A survey", "author": ["M. Imran", "C. Castillo", "F. Diaz", "S. Vieweg"], "venue": "ACM Computing Surveys (CSUR),", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2015}, {"title": "Aidr: Artificial intelligence for disaster response", "author": ["M. Imran", "C. Castillo", "J. Lucas", "P. Meier", "S. Vieweg"], "venue": "In Proceedings of the 23rd International Conference on World Wide Web,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "Cross-language domain adaptation for classifying crisis-related short messages", "author": ["M. Imran", "P. Mitra", "J. Srivastava"], "venue": "arXiv preprint arXiv:1602.05388,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2016}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["T. Mikolov", "J. Dean"], "venue": "Advances in neural information processing systems,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2013}, {"title": "Crisislex: A lexicon for collecting and filtering microblogged communications in crises", "author": ["A. Olteanu", "C. Castillo", "F. Diaz", "S. Vieweg"], "venue": "In ICWSM,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}, {"title": "Characterization of permutation tests for feature selection", "author": ["P. Radivojac", "Z. Obradovic", "A. Dunker", "S. Vucetic"], "venue": "In Proc. 15th European Conference on Machine Learning,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2004}, {"title": "Emterms 1. 0: a terminological resource for crisis tweets", "author": ["I. Temnikova", "C. Castillo", "S. Vieweg"], "venue": "In IS- CRAM 2015 proceedings of the 12th international conference on information systems for crisis response and management,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2015}], "referenceMentions": [{"referenceID": 3, "context": "During the past decade, there has been plentiful evidence that social media can be very useful in improving the situational awareness during emergencies and disasters [4], and several research groups even proposed specific systems to extract, process, and summarize social media data for such purpose [1, 2, 5].", "startOffset": 167, "endOffset": 170}, {"referenceID": 0, "context": "During the past decade, there has been plentiful evidence that social media can be very useful in improving the situational awareness during emergencies and disasters [4], and several research groups even proposed specific systems to extract, process, and summarize social media data for such purpose [1, 2, 5].", "startOffset": 301, "endOffset": 310}, {"referenceID": 1, "context": "During the past decade, there has been plentiful evidence that social media can be very useful in improving the situational awareness during emergencies and disasters [4], and several research groups even proposed specific systems to extract, process, and summarize social media data for such purpose [1, 2, 5].", "startOffset": 301, "endOffset": 310}, {"referenceID": 4, "context": "During the past decade, there has been plentiful evidence that social media can be very useful in improving the situational awareness during emergencies and disasters [4], and several research groups even proposed specific systems to extract, process, and summarize social media data for such purpose [1, 2, 5].", "startOffset": 301, "endOffset": 310}, {"referenceID": 7, "context": "One is the information retrieval approach, which is based on developing a lexicon of disaster-related unigrams or bigrams based on a study of posts from previous disasters and emergencies [8, 10].", "startOffset": 188, "endOffset": 195}, {"referenceID": 9, "context": "One is the information retrieval approach, which is based on developing a lexicon of disaster-related unigrams or bigrams based on a study of posts from previous disasters and emergencies [8, 10].", "startOffset": 188, "endOffset": 195}, {"referenceID": 0, "context": "An alternative supervised learning approach is based on training a classifier that recognizes informative posts [1, 2, 5].", "startOffset": 112, "endOffset": 121}, {"referenceID": 1, "context": "An alternative supervised learning approach is based on training a classifier that recognizes informative posts [1, 2, 5].", "startOffset": 112, "endOffset": 121}, {"referenceID": 4, "context": "An alternative supervised learning approach is based on training a classifier that recognizes informative posts [1, 2, 5].", "startOffset": 112, "endOffset": 121}, {"referenceID": 8, "context": "There are many known scoring functions [9], among which the \u03c7 statistics and Pointwise Mutual Information (PMI) are very popular for text classification.", "startOffset": 39, "endOffset": 42}, {"referenceID": 2, "context": "Brown clustering (BC)[3].", "startOffset": 21, "endOffset": 24}, {"referenceID": 6, "context": "The idea of neural language models, of which the skip-gram model [7] is a representative, is to learn low-dimensional vector representation of words.", "startOffset": 65, "endOffset": 68}, {"referenceID": 6, "context": "In this paper, we use word2vec [7], which is a stochastic gradient algorithm that is commonly used to maximize this objective function.", "startOffset": 31, "endOffset": 34}, {"referenceID": 7, "context": "For our experiments, we used CrisisLexT6 data described in [8].", "startOffset": 59, "endOffset": 62}, {"referenceID": 7, "context": "Out of the 60,000 Twitter IDs of the labeled tweets provided by the authors of [8], we were only able to download 70% of them and we summarize their basic statistics in Table 1.", "startOffset": 79, "endOffset": 82}, {"referenceID": 4, "context": "Unlike the previous work that merged tweets from those two samples and split them randomly into training and test sets for evaluation [5, 6, 8], in this work we used only the tweets obtained by the location search.", "startOffset": 134, "endOffset": 143}, {"referenceID": 5, "context": "Unlike the previous work that merged tweets from those two samples and split them randomly into training and test sets for evaluation [5, 6, 8], in this work we used only the tweets obtained by the location search.", "startOffset": 134, "endOffset": 143}, {"referenceID": 7, "context": "Unlike the previous work that merged tweets from those two samples and split them randomly into training and test sets for evaluation [5, 6, 8], in this work we used only the tweets obtained by the location search.", "startOffset": 134, "endOffset": 143}], "year": 2016, "abstractText": "The first objective towards the effective use of microblogging services such as Twitter for situational awareness during the emerging disasters is discovery of the disaster-related postings. Given the wide range of possible disasters, using a pre-selected set of disaster-related keywords for the discovery is suboptimal. An alternative that we focus on in this work is to train a classifier using a small set of labeled postings that are becoming available as a disaster is emerging. Our hypothesis is that utilizing large quantities of historical microblogs could improve the quality of classification, as compared to training a classifier only on the labeled data. We propose to use unlabeled microblogs to cluster words into a limited number of clusters and use the word clusters as features for classification. To evaluate the proposed semisupervised approach, we used Twitter data from 6 different disasters. Our results indicate that when the number of labeled tweets is 100 or less, the proposed approach is superior to the standard classification based on the bag or words feature representation. Our results also reveal that the choice of the unlabeled corpus, the choice of word clustering algorithm, and the choice of hyperparameters can have a significant impact on the classification accuracy. CCS Concepts \u2022Information systems \u2192 Data analytics;", "creator": "LaTeX with hyperref package"}}}