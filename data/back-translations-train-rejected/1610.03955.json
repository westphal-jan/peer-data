{"id": "1610.03955", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Oct-2016", "title": "Dialogue Session Segmentation by Embedding-Enhanced TextTiling", "abstract": "In human-computer conversation systems, the context of a user-issued utterance is particularly important because it provides useful background information of the conversation. However, it is unwise to track all previous utterances in the current session as not all of them are equally important. In this paper, we address the problem of session segmentation. We propose an embedding-enhanced TextTiling approach, inspired by the observation that conversation utterances are highly noisy, and that word embeddings provide a robust way of capturing semantics. Experimental results show that our approach achieves better performance than the TextTiling, MMD approaches.", "histories": [["v1", "Thu, 13 Oct 2016 07:07:50 GMT  (403kb,D)", "http://arxiv.org/abs/1610.03955v1", "INTERSPEECH-16, pages 2706--2710"]], "COMMENTS": "INTERSPEECH-16, pages 2706--2710", "reviews": [], "SUBJECTS": "cs.CL cs.HC", "authors": ["yiping song", "lili mou", "rui yan", "li yi", "zinan zhu", "xiaohua hu", "ming zhang"], "accepted": false, "id": "1610.03955"}, "pdf": {"name": "1610.03955.pdf", "metadata": {"source": "CRF", "title": "Dialogue Session Segmentation by Embedding-Enhanced TextTiling", "authors": ["Yiping Song", "Lili Mou", "Rui Yan", "Li Yi", "Zinan Zhu", "Xiaohua Hu", "Ming Zhang"], "emails": ["songyiping@pku.edu.cn,", "doublepower.mou@gmail.com", "yanrui@mail.ccnu.edu.cn", "yili@mail.ccnu.edu.cn", "zzn@mail.ccnu.edu.cn", "huxiaohua@mail.ccnu.edu.cn"], "sections": [{"heading": "1. Introduction", "text": "In fact, most people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move and to move."}, {"heading": "2. Related Work", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1. Dialogue Systems and Context Modeling", "text": "Human computer-assisted dialog systems can be roughly divided into several categories. Template and rule-based systems are mainly designed for specific areas [5, 6, 14]. Although manually created templates can also be used in open spaces such as [15], their generated sentences are subject to 7 predefined forms and are therefore severely restricted. Retrieval methods search for an answer from a candidate in a large conversation corpus when a user issues a statement as a query [8]. Generative methods can synthesize new answers using statistical machine translation [16, 17] or neural networks [9]. The above studies do not take context information into account when querying or generating answers. However, recent research shows that earlier statements in a conversation session are important because they capture rich background information. Sordoni et al. [12] combine a single previous sentence as bag-of-words features that are fed into a recursive network for response."}, {"heading": "2.2. Text Segmentation", "text": "An early and classical work on text segmentation is TextTiling, proposed in [13]. The idea is to measure the similarity between two consecutive sentences using smoothing techniques; then segmentation is achieved by the threshold of the depth of a \"valley.\" In the original form of TextTiling, the cosine of term frequency characteristics is used as a measure of similarity. Joty et al. [23] instead of the threshold for segmentation, apply dividing clusters. Malioutov et al. [24] formalize segmentation as a graphical partitioning problem and propose a minimal intersection model based on tf \u00b7 idf characteristics for segmentation lectures. Ja et al. [25] minimize the similarity between segments and maximize the similarity within segments. However, the above-mentioned complicated approaches are known as global methods: if we make the segmentation between two consecutive sentences available as quantum information, we cannot use them as contexts within a word."}, {"heading": "3. Session Segmentation Methodology", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1. TextTiling", "text": "We use a TextTiling-like session segmentation algorithm. The original TextTiling is proposed by Hearst [13]. The basic idea is to measure the similarity of each adjacent sentence pair; then \"valleys\" of similarities are detected for segmentation. Specifically, the \"depth of the valley\" is defined by the similarity differences between the peak on each page and the current position. We can obtain some statistics on depth values such as the mean of \u00b5 and standard deviation \u03c3 and perform the segmentation by a limit threshold. cut-off (\u03b1) = \u00b5 + \u03b1 \u00b7 \u03c3 (1), where \u03b1 is a hyperparameter that adjusts the number of segmentation limits; \u00b5 and \u03c3 are the average and standard deviation of depth values, or standard deviation. In the scenario of human-computer conversations, we calculate the depth solely by the similarity difference between its left peak (previous context) and the current position, because we cannot get this during future utterances."}, {"heading": "3.2. Learning Word Embeddings", "text": "Word embedding learning is to maximize the average probability of all words (we have T running words) fixed = T = 1 imperated (T = 1 imperical). Compared to a one-dimensional representation, Word embedings are low-dimensional and dense, measuring word embeddings in a continuous vector space. Studies show that the offset of two words \"embedings\" represents a certain relationship, e.g. \"man\" \u2212 \"woman\" \u2248 \"king\" \u2212 \"queen\" [26]. Therefore, it is appropriate to use word embeddings to model short and loud conversation expressions. To train the embedding, we take the word2vec approach. The idea is to map a word w and its context c to vectors (w and c). Then we estimate the probability of a word byp (w | c) = exp (w > c)."}, {"heading": "3.3. Measuring Similarity", "text": "In this part we introduce several heuristics of similarity based on word embedding. Note that we do not use supervised learning (e.g. complete neural networks for sentence statements [28, 29]) to measure similarity, as it is costly to obtain high quality marked data. Perhaps the simplest approach is to sum up all word embedding in an utterance as sentence selection characteristics. This heuristics is essentially the method of sum compilation widely used in neural networks [30, 31, 28]. The cosinine measure is used as a similarity value between two utterances S1 and S2. Let s1 and s2 be their sentence selection vectors; then havesim (S1, S2) = cos (s2)."}, {"heading": "4. Experiments", "text": "In this section, we evaluate our Embedding Enhanced TextTiling method and the effects of session segmentation. In Section 4.1, we describe the data sets used in our experiments. Section 4.2 describes the segmentation accuracy of our method and baselines. In Section 4.3, we show that our session segmentation can improve the performance of a call system."}, {"heading": "4.1. Dataset", "text": "To evaluate the session segmentation method, we used a real-time chat corpus from DuMi, 3, a practice-oriented open-domain conversation system in Chinese. We randomly assigned 200 sessions as our experimental corpus. Session segmentations were commented manually before experiments and served as the basis for the truth. 200 sessions were randomly divided by 1: 1 for validation and verification. Note that our method does not require labeled training samples; massive data with high quality labels is quite expensive to procure. We also used an unlabeled massive data set of conversation expressions to train our word embedding with \"virtual sentences.\" The data set was searched from the Douban forum, 4 containing 3 million expressions and approximately 150,000 unique words (Chinese terms)."}, {"heading": "4.2. Segmentation Performance", "text": "We compared our complete method (TextTiling with heuristic-max based on embedding characterized by virtual sentences) with several baselines: \u2022 Random. We randomly segmented the conversation sessions. In this baseline we were provided with the previous probability of segmentation. \u2022 We applied the MinMax dotplotting (MMD) method provided by the authors."}, {"heading": "4.3. Session Segmentation in Dialogue Systems", "text": "We conducted an external experiment to show the effect of session segmentation in dialog systems. We integrated the segmentation mechanism into a practice-oriented retrieval system and evaluated the results using manual annotations, similar to our previous work [28, 32, 33]. Specifically, we compared our session segmentation with a fixed-length context used in [12]. That is, the competing method always considers two previous statements as context. We hired three employees to comment on the results with three integer results (0-2 points indicating bad, marginal, or good answers). We stamped 30 queries from the test set of 100 sessions. For each query, we collected 10 candidates and calculated p @ 15 and nDCG values [34] (averaged with three annotations). Provided, with previous statements as context, each employee had up to 1,000 sentences that he could read during the dialog, presenting the table 3 with fixed entries of the dialog system with a set of results."}, {"heading": "5. Conclusion", "text": "In this paper, we addressed the issue of session segmentation for open domain dialog systems. We proposed an embedding-enhanced TextTiling approach, where we practiced embedding with the novel idea of virtual sentences; we also proposed several heuristics for measuring similarity. Experimental results show that both our embedded learning and similarity measurement are effective at session segmentation and that our approach can improve the performance of a retrievable dialog system."}, {"heading": "6. Acknowledgments", "text": "We thank anonymous reviewers for useful comments and Jingbo Zhu for sharing the executable MMD program. This work is partially supported by the National Natural Science Foundation of China (NSFC funding numbers 61272343 and 61472006), the Doctoral Program of Chinese Higher Education (funding number 20130001110032) and the National Basic Research Program (973 funding number 2014CB340405)."}, {"heading": "7. References", "text": "[1] F. Bechet, A. Nasr, and B. Favre, \"Adapting dependency parsingto spontaneous speech for open domain spoken language understanding.\" in INTERSPEECH, 2014, pp. 135-139. [2] C. Liu, P. Xu, and R. Sarikaya, \"Deep contextual language understanding in spoken dialogue systems,\" in INTERSPEECH, 2015, pp. 120-124. [3] A. Cervone, C. Lai, S. Pareti, and P. Bell, \"Towards automatic detection of reported speech using prosodic cues,\" in INTERSPEECH, 2015, pp. 120-124. [V. Freeman, G.-A. Levow, R. Wright, and M. Ostendorf \"Investigating the role of\" yeah'in stance-dense conversation., \"in stance-dense conversation.,\" in INTERSPEECH, 2015, pp. 3076-3080. [5] G. Ferguson, J. Miller, B. Ostendorf. \""}], "references": [{"title": "Adapting dependency parsing to spontaneous speech for open domain spoken language understanding.", "author": ["F. Bechet", "A. Nasr", "B. Favre"], "venue": "INTERSPEECH,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "Deep contextual language understanding in spoken dialogue systems", "author": ["C. Liu", "P. Xu", "R. Sarikaya"], "venue": "INTERSPEECH, 2015, pp. 120\u2013124.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2015}, {"title": "Towards automatic detection of reported speech in dialogue using prosodic cues", "author": ["A. Cervone", "C. Lai", "S. Pareti", "P. Bell"], "venue": "INTERSPEECH, 2015, pp. 3061\u20133065.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}, {"title": "Investigating the role of \u2018yeah\u2019 in stance-dense conversation", "author": ["V. Freeman", "G.-A. Levow", "R. Wright", "M. Ostendorf"], "venue": "INTER- SPEECH, 2015, pp. 3076\u20133080.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2015}, {"title": "TRAINS-95: Towards a mixed-initiative planning assistant.", "author": ["G. Ferguson", "J. Allen", "B. Miller"], "venue": "AIPS,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1996}, {"title": "AutoTutor: An intelligent tutoring system with mixed-initiative dialogue", "author": ["A.C. Graesser", "P. Chipman", "B.C. Haynes", "A. Olney"], "venue": "IEEE Trans. Education, vol. 48, no. 4, pp. 612\u2013618, 2005.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2005}, {"title": "Investigation of recurrent-neural-network architectures and learning methods for spoken language understanding.", "author": ["G. Mesnil", "X. He", "L. Deng", "Y. Bengio"], "venue": "INTERSPEECH,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2013}, {"title": "Using random walks for question-focused sentence retrieval", "author": ["J. Otterbacher", "G. Erkan", "D.R. Radev"], "venue": "HLT-EMNLP, 2005, pp. 915\u2013922.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2005}, {"title": "Neural responding machine for shorttext conversation", "author": ["L. Shang", "Z. Lu", "H. Li"], "venue": "ACL-IJCNLP, 2015, pp. 1577\u20131586.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2015}, {"title": "A hierarchical recurrent encoder-decoder for generative context-aware query suggestion", "author": ["A. Sordoni", "Y. Bengio", "H. Vahabi", "C. Lioma", "J. Grue Simonsen", "J.-Y. Nie"], "venue": "CIKM, 2015, pp. 553\u2013 562.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2015}, {"title": "Easy contextual intent prediction and slot detection", "author": ["A. Bhargava", "A. Celikyilmaz", "D. Hakkani-Tur", "R. Sarikaya"], "venue": "ICASSP, 2013, pp. 8337\u20138341.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2013}, {"title": "A neural network approach to context-sensitive generation of conversational responses", "author": ["A. Sordoni", "M. Galley", "M. Auli", "C. Brockett", "Y. Ji", "M. Mitchell", "J.-Y. Nie", "J. Gao", "B. Dolan"], "venue": "NAACL-HLT, 2015, pp. 196\u2013205.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2015}, {"title": "TextTiling: Segmenting text into multi-paragraph subtopic passages", "author": ["M.A. Hearst"], "venue": "Computational Linguistics, vol. 23, no. 1, pp. 33\u201364, 1997.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1997}, {"title": "Cost-level integration of statistical and rule-based dialog managers", "author": ["S. Watanabe", "J.R. Hershey", "T.K. Marks", "Y. Fujii", "Y. Koji"], "venue": "INTERSPEECH, 2014, pp. 323\u2013327.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2014}, {"title": "Exploiting knowledge base to generate responses for natural language dialog listening agents", "author": ["S. Han", "J. Bang", "S. Ryu", "G.G. Lee"], "venue": "SIGDIAL, 2015, pp. 129\u2013133.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2015}, {"title": "Response-based learning for machine translation of open-domain database queries", "author": ["C. Haas", "S. Riezler"], "venue": "NAACL-HLT, 2015, pp. 1339\u20131344.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2015}, {"title": "Holy Moses! Leveraging existing tools and resources for entity translation", "author": ["J. Tavernier", "R. Cowan", "M. Vanni"], "venue": "LREC, 2008, pp. 2715\u20132719.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2008}, {"title": "Building end-to-end dialogue systems using generative hierarchical neural network models", "author": ["I.V. Serban", "A. Sordoni", "Y. Bengio", "A. Courville", "J. Pineau"], "venue": "arXiv preprint arXiv:1507.04808, 2015.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2015}, {"title": "Wikipedia-based kernels for dialogue topic tracking", "author": ["S. Kim", "R.E. Banchs", "H. Li"], "venue": "ICASSP, 2014, pp. 131\u2013135.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "Approximate inference for domain detection in spoken language understanding", "author": ["A. Celikyilmaz", "D.Z. Hakkani-T\u00fcr", "G. T\u00fcr"], "venue": "INTERSPEECH, 2011, pp. 713\u2013716.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2011}, {"title": "Topic identification in natural language dialogues using neural networks", "author": ["K. Lagus", "J. Kuusisto"], "venue": "SIGDIAL, 2002, pp. 95\u2013102.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2002}, {"title": "Multi-language hypotheses ranking and domain tracking for open domain dialogue systems", "author": ["P.A. Crook", "J.-P. Robichaud", "R. Sarikaya"], "venue": "INTERSPEECH, 2015, pp. 1810\u20131814.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2015}, {"title": "Topic segmentation and labeling in asynchronous conversations", "author": ["S. Joty", "G. Carenini", "R.T. Ng"], "venue": "JAIR, no. 47, pp. 521\u2013573, 2013.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2013}, {"title": "Minimum cut model for spoken lecture segmentation", "author": ["I. Malioutov", "R. Barzilay"], "venue": "COLING-ACL, 2006, pp. 25\u201332.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2006}, {"title": "An improved model of dotplotting for text segmentation", "author": ["N. Ye", "N. Ye", "J. Zhu", "H. Wang", "M.Y. Ma", "B. Zhang"], "venue": "J. Chinese Language and Computing, vol. 17, no. 1, pp. 27\u201340, 2007.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2007}, {"title": "Efficient estimation of word representations in vector space", "author": ["T. Mikolov", "K. Chen", "G. Corrado", "J. Dean"], "venue": "arXiv preprint arXiv:1301.3781, 2013.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2013}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["T. Mikolov", "I. Sutskever", "K. Chen", "G.S. Corrado", "J. Dean"], "venue": "NIPS, 2013, pp. 3111\u20133119.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2013}, {"title": "Learning to respond with deep neural networks for retrieval based human-computer conversation system", "author": ["R. Yan", "Y. Song", "H. Wu"], "venue": "SIGIR, 2016.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2016}, {"title": "Natural language inference by tree-based convolution and heuristic matching", "author": ["L. Mou", "R. Men", "G. Li", "Y. Xu", "L. Zhang", "R. Yan", "Z. Jin"], "venue": "ACL (2), 2016.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2016}, {"title": "Comparison of learning algorithms for handwritten digit recognition", "author": ["Y. LeCun", "L. Jackel", "L. Bottou", "A. Brunot", "C. Cortes", "J. Denker", "H. Drucker", "I. Guyon", "U. Muller", "E. Sackinger", "P. Simard", "V. Vapnik"], "venue": "Proc. Int\u2019l Conf. Artificial Neural Networks, 1995, pp. 53\u201360.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 1995}, {"title": "Discriminative neural sentence modeling by tree-based convolution", "author": ["L. Mou", "H. Peng", "G. Li", "Y. Xu", "L. Zhang", "Z. Jin"], "venue": "EMNLP, 2015, pp. 2315\u20132325.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2015}, {"title": "StalemateBreaker: A proactive content-introducing approach to automatic humancomputer conversation", "author": ["X. Li", "L. Mou", "R. Yan", "M. Zhang"], "venue": "IJCAI, 2016.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2016}, {"title": "Backward and forward language modeling for constrained natural language generation", "author": ["L. Mou", "R. Yan", "G. Li", "L. Zhang", "Z. Jin"], "venue": "arXiv preprint arXiv:1512.06612, 2015.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2015}, {"title": "Cumulated gain-based evaluation of ir techniques", "author": ["K. J\u00e4rvelin", "J. Kek\u00e4l\u00e4inen"], "venue": "ACM Trans. Information Systems, vol. 20, no. 4, pp. 422\u2013446, 2002.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2002}, {"title": "Measuring nominal scale agreement among many raters", "author": ["J. Fleiss"], "venue": "Psychological Bulletin, vol. 76, no. 5, pp. 378\u2013382, 1971.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 1971}], "referenceMentions": [{"referenceID": 4, "context": "In early years, researchers have developed various domain-oriented dialogue systems, which are typically based on rules or templates [5, 6, 7].", "startOffset": 133, "endOffset": 142}, {"referenceID": 5, "context": "In early years, researchers have developed various domain-oriented dialogue systems, which are typically based on rules or templates [5, 6, 7].", "startOffset": 133, "endOffset": 142}, {"referenceID": 6, "context": "In early years, researchers have developed various domain-oriented dialogue systems, which are typically based on rules or templates [5, 6, 7].", "startOffset": 133, "endOffset": 142}, {"referenceID": 7, "context": "Researchers have proposed information retrieval methods [8] and modern generative neural networks [9, 10] to either search for a reply from a large conversation corpus or generate a new sentence as the reply.", "startOffset": 56, "endOffset": 59}, {"referenceID": 8, "context": "Researchers have proposed information retrieval methods [8] and modern generative neural networks [9, 10] to either search for a reply from a large conversation corpus or generate a new sentence as the reply.", "startOffset": 98, "endOffset": 105}, {"referenceID": 9, "context": "Researchers have proposed information retrieval methods [8] and modern generative neural networks [9, 10] to either search for a reply from a large conversation corpus or generate a new sentence as the reply.", "startOffset": 98, "endOffset": 105}, {"referenceID": 1, "context": "In open-domain conversations, context information (one or a few previous utterances) is particularly important to language understanding [2, 10, 11, 12].", "startOffset": 137, "endOffset": 152}, {"referenceID": 9, "context": "In open-domain conversations, context information (one or a few previous utterances) is particularly important to language understanding [2, 10, 11, 12].", "startOffset": 137, "endOffset": 152}, {"referenceID": 10, "context": "In open-domain conversations, context information (one or a few previous utterances) is particularly important to language understanding [2, 10, 11, 12].", "startOffset": 137, "endOffset": 152}, {"referenceID": 11, "context": "In open-domain conversations, context information (one or a few previous utterances) is particularly important to language understanding [2, 10, 11, 12].", "startOffset": 137, "endOffset": 152}, {"referenceID": 0, "context": "However, our approach is directly applicable to dialogue systems with acoustic interaction, provided that the spoken language is converted to texts by automatic speech recognition (ASR) [1, 2], or even manually text-transcribed for research purposes like [3, 4].", "startOffset": 186, "endOffset": 192}, {"referenceID": 1, "context": "However, our approach is directly applicable to dialogue systems with acoustic interaction, provided that the spoken language is converted to texts by automatic speech recognition (ASR) [1, 2], or even manually text-transcribed for research purposes like [3, 4].", "startOffset": 186, "endOffset": 192}, {"referenceID": 2, "context": "However, our approach is directly applicable to dialogue systems with acoustic interaction, provided that the spoken language is converted to texts by automatic speech recognition (ASR) [1, 2], or even manually text-transcribed for research purposes like [3, 4].", "startOffset": 255, "endOffset": 261}, {"referenceID": 3, "context": "However, our approach is directly applicable to dialogue systems with acoustic interaction, provided that the spoken language is converted to texts by automatic speech recognition (ASR) [1, 2], or even manually text-transcribed for research purposes like [3, 4].", "startOffset": 255, "endOffset": 261}, {"referenceID": 12, "context": "For example, Hearst [13] proposes the TextTiling approach; she measures the similarity of neighboring sentences based on bag-of-words features, and performs segmentation by thresholding.", "startOffset": 20, "endOffset": 24}, {"referenceID": 4, "context": "Template- and rule-based systems are mainly designed for certain domains [5, 6, 14].", "startOffset": 73, "endOffset": 83}, {"referenceID": 5, "context": "Template- and rule-based systems are mainly designed for certain domains [5, 6, 14].", "startOffset": 73, "endOffset": 83}, {"referenceID": 13, "context": "Template- and rule-based systems are mainly designed for certain domains [5, 6, 14].", "startOffset": 73, "endOffset": 83}, {"referenceID": 14, "context": "Although manually engineered templates can also be applied in the open domain like [15], but their generated sentences are subject to 7 predefined forms, and hence are highly restricted.", "startOffset": 83, "endOffset": 87}, {"referenceID": 7, "context": "Retrieval methods search for a candidate reply from a large conversation corpus given a user-issued utterance as a query [8].", "startOffset": 121, "endOffset": 124}, {"referenceID": 15, "context": "Generative methods can synthesize new replies by statistical machine translation [16, 17] or neural networks [9].", "startOffset": 81, "endOffset": 89}, {"referenceID": 16, "context": "Generative methods can synthesize new replies by statistical machine translation [16, 17] or neural networks [9].", "startOffset": 81, "endOffset": 89}, {"referenceID": 8, "context": "Generative methods can synthesize new replies by statistical machine translation [16, 17] or neural networks [9].", "startOffset": 109, "endOffset": 112}, {"referenceID": 11, "context": "[12] summarize a single previous sentence as bag-of-words features, which are fed to a recurrent neural network for reply generation.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[18] design an attention-based neural network over all previous conversation turns/rounds, but this could be inefficient if a session lasts long in real commercial applications.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": ", [19, 20, 21, 22].", "startOffset": 2, "endOffset": 18}, {"referenceID": 19, "context": ", [19, 20, 21, 22].", "startOffset": 2, "endOffset": 18}, {"referenceID": 20, "context": ", [19, 20, 21, 22].", "startOffset": 2, "endOffset": 18}, {"referenceID": 21, "context": ", [19, 20, 21, 22].", "startOffset": 2, "endOffset": 18}, {"referenceID": 12, "context": "An early and classic work on text segmentation is TextTiling, proposed in [13].", "startOffset": 74, "endOffset": 78}, {"referenceID": 22, "context": "[23] apply divisive clustering instead of thresholding for segmentation.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[24] formalize segmentation as a graph-partitioning problem and propose a minimum cut model based on tf \u00b7idf features to segment lectures.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "[25] minimize between-segment similarity while maximizing within-segment similarity.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "The original TextTiling is proposed by Hearst [13].", "startOffset": 46, "endOffset": 50}, {"referenceID": 12, "context": "As argued by Hearst [13], text overlap (repetition) between neighboring sentences is a strong hint of semantic coherence, which can be well captured by term frequency or tf \u00b7idf variants.", "startOffset": 20, "endOffset": 24}, {"referenceID": 25, "context": "Word embeddings are distributed, real-valued vector representations of discrete words [26, 27].", "startOffset": 86, "endOffset": 94}, {"referenceID": 26, "context": "Word embeddings are distributed, real-valued vector representations of discrete words [26, 27].", "startOffset": 86, "endOffset": 94}, {"referenceID": 25, "context": ", \u201cman\u201d \u2212 \u201cwoman\u201d \u2248 \u201cking\u201d \u2212 \u201cqueen\u201d [26].", "startOffset": 37, "endOffset": 41}, {"referenceID": 25, "context": "Notice that the context vector u in Equation (4) and the output vector w in Equation (2) are different as suggested in [26, 27], but the details are beyond the scope of our paper.", "startOffset": 119, "endOffset": 127}, {"referenceID": 26, "context": "Notice that the context vector u in Equation (4) and the output vector w in Equation (2) are different as suggested in [26, 27], but the details are beyond the scope of our paper.", "startOffset": 119, "endOffset": 127}, {"referenceID": 27, "context": ", full neural networks for sentence paring [28, 29]) to measure similarity, because it is costly to obtain labeled data of high quality.", "startOffset": 43, "endOffset": 51}, {"referenceID": 28, "context": ", full neural networks for sentence paring [28, 29]) to measure similarity, because it is costly to obtain labeled data of high quality.", "startOffset": 43, "endOffset": 51}, {"referenceID": 29, "context": "This heuristic is essentially the sum pooling method widely used in neural networks [30, 31, 28].", "startOffset": 84, "endOffset": 96}, {"referenceID": 30, "context": "This heuristic is essentially the sum pooling method widely used in neural networks [30, 31, 28].", "startOffset": 84, "endOffset": 96}, {"referenceID": 27, "context": "This heuristic is essentially the sum pooling method widely used in neural networks [30, 31, 28].", "startOffset": 84, "endOffset": 96}, {"referenceID": 24, "context": "[25].", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "We implemented TextTiling ourselves according to [13].", "startOffset": 49, "endOffset": 53}, {"referenceID": 25, "context": "For word embeddings, we trained them on the 3Msentence dataset with three strategies: (1) virtual-sentence context proposed in our paper; (2) within-sentence context, where all words (except the current one) within a sentence (either a query or reply) are regarded as the context; (3) window-based context, which is the original form of [26]: the context is the words in a window (previous 2 words and future 2 words in the sentence).", "startOffset": 337, "endOffset": 341}, {"referenceID": 27, "context": "We integrated the segmentation mechanism into a state-of-the-practice retrievalbased system and evaluated the results by manual annotation, similar to our previous work [28, 32, 33].", "startOffset": 169, "endOffset": 181}, {"referenceID": 31, "context": "We integrated the segmentation mechanism into a state-of-the-practice retrievalbased system and evaluated the results by manual annotation, similar to our previous work [28, 32, 33].", "startOffset": 169, "endOffset": 181}, {"referenceID": 32, "context": "We integrated the segmentation mechanism into a state-of-the-practice retrievalbased system and evaluated the results by manual annotation, similar to our previous work [28, 32, 33].", "startOffset": 169, "endOffset": 181}, {"referenceID": 11, "context": "Concretely, we compared our session segmentation with fixed-length context, used in [12].", "startOffset": 84, "endOffset": 88}, {"referenceID": 33, "context": "For each query, we retrieved 10 candidates and computed p@1 and nDCG scores [34] (averaged over three annotators).", "startOffset": 76, "endOffset": 80}, {"referenceID": 34, "context": "411, indicating moderate agreement [35].", "startOffset": 35, "endOffset": 39}], "year": 2016, "abstractText": "In human-computer conversation systems, the context of a userissued utterance is particularly important because it provides useful background information of the conversation. However, it is unwise to track all previous utterances in the current session as not all of them are equally important. In this paper, we address the problem of session segmentation. We propose an embedding-enhanced TextTiling approach, inspired by the observation that conversation utterances are highly noisy, and that word embeddings provide a robust way of capturing semantics. Experimental results show that our approach achieves better performance than the TextTiling, MMD approaches.", "creator": "LaTeX with hyperref package"}}}