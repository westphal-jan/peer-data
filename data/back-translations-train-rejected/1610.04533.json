{"id": "1610.04533", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Feb-2016", "title": "A Comprehensive Comparative Study of Word and Sentence Similarity Measures", "abstract": "Sentence similarity is considered the basis of many natural language tasks such as information retrieval, question answering and text summarization. The semantic meaning between compared text fragments is based on the words semantic features and their relationships. This article reviews a set of word and sentence similarity measures and compares them on benchmark datasets. On the studied datasets, results showed that hybrid semantic measures perform better than both knowledge and corpus based measures.", "histories": [["v1", "Wed, 17 Feb 2016 19:33:47 GMT  (444kb)", "http://arxiv.org/abs/1610.04533v1", "7 pages,4 figures"]], "COMMENTS": "7 pages,4 figures", "reviews": [], "SUBJECTS": "cs.IR cs.CL", "authors": ["issa atoum", "ahmed otoom", "narayanan kulathuramaiyer"], "accepted": false, "id": "1610.04533"}, "pdf": {"name": "1610.04533.pdf", "metadata": {"source": "CRF", "title": "A Comprehensive Comparative Study of Word and Sentence Similarity Measures", "authors": ["Issa Atoum", "Ahmed Otoom", "Narayanan Kulathuramaiyer"], "emails": ["Issa.Atoum@wise.edu.jo", "aotoom@rjaf.mil.jo", "nara@fit.unimas.my"], "sections": [{"heading": null, "text": "The semantic meaning of comparative text fragments is based on the semantic characteristics of the words and their relationships. This article reviews a number of word and sentence similarity measurements and compares them against benchmark data sets. In the data sets examined, the results showed that hybrid semantic metrics work better than knowledge and body-based metrics. General terms semantic similarity, natural language processing, computational linguistics, text similarity Keywords word similarity, sentence similarity, corpus measurements, knowledge measurements, hybrid measurements, text similarity"}, {"heading": "1. INTRODUCTION", "text": "In fact, most people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move and to move."}, {"heading": "2. RELATED WORK", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Word Similarity Methods", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1.1 Corpus based Methods", "text": "The first category of these methods is based on the information content (IC) of the least common subsumer (LCS) of compared term synsets [23] - [25]; the second category, a group known as distribution methods, depends on the distribution of words within a text context. Words that occur simultaneously are presented as vectors of grammatical dependencies; the distribution method, the LSA similarity [16], [26] transforms text into a low-dimensional matrix and finds the most common words that can occur together in the edited text. Corpus-based methods are domain-dependent because they are limited to their base corpora."}, {"heading": "2.1.2 Knowledge based Methods", "text": "Knowledge-based methods use information from dictionaries (such as WordNet) to obtain similarity values. Classical knowledge-based methods use the shortest path measurement [27], while others extend the path measurement by the depth of the LCS of compared words [28], [29]. Leacock Khodorov [30] proposed a measure of similarity based on the number of nodes in a taxonomy and the shortest path between compared terms. Hirst and St-Onge [31] looked at all types of WordNet relationships; the path length and its change in direction. Some methods [23] - [25] have the ability to use intrinsic information instead of information content. Knowledge-based methods suffer from limited handmade ontologies."}, {"heading": "2.1.3 Hybrid Methods", "text": "Rodriguez and Egenhofer [33] used the weighted sum between synthesis paths, adjacent concepts, and their properties in a knowledge fusion model. Dong et al. [34] proposed a weighted edge approach to obtain different word weights that share the same LCS and have the same graph spacing; words with lower edge weights are more similar than words with higher edge weights. Atoum and Bong [35] proposed a hybrid measure for distance-based / knowledge-based method [29] and a method for information content [23]. They called their model Joint Distance and Information Content Word Similarity Measure (JDIC). In this category too, web-based methods depend on web resources to calculate the similarity. Turney et al. [9] used a measure called Point-Wise Mutual Information and Retrieval (JDIC)."}, {"heading": "2.2 Sentence Similarity Methods", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.2.1 Corpus based Methods", "text": "These methods are based on a corpus characteristic. The first category, traditional methods of retrieving information, Term Frequency -Inverse Document Frequency (TF-IDF) methods [37] - [39], assumes that documents have common words. However, these methods are not valid for sentences because sentences can have zero common words [29], [40]. The sentences \"my boy went to school\" and \"children learn mathematics\" have no common word, although they are semantically related to education.Based on the TF-IDF idea, word randomness is proposed in the second category. They model words more randomly than vectors of semantic characteristics; LSA [10] [26], hyperspace analogues to language (HAL) [41], and LDA [7] [17] [18] [45]. After these vectors have measured a similarity in how the Cosinus problem is used to calculate the final similarity between text categories."}, {"heading": "2.2.2 Knowledge based Methods", "text": "Knowledge-based methods use semantic dictionary information such as word relations [31] [40] [49], information content [1], [23] to obtain semantic properties of these objects and behaviors of these objects. Li et al. [20] proposed sentence similarity based on the aspects a person interprets sentences; objects described in the sentence, properties of these objects and behaviors of these objects. Tian et al. [19] proposed sentence similarity based on WordNet IC and parts of speech tree cores. Huang and Sheng [45] proposed sentence similarity measurement for paraphrase recognition and text processing based on WordNet IC and string processing distance. Lee [50] built semantic vectors from WordNet information and a portion of language tree cores. Abdalgader and Skabar [51] proposed sentence similarity measurement based on word disambigurement and text development."}, {"heading": "2.2.3 Hybrid Methods", "text": "Hybrid methods are combinations of the aforementioned methods. Croft et al. [4] applied their measure to photographic descriptive data based on semantic vectors of path and term frequency. Li et al. [29] proposed a sentence similarity based on WordNet information, IC of the Brown corpus, and sentence orders. Later [52] proposed a word similarity based on a new information content formula and Lin word similarity [23].Ho et al. [6] included a modified version of the meaning of the word clarification of [53] in their similarity measurement. Feng et al. [54] used direct (word relations) and indirect (argumentation) relevance between sentences to estimate the sentence similarity. Liu et al. [55] proposed a sentence similarity based on dynamic time-wrapping method (DTW). They calculated the similarity between sentences by dividing them by means of W distance measurement."}, {"heading": "3. EXPERIMENTAL EVALUATION", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Word Similarity Methods", "text": "Rubenstein and Goodenough examined synonymic assessments of 65 nounpairs categorized by human experts on a scale from 0.0 to 4.0. Miller and Charles selected 30 pairs of words from 65 pairs of nounpairs and ranked them among three levels of similarity. Experiments were conducted using WordNet 3.0 [59] for knowledge-based measurements and Brown Dictionary [60] for corporeal measurements, and the similarity measurements were implemented using custom Python code. Figure 1 and Figure 2 summarize the Pearson correlation of human-based measurements of difference similarity on the Millern- and Goodenough datasets, respectively. Results showed that it is impossible to argue which is the best word method unless the method is applied in real life or tested on a benchmark dataset. Hybrid methods (e.g. DIC) provide better results than other knowledge-based and knowledge-based methods."}, {"heading": "3.2 Sentence Similarity Methods", "text": "To evaluate the performance of the set similarity methods [29], the data set that was replaced by [29] (the STSS-65 data set) was selected at 0.01 (the STSS-65 data set). It consists of set pairs that were originally constructed manually to evaluate a brief similarity measurement 1 http: / / semanticsimilarity.net / benchmark-datasets.named STASIS. In STSS-65 data set, the corresponding words in [57] are replaced with the word definitions from the Collins Cobuild Dictionary [61]. Instead of all 65 pairs Li et al. [29] decided to keep only the most accurate commented and balanced set pairs. Note that in this data set the pair number 17 was used with different human scores, namely (0,13,0.063,0.048) in various research papers e.g. [4], [29], [50]. The human score 0.13 was used first in the main work, but later published with the [00.62 data sets]."}, {"heading": "4. CONCLUSION", "text": "The study showed that word similarity is not enough to choose a good unit for sentence similarity. Hybrid sentence similarities are generally better than corpus- and knowledge-based methods. In the future it is planned to test further word and sentence methods on other data sets. In addition, more work will focus on an approach to choose between correlations between Spearman and Pearson. No corresponding word pairs Mean Li 2006Tsatsaronis2010Islam 2008 Ho 2010Croft 2013 Islam 201256 Coastal Regions 0.59 0.76 0.93 0.47 0.49 0.80 0.4257 Forest Forest 0.63 0.7 0.61 0.26 0.34 1.00 0.4758 Implementing Tool 0.59 0.75 0.74 0.51 0.56 0.80 6759 Rooster 0.86 0.94 0.87 1.00 1.00 0.94 1.00 0.87 0.00 0.49 0.49 0.49 86 0.49 86 0.49 0.49 0.49 86 0.49 0.49 0.49 0.49 86 0.49 0.49 0.49 0.49 0.49 86 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 86 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 86 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 86 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49"}, {"heading": "5. REFERENCES", "text": "[1] P. Resnik, \"Using information content to evaluate semanticsimilarity in a taxonomy 13th,\" I, in Proceedings of the 14th international joint conference on Artificial intelligence (IJCAI '95), 1995, vol. 1, pp. 448-453. [2] A. Islam and D. Inkpen, \"Unsupervised Near-SynonymChoice using the Google Web 1T,\" ACM Trans. Knowl. International Conference on Acoustics, vol. V, no. June, pp. 1-19, 2012. [3] B. Chen, \"Latent topic of word co-occurenceinformation.\" [4] D. Croft, S. Coupland, S. Brown, A."}], "references": [{"title": "Using information content to evaluate semantic similarity in a taxonomy", "author": ["P. Resnik"], "venue": "Proceedings of the 14th international joint conference on Artificial intelligence (IJCAI\u201995), 1995, vol. 1, pp. 448\u2013453.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1995}, {"title": "Unsupervised Near-Synonym Choice using the Google Web 1T", "author": ["A. Islam", "D. Inkpen"], "venue": "ACM Trans. Knowl. Discov. Data, vol. V, no. June, pp. 1\u201319, 2012.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2012}, {"title": "Latent topic modelling of word co-occurence information for spoken document retrieval", "author": ["B. Chen"], "venue": "IEEE International Conference on Acoustics, Speech and Signal Processing ICASSP 2009, 2009, no. 2, pp. 3961\u20133964.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2009}, {"title": "A fast and efficient semantic short text similarity metric", "author": ["D. Croft", "S. Coupland", "J. Shell", "S. Brown"], "venue": "Computational Intelligence (UKCI), 2013 13th UK Workshop on, 2013, pp. 221\u2013227.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2013}, {"title": "An integrated semantic-based approach in concept based video retrieval", "author": ["S. Memar", "L.S. Affendey", "N. Mustapha", "S.C. Doraisamy", "M. Ektefa"], "venue": "Multimed. Tools Appl., vol. 64, no. 1, pp. 77\u201395, Aug. 2011.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2011}, {"title": "Word sense disambiguation-based sentence similarity", "author": ["C. Ho", "M.A.A. Murad", "R.A. Kadir", "S.C. Doraisamy"], "venue": "Proceedings of the 23rd International Conference on Computational Linguistics: Posters, 2010, no. August, pp. 418\u2013426.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2010}, {"title": "Real-word Spelling Correction Using Google Web IT 3-grams", "author": ["A. Islam", "D. Inkpen"], "venue": "Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 3 - Volume 3, 2009, pp. 1241\u20131249.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2009}, {"title": "Roget\u2019s Thesaurus and Semantic Similarity", "author": ["M. Jarmasz", "S. Szpakowicz"], "venue": "Recent Adv. Nat. Lang. Process. III Sel. Pap. from RANLP 2003, vol. 111, 2004.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2003}, {"title": "Mining the Web for Synonyms: PMI-IR versus LSA on TOEFL", "author": ["P. Turney"], "venue": "Proceedings of the 12th European Conference on Machine Learning, 2001, pp. 491\u2013502.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2001}, {"title": "A Comparative Study of Two Short Text Semantic Similarity Measures", "author": ["J. O\u2019Shea", "Z. Bandar", "K. Crockett", "D. McLean"], "venue": "Agent and Multi-Agent Systems: Technologies and Applications, vol. 4953, N. Nguyen, G. Jo, R. Howlett, and L. Jain, Eds. Springer Berlin Heidelberg, 2008, pp. 172\u2013181.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2008}, {"title": "Literature extraction of protein functions using sentence pattern mining", "author": ["J.-H. Chiang", "H.-C. Yu"], "venue": "IEEE Trans. Knowl. Data Eng., vol. 17, no. 8, pp. 1088\u20131098, 2005.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2005}, {"title": "Measuring Software Quality in Use: State-of-the-Art and Research Challenges", "author": ["I. Atoum", "C.H. Bong"], "venue": "ASQ.Software Qual. Prof., vol. 17, no. 2, pp. 4\u201315, 2015.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2015}, {"title": "Using Latent Semantic Analysis to Identify Quality in Use ( QU ) Indicators from User Reviews", "author": ["S.T.W. Wendy", "B.C. How", "I. Atoum"], "venue": "The International Conference on Artificial Intelligence and Pattern Recognition (AIPR2014), 2014, pp. 143\u2013151.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2014}, {"title": "Building a Pilot Software Quality-in-Use Benchmark Dataset", "author": ["I. Atoum", "C.H. Bong", "N. Kulathuramaiyer"], "venue": "9th International Conference on IT in Asia, 2015.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2015}, {"title": "Indexing by latent semantic analysis", "author": ["S. Deerwester", "S. Dumais", "T. Landauer", "G. Furnas", "R. Harshman"], "venue": "J. Am. Soc. Inf. Sci., vol. 41, no. 6, pp. 391\u2013407, Sep. 1990.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1990}, {"title": "An introduction to latent semantic analysis", "author": ["T.K. Landauer", "P.W. Foltz", "D. Laham"], "venue": "Discourse Process., vol. 25, no. 2\u20133, pp. 259\u2013284, 1998.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1998}, {"title": "A Simple Unsupervised Latent Semantics Based Approach for Sentence Similarity", "author": ["W. Guo", "M. Diab"], "venue": "Proceedings of the First Joint Conference on Lexical and Computational Semantics - Volume 1: Proceedings of the Main Conference and the Shared Task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation, 2012, pp. 586\u2013590.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2012}, {"title": "A Fast Matching Method Based on Semantic Similarity for Short Texts", "author": ["J. Xu", "P. Liu", "G. Wu", "Z. Sun", "B. Xu", "H. Hao"], "venue": "Natural Language Processing and Chinese Computing, Y. Zhou, Guodong and Li, Juanzi and Zhao, Dongyan and Feng, Ed. Chongqing, China: Springer Berlin Heidelberg, 2013, pp. 299\u2013309.  8", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2013}, {"title": "Measuring the similarity of short texts by word similarity and tree kernels", "author": ["Y. Tian", "H. Li", "Q. Cai", "S. Zhao"], "venue": "IEEE Youth Conference on Information Computing and Telecommunications (YC-ICT), 2010, pp. 363\u2013366.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2010}, {"title": "Measuring sentence similarity from different aspects", "author": ["L. Li", "X. Hu", "B.-Y. Hu", "J. Wang", "Y.-M. Zhou"], "venue": "International Conference on Machine Learning and Cybernetics, 2009, 2009, vol. 4, pp. 2244\u20132249.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2009}, {"title": "WordNet: An electronic lexical database. 1998", "author": ["C. Fellbaum"], "venue": "WordNet is available from http//www. cogsci. princeton. edu/wn, no. 2000, pp. 231\u2013243, 2010.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2000}, {"title": "The Evaluation of Sentence Similarity Measures", "author": ["P. Achananuparp", "X. Hu", "X. Shen"], "venue": "Data Warehousing and Knowledge Discovery, vol. 5182, I.-Y. Song, J. Eder, and T. Nguyen, Eds. Springer Berlin Heidelberg, 2008, pp. 305\u2013316.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2008}, {"title": "An information-theoretic definition of similarity", "author": ["D. Lin"], "venue": "Proceedings of the 15th international conference on Machine Learning, 1998, vol. 1, pp. 296\u2013304.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1998}, {"title": "Disambiguating Noun Groupings with Respect to WordNet Senses", "author": ["P. Resnik"], "venue": "Natural Language Processing Using Very Large Corpora SE - 6, 1995, vol. 11, pp. 77\u2013 98.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1995}, {"title": "Semantic similarity based on corpus statistics and lexical taxonomy", "author": ["J.J. Jiang", "D.W. Conrath"], "venue": "Proceedings of the 10th Research on Computational Linguistics International Conference (ROCLING X), 1997, pp. 19\u201333.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 1997}, {"title": "Indexing by latent semantic analysis", "author": ["S. Deerwester", "S. Dumais"], "venue": "J. Am. Soc. Inf. Sci., vol. 41, no. 6, pp. 391\u2013407, Sep. 1990.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1990}, {"title": "Development and application of a metric on semantic nets", "author": ["R. Rada", "H. Mili", "E. Bicknell", "M. Blettner"], "venue": "IEEE Trans. Syst. Man Cybern., vol. 19, no. 1, pp. 17\u201330, 1989.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1989}, {"title": "Verbs semantics and lexical selection", "author": ["Z. Wu", "M. Palmer"], "venue": "Proceedings of the 32nd annual meeting on Association for Computational Linguistics, 1994, pp. 133\u2013 138.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 1994}, {"title": "Sentence similarity based on semantic nets and corpus statistics", "author": ["Y. Li", "D. McLean", "Z.A. Bandar", "J.D. O\u2019Shea", "K. Crockett"], "venue": "IEEE Trans. Knowl. Data Eng., vol. 18, no. 8, pp. 1138\u20131150, Aug. 2006.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2006}, {"title": "Combining local context and WordNet similarity for word sense identification", "author": ["C. Leacock", "M. Chodorow"], "venue": "WordNet An Electron. Lex. database, vol. 49, no. 2, pp. 265\u2013283, 1998.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 1998}, {"title": "Lexical chains as representations of context for the detection and correction of malapropisms", "author": ["G. Hirst", "D. St-Onge"], "venue": "WordNet: An electronic lexical database, vol. 305, C. Fellbaum, Ed. Cambridge, MA: The MIT Press, 1998, pp. 305\u2013332.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 1998}, {"title": "A New Model of Information Content for Semantic Similarity in WordNet", "author": ["Z. Zhou", "Y. Wang", "J. Gu"], "venue": "Second International Conference on Future Generation Communication and Networking Symposia, 2008, vol. 1, pp. 85\u201389.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2008}, {"title": "Determining semantic similarity among entity classes from different ontologies", "author": ["M. a. Rodriguez", "M.J.J. Egenhofer"], "venue": "IEEE Trans. Knowl. Data Eng., vol. 15, no. 2, pp. 442\u2013456, Mar. 2003.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2003}, {"title": "WEST: Weighted-Edge Based Similarity Measurement Tools for Word Semantics", "author": ["L. Dong", "P.K. Srimani", "J.Z. Wang"], "venue": "IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT), 2010, vol. 1, pp. 216\u2013223.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2010}, {"title": "Joint Distance and Information Content Word Similarity Measure", "author": ["I. Atoum", "C.H. Bong"], "venue": "Soft Computing Applications and Intelligent Systems SE - 22, vol. 378, S. Noah, A. Abdullah, H. Arshad, A. Abu Bakar, Z. Othman, S. Sahran, N. Omar, and Z. Othman, Eds. Kuala Lumpur: Springer Berlin Heidelberg, 2013, pp. 257\u2013267.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2013}, {"title": "A Web Search Engine- Based Approach to Measure Semantic Similarity between Words", "author": ["D. Bollegala", "Y. Matsuo", "M. Ishizuka", "M.D. Thiyagarajan", "N. Navaneethakrishnanc"], "venue": "IEEE Trans. Knowl. Data Eng., vol. 23, no. 7, pp. 977\u2013990, Jul. 2011.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2011}, {"title": "Retrieval and Novelty Detection at the Sentence Level", "author": ["J. Allan", "C. Wade", "A. Bolivar"], "venue": "Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Informaion Retrieval, 2003, pp. 314\u2013321.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2003}, {"title": "Methods for identifying versioned and plagiarized documents", "author": ["T.C. Hoad", "J. Zobel"], "venue": "J. Am. Soc. Inf. Sci. Technol., vol. 54, no. 3, pp. 203\u2013215, 2003.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2003}, {"title": "Subjectivity word sense disambiguation", "author": ["C. Akkaya", "J. Wiebe", "R. Mihalcea"], "venue": "Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 1, 2009, pp. 190\u2013199.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2009}, {"title": "Text relatedness based on a word thesaurus", "author": ["G. Tsatsaronis", "I. Varlamis", "M. Vazirgiannis"], "venue": "J. Artif. Intell. Res., vol. 37, pp. 1\u201338, 2010.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2010}, {"title": "Explorations in context space: Words, sentences, discourse", "author": ["C. Burgess", "K. Livesay", "K. Lund"], "venue": "Discourse Process., vol. 25, no. 2\u20133, pp. 211\u2013257, 1998.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 1998}, {"title": "Latent dirichlet allocation", "author": ["D.M. Blei", "A.Y. Ng", "M.I. Jordan"], "venue": "J. Mach. Learn. Res., vol. 3, pp. 993\u20131022, Mar. 2003.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2003}, {"title": "Semantic text similarity using corpus-based word similarity and string similarity", "author": ["A. Islam", "D. Inkpen"], "venue": "ACM Trans. Knowl. Discov. from Data, vol. 2, no. 2, pp. 10:1\u2013 10:25, Jul. 2008.", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2008}, {"title": "A Syntactic Approach for Searching Similarities Within Sentences", "author": ["F. Mandreoli", "R. Martoglia", "P. Tiberio"], "venue": "Proceedings of the Eleventh International Conference on Information and Knowledge Management, 2002, pp. 635\u2013 637.  9", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2002}, {"title": "Measuring Similarity between Sentence Fragments", "author": ["G. Huang", "J. Sheng"], "venue": "4th International Conference on Intelligent Human-Machine Systems and Cybernetics, 2012, pp. 327\u2013330.", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2012}, {"title": "Exploiting Wikipedia for Directional Inferential Text Similarity", "author": ["L.C. Wee", "S. Hassan"], "venue": "Fifth International Conference on Information Technology: New Generations, 2008, pp. 686\u2013691.", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2008}, {"title": "Text similarity using google tri-grams", "author": ["A. Islam", "E. Milios", "V. Ke\u0161elj"], "venue": "Advances in Artificial Intelligence, vol. 7310, L. Kosseim and D. Inkpen, Eds. Springer, 2012, pp. 312\u2013317.", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2012}, {"title": "DeepPurple: Estimating Sentence Semantic Similarity Using N-gram Regression Models and Web Snippets", "author": ["N. Malandrakis", "E. Iosif", "A. Potamianos"], "venue": "Proceedings of the First Joint Conference on Lexical and Computational Semantics - Volume 1: Proceedings of the Main Conference and the Shared Task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation, 2012, pp. 565\u2013570.", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2012}, {"title": "An Intrinsic Information Content Metric for Semantic Similarity in WordNet", "author": ["N. Seco", "T. Veale", "J. Hayes"], "venue": "Proceedings of the 16th European Conference on Artificial Intelligence, 2004, no. Ic, pp. 1\u20135.", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2004}, {"title": "A novel sentence similarity measure for semantic-based expert systems", "author": ["M.C. Lee"], "venue": "Expert Syst. Appl., vol. 38, no. 5, pp. 6392\u20136399, 2011.", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2011}, {"title": "Short-text similarity measurement using word sense disambiguation and synonym expansion", "author": ["K. Abdalgader", "A. Skabar"], "venue": "AI 2010: Advances in Artificial Intelligence, Springer Berlin / Heidelberg, 2011, pp. 435\u2013 444.", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2010}, {"title": "A novel semantic similarity measure within sentences", "author": ["Y. Li", "H. Li", "Q. Cai", "D. Han"], "venue": "Proceedings of 2012 2nd International Conference on Computer Science and Network Technology, 2012, pp. 1176\u20131179.", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2012}, {"title": "Measuring semantic similarity in the taxonomy of WordNet", "author": ["D. Yang", "D.M.W. Powers"], "venue": "Proceedings of the Twenty-eighth Australasian conference on Computer Science - Volume 38, 2005, pp. 315\u2013322.", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2005}, {"title": "Sentence similarity based on relevance", "author": ["J. Feng", "Y. Zhou", "T. Martin"], "venue": "Proceedings of IPMU, 2008, pp. 832\u2013839.", "citeRegEx": "54", "shortCiteRegEx": null, "year": 2008}, {"title": "Sentence Similarity based on Dynamic Time Warping", "author": ["X. Liu", "Y. Zhou", "R. Zheng"], "venue": "International Conference on Semantic Computing (ICSC 2007), 2007, pp. 250\u2013256.", "citeRegEx": "55", "shortCiteRegEx": null, "year": 2007}, {"title": "Corpusbased and knowledge-based measures of text semantic similarity", "author": ["R. Mihalcea", "C. Corley", "C. Strapparava"], "venue": "Assoc. Adv. Artif. Intell., vol. 6, pp. 775\u2013780, 2006.", "citeRegEx": "56", "shortCiteRegEx": null, "year": 2006}, {"title": "Contextual correlates of synonymy", "author": ["H. Rubenstein", "J.B. Goodenough"], "venue": "Commun. ACM, vol. 8, no. 10, pp. 627\u2013633, Oct. 1965.", "citeRegEx": "57", "shortCiteRegEx": null, "year": 1965}, {"title": "Contextual correlates of semantic similarity", "author": ["G.A. Miller", "W.G. Charles"], "venue": "Lang. Cogn. Process., vol. 6, no. 1, pp. 1\u201328, 1991.", "citeRegEx": "58", "shortCiteRegEx": null, "year": 1991}, {"title": "About WordNet", "author": ["P. University"], "venue": "Princeton University, 2010. [Online]. Available: http://wordnet.princeton.edu.", "citeRegEx": "59", "shortCiteRegEx": null, "year": 2010}, {"title": "Brown corpus manual", "author": ["W.N. Francis", "H. Kucera"], "venue": "Lett. to Ed., vol. 5, no. 2, p. 7, 1979.", "citeRegEx": "60", "shortCiteRegEx": null, "year": 1979}, {"title": "Pilot Short Text Semantic Similarity Benchmark Data Set: Full Listing and Description", "author": ["J. O\u2019Shea", "Z. Bandar", "K. Crockett", "D. McLean"], "venue": "2008.", "citeRegEx": "62", "shortCiteRegEx": null, "year": 2008}, {"title": "The Google Similarity Distance", "author": ["R. Cilibrasi", "P.M.B. Vit\u00e1nyi"], "venue": "CoRR, vol. abs/cs/041, 2004.", "citeRegEx": "63", "shortCiteRegEx": null, "year": 2004}, {"title": "Text-to-text Semantic Similarity for Automatic Short Answer Grading", "author": ["M. Mohler", "R. Mihalcea"], "venue": "Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics, 2009, pp. 567\u2013575.", "citeRegEx": "64", "shortCiteRegEx": null, "year": 2009}], "referenceMentions": [{"referenceID": 0, "context": "Resnik illustrated that word similarity is a subcase of word relatedness[1].", "startOffset": 72, "endOffset": 75}, {"referenceID": 1, "context": "It has an important role in many applications such as machine translation [2], information retrieval [3]\u2013[5], word sense disambiguation [6], spell checking [7], thesauri generation [8], synonymy detection [9], and question answering [10].", "startOffset": 74, "endOffset": 77}, {"referenceID": 2, "context": "It has an important role in many applications such as machine translation [2], information retrieval [3]\u2013[5], word sense disambiguation [6], spell checking [7], thesauri generation [8], synonymy detection [9], and question answering [10].", "startOffset": 101, "endOffset": 104}, {"referenceID": 4, "context": "It has an important role in many applications such as machine translation [2], information retrieval [3]\u2013[5], word sense disambiguation [6], spell checking [7], thesauri generation [8], synonymy detection [9], and question answering [10].", "startOffset": 105, "endOffset": 108}, {"referenceID": 5, "context": "It has an important role in many applications such as machine translation [2], information retrieval [3]\u2013[5], word sense disambiguation [6], spell checking [7], thesauri generation [8], synonymy detection [9], and question answering [10].", "startOffset": 136, "endOffset": 139}, {"referenceID": 6, "context": "It has an important role in many applications such as machine translation [2], information retrieval [3]\u2013[5], word sense disambiguation [6], spell checking [7], thesauri generation [8], synonymy detection [9], and question answering [10].", "startOffset": 156, "endOffset": 159}, {"referenceID": 7, "context": "It has an important role in many applications such as machine translation [2], information retrieval [3]\u2013[5], word sense disambiguation [6], spell checking [7], thesauri generation [8], synonymy detection [9], and question answering [10].", "startOffset": 181, "endOffset": 184}, {"referenceID": 8, "context": "It has an important role in many applications such as machine translation [2], information retrieval [3]\u2013[5], word sense disambiguation [6], spell checking [7], thesauri generation [8], synonymy detection [9], and question answering [10].", "startOffset": 205, "endOffset": 208}, {"referenceID": 9, "context": "It has an important role in many applications such as machine translation [2], information retrieval [3]\u2013[5], word sense disambiguation [6], spell checking [7], thesauri generation [8], synonymy detection [9], and question answering [10].", "startOffset": 233, "endOffset": 237}, {"referenceID": 10, "context": "Furthermore, semantic similarity is also used in other domains; in medical domain to extract protein functions from biomedical literature [11] and in software quality[12]\u2013[14] to find common software attributes.", "startOffset": 138, "endOffset": 142}, {"referenceID": 11, "context": "Furthermore, semantic similarity is also used in other domains; in medical domain to extract protein functions from biomedical literature [11] and in software quality[12]\u2013[14] to find common software attributes.", "startOffset": 166, "endOffset": 170}, {"referenceID": 13, "context": "Furthermore, semantic similarity is also used in other domains; in medical domain to extract protein functions from biomedical literature [11] and in software quality[12]\u2013[14] to find common software attributes.", "startOffset": 171, "endOffset": 175}, {"referenceID": 9, "context": "In this category, Latent Semantic Analysis (LSA) [10], [15], [16], and Latent Dirichlet Allocation (LDA) [3], [17], [18] have shown positive outcomes, however they are rather domain dependent [19], [20].", "startOffset": 49, "endOffset": 53}, {"referenceID": 14, "context": "In this category, Latent Semantic Analysis (LSA) [10], [15], [16], and Latent Dirichlet Allocation (LDA) [3], [17], [18] have shown positive outcomes, however they are rather domain dependent [19], [20].", "startOffset": 55, "endOffset": 59}, {"referenceID": 15, "context": "In this category, Latent Semantic Analysis (LSA) [10], [15], [16], and Latent Dirichlet Allocation (LDA) [3], [17], [18] have shown positive outcomes, however they are rather domain dependent [19], [20].", "startOffset": 61, "endOffset": 65}, {"referenceID": 2, "context": "In this category, Latent Semantic Analysis (LSA) [10], [15], [16], and Latent Dirichlet Allocation (LDA) [3], [17], [18] have shown positive outcomes, however they are rather domain dependent [19], [20].", "startOffset": 105, "endOffset": 108}, {"referenceID": 16, "context": "In this category, Latent Semantic Analysis (LSA) [10], [15], [16], and Latent Dirichlet Allocation (LDA) [3], [17], [18] have shown positive outcomes, however they are rather domain dependent [19], [20].", "startOffset": 110, "endOffset": 114}, {"referenceID": 17, "context": "In this category, Latent Semantic Analysis (LSA) [10], [15], [16], and Latent Dirichlet Allocation (LDA) [3], [17], [18] have shown positive outcomes, however they are rather domain dependent [19], [20].", "startOffset": 116, "endOffset": 120}, {"referenceID": 18, "context": "In this category, Latent Semantic Analysis (LSA) [10], [15], [16], and Latent Dirichlet Allocation (LDA) [3], [17], [18] have shown positive outcomes, however they are rather domain dependent [19], [20].", "startOffset": 192, "endOffset": 196}, {"referenceID": 19, "context": "In this category, Latent Semantic Analysis (LSA) [10], [15], [16], and Latent Dirichlet Allocation (LDA) [3], [17], [18] have shown positive outcomes, however they are rather domain dependent [19], [20].", "startOffset": 198, "endOffset": 202}, {"referenceID": 20, "context": "Most knowledge based measures depend on WordNet[21].", "startOffset": 47, "endOffset": 51}, {"referenceID": 21, "context": "To the best of authors knowledge, there are a few works that compares sentences [22] [10].", "startOffset": 80, "endOffset": 84}, {"referenceID": 9, "context": "To the best of authors knowledge, there are a few works that compares sentences [22] [10].", "startOffset": 85, "endOffset": 89}, {"referenceID": 22, "context": "The first category of these methods is based on the information content (IC) of the least common subsumer (LCS) of compared term synsets [23]\u2013[25].", "startOffset": 137, "endOffset": 141}, {"referenceID": 24, "context": "The first category of these methods is based on the information content (IC) of the least common subsumer (LCS) of compared term synsets [23]\u2013[25].", "startOffset": 142, "endOffset": 146}, {"referenceID": 15, "context": "The distributional method, LSA similarity [16], [26] transforms text to low dimensional matrix and it finds the most common words that can appear together in the processed text.", "startOffset": 42, "endOffset": 46}, {"referenceID": 25, "context": "The distributional method, LSA similarity [16], [26] transforms text to low dimensional matrix and it finds the most common words that can appear together in the processed text.", "startOffset": 48, "endOffset": 52}, {"referenceID": 26, "context": "Classical knowledge based methods use the shortest path measure [27] , while others extend the path measure with depth of the LCS of compared words [28], [29] .", "startOffset": 64, "endOffset": 68}, {"referenceID": 27, "context": "Classical knowledge based methods use the shortest path measure [27] , while others extend the path measure with depth of the LCS of compared words [28], [29] .", "startOffset": 148, "endOffset": 152}, {"referenceID": 28, "context": "Classical knowledge based methods use the shortest path measure [27] , while others extend the path measure with depth of the LCS of compared words [28], [29] .", "startOffset": 154, "endOffset": 158}, {"referenceID": 29, "context": "Leacock Chodorow [30] proposed a similarity measure based on number of nodes in a taxonomy", "startOffset": 17, "endOffset": 21}, {"referenceID": 30, "context": "Hirst and St-Onge [31] considered all types of WordNet relations; the path length and its change in direction.", "startOffset": 18, "endOffset": 22}, {"referenceID": 22, "context": "Some methods [23]\u2013[25] have the ability to use intrinsic information rather than information content.", "startOffset": 13, "endOffset": 17}, {"referenceID": 24, "context": "Some methods [23]\u2013[25] have the ability to use intrinsic information rather than information content.", "startOffset": 18, "endOffset": 22}, {"referenceID": 31, "context": "[32] proposed a similarity measure as a function of the IC and the path length of compared words.", "startOffset": 0, "endOffset": 4}, {"referenceID": 32, "context": "Rodriguez and Egenhofer [33] used the weighted sum between synsets paths, neighboring concepts and their features in a knowledge fusion model .", "startOffset": 24, "endOffset": 28}, {"referenceID": 33, "context": "[34] proposed a weighted edge approach to give different weights of words that share the same LCS and have the same graph distance; words with lower edge weights are more similar than words with higher edge weights.", "startOffset": 0, "endOffset": 4}, {"referenceID": 34, "context": "Atoum and Bong [35] proposed a hybrid measure of distance based/knowledge based method[29] and information content method [23].", "startOffset": 15, "endOffset": 19}, {"referenceID": 28, "context": "Atoum and Bong [35] proposed a hybrid measure of distance based/knowledge based method[29] and information content method [23].", "startOffset": 86, "endOffset": 90}, {"referenceID": 22, "context": "Atoum and Bong [35] proposed a hybrid measure of distance based/knowledge based method[29] and information content method [23].", "startOffset": 122, "endOffset": 126}, {"referenceID": 8, "context": "[9] used a measure called Point-Wise Mutual Information and Information Retrieval (PMI-IR) that is based on the number of hits returned by a web search engine.", "startOffset": 0, "endOffset": 3}, {"referenceID": 35, "context": "[36] used a WordNet metric and Support Vector Machines on text snippets returned by a Web search engine to learn semantically related and unrelated words.", "startOffset": 0, "endOffset": 4}, {"referenceID": 36, "context": "The first category, traditional information retrieval methods, Term Frequency \u2013Inverse Document Frequency (TF-IDF) methods [37]\u2013[39], assume that documents have common words.", "startOffset": 123, "endOffset": 127}, {"referenceID": 38, "context": "The first category, traditional information retrieval methods, Term Frequency \u2013Inverse Document Frequency (TF-IDF) methods [37]\u2013[39], assume that documents have common words.", "startOffset": 128, "endOffset": 132}, {"referenceID": 28, "context": "However, these methods are not valid for sentences because sentences may have null common words[29], [40] .", "startOffset": 95, "endOffset": 99}, {"referenceID": 39, "context": "However, these methods are not valid for sentences because sentences may have null common words[29], [40] .", "startOffset": 101, "endOffset": 105}, {"referenceID": 9, "context": "They model words cooccurrences as vectors of semantic features; LSA[10][16][26], Hyperspace Analogues to Language (HAL) [41], and LDA [7] [17][18][45].", "startOffset": 67, "endOffset": 71}, {"referenceID": 15, "context": "They model words cooccurrences as vectors of semantic features; LSA[10][16][26], Hyperspace Analogues to Language (HAL) [41], and LDA [7] [17][18][45].", "startOffset": 71, "endOffset": 75}, {"referenceID": 25, "context": "They model words cooccurrences as vectors of semantic features; LSA[10][16][26], Hyperspace Analogues to Language (HAL) [41], and LDA [7] [17][18][45].", "startOffset": 75, "endOffset": 79}, {"referenceID": 40, "context": "They model words cooccurrences as vectors of semantic features; LSA[10][16][26], Hyperspace Analogues to Language (HAL) [41], and LDA [7] [17][18][45].", "startOffset": 120, "endOffset": 124}, {"referenceID": 6, "context": "They model words cooccurrences as vectors of semantic features; LSA[10][16][26], Hyperspace Analogues to Language (HAL) [41], and LDA [7] [17][18][45].", "startOffset": 134, "endOffset": 137}, {"referenceID": 16, "context": "They model words cooccurrences as vectors of semantic features; LSA[10][16][26], Hyperspace Analogues to Language (HAL) [41], and LDA [7] [17][18][45].", "startOffset": 138, "endOffset": 142}, {"referenceID": 17, "context": "They model words cooccurrences as vectors of semantic features; LSA[10][16][26], Hyperspace Analogues to Language (HAL) [41], and LDA [7] [17][18][45].", "startOffset": 142, "endOffset": 146}, {"referenceID": 44, "context": "They model words cooccurrences as vectors of semantic features; LSA[10][16][26], Hyperspace Analogues to Language (HAL) [41], and LDA [7] [17][18][45].", "startOffset": 146, "endOffset": 150}, {"referenceID": 42, "context": "The third category, string similarity methods (mini corpus based methods) depend on strings edit distance and the word order in a sentence [43]\u2013[45].", "startOffset": 139, "endOffset": 143}, {"referenceID": 44, "context": "The third category, string similarity methods (mini corpus based methods) depend on strings edit distance and the word order in a sentence [43]\u2013[45].", "startOffset": 144, "endOffset": 148}, {"referenceID": 45, "context": "They use the internet resources as their baseline; Wikipedia [46], Google Tri-grams[6][47] , and search engine documents [48].", "startOffset": 61, "endOffset": 65}, {"referenceID": 5, "context": "They use the internet resources as their baseline; Wikipedia [46], Google Tri-grams[6][47] , and search engine documents [48].", "startOffset": 83, "endOffset": 86}, {"referenceID": 46, "context": "They use the internet resources as their baseline; Wikipedia [46], Google Tri-grams[6][47] , and search engine documents [48].", "startOffset": 86, "endOffset": 90}, {"referenceID": 47, "context": "They use the internet resources as their baseline; Wikipedia [46], Google Tri-grams[6][47] , and search engine documents [48].", "startOffset": 121, "endOffset": 125}, {"referenceID": 18, "context": "Corpus based methods (second and fourth category) suffer from these problems; once the vector space model is built for a domain it can be hardly used in another domain [19].", "startOffset": 168, "endOffset": 172}, {"referenceID": 19, "context": "They also have the problem of high sparse vectors especially for short sentences and generally they are not practical [20].", "startOffset": 118, "endOffset": 122}, {"referenceID": 30, "context": "2 Knowledge based Methods knowledge based methods use semantic dictionary information such word relationships [31][40][49], information content [1], [23] to get word semantic features.", "startOffset": 110, "endOffset": 114}, {"referenceID": 39, "context": "2 Knowledge based Methods knowledge based methods use semantic dictionary information such word relationships [31][40][49], information content [1], [23] to get word semantic features.", "startOffset": 114, "endOffset": 118}, {"referenceID": 48, "context": "2 Knowledge based Methods knowledge based methods use semantic dictionary information such word relationships [31][40][49], information content [1], [23] to get word semantic features.", "startOffset": 118, "endOffset": 122}, {"referenceID": 0, "context": "2 Knowledge based Methods knowledge based methods use semantic dictionary information such word relationships [31][40][49], information content [1], [23] to get word semantic features.", "startOffset": 144, "endOffset": 147}, {"referenceID": 22, "context": "2 Knowledge based Methods knowledge based methods use semantic dictionary information such word relationships [31][40][49], information content [1], [23] to get word semantic features.", "startOffset": 149, "endOffset": 153}, {"referenceID": 19, "context": "[20] proposed a sentence similarity based on the aspects that a human interprets sentences; objects the sentence describes, properties of these objects and behaviors of these objects.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "[19] proposed sentence similarity based on WordNet IC and part of speech tree kernels.", "startOffset": 0, "endOffset": 4}, {"referenceID": 44, "context": "Huang and Sheng [45] proposed a sentence similarity measure for paraphrase recognition and text entailment based on WordNet IC and string edit distance.", "startOffset": 16, "endOffset": 20}, {"referenceID": 49, "context": "Lee [50] built semantic vectors from WordNet information and part of speech tags.", "startOffset": 4, "endOffset": 8}, {"referenceID": 50, "context": "Abdalgader and Skabar [51] proposed a sentence similarity measure based on word sense disambiguation and the WordNet synonym expansion.", "startOffset": 22, "endOffset": 26}, {"referenceID": 39, "context": "[40] measured the semantic relatedness between compared texts based on their implicit semantic links extracted from a thesaurus.", "startOffset": 0, "endOffset": 4}, {"referenceID": 51, "context": "[52] proposed a sentence similarity measure based on word and verb vectors and the words order.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "[4] applied their measure on photographic description data based semantic vectors of path and term frequency.", "startOffset": 0, "endOffset": 3}, {"referenceID": 28, "context": "[29] proposed a sentence similarity based on WordNet information, IC of Brown Corpus, and sentence words orders.", "startOffset": 0, "endOffset": 4}, {"referenceID": 51, "context": "Later, [52] proposed a word similarity based on a new information content formula and Lin word similarity[23].", "startOffset": 7, "endOffset": 11}, {"referenceID": 22, "context": "Later, [52] proposed a word similarity based on a new information content formula and Lin word similarity[23].", "startOffset": 105, "endOffset": 109}, {"referenceID": 5, "context": "[6] incorporated a modified version of word sense disambiguation of [53] in their similarity measure.", "startOffset": 0, "endOffset": 3}, {"referenceID": 52, "context": "[6] incorporated a modified version of word sense disambiguation of [53] in their similarity measure.", "startOffset": 68, "endOffset": 72}, {"referenceID": 53, "context": "[54] used direct( words relationships) and indirect (reasoning) relevance between sentences to estimate sentence similarity.", "startOffset": 0, "endOffset": 4}, {"referenceID": 54, "context": "[55] proposed a sentence similarity based on Dynamic Time Wrapping (DTW) approach.", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "[6] showed that DTW is computationally costly and time proportionately with the sentence\u2019s length.", "startOffset": 0, "endOffset": 3}, {"referenceID": 38, "context": "A combination of eight knowledge base measures and three corpus based measures is proposed in [39], [56].", "startOffset": 94, "endOffset": 98}, {"referenceID": 55, "context": "A combination of eight knowledge base measures and three corpus based measures is proposed in [39], [56].", "startOffset": 100, "endOffset": 104}, {"referenceID": 56, "context": "1 Word Similarity Methods To evaluate the performance of word similarity methods, the Rubenstein Goodenough[57] and Miller Charles[58] word pairs benchmark datasets are selected.", "startOffset": 107, "endOffset": 111}, {"referenceID": 57, "context": "1 Word Similarity Methods To evaluate the performance of word similarity methods, the Rubenstein Goodenough[57] and Miller Charles[58] word pairs benchmark datasets are selected.", "startOffset": 130, "endOffset": 134}, {"referenceID": 58, "context": "0 [59] for knowledge based measures and Brown Dictionary [60] for corpus based measures.", "startOffset": 2, "endOffset": 6}, {"referenceID": 59, "context": "0 [59] for knowledge based measures and Brown Dictionary [60] for corpus based measures.", "startOffset": 57, "endOffset": 61}, {"referenceID": 28, "context": "2 Sentence Similarity Methods To evaluate the performance of the sentence similarity methods, the dataset constructed by [29] ( the STSS-65 dataset) is selected.", "startOffset": 121, "endOffset": 125}, {"referenceID": 56, "context": "In STSS-65 dataset, the corresponding words in [57] are replaced with the words definitions from the Collins Cobuild Dictionary [61].", "startOffset": 47, "endOffset": 51}, {"referenceID": 28, "context": "[29] decided to keep only the most accurate annotated and balanced sentence pairs.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": ", [4], [29], [50].", "startOffset": 2, "endOffset": 5}, {"referenceID": 28, "context": ", [4], [29], [50].", "startOffset": 7, "endOffset": 11}, {"referenceID": 49, "context": ", [4], [29], [50].", "startOffset": 13, "endOffset": 17}, {"referenceID": 28, "context": "13 was first used in the main work of [29], but later [62] published the dataset on 2009 with the figure 0.", "startOffset": 38, "endOffset": 42}, {"referenceID": 60, "context": "13 was first used in the main work of [29], but later [62] published the dataset on 2009 with the figure 0.", "startOffset": 54, "endOffset": 58}, {"referenceID": 28, "context": "13 figure is used in this article as first used by the original work of [29].", "startOffset": 72, "endOffset": 76}, {"referenceID": 10, "context": "For Mihalcea [11] measure the PMI-IR measure is replaced with Normalized Search engine Index Distance (NSID) [63] as Turner 's PMI is not available.", "startOffset": 13, "endOffset": 17}, {"referenceID": 61, "context": "For Mihalcea [11] measure the PMI-IR measure is replaced with Normalized Search engine Index Distance (NSID) [63] as Turner 's PMI is not available.", "startOffset": 109, "endOffset": 113}, {"referenceID": 49, "context": "Ming Che Lee 2011[50] 0.", "startOffset": 17, "endOffset": 21}, {"referenceID": 38, "context": "2009 [39] 0.", "startOffset": 5, "endOffset": 9}, {"referenceID": 53, "context": "2008 [54] 0.", "startOffset": 5, "endOffset": 9}, {"referenceID": 3, "context": "2013 (LSS) [4] 0.", "startOffset": 11, "endOffset": 14}, {"referenceID": 28, "context": "2006(STASIS)[29] 0.", "startOffset": 12, "endOffset": 16}, {"referenceID": 9, "context": "2008 (LSA)[10] 0.", "startOffset": 10, "endOffset": 14}, {"referenceID": 54, "context": "2007 [55] 0.", "startOffset": 5, "endOffset": 9}, {"referenceID": 42, "context": "2008 [43] 0.", "startOffset": 5, "endOffset": 9}, {"referenceID": 39, "context": "Tsatsaronis et al 2010 (Omiotis)[40] 0.", "startOffset": 32, "endOffset": 36}, {"referenceID": 5, "context": "2010 (SPDSTS)[6] 0.", "startOffset": 13, "endOffset": 16}, {"referenceID": 46, "context": "2012(TriGrams) [47] 0.", "startOffset": 15, "endOffset": 19}, {"referenceID": 49, "context": "Table 2 shows that Ming [50] and Mihalcea measures have the lowest Pearson and Spearman Coefficients.", "startOffset": 24, "endOffset": 28}, {"referenceID": 10, "context": "To investigate this result, Mihalcea [11] is taken as an example.", "startOffset": 37, "endOffset": 41}, {"referenceID": 5, "context": "[6] findings.", "startOffset": 0, "endOffset": 3}, {"referenceID": 46, "context": "Many sentence similarity approaches have been proposed but many of them might be difficult to implement[47], [64] or has poor performance[4], [50], [54], [64] .", "startOffset": 103, "endOffset": 107}, {"referenceID": 62, "context": "Many sentence similarity approaches have been proposed but many of them might be difficult to implement[47], [64] or has poor performance[4], [50], [54], [64] .", "startOffset": 109, "endOffset": 113}, {"referenceID": 3, "context": "Many sentence similarity approaches have been proposed but many of them might be difficult to implement[47], [64] or has poor performance[4], [50], [54], [64] .", "startOffset": 137, "endOffset": 140}, {"referenceID": 49, "context": "Many sentence similarity approaches have been proposed but many of them might be difficult to implement[47], [64] or has poor performance[4], [50], [54], [64] .", "startOffset": 142, "endOffset": 146}, {"referenceID": 53, "context": "Many sentence similarity approaches have been proposed but many of them might be difficult to implement[47], [64] or has poor performance[4], [50], [54], [64] .", "startOffset": 148, "endOffset": 152}, {"referenceID": 62, "context": "Many sentence similarity approaches have been proposed but many of them might be difficult to implement[47], [64] or has poor performance[4], [50], [54], [64] .", "startOffset": 154, "endOffset": 158}, {"referenceID": 38, "context": "For example the works of [39], [56] are based on 8 different knowledge based measures and 3 corpus based measures which makes their implementation difficult.", "startOffset": 25, "endOffset": 29}, {"referenceID": 55, "context": "For example the works of [39], [56] are based on 8 different knowledge based measures and 3 corpus based measures which makes their implementation difficult.", "startOffset": 31, "endOffset": 35}, {"referenceID": 46, "context": "Further difficulties in other works includes the need of processing gigantic data processing [47].", "startOffset": 93, "endOffset": 97}, {"referenceID": 46, "context": "[47] used the Web 1T 5-gram dataset; a compressed text file of approximately 24 GB compressed composed of more than 1 million tri-grams extracted from 1 trillion tokens.", "startOffset": 0, "endOffset": 4}, {"referenceID": 46, "context": "Nevertheless, [47] [10] are considered comprehensive datasets and can be accessed easily once indexed.", "startOffset": 14, "endOffset": 18}, {"referenceID": 9, "context": "Nevertheless, [47] [10] are considered comprehensive datasets and can be accessed easily once indexed.", "startOffset": 19, "endOffset": 23}, {"referenceID": 5, "context": "[6], [55], [40]) perform better than knowledge based (e.", "startOffset": 0, "endOffset": 3}, {"referenceID": 54, "context": "[6], [55], [40]) perform better than knowledge based (e.", "startOffset": 5, "endOffset": 9}, {"referenceID": 39, "context": "[6], [55], [40]) perform better than knowledge based (e.", "startOffset": 11, "endOffset": 15}, {"referenceID": 28, "context": "[29]) and corpus based (e.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "[10]) methods.", "startOffset": 0, "endOffset": 4}, {"referenceID": 46, "context": "Tri-gram measure [47] is an exception.", "startOffset": 17, "endOffset": 21}, {"referenceID": 46, "context": "It is found that [47] overestimates the human rating scores especially the dissimilar sentence pairs.", "startOffset": 17, "endOffset": 21}, {"referenceID": 46, "context": "Figure 4 shows the STS-65 dataset human scores versus the scores of [47] and [40].", "startOffset": 68, "endOffset": 72}, {"referenceID": 39, "context": "Figure 4 shows the STS-65 dataset human scores versus the scores of [47] and [40].", "startOffset": 77, "endOffset": 81}, {"referenceID": 46, "context": "It is clear that [47] overestimates sentence pairs 1-29(30% of the original dataset).", "startOffset": 17, "endOffset": 21}, {"referenceID": 39, "context": "On the other hand, although [40] has less Pearson correlation, as shown in Figure 3, it is relatively better than [47] in sentence pairs 1-29.", "startOffset": 28, "endOffset": 32}, {"referenceID": 46, "context": "On the other hand, although [40] has less Pearson correlation, as shown in Figure 3, it is relatively better than [47] in sentence pairs 1-29.", "startOffset": 114, "endOffset": 118}, {"referenceID": 49, "context": "8 1 Worst Human Participant Ming Che Lee 2011[50] Mihalcea et al.", "startOffset": 45, "endOffset": 49}, {"referenceID": 38, "context": "2009 [39] Feng et al.", "startOffset": 5, "endOffset": 9}, {"referenceID": 53, "context": "2008 [54] Croft et al.", "startOffset": 5, "endOffset": 9}, {"referenceID": 3, "context": "2013 (LSS) [4] Li et al.", "startOffset": 11, "endOffset": 14}, {"referenceID": 28, "context": "2006(STASIS)[29] Human Participants Means O\u2019shea et al.", "startOffset": 12, "endOffset": 16}, {"referenceID": 9, "context": "2008 (LSA)[10] Liu et al.", "startOffset": 10, "endOffset": 14}, {"referenceID": 54, "context": "2007 [55] Islam et al.", "startOffset": 5, "endOffset": 9}, {"referenceID": 42, "context": "2008 [43] Tsatsaronis et al 2010 [40] Ho et al.", "startOffset": 5, "endOffset": 9}, {"referenceID": 39, "context": "2008 [43] Tsatsaronis et al 2010 [40] Ho et al.", "startOffset": 33, "endOffset": 37}, {"referenceID": 5, "context": "2010 [6] Islam et al.", "startOffset": 5, "endOffset": 8}, {"referenceID": 46, "context": "2012 [47] Pearson Correlation", "startOffset": 5, "endOffset": 9}, {"referenceID": 46, "context": "Corresponding Sentence pairs [47] [40]", "startOffset": 29, "endOffset": 33}, {"referenceID": 39, "context": "Corresponding Sentence pairs [47] [40]", "startOffset": 34, "endOffset": 38}], "year": 2016, "abstractText": "Sentence similarity is considered the basis of many natural language tasks such as information retrieval, question answering and text summarization. The semantic meaning between compared text fragments is based on the words\u2019 semantic features and their relationships. This article reviews a set of word and sentence similarity measures and compares them on benchmark datasets. On the studied datasets, results showed that hybrid semantic measures perform better than both knowledge and corpus based measures. General Terms Semantic Similarity, Natural Language Processing, Computational Linguistics, Text Similarity", "creator": "Microsoft\u00ae Word 2013"}}}