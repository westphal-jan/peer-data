{"id": "1610.05556", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Oct-2016", "title": "Identifiability and Transportability in Dynamic Causal Networks", "abstract": "In this paper we propose a causal analog to the purely observational Dynamic Bayesian Networks, which we call Dynamic Causal Networks. We provide a sound and complete algorithm for identification of Dynamic Causal Net- works, namely, for computing the effect of an intervention or experiment, based on passive observations only, whenever possible. We note the existence of two types of confounder variables that affect in substantially different ways the iden- tification procedures, a distinction with no analog in either Dynamic Bayesian Networks or standard causal graphs. We further propose a procedure for the transportability of causal effects in Dynamic Causal Network settings, where the re- sult of causal experiments in a source domain may be used for the identification of causal effects in a target domain.", "histories": [["v1", "Tue, 18 Oct 2016 12:07:03 GMT  (157kb,D)", "http://arxiv.org/abs/1610.05556v1", "Presented at the 2016 ACM SIGKDD Workshop on Causal Discovery"]], "COMMENTS": "Presented at the 2016 ACM SIGKDD Workshop on Causal Discovery", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["gilles blondel", "marta arias", "ricard gavald\\`a"], "accepted": false, "id": "1610.05556"}, "pdf": {"name": "1610.05556.pdf", "metadata": {"source": "CRF", "title": "Identifiability and Transportability in Dynamic Causal Networks", "authors": ["Gilles Blondel", "Ricard Gavald\u00e0"], "emails": ["gillesblondel@yahoo.com", "marias@cs.upc.edu", "gavalda@cs.upc.edu"], "sections": [{"heading": null, "text": "Keywords Causal Analysis \u00b7 Dynamic Modelling"}, {"heading": "1 Introduction", "text": "This year, it will be able to enlighten the aforementioned brain-consecrated brain-consecrated brain-consecrated brain-consecrated brain-consecrated brain-consecrated brain-consecrated brain-tecsrteeeenrsrteeeaeFnln."}, {"heading": "2 Previous Definitions and Results", "text": "In this section, we review the definitions and basic results of the three existing concepts that form the basis of our work: DBN, causal networks and causal systems. It's not just the way we move, but also the way we move. (It's not the way we move), but the way we move. (It's the way we move.) \"We say that a probability distribution P is time-invariant if it develops over time. (It's the way we move.) (It's the way we move.\") It's the way we move. \"We say that a probability distribution P is time-invariant if P (Vt + 1 | Vt) is the same way we move.\" (It's the way we move. \")"}, {"heading": "3 Dynamic Causal Networks and Do-Calculus", "text": "In this section we present the most important definitions of this paper and the state of several lemmas based on the application of the Dokalus rules to DCN.In definition 3 of the causal model, the functions fk are not specified and can take any appropriate form that best describes the causal dependencies between the variables in the model. However, in natural appearance, some variables may be time independent, while others may evolve over time. In definition 4 (Dynamic causal networks), the definition of the Dynamic causal network is an extension of Pearl's causal model in definition 3, specifying that the variables are compressed over time, as in [32].Definition 4 (Dynamic causal networks) is a dynamic causal model in which the causal models are set so that Vk, t = fk (pa, t), Uk, t \u2212 cepts in which the variable is linked to time."}, {"heading": "4 Identifiability in Dynamic Causal Networks", "text": "In this section, we will analyze the identifiability of causal effects in the DCN setting. We will first examine DCNs with static confounders and propose a method for identifying causal effects in DCNs. Then, we will expand the analysis and identification method to DCNs with dynamic confounders. As discussed in Section 3, both the DCNs with static confounders and the dynamic confounders can be represented as a Markov chain. For graphical and notational simplicity, we will graphically represent these DCN as recurring time periods, which are in contrast to the shorter time samples, on the basis that a time period contains as many time samples as the maximum delay of causal influences among processes. Also, for notational simplicity, we assume that the transition matrix from one time span to the next time period will be timely variant; however, removing this limitation would not render any of the lemmas, theorems, or algorithms invalid, as they are not a parambiguous result."}, {"heading": "4.1.1 DCN-ID Algorithm for DCNs with Static Confounders", "text": "The DCN ID algorithms for DCNs with static confounders can be found in Figure 4 (b) (b). Their solidity is directly from theorem 1, the solidity of the VCN algorithm [2], and Lemma 2.Theorem 2 (G), if DCN ID returns a distribution for P (Y | do (X), it is correct. utObserve that line 2 of the algorithm can call identification with a diagram of size 4, this is two calls, but in this case we cannot spare the call for the \"denominator\" P (Vtx \u2212 1), because Lemma 1 guarantees that P (X) can perform a dynamic distribution (X) = P (Vtx \u2212 1). We calculate transition matrix A on line 3 has complexity O (4k) (b + 2), where k is the number of variables in a time and the number of variable bits."}, {"heading": "4.2.1 DCN-ID Algorithm for DCNs with Dynamic Confounders", "text": "Function DCN-ID (Y, X, tx, G, C, C, C, V, T, P (Vt0)) INPUT: - DCN defined by a causal graph G on a set of variables V and a set C V \u00b7 V describing causal relations from Vt to Vt + 1 for each t, and a set C \u2032 V \u00b7 V, the confounder relations from Vt to Vt \u2212 \u2212 n for each t - transition matrix T for G derived observation data - a set Y contained in Vty - a set X contained in Vtx - distribution P (Vt0) in the initial state, OUTPUT: The distribution P (Y \u2212 do (X)) - or else FAIL1. Let us form the acyclic graph by giving Gtx \u2212 2, Gtx \u2212 1, and Gtx + 1 through the causal relationships given by C and confounders."}, {"heading": "5 Complete DCN Identifiability", "text": "In this section, we show that the identification algorithms as formulated in the previous sections are not complete, and that we are developing complete algorithms for the complete identification of DCNs. (D) It is therefore the absence of a structure called a \"hedge\" in the graph. (D) We must first define some graphical structures that lead to the definition of hedges. (D) The definition of DCN and C component of D. If all variables in C have a child, then C forest is called. (D) The set of variables in C forest that have no ancestry, and the C component of D. (D component). (D component) We have all variables in C forest, then C forest is called. (R variables in C forest that have no ancestry, and the C component is called. (D component in C forest)"}, {"heading": "6 Transportability in DCN", "text": "The impact of transport policy on routes in different countries is different. (The impact on routes in the destination regions can be derived from experimental results in one source domain and some observations in the destination domain, thus avoiding the need to conduct an experiment in the destination domain.) Consider a country with a number of alternative transport bets in different provinces. Suppose that the alternative roads are all in line with the same causal model (e.g. Figure 3), but have different traffic patterns (share of cars / trucks, tolls, durability of traffic routes). Transport authorities in one of the provinces may have experimented and have had an impact on, say, traffic delays. This information can be used to predict the average travel delay in another province for a particular transport policy, the source domain (province where the effects of transport policy have already been monitored) and to share the objectives between regions."}, {"heading": "7 Experiments", "text": "In this section we present some numerical examples of causal effects identifiability in DCN = 0.0 0.4 0.0 0.3 0.0 0.0 0.2 0.0 0.2 0.0 0.0 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 (1, 2, 2, 2). There are two roads and drivers choose every day to use one or the other road. For simplicity we assume that the variables will be tr1, tr2 and d respectively binary. Suppose that from Monday to Friday the common distribution of the variables of the transition matrix T1 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0, 0.5 0.5 0.5 0.5 0.0, 0.0 0.0 0.0 0.0, 0.5 0.0 0.0 0.0 0.0, 0.5 0.0 0.0 0.0 0.0, 0.0 0.4 0.4, 0.4 0.4, 0.4 0.4 0.4, 0.4 0.4, 0.4 0.4, 0.4, 0.4 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4 0.4, 0.4, 0.4 0.4, 0.4, 0.4, 0.4 0.4, 0.4 0.4 0.4, 0.4, 0.4 0.4, 0.4 0.4, 0.4 0.4 0.4, 0.4 0.4 0.4, 0.4 0.4, 0 0.4, 0 0.4, 0 0.4, 0 0.0 0.4, 0 0.0 0.0 0.0 0.0 0.0 0.0, 0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0."}, {"heading": "8 Conclusions and Future Work", "text": "We extend the ID algorithm to the identification of DCNs and point out the difference between static and dynamic confounders. We also provide an algorithm for the transportability of causal effects from one domain to another with the same dynamic causal structure. Note that in the present work we have assumed that all the variables intervened are within the same time span; the removal of this restriction may be of moderate interest. We would also like to extend the introduction of causal analysis to a number of dynamic contexts, including Hidden Markov models and study properties of DCNs in relation to Markov chains (e.g. conditions of occupational health). Finally, the evaluation of the distribution returned by ID is generally impracticable (exponential in the number of variables and domain size); the identification of detectable failures or feasible hayritics is a general question within the framework of Project 857 MAX 2014."}], "references": [{"title": "in Proceedings of the National Conference on Artificial Intelligence, vol", "author": ["I. Shpitser", "J. Pearl"], "venue": "21 (Menlo Park, CA; Cambridge, MA; London; AAAI Press; MIT Press;", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1999}, {"title": "in Proceedings of the National Conference on Artificial Intelligence, vol", "author": ["Y. Huang", "M. Valtorta"], "venue": "21 (Menlo Park, CA; Cambridge, MA; London; AAAI Press; MIT Press;", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1999}, {"title": "Simon, in Readings in qualitative reasoning about physical systems", "author": ["H.A.Y. Iwasaki"], "venue": "(Morgan Kaufmann Publishers Inc.,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1989}, {"title": "Information-based methods for neuroimaging: analyzing structure, function and dynamics", "author": ["D. Chicharro", "S. Panzeri"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2015}, {"title": "Symbolic and Quantitative Approaches to Reasoning with Uncertainty (Springer", "author": ["D. Dash", "M. Druzdzel"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2001}, {"title": "Causality: statistical perspectives and applications", "author": ["M. Eichler"], "venue": "Wiley, Chichester pp", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2012}, {"title": "Studies in causal reasoning and learning", "author": ["J. Tian"], "venue": "Ph.D. thesis,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2002}, {"title": "Knowledge and Data Engineering", "author": ["S.J. Pan", "Q. Yang"], "venue": "IEEE Transactions on 22(10),", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2010}, {"title": "Causality: models, reasoning and inference, vol", "author": ["J. Pearl"], "venue": "29 (Cambridge Univ Press,", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2000}, {"title": "On the identification of causal effects", "author": ["J. Tian", "J. Pearl"], "venue": "Tech. rep., Department of Computer Science,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2002}, {"title": "T", "author": ["J. Pearl"], "venue": "Verma, et al., A theory of inferred causation (Morgan Kaufmann San Mateo, CA,", "citeRegEx": "33", "shortCiteRegEx": null, "year": 1991}], "referenceMentions": [{"referenceID": 0, "context": "[2,3] showed that a do-expression is identifiable if and only if it can be rewritten in this way with a finite number of applications of the three rules of docalculus, and [2] proposed the ID algorithm which performs this transformation if at all possible, or else returns fail indicating non-identifiability.", "startOffset": 0, "endOffset": 5}, {"referenceID": 1, "context": "[2,3] showed that a do-expression is identifiable if and only if it can be rewritten in this way with a finite number of applications of the three rules of docalculus, and [2] proposed the ID algorithm which performs this transformation if at all possible, or else returns fail indicating non-identifiability.", "startOffset": 0, "endOffset": 5}, {"referenceID": 0, "context": "[2,3] showed that a do-expression is identifiable if and only if it can be rewritten in this way with a finite number of applications of the three rules of docalculus, and [2] proposed the ID algorithm which performs this transformation if at all possible, or else returns fail indicating non-identifiability.", "startOffset": 172, "endOffset": 175}, {"referenceID": 2, "context": "Regarding the discovery of causal models in dynamic systems [4] and [5] propose an algorithm to establish an ordering of the variables corresponding to the temporal order of propagation of causal effects.", "startOffset": 60, "endOffset": 63}, {"referenceID": 3, "context": "Existing algorithms for causal discovery from static data have been extended to the dynamic setting by [8] and [9].", "startOffset": 111, "endOffset": 114}, {"referenceID": 4, "context": "However [13] [14] [15] show the caveats of causal discovery of dynamic models based on differential equations which pass through equilibrium states, and how causal reasoning based on such models may fail.", "startOffset": 13, "endOffset": 17}, {"referenceID": 5, "context": "Regarding causal reasoning given a dynamic causal model, one line of research is based on time series and granger causality concepts [19,20,21].", "startOffset": 133, "endOffset": 143}, {"referenceID": 5, "context": "[19,20,21] discuss back-door and front-door criteria in timeseries but do not extend to the full power of do-calculus as a complete logic for causal identification.", "startOffset": 0, "endOffset": 10}, {"referenceID": 6, "context": "\u2013 We extend causal identification algorithms [25,2,26] to the identifiability of causal effects in DCN settings.", "startOffset": 45, "endOffset": 54}, {"referenceID": 0, "context": "\u2013 We extend causal identification algorithms [25,2,26] to the identifiability of causal effects in DCN settings.", "startOffset": 45, "endOffset": 54}, {"referenceID": 7, "context": "This opens the way to studying relational knowledge transfer learning [28] of causal information in domains with a time component.", "startOffset": 70, "endOffset": 74}, {"referenceID": 8, "context": "The notation used in our paper is based on causal models and do-calculus [1,29].", "startOffset": 73, "endOffset": 79}, {"referenceID": 0, "context": "Do-calculus was proven to be complete [2,3] in the sense that if an expression cannot be converted into a do-free one by iterative application of the three do-calculus rules, then it is not identifiable.", "startOffset": 38, "endOffset": 43}, {"referenceID": 1, "context": "Do-calculus was proven to be complete [2,3] in the sense that if an expression cannot be converted into a do-free one by iterative application of the three do-calculus rules, then it is not identifiable.", "startOffset": 38, "endOffset": 43}, {"referenceID": 0, "context": "The ID algorithm [2], and earlier versions by [30,31] implement an iterative application of do-calculus rules to transform a causal expressionP (Y |do(X)) into an equivalent expression without any do() terms in semi-Markovian causal", "startOffset": 17, "endOffset": 20}, {"referenceID": 9, "context": "The ID algorithm [2], and earlier versions by [30,31] implement an iterative application of do-calculus rules to transform a causal expressionP (Y |do(X)) into an equivalent expression without any do() terms in semi-Markovian causal", "startOffset": 46, "endOffset": 53}, {"referenceID": 0, "context": "The ID algorithm is sound and complete [2] in the sense that if a do-free equivalent expression exists it will be found by the algorithm, and if it does not exist the algorithm will exit and provide an error.", "startOffset": 39, "endOffset": 42}, {"referenceID": 0, "context": "The expressionP (Y |Z, do(X)) is thus identifiable if and only if both P (Y,Z|do(X)) and P (Z|do(X)) are [2].", "startOffset": 105, "endOffset": 108}, {"referenceID": 10, "context": "To represent unobserved confounders in DCN, we extend to the dynamic context the framework developed in [33] on causal model equivalence and latent structure projections.", "startOffset": 104, "endOffset": 108}, {"referenceID": 0, "context": "Proof The first equality derives from rule 3 and the proof in [2] that interventions on variables which are not ancestors of Y in D have no effect on Y .", "startOffset": 62, "endOffset": 65}, {"referenceID": 6, "context": "Proof (sketch) By C-component factorization [25], we decompose the problem as that of identification of each Ccomponent in D and (if all C-components are identifiable) multiplying all identified quantities to obtain P (Y |do(X)).", "startOffset": 44, "endOffset": 48}, {"referenceID": 0, "context": "An identifiable C-component is computed as the product of P (vi|V i\u22121 \u03c0 ) for each variable vi in the C-component, where V i\u22121 \u03c0 is the set of all variables preceding vi in some topological ordering \u03c0 [2,25].", "startOffset": 201, "endOffset": 207}, {"referenceID": 6, "context": "An identifiable C-component is computed as the product of P (vi|V i\u22121 \u03c0 ) for each variable vi in the C-component, where V i\u22121 \u03c0 is the set of all variables preceding vi in some topological ordering \u03c0 [2,25].", "startOffset": 201, "endOffset": 207}, {"referenceID": 0, "context": "Its soundness is immediate from Theorem 1, the soundness of the ID algorithm [2], and Lemma 2.", "startOffset": 77, "endOffset": 80}, {"referenceID": 0, "context": "Its soundness is immediate from Theorem 3, the soundness of the ID algorithm [2], and Lemma 2.", "startOffset": 77, "endOffset": 80}, {"referenceID": 0, "context": "To prove completeness we use previous results [2].", "startOffset": 46, "endOffset": 49}, {"referenceID": 0, "context": "The presence of a hedge prevents the identifiability of causal graphs [2].", "startOffset": 70, "endOffset": 73}, {"referenceID": 7, "context": "This amounts to relational knowledge transfer learning between the two domains [28].", "startOffset": 79, "endOffset": 83}], "year": 2016, "abstractText": "In this paper we propose a causal analog to the purely observational Dynamic Bayesian Networks, which we call Dynamic Causal Networks. We provide a sound and complete algorithm for identification of Dynamic Causal Networks, namely, for computing the effect of an intervention or experiment, based on passive observations only, whenever possible. We note the existence of two types of confounder variables that affect in substantially different ways the identification procedures, a distinction with no analog in either Dynamic Bayesian Networks or standard causal graphs. We further propose a procedure for the transportability of causal effects in Dynamic Causal Network settings, where the result of causal experiments in a source domain may be used for the identification of causal effects in a target domain.", "creator": "LaTeX with hyperref package"}}}