{"id": "1610.05815", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Oct-2016", "title": "Statistical Learning Theory Approach for Data Classification with l-diversity", "abstract": "Corporations are retaining ever-larger corpuses of personal data; the frequency or breaches and corresponding privacy impact have been rising accordingly. One way to mitigate this risk is through use of anonymized data, limiting the exposure of individual data to only where it is absolutely needed. This would seem particularly appropriate for data mining, where the goal is generalizable knowledge rather than data on specific individuals. In practice, corporate data miners often insist on original data, for fear that they might \"miss something\" with anonymized or differentially private approaches. This paper provides a theoretical justification for the use of anonymized data. Specifically, we show that a support vector classifier trained on anatomized data satisfying l-diversity should be expected to do as well as on the original data. Anatomy preserves all data values, but introduces uncertainty in the mapping between identifying and sensitive values, thus satisfying l-diversity. The theoretical effectiveness of the proposed approach is validated using several publicly available datasets, showing that we outperform the state of the art for support vector classification using training data protected by k-anonymity, and are comparable to learning on the original data.", "histories": [["v1", "Tue, 18 Oct 2016 22:14:27 GMT  (2170kb,D)", "http://arxiv.org/abs/1610.05815v1", "Technical Report"]], "COMMENTS": "Technical Report", "reviews": [], "SUBJECTS": "cs.LG cs.CR cs.DB", "authors": ["koray mancuhan", "chris clifton"], "accepted": false, "id": "1610.05815"}, "pdf": {"name": "1610.05815.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Koray Mancuhan", "Chris Clifton"], "emails": ["kmancuha@cs.purdue.edu", "clifton@cs.purdue.edu"], "sections": [{"heading": null, "text": "One way to reduce this risk is to use anonymized data, limiting exposure to individual data only where absolutely necessary, which seems especially appropriate for data mining, where the goal is generalizable knowledge and not data about specific individuals. In practice, data miners often insist on original data, fearing that they may \"miss out\" on something with anonymized or differentiated private approaches. This paper provides a theoretical justification for using anonymized data. In particular, we show that a support vector classifier trained on anatomized data should expect satisfactory diversity, just as with the original data. Anatomy preserves all data values, but introduces ambiguities in mapping between identifying and sensitive values, which satisfies the theoretical effectiveness of the proposed approach."}, {"heading": "1 Introduction", "text": "In fact, it is such that most of them will be able to move into a different world, in which they are able to move, in which they are able to move, in which they move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live."}, {"heading": "2 Related Work and Problem Statement", "text": "There have been studies on the linear classification of anonymized data. Agrawal et al. proposed an iterative distribution reconstruction algorithm for distorted training data, from which a C4.5 decision tree classifier was formed [1]. Iyengar proposed to use a classification metric to find the optimal generalization. Then, a C4.5 decision tree classifier was formed from the optimally generalized training data [16]. Dowd et al. investigated C4.5 decision tree learning by random substitutions. A matrix-based distribution reconstruction algorithm was applied to the disturbed training data, from which a precise C4.5 decision tree classifier was learned [10]. Inan et al. proposed to support vector machine classifiers by using anonymized training data that fulfill the k-anonymity. The kernel rubric-Taylor approximation was used to estimate the kernel base-F algorithms."}, {"heading": "3 Definitions and Notations", "text": "The first four definitions restate standardized definitions of unprotected data and attribute types 2. Definition 1. Definition D is referred to as a person-specific data set for the population P if each instance specifies Xi's unique individual p-P data. Definition 1. Definition D is referred to as the first type of attributes. Definition 2. A set of attributes is referred to as direct identification of attributes when they allow an adversary to associate. Definition 3. Definition of attributes are referred to as quasi identification if there is background knowledge that associates the quasi identification of attributes with a unique individual p-P. We include both direct and quasi-identifying attributes under the name identifying attributes. Definition 3. Definition of attributes are referred to as quasi identification of attributes."}, {"heading": "4 Pruning Mechanism for Anatomization", "text": "This year, it has reached the stage where it will be able to take the lead."}, {"heading": "5 Experiments", "text": "In fact, it is a way in which people are able to determine for themselves how they want to behave."}, {"heading": "6 Conclusion and Future Directions", "text": "Our algorithm estimates linearly separable training data from anatomized training data. We defined the generalizability of support vector classifiers when trained on the pre-processed data. The key point is that our algorithm provides good generalization guarantees for support vector classifiers. The proposed mechanism is evaluated on the basis of several publicly available data sets, and in most cases precise models have been observed while maintaining \"diversity.\" There are several future directions for this work. First, the development of other classification or cluster algorithms for anatomization. Second, the extension of current work to k-anonymity or generalization-based \"diversity. Considering several sensitive attributes is another direction."}, {"heading": "A Proof of Generalization Theorem", "text": "It is not the first time that the EU Commission (EU Commission), the EU Commission (EU Commission), the EU Commission (EU Commission), the EU Commission (EU Commission), the EU Commission (EU Commission), the EU Commission (EU Commission), the EU Commission (EU Commission), the EU Commission (EU Commission), the EU Commission (EU Commission), the EU Commission (EU Commission), the EU Commission (EU Commission), the EU Commission (EU Commission), the EU Commission (EU Commission), the EU Commission (EU Commission), the EU Commission (EU Commission), the EU Commission (EU Commission), the EU Commission (EU Commission), the EU Commission (EU Commission), the EU Commission (EU Commission), the EU Commission (EU Commission), the EU Commission (EU Commission), the EU Commission (EU Commission), the EU Commission (EU Commission), the EU Commission (EU Commission), the EU (EU), (EU), (EU), (EU), (EU), (EU), (EU), (EU), (EU), (EU), (EU), (EU), (EU), (EU), (EU), (EU), (EU), (EU, (EU), (EU), (EU), (EU, (EU), (EU), (EU), (EU, (EU), (EU), (EU), (EU, (EU), (EU), (EU), (), (), (EU, (EU), (), (EU), (), (EU), (), (), (EU, (), (), (), (), ((), (), ((), (), ((), ((), (), (), (), (((((), ((), (((),), (((), (((),), ((((), (((),), (((),), ((((), (((),), (((),), ((),), (((((), ((((),), ((),),),), ("}, {"heading": "B Pruning Mechanism Algorithm", "text": "Figures B.1 and B.2 indicate the pseudo-codes of two steps mentioned in Section 4.1.pruneTrainingData (): In the pseudo-codes, the DA parameter denotes the extended anatomical training data. The extension includes three points: 1. After the internal connection between the IT and ST tables (cf. Definition 11), the instances are sorted with respect to the GID attribute; and then the attributes IT.GID and ST.GID are suspended. 2. The mean value of each numerical and non-numerical ordinary attribute is subtracted in the augmented anatomical execution. 3. If the attribute Ai is nonnumerically ordinal, we replace the non-numerical values with integer values 1 to | dom (Ai) | according to the domain-wise order and the mode of discrete values to be used. 3. If the attribute Ai is not numerically ordinal, we replace the numerical values with 1.toothed values (Ai)."}, {"heading": "C Analysis of Additional Results", "text": "In fact, most of them are able to survive on their own if they do not play by the rules."}], "references": [{"title": "On the design and quantification of privacy preserving data mining algorithms", "author": ["D. Agrawal", "C.C. Aggarwal"], "venue": "Proceedings of the Twentieth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, Santa Barbara,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2001}, {"title": "Privacy-preserving data mining", "author": ["R. Agrawal", "R. Srikant"], "venue": "Proceedings of the 2000 ACM SIG- MOD Conference on Management of Data, Dallas,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2000}, {"title": "Keel datamining software tool: Data set repository", "author": ["J. Alcal\u00e1", "A. Fern\u00e1ndez", "J. Luengo", "J. Derrac", "S. Gar\u0107\u0131a", "L. S\u00e1nchez", "F. Herrera"], "venue": "integration of algorithms and experimental analysis framework, Journal of Multiple-Valued Logic and Soft Computing, 17 ", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2010}, {"title": "A tutorial on support vector machines for pattern recognition", "author": ["C.J. Burges"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1998}, {"title": "Libsvm: a library for support vector machines", "author": ["C.-C. Chang", "C.-J. Lin"], "venue": "ACM Transactions on Intelligent Systems and Technology (TIST), 2 ", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "Combining fragmentation and encryption to protect privacy in data storage", "author": ["V. Ciriani", "S.D.C.D. Vimercati", "S. Foresti", "S. Jajodia", "S. Paraboschi", "P. Samarati"], "venue": "ACM Trans. Inf. Syst. Secur., 13 ", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2010}, {"title": "Minimizing minimality and maximizing utility: Analyzing method-based attacks on anonymized data", "author": ["G. Cormode", "N. Li", "T. Li", "D. Srivastava"], "venue": "Proceedings of the VLDB Endowment, vol. 3", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2010}, {"title": "Extending loose associations to multiple fragments, in DBSec\u201913", "author": ["S.D.C. di Vimercati", "S. Foresti", "S. Jajodia", "G. Livraga", "S. Paraboschi", "P. Samarati"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2013}, {"title": "Privacy-preserving decision tree mining based on random substitutions", "author": ["J. Dowd", "S. Xu", "W. Zhang"], "venue": "tech. report, In International Conference on Emerging Trends in Information and Communication Security", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2005}, {"title": "Differential privacy", "author": ["C. Dwork"], "venue": "33rd International Colloquium on Automata, Languages and Programming ", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2006}, {"title": "Limiting privacy breaches in privacy preserving data mining", "author": ["A. Evfimievski", "J. Gehrke", "R. Srikant"], "venue": "Proceedings of the 22nd ACM SIGACT-SIGMOD- SIGART Symposium on Principles of Database Systems ", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2003}, {"title": "A privacy protection model for patient data with multiple sensitive attributes", "author": ["T. Gal", "Z. Chen", "A. Gangopadhyay"], "venue": "International Journal of Information Security and Privacy, IGI Global, Hershey, PA, 2 ", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2008}, {"title": "and B", "author": ["X. He", "Y. Xiao", "Y. Li", "Q. Wang", "W. Wang"], "venue": "Shi, Permutation anonymization: Improving anatomy for privacy preservation in data publication., in PAKDD Workshops, L. Cao, J. Z. Huang, J. Bailey, Y. S. Koh, and J. Luo, eds., vol. 7104 of Lecture Notes in Computer Science, Springer", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2011}, {"title": "Using anonymized data for classification", "author": ["A. Inan", "M. Kantarcioglu", "E. Bertino"], "venue": "Proceedings of the 2009 IEEE International Conference on Data Engineering, ICDE \u201909, Washington, DC, USA", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2009}, {"title": "Transforming data to satisfy privacy constraints", "author": ["V. Iyengar"], "venue": "Proc., the Eigth ACM SIGKDD Int\u2019l Conf. on Knowledge Discovery and Data Mining", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2002}, {"title": "Differentially private learning with kernels", "author": ["P. Jain", "A. Thakurta"], "venue": "ICML (3),", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2013}, {"title": "Attacks on privacy and de finettis theorem", "author": ["D. Kifer"], "venue": "In SIGMOD", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2009}, {"title": "t-closeness: Privacy beyond k-  anonymity and l-diversity", "author": ["N. Li", "T. Li"], "venue": "Proceedings of the 23nd International Conference on Data Engineering (ICDE \u201907),", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2007}, {"title": "On the tradeoff between privacy and utility in data publishing", "author": ["T. Li", "N. Li"], "venue": "Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Paris, France, June 28 - July 1, 2009", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2009}, {"title": "Slicing: A new approach for privacy preserving data publishing", "author": ["T. Li", "N. Li", "J. Zhang", "I. Molloy"], "venue": "IEEE Trans. Knowl. Data Eng., 24 ", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2012}, {"title": "Privacy-preserving outsourcing support vector machines with random transformation", "author": ["K.-P. Lin", "M.-S. Chen"], "venue": "Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD \u201910, New York, NY, USA", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2010}, {"title": "l-diversity: Privacy beyond k-anonymity", "author": ["A. Machanavajjhala", "J. Gehrke", "D. Kifer", "M. Venkitasubramaniam"], "venue": "Proceedings of the 22nd IEEE International Conference on Data Engineering ", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2006}, {"title": "Controlled data-swapping techniques for masking public use microdata sets, Statistical Research Division Report Series RR 96-04", "author": ["R.A. Moore", "Jr."], "venue": "U.S. Bureau of the Census,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1996}, {"title": "\u03b4-presence without complete world knowledge", "author": ["M.E. Nergiz", "C. Clifton"], "venue": "22 ", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2010}, {"title": "Learning in a large function space: Privacy-preserving mechanisms for svm learning", "author": ["B.I. Rubinstein", "P.L. Bartlett", "L. Huang", "N. Taft"], "venue": "arXiv preprint arXiv:0911.5708, ", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2009}, {"title": "Protecting respondent\u2019s privacy in microdata release", "author": ["P. Samarati"], "venue": "13 ", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2001}, {"title": "k-anonymity: a model for protecting privacy", "author": ["L. Sweeney"], "venue": "International Journal on Uncertainty, Fuzziness and Knowledge-based Systems, ", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2002}, {"title": "Statistical learning theory", "author": ["V.N. Vapnik", "V. Vapnik"], "venue": "vol. 1, Wiley New York", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1998}, {"title": "Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations", "author": ["I.H. Witten", "E. Frank"], "venue": null, "citeRegEx": "30", "shortCiteRegEx": "30", "year": 1999}, {"title": "Minimality attack in privacy preserving data publishing", "author": ["R.C.-W. Wong", "A.W.-C. Fu", "K. Wang", "J. Pei"], "venue": "VLDB", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2007}, {"title": "\u03b1", "author": ["R.C.-W. Wong", "J. Li", "A.W.-C. Fu", "K. Wang"], "venue": "k)-anonymity: An enhanced k-anonymity model for privacy preserving data publishing, in Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD \u201906, New York, NY, USA", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2006}, {"title": "Anatomy: Simple and effective privacy preservation", "author": ["X. Xiao", "Y. Tao"], "venue": "Proceedings of 32nd International Conference on Very Large Data Bases ", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2006}], "referenceMentions": [{"referenceID": 21, "context": "Many privacy definitions have been proposed based on generalizing/suppressing data (`-diversity[23], kanonymity [27, 28], t-closeness [19], \u03b4-presence [25], (\u03b1,k)-anonymity [32]).", "startOffset": 95, "endOffset": 99}, {"referenceID": 25, "context": "Many privacy definitions have been proposed based on generalizing/suppressing data (`-diversity[23], kanonymity [27, 28], t-closeness [19], \u03b4-presence [25], (\u03b1,k)-anonymity [32]).", "startOffset": 112, "endOffset": 120}, {"referenceID": 26, "context": "Many privacy definitions have been proposed based on generalizing/suppressing data (`-diversity[23], kanonymity [27, 28], t-closeness [19], \u03b4-presence [25], (\u03b1,k)-anonymity [32]).", "startOffset": 112, "endOffset": 120}, {"referenceID": 17, "context": "Many privacy definitions have been proposed based on generalizing/suppressing data (`-diversity[23], kanonymity [27, 28], t-closeness [19], \u03b4-presence [25], (\u03b1,k)-anonymity [32]).", "startOffset": 134, "endOffset": 138}, {"referenceID": 23, "context": "Many privacy definitions have been proposed based on generalizing/suppressing data (`-diversity[23], kanonymity [27, 28], t-closeness [19], \u03b4-presence [25], (\u03b1,k)-anonymity [32]).", "startOffset": 151, "endOffset": 155}, {"referenceID": 30, "context": "Many privacy definitions have been proposed based on generalizing/suppressing data (`-diversity[23], kanonymity [27, 28], t-closeness [19], \u03b4-presence [25], (\u03b1,k)-anonymity [32]).", "startOffset": 173, "endOffset": 177}, {"referenceID": 22, "context": "Other alternatives include value swapping [24], distortion [2], randomization [12], and noise addition (e.", "startOffset": 42, "endOffset": 46}, {"referenceID": 1, "context": "Other alternatives include value swapping [24], distortion [2], randomization [12], and noise addition (e.", "startOffset": 59, "endOffset": 62}, {"referenceID": 10, "context": "Other alternatives include value swapping [24], distortion [2], randomization [12], and noise addition (e.", "startOffset": 78, "endOffset": 82}, {"referenceID": 9, "context": ", differential privacy [11]).", "startOffset": 23, "endOffset": 27}, {"referenceID": 26, "context": "Generalization consists of replacing identifying attribute values with a less specific version [28].", "startOffset": 95, "endOffset": 99}, {"referenceID": 26, "context": "Suppression can be viewed as the ultimate generalization, replacing the identifying value with an \u201cany\u201d value [28].", "startOffset": 110, "endOffset": 114}, {"referenceID": 31, "context": "edu to enforce `-diversity while preserving specific data values [33].", "startOffset": 65, "endOffset": 69}, {"referenceID": 5, "context": "The more general approach of fragmentation [7] divides a given dataset\u2019s attributes into two sets of attributes (2 partitions) such that an encryption mechanism avoids associations between two different small partitions.", "startOffset": 43, "endOffset": 46}, {"referenceID": 7, "context": "extend fragmentation to multiple partitions [9], and Tamas et al.", "startOffset": 44, "endOffset": 47}, {"referenceID": 11, "context": "propose an extension that deals with multiple sensitive attributes [13].", "startOffset": 67, "endOffset": 71}, {"referenceID": 16, "context": "There is concern that anatomization is vulnerable to several attacks [18, 14, 21].", "startOffset": 69, "endOffset": 81}, {"referenceID": 12, "context": "There is concern that anatomization is vulnerable to several attacks [18, 14, 21].", "startOffset": 69, "endOffset": 81}, {"referenceID": 19, "context": "There is concern that anatomization is vulnerable to several attacks [18, 14, 21].", "startOffset": 69, "endOffset": 81}, {"referenceID": 18, "context": "While this can be an issue, any method that provides meaningful utility fails to provide perfect privacy against a sufficiently strong adversary [20, 11].", "startOffset": 145, "endOffset": 153}, {"referenceID": 9, "context": "While this can be an issue, any method that provides meaningful utility fails to provide perfect privacy against a sufficiently strong adversary [20, 11].", "startOffset": 145, "endOffset": 153}, {"referenceID": 29, "context": ", minimality [31, 8].", "startOffset": 13, "endOffset": 20}, {"referenceID": 6, "context": ", minimality [31, 8].", "startOffset": 13, "endOffset": 20}, {"referenceID": 16, "context": "A violating classification task would be the prediction of sensitive attribute, a task that was found to be #P-complete by Kifer [18].", "startOffset": 129, "endOffset": 133}, {"referenceID": 13, "context": "already gives a practical applications of such a learning scenario [15].", "startOffset": 67, "endOffset": 71}, {"referenceID": 13, "context": "In empirical analysis, our algorithm will be compared with SVM and SVC that are trained on either unprotected data or generalized data (under k-anonymity [15]).", "startOffset": 154, "endOffset": 158}, {"referenceID": 27, "context": "The analysis will be justified with the statistical learning theory [29, 5]", "startOffset": 68, "endOffset": 75}, {"referenceID": 3, "context": "The analysis will be justified with the statistical learning theory [29, 5]", "startOffset": 68, "endOffset": 75}, {"referenceID": 0, "context": "5 decision tree classifier was trained [1].", "startOffset": 39, "endOffset": 42}, {"referenceID": 14, "context": "5 decision tree classifier was trained from the optimally generalized training data [16].", "startOffset": 84, "endOffset": 88}, {"referenceID": 8, "context": "5 decision tree classifier was learned [10].", "startOffset": 39, "endOffset": 43}, {"referenceID": 13, "context": "Taylor approximation was used to estimate the linear and RBF kernel computation from generalized data[15].", "startOffset": 101, "endOffset": 105}, {"referenceID": 24, "context": "They analyze finite and infinite dimensional kernels in function of the approximation error under differential privacy [26].", "startOffset": 119, "endOffset": 123}, {"referenceID": 20, "context": "Random transformation is applied on the training set so that the cloud server computes the accurate model without knowing what the actual values are [22].", "startOffset": 149, "endOffset": 153}, {"referenceID": 15, "context": "They propose differentially private mechanisms to train support vector machines for interactive, semi-interactive and non-interactive learning scenarios, providing theoretical analysis of the proposed approaches [17].", "startOffset": 212, "endOffset": 216}, {"referenceID": 26, "context": "Given the former definitions, we will next define the anonymized training data following the definition of kanonymity [28].", "startOffset": 118, "endOffset": 122}, {"referenceID": 26, "context": "A training dataset D that satisfies the following conditions is said to be anonymized training data Dk [28]:", "startOffset": 103, "endOffset": 107}, {"referenceID": 27, "context": "We will remind the theoretical analysis of the original SVC and SVM classifiers in the end of this section [29].", "startOffset": 107, "endOffset": 111}, {"referenceID": 21, "context": "This new requirement uses the definition of groups [23].", "startOffset": 51, "endOffset": 55}, {"referenceID": 31, "context": "[33].", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "when the training data is linearly separable [5].", "startOffset": 45, "endOffset": 48}, {"referenceID": 27, "context": "5) according to VC theory [29, 5].", "startOffset": 26, "endOffset": 33}, {"referenceID": 3, "context": "5) according to VC theory [29, 5].", "startOffset": 26, "endOffset": 33}, {"referenceID": 3, "context": "See Burges [5] and Vapnik [29] for general discussion.", "startOffset": 11, "endOffset": 14}, {"referenceID": 27, "context": "See Burges [5] and Vapnik [29] for general discussion.", "startOffset": 26, "endOffset": 30}, {"referenceID": 3, "context": "are closest to the decision boundary lie on the surface of a circle [5].", "startOffset": 68, "endOffset": 71}, {"referenceID": 31, "context": "Under the random worlds assumption [33], the prerequisite step assumes that (rAmin, rAmax) has uniform distribution and therefore estimates the expected radius E[r] with rAmin+rAmax 2 (dashed green line in Figure 3).", "startOffset": 35, "endOffset": 39}, {"referenceID": 3, "context": "The instances within each group are not linearly independent from the other `\u2212 1 instances and the shattering property is damaged [5].", "startOffset": 130, "endOffset": 133}, {"referenceID": 27, "context": "1 in the infinite dimensional space [29, 5].", "startOffset": 36, "endOffset": 43}, {"referenceID": 3, "context": "1 in the infinite dimensional space [29, 5].", "startOffset": 36, "endOffset": 43}, {"referenceID": 2, "context": "1 Datasets We tested our algorithm on the adult, IPUMS and marketing datasets of the UCI data repository [4] and the fatality dataset of Keel data repository [3]:", "startOffset": 158, "endOffset": 161}, {"referenceID": 28, "context": "Weka was used for attribute selection and discretization if needed [30].", "startOffset": 67, "endOffset": 71}, {"referenceID": 31, "context": "\u2019s bucketization algorithm [33].", "startOffset": 27, "endOffset": 31}, {"referenceID": 4, "context": "21 was used for the support vector classification [6].", "startOffset": 50, "endOffset": 53}, {"referenceID": 13, "context": "provided generalization hierarchies only in the adult dataset [15].", "startOffset": 62, "endOffset": 66}, {"referenceID": 31, "context": "The rate of the error rate increase in function of ` is theoretically hard to estimate since the assignments of sensitive attributes to each group will be random throughout the bucketization algorithm [33].", "startOffset": 201, "endOffset": 205}, {"referenceID": 13, "context": "The generalization based k-anonymity, on the other hand, distorts most of the original attribute values [15].", "startOffset": 104, "endOffset": 108}], "year": 2016, "abstractText": "Corporations are retaining ever-larger corpuses of personal data; the frequency or breaches and corresponding privacy impact have been rising accordingly. One way to mitigate this risk is through use of anonymized data, limiting the exposure of individual data to only where it is absolutely needed. This would seem particularly appropriate for data mining, where the goal is generalizable knowledge rather than data on specific individuals. In practice, corporate data miners often insist on original data, for fear that they might \u201dmiss something\u201d with anonymized or differentially private approaches. This paper provides a theoretical justification for the use of anonymized data. Specifically, we show that a support vector classifier trained on anatomized data satisfying `-diversity should be expected to do as well as on the original data. Anatomy preserves all data values, but introduces uncertainty in the mapping between identifying and sensitive values, thus satisfying `-diversity. The theoretical effectiveness of the proposed approach is validated using several publicly available datasets, showing that we outperform the state of the art for support vector classification using training data protected by k-anonymity, and are comparable to learning on the original data.", "creator": "TeX"}}}