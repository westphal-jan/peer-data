{"id": "1610.05945", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Oct-2016", "title": "A multi-task learning model for malware classification with useful file access pattern from API call sequence", "abstract": "Based on API call sequences, semantic-aware and machine learning (ML) based malware classifiers can be built for malware detection or classification. Previous works concentrate on crafting and extracting various features from malware binaries, disassembled binaries or API calls via static or dynamic analysis and resorting to ML to build classifiers. However, they tend to involve too much feature engineering and fail to provide interpretability. We solve these two problems with the recent advances in deep learning: 1) RNN-based autoencoders (RNN-AEs) can automatically learn low-dimensional representation of a malware from its raw API call sequence. 2) Multiple decoders can be trained under different supervisions to give more information, other than the class or family label of a malware. Inspired by the works of document classification and automatic sentence summarization, each API call sequence can be regarded as a sentence. In this paper, we make the first attempt to build a multi-task malware learning model based on API call sequences. The model consists of two decoders, one for malware classification and one for $\\emph{file access pattern}$ (FAP) generation given the API call sequence of a malware. We base our model on the general seq2seq framework. Experiments show that our model can give competitive classification results as well as insightful FAP information.", "histories": [["v1", "Wed, 19 Oct 2016 10:06:14 GMT  (2270kb,D)", "http://arxiv.org/abs/1610.05945v1", null]], "reviews": [], "SUBJECTS": "cs.SD cs.CR cs.LG", "authors": ["xin wang", "siu ming yiu"], "accepted": false, "id": "1610.05945"}, "pdf": {"name": "1610.05945.pdf", "metadata": {"source": "CRF", "title": "A multi-task learning model for malware classification with useful file access pattern from API call sequence", "authors": ["Xin Wang", "Siu Ming Yiu"], "emails": ["smyiu}@cs.hku.hk"], "sections": [{"heading": "Introduction", "text": "This year, it is so far that it is only a matter of time before it is ready, until it is ready."}, {"heading": "Preliminaries", "text": "Unlike traditional neural networks, which assume that all inputs are independent of each other, a recursive neural network (RNN) is able to handle sequential data of different lengths and has proven its power in many NLP tasks. The idea is that an RNN maintains a hidden state that can be considered the memory of the network. At each step t, an RNN performs the same calculations on different inputs with the same common parameters: ht = f (ht \u2212 1, xt), where f is an activation function that normally provides nonlinearity, and xt is the input step. At each step, an RNN performs the same calculations on different input data with the same common parameters. An RNN can effectively learn the conditional distribution p (Y | X), where the output sequence Y = (y1,..., yT \u2032) and the input sequence X = (x1, xT) are the input sequence X (T)."}, {"heading": "Multi-task Malware Learning Model", "text": "The basic seq2seq model is an exact action performed by malware, e.g. the creation of file formats. The basic seq2seq models can be converted into multi-task models seq2seq. (Luong et al. 2015) The multi-task extension can improve the performance of the seq2seq model on machine translation of centered tasks. (Depending on the number of encoders or decoders, three settings are available in MTL seq2seq model: one-to-many, many-to-one, many-to-tomany.) Our model employs one-to-many settings, consisting of one encoder for representation learning and two decoders for classification and FAP generation (see Fig. 1).Representation learning on API call sequences is usually collected by ticking while the samples are running in a sandbox environment."}, {"heading": "Evaluations", "text": "We evaluate the accuracy of our model using a public Malware API call sequence data set (Kim 2016) at different granularity levels. We select two sets of data, which include 7,430 samples for coarse-grained evaluation and 4,932 samples for fine-grained evaluation (see Tab. 1 and Tab. 6). Malware whose families are unknown or whose corresponding families do not have enough samples for training will be dropped and randomly divided into traction, validation and test data sets containing 75%, 5% and 20% samples, respectively."}, {"heading": "Preprocessing", "text": "s say S = {s1, s2,..., sn} is a set of APIs for file access called the FAP set, and l \u00b2 Z, then we say p = | s | l is a FAP of length l, in which s \u00b2. We select seven APIs for file access from Windows kernel APIs as our FAP set. Different Windows kernel APIs that perform the same function are assigned to an API (see Table 2). For example, both CopyFile and CopyFileEx perform the function that copies a file, and the difference is whether the file already exists. Each function has two names for Unicode with W as suffix and for ANSI with A as malware."}, {"heading": "Model setup", "text": "Since our model is a multi-task model based on the basic seq2seq model, we first experiment with seq2seq models for classification and FAP generation as baselines. We then verify our multi-task malware learning model using classification or FAP generation tasks. There are many variants of RNN units since the introduction of LSTM (Hochreiter and Schmidhuber 1997). We use GRU as our standard RNN unit, which has been proven to be more computationally efficient than standard LSTM with no discernible performance loss (Chung et al. 2014). The standard experiment (AE + decoder) trains on the train data set and decodes on the test data set. We can also train on the full data set (AE (full) + decoder) because imaging learning is not supervised. In addition, we evaluate the bidirectional extension of our GRU-based model (full + decoder) with the train datasets (or both)."}, {"heading": "Coarse-grained Evaluations and Results", "text": "All FAP candidates are mapped on indices (see Table 5). This is because we find a classification performance in samples from F3 and packaged samples that appears to be decreasing compared to the performance of samples from F3. We visualize the feature vectors in Tsne (van der Maaten and Hinton 2008), a method for visualizing high-dimensional vectors (see Figure 2). Adware samples form two clear clusters, while samples from other families are very scattered and some of them are highly interwoven. A feature vector learned from the API call sequence can be considered a behavioral aggregation of a malware (see Figure 2)."}, {"heading": "Case Studies", "text": "In fact, most of them will be able to survive themselves, and they will be able to survive themselves, \"he told the German Press Agency in an interview with\" Welt am Sonntag \":\" I don't think we will be able to put the world in order. \""}, {"heading": "Fine-grained Evaluations and Results", "text": "The quality of the characteristics is quite self-explanatory, samples from different families form different clusters (see Fig. 5). Results show that both the classification and performance of the FAP generation are more competitive than those of the coarse-grained evaluation (see Fig. 7). Compared to other families, the characteristic vectors of some samples from Trojan-fakeav.win32.smartfortress and packed.win32.krap are quite scattered and interwoven (see Fig. 5). This justifies the essentiality of more revealing and interpretable FAP information, as these samples can be very similar and difficult to distinguish from the API call sequences. The fine-grained evaluation also limits the scope of FAP p6 and p5 to networm.32.apalle.wallware.ww."}, {"heading": "Discussion", "text": "Scalability It is not enough that ML-based malware model simply give us a class label with no explanatory information. On the other hand, malware from the same family does not necessarily perform the same way on our system. It is natural that we want to know what a malware will do to a system, except for the family to which it belongs. Experimental results show that our multi-task malware learning model is capable of giving FAP as well as class designation of a malware. Malware representations, which are learned by RNNautoencoder from API call sequences, are robust enough to totrained multiple decoders with completely different goals and give more informative results. Instead of performing a single task at once, our model first learns representations of malware in an unattended manner, and then multiple decoders can be trained very efficiently."}, {"heading": "Conclusion", "text": "There are two problems with previous work on malware classification: (I) Malware evolves every day and new unknown families keep appearing; classifiers built to issue known family labels on their own are not enough; (II) Labels themselves are not very interpretable for samples from the same family, even if the label is correct; it is more robust to briefly describe both the behavior of a malware and the class label; we are building a multifunctional malware learning model based on the proven, powerful seq2seq multi-task model for classification and FAP generation; an FAP says what a malware does with a file system, and sometimes it points directly to the family to which the malware belongs. Our preliminary results show that the seq2seq model can not only be used for malware classification based on API call sequences, but can also be used to generate more insightful information from the newer AE files."}], "references": [{"title": "Novel feature extraction, selection and fusion for effective malware family classification", "author": ["Ahmadi"], "venue": "In Proceedings of the Sixth ACM Conference on Data and Application Security and Privacy,", "citeRegEx": "Ahmadi,? \\Q2016\\E", "shortCiteRegEx": "Ahmadi", "year": 2016}, {"title": "Semanticsaware malware detection", "author": ["Christodorescu"], "venue": "IEEE Symposium on Security and Privacy (S&P\u201905),", "citeRegEx": "Christodorescu,? \\Q2005\\E", "shortCiteRegEx": "Christodorescu", "year": 2005}, {"title": "Empirical evaluation of gated recurrent neural networks on sequence modeling", "author": ["Chung"], "venue": "arXiv preprint arXiv:1412.3555", "citeRegEx": "Chung,? \\Q2014\\E", "shortCiteRegEx": "Chung", "year": 2014}, {"title": "Large-scale malware classification using random projections and neural networks", "author": ["Dahl"], "venue": "IEEE International Conference on Acoustics, Speech and Signal Processing,", "citeRegEx": "Dahl,? \\Q2013\\E", "shortCiteRegEx": "Dahl", "year": 2013}, {"title": "Semisupervised sequence learning", "author": ["Dai", "A.M. Le 2015] Dai", "Q.V. Le"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Dai et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Dai et al\\.", "year": 2015}, {"title": "Long short-term memory. Neural computation 9(8):1735\u20131780", "author": ["Hochreiter", "S. Schmidhuber 1997] Hochreiter", "J. Schmidhuber"], "venue": null, "citeRegEx": "Hochreiter et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter et al\\.", "year": 1997}, {"title": "Api call sequence dataset. http://ocslab.hk security.net/apimds-dataset; accessed 11August-2016", "author": ["H.K. Kim"], "venue": null, "citeRegEx": "Kim,? \\Q2016\\E", "shortCiteRegEx": "Kim", "year": 2016}, {"title": "Feature selection and extraction for malware classification", "author": ["Lin"], "venue": "Journal of Information Science and Engineering", "citeRegEx": "Lin,? \\Q2015\\E", "shortCiteRegEx": "Lin", "year": 2015}, {"title": "Multi-task sequence to sequence learning", "author": ["Luong"], "venue": "arXiv preprint arXiv:1511.06114", "citeRegEx": "Luong,? \\Q2015\\E", "shortCiteRegEx": "Luong", "year": 2015}, {"title": "A scalable multi-level feature extraction technique to detect malicious executables. Information Systems Frontiers 10(1):33\u201345", "author": ["Khan Masud", "M.M. Thuraisingham 2008] Masud", "L. Khan", "B. Thuraisingham"], "venue": null, "citeRegEx": "Masud et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Masud et al\\.", "year": 2008}, {"title": "Abstractive text summarization using sequence-to-sequence rnns and beyond", "author": ["Nallapati"], "venue": "arXiv preprint arXiv:1602.06023", "citeRegEx": "Nallapati,? \\Q2016\\E", "shortCiteRegEx": "Nallapati", "year": 2016}, {"title": "Malware images: visualization and automatic classification", "author": ["Nataraj"], "venue": "In Proceedings of the 8th international symposium on visualization for cyber security,", "citeRegEx": "Nataraj,? \\Q2011\\E", "shortCiteRegEx": "Nataraj", "year": 2011}, {"title": "Malware classification with recurrent networks", "author": ["Pascanu"], "venue": "In 2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP),", "citeRegEx": "Pascanu,? \\Q2015\\E", "shortCiteRegEx": "Pascanu", "year": 2015}, {"title": "A neural attention model for abstractive sentence summarization", "author": ["Chopra Rush", "A.M. Weston 2015] Rush", "S. Chopra", "J. Weston"], "venue": "arXiv preprint arXiv:1509.00685", "citeRegEx": "Rush et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Rush et al\\.", "year": 2015}, {"title": "Kernel machines for malware classification and similarity analysis", "author": ["Shankarapani"], "venue": "In The 2010 International Joint Conference on Neural Networks (IJCNN),", "citeRegEx": "Shankarapani,? \\Q2010\\E", "shortCiteRegEx": "Shankarapani", "year": 2010}, {"title": "Practical malware analysis: the hands-on guide to dissecting malicious software. no starch", "author": ["Sikorski", "M. Honig 2012] Sikorski", "A. Honig"], "venue": null, "citeRegEx": "Sikorski et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Sikorski et al\\.", "year": 2012}, {"title": "Sequence to sequence learning with neural networks. In Advances in neural information processing systems, 3104\u20133112", "author": ["Vinyals Sutskever", "I. Le 2014] Sutskever", "O. Vinyals", "Q.V. Le"], "venue": null, "citeRegEx": "Sutskever et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "Differentiating malware from cleanware using behavioural analysis", "author": ["Tian"], "venue": "In Malicious and Unwanted Software (MALWARE),", "citeRegEx": "Tian,? \\Q2010\\E", "shortCiteRegEx": "Tian", "year": 2010}, {"title": "Visualizing high-dimensional data using t-sne", "author": ["van der Maaten", "L. Hinton 2008] van der Maaten", "G. Hinton"], "venue": "Journal of Machine Learning Research", "citeRegEx": "Maaten et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Maaten et al\\.", "year": 2008}, {"title": "Malware obfuscation techniques: A brief survey", "author": ["You", "I. Yim 2010] You", "K. Yim"], "venue": "In BWCCA,", "citeRegEx": "You et al\\.,? \\Q2010\\E", "shortCiteRegEx": "You et al\\.", "year": 2010}, {"title": "Semantics-aware android malware classification using weighted contextual api dependency graphs", "author": ["Zhang"], "venue": "In Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security,", "citeRegEx": "Zhang,? \\Q2014\\E", "shortCiteRegEx": "Zhang", "year": 2014}], "referenceMentions": [{"referenceID": 6, "context": "We evaluate the accuracy of our model on a public malware API call sequence dataset (Kim 2016) at different granularity levels.", "startOffset": 84, "endOffset": 94}], "year": 2016, "abstractText": "Based on API call sequences, semantic-aware and machine learning (ML) based malware classifiers can be built for malware detection or classification. Previous works concentrate on crafting and extracting various features from malware binaries, disassembled binaries or API calls via static or dynamic analysis and resorting to ML to build classifiers. However, they tend to involve too much feature engineering and fail to provide interpretability. We solve these two problems with the recent advances in deep learning: 1) RNNbased autoencoders (RNN-AEs) can automatically learn lowdimensional representation of a malware from its raw API call sequence. 2) Multiple decoders can be trained under different supervisions to give more information, other than the class or family label of a malware. Inspired by the works of document classification and automatic sentence summarization, each API call sequence can be regarded as a sentence. In this paper, we make the first attempt to build a multi-task malware learning model based on API call sequences. The model consists of two decoders, one for malware classification and one for file access pattern (FAP) generation given the API call sequence of a malware. We base our model on the general seq2seq framework. Experiments show that our model can give competitive classification results as well as insightful FAP information.", "creator": "LaTeX with hyperref package"}}}