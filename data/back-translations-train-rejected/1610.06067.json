{"id": "1610.06067", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Oct-2016", "title": "Fairness as a Program Property", "abstract": "We explore the following question: Is a decision-making program fair, for some useful definition of fairness? First, we describe how several algorithmic fairness questions can be phrased as program verification problems. Second, we discuss an automated verification technique for proving or disproving fairness of decision-making programs with respect to a probabilistic model of the population.", "histories": [["v1", "Wed, 19 Oct 2016 15:31:34 GMT  (2264kb,D)", "http://arxiv.org/abs/1610.06067v1", null]], "reviews": [], "SUBJECTS": "cs.PL cs.AI", "authors": ["aws albarghouthi", "loris d'antoni", "samuel drews", "aditya nori"], "accepted": false, "id": "1610.06067"}, "pdf": {"name": "1610.06067.pdf", "metadata": {"source": "CRF", "title": "Fairness as a Program Property", "authors": ["Aws Albarghouthi", "Loris D\u2019Antoni", "Samuel Drews", "Aditya Nori"], "emails": [], "sections": [{"heading": "1. Introduction", "text": "Algorithms have become powerful arbitrators of a number of important decisions with far-reaching societal implications - attitudes [21, 22], welfare allocations [15], prison sentences [2], policing [5, 25], and many others. Given the scope and sensitivity of algorithmic decisions that increase with each passing day, the question of whether an algorithm is fair is pressing. Indeed, the concept of algorithmic fairness has attracted the attention of a wide range of experts: machine learning and theory researchers [6, 13, 16, 29]; privacy researchers and investigative journalists [2, 10, 26, 28]; legal scholars and social scientists [1, 3, 27]; government agencies and NGOs [24]. Ultimately, algorithmic fairness is a question of programs and their characteristics: Is a given program P fair, under a certain definition of fairness? Or how fair is it when we analyze it?"}, {"heading": "2. Proving Programs Fair", "text": "In this section, we describe the components of the issue of fairness. Our goal is to prove whether a particular program is fair in terms of the way it is run. To get a handle on the issue of fairness, we need to answer a number of questions: - What class of decision-making programs should we be able to verify? - How can we describe what it means for the program to be fair? - How can we fully automate the review process?"}, {"heading": "3. Case Study", "text": "This year, it has reached the point where it will be able to retaliate."}, {"heading": "4. Experience and future Outlook", "text": "We have developed a fairness verification tool called FairSquare, which requires a decision-making program, a population model, and checks the fairness of the program with respect to the model. So far, we have focused on group equity. The tool uses the popular Z3 SMT Solver [12] to manipulate first-order formulas against arithmetic theories. We have used FairSquare to prove or disprove the fairness of a number of population models and programs that represent machine learning classifiers automatically generated from real-world datasets used in other algorithmic fairness work [11, 16, 29]. Specifically, we have considered linear SVMs, simple neural networks with reflected linear units and decision trees. Looking ahead, we see a wide range of opportunities for improvement and exploration."}], "references": [{"title": "Hiring by algorithm: predicting and preventing disparate impact", "author": ["Ifeoma Ajunwa", "Sorelle Friedler", "Carlos E Scheidegger", "Suresh Venkatasubramanian"], "venue": "Available at SSRN", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2016}, {"title": "Machine bias: There\u2019s software used across the country to predict future criminals. and it\u2019s biased against blacks", "author": ["Julia Angwin", "Jeff Larson", "Surya Mattu", "Lauren Kirchner"], "venue": "https://www.propublica.org/article/machinebias-risk-assessments-in-criminal-sentencing,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2016}, {"title": "Big data\u2019s disparate impact", "author": ["Solon Barocas", "Andrew D Selbst"], "venue": "Available at SSRN 2477899,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2014}, {"title": "Satisfiability modulo theories", "author": ["Clark W. Barrett", "Roberto Sebastiani", "Sanjit A. Seshia", "Cesare Tinelli"], "venue": "In Handbook of Satisfiability,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2009}, {"title": "Predicting crime, lapd-style", "author": ["Nate Berg"], "venue": "https://www.theguardian.com/cities/2014/jun/ 25/predicting-crime-lapd-los-angeles-policedata-analysis-algorithm-minority-report,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "Three naive bayes approaches for discrimination-free classification", "author": ["Toon Calders", "Sicco Verwer"], "venue": "Data Mining and Knowledge Discovery,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2010}, {"title": "Stan: a probabilistic programming language", "author": ["Bob Carpenter", "Andrew Gelman", "Matt Hoffman", "Daniel Lee", "Ben Goodrich", "Michael Betancourt", "Marcus A Brubaker", "Jiqiang Guo", "Peter Li", "Allen Riddell"], "venue": "Journal of Statistical Software,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2015}, {"title": "On probabilistic inference by weighted model counting", "author": ["Mark Chavira", "Adnan Darwiche"], "venue": "Artificial Intelligence,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2008}, {"title": "Automated experiments on ad privacy settings", "author": ["Amit Datta", "Michael Carl Tschantz", "Anupam Datta"], "venue": "Proceedings on Privacy Enhancing Technologies,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2015}, {"title": "Algorithmic transparency via quantitative input influence", "author": ["Anupam Datta", "Shayak Sen", "Yair Zick"], "venue": "In Proceedings of 37th IEEE Symposium on Security and Privacy,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2016}, {"title": "An efficient smt solver", "author": ["Leonardo De Moura", "Nikolaj Bj\u00f8rner. Z"], "venue": "In International conference on Tools and Algorithms for the Construction and Analysis of Systems,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2008}, {"title": "Fairness through awareness", "author": ["Cynthia Dwork", "Moritz Hardt", "Toniann Pitassi", "Omer Reingold", "Richard S. Zemel"], "venue": "In Innovations in Theoretical Computer Science", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "On the complexity of computing the volume of a polyhedron", "author": ["Martin E. Dyer", "Alan M. Frieze"], "venue": "SIAM Journal on Computing,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1988}, {"title": "The dangers of letting algorithms enforce policy. http://www.slate.com/articles/ technology/future_tense/2015/04/the_dangers_ of_letting_algorithms_enforce_policy.html", "author": ["Virginia Eubanks"], "venue": "(Accessed on 06/18/2016)", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2015}, {"title": "Certifying and removing disparate impact", "author": ["Michael Feldman", "Sorelle A. Friedler", "John Moeller", "Carlos Scheidegger", "Suresh Venkatasubramanian"], "venue": "In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2015}, {"title": "EU regulations on algorithmic decision-making and a \u201cright to explanation", "author": ["B. Goodman", "S. Flaxman"], "venue": "ArXiv e-prints,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2016}, {"title": "Church: a language for generative models", "author": ["Noah Goodman", "Vikash Mansinghka", "Daniel M Roy", "Keith Bonawitz", "Joshua B Tenenbaum"], "venue": "arXiv preprint arXiv:1206.3255,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2012}, {"title": "Probabilistic programming", "author": ["Andrew D Gordon", "Thomas A Henzinger", "Aditya V Nori", "Sriram K Rajamani"], "venue": "In Proceedings of the on Future of Software Engineering,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2014}, {"title": "Complexity of polytope volume", "author": ["Leonid Khachiyan"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1993}, {"title": "Who do you blame when an algorithm gets you fired? http://www.wired.co.uk/article/ make-algorithms-accountable, January 2016", "author": ["Nicole Kobie"], "venue": null, "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2016}, {"title": "Can an algorithm hire better than a human? http://www.nytimes.com/2015/06/26/ upshot/can-an-algorithm-hire-better-than-ahuman.html", "author": ["Claire Cain Miller"], "venue": "(Accessed on 06/18/2016)", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2015}, {"title": "An efficient mcmc sampler for probabilistic programs", "author": ["Aditya V Nori", "Chung-Kil Hur", "Sriram K Rajamani", "Selva Samuel"], "venue": "In AAAI,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2014}, {"title": "Predictive policing: The role of crime forecasting in law enforcement operations", "author": ["Walt L Perry"], "venue": "Rand Corporation,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2013}, {"title": "Discrimination in online ad delivery", "author": ["Latanya Sweeney"], "venue": null, "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2013}, {"title": "An fda for algorithms", "author": ["Andrew Tutt"], "venue": "Available at SSRN", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2016}, {"title": "Websites vary prices, deals based on users", "author": ["Jennifer Valentino-Devries", "Jeremy Singer-Vine", "Ashkan Soltani"], "venue": "information. http://www.wsj.com/articles/ SB10001424127887323777204578189391813881534,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2012}, {"title": "Learning fair representations", "author": ["Richard S. Zemel", "Yu Wu", "Kevin Swersky", "Toniann Pitassi", "Cynthia Dwork"], "venue": "In Proceedings of the 30th International Conference on Machine Learning,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2013}], "referenceMentions": [{"referenceID": 19, "context": "Algorithms have become powerful arbitrators of a range of significant decisions with far-reaching societal impact\u2014hiring [21, 22], welfare allocation [15], prison sentencing [2], policing [5, 25], amongst many others.", "startOffset": 121, "endOffset": 129}, {"referenceID": 20, "context": "Algorithms have become powerful arbitrators of a range of significant decisions with far-reaching societal impact\u2014hiring [21, 22], welfare allocation [15], prison sentencing [2], policing [5, 25], amongst many others.", "startOffset": 121, "endOffset": 129}, {"referenceID": 13, "context": "Algorithms have become powerful arbitrators of a range of significant decisions with far-reaching societal impact\u2014hiring [21, 22], welfare allocation [15], prison sentencing [2], policing [5, 25], amongst many others.", "startOffset": 150, "endOffset": 154}, {"referenceID": 1, "context": "Algorithms have become powerful arbitrators of a range of significant decisions with far-reaching societal impact\u2014hiring [21, 22], welfare allocation [15], prison sentencing [2], policing [5, 25], amongst many others.", "startOffset": 174, "endOffset": 177}, {"referenceID": 4, "context": "Algorithms have become powerful arbitrators of a range of significant decisions with far-reaching societal impact\u2014hiring [21, 22], welfare allocation [15], prison sentencing [2], policing [5, 25], amongst many others.", "startOffset": 188, "endOffset": 195}, {"referenceID": 22, "context": "Algorithms have become powerful arbitrators of a range of significant decisions with far-reaching societal impact\u2014hiring [21, 22], welfare allocation [15], prison sentencing [2], policing [5, 25], amongst many others.", "startOffset": 188, "endOffset": 195}, {"referenceID": 5, "context": "Indeed, the notion of algorithmic fairness has captured the attention of a broad spectrum of experts: machine learning and theory researchers [6, 13, 16, 29]; privacy researchers and investigative journalists [2, 10, 26, 28]; law scholars and social scientists [1, 3, 27]; governmental agencies and NGOs [24].", "startOffset": 142, "endOffset": 157}, {"referenceID": 11, "context": "Indeed, the notion of algorithmic fairness has captured the attention of a broad spectrum of experts: machine learning and theory researchers [6, 13, 16, 29]; privacy researchers and investigative journalists [2, 10, 26, 28]; law scholars and social scientists [1, 3, 27]; governmental agencies and NGOs [24].", "startOffset": 142, "endOffset": 157}, {"referenceID": 14, "context": "Indeed, the notion of algorithmic fairness has captured the attention of a broad spectrum of experts: machine learning and theory researchers [6, 13, 16, 29]; privacy researchers and investigative journalists [2, 10, 26, 28]; law scholars and social scientists [1, 3, 27]; governmental agencies and NGOs [24].", "startOffset": 142, "endOffset": 157}, {"referenceID": 26, "context": "Indeed, the notion of algorithmic fairness has captured the attention of a broad spectrum of experts: machine learning and theory researchers [6, 13, 16, 29]; privacy researchers and investigative journalists [2, 10, 26, 28]; law scholars and social scientists [1, 3, 27]; governmental agencies and NGOs [24].", "startOffset": 142, "endOffset": 157}, {"referenceID": 1, "context": "Indeed, the notion of algorithmic fairness has captured the attention of a broad spectrum of experts: machine learning and theory researchers [6, 13, 16, 29]; privacy researchers and investigative journalists [2, 10, 26, 28]; law scholars and social scientists [1, 3, 27]; governmental agencies and NGOs [24].", "startOffset": 209, "endOffset": 224}, {"referenceID": 8, "context": "Indeed, the notion of algorithmic fairness has captured the attention of a broad spectrum of experts: machine learning and theory researchers [6, 13, 16, 29]; privacy researchers and investigative journalists [2, 10, 26, 28]; law scholars and social scientists [1, 3, 27]; governmental agencies and NGOs [24].", "startOffset": 209, "endOffset": 224}, {"referenceID": 23, "context": "Indeed, the notion of algorithmic fairness has captured the attention of a broad spectrum of experts: machine learning and theory researchers [6, 13, 16, 29]; privacy researchers and investigative journalists [2, 10, 26, 28]; law scholars and social scientists [1, 3, 27]; governmental agencies and NGOs [24].", "startOffset": 209, "endOffset": 224}, {"referenceID": 25, "context": "Indeed, the notion of algorithmic fairness has captured the attention of a broad spectrum of experts: machine learning and theory researchers [6, 13, 16, 29]; privacy researchers and investigative journalists [2, 10, 26, 28]; law scholars and social scientists [1, 3, 27]; governmental agencies and NGOs [24].", "startOffset": 209, "endOffset": 224}, {"referenceID": 0, "context": "Indeed, the notion of algorithmic fairness has captured the attention of a broad spectrum of experts: machine learning and theory researchers [6, 13, 16, 29]; privacy researchers and investigative journalists [2, 10, 26, 28]; law scholars and social scientists [1, 3, 27]; governmental agencies and NGOs [24].", "startOffset": 261, "endOffset": 271}, {"referenceID": 2, "context": "Indeed, the notion of algorithmic fairness has captured the attention of a broad spectrum of experts: machine learning and theory researchers [6, 13, 16, 29]; privacy researchers and investigative journalists [2, 10, 26, 28]; law scholars and social scientists [1, 3, 27]; governmental agencies and NGOs [24].", "startOffset": 261, "endOffset": 271}, {"referenceID": 24, "context": "Indeed, the notion of algorithmic fairness has captured the attention of a broad spectrum of experts: machine learning and theory researchers [6, 13, 16, 29]; privacy researchers and investigative journalists [2, 10, 26, 28]; law scholars and social scientists [1, 3, 27]; governmental agencies and NGOs [24].", "startOffset": 261, "endOffset": 271}, {"referenceID": 15, "context": "1 The European Union (EU), for instance, has already begun regulating algorithmic decision-making [17].", "startOffset": 98, "endOffset": 102}, {"referenceID": 17, "context": "Like other probabilistic programming languages, our programming model is rich enough to subsume graphical models like Bayesian networks [19].", "startOffset": 136, "endOffset": 140}, {"referenceID": 14, "context": "[16]: Pr[hire | min] Pr[hire | \u00acmin] > 1\u2212", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": ", Church [18], R2 [23], and Stan [7], employ approximate inference techniques, like MCMC, which converge in the limit but offer no guarantees on how far we are from the exact result.", "startOffset": 9, "endOffset": 13}, {"referenceID": 21, "context": ", Church [18], R2 [23], and Stan [7], employ approximate inference techniques, like MCMC, which converge in the limit but offer no guarantees on how far we are from the exact result.", "startOffset": 18, "endOffset": 22}, {"referenceID": 6, "context": ", Church [18], R2 [23], and Stan [7], employ approximate inference techniques, like MCMC, which converge in the limit but offer no guarantees on how far we are from the exact result.", "startOffset": 33, "endOffset": 36}, {"referenceID": 7, "context": "In our work, we consider exact inference, which has primarily received attention in the Bayesian network setting, and boils down to solving a #SAT instance [8].", "startOffset": 156, "endOffset": 159}, {"referenceID": 12, "context": "The volume computation problem is a well-studied and hard problem [14, 20].", "startOffset": 66, "endOffset": 74}, {"referenceID": 18, "context": "The volume computation problem is a well-studied and hard problem [14, 20].", "startOffset": 66, "endOffset": 74}, {"referenceID": 3, "context": "Leveraging the great developments in satisfiabiltiy modulo theories (SMT) solvers [4], we developed a procedure that reduces the volume compuation problem to a series of colRank", "startOffset": 82, "endOffset": 85}, {"referenceID": 10, "context": "The tool uses the popular Z3 SMT solver [12] for manipulating first-order formulas over arithmetic theories.", "startOffset": 40, "endOffset": 44}, {"referenceID": 9, "context": "We have used FairSquare to prove or disprove fairness of a suite of population models and programs representing machine-learning classifiers that were automatically generated from real-world datasets used in other work on algorithmic fairness [11, 16, 29].", "startOffset": 243, "endOffset": 255}, {"referenceID": 14, "context": "We have used FairSquare to prove or disprove fairness of a suite of population models and programs representing machine-learning classifiers that were automatically generated from real-world datasets used in other work on algorithmic fairness [11, 16, 29].", "startOffset": 243, "endOffset": 255}, {"referenceID": 26, "context": "We have used FairSquare to prove or disprove fairness of a suite of population models and programs representing machine-learning classifiers that were automatically generated from real-world datasets used in other work on algorithmic fairness [11, 16, 29].", "startOffset": 243, "endOffset": 255}], "year": 2016, "abstractText": "We explore the following question: Is a decision-making program fair, for some useful definition of fairness? First, we describe how several algorithmic fairness questions can be phrased as program verification problems. Second, we discuss an automated verification technique for proving or disproving fairness of decision-making programs with respect to a model of the population.", "creator": "LaTeX with hyperref package"}}}