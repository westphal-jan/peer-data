{"id": "1610.06272", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Oct-2016", "title": "Lexicon Integrated CNN Models with Attention for Sentiment Analysis", "abstract": "With the advent of word embeddings, lexicons are no longer fully utilized for sentiment analysis although they still provide important features in the traditional setting. This paper introduces a novel approach to sentiment analysis that integrates lexicon embeddings and an attention mechanism into Convolutional Neural Networks. Our approach performs separate convolutions for word and lexicon embeddings and provides a global view of the document using attention. Our models are experimented on both the SemEval'16 Task 4 dataset and the Stanford Sentiment Treebank, and show comparative or better results against the existing state-of-the-art systems. Our analysis shows that lexicon embeddings allow to build high-performing models with much smaller word embeddings, and the attention mechanism effectively dims out noisy words for sentiment analysis.", "histories": [["v1", "Thu, 20 Oct 2016 03:10:57 GMT  (1899kb,D)", "http://arxiv.org/abs/1610.06272v1", null], ["v2", "Tue, 22 Aug 2017 21:21:30 GMT  (2144kb,D)", "http://arxiv.org/abs/1610.06272v2", "In Proceedings of the EMNLP Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, of WASSA'17, 2017"]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["bonggun shin", "timothy lee", "jinho d choi"], "accepted": false, "id": "1610.06272"}, "pdf": {"name": "1610.06272.pdf", "metadata": {"source": "CRF", "title": "Lexicon Integrated CNN Models with Attention for Sentiment Analysis", "authors": ["Bonggun Shin", "Timothy Lee", "Jinho D. Choi"], "emails": ["bonggun.shin@emory.edu", "timothy.lee@emory.edu", "jinho.choi@emory.edu"], "sections": [{"heading": "1 Introduction", "text": "Although the task of sentiment analysis is well researched (Mullen and Collier, 2004; Pang and Lee, 2005; Wilson et al., 2005), it is still very challenging due to the complexity of extracting human emotions from raw text. Recent advances in deep learning have clearly boosted the performance of this task (Socher et al., 2013; Kim, 2014; Yin and Guesses, 2015), although there is much more room to improve.In the traditional environment, where statistical models are based on sparse characteristics, lexicographs consisting of words and their sentiment results show that they are highly effective for sentiment analysis because they provide features that cannot be captured from training data (Hu and Liu, 2004; Kim and Hovy, 2004; Ding et al., 2008; Taboada et al., 2011)."}, {"heading": "2 Related Work", "text": "The first attempt at sentiment analysis on text was initiated by Pang et al. (2002), who propelled this field through the use of bag-of-word features. This work depended largely on feature engineering; since then, 1All of our resources have been publicly available: anonymous _ urlar Xiv: 161 0.06 272v 1 [cs.C L] 20 October 201 6many types of feature learning methods had been introduced to increase performance (Pang and Lee, 2008; Liu, 2012; Gimpel et al., 2011; Feldman, 2013; Mohammad et al., 2013b). Besides pure machine learning approaches, lexicon-based approaches were another trend that relied on manual or algorithmic creation of word entities (Hu and Liu, 2004; Kim and Hovy, 2004; Ding et al., 2008; Taboada et al., 2011).Since the emergence of neural networks (CNN; Collobert, al.)."}, {"heading": "3 Approach", "text": "The models proposed here are based on a wave architecture and use naive concatenation (Section 3.2.1), multi-channel (Section 3.2.2), separate wave formation (Section 3.2.3) and the embedding of attention (Section 3.3) for the integration of lexicon embedding into CNN."}, {"heading": "3.1 Baseline", "text": "Our basic approach is a single-layer CNN model using pre-trained word embedding, which is a slight modification of the CNN model introduced by Kim (2014). Let s-Rn-d be a matrix representing the input document, where n is the number of words, d is the dimension of the word embedding, and each line corresponds to the word embedding, wi-Rd, where wi is the i-th word in the document. This document matrix s is fed into the coil layer and entangled by the weights c-Rl-d, where l is the length of the filter. The coil layer can take m-number of filters of length l. Each fold creates a vector vc-Rn-l + 1, where elements in vc are transferred the L-gram characteristics through the entire document. The max-pooling layer selects the most prominent characteristics from each of the maximum filter vectors generated for this output layer Volm 1."}, {"heading": "3.2 Lexicon Integration", "text": "Each lexicon row consists of key-value pairs, where the key is a word and the value is a list of sentiment scores for that word (e.g. probabilities of the word in positive, neutral, and negative contexts).These scores range from \u2212 1 to 1, where \u2212 1 and 1 are the most negative or positive values, respectively. However, some lexicographs contain non-probable scores (e.g. word frequency numbers in sentimental contexts), which are normalized to [\u2212 1, 1].If w does not appear in certain rows, 0 values are assigned, where W is the union of all words in the lexicon rows, a lexicon embedding is constructed by linking all scores between the rows in relation to w."}, {"heading": "3.2.1 Naive Concatenation", "text": "The easiest way to embed a lexicon in its corresponding word embedding is to append it to the end of the word embedding (Figure 1 (a)). In formal notation, the document matrix is s-Rn \u00b7 (d + e)."}, {"heading": "3.2.2 Multichannel", "text": "Inspired by Yin and Schatz (2015), which integrated multiple types of word embedding using multi-channel CNN, lexicon embedding in this approach is presented in another channel, along with the word embedding channel in which both channels are intertwined (Figure 1 (b)). Since the dimension of lexicon embedding is considerably smaller than that of word embedding (i.e. d e), zeros are added to the lexicon embedding so that their dimensions (i.e. d = e) match. The identical shape of these two channels allows multi-channel embedding to the input document."}, {"heading": "3.2.3 Separate Convolution", "text": "Another way to add lexicon embeddings to the CNN model is to process a separate fold for them (Figure 1 (c)), in which case two individual turns are applied to Word embeddings and lexicon embeddings. The maximum bundled output characteristics of each fold are then merged into an input vector on the Softmax level. Formally, lw, lx should be the filter lengths for Word embeddings or lexicon embeddings, respectively. Let mw and mx be the number of filters for Word embeddings or lexicon embeddings, respectively. The resulting penultimate layer includes maximum pooled features from Word embeddings and lexicon embeddings of size [(n \u2212 lw + 1) \u00d7 mw] + [(n \u2212 lx + 1) \u00d7 mx]."}, {"heading": "3.3 Embedding Attention", "text": "Each CNN model uses multiple filters of different lengths; given the filter length l, the convolution of L-gram characteristics is taken into account. However, these L-gram characteristics only take into account local views, not the global view of the document required for multiple transition cases such as negation in the sensation analysis (Socher et al., 2012). To improve this problem, we introduce the embedded attention vector (EAV), which transforms the document matrix in each embedding space into a vector matrix. For example, the EAV matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix is weighted sum of each column in the document matrix s-Rn-d, giving a vector v-Rd. For each document, two EAVs matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix"}, {"heading": "4 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Corpora", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1.1 SemEval-2016 Task 4", "text": "All models are evaluated on the basis of the microblog dataset distributed by SemEval '16 Task 4a (Nakov et al., 2016), which is based on tweets with comments on three sentiment classes: positive, neutral and negative. The publicly available dataset contains only tweet IDs and their sentiment polarities; the actual tweet texts are not included in this dataset due to copyright restrictions. Although the download script provided by SemEval' 16 provides access to the actual texts on the web, some of the tweets are no longer accessible. To compensate for this loss, the dataset also contains tweet instances from the SemEval '13 task. Table 1 shows the statistics of the training, development and evaluation sets (TRN / DEV / TST). Classification results are evaluated on the average values of positive and negative feelings, as suggested by SemEval' 16 Task 4a."}, {"heading": "4.1.2 Stanford Sentiment Treebank", "text": "Another data set, consisting of film reviews from Rotten Tomatoes, is used to evaluate the robustness of our models across genres. This data set, called the Stanford Sentiment Treebank, was originally collected by Pang and Lee (2005) and later expanded by Socher et al. (2013). Mood comments in this data set are divided into five classes: very positive, positive, neutral, negative and very negative. Following the previous work (Kim, 2014), the results are evaluated on the basis of conventional classification accuracy."}, {"heading": "4.2 Embedding Construction", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.2.1 Word Embeddings", "text": "In order to best understand word semantics in each genre, different corpora are used to train word embeddings for the SemEval '16 (S16) and Stanford Sentiment Treebank (SST) datasets. For S16, word embeddings are trained on tweets collected by the Archive Team, 2 consisting of 3.67 million word types. For SST, word embeddings are trained on the Amazon Review dataset, 3 containing 2.67 million word types. All documents are pre-tokenized by the NLP4J.4 open source toolkit. Word embeddings are trained by the original implementation of word2vec by Google using Skip-gram and negative sampling.5 No explicit hyperparameter tuning is performed. For each genre, four sets of embeddings of different dimensions (50, 100, 200, 400) are trained to observe the impact of the embedsize on each approach."}, {"heading": "4.2.2 Lexicon Embeddings", "text": "Six types of sentiment lexicon are used to create lexicon embeddings for our experiments: \u2022 National Research Council Canada (NRC) Hashtag Affirmative and Negated Context Sentiment Lexicon (Kiritchenko et al., 2014). \u2022 NRC Hashtag Sentiment Lexicon (Mohammad et al., 2013a). \u2022 NRC Sentiment140 Lexicon (Kiritchenko et al., 2014). \u2022 Sentiment140 Lexicon (Mohammad et al., 2013a). \u2022 MaxDiff Twitter Sentiment Lexicon (Kiritchenko et al., 2014). \u2022 Bing Liu Opinion Lexicon (Hu and Liu, 2004).2archive.org / details / twittericon 3snap.stanford.edu / data / web-Amazon.html 4github.com / emorynlp / nlp4j 5code.google.com / p / word2vecons All of the associated sentiment lexixivons are associated with the respective Sentivity."}, {"heading": "4.3 Evaluation", "text": "It is evaluated to show the effectiveness of lexicon embedding in sentiment analysis: baseline (Section 3.1), naive concatenation (Section 3.2.1), multi-channel (Section 3.2.2), separate confrontation (Section 3.2.3), and the three integration concepts with embedding attention (Section 4.4.1). Comparisons of our proposed models with the previous state-of-the-art approach are outlined in Table 4.2.2. For all experiments, the specified random number of 1 is used to avoid performance enhancements from other countries (see Section 4.4.1 for more discussions). The following configuration is used for all models."}, {"heading": "4.4 Analysis", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.4.1 Randomness in Deep Learning", "text": "We observed that using different random seeds in training the CNN models could change the behavior of the models, sometimes by more than 1%. This is due to the randomness that comes with deep learning, such as randomly mixing the data sets, initializing the weights, and the drop-out rate of a tensor. To reduce the impact of random seeds on our results and to capture the overall characteristics of the model, we performed a group analysis by training each model with 10 different random seeds, as shown in Figure 4."}, {"heading": "4.4.2 S16: SemEval\u201916 Task 4", "text": "For S16, the lexicon integration reduces the discrepancies, and the introduction of attention vector embedding increases accuracy even higher than the models without it between different random seeds. Another notable observation of the models is that the multi-channel method, when fixed to a random seed as shown in Table 4.2.2, produces a competitive performance in group analysis. Such low performance of the multi-channel method with fixed random seed is probably due to the well-known problem of optimization, where local optimisation is caught."}, {"heading": "4.4.3 SST: Stanford Sentiment Treebank", "text": "Because the word embed data set comes from Twitter, it has less vocabulary on SST than S16, as in the right columns of Table 3. On the contrary, word embed coverage on SST is remarkably high at about 98%, whereas it is only about 70% for S16 (left columns of Table 3). These conditions are well reflected in the group analysis of the model in SST. Since word embeddings themselves are sufficient to cover the majority of words, the variance of the model is relatively small compared to S16. Although we hypothesized that adding a lexicon could reduce the performance of the SST task because many lexicographs come from tweets, our models successfully adopt exogenous characteristics and accuracy is increased."}, {"heading": "4.4.4 Learning Speed", "text": "Another advantage of the proposed model, PC-EAV, is that it speeds up the learning speed (Figure 6). A high F1 value can be achieved at an earlier stage if lexicon information is included along with EAV. This statement is general behavior, since the learning curves in Figure 6 are the result of an average of ten different learning attempts with different random seeds."}, {"heading": "4.4.5 Attention", "text": "EAV-enabled models perform better than non-EAV models, and we provide compelling explanatory information about the model. As observed in Figure 5, all negative words are weighted higher (Dart Red), while non-sentimental words such as Stop Words are not emphasized (Green and Light Blue). Our visual explanations are particularly desirable for neural network models because they provide a detailed insight into why the models work well."}, {"heading": "5 Conclusion", "text": "This paper suggests several approaches that effectively integrate lexicon embedding and an attention mechanism into a well-researched, deep learning system, Convolutional Neural Networks, for sentimental analysis. Our experiments show that lexicon integration can improve the accuracy, stability and efficiency of the traditional CNN model. Several training results with different random seeds demonstrate the overall effectiveness of using lexicon embedding and embedding attention vectors. Comparing the training curves shows another advantage of this integration for more robust learning. Attention heatmap analysis confirms that embedding attention vectors provides CNN models with explanatory properties, which gives a good understanding of how the CNN models work. The proposed attention models are applied to each single word. However, focusing on multiple words could provide more promising information. Applying the attention mechanism to multiple words at the same time is a majority of the work in this lexicon."}, {"heading": "Acknowledgments", "text": "We are grateful for the support of the University Research Committee Award and the Infosys Research Enhancement Grant. All content in this material is that of the authors and does not necessarily reflect the views of these prizes and scholarships. We thank Jung-Hyun Kang for producing most of the figures."}], "references": [{"title": "Neural machine translation by jointly learning to align and translate", "author": ["Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio."], "venue": "ICLR.", "citeRegEx": "Bahdanau et al\\.,? 2014", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2014}, {"title": "Abccnn: An attention based convolutional neural network for visual question answering", "author": ["Kan Chen", "Jiang Wang", "Liang-Chieh Chen", "Haoyuan Gao", "Wei Xu", "Ram Nevatia."], "venue": "arXiv preprint arXiv:1511.05960.", "citeRegEx": "Chen et al\\.,? 2015", "shortCiteRegEx": "Chen et al\\.", "year": 2015}, {"title": "Learning phrase representations using rnn encoder-decoder for statistical machine translation. EMNLP", "author": ["EAV. Schwenk", "Yoshua Bengio"], "venue": null, "citeRegEx": "Schwenk and Bengio.,? \\Q2014\\E", "shortCiteRegEx": "Schwenk and Bengio.", "year": 2014}, {"title": "Natural language processing (almost) from scratch", "author": ["Ronan Collobert", "Jason Weston", "L\u00e9on Bottou", "Michael Karlen", "Koray Kavukcuoglu", "Pavel Kuksa."], "venue": "Journal of Machine Learning Research, 12(Aug):2493\u20132537.", "citeRegEx": "Collobert et al\\.,? 2011", "shortCiteRegEx": "Collobert et al\\.", "year": 2011}, {"title": "Swisscheese at semeval-2016 task 4: Sentiment classification using an ensemble of convolutional neural networks with distant supervision", "author": ["Jan Deriu", "Maurice Gonzenbach", "Fatih Uzdilli", "Aurelien Lucchi", "Valeria De Luca", "Martin Jaggi."], "venue": "Pro-", "citeRegEx": "Deriu et al\\.,? 2016", "shortCiteRegEx": "Deriu et al\\.", "year": 2016}, {"title": "A holistic lexicon-based approach to opinion mining", "author": ["Xiaowen Ding", "Bing Liu", "Philip S Yu."], "venue": "Proceedings of the 2008 international conference on web search and data mining, pages 231\u2013240. ACM.", "citeRegEx": "Ding et al\\.,? 2008", "shortCiteRegEx": "Ding et al\\.", "year": 2008}, {"title": "Techniques and applications for sentiment analysis", "author": ["Ronen Feldman."], "venue": "Communications of the ACM, 56(4):82\u201389.", "citeRegEx": "Feldman.,? 2013", "shortCiteRegEx": "Feldman.", "year": 2013}, {"title": "Part-of-speech tagging for twitter: Annotation", "author": ["Kevin Gimpel", "Nathan Schneider", "Brendan O\u2019Connor", "Dipanjan Das", "Daniel Mills", "Jacob Eisenstein", "Michael Heilman", "Dani Yogatama", "Jeffrey Flanigan", "Noah A Smith"], "venue": null, "citeRegEx": "Gimpel et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Gimpel et al\\.", "year": 2011}, {"title": "Mining and summarizing customer reviews", "author": ["Minqing Hu", "Bing Liu."], "venue": "Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 168\u2013177. ACM.", "citeRegEx": "Hu and Liu.,? 2004", "shortCiteRegEx": "Hu and Liu.", "year": 2004}, {"title": "A convolutional neural network for modelling sentences", "author": ["Nal Kalchbrenner", "Edward Grefenstette", "Phil Blunsom."], "venue": "arXiv preprint arXiv:1404.2188.", "citeRegEx": "Kalchbrenner et al\\.,? 2014a", "shortCiteRegEx": "Kalchbrenner et al\\.", "year": 2014}, {"title": "A convolutional neural network for modelling sentences", "author": ["Nal Kalchbrenner", "Edward Grefenstette", "Phil Blunsom."], "venue": "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 655\u2013", "citeRegEx": "Kalchbrenner et al\\.,? 2014b", "shortCiteRegEx": "Kalchbrenner et al\\.", "year": 2014}, {"title": "Determining the sentiment of opinions", "author": ["Soo-Min Kim", "Eduard Hovy."], "venue": "Proceedings of the 20th international conference on Computational Linguistics, page 1367. Association for Computational Linguistics.", "citeRegEx": "Kim and Hovy.,? 2004", "shortCiteRegEx": "Kim and Hovy.", "year": 2004}, {"title": "Convolutional neural networks for sentence classification", "author": ["Yoon Kim."], "venue": "arXiv preprint arXiv:1408.5882.", "citeRegEx": "Kim.,? 2014", "shortCiteRegEx": "Kim.", "year": 2014}, {"title": "Sentiment analysis of short informal texts", "author": ["Svetlana Kiritchenko", "Xiaodan Zhu", "Saif M Mohammad."], "venue": "Journal of Artificial Intelligence Research, 50:723\u2013762.", "citeRegEx": "Kiritchenko et al\\.,? 2014", "shortCiteRegEx": "Kiritchenko et al\\.", "year": 2014}, {"title": "Distributed representations of sentences and documents", "author": ["Quoc V. Le", "Tomas Mikolov."], "venue": "Proceedings of the 31th International Conference on Machine Learning, ICML 2014, Beijing, China, 2126 June 2014, pages 1188\u20131196.", "citeRegEx": "Le and Mikolov.,? 2014", "shortCiteRegEx": "Le and Mikolov.", "year": 2014}, {"title": "Sentiment analysis and opinion mining", "author": ["Bing Liu."], "venue": "Synthesis lectures on human language technologies, 5(1):1\u2013167.", "citeRegEx": "Liu.,? 2012", "shortCiteRegEx": "Liu.", "year": 2012}, {"title": "Effective approaches to attentionbased neural machine translation", "author": ["Minh-Thang Luong", "Hieu Pham", "Christopher D Manning."], "venue": "EMNLP.", "citeRegEx": "Luong et al\\.,? 2015", "shortCiteRegEx": "Luong et al\\.", "year": 2015}, {"title": "Nrc-canada: Building the state-of-theart in sentiment analysis of tweets", "author": ["Saif Mohammad", "Svetlana Kiritchenko", "Xiaodan Zhu."], "venue": "Proceedings of the seventh international workshop on Semantic Evaluation Exercises (SemEval-2013), Atlanta,", "citeRegEx": "Mohammad et al\\.,? 2013a", "shortCiteRegEx": "Mohammad et al\\.", "year": 2013}, {"title": "Nrc-canada: Building the stateof-the-art in sentiment analysis of tweets", "author": ["Saif M Mohammad", "Svetlana Kiritchenko", "Xiaodan Zhu."], "venue": "arXiv preprint arXiv:1308.6242.", "citeRegEx": "Mohammad et al\\.,? 2013b", "shortCiteRegEx": "Mohammad et al\\.", "year": 2013}, {"title": "Sentiment analysis using support vector machines with diverse information sources", "author": ["Tony Mullen", "Nigel Collier."], "venue": "EMNLP, volume 4, pages 412\u2013 418.", "citeRegEx": "Mullen and Collier.,? 2004", "shortCiteRegEx": "Mullen and Collier.", "year": 2004}, {"title": "Semeval2016 task 4: Sentiment analysis in twitter", "author": ["Preslav Nakov", "Alan Ritter", "Sara Rosenthal", "Fabrizio Sebastiani", "Veselin Stoyanov."], "venue": "Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016), pages 1\u201318,", "citeRegEx": "Nakov et al\\.,? 2016", "shortCiteRegEx": "Nakov et al\\.", "year": 2016}, {"title": "Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales", "author": ["Bo Pang", "Lillian Lee."], "venue": "Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, pages 115\u2013124. Association for", "citeRegEx": "Pang and Lee.,? 2005", "shortCiteRegEx": "Pang and Lee.", "year": 2005}, {"title": "Opinion mining and sentiment analysis", "author": ["Bo Pang", "Lillian Lee."], "venue": "Foundations and trends in information retrieval, 2(1-2):1\u2013135.", "citeRegEx": "Pang and Lee.,? 2008", "shortCiteRegEx": "Pang and Lee.", "year": 2008}, {"title": "Thumbs up?: sentiment classification using machine learning techniques", "author": ["Bo Pang", "Lillian Lee", "Shivakumar Vaithyanathan."], "venue": "Proceedings of the ACL-02 conference on Empirical methods in natural language processing-Volume 10, pages 79\u201386. Asso-", "citeRegEx": "Pang et al\\.,? 2002", "shortCiteRegEx": "Pang et al\\.", "year": 2002}, {"title": "Sensei-lif at semeval-2016 task 4: Polarity embedding fusion for robust sentiment analysis", "author": ["Mickael Rouvier", "Benoit Favre."], "venue": "Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016), pages 202\u2013208, San Diego,", "citeRegEx": "Rouvier and Favre.,? 2016", "shortCiteRegEx": "Rouvier and Favre.", "year": 2016}, {"title": "Where to look: Focus regions for visual question answering", "author": ["Kevin J Shih", "Saurabh Singh", "Derek Hoiem."], "venue": "CVPR.", "citeRegEx": "Shih et al\\.,? 2016", "shortCiteRegEx": "Shih et al\\.", "year": 2016}, {"title": "Semantic compositionality through recursive matrix-vector spaces", "author": ["Richard Socher", "Brody Huval", "Christopher D Manning", "Andrew Y Ng."], "venue": "Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Com-", "citeRegEx": "Socher et al\\.,? 2012", "shortCiteRegEx": "Socher et al\\.", "year": 2012}, {"title": "Recursive deep models for semantic compositionality over a sentiment treebank", "author": ["Richard Socher", "Alex Perelygin", "Jean Y Wu", "Jason Chuang", "Christopher D Manning", "Andrew Y Ng", "Christopher Potts."], "venue": "Proceedings of the conference on", "citeRegEx": "Socher et al\\.,? 2013", "shortCiteRegEx": "Socher et al\\.", "year": 2013}, {"title": "Deep networks with internal selective attention through feedback connections", "author": ["Marijn F Stollenga", "Jonathan Masci", "Faustino Gomez", "J\u00fcrgen Schmidhuber."], "venue": "Advances in Neural Information Processing Systems, pages 3545\u20133553.", "citeRegEx": "Stollenga et al\\.,? 2014", "shortCiteRegEx": "Stollenga et al\\.", "year": 2014}, {"title": "Lexiconbased methods for sentiment analysis", "author": ["Maite Taboada", "Julian Brooke", "Milan Tofiloski", "Kimberly Voll", "Manfred Stede."], "venue": "Computational linguistics, 37(2):267\u2013307.", "citeRegEx": "Taboada et al\\.,? 2011", "shortCiteRegEx": "Taboada et al\\.", "year": 2011}, {"title": "Recognizing contextual polarity in phraselevel sentiment analysis", "author": ["Theresa Wilson", "Janyce Wiebe", "Paul Hoffmann."], "venue": "Proceedings of the conference on human language technology and empirical methods in natural language processing, pages", "citeRegEx": "Wilson et al\\.,? 2005", "shortCiteRegEx": "Wilson et al\\.", "year": 2005}, {"title": "Show, attend and tell: Neural image caption generation with visual attention", "author": ["Kelvin Xu", "Jimmy Ba", "Ryan Kiros", "Kyunghyun Cho", "Aaron Courville", "Ruslan Salakhutdinov", "Richard S Zemel", "Yoshua Bengio."], "venue": "International Conference for Ma-", "citeRegEx": "Xu et al\\.,? 2015", "shortCiteRegEx": "Xu et al\\.", "year": 2015}, {"title": "bunji at semeval-2016 task 5: Neural and syntactic models of entity-attribute relationship for aspect-based sentiment analysis", "author": ["Toshihiko Yanase", "Kohsuke Yanai", "Misa Sato", "Toshinori Miyoshi", "Yoshiki Niwa."], "venue": "Proceedings of SemEval, pages 289\u2013", "citeRegEx": "Yanase et al\\.,? 2016", "shortCiteRegEx": "Yanase et al\\.", "year": 2016}, {"title": "Stacked attention networks for image question answering", "author": ["Zichao Yang", "Xiaodong He", "Jianfeng Gao", "Li Deng", "Alex Smola."], "venue": "CVPR.", "citeRegEx": "Yang et al\\.,? 2016", "shortCiteRegEx": "Yang et al\\.", "year": 2016}, {"title": "An exploration of embeddings for generalized phrases", "author": ["Wenpeng Yin", "Hinrich Sch\u00fctze."], "venue": "ACL (Student Research Workshop), pages 41\u201347.", "citeRegEx": "Yin and Sch\u00fctze.,? 2014", "shortCiteRegEx": "Yin and Sch\u00fctze.", "year": 2014}, {"title": "Multichannel variable-size convolution for sentence classification", "author": ["Wenpeng Yin", "Hinrich Sch\u00fctze."], "venue": "Proceedings of the Nineteenth Conference on Computational Natural Language Learning, pages 204\u2013214, Beijing, China, July. Association for", "citeRegEx": "Yin and Sch\u00fctze.,? 2015", "shortCiteRegEx": "Yin and Sch\u00fctze.", "year": 2015}, {"title": "Evaluation set results of the proposed models in comparison to the state-of-the-art approaches. Deriu et al. (2016): the first place for the SemEval\u201916 task 4a using an ensemble of two CNN models. Rouvier and Favre (2016): the second place for the SemEval\u201916 task 4a using various embeddings in CNN", "author": ["Kalchbrenner"], "venue": null, "citeRegEx": "49", "shortCiteRegEx": "49", "year": 2014}], "referenceMentions": [{"referenceID": 19, "context": "Although the task of sentiment analysis has been well-explored (Mullen and Collier, 2004; Pang and Lee, 2005; Wilson et al., 2005), it is still very challenging due to the complexity of extracting human emotion from raw text.", "startOffset": 63, "endOffset": 130}, {"referenceID": 21, "context": "Although the task of sentiment analysis has been well-explored (Mullen and Collier, 2004; Pang and Lee, 2005; Wilson et al., 2005), it is still very challenging due to the complexity of extracting human emotion from raw text.", "startOffset": 63, "endOffset": 130}, {"referenceID": 30, "context": "Although the task of sentiment analysis has been well-explored (Mullen and Collier, 2004; Pang and Lee, 2005; Wilson et al., 2005), it is still very challenging due to the complexity of extracting human emotion from raw text.", "startOffset": 63, "endOffset": 130}, {"referenceID": 27, "context": "The recent advance of deep learning has definitely elevated the performance of this task (Socher et al., 2013; Kim, 2014; Yin and Sch\u00fctze, 2015) although there is much more room to improve.", "startOffset": 89, "endOffset": 144}, {"referenceID": 12, "context": "The recent advance of deep learning has definitely elevated the performance of this task (Socher et al., 2013; Kim, 2014; Yin and Sch\u00fctze, 2015) although there is much more room to improve.", "startOffset": 89, "endOffset": 144}, {"referenceID": 35, "context": "The recent advance of deep learning has definitely elevated the performance of this task (Socher et al., 2013; Kim, 2014; Yin and Sch\u00fctze, 2015) although there is much more room to improve.", "startOffset": 89, "endOffset": 144}, {"referenceID": 8, "context": "In the traditional setting where statistical models are based on sparse features, lexicons consisting of words and their sentiment scores are shown to be highly effective for sentiment analysis because they provide features that may not be captured from training data (Hu and Liu, 2004; Kim and Hovy, 2004; Ding et al., 2008; Taboada et al., 2011).", "startOffset": 268, "endOffset": 347}, {"referenceID": 11, "context": "In the traditional setting where statistical models are based on sparse features, lexicons consisting of words and their sentiment scores are shown to be highly effective for sentiment analysis because they provide features that may not be captured from training data (Hu and Liu, 2004; Kim and Hovy, 2004; Ding et al., 2008; Taboada et al., 2011).", "startOffset": 268, "endOffset": 347}, {"referenceID": 5, "context": "In the traditional setting where statistical models are based on sparse features, lexicons consisting of words and their sentiment scores are shown to be highly effective for sentiment analysis because they provide features that may not be captured from training data (Hu and Liu, 2004; Kim and Hovy, 2004; Ding et al., 2008; Taboada et al., 2011).", "startOffset": 268, "endOffset": 347}, {"referenceID": 29, "context": "In the traditional setting where statistical models are based on sparse features, lexicons consisting of words and their sentiment scores are shown to be highly effective for sentiment analysis because they provide features that may not be captured from training data (Hu and Liu, 2004; Kim and Hovy, 2004; Ding et al., 2008; Taboada et al., 2011).", "startOffset": 268, "endOffset": 347}, {"referenceID": 12, "context": "similar to Kim (2014). Three ways of lexicon integration to the CNN model are proposed, which show distinctive characteristics for different genres (Section 3.", "startOffset": 11, "endOffset": 22}, {"referenceID": 23, "context": "The first attempt of sentiment analysis on text was initiated by Pang et al. (2002) who pioneered this field by using bag-of-word features.", "startOffset": 65, "endOffset": 84}, {"referenceID": 22, "context": "many kinds of feature learning methods had been introduced to increase the performance (Pang and Lee, 2008; Liu, 2012; Gimpel et al., 2011; Feldman, 2013; Mohammad et al., 2013b).", "startOffset": 87, "endOffset": 178}, {"referenceID": 15, "context": "many kinds of feature learning methods had been introduced to increase the performance (Pang and Lee, 2008; Liu, 2012; Gimpel et al., 2011; Feldman, 2013; Mohammad et al., 2013b).", "startOffset": 87, "endOffset": 178}, {"referenceID": 7, "context": "many kinds of feature learning methods had been introduced to increase the performance (Pang and Lee, 2008; Liu, 2012; Gimpel et al., 2011; Feldman, 2013; Mohammad et al., 2013b).", "startOffset": 87, "endOffset": 178}, {"referenceID": 6, "context": "many kinds of feature learning methods had been introduced to increase the performance (Pang and Lee, 2008; Liu, 2012; Gimpel et al., 2011; Feldman, 2013; Mohammad et al., 2013b).", "startOffset": 87, "endOffset": 178}, {"referenceID": 18, "context": "many kinds of feature learning methods had been introduced to increase the performance (Pang and Lee, 2008; Liu, 2012; Gimpel et al., 2011; Feldman, 2013; Mohammad et al., 2013b).", "startOffset": 87, "endOffset": 178}, {"referenceID": 8, "context": "Aside from pure machine learning approaches, lexicon based approaches had been another trend, which relied on the manual or algorithmic creation of word sentiment scores (Hu and Liu, 2004; Kim and Hovy, 2004; Ding et al., 2008; Taboada et al., 2011).", "startOffset": 170, "endOffset": 249}, {"referenceID": 11, "context": "Aside from pure machine learning approaches, lexicon based approaches had been another trend, which relied on the manual or algorithmic creation of word sentiment scores (Hu and Liu, 2004; Kim and Hovy, 2004; Ding et al., 2008; Taboada et al., 2011).", "startOffset": 170, "endOffset": 249}, {"referenceID": 5, "context": "Aside from pure machine learning approaches, lexicon based approaches had been another trend, which relied on the manual or algorithmic creation of word sentiment scores (Hu and Liu, 2004; Kim and Hovy, 2004; Ding et al., 2008; Taboada et al., 2011).", "startOffset": 170, "endOffset": 249}, {"referenceID": 29, "context": "Aside from pure machine learning approaches, lexicon based approaches had been another trend, which relied on the manual or algorithmic creation of word sentiment scores (Hu and Liu, 2004; Kim and Hovy, 2004; Ding et al., 2008; Taboada et al., 2011).", "startOffset": 170, "endOffset": 249}, {"referenceID": 12, "context": "The first success of CNN in sentiment analysis was triggered by document classification research (Kim, 2014), where CNN showed state-of-the-art results in numerous document classification datasets.", "startOffset": 97, "endOffset": 108}, {"referenceID": 3, "context": "Since the emergence of the Convolutional Neural Networks (CNN; Collobert et al. (2011)), conventional methods have become gradually obsolete because of the outstanding performance from the CNN variants.", "startOffset": 63, "endOffset": 87}, {"referenceID": 3, "context": "Since the emergence of the Convolutional Neural Networks (CNN; Collobert et al. (2011)), conventional methods have become gradually obsolete because of the outstanding performance from the CNN variants. CNN based models are distinguished from earlier methods because they do not rely on laborious feature engineering. The first success of CNN in sentiment analysis was triggered by document classification research (Kim, 2014), where CNN showed state-of-the-art results in numerous document classification datasets. This success has engendered an upsurge in deep neural network research for sentiment analysis. Various modified models have been proposed in the literature. One of the famous deep learning methods that models a document is the generalized phrase proposed by Yin and Sch\u00fctze (2014), which represents a sentence using element-wise addition, multiplication, or recursive auto-encoder.", "startOffset": 63, "endOffset": 797}, {"referenceID": 3, "context": "Endeavors to capture n-gram information bore fruits with CNN, max pooling, and softmax (Collobert et al., 2011; Kim, 2014), which is regarded as the standard methods of the document classification problem these days.", "startOffset": 87, "endOffset": 122}, {"referenceID": 12, "context": "Endeavors to capture n-gram information bore fruits with CNN, max pooling, and softmax (Collobert et al., 2011; Kim, 2014), which is regarded as the standard methods of the document classification problem these days.", "startOffset": 87, "endOffset": 122}, {"referenceID": 3, "context": "Endeavors to capture n-gram information bore fruits with CNN, max pooling, and softmax (Collobert et al., 2011; Kim, 2014), which is regarded as the standard methods of the document classification problem these days. Kalchbrenner et al. (2014a)", "startOffset": 88, "endOffset": 245}, {"referenceID": 12, "context": "Multichannel CNN methods (Kim, 2014; Yin and Sch\u00fctze, 2015) are another branch of CNN, where assorted embeddings are considered together when convolving the input.", "startOffset": 25, "endOffset": 59}, {"referenceID": 35, "context": "Multichannel CNN methods (Kim, 2014; Yin and Sch\u00fctze, 2015) are another branch of CNN, where assorted embeddings are considered together when convolving the input.", "startOffset": 25, "endOffset": 59}, {"referenceID": 12, "context": "Multichannel CNN methods (Kim, 2014; Yin and Sch\u00fctze, 2015) are another branch of CNN, where assorted embeddings are considered together when convolving the input. Unlike Kim (2014)\u2019s model that relies on a single type of embedding with different mutability characteristics of the weights of embedding layer, Yin and Sch\u00fctze (2015) incorporates diverse sort of embedding types using multichannel CNN.", "startOffset": 26, "endOffset": 182}, {"referenceID": 12, "context": "Multichannel CNN methods (Kim, 2014; Yin and Sch\u00fctze, 2015) are another branch of CNN, where assorted embeddings are considered together when convolving the input. Unlike Kim (2014)\u2019s model that relies on a single type of embedding with different mutability characteristics of the weights of embedding layer, Yin and Sch\u00fctze (2015) incorporates diverse sort of embedding types using multichannel CNN.", "startOffset": 26, "endOffset": 332}, {"referenceID": 17, "context": "Two notable pioneers in using lexicon for sentiment analysis are Mohammad and Kiritchenko, who usedautomatically generated scores with other manually generated sentiment lexicon scores to achieved the state-of-the-art result in SemEval2013 Twitter sentiment analysis task (Mohammad et al., 2013a; Kalchbrenner et al., 2014b).", "startOffset": 272, "endOffset": 324}, {"referenceID": 10, "context": "Two notable pioneers in using lexicon for sentiment analysis are Mohammad and Kiritchenko, who usedautomatically generated scores with other manually generated sentiment lexicon scores to achieved the state-of-the-art result in SemEval2013 Twitter sentiment analysis task (Mohammad et al., 2013a; Kalchbrenner et al., 2014b).", "startOffset": 272, "endOffset": 324}, {"referenceID": 8, "context": "In general domain, Liu generated a user review lexicon that showed promising result in capturing sentiment in customer product reviews (Hu and Liu, 2004).", "startOffset": 135, "endOffset": 153}, {"referenceID": 28, "context": "Attention based methods have been successful in many application domains, such as image classification (Stollenga et al., 2014), image caption generation (Xu et al.", "startOffset": 103, "endOffset": 127}, {"referenceID": 31, "context": ", 2014), image caption generation (Xu et al., 2015), machine translation (Cho et al.", "startOffset": 34, "endOffset": 51}, {"referenceID": 0, "context": ", 2015), machine translation (Cho et al., 2014; Bahdanau et al., 2014; Luong et al., 2015), and question answering (Shih et al.", "startOffset": 29, "endOffset": 90}, {"referenceID": 16, "context": ", 2015), machine translation (Cho et al., 2014; Bahdanau et al., 2014; Luong et al., 2015), and question answering (Shih et al.", "startOffset": 29, "endOffset": 90}, {"referenceID": 25, "context": ", 2015), and question answering (Shih et al., 2016; Chen et al., 2015; Yang et al., 2016).", "startOffset": 32, "endOffset": 89}, {"referenceID": 1, "context": ", 2015), and question answering (Shih et al., 2016; Chen et al., 2015; Yang et al., 2016).", "startOffset": 32, "endOffset": 89}, {"referenceID": 33, "context": ", 2015), and question answering (Shih et al., 2016; Chen et al., 2015; Yang et al., 2016).", "startOffset": 32, "endOffset": 89}, {"referenceID": 32, "context": "However, in the field of sentiment analysis, the attention is applied to only aspect-based sentiment classification (Yanase et al., 2016).", "startOffset": 116, "endOffset": 137}, {"referenceID": 12, "context": "Our baseline approach is a one-layer CNN model using pre-trained word embeddings, which is a minor modification of the CNN model introduced by Kim (2014). Let s \u2208 Rn\u00d7d be a matrix representing the input document, where n is the number of words, d is the dimension of the word embeddings, and each row corresponds to the word embedding, wi \u2208 Rd, where wi indicates the i\u2019th word in the document.", "startOffset": 143, "endOffset": 154}, {"referenceID": 34, "context": "Inspired by Yin and Sch\u00fctze (2015) who integrated several kinds of word embeddings using multichannel CNN, lexicon embeddings in this approach are represented in another channel along with the word embedding channel where both channels are con-", "startOffset": 12, "endOffset": 35}, {"referenceID": 26, "context": "However, these l-gram features account only for local views, not the global view of the document, which is necessary for several transitional cases such as negation in sentiment analysis (Socher et al., 2012).", "startOffset": 187, "endOffset": 208}, {"referenceID": 20, "context": "All models are evaluated on the micro-blog dataset distributed by the SemEval\u201916 Task 4a (Nakov et al., 2016).", "startOffset": 89, "endOffset": 109}, {"referenceID": 12, "context": "Following the previous work (Kim, 2014), the results are evaluated by the conventional classification accuracy.", "startOffset": 28, "endOffset": 39}, {"referenceID": 20, "context": "This dataset, called the Stanford Sentiment Treebank, was originally collected by Pang and Lee (2005) and later extended by Socher et al.", "startOffset": 82, "endOffset": 102}, {"referenceID": 20, "context": "This dataset, called the Stanford Sentiment Treebank, was originally collected by Pang and Lee (2005) and later extended by Socher et al. (2013). The sentiment annotation in this dataset is categorized into five classes: very positive, positive, neutral, negative, and very negative.", "startOffset": 82, "endOffset": 145}, {"referenceID": 13, "context": "\u2022 National Research Council Canada (NRC) Hashtag Affirmative and Negated Context Sentiment Lexicon (Kiritchenko et al., 2014).", "startOffset": 99, "endOffset": 125}, {"referenceID": 17, "context": "\u2022 NRC Hashtag Sentiment Lexicon (Mohammad et al., 2013a).", "startOffset": 32, "endOffset": 56}, {"referenceID": 13, "context": "\u2022 NRC Sentiment140 Lexicon (Kiritchenko et al., 2014).", "startOffset": 27, "endOffset": 53}, {"referenceID": 17, "context": "\u2022 Sentiment140 Lexicon (Mohammad et al., 2013a).", "startOffset": 23, "endOffset": 47}, {"referenceID": 13, "context": "\u2022 MaxDiff Twitter Sentiment Lexicon (Kiritchenko et al., 2014).", "startOffset": 36, "endOffset": 62}, {"referenceID": 8, "context": "\u2022 Bing Liu Opinion Lexicon (Hu and Liu, 2004).", "startOffset": 27, "endOffset": 45}, {"referenceID": 4, "context": "Comparing the baseline to SC, lexicon embeddings significantly improved accuracy for S16, about 2%, surpassing the previous state-of-the-art result achieved by Deriu et al. (2016). However, SC did not show much improvement for SST where the baseline was already performing well.", "startOffset": 160, "endOffset": 180}, {"referenceID": 34, "context": "8% lower than the state-of-the-art result achieved by Yin and Sch\u00fctze (2015); however, considering their model uses five embedding channels and dual-layer convolutions whereas our model uses a single channel and a single-layer convolution, in other words, our model is much more compact, this is very promising.", "startOffset": 54, "endOffset": 77}], "year": 2016, "abstractText": "With the advent of word embeddings, lexicons are no longer fully utilized for sentiment analysis although they still provide important features in the traditional setting. This paper introduces a novel approach to sentiment analysis that integrates lexicon embeddings and an attention mechanism into Convolutional Neural Networks. Our approach performs separate convolutions for word and lexicon embeddings and provides a global view of the document using attention. Our models are experimented on both the SemEval\u201916 Task 4 dataset and the Stanford Sentiment Treebank, and show comparative or better results against the existing state-of-the-art systems. Our analysis shows that lexicon embeddings allow to build high-performing models with much smaller word embeddings, and the attention mechanism effectively dims out noisy words for sentiment analysis.", "creator": "TeX"}}}