{"id": "1610.06488", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Oct-2016", "title": "An Evolving Neuro-Fuzzy System with Online Learning/Self-learning", "abstract": "An architecture of a new neuro-fuzzy system is proposed. The basic idea of this approach is to tune both synaptic weights and membership functions with the help of the supervised learning and self-learning paradigms. The approach to solving the problem has to do with evolving online neuro-fuzzy systems that can process data under uncertainty conditions. The results prove the effectiveness of the developed architecture and the learning procedure.", "histories": [["v1", "Thu, 20 Oct 2016 16:29:40 GMT  (335kb)", "http://arxiv.org/abs/1610.06488v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.NE", "authors": ["yevgeniy v bodyanskiy", "oleksii k tyshchenko", "anastasiia o deineko"], "accepted": false, "id": "1610.06488"}, "pdf": {"name": "1610.06488.pdf", "metadata": {"source": "CRF", "title": "An Evolving Neuro-Fuzzy System with Online Learning/Self-learning", "authors": ["Yevgeniy V. Bodyanskiy", "Anastasiia O. Deineko"], "emails": ["bodya@kture.kharkov.ua", "anastasiya.deineko}@gmail.com"], "sections": [{"heading": null, "text": "This year, it is as far as ever in the history of the city, where it is as far as never before."}], "references": [{"title": "Neural Networks for Optimization and Signal Processing", "author": ["A. Cichocki", "R. Unbehauen"], "venue": "Stuttgart: Teubner", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1993}, {"title": "Neural Networks: A Comprehensive Foundation", "author": ["S. Haykin"], "venue": "Upper Saddle River, New Jersey: Prentice Hall", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1999}, {"title": "Artificial Neural Networks", "author": ["R.J. Schalkoff"], "venue": "New York: The McGraw-Hill Comp.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1997}, {"title": "Principles of Artificial Neural Networks (Advanced Series in Circuits and Systems)", "author": ["D. Graupe"], "venue": "Singapore: World Scientific Publishing Co. Pte. Ltd.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2007}, {"title": "Artificial Neural Networks: Architectures and Applications", "author": ["K. Suzuki"], "venue": "NY: InTech", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "Artificial Neural Networks in Biological and Environmental Analysis", "author": ["G. Hanrahan"], "venue": "NW: CRC Press", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "Neural Networks and Statistical Learning", "author": ["K.-L. Du", "M.N.S. Swamy"], "venue": "London: Springer-Verlag", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "Artificial Neural Network Based Control Strategies for Paddy Drying Process", "author": ["S.F. Lilhare", "N.G. Bawane"], "venue": "Int. J. Information Technology and Computer Science, vol. 6, no. 11", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "Integrated Model of DNA Sequence Numerical Representation and Artificial Neural Network for Human Donor and Acceptor Sites Prediction", "author": ["M. Abo-Zahhad", "S.M. Ahmed", "S.A. Abd-Elrahman"], "venue": "Int. J. Information Technology and Computer Science, vol. 6, no. 8", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Long Range Forecast on South West Monsoon Rainfall using Artificial Neural Networks based on Clustering Approach", "author": ["M.L. Pai", "K.V. Pramod", "A.N. Balchand"], "venue": "Int. J. Information Technology and Computer Science, vol. 6, no. 7", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}, {"title": "Computational Intelligence", "author": ["L. Rutkowski"], "venue": "Methods and Tehniques. Berlin-Heidelberg: Springer-Verlag", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2008}, {"title": "Neuro-Fuzzy and Soft Computing: A Computational Approach to Learning and Maching Intelligence", "author": ["J.-S. Jang", "C.-T. Sun", "E. Mizutani"], "venue": "Upper Saddle River, N.J.: Prentice Hall", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1997}, {"title": "Computational Intelligence", "author": ["C.L. Mumford", "L.C. Jain"], "venue": "Berlin: Springer-Verlag", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2009}, {"title": "Computational Intelligence", "author": ["R. Kruse", "C. Borgelt", "F. Klawonn", "C. Moewes", "M. Steinbrecher", "P. Held"], "venue": "A Methodological Introduction. Berlin: Springer-Verlag", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}, {"title": "Fuzzy basis functions", "author": ["L.-X. Wang", "J.M. Mendel"], "venue": "universal approximation and orthogonal least squares learning\u201d, in IEEE Trans. on Neural Networks, vol. 3", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1993}, {"title": "Neuro-fuzzy algorithms", "author": ["K.J. Cios", "W. Pedrycz"], "venue": "Oxford: IOP Publishing Ltd and Oxford University Press", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1997}, {"title": "The Elements of Statistical Learning", "author": ["J. Friedman", "T. Hastie", "R. Tibshirani"], "venue": "Data Mining, Inference and Prediction. Berlin: Springer", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2003}, {"title": "Sieci neuronowe do przetwarzania informacji", "author": ["S. Osowski"], "venue": "Warszawa: Oficijna Wydawnicza Politechniki Warszawskiej", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2006}, {"title": "Evolving Connectionist Systems", "author": ["N. Kasabov"], "venue": "London: Springer-Verlag", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2003}, {"title": "Evolving Fuzzy Systems \u2013 Methodologies", "author": ["E. Lughofer"], "venue": "Advanced Concepts and Applications. Berlin-Heidelberg: Springer- Verlag", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2011}, {"title": "Evolving cascaded neural network based on multidimensional Epanechnikov\u2019s kernels and its learning algorithm,", "author": ["Ye. Bodyanskiy", "P. Grimm", "N. Teslenko"], "venue": "in Int. J. Information Technologies and Knowledge,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2011}, {"title": "Evolving Intelligent Systems: Methodology and Applications", "author": ["P. Angelov", "D. Filev", "N. Kasabov"], "venue": "New York: John Wiley and Sons", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2010}, {"title": "Evolving Connectionist Systems: The Knowledge Engineering Approach", "author": ["N. Kasabov"], "venue": "London: Springer-Verlag", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2007}, {"title": "Evolving fuzzy neural networks for supervised/unsupervised online knowledge-based learning", "author": ["N.K. Kasabov"], "venue": "IEEE Transactions on Systems, Man and Cybernetics, Part B: Cybernetics, no. 31(6)", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2001}, {"title": "DENFIS: Dynamic evolving neural-fuzzy inference system and its application for time-series prediction", "author": ["N.K. Kasabov", "Q. Song"], "venue": "IEEE Transactions on Fuzzy Systems, no. 10(2)", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2002}, {"title": "FLEXFIS: A robust incremental learning approach for evolving TS fuzzy models", "author": ["E. Lughofer"], "venue": "IEEE Transactions on Fuzzy Systems, no. 16(6)", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2008}, {"title": "Deineko, \u201cAdaptive learning of the RBFN architecture and parameters", "author": ["A.A. Ye.V. Bodyanskiy"], "venue": "in System Technologies,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2013}, {"title": "The evolving radial-basis neural network and its learning with the help of the Kohonen map", "author": ["Ye.V. Bodyanskiy", "A.A. Deineko"], "venue": "in Proc. Sci. Conf. \u00abInformation Technologies in Metallurgy and Mechanical Engineering\u00bb,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2013}, {"title": "The problem of organizing and partition large data sets in learning algorithms for SOM-RBF mixed structure", "author": ["J.A. Torres", "S. Martinez", "F.J. Martinez", "M. Peralta"], "venue": "Proc. 5 Int. Joint Conf. on Computational Intelligence", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2013}, {"title": "Self-Organizing Maps", "author": ["T. Kohonen"], "venue": "Berlin: Springer-Verlag", "citeRegEx": "30", "shortCiteRegEx": null, "year": 1995}, {"title": "Nonlinear System Identification", "author": ["O. Nelles"], "venue": "Berlin: Springer", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2001}, {"title": "An adaptive learning algorithm for a neuro-fuzzy network", "author": ["Ye. Bodyanskiy", "V. Kolodyazhniy", "A. Stephan"], "venue": "Computational Intelligence. Theory and Applications,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2001}, {"title": "Ye", "author": ["P. Otto"], "venue": "Bodyanskiy, and V. Kolodyazhniy, \u201cA new learning algorithm for a forecasting neuro-fuzzy network\u201d, in Integrated Computer-Aided Engeneering, vol. 10, no. 4", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2003}, {"title": "Artificial Neural Networks: Architectures, Learning, Applications", "author": ["Ye.V. Bodyanskiy", "\u041e.G. Rudenko"], "venue": "Kharkiv: \u0422\u0415L\u0415\u0422\u0415H,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2004}, {"title": "Oscillation and chaos in physiological control systems", "author": ["M.C. Mackey", "L. Glass"], "venue": "Science, no. 197", "citeRegEx": "35", "shortCiteRegEx": null, "year": 1977}], "referenceMentions": [{"referenceID": 0, "context": "under conditions of uncertainty, nonlinearity, stochasticity and chaoticity, various kinds of disturbance and noise [1-10].", "startOffset": 116, "endOffset": 122}, {"referenceID": 1, "context": "under conditions of uncertainty, nonlinearity, stochasticity and chaoticity, various kinds of disturbance and noise [1-10].", "startOffset": 116, "endOffset": 122}, {"referenceID": 2, "context": "under conditions of uncertainty, nonlinearity, stochasticity and chaoticity, various kinds of disturbance and noise [1-10].", "startOffset": 116, "endOffset": 122}, {"referenceID": 3, "context": "under conditions of uncertainty, nonlinearity, stochasticity and chaoticity, various kinds of disturbance and noise [1-10].", "startOffset": 116, "endOffset": 122}, {"referenceID": 4, "context": "under conditions of uncertainty, nonlinearity, stochasticity and chaoticity, various kinds of disturbance and noise [1-10].", "startOffset": 116, "endOffset": 122}, {"referenceID": 5, "context": "under conditions of uncertainty, nonlinearity, stochasticity and chaoticity, various kinds of disturbance and noise [1-10].", "startOffset": 116, "endOffset": 122}, {"referenceID": 6, "context": "under conditions of uncertainty, nonlinearity, stochasticity and chaoticity, various kinds of disturbance and noise [1-10].", "startOffset": 116, "endOffset": 122}, {"referenceID": 7, "context": "under conditions of uncertainty, nonlinearity, stochasticity and chaoticity, various kinds of disturbance and noise [1-10].", "startOffset": 116, "endOffset": 122}, {"referenceID": 8, "context": "under conditions of uncertainty, nonlinearity, stochasticity and chaoticity, various kinds of disturbance and noise [1-10].", "startOffset": 116, "endOffset": 122}, {"referenceID": 9, "context": "under conditions of uncertainty, nonlinearity, stochasticity and chaoticity, various kinds of disturbance and noise [1-10].", "startOffset": 116, "endOffset": 122}, {"referenceID": 10, "context": "Neuro-fuzzy systems (NFSs) have more potential compared to neural networks [11-16], which combine learning capabilities, universal approximating properties and linguistic transparency of the results.", "startOffset": 75, "endOffset": 82}, {"referenceID": 11, "context": "Neuro-fuzzy systems (NFSs) have more potential compared to neural networks [11-16], which combine learning capabilities, universal approximating properties and linguistic transparency of the results.", "startOffset": 75, "endOffset": 82}, {"referenceID": 12, "context": "Neuro-fuzzy systems (NFSs) have more potential compared to neural networks [11-16], which combine learning capabilities, universal approximating properties and linguistic transparency of the results.", "startOffset": 75, "endOffset": 82}, {"referenceID": 13, "context": "Neuro-fuzzy systems (NFSs) have more potential compared to neural networks [11-16], which combine learning capabilities, universal approximating properties and linguistic transparency of the results.", "startOffset": 75, "endOffset": 82}, {"referenceID": 14, "context": "Neuro-fuzzy systems (NFSs) have more potential compared to neural networks [11-16], which combine learning capabilities, universal approximating properties and linguistic transparency of the results.", "startOffset": 75, "endOffset": 82}, {"referenceID": 15, "context": "Neuro-fuzzy systems (NFSs) have more potential compared to neural networks [11-16], which combine learning capabilities, universal approximating properties and linguistic transparency of the results.", "startOffset": 75, "endOffset": 82}, {"referenceID": 16, "context": "At the same time, to avoid gaps in the input space generated by scatter partitioning [17] which is used in ANFIS and TSK-systems, the parameters\u2019 tuning of membership functions is performed in the NFS\u2019s first hidden layer.", "startOffset": 85, "endOffset": 89}, {"referenceID": 17, "context": "The backpropagation algorithm is used for this purpose which is implemented with the help of multi-epochs learning [18].", "startOffset": 115, "endOffset": 119}, {"referenceID": 18, "context": "The idea of evolving computational systems is very popular nowadays with Data Mining scientists [19-26].", "startOffset": 96, "endOffset": 103}, {"referenceID": 19, "context": "The idea of evolving computational systems is very popular nowadays with Data Mining scientists [19-26].", "startOffset": 96, "endOffset": 103}, {"referenceID": 20, "context": "The idea of evolving computational systems is very popular nowadays with Data Mining scientists [19-26].", "startOffset": 96, "endOffset": 103}, {"referenceID": 21, "context": "The idea of evolving computational systems is very popular nowadays with Data Mining scientists [19-26].", "startOffset": 96, "endOffset": 103}, {"referenceID": 22, "context": "The idea of evolving computational systems is very popular nowadays with Data Mining scientists [19-26].", "startOffset": 96, "endOffset": 103}, {"referenceID": 23, "context": "The idea of evolving computational systems is very popular nowadays with Data Mining scientists [19-26].", "startOffset": 96, "endOffset": 103}, {"referenceID": 24, "context": "The idea of evolving computational systems is very popular nowadays with Data Mining scientists [19-26].", "startOffset": 96, "endOffset": 103}, {"referenceID": 25, "context": "The idea of evolving computational systems is very popular nowadays with Data Mining scientists [19-26].", "startOffset": 96, "endOffset": 103}, {"referenceID": 26, "context": "To control the RBFN activation functions\u2019 parameters (centers and matrix receptive fields) in an online mode, it was proposed in [27-29] to use the self-organizing Kohonen map [30], which provides these parameters\u2019 tuning in the self-learning process in an online mode.", "startOffset": 129, "endOffset": 136}, {"referenceID": 27, "context": "To control the RBFN activation functions\u2019 parameters (centers and matrix receptive fields) in an online mode, it was proposed in [27-29] to use the self-organizing Kohonen map [30], which provides these parameters\u2019 tuning in the self-learning process in an online mode.", "startOffset": 129, "endOffset": 136}, {"referenceID": 28, "context": "To control the RBFN activation functions\u2019 parameters (centers and matrix receptive fields) in an online mode, it was proposed in [27-29] to use the self-organizing Kohonen map [30], which provides these parameters\u2019 tuning in the self-learning process in an online mode.", "startOffset": 129, "endOffset": 136}, {"referenceID": 29, "context": "To control the RBFN activation functions\u2019 parameters (centers and matrix receptive fields) in an online mode, it was proposed in [27-29] to use the self-organizing Kohonen map [30], which provides these parameters\u2019 tuning in the self-learning process in an online mode.", "startOffset": 176, "endOffset": 180}, {"referenceID": 30, "context": "T h x k x k x k x k \uf06a \uf06a \uf06a \uf06a \uf03d It\u2019s easy to notice that the proposed system implements a nonlinear mapping of the input space into a scalar output signal like the normalized RBFN [31].", "startOffset": 178, "endOffset": 182}, {"referenceID": 14, "context": "the Wang \u2013 Mendel architecture [15].", "startOffset": 31, "endOffset": 35}, {"referenceID": 31, "context": "a learning algorithm which possesses both tracking and smoothing properties [32, 33] \uf028 \uf029 \uf028 \uf029 \uf028 \uf029 \uf028 \uf029 \uf028 \uf029 \uf028 \uf029 \uf028 \uf029 \uf028 \uf029 \uf028 \uf029 \uf028 \uf029 \uf028 \uf029 \uf028 \uf029 \uf028 \uf029 \uf028 \uf029 1", "startOffset": 76, "endOffset": 84}, {"referenceID": 32, "context": "a learning algorithm which possesses both tracking and smoothing properties [32, 33] \uf028 \uf029 \uf028 \uf029 \uf028 \uf029 \uf028 \uf029 \uf028 \uf029 \uf028 \uf029 \uf028 \uf029 \uf028 \uf029 \uf028 \uf029 \uf028 \uf029 \uf028 \uf029 \uf028 \uf029 \uf028 \uf029 \uf028 \uf029 1", "startOffset": 76, "endOffset": 84}, {"referenceID": 30, "context": "and similar procedures, including the well-known linear identification procedures [31].", "startOffset": 82, "endOffset": 86}, {"referenceID": 29, "context": "Kohonen [30] but there\u2019s a slight difference that the \u00abwinner\u00bb on each axis can belong to membership functions with different indexes l .", "startOffset": 8, "endOffset": 12}, {"referenceID": 33, "context": "In a common case, one can use an estimate which was proposed for the traditional Kohonen map [34]: \uf028 \uf029 \uf028 \uf029 \uf028 \uf029 1", "startOffset": 93, "endOffset": 97}, {"referenceID": 34, "context": "TIME-SERIES FORECASTING WITH THE HELP OF THE PROPOSED NEURO-FUZZY SYSTEM In our experiment we used a signal generated by the Mackey-Glass equation [35] which is a non-linear differential equation", "startOffset": 147, "endOffset": 151}, {"referenceID": 0, "context": "It should be noticed that the prediction results\u2019 validation was performed in such a way: the system returned a result vector whose values were in the range [0,1] as well as the input vector\u2019s values, and then values of this output vector with the help of the quadratic error criterion were compared to actual values.", "startOffset": 157, "endOffset": 162}], "year": 2016, "abstractText": "A new neuro-fuzzy system\u2019s architecture and a learning method that adjusts its weights as well as automatically determines a number of neurons, centers\u2019 location of membership functions and the receptive field\u2019s parameters in an online mode with high processing speed is proposed in this paper. The basic idea of this approach is to tune both synaptic weights and membership functions with the help of the supervised learning and self-learning paradigms. The approach to solving the problem has to do with evolving online neuro-fuzzy systems that can process data under uncertainty conditions. The results proves the effectiveness of the developed architecture and the learning procedure.", "creator": "PScript5.dll Version 5.2.2"}}}