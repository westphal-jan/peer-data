{"id": "1610.06856", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Oct-2016", "title": "Automated Big Text Security Classification", "abstract": "In recent years, traditional cybersecurity safeguards have proven ineffective against insider threats. Famous cases of sensitive information leaks caused by insiders, including the WikiLeaks release of diplomatic cables and the Edward Snowden incident, have greatly harmed the U.S. government's relationship with other governments and with its own citizens. Data Leak Prevention (DLP) is a solution for detecting and preventing information leaks from within an organization's network. However, state-of-art DLP detection models are only able to detect very limited types of sensitive information, and research in the field has been hindered due to the lack of available sensitive texts. Many researchers have focused on document-based detection with artificially labeled \"confidential documents\" for which security labels are assigned to the entire document, when in reality only a portion of the document is sensitive. This type of whole-document based security labeling increases the chances of preventing authorized users from accessing non-sensitive information within sensitive documents. In this paper, we introduce Automated Classification Enabled by Security Similarity (ACESS), a new and innovative detection model that penetrates the complexity of big text security classification/detection. To analyze the ACESS system, we constructed a novel dataset, containing formerly classified paragraphs from diplomatic cables made public by the WikiLeaks organization. To our knowledge this paper is the first to analyze a dataset that contains actual formerly sensitive information annotated at paragraph granularity.", "histories": [["v1", "Fri, 21 Oct 2016 16:53:09 GMT  (1912kb,D)", "http://arxiv.org/abs/1610.06856v1", "Pre-print of Best Paper Award IEEE Intelligence and Security Informatics (ISI) 2016 Manuscript"]], "COMMENTS": "Pre-print of Best Paper Award IEEE Intelligence and Security Informatics (ISI) 2016 Manuscript", "reviews": [], "SUBJECTS": "cs.CR cs.AI cs.CL cs.CY", "authors": ["khudran alzhrani", "ethan m rudd", "terrance e boult", "c edward chow"], "accepted": false, "id": "1610.06856"}, "pdf": {"name": "1610.06856.pdf", "metadata": {"source": "CRF", "title": "Automated Big Text Security Classification", "authors": ["Khudran Alzhrani", "Ethan M. Rudd", "Terrance E. Boult", "Edward Chow"], "emails": ["kalzhran@uccs.edu", "cchow@uccs.edu", "erudd@vast.uccs.edu", "tboult@vast.uccs.edu"], "sections": [{"heading": null, "text": "This year, it will be able to fix the mentioned bugs."}, {"heading": "II. RELATED WORK", "text": "While the use of statistical analysis to detect sensitive texts is relatively new, several techniques have been proposed to question the actual performance of tweets. Katz et al. [6] used the k-mean algorithm on kosine- 1 -ar Xiv: 161 0.06 856v 1 [cs.C R] October 21, 201 6similarity to group all documents in a corpus, regardless of their sensitivity level. They then assigned a confidentiality value to each document by calculating the confidential term probability. Alneyadi et al. [7] used L1 standards [8] between the ngram category profiles and assigned the document to the shortest distance category. Hart et al. [9] proposed a new training method to overcome the problem of unbalanced data by implementing class-specific classifiers. Gomez-Hidalgoy et al. [10] suggested the use of benchmark recognition to detect \"sensitive tweets.\""}, {"heading": "III. A PROTOTYPICAL DLP FRAMEWORK", "text": "During the discovery phase, blank data is located at rest by remote scanning of the target device with a scanning agent [13]. This blank data is passed on to the Detection Module of DLP for sensitivity assessment, and the data is then labeled according to the sensitivity level detected. Depending on the sensitivity level detected, the data is either transmitted to untrusted channels or sent to the Protection Module. Protection can protect sensitive data in different ways and can handle data in transit and at rest in different ways. For example, sensitive data could be encrypted during transit, a security officer could be alerted, or the transmission could be stopped. On the other hand, for data at rest, the DLP Protection Module can perform encryption and change access rights."}, {"heading": "IV. LEARNING THE SECRETS", "text": "It is a way in which the individual groups as a whole can differ when they select their respective characters in large and distinct paragraphs. We assume that one solution to this problem is to divide the datasets into several smaller groups, such as splitting the WikiLeaks datasets into several smaller groups and establishing a classification for each group. This approach also has the advantage of examining smaller groups of features for each group that allow a principled selection of security features. One way to do this is to do the group of similar paragraphs in several smaller groups."}, {"heading": "V. THE WIKILEAKS DATASET", "text": "WikiLeaks is an organization that collects and publishes leaked sensitive documents. WikiLeaks gained particular notoriety when it released sensitive U.S. diplomatic cables dated between 2003 and February 2010, the largest collection of leaked sensitive documents ever distributed by the organization. These cables came from U.S. embassies and consulates around the world and are stored on the WikiLeaks website in static HTML format, mixed and sorted according to their origin data. By reorganizing these documents based on their geographical locations, we were able to create several different sets of related cables - one per message. We then removed the HTML tags and categorized each of the paragraphs in relation to three fields: a UID consisting of sender, recipient and time stamp; the raw text itself; and the classification label. We then divided the classifications into three categories: Unclassified, Confidential, and Secret Data Files should be classified as confidential, for example, we classify them as ORASASASASS, because of the constraint of the meta / labels, and the ORASS."}, {"heading": "VI. EXPERIMENTAL EVALUATION", "text": "In this area, we believe that the majority of people who work for the rights of minorities have the same rights as the majority of people who work for the rights of minorities, and in this area we believe that the rights of minorities and the rights of minorities and minorities are fully protected."}, {"heading": "VII. DISCUSSION", "text": "The fact that ACESS exceeds baseline algorithms suggests that several classifiers trained in locally derived feature spaces are more discriminatory for the type of sensitive data contained in the WikiLeaks datasets than a single monolithic classifier trained in a globally learned feature space. Equivalent seems to be the aggregation of all paragraphs under a single TFIDF representation dampening the local signal. In our assessments, we could not solve this by non-linearity in the classifier alone, as kernel SVMs do not statistically significantly improve performance in TF-IDF space.Instead, ACESS achieves superior classification performance by directing the query into the correct cluster, then performing a local, fine-grained classification using the feature space and the decision boundary of that cluster. In this respect, clustering serves as a loose form of theme modeling, and an alternative approach, such as introducing lateral analysis, could result in a lateral sectarian space."}, {"heading": "VIII. CONCLUSION", "text": "To our knowledge, the WikiLeaks dataset is the first dataset available to the research community that actually contains sensitive information; the dataset is labeled with multiple levels of sensitivity per paragraph, and we hope it will be useful to future researchers; our experiments show compelling evidence that ACESS can improve the accuracy of generalized machine-learned DLP detection modules by synthesizing both local and global characteristic spatial information; the integration of the ACESS model into DLP systems ensures consistency of labeling by instantly recognizing sensitive documents; we have proven that even with an enormous amount of textual information, it is possible to identify different levels of sensitivity within a document; and the automation of the security classification of paragraphs maximizes access to unclassified or public texts that exist alongside sensitive ones."}], "references": [], "referenceMentions": [], "year": 2016, "abstractText": "In recent years, traditional cybersecurity safeguards have proven ineffective against insider threats. Famous cases of sensitive information leaks caused by insiders, including the WikiLeaks release of diplomatic cables and the Edward Snowden incident, have greatly harmed the U.S. government\u2019s relationship with other governments and with its own citizens. Data Leak Prevention (DLP) is a solution for detecting and preventing information leaks from within an organization\u2019s network. However, state-of-art DLP detection models are only able to detect very limited types of sensitive information, and research in the field has been hindered due to the lack of available sensitive texts. Many researchers have focused on document-based detection with artificially labeled \u201cconfidential documents\u201d for which security labels are assigned to the entire document, when in reality only a portion of the document is sensitive. This type of whole-document based security labeling increases the chances of preventing authorized users from accessing non-sensitive information within sensitive documents. In this paper, we introduce Automated Classification Enabled by Security Similarity (ACESS), a new and innovative detection model that penetrates the complexity of big text security classification/detection. To analyze the ACESS system, we constructed a novel dataset, containing formerly classified paragraphs from diplomatic cables made public by the WikiLeaks organization. To our knowledge this paper is the first to analyze a dataset that contains actual formerly sensitive information annotated at paragraph granularity.", "creator": "LaTeX with hyperref package"}}}