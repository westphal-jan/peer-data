{"id": "1610.06912", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Oct-2016", "title": "KGEval: Estimating Accuracy of Automatically Constructed Knowledge Graphs", "abstract": "Automatic construction of large knowledge graphs (KG) by mining web-scale text datasets has received considerable attention over the last few years, resulting in the construction of several KGs, such as NELL, Google Knowledge Vault, etc. These KGs consist of thousands of predicate-relations (e.g., isPerson, isMayorOf ) and millions of their instances (e.g., (Bill de Blasio, isMayorOf, New York City)). Estimating accuracy of such automatically constructed KGs is a challenging problem due to their size and diversity. Even though crowdsourcing is an obvious choice for such evaluation, the standard single-task crowdsourcing, where each predicate in the KG is evaluated independently, is very expensive and especially problematic if the budget available is limited. We show that such approaches are sub-optimal as they ignore dependencies among various predicates and their instances. To overcome this challenge, we propose Relational Crowdsourcing (RelCrowd), where the tasks are created while taking dependencies among predicates and instances into account. We apply this framework in the context of evaluation of large-scale KGs and demonstrate its effectiveness through extensive experiments on real-world datasets.", "histories": [["v1", "Fri, 21 Oct 2016 19:49:19 GMT  (1116kb,D)", "http://arxiv.org/abs/1610.06912v1", null], ["v2", "Thu, 1 Dec 2016 06:45:34 GMT  (2493kb,D)", "http://arxiv.org/abs/1610.06912v2", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["prakhar ojha", "partha talukdar"], "accepted": false, "id": "1610.06912"}, "pdf": {"name": "1610.06912.pdf", "metadata": {"source": "CRF", "title": "Relational Crowdsourcing and its Application in Knowledge Graph Evaluation", "authors": ["Prakhar Ojha", "Partha P Talukdar"], "emails": ["prakhar.ojha@csa.iisc.ernet.in", "ppt@serc.iisc.in"], "sections": [{"heading": "1. INTRODUCTION", "text": "In recent years, significant advances have been made in the automatic construction of knowledge graphs such as NELL [30], Yago [37], Knowledge-Vault [10], etc., extracting information from web documents and embedding it in coherent knowledge graphs (KGs). Such KGs contain hundreds of predicate relationships (e.g., city, stadiumLocatedInCity) and millions of instances called beliefs (e.g., Joe Luis Arena, stadiumLocatedInCity, Detroit). Due to shortcomings in the automatic models and the unreliability of web documents, many of these beliefs can be communicated in the KG."}, {"heading": "Motivating example", "text": "In fact, the fact is that we are able to assert ourselves, that we are able, we will be able, we will be able, we will be able, we will be able, we will be able, \"he said."}, {"heading": "2. RELATIONAL CROWDSOURCING", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Notations", "text": "The notations used in the thesis are summarized in Table 1. In this section we provide brief descriptions of each Q. We get a set of n, categorization modes, Human Intelligence Tasks (HITs) H = {h1,.., hn} and a total budget B. Each HIT-Hi-H is a binary classification task whose crowdsourcing costs c (hi).R +. Mapping function l (hi).0, 1} returns the value of the evaluation label of hi, more general l ({h1.., ht}) \u2192 {0, 1} t provide binary labels for set. Label for hi could be either gold expert label lg (hi) or its estimate lu (hi) returned as by noisy crowdworkers.We also have access to a set of coupling constraints C = (Ci, \u03b8i)}, where each coupling constraint Ci forces the consistency of judgement designations."}, {"heading": "2.2 Problem of Relational Crowdsourcing", "text": "Using the above notation, it should be noted that \u03a6 (H) is the average categorization correction 2 if all HITs in H are categorized using experts. Unfortunately, computing \u03a6 (H) is not feasible in most application scenarios, since evaluating all HITs in H can be prohibitively expensive, i.e., the resulting derivative quantity I (G, Q, B) provides the best estimate of (H) among all possible choices of Q, while remaining within the crowdsourcing budget. This can be formulated as follows: arg min Q'H-Q = a smaller subset of HITs Q'H-H of crowdsourcing budgets, so that the resulting derivative quantity I (G, Q, E) provides the best estimate of (H) among all possible choices of Q while remaining within the crowdsourcing budget."}, {"heading": "3. EVALUATION OF KNOWLEDGE GRAPHS USING RelCrowd", "text": "In this section, we describe how the ECG evaluation can be presented as an example of Relational Crowdsourcing, where each HIT attempts to categorize a belief (an edge in KG) into right or wrong. In view of a number of evaluated HITs, Q, \u03a6 (I (G, Q) is the accuracy of the corresponding beliefs in their inferior quantity, whereas \u03a6 (H) is the general gold accuracy of the entire KG. We would like to estimate this unknown quantity by crowdsourcing a small subset Q, which is identified by optimizing the RelCrowd target represented in Equation (1). To solve the RelCrowd target in the context of the KG evaluation, we proceed as follows: \u2022 We first create a new graph, the Evaluation Coupling Graph (Ecoupling Graph), which integrates the KGK and the coupling constraints into a structure."}, {"heading": "3.1 Evaluation Coupling Constraints", "text": "In fact, most of them are not a real solution, but a strategy that has worked in practice."}, {"heading": "3.2 Evaluation Coupling Graph (ECG) Construction", "text": "Considering the set of HIT H and the coupling constraints C, we construct a graph with two types of nodes: (1) one node for each HIT h-H and (2) one node for each constraint c-C. The node of the constraint is connected to all HIT nodes that operate over. We call this graph Evaluation Coupling Graph (ECG), represented as G = (H-C, E) with the set of undirected edges E = {(c, h) | h-H, c-C, h-dome (c)}. Please note that the EKGG is in fact a split factor graph, where HIT nodes correspond to variable nodes and coupling constraints correspond to nodes that correspond to factor nodes. Example of an EKGG constructed from the node system is the coupling constraint C illustrated with | C | = 8 in Figure 2."}, {"heading": "3.3 Inference Mechanism", "text": "In fact, it is as if it is a matter of a way in which people are able to survive themselves. (...) It is as if they were able to survive themselves. (...) It is as if they were able to survive themselves. (...) It is as if they were able to survive themselves. (...) It is as if they were able to survive themselves. (...) It is as if they were able to survive themselves. (...) It is as if they were able to survive themselves. (...) It is as if they were able to survive themselves. (...) It is as if they were able to survive themselves. (...) It is as if they were able to survive themselves. (...) It is as if they are able to survive themselves. (...) It is as if they are able to survive themselves."}, {"heading": "3.4 Control Mechanism", "text": "In view of a partially evaluated ECG, the control mechanism aims to select the next group of HITs to be evaluated by the crowd. However, before going into the details of the control mechanism, we list some characteristics relating to RelCrowd optimization in Equation (1)."}, {"heading": "Submodularity", "text": "Theorem 1: The function optimized by RelCrowd (Equation (1)) using the PSL-based inference mechanism as described in Section 3.3 is submodular [29].Intuitively, the amount of additional benefit achieved by adding an HIT to a larger group is lower than by adding it to a smaller group. This can be demonstrated by observing that all pairs of HITs meet the regularity state [16] [22] and by using the assumption of [20], which is proven later in [31]. See Section 9 for detailed proof. Algorithm 1: RelCrowd: Knowledge Graph Evaluation using RelCrowdRequire: H: HITs, C: Coupling Constraints, B: Budget to be allocated, S: Seed Set, c (h): HIT Cost Function, \u03a6: HIT Categorization Score aggregator1: ECG = BuildG (2), C: QE (4): QE (QE) 1: QE (4)."}, {"heading": "NP-Hardness", "text": "Theorem 2 The problem of selecting the optimal solution in the RelCrowd optimization (equation (1)) is NP-Hard.This can be proved by showing that NP-complete set-cover problem (SCP) can be reduced to selecting Q, which covers I (G, Q, \u044b) (see Equation (1))."}, {"heading": "Control Mechanism", "text": "Fortunately, we know from the classical results of [33] that greedy mountaineering algorithms solve such a maximization problem with an approximation factor of (1 \u2212 1 / e) \u2248 63% of the optimal solution. Therefore, we use a greedy strategy as a control mechanism. This greedy strategy uses the PSL-based inference mechanism to iteratively select the next HIT, which is likely to cause the greatest increase in cumulative intangible target size. More details will be presented in the next section."}, {"heading": "3.5 Bringing it all together: RelCrowd-KGE", "text": "Following all the above observations, we present RelCrowdKGE in Algorithm 1, a greedy algorithm that uses Relational Crowdsourcing in the context of the evaluation of knowledge graphs. In Algorithm 1, we first get a set of all beliefs H by kg, we have access to coupling constraints C that bind the HITs of H, evidence seed sets S and H for which we apriori have gold markings available, cost functions, allocated budget and a score aggregator. In lines 4-14, we repeatedly execute our inference mechanism until the budget is exhausted or all HITs are covered. In each iteration, the HIT is executed with the largest inferentialized and evaluated parameters of the inference machine. In lines 4-14, we execute our inference mechanism until the budget is exhausted or all HITs are covered."}, {"heading": "4. ANALYSIS: BUDGET ALLOCATION FOR NOISY WORKERS", "text": "In the discussion so far, we have not addressed the problem that the labels provided by workers can be noisy. (Q =) Therefore, one must redundantly pass the same task on to multiple workers and estimate its accuracy by aggregating all the answers. (In this section, we provide limits on the number of workers who should evaluate a given task.) We are assuming here a rational assumption, which is also widespread in the literature, that the employee's response could attribute their true views and the noise to innocent mistakes or lack of specific expertise. (H) This assumption, together with the widely accepted notion of the \"wisdom of the masses,\" leads us to a stronger conclusion that the expectation of the answers rh (u) for a task h of workers is closer to the golden truth Gh [40]. Formally, we are forced to perform this task. (H, u) \u2212 Gh (G) \u2212 hc (4) in relation to the distribution of workers."}, {"heading": "5. EXPERIMENTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "HIT set #Correct #Incorrect Gold Acc.", "text": "In order to evaluate Relational Crowdsourcing (RelCrowd) in the context of the evaluation of knowledge graphs, we examine the following questions in this section: \u2022 How effective is RelCrowd compared to other competitive baselines while using a limited budget? (see Section 5.3) \u2022 How robust is RelCrowd in the belief data set? (see Section 5.5) \u2022 Do more coupling constraints contribute to improving the performance of RelCrowd? (see Section 5.6)"}, {"heading": "5.1 Setup", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Datasets", "text": "We experimented with the following datasets in this paper. Statistics of the used dataset, their true accuracy, and the number of coupling constraints used are presented in Table 2. \u2022 NELL: From NELL4, we chose a relatively denser subset of sports-related facts, which largely related to athletes, coaches, teams, leagues, stadiums, etc. \u2022 Yago2: We also chose a coupling constraint that set CN using some top PRA inference rules [25] along with domain and range information from the predicate signatures of ontology. \u2022 Yago25: We also chose a Yago25 sample dataset that, unlike the NELL subset above, is not domain-specific. [12] We used AMIE horn clauses [12] to construct multirelational coupling constraints CY for Yago ECG. To ensure consistency in our two datasets, we included them naturally, although we did not include them in the original CY."}, {"heading": "Crowdsourcing of HITs", "text": "To compare predictions of algorithms with human ratings, we posted all HITs (HN-HY) on MTurk. To get high-quality answers and make the work easier, we used ontology to translate each triple extraction into human-readable format. For example, (Joe Louis Arena, homeStadiumOf, Red Wings) was depicted in HITs as \"Stadium Joe.\""}, {"heading": "4 http://rtw.ml.cmu.edu/rtw/resources", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5 https://www.mpi-inf.mpg.de/departments/ databases-and-information-systems/research/", "text": "yago-naga / Louis Arena is the home stadium of the Red Wings sports team. \"In order to capture even more strange cases of machine extractions that might not make sense to an abstracted worker, we have given the opportunity to classify facts as\" ambiguous, \"which we ourselves later clearly identified. To help workers in case they were unsure of the answer, hyperlinks to the web search have been provided. Figure 3 shows an example of HIT published on AMT. Our focus in this work is not to address the conventional problem of truthfulness assessment of noisy crowdsourcing workers. We resort to simple majority decision techniques for structurally rich relational crowdsourcing in our analysis of noisy workers. For our experiments, we consider votes of master workers for {HN-HY} as gold labels, which we would like our inference algorithm to be able to predict. However, we also recognize some highly developed techniques, such as those proposed by the majority."}, {"heading": "Inference Engine", "text": "Since each HIT in our case can only be either true or false, we set an additional functional constraint on the soft inference values to ensure that the probability of label association is 1, i.e., P (l (h) = true) = 1 \u2212 P (h) = false. We also take rule weights with maximum probability. We use the initial evidence provided for learning latecomers via normalized horn clauses. Cold Start Problem: Algorithm 1 assumes that we get few rated HITs S as initial seeds."}, {"heading": "Performance Evaluation Metrics", "text": "In order to quantify the performance of algorithms, we measure them using the following indicators. We define \"AccMicro\" collectively over the entire KG, without any differentiation in HITs, and \"AccMacro\" as an average of \"AccMicro\" over each of the R \"predicate relations\" of the KG. Formally, \"AccMicro\" = \u03a6 (H) - 1 (H) - 1 (H) - \"AccMacro = 1 (R) - 1 (N) - 1 (Hr) - 1 (H)))), where\" (H) \"is the measure of accuracy we want to estimate from our baselines (see section 2.1) and\" l (h) is the baseline label assignment. \"AccMicro\" treats the entire knowledge diagram as a bag of HITs, while \"AccMacro\" separates tasks based on the edge type in the KGK and calculates mean precision over all such relationship types."}, {"heading": "5.2 Baseline Methods", "text": "Sampling from structurally rich multi-relational graphs such as KGs in our environment is a relatively unexplored problem. Below, we present only a few competing baselines that we have compared with RelCrowd."}, {"heading": "Random baseline", "text": "We randomly selected each HIT h-H and crowdsourced its accuracy. Selecting each subsequent HIT was another independent random selection that was repeated until the budget was exhausted. Results were averaged over a few such random sequences of studies."}, {"heading": "Max-Degree selection", "text": "We have reclassified the HITs to G based on their degrees and selected the HITs from above in order to evaluate them. Due to the step-by-step order, this method first prefers the selection of more centrally connected HITs. Note that there is no idea of derivative sets in these two baselines. Individual HITs are selected and their ratings are added individually to calculate the accuracy of KG."}, {"heading": "Independent Cascade propagation", "text": "This method is based on the contagion model of social networks, in which nodes infect their immediate neighbors. [20] Here, all logistical constraints of the first order C are transformed into mere neighborhood relationships. Since there is no idea of prioritization, all constraints are weighted evenly. In each iteration, we chose H, which has the highest number of neighboring HITs not included in the consequential Group I (G, Qt \u2212 1, Hht, HT). Your crowdsourcing rating is added to Qt and we let them perform their categorization (rating) on neighboring HITs in the ECG. This process repeats until the entire budget is exhausted or all nodes are covered in the ECG.We can imagine this baseline as a simplification of RelCrowd, where all relationships are ignored and the set inference derived from it is just neighborhood propagation."}, {"heading": "RelCrowd", "text": "This is the method proposed in the paper, which is described in Algorithm 1. In addition to horn clause and typo constraints, we used two additional negation rules for each class. These rules state that no fact should be accepted as true (or false) unless there is evidence for it. In other words, these rules provide regulatory protection against predictions. Their weighting is learned with maximum probability against initial evidence S, as explained above."}, {"heading": "5.3 Is RelCrowd Effective at Estimating KG Accuracy with Limited Budget?", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Micro Accuracy", "text": "Experimental results comparing all methods of estimating micro-accuracy in two sets of data - NELL and Yago2 - are presented in Table 4. The number of HITs evaluated (# queries) is a direct indicator of the budget spent by the respective methods. It is clear from this table that RelCrowd is able to be close to each other among all the methods compared.5 Due to the significant positive bias in the Yago dataset, random converges initially to almost zero micro-accuracy difference. However, because random does not provide stop criteria, it soon deviates with higher accuracy difference and ultimately requires much more HIT evaluation to converge back to zero error, while evaluating the smallest amount of HITs. Random selection and max degrees are naive methods that are unable to identify any structure in our problem and completely ignore constraints C, resulting in many more queries."}, {"heading": "Macro Accuracy", "text": "As in the case of micro-accuracy described above, we find that RelCrowd significantly outperforms all other methods, and these experiments show that RelCrowd effectively expands the labels of crowdsourcing tasks, not just by treating them as a single set of disordered tasks. This granular information is particularly useful in question-and-answer applications. Unlike RelCrowd and random baseline, which seem to be narrow in evaluation metrics, Figure 5 shows predicate errors over NELL data sets. It is obvious that RelCrowd appreciates accuracy more extensively."}, {"heading": "Stopping Criteria", "text": "A highly desirable feature of RelCrowd is that it has a stop criterion - the algorithm stops further evaluation as soon as all HIT is covered, i.e. all beliefs of RelCrowd are part of the derivative sentence. Independent cascade is the only other method that also has stop criteria. However, as we have seen, it requires much more HIT evaluations than RelCrowd. By contrast, due to its wavy nature of convergence and high variance (in the case of Random), Random and Max degrees do not lead to a concrete termination step until the budget is exhausted. Based on the coverage-based stop criteria, RelCrowd can detect that further HIT evaluations are stopped, even if additional budget is available."}, {"heading": "Budget Saved", "text": "In analyzing the reduction in the number of questions asked to the crowd, it is observed that RelCrowd outperforms all other baselines by huge margins: the random baseline can take between 2.5 and 4.4x, the maximum degree between 2.7x and 9.1x, and the independent cascade between 1.6x and 3.1x more crowd-sourced questions to match their respective accuracy estimates."}, {"heading": "5.4 How Effective is the Control Mechanism in isolation?", "text": "We experimented with Random-RelCrowd and Max-Grad-RelCrowd by replacing only the greedy step of algorithm 1 with the respective selection euristics. We observed that the random selection resulted in a 1.1-fold budget increase, while the maximum degree converged within 1.05x. Although the final convergent values were within an acceptable range (\u00b1 0.05%), we would like to emphasize that theoretical guarantees are only given via Greedy-RelCrowd and not via other baselines. It is always possible to construct contrary ECGs that perform poorly with the maximum or random selection."}, {"heading": "5.5 How Robust is RelCrowd to Noise in KG Beliefs?", "text": "To investigate the adaptability and robustness of different algorithms in the presence of noise, we evaluated all methods using noisy variants of the NELL dataset."}, {"heading": "Constraint Set Iterations to \u2206AccMicro (%) Convergence", "text": "RelCrowd has added additional noise to the NELL facts from HN by twisting the edges of triples (unit, relationship, value) rated as true by Mechanical Turkers and even where the relationship worked. Note that the functional nature of the relationship ensures that the generated example is actually negative. Experimental results comparing all methods with 10% noise are shown in Table 5. We observe that RelCrowd achieves the fastest convergence in this noisy environment. We observed similar patterns at other noise levels as well. If we compare Table 4 with Table 5, we find that the performance of other methods (e.g. Independent Cascade) significantly deteriorates in the presence of noise, but RelCrowd is much more robust in such a noisy environment."}, {"heading": "5.6 Do Additional Coupling Constraints Help?", "text": "To evaluate this thesis, we conducted several ablation experiments in which we evaluated the performance of RelCrowd using the same NELL HITs, but with successively reduced coupling constraints. \u00b2 AccMicro and the number of iterations required to achieve convergence are presented in Table 6. In this table, Cb2 and Cb3 represent two groups of coupling constraints corresponding to the horn clauses of length 2 and 3. This table shows that the performance of RelCrowd with the unremoved C constraint requires the lowest number of iterations (or HIT evaluations) to convergence, and also provides the best accuracy estimate (lowest AccMicro level).These results support our thesis that the increasing coupling constraints between HITs can be exploited for more effective use of the budget and better utilization of HITs."}, {"heading": "5.7 Scalability and Run-time", "text": "Comparisons with MLN: Markov Logic Networks (MLN) [35] is a probabilistic logic that can serve as another candidate for our inference mechanism. To compare the runtime of RelCrowd with PSL and MLN as inference machines, we have experimented with a subset of the NELL dataset with 1860 HITs and 130 limitations. While the PSL engine lasted only 320 seconds, the MLN implementation took 6 considerably more time and did not even complete the graph grounding step after 7 hours, justifying the choice of PSL as inference engine for RelCrowd."}, {"heading": "6. RELATED WORK", "text": "Most of them are able to play by the rules they have imposed on themselves."}, {"heading": "7. CONCLUSION", "text": "In this paper, we have introduced Relational Crowdsourcing (RelCrowd), a novel framework for crowdsourcing multirelational data. RelCrowd targets environments where the number of potential HITs far exceeds the available budget. To our knowledge, this is the first such framework of its kind. We have shown that the goal optimized by RelCrowd is actually NP-hard and submodular, enabling the application of greedy algorithms with approximation guarantees. By conducting extensive experiments on real data sets, we have successfully demonstrated that RelCrowd is applicable to the important problem of assessing knowledge graphs. In future work, we hope to expand RelCrowd to include different costs and more complex valuation aggregations, and we hope to apply the model to other structurally rich environments."}, {"heading": "8. REFERENCES", "text": "[1] I. Abraham, O. Alonso, V. Kandylas, and A. Slivkins. Adaptivecrowdsourcing algorithms for the bandit survey problem. In COLT, pages 882-910, 2013. [2] A. Amarilli, Y. Vaudamer, T. Milo, and P. Senellart. Top-k querying of unknown values under order constraints, 2015. [3] A. Azaria, Y. Aumann, and S. Kraus. Automated strategies for determining rewards for human work. In AAI. Citeseer, 2012. [4] S. H. Bach, B. Huang, B. London, and L. Getoor. Hinge-loss Markov random fields. Convex inference for structured prediction. In UAI, 2013. [5] M. S. Bernstein, G. Little, R. C. Miller, B. Hartmann, M. S. Ackerman, D. R. Karger, D. Panovich."}, {"heading": "9. APPENDIX", "text": "It is not as if we are able to establish a new system, in which we can build a new system, in which we can build a new system, in which we can build a new system, in which we can build a new system. (...) We assume that we are able to establish a new system, in which we can build a new system. (...) We assume that there will be a new system in which we can build a new system. (...) We assume that both submodular and regular properties are compatible with each other. (...) We assume that both submodular and regular energy functions and submodular set functions are compatible. (...) We assume that we have both submodular and regular properties compatible with each other. (...) We assume that both submodular and submodular set functions are compatible with each other. (...) We assume that both submodular and submodular functions are compatible with each other."}, {"heading": "Error Bounds", "text": "We also show that with our biased allocation mechanism, theoretical error estimates for each task decrease exponentially with an increase in the magnitude of the task derived from it. Let us summarize the answers of the workers for the task of binary classification, which is denoted by rht {0, 1}, by means of majority voting on the users. Let us summarize the golden truth for the task ht (h, u) k = 1 rht (uk) \u2212 1 2 + 1 (6) For a given task ht, these nht answers are i.i.d samples from the distribution of users and answer D (ht, u). Let us let the golden truth for the task ht (h, u) k = 1 rht (uk) and their error from the aggregated answer p (ht) = | Ght \u2212. From our earlier assumption in Equation (4), we approach Ght by expecting the answers ED (h, u) (rh) (u) (rh) (u)."}], "references": [{"title": "Adaptive crowdsourcing algorithms for the bandit survey problem", "author": ["I. Abraham", "O. Alonso", "V. Kandylas", "A. Slivkins"], "venue": "COLT, pages 882\u2013910", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2013}, {"title": "and P", "author": ["A. Amarilli", "Y. Amsterdamer", "T. Milo"], "venue": "Senellart. Top-k querying of unknown values under order constraints", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2015}, {"title": "Automated strategies for determining rewards for human work", "author": ["A. Azaria", "Y. Aumann", "S. Kraus"], "venue": "AAAI. Citeseer", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "Hinge-loss Markov random fields: Convex inference for structured prediction", "author": ["S.H. Bach", "B. Huang", "B. London", "L. Getoor"], "venue": "UAI", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2013}, {"title": "Soylent: a word processor with a crowd inside", "author": ["M.S. Bernstein", "G. Little", "R.C. Miller", "B. Hartmann", "M.S. Ackerman", "D.R. Karger", "D. Crowell", "K. Panovich"], "venue": "ACM symposium on User interface software and technology, pages 313\u2013322", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2010}, {"title": "Crowdsourcing as a model for problem solving an introduction and cases", "author": ["D.C. Brabham"], "venue": "Convergence: the international journal of research into new media technologies, 14(1):75\u201390", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2008}, {"title": "et al", "author": ["J. Bragg", "D.S. Weld"], "venue": "Crowdsourcing multi-label classification for taxonomy creation. In HCOMP", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "Probabilistic similarity logic", "author": ["M. Broecheler", "L. Mihalkova", "L. Getoor"], "venue": "UAI", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2010}, {"title": "Scalable multi-label annotation", "author": ["J. Deng", "O. Russakovsky", "J. Krause", "M.S. Bernstein", "A. Berg", "L. Fei-Fei"], "venue": "SIGCHI, pages 3099\u20133102", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Knowledge vault: A web-scale approach to probabilistic knowledge fusion", "author": ["X. Dong", "E. Gabrilovich", "G. Heitz", "W. Horn", "N. Lao", "K. Murphy", "T. Strohmann", "S. Sun", "W. Zhang"], "venue": "SIGKDD, pages 601\u2013610", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}, {"title": "Separate or joint? estimation of multiple labels from crowdsourced annotations", "author": ["L. Duan", "S. Oyama", "H. Sato", "M. Kurihara"], "venue": "Expert Systems with Applications, 41(13):5723\u20135732", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2014}, {"title": "Amie: association rule mining under incomplete evidence in ontological knowledge bases", "author": ["L.A. Gal\u00e1rraga", "C. Teflioudi", "K. Hose", "F. Suchanek"], "venue": "WWW, pages 413\u2013422", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2013}, {"title": "Using complex systems analysis to advance marketing theory development: Modeling heterogeneity effects on new product growth through stochastic cellular automata", "author": ["J. Goldenberg", "B. Libai", "E. Muller"], "venue": "Academy of Marketing Science Review, 9(3):1\u201318", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2001}, {"title": "Adaptive task assignment for crowdsourced classification", "author": ["C.-J. Ho", "S. Jabbari", "J.W. Vaughan"], "venue": "ICML, pages 534\u2013542", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}, {"title": "Analyzing the amazon mechanical turk marketplace", "author": ["P.G. Ipeirotis"], "venue": "XRDS: Crossroads, The ACM Magazine for Students, 17(2):16\u201321", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2010}, {"title": "Submodularity beyond submodular energies: coupling edges in graph cuts", "author": ["S. Jegelka", "J. Bilmes"], "venue": "CVPR, pages 1897\u20131904", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2011}, {"title": "Combining human and machine intelligence in large-scale crowdsourcing", "author": ["E. Kamar", "S. Hacker", "E. Horvitz"], "venue": "AAMAS, pages 467\u2013474", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2012}, {"title": "Budget-optimal task allocation for reliable crowdsourcing systems", "author": ["D.R. Karger", "S. Oh", "D. Shah"], "venue": "Operations Research, 62(1):1\u201324", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2014}, {"title": "Bayesian knowledge corroboration with logical rules and user feedback. In Machine Learning and Knowledge Discovery in Databases, pages", "author": ["G. Kasneci", "J. Van Gael", "R. Herbrich", "T. Graepel"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2010}, {"title": "Maximizing the spread of influence through a social network", "author": ["D. Kempe", "J. Kleinberg", "\u00c9. Tardos"], "venue": "SIGKDD", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2003}, {"title": "Crowdsourcing user studies with mechanical turk", "author": ["A. Kittur", "E.H. Chi", "B. Suh"], "venue": "SIGCHI, pages 453\u2013456", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2008}, {"title": "What energy functions can be minimized via graph cuts? Pattern Analysis and Machine Intelligence", "author": ["V. Kolmogorov", "R. Zabih"], "venue": "IEEE Transactions on, 26(2):147\u2013159", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2004}, {"title": "et al", "author": ["A. Kolobov", "D.S. Weld"], "venue": "Joint crowdsourcing of multiple tasks. In HCOMP", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2013}, {"title": "Factor graphs and the sum-product algorithm", "author": ["F.R. Kschischang", "B.J. Frey", "H.-A. Loeliger"], "venue": "Information Theory, IEEE Transactions on, 47(2):498\u2013519", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2001}, {"title": "Random walk inference and learning in a large scale knowledge base", "author": ["N. Lao", "T. Mitchell", "W.W. Cohen"], "venue": "EMNLP, pages 529\u2013539", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2011}, {"title": "Cost-effective outbreak detection in networks", "author": ["J. Leskovec", "A. Krause", "C. Guestrin", "C. Faloutsos", "J. VanBriesen", "N. Glance"], "venue": "SIGKDD, pages 420\u2013429", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2007}, {"title": "Turkit: human computation algorithms on mechanical turk", "author": ["G. Little", "L.B. Chilton", "M. Goldman", "R.C. Miller"], "venue": "Proceedings of the 23nd annual ACM symposium on User interface software and technology, pages 57\u201366. ACM", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2010}, {"title": "Submodular functions and convexity", "author": ["L. Lov\u00e1sz"], "venue": "Mathematical Programming The State of the Art, pages 235\u2013257. Springer", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1983}, {"title": "et al", "author": ["T. Mitchell", "W. Cohen", "E. Hruschka", "P. Talukdar", "J. Betteridge"], "venue": "Never-ending learning. In AAAI", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2015}, {"title": "On the submodularity of influence in social networks", "author": ["E. Mossel", "S. Roch"], "venue": "ACM symposium on Theory of computing, pages 128\u2013134", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2007}, {"title": "Scaling up crowd-sourcing to very large datasets: a case for active learning", "author": ["B. Mozafari", "P. Sarkar", "M. Franklin", "M. Jordan", "S. Madden"], "venue": "VLDB, 8(2):125\u2013136", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2014}, {"title": "An analysis of approximations for maximizing submodular set functionsi", "author": ["G.L. Nemhauser", "L.A. Wolsey", "M.L. Fisher"], "venue": "Mathematical Programming, 14(1):265\u2013294", "citeRegEx": "33", "shortCiteRegEx": null, "year": 1978}, {"title": "Knowledge graph identification", "author": ["J. Pujara", "H. Miao", "L. Getoor", "W. Cohen"], "venue": "The Semantic Web\u2013ISWC 2013, pages 542\u2013557. Springer", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2013}, {"title": "Markov logic networks", "author": ["M. Richardson", "P. Domingos"], "venue": "Machine learning, 62(1-2):107\u2013136", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2006}, {"title": "Bayesian combination of multiple, imperfect classifiers", "author": ["E. Simpson", "S.J. Roberts", "A. Smith", "C. Lintott"], "venue": null, "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2011}, {"title": "Yago: a core of semantic knowledge", "author": ["F.M. Suchanek", "G. Kasneci", "G. Weikum"], "venue": "WWW", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2007}, {"title": "Building hierarchies of concepts via crowdsourcing", "author": ["Y. Sun", "A. Singla", "D. Fox", "A. Krause"], "venue": "arXiv preprint arXiv:1504.07302", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2015}, {"title": "Budgetfix: budget limited crowdsourcing for interdependent task allocation with quality guarantees", "author": ["L. Tran-Thanh", "T.D. Huynh", "A. Rosenfeld", "S.D. Ramchurn", "N.R. Jennings"], "venue": "AAMAS, pages 477\u2013484", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2014}, {"title": "Efficient budget allocation with accuracy guarantees for crowdsourcing classification tasks", "author": ["L. Tran-Thanh", "M. Venanzi", "A. Rogers", "N.R. Jennings"], "venue": "AAMAS", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2013}, {"title": "The multidimensional wisdom of crowds", "author": ["P. Welinder", "S. Branson", "P. Perona", "S.J. Belongie"], "venue": "NIPS, pages 2424\u20132432", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2010}, {"title": "Human computation tasks with global constraints", "author": ["H. Zhang", "E. Law", "R. Miller", "K. Gajos", "D. Parkes", "E. Horvitz"], "venue": "SIGCHI, pages 217\u2013226", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2012}], "referenceMentions": [{"referenceID": 28, "context": "Over the last few years, significant advances have been made in automatically constructing knowledge graphs such as NELL [30], Yago [37], Knowledge-Vault [10] etc.", "startOffset": 121, "endOffset": 125}, {"referenceID": 35, "context": "Over the last few years, significant advances have been made in automatically constructing knowledge graphs such as NELL [30], Yago [37], Knowledge-Vault [10] etc.", "startOffset": 132, "endOffset": 136}, {"referenceID": 9, "context": "Over the last few years, significant advances have been made in automatically constructing knowledge graphs such as NELL [30], Yago [37], Knowledge-Vault [10] etc.", "startOffset": 154, "endOffset": 158}, {"referenceID": 14, "context": "Crowdsourcing marketplaces such as Amazon Mechanical Turk (AMT) have emerged as a convenient way to collect human judgments on a variety of tasks, ranging from document and image classification to scientific experimentation [15, 26, 6, 21].", "startOffset": 224, "endOffset": 239}, {"referenceID": 5, "context": "Crowdsourcing marketplaces such as Amazon Mechanical Turk (AMT) have emerged as a convenient way to collect human judgments on a variety of tasks, ranging from document and image classification to scientific experimentation [15, 26, 6, 21].", "startOffset": 224, "endOffset": 239}, {"referenceID": 20, "context": "Crowdsourcing marketplaces such as Amazon Mechanical Turk (AMT) have emerged as a convenient way to collect human judgments on a variety of tasks, ranging from document and image classification to scientific experimentation [15, 26, 6, 21].", "startOffset": 224, "endOffset": 239}, {"referenceID": 0, "context": "More recently, algorithms have been developed to adjust these parameters adaptively [1, 14].", "startOffset": 84, "endOffset": 91}, {"referenceID": 13, "context": "More recently, algorithms have been developed to adjust these parameters adaptively [1, 14].", "startOffset": 84, "endOffset": 91}, {"referenceID": 28, "context": "In addition to type coupling constraints, Horn clauses [30, 25], such as homeStadiumOf \u2227 homeCity \u2192 stadiumLocatedInCity, can also be used.", "startOffset": 55, "endOffset": 63}, {"referenceID": 24, "context": "In addition to type coupling constraints, Horn clauses [30, 25], such as homeStadiumOf \u2227 homeCity \u2192 stadiumLocatedInCity, can also be used.", "startOffset": 55, "endOffset": 63}, {"referenceID": 28, "context": "\u2022 We apply the RelCrowd for quality estimation of automatically constructed KGs such as NELL [30] and Symbol Description H = {h1, .", "startOffset": 93, "endOffset": 97}, {"referenceID": 35, "context": "Yago [37].", "startOffset": 5, "endOffset": 9}, {"referenceID": 24, "context": "Given a KG, recent research has developed efficient techniques to automatically learn such coupling constraints [25, 12].", "startOffset": 112, "endOffset": 120}, {"referenceID": 11, "context": "Given a KG, recent research has developed efficient techniques to automatically learn such coupling constraints [25, 12].", "startOffset": 112, "endOffset": 120}, {"referenceID": 28, "context": ", which have also been successfully employed during knowledge extraction in NELL [30] and during integration of such extracted knowledge [34], can also be used as coupling constraints.", "startOffset": 81, "endOffset": 85}, {"referenceID": 32, "context": ", which have also been successfully employed during knowledge extraction in NELL [30] and during integration of such extracted knowledge [34], can also be used as coupling constraints.", "startOffset": 137, "endOffset": 141}, {"referenceID": 23, "context": "Please note that the ECG is in fact a bi-partite factor graph [24] with HIT nodes corresponding to variable-nodes and coupling constraint nodes corresponding to factor-nodes.", "startOffset": 62, "endOffset": 66}, {"referenceID": 6, "context": "Inference module, which mostly involves machine intelligence and automated computing over crowd labels, is an essential part of crowdsourcing system [7] to save on total expenditure.", "startOffset": 149, "endOffset": 152}, {"referenceID": 7, "context": "We use Probabilistic Soft Logic (PSL) [8], as our inference engine, to implement propagation of evaluation labels.", "startOffset": 38, "endOffset": 41}, {"referenceID": 0, "context": "One of the motivations to use PSL as our evaluation propagation mechanism is that it relaxes boolean truth values over H to continuous soft values in interval [0,1], unlike discrete binary Markov Logic Networks [35].", "startOffset": 159, "endOffset": 164}, {"referenceID": 33, "context": "One of the motivations to use PSL as our evaluation propagation mechanism is that it relaxes boolean truth values over H to continuous soft values in interval [0,1], unlike discrete binary Markov Logic Networks [35].", "startOffset": 211, "endOffset": 215}, {"referenceID": 27, "context": "3 is submodular [29].", "startOffset": 16, "endOffset": 20}, {"referenceID": 15, "context": "This can be proved using the observation that all pairs of HITs satisfy regularity condition [16] [22] and by using the conjecture of [20] which is later proved in [31].", "startOffset": 93, "endOffset": 97}, {"referenceID": 21, "context": "This can be proved using the observation that all pairs of HITs satisfy regularity condition [16] [22] and by using the conjecture of [20] which is later proved in [31].", "startOffset": 98, "endOffset": 102}, {"referenceID": 19, "context": "This can be proved using the observation that all pairs of HITs satisfy regularity condition [16] [22] and by using the conjecture of [20] which is later proved in [31].", "startOffset": 134, "endOffset": 138}, {"referenceID": 29, "context": "This can be proved using the observation that all pairs of HITs satisfy regularity condition [16] [22] and by using the conjecture of [20] which is later proved in [31].", "startOffset": 164, "endOffset": 168}, {"referenceID": 31, "context": "Fortunately, from classic results of [33], we know that greedy hill-climbing algorithms solve such maximization problem with approximation factor of (1 \u2212 1/e) \u2248 63% of optimal solution.", "startOffset": 37, "endOffset": 41}, {"referenceID": 38, "context": "This assumption, together with the widely accepted notion of \u2018wisdom of crowds\u2019, leads us to a stronger conclusion that expectation over the responses rh(u) for a task h by worker set {u} is closer to gold truth Gh [40].", "startOffset": 215, "endOffset": 219}, {"referenceID": 38, "context": "Earlier works have considered allocation of workers to varyingcost model [40], but are not directly applicable in this setting due to our preference bias for few tasks over others.", "startOffset": 73, "endOffset": 77}, {"referenceID": 24, "context": "We constructed coupling constraints set CN using a few topranked PRA inference rules [25] along with domain and range information from ontology\u2019s predicate signatures.", "startOffset": 85, "endOffset": 89}, {"referenceID": 11, "context": "We used AMIE horn clauses [12] to construct multi-relational coupling constraints CY for Yago-ECG.", "startOffset": 26, "endOffset": 30}, {"referenceID": 24, "context": ", P(l(h) = True) = 1\u2212 P(l(h) = False) We take PRA and AMIE paths [25, 12] along with ontological domain-range information to build PSL rules.", "startOffset": 65, "endOffset": 73}, {"referenceID": 11, "context": ", P(l(h) = True) = 1\u2212 P(l(h) = False) We take PRA and AMIE paths [25, 12] along with ontological domain-range information to build PSL rules.", "startOffset": 65, "endOffset": 73}, {"referenceID": 19, "context": "This method is based on contagion transmission model of social networks wherein nodes infect their immediate neighbors [20].", "startOffset": 119, "endOffset": 123}, {"referenceID": 33, "context": "Comparisons with MLN: Markov Logic Networks (MLN) [35] is a probabilistic logic which can serve as another candidate for our Inference Mechanism.", "startOffset": 50, "endOffset": 54}, {"referenceID": 3, "context": "PSL inference engine uses Java implementation of hinge-loss Markov random fields (hl-mrf) to find the most probable explanation[4].", "startOffset": 127, "endOffset": 130}, {"referenceID": 7, "context": "It also uses relational database for efficient retrieval during rule grounding [8].", "startOffset": 79, "endOffset": 82}, {"referenceID": 18, "context": "In estimating the accuracy of knowledge bases through crowdsourcing, we find the task of knowledge corroboration [19] to be closely aligned with our motivations.", "startOffset": 113, "endOffset": 117}, {"referenceID": 39, "context": "They are mainly focused on getting a better hold on user\u2019s behavior and use it to further get better estimates of gold truth [41].", "startOffset": 125, "endOffset": 129}, {"referenceID": 16, "context": "Recent improvements use Bayesian techniques [17, 36] for predicting accuracy of classification type HITs, but they operate in much simpler atomic", "startOffset": 44, "endOffset": 52}, {"referenceID": 34, "context": "Recent improvements use Bayesian techniques [17, 36] for predicting accuracy of classification type HITs, but they operate in much simpler atomic", "startOffset": 44, "endOffset": 52}, {"referenceID": 4, "context": "There have been models named Find-Fix-Verify which break large complex tasks, such as editing erroneous text, into modular chunks of simpler HITs and deal with these three inter-dependent tasks [5, 18].", "startOffset": 194, "endOffset": 201}, {"referenceID": 17, "context": "There have been models named Find-Fix-Verify which break large complex tasks, such as editing erroneous text, into modular chunks of simpler HITs and deal with these three inter-dependent tasks [5, 18].", "startOffset": 194, "endOffset": 201}, {"referenceID": 37, "context": "The kind of inter-dependency among the three micro-tasks is very specific in the sense that output of previous stage goes as input to the next stage and cost analysis, workers Allocation and performance bounds over this model are done [39].", "startOffset": 235, "endOffset": 239}, {"referenceID": 22, "context": "Decision theoretic approaches on constrained workflows have been employed to obtain high quality output for minimum allocated resources [23, 7].", "startOffset": 136, "endOffset": 143}, {"referenceID": 6, "context": "Decision theoretic approaches on constrained workflows have been employed to obtain high quality output for minimum allocated resources [23, 7].", "startOffset": 136, "endOffset": 143}, {"referenceID": 40, "context": "Crowdsourcing tasks, like collective itinerary planning [42, 28], involves handling tasks with global constraints, but our notion of inter-dependence is again very different as compared to above model More recent work on construction of hierarchy over domain concepts [38], top-k querying over noisy crowd data [2], multi-label image annotation from crowd [11, 9] involve crowdsourcing over dependent HITs but their goals and methods vary largely from ours.", "startOffset": 56, "endOffset": 64}, {"referenceID": 26, "context": "Crowdsourcing tasks, like collective itinerary planning [42, 28], involves handling tasks with global constraints, but our notion of inter-dependence is again very different as compared to above model More recent work on construction of hierarchy over domain concepts [38], top-k querying over noisy crowd data [2], multi-label image annotation from crowd [11, 9] involve crowdsourcing over dependent HITs but their goals and methods vary largely from ours.", "startOffset": 56, "endOffset": 64}, {"referenceID": 36, "context": "Crowdsourcing tasks, like collective itinerary planning [42, 28], involves handling tasks with global constraints, but our notion of inter-dependence is again very different as compared to above model More recent work on construction of hierarchy over domain concepts [38], top-k querying over noisy crowd data [2], multi-label image annotation from crowd [11, 9] involve crowdsourcing over dependent HITs but their goals and methods vary largely from ours.", "startOffset": 268, "endOffset": 272}, {"referenceID": 1, "context": "Crowdsourcing tasks, like collective itinerary planning [42, 28], involves handling tasks with global constraints, but our notion of inter-dependence is again very different as compared to above model More recent work on construction of hierarchy over domain concepts [38], top-k querying over noisy crowd data [2], multi-label image annotation from crowd [11, 9] involve crowdsourcing over dependent HITs but their goals and methods vary largely from ours.", "startOffset": 311, "endOffset": 314}, {"referenceID": 10, "context": "Crowdsourcing tasks, like collective itinerary planning [42, 28], involves handling tasks with global constraints, but our notion of inter-dependence is again very different as compared to above model More recent work on construction of hierarchy over domain concepts [38], top-k querying over noisy crowd data [2], multi-label image annotation from crowd [11, 9] involve crowdsourcing over dependent HITs but their goals and methods vary largely from ours.", "startOffset": 356, "endOffset": 363}, {"referenceID": 8, "context": "Crowdsourcing tasks, like collective itinerary planning [42, 28], involves handling tasks with global constraints, but our notion of inter-dependence is again very different as compared to above model More recent work on construction of hierarchy over domain concepts [38], top-k querying over noisy crowd data [2], multi-label image annotation from crowd [11, 9] involve crowdsourcing over dependent HITs but their goals and methods vary largely from ours.", "startOffset": 356, "endOffset": 363}, {"referenceID": 12, "context": "Our model significantly differs from previous works in marketing theory [13], outbreak detection [27] and social network analysis [20] etc.", "startOffset": 72, "endOffset": 76}, {"referenceID": 25, "context": "Our model significantly differs from previous works in marketing theory [13], outbreak detection [27] and social network analysis [20] etc.", "startOffset": 97, "endOffset": 101}, {"referenceID": 19, "context": "Our model significantly differs from previous works in marketing theory [13], outbreak detection [27] and social network analysis [20] etc.", "startOffset": 130, "endOffset": 134}, {"referenceID": 17, "context": "Work on budget sensitive algorithm [18, 3, 40] provides performance guarantees over several cost models, but do not account for any inter-relation among tasks.", "startOffset": 35, "endOffset": 46}, {"referenceID": 2, "context": "Work on budget sensitive algorithm [18, 3, 40] provides performance guarantees over several cost models, but do not account for any inter-relation among tasks.", "startOffset": 35, "endOffset": 46}, {"referenceID": 38, "context": "Work on budget sensitive algorithm [18, 3, 40] provides performance guarantees over several cost models, but do not account for any inter-relation among tasks.", "startOffset": 35, "endOffset": 46}, {"referenceID": 30, "context": "In large scale crowdsourcing, recent works have highlighted case for active learning [32].", "startOffset": 85, "endOffset": 89}], "year": 2017, "abstractText": "Automatic construction of large knowledge graphs (KG) by mining web-scale text datasets has received considerable attention over the last few years, resulting in the construction of several KGs, such as NELL, Google Knowledge Vault, etc. These KGs consist of thousands of \u2018predicate-relations\u2019 (e.g., isPerson, isMayorOf ) and millions of their instances (e.g., (Bill de Blasio, isMayorOf, New York City)). Estimating accuracy of such automatically constructed KGs is a challenging problem due to their size and diversity. Even though crowdsourcing is an obvious choice for such evaluation, the standard single-task crowdsourcing, where each predicate in the KG is evaluated independently, is very expensive and especially problematic if the budget available is limited. We show that such approaches are sub-optimal as they ignore dependencies among various predicates and their instances. To overcome this challenge, we propose Relational Crowdsourcing (RelCrowd), where the tasks are created while taking dependencies among predicates and instances into account. We apply this framework in the context of evaluation of large-scale KGs and demonstrate its effectiveness through extensive experiments on real-world datasets.", "creator": "LaTeX with hyperref package"}}}