{"id": "1610.07183", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Oct-2016", "title": "How to be Fair and Diverse?", "abstract": "Due to the recent cases of algorithmic bias in data-driven decision-making, machine learning methods are being put under the microscope in order to understand the root cause of these biases and how to correct them. Here, we consider a basic algorithmic task that is central in machine learning: subsampling from a large data set. Subsamples are used both as an end-goal in data summarization (where fairness could either be a legal, political or moral requirement) and to train algorithms (where biases in the samples are often a source of bias in the resulting model). Consequently, there is a growing effort to modify either the subsampling methods or the algorithms themselves in order to ensure fairness. However, in doing so, a question that seems to be overlooked is whether it is possible to produce fair subsamples that are also adequately representative of the feature space of the data set - an important and classic requirement in machine learning. Can diversity and fairness be simultaneously ensured? We start by noting that, in some applications, guaranteeing one does not necessarily guarantee the other, and a new approach is required. Subsequently, we present an algorithmic framework which allows us to produce both fair and diverse samples. Our experimental results on an image summarization task show marked improvements in fairness without compromising feature diversity by much, giving us the best of both the worlds.", "histories": [["v1", "Sun, 23 Oct 2016 15:13:46 GMT  (2875kb,D)", "http://arxiv.org/abs/1610.07183v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["l elisa celis", "amit deshpande", "tarun kathuria", "nisheeth k vishnoi"], "accepted": false, "id": "1610.07183"}, "pdf": {"name": "1610.07183.pdf", "metadata": {"source": "CRF", "title": "How to be Fair and Diverse?", "authors": ["L. Elisa Celis", "Amit Deshpande", "Nisheeth K. Vishnoi"], "emails": [], "sections": [{"heading": "1. Introduction", "text": "In fact, most of them are able to determine for themselves what they want and what they want to do."}, {"heading": "2. Preliminaries", "text": "In fact, it is such that it is a matter of a way in which people find themselves in a world in which they are able to understand the world, and in which they put themselves in a world in which they are able to move, in which they move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they, in which they, in which they live, in which they, in which they live, in which they live, in which they, in which they, in which they live."}, {"heading": "3. Experimental Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1. Datasets and Features", "text": "We conducted our experiments with a collection of images curated using Google Image Search: four search terms were used: (a) \"Scientist Male,\" (b) \"Scientist Female,\" (c) \"Painter Male\" and (d) \"Painter Female.\" The search was limited to medium-sized JPEG files that went through the strictest filter level of safe search filtering; the top 200 different images were collected to create the following three sets of data: 1 \u2022 Scientist: (a) and (b) \u2022 Artist: (c) and (d) \u2022 Scientist + Artist: (a), (b), (c) and (d). Therefore, each data set has inherent labels (a) - (d) that allow us to measure the combinatorial diversity of a sample. To measure geometric diversity, each image was edited with the vlBlock feat toolbox to combine groups of 128-dimensional SIFT descriptors into one [15] cluster."}, {"heading": "3.2. Algorithms and Baselines", "text": "In each experiment, we compare four different probability distributions, on the basis of which k samples can be selected from a data set: 1) Our proposed P -DPP (see Def 2.4), 2) the1The images are available at goo.gl / hNukfP.classic k-DPP (see Def 2.3), 3) ki-DPP (see Def 2.5), and 4) UNIF, which uses a uniformly random subset of the size k to sample k-DPP, ki-DPP, and P -DPP. Instead of using the polynomic time algorithms of [10, 18], we refer to a Markov chain Monte Carlo (MCMC) inspired by [1], as the latter appears faster in practice. The Markov chain is defined using the space of subsets of cardinality k. The algorithm first selects a \"warm start state,\" which is achieved by greedily maximizing the determination of the termination, while the dividing restrictions are fulfilled."}, {"heading": "3.3. Experiments and Discussion", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.3.1. Experiment 1: Perfect Fairness", "text": "Experimental Setup. We first look at the performance, as we vary the sample size k from 20 to 100 on the Scientist dataset (see Figure 2 (i)); remember that the dataset has two parts, male and female, and that the dataset is unbiased. We set fairness constraints so that P -DPP and ki-DPP select exactly 50% of their samples from the male and female part. Therefore, we set up the experiment to guarantee an optimal D (\u00b7) for P -DPP and ki-DPP, and measure the resulting deterioration in G (\u00b7). Results. Both P -DPP and ki-DPP achieve the optimal D (\u00b7) of 2. As expected, this is significantly higher than UNIF and k-DPP (paired one-sided t-tests, p < 0.05), that the DPP results are significantly higher than DPP-DPP."}, {"heading": "3.3.2. Experiment 2: Hidden Attributes", "text": "Experimental Setup. We then look at the performance of the algorithms, as we vary the sample size k in relation to the Scientist + Artist dataset from 10 to 50, but look at the case where there is a hidden underlying partition (see Figure 2 (ii)). Here, we use fairness constraints so that P -DPP and ki-DPP select exactly 50% of their samples from the male (a and c) and female (b and d) images, but do not impose any constraints between the images of scientists (a and b) and artists (c and d), allowing for disproportionality in this dimension. However, we measure fairness in relation to all four parts. Results. In relation to the D (\u00b7), P -DPP and ki-DPP, however, P-DPP no longer achieve the optimal fairness of 4. However, P-DPP is significantly better than k-DPP and ki-DPP significantly better than the performance of k-DPP (DPP and Dki-DPP)."}, {"heading": "3.3.3. Experiment 3: Biased Datasets", "text": "\"I don't think there's a lot of evidence to support that,\" he said, \"but I think there's a lot of evidence to support that, and I think that's what we're going to have to do in the next couple of weeks.\""}], "references": [{"title": "Monte carlo markov chain algorithms for sampling strongly rayleigh distributions and determinantal point processes", "author": ["Nima Anari", "Shayan Oveis Gharan", "Alireza Rezaei"], "venue": "In Proceedings of the 29th Conference on Learning Theory, COLT 2016,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2016}, {"title": "Selbst. Big Data\u2019s Disparate Impact", "author": ["A.D.S. Barocas"], "venue": "SSRN eLibrary,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2015}, {"title": "Efficient volume sampling for row/column subset selection", "author": ["A. Deshpande", "L. Rademacher"], "venue": "In Foundations of Computer Science (FOCS),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2010}, {"title": "On the nystr\u00f6m method for approximating a gram matrix for improved kernel-based learning", "author": ["Petros Drineas", "Michael W. Mahoney"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2005}, {"title": "Fairness through awareness", "author": ["Cynthia Dwork", "Moritz Hardt", "Toniann Pitassi", "Omer Reingold", "Richard Zemel"], "venue": "In Proceedings of the 3rd Innovations in Theoretical Computer Science Conference,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2012}, {"title": "Revisiting the nystrom method for improved large-scale machine learning", "author": ["Alex Gittens", "Michael W. Mahoney"], "venue": "In Proceedings of the 30th International Conference on Machine Learning,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2013}, {"title": "Diverse sequential subset selection for supervised video summarization", "author": ["Boqing Gong", "Wei-Lun Chao", "Kristen Grauman", "Fei Sha"], "venue": "In Advances in Neural Information Processing Systems 27: Annual Conference on Neural  Information Processing Systems", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "Semantics derived automatically from language corpora necessarily contain human", "author": ["Aylin Caliskan Islam", "Joanna J. Bryson", "Arvind Narayanan"], "venue": "biases. CoRR,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2016}, {"title": "Classifying without discriminating", "author": ["Faisal Kamiran", "Toon Calders"], "venue": "In Computer, Control and Communication,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2009}, {"title": "On Sampling and Greedy MAP Inference of Constrained Determinantal Point Processes", "author": ["Tarun Kathuria", "Amit Deshpande"], "venue": "ArXiv e-prints,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2016}, {"title": "Near-optimal sensor placements in gaussian processes: Theory, efficient algorithms and empirical studies", "author": ["Andreas Krause", "Ajit Paul Singh", "Carlos Guestrin"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2008}, {"title": "k-dpps: Fixed-size determinantal point processes", "author": ["Alex Kulesza", "Ben Taskar"], "venue": "In Proceedings of the 28th International Conference on Machine Learning,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2011}, {"title": "Determinantal point processes for machine learning", "author": ["Alex Kulesza", "Ben Taskar"], "venue": "Foundations and Trends in Machine Learning,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "Learning mixtures of submodular shells with application to document summarization", "author": ["Hui Lin", "Jeff A. Bilmes"], "venue": "In Proceedings of the Twenty-Eighth Conference on Uncertainty in Artificial Intelligence (UAI),", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2012}, {"title": "Object recognition from local scaleinvariant features", "author": ["David G. Lowe"], "venue": "In ICCV, pages 1150\u20131157,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1999}, {"title": "Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy", "author": ["C. O\u2019Neil"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2016}, {"title": "Measurement of diversity", "author": ["Edward H Simpson"], "venue": "Nature,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1949}, {"title": "Generalized determinantal point processes: The linear case", "author": ["Damian Straszak", "Nisheeth Vishnoi"], "venue": "ArXiv eprints,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2016}, {"title": "Vlfeat: An open and portable library of computer vision", "author": ["A. Vedaldi", "B. Fulkerson"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2008}, {"title": "Fairness Constraints: A Mechanism for Fair Classification", "author": ["Muhammad Bilal Zafar", "Isabel Valera", "Manuel Gomez Rodriguez", "Krishna Gummadi"], "venue": "In 2nd Workshop on Fairness, Accountability, and Transparency in Machine Learning, Lille, France,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2015}, {"title": "Solving the apparent diversity-accuracy dilemma of recommender systems", "author": ["Tao Zhou", "Zoltn Kuscsik", "Jian-Guo Liu", "Mat Medo", "Joseph Rushton Wakeling", "Yi-Cheng Zhang"], "venue": "Proceedings of the National Academy of Sciences,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2010}], "referenceMentions": [{"referenceID": 15, "context": "As more and more machine learning algorithms automate data-driven processes in education, recruitment, banking, and judiciary systems, one thing has become evident \u2013 algorithms can have biases [16].", "startOffset": 193, "endOffset": 197}, {"referenceID": 1, "context": ", see [2, 8, 5, 20]).", "startOffset": 6, "endOffset": 19}, {"referenceID": 7, "context": ", see [2, 8, 5, 20]).", "startOffset": 6, "endOffset": 19}, {"referenceID": 4, "context": ", see [2, 8, 5, 20]).", "startOffset": 6, "endOffset": 19}, {"referenceID": 19, "context": ", see [2, 8, 5, 20]).", "startOffset": 6, "endOffset": 19}, {"referenceID": 12, "context": ", [13]).", "startOffset": 2, "endOffset": 6}, {"referenceID": 15, "context": "However, diversity may not guarantee fairness on sensitive attributes and may propagate biases, leading to broken models and algorithmic prejudice [16, 2].", "startOffset": 147, "endOffset": 154}, {"referenceID": 1, "context": "However, diversity may not guarantee fairness on sensitive attributes and may propagate biases, leading to broken models and algorithmic prejudice [16, 2].", "startOffset": 147, "endOffset": 154}, {"referenceID": 12, "context": ", [13] and [9]), to the best of our knowledge, this is the first systematic study that addresses both simultaneously.", "startOffset": 2, "endOffset": 6}, {"referenceID": 8, "context": ", [13] and [9]), to the best of our knowledge, this is the first systematic study that addresses both simultaneously.", "startOffset": 11, "endOffset": 14}, {"referenceID": 16, "context": "The combinatorial notion works with much less information, and is known as the diversity index [17] in social and biological sciences.", "startOffset": 95, "endOffset": 99}, {"referenceID": 12, "context": "The geometric notion gives rise to a probability distribution known as determinantal point process (or k-DPP), and such measures have been used to quantify feature diversity in a variety of machine learning applications for images [13], videos [7], documents [14], recommendation systems [21], and sensor placement [11].", "startOffset": 231, "endOffset": 235}, {"referenceID": 6, "context": "The geometric notion gives rise to a probability distribution known as determinantal point process (or k-DPP), and such measures have been used to quantify feature diversity in a variety of machine learning applications for images [13], videos [7], documents [14], recommendation systems [21], and sensor placement [11].", "startOffset": 244, "endOffset": 247}, {"referenceID": 13, "context": "The geometric notion gives rise to a probability distribution known as determinantal point process (or k-DPP), and such measures have been used to quantify feature diversity in a variety of machine learning applications for images [13], videos [7], documents [14], recommendation systems [21], and sensor placement [11].", "startOffset": 259, "endOffset": 263}, {"referenceID": 20, "context": "The geometric notion gives rise to a probability distribution known as determinantal point process (or k-DPP), and such measures have been used to quantify feature diversity in a variety of machine learning applications for images [13], videos [7], documents [14], recommendation systems [21], and sensor placement [11].", "startOffset": 288, "endOffset": 292}, {"referenceID": 10, "context": "The geometric notion gives rise to a probability distribution known as determinantal point process (or k-DPP), and such measures have been used to quantify feature diversity in a variety of machine learning applications for images [13], videos [7], documents [14], recommendation systems [21], and sensor placement [11].", "startOffset": 315, "endOffset": 319}, {"referenceID": 2, "context": "Besides quantification of diversity in feature-rich datasets, an important reason for the deployment of k-DPPs is the recent efficient algorithms to sample from these distributions [3, 1].", "startOffset": 181, "endOffset": 187}, {"referenceID": 0, "context": "Besides quantification of diversity in feature-rich datasets, an important reason for the deployment of k-DPPs is the recent efficient algorithms to sample from these distributions [3, 1].", "startOffset": 181, "endOffset": 187}, {"referenceID": 9, "context": ", p = O(1)), making our approach feasible [10, 18].", "startOffset": 42, "endOffset": 50}, {"referenceID": 17, "context": ", p = O(1)), making our approach feasible [10, 18].", "startOffset": 42, "endOffset": 50}, {"referenceID": 3, "context": ", [4, 6]), and it remains an important avenue for future work to study if P -DPPs can also help mitigate algorithmic bias in such settings.", "startOffset": 2, "endOffset": 8}, {"referenceID": 5, "context": ", [4, 6]), and it remains an important avenue for future work to study if P -DPPs can also help mitigate algorithmic bias in such settings.", "startOffset": 2, "endOffset": 8}, {"referenceID": 9, "context": "A multivariate generalization of this can incorporate partition constraints (and beyond) to sample from P -DPPs in time n, which is polynomial for p = O(1) [10, 18].", "startOffset": 156, "endOffset": 164}, {"referenceID": 17, "context": "A multivariate generalization of this can incorporate partition constraints (and beyond) to sample from P -DPPs in time n, which is polynomial for p = O(1) [10, 18].", "startOffset": 156, "endOffset": 164}, {"referenceID": 11, "context": "In order to measure geometric diversity, following [12], each image was processed with the vlfeat toolbox to obtain sets of 128-dimensional SIFT descriptors [15, 19].", "startOffset": 51, "endOffset": 55}, {"referenceID": 14, "context": "In order to measure geometric diversity, following [12], each image was processed with the vlfeat toolbox to obtain sets of 128-dimensional SIFT descriptors [15, 19].", "startOffset": 157, "endOffset": 165}, {"referenceID": 18, "context": "In order to measure geometric diversity, following [12], each image was processed with the vlfeat toolbox to obtain sets of 128-dimensional SIFT descriptors [15, 19].", "startOffset": 157, "endOffset": 165}, {"referenceID": 9, "context": "In order to sample from k-DPP, ki-DPP and P -DPP, instead of using the polynomial time algorithms of [10, 18], we appeal to a Markov Chain Monte Carlo (MCMC) heuristic inspired by [1] as the latter seems faster in practice.", "startOffset": 101, "endOffset": 109}, {"referenceID": 17, "context": "In order to sample from k-DPP, ki-DPP and P -DPP, instead of using the polynomial time algorithms of [10, 18], we appeal to a Markov Chain Monte Carlo (MCMC) heuristic inspired by [1] as the latter seems faster in practice.", "startOffset": 101, "endOffset": 109}, {"referenceID": 0, "context": "In order to sample from k-DPP, ki-DPP and P -DPP, instead of using the polynomial time algorithms of [10, 18], we appeal to a Markov Chain Monte Carlo (MCMC) heuristic inspired by [1] as the latter seems faster in practice.", "startOffset": 180, "endOffset": 183}], "year": 2016, "abstractText": "Due to the recent cases of algorithmic bias in datadriven decision-making, machine learning methods are being put under the microscope in order to understand the root cause of these biases and how to correct them. Here, we consider a basic algorithmic task that is central in machine learning: subsampling from a large data set. Subsamples are used both as an end-goal in data summarization (where fairness could either be a legal, political or moral requirement) and to train algorithms (where biases in the samples are often a source of bias in the resulting model). Consequently, there is a growing effort to modify either the subsampling methods or the algorithms themselves in order to ensure fairness. However, in doing so, a question that seems to be overlooked is whether it is possible to produce fair subsamples that are also adequately representative of the feature space of the data set \u2013 an important and classic requirement in machine learning. Can diversity and fairness be simultaneously ensured? We start by noting that, in some applications, guaranteeing one does not necessarily guarantee the other, and a new approach is required. Subsequently, we present an algorithmic framework which allows us to produce both fair and diverse samples. Our experimental results on an image summarization task show marked improvements in fairness without compromising feature diversity by much, giving us the best of both the worlds.", "creator": "LaTeX with hyperref package"}}}