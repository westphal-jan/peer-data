{"id": "1610.07363", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Oct-2016", "title": "Learning Reporting Dynamics during Breaking News for Rumour Detection in Social Media", "abstract": "Breaking news leads to situations of fast-paced reporting in social media, producing all kinds of updates related to news stories, albeit with the caveat that some of those early updates tend to be rumours, i.e., information with an unverified status at the time of posting. Flagging information that is unverified can be helpful to avoid the spread of information that may turn out to be false. Detection of rumours can also feed a rumour tracking system that ultimately determines their veracity. In this paper we introduce a novel approach to rumour detection that learns from the sequential dynamics of reporting during breaking news in social media to detect rumours in new stories. Using Twitter datasets collected during five breaking news stories, we experiment with Conditional Random Fields as a sequential classifier that leverages context learnt during an event for rumour detection, which we compare with the state-of-the-art rumour detection system as well as other baselines. In contrast to existing work, our classifier does not need to observe tweets querying a piece of information to deem it a rumour, but instead we detect rumours from the tweet alone by exploiting context learnt during the event. Our classifier achieves competitive performance, beating the state-of-the-art classifier that relies on querying tweets with improved precision and recall, as well as outperforming our best baseline with nearly 40% improvement in terms of F1 score. The scale and diversity of our experiments reinforces the generalisability of our classifier.", "histories": [["v1", "Mon, 24 Oct 2016 11:25:24 GMT  (154kb,D)", "http://arxiv.org/abs/1610.07363v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.IR cs.SI", "authors": ["arkaitz zubiaga", "maria liakata", "rob procter"], "accepted": false, "id": "1610.07363"}, "pdf": {"name": "1610.07363.pdf", "metadata": {"source": "CRF", "title": "Learning Reporting Dynamics during Breaking News for Rumour Detection in Social Media", "authors": ["Arkaitz Zubiaga", "Maria Liakata", "Rob Procter"], "emails": ["a.zubiaga@warwick.ac.uk"], "sections": [{"heading": "1 Introduction", "text": "The presence of such rumoursar Xiv: 161 0.07 363v 1 [cs.C L] 24 Oin the stream of tweets makes it more difficult for users to distinguish themselves from the news. Well-known platforms such as Twitter are increasingly being used by people to learn about the latest developments (Sankaranarayanan et al., 2009), as well as by journalists for collecting false news (Zubiaga et al., 2013), thanks to the way in which they allow users to post and share news from anywhere and at any time, making it possible to receive reports from local users who happen to witness a newsworthy event or from users who appear to have access to exclusive information for any reason. However, the speed at which news spreads on social media during fast-paced events, such as terrorist attacks or uprisings, inevitably means that much of the information published in the early stages of news reporting is not verified by Procter Tweet (Ximoar is more difficult to handle the reporting of such rumoursar al: 363a)."}, {"heading": "2 Background: Definition of Rumour", "text": "Most of the definitions given in the literature coincide with those of major dictionaries such as the Oxford English Dictionary, which defines a rumor as \"a story that is currently circulating or a report of uncertain or dubious truth,\" and the Merriam-Webster Dictionary, which defines it as \"information or a story that is passed on from person to person but has not proven to be true.\" Whether or not the underlying story ultimately proves true or false or remains unfounded, a rumor circulates while it has yet to be verified. A number of researchers have broadened the definition of rumor (DiFonzo and Bordia, 2007) define rumors as \"unverified and instrumentally relevant information that circulates around ambiguity, danger, or potential threat, and this function to help people make sense and manage risk.\" (Moreover, this is why we are circulating rumors in 2007) that individuals (or persons) are circulating."}, {"heading": "3 Related Work", "text": "Despite the growing interest in analyzing rumors on social media (Procter et al., 2013b; Procter et al., 2013a; Starbird et al., 2014; Zubiaga et al., 2015; Takayasu et al., 2015; Tolosi et al., 2016; Zubiaga et al., 2016) and the development of tools to deal with rumors previously identified (Seo et al., 2012; Takahashi and Igata, 2012), there has been very little work on automatic detection of rumors (Qazvinian et al., 2011; Hamidian and Diab, 2015; Hamidian and Diab, 2016), limited to finding rumors that are a priori known. A classifier is fed a set of predefined rumors (e.g. Obama is Muslim) that then link new tweets to one of the known rumors or or or not."}, {"heading": "4 Dataset", "text": "One of our main objectives in planning the compilation of a dataset of rumors and non-rumors was to develop a means to collect a set of stories that would not necessarily be known a priori and that would include both rumors and non-rumors. We did this by mimicking the scenario in which a user would follow tweets from journalists associated with breaking news. If we see a timeline of tweets about breaking news, a user would then comment on each tweet as rumor or or non-rumor. To ensure that our users had the expertise to make that remark, we enlisted the help of a team of journalists who are partners in our research project. Our dataset is significantly different from the previous work (Qazvinian et al., 2011; Procter et al., 2013b; Starbird et al.), which first identified rumors of interest and then collected tweets that were associated with relevant key messages from the latter approach."}, {"heading": "5 Rumour Detection Task", "text": "We define the task of detecting rumors as the one where the system must determine by a timeline of tweets which of the tweets report rumors and thus disseminate information that has yet to be verified; identifying rumors within a timeline is ultimately intended to warn users that the information has not been confirmed and may therefore prove false; this can be operationalized by labeling the tweets identified as rumors and warning users to think twice before disseminating the information. Formally, the task takes an evolving timeline of tweets TL = {t1,..., t | TL |} as input, and the classifier must determine whether each of these tweets ti is a rumor a non-rumor by assigning a label of Y = {R, NR}. Therefore, we formulate the task as a binary classification problem whose performance is evaluated by calculating precision, memory, and F1 values for the target category, i.e., rumors."}, {"heading": "6 Learning Sequential Dynamics for Rumour Detection", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.1 Hypothesis", "text": "We argue that a single headline or tweet does not always indicate that some of the information is a rumor. However, there are instances where a single tweet uses securing words or provides little or no evidence to be considered corroborated information, and therefore these cases can be considered rumors from the tweet alone. This is the case, for example, of tweets reporting during the Ferguson riots that \"the name of the police officer who shot the child would allegedly be disclosed by the police later in the day.\" If the tweet itself expresses uncertainty, as in this case with the use of \"reports,\" it can be taken into account that the underlying information is not corroborated. Reports confidently reporting that \"the child was involved in a robbery before he was shot\" may not be so easily identified by an automated classifier from the tweet alone, although it is a rumor. The lack of sufficient evidence that the information that occurs in many tweets may encourage us to use more leverage contexts to classify rumors and encourage the more encouraging."}, {"heading": "6.2 Classifiers", "text": "To test our hypothesis, we use Conditional Random Fields (CRF) as a sequential classification unit (CRF), which allows each individual recognition of tweets as a chain of reports. We use a maximum entropy classification scenario as the non-sequential equivalent of tweets to test the validity of the tweet hypothesis, and also use additional base classifiers for further comparisons. In addition, we also reproduce a baseline based on the approach presented by (Zhao et al, 2015) to compare the performance of our approach with that of a state-of-the-art approach. Conditional Random Fields (CRF) we use CRF as a structured classifier for model sequences of tweets observed in the timelines of Twitter Breaking News. With CRF, we can model the timeline as a linear chain or graph that is treated as a sequence of rumors."}, {"heading": "6.3 Features", "text": "We use two types of traits in classifiers: content-based traits and social traits. We test them separately or combined. In each of these categories, the following traits fall into:"}, {"heading": "6.3.1 Content-based Features", "text": "We use seven different characteristics extracted from the content of the tweets: \u2022 Word vectors: to create vectors that represent the words in each tweet, we build word vector representations with Word2Vec (Mikolov et al., 2013). If we wet a different Word2Vec model with 300 dimensions for each of the five folds, we train the model in each case from the collection of tweets referring to the four events in the training set, so that the event (and vocabulary) is unknown in the test set. As a result, we get five different Word2Vec models, each of which are used in a separate fold. \u2022 Part-of-Speech tags: We build a vector of Part-of-Speech (POS) tags with each feature in the vector that represents the number of occurrences of a particular POS tag in the tweet. We use Twitie (Bontchet al., the 2013 character) to make the Tweet package for the information package of the POS, the Pingham."}, {"heading": "6.3.2 Social Features", "text": "We use five social characteristics, all of which can be derived from the metadata associated with the author of the tweet and which are embedded as part of a tweet object retrieved from the Twitter API. We define a number of social characteristics that indicate a user's experience and reputation: \u2022 Tweet Count: We exclude this function from the number of tweets a user has posted on Twitter. Since the numbers can vary considerably between users, we apply it by rounding up the logarithm of the number of tweets with 10 bases: dlog10 (status count) e. \u2022 Listed Count: This function is calculated by normalizing the number of Listsa users, i.e. the number of times other users have decided to add the topic to a list: dlog10 (Listedcount) e. \u2022 Follow Ratio: In this function, we consider a user's reputation based on the number of followers."}, {"heading": "7 Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "7.1 Comparison of Classifiers", "text": "In fact, the results for the various classifiers using either or both of the satisfactory and social characteristics, as well as the state of the classifiers, are through (Zhao et al., 2015). The results of the classifiers, with their content characteristics, indicate a remarkable improvement for CRF over the rest of the classifiers, which means that CRF performs better in terms of the sequence of tweets before each tweet than in terms of the context in which input to the classifier is enriched. This is especially true for precision, where CRF performs much better than the rest. Only the na\u00efve features of the classifier result in better mapping, but they do poorly in enriching the content for the classifier. As a result, CRF balances in a much better way where CRF performs much better than the rest of the classifier."}, {"heading": "7.2 Consistency of the Sequential Classifier\u2019s Performance", "text": "Although CRF as a sequential classifier has proven to be better overall than the rest of the non-sequential classifiers, we are interested in whether the high performance of CRF is consistent over time. Since CRF depends on the sequence as context to improve the classification of a tweet, the first tweets always lack the context that subsequent tweets have. To analyze performance over time, we look at the F1 values for each decile and for each event individually. Figure 3 shows these results, broken down by event and decile; thick orange bars represent the F1 value of the CRF classifier in each decile, while the thin gray bars represent the highest F1 value over all non-sequential classifiers in each decile. We make some interesting observations from these results: \u2022 CRF generally performs better than the non-sequential classifiers, even if they break down the results by decile; for the 50 deciles in each decile, this is better in each case, with only 7 data sets being better in each case."}, {"heading": "8 Discussion", "text": "Our experiments to detect rumors from five sets of data, each associated with a breaking news report, show that a classifier that sequentially exploits the context of previous tweets achieves significant improvements over standard, non-sequentially classified rumors. We have proven this in the case of a CRF classifier that significantly outperforms its non-sequential counterpart, a Maximum Entropy classifier. Furthermore, our approach also beats the state of the art by (Zhao et al., 2015) using regular expressions to classify tweets as rumors that provoke responses that match specific patterns, the latter failing to achieve a competitive recall score, which we believe is two main reasons: (1) rumors will not always trigger questioning responses from the general public, and (2) the manually curated regular expressions may be limited and require regular updates that affect a person in the loop."}, {"heading": "9 Conclusion", "text": "We have introduced a novel approach to detecting rumors on social media by using the context that precedes a tweet, with a sequential classifier. Experimenting with five current news records collected by Twitter and commented on by journalists for rumor and non-rumor, we show that the preceding context, used as a sequence, can greatly enhance the performance of the rumor detector. Our approach has also proven to be better than the state-of-the-art rumor detection system introduced by (Zhao et al., 2015), which relies instead on query posts that correspond to a set of manually curated expressions. Their approach performs well in terms of accuracy but fails in terms of recall, suggesting that regular manual inputs are necessary to revise the regular expressions. Instead, our fully automated approach achieves superior performance that is better balanced for both accuracy and recall."}, {"heading": "10 Acknowledgments", "text": "This work was supported by the PHEME FP7 project (grant no. 611233), which used Queen Mary's MidPlus computing equipment supported by QMUL Research-IT and funded by the EPSRC funding programme EP / K000128 / 1."}], "references": [{"title": "An analysis of rumor", "author": ["G.W. Allport", "L. Postman"], "venue": "Public Opinion Quarterly,", "citeRegEx": "Allport and Postman,? 1946", "shortCiteRegEx": "Allport and Postman", "year": 1946}, {"title": "The psychology of rumor", "author": ["G.W. Allport", "L. Postman"], "venue": null, "citeRegEx": "Allport and Postman,? \\Q1947\\E", "shortCiteRegEx": "Allport and Postman", "year": 1947}, {"title": "Rumors detection in chinese via crowd responses", "author": ["G. Cai", "H. Wu", "R. Lv"], "venue": null, "citeRegEx": "Cai et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Cai et al\\.", "year": 2014}, {"title": "Text processing with gate", "author": ["H. IEEE. Cunningham", "D. Maynard", "K. Bontcheva"], "venue": "International Conference on,", "citeRegEx": "Cunningham et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Cunningham et al\\.", "year": 2011}, {"title": "How idle is idle talk? one hundred years of rumor research", "author": ["P. Donovan"], "venue": "Diogenes,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2007}, {"title": "Rumor detection and classification for twitter", "author": ["S. Hamidian", "M.T. Diab"], "venue": null, "citeRegEx": "Hamidian and Diab,? \\Q2015\\E", "shortCiteRegEx": "Hamidian and Diab", "year": 2015}, {"title": "Rumor identification and belief investigation", "author": ["Communication", "M.T. Diab"], "venue": null, "citeRegEx": "Communication et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Communication et al\\.", "year": 2016}, {"title": "News verification by exploiting conflicting", "author": ["Z. Jin", "J. Cao", "Y. Zhang", "J. Luo"], "venue": "Proceedings of NAACL-HLT,", "citeRegEx": "Jin et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Jin et al\\.", "year": 2016}, {"title": "Rumor identification", "author": ["W. He", "C. Xu", "L. Chen", "J. Zeng"], "venue": "international conference on machine learning, ICML,", "citeRegEx": "G. et al\\.,? \\Q2015\\E", "shortCiteRegEx": "G. et al\\.", "year": 2015}, {"title": "Real-time rumor debunking", "author": ["X. Liu", "A. Nourbakhsh", "Q. Li", "R. Fang", "S. Shah"], "venue": "Social Systems,", "citeRegEx": "Liu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2015}, {"title": "Using gaussian processes for rumour stance classification", "author": ["M. Lukasik", "T. Cohn", "K. Bontcheva"], "venue": null, "citeRegEx": "Lukasik et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lukasik et al\\.", "year": 2015}, {"title": "Detecting rumors from microblogs with recurrent neural networks", "author": ["J. Ma", "W. Gao", "P. Mitra", "S. Kwon", "B.J. Jansen", "Wong", "K.-F.", "M. Cha"], "venue": "Proceedings of IJCAI.", "citeRegEx": "Ma et al\\.,? 2016", "shortCiteRegEx": "Ma et al\\.", "year": 2016}, {"title": "Detect rumors using time series of social context information on microblogging websites", "author": ["J. Ma", "W. Gao", "Z. Wei", "Y. Lu", "Wong", "K.-F."], "venue": "Proceedings of the 24th ACM International on Conference on Information and Knowledge Management, pages 1751\u20131754. ACM.", "citeRegEx": "Ma et al\\.,? 2015", "shortCiteRegEx": "Ma et al\\.", "year": 2015}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["T. Mikolov", "I. Sutskever", "K. Chen", "G.S. Corrado", "J. Dean"], "venue": "Advances in neural information processing systems, pages 3111\u20133119.", "citeRegEx": "Mikolov et al\\.,? 2013", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Pystruct: learning structured prediction in python", "author": ["A.C. M\u00fcller", "S. Behnke"], "venue": "The Journal of Machine Learning Research, 15(1):2055\u20132060.", "citeRegEx": "M\u00fcller and Behnke,? 2014", "shortCiteRegEx": "M\u00fcller and Behnke", "year": 2014}, {"title": "Reading the riots: What were the police doing on twitter", "author": ["R. Procter", "J. Crump", "S. Karstedt", "A. Voss", "M. Cantijoch"], "venue": "Policing and society,", "citeRegEx": "Procter et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Procter et al\\.", "year": 2013}, {"title": "Reading the riots on twitter: methodological innovation for the analysis of big data", "author": ["R. Procter", "F. Vis", "A. Voss"], "venue": "International journal of social research methodology, 16(3):197\u2013214.", "citeRegEx": "Procter et al\\.,? 2013b", "shortCiteRegEx": "Procter et al\\.", "year": 2013}, {"title": "Rumor has it: Identifying misinformation in microblogs", "author": ["V. Qazvinian", "E. Rosengren", "D.R. Radev", "Q. Mei"], "venue": "Proceedings of EMNLP, pages 1589\u20131599.", "citeRegEx": "Qazvinian et al\\.,? 2011", "shortCiteRegEx": "Qazvinian et al\\.", "year": 2011}, {"title": "Twitterstand: news in tweets", "author": ["J. Sankaranarayanan", "H. Samet", "B.E. Teitler", "M.D. Lieberman", "J. Sperling"], "venue": "Proceedings of the 17th ACM SIGSPATIAL international conference on advances in geographic information systems, pages 42\u201351. ACM.", "citeRegEx": "Sankaranarayanan et al\\.,? 2009", "shortCiteRegEx": "Sankaranarayanan et al\\.", "year": 2009}, {"title": "Identifying rumors and their sources in social networks", "author": ["E. Seo", "P. Mohapatra", "T. Abdelzaher"], "venue": "SPIE defense, security, and sensing, pages 83891I\u201383891I. International Society for Optics and Photonics.", "citeRegEx": "Seo et al\\.,? 2012", "shortCiteRegEx": "Seo et al\\.", "year": 2012}, {"title": "Rumors, false flags, and digital vigilantes: Misinformation on twitter after the 2013 boston marathon bombing", "author": ["K. Starbird", "J. Maddock", "M. Orand", "P. Achterman", "R.M. Mason"], "venue": "iConference 2014 Proceedings.", "citeRegEx": "Starbird et al\\.,? 2014", "shortCiteRegEx": "Starbird et al\\.", "year": 2014}, {"title": "Detecting event rumors on sina weibo automatically", "author": ["S. Sun", "H. Liu", "J. He", "X. Du"], "venue": "Asia-Pacific Web Conference, pages 120\u2013131. Springer.", "citeRegEx": "Sun et al\\.,? 2013", "shortCiteRegEx": "Sun et al\\.", "year": 2013}, {"title": "An introduction to conditional random fields", "author": ["C. Sutton", "A. McCallum"], "venue": "Machine Learning, 4(4):267\u2013373.", "citeRegEx": "Sutton and McCallum,? 2011", "shortCiteRegEx": "Sutton and McCallum", "year": 2011}, {"title": "Rumor detection on twitter", "author": ["T. Takahashi", "N. Igata"], "venue": "Soft Computing and Intelligent Systems (SCIS) and 13th International Symposium on Advanced Intelligent Systems (ISIS), 2012 Joint 6th International Conference on, pages 452\u2013457. IEEE.", "citeRegEx": "Takahashi and Igata,? 2012", "shortCiteRegEx": "Takahashi and Igata", "year": 2012}, {"title": "Rumor diffusion and convergence during the 3.11 earthquake: a twitter case study", "author": ["M. Takayasu", "K. Sato", "Y. Sano", "K. Yamada", "W. Miura", "H. Takayasu"], "venue": "PLoS one,", "citeRegEx": "Takayasu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Takayasu et al\\.", "year": 2015}, {"title": "An analysis of event-agnostic features for rumour classification in twitter", "author": ["L. Tolosi", "A. Tagarev", "G. Georgiev"], "venue": "ICWSM Workshop on Social Media in the Newsroom.", "citeRegEx": "Tolosi et al\\.,? 2016", "shortCiteRegEx": "Tolosi et al\\.", "year": 2016}, {"title": "Digital wildfires: Propagation, verification, regulation, and responsible innovation", "author": ["H. Webb", "P. Burnap", "R. Procter", "O. Rana", "B. Stahl", "M. Williams", "W. Housley", "A. Edwards", "M. Jirotka"], "venue": "ACM Transactions on Information Systems, 34(3).", "citeRegEx": "Webb et al\\.,? 2016", "shortCiteRegEx": "Webb et al\\.", "year": 2016}, {"title": "False rumors detection on sina weibo by propagation structures", "author": ["K. Wu", "S. Yang", "K.Q. Zhu"], "venue": "2015 IEEE 31st International Conference on Data Engineering, pages 651\u2013662. IEEE.", "citeRegEx": "Wu et al\\.,? 2015", "shortCiteRegEx": "Wu et al\\.", "year": 2015}, {"title": " unconfirmed: Classifying rumor stance in crisis-related social media messages", "author": ["L. Zeng", "K. Starbird", "E.S. Spiro"], "venue": "Tenth International AAAI Conference on Web and Social Media.", "citeRegEx": "Zeng et al\\.,? 2016", "shortCiteRegEx": "Zeng et al\\.", "year": 2016}, {"title": "Enquiring minds: Early detection of rumors in social media from enquiry posts", "author": ["Z. Zhao", "P. Resnick", "Q. Mei"], "venue": "Proceedings of the 24th International Conference on World Wide Web, pages 1395\u20131405. ACM.", "citeRegEx": "Zhao et al\\.,? 2015", "shortCiteRegEx": "Zhao et al\\.", "year": 2015}, {"title": "Curating and contextualizing twitter stories to assist with social newsgathering", "author": ["A. Zubiaga", "H. Ji", "K. Knight"], "venue": "Proceedings of the 2013 international conference on Intelligent user interfaces, pages 213\u2013224. ACM.", "citeRegEx": "Zubiaga et al\\.,? 2013", "shortCiteRegEx": "Zubiaga et al\\.", "year": 2013}, {"title": "Crowdsourcing the annotation of rumourous conversations in social media", "author": ["A. Zubiaga", "M. Liakata", "R. Procter", "K. Bontcheva", "P. Tolmie"], "venue": "Proceedings of the 24th International Conference on World Wide Web Companion, pages 347\u2013353. International World Wide Web Conferences Steering Committee.", "citeRegEx": "Zubiaga et al\\.,? 2015", "shortCiteRegEx": "Zubiaga et al\\.", "year": 2015}, {"title": "Analysing how people orient to and spread rumours in social media by looking at conversational threads", "author": ["A. Zubiaga", "M. Liakata", "R. Procter", "G. Wong Sak Hoi", "P. Tolmie"], "venue": "PLoS ONE, 11(3):1\u201329.", "citeRegEx": "Zubiaga et al\\.,? 2016", "shortCiteRegEx": "Zubiaga et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 18, "context": "Well-known platforms such as Twitter are increasingly being used by people to learn about the latest developments (Sankaranarayanan et al., 2009), as well as by journalists for news gathering (Zubiaga et al.", "startOffset": 114, "endOffset": 145}, {"referenceID": 30, "context": ", 2009), as well as by journalists for news gathering (Zubiaga et al., 2013).", "startOffset": 54, "endOffset": 76}, {"referenceID": 26, "context": "A rumour detection system would ultimately warn users of the unverified status of a post, letting them know that it might later be proven false; this can be useful both to limit the diffusion of information that might turn out subsequently to be false and so reduce the risk of harm to individuals, communities and society (Webb et al., 2016).", "startOffset": 323, "endOffset": 342}, {"referenceID": 29, "context": "Research in rumour detection is scarce in the scientific literature, (Zhao et al., 2015) being the only published work to date that addresses this issue.", "startOffset": 69, "endOffset": 88}, {"referenceID": 32, "context": "Other work has dealt with \u201crumour detection\u201d with what we argue is a questionable definition and which conflicts with our own (Zubiaga et al., 2016).", "startOffset": 126, "endOffset": 148}, {"referenceID": 0, "context": "In our study we adhere to the prevailing definition in the scientific literature that understands a rumour as the information that is being circulated while its veracity is yet to be confirmed (Allport and Postman, 1946; DiFonzo and Bordia, 2007).", "startOffset": 193, "endOffset": 246}, {"referenceID": 29, "context": "The performance of CRF is compared with its non-sequential equivalent, a Maximum Entropy classifier, as well as the state-of-the-art rumour detection approach by (Zhao et al., 2015) and additional baseline classifiers.", "startOffset": 162, "endOffset": 181}, {"referenceID": 0, "context": "Moreover, (Allport and Postman, 1946) posit that one of the main reasons why rumours circulate is that \u201cthe topic has importance for the individual who hears and spreads the story\u201d.", "startOffset": 10, "endOffset": 37}, {"referenceID": 1, "context": "In (Allport and Postman, 1947), the authors also emphasise that \u201cnewsworthy events are likely to breed rumors\u201d and that \u201cthe amount of rumor in circulation will vary with the importance of the subject to the individuals involved times the ambiguity of the evidence pertaining to the topic at issue\u201d.", "startOffset": 3, "endOffset": 30}, {"referenceID": 32, "context": "Consistent with these definitions, we adhere here to a definition adapted to the context of breaking news, which we introduced in previous work (Zubiaga et al., 2016): a rumour is a \u201ccirculating story of questionable veracity, which is apparently credible but hard to verify, and produces sufficient skepticism and/or anxiety so as to motivate finding out the actual truth\u201d.", "startOffset": 144, "endOffset": 166}, {"referenceID": 16, "context": "Despite the increasing interest in analysing rumours in social media (Procter et al., 2013b; Procter et al., 2013a; Starbird et al., 2014; Zubiaga et al., 2015; Takayasu et al., 2015; Tolosi et al., 2016; Zubiaga et al., 2016) and the building of tools to deal with rumours that had been previously identified (Seo et al.", "startOffset": 69, "endOffset": 226}, {"referenceID": 20, "context": "Despite the increasing interest in analysing rumours in social media (Procter et al., 2013b; Procter et al., 2013a; Starbird et al., 2014; Zubiaga et al., 2015; Takayasu et al., 2015; Tolosi et al., 2016; Zubiaga et al., 2016) and the building of tools to deal with rumours that had been previously identified (Seo et al.", "startOffset": 69, "endOffset": 226}, {"referenceID": 31, "context": "Despite the increasing interest in analysing rumours in social media (Procter et al., 2013b; Procter et al., 2013a; Starbird et al., 2014; Zubiaga et al., 2015; Takayasu et al., 2015; Tolosi et al., 2016; Zubiaga et al., 2016) and the building of tools to deal with rumours that had been previously identified (Seo et al.", "startOffset": 69, "endOffset": 226}, {"referenceID": 24, "context": "Despite the increasing interest in analysing rumours in social media (Procter et al., 2013b; Procter et al., 2013a; Starbird et al., 2014; Zubiaga et al., 2015; Takayasu et al., 2015; Tolosi et al., 2016; Zubiaga et al., 2016) and the building of tools to deal with rumours that had been previously identified (Seo et al.", "startOffset": 69, "endOffset": 226}, {"referenceID": 25, "context": "Despite the increasing interest in analysing rumours in social media (Procter et al., 2013b; Procter et al., 2013a; Starbird et al., 2014; Zubiaga et al., 2015; Takayasu et al., 2015; Tolosi et al., 2016; Zubiaga et al., 2016) and the building of tools to deal with rumours that had been previously identified (Seo et al.", "startOffset": 69, "endOffset": 226}, {"referenceID": 32, "context": "Despite the increasing interest in analysing rumours in social media (Procter et al., 2013b; Procter et al., 2013a; Starbird et al., 2014; Zubiaga et al., 2015; Takayasu et al., 2015; Tolosi et al., 2016; Zubiaga et al., 2016) and the building of tools to deal with rumours that had been previously identified (Seo et al.", "startOffset": 69, "endOffset": 226}, {"referenceID": 19, "context": ", 2016) and the building of tools to deal with rumours that had been previously identified (Seo et al., 2012; Takahashi and Igata, 2012), there has been very little work in automatic rumour detection.", "startOffset": 91, "endOffset": 136}, {"referenceID": 23, "context": ", 2016) and the building of tools to deal with rumours that had been previously identified (Seo et al., 2012; Takahashi and Igata, 2012), there has been very little work in automatic rumour detection.", "startOffset": 91, "endOffset": 136}, {"referenceID": 17, "context": "Some of the work in rumour detection (Qazvinian et al., 2011; Hamidian and Diab, 2015; Hamidian and Diab, 2016) has been limited to finding rumours known a priori.", "startOffset": 37, "endOffset": 111}, {"referenceID": 5, "context": "Some of the work in rumour detection (Qazvinian et al., 2011; Hamidian and Diab, 2015; Hamidian and Diab, 2016) has been limited to finding rumours known a priori.", "startOffset": 37, "endOffset": 111}, {"referenceID": 29, "context": "To the best of our knowledge, the only work that has tackled the detection of new rumours is that by (Zhao et al., 2015).", "startOffset": 101, "endOffset": 120}, {"referenceID": 32, "context": "While this work builds on a sensible hypothesis and presents a clever approach to tackling the rumour detection task, we foresee three potential limitations: (1) being based on manually curated regular expressions the approach may not generalise well, (2) the hypothesis might not always apply and hence lead to low recall as, for example, certain rumours reported by reputable media are not always questioned by the general public (Zubiaga et al., 2016), and (3) it takes no account of the context that precedes the rumour, which can give additional insights into what is going on and how a piece of information can be rumourous in that context (e.", "startOffset": 432, "endOffset": 454}, {"referenceID": 17, "context": "For instance, there is an increasing body of work (Qazvinian et al., 2011; Liu et al., 2015; Hamidian and Diab, 2015; Hamidian and Diab, 2016; Lukasik et al., 2015; Zeng et al., 2016) looking into stance classification of tweets discussing rumours, categorising tweets as supporting, denying or questioning the rumour.", "startOffset": 50, "endOffset": 183}, {"referenceID": 9, "context": "For instance, there is an increasing body of work (Qazvinian et al., 2011; Liu et al., 2015; Hamidian and Diab, 2015; Hamidian and Diab, 2016; Lukasik et al., 2015; Zeng et al., 2016) looking into stance classification of tweets discussing rumours, categorising tweets as supporting, denying or questioning the rumour.", "startOffset": 50, "endOffset": 183}, {"referenceID": 5, "context": "For instance, there is an increasing body of work (Qazvinian et al., 2011; Liu et al., 2015; Hamidian and Diab, 2015; Hamidian and Diab, 2016; Lukasik et al., 2015; Zeng et al., 2016) looking into stance classification of tweets discussing rumours, categorising tweets as supporting, denying or questioning the rumour.", "startOffset": 50, "endOffset": 183}, {"referenceID": 10, "context": "For instance, there is an increasing body of work (Qazvinian et al., 2011; Liu et al., 2015; Hamidian and Diab, 2015; Hamidian and Diab, 2016; Lukasik et al., 2015; Zeng et al., 2016) looking into stance classification of tweets discussing rumours, categorising tweets as supporting, denying or questioning the rumour.", "startOffset": 50, "endOffset": 183}, {"referenceID": 28, "context": "For instance, there is an increasing body of work (Qazvinian et al., 2011; Liu et al., 2015; Hamidian and Diab, 2015; Hamidian and Diab, 2016; Lukasik et al., 2015; Zeng et al., 2016) looking into stance classification of tweets discussing rumours, categorising tweets as supporting, denying or questioning the rumour.", "startOffset": 50, "endOffset": 183}, {"referenceID": 21, "context": "There is also work on veracity classification both in the context of rumours and beyond (Sun et al., 2013; Cai et al., 2014; Liang et al., 2015; Liu et al., 2015; Ma et al., 2015; Wu et al., 2015; Ma et al., 2016; Jin et al., 2016).", "startOffset": 88, "endOffset": 231}, {"referenceID": 2, "context": "There is also work on veracity classification both in the context of rumours and beyond (Sun et al., 2013; Cai et al., 2014; Liang et al., 2015; Liu et al., 2015; Ma et al., 2015; Wu et al., 2015; Ma et al., 2016; Jin et al., 2016).", "startOffset": 88, "endOffset": 231}, {"referenceID": 9, "context": "There is also work on veracity classification both in the context of rumours and beyond (Sun et al., 2013; Cai et al., 2014; Liang et al., 2015; Liu et al., 2015; Ma et al., 2015; Wu et al., 2015; Ma et al., 2016; Jin et al., 2016).", "startOffset": 88, "endOffset": 231}, {"referenceID": 12, "context": "There is also work on veracity classification both in the context of rumours and beyond (Sun et al., 2013; Cai et al., 2014; Liang et al., 2015; Liu et al., 2015; Ma et al., 2015; Wu et al., 2015; Ma et al., 2016; Jin et al., 2016).", "startOffset": 88, "endOffset": 231}, {"referenceID": 27, "context": "There is also work on veracity classification both in the context of rumours and beyond (Sun et al., 2013; Cai et al., 2014; Liang et al., 2015; Liu et al., 2015; Ma et al., 2015; Wu et al., 2015; Ma et al., 2016; Jin et al., 2016).", "startOffset": 88, "endOffset": 231}, {"referenceID": 11, "context": "There is also work on veracity classification both in the context of rumours and beyond (Sun et al., 2013; Cai et al., 2014; Liang et al., 2015; Liu et al., 2015; Ma et al., 2015; Wu et al., 2015; Ma et al., 2016; Jin et al., 2016).", "startOffset": 88, "endOffset": 231}, {"referenceID": 7, "context": "There is also work on veracity classification both in the context of rumours and beyond (Sun et al., 2013; Cai et al., 2014; Liang et al., 2015; Liu et al., 2015; Ma et al., 2015; Wu et al., 2015; Ma et al., 2016; Jin et al., 2016).", "startOffset": 88, "endOffset": 231}, {"referenceID": 17, "context": "Our data collection approach differs substantially from that of previous work (Qazvinian et al., 2011; Procter et al., 2013b; Starbird et al., 2014), who first identified the rumours of interest and then collected tweets associated with those by filtering using relevant keywords.", "startOffset": 78, "endOffset": 148}, {"referenceID": 16, "context": "Our data collection approach differs substantially from that of previous work (Qazvinian et al., 2011; Procter et al., 2013b; Starbird et al., 2014), who first identified the rumours of interest and then collected tweets associated with those by filtering using relevant keywords.", "startOffset": 78, "endOffset": 148}, {"referenceID": 20, "context": "Our data collection approach differs substantially from that of previous work (Qazvinian et al., 2011; Procter et al., 2013b; Starbird et al., 2014), who first identified the rumours of interest and then collected tweets associated with those by filtering using relevant keywords.", "startOffset": 78, "endOffset": 148}, {"referenceID": 31, "context": "Afterwards, journalists read through the timeline to mark each of the tweets as being a rumour or not, making sure that the identification of rumours was in line with the established criteria (Zubiaga et al., 2015).", "startOffset": 192, "endOffset": 214}, {"referenceID": 29, "context": "We use the replying tweets for two purposes: (1) for the manual annotation work, where replies to each tweet can provide context for the annotator where needed to decide if a tweet is a rumour, and (2) we use them to reproduce a baseline classifier based on the baseline introduced by (Zhao et al., 2015).", "startOffset": 285, "endOffset": 304}, {"referenceID": 29, "context": "One possibility to extend a tweet with context is to look at how others react to it, as (Zhao et al., 2015) proposed in their work that querying or enquiring tweets provoked by a posting may indicate it is a rumour.", "startOffset": 88, "endOffset": 107}, {"referenceID": 29, "context": "Moreover, we also reproduce a baseline based on the approach introduced by (Zhao et al., 2015) to compare the performance of our approach with that of a state-of-the-art approach.", "startOffset": 75, "endOffset": 94}, {"referenceID": 22, "context": "The generalisable conditional distribution of CRF is shown in Equation 1 (Sutton and McCallum, 2011).", "startOffset": 73, "endOffset": 100}, {"referenceID": 29, "context": "Enquiry-based approach by (Zhao et al., 2015): As a state-of-the-art baseline for rumour detection, and the only approach that so far has tackled rumour detection in social media, we reproduce the approach by Zhao et al.", "startOffset": 26, "endOffset": 45}, {"referenceID": 14, "context": "2 We use the PyStruct to implement Conditional Random Fields (M\u00fcller and Behnke, 2014).", "startOffset": 61, "endOffset": 86}, {"referenceID": 13, "context": "\u2022 Word Vectors: to create vectors representing the words in each tweet, we build word vector representations using Word2Vec (Mikolov et al., 2013).", "startOffset": 124, "endOffset": 146}, {"referenceID": 3, "context": ", 2013) to parse the tweets for POS tags, an information extraction package that is part of GATE (Cunningham et al., 2011).", "startOffset": 97, "endOffset": 122}, {"referenceID": 29, "context": "Table 3 shows the results for different classifiers using either or both of the contentbased and social features, as well as the results for the state-of-the-art classifier by (Zhao et al., 2015).", "startOffset": 176, "endOffset": 195}, {"referenceID": 29, "context": "(Zhao et al., 2015) 0.", "startOffset": 0, "endOffset": 19}, {"referenceID": 29, "context": "Moreover, our approach also beats the state-of-the-art baseline by (Zhao et al., 2015) that uses regular expressions to classify as rumours the tweets that provoke reactions matching certain patterns.", "startOffset": 67, "endOffset": 86}, {"referenceID": 29, "context": "Our approach has also proven to outperform the state-of-the-art rumour detection system introduced by (Zhao et al., 2015) that, instead, relies on find querying posts that match a set of manually curated list of regular expressions.", "startOffset": 102, "endOffset": 121}, {"referenceID": 32, "context": ", 2015), we have been developing tools that address the need for the latter (Zubiaga et al., 2016; Lukasik et al., 2016).", "startOffset": 76, "endOffset": 120}], "year": 2016, "abstractText": "Breaking news leads to situations of fast-paced reporting in social media, producing all kinds of updates related to news stories, albeit with the caveat that some of those early updates tend to be rumours, i.e., information with an unverified status at the time of posting. Flagging information that is unverified can be helpful to avoid the spread of information that may turn out to be false. Detection of rumours can also feed a rumour tracking system that ultimately determines their veracity. In this paper we introduce a novel approach to rumour detection that learns from the sequential dynamics of reporting during breaking news in social media to detect rumours in new stories. Using Twitter datasets collected during five breaking news stories, we experiment with Conditional Random Fields as a sequential classifier that leverages context learnt during an event for rumour detection, which we compare with the state-of-the-art rumour detection system as well as other baselines. In contrast to existing work, our classifier does not need to observe tweets querying a piece of information to deem it a rumour, but instead we detect rumours from the tweet alone by exploiting context learnt during the event. Our classifier achieves competitive performance, beating the state-of-the-art classifier that relies on querying tweets with improved precision and recall, as well as outperforming our best baseline with nearly 40% improvement in terms of F1 score. The scale and diversity of our experiments reinforces the generalisability of our classifier.", "creator": "LaTeX with hyperref package"}}}