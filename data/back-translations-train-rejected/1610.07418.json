{"id": "1610.07418", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Oct-2016", "title": "Statistical Machine Translation for Indian Languages: Mission Hindi", "abstract": "This paper discusses Centre for Development of Advanced Computing Mumbai's (CDACM) submission to the NLP Tools Contest on Statistical Machine Translation in Indian Languages (ILSMT) 2014 (collocated with ICON 2014). The objective of the contest was to explore the effectiveness of Statistical Machine Translation (SMT) for Indian language to Indian language and English-Hindi machine translation. In this paper, we have proposed that suffix separation and word splitting for SMT from agglutinative languages to Hindi significantly improves over the baseline (BL). We have also shown that the factored model with reordering outperforms the phrase-based SMT for English-Hindi (\\enhi). We report our work on all five pairs of languages, namely Bengali-Hindi (\\bnhi), Marathi-Hindi (\\mrhi), Tamil-Hindi (\\tahi), Telugu-Hindi (\\tehi), and \\enhi for Health, Tourism, and General domains.", "histories": [["v1", "Mon, 24 Oct 2016 14:06:31 GMT  (21kb,D)", "http://arxiv.org/abs/1610.07418v1", "5 pages, Published at NLP Tools Contest: Statistical Machine Translation in Indian Languages, ICON-2015"]], "COMMENTS": "5 pages, Published at NLP Tools Contest: Statistical Machine Translation in Indian Languages, ICON-2015", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["raj nath patel", "prakash b pimpale", "sasikumar m"], "accepted": false, "id": "1610.07418"}, "pdf": {"name": "1610.07418.pdf", "metadata": {"source": "CRF", "title": "Statistical Machine Translation for Indian Languages: Mission Hindi", "authors": ["Raj Nath Patel", "Prakash B. Pimpale"], "emails": ["rajnathp@cdac.in", "prakash@cdac.in", "sasi@cdac.in"], "sections": [{"heading": "1 Introduction", "text": "In this paper, we present our experiments on SMT from Bengali, Marathi, Tamil, Telugu and English in Hindi. Of the languages involved in the common task, Bengali, Hindi and Marathi belong to the Indo-Aryan family and Tamil and Telugu belong to the Dravidian family. All languages except English have the same flexibility in word order, canonically according to the SOV structure. In terms of morphology, Bengali, Marathi, Tamil and Telugu are more agglutinative compared to Hindi. SMT is known to produce more unknown words, which leads to the poor translation quality when the morphological difference between the source and target languages is high. Koehn and Knight (2003), Popovic and Ney (2004) and Popovic'et al (2006) have shown ways to tackle this problem with morphological segmentation of words prior to SMT training."}, {"heading": "2 Methodology", "text": "Our methodology for coping with morphological and structural divergences includes the use of suffix separation, compound splitting and reordering for the language pairs studied. These methods are briefly described in the following. Pseudo-codes for suffix separation and compound word division are described in detail in algorithms 1 and 2, respectively."}, {"heading": "2.1 Suffix Separation (SS)", "text": "In this step, the words of the source language are pre-processed for the suffix separation. We have only looked at suffix from the source language which corresponds to postpositions in Hindi. In Marathi, for example, 1'mahinyaMnii' is translated in Hindi as' mahiine meM '. In this case, we have mavoc1All non-English (Marathi and Hindi) words in Itrans with http: / / sanskritlibrary. org / transcodeText.htmlar Xiv: 161 0.07 418v 1 [cs.C L] 24 October 201 6Algorithm 1 Suffix separation 1: Procedure SUFFIXSEP (word) 2: Suffix suffix list 3: Splits list 3: Suffix suffix suffix suffix 2: Suffix suffix suffix suffix suffix suffix list 5: if word.ENDSWITH = Suffix suffix suffix list 5: then word.LENDENDSWITSWITH > Suffid.H (.SUffid.H)."}, {"heading": "2.2 Compound Splitting (CS)", "text": "In this step, compound words are recursively divided into components, e.g. in Marathi, a compound word \"daMtatajGYaaaMkaDuuna\" in Hindi is translated as \"danta visheShaGYa se.\" In this case, we divide the compound word into components, \"daMta,\" \"tajGYaaM\" and \"kaDuuna.\" The list of compound suffixes for the division is compiled empirically from monolingual data. The algorithm for generating the compound suffix is very simple and simple, the pseudocode is detailed in Algoritm 2. A word is considered a compound suffix list if it appears as a suffix in another word of the monolingual corpus."}, {"heading": "2.3 Reordering (RO)", "text": "It is based on the syntactical transformation of the English sentence tree according to the target language (Hindi) structure. We have used the source-side reordering developed by Patel et al. (2013) and Ramanathan et al. (2008)."}, {"heading": "3 Data-set and Experimental Setup", "text": "We will now discuss the training and testing of corpus in the fields of health, tourism and general areas for be-hi, mrhi, ta-hi, te-hi and en-hi language pairs, followed by pre-processing, SMT system construction and evaluation metrics for experiments."}, {"heading": "3.1 Corpus for SMT Training and Testing", "text": "For experiments, we used the corpus split by ILSMT organizers, which is described in Table 1. Additional monolingual corpus of approximately 23K sentences (Khapra et al., 2010) is used to train the language model. Evaluation of the systems was based on Test1 data, which was the development set. The quality of the submitted systems was assessed by the organizers against the Test2 corpus."}, {"heading": "3.2 Pre-Processing", "text": "To address the morphological divergence between source and target languages (Bengali / Marathi / Tamil / Telugu to Hindi), we used suffix separation and compound splitting as described in Section 2. To address the structural divergence for English-Hindi SMT, we used source-side preference (Patel et al., 2013; Ramanathan et al., 2008)."}, {"heading": "3.3 SMT System Set up", "text": "The basic system was constructed using the phrase-based model (Brown et al., 1990; Marcu and Wong, 2002; Och and Ney, 2003; Koehn et al., 2003) and Koehn et al. (2007) was used as factor model.The language model was trained using the KenLM (Heafield, 2011) toolkits with modified Kneser-Ney smoothing (Chen and Goodman, 1996).For the factored SMT training we used source and target side stem as alignment factor. Stepping was done with a light shaft (Ramanathan and Rao, 2003) for Hindi. For English we used carrier trunk (Minnen et al., 2001)."}, {"heading": "3.4 Evaluation Metrics", "text": "We compared different experimental systems with BLEU (Papineni et al., 2002), NIST (Doddington, 2002) and Translation Edit Rate (TER) (Snover et al., 2006). For an MT system to be better, higher BLEU- and NIST-values with lower TER are desirable."}, {"heading": "4 Experiments and Results", "text": "In the following sections, we present various experiments performed for the common task, as well as the effects of suffix separation, compound splitting, and pre-arrangement on SMT accuracy."}, {"heading": "4.1 Impact of Suffix Separation and Compound Splitting", "text": "The improvement in translation quality can be seen from the different scores in Table 3. From the table, we can conclude that the suffix separation for be-hi and mr-hi has shown significant improvements over the baseline, while the suffix separation for ta-hi and te-hi has resulted in a slight improvement. However, it has been found that the suffix separation is more effective than the suffix separation for ta-hi and te-hi. We have also tried a combination of compound word splitting and suffix separation, namely serial. We have observed improvements over the BL + SS and BL + CS for ta-hi and te-hi for the scores, and BL + SS for the scores. BL + SS is better than all other systems for be-hi, for the rating metrics, while mr-hi BL + CS + SS can be determined for the highest BLEU- and BL + SS + scores for the best TIST systems."}, {"heading": "4.2 Impact of Reordering", "text": "Pre-sorting the source language sentence helps to better align and decode English to Indian (Ramanathan et al., 2008; Patel et al., 2013; Kunchukuttan et al., 2014). Table 4 describes the results for the systems studied. We see that BL + RO shows a significant improvement over BL. Furthermore, the factorized SMT system with strain as an alignment factor shows a slight improvement in BLEU over BL + RO, but other indicators show that BL + RO is better than the factorized system."}, {"heading": "5 Submission", "text": "In this section we discuss the evaluation results of the submitted systems. We have submitted BL + SS for behi and BL + CS + SS for all other language pairs except en-hi. For en-hi, BL + RO + FACT is submitted as the final system. Table 5 summarizes the evaluation of the submission against Test1 and Test2."}, {"heading": "6 Error Analysis", "text": "A closer look at the performance of these systems has been taken to understand the benefits of SS and CS. We report on some early observations."}, {"heading": "6.1 Superfluous Splitting", "text": "With the suffix separation, the Marathi word splits like \"dilaavara\" into \"dilaa\" + \"vara,\" which is an incorrect split. Since \"dilaavara\" is a proper word and therefore should not have been split, we tried to correct this error by avoiding suffix separation and compound splitting of NNP-POS marked words, but this stopped many other valid candidates from pre-processing."}, {"heading": "6.2 Bad Split", "text": "The words like \"jarmaniitiila\" split into \"jarmaniit +\" iila, which should have been divided into \"jarmanii +\" tiila. \"Similarly, many words about splitting have not given a valid Marathi word, which would have caused the scarcity of training data to some extent."}, {"heading": "7 Conclusion and Future Work", "text": "In this paper we presented different systems for translation from Bengali, English, Marathi, Tamil Telugu to Hindi. These SMT systems with source-side suffix separation, compound splitting and pre-recording showed significantly higher accuracy over the baseline. In the future, we could study the formulation of more effective solutions for SS, CS and RO. Reasons for a lower BLEU due to the combination of suffix separation and compound word division for Bengali and Marathi are another interesting case that we should investigate further."}], "references": [{"title": "A Statistical Approach to Machine Translation", "author": ["Brown et al.1990] Peter F Brown", "John Cocke", "Stephen A Della Pietra", "Vincent J Della Pietra", "Fredrick Jelinek", "John D Lafferty", "Robert L Mercer", "Paul S Roossin"], "venue": "Computational linguistics,", "citeRegEx": "Brown et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Brown et al\\.", "year": 1990}, {"title": "An Empirical Study of Smoothing Techniques for Language Modeling", "author": ["Chen", "Goodman1996] Stanley F Chen", "Joshua Goodman"], "venue": "In Proceedings of the 34th annual meeting on Association for Computational Linguistics,", "citeRegEx": "Chen et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Chen et al\\.", "year": 1996}, {"title": "Automatic Evaluation of Machine Translation Quality using N-gram Co-occurrence Statistics", "author": ["George Doddington"], "venue": null, "citeRegEx": "Doddington.,? \\Q2002\\E", "shortCiteRegEx": "Doddington.", "year": 2002}, {"title": "KenLM: Faster and Smaller Language Model Queries", "author": ["Kenneth Heafield"], "venue": "In Proceedings of the Sixth Workshop on Statistical Machine Translation,", "citeRegEx": "Heafield.,? \\Q2011\\E", "shortCiteRegEx": "Heafield.", "year": 2011}, {"title": "All Words Domain Adapted WSD: Finding a Middle Ground between Supervision and Unsupervision", "author": ["Anup Kulkarni", "Saurabh Sohoney", "Pushpak Bhattacharyya"], "venue": "In Proceedings of the 48th Annual Meet-", "citeRegEx": "Khapra et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Khapra et al\\.", "year": 2010}, {"title": "Factored translation models", "author": ["Koehn", "Hoang2007] Philipp Koehn", "Hieu Hoang"], "venue": "In EMNLP-CoNLL,", "citeRegEx": "Koehn et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Koehn et al\\.", "year": 2007}, {"title": "Empirical Methods for Compound Splitting", "author": ["Koehn", "Knight2003] Philipp Koehn", "Kevin Knight"], "venue": "In Proceedings of the tenth conference on European chapter of the Association for Computational Linguistics-Volume", "citeRegEx": "Koehn et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Koehn et al\\.", "year": 2003}, {"title": "Statistical Phrase-Based Translation", "author": ["Koehn et al.2003] Philipp Koehn", "Franz Josef Och", "Daniel Marcu"], "venue": "In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language", "citeRegEx": "Koehn et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Koehn et al\\.", "year": 2003}, {"title": "Sata-anuvadak: Tackling multiway translation of indian languages", "author": ["Abhijit Mishra", "Rajen Chatterjee", "Ritesh Shah", "Pushpak Bhattacharyya"], "venue": null, "citeRegEx": "Kunchukuttan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kunchukuttan et al\\.", "year": 2014}, {"title": "A Phrase-Based, Joint Probability Model for Statistical Machine Translation", "author": ["Marcu", "Wong2002] Daniel Marcu", "William Wong"], "venue": "In Proceedings of the ACL-02 conference on Empirical methods in natural language processing-Volume", "citeRegEx": "Marcu et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Marcu et al\\.", "year": 2002}, {"title": "Applied morphological processing of english", "author": ["Minnen et al.2001] Guido Minnen", "John Carroll", "Darren Pearce"], "venue": "Natural Language Engineering,", "citeRegEx": "Minnen et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Minnen et al\\.", "year": 2001}, {"title": "A Systematic Comparison of Various Statistical Alignment Models", "author": ["Och", "Ney2003] Franz Josef Och", "Hermann Ney"], "venue": "Computational linguistics,", "citeRegEx": "Och et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Och et al\\.", "year": 2003}, {"title": "BLEU: A Method for Automatic Evaluation of Machine Translation", "author": ["Salim Roukos", "Todd Ward", "Wei-Jing Zhu"], "venue": "In Proceedings of the 40th annual meeting on association for computational linguis-", "citeRegEx": "Papineni et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Papineni et al\\.", "year": 2002}, {"title": "Reordering rules for english-hindi smt", "author": ["Patel et al.2013] Raj Nath Patel", "Rohit Gupta", "Prakash B Pimpale", "Sasikumar M"], "venue": "In Proceedings of the Second Workshop on Hybrid Approaches to Translation,", "citeRegEx": "Patel et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Patel et al\\.", "year": 2013}, {"title": "Towards the Use of Word Stems and Suffixes for Statistical Machine Translation", "author": ["Popovic", "Ney2004] Maja Popovic", "Hermann Ney"], "venue": null, "citeRegEx": "Popovic et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Popovic et al\\.", "year": 2004}, {"title": "Statistical Machine Translation of German Compound Words", "author": ["Popovi\u0107 et al.2006] Maja Popovi\u0107", "Daniel Stein", "Hermann Ney"], "venue": "In Advances in Natural Language Processing,", "citeRegEx": "Popovi\u0107 et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Popovi\u0107 et al\\.", "year": 2006}, {"title": "A Lightweight Stemmer for Hindi", "author": ["Ramanathan", "Durgesh D Rao"], "venue": "In The Proceedings of EACL", "citeRegEx": "Ramanathan et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Ramanathan et al\\.", "year": 2003}, {"title": "Simple Syntactic and Morphological Processing Can Help English-Hindi Statistical Machine", "author": ["Ramanathan", "Jayprasad Hegde", "Ritesh M Shah", "Pushpak Bhattacharyya", "M Sasikumar"], "venue": null, "citeRegEx": "Ramanathan et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Ramanathan et al\\.", "year": 2008}, {"title": "A Study of Translation Edit Rate with Targeted Human Annotation. In Proceedings of association for machine translation in the Ameri", "author": ["Bonnie Dorr", "Richard Schwartz", "Linnea Micciulla", "John Makhoul"], "venue": null, "citeRegEx": "Snover et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Snover et al\\.", "year": 2006}], "referenceMentions": [{"referenceID": 15, "context": "Koehn and Knight (2003), Popovic and Ney (2004) and Popovi\u0107 et al. (2006) have demonstrated ways to handle this issue with morphological segmentation of words before training the SMT system.", "startOffset": 52, "endOffset": 74}, {"referenceID": 13, "context": "by Patel et al. (2013) and stem as an alignment factor (Koehn and Hoang, 2007).", "startOffset": 3, "endOffset": 23}, {"referenceID": 13, "context": "We have used source side reordering developed by Patel et al. (2013), and Ramanathan et al.", "startOffset": 49, "endOffset": 69}, {"referenceID": 13, "context": "We have used source side reordering developed by Patel et al. (2013), and Ramanathan et al. (2008). health tourism general training (TM) 24K 24K 48K training (LM) 71K 71K 71K test1 500 500 1000 test2 500 500 1000", "startOffset": 49, "endOffset": 99}, {"referenceID": 4, "context": ", 23K sentences (Khapra et al., 2010) is used to train the language model.", "startOffset": 16, "endOffset": 37}, {"referenceID": 13, "context": "To handle the structural divergence for English-Hindi SMT, we exploited source side preordering (Patel et al., 2013; Ramanathan et al., 2008).", "startOffset": 96, "endOffset": 141}, {"referenceID": 17, "context": "To handle the structural divergence for English-Hindi SMT, we exploited source side preordering (Patel et al., 2013; Ramanathan et al., 2008).", "startOffset": 96, "endOffset": 141}, {"referenceID": 0, "context": "The baseline system was setup using the phrasebased model ( (Brown et al., 1990; Marcu and Wong, 2002; Och and Ney, 2003; Koehn et al., 2003) and Koehn et al.", "startOffset": 60, "endOffset": 141}, {"referenceID": 6, "context": "The baseline system was setup using the phrasebased model ( (Brown et al., 1990; Marcu and Wong, 2002; Och and Ney, 2003; Koehn et al., 2003) and Koehn et al.", "startOffset": 60, "endOffset": 141}, {"referenceID": 3, "context": "The language model was trained using KenLM (Heafield, 2011) toolkit with modified Kneser-Ney smoothing (Chen and Goodman, 1996).", "startOffset": 43, "endOffset": 59}, {"referenceID": 10, "context": "For English, we used porter stemmer (Minnen et al., 2001).", "startOffset": 36, "endOffset": 57}, {"referenceID": 0, "context": "The baseline system was setup using the phrasebased model ( (Brown et al., 1990; Marcu and Wong, 2002; Och and Ney, 2003; Koehn et al., 2003) and Koehn et al. (2007) was used for factored model.", "startOffset": 61, "endOffset": 166}, {"referenceID": 12, "context": "We compared different experimental systems using BLEU (Papineni et al., 2002), NIST (Dodding-", "startOffset": 54, "endOffset": 77}, {"referenceID": 18, "context": "ton, 2002) and translation edit rate (TER) (Snover et al., 2006).", "startOffset": 43, "endOffset": 64}, {"referenceID": 17, "context": "Preordering of the source language sentence helps in the better alignment and decoding for English to Indian language (Ramanathan et al., 2008; Patel et al., 2013; Kunchukuttan et al., 2014) SMT.", "startOffset": 118, "endOffset": 190}, {"referenceID": 13, "context": "Preordering of the source language sentence helps in the better alignment and decoding for English to Indian language (Ramanathan et al., 2008; Patel et al., 2013; Kunchukuttan et al., 2014) SMT.", "startOffset": 118, "endOffset": 190}, {"referenceID": 8, "context": "Preordering of the source language sentence helps in the better alignment and decoding for English to Indian language (Ramanathan et al., 2008; Patel et al., 2013; Kunchukuttan et al., 2014) SMT.", "startOffset": 118, "endOffset": 190}], "year": 2016, "abstractText": "This paper discusses Centre for Development of Advanced Computing Mumbai\u2019s (CDACM) submission to the NLP Tools Contest on Statistical Machine Translation in Indian Languages (ILSMT) 2014 (collocated with ICON 2014). The objective of the contest was to explore the effectiveness of Statistical Machine Translation (SMT) for Indian language to Indian language and English-Hindi machine translation. In this paper, we have proposed that suffix separation and word splitting for SMT from agglutinative languages to Hindi significantly improves over the baseline (BL). We have also shown that the factored model with reordering outperforms the phrase-based SMT for EnglishHindi (en-hi). We report our work on all five pairs of languages, namely Bengali-Hindi (be-hi), Marathi-Hindi (mrhi), Tamil-Hindi (ta-hi), Telugu-Hindi (tehi), and en-hi for Health, Tourism, and General domains.", "creator": "LaTeX with hyperref package"}}}