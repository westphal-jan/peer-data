{"id": "1610.07419", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Oct-2016", "title": "Using Machine Learning to Detect Noisy Neighbors in 5G Networks", "abstract": "5G networks are expected to be more dynamic and chaotic in their structure than current networks. With the advent of Network Function Virtualization (NFV), Network Functions (NF) will no longer be tightly coupled with the hardware they are running on, which poses new challenges in network management. Noisy neighbor is a term commonly used to describe situations in NFV infrastructure where an application experiences degradation in performance due to the fact that some of the resources it needs are occupied by other applications in the same cloud node. These situations cannot be easily identified using straightforward approaches, which calls for the use of sophisticated methods for NFV infrastructure management. In this paper we demonstrate how Machine Learning (ML) techniques can be used to identify such events. Through experiments using data collected at real NFV infrastructure, we show that standard models for automated classification can detect the noisy neighbor phenomenon with an accuracy of more than 90% in a simple scenario.", "histories": [["v1", "Mon, 24 Oct 2016 14:07:56 GMT  (32kb,D)", "http://arxiv.org/abs/1610.07419v1", null]], "reviews": [], "SUBJECTS": "cs.NI cs.LG", "authors": ["udi margolin", "alberto mozo", "bruno ordozgoiti", "danny raz", "elisha rosensweig", "itai segall"], "accepted": false, "id": "1610.07419"}, "pdf": {"name": "1610.07419.pdf", "metadata": {"source": "CRF", "title": "Using Machine Learning to Detect Noisy Neighbors in 5G Networks", "authors": ["Udi Margolin", "Alberto Mozo", "Bruno Ordozgoiti", "Danny Raz", "Elisha Rosensweig", "Itai Segall"], "emails": ["bruno.ordozgoiti@etsisi.upm.es,", "danny.raz@nokia.com"], "sections": [{"heading": null, "text": "This year, it has reached the point where it will be able to retaliate."}, {"heading": "II. PROBLEM SETTING", "text": "This test environment consists of a total of five high-performance servers (each with 12 cores) with a proprietary management system running on an OpenStack cloud [3]. Two of the servers are dedicated to management processes, while the other three are available as computing systems. A corresponding server is inserted and configured in a second machine to guide and guide the server, in a single virtual machine that uses a core and 1024 MB of memory."}, {"heading": "III. MACHINE LEARNING METHODS", "text": "The problem of whether or not the behavior of a virtual machine is caused by the presence of a noisy neighbor is not trivial. Based on the measurements described above, a simple threshold approach or set of rules would not suffice. To solve this problem, we propose the use of machine learning methods. Machine learning has proven successful in a variety of areas, such as computer vision [15] [11], bioinformatics [17], natural language processing [12] [16] and others. A key advantage of machine learning is that the same models can be applied to completely different areas, provided the data is transformed into an adequate representation. In this paper, we address the problem of whether or not there is a noisy neighboring situation that can be modeled as a classification problem in machine learning. Therefore, we propose to use two well-known classifiers: support vector machines and random forests."}, {"heading": "A. Support vector machines", "text": "In the face of a set of data points presented as real-rated vectors corresponding to two different classes, support vector machines (SVM) [9] present the problem of finding a maximum margin separating the hyperplane. It can be shown that this corresponds to a minimization of the norm of the vector, which is orthogonal to the said hyperplane and forces the data points of the different classes to lie on different sides and at a minimum distance from it. Formally, this can be formulated as the following. In the face of a set of data points {x1,.., xn} and corresponding designations {y1,., yn}, where xi, xi, Rd and yi, [\u2212 1, 1}, i = 1,.., n, for some d,."}, {"heading": "B. Random forests", "text": "Random forests [8], because of their simplicity, efficiency and effectiveness, are a learning model that combines decision trees with the concept of bagging [7] and selecting random characteristics. Random forests work by combining bagging or bootstrap aggregation with decision trees. Specifically, a number of random samples are taken from the data set and substituted, and a decision tree is trained for each of these nodes.The final decision to classify an invisible data instance is made by the majority vote of the tracked decision trees. Decision trees, in turn, are created by building a hierarchy of binary split nodes. The criterion for selecting the split rule for each node is to maximize information gain based on a certain level of entropy. In addition to the bagging process, random forests also use random subsets of characteristics. In our case, however, we limit the model to decision trees because of the small number of features."}, {"heading": "IV. EXPERIMENTAL RESULTS", "text": "In this section, we describe the experiments that have been carried out to assess the validity of machine learning as a method for detecting noisy neighbours, as well as the results obtained."}, {"heading": "A. Data", "text": "Each of the resulting data points represents the average CPU load, the incoming and outgoing bandwidth of the monitored machine, and the corresponding binary label determines whether or not the noisy neighbor has caused a load during that period. The resulting data set consists of 9169 data instances, of which 3088 correspond to noisy neighbors. As mentioned above, detecting noisy neighbors from the available data is not trivial. To illustrate this fact, Table I shows two different measurements of the relationship between the characteristics collected and the noise value; the first line shows the correlation coefficient between each of the different characteristics and the CPU load of the machine that generates noise; the second line shows the coefficient (MIC), which itself proves to be highly reliable."}, {"heading": "B. Experiments", "text": "We train the two models described in Section III on the automatic classification of data instances that correspond to a noisy neighborhood situation or not. Input data is standardized to zero mean and variance. In both cases, we follow a 10-fold cross-sectional validation process. We now describe the specific training procedures for each of the models1) Support vector machines: We train \"1 soft margin models with the minimum sequential optimization algorithm [13] using a Gaussian kernel that can be defined as K (u, v)."}, {"heading": "V. CONCLUSIONS & FUTURE WORK", "text": "In this paper, we have examined how machine learning can help manage the NFV infrastructure, which is expected to be a widespread approach in 5G networks. In particular, we have shown that standard classification models can detect the noisy neighbouring phenomenon in a simple scenario with an accuracy of over 90%. In the future, it would be interesting to evaluate the performance of these models in more complex scenarios. It would also be interesting to extract more features from the infrastructure and use more complex models for improved classification rates."}, {"heading": "ACKNOWLEDGMENT", "text": "The research that led to these results was funded by the European Union under the H2020 Funding Agreement No 671625 (CogNet project) and the authors thank Ignacio Rubio Lo'pez for his valuable help in conducting experiments."}], "references": [{"title": "A training algorithm for optimal margin classifiers", "author": ["Bernhard E Boser", "Isabelle M Guyon", "Vladimir N Vapnik"], "venue": "In Proceedings of the fifth annual workshop on Computational learning theory,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1992}, {"title": "Can machine learning aid in delivering new use cases & scenarios in 5g", "author": ["T.S. Buda"], "venue": "In The First IFIP/IEEE International Workshop on Management of 5G Networks,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2016}, {"title": "Imagenet classification with deep convolutional neural networks. In Advances in neural information processing", "author": ["Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E Hinton"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2012}, {"title": "Hierarchical probabilistic neural network language model", "author": ["Frederic Morin", "Yoshua Bengio"], "venue": "In Aistats,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2005}, {"title": "Sequential minimal optimization: A fast algorithm for training support vector machines", "author": ["John Platt"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1998}, {"title": "Detecting novel associations in large data", "author": ["David N Reshef", "Yakir A Reshef", "Hilary K Finucane", "Sharon R Grossman", "Gilean McVean", "Peter J Turnbaugh", "Eric S Lander", "Michael Mitzenmacher", "Pardis C Sabeti"], "venue": "sets. science,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2011}, {"title": "Deep boltzmann machines", "author": ["Ruslan Salakhutdinov", "Geoffrey E Hinton"], "venue": "In International conference on artificial intelligence and statistics,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2009}, {"title": "Lstm neural networks for language modeling", "author": ["Martin Sundermeyer", "Ralf Schl\u00fcter", "Hermann Ney"], "venue": "In INTERSPEECH,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2012}, {"title": "A review of ensemble methods in bioinformatics", "author": ["Pengyi Yang", "Yee Hwa Yang", "Bing B Zhou", "Albert Y Zomaya"], "venue": "Current Bioinformatics,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2010}], "referenceMentions": [{"referenceID": 1, "context": "This is a critical building block in addressing use cases similar to the Optimized Services in Dynamic Environments use case described in [10].", "startOffset": 138, "endOffset": 142}, {"referenceID": 6, "context": "vision [15] [11], bioinformatics [17], natural language processing [12][16] and others.", "startOffset": 7, "endOffset": 11}, {"referenceID": 2, "context": "vision [15] [11], bioinformatics [17], natural language processing [12][16] and others.", "startOffset": 12, "endOffset": 16}, {"referenceID": 8, "context": "vision [15] [11], bioinformatics [17], natural language processing [12][16] and others.", "startOffset": 33, "endOffset": 37}, {"referenceID": 3, "context": "vision [15] [11], bioinformatics [17], natural language processing [12][16] and others.", "startOffset": 67, "endOffset": 71}, {"referenceID": 7, "context": "vision [15] [11], bioinformatics [17], natural language processing [12][16] and others.", "startOffset": 71, "endOffset": 75}, {"referenceID": 0, "context": "The sole dependence of this formulation on the inner products allows for the use of a technique often referred to as the kernel trick [5].", "startOffset": 134, "endOffset": 137}, {"referenceID": 5, "context": "The second row shows the maximal information coefficient (MIC) [14].", "startOffset": 63, "endOffset": 67}, {"referenceID": 4, "context": "1) Support vector machines: We train `1 soft-margin models with the sequential minimal optimization algorithm [13] using a Gaussian kernel.", "startOffset": 110, "endOffset": 114}], "year": 2016, "abstractText": "5G networks are expected to be more dynamic and chaotic in their structure than current networks. With the advent of Network Function Virtualization (NFV), Network Functions (NF) will no longer be tightly coupled with the hardware they are running on, which poses new challenges in network management. Noisy neighbor is a term commonly used to describe situations in NFV infrastructure where an application experiences degradation in performance due to the fact that some of the resources it needs are occupied by other applications in the same cloud node. These situations cannot be easily identified using straightforward approaches, which calls for the use of sophisticated methods for NFV infrastructure management. In this paper we demonstrate how Machine Learning (ML) techniques can be used to identify such events. Through experiments using data collected at real NFV infrastructure, we show that standard models for automated classification can detect the noisy neighbor phenomenon with an accuracy of more than 90% in a simple scenario.", "creator": "LaTeX with hyperref package"}}}