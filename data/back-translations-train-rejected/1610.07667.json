{"id": "1610.07667", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Oct-2016", "title": "Predicting Counterfactuals from Large Historical Data and Small Randomized Trials", "abstract": "When a new treatment is considered for use, whether a pharmaceutical drug or a search engine ranking algorithm, a typical question that arises is, will its performance exceed that of the current treatment? The conventional way to answer this counterfactual question is to estimate the effect of the new treatment in comparison to that of the conventional treatment by running a controlled, randomized experiment. While this approach theoretically ensures an unbiased estimator, it suffers from several drawbacks, including the difficulty in finding representative experimental populations as well as the cost of running such trials. Moreover, such trials neglect the huge quantities of available control-condition data which are often completely ignored.", "histories": [["v1", "Mon, 24 Oct 2016 22:12:52 GMT  (211kb,D)", "https://arxiv.org/abs/1610.07667v1", null], ["v2", "Wed, 26 Oct 2016 06:11:07 GMT  (213kb,D)", "http://arxiv.org/abs/1610.07667v2", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["nir rosenfeld", "yishay mansour", "elad yom-tov"], "accepted": false, "id": "1610.07667"}, "pdf": {"name": "1610.07667.pdf", "metadata": {"source": "CRF", "title": "Predicting Counterfactuals from Large Historical Data and Small Randomized Trials", "authors": ["Nir Rosenfeld", "Yishay Mansour", "Elad Yom-Tov"], "emails": ["nir.rosenfeld@mail.huji.ac.il", "mansour@microsoft.com", "eladyt@microsoft.com", "permissions@acm.org."], "sections": [{"heading": null, "text": "In this paper, we propose a discriminatory framework for evaluating the performance of a new treatment, as a large data set on the control status and data from a small (and possibly unrepresentative) randomized trial comparing new and old treatments are available. Our goal, which requires minimal assumptions about the treatments, models the relationship between the outcomes of the different conditions, allowing us not only to estimate mean effects, but also to make individual predictions for examples outside the randomized sample. We demonstrate the benefits of our approach through experiments in three areas: search engine operation, treatments for diabetes patients, and market valuation for homes. Our results show that our approach can reduce the number and size of randomized controlled experiments currently conducted, saving practitioners significant time, money, and effort."}, {"heading": "1. INTRODUCTION", "text": "This year it is more than ever before."}, {"heading": "2. RELATED MATERIAL", "text": "The fundamental property of the predictive task we are looking at is that it is counterproductive in nature. Causal conclusions [13] are a standard framework for assessing the causal relationship between variables in a way that can then be used to answer counterproductive questions. To achieve this, methods of causal inference are usually based on simple models that can be interpreted from which to draw on arbitrary characteristics [4]. Our approach is different, focusing on predictions by introducing parameterized predictors."}, {"heading": "3. NOTATIONS", "text": "We assume that the examples come from a general domain X, so we use X \u2032 X to denote the subdomain of the examples participating in the controlled studies. We have two label domains designated by YC for the control variable and by YT for the treatment variable. Throughout the essay, we use the terms label, variable and experimental results interchangeable. Instances of the examples are denoted by x-X, and the labels are denoted by yC-YC and yT-YT. We assume that there is a single common distribution DX, YC, YT for tuples (x, yT), although we do not have direct access to them, nor do we observe such tuples. Rather, we assume that in a given example, x-DX is drawn from the boundary distribution."}, {"heading": "4. PROBLEM STATEMENT", "text": "Remember that our goal is to create a framework for learning predictors by using both the small randomized trial data (S \u2032 C, S \u2032 T) and the large control data set SC. The main task we are considering is to predict the treatment variable yT for new, unobserved examples from a test set ST \u0445 DX, YT. In other words, we want our predictor YT to generalize well to the general population. The challenge here is that our data contain only a small number of treatment labels. [14, 20] The solution we present in Section 5 uses all available data by modeling the relationship between control and treatment variable. A related task that is of great interest in predicting the individual treatment effect y \u0445 = yT \u2212 yC. Precise predictions of y \u00b2 can in principle help decision makers in deciding which treatment to use. Predictions of this kind can also be used to estimate the conventional treatment effect and provide an alternative to the mean effect."}, {"heading": "5. METHOD", "text": "We assume that predictors are linear in some characteristics (x) as we describe them in sec."}, {"heading": "6. EXTENSIONS", "text": "In the section above, we presented our method for a regression task using a quadratic loss function and a '2 regularization term. Note, however, that our only modeling assumption was that both yT and yC (and accordingly y \u0445) 3This is similar to the regularization term of the fused lasso approach [19] used for time series predictions. Approved for linear predictors under a common feature representation. This simple assumption allows us to apply our method to more general settings and, in some cases, to offer a closed solution."}, {"heading": "6.1 Linear predictors", "text": "A direct conclusion from the above is that our method can be applied to all general loss functions L (< w, x >, y), which are defined by a linear predictor, and to any regularization term Q (w) of the predictor parameter.The general form of the training target in equivalent (5) for linear predictors is given by the following factors: min wT, w \u00b2 p \u00b2 p \u00b2 p \u00b2 p \u00b2 p \u00b2 p (< wT, x (i) p \u00b2 p (i) p \u00b2 p (1 \u2212 p) p \u00b2 p \u00b2 p (< wT \u2212 w) p \u00b2 p (i) p \u00b2 p (i) p \u00b2 p (i) p \u00b2 p (i) p (c \u00b2 p (i) p) p (c \u00b2 p (i) p (i) p (i) p (i) p (i) p (i) p (i) p (i) p (i) p (i) p (i) p (i) p (i) p (i) p (i) p (i) p (i) p (i) p (i) p) p (i) p (i) p (c) p (c) c \u00b2 p (i) p (i) p (i) p (i) p (p) p (i) p (i) p (p) p (i) p (p) p (p) p (i) p (p (p) p (i) p (p) p (p (i) p (c) p (i) p (i) p (i) p (p (p) p (i) p (i) p (i) p (p (p) p (p (i) p (p) p (p (i) p (p) p (i) p (p (p (p) p) p (i) p (p (p) p (p (i) p (p (p) p) p (p (p) p (p (p (p) p) p (p) p) p (p (p) p (p (p (p (p) p (p) p) p) p (p (p) p (p (p (p) p (p (p) p) p ("}, {"heading": "6.2 Closed form solution", "text": "If we apply our method to the burr regression (as in the example in Sec. 5), we can achieve a closed solution of the object in Eq. (5) with the setting R (\u00b7) = Eq. 22 by converting the lens into a canonical burr regression form: min w, w > X \u2212 Y, and the regulating constant \u03b1, so that the minimizer of Eq. (5) can be extracted from w. Since the target in Eq. (5) includes both the minimization via wT and w, we first define w as its concatenation, namely w = (wT, w), w = R2d. Under this extended representation, the next result is the minimization via wT and w."}, {"heading": "6.3 Non-linear predictors", "text": "While linear predictors are easy to use and often work well in practice, they lack the meaningfulness that nonlinear predictors provide. As our method is not limited to a specific representation, a simple method of incorporating nonlinearity via nuclei, as we describe it, can be used. In Sec. 6.2, the construction in Eq. (9) shows how the regulation of w can be achieved by a simple extension of function representation. A similar procedure can be applied to a more general case, especially if R, Q decompose and R = Q. For \u03b3 = 1 / 2,4, the setting of extended function characteristics (x) = (x, 0) for x, S \"T\" and (x) for x, \u2212 cx \"SC with c = distortion and Q for a single constant function component (x)."}, {"heading": "7. EXPERIMENTS", "text": "In this section, we evaluate the performance of our method using three counterfactual prediction tasks: a simulated medical clinical trial, a web search engine experiment, and a social choice question. Since our learning objectives include predictions of the yT treatment variable, our data must include a large pool of basic truths for this class, which is a necessary requirement for ensuring a valid assessment process. Unfortunately, the first dataset contains information about the clinical status of approximately 100,000 diabetes patients. Our task is to predict the length of hospitalizations for each patient, as they are typically hard, expensive, and time-consuming. To this end, we focus on three datasets. The first dataset contains information about the clinical status of approximately 100,000 diabetes patients. Our task is to predict the length of hospitalizations for each patient, as their treatments are so advanced. A second dataset includes a large collection of approximately 20,000 homes along with their attributes. Our task is to estimate the market price of a home based on its attributes."}, {"heading": "7.1 Hospitalization of diabetes patients", "text": "This dataset contains data from 10 years (1999-2008) of clinical care in 130 U.S. hospitals and integrated maternity networks. [16] We are trying to predict the length of hospitalization (in days) or (for the classification task) whether the duration of hospitalization would be longer than the median duration of hospitalization. [16] The \"new\" treatment we are trying to estimate is whether prescribing diabetes medications before hospitalization would have changed the duration of hospitalization. We focused on patients for whom the reason for admission was unknown, as these are the difficult cases of which 4,785 patients were included in the data. We simulated a clinical trial by randomly selecting 25% of the population in X, some of whom were prescribed diabetes medications and others were not. We used 25: 75 pull test splits.We evaluate performance against two tasks: predicting hospital duration and predicting whether the length was above the median. The results are presented in this table 1."}, {"heading": "7.2 House pricing Dataset", "text": "The house sales in King County Dataset5 contain records of 21,613 homes sold in King County, USA, a region that includes Seattle. Along with the market price of each house, the data includes 19 numerical and categorical attributes for each house, including the number and type of rooms, size, number of floors, and geographical location. Of special in-5https: / / www.kaggle.com / harlfoxem / housesalespredictionterest is an attribute that determines whether or not the house has been renovated. By dividing this as a treatment indicator variably and appropriately, we can simulate the following counterfactual question: Does renovation increase the value of a house, and by how much? Since the houses were not randomly assigned to each state, the data do not represent a true randomized controlled study. This, of course, raises questions about whether predictions can be used to answer the above question. Nevertheless, our method applies here, as we do not assume random mapping, but only a random character."}, {"heading": "7.3 Search Engine Dataset", "text": "We collected queries to the Bing search engine on June 1, 2016 that were randomly assigned to internal A / B tests with a frequency of at least 1,000. As an example (x), we included all queries that appeared in the control condition and focused exclusively on tests that included all of these queries. Our record contains 277 comparable treatment conditions and a control condition, each developed by the Microsoft Bing team, to classify each query into a series of 63 categories, including, commercialization, video games, weather-related, and adult topic queries. The classifier is used by Bing to determine whether specific results such as instant responses can be displayed."}, {"heading": "8. DISCUSSION", "text": "Randomized Controlled Trials (RCTs) are the gold standard for evaluating new treatments and interventions. RCTs are widely used by Internet sites, medical authorities, and increasingly by governments. However, RCTs are difficult and expensive to use. Nowadays, historical data is available in many areas where RCTs are taken into account. However, because these data were collected using an existing policy, using this data has proven difficult. In this paper, we proposed a new algorithm for using historical data in conjunction with the results of small RCTs to counterfactually infer the results of large RCTs. Our method can also be used as an early stop criterion for RCTs when the method predicts that the benefits of a new treatment will not be greater than those of the existing treatment. Thus, our method can provide benefits for existing RCTs. The proposed method is based on two assumptions: The first is that the outcome of each treatment can be predicted using a linear predictor."}, {"heading": "9. REFERENCES", "text": "[1] H. Bang and J. M. Robins. Doubly robust estimationin missing data and causal inference models. [Biometrics, 61 (4): 962-973, 2005. [2] S. Ben-David, J. Blitzer, K. Crammer, A. Kulesza, F. Pereira, and J. W. Vaughan. A theory of learning from different domains. Machine learning, 79 (1-2): 151-175, 2010. [3] S. Bickel, J. Bogojeska, T. Lengauer, and T. Scheffer. Multi-task for hiv therapy screening. In Proceedings of the 25th International Conference on Machine learning, pp. 56-63. ACM, 2008. [4] L. Bottou, J. Peters, J. Q. Candela, D. X. Charles, M. Chickering, E. Portugaly, D. Ray, P. Y. Simard, and E. Snelson. Counterfactual reasoning and learning systems: the example of compational advertising."}], "references": [{"title": "Doubly robust estimation in missing data and causal inference models", "author": ["H. Bang", "J.M. Robins"], "venue": "Biometrics, 61(4):962\u2013973", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2005}, {"title": "A theory of learning from different domains", "author": ["S. Ben-David", "J. Blitzer", "K. Crammer", "A. Kulesza", "F. Pereira", "J.W. Vaughan"], "venue": "Machine learning, 79(1-2):151\u2013175", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2010}, {"title": "Multi-task learning for hiv therapy screening", "author": ["S. Bickel", "J. Bogojeska", "T. Lengauer", "T. Scheffer"], "venue": "Proceedings of the 25th international conference on Machine learning, pages 56\u201363. ACM", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2008}, {"title": "Counterfactual reasoning and learning systems: the example of computational advertising", "author": ["L. Bottou", "J. Peters", "J.Q. Candela", "D.X. Charles", "M. Chickering", "E. Portugaly", "D. Ray", "P.Y. Simard", "E. Snelson"], "venue": "Journal of Machine Learning Research, 14(1):3207\u20133260", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2013}, {"title": "Bart: Bayesian additive regression trees", "author": ["H.A. Chipman", "E.I. George", "R.E. McCulloch"], "venue": "The Annals of Applied Statistics, pages 266\u2013298", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2010}, {"title": "Test", "author": ["L. Haynes", "O. Service", "B. Goldacre", "D. Torgerson"], "venue": "learn, adapt: Developing public policy with randomised controlled trials", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2012}, {"title": "Learning representations for counterfactual inference", "author": ["F.D. Johansson", "U. Shalit", "D. Sontag"], "venue": "Proceedings of the 33nd International Conference on Machine Learning, ICML, pages 3020\u20133029", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2016}, {"title": "Trustworthy online controlled experiments: Five puzzling outcomes explained", "author": ["R. Kohavi", "A. Deng", "B. Frasca", "R. Longbotham", "T. Walker", "Y. Xu"], "venue": "Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 786\u2013794. ACM", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Controlled experiments on the web: survey and practical guide", "author": ["R. Kohavi", "R. Longbotham", "D. Sommerfield", "R.M. Henne"], "venue": "Data mining and knowledge discovery, 18(1):140\u2013181", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2009}, {"title": "Counterfactual estimation and optimization of click metrics for search engines", "author": ["L. Li", "S. Chen", "J. Kleban", "A. Gupta"], "venue": "arXiv preprint arXiv:1403.1891", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}, {"title": "A contextual-bandit approach to personalized news article recommendation", "author": ["L. Li", "W. Chu", "J. Langford", "R.E. Schapire"], "venue": "Proceedings of the 19th international conference on World wide web, pages 661\u2013670. ACM", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2010}, {"title": "Toward predicting the outcome of an a/b experiment for search relevance", "author": ["L. Li", "J.Y. Kim", "I. Zitouni"], "venue": "Proceedings of the Eighth ACM International Conference on Web Search and Data Mining, pages 37\u201346. ACM", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2015}, {"title": "Causality", "author": ["J. Pearl"], "venue": "Cambridge university press", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2009}, {"title": "Estimating causal effects of treatments in randomized and nonrandomized studies", "author": ["D.B. Rubin"], "venue": "Journal of educational Psychology, 66(5):688", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1974}, {"title": "On causal and anticausal learning", "author": ["B. Sch\u00f6lkopf", "D. Janzing", "J. Peters", "E. Sgouritsa", "K. Zhang", "J.M. Mooij"], "venue": "Proceedings of the 29th International Conference on Machine Learning, ICML", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2012}, {"title": "and J", "author": ["B. Strack", "J.P. DeShazo", "C. Gennings", "J.L. Olmo", "S. Ventura", "K.J. Cios"], "venue": "N. Clore. Impact of  hba1c measurement on hospital readmission rates: analysis of 70,000 clinical database patient records. BioMed research international, 2014", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2014}, {"title": "Counterfactual risk minimization", "author": ["A. Swaminathan", "T. Joachims"], "venue": "Proceedings of the 24th International Conference on World Wide Web, pages 939\u2013941. ACM", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2015}, {"title": "The self-normalized estimator for counterfactual learning", "author": ["A. Swaminathan", "T. Joachims"], "venue": "Advances in Neural Information Processing Systems, pages 3231\u20133239", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2015}, {"title": "Sparsity and smoothness via the fused lasso", "author": ["R. Tibshirani", "M. Saunders", "S. Rosset", "J. Zhu", "K. Knight"], "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology), 67(1):91\u2013108", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2005}, {"title": "Causal effect models for realistic individualized treatment and intention to treat rules", "author": ["M.J. van der Laan", "M.L. Petersen"], "venue": "The International Journal of Biostatistics,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2007}, {"title": "Estimation and inference of heterogeneous treatment effects using random forests", "author": ["S. Wager", "S. Athey"], "venue": "arXiv preprint arXiv:1510.04342", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2015}, {"title": "Feature hashing for large scale multitask learning", "author": ["K.Q. Weinberger", "A. Dasgupta", "J. Langford", "J. Attenberg", "A.J. Smola"], "venue": "Proceedings of the 26th International Conference on Machine Learning (ICML-09), page 140", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2009}, {"title": "Machine learning for treatment assignment: Improving individualized risk attribution", "author": ["J. Weiss", "F. Kuusisto", "K. Boyd", "J. Liu", "D. Page"], "venue": "AMIA Annual Symposium Proceedings, volume 2015, page 1306. American Medical Informatics Association", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2015}, {"title": "Seeking insights about cycling mood disorders via anonymized search logs", "author": ["E. Yom-Tov", "R.W. White", "E. Horvitz"], "venue": "Journal of medical Internet research, 16(2):e65", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 5, "context": "The gold standard for testing such interventions are randomized controlled trials (RCTs) [6].", "startOffset": 89, "endOffset": 92}, {"referenceID": 5, "context": "1145/1235 used in medicine: Approximately 200,000 RCTs were conducted in the 1990\u2019s alone [6].", "startOffset": 90, "endOffset": 93}, {"referenceID": 8, "context": "Internet website operators were early adopters of RCTs [9].", "startOffset": 55, "endOffset": 58}, {"referenceID": 7, "context": "Most large Internet companies are known to run thousands of RCTs every year [8].", "startOffset": 76, "endOffset": 79}, {"referenceID": 12, "context": "The latter objective has been the focus of an abundant body of works, most based on the framework of causal inference [13].", "startOffset": 118, "endOffset": 122}, {"referenceID": 16, "context": "Our work follows the more recent line of work where a discriminative loss-centric approach is applied in counterfactual settings [17, 18, 7].", "startOffset": 129, "endOffset": 140}, {"referenceID": 17, "context": "Our work follows the more recent line of work where a discriminative loss-centric approach is applied in counterfactual settings [17, 18, 7].", "startOffset": 129, "endOffset": 140}, {"referenceID": 6, "context": "Our work follows the more recent line of work where a discriminative loss-centric approach is applied in counterfactual settings [17, 18, 7].", "startOffset": 129, "endOffset": 140}, {"referenceID": 12, "context": "Causal inference [13] is a standard framework for estimating the causal relation between variables, in a way which can then be used to answer counterfactual questions.", "startOffset": 17, "endOffset": 21}, {"referenceID": 3, "context": "In order to achieve this, methods for causal inference are usually based on simple, interpretable models from which actionable conclusions can be drawn [4].", "startOffset": 152, "endOffset": 155}, {"referenceID": 10, "context": "Alternatively, counterfactual questions can be answered if data can be collected under a random policy [11, 4, 10].", "startOffset": 103, "endOffset": 114}, {"referenceID": 3, "context": "Alternatively, counterfactual questions can be answered if data can be collected under a random policy [11, 4, 10].", "startOffset": 103, "endOffset": 114}, {"referenceID": 9, "context": "Alternatively, counterfactual questions can be answered if data can be collected under a random policy [11, 4, 10].", "startOffset": 103, "endOffset": 114}, {"referenceID": 11, "context": "Because of this, it has been proposed to treat data collected under different settings as randomized, and use it to answer counterfactual questions [12].", "startOffset": 148, "endOffset": 152}, {"referenceID": 16, "context": "In analogy to Empirical Risk Minimization, the principle of Countefactual Risk Minimization is proposed in [17, 18].", "startOffset": 107, "endOffset": 115}, {"referenceID": 17, "context": "In analogy to Empirical Risk Minimization, the principle of Countefactual Risk Minimization is proposed in [17, 18].", "startOffset": 107, "endOffset": 115}, {"referenceID": 0, "context": "Other works use doubly-robust methods which are based on propensity scores as well [1].", "startOffset": 83, "endOffset": 86}, {"referenceID": 4, "context": "Some parametric non-linear methods for estimating treatment effect are based on Bayesian regression trees [5] and random forests [21].", "startOffset": 106, "endOffset": 109}, {"referenceID": 20, "context": "Some parametric non-linear methods for estimating treatment effect are based on Bayesian regression trees [5] and random forests [21].", "startOffset": 129, "endOffset": 133}, {"referenceID": 1, "context": "A parallel discriminative approach to counterfactual prediction is based on the notion of domain adaptation [2].", "startOffset": 108, "endOffset": 111}, {"referenceID": 14, "context": "Following the work of [15], the authors of [7] observe that generalizing from the observed factual distribution to the unobserved counterfactual distribution is a special case of covariance shift, and in general of domain adaptation.", "startOffset": 22, "endOffset": 26}, {"referenceID": 6, "context": "Following the work of [15], the authors of [7] observe that generalizing from the observed factual distribution to the unobserved counterfactual distribution is a special case of covariance shift, and in general of domain adaptation.", "startOffset": 43, "endOffset": 46}, {"referenceID": 6, "context": "Therefore, the non-convex representation learning method in [7] incorporates a discrepancy-based regularization term which encourages a label-invariant representation.", "startOffset": 60, "endOffset": 63}, {"referenceID": 6, "context": "Moreover, while the method of [7] requires large amounts of data for both labels, our method is tailored for a setting where the treatment variable is rare.", "startOffset": 30, "endOffset": 33}, {"referenceID": 22, "context": "This is a fundamental problem in counterfactual settings, and makes estimating the individual treatment effect y\u2206 = yT \u2212yC especially challenging [23].", "startOffset": 146, "endOffset": 150}, {"referenceID": 13, "context": "A related task that is of high interest is to predict the individualized treatment effect y\u2206 = yT \u2212yC [14, 20].", "startOffset": 102, "endOffset": 110}, {"referenceID": 19, "context": "A related task that is of high interest is to predict the individualized treatment effect y\u2206 = yT \u2212yC [14, 20].", "startOffset": 102, "endOffset": 110}, {"referenceID": 0, "context": "where \u03b3 \u2208 [0, 1] controls the relative weight of each dataset in the training objective.", "startOffset": 10, "endOffset": 16}, {"referenceID": 2, "context": "[3].", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "This is in contrast to the more conventional approach where the distribution is modeled using tuples of the form (x, \u03bd, y\u03bd), where \u03bd \u2208 {C, T} is the experimental condition and y\u03bd is the outcome under that condition [7].", "startOffset": 215, "endOffset": 218}, {"referenceID": 18, "context": "This is similar to the regularization term of the Fused Lasso approach [19] used for time-series prediction.", "startOffset": 71, "endOffset": 75}, {"referenceID": 16, "context": "2, [17, 18] assume that samples include loss terms and propensity scores, while the linear method in [7] does not outperform standard ridge regression.", "startOffset": 3, "endOffset": 11}, {"referenceID": 17, "context": "2, [17, 18] assume that samples include loss terms and propensity scores, while the linear method in [7] does not outperform standard ridge regression.", "startOffset": 3, "endOffset": 11}, {"referenceID": 6, "context": "2, [17, 18] assume that samples include loss terms and propensity scores, while the linear method in [7] does not outperform standard ridge regression.", "startOffset": 101, "endOffset": 104}, {"referenceID": 15, "context": "This dataset contains data from 10 years (1999-2008) of clinical care at 130 US hospitals and integrated delivery networks [16].", "startOffset": 123, "endOffset": 127}, {"referenceID": 23, "context": "Categorization was determined using a proprietary classifier [24] developed by the Microsoft Bing team to assign each query into a set of 63 categories, including, for example, commerce, tourism, video games,", "startOffset": 61, "endOffset": 65}, {"referenceID": 21, "context": "In addition, a bag-of-words representation of the tokens was computed, and applied using the feature hashing trick [22].", "startOffset": 115, "endOffset": 119}], "year": 2016, "abstractText": "When a new treatment is considered for use, whether a pharmaceutical drug or a search engine ranking algorithm, a typical question that arises is, will its performance exceed that of the current treatment? The conventional way to answer this counterfactual question is to estimate the effect of the new treatment in comparison to that of the conventional treatment by running a controlled, randomized experiment. While this approach theoretically ensures an unbiased estimator, it suffers from several drawbacks, including the difficulty in finding representative experimental populations as well as the cost of running such trials. Moreover, such trials neglect the huge quantities of available control-condition data which are often completely ignored. In this paper we propose a discriminative framework for estimating the performance of a new treatment given a large dataset of the control condition and data from a small (and possibly unrepresentative) randomized trial comparing new and old treatments. Our objective, which requires minimal assumptions on the treatments, models the relation between the outcomes of the different conditions. This allows us to not only estimate mean effects but also to generate individual predictions for examples outside the randomized sample. We demonstrate the utility of our approach through experiments in three areas: Search engine operation, treatments to diabetes patients, and market value estimation for houses. Our results demonstrate that our approach can reduce the number and size of the currently performed randomized controlled experiments, thus saving significant time, money and effort on the part of practitioners.", "creator": "TeX"}}}