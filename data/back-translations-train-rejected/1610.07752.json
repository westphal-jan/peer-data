{"id": "1610.07752", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Oct-2016", "title": "Big Models for Big Data using Multi objective averaged one dependence estimators", "abstract": "Even though, many researchers tried to explore the various possibilities on multi objective feature selection, still it is yet to be explored with best of its capabilities in data mining applications rather than going for developing new ones. In this paper, multi-objective evolutionary algorithm ENORA is used to select the features in a multi-class classification problem. The fusion of AnDE (averaged n-dependence estimators) with n=1, a variant of naive Bayes with efficient feature selection by ENORA is performed in order to obtain a fast hybrid classifier which can effectively learn from big data. This method aims at solving the problem of finding optimal feature subset from full data which at present still remains to be a difficult problem. The efficacy of the obtained classifier is extensively evaluated with a range of most popular 21 real world dataset, ranging from small to big. The results obtained are encouraging in terms of time, Root mean square error, zero-one loss and classification accuracy.", "histories": [["v1", "Tue, 25 Oct 2016 07:11:11 GMT  (142kb)", "http://arxiv.org/abs/1610.07752v1", "21 pages, 2 Figures, 10 tables"]], "COMMENTS": "21 pages, 2 Figures, 10 tables", "reviews": [], "SUBJECTS": "cs.NE cs.LG", "authors": ["mrutyunjaya panda"], "accepted": false, "id": "1610.07752"}, "pdf": {"name": "1610.07752.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Mrutyunjaya Panda"], "emails": ["mrutyunjaya74@gmail.com"], "sections": [{"heading": null, "text": "Although many researchers have tried to explore the various possibilities of selecting multi-objective features, it has yet to be explored with the best of its abilities in data mining applications, rather than developing new ones. In this paper, the multi-objective evolutionary algorithm ENORA is used to select the features in a multi-class classification problem. EnORA's fusion of AnDE (Averaged n Dependency Estimates) with n = 1, a variant of naive Bayes with efficient function selection, is performed to obtain a fast hybrid classifier that can effectively learn from Big Data. This method aims to solve the problem of determining optimal function subsets from complete data, which is currently still a difficult problem. The effectiveness of the obtained classifier is comprehensively evaluated with a number of popular 21 real data sets ranging from small to large. The results obtained are encouraging in terms of time, root-quadrant error, classification loss and accuracy."}, {"heading": "Motivation", "text": "In fact, it is the case that most of them are able to go in search of a solution that has its origin in the past. In fact, it is the case that they are able to find a solution that has its origin in the past. In fact, it is the case that they are able to find a solution that has proved itself in the past. In the present, it is the case that they are able to find a solution for the future. In the present, it is the case that they are able to find a solution for the future. In the present, it is the case that they are able to find a solution for the future. In the present, it is the case that they are able to find a solution for the future."}, {"heading": "3.1. ENORA", "text": "ENORA [33] is an elitist pareto-based multi-objective evolutionary algorithm that uses a Mu plus lambda survival with uniform random initialization and binary tournament selection process to explore attribute space. Crowding distance is used as a measure to find ranking at the local non-dominance level, along with self-adaptive uniform crossover and self-adaptive single-bit flip mutation. Ad-hoc elite generation substitution technique is used to maintain diversity between individuals. In this paper, multi-objective evolutionary search is used as a feature sub-selection process using ENORA and the process appears to be maximization-minimization task. First, the maximization process is determined by the evaluator and then the cardinality minimization of the subset is performed as a second step. Finally, the non-dominated pareto-optimal solution is selected using ENORA as the best choice between the individual and the individual in view of the last fitness, with N being generated as the best distance between the individual and the population."}, {"heading": "3.2. NSGA-II: elitist non-dominated sorting genetic algorithm", "text": "The difference between NSGA-II and ENORA is how the calculation of the rank of individuals in the total population is performed. In ENORA, the rank of an individual in a population is the non-dominance level of the individual in his slot, while in NSGA-II, the rank of an individual in the non-dominance level of the individual in the total population. 4. On average, a dependency estimator (AODE) Naive bayes is one of the most popular machine learning techniques that is highly efficient and computationally intensive for small datasets. This is mainly due to its attribute independence assumption, which is based on an accurate classification."}, {"heading": "Computational complexity", "text": "In fact, the two are a very selective group that is able to assert itself, and it is also a very selective group of people that are able to assert themselves, \"he said in an interview with the\" New York Times. \"\" I don't think they will be able to outdo themselves, \"he said.\" I think they will be able to change the world, \"he told the\" New York Times. \"\" I don't think they will be able to change the world, \"he said.\" I don't think they will be able to change the world. \""}, {"heading": "6. Research Findings", "text": "In this section, the obtained experimental results will be evaluated to understand the effectiveness of the proposed ENORA-AODE classification model. Initially, the experimental study will be conducted with 21 sets of data obtained from the UCI Machine Learning Repository by merging ENORA and AODE classifiers, the results of which will be presented in Table 2. From Table 2, it can be observed that the model-building time of the AODE classifier for a large number of attributes increases significantly from 0 seconds to 6.24 seconds for completing the 10-fold cross-validation. For most sets, it takes almost no time to create the model. Their corresponding classification accuracy is good with a low root center square (RMSE), making the proposed approach a competitive among many available machine learning algorithms. The obtained results for biomedical data sets are almost timeless, their corresponding classification accuracy is well matched with the existing MASS results, and the MASS results are available in detail with the existing MASS and MASS."}, {"heading": "3 DLBCL 0.03 97.87 0.1504", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2 ALL-AML 0.71 97.37 0.1621", "text": "18 Airline 2.63 26.41 0.217519 Spam Base 0.08 93.37 0.238120 Supermarket 0.01 64.03 0.450221 Emotion 0.01 84.32 0.3546"}, {"heading": "CHCGA+S", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "CHCGA+R", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "MOGA-3", "text": "Table 3 shows that our approach performs best in ALL-AML, DLBC and medical data sets, relatively well in colorectal tumors, Pima diabetes data sets, but poorly in breast cancer data sets."}, {"heading": "Methodology Accuracy in %", "text": "NurserySSMA [44] 88.07Ours (ENORA-AODE) 70.97DLBCLMulti-objective binary PSO [46] 91.84Ours (ENORA-AODE) 97.87ALL-AMLMulti-objective binary PSO [46] 79.09Ours (ENORA-AODE) 97.37Table 4 confirms that our proposed approach wins the race for German credit, spam, HeartC, lymphography, DLBCL- and ALL-AML datasets and loses in Pima diabetes, nursery and breast cancer datasets."}, {"heading": "NB [39] 0.2601 0.4204 0.3413 0.1770 0.1652 0.3714 --", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "RS [42] --- --- ---- ---- ---- ---- 0.370", "text": "As can be seen from Table 6, our approach predominates Naive Bayes, AODE, A2DE, PA2DE in lymphography (lymphography), waveform, pen-digit and Heart-C datasets and RS in emotion datasets, but fails in German credit and baby datasets. Again, majority gains support our approach. Lymph 85.81 86.25 81.52 80.76 84.16 81.87Waveform5000 84.1 84.87 83.64 86.31 83.85 84.4In order to verify whether our ENORA-AODE approach performs better compared to recent developments in variants of AODE classifiers, Table 7 and Table 8 offer a comparison in terms of accuracy and 0-1 loss in terms of accuracy and 0-1 loss. From Table 8, we can once again confirm that our proposed approach in accuracy comparison to AWAODE-CFS, WODE and WD-10 intersects all the results from AADE-10 with losses similar to Table 1."}, {"heading": "NB --- 1/4/4 1/5/3 1/4/4 1/5/3 2/4/3 1/1/7", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "7. Conclusions", "text": "This paper presents the fusion of the AODE classifier with the multi-objective evolutionary algorithm ENORA to address the large number of attributes in the dataset that are sometimes not advisable for better machine learning applications. AODE is mathematically efficient due to its nature of behaving linearly for the training data, taking less time to build the model, although the number of attributes is large. ENORA is a promising algorithm for its ability to reduce the entire set of attributes to the best possible level. Results obtained by merging ENORA-AODE have exceeded all available AODE variants in terms of better predictive accuracy, low 0-1 losses and low RMSE."}, {"heading": "2010. ISBN: 978-0-471-87339-6", "text": "[29] J.C. Fernandez, C. Hervas, F.J. Martinez-Eestimllo, P.A. Gutierrez, Memetic Pareto Evolutionary Artificial Neural Networks to determine growth / no-growth in predictive microbiology, Applied soft computing, 11 (1), 534-550, 2011, Elsevier. [31] K. Deb and N. Srinivas, Multiobjective optimization using nondominated sorting in genetic algorithms, Journal Evol. Comput., 2, 221-248, 1994. [31] L. Thiele and E. Zitzler, \"Multijective evolutionary algorithms: The strength Pareto approach,\" IEEE Trans. Evol. Comput., 3, 257-271, November 1999. [32] E. Zitzler, L. Thiele and M. Laumanns, SPEA2: Improving the strength Pareto evolutionary algorithm, in: Proc. EUROGEN Int. Conf. Ef. Evol. M. Evolmanns, Evolto Laumanns Pargorithm, Eevolutionary strength."}, {"heading": "58, 5-24, 2005.", "text": "[36] A. Frank and A. Asunction, UCI Machine Learning repository, 2010. URL http: / / archieve.ics.uci.edu / ml [37] J. Liu and H. Iba, Selective informative genes using a multi-objective evolutionary algorithm, in: Proceedings of the IEEE congress on Evolutionary computation, CEC 2002, 1, 297-302. [38] J. Hernandez, B. Duval and J.-K. Hao, A genetic embedded approach for gene selection and classification of microarray data, in: E. Marchiori et al. (eds.), EvoBIO in: LNCS, 90-101, 2007. [39] G.I. Webb, J. Boughton, F. Zheng, K. M. Ting and H. Salem, Decreasonably naive Bayes: aggregating n-dependence estomators, EvoBI.4, KNOWSYS, Lab technical 2010-01, Monash University, 2010."}], "references": [{"title": "Feature Subset Selection Based on Bio-Inspired Algorithm", "author": ["C. Yun", "B. O", "J. Yang", "J. Nang"], "venue": "Journal of Information Science and Engineering,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2011}, {"title": "A survey of multi-objective evolutionary algorithms for data mining: Part-II", "author": ["A. Mukhopadhyay", "U. Maulik", "S. Bandyopadhyay", "C.A. Coello Coello"], "venue": "IEEE Transactions on Evolutionary Computation, 18(1), 20-35", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2014}, {"title": "Multiobjective Genetic Algorithms for Clustering", "author": ["U. Maulik", "S. Bandyopadhyay", "A. Mukhopadhyay"], "venue": "Applications in Data Mining and Bioinformatics. Springer", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2011}, {"title": "A survey on multi-objective evolutionary algorithms for many-objective problems", "author": ["Carlos Brizuela"], "venue": "Comput Optim Appl,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "A Multiobjective Genetic Algorithm Based on a Discrete Selection Procedure", "author": ["Qiang Long", "Changzhi Wu", "XiangyuWang", "Lin Jiang", "Jueyou Li"], "venue": "Mathematical Problems in Engineering,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "Multi-objective genetic fuzzy classifiers for imbalanced and cost-sensitive datasets, WIREs Data Mining", "author": ["Satchidananda Dehuri", "Ashish Ghosh"], "venue": "Knowl Discov", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2013}, {"title": "Multi-objective genetic fuzzy classifiers for imbalanced and cost-sensitive datasets", "author": [], "venue": "Soft Comput,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "Filter-based optimization techniques for selection of feature subsets in ensemble systems, Expert Systems with Applications", "author": ["Anne M. de Paula Canuto"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "Feature Subset Selection using Non-dominated Sorting", "author": ["A. Khan", "A.R. Baig", "Multi-Objective"], "venue": "Genetic Algorithm, JournalUofUAppliedUResearchUandUTechnology,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2015}, {"title": "A Multi Objective Evolutionary Algorithm for Solving a Real Health Care Fleet Optimization Problem, In: proc", "author": ["Carlos Cataniaa", "Cecilia Zanni-Merka", "Pierre Colleta"], "venue": "Of 19th International Conference on Knowledge Based and Intelligent Information and Engineering Systems, Procedia Computer Science 60,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2015}, {"title": "A survey on feature ranking by means of evolutionary computation, Annals of the University of Craiova", "author": ["Ruxandra Stoean", "Florin Gorunescu"], "venue": "Mathematics and Computer Science Series,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "A Survey of Multi-Objective Evolutionary Algorithms for Data Mining: Part-I", "author": ["Anirban Mukhopadhyay", "Ujjwal Maulik", "Sanghamitra Bandyopadhyay", "Carlos A. Coello Coello"], "venue": "IEEE Transaction on Evolutionary Computation,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "A Filter-based Evolutionary Approach for Selecting Features in High-Dimensional Micro-array Data, Intelligent Information Processing V, IFIP Advances in Information and Communication", "author": ["Laura Maria Cannas", "Nicoletta Dess\u00ec", "Barbara Pes"], "venue": "Technology series,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2010}, {"title": "A survey on feature selection methods", "author": ["Girish Chandrashekar", "Ferat Sahin"], "venue": "Computers and Electrical Engineering", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2014}, {"title": "Evolutionary Multiobjective Ensemble Learning Based on Bayesian Feature Selection", "author": ["Huanhuan Chen", "Xin Yao"], "venue": "Proc. of IEEE Congress on Evolutionary Computation ,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2006}, {"title": "A Multi- Objective Genetic Algorithm Approach to Feature Selection in Neural and Fuzzy Modeling, Evolutionary Optimization, An International", "author": ["Christos Emmanouilidis", "Andrew Hunter", "John Macintyre", "Chris Cox"], "venue": "Journal on the Internet,3", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2001}, {"title": "Puertaa, A Scalable Pairwise Class Interaction Framework for Multidimensional Classification, International", "author": ["Jacinto Ariasa", "Jose A. Gameza", "Thomas D. Nielsenb", "Jose M"], "venue": "Journal of Approximate Reasoning,68(C),", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2016}, {"title": "Sensitivity and specificity based multiobjective approach for feature selection: Application to cancer diagnosis", "author": ["J. Garc\u00eda-Nieto", "E. Albaa", "L. Jourdanb", "E. Talbi"], "venue": "Information Processing Letters 109, 887\u2013896", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2009}, {"title": "Multi-Class Protein Fold Recognition Using Multi-Objective Evolutionary Algorithms", "author": ["Stanley Y.M. Shi", "P.N. Suganthan", "Kalyanmoy Deb"], "venue": "in: Proc. Of CIBCB,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2004}, {"title": "Condado, Multi- Objective Evolutionary Algorithm for Land-Use Management Problem", "author": ["Dilip Datta", "Kalyanmoy Deb", "Carlos M. Fonseca", "Fernando Lobo", "Paulo"], "venue": "International Journal of Computational Intelligence Research; 3(4),", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2007}, {"title": "Multi-objective optimization of support vector Machines", "author": ["Thorsten Suttorp", "Christian Igel"], "venue": "Multi-objective Machine Learning Studies in Computational Intelligence,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2006}, {"title": "Q", "author": ["K.C. Tan", "E.J. Teoh"], "venue": "Yua, K.C. Goh , A hybrid evolutionary algorithm for attribute selection in data mining, Expert Systems with Applications 36, 8616\u20138630", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2009}, {"title": "Comparison of Multiobjective Evolutionary Algorithms: Empirical Results", "author": ["Eckart Zitzler", "Kalyanmoy Deb", "Lothar Thiele"], "venue": "Evolutionary Computation", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2000}, {"title": "A Tutorial on Evolutionary Multiobjective Optimization, Metaheuristics for Multiobjective Optimisation", "author": ["Eckart Zitzler", "Marco Laumanns", "Stefan Bleuler"], "venue": "Lecture Notes in Economics and Mathematical Systems,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2004}, {"title": "Multi-Objective Optimization using Evolutionary Algorithms.Wiley", "author": ["K. Deb"], "venue": null, "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2010}, {"title": "Memetic Pareto Evolutionary Artificial Neural Networks to determine growth/no-growth in predictive microbiology", "author": ["J.C. Fernandez", "C. Hervas", "F.J. Martinez-Estudillo", "P.A. Gutierrez"], "venue": "Applied soft computing, 11(1), 534-550", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2011}, {"title": "Multiobjective optimization using nondominated sorting in genetic algorithms", "author": ["K. Deb", "N. Srinivas"], "venue": "Journal Evol. Comput., 2, 221\u2013248", "citeRegEx": "30", "shortCiteRegEx": null, "year": 1994}, {"title": "Multiobjective evolutionary algorithms: The strength Pareto approach,", "author": ["L. Thiele", "E. Zitzler"], "venue": "IEEE Trans. Evol. Comput.,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 1999}, {"title": "SPEA2: Improving the strength Pareto evolutionary algorithm", "author": ["E. Zitzler", "L. Thiele", "M. Laumanns"], "venue": "in: Proc. EUROGEN Int. Conf. on Evol. methods for Design, Opti. And control with appls. To industrial problems, 95\u2013100", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2001}, {"title": "Multi-objective evolutionary algorithms for fuzzy classification in survival prediction", "author": ["F. Jimenez", "G. Sanchez", "JM. Juarez"], "venue": "Artificial intelligence in medicine,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2014}, {"title": "A Fast and Elitist Multiobjective Genetic Algorithm: NSGA\u2013II", "author": ["K. Deb", "A. Pratap", "S. Agarwal", "T. Meyarivan"], "venue": "IEEE Transactions on Evolutionary Computation, Volume:6 (2) , 182-197", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2002}, {"title": "Not so Naive Bayes: aggregating one-dependence estimators", "author": ["G.I. Webb"], "venue": "Machine learning, 58, 5-24", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2005}, {"title": "Selective informative genes using a multiobjective evolutionary algorithm, in:proceedings of the IEEE congress on Evolutionary computation", "author": ["J. Liu", "H. Iba"], "venue": "CEC 2002,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2002}, {"title": "A genetic embedded approach for gene selection and classification of microarray data", "author": ["J. Hernandez", "B. Duval", "J.-K. Hao"], "venue": "in: E. Marchiori et al. (eds.), EvoBIO in: LNCS, 90-101", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2007}, {"title": "Decreasingly naive Bayes: aggregating n-dependence estomators", "author": ["G.I. Webb", "J.R. Boughton", "F. Zheng", "K.M. Ting", "H. Salem"], "venue": "KNOWSYS Lab technical report 2010-01, Monash university", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2010}, {"title": "Deep broad Learning-Big models for Big data, Journal of Machine Learning research", "author": ["N.A.zaidi", "G.I.Webb", "M.J.carman", "F. Petitjean"], "venue": null, "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2015}, {"title": "A microarray gene expression data classification using hybrid back propagation neural network", "author": ["M. Vimaladev", "B. Kalavathi"], "venue": "genetika, 4693, 1013-1026", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2014}, {"title": "A ranking based KNN approach for multi label classification, Asian conference on machine learning, journal of machine learning", "author": ["T. -H. Chirag", "H. -Y. Lo", "s. -de Lin"], "venue": "researchworkshop and conference proceedings,", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2012}, {"title": "Journal of advances in computer research", "author": ["M.R. Gholamian", "S.M. Sadatrasoul", "Z. Hajimohamadi"], "venue": "3(3), 53-64", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2012}, {"title": "A memetic algorithm for evolutionary prototype selection: a scaling up approach", "author": ["S. Garcia", "J.R. Cano", "F. Herrera"], "venue": "Pattern Recognition,", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2008}, {"title": "A multiobjective genetic ptimization of interpretability oriented fuzzy rule based classifiers", "author": ["F. Rudzinsky"], "venue": "Applied Soft Computing,", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2016}, {"title": "A graph theoritic approach for identifying nonredundant and relevant gene markers from microarray data using multiobjective binary PSO", "author": ["M. Mandal", "A. Mukhopadhyay"], "venue": "PLOS One, 9(3)", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning average one dependence estimator by attribute weighting", "author": ["J. Wu", "Z. Cai"], "venue": "journal of Information and computational science, 8(7), 1063-1073.", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2011}], "referenceMentions": [{"referenceID": 0, "context": "It is also noticed that, there are a plenty of approaches present in the literature for obtaining quality feature subsets, still it is considered to be a difficult task to obtain the best ones [1].", "startOffset": 193, "endOffset": 196}, {"referenceID": 1, "context": "The parallel architecture of the Evolutionary algorithms (EA) are a potential candidate to process such big data automatically for optimal parameter setting and more importantly obtaining a viable solution for better interpretation of the model with best classification accuracy possible [3,4].", "startOffset": 288, "endOffset": 293}, {"referenceID": 2, "context": "The parallel architecture of the Evolutionary algorithms (EA) are a potential candidate to process such big data automatically for optimal parameter setting and more importantly obtaining a viable solution for better interpretation of the model with best classification accuracy possible [3,4].", "startOffset": 288, "endOffset": 293}, {"referenceID": 3, "context": "The Pareto-optimal set solutions are considered not to be dominated by any other possible solution [5,6].", "startOffset": 99, "endOffset": 104}, {"referenceID": 4, "context": "The Pareto-optimal set solutions are considered not to be dominated by any other possible solution [5,6].", "startOffset": 99, "endOffset": 104}, {"referenceID": 5, "context": "Dehuri and Ghosh [7] proposes to use a multi-objective genetic based feature selection method for knowledge discovery process and discusses its pros and cons for its validity and potentiality.", "startOffset": 17, "endOffset": 20}, {"referenceID": 6, "context": "Ducange, Lazzerini and Marcelloni [8] used NSGA-II, a well known multiobjective optimization algorithm as a feature subset selection in highly imbalanced dataset.", "startOffset": 34, "endOffset": 37}, {"referenceID": 7, "context": "[9] proposed to use ensemble filter based classification with feature subset selection done by Particle swarm (PSO), genetic algorithm (GA) and ant-colony optimization (ACO) techniques.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "Khan and Baig [10] opined that large number of irrelevant attributes are to be removed from the datasets in order to enhance the accuracy of the classifier.", "startOffset": 14, "endOffset": 18}, {"referenceID": 9, "context": "Cataniaa, Zanni-merka, Beuvrona and Colleta [11] discussed the various aspects of multi-objective optimization NSGA-II implementation in Patient Transport services with preliminary results.", "startOffset": 44, "endOffset": 48}, {"referenceID": 10, "context": "The authors Stoean and Gorunescu [12] presented a study to", "startOffset": 33, "endOffset": 37}, {"referenceID": 11, "context": "Mukhopadhyay, Maulik, Bandyopadhyay, and Coello Coello [14] presented a comprehensive survey on recent advances in multi-objective evolutionary optimization techniques as a feature selection and classification for automatic processing of large qualities of data that can solve many real world problems with various various conflicting measures of performance.", "startOffset": 55, "endOffset": 59}, {"referenceID": 12, "context": "Cannas, Dessi and Pes [15] proposed four popular filter based procedure along with support vector machine in order to reduce the search space in high dimensional micro array data sets, for obtaining potential solutions to predict and diagnose the disease.", "startOffset": 22, "endOffset": 26}, {"referenceID": 13, "context": "A generic review on various filter, wrapper based feature selection and their possible combination are presented by Chandrasekharan and Sahin [16].", "startOffset": 142, "endOffset": 146}, {"referenceID": 14, "context": "Chen and Yao [17] demonstrated the effectiveness of the proposed ensemble of evolutionary multi-objective algorithms and Bayesian automatic relevance determination to obtain better accuracy with reduced feature sets.", "startOffset": 13, "endOffset": 17}, {"referenceID": 15, "context": "[18] where they pointed out the tradeoffs between computational complexity with classification accuracy.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "Ariasa, Gameza, Nielsenb and Puertaa [20] proposed a scalable pair wise class interaction framework for multi-dimension classification by taking several base classifiers and inference methods afterwards.", "startOffset": 37, "endOffset": 41}, {"referenceID": 17, "context": "A novel multi-objective genetic algorithm based feature selection combined with support vector machine is used [21] for selection of genes in micro array dataset for cancer diagnosis.", "startOffset": 111, "endOffset": 115}, {"referenceID": 18, "context": "Shi, Suganthan and Deb [22] proposed to use support vector machine as a classifier for structural classification of protein (SCOP) after the relevant feature are selected by using Multi-Objective Feature Analysis and Selection Algorithm (MOFASA).", "startOffset": 23, "endOffset": 27}, {"referenceID": 19, "context": "Datta, Deb, Fonseca, Lobo and Condado [23] proposed a spatial GIS based multi-objective evolutionary algorithm (NSGAII-LUM) for better understanding of the impact from land uses in Mediterranean landscape from Southern Portugal.", "startOffset": 38, "endOffset": 42}, {"referenceID": 20, "context": "They discuss about how to model the proposed framework by considering the tradeoffs between accuracy and model complexity with reduced number of support vector [24].", "startOffset": 160, "endOffset": 164}, {"referenceID": 21, "context": "Goh [25] proposed genetic- support vector (GA-SVM) hybrid evolutionary algorithm for attribute selection in data mining.", "startOffset": 4, "endOffset": 8}, {"referenceID": 22, "context": "The authors provided an empirical comparison of various MOO algorithms, considering six test functions, which are aimed at giving an impression to understand which technique performs well under what condition in Zitler, Deb and Thiele [26].", "startOffset": 235, "endOffset": 239}, {"referenceID": 23, "context": "A good tutorial on theory and model are provided by Zitzler, Laumanns, and Bleuler [27], where various algorithmic aspects of MOO such as: assignment of fitness function, elitism and diversity etc.", "startOffset": 83, "endOffset": 87}, {"referenceID": 23, "context": "[27] that due to the complex nature of generating Pareto optimal solution sets, many stochastic search namely: evolutionary algorithms, simulated annealing etc.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "Further, it can be noticed that MOO can be a maximization or minimization problem with a number of objective functions [28].", "startOffset": 119, "endOffset": 123}, {"referenceID": 24, "context": "Now-a-days, multi-objective evolutionary algorithms have attracted many a researchers in the multi faced applications to provide some viable solutions to multi-objective problems [28-29]; that include to name a few: Non-dominated sorting Genetic algorithm (NSGA) by Deb and Srinivas [30]; Strength Pareto Evolutionary Algorithm (SPEA 1 and 2) [31-32].", "startOffset": 179, "endOffset": 186}, {"referenceID": 25, "context": "Now-a-days, multi-objective evolutionary algorithms have attracted many a researchers in the multi faced applications to provide some viable solutions to multi-objective problems [28-29]; that include to name a few: Non-dominated sorting Genetic algorithm (NSGA) by Deb and Srinivas [30]; Strength Pareto Evolutionary Algorithm (SPEA 1 and 2) [31-32].", "startOffset": 179, "endOffset": 186}, {"referenceID": 26, "context": "Now-a-days, multi-objective evolutionary algorithms have attracted many a researchers in the multi faced applications to provide some viable solutions to multi-objective problems [28-29]; that include to name a few: Non-dominated sorting Genetic algorithm (NSGA) by Deb and Srinivas [30]; Strength Pareto Evolutionary Algorithm (SPEA 1 and 2) [31-32].", "startOffset": 283, "endOffset": 287}, {"referenceID": 27, "context": "Now-a-days, multi-objective evolutionary algorithms have attracted many a researchers in the multi faced applications to provide some viable solutions to multi-objective problems [28-29]; that include to name a few: Non-dominated sorting Genetic algorithm (NSGA) by Deb and Srinivas [30]; Strength Pareto Evolutionary Algorithm (SPEA 1 and 2) [31-32].", "startOffset": 343, "endOffset": 350}, {"referenceID": 28, "context": "Now-a-days, multi-objective evolutionary algorithms have attracted many a researchers in the multi faced applications to provide some viable solutions to multi-objective problems [28-29]; that include to name a few: Non-dominated sorting Genetic algorithm (NSGA) by Deb and Srinivas [30]; Strength Pareto Evolutionary Algorithm (SPEA 1 and 2) [31-32].", "startOffset": 343, "endOffset": 350}, {"referenceID": 29, "context": "ENORA [33] is an elitist Pareto- based multi-objective evolutionary algorithm that uses a Mu plus Lambda survival with uniform random initialization and binary tournament selection process for exploring the attribute space.", "startOffset": 6, "endOffset": 10}, {"referenceID": 30, "context": "NSGA-II [34] is also a popular multi-objective genetic algorithm based constrained optimization technique which is aimed at improving the Pareto optimal solutions using evolutionary operators such as: selection, genetic mutation and crossover.", "startOffset": 8, "endOffset": 12}, {"referenceID": 31, "context": "One variant of such a popular Naive Bayes technique is Averaged one-dependence estimator (AODE) Naive Bayes [35].", "startOffset": 108, "endOffset": 112}, {"referenceID": 13, "context": "Algorithm/ Dataset Colon Tumor ALL-AML DLBCL Medical Breast Cancer PimaDiabetes CHCGA+S VM[16 ] --- ------73.", "startOffset": 90, "endOffset": 95}, {"referenceID": 13, "context": "CHCGA+R BF [16 ] --- ------70 96.", "startOffset": 11, "endOffset": 16}, {"referenceID": 17, "context": "K-means [21] 78.", "startOffset": 8, "endOffset": 12}, {"referenceID": 17, "context": "MOGA-3 Obj [21] 89.", "startOffset": 11, "endOffset": 15}, {"referenceID": 32, "context": "Liu and Eba [37] 80 -90 ---------", "startOffset": 12, "endOffset": 16}, {"referenceID": 33, "context": "Hermandev [38] 84.", "startOffset": 10, "endOffset": 14}, {"referenceID": 36, "context": "Hybrid GABPN [41 ] --- 89.", "startOffset": 13, "endOffset": 18}, {"referenceID": 38, "context": "ANFIS [43] 70 MOPSO [43] 70 NSGA-II+SFP [45] 72.", "startOffset": 6, "endOffset": 10}, {"referenceID": 38, "context": "ANFIS [43] 70 MOPSO [43] 70 NSGA-II+SFP [45] 72.", "startOffset": 20, "endOffset": 24}, {"referenceID": 40, "context": "ANFIS [43] 70 MOPSO [43] 70 NSGA-II+SFP [45] 72.", "startOffset": 40, "endOffset": 44}, {"referenceID": 39, "context": "SSMA [44] 91.", "startOffset": 5, "endOffset": 9}, {"referenceID": 40, "context": "23 NSGA-II+SFP [45] 86.", "startOffset": 15, "endOffset": 19}, {"referenceID": 39, "context": "SSMA [44] 63.", "startOffset": 5, "endOffset": 9}, {"referenceID": 39, "context": "SSMA [44] 55.", "startOffset": 5, "endOffset": 9}, {"referenceID": 39, "context": "SSMA [44] 82.", "startOffset": 5, "endOffset": 9}, {"referenceID": 40, "context": "15 NSGA-II+SFP [45] 76.", "startOffset": 15, "endOffset": 19}, {"referenceID": 39, "context": "SSMA [44] 97.", "startOffset": 5, "endOffset": 9}, {"referenceID": 39, "context": "SSMA [44] 88.", "startOffset": 5, "endOffset": 9}, {"referenceID": 41, "context": "Multi-objective binary PSO [46] 91.", "startOffset": 27, "endOffset": 31}, {"referenceID": 41, "context": "Multi-objective binary PSO [46] 79.", "startOffset": 27, "endOffset": 31}, {"referenceID": 35, "context": "A1DE[40] 0.", "startOffset": 4, "endOffset": 8}, {"referenceID": 35, "context": "A2DE [40] 0.", "startOffset": 5, "endOffset": 9}, {"referenceID": 35, "context": "DBL1 [40] 0.", "startOffset": 5, "endOffset": 9}, {"referenceID": 35, "context": "A1JE [40] 0.", "startOffset": 5, "endOffset": 9}, {"referenceID": 34, "context": "NB [39] 0.", "startOffset": 3, "endOffset": 7}, {"referenceID": 34, "context": "3714 -AODE [39] 0.", "startOffset": 11, "endOffset": 15}, {"referenceID": 34, "context": "A2DE [39] 0.", "startOffset": 5, "endOffset": 9}, {"referenceID": 34, "context": "PA2DE [39] 0.", "startOffset": 6, "endOffset": 10}, {"referenceID": 37, "context": "RS [42] -------- ---- ---- ---- 0.", "startOffset": 3, "endOffset": 7}, {"referenceID": 42, "context": "Dataset Ours (ENORAAODE) AODE [47] AWAODECFS [47] AWAODE-GW [47] WAODE [47] DTWAODE [47] Breast cancer 72.", "startOffset": 30, "endOffset": 34}, {"referenceID": 42, "context": "Dataset Ours (ENORAAODE) AODE [47] AWAODECFS [47] AWAODE-GW [47] WAODE [47] DTWAODE [47] Breast cancer 72.", "startOffset": 45, "endOffset": 49}, {"referenceID": 42, "context": "Dataset Ours (ENORAAODE) AODE [47] AWAODECFS [47] AWAODE-GW [47] WAODE [47] DTWAODE [47] Breast cancer 72.", "startOffset": 60, "endOffset": 64}, {"referenceID": 42, "context": "Dataset Ours (ENORAAODE) AODE [47] AWAODECFS [47] AWAODE-GW [47] WAODE [47] DTWAODE [47] Breast cancer 72.", "startOffset": 71, "endOffset": 75}, {"referenceID": 42, "context": "Dataset Ours (ENORAAODE) AODE [47] AWAODECFS [47] AWAODE-GW [47] WAODE [47] DTWAODE [47] Breast cancer 72.", "startOffset": 84, "endOffset": 88}, {"referenceID": 34, "context": "Dataset NB [39] AODE [39] A2DE [39] PA2DE [39] FA2DE [39] TAN [39] Ours (ENORA -AODE) Lymph 0.", "startOffset": 11, "endOffset": 15}, {"referenceID": 34, "context": "Dataset NB [39] AODE [39] A2DE [39] PA2DE [39] FA2DE [39] TAN [39] Ours (ENORA -AODE) Lymph 0.", "startOffset": 21, "endOffset": 25}, {"referenceID": 34, "context": "Dataset NB [39] AODE [39] A2DE [39] PA2DE [39] FA2DE [39] TAN [39] Ours (ENORA -AODE) Lymph 0.", "startOffset": 31, "endOffset": 35}, {"referenceID": 34, "context": "Dataset NB [39] AODE [39] A2DE [39] PA2DE [39] FA2DE [39] TAN [39] Ours (ENORA -AODE) Lymph 0.", "startOffset": 42, "endOffset": 46}, {"referenceID": 34, "context": "Dataset NB [39] AODE [39] A2DE [39] PA2DE [39] FA2DE [39] TAN [39] Ours (ENORA -AODE) Lymph 0.", "startOffset": 53, "endOffset": 57}, {"referenceID": 34, "context": "Dataset NB [39] AODE [39] A2DE [39] PA2DE [39] FA2DE [39] TAN [39] Ours (ENORA -AODE) Lymph 0.", "startOffset": 62, "endOffset": 66}], "year": 2016, "abstractText": "Even though, many researchers tried to explore the various possibilities on multi objective feature selection, still it is yet to be explored with best of its capabilities in data mining applications rather than going for developing new ones. In this paper, multi-objective evolutionary algorithm ENORA is used to select the features in a multi-class classification problem. The fusion of AnDE (averaged n-dependence estimators) with n=1, a variant of naive Bayes with efficient feature selection by ENORA is performed in order to obtain a fast hybrid classifier which can effectively learn from big data. This method aims at solving the problem of finding optimal feature subset from full data which at present still remains to be a difficult problem. The efficacy of the obtained classifier is extensively evaluated with a range of most popular 21 real world dataset, ranging from small to big. The results obtained are encouraging in terms of time, Root mean square error, zero-one loss and classification accuracy. Key-words: MOEA, ENORA, AODE, Classification, 0/1 loss, RMSE", "creator": "Bullzip PDF Printer (10.10.0.2307)"}}}