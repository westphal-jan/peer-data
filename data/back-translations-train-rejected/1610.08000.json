{"id": "1610.08000", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Oct-2016", "title": "Statistical Machine Translation for Indian Languages: Mission Hindi 2", "abstract": "This paper presents Centre for Development of Advanced Computing Mumbai's (CDACM) submission to NLP Tools Contest on Statistical Machine Translation in Indian Languages (ILSMT) 2015 (collocated with ICON 2015). The aim of the contest was to collectively explore the effectiveness of Statistical Machine Translation (SMT) while translating within Indian languages and between English and Indian languages. In this paper, we report our work on all five language pairs, namely Bengali-Hindi (\\bnhi), Marathi-Hindi (\\mrhi), Tamil-Hindi (\\tahi), Telugu-Hindi (\\tehi), and English-Hindi (\\enhi) for Health, Tourism, and General domains. We have used suffix separation, compound splitting and preordering prior to SMT training and testing.", "histories": [["v1", "Tue, 25 Oct 2016 18:20:08 GMT  (19kb,D)", "http://arxiv.org/abs/1610.08000v1", "4 pages, Published in the Proceedings of NLP Tools Contest: Statistical Machine Translation in Indian Languages"]], "COMMENTS": "4 pages, Published in the Proceedings of NLP Tools Contest: Statistical Machine Translation in Indian Languages", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["raj nath patel", "prakash b pimpale"], "accepted": false, "id": "1610.08000"}, "pdf": {"name": "1610.08000.pdf", "metadata": {"source": "CRF", "title": "Statistical Machine Translation for Indian Languages: Mission Hindi 2", "authors": ["Raj Nath Patel", "Prakash B. Pimpale"], "emails": ["rajnathp@cdac.in", "prakash@cdac.in"], "sections": [{"heading": "1 Introduction", "text": "In this essay we present our SMT experiments from Bengali, Marathi, Tamil, Telugu and English to Hindi. Of the languages involved, Bengali, Hindi and Marathi belong to the Indo-Aryan family and Tamil and Telugu belong to the Dravidian language family. All languages except English have the same flexibility in word order, canonically according to the Subject-ObjectVerb (SOV) structure. In terms of morphology, Bengali, Marathi, Tamil and Telugu are more agglutinative in comparison to Hindi. It is known that SMT produces unknown words that lead to poor translation quality when the morphological divergence between source and target languages is high. Koehn and Knight (2003), Popovic and Ney (2004), and Popovic and al et al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al"}, {"heading": "2 Data-set and Experimental Setup", "text": "In the following sections we describe training and testing corpus followed by preprocessing and setup of SMT systems for experiments."}, {"heading": "2.1 Corpus for SMT Training and Testing", "text": "For the experiments, we used the corpus shared by ILSMT, which is described in Table 1. Tests for the experiments were performed with Test1, the development set. The submitted systems were evaluated by the organizers against Test2 corpus. For unrestricted systems, additional data (Bojar et al., 2014; Khapra et al., 2010) was used for speech modeling. Xiv: 161 0.08000v 1 [cs.C L] 25 Oct 201 6"}, {"heading": "2.2 SMT System Set Up", "text": "The baseline system was constructed using the phrase-based model (Och and Ney, 2003; Brown et al., 1990; Marcu and Wong, 2002; Koehn et al., 2003; Koehn et al., 2007) and Koehn and Hoang (2007) were used as factor models.The language model was practiced using the KenLM (Heafield, 2011) toolkits with modified Kneser-Ney smoothing (Chen and Goodman, 1996).The factored SMT training source and target-sided shaft were used as alignment factor. Peeling was done with a light shaft for Hindi (Ramanathan and Rao, 2003).For English we used carrier trunk (Minnen et al., 2001)."}, {"heading": "2.3 Evaluation Metrics", "text": "The different experimental systems were compared using BLEU (Papineni et al., 2002), NIST (Doddington, 2002), Translation error rate (TER) (Snover et al., 2006). Better, higher BLEU- and NIST-values with lower TER are desirable for an MT-system."}, {"heading": "2.4 Pre-Processing (PP)", "text": "To address the morphological divergence between source and target languages for the purpose of a better SMT system, we pre-processed the source (Bengali, Marathi, Tamil and Telugu) for suffix separation and compound word division (Pimpale et al., 2014; Patel et al., 2014) before training and testing. To address structural divergence (enhi), we used source-side reordering (Patel et al., 2013)."}, {"heading": "2.5 Transliteration (TR)", "text": "We developed transliteration systems using Durrani et al. (2014) built into the Moses tool. We used the n-best transliteration output for OOV words. These candidates were then connected and rescored with the language model to get the best translation for the given source sentence."}, {"heading": "2.6 Language Modelling", "text": "We trained 5-gram LM with KenLM with modified Kneser-Ney smoothing. LM size was quite large (ARPA-88.7GB, binary-27.4GB), even after binarization. Training LM with the huge amount of monolingual data like Bojar et al. (2014) (approx. 10GB) required good computing resources (60GB RAM and 200GB working directory space). Besides, Bojar et al. (2014) corpus contains unwanted symbols for KenLM that we need to remove first."}, {"heading": "3 Experiments and Results", "text": "Table 2 shows evaluation results for different systems tested under restricted submission, i.e. systems trained only on the common data. Table 3 shows that the use of pre-processing and transliteration helped to improve about 1-5 blueprints in the language pairs. Detailed evaluation results for unrestricted systems, i.e. systems that use language models based on external data, are shown in Table 3. A significant improvement can be seen in the table when additional data is used for voice modeling."}, {"heading": "4 Submission to the Shared Task", "text": "We submitted two different results to the competition, restricted and unrestricted, and the restricted systems were trained only on the basis of data released by the organizers. For unrestricted systems, we used additional monolingual data, including Bojar et al. (2014) and Khapra et al. (2010) for speech modeling."}, {"heading": "5 Conclusion and Feature Work", "text": "In this article we introduced translation systems from Bengali, English, Marathi, Tamil and Telugu to Hindi. These SMT systems with source-side suffix separation, compound splitting, pre-ordering and larger language model have significantly higher accuracy above the baseline. More complex features for factor models and better formulation of pre-processing could be the next step."}], "references": [{"title": "A Statistical Approach", "author": ["Brown et al.1990] Peter F Brown", "John Cocke", "Stephen A Della Pietra", "Vincent J Della Pietra", "Fredrick Jelinek", "John D Lafferty", "Robert L Mercer", "Paul S Roossin"], "venue": null, "citeRegEx": "Brown et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Brown et al\\.", "year": 1990}, {"title": "An Empirical Study of Smoothing Techniques for Language Modeling", "author": ["Chen", "Goodman1996] Stanley F Chen", "Joshua Goodman"], "venue": "In Proceedings of the 34th annual meeting on Association for Computational Linguistics,", "citeRegEx": "Chen et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Chen et al\\.", "year": 1996}, {"title": "Automatic Evaluation of Machine Translation Quality using N-gram Co-occurrence Statistics", "author": ["George Doddington"], "venue": "In Proceedings of the second international conference on Human Language Technology Research,", "citeRegEx": "Doddington.,? \\Q2002\\E", "shortCiteRegEx": "Doddington.", "year": 2002}, {"title": "Integrating an unsupervised transliteration model into statistical machine translation", "author": ["Hassan Sajjad", "Hieu Hoang", "Philipp Koehn"], "venue": "In Proceedings of the 15th Conference of the European Chapter of the ACL", "citeRegEx": "Durrani et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Durrani et al\\.", "year": 2014}, {"title": "KenLM: Faster and Smaller Language Model Queries", "author": ["Kenneth Heafield"], "venue": "In Proceedings of the Sixth Workshop on Statistical Machine Translation,", "citeRegEx": "Heafield.,? \\Q2011\\E", "shortCiteRegEx": "Heafield.", "year": 2011}, {"title": "All Words Domain Adapted WSD: Finding a Middle Ground between Supervision and Unsupervision", "author": ["Anup Kulkarni", "Saurabh Sohoney", "Pushpak Bhattacharyya"], "venue": "In Proceedings of the 48th Annual Meet-", "citeRegEx": "Khapra et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Khapra et al\\.", "year": 2010}, {"title": "Factored translation models", "author": ["Koehn", "Hoang2007] Philipp Koehn", "Hieu Hoang"], "venue": "In EMNLP-CoNLL,", "citeRegEx": "Koehn et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Koehn et al\\.", "year": 2007}, {"title": "Empirical Methods for Compound Splitting", "author": ["Koehn", "Knight2003] Philipp Koehn", "Kevin Knight"], "venue": "In Proceedings of the tenth conference on European chapter of the Association for Computational Linguistics-Volume", "citeRegEx": "Koehn et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Koehn et al\\.", "year": 2003}, {"title": "Statistical Phrase-Based Translation", "author": ["Koehn et al.2003] Philipp Koehn", "Franz Josef Och", "Daniel Marcu"], "venue": "In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language", "citeRegEx": "Koehn et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Koehn et al\\.", "year": 2003}, {"title": "A Phrase-Based, Joint Probability Model for Statistical Machine Translation", "author": ["Marcu", "Wong2002] Daniel Marcu", "William Wong"], "venue": "In Proceedings of the ACL-02 conference on Empirical methods in natural language processing-Volume", "citeRegEx": "Marcu et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Marcu et al\\.", "year": 2002}, {"title": "Applied morphological processing of english", "author": ["Minnen et al.2001] Guido Minnen", "John Carroll", "Darren Pearce"], "venue": "Natural Language Engineering,", "citeRegEx": "Minnen et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Minnen et al\\.", "year": 2001}, {"title": "A Systematic Comparison of Various Statistical Alignment Models", "author": ["Och", "Ney2003] Franz Josef Och", "Hermann Ney"], "venue": "Computational linguistics,", "citeRegEx": "Och et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Och et al\\.", "year": 2003}, {"title": "BLEU: A Method for Automatic Evaluation of Machine Translation", "author": ["Salim Roukos", "Todd Ward", "Wei-Jing Zhu"], "venue": "In Proceedings of the 40th annual meeting on association for computational linguis-", "citeRegEx": "Papineni et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Papineni et al\\.", "year": 2002}, {"title": "Reordering rules for english-hindi smt", "author": ["Patel et al.2013] Raj Nath Patel", "Rohit Gupta", "Prakash B Pimpale", "Sasikumar M"], "venue": "In Proceedings of the Second Workshop on Hybrid Approaches to Translation,", "citeRegEx": "Patel et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Patel et al\\.", "year": 2013}, {"title": "Statistical Machine Translation for Indian Languages: Mission Hindi", "author": ["Patel et al.2014] Raj Nath Patel", "Prakash B Pimpale", "Sasikumar M"], "venue": "In Proceedings of NLP Tools contest. ICON-2014: 11th International Conference on Natural Language Pro-", "citeRegEx": "Patel et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Patel et al\\.", "year": 2014}, {"title": "SMT from Agglutinative Languages: Use of Suffix Separation and Word Splitting", "author": ["Raj Nath Patel", "Sasikumar M"], "venue": "In Proceedings of ICON-2014: 11th International Conference on Natural Language Process-", "citeRegEx": "Pimpale et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Pimpale et al\\.", "year": 2014}, {"title": "Towards the Use of Word Stems and Suffixes for Statistical Machine Translation", "author": ["Popovic", "Ney2004] Maja Popovic", "Hermann Ney"], "venue": null, "citeRegEx": "Popovic et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Popovic et al\\.", "year": 2004}, {"title": "Statistical Machine Translation of German Compound Words", "author": ["Popovi\u0107 et al.2006] Maja Popovi\u0107", "Daniel Stein", "Hermann Ney"], "venue": "In Advances in Natural Language Processing,", "citeRegEx": "Popovi\u0107 et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Popovi\u0107 et al\\.", "year": 2006}, {"title": "A Lightweight Stemmer for Hindi", "author": ["Ramanathan", "Durgesh D Rao"], "venue": "In The Proceedings of EACL", "citeRegEx": "Ramanathan et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Ramanathan et al\\.", "year": 2003}, {"title": "A Study of Translation Edit Rate with Targeted Human Annotation. In Proceedings of association for machine translation in the Ameri", "author": ["Bonnie Dorr", "Richard Schwartz", "Linnea Micciulla", "John Makhoul"], "venue": null, "citeRegEx": "Snover et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Snover et al\\.", "year": 2006}], "referenceMentions": [{"referenceID": 14, "context": "Koehn and Knight (2003), Popovic and Ney (2004), nd Popovi\u0107 et al. (2006) have demonstrated ways to handle this issue with morphological segmentation of words in the source sentences before training the SMT system.", "startOffset": 52, "endOffset": 74}, {"referenceID": 13, "context": "To handle this morphological difference we have used suffix separation and compound word splitting developed by Pimpale et al. (2014) and Patel et al.", "startOffset": 112, "endOffset": 134}, {"referenceID": 13, "context": "(2014) and Patel et al. (2014).", "startOffset": 11, "endOffset": 31}, {"referenceID": 13, "context": "For English-Hindi SMT, we achieve better alignment using preordering (Patel et al., 2013) and stem as an alignment factor (Koehn and Hoang, 2007).", "startOffset": 69, "endOffset": 89}, {"referenceID": 3, "context": "We used Durrani et al. (2014), which is a fully unsupervised approach for developing a transliteration system using parallel corpus meant for the SMT training.", "startOffset": 8, "endOffset": 30}, {"referenceID": 5, "context": "For unconstrained systems, additional data (Bojar et al., 2014; Khapra et al., 2010) has been used for language modeling.", "startOffset": 43, "endOffset": 84}, {"referenceID": 0, "context": "The baseline system was setup by using the phrase-based model (Och and Ney, 2003; Brown et al., 1990; Marcu and Wong, 2002; Koehn et al., 2003; Koehn et al., 2007) and Koehn and Hoang (2007) was used for factored model.", "startOffset": 62, "endOffset": 163}, {"referenceID": 7, "context": "The baseline system was setup by using the phrase-based model (Och and Ney, 2003; Brown et al., 1990; Marcu and Wong, 2002; Koehn et al., 2003; Koehn et al., 2007) and Koehn and Hoang (2007) was used for factored model.", "startOffset": 62, "endOffset": 163}, {"referenceID": 6, "context": "The baseline system was setup by using the phrase-based model (Och and Ney, 2003; Brown et al., 1990; Marcu and Wong, 2002; Koehn et al., 2003; Koehn et al., 2007) and Koehn and Hoang (2007) was used for factored model.", "startOffset": 62, "endOffset": 163}, {"referenceID": 4, "context": "The language model was trained using KenLM (Heafield, 2011) toolkit with modified Kneser-Ney smoothing (Chen and Goodman, 1996).", "startOffset": 43, "endOffset": 59}, {"referenceID": 10, "context": "For English, we used porter stemmer (Minnen et al., 2001).", "startOffset": 36, "endOffset": 57}, {"referenceID": 0, "context": "The baseline system was setup by using the phrase-based model (Och and Ney, 2003; Brown et al., 1990; Marcu and Wong, 2002; Koehn et al., 2003; Koehn et al., 2007) and Koehn and Hoang (2007) was used for factored model.", "startOffset": 82, "endOffset": 191}, {"referenceID": 12, "context": "The different experimental systems were compared using, BLEU (Papineni et al., 2002), NIST (Doddington, 2002), translation error rate (TER) (Snover et al.", "startOffset": 61, "endOffset": 84}, {"referenceID": 2, "context": ", 2002), NIST (Doddington, 2002), translation error rate (TER) (Snover et al.", "startOffset": 14, "endOffset": 32}, {"referenceID": 19, "context": ", 2002), NIST (Doddington, 2002), translation error rate (TER) (Snover et al., 2006).", "startOffset": 63, "endOffset": 84}, {"referenceID": 15, "context": "To tackle the morphological divergence between the source and target languages for the purpose of a better SMT system, we preprocessed the source (Bengali, Marathi, Tamil, and Telugu) for suffix separation and compound word splitting (Pimpale et al., 2014; Patel et al., 2014) prior to training and testing.", "startOffset": 234, "endOffset": 276}, {"referenceID": 14, "context": "To tackle the morphological divergence between the source and target languages for the purpose of a better SMT system, we preprocessed the source (Bengali, Marathi, Tamil, and Telugu) for suffix separation and compound word splitting (Pimpale et al., 2014; Patel et al., 2014) prior to training and testing.", "startOffset": 234, "endOffset": 276}, {"referenceID": 13, "context": "To handle the structural divergence (enhi), we used source side reordering (Patel et al., 2013).", "startOffset": 75, "endOffset": 95}, {"referenceID": 3, "context": "We developed transliteration systems using Durrani et al. (2014) inbuilt with the Moses tool.", "startOffset": 43, "endOffset": 65}, {"referenceID": 5, "context": "(2014) and Khapra et al. (2010), for language modeling.", "startOffset": 11, "endOffset": 32}], "year": 2016, "abstractText": "This paper presents Centre for Development of Advanced Computing Mumbai\u2019s (CDACM) submission to NLP Tools Contest on Statistical Machine Translation in Indian Languages (ILSMT) 2015 (collocated with ICON 2015). The aim of the contest was to collectively explore the effectiveness of Statistical Machine Translation (SMT) while translating within Indian languages and between English and Indian languages. In this paper, we report our work on all five language pairs, namely Bengali-Hindi (bn-hi), Marathi-Hindi (mrhi), Tamil-Hindi (ta-hi), Telugu-Hindi (tehi), and English-Hindi (en-hi) for Health, Tourism and General domains. We have used suffix separation, compound splitting and preordering prior to SMT training and testing.", "creator": "LaTeX with hyperref package"}}}