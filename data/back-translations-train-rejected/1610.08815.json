{"id": "1610.08815", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Oct-2016", "title": "A Deeper Look into Sarcastic Tweets Using Deep Convolutional Neural Networks", "abstract": "Sarcasm detection is a key task for many natural language processing tasks. In sentiment analysis, for example, sarcasm can flip the polarity of an \"apparently positive\" sentence and, hence, negatively affect polarity detection performance. To date, most approaches to sarcasm detection have treated the task primarily as a text categorization problem. Sarcasm, however, can be expressed in very subtle ways and requires a deeper understanding of natural language that standard text categorization techniques cannot grasp. In this work, we develop models based on a pre-trained convolutional neural network for extracting sentiment, emotion and personality features for sarcasm detection. Such features, along with the network's baseline features, allow the proposed models to outperform the state of the art on benchmark datasets. We also address the often ignored generalizability issue of classifying data that have not been seen by the models at learning phase.", "histories": [["v1", "Thu, 27 Oct 2016 14:50:43 GMT  (1406kb,D)", "https://arxiv.org/abs/1610.08815v1", "12 pages, 4 figures in COLING 2016"], ["v2", "Thu, 27 Jul 2017 02:38:59 GMT  (1406kb,D)", "http://arxiv.org/abs/1610.08815v2", "Published in COLING 2016"]], "COMMENTS": "12 pages, 4 figures in COLING 2016", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["soujanya poria", "erik cambria", "devamanyu hazarika", "prateek vij"], "accepted": false, "id": "1610.08815"}, "pdf": {"name": "1610.08815.pdf", "metadata": {"source": "CRF", "title": "A Deeper Look into Sarcastic Tweets Using Deep Convolutional Neural Networks", "authors": ["Soujanya Poria", "Erik Cambria", "Devamanyu Hazarika", "Prateek Vij"], "emails": ["cambria}@ntu.edu.sg", "prateek}@sentic.net"], "sections": [{"heading": "1 Introduction", "text": "Sarcasm is defined as \"a sharp, bitter or cutting utterance or remark; a bitter giveaway or mockery of unclassified events.\" As the fields of affective calculation and sensation analysis have become increasingly popular (Cambria, 2016), it is important to recognize sarcastic, ironic and metaphorical expressions. Sarcasm, in particular, is key to sensation analysis as it can completely reverse the polarity of opinions. \"I love the pain of separation.\" However, acquiring this knowledge is very difficult, we have indirectly extracted the classifiers to such knowledge from Twitter. We used Twitter data that probably includes both the sarcastic and the nonsarcastic accounts of an event or similar event. We believe that these sentences were indirectly extracted from Twitter."}, {"heading": "2 Related Works", "text": "NLP research is gradually evolving from lexical to compositional semantics (Cambria and White, 2014) through the introduction of novel, meaningful, and context-sensitive paradigms such as revolutionary networks (Poria et al., 2016a), recurring belief patterns (Chaturvedi et al., 2016), statistical learning theory (Oneto et al., 2016), revolutionary multiple kernel learning processes (Poria et al., 2016b), and sound reasoning (Cambria and Hussain, 2015). But while other NLP tasks have been extensively studied, detection of sarcasms is a relatively new research topic that has only recently gained importance, thanks in part to the rise of social media analysis and sentiment analysis (Zadeh et al., 2016b) and the use of multimodal information as a new trend (Zadeh et al., 2016a; Poria et al, 2015b)."}, {"heading": "3 Sentiment Analysis and Sarcasm Detection", "text": "Sarcasm detection is an important sub-task of sentiment analysis (Cambria et al., 2015). Since sarcastic sentences are subjective, they carry feelings and emotional information. Most studies in literature (Joshi et al., 2016; Bosco et al., 2013; Joshi et al., 2015; Far\u0131 \u0301 as et al., 2016) include sentiment features in sarcasm detection using a state-of-the-art sentiment lexicon. Below, we explain how sentiment information is central to expressing sarcastic opinions and the approach we take to using such information for sarcasm detection. Generally, most sarcastic sentences contradict the fact \"I love the pain present in resolutions.\" (Figure 1), the word \"love\" contradicts the pain present in resolutions, \"because generally no one loves to be in pain."}, {"heading": "4 The Proposed Framework", "text": "As discussed in the literature (Riloff et al., 2013), detection of sarcasm may depend on mood and other cognitive aspects. Therefore, we incorporate both emotional and emotional cues into our framework. At the same time, we argue that the personality of the opinion-holder is an important factor in detection of sarcasm. To take all of these variables into account, we create different models for each of these variables, namely: feeling, emotion and personality. The idea is to train each model on its corresponding benchmark data set and therefore to use such pre-trained models together to extract sarcasm-related characteristics from the sarcasm datasets. Now, the workable research question is: Do these models contribute to improving the performance of detection of sarcasm? 'The literature shows that they improve performance, but not significantly."}, {"heading": "4.1 General CNN Framework", "text": "It captures contextual local characteristics from a set and, after several linking operations, it forms a global characteristic vector from these local characteristics. CNN does not need the handmade characteristics that are used in traditional, monitored classifiers. However, such handmade characteristics are difficult to calculate and a good guess for encrypting the characteristics is therefore always necessary to get satisfactory results. CNN instead uses a hierarchy of local characteristics that are important to learn the context. Handmade characteristics often ignore such a hierarchy of local characteristics that can be extracted from CNN, instead of using the handmade characteristics as they carry more useful information. The idea behind the linkage is to use the dot product of a vector of k-weights wk also known as a kernel vector with each k-gram in the set s (t) to get another sequence of characteristics c (t)."}, {"heading": "4.2 Sentiment Feature Extraction Model", "text": "As discussed above, sentiment clues play an important role in detecting sarcastic sentences. In our work, we train a CNN (see Section 4.1 for details) based on a sentiment benchmark dataset. This pre-trained model is then used to extract characteristics from the sarcastic datasets. Specifically, we use Semeval 2014 (Rosenthal et al., 2014) Twitter sentiment analysis dataset for the training. This dataset contains 9,497 tweets, of which 5,895 are positive, 3,131 negative, and 471 neutral. The fully connected layer of CNN used for sentiment feature extraction has 100 neurons, so 100 features are extracted from this pre-tracted model. The final Softmax determines whether a sentence is positive, negative, or neutral."}, {"heading": "4.3 Emotion Feature Extraction Model", "text": "We use the CNN structure as described in Section 4.1 for the extraction of emotional characteristics. As a data set for the extraction of emotional characteristics, we use the corpus developed by (Aman and Szpakowicz, 2007). This data set consists of blog posts characterized by the corresponding emotional categories. As an emotional taxonomy, the authors used six basic emotions, i.e. anger, disgust, surprise, sadness, joy, and fear. Specifically, the blog posts were divided into sentences and each sentence was labeled. The data set contains 5,205 sentences labeled by one of the emotional categories. After applying this model to the sarcasm data set, we obtained a 150-dimensional characteristic vector from the fully connected layer. Since the goal of the training is to place each sentence into one of the six emotion categories, we used six neurons in the Softmax layer."}, {"heading": "4.4 Personality Feature Extraction Model", "text": "In our work, we use five personality traits described by (Matthews and Gilliland, 1999), i.e. openness, conscientiousness, extraversion, agreement, and neuroticism. As a training data set, we use the corpus developed by (Matthews and Gilliland, 1999), which contains 2,400 essays labeled by each of the five personality traits. The fully connected layer comprises 150 neurons that are treated as traits. To create the final trait vector, we link the trait vector of each personality dimension. Thus, the personality model ultimately extracts a 750-dimensional trait vector (150-dimensional trait vector for each of the five personality traits).This network is replicated five times, one for each personality trait. Specifically, we create a CNN vector for each personality trait and the goal of each trait vector is to classify a sentence into a personality, whether it is binary or not."}, {"heading": "4.5 Baseline Method and Features", "text": "CNN can also be applied to the sarcasm data sets to identify sarcastic and non-sarcastic tweets. We designate the features extracted from these basic network functions, the method as the basic method, and 1 We show the optimal training settings of the CNNs used in this work. Changing the core size or adding / removing layers does not improve the results. The CNN architecture used in this basic method as the basic method CNN. Since the fully connected layer has 100 neurons, we have 100 basic functions in our experiment. This method is called the basic method because it directly aims to classify a sentence as sarcastic versus non-sarcastic."}, {"heading": "5 Experimental Results and Discussion", "text": "In this section, we present the experimental results using different feature combinations and compare them with the state of the art. For each feature, we show the results exclusively with CNN and CNNSVM (i.e. when the features extracted from CNN are transferred to the SVM)."}, {"heading": "5.1 Sarcasm Datasets Used in the Experiment", "text": "Dataset 1 (Balanced Dataset) This dataset was created by (Pta \u0301 cek et al., 2014). The tweets were downloaded from Twitter, using # Sarcasm as a marker for sarcastic tweets. It is a monolingual English dataset that consists of a balanced distribution of 50,000 sarcastic tweets and 50,000 non-sarcastic tweets. Dataset 2 (Imbalanced Dataset) Since sarcastic tweets are used less often (Pta \u0301 cek et al., 2014), we also need to examine the robustness of the features selected and train the model trained on these features on an unbalanced dataset. To this end, we have used another English dataset from (Pta \u0301 cek et al., 2014). It consists of 25,000 sarcastic tweets and 75,000 non-sarcastic tweets. Dataset 3 (Test Dataset) We received this dataset from The Sarcasm Detector2."}, {"heading": "5.2 Merging the Features", "text": "In the course of this research, we have conducted several experiments with different combinations of features. To provide clarity, we will explain below how the features extracted using differential models are merged. \u2022 In the standard feature merge process, we first extract the features from all deep CNN-based feature extraction models and then concatenate them. Subsequently, SVM is used on the resulting feature vector. \u2022 In another setting, we use the features extracted from the pre-trained models as static feature channels in the CNN of the base method. These features are appended to the hidden layer of the base line CNN before the final Softmax layer is issued. \u2022 For comparison, we have reimplemented the most advanced methods. Since (Joshi et al., 2015) did not mention the mood lexicon they use in the experiment, we have used SenticNet (Cambria et al., 2016) in re-implementing their method."}, {"heading": "5.3 Results on Dataset 1", "text": "As shown in Table 2, CNN-SVM for each feature exceeds the performance of the CNN model. Following (Tsur et al., 2010), we performed a 5x cross-validation of this dataset. Basic features (4.5) perform best among other features. However, among all pre-trained models, the sentiment model (F1 score: 87.00%) achieves better performance compared to the other two pre-trained models. Interestingly, when we combine the basic features with the features extracted from the pre-trained, low NLP models, we achieve only an improvement of 0.11% over the F-Score. It means that the basic features alone are quite capable of detecting sarcasm. On the other hand, when we combine feelings, emotions and personality traits, we get 90.70% F1-Score. This indicates that the pre-trained features are actually useful for detecting the sarcasm score. On the other hand, when we combine the emotions and personality traits, we get 90.70% F1-Score-Score-Score-Score-Score. This indicates that the pre-trained features are actually useful for detecting the Score-Score-Score-Score-dominant (we also compare the research model's best approach to this Score-conducted)."}, {"heading": "5.4 Results on Dataset 2", "text": "For this data set, too, we achieve the best accuracy by using all characteristics. Baseline characteristics perform significantly better (F1 score: 92.32%) than all other characteristics. However, if we use all characteristics, CNN alone (F1 score: 89.73%) does not perform better than the state of the art (Pta \u0301 cek et al., 2014) (F1 score: 92.37%). As shown in Table 3, CNN-SVM alone (F1 score: 89.73%) outperforms the state of the art (F1 score: 94.80%). Among pre-trained models, the sentiment model performs best (F1 score: 87.00%). Table 2 shows the performance of different combinations of characteristics. The gap between the F1 scores of the basic values of only the larger characteristics and the balanced sentiment characteristics based on 9F1 sensors underpins the sentiment very well."}, {"heading": "5.5 Results on Dataset 3", "text": "Experimental results of dataset 3 show similar trends (Table 3) compared to dataset 1 and dataset 2. The highest performance (F1 score 93.30%) is achieved when we combine basic traits with emotional, emotional and personality traits. In this case, CNN-SVM consistently performs better than CNN in any combination of traits. The sentiment model proves to be the best prepared model. The F1 score of 84.43% is achieved when we merge feelings, emotions and personality traits. Dataset 3 is more complex and non-linear in nature compared to the other two datasets. As shown in Table 3, the methods of (Joshi et al., 2015) and (Pta'cek et al., 2014) perform poorly on this dataset. The TP rate achieved by (Joshi et al., 2015) is only 10.07%, meaning that their method performs poorly on complex datasets."}, {"heading": "5.6 Testing Generalizability of the Models and Discussions", "text": "To test the generalizability of the proposed approach, we conduct training on Dataset 1 and test this method on Dataset 3. F1 score drops dramatically to 33.05%. To understand this finding, we visualize each dataset with PCA (Figure 3). It shows that although Dataset 1 is largely linearly separable, Dataset 3 is not. A linear kernel that works well on Dataset 1 does not perform well on Dataset 3. Using the RBF kernel, it outperforms the data and produces worse results than what we get with linear kernels. Similar trends are seen in the performance of other two state-of-the-art approaches (Joshi et al. 2015; Pta-Scak et al., 2014). So we decide to conduct training on Dataset 3 and test on Dataset 1. Better performance than expected is observed with F1 score 76.78%."}, {"heading": "5.7 Baseline Features vs Pre-trained Features", "text": "Our experimental results show that the basic traits are better than the pre-trained traits for detecting sarcasm. However, the combination of pre-trained traits and baseline traits outperforms both on their own. It is counterintuitive because experimental results show that both traits learn almost the same global and contextual traits. In particular, the baseline network dominates over the pre-trained network, as the former learns most of the traits that the latter have learnt. Nevertheless, the combination of baseline traits and pre-trained classifiers improves overall performance and generalisability, thus proving their effectiveness in detecting sarcasm. Experimental results show that sensory traits and emotion traits are the most useful traits alongside baseline traits (Figure 4). Therefore, in order to achieve a better understanding of the relationship between personality traits and other pre-trained traits, we conducted Spearman correlation tests to correlate these traits with each other in a high-correlation table."}, {"heading": "6 Conclusion", "text": "In this work, we developed pre-trained sentiment, emotion and personality models for identifying sarcastic texts using CNN, which prove to be very effective for detecting sarcasm. In the future, we plan to evaluate the performance of the proposed method on a large corpus and other domain-dependent corpus. Future work will also focus on analyzing past tweets and activities of users to better understand their personality and profile, thus further improving the disambiguity between sarcastic and non-sarcastic text."}], "references": [{"title": "Identifying expressions of emotion in text", "author": ["Aman", "Szpakowicz2007] Saima Aman", "Stan Szpakowicz"], "venue": "In International Conference on Text, Speech and Dialogue,", "citeRegEx": "Aman et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Aman et al\\.", "year": 2007}, {"title": "Modelling sarcasm in Twitter, a novel approach", "author": ["Horacio Saggion", "Francesco Ronzano"], "venue": "ACL", "citeRegEx": "Barbieri et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Barbieri et al\\.", "year": 2014}, {"title": "Developing corpora for sentiment analysis and opinion mining: A survey and the Senti-TUT case study", "author": ["Bosco et al.2013] Cristina Bosco", "Viviana Patti", "Andrea Bolioli"], "venue": "IEEE Intelligent Systems,", "citeRegEx": "Bosco et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bosco et al\\.", "year": 2013}, {"title": "An impact analysis of features in a classification approach to irony detection in product reviews", "author": ["Philipp Cimiano", "Roman Klinger"], "venue": "In Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis,", "citeRegEx": "Buschmeier et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Buschmeier et al\\.", "year": 2014}, {"title": "Sentic Computing: A Common-Sense-Based Framework for Concept-Level Sentiment Analysis", "author": ["Cambria", "Hussain2015] Erik Cambria", "Amir Hussain"], "venue": null, "citeRegEx": "Cambria et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Cambria et al\\.", "year": 2015}, {"title": "Jumping NLP curves: A review of natural language processing research", "author": ["Cambria", "White2014] Erik Cambria", "Bebo White"], "venue": null, "citeRegEx": "Cambria et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Cambria et al\\.", "year": 2014}, {"title": "The CLSA model: A novel framework for concept-level sentiment analysis", "author": ["Cambria et al.2015] Erik Cambria", "Soujanya Poria", "Federica Bisio", "Rajiv Bajpai", "Iti Chaturvedi"], "venue": "In International Conference on Intelligent Text Processing and Computational Linguistics,", "citeRegEx": "Cambria et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Cambria et al\\.", "year": 2015}, {"title": "SenticNet 4: A semantic resource for sentiment analysis based on conceptual primitives", "author": ["Cambria et al.2016] Erik Cambria", "Soujanya Poria", "Rajiv Bajpai", "Bj\u00f6rn Schuller"], "venue": "In COLING", "citeRegEx": "Cambria et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Cambria et al\\.", "year": 2016}, {"title": "Affective computing and sentiment analysis", "author": ["Erik Cambria"], "venue": "IEEE Intelligent Systems,", "citeRegEx": "Cambria.,? \\Q2016\\E", "shortCiteRegEx": "Cambria.", "year": 2016}, {"title": "Clues for detecting irony in user-generated contents: oh...!! it\u2019s so easy;-)", "author": ["Lu\u0131\u0301s Sarmento", "M\u00e1rio J Silva", "Eug\u00e9nio De Oliveira"], "venue": "In International CIKM workshop on Topicsentiment analysis for mass opinion,", "citeRegEx": "Carvalho et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Carvalho et al\\.", "year": 2009}, {"title": "Learning word dependencies in text by means of a deep recurrent belief network. Knowledge-Based Systems, 108:144\u2013154", "author": ["Yew-Soon Ong", "Ivor Tsang", "Roy Welsch", "Erik Cambria"], "venue": null, "citeRegEx": "Chaturvedi et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Chaturvedi et al\\.", "year": 2016}, {"title": "Semi-supervised recognition of sarcastic sentences in Twitter and Amazon", "author": ["Oren Tsur", "Ari Rappoport"], "venue": "In Conference on computational natural language learning,", "citeRegEx": "Davidov et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Davidov et al\\.", "year": 2010}, {"title": "Irony detection in Twitter: The role of affective content", "author": ["Viviana Patti", "Paolo Rosso"], "venue": "ACM Transactions on Internet Technology,", "citeRegEx": "Far\u0131\u0301as et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Far\u0131\u0301as et al\\.", "year": 2016}, {"title": "Identifying sarcasm in Twitter: A closer look", "author": ["Smaranda Muresan", "Nina Wacholder"], "venue": null, "citeRegEx": "Gonz\u00e1lez.Ib\u00e1nez et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Gonz\u00e1lez.Ib\u00e1nez et al\\.", "year": 2011}, {"title": "Harnessing context incongruity for sarcasm detection", "author": ["Joshi et al.2015] Aditya Joshi", "Vinita Sharma", "Pushpak Bhattacharyya"], "venue": "In Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing,", "citeRegEx": "Joshi et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Joshi et al\\.", "year": 2015}, {"title": "Automatic sarcasm detection: A survey", "author": ["Joshi et al.2016] Aditya Joshi", "Pushpak Bhattacharyya", "Mark James Carman"], "venue": "arXiv preprint arXiv:1602.03426", "citeRegEx": "Joshi et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Joshi et al\\.", "year": 2016}, {"title": "A convolutional neural network for modelling sentences. CoRR, abs/1404.2188", "author": ["Edward Grefenstette", "Phil Blunsom"], "venue": null, "citeRegEx": "Kalchbrenner et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kalchbrenner et al\\.", "year": 2014}, {"title": "The perfect solution for detecting sarcasm in tweets # not", "author": ["Florian Kunneman", "Antal van den Bosch"], "venue": "In Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis (WASSA),", "citeRegEx": "Liebrecht et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Liebrecht et al\\.", "year": 2013}, {"title": "The personality theories of H.J. Eysenck and J.A. Gray: A comparative review", "author": ["Matthews", "Gilliland1999] Gerald Matthews", "Kirby Gilliland"], "venue": "Personality and Individual differences,", "citeRegEx": "Matthews et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Matthews et al\\.", "year": 1999}, {"title": "Who cares about sarcastic tweets? investigating the impact of sarcasm on sentiment analysis", "author": ["Maynard", "Greenwood2014] Diana Maynard", "Mark A Greenwood"], "venue": "In LREC,", "citeRegEx": "Maynard et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Maynard et al\\.", "year": 2014}, {"title": "Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781", "author": ["Kai Chen", "Greg Corrado", "Jeffrey Dean"], "venue": null, "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Statistical learning theory and ELM for big social data analysis", "author": ["Oneto et al.2016] Luca Oneto", "Federica Bisio", "Erik Cambria", "Davide Anguita"], "venue": null, "citeRegEx": "Oneto et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Oneto et al\\.", "year": 2016}, {"title": "Deep convolutional neural network textual features and multiple kernel learning for utterance-level multimodal sentiment analysis", "author": ["Erik Cambria", "Alexander Gelbukh"], "venue": null, "citeRegEx": "Poria et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Poria et al\\.", "year": 2015}, {"title": "Sentiment data flow analysis by means of dynamic linguistic patterns", "author": ["Erik Cambria", "Alexander Gelbukh", "Federica Bisio", "Amir Hussain"], "venue": null, "citeRegEx": "Poria et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Poria et al\\.", "year": 2015}, {"title": "2016a. Aspect extraction for opinion mining with a deep convolutional neural network. Knowledge-Based Systems, 108:42\u201349", "author": ["Erik Cambria", "Alexander Gelbukh"], "venue": null, "citeRegEx": "Poria et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Poria et al\\.", "year": 2016}, {"title": "Convolutional MKL based multimodal emotion recognition and sentiment analysis", "author": ["Iti Chaturvedi", "Erik Cambria", "Amir Hussain"], "venue": null, "citeRegEx": "Poria et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Poria et al\\.", "year": 2016}, {"title": "Context-dependent sentiment analysis in user-generated videos", "author": ["Poria et al.2017] Soujanya Poria", "Erik Cambria", "Devamanyu Hazarika", "Navonil Mazumder", "Amir Zadeh", "Louis-Philippe Morency"], "venue": null, "citeRegEx": "Poria et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Poria et al\\.", "year": 2017}, {"title": "A multidimensional approach for detecting irony in Twitter", "author": ["Reyes et al.2013] Antonio Reyes", "Paolo Rosso", "Tony Veale"], "venue": "Language resources and evaluation,", "citeRegEx": "Reyes et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Reyes et al\\.", "year": 2013}, {"title": "Sarcasm as contrast between a positive sentiment and negative situation", "author": ["Riloff et al.2013] Ellen Riloff", "Ashequl Qadir", "Prafulla Surve", "Lalindra De Silva", "Nathan Gilbert", "Ruihong Huang"], "venue": "In EMNLP,", "citeRegEx": "Riloff et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Riloff et al\\.", "year": 2013}, {"title": "Semeval-2014 task 9: Sentiment analysis in Twitter", "author": ["Alan Ritter", "Preslav Nakov", "Veselin Stoyanov"], "venue": "In International workshop on semantic evaluation (SemEval", "citeRegEx": "Rosenthal et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Rosenthal et al\\.", "year": 2014}, {"title": "Combating human trafficking with deep multimodal models", "author": ["Tong et al.2017] Edmund Tong", "Amir Zadeh", "Louis-Philippe Morency"], "venue": "In Association for Computational Linguistics", "citeRegEx": "Tong et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Tong et al\\.", "year": 2017}, {"title": "ICWSM-a great catchy name: Semisupervised recognition of sarcastic sentences in online product reviews", "author": ["Tsur et al.2010] Oren Tsur", "Dmitry Davidov", "Ari Rappoport"], "venue": "In ICWSM,", "citeRegEx": "Tsur et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Tsur et al\\.", "year": 2010}, {"title": "2016a. Mosi: multimodal corpus of sentiment intensity and subjectivity analysis in online opinion videos. arXiv preprint arXiv:1606.06259", "author": ["Zadeh et al.2016a] Amir Zadeh", "Rowan Zellers", "Eli Pincus", "Louis-Philippe Morency"], "venue": null, "citeRegEx": "Zadeh et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Zadeh et al\\.", "year": 2016}, {"title": "Multimodal sentiment intensity analysis in videos: Facial gestures and verbal messages", "author": ["Zadeh et al.2016b] Amir Zadeh", "Rowan Zellers", "Eli Pincus", "Louis-Philippe Morency"], "venue": "IEEE Intelligent Systems,", "citeRegEx": "Zadeh et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Zadeh et al\\.", "year": 2016}, {"title": "Convolutional experts constrained local model for facial landmark detection", "author": ["Zadeh et al.2017a] Amir Zadeh", "Tadas Baltru\u0161aitis", "Louis-Philippe Morency"], "venue": "In Computer Vision and Pattern Recognition Workshop (CVPRW). IEEE", "citeRegEx": "Zadeh et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Zadeh et al\\.", "year": 2017}, {"title": "2017b. Tensor fusion network for multimodal sentiment analysis", "author": ["Zadeh et al.2017b] Amir Zadeh", "Minghai Chen", "Soujanya Poria", "Erik Cambria", "Louis-Philippe Morency"], "venue": "In Empirical Methods in NLP", "citeRegEx": "Zadeh et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Zadeh et al\\.", "year": 2017}, {"title": "Micro-opinion sentiment intensity analysis and summarization in online videos", "author": ["Amir Zadeh"], "venue": "In Proceedings of the 2015 ACM on International Conference on Multimodal Interaction,", "citeRegEx": "Zadeh.,? \\Q2015\\E", "shortCiteRegEx": "Zadeh.", "year": 2015}], "referenceMentions": [{"referenceID": 8, "context": "As the fields of affective computing and sentiment analysis have gained increasing popularity (Cambria, 2016), it is a major concern to detect sarcastic, ironic, and metaphoric expressions.", "startOffset": 94, "endOffset": 109}, {"referenceID": 13, "context": "Existing works on sarcasm detection have mainly focused on unigrams and the use of emoticons (Gonz\u00e1lez-Ib\u00e1nez et al., 2011; Carvalho et al., 2009; Barbieri et al., 2014), unsupervised pattern mining approach (Maynard and Greenwood, 2014), semi-supervised approach (Riloff et al.", "startOffset": 93, "endOffset": 169}, {"referenceID": 9, "context": "Existing works on sarcasm detection have mainly focused on unigrams and the use of emoticons (Gonz\u00e1lez-Ib\u00e1nez et al., 2011; Carvalho et al., 2009; Barbieri et al., 2014), unsupervised pattern mining approach (Maynard and Greenwood, 2014), semi-supervised approach (Riloff et al.", "startOffset": 93, "endOffset": 169}, {"referenceID": 1, "context": "Existing works on sarcasm detection have mainly focused on unigrams and the use of emoticons (Gonz\u00e1lez-Ib\u00e1nez et al., 2011; Carvalho et al., 2009; Barbieri et al., 2014), unsupervised pattern mining approach (Maynard and Greenwood, 2014), semi-supervised approach (Riloff et al.", "startOffset": 93, "endOffset": 169}, {"referenceID": 28, "context": ", 2014), unsupervised pattern mining approach (Maynard and Greenwood, 2014), semi-supervised approach (Riloff et al., 2013) and ngrams based approach (Tsur et al.", "startOffset": 102, "endOffset": 123}, {"referenceID": 31, "context": ", 2013) and ngrams based approach (Tsur et al., 2010; Davidov et al., 2010; Pt\u00e1cek et al., 2014; Joshi et al., 2015) with sentiment features.", "startOffset": 34, "endOffset": 116}, {"referenceID": 11, "context": ", 2013) and ngrams based approach (Tsur et al., 2010; Davidov et al., 2010; Pt\u00e1cek et al., 2014; Joshi et al., 2015) with sentiment features.", "startOffset": 34, "endOffset": 116}, {"referenceID": 14, "context": ", 2013) and ngrams based approach (Tsur et al., 2010; Davidov et al., 2010; Pt\u00e1cek et al., 2014; Joshi et al., 2015) with sentiment features.", "startOffset": 34, "endOffset": 116}, {"referenceID": 10, "context": ", 2016a), recurrent belief networks (Chaturvedi et al., 2016), statistical learning theory (Oneto et al.", "startOffset": 36, "endOffset": 61}, {"referenceID": 21, "context": ", 2016), statistical learning theory (Oneto et al., 2016), convolutional multiple kernel learning (Poria et al.", "startOffset": 37, "endOffset": 57}, {"referenceID": 30, "context": ", 2016b) and using multimodal information as a new trend (Zadeh et al., 2016a; Poria et al., 2015a; Tong et al., 2017; Poria et al., 2017; Poria et al., 2016b) is a popular branch of NLP research that aims to understand sentiment of documents automatically using combination of various machine learning approaches (Zadeh, 2015; Zadeh et al.", "startOffset": 57, "endOffset": 159}, {"referenceID": 26, "context": ", 2016b) and using multimodal information as a new trend (Zadeh et al., 2016a; Poria et al., 2015a; Tong et al., 2017; Poria et al., 2017; Poria et al., 2016b) is a popular branch of NLP research that aims to understand sentiment of documents automatically using combination of various machine learning approaches (Zadeh, 2015; Zadeh et al.", "startOffset": 57, "endOffset": 159}, {"referenceID": 36, "context": ", 2016b) is a popular branch of NLP research that aims to understand sentiment of documents automatically using combination of various machine learning approaches (Zadeh, 2015; Zadeh et al., 2017b; Poria et al., 2017; Zadeh et al., 2017a).", "startOffset": 163, "endOffset": 238}, {"referenceID": 26, "context": ", 2016b) is a popular branch of NLP research that aims to understand sentiment of documents automatically using combination of various machine learning approaches (Zadeh, 2015; Zadeh et al., 2017b; Poria et al., 2017; Zadeh et al., 2017a).", "startOffset": 163, "endOffset": 238}, {"referenceID": 31, "context": "An early work in this field was done by (Tsur et al., 2010) on a dataset of 6,600 manually annotated Amazon reviews using a kNN-classifier over punctuation-based and pattern-based features, i.", "startOffset": 40, "endOffset": 59}, {"referenceID": 13, "context": "(Gonz\u00e1lez-Ib\u00e1nez et al., 2011) used support vector machine (SVM) and logistic regression over a feature set of unigrams, dictionary-based lexical features and pragmatic features (e.", "startOffset": 0, "endOffset": 30}, {"referenceID": 27, "context": "(Reyes et al., 2013) described a set of textual features for recognizing irony at a linguistic level, especially in short texts created via Twitter, and constructed a new model that was assessed along two dimensions: representativeness and relevance.", "startOffset": 0, "endOffset": 20}, {"referenceID": 28, "context": "(Riloff et al., 2013) used the presence of a positive sentiment in close proximity of a negative situation phrase as a feature for sarcasm detection.", "startOffset": 0, "endOffset": 21}, {"referenceID": 17, "context": "(Liebrecht et al., 2013) used the Balanced Window algorithm for classifying Dutch tweets as sarcastic vs.", "startOffset": 0, "endOffset": 24}, {"referenceID": 3, "context": "(Buschmeier et al., 2014) compared the performance of different classifiers on the Amazon review dataset using the imbalance between the sentiment expressed by the review and the user-given star rating.", "startOffset": 0, "endOffset": 25}, {"referenceID": 1, "context": "Features based on frequency (gap between rare and common words), written spoken gap (in terms of difference between usage), synonyms (based on the difference in frequency of synonyms) and ambiguity (number of words with many synonyms) were used by (Barbieri et al., 2014) for sarcasm detection in tweets.", "startOffset": 248, "endOffset": 271}, {"referenceID": 14, "context": "(Joshi et al., 2015) proposed the use of implicit incongruity and explicit incongruity based", "startOffset": 0, "endOffset": 20}, {"referenceID": 28, "context": "Their method is very much similar to the method proposed by (Riloff et al., 2013) except (Joshi et al.", "startOffset": 60, "endOffset": 81}, {"referenceID": 14, "context": ", 2013) except (Joshi et al., 2015) used explicit incongruity features.", "startOffset": 15, "endOffset": 35}, {"referenceID": 28, "context": "Their method outperforms the approach by (Riloff et al., 2013) on two datasets.", "startOffset": 41, "endOffset": 62}, {"referenceID": 4, "context": "Sarcasm detection is an important subtask of sentiment analysis (Cambria et al., 2015).", "startOffset": 64, "endOffset": 86}, {"referenceID": 15, "context": "Most of the studies in the literature (Joshi et al., 2016; Bosco et al., 2013; Joshi et al., 2015; Far\u0131\u0301as et al., 2016) include sentiment features in sarcasm detection with the use of a state-of-the-art sentiment lexicon.", "startOffset": 38, "endOffset": 120}, {"referenceID": 2, "context": "Most of the studies in the literature (Joshi et al., 2016; Bosco et al., 2013; Joshi et al., 2015; Far\u0131\u0301as et al., 2016) include sentiment features in sarcasm detection with the use of a state-of-the-art sentiment lexicon.", "startOffset": 38, "endOffset": 120}, {"referenceID": 14, "context": "Most of the studies in the literature (Joshi et al., 2016; Bosco et al., 2013; Joshi et al., 2015; Far\u0131\u0301as et al., 2016) include sentiment features in sarcasm detection with the use of a state-of-the-art sentiment lexicon.", "startOffset": 38, "endOffset": 120}, {"referenceID": 12, "context": "Most of the studies in the literature (Joshi et al., 2016; Bosco et al., 2013; Joshi et al., 2015; Far\u0131\u0301as et al., 2016) include sentiment features in sarcasm detection with the use of a state-of-the-art sentiment lexicon.", "startOffset": 38, "endOffset": 120}, {"referenceID": 28, "context": "As discussed in the literature (Riloff et al., 2013), sarcasm detection may depend on sentiment and other cognitive aspects.", "startOffset": 31, "endOffset": 52}, {"referenceID": 16, "context": "Similarly, varying kernel vectors and window sizes are used to obtain multiple features (Kalchbrenner et al., 2014).", "startOffset": 88, "endOffset": 115}, {"referenceID": 20, "context": "For each word xi in the vocabulary, a d-dimensional vector representation is given in a look up table that is learned from the data (Mikolov et al., 2013).", "startOffset": 132, "endOffset": 154}, {"referenceID": 20, "context": "The vectors are of dimensionality 300, trained using the continuous bag-of-words architecture (Mikolov et al., 2013).", "startOffset": 94, "endOffset": 116}, {"referenceID": 29, "context": "In particular, we use Semeval 2014 (Rosenthal et al., 2014) Twitter Sentiment Analysis Dataset for the training.", "startOffset": 35, "endOffset": 59}, {"referenceID": 14, "context": "Since (Joshi et al., 2015) did not mention about the sentiment lexicon they use in the experiment, we used SenticNet (Cambria et al.", "startOffset": 6, "endOffset": 26}, {"referenceID": 7, "context": ", 2015) did not mention about the sentiment lexicon they use in the experiment, we used SenticNet (Cambria et al., 2016) in the re-implementation of their method.", "startOffset": 98, "endOffset": 120}, {"referenceID": 31, "context": "Following (Tsur et al., 2010), we have carried out a 5-fold cross-validation on this dataset.", "startOffset": 10, "endOffset": 29}, {"referenceID": 14, "context": "Both the proposed baseline model and the baseline + sentiment + emotion + personality model outperform the state of the art (Joshi et al., 2015; Pt\u00e1cek et al., 2014).", "startOffset": 124, "endOffset": 165}, {"referenceID": 14, "context": "02% (Joshi et al., 2015) 65.", "startOffset": 4, "endOffset": 24}, {"referenceID": 14, "context": "As shown in Table 3, the methods by (Joshi et al., 2015) and (Pt\u00e1cek et al.", "startOffset": 36, "endOffset": 56}, {"referenceID": 14, "context": "The TP rate achieved by (Joshi et al., 2015) is only 10.", "startOffset": 24, "endOffset": 44}, {"referenceID": 14, "context": "15% than (Joshi et al., 2015).", "startOffset": 9, "endOffset": 29}, {"referenceID": 14, "context": "Similar trends are seen in the performance of other two state-of-the-art approaches (Joshi et al., 2015; Pt\u00e1cek et al., 2014).", "startOffset": 84, "endOffset": 125}, {"referenceID": 14, "context": "While the method by (Joshi et al., 2015) obtains F1-score of 47.", "startOffset": 20, "endOffset": 40}], "year": 2017, "abstractText": "Sarcasm detection is a key task for many natural language processing tasks. In sentiment analysis, for example, sarcasm can flip the polarity of an \u201capparently positive\u201d sentence and, hence, negatively affect polarity detection performance. To date, most approaches to sarcasm detection have treated the task primarily as a text categorization problem. Sarcasm, however, can be expressed in very subtle ways and requires a deeper understanding of natural language that standard text categorization techniques cannot grasp. In this work, we develop models based on a pre-trained convolutional neural network for extracting sentiment, emotion and personality features for sarcasm detection. Such features, along with the network\u2019s baseline features, allow the proposed models to outperform the state of the art on benchmark datasets. We also address the often ignored generalizability issue of classifying data that have not been seen by the models at learning phase.", "creator": "LaTeX with hyperref package"}}}