{"id": "1610.09543", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Oct-2016", "title": "FEAST: An Automated Feature Selection Framework for Compilation Tasks", "abstract": "The success of the application of machine-learning techniques to compilation tasks can be largely attributed to the recent development and advancement of program characterization, a process that numerically or structurally quantifies a target program. While great achievements have been made in identifying key features to characterize programs, choosing a correct set of features for a specific compiler task remains an ad hoc procedure. In order to guarantee a comprehensive coverage of features, compiler engineers usually need to select excessive number of features. This, unfortunately, would potentially lead to a selection of multiple similar features, which in turn could create a new problem of bias that emphasizes certain aspects of a program's characteristics, hence reducing the accuracy and performance of the target compiler task. In this paper, we propose FEAture Selection for compilation Tasks (FEAST), an efficient and automated framework for determining the most relevant and representative features from a feature pool. Specifically, FEAST utilizes widely used statistics and machine-learning tools, including LASSO, sequential forward and backward selection, for automatic feature selection, and can in general be applied to any numerical feature set. This paper further proposes an automated approach to compiler parameter assignment for assessing the performance of FEAST. Intensive experimental results demonstrate that, under the compiler parameter assignment task, FEAST can achieve comparable results with about 18% of features that are automatically selected from the entire feature pool. We also inspect these selected features and discuss their roles in program execution.", "histories": [["v1", "Sat, 29 Oct 2016 17:10:15 GMT  (190kb)", "http://arxiv.org/abs/1610.09543v1", null]], "reviews": [], "SUBJECTS": "cs.PL cs.LG cs.SE", "authors": ["pai-shun ting", "chun-chen tu", "pin-yu chen", "ya-yun lo", "shin-ming cheng"], "accepted": false, "id": "1610.09543"}, "pdf": {"name": "1610.09543.pdf", "metadata": {"source": "CRF", "title": "FEAST: An Automated Feature Selection Framework for Compilation Tasks", "authors": ["Pai-Shun Ting", "Pin-Yu Chen", "Shin-Ming Cheng"], "emails": ["paishun@umich.edu", "timtu@umich.edu", "pin-yu.chen@ibm.com", "ylo@adobe.com", "smcheng@mail.ntust.edu.tw"], "sections": [{"heading": null, "text": "This year is the highest in the history of the country."}, {"heading": "II. FEAST AND COMPILER PARAMETER ASSIGNMENT", "text": "This section describes the mechanisms of FEAST and introduces the proposed method for assigning compiler parameters."}, {"heading": "A. FEAST", "text": "In view of the K-training programs and a series of p-numerical features, FEAST assumes a linear model for the resulting performance and characteristic values: y = X\u03b2 + \u03b201 (1), where y-RK \u00b7 1 is the power vector of the composed programs, the i-th entry of which denotes the performance of the i-th program (measured in some predefined parameters) in the set of the total K-training programs. X-RK \u00b7 p is a matrix whose (i, j) -th entry denotes the value of the j-th extracted feature of the i-th program. \u03b2-Rp \u00d7 1 and \u03b20-R are the coefficients describing the linear relationship between the features and the resulting performance. 1 is a K-1 vector with its elements, which are all 1s. FEAST uses three widely used feature selection methods, namely LASSO, sequential forward selection (SFS) and all reverse sequences (SM), whereby all of the features are most influential."}, {"heading": "B. Compiler Parameter Assignment Algorithms", "text": "In this section, the proposed method for compiler parameter assignment algorithm and the application of FEAST to this task is discussed in detail. In view of a compiler with many parameters to be specified, finding an optimal mapping of parameters that can best compile a target program is an annoying problem. This work proposes a machine learning algorithm that automatically equips target programs with \"good\" parameters based on the known optimal mapping of programs to the training programs. The proposed method works in two schemes: active training scheme and passive training scheme (see Fig. 1). In the active training scheme, users can actively acquire the optimal compilation parameters for a subset of programs, while in the passive training scheme, the user as prior knowledge is given a number of programs whose optimal compiler parameters are known. A practical example of an active training scheme is that has very limited parameters for a subset of programs, while in the passive training scheme, the user is given a set of programs whose optimal compiler parameters are very limited, and has a very limited knowledge of one of the previous companies, and has very limited one of them."}, {"heading": "III. PERFORMANCE EVALUATION OF COMPLIER PARAMETER ASSIGNMENT", "text": "We test our implementations with the PolyBench [5] benchmark series, which consists of n = 30 programs. The programs are characterized with p = 56 static features from the cTuning Compiler Collection [1]. For the two proposed training schemes, K-trained programs are used for feature selection and assignment of compiler parameters, and for each feature selection method (LASSO, SFS, SBS) we select the M = 10 most relevant features."}, {"heading": "A. Performance Comparison of the Active and Passive Training Schemes", "text": "The minimum execution time refers to the optimal performance over 192 possible combinations of compiler parameters of each program. We also show the results in case no tunable compiler parameters are enabled. In addition, to validate the benefits of FEAST, we also calculate the execution time using all features, i.e., the case in which FEAST is not removable because its execution time does not depend on the number K of training programs (LASSO, SFS and SBS), calculating the execution time using all features, i.e., the case in which FEAST is disqualified. For the three execution methods introduced in Sec. II-A (LASSO, SFS and SFS), we select the top M = 10 important features and use these selected features to calculate program similarity and assign compiler parameters."}, {"heading": "200 400 600 800 1000", "text": "In order to gain more insight into the performance of active and passive training programs, we compare the execution time of LASSO and SFS in Fig. 3. Comparison of SBS is omitted because SBS is mathematically inefficient in practice, especially with high-dimensional data. Fig. 3 observes that the average execution time of active training programs is smaller than that of passive training programs, because we can select representative training programs for optimization for active training programs. These results suggest that execution time can be further reduced if we are free to select K-representative programs from clustering as training samples for assigning compiler parameters."}, {"heading": "B. Overall Execution Time Comparison", "text": "In this section, we look at the total execution time, including the time required by the proposed algorithms, as well as the execution time of each untrained program. To this end, we introduce a parameter Nexec, the number of executions per program. The motivation behind the introduction of Nexec is as follows: In programs such as matrix operations, users can run these core programs multiple times (i.e. Nexec times). Therefore, as the detailed analysis in this section shows, the amount of time introduced by the proposed algorithms can be compensated with the increase in Nexec, since the time spent on optimizing the training programs accounts for a relatively small part of the total execution costs with large Nexec. Therefore, the time reduction (TR) can be calculated using the following formula: TR = Nexec \u00b7 Tnull \u2212 Tauto \u2212 TKersch\u00f6pfende, where Nexec \u2212 TKersch\u00f6pfende represents the number of executions for each program specifies zero total time with each program being executed."}, {"heading": "C. Features Selected by FEAST", "text": "In order to examine the most important features that affect the execution time of the compiler, we inspect the selected features of FEAST. Table II lists the top 10 selected features using various feature selection methods integrated in FEAST. The features are selected using a triple cross-validation method to reverse the optimal execution time of all 30 programs in terms of their static program features. Based on the features selected, we can categorize the selected features into three groups: 1) control flow diagram (CFG), 2) assignments / operations, and 3) Phi-nodes. CFG features describe the control flow of a program that can be largely influenced by statement branches, e.g. \"if-else,\" \"if- if,\" and \"for loop statements. The selected CFG features are reasonable, as in our program test set, because the loop part of the command flow is therefore unaffected by the control flow of the program."}, {"heading": "IV. RELATED WORK", "text": "In fact, most people who are able to survive themselves, to survive themselves, and to survive themselves, are able to survive themselves, \"he said in an interview with The New York Times,\" I don't think we will be able to change the world. \""}, {"heading": "V. CONCLUSIONS AND FUTURE WORK", "text": "In this thesis, we propose FEAST, an automated framework for feature selection in compiler tasks, which includes well-known methods for feature selection such as LASSO, sequential forward and backward selection. We demonstrate the feasibility and applicability of FEAST by testing it on a proposed method for the task of assigning compiler parameters. Experimental results show that the three feature selection methods integrated in FEAST can select a representative small subset of static features that, when used in the task of assigning compiler parameters, can achieve uncompromising performance. We also validate the effectiveness of the proposed methods by experimentally demonstrating a significant shortening of the execution time of our method in a practical scenario in which each program must be executed several times. Finally, we discussed the roles of the features selected by FEAST, which are deep insights into AST's two-way summarizing procedures:"}], "references": [{"title": "Regularization and variable selection via the elastic net", "author": ["H. Zou", "T. Hastie"], "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology), vol. 67, no. 2, pp. 301\u2013320, 2005.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2005}, {"title": "Using machine learning to focus iterative optimization", "author": ["F. Agakov", "E. Bonilla", "J. Cavazos", "B. Franke", "G. Fursin", "M.F. O\u2019Boyle", "J. Thomson", "M. Toussaint", "C.K. Williams"], "venue": "Proceedings of the International Symposium on Code Generation and Optimization. IEEE Computer Society, 2006, pp. 295\u2013305.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2006}, {"title": "Feature selection for classification", "author": ["M. Dash", "H. Liu"], "venue": "Intelligent data analysis, vol. 1, no. 1, pp. 131\u2013156, 1997.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1997}, {"title": "The road not taken: Estimating path execution frequency statically", "author": ["R.P. Buse", "W. Weimer"], "venue": "Proceedings of the 31st International Conference on Software Engineering. IEEE Computer Society, 2009, pp. 144\u2013154.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2009}, {"title": "Automatic construction of inlining heuristics using machine learning", "author": ["S. Kulkarni", "J. Cavazos", "C. Wimmer", "D. Simon"], "venue": "Code Generation and Optimization (CGO), 2013 IEEE/ACM International Symposium on. IEEE, 2013, pp. 1\u201312.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "Mapping parallelism to multi-cores: a machine learning based approach", "author": ["Z. Wang", "M.F. O\u2019Boyle"], "venue": "ACM Sigplan notices, vol. 44, no. 4. ACM, 2009, pp. 75\u201384.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2009}, {"title": "Approximate graph clustering for program characterization", "author": ["J. Demme", "S. Sethumadhavan"], "venue": "ACM Transactions on Architecture and Code Optimization (TACO), vol. 8, no. 4, p. 21, 2012.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2012}, {"title": "Predicting unroll factors using supervised classification", "author": ["M. Stephenson", "S. Amarasinghe"], "venue": "International symposium on code generation and optimization. IEEE, 2005, pp. 123\u2013134.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2005}, {"title": "Rapidly selecting good compiler optimizations using performance counters", "author": ["J. Cavazos", "G. Fursin", "F. Agakov", "E. Bonilla", "M.F. O\u2019Boyle", "O. Temam"], "venue": "International Symposium on Code Generation and Optimization (CGO\u201907). IEEE, 2007, pp. 185\u2013197.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2007}, {"title": "Using graph-based program characterization for predictive modeling", "author": ["E. Park", "J. Cavazos", "M.A. Alvarez"], "venue": "Proceedings of the Tenth International Symposium on Code Generation and Optimization. ACM, 2012, pp. 196\u2013206.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2012}], "referenceMentions": [{"referenceID": 1, "context": "ft1 # basic blocks in the method ft29 # basic blocks with phi nodes in the interval [0, 3] ft2 # basic blocks with a single successor ft30 # basic blocks with more then 3 phi nodes", "startOffset": 84, "endOffset": 90}, {"referenceID": 0, "context": "FEAST incorporates into its framework a variety of feature selection methods, including the well-known LASSO [2], sequential forward and backward selection.", "startOffset": 109, "endOffset": 112}, {"referenceID": 1, "context": "As many other compiler tasks, in practice, expert intervention is frequently triggered and heuristics based on expertise and experience are adopted as a general guideline for tuning parameters [3].", "startOffset": 193, "endOffset": 196}, {"referenceID": 0, "context": "Specifically, the elastic net approach for LASSO adopted in FEAST selects features by first solving optimization problem [2]:", "startOffset": 121, "endOffset": 124}, {"referenceID": 2, "context": "We omit algorithmic descriptions of SFS and SBS, and refer interested readers to [4] for implementation details.", "startOffset": 81, "endOffset": 84}, {"referenceID": 3, "context": "For example, Buse and Weimer use static features to identify \u201dhot paths\u201d (executional paths that are most frequently invoked) of a target program by applying logistic regression [6] without ever profiling the program, Kulkarni et al.", "startOffset": 178, "endOffset": 181}, {"referenceID": 4, "context": "build an evolving neural-network model that uses static features to help guide the inlining heuristics in compilation process [7], and Wang and O\u2019Boyle exploit the use of artificial neural networks (ANNs) as well as support vector machine (SVM) for automatic code parallelization on multicore systems [8], among others.", "startOffset": 126, "endOffset": 129}, {"referenceID": 5, "context": "build an evolving neural-network model that uses static features to help guide the inlining heuristics in compilation process [7], and Wang and O\u2019Boyle exploit the use of artificial neural networks (ANNs) as well as support vector machine (SVM) for automatic code parallelization on multicore systems [8], among others.", "startOffset": 301, "endOffset": 304}, {"referenceID": 6, "context": "For example, it is shown in [9] that, for compiler tasks that cannot afford the time cost for procurement of dynamic features, carefully designed graph-based static features can achieve accuracy and performance comparable to dynamic features in some applications, regardless the fact that it is prevailingly believed dynamic features are preferred due to insightful information they provide.", "startOffset": 28, "endOffset": 31}, {"referenceID": 9, "context": "[12].", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "Stephenson and Amarasinghe demonstrate the potential of machine learning on automatic compiler parameter tuning by applying ANNs and SVM to predict a suitable loop-unrolling factor for a target program [10].", "startOffset": 202, "endOffset": 206}, {"referenceID": 1, "context": "propose a computeraided compiler parameter tuning method by identifying similar programs using static features [3], where certain level of expert intervention is still required.", "startOffset": 111, "endOffset": 114}, {"referenceID": 8, "context": "characterize programs with dynamic features, and use logistic regression, a classic example of conventional machine-learning algorithm, to predict good compiler parameter assignment [11].", "startOffset": 182, "endOffset": 186}, {"referenceID": 8, "context": "While providing state-of-the-art performance, [11] requires dynamic features, which can be expensive to acquire.", "startOffset": 46, "endOffset": 50}, {"referenceID": 9, "context": "In [12], graphbased features are used along with SVM for performance prediction given a compilation sequence.", "startOffset": 3, "endOffset": 7}], "year": 2016, "abstractText": "Modern machine-learning techniques greatly reduce the efforts required to conduct high-quality program compilation, which, without the aid of machine learning, would otherwise heavily rely on human manipulation as well as expert intervention. The success of the application of machine-learning techniques to compilation tasks can be largely attributed to the recent development and advancement of program characterization, a process that numerically or structurally quantifies a target program. While great achievements have been made in identifying key features to characterize programs, choosing a correct set of features for a specific compiler task remains an ad hoc procedure. In order to guarantee a comprehensive coverage of features, compiler engineers usually need to select excessive number of features. This, unfortunately, would potentially lead to a selection of multiple similar features, which in turn could create a new problem of bias that emphasizes certain aspects of a program\u2019s characteristics, hence reducing the accuracy and performance of the target compiler task. In this paper, we propose FEAture Selection for compilation Tasks (FEAST), an efficient and automated framework for determining the most relevant and representative features from a feature pool. Specifically, FEAST utilizes widely used statistics and machine-learning tools, including LASSO, sequential forward and backward selection, for automatic feature selection, and can in general be applied to any numerical feature set. This paper further proposes an automated approach to compiler parameter assignment for assessing the performance of FEAST. Intensive experimental results demonstrate that, under the compiler parameter assignment task, FEAST can achieve comparable results with about 18% of features that are automatically selected from the entire feature pool. We also inspect these selected features and discuss their roles in program execution.", "creator": "LaTeX with hyperref package"}}}