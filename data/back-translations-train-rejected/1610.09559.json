{"id": "1610.09559", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Oct-2016", "title": "Fair Algorithms for Infinite and Contextual Bandits", "abstract": "Motivated by concerns that automated decision-making procedures can unintentionally lead to discriminatory behavior, we study a technical definition of fairness modeled after John Rawls' notion of \"fair equality of opportunity\". In the context of a simple model of online decision making, we give an algorithm that satisfies this fairness constraint, while still being able to learn at a rate that is comparable to (but necessarily worse than) that of the best algorithms absent a fairness constraint. We prove a regret bound for fair algorithms in the linear contextual bandit framework that is a significant improvement over our technical companion paper [16], which gives black-box reductions in a more general setting. We analyze our algorithms both theoretically and experimentally. Finally, we introduce the notion of a \"discrimination index\", and show that standard algorithms for our problem exhibit structured discriminatory behavior, whereas the \"fair\" algorithms we develop do not.", "histories": [["v1", "Sat, 29 Oct 2016 18:46:11 GMT  (819kb,D)", "http://arxiv.org/abs/1610.09559v1", null], ["v2", "Tue, 1 Nov 2016 12:14:54 GMT  (819kb,D)", "http://arxiv.org/abs/1610.09559v2", null], ["v3", "Fri, 14 Apr 2017 19:10:14 GMT  (4204kb,D)", "http://arxiv.org/abs/1610.09559v3", null], ["v4", "Thu, 29 Jun 2017 15:46:55 GMT  (1035kb,D)", "http://arxiv.org/abs/1610.09559v4", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["matthew joseph", "michael kearns", "jamie morgenstern", "seth neel", "aaron roth"], "accepted": false, "id": "1610.09559"}, "pdf": {"name": "1610.09559.pdf", "metadata": {"source": "CRF", "title": "Rawlsian Fairness for Machine Learning", "authors": ["Matthew Joseph", "Michael Kearns", "Jamie Morgenstern", "Aaron Roth"], "emails": ["aaroth@cis.upenn.edu.", "sethneel@wharton.upenn.edu."], "sections": [{"heading": null, "text": "majos, mkearns, jamiemor, aaroth @ cis.upenn.edu. Faculty of Computer Science and Information Sciences, University of Pennsylvania. \u2020 sethneel @ wharton.upenn.edu. Faculty of Statistics, The Wharton School, University of Pennsylvania. Xiv: 161 0.09 559v 1 [cs.L G] 29 October 201 613"}, {"heading": "1 Introduction 3", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2 Definitions: Learning and Fairness 5", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3 Provably Fair and No-Regret Algorithms 6", "text": "3.1 IntervalChaining.............................................................................................................."}, {"heading": "4 Experimental Results 12", "text": "4.1 Empirical costs of fairness: regrets.........................................................................................................................................................................................................................................................................."}, {"heading": "5 Supplement 21", "text": "5.1 Complete description of interval concatenation......................................................................................................................................................................................................................................................"}, {"heading": "1 Introduction", "text": "In fact, most people who are able to survive on their own are not able to survive on their own."}, {"heading": "2 Definitions: Learning and Fairness", "text": "In this section, we describe the formal model that we consider differently for each group. An instance of problem is defined by a domain from which the prominent characteristics of each individual are drawn, which we consider X = Rd, and a series of k different groups, which are defined by i [1,.., k]. Each group j is equipped with an unknown function fi: X \u2192 R mapping the characteristics of an individual from group i to their true \"quality.\" In this paper, these functions have a linear form: that is, there is an unknown vector of coefficients \u03b2i. R such that fi (x) = \u03b2i \u00b7 x.In rounds t = 1,., T, an individual from each of the k groups arrives, and the salient characteristics of each are observed by the learning algorithms. In this paper, we assume that the characteristics of the individual from group i, which comes at the time, are independent of a distribution Di, which may be different for each group."}, {"heading": "3 Provably Fair and No-Regret Algorithms", "text": "A direct consequence of our definition of fairness, therefore, is that the optimal policy, which deterministically plays the highest quality of the individual in each round, may be more unfair than unfair rules of the game. This indicates that the goal of fairness is not fundamentally at odds with the goal of accuracy, but strictly aims at accuracy (i.e. minimizes regret). A characteristic feature of this class of algorithms is that they are balanced (the selection of individuals from groups over which the algorithm has a high degree of uncertainty in order to learn more about this group) and instead base the highest esteemed quality on the observations of the algorithm. As the algorithm gradually learns the true parameters, the exploratory steps become increasingly infrequent until the algorithm essentially plays optimally."}, {"heading": "3.1 IntervalChaining", "text": "We present IntervalChaining, a demonstrably fair algorithm with strong performance guarantees. In IntervalChaining, we are chosen regardless of the probability that it is an exploration round, in which the algorithm selects uniformly at random between all individuals in order to learn better estimates of k-linear models. All other rounds are exploitation rounds, in which the algorithm uses these estimates to select high-quality individuals, to the extent that it is subject to fairness limitations (the algorithm also improves its model estimates from the data collected in these rounds). In exploitation rounds, intervalChaining methods are used by OLS estimators, in which each group calculates the estimated qualities, i = \u03b2 t, i \u00b7 xt, i xt, i for each xt, i. The algorithms also calculate reliability intervals, i, around these assessments, so that i:"}, {"heading": "3.2 RidgeFair", "text": "In this section, we define the validity intervals harder than for the simple OLS estimator, and rely on similar methods. (We assume that validation is no longer an unbiased estimate.) We assume that we make an unbiased estimate for the likely quality of each group. (We assume that an unbiased estimate means for the true validation. (We assume that an unbiased estimate is no longer possible for the true validation.) We assume that an unbiased estimate for the actual estimate of the quality of each group means an unbiased estimate for the true validation. (We assume that the actual estimate is more difficult than for the simple OLS estimator.) We assume that an unbiased estimate for the estimated quality of each group, but an unbiased estimate does not mean an unbiased estimate for the true validation."}, {"heading": "4 Experimental Results", "text": "In this section, we offer an empirical evaluation of intervalChaining. We recall that the confidence intervals for RidgeFair are more universal when we specialize in the case of normal noise, they are larger than the confidence intervals of intervalChaining, which are explicitly derived using normality. As our experiments show normal noise, it follows that intervalChaining performs empirically reliably better despite RidgeFair's superior theoretical regret. Therefore, we focus exclusively on intervalChaining in simulations. Before we turn to a more systematic series of experiments, we first give an illustration of the effects and variability of the concatenation over the course of a single pass of intervalChaining. In Figure 4, we visualize the concatenation behavior of intervalChaining through a sequence of T = 106 laps on a protocol scale of the x-axis that measures t. There are groups of 5, each of which are represented by a different color for each of the confidence and the confidence with each of the others."}, {"heading": "4.1 Empirical Cost of Fairness: Regret", "text": "This year, it has come to the point that it has never come as far as it has this year."}, {"heading": "4.2 Empirical Unfairness of Standard Algorithms", "text": "It is not obvious that these algorithms actually exhibit discriminatory behavior. In fact, one might suspect that the damage caused by those rounds in which TopInterval selects suboptimal discrimination spreads evenly to all groups and all members of each group, because there is no deliberate discrimination built into the algorithm. In this section, we show empirically that this is not the case: In particular, the cost of incorrect decisions made by TopInterval can be disproportionately distributed among certain groups and structured subgroups within a particular group, which we call structural injustice. To talk about structural injustice, we present some notations. We will be interested to examine the costs of these rounds, where the algorithms do not select the most qualified individuals."}, {"heading": "Acknowledgements", "text": "We thank Glen Weyl for pointing out the link between our definition of fairness and the ideas of John Rawls and Adel Boyarsky for his help in researching the legal interpretations of different effects of discrimination."}, {"heading": "5 Supplement", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Complete Description of Interval Chaining", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.2 Proof of the Fairness of Interval Chaining", "text": "The proof of fairness in Theorem 1 (\u03b2t, i \u00b7 xt, i \u00b7 t) is usually not provided. (...) The proof of fairness in Theorem 1 (...) is not provided. (...) The proof of fairness in Theorem 1 (...) is provided. (...) The proof of fairness in Theorem 1 (...) is provided. (...) The proof of fairness in Theorem 1 (...) is provided. (...) The proof of fairness in Theorem 1 (...) is provided. (...) The proof of fairness in Theorem 1 (...) is provided. (...) The proof of fairness in Theorem 3 (...) is provided. (...) The algorithm fulfils the fairness condition in this round. (...) Is a round in which the OLS estimates are used. (...) With the standard properties of the OLS estimators (see e.g. Kuan, [... 3.7] (theorem)."}], "references": [{"title": "Improved algorithms for linear stochastic bandits", "author": ["Yasin Abbasi-yadkori", "D\u00e1vid P\u00e1l", "Csaba Szepesv\u00e1ri"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2011}, {"title": "Taming the monster: A fast and simple algorithm for contextual bandits", "author": ["Alekh Agarwal", "Daniel J. Hsu", "Satyen Kale", "John Langford", "Lihong Li", "Robert E. Schapire"], "venue": "In Proceedings of the 31th International Conference on Machine Learning,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2014}, {"title": "URL https://www.propublica.org/article/ machine-bias-risk-assessments-in-criminal-sentencing", "author": ["Julia Angwin", "Jeff Larson", "Surya Mattu", "Lauren Kirchner"], "venue": "Machine bias. Propublica,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2016}, {"title": "Big data\u2019s disparate impact", "author": ["Solon Barocas", "Andrew D. Selbst"], "venue": "California Law Review,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2016}, {"title": "The new science of sentencing", "author": ["Anna Maria Barry-Jester", "Ben Casselman", "Dana Goldstein"], "venue": "The Marshall Project, August", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "Regret analysis of stochastic and nonstochastic multi-armed bandit problems", "author": ["S\u00e9bastien Bubeck", "Nicolo Cesa-Bianchi"], "venue": "Machine Learning,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2012}, {"title": "Artificial intolerance. MIT Technology Review, March 28 2016", "author": ["Nanette Byrnes"], "venue": "URL https: //www.technologyreview.com/s/600996/artificial-intolerance/", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2016}, {"title": "Three naive bayes approaches for discrimination-free classification", "author": ["Toon Calders", "Sicco Verwer"], "venue": "Data Mining and Knowledge Discovery,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2010}, {"title": "Contextual bandits with linear payoff functions", "author": ["Wei Chu", "Lihong Li", "Lev Reyzin", "Robert E. Schapire"], "venue": "In Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2011}, {"title": "Regulating by robot: Administrative decision-making in the machine-learning era", "author": ["Cary Coglianese", "David Lehr"], "venue": "Georgetown Law Journal,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2016}, {"title": "Fairness through awareness", "author": ["Cynthia Dwork", "Moritz Hardt", "Toniann Pitassi", "Omer Reingold", "Richard Zemel"], "venue": "In Proceedings of the 3rd Innovations in Theoretical Computer Science Conference,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2012}, {"title": "Certifying and removing disparate impact", "author": ["Michael Feldman", "Sorelle A. Friedler", "John Moeller", "Carlos Scheidegger", "Suresh Venkatasubramanian"], "venue": "In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2015}, {"title": "A confidence-based approach for balancing fairness and accuracy", "author": ["Benjamin Fish", "Jeremy Kun", "\u00c1d\u00e1m D Lelkes"], "venue": "SIAM International Symposium on Data Mining,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2016}, {"title": "Equality of opportunity in supervised learning", "author": ["Moritz Hardt", "Eric Price", "Nathan Srebro"], "venue": "arXiv preprint arXiv:1610.02413,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2016}, {"title": "Fairness in learning: Classic and contextual bandits", "author": ["Matthew Joseph", "Michael Kearns", "Jamie Morgenstern", "Aaron Roth"], "venue": "arXiv preprint arXiv:1605.07139,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2016}, {"title": "Navigating the \u201ctrackless ocean\u201d: Fairness in big data research and decision making", "author": ["FTC Commisioner Julie Brill"], "venue": "Keynote Address at the Columbia", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2015}, {"title": "Fairness-aware learning through regularization approach", "author": ["Toshihiro Kamishima", "Shotaro Akaho", "Jun Sakuma"], "venue": "In Data Mining Workshops (ICDMW),", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2011}, {"title": "Inherent trade-offs in the fair determination of risk scores", "author": ["Jon Kleinberg", "Sendhil Mullainathan", "Manish Raghavan"], "venue": "arXiv preprint arXiv:1609.05807,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2016}, {"title": "Classical least squares theory. Available on: http://homepage", "author": ["Chung-Ming Kuan"], "venue": "ntu. edu. tw/ \u0303 ckuan/pdf/et01/et Ch3", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2004}, {"title": "Asymptotically efficient adaptive allocation rules", "author": ["Tze Leung Lai", "Herbert Robbins"], "venue": "Advances in applied mathematics,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1985}, {"title": "A contextual-bandit approach to personalized news article recommendation", "author": ["Lihong Li", "Wei Chu", "John Langford", "Robert E Schapire"], "venue": "In Proceedings of the 19th international conference on World wide web,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2010}, {"title": "Contextual multi-armed bandits", "author": ["Tyler Lu", "D\u00e1vid P\u00e1l", "Martin P\u00e1l"], "venue": "In AISTATS, pages 485\u2013492,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2010}, {"title": "k-nn as an implementation of situation testing for discrimination discovery and prevention", "author": ["Binh Thanh Luong", "Salvatore Ruggieri", "Franco Turini"], "venue": "In Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2011}, {"title": "Can an algorithm hire better than a human", "author": ["Clair C Miller"], "venue": "The New York Times, June", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2015}, {"title": "Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy", "author": ["Cathy O\u2019Neil"], "venue": null, "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2016}, {"title": "A Theory of Justice", "author": ["John Rawls"], "venue": "Harvard university press,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2009}, {"title": "Some aspects of the sequential design of experiments", "author": ["Herbert Robbins"], "venue": "Bulletin of the American Mathematical Society,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 1952}, {"title": "A sequential decision problem with a finite memory", "author": ["Herbert Robbins"], "venue": "Proceedings of the National Academy of Sciences,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 1956}, {"title": "Predictive policing using machine learning to detect patterns of crime", "author": ["Cynthia Rudin"], "venue": "URL http://www.wired.com/insights/2013/08/ predictive-policing-using-machine-learning-to-detect-\\patterns-of-crime/. Retrieved 4/28/2016", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2013}], "referenceMentions": [{"referenceID": 14, "context": "We prove a regret bound for fair algorithms in the linear contextual bandit framework that is a significant improvement over our technical companion paper [16], which gives black-box reductions in a more general setting.", "startOffset": 155, "endOffset": 159}, {"referenceID": 23, "context": "Automated techniques from statistics and machine learning are increasingly being used to make important decisions that directly affect the lives of individuals, including hiring [25], lending [8], policing [30], and criminal sentencing [6].", "startOffset": 178, "endOffset": 182}, {"referenceID": 6, "context": "Automated techniques from statistics and machine learning are increasingly being used to make important decisions that directly affect the lives of individuals, including hiring [25], lending [8], policing [30], and criminal sentencing [6].", "startOffset": 192, "endOffset": 195}, {"referenceID": 28, "context": "Automated techniques from statistics and machine learning are increasingly being used to make important decisions that directly affect the lives of individuals, including hiring [25], lending [8], policing [30], and criminal sentencing [6].", "startOffset": 206, "endOffset": 210}, {"referenceID": 4, "context": "Automated techniques from statistics and machine learning are increasingly being used to make important decisions that directly affect the lives of individuals, including hiring [25], lending [8], policing [30], and criminal sentencing [6].", "startOffset": 236, "endOffset": 239}, {"referenceID": 9, "context": "These high-stakes uses of machine learning have led to increasing concern in law and policy circles about the potential for (often opaque) machine learning techniques to be discriminatory or unfair [11, 5, 26].", "startOffset": 198, "endOffset": 209}, {"referenceID": 3, "context": "These high-stakes uses of machine learning have led to increasing concern in law and policy circles about the potential for (often opaque) machine learning techniques to be discriminatory or unfair [11, 5, 26].", "startOffset": 198, "endOffset": 209}, {"referenceID": 24, "context": "These high-stakes uses of machine learning have led to increasing concern in law and policy circles about the potential for (often opaque) machine learning techniques to be discriminatory or unfair [11, 5, 26].", "startOffset": 198, "endOffset": 209}, {"referenceID": 2, "context": "For example, a 2016 ProPublica study [4] of the COMPAS Recidivism Algorithm (used to inform criminal sentencing decisions by attempting to predict recidivism) found that the algorithm was significantly more likely to incorrectly label black defendants as recidivism risks compared to white defendants, despite similar overall rates of prediction accuracy between groups.", "startOffset": 37, "endOffset": 40}, {"referenceID": 7, "context": "[9, 24, 18, 13, 14] for a sample of papers studying such definitions).", "startOffset": 0, "endOffset": 19}, {"referenceID": 22, "context": "[9, 24, 18, 13, 14] for a sample of papers studying such definitions).", "startOffset": 0, "endOffset": 19}, {"referenceID": 16, "context": "[9, 24, 18, 13, 14] for a sample of papers studying such definitions).", "startOffset": 0, "endOffset": 19}, {"referenceID": 11, "context": "[9, 24, 18, 13, 14] for a sample of papers studying such definitions).", "startOffset": 0, "endOffset": 19}, {"referenceID": 12, "context": "[9, 24, 18, 13, 14] for a sample of papers studying such definitions).", "startOffset": 0, "endOffset": 19}, {"referenceID": 10, "context": "[12], these group-level definitions often fail at both fairness and accurate learning.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[12] advocate that technical definitions of fairness should focus on individual fairness, rather than fairness at the group level.", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "\u201d [27]", "startOffset": 2, "endOffset": 6}, {"referenceID": 17, "context": "For instance, Title VII of the 1964 Civil Rights Act prohibits \u201cdisparate impact discrimination\u201d \u2014 The company that sells COMPAS has raised methodological concerns about the ProPublica study, but it is apparent that not only are some of the objections raised valid in the case of COMPAS, they are more generally unavoidable [19].", "startOffset": 324, "endOffset": 328}, {"referenceID": 15, "context": "In a recent speech FTC Commissioner Julie Brill [17] observed, \u201c.", "startOffset": 48, "endOffset": 52}, {"referenceID": 13, "context": "What can be done to make sure these products and services\u2013and the companies that use them treat consumers fairly and ethically?\u201d An interesting recent paper [15] gives a different formalization of the idea of \u201cequality of opportunity\u201d in a classification setting.", "startOffset": 157, "endOffset": 161}, {"referenceID": 13, "context": "The definition suggested by [15] is a \u201cgroup fairness\u201d constraint on the average behaviour of the algorithm over all individuals of the same quality.", "startOffset": 28, "endOffset": 32}, {"referenceID": 26, "context": "This setting is a generalization of the classical \u201cmulti-armed bandit\u201d problem [28, 29, 21] called the contextual bandit problem [23, 10].", "startOffset": 79, "endOffset": 91}, {"referenceID": 27, "context": "This setting is a generalization of the classical \u201cmulti-armed bandit\u201d problem [28, 29, 21] called the contextual bandit problem [23, 10].", "startOffset": 79, "endOffset": 91}, {"referenceID": 19, "context": "This setting is a generalization of the classical \u201cmulti-armed bandit\u201d problem [28, 29, 21] called the contextual bandit problem [23, 10].", "startOffset": 79, "endOffset": 91}, {"referenceID": 21, "context": "This setting is a generalization of the classical \u201cmulti-armed bandit\u201d problem [28, 29, 21] called the contextual bandit problem [23, 10].", "startOffset": 129, "endOffset": 137}, {"referenceID": 8, "context": "This setting is a generalization of the classical \u201cmulti-armed bandit\u201d problem [28, 29, 21] called the contextual bandit problem [23, 10].", "startOffset": 129, "endOffset": 137}, {"referenceID": 14, "context": "In our technical companion paper [16], we generalize the framework presented here beyond linear functions, and relax several other simplifying assumptions made here (at the cost of less tight quantitative bounds).", "startOffset": 33, "endOffset": 37}, {"referenceID": 27, "context": "When designing fair algorithms, then, a natural starting place is the class of well-studied bandit algorithms that do not obey a fairness condition, but instead purely aim for accuracy [29].", "startOffset": 185, "endOffset": 189}, {"referenceID": 14, "context": "For RidgeFair, a sharper technical analysis yields a regret bound of R(T ) = \u00d5(d \u221a k3T ) In our companion paper [16] we prove a lower bound of R(T ) = \u03a9(k3) for fair algorithms in the multi-armed bandit setting (i.", "startOffset": 112, "endOffset": 116}, {"referenceID": 5, "context": "A lower bound of R(T ) = \u03a9( \u221a T ) is also known for this setting, even absent a fairness constraint [7].", "startOffset": 100, "endOffset": 103}, {"referenceID": 1, "context": "In [3] an R(T ) = \u03a9( \u221a Td) lower bound is proven for linear contextual bandit algorithms absent a fairness constraint, along with an algorithm enjoying a matching \u00d5( \u221a Td) upper bound.", "startOffset": 3, "endOffset": 6}, {"referenceID": 14, "context": "Finally, we note that this is a significant improvement over the R(T ) = \u00d5(T 4/5k6/5d3/5) bound for the linear contextual bandit setting given in our companion paper [16], which is derived as a corollary of a general black box reduction rather than with a specialized analysis.", "startOffset": 166, "endOffset": 170}, {"referenceID": 0, "context": "Consequently valid confidence intervals are harder to derive than for the simple OLS estimator, and rely on martingale techniques borrowed from [2], which derives similar bounds absent a fairness constraint.", "startOffset": 144, "endOffset": 147}, {"referenceID": 0, "context": "Theorem 3 (From [2]).", "startOffset": 16, "endOffset": 19}, {"referenceID": 0, "context": "[2]: let V\u0304it = X T i Xi + \u03bbI, where Xi is the design matrix at time t corresponding to group i, \u03bb \u2265 1.", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "Then some matrix algebra from [2] shows: xt,i \u00b7 (\u03b2\u0302it \u2212 \u03b2i) = xt,iV\u0304 \u22121 it X T i \u03b7i \u2212 \u03bbxt,iV\u0304 \u22121 it \u03b2i, which using the above notation gives", "startOffset": 30, "endOffset": 33}, {"referenceID": 0, "context": "Finally, in the proof of Lemma 11 in [2] it is noted that:", "startOffset": 37, "endOffset": 40}, {"referenceID": 20, "context": "We note that our implementation of IntervalChaining does not include the random sampling component given in its formal presentation in the previous section, as we have found that this improves empirical performance over the TopInterval is a variant of the standard linear bandits algorithm \u201cLinUCB\u201d [22], simplified to take advantages of the assumptions in our model.", "startOffset": 299, "endOffset": 303}], "year": 2017, "abstractText": "Motivated by concerns that automated decision-making procedures can unintentionally lead to discriminatory behavior, we study a technical definition of fairness modeled after John Rawls\u2019 notion of \u201cfair equality of opportunity\u201d. In the context of a simple model of online decision making, we give an algorithm that satisfies this fairness constraint, while still being able to learn at a rate that is comparable to (but necessarily worse than) that of the best algorithms absent a fairness constraint. We prove a regret bound for fair algorithms in the linear contextual bandit framework that is a significant improvement over our technical companion paper [16], which gives black-box reductions in a more general setting. We analyze our algorithms both theoretically and experimentally. Finally, we introduce the notion of a \u201cdiscrimination index\u201d, and show that standard algorithms for our problem exhibit structured discriminatory behavior, whereas the \u201cfair\u201d algorithms we develop do not. \u2217majos, mkearns, jamiemor, aaroth@cis.upenn.edu. Department of Computer and Information Sciences, University of Pennsylvania. \u2020sethneel@wharton.upenn.edu. Department of Statistics, The Wharton School, University of Pennsylvania. 1 ar X iv :1 61 0. 09 55 9v 1 [ cs .L G ] 2 9 O ct 2 01 6", "creator": "LaTeX with hyperref package"}}}