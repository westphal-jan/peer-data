{"id": "1610.09882", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-Oct-2016", "title": "A Survey of Brain Inspired Technologies for Engineering", "abstract": "Cognitive engineering is a multi-disciplinary field and hence it is difficult to find a review article consolidating the leading developments in the field. The in-credible pace at which technology is advancing pushes the boundaries of what is achievable in cognitive engineering. There are also differing approaches to cognitive engineering brought about from the multi-disciplinary nature of the field and the vastness of possible applications. Thus research communities require more frequent reviews to keep up to date with the latest trends. In this paper we shall dis-cuss some of the approaches to cognitive engineering holistically to clarify the reasoning behind the different approaches and to highlight their strengths and weaknesses. We shall then show how developments from seemingly disjointed views could be integrated to achieve the same goal of creating cognitive machines. By reviewing the major contributions in the different fields and showing the potential for a combined approach, this work intends to assist the research community in devising more unified methods and techniques for developing cognitive machines.", "histories": [["v1", "Mon, 31 Oct 2016 11:58:29 GMT  (845kb,D)", "http://arxiv.org/abs/1610.09882v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.NE", "authors": ["jarryd son", "amit kumar mishra"], "accepted": false, "id": "1610.09882"}, "pdf": {"name": "1610.09882.pdf", "metadata": {"source": "CRF", "title": "A Survey of Brain Inspired Technologies for Engineering", "authors": ["Jarryd Son", "Amit Kumar Mishra"], "emails": ["jdsonza@gmail.com", "akmishra@ieee.org"], "sections": [{"heading": null, "text": "artificial intelligence, cognitive architecture, bio-inspired"}, {"heading": "1 Introduction", "text": "The functioning of the brain has fascinated researchers since the beginning of scientific endeavors, and the advent of computers has encouraged the emergence of exciting developments culminating in the development of the new discipline of artificial intelligence (AI). Within the realm of AI, there was a divided opinion about what is the best approach to creating cognitive machines [1]. This division is based primarily on how informationally Xiv: 161 0.09 882v 1 claims to be processed in the brain [2,3]. On the one hand, the symbolic approach and on the other, the sub-symbolic approach. Symbolic approaches such as cognitive architectures have a long history in AI and their developments are aimed at creating computer-based models that formalize the structure of the human brain [4]. Cognitive architectures such as Soar [5] and ACT-R [6] have been in development for many decades and have been successfully applied."}, {"heading": "2 Symbolic Approaches", "text": "Robotics is often cited as an area where AI and machine learning can be used, but many of the experiments focus on perception systems and ignore high-level cognitive skills. [8] Much of the early success in achieving these skills was based on the use of symbolic AI systems. AI pioneers Alan Newell and Herbert A. Simon formulated the physical symbolic system hypothesis that \"a physical symbolic system has the necessary and sufficient means to act intelligently.\" [1] Their work culminated in the creation of many impressive AI systems, including the creation of the cognitive architecture of Soar [5]. Soar is one of many cognitive architectures aimed at creating a formal, structured model of a cognitive system. [4] Figure 1 illustrates how Soar is composed and should clarify what a cognitive architecture entails. Formal structure does not only play an important role in Soar, but all cognitive characteristics must remain constant in a cognitive architecture4."}, {"heading": "Symbolic Long-Term Memory", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Body", "text": "These models are usually based on the hypothesis of a physical symbol, but there is a shift towards hybrid approaches such as CLARION [4] and Sigma [10] architecture.Cognitive architectures aim to use the knowledge contained in each of the different modules in a coherent and uniform manner to generate cognitive behaviour.The advantage of this approach is that it can be designed with specific characteristics that are understood by people, which is particularly important for cognitive abilities that are easier to understand on a symbolic level than on a symbolic level."}, {"heading": "3 Sub-symbolic Approaches", "text": "In fact, most of them will be able to move to another world in which they are able, in which they are able to move, in which they are able, and in which they are able to move."}, {"heading": "4 Hybrid Approaches", "text": "This year, it has come to the point that it has never been as far as this year."}, {"heading": "5 Neuromorphic Emulation", "text": "The Human Brain Project has a platform that aims to mimic the workings of the human brain. They provide an overview of neuromorphic technologies in [21] where they represent a breakdown of neuromorphic hardware, as shown in Figure 5.Simulating large-scale neural networks using Neumann architectures is inefficient and would require incredibly high levels of performance [22-24]. One of the primary bottlenecks to overcome is the inefficient movement of data between processors and memory in traditional von Neumann architectures. [23] Most notable are the work of the University of Manchester with its SpiNaker project [24], IBM with its TrueNorth architecture [25], Stanford University and its neuroarchitecture [22], where a multiple team from the University of Santa Monica uses 9 PCs to implement PCs."}, {"heading": "Router", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "System network-on-chip", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Inter-chip links", "text": "In fact, it is in such a way that most of them are able to show that they see themselves in a position to feel themselves in a position to move, and that they are able to move. In such a way that they are able to show that they are able to move, to feel themselves in a position to move, and that they are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move,"}, {"heading": "6 Conclusion", "text": "Much has changed over the years in the relatively short history of AI, owing to new scientific knowledge and rapid technological growth; symbolic AI systems that emerged early on have been stunningly inhibited by the excessive simplification of cognitive mechanisms [1]; in the opposite direction, the early abandonment of connectionist models has been reversed by technological advances that have made massive parallel computation possible [1]; a hybrid cognitive architecture that uses cutting-edge techniques from both approaches is a viable option for creating machines that are augmented by cognitive capabilities; primary attempts to develop hybrid approaches have not integrated the absolute best of both worlds; as Smolensky [11] mentions, it is not advisable for the two camps (symbolic and connecxionistic) to ignore each other, however significant developments in hybrid hybrid models have lagged behind in comparison in order to develop individual machines capable of completing a network."}], "references": [{"title": "Connectionist AI, symbolic AI, and the brain", "author": ["P. Smolensky"], "venue": "Artificial Intelligence Review, vol. 1, no. 2, pp. 95\u2013109, 1987. [Online]. Available: http://dx.doi.org/10.1007/BF00130011", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1987}, {"title": "The symbol grounding problem", "author": ["S. Harnad"], "venue": "Physica D: Nonlinear Phenomena, vol. 42, no. 1, pp. 335 \u2013 346, 1990.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1990}, {"title": "Cognitive architectures: Research issues and challenges", "author": ["P. Langley", "J.E. Laird", "S. Rogers"], "venue": "Cognitive Systems Research, vol. 10, no. 2, pp. 141\u2013160, 2009. 12", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2009}, {"title": "Soar: An architecture for general intelligence", "author": ["J.E. Laird", "A. Newell", "P.S. Rosenbloom"], "venue": "Artificial intelligence, vol. 33, no. 1, pp. 1\u201364, 1987.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1987}, {"title": "The architecture of cognition", "author": ["J.R. Anderson"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2013}, {"title": "Visual place recognition: A survey", "author": ["S. Lowry", "N. Snderhauf", "P. Newman", "J.J. Leonard", "D. Cox", "P. Corke", "M.J. Milford"], "venue": "IEEE Transactions on Robotics, vol. 32, no. 1, pp. 1\u201319, 2016.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2016}, {"title": "A cognitive robotic system based on the Soar cognitive architecture for mobile robot navigation, search, and mapping missions", "author": ["S.D. Hanford"], "venue": "Pennsylvania State University,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2011}, {"title": "Extending the soar cognitive architecture", "author": ["J.E. Laird"], "venue": "Frontiers in Artificial Intelligence and Applications, vol. 171, p. 224, 2008.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2008}, {"title": "The sigma cognitive architecture and system", "author": ["P.S. Rosenbloom"], "venue": "AISB Quarterly, vol. 136, pp. 4\u201313, 2013.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2013}, {"title": "Tensor product variable binding and the representation of symbolic structures in connectionist systems", "author": ["P. Smolensky"], "venue": "Artificial intelligence, vol. 46, no. 1, pp. 159\u2013216, 1990.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1990}, {"title": "Enhancing intelligent agents with episodic memory", "author": ["A.M. Nuxoll", "J.E. Laird"], "venue": "Cognitive Systems Research, vol. 17, pp. 34\u201348, 2012.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2012}, {"title": "Neural networks and learning machines", "author": ["S. Haykin"], "venue": "Pearson Education Upper Saddle River,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2009}, {"title": "A critical review of recurrent neural networks for sequence learning", "author": ["Z.C. Lipton"], "venue": "arXiv preprint arXiv:1506.00019, 2015.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2015}, {"title": "Long short-term memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural computation, vol. 9, no. 8, pp. 1735\u20131780, 1997.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1997}, {"title": "Understanding lstm networks", "author": ["C. Olah"], "venue": "[Online]. Available: http://colah.github", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2015}, {"title": "Deep learning in neural networks: An overview", "author": ["J. Schmidhuber"], "venue": "Neural Networks, vol. 61, pp. 85 \u2013 117, 2015.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2015}, {"title": "Artificial intelligence: Connectionist and symbolic approaches", "author": ["R. Sun"], "venue": "1999.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1999}, {"title": "Cognitive control", "author": ["S. Haykin", "M. Fatemi", "P. Setoodeh", "Y. Xue"], "venue": "Proceedings of the IEEE, vol. 100, no. 12, pp. 3156\u20133169, 2012.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2012}, {"title": "A hybrid symbolic and subsymbolic intelligent system for mobile robots", "author": ["T.D. Kelley", "E. Avery", "L.N. Long", "E. Dimperio"], "venue": "InfoTech@ Aerospace Conference, 2009, pp. 2009\u20131976.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2009}, {"title": "The human brain project and neuromorphic computing", "author": ["A. Calimera", "E. Macii", "M. Poncino"], "venue": "Functional neurology, vol. 28, no. 3, pp. 191\u2013196, 2013. 13", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2013}, {"title": "Neurogrid: A mixed-analog-digital multichip system for large-scale neural simulations", "author": ["B.V. Benjamin", "P. Gao", "E. McQuinn", "S. Choudhary", "A.R. Chandrasekaran", "J.-M. Bussat", "R. Alvarez-Icaza", "J.V. Arthur", "P.A. Merolla", "K. Boahen"], "venue": "Proceedings of the IEEE, vol. 102, no. 5, pp. 699\u2013716, 2014.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2014}, {"title": "A million spiking-neuron integrated circuit with a scalable communication network and interface", "author": ["P.A. Merolla", "J.V. Arthur", "R. Alvarez-Icaza", "A.S. Cassidy", "J. Sawada", "F. Akopyan", "B.L. Jackson", "N. Imam", "C. Guo", "Y. Nakamura"], "venue": "Science, vol. 345, no. 6197, pp. 668\u2013673, 2014.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2014}, {"title": "The spinnaker project", "author": ["S.B. Furber", "F. Galluppi", "S. Temple", "L.A. Plana"], "venue": "Proceedings of the IEEE, vol. 102, no. 5, pp. 652\u2013665, 2014.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2014}, {"title": "A digital neurosynaptic core using embedded crossbar memory with 45pj per spike in 45nm", "author": ["P. Merolla", "J. Arthur", "F. Akopyan", "N. Imam", "R. Manohar", "D.S. Modha"], "venue": "Custom Integrated Circuits Conference (CICC), 2011 IEEE. IEEE, 2011, pp. 1\u20134.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2011}, {"title": "Training and operation of an integrated neuromorphic network based on metal-oxide memristors", "author": ["M. Prezioso", "F. Merrikh-Bayat", "B.D. Hoskins", "G.C. Adam", "K.K. Likharev", "D.B. Strukov"], "venue": "Nature, vol. 521, no. 7550, pp. 61\u201364, 5 2015. [Online]. Available: http://dx.doi.org/10.1038/nature14441", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2015}, {"title": "Overview of the spinnaker system architecture", "author": ["S.B. Furber", "D.R. Lester", "L.A. Plana", "J.D. Garside", "E. Painkras", "S. Temple", "A.D. Brown"], "venue": "Computers, IEEE Transactions on, vol. 62, no. 12, pp. 2454\u20132467, 2013.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2013}, {"title": "Memristor-based neural networks", "author": ["A. Thomas"], "venue": "Journal of Physics D: Applied Physics, vol. 46, no. 9, p. 093001, 2013. 14", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "is claimed to be processed in the brain [2,3].", "startOffset": 40, "endOffset": 45}, {"referenceID": 1, "context": "is claimed to be processed in the brain [2,3].", "startOffset": 40, "endOffset": 45}, {"referenceID": 2, "context": "Symbolic approaches such as cognitive architectures have a long history in AI and their developments have been devoted towards creating computational models that formalize the structure of the human brain [4].", "startOffset": 205, "endOffset": 208}, {"referenceID": 3, "context": "Cognitive architectures such as Soar [5] and ACT-R [6] have been under development for many decades and have been successfully applied in various studies.", "startOffset": 37, "endOffset": 40}, {"referenceID": 4, "context": "Cognitive architectures such as Soar [5] and ACT-R [6] have been under development for many decades and have been successfully applied in various studies.", "startOffset": 51, "endOffset": 54}, {"referenceID": 0, "context": "There have been arguments against the use of symbol systems because they oversimplify the underlying mechanisms required for cognition [2].", "startOffset": 135, "endOffset": 138}, {"referenceID": 5, "context": "Connectionist approaches such as artificial neural networks (ANN\u2019s) have been through several generations of major developments and have become the leading technology in AI in recent years [7].", "startOffset": 189, "endOffset": 192}, {"referenceID": 6, "context": "Robotics is often cited as a field where AI and machine learning technology can be used, however many of the attempts focus on perceptual systems and ignore high-level cognitive capabilities [8].", "startOffset": 191, "endOffset": 194}, {"referenceID": 3, "context": "Their work culminated in the creation of many impressive AI systems including the creation of the Soar cognitive architecture [5].", "startOffset": 126, "endOffset": 129}, {"referenceID": 2, "context": "Soar is one of many cognitive architectures that aims to create a formal, structured model of a cognitive system [4].", "startOffset": 113, "endOffset": 116}, {"referenceID": 2, "context": "Formal structure plays an important role not only in Soar but all cognitive architectures as they must define features that remain constant in a cognitive agent [4].", "startOffset": 161, "endOffset": 164}, {"referenceID": 7, "context": "[9]", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "These models are typically based on the physical symbol system hypothesis, however there has been a shift towards hybridlike approaches such as the CLARION [4] and Sigma [10] architectures.", "startOffset": 156, "endOffset": 159}, {"referenceID": 8, "context": "These models are typically based on the physical symbol system hypothesis, however there has been a shift towards hybridlike approaches such as the CLARION [4] and Sigma [10] architectures.", "startOffset": 170, "endOffset": 174}, {"referenceID": 2, "context": "Cognitive architectures aim to utilise the knowledge contained in each of the different modules in a coherent and unified manner to produce cognitive behaviour [4].", "startOffset": 160, "endOffset": 163}, {"referenceID": 9, "context": "This is particularly important for high level cognitive capabilities that are easier to understand at a symbolic level than at a sub-symbolic level [11].", "startOffset": 148, "endOffset": 152}, {"referenceID": 6, "context": "Autonomous vehicles are a popular application of AI in engineering and even though there has been great success in recent years the technology used still lack the capabilities most associated with intelligence such as problem solving and decision making [8].", "startOffset": 254, "endOffset": 257}, {"referenceID": 10, "context": "This type of memory, known as episodic memory, has been introduced in Soar and it offers some impressive capabilities as shown by Nuxoll and Laird [12].", "startOffset": 147, "endOffset": 151}, {"referenceID": 2, "context": "Episodic memory is just one example of many high-level cognitive capabilities where the classical approach to AI has been at the forefront [4].", "startOffset": 139, "endOffset": 142}, {"referenceID": 11, "context": "While it is definitely possible for connectionist models to implement these exact structures (this must be true because the human brain is a biological connectionist system) the techniques and methods in achieving this seem out of reach for now [13].", "startOffset": 245, "endOffset": 249}, {"referenceID": 1, "context": "Cognitive architectures are also reliant on humans to encode much of the necessary knowledge which creates many practical and theoretical problems [3] that will not be discussed in this paper.", "startOffset": 147, "endOffset": 150}, {"referenceID": 0, "context": "An alternative to symbolic AI is the connectionist approach that does away with formal processing blocks that model cognition in favour of an approach inspired by neurobiology [2].", "startOffset": 176, "endOffset": 179}, {"referenceID": 11, "context": "Instead of relying on hand-engineered features and symbolic data structures connectionist models, such as artificial neural networks (ANN\u2019s), rely on the processing power of having many simple, interconnected processing units that allow for massively parallel computing [13].", "startOffset": 270, "endOffset": 274}, {"referenceID": 0, "context": "An important feature is that the activation functions are mostly non-linear and are therefore useful for solving non-linear problems, whereas traditional approaches often involve the linearisation of problems so that linear techniques can be applied The information contained in a neural network is a result of learning and not through direct encoding by a human [2].", "startOffset": 363, "endOffset": 366}, {"referenceID": 11, "context": "put [13].", "startOffset": 4, "endOffset": 8}, {"referenceID": 11, "context": "Unlike the rigid structure of cognitive architectures, connectionist models are adaptive by nature [13].", "startOffset": 99, "endOffset": 103}, {"referenceID": 11, "context": "The beauty of ANN\u2019s is that one can use them to accomplish many different tasks even though the principles and methods will remain the same [13].", "startOffset": 140, "endOffset": 144}, {"referenceID": 12, "context": "Recent developments have seen an increase in the number of neural networks with recurrent connections that essentially act as some form of memory [14].", "startOffset": 146, "endOffset": 150}, {"referenceID": 12, "context": "Instead of only seeing a snapshot of data at each time step the network is capable of using the data from previous time steps to assist in processing the current data [14].", "startOffset": 167, "endOffset": 171}, {"referenceID": 14, "context": "[16]", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "techniques have helped solve this [15].", "startOffset": 34, "endOffset": 38}, {"referenceID": 13, "context": "For example a popular RNN model and learning algorithm known as long short-term memory (LSTM) introduces specialised gates that control the flow of information to allow for the learning of long-term dependencies [15].", "startOffset": 212, "endOffset": 216}, {"referenceID": 13, "context": "In this model the basic building block is no longer just a neuron, but rather what is known as a \u201cmemory cell\u201d [15].", "startOffset": 111, "endOffset": 115}, {"referenceID": 15, "context": "This increased complexity in RNN\u2019s makes them capable of learning more advanced features at the expense of becoming more difficult to train and compute [17].", "startOffset": 152, "endOffset": 156}, {"referenceID": 0, "context": "A major stumbling block in creating large neural networks, however, is the sheer quantity of model parameters that make it impossible for a human to comprehend [2].", "startOffset": 160, "endOffset": 163}, {"referenceID": 16, "context": "This approach has worked well for perceptual tasks such as classification and recognition of patterns, however, this is a small piece of the cognition and there is still difficulty in learning complex representations necessary for high-level cognitive functions [18].", "startOffset": 262, "endOffset": 266}, {"referenceID": 11, "context": "parallel computation required in neural networks compared to CPUs, however their power usage is still far beyond that of the human brain [13].", "startOffset": 137, "endOffset": 141}, {"referenceID": 1, "context": "[3] suggests that this is a viable and attractive solution to many problems that each individual approach is faced with and that it may be necessary to accomplish cognitive machines.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "Connectionist approaches have been extremely successful in perceptual tasks and are useful in adaptive control but so far lack the high-level capabilities that are necessary for complex tasks [3, 11].", "startOffset": 192, "endOffset": 199}, {"referenceID": 9, "context": "Connectionist approaches have been extremely successful in perceptual tasks and are useful in adaptive control but so far lack the high-level capabilities that are necessary for complex tasks [3, 11].", "startOffset": 192, "endOffset": 199}, {"referenceID": 17, "context": "In the case of machines such robots, there is a need for strong perception and action capabilities because the agents must interact with the physical world [19] and there is also the need to include problem solving and decision making capabilities for the robotic agents to operate without human intervention [19].", "startOffset": 156, "endOffset": 160}, {"referenceID": 17, "context": "In the case of machines such robots, there is a need for strong perception and action capabilities because the agents must interact with the physical world [19] and there is also the need to include problem solving and decision making capabilities for the robotic agents to operate without human intervention [19].", "startOffset": 309, "endOffset": 313}, {"referenceID": 18, "context": "Hybrid cognitive robotic architectures have been explored before in [20] and [8] but there remains a wealth of untapped capabilities such as the use of episodic memory.", "startOffset": 68, "endOffset": 72}, {"referenceID": 6, "context": "Hybrid cognitive robotic architectures have been explored before in [20] and [8] but there remains a wealth of untapped capabilities such as the use of episodic memory.", "startOffset": 77, "endOffset": 80}, {"referenceID": 18, "context": "The SS-RICS architecture in [20] used a common robotics approach for generating a map for navigation that utilizes metric information from sensor data.", "startOffset": 28, "endOffset": 32}, {"referenceID": 18, "context": "They argue that without a useful perceptual system the higher-level capabilities can never be realised because there would be difficulty in creating meaningful symbolic relationships [20].", "startOffset": 183, "endOffset": 187}, {"referenceID": 6, "context": "The CRS architecture used in [8] used fuzzy logic to improve the classification of intersections but odometery errors meant that the robot mistakenly identified the same intersections as different ones.", "startOffset": 29, "endOffset": 32}, {"referenceID": 6, "context": "Even though they both mention that such techniques are not cognitive processes they continue to use them as a step towards providing semantic labels for a high-level symbol system [8, 20].", "startOffset": 180, "endOffset": 187}, {"referenceID": 18, "context": "Even though they both mention that such techniques are not cognitive processes they continue to use them as a step towards providing semantic labels for a high-level symbol system [8, 20].", "startOffset": 180, "endOffset": 187}, {"referenceID": 6, "context": "The cognitive architecture could use that local information to construct topological maps which allow for easier path planning, decision making and problem solving compared to metric maps [8].", "startOffset": 188, "endOffset": 191}, {"referenceID": 19, "context": "They provide a review of neuromorphic technology in [21] where they provide a breakdown of neuromorphic hardware as shown in Figure 5.", "startOffset": 52, "endOffset": 56}, {"referenceID": 20, "context": "Simulating large scale neural networks using von Neumann architectures is inefficient and would require incredibly large amounts of power [22\u201324].", "startOffset": 138, "endOffset": 145}, {"referenceID": 21, "context": "Simulating large scale neural networks using von Neumann architectures is inefficient and would require incredibly large amounts of power [22\u201324].", "startOffset": 138, "endOffset": 145}, {"referenceID": 22, "context": "Simulating large scale neural networks using von Neumann architectures is inefficient and would require incredibly large amounts of power [22\u201324].", "startOffset": 138, "endOffset": 145}, {"referenceID": 21, "context": "One of the primary bottlenecks to overcome is the inefficient movement of data that occurs between processors and memory in traditional von Neumann architectures [23].", "startOffset": 162, "endOffset": 166}, {"referenceID": 22, "context": "Most notable are the works done by the University of Manchester with their SpiNNaker project [24], IBM with their TrueNorth architecture [25], Stanford University and their Neurogrid architecture [22], and a team from the University of California at Santa Barbara [26].", "startOffset": 93, "endOffset": 97}, {"referenceID": 23, "context": "Most notable are the works done by the University of Manchester with their SpiNNaker project [24], IBM with their TrueNorth architecture [25], Stanford University and their Neurogrid architecture [22], and a team from the University of California at Santa Barbara [26].", "startOffset": 137, "endOffset": 141}, {"referenceID": 20, "context": "Most notable are the works done by the University of Manchester with their SpiNNaker project [24], IBM with their TrueNorth architecture [25], Stanford University and their Neurogrid architecture [22], and a team from the University of California at Santa Barbara [26].", "startOffset": 196, "endOffset": 200}, {"referenceID": 24, "context": "Most notable are the works done by the University of Manchester with their SpiNNaker project [24], IBM with their TrueNorth architecture [25], Stanford University and their Neurogrid architecture [22], and a team from the University of California at Santa Barbara [26].", "startOffset": 264, "endOffset": 268}, {"referenceID": 22, "context": "The architecture employed in their SpiNNaker project utilizes processing nodes consisting of 18 general purpose ARM968 cores and extra memory for each node [24].", "startOffset": 156, "endOffset": 160}, {"referenceID": 22, "context": "[24]", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "to achieving massively parallel computing by opting to use large quantities of existing processors rather than designing custom circuitry to emulate individual neurons [27].", "startOffset": 168, "endOffset": 172}, {"referenceID": 21, "context": "At IBM they have developed what they call digital neurosynaptic cores as the fundamental building blocks of their TrueNorth architecture [23, 25].", "startOffset": 137, "endOffset": 145}, {"referenceID": 23, "context": "At IBM they have developed what they call digital neurosynaptic cores as the fundamental building blocks of their TrueNorth architecture [23, 25].", "startOffset": 137, "endOffset": 145}, {"referenceID": 21, "context": "TrueNorth has 1 million neurons and 256 million synapses [23] compared to SpiNNaker\u2019s approximate number of 18 thousand neurons and 18 million synapses per node [27].", "startOffset": 57, "endOffset": 61}, {"referenceID": 25, "context": "TrueNorth has 1 million neurons and 256 million synapses [23] compared to SpiNNaker\u2019s approximate number of 18 thousand neurons and 18 million synapses per node [27].", "startOffset": 161, "endOffset": 165}, {"referenceID": 20, "context": "The team working at Stanford are working on a mixed analog-digital hardware platform for neural computing called Neurogrid [22].", "startOffset": 123, "endOffset": 127}, {"referenceID": 23, "context": "[25]", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "technology has proved to be very efficient [22] and is a highly promising project.", "startOffset": 43, "endOffset": 47}, {"referenceID": 24, "context": "At the University of California at Santa Barbara they have been working on creating neural networks that use the well suited properties of memristors [26].", "startOffset": 150, "endOffset": 154}, {"referenceID": 26, "context": "Memristors have a fundamental property that is very much like the synaptic connection between neurons [28].", "startOffset": 102, "endOffset": 106}, {"referenceID": 26, "context": "Where an increase in flux in one direction causes the resistance to increase and flux in the opposite direction causes resistance to decrease [28].", "startOffset": 142, "endOffset": 146}, {"referenceID": 24, "context": "In their paper [26] they were able to train a single-layer perceptron network to classify a 3x3-pixel image without the use of any CMOS components - only memristors.", "startOffset": 15, "endOffset": 19}, {"referenceID": 20, "context": "[22]", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "As mentioned by Smolensky [11] it is ill-advised for the two camps (symbolic and connectionist) to ignore each other, however major developments in hybrid models have fallen behind in comparison to developments in the individual fields.", "startOffset": 26, "endOffset": 30}], "year": 2016, "abstractText": "Cognitive engineering is a multi-disciplinary field and hence it is difficult to find a review article consolidating the leading developments in the field. The incredible pace at which technology is advancing pushes the boundaries of what is achievable in cognitive engineering. There are also differing approaches to cognitive engineering brought about from the multi-disciplinary nature of the field and the vastness of possible applications. Thus research communities require more frequent reviews to keep up to date with the latest trends. In this paper we shall discuss some of the approaches to cognitive engineering holistically to clarify the reasoning behind the different approaches and to highlight their strengths and weaknesses. We shall then show how developments from seemingly disjointed views could be integrated to achieve the same goal of creating cognitive machines. By reviewing the major contributions in the different fields and showing the potential for a combined approach, this work intends to assist the research community in devising more unified methods and techniques for developing cognitive machines. artificial intelligence, cognitive architecture, bio-inspired", "creator": "LaTeX with hyperref package"}}}