{"id": "1610.09982", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-Oct-2016", "title": "Sentiment Analysis of Review Datasets Using Naive Bayes and K-NN Classifier", "abstract": "The advent of Web 2.0 has led to an increase in the amount of sentimental content available in the Web. Such content is often found in social media web sites in the form of movie or product reviews, user comments, testimonials, messages in discussion forums etc. Timely discovery of the sentimental or opinionated web content has a number of advantages, the most important of all being monetization. Understanding of the sentiments of human masses towards different entities and products enables better services for contextual advertisements, recommendation systems and analysis of market trends. The focus of our project is sentiment focussed web crawling framework to facilitate the quick discovery of sentimental contents of movie reviews and hotel reviews and analysis of the same. We use statistical methods to capture elements of subjective style and the sentence polarity. The paper elaborately discusses two supervised machine learning algorithms: K-Nearest Neighbour(K-NN) and Naive Bayes and compares their overall accuracy, precisions as well as recall values. It was seen that in case of movie reviews Naive Bayes gave far better results than K-NN but for hotel reviews these algorithms gave lesser, almost same accuracies.", "histories": [["v1", "Mon, 31 Oct 2016 15:45:41 GMT  (690kb)", "http://arxiv.org/abs/1610.09982v1", "Volume-8, Issue-4, pp.54-62, 2016"]], "COMMENTS": "Volume-8, Issue-4, pp.54-62, 2016", "reviews": [], "SUBJECTS": "cs.IR cs.CL", "authors": ["lopamudra dey", "sanjay chakraborty", "anuraag biswas", "beepa bose", "sweta tiwari"], "accepted": false, "id": "1610.09982"}, "pdf": {"name": "1610.09982.pdf", "metadata": {"source": "CRF", "title": "Sentiment Analysis of Review Datasets using Nai\u0308ve Bayes\u2019 and K-NN Classifier", "authors": ["Lopamudra Dey", "Sanjay Chakraborty", "Anuraag Biswas", "Beepa Bose", "Sweta Tiwari"], "emails": ["lopamudra.dey@heritageit.edu", "sanjay.chakraborty@iemcal.com", "anuraagbiswas111@gmail.com", "beepabose@gmail.com", "sweta.tiwari604@gmail.com"], "sections": [{"heading": null, "text": "This year it is more than ever before."}, {"heading": "A) Data source and Data Set", "text": "To conduct the research, two sets of data are taken into account: movie reviews and hotel reviews. All movie reviews were scanned from www.imdb.com. All hotel reviews were downloaded from OpinRank Review Dataset (http: / / archive.ics.uci.edu / ml / datasets / OpinRank + Review + Dataset). The data set was created by evaluating 5000 positive and 5000 negative reviews from each of the websites mentioned."}, {"heading": "B) Methodology", "text": "The main objective of the research is to analyze the data from the surveys and to decide whether it is appropriate to be analyzed using the data mining methods discussed. A graphical description of the processes involved in sentiment analysis is detailed in Figure 1 below. Knowledge and observed data can be combined. In Na\u00efve Bayes \"technique, the basic idea is to find the probabilities of categories given to a text document by using the common probabilities of words and categories. It is based on the assumption of word independence. Starting point is the Bayes Conditional Probability Theorem, which states that for a given data point x and the class C: P (C / x) / P (x) the assumption that for a data point x = {x1, x2,... xj} the probability of each of its attributes occurring in a given class is independent."}, {"heading": "2) k-Nearest Neighbour Classifier", "text": "K-NN is a type of instance-based learning, or lazy learning, in which the function is approximate only locally and all calculations are deferred until classification. It is a non-parametric method used for classification or regression. In the case of classification, the output is class affiliation (the most common cluster can be returned), the object is classified with the majority of its neighbors, assigning the object to the class that is most common among its k nearest neighbors. This rule simply maintains the entire training program during learning and assigns each request a class that is represented by the majority designation of its k nearest neighbors in the training set. The closest neighbor rule (NN) is the simplest form of K-NN, if K = 1. In the face of an unknown sample and a training set, all distances between the unknown sample and all samples in the training set can be calculated as k-nearest distances."}, {"heading": "1. Pre-processing:", "text": "In fact, the majority of people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to move, to move, to move, to move, to move, to move, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move"}, {"heading": "1. 100 56.78 47.64 43.11 45.35", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2. 200 64.29 55.07 41.26 40.97", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3. 500 70.06 58.44 42.56 41.42", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4. 1000 73.81 61.48 44.64 41.18", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5. 1500 77.23 64.21 48.21 42.01", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6. 2000 79.14 66.02 51.28 46.57", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "7. 2500 79.82 67.89 52.03 47.04", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "8. 3000 80.27 68.58 52.64 47.03", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "9. 4000 82.11 69.03 53.92 49.75", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "10. 4500 82.43 69.81 55.09 52.14", "text": "Fig. 4. Diagram of accuracy in the experiments ws) ws) ws)"}, {"heading": "1. 100 59.04 41.35 42.11 44.51", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2. 200 64.96 50.97 40.26 40.86", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3. 500 69.56 54.42 41.56 40.41", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4. 1000 73.64 58.18 43.64 42.21", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5. 1500 77.21 62.01 47.21 42.12", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6. 2000 80.28 65.57 50.28 45.36", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "7. 2500 81.03 66.04 51.03 46.14", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "8. 3000 81.64 67.03 51.64 47.13", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "9. 4000 82.92 67.75 52.92 47.57", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "10. 4500 84.09 68.14 54.09 48.21", "text": "Fig. 5. Diagram of positive precision in the experiments Table 5. Precision comparison for Negative Corpus on test database no. Number of reviews in the training database tPrecision for Negatives Corpus: Na\u00efve Bayes' (Movie reviews) K-NN (Movie reviews) Na\u00efve Bayes' (hotel reviews) K-NN (hotel reviews)"}, {"heading": "1. 100 55.43 38.12 48.39 46.21", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2. 200 63.67 49.56 42.61 41.63", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3. 500 70.59 57.25 50.62 47.32", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4. 1000 73.99 62.12 53.81 52.15", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5. 1500 77.25 64.48 57.31 54.43", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6. 2000 78.09 65.73 58.11 55.69", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "7. 2500 78.70 66.23 58.4 56.32", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "8. 3000 79.00 66.47 59.91 56.51", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "9. 4000 81.33 66.62 61.29 56.66", "text": "10. 4500 81,01 66,73 61,11 56,77"}, {"heading": "1. 100 44.33 31.12 32.24 30.35", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2. 200 62.04 45.37 43.54 42.41", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3. 500 71.34 52.24 41.79 41.86", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4. 1000 74.19 56.31 47.44 42.21", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5. 1500 77.26 58.24 49.19 44.72", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6. 2000 77.26 60.02 50.02 45.03", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "7. 2500 77.89 61.12 51.77 46.01", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "8. 3000 78.09 61.53 51.44 46.52", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "9. 4000 80.87 61.72 51.34 46.25", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "10. 4500 80.12 61.81 51.84 46.31", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "1. 100 69.24 39.25 62.33 60.35", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2. 200 66.54 55.12 53.51 52.41", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3. 500 68.79 53.86 51.81 51.89", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4. 1000 73.44 60.21 57.52 52.19", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5. 1500 77.19 63.72 59.24 54.77", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6. 2000 81.02 65.03 60.11 5513", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "7. 2500 81.77 66.01 61.83 56.11", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "8. 3000 82.44 66.52 61.49 56.32", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "9. 4000 83.34 66.25 61.37 56.35", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "10. 4500 84.84 66.31 61.88 56.41", "text": "V. Conclusion: The aim of the study is to evaluate the performance of the sentiment classification in terms of accuracy, precision and recall. In this paper, we compared two supervised machine learning algorithms developed by Na\u00efve Bayes and KNN for the sentiment classification of film reviews and hotel reviews. Experimental results show that the classifiers achieved better results for film reviews using Na\u00efve Bayes \"approach, which provides over 80% accuracy and more performance than the k-NN approach. However, in the case of hotel reviews, the accuracy is much lower and both classifiers produced similar results. Therefore, we can say that the Na\u00efve Bayes classifier can be successfully used to analyze film reviews."}, {"heading": "2013, ISSN: 0870-8541.", "text": "[4] Weiguo Fan, Linda Wallace, Stephanie Rich, andZhongju Zhang, \"Tapping into the Power of TextMining,\" Journal of ACM, Blacksburg, 2005. [5] \"Movie review dataset,\" [Online] Availablehttp: / / www.cs.cornell.edu / people / pabo / movie-review-data /, [6] K. M. Leung, \"Naive Bayesian classifier,\" [Online] Available: http: / / www.sharepdf.com / 81fb247fa7c54680a94dc0f3a253fd85 / naiveBayesianClassifier.pdf, [Online] [7] Zhou Yong, Li Youwen and Xia Shixiong \"AnImproved KNN Text Classification Algorithm Basedon Clustering,\" Journal of Computers, vol."}, {"heading": "2014, pp. 723-762.", "text": "[12] Jusoh, Shaidah and Hejab M. Alfawareh. \"Techniques, Applications and Challenges in Text Mining.\" International Journal of Computer ScienceIssues (IJCSI) 9, No. 6, 2012. [13] L. Dey and S. Chakraborty, \"Canonical PSO Based -Means Clustering Approach for Real Datasets,\" International Scholarly Research Notices, Hindawi Publishing Corporation, Vol.2014, pp. 111.2014. [14] R. Dey and S. Chakraborty, \"Convex-hull & DBSCAN Clustering to Predict Future Weather,\" 6th International IEEE Conference and Workshop on Computing and Communication, Canada, 2015, pp. 18."}], "references": [{"title": "Analyzing Sentiment of Movie Review Data using Naive Bayes Neural Classifier\u201d, IJETTCS, Volume 3, Issue 4 July-August", "author": ["Lina L. Dhande", "Dr. Prof. Girish K. Patnaik"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "Marketing Research: The Role of Sentiment Analysis", "author": ["Meena Rambocas", "Jo\u00e3o Gama"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2013}, {"title": "Tapping into the Power of Text Mining", "author": ["Weiguo Fan", "Linda Wallace", "Stephanie Rich", "Zhongju Zhang"], "venue": "Journal of ACM, Blacksburg,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2005}, {"title": "Naive Bayesian classifier", "author": ["K.M. Leung"], "venue": "[Online] Available: http://www.sharepdf.com/81fb247fa7c54680a94dc0f3a 253fd85/naiveBayesianClassifier.pdf, [Accessed: September 2013].", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "An Improved KNN Text Classification Algorithm Based  on Clustering", "author": ["Zhou Yong", "Li Youwen", "Xia Shixiong"], "venue": "journal of computers,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2009}, {"title": "Sentiment Analysis: A Combined Approach", "author": ["Rudy Prabowo", "Mike Thelwall"], "venue": "Journal of Informatics,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2009}, {"title": "Sentiment Analysis of Short Informal Texts", "author": ["Svetlana Kiritchenko", "Xiaodan Zhu", "Saif M. Mohammad"], "venue": "Journal of Artificial Intelligence Research", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "Techniques, applications and challenging issue in text mining.\" International Journal of Computer Science Issues (IJCSI", "author": ["Jusoh", "Shaidah", "Hejab M. Alfawareh"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2012}, {"title": "Canonical PSO Based K-Means Clustering Approach for Real Datasets", "author": ["L. Dey", "S. Chakraborty"], "venue": "International Scholarly Research Notices, Hindawi Publishing", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Convex-hull & DBSCAN clustering to predict future weather", "author": ["R. Dey", "S. Chakraborty"], "venue": "IEEE Conference and Workshop on Computing and Communication,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2015}], "referenceMentions": [{"referenceID": 8, "context": "Several analysis tools of data mining (like, clustering, classification, regression etc,) can be used for sentiment analysis task [13][14].", "startOffset": 130, "endOffset": 134}, {"referenceID": 9, "context": "Several analysis tools of data mining (like, clustering, classification, regression etc,) can be used for sentiment analysis task [13][14].", "startOffset": 134, "endOffset": 138}, {"referenceID": 0, "context": "Here the source materials refer to opinions / reviews /comments given in various social networking sites [1].", "startOffset": 105, "endOffset": 108}, {"referenceID": 1, "context": "The traditional text mining concentrates on analysis of facts whereas opinion mining deals with the attitudes [3].", "startOffset": 110, "endOffset": 113}, {"referenceID": 2, "context": "- Measuring public response to an activity or company related issue [4].", "startOffset": 68, "endOffset": 71}, {"referenceID": 2, "context": "Here is the point where we can scale the accuracy and efficiency of different algorithms [4].", "startOffset": 89, "endOffset": 92}, {"referenceID": 1, "context": "Few Related work are as follow: (a)Mori Rimon[3] used the keyword based approach to classify sentiment.", "startOffset": 45, "endOffset": 48}, {"referenceID": 2, "context": "(b)Alec co [4] used different machine learning algorithms such as Na\u00efve Bayes\u2019, Support vector machine and maximum entropy.", "startOffset": 11, "endOffset": 14}, {"referenceID": 3, "context": "Modha [6] worked on techniques of handling both subjective as well as objective unstructured data.", "startOffset": 6, "endOffset": 9}, {"referenceID": 4, "context": "(e) Theresa Wilson, Janyce Wiebe and Paul Hoffman [7] worked on a new approach on sentiment analysis by first determining whether an expression is neutral or polar and then disambiguates the polarity of the polar expression.", "startOffset": 50, "endOffset": 53}, {"referenceID": 5, "context": "and accuracy, Precision and recall as explained below [9].", "startOffset": 54, "endOffset": 57}], "year": 2015, "abstractText": "The advent of Web 2.0 has led to an increase in the amount of sentimental content available in the Web. Such content is often found in social media web sites in the form of movie or product reviews, user comments, testimonials, messages in discussion forums etc. Timely discovery of the sentimental or opinionated web content has a number of advantages, the most important of all being monetization. Understanding of the sentiments of human masses towards different entities and products enables better services for contextual advertisements, recommendation systems and analysis of market trends. The focus of our project is sentiment focussed web crawling framework to facilitate the quick discovery of sentimental contents of movie reviews and hotel reviews and analysis of the same. We use statistical methods to capture elements of subjective style and the sentence polarity. The paper elaborately discusses two supervised machine learning algorithms: K-Nearest Neighbour(K-NN) and Na\u00efve Bayes\u2019 and compares their overall accuracy, precisions as well as recall values. It was seen that in case of movie reviews Na\u00efve Bayes\u2019 gave far better results than K-NN but for hotel reviews these algorithms gave lesser, almost same", "creator": "Microsoft\u00ae Word 2013"}}}