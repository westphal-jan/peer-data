{"id": "1611.00201", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Nov-2016", "title": "Towards Lifelong Self-Supervision: A Deep Learning Direction for Robotics", "abstract": "Despite outstanding success in vision amongst other domains, many of the recent deep learning approaches have evident drawbacks for robots. This manuscript surveys recent work in the literature that pertain to applying deep learning systems to the robotics domain, either as means of estimation or as a tool to resolve motor commands directly from raw percepts. These recent advances are only a piece to the puzzle. We suggest that deep learning as a tool alone is insufficient in building a unified framework to acquire general intelligence. For this reason, we complement our survey with insights from cognitive development and refer to ideas from classical control theory, producing an integrated direction for a lifelong learning architecture.", "histories": [["v1", "Tue, 1 Nov 2016 12:47:50 GMT  (656kb,D)", "http://arxiv.org/abs/1611.00201v1", null]], "reviews": [], "SUBJECTS": "cs.RO cs.AI", "authors": ["jay m wong"], "accepted": false, "id": "1611.00201"}, "pdf": {"name": "1611.00201.pdf", "metadata": {"source": "CRF", "title": "Towards Lifelong Self-Supervision: A Deep Learning Direction for Robotics", "authors": ["Jay M. Wong"], "emails": [], "sections": [{"heading": "Keywords", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Robotics, Deep Learning, Cognition, Autonomy, Lifelong Learning", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "1 Introduction", "text": "In fact, our goal is to find a solution to a particular task that is located in a specific area, or is it to build a system that has the ability to acquire general intelligence (an idea characterized by Legg and Hutter)? A historical example is that success in aviation does not necessarily lead to success, but to a task that is about having some similarity."}, {"heading": "1.1 From Computer Vision to Robotics", "text": "This particular tool, popularized by Krizhevsky et al. (2012) in the ImageNet competition, showed significant success stories as latent representations of features were learned through a neural network that included a series of folds, pooling, and tightly connected neurons that exceeded existing handcrafted feature representations that were otherwise standard. Computer machine (GPU) support enabled the efficient parallelization needed to train neural network structures with massive datasets. Since then, the computer vision community has produced a wealth of in-depth learning research and human cognition skills through the construction of deeper and deeper networks Szegedy et al. (2015), fine-tuning, and the introduction of additional features (e.g. surface standards) Madai-Tahy et al. (2016)."}, {"heading": "1.2 On Overgeneralization", "text": "An immediate disadvantage to these computer vision architectures is that studies have found that image classification has a regrettable over-generalization phenomenon (\"scars\"). These classification tasks typically take as input a single sensor modality, in many cases RGB. Where deep learning tools fail is when opposing RGB examples are used in attempts to deceive these networks into very false predictions that are predicted by the network in studies by Szegedy et al. (2013); Nguyen et al. (2015); Carlini and Wagner (2016). In this work, mountain races and gradient ascent methods were used to match very false classes with high probability predicted by the network. Although there is work to make these networks robust against such malicious attacks (e.g. Bendale and Boult (2015); Wang et al. (2016a) 1, we theorize that the addition of multiple modalities (with more than just vision) can mitigate such phenomena."}, {"heading": "1.3 On Deep Reinforcement Learning", "text": "Mnih et al. (2013, 2015) built a single learning framework that could learn to play a large number of Atari games beyond human competence through a trial-and-error approach in which the only information given to the system was multiple game frames, score scores, and a discrete control set. A neural network was used to approximate the Q values of a discrete series of actions from multiple game frames, and performed the highest-rated action that led to a competent game strategy. The idea of using a neural network as 1 This particular phenomenon is categorized under open-set recognition. Bendale and Boult (2015) proposed a new model layer, OpenMax, which appreciates the likelihood of input from unknown classes and rejects contradictory examples."}, {"heading": "Jay M. Wong \u2014 Towards Lifelong Self-Supervision: A Deep Learning Direction for Robotics 3", "text": "Approaching a value function is nothing profound or novel. Two and a half decades ago, Tesauro tried to tackle the game of backgammon - a board game with about 1020 states, making traditional tabular reinforcement learning unfeasible. Instead, a neural network derived from human task knowledge was used to approximate the value function to describe board positions and probabilities of winning. It showed up in various incarnations of his algorithm, in which both raw coding and handmade features from human task knowledge were used to learn competent gameplay strategies Tesauro (1992, 1995a, b). Furthermore, other researchers in the past have used recurring neural networks to learn Q values from a history of features to form strategies Schmidhuber (1991); Lin and Mitchell (1992); Meeden et al. (1993)."}, {"heading": "1.4 On Domain Transfer", "text": "Unfortunately, one reason why many of these play areas are successful is that the domain is fully observable. Although there are some studies that offer partial observability and attempt to address this problem with an expanded memory structure, Heess et al. (2015a), the algorithms developed through gameplay should not be considered game-changing success stories in physically dynamic systems. The real world obeys physics and uncertainties that cannot be perfectly modeled in simulation, and as a result, strategies learned in simulation have difficulty generalizing to real robotic systems. Thus, for example, millions of training steps in over hundreds of simulation hours have failed to visualize strategies learned on a Baxter simulator when the physical platform Zhang et al. (2015) interestingly showed that James and Johns (2016) were able to transfer visual strategies into a reactive system."}, {"heading": "1.5 On Self-Supervision", "text": "In fact, most people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to dance, to dance, to dance, to dance, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to"}, {"heading": "2 Implications for Robotics", "text": "In a simplistic sense, deep learning is an algorithmic tool that uses neural networks as non-linear function approximation factors, where weighted connections between input and output neurons are trained by error reverse propagation, encoding a function that minimizes the discrepancy between prediction and truth by building latent representations in the hidden layers. Since its great success in vision, popularized by the outstanding results in the ImageNet competition Krizhevsky et al. (2012), the deep learning field has exploded rapidly, producing a plethora wealth of general reviews on deep neural networks. As a result, we let the foundations of neural networks, convolutions, autocoding, regulation, repetition, and related concepts in this manuscript explode. Readers are referred to the following general reviews: Bengio (2009); LeCun et al. (2015); Goodet al. (2016) we will instead apply a number of thorough and thorough reviews to these areas."}, {"heading": "2.1 Detection, Estimation, and Tracking", "text": "A number of these individual triumphs used neural networks as a means of approaching otherwise very complex and highly non-linear functions related to estimation and scene understanding. For example, tasks related to rule-based navigation systems such as autonomous driving were specifically used to understand the identities of objects in the world. Identification and scene understanding can be considered a segmentation problem requiring visual input. SegNet, a semantic pixel-by-pixel segmentation encoder network, was presented to achieve competitive predictive skills that Badrinarayanan et al. (2015) Other methods also attempted to solve a similar task, but were either generative object suggestions Noh et al. (2015); Hariharan et al. (2015) or required multi-level training et al. (2015); Zheng et al."}, {"heading": "Jay M. Wong \u2014 Towards Lifelong Self-Supervision: A Deep Learning Direction for Robotics 5", "text": "Some of these research solutions only attempt to develop robust perception interfaces to autonomous systems, but a central, perhaps most important, module is one that thinks about sensations and performs useful motor control. Perception alone may not be the answer, but somewhere at the interface of perception, cognition, and action."}, {"heading": "2.2 From Perception to Motor Control", "text": "In fact, it is the case that most of them are in a position to go to another world, in which they go to another world, in which they go to another world, in which they do not find themselves, in which they do not find themselves in another world, in which they do not find themselves in another world, in which they cannot find themselves again, in which they do not find themselves, in which they do not find themselves, in which they live themselves, in which they live themselves, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they do not find themselves, in which they do not find themselves, in which they cannot find themselves, in which they do not find themselves, in which they do not find themselves, in which they do not find themselves, in which they live, in which they live themselves, in which they live themselves, in which they live themselves, in which they live themselves, in which they live, in which they live themselves, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live."}, {"heading": "Jay M. Wong \u2014 Towards Lifelong Self-Supervision: A Deep Learning Direction for Robotics 7", "text": "Guarantees and parameterization Insight that abstract skills derived from control theory approaches can make sense. By learning at the lowest level of motor units (e.g. in the configuration space via common torques), systems require a massive set of examples and training steps to cover this space. For example, even for a simple 2D spatial accomplishment of tasks in a limited 40cm x 30cm area with a 6 DOF Kinova arm with three fingers, it has been said that over 50 million steps are required via an end-to-end process (raw pixels to common spatial mapping) paradigm Rusu et al. (2016b) For such reasons, learning via a parametrized space abstracts these basic motor units and we theorize will accelerate learning. The notion of control guarantees is of paramount importance through an industry and product-delivering perspective. Particularly in scenarios where human factors are involved or other systems must have acquired high-level experience or learning through competence in the history of the systems."}, {"heading": "3 Complex Sensorimotor Hierarchies", "text": "In fact, a number of cognitive psychologists have shown that the nature of behavior is distributed among numerous individual entities, which together, in the strength of their connections, describe the behavior of people. They are plastic and modify themselves through dynamic processes with the world. Thelen and Smith (1996) in particular argue against the notion that these \"neural networks\" contain some privileged icons of behavior that are inherent in complex motivations and environmental contexts. \"In other words, the networks encode a certain contextual behavior - something like a central pattern - is completely wrong."}, {"heading": "3.1 Activating Motion Primitives", "text": "In their revolutionary book, Thelen and Smith (1996) outline the misinformation of contemporary theories of cognitive development, suggesting that cognitive and motor skills do not arise linearly through development, but that these primitive behaviors are inherently deeply rooted, amplified by interaction with the environment to seek dynamically stable solutions. As a result, skills arise from context-specific situations provided by the world. It appears that local circuits within the spinal cord mediate a number of closed sensory reflexes - for example, the stretch reflex Purves et al. (2001). Indeed, it has been observed that all people who develop infants exhibit similar chronicles of reflexive motor behavior. Aronson's central nervous system is organized according to motion patterns (1981) - its most basic form being the reflex. Under the concept of epigenetics 4Grupen and Huber (2005) expresses that packed patterns of motion contribute most strongly to the unreactive nervous system in the central and unreactive area of the nervous system."}, {"heading": "Jay M. Wong \u2014 Towards Lifelong Self-Supervision: A Deep Learning Direction for Robotics 9", "text": "The developmental theory of primitive reflexes, expressed as neuroanatomical structures, are the basic building blocks of behavior. In this respect, complex behavior results from combinatorial sequences of primitive control in response to amplification by the world. These primitive behaviors collectively describe an epigenetic computational ability through which complex control measures are derived. (2016) The ability to transform these developmental reflexes into intentional actions remains a fundamental cognitive process Zelazo (1983) and was briefly explored in the work of Wong et al. (2016), in which a deep network of controlled closed motion primitives was implemented, achieved by activating output neurons that describe control states. In short, this reduces sensor-imotor control to a supervised learning problem in which the state of the world is predicted by sensory modalities (vision was demonstrated in her study)."}, {"heading": "3.2 Composition of Motor Behaviors", "text": "In fact, it is the case that most people are able to determine for themselves what they want and what they do not want. (...) It is not that people are able to identify themselves. (...) It is not that they are able to identify themselves. (...) It is not that they are able to identify themselves. (...) It is not that they are able to identify themselves. (...) It is not that they are able to identify themselves. (...) It is that they are not able to identify themselves. (...) It is that they are not able to identify themselves. (...) \"(...)\" (...) \"() () () () () () () () () () ()) () () ()) () () ()) ()) () ()) ()) () ()) ()) () ()) () () ()) ()) () ()) () () ()) () ()) () () ()) () ()) () () ()) () ()) () () ()) () ()) ()) () ()) () ()) () ()) ()) () ()) () ()) () () ()) ()) () ()) () ()) () ()) ()) () () ()) () () ()) () ()) () () () ()) () () ()) () () ()) () () () () () ()) () () () () () () () () () () () () () () () () ()) () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () ("}, {"heading": "Jay M. Wong \u2014 Towards Lifelong Self-Supervision: A Deep Learning Direction for Robotics 11", "text": "This idea is based on the fact that in many cases it is necessary to realize resources. (...) The idea of operating multiple control programs through compositions in nullspace paradigms. (...) The idea of operating multiple control systems through compositions in nullspace paradigms. (...) The idea of operating multiple control programs through compositions in nullspace paradigms. (...) The idea of operating multiple control systems through compositions in nullspace paradigms. (...) The idea of operating multiple control mechanisms through compositions in nullspace paradigms. (...) The idea of operating multiple control mechanisms through compositions in nullspace paradigms. (...) The idea of operating multiple control systems through compositions in nullspace paradigms. (...) This idea is based on the fact that in many cases a zero space N is produced which is tangent to all gradients. (...) The idea of operating multiple control programs through compositions in nullspace paradigms."}, {"heading": "3.3 Continuous Control Parameterization", "text": "The situation presented in Wong et al. (2016) is an unfortunate assumption that the primitive motion control described by closed-loop controllers \u03c6 (2015) defines a static control goal. This particular form of goal is derived from cognitive developmental knowledge that allows networks to learn when to perform certain abstract skills that are presented as reflexive actions. However, the question that remains is how to encode how these skills are to be performed. Infants are willing to quickly learn their innate reflexive repertoire to recognize the functionality of their end effectors as entities corresponding to their hands via Palmar-Grasp reflex. Static parameterized learning goals allow rapid association-based learning, but not generalized to future tasks that require goals outside of innate reflex descriptions. As a result, both children and robots must learn useful parameters for their inert response to stimuli in the world."}, {"heading": "Jay M. Wong \u2014 Towards Lifelong Self-Supervision: A Deep Learning Direction for Robotics 13", "text": "Rewards have immediate connections and are analogous to an interaction-based knowledge repertoire that follows a series of task schedules and intrinsic motivational frameworks."}, {"heading": "4 Unsupervised Affordances", "text": "The development of an interaction-based knowledge repertoire in 1953 is an important structure that can be integrated into a number of algorithms that require forward models or predictions of future states. Fortunately, learning this action-centered knowledge is a close analogy of transition dynamics that is already part of these model-based acceleration techniques that are presented to make efficient use of experiences in reinforcement learning paradigms. As such, this structural appropriation has direct links to intrinsic motivators that seek to impart artificial curiosity to autonomous systems. Intrinsic motivators allow systems to build their own representations that reflect the inherent uncertainties of the system. Curiosity is important for learning systems - as without a sense of curiosity, learning becomes very task-specific and one-dimensional - the robot cannot choose to learn new skills, just a task-specific movement for a human-defined task."}, {"heading": "4.1 Predicting the Dynamics of the World", "text": "Based on ecological approaches to visual perception, the central concepts of Gibson's framework of perception are the terms affordance, an observable ecological context that generates a multitude of latent interactions. Affordances emphasize a relationship between actor and world and form an interactionist representation of perception, reflecting environmental signals in relation to an actor's ability to respond to these signals. Gibson, in the strongest sense, emphasizes the theory of direct perception, that the transformation from signal to behavior is expressed directly through neuronal projections that recognize possibilities for context-specific actions. Reed (1996); Turvey (1992). Such theories emphasize that they perceive themselves as a direct index into all possibilities for latent action in the environment. \"Gibson 1977, i.e. applicable actions and associated outcomes, are immediately recognized without necessarily identifying the object itself. Gibson's notion of affordances describes possibilities for action and can be regarded as an environment of the world state triggered by sensory inputs and interactions."}, {"heading": "Jay M. Wong \u2014 Towards Lifelong Self-Supervision: A Deep Learning Direction for Robotics 15", "text": "Similarly, Santana and Hotz (2016) trained a realistic, action-driven vehicle simulator using generative adversary networks. These video prediction mechanisms share a similar action-based approach to functional approximation as aspect transition networks given by fW: s. Further work presented by Agrawal et al. (2016) allowed a robot to gain over 400 hours of experience by poking different objects over 50,000 times, learning both an inverse and a forward-facing model of dynamics - the inverse model provided supervision to create informative visual features that were then used by the forward model to predict interaction outcomes. They refer to these precise models for multi-level decision making."}, {"heading": "4.2 Deriving Environmental Reward", "text": "A probable candidate for an ecological reward is one calculated by an information theory interpretation of affordance prediction networks (which correspond to understanding the system of interaction and dynamics of the world). (Suppose the robot interacts with the world by executing a series of control programs and receiving interaction stuples.) This, in turn, outlines some experience datasets described by Dt = {e1, e2, \u00b7 \u00b7 en \u00b2, with the control programs each consisting of ei = < s consisting of parameters leading to future states. (This, in turn, outlines some experience datasets described by Dt = {e1, e2, \u00b7 en} in which each level of experience consists of ei = < s in which future actions result.) Now we consider the class of reward structures that use uncertainty and the degree of understanding to punish or encourage new choices and behaviors."}, {"heading": "5 Implications for Task Planning", "text": "Perhaps one of the most recurrent themes in this manuscript is that there is probably no single method capable of solving all problems, especially those related to the development of artificial intelligence for physical robotic systems. Similarly, we can note that a candidate approach describes the marriage between several theses of thought. For example, consider a lifelong learning system that produces useful artifacts that can be evaluated by task planners - in the current climate, let's briefly imagine this idea. Obviously, we want robots to perform useful tasks or missions in the real world given their massive repertoire of motor skills and precise, learned representation of interaction dynamics in the world. As these representations and control strategies are all derived from the robot through intrinsic motivation, it encodes innate uncertainties that enable robust plans and the execution of actions. So obvious is it up to task planners to find plans for controlling and transitional dynamics."}, {"heading": "Jay M. Wong \u2014 Towards Lifelong Self-Supervision: A Deep Learning Direction for Robotics 17", "text": "Similarly, the network variants are good candidates for rapid evaluation of potential control contexts and the feasibility of certain parameters of action. Importantly, the control strategies and transition dynamics learned through lifelong intrinsic motivation do not in any way limit the use of more sophisticated planners. Dealing with unstructured and dynamic environments becomes a fundamental problem, and a number of frameworks have been adapted to function through uncertainties, such as the Active Belief Planner Ruiken et al. (2016b) and the faith space HPN Kaelbling and LozanoPe'rez (2013). A key finding is that many of these video prediction paradigms (as described in Section 4) can be interpreted as affordance models that predict all possible future interactions with the world - a promising advantage of using opposite, generative networks."}, {"heading": "6 Conclusion", "text": "This paper has provided an initial overview of recent developments in the world of the Internet, in the form of basic policies relating to the field of capture, control and control; we are discussing a number of challenges arising from the application to physical systems that would otherwise be unable to establish themselves in this area; and we have outlined these recent advances in the detection, control and future prediction of problems that are relevant to the development of robots; and we point out that technologies are now ripe for designing lifelong autonomous behavior in the real world. As such, acquisition can be used over a longer period of learning in numerous areas of research and industry."}, {"heading": "Acknowledgements", "text": "Although the author's relationship with the Charles Stark Draper Laboratory, Inc., exists, any opinions, findings, conclusions or recommendations expressed in this material are solely those of the author (s) and do not necessarily reflect the views of the organization. I would like to thank Takeshi Takahashi and Roderic A. Grupen for their expertise, enthusiasm, and insight into preparatory work with government-controlled prediction networks leading to this line of thinking. Finally, and most importantly, the state, structure, and direction of this manuscript would not be in its current form without the criticism and \"skepticism\" of my good friend Mitchell Hebert."}, {"heading": "Jay M. Wong \u2014 Towards Lifelong Self-Supervision: A Deep Learning Direction for Robotics 19", "text": "In: Experimental Robotics, pp. 149- 163.Devin C, Gupta A, Darrell T, Abbeel P and Levine S (2016) Learning-based full body control for the darpa robotics challenge and multi-robot transfer. arXiv preprint: 1609.07088.Feng S, Whitman E, Xinjilefu X and Atkeson CG (2015a). Optimization-based full body control for the darpa robotics challenge and multi-robot transfer. XiXiXi. Journal of Field Robotics 32 (2): 293-312.Feng S, Xinjilefu X, Atkeson CG and Kim J (2015b) Optimization-based controller design and implementation for the atlas robot challenge."}, {"heading": "Jay M. Wong \u2014 Towards Lifelong Self-Supervision: A Deep Learning Direction for Robotics 21", "text": "Lin LJ (1993) Reinforcement learning for robots using neural networks."}, {"heading": "Jay M. Wong \u2014 Towards Lifelong Self-Supervision: A Deep Learning Direction for Robotics 23", "text": "In: Proceedings of the Eighth International Workshop on Machine Learning. pp. E \"s\" s \"s\" s. \"S\" s \"s\" s. \"S\" s \"s.\" s \"s.\" s \"s.\" s \"s.\" s \"s.\" s \"s.\" s \"s.\" s \"s.\" s \"s\" s. \"s\" s \"s.\" s \"s\" s. \"s\" s. \"s\" s. \"s\" s. \"s\" s. \"s\" s. \"s\" s. \"s\" s \"s.\" s \"s\" s \"s\" s. \"s\" s \"s\" s. \"s\" s \"s\" s. \"s\" s \"s\" s. \"s\" s \"s.\" s \"s\" s. \"s\" s \"s.\" s \"s\" s. \"s\" s. \"s\" s. \"s\" s \"s.\" s \"s\" s \"s.\" s \"s\" s. \"s\" s \"s.\" s \"s\" s. \"s\" s \"s.\" s \"s\" s. \"s\" s \"s.\" s \"s\" s. \"s\" s \"s.\" s \"s\" s. \"s\" s \"s\" s \"s.\" s \"s\" s \"s.\" s \"s.\" s \"s\" s. \"s\" \"s\" s \"s\" s \"s\" s. \"\" s \"s\" s \".\" s \"s\" s \"s.\" \"s\" s \".\" \"s\" \"s\" s \"s\" s. \"s\" s \"s.\" s \"\" \"s.\" \"\" s \"\" s \"s\" \"\" s \"s\" s \"\" s. \"\" s \"\" s \"s\" s \"s.\" \"\" s \"s\" \"\" \"\" \"s\" \"\" s. \"\" s. \"\" \"\" \"\" s \"\" s \"s.\" \"s\" \"\" s. \"\". \"\" \"\" \"\" \"\" s \"s\" \"\" s \"s\" s \"s\" s \"s\". \".\" \"\" s \"\""}], "references": [], "referenceMentions": [], "year": 2016, "abstractText": "Despite outstanding success in vision amongst other domains, many of the recent deep learning approaches have evident drawbacks for robots. This manuscript surveys recent work in the literature that pertain to applying deep learning systems to the robotics domain, either as means of estimation or as a tool to resolve motor commands directly from raw percepts. These recent advances are only a piece to the puzzle. We suggest that deep learning as a tool alone is insufficient in building a unified framework to acquire general intelligence. For this reason, we complement our survey with insights from cognitive development and refer to ideas from classical control theory, producing an integrated direction for a lifelong learning architecture.", "creator": "LaTeX with hyperref package"}}}