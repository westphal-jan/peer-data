{"id": "1611.00356", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Nov-2016", "title": "Using Artificial Intelligence to Identify State Secrets", "abstract": "Whether officials can be trusted to protect national security information has become a matter of great public controversy, reigniting a long-standing debate about the scope and nature of official secrecy. The declassification of millions of electronic records has made it possible to analyze these issues with greater rigor and precision. Using machine-learning methods, we examined nearly a million State Department cables from the 1970s to identify features of records that are more likely to be classified, such as international negotiations, military operations, and high-level communications. Even with incomplete data, algorithms can use such features to identify 90% of classified cables with &lt;11% false positives. But our results also show that there are longstanding problems in the identification of sensitive information. Error analysis reveals many examples of both overclassification and underclassification. This indicates both the need for research on inter-coder reliability among officials as to what constitutes classified material and the opportunity to develop recommender systems to better manage both classification and declassification.", "histories": [["v1", "Tue, 1 Nov 2016 19:59:48 GMT  (642kb)", "http://arxiv.org/abs/1611.00356v1", null]], "reviews": [], "SUBJECTS": "cs.CY cs.CL cs.LG", "authors": ["renato rocha souza", "flavio codeco coelho", "rohan shah", "matthew connelly"], "accepted": false, "id": "1611.00356"}, "pdf": {"name": "1611.00356.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Rohan Shah", "Matthew Connelly"], "emails": [], "sections": [{"heading": null, "text": "The declassification of millions of electronic records has made it possible to analyze these issues with greater care and precision. Using machine learning methods, we examined nearly one million State Department cables from the 1970s to identify features of records that are more likely to be classified, such as international negotiations, military operations, and high-level communications. Even with incomplete data, algorithms can use these features to identify 90% of classified cables with < 11% false positives. But our results also show that there have long been problems in identifying sensitive information. Error analyses show many examples of both over-classification and under-classification, demonstrating both the need for research on reliability between coders among officials, which constitutes classified material, and the ability to develop recommendation systems to better manage both classification and declassification."}, {"heading": "Main Text:", "text": "In fact, it is the case that most of the people who have gone into politics in recent years have put themselves at the centre. (...) It is not that they have been able to survive themselves. (...) It is not that they have outlived themselves. (...) It is that they have outlived themselves. (...) It is that they have outlived themselves. (...) It is that they have outlived themselves. (...) It is that they have outlived themselves. (...) It is as if they have outlived themselves. (...) It is as if they have outlived themselves. (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (. (...). (.). (...). (). (...). (. (). (.). (.). (). (. (.). (.). (.). (.). (. (). (.). (). (.). (). (.). (. (). (.). (.). (.). (). (.). (). (). (.). (). (.). (). (.). (). (). (). (). (). (.). (). (). (). (). (). (). (). (. (). (). (). (). (). (). (). (). (). (). (). (. (). (). (). (). (). (). (). (. (). (). (). (). (). (). (). (). (). (). (). (). (). (). (). (). (). (). (). (). (). (). (). (). (). (). (). (). (). (). (). (). (). (). (). (). ()."}, {"heading": "Materials and Methods:", "text": "This year, it is more than ever before in the history of the city, where it has gone down in history as never before."}, {"heading": "What Makes Secret Cables Different?", "text": "In fact, it is the case that most people who are able to protect themselves must put themselves and themselves at the centre. (...) Most of them have a purely qualitative analysis based on an approach that allows for multiple combinations of variables and different weight classes. (...) And when we determine the characteristics that are most useful, we can look more closely at the way in which the individual groups are brought together. (...) It is not the case that the individual groups are able to identify themselves. (...) It is as if it is the individual groups that are involved. (...) It is as if it is the individual groups that are involved. (...) It is as if it is groups that are involved. (...) It is as if it is groups that are involved, as if it is (it is) about. (It is) whether it is (it is) about."}, {"heading": "Results:", "text": "This year, it has come to the point that it has never come as far as it has this year."}, {"heading": "Discussion:", "text": "This year, it has come to the point that it has never come as far as it has this year."}, {"heading": "Acknowledgements", "text": "This year it is more than ever before in the history of the city."}, {"heading": "Data acquisition and preparation", "text": "The Central Foreign Policy Files available from the U.S. National archives contain both cables and so-called p-reel records, i.e. communications physically sent through diplomatic bags. Both are either fully available or have been \"withdrawn\" because the recording contains either sensitive national security information or personal information. Both p-reel records and retracted cables have limited metadata, but no message text. We limited our analysis to cables that have been fully declassified. The metadata contains the original classification (origclass), i.e. secret, confidential, restricted official use, and not secret. Cables with zero, degenerated, or misspelled names of classes inorigclass were omitted from the analysis."}, {"heading": "Table S1:", "text": "Cable number and classification by cable type Cable _ type e feldTotal in DatabaseUnclassified Limited Official UseConfidential Secret Zero or degeneratedFull cable 1,758,279 876,797 411,973 375,690 93,635 184 P-reel 505,030 419,052 33,887 28,695 14,716 0 Retracted cables 410,539 298,932 25,988 25,816 21,474 38,329 P-reel withdrawn 8,920 3,538 570 2,277 2,304 231Draft only -- Not for circulation without author's permissionWe first analyzed the cables to determine which fields might be useful as input characteristics. Feature engineering included analysis of text quality; discovery of the most common values for each class; and definition of the subset valid for testing. The fields a posteriori added to create the cable were not used because they contained information related to the sweetening."}, {"heading": "Table S2:", "text": "Explanation of the fields used in ClassifierUsed Fields Descriptionorigclass The original classification level of the cable harness Full text of the cable harness topic covered in the document. conceptual keywords used in the document TAGS Traffic Analysis by Geography and Subject from which person / what office sent the document. to which person / what office received the document. office which State Department office or bureau was responsible for the document. date Document Creation DateNot all cables that display cable field in its entirety have useful content in the body. Some of them exhibit errors in the digitization process and, like their bodies, have only small error messages, as illustrated in Table S3.Draft -- Not for distribution without authorization"}, {"heading": "Table S3:", "text": "Review of Error Types in the Complete Cable Data Set and Number of ClassifiedType of Errors in DigitizationTotal in DatabaseUnclassified Limited OfficialUseConfidential Secret \"Error Reading Text Index\" 46,876 13,931 6,241 11,592 15,112 \"Expand Error Encountered\" 72,850 39,988 15,499 13,723 \"Encryption Error\" 42 22 10 0 Total (Errors are not exclusive) 119,744 53,935 21,744 25,233 18,832 The tests were aimed at predicting the level of sensitivity in a binary way; therefore, we have tested binary aggregations (here scenarios) of the four classes that they group according to broad or narrow definitions of secrecy. (S) ecret, (C) onfidential, (L) imitated Official Use and (U) nclassified. Additional tests using four classes as targets were also performed, but the selected subjects were not classified."}, {"heading": "Feature vectors", "text": "Like Lead et al. (Lead 2003), we define the following terms: A word or token is the basic unit of discrete data, defined as an element of a vocabulary indexed by {1,..., N}. Words are represented by vectors that have a single component equal to zero. A document vector is a sequence of N-word numbers denoted by w = (w1, w2,..., wN), where wn is the n-th word in the sequence and N is the size of the vocabulary equal to zero. A document vector is a sequence of N-word numbers denoted by w = (w1, w2,..., wN), where wn is the n-th word in the sequence and N is the size of the vocabulary. A corpus is a collection of M-documents denoted by D = {w11, w21, wN1], wN1, wNulary, vocular, etc."}, {"heading": "Table S.4:", "text": "Overview of Analytical Parameters vs. Feature TypesNumber of TokensVocabulary Size (N) Max. vector size (N ') Best n-gram rangeBest vectorization axis 6,894,992 180,480 8,000 (1.1) Term frequency concepts 4,929,265 13,192 650 (1.2) Term frequencies Body 259,276,062 1,929,902 15,000 (1.1) Term frequencies TAGS 3,272,125 939 844 (1.1) Term frequencies Messages (from / to) 2,234,457 4,874 1,036 (1.1) Term frequencies Office 1,937,707 261 170 (1.1) Term frequencies All texts 278,544,608 1,968,680 15,000 (1.1) Term frequencies"}, {"heading": "Classifiers and Ensembles", "text": "Draft Only -- Not for circulation without authorization We conducted extensive tests with different classifiers: Linear Models (Logistic Regression, Passive Aggressive, Stochastic Gradients Descent, Ridge Regression; Perceptron); Support Vector Machines (Linear SVC); K-Nearest Neighbors; Bayesian Approaches (Bernoulli Naive Bayes, Multinomial Naive Bayes); Ensembles of Classifiers (Random Forests, Extremely Randomized Trees) and combined techniques such as bagging and boosting (Bagging Classifier, Gradient Boosting, AdaBoost and Weighted Tuning Approaches). For more information on these different approaches, see supplementary references. To select the best classifiers for the task, a predictive comparison was conducted in advance, combining all textual features and using the scenario [U (Class 0) versus L, C, S (Class 1)]."}, {"heading": "Table S5:", "text": "Performance of All Classifiers Across Various MeasuresClassifier ROC / AUC ScoreAccuracy ScorePrecision (Class 0 / 1) Recall (Class 0 / 1) F1 Score (Class 0 / 1) 0.77 0.8462 / 0.83380.76 / 0.8576 (Class 0 / 0.88) Recall (Class 0 / 0.83 / 0.86) F1 Score (Class 0 / 0.89) (0.81 / 0.89) / 0.89) (0.79 / 0.88) Logistic Regression 0.8457 / 0.8434 (Class 8569 / 0.8574) (Class 883 / 0.88) (0.80 / 0.89) (0.89 / 0.89) (0.79 / 0.88) Logistic Regression 0.8457 / 0.8457 (0.8484) (Class 8484 / 0.83 / 0.8574 (Class 8583 / 0.88) (0.82 / 0.88)"}, {"heading": "Evaluation of Results", "text": "Table S6 shows the performance of the classifier for the three combinations of the classes usingeach feature as input and two feature combinations.The fields body, subject, concepts, tags, message and office were combined in a new field / feature all _ text, which was tested as an alternative to the combination of all other features by concatenating these vectors.All vectors were created using plain count BoW. All measurements are calculated as the mean of the three folds using layered k-folds.Design only -- Not for distribution without authorization"}, {"heading": "Table S6:", "text": "Performance of the classifier in different capacities according to characteristic type"}, {"heading": "Feature Class", "text": "CombinationROC / AU C ScoreAccuracy Score Precision (class 0 / 1) 0.84 / 84 0.84 / 92 0.84 / 84 0.84 / 93 f1-scoreSubject (U vs L, C, S) 0.79 0.82 0.81 / 0.82 0.68 / 0.91 0.74 / 0.86 (U, L vs C, S) 0.81 vs 93 0.83 0.85 / 0.77 0.89 / 0.72 0.87 / 0.74 (U, L, C vs S) 0.70 0.96 0.99 / 0.80 0.40 0.98 / 0.53Concepts (U vs L, C, S, S, S, S, S) 0.72 0.83 0.75 0.69 / 0.77 0.77 (U, L vs C, C vs C) 0.78 0.80 / 0.74 0.89 / 0.99 / 0.40 0.65 (U vs L, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S) 0.72 0.83 0.69 / 0.69 (U, S vs C) 0.77 / 0.59 (U, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S vs L, S, S, S, S, S, S, S, S, S, S, S, S"}, {"heading": "Figure S1:", "text": "AUC points only for all FeaturesDraft -- Not for distribution without authorization"}, {"heading": "Figure S2:", "text": "Precision versus recall for each feature and the combination of attributes The use of all attributes resulted in the best results in all scenarios, closely followed by the summation of the text fields, then the body and the subject. The other attributes alone did not perform well."}, {"heading": "Discussion", "text": "Results above 80% on classification tasks are generally considered good (e.g. the Netflix challenge, where the best score was about 85%) (Netflix 2009), but whether such results are appropriate depends on the task at hand. If our priority is to protect sensitive information and we want to minimize the number of false negatives, i.e. cables that are predicted only as unclassified designs -- Not for distribution without authorization, but actually classified, the classification thresholds could be changed at the expense of the increase in false positives. Our current developments point to future improvements in the classifier. We are testing the implementation of an artificial neural network, exploring new features, and developing methods to correct errors in the metadata (original classes), which could further improve the results."}, {"heading": "Supplementary References", "text": "Breiman, Leo. \"Bagging predictors.\" Machine learning 24, no. 2 (1996): 123-140. Breiman, Leo. \"Random forests.\" Machine learning 45, no. 1 (2001): 5-32. Crammer, Koby, Ofer Dekel, Joseph Keshet, Shai Shalev-Shwartz, and Yoram Singer. \"Online passive-aggressive algorithms.\" Journal of Machine Learning Research 7, no. Mar. (2006): 551-585. Fan, Rong-En, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui Wang, and Chih-Jen Lin. \"LIBLINEAR: A library for large linear classification.\" Journal of machine learning research 9, no. Aug (2008): 1871-1874. Fix, Evelyn, and Joseph L. Hodges Jr. \"Discriminatory analysis-nonparametric discrimination: consistency."}], "references": [{"title": "Online passive-aggressive algorithms.\" \u200bJournal of Machine Learning Research", "author": ["Crammer", "Koby", "Ofer Dekel", "Joseph Keshet", "Shai Shalev-Shwartz", "Yoram Singer"], "venue": null, "citeRegEx": "Crammer et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Crammer et al\\.", "year": 2001}, {"title": "LIBLINEAR: A library for large linear classification.\" \u200b", "author": ["Rong-En", "Kai-Wei Chang", "Cho-Jui Hsieh", "Xiang-Rui Wang", "Chih-Jen Lin"], "venue": null, "citeRegEx": "Rong.En et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Rong.En et al\\.", "year": 2006}, {"title": "Large margin classification using the perceptron algorithm.\" \u200bMachine learning", "author": ["Freund", "Yoav", "Robert E. Schapire"], "venue": null, "citeRegEx": "Freund et al\\.,? \\Q1951\\E", "shortCiteRegEx": "Freund et al\\.", "year": 1951}, {"title": "Extremely randomized trees.\" \u200b", "author": ["Geurts", "Pierre", "Damien Ernst", "Louis Wehenkel"], "venue": null, "citeRegEx": "Geurts et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Geurts et al\\.", "year": 2001}, {"title": "On linear discriminant analysis with adaptive ridge classification rules.", "author": ["Loh", "Wei-Liem"], "venue": "Journal of Multivariate Analysis", "citeRegEx": "Loh and Wei.Liem.,? \\Q2006\\E", "shortCiteRegEx": "Loh and Wei.Liem.", "year": 2006}, {"title": "Dual coordinate descent methods for logistic regression and maximum entropy", "author": ["Hsiang-Fu", "Fang-Lan Huang", "Chih-Jen Lin"], "venue": null, "citeRegEx": "Hsiang.Fu et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Hsiang.Fu et al\\.", "year": 2003}, {"title": "Transforming classifier scores into accurate multiclass probability estimates.\" In \u200bProceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining", "author": ["Zadrozny", "Bianca", "Charles Elkan"], "venue": null, "citeRegEx": "Zadrozny et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Zadrozny et al\\.", "year": 2011}, {"title": "Multi-class adaboost.\" \u200b", "author": ["Zhu", "Ji", "Hui Zou", "Saharon Rosset", "Trevor Hastie"], "venue": null, "citeRegEx": "Zhu et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Zhu et al\\.", "year": 2002}], "referenceMentions": [], "year": 0, "abstractText": "Whether officials can be trusted to protect national security information has become a matter of great public controversy, reigniting a long-standing debate about the scope and nature of official secrecy. The declassification of millions of electronic records has made it possible to analyze these issues with greater rigor and precision. Using machine-learning methods, we examined nearly a million State Department cables from the 1970s to identify features of records that are more likely to be classified, such as international negotiations, military operations, and high-level communications. Even with incomplete data, algorithms can use such features to identify 90% of classified cables with <11% false positives. But our results also show that there are longstanding problems in the identification of sensitive information. Error analysis reveals many examples of both overclassification and underclassification. This indicates both the need for research on inter-coder reliability among officials as to what constitutes classified material and the opportunity to develop recommender systems to better manage both classification and declassification.", "creator": null}}}