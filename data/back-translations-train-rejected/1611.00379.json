{"id": "1611.00379", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Nov-2016", "title": "The Machine Learning Algorithm as Creative Musical Tool", "abstract": "Machine learning is the capacity of a computational system to learn structures from datasets in order to make predictions on newly seen data. Such an approach offers a significant advantage in music scenarios in which musicians can teach the system to learn an idiosyncratic style, or can break the rules to explore the system's capacity in unexpected ways. In this chapter we draw on music, machine learning, and human-computer interaction to elucidate an understanding of machine learning algorithms as creative tools for music and the sonic arts. We motivate a new understanding of learning algorithms as human-computer interfaces. We show that, like other interfaces, learning algorithms can be characterised by the ways their affordances intersect with goals of human users. We also argue that the nature of interaction between users and algorithms impacts the usability and usefulness of those algorithms in profound ways. This human-centred view of machine learning motivates our concluding discussion of what it means to employ machine learning as a creative tool.", "histories": [["v1", "Tue, 1 Nov 2016 20:35:46 GMT  (241kb,D)", "http://arxiv.org/abs/1611.00379v1", "Pre-print to appear in the Oxford Handbook on Algorithmic Music. Oxford University Press"]], "COMMENTS": "Pre-print to appear in the Oxford Handbook on Algorithmic Music. Oxford University Press", "reviews": [], "SUBJECTS": "cs.HC cs.LG", "authors": ["rebecca fiebrink", "baptiste caramiaux"], "accepted": false, "id": "1611.00379"}, "pdf": {"name": "1611.00379.pdf", "metadata": {"source": "CRF", "title": "The Machine Learning Algorithm as Creative Musical Tool", "authors": ["Rebecca Fiebrink", "Baptiste Caramiaux"], "emails": ["r.fiebrink@gold.ac.uk", "b.caramiaux@gold.ac.uk"], "sections": [{"heading": "1 Introduction", "text": "Machine learning algorithms are behind some of the most widespread and powerful technologies of the 21st century. Accurate speech recognition, robotic control, and shopping recommendations are among the most impressive achievements of machine learning in recent times. Like other universal computer tools, machine learning has captured the imagination of musicians and artists since its inception. Sometimes, musicians politely borrow existing machine learning algorithms and use them exactly as they were intended, providing numerous well-chosen examples of a phenomenon and then using an appropriate algorithm to precisely model or detect that phenomenon. Sometimes, musicians break the rules and use existing algorithms in unexpected ways, perhaps by not using machine learning to accurately model a phenomenon implicit in the data, but to discover new sounds or new relationships between human performers and computer-generated processes. In other cases, music researchers have formulated their own new definitions of what it means for a computer to learn this, to perform this learning with new algorithms, and to create new ways of learning specific to it."}, {"heading": "1.1 What is this Chapter?", "text": "This chapter focuses on music, machine learning and human-computer interaction to provide an understanding of machine learning algorithms as creative tools for music and the sound arts. Machine learning algorithms can be used to achieve autonomous computer generation of musical content, a goal explored from different perspectives in other chapters of this book. However, our main focus is on how machine learning can support these activities and be shaped by algorithmic processes. This chapter provides readers who are beginners in machine learning, experts, or somewhere in between, with new ways of thinking about machine learning. We start with a brief overview of different types of machine learning by writing programming code, and offer a friendly introduction to machine learning processes."}, {"heading": "1.2 Learning More about Machine Learning and Music", "text": "We will not discuss machine learning outside the context of electronic, electroacoustic, and / or experimental music production; readers with a more general interest in machine learning for recommending and analyzing music should find David Cope's work stimulating (e.g. Cope and Mayer [1996]); machine learning of accompanying music (e.g. Raphael [2001]) and expressive rendering of scores (e.g. the Rencon workshop, Hiraga et al. [2004]); and finally, readers who are new to machine learning and interested in learning more (albeit from a conventional, not art-centric perspective) should use textbooks by Witten and Frank [2005] for a practical introduction; or Bischof [2006] for a more thorough understanding of such methods to improve understanding of techniques."}, {"heading": "2 Machine Learning as a Tool for Musical Interaction", "text": "A major advantage of machine learning is that it enables us to cope with increasingly complex musical scenarios using advances in computation and / or data resources. In this section, we begin by describing the benefits of machine learning for these types of scenarios at a very high level and introduce the basic terms needed to describe the learning process. We then offer a practical perspective on how different families of algorithms - each with their own approach to learning from data - enable us to achieve common musical goals."}, {"heading": "2.1 From Executing Rules to Learning Rules", "text": "Creating algorithms for making music can be thought of as defining rules that then determine the behavior of a machine. For example, mapping rules can be defined between input data (such as sounds or gestures performed by a human musician) and output values (such as sounds generated by a computer). Although the explicit definition of these rules provides complete control over the elements in the game, there are complex situations in which execution rules cannot be explicitly defined or where defining a comprehensive set of rules would be too time consuming. An alternative approach is to learn these rules using examples. For example, a gesture mapping can be defined by providing examples of input requests paired with the output concrete that should be generated for this gesture. Using a learning algorithm to learn these rules has several advantages. First, it can make creating input data practicable if the desired manual formulations are too complex or if they are too loud to be described by highly analytical or by highly analytical applications."}, {"heading": "2.2 Learning from Data", "text": "A learning algorithm builds a model from a set of training examples (the training set), which can be used to make predictions or decisions, or to better understand the structure of the data, and its exact nature depends on the type of learning algorithm used, as we explain below. A training data set typically consists of many sample data points, each of which is presented as a list of numerical attributes. A feature can be thought of as a simple, informative measurement of the raw data. For example, an audio analysis system could describe each audio example based on characteristics related to pitch, volume, and timbre. A gesture analysis system could describe each example of human pose based on (x, y, z) coordinates of each hand in 3D space."}, {"heading": "2.2.1 Supervised learning", "text": "In \"Supervised Learning\" (Figure 1), the algorithm builds a model of the relationship between two types of data: input data (i.e. the feature list for each example) and output data (sometimes called \"labels\" or \"targets\").The training data set for an assisted learning problem includes examples of input-output pairs. Once trained, the model can calculate new outputs in response to new inputs (Figure 2).For example, a musician who wants to associate different hand positions captured by a video camera with different notes played by a computer can construct a training set by recording several examples of a first-hand position and labeling each with the desired note, e.g. \"A #.\" She can then record examples of a second-hand position by labeling each with a different note, e.g. \"F.\" The training process learns what distinguishes an \"A #\" hand \"from a\" hand \"position\" when it can be used as a position after the two musicians."}, {"heading": "2.2.2 Unsupervised learning", "text": "In unattended learning (Figure 3), the algorithm learns only the internal structure of the input data; no corresponding output markers are provided. A musician can use unattended learning to simply discover structure within the training set, for example, to identify latent clusters of perceptibly similar sound samples within a large sample database, or to identify common chord gradients within a database of scores. A musician could use this learned structure to generate new examples similar to those in the database, or use this learned structure to provide better characterization representations for further supervised learning or other processing. We return to this topic in Section 2.3.4. Let's consider once again our musician who wants to play music by performing different hand positions in front of a video camera, but this time she does not know beforehand how to define a suitable feature representation for hand positions. She could use the computer examples of different hand positions, with no note marker algorithms, to identify an unattended cluster."}, {"heading": "2.2.3 Other types of learning", "text": "Although most machine learning applications in music use monitored or unattended learning algorithms, other families of algorithms exist; for example, some training examples for semi-monitored learning include output labels, while others do not. This approach is supported by the fact that providing output labels for each input in the training set can be difficult and time consuming. Our hand positioning instrument designer could create a large, unlabeled example by moving her hand in front of the camera without providing additional information, then selecting a few stills from that data set and adding labels showing what note should be played for those hand positions. She could then apply a semi-monitored learning algorithm to create her hand position classifier, with the algorithm learning from the labeled examples how to match inputs with notes, but also benefiting from the numerous unlabeled examples that provide more information about the nature of inputs that are likely to come across."}, {"heading": "2.3 Algorithms and Musical Applications", "text": "In the previous section, we outlined the most basic ideas of how different learning algorithms learn from data. Numerous textbooks describe how certain algorithms actually accomplish this learning, so we refer readers interested in such details to the resources mentioned in Section 1.2. At this point, however, we turn to a discussion of how these general approaches to machine learning can be reconciled with different types of musical goals. Specifically, we examine five goals that are relevant to many musical systems: Detect, Map, Track, Discover New Data Representations, and Collaborate."}, {"heading": "2.3.1 Recognise", "text": "Many types of music systems could take advantage of a computer's ability to recognize physical gestures, audio patterns, or other relevant behaviors of a musician. To achieve this, monitored learning algorithms can be used to perform classifications, and such interactions can be used to create new gesture-controlled musical instruments. Modler [2000] describes several hand-controlled instruments that use neural networks to classify hand positions. Specific hand positions measured with a sensor glove have been used to start and stop sound syntheses, design a physical model, or select control modes for a granular synthesis algorithm. Gesture recognition can also be used to increase the performance of existing musical instruments. Thus, Gillian and Nicolls [2015] use an adaptive naive Bayes classifier to detect a number of signal types relevant to pianist postures to allow other types of musical positions to respond to the reactions of typical reactions of the music machine during these live reactions, or to respond to the reactions of the usual reactions of the music settings."}, {"heading": "2.3.2 Map", "text": "Machine learning can also be used to map input values in a domain to output values in the same or another domain. Mapping has been extensively studied in the creative area of gesture-driven control of sound synthesis, where characteristics of a musician's gesture are measured and mapped using sensors to control the parameters of sound synthesis [Wanderley and Depalle, 2004]. Other musical applications include generating images from sound or vice versa [Fried and Fiebrink, 2013] and creating sound-to-sound mappings for the audio mosaic and reproduction of sound colors [Stowell, 2010]. Designing a mapping function to generate outputs in response to inputs is a difficult task, especially for the many musical applications where inputs and outputs are high dimensional. The space for possible mappings is vast, and it is difficult to know what form a mapping should take to fulfill the system designer's overall goals."}, {"heading": "2.3.3 Track", "text": "Some systems that react to human actions not only recognize that an action has taken place, or reproduce a machine behavior from a given human state. Musical applications can benefit from the machine understanding of how an action is performed, that is, by following an action and its characteristics over time. Finally, in many forms of musical activity, it is the dynamics of an action that communicates musical expression and expertise. Sequences of scores are a common type of tracking problem where the goal is to align a person's musical performance - specifically, the audio signal of that performance - to a score. Sequences of scores enable the synchronization of electronic events to an acoustic piece whose performance is subject to expressive changes by a human performer (e.g. Cont [2010])."}, {"heading": "2.3.4 Discover New Data Representations", "text": "We can also use learning algorithms to detect structures within a collection of sound samples, scores, recordings of human movements, or other data. Unmonitored algorithms can detect latent clusters of similar objects and map elements into low-dimensional spaces that retain certain structural characteristics, techniques commonly used to facilitate human surfing and navigation of datasets, such as self-organizing maps that can be used to create 2D interfaces for audio browsing and real-time audio playback [Smith and Garnett, 2012] where perceptibly similar sounds appear close to each other in space. Supervised approaches such as metric learning can also be used to guide the representation learned to more closely match the perception of similarities between sounds or other data elements (e.g. [Fried et al., 2014])."}, {"heading": "2.3.5 Collaborate", "text": "Another category of application is that the computer assumes a role more akin to a human music collaborator, imbued with \"knowledge\" of music style, structure, or other characteristics that are difficult to express with explicit rules. Constructing an artificial music collaborator often requires the computer to understand the sequences of human actions, and / or to generate appropriate sequences itself. Therefore, algorithms are used for the likely modeling of sequences in this context, including Markov processes and their expansions, including the hierarchical and variable length of Markov models (e.g. Ames, 1989; Conklin, 2003)."}, {"heading": "3 Machine Learning Algorithm as Interface", "text": "Different machine learning algorithms make different assumptions about what it means to learn and how data can be used in the learning process, and it is not always clear which algorithm is best suited to a problem. Algorithms can be slowed down by noisy data, by too little data, by poor representation of characteristics. Calculation perspectives on these challenges are easy to find both in machine learning textbooks and in machine learning research literature. In this section, we describe how applied machine learning can be understood as a kind of interface - not as a graphical user interface, but as a more fundamental human-computer relationship in which a user's intentions for computer behavior are conveyed by a learning algorithm and by the model that produces it."}, {"heading": "3.1 Affordances of Learning Algorithms", "text": "The term \"affinity\" was coined by the perceptual psychologist Gibson, and it is now used in HCI to discuss the way in which an object - for example, a software program, a user interface element, a chair - can be used by a human actor. Gaver [1991] defines affordability for an HCI reader as \"characteristics of the world defined in terms of interaction with it. Most fundamentally, affordability is defined as characteristics of the world that enable action for an organism equipped to act.\" McGrenere and Ho [2000] write about the historical use and adaptation of the concept within the HCI community, encompassing several \"fundamental characteristics\" of a person that enable such action."}, {"heading": "3.1.1 Defining and shaping model behaviour through data", "text": "An example of this is the fact that most of them are able to determine for themselves what they want to do."}, {"heading": "3.1.2 Exposing relevant parameters", "text": "Many parameters of the algorithm are notoriously difficult to determine with human intuition alone: For example, the parameters of support vector machines (SVMs) (including core selection, complexity parameters, others; see Witten and Frank [2005]) can significantly affect the ability to model a data set accurately. People who use machine learning in musical contexts often care about the characteristics of models that cannot be adequately measured with automated empirical tests, and they do not manipulate them simply by selecting the training data set [Fiebrink et al., 2011]. Sometimes learning algorithms can uncover parameters that allow users to more directly control characteristics they are interested in. Algorithms that train iterative optimization often represent a trade-off between training time and accuracy."}, {"heading": "3.1.3 Modelling temporal structure", "text": "In fact, most of them are able to determine for themselves what they want and what they want to do."}, {"heading": "3.1.4 Running and adapting in real-time", "text": "In many musical contexts, trained models need to respond to a performer's actions in real time. Therefore, it is often necessary to select or adapt machine learning algorithms so that the models they produce have sufficient real-time responsiveness. An unavoidable challenge is that time models that analyze real-time input sequences must constantly respond and adapt to a sequence before it is complete. A real-time accompaniment or control system may need to generate sound while a performer is playing or moving, rather than waiting for a phrase or gesture to finish, which may require a change in computational approach compared to offline contexts. For example, algorithms that analyze a sequence as it unfolds in time (such as the forward sequence algorithm for HMMs) may be less accurate than algorithms that have access to the full sequence (such as Viterbi Miner for HMM 1989; see HMM)."}, {"heading": "3.2 Interactive Machine Learning", "text": "In fact, most people are able to decide for themselves what they want and what they want."}, {"heading": "3.3 A Human-Centred Perspective on Machine Learning", "text": "We have shown that these algorithms (and the models they create) offer musicians, composers, and interaction designers relevant ways to achieve their musical goals (we also refer to Bullock's chapter in this book [Bullock, 2017], which provides a complementary discussion of interface design in music).A human-centered view requires that we consider the goals of human action as they build and modify a model (we also refer to Bullock's chapter in this book [Bullock, 2017], which provides a complementary discussion of interface design in music)."}, {"heading": "4 Machine Learning as Creative Tool", "text": "Applying a human-centered perspective to the analysis of machine learning in the context we have outlined in Section 3 shifts the focus from technical machines to human goals and intentions. As we will argue next, this shift in perspective opens up new possibilities for understanding and better supporting creative practice."}, {"heading": "4.1 Roles of Machine Learning in Creative Work", "text": "A number of works that are being discussed in terms of the way in which they are carried out are proving to be insufficient."}, {"heading": "4.2 A Comparison with Conventional Machine Learning", "text": "We conclude this section with a summary of the common goals and divergences between a \"conventional\" perspective of machine learning (i.e. the perspective implicit in most machine learning textbooks) and an understanding of machine learning as a creative tool. Both perspectives are relevant to creative practitioners who want to apply learning algorithms effectively in practice, and both can influence advances in research in the field of musical machine learning."}, {"heading": "4.2.1 Commonalities", "text": "Indeed, in many areas, machine learning algorithms are being used to gain new insights into data that is otherwise poorly understood by humans. \"Big data\" is leading to new discoveries in the fields of astronomy, high-energy physics, and molecular biology. \"The discovery of the latent structure in music can support the creation of new interfaces for human exploration, although the goal of these interfaces is often to create new interactions rather than to understand them.\""}, {"heading": "4.2.2 Differences", "text": "In fact, it is such that most of them will be able to survive themselves without a process occurring in which a process occurs, in which a process occurs, in which a process occurs, in which a process occurs, in which a process occurs, in which a process occurs, in which a process occurs, in which a process occurs, in which a process occurs, in which a process occurs, in which a process occurs, in which a process, in which a process occurs, in which a process occurs, in which it occurs, in which it occurs, in which it occurs, in which it occurs, in a process, in which it occurs, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process, in a process"}, {"heading": "5 Discussion", "text": "In fact, it is the case that most people who are able are able to determine for themselves what they want and what they do not want."}], "references": [], "referenceMentions": [], "year": 2016, "abstractText": "Machine learning is the capacity of a computational system to learn structures from datasets in order to make predictions on newly seen data. Such an approach offers a significant advantage in music scenarios in which musicians can teach the system to learn an idiosyncratic style, or can break the rules to explore the system\u2019s capacity in unexpected ways. In this chapter we draw on music, machine learning, and humancomputer interaction to elucidate an understanding of machine learning algorithms as creative tools for music and the sonic arts. We motivate a new understanding of learning algorithms as human-computer interfaces. We show that, like other interfaces, learning algorithms can be characterised by the ways their affordances intersect with goals of human users. We also argue that the nature of interaction between users and algorithms impacts the usability and usefulness of those algorithms in profound ways. This human-centred view of machine learning motivates our concluding discussion of what it means to employ machine learning as a creative tool.", "creator": "LaTeX with hyperref package"}}}