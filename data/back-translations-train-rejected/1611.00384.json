{"id": "1611.00384", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Nov-2016", "title": "The Deep Journey from Content to Collaborative Filtering", "abstract": "In Recommender Systems research, algorithms are often characterized as either Collaborative Filtering (CF) or Content Based (CB). CF algorithms are trained using a dataset of user explicit or implicit preferences while CB algorithms are typically based on item profiles. These approaches harness very different data sources hence the resulting recommended items are generally also very different. This paper presents a novel model that serves as a bridge from items content into their CF representations. We introduce a multiple input deep regression model to predict the CF latent embedding vectors of items based on their textual description and metadata. We showcase the effectiveness of the proposed model by predicting the CF vectors of movies and apps based on their textual descriptions. Finally, we show that the model can be further improved by incorporating metadata such as the movie release year and tags which contribute to a higher accuracy.", "histories": [["v1", "Tue, 1 Nov 2016 20:48:34 GMT  (2221kb)", "http://arxiv.org/abs/1611.00384v1", null]], "reviews": [], "SUBJECTS": "cs.IR cs.CL cs.LG", "authors": ["oren barkan", "noam koenigstein", "eylon yogev"], "accepted": false, "id": "1611.00384"}, "pdf": {"name": "1611.00384.pdf", "metadata": {"source": "META", "title": "Microsoft Word - cb2cf_arxiv.docx", "authors": ["Oren Barkan", "Noam Koenigstein", "Eylon Yogev"], "emails": [], "sections": [{"heading": null, "text": "In Recommender Systems research, algorithms are often characterized as Collaborative Filtering (CF) or Content Based (CB). CF algorithms are trained on a dataset of explicit or implicit preferences, while CB algorithms are typically based on item profiles. These approaches use very different data sources, making the resulting recommended items generally very different as well. In this paper, a novel model is presented that serves as a bridge between item content and its CF representations. We introduce a multiple input depth regression model to predict the latent embedding of items based on their text description and metadata. We demonstrate the effectiveness of the proposed model by predicting the CF vectors of movies and apps based on their text descriptions. Finally, we show that the model can be further improved by including metadata such as film release and higher accuracy."}, {"heading": "1. INTRODUCTION", "text": "A common approach in CF is to learn a low-dimensional latent space that captures the user's preferences or \"taste.\" An alternative to the CF approach is the approach that uses items such as metadata and items, etc. CF approaches are generally accepted as more precise than CB approaches. Our goal is to predict the CF representation of items based on their CB profiles. CB profiles are obtained from multiple sources such as items and item descriptions."}, {"heading": "2. RELATED WORK", "text": "In fact, most people who are in the city are not able to understand themselves."}, {"heading": "3. MULTIPLE INPUT DEEP REGRESSION", "text": "In this section we provide a detailed description of the proposed model."}, {"heading": "3.1 Text Components", "text": "The text components are designed to receive a fixed size vector as input and output. In this work, we implement two different types of text components: \"CNN\" and \"BOW\" (marked in red in Fig. 1). The CNN approach follows Kim's \"CNN non-static\" model from [7]. As explained earlier, we map the word sequence in the textual input to a matrix that serves as input to a CNN network. An image of this approach (taken from [7]) appears in Fig. 1 (d). We note that the back propagation process continues through CNN to the original word2vec representation, which allows the word to be freely embedded in relation to the present CF prediction task. Therefore, the initial mapping2w vM method is refined throughout the training process."}, {"heading": "3.2 Tags Components", "text": "The network component of the tags is a binary input vector in the dimension of the number of tags and a single hidden layer FC with L2 regularization of their weights. No further improvement was achieved by including additional layers. Input for the tag component is done by tags M. The tags component is illustrated in Fig. 1 (a). In the movie examples, we used different tag components for different types of tags: genres, actors, directors and speech tags. The dimension of the hidden layer is determined for each component based on the number of tags and their available combinations. For example, the actor component could be assigned a higher output dimension than the language component. This is because the number of actors is much greater than the number of languages. Furthermore, movies usually contain several actors, but a single language."}, {"heading": "3.3 Numeric Components", "text": "Numerical components are designed to deal with numerically structured data that are represented as sequential feature vectors. In this work, the only numerical values available are the release years of the movies. Therefore, the numerical component was simply selected to be a network with a single input neuron (fig. 1 (b)). This input is done by numM. Figure 1: A mapping of the components used in our model. Input, hide and output layers are labeled \"x,\" \"h\" or \"y,\" respectively. Note that each layer may contain a different number of neurons. (c) The BOW components consist of an input layer the size of available tags and a single hidden layer. The input is done as a binary vector that consists of. (b) The numerical component receives input with the help of this use. (c) The BOW component receives the BOW features that are extracted with the help of two hidden layers."}, {"heading": "3.4 A Combiner Component", "text": "The Combiner component (Figure 1 (e)) consists of several input layers, which are completely connected to a hidden layer with L2 regularization. This is followed by a last FC output layer with the same dimension of the CF space."}, {"heading": "3.5 The Full Model", "text": "The complete model is shown in Fig. 2. In accordance with Fig. 1, tags, text and numerical components are colored in blue, red and green. The combination component is colored in yellow. Fig. 2 illustrates the application of the presented model to the task of movie similarity, especially for the movie Pulp Fiction. Genres, actors, directors and languages are modeled as tag components, the summary of the movie is modeled as text component. In this implementation, the text component can be either CNN or BOW network. The year of release of the movie is modeled as a numerical component. All output components are then fed into the combination component, which outputs a predicted CF vector. The loss function we use to train the model is the Mean Square Error (MSE), which is a frequent choice for regression tasks."}, {"heading": "4. EXPERIMENTAL SETUP AND RESULTS", "text": "The quantitative evaluation results in this paper are based on a 10-fold cross-validation process. We supplement these quantitative results with qualitative results in order to obtain a better \"feeling\" of the model. Remember that our goal is to predict the CF vector for each element based on its content profile. Therefore, the CF representation is considered to be the fundamental truth in all our experiments. As our model and experimental setup differ substantially from previous work [20] - [22] no direct comparison between these models and ours can be made (as explained in section 2). Next, we describe in detail the data sets, evaluated systems, parameter configurations, evaluation measures and current results."}, {"heading": "4.1 Datasets", "text": "We illustrate the model by mapping CB to CF in two areas: film recommendations based on a public data set and Windows Apps recommendations based on a proprietary data set."}, {"heading": "4.1.1 Word2vec dataset", "text": "We used a subset of the dataset of [14] to establish a word2vec model. Specifically, we kept only the most common 50K words. Furthermore, we mapped all numbers to the number 9 and removed punctuation marks. Subsequently, we sampled 9.2 M sentences, which formed a total text length of 217M words, in order to train the word2vec model according to [5]."}, {"heading": "4.1.2 Movies dataset", "text": "The data set of movies is publicly available and includes both CF and CB data for movies. CF data is based on the latest data set from MovieLens [18], which contains 22,884,377 ratings collected between 1995 and 2016 from 247,753 users who watched 34,208 movies. Movies are rated on a five-star scale with half-step (0.5 - 5.0) ratings. From each user's rating list, we consider all movies with ratings above 3.5 as a series of contiguous movies. Furthermore, we discard all sets of size < 2. This results in 173,266 sets, which include 11,108 unique items (movies) as effective training data for learning the item2vec model [12]. For each movie, we have collected metadata from IMDB [33]. Three types of information sources are collected: movie plot (given as raw text), genres / actor / director profiles / languages (given as a summary), and the number of 15,000 words (given as free words)."}, {"heading": "4.1.3 Windows apps dataset", "text": "The second dataset is a correctness dataset with CF and CB data for apps from the Microsoft Windows Store. We created CF profiles for the articles using a dataset of user activity with 5M user sessions. Each user session contains a list of items clicked by the same user in the same activity session. This dataset consisted of 33K of unique items (apps) that were used to create an item2vec model of representative CF vectors. For each app, we created text profiles based on the app description in the same way as for the movie data (the first 500 words that word2vec display are stored as text descriptions for each app). In this case, no further metadata was used beyond the text descriptions."}, {"heading": "4.2 Evaluated Systems", "text": "In order to quantify the relative contribution of each data source in our model, we trained different configurations of the model, each connecting a single component to the combinator and separating all the other components. For tag components, we trained separate models for genres, actors, director, and language. In presenting the results, we intuitively synchronized each of these models according to their information sources, i.e. \"genres,\" \"actor,\" \"director,\" and \"language.\" For the text components, we trained separate models for CNN and BOW as explained above and named them \"CNN\" and \"BOW.\" For the numerical components, we trained a separate model for the year of release and dub it \"year.\" To quantify the relative contribution of each combination, we continued to train the models for the following component combinations: \"Tags\" - a combination of \"genres,\" \"actors,\" \"\" director, \"and\" language. \"Tags + Year\" - a combination of \"tags\" and \"once\" we found \"CNN\" and \"a combination of\" CNN \"is a combination of\" year. \""}, {"heading": "4.3 Parameter Configuration", "text": "The item2vec models (for both movies and apps) were trained for 100 epochs with a target dimension of 40n =, negative to positive ratio 15 and subsampling parameter 1e-4. The word2vec model was trained for 100 epochs with a target dimension of 100 m =, window size 4, subsampling parameters 1e-5 and negative-positive ratio 15. For the components \"Genres,\" \"Actors,\" \"Director\" and \"Language,\" we used hidden layers with dimensions 100, 100, 40 and 20 respectively. The \"CNN\" components (for both movies and apps) use 300 filters with a length of 3 (the dimensions of each filter are 3 100 x x x x x x x x x x x x x x x x x x x)."}, {"heading": "4.4 Evaluation Measures", "text": "The first evaluation quantity used in this paper is the Mean Squared Error (MSE), measured by the difference between the predicted CF vectors and their original (item2vec) CF vectors. Formally, MSE is measured as follows: = | Looking Item, where the set of all test set items is, is the original CF vector and is the predicted vector. Minimizing the MSE is the goal of all systems in this work. It quantifies the ability of the various systems to reconstruct the original CF vectors. However, MSE has no direct business interpretation in terms of the ulare collaborative filtering task. Therefore, our next evaluation measures are borrowed from the field of CF research and directly quantify the quality of the predicted vectors in relation to the CF task. Our second measurement quantifies the quality of the predicted vectors in relation to the item similarity in relation to the determination of the latent."}, {"heading": "4.5 Quantitative Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.5.1 Movies data", "text": "In most cases, the three evaluation measures are strongly correlated. In the following, we identify common trends in all evaluation measures and provide interpretations for these trends. First, we look at the \"BOW\" model compared to the \"CNN\" systems. Both systems are based purely on the text descriptions of the film. Our results show that the \"CNN\" approach achieves better results than the \"BOW\" approach. This shows the ability of the \"CNN\" model to benefit from the semantic information encoded in the word2vec presentations, as well as the ability of the \"CNN\" approach to achieve better results than the \"BOW\" approach. This shows the ability of the \"CNN\" model to benefit from the semantic information encoded in the word2vec presentations, as the ability of the \"CNN\" filters to take up the semantic context encoded by word propagation in the text."}, {"heading": "4.5.2 Windows apps data", "text": "Table 2 shows MPR and NDCG values obtained by the \"CNN\" system on the app dataset. As we can see, the MPR value obtained by the \"CNN\" model is significantly lower than the best result obtained by the \"Full\" model for the movies data (2.35 vs. 5.4). We believe this is due to the fact that the app dataset contains more training examples than the Movies dataset (30K vs. 11K), which allows better fine-tuning of the word vectors for the prediction task."}, {"heading": "4.6 Qualitative Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.6.1 Movies data", "text": "The second column shows recommendations made with the original CF vectors; the third column presents recommendations produced by the \"CNN + s\" models are considered as such. \"Shrek\" models that use all sources of information. \"The last column shows recommendations emanating from the\" CNN + s \"films.\" The third column shows that these are films that range from the first to the second spiral. \"\" The third spiral goes from the first to the last spiral. \"\" The third spiral goes from the second to the last spiral. \"\" The third spiral goes from the second to the last spiral. \"The third spiral\" The third spiral \"The third spiral\" The third spiral \"The third spiral\" The third spiral \"The first spiral\" The third spiral \"The third spiral\" The third spiral \"The third spiral\" The third spiral \"The third spiral\" The third spiral \"The third spiral\" The third spiral \"The third spiral\" The third spiral \"The third spiral\" The third spiral \"The third spiral\" The third spiral \"The third spiral\" The third spiral \"The third spiral\" The third spiral \"The third spiral\" The third spiral \""}, {"heading": "4.6.2 Windows apps data", "text": "Table 3 presents recommendations for apps that have been created according to a similar setting as in Table 2. In the second column, recommendations are presented that were created with the original CF vectors based on item2vec. In the third column, recommendations that were created by the \"CNN\" system are presented. As we can see, the \"CNN\" system manages to give precise recommendations regarding the respective seed that are based exclusively on the textual description of apps."}, {"heading": "5. CONCLUSION AND FUTURE WORK", "text": "We focus on film and app recommendations and show a network architecture that maps structured film metadata and unstructured text descriptions into their latent CF representation.The text descriptions were processed using a word2vec model, followed by a CNN that scans the text in a similar way to the latest NLP models [7].In our evaluation, we demonstrate the effectiveness of the system in predicting useful film and app recommendations and examine the contribution of each component.In the future, we plan to explore additional directions. Specifically, we plan to build a model for simultaneously predicting both metadata tags and CF representation from text descriptions.This model will use a hybrid loss function consisting of classification and regression losses. In addition, we plan to expand the model presented in this paper to include additional information sources such as audio, image and video."}, {"heading": "6. REFERENCES", "text": "[1] A. Krizhevsky, I. Sutskever, and G. E. Hinton, \"ImageNet Classification with Deep Convolutional Neural Networks,\" in Advances in Neural Information Processing Systems 25, F. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger, Eds. Curran Associates, Inc., 2012, pp. 1097-1105. [2] A. Graves, A. Mohamed, and G. E. Hinton, \"Speech recognition with deep recurrent neural networks,\" in {IEEE} International Conference on Acoustics, Speech and Signal Processing, {ICASSP} 2013, BC, Canada, May XiXi. 2013, and G. E. Hinton, \"Bengio, R. Ducharme, P. Vincent, and C. Janvin,\" A Neural Probabilistic Language Model,. \""}], "references": [{"title": "ImageNet Classification with Deep Convolutional Neural Networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "Advances in Neural Information Processing Systems 25, F. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger, Eds. Curran Associates, Inc., 2012, pp. 1097\u20131105.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "Speech recognition with deep recurrent neural networks", "author": ["A. Graves", "A. Mohamed", "G.E. Hinton"], "venue": "{IEEE} International Conference on Acoustics, Speech and Signal Processing, {ICASSP} 2013, Vancouver, BC, Canada, May 26-31, 2013, 2013, pp. 6645\u2013 6649.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2013}, {"title": "A Neural Probabilistic Language Model", "author": ["Y. Bengio", "R. Ducharme", "P. Vincent", "C. Janvin"], "venue": "J. Mach. Learn. Res., vol. 3, pp. 1137\u20131155, Mar. 2003.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2003}, {"title": "Learning Discriminative Projections for Text Similarity Measures", "author": ["W. Yih", "K. Toutanova", "J.C. Platt", "C. Meek"], "venue": "Proceedings of the Fifteenth Conference on Computational Natural Language Learning, 2011, pp. 247\u2013256.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2011}, {"title": "Distributed Representations of Words and Phrases and their Compositionality", "author": ["T. Mikolov", "I. Sutskever", "K. Chen", "G.S. Corrado", "J. Dean"], "venue": "Advances in Neural Information Processing Systems 26, C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. Weinberger, Eds. Curran Associates, Inc., 2013, pp. 3111\u20133119.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "Natural Language Processing (Almost) from Scratch", "author": ["R. Collobert", "J. Weston", "L. Bottou", "M. Karlen", "K. Kavukcuoglu", "P. Kuksa"], "venue": "J. Mach. Learn. Res., vol. 12, pp. 2493\u20132537, Nov. 2011.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "Convolutional Neural Networks for Sentence Classification", "author": ["Y. Kim"], "venue": "Proc. 2014 Conf. Empir. Methods Nat. Lang. Process. (EMNLP 2014), pp. 1746\u20131751, 2014.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "Matrix Factorization Techniques for Recommender Systems", "author": ["Y. Koren", "R. Bell", "C. Volinsky"], "venue": "Computer (Long. Beach. Calif)., vol. 42, no. 8, pp. 30\u201337, Aug. 2009.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2009}, {"title": "The Netflix Prize", "author": ["J. Bennett", "S. Lanning"], "venue": "Proceedings of the KDD Cup Workshop 2007, 2007, pp. 3\u20136.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2007}, {"title": "Lessons from the Netflix Prize Challenge", "author": ["R.M. Bell", "Y. Koren"], "venue": "SIGKDD Explor. Newsl., vol. 9, no. 2, pp. 75\u201379, Dec. 2007.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2007}, {"title": "The Yahoo ! Music Dataset and KDD-Cup \u2019 11", "author": ["G. Dror", "N. Koenigstein", "Y. Koren", "M. Weimer"], "venue": "KDD Cup, pp. 8\u201318, 2012.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2012}, {"title": "Item2Vec: Neural item embedding for collaborative filtering", "author": ["O. Barkan", "N. Koenigstein"], "venue": "arXiv: 1603.04259. 2016 Mar 14.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2016}, {"title": "Visualizing Data using t- SNE", "author": ["L. Van Der Maaten", "G. Hinton"], "venue": "JMLR., vol. 9, pp. 2579\u20132605, 2008.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2008}, {"title": "One billion word benchmark for measuring progress in statistical language modeling", "author": ["C Chelba", "T Mikolov", "M Schuster", "Q Ge", "T Brants", "P Koehn", "T. Robinson"], "venue": "arXiv preprint arXiv:1312.3005", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2013}, {"title": "December). Using tf-idf to determine  word relevance in document queries", "author": ["J. Ramos"], "venue": "In Proceedings of the first instructional conference on machine learning", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2003}, {"title": "Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980", "author": ["D. Kingma", "J. Ba"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2014}, {"title": "The MovieLens Datasets: History and Context", "author": ["F.M. Harper", "J.A. Konstan"], "venue": "ACM Transactions on Interactive Intelligent Systems (TiiS),", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2015}, {"title": "Automatic early stopping using cross validation: quantifying the criteria", "author": ["L. Prechelt"], "venue": "Neural Networks", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1998}, {"title": "Collaborative deep learning for recommender systems", "author": ["H Wang", "N Wang", "DY. Yeung"], "venue": "In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining 2015 Aug", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2015}, {"title": "Hierarchical neural language models for joint representation of streaming documents and their content", "author": ["N Djuric", "H Wu", "V Radosavljevic", "M Grbovic", "N. Bhamidipati"], "venue": "InProceedings of the 24th International Conference on World Wide Web 2015 May", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2015}, {"title": "Research and Implementation of Hybrid Recommendation Algorithm Based on Collaborative Filtering and Word2Vec.\" 2015", "author": ["Xiao", "Yao", "Quan Shi"], "venue": "8th International Symposium on Computational Intelligence and Design (ISCID)", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2015}, {"title": "Glove: Global Vectors for Word Representation", "author": ["J Pennington", "R Socher", "CD. Manning"], "venue": "In EMNLP 2014 Oct 25 (Vol", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2014}, {"title": "Neural word embedding as implicit matrix factorization. In Advances in neural information processing systems (pp. 2177-2185)", "author": ["O. Levy", "Y. Goldberg"], "venue": null, "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2014}, {"title": "Multimodal deep learning", "author": ["J. Ngiam", "A. Khosla", "M. Kim", "J. Nam", "H. Lee", "A.Y. Ng"], "venue": "In Proceedings of the 28th international conference on machine learning (ICML-11)", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2011}, {"title": "Unsupervised learning of acoustic features via deep canonical correlation analysis", "author": ["W. Wang", "R. Arora", "K. Livescu", "Bilmes", "J. A", "April"], "venue": "In 2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (pp. 4590-4594)", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2015}, {"title": "On deep multi-view representation learning", "author": ["W. Wang", "R. Arora", "K. Livescu", "J. Bilmes"], "venue": "In Proc. of the 32st Int. Conf. Machine Learning (ICML", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2015}, {"title": "Relations between two sets of variates", "author": ["H. Hotelling"], "venue": "Biometrika, 28(3/4):321\u2013377,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 1936}, {"title": "Bayesian Neural Word Embedding", "author": ["O. Barkan"], "venue": "arXiv preprint arXiv:1603.06571", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2016}, {"title": "A Sensitivity Analysis of (and Practitioners' Guide to) Convolutional Neural Networks for Sentence Classification", "author": ["Y. Zhang", "B. Wallace"], "venue": "arXiv preprint arXiv:1510.03820", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2015}, {"title": "Web-scale multimedia analysis: Does content matter", "author": ["M. Slaney"], "venue": "IEEE MultiMedia,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2011}], "referenceMentions": [{"referenceID": 8, "context": "In Recommender Systems research, CF models are commonly used for a variety of personalization tasks [9]\u2013[11].", "startOffset": 100, "endOffset": 103}, {"referenceID": 10, "context": "In Recommender Systems research, CF models are commonly used for a variety of personalization tasks [9]\u2013[11].", "startOffset": 104, "endOffset": 108}, {"referenceID": 7, "context": "For example, Matrix Factorization (MF) models [8] are commonly used to map users and items into a dense manifold using a dataset of usage patterns or explicit ratings.", "startOffset": 46, "endOffset": 49}, {"referenceID": 29, "context": "CF approaches are generally accepted to more accurate than CB approaches [32].", "startOffset": 73, "endOffset": 77}, {"referenceID": 11, "context": "To obtain the CF representations, we have used the item2vec [12] algorithm.", "startOffset": 60, "endOffset": 64}, {"referenceID": 7, "context": "We note that the approach in this paper is not restricted to item2vec and can be trivially extended to any CF algorithm that is based on a low-dimensional latent embedding such as most common MF models [8].", "startOffset": 202, "endOffset": 205}, {"referenceID": 0, "context": "Considerable technological advancements have been achieved in the fields of computer vision [1] and speech recognition [2].", "startOffset": 92, "endOffset": 95}, {"referenceID": 1, "context": "Considerable technological advancements have been achieved in the fields of computer vision [1] and speech recognition [2].", "startOffset": 119, "endOffset": 122}, {"referenceID": 2, "context": "In Natural Language Processing (NLP), deep learning methods have been mostly focused on learning word vector representations [3]-[6], [30].", "startOffset": 125, "endOffset": 128}, {"referenceID": 5, "context": "In Natural Language Processing (NLP), deep learning methods have been mostly focused on learning word vector representations [3]-[6], [30].", "startOffset": 129, "endOffset": 132}, {"referenceID": 27, "context": "In Natural Language Processing (NLP), deep learning methods have been mostly focused on learning word vector representations [3]-[6], [30].", "startOffset": 134, "endOffset": 138}, {"referenceID": 4, "context": "Specifically, Skip-Gram with Negative Sampling (SGNS) [5], known also as word2vec, has drawn much attention for its versatile uses in several linguistic tasks.", "startOffset": 54, "endOffset": 57}, {"referenceID": 6, "context": "A recent work by Kim [7] has further enhanced this approach by applying a convolutional neural network (CNN) on top Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.", "startOffset": 21, "endOffset": 24}, {"referenceID": 22, "context": "The similarity of SGNS to MF has been thoroughly studied in [24].", "startOffset": 60, "endOffset": 64}, {"referenceID": 11, "context": "Item2vec [12] is a variant of the SGNS with a modified objective aimed at learning item representations for CF tasks.", "startOffset": 9, "endOffset": 13}, {"referenceID": 23, "context": "[25] proposed a \u2018split autoencoder\u2019 approach to extract a joint representation by reconstructing both views from a single view.", "startOffset": 0, "endOffset": 4}, {"referenceID": 26, "context": "[26] introduce a deep variant of Canonical Correlation Analysis (CCA) [29] dubbed Deep CCA (DCCA).", "startOffset": 70, "endOffset": 74}, {"referenceID": 24, "context": "Other variants of DCCA are investigated in [27, 28].", "startOffset": 43, "endOffset": 51}, {"referenceID": 25, "context": "Other variants of DCCA are investigated in [27, 28].", "startOffset": 43, "endOffset": 51}, {"referenceID": 18, "context": "[20] proposed a hierarchical Bayesian model for learning a joint representation for content information and collaborative filtering ratings.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[21] introduced hierarchical neural language models for joint representation of streaming documents and their content with application to personalized recommendations.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "Xiao and Quan [22] suggested a hybrid recommendation algorithm based on collaborative filtering and word2vec, where recommendations scores are computed by a weighted combination of CF and CB scores.", "startOffset": 14, "endOffset": 18}, {"referenceID": 11, "context": "{0,1} K A \u00d7 \u2208 , we first employ item2vec [12] to produce a mapping", "startOffset": 41, "endOffset": 45}, {"referenceID": 4, "context": "vector obtained by word2vec [5].", "startOffset": 28, "endOffset": 31}, {"referenceID": 0, "context": "The second mapping for textual data maps an item to its bag of words (BOW) representation denoted by : [0,1] BOW M I \u2192 .", "startOffset": 103, "endOffset": 108}, {"referenceID": 6, "context": "model from [7].", "startOffset": 11, "endOffset": 14}, {"referenceID": 6, "context": "An illustration of this approach (taken from [7]) appears in Fig.", "startOffset": 45, "endOffset": 48}, {"referenceID": 6, "context": "In contrast to [7], we did not apply parallel convolutional layers with different filter lengths.", "startOffset": 15, "endOffset": 18}, {"referenceID": 28, "context": "A similar observation was also made in [31].", "startOffset": 39, "endOffset": 43}, {"referenceID": 6, "context": "We considered several additional variants of CNN-based models as in [7]: (1) the \u2018CNN random\u2019 model learns the word", "startOffset": 68, "endOffset": 71}, {"referenceID": 0, "context": "ReLU [1] activations are used in all of the model components.", "startOffset": 5, "endOffset": 8}, {"referenceID": 18, "context": "Furthermore, since our model and the experimental setup are substantially different from previous other work [20]-[22], a direct comparison between these models to ours cannot be made (as explained in Section 2).", "startOffset": 109, "endOffset": 113}, {"referenceID": 20, "context": "Furthermore, since our model and the experimental setup are substantially different from previous other work [20]-[22], a direct comparison between these models to ours cannot be made (as explained in Section 2).", "startOffset": 114, "endOffset": 118}, {"referenceID": 13, "context": "We used a subset of the dataset from [14] in order to establish a word2vec model.", "startOffset": 37, "endOffset": 41}, {"referenceID": 4, "context": "2M sentences that formed a total text length of 217M words for training the word2vec model according to [5].", "startOffset": 104, "endOffset": 107}, {"referenceID": 16, "context": "The CF data is based on the latest MovieLens dataset [18] containing 22,884,377 ratings collected during 19952016 from 247,753 users that watched 34,208 movies.", "startOffset": 53, "endOffset": 57}, {"referenceID": 11, "context": "This results in 173,266 sets that contain 11,108 unique items (movies) as the effective training data for learning the item2vec model [12].", "startOffset": 134, "endOffset": 138}, {"referenceID": 15, "context": "We used the Adam optimizer [17] with a mini-batch size of 32 and applied an early stopping procedure [19].", "startOffset": 27, "endOffset": 31}, {"referenceID": 17, "context": "We used the Adam optimizer [17] with a mini-batch size of 32 and applied an early stopping procedure [19].", "startOffset": 101, "endOffset": 105}, {"referenceID": 4, "context": "[5], the authors illustrated the ability of their model to automatically organize word representations that capture semantical relations.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "2 in [5]).", "startOffset": 5, "endOffset": 8}, {"referenceID": 12, "context": "Figure 4 depicts a t-SNE [13] embedding of the original (item2vec) CF vectors (a) and the predicted vectors by our \u2018full\u2019 model (b) for a random pick of 900 movies from the top six genres in the test set.", "startOffset": 25, "endOffset": 29}, {"referenceID": 6, "context": "The textual descriptions were processed using a word2vec model followed by a CNN that scans the text in a similar fashion to latest NLP models [7].", "startOffset": 143, "endOffset": 146}], "year": 2016, "abstractText": "In Recommender Systems research, algorithms are often characterized as either Collaborative Filtering (CF) or Content Based (CB). CF algorithms are trained using a dataset of user explicit or implicit preferences while CB algorithms are typically based on item profiles. These approaches harness very different data sources hence the resulting recommended items are generally also very different. This paper presents a novel model that serves as a bridge from items content into their CF representations. We introduce a multiple input deep regression model to predict the CF latent embedding vectors of items based on their textual description and metadata. We showcase the effectiveness of the proposed model by predicting the CF vectors of movies and apps based on their textual descriptions. Finally, we show that the model can be further improved by incorporating metadata such as the movie release year and tags which contribute to a higher accuracy.", "creator": "PScript5.dll Version 5.2.2"}}}