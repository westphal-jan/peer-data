{"id": "1611.00625", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Nov-2016", "title": "TorchCraft: a Library for Machine Learning Research on Real-Time Strategy Games", "abstract": "We present TorchCraft, an open-source library that enables deep learning research on Real-Time Strategy (RTS) games such as StarCraft: Brood War, by making it easier to control these games from a machine learning framework, here Torch. This white paper argues for using RTS games as a benchmark for AI research, and describes the design and components of TorchCraft.", "histories": [["v1", "Tue, 1 Nov 2016 05:01:24 GMT  (1891kb,D)", "http://arxiv.org/abs/1611.00625v1", null], ["v2", "Thu, 3 Nov 2016 21:54:28 GMT  (1878kb,D)", "http://arxiv.org/abs/1611.00625v2", null]], "reviews": [], "SUBJECTS": "cs.LG cs.AI", "authors": ["gabriel synnaeve", "nantas nardelli", "alex auvolat", "soumith chintala", "timoth\\'ee lacroix", "zeming lin", "florian richoux", "nicolas usunier"], "accepted": false, "id": "1611.00625"}, "pdf": {"name": "1611.00625.pdf", "metadata": {"source": "CRF", "title": "TorchCraft: a Library for Machine Learning Research on Real-Time Strategy Games", "authors": ["Gabriel Synnaeve", "Nantas Nardelli", "Alex Auvolat", "Soumith Chintala", "Timoth\u00e9e Lacroix", "Zeming Lin", "Florian Richoux", "Nicolas Usunier"], "emails": ["gab@fb.com,", "nantas@robots.ox.ac.uk"], "sections": [{"heading": "1 Introduction", "text": "In the realm of Reinforcement Learning, this has translated into the ability to develop agents capable of acting in high-dimensional input spaces. In particular, deep neural networks have been used to extend the scale of amplification to visual input environments, enabling them to learn strategies in test beds that were previously completely insoluble. For example, it has been shown that algorithms such as Deep Q-Network (DQN) [14] in most of the classic ATARI 2600 games reach a human level by learning a controller directly from raw pixels, with no additional monitoring next to the score. However, most of the work produced in this new area has tackled environments where the state is fully observable, the reward function has no or little delay, and the action set is relatively small."}, {"heading": "2 Real-Time Strategy for Games AI", "text": "In fact, most of them will be able to move to a different world in which they are able to live than in a world in which they are able to live and live."}, {"heading": "3 Design", "text": "The simplified design of TorchCraft is therefore applicable to any video game and any type of machine learning library or frame. Our current implementation links Torch to a low interface [1] to StarCraft: Brood War. TorchCraft's approach is to dynamically inject a piece of code into the game engine, which will be a server. This server sends the state of the game to a client (our machine learning code) and receives commands that are sent to the game. This is shown in Figure 1. The two modules are perfectly synchronous, but we offer two execution modalities based on how we interact with the game: game-controlled - we inject a DLL that provides the bots with the game interface, and one that contains all the instructions to communicate with the machine learning client interpreted by the game as a player (or bot-AI). In this mode, the server starts at the start of the game and turns off when the game is finished."}, {"heading": "4 Conclusion", "text": "We presented several papers that established RTS games as a source of interesting and relevant issues for the AI research community. We believe that an efficient bridge between existing low-level APIs and machine learning frameworks / libraries would facilitate and foster the exploration of such games. We introduced TorchCraft: a library that enables state-of-the-art machine learning research on real game data by linking Torch with StarCraft: BroodWar. TorchCraft has already been used in enhanced learning experiments on StarCraft, which led to the results in [23] (soon to be open source and part of TorchCraft)."}, {"heading": "5 Acknowledgements", "text": "We thank Yann LeCun, L\u00e9on Bottou, Pushmeet Kohli, Subramanian Ramamoorthy and Phil Torr for their ongoing feedback and help with various aspects of this work. Many thanks to David Churchill for proofreading earlier versions of this essay."}, {"heading": "A Frame data", "text": "F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F"}], "references": [{"title": "Learning to win: Case-based plan selection in a real-time strategy game", "author": ["D.W. Aha", "M. Molineaux", "M. Ponsen"], "venue": "In International Conference on Case-Based Reasoning", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2005}, {"title": "The arcade learning environment: An evaluation platform for general agents", "author": ["M.G. Bellemare", "Y. Naddaf", "J. Veness", "M. Bowling"], "venue": "Journal of Artificial Intelligence Research", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2012}, {"title": "Rts games and real-time ai research", "author": ["M. Buro", "T. Furtak"], "venue": "In Proceedings of the Behavior Representation in Modeling and Simulation Conference (BRIMS)", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2004}, {"title": "Starcraft ai competition", "author": ["D. Churchill"], "venue": "http://www.cs.mun.ca/~dchurchill/ starcraftaicomp/,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2011}, {"title": "Heuristic Search Techniques for Real-Time Strategy Games", "author": ["D. Churchill"], "venue": "PhD thesis, University of Alberta,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2016}, {"title": "Fast heuristic search for rts game combat scenarios", "author": ["D. Churchill", "A. Saffidine", "M. Buro"], "venue": "AIIDE", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2012}, {"title": "Torch7: A matlab-like environment for machine learning", "author": ["R. Collobert", "K. Kavukcuoglu", "C. Farabet"], "venue": "In BigLearn, NIPS Workshop", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2011}, {"title": "A turing test for computer game bots", "author": ["P. Hingston"], "venue": "IEEE Transactions on Computational Intelligence and AI in Games 1,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2009}, {"title": "The malmo platform for artificial intelligence experimentation", "author": ["M. Johnson", "K. Hofmann", "T. Hutton", "D. Bignell"], "venue": "In International joint conference on artificial intelligence (IJCAI)", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2016}, {"title": "Vizdoom: A doombased ai research platform for visual reinforcement learning", "author": ["M. Kempka", "M. Wydmuch", "G. Runc", "J. Toczek", "W. Ja\u015bkowski"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2016}, {"title": "Human-level control through deep reinforcement learning", "author": ["V. Mnih", "K. Kavukcuoglu", "D. Silver", "A.A. Rusu", "J. Veness", "M.G. Bellemare", "A. Graves", "M. Riedmiller", "A.K. Fidjeland", "G Ostrovski"], "venue": "Nature 518,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2015}, {"title": "Case-based planning and execution for real-time strategy games", "author": ["S. Onta\u00f1\u00f3n", "K. Mishra", "N. Sugandh", "A. Ram"], "venue": "In International Conference on Case-Based Reasoning", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2007}, {"title": "A survey of real-time strategy game ai research and competition in starcraft", "author": ["S. Ontan\u00f3n", "G. Synnaeve", "A. Uriarte", "F. Richoux", "D. Churchill", "M. Preuss"], "venue": "Computational Intelligence and AI in Games, IEEE Transactions on 5,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2013}, {"title": "A review of real-time strategy game ai", "author": ["G. Robertson", "I. Watson"], "venue": "AI Magazine 35,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2014}, {"title": "Bayesian programming and learning for multi-player video games: application to RTS AI", "author": ["G. Synnaeve"], "venue": "PhD thesis, PhD thesis, Institut National Polytechnique de Grenoble\u2014INPG,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2012}, {"title": "A dataset for starcraft ai & an example of armies clustering", "author": ["G. Synnaeve", "P. Bessiere"], "venue": "arXiv preprint arXiv:1211.4552", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2012}, {"title": "The 2009 mario ai competition", "author": ["J. Togelius", "S. Karakovskiy", "R. Baumgarten"], "venue": "In IEEE Congress on Evolutionary Computation", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2010}, {"title": "Starcraft brood war data mining", "author": ["A. Uriarte"], "venue": "http://nova.wolfwork.com/dataMining.html,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2015}, {"title": "Game-tree search over high-level game states in rts games", "author": ["A. Uriarte", "S. Onta\u00f1\u00f3n"], "venue": "In Tenth Artificial Intelligence and Interactive Digital Entertainment Conference", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2014}, {"title": "Episodic exploration for deep deterministic policies: An application to starcraft micromanagement", "author": ["N. Usunier", "G. Synnaeve", "Z. Lin", "S. Chintala"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2016}, {"title": "Reactive planning for micromanagement in rts games", "author": ["B. Weber"], "venue": "Department of Computer Science,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2014}, {"title": "A data mining approach to strategy prediction", "author": ["B.G. Weber", "M. Mateas"], "venue": "In 2009 IEEE Symposium on Computational Intelligence and Games (2009),", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2009}, {"title": "Applying reinforcement learning to small scale combat in the real-time strategy game starcraft: broodwar", "author": ["S. Wender", "I. Watson"], "venue": "In Computational Intelligence and Games (CIG),", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2012}], "referenceMentions": [{"referenceID": 6, "context": "We present TorchCraft, an open-source library that enables deep learning research on Real-Time Strategy (RTS) games such as StarCraft: Brood War, by making it easier to control these games from a machine learning framework, here Torch [9].", "startOffset": 235, "endOffset": 238}, {"referenceID": 10, "context": "For instance, algorithms such as Deep Q-Network (DQN) [14] have been shown to reach human-level performances on most of the classic ATARI 2600 games by learning a controller directly from raw pixels, and without any additional supervision beside the score.", "startOffset": 54, "endOffset": 58}, {"referenceID": 16, "context": "To provide the community with useful research environments, work was done towards building platforms based on videogames such as Torcs [27], Mario AI [20], Unreal\u2019s BotPrize [10], the Atari Learning Environment [3], VizDoom [12], and Minecraft [11], all of which have allowed researchers to train deep learning models with imitation learning, reinforcement learning and various decision making algorithms on increasingly difficult problems.", "startOffset": 150, "endOffset": 154}, {"referenceID": 7, "context": "To provide the community with useful research environments, work was done towards building platforms based on videogames such as Torcs [27], Mario AI [20], Unreal\u2019s BotPrize [10], the Atari Learning Environment [3], VizDoom [12], and Minecraft [11], all of which have allowed researchers to train deep learning models with imitation learning, reinforcement learning and various decision making algorithms on increasingly difficult problems.", "startOffset": 174, "endOffset": 178}, {"referenceID": 1, "context": "To provide the community with useful research environments, work was done towards building platforms based on videogames such as Torcs [27], Mario AI [20], Unreal\u2019s BotPrize [10], the Atari Learning Environment [3], VizDoom [12], and Minecraft [11], all of which have allowed researchers to train deep learning models with imitation learning, reinforcement learning and various decision making algorithms on increasingly difficult problems.", "startOffset": 211, "endOffset": 214}, {"referenceID": 9, "context": "To provide the community with useful research environments, work was done towards building platforms based on videogames such as Torcs [27], Mario AI [20], Unreal\u2019s BotPrize [10], the Atari Learning Environment [3], VizDoom [12], and Minecraft [11], all of which have allowed researchers to train deep learning models with imitation learning, reinforcement learning and various decision making algorithms on increasingly difficult problems.", "startOffset": 224, "endOffset": 228}, {"referenceID": 8, "context": "To provide the community with useful research environments, work was done towards building platforms based on videogames such as Torcs [27], Mario AI [20], Unreal\u2019s BotPrize [10], the Atari Learning Environment [3], VizDoom [12], and Minecraft [11], all of which have allowed researchers to train deep learning models with imitation learning, reinforcement learning and various decision making algorithms on increasingly difficult problems.", "startOffset": 244, "endOffset": 248}, {"referenceID": 12, "context": "We propose a bridge between StarCraft: Brood War, an RTS game with an active AI research community and annual AI competitions [16, 6, 1], and Lua, with examples in Torch [9] (a machine learning library).", "startOffset": 126, "endOffset": 136}, {"referenceID": 3, "context": "We propose a bridge between StarCraft: Brood War, an RTS game with an active AI research community and annual AI competitions [16, 6, 1], and Lua, with examples in Torch [9] (a machine learning library).", "startOffset": 126, "endOffset": 136}, {"referenceID": 6, "context": "We propose a bridge between StarCraft: Brood War, an RTS game with an active AI research community and annual AI competitions [16, 6, 1], and Lua, with examples in Torch [9] (a machine learning library).", "startOffset": 170, "endOffset": 173}, {"referenceID": 2, "context": "Real-time strategy (RTS) games have historically been a domain of interest of the planning and decision making research communities [5, 2, 6, 16, 17].", "startOffset": 132, "endOffset": 149}, {"referenceID": 0, "context": "Real-time strategy (RTS) games have historically been a domain of interest of the planning and decision making research communities [5, 2, 6, 16, 17].", "startOffset": 132, "endOffset": 149}, {"referenceID": 3, "context": "Real-time strategy (RTS) games have historically been a domain of interest of the planning and decision making research communities [5, 2, 6, 16, 17].", "startOffset": 132, "endOffset": 149}, {"referenceID": 12, "context": "Real-time strategy (RTS) games have historically been a domain of interest of the planning and decision making research communities [5, 2, 6, 16, 17].", "startOffset": 132, "endOffset": 149}, {"referenceID": 13, "context": "Real-time strategy (RTS) games have historically been a domain of interest of the planning and decision making research communities [5, 2, 6, 16, 17].", "startOffset": 132, "endOffset": 149}, {"referenceID": 0, "context": "Related work: Classical AI approaches normally involving planning and search [2, 15, 24, 7] are extremely challenged by the combinatorial action space and the complex dynamics of RTS games, making simulation (and thus Monte Carlo tree search) difficult [8, 22].", "startOffset": 77, "endOffset": 91}, {"referenceID": 11, "context": "Related work: Classical AI approaches normally involving planning and search [2, 15, 24, 7] are extremely challenged by the combinatorial action space and the complex dynamics of RTS games, making simulation (and thus Monte Carlo tree search) difficult [8, 22].", "startOffset": 77, "endOffset": 91}, {"referenceID": 20, "context": "Related work: Classical AI approaches normally involving planning and search [2, 15, 24, 7] are extremely challenged by the combinatorial action space and the complex dynamics of RTS games, making simulation (and thus Monte Carlo tree search) difficult [8, 22].", "startOffset": 77, "endOffset": 91}, {"referenceID": 4, "context": "Related work: Classical AI approaches normally involving planning and search [2, 15, 24, 7] are extremely challenged by the combinatorial action space and the complex dynamics of RTS games, making simulation (and thus Monte Carlo tree search) difficult [8, 22].", "startOffset": 77, "endOffset": 91}, {"referenceID": 5, "context": "Related work: Classical AI approaches normally involving planning and search [2, 15, 24, 7] are extremely challenged by the combinatorial action space and the complex dynamics of RTS games, making simulation (and thus Monte Carlo tree search) difficult [8, 22].", "startOffset": 253, "endOffset": 260}, {"referenceID": 18, "context": "Related work: Classical AI approaches normally involving planning and search [2, 15, 24, 7] are extremely challenged by the combinatorial action space and the complex dynamics of RTS games, making simulation (and thus Monte Carlo tree search) difficult [8, 22].", "startOffset": 253, "endOffset": 260}, {"referenceID": 12, "context": "As the scope of this paper is not to give a review of RTS AI research, we refer the reader to these surveys about existing research on RTS and StarCraft AI [16, 17].", "startOffset": 156, "endOffset": 164}, {"referenceID": 13, "context": "As the scope of this paper is not to give a review of RTS AI research, we refer the reader to these surveys about existing research on RTS and StarCraft AI [16, 17].", "startOffset": 156, "endOffset": 164}, {"referenceID": 22, "context": "Most previous reinforcement learning research involve simple models or limited experimental settings [26, 23].", "startOffset": 101, "endOffset": 109}, {"referenceID": 19, "context": "Most previous reinforcement learning research involve simple models or limited experimental settings [26, 23].", "startOffset": 101, "endOffset": 109}, {"referenceID": 21, "context": "Other models are trained on offline datasets of highly skilled players [25, 18, 19, 21].", "startOffset": 71, "endOffset": 87}, {"referenceID": 14, "context": "Other models are trained on offline datasets of highly skilled players [25, 18, 19, 21].", "startOffset": 71, "endOffset": 87}, {"referenceID": 15, "context": "Other models are trained on offline datasets of highly skilled players [25, 18, 19, 21].", "startOffset": 71, "endOffset": 87}, {"referenceID": 17, "context": "Other models are trained on offline datasets of highly skilled players [25, 18, 19, 21].", "startOffset": 71, "endOffset": 87}, {"referenceID": 1, "context": "Contrary to most Atari games [3], RTS games have much higher action spaces and much more structured states.", "startOffset": 29, "endOffset": 32}, {"referenceID": 1, "context": "Thus, we advocate here to have not only the pixels as input and keyboard/mouse for commands, as in [3, 4, 12], but also a structured representation of the game state, as in", "startOffset": 99, "endOffset": 109}, {"referenceID": 9, "context": "Thus, we advocate here to have not only the pixels as input and keyboard/mouse for commands, as in [3, 4, 12], but also a structured representation of the game state, as in", "startOffset": 99, "endOffset": 109}, {"referenceID": 8, "context": "[11].", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "TorchCraft has already been used in reinforcement learning experiments on StarCraft, which led to the results in [23] (soon to be open-sourced too and included within TorchCraft).", "startOffset": 113, "endOffset": 117}], "year": 2016, "abstractText": "We present TorchCraft, an open-source library that enables deep learning research on Real-Time Strategy (RTS) games such as StarCraft: Brood War, by making it easier to control these games from a machine learning framework, here Torch [9]. This white paper argues for using RTS games as a benchmark for AI research, and describes the design and components of TorchCraft.", "creator": "LaTeX with hyperref package"}}}