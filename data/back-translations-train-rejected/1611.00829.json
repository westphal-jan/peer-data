{"id": "1611.00829", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Nov-2016", "title": "Multidimensional Binary Search for Contextual Decision-Making", "abstract": "We consider a multidimensional search problem that is motivated by questions in contextual decision-making, such as dynamic pricing and personalized medicine. Nature selects a state from a $d$-dimensional unit ball and then generates a sequence of $d$-dimensional directions. We are given access to the directions, but not access to the state. After receiving a direction, we have to guess the value of the dot product between the state and the direction. Our goal is to minimize the number of times when our guess is more than $\\epsilon$ away from the true answer. We construct a polynomial time algorithm that we call Projected Volume achieving regret $O(d\\log(d/\\epsilon))$, which is optimal up to a $\\log d$ factor. The algorithm combines a volume cutting strategy with a new geometric technique that we call cylindrification.", "histories": [["v1", "Wed, 2 Nov 2016 22:38:32 GMT  (33kb)", "http://arxiv.org/abs/1611.00829v1", null], ["v2", "Wed, 26 Apr 2017 02:29:51 GMT  (34kb)", "http://arxiv.org/abs/1611.00829v2", "Appears in EC 2017"]], "reviews": [], "SUBJECTS": "cs.DS cs.LG", "authors": ["ilan lobel", "renato paes leme", "adrian vladu"], "accepted": false, "id": "1611.00829"}, "pdf": {"name": "1611.00829.pdf", "metadata": {"source": "CRF", "title": "Multidimensional Binary Search for Contextual Decision-Making", "authors": ["Ilan Lobel"], "emails": ["ilobel@stern.nyu.edu", "renatoppl@google.com", "avladu@mit.edu"], "sections": [{"heading": null, "text": "ar Xiv: 161 1,00 829v 1 [cs.D S] 2 Nov 201 6"}, {"heading": "1 Introduction", "text": "\"I think it's important to remember that there are a lot of people out there who don't have a lot of money, who don't have any money, who don't have any money, who don't have any money, who don't have any money, who don't have any money, who don't have any money, who don't have any money, who don't have any money, who don't have any money, who don't have any money, who don't have any money, who don't have any money, who don't have any money, who don't have any money, who don't have any money, who don't have any money, who don't have any money, who don't have any money, who don't have any money, who don't have any money, who don't have any money, who don't have any money, who don't have any money,\" he said."}, {"heading": "2 The Model", "text": "We consider an infinite horizontal game between a player and nature. The game begins with nature selecting a state from the d-dimensional unified sphere centered at the origin. We call this ball K0, i.e. K0 = {\u03b8]. The player knows K0, but does not know the value of the x-dimensional unified sphere. 1 In each period after nature has revealed it, nature selects a vector from the d-dimensional unified sphere, i.e., U = {u-Rd: | 2 = 1}, which we call the period t-direction. In each period after nature has revealed it, the player must choose an action xt. The goal of the player is to choose a value of xt that is close to u-t level. Formally, we try to minimize the number of errors we make whenever an error occurs."}, {"heading": "3 Lower Bound", "text": "Proposition 3.1. Each algorithm generates regret of at least one (d log (1 / 2). Proof. Suppose nature chooses within a d-dimensional cube with sides of length 1 / 2 d. This is a valid choice since the unit sphere K0 contains such a cube. Let us represent the vector with the value 1 in coordinate i [1],..., d} and the value 0 in all other coordinates. Suppose nature chooses directions that correspond to the vectors ei in round spherical form, i.e. ut = e (t mod) + 1. Because of the symmetry of the cube from which the vector is selected and the value 0 in all other coordinates. Suppose that nature chooses directions that correspond to the vectors ei in round spherical form, i.e. ut = e (t mod) + 1. Because of the symmetry of the cube from which the vector is selected and the orthogonality of the directions, this problem is equivalent to an independent subinary over all dimensions."}, {"heading": "4 The Projected Volume Algorithm", "text": "In this section, we describe the central idea for obtaining a near-optimal deplorable value. In this section, the central idea for obtaining a near-optimal deplorable value will be contained. In the standard one-dimensional binary search algorithm, the error rate of the algorithms at any given point is relatively high. Thus, the length of the interval provides a clear measure in which progress is being made. However, in the multidimensional case, there is no global measure of error, but only a measure of error for each direction. To make this more precise, we consider knowledge that corresponds to the values of the algorithm that are compatible with what the algorithm has observed. In the face of a direction u (i.e., u is a unit of measurement vector), the error caused by the algorithm to predict the dot product corresponds to the direction of K along u: w (K, u) = max, y (x) (our paper \u2212 x), although we assume that a ball passes through K1."}, {"heading": "Or more concisely, but less intuitively:", "text": "We (K, S) = D (K) = D (K) = D (K) = D (K) = D (K) = D (K) = D (K) s (K) s (K) s (K) s (K) s (K) s (K) s (K) s (K) s (K) s (K) s (K) s (K) s (K) s (K) s (K) s (K) s (K) s (K) s (K) s (K) s) s (K) s (K) s (K) s (K) s (K) s (K) s (K) s (K) s (K) s (K) s) K (K) s (K) s) K (K) s (K) K (K) s (K) K (K) s (K) K (K) s (K) K (K) s (K) K (K) s (K) K (K) s (K) K (K) s (K) K (K) s (K) K (K) s) K (K (K) s) K (K (K) s) K (K (K) s) K (K) s) K (K (K) s) K (K (K) s) K (K (K) s) K (K (K) s) s) K (K (K (K) s) s) K (K (K (K) s) s) K (K (K) s) s (K (K (K) s) s (K (K (K) s) s) s (K (K (K) s) s (K (K (K) s) s) s (K (K (K (K) s) s) s (K (K (K (K (K) s) s) s) s (K (K (K (K) s) s (K (K (K (K (K (K) s) s) s) s) K (K (K (K (K (K (K) s) s) s) s) K (K (K (K (K (K (K (K) s) s) s) K (K (K (K"}, {"heading": "5 Convex Geometry Tools", "text": "In this section, we will begin with the development of the technical machinery required by the plan outlined in the previous section. At the center of the proof will be a statement concerning the volume of a convex body and the volume of its cylindrification in relation to the dimensions along which the body is \"small.\" To obtain this result, we will need tailor-made versions of Green Tree Theorem. Let us begin with a verification of the basic statement of the theorem: Theorem 5.1 (Green Tree). Let K be a convex set and let z be its centrid. Faced with any vector non-zero u, let K + = K \u2022 x (x \u2212 z) \u2265 0}. Then, let 1 e \u00b7 vol (K +) \u2264 (1 \u2212 1 e) \u00b7 vol (K) \u00b7 vol (K) \u00b7 vol (K) \u00b7 vol (K). In other words, each hyperplane through the centrifugal \u2212 n splits the constant fraction of each fraction of the original part (one of each of 7) into two parts."}, {"heading": "5.1 Directional Gru\u0308nbaum Theorem", "text": "We begin with the proof of a theorem that describes how much direction widths of a convex body can change after a section through the middle. \u2212 K \u2212 K \u2212 K \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 k \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v. The first step will prove theorem 5.3 if v is the direction of u itself. We prove this in the following example: Lemma 5.4. Under the conditions of Theorem 5.3, w (K +, u) x."}, {"heading": "5.2 Approximate Gru\u0308nbaum Theorem", "text": "We will use the Directional Grunbaum Theorem to give an approximate version of the Standard Volumetric Grunbaum Theorem. Essentially, we will argue that if we cut a point sufficiently close to the center, then each side of the cut will still contain a constant fraction of the volume. Lemma 5.5 (Approximately Grunbaum). Let K be a convex body, and let z be its center. For an arbitrary unit vector u and scalar procedure, so that 0 \u2264 w (K, u) / (d + 1) 2, let K\u03b4 + = {x \u0445K | u (x \u2212 z). Then, vol (K\u03b4 +) \u2265 1e2 \u00b7 vol (K).The proof for this problem arises from a modification of the original evidence for Grunbaum Theorem, and it can be found in Appendix A.2."}, {"heading": "6 Cylindrification", "text": "Next, we examine how we use the volume of a convex body on the volume of its projection on a subspace.Lemma 6.1 (cylindrification).Let K-Rd be a convex body, so that w (K, u).D-R for each unit u, then for each (D-1) dimensional subspace L: vol (D-LK).D-L (D + 1).D-L-L (K).D-L (D).D-L-L-L-L (D).D-L-L).D-L-L (D).D-L-L (D).D-L-L).D-L (D).D-L (D).D-L: Theorem 6.2 (John).D-Rd is a bounded convex body, then there is a point z and an ellipsoid E that is centered in the region of origin so that z + E.D. Specifically, we will use the following lemon of John's exvex Rd, then it is a 6.Rexvex."}, {"heading": "7 Analysis of the Projected Volume Algorithm", "text": "s theorem, which relates to answering the question whether the answer to the question is limited to answering the question, whether the answer to the question is limited to answering the question, whether the answer to the question is limited to answering the question, whether the answer to the question is limited to answering the question, whether the answer to the question is limited to answering the question, whether the answer to the question is limited to answering the question, whether the answer to the answer to the question is limited to answering the question, whether the answer to the answer to the answer to the question is limited, whether the answer to the answer to the question to the answer to the answer to the answer to the answer to the question, whether the answer to the answer to the question after the answer to the answer to the question after the answer to the answer to the answer to the question, whether the answer to the answer to the question after the answer to the answer to the question after the answer to the answer to the question, whether the answer to the answer to the question after the answer to the answer to the question after the answer to the answer to the question after the answer to the answer to the question after the answer to the answer to the question after the answer to the answer to the question after the answer to the question after the answer to the answer to the answer to the question after the answer to the answer to the question after the answer to the answer to the question after the answer to the answer to the answer to the question after the answer to the question after the answer to the answer to the question after the answer to the answer to the answer to the question after the answer to the question after the answer to the answer to the question after the answer to the question after the answer to the answer to the question after the answer to the question after the answer to the answer to the answer to the answer to the question after the answer of the answer of the answer to the answer to the question after the answer to the answer to the answer of the answer to the answer to the question of the answer to the answer to the answer of the answer to the question,"}, {"heading": "8 Why Cylindrification?", "text": "At the heart of our algorithm is the simple idea that we should select a constant fraction of the volume on each iteration if we want to achieve an O (d log (1 / 2)) that triggers regret. However, our algorithm is somewhat more complex than that. In this section, we argue that cylindrification is actually necessary to obtain our near-optimal regret. We prove that there is an instance in which the algorithm leads only through the center of knowledge (without cylindrical behavior)."}, {"heading": "9 Computation", "text": "The Projected Volume Algorithm described above, although it arouses optimal regret in terms of the number of dimensions d, cannot be implemented as in polynomic time, for the reason that it requires the implementation of two steps, both of which involve solving highly non-trivial problems: the first is the calculation of the centride, which is known to be # P-hard [13]; the second is to find a direction along which a convex body K is \"thin\" (i.e. finding a unit vector u in such a way that w (K, u) \u2264 \u03b4), for which we are not aware of a polynomic time algorithm; in order to make these problems comprehensible, we relax the requirements of our algorithm. More specifically, we will show how robust our algorithm is, in the sense that using an approximate centrifugal and finding approximately thin directions does not prohibit the analysis. In the following sections, we will show how to implement these two steps together in our algorithm version."}, {"heading": "9.1 Approximating the Centroid", "text": "A sufficient approximation of the center for our purposes results from a simple application of standard algorithms for scanning points from convex fields (hit-and-run [9], ball-walk [10]). A similar application is found in Bertsimas and Vempala [4], where the authors use approximately centric calculations to solve linear programs. Our application faces the same problems as in [4]. Namely, in order to try efficiently from a convex body, it is required that the body be nearly isotropic. Although the body with which we begin is isotropic, this property is lost after cutting or projecting. Therefore, we need a linear transformation under which the body is ultimately in isotropic position. The many problems that occur when approaching the centrite are carefully treated in [4], so that we reflect the following result, which is implicit there (see Lem5 and Theorem 12: A single K-approximate curve)."}, {"heading": "9.2 Finding Approximately Thin Directions", "text": "Instead of recovering exactly the direction u (K, u) \u2264 \u043c, we restore instead all directions along which w (K, u) \u2264 \u03b4\u03b1 and possibly some along which \u03b4\u03b1 \u2264 w (K, u) \u2264 \u043c. We do this by calculating an elliptical approximation to K. In fact, if we have access to an ellipsoid E so that E K \u03b1E, we can find a direction u so that w (K, u) \u2264 \u03b4 is by checking whether E has a direction u, that w (E, u) \u2264 \u03b4 / \u03b1, or2. decides that w (K, u) \u0430 is for all u simply by proving that the smallest directional width of E is greater or equal to \u03b4 / \u03b1.This task can be accomplished simply by examining the eigenvalues of E. A natural conception of such an ellipsoid is the John ellipsoid."}, {"heading": "9.3 Obtaining a Polynomial Time Algorithm", "text": "The polynomial time version of our algorithm is very similar to the original one. Differences that make the calculation traceable are: 1. Instead of calculating the centrides exactly, we calculate the centride at distance \u03c1 = (B / D) O (1), via theorem 9.1.2. Each iteration of the algorithm updates the set St by repeatedly calculating the elliptical approximation described in sequence 9.3 and adding the direction u, which corresponds to the smallest eigenvalue of the ellipsoid, if it confirms that w (K, u) \u2264 \u043c. If no such direction is found, we know that w (K, u) \u2265 approx: = B / D (d + 1) for all U.A complete description of the new algorithm along with its analysis can be found in Appendix B. If we combine the results in this section, we get the following sentence: Theorem 9.4. There is an algorithm that runs in d / D (O)."}, {"heading": "A Deferred Proofs", "text": "We will do it in a sequence of two steps to get us V: = vol (K).Step 1: 0 (t).Step 1: 0 (t).Step 1: 0 (t).Step 1: 0 (t).Step 1: 0 (t).Step 2: 2 (t).Step 4 (t).4 (t).4 (t).4 (t).4 (t).4 (t).4 (t).4 (t).4 (t).4 (t).4 (t).4 (t).4 (t).4 (t).4 (t).4 (t).4 (t).4 (t).4 (t).4 (t).4 (t).4 (t).4 (t).4 (t).4).4 (t).4 (.4).4 (t).4.4 (t).4 (.4).4 (t).4 (.4).4 (t).4 (.4).4 (t).4 (t).4 (.4).4 (t).4 (t).4 (.4).4 (t).4 (t).4 (.4).4 (t).4 (.4 (t).4 (.4).4 (.4).4 (t).4 (.4 (.4).4 (t).4 (.4 (.4).4 (.4).4 (t).4 (.4 (.4).4 (.4).4 (.4).4 (.4).4 (.4).4 (t).4 (.4).4 (.4 (.4).4 (.4).4 (.4).4 (.4).4 (.4).4 (.4).4 (.4).4 (.4).4 (.4).4 (.4).4 (.4).4 (.4).4 (.4).4 (.4 (.4).4).4 (.4).4 ("}, {"heading": "B Polynomial Time Algorithm", "text": "The correctness of this algorithm follows from a simple modification of our original analysis (max.). In order to tolerate the fact that the centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid centroid"}], "references": [{"title": "Taming the monster: A fast and simple algorithm for contextual bandits", "author": ["Alekh Agarwal", "Daniel Hsu", "Satyen Kale", "John Langford", "Lihong Li", "Robert E Schapire"], "venue": "In Proceedings of ICML,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "Repeated contextual auctions with strategic buyers", "author": ["Kareem Amin", "Afshin Rostamizadeh", "Umar Syed"], "venue": "In Proceedings of NIPS, pages 622\u2013630,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2014}, {"title": "Online decision-making with high-dimensional covariates", "author": ["Hamsa Bastani", "Mohsen Bayati"], "venue": "Working paper, Stanford University,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2016}, {"title": "Solving convex programs by random walks", "author": ["Dimitris Bertsimas", "Santosh Vempala"], "venue": "J. ACM,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2004}, {"title": "Feature-based Dynamic Pricing", "author": ["Maxime C. Cohen", "Ilan Lobel", "Renato Paes Leme"], "venue": "In Proceedings of the 2016 ACM Conference on Economics and Computation, EC \u201916,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2016}, {"title": "Geometric algorithms and combinatorial optimization, volume 2", "author": ["Martin Gr\u00f6tschel", "L\u00e1szl\u00f3 Lov\u00e1sz", "Alexander Schrijver"], "venue": "Springer Science & Business Media,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2012}, {"title": "Partitions of mass-distributions and of convex bodies by hyperplanes", "author": ["Branko Gr\u00fcnbaum"], "venue": "Pacific Journal of Mathematics,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1960}, {"title": "Dynamic pricing in high-dimensions", "author": ["Adel Javanmard", "Hamid Nazerzadeh"], "venue": "arXiv preprint arXiv:1609.07574,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2016}, {"title": "Hit-and-run mixes fast", "author": ["L\u00e1szl\u00f3 Lov\u00e1sz"], "venue": "Mathematical Programming,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1999}, {"title": "Faster mixing via average conductance", "author": ["L\u00e1szl\u00f3 Lov\u00e1sz", "Ravi Kannan"], "venue": "In Proceedings of the thirty-first annual ACM symposium on Theory of computing,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1999}, {"title": "Efficient methods in convex programming", "author": ["Arkadi Nemirovski"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2005}, {"title": "Dynamic pricing with demand covariates", "author": ["Sheng Qiang", "Mohsen Bayati"], "venue": "Available at SSRN 2765257,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2016}], "referenceMentions": [{"referenceID": 0, "context": "The binary search problem consists in trying to guess an unknown real number \u03b8 \u2208 [0, 1] given access to an oracle that replies for every guess xt if xt \u2264 \u03b8 or xt > \u03b8.", "startOffset": 81, "endOffset": 87}, {"referenceID": 2, "context": "We now mention two applications: Personalized Medicine [3]: Determining the right dosage of a drug for a given patient is a well-studied problem in the medical literature.", "startOffset": 55, "endOffset": 58}, {"referenceID": 2, "context": "Bastani and Bayati [3] propose a mathematical formulation for this problem and tackle it using tools from statistical learning and contextual bandits.", "startOffset": 19, "endOffset": 22}, {"referenceID": 1, "context": "Feature-based Pricing [2, 5, 12, 8]: Consider a firm that sells a very large number of differentiated products.", "startOffset": 22, "endOffset": 35}, {"referenceID": 4, "context": "Feature-based Pricing [2, 5, 12, 8]: Consider a firm that sells a very large number of differentiated products.", "startOffset": 22, "endOffset": 35}, {"referenceID": 11, "context": "Feature-based Pricing [2, 5, 12, 8]: Consider a firm that sells a very large number of differentiated products.", "startOffset": 22, "endOffset": 35}, {"referenceID": 7, "context": "Feature-based Pricing [2, 5, 12, 8]: Consider a firm that sells a very large number of differentiated products.", "startOffset": 22, "endOffset": 35}, {"referenceID": 4, "context": "Nevertheless, Cohen et al [5] showed that an algorithm for the multidimensional binary search problem can be converted into an algorithm for the feature-based pricing problem in a black-box manner.", "startOffset": 26, "endOffset": 29}, {"referenceID": 1, "context": "The first approach to this problem was due to Amin, Rostamizadeh and Syed [2] in the context of the pricing problem and is based on stochastic gradient descent.", "startOffset": 74, "endOffset": 77}, {"referenceID": 2, "context": "Subsequent approaches by Bastani and Bayati [3] and Qiang and Bayati [12] use techniques from statistical learning such as greedy least squares or LASSO.", "startOffset": 44, "endOffset": 47}, {"referenceID": 11, "context": "Subsequent approaches by Bastani and Bayati [3] and Qiang and Bayati [12] use techniques from statistical learning such as greedy least squares or LASSO.", "startOffset": 69, "endOffset": 73}, {"referenceID": 7, "context": "Javanmard and Nazerzadeh [8] apply a regularized maximum likelihood estimation approach and obtain an improved regret guarantee.", "startOffset": 25, "endOffset": 28}, {"referenceID": 0, "context": "[1]) to tackle the iid version of the multidimensional binary search problem, but such an algorithm would have regret that is polynomial in 1/\u01eb instead of the logarithmic regret obtained by the specialized algorithms.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "The only approach that makes no assumptions about the directions ut is by Cohen et al [5].", "startOffset": 86, "endOffset": 89}, {"referenceID": 4, "context": "1, we construct a lower bound of \u03a9(d log(1/\u01eb \u221a d)) via a reduction to d one-dimensional problems, which is significantly lower than the O(d2 log(d/\u01eb)) regret bound from Cohen et al [5].", "startOffset": 181, "endOffset": 184}, {"referenceID": 3, "context": "An idea similar to this one was proposed by Bertsimas and Vempala [4], in a paper where they proposed a method for solving linear programs via an approximate Gr\u00fcnbaum theorem.", "startOffset": 66, "endOffset": 69}, {"referenceID": 6, "context": "See Gr\u00fcnbaum [7] for the original proof of this theorem, or Nemirovski [11] for a more recent exposition.", "startOffset": 13, "endOffset": 16}, {"referenceID": 10, "context": "See Gr\u00fcnbaum [7] for the original proof of this theorem, or Nemirovski [11] for a more recent exposition.", "startOffset": 71, "endOffset": 75}, {"referenceID": 0, "context": "If K = \u2206(y)\u00d7 [0, 1] then there is a sequence of \u03a9(k log(1/\u01eb)) directions ut such that the Centroid algorithm incurs \u03a9(k log(1\u01eb )) regret and by the end of the sequence, the knowledge set has the form: K \u2032 = \u2206(s)\u00d7 [0, 1] where s \u2208 Rk+1, 0 \u2264 s\u2032i \u2264 \u01eb for i < k + 1, 1 4 \u2264 s\u2032i \u2264 1.", "startOffset": 13, "endOffset": 19}, {"referenceID": 0, "context": "If K = \u2206(y)\u00d7 [0, 1] then there is a sequence of \u03a9(k log(1/\u01eb)) directions ut such that the Centroid algorithm incurs \u03a9(k log(1\u01eb )) regret and by the end of the sequence, the knowledge set has the form: K \u2032 = \u2206(s)\u00d7 [0, 1] where s \u2208 Rk+1, 0 \u2264 s\u2032i \u2264 \u01eb for i < k + 1, 1 4 \u2264 s\u2032i \u2264 1.", "startOffset": 213, "endOffset": 219}, {"referenceID": 0, "context": "Start with the set K0 = [0, 1] d.", "startOffset": 24, "endOffset": 30}, {"referenceID": 0, "context": "We did not do our computations above using this scaled down instance instead of [0, 1]d in order to avoid carrying extra \u221a d terms.", "startOffset": 80, "endOffset": 86}, {"referenceID": 8, "context": "1 Approximating the Centroid An approximation of the centroid sufficient for our purposes follows from a simple application of standard algorithms for sampling points from convex bodies (hit-and-run [9], ball-walk [10]).", "startOffset": 199, "endOffset": 202}, {"referenceID": 9, "context": "1 Approximating the Centroid An approximation of the centroid sufficient for our purposes follows from a simple application of standard algorithms for sampling points from convex bodies (hit-and-run [9], ball-walk [10]).", "startOffset": 214, "endOffset": 218}, {"referenceID": 3, "context": "similar application can be found in Bertsimas and Vempala [4], where the authors use approximate centroid computation in order to solve linear programs.", "startOffset": 58, "endOffset": 61}, {"referenceID": 3, "context": "Our application faces the same issues as in [4].", "startOffset": 44, "endOffset": 47}, {"referenceID": 3, "context": "The many issues encountered when approximating the centroid are carefully handled in [4], so we will restate the following result which is implicit there (see Lemma 5 and Theorem 12): Theorem 9.", "startOffset": 85, "endOffset": 88}, {"referenceID": 3, "context": "1 ([4]).", "startOffset": 3, "endOffset": 6}, {"referenceID": 5, "context": "Such a result is provided in Gr\u00f6tschel et al [6], which we reproduce below for completeness (see Corollary 4.", "startOffset": 45, "endOffset": 48}, {"referenceID": 5, "context": "2 ([6]).", "startOffset": 3, "endOffset": 6}], "year": 2016, "abstractText": "We consider a multidimensional search problem that is motivated by questions in contextual decision-making, such as dynamic pricing and personalized medicine. Nature selects a state from a d-dimensional unit ball and then generates a sequence of d-dimensional directions. We are given access to the directions, but not access to the state. After receiving a direction, we have to guess the value of the dot product between the state and the direction. Our goal is to minimize the number of times when our guess is more than \u01eb away from the true answer. We construct a polynomial time algorithm that we call Projected Volume achieving regret O(d log(d/\u01eb)), which is optimal up to a log d factor. The algorithm combines a volume cutting strategy with a new geometric technique that we call cylindrification.", "creator": "LaTeX with hyperref package"}}}