{"id": "1611.00873", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Nov-2016", "title": "Extracting Actionability from Machine Learning Models by Sub-optimal Deterministic Planning", "abstract": "A main focus of machine learning research has been improving the generalization accuracy and efficiency of prediction models. Many models such as SVM, random forest, and deep neural nets have been proposed and achieved great success. However, what emerges as missing in many applications is actionability, i.e., the ability to turn prediction results into actions. For example, in applications such as customer relationship management, clinical prediction, and advertisement, the users need not only accurate prediction, but also actionable instructions which can transfer an input to a desirable goal (e.g., higher profit repays, lower morbidity rates, higher ads hit rates). Existing effort in deriving such actionable knowledge is few and limited to simple action models which restricted to only change one attribute for each action. The dilemma is that in many real applications those action models are often more complex and harder to extract an optimal solution.", "histories": [["v1", "Thu, 3 Nov 2016 03:53:41 GMT  (287kb)", "http://arxiv.org/abs/1611.00873v1", "16 pages, 4 figures"]], "COMMENTS": "16 pages, 4 figures", "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["qiang lyu", "yixin chen", "zhaorong li", "zhicheng cui", "ling chen", "xing zhang", "haihua shen"], "accepted": false, "id": "1611.00873"}, "pdf": {"name": "1611.00873.pdf", "metadata": {"source": "CRF", "title": "Extracting Actionability from Machine Learning Models by Sub-optimal Deterministic Planning", "authors": ["Qiang Lyu", "Yixin Chen", "Zhaorong Li", "Zhicheng Cui", "Ling Chen", "Xing Zhang", "Haihua Shen"], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 161 1.00 873v 1 [cs.A I] 3 Nov 201 6In this work, we propose a novel approach that achieves feasibility through the combination of learning and planning, two core areas of AI. In particular, we propose a framework to extract actionable knowledge from random forests, one of the most widely used and best standard classifiers. We formulate the feasibility problem to a suboptimal action plan problem (SOAP), which consists in finding a plan to change certain characteristics of a given input in such a way that the random forest would provide desirable output while minimizing the total cost of the measures. Technically, the SOAP problem is formulated in the planning formalism SAS + and solved using a Max SAT-based approach. Our experimental results show the effectiveness and efficiency of the proposed approach using a personal credit data and other benchmarks, weighted knowledge turns out to be a new application of an automated learning paradigm: our knowledge based on an automated plan."}, {"heading": "1. Introduction", "text": "This year, it has come to the point that it has never come as far as it has this year."}, {"heading": "2. Preliminaries", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1. Random forest", "text": "Random forest is a popular model for classification, one of the main tasks of learning. The reasons why we choose random forest are: 1) In addition to superior classification / regression performance, random forest has many attractive features that many other models do not have Friedman et al. (2001), including support for multi-class classification and natural handling of missing values and data of mixed types. 2) Often referred to as one of the best standard features Friedman et al. (2001), random forest is widely used in many industrial products such as Kinect Shotton et al. (2013) and facial recognition in the Viola and Jones cameras (2004), and is the popular method for some competitions such as Web search ranking Mohan et al. (2011). Consider a dataset al."}, {"heading": "2.2. SAS+ formalism", "text": "In recent years, another indirect formalism, SAS +, has seen an increase in use due to its many beneficial properties, such as compact coding with multi-value variables, natural support for invariants, associated domain transitions (DTGs) and causal graphs (CGs) that capture important structural information, Ba \ufffd ckstro \ufffd m and Nebula (1995); Jonsson and Ba \ufffd ckstro \ufffd m (1998); Helmert (2006). In SAS + causal graphs, a planning problem is defined using a set of multi-value state variables."}, {"heading": "3. Sub-Optimal Actionable Plan (SOAP) Problem", "text": "First, we give an intuitive description of the SOAP problem. In the face of a random forest and an input x, the SOAP problem is to find a sequence of actions that, when applied to x, transform it into a new instance that has a desirable output designation from the random forest. Since each action incurs costs, it must also minimize the total cost of the action. Generally, the actions and their costs are determined by domain experts. For example, analysts at a credit card company can decide what actions they can perform and how much each action costs. There are two types of characteristics, soft attributes that can be changed at reasonable cost and hard attributes that cannot be changed at reasonable cost, such as gender Yang et al. (2003). We only consider actions that change soft attributes. Definition 7 (SOAP problem) A SOAP problem is a tuple soap (= H, c, O)."}, {"heading": "4. A Planning Approach to SOAP", "text": "The SOAP problem turns out to be a NP-hard problem, even if an action can change only one feature Cui et al. (2015). Therefore, we cannot expect an efficient algorithm to find its optimal solution. We propose a planning-based approach to solving the SOAP problem. Our approach consists of an offline pre-processing phase that only needs to be run once for a given random forest, and an online phase that is used to solve each SOAP problem."}, {"heading": "4.1. Action graph and preferred goals", "text": "Since there is typically an prohibitively high number of possible instances in the attribute space, it is too expensive and unnecessary to explore the entire space. We argue that the training data sets for building the random forest result in a representative distribution of instances. Therefore, in offline preprocessing, we form a plot graph and determine a preferred target state for each training session. Definition 8 (attribute partitions): Faced with a random forest of H, we divide the domain of each attribute xi (i = 1, \u00b7 \u00b7, M) into a number of partitions according to the following rules. 1. xi is divided into n partitions if xi is categorical and has n categories. 2. xi is divided into n + 1 partitions if xi is numeric and branched into H in all decision trees. Let's place the branched nodes (b1, \u00b7 bn), the partitions are {(\u2212), the partitions are {b1, b1, b2, \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 female."}, {"heading": "4.2. Online SAS+ planning", "text": "Once the first phase is complete, the results can be used to repeatedly solve SOAP instances = = i \u2032 s (i \u2032 s). We will now describe how to deal with a new instance xI and find the feasible plan.In the online SAS + planning, we will find a number of the closest states of s (xI) and use the combination of their goals to construct the target s * (xI).This is inspired by the idea of similarity-based learning methods such as k-closest neighboring states (kNN). We will first define the similarity between two states. Definition 11 (characteristic similarity) Given two states s (x1, xM) and s * (x-next neighboring states), the similarity of the i-th function variable is defined as: \u2022 if the i-th function is categorized, i (s, s, s, s, s, s, s, s) and i-th states are not given."}, {"heading": "5. Experimental Results", "text": "In order to test the proposed approach to solving the SOAP problem, ILP provides an optimal approach."}, {"heading": "6. Conclusions", "text": "We investigated the problem of extracting actionable knowledge from random forests, one of the most widely used and best standard classifiers. We then formulated a sub-optimal actionable plan (SOAP) problem that aims to find an action sequence that can change the predictive power of an instance to a desired target with minimal total cost of action. We then proposed an SAS + planning approach to solve the SOAP problem. In an offline phase, we construct an action sequence and identify a preferred target for each instance in the training dataset. In the online planning phase, we formulate the SOAP problem as an SAS + planning instance based on preferred objectives, encode the SAS + problem on a WPMax SAT instance, and solve it by calling a WPMax SAT instance."}, {"heading": "Acknowledgments", "text": "This work was partially supported by the National Natural Science Foundation of China (No. 61502412, 61033009 and 61175057), the Natural Science Foundation of the Jiangsu Province (No. BK20150459), the Natural Science Foundation of the Jiangsu Higher Education Institutions (No. 15KJB520036), the National Science Foundation, United States (IIS-0534699, IIS-0713109, CNS-1017701) and a Microsoft Research New Faculty Fellowship."}], "references": [{"title": "Complexity results for sas+ planning", "author": ["C. B\u00e4ckstr\u00f6m", "B. Nebel"], "venue": "Computational Intelligence,", "citeRegEx": "B\u00e4ckstr\u00f6m and Nebel.,? \\Q1995\\E", "shortCiteRegEx": "B\u00e4ckstr\u00f6m and Nebel.", "year": 1995}, {"title": "On different strategies for eliminating redundant actions from plans", "author": ["Tom\u00e1\u0161 Balyo", "Luk\u00e1\u0161 Chrpa", "Asma Kilani"], "venue": "In Seventh Annual Symposium on Combinatorial Search,", "citeRegEx": "Balyo et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Balyo et al\\.", "year": 2014}, {"title": "Fast planning through planning graph analysis", "author": ["A. Blum", "M.L. Furst"], "venue": "Artificial Intelligence,", "citeRegEx": "Blum and Furst.,? \\Q1997\\E", "shortCiteRegEx": "Blum and Furst.", "year": 1997}, {"title": "Knowledge actionability: satisfying technical and business interestingness", "author": ["L. Cao", "D. Luo", "C. Zhang"], "venue": "International Journal of Business Intelligence and Data Mining,", "citeRegEx": "Cao et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Cao et al\\.", "year": 2007}, {"title": "Domain-driven, actionable knowledge discovery", "author": ["L. Cao", "C. Zhang", "D. Taniar", "E. Dubossarsky", "W. Graco", "Q. Yang", "D. Bell", "M. Vlachos", "B. Taneri", "E. Keogh"], "venue": "IEEE Intelligent Systems,", "citeRegEx": "Cao et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Cao et al\\.", "year": 2007}, {"title": "Flexible frameworks for actionable knowledge discovery", "author": ["L. Cao", "Y. Zhao", "H. Zhang", "D. Luo", "C. Zhang", "E.K. Park"], "venue": "IEEE Transactions on Knowledge and Data Engineering,", "citeRegEx": "Cao et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Cao et al\\.", "year": 2010}, {"title": "Optimal action extraction for random forests and boosted trees", "author": ["Z. Cui", "W. Chen", "Y. He", "Y. Chen"], "venue": "In Proc. ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "Cui et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Cui et al\\.", "year": 2015}, {"title": "Crisp: customer response based iterative segmentation procedures for response modeling in direct marketing", "author": ["W.S. DeSarbo", "V. Ramaswamy"], "venue": "Journal of Direct Marketing,", "citeRegEx": "DeSarbo and Ramaswamy.,? \\Q1994\\E", "shortCiteRegEx": "DeSarbo and Ramaswamy.", "year": 1994}, {"title": "PDDL2.1: An extension to PDDL for expressing temporal planning domains", "author": ["M. Fox", "D. Long"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Fox and Long.,? \\Q2003\\E", "shortCiteRegEx": "Fox and Long.", "year": 2003}, {"title": "A decision-theoretic generalization of online learning and an application to boosting", "author": ["Y. Freund", "R.E. Schapire"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "Freund and Schapire.,? \\Q1997\\E", "shortCiteRegEx": "Freund and Schapire.", "year": 1997}, {"title": "The elements of statistical learning, volume", "author": ["J. Friedman", "T. Hastie", "R. Tibshirani"], "venue": null, "citeRegEx": "Friedman et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Friedman et al\\.", "year": 2001}, {"title": "The fast downward planning system", "author": ["M. Helmert"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Helmert.,? \\Q2006\\E", "shortCiteRegEx": "Helmert.", "year": 2006}, {"title": "Applying objective interestingness measures in data mining systems", "author": ["R.J. Hilderman", "H.J. Hamilton"], "venue": "In Proc. Principles of Data Mining and Knowledge Discovery,", "citeRegEx": "Hilderman and Hamilton.,? \\Q2000\\E", "shortCiteRegEx": "Hilderman and Hamilton.", "year": 2000}, {"title": "A novel transition based encoding scheme for planning as satisfiability", "author": ["R. Huang", "Y. Chen", "W. Zhang"], "venue": "In Proc. AAAI Conference on Artificial Intelligence,", "citeRegEx": "Huang et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Huang et al\\.", "year": 2010}, {"title": "SAS+ planning as satisfiability", "author": ["R. Huang", "Y. Chen", "W. Zhang"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Huang et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Huang et al\\.", "year": 2012}, {"title": "State-variable planning under structural restrictions: Algorithms and complexity", "author": ["P. Jonsson", "C. B\u00e4ckstr\u00f6m"], "venue": "Artificial Intelligence,", "citeRegEx": "Jonsson and B\u00e4ckstr\u00f6m.,? \\Q1998\\E", "shortCiteRegEx": "Jonsson and B\u00e4ckstr\u00f6m.", "year": 1998}, {"title": "Planning as satisfiability", "author": ["H. Kautz", "B. Selman"], "venue": "In Proc. European Conference on Artificial Intelligence,", "citeRegEx": "Kautz and Selman.,? \\Q1992\\E", "shortCiteRegEx": "Kautz and Selman.", "year": 1992}, {"title": "Segmentation analysis with managerial judgment", "author": ["N. Levin", "J. Zahavi"], "venue": "Journal of Direct Marketing,", "citeRegEx": "Levin and Zahavi.,? \\Q1996\\E", "shortCiteRegEx": "Levin and Zahavi.", "year": 1996}, {"title": "Post-analysis of learned rules", "author": ["B. Liu", "W. Hsu"], "venue": "In Proc. AAAI Conference on Artificial Intelligence,", "citeRegEx": "Liu and Hsu.,? \\Q1996\\E", "shortCiteRegEx": "Liu and Hsu.", "year": 1996}, {"title": "Pruning and summarizing the discovered associations", "author": ["B. Liu", "W. Hsu", "Y. Ma"], "venue": "In Proc. ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "Liu et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Liu et al\\.", "year": 1999}, {"title": "A SAT-based approach to cost-sensitive temporally expressive planning", "author": ["Q. Lu", "R. Huang", "Y. Chen", "Y. Xu", "W. Zhang", "G. Chen"], "venue": "ACM Transactions on Intelligent Systems and Technology,", "citeRegEx": "Lu et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Lu et al\\.", "year": 2014}, {"title": "Extracting optimal actionable plans from additive tree models", "author": ["Q. Lu", "Z. Cui", "Y. Chen", "X. Chen"], "venue": "Frontiers of Computer Science,", "citeRegEx": "Lu et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Lu et al\\.", "year": 2016}, {"title": "Machine learning and data mining", "author": ["T.M. Mitchell"], "venue": "Communications of the ACM,", "citeRegEx": "Mitchell.,? \\Q1999\\E", "shortCiteRegEx": "Mitchell.", "year": 1999}, {"title": "Web-search ranking with initialized gradient boosted regression trees", "author": ["A. Mohan", "Z. Chen", "K.Q. Weinberger"], "venue": "In Journal of Machine Learning Research,", "citeRegEx": "Mohan et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Mohan et al\\.", "year": 2011}, {"title": "Real-time human pose recognition in parts from single depth images", "author": ["J. Shotton", "T. Sharp", "A. Kipman", "A. Fitzgibbon", "M. Finocchio", "A. Blake", "M. Cook", "R. Moore"], "venue": "Communications of the ACM,", "citeRegEx": "Shotton et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Shotton et al\\.", "year": 2013}, {"title": "Robust real-time face detection", "author": ["P. Viola", "M.J. Jones"], "venue": "International Journal of Computer Vision,", "citeRegEx": "Viola and Jones.,? \\Q2004\\E", "shortCiteRegEx": "Viola and Jones.", "year": 2004}, {"title": "Postprocessing decision trees to extract actionable knowledge", "author": ["Q. Yang", "J. Yin", "C. Ling", "T. Chen"], "venue": "In Proc. IEEE International Conference on Data Mining,", "citeRegEx": "Yang et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Yang et al\\.", "year": 2003}, {"title": "Extracting actionable knowledge from decision trees", "author": ["Q. Yang", "J. Yin", "C. Ling", "R. Pan"], "venue": "IEEE Transactions on Knowledge and Data Engineering,", "citeRegEx": "Yang et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Yang et al\\.", "year": 2007}], "referenceMentions": [{"referenceID": 22, "context": "Successful models such as support vector machines (SVMs), random forests, and deep neural nets have been applied to vast industrial applications Mitchell (1999). However, in many applications, users may need not only a prediction model, but also suggestions on courses of actions to achieve desirable goals.", "startOffset": 145, "endOffset": 161}, {"referenceID": 3, "context": "Statisticians have adopted stochastic models to find specific rules of the response behavior of customer DeSarbo and Ramaswamy (1994); Levin and Zahavi (1996).", "startOffset": 105, "endOffset": 134}, {"referenceID": 3, "context": "Statisticians have adopted stochastic models to find specific rules of the response behavior of customer DeSarbo and Ramaswamy (1994); Levin and Zahavi (1996). There have also been efforts on the development of ranking mechanisms with business interests Hilderman and Hamilton (2000); Cao et al.", "startOffset": 105, "endOffset": 159}, {"referenceID": 3, "context": "Statisticians have adopted stochastic models to find specific rules of the response behavior of customer DeSarbo and Ramaswamy (1994); Levin and Zahavi (1996). There have also been efforts on the development of ranking mechanisms with business interests Hilderman and Hamilton (2000); Cao et al.", "startOffset": 105, "endOffset": 284}, {"referenceID": 3, "context": "There have also been efforts on the development of ranking mechanisms with business interests Hilderman and Hamilton (2000); Cao et al. (2007a) and pruning and summarizing learnt rules by considering similarity Liu and Hsu (1996); Liu et al.", "startOffset": 125, "endOffset": 144}, {"referenceID": 3, "context": "There have also been efforts on the development of ranking mechanisms with business interests Hilderman and Hamilton (2000); Cao et al. (2007a) and pruning and summarizing learnt rules by considering similarity Liu and Hsu (1996); Liu et al.", "startOffset": 125, "endOffset": 230}, {"referenceID": 3, "context": "There have also been efforts on the development of ranking mechanisms with business interests Hilderman and Hamilton (2000); Cao et al. (2007a) and pruning and summarizing learnt rules by considering similarity Liu and Hsu (1996); Liu et al. (1999); Cao et al.", "startOffset": 125, "endOffset": 249}, {"referenceID": 3, "context": "There have also been efforts on the development of ranking mechanisms with business interests Hilderman and Hamilton (2000); Cao et al. (2007a) and pruning and summarizing learnt rules by considering similarity Liu and Hsu (1996); Liu et al. (1999); Cao et al. (2007b, 2010). However, such approaches are not suitable for the problems studied in this paper due to two major drawbacks. First, they can not provide customized actionable knowledge for each individual since the rules or rankings are derived from the entire population of training data. Second, they did not consider the action costs while building the rules or rankings. For example, a low income housewife may be more sensitive to sales promotion driven by consumption target, while a social housewife may be more interested in promotions related to social networks. Thus, these rule-based and ranking algorithms cannot tackle these problems very well since they are not personalized for each customer. Another related work is extracting actionable knowledge from decision tree and additive tree models by bounded tree search and integer linear programming Yang et al. (2003, 2007); Cui et al. (2015). Yang\u2019s work focuses on finding optimal strategies by using a greedy strategy to search on one or multiple decision trees Yang et al.", "startOffset": 125, "endOffset": 1166}, {"referenceID": 3, "context": "There have also been efforts on the development of ranking mechanisms with business interests Hilderman and Hamilton (2000); Cao et al. (2007a) and pruning and summarizing learnt rules by considering similarity Liu and Hsu (1996); Liu et al. (1999); Cao et al. (2007b, 2010). However, such approaches are not suitable for the problems studied in this paper due to two major drawbacks. First, they can not provide customized actionable knowledge for each individual since the rules or rankings are derived from the entire population of training data. Second, they did not consider the action costs while building the rules or rankings. For example, a low income housewife may be more sensitive to sales promotion driven by consumption target, while a social housewife may be more interested in promotions related to social networks. Thus, these rule-based and ranking algorithms cannot tackle these problems very well since they are not personalized for each customer. Another related work is extracting actionable knowledge from decision tree and additive tree models by bounded tree search and integer linear programming Yang et al. (2003, 2007); Cui et al. (2015). Yang\u2019s work focuses on finding optimal strategies by using a greedy strategy to search on one or multiple decision trees Yang et al. (2003, 2007). Cui et al. use an integer linear programming (ILP) method to find actions changing sample membership on an ensemble of trees Cui et al. (2015). A limitation of these works is that the actions are assumed to change only one attribute each time.", "startOffset": 125, "endOffset": 1457}, {"referenceID": 3, "context": "There have also been efforts on the development of ranking mechanisms with business interests Hilderman and Hamilton (2000); Cao et al. (2007a) and pruning and summarizing learnt rules by considering similarity Liu and Hsu (1996); Liu et al. (1999); Cao et al. (2007b, 2010). However, such approaches are not suitable for the problems studied in this paper due to two major drawbacks. First, they can not provide customized actionable knowledge for each individual since the rules or rankings are derived from the entire population of training data. Second, they did not consider the action costs while building the rules or rankings. For example, a low income housewife may be more sensitive to sales promotion driven by consumption target, while a social housewife may be more interested in promotions related to social networks. Thus, these rule-based and ranking algorithms cannot tackle these problems very well since they are not personalized for each customer. Another related work is extracting actionable knowledge from decision tree and additive tree models by bounded tree search and integer linear programming Yang et al. (2003, 2007); Cui et al. (2015). Yang\u2019s work focuses on finding optimal strategies by using a greedy strategy to search on one or multiple decision trees Yang et al. (2003, 2007). Cui et al. use an integer linear programming (ILP) method to find actions changing sample membership on an ensemble of trees Cui et al. (2015). A limitation of these works is that the actions are assumed to change only one attribute each time. As we discussed above, actions like \u201csending promotion amt N\u201d may change multiple features, such as \u201cnbr promotion amt N\u201d and \u201cs amt N\u201d. Moreover, Yang\u2019s greedy method is fast but cannot give optimal solution Yang et al. (2003), and Cui\u2019s optimization method is optimal but very slow Cui et al.", "startOffset": 125, "endOffset": 1786}, {"referenceID": 3, "context": "There have also been efforts on the development of ranking mechanisms with business interests Hilderman and Hamilton (2000); Cao et al. (2007a) and pruning and summarizing learnt rules by considering similarity Liu and Hsu (1996); Liu et al. (1999); Cao et al. (2007b, 2010). However, such approaches are not suitable for the problems studied in this paper due to two major drawbacks. First, they can not provide customized actionable knowledge for each individual since the rules or rankings are derived from the entire population of training data. Second, they did not consider the action costs while building the rules or rankings. For example, a low income housewife may be more sensitive to sales promotion driven by consumption target, while a social housewife may be more interested in promotions related to social networks. Thus, these rule-based and ranking algorithms cannot tackle these problems very well since they are not personalized for each customer. Another related work is extracting actionable knowledge from decision tree and additive tree models by bounded tree search and integer linear programming Yang et al. (2003, 2007); Cui et al. (2015). Yang\u2019s work focuses on finding optimal strategies by using a greedy strategy to search on one or multiple decision trees Yang et al. (2003, 2007). Cui et al. use an integer linear programming (ILP) method to find actions changing sample membership on an ensemble of trees Cui et al. (2015). A limitation of these works is that the actions are assumed to change only one attribute each time. As we discussed above, actions like \u201csending promotion amt N\u201d may change multiple features, such as \u201cnbr promotion amt N\u201d and \u201cs amt N\u201d. Moreover, Yang\u2019s greedy method is fast but cannot give optimal solution Yang et al. (2003), and Cui\u2019s optimization method is optimal but very slow Cui et al. (2015). In order to address these challenges, we propose a novel approach to extract actionable knowledge from random forests, one of the most popular learning models.", "startOffset": 125, "endOffset": 1860}, {"referenceID": 10, "context": "The reasons why we choose Random forest are: 1) In addition to superior classification/regression performance, Random forest enjoys many appealing properties many other models lack Friedman et al. (2001), including the support for multi-class classification and natural handling of missing values and data of mixed types.", "startOffset": 181, "endOffset": 204}, {"referenceID": 10, "context": "The reasons why we choose Random forest are: 1) In addition to superior classification/regression performance, Random forest enjoys many appealing properties many other models lack Friedman et al. (2001), including the support for multi-class classification and natural handling of missing values and data of mixed types. 2) Often referred to as one of the best off-the-shelf classifier Friedman et al. (2001), Random forest has been widely deployed in many industrial products such as Kinect Shotton et al.", "startOffset": 181, "endOffset": 410}, {"referenceID": 10, "context": "The reasons why we choose Random forest are: 1) In addition to superior classification/regression performance, Random forest enjoys many appealing properties many other models lack Friedman et al. (2001), including the support for multi-class classification and natural handling of missing values and data of mixed types. 2) Often referred to as one of the best off-the-shelf classifier Friedman et al. (2001), Random forest has been widely deployed in many industrial products such as Kinect Shotton et al. (2013) and face detection in camera Viola and Jones (2004), and is the popular method for some competitions such as web search ranking Mohan et al.", "startOffset": 181, "endOffset": 515}, {"referenceID": 10, "context": "The reasons why we choose Random forest are: 1) In addition to superior classification/regression performance, Random forest enjoys many appealing properties many other models lack Friedman et al. (2001), including the support for multi-class classification and natural handling of missing values and data of mixed types. 2) Often referred to as one of the best off-the-shelf classifier Friedman et al. (2001), Random forest has been widely deployed in many industrial products such as Kinect Shotton et al. (2013) and face detection in camera Viola and Jones (2004), and is the popular method for some competitions such as web search ranking Mohan et al.", "startOffset": 181, "endOffset": 567}, {"referenceID": 10, "context": "The reasons why we choose Random forest are: 1) In addition to superior classification/regression performance, Random forest enjoys many appealing properties many other models lack Friedman et al. (2001), including the support for multi-class classification and natural handling of missing values and data of mixed types. 2) Often referred to as one of the best off-the-shelf classifier Friedman et al. (2001), Random forest has been widely deployed in many industrial products such as Kinect Shotton et al. (2013) and face detection in camera Viola and Jones (2004), and is the popular method for some competitions such as web search ranking Mohan et al. (2011). Consider a dataset {X,Y }, where X = {x1, \u00b7 \u00b7 \u00b7 , x} is the set of training samples and Y = {y1, \u00b7 \u00b7 \u00b7 , y} is the set of classification labels.", "startOffset": 181, "endOffset": 663}, {"referenceID": 7, "context": "SAS+ formalism In classical planning, there are two popular formalisms, STRIPS and PDDL Fox and Long (2003). In recent years, another indirect formalism, SAS+, has attracted increasing uses due to its many favorable features, such as compact encoding with multi-valued variables, natural support for invariants, associated domain transition graphs (DTGs) and causal graphs (CGs) which capture vital structural information B\u00e4ckstr\u00f6m and Nebel (1995); Jonsson and B\u00e4ckstr\u00f6m (1998); Helmert (2006).", "startOffset": 88, "endOffset": 108}, {"referenceID": 0, "context": "In recent years, another indirect formalism, SAS+, has attracted increasing uses due to its many favorable features, such as compact encoding with multi-valued variables, natural support for invariants, associated domain transition graphs (DTGs) and causal graphs (CGs) which capture vital structural information B\u00e4ckstr\u00f6m and Nebel (1995); Jonsson and B\u00e4ckstr\u00f6m (1998); Helmert (2006).", "startOffset": 313, "endOffset": 340}, {"referenceID": 0, "context": "In recent years, another indirect formalism, SAS+, has attracted increasing uses due to its many favorable features, such as compact encoding with multi-valued variables, natural support for invariants, associated domain transition graphs (DTGs) and causal graphs (CGs) which capture vital structural information B\u00e4ckstr\u00f6m and Nebel (1995); Jonsson and B\u00e4ckstr\u00f6m (1998); Helmert (2006).", "startOffset": 313, "endOffset": 370}, {"referenceID": 0, "context": "In recent years, another indirect formalism, SAS+, has attracted increasing uses due to its many favorable features, such as compact encoding with multi-valued variables, natural support for invariants, associated domain transition graphs (DTGs) and causal graphs (CGs) which capture vital structural information B\u00e4ckstr\u00f6m and Nebel (1995); Jonsson and B\u00e4ckstr\u00f6m (1998); Helmert (2006). In SAS+ formalism, a planning problem is defined over a set of multi-valued state variables X = {x1, \u00b7 \u00b7 \u00b7 , x|X |}.", "startOffset": 313, "endOffset": 386}, {"referenceID": 26, "context": "There are two kinds of features, soft attributes which can be changed with reasonable costs and hard attributes which cannot be changed with a reasonable cost, such as gender Yang et al. (2003). We only consider actions that change soft attributes.", "startOffset": 175, "endOffset": 194}, {"referenceID": 6, "context": "A Planning Approach to SOAP The SOAP problem is proven to be an NP-hard problem, even when an action can change only one feature Cui et al. (2015). Therefore, we cannot expect any efficient algorithm for optimally solving it.", "startOffset": 129, "endOffset": 147}, {"referenceID": 15, "context": "Our method follows the bounded SAT solving strategy, originally proposed in SATPlan Kautz and Selman (1992) and Graphplan Blum and Furst (1997).", "startOffset": 84, "endOffset": 108}, {"referenceID": 2, "context": "Our method follows the bounded SAT solving strategy, originally proposed in SATPlan Kautz and Selman (1992) and Graphplan Blum and Furst (1997). It starts from a lower bound of makespan (L=1), encodes the SAS+ problem as a weighted partial Max-SAT (WPMax-SAT) instance Lu et al.", "startOffset": 122, "endOffset": 144}, {"referenceID": 2, "context": "Our method follows the bounded SAT solving strategy, originally proposed in SATPlan Kautz and Selman (1992) and Graphplan Blum and Furst (1997). It starts from a lower bound of makespan (L=1), encodes the SAS+ problem as a weighted partial Max-SAT (WPMax-SAT) instance Lu et al. (2014), and either proves it unsatisfiable or finds a plan while trying to minimize total action costs at the same time.", "startOffset": 122, "endOffset": 286}, {"referenceID": 1, "context": "Using soft clauses to optimize the plan in our WPMax-SAT encoding is similar to Balyo\u2019s work Balyo et al. (2014) which uses a MAXSAT based approach for plan optimization (removing redundant actions).", "startOffset": 93, "endOffset": 113}, {"referenceID": 19, "context": "2) A sub-optimal state space method denoted as \u201cNS\u201d Lu et al. (2016). 3) An integer linear programming (ILP) method Cui et al.", "startOffset": 52, "endOffset": 69}, {"referenceID": 6, "context": "3) An integer linear programming (ILP) method Cui et al. (2015), one of the state-of-the-art algorithms for solving the SOAP problem.", "startOffset": 46, "endOffset": 64}, {"referenceID": 6, "context": "3) An integer linear programming (ILP) method Cui et al. (2015), one of the state-of-the-art algorithms for solving the SOAP problem. ILP gives exact optimal solutions. We test these algorithms on a real-world credit card company dataset (\u201cCredit\u201d) and other nine benchmark datasets from the UCI repository2 and the LibSVM website3 used in ILP\u2019s original experiments Cui et al. (2015). Information of the datasets is listed in Table 1.", "startOffset": 46, "endOffset": 385}, {"referenceID": 19, "context": "Note that the proposed action extraction algorithm can be easily expanded to other additive tree models (ATMs) Lu et al. (2016), such as adaboost Freund and Schapire (1997), gradient boosting trees Friedman.", "startOffset": 111, "endOffset": 128}, {"referenceID": 9, "context": "(2016), such as adaboost Freund and Schapire (1997), gradient boosting trees Friedman.", "startOffset": 25, "endOffset": 52}], "year": 2016, "abstractText": "A main focus of machine learning research has been improving the generalization accuracy and efficiency of prediction models. Many models such as SVM, random forest, and deep neural nets have been proposed and achieved great success. However, what emerges as missing in many applications is actionability, i.e., the ability to turn prediction results into actions. For example, in applications such as customer relationship management, clinical prediction, and advertisement, the users need not only accurate prediction, but also actionable instructions which can transfer an input to a desirable goal (e.g., higher profit repays, lower morbidity rates, higher ads hit rates). Existing effort in deriving such actionable knowledge is few and limited to simple action models which restricted to only change one attribute for each action. The dilemma is that in many real applications those action models are often more complex and harder to extract an optimal solution. In this paper, we propose a novel approach that achieves actionability by combining learning with planning, two core areas of AI. In particular, we propose a framework to extract actionable knowledge from random forest, one of the most widely used and best off-the-shelf classifiers. We formulate the actionability problem to a sub-optimal action planning (SOAP) problem, which is to find a plan to alter certain features of a given input so that the random forest would yield a desirable output, while minimizing the total costs of actions. Technically, the SOAP problem is formulated in the SAS+ planning formalism, and solved using a Max-SAT based approach. Our experimental results demonstrate the effectiveness and efficiency of the proposed approach on a personal credit dataset and other benchmarks. Our work represents a new application of automated planning on an emerging and challenging machine learning paradigm.", "creator": "LaTeX with hyperref package"}}}