{"id": "1611.01101", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Nov-2016", "title": "CogALex-V Shared Task: ROOT18", "abstract": "In this paper, we describe ROOT 18, a classifier using the scores of several unsupervised distributional measures as features to discriminate between semantically related and unrelated words, and then to classify the related pairs according to their semantic relation (i.e. synonymy, antonymy, hypernymy, part-whole meronymy). Our classifier participated in the CogALex-V Shared Task, showing a solid performance on the first subtask, but a poor performance on the second subtask. The low scores reported on the second subtask suggest that distributional measures are not sufficient to discriminate between multiple semantic relations at once.", "histories": [["v1", "Thu, 3 Nov 2016 17:41:47 GMT  (17kb)", "http://arxiv.org/abs/1611.01101v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["emmanuele chersoni", "giulia rambelli", "enrico santus"], "accepted": false, "id": "1611.01101"}, "pdf": {"name": "1611.01101.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["emmanuelechersoni@gmail.com", "rambelligiulia@gmail.com", "esantus@gmail.com"], "sections": [{"heading": null, "text": "ar Xiv: 161 1.01 101v 1 [cs.C L] 3N ov2 016"}, {"heading": "1 Introduction", "text": "The system described in this paper was designed for the CogALex-V Shared Task and focuses on the body-based identification of semantic relationships. As distribution semantic models (henceforth DSMs) were proposed as a specific topic of interest for the current edition of the CogALex workshop, we decided to base our classifier on a set of distribution measures used in the past by Natural Language Processing (NLP) research to distinguish between a specific semantic relationship and other relationship types. The task is divided into the following subtasks: \u2022 for each pair of words, the participating systems must decide whether the terms are semantically related or not (TRUE and FALSE are the only possible outcomes); \u2022 for each pair of words, the participating systems must decide what semantic relationship exists between the terms of the pair, with the five possible semantic relationships ynonetheless (our Yonmy), our system (our YonyANT) and (our) hyper-critical relationship (our)."}, {"heading": "2 The Task: Related Work", "text": "In fact, most of them will be able to orient themselves in a different direction than in the other direction, namely the direction in which they are moving."}, {"heading": "3 System description", "text": "Our system, ROOT18, is a Random Forest classifier (Breiman, 2001) and is based on the 18 characteristics described in the following sections. At its best setting, the system uses the Gini impurity index as the division criterion and has 10 as the maximum tree depth. Half of the total number of characteristics was considered for each split."}, {"heading": "3.1 Data", "text": "Our data comes from ukWaC (Baroni et al., 2009), a 2 billion token corpus in English created by searching the.uk Internet domain. To extract our characteristics, we have created several distribution spaces that differ according to window size and the statistical measure of association used to weight raw coexistence. Since we obtained the best results with window size 2 and Positive Pointwise Mutual Information (Church and Hanks, 1990), we report the results only for this setting."}, {"heading": "3.2 Features", "text": "In fact, most people are able to decide whether they will be able to move, to move, to move, to move, to move, to move, to move, to move, to move, to defend themselves, to defend themselves, to defend themselves, to dig, to dig, to dig, to dig, to dig, to hunt, to hunt, to hunt, to hunt, to hunt, to hunt, to hunt, to hunt, to hunt, to hunt, to hunt, to hunt, to hunt, to hunt, to hunt, to hunt, to hunt, to hunt, to hunt, to hunt, to hunt, to hunt, to hunt, to hunt, to hunt, to hunt, to hunt, to hunt, to hunt, to hunt, to hunt, to hunt, to hunt, to hunt, to hunt, to hunt, to hunt, to hunt, to hunt, to hunt, to hunt, to hunt, to hunt, to hunt."}, {"heading": "3.3 Evaluation dataset", "text": "The task organizers provided training and a test set from EVALution 1.0, a resource specifically designed for the evaluation of systems for identifying semantic relationships (Santus et al., 2015). EVALution 1.0 was derived from WordNet (Fellbaum, 1998) and ConceptNet (Liu and Singh, 2004) and consists of almost 7,500 word pairs that initiate multiple semantic relationships. The training and test set consisted of 3,054 and 4,260 word pairs, respectively, and they are divided lexically, meaning that the two sentences do not share a pair. Since words were not tagged, we conducted POS tagging with the TreeTagger (Schmid, 1995)."}, {"heading": "4 Results", "text": "As can be seen from Table 1, ROOT18 performs solidly in subproblem 1, and it is pretty much accurate in separating related terms from unrelated ones. Generally, we have noticed that the classifier performs better when the Gini impurity index is used as a splitting criterion instead of entropy. The 1000 estimator model is our best performing with precision = 0.823, recall = 0.657, and F-score = 0.731. In terms of the contribution of characteristics, APSyn1000 and vector cosinus have the highest relative importance, with corresponding contributions of 0.29 and 0.12 to the prediction function. This is not at all surprising, since APSyn and Kosinus have already proven to be strong predictors of semantic similarity. Results are much less convincing for subproblem 2. In particular, the memory values are extremely low, especially for some of the semantic relationships: part of, for example, is often below 0.15."}, {"heading": "4.1 Conclusions", "text": "Our results clearly underscore the difficulty of DSMs to distinguish multiple semantic relationships at once. Indeed, such models are based on a vague definition of semantic similarity (i.e. distributional similarity), which does not offer a principled way to distinguish between different types of semantic relationships. Nevertheless, it is still possible for traditional DSMs to achieve good performance in recognizing taxonomic relationships (Santus et al., 2016a), for which metrics can be defined based on feature inclusion, context informativity, etc. For other relationships, such as antonymy and meronymy, it is not easy to define actions based on distributional similarity (for the latter relationship, it is even difficult to find a clear definition: see Morlane-Honde-Re (2015))): APAnt works relatively well in distinguishing antonyms from synonyms, but - as Santus et al al (2015b) - this measure is also often based on the v\u00e9ra, which we assume is a cosmic measure of v\u00e9ra."}, {"heading": "5 Acknowledgements", "text": "This work was carried out with the support of the A * MIDEX Fellowship (No. ANR-11-IDEX-0001-02), which is funded by the French Government's Investissements d'Avenir programme."}], "references": [{"title": "The WaCky wide web: a collection of very large linguistically processed web-crawled corpora", "author": ["Baroni et al.2009] Marco Baroni", "Silvia Bernardini", "Adriano Ferraresi", "Eros Zanchetta"], "venue": "Language resources and evaluation,", "citeRegEx": "Baroni et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Baroni et al\\.", "year": 2009}, {"title": "Don\u2019t count, predict! A systematic comparison of context-counting vs. context-predicting semantic vectors", "author": ["Baroni et al.2014] Baroni", "Marco", "Georgiana Dinu", "German Kruszewski"], "venue": "Proceedings of ACL,", "citeRegEx": "Baroni et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Baroni et al\\.", "year": 2014}, {"title": "Word association norms, mutual information, and lexicography", "author": ["Church", "Hanks1990] Kenneth Ward Church", "Patrick Hanks"], "venue": "Computational linguistics,", "citeRegEx": "Church et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Church et al\\.", "year": 1990}, {"title": "Analogy-based detection of morphological and semantic relations with word embeddings: what works and what doesn\u2019t Proceedings of SRW@HLT-NAACL", "author": ["Anna Gladkova", "Aleksandr Drozd", "Satoshi Matsuoka"], "venue": null, "citeRegEx": "Gladkova et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Gladkova et al\\.", "year": 2016}, {"title": "Deriving Boolean structures from distributional vectors", "author": ["Denis Paperno", "Marco Baroni"], "venue": "TACL,", "citeRegEx": "Kruszewski et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kruszewski et al\\.", "year": 2015}, {"title": "Do Supervised Distributional Methods Really Learn Lexical Inference Relations", "author": ["Levy et al.2015] Omer Levy", "Steffen Remus", "Chris Biemann", "Ido Dagan"], "venue": "Proceedings of NAACL HLT", "citeRegEx": "Levy et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Levy et al\\.", "year": 2015}, {"title": "Improving distributional similarity with lessons learned from word", "author": ["Levy et al.2015] Omer Levy", "Yoav Goldberg", "Ido Dagan"], "venue": "embeddings. TACL,", "citeRegEx": "Levy et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Levy et al\\.", "year": 2015}, {"title": "An information-theoretic definition of similarity", "author": ["Dekang Lin"], "venue": null, "citeRegEx": "Lin.,? \\Q1998\\E", "shortCiteRegEx": "Lin.", "year": 1998}, {"title": "ConceptNet: a practical commonsense reasoning toolkit", "author": ["Liu", "Singh2004] Hugo Liu", "Push Singh"], "venue": "BT technology journal,", "citeRegEx": "Liu et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2004}, {"title": "Computing Lexical Contrast", "author": ["Saif M. Mohammad", "Bonnie J. Dorr", "Graeme Hirst", "Peter D. Turney"], "venue": "Computational Linguistics,", "citeRegEx": "Mohammad et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mohammad et al\\.", "year": 2013}, {"title": "Semantic relations and the lexicon: Antonymy, synonymy and other paradigms", "author": ["Lynne G Murphy"], "venue": null, "citeRegEx": "Murphy.,? \\Q2003\\E", "shortCiteRegEx": "Murphy.", "year": 2003}, {"title": "Integrating Distributional Lexical Contrast into Word Embeddings for Antonym-Synonym Distinction", "author": ["Sabine Schulte im Walde", "Ngoc Thang Vu"], "venue": "Proceedings of ACL", "citeRegEx": "Nguyen et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Nguyen et al\\.", "year": 2016}, {"title": "Espresso: Leveraging Generic Patterns for Automatically Harvesting Semantic Relations", "author": ["Pantel", "Marco Pennacchiotti"], "venue": "Proceedings of COLING ACL:", "citeRegEx": "Pantel et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Pantel et al\\.", "year": 2006}, {"title": "Inclusive yet Selective: Supervised Distributional Hypernymy Detection", "author": ["Katrin Erk", "Gemma Boleda"], "venue": "Proceedings of COLING:", "citeRegEx": "Roller et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Roller et al\\.", "year": 2014}, {"title": "Relations such as Hypernymy: Identifying and Exploiting Hearst Patterns in Distributional Vectors for Lexical Entailment", "author": ["Roller", "Erk2016] Stephen Roller", "Katrin Erk"], "venue": "Proceedings of EMNLP", "citeRegEx": "Roller et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Roller et al\\.", "year": 2016}, {"title": "Taking antonymy mask off in vector space", "author": ["Santus et al.2014] Enrico Santus", "Qin Lu", "Alessandro Lenci", "Chu-Ren Huang"], "venue": "Proceedings of PACLIC", "citeRegEx": "Santus et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Santus et al\\.", "year": 2014}, {"title": "EVALution 1.0: an Evolving Semantic Dataset for Training and Evaluation of Distributional Semantic Models", "author": ["Santus et al.2015] Enrico Santus", "Frances Yung", "Alessandro Lenci", "Chu-Ren Huang"], "venue": "Proceedings of the ACL Workshop on Linked Data in Linguistics:", "citeRegEx": "Santus et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Santus et al\\.", "year": 2015}, {"title": "Nine Features in a Random Forest to Learn Taxonomical Semantic Relations", "author": ["Alessandro Lenci", "Tin-Shing Chiu", "Qin Lu", "Chu-Ren Huang"], "venue": "Proceedings of LREC", "citeRegEx": "Santus et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Santus et al\\.", "year": 2016}, {"title": "What a Nerd! Beating Students and Vector Cosine in the ESL and TOEFL Datasets", "author": ["Tin-Shing Chiu", "Qin Lu", "Alessandro Lenci", "Chu-Ren Huang"], "venue": "Proceedings of LREC", "citeRegEx": "Santus et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Santus et al\\.", "year": 2016}, {"title": "Treetagger: a language independent part-of-speech tagger. Institut f\u00fcr Maschinelle Sprachverarbeitung, Universit\u00e4t Stuttgart", "author": ["Helmut Schmid"], "venue": null, "citeRegEx": "Schmid.,? \\Q1995\\E", "shortCiteRegEx": "Schmid.", "year": 1995}, {"title": "A Mathematical Theory of Communication", "author": ["Claude Shannon"], "venue": "Bell System Technical Journal,", "citeRegEx": "Shannon.,? \\Q1948\\E", "shortCiteRegEx": "Shannon.", "year": 1948}, {"title": "Improving hypernymy detection with an integrated path-based and distributional method", "author": ["Yoav Goldberg", "Ido Dagan"], "venue": "Proceedings of ACL", "citeRegEx": "Shwartz et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Shwartz et al\\.", "year": 2016}, {"title": "A uniform approach to analogies, synonyms, antonyms, and associations", "author": ["Peter Turney"], "venue": "Proceedings of the 22nd International Conference on Computational Linguistics (Coling", "citeRegEx": "Turney.,? \\Q2008\\E", "shortCiteRegEx": "Turney.", "year": 2008}, {"title": "From frequency to meaning: Vector Space Models for semantics", "author": ["Turney", "Pantel2010] Peter Turney", "Patrick Pantel"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Turney et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Turney et al\\.", "year": 2010}, {"title": "A general framework for distributional similarity", "author": ["Weeds", "Weir2003] Julie Weeds", "David Weir"], "venue": "Proceedings of EMNLP:", "citeRegEx": "Weeds et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Weeds et al\\.", "year": 2003}, {"title": "Learning to Distinguish Hypernyms and Co-Hyponyms", "author": ["Weeds et al.2014] Julie Weeds", "Daoud Clarke", "Jeremy Reffin", "David J Weir", "Bill Keller"], "venue": "Proceedings of COLING:", "citeRegEx": "Weeds et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Weeds et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 15, "context": "The attempts to provide DSMs with the ability of automatically identifying semantic relations include a large number of unsupervised methods (Weeds and Weir, 2003; Lenci and Benotto, 2012; Santus et al., 2014), which are unfortunately far from achieving the perfect accuracy.", "startOffset": 141, "endOffset": 209}, {"referenceID": 25, "context": "In order to achieve higher performance, supervised methods have been recently adopted, also thanks to their ease (Weeds et al., 2014; Roller et al., 2014; Kruszewski et al., 2015; Roller and Erk, 2016; Santus et al., 2016a; Nguyen et al., 2016; Shwartz et al., 2016).", "startOffset": 113, "endOffset": 266}, {"referenceID": 13, "context": "In order to achieve higher performance, supervised methods have been recently adopted, also thanks to their ease (Weeds et al., 2014; Roller et al., 2014; Kruszewski et al., 2015; Roller and Erk, 2016; Santus et al., 2016a; Nguyen et al., 2016; Shwartz et al., 2016).", "startOffset": 113, "endOffset": 266}, {"referenceID": 4, "context": "In order to achieve higher performance, supervised methods have been recently adopted, also thanks to their ease (Weeds et al., 2014; Roller et al., 2014; Kruszewski et al., 2015; Roller and Erk, 2016; Santus et al., 2016a; Nguyen et al., 2016; Shwartz et al., 2016).", "startOffset": 113, "endOffset": 266}, {"referenceID": 11, "context": "In order to achieve higher performance, supervised methods have been recently adopted, also thanks to their ease (Weeds et al., 2014; Roller et al., 2014; Kruszewski et al., 2015; Roller and Erk, 2016; Santus et al., 2016a; Nguyen et al., 2016; Shwartz et al., 2016).", "startOffset": 113, "endOffset": 266}, {"referenceID": 21, "context": "In order to achieve higher performance, supervised methods have been recently adopted, also thanks to their ease (Weeds et al., 2014; Roller et al., 2014; Kruszewski et al., 2015; Roller and Erk, 2016; Santus et al., 2016a; Nguyen et al., 2016; Shwartz et al., 2016).", "startOffset": 113, "endOffset": 266}, {"referenceID": 5, "context": "On top of it, some scholars have questioned their ability to really learn semantic relations (Levy et al., 2015), claiming that they rather learn some lexical properties from the word vectors they are trained with.", "startOffset": 93, "endOffset": 112}, {"referenceID": 1, "context": "Recently, count based vectors have been substituted by prediction-based ones, which seem to slightly improve the performance in some tasks, such as similarity estimation (Baroni et al., 2014), even though Levy et al.", "startOffset": 170, "endOffset": 191}, {"referenceID": 5, "context": "On top of it, when combined with supervised methods, the low interpretability of their dimensions makes it even harder to understand what the classifiers actually learn (Levy et al., 2015).", "startOffset": 169, "endOffset": 188}, {"referenceID": 7, "context": "over the last few years have been proposed to tackle this problem, using both unsupervised and supervised approaches (see the works of Lenci and Benotto (2012) and Shwartz et al. (2016) on hypernymy; Weeds et al.", "startOffset": 164, "endOffset": 186}, {"referenceID": 7, "context": "over the last few years have been proposed to tackle this problem, using both unsupervised and supervised approaches (see the works of Lenci and Benotto (2012) and Shwartz et al. (2016) on hypernymy; Weeds et al. (2014) and Santus et al.", "startOffset": 164, "endOffset": 220}, {"referenceID": 5, "context": "(2014) and Santus et al. (2016a) on hypernymy and co-hyponymy; Mohammad et al.", "startOffset": 11, "endOffset": 33}, {"referenceID": 3, "context": "(2016a) on hypernymy and co-hyponymy; Mohammad et al. (2013) and Santus et al.", "startOffset": 38, "endOffset": 61}, {"referenceID": 3, "context": "(2016a) on hypernymy and co-hyponymy; Mohammad et al. (2013) and Santus et al. (2014) on antonymy).", "startOffset": 38, "endOffset": 86}, {"referenceID": 3, "context": "(2016a) on hypernymy and co-hyponymy; Mohammad et al. (2013) and Santus et al. (2014) on antonymy). However, many of these works focus on a single semantic relation, e.g. antonymy, and describe methods or measures to set it apart from other relations. There have not been many attempts, at the best of our knowledge, to deal with corpus-based semantic relation identification in a multiclass classification task. Few exceptions include the works by Turney (2008) on similarity, antonymy and analogy, and by Pantel and Pernacchiotti (2006) on Espresso, a weakly supervised, pattern-based algorithm.", "startOffset": 38, "endOffset": 463}, {"referenceID": 3, "context": "(2016a) on hypernymy and co-hyponymy; Mohammad et al. (2013) and Santus et al. (2014) on antonymy). However, many of these works focus on a single semantic relation, e.g. antonymy, and describe methods or measures to set it apart from other relations. There have not been many attempts, at the best of our knowledge, to deal with corpus-based semantic relation identification in a multiclass classification task. Few exceptions include the works by Turney (2008) on similarity, antonymy and analogy, and by Pantel and Pernacchiotti (2006) on Espresso, a weakly supervised, pattern-based algorithm.", "startOffset": 38, "endOffset": 539}, {"referenceID": 1, "context": ", 2014; Kruszewski et al., 2015; Roller and Erk, 2016; Santus et al., 2016a; Nguyen et al., 2016; Shwartz et al., 2016). Many of them rely on distributional word vectors, either concatenated or combined through algebraic functions. Others use as features either patterns or scores from the above-mentioned unsupervised methods. While these systems generally obtain high performance in classification tasks involving a single semantic relation, they have rarely been used on multiclass relation classification. On top of it, some scholars have questioned their ability to really learn semantic relations (Levy et al., 2015), claiming that they rather learn some lexical properties from the word vectors they are trained with. This was also confirmed by an experiment carried out by Santus et al. (2016a), showing that up to 100% synthetic switched pairs (i.", "startOffset": 8, "endOffset": 803}, {"referenceID": 0, "context": "Recently, count based vectors have been substituted by prediction-based ones, which seem to slightly improve the performance in some tasks, such as similarity estimation (Baroni et al., 2014), even though Levy et al. (2015) demonstrated that these improvements were most likely due to the optimization of hyperparameters that were instead left unoptimized in count-based models (for an overview on word embeddings, see Gladkova et al.", "startOffset": 171, "endOffset": 224}, {"referenceID": 0, "context": "Recently, count based vectors have been substituted by prediction-based ones, which seem to slightly improve the performance in some tasks, such as similarity estimation (Baroni et al., 2014), even though Levy et al. (2015) demonstrated that these improvements were most likely due to the optimization of hyperparameters that were instead left unoptimized in count-based models (for an overview on word embeddings, see Gladkova et al. (2016)).", "startOffset": 171, "endOffset": 442}, {"referenceID": 0, "context": "Recently, count based vectors have been substituted by prediction-based ones, which seem to slightly improve the performance in some tasks, such as similarity estimation (Baroni et al., 2014), even though Levy et al. (2015) demonstrated that these improvements were most likely due to the optimization of hyperparameters that were instead left unoptimized in count-based models (for an overview on word embeddings, see Gladkova et al. (2016)). On top of it, when combined with supervised methods, the low interpretability of their dimensions makes it even harder to understand what the classifiers actually learn (Levy et al., 2015). Finally, the recent attempt of Shwartz et al. (2016) of combining patterns and distributional information achieved extremely promising results in hypernymy identification.", "startOffset": 171, "endOffset": 687}, {"referenceID": 0, "context": "1 Data Our data come from ukWaC (Baroni et al., 2009), a 2 billion tokens corpus of English built by crawling the .", "startOffset": 32, "endOffset": 53}, {"referenceID": 10, "context": "This measure has been claimed to be particularly useful to spot antonyms (Murphy, 2003), since they are expected to occur in the same sentence more often than chance (e.", "startOffset": 73, "endOffset": 87}, {"referenceID": 20, "context": "Entropy In information theory, this score is related to the informativeness of a message: the lower its entropy, the higher its informativeness (Shannon, 1948).", "startOffset": 144, "endOffset": 159}, {"referenceID": 7, "context": "LinSimilarity LinSimilarity (Lin, 1998) is a different similarity measure, computed as the ratio of shared context between u and v to the contexts of each word:", "startOffset": 28, "endOffset": 39}, {"referenceID": 15, "context": "APAnt APAnt (Santus et al., 2014) is defined as the inverse of APSyn.", "startOffset": 12, "endOffset": 33}, {"referenceID": 16, "context": "0, a resource that was specifically designed for evaluating systems on the identification of semantic relations (Santus et al., 2015).", "startOffset": 112, "endOffset": 133}, {"referenceID": 19, "context": "Since words were not tagged, we performed POS-tagging with the TreeTagger (Schmid, 1995).", "startOffset": 74, "endOffset": 88}, {"referenceID": 15, "context": "Nonetheless, it is still feasible for traditional DSMs to achieve good performances on the recognition of taxonomical relations (Santus et al., 2016a), for which metrics can be defined on the basis of feature inclusion, of context informativeness etc. For other relations, such as antonymy and meronymy, it is not easy to define measures based on distributional similarity (for the latter relation, it is difficult even to find an univocal definition: see Morlane-Hond\u00e8re (2015)): APAnt works relatively well in discriminating antonyms from synonyms, but \u2013 as noticed by Santus et al.", "startOffset": 129, "endOffset": 479}, {"referenceID": 15, "context": "Nonetheless, it is still feasible for traditional DSMs to achieve good performances on the recognition of taxonomical relations (Santus et al., 2016a), for which metrics can be defined on the basis of feature inclusion, of context informativeness etc. For other relations, such as antonymy and meronymy, it is not easy to define measures based on distributional similarity (for the latter relation, it is difficult even to find an univocal definition: see Morlane-Hond\u00e8re (2015)): APAnt works relatively well in discriminating antonyms from synonyms, but \u2013 as noticed by Santus et al. (2015b) \u2013 this measure has also a bias towards hypernyms, which explains why these are often confused.", "startOffset": 129, "endOffset": 593}, {"referenceID": 15, "context": "Nonetheless, it is still feasible for traditional DSMs to achieve good performances on the recognition of taxonomical relations (Santus et al., 2016a), for which metrics can be defined on the basis of feature inclusion, of context informativeness etc. For other relations, such as antonymy and meronymy, it is not easy to define measures based on distributional similarity (for the latter relation, it is difficult even to find an univocal definition: see Morlane-Hond\u00e8re (2015)): APAnt works relatively well in discriminating antonyms from synonyms, but \u2013 as noticed by Santus et al. (2015b) \u2013 this measure has also a bias towards hypernyms, which explains why these are often confused. A possible solution, in our view, would be the integration of DSMs with pattern-based information, in a way that is already being shown by some of the current state-of-the-art systems (see, for example, Shwartz et al. (2016)).", "startOffset": 129, "endOffset": 913}], "year": 2016, "abstractText": "In this paper, we describe ROOT 18, a classifier using the scores of several unsupervised distributional measures as features to discriminate between semantically related and unrelated words, and then to classify the related pairs according to their semantic relation (i.e. synonymy, antonymy, hypernymy, part-whole meronymy). Our classifier participated in the CogALex-V Shared Task, showing a solid performance on the first subtask, but a poor performance on the second subtask. The low scores reported on the second subtask suggest that distributional measures are not sufficient to discriminate between multiple semantic relations at once.", "creator": "LaTeX with hyperref package"}}}