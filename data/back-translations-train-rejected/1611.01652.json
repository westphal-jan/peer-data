{"id": "1611.01652", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Nov-2016", "title": "A Differentiable Physics Engine for Deep Learning in Robotics", "abstract": "One of the most important fields in robotics is the optimization of controllers. Currently, robots are treated as a black box in this optimization process, which is the reason why derivative-free optimization methods such as evolutionary algorithms or reinforcement learning are omnipresent. We propose an implementation of a modern physics engine, which has the ability to differentiate control parameters. This has been implemented on both CPU and GPU. We show how this speeds up the optimization process, even for small problems, and why it will scale to bigger problems. We explain why this is an alternative approach to deep Q-learning, for using deep learning in robotics. Lastly, we argue that this is a big step for deep learning in robotics, as it opens up new possibilities to optimize robots, both in hardware and software.", "histories": [["v1", "Sat, 5 Nov 2016 13:34:58 GMT  (2591kb,D)", "http://arxiv.org/abs/1611.01652v1", "International Conference on Learning Representations 2017"]], "COMMENTS": "International Conference on Learning Representations 2017", "reviews": [], "SUBJECTS": "cs.NE cs.AI cs.RO", "authors": ["jonas degrave", "michiel hermans", "joni dambre", "francis wyffels"], "accepted": false, "id": "1611.01652"}, "pdf": {"name": "1611.01652.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Jonas Degrave", "Michiel Hermans", "Joni Dambre"], "emails": ["Jonas.Degrave@UGent.be", "Joni.Dambre@UGent.be", "Francis.wyffels@UGent.be"], "sections": [{"heading": null, "text": "One of the most important areas in robotics is the optimization of controllers. Currently, robots are treated as a black box in this optimization process, which is why derivative-free optimization methods such as evolutionary algorithms or reinforcement learning are ubiquitous. We propose the implementation of a modern physics engine capable of differentiating control parameters, which has been implemented both on the CPU and on the GPU. We show how this speeds up the optimization process, even with small problems, and why it will grow to larger problems. We explain why this is an alternative approach to deep Q-learning, for the use of deep learning in robotics. Finally, we argue that this is a big step for deep learning in robotics, as it opens up new possibilities to optimize robots in both hardware and software."}, {"heading": "1 INTRODUCTION", "text": "This optimization process can be performed in automated test environments, but typically these controllers are optimized in simulation. Common methods for optimizing these controllers include particle swarms, amplification learning, genetic algorithms, and evolutionary strategies. These are all derivative-free methods. However, deep learning has taught us that optimizing with a gradient is often faster and more efficient. This is especially true when there are a lot of parameters common in deep learning. However, in these optimization processes, the robot is almost exclusively treated as an undifferentiated black box. The reason for this is that the robot is not differentiable in hardware, nor are current physics motors able to provide the gradients of the robot models. The resulting need for derivative-free optimization processes limits both the optimization speed and the number of parameters in the controllers."}, {"heading": "2 A 3D RIGID BODY ENGINE", "text": "The idea is that people in the city they live in will continue to live in the future, and that people in the city they live in will not be able to integrate, \"he said.\" We need to enable them to live and live. \"He added,\" I believe we will be able to change the world. \"He added,\" I don't think we will be able to change the world. \"He added,\" I don't think we will be able to change the world. \"He added,\" I don't think we will be able to change the world. \""}, {"heading": "3 RESULTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 THROWING A BALL", "text": "To test our engine, we have implemented a model of a giant football in the physics engine, as shown in Fig. 1a. The ball has a diameter of 1m, a friction of \u00b5 = 1.0 and restitution e = 0.5. The ball starts at position (0, 0). After 5 s it should be at position (10, 0) with zero velocity v and zero angular velocity \u03c9. We optimized the initial velocity v0 and angular velocity \u03c90 at the beginning of the simulation until the errors at t = 5 s are less than 0.001 and 0.001 m / s, respectively. Since the quantity we optimize is only known at the end of the simulation, but we need to optimize the parameters at the beginning of the simulation, we need to propagate our error at t = 5 s backwards through time (BPTT)."}, {"heading": "3.2 QUADRUPEDAL ROBOT", "text": "In order to verify the speed of our motor, we have also implemented a small four-legged robot model, as shown in Fig. 1b. This model has a total of 81 sensors, e.g. encoders and an inertial measuring unit (IMU).The servomotors are controlled in a closed circuit by a small neural network with a different number of parameters, as shown in Fig. 1c. The gradient is the Jacobian of the total distance travelled by the robot in 10 s, differentiated in relation to all parameters of the controller. This Jacobian is found back by the use of BPTT and the propagation of every 10 sec. The time it takes to calculate this distance travelled and the accompanying Jacobian is shown in Table 1. We include both the computation time with and without the gradient, i.e. both the forward and reverse passing pass and the forward."}, {"heading": "3.3 4 DEGREE OF FREEDOM ROBOT ARM", "text": "As a first test to optimize the robot control, we have implemented a robotic arm with four degrees of freedom as shown in Fig. 1c. The bottom of the robot has a 2 degrees of freedom universal joint, the elbow also has a 2 degrees of freedom operated joint. The arm is 1 m long and has a total mass of 32 kg. The servos have a gain of 30 s \u2212 1, a torque of 30 Nm and a speed of 45 ms \u2212 1. For this robotic arm, we train the controllers for a task with decreasing difficulty. In order to train our parameters, we need to use a few tricks that are often used in the formation of recurring neural networks. \u2022 We select a target that is evaluated at each step and then averaged instead of at specific points in the simulation. This further increases the amount of samples over which the gradient is averaged."}, {"heading": "3.3.1 REACHING A FIXED POINT", "text": "A first simple task is to let a small net neural controller learn to move the controller to a specific fixed point in space, at coordinates (0.5 m; 0.5 m; 0.5 m; 0.5 m).The goal we minimize for this task is the distance between the end effector and the target point averaged over the 8 seconds we simulate our model.We provide the controller with a single sensor input, namely the current distance between the end effector and the target point. Input is not required for this task, as there are solutions for which the motor signals are constant over time. However, this would not necessarily be the optimal approach to minimize the average distance over time, it only solves the distance at the end of the simulation, but does not minimize the distance during the trajectory to get to the final position. As the controller, we use a dense neural network with 1 input, 2 hidden layers of 128 units with a rectifier function, and 4 outputs with an identification function of 28 meters is this activation problem."}, {"heading": "3.3.2 REACHING A RANDOM POINT", "text": "As a second task, we capture a random target point in space, within the cuboid between (1m; 1m; 1m) and (\u2212 1m; \u2212 1m; 0m), parallel to the axes. We give this point to the controller as input, and the task is to minimize the average distance between the end effector and the target point again. As controllers, we use the same dense neural network as in the previous section, but this time with 3 inputs. This controller has a total of 17,540 parameters. To train for this task, we use a stack size of 64 robots, so that each update step takes 52 s on the GPU. Each simulation takes 8 s with a simulation step of 0.01 s, so the gradient on the controller parameters averages over 51,200 timesteps at each update step. We find that it takes 5,000 update steps before the 17,540 parameters are optimized, so that the robot has an average accuracy of 10 cm, on average, within about half of the space achievable."}, {"heading": "3.4 OPTIMIZING A CONTROLLER FOR THE QUADRUPEDAL ROBOT \u2013 REVISITED", "text": "Optimizing a gait for a four-legged robot is a problem of a different order, something the authors have extensive experience with (Sproewitz et al., 2013; Degrave et al., 2013; 2015). The problem is much more difficult, and allows a wide range of possible solutions. In nature, we find a wide range of gaits, from hopping to trotting, walking and galloping. With the hand setting, we were able to get a trotting look at this robot model, with an average forward speed of 0.7 m / s. We found it difficult to find a gait in which the robot does not end up as a headless turtle, as 75% of the mass of the robot in its spine.As controller for our four-legged robot, we use a neural network with 2 input signals, namely a Sine and a cosine signal with a frequency of 1.5 Hz."}, {"heading": "4 DISCUSSION", "text": "Our results show the first prototype of a differentiated physics engine based on algorithms similar to those commonly used in current robotics simulators. When we originally tackled the problem, we had no idea whether it would be mathematically feasible to find the gradient, let alone whether its evaluation would be fast enough to be advantageous for optimization. We have now shown that the evaluation of the gradient is expensive, but at a very manageable level. The speed of evaluation of the gradient mainly depends on the complexity of the physical model and only marginally on the number of parameters to be optimized. Our results therefore suggest that these costs can be dominated by the gain that can be achieved by combining the use of stack gradients and GPU acceleration, especially when the optimization of controllers with a very high number of parameters, which we suspect this approach is symptomatic of any number of gradients in proportion to the order."}, {"heading": "5 FUTURE WORK", "text": "Any results in this paper will, of course, largely depend on how these controllers work on the physical counterparts of our models. Nevertheless, we would like to suspect that this gradient of a model is close to the gradient of the physical system. However, the gradient of the model is even more susceptible to radio frequency noise introduced by modeling the system than the imaginary gradient of the system itself. Nevertheless, it contains information that could be indicative, even if it is not perfect. We would theorize that the use of this low-noise gradient is still better than optimization in blindness, and that the transferability to real robots can be improved by evaluating the gradients on stacks of (slightly) different robots, a technique already used in (Hermans et al., 2014) as a regulation technique that avoids bifurcations during online learning."}, {"heading": "6 CONCLUSION", "text": "In this work, we show that it is possible to build a differentiated physics engine. We have implemented a modern engine that can execute a rigid 3D body model, using the same algorithm as other motors commonly used to simulate robots, but we can additionally differentiate control parameters with BPTT. Our implementation also runs on GPU and we show that using GPUs to simulate physics can speed up the process for large batches of robots. We find that these gradients can be calculated surprisingly quickly. We also show that the use of gradient departures with BPTT accelerates optimization processes that are common in robotics, even with relatively small problems due to the reduced number of model evaluations required. This speed improvement will scale to problems with many parameters, so this method should provide a new way to apply deep learning methods in robotics."}, {"heading": "ACKNOWLEDGMENTS", "text": "A special thanks goes to Iryna Korshunova for valuable discussions and proofreading of the paper. Research that led to these results was funded by the Agency for Innovation by Science and Technology in Flanders (IWT) and the GTX 1080 used for this research was donated by NVIDIA Corporation."}], "references": [{"title": "Theano: A python framework for fast computation of mathematical expressions. arXiv preprint arXiv:1605.02688", "author": ["R. Al-Rfou", "G. Alain", "A. Almahairi", "C. Angermueller", "D. Bahdanau", "N. Ballas", "F. Bastien", "J. Bayer", "A Belikov"], "venue": null, "citeRegEx": "Al.Rfou et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Al.Rfou et al\\.", "year": 2016}, {"title": "Modeling and solving constraints", "author": ["E. Catto"], "venue": "In Game Developers Conference", "citeRegEx": "Catto,? \\Q2009\\E", "shortCiteRegEx": "Catto", "year": 2009}, {"title": "Constraints derivation for rigid body simulation in 3D", "author": ["D. Chappuis"], "venue": null, "citeRegEx": "Chappuis,? \\Q2013\\E", "shortCiteRegEx": "Chappuis", "year": 2013}, {"title": "Transfer learning of gaits on a quadrupedal robot", "author": ["J. Degrave", "M. Burm", "Kindermans", "P.-J", "J Dambre"], "venue": "Adaptive Behavior,", "citeRegEx": "Degrave et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Degrave et al\\.", "year": 2015}, {"title": "Comparing trotting and turning strategies on the quadrupedal oncilla robot", "author": ["J. Degrave", "M. Burm", "T. Waegeman", "F. Wyffels", "B. Schrauwen"], "venue": "In Robotics and Biomimetics (ROBIO),", "citeRegEx": "Degrave et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Degrave et al\\.", "year": 2013}, {"title": "Spatial chirp-Z transformer networks", "author": ["J. Degrave", "S. Dieleman", "J Dambre"], "venue": "In European Symposium on Artificial Neural Networks (ESANN)", "citeRegEx": "Degrave et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Degrave et al\\.", "year": 2016}, {"title": "Simulation tools for model-based robotics: Comparison of bullet, havok, mujoco, ode and physx", "author": ["T. Erez", "Y. Tassa", "E. Todorov"], "venue": "In International Conference on Robotics and Automation (ICRA),", "citeRegEx": "Erez et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Erez et al\\.", "year": 2015}, {"title": "Generative adversarial nets", "author": ["I. Goodfellow", "J. Pouget-Abadie", "M. Mirza", "B. Xu", "D. Warde-Farley", "S. Ozair", "A. Courville", "Y. Bengio"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Goodfellow et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2014}, {"title": "The cma evolution strategy: a comparing review", "author": ["N. Hansen"], "venue": null, "citeRegEx": "Hansen,? \\Q2006\\E", "shortCiteRegEx": "Hansen", "year": 2006}, {"title": "Automated design of complex dynamic systems", "author": ["M. Hermans", "B. Schrauwen", "P. Bienstman", "J. Dambre"], "venue": "PloS one,", "citeRegEx": "Hermans et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hermans et al\\.", "year": 2014}, {"title": "Long short-term memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural computation,", "citeRegEx": "Hochreiter and Schmidhuber,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter and Schmidhuber", "year": 1997}, {"title": "Approximating polyhedra with spheres for time-critical collision detection", "author": ["P.M. Hubbard"], "venue": "ACM Transactions on Graphics (TOG),", "citeRegEx": "Hubbard,? \\Q1996\\E", "shortCiteRegEx": "Hubbard", "year": 1996}, {"title": "An aerodynamic optimization method based on the inverse problem adjoint equations", "author": ["A. Iollo", "M. Ferlauto", "L. Zannetti"], "venue": "Journal of Computational Physics,", "citeRegEx": "Iollo et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Iollo et al\\.", "year": 2001}, {"title": "A general optimization method using adjoint equation for solving multidimensional inverse heat conduction", "author": ["Y. Jarny", "M. Ozisik", "J. Bardon"], "venue": "International journal of heat and mass transfer,", "citeRegEx": "Jarny et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Jarny et al\\.", "year": 1991}, {"title": "A gauss-seidel like algorithm to solve frictional contact problems. Computer methods in applied mechanics and engineering, 155(1):31\u201347", "author": ["F. Jourdan", "P. Alart", "M. Jean"], "venue": null, "citeRegEx": "Jourdan et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Jourdan et al\\.", "year": 1998}, {"title": "Adam: A method for stochastic optimization", "author": ["D.P. Kingma", "J. Ba"], "venue": "Proceedings of the 3rd International Conference on Learning Representations (ICLR)", "citeRegEx": "Kingma and Ba,? \\Q2014\\E", "shortCiteRegEx": "Kingma and Ba", "year": 2014}, {"title": "Learning hand-eye coordination for robotic grasping with deep learning and large-scale data collection", "author": ["S. Levine", "P. Pastor", "A. Krizhevsky", "D. Quillen"], "venue": "arXiv preprint arXiv:1603.02199", "citeRegEx": "Levine et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Levine et al\\.", "year": 2016}, {"title": "V-clip: Fast and robust polyhedral collision detection", "author": ["B. Mirtich"], "venue": "ACM Transactions On Graphics (TOG),", "citeRegEx": "Mirtich,? \\Q1998\\E", "shortCiteRegEx": "Mirtich", "year": 1998}, {"title": "Direction cosine matrix IMU: Theory", "author": ["W. Premerlani", "P. Bizard"], "venue": "DIY DRONE: USA,", "citeRegEx": "Premerlani and Bizard,? \\Q2009\\E", "shortCiteRegEx": "Premerlani and Bizard", "year": 2009}, {"title": "Nonlinear black-box modeling in system identification: a unified overview", "author": ["J. Sj\u00f6berg", "Q. Zhang", "L. Ljung", "A. Benveniste", "B. Delyon", "Glorennec", "P.-Y", "H. Hjalmarsson", "A. Juditsky"], "venue": null, "citeRegEx": "Sj\u00f6berg et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Sj\u00f6berg et al\\.", "year": 1995}, {"title": "Towards dynamically running quadruped robots: performance, scaling, and comparison", "author": ["A. Sproewitz", "A. Tuleu", "M. D\u2019Haene", "R. M\u00f6ckel", "J. Degrave", "M. Vespignani", "S. Gay", "M. Ajallooeian", "B. Schrauwen", "A.J. Ijspeert"], "venue": "In Adaptive Motion of Animals and Machines,", "citeRegEx": "Sproewitz et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Sproewitz et al\\.", "year": 2013}, {"title": "An implicit time-stepping scheme for rigid body dynamics with coulomb friction", "author": ["D. Stewart", "J.C. Trinkle"], "venue": "In International Conference on Robotics and Automation (ICRA),", "citeRegEx": "Stewart and Trinkle,? \\Q2000\\E", "shortCiteRegEx": "Stewart and Trinkle", "year": 2000}, {"title": "Training recurrent neural networks", "author": ["I. Sutskever"], "venue": "PhD thesis,", "citeRegEx": "Sutskever,? \\Q2013\\E", "shortCiteRegEx": "Sutskever", "year": 2013}], "referenceMentions": [{"referenceID": 16, "context": "This method requires a lot of evaluations in order to work and to learn the many parameters (Levine et al., 2016).", "startOffset": 92, "endOffset": 113}, {"referenceID": 9, "context": "It has been done before with spring-damper models in 2D and 3D (Hermans et al., 2014).", "startOffset": 63, "endOffset": 85}, {"referenceID": 13, "context": "This approach is also similar to adjoint optimisation, a method widely used in various applications such as thermodynamics (Jarny et al., 1991) and fluid dynamics (Iollo et al.", "startOffset": 123, "endOffset": 143}, {"referenceID": 12, "context": ", 1991) and fluid dynamics (Iollo et al., 2001).", "startOffset": 27, "endOffset": 47}, {"referenceID": 6, "context": "The most commonly used ones are 3D rigid body engines, which rely on impulse-based velocity stepping methods (Erez et al., 2015).", "startOffset": 109, "endOffset": 128}, {"referenceID": 6, "context": "The most frequently used simulation tools for model-based robotics, such as PhysX, Bullet, Havok and ODE, go back to MathEngine (Erez et al., 2015).", "startOffset": 128, "endOffset": 147}, {"referenceID": 2, "context": "The velocities, positions and constraints of the rigid bodies define a linear complementarity problem (LCP) (Chappuis, 2013), which is then solved using a Gauss-Seidel projection (GSP) method (Jourdan et al.", "startOffset": 108, "endOffset": 124}, {"referenceID": 14, "context": "The velocities, positions and constraints of the rigid bodies define a linear complementarity problem (LCP) (Chappuis, 2013), which is then solved using a Gauss-Seidel projection (GSP) method (Jourdan et al., 1998).", "startOffset": 192, "endOffset": 214}, {"referenceID": 21, "context": "The solution of this problem are the new velocities of the bodies, which are then integrated by semi-implicit Euler integration to get the new positions (Stewart and Trinkle, 2000).", "startOffset": 153, "endOffset": 180}, {"referenceID": 1, "context": "This system is not always numerically stable, therefore the constraints are usually softened (Catto, 2009).", "startOffset": 93, "endOffset": 106}, {"referenceID": 0, "context": "We implemented such an engine as a mathematical expression in Theano (Al-Rfou et al., 2016), a software library which does automatic evaluation and differentiation of expressions with a focus on deep learning.", "startOffset": 69, "endOffset": 91}, {"referenceID": 5, "context": "This library has allowed for efficient differentiation of remarkably complex functions before (Degrave et al., 2016).", "startOffset": 94, "endOffset": 116}, {"referenceID": 17, "context": "Collision detection algorithms for cubes typically have a lot of branching (Mirtich, 1998).", "startOffset": 75, "endOffset": 90}, {"referenceID": 11, "context": "However, this sphere based approach can in principle be extended to any other shape (Hubbard, 1996).", "startOffset": 84, "endOffset": 99}, {"referenceID": 18, "context": "To correct for this, we renormalize our matrix with the update equation (Premerlani and Bizard, 2009):", "startOffset": 72, "endOffset": 101}, {"referenceID": 22, "context": "(BPTT) (Sutskever, 2013).", "startOffset": 7, "endOffset": 24}, {"referenceID": 8, "context": "Optimizing this problem with CMA-ES (Hansen, 2006), a state of the art derivative-free optimization method, took 2422 iterations.", "startOffset": 36, "endOffset": 50}, {"referenceID": 19, "context": "This vastly increases the amount of samples over which the gradient is averaged, which in turn makes the gradient direction more reliable (Sj\u00f6berg et al., 1995).", "startOffset": 138, "endOffset": 160}, {"referenceID": 9, "context": "This also improves robustness against exploding gradients (Hermans et al., 2014).", "startOffset": 58, "endOffset": 80}, {"referenceID": 22, "context": "This makes sure that gradients close to discontinuities in the fitness landscape do not push the parameter values too far away, such that everything which was learnt is forgotten (Sutskever, 2013).", "startOffset": 179, "endOffset": 196}, {"referenceID": 15, "context": "The parameters are optimized with Adam\u2019s rule (Kingma and Ba, 2014) with a learning rate of 0.", "startOffset": 46, "endOffset": 67}, {"referenceID": 19, "context": "Solving problems like these, in less iteration steps than the number of parameters, is completely unfeasible with derivative free methods (Sj\u00f6berg et al., 1995).", "startOffset": 138, "endOffset": 160}, {"referenceID": 20, "context": "Optimizing a gait for a quadrupedal robot is a problem of a different order, something the authors have extensive experience with (Sproewitz et al., 2013; Degrave et al., 2013; 2015).", "startOffset": 130, "endOffset": 182}, {"referenceID": 4, "context": "Optimizing a gait for a quadrupedal robot is a problem of a different order, something the authors have extensive experience with (Sproewitz et al., 2013; Degrave et al., 2013; 2015).", "startOffset": 130, "endOffset": 182}, {"referenceID": 9, "context": "Earlier research shows that these methods can be extended to even more difficult tasks than the ones discussed here (Hermans et al., 2014; Sutskever, 2013).", "startOffset": 116, "endOffset": 155}, {"referenceID": 22, "context": "Earlier research shows that these methods can be extended to even more difficult tasks than the ones discussed here (Hermans et al., 2014; Sutskever, 2013).", "startOffset": 116, "endOffset": 155}, {"referenceID": 9, "context": "This technique was already applied in (Hermans et al., 2014) as a regularization technique to avoid bifurcations during online learning.", "startOffset": 38, "endOffset": 60}, {"referenceID": 10, "context": "with a memory made out of LSTM cells (Hochreiter and Schmidhuber, 1997) can allow for more powerful controllers than the controllers described in this paper.", "startOffset": 37, "endOffset": 71}, {"referenceID": 13, "context": "Hardware parameters of the robot have been optimized the same way before (Jarny et al., 1991; Iollo et al., 2001; Hermans et al., 2014).", "startOffset": 73, "endOffset": 135}, {"referenceID": 12, "context": "Hardware parameters of the robot have been optimized the same way before (Jarny et al., 1991; Iollo et al., 2001; Hermans et al., 2014).", "startOffset": 73, "endOffset": 135}, {"referenceID": 9, "context": "Hardware parameters of the robot have been optimized the same way before (Jarny et al., 1991; Iollo et al., 2001; Hermans et al., 2014).", "startOffset": 73, "endOffset": 135}, {"referenceID": 7, "context": "Like in generative adversarial nets (GAN) (Goodfellow et al., 2014), where the gradient is pulled through two competing neural networks, the gradient could be pulled through multiple competing robots as well.", "startOffset": 42, "endOffset": 67}], "year": 2016, "abstractText": "One of the most important fields in robotics is the optimization of controllers. Currently, robots are treated as a black box in this optimization process, which is the reason why derivative-free optimization methods such as evolutionary algorithms or reinforcement learning are omnipresent. We propose an implementation of a modern physics engine, which has the ability to differentiate control parameters. This has been implemented on both CPU and GPU. We show how this speeds up the optimization process, even for small problems, and why it will scale to bigger problems. We explain why this is an alternative approach to deep Q-learning, for using deep learning in robotics. Lastly, we argue that this is a big step for deep learning in robotics, as it opens up new possibilities to optimize robots, both in hardware and software.", "creator": "LaTeX with hyperref package"}}}