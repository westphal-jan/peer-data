{"id": "1611.01726", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Nov-2016", "title": "LSTM-Based System-Call Language Modeling and Robust Ensemble Method for Designing Host-Based Intrusion Detection Systems", "abstract": "In computer security, designing a robust intrusion detection system is one of the most fundamental and important problems. In this paper, we propose a system-call language-modeling approach for designing anomaly-based host intrusion detection systems. To remedy the issue of high false-alarm rates commonly arising in conventional methods, we employ a novel ensemble method that blends multiple thresholding classifiers into a single one, making it possible to accumulate 'highly normal' sequences. The proposed system-call language model has various advantages leveraged by the fact that it can learn the semantic meaning and interactions of each system call that existing methods cannot effectively consider. Through diverse experiments on public benchmark datasets, we demonstrate the validity and effectiveness of the proposed method. Moreover, we show that our model possesses high portability, which is one of the key aspects of realizing successful intrusion detection systems.", "histories": [["v1", "Sun, 6 Nov 2016 04:07:29 GMT  (972kb,D)", "http://arxiv.org/abs/1611.01726v1", "12 pages, 5 figures"]], "COMMENTS": "12 pages, 5 figures", "reviews": [], "SUBJECTS": "cs.CR cs.LG", "authors": ["gyuwan kim", "hayoon yi", "jangho lee", "yunheung paek", "sungroh yoon"], "accepted": false, "id": "1611.01726"}, "pdf": {"name": "1611.01726.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Gyuwan Kim", "Hayoon Yi", "Jangho Lee", "Yunheung Paek", "Sungroh Yoon"], "emails": ["kgwmath@snu.ac.kr", "hyyi@snu.ac.kr", "ubuntu@snu.ac.kr", "ypaek@snu.ac.kr", "sryoon@snu.ac.kr"], "sections": [{"heading": null, "text": "In this paper, we propose an approach to modelling intruder detection system calls based on anomalies. To address the problem of high false alarms commonly encountered by conventional methods, we use a novel ensemble method that combines several threshold classifiers into a single one, making it possible to accumulate \"highly normal\" sequences. The proposed system call language model has several advantages that are exploited by the fact that it can learn the semantic meaning and interactions of each system call that existing methods cannot effectively take into account. Through various experiments with public benchmark data sets, we demonstrate the validity and effectiveness of the proposed method. Furthermore, we demonstrate that our model has high portability, which is one of the key aspects for realizing successful intrusion detection systems."}, {"heading": "1 INTRODUCTION", "text": "It is indeed the case that we are able to change the world, and that we are able to change the world."}, {"heading": "2 PROPOSED METHOD", "text": "Figure 1 shows the overview of our proposed approach to developing an intrusion detection system. Our method consists of two parts: the front-end is used for voice modelling of system calls in various settings and the back-end of anomaly prediction based on an ensemble of threshold classifiers derived from the front-end. In this section we describe details of each component in our pipeline."}, {"heading": "2.1 LANGUAGE MODELING OF SYSTEM CALLS", "text": "In fact, most of them are able to go in search of a solution that puts them in the position in which they find themselves."}, {"heading": "2.2 ENSEMBLE METHOD TO MINIMIZE FALSE ALARM RATES", "text": "Building a \"strong normal\" system is more difficult than creating synthetic system call data. Generating normal data in a realistic situation is a challenge due to over-adaptation. In other words, a lower loss of education does not necessarily imply better generalization performance. We can consider two reasons for the occurrence of this problem: First, it is possible that only normal data was used to train IDS without using any attack data. Especially malicious behaviors are often hidden and are used for only a small part of all system call sequences. Second, in theory, we need an enormous amount of data to capture all possible normal patterns in order to train the model satisfactorily. However, this is often impossible in a realistic situation because the multiple and dynamic system call patterns are visible."}, {"heading": "2.3 BASELINE CLASSIFIERS", "text": "For comparison with our main classifier, we use two basic classifiers that are commonly used to detect anomalies and use vectors that match each sequence: k-nearest neighbor (kNN) and k-middle clustering (kMC). Examples of previous work on mapping sequences in vectors of fixed-dimensional handmade characteristics include normalized frequencies and tf-idf (Liao & Vemuri, 2002; Xie et al., 2014). Let T be a normal sequence, and let lstm (x) learn a call sequence representation x from the LSTM stratum. kNN classifiers search for k nearest neighbors in T of the query sequence x."}, {"heading": "3 EXPERIMENTAL RESULTS AND DISCUSSION", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 DATASETS", "text": "To help researchers in this regard, the following datasets from previous work have been made publicly available: ADFA-LD (Creech & Hu, 2013), KDD98 (Lippmann et al., 2000) and UNM (of New Mexico, 2012) The KDD98 and UNM datasets were published in 1998 and 2004, respectively. Although these two received continued criticism for their applicability to modern systems (Brown et al., 2009; McHugh, 2000; Tan & Maxion, 2003), we include them because the results would show how our model farms compare to early field work, which was largely evaluated on these datasets."}, {"heading": "3.2 PERFORMANCE EVALUATION", "text": "In fact, it is the case that most of them are able to move into another world, in which they are able to move, in which they are able to move, in which they move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they, in which they live, in which they live, in which they are able to move, in which they are able to move, in which they are able to move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they, in which they are able to live, in which they, in which they, in which they, in which they are able to"}, {"heading": "3.3 PORTABILITY EVALUATION", "text": "We conducted experiments similar to those in Section 3.2, using the KDD98 dataset and the UNM dataset. First, we trained our system call language model with LSTM, which had a layer of 200 cells, and built our classifier using the normal training tracks of the KDD98 dataset. The same model was used to evaluate the UNM dataset, to examine the portability of the LSTM models trained with data from another, but similar system. The results of our experiments are presented in Figure 4. For comparison, we show the ROC curve of the UNM dataset, using the model from the training of the normal tracks contained therein. To examine portability, the system calls up test records that need to be matched or synchronized with those of training datasets. UNM was created using an earlier version of the operating system than that of KDD98, but ADFA-LFA was fairly audited on another operating system."}, {"heading": "3.4 VISUALIZATION OF LEARNED REPRESENTATIONS", "text": "It is well known that neural network-based speech models can learn semantically meaningful embedding in continuous space (Bengio et al., 2003; Mikolov et al., 2013; Cho et al., 2014). We expected a similar characteristic with the proposed system call speech model. Just like the natural language model, we can expect calls with similar coexistence patterns to be positioned in similar locations in embedded space after training the system call speech model. We can clearly see that calls with the same functionality are clustered with each other. Just like the natural language model, we can expect calls with similar coexistence patterns to be positioned in similar locations in embedded space."}, {"heading": "4 CONCLUSION", "text": "Our main contributions to the development of intruder detection systems, as described in this paper, consist of two parts: the introduction of an approach to modeling system calls and a new ensemble method. To the best of our knowledge, our method is the first to introduce the concept of a language model, especially using LSTM, into anomaly-based IDS. The language model of the system call can capture the semantic meaning of each call and its relationship to other system calls. In addition, we proposed an innovative and simple ensemble method that can better fit the IDS design by focusing on reducing false alarm rates. We demonstrated its outstanding performance by comparing it with existing state-of-the-art methods and demonstrated its robustness and universality by experimenting on different benchmarks. As already discussed, the proposed method also has excellent portability. Unlike alternative methods, our proposed method requires significant smaller overall capture walls, because it does not require a volume of intrusion or exposable pattern."}, {"heading": "ACKNOWLEDGMENTS", "text": "This work was supported by the BK21 Plus Project (Electrical and Computer Engineering, Seoul National University) in 2016."}], "references": [{"title": "Neural machine translation by jointly learning to align and translate", "author": ["Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio"], "venue": "arXiv preprint arXiv:1409.0473,", "citeRegEx": "Bahdanau et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2014}, {"title": "Learning long-term dependencies with gradient descent is difficult", "author": ["Yoshua Bengio", "Patrice Simard", "Paolo Frasconi"], "venue": "Neural Networks, IEEE Transactions on,", "citeRegEx": "Bengio et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 1994}, {"title": "A neural probabilistic language model", "author": ["Yoshua Bengio", "R\u00e9jean Ducharme", "Pascal Vincent", "Christian Jauvin"], "venue": "In Journal of Machine Learning Research,", "citeRegEx": "Bengio et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 2003}, {"title": "The use of the area under the roc curve in the evaluation of machine learning algorithms", "author": ["Andrew P Bradley"], "venue": "Pattern recognition,", "citeRegEx": "Bradley.,? \\Q1997\\E", "shortCiteRegEx": "Bradley.", "year": 1997}, {"title": "Analysis of the 1999 darpa/lincoln laboratory ids evaluation data with netadhict", "author": ["Carson Brown", "Alex Cowperthwaite", "Abdulrahman Hijazi", "Anil Somayaji"], "venue": "In Computational Intelligence for Security and Defense Applications,", "citeRegEx": "Brown et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Brown et al\\.", "year": 2009}, {"title": "Learning phrase representations using rnn encoder-decoder for statistical machine translation", "author": ["Kyunghyun Cho", "Bart Van Merri\u00ebnboer", "Caglar Gulcehre", "Dzmitry Bahdanau", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio"], "venue": "arXiv preprint arXiv:1406.1078,", "citeRegEx": "Cho et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Cho et al\\.", "year": 2014}, {"title": "Generation of a new ids test dataset: Time to retire the kdd collection", "author": ["Gideon Creech", "Jiankun Hu"], "venue": "In Wireless Communications and Networking Conference (WCNC),", "citeRegEx": "Creech and Hu.,? \\Q2013\\E", "shortCiteRegEx": "Creech and Hu.", "year": 2013}, {"title": "A semantic approach to host-based intrusion detection systems using contiguousand discontiguous system call patterns", "author": ["Gideon Creech", "Jiankun Hu"], "venue": "Computers, IEEE Transactions on,", "citeRegEx": "Creech and Hu.,? \\Q2014\\E", "shortCiteRegEx": "Creech and Hu.", "year": 2014}, {"title": "A sense of self for unix processes", "author": ["Stephanie Forrest", "Steven A Hofmeyr", "Aniln Somayaji", "Thomas A Longstaff"], "venue": "In Security and Privacy,", "citeRegEx": "Forrest et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Forrest et al\\.", "year": 1996}, {"title": "The evolution of system-call monitoring", "author": ["Stephanie Forrest", "Steven Hofmeyr", "Anil Somayaji"], "venue": "In Computer Security Applications Conference,", "citeRegEx": "Forrest et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Forrest et al\\.", "year": 2008}, {"title": "Speech recognition with deep recurrent neural networks", "author": ["Alan Graves", "Abdel-rahman Mohamed", "Geoffrey Hinton"], "venue": "In Acoustics, Speech and Signal Processing (ICASSP),", "citeRegEx": "Graves et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Graves et al\\.", "year": 2013}, {"title": "Teaching machines to read and comprehend", "author": ["Karl Moritz Hermann", "Tomas Kocisky", "Edward Grefenstette", "Lasse Espeholt", "Will Kay", "Mustafa Suleyman", "Phil Blunsom"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Hermann et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Hermann et al\\.", "year": 2015}, {"title": "A multi-layer model for anomaly intrusion detection using program sequences of system calls", "author": ["Xuan Dau Hoang", "Jiankun Hu", "Peter Bertok"], "venue": "In Proc. 11th IEEE Intl. Conf. Citeseer,", "citeRegEx": "Hoang et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Hoang et al\\.", "year": 2003}, {"title": "Long short-term memory", "author": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber"], "venue": "Neural computation,", "citeRegEx": "Hochreiter and Schmidhuber.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter and Schmidhuber.", "year": 1997}, {"title": "Intrusion detection using sequences of system calls", "author": ["Steven A Hofmeyr", "Stephanie Forrest", "Anil Somayaji"], "venue": "Journal of computer security,", "citeRegEx": "Hofmeyr et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Hofmeyr et al\\.", "year": 1998}, {"title": "A simple and efficient hidden markov model scheme for host-based anomaly intrusion detection", "author": ["Jiankun Hu", "Xinghuo Yu", "Dong Qiu", "Hsiao-Hwa Chen"], "venue": "Network, IEEE,", "citeRegEx": "Hu et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Hu et al\\.", "year": 2009}, {"title": "Exploring the limits of language modeling", "author": ["Rafal Jozefowicz", "Oriol Vinyals", "Mike Schuster", "Noam Shazeer", "Yonghui Wu"], "venue": "arXiv preprint arXiv:1602.02410,", "citeRegEx": "Jozefowicz et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Jozefowicz et al\\.", "year": 2016}, {"title": "A review of anomaly based intrusion detection systems", "author": ["V Jyothsna", "VV Rama Prasad", "K Munivara Prasad"], "venue": "International Journal of Computer Applications,", "citeRegEx": "Jyothsna et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Jyothsna et al\\.", "year": 2011}, {"title": "Adam: A method for stochastic optimization", "author": ["Diederik Kingma", "Jimmy Ba"], "venue": "arXiv preprint arXiv:1412.6980,", "citeRegEx": "Kingma and Ba.,? \\Q2014\\E", "shortCiteRegEx": "Kingma and Ba.", "year": 2014}, {"title": "Using text categorization techniques for intrusion detection", "author": ["Yihua Liao", "V Rao Vemuri"], "venue": "In USENIX Security Symposium,", "citeRegEx": "Liao and Vemuri.,? \\Q2002\\E", "shortCiteRegEx": "Liao and Vemuri.", "year": 2002}, {"title": "Evaluating intrusion detection systems: The 1998 darpa off-line intrusion detection evaluation", "author": ["Richard P Lippmann", "David J Fried", "Isaac Graf", "Joshua W Haines", "Kristopher R Kendall", "David McClung", "Dan Weber", "Seth E Webster", "Dan Wyschogrod", "Robert K Cunningham"], "venue": "In DARPA Information Survivability Conference and Exposition,", "citeRegEx": "Lippmann et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Lippmann et al\\.", "year": 2000}, {"title": "Rectifier nonlinearities improve neural network acoustic models", "author": ["Andrew L Maas", "Awni Y Hannun", "Andrew Y Ng"], "venue": "In Proc. ICML,", "citeRegEx": "Maas et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Maas et al\\.", "year": 2013}, {"title": "Testing intrusion detection systems: a critique of the 1998 and 1999 darpa intrusion detection system evaluations as performed by lincoln laboratory", "author": ["John McHugh"], "venue": "ACM transactions on Information and system Security,", "citeRegEx": "McHugh.,? \\Q2000\\E", "shortCiteRegEx": "McHugh.", "year": 2000}, {"title": "Linguistic regularities in continuous space word representations", "author": ["Tomas Mikolov", "Wen-tau Yih", "Geoffrey Zweig"], "venue": "In NAACL-HLT, pp", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "On the difficulty of training recurrent neural networks", "author": ["Razvan Pascanu", "Tomas Mikolov", "Yoshua Bengio"], "venue": "In Proceedings of The 30th International Conference on Machine Learning,", "citeRegEx": "Pascanu et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Pascanu et al\\.", "year": 2013}, {"title": "A neural attention model for abstractive sentence summarization", "author": ["Alexander M Rush", "Sumit Chopra", "Jason Weston"], "venue": "arXiv preprint arXiv:1509.00685,", "citeRegEx": "Rush et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Rush et al\\.", "year": 2015}, {"title": "Dropout: A simple way to prevent neural networks from overfitting", "author": ["Nitish Srivastava", "Geoffrey Hinton", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan Salakhutdinov"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Srivastava et al\\.,? \\Q1929\\E", "shortCiteRegEx": "Srivastava et al\\.", "year": 1929}, {"title": "Evaluating performance of long short-term memory recurrent neural networks on intrusion detection data", "author": ["Ralf C Staudemeyer", "Christian W Omlin"], "venue": "In Proceedings of the South African Institute for Computer Scientists and Information Technologists Conference,", "citeRegEx": "Staudemeyer and Omlin.,? \\Q2013\\E", "shortCiteRegEx": "Staudemeyer and Omlin.", "year": 2013}, {"title": "Determining the operational limits of an anomaly-based intrusion detector", "author": ["Kymie Tan", "Roy A Maxion"], "venue": "Selected Areas in Communications, IEEE Journal on,", "citeRegEx": "Tan and Maxion.,? \\Q2003\\E", "shortCiteRegEx": "Tan and Maxion.", "year": 2003}, {"title": "Visualizing data using t-sne", "author": ["Laurens Van der Maaten", "Geoffrey Hinton"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Maaten and Hinton.,? \\Q2008\\E", "shortCiteRegEx": "Maaten and Hinton.", "year": 2008}, {"title": "Detecting intrusions using system calls: Alternative data models", "author": ["Christina Warrender", "Stephanie Forrest", "Barak Pearlmutter"], "venue": "In Security and Privacy,", "citeRegEx": "Warrender et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Warrender et al\\.", "year": 1999}, {"title": "Evaluating host-based anomaly detection systems: Application of the frequency-based algorithms to adfa-ld", "author": ["Miao Xie", "Jiankun Hu", "Xinghuo Yu", "Elizabeth Chang"], "venue": "In Network and System Security,", "citeRegEx": "Xie et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Xie et al\\.", "year": 2014}, {"title": "System call anomaly detection using multihmms", "author": ["Esra N Yolacan", "Jennifer G Dy", "David R Kaeli"], "venue": "In Software Security and Reliability-Companion (SERE-C),", "citeRegEx": "Yolacan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Yolacan et al\\.", "year": 2014}, {"title": "Recurrent neural network regularization", "author": ["Wojciech Zaremba", "Ilya Sutskever", "Oriol Vinyals"], "venue": "arXiv preprint arXiv:1409.2329,", "citeRegEx": "Zaremba et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zaremba et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 17, "context": "From a methodological point of view, intrusion detection systems can also be classified into two classes (Jyothsna et al., 2011): signature-based and anomaly-based.", "startOffset": 105, "endOffset": 128}, {"referenceID": 9, "context": "(1996) who first started to use system-call traces as the raw data for host-based anomaly intrusion detection systems, and system-call traces have been widely used for IDS research and development since their seminal work (Forrest et al., 2008).", "startOffset": 222, "endOffset": 244}, {"referenceID": 5, "context": "In natural language processing (NLP), a language model represents a probability distribution over sequences of words, and language modeling has been a very important component of many NLP applications, including machine translation (Cho et al., 2014; Bahdanau et al., 2014), speech recognition (Graves et al.", "startOffset": 232, "endOffset": 273}, {"referenceID": 0, "context": "In natural language processing (NLP), a language model represents a probability distribution over sequences of words, and language modeling has been a very important component of many NLP applications, including machine translation (Cho et al., 2014; Bahdanau et al., 2014), speech recognition (Graves et al.", "startOffset": 232, "endOffset": 273}, {"referenceID": 10, "context": ", 2014), speech recognition (Graves et al., 2013), question answering (Hermann et al.", "startOffset": 28, "endOffset": 49}, {"referenceID": 11, "context": ", 2013), question answering (Hermann et al., 2015), and summarization (Rush et al.", "startOffset": 28, "endOffset": 50}, {"referenceID": 25, "context": ", 2015), and summarization (Rush et al., 2015).", "startOffset": 27, "endOffset": 46}, {"referenceID": 33, "context": "Recently, deep recurrent neural network (RNN)-based language models are showing remarkable performance in various tasks (Zaremba et al., 2014; Jozefowicz et al., 2016).", "startOffset": 120, "endOffset": 167}, {"referenceID": 16, "context": "Recently, deep recurrent neural network (RNN)-based language models are showing remarkable performance in various tasks (Zaremba et al., 2014; Jozefowicz et al., 2016).", "startOffset": 120, "endOffset": 167}, {"referenceID": 21, "context": "1 Second, to reduce false-alarm rates of anomaly-based intrusion detection, we propose a leaky rectified linear units (ReLU) (Maas et al., 2013) based ensemble method that constructs an integrative classifier using multiple (relatively weak) thresholding classifiers.", "startOffset": 125, "endOffset": 144}, {"referenceID": 6, "context": "It was Forrest et al. (1996) who first started to use system-call traces as the raw data for host-based anomaly intrusion detection systems, and system-call traces have been widely used for IDS research and development since their seminal work (Forrest et al.", "startOffset": 7, "endOffset": 29}, {"referenceID": 1, "context": "This makes it difficult to learn long-term dependency in RNNs (Bengio et al., 1994).", "startOffset": 62, "endOffset": 83}, {"referenceID": 14, "context": "There has been previous work on using Markov models in intrusion detection systems (Hofmeyr et al., 1998; Hoang et al., 2003; Hu et al., 2009; Yolacan et al., 2014).", "startOffset": 83, "endOffset": 164}, {"referenceID": 12, "context": "There has been previous work on using Markov models in intrusion detection systems (Hofmeyr et al., 1998; Hoang et al., 2003; Hu et al., 2009; Yolacan et al., 2014).", "startOffset": 83, "endOffset": 164}, {"referenceID": 15, "context": "There has been previous work on using Markov models in intrusion detection systems (Hofmeyr et al., 1998; Hoang et al., 2003; Hu et al., 2009; Yolacan et al., 2014).", "startOffset": 83, "endOffset": 164}, {"referenceID": 32, "context": "There has been previous work on using Markov models in intrusion detection systems (Hofmeyr et al., 1998; Hoang et al., 2003; Hu et al., 2009; Yolacan et al., 2014).", "startOffset": 83, "endOffset": 164}, {"referenceID": 3, "context": "The area under curve (AUC) summarizes the ROC curve into a single value in the range [0, 1] (Bradley, 1997).", "startOffset": 92, "endOffset": 107}, {"referenceID": 31, "context": "Examples of previous work for mapping sequences into vectors of fixed-dimensional hand-crafted features include normalized frequency and tf-idf (Liao & Vemuri, 2002; Xie et al., 2014).", "startOffset": 144, "endOffset": 183}, {"referenceID": 20, "context": "In order to aid researchers in this regard, the following datasets were made publicly available from prior work: ADFA-LD (Creech & Hu, 2013), KDD98 (Lippmann et al., 2000) and UNM (of New Mexico, 2012).", "startOffset": 148, "endOffset": 171}, {"referenceID": 4, "context": "Although these two received continued criticism about their applicability to modern systems (Brown et al., 2009; McHugh, 2000; Tan & Maxion, 2003), we include them as the results would show how our model fares against early works in the field, which were mostly evaluated on these datasets.", "startOffset": 92, "endOffset": 146}, {"referenceID": 22, "context": "Although these two received continued criticism about their applicability to modern systems (Brown et al., 2009; McHugh, 2000; Tan & Maxion, 2003), we include them as the results would show how our model fares against early works in the field, which were mostly evaluated on these datasets.", "startOffset": 92, "endOffset": 146}, {"referenceID": 24, "context": "The normalized gradient was rescaled whenever its norm exceeded 5 (Pascanu et al., 2013), and we used dropout (Srivastava et al.", "startOffset": 66, "endOffset": 88}, {"referenceID": 24, "context": "The normalized gradient was rescaled whenever its norm exceeded 5 (Pascanu et al., 2013), and we used dropout (Srivastava et al., 2014) with probability 0.5. We show the ROC curves obtained from the experiment in Figure 3. For the two baseline classifiers, we used the Euclidean distance measure. Changing the distance measure to another metric did not perform well on average. In case of kNN, using k = 11 achieved the best performance empirically. For kMC, using k = 1 gave the best performance. Increasing the value of k produced similar but poorer results. We speculate the reason why a single cluster suffices as follows: learned representation vectors of normal training sequence are symmetrically distributed. The kNN classifier Cg and the kMC classifier Ch achieved similar performance. Compared to Liao & Vemuri (2002); Xie et al.", "startOffset": 67, "endOffset": 828}, {"referenceID": 24, "context": "The normalized gradient was rescaled whenever its norm exceeded 5 (Pascanu et al., 2013), and we used dropout (Srivastava et al., 2014) with probability 0.5. We show the ROC curves obtained from the experiment in Figure 3. For the two baseline classifiers, we used the Euclidean distance measure. Changing the distance measure to another metric did not perform well on average. In case of kNN, using k = 11 achieved the best performance empirically. For kMC, using k = 1 gave the best performance. Increasing the value of k produced similar but poorer results. We speculate the reason why a single cluster suffices as follows: learned representation vectors of normal training sequence are symmetrically distributed. The kNN classifier Cg and the kMC classifier Ch achieved similar performance. Compared to Liao & Vemuri (2002); Xie et al. (2014), our baseline classifiers easily returned \u2018highly normal\u2019 calls.", "startOffset": 67, "endOffset": 847}, {"referenceID": 8, "context": "According to Creech & Hu (2014), the extreme learning machine (ELM) model, sequence timedelay embedding (STIDE), and the hidden Markov model (HMM) (Forrest et al., 1996; Warrender et al., 1999) achieved about 13%, 23%, and42% false alarm rates (FAR) for 90% detection rate (DR), respectively.", "startOffset": 147, "endOffset": 193}, {"referenceID": 30, "context": "According to Creech & Hu (2014), the extreme learning machine (ELM) model, sequence timedelay embedding (STIDE), and the hidden Markov model (HMM) (Forrest et al., 1996; Warrender et al., 1999) achieved about 13%, 23%, and42% false alarm rates (FAR) for 90% detection rate (DR), respectively.", "startOffset": 147, "endOffset": 193}, {"referenceID": 8, "context": "According to Creech & Hu (2014), the extreme learning machine (ELM) model, sequence timedelay embedding (STIDE), and the hidden Markov model (HMM) (Forrest et al., 1996; Warrender et al., 1999) achieved about 13%, 23%, and42% false alarm rates (FAR) for 90% detection rate (DR), respectively. We achieved 16% FAR for 90% DR, which is comparable result with the result of ELM and outperforms STIDE and HMM. The ROC curves for ELM, HMM, and STIDE can be found, but we could not draw those curves on the same plot with ours because the authors provided no specific data on their results. Creech & Hu (2014) classified ELM as a semantic approach and other two as syntactic approaches which treat each call as a basic unit.", "startOffset": 148, "endOffset": 604}, {"referenceID": 2, "context": "It is well-known that neural network based-language models can learn semantically meaningful embeddings to continuous space (Bengio et al., 2003; Mikolov et al., 2013; Cho et al., 2014).", "startOffset": 124, "endOffset": 185}, {"referenceID": 23, "context": "It is well-known that neural network based-language models can learn semantically meaningful embeddings to continuous space (Bengio et al., 2003; Mikolov et al., 2013; Cho et al., 2014).", "startOffset": 124, "endOffset": 185}, {"referenceID": 5, "context": "It is well-known that neural network based-language models can learn semantically meaningful embeddings to continuous space (Bengio et al., 2003; Mikolov et al., 2013; Cho et al., 2014).", "startOffset": 124, "endOffset": 185}], "year": 2016, "abstractText": "In computer security, designing a robust intrusion detection system is one of the most fundamental and important problems. In this paper, we propose a system-call language-modeling approach for designing anomaly-based host intrusion detection systems. To remedy the issue of high false-alarm rates commonly arising in conventional methods, we employ a novel ensemble method that blends multiple thresholding classifiers into a single one, making it possible to accumulate \u2018highly normal\u2019 sequences. The proposed system-call language model has various advantages leveraged by the fact that it can learn the semantic meaning and interactions of each system call that existing methods cannot effectively consider. Through diverse experiments on public benchmark datasets, we demonstrate the validity and effectiveness of the proposed method. Moreover, we show that our model possesses high portability, which is one of the key aspects of realizing successful intrusion detection systems.", "creator": "LaTeX with hyperref package"}}}