{"id": "1611.01919", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Nov-2016", "title": "Decision Tree Classification with Differential Privacy: A Survey", "abstract": "Data mining information about people is becoming increasingly important in the data-driven society of the 21st century. Unfortunately, sometimes there are real-world considerations that conflict with the goals of data mining; sometimes the privacy of the people being data mined needs to be considered. This necessitates that the output of data mining algorithms be modified to preserve privacy while simultaneously not ruining the predictive power of the outputted model. Differential privacy is a strong, enforceable definition of privacy that can be used in data mining algorithms, guaranteeing that nothing will be learned about the people in the data that could not already be discovered without their participation. In this survey, we focus on one particular data mining algorithm -- decision trees -- and how differential privacy interacts with each of the components that constitute decision tree algorithms. We analyze both greedy and random decision trees, and the conflicts that arise when trying to balance privacy requirements with the accuracy of the model.", "histories": [["v1", "Mon, 7 Nov 2016 07:13:27 GMT  (314kb)", "http://arxiv.org/abs/1611.01919v1", "Pre-print of paper submitted to ACM Computing Surveys, 33 pages"]], "COMMENTS": "Pre-print of paper submitted to ACM Computing Surveys, 33 pages", "reviews": [], "SUBJECTS": "cs.DB cs.LG", "authors": ["sam fletcher", "md zahidul islam"], "accepted": false, "id": "1611.01919"}, "pdf": {"name": "1611.01919.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 161 1.01 919v 1 [cs.D B] 7N ov2 016ZDecision Tree Classification with Differential Privacy: A SurveySAM FLETCHER, Charles Sturt University MD ZAHIDUL ISLAM, Charles Sturt UniversityData Mining Information about people is becoming increasingly important in the data-driven society of the 21st century. Unfortunately, there are sometimes real-world considerations that conflict with the goals of data mining; sometimes the privacy of people mining data needs to be taken into account. This requires that the output of data mining algorithms be modified to maintain privacy while at the same time not ruining the predictive power of the output model. Differential Privacy is a strong, enforceable definition of privacy that can be used in data mining algorithms to ensure that nothing is learned about people in the data that could not already be discovered without their participation."}, {"heading": "1. INTRODUCTION", "text": "Collecting and analyzing information about people is becoming increasingly important in the data-driven society of the 21st century. Unfortunately, there is sometimes attention to detail. Technology continues to facilitate new and efficient ways of collecting data, but extracting knowledge from data remains a difficult and nuanced subject. However, many fields of science overlap when \"mining\" data for privacy includes a wide range of applications, statistics and database systems, all of which play a role in producing useful information from (potentially enormous) data storage. [Vellido et al. 2012], some companies produce a classification or regression model that can predict the future. 2011], and others detect anomalies in the data. [Chandola et al al al al. 2009] In this survey, we focus on a particular type of classification model: decision trees [Quinlan 1986]."}, {"heading": "2. PRELIMINARIES", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1. Differential Privacy", "text": "This is not a 100% guarantee, but a very high probability guarantee. The exact probability is determined by a parameter chosen by the owners. \"They will not be affected, disadvantageous or otherwise, by other analyses, datasets or information sources that are available.\" It does not promise that anything about the individual will be discovered, only that everything that has been discovered about them would have been discovered even if their data were not included in the datasets at all. It also promises that supplementary data that a malicious user might have about the individual is irrelevant; the attacker can know any amount of information about an individual and even know any other data point in the datasets, and still will not be able to detect the presence of the affected individual. This is not a 100% guarantee, but a very high probability guarantee."}, {"heading": "2.2. Conventional, Non-private Decision Trees", "text": "In fact, it is so that most of them are able to survive themselves, and that they see themselves as being able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...)"}, {"heading": "3. DIFFERENTIALLY PRIVATE DECISION TREE CLASSIFICATION", "text": "At the most basic level, a decision tree algorithm decides which attribute to share each node with (e.g. with a splitting function; see Equation 4), and this decision is dictated by the data in the node. Once the tree is finished, the leaf nodes can output some information about the class number, which is also dictated by the data in the node (see Section 2.2). Since these decisions and results are based directly on the data, the differentiated privacy statement states that the disclosure of the information can be a privacy violation, and a differentiated-private decision tree algorithm seeks to prevent these potential violations."}, {"heading": "3.1. When is the data needed?", "text": "This means that it is important to identify when exactly the data needs to be queried in order to build a decision tree. The less the data needs to be queried, the less budget we need to spend, or the more money we can spend per query. Sometimes, the data does not necessarily need to be queried, but it will still be worth the cost of privacy caused by the way the classifier executes it because it issues it. Part of the budget for optional queries is examined in Section 3.8. Which queries should be considered as such depends on an important feature of the algorithms that build the tree and how it randomly processes it. By \"greedily,\" we refer to an algorithm that uses an objective function locally in each node; heuristically, we find the best attribute to share the data contained in a node (see Section 2.1)."}, {"heading": "3.2. Non-leaf Queries", "text": "In fact, it is a question of a way in which people move in the most different parts of the world in such a way that they find their way in the most different parts of the world. (...) It is as if people live in the most different parts of the world, as if they live in the most different parts of the world. (...) It is as if people live in the most different parts of the world, as if they live in the most different parts of the world. (...) It is as if people live in the most different parts of the world, as if they live in the most different parts of the world, as if they live in the most different parts of the world, as if they live in the most different parts of the world, as if they live in the most different parts of the world, as if they live in the most different parts of the world, as if they live in the most different parts of the most different parts of the world, as if they live in the most different parts of the most different parts of the world, as if they live in the most different parts of the most different parts of the world, as if they live in the most different parts of the most different parts of the most different parts of the world, as if they live in the most different parts of the most different parts of the most different parts of the world, as if they live in the most different parts of the most different parts of the most different parts of the world, as if they live in the most different parts of the most different cultures, as if they live in the most different parts of the most different parts, as if they live in the most different parts of the most different parts of the most different parts of the cultures, as if they live in the most different parts of the most different parts of the most different parts of the cultures, as if they live in different parts of the most different parts of the most different cultures, as if they live in the most different parts of the most different parts of the most different cultures, as if they live in the most different parts of the most different cultures, as if they live in the most different parts of the most different parts of the most different parts of the most different cultures, as if they live in the most different parts of the most different cultures, as if they live in the most different parts of the most different parts of the most different parts of the most different cultures"}, {"heading": "3.3. Leaf Queries", "text": "The information to be derived from the data of a leaf node is very different from the information required in a non-leaf node. (Instead of learning the best attribute to share the data, the purpose of a leaf node is merely to predict a random approach filtered onto the leaf.) A query different from the one discussed in Section 3.2 is therefore required; reference is made to the class labels of the leaf node of 2012; a census is the most direct solution and is the solution used by almost every private decision tree we know of [Blum et al. 2005; Friedman and Schuster 2010; Jagannathan et al. 2012; Fletcher and Islam 2015b; Mohammed et al. 2015; Patil and Singh 2014; Rana et al. 2016]."}, {"heading": "3.4. Termination Criteria", "text": "In fact, most of us are able to play by the rules that they have imposed on ourselves, \"he told the Deutsche Presse-Agentur.\" We have to play by the rules, \"he said.\" We have to play by the rules, \"he said.\" But we have to play by the rules. \"He added:\" We have to play by the rules that we have imposed on ourselves, and we have to play by the rules that we have imposed on ourselves. \""}, {"heading": "3.5. Pruning", "text": "In fact, it is not the case that it is a matter of a way as it has arisen in recent years in the USA. (...) It is not as if it is a matter of a way as it exists in the USA. (...) It is not as if it is a matter of a way as it exists in the USA. (...) It is not as if it is a matter of a way as it exists in the USA. (...) It is not as if it is a matter of a way as it exists in the USA. (...) It is not as if it is a matter of a way as it exists in the USA. (...) It is not as if it is a matter of a way as it exists in the United States of the USA and in the United States of the USA and in the United States of the USA and in the United States of the United States of the United States of the United States and in the United States of the United States of the United States of the United States and in the United States of the United States of the United States of the United States of the United States and in the United States of the United States of the United States of the United States of the United States and in the United States of the United States of the United States of the United States of the United States and in the United States of the United States of the United States of the United States of the United States and in the United States of the United States of the United States of the United States of the United States and in the United States of the United States of the United States of the United States of the United States and in the United States of the United States of the United States of the United States of the United States and in the United States of the United States of the United States of the United States of the United States of the United States and in the United States of the United States of the United States of the United States of the United States of the United States and in the United States of the United States of the United States of the United States of the United States and in the United States of the United States of the United States of the United States of the United States of the United States of the United States and in the United States of the United States of the United States of the United States of the United States of the United States of the United States of the United States of the United States of the United States of the United States of the United States"}, {"heading": "3.6. Multiple Trees", "text": "(...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (). (...). (...). (...). (). (...).). (...). (...). (...). ().). (...). (...). (...). (). (). ().). (...).).). (). (). (). ().).).).). (...). (...). (). ().). (). ().).)."}, {"heading": "3.7. Weakening the Privacy Requirements", "text": "The main weakness of this approach is the question of applicability in the real world, which they posed with Wright the previous year to create a semi-supervised classifier in a semi-private scenario [Jagannathan et al. 2013]. The scenario they describe is one in which the user has a large number of non-private (i.e. public) data sets and a small number of marked private (i.e. sensitive) datasets. The authors propose an algorithm that uses the unmarked datasets in two ways. First, to locate dense regions of the data hypercube and to divide these regions in the construction of decision trees, with the aim of distributing the datasets evenly among the leaf nodes. Second, to use a small differentiated private random forest built from the private (labeled) data to classify the non-private (unlabeled) data, and then to build a large non-private decision forest with the non-private data of the decision forests, the latter two being the decision makers \"last."}, {"heading": "3.8. Query Efficiency", "text": "In this section, we use Friedman and Schuster [2010] s differentiated-private greedy decision tree as a case study, which ultimately focuses only on how to efficiently query a dataset when designing a data mining algorithm, and how to save parts of the household where possible. Section 3.2 discusses how Friedman and Schuster [2010] asked two questions per node (which split the household budget equally among all queries).The authors split half of the budget evenly, with each query being answered with other questions about where the depth of the tree is. \"A natural question might be, is the first query in each node (which spends the support) useful enough to be worth half of the budget?\" While no research has directly explored this question, a differentiated-private decision tree proposed by Mohammed et al. [2015] takes a very similar approach to Friedman and Schuster, but shifts the first node in each node allows for much the same query."}, {"heading": "4. BRINGING IT ALL TOGETHER: IMPLEMENTATIONS", "text": "All the algorithms we discuss in this survey achieve the same basic goal of issuing information about nodes in a differentiated-private manner, but do so with a variety of strategies. Some algorithms find smart patterns in the data that provide the user with knowledge, not just a black box classifier. Other algorithms sacrifice everything that is not strictly necessary to build a precise classifier by submitting as few queries as possible. These two extremes, and everything in between, offer different trade-offs between knowledge, accuracy, noise, and cost to privacy. Cleverly using the privacy budget is imperative when designing a differentially-private decision tree classifier. Table I summarizes the main properties of all the algorithms discussed. While no table could properly capture all the details of these algorithms, noise, noise, and privacy budget is imperative at imperative."}, {"heading": "5. LOOKING FORWARD", "text": "New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York Times, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York Times, New York Times, New York, New York Times, New York, New York, New York Times, New York, New York Times, New York, New York Times, New York, New York Times, New York, New York, New York Times, New York, New York, New York Times, New York, New York, New York, New York Times, New York, New York, New York, New York, New York, New York Times, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York, New York,"}, {"heading": "6. PRIVATE DATA PUBLISHING WITH DECISION TREES", "text": "This scenario is an example of what is sometimes referred to as \"privacy preserving data collection,\" and the data holder would prefer to release a private version of the data to the public. This scenario is an example of \"privacy preserving data disclosures\" [Fung et al. 2010], where the data is kept as close as possible to the original data [Fletcher and Islam 2014], while this survey focuses on the construction of differentiated-private decision trees, let's take a moment to briefly discuss the other side of the coin: how traditional, non-private decision trees can be used to publish private data."}, {"heading": "7. CHOOSING THE PRIVACY BUDGET", "text": "In all the algorithms discussed in this study, the privacy parameter determines how much noise is contained in the results of the search results. This extends to all applications of differentiated privacy; this is the core of their definition. Nevertheless, very little has been done to choose an appropriate value for the real world, both to ensure a comparable benefit between private and non-private search results, and to provide a reasonable amount of privacy protection for the individuals in the data. Dwork et al. They have left these questions to the discretion of the user and their particular needs. [Dwork and Roth 2013] have provided the best results of our knowledge, two papers have provided practical guidelines for the selection of the user. [Vu and Slavkovic 2009] have left these questions from the privacy perspective."}, {"heading": "8. CONCLUSION", "text": "When sensitive data - data that jeopardizes the privacy of the individuals described in it - needs to be mined, decision trees are well-suited to meet the stringent requirements of differentiated privacy. We have reviewed the current literature on differentiated-private decision trees and queried the names in leaf nodes to break them down into their constituent parts. Termination criteria, pruning strategies, building an ensemble of trees, greedy heuristics in non-leaf nodes, and queriing the names in leaf nodes are some of the factors that need to be taken into account when creating a powerful decision tree. We have examined each of these factors in turn, as well as others. We have compared and compared the design decisions made by the authors, assessing their effectiveness in discovering predictive knowledge from sensitive data. ACM Computing Surveys, Vol. X, Article Z, Release Date: November 2016 One topic that re-emerged in our discussion was the pervasive conflict between privacy and non-existence."}], "references": [], "referenceMentions": [], "year": 2016, "abstractText": "Data mining information about people is becoming increasingly important in the data-driven society of the 21st century. Unfortunately, sometimes there are real-world considerations that conflict with the goals of data mining; sometimes the privacy of the people being data mined needs to be considered. This necessitates that the output of data mining algorithms be modified to preserve privacy while simultaneously not ruining the predictive power of the outputtedmodel. Differential privacy is a strong, enforceable definition of privacy that can be used in data mining algorithms, guaranteeing that nothing will be learned about the people in the data that could not already be discovered without their participation. In this survey, we focus on one particular data mining algorithm \u2013 decision trees \u2013 and how differential privacy interacts with each of the components that constitute decision tree algorithms. We analyze both greedy and random decision trees, and the conflicts that arise when trying to balance privacy requirements with the accuracy of the model.", "creator": "LaTeX with hyperref package"}}}