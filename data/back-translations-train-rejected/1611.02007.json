{"id": "1611.02007", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Nov-2016", "title": "Keyphrase Annotation with Graph Co-Ranking", "abstract": "Keyphrase annotation is the task of identifying textual units that represent the main content of a document. Keyphrase annotation is either carried out by extracting the most important phrases from a document, keyphrase extraction, or by assigning entries from a controlled domain-specific vocabulary, keyphrase assignment. Assignment methods are generally more reliable. They provide better-formed keyphrases, as well as keyphrases that do not occur in the document. But they are often silent on the contrary of extraction methods that do not depend on manually built resources. This paper proposes a new method to perform both keyphrase extraction and keyphrase assignment in an integrated and mutual reinforcing manner. Experiments have been carried out on datasets covering different domains of humanities and social sciences. They show statistically significant improvements compared to both keyphrase extraction and keyphrase assignment state-of-the art methods.", "histories": [["v1", "Mon, 7 Nov 2016 12:08:13 GMT  (150kb)", "http://arxiv.org/abs/1611.02007v1", "Accepted at the COLING 2016 conference"]], "COMMENTS": "Accepted at the COLING 2016 conference", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["adrien bougouin", "florian boudin", "b\\'eatrice daille"], "accepted": false, "id": "1611.02007"}, "pdf": {"name": "1611.02007.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["adrien.bougouin@univ-nantes.fr", "florian.boudin@univ-nantes.fr", "beatrice.daille@univ-nantes.fr"], "sections": [{"heading": null, "text": "ar Xiv: 161 1.02 007v 1 [cs.C L] 7N ov2 016"}, {"heading": "1 Introduction", "text": "Keyphrases are words and phrases that give a synoptic picture of what is important within a document. They are useful in many tasks such as document indexing (Gutwin et al., 1999), text categorization (Hulth and Megyesi, 2006), or summary (Litvak and Last, 2008). However, most documents do not provide keyphrases, and the daily flow of new documents makes manual keyphrase annotation impractical. As a result, automatic keyphrase annotation has received particular attention in the NLP community and many methods have been suggested (Hasan and Ng, 2014). The task of automatic keyphrase annotation is to identify the most important concepts, or topics addressed in a document. Such a task is critical for accessing relevant scientific documents that may be useful for researchers. Keyphrase annotation methods fall into two broad categories: key phrase extraction and key phrase assignment and keyphrase assignment."}, {"heading": "2 Related Work", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Keyphrase extraction", "text": "Keyphrase extraction is the most common approach to tackling the automatic keyphrase annotation task. Previous work includes many approaches (Hasan and Ng, 2014), from statistical ranking (Salton et al., 1975) to binary classification (Witten et al., 1999), by graph-based ranking (Mihalcea and Tarau, 2004) of the keyphrase candidates. As our approach uses graph-based ranking, we focus on the latter. For a detailed overview of keyphrase extraction methods, refer to (Hasan and Ng, 2010; Hasan and Ng, 2014).Since the pioneering work of Mihalcea and Tarau (2004), graph-based ranking approaches to keyphrase extraction are becoming increasingly popular. The original idea behind these approaches is to create a graph from the document and rate its nodes according to their significance using central metrics. In Textank Co (Micehala document, the input 2004)."}, {"heading": "2.2 Keyphrase assignment", "text": "Unlike keyphrase extraction, keyphrase assignment also aims to provide keyphrases that do not occur within the document, a task that is more difficult than keyphrase extraction and thus rarely used for automatic keyphrase annotation. KEA + + (Medelyan and Witten, 2006) is the state-of-the-art method of keyphrase assignment. KEA + + uses a domain-specific thesaurus to assign keyphrases to a document. First, keyphrase candidates are selected from among the document's n programs. N programs that do not match a thesaurus entry are either removed or replaced with a synonym that matches a thesaurus entry. This candidate selection approach induces a constraint on keyphrase assignment, which Medelyan and Witten call keyphrase indexing."}, {"heading": "3 Co-ranking for Keyphrase Annotation", "text": "In this section we present TopicCoRank1, our method for annotating keywords, which builds on the existing method TopicRank (Bougouin et al., 2013) and to which we add keyword assignment."}, {"heading": "3.1 TopicRank", "text": "TopicRank is a graph-based keyphrase extraction method based on the following five steps: 1. Keyphrase candidate selection. After previous work (Hasan and Ng, 2010; Wan and Xiao, 2008), keyphrase candidates are selected from the sequence of neighboring nouns and adjectives that occur within the document (/ (N | A) + /). 2. Topical clustering. Similar keyphrase candidates c are grouped into topics based on the words they share. Bougouin et al. (2013) use hierarchical agglomerative clustering (HAC) with a strain overlap similarity (see Eq.2) and an average keyword category candidate. Initially, each keyphrase candidate is a single cluster, then candidates share an average of 1 {4 derived words with the candidates of another cluster."}, {"heading": "3.2 Unified graph construction", "text": "TopicCoRank operates through a uniform graph that links two graphs representing document topics, the controlled keyphrases and the relationships between them (see Figure 1). The controlled keyphrases are the key phrases that were manually assigned to the training documents. Considering the manually assigned keyphrases as the controlled vocabulary, one bypasses the need for manually generated controlled vocabulary and also allows us to further exploit the semantic mappings between domain-specific (controlled) keyphrases. Since controlled keyphrases are probably not redundant, we do not group them topically, as we do for keyphrase candidates. Let G \"pV\" T Y K, E \"A Y Eoutq denote the unified graph. Topics T\" tt1, t2, tnu and controlled keyphrases K \"tk1, k2,... are connected to their V fields."}, {"heading": "3.3 Graph-based co-ranking", "text": "TopicCoRank gives each topic or controlled keyphrase an importance score using graph co-ranking (see equations 6 and 7) Sptiq or Spkiq. Our graph co-ranking simulates the voting concept based on internal and external recommendations. The internal recommendation Rin comes from nodes of the same graph (see equation 8). A topic or controlled keyphrase is important if it is strongly associated with other topics or controlled keyphrases. The external recommendation Rin influences the ranking of topics by controlled keyphrases and controlled keyphrases by topic. The external recommendation Rout comes from nodes of the other graph (see equation 9). A topic or controlled keyphrase gains importance when it is associated with important controlled keyphrases or an important topic."}, {"heading": "3.4 Keyphrase annotation", "text": "Keyphrases are extracted and assigned from the N-ranked topics and controlled keyphrases, regardless of their nature. We extract topic-related keyphrases using the previous TopicRank strategy. Only one keyphrase is extracted per topic: the keyphrase candidate that first occurs within the document. We assign controlled keyphrases only if they are directly or temporarily associated with a topic in the document. If the ranking of a controlled keyphrase is not affected by either a topic in the document or by controlled keyphrases associated with topics, then their value status is not associated with the content of the document and it should not be assigned. In this step, two variants of TopicCoRank can be suggested that perform either extraction or assignment, namely TopicCoRankextr and TopicCoRankextr. If keyphrases are only extracted from the topics, we get TopicRankextr. If keyphrases are assigned only to the controlled keyphrases, we get TopicRankextr."}, {"heading": "4 Experimental Setup", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Datasets", "text": "We are conducting our experiments with data from the reference data sets DEFT-2016 (Daille et al., 2016) 3 in three areas: linguistics, information science and archaeology. Table 1 shows the factual information3Data was provided by the TermITH project both for DEFT-2016 and for this thesis. In parallel, the subset has been modified for the purposes of DEFT-2016. Therefore, we are using the same data as DEFT2016, but the subset is different. The subset we have used for our experiences can be found here: https: / / github.com / adrien-bougouin / KeyBench / tree / coling _ 2016 / datasets / about the datasets. Each data set is a collection of 706 to 718 French bibliographic data sets collected from the database of the French Institute of Scientific and Technical Information (Inist)."}, {"heading": "4.2 Document preprocessing", "text": "We apply the following pre-processing steps to each document: sentence segmentation, word tokenization, and part-of-speech (POS) tagging. Sentence segmentation is performed using the Python Natural Language ToolKit (NLTK) point SentenceTokenizer (Bird et al., 2009), word tokenization using the bonsai word tokenizer5, and POS tagging with MElt (Denis and Sagot, 2009)."}, {"heading": "4.3 Baselines", "text": "To demonstrate the effectiveness of our approach, we compare TopicCoRank and its variants (TopicCoRankextr and TopicCoRankassign) with TopicRank and KEA + +. For KEA + +, we use the thesauri of Inist6 to index the bibliographic records of linguistics, information science and archaeology."}, {"heading": "4.4 TopicCoRank setting", "text": "The empirical setup means that the meaning of topics is much more strongly influenced by controlled keyphrases than other topics, and that the meaning of controlled keyphrases is also influenced by controlled keyphrases and topics. In other words, the domain has a positive influence on the common task of keyphrase extraction and assignment."}, {"heading": "5 Experimental Results", "text": "This section presents and analyzes the results of our experiments. For each document of each dataset, we compare the keyphrases issued by each method with the reference keyphrases of the document. From the comparisons, we calculate the macro-averaged precision (P), the recall (R) and the f1 score (F) per dataset and per method.4http: / / www.inist.fr 5The bonsai word tokenizer is a tool provided with the Bonsai PCFG-LA parser: http: / / alpage.inria.fr / statgram / frdep / fr _ stat _ dep _ parsing.html 6Thesauri are available at: http: / / deft2016.univ-nantes.fr / download / traindev /"}, {"heading": "5.1 Macro-averages results", "text": "Table 2 shows the macro-averaged precision, retrieval, and f1 score in percent when 10 keyphrases are extracted / assigned for each row by TopicRank, KEA + +, TopicCoRankextr, TopicCoRankassign, and TopicCoRank. First, we note that the assignment basis KEA + + usually performs the lowest, which is surprising compared to the performance reported by Medelyan and Witten (2006). First, the reason for this observation is that KEA + + is limited to thesauri entries, while most keyphrases are absent from our documents. Second, KEA + + relies on rich thesauri containing a significant amount of semantic relationships between entries, while our (real-world application) thesauri significantly exceeds a modest amount of semantic relationships between centres.Overall, the use of graph co-rankings TopicRank and K+ clearly exceeds."}, {"heading": "5.2 Precision/recall curves", "text": "In addition, we follow Hasan and Ng (2010) and analyze the accuracy callback curves of TopicRank, KEA + + and TopicCoRank. To generate the curves, we vary the number of keyphrases evaluated (cutoff) from 1 to the total number of keyphrases extracted / assigned, and calculate the accuracy and retrieval for each cut-off. Such a representation gives a good estimate of the advantage of one method over others, especially if the other methods provide below-the-curve (AUC) performance. Figure 2 shows the accuracy / retrieval curves of TopicRank, KEA + + and TopicCoRank on each dataset. The final callback rate for the methods does not reach 100%, because the candidate selection method does not provide keyphrases that do not occur within the document, as well as candidates that do not fit the POS tag pattern / (N | A) + / TopicRank. TopicRank is also a keyboard keyboard keyboard keyboard and keyboard output, both of which is a keyboard Rank and a keyboard keyword."}, {"heading": "5.3 Extraction vs. assignment", "text": "Since TopicCoRank is the first method for simultaneous extraction and assignment of keyphrases, we are conducting an additional experiment that shows the extent to which extraction and assignment contribute to the final results. To this end, we show the behavior of extraction and assignment depending on the influence of the internal recommendation on the ranking for each (test) document of each record. Fig.3 shows the behavior of TopicCoRankextr in case of deviations from 0 to 1. In case of \"0,\" only the domain affects the ranking of the topics. Somewhat equivalent to KEA + +, TopicRankextr uses \"0 to mainly extract keyphrases from topics related to controlled keyphrases. In case of\" 1, \"the domain does not affect the ranking and the performance of TopicCoRankextr lies within the range of TopicRankextr. Overall, the performance curve of TopicRankextr decreases with the simultaneous increase of the keysign."}, {"heading": "5.4 Qualitative example", "text": "To demonstrate the usefulness of TopicCoRank, we compare it to TopicRank on one of our bibliographic linguistics datasets (see Figure 5). TopicRank successfully identifies two of the reference keyphrases across the nine reference keyphrases: \"lexical semantics\" and \"semantic variation.\" TopicCoRank outperforms TopicRank mostly because it finds keyphrases that do not appear within the document: \"French,\" \"semantic variation,\" \"French,\" \"syntax,\" \"semantic interpretation,\" and \"distribution analysis.\" Some keyphrases, such as \"French,\" are often assigned to TopicRank because they are part of most bibliographic datasets in our datasets: \"French,\" \"\" semantic interpretation, \"\" semantic interpretation, \"and\" distribution analysis. \""}, {"heading": "6 Conclusion", "text": "Our method, TopicCoRank, builds two graphs: one with document topics and one with controlled keyphrases (Training Keyphrases). We developed a strategy to unify the two graphs and rank them by important topics and controlled keyphrases by means of co-ranking. We conducted experiments on three sets of data from different domains. Results showed that our approach benefits from both controlled keyphrases and document topics and improves both keyphrase extraction and keyphrase mapping. TopicCoRank can be used to comment on keyphrases in scientific fields similar to professional indexers."}, {"heading": "Acknowledgments", "text": "This work was supported by the French National Research Agency (TermITH project - ANR-12-CORD-0029) and the TALIAS project (CNRS PEPS INS2I 2016 funding, https: / / boudinfl.github.io / talias /)."}], "references": [{"title": "Latent Dirichlet Allocation", "author": ["Blei et al.2003] David M. Blei", "Andrew Y. Ng", "Michael I. Jordan"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Blei et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Blei et al\\.", "year": 2003}, {"title": "TopicRank: Graph-Based Topic Ranking for Keyphrase Extraction", "author": ["Florian Boudin", "B\u00e9atrice Daille"], "venue": "In Proceedings of the 6th International Joint Conference on Natural Language Processing (IJCNLP),", "citeRegEx": "Bougouin et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bougouin et al\\.", "year": 2013}, {"title": "The Anatomy of a Large-Scale Hypertextual Web Search Engine", "author": ["Brin", "Page1998] Sergey Brin", "Lawrence Page"], "venue": "Computer Networks and ISDN Systems,", "citeRegEx": "Brin et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Brin et al\\.", "year": 1998}, {"title": "Indexation d\u2019articles scientifiques pr\u00e9sentation et r\u00e9sultats du d\u00e9fi fouille de textes deft 2016", "author": ["Sabine Barreaux", "Florian Boudin", "Adrien Bougouin", "Damien Cram", "Amir Hazem"], "venue": "In Actes de 12e De\u0301fi Fouille de Texte (DEFT),", "citeRegEx": "Daille et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Daille et al\\.", "year": 2016}, {"title": "Coupling an Annotated Corpus and a Morphosyntactic Lexicon for State-of-the-Art POS Tagging with Less Human Effort", "author": ["Denis", "Sagot2009] Pascal Denis", "Beno\u0131\u0302t Sagot"], "venue": "In Proceedings of the 23rd Pacific Asia Conference on Language, Information and Computation (PACLIC),", "citeRegEx": "Denis et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Denis et al\\.", "year": 2009}, {"title": "Improving Browsing in Digital Libraries with Keyphrase Indexes", "author": ["Gutwin et al.1999] Carl Gutwin", "Gordon Paynter", "Ian Witten", "Craig Nevill Manning", "Eibe Frank"], "venue": "Decision Support Systems,", "citeRegEx": "Gutwin et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Gutwin et al\\.", "year": 1999}, {"title": "Conundrums in Unsupervised Keyphrase Extraction: Making Sense of the State-of-the-Art", "author": ["Hasan", "Ng2010] Kazi Saidul Hasan", "Vincent Ng"], "venue": "In Proceedings of the 23rd International Conference on Computational Linguistics: Posters (COLING),", "citeRegEx": "Hasan et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Hasan et al\\.", "year": 2010}, {"title": "Automatic Keyphrase Extraction: A Survey of the State of the Art", "author": ["Hasan", "Ng2014] Kazi Saidul Hasan", "Vincent Ng"], "venue": "In Proceedings of the Association for Computational Linguistics (ACL),", "citeRegEx": "Hasan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hasan et al\\.", "year": 2014}, {"title": "A study on automatically extracted keywords in text categorization", "author": ["Hulth", "Megyesi2006] Anette Hulth", "Be\u00e1ta B. Megyesi"], "venue": "In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Hulth et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Hulth et al\\.", "year": 2006}, {"title": "Graph-Based Keyword Extraction for SingleDocument Summarization", "author": ["Litvak", "Last2008] Marina Litvak", "Mark Last"], "venue": "In Proceedings of the Workshop on Multi-Source Multilingual Information Extraction and Summarization,", "citeRegEx": "Litvak et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Litvak et al\\.", "year": 2008}, {"title": "Automatic Keyphrase Extraction Via Topic Decomposition", "author": ["Liu et al.2010] Zhiyuan Liu", "Wenyi Huang", "Yabin Zheng", "Maosong Sun"], "venue": "In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing(EMNLP),", "citeRegEx": "Liu et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2010}, {"title": "Automatic Keyphrase Extraction by Bridging Vocabulary Gap", "author": ["Liu et al.2011] Zhiyuan Liu", "Xinxiong Chen", "Yabin Zheng", "Maosong Sun"], "venue": "In Proceedings of the 15th Conference on Computational Natural Language Learning,", "citeRegEx": "Liu et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2011}, {"title": "Thesaurus Based Automatic Keyphrase Indexing", "author": ["Medelyan", "Witten2006] Olena Medelyan", "Ian H Witten"], "venue": "In Proceedings of the 6th ACM/IEEE-CS joint conference on Digital libraries,", "citeRegEx": "Medelyan et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Medelyan et al\\.", "year": 2006}, {"title": "Domain-Independent Automatic Keyphrase Indexing with Small Training Sets", "author": ["Medelyan", "Witten2008] Olena Medelyan", "Ian H. Witten"], "venue": "Journal of the American Society for Information Science and Technology,", "citeRegEx": "Medelyan et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Medelyan et al\\.", "year": 2008}, {"title": "TextRank: Bringing Order Into Texts", "author": ["Mihalcea", "Tarau2004] Rada Mihalcea", "Paul Tarau"], "venue": "Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Mihalcea et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Mihalcea et al\\.", "year": 2004}, {"title": "A Vector Space Model for Automatic Indexing", "author": ["Salton et al.1975] Gerard Salton", "Andrew Wong", "Chungshu Yang"], "venue": "Communication ACM,", "citeRegEx": "Salton et al\\.,? \\Q1975\\E", "shortCiteRegEx": "Salton et al\\.", "year": 1975}, {"title": "Single Document Keyphrase Extraction Using Neighborhood Knowledge", "author": ["Wan", "Xiao2008] Xiaojun Wan", "Jianguo Xiao"], "venue": "In Proceedings of the 23rd National Conference on Artificial Intelligence - Volume", "citeRegEx": "Wan et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Wan et al\\.", "year": 2008}, {"title": "KEA: Practical Automatic Keyphrase Extraction", "author": ["Witten et al.1999] Ian H. Witten", "Gordon W. Paynter", "Eibe Frank", "Carl Gutwin", "Craig G. Nevill Manning"], "venue": "In Proceedings of the 4th ACM Conference on Digital Libraries,", "citeRegEx": "Witten et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Witten et al\\.", "year": 1999}, {"title": "WordTopic-MultiRank: A New Method for Automatic Keyphrase Extraction", "author": ["Zhang et al.2013] Fan Zhang", "Lian\u2019en Huang", "Bo Peng"], "venue": "In Proceedings of the Sixth International Joint Conference on Natural Language Processing,", "citeRegEx": "Zhang et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2013}], "referenceMentions": [{"referenceID": 5, "context": "They are useful in many tasks such as document indexing (Gutwin et al., 1999), text categorization (Hulth and Megyesi, 2006) or summarization (Litvak and Last, 2008).", "startOffset": 56, "endOffset": 77}, {"referenceID": 11, "context": "Observations made on manually assigned keyphrases from scientific papers of specialized domains show that professional human indexers both extract keyphrases from the content of the document and assign keyphrases based on their knowledge of the domain (Liu et al., 2011).", "startOffset": 252, "endOffset": 270}, {"referenceID": 1, "context": "First, we present a simple yet efficient assignment extension of a state-of-the-art graph-based keyphrase extraction method, TopicRank (Bougouin et al., 2013).", "startOffset": 135, "endOffset": 158}, {"referenceID": 15, "context": "Previous work includes many approaches (Hasan and Ng, 2014), from statistical ranking (Salton et al., 1975) to binary classification (Witten et al.", "startOffset": 86, "endOffset": 107}, {"referenceID": 17, "context": ", 1975) to binary classification (Witten et al., 1999), through graph-based ranking (Mihalcea and Tarau, 2004) of keyphrase candidates.", "startOffset": 33, "endOffset": 54}, {"referenceID": 15, "context": "Previous work includes many approaches (Hasan and Ng, 2014), from statistical ranking (Salton et al., 1975) to binary classification (Witten et al., 1999), through graph-based ranking (Mihalcea and Tarau, 2004) of keyphrase candidates. As our approach uses graph-based ranking, we focus on the latter. For a detailed overview of keyphrase extraction methods, refer to (Hasan and Ng, 2010; Hasan and Ng, 2014). Since the seminal work of Mihalcea and Tarau (2004), graph-based ranking approaches to keyphrase extraction are becoming increasingly popular.", "startOffset": 87, "endOffset": 462}, {"referenceID": 0, "context": "(2010) biased multiple graphs with topic probabilities drawn from LDA (Latent Dirichlet Allocation) (Blei et al., 2003), to rank the words regarding each graph and to merge the rankings together.", "startOffset": 100, "endOffset": 119}, {"referenceID": 8, "context": "Liu et al. (2010) biased multiple graphs with topic probabilities drawn from LDA (Latent Dirichlet Allocation) (Blei et al.", "startOffset": 0, "endOffset": 18}, {"referenceID": 0, "context": "(2010) biased multiple graphs with topic probabilities drawn from LDA (Latent Dirichlet Allocation) (Blei et al., 2003), to rank the words regarding each graph and to merge the rankings together. This method performs as many rankings as the number of topics and gives higher importance scores to high-ranking words for as many topics as possible. By doing so, Liu et al. (2010) increase the topic coverage provided by the extracted keyphrases.", "startOffset": 101, "endOffset": 378}, {"referenceID": 0, "context": "(2010) biased multiple graphs with topic probabilities drawn from LDA (Latent Dirichlet Allocation) (Blei et al., 2003), to rank the words regarding each graph and to merge the rankings together. This method performs as many rankings as the number of topics and gives higher importance scores to high-ranking words for as many topics as possible. By doing so, Liu et al. (2010) increase the topic coverage provided by the extracted keyphrases. Most recently, Zhang et al. (2013) and Bougouin et al.", "startOffset": 101, "endOffset": 479}, {"referenceID": 0, "context": "(2010) biased multiple graphs with topic probabilities drawn from LDA (Latent Dirichlet Allocation) (Blei et al., 2003), to rank the words regarding each graph and to merge the rankings together. This method performs as many rankings as the number of topics and gives higher importance scores to high-ranking words for as many topics as possible. By doing so, Liu et al. (2010) increase the topic coverage provided by the extracted keyphrases. Most recently, Zhang et al. (2013) and Bougouin et al. (2013) explored further the value of topics for keyphrase extraction.", "startOffset": 101, "endOffset": 506}, {"referenceID": 0, "context": "(2010) biased multiple graphs with topic probabilities drawn from LDA (Latent Dirichlet Allocation) (Blei et al., 2003), to rank the words regarding each graph and to merge the rankings together. This method performs as many rankings as the number of topics and gives higher importance scores to high-ranking words for as many topics as possible. By doing so, Liu et al. (2010) increase the topic coverage provided by the extracted keyphrases. Most recently, Zhang et al. (2013) and Bougouin et al. (2013) explored further the value of topics for keyphrase extraction. Zhang et al. (2013) used graph co-ranking to improve the method of Liu et al.", "startOffset": 101, "endOffset": 589}, {"referenceID": 0, "context": "(2010) biased multiple graphs with topic probabilities drawn from LDA (Latent Dirichlet Allocation) (Blei et al., 2003), to rank the words regarding each graph and to merge the rankings together. This method performs as many rankings as the number of topics and gives higher importance scores to high-ranking words for as many topics as possible. By doing so, Liu et al. (2010) increase the topic coverage provided by the extracted keyphrases. Most recently, Zhang et al. (2013) and Bougouin et al. (2013) explored further the value of topics for keyphrase extraction. Zhang et al. (2013) used graph co-ranking to improve the method of Liu et al. (2010) by introducing LDA topics right inside the graph.", "startOffset": 101, "endOffset": 654}, {"referenceID": 0, "context": "(2010) biased multiple graphs with topic probabilities drawn from LDA (Latent Dirichlet Allocation) (Blei et al., 2003), to rank the words regarding each graph and to merge the rankings together. This method performs as many rankings as the number of topics and gives higher importance scores to high-ranking words for as many topics as possible. By doing so, Liu et al. (2010) increase the topic coverage provided by the extracted keyphrases. Most recently, Zhang et al. (2013) and Bougouin et al. (2013) explored further the value of topics for keyphrase extraction. Zhang et al. (2013) used graph co-ranking to improve the method of Liu et al. (2010) by introducing LDA topics right inside the graph. Bougouin et al. (2013) proposed to represent topics as clusters of similar keyphrase candidates within the document (i.", "startOffset": 101, "endOffset": 727}, {"referenceID": 0, "context": "(2010) biased multiple graphs with topic probabilities drawn from LDA (Latent Dirichlet Allocation) (Blei et al., 2003), to rank the words regarding each graph and to merge the rankings together. This method performs as many rankings as the number of topics and gives higher importance scores to high-ranking words for as many topics as possible. By doing so, Liu et al. (2010) increase the topic coverage provided by the extracted keyphrases. Most recently, Zhang et al. (2013) and Bougouin et al. (2013) explored further the value of topics for keyphrase extraction. Zhang et al. (2013) used graph co-ranking to improve the method of Liu et al. (2010) by introducing LDA topics right inside the graph. Bougouin et al. (2013) proposed to represent topics as clusters of similar keyphrase candidates within the document (i.e. words and phrases from the document), to rank these topics instead of the words and to extract the most representative candidate as keyphrase for each important topic. As our work extends that of Bougouin et al. (2013), we present a detailed description of their method in Section 3.", "startOffset": 101, "endOffset": 1045}, {"referenceID": 1, "context": "3 Co-ranking for Keyphrase Annotation This section presents TopicCoRank1, our keyphrase annotation method built on the existing method TopicRank (Bougouin et al., 2013) to which we add keyphrase assignment.", "startOffset": 145, "endOffset": 168}, {"referenceID": 1, "context": "3 Co-ranking for Keyphrase Annotation This section presents TopicCoRank1, our keyphrase annotation method built on the existing method TopicRank (Bougouin et al., 2013) to which we add keyphrase assignment. We first detail TopicRank, then present our contributions. 3.1 TopicRank TopicRank is a graph-based keyphrase extraction method that relies on the following five steps: 1. Keyphrase candidate selection. Following previous work (Hasan and Ng, 2010; Wan and Xiao, 2008), keyphrase candidates are selected from the sequences of adjacent nouns and adjectives that occur within the document (/(N|A)+/). 2. Topical clustering. Similar keyphrase candidates c are clustered into topics based on the words they share. Bougouin et al. (2013) use a Hierarchical Agglomerative Clustering (HAC) with a stem overlap similarity (see equation 2) and an average linkage.", "startOffset": 146, "endOffset": 739}, {"referenceID": 1, "context": "To accept inflexions, such as plural inflexions, we follow Bougouin et al. (2013) and perform the comparison with stems.", "startOffset": 59, "endOffset": 82}, {"referenceID": 1, "context": "The inner recommendation is similar to the recommendation computed in previous work (Bougouin et al., 2013; Mihalcea and Tarau, 2004; Wan and Xiao, 2008).", "startOffset": 84, "endOffset": 153}, {"referenceID": 3, "context": "1 Datasets We conduct our experiments on data from the DEFT-2016 benchmark datasets (Daille et al., 2016)3 in three domains: linguistics, information Science and archaeology.", "startOffset": 84, "endOffset": 105}], "year": 2016, "abstractText": "Keyphrase annotation is the task of identifying textual units that represent the main content of a document. Keyphrase annotation is either carried out by extracting the most important phrases from a document, keyphrase extraction, or by assigning entries from a controlled domain-specific vocabulary, keyphrase assignment. Assignment methods are generally more reliable. They provide better-formed keyphrases, as well as keyphrases that do not occur in the document. But they are often silent on the contrary of extraction methods that do not depend on manually built resources. This paper proposes a new method to perform both keyphrase extraction and keyphrase assignment in an integrated and mutual reinforcing manner. Experiments have been carried out on datasets covering different domains of humanities and social sciences. They show statistically significant improvements compared to both keyphrase extraction and keyphrase assignment state-of-the art methods.", "creator": "LaTeX with hyperref package"}}}