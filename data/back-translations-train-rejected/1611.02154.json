{"id": "1611.02154", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Nov-2016", "title": "Bayesian Non-parametric model to Target Gamification Notifications Using Big Data", "abstract": "I suggest an approach that helps the online marketers to target their Gamification elements to users by modifying the order of the list of tasks that they send to users. It is more realistic and flexible as it allows the model to learn more parameters when the online marketers collect more data. The targeting approach is scalable and quick, and it can be used over streaming data.", "histories": [["v1", "Fri, 4 Nov 2016 04:40:23 GMT  (1577kb)", "http://arxiv.org/abs/1611.02154v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["meisam hejazi nia", "brian ratchford"], "accepted": false, "id": "1611.02154"}, "pdf": {"name": "1611.02154.pdf", "metadata": {"source": "CRF", "title": "BAYESIAN NON-PARAMETRIC MODEL TO TARGET GAMIFICATION NOTIFICATIONS USING BIG DATA", "authors": ["Meisam Hejazi Nia", "Brian Ratchford", "Naveen Jindal"], "emails": [], "sections": [{"heading": null, "text": "This year it is so far that it will only take a few days to reach an agreement."}], "references": [{"title": "The infinite hidden Markov model. In Advances in neural information processing systems (pp. 577-584)", "author": ["M.J. Beal", "Z. Ghahramani", "C.E. Rasmussen"], "venue": "Bayesian analysis,", "citeRegEx": "Beal et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Beal et al\\.", "year": 2001}, {"title": "Particle learning and smoothing", "author": ["C. Carvalho", "M.S. Johannes", "H.F. Lopes", "N. Polson"], "venue": "choice. Journal of Econometrics,", "citeRegEx": "Carvalho et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Carvalho et al\\.", "year": 2010}, {"title": "Auxiliary mixture sampling with applications to logistic models", "author": ["S. Fr\u00fchwirth-Schnatter", "R. Fr\u00fchwirth"], "venue": "Computational Statistics & Data Analysis,", "citeRegEx": "Fr\u00fchwirth.Schnatter and Fr\u00fchwirth,? \\Q2007\\E", "shortCiteRegEx": "Fr\u00fchwirth.Schnatter and Fr\u00fchwirth", "year": 2007}, {"title": "Why more data and simple algorithms beat complex analytics models", "author": ["W. Garrett"], "venue": "Data informed website. http://data-informed.com/why-more-data-and-simple-algorithms-beat-complex-analytics-models/. August", "citeRegEx": "Garrett,? \\Q2013\\E", "shortCiteRegEx": "Garrett", "year": 2013}, {"title": "Variational Bayes for d-dimensional Gaussian mixture models. University College London. Penny, W.D. \u201cKullback-Liebler Divergences of Normal, Gamma, Dirichlet and Wishart Densities.", "author": ["W.D. Penny"], "venue": "Technical report, Wellcome Department of Cognitive Neurology,", "citeRegEx": "Penny,? \\Q2001\\E", "shortCiteRegEx": "Penny", "year": 2001}, {"title": "On-line learning for the infinite hidden Markov model.Communications in StatisticsSimulation and Computation", "author": ["A. Rodriguez"], "venue": "Journal of the american statistical association,", "citeRegEx": "Rodriguez,? \\Q2011\\E", "shortCiteRegEx": "Rodriguez", "year": 2011}], "referenceMentions": [{"referenceID": 5, "context": "In order to write the particle learning algorithm for the infinite Hidden Markov Model consistent with Rodriguez (2011) an integrated likelihood for emission probability is required.", "startOffset": 103, "endOffset": 120}, {"referenceID": 5, "context": "Consistent Rodriguez (2011), I integrate out the transition probability } { i s \uf070 , but to be able to run hierarchical DP model on the emission parameter, I do not integrate out the state-specific emission parameters \uf07b \uf07d i s \uf047 , so I draw particles for them along with other structural (i.", "startOffset": 11, "endOffset": 28}, {"referenceID": 5, "context": "Rodriguez (2011) suggests that consistent with MCMC algorithm series of auxiliary variables can be used to draw structural parameters.", "startOffset": 0, "endOffset": 17}, {"referenceID": 4, "context": "Penny (2001) computes Kullback-Leibler (KL) divergence or relative entropy of of Normal, Gamma, Dirichlet and Wishart densities.", "startOffset": 0, "endOffset": 13}, {"referenceID": 4, "context": "Penny (2001) computes Kullback-Leibler (KL) divergence or relative entropy of of Normal, Gamma, Dirichlet and Wishart densities. For DP mixture Blei and Jordan (2006) apply mean filed variational approach for the stick-breaking construction.", "startOffset": 0, "endOffset": 167}, {"referenceID": 4, "context": "For the Gaussian component portion, we adopted an algorithm suggested by Penny (2002). We refer interested reader to that short instruction.", "startOffset": 73, "endOffset": 86}], "year": 2016, "abstractText": null, "creator": null}}}