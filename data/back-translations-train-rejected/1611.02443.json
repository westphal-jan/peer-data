{"id": "1611.02443", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Nov-2016", "title": "Domain Adaptation with L2 constraints for classifying images from different endoscope systems", "abstract": "This paper proposes a method for domain adaptation that extends the maximum margin domain transfer (MMDT) proposed by Hoffman et al., by introducing L_2 distance constraints between samples of different domains; thus, our method is denoted as MMDTL2. Motivated by the differences between the images taken by narrow band imaging (NBI) endoscopic devices, we utilize different NBI devices as different domains and estimate the transformations between samples of different domains, i.e., image samples taken by different NBI endoscope systems. We first formulate the problem in the primal form, and then derive the dual form with much lesser computational costs as compared to the naive approach. From our experimental results using NBI image datasets from two different NBI endoscopic devices, we find that MMDTL2 is more stable than MMDT and better than support vector machines without adaptation.", "histories": [["v1", "Tue, 8 Nov 2016 09:29:17 GMT  (5438kb,D)", "http://arxiv.org/abs/1611.02443v1", "28 pages"]], "COMMENTS": "28 pages", "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["toru tamaki", "shoji sonoyama", "takio kurita", "tsubasa hirakawa", "bisser raytchev", "kazufumi kaneda", "tetsushi koide", "shigeto yoshida", "hiroshi mieno", "shinji tanaka", "kazuaki chayama"], "accepted": false, "id": "1611.02443"}, "pdf": {"name": "1611.02443.pdf", "metadata": {"source": "CRF", "title": "Domain Adaptation with L2 constraints for classifying images from different endoscope systems", "authors": ["Toru Tamakia", "Shoji Sonoyama", "Takio Kurita", "Tsubasa Hirakawa", "Bisser Raytchev", "Kazufumi Kaneda", "Tetsushi Koide", "Shigeto Yoshida", "Hiroshi Mieno", "Shinji Tanaka", "Kazuaki Chayama"], "emails": [], "sections": [{"heading": null, "text": "This paper proposes a domain adjustment method that extends the maximum margin domain transfer (MMDT) proposed by Hoffman et al. by introducing L2 distance constraints between samples from different domains; therefore, our method is referred to as MMDTL2. Motivated by the differences between images taken by endoscopic narrowband imaging devices (NBI), we use different NBI devices as different domains and estimate the transformations between samples from different domains, i.e. image samples taken from different NBI endoscope systems. We first formulate the problem in its original form and then derive the dual form with significantly lower processing costs compared to the na\u00efve approach. From our experimental results using NBI image sets from two different endoscopic NBI devices, we find that MDTL2 is more stable than MDTL2 and better supports vector machines without adjustment."}, {"heading": "1. Introduction", "text": "This year, it is at an all-time high in the history of the European Union."}, {"heading": "2. Problem formulation", "text": "In this section we will discuss the problems of MMDT (21) and our proposed MMDTL2.Problem (MMDT) (MMDT) (1), which we present in the MMDT (1) and in the MMDT (2), which we present in the MMDT (1) and in the MDT (2), which we present in the MDT (1) and in the MDT (2), which we present in the MDT (2), which we present in the MDT (2) and in the MDT (2), which we present in the MDT (2), which we present in the MDD (2), which (2), which (2), which (2), which (2), which (2), which (2), which (MD), which (2), which (2), which (2), which (2), which (MD), which (2), which we present in the MD."}, {"heading": "3. Primal problem", "text": "In this section, we reformulate the partial problem (7) with inequality limitations instead of loss functions. Problem 4 (estimation of W). We want to find W-RLs (Lt + 1) that minimize the following objective function: min W, {\u0445tkm} 1 2 cf-W-2F + cT K-K-K = 1 M-K = 1 l-tkm + 1 2 M-M-M = 1 N-N = 1 snm-W x-tm \u2212 xsn-22 (10) s.t.t.t.t.t.t.tkm \u2265 0, (11) ytkm-T k (W x-tm1) \u2212 1 + \u041atkm \u2265 0. (12) First, we rewrite the objective function into a matrix form. For this purpose, we present the Vec operator and some formulas below."}, {"heading": "3.1. Operator vec", "text": "Here we define a vectorized operator for the rearrangement of matrix vector products = WT2... wTLs, (13) we define the operator vec, which W in the main order asvec (W) = w1 w2... wLs (Lt + 1). (14) This definition differs from the definition used in the literature, which is defined in the main order column, e.g. in [24]. Next we can describe matrix vector multiplications using the vector operator T (Lt + 1). (14) This definition differs from the definition T used in the literature, which is defined in the column main order T. (T).wLs We can summarize matrix vector multiplications using the vector operator T (Lt + 1)."}, {"heading": "3.2. Rewriting terms with vec operator", "text": "In this part, we have rewritten the L2 terms in the objective function, in which we have rewritten the L2 terms in the L2 terms in the L2 terms (MDTL2) and L2 terms (MDTL2 terms) (L2 terms) (L2 terms) (L2 terms) (L2 terms) (L2 terms) (L2 terms) (L2 terms) (L2 terms) (L2 terms) (L2 terms) (L2 terms) (L2 terms) (L2 terms) (L2 terms) (L2 terms) (L2), (2), (2) (2), (2), (2), (2), (2), (2), (2), (2), (L2), (2), (2), (L2), (2), (2), (2), (2), (L2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2)."}, {"heading": "3.3. Primal QP problem", "text": "In this subsection we write the problem in the form of a canonical QP problem (Lt + 1) (Lt + 1). we write the problem in the form of a canonical QP problem (Lt + 1) (Lt + 1). we write the problem (Lt + 1). we define two matrices V (Lt + 1). we define two matrices V (Lt + 1). we define two matrices V (Lt + 1)."}, {"heading": "4. Dual problem", "text": "In this section we deduce the dual of the problem."}, {"heading": "4.1. Lagrangian", "text": "Lemma 5 (Lagrangian). \u2212 The Lagrangian of the problem (51) refers to L = q = q = 1 2 aTY \u03a6TV \u2212 1\u03a6Y a + (1T \u2212 p \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v = 1 m = 1 x s. (70) proof. The Lagrangian of the problem (51) results from L = 1 2 wTVw \u2212 qTw + 1 s + 1 s + 1 s + cT \u2212 k \u2212 1 m = 1 x x x x km \u2212 k = 1 m \u00b2 m = 1 x km \u2212 k = 1 x km \u2212 V \u2212 T \u2212 0 kmw + bk \u2212 k \u2212 km), (71) where akm \u00b2 m \u00b2 m \u00b2 and \u00b5km \u00b2 a = 0 x \u00b2 a = Lagrange multipliers. To simplify the derivative, we convert it to the vector formL = 1 wTVM \u2212 V, 2 wTVw \u2212 vTw + 1 s, 2 s \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v \u2212 v."}, {"heading": "4.2. Lagrangian with a compact form", "text": "To remove the large matrix V, we use the structure of V and write terms around, the V (\u03c6TV) (1x T) (1x T) (1x T) (1x T) (1x T) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x) (4x)"}, {"heading": "5. Retrieving the primal solution", "text": "After solving the double problem with a QP solver, we have to solve the double solution a = x = x (A = 1x) (A = 1x) (A = 1x) (A = 1x) (A = 1x) (A = 1x) (A = 1x) (A = 1x) (A = 1x) (A = 1x) (A = 1x) (A = 1x) (A = 1x) (A = 1x) (A = 1x) (A = 1x) (A = 1x) (A = 1x) (A = 1x) (A = 1x) (A = 1x) (A = 1x) (A = 1x) (A = 1x) (A = 1x) (A = 1x) (A = 1x) (A = 1x) (A = 1x) (A = 1x) (A = 1x) (A = 1x) (A = 1x) (A = 1x) (A = 1x) (A = 1x) (A = 1x) (A = 1x) (A = 1x)."}, {"heading": "6. Kernelization", "text": "In this section we derive the core version of the dual formula. The resulting transformation is further rewritten asW = (XsS + 1 \u2212 1c2f Xt (S \u2212 1M + 1cf (Xt) TXt) \u2212 1 (Xt) T) (172) = (XsS + 1 (XsS + 1 \u2212 1c2f Xt (S \u2212 1M + 1 cf (Xt) TXt) T) (173) = (XsS + 1 (XsS) T) (1 cf (Xt) T \u2212 1 c2f (Xt) TXt (Xt) TXt) (173) = (XsS + 1) T) (1 cf IM \u2212 1 c2f Kt (S \u2212 1 c2f Kt)."}, {"heading": "7. Results and discussions", "text": "In this section, we present two sets of experimental results: our first experiment uses a standard data set of monitored domain matching to compare our proposed MMDTL2 with MMDT; our second experiment uses data sets consisting of two NBI endoscopic devices to understand how our proposed method behaves in the face of the different number of target domain training samples."}, {"heading": "7.1. Office-Caltech dataset", "text": "In this experiment, we compare our proposed MMDTL2 methodology with MMDT using the Office Caltech dataset, a standard domain adaptation dataset [20, 21, 25, 26]. Therefore, in this dataset there are four domains, i.e. Amazon, Webcam, Digital SLR (dslr) and Caltech, each of which has 10 categories. For each domain pair, each sample is represented by an 800-dimensional descriptor. A training set has eight source training samples per category (80 samples in total except Amazon domain, which has 200 source training samples (20 samples per category) and three target training samples per category (30 samples in total). In addition, 20 training / test sets are given by random selection of samples from each domain and category (80 samples in total except Amazon domain, which has 200 source training samples (20 samples per category)) and three target training samples per category (30 samples in total)."}, {"heading": "7.2. NBI endoscopic image dataset", "text": "In fact, it is the case that most of them are able to survive themselves if they do not abide by the rules they have imposed on themselves. (...) Most of them are able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are not able to survive themselves. (...)"}, {"heading": "7.3. NBI endoscopic image dataset with high-dimension features", "text": "Figure 4 shows the performance results of the given methods as in Figure 3 with the same training and evaluation protocols. The difference here is in the amount of features used; more precisely, we are using the features of conv3 with 64,896 dimensions instead of fc6. We have shown that conv3 features may work better for NBI patch classification problems than fc6 features [32]; however, the transformation matrix W for the conv3 features could be very large without our efficient dual formulation. The ability to deal with such large feature dimensions is the main advantage of our proposed method. Figure 4 shows that the source SVM is best when some target samples are available, just as in Figure 3. Moreover, our proposed MMDTL2 with a polynomial core in the right half of the diagram will be better, and the differences between source and target SVM are much more significant than in Figure 3."}, {"heading": "8. Conclusions", "text": "In this paper, we proposed MMDT with L2 constraints, i.e. MMDTL2, deriving the dual formulation with significantly lower computational costs compared to the na\u00efve QP problem. Furthermore, we demonstrated the kerelization of our method. Experimental results with NBI datasets from two different endoscopic devices showed that our proposed MMDTL2 classification with linear and polynomial cores performed better than the specified baselines (i.e. source and target SVMs). Our future work includes the use of other loss functions for problem formulation. We observed that the one-on-rest multiclase classification by SVMs was a performance bottleneck of MMDTL2 in our experiments using the Office Caltech dataset. In 10 categories, we had 10 SVMs, each of which classified target samples with 80-90% accuracy as 10 separate and independent binary classifiers."}, {"heading": "Acknowledgment", "text": "Part of this work was supported by the grant for scientific research (B) JSPS KAKENHI, grant numbers 26280015 and 14J00223 and respectively with a grant from the Chugoku Industrial Innovation Center."}], "references": [{"title": "High-magnification colonoscopy (with videos)", "author": ["S. Tanaka", "T. Kaltenbach", "K. Chayama", "R. Soetikno"], "venue": "Gastrointest Endosc 64 (4) ", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2006}, {"title": "K", "author": ["H. Kanao", "S. Tanaka", "S. Oka", "M. Hirata", "S. Yoshida"], "venue": "Chayama, Narrowband imaging magnification predicts the histology and invasion depth of colorectal tumors., Gastrointest Endosc 69 (3 Pt 2) ", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2009}, {"title": "Characterization of colorectal tumors using narrow-band imaging magnification: combined diagnosis with both pit pattern and microvessel features", "author": ["S. Oba", "S. Tanaka", "S. Oka", "H. Kanao", "S. Yoshida", "F. Shimamoto", "K. Chayama"], "venue": "Scand J Gastroenterol 45 (9) ", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2010}, {"title": "Classification of endoscopic images using delaunay triangulation-based edge features", "author": ["M. H\u00e4fner", "A. Gangl", "M. Liedlgruber", "A. Uhl", "A. V\u00e9csei", "F. Wrba"], "venue": "in: A. Campilho, M. Kamel (Eds.), Image Analysis and Recognition, Vol. 6112 of Lecture Notes in Computer Science, Springer Berlin Heidelberg", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2010}, {"title": "Endoscopic image classification using edge-based features", "author": ["M. H\u00e4fner", "A. Gangl", "M. Liedlgruber", "A. Uhl", "A. Vecsei", "F. Wrba"], "venue": "in: Pattern Recognition (ICPR), 2010 20th International Conference on", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2010}, {"title": "Predicting the histology of colorectal lesions in a probabilistic framework", "author": ["R. Kwitt", "A. Uhl", "M. H\u00e4fner", "A. Gangl", "F. Wrba", "A. V\u00e9csei"], "venue": "in: Computer Vision and Pattern Recognition Workshops (CVPRW), 2010 IEEE Computer Society Conference on", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2010}, {"title": "A comparison of blood vessel features and local binary patterns for colorectal polyp classification", "author": ["S. Gross", "T. Stehle", "A. Behrens", "R. Auer", "T. Aach", "R. Winograd", "C. Trautwein", "J. Tischendorf"], "venue": "in: Proc. SPIE, Vol. 7260", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2009}, {"title": "Classification of colon polyps in nbi endoscopy using vascularization features", "author": ["T. Stehle", "R. Auer", "S. Gross", "A. Behrens", "J. Wulff", "T. Aach", "R. Winograd", "C. Trautwein", "J. Tischendorf"], "venue": "in: Proc. SPIE, Vol. 7260", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2009}, {"title": "Computer-aided classification of colorectal polyps based on vascular patterns: a pilot study", "author": ["J.J.W. Tischendorf", "S. Gross", "R. Winograd", "H. Hecker", "R. Auer", "A. Behrens", "C. Trautwein", "T. Aach", "T. Stehle"], "venue": "Endoscopy 42 (3) ", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2010}, {"title": "Computer-aided colorectal tumor classification in NBI endoscopy using local features", "author": ["T. Tamaki", "J. Yoshimuta", "M. Kawakami", "B. Raytchev", "K. Kaneda", "S. Yoshida", "Y. Takemura", "K. Onji", "R. Miyaki", "S. Tanaka"], "venue": "Medical Image Analysis 17 (1) ", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2013}, {"title": "Transfer learning for 26  Bag-of-Visual words approach to NBI endoscopic image classification", "author": ["S. Sonoyama", "T. Hirakawa", "T. Tamaki", "T. Kurita", "B. Raytchev", "K. Kaneda", "T. Koide", "S. Yoshida", "Y. Kominami", "S. Tanaka"], "venue": "in: 2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), IEEE", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2015}, {"title": "A survey on transfer learning", "author": ["S.J. Pan", "Q. Yang"], "venue": "Knowledge and Data Engineering, IEEE Transactions on 22 (10) ", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2010}, {"title": "Self-taught learning: transfer learning from unlabeled data", "author": ["R. Raina", "A. Battle", "H. Lee", "B. Packer", "A.Y. Ng"], "venue": "in: Proceedings of the 24th international conference on Machine learning, ACM", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2007}, {"title": "Boosting for transfer learning", "author": ["W. Dai", "Q. Yang", "G.-R. Xue", "Y. Yu"], "venue": "in: Proceedings of the 24th international conference on Machine learning, ACM", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2007}, {"title": "Efficient learning of domain-invariant image representations", "author": ["J. Hoffman", "E. Rodner", "T. Darrell", "J. Donahue", "K. Saenko"], "venue": "Proceedings of the 1st International Conference on Learning Representations ", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2013}, {"title": "Asymmetric and category invariant feature transformations for domain adaptation", "author": ["J. Hoffman", "E. Rodner", "J. Donahue", "B. Kulis", "K. Saenko"], "venue": "International Journal of Computer Vision 109 (1-2) ", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2014}, {"title": "Transfer Learning for Endoscopic Image Classification", "author": ["S. Sonoyama", "T. Tamaki", "T. Hirakawa", "B. Raytchev", "K. Kaneda", "T. Koide", "S. Yoshida", "H. Mieno", "S. Tanaka"], "venue": "in: The Korea-Japan joint workshop on Frontiers of Computer Vision ", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2016}, {"title": "K", "author": ["E. Rodner", "J. Hoffman", "J. Donahue", "T. Darrell"], "venue": "Saenko, Towards Adapting ImageNet to Reality: Scalable Domain Adaptation with Implicit Lowrank Transformations ", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2013}, {"title": "Matrix Algebra From a Statistician\u2019s Perspective", "author": ["D.A. Harville"], "venue": "Springer- Verlag, New York", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1997}, {"title": "Geodesic flow kernel for unsupervised domain adaptation", "author": ["B. Gong", "Y. Shi", "F. Sha", "K. Grauman"], "venue": "in: Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on, IEEE", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2012}, {"title": "Adapting Visual Category Models to New Domains", "author": ["K. Saenko", "B. Kulis", "M. Fritz", "T. Darrell"], "venue": "Springer Berlin Heidelberg, Berlin, Heidelberg", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2010}, {"title": "B", "author": ["J. Hoffman", "E. Rodner", "J. Donahue", "K. Saenko", "T. Darrell"], "venue": "Kulis, Domain Adaptation Project ", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2013}, {"title": "SVM-MRF segmentation of colorectal NBI endoscopic images", "author": ["T. Hirakawa", "T. Tamaki", "B. Raytchev", "K. Kaneda", "T. Koide", "Y. Kominami", "S. Yoshida", "S. Tanaka"], "venue": "in: 2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society, Vol. 2014, IEEE", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2014}, {"title": "Trade-off between speed and performance for colorectal endoscopic NBI image classification", "author": ["S. Sonoyama", "T. Tamaki", "T. Hirakawa", "B. Raytchev", "K. Kaneda", "T. Koide", "Y. Kominami", "S. Yoshida", "S. Tanaka"], "venue": "in: S. Ourselin, M. A. Styner (Eds.), Proc. SPIE, Vol. 9413", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2015}, {"title": "CNN Features Off-the-Shelf: An Astounding Baseline for Recognition", "author": ["A. Sharif Razavian", "H. Azizpour", "J. Sullivan", "S. Carlsson"], "venue": "in: The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2014}, {"title": "Computer-Aided Colorectal Tumor Classification in NBI Endoscopy Using CNN Features", "author": ["T. Tamaki", "S. Sonoyama", "T. Hirakawa", "B. Raytchev", "K. Kaneda", "T. Koide", "S. Yoshida", "H. Mieno", "S. Tanaka"], "venue": "in: The Korea-Japan joint workshop on Frontiers of Computer Vision ", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2016}], "referenceMentions": [{"referenceID": 0, "context": ", colonoscopies) using narrow band imaging (NBI) systems are widely performed to diagnose colorectal cancer [1], which is a major cause of cancer deaths worldwide [2].", "startOffset": 108, "endOffset": 111}, {"referenceID": 1, "context": "During examinations, endoscopists observe and examine a polyp based on its visual appearance, including via NBI magnification findings [3, 4], as shown in Figure 1.", "startOffset": 135, "endOffset": 141}, {"referenceID": 2, "context": "During examinations, endoscopists observe and examine a polyp based on its visual appearance, including via NBI magnification findings [3, 4], as shown in Figure 1.", "startOffset": 135, "endOffset": 141}, {"referenceID": 3, "context": "To support proper diagnosis during examinations, a computer-aided diagnostic system based on the textural appearance of polyps would be helpful; thus, numerous patch-based classification methods for endoscopic images have been proposed [5, 6, 7, 8, 9, 10, 11].", "startOffset": 236, "endOffset": 259}, {"referenceID": 4, "context": "To support proper diagnosis during examinations, a computer-aided diagnostic system based on the textural appearance of polyps would be helpful; thus, numerous patch-based classification methods for endoscopic images have been proposed [5, 6, 7, 8, 9, 10, 11].", "startOffset": 236, "endOffset": 259}, {"referenceID": 5, "context": "To support proper diagnosis during examinations, a computer-aided diagnostic system based on the textural appearance of polyps would be helpful; thus, numerous patch-based classification methods for endoscopic images have been proposed [5, 6, 7, 8, 9, 10, 11].", "startOffset": 236, "endOffset": 259}, {"referenceID": 6, "context": "To support proper diagnosis during examinations, a computer-aided diagnostic system based on the textural appearance of polyps would be helpful; thus, numerous patch-based classification methods for endoscopic images have been proposed [5, 6, 7, 8, 9, 10, 11].", "startOffset": 236, "endOffset": 259}, {"referenceID": 7, "context": "To support proper diagnosis during examinations, a computer-aided diagnostic system based on the textural appearance of polyps would be helpful; thus, numerous patch-based classification methods for endoscopic images have been proposed [5, 6, 7, 8, 9, 10, 11].", "startOffset": 236, "endOffset": 259}, {"referenceID": 8, "context": "To support proper diagnosis during examinations, a computer-aided diagnostic system based on the textural appearance of polyps would be helpful; thus, numerous patch-based classification methods for endoscopic images have been proposed [5, 6, 7, 8, 9, 10, 11].", "startOffset": 236, "endOffset": 259}, {"referenceID": 9, "context": "To support proper diagnosis during examinations, a computer-aided diagnostic system based on the textural appearance of polyps would be helpful; thus, numerous patch-based classification methods for endoscopic images have been proposed [5, 6, 7, 8, 9, 10, 11].", "startOffset": 236, "endOffset": 259}, {"referenceID": 10, "context": "[12] proposed a method based on transfer learning [13, 14, 15, 16] to estimate a transformation matrix between feature vectors of training and test datasets captured by different (i.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[12] proposed a method based on transfer learning [13, 14, 15, 16] to estimate a transformation matrix between feature vectors of training and test datasets captured by different (i.", "startOffset": 50, "endOffset": 66}, {"referenceID": 12, "context": "[12] proposed a method based on transfer learning [13, 14, 15, 16] to estimate a transformation matrix between feature vectors of training and test datasets captured by different (i.", "startOffset": 50, "endOffset": 66}, {"referenceID": 13, "context": "[12] proposed a method based on transfer learning [13, 14, 15, 16] to estimate a transformation matrix between feature vectors of training and test datasets captured by different (i.", "startOffset": 50, "endOffset": 66}, {"referenceID": 14, "context": "[20, 21], called maximum margin domain transfer (MMDT).", "startOffset": 0, "endOffset": 8}, {"referenceID": 15, "context": "[20, 21], called maximum margin domain transfer (MMDT).", "startOffset": 0, "endOffset": 8}, {"referenceID": 1, "context": "Figure 1: NBI magnification findings [3].", "startOffset": 37, "endOffset": 40}, {"referenceID": 15, "context": "Other regularizers were discussed by [21], e.", "startOffset": 37, "endOffset": 41}, {"referenceID": 14, "context": "In [20, 21], the MMDT problem was described but not in a QP form.", "startOffset": 3, "endOffset": 11}, {"referenceID": 15, "context": "In [20, 21], the MMDT problem was described but not in a QP form.", "startOffset": 3, "endOffset": 11}, {"referenceID": 16, "context": "1A conference version of this paper was presented [22].", "startOffset": 50, "endOffset": 54}, {"referenceID": 17, "context": "[23].", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "Problem formulation In this section, we introduce the problems of MMDT [21] and our proposed MMDTL2.", "startOffset": 71, "endOffset": 75}, {"referenceID": 15, "context": "Because this problem is non-convex, an alternating optimization approach was used in [21].", "startOffset": 85, "endOffset": 89}, {"referenceID": 18, "context": "This definition is different from the one used in the literature, which is defined in the column-major order, for example, in [24].", "startOffset": 126, "endOffset": 130}, {"referenceID": 14, "context": "Office-Caltech dataset In this experiment, we compare our proposed MMDTL2 method with MMDT using the Office-Caltech dataset, a standard dataset of domain adaptation [20, 21, 25, 26].", "startOffset": 165, "endOffset": 181}, {"referenceID": 15, "context": "Office-Caltech dataset In this experiment, we compare our proposed MMDTL2 method with MMDT using the Office-Caltech dataset, a standard dataset of domain adaptation [20, 21, 25, 26].", "startOffset": 165, "endOffset": 181}, {"referenceID": 19, "context": "Office-Caltech dataset In this experiment, we compare our proposed MMDTL2 method with MMDT using the Office-Caltech dataset, a standard dataset of domain adaptation [20, 21, 25, 26].", "startOffset": 165, "endOffset": 181}, {"referenceID": 20, "context": "Office-Caltech dataset In this experiment, we compare our proposed MMDTL2 method with MMDT using the Office-Caltech dataset, a standard dataset of domain adaptation [20, 21, 25, 26].", "startOffset": 165, "endOffset": 181}, {"referenceID": 19, "context": "Further, 20 training/test sets are given (and provided by [25, 27]) by randomly selecting samples from each domain and category, which are used to report average performance measures.", "startOffset": 58, "endOffset": 66}, {"referenceID": 21, "context": "Further, 20 training/test sets are given (and provided by [25, 27]) by randomly selecting samples from each domain and category, which are used to report average performance measures.", "startOffset": 58, "endOffset": 66}, {"referenceID": 14, "context": "The second column shows a reproduction of results from [20, 21] using publicly available code [27] with the", "startOffset": 55, "endOffset": 63}, {"referenceID": 15, "context": "The second column shows a reproduction of results from [20, 21] using publicly available code [27] with the", "startOffset": 55, "endOffset": 63}, {"referenceID": 21, "context": "The second column shows a reproduction of results from [20, 21] using publicly available code [27] with the", "startOffset": 94, "endOffset": 98}, {"referenceID": 1, "context": ", source) domain, we used the NBI image dataset consisting of 908 NBI patches collected from endoscopic examinations at Hiroshima University by using OLYMPUS EVIS LUCERA endoscope system [17]; patches were labeled based on NBI magnification findings [3, 4], which categorizes appearances of tumors into types A, B, and C, with type C further sub-classified into C1, C2, and C3 based on microvessel structures (see Figure 1).", "startOffset": 250, "endOffset": 256}, {"referenceID": 2, "context": ", source) domain, we used the NBI image dataset consisting of 908 NBI patches collected from endoscopic examinations at Hiroshima University by using OLYMPUS EVIS LUCERA endoscope system [17]; patches were labeled based on NBI magnification findings [3, 4], which categorizes appearances of tumors into types A, B, and C, with type C further sub-classified into C1, C2, and C3 based on microvessel structures (see Figure 1).", "startOffset": 250, "endOffset": 256}, {"referenceID": 9, "context": "In this study, we used only types A, B, and C3 in accordance with our previous work [11, 28, 12, 29].", "startOffset": 84, "endOffset": 100}, {"referenceID": 22, "context": "In this study, we used only types A, B, and C3 in accordance with our previous work [11, 28, 12, 29].", "startOffset": 84, "endOffset": 100}, {"referenceID": 10, "context": "In this study, we used only types A, B, and C3 in accordance with our previous work [11, 28, 12, 29].", "startOffset": 84, "endOffset": 100}, {"referenceID": 23, "context": "In this study, we used only types A, B, and C3 in accordance with our previous work [11, 28, 12, 29].", "startOffset": 84, "endOffset": 100}, {"referenceID": 24, "context": "From these two domains, we computed convolutional neural network (CNN) features extracted using CaffeNet [30]; more specifically, this is the fc6 feature of 4096 dimensions, which is known to work well for many tasks [31].", "startOffset": 217, "endOffset": 221}, {"referenceID": 21, "context": "MMDT results were obtained using the code provided by [27], just as in our first experiment.", "startOffset": 54, "endOffset": 58}, {"referenceID": 25, "context": "We have shown that conv3 features are expected to work better than fc6 features for NBI patch classification problems [32]; however, transformation matrix W for the conv3 features could be very large without our efficient dual formulation.", "startOffset": 118, "endOffset": 122}], "year": 2016, "abstractText": "This paper proposes a method for domain adaptation that extends the maximum margin domain transfer (MMDT) proposed by Hoffman et al., by introducing L2 distance constraints between samples of different domains; thus, our method is denoted as MMDTL2. Motivated by the differences between the images taken by narrow band imaging (NBI) endoscopic devices, we utilize different NBI devices as different domains and estimate the transformations between samples of different domains, i.e., image samples taken by different NBI endoscope systems. We first formulate the problem in the primal form, and then derive the dual form with much lesser computational costs as compared to the naive approach. From our experimental results using NBI image datasets from two different NBI endoscopic devices, we find that MMDTL2 is more stable than MMDT and better than support vector machines without adaptation.", "creator": "LaTeX with hyperref package"}}}