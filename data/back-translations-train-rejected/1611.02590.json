{"id": "1611.02590", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Nov-2016", "title": "Veracity Computing from Lexical Cues and Perceived Certainty Trends", "abstract": "We present a data-driven method for determining the veracity of a set of rumorous claims on social media data. Tweets from different sources pertaining to a rumor are processed on three levels: first, factuality values are assigned to each tweet based on four textual cue categories relevant for our journalism use case; these amalgamate speaker support in terms of polarity and commitment in terms of certainty and speculation. Next, the proportions of these lexical cues are utilized as predictors for tweet certainty in a generalized linear regression model. Subsequently, lexical cue proportions, predicted certainty, as well as their time course characteristics are used to compute veracity for each rumor in terms of the identity of the rumor-resolving tweet and its binary resolution value judgment. The system operates without access to extralinguistic resources. Evaluated on the data portion for which hand-labeled examples were available, it achieves .74 F1-score on identifying rumor resolving tweets and .76 F1-score on predicting if a rumor is resolved as true or false.", "histories": [["v1", "Tue, 8 Nov 2016 16:21:16 GMT  (357kb,D)", "http://arxiv.org/abs/1611.02590v1", "to appear in: Proc. 2nd Workshop on Noisy User-generated Text, Osaka, Japan, 2016"], ["v2", "Fri, 11 Nov 2016 01:19:06 GMT  (354kb,D)", "http://arxiv.org/abs/1611.02590v2", "to appear in: Proc. 2nd Workshop on Noisy User-generated Text, Osaka, Japan, 2016"]], "COMMENTS": "to appear in: Proc. 2nd Workshop on Noisy User-generated Text, Osaka, Japan, 2016", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["uwe d reichel", "piroska lendvai"], "accepted": false, "id": "1611.02590"}, "pdf": {"name": "1611.02590.pdf", "metadata": {"source": "CRF", "title": "Veracity Computing from Lexical Cues and Perceived Certainty Trends", "authors": ["Uwe D. Reichel", "Piroska Lendvai"], "emails": ["uwe.reichel@nytud.mta.hu", "piroska.r@gmail.com"], "sections": [{"heading": "1 Background and Task Definition", "text": "A growing number of studies examine how rumors and memes spread and change on social media platforms (Leskovec et al., 2009; Qazvinian et al., 2011; Procter et al., 2013); given the amount of user-generated content, the need for automatic fact checking and verification procedures is obvious. To determine the credibility of sources and assertions, systems have recently been created to evaluate the credibility of sources and assertions (Berti-E-quille and Borge-Holthoefer, 2015). Emerging initiatives advocate the recognition of verification in social media as a shared task, calling for targeted applications and looking for benchmark data. To address this challenge, we implemented a system that attempts to achieve three goals: (i) a judgment indicating how a factual claim is based on textual cues and predicted speaker security (ii) to identify which tweet will be resolved by those rumors, and discuss the series of rumors in an ii)."}, {"heading": "2 Data", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Corpus", "text": "We were working on a subset of a freely available, commented social media corpus2 collected on the Germanwings twitter platform. Hill / pedia.org / 2014 contains tweets in English referring to three crisis events: the Ottawa rampage, the Sydney rampage, the Germanwings crash, etc. Each event is commented on in relation to several rumors7 - plausible, but at the time of the appearance of unconfirmed statements, e.g. in the Sydney Siege collection, two assertions are made: \"There is a hostage situation in a Sydney cafe\" and \"The police (authorities) have been in contact with the hostage taker.\" For each allegation, there is a series of tweets discussing or mentioning this claim, and a single one of these tweets has been manually identified and judged authoritative to resolve the claim as either true or false. A resolving tweet for the claim \"The Germanwings airplane has experienced this claim: Germankingshfigshare.com / 650 PH9dat468E / EMpedi4articles / EMour articles /"}, {"heading": "2.2 Certainty annotations", "text": "Certain Notes were given in the Corpus in relation to the Position Value Notes (Zubiaga et al., 2015). Certain Notes represent the Speaker's attitude toward a target: In this Corpus, the target is a rumor claim, and each tweet was manually marked as either supportive, denying, questioning, or commenting. Tweets that received comments supporting or dismissing the viewpoint were also given a Certificate Value. This value was used to express Twitter confidence in their posture, as perceived by independent crowdsourced commenters. Each tweet was commented on by 5-7 crowdsourced commenters, unsafe, safe, safe, and sub-specified with respect to the four labels. We continued to process these comments as follows. To deal with common annotation errors, we did not simply choose the majority-selected certainty label for our subsequent tweets, but the aggregates for each of the comments below."}, {"heading": "2.3 Factuality cues: from seeds to extended lists", "text": "In fact, it is a way in which people are able to determine for themselves how they want to behave."}, {"heading": "3 Certainty prediction", "text": "The researchers looked at the relationship between keywords and safety values that were assigned to tweets via regression analyses, and found that those words were associated with a higher risk of depression, anxiety, depression, depression, depression, depression, anxiety, depression, depression, anxiety, depression, depression, anxiety, depression, depression, anxiety, depression, depression, anxiety, depression, depression, depression, anxiety, depression, depression, depression, anxiety, depression, depression, anxiety, depression, depression, depression, depression, anxiety, depression, depression, depression, depression, depression, depression, depression, anxiety, depression, depression, depression, depression, depression, depression, anxiety, depression, depression, depression, depression, depression, depression, depression, depression, depression, depression, depression, depression, depression, depression, depression, depression, depression, depression, depression, depression, depression, depression, depression, depression, depression, depression, depression, depression, depression, depression, depression, depression, depression, and depression."}, {"heading": "4 Certainty trend quantification", "text": "In our approach, we address time rate characteristics more explicitly than previous studies (Kwon and Cha, 2014; Ma et al., 2015). That is, instead of bundling characteristic vectors at different timestamps into a common vector, we capture the time rate characteristics using parameters of the regression lines that have been adjusted by the characteristic values over time. These regression lines are used for trend discontinuity analyses as described in detail below. On the basis of this analysis, we expand the set of variables in the following ways: for all four keywords and the derived safety score, we calculated four discontinuity characteristics, each resulting in five characteristics for each keyword and certainty. These variables are introduced and represented in the following paragraphs: Tweet-intrinsic characteristics (lexical keywords KCR, RCR, BCR, TweDR, CRT, CRT predictive pairs)."}, {"heading": "5 Predicting the resolving tweet and its resolution value", "text": "As illustrated in Section 4, the differentiation of tweets in rumor resolution and non-resolution and their resolution values affects several of the quantity, certainty and discontinuity variables studied. Therefore, our next step was to use these variables to predict: \u2022 for each tweet, whether it resolves a rumor or or not (RES), \u2022 for each resolving tweet, whether its resolution value is true or false (VAL).Method For both binary classification tasks, we added tweet density to the feature vector for each tweet, i.e. the mean number of tweets per minute in a 10-minute time window centered on the tweet. As for the above features, the tweet density also applies to its four discontinuity measures (cf. Section 4). We then divided the characteristics into two groups: \u2022 CueSet: consisting of all lexical knowledge, beliefs, their discontinuity, their discontinuity reports, their discontinuity derived proportions."}, {"heading": "6 Discussion and conclusion", "text": "Relation between lexical indicators and certainty As described in Section 3, we have established a link between lexical indicators of different levels of certainty and the certainty associated with tweets by regression analysis. The zero inflation problem, as well as the reported low correlations between individual indicators and certainty values, suggest that factuality values cannot be fully expressed by quantity indicators in isolation, but require a more complex model. Applying GLMs to bundle and thus strengthen these weak relationships was a first step in this direction. Certainty is a phenomenon at the discourse level that can represent lexical means to a certain extent, but not completely. In future work, we will address the representation of certainty indicators in connection with higher linguistic levels. Effect of odor resolution on quantity indicators and certainty Variability As shown in Section 4, for several quantity indicators studied, significant differences in relation to significant resolution are observed."}], "references": [{"title": "The control of the false discovery rate in multiple testing under dependency", "author": ["Benjamini", "Yekutieli2001] Yoav Benjamini", "Daniel Yekutieli"], "venue": "Annals of Statistics,", "citeRegEx": "Benjamini et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Benjamini et al\\.", "year": 2001}, {"title": "Veracity of data: From truth discovery computation algorithms to models of misinformation dynamics", "author": ["Berti-\u00c9quille", "Javier Borge-Holthoefer"], "venue": "Synthesis Lectures on Data Management,", "citeRegEx": "Berti.\u00c9quille et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Berti.\u00c9quille et al\\.", "year": 2015}, {"title": "Did it happen? the pragmatic complexity of veridicality assessment", "author": ["Christopher D Manning", "Christopher Potts"], "venue": null, "citeRegEx": "Marneffe et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Marneffe et al\\.", "year": 2012}, {"title": "The CoNLL-2010 Shared Task: Learning to detect hedges and their scope in natural language text", "author": ["Veronika Vincze", "Gy\u00f6rgy M\u00f3ra", "J\u00e1nos Csirik", "Gy\u00f6rgy Szarvas"], "venue": "In Proceedings of the 14th Conference on Natural Language Learning", "citeRegEx": "Farkas et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Farkas et al\\.", "year": 2010}, {"title": "Investigating rumor propagation with TwitterTrails", "author": ["Finn et al.2014] Samantha Finn", "Panagiotis Takis Metaxas", "Eni Mustafaraj"], "venue": "arXiv preprint arXiv:1411.3550", "citeRegEx": "Finn et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Finn et al\\.", "year": 2014}, {"title": "A short introduction to boosting", "author": ["Freund", "Schapire1999] Yoav Freund", "Robert E. Schapire"], "venue": "J. Japanese Society for Artificial Intelligence,", "citeRegEx": "Freund et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Freund et al\\.", "year": 1999}, {"title": "A compositional interpretation of biomedical event factuality", "author": ["Graciela Rosemblat", "Michael J Cairelli", "Thomas C Rindflesch"], "venue": "ExProM", "citeRegEx": "Kilicoglu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kilicoglu et al\\.", "year": 2015}, {"title": "Modeling bursty temporal pattern of rumors", "author": ["Kwon", "Cha2014] Sejeong Kwon", "Meeyoung Cha"], "venue": "In Proc. ICWSM,", "citeRegEx": "Kwon et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kwon et al\\.", "year": 2014}, {"title": "Factuality drift assessment by lexical markers in resolved rumors", "author": ["Uwe D Reichel", "Thierry Declerck"], "venue": "In Joint Proceedings of the Posters and Demos Track of the 12th International Conference on Semantic Systems (SEMANTiCS 2016) and the 1st International Workshop on Semantic Change & Evolving Semantics,", "citeRegEx": "Lendvai et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Lendvai et al\\.", "year": 2016}, {"title": "Meme-tracking and the dynamics of the news cycle", "author": ["Lars Backstrom", "Jon Kleinberg"], "venue": "In Proc. of KDD-09", "citeRegEx": "Leskovec et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Leskovec et al\\.", "year": 2009}, {"title": "2016. Hawkes Processes for Continuous Time Sequence Classification: An Application to Rumour Stance Classification in Twitter", "author": ["P.K. Srijith", "Duy Vu", "Kalina Bontcheva", "Arkaitz Zubiaga", "Trevor Cohn"], "venue": "Proceedings of ACL-16", "citeRegEx": "Lukasik et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Lukasik et al\\.", "year": 2016}, {"title": "Detect rumors using time series of social context information on microblogging websites", "author": ["Ma et al.2015] Jing Ma", "Wei Gao", "Zhongyu Wei", "Yueming Lu", "Kam-Fai Wong"], "venue": "In Proceedings of the 24th ACM International on Conference on Information and Knowledge Management,", "citeRegEx": "Ma et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ma et al\\.", "year": 2015}, {"title": "SEM 2012 shared task: Resolving the scope and focus of negation", "author": ["Morante", "Blanco2012] Roser Morante", "Eduardo Blanco"], "venue": "In Proceedings of the First Joint Conference on Lexical and Computational Semantics", "citeRegEx": "Morante et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Morante et al\\.", "year": 2012}, {"title": "Reading the riots on Twitter: methodological innovation for the analysis of big data", "author": ["Procter et al.2013] Rob Procter", "Farida Vis", "Alex Voss"], "venue": "International Journal of Social Research Methodology,", "citeRegEx": "Procter et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Procter et al\\.", "year": 2013}, {"title": "Rumor has it: Identifying misinformation in microblogs", "author": ["Emily Rosengren", "Dragomir R. Radev", "Qiaozhu Mei"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Qazvinian et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Qazvinian et al\\.", "year": 2011}, {"title": "Comparing parameterizations of pitch register and its discontinuities at prosodic boundaries for Hungarian", "author": ["Reichel", "M\u00e1dy2014] Uwe D. Reichel", "Katalin M\u00e1dy"], "venue": "In Proc. Interspeech", "citeRegEx": "Reichel et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Reichel et al\\.", "year": 2014}, {"title": "Factbank: A corpus annotated with event factuality", "author": ["Saur\u0131", "Pustejovsky2009] Roser Saur\u0131", "James Pustejovsky"], "venue": "Language Resources and Evaluation,", "citeRegEx": "Saur\u0131\u0301 et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Saur\u0131\u0301 et al\\.", "year": 2009}, {"title": "Are you sure that this happened? Assessing the factuality degree of events in text", "author": ["Saur\u0131", "Pustejovsky2012] Roser Saur\u0131", "James Pustejovsky"], "venue": null, "citeRegEx": "Saur\u0131\u0301 et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Saur\u0131\u0301 et al\\.", "year": 2012}, {"title": "Modeling factuality judgments in social media text", "author": ["Soni et al.2014] Sandeep Soni", "Tanushree Mitra", "Eric Gilbert", "Jacob Eisenstein"], "venue": "Proc. of ACL", "citeRegEx": "Soni et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Soni et al\\.", "year": 2014}, {"title": "Cross-genre and cross-domain detection of semantic uncertainty", "author": ["Veronika Vincze", "Rich\u00e1rd Farkas", "Gy\u00f6rgy M\u00f3ra", "Iryna Gurevych"], "venue": null, "citeRegEx": "Szarvas et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Szarvas et al\\.", "year": 2012}, {"title": "Building a crisis management term resource for social media: The case of floods and protests", "author": ["Andrea Varga", "Dogan Biyikli"], "venue": "In LREC,", "citeRegEx": "Temnikova et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Temnikova et al\\.", "year": 2014}, {"title": "Factuality detection on the cheap: Inferring factuality for increased precision in detecting negated events", "author": ["Velldal", "Read2012] Erik Velldal", "Jonathon Read"], "venue": "In Proceedings of the ACL-2012 Workshop on ExtraPropositional Aspects of Meaning in Computational Linguistics", "citeRegEx": "Velldal et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Velldal et al\\.", "year": 2012}, {"title": "An Empirical Study on Uncertainty Identification in Social Media Context", "author": ["Wei et al.2013] Zhongyu Wei", "Junwen Chen", "Wei Gao", "Binyang Li", "Lanjun Zhou", "Yulan He", "Kam-fai Wong"], "venue": "Proceedings of ACL", "citeRegEx": "Wei et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Wei et al\\.", "year": 2013}, {"title": "Towards Detecting Rumours in Social Media", "author": ["Maria Liakata", "Rob Procter", "Kalina Bontcheva", "Peter Tolmie"], "venue": null, "citeRegEx": "Zubiaga et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Zubiaga et al\\.", "year": 2015}, {"title": "Analysing how people orient to and spread rumours in social media by looking at conversational threads", "author": ["Maria Liakata", "Rob Procter", "Geraldine Wong Sak Hoi", "Peter Tolmie"], "venue": "PLoS ONE,", "citeRegEx": "Zubiaga et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Zubiaga et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 9, "context": "A growing amount of studies investigate how rumors and memes spread and change on social media platforms (Leskovec et al., 2009; Qazvinian et al., 2011; Procter et al., 2013); given the amount of usergenerated content, the need for automatic fact checking and claim verification procedures is obvious.", "startOffset": 105, "endOffset": 174}, {"referenceID": 14, "context": "A growing amount of studies investigate how rumors and memes spread and change on social media platforms (Leskovec et al., 2009; Qazvinian et al., 2011; Procter et al., 2013); given the amount of usergenerated content, the need for automatic fact checking and claim verification procedures is obvious.", "startOffset": 105, "endOffset": 174}, {"referenceID": 13, "context": "A growing amount of studies investigate how rumors and memes spread and change on social media platforms (Leskovec et al., 2009; Qazvinian et al., 2011; Procter et al., 2013); given the amount of usergenerated content, the need for automatic fact checking and claim verification procedures is obvious.", "startOffset": 105, "endOffset": 174}, {"referenceID": 3, "context": "Benchmark corpora with annotations emerged (Saur\u0131\u0301 and Pustejovsky, 2009; Farkas et al., 2010), and systems have been built (Saur\u0131\u0301 and Pustejovsky, 2012; de Marneffe et al.", "startOffset": 43, "endOffset": 94}, {"referenceID": 19, "context": "(Szarvas et al., 2012) propose a method for porting uncertainty detection across genres and domains.", "startOffset": 0, "endOffset": 22}, {"referenceID": 6, "context": "(Kilicoglu et al., 2015) present a full-fledged, compositional approach to factuality", "startOffset": 0, "endOffset": 24}, {"referenceID": 18, "context": "(Soni et al., 2014) focus on factuality framing in social media data in quoted claims with a small set of cues, whereas (Finn et al.", "startOffset": 0, "endOffset": 19}, {"referenceID": 4, "context": ", 2014) focus on factuality framing in social media data in quoted claims with a small set of cues, whereas (Finn et al., 2014) implement keyword-based negation detection without providing quantitative evaluation.", "startOffset": 108, "endOffset": 127}, {"referenceID": 20, "context": "Previous studies that investigated temporal patterns of linguistic cues tied to claims emerging in real-world events focus on keywords related to sentiment, named entities and domain terms (Temnikova et al., 2014), but not factuality-conveying cues.", "startOffset": 189, "endOffset": 213}, {"referenceID": 22, "context": "(Wei et al., 2013) report on the first uncertainty corpus based on tweets, as well as on classification results for uncertain tweets.", "startOffset": 0, "endOffset": 18}, {"referenceID": 11, "context": "(Kwon and Cha, 2014) and (Ma et al., 2015) show for rumor detection that accuracy can be improved by not only looking at message-related properties but also at how these properties change over time.", "startOffset": 25, "endOffset": 42}, {"referenceID": 11, "context": "(Ma et al., 2015) propose a time series structure for features and their deltas as the input for classification.", "startOffset": 0, "endOffset": 17}, {"referenceID": 10, "context": "On the full PHEME dataset, (Lukasik et al., 2016) report on stance detection in the context of temporal dynamics.", "startOffset": 27, "endOffset": 49}, {"referenceID": 24, "context": "On the same dataset, (Zubiaga et al., 2016) analyzed labeled certainty values in dependence of claim resolution, and found that tweeters post messages with statistically similar certainty before and after a claim is resolved, moreover, irrespective of the resolution value.", "startOffset": 21, "endOffset": 43}, {"referenceID": 8, "context": "In (Lendvai et al., 2016) we analyzed and validated a subset of the PHEME data on English and German data that temporal distribution and polarity of lexical markers can be used to represent and quantify changes in factuality framing in a rumor\u2019s lifecycle.", "startOffset": 3, "endOffset": 25}, {"referenceID": 23, "context": "Tweets are organized into threaded conversations and are marked up with respect to seven categories of evidence, among others stance and certainty; for full details on the corpus we refer to (Zubiaga et al., 2015).", "startOffset": 191, "endOffset": 213}, {"referenceID": 23, "context": "Certainty annotations were pre-assigned in the corpus in relation to stance value annotations by (Zubiaga et al., 2015).", "startOffset": 97, "endOffset": 119}, {"referenceID": 23, "context": "(Zubiaga et al., 2015) retained only microposts that passed a retweet count threshold, often by media outlets using well-formed language.", "startOffset": 0, "endOffset": 22}, {"referenceID": 18, "context": "Based on the factuality literature, most prominently (Saur\u0131\u0301 and Pustejovsky, 2009) and (Soni et al., 2014), we devised four factuality groups, each holding up to 40 single-token lexical cues.", "startOffset": 88, "endOffset": 107}, {"referenceID": 11, "context": "Method In our approach we address time course characteristics more explicitly than previous studies (Kwon and Cha, 2014; Ma et al., 2015).", "startOffset": 100, "endOffset": 137}], "year": 2017, "abstractText": "We present a data-driven method for determining the veracity of a set of rumorous claims on social media data. Tweets from different sources pertaining to a rumor are processed on three levels: first, factuality values are assigned to each tweet based on four textual cue categories relevant for our journalism use case; these amalgamate speaker support in terms of polarity and commitment in terms of certainty and speculation. Next, the proportions of these lexical cues are utilized as predictors for tweet certainty in a generalized linear regression model. Subsequently, lexical cue proportions, predicted certainty, as well as their time course characteristics are used to compute veracity for each rumor in terms of the identity of the rumor-resolving tweet and its binary resolution value judgment. The system operates without access to extralinguistic resources. Evaluated on the data portion for which hand-labeled examples were available, it achieves .74 F1-score on identifying rumor resolving tweets and .76 F1-score on predicting if a rumor is resolved as true or false. 1 Background and Task Definition A growing amount of studies investigate how rumors and memes spread and change on social media platforms (Leskovec et al., 2009; Qazvinian et al., 2011; Procter et al., 2013); given the amount of usergenerated content, the need for automatic fact checking and claim verification procedures is obvious. To compute veracity, systems have been created recently for assessing the credibility of sources and claims (Berti-\u00c9quille and Borge-Holthoefer, 2015). Upcoming initiatives endorsed veracity detection in social media content as a shared task, calling for targeted applications and releasing benchmark data1. To tackle this challenge, we implemented a system that seeks to achieve three goals: (i) to compute a judgment indicating how factual a claim is, based on textual cues and predicted speaker certainty, (ii) to identify which tweet is resolving a rumor, in a set of tweets that discuss this rumor, and (iii) to predict the resolution value for the rumor, i.e., whether the rumor is verified as true or false. Veracity computation is based on information from three information layers related to rumorousness: (1) lexical-level factuality cues, (2) temporal patterns, and (3) speaker certainty. The system is purely data-driven and operates without building claim source profiles for the analyzed content. Below we introduce our motivation in the context of previous and related work. The means by which factuality is conveyed are largely but not exclusively encoded on linguistic levels and are tightly related to the notion of certainty. Certainty and other extra-propositional aspects of meaning have prominently been investigated in terms of modality, negation and speculative language phenomena (Morante and Blanco, 2012; Morante and Sporleder, 2012). Benchmark corpora with annotations emerged (Saur\u0131\u0301 and Pustejovsky, 2009; Farkas et al., 2010), and systems have been built (Saur\u0131\u0301 and Pustejovsky, 2012; de Marneffe et al., 2012; Velldal and Read, 2012) to process texts from the genres of literature, newswire, biomedicine and online encyclopedia, typically drawing on lexical and syntactic cues. (Szarvas et al., 2012) propose a method for porting uncertainty detection across genres and domains. (Kilicoglu et al., 2015) present a full-fledged, compositional approach to factuality \u2217UDR is supported by an Alexander von Humboldt Society grant. \u2020PL is supported by the PHEME FP7 project (Grant No. 611233). http://alt.qcri.org/semeval2017/task8/ ar X iv :1 61 1. 02 59 0v 1 [ cs .C L ] 8 N ov 2 01 6 modeling and detection on texts from the domain of biomedicine based on fine-grained typology and dictionary-based classification of extra-propositional phenomena. Several components of the model are motivated by the nature of scientific communication that serves to track hypothesis building processes with tentative results, analogously to journalistic reports about breaking news. (Soni et al., 2014) focus on factuality framing in social media data in quoted claims with a small set of cues, whereas (Finn et al., 2014) implement keyword-based negation detection without providing quantitative evaluation. Next to linguistically expressed uncertainty, extralinguistic information such as the temporal distribution of claims is shown to be an important aspect of veracity computation. Previous studies that investigated temporal patterns of linguistic cues tied to claims emerging in real-world events focus on keywords related to sentiment, named entities and domain terms (Temnikova et al., 2014), but not factuality-conveying cues. (Wei et al., 2013) report on the first uncertainty corpus based on tweets, as well as on classification results for uncertain tweets. Next to platform-specific metadata, they utilized cue phrases in annotated uncertain tweets and an algorithm to detect peaks in the data. (Kwon and Cha, 2014) and (Ma et al., 2015) show for rumor detection that accuracy can be improved by not only looking at message-related properties but also at how these properties change over time. (Ma et al., 2015) propose a time series structure for features and their deltas as the input for classification. On the full PHEME dataset, (Lukasik et al., 2016) report on stance detection in the context of temporal dynamics. They utilize textual information via language modeling but do not evaluate the contribution of textual as opposed to other features. On the same dataset, (Zubiaga et al., 2016) analyzed labeled certainty values in dependence of claim resolution, and found that tweeters post messages with statistically similar certainty before and after a claim is resolved, moreover, irrespective of the resolution value. In (Lendvai et al., 2016) we analyzed and validated a subset of the PHEME data on English and German data that temporal distribution and polarity of lexical markers can be used to represent and quantify changes in factuality framing in a rumor\u2019s lifecycle. Our current study furthers this research by incorporating, evaluating, and visualizing temporally anchored features for claim resolution point as well as claim resolution value prediction in English language rumors discussed in potentially noisy, user-generated content. The paper is structured as follows. In Section 2 we introduce the underlying data and certainty annotations, and describe the automatic extension of lexical cues assigned to four levels of factuality. In Section 3 the relation between certainty and each of the factuality levels is assessed, and regression analysis is used for predicting certainty values by cue-type ratios. In Section 4 we quantify trend discontinuities in time series data of lexical cue ratios and predicted certainty scores to describe rumor resolution points. Cue ratios, certainty, as well as their time course characteristics are exploited in Section 5, where we train classifiers to identify claim-resolving tweets within series of tweets spanning a claim\u2019s lifetime, and additionally predict the claim\u2019s resolution value. The findings are discussed in Section 6.", "creator": "LaTeX with hyperref package"}}}