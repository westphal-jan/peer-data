{"id": "1611.02944", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Nov-2016", "title": "Increasing the throughput of machine translation systems using clouds", "abstract": "The manuscript presents an experiment at implementation of a Machine Translation system in a MapReduce model. The empirical evaluation was done using fully implemented translation systems embedded into the MapReduce programming model. Two machine translation paradigms were studied: shallow transfer Rule Based Machine Translation and Statistical Machine Translation.", "histories": [["v1", "Wed, 9 Nov 2016 14:27:03 GMT  (1402kb)", "http://arxiv.org/abs/1611.02944v1", "20 pages, 7 figures"]], "COMMENTS": "20 pages, 7 figures", "reviews": [], "SUBJECTS": "cs.CL cs.DC", "authors": ["jernej vi\\v{c}i\\v{c}", "rej brodnik"], "accepted": false, "id": "1611.02944"}, "pdf": {"name": "1611.02944.pdf", "metadata": {"source": "CRF", "title": "Increasing the throughput of machine translation systems using clouds", "authors": ["Jernej Vi\u010di\u010d", "Andrej Brodnik"], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 161 1.02 944v 1 [cs.C L] 9N ov2 016Increasing the throughput of machine translation systems using CloudsJernej Vic, 2 and Andrej Brodnik1, 31University of Primorska, Andrej Marusic Institute, Slovenia2Research Centre of the Slovenian Academy of Sciences and Arts, The Fran Ramovs, Institute3University of Ljubljana, Faculty of Computer Science and Informatics, SloveniaThe manuscript represents an experiment in implementing a machine translation system into a MapReduce model. Empirical evaluation has been made using usefully implemented translation systems embedded in the MapReduce programming model. Two paradigms of machine translation have been studied: the superficial translation of ruleBased Machine Translation and Statistical Machine Translation.The results show that the MapReduce model can be successfully used to improve the translation system without reducing the importance of the current machine translation system."}, {"heading": "1. INTRODUCTION", "text": "Most research in the field of machine translation focuses on the translation quality of the translation systems observed. The research in this manuscript focuses entirely on the throughput of the translation system and proposes a method to increase the throughput without affecting the quality of the translation. There are a number of cases where the throughput of machine translation is a crucial aspect, such as translating large volumes of text, e.g. translating all texts in Project2 Gutenberg1 or translating huge manuals to enter a new market, etc. Some of these cases can be translated using publicly available services such as Google."}, {"heading": "2. MACHINE TRANSLATION", "text": "Machine translation, as examined in this manuscript, is an unattended process of translating from one natural language to another using computer programs. 4There has been almost no research on the throughput of machine translation, largely due to the fact that most research in the field of machine translation focuses on the quality of machine translation, and the throughput of systems is at least an order of magnitude higher than the throughput of human translators. Some comparative studies have been conducted to investigate the increase in the overall speed of the translation process using machine translation tools compared to the conventional process of human translation [4] and also the impact of the use of computer-assisted translation - CAT tools that combine MT systems with translation memory and human post-processing [5]."}, {"heading": "3. MACHINE TRANSLATION THROUGHPUT", "text": "Definition 1 Translation throughput: T = n t, where n \u2261 number of words in a text; t \u2261 setup time + translation time; Description: T is the measured property of the translation system; n is the number of units of the source text, in our case words; t is the sum of the time it takes to initialize the translation system and the time it takes for the n words to be translated. Definition 2 Increased translation throughput speed: S = Tnew Torig; is the ratio between the new translation throughput and the original (reference) translation throughput. The rating requires a \"sufficiently large\" test that minimizes the start-up effect to a desired minimum. We can rely on this simple metric because both translation paradigms base the translations on fixed parts of the text and both paradigms."}, {"heading": "4. OVERVIEW OF MACHINE TRANSLATION SYSTEMS", "text": "The following sections describe the translation system toolkits used in the experiment. Both toolkits are commonly used as open source toolkits from the respective translation paradigms: \u2022 Shallow-Transfer Rule Based Machine Translation (Shallow Transfer RBMT) [6] paradigm best suited for translating related languages [7], represented by Apertium [8]; \u2022 Statistical Machine Translation (SMT) [9, 10] paradigm based on large quantities of data and mathematical models, represented by Moses [11];"}, {"heading": "4.1. Apertium", "text": "Apertium [8] is an open source machine translation platform originally aimed at related language pairs, but has recently been expanded to deal with more divergent language pairs (such as English-Spanish).The shallow transfer paradigm of the toolkit is best suited for related languages, as the architecture does not provide the resources for in-depth parsing, which can cause problems, especially for the more divergent language pairs. All of these features make Apertium a perfect choice for cost-effective development of a machine translation system for similar languages. The basic architecture of the Apertium system is shown in Figure 1. The systems [8] and [12] follow this design. The numbered rectangles describe translation modules, the output of a previous module is input to the successor: 5. Morphological analyzer searches for the monolingual source morphological dictionary to find all possible lemmatic and lemmatic tags."}, {"heading": "4.2. Moses", "text": "Moses [11] has recently become the most widely used framework for setting up statistical machine translation systems. The main features of the framework are: \u2022 Two types of conductive models (source models) based on phrases of actual parts of text (phrase-based) and trees (tree-based); \u2022 To some extent, it allows for the integration of explicit language knowledge at the word level; \u2022 provides support for integrating tools with ambiguous outputs, such as morphosynthetic analyzers and language parsers; and \u2022 it is supported by large language models. Moses can be run in a server-like mode, where all models are loaded into memory and communication is done via XML: RPC. Figure 2 shows a fundamental variation in server subset-up. Moses is also licensed under LGPL.55 GNU Lesser General Public License (LGPL) 6."}, {"heading": "5. RELATED WORK", "text": "Most of the work has been done in accelerating automatic learning processes in the field of Statistical Machine Translation - SMT. [13] The most widely used machine translation toolkit, Moses [11], has already implemented support for multi-processor cores and, to some extent, for multi-computers. A MapReduce-based large-scale MT architecture has been proposed [14], which focuses on distributed storage for streaming and structured data that could be used. [15] The proposed architecture focuses mainly on the SMT paradigm, while the training phase for SMT based on MapReduce has been proposed by [13]. The translation phase has received less attention in the research community, although there have been some successful attempts, such as [15] the use of GPUs and the focus on the SMT paradigm."}, {"heading": "6. DISTRIBUTED COMPUTING", "text": "In general, distributed systems are used to solve hard and parallel computing problems. In the distributed computer, a problem is divided into many tasks, each of which is solved by one or more computers [20] that communicate with each other through messaging [21]. In order to increase efficiency, it is desirable to minimize the exchange of information between tasks. Main advantages of distributed computing are: \u2022 Users are distributed; \u2022 Information is distributed; \u2022 They can be more reliable if used correctly and \u2022 They can be faster and cheaper, especially compared to supercomputers. The main conceptual problem is the separation of a task and its data: Data is located on one computer while the task is on another. The main technical problems are: \u2022 Computers are susceptible to interference, which increases the number of computers that also increase the likelihood of failure; \u2022 Network connections fall; \u2022 Data transmission is slow (10 Gbit network has 300 micro-second latency [22])."}, {"heading": "6.1. MapReduce and Hadoop", "text": "MapReduce [23] is a programming model for the processing of large data sets and the name of an implementation of the Google model. The model was developed by Google on the basis of the map fold model, which has its roots in functional programming. It simplifies communication and coordination, rescuing crashed computers (shifting load to available nodes), status reporting, debugging and basic optimizations. The basic architecture of a MapReduce setting is illustrated in Figure 3, Shards are basic bits of data, mappers extract information from data fragments and pass the extracted information on to the reducers, who collect or generalize the results. Apache Hadoop [17] is an open source software framework that supports data-intensive distributed applications. It supports the operation of applications on large clusters of raw material hardware. Hadoop is based on Google MapReduce [23] and Google File System (GFS) [24], which is available as a BOoop framework for both data fracking and data delivery."}, {"heading": "7. METHODOLOGY", "text": "The research presented in this manuscript focuses entirely on the throughput of the translation system and proposes a method to increase throughput without affecting translation quality.The throughput of the translation is as in Definition 1.In order to apply machine translation in a MapReduce model, we must first find parallelism in our data and / or algorithms.The parallelism of data results from the fact that sentences are translated independently. The first assumption for cullet length can be a sentence. Finding parallelism in translation algorithms is beyond the scope of this research.The movement of data to the processing nodes takes place in Hadoop, provided by the Hadoop Distributed FileSystem. From this perspective, SMT is understood as a service in a6 Apache 2 license9 system, which is installed on individual nodes in a similar way to any other service. Now the massive question arises how to translate paradigms of data. The data is translated into e.Shard's [Sharache's only translation method for each of the Apsev9] system [was the most common text message translation type used]."}, {"heading": "8. EVALUATION METHODOLOGY AND RESULTS", "text": "The experiment involved the generation of test data, the use of the translation system and the measurement of the time it took for the system to translate the prepared test sentence. Three basic objectives were pursued: \u2022 Eliminating the start-up effect; \u2022 Evaluating the translation throughput of the translation system on a machine; \u2022 Evaluating the translation throughput of the translation system using a MapReducecluster."}, {"heading": "8.1. Test setting", "text": "The test environments were installed on a cluster of commodity machines8 used as the main test bed, and on a faster machine9 used as a reference, using algorithms that are almost independent of input text when it comes to translation throughput only. The same can be attributed to the algorithms used by the Moses system when the caching option is turned off.7 https: / / svn.code.sf.net / p / apertium / svn / trunk / apertium-en-es 8 Pentium (R) Dual-core CPU E5300 @ 2.60GHz, 4GB RAM, Gigabit Ethernet. 9 Intel (R) Core (TM) i7-3930K @ 3.20GHz, 32GB RAM, Gigabit Ethernet.10The operating system on all test machines was Ubuntu 14.04 LTS (Trusty 1.1), the only version that was installed on the fastest server, and version 1.1 the fastest."}, {"heading": "8.2. Test data", "text": "The artificial sentences were constructed from a set of 20 words present in the dictionary and copied the desired number of times. Sentence length was chosen as the approximate upper mean of sentence length in the opus corpus [26] (the exact value is 16.5) and as the upper limit of sentence length in the Google n-gram corpus (the exact value is 10.8) [27]. This data set would be a problematic choice if the quality of the translation was measured or if complex parsing algorithms were included in the translation. Selecting simple translation techniques (apertium) and mathematical models (Moses) allows the use of artificial test data. The only problem that arises from using this simple test data set was the caching option used by Moses to store and benefit from previous translations."}, {"heading": "8.3. Sequential system", "text": "The first experiment involved measuring the throughput of standard installations using two sequential settings, one for each translation toolbox (Apertium and Moses); the translation systems were installed on the same set of machines (one tested 8 and one reference machine9) and the translation throughput was tested using the same test sets; the results of the apertium system with different-sized artificial test data are presented in Table 2; it shows the test data with the results of translating the translation throughput of a single system; the throughput is in words per second (using real-time); a steep increase in throughput with a small number of sentences that can be traced back to a fixed setup time."}, {"heading": "8.4. Distributed system", "text": "Three architectures were implemented in the MapReduce model. Actual translation was done in the mapping phase of the MapReduce model in all three architectures.The first architecture (Apertium Service Architecture) dealt with a simple service to minimize the start-up effect of the translation system.The server services mappers in a FIFO style. Communication is one-sided; the mappers simply deliver the data to the server and the continuation. The presented architecture minimizes the startup effect, but the communication overhead ensures data integrity. The server services mappers in a FIFO style."}, {"heading": "9. DISCUSSION AND FURTHER WORK", "text": "The aim of the experiment was to test whether the MapReduce model is suitable for machine translation tasks, and the most commonly used open source toolbox was selected for each of the two most popular translation system paradigms, RBMT and SMT. Systems were tested in a 16 MapReduce model. It was empirically demonstrated that the MapReduce programming model is suitable for the machine translation task according to the architectural combination of Hadoop and individual MT systems. Throughput for the presented RBMT system was approximately 800% higher using the 16 machines in the test cluster over the single machine (one of the machines in the 17cluster), and the shards for the translation task were 1,000 sentences or more.The increase in throughput for the presented SMT system was approximately 1,200% using the 16 machines in the test cluster over the single machine (one of the machines in the cluster)."}], "references": [{"title": "Proceedings of the 2008 inter- national workshop on Data-aware distributed computing - DADC \u201908", "author": ["M.R. Palankar", "A. Iamnitchi", "M. Ripeanu", "S. Garfinkel"], "venue": "URL http://dl.acm.org/citation. cfm?id=1383519.1383526", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2008}, {"title": "Mart\u0301inez, Ph.D. thesis, Dublin City", "author": ["G. L"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2003}, {"title": "Trombetti, in Conference of the Association for Machine Translation in the Americas (2012), URL http://amta2012.amtaweb.org/AMTA2012Files/ papers/123.pdf", "author": ["M. Federico", "A. Cattelan"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2012}, {"title": "Forcada, in (organized in conjunction with LREC", "author": ["L. M"], "venue": "(Genoa, Italy,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2006}, {"title": "Vi\u010di\u010d (Academic publishing house", "author": ["P. Homola", "V. Kubon"], "venue": "EXIT, Warsaw,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2009}, {"title": "Hadoop: The definitive guide (O\u2019Reilly", "author": ["T. White"], "venue": "Media, Inc.,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2012}, {"title": "Distributed Systems: Principles and Paradigms (2nd Edition", "author": ["A.S. Tanenbaum", "M. van Steen"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2006}, {"title": "Foundations of multithreaded, parallel, and distributed programming (Addison- Wesley", "author": ["G.R. Andrews"], "venue": null, "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2000}], "referenceMentions": [{"referenceID": 0, "context": "This approach would also involve an architecture change [1].", "startOffset": 56, "endOffset": 59}, {"referenceID": 1, "context": "Some comparative research has been done examining the increase on the overall speed of translation process using machine translation tools compared to standard human translation process [4] and also the effect of the using Computer Assisted Translation \u2013 CAT tools that combine MT systems with translation memory and human post-editing process [5].", "startOffset": 186, "endOffset": 189}, {"referenceID": 2, "context": "Some comparative research has been done examining the increase on the overall speed of translation process using machine translation tools compared to standard human translation process [4] and also the effect of the using Computer Assisted Translation \u2013 CAT tools that combine MT systems with translation memory and human post-editing process [5].", "startOffset": 344, "endOffset": 347}, {"referenceID": 3, "context": "\u2022 Shallow-transfer Rule Based Machine Translation (Shallow Transfer RBMT) [6] paradigm that is most suited for translation of related languages [7], represented by Apertium [8];", "startOffset": 74, "endOffset": 77}, {"referenceID": 4, "context": "\u2022 Shallow-transfer Rule Based Machine Translation (Shallow Transfer RBMT) [6] paradigm that is most suited for translation of related languages [7], represented by Apertium [8];", "startOffset": 144, "endOffset": 147}, {"referenceID": 5, "context": "The Apache Hadoop [17] framework transparently provides both reliability and data delivery to applications \u2013 moving data to processors (computers) that do task execution in contrast to systems such as BOINC [18] or HTCondor [19].", "startOffset": 18, "endOffset": 22}, {"referenceID": 6, "context": "In distributed computing, a problem is divided into many tasks, each of which is solved by one or more computers [20] that communicate with each other by message passing [21].", "startOffset": 113, "endOffset": 117}, {"referenceID": 7, "context": "In distributed computing, a problem is divided into many tasks, each of which is solved by one or more computers [20] that communicate with each other by message passing [21].", "startOffset": 170, "endOffset": 174}, {"referenceID": 5, "context": "Apache Hadoop [17] is an open-source software framework that supports data-intensive distributed applications.", "startOffset": 14, "endOffset": 18}], "year": 2016, "abstractText": "The manuscript presents an experiment at implementation of a Machine Translation system in a MapReduce model. The empirical evaluation was done using fully implemented translation systems embedded into the MapReduce programming model. Two machine translation paradigms were studied: shallow transfer Rule Based Machine Translation and Statistical Machine Translation. The results show that the MapReduce model can be successfully used to increase the throughput of a machine translation system. Furthermore this method enhances the throughput of a machine translation system without decreasing the quality of the translation output. Thus, the present manuscript also represents a contribution to the seminal work in natural language processing, specifically Machine Translation. It first points toward the importance of the definition of the metric of throughput of translation system and, second, the applicability of the machine translation task to the MapReduce paradigm.", "creator": "dvips(k) 5.991 Copyright 2011 Radical Eye Software"}}}