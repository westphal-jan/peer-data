{"id": "1611.03057", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Nov-2016", "title": "When silver glitters more than gold: Bootstrapping an Italian part-of-speech tagger for Twitter", "abstract": "We bootstrap a state-of-the-art part-of-speech tagger to tag Italian Twitter data, in the context of the Evalita 2016 PoSTWITA shared task. We show that training the tagger on native Twitter data enriched with little amounts of specifically selected gold data and additional silver-labelled data scraped from Facebook, yields better results than using large amounts of manually annotated data from a mix of genres.", "histories": [["v1", "Wed, 9 Nov 2016 19:39:15 GMT  (176kb,D)", "http://arxiv.org/abs/1611.03057v1", "Proceedings of the 5th Evaluation Campaign of Natural Language Processing and Speech Tools for Italian (EVALITA 2016)"]], "COMMENTS": "Proceedings of the 5th Evaluation Campaign of Natural Language Processing and Speech Tools for Italian (EVALITA 2016)", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["barbara plank", "malvina nissim"], "accepted": false, "id": "1611.03057"}, "pdf": {"name": "1611.03057.pdf", "metadata": {"source": "CRF", "title": "When silver glitters more than gold: Bootstrapping an Italian part-of-speech tagger for Twitter", "authors": ["Barbara Plank", "Malvina Nissim"], "emails": ["b.plank@rug.nl", "m.nissim@rug.nl"], "sections": [{"heading": null, "text": "Italiano. Nell'ambito della campagna di valutazione PoSTWITA di Evalita 2016, addestriamo due modelli che differiscono nel grado di supervisione in phase di training. Il modello addestrato con due cicli di bootstrapping usando post da Facebook, e che quindi impara anche da etichette \"silver,\" ha una performance superiore alla versione supervisionata che usa solo dati annotati manualmente. Discutiamo l'importanza della scelta dei dati di training e development."}, {"heading": "1 Introduction", "text": "The emergence and abundance of social media texts has triggered the urge to develop tools that are able to process language that is often unconventional, both in terms of lexicon and grammar. In fact, models trained on standard newswire data suffer greatly from the use of data from a different linguistic diversity, particularly Twitter (McClosky et al., 2010; Foster et al., 2011; Gimpel et al., 2011; Plank, 2016). As a way to equip microblog processing with efficient tools, two ways of developing Twitter-compliant models have been explored. One option is to transform Twitter language back into what pre-tracted models already know about normalization operations, so that existing tools are more successful on such different data. The other option is to create native models by training them on labeled Twitter data. The downside of the first option is that it is not clear which standard to target in 2016, so that standard language is more subjective? (What is the set of standards?)"}, {"heading": "2 Data selection and bootstrapping", "text": "In fact, it is the case that you are able to play by the rules."}, {"heading": "3 Experiments and Results", "text": "In this section, we describe how we developed the two models of the final template, including all the preliminary decisions. We stress the importance of selecting an adequate development set to identify promising directions."}, {"heading": "3.1 Experimental Setup", "text": "\"We have been involved in the discussion time and again in recent years,\" he said. \"We have been involved in the discussion time and again in recent years.\" \"We have been involved in the discussion time and again in recent years.\" \"We have been involved in the discussion time and again in recent years.\" \"We have been involved in the discussion time and again in recent years.\" \"We have been involved in the discussion time and again.\" \"We have been involved in the discussion time and again.\" \"We have been involved in the discussion.\" \"We have been involved in the discussion.\" \"We have been involved in the discussion.\" \"We have been involved in the discussion.\" \"We have been involved in the discussion.\" \"We have been involved in the discussion.\" \"We have been involved in the discussion.\" \"We have been involved in the discussion.\""}, {"heading": "3.2 Model", "text": "The bilty7 bidirectional long short-term memory model is illustrated in Figure 2. It is a7https: / / github.com / bplank / bilstm-auxcontext bi-LSTM, with word embeddings ~ w. Character embeddings ~ c are taken as input using a hierarchical bi-LSTM sequence bi-LSTM at the lower level (Ballesteros et al., 2015; Plank et al., 2016) The character representation is linked to the (learned) word embeddings ~ w to form the input into the bi-LSTM context at the upper level. We used standard parameters, i.e. 100 character embeddings, word embeddings set to 64, 20 iterations of the training using stochastic gradient pedigree, a single bi-LSTM layer and regulation using Gaussian noise spacing with 2 characters (cdigindid, 64)."}, {"heading": "3.3 Results on test data", "text": "Since SILVERBOOT performs better than GOLDPICK on the basis of development data, we have selected the former for our official submission and the latter for the unofficial, which also allows us to assess the specific contribution of bootstrapping to performance.Table 3 shows the results of official test data for our models and TNT (Brants, 2000).The results show that adding bootstrapping silver data exceeds the model trained on gold data alone. SILVERBOOT's additional training data reduced the OV rate for the test set to 41.2% (compared to 46.9% for the original PoSTWITA training set).Note that the results on the original randomly selected development set were less meaningful for the contribution of the silver data (see Table 4), demonstrating the importance of a carefully selected development set."}, {"heading": "4 What didn\u2019t work", "text": "In fact, most of us are able to play by the rules that they have imposed on themselves, and they are able to play by the rules that they have imposed on themselves, \"he told the German Press Agency in an interview with\" Welt am Sonntag. \""}, {"heading": "5 Conclusions", "text": "The main conclusion we draw from the experiments in this paper is that data selection is important, not only for education, but also for making informed decisions. In fact, it was only after creating a carefully designed internal development set that we received stronger evidence for the contribution of silver data, which is also reflected in the official results. We also observed that selecting fewer but more targeted data is more effective. Thus, TWITA embedding contributes more to performance than generic POLY embedding, which has been trained on much larger amounts of Wikipedia data. Also, it does not help to simply blindly add training data. We have seen that using the entire UD corpus compared to a small amount of selected gold data, both in terms of origin and labels, is not helpful. Finally, and most importantly, we have found that adding small amounts of not-so-distant silver data obtained via bootmapping is likely to have led the best performance of our model to believe that adding the two IME tags is due to the low level of data strapping that we have observed."}], "references": [{"title": "Semisupervised learning for computational linguistics", "author": ["Steven Abney"], "venue": null, "citeRegEx": "Abney.,? \\Q2007\\E", "shortCiteRegEx": "Abney.", "year": 2007}, {"title": "Multilingual projection for parsing truly low-resource languages", "author": ["Agi\u0107 et al.2016] \u017deljko Agi\u0107", "Anders Johannsen", "Barbara Plank", "H\u00e9ctor Mart\u0131\u0301nez Alonso", "Natalie Schluter", "Anders S\u00f8gaard"], "venue": "Transactions of the Association", "citeRegEx": "Agi\u0107 et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Agi\u0107 et al\\.", "year": 2016}, {"title": "Polyglot: Distributed word representations for multilingual NLP", "author": ["Al-Rfou et al.2013] Rami Al-Rfou", "Bryan Perozzi", "Steven Skiena"], "venue": "arXiv preprint arXiv:1307.1662", "citeRegEx": "Al.Rfou et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Al.Rfou et al\\.", "year": 2013}, {"title": "Improved transitionbased parsing by modeling characters instead of words with lstms", "author": ["Chris Dyer", "Noah A. Smith"], "venue": null, "citeRegEx": "Ballesteros et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ballesteros et al\\.", "year": 2015}, {"title": "Sentiment analysis on italian tweets", "author": ["Basile", "Nissim2013] Valerio Basile", "Malvina Nissim"], "venue": "In Proceedings of the 4th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis,", "citeRegEx": "Basile et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Basile et al\\.", "year": 2013}, {"title": "Joint learning of words and meaning representations for opentext semantic parsing", "author": ["Xavier Glorot", "Jason Weston", "Yoshua Bengio"], "venue": "In AISTATS,", "citeRegEx": "Bordes et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Bordes et al\\.", "year": 2012}, {"title": "Tnt: a statistical part-of-speech tagger. In ANLP", "author": ["Thorsten Brants"], "venue": null, "citeRegEx": "Brants.,? \\Q2000\\E", "shortCiteRegEx": "Brants.", "year": 2000}, {"title": "Natural language processing (almost) from scratch", "author": ["Jason Weston", "L\u00e9on Bottou", "Michael Karlen", "Koray Kavukcuoglu", "Pavel Kuksa"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Collobert et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Collobert et al\\.", "year": 2011}, {"title": "What to do about bad language on the internet", "author": ["Jacob Eisenstein"], "venue": "In Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL),", "citeRegEx": "Eisenstein.,? \\Q2013\\E", "shortCiteRegEx": "Eisenstein.", "year": 2013}, {"title": "From news to comments: Resources and benchmarks for parsing the language of Web 2.0", "author": ["Ozlem Cetinoglu", "Joachim Wagner", "Josef Le Roux", "Joakim Nivre", "Deirde Hogan", "Josef van Genabith"], "venue": "In IJCNLP", "citeRegEx": "Foster et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Foster et al\\.", "year": 2011}, {"title": "Part-ofSpeech Tagging for Twitter: Annotation, Features", "author": ["Gimpel et al.2011] Kevin Gimpel", "Nathan Schneider", "Brendan O\u2019Connor", "Dipanjan Das", "Daniel Mills", "Jacob Eisenstein", "Michael Heilman", "Dani Yogatama", "Jeffrey Flanigan", "Noah A. Smith"], "venue": null, "citeRegEx": "Gimpel et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Gimpel et al\\.", "year": 2011}, {"title": "Learning whom to trust with MACE", "author": ["Hovy et al.2013] Dirk Hovy", "Taylor Berg-Kirkpatrick", "Ashish Vaswani", "Eduard Hovy"], "venue": null, "citeRegEx": "Hovy et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Hovy et al\\.", "year": 2013}, {"title": "Representation learning using multi-task deep neural networks for semantic classification and information", "author": ["Liu et al.2015] Xiaodong Liu", "Jianfeng Gao", "Xiaodong He", "Li Deng", "Kevin Duh", "Ye-Yi Wang"], "venue": null, "citeRegEx": "Liu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2015}, {"title": "Automatic domain adaptation for parsing", "author": ["Eugene Charniak", "Mark Johnson"], "venue": null, "citeRegEx": "McClosky et al\\.,? \\Q2010\\E", "shortCiteRegEx": "McClosky et al\\.", "year": 2010}, {"title": "Distributed representations of words and phrases and their compositionality. Advances in neural information processing systems", "author": ["Mikolov", "Dean2013] T Mikolov", "J Dean"], "venue": null, "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Universal dependencies 1.3. LINDAT/CLARIN digital library at the Institute of Formal and Applied Linguistics, Charles University in Prague", "author": ["Nivre et al.2016] Joakim Nivre"], "venue": null, "citeRegEx": "Nivre,? \\Q2016\\E", "shortCiteRegEx": "Nivre", "year": 2016}, {"title": "Multilingual part-of-speech tagging with bidirectional long short-term memory models and auxiliary loss", "author": ["Plank et al.2016] Barbara Plank", "Anders S\u00f8gaard", "Yoav Goldberg"], "venue": null, "citeRegEx": "Plank et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Plank et al\\.", "year": 2016}, {"title": "What to do about non-standard (or non-canonical) language in NLP", "author": ["Barbara Plank"], "venue": "In KONVENS", "citeRegEx": "Plank.,? \\Q2016\\E", "shortCiteRegEx": "Plank.", "year": 2016}, {"title": "A multilingual social media linguistic corpus. In Conference of CMC and Social Media Corpora for the Humanities", "author": ["Rei et al.2016] Luis Rei", "Dunja Mladenic", "Simon Krek"], "venue": null, "citeRegEx": "Rei et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Rei et al\\.", "year": 2016}, {"title": "Overview of the EVALITA 2016 Part Of Speech on TWitter for ITAlian Task", "author": ["Cristina Bosco", "Alessandro Mazzei", "Andrea Bolioli"], "venue": null, "citeRegEx": "Tamburini et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Tamburini et al\\.", "year": 2016}, {"title": "Morph-it! A free corpus-based morphological resource for the Italian language", "author": ["Zanchetta", "Baroni2005] Eros Zanchetta", "Marco Baroni"], "venue": "Corpus Linguistics", "citeRegEx": "Zanchetta et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Zanchetta et al\\.", "year": 2005}], "referenceMentions": [{"referenceID": 13, "context": "Indeed, models trained on standard newswire data heavily suffer when used on data from a different language variety, especially Twitter (McClosky et al., 2010; Foster et al., 2011; Gimpel et al., 2011; Plank, 2016).", "startOffset": 136, "endOffset": 214}, {"referenceID": 9, "context": "Indeed, models trained on standard newswire data heavily suffer when used on data from a different language variety, especially Twitter (McClosky et al., 2010; Foster et al., 2011; Gimpel et al., 2011; Plank, 2016).", "startOffset": 136, "endOffset": 214}, {"referenceID": 10, "context": "Indeed, models trained on standard newswire data heavily suffer when used on data from a different language variety, especially Twitter (McClosky et al., 2010; Foster et al., 2011; Gimpel et al., 2011; Plank, 2016).", "startOffset": 136, "endOffset": 214}, {"referenceID": 17, "context": "Indeed, models trained on standard newswire data heavily suffer when used on data from a different language variety, especially Twitter (McClosky et al., 2010; Foster et al., 2011; Gimpel et al., 2011; Plank, 2016).", "startOffset": 136, "endOffset": 214}, {"referenceID": 8, "context": "The drawback of the first option is that it\u2019s not clear what norm to target: \u201cwhat is standard language?\u201d (Eisenstein, 2013; Plank, 2016), and implementing normalisation procedures requires quite a lot of manual intervention and subjective decisions.", "startOffset": 106, "endOffset": 137}, {"referenceID": 17, "context": "The drawback of the first option is that it\u2019s not clear what norm to target: \u201cwhat is standard language?\u201d (Eisenstein, 2013; Plank, 2016), and implementing normalisation procedures requires quite a lot of manual intervention and subjective decisions.", "startOffset": 106, "endOffset": 137}, {"referenceID": 19, "context": "In this paper, we report on our participation in PoSTWITA1, the EVALITA 2016 shared task on Italian Part-of-Speech (POS) tagging for Twitter (Tamburini et al., 2016).", "startOffset": 141, "endOffset": 165}, {"referenceID": 16, "context": "for the model itself, we simply take an off-theshelf tagger, namely a bi-directional Long ShortTerm Memory (bi-LSTM) model (Plank et al., 2016), which we use with default parameters (see Section 3.", "startOffset": 123, "endOffset": 143}, {"referenceID": 0, "context": "We used two iterations of indelible self-training (Abney, 2007), i.", "startOffset": 50, "endOffset": 63}, {"referenceID": 1, "context": "In order to get the PoSTWITA ADP A and VERB CLIT tags for these fused word forms from UD, we adjust the UCPH ud-conversion-tools5 (Agi\u0107 et al., 2016) that propagates head POS information up to the original form.", "startOffset": 130, "endOffset": 149}, {"referenceID": 2, "context": "Vectors were created using word2vec (Mikolov and Dean, 2013) with default parameters, except for the fact that we set the dimensions to 64, to match the vector size of the multilingual (POLY) embeddings (Al-Rfou et al., 2013) used by Plank et al.", "startOffset": 203, "endOffset": 225}, {"referenceID": 2, "context": "Vectors were created using word2vec (Mikolov and Dean, 2013) with default parameters, except for the fact that we set the dimensions to 64, to match the vector size of the multilingual (POLY) embeddings (Al-Rfou et al., 2013) used by Plank et al. (2016). We dealt with unknown words by adding a \u201cUNK\u201d token computing the mean vector of three infrequent words (\u201cvip!\u201d,\u201ccuora\u201d, \u201cWhite\u201d).", "startOffset": 204, "endOffset": 254}, {"referenceID": 3, "context": "Character embeddings ~c are incorporated via a hierarchical bi-LSTM using a sequence bi-LSTM at the lower level (Ballesteros et al., 2015; Plank et al., 2016).", "startOffset": 112, "endOffset": 158}, {"referenceID": 16, "context": "Character embeddings ~c are incorporated via a hierarchical bi-LSTM using a sequence bi-LSTM at the lower level (Ballesteros et al., 2015; Plank et al., 2016).", "startOffset": 112, "endOffset": 158}, {"referenceID": 16, "context": "The model has been shown to achieve state-of-the-art performance on a range of languages, where the incorporation of character information was particularly effective (Plank et al., 2016).", "startOffset": 166, "endOffset": 186}, {"referenceID": 6, "context": "Table 3 shows the results on the official test data for both our models and TNT (Brants, 2000).", "startOffset": 80, "endOffset": 94}, {"referenceID": 18, "context": "8600 tweets and 160K tokens (Rei et al., 2016).", "startOffset": 28, "endOffset": 46}, {"referenceID": 11, "context": "separate annotations produced by different judges, so that we used MACE (Hovy et al., 2013) to adjudicate divergences.", "startOffset": 72, "endOffset": 91}, {"referenceID": 7, "context": "Multi-task learning Multi-task learning (MTL) (Caruana, 1997), namely a learning setting where more than one task is learnt at the same time, has been shown to improve performance for several NLP tasks (Collobert et al., 2011; Bordes et al., 2012; Liu et al., 2015).", "startOffset": 202, "endOffset": 265}, {"referenceID": 5, "context": "Multi-task learning Multi-task learning (MTL) (Caruana, 1997), namely a learning setting where more than one task is learnt at the same time, has been shown to improve performance for several NLP tasks (Collobert et al., 2011; Bordes et al., 2012; Liu et al., 2015).", "startOffset": 202, "endOffset": 265}, {"referenceID": 12, "context": "Multi-task learning Multi-task learning (MTL) (Caruana, 1997), namely a learning setting where more than one task is learnt at the same time, has been shown to improve performance for several NLP tasks (Collobert et al., 2011; Bordes et al., 2012; Liu et al., 2015).", "startOffset": 202, "endOffset": 265}], "year": 2016, "abstractText": "English. We bootstrap a state-of-the-art part-of-speech tagger to tag Italian Twitter data, in the context of the Evalita 2016 PoSTWITA shared task. We show that training the tagger on native Twitter data enriched with little amounts of specifically selected gold data and additional silver-labelled data scraped from Facebook, yields better results than using large amounts of manually annotated data from a mix of genres. Italiano. Nell\u2019ambito della campagna di valutazione PoSTWITA di Evalita 2016, addestriamo due modelli che differiscono nel grado di supervisione in fase di training. Il modello addestrato con due cicli di bootstrapping usando post da Facebook, e che quindi impara anche da etichette \u201csilver\u201d, ha una performance superiore alla versione supervisionata che usa solo dati annotati manualmente. Discutiamo l\u2019importanza della scelta dei dati di train-", "creator": "LaTeX with hyperref package"}}}