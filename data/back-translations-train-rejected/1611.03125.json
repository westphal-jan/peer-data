{"id": "1611.03125", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Nov-2016", "title": "A Modular Theory of Feature Learning", "abstract": "Learning representations of data, and in particular learning features for a subsequent prediction task, has been a fruitful area of research delivering impressive empirical results in recent years. However, relatively little is understood about what makes a representation `good'. We propose the idea of a risk gap induced by representation learning for a given prediction context, which measures the difference in the risk of some learner using the learned features as compared to the original inputs. We describe a set of sufficient conditions for unsupervised representation learning to provide a benefit, as measured by this risk gap. These conditions decompose the problem of when representation learning works into its constituent parts, which can be separately evaluated using an unlabeled sample, suitable domain-specific assumptions about the joint distribution, and analysis of the feature learner and subsequent supervised learner. We provide two examples of such conditions in the context of specific properties of the unlabeled distribution, namely when the data lies close to a low-dimensional manifold and when it forms clusters. We compare our approach to a recently proposed analysis of semi-supervised learning.", "histories": [["v1", "Wed, 9 Nov 2016 22:40:15 GMT  (385kb,D)", "http://arxiv.org/abs/1611.03125v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["daniel mcnamara", "cheng soon ong", "robert c williamson"], "accepted": false, "id": "1611.03125"}, "pdf": {"name": "1611.03125.pdf", "metadata": {"source": "CRF", "title": "A Modular Theory of Feature Learning", "authors": ["Daniel McNamara", "Cheng Soon Ong", "Robert C. Williamson"], "emails": ["bob.williamson}@anu.edu.au"], "sections": [{"heading": null, "text": "The presentation of data, especially learning characteristics for a subsequent predictive task, has been a fruitful field of research in recent years with impressive empirical results. However, relatively little is understood about what makes a presentation \"good.\" We propose the idea of a risk gap caused by imaging learning for a given predictive context, which measures the difference in risk when a learner uses the learned characteristics in comparison to the original inputs. We describe a set of sufficient conditions for unattended imaging learning to provide a benefit, measured by that risk gap. These conditions break down the problem of when imaging learning is broken down into its components, which can be evaluated separately on the basis of an unmarked sample, appropriate domain-specific assumptions about the common distribution, and analysis of the learner and the subsequent supervised learner. We provide two examples of such conditions in the context of specific characteristics of unlabeled distribution, namely when the data is close to a low-dimensional manifold and when they form clusters."}, {"heading": "1 Introduction", "text": "The predictive power of machine learning algorithms is highly dependent on the characteristics they receive as inputs. Traditionally, features have been handcrafted by domain experts. While this works well in some cases, it offers no performance guarantees and requires costly individual implementation for each new problem. Performing learning, also known as feature learning, involves the automatic transformation of input data to improve the performance of prediction algorithms. Over the past decade, imaging techniques using unmarked data have been used to make empirical advances in areas such as computer vision [HS06] and natural language processing [MSC + 13], and are expected to be at the forefront of further advances in machine learning [LBH15]. However, there are few theoretical results when such techniques provide benefits. The main contribution of this paper is a set of sufficient conditions under which unattended imaging has been shown to improve task performance."}, {"heading": "1.1 This is unlike standard learning theory papers", "text": "There are two key features of the paper that are worth highlighting: 1) We are analyzing a processing pipeline, not just a single step; sequential pipeline use is common in practice, but is rarely approached in theory; and our methodology appears novel in this regard. 2) We are analyzing the problem in terms of risk gaps, not sample complexity, as illustrated in Figure 1, which we detail in Section 3. Although it is ultimately desirable to say something about finite sample performance, current technology of limitations seems inadequate for the task at hand. Fortunately, by using risk limits, we can justifiably compare performance in the complex processing pipeline that is inherent to the problem by avoiding the inadequacy of comparing only upper limits. In Section 2, we offer a comparison with current approaches to imaging learning and existing theoretical results, which largely focus on the limitations of learning and non-use."}, {"heading": "2 Related work", "text": "Many learning methods of representation have been developed, including those that use blank data, and have achieved considerable empirical success [BCV13], but few theoretical guarantees regarding the impact on the execution of the task. The literature so far shows the usefulness of such techniques, while also the need for further analysis of when and why they work. The desire for computational efficiency has motivated techniques to learn low-dimensional manifold embedding. Principal components analysis (PCA) is the canonical such technique and has been limited to core variants such as isomap, laplacian eigenmaps and local linear embedding [MRT12]. Theoretically, it has been shown that it is possible to compress a finite number of high-dimensional dots to a low-dimensional representation, while the distortion at pointedly Euclidean distances [JL84]. Diverse learning approaches have generally not been shown to improve the performance of a subsequent learning multi-focused learning experience in the deep learning field."}, {"heading": "2.1 Relationship to existing representation learning approaches", "text": "Our example (see Section 4.1), which includes exploiting the cluster structure in the unlabeled data, shares the main goal of deep neural networks: learning a representation that will be linearly separable. Methods that aim to learn the nucleus also share this goal, although the core function implicitly and not explicitly defines the attribute space.Multiple learning techniques can be analyzed using our theorems and are discussed in the Supplement. Conditions in these cases require that the unlabeled data be close to a low-dimensional manifold, that the manifold structure is related to the labels, and that the proposed repair of the manifold structure is compatible with the supervised learner.A characteristic aspect of our approach is that it provides a high probability performance that guarantees the performance of a particular later learner, unlike most unsupervised learning approaches, where the objective function has no relation to the task being reviewed most suitable for our task."}, {"heading": "2.2 Relationship to semi-supervised learning", "text": "The schematic representation shown in Figure 1 can be considered a special case of a more general dilemma faced by machine learning practitioners, and an additional step is suggested given an existing system. We would like to know under what circumstances such a step will improve the performance of the system. We can also characterize semi-supervised learning in this way, if the step is a specific use of unlabeled data. The differences between the two approaches are shown in Figure 2. In semi-supervised learning, if a compatibility function exists that allows the elimination of incompatible hypotheses using only unlabeled data, performance may improve, as optimization via a smaller hypotheses category is easier and less sensitive to noise when few labeled data points are available. Furthermore, a narrower generalization error limit will be possible [BB10] (see Appendix B). If the target function lies outside the original hypotheses category, semi-supervised learning will not contribute to detecting it."}, {"heading": "3 When unsupervised representation learning improves task performance", "text": "This situation describes a number of common machine learning scenarios. Do the features learned from an autoencoder increase the performance of a linear classifier compared to using the original input? Does unattended pre-training increase the performance of a monitored neural network? Does a particular core function outperform a linear kernel when used with a hypothesis class of linear delimiters (remembering that core functions implicitly specify a trait space)? Do distributed vector representations of words outperform one-hot unigram representations in natural language processing tasks? Our approach to evaluating the impact of unattended imaging learning is shown in Figure 1. We will examine when it can be shown that the path including a learning step to imaging reduces the risk."}, {"heading": "3.1 Problem statement", "text": "The letters X, Y, and Z are the input, output, and learned attribute spaces. Let fL be an unattended attribute learning algorithm, Su and Xmu be an unlabeled sample, and f: X and Z be the attribute map learned with fL and Su. Let hZL be a supervised hypothesis learner accepting input in the learned attribute space, SZl = {x, y} ml be a labeled sample converted with hL and Sl. Let hZL be the supervised hypotheses learner accepting input in the learned attribute space, SZl = {x, y} being converted into the learned attribute space, and hZ: Y be the hypothesis learned with hZL and S. The risk of h (h) = h (h) (h), {E = y, y =), is (x), y (x), y = L, y (x), y (x), y = Z is a loss, y (x)."}, {"heading": "3.2 Set of sufficient conditions", "text": "We provide a set of sufficient conditions for unmonitored representation to reduce the risk of a hypothesis as presented in Table 1. We motivate these conditions by pointing out that any independent aspect of the predictive context (the source nodes in Figure 1) is associated with a specific context. Therefore, it is unlikely that we will be able to reduce the set of conditions, a topic we will discuss further in Supplement A.1. The conditions allow us to measure the impact of representation by analyzing specific aspects of the problem separately and then combining the results. Conditions use a set of intermediate risk conditions to measure the extent to which certain properties of the predictive context are held. RA (PX) measures the extent to which some members of a class of structural properties for PX, Ra (PX) measures the extent to which some specific structural properties are held, and R (X) measures the emptive extent to which is held by X (some structural properties) and PX (some) is held by X (some)."}, {"heading": "4 Application of Theorem 1 and 2: Cluster representation", "text": "We present an illustrative example of the sufficient conditions for unattended representation learning. The first learns a representation of cluster structure and demonstrates the application of theorem 2. The second example in the supplement discusses manifold learning and applies theorem 1. In both examples, we assume a limited continuous input space X = [0, 1] n, a binary output space Y = {0, 1} and a zero / one loss function L (y, y \u2032) = 1 (y 6 = y \u2032). We outline the strategy used for our proofs. We prove each condition individually with high probability, and then take a union that inevitably shows that all conditions will hold (see attachment A.3 for a discussion of these high probability statements). We divide the input space into hypercubes and perform an algorithm to test endless properties within a property class."}, {"heading": "4.1 Learning cluster representation improves risk", "text": "We present an example where unsupervised learning has been shown to reduce risk. It uses cluster structure in the unreported data to learn a representation in which each cluster has a uniform risk, as shown in Figure 3. Assuming that the learner hypothesis has a linear separator, and that it is possible to prove that representation provides a benefit to learning as formalized in Theorem 3, the instantiated theorem 2. This result makes sense if the risk gap is positive (see Figure 7 for an example).Theorem 3. Let R (PX) get the result of the cluster trait test described in Theorem 2."}, {"heading": "5 Conclusion", "text": "We have developed a theory that explains when unsupervised pre-training works - a set of sufficient conditions that most likely imply that a change in representation improves task fulfillment. These conditions collectively depend on the structural characteristics of the distribution, the learner attribute, the subsequent supervised learner, and the loss function used. We have instantiated the conditions using an example that exploits the cluster structure, with a second example of the diverse structure in the supplement. Our approach of analyzing a processing pipeline appears new, where it seems necessary to take into account risk gaps rather than sample complexity. The modular nature of our reasoning is a central feature; it splits an obscure black box into intelligible components. Moreover, the instantiation of each component for a given problem is reduced to the relatively standard application of existing techniques."}, {"heading": "A Motivation for and technical discussion of proposed sufficient conditions", "text": "We outline the motivation for the sufficient conditions proposed for unsupervised learning of representation, as well as technical aspects of these conditions, which are omitted from the main text for reasons of space."}, {"heading": "A.1 Motivation for sufficient conditions", "text": "The subsequent process of evaluating the effect of unsupervised representation of learning is described in Figure 1. Thus, by identifying source nodes that represent independent elements of the predictive context, we associate a condition with each such element as shown in Table 1. Thus, although we do not formally show that the conditions for unsupervised representation of learning are necessary, it seems unlikely that the conditions can be further reduced. Furthermore, the modular structure of the conditions is such that the task of determining the effect of the representation of learning is usually \"factored\" over the various elements of the predictive context, making the analysis appear more tractable. In view of an unlabeled data sample, a trait learner, and appropriate assumptions about the common structure between the marginal distribution PX and the common distribution PXY, it is possible to evaluate the effect of representation of learning with high probability. While we do not treat PX independently of a PY, because we treat XX as independent of a common structure and XY is unknown."}, {"heading": "A.4 Concept of transparent polymorphism", "text": "Our analysis allows for the comparison of two (potentially independently) supervised learners, but focuses on \"transparent polymorphic\" learners to isolate the effects of the representative learning step. These are families of learning algorithms, so that the algorithm can easily be extended to the new type if the type signature is changed. Examples of such learners cited in this text - empirical risk minimization versus the class of linear classifiers and 1 nearest neighbour using Euclidean distance - are examples of such learners. An exact definition of this learning class is not attempted here and does not appear to have been well studied elsewhere. A quantitative measure of the transparent polymorphism of a particular learner is of interest because of the ubiquity of such learners in practical applications. It is easy to construct a learner that is not transparent polymorphic: A learner performing logistic regression when he receives inputs with ten dimensions or less than, and when he receives support in a number that is available."}, {"heading": "B Generalization error bounds in semi-supervised learning", "text": "A formalization of semi-supervised learning is provided in [BB10], including improved generalization error margins compared to supervised learning. We describe this approach to build on the comparison between unsupervised representative learning and semi-supervised learning presented in Section 2.2. For one hypothesis, class H and entrance hall X are defined as compatibility functions, while the incompatibility of a hypothesis in relation to an unlabeled sample h is defined as RU (h) = 1 \u2212 Ex-PX (h, x), while the incompatibility of a hypothesis in relation to an unlabeled sample Su of points R (h) = 1 \u2212 1mu x (h, x). The benefit of semi-supervised learning is based on the idea that the hypothesis in relation to the target function h, RU (h) = 0 in the simplest case we are considering here, or in other cases is reduced (h)."}, {"heading": "C Algorithm for selecting a feature learner", "text": "Algorithm 1 uses upper risk limits to select a learner. It is presented as a high-level conceptual algorithm and not as a tool for immediate practical use. The algorithm accepts a number of possible learners, an undescribed sample Su, a learner for hypotheses hL, the number of labeled samples ml, the degree of certainty parameters \u03b4, and a dictionary of boundaries. Each boundary in the dictionary contains a property test for PX based on an unlabeled sample, a learner for characteristics fL and a hypotheses hL to which the boundary applies, and reasonable assumptions for PXY based on the results of the property test. Two examples of such boundaries are provided in Section 4 of this paper. For each condition, the algorithm performs the associated property test and uses this result to calculate the bound property test fL _ end _ end _ end _ end _ end _ end _ end _ bound _ boundary as the closest boundary: If the current boundary is then the previous boundary is selected as the previous boundary."}, {"heading": "D Main theorem proofs and lemmas used in examples", "text": "We present the proofs for the most important theorems, present a technical problem, and present the standard boundaries for generalization errors used in the proofs for the theorems associated with the examples."}, {"heading": "D.1 Proof of Theorem 1", "text": "Evidence According to the definitions in Table 1: R-a (PX) \u2264 \u0442 A-A (PX) = \u21d2 Ra (PX) \u2264 A-RA (PX) \u2264 A. RA (PX) \u2264 A-B (PXY) = \u21d2 RB (PXY) \u2264 B. In addition, Ra (PX) \u2264 A-C (fL) = \u21d2 RC (f) \u2264 C. In addition, D (hL), RB (PXY) \u2264 B-RC (f) \u2264 C-R (hZ-f) \u2264 Zmax. Therefore R-a (PX) \u2264 A-A (PX) \u2264 A-A (PX) \u0445B (PXY) \u0445C (hL) \u0432D (hL) = \u21d2 R (hZ-f) \u2264 Zmax."}, {"heading": "D.2 Proof of Theorem 2", "text": "PX. PX. PX. PX. PX. PX. PX. PX. PX. PX. PX. PX. PX. PX. (PX). (PX). (PX). (PX). (PX). (PX). (PX). (PX). (PX). (PX). (PX). PX. (PX). PX. (PX). PX. (PX). PX. PX. (PX). PX. PX. (PX). PX. PX. PX. PX. PX. PX. (PX). PX. (PX). PX. (PX). PX. (PX). PX. (PX). PX. (PX). PX. (PX). PX. (PX). PX. (PX. (PX). (PX. (PX). (PX). PX. (PX). (PX). (PX. (PX). (PX). (PX. (PX). (PX). (PX). (PX. (PX). (PX). (PX. (PX). (PX). (PX). (PX). (PX. (PX). (PX). (PX). (PX. (PX). (PX. (PX). (PX). (PX). (PX). (PX). (PXY.). (PXY.). (PX.). (PXY. (PXY. (). (). (). (PXY.). (PXY.). (). (). (PXY.). (PXY. (). (). (PXY. (). (PX. (). (PX.). ().). (PXY. ().). (PX. (). ("}, {"heading": "E Supplementary material for the cluster example", "text": "The parameters used for the cluster example in Section 4.1 are summarized in Table 2. Evidence for theorem 3 and the lemmas used below. For a given set of parameters, we represent the risk gap caused by the learned features in Figure 7 (right), which depends on both the number of blank points mu and the number of labeled points ml. In particular, the learned features are only demonstrably useful if the risk gap is positive. This is not always the case, which is not surprising, since we expect that a certain imaging learning technique will only be useful in certain predictive contexts."}, {"heading": "E.1 Kernel interpretation", "text": "It is possible to obtain a dual form of linear classifiers that work with a core function k in the original input space, which corresponds to the inclusion of a point product in the attribute space in connection with the attribute pattern f. This can be written as k (x, x \u2032) = < f (x), f (x \u2032) >. By defining f (x) in Section 4.2 and defining cx and cx \u2032 as the hypercubes in which x and x \u2032 are located, we obtain: k (x, x \u2032) = 1, if x0,...,..., xG, Su s.t. x0, xG, cx, xG, cx, cx, xG, xG, xG, xG, xG, xG, xG, xG \u2212 1, i = 0 | xi \u2212 xi + 1 | 2 \u2264 s, n0, others.Thus, the proposed representation can be regarded as a form of unattended kernel learning. However, in the general case of hypotheses learning hL, no linear interpretation is possible, since no general form of hypotheses as in the classifixes."}, {"heading": "E.2 Proof of Theorem 3", "text": "Proof With a probability of at least 1 \u2212 \u03b4, measured at the bond boundary, we have A (PX) by lemmas 4, B (PXY) by lemmas 5, C (fL) by lemmas 6, D (hL) by lemmas 7, E (PXY) by lemmas 8 and F (PX, hL) by lemmas 9. Applied to theorems 2, we have \u2206 R \u2265 min \u2212 Zmax."}, {"heading": "E.3 Proof of Lemma 4", "text": "First, given a distribution PX and a length parameter of the page s, let it be: = s \u00b2 n and let XA be the set of all sets Xa with the following properties: 1. Xa = k \u00b2 i = 1 {Xi} for some finite k \u00b2, where Xi \u00b2 X for all i \u2264 k2. | | x \u2212 x \u00b2 | 2 > \u03b3 for all x \u00b2 Xa \u00b2 data is represented in Algorithm 2. The algorithm returns a failure if it cannot find at least two disjointed clusters, all supported by Su. In the future, this restriction could be relaxed to find clusters in which most of the data lies within x and allow us to look at the case in which X > 0.Data: unlabeled example Su, Input Space X, Page length parameter s Result: Cluster to find that most of the data lies within x."}, {"heading": "E.4 Proof of Lemma 6", "text": "Proof By constructing fL, for all points x such that f (x) is not the zero vector, LC (x, f): = max {x \u2032: f (x) = f (x \u2032)} d\u03b3 (x, x \u2032) = 0. These points x are exactly the points for which La (x) = 0. Thus, if Ra (PX) \u2264 A, then RC (f) \u2264 A."}, {"heading": "E.5 Proof of Lemma 7", "text": "The proof that f can be applied to PX results in a distribution supported by k + 1 points. With a probability of at least 1 \u2212 \u03b43, Ex \u0445 PX [min {f (x \u2032), y \u2032} - Zl 1 (f (x) 6 = f (x \u2032))] - max t [0,1] (k + 1 \u2212 \u03b43 (1 \u2212 t) \u2212 ml) t =: \u03b1, by Lemma 10.Remember that by the definition of RC (f), if we randomly draw a point x from PX, then with a probability of at most C there is any x \u00b2 point, so that there is an x \u00b2 point, which is such that f (x) > 0 and f (x \u2032) = f (x \u2032) > 0 by the compound boundary, with a probability of at most \u03b1 + C, there is either no point {f (x \u2032), y \u2032} - or SZl point, which is such that f (x) that we have such a point (f) - or we have a point - f - or a point - x - x - (x) classification (x -) or x - (x -) classification."}, {"heading": "E.6 Proof of Lemma 9", "text": "Run the property test algorithm described in algorithm 2 to k = | Xa |. Run 1 2k (k \u2212 1) tests of the following type for each pair of Xi, Xj, Xa, i 6 = j. Construct the sentence Siju, which contains only the points in Su located in Xi, Xj, adding the terms y = 1 for x, Xi and y = 0 for x, Xj. Run the empirical risk minimization on Siju to produce the hypothesis hij, which we assume has the minimum empirical risk of each hypothesis in H. Let Su be the set of all possible designated samples, which lies within the minimum empirical risks by adding the terms RB (PXY) = 0 and RE (PXY). If these limitations apply, we have H: \u03b2, j 1 must have the certificate of authenticity {x} y."}, {"heading": "F Example: Manifold representation", "text": "We present an example that uses a low-dimensional manifold structure present in the unlabeled distribution to learn a new representation, as shown in Figure 6. One toy for this example is the binary classification problem of determining whether there are crocodiles in a particular section of a river. Crocodiles tend to be concentrated in certain regions of the river because they swim along the river and cannot move over land. A representation that is parameterized by river position, rather than by latitude and longitude, will allow a Nearest Neighbor algorithm to better learn where there are crocodiles. A probable upper limit for the risk of a subsequent superior learner is shown by the learned representation in Theorem 13, which is instantiated Theorem 1. This result will be more significant if the limit is less than 1 (see Figure 7 for an example). In this case, the Lalgorithm is the nocturnal distance used in this case."}], "references": [{"title": "A discriminative model for semi-supervised learning", "author": ["Maria-Florina Balcan", "Avrim Blum"], "venue": "Journal of the ACM,", "citeRegEx": "Balcan and Blum.,? \\Q2010\\E", "shortCiteRegEx": "Balcan and Blum.", "year": 2010}, {"title": "Representation Learning: A Review and New Perspectives", "author": ["Yoshua Bengio", "Aaron Courville", "Pascal Vincent"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Bengio et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 2013}, {"title": "Semi-supervised learning with density based distances", "author": ["Avleen S. Bijral", "Nathan Ratliff", "Nathan Srebro"], "venue": "In Uncertainty in Artificial Intelligence 2011 Proceedings,", "citeRegEx": "Bijral et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Bijral et al\\.", "year": 2012}, {"title": "Elements of Information Theory", "author": ["Thomas M. Cover", "Joy A. Thomas"], "venue": null, "citeRegEx": "Cover and Thomas.,? \\Q2012\\E", "shortCiteRegEx": "Cover and Thomas.", "year": 2012}, {"title": "Why Does Unsupervised Pre-training Help Deep Learning", "author": ["Dumitru Erhan", "Yoshua Bengio", "Aaron Courville", "Pierre-Antoine Manzagol", "Pascal Vincent", "Samy Bengio"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Erhan et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Erhan et al\\.", "year": 2010}, {"title": "Reducing the dimensionality of data with neural networks", "author": ["Geoffrey E. Hinton", "Ruslan R. Salakhutdinov"], "venue": null, "citeRegEx": "Hinton and Salakhutdinov.,? \\Q2006\\E", "shortCiteRegEx": "Hinton and Salakhutdinov.", "year": 2006}, {"title": "Extensions of Lipschitz mappings into a Hilbert space", "author": ["William B. Johnson", "Joram Lindenstrauss"], "venue": "Contemporary Mathematics,", "citeRegEx": "Johnson and Lindenstrauss.,? \\Q1984\\E", "shortCiteRegEx": "Johnson and Lindenstrauss.", "year": 1984}, {"title": "Foundations of Machine Learning", "author": ["Mehryar Mohri", "Afshin Rostamizadeh", "Ameet Talwalkar"], "venue": "MIT press,", "citeRegEx": "Mohri et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Mohri et al\\.", "year": 2012}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S. Corrado", "Jeff Dean"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Generalization Error Bounds in Semi-supervised Classification Under the Cluster Assumption", "author": ["Philippe Rigollet"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Rigollet.,? \\Q2007\\E", "shortCiteRegEx": "Rigollet.", "year": 2007}, {"title": "Towards Principled Unsupervised Learning", "author": ["Ilya Sutskever", "Rafal Jozefowicz", "Karol Gregor", "Danilo Rezende", "Tim Lillicrap", "Oriol Vinyals"], "venue": "[cs],", "citeRegEx": "Sutskever et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2015}, {"title": "Exact solutions to the nonlinear dynamics of learning in deep linear neural networks", "author": ["Andrew M. Saxe", "James L. McClelland", "Surya Ganguli"], "venue": "In International Conference on Learning Representations,", "citeRegEx": "Saxe et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Saxe et al\\.", "year": 2014}, {"title": "Unlabeled data: Now it helps, now it doesn\u2019t", "author": ["Aarti Singh", "Robert Nowak", "Xiaojin Zhu"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Singh et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Singh et al\\.", "year": 2009}, {"title": "A Theory of Feature Learning", "author": ["Brendan van Rooyen", "Robert C. Williamson"], "venue": "arXiv preprint arXiv:1504.00083,", "citeRegEx": "Rooyen and Williamson.,? \\Q2015\\E", "shortCiteRegEx": "Rooyen and Williamson.", "year": 2015}], "referenceMentions": [], "year": 2016, "abstractText": "Learning representations of data, and in particular learning features for a subsequent prediction task, has been a fruitful area of research delivering impressive empirical results in recent years. However, relatively little is understood about what makes a representation \u2018good\u2019. We propose the idea of a risk gap induced by representation learning for a given prediction context, which measures the difference in the risk of some learner using the learned features as compared to the original inputs. We describe a set of sufficient conditions for unsupervised representation learning to provide a benefit, as measured by this risk gap. These conditions decompose the problem of when representation learning works into its constituent parts, which can be separately evaluated using an unlabeled sample, suitable domain-specific assumptions about the joint distribution, and analysis of the feature learner and subsequent supervised learner. We provide two examples of such conditions in the context of specific properties of the unlabeled distribution, namely when the data lies close to a low-dimensional manifold and when it forms clusters. We compare our approach to a recently proposed analysis of semi-supervised learning.", "creator": "LaTeX with hyperref package"}}}