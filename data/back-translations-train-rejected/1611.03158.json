{"id": "1611.03158", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Nov-2016", "title": "Using Neural Networks to Compute Approximate and Guaranteed Feasible Hamilton-Jacobi-Bellman PDE Solutions", "abstract": "Hamilton-Jacobi (HJ) reachability is a powerful tool that provides performance and safety guarantees for dynamical systems. Unfortunately, using the state-of-the-art dynamic programming-based approaches, HJ reachability is intractable for systems with more than five dimensions because its computational complexity scales exponentially with system dimension. To sidestep the curse of dimensionality, we propose an algorithm that leverages a neural network to approximate the minimum time-to-reach function to synthesize controls. We show that our neural network generates near optimal controls which are guaranteed to successfully drive the system to a target state. Our framework is not dependent on state space discretization, leading to a significant reduction in computation time and space complexity in comparison with dynamic programming-based approaches. Using this grid-free approach also enables us to plan over longer time horizons with relatively little additional computation overhead. Unlike many previous neural network reachability formulations, our approximation is conservative and hence any trajectories we generate will be strictly feasible. For demonstration, we specialize our new general framework to the Dubins car model and discuss how the general framework can be applied to other models with higher-dimensional state spaces.", "histories": [["v1", "Thu, 10 Nov 2016 01:48:39 GMT  (3022kb,D)", "http://arxiv.org/abs/1611.03158v1", "Submitted to HSCC 2017"], ["v2", "Mon, 27 Mar 2017 05:21:42 GMT  (5055kb,D)", "http://arxiv.org/abs/1611.03158v2", "Submitted to IEEE Conference on Decision and Control, 2017"]], "COMMENTS": "Submitted to HSCC 2017", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["frank jiang", "glen chou", "mo chen", "claire j tomlin"], "accepted": false, "id": "1611.03158"}, "pdf": {"name": "1611.03158.pdf", "metadata": {"source": "CRF", "title": "Using Neural Networks for Fast Reachable Set Computations", "authors": ["Frank Jiang", "Glen Chou", "Mo Chen", "Claire J. Tomlin"], "emails": [], "sections": [{"heading": "1. INTRODUCTION", "text": "In fact, most of them are able to survive on their own."}, {"heading": "2. PROBLEM FORMULATION", "text": "In this section, we will first give an overview of the HY accessibility theory, as well as some definitions that are indispensable for our main results, and then briefly discuss the objectives of this paper."}, {"heading": "2.1 Background", "text": "2.1.1 System dynamics Consider a dynamic system determined by the following differential equation (ODE): x x = f (x, u), u \u00b2 U (1) Here x \u00b2 Rn is the state of the system and the control function u (\u00b7) is assumed to be drawn from the set of measurable functions1. Let us further assume that the system dynamics f: Rn \u00b7 U \u2192 Rn is uniformly continuous, limited and Lipschitz continuously in x for fixed and. Let us think of the functional space from which f as F. With these assumptions, some initial state x, initial time t0 and control function t0 (\u00b7 U, there is a unique orbit solution (1). We refer to the trajectories of (1) starting with the state x and time t0 as the result (t; x, t0, u (\u00b7))."}, {"heading": "2.2 Goal", "text": "In this paper, we attempt to overcome the exponential scaling of computational complexity, inspired by two inherent challenges that dynamic programming methods face. Firstly, since only relatively mild assumptions are made on system dynamics (1), optimal trajectories are a priori unknown and could essentially trace arbitrary paths in the state space. Dynamic programming ignores this problem by taking into account all possible behaviors of the orbit. Numerical methods are required to obtain dynamic programming solutions, which leads to the necessity of discrediting the state space. Secondly, in a practical environment, the system starts at a certain state x. Thus, the optimal control, and in particular the (x), is only needed along the optimal orbit."}, {"heading": "3. NEURAL NETWORK TRAINING PHASE", "text": "Given a target state xL, and assuming that the system starts from an initial state of x, we want to develop an NN that can generate a control function u (\u00b7) that drives the system from x (\u00b7) to xL. Likewise, u (\u00b7) should drive the rear system from xL to x (\u00b7). Since the NN is not perfect, it can only be expected that they will produce the rear control of the system u (\u00b7) that drives the rear system from xL to x (\u00b7 i). If the NN is well formed, then any x (\u00b7) would be very close to x (\u00b7). More specifically, consider the backward dynamics of the system, which is called g: Rn \u00b7 F \u2192 U, and define comprehension (x, \u00b7 f (\u00b7, \u00b7) = u (\u00b7).)"}, {"heading": "3.1 Neural Network Architecture", "text": "We propose a rectified linear unit recurrent NN (RRNN) with the following structure: Primitive Layer: P [n] = improved (WP \u00b7 X [n] + bP) Duration Layer: D [n] = improved (WD1 \u00b7 P [n] + WD2 \u00b7 X [n] + bD) Control Layer: U [n] = WL \u00b7 D [n] + bL Plant Layer: X [n + 1] = improved (WX \u00b7 U [n] + bX) where is the positive rectifying function defined as (a) = max (0, a) and n = 0, 1,., N. The input of the RNN is x (X [0] = x), and the output is some u (U [N] = dytifying layer defined)."}, {"heading": "3.2 Initial Training Data Generation", "text": "To do this, we need training examples in the form of {(x-i, u-i (\u00b7))}, which sufficiently capture the behavior of system dynamics. {x-i} is randomly generated with an accept-reject algorithm similar to that in [17] and described in Alg. 1, which prints a Boolean variable A that indicates whether a state x is to be accepted. A state x, an accept-region R and a decay rate are required as inputs. In Alg. 1, we first calculate xproj, the euclidean projection of state x on the set R as follows: xproj = min x-x \u00b2 x \u00b2 x \u00b2 \u2212 x \u00b2 2: x-region R (10) Using the accept-reject algorithm, we first calculate xproj, the euclidean projection of state x on the set R: xproj = min x \u00b2. \u2212 x-x \u00b2 -x \u00b2 -x -\u00b2 -range R: a value ranging from -\u00b2 to -generic is accepted."}, {"heading": "3.3 Dynamic Training", "text": "rf\u00fc eid rf\u00fc rf\u00fc eid rf\u00fc eid rf\u00fc eid rf\u00fc eid rf\u00fc eid rf\u00fc eid rf\u00fc rf\u00fc eid rf\u00fc rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc"}, {"heading": "4. CONTROLLER SYNTHESIS PHASE", "text": "After completing the dynamic training process, we obtain the set of states X near x and the corresponding controls V. From each state x-i-X and the control function u-i (\u00b7) -V, we obtain the approximate TTR values directly: \u03c6-i (xi) = T-i. These approximate TTR values can be used to synthesize a control at x-i according to (6). However, in order to move the system from x-i to xL, a few further post-processing steps are required."}, {"heading": "4.1 Trajectory Tracing", "text": "Fortunately, this information can be calculated from X and V. Specifically, each x-i-X and u-i (\u00b7) -V curve can be determined by discretizing time t into MT points of time. We designate these states x (i, j), where the index i comes from the index x-i-X and the index j-i-X.... MT-1) indicates that the state is calculated from the j point in time t in the MT points of time. Mathematically, x-i (i, j) results from the index x-i-X and the index j-i (tj-i) from the j."}, {"heading": "4.2 Imposing a Grid", "text": "While the source of the exponential problem of time and space complexity lies in discrediting the state space, the introduction of a grid can still be useful as long as the number of grid points is small. Thus, we organize the approximate TTR values if we move the grid G (x) so that it is always centered in the current system state x (t) and has a resolution suitable for the local density of the points near x in X. This is mathematically feasible since the grid does not cover a large part of the state space. According to the local grid G (x), each state x is created which is mapped to the next grid point within the boundaries of G (x)."}, {"heading": "4.3 Smart Gradient Approximation", "text": "The next step to bring the system to xL is to calculate the slopes of the approximate TTR function and its use (6). Since we have the grid G (x) and approximate TTR values \u03c6 (x) in the grid, standard numerical methods can in principle be used to calculate the gradient. However, depending on the X value set, it is generally not possible to assign an equal value to every grid point of G (x). Alg. 4 provides heuristics for approximating the gradient on a grid whose grid points do not all contain a function value. This is done by carefully selecting grid points near x based on the availability of the function value and then approximating a component of the gradient by forward, backward or central difference. If necessary, function values are extrapolated. In the algorithm, we assume that the gradient is calculated in the lowest component, the definition value (x)."}, {"heading": "4.4 Control Computation", "text": "In practice, depending on how the control appears in system dynamics, some components of the gradients may not be necessary to derive a control. In this case, only the gradient components required to calculate the control according to (6) are required.Algorithm 4 Gradient Ca. 1: Result: Gradients (x) 2: Inputs: G, (i, j), X: Initialization: 4: Data about (G, X) 5: Data about (G, X) 6: Data about (G, X) 6: Data about (G, X) 6: Inputs: Inputs: G, (x) 2: Inputs: G, (i, j)}, X: Initialization: 4: Data about (G, X) 5: Data about (G, X) 6: Data about (G, X) 6: Data about (X) 6: Data about (top |! = 0 and |! = 0 then 7: x + \u2190: Next: (G, X, X) Next: (G, X, X) Next: (G, X) Next: (X, X), Numbers about (X) 5: Data about (G, X) 5: Data about (G, X) 5: Data about (G, X) 6: Data about (G, X) 6: Data about (G, X) 6: Data about (G, X) 6: Data about (G, X) 6: Data about (G, X) 6: Data about (G, X) 6: Data about (G, X) 6: Data about (G, X: Data about (G, X) 6: Data about (G, X) 6: Data about (G, X) 6: Data about (G, X under (G, X) 6: Data about (G, X, X under (G, X) 6: Data about (G, X) 6: Data about (G under (G, X, X, X) 6: Data about X, X under (G, X, X under (X) 6: Data about (G, X, X under (G, X, X), X under (X, X, X under (X, X, X) Indices, X under: Numbers, X, X under (X, X, X, X"}, {"heading": "5. DUBINS CAR EXAMPLE", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Vehicle Dynamics", "text": "Consider the Dubins car with the state x = (px, py, \u03b8). (px, py) are the X and Y positions of the vehicle, and \u03b8 is the heading of the vehicle. The system dynamics, which proceeds from the longitudinal velocity, arep-x = cos-p-y = sin \u03b8\u03b8 = u, | u | \u2264 1 (12) The control of the Dubins car is called u and inevitably lies in the interval [\u2212 1, 1], whose interpretation is that the vehicle has a maximum turning speed of 1 wheel / s. To illustrate our method, we choose the Dubins car. Since the model is only three-dimensional, we can check our results by comparing them with those achieved via HJ accessibility. In our example, we have selected many different starting states x-L for the system. As the origin, the target state xL is chosen."}, {"heading": "5.2 Control Primitives", "text": "In [19], the author shows that all optimal trajectories of the Dubins car use controls that represent a straight exit or a maximum left or right curve. Thus, the set of controls valid for generating optimal trajectories can be reduced to three motion primitives, {\"L,\" \"S,\" \"R\"}, encoding the controls u = 1 (max left), u = 0 (even) or u = \u2212 1 (max right), respectively. Furthermore, [19] also shows that the optimal control for each given x \"and xL is a sequence of a maximum of three of these motion primitives. In other words, the optimal control for a given target state is simply a permutation of {\" L, \"\" S, \"\" R \"} with a reasonable time period associated with each primitive. Since these motion primitives coincide with arcs and line segments, the optimal control for a given target state can be written as {tractories} for three car segments."}, {"heading": "5.3 Neural Network", "text": "Using the RRNN architecture described in Section 3.1, we allow N = 3 because we need a maximum of three control primitives. As the control and dynamics of Dubin's car are simple, we have chosen the hidden sizes P, D, U, X to [10, 10, 6, 75] or. NN is trained with the training functionality of MATLAB Neural Network ToolBox 2016. The training function used for the full NN is resistant and the performance function used is a rectangular error."}, {"heading": "5.4 Neural Network Training", "text": "In fact, it is very likely that the solution can be found in the entire corridor, since the region does not have dynamically realizable trajectories. Before dynamic training, we first initialize the weights WX. This is done using the Dataset D1, which is generated by random sampling methods. It is unlikely that the solution can be found in the entire corridor, since the region does not have dynamically realizable trajectories. Before dynamic training, we initialized the weights WX. We use the Dataset D1, which is generated by random sampling effects."}, {"heading": "5.5 Dubins Car Results", "text": "5.5.1 Training Process In Fig. 6a, 6b, 6c, the process by which the training set Xchanges from the initial training set D2 to a -ball around x = (15, 12, 3) is shown. Here, the red states represent the set E and the black states represent the states in X. In theearly iterations (Fig. 6a), the NN explores outward from the initial training set, frequently making errors, resulting in the states in X being very far away from x. As the number of iterations increases, the training set D2 is filtered out, and finally the NN tends to control the output control of the computing power. (\u00b7) that produced states x-i in an arc. This can be seen in Fig. 6b. At the end of the training process, the RO conical target filter prunes the states outside the -ball. This can be seen in Fig. 6c.5.2 TTR Value Comparison The true TTR values (x) and the computational performance are the unaffected TTR-TTR."}, {"heading": "6. CONCLUSIONS AND FUTURE WORK", "text": "Our NN-based grid-free method calculates an upper limit of optimal TTR function in a region of the state that contains the initial state, target, and practicable trajectory. By combining the strengths of dynamic programming-based and machine-learning approaches, we alleviate the curse of dimensionality while maintaining a desired direction of conservatism, and effectively avoid the shortcomings of both approaches. Using a numerical example, we show that our approach can successfully generate near-optimal TTR values for the Dubins car in several test cases. Since our method is grid-free, the estimated TTR values are in some cases even smaller than those calculated by level-based methods suffering from discretization errors. In addition, we are able to approximate TTR values in regions that are very far from the target, which is a very computationally intensive task for dynamic function-based approaches currently required in the car."}, {"heading": "7. REFERENCES", "text": "[1] Adler, A., Bar-Gill, A., and Shimkin, N. Optimalflight paths for engine-out emergency landing. In Proceedings of the 2012 24th Chinese Control and Decision Conference, CCDC 2012 (May 2012), IEEE, pp. 2908-2915. [2] Allen, R. E., Clark, A., Starek, J. A., and Pavone, M. A Machine Learning Approach for Real-Time Reachability Analysis Ross. In International Conference on Intelligent Robots and Systems (sep 2014), no. Iros, IEEE, pp. 2202-2208. [3] Amazon Prime Air. http: / www.amazon.com / b? node = 8037720011. Accessed: 2016-10-09. [4] AUVSI News. UAS Aid in South Carolina Tornado Investigation."}], "references": [{"title": "Optimal flight paths for engine-out emergency landing", "author": ["A. Adler", "A. Bar-Gill", "N. Shimkin"], "venue": "In Proceedings of the 2012 24th Chinese Control and Decision Conference,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2012}, {"title": "A Machine Learning Approach for Real-Time Reachability Analysis Ross", "author": ["R.E. Allen", "A.A. Clark", "J.A. Starek", "M. Pavone"], "venue": "In International Conference on Intelligent Robots and Systems (sep", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2014}, {"title": "Differential games with maximum cost", "author": ["E.N. Barron"], "venue": "Nonlinear Analysis", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1990}, {"title": "The Bellman equation for minimizing the maximum cost", "author": ["E.N. Barron", "H. Ishii"], "venue": "Nonlinear Analysis 13,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1989}, {"title": "Google plans drone delivery service for 2017", "author": ["BBC News"], "venue": "http://www.bbc.co.uk/news/technology-34704868", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2015}, {"title": "Intelligent optimal control with dynamic neural networks", "author": ["Y. Becerikli", "A.F. Konar", "T. Samad"], "venue": "Neural networks : the official journal of the International Neural Network Society", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2003}, {"title": "Reachability and Minimal Times for State Constrained Nonlinear Problems without Any Controllability Assumption", "author": ["O. Bokanowski", "N. Forcadel", "H. Zidani"], "venue": "SIAM Journal on Control and Optimization", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2010}, {"title": "Minimal time problems with moving targets and obstacles", "author": ["O. Bokanowski", "H. Zidani"], "venue": "IFAC Proceedings Volumes (IFAC-PapersOnline) 18, PART", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2011}, {"title": "Fast Reachable Set Approximations via State Decoupling Disturbances", "author": ["M. Chen", "S. Herbert", "C.J. Tomlin"], "venue": "In 55th IEEE Conference on Decision and Control (to appear)", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2016}, {"title": "Safe platooning of unmanned aerial vehicles via reachability", "author": ["M. Chen", "Q. Hu", "C. Mackin", "J.F. Fisac", "C.J. Tomlin"], "venue": "In 2015 54th IEEE Conference on Decision and Control (CDC) (dec 2015), vol. 2016-Febru,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2016}, {"title": "Viscosity solutions of Hamilton-Jacobi equations", "author": ["M.G. Crandall", "Lions", "P.-l"], "venue": "Transactions of the American Mathematical Society 277,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1983}, {"title": "Algorithms for overcoming the curse of dimensionality for certain Hamilton\u00e2\u0102\u015eJacobi equations arising in control theory and elsewhere", "author": ["J. Darbon", "S. Osher"], "venue": "Research in the Mathematical Sciences", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2016}, {"title": "Reachability calculations for automated aerial refueling", "author": ["J. Ding", "J. Sprinkle", "S.S. Sastry", "C.J. Tomlin"], "venue": "In Proceedings of the IEEE Conference on Decision and Control (Cancun, Mexico,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2008}, {"title": "Neural approximation of PDE solutions: An application to reachability computations", "author": ["B. Djeridane", "J. Lygeros"], "venue": "In Proceedings of the 45th IEEE Conference on Decision and Control (2006),", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2006}, {"title": "Parallelotope Bundles for Polynomial Reachability", "author": ["T. Dreossi", "T. Dang", "C. Piazza"], "venue": "Proceedings of the 19th International Conference on Hybrid Systems: Computation and Control - HSCC \u201916", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2016}, {"title": "On Curves of Minimal Length with a Constraint on Average Curvature, and with Prescribed Initial and Terminal Positions and Tangents", "author": ["L.E. Dubins"], "venue": "American Journal of Mathematics 79,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1957}, {"title": "Differential games and representation formulas for solutions of {Hamilton-Jacobi-Isaacs} equations", "author": ["L.C. Evans", "P.E. Souganidis"], "venue": "Indiana Univ. Math. J. 33,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1984}, {"title": "Feds Say Safety Is the Key to the Future of Autonomous Cars", "author": ["K. Fehrenbacher"], "venue": "http://fortune.com/ 2016/07/19/safety-feds-autonomous-cars/", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2016}, {"title": "Reach-avoid problems with time-varying dynamics, targets and constraints", "author": ["J.F. Fisac", "M. Chen", "C.J. Tomlin", "S.S. Sastry"], "venue": "In Proceedings of the 18th International Conference on Hybrid Systems Computation and Control - HSCC", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2015}, {"title": "Nonlinear Flight Control Using Neural Networks", "author": ["B.S. Kim", "A.J. Calise"], "venue": "Journal of Guidance, Control, and Dynamics 20,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1997}, {"title": "Convex optimization of nonlinear feedback controllers via occupation measures", "author": ["A. Majumdar", "R. Vasudevan", "M.M. Tobenkin", "R. Tedrake"], "venue": "The International Journal of Robotics Research", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2014}, {"title": "Hamilton-Jacobi Formulation for Reach-Avoid Differential Games", "author": ["K. Margellos", "J. Lygeros"], "venue": "IEEE Transactions on Automatic Control", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2011}, {"title": "Air Combat Strategy Using Approximate Dynamic Programming. AIAA Guidance, Navigation and Control Conference and Exhibit (aug", "author": ["J. McGrew", "L. Bush", "J. How", "N. Roy", "B. Williams"], "venue": null, "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2008}, {"title": "A toolbox of level set methods", "author": ["I. Mitchell"], "venue": "Tech. rep.,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2007}, {"title": "A time-dependent Hamilton-Jacobi formulation of reachable sets for continuous dynamic games", "author": ["I.M. Mitchell", "A.M. Bayen", "C.J. Tomlin"], "venue": "IEEE Transactions on Automatic Control 50,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2005}, {"title": "Overapproximating Reachable Sets by Hamilton-Jacobi Projections", "author": ["I.M. Mitchell", "C.J. Tomlin"], "venue": "Journal of Scientific Computing 19,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2003}, {"title": "A Neural Approximation to Continuous Time Reachability Computations", "author": ["K.N. Niarchos", "J. Lygeros"], "venue": "In Proceedings of the 45th IEEE Conference on Decision and Control (2006),", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2006}, {"title": "A fast marching level set method for monotonically advancing fronts", "author": ["J.A. Sethian"], "venue": "Pnas 93,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 1996}, {"title": "A Game Theoretic Approach to Controller Design for Hybrid Systems", "author": ["C.J. Tomlin", "J. Lygeros", "S. Sastry"], "venue": "Proceedings of IEEE 88,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2000}, {"title": "On the existence of solutions to a differential game", "author": ["P. Varaiya"], "venue": "SIAM Journal on Control", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 1967}, {"title": "One-shot computation of reachable sets for differential games. In Proceedings of the 16th international conference on Hybrid systems: computation and control - HSCC", "author": ["I. Yang", "S. Becker-Weimann", "M.J. Bissell", "C.J. Tomlin"], "venue": null, "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2013}], "referenceMentions": [{"referenceID": 4, "context": "In particular, there has been vast interest in the development of autonomous cars and unmanned aerial vehicles (UAVs) for civilian purposes [3,4,7,21,23,25].", "startOffset": 140, "endOffset": 156}, {"referenceID": 17, "context": "In particular, there has been vast interest in the development of autonomous cars and unmanned aerial vehicles (UAVs) for civilian purposes [3,4,7,21,23,25].", "startOffset": 140, "endOffset": 156}, {"referenceID": 2, "context": "It has been extensively studied in [5, 9, 20, 22, 27, 30, 35, 36], and successfully applied to many lowdimensional real world systems [12,16,30].", "startOffset": 35, "endOffset": 65}, {"referenceID": 6, "context": "It has been extensively studied in [5, 9, 20, 22, 27, 30, 35, 36], and successfully applied to many lowdimensional real world systems [12,16,30].", "startOffset": 35, "endOffset": 65}, {"referenceID": 16, "context": "It has been extensively studied in [5, 9, 20, 22, 27, 30, 35, 36], and successfully applied to many lowdimensional real world systems [12,16,30].", "startOffset": 35, "endOffset": 65}, {"referenceID": 18, "context": "It has been extensively studied in [5, 9, 20, 22, 27, 30, 35, 36], and successfully applied to many lowdimensional real world systems [12,16,30].", "startOffset": 35, "endOffset": 65}, {"referenceID": 21, "context": "It has been extensively studied in [5, 9, 20, 22, 27, 30, 35, 36], and successfully applied to many lowdimensional real world systems [12,16,30].", "startOffset": 35, "endOffset": 65}, {"referenceID": 24, "context": "It has been extensively studied in [5, 9, 20, 22, 27, 30, 35, 36], and successfully applied to many lowdimensional real world systems [12,16,30].", "startOffset": 35, "endOffset": 65}, {"referenceID": 28, "context": "It has been extensively studied in [5, 9, 20, 22, 27, 30, 35, 36], and successfully applied to many lowdimensional real world systems [12,16,30].", "startOffset": 35, "endOffset": 65}, {"referenceID": 29, "context": "It has been extensively studied in [5, 9, 20, 22, 27, 30, 35, 36], and successfully applied to many lowdimensional real world systems [12,16,30].", "startOffset": 35, "endOffset": 65}, {"referenceID": 9, "context": "It has been extensively studied in [5, 9, 20, 22, 27, 30, 35, 36], and successfully applied to many lowdimensional real world systems [12,16,30].", "startOffset": 134, "endOffset": 144}, {"referenceID": 12, "context": "It has been extensively studied in [5, 9, 20, 22, 27, 30, 35, 36], and successfully applied to many lowdimensional real world systems [12,16,30].", "startOffset": 134, "endOffset": 144}, {"referenceID": 24, "context": "It has been extensively studied in [5, 9, 20, 22, 27, 30, 35, 36], and successfully applied to many lowdimensional real world systems [12,16,30].", "startOffset": 134, "endOffset": 144}, {"referenceID": 14, "context": "For example, one method requires the system dynamics to be polynomial [18, 26], while another method requires the Hamiltonian to be a function of only the controlled variable [15].", "startOffset": 70, "endOffset": 78}, {"referenceID": 20, "context": "For example, one method requires the system dynamics to be polynomial [18, 26], while another method requires the Hamiltonian to be a function of only the controlled variable [15].", "startOffset": 70, "endOffset": 78}, {"referenceID": 11, "context": "For example, one method requires the system dynamics to be polynomial [18, 26], while another method requires the Hamiltonian to be a function of only the controlled variable [15].", "startOffset": 175, "endOffset": 179}, {"referenceID": 8, "context": "There are also less restrictive methods using projections, approximate dynamic programming, and approximate systems decoupling [11, 28, 31], each with its own limitations in flexibility, scalability, and degree of conservatism.", "startOffset": 127, "endOffset": 139}, {"referenceID": 22, "context": "There are also less restrictive methods using projections, approximate dynamic programming, and approximate systems decoupling [11, 28, 31], each with its own limitations in flexibility, scalability, and degree of conservatism.", "startOffset": 127, "endOffset": 139}, {"referenceID": 25, "context": "There are also less restrictive methods using projections, approximate dynamic programming, and approximate systems decoupling [11, 28, 31], each with its own limitations in flexibility, scalability, and degree of conservatism.", "startOffset": 127, "endOffset": 139}, {"referenceID": 5, "context": "For instance, [8] and [24] use neural networks (NNs) as nonlinear optimizers to synthesize trajectories which may not be dynamically feasible.", "startOffset": 14, "endOffset": 17}, {"referenceID": 19, "context": "For instance, [8] and [24] use neural networks (NNs) as nonlinear optimizers to synthesize trajectories which may not be dynamically feasible.", "startOffset": 22, "endOffset": 26}, {"referenceID": 1, "context": "The authors in [2] propose a supervised learningbased algorithm that depends heavily on feature tuning and design, making its application to high-dimensional problems cumbersome.", "startOffset": 15, "endOffset": 18}, {"referenceID": 13, "context": "In [17] and [32], the authors successfully use NNs for approximating the value function, but the approximation is not guaranteed to be conservative.", "startOffset": 3, "endOffset": 7}, {"referenceID": 26, "context": "In [17] and [32], the authors successfully use NNs for approximating the value function, but the approximation is not guaranteed to be conservative.", "startOffset": 12, "endOffset": 16}, {"referenceID": 3, "context": "There are many HJ formulations for obtaining the TTR function \u03c6(x) [6, 10, 30].", "startOffset": 67, "endOffset": 78}, {"referenceID": 7, "context": "There are many HJ formulations for obtaining the TTR function \u03c6(x) [6, 10, 30].", "startOffset": 67, "endOffset": 78}, {"referenceID": 24, "context": "There are many HJ formulations for obtaining the TTR function \u03c6(x) [6, 10, 30].", "startOffset": 67, "endOffset": 78}, {"referenceID": 10, "context": "For example, \u03c6(x) is the viscosity solution [13] of the following HJ PDE [37]:", "startOffset": 44, "endOffset": 48}, {"referenceID": 30, "context": "For example, \u03c6(x) is the viscosity solution [13] of the following HJ PDE [37]:", "startOffset": 73, "endOffset": 77}, {"referenceID": 30, "context": "In general, numerical methods for finding \u03c6(x) such as the one outlined in [37], as well as many others [29, 33, 34], involve representing the state space on a grid, leading to an exponentially scaling computation complexity with respect to the system dimension.", "startOffset": 75, "endOffset": 79}, {"referenceID": 23, "context": "In general, numerical methods for finding \u03c6(x) such as the one outlined in [37], as well as many others [29, 33, 34], involve representing the state space on a grid, leading to an exponentially scaling computation complexity with respect to the system dimension.", "startOffset": 104, "endOffset": 116}, {"referenceID": 27, "context": "In general, numerical methods for finding \u03c6(x) such as the one outlined in [37], as well as many others [29, 33, 34], involve representing the state space on a grid, leading to an exponentially scaling computation complexity with respect to the system dimension.", "startOffset": 104, "endOffset": 116}, {"referenceID": 13, "context": "{x\u0302i} is randomly generated using an accept-reject algorithm similar to the one in [17] and described in Alg.", "startOffset": 83, "endOffset": 87}, {"referenceID": 15, "context": "In [19], the author shows that all optimal trajectories of the Dubins car utilize controls that represent going straight or turning maximally left or right.", "startOffset": 3, "endOffset": 7}, {"referenceID": 15, "context": "Furthermore, [19] also shows that for any given x\u0304 and xL, the optimal control is a sequence of at most three of these motion primitives.", "startOffset": 13, "endOffset": 17}, {"referenceID": 7, "context": "Since the controls and dynamics of Dubins car are simple, we have chosen the hidden sizes of P,D,U,X to be [10, 10, 6, 75], respectively.", "startOffset": 107, "endOffset": 122}, {"referenceID": 7, "context": "Since the controls and dynamics of Dubins car are simple, we have chosen the hidden sizes of P,D,U,X to be [10, 10, 6, 75], respectively.", "startOffset": 107, "endOffset": 122}, {"referenceID": 3, "context": "Since the controls and dynamics of Dubins car are simple, we have chosen the hidden sizes of P,D,U,X to be [10, 10, 6, 75], respectively.", "startOffset": 107, "endOffset": 122}, {"referenceID": 0, "context": "We currently plan to investigate applying our method to the 6D engine-out plane [1] as well as a 12D quadrotor model.", "startOffset": 80, "endOffset": 83}], "year": 2017, "abstractText": "Hamilton-Jacobi (HJ) reachability is a powerful tool that provides performance and safety guarantees for dynamical systems. Unfortunately, using the state-of-the-art dynamic programming-based approaches, HJ reachability is intractable for systems with more than five dimensions because its computational complexity scales exponentially with system dimension. To sidestep the curse of dimensionality, we propose an algorithm that leverages a neural network to approximate the minimum time-to-reach function to synthesize controls. We show that our neural network generates near optimal controls which are guaranteed to successfully drive the system to a target state. Our framework is not dependent on state space discretization, leading to a significant reduction in computation time and space complexity in comparison with dynamic programming-based approaches. Using this grid-free approach also enables us to plan over longer time horizons with relatively little additional computation overhead. Unlike many previous neural network reachability formulations, our approximation is conservative and hence any trajectories we generate will be strictly feasible. For demonstration, we specialize our new general framework to the Dubins car model and discuss how the general framework can be applied to other models with higher-dimensional state spaces.", "creator": "LaTeX with hyperref package"}}}