{"id": "1611.03279", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Nov-2016", "title": "Tracing metaphors in time through self-distance in vector spaces", "abstract": "From a diachronic corpus of Italian, we build consecutive vector spaces in time and use them to compare a term's cosine similarity to itself in different time spans. We assume that a drop in similarity might be related to the emergence of a metaphorical sense at a given time. Similarity-based observations are matched to the actual year when a figurative meaning was documented in a reference dictionary and through manual inspection of corpus occurrences.", "histories": [["v1", "Thu, 10 Nov 2016 12:22:43 GMT  (136kb,D)", "http://arxiv.org/abs/1611.03279v1", "Proceedings of the Third Italian Conference on Computational Linguistics (CLIC 2016)"]], "COMMENTS": "Proceedings of the Third Italian Conference on Computational Linguistics (CLIC 2016)", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["marco del tredici", "malvina nissim", "andrea zaninello"], "accepted": false, "id": "1611.03279"}, "pdf": {"name": "1611.03279.pdf", "metadata": {"source": "CRF", "title": "Tracing metaphors in time through self-distance in vector spaces", "authors": ["Marco Del Tredici", "Malvina Nissim", "Andrea Zaninello"], "emails": ["marcodeltredici@gmail.com", "m.nissim@rug.nl", "azaninello@zanichelli.it"], "sections": [{"heading": null, "text": "Italiano. Nel presente esperimento costruiamo spazi vettoriali progressivi nel tempo su un corpus diacronico dell'italiano e calcoliamo la distanza di alcuni termini rispetto a loro stessi in different periodi. L'ipotesi e che un calo di similitudine possa essere indicativo dell'acquisizione di un significant metaforico. Tale ipotesi e valutata attraverso una risorsa lessicografica esterna e l'annotazione manuale dei contesti dei termini nel corpus."}, {"heading": "1 Introduction", "text": "It is generally accepted that metaphors are widely used, and that their recognition and interpretation are crucial for language processing (Group, 2007; Turney et al., 2011; Shutova, 2015).A delicate aspect of metaphors is their dynamic nature: new metaphors are created all the time. In recent years, the Italian term \"talebano\" (\"Taliban\"), which has so far only been used to refer to the Islamic fundamentalist political movement in Afghanistan in the 1990s, has led to someone who is extreme in his positions defining l'operazione in terms of food, the use of medicines and the like (Example 2)."}, {"heading": "2 Approach", "text": "According to the principle of distributional semantics, the meaning of a word is represented by vectors that encode the contextual information of that word in a corpus (Turney et al., 2010). All vectors that represent words are located in a distributional semantic space in which similar words are represented by vectors that are close in that space, while other words are not yet removed. We rely on the intuition that when a term develops a metaphorical sense, its contexts of events begin to differ, at least partially, from those observed for the same term, the metaphorical meaning has not yet arisen. This implies that tracking a distance in space over time could represent a shift in meaning. Instead of synchronously comparing different terms, we focus on their self-removal over time, pursuing their diachronic evolution of meaning."}, {"heading": "3 Related Work", "text": "Automatic modeling of diachronic shifts in meaning has been studied using various techniques, most recently latent semantic analysis (Sagi et al., 2011; Jatowt and Duh, 2014), theme clustering (Wijaya and Yeniterzi, 2011), and dynamic theme modeling (Frermann and Lapata, 2016). Vector representations of diachronic shifts in meaning have been used by Gulordava and Baroni (2011), using a simple random matrix of target words and context terms. Jatowt and Duh (2014) and Xu and Kemp (2015) experimented with both a sack-of-word approach and a linguistically motivated representation, which also includes the relative position of lexical objects in relation to the target words.Recently, word embeddings (Mikolov and Dean (2013) have been used to investigate ecronic shifts in meaning."}, {"heading": "4 Experiment", "text": "Following the approach described in Section 2, we selected a small set of pilot terms from a lexicographic reference and observed their spatial evolution over time on a diachronic corpus of Italian that we had collected for this purpose. Since there are no datasets in which words are commented on to change meaning, a qualitative analysis of a set of hand-selected words such as we suggest has become established as a common evaluation method in previous work on diachronic change of meaning (Frermann and Lapata, 2016)."}, {"heading": "4.1 Lexicographic reference and term selection", "text": "The Zingarelli Dictionary is a reference dictionary for the Italian language that is updated and published each year, both in digital and paper versions. Traditionally, the dictionary is dated one year before the year of publication, so the Zingarelli Dictionary will appear in June 2016, and it refers to decisions on new words and new meanings (including metaphorical ones) made up to December 2015. We analyzed the behavior of a small group of terms extracted from the dictionary. We searched the 2017 edition to extract nouns that have a figurative meaning and limited our search to words whose first appearance is recorded in the 20th or 21st century. Newborn words (including bonds) are more likely to exhibit a shift in meaning in the period of time that is taken into account in our search (1984-2015) than older words (especially if they come directly from Latin, where the figurative meaning was also originally highly available, so that the sense of probability occurs)."}, {"heading": "4.2 Corpus", "text": "By collecting articles from the Italian newspaper la Repubblica from 1984 (the first year for which data is digitally available) to 2015, we created a diachronic corpus of about 60 million tokens. All texts were shortened and shortened. Interested in how the context of a term changes over time, we had to determine time spans for our corpus and agree on biennial blocks for a total of 16 periods, the first being 1984-1985 and the last 2014-2015. These sub-corpus are used to train successive vector space models."}, {"heading": "4.3 Model", "text": "These representations (Word Embeddings) are low-dimensional, dense and real-valued vectors that have been proven to receive syntactic and semantic information in multiple NLP tasks (Baroni et al., 2014).Vectors created on different corpora cannot be directly compared, since each semantic space implements arbitrary orthogonal transformations, and therefore there is no direct agreement between word vectors in different semantic spaces (Zhang et al., 2015).This would also apply to our data, since we create a different corpus for each time span. Therefore, in order to create comparable vector representations for each word in any time span, we adopt the methodology introduced by Kim et al. (2014) (see Section 3) by slightly modifying them."}, {"heading": "4.4 Results and discussion", "text": "This year, the time has come for only one person to be able to decide whether he will be able to play by the rules or whether he will be able to play by the rules."}, {"heading": "5 Conclusion and future work", "text": "This work was intended as an exploration of the assumption that the emergence of the metaphorical use of a term could be reflected in changes in the cosine similarity of the term to itself over time. This assumption was partially confirmed by comparing it to the Zingarelli dictionary, while we found more robust evidence in manual verification of the contexts of use of the terms. Future work will result from the methodology and observations discussed here. Specifically, we plan to examine other aspects of this initial work, including the relationship between changes in cosmic similarity and the frequency of use of a word: To what extent does a change in the term correlate to an increase in the term? Mostly, however, we plan to conduct experiments on larger vocabulary sets in order to develop the mainly qualitative observations reported here with a view to the development of reliable predictive metrics that can serve to automatically and completely detect the occurrence of shifts from bottom to top."}, {"heading": "Acknowledgments", "text": "Malvina Nissim would like to thank the ILC-CNR ItaliaNLP Lab for their hospitality during the work on this project and the anonymous reviewers who have made revealing comments that have undoubtedly contributed to the improvement of this work."}], "references": [{"title": "Don\u2019t count, predict! a systematic comparison of context-counting vs. context-predicting semantic vectors", "author": ["Baroni et al.2014] Marco Baroni", "Georgiana Dinu", "Germ\u00e1n Kruszewski"], "venue": "In Proceedings of the 52nd Annual Meeting of the Association", "citeRegEx": "Baroni et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Baroni et al\\.", "year": 2014}, {"title": "A bayesian model of diachronic meaning change. Transactions of the Association for Computational Linguistics, 4:31\u201345", "author": ["Frermann", "Lapata2016] Lea Frermann", "Mirella Lapata"], "venue": null, "citeRegEx": "Frermann et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Frermann et al\\.", "year": 2016}, {"title": "A distributional similarity approach to the detection of semantic change in the Google books ngram corpus", "author": ["Gulordava", "Baroni2011] Kristina Gulordava", "Marco Baroni"], "venue": "In Proceedings of the GEMS 2011 Workshop on GEometrical Models", "citeRegEx": "Gulordava et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Gulordava et al\\.", "year": 2011}, {"title": "Diachronic word embeddings reveal statistical laws of semantic change", "author": ["Jure Leskovec", "Dan Jurafsky"], "venue": "arXiv preprint arXiv:1605.09096", "citeRegEx": "Hamilton et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Hamilton et al\\.", "year": 2016}, {"title": "Automatic extraction of linguistic metaphor with LDA topic modeling", "author": ["Heintz et al.2013] Ilana Heintz", "Ryan Gabbard", "Mahesh Srinivasan", "David Barner", "Donald S Black", "Marjorie Freedman", "Ralph Weischedel"], "venue": "Proceedings of the First", "citeRegEx": "Heintz et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Heintz et al\\.", "year": 2013}, {"title": "Identifying metaphorical word use with tree kernels", "author": ["Hovy et al.2013] Dirk Hovy", "Shashank Srivastava", "Sujay Kumar Jauhar", "Mrinmaya Sachan", "Kartik Goyal", "Huiying Li", "Whitney Sanders", "Eduard Hovy"], "venue": "In Proceedings of the First Workshop", "citeRegEx": "Hovy et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Hovy et al\\.", "year": 2013}, {"title": "A framework for analyzing semantic change of words across time", "author": ["Jatowt", "Duh2014] Adam Jatowt", "Kevin Duh"], "venue": "In Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries,", "citeRegEx": "Jatowt et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Jatowt et al\\.", "year": 2014}, {"title": "Temporal analysis of language through neural language models", "author": ["Kim et al.2014] Yoon Kim", "Yi-I Chiu", "Kentaro Hanaki", "Darshan Hegde", "Slav Petrov"], "venue": "In Proceedings of the ACL 2014 Workshop on Language Technologies and Computational So-", "citeRegEx": "Kim et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kim et al\\.", "year": 2014}, {"title": "Statistically significant detection of linguistic change", "author": ["Rami Al-Rfou", "Bryan Perozzi", "Steven Skiena"], "venue": "In Proceedings of the 24th International Conference on World Wide Web,", "citeRegEx": "Kulkarni et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kulkarni et al\\.", "year": 2015}, {"title": "Distributed representations of words and phrases and their compositionality. Advances in neural information processing systems", "author": ["Mikolov", "Dean2013] T Mikolov", "J Dean"], "venue": null, "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Software Framework for Topic Modelling with Large Corpora", "author": ["\u0158eh\u016f\u0159ek", "Sojka2010] Radim \u0158eh\u016f\u0159ek", "Petr Sojka"], "venue": "In Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks,", "citeRegEx": "\u0158eh\u016f\u0159ek et al\\.,? \\Q2010\\E", "shortCiteRegEx": "\u0158eh\u016f\u0159ek et al\\.", "year": 2010}, {"title": "Tracing semantic change with latent semantic analysis", "author": ["Sagi et al.2011] Eyal Sagi", "Stefan Kaufmann", "Brady Clark"], "venue": "Current methods in historical semantics,", "citeRegEx": "Sagi et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Sagi et al\\.", "year": 2011}, {"title": "Unsupervised metaphor identification using hierarchical graph factorization clustering", "author": ["Shutova", "Sun2013] Ekaterina Shutova", "Lin Sun"], "venue": "In HLTNAACL,", "citeRegEx": "Shutova et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Shutova et al\\.", "year": 2013}, {"title": "Design and evaluation of metaphor processing systems", "author": ["Ekaterina Shutova"], "venue": "Computational Linguistics,", "citeRegEx": "Shutova.,? \\Q2015\\E", "shortCiteRegEx": "Shutova.", "year": 2015}, {"title": "From frequency to meaning: Vector space models of semantics", "author": ["Patrick Pantel"], "venue": "Journal of artificial intelligence research,", "citeRegEx": "Turney and Pantel,? \\Q2010\\E", "shortCiteRegEx": "Turney and Pantel", "year": 2010}, {"title": "Literal and metaphorical sense identification through concrete and abstract context", "author": ["Yair Neuman", "Dan Assaf", "Yohai Cohen"], "venue": "In Proceedings of the 2011 Conference on the Empirical Methods in Natural", "citeRegEx": "Turney et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Turney et al\\.", "year": 2011}, {"title": "Understanding semantic change of words over centuries", "author": ["Wijaya", "Reyyan Yeniterzi"], "venue": "In Proceedings of the 2011 international workshop on DETecting and Exploiting Cultural diversiTy on the social web,", "citeRegEx": "Wijaya et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Wijaya et al\\.", "year": 2011}, {"title": "A computational evaluation of two laws of semantic change", "author": ["Xu", "Kemp2015] Y. Xu", "C. Kemp"], "venue": "In Proceedings of the 37th Annual Conference of the Cognitive Science Society", "citeRegEx": "Xu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Xu et al\\.", "year": 2015}, {"title": "Omnia mutantur, nihil interit: Connecting past with present by finding corresponding terms across time", "author": ["Zhang et al.2015] Yating Zhang", "Adam Jatowt", "Sourav S Bhowmick", "Katsumi Tanaka"], "venue": "In Proc. of ACL,", "citeRegEx": "Zhang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2015}, {"title": "1993\u20132017. Lo Zingarelli - Vocabolario della lingua italiana", "author": ["N. Zingarelli"], "venue": "Zanichelli editore,", "citeRegEx": "Zingarelli.,? \\Q2017\\E", "shortCiteRegEx": "Zingarelli.", "year": 2017}], "referenceMentions": [{"referenceID": 15, "context": "It is widely acknowledged that metaphors are pervasive in language use, and that their detection and interpretation are crucial to language processing (Group, 2007; Turney et al., 2011; Shutova, 2015).", "startOffset": 151, "endOffset": 200}, {"referenceID": 13, "context": "It is widely acknowledged that metaphors are pervasive in language use, and that their detection and interpretation are crucial to language processing (Group, 2007; Turney et al., 2011; Shutova, 2015).", "startOffset": 151, "endOffset": 200}, {"referenceID": 4, "context": "Most of the computational work on metaphors has focused on their identification and interpretation using a variety of techniques and models, such as clustering (Shutova and Sun, 2013), LDA topic modeling (Heintz et al., 2013), tree kernels (Hovy et al.", "startOffset": 204, "endOffset": 225}, {"referenceID": 5, "context": ", 2013), tree kernels (Hovy et al., 2013), but all from a purely synchronic perspective.", "startOffset": 22, "endOffset": 41}, {"referenceID": 13, "context": "For a detailed survey on current NLP systems for metaphor modeling see (Shutova, 2015).", "startOffset": 71, "endOffset": 86}, {"referenceID": 11, "context": "Among these, most recently, Latent Semantic Analysis (Sagi et al., 2011; Jatowt and Duh, 2014), topic clustering (Wijaya and Yeniterzi, 2011) and dynamic topic modeling (Frermann and Lapata, 2016).", "startOffset": 53, "endOffset": 94}, {"referenceID": 11, "context": "Among these, most recently, Latent Semantic Analysis (Sagi et al., 2011; Jatowt and Duh, 2014), topic clustering (Wijaya and Yeniterzi, 2011) and dynamic topic modeling (Frermann and Lapata, 2016). Vector representations for diachronic shift of meaning have been used by Gulordava and Baroni (2011), with a simple cooccurence matrix of target words and context terms.", "startOffset": 54, "endOffset": 299}, {"referenceID": 11, "context": "Among these, most recently, Latent Semantic Analysis (Sagi et al., 2011; Jatowt and Duh, 2014), topic clustering (Wijaya and Yeniterzi, 2011) and dynamic topic modeling (Frermann and Lapata, 2016). Vector representations for diachronic shift of meaning have been used by Gulordava and Baroni (2011), with a simple cooccurence matrix of target words and context terms. Jatowt and Duh (2014) and Xu and Kemp (2015) experimented both with a bag-of-words approach and a more linguistically motivated representation that also captures the relative position of lexical items in relation to the target word.", "startOffset": 54, "endOffset": 390}, {"referenceID": 11, "context": "Among these, most recently, Latent Semantic Analysis (Sagi et al., 2011; Jatowt and Duh, 2014), topic clustering (Wijaya and Yeniterzi, 2011) and dynamic topic modeling (Frermann and Lapata, 2016). Vector representations for diachronic shift of meaning have been used by Gulordava and Baroni (2011), with a simple cooccurence matrix of target words and context terms. Jatowt and Duh (2014) and Xu and Kemp (2015) experimented both with a bag-of-words approach and a more linguistically motivated representation that also captures the relative position of lexical items in relation to the target word.", "startOffset": 54, "endOffset": 413}, {"referenceID": 7, "context": "An alternative approach, which we also adopt \u2013 with a slight change \u2013 in our work, is introduced by Kim et al. (2014), who propose a simple but effective methodology to make vectors trained on different corpora directly comparable: embeddings created for year y are used to initialise the vectors for year y+1.", "startOffset": 100, "endOffset": 118}, {"referenceID": 0, "context": "Such representations (Word Embeddings) are low dimensional, dense and real-valued vectors that have been proved to preserve syntactic and semantic information in several NLP tasks (Baroni et al., 2014).", "startOffset": 180, "endOffset": 201}, {"referenceID": 18, "context": "Vectors created on different corpora cannot be directly compared, since every semantic space implements arbitrary orthogonal transformations and hence there is no direct correspondence between word vectors in different semantic spaces (Zhang et al., 2015).", "startOffset": 235, "endOffset": 255}, {"referenceID": 7, "context": "Therefore, in order to create comparable vector representations for each word in any time span, we adopt the methodology introduced by Kim et al. (2014) (see Section 3), slightly modifying it.", "startOffset": 135, "endOffset": 153}, {"referenceID": 7, "context": "Therefore, in order to create comparable vector representations for each word in any time span, we adopt the methodology introduced by Kim et al. (2014) (see Section 3), slightly modifying it. While Kim et al. (2014) use vectors of span y to initialise the vectors for year y + 1, we do the opposite, i.", "startOffset": 135, "endOffset": 217}, {"referenceID": 7, "context": "Indeed, using Kim et al. (2014)\u2019s original approach, which we implemented in a preliminary experiment, the vectors for these words were correctly initialised, but were basically random vectors with no meaningful information.", "startOffset": 14, "endOffset": 32}], "year": 2016, "abstractText": "English. From a diachronic corpus of Italian, we build consecutive vector spaces in time and use them to compare a term\u2019s cosine similarity to itself in different time spans. We assume that a drop in similarity might be related to the emergence of a metaphorical sense at a given time. Similarity-based observations are matched to the actual year when a figurative meaning was documented in a reference dictionary and through manual inspection of corpus occurrences. Italiano. Nel presente esperimento costruiamo spazi vettoriali progressivi nel tempo su un corpus diacronico dell\u2019italiano e calcoliamo la distanza di alcuni termini rispetto a loro stessi in differenti periodi. L\u2019ipotesi \u00e8 che un calo di similitudine possa essere indicativo dell\u2019acquisizione di un significato metaforico. Tale ipotesi \u00e8 valutata attraverso una risorsa lessicografica esterna e l\u2019annotazione manuale dei contesti dei termini nel corpus.", "creator": "LaTeX with hyperref package"}}}