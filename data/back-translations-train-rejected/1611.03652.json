{"id": "1611.03652", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Nov-2016", "title": "Show me the material evidence: Initial experiments on evaluating hypotheses from user-generated multimedia data", "abstract": "Subjective questions such as `does neymar dive', or `is clinton lying', or `is trump a fascist', are popular queries to web search engines, as can be seen by autocompletion suggestions on Google, Yahoo and Bing. In the era of cognitive computing, beyond search, they could be handled as hypotheses issued for evaluation. Our vision is to leverage on unstructured data and metadata of the rich user-generated multimedia that is often shared as material evidence in favor or against hypotheses in social media platforms. In this paper we present two preliminary experiments along those lines and discuss challenges for a cognitive computing system that collects material evidence from user-generated multimedia towards aggregating it into some form of collective decision on the hypothesis.", "histories": [["v1", "Fri, 11 Nov 2016 10:46:58 GMT  (300kb,D)", "http://arxiv.org/abs/1611.03652v1", "6 pages, 6 figures, 3 tables in Proc. of the 1st Workshop on Multimedia Support for Decision-Making Processes, at IEEE Intl. Symposium on Multimedia (ISM'16), San Jose, CA, 2016"]], "COMMENTS": "6 pages, 6 figures, 3 tables in Proc. of the 1st Workshop on Multimedia Support for Decision-Making Processes, at IEEE Intl. Symposium on Multimedia (ISM'16), San Jose, CA, 2016", "reviews": [], "SUBJECTS": "cs.AI cs.DB cs.MM", "authors": ["bernardo gon\\c{c}alves"], "accepted": false, "id": "1611.03652"}, "pdf": {"name": "1611.03652.pdf", "metadata": {"source": "CRF", "title": "Show me the material evidence \u2014 Initial experiments on evaluating hypotheses from user-generated multimedia data", "authors": ["Bernardo Gon\u00e7alves"], "emails": ["begoncalves@acm.org"], "sections": [{"heading": null, "text": "In fact, we have large amounts of unstructured data to digest and come up with an answer to some interesting questions, such as whether a popular football player is \"dives\" or not \"dive\" in terms of general public opinion. In fact, such claims, whether in affirmative, negative or interrogative form, we are frequently represented in news feeds, microblogs and social media platforms, produced by an army of journalists, bloggers and ordinary people through their social media accounts."}, {"heading": "II. EXPERIMENT 1: PARSING CLAIMS FROM THE WEB", "text": "We begin the section with an introduction to the latest cognitive technologies we have used, as well as to our data collection process. We then present the first results."}, {"heading": "A. Data Collection from the Web", "text": "We will rely on social media data retrieved from a popular search engine. Specifically, we sent the hypotheses question about Neymar to search in three different forms: affirmative, negative and questioning insertions (or) \"Neymar is a diver,\" \"Neymar is not a diver\" and \"Does Neymar Dive?\" Among the three search results obtained, some results will overlap. We will combine the result sets by association and eliminate duplicates. In addition, we will repeat the search process twice, limiting it to each of two modalities, text and video. The results sets will then also be combined by the union, logging the media type.) Once we have in our database such social media data links / entries related to the target question (which is considered relevant by the search engine), we will perform some cognitive processing on them - essentially a Natural Language Processing (NL) data that we will then consider as the subject of each of them, and then we will claim them as the subject of their respective method."}, {"heading": "B. NLP-based Parsing and Validation of Claims", "text": "We use some of the state-of-the-art web mining and text analytics technologies available within a sentence to extract candidate claims from the web and validate them as a reference point for the target mortgage. Specifically, for Neymar's web mining task, which we have already used as a key term for ourselves, we have a pattern. 4 For the NLP core tasks, we have spaCy, 5 which is a fast and accurate API for multiple NLP tasks. 2 For each data link / entry that has a valid claim, the output we store is illustrated in the table. I.Given the natural language phrases extracted from the web to disambiguate them to the target structure. \""}, {"heading": "C. Web-Mined Claims: Preliminary results", "text": "Table II shows the preliminary results of this experiment. In addition to the aforementioned Neymar company, we have also operated our pipeline for two similarly named companies, Lionel Messi and Cristiano Ronaldo. The inclusion of these two other popular football players in the study provides us with a starting point. Some observations about the data shown in Table II are: \u2022 The number of validated claims is quite lower than the number of URLs returned by the search engine. This may be either due to too much precision in the evaluation of the claims or because the results of too many search engines are not so much related to the target claims. \u2022 Comparing the positive polarity proportions of the claims in text and video, the difference is (Neymar) + 21%, (Messi) + 8% and (Ronaldo) -4%. Interestingly, Neymar shows the higher difference. It could, say, indicate social science research whether the claims about the \"diver\" involve more passion than others. \u2022 Messi's quotas are remarkably low compared to the other two players."}, {"heading": "III. EXPERIMENT 2: CROWDSOURCING CLAIMS", "text": "In this section, we present the second experiment on our sample hypothesis: \"Is Neymar diving?.\" Instead of analyzing claims from the Internet, we have sent videos directly to crowdworkers questioning their assessment of the hypotheses. 6 Our goal here is to get a different perspective on the problem under more controlled conditions. Here, too, we will see if the data suggests that people can evaluate a hypothesis differently when they receive a certain piece of material evidence than what they would freely say without any material."}, {"heading": "A. Experimental Setup", "text": "The experiment was crowdsourced on the Microworkers.com platform on July 18th, 2015. For each instance of task (rating a video), we recruited 10 different workers. We evaluated a total of 11 videos (see next). Due to crowd greed, all 110 task instances were completed in less than 2 hours.Crowdtask design. Figure 5 shows our design for this crowd task. Before seeing a video, the workers had to explain their previous bias toward the hypothesis. A completed task was only accepted if the worker provided the correct answer to the \"gotcha\" subtask shown at the bottom of the form about Neymar's T-Shirts. Sample video selection. We searched on a popular social media platform for queries about \"neymar dives\" and classified the videos as high-ranking (top-30) through the search query. In an effort to find some balance of opinion about the hypothesis, we selected 11 videos that are both outsourced in the social media table and in their statistics."}, {"heading": "B. Crowdsourced Claims: Preliminary results", "text": "Looking at Table III (see below in the last two columns of the table), a comparison between the average (normalized) prior bias of workers and their average rating on each piece of evidence shows a difference of 10%. Opinions shift with respect to the physical evidence. Figure 6a shows a histogram of the stated prior bias (skeptical, neutral, supportive) of workers. Figure 6b shows a histogram of their overall ratings based on the evidence to which they were exposed (no diving, little, sometimes, many dives, massive dives). The third histogram (Figure 6c) results from the merging of containers from the histogram of Figure 6b: rates on containers \"no-dives\" and \"little-bit\" are transformed into skepticism, and those on containers \"many times\" and \"massive dives\" into supportive (Figure 6c)."}, {"heading": "IV. RESEARCH CHALLENGES", "text": "In fact, it is that they can only rely on the accumulated (material) evidence that they can use in their respective questions. (...) It is not as if they get involved in the way people do things. (...) It is not as if they get involved in the way people do things. (...) It is not as if they get involved in the way they do things. (...) It is not as if they do things, as if they do things. (...) It is not as if they do things. (...) It is not as if they do things, as if they do things. (...)"}, {"heading": "V. RELATED WORK", "text": "There is a fast-growing literature to support claims from the text, usually on the Web. However, we are not aware that previous work on the cognitive processing of multimedia data as essential evidence for a hypothesis. Here is a related work on certain aspects that are worth discussing. [http: / / www.youtube.com / watch? v = J13OPri3Ep0].Our work refers to the so-called \"Debate Technologies at IBM [11]. Your work is strongly based on the correlated text passages that can be distributed across a corpus."}, {"heading": "VI. CONCLUSIONS", "text": "In this paper, we have presented two preliminary experiments that represent a \"baby step\" toward assessing subjective hypotheses based on material evidence. If this research direction becomes practicable, it will be an important application for answering questions and cognitive computing in general.The most important finding we have studied is that while people have endless discussions about such subjective topics, they may be able to agree on the interpretation of a particular material evidence. If a data system collects evidence provided by multiple users, then cognitive computing could enable analysis and a current decision to answer such interesting subjective questions. We hope that this will become a new research front in the field of multimedia cognitive computing."}, {"heading": "ACKNOWLEDGEMENTS", "text": "I am grateful to Rafael Branda o and Ma rcio Moreno for their encouragement, and Roge rio de Paula for recently drawing my attention to the ambitious debator project at IBM Resarch. I am grateful to Prof. H. V. Jagadish for reading an earlier version of this manuscript and providing feedback in mid-2015."}], "references": [{"title": "Building Watson: an overview of the DeepQA Project", "author": ["D. Ferrucci"], "venue": "AI Magazine, vol. 31, no. 3, 2010.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2010}, {"title": "Mining subjective properties on the web", "author": ["I. Trummer", "A. Halevy", "H. Lee", "S. Sarawagi", "R. Gupta"], "venue": "ACM SIG- MOD\u201915, 2015, pp. 1745\u201360.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}, {"title": "An improved non-monotonic transition system for dependency parsing", "author": ["M. Honnibal", "M. Johnson"], "venue": "Proc. of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP), 2015, pp. 1373\u20131378.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2015}, {"title": "It depends: Dependency parser comparison using a web-based evaluation tool", "author": ["A.S.J.D. Choi", "J. Tetreault"], "venue": "Proc. of the 53rd Annual Meeting of the ACL and the 7th International Joint Conf. on NLP, 2015, pp. 387\u2013396.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2015}, {"title": "Guidelines for the CLEAR style constituent to dependency conversion guidelines for the clear style constituent to dependency conversion", "author": ["J.D. Choi", "M. Palmer"], "venue": "University of Colorado, Tech. Rep. 01-12, 2012.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2012}, {"title": "A guided tour to approximate string matching", "author": ["G. Navarro"], "venue": "ACM Computing Surveys, vol. 33, no. 1, pp. 31\u201388, 2001.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2001}, {"title": "A Historical Introduction to the Philosophy of Science, 4th ed", "author": ["J. Losee"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2001}, {"title": "A bayesian truth serum for subjective data", "author": ["D. Prelec"], "venue": "Science, vol. 306, no. 5695, pp. 462\u20136, 2004.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2004}, {"title": "The Bayesian choice: From decision-theoretic foundations to computational implementation, 2nd ed., ser", "author": ["C.P. Robert"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2007}, {"title": "Show me your evidence \u2013 an automatic method for context dependent evidence detection", "author": ["R. Rinott", "L. Dankin", "C. Alzate", "M.M. Khapra", "E. Aharoni", "N. Slonim"], "venue": "Proc. of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP), 2015, pp. 440\u2013450.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2015}, {"title": "Sentiment Analysis: Mining Opinions, Sentiments, and Emotions", "author": ["B. Liu"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2015}, {"title": "Answering yes/no questions via question inversion", "author": ["H. Kanayama", "Y. Miyao", "J. Prager"], "venue": "Proc. of the International Conf. on Comp. Linguistics (COLING), 2012, pp. 1377\u201392.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2012}], "referenceMentions": [{"referenceID": 0, "context": "Recent advances in artificial intelligence and other areas are enabling a generation of systems so-called \u2018cognitive\u2019,1 for their capability to digest large volumes of unstructured data and come up with an answer to some interesting question [1], such as whether one\u2019s favorite soccer player \u2018dives\u2019 or does not \u2018dive\u2019 according to the general public opinion.", "startOffset": 242, "endOffset": 245}, {"referenceID": 1, "context": "\u2019 Although this kind of experiment has already been tried for fairly less controversial topics (like \u2018cute animals,\u2019 \u2018safe cities,\u2019 etc, see [3]), we are not aware of any work on claim extraction and parsing that also observes whether the claim is attached to some (user-generated) multimedia as a form of material evidence to back it up.", "startOffset": 141, "endOffset": 144}, {"referenceID": 4, "context": "Terms are shown with their partof-speech tag, and connected in a linguistic dependency parse tree labeled according to the CLEAR style [6].", "startOffset": 135, "endOffset": 138}, {"referenceID": 2, "context": "4 For the NLP core tasks we have used spaCy,5 which is a fast and accurate API for several NLP tasks [4], [5], specially dependency parsing which is key for us.", "startOffset": 101, "endOffset": 104}, {"referenceID": 3, "context": "4 For the NLP core tasks we have used spaCy,5 which is a fast and accurate API for several NLP tasks [4], [5], specially dependency parsing which is key for us.", "startOffset": 106, "endOffset": 109}, {"referenceID": 5, "context": "A term token is detected to stand for the target named entity in a sentence if all these conditions hold: (i) string similarity based on the Levenshtein edit distance function is higher than a threshold [7]; and (ii) it is tagged as a proper name (PROPN) by part-of-speech processing.", "startOffset": 203, "endOffset": 206}, {"referenceID": 6, "context": "Hypotheses like \u2018Neymar is a diver\u2019 are \u2018observational\u2019 [8], as opposed to tentative explanations or complex theories.", "startOffset": 56, "endOffset": 59}, {"referenceID": 7, "context": ", the Bayesian truth serum [9]) to filter out people\u2019s biases, which can be useful in our framework.", "startOffset": 27, "endOffset": 30}, {"referenceID": 8, "context": "To establish an up-to-date decision, besides hypothesis testing methods, decision-theoretic frameworks may also be helpful [10].", "startOffset": 123, "endOffset": 127}, {"referenceID": 9, "context": "Our work is related to the socalled \u2018debating\u2019 technologies at IBM [11].", "startOffset": 67, "endOffset": 71}, {"referenceID": 10, "context": "Sentiment analysis [12].", "startOffset": 19, "endOffset": 23}, {"referenceID": 1, "context": "[3].", "startOffset": 0, "endOffset": 3}, {"referenceID": 11, "context": "Propositional (yes/no) questions are an important class of questions that are addressed by Q&A systems [13], but our understanding of hypotheses as a specific kind of propositional questions is an important distinction in the enormous scope of Q&A systems.", "startOffset": 103, "endOffset": 107}], "year": 2016, "abstractText": "Subjective questions such as \u2018does neymar dive\u2019, or \u2018is clinton lying\u2019, or \u2018is trump a fascist\u2019, are popular queries to web search engines, as can be seen by autocompletion suggestions on Google, Yahoo and Bing. In the era of cognitive computing, beyond search, they could be handled as hypotheses issued for evaluation. Our vision is to leverage on unstructured data and metadata of the rich user-generated multimedia that is often shared as material evidence in favor or against hypotheses in social media platforms. In this paper we present two preliminary experiments along those lines and discuss challenges for a cognitive computing system that collects material evidence from user-generated multimedia towards aggregating it into some form of collective decision on the hypothesis. Keywords-Material evidence; User-generated multimedia; Social media hypothesis management; Cognitive computing. In: Proc. of the 1st Workshop on Multimedia Support for Decision-Making Processes, at IEEE Intl. Symposium on Multimedia (ISM\u201916), San Jose, CA, 2016.", "creator": "LaTeX with hyperref package"}}}