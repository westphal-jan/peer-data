{"id": "1611.03932", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Nov-2016", "title": "Training IBM Watson using Automatically Generated Question-Answer Pairs", "abstract": "IBM Watson is a cognitive computing system capable of question answering in natural languages. It is believed that IBM Watson can understand large corpora and answer relevant questions more effectively than any other question-answering system currently available. To unleash the full power of Watson, however, we need to train its instance with a large number of well-prepared question-answer pairs. Obviously, manually generating such pairs in a large quantity is prohibitively time consuming and significantly limits the efficiency of Watson's training. Recently, a large-scale dataset of over 30 million question-answer pairs was reported. Under the assumption that using such an automatically generated dataset could relieve the burden of manual question-answer generation, we tried to use this dataset to train an instance of Watson and checked the training efficiency and accuracy. According to our experiments, using this auto-generated dataset was effective for training Watson, complementing manually crafted question-answer pairs. To the best of the authors' knowledge, this work is the first attempt to use a large-scale dataset of automatically generated question-answer pairs for training IBM Watson. We anticipate that the insights and lessons obtained from our experiments will be useful for researchers who want to expedite Watson training leveraged by automatically generated question-answer pairs.", "histories": [["v1", "Sat, 12 Nov 2016 01:49:48 GMT  (570kb)", "http://arxiv.org/abs/1611.03932v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["jangho lee", "gyuwan kim", "jaeyoon yoo", "changwoo jung", "minseok kim", "sungroh yoon"], "accepted": false, "id": "1611.03932"}, "pdf": {"name": "1611.03932.pdf", "metadata": {"source": "CRF", "title": "Training IBM Watson using Automatically Generated Question-Answer Pairs", "authors": ["Jangho Lee", "Changwoo Jung", "Jaeyoon Yoo", "Sungroh Yoon"], "emails": ["ubuntu@snu.ac.kr", "jungcw@kr.ibm.com", "kgwmath@snu.ac.kr", "misekim@kr.ibm.com", "yjy765@snu.ac.kr", "sryoon@snu.ac.kr"], "sections": [{"heading": null, "text": "IBM Watson is believed to be able to understand large corporations and answer relevant questions more effectively than any other question-and-answer system currently available. However, in order to unleash the full power of Watson, we need to train its instance with a large number of well-prepared question-and-answer pairs. Obviously, manually generating such pairs in large quantities is prohibitively time-consuming and significantly limits the efficiency of Watson's training. Recently, a large data set of over 30 million question-and-answer pairs was reported. Assuming that using such an automatically generated data set could reduce the burden of manual question-and-answer generation, we attempted to use this data set to train an instance of Watson and verify training efficiency and accuracy. According to our experiments, using this automatically generated data set was effective for training Watson to supplement the manually created question-and-answer pairs. In order to maximize the knowledge of the authors to make it possible for Watson's researchers to automatically pass this extensive work for the first attempt to pair the IBM to automatically."}, {"heading": "1. Introduction", "text": "The purpose of QA is to find and return a specific and useful piece of information that is automatically available to the * corresponding author user in response to a question [2] [3]. A QA system is a software system designed to answer questions that are asked in natural languages. IBM Watson differs from traditional QA systems in that it uses more than 100 different sophisticated techniques for careful analysis of natural languages [5]. This makes Watson a cognitive computer system that can potentially observe, interpret and evaluate the ability of people to do so [6]. Watson takes a large number of documents and learns question-and-answer systems in natural languages when processing questions prepared by the user for education.Due to its outstanding NLP processing capability [7], Watson is gradually gaining a high reputation in the NLP community. IBM Watson is expanding its application areas in medical cancer research 11."}, {"heading": "2. Background", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Review of QA Systems", "text": "In the research on QA systems, we aim to build an automated system that can retrieve relevant answers when questions are asked in natural language, as most information retrieval systems currently do [2] [3] [14]. A general QA system consists of three phases, as shown in Figure 1 [5]. The first stage of a QA system consists of processing questions and consists of two steps: formulation and classification of the query. In the query formulation, the QA system extracts queries in order to receive an answer. Next, in the query type classification called response type classification, the QA system classifies a question according to the expected answer to the question. For example, given the question \"Who is the founder of IBM?,\" we expect an answer type from PERSON. In another question, \"What is the capital of the Republic of Korea?,\" we expect an answer type recognition. These tasks will be performed in the question processing phase of the QA system."}, {"heading": "2.2 Question Categories", "text": "There are many ways to categorize questions, such as questions in open or closed domains, descriptive questions, and yes / no questions. Descriptive questions include not only definite questions, but also factual questions that begin with a question word, such as what, where, when, who, and how. [17] For example, for the term \"IBM Watson,\" we can answer questions such as \"What is IBM Watson?\" and \"How is IBM Watson used?.\" Questions in open domains require a statement indicating whether something is true or false. [17] Examples are \"Is there research related to IBM Watson's education?\" From the perspective of the types of issues that have to do with questions, a question can be categorized either as open or as closed domain. Questions in open domains consist of different topics. Topics in open domains are not limited to a specific area, and training in open QA systems therefore requires a large amount of data. In contrast, a question in closed domains refers to a specific question after a specific domain."}, {"heading": "2.3 Overview of Watson QA System", "text": "Figure 2 illustrates the architecture of the DeepQA [7] technology that underlies Watson. DeepQA is designed to find potential answers using NLP techniques such as Deep Content Analysis, Information Retrieeval and Machine Learning [7]. Furthermore, DeepQA is designed to process a huge amount of data based on big data platforms such as Apache Unstructured Information Management Applications (UIMA) [18] and Apache Hadoop [19]. QA begins by building a knowledge database1, which is used as evidence for Watson to find an answer. Once a question has been entered into Watson, Watson analyses it and breaks it down into query languages. Once query languages are extracted, Watson generates hypotheses from query languages and filters the content needed to get the right answer. At the same time, Watson performs the tasks of gathering evidence, ranking hypotheses, and feedback from languages."}, {"heading": "2.4 Related Work", "text": "As a member of the Watson University Program, Murtaza et al. [12] have proposed methods and criteria for effective Watson training to address the challenge of Watson's internal structure being like a black box [9]. IBM Watson, for example, prefers well-organized texts to a cursory enumeration of sentences from input documents (i.e. unstructured texts). In addition, Murtaza et al. have proposed three metrics to evaluate Watson's performance on the basis of answers returned and trustworths.These three metrics are recall, accuracy, and precision. Meanwhile, Wollowski [24] has reported on how to teach the best discipline in using and training Watson in a university class.This work provides helpful tips for students to better understand the technical details behind Watson.In general, training QA systems requires a large number of questions."}, {"heading": "3. Proposed Methods", "text": "In this section, we present our methods for demonstrating the effectiveness of automatic generation of question-answer pairs [13] [31] for Watson training, which consists of three phases as shown in Figure 5."}, {"heading": "3.1 Stage 1: Data Processing", "text": "In fact, it is so that most people who are able to put themselves into the world, put themselves into the world, into the world in which they live, into the world, into the world, into the world, into the world, into the world, into the world, into the world, into the world, into the world, into the world, into the world, into the world, into the world, into the world, into the world, into the world, into the world, into the world, into the world, into the world, into the world, into the world, into the world, into the world, into the world, into the world, into the world, into the world, into the world, into the world, into the world, into the world, into the world, into the world, into the world, into the world, into the world, into the world, into the world, into the world, into the world, into the world, into the, into the, into the, into the, into the, into the, into the, into the, into the, into the, into the, into the, into the, the, into the, into the, the, into the, the, into the, the, the, into the, the, the, the, the, the, the, the, into the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the,"}, {"heading": "3.2 Stage 2: Watson Training", "text": "Since our main goal of this study was to prove the validity of using automatically generated questions along with the feasibility of using them as complementary questions for training Watson, we tested three types of training methods: using only the 400 automatically generated question-answer pairs (we call the set of these pairs AQA in Table 4), using only the 400 handmade question-answer pairs (called HQA in Table 4) and using the combination of the two types of pairs (called AQA + HQA in Table 4). We trained three different instances of Watson using the three different methods. To improve training performance, we provided human feedback for each QA process. That is, for each question we reviewed Watson's answers, chose the best answer and specified the section of the input text containing the expected answer, as shown in Figure 3.3.3. Level 3: Watson TestingIn this last stage of our approach, we analyzed the performance of Watson trained with the three different methods we use."}, {"heading": "4. Results and Discussion", "text": "In fact, most people who are able are able to surpass themselves, to surpass themselves, to surpass themselves and to surpass themselves, \"he said.\" But it's not like I'm able to surpass myself. \"He added,\" I don't think it's like I'm surpassing myself. \"He added,\" I don't think it's like I'm surpassing myself. \"He added,\" I don't think it's like I'm surpassing myself. \"He added,\" I don't think I'm surpassing myself, but I don't think I'm surpassing myself. \"He pointed out that he's able to surpass himself,\" that I'm surpassing myself, \"that I'm surpassing myself.\""}, {"heading": "5. Conclusion", "text": "In this paper, we have described our methodology for training IBM Watson using automatically generated question-and-answer pairs as an attempt to reduce the burden of manually generating large amounts of training data. Through our experiments, we have confirmed that our approach is indeed effective for training Watson and performs competitively compared to traditional training methods. Furthermore, we have shown that training Watson using automatically generated question-and-answer pairs, together with handmade question-and-answer pairs, can enable Watson to provide more precise answers to invisible questions. We hope that the results and insights of this work will help users of extensive QA systems to make informed decisions about the use of automatically generated QA pairs for training their systems."}, {"heading": "6. Acknowledgement", "text": "The authors would like to thank IBM Korea for the generous support that made this work possible, and Seongsik Park, Jaehong Park and Jahee Jang from SNU Data Science Lab for their help in generating the question. This work was supported by the IBM Korea University Program. J. Lee, G. Kim, J. Yoo and S. Yoon were also partially supported by Naver Corp, partially by DataSolution Inc. and partially by the SNU ECE Brain Korea 21 Plus Project 2016."}, {"heading": "7. References", "text": "[1] G. Salton and M. J. McGill, \"Introduction to Modern Information Processing,\" India 2000, D. Moddy p. 71, \"1986. [2] V. Lopez, V. Uren, M. Sabou, and E. Motta,\" Is Answering Questions Suitable for the Semantic Web? a Survey., \"Semantic Web, Vol. 2, No. 2, 2011, pp 125-155. [3] S. Dumais, M. Banko, E. Brill, J. McCol, and Ng. Andrew\" Web question answering: Is more always better?, \"Proceedings of the 25th annual international ACM SIGIR Conference on Research and Development in information retrieval, M. IBICS, 2002, pp. 291-298. E. Voorhees and D. M. Tice,\" Overview of the TREC9 Question Track., \"TREC, 2000. [5] J. H. Martin and D. Jurafsky,\" Speech language processing. \""}], "references": [{"title": "Is question answering fit for the semantic web? a survey.", "author": ["V. Lopez", "V. Uren", "M. Sabou", "E. Motta"], "venue": "Semantic Web,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2011}, {"title": "Web question answering: Is more always better?.", "author": ["S. Dumais", "M. Banko", "E. Brill", "J. Lin", "Ng. Andrew"], "venue": "Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrieval,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2002}, {"title": "Overview of the TREC- 9 Question Answering Track.", "author": ["E.M. Voorhees", "D.M. Tice"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2000}, {"title": "Speech & language processing.", "author": ["J.H. Martin", "D. Jurafsky"], "venue": "Pearson Education India,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2000}, {"title": "Building Watson: An Overview of the DeepQA Project.", "author": ["D. Ferrucci", "E. Brown", "J. Chu-Carroll", "J. Fan", "D. Gondek", "A.A. Kalyanpur", "A. Lally", "J.W. Murdock", "E. Nyberg", "J. Prager", "N. Schlaefer", "C. Welty"], "venue": "AI Magazine,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2010}, {"title": "Question analysis: How Watson reads a clue.", "author": ["A. Lally", "J.M. Prager", "M.C. McCord", "B.K. Boguraev", "S. Patwardhan", "J. Fan", "P. Fodor", "J. Chu-Carroll"], "venue": "IBM Journal of Research and Development,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2012}, {"title": "Pischdotchian, \"How to Effectively Train IBM Watson: Classroom Experience.", "author": ["S.S. Murtaza", "P. Lak", "A. Bener"], "venue": "49th Hawaii International Conference on System Sciences (HICSS),", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2016}, {"title": "Generating Factoid Questions With Recurrent Neural Networks: The 30M Factoid Question-Answer Corpus.", "author": ["I.V. Serban", "A. Garc\u00eda-Dur\u00e1n", "C. Gulcehre", "S. Ahn", "S. Chandar", "A. Courville", "Y. Bengio"], "venue": "arXiv preprint arXiv:1603.06807,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2016}, {"title": "An analysis of the AskMSR question-answering system.", "author": ["E. Brill", "S. Dumais", "M. Banko"], "venue": "Proceedings of the ACL-02 conference on Empirical methods in natural language processing,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2002}, {"title": "Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition.", "author": ["K.S. Tjong", "F. Erik", "F. De Meulder"], "venue": "Proceedings of the seventh conference on Natural language learning at HLT-NAACL, Association for Computational Linguistics,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2003}, {"title": "Class-based n-gram models of natural language.", "author": ["P.F. Brown", "P.V. Desouza", "R. L Mercer", "V.J.D. Pietra", "J.C. Lai"], "venue": "Computational linguistics,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1992}, {"title": "Training Watson - A Cognitive System Courses.", "author": ["M. Wollowski"], "venue": "AAAI Conference on Artificial Intelligence,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2016}, {"title": "Towards topic-to-question generation.", "author": ["Y. Chali", "S.A. Hasan"], "venue": "Computational Linguistics,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2015}, {"title": "Good question! statistical ranking for question generation.\", Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics", "author": ["H. Michael", "N.A. Smith"], "venue": "Association for Computational Linguistics,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2010}, {"title": "Learning phrase representations using RNN encoder-decoder for statistical machine translation.", "author": ["K. Cho", "B.V. Merrienboer", "C. Gulcehre", "D. Bahdanau", "F. Bougares", "H. Schwenk", "Y. Bengio"], "venue": "arXiv preprint arXiv:1406.1078,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2014}, {"title": "Sequence to sequence learning with neural networks.", "author": ["I. Sutskever", "O. Vinyals", "Q.V. Le"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2014}, {"title": "Neural machine translation by jointly learning to align and translate.", "author": ["D. Bahdanau", "K. Cho", "Y. Bengio"], "venue": "In International Conference on Learning Representations,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2015}, {"title": "The relationship between Precision-Recall and ROC curves.", "author": ["J. Davs", "M. Goadrich"], "venue": "Proceedings of the 23rd international conference on Machine learning,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2006}], "referenceMentions": [{"referenceID": 0, "context": "Question answering (QA) is a subfield of natural language processing (NLP) and information retrieval (IR) [1] [2] [3] [4].", "startOffset": 110, "endOffset": 113}, {"referenceID": 1, "context": "Question answering (QA) is a subfield of natural language processing (NLP) and information retrieval (IR) [1] [2] [3] [4].", "startOffset": 114, "endOffset": 117}, {"referenceID": 2, "context": "Question answering (QA) is a subfield of natural language processing (NLP) and information retrieval (IR) [1] [2] [3] [4].", "startOffset": 118, "endOffset": 121}, {"referenceID": 0, "context": "Corresponding author user in response to a question [2] [3] [5].", "startOffset": 52, "endOffset": 55}, {"referenceID": 1, "context": "Corresponding author user in response to a question [2] [3] [5].", "startOffset": 56, "endOffset": 59}, {"referenceID": 3, "context": "Corresponding author user in response to a question [2] [3] [5].", "startOffset": 60, "endOffset": 63}, {"referenceID": 3, "context": "IBM Watson is different from the conventional QA systems in that it uses more than 100 different sophisticated techniques for carefully analyzing natural languages [5].", "startOffset": 164, "endOffset": 167}, {"referenceID": 4, "context": "Owing to the outstanding NLP processing capability [7] [8], Watson is gradually acquiring a high reputation in the NLP community.", "startOffset": 51, "endOffset": 54}, {"referenceID": 5, "context": "Owing to the outstanding NLP processing capability [7] [8], Watson is gradually acquiring a high reputation in the NLP community.", "startOffset": 55, "endOffset": 58}, {"referenceID": 6, "context": "Watson can show its full capability only through sufficient training [12].", "startOffset": 69, "endOffset": 73}, {"referenceID": 7, "context": "Lately, machine learning techniques to generate question-answer pairs in large scale have been proposed, and resulting datasets are being released for training large-scale QA systems [13].", "startOffset": 183, "endOffset": 187}, {"referenceID": 7, "context": "These question-answer datasets were generated using deep neural networks [13] and are hopefully expected to reduce the burden of question generation.", "startOffset": 73, "endOffset": 77}, {"referenceID": 0, "context": "In QA systems research, we aim to build an automatic system that can retrieve relevant answers when asked questions in a natural language, as most information retrieval systems currently do [2] [3] [14].", "startOffset": 190, "endOffset": 193}, {"referenceID": 1, "context": "In QA systems research, we aim to build an automatic system that can retrieve relevant answers when asked questions in a natural language, as most information retrieval systems currently do [2] [3] [14].", "startOffset": 194, "endOffset": 197}, {"referenceID": 8, "context": "In QA systems research, we aim to build an automatic system that can retrieve relevant answers when asked questions in a natural language, as most information retrieval systems currently do [2] [3] [14].", "startOffset": 198, "endOffset": 202}, {"referenceID": 3, "context": "A general QA system is composed of three stages as shown in Figure 1 [5].", "startOffset": 69, "endOffset": 72}, {"referenceID": 9, "context": "In this stage, for each query generated in the previous question processing stage, candidates of the evidence for an answer to the corresponding question are filtered from the passage using the features of named entity information [15], the number of questions, and keywords and n-gram overlaps [16].", "startOffset": 231, "endOffset": 235}, {"referenceID": 10, "context": "In this stage, for each query generated in the previous question processing stage, candidates of the evidence for an answer to the corresponding question are filtered from the passage using the features of named entity information [15], the number of questions, and keywords and n-gram overlaps [16].", "startOffset": 295, "endOffset": 299}, {"referenceID": 3, "context": "A QA system consists of three stages [5].", "startOffset": 37, "endOffset": 40}, {"referenceID": 4, "context": "Figure 2 illustrates the architecture of the DeepQA [7] technology underlying Watson.", "startOffset": 52, "endOffset": 55}, {"referenceID": 4, "context": "DeepQA can find potential answers using NLP techniques such as deep content analysis, information retrieval, and machine learning [7] [8].", "startOffset": 130, "endOffset": 133}, {"referenceID": 5, "context": "DeepQA can find potential answers using NLP techniques such as deep content analysis, information retrieval, and machine learning [7] [8].", "startOffset": 134, "endOffset": 137}, {"referenceID": 4, "context": "1 A technology used to store and manage complex structured and unstructured information on entities and can not only understand questions in natural languages but also answer unseen questions [7].", "startOffset": 192, "endOffset": 195}, {"referenceID": 4, "context": "The biggest difference between traditional QA systems and DeepQA is that the latter is able to extract and accumulate knowledge automatically [7] [20] [21] [22].", "startOffset": 142, "endOffset": 145}, {"referenceID": 6, "context": "Watson prefers documents in well-organized structure such as HTML and XML formats [12] [17].", "startOffset": 82, "endOffset": 86}, {"referenceID": 7, "context": "Question-generation model [13].", "startOffset": 26, "endOffset": 30}, {"referenceID": 6, "context": "There have been a few studies related to exploring the properties of Watson [12] [23].", "startOffset": 76, "endOffset": 80}, {"referenceID": 6, "context": "[12] proposed methods and criteria for efficient training of Watson to address the challenge that the internal structure of Watson is like a black box [9].", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "Meanwhile, Wollowski [24] reported how to teach the best discipline on using and training Watson in a university class setup.", "startOffset": 21, "endOffset": 25}, {"referenceID": 12, "context": "Research into generating questions has been implemented using diverse strategies [25] [26].", "startOffset": 81, "endOffset": 85}, {"referenceID": 13, "context": "Research into generating questions has been implemented using diverse strategies [25] [26].", "startOffset": 86, "endOffset": 90}, {"referenceID": 7, "context": "[13] produced large-scale question-answer pairs and published the resulting data.", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "The second stage represents the encoderdecoder model [13] [28] [29] [30] to generate questions from triplets, each of which consists of a subject entity, an object entity, and relationships between the two entities.", "startOffset": 53, "endOffset": 57}, {"referenceID": 14, "context": "The second stage represents the encoderdecoder model [13] [28] [29] [30] to generate questions from triplets, each of which consists of a subject entity, an object entity, and relationships between the two entities.", "startOffset": 58, "endOffset": 62}, {"referenceID": 15, "context": "The second stage represents the encoderdecoder model [13] [28] [29] [30] to generate questions from triplets, each of which consists of a subject entity, an object entity, and relationships between the two entities.", "startOffset": 63, "endOffset": 67}, {"referenceID": 16, "context": "The second stage represents the encoderdecoder model [13] [28] [29] [30] to generate questions from triplets, each of which consists of a subject entity, an object entity, and relationships between the two entities.", "startOffset": 68, "endOffset": 72}, {"referenceID": 7, "context": "In this section, we provide more details of our methods to prove the effectiveness of automatically generate question-answer pairs [13] [31] for training Watson.", "startOffset": 131, "endOffset": 135}, {"referenceID": 7, "context": "In this work, we used an academic version of Watson, which is limited to training with the maximum of 1,000 question-answer pairs [13] [31].", "startOffset": 130, "endOffset": 134}, {"referenceID": 6, "context": "[12].", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "[12].", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "Note that the definitions of these metrics are different from those used in typical machine learning or information retrieval settings [34].", "startOffset": 135, "endOffset": 139}, {"referenceID": 6, "context": "[12] to assess the effectiveness of Watson training.", "startOffset": 0, "endOffset": 4}], "year": 2016, "abstractText": "IBM Watson is a cognitive computing system capable of question answering in natural languages. It is believed that IBM Watson can understand large corpora and answer relevant questions more effectively than any other question-answering system currently available. To unleash the full power of Watson, however, we need to train its instance with a large number of wellprepared question-answer pairs. Obviously, manually generating such pairs in a large quantity is prohibitively time consuming and significantly limits the efficiency of Watson\u2019s training. Recently, a large-scale dataset of over 30 million question-answer pairs was reported. Under the assumption that using such an automatically generated dataset could relieve the burden of manual question-answer generation, we tried to use this dataset to train an instance of Watson and checked the training efficiency and accuracy. According to our experiments, using this auto-generated dataset was effective for training Watson, complementing manually crafted question-answer pairs. To the best of the authors\u2019 knowledge, this work is the first attempt to use a largescale dataset of automatically generated questionanswer pairs for training IBM Watson. We anticipate that the insights and lessons obtained from our experiments will be useful for researchers who want to expedite Watson training leveraged by automatically generated question-answer pairs.", "creator": "Microsoft\u00ae Word 2016"}}}