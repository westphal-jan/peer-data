{"id": "1611.03977", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Nov-2016", "title": "A Review on Algorithms for Constraint-based Causal Discovery", "abstract": "Causal discovery studies the problem of mining causal relationships between variables from data, which is of primary interest in science. During the past decades, significant amount of progresses have been made toward this fundamental data mining paradigm. Recent years, as the availability of abundant large-sized and complex observational data, the constrain-based approaches have gradually attracted a lot of interest and have been widely applied to many diverse real-world problems due to the fast running speed and easy generalizing to the problem of causal insufficiency. In this paper, we aim to review the constraint-based causal discovery algorithms. Firstly, we discuss the learning paradigm of the constraint-based approaches. Secondly and primarily, the state-of-the-art constraint-based casual inference algorithms are surveyed with the detailed analysis. Thirdly, several related open-source software packages and benchmark data repositories are briefly summarized. As a conclusion, some open problems in constraint-based causal discovery are outlined for future research.", "histories": [["v1", "Sat, 12 Nov 2016 09:25:38 GMT  (241kb)", "http://arxiv.org/abs/1611.03977v1", null], ["v2", "Thu, 24 Nov 2016 22:33:25 GMT  (0kb,I)", "http://arxiv.org/abs/1611.03977v2", "This paper has been withdrawn by the author due to further improvement"]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["kui yu", "jiuyong li", "lin liu"], "accepted": false, "id": "1611.03977"}, "pdf": {"name": "1611.03977.pdf", "metadata": {"source": "CRF", "title": "A Review on Algorithms for Constraint-based Causal Discovery", "authors": ["Kui Yu", "Jiuyong Li"], "emails": ["Lin.Liu}@unisa.edu.au"], "sections": [{"heading": null, "text": "ar Xiv: 161 1,03 977v 1 [cs.A I] 1 2N ov2 016 1Index Terms - Causal discovery, Causal sufficiency, Bayesian networks, Directional acyclic graph, Maximum ancestor graph"}, {"heading": "1 INTRODUCTION", "text": "In fact, we are able to put ourselves in a situation in which we are able to put ourselves in a situation in which we are able, in which we are able to assert ourselves, in which we are able, in which we are able, and in which we are able to put ourselves in a situation in which we are able, in which we are able, in which we are able, in which we are able to change the world we are in, in which we are in which we are in."}, {"heading": "2 LEARNING PARADIGM", "text": "In this section, we will discuss (1) learning frameworks in Section 3.1, (2) key assumptions in restriction-based learning in Section 3.2, (3) conditional independence testing in Section 3.3, (4) evaluation metrics in Section 3.4 and (5) key challenges in Section 3.5. Table 1 summarizes some of the mathematical notations commonly used in this paper."}, {"heading": "2.1 Learning Framework", "text": "In view of an observation dataset D defined on a variable set V, the constraint-based algorithms consist of three key steps: (1) the discovery of the entire skeleton, (2) the discovery of Vstructures, and (3) the orientation of as many edges as possible, as shown in Figure 2.Step 1: Skeletal Identification. There are two approaches in skeletal identification, the global approach and the local approach. The global approach then attempts to discover the skeleton including all variables [13, 90, 90, 106] while the local method deconstructs local skeletons, i.e. the set of adjacent variables (parents and children) or Markov's blanket from each vertex, then constructs a global skeleton based on local skeletons [65, 75]. Step 2: V structure discovery. This identifies v-structures based on the separation sets found (i.e. conditional sets) as orientation between variables."}, {"heading": "2.2 Key Assumptions.", "text": "Three main assumptions are assumed to develop and analyze a limitation-based algorithm. \u2022 Assumption 1: causal sufficiency. The proposition V (observed variables) fulfills the causal sufficiency assumption. \u2022 Assumption 2: fidelity and Markov condition. The distribution P over V corresponds to a DAG of the causal structure (fidelity) and fulfills the Markov condition. \u2022 Assumption 3: reliable independence tests. The statistical tests used by algorithms are correct and reliable."}, {"heading": "2.3 Conditional Independence Tests", "text": "In limitation-based algorithms, the independence tests can generally be implemented using the G2 test [1], the mutual information [59, 108], and Fisher's Z test [77]. The G2 test and the mutual information are both used to handle discrete (categorical) data, while Fisher's Z test is used to handle continuous (numerical) data (see appendix for details of these tests)."}, {"heading": "2.4 Evaluation Metrics", "text": "The commonly used parameters for evaluating the constraint-based algorithms are summarized as follows: \u2022 Missing edges. The number of edges that exist in the original structure but are missing in the learned structure. \u2022 Additional edges. The number of edges that exist in the learned structure but are not present in the learned structure. \u2022 Correct undirected edges. The number of undirected edges that exist both in the original structure and in the learned structure. \u2022 Correct edges. Correct edges in the learned structure that are correctly aligned. \u2022 Correct edges in the learned structure that are incorrectly aligned. \u2022 Correct edges in the learned structure that are incorrect aligned. \u2022 Computational efficiency. Two parables are always used, runtimes and number of statistical tests."}, {"heading": "2.5 Key Challenges", "text": "In this context, it should be noted that the data we collect is not only the number of cases recorded, but also the number of errors recorded, which are often set at 5 or 10. [1] Therefore, independence tests can be unreliable unless the size of the sample is huge. [2] Unreliable tests not only lead to errors in the resulting causal model structure, but also lead to cascading errors in the search."}, {"heading": "3 LEARNING WITH CAUSAL SUFFICIENCY", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Problem Definition and Algorithm Overview", "text": "Problem definition. Starting with an observational data set D defined on a variable set V and the underlying DAG G, the limitation-based search algorithms learn a CPDAG from G. Algorithm Overview under the assumptions of fidelity and causal sufficiency. Table 2 provides an overview of limitation-based algorithms under the assumptions of causal sufficiency and fidelity. In Table 2, \"global\" means that an algorithm uses a global search strategy to find an entire skeleton, while \"local\" means that an algorithm applies a local discovery approach to discover skeletons. In the table, a tick indicates that the main modification of the corresponding algorithm will not change, and \"-\" denotes the step. In Table 2, with the exception of SLPR, all other algorithms deal with a single data set."}, {"heading": "3.2 Global algorithm", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.2.1 SGS Algorithm", "text": "In fact, it is as if it were a way of acting in which the vassals, the vassals, the vassals, the vassals, the vassals, the vassals, the vassals, the vassals, the vassals, the vassals, the vassals, the vassals, the vassals, the vassals, the vassals, the vassals, the vassals, the vassals, the vassals, the vassals, the vassals, the vassals, the vassals, the vassals, the vassals, the vassals, the vassals, the vassals, the vassals, the vassals, the vassals, the vassals, the vassals, the vassals, the vassals, the vassals, the vassals, the vassals, the vassals, the vassals, the vassals, the vassals, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the"}, {"heading": "3.2.2 PC algorithm", "text": "The PC (PC stands for Peter Spirtes and Clark Glymour, who invented this algorithm) algorithm [89, 90] was proposed to improve learning efficiency in skeletal identification (Step 1 in Algorithm 1). Instead of checking every possible conditioning in any order of conditioning, the PC algorithm only checks conditioning sets adjacent to the variables. The main idea of the PC algorithm in skeletal identification is summarized as follows: \u2022 The PC algorithm starts with a complete undirected graph, which then refines the graph by removing edges with an empty condition for independence testing. If a pair of variables is found to be independent, the edge between them is removed, for each pair of nodes (Vi, Vj) that are still adjacent, it tests conditional independence of the corresponding variable, on all possible subsets of G (Vadj)."}, {"heading": "3.2.3 Conservative SGS and PC algorithms", "text": "In fact, it is a way in which people are able to determine for themselves how they want to behave."}, {"heading": "3.2.4 PC-stable algorithm", "text": "This year, it has come to the point that it will only be a matter of time before it is ready, until it is ready."}, {"heading": "3.2.5 Parallel PC algorithm", "text": "It is known that in the worst case, the PC algorithm is exponential to the number of variables, and therefore it is computational inefficiency in applying to a high-dimensional dataset involved thousands of variables. The work [47, 48] suggested the parallel versions of the PC algorithm and the PC stable algorithm using the parallel computer technology and showed that the parallel PC and PC stable algorithms produce the same outputs as the PC and PCstable algorithms, but much more efficient in runtime. 3.2.6 PCfdr skeletal algorithm In several hypotheses tests for learning skeletons (Step 2), a Type I error occurs when the variables are independent, but the test shows that they are dependent, while a Type II error occurs when the variables are dependent, but the statistical test indicates independence. The false detection rate (FDR) is PCs [10, 94] a criterion being tested simultaneously to ascertain the errors when several hypotheses are tested."}, {"heading": "3.2.7 AIT Framework", "text": "Against the background of the PCfdr skeletal algorithm, Bromberg and Margaritis [12] have proposed the AIT (Argumentative Independence Test) framework to improve the reliability of constraint-based algorithms when independence tests on small datasets are not reliable. \u2022 The AIT framework model models the problem of unreliability of statistical independence tests as a knowledge base, which contain a number of independence factors inherent in Pearl's well-known axioms [72]. \u2022 Symmetry (X-Y-Z) decomposition implies consistent independence. (X-Y-Z) decomposition (X-Y-Z) decomposition is a consistent position in which statistical tests are performed."}, {"heading": "3.2.8 TPDA algorithm", "text": "The TPDA algorithm (three-phase dependency analysis) was proposed by Cheng et. al. [13] Compared to the PC algorithm, TPDA uses mutual information for independence testing to learn graph skeletons from data and divides the structure learning process into three phases, i.e., creation, thickening and dilution. There are two versions of the TPDA algorithm, TPDA, which learns DAGs when a node order is not given, and TPDA-II, when the node order is given. When the correct node order is available, TPDA II only requires standard DAG fidelity, while TPDA is correct when the node order is given with a sufficient quantity of training data and the monotonous DAG fidelity condition."}, {"heading": "3.3 Local-to-global approach", "text": "The main problem with global restriction-based algorithms is their inefficiency and inaccuracy in conducting conditional independence tests for large conditional sets. For example, the PC and TPDA algorithms require an exponentially increasing number of independence tests with the number of nodes to learn a skeleton. Their time complexity can be reduced to a polynomial by specifying the number of parents (PC algorithm) or using a threshold to control the number of mutual information tests and some strong assumptions (TPDA algorithm). Furthermore, the TPDA algorithm ignores the problem of the curse of dimensionality by not limiting the size of conditional sets. To reduce the conditional sets for testing independence, in the section we review causal discovery algorithms using a local-global learning approach."}, {"heading": "3.3.1 Decomposition approaches", "text": "Geng et. al [33] proposed a decomposition method to simplify the search for V-structures for efficient structural learning; the basic idea behind this is that an undirected moral graph is first decomposed into several subgraphs, then searched for V-structures in each subgraph individually; the rational idea behind the idea is that if the vertices Vi and Vj are adjacent to each other in the moral graph, but there is a vertex that comprises S so that Vi, Vj and a variable proposition S exist, and vice versa. To decompose a graph into subgraphs, the approach in [33] requires a moral graph and requires that each deseparator (conditional propositions) has a complete subgraph in the moral graph. To solve the condition, Xie et al have proposed an improved decomposition approach by using d-separation tree instead of a moral graph."}, {"heading": "3.3.2 Markov blanket approach", "text": "This year, it has reached the stage where it will be able to take the lead."}, {"heading": "3.3.3 Recursive Autonomy Identification", "text": "The RAI (Recursive Autonomy Identification) algorithm was presented in [111, 112], which uses a structural decomposition approach. While the RAI (Recursive Autonomy Identification) algorithm combines skeletal discovery and edge orientation, all the above-mentioned algorithms separate skeletal discovery and edge orientation into independent steps. Starting with a complete undirected graph and progressing from low to high sizes of conditional sets, the RAI algorithm detects a casual structure by performing the following sequence of operations: (1) pairs of independence tests between nodes, followed by removal of edges related to independence, (2) edge direction according to orientation rules, and (3) structure decomposition in autonomous sub-structures. For each autonomous substructure, the RAI algorithm is applied recursively, with the autonomy X-structure, the autonomy-exposition, and the autonomy-cause (3)."}, {"heading": "3.4 Active learning-based approaches", "text": "Existing random discovery methods are based entirely on observational data to detect causal relationships between variables up to a Markov equivalence class, leaving many edge directions indefinite [90]. Generally, the complete identification of all edge directions requires manipulation / experiments to expand the discoveries from observational data, which has led to the recent development of several methods for active learning of causal networks using both observational and experimental data.The active learning approach first learns a CPDAG from observation data, then orients itself to remaining undirected edges in the resulting CPDAG by intervention experiments.The method type includes the work of [22, 27, 68, 97] and the method proposed by He and Geng [37]. The main idea behind these approaches is to use the PC algorithm to obtain an undirected or partially directed graph from observation data, and then to select some decision criteria to use for manipulating the number of variables."}, {"heading": "3.5 Local discovery of direct causes and effects", "text": "This year it is as far as never before in the history of the Federal Republic of Germany."}, {"heading": "3.6 Learning from overlapping variable sets", "text": "Instead of learning with a single observation data set, we sometimes have to deal with multiple data sets that do not share the same set of variables but have significant overlaps due to privacy or ethics. [23, 24] In this context, the joint analysis of a collection of data sets and the learning of causal structures via the common set of observed variables is an active field of research. Danks [23] pioneered the SLPR algorithm (Structure learning using previous results) to learn the causal structure via the common set of observed variables. The SLPR algorithm first learns a sub-CPDAG for each data set using the existing restriction-based algorithm. Then, the SLPR algorithm starts with a completely undirected graph and uses each sub-CPDAG and edge removal rules to obtain a complete CPDAG. Specifically, the SLPR algorithm draws up some rules to remove false information from the base algorithm, which is sufficient to remove the binary algorithm from the network."}, {"heading": "4 LEARNING WITHOUT CAUSAL SUFFICIENCY", "text": "In real-world applications, such as medicine, epidemiology, and sociology, it is impossible to ensure that all common causes are measured in real data [6, 17]. Therefore, the assumption of causal sufficiency is often violated in many situations. There has been some work on learning a Bayesian network of latent variables. However, this type of approach (mainly based on score-based methods) still deals with latent variables within the framework of a DAG model and assumes causal sufficiency, since these algorithms must determine the number of latent variables and the exact positions of latent variables in the data in advance before learning begins. In this case, by incorporating latent variables into the structure to be learned, these methods transfer the problem of latent variable learning to the problem of missing data that completes the latent variables [85]. In practice, since the latent variables are not observed, both the number of the explicit and their explicit positions are unclear."}, {"heading": "4.1 Problem Definition and Algorithm Overview", "text": "Considering a perfect oracle of conditional independence and fidelity, the algorithm for learning causal structures without adopting a causal sufficiency is a PAG of the Markov equivalent class of true causal MAG.Algorithm AG contains an overview of restriction-based algorithms under the premises of causal sufficiency and fidelity. In Table 3, it is shown whether an algorithm is able to deal with a single record or multiple records. Deviating from a DAG, a mixed chart may contain three types of edges: directed edges (\u2190 or \u2192), bidirectional edges (\u2212). In a mixed chart, if the margin Vi \u2192 Vj is present, Vi is Vi, Vi, Vi, Vi, Vi, Vi, Vi, Vi, Vi, Vi, Vi, Vi, Vi, Vi, Vi, Vi, Vi, Vi, Vi, Vi, Vi, Vi, Vi, Vi, Vi, Vi, Vi, Vi, Vi, Vi, Vi, Vi, Vi, Vi, Vi, Vi, Vi, Vi, Vi, Vi, Vi, Vi, Vi, Vi, Vi, Vi, Vi, Vi, Vi, Vi, Vi"}, {"heading": "4.2 Learning from a single data set", "text": "The IC * (Inductive Causation) algorithm [74] is the pioneer in learning causal structures without assuming causal sufficiency. It starts with an empty graph and performs the following steps. \u2022 Step 1: Find an undirected edge between X and Y if no SXY structure exists. \u2022 Step 2: Define the v structures. For each connected triple X \u2212 Y where X and Y are not adjacent, direct the edges and add a V structure. \u2022 Z 2: Y if Z / S SXY, i.e. if and only the Y structures depend. \u2022 Step 3: Orient the directions of the remaining edges. Step 1 is identical to those of the SGS algorithms, but IC * uses the following rules to deal with the variables and edges."}, {"heading": "4.3 Learning with overlapping variable sets", "text": "This year it is so far that it is only a matter of time before it will be so far, until it is so far, until it is so far."}, {"heading": "5 PUBLIC SOFTWARE AND BENCHMARK DATA", "text": "In the section, we list some of the most important public software packages related to restriction-based methods in Table 4. Commonly used Bayesian benchmark networks come from the Bayesian Network Repository3. We can also use the above software package to generate synthetic Bayesian networks. Specifically, the Causal Explore package provides a billion-tile algorithm to generate any size of Bayesian networks."}, {"heading": "6 CONCLUSION AND DISCUSSION", "text": "In this paper, we present a comprehensive survey of algorithms for constraint-based causal discovery. We first cite the learn paradigm of constraint-based methods, then we give the problem definitions and discuss the details of state-of-the-art causal structure learning algorithms. Finally, we briefly mention publicly available software and datasets for constraint-based causal discovery. As we discussed above, the emergence of big data brings not only opportunities for constraint-basedmethods, but also challenges. First, we present an immediate challenge to learning an entire casual structure due to computational feasibility, even though the current local causal discovery techniques are scalable up to hundreds of thousands of variables. In addition, the current constraint-based methods all assume that the causal structure is spared, that is to limit the maximum neighborhood size for each node."}], "references": [{"title": "Categorical data analysis", "author": ["A. Agresti", "M. Kateri"], "venue": "Springer,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2011}, {"title": "Local causal and markov blanket induction for causal discovery and feature selection for classification part i: Algorithms and empirical evaluation", "author": ["C.F. Aliferis", "A. Statnikov", "I. Tsamardinos", "S. Mani", "X.D. Koutsoukos"], "venue": "Journal of Machine Learning Research, 11:171\u2013234,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2010}, {"title": "Local causal and markov blanket induction for causal discovery and feature selection for classification part ii: Analysis and extensions", "author": ["C.F. Aliferis", "A. Statnikov", "I. Tsamardinos", "S. Mani", "X.D. Koutsoukos"], "venue": "Journal of Machine Learning Research, 11(Jan):235\u2013284,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2010}, {"title": "Hiton: a novel markov blanket algorithm for optimal variable selection", "author": ["C.F. Aliferis", "I. Tsamardinos", "A. Statnikov"], "venue": "AMIA Annual Symposium Proceedings, volume 2003, page 21. American Medical Informatics Association,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2003}, {"title": "A reasoning model based on the production of acceptable arguments", "author": ["L. Amgoud", "C. Cayrol"], "venue": "Annals of Mathematics and Artificial Intelligence, 34(1-3):197\u2013215,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2002}, {"title": "Learning linear bayesian networks with latent variables", "author": ["A. Anandkumar", "D. Hsu", "A. Javanmard", "S. Kakade"], "venue": "Proceedings of The 30th International Conference on Machine Learning, pages 249\u2013 257,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "Controlling selection bias in causal inference", "author": ["E. Bareinboim", "J. Pearl"], "venue": "AISTATS, pages 100\u2013108,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2012}, {"title": "Causal inference and the datafusion problem", "author": ["E. Bareinboim", "J. Pearl"], "venue": "Proceedings of the National Academy of Sciences, 113(27):7345\u20137352,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2016}, {"title": "Recovering causal effects from selection bias", "author": ["E. Bareinboim", "J. Tian"], "venue": "AAAI, pages 3475\u20133481,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2015}, {"title": "The control of the false discovery rate in multiple testing under dependency", "author": ["Y. Benjamini", "D. Yekutieli"], "venue": "Annals of statistics, pages 1165\u20131188,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2001}, {"title": "Incorporating causal prior knowledge as path-constraints in bayesian networks and maximal ancestral graphs", "author": ["G. Borboudakis", "I. Tsamardinos"], "venue": "Proceedings of the 29th International Conference on Machine Learning (ICML\u201912), pages 1799\u20131806,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2012}, {"title": "Improving the reliability of causal discovery from small data sets using argumentation", "author": ["F. Bromberg", "D. Margaritis"], "venue": "Journal of Machine Learning Research, 10(Feb):301\u2013340,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2009}, {"title": "Learning bayesian networks from data: An information-theory based approach", "author": ["J. Cheng", "D.A. Bell", "W. Liu"], "venue": "Artificial Intelligence, 137(May):43\u201390,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2002}, {"title": "Learning Bayesian networks from data", "author": ["D.M. Chickering"], "venue": "University of California, Los Angeles,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1996}, {"title": "Learning equivalence classes of bayesiannetwork structures", "author": ["D.M. Chickering"], "venue": "Journal of machine learning research, 2(Feb):445\u2013498,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2002}, {"title": "Order-independent constraintbased causal structure learning", "author": ["D. Colombo", "M.H. Maathuis"], "venue": "The Journal of Machine Learning Research, 15(1):3741\u20133782,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning high-dimensional directed acyclic graphs with latent and selection variables", "author": ["D. Colombo", "M.H. Maathuis", "M. Kalisch", "T.S. Richardson"], "venue": "The Annals of Statistics,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2012}, {"title": "An overview of the representation and discovery of causal relationships using bayesian networks", "author": ["G. Cooper"], "venue": "Computation, causation, and discovery, pages 4\u201362,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1999}, {"title": "A simple constraint-based algorithm for efficiently mining observational databases for causal relationships", "author": ["G.F. Cooper"], "venue": "Data Mining and Knowledge Discovery, 1(2):203\u2013224,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1997}, {"title": "The center for causal discovery of biomedical knowledge from big data", "author": ["G.F. Cooper", "I. Bahar", "M.J. Becich", "P.V. Benos", "J. Berg", "J.U. Espino", "C. Glymour", "R.C. Jacobson", "M. Kienholz", "A.V. Lee"], "venue": "Journal of the American Medical Informatics Association, page ocv059,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2015}, {"title": "A bayesian method for the induction of probabilistic networks from data", "author": ["G.F. Cooper", "E. Herskovits"], "venue": "Machine learning, 9(4):309\u2013347,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1992}, {"title": "Causal discovery from a mixture of experimental and observational data", "author": ["G.F. Cooper", "C. Yoo"], "venue": "Proceedings of the Fifteenth conference on Uncertainty in artificial intelligence, pages 116\u2013125. Morgan Kaufmann Publishers Inc.,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1999}, {"title": "Learning the causal structure of overlapping variable sets", "author": ["D. Danks"], "venue": "International Conference on Discovery Science, pages 178\u2013 191. Springer,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2002}, {"title": "Scientific coherence and the fusion of experimental results", "author": ["D. Danks"], "venue": "The British Journal for the Philosophy of Science, 56(4):791\u2013 807,", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2005}, {"title": "Structure learning in graphical modeling", "author": ["M. Drton", "M.H. Maathuis"], "venue": "arXiv preprint arXiv:1606.02359,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2016}, {"title": "Introduction to structural equation models", "author": ["O.D. Duncan"], "venue": "Elsevier,", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2014}, {"title": "On the number of experiments sufficient and in the worst case necessary to identify all causal relations among n variables", "author": ["F. Eberhardt", "C. Glymour", "R. Scheines"], "venue": "In UAI,", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2005}, {"title": "Causal discovery for climate research using graphical models", "author": ["I. Ebert-Uphoff", "Y. Deng"], "venue": "Journal of Climate, 25(17):5648\u2013 5665,", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2012}, {"title": "Inferring cellular networks using probabilistic graphical models", "author": ["N. Friedman"], "venue": "Science, 303(5659):799\u2013805,", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2004}, {"title": "Fast markov blanket discovery algorithm via local learning within single pass", "author": ["S. Fu", "M.C. Desmarais"], "venue": "Conference of the Canadian Society for Computational Studies of Intelligence, pages 96\u2013107. Springer,", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2008}, {"title": "Local causal discovery of direct causes and effects", "author": ["T. Gao", "Q. Ji"], "venue": "NIPS\u201915, pages 2503\u20132511,", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2015}, {"title": "Efficient markov blanket discovery and its application", "author": ["T. Gao", "Q. Ji"], "venue": "IEEE Transactions on Cybernetics, DOI: 10.1109/TCYB.2016.2539338,", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2016}, {"title": "Decomposition of search for vstructures in dags", "author": ["Z. Geng", "C. Wang", "Q. Zhao"], "venue": "Journal of Multivariate Analysis, 96(2):282\u2013294,", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2005}, {"title": "Computation, causation, and discovery", "author": ["C.N. Glymour", "G.F. Cooper"], "venue": "Aaai Press,", "citeRegEx": "34", "shortCiteRegEx": null, "year": 1999}, {"title": "Gene selection for cancer classification using support vector machines", "author": ["I. Guyon", "J. Weston", "S. Barnhill", "V. Vapnik"], "venue": "Machine learning, 46(1-3):389\u2013422,", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2002}, {"title": "Pc algorithm for nonparanormal graphical models", "author": ["N. Harris", "M. Drton"], "venue": "Journal of Machine Learning Research, 14(1):3365\u20133383,", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2013}, {"title": "Active learning of causal networks with intervention experiments and optimal designs", "author": ["Y.-B. He", "Z. Geng"], "venue": "Journal of Machine Learning Research, 9(Nov):2523\u20132547,", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2008}, {"title": "Experiment selection for causal discovery", "author": ["A. Hyttinen", "F. Eberhardt", "P.O. Hoyer"], "venue": "Journal of Machine Learning Research, 14(1):3041\u20133071,", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2013}, {"title": "Constraint-based causal discovery: Conflict resolution with answer set programming", "author": ["A. Hyttinen", "F. Eberhardt", "M. J\u00e4rvisalo"], "venue": "Proc. UAI, pages 340\u2013349,", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2014}, {"title": "Discovering cyclic causal models with latent variables: A general sat-based procedure", "author": ["A. Hyttinen", "P.O. Hoyer", "F. Eberhardt", "M. J\u00e4rvisalo"], "venue": "Uncertainty in Artificial Intelligence, page 301. Citeseer,", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2013}, {"title": "The directions of selection bias", "author": ["Z. Jiang", "P. Ding"], "venue": "arXiv preprint arXiv:1609.07834,", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2016}, {"title": "Estimating high-dimensional directed acyclic graphs with the pc-algorithm", "author": ["M. Kalisch", "P. B\u00fchlmann"], "venue": "Journal of Machine Learning Research, 8(Mar):613\u2013636,", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2007}, {"title": "A review of causal inference for biomedical informatics", "author": ["S. Kleinberg", "G. Hripcsak"], "venue": "Journal of biomedical informatics, 44(6):1102\u20131112,", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2011}, {"title": "Probabilistic graphical models: principles and techniques", "author": ["D. Koller", "N. Friedman"], "venue": "MIT press,", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2009}, {"title": "A review of bayesian networks and structure learning", "author": ["T.J. Koski", "J.M. Noble"], "venue": "Mathematica Applicanda, 40(1):53\u2013103,", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2012}, {"title": "Probabilistic computational causal discovery for systems biology", "author": ["V. Lagani", "S. Triantafillou", "G. Ball", "J. Tegn\u00e9r", "I. Tsamardinos"], "venue": "Uncertainty in Biology, pages 33\u201373. Springer,", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2016}, {"title": "Parallelpc: an r package for efficient constraint based causal exploration", "author": ["T.D. Le", "T. Hoang", "J. Li", "L. Liu", "S. Hu"], "venue": "arXiv preprint arXiv:1510.03042,", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2015}, {"title": "A fast pc algorithm for high dimensional causal discovery with multi-core pcs", "author": ["T.D. Le", "T. Hoang", "J. Li", "L. Liu", "H. Liu"], "venue": "arXiv preprint arXiv:1502.02454,", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2015}, {"title": "Inferring microrna\u2013mrna causal regulatory relationships from expression data", "author": ["T.D. Le", "L. Liu", "A. Tsykin", "G.J. Goodall", "B. Liu", "B.-Y. Sun", "J. Li"], "venue": "Bioinformatics, 29(6):765\u2013771,", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2013}, {"title": "Conservative independence-based causal structure learning in absence of adjacency faithfulness", "author": ["J. Lemeire", "S. Meganck", "F. Cartella", "T. Liu"], "venue": "International Journal of Approximate Reasoning, 53(9):1305\u20131325,", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2012}, {"title": "Adaptive thresholding in structure learning of a bayesian network", "author": ["B. Lerner", "M. Afek", "R. Bojmel"], "venue": "IJCAI,", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2013}, {"title": "From observational studies to causal rule mining", "author": ["J. Li", "T.D. Le", "L. Liu", "J. Liu", "Z. Jin", "B. Sun", "S. Ma"], "venue": "ACM Transactions on Intelligent Systems and Technology (TIST), 7(2):14,", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2016}, {"title": "Practical approaches to causal relationship exploration", "author": ["J. Li", "L. Liu", "T. Le"], "venue": "Springer,", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2015}, {"title": "Controlling the false discovery rate of the association/causality structure learned with the pc algorithm", "author": ["J. Li", "Z.J. Wang"], "venue": "Journal of Machine Learning Research, 10(Feb):475\u2013514,", "citeRegEx": "54", "shortCiteRegEx": null, "year": 2009}, {"title": "Big data problems on discovering and analyzing causal relationships in epidemiological data", "author": ["Y. Liang", "A.R. Mikler"], "venue": "Big Data, 2014 IEEE International Conference on, pages 11\u201318. IEEE,", "citeRegEx": "55", "shortCiteRegEx": null, "year": 2014}, {"title": "Determining molecular predictors of adverse drug reactions with causality analysis based on structure learning", "author": ["M. Liu", "R. Cai", "Y. Hu", "M.E. Matheny", "J. Sun", "J. Hu", "H. Xu"], "venue": "Journal of the American Medical Informatics Association, 21(2):245\u2013251,", "citeRegEx": "56", "shortCiteRegEx": null, "year": 2014}, {"title": "Swamping and masking in markov boundary discovery", "author": ["X. Liu", "X. Liu"], "venue": "Machine Learning, pages 1\u201330,", "citeRegEx": "57", "shortCiteRegEx": null, "year": 2016}, {"title": "A review of some recent advances in causal inference", "author": ["M.H. Maathuis", "P. Nandy"], "venue": "Handbook of Big Data, page 387,", "citeRegEx": "58", "shortCiteRegEx": null, "year": 2016}, {"title": "A new class of non-shannon-type inequalities for entropies", "author": ["K. Makarychev", "Y. Makarychev", "A. Romashchenko", "N. Vereshchagin"], "venue": "Communications in Information and Systems, 2(2):147\u2013 166,", "citeRegEx": "59", "shortCiteRegEx": null, "year": 2002}, {"title": "Bayesian algorithms for causal data mining", "author": ["S. Mani", "C.F. Aliferis", "A.R. Statnikov", "M. NYU"], "venue": "NIPS Causality: Objectives and Assessment, pages 121\u2013136,", "citeRegEx": "60", "shortCiteRegEx": null, "year": 2010}, {"title": "A study in causal discovery from population-based infant birth and death records", "author": ["S. Mani", "G.F. Cooper"], "venue": "Proceedings of the AMIA Symposium, page 315. American Medical Informatics Association,", "citeRegEx": "61", "shortCiteRegEx": null, "year": 1999}, {"title": "Causal discovery from medical textual data", "author": ["S. Mani", "G.F. Cooper"], "venue": "Proceedings of the AMIA Symposium, page 542. American Medical Informatics Association,", "citeRegEx": "62", "shortCiteRegEx": null, "year": 2000}, {"title": "Causal discovery using a bayesian local causal discovery algorithm", "author": ["S. Mani", "G.F. Cooper"], "venue": "Medinfo, 11(Pt 1):731\u2013735,", "citeRegEx": "63", "shortCiteRegEx": null, "year": 2004}, {"title": "A constraint-based modelling approach to metabolic dysfunction in parkinson\u2019s disease", "author": ["L. Mao", "A. Nicolae", "M.A. Oliveira", "F. He", "S. Hachi", "R.M. Fleming"], "venue": "Computational and structural biotechnology journal, 13:484\u2013491,", "citeRegEx": "64", "shortCiteRegEx": null, "year": 2015}, {"title": "Bayesian network induction via local neighborhoods", "author": ["D. Margaritis", "S. Thrun"], "venue": "Technical report,", "citeRegEx": "65", "shortCiteRegEx": null, "year": 2000}, {"title": "Bayesian network induction via local neighborhoods", "author": ["D. Margaritis", "S. Thrun"], "venue": "Advances in Neural Information Processing Systems, pages 505\u2013511,", "citeRegEx": "66", "shortCiteRegEx": null, "year": 2000}, {"title": "Causal inference and causal explanation with background knowledge", "author": ["C. Meek"], "venue": "Proceedings of the Eleventh conference on Uncertainty in artificial intelligence, pages 403\u2013410. Morgan Kaufmann Publishers Inc.,", "citeRegEx": "67", "shortCiteRegEx": null, "year": 1995}, {"title": "Learning causal bayesian networks from observations and experiments: A decision theoretic approach", "author": ["S. Meganck", "P. Leray", "B. Manderick"], "venue": "International Conference on Modeling Decisions for Artificial Intelligence, pages 58\u201369. Springer,", "citeRegEx": "68", "shortCiteRegEx": null, "year": 2006}, {"title": "Learning bayesian networks", "author": ["R.E. Neapolitan"], "venue": null, "citeRegEx": "69", "shortCiteRegEx": "69", "year": 2004}, {"title": "Causal inference with observational data", "author": ["A. Nichols"], "venue": "Stata Journal,", "citeRegEx": "70", "shortCiteRegEx": "70", "year": 2007}, {"title": "Causation in epidemiology", "author": ["M. Parascandola", "D.L. Weed"], "venue": "Journal of Epidemiology and Community Health, 55(12):905\u2013912,", "citeRegEx": "71", "shortCiteRegEx": null, "year": 2001}, {"title": "Probabilistic reasoning in intelligent systems: networks of plausible inference", "author": ["J. Pearl"], "venue": "Morgan Kaufmann,", "citeRegEx": "72", "shortCiteRegEx": null, "year": 1988}, {"title": "An introduction to causal inference", "author": ["J. Pearl"], "venue": "The international journal of biostatistics, 6(2),", "citeRegEx": "73", "shortCiteRegEx": null, "year": 2010}, {"title": "Causality: Models, Reasoning, and Inference", "author": ["J. Pearl"], "venue": "Second Edition, Cambridge University Press,", "citeRegEx": "74", "shortCiteRegEx": null, "year": 2014}, {"title": "Using markov blankets for causal structure learning", "author": ["J.-P. Pellet", "A. Elisseeff"], "venue": "Journal of Machine Learning Research, 9(Jul):1295\u20131342,", "citeRegEx": "75", "shortCiteRegEx": null, "year": 2008}, {"title": "Finding latent causes in causal networks: an efficient approach based on markov blankets", "author": ["J.-P. Pellet", "A. Elisseeff"], "venue": "NIPS\u201909, pages 1249\u20131256,", "citeRegEx": "76", "shortCiteRegEx": null, "year": 2009}, {"title": "Learning gaussian graphical models of gene networks with false discovery rate control", "author": ["J.M. Pe\u00f1a"], "venue": "European conference on evolutionary computation, machine learning and data mining in bioinformatics, pages 165\u2013176. Springer,", "citeRegEx": "77", "shortCiteRegEx": null, "year": 2008}, {"title": "Towards scalable and data efficient learning of markov boundaries", "author": ["J.M. Pe\u00f1a", "R. Nilsson", "J. Bj\u00f6rkegren", "J. Tegn\u00e9r"], "venue": "International Journal of Approximate Reasoning, 45(2):211\u2013232,", "citeRegEx": "78", "shortCiteRegEx": null, "year": 2007}, {"title": "Causal inference using invariant prediction: identification and confidence intervals", "author": ["J. Peters", "P. B\u00fchlmann", "N. Meinshausen"], "venue": "arXiv preprint arXiv:1501.01332,", "citeRegEx": "79", "shortCiteRegEx": null, "year": 2015}, {"title": "Adjacency-faithfulness and conservative causal inference", "author": ["J. Ramsey", "J. Zhang", "P.L. Spirtes"], "venue": "UAI\u201906, pages 401\u2013408,", "citeRegEx": "80", "shortCiteRegEx": null, "year": 2006}, {"title": "Ancestral graph markov models", "author": ["T. Richardson", "P. Spirtes"], "venue": "Annals of Statistics, pages 962\u20131030,", "citeRegEx": "81", "shortCiteRegEx": null, "year": 2002}, {"title": "Estimating causal effects of treatments in randomized and nonrandomized studies", "author": ["D.B. Rubin"], "venue": "Journal of educational Psychology, 66(5):688,", "citeRegEx": "82", "shortCiteRegEx": null, "year": 1974}, {"title": "Causal inference using potential outcomes", "author": ["D.B. Rubin"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "83", "shortCiteRegEx": null, "year": 2011}, {"title": "Identifying causal gateways and mediators in complex spatio-temporal systems", "author": ["J. Runge", "V. Petoukhov", "J.F. Donges", "J. Hlinka", "N. Jajcay", "M. Vejmelka", "D. Hartman", "N. Marwan", "M. Palu\u0161", "J. Kurths"], "venue": "Nature communications, 6,", "citeRegEx": "84", "shortCiteRegEx": null, "year": 2015}, {"title": "The hidden life of latent variables: Bayesian learning with mixed graph models", "author": ["R. Silva", "Z. Ghahramani"], "venue": "Journal of Machine Learning Research, 10(Jun):1187\u20131238,", "citeRegEx": "85", "shortCiteRegEx": null, "year": 2009}, {"title": "Scalable techniques for mining causal structures", "author": ["C. Silverstein", "S. Brin", "R. Motwani", "J. Ullman"], "venue": "Data Mining and Knowledge Discovery, 4(2-3):163\u2013192,", "citeRegEx": "86", "shortCiteRegEx": null, "year": 2000}, {"title": "Introduction to causal inference", "author": ["P. Spirtes"], "venue": "Journal of Machine Learning Research, 11(May):1643\u20131662,", "citeRegEx": "88", "shortCiteRegEx": null, "year": 2010}, {"title": "An algorithm for fast recovery of sparse causal graphs", "author": ["P. Spirtes", "C. Glymour"], "venue": "Social science computer review, 9(1):62\u201372,", "citeRegEx": "89", "shortCiteRegEx": null, "year": 1991}, {"title": "Causation, prediction, and search", "author": ["P. Spirtes", "C.N. Glymour", "R. Scheines"], "venue": "MIT press,", "citeRegEx": "90", "shortCiteRegEx": null, "year": 2000}, {"title": "A uniformly consistent estimator of causal effects under the k-triangle-faithfulness assumption", "author": ["P. Spirtes", "J. Zhang"], "venue": "Statistical Science,", "citeRegEx": "91", "shortCiteRegEx": "91", "year": 2014}, {"title": "Algorithms for discovery of multiple markov boundaries", "author": ["A. Statnikov", "J. Lemeir", "C.F. Aliferis"], "venue": "The Journal of Machine Learning Research, 14(1):499\u2013566,", "citeRegEx": "92", "shortCiteRegEx": null, "year": 2013}, {"title": "Ultra-scalable and efficient methods for hybrid observational and experimental local causal pathway discovery", "author": ["A. Statnikov", "S. Ma", "M. Henaff", "N. Lytkin", "E. Efstathiadis", "E.R. Peskin", "C.F. Aliferis"], "venue": "J Mach Learn Res,", "citeRegEx": "93", "shortCiteRegEx": null, "year": 2015}, {"title": "A direct approach to false discovery rates", "author": ["J.D. Storey"], "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology), 64(3):479\u2013498,", "citeRegEx": "94", "shortCiteRegEx": null, "year": 2002}, {"title": "Integrating locally learned causal structures with overlapping variables", "author": ["R.E. Tillman", "D. Danks", "C. Glymour"], "venue": "Advances in Neural Information Processing Systems, pages 1665\u20131672,", "citeRegEx": "95", "shortCiteRegEx": null, "year": 2009}, {"title": "Learning equivalence classes of acyclic models with latent and selection variables from multiple datasets with overlapping variables", "author": ["R.E. Tillman", "P. Spirtes"], "venue": "AISTATS, pages 3\u201315,", "citeRegEx": "96", "shortCiteRegEx": null, "year": 2011}, {"title": "Active learning for structure in bayesian networks", "author": ["S. Tong", "D. Koller"], "venue": "International joint conference on artificial intelligence, volume 17, pages 863\u2013869. LAWRENCE ERLBAUM AS- SOCIATES LTD,", "citeRegEx": "97", "shortCiteRegEx": null, "year": 2001}, {"title": "Constraint-based causal discovery from multiple interventions over overlapping variable sets", "author": ["S. Triantafillou", "I. Tsamardinos"], "venue": "J Machine Learn Res, 16:2147\u20132205,", "citeRegEx": "98", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning causal structure from overlapping variable sets", "author": ["S. Triantafilou", "I. Tsamardinos", "I.G. Tollis"], "venue": "AISTATS, pages 860\u2013 867,", "citeRegEx": "99", "shortCiteRegEx": null, "year": 2010}, {"title": "Towards principled feature selection: relevancy, filters and wrappers", "author": ["I. Tsamardinos", "C.F. Aliferis"], "venue": "AISTATS,", "citeRegEx": "100", "shortCiteRegEx": null, "year": 2003}, {"title": "Time and sample efficient discovery of markov blankets and direct causal relations", "author": ["I. Tsamardinos", "C.F. Aliferis", "A. Statnikov"], "venue": "Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 673\u2013678. ACM,", "citeRegEx": "101", "shortCiteRegEx": null, "year": 2003}, {"title": "Algorithms for large scale markov blanket discovery", "author": ["I. Tsamardinos", "C.F. Aliferis", "A.R. Statnikov", "E. Statnikov"], "venue": "FLAIRS conference, volume 2,", "citeRegEx": "102", "shortCiteRegEx": null, "year": 2003}, {"title": "Bounding the false discovery rate in local bayesian network learning", "author": ["I. Tsamardinos", "L.E. Brown"], "venue": "AAAI, pages 1100\u2013 1105,", "citeRegEx": "103", "shortCiteRegEx": null, "year": 2008}, {"title": "The max-min hillclimbing bayesian network structure learning algorithm", "author": ["I. Tsamardinos", "L.E. Brown", "C.F. Aliferis"], "venue": "Machine learning, 65(1):31\u201378,", "citeRegEx": "104", "shortCiteRegEx": null, "year": 2006}, {"title": "Towards integrative causal analysis of heterogeneous data sets and studies", "author": ["I. Tsamardinos", "S. Triantafillou", "V. Lagani"], "venue": "Journal of Machine Learning Research, 13(Apr):1097\u20131157,", "citeRegEx": "105", "shortCiteRegEx": null, "year": 2012}, {"title": "Equivalence and synthesis of causal models", "author": ["T. Vermal", "J. Pearl"], "venue": "Proceedings of Sixth Conference on Uncertainty in Artijicial Intelligence, pages 220\u2013227,", "citeRegEx": "106", "shortCiteRegEx": null, "year": 1991}, {"title": "Correlation and causation", "author": ["S. Wright"], "venue": "Journal of agricultural research, 20(7):557\u2013585,", "citeRegEx": "107", "shortCiteRegEx": null, "year": 1921}, {"title": "A definition of conditional mutual information for arbitrary ensembles", "author": ["A.D. Wyner"], "venue": "Information and Control, 38(1):51\u201359,", "citeRegEx": "108", "shortCiteRegEx": null, "year": 1978}, {"title": "A recursive method for structural learning of directed acyclic graphs", "author": ["X. Xie", "Z. Geng"], "venue": "Journal of Machine Learning Research, 9(Mar):459\u2013483,", "citeRegEx": "109", "shortCiteRegEx": null, "year": 2008}, {"title": "Decomposition of structural learning about directed acyclic graphs", "author": ["X. Xie", "Z. Geng", "Q. Zhao"], "venue": "Artificial Intelligence, 170(4):422\u2013439,", "citeRegEx": "110", "shortCiteRegEx": null, "year": 2006}, {"title": "Recursive autonomy identification for bayesian network structure learning", "author": ["R. Yehezkel", "B. Lerner"], "venue": "AISTATS, pages 429\u2013436. Citeseer,", "citeRegEx": "111", "shortCiteRegEx": null, "year": 2005}, {"title": "Bayesian network structure learning by recursive autonomy identification", "author": ["R. Yehezkel", "B. Lerner"], "venue": "Journal of Machine Learning Research, 10(Jul):1527\u20131570,", "citeRegEx": "112", "shortCiteRegEx": null, "year": 2009}, {"title": "Partial orientation and local structural learning of causal networks for prediction", "author": ["J. Yin", "Y. Zhou", "C. Wang", "P. He", "C. Zheng", "Z. Geng"], "venue": "WCCI Causation and Prediction Challenge, pages 93\u2013 105,", "citeRegEx": "113", "shortCiteRegEx": null, "year": 2008}, {"title": "Bridging causal relevance and pattern discriminability: Mining emerging patterns from high-dimensional data", "author": ["K. Yu", "W. Ding", "H. Wang", "X. Wu"], "venue": "IEEE Transactions on Knowledge and Data Engineering, 25(12):2721\u20132739,", "citeRegEx": "114", "shortCiteRegEx": null, "year": 2013}, {"title": "Tornado forecasting with multiple markov boundaries", "author": ["K. Yu", "D. Wang", "W. Ding", "J. Pei", "D.L. Small", "S. Islam", "X. Wu"], "venue": "Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 2237\u20132246. ACM,", "citeRegEx": "115", "shortCiteRegEx": null, "year": 2015}, {"title": "Markov blanket feature selection using representative sets", "author": ["K. Yu", "X. Wu", "W. Ding", "Y. Mu", "H. Wang"], "venue": "IEEE Transactions on Neural Networks and Learning Systems, DOI: 10.1109/TNNLS.2016.2602365,", "citeRegEx": "116", "shortCiteRegEx": null, "year": 2016}, {"title": "Exploring causal relationships with streaming features", "author": ["K. Yu", "X. Wu", "W. Ding", "H. Wang"], "venue": "The Computer Journal, 55(9):1103\u2013 1117,", "citeRegEx": "117", "shortCiteRegEx": null, "year": 2012}, {"title": "On the completeness of orientation rules for causal discovery in the presence of latent confounders and selection bias", "author": ["J. Zhang"], "venue": "Artificial Intelligence, 172(16):1873\u20131896,", "citeRegEx": "118", "shortCiteRegEx": null, "year": 2008}, {"title": "Detection of unfaithfulness and robust causal inference", "author": ["J. Zhang", "P. Spirtes"], "venue": "Minds and Machines, 18(2):239\u2013271,", "citeRegEx": "119", "shortCiteRegEx": null, "year": 2008}], "referenceMentions": [{"referenceID": 28, "context": "Discovering causal relationships between variables from data is fundamental in all areas of sciences, such as computer science, medicine, statistics, economy, and social sciences [29, 44, 52, 69, 74, 90, 114].", "startOffset": 179, "endOffset": 208}, {"referenceID": 43, "context": "Discovering causal relationships between variables from data is fundamental in all areas of sciences, such as computer science, medicine, statistics, economy, and social sciences [29, 44, 52, 69, 74, 90, 114].", "startOffset": 179, "endOffset": 208}, {"referenceID": 51, "context": "Discovering causal relationships between variables from data is fundamental in all areas of sciences, such as computer science, medicine, statistics, economy, and social sciences [29, 44, 52, 69, 74, 90, 114].", "startOffset": 179, "endOffset": 208}, {"referenceID": 68, "context": "Discovering causal relationships between variables from data is fundamental in all areas of sciences, such as computer science, medicine, statistics, economy, and social sciences [29, 44, 52, 69, 74, 90, 114].", "startOffset": 179, "endOffset": 208}, {"referenceID": 73, "context": "Discovering causal relationships between variables from data is fundamental in all areas of sciences, such as computer science, medicine, statistics, economy, and social sciences [29, 44, 52, 69, 74, 90, 114].", "startOffset": 179, "endOffset": 208}, {"referenceID": 88, "context": "Discovering causal relationships between variables from data is fundamental in all areas of sciences, such as computer science, medicine, statistics, economy, and social sciences [29, 44, 52, 69, 74, 90, 114].", "startOffset": 179, "endOffset": 208}, {"referenceID": 112, "context": "Discovering causal relationships between variables from data is fundamental in all areas of sciences, such as computer science, medicine, statistics, economy, and social sciences [29, 44, 52, 69, 74, 90, 114].", "startOffset": 179, "endOffset": 208}, {"referenceID": 43, "context": "alternative to randomized controlled experiments [44, 53, 83, 117], since observational data can often be collected cheaply and is abundant, while in many settings, randomized controlled experiments are unethical or impossible [38, 70, 82].", "startOffset": 49, "endOffset": 66}, {"referenceID": 52, "context": "alternative to randomized controlled experiments [44, 53, 83, 117], since observational data can often be collected cheaply and is abundant, while in many settings, randomized controlled experiments are unethical or impossible [38, 70, 82].", "startOffset": 49, "endOffset": 66}, {"referenceID": 82, "context": "alternative to randomized controlled experiments [44, 53, 83, 117], since observational data can often be collected cheaply and is abundant, while in many settings, randomized controlled experiments are unethical or impossible [38, 70, 82].", "startOffset": 49, "endOffset": 66}, {"referenceID": 115, "context": "alternative to randomized controlled experiments [44, 53, 83, 117], since observational data can often be collected cheaply and is abundant, while in many settings, randomized controlled experiments are unethical or impossible [38, 70, 82].", "startOffset": 49, "endOffset": 66}, {"referenceID": 37, "context": "alternative to randomized controlled experiments [44, 53, 83, 117], since observational data can often be collected cheaply and is abundant, while in many settings, randomized controlled experiments are unethical or impossible [38, 70, 82].", "startOffset": 227, "endOffset": 239}, {"referenceID": 69, "context": "alternative to randomized controlled experiments [44, 53, 83, 117], since observational data can often be collected cheaply and is abundant, while in many settings, randomized controlled experiments are unethical or impossible [38, 70, 82].", "startOffset": 227, "endOffset": 239}, {"referenceID": 81, "context": "alternative to randomized controlled experiments [44, 53, 83, 117], since observational data can often be collected cheaply and is abundant, while in many settings, randomized controlled experiments are unethical or impossible [38, 70, 82].", "startOffset": 227, "endOffset": 239}, {"referenceID": 33, "context": "particularly in the area of graphical causal modeling [34, 44, 74, 87].", "startOffset": 54, "endOffset": 70}, {"referenceID": 43, "context": "particularly in the area of graphical causal modeling [34, 44, 74, 87].", "startOffset": 54, "endOffset": 70}, {"referenceID": 73, "context": "particularly in the area of graphical causal modeling [34, 44, 74, 87].", "startOffset": 54, "endOffset": 70}, {"referenceID": 17, "context": "The most frequently used causal models belong to two broad families: (1) causal Bayesian networks [18, 72, 87], and (2) structural equation models (functional causal models) [26, 107].", "startOffset": 98, "endOffset": 110}, {"referenceID": 71, "context": "The most frequently used causal models belong to two broad families: (1) causal Bayesian networks [18, 72, 87], and (2) structural equation models (functional causal models) [26, 107].", "startOffset": 98, "endOffset": 110}, {"referenceID": 25, "context": "The most frequently used causal models belong to two broad families: (1) causal Bayesian networks [18, 72, 87], and (2) structural equation models (functional causal models) [26, 107].", "startOffset": 174, "endOffset": 183}, {"referenceID": 105, "context": "The most frequently used causal models belong to two broad families: (1) causal Bayesian networks [18, 72, 87], and (2) structural equation models (functional causal models) [26, 107].", "startOffset": 174, "endOffset": 183}, {"referenceID": 14, "context": "Score-based algorithms assign a score to each candidate Bayesian network for measuring how well the candidate Bayesian network fits a data set [15, 21].", "startOffset": 143, "endOffset": 151}, {"referenceID": 20, "context": "Score-based algorithms assign a score to each candidate Bayesian network for measuring how well the candidate Bayesian network fits a data set [15, 21].", "startOffset": 143, "endOffset": 151}, {"referenceID": 71, "context": "with conditional independence tests through analyzing the probabilistic relations entailed by the Markov property of Bayesian networks [72, 74].", "startOffset": 135, "endOffset": 143}, {"referenceID": 73, "context": "with conditional independence tests through analyzing the probabilistic relations entailed by the Markov property of Bayesian networks [72, 74].", "startOffset": 135, "endOffset": 143}, {"referenceID": 84, "context": "of latent variables and the exact locations of the latent variables with the observed variables in data before learning starts [85].", "startOffset": 127, "endOffset": 131}, {"referenceID": 13, "context": "based method [14].", "startOffset": 13, "endOffset": 17}, {"referenceID": 17, "context": "The computational intractability is a key drawback of the score-based methods [18].", "startOffset": 78, "endOffset": 82}, {"referenceID": 27, "context": "based approaches have gradually attracted a lot of recent interest and has been widely applied to diverse real-world problems in climate research [28, 84], bioinformatics [43, 49], medical science [20, 56, 62], and epidemiology [55, 64, 71].", "startOffset": 146, "endOffset": 154}, {"referenceID": 83, "context": "based approaches have gradually attracted a lot of recent interest and has been widely applied to diverse real-world problems in climate research [28, 84], bioinformatics [43, 49], medical science [20, 56, 62], and epidemiology [55, 64, 71].", "startOffset": 146, "endOffset": 154}, {"referenceID": 42, "context": "based approaches have gradually attracted a lot of recent interest and has been widely applied to diverse real-world problems in climate research [28, 84], bioinformatics [43, 49], medical science [20, 56, 62], and epidemiology [55, 64, 71].", "startOffset": 171, "endOffset": 179}, {"referenceID": 48, "context": "based approaches have gradually attracted a lot of recent interest and has been widely applied to diverse real-world problems in climate research [28, 84], bioinformatics [43, 49], medical science [20, 56, 62], and epidemiology [55, 64, 71].", "startOffset": 171, "endOffset": 179}, {"referenceID": 19, "context": "based approaches have gradually attracted a lot of recent interest and has been widely applied to diverse real-world problems in climate research [28, 84], bioinformatics [43, 49], medical science [20, 56, 62], and epidemiology [55, 64, 71].", "startOffset": 197, "endOffset": 209}, {"referenceID": 55, "context": "based approaches have gradually attracted a lot of recent interest and has been widely applied to diverse real-world problems in climate research [28, 84], bioinformatics [43, 49], medical science [20, 56, 62], and epidemiology [55, 64, 71].", "startOffset": 197, "endOffset": 209}, {"referenceID": 61, "context": "based approaches have gradually attracted a lot of recent interest and has been widely applied to diverse real-world problems in climate research [28, 84], bioinformatics [43, 49], medical science [20, 56, 62], and epidemiology [55, 64, 71].", "startOffset": 197, "endOffset": 209}, {"referenceID": 54, "context": "based approaches have gradually attracted a lot of recent interest and has been widely applied to diverse real-world problems in climate research [28, 84], bioinformatics [43, 49], medical science [20, 56, 62], and epidemiology [55, 64, 71].", "startOffset": 228, "endOffset": 240}, {"referenceID": 63, "context": "based approaches have gradually attracted a lot of recent interest and has been widely applied to diverse real-world problems in climate research [28, 84], bioinformatics [43, 49], medical science [20, 56, 62], and epidemiology [55, 64, 71].", "startOffset": 228, "endOffset": 240}, {"referenceID": 70, "context": "based approaches have gradually attracted a lot of recent interest and has been widely applied to diverse real-world problems in climate research [28, 84], bioinformatics [43, 49], medical science [20, 56, 62], and epidemiology [55, 64, 71].", "startOffset": 228, "endOffset": 240}, {"referenceID": 7, "context": "Although some reviews on causal inference have been proposed [8, 25, 45, 58, 73, 88], those reviews attempt to", "startOffset": 61, "endOffset": 84}, {"referenceID": 24, "context": "Although some reviews on causal inference have been proposed [8, 25, 45, 58, 73, 88], those reviews attempt to", "startOffset": 61, "endOffset": 84}, {"referenceID": 44, "context": "Although some reviews on causal inference have been proposed [8, 25, 45, 58, 73, 88], those reviews attempt to", "startOffset": 61, "endOffset": 84}, {"referenceID": 57, "context": "Although some reviews on causal inference have been proposed [8, 25, 45, 58, 73, 88], those reviews attempt to", "startOffset": 61, "endOffset": 84}, {"referenceID": 72, "context": "Although some reviews on causal inference have been proposed [8, 25, 45, 58, 73, 88], those reviews attempt to", "startOffset": 61, "endOffset": 84}, {"referenceID": 86, "context": "Although some reviews on causal inference have been proposed [8, 25, 45, 58, 73, 88], those reviews attempt to", "startOffset": 61, "endOffset": 84}, {"referenceID": 80, "context": "cestral graph) [81] to represent casual relations when causal sufficiency is not assumed.", "startOffset": 15, "endOffset": 19}, {"referenceID": 12, "context": "to discover the skeleton including all variables [13, 90, 90, 106], while the local method mines local skeletons, i.", "startOffset": 49, "endOffset": 66}, {"referenceID": 88, "context": "to discover the skeleton including all variables [13, 90, 90, 106], while the local method mines local skeletons, i.", "startOffset": 49, "endOffset": 66}, {"referenceID": 88, "context": "to discover the skeleton including all variables [13, 90, 90, 106], while the local method mines local skeletons, i.", "startOffset": 49, "endOffset": 66}, {"referenceID": 104, "context": "to discover the skeleton including all variables [13, 90, 90, 106], while the local method mines local skeletons, i.", "startOffset": 49, "endOffset": 66}, {"referenceID": 64, "context": ", the set of adjacent variables (parents and children) or Markov blanket of each vertex, then constructs a global skeleton by local skeletons [65, 75].", "startOffset": 142, "endOffset": 150}, {"referenceID": 74, "context": ", the set of adjacent variables (parents and children) or Markov blanket of each vertex, then constructs a global skeleton by local skeletons [65, 75].", "startOffset": 142, "endOffset": 150}, {"referenceID": 66, "context": "Meek rules and Zhang Jiji\u2019s rules) defined in [67, 118] using observational data.", "startOffset": 46, "endOffset": 55}, {"referenceID": 116, "context": "Meek rules and Zhang Jiji\u2019s rules) defined in [67, 118] using observational data.", "startOffset": 46, "endOffset": 55}, {"referenceID": 21, "context": "entation [22, 97].", "startOffset": 9, "endOffset": 17}, {"referenceID": 95, "context": "entation [22, 97].", "startOffset": 9, "endOffset": 17}, {"referenceID": 36, "context": "\u2022 Edge orientation using both observational data and experimental data, which first applies the rules in (1) to orient edges as many as possible, then orients the remaining unoriented edges with the method in (2) [37].", "startOffset": 213, "endOffset": 217}, {"referenceID": 0, "context": "In constraint-based algorithms, the independence tests generally can be implemented using the G test [1], mutual information [59, 108], and Fisher\u2019s Z-test [77].", "startOffset": 101, "endOffset": 104}, {"referenceID": 58, "context": "In constraint-based algorithms, the independence tests generally can be implemented using the G test [1], mutual information [59, 108], and Fisher\u2019s Z-test [77].", "startOffset": 125, "endOffset": 134}, {"referenceID": 106, "context": "In constraint-based algorithms, the independence tests generally can be implemented using the G test [1], mutual information [59, 108], and Fisher\u2019s Z-test [77].", "startOffset": 125, "endOffset": 134}, {"referenceID": 76, "context": "In constraint-based algorithms, the independence tests generally can be implemented using the G test [1], mutual information [59, 108], and Fisher\u2019s Z-test [77].", "startOffset": 156, "endOffset": 160}, {"referenceID": 0, "context": ",N/((ri\u22121)(rj\u22121)rk) \u2265 \u03c6 (N is the total number of instances, ri is the number of distinct values of Vi, and \u03c6 is often set to 5 or 10) [1].", "startOffset": 135, "endOffset": 138}, {"referenceID": 50, "context": "evaluated in terms of reliability [51].", "startOffset": 34, "endOffset": 38}, {"referenceID": 85, "context": "includes all variables involved in data is computational expensive or even infeasible in large-scale data mining applications with thousands of variables, thus it is challenging to develop algorithms scaling up to real-world data with high dimensionality [86].", "startOffset": 255, "endOffset": 259}, {"referenceID": 90, "context": "such as biomedical science [92] and climate research [115, 116], the assumption is often violated.", "startOffset": 27, "endOffset": 31}, {"referenceID": 113, "context": "such as biomedical science [92] and climate research [115, 116], the assumption is often violated.", "startOffset": 53, "endOffset": 63}, {"referenceID": 114, "context": "such as biomedical science [92] and climate research [115, 116], the assumption is often violated.", "startOffset": 53, "endOffset": 63}, {"referenceID": 117, "context": "Thus it is challenging to design robust causal inference algorithms by relaxing this assumption [119].", "startOffset": 96, "endOffset": 101}, {"referenceID": 16, "context": "In realworld applications, such as medical science, epidemiology, and sociology, it is impossible to ensure that all common causes are measured in study data [17].", "startOffset": 158, "endOffset": 162}, {"referenceID": 88, "context": "Algorithm approach Skeleton v-structure edge orientation Reference SGS global \u221a \u221a Rules 1 to 4 (meek rules) [90] TPDA global \u221a [13] PC global \u221a [90] CPC global \u221a \u221a [80] VCSGS global \u221a \u221a [91] ACPC global \u221a \u221a [50] PC-stable global \u221a [16] CPC/MPC-stable global \u221a \u221a [16] PC-FDR global \u221a [54] AIT global \u221a [22, 27, 68, 97] ALCBN global \u221a (hybrid orientation rules) [12] Xie-geng algorithm local-to-global \u221a \u221a [33, 33, 109] GSBN local-to-global \u221a [65] TC local-to-global \u221a [75] RAI local-to-global \u221a \u221a \u221a [111, 112] LCD local \u221a \u221a \u221a [19, 61, 86] PCD-by-PCD local \u221a \u221a \u221a [113] CMB local \u221a \u221a \u221a [31] ODLP local \u221a ignore the step \u221a (experimental orientation rules) [93] SLPR global (multiple data) \u221a \u221a [23]", "startOffset": 108, "endOffset": 112}, {"referenceID": 12, "context": "Algorithm approach Skeleton v-structure edge orientation Reference SGS global \u221a \u221a Rules 1 to 4 (meek rules) [90] TPDA global \u221a [13] PC global \u221a [90] CPC global \u221a \u221a [80] VCSGS global \u221a \u221a [91] ACPC global \u221a \u221a [50] PC-stable global \u221a [16] CPC/MPC-stable global \u221a \u221a [16] PC-FDR global \u221a [54] AIT global \u221a [22, 27, 68, 97] ALCBN global \u221a (hybrid orientation rules) [12] Xie-geng algorithm local-to-global \u221a \u221a [33, 33, 109] GSBN local-to-global \u221a [65] TC local-to-global \u221a [75] RAI local-to-global \u221a \u221a \u221a [111, 112] LCD local \u221a \u221a \u221a [19, 61, 86] PCD-by-PCD local \u221a \u221a \u221a [113] CMB local \u221a \u221a \u221a [31] ODLP local \u221a ignore the step \u221a (experimental orientation rules) [93] SLPR global (multiple data) \u221a \u221a [23]", "startOffset": 127, "endOffset": 131}, {"referenceID": 88, "context": "Algorithm approach Skeleton v-structure edge orientation Reference SGS global \u221a \u221a Rules 1 to 4 (meek rules) [90] TPDA global \u221a [13] PC global \u221a [90] CPC global \u221a \u221a [80] VCSGS global \u221a \u221a [91] ACPC global \u221a \u221a [50] PC-stable global \u221a [16] CPC/MPC-stable global \u221a \u221a [16] PC-FDR global \u221a [54] AIT global \u221a [22, 27, 68, 97] ALCBN global \u221a (hybrid orientation rules) [12] Xie-geng algorithm local-to-global \u221a \u221a [33, 33, 109] GSBN local-to-global \u221a [65] TC local-to-global \u221a [75] RAI local-to-global \u221a \u221a \u221a [111, 112] LCD local \u221a \u221a \u221a [19, 61, 86] PCD-by-PCD local \u221a \u221a \u221a [113] CMB local \u221a \u221a \u221a [31] ODLP local \u221a ignore the step \u221a (experimental orientation rules) [93] SLPR global (multiple data) \u221a \u221a [23]", "startOffset": 144, "endOffset": 148}, {"referenceID": 79, "context": "Algorithm approach Skeleton v-structure edge orientation Reference SGS global \u221a \u221a Rules 1 to 4 (meek rules) [90] TPDA global \u221a [13] PC global \u221a [90] CPC global \u221a \u221a [80] VCSGS global \u221a \u221a [91] ACPC global \u221a \u221a [50] PC-stable global \u221a [16] CPC/MPC-stable global \u221a \u221a [16] PC-FDR global \u221a [54] AIT global \u221a [22, 27, 68, 97] ALCBN global \u221a (hybrid orientation rules) [12] Xie-geng algorithm local-to-global \u221a \u221a [33, 33, 109] GSBN local-to-global \u221a [65] TC local-to-global \u221a [75] RAI local-to-global \u221a \u221a \u221a [111, 112] LCD local \u221a \u221a \u221a [19, 61, 86] PCD-by-PCD local \u221a \u221a \u221a [113] CMB local \u221a \u221a \u221a [31] ODLP local \u221a ignore the step \u221a (experimental orientation rules) [93] SLPR global (multiple data) \u221a \u221a [23]", "startOffset": 164, "endOffset": 168}, {"referenceID": 89, "context": "Algorithm approach Skeleton v-structure edge orientation Reference SGS global \u221a \u221a Rules 1 to 4 (meek rules) [90] TPDA global \u221a [13] PC global \u221a [90] CPC global \u221a \u221a [80] VCSGS global \u221a \u221a [91] ACPC global \u221a \u221a [50] PC-stable global \u221a [16] CPC/MPC-stable global \u221a \u221a [16] PC-FDR global \u221a [54] AIT global \u221a [22, 27, 68, 97] ALCBN global \u221a (hybrid orientation rules) [12] Xie-geng algorithm local-to-global \u221a \u221a [33, 33, 109] GSBN local-to-global \u221a [65] TC local-to-global \u221a [75] RAI local-to-global \u221a \u221a \u221a [111, 112] LCD local \u221a \u221a \u221a [19, 61, 86] PCD-by-PCD local \u221a \u221a \u221a [113] CMB local \u221a \u221a \u221a [31] ODLP local \u221a ignore the step \u221a (experimental orientation rules) [93] SLPR global (multiple data) \u221a \u221a [23]", "startOffset": 186, "endOffset": 190}, {"referenceID": 49, "context": "Algorithm approach Skeleton v-structure edge orientation Reference SGS global \u221a \u221a Rules 1 to 4 (meek rules) [90] TPDA global \u221a [13] PC global \u221a [90] CPC global \u221a \u221a [80] VCSGS global \u221a \u221a [91] ACPC global \u221a \u221a [50] PC-stable global \u221a [16] CPC/MPC-stable global \u221a \u221a [16] PC-FDR global \u221a [54] AIT global \u221a [22, 27, 68, 97] ALCBN global \u221a (hybrid orientation rules) [12] Xie-geng algorithm local-to-global \u221a \u221a [33, 33, 109] GSBN local-to-global \u221a [65] TC local-to-global \u221a [75] RAI local-to-global \u221a \u221a \u221a [111, 112] LCD local \u221a \u221a \u221a [19, 61, 86] PCD-by-PCD local \u221a \u221a \u221a [113] CMB local \u221a \u221a \u221a [31] ODLP local \u221a ignore the step \u221a (experimental orientation rules) [93] SLPR global (multiple data) \u221a \u221a [23]", "startOffset": 207, "endOffset": 211}, {"referenceID": 15, "context": "Algorithm approach Skeleton v-structure edge orientation Reference SGS global \u221a \u221a Rules 1 to 4 (meek rules) [90] TPDA global \u221a [13] PC global \u221a [90] CPC global \u221a \u221a [80] VCSGS global \u221a \u221a [91] ACPC global \u221a \u221a [50] PC-stable global \u221a [16] CPC/MPC-stable global \u221a \u221a [16] PC-FDR global \u221a [54] AIT global \u221a [22, 27, 68, 97] ALCBN global \u221a (hybrid orientation rules) [12] Xie-geng algorithm local-to-global \u221a \u221a [33, 33, 109] GSBN local-to-global \u221a [65] TC local-to-global \u221a [75] RAI local-to-global \u221a \u221a \u221a [111, 112] LCD local \u221a \u221a \u221a [19, 61, 86] PCD-by-PCD local \u221a \u221a \u221a [113] CMB local \u221a \u221a \u221a [31] ODLP local \u221a ignore the step \u221a (experimental orientation rules) [93] SLPR global (multiple data) \u221a \u221a [23]", "startOffset": 231, "endOffset": 235}, {"referenceID": 15, "context": "Algorithm approach Skeleton v-structure edge orientation Reference SGS global \u221a \u221a Rules 1 to 4 (meek rules) [90] TPDA global \u221a [13] PC global \u221a [90] CPC global \u221a \u221a [80] VCSGS global \u221a \u221a [91] ACPC global \u221a \u221a [50] PC-stable global \u221a [16] CPC/MPC-stable global \u221a \u221a [16] PC-FDR global \u221a [54] AIT global \u221a [22, 27, 68, 97] ALCBN global \u221a (hybrid orientation rules) [12] Xie-geng algorithm local-to-global \u221a \u221a [33, 33, 109] GSBN local-to-global \u221a [65] TC local-to-global \u221a [75] RAI local-to-global \u221a \u221a \u221a [111, 112] LCD local \u221a \u221a \u221a [19, 61, 86] PCD-by-PCD local \u221a \u221a \u221a [113] CMB local \u221a \u221a \u221a [31] ODLP local \u221a ignore the step \u221a (experimental orientation rules) [93] SLPR global (multiple data) \u221a \u221a [23]", "startOffset": 262, "endOffset": 266}, {"referenceID": 53, "context": "Algorithm approach Skeleton v-structure edge orientation Reference SGS global \u221a \u221a Rules 1 to 4 (meek rules) [90] TPDA global \u221a [13] PC global \u221a [90] CPC global \u221a \u221a [80] VCSGS global \u221a \u221a [91] ACPC global \u221a \u221a [50] PC-stable global \u221a [16] CPC/MPC-stable global \u221a \u221a [16] PC-FDR global \u221a [54] AIT global \u221a [22, 27, 68, 97] ALCBN global \u221a (hybrid orientation rules) [12] Xie-geng algorithm local-to-global \u221a \u221a [33, 33, 109] GSBN local-to-global \u221a [65] TC local-to-global \u221a [75] RAI local-to-global \u221a \u221a \u221a [111, 112] LCD local \u221a \u221a \u221a [19, 61, 86] PCD-by-PCD local \u221a \u221a \u221a [113] CMB local \u221a \u221a \u221a [31] ODLP local \u221a ignore the step \u221a (experimental orientation rules) [93] SLPR global (multiple data) \u221a \u221a [23]", "startOffset": 283, "endOffset": 287}, {"referenceID": 21, "context": "Algorithm approach Skeleton v-structure edge orientation Reference SGS global \u221a \u221a Rules 1 to 4 (meek rules) [90] TPDA global \u221a [13] PC global \u221a [90] CPC global \u221a \u221a [80] VCSGS global \u221a \u221a [91] ACPC global \u221a \u221a [50] PC-stable global \u221a [16] CPC/MPC-stable global \u221a \u221a [16] PC-FDR global \u221a [54] AIT global \u221a [22, 27, 68, 97] ALCBN global \u221a (hybrid orientation rules) [12] Xie-geng algorithm local-to-global \u221a \u221a [33, 33, 109] GSBN local-to-global \u221a [65] TC local-to-global \u221a [75] RAI local-to-global \u221a \u221a \u221a [111, 112] LCD local \u221a \u221a \u221a [19, 61, 86] PCD-by-PCD local \u221a \u221a \u221a [113] CMB local \u221a \u221a \u221a [31] ODLP local \u221a ignore the step \u221a (experimental orientation rules) [93] SLPR global (multiple data) \u221a \u221a [23]", "startOffset": 301, "endOffset": 317}, {"referenceID": 26, "context": "Algorithm approach Skeleton v-structure edge orientation Reference SGS global \u221a \u221a Rules 1 to 4 (meek rules) [90] TPDA global \u221a [13] PC global \u221a [90] CPC global \u221a \u221a [80] VCSGS global \u221a \u221a [91] ACPC global \u221a \u221a [50] PC-stable global \u221a [16] CPC/MPC-stable global \u221a \u221a [16] PC-FDR global \u221a [54] AIT global \u221a [22, 27, 68, 97] ALCBN global \u221a (hybrid orientation rules) [12] Xie-geng algorithm local-to-global \u221a \u221a [33, 33, 109] GSBN local-to-global \u221a [65] TC local-to-global \u221a [75] RAI local-to-global \u221a \u221a \u221a [111, 112] LCD local \u221a \u221a \u221a [19, 61, 86] PCD-by-PCD local \u221a \u221a \u221a [113] CMB local \u221a \u221a \u221a [31] ODLP local \u221a ignore the step \u221a (experimental orientation rules) [93] SLPR global (multiple data) \u221a \u221a [23]", "startOffset": 301, "endOffset": 317}, {"referenceID": 67, "context": "Algorithm approach Skeleton v-structure edge orientation Reference SGS global \u221a \u221a Rules 1 to 4 (meek rules) [90] TPDA global \u221a [13] PC global \u221a [90] CPC global \u221a \u221a [80] VCSGS global \u221a \u221a [91] ACPC global \u221a \u221a [50] PC-stable global \u221a [16] CPC/MPC-stable global \u221a \u221a [16] PC-FDR global \u221a [54] AIT global \u221a [22, 27, 68, 97] ALCBN global \u221a (hybrid orientation rules) [12] Xie-geng algorithm local-to-global \u221a \u221a [33, 33, 109] GSBN local-to-global \u221a [65] TC local-to-global \u221a [75] RAI local-to-global \u221a \u221a \u221a [111, 112] LCD local \u221a \u221a \u221a [19, 61, 86] PCD-by-PCD local \u221a \u221a \u221a [113] CMB local \u221a \u221a \u221a [31] ODLP local \u221a ignore the step \u221a (experimental orientation rules) [93] SLPR global (multiple data) \u221a \u221a [23]", "startOffset": 301, "endOffset": 317}, {"referenceID": 95, "context": "Algorithm approach Skeleton v-structure edge orientation Reference SGS global \u221a \u221a Rules 1 to 4 (meek rules) [90] TPDA global \u221a [13] PC global \u221a [90] CPC global \u221a \u221a [80] VCSGS global \u221a \u221a [91] ACPC global \u221a \u221a [50] PC-stable global \u221a [16] CPC/MPC-stable global \u221a \u221a [16] PC-FDR global \u221a [54] AIT global \u221a [22, 27, 68, 97] ALCBN global \u221a (hybrid orientation rules) [12] Xie-geng algorithm local-to-global \u221a \u221a [33, 33, 109] GSBN local-to-global \u221a [65] TC local-to-global \u221a [75] RAI local-to-global \u221a \u221a \u221a [111, 112] LCD local \u221a \u221a \u221a [19, 61, 86] PCD-by-PCD local \u221a \u221a \u221a [113] CMB local \u221a \u221a \u221a [31] ODLP local \u221a ignore the step \u221a (experimental orientation rules) [93] SLPR global (multiple data) \u221a \u221a [23]", "startOffset": 301, "endOffset": 317}, {"referenceID": 11, "context": "Algorithm approach Skeleton v-structure edge orientation Reference SGS global \u221a \u221a Rules 1 to 4 (meek rules) [90] TPDA global \u221a [13] PC global \u221a [90] CPC global \u221a \u221a [80] VCSGS global \u221a \u221a [91] ACPC global \u221a \u221a [50] PC-stable global \u221a [16] CPC/MPC-stable global \u221a \u221a [16] PC-FDR global \u221a [54] AIT global \u221a [22, 27, 68, 97] ALCBN global \u221a (hybrid orientation rules) [12] Xie-geng algorithm local-to-global \u221a \u221a [33, 33, 109] GSBN local-to-global \u221a [65] TC local-to-global \u221a [75] RAI local-to-global \u221a \u221a \u221a [111, 112] LCD local \u221a \u221a \u221a [19, 61, 86] PCD-by-PCD local \u221a \u221a \u221a [113] CMB local \u221a \u221a \u221a [31] ODLP local \u221a ignore the step \u221a (experimental orientation rules) [93] SLPR global (multiple data) \u221a \u221a [23]", "startOffset": 360, "endOffset": 364}, {"referenceID": 32, "context": "Algorithm approach Skeleton v-structure edge orientation Reference SGS global \u221a \u221a Rules 1 to 4 (meek rules) [90] TPDA global \u221a [13] PC global \u221a [90] CPC global \u221a \u221a [80] VCSGS global \u221a \u221a [91] ACPC global \u221a \u221a [50] PC-stable global \u221a [16] CPC/MPC-stable global \u221a \u221a [16] PC-FDR global \u221a [54] AIT global \u221a [22, 27, 68, 97] ALCBN global \u221a (hybrid orientation rules) [12] Xie-geng algorithm local-to-global \u221a \u221a [33, 33, 109] GSBN local-to-global \u221a [65] TC local-to-global \u221a [75] RAI local-to-global \u221a \u221a \u221a [111, 112] LCD local \u221a \u221a \u221a [19, 61, 86] PCD-by-PCD local \u221a \u221a \u221a [113] CMB local \u221a \u221a \u221a [31] ODLP local \u221a ignore the step \u221a (experimental orientation rules) [93] SLPR global (multiple data) \u221a \u221a [23]", "startOffset": 404, "endOffset": 417}, {"referenceID": 32, "context": "Algorithm approach Skeleton v-structure edge orientation Reference SGS global \u221a \u221a Rules 1 to 4 (meek rules) [90] TPDA global \u221a [13] PC global \u221a [90] CPC global \u221a \u221a [80] VCSGS global \u221a \u221a [91] ACPC global \u221a \u221a [50] PC-stable global \u221a [16] CPC/MPC-stable global \u221a \u221a [16] PC-FDR global \u221a [54] AIT global \u221a [22, 27, 68, 97] ALCBN global \u221a (hybrid orientation rules) [12] Xie-geng algorithm local-to-global \u221a \u221a [33, 33, 109] GSBN local-to-global \u221a [65] TC local-to-global \u221a [75] RAI local-to-global \u221a \u221a \u221a [111, 112] LCD local \u221a \u221a \u221a [19, 61, 86] PCD-by-PCD local \u221a \u221a \u221a [113] CMB local \u221a \u221a \u221a [31] ODLP local \u221a ignore the step \u221a (experimental orientation rules) [93] SLPR global (multiple data) \u221a \u221a [23]", "startOffset": 404, "endOffset": 417}, {"referenceID": 107, "context": "Algorithm approach Skeleton v-structure edge orientation Reference SGS global \u221a \u221a Rules 1 to 4 (meek rules) [90] TPDA global \u221a [13] PC global \u221a [90] CPC global \u221a \u221a [80] VCSGS global \u221a \u221a [91] ACPC global \u221a \u221a [50] PC-stable global \u221a [16] CPC/MPC-stable global \u221a \u221a [16] PC-FDR global \u221a [54] AIT global \u221a [22, 27, 68, 97] ALCBN global \u221a (hybrid orientation rules) [12] Xie-geng algorithm local-to-global \u221a \u221a [33, 33, 109] GSBN local-to-global \u221a [65] TC local-to-global \u221a [75] RAI local-to-global \u221a \u221a \u221a [111, 112] LCD local \u221a \u221a \u221a [19, 61, 86] PCD-by-PCD local \u221a \u221a \u221a [113] CMB local \u221a \u221a \u221a [31] ODLP local \u221a ignore the step \u221a (experimental orientation rules) [93] SLPR global (multiple data) \u221a \u221a [23]", "startOffset": 404, "endOffset": 417}, {"referenceID": 64, "context": "Algorithm approach Skeleton v-structure edge orientation Reference SGS global \u221a \u221a Rules 1 to 4 (meek rules) [90] TPDA global \u221a [13] PC global \u221a [90] CPC global \u221a \u221a [80] VCSGS global \u221a \u221a [91] ACPC global \u221a \u221a [50] PC-stable global \u221a [16] CPC/MPC-stable global \u221a \u221a [16] PC-FDR global \u221a [54] AIT global \u221a [22, 27, 68, 97] ALCBN global \u221a (hybrid orientation rules) [12] Xie-geng algorithm local-to-global \u221a \u221a [33, 33, 109] GSBN local-to-global \u221a [65] TC local-to-global \u221a [75] RAI local-to-global \u221a \u221a \u221a [111, 112] LCD local \u221a \u221a \u221a [19, 61, 86] PCD-by-PCD local \u221a \u221a \u221a [113] CMB local \u221a \u221a \u221a [31] ODLP local \u221a ignore the step \u221a (experimental orientation rules) [93] SLPR global (multiple data) \u221a \u221a [23]", "startOffset": 441, "endOffset": 445}, {"referenceID": 74, "context": "Algorithm approach Skeleton v-structure edge orientation Reference SGS global \u221a \u221a Rules 1 to 4 (meek rules) [90] TPDA global \u221a [13] PC global \u221a [90] CPC global \u221a \u221a [80] VCSGS global \u221a \u221a [91] ACPC global \u221a \u221a [50] PC-stable global \u221a [16] CPC/MPC-stable global \u221a \u221a [16] PC-FDR global \u221a [54] AIT global \u221a [22, 27, 68, 97] ALCBN global \u221a (hybrid orientation rules) [12] Xie-geng algorithm local-to-global \u221a \u221a [33, 33, 109] GSBN local-to-global \u221a [65] TC local-to-global \u221a [75] RAI local-to-global \u221a \u221a \u221a [111, 112] LCD local \u221a \u221a \u221a [19, 61, 86] PCD-by-PCD local \u221a \u221a \u221a [113] CMB local \u221a \u221a \u221a [31] ODLP local \u221a ignore the step \u221a (experimental orientation rules) [93] SLPR global (multiple data) \u221a \u221a [23]", "startOffset": 467, "endOffset": 471}, {"referenceID": 109, "context": "Algorithm approach Skeleton v-structure edge orientation Reference SGS global \u221a \u221a Rules 1 to 4 (meek rules) [90] TPDA global \u221a [13] PC global \u221a [90] CPC global \u221a \u221a [80] VCSGS global \u221a \u221a [91] ACPC global \u221a \u221a [50] PC-stable global \u221a [16] CPC/MPC-stable global \u221a \u221a [16] PC-FDR global \u221a [54] AIT global \u221a [22, 27, 68, 97] ALCBN global \u221a (hybrid orientation rules) [12] Xie-geng algorithm local-to-global \u221a \u221a [33, 33, 109] GSBN local-to-global \u221a [65] TC local-to-global \u221a [75] RAI local-to-global \u221a \u221a \u221a [111, 112] LCD local \u221a \u221a \u221a [19, 61, 86] PCD-by-PCD local \u221a \u221a \u221a [113] CMB local \u221a \u221a \u221a [31] ODLP local \u221a ignore the step \u221a (experimental orientation rules) [93] SLPR global (multiple data) \u221a \u221a [23]", "startOffset": 498, "endOffset": 508}, {"referenceID": 110, "context": "Algorithm approach Skeleton v-structure edge orientation Reference SGS global \u221a \u221a Rules 1 to 4 (meek rules) [90] TPDA global \u221a [13] PC global \u221a [90] CPC global \u221a \u221a [80] VCSGS global \u221a \u221a [91] ACPC global \u221a \u221a [50] PC-stable global \u221a [16] CPC/MPC-stable global \u221a \u221a [16] PC-FDR global \u221a [54] AIT global \u221a [22, 27, 68, 97] ALCBN global \u221a (hybrid orientation rules) [12] Xie-geng algorithm local-to-global \u221a \u221a [33, 33, 109] GSBN local-to-global \u221a [65] TC local-to-global \u221a [75] RAI local-to-global \u221a \u221a \u221a [111, 112] LCD local \u221a \u221a \u221a [19, 61, 86] PCD-by-PCD local \u221a \u221a \u221a [113] CMB local \u221a \u221a \u221a [31] ODLP local \u221a ignore the step \u221a (experimental orientation rules) [93] SLPR global (multiple data) \u221a \u221a [23]", "startOffset": 498, "endOffset": 508}, {"referenceID": 18, "context": "Algorithm approach Skeleton v-structure edge orientation Reference SGS global \u221a \u221a Rules 1 to 4 (meek rules) [90] TPDA global \u221a [13] PC global \u221a [90] CPC global \u221a \u221a [80] VCSGS global \u221a \u221a [91] ACPC global \u221a \u221a [50] PC-stable global \u221a [16] CPC/MPC-stable global \u221a \u221a [16] PC-FDR global \u221a [54] AIT global \u221a [22, 27, 68, 97] ALCBN global \u221a (hybrid orientation rules) [12] Xie-geng algorithm local-to-global \u221a \u221a [33, 33, 109] GSBN local-to-global \u221a [65] TC local-to-global \u221a [75] RAI local-to-global \u221a \u221a \u221a [111, 112] LCD local \u221a \u221a \u221a [19, 61, 86] PCD-by-PCD local \u221a \u221a \u221a [113] CMB local \u221a \u221a \u221a [31] ODLP local \u221a ignore the step \u221a (experimental orientation rules) [93] SLPR global (multiple data) \u221a \u221a [23]", "startOffset": 525, "endOffset": 537}, {"referenceID": 60, "context": "Algorithm approach Skeleton v-structure edge orientation Reference SGS global \u221a \u221a Rules 1 to 4 (meek rules) [90] TPDA global \u221a [13] PC global \u221a [90] CPC global \u221a \u221a [80] VCSGS global \u221a \u221a [91] ACPC global \u221a \u221a [50] PC-stable global \u221a [16] CPC/MPC-stable global \u221a \u221a [16] PC-FDR global \u221a [54] AIT global \u221a [22, 27, 68, 97] ALCBN global \u221a (hybrid orientation rules) [12] Xie-geng algorithm local-to-global \u221a \u221a [33, 33, 109] GSBN local-to-global \u221a [65] TC local-to-global \u221a [75] RAI local-to-global \u221a \u221a \u221a [111, 112] LCD local \u221a \u221a \u221a [19, 61, 86] PCD-by-PCD local \u221a \u221a \u221a [113] CMB local \u221a \u221a \u221a [31] ODLP local \u221a ignore the step \u221a (experimental orientation rules) [93] SLPR global (multiple data) \u221a \u221a [23]", "startOffset": 525, "endOffset": 537}, {"referenceID": 85, "context": "Algorithm approach Skeleton v-structure edge orientation Reference SGS global \u221a \u221a Rules 1 to 4 (meek rules) [90] TPDA global \u221a [13] PC global \u221a [90] CPC global \u221a \u221a [80] VCSGS global \u221a \u221a [91] ACPC global \u221a \u221a [50] PC-stable global \u221a [16] CPC/MPC-stable global \u221a \u221a [16] PC-FDR global \u221a [54] AIT global \u221a [22, 27, 68, 97] ALCBN global \u221a (hybrid orientation rules) [12] Xie-geng algorithm local-to-global \u221a \u221a [33, 33, 109] GSBN local-to-global \u221a [65] TC local-to-global \u221a [75] RAI local-to-global \u221a \u221a \u221a [111, 112] LCD local \u221a \u221a \u221a [19, 61, 86] PCD-by-PCD local \u221a \u221a \u221a [113] CMB local \u221a \u221a \u221a [31] ODLP local \u221a ignore the step \u221a (experimental orientation rules) [93] SLPR global (multiple data) \u221a \u221a [23]", "startOffset": 525, "endOffset": 537}, {"referenceID": 111, "context": "Algorithm approach Skeleton v-structure edge orientation Reference SGS global \u221a \u221a Rules 1 to 4 (meek rules) [90] TPDA global \u221a [13] PC global \u221a [90] CPC global \u221a \u221a [80] VCSGS global \u221a \u221a [91] ACPC global \u221a \u221a [50] PC-stable global \u221a [16] CPC/MPC-stable global \u221a \u221a [16] PC-FDR global \u221a [54] AIT global \u221a [22, 27, 68, 97] ALCBN global \u221a (hybrid orientation rules) [12] Xie-geng algorithm local-to-global \u221a \u221a [33, 33, 109] GSBN local-to-global \u221a [65] TC local-to-global \u221a [75] RAI local-to-global \u221a \u221a \u221a [111, 112] LCD local \u221a \u221a \u221a [19, 61, 86] PCD-by-PCD local \u221a \u221a \u221a [113] CMB local \u221a \u221a \u221a [31] ODLP local \u221a ignore the step \u221a (experimental orientation rules) [93] SLPR global (multiple data) \u221a \u221a [23]", "startOffset": 561, "endOffset": 566}, {"referenceID": 30, "context": "Algorithm approach Skeleton v-structure edge orientation Reference SGS global \u221a \u221a Rules 1 to 4 (meek rules) [90] TPDA global \u221a [13] PC global \u221a [90] CPC global \u221a \u221a [80] VCSGS global \u221a \u221a [91] ACPC global \u221a \u221a [50] PC-stable global \u221a [16] CPC/MPC-stable global \u221a \u221a [16] PC-FDR global \u221a [54] AIT global \u221a [22, 27, 68, 97] ALCBN global \u221a (hybrid orientation rules) [12] Xie-geng algorithm local-to-global \u221a \u221a [33, 33, 109] GSBN local-to-global \u221a [65] TC local-to-global \u221a [75] RAI local-to-global \u221a \u221a \u221a [111, 112] LCD local \u221a \u221a \u221a [19, 61, 86] PCD-by-PCD local \u221a \u221a \u221a [113] CMB local \u221a \u221a \u221a [31] ODLP local \u221a ignore the step \u221a (experimental orientation rules) [93] SLPR global (multiple data) \u221a \u221a [23]", "startOffset": 583, "endOffset": 587}, {"referenceID": 91, "context": "Algorithm approach Skeleton v-structure edge orientation Reference SGS global \u221a \u221a Rules 1 to 4 (meek rules) [90] TPDA global \u221a [13] PC global \u221a [90] CPC global \u221a \u221a [80] VCSGS global \u221a \u221a [91] ACPC global \u221a \u221a [50] PC-stable global \u221a [16] CPC/MPC-stable global \u221a \u221a [16] PC-FDR global \u221a [54] AIT global \u221a [22, 27, 68, 97] ALCBN global \u221a (hybrid orientation rules) [12] Xie-geng algorithm local-to-global \u221a \u221a [33, 33, 109] GSBN local-to-global \u221a [65] TC local-to-global \u221a [75] RAI local-to-global \u221a \u221a \u221a [111, 112] LCD local \u221a \u221a \u221a [19, 61, 86] PCD-by-PCD local \u221a \u221a \u221a [113] CMB local \u221a \u221a \u221a [31] ODLP local \u221a ignore the step \u221a (experimental orientation rules) [93] SLPR global (multiple data) \u221a \u221a [23]", "startOffset": 652, "endOffset": 656}, {"referenceID": 22, "context": "Algorithm approach Skeleton v-structure edge orientation Reference SGS global \u221a \u221a Rules 1 to 4 (meek rules) [90] TPDA global \u221a [13] PC global \u221a [90] CPC global \u221a \u221a [80] VCSGS global \u221a \u221a [91] ACPC global \u221a \u221a [50] PC-stable global \u221a [16] CPC/MPC-stable global \u221a \u221a [16] PC-FDR global \u221a [54] AIT global \u221a [22, 27, 68, 97] ALCBN global \u221a (hybrid orientation rules) [12] Xie-geng algorithm local-to-global \u221a \u221a [33, 33, 109] GSBN local-to-global \u221a [65] TC local-to-global \u221a [75] RAI local-to-global \u221a \u221a \u221a [111, 112] LCD local \u221a \u221a \u221a [19, 61, 86] PCD-by-PCD local \u221a \u221a \u221a [113] CMB local \u221a \u221a \u221a [31] ODLP local \u221a ignore the step \u221a (experimental orientation rules) [93] SLPR global (multiple data) \u221a \u221a [23]", "startOffset": 689, "endOffset": 693}, {"referenceID": 88, "context": "[90], which provides a theoretical framework for learning structures of causal models.", "startOffset": 0, "endOffset": 4}, {"referenceID": 88, "context": "In the original version of the SGS algorithm [90], at the step of edge orientation, Rule 1 is used to avoid any alternative orientation would yield a new v-structure, while Rule 2 is employed to avoid any alternative orientations would generate a directed cycle.", "startOffset": 45, "endOffset": 49}, {"referenceID": 66, "context": "only if any orientation other than the orientation indicated by the rule would lead to a new unshielded collider or a directed cycle [67].", "startOffset": 133, "endOffset": 137}, {"referenceID": 66, "context": "Later, Meek [67] extended the rules by the additional two rules (noted as Rule 3 and Rule 4) which are summarized as the following.", "startOffset": 12, "endOffset": 16}, {"referenceID": 66, "context": "Meek [67] proved that these four rules are sufficient in terms of the soundness and completeness (please refer", "startOffset": 5, "endOffset": 9}, {"referenceID": 66, "context": "to Theorem 2 and Theorem 3 in Section 2 in [67]).", "startOffset": 43, "endOffset": 47}, {"referenceID": 88, "context": "[90] Given the distribution P over set of variables V and its corresponding DAG G, under Assumptions 1 to 3, the output of the SGS algorithm is the CPDAG that represents G.", "startOffset": 0, "endOffset": 4}, {"referenceID": 87, "context": "The PC (PC stands for Peter Spirtes and Clark Glymour who invented this algorithm) algorithm [89, 90] was proposed to improve learning efficiency in skeleton identification (Step 1 in Algorithm 1).", "startOffset": 93, "endOffset": 101}, {"referenceID": 88, "context": "The PC (PC stands for Peter Spirtes and Clark Glymour who invented this algorithm) algorithm [89, 90] was proposed to improve learning efficiency in skeleton identification (Step 1 in Algorithm 1).", "startOffset": 93, "endOffset": 101}, {"referenceID": 1, "context": "[2, 90] Under Assumptions 1 to 2, in a DAG G, there is an edge between the pair of variables Vi \u2208 V and Vj \u2208 V , if and only if Vi \u22a56 Vj |S, for all S \u2286 pa(Vi)\\{Vj} and S \u2286 pa(Vj)\\{Vi}.", "startOffset": 0, "endOffset": 7}, {"referenceID": 88, "context": "[2, 90] Under Assumptions 1 to 2, in a DAG G, there is an edge between the pair of variables Vi \u2208 V and Vj \u2208 V , if and only if Vi \u22a56 Vj |S, for all S \u2286 pa(Vi)\\{Vj} and S \u2286 pa(Vj)\\{Vi}.", "startOffset": 0, "endOffset": 7}, {"referenceID": 87, "context": "[89, 90] Under Assumptions 1 to 3, the PC algorithm gives the same output as the SGS algorithm.", "startOffset": 0, "endOffset": 8}, {"referenceID": 88, "context": "[89, 90] Under Assumptions 1 to 3, the PC algorithm gives the same output as the SGS algorithm.", "startOffset": 0, "endOffset": 8}, {"referenceID": 73, "context": "[87] and Pearl [74] described asymptotically consistent", "startOffset": 15, "endOffset": 19}, {"referenceID": 41, "context": "Kalisch and B\u00fchlmann [42] showed the PC-algorithm is asymptotically consistent for the equivalence class of the DAG and its skeleton with corresponding high-dimensional and sparse Gaussian distribution.", "startOffset": 21, "endOffset": 25}, {"referenceID": 35, "context": "Harris and Drton [36] studied the PC algorithm in the nonparanormal distributions, i.", "startOffset": 17, "endOffset": 21}, {"referenceID": 79, "context": "To the beginning, we introduce two consequences of the faithfulness assumption proposed by [80], i.", "startOffset": 91, "endOffset": 95}, {"referenceID": 117, "context": "The Adjacency-Faithfulness and the Orientation-Faithfulness both are consequences of the faithfulness assumption, but they together do not imply the faithfulness assumption [119].", "startOffset": 173, "endOffset": 178}, {"referenceID": 79, "context": "The triple is a v-structure if and only if the set S does not contain Vk [80, 119].", "startOffset": 73, "endOffset": 82}, {"referenceID": 117, "context": "The triple is a v-structure if and only if the set S does not contain Vk [80, 119].", "startOffset": 73, "endOffset": 82}, {"referenceID": 79, "context": "[80] for improving the robustness of the PC algorithm in the orientation phase.", "startOffset": 0, "endOffset": 4}, {"referenceID": 79, "context": "[80] extended the PC algorithm to capture violations of the Orientation-Faithfulness assumption.", "startOffset": 0, "endOffset": 4}, {"referenceID": 117, "context": "[119] Assuming the causal Markov condition and the Adjacency-Faithfulness condition hold, any violation of the Orientation-Faithfulness condition is detectable.", "startOffset": 0, "endOffset": 5}, {"referenceID": 117, "context": "Zhang and Spirtes [119] proved that given the Causal Markov, Minimality, and Triangle-Faithfulness assumptions, any violations of faithfulness are detectable.", "startOffset": 18, "endOffset": 23}, {"referenceID": 89, "context": "Then Spirtes and Zhang [91] proposed the VCSGS algorithm under those two weaker assumptions of faithfullness.", "startOffset": 23, "endOffset": 27}, {"referenceID": 89, "context": "Spirtes and Zhang [91] only analyzed the soundness of", "startOffset": 18, "endOffset": 22}, {"referenceID": 117, "context": "More explanations and examples for the Causal Minimality assumption, Triangle-Faithfulness Condition, and the AdjacencyFaithfulness condition, please refer to the work [119].", "startOffset": 168, "endOffset": 173}, {"referenceID": 49, "context": "[50] proposed two specific violations of the Adjacency-Faithfulness assumption, i.", "startOffset": 0, "endOffset": 4}, {"referenceID": 49, "context": "[50] developed the Adjacency Conservative PC (ACPC) algorithm to deal with the two violations.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "and conclusions for different variable orderings [17].", "startOffset": 49, "endOffset": 53}, {"referenceID": 16, "context": "Colombo and Maathuis [17] proposed the PC-stable algorithm and its variants to address this order-dependence problem.", "startOffset": 21, "endOffset": 25}, {"referenceID": 16, "context": "[17] Let the distribution of P be faithful to a DAG G, and assume that we are given perfect conditional independence information about all pairs of variables (Fi, Fj) in P given subsets S \u2286 F \\{Fi\u222aFj}.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[17] The skeleton resulting of the PC-stable algorithm is order-independent.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "The CPC-stable algorithm [17] is the combination of the PC-stable algorithm and the CPC algorithm, that is, using the idea of the CPC algorithm to identify v-structures.", "startOffset": 25, "endOffset": 29}, {"referenceID": 16, "context": "Maathuis [17] proposed the majority rule PC-stable algorithm (MPC-stable).", "startOffset": 9, "endOffset": 13}, {"referenceID": 16, "context": "[17] Let the distribution of P be faithful to a DAG G, and assume that we are given perfect conditional independence information about all pairs of variables (Fi;Fj) in P given subsets S \u2286 F \\ {Fi \u222a Fj}.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[17] The decisions about v-structures in the sample versions of the CPC/MPC-stable algorithms are", "startOffset": 0, "endOffset": 4}, {"referenceID": 46, "context": "The work [47, 48] proposed the parallelized versions of the PC algorithm and the PC-stable algorithm using the parallel computing technique, and showed that the parallel PC and PC-stable algorithms produce the same outputs as the PC and PC-", "startOffset": 9, "endOffset": 17}, {"referenceID": 47, "context": "The work [47, 48] proposed the parallelized versions of the PC algorithm and the PC-stable algorithm using the parallel computing technique, and showed that the parallel PC and PC-stable algorithms produce the same outputs as the PC and PC-", "startOffset": 9, "endOffset": 17}, {"referenceID": 9, "context": "The false discovery rate (FDR) [10, 94] is a criterion to assess the errors when multiple hypotheses are simultaneously tested.", "startOffset": 31, "endOffset": 39}, {"referenceID": 92, "context": "The false discovery rate (FDR) [10, 94] is a criterion to assess the errors when multiple hypotheses are simultaneously tested.", "startOffset": 31, "endOffset": 39}, {"referenceID": 15, "context": "Colombo and Maathuis [16] proposed the PCfdr-skeleton algorithm by embedding an FDR-control procedure into the PC algorithm to curb the error rate of the skeleton of the learned PDAGs.", "startOffset": 21, "endOffset": 25}, {"referenceID": 11, "context": "Against the PCfdr-skeleton algorithm, Bromberg and Margaritis [12] proposed the AIT (Argumentative Independence Test) framework to improve the reliability of the constraintbased algorithms when independence tests on small data sets are not reliable.", "startOffset": 62, "endOffset": 66}, {"referenceID": 71, "context": "a knowledge base containing a set of independence facts that are related through Pearls well-known axioms [72], as shown as follows.", "startOffset": 106, "endOffset": 110}, {"referenceID": 4, "context": "feasible logic proposed by Amgoud and Cayrol [5] to reason about and correct errors.", "startOffset": 45, "endOffset": 48}, {"referenceID": 12, "context": "[13].", "startOffset": 0, "endOffset": 4}, {"referenceID": 32, "context": "al [33] proposed a decomposition method for", "startOffset": 3, "endOffset": 7}, {"referenceID": 32, "context": "The rational behind the idea is that if vertices Vi and Vj are adjacent in the moral graph but there exists a vertex set S such that Vi \u22a5 Vj |S, then there exists a decomposed subgraph that contains Vi, Vj and a variable set S \u2032 such that Vi \u22a5 Vj |S , and vice versa [33].", "startOffset": 267, "endOffset": 271}, {"referenceID": 32, "context": "To decompose a graph into subgraphs, the approach in [33] needs a moral graph and requires that each dseparator (conditional sets) has a complete subgraph in the moral graph.", "startOffset": 53, "endOffset": 57}, {"referenceID": 108, "context": "[110] proposed", "startOffset": 0, "endOffset": 5}, {"referenceID": 107, "context": "[109] proposed a recursive method for learning structures of DAGs.", "startOffset": 0, "endOffset": 5}, {"referenceID": 65, "context": "Margaritis and Thrun [66] proposed the Grow-Shrink Bayesain network learning (GSBN) algorithm for constrain-based causal network learning.", "startOffset": 21, "endOffset": 25}, {"referenceID": 98, "context": "To conquer this drawback of the GSMB algorithm, Tsamardinos and Aliferis [100] proposed a modified version of the GSMB algorithm, called the IAMB algorithm, which guarantees to find the actual Markov", "startOffset": 73, "endOffset": 78}, {"referenceID": 100, "context": "blanket given enough training data and the method is more sample efficient than GSMB, and its variants, such as inter-IAMB [102], Fast-IAMB [102], and IAMBFDR [77].", "startOffset": 123, "endOffset": 128}, {"referenceID": 100, "context": "blanket given enough training data and the method is more sample efficient than GSMB, and its variants, such as inter-IAMB [102], Fast-IAMB [102], and IAMBFDR [77].", "startOffset": 140, "endOffset": 145}, {"referenceID": 76, "context": "blanket given enough training data and the method is more sample efficient than GSMB, and its variants, such as inter-IAMB [102], Fast-IAMB [102], and IAMBFDR [77].", "startOffset": 159, "endOffset": 163}, {"referenceID": 1, "context": "Thus, HITONMB [2, 4] and MMMB [101, 104] were introduced to mitigate", "startOffset": 14, "endOffset": 20}, {"referenceID": 3, "context": "Thus, HITONMB [2, 4] and MMMB [101, 104] were introduced to mitigate", "startOffset": 14, "endOffset": 20}, {"referenceID": 99, "context": "Thus, HITONMB [2, 4] and MMMB [101, 104] were introduced to mitigate", "startOffset": 30, "endOffset": 40}, {"referenceID": 102, "context": "Thus, HITONMB [2, 4] and MMMB [101, 104] were introduced to mitigate", "startOffset": 30, "endOffset": 40}, {"referenceID": 1, "context": "As an efficient implementation of Step 1, two major algorithms HITON-PC [2, 4] and MMPC", "startOffset": 72, "endOffset": 78}, {"referenceID": 3, "context": "As an efficient implementation of Step 1, two major algorithms HITON-PC [2, 4] and MMPC", "startOffset": 72, "endOffset": 78}, {"referenceID": 99, "context": "were introduced [101, 103].", "startOffset": 16, "endOffset": 26}, {"referenceID": 101, "context": "were introduced [101, 103].", "startOffset": 16, "endOffset": 26}, {"referenceID": 77, "context": "Following the ideas above, PCMB [78], IPCMB [30], STMB [32], WLCMB [57] was also proposed to efficient and effective discovery of Markov blankets.", "startOffset": 32, "endOffset": 36}, {"referenceID": 29, "context": "Following the ideas above, PCMB [78], IPCMB [30], STMB [32], WLCMB [57] was also proposed to efficient and effective discovery of Markov blankets.", "startOffset": 44, "endOffset": 48}, {"referenceID": 31, "context": "Following the ideas above, PCMB [78], IPCMB [30], STMB [32], WLCMB [57] was also proposed to efficient and effective discovery of Markov blankets.", "startOffset": 55, "endOffset": 59}, {"referenceID": 56, "context": "Following the ideas above, PCMB [78], IPCMB [30], STMB [32], WLCMB [57] was also proposed to efficient and effective discovery of Markov blankets.", "startOffset": 67, "endOffset": 71}, {"referenceID": 98, "context": "Total Conditioning (TC) algorithm Tsamardinos and Aliferis [100] associated Markov blankets in Bayesian networks with strongly relevant variables defined by Kohavi and John in feature selection, then transferred the feature selection task to the discovery of Markov blankets in", "startOffset": 59, "endOffset": 64}, {"referenceID": 74, "context": "Based on the work, in contrast, Pellet and Elisseeff [75] connected the problem of learning causal structures with a problem of feature selection in data mining.", "startOffset": 53, "endOffset": 57}, {"referenceID": 34, "context": "They proposed the Total Conditioning (TC) algorithm, and its improved version, the TCbw algorithm, using the Recursive Feature Elimination (RFE) algorithm [35].", "startOffset": 155, "endOffset": 159}, {"referenceID": 109, "context": "The RAI (Recursive Autonomy Identification) algorithm was presented in [111, 112] which uses a structure decomposition approach.", "startOffset": 71, "endOffset": 81}, {"referenceID": 110, "context": "The RAI (Recursive Autonomy Identification) algorithm was presented in [111, 112] which uses a structure decomposition approach.", "startOffset": 71, "endOffset": 81}, {"referenceID": 71, "context": "[72] A node Y in G(V,E) is an exogenous cause to G(V ,E), where V \u2282 V and E \u2282 E, if Y / \u2208 V and \u2200X \u2208 V , Y \u2208 Pa(X,G) or Y / \u2208 Adj(X,G).", "startOffset": 0, "endOffset": 4}, {"referenceID": 110, "context": "[112] In a DAG G(V,E), a sub-structureG(V , E) such that V A \u2282 V and E \u2282 E is said to be autonomous in G given a set Vex \u2282 V of exogenous causes to G A if \u2200X \u2208 V , Pa(X,G) \u2282 {V A \u222a Vex}.", "startOffset": 0, "endOffset": 5}, {"referenceID": 88, "context": "The existing methods for casual discovery fully rely on observational data to discover causal relations between variables up to a Markov equivalence class, and thus leave many edge directions undetermined [90].", "startOffset": 205, "endOffset": 209}, {"referenceID": 21, "context": "The type of methods includes the work of [22, 27, 68, 97] and the method proposed by He and Geng [37].", "startOffset": 41, "endOffset": 57}, {"referenceID": 26, "context": "The type of methods includes the work of [22, 27, 68, 97] and the method proposed by He and Geng [37].", "startOffset": 41, "endOffset": 57}, {"referenceID": 67, "context": "The type of methods includes the work of [22, 27, 68, 97] and the method proposed by He and Geng [37].", "startOffset": 41, "endOffset": 57}, {"referenceID": 95, "context": "The type of methods includes the work of [22, 27, 68, 97] and the method proposed by He and Geng [37].", "startOffset": 41, "endOffset": 57}, {"referenceID": 36, "context": "The type of methods includes the work of [22, 27, 68, 97] and the method proposed by He and Geng [37].", "startOffset": 97, "endOffset": 101}, {"referenceID": 67, "context": "The ALCBN algorithm [68] uses either the mini-max, maximin or Laplace decision criteria, whereas the approach proposed by He and Geng [37] uses either the maxi-min", "startOffset": 20, "endOffset": 24}, {"referenceID": 36, "context": "The ALCBN algorithm [68] uses either the mini-max, maximin or Laplace decision criteria, whereas the approach proposed by He and Geng [37] uses either the maxi-min", "startOffset": 134, "endOffset": 138}, {"referenceID": 67, "context": "The method in [68] repeats this process until all edges in the graph are oriented.", "startOffset": 14, "endOffset": 18}, {"referenceID": 36, "context": "The algorithm in [37] first partitions the graph into chain components which are only connected", "startOffset": 17, "endOffset": 21}, {"referenceID": 18, "context": "The LCD (Local Causal Discovery) algorithm and its variants [19, 61, 86] aim to find causal edges by testing the dependence/independence relationships among", "startOffset": 60, "endOffset": 72}, {"referenceID": 60, "context": "The LCD (Local Causal Discovery) algorithm and its variants [19, 61, 86] aim to find causal edges by testing the dependence/independence relationships among", "startOffset": 60, "endOffset": 72}, {"referenceID": 85, "context": "The LCD (Local Causal Discovery) algorithm and its variants [19, 61, 86] aim to find causal edges by testing the dependence/independence relationships among", "startOffset": 60, "endOffset": 72}, {"referenceID": 62, "context": "Bayesian Local Causal Discovery (BLCD) [63] and CD-B/H algorithm [60] explores the Y-structures among the nodes in a Markov blanket to infer causal edges using Baysain scoring-based method.", "startOffset": 39, "endOffset": 43}, {"referenceID": 59, "context": "Bayesian Local Causal Discovery (BLCD) [63] and CD-B/H algorithm [60] explores the Y-structures among the nodes in a Markov blanket to infer causal edges using Baysain scoring-based method.", "startOffset": 65, "endOffset": 69}, {"referenceID": 111, "context": "target [113].", "startOffset": 7, "endOffset": 12}, {"referenceID": 30, "context": "Based on the idea of the PCD-by-PCD algorithm, Tian and Ji [31] propose a new Causal Markov Blanket (CMB) discovery algorithm to identify the direct", "startOffset": 59, "endOffset": 63}, {"referenceID": 2, "context": "and may not orient all edge directions with observational data alone [3, 93].", "startOffset": 69, "endOffset": 76}, {"referenceID": 91, "context": "and may not orient all edge directions with observational data alone [3, 93].", "startOffset": 69, "endOffset": 76}, {"referenceID": 91, "context": "[93] introduced a local causal discovery method, called ODLP, for discovery of local causal pathways around the target variable of interest (i.", "startOffset": 0, "endOffset": 4}, {"referenceID": 90, "context": "of parents and children when the faithfullness assumption is violated [92], while the TIE* algorithm was designed to discover multiple Markov blanket of a target as the assumption does not hold in data.", "startOffset": 70, "endOffset": 74}, {"referenceID": 22, "context": "Instead of learning with a single observational data set, sometimes we need to deal with several data sets that do not share the same set of variables, but share significant overlap variable sets due to privacy or ethics [23, 24].", "startOffset": 221, "endOffset": 229}, {"referenceID": 23, "context": "Instead of learning with a single observational data set, sometimes we need to deal with several data sets that do not share the same set of variables, but share significant overlap variable sets due to privacy or ethics [23, 24].", "startOffset": 221, "endOffset": 229}, {"referenceID": 22, "context": "As a pioneering work, Danks [23] proposed the SLPR (Structure learning using prior results) algorithm to learning the causal structure over the joint set of observed variables.", "startOffset": 28, "endOffset": 32}, {"referenceID": 5, "context": "In real-world applications, such as medical science, epidemiology, and sociology, it is impossible to ensure that all common causes are measured in real-world data [6, 17].", "startOffset": 164, "endOffset": 171}, {"referenceID": 16, "context": "In real-world applications, such as medical science, epidemiology, and sociology, it is impossible to ensure that all common causes are measured in real-world data [6, 17].", "startOffset": 164, "endOffset": 171}, {"referenceID": 84, "context": "In this case, by involved latent variable into the structure to be learnt, these methods then transfer the problem of latent variable learning to the problem of missing data completing [85].", "startOffset": 185, "endOffset": 189}, {"referenceID": 16, "context": "Moreover, with latent variables, the space of DAGs is not closed under marginalization [17].", "startOffset": 87, "endOffset": 91}, {"referenceID": 80, "context": "Instead of DAGs, using a MAG (maximal ancestral graph) [81] model to represent latent common causes is an emerging research direction in causal discovery without the assumption of causal sufficiency [11, 17, 85].", "startOffset": 55, "endOffset": 59}, {"referenceID": 10, "context": "Instead of DAGs, using a MAG (maximal ancestral graph) [81] model to represent latent common causes is an emerging research direction in causal discovery without the assumption of causal sufficiency [11, 17, 85].", "startOffset": 199, "endOffset": 211}, {"referenceID": 16, "context": "Instead of DAGs, using a MAG (maximal ancestral graph) [81] model to represent latent common causes is an emerging research direction in causal discovery without the assumption of causal sufficiency [11, 17, 85].", "startOffset": 199, "endOffset": 211}, {"referenceID": 84, "context": "Instead of DAGs, using a MAG (maximal ancestral graph) [81] model to represent latent common causes is an emerging research direction in causal discovery without the assumption of causal sufficiency [11, 17, 85].", "startOffset": 199, "endOffset": 211}, {"referenceID": 88, "context": "Algorithm single or multiple Reference IC* single data set [90] FCI single data set [90] RFCI single data set [17] MBCS* single data set [76] ION multiple data set [95] IOD multiple data set [96] cSAT+ multiple data set [99] INCA multiple data set [105] COmbINE multiple data set [98]", "startOffset": 59, "endOffset": 63}, {"referenceID": 88, "context": "Algorithm single or multiple Reference IC* single data set [90] FCI single data set [90] RFCI single data set [17] MBCS* single data set [76] ION multiple data set [95] IOD multiple data set [96] cSAT+ multiple data set [99] INCA multiple data set [105] COmbINE multiple data set [98]", "startOffset": 84, "endOffset": 88}, {"referenceID": 16, "context": "Algorithm single or multiple Reference IC* single data set [90] FCI single data set [90] RFCI single data set [17] MBCS* single data set [76] ION multiple data set [95] IOD multiple data set [96] cSAT+ multiple data set [99] INCA multiple data set [105] COmbINE multiple data set [98]", "startOffset": 110, "endOffset": 114}, {"referenceID": 75, "context": "Algorithm single or multiple Reference IC* single data set [90] FCI single data set [90] RFCI single data set [17] MBCS* single data set [76] ION multiple data set [95] IOD multiple data set [96] cSAT+ multiple data set [99] INCA multiple data set [105] COmbINE multiple data set [98]", "startOffset": 137, "endOffset": 141}, {"referenceID": 93, "context": "Algorithm single or multiple Reference IC* single data set [90] FCI single data set [90] RFCI single data set [17] MBCS* single data set [76] ION multiple data set [95] IOD multiple data set [96] cSAT+ multiple data set [99] INCA multiple data set [105] COmbINE multiple data set [98]", "startOffset": 164, "endOffset": 168}, {"referenceID": 94, "context": "Algorithm single or multiple Reference IC* single data set [90] FCI single data set [90] RFCI single data set [17] MBCS* single data set [76] ION multiple data set [95] IOD multiple data set [96] cSAT+ multiple data set [99] INCA multiple data set [105] COmbINE multiple data set [98]", "startOffset": 191, "endOffset": 195}, {"referenceID": 97, "context": "Algorithm single or multiple Reference IC* single data set [90] FCI single data set [90] RFCI single data set [17] MBCS* single data set [76] ION multiple data set [95] IOD multiple data set [96] cSAT+ multiple data set [99] INCA multiple data set [105] COmbINE multiple data set [98]", "startOffset": 220, "endOffset": 224}, {"referenceID": 103, "context": "Algorithm single or multiple Reference IC* single data set [90] FCI single data set [90] RFCI single data set [17] MBCS* single data set [76] ION multiple data set [95] IOD multiple data set [96] cSAT+ multiple data set [99] INCA multiple data set [105] COmbINE multiple data set [98]", "startOffset": 248, "endOffset": 253}, {"referenceID": 96, "context": "Algorithm single or multiple Reference IC* single data set [90] FCI single data set [90] RFCI single data set [17] MBCS* single data set [76] ION multiple data set [95] IOD multiple data set [96] cSAT+ multiple data set [99] INCA multiple data set [105] COmbINE multiple data set [98]", "startOffset": 280, "endOffset": 284}, {"referenceID": 80, "context": "[81] A mixed graph is ancestral if the conditions hold that (1) it does not contain directed cycles, (2) it does not contain almost directed cycles, and (3) for any undirected edge Vi \u2212 Vj , Vi and Vj have no parents or spouses.", "startOffset": 0, "endOffset": 4}, {"referenceID": 80, "context": "[81] In an ancestral graph, Vi and Vj are m-separated by Z \u2286 V \\{Vi, Vj}, if every path between Vi and Vj is blocked by Z .", "startOffset": 0, "endOffset": 4}, {"referenceID": 80, "context": "[81] For any two non-adjacent variables in an ancestral graph, if there exists a set of variables that m-separates them, then the ancestral graph is said to be maximal.", "startOffset": 0, "endOffset": 4}, {"referenceID": 73, "context": "The IC* (Inductive Causation) algorithm [74] is the pioneer work to learn causal structures without assuming causal sufficiency.", "startOffset": 40, "endOffset": 44}, {"referenceID": 88, "context": "To improve the efficiency of the IC* algorithm, the FCI algorithm [90] was proposed which finds an graph skeleton in Step 1 using the PC algorithm.", "startOffset": 66, "endOffset": 70}, {"referenceID": 116, "context": "\u2022 Step 5: Replacing as many circles as possible by arrowheads and tails using the R1-R10 orientation rules (in total 10 rules) described by [118].", "startOffset": 140, "endOffset": 145}, {"referenceID": 16, "context": "algorithm [17] is a modification of the FCI algorithm.", "startOffset": 10, "endOffset": 14}, {"referenceID": 75, "context": "MBCS* algorithm [76] and the FCI algorithm exists in Step 1.", "startOffset": 16, "endOffset": 20}, {"referenceID": 93, "context": "The ION (Integration of Overlapping Networks) algorithm [95] is the first and an asymptotically correct algorithm for discovering the complete set of causal", "startOffset": 56, "endOffset": 60}, {"referenceID": 94, "context": "To deal with the problem of conflict information resulted from different data sets, the IOD (integration of overlapping datasets) algorithm [96] was", "startOffset": 140, "endOffset": 144}, {"referenceID": 97, "context": "[99] also presented a cSAT+ algorithm to improve the efficiency of the ION algorithm.", "startOffset": 0, "endOffset": 4}, {"referenceID": 39, "context": "[40] proposed a general SAT-based procedure by transforming the observed dependences and independences constraints into a SAT instance.", "startOffset": 0, "endOffset": 4}, {"referenceID": 38, "context": "[39] presented an ASP-based constraint optimization approach to handle inconsistent (in)dependence constraints", "startOffset": 0, "endOffset": 4}, {"referenceID": 103, "context": "[105] unified the prior work above and proposed the INCA (Integrative Causal Analysis) framework for the co-analysis of heteroge-", "startOffset": 0, "endOffset": 5}, {"referenceID": 96, "context": "The COmbINE (Causal discovery from Overlapping INtErventions) algorithm [98] builds upon the ideas in the cSAT+ algorithm [99] and is the first algorithm to address both overlapping variables and multiple (hard) interventions for acyclic structures without", "startOffset": 72, "endOffset": 76}, {"referenceID": 97, "context": "The COmbINE (Causal discovery from Overlapping INtErventions) algorithm [98] builds upon the ideas in the cSAT+ algorithm [99] and is the first algorithm to address both overlapping variables and multiple (hard) interventions for acyclic structures without", "startOffset": 122, "endOffset": 126}, {"referenceID": 96, "context": "The algorithm is proved to be sound and complete in the sample limit under different interventions in acyclic domains [98].", "startOffset": 118, "endOffset": 122}, {"referenceID": 7, "context": "causal knowledge from multiple data sets instead of any individual data source alone [8].", "startOffset": 85, "endOffset": 88}, {"referenceID": 78, "context": "Recent, the idea of invariant causal inference may open a new way to handle those issues [79].", "startOffset": 89, "endOffset": 93}, {"referenceID": 80, "context": "Thirdly, the MAGmodels provide a different perspective in causal inference without assuming causal sufficiency, compared to DAGs [81].", "startOffset": 129, "endOffset": 133}, {"referenceID": 16, "context": "Using MAGs to represent latent variables is an emerging direction in causal discovery without the assumption of causal sufficiency [17, 46, 85].", "startOffset": 131, "endOffset": 143}, {"referenceID": 45, "context": "Using MAGs to represent latent variables is an emerging direction in causal discovery without the assumption of causal sufficiency [17, 46, 85].", "startOffset": 131, "endOffset": 143}, {"referenceID": 84, "context": "Using MAGs to represent latent variables is an emerging direction in causal discovery without the assumption of causal sufficiency [17, 46, 85].", "startOffset": 131, "endOffset": 143}, {"referenceID": 6, "context": "ery [7].", "startOffset": 4, "endOffset": 7}, {"referenceID": 6, "context": "Recently, some work has been proposed to address the problem of selection bias in causal discovery, but those work is still in a theoretical aspect [7, 9, 41].", "startOffset": 148, "endOffset": 158}, {"referenceID": 8, "context": "Recently, some work has been proposed to address the problem of selection bias in causal discovery, but those work is still in a theoretical aspect [7, 9, 41].", "startOffset": 148, "endOffset": 158}, {"referenceID": 40, "context": "Recently, some work has been proposed to address the problem of selection bias in causal discovery, but those work is still in a theoretical aspect [7, 9, 41].", "startOffset": 148, "endOffset": 158}], "year": 2016, "abstractText": "Causal discovery studies the problem of mining causal relationships between variables from data, which is of primary interest in science. During the past decades, significant amount of progresses have been made toward this fundamental data mining paradigm. Recent years, as the availability of abundant large-sized and complex observational data, the constrain-based approaches have gradually attracted a lot of interest and have been widely applied to many diverse real-world problems due to the fast running speed and easy generalizing to the problem of causal insufficiency. In this paper, we aim to review the constraint-based causal discovery algorithms. Firstly, we discuss the learning paradigm of the constraint-based approaches. Secondly and primarily, the state-of-the-art constraint-based casual inference algorithms are surveyed with the detailed analysis. Thirdly, several related open-source software packages and benchmark data repositories are briefly summarized. As a conclusion, some open problems in constraint-based causal discovery are outlined for future research.", "creator": "dvips(k) 5.991 Copyright 2011 Radical Eye Software"}}}