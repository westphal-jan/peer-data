{"id": "1611.04010", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Nov-2016", "title": "Multi-Language Identification Using Convolutional Recurrent Neural Network", "abstract": "Language Identification, being an important aspect of Automatic Speaker Recognition has had many changes and new approaches to ameliorate performance over the last decade. We compare the performance of using audio spectrum in the log scale and using Polyphonic sound sequences from raw audio samples to train the neural network and to classify speech as either English or Spanish. To achieve this, we use the novel approach of using a Convolutional Recurrent Neural Network using Long Short Term Memory (LSTM) or a Gated Recurrent Unit (GRU) for forward propagation of the neural network. Our hypothesis is that the performance of using polyphonic sound sequence as features and both LSTM and GRU as the gating mechanisms for the neural network outperform the traditional MFCC features using a unidirectional Deep Neural Network.", "histories": [["v1", "Sat, 12 Nov 2016 15:59:22 GMT  (861kb)", "http://arxiv.org/abs/1611.04010v1", "10 pages, 6 figures"], ["v2", "Thu, 18 May 2017 09:15:26 GMT  (0kb,I)", "http://arxiv.org/abs/1611.04010v2", "Further experiments were performed on the model using LibriVox speech dataset and it was found that a Time Distributed CRNN model performed better and represented our initial ideas about the speaker recognition task better. The dataset contains speech in three languages - English, Spanish and Czech. A report on our findings along with experimental results will be published soon"]], "COMMENTS": "10 pages, 6 figures", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["vrishabh ajay lakhani", "rohan mahadev"], "accepted": false, "id": "1611.04010"}, "pdf": {"name": "1611.04010.pdf", "metadata": {"source": "CRF", "title": "MULTI-LANGUAGE IDENTIFICATION USING CONVOLUTIONAL RECURRENT NEURAL NETWORK", "authors": ["Rohan Mahadev", "Vrishabh Lakhani"], "emails": ["rohan.mahadev@somaiya.edu", "vrishabh.l@somaiya.edu"], "sections": [{"heading": null, "text": "KEYWORDSSpeech recognition, Neural networks, Machine learning, Speech recognition, Acoustic features."}, {"heading": "1. INTRODUCTION", "text": "The problem of language identification (LID) can be extended as a process of automatic identification of the language of a given spoken utterance. Many state-of-the-art LID systems rely on acoustic modeling. In particular, guided by advances in the verication and recognition of loudspeakers, the use of i-vector extractors to extract characteristics from the sample and the use of classification techniques such as Bayesian classification has become the norm in acoustic LID systems [1]. Language identification has long been an aspect of automatic loudspeaker detection, constrained more by the processing capacities of machines than by the use of the best technology available at the time. One such case was the less frequent use of Convolutional Recurrent Neural Networks (CRNN) [7], which are difficult due to several complex layers and each layer requiring multiple calculations of parameters."}, {"heading": "2. RELATED WORK", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1. The i-vector based standard LID system", "text": "This approach is based on the approach described in [4]. This approach is based on Gaussian components trained on PLP coefficients such as MFCC and \u2206 (delta) of MFCC and \u0445 (double delta) MFCC, which are extracted over a certain frame rate of 10ms over 25ms window length. According to the standard protocol described in [5], we can extract the i-vector of each language. After extracting the i-vector of each language, we can apply our machine to the language classification task using logistic regression (LR) thereon; or alternatively, we can use linear discrimination analysis (LDA) followed by cosine linear discrimination analysis and Gaussian modeling to adapt the i-vectors of each language."}, {"heading": "2.2. Automatic Language Identification using Convolutional Recurrent Neural Networks", "text": "The approach presented by [6] is an improvement over the traditional i-vector analysis of the LID system, in that it attempts to find the temporally hidden patterns between the individual window frames using the recurring hidden layers. However, the main shortcoming of this approach is that it cannot find the intra-frame pattern that can provide the information needed to identify the variance necessary to eliminate the distortion of the phonetic spectrum of a particular voice frequency, which is specific to the speaker phoneme on which the training record is based."}, {"heading": "3. APPROACH", "text": "Traditionally, Convolutionary Recursive Neural Networks are used for scene labeling [7], i.e., with Convolutionary Neural Networks with Intra-layer Recurrent Connections, we use this novel approach to find the relationship between the frames of the audio sample in the training data, with the advantage that theoretically it can provide the solution to the problem in the approach described in [6]. In the figure, we see that we have extracted the audio sample log scale, eliminating all redundant frequencies and drawing a spectrogram of the frequency log scale, here we can visualize that the Convolutionary Part of the CRNN model has tried to find the pattern within each timeframe, while the Recursive Part of the memory attempts to search for patterns between each timeframe, outperforming all other traditional approaches."}, {"heading": "4.1 RNN:", "text": "The main relationship that needs to be established in a speaker detection problem is between the temporal audio features that change over time. Feedback to the network at each time interval results in a sequence of values as input. In conventional RNNs, input sequences to hidden layers are mapped by the following equations: h t = g (W x h xt + W hh h t \u2212 1 + b h h h) z \u2212 g (W hz h t + b z) Where g is normally mapped to hidden layers by the following instance: h t = g (W x h xt + W hh h t \u2212 1 + h h = h (W hz t + b z) where g is normally used as the basis for our architecture. Although a temporal relationship is established, the disappearing gradient problem mentioned by [9] is even more common in an RNN because each feedback to each layer can be typed as a whole new hidden layer from a forward network."}, {"heading": "4.3 Convolutional Neural Network Layer", "text": "There is some work, in the form of a framework, for analyzing the operations they perform. The goal of this project is to present the main results from this theory and provide an intuition of why CNNs work. CNN filters, which look for specific patterns in an image in their typical use, are used as a hypothesis for the work in a similar way - extracting patterns of sound from each audio input sequence. Likewise, each filter has the same bias and weighting that help to detect a frequency pattern that is then fed into a rectified linear unit and a maximum pooling layer to reduce dimensions. Complex patterns are then fed into a fully interconnected layer for classification. As baking propagation is used in the formation of CNNs, the disappearing gradient problem can still prevail."}, {"heading": "5. CONCLUSION", "text": "In this paper we have developed a novel approach to problems of automatic speech recognition, in particular language identification, which should prove more accurate than other approaches such as i-Vector classification and unidirectional recursive neural networks due to the increased information extraction from the characteristics of the log scale using convective recursive networks. In view of the existing studies on bidirectional networks, we note that the use of an LSTM unit in forward direction and a GRU unit in backward direction with lesser characteristics than conventional classification approaches should theoretically have greater accuracy and time efficiency compared to existing models. Thus, such a revolutionary recursive neural network unit can be better classified when the input data is available in raw audio form. The presented approach will either improve or simplify the application of classical methods while maintaining their reliability."}], "references": [{"title": "Automatic language identification using long short-term memory recurrent neural networks.\" \u200bINTERSPEECH  \u200b", "author": ["Gonzalez-Dominguez", "Javier"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "Empirical evaluation of gated recurrent neural networks on sequence modeling.\" \u200barXiv preprint arXiv:1412.3555  \u200b", "author": ["Chung", "Junyoung"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2014}, {"title": "Bidirectional LSTM networks for improved phoneme classification and recognition.\"\u200bInternational Conference on Artificial Neural Networks  \u200b", "author": ["Graves", "Alex", "Santiago Fern\u00e1ndez", "J\u00fcrgen Schmidhuber"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2005}, {"title": "Language recognition in ivectors space.\" \u200bProceedings of Interspeech, Firenze, Italy  \u200b", "author": ["Mart\u0131nez", "David"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2011}, {"title": "Front-end factor analysis for speaker verification.\" \u200bIEEE Transactions on Audio, Speech, and Language Processing  \u200b", "author": ["Dehak", "Najim"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2011}, {"title": "Language Identification in Short Utterances Using Long Short-Term Memory (LSTM) Recurrent Neural Networks.\" \u200bPloS one  \u200b", "author": ["Zazo", "Ruben"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2016}, {"title": "Recurrent Convolutional Neural Networks for Scene Labeling.\" \u200bICML  \u200b", "author": ["Pinheiro", "Pedro HO", "Ronan Collobert"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "LSTM with Working Memory.\" \u200barXiv preprint arXiv:1605.01988  \u200b", "author": ["Pulver", "Andrew", "Siwei Lyu"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2016}, {"title": "The vanishing gradient problem during learning recurrent neural nets and problem solutions.\" \u200bInternational Journal of Uncertainty, Fuzziness and Knowledge-Based Systems  \u200b", "author": ["Hochreiter", "Sepp"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1998}, {"title": "ImageNet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "NIPS, 2012", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["K. Simonyan", "A. Zisserman"], "venue": "ICLR, 2015.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2015}, {"title": "Going deeper with convolutions", "author": ["C. Szegedy", "W. Liu", "Y. Jia", "P. Sermanet", "S. Reed", "D. Anguelov", "D. Erhan", "V. Vanhoucke", "A. Rabinovich"], "venue": "CVPR, 2015.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "In particular, guided by the advances on speaker veri\uf001cation and recognition, the use of i-vector extractors for extracting features from the sample and using classification techniques such as Bayesian classification has become the norm in acoustic LID systems [1].", "startOffset": 261, "endOffset": 264}, {"referenceID": 6, "context": "One such case has been the less frequent use of Convolutional Recurrent Neural Networks (CRNN)[7] which are computationally heavy due to multiple complex layers and each layer having to compute the parameters multiple times.", "startOffset": 94, "endOffset": 97}, {"referenceID": 2, "context": "\u200bThe study by Schmidhuber, Graves and Fernandez shows this gulf in the performance [3].", "startOffset": 83, "endOffset": 86}, {"referenceID": 3, "context": "This approach is based on the approach described in [4].", "startOffset": 52, "endOffset": 55}, {"referenceID": 4, "context": "This approach is based on the Gaussian components, which are trained on PLP coefficients like MFCC and \u2206(delta) of MFCC and \u2206\u2206(double-delta) MFCC which are extracted over a specific frame rate of 10ms over 25ms window length and following the standard protocol described in [5] we can extract the i-vector of each languages.", "startOffset": 274, "endOffset": 277}, {"referenceID": 5, "context": "The approach presented by [6] is an improvement over the traditional i-vector analysis of the LID system since it tries to find the temporal hidden patterns between each window frames using the recurrent hidden layers.", "startOffset": 26, "endOffset": 29}, {"referenceID": 6, "context": "Traditionally, Convolutional recurrent neural network are used for scene labelling[7], that is, using Convolutional Neural Networks with Intra-layer Recurrent Connections, we use this novel approach for finding the relation between the frames of audio sample in the training dataset.", "startOffset": 82, "endOffset": 85}, {"referenceID": 5, "context": "The advantage of doing is that, theoretically, it can provide the solution to the problem in the approach described by [6].", "startOffset": 119, "endOffset": 122}, {"referenceID": 8, "context": "Although a temporal relationship is established, the vanishing gradient problem, mentioned by [9] is even more prevalent in an RNN, because each feedback to each layer can be visualized as an entire new hidden layer from a typical feed forward network.", "startOffset": 94, "endOffset": 97}, {"referenceID": 0, "context": "Because i\u200bt and f\u200bt are sigmoidal, their values lie within the range [0, 1].", "startOffset": 69, "endOffset": 75}, {"referenceID": 7, "context": "What the LSTM [8] unit does is, taking the input layer at a particular instance of time and the output from the previous instance, the input to each cell is multiplied by the activation of the input gate.", "startOffset": 14, "endOffset": 17}, {"referenceID": 9, "context": "LCRNN are proven to be powerful models in perceptual challenges [10],[11],[12], especially visual feature pattern recognition, because of the their strategic implementation of the non-linear functions.", "startOffset": 64, "endOffset": 68}, {"referenceID": 10, "context": "LCRNN are proven to be powerful models in perceptual challenges [10],[11],[12], especially visual feature pattern recognition, because of the their strategic implementation of the non-linear functions.", "startOffset": 69, "endOffset": 73}, {"referenceID": 11, "context": "LCRNN are proven to be powerful models in perceptual challenges [10],[11],[12], especially visual feature pattern recognition, because of the their strategic implementation of the non-linear functions.", "startOffset": 74, "endOffset": 78}], "year": 0, "abstractText": "Language Identification, being an important aspect of Automatic Speaker Recognition has had many changes and new approaches to ameliorate performance over the last decade. We compare the performance of using audio spectrum in the log scale and using Polyphonic sound sequences from raw audio samples to train the neural network and to classify speech as either English or Spanish. To achieve this, we use the novel approach of using a Convolutional Recurrent Neural Network using Long Short Term Memory (LSTM) or a Gated Recurrent Unit (GRU) for forward propagation of the neural network. Our hypothesis is that the performance of using polyphonic sound sequence as features and both LSTM and GRU as the gating mechanisms for the neural network outperform the traditional MFCC features using a unidirectional Deep Neural Network.", "creator": null}}}