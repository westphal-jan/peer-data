{"id": "1611.04326", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Nov-2016", "title": "`Who would have thought of that!': A Hierarchical Topic Model for Extraction of Sarcasm-prevalent Topics and Sarcasm Detection", "abstract": "Topic Models have been reported to be beneficial for aspect-based sentiment analysis. This paper reports a simple topic model for sarcasm detection, a first, to the best of our knowledge. Designed on the basis of the intuition that sarcastic tweets are likely to have a mixture of words of both sentiments as against tweets with literal sentiment (either positive or negative), our hierarchical topic model discovers sarcasm-prevalent topics and topic-level sentiment. Using a dataset of tweets labeled using hashtags, the model estimates topic-level, and sentiment-level distributions. Our evaluation shows that topics such as `work', `gun laws', `weather' are sarcasm-prevalent topics. Our model is also able to discover the mixture of sentiment-bearing words that exist in a text of a given sentiment-related label. Finally, we apply our model to predict sarcasm in tweets. We outperform two prior work based on statistical classifiers with specific features, by around 25\\%.", "histories": [["v1", "Mon, 14 Nov 2016 10:40:44 GMT  (55kb,D)", "http://arxiv.org/abs/1611.04326v1", "This paper will be presented at ExPROM workshop at COLING 2016"], ["v2", "Tue, 22 Nov 2016 10:55:56 GMT  (55kb,D)", "http://arxiv.org/abs/1611.04326v2", "This version of the paper contains corrected changes, after the camera -ready submission. These changes were observed based on an issue in the output returned by SVM Perf. This paper will be presented at ExPROM workshop at COLING 2016"]], "COMMENTS": "This paper will be presented at ExPROM workshop at COLING 2016", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["aditya joshi", "prayas jain", "pushpak bhattacharyya", "mark carman"], "accepted": false, "id": "1611.04326"}, "pdf": {"name": "1611.04326.pdf", "metadata": {"source": "CRF", "title": "\u2018Who would have thought of that!\u2019: A Hierarchical Topic Model for Extraction of Sarcasm-prevalent Topics and Sarcasm Detection", "authors": ["Aditya Joshi", "Prayas Jain", "Pushpak Bhattacharyya", "Mark James Carman"], "emails": ["pb}@cse.iitb.ac.in", "prayas.jain.cse14@iitbhu.ac.in", "mark.carman@monash.edu"], "sections": [{"heading": "1 Introduction", "text": "This work will be presented at the 3rd ExPROM workshop in COLING 2016. http: / / www.cse. unt.edu / exprom2016 / Sarcasm detection is the computational task of predicting sarcasm in text. Previous approaches to sarcasm detection rely on designing classifiers with specific characteristics (to capture sentiments changes or incorporate context about the author, environment, etc.) (Joshi et al., 2015; Wallace et al., 2014; Rajadesingan et al., 2015; Bamman and Smith, 2015), or modeling with the sequence-labeling-based approach of Joshi et al. (2016c). This work employs approaches that are in addition to these statistical classification paradigms: deep learning-based approaches as in the case of Silvio Amir et al. (2016) or rule-based approaches such as Riloff et al. (2013; Khattri et al.).This work employs a machine learning technique that we do not have the best outcome for us."}, {"heading": "2 Related Work", "text": "However, in terms of the use of two latent variables, one for aspect and one for feeling, they are related to our model. Finally, McAuley and Leskovec (2013a) attempt to generate valuation dimensions of products based on theme models. However, the theme models reported in the past have been used for sentiment analysis in general, with no particular emphasis on sarcasm as a label or sarcastic tweets as a special case of tweets. Hierarchy-based structure (especially the chain of distribution models for sentiment analysis)."}, {"heading": "3 Motivation", "text": "The motivation behind the use of topic models to detect sarcasm stems from two reasons: (a) the presence of topic that dominates sarcasm, and (b) differences in the distribution of emotion in sarcastic and non-sarcastic text. In the context of sentiment analysis, topic models were used for aspect-based sentiment analysis to detect topic and sentiment words (Jo and Oh, 2011). The general idea is that for restaurant evaluation, the word \"spicy\" describes food rather than ambience. Similarly, the discovery that a number of words belong to a sarcasm-dominant topic - a topic to which sarcasm remarks are common - is useful as additional information to a sarcasm recognition system. The basic idea of our approach is that some topics evoke negative words rather than negative sarcasms."}, {"heading": "4 Sarcasm Topic Model", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Design Rationale", "text": "Our theme model requires sentiment labels of tweets, such as those used in Ramage et al. (2009). This sentiment can be positive or negative. However, to include sarcasm, we divide the two sentiment values into three: literally positive, literally negative and sarcastic. The observed variable l in our model indicates this sentiment label. For the sake of simplicity, we refer to the three values of l as positive, negative and sarcastic in the rest of the paper. Every word w in a tweet is either a theme word or a sentiment word. A theme word arises from a theme, whereas a sentiment word arises from a combination of theme and sentiment. This notion is common in several sentiment-based theme models of past work (Jo and Oh, 2011). To determine which of the two (theme or sentiment words) is a given word, our model uses three latent tweets: a sentiment, a sentiment, an element."}, {"heading": "4.2 Plate Diagram", "text": "Our sarcasm theme model for extracting sarcasm dominant themes is based on a monitored sentiment sentiment (Lead et al., 2003). Figure 1 shows the plate chart, while Table 1 describes the variables and distributions in the model. Each tweet consists of a series of observed words w and a tweet level, observed sentiment labeling l. The label assumes three values: positive, negative or sarcastic. The third label value \"sarcastic\" refers to a topic where a tweet appears positive on the surface but is implicitly negative (hence, sarcastic). z is a latent word variable that represents when a word is a theme word or sentiment word, 1note that this word is not appreciated during sampling, but is learned from a large-scale corpus."}, {"heading": "5 Experiment Setup", "text": "We create a dataset of English tweets for our theme model. We do not use datasets that have been repeated in the past (related to classifiers) because theme models typically require larger datasets than classifiers. Tweets are downloaded from Twitter and use the Twitter API2 using hashtag-based monitoring. Hashtag-based monitoring is common in sarcasm-designated datasets (Joshi et al., 2015). Tweets that contain hashtags # happy, # excited are labeled as positive tweets. Tweets with # sad, # angry are labeled as negative tweets. Tweets with # sarcasm and # sarcastic are labeled as sarcastic tweets. Tweets are converted into lowercase letters, and the hashtags used for monitoring are labeled as positive tweets. Functional wort3, punctuation, hashtags, author names2https: / twiubli.twitterrest / Twecepsh3.com and www.Hypersequences.com are removed."}, {"heading": "6.1 Qualitative Evaluation", "text": "We do this in two steps. First, we describe the topics that arise when only sarcastic tweets from our corpus are used to estimate the distributions, followed by those when the full corpus is used. In the case of the first tweet, since only sarcastic tweets are used, the topics generated here point to words that correspond to sarcastic dominant topics. In the case of the second topic, the distributions of sentiment topics in the model capture the spread of sarcasm. The model estimates the number and distributions that correspond to the topic words and sentiment words. The top five words for a subset of topics (how they are estimated) are shown in Table 2. Headings in bold are assigned manually 4. Sarcasm-dominant topics, as discovered by our topic model, are work, party, weather, women, etc. The corresponding sentiment topics for each of these sarcastic dominant topics."}, {"heading": "6.2 Quantitative Evaluation", "text": "In this section, we will answer three questions: (A) What is the likely sentiment designation when a user talks about a particular topic? (Section 6.2.1), (B) We assume that sarcastic text tends to have mixed polarities; does this apply to our model? (Section 6.2.2) and (C) How can the sarcasm theme model be used to detect sarcasm? (Section 6.2.3)."}, {"heading": "6.2.1 Probability of sentiment label, given topic", "text": "We calculate the probability p (l / z) based on the model. Table 6 shows these values for a subset of topics. Topics with a predominantly positive mood are Father's Day (0.9224), holidays (0.9538), etc. The subject with the highest probability of a negative mood is the Orlando rampage (0.95). Gun laws (0.5230), work and humor are the areas where sarcasm prevails."}, {"heading": "6.2.2 Distribution of sentiment words for tweet-level sentiment labels", "text": "The X axis indicates the percentage of positive sentiment words in a tweet, while the Y axis indicates the percentage of tweets that indicate a certain percentage value. Over 60% of negative tweets (bars in red) have 0% words with positive content. Here, the \"positive\" indicates the value of s for a word in a tweet. In other words, said red bar indicates that 60% of tweets have 0% words that are scanned with s as a positive value. It intuitively results that negative tweets have a small percentage of positive words (red bar on the left part of the chart), while positive tweets have a high percentage of positive words (blue bar on the right part of the chart). Interesting deviations can be observed in sarcastic tweets. It should be noted that the sentiment labels considered for these proportions are considered positive by our topic model."}, {"heading": "6.2.3 Application to Sarcasm Detection", "text": "We now use our sarcasm theme model to detect sarcasm, and compare it to two previous papers. Here, the task is to classify a tweet as either sarcastic or not. We use the theme model to detect sarcasm using two methods: 1. Log probability based: The theme model is first learned from the training corpus in which the distributions in the model are estimated, and then the theme model conducts sampling for a pre-determined number of samples, in three runs - once for each topic. 2. Sample based on: As in the previous case, the theme model will classify the distributions (during the training phase) and the sample values of the latent variables (for this tweet). The name of the tweet will be returned as the one with the highest log probability. 2. Sample based on: As in the previous case, the theme model will classify the distributions (during the training phase) and the sample values of the latables for this tweet as incorrect."}, {"heading": "7 Conclusion & Future Work", "text": "Our theme model uses a data set of tweets (defined as positive, negative, and sarcastic) and estimates distributions that correspond to the prevalence of a topic, the prevalence of an emotive word. We observed that topics such as work, weather, politics, etc. were discovered to be sarcastic dominant themes. We evaluated the model in three steps: (a) Based on the distributions learned by our model, we show the most likely designation for all themes. This is to understand the prevalence of themes when the model is learned on the full corpus. (b) We then show the distribution of the emotional mood at the word level for each sentiment appreciated by our model at the tweet level. Our intuition that the mood distribution in a tweet is different for the three labels: positive, negative, and sarcastic, applies to the current work. (c) Finally, we show how themes from this theme model can be used as sarcastic."}], "references": [{"title": "Sentiwordnet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining", "author": ["Andrea Esuli", "Fabrizio Sebastiani"], "venue": "In LREC,", "citeRegEx": "Baccianella et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Baccianella et al\\.", "year": 2010}, {"title": "Contextualized sarcasm detection on twitter", "author": ["Bamman", "Smith2015] David Bamman", "Noah A Smith"], "venue": "In Ninth International AAAI Conference on Web and Social Media", "citeRegEx": "Bamman et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Bamman et al\\.", "year": 2015}, {"title": "Latent dirichlet allocation", "author": ["Blei et al.2003] David M Blei", "Andrew Y Ng", "Michael I Jordan"], "venue": "Journal of machine Learning research,", "citeRegEx": "Blei et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Blei et al\\.", "year": 2003}, {"title": "An impact analysis of features in a classification approach to irony detection in product reviews", "author": ["Philipp Cimiano", "Roman Klinger"], "venue": "In Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis,", "citeRegEx": "Buschmeier et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Buschmeier et al\\.", "year": 2014}, {"title": "Aspect and sentiment unification model for online review analysis", "author": ["Jo", "Oh2011] Yohan Jo", "Alice H Oh"], "venue": "In Proceedings of the fourth ACM international conference on Web search and data mining,", "citeRegEx": "Jo et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Jo et al\\.", "year": 2011}, {"title": "Harnessing context incongruity for sarcasm detection", "author": ["Joshi et al.2015] Aditya Joshi", "Vinita Sharma", "Pushpak Bhattacharyya"], "venue": "In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing,", "citeRegEx": "Joshi et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Joshi et al\\.", "year": 2015}, {"title": "Political issue extraction model: A novel hierarchical topic model that uses tweets by political and non-political authors", "author": ["Joshi et al.2016a] Aditya Joshi", "Pushpak Bhattacharyya", "Mark Carman"], "venue": "In 7th Workshop on Computational Approaches to Subjectivity, Sentiment & Social Media Analysis,", "citeRegEx": "Joshi et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Joshi et al\\.", "year": 2016}, {"title": "Automatic sarcasm detection: A survey", "author": ["Joshi et al.2016b] Aditya Joshi", "Pushpak Bhattacharyya", "Mark James Carman"], "venue": "arXiv preprint arXiv:1602.03426", "citeRegEx": "Joshi et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Joshi et al\\.", "year": 2016}, {"title": "Harnessing sequence labeling for sarcasm detection in dialogue from tv series \u2018friends", "author": ["Joshi et al.2016c] Aditya Joshi", "Vaibhav Tripathi", "Pushpak Bhattacharyya", "Mark Carman"], "venue": null, "citeRegEx": "Joshi et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Joshi et al\\.", "year": 2016}, {"title": "Your sentiment precedes you: Using an author\u2019s historical tweets to predict sarcasm", "author": ["Aditya Joshi", "Pushpak Bhattacharyya", "Mark James Carman"], "venue": "In 6TH WORKSHOP ON COMPUTATIONAL APPROACHES TO SUBJECTIVITY, SENTIMENT AND SOCIAL MEDIA ANALYSIS WASSA", "citeRegEx": "Khattri et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Khattri et al\\.", "year": 2015}, {"title": "A hierarchical aspect-sentiment model for online reviews", "author": ["Kim et al.2013] Suin Kim", "Jianwen Zhang", "Zheng Chen", "Alice H Oh", "Shixia Liu"], "venue": null, "citeRegEx": "Kim et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Kim et al\\.", "year": 2013}, {"title": "The perfect solution for detecting sarcasm in tweets", "author": ["FA Kunneman", "APJ van den Bosch"], "venue": null, "citeRegEx": "Liebrecht et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Liebrecht et al\\.", "year": 2013}, {"title": "Hidden factors and hidden topics: understanding rating dimensions with review text", "author": ["McAuley", "Leskovec2013a] Julian McAuley", "Jure Leskovec"], "venue": "In Proceedings of the 7th ACM conference on Recommender systems,", "citeRegEx": "McAuley et al\\.,? \\Q2013\\E", "shortCiteRegEx": "McAuley et al\\.", "year": 2013}, {"title": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "author": ["McAuley", "Jure Leskovec"], "venue": "In Proceedings of the 22nd international conference on World Wide Web,", "citeRegEx": "McAuley et al\\.,? \\Q2013\\E", "shortCiteRegEx": "McAuley et al\\.", "year": 2013}, {"title": "Aspect extraction through semi-supervised modeling", "author": ["Mukherjee", "Liu2012a] Arjun Mukherjee", "Bing Liu"], "venue": "In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume", "citeRegEx": "Mukherjee et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Mukherjee et al\\.", "year": 2012}, {"title": "Aspect extraction through semi-supervised modeling", "author": ["Mukherjee", "Liu2012b] Arjun Mukherjee", "Bing Liu"], "venue": "In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume", "citeRegEx": "Mukherjee et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Mukherjee et al\\.", "year": 2012}, {"title": "Modeling review comments. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1, pages 320\u2013329", "author": ["Mukherjee", "Liu2012c] Arjun Mukherjee", "Bing Liu"], "venue": null, "citeRegEx": "Mukherjee et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Mukherjee et al\\.", "year": 2012}, {"title": "Sarcasm detection on twitter: A behavioral modeling approach", "author": ["Reza Zafarani", "Huan Liu"], "venue": "In Proceedings of the Eighth ACM International Conference on Web Search and Data Mining,", "citeRegEx": "Rajadesingan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Rajadesingan et al\\.", "year": 2015}, {"title": "Labeled lda: A supervised topic model for credit attribution in multi-labeled corpora", "author": ["Ramage et al.2009] Daniel Ramage", "David Hall", "Ramesh Nallapati", "Christopher D. Manning"], "venue": "In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 1 - Volume 1,", "citeRegEx": "Ramage et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Ramage et al\\.", "year": 2009}, {"title": "Sarcasm as contrast between a positive sentiment and negative situation", "author": ["Riloff et al.2013] Ellen Riloff", "Ashequl Qadir", "Prafulla Surve", "Lalindra De Silva", "Nathan Gilbert", "Ruihong Huang"], "venue": "In EMNLP,", "citeRegEx": "Riloff et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Riloff et al\\.", "year": 2013}, {"title": "Modelling context with user embeddings for sarcasm detection in social media", "author": ["Wallace", "Hao Lyu", "Paula Carvalho M\u00e1rio J Silva"], "venue": null, "citeRegEx": "Amir et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Amir et al\\.", "year": 2016}, {"title": "Humans require context to infer ironic intent (so computers probably do, too)", "author": ["Do Kook Choe", "Laura Kertz", "Eugene Charniak"], "venue": "In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),", "citeRegEx": "Wallace et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Wallace et al\\.", "year": 2014}, {"title": "Twitter sarcasm detection exploiting a context-based model", "author": ["Wang et al.2015] Zelin Wang", "Zhijian Wu", "Ruimin Wang", "Yafeng Ren"], "venue": "In Web Information Systems Engineering\u2013WISE", "citeRegEx": "Wang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 5, "context": ") (Joshi et al., 2015; Wallace et al., 2014; Rajadesingan et al., 2015; Bamman and Smith, 2015), or model conversations using the sequence labeling-based approach by Joshi et al.", "startOffset": 2, "endOffset": 95}, {"referenceID": 21, "context": ") (Joshi et al., 2015; Wallace et al., 2014; Rajadesingan et al., 2015; Bamman and Smith, 2015), or model conversations using the sequence labeling-based approach by Joshi et al.", "startOffset": 2, "endOffset": 95}, {"referenceID": 17, "context": ") (Joshi et al., 2015; Wallace et al., 2014; Rajadesingan et al., 2015; Bamman and Smith, 2015), or model conversations using the sequence labeling-based approach by Joshi et al.", "startOffset": 2, "endOffset": 95}, {"referenceID": 2, "context": "Our model based on a supervised version of the Latent Dirichlet Allocation (LDA) model (Blei et al., 2003) is able to discover clusters of words that correspond to sarcastic topics.", "startOffset": 87, "endOffset": 106}, {"referenceID": 4, "context": ") (Joshi et al., 2015; Wallace et al., 2014; Rajadesingan et al., 2015; Bamman and Smith, 2015), or model conversations using the sequence labeling-based approach by Joshi et al. (2016c). Approaches, in addition to this statistical classifier-based paradigm are: deep learning-based approaches as in the case of Silvio Amir et al.", "startOffset": 3, "endOffset": 187}, {"referenceID": 4, "context": ") (Joshi et al., 2015; Wallace et al., 2014; Rajadesingan et al., 2015; Bamman and Smith, 2015), or model conversations using the sequence labeling-based approach by Joshi et al. (2016c). Approaches, in addition to this statistical classifier-based paradigm are: deep learning-based approaches as in the case of Silvio Amir et al. (2016) or rule-based approaches such as Riloff et al.", "startOffset": 3, "endOffset": 338}, {"referenceID": 4, "context": ") (Joshi et al., 2015; Wallace et al., 2014; Rajadesingan et al., 2015; Bamman and Smith, 2015), or model conversations using the sequence labeling-based approach by Joshi et al. (2016c). Approaches, in addition to this statistical classifier-based paradigm are: deep learning-based approaches as in the case of Silvio Amir et al. (2016) or rule-based approaches such as Riloff et al. (2013; Khattri et al. (2015). This work employs a machine learning technique that, to the best of our knowledge, has not been used for computational sarcasm.", "startOffset": 3, "endOffset": 414}, {"referenceID": 11, "context": "Sarcasm detection approaches have also been reported in the past (Joshi et al., 2016b; Liebrecht et al., 2013; Wang et al., 2015; Joshi et al., 2015).", "startOffset": 65, "endOffset": 149}, {"referenceID": 22, "context": "Sarcasm detection approaches have also been reported in the past (Joshi et al., 2016b; Liebrecht et al., 2013; Wang et al., 2015; Joshi et al., 2015).", "startOffset": 65, "endOffset": 149}, {"referenceID": 5, "context": "Sarcasm detection approaches have also been reported in the past (Joshi et al., 2016b; Liebrecht et al., 2013; Wang et al., 2015; Joshi et al., 2015).", "startOffset": 65, "endOffset": 149}, {"referenceID": 4, "context": "The hierarchy-based structure (specifically, the chain of distributions for sentiment label) in our model is based on Joshi et al. (2016a) who extract politically relevant topics from a dataset of political tweets.", "startOffset": 118, "endOffset": 139}, {"referenceID": 4, "context": "The hierarchy-based structure (specifically, the chain of distributions for sentiment label) in our model is based on Joshi et al. (2016a) who extract politically relevant topics from a dataset of political tweets. The chain in their case is sentiment distribution of an individual and a group. Sarcasm detection approaches have also been reported in the past (Joshi et al., 2016b; Liebrecht et al., 2013; Wang et al., 2015; Joshi et al., 2015). Wang et al. (2015) present a contextual model for sarcasm detection that collectively models a set of tweets, using a sequence labeling algorithm - however, the goal is to detect sarcasm in the last tweet in the sequence.", "startOffset": 118, "endOffset": 465}, {"referenceID": 3, "context": "In order to evaluate the benefit of our model to sarcasm detection, we compare two sarcasm detection approaches based on our model with two prior work, namely by Buschmeier et al. (2014) and Liebrecht et al.", "startOffset": 162, "endOffset": 187}, {"referenceID": 3, "context": "In order to evaluate the benefit of our model to sarcasm detection, we compare two sarcasm detection approaches based on our model with two prior work, namely by Buschmeier et al. (2014) and Liebrecht et al. (2013). Buschmeier et al.", "startOffset": 162, "endOffset": 215}, {"referenceID": 3, "context": "In order to evaluate the benefit of our model to sarcasm detection, we compare two sarcasm detection approaches based on our model with two prior work, namely by Buschmeier et al. (2014) and Liebrecht et al. (2013). Buschmeier et al. (2014) train their classifiers using features such as unigrams, laughter expressions, hyperbolic expressions, etc.", "startOffset": 162, "endOffset": 241}, {"referenceID": 3, "context": "In order to evaluate the benefit of our model to sarcasm detection, we compare two sarcasm detection approaches based on our model with two prior work, namely by Buschmeier et al. (2014) and Liebrecht et al. (2013). Buschmeier et al. (2014) train their classifiers using features such as unigrams, laughter expressions, hyperbolic expressions, etc. Liebrecht et al. (2013) experiment with unigrams, bigrams and trigrams as features.", "startOffset": 162, "endOffset": 373}, {"referenceID": 18, "context": "Our topic model requires sentiment labels of tweets, as used in Ramage et al. (2009). This sentiment can be positive or negative.", "startOffset": 64, "endOffset": 85}, {"referenceID": 2, "context": "Our sarcasm topic model to extract sarcasm-prevalent topics is based on supervised LDA (Blei et al., 2003).", "startOffset": 87, "endOffset": 106}, {"referenceID": 5, "context": "Hashtag-based supervision is common in sarcasm-labeled datasets (Joshi et al., 2015).", "startOffset": 64, "endOffset": 84}, {"referenceID": 0, "context": "SentiWordNet (Baccianella et al., 2010) is used to learn the distribution \u03b7w prior to estimating the model.", "startOffset": 13, "endOffset": 39}, {"referenceID": 10, "context": "(Mukherjee and Liu, 2012b; Joshi et al., 2016a; Kim et al., 2013)", "startOffset": 0, "endOffset": 65}, {"referenceID": 3, "context": "We compare our results with two previously existing techniques, Buschmeier et al. (2014) and Liebrecht et al.", "startOffset": 64, "endOffset": 89}, {"referenceID": 3, "context": "We compare our results with two previously existing techniques, Buschmeier et al. (2014) and Liebrecht et al. (2013). We ensure that our implementations result in performance comparable to the reported papers.", "startOffset": 64, "endOffset": 117}, {"referenceID": 3, "context": "We compare our results with two previously existing techniques, Buschmeier et al. (2014) and Liebrecht et al. (2013). We ensure that our implementations result in performance comparable to the reported papers. The two rely on designing sarcasm-level features, and training classifiers for these features. For these classifiers, the positive and negative labels are combined as non-sarcastic. As stated above, the test set is separate from the training set. The results of these two past methods compared with the two based on topic models are shown in Table 7. The values are averaged over the two classes. Both prior work show poor F-score (around 18-19%) while our sampling based approach achieves the best F-score of 46.80%. The low values, in general, may be because our corpus is large in size, and is diverse in terms of the topics. Also, features in Liebrecht et al. (2013) are unigrams, bigrams and trigrams which may result in sparse features.", "startOffset": 64, "endOffset": 881}, {"referenceID": 3, "context": "(Buschmeier et al., 2014) 10.", "startOffset": 0, "endOffset": 25}, {"referenceID": 11, "context": "85 (Liebrecht et al., 2013) 11.", "startOffset": 3, "endOffset": 27}], "year": 2017, "abstractText": "Topic Models have been reported to be beneficial for aspect-based sentiment analysis. This paper reports a simple topic model for sarcasm detection, a first, to the best of our knowledge. Designed on the basis of the intuition that sarcastic tweets are likely to have a mixture of words of both sentiments as against tweets with literal sentiment (either positive or negative), our hierarchical topic model discovers sarcasm-prevalent topics and topic-level sentiment. Using a dataset of tweets labeled using hashtags, the model estimates topic-level, and sentiment-level distributions. Our evaluation shows that topics such as \u2018work\u2019, \u2018gun laws\u2019, \u2018weather\u2019 are sarcasm-prevalent topics. Our model is also able to discover the mixture of sentiment-bearing words that exist in a text of a given sentiment-related label. Finally, we apply our model to predict sarcasm in tweets. We outperform two prior work based on statistical classifiers with specific features, by around 25%.", "creator": "LaTeX with hyperref package"}}}