{"id": "1611.04871", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Nov-2016", "title": "Audio Event and Scene Recognition: A Unified Approach using Strongly and Weakly Labeled Data", "abstract": "In this paper we propose a novel learning framework called Supervised and Weakly Supervised Learning where the goal is to learn simultaneously from weakly and strongly labeled data. Strongly labeled data can be simply understood as fully supervised data where all labeled instances are available. In weakly supervised learning only weak labels are available. Our proposed framework is motivated by the fact that a small amount of strongly labeled data can give considerable improvement over only weakly supervised learning. The primary problem domain focus of this paper is acoustic event and scene detection in audio recordings. We first propose a naive formulation for leveraging labeled data in both forms. We then propose a more general framework for Supervised and Weakly Supervised Learning (SWSL). Based on this general framework, we propose a graph based approach for SWSL. Our main method is based on manifold regularization on graphs in which we show that the unified learning can be formulated as a constraint optimization problem which can be solved by iterative concave-convex procedure (CCCP). Our experiments show that our proposed framework can address several concerns of audio content analysis using weakly labeled data.", "histories": [["v1", "Sat, 12 Nov 2016 07:39:50 GMT  (103kb)", "https://arxiv.org/abs/1611.04871v1", null], ["v2", "Wed, 23 Nov 2016 23:17:46 GMT  (103kb)", "http://arxiv.org/abs/1611.04871v2", null], ["v3", "Sat, 18 Feb 2017 07:18:32 GMT  (103kb)", "http://arxiv.org/abs/1611.04871v3", "IJCNN 2017, 8 pages"]], "reviews": [], "SUBJECTS": "cs.LG cs.CV cs.SD", "authors": ["anurag kumar", "bhiksha raj"], "accepted": false, "id": "1611.04871"}, "pdf": {"name": "1611.04871.pdf", "metadata": {"source": "CRF", "title": "Audio Event and Scene Recognition: A Unified Approach using Strongly and Weakly Labeled Data", "authors": ["Anurag Kumar", "Bhiksha Raj"], "emails": ["alnu@andrew.cmu.edu", "bhiksha@cs.cmu.edu"], "sections": [{"heading": null, "text": "This year is the highest in the history of the country."}, {"heading": "A. Naive SWSL", "text": "The simplest approach for SWSL is to formulate the heavily labeled data as a special case of poorly labeled data. In this particular case, each labeled instance is framed as a single-instance bag. The bag label is the same as the instance level. Once this is done, any MIL approach can be applied, as in the case of poorly supervised learning. We call this method naive SWSL or simple SWSL. Since each bag contains only one instance, all MIL methods that consider limits in bags of at least one positive in positive bags and all negatives in negative bags would end up meeting supervised labeled limits. For example, the use of miSVM as a simple SWSL would imply that for bags made up of supervised data, limits are met in bags as in classically supervised bags, while for other bags the same limitations as in bad descriptions and bad HSL forms are used."}, {"heading": "B. Generalized SWSL", "text": "This year, the time has come for it to be able to reform and reform itself."}, {"heading": "A. Manifold Regularization approach for SWSL", "text": "In the diagram based on semi-supervised learning, all instances are assumed to be joined by a diagram G = (V, E) (with indentations V being instances in the data).In this paper, we assume that kNN diagram [24], where a vertex xi is connected to another vertex xj, is joined by a non-zero weight wij if xi is one of the closest neighbors of xj and vice versa. Edge weight wij is then defined by Gaussian kernel, wij = exp (\u2212 xi \u2212 xj).The bandwidth parameter for the weights is unique if xi and xj are not connected wij = 0. The general diagram is by a symmetrical weight matrix W, whose elements are wij. Finally, the unstandardized diagram laplacian L is defined by L = D \u2212 W, where D \u2212 W is diagonal matrix with Dii =."}, {"heading": "B. Optimization Solution", "text": "The objective function in the optimization problem in Eq 5 is a convex differential function = max. constraint (1 \u2212 max j = pt,..., qt K \u2032 j\u03b1 \u0445t) is not a convex, but a difference of two convex functions. Convex concave method (CCCP) [32] is a well-known method of sequential convex programming to handle problems like this. It is an iterative method in which the non-convex function is converted into a convex function by Taylor making an approximation to the current solution. For a lens or constraint in the form of g (x) \u2212 h (x) \u2212 h (x) \u2212 kp \u2212 h (x) is a convex approximation to x (k)."}, {"heading": "IV. ACOUSTIC FEATURES FOR AUDIO SEGMENTS", "text": "In this thesis, we use the Gaussian Mixture Model (GMM) based histogram to characterize audio segments used in earlier weakly monitored audio event detection work [18], [17]. It has proven to be an effective feature representation for audio event detection tasks. GMM components represent audio words and the final features are normalized soft-count histograms. All audio recordings are first parameterized by MelCeptra coefficients (MFCCs). MFCCs for the training data are then used to train a GMM. Let G = {wc, N (~ \u00b5c, pracc)} be this GMM, with wc being the mixing weight for the c th component of GMM and ~ \u00b5c being the mean and covariance matrix of GMM."}, {"heading": "V. EXPERIMENTS AND RESULTS", "text": "In our experiments, we add a small amount of heavily labeled data to the pool of poorly labeled data to learn event or scene detectors using SWSL and compare them with poorly supervised learning. for poorly labeled learning, we use the miSVM approach [22]. miSVM was also used in earlier poorly supervised audio event detection work [17]. For simple SWSL, we reuse the miSVM approach to integrate strongly and weakly labeled data.The details specific to audio events and scenes are presented in corresponding paragraphs. The details specific to audio events and scenes are displayed in corresponding paragraphs. The joint experimental recordings are sampled at 44.1KHz sampling frequency. 20 dimensional MFCC features along with delta and acceleration coefficients are used to parameterise audio recordings."}, {"heading": "A. Acoustic Event Detection", "text": "rE \"s rf\u00fc ide rf\u00fc ide rf\u00fc ide rf\u00fc die f \u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f"}, {"heading": "B. Acoustic Scene Detection", "text": "The procedure for acoustic scenes remains similar to acoustic events. We work with a toal of 15 acoustic scenes from DCASE [14] data set, which is also the source of our heavily labeled data. Weakly labeled training data is retrieved from Youtube in a process similar to audio events. In this case, we create weakly labeled data of 40 recordings per scene, totaling 600 recordings spanning over 27 hours. Again, we get test data from Freesound. In total, 928 test recordings (38 hours) are used. Test data contain an average of 61 recordings per scene with a minimum of 53 for Forest Path scene and a maximum of 71 for Residential Area Scene. Segment size is the average duration of scenes in heavily labeled data. The monitored data from DCASE comes in 4 folds and our experimental approach is evident as before."}, {"heading": "C. Temporal Localization of Audio Events", "text": "An important advantage of poorly monitored AED with methods like miSVM is that we get a rough estimate of the temporal location of events in an audio recording. In this section, we evaluate different methods for timing events. We only consider audio events, as audio events are usually short-term acoustic phenomena. Assessing the temporal location of events is more difficult than detecting the recording level of events. In simplified terms, timing means evaluating all methods at the instance level. Therefore, we need heavily labeled test data to know the ground truth labels for instance (segments). As this is not available for the test data used in the previous section, we use the omitted convolution from the ESC-10 dataset to evaluate the instance performance. This means that the convolution omitted from the training process for simple SWSLand charts is used as test data."}, {"heading": "VI. CONCLUSIONS", "text": "The unified learning framework proposed in this paper enables marked data to be used in both forms at the same time. More importantly, the proposed SWSL framework can help allay concerns about poorly monitored learning of audio events. Weakly monitored learning is a promising approach to scaling audio events by using poorly described web data. However, it comes with its own concerns and we have shown that SWSL can successfully solve these problems. From a learning perspective, our primary assertion in this paper is that SWSL can be cast as a limitation form of semi-monitored learning. We proposed a method based on diverse regulation of charts, in addition to the naive way in which strongly described data can be incorporated into weakly monitored learning. A significant improvement in performance can be observed for both audio event and scene recognition tasks."}], "references": [{"title": "Detection and classification of acoustic scenes and events", "author": ["D. Stowell", "D. Giannoulis", "E. Benetos", "M. Lagrange", "M.D. Plumbley"], "venue": "IEEE Transactions on Multimedia, vol. 17, no. 10, pp. 1733\u20131746, 2015.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2015}, {"title": "Multimedia information retrieval: content-based information retrieval from large text and audio databases", "author": ["P. Sch\u00e4uble"], "venue": "Springer Science & Business Media,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "A multimedia retrieval framework based on semi-supervised ranking and relevance feedback", "author": ["Y. Yang", "F. Nie", "D. Xu", "J. Luo", "Y. Zhuang", "Y. Pan"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 34, pp. 723\u2013742, 2012.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "Content-based multimedia information retrieval: State of the art and challenges", "author": ["M.S. Lew", "N. Sebe", "C. Djeraba", "R. Jain"], "venue": "ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM), vol. 2, no. 1, pp. 1\u201319, 2006.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2006}, {"title": "Soundevent recognition with a companion humanoid", "author": ["M. Janvier", "X. Alameda-Pineda", "L. Girinz", "R. Horaud"], "venue": "2012 12th IEEE- RAS International Conference on Humanoid Robots (Humanoids 2012). IEEE, 2012, pp. 104\u2013111.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2012}, {"title": "Sound representation and classification benchmark for domestic robots", "author": ["J. Maxime", "X. Alameda-Pineda", "L. Girin", "R. Horaud"], "venue": "2014 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2014, pp. 6285\u20136292.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}, {"title": "Scream and gunshot detection and localization for audio-surveillance systems", "author": ["G. Valenzise", "L. Gerosa", "M. Tagliasacchi", "F. Antonacci", "A. Sarti"], "venue": "Advanced Video and Signal Based Surveillance, 2007. AVSS 2007. IEEE Conference on. IEEE, 2007.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2007}, {"title": "Adaptive audio-based context recognition", "author": ["W. Dargie"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics-Part A: Systems and Humans, vol. 39, no. 4, pp. 715\u2013725, 2009.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2009}, {"title": "Realworld acoustic event detection", "author": ["X. Zhuang", "X. Zhou", "M.A. Hasegawa-Johnson", "T.S. Huang"], "venue": "Pattern Recognition Letters, vol. 31, pp. 1543\u20131551, 2010.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2010}, {"title": "Sound event detection in real life recordings using coupled matrix factorization of spectral representations and class activity annotations", "author": ["A. Mesaros", "T. Heittola", "O. Dikmen", "T. Virtanen"], "venue": "2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2015.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2015}, {"title": "Random regression forests for acoustic event detection and classification", "author": ["H. Phan", "M. Maa\u00df", "R. Mazur", "A. Mertins"], "venue": "IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol. 23, pp. 20\u201331, 2015.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2015}, {"title": "Recognition of acoustic events using deep neural networks", "author": ["O. Gencoglu", "T. Virtanen", "H. Huttunen"], "venue": "2014 22nd European Signal Processing Conference (EUSIPCO). IEEE, 2014, pp. 506\u2013510.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2014}, {"title": "Detection and classification of acoustic scenes and events: an ieee aasp challenge", "author": ["D. Giannoulis", "E. Benetos", "D. Stowell", "M. Rossignol", "M. Lagrange", "M.D. Plumbley"], "venue": "2013 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics. IEEE, 2013, pp. 1\u20134.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2013}, {"title": "Tut database for acoustic scene classification and sound event detection", "author": ["A. Mesaros", "T. Heittola", "T. Virtanen"], "venue": "24th European Signal Processing Conference, vol. 2016, 2016.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2016}, {"title": "Esc: Dataset for environmental sound classification", "author": ["K.J. Piczak"], "venue": "Proceedings of the 23rd ACM International Conference on Multimedia. ACM, 2015, pp. 1015\u20131018.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2015}, {"title": "A dataset and taxonomy for urban sound research", "author": ["J. Salamon", "C. Jacoby", "J.P. Bello"], "venue": "Proceedings of the 22nd ACM international conference on Multimedia. ACM, 2014, pp. 1041\u20131044.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2014}, {"title": "Audio event detection using weakly labeled data", "author": ["A. Kumar", "B. Raj"], "venue": "24th ACM International Conference on Multimedia. ACM Multimedia, 2016.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2016}, {"title": "Weakly supervised scalable audio content analysis", "author": ["\u2014\u2014"], "venue": "2016 IEEE International Conference on Multimedia and Expo (ICME). IEEE, 2016.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2016}, {"title": "Weakly supervised object localization with multi-fold multiple instance learning", "author": ["R.G. Cinbis", "J. Verbeek", "C. Schmid"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, 2016.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2016}, {"title": "Keywords to visual categories: Multiple-instance learning forweakly supervised object categorization", "author": ["S. Vijayanarasimhan", "K. Grauman"], "venue": "Computer Vision and Pattern Recognition, 2008. CVPR 2008. IEEE Conference on. IEEE, 2008, pp. 1\u20138.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2008}, {"title": "Content-based image retrieval using multiple-instance learning", "author": ["Q. Zhang", "S.A. Goldman", "W. Yu", "J.E. Fritts"], "venue": "International Conference on Machine Learning, vol. 2. Citeseer, 2002, pp. 682\u2013689.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2002}, {"title": "Support vector machines for multiple-instance learning", "author": ["S. Andrews", "I. Tsochantaridis", "T. Hofmann"], "venue": "Advances in neural information processing systems, 2002, pp. 561\u2013568.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2002}, {"title": "Neural networks for multi-instance learning", "author": ["Z.-H. Zhou", "M.-L. Zhang"], "venue": "Proceedings of the International Conference on Intelligent Information Technology, Beijing, China, 2002, pp. 455\u2013459.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2002}, {"title": "Introduction to semi-supervised learning", "author": ["X. Zhu", "A.B. Goldberg"], "venue": "Synthesis lectures on artificial intelligence and machine learning, vol. 3, pp. 1\u2013130, 2009.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2009}, {"title": "Semi-supervised learning using gaussian fields and harmonic functions", "author": ["X. Zhu", "Z. Ghahramani", "J. Lafferty"], "venue": "International Conference on Machine Learning, 2003.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2003}, {"title": "Manifold regularization: A geometric framework for learning from labeled and unlabeled examples", "author": ["M. Belkin", "P. Niyogi", "V. Sindhwani"], "venue": "Journal of machine learning research, vol. 7, no. Nov, pp. 2399\u20132434, 2006.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2006}, {"title": "Semi-supervised support vector machines", "author": ["K. Bennett", "A. Demiriz"], "venue": "Advances in Neural Information processing systems, pp. 368\u2013 374, 1999.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1999}, {"title": "Missl: Multiple-instance semisupervised learning", "author": ["R. Rahmani", "S.A. Goldman"], "venue": "Proceedings of the 23rd international conference on Machine learning. ACM, 2006, pp. 705\u2013712.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2006}, {"title": "On the relation between multi-instance learning and semi-supervised learning", "author": ["Z.-H. Zhou", "J.-M. Xu"], "venue": "Proceedings of the 24th International Conference on Machine learning. ACM, 2007, pp. 1167\u2013 1174.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2007}, {"title": "Instance-level semisupervised multiple instance learning.", "author": ["Y. Jia", "C. Zhang"], "venue": "in AAAI,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2008}, {"title": "Kernel methods for missing variables.", "author": ["A.J. Smola", "S. Vishwanathan", "T. Hofmann"], "venue": "in AISTATS. Citeseer,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2005}, {"title": "A regularization framework for multipleinstance learning", "author": ["P.-M. Cheung", "J.T. Kwok"], "venue": "Proceedings of the 23rd International Conference on Machine learning. ACM, 2006, pp. 193\u2013200.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2006}, {"title": "Robust audio-codebooks for large-scale event detection in consumer videos", "author": ["S. Rawat", "P.F. Schulam", "S. Burger", "D. Ding", "Y. Wang", "F. Metze"], "venue": "2013.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2013}, {"title": "Features and kernels for audio event recognition", "author": ["A. Kumar", "B. Raj"], "venue": "arXiv preprint arXiv:1607.05765, 2016.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2016}], "referenceMentions": [{"referenceID": 0, "context": "Hence, detection of acoustic events and scenes have become an important research problem [1].", "startOffset": 89, "endOffset": 92}, {"referenceID": 1, "context": "These include but are not limited to content based indexing and retrieval of multimedia recordings [2], [3], [4], improving human computer (robot) interaction by making computers (robots) aware of acoustic scene or environment around it [5], [6], surveillance and monitoring application [7], audio based context recognition system [8].", "startOffset": 99, "endOffset": 102}, {"referenceID": 2, "context": "These include but are not limited to content based indexing and retrieval of multimedia recordings [2], [3], [4], improving human computer (robot) interaction by making computers (robots) aware of acoustic scene or environment around it [5], [6], surveillance and monitoring application [7], audio based context recognition system [8].", "startOffset": 104, "endOffset": 107}, {"referenceID": 3, "context": "These include but are not limited to content based indexing and retrieval of multimedia recordings [2], [3], [4], improving human computer (robot) interaction by making computers (robots) aware of acoustic scene or environment around it [5], [6], surveillance and monitoring application [7], audio based context recognition system [8].", "startOffset": 109, "endOffset": 112}, {"referenceID": 4, "context": "These include but are not limited to content based indexing and retrieval of multimedia recordings [2], [3], [4], improving human computer (robot) interaction by making computers (robots) aware of acoustic scene or environment around it [5], [6], surveillance and monitoring application [7], audio based context recognition system [8].", "startOffset": 237, "endOffset": 240}, {"referenceID": 5, "context": "These include but are not limited to content based indexing and retrieval of multimedia recordings [2], [3], [4], improving human computer (robot) interaction by making computers (robots) aware of acoustic scene or environment around it [5], [6], surveillance and monitoring application [7], audio based context recognition system [8].", "startOffset": 242, "endOffset": 245}, {"referenceID": 6, "context": "These include but are not limited to content based indexing and retrieval of multimedia recordings [2], [3], [4], improving human computer (robot) interaction by making computers (robots) aware of acoustic scene or environment around it [5], [6], surveillance and monitoring application [7], audio based context recognition system [8].", "startOffset": 287, "endOffset": 290}, {"referenceID": 7, "context": "These include but are not limited to content based indexing and retrieval of multimedia recordings [2], [3], [4], improving human computer (robot) interaction by making computers (robots) aware of acoustic scene or environment around it [5], [6], surveillance and monitoring application [7], audio based context recognition system [8].", "startOffset": 331, "endOffset": 334}, {"referenceID": 0, "context": "Over the past few years, several approaches based on different signal processing and machine learning techniques have been proposed for audio event and scene detection, such as [1], [9], [10], [11], [12] to cite a few.", "startOffset": 177, "endOffset": 180}, {"referenceID": 8, "context": "Over the past few years, several approaches based on different signal processing and machine learning techniques have been proposed for audio event and scene detection, such as [1], [9], [10], [11], [12] to cite a few.", "startOffset": 182, "endOffset": 185}, {"referenceID": 9, "context": "Over the past few years, several approaches based on different signal processing and machine learning techniques have been proposed for audio event and scene detection, such as [1], [9], [10], [11], [12] to cite a few.", "startOffset": 187, "endOffset": 191}, {"referenceID": 10, "context": "Over the past few years, several approaches based on different signal processing and machine learning techniques have been proposed for audio event and scene detection, such as [1], [9], [10], [11], [12] to cite a few.", "startOffset": 193, "endOffset": 197}, {"referenceID": 11, "context": "Over the past few years, several approaches based on different signal processing and machine learning techniques have been proposed for audio event and scene detection, such as [1], [9], [10], [11], [12] to cite a few.", "startOffset": 199, "endOffset": 203}, {"referenceID": 12, "context": "Audio event and scene detection challenges [13] (DCASE 2013), [14] (DCASE 2016) have helped in increasing the pace of audio content analysis research.", "startOffset": 43, "endOffset": 47}, {"referenceID": 13, "context": "Audio event and scene detection challenges [13] (DCASE 2013), [14] (DCASE 2016) have helped in increasing the pace of audio content analysis research.", "startOffset": 62, "endOffset": 66}, {"referenceID": 14, "context": "This can be gauged from the fact that most publicly available datasets have less than an hour of audio data for each event [15], [14], [13], [16].", "startOffset": 123, "endOffset": 127}, {"referenceID": 13, "context": "This can be gauged from the fact that most publicly available datasets have less than an hour of audio data for each event [15], [14], [13], [16].", "startOffset": 129, "endOffset": 133}, {"referenceID": 12, "context": "This can be gauged from the fact that most publicly available datasets have less than an hour of audio data for each event [15], [14], [13], [16].", "startOffset": 135, "endOffset": 139}, {"referenceID": 15, "context": "This can be gauged from the fact that most publicly available datasets have less than an hour of audio data for each event [15], [14], [13], [16].", "startOffset": 141, "endOffset": 145}, {"referenceID": 16, "context": "Recently, there have been attempts towards weakly supervised learning of audio events [17], [18].", "startOffset": 86, "endOffset": 90}, {"referenceID": 17, "context": "Recently, there have been attempts towards weakly supervised learning of audio events [17], [18].", "startOffset": 92, "endOffset": 96}, {"referenceID": 16, "context": "\u2022 The multimedia data on web contains a large amount of within-category variations [17].", "startOffset": 83, "endOffset": 87}, {"referenceID": 18, "context": "For example, multiple instance learning based weakly supervised image retrieval and visual object detection have been explored in computer vision community [19], [20], [21].", "startOffset": 156, "endOffset": 160}, {"referenceID": 19, "context": "For example, multiple instance learning based weakly supervised image retrieval and visual object detection have been explored in computer vision community [19], [20], [21].", "startOffset": 162, "endOffset": 166}, {"referenceID": 20, "context": "For example, multiple instance learning based weakly supervised image retrieval and visual object detection have been explored in computer vision community [19], [20], [21].", "startOffset": 168, "endOffset": 172}, {"referenceID": 16, "context": "[17] introduced audio event detection (AED) using weakly labeled data.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "The main idea in weakly supervised AED is that AED using weak labels can be formulated as an multiple instance learning problem [22].", "startOffset": 128, "endOffset": 132}, {"referenceID": 16, "context": "[17] used SVM (miSVM) [22] and neural network (BPMIL) [23] based MIL methods to show that AED with weak labels can be successfully done.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "[17] used SVM (miSVM) [22] and neural network (BPMIL) [23] based MIL methods to show that AED with weak labels can be successfully done.", "startOffset": 22, "endOffset": 26}, {"referenceID": 22, "context": "[17] used SVM (miSVM) [22] and neural network (BPMIL) [23] based MIL methods to show that AED with weak labels can be successfully done.", "startOffset": 54, "endOffset": 58}, {"referenceID": 17, "context": "In another work, [18] tries to scale AED with weak labels by proposing scalable MIL methods.", "startOffset": 17, "endOffset": 21}, {"referenceID": 23, "context": "A variety of methods for semi-supervised learning including multiple instance learning semi-supervised learning have been proposed [24], [25], [26], [27], [28], [29], [30].", "startOffset": 131, "endOffset": 135}, {"referenceID": 24, "context": "A variety of methods for semi-supervised learning including multiple instance learning semi-supervised learning have been proposed [24], [25], [26], [27], [28], [29], [30].", "startOffset": 137, "endOffset": 141}, {"referenceID": 25, "context": "A variety of methods for semi-supervised learning including multiple instance learning semi-supervised learning have been proposed [24], [25], [26], [27], [28], [29], [30].", "startOffset": 143, "endOffset": 147}, {"referenceID": 26, "context": "A variety of methods for semi-supervised learning including multiple instance learning semi-supervised learning have been proposed [24], [25], [26], [27], [28], [29], [30].", "startOffset": 149, "endOffset": 153}, {"referenceID": 27, "context": "A variety of methods for semi-supervised learning including multiple instance learning semi-supervised learning have been proposed [24], [25], [26], [27], [28], [29], [30].", "startOffset": 155, "endOffset": 159}, {"referenceID": 28, "context": "A variety of methods for semi-supervised learning including multiple instance learning semi-supervised learning have been proposed [24], [25], [26], [27], [28], [29], [30].", "startOffset": 161, "endOffset": 165}, {"referenceID": 29, "context": "A variety of methods for semi-supervised learning including multiple instance learning semi-supervised learning have been proposed [24], [25], [26], [27], [28], [29], [30].", "startOffset": 167, "endOffset": 171}, {"referenceID": 25, "context": "In this work, we adopt one of the most popular method for semi-supervised learning, manifold regularization on graphs [26] for SWSL.", "startOffset": 118, "endOffset": 122}, {"referenceID": 25, "context": "A particularly well known method for semisupervised learning is manifold regularization on graphs [26].", "startOffset": 98, "endOffset": 102}, {"referenceID": 23, "context": "In this paper we assume kNN graph [24] where a vertex xi is connected to another vertex xj by a non-zero weight wij if xi is among the knearest neighbour of xj and vice versa.", "startOffset": 34, "endOffset": 38}, {"referenceID": 25, "context": "The intrinsic norm ||f ||I is estimated using the graph laplacian matrix L by ||f ||I = 1 N fLf [26].", "startOffset": 96, "endOffset": 100}, {"referenceID": 30, "context": "Convex Concave Procedure (CCCP) [32] is a well known method of sequential convex programming to handle problems like this.", "startOffset": 32, "endOffset": 36}, {"referenceID": 31, "context": "be defined as [33]", "startOffset": 14, "endOffset": 18}, {"referenceID": 0, "context": "Several acoustic feature representations for audio event or scene detection has been proposed [1].", "startOffset": 94, "endOffset": 97}, {"referenceID": 17, "context": "In this work we use the Gaussian Mixture Model (GMM) based histogram characterization of audio segments which has been used in previous weakly supervised audio event detection works [18],[17].", "startOffset": 182, "endOffset": 186}, {"referenceID": 16, "context": "In this work we use the Gaussian Mixture Model (GMM) based histogram characterization of audio segments which has been used in previous weakly supervised audio event detection works [18],[17].", "startOffset": 187, "endOffset": 191}, {"referenceID": 21, "context": "For weakly supervised learning we use miSVM approach [22].", "startOffset": 53, "endOffset": 57}, {"referenceID": 16, "context": "miSVM has also been used in previous weakly supervised audio event detection work [17].", "startOffset": 82, "endOffset": 86}, {"referenceID": 32, "context": "Exponential Chi-square (\u03c7) kernels in form of exp(\u2212\u03b3d(x, y)) have been known to work remarkably well with histogram features, including for detection of acoustic concepts [34][35].", "startOffset": 171, "endOffset": 175}, {"referenceID": 33, "context": "Exponential Chi-square (\u03c7) kernels in form of exp(\u2212\u03b3d(x, y)) have been known to work remarkably well with histogram features, including for detection of acoustic concepts [34][35].", "startOffset": 175, "endOffset": 179}, {"referenceID": 14, "context": "The events are part of ESC-10 [15] dataset which provides us strongly labeled data for these events.", "startOffset": 30, "endOffset": 34}, {"referenceID": 13, "context": "We work with a toal of 15 acoustic scenes from DCASE [14] dataset, which is also source of our strongly labeled data.", "startOffset": 53, "endOffset": 57}], "year": 2017, "abstractText": "In this paper we propose a novel learning framework called Supervised and Weakly Supervised Learning where the goal is to learn simultaneously from weakly and strongly labeled data. Strongly labeled data can be simply understood as fully supervised data where all labeled instances are available. In weakly supervised learning only data is weakly labeled which prevents one from directly applying supervised learning methods. Our proposed framework is motivated by the fact that a small amount of strongly labeled data can give considerable improvement over only weakly supervised learning. The primary problem domain focus of this paper is acoustic event and scene detection in audio recordings. We first propose a naive formulation for leveraging labeled data in both forms. We then propose a more general framework for Supervised and Weakly Supervised Learning (SWSL). Based on this general framework, we propose a graph based approach for SWSL. Our main method is based on manifold regularization on graphs in which we show that the unified learning can be formulated as a constraint optimization problem which can be solved by iterative concave-convex procedure (CCCP). Our experiments show that our proposed framework can address several concerns of audio content analysis using weakly labeled data.", "creator": "LaTeX with hyperref package"}}}