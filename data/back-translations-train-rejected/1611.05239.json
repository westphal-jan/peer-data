{"id": "1611.05239", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Nov-2016", "title": "How to do lexical quality estimation of a large OCRed historical Finnish newspaper collection with scarce resources", "abstract": "The National Library of Finland has digitized the historical newspapers published in Finland between 1771 and 1910. This collection contains approximately 1.95 million pages in Finnish and Swedish. Finnish part of the collection consists of about 2.40 billion words. The National Library's Digital Collections are offered via the digi.kansalliskirjasto.fi web service, also known as Digi. Part of the newspaper material (from 1771 to 1874) is also available freely downloadable in The Language Bank of Finland provided by the FINCLARIN consortium. The collection can also be accessed through the Korp environment that has been developed by Spr{\\aa}kbanken at the University of Gothenburg and extended by FINCLARIN team at the University of Helsinki to provide concordances of text resources. A Cranfield style information retrieval test collection has also been produced out of a small part of the Digi newspaper material at the University of Tampere.", "histories": [["v1", "Wed, 16 Nov 2016 12:04:19 GMT  (517kb)", "http://arxiv.org/abs/1611.05239v1", "24 pages, 6 tables, 6 figures"]], "COMMENTS": "24 pages, 6 tables, 6 figures", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["kimmo kettunen", "tuula p\\\"a\\\"akk\\\"onen"], "accepted": false, "id": "1611.05239"}, "pdf": {"name": "1611.05239.pdf", "metadata": {"source": "CRF", "title": "How to do lexical quality estimation of a large OCRed historical Finnish newspaper collection with scarce resources", "authors": ["Kimmo Kettunen", "Tuula P\u00e4\u00e4kk\u00f6nen"], "emails": ["kimmo.kettunen@helsinki.fi,", "tuula.paakkonen@helsinki.fi"], "sections": [{"heading": null, "text": "This year it is more than ever before in the history of the city, where it is so far that it is a place, where it is a place, where it is a place."}, {"heading": "N of word", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "1K 134 13.4 % 120 12 % 790 710 542 33.1 %", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "1 M 563 130 56.3 % 577 974 57. 8 % 2 043 976 151 85.6 %", "text": "For the sake of simplicity, we have analyzed the words only at the token level with FINTWOL, and the figures are shown in Table 5."}, {"heading": "1K 790 710 542 61 170 210 7.7 %", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "1 M 2 043 976 151 427 214 868 20.9 %", "text": "The data in Tables 4 and 5 show that the 1M of the most common words are of quite good quality. At the token level, only about 21% of them are not recognized by FINTWOL, at type level the percentage is about 58%. The bottom line of Table 5 is that 1.62 G of the tokens of 1 M of the most common word types are recognized. From the total data, this is 67.6%. Thus, for the rest about 765 M of the tokens, the recognition rate is very low, only 30 M of them are recognized.After analyzing the quality of the top of the frequency list of the most common word types, we have to check the least common end of the data. Frequently, with large corps, word types that occur only once in the data, so-called hapax legomena (Baayen 2001). Number of these words in the data is 145 056 481, 81.8% of the data at type level."}, {"heading": "2.1 Other considerations", "text": "In fact, the fact is that most of them will be able to be able to be able to be able to be themselves."}, {"heading": "Acknowledgements", "text": "This work is supported by the European Regional Development Fund (ERDF), Leverage from the EU, 2014-2020."}], "references": [{"title": "Word Frequency Distributions", "author": ["H. Baayen"], "venue": "On Measuring the Lexical Quality of the Web. WebQuality", "citeRegEx": "Baayen,? \\Q2001\\E", "shortCiteRegEx": "Baayen", "year": 2001}, {"title": "A Nordic Digital Newspaper Library", "author": ["Bremer-Laamanen", "M-L"], "venue": "International Preservation News", "citeRegEx": "Bremer.Laamanen and M.L.,? \\Q2001\\E", "shortCiteRegEx": "Bremer.Laamanen and M.L.", "year": 2001}, {"title": "Reducing OCR Errors in Gothic-Script Documents", "author": ["L. Furrer", "M. Volk"], "venue": "In Proceedings of Language Technologies for Digital Humanities and Cultural Heritage Workshop,", "citeRegEx": "Furrer and Volk,? \\Q2011\\E", "shortCiteRegEx": "Furrer and Volk", "year": 2011}, {"title": "A \u201cquick and dirty\u201d website data quality indicator. In The 2nd ACM workshop on Information credibility on the Web (WICOW \u201908), (pp. 43\u201346)", "author": ["I.A. Gelman", "A.L. Barletta"], "venue": "Holley, R", "citeRegEx": "Gelman and Barletta,? \\Q2008\\E", "shortCiteRegEx": "Gelman and Barletta", "year": 2008}, {"title": "Digitoitujen kulttuuriperint\u00f6aineistojen tutkimusk\u00e4ytt\u00f6 ja tutkijat", "author": ["T. H\u00f6ltt\u00e4"], "venue": "M. Sc. thesis (in Finnish),", "citeRegEx": "H\u00f6ltt\u00e4,? \\Q2016\\E", "shortCiteRegEx": "H\u00f6ltt\u00e4", "year": 2016}, {"title": "The TREC-5 Confusion Track: Comparing Retrieval Methods for Scanned Texts", "author": ["P.B. Kantor", "E.M. Voorhees"], "venue": "Journal of the Association for Information Science and Technology,", "citeRegEx": "Kantor and Voorhees,? \\Q2000\\E", "shortCiteRegEx": "Kantor and Voorhees", "year": 2000}, {"title": "Measuring Lexical Quality of a Historical Finnish Newspaper Collection \u2013 Analysis of Garbled OCR Data with Basic Language Technology Tools and Means", "author": ["T. P\u00e4\u00e4kk\u00f6nen"], "venue": "Digital Libraries - IRCDL 2015, Bozen-Bolzano,", "citeRegEx": "Kettunen and P\u00e4\u00e4kk\u00f6nen,? \\Q2015\\E", "shortCiteRegEx": "Kettunen and P\u00e4\u00e4kk\u00f6nen", "year": 2015}, {"title": "The Current State-of-art in Newspaper Digitization", "author": ["A. Kilgariff"], "venue": "Comparing Corpora. International Journal of Corpus Linguistics,", "citeRegEx": "Kilgariff,? \\Q2001\\E", "shortCiteRegEx": "Kilgariff", "year": 2001}, {"title": "Lounela (eds.): Genreanalyysi \u2013 tekstilajitutkimuksen k\u00e4yt\u00e4nt\u00f6\u00e4, s. 308\u2013312. Kotimaisten kielten keskuksen verkkojulkaisuja 29. Helsinki: Kotimaisten kielten keskus", "author": ["Eero Voutilainen", "Petri Lauerma", "Ulla Tiilil\u00e4", "Mikko"], "venue": "CLEF", "citeRegEx": "Voutilainen et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Voutilainen et al\\.", "year": 2010}, {"title": "Information retrieval can cope with many errors. Information Retrieval, 3(3):189\u2013216", "author": ["E. Mittendorf", "P. Sch\u00e4uble"], "venue": "Niklas, K", "citeRegEx": "Mittendorf and Sch\u00e4uble,? \\Q2000\\E", "shortCiteRegEx": "Mittendorf and Sch\u00e4uble", "year": 2000}, {"title": "Unsupervised profiling of OCRed historical documents", "author": ["U. Reffle", "C. Ringlstetter"], "venue": "Pattern Recognition,", "citeRegEx": "Reffle and Ringlstetter,? \\Q2013\\E", "shortCiteRegEx": "Reffle and Ringlstetter", "year": 2013}, {"title": "Orthographic Errors in Web Pages: Toward Cleaner Web Corpora", "author": ["C. Ringlstetter", "K. Schulz", "S. Mihanov"], "venue": "Computational Linguistics", "citeRegEx": "Ringlstetter et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Ringlstetter et al\\.", "year": 2006}, {"title": "Evaluation of Model-Based Retrieval Effectiveness with OCR Text", "author": ["K. Taghva", "J. Borsack", "A. Condit"], "venue": "OCR Quality on the Use of Digitized Historical Newspapers. Digital Humanitites Quarterly,", "citeRegEx": "Taghva et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Taghva et al\\.", "year": 1996}, {"title": "Strategies for reducing and correcting OCR errors", "author": ["M. Volk", "L. Furrer", "R. Sennrich"], "venue": "Language Technology for Cultural Heritage (pp. 3\u201322)", "citeRegEx": "Volk et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Volk et al\\.", "year": 2011}], "referenceMentions": [{"referenceID": 4, "context": "The web service is used, for example, by genealogists, heritage societies, researchers, and history enthusiast laymen (H\u00f6ltt\u00e4, 2016).", "startOffset": 118, "endOffset": 132}, {"referenceID": 2, "context": "It is well known that the typeface is difficult to recognize for OCR software (Holley 2008; Furrer and Volk 2011; Volk et al. 2011).", "startOffset": 78, "endOffset": 131}, {"referenceID": 13, "context": "It is well known that the typeface is difficult to recognize for OCR software (Holley 2008; Furrer and Volk 2011; Volk et al. 2011).", "startOffset": 78, "endOffset": 131}, {"referenceID": 3, "context": "Baeza-Yates and Rello (2012) suggest a simple spelling error based look-up method to evaluate lexical quality of web content, based on the original idea of Gelman and Barletta (2008). We believe that this method might also be useful in analysis of our data, but we are not able to discuss its possible use at present.", "startOffset": 156, "endOffset": 183}, {"referenceID": 10, "context": "System described in Reffle and Ringlstetter (2013) may be suitable, but its availability is unknown.", "startOffset": 20, "endOffset": 51}, {"referenceID": 10, "context": "System described in Reffle and Ringlstetter (2013) may be suitable, but its availability is unknown. 6 http://www2.lingsoft.fi/doc/fintwol/; We use FINTWOL\u2019s version 1999/12/20. 7 https://github.com/flammie/omorfi; We use omorfi-analyse version 0.1, dated 2012. 8 A statistical lemmatizer described in Loponen and J\u00e4rvelin (2010) might also be suitable for our purposes, but unfortunately this software is not available.", "startOffset": 20, "endOffset": 330}, {"referenceID": 0, "context": "Common to large corpuses are word form types that occur only once in the data, so called hapax legomena (Baayen 2001).", "startOffset": 104, "endOffset": 117}, {"referenceID": 0, "context": "It is apparent that we need to be cautious in conclusions, as different data are of different sizes which may cause errors in estimations (Baayen 2001; Kilgariff 2001).", "startOffset": 138, "endOffset": 167}, {"referenceID": 7, "context": "It is apparent that we need to be cautious in conclusions, as different data are of different sizes which may cause errors in estimations (Baayen 2001; Kilgariff 2001).", "startOffset": 138, "endOffset": 167}, {"referenceID": 12, "context": "One of the most important effects of poor OCR quality \u2013 besides worse readability and comprehensibility - is worse on-line searchability of the documents in the collections (Taghva et al. 1996).", "startOffset": 173, "endOffset": 193}, {"referenceID": 5, "context": "Same and larger level of decrease in retrieval effectiveness is shown also in results of the TREC-5\u2019s confusion track (Kantor and Voorhees 2000).", "startOffset": 118, "endOffset": 144}, {"referenceID": 10, "context": "One of the most important effects of poor OCR quality \u2013 besides worse readability and comprehensibility - is worse on-line searchability of the documents in the collections (Taghva et al. 1996). In a recent study Savoy and Naji (2011), for example, showed how retrieval performance decreases with OCR error corrupted documents quite severely.", "startOffset": 174, "endOffset": 235}, {"referenceID": 5, "context": "Same and larger level of decrease in retrieval effectiveness is shown also in results of the TREC-5\u2019s confusion track (Kantor and Voorhees 2000). The effect of errors is not clear cut, however. Tanner et al. (2009) suggest that word accuracy rates less than 80 % are harmful for search, but when the word accuracy is over 80 %, fuzzy search capabilities of search engines should manage the problems caused by word errors.", "startOffset": 119, "endOffset": 215}, {"referenceID": 5, "context": "Same and larger level of decrease in retrieval effectiveness is shown also in results of the TREC-5\u2019s confusion track (Kantor and Voorhees 2000). The effect of errors is not clear cut, however. Tanner et al. (2009) suggest that word accuracy rates less than 80 % are harmful for search, but when the word accuracy is over 80 %, fuzzy search capabilities of search engines should manage the problems caused by word errors. Mittendorf and Sch\u00e4uble\u2019s (2000) probabilistic model for data corruption seems to support this.", "startOffset": 119, "endOffset": 455}, {"referenceID": 5, "context": "Same and larger level of decrease in retrieval effectiveness is shown also in results of the TREC-5\u2019s confusion track (Kantor and Voorhees 2000). The effect of errors is not clear cut, however. Tanner et al. (2009) suggest that word accuracy rates less than 80 % are harmful for search, but when the word accuracy is over 80 %, fuzzy search capabilities of search engines should manage the problems caused by word errors. Mittendorf and Sch\u00e4uble\u2019s (2000) probabilistic model for data corruption seems to support this. Information retrieval is robust even with corrupted data, but IR works best with longer documents and long queries. Empirical results of J\u00e4rvelin et al. (2015) with the Finnish historical newspaper search collection, for example, show that even impractically heavy usage of fuzzy matching will help only to a limited degree in search of a low quality OCRed newspaper collection, when short queries and their query expansions are used.", "startOffset": 119, "endOffset": 678}, {"referenceID": 5, "context": "Same and larger level of decrease in retrieval effectiveness is shown also in results of the TREC-5\u2019s confusion track (Kantor and Voorhees 2000). The effect of errors is not clear cut, however. Tanner et al. (2009) suggest that word accuracy rates less than 80 % are harmful for search, but when the word accuracy is over 80 %, fuzzy search capabilities of search engines should manage the problems caused by word errors. Mittendorf and Sch\u00e4uble\u2019s (2000) probabilistic model for data corruption seems to support this. Information retrieval is robust even with corrupted data, but IR works best with longer documents and long queries. Empirical results of J\u00e4rvelin et al. (2015) with the Finnish historical newspaper search collection, for example, show that even impractically heavy usage of fuzzy matching will help only to a limited degree in search of a low quality OCRed newspaper collection, when short queries and their query expansions are used. Evershed and Fitch (2014), on the other hand, show that if OCR word errors are corrected and word error rate decreased with about 10 % units, recall in document retrieval may have about 9\u201310 % unit boost with historical OCRed English documents.", "startOffset": 119, "endOffset": 979}, {"referenceID": 4, "context": "Users of the Digi collection have complained about the poor OCR of the collection relatively little, but some of them have reported curious search results and been annoyed by the OCR quality (H\u00f6ltt\u00e4, 2016; Kettunen, P\u00e4\u00e4kk\u00f6nen, Koistinen, 2016).", "startOffset": 191, "endOffset": 243}, {"referenceID": 12, "context": "Besides retrieval performance effects poor OCR quality has an effect on ranking of the documents (Taghva et al. 1996; Mittendorf and Sch\u00e4uble 2000).", "startOffset": 97, "endOffset": 147}, {"referenceID": 9, "context": "Besides retrieval performance effects poor OCR quality has an effect on ranking of the documents (Taghva et al. 1996; Mittendorf and Sch\u00e4uble 2000).", "startOffset": 97, "endOffset": 147}, {"referenceID": 9, "context": "1996; Mittendorf and Sch\u00e4uble 2000). In practice these kinds of drops in retrieval and ranking performance mean that the user will lose relevant documents: either they are not found at all by the search engine or the documents are so low in the ranking list that the user may skip them. Some examples of this in the work of digital humanities scholars are discussed e.g. in Traub et al. (2015).", "startOffset": 6, "endOffset": 394}], "year": 2016, "abstractText": "Digitization of both hand-written and printed historical material during the last 10\u201315 years has been an ongoing academic and non-academic industry. Most probably this activity will only increase in the current Digital Humanities era. As a result of past and current work we have lots of digital historical document collections available and will have more of them in the future. The National Library of Finland has digitized a large proportion of the historical newspapers published in Finland between 1771 and 1910 (Bremer-Laamanen 2001, 2005, 2014; Kettunen et al. 2014). This collection contains approximately 1.95 million pages in Finnish and Swedish. Finnish part of the collection consists of about 2.40 billion words. The National Library\u2019s Digital Collections are offered via the digi.kansalliskirjasto.fi web service, also known as Digi. Part of the newspaper material (years 1771\u20131874) is also available freely downloadable in The Language Bank of Finland provided by the FIN-CLARIN consortium 1 . The collection can also be accessed through the Korp 2 environment that has been developed by Spr\u00e5kbanken at the University of Gothenburg and extended by FIN-CLARIN team at the University of Helsinki to provide concordances of text resources. A Cranfield style information retrieval test collection has also been produced out of a small part of the Digi newspaper material at the University of Tampere (J\u00e4rvelin et al. 2015). An open data package of the whole collection will be released during the year 2016 (P\u00e4\u00e4kk\u00f6nen et al., 2016) The web service digi.kansalliskirjasto.fi contains different material besides newspapers, including journals, and ephemera (different small prints). Recently a new service was created: it enables marking of clips and storing of them to a personal scrapbook. The user can also save links to his search keys and results in an Excel file. The web service is used, for example, by genealogists, heritage societies, researchers, and history enthusiast laymen (H\u00f6ltt\u00e4, 2016). There is also an 1 https://kitwiki.csc.fi/twiki/bin/view/FinCLARIN/KielipankkiAineistotDigilibPub 2 https://korp.csc.fi/", "creator": "Microsoft\u00ae Word 2010"}}}