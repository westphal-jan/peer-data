{"id": "1611.05377", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Nov-2016", "title": "Fully-adaptive Feature Sharing in Multi-Task Networks with Applications in Person Attribute Classification", "abstract": "Multi-task learning aims to improve generalization performance of multiple prediction tasks by appropriately sharing relevant information across them. In the context of deep neural networks, this idea is often realized by hand-designed network architectures with layers that are shared across tasks and branches that encode task-specific features. However, the space of possible multi-task deep architectures is combinatorially large and often the final architecture is arrived at by manual exploration of this space subject to designer's bias, which can be both error-prone and tedious. In this work, we propose a principled approach for designing compact multi-task deep learning architectures. Our approach starts with a thin network and dynamically widens it in a greedy manner during training using a novel criterion that promotes grouping of similar tasks together. Our Extensive evaluation on person attributes classification tasks involving facial and clothing attributes suggests that the models produced by the proposed method are fast, compact and can closely match or exceed the state-of-the-art accuracy from strong baselines by much more expensive models.", "histories": [["v1", "Wed, 16 Nov 2016 17:31:44 GMT  (767kb,D)", "http://arxiv.org/abs/1611.05377v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["yongxi lu", "abhishek kumar", "shuangfei zhai", "yu cheng", "tara javidi", "rogerio feris"], "accepted": false, "id": "1611.05377"}, "pdf": {"name": "1611.05377.pdf", "metadata": {"source": "CRF", "title": "Fully-adaptive Feature Sharing in Multi-Task Networks with Applications in Person Attribute Classification", "authors": ["Yongxi Lu", "UC San Diego", "Abhishek Kumar", "Shuangfei Zhai", "Yu Cheng", "Tara Javidi", "Rogerio Feris"], "emails": ["yol070@ucsd.edu", "abhishk@us.ibm.com", "szhai2@binghamton.edu", "chengyu@us.ibm.com", "tjavidi@eng.ucsd.edu", "rsferis@us.ibm.com"], "sections": [{"heading": "1. Introduction", "text": "We possess a natural yet remarkable ability to seamlessly transfer and disseminate knowledge across multiple related areas in which only two layers are shared while drawing conclusions about a given task. However, effective mechanisms for sharing relevant information across multiple predictive tasks (referred to as multi-task learning) are equally important for significant advances in machine intelligence. In this paper, we propose a novel approach for multi-task learning in the context of deep neural networks for computer vision tasks. We specifically aim at two desirable features of the proposed approach: (i) automatic learning of multi-task tectures based on branching, (ii) selective sharing between tasks with automated learning of whom we want to share, in order to have our multi-task models to have low memory and low latency during prediction (moving forward through the network).A natural approach for sharing the specific tasks is to allow us to partially parameo-divide the respective tasks across the network."}, {"heading": "2. Related Work", "text": "In fact, it is so that most of them are able to survive themselves without there being a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is"}, {"heading": "3. Methodology", "text": "Let's parameterise the linear operations in a layer l of the network. Let xl \"Rcl\" be the input vector of the layer l, and yl \"Rcl + 1\" is the output vector. In other words, the output of a layer is the input to the layer over. In vision applications, feature maps are often considered three-way tensors, and one should think of xl and yl as appropriately vectorized versions of the input and output function tensors. The functional form of the network is a series of compilations within a layer linking the lowest (output) layer. The compilation within the layer (for both revolutionary and fully connected layers) can be parameterized by a simple linear operation."}, {"heading": "3.1. Thin Networks and Filter Selection using Simultaneous Orthogonal Matching Pursuit", "text": "The initial model we are using is a thin version of the VGG-16 network. It has the same structure as VGG-16 except for the widths at each level. We are experimenting with a series of thin models called thin \u03c9 models. However, the width of a revolutionary layer of the thin \u03c9 model is the minimum between \u03c9 and the width of the corresponding layer of the VGG-16 network. The width of the fully bonded layers is set at 2\u043c. We will call the \"thin film factor.\" Figure 1 illustrates a thin model side by side with VGG-16. The use of weights from pre-prepared models is known to accelerate the formation and improve the generalization of the model. However, the standard method of direct copy is only suitable if the source and the target networks have the same architecture (at least for most of the layers). Our assumption of a thin initial model formats the use of the direct copy because there is a mismatch in the dimension of the dimension."}, {"heading": "3.2. Top-Down Layer-wise Model Widening", "text": "At the core of our training algorithm is a process that gradually expands the current design in layers. Let's introduce the concept of a \"junction.\" A junction is a point where the network splits into two or more independent sub-networks. We will, of course, refer to such a sub-network as a \"branch.\" Each branch leads to a subset of prediction tasks that are performed by the entire network. In the context of the person attributes classification, each prediction is a sigmoid unit that provides a standardized advance of confidence about the existence of an attribute. We propose to extend the network only on these junctions. Formally, we consider a crossing of layer l with input xl and d outputs {yli} di = 1. Note that each output is the input to one of the d-top sub-networks. Similar to Equation 1, the within the layer calculation asyli = \u03c3l (P (W li) xl) di = d [d-outputs]."}, {"heading": "3.3. Task Grouping based on the Probability of Concurrently Simple or Difficult Examples", "text": "For similar tasks, the situation is the opposite. We observe that when a simple example of one task is typically a difficult example of another, intuitively a different set of filters is required for each task to make it mathematically concrete, we need to define the affinity between a pair of tasks as the probability of simultaneously observing simple or difficult examples of the underlying tasks from a random sample of training data. To make it mathematically concrete, we need to define the notion of a \"difficult\" and a \"simple\" example. Consider an arbitrary attribute classification task i. Denote predicting the task for example n as sni, and the error margin as mni = | tni \u2212 sni \u2212 sni the binary term for task i in the previous discussion, it seems natural to set a fixed threshold on mni to decide whether an example n is easy or difficult."}, {"heading": "3.4. Complexity-aware Width Selection", "text": "The number of branches to be created determines how much wider the network becomes after expansion, a number determined by a loss function that balances the complexity and separation of different tasks into different branches. For each number of clusters 1 \u2264 d \u2264 c, we perform spectral clustering to obtain a grouping function gd: [d] \u2192 [c], which associates the newly created branches with the c old branches by one layer above it. On layer l, the loss function is given by Ll (gd) = (d \u2212 1) L02pl + \u03b1Ls (gd) (9), where (d \u2212 1) L02pl is a penalty term for generating branches on layer l, Ls (gd) is a penalty for separation. pl is defined as the number of bundling layers above layer l and L0 is the unit cost for generating branches. The first term grows linearly with the number of branches, with a scale it is too expensive to generate."}, {"heading": "4. Experiments", "text": "We use CelebA [24] data sets for classifying facial attributes and Deepfashion [23] for classifying clothing categories. CelebA consists of images of celebrities labeled with 40 attribute classes. Most images include the upper body region in addition to the face. Our models are rated based on the standard classification accuracy (average of classification accuracy across all attribute classes) and the top 10 retrieval rate (percentage of correctly retrieved attributes from the top 10 prediction values for each image). Top 10 is used as this data set averages about 9 positive face attributes per image. DeepFashion is rich with 50 categories of clothing labeled such as \"shorts,\" \"jeans,\" \"coats,\" etc. (the labels are mutually exclusive). Faces are often visible in these images."}, {"heading": "4.1. Comparison with the State of the art", "text": "We establish three baseline lines: the first baseline is a VGG-16 model initialized by a model trained by the imdb-wiki gender classification [30]; the second baseline is a low-factoring model at all levels. This model was also initialized by the imdb-wiki gender model, but the initialization is done by truncated Singular Value Decomposition (SVD) [7]. The number of base filters is 8-16-32-64-64 for the revolutionary layers, 64-64 for the two fully connected layers, and 16 for the output layer. The third is a thin model initialized using the SOMP initialization method introduced in Section 3.1, using the same pre-trained model. Our VGG-16 baseline is stronger than any previously reported methods, while the low baseline is closely aligned with the state of the art and more compact."}, {"heading": "4.2. Cross-domain Training of Joint Person Attribute Network", "text": "To test the capability of our approach to cross-domain tasks, we train a network that collectively predicts facial and clothing characteristics, and train the model by connecting the two training groups. Note that the CelebA dataset is not commented on with garment labels, and the deepfashion dataset is not commented on with facial markings. To supplement the annotations for both datasets, we use the predictions of the VGG-16 base models as soft training targets. We show that the common model is state-of-the-art for both face and clothing tasks, which is a much more efficient combined model than two separate models. Comparison between the common models and basic lines is shown in Tables 1 and 2."}, {"heading": "4.3. Visual Validation of Task Grouping", "text": "Figure 3 shows the actual task grouping in the branch 32 2.0 model that is trained on CelebA. Grouping is often very intuitive, such as \"5-o-clock Shadow,\" \"Bushy Eyebrows,\" and \"No Beard,\" which all describe some forms of facial hair. \"Attractive\" and \"Receding Hairline\" are added to the cluster of \"Heavy Make-up,\" \"Pale Skin,\" and \"Wearing Lipstick\" at fc6, probably because they all describe age characteristics, which is particularly interesting because no human intervention is involved in model making."}, {"heading": "4.4. Ablation Studies", "text": "What are the advantages of grouping similar tasks? We mix the correspondence between the educational objectives and the network output for CelebA's Branch 32 2.0 model and report on the decrease in accuracy for each task. Both randomly and manually, the mixing is tested, but we report only on the mixing because they are similar. Specifically, for manual mixing, we choose a new grouping of tasks so that the network separates many tasks that are originally in the same industry. Figure 4 summarizes our results. Clearly, the task is grouped by similarity and improves accuracy for most tasks. Closer investigation yields other interesting observations. The three tasks that actually benefit from regrouping (as opposed to most of the tasks), namely \"wavy hair,\" \"wearing necklaces\" and \"pointed noses,\" are all from the industry with the largest number of tasks."}, {"heading": "5. Conclusion", "text": "We have proposed a novel method for learning the structure of compact multi-task deep neural networks. Our method starts with a thin network model and expands it during training with a novel multi-round branching mechanism that determines with whom each task shares characteristics in each network layer, punishing the complexity of the model. We showed convincing results of the proposed approach to the problem of classifying personal attributes. As for future work, we plan to adapt the approach to other related problems, such as gradual learning and domain adaptation."}], "references": [{"title": "Network of experts for large-scale image categorization", "author": ["K. Ahmed", "M.H. Baig", "L. Torresani"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2016}, {"title": "Dynamic capacity networks", "author": ["A. Almahairi", "N. Ballas", "T. Cooijmans", "Y. Zheng", "H. Larochelle", "A. Courville"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2016}, {"title": "Integrated perception with recurrent multi-task neural networks", "author": ["H. Bilen", "A. Vedaldi"], "venue": "In NIPS,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2016}, {"title": "Multi-task learning", "author": ["R. Caruana"], "venue": "Machine Learning Journal,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1997}, {"title": "Deep domain adaptation for describing people based on fine-grained clothing attributes", "author": ["Q. Chen", "J. Huang", "R. Feris", "L.M. Brown", "J. Dong", "S. Yan"], "venue": "In CVPR,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "An exploration of parameter redundancy in deep networks with circulant projections", "author": ["Y. Cheng", "F. Yu", "R. Feris", "S. Kumar", "A. Choudhary", "S.F. Chang"], "venue": "In ICCV,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "Exploiting linear structure within convolutional networks for efficient evaluation", "author": ["E.L. Denton", "W. Zaremba", "J. Bruna", "Y. LeCun", "R. Fergus"], "venue": "In NIPS,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "Attributebased people search: Lessons learnt from a practical surveillance system", "author": ["R. Feris", "R. Bobbitt", "L. Brown", "S. Pankanti"], "venue": "In ICMR,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}, {"title": "Tamp: A library for compact deep neural networks with structured matrices", "author": ["B. Gong", "B. Jou", "F. Yu", "S.-F. Chang"], "venue": "In ACM Multimedia,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2016}, {"title": "Deep compression: Compressing deep neural network with pruning, trained quantization and huffman coding", "author": ["S. Han", "H. Mao", "W.J. Dally"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2016}, {"title": "Deep residual learning for image recognition", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2016}, {"title": "Distilling the knowledge in a neural network", "author": ["G. Hinton", "O. Vinyals", "J. Dean"], "venue": "In arXiv preprint arXiv:1503.02531,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2015}, {"title": "Cross-domain image retrieval with a dual attribute-aware ranking network", "author": ["J. Huang", "R.S. Feris", "Q. Chen", "S. Yan"], "venue": "In ICCV,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2015}, {"title": "Training cnns with low-rank filters for efficient image classification", "author": ["Y. Ioannou", "D. Robertson", "J. Shotton", "R. Cipolla", "A. Criminisi"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2016}, {"title": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "author": ["S. Ioffe", "C. Szegedy"], "venue": "arXiv preprint arXiv:1502.03167,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2015}, {"title": "Clustered multi-task learning: A convex formulation", "author": ["L. Jacob", "J.-p. Vert", "F.R. Bach"], "venue": "In NIPS,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2009}, {"title": "Deep cross residual learning for multi-task visual recognition", "author": ["B. Jou", "S.F. Chang"], "venue": "In ACM Multimedia,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2016}, {"title": "Learning with whom to share in multi-task feature learning", "author": ["Z. Kang", "K. Grauman", "F. Sha"], "venue": "In ICML,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2011}, {"title": "Ubernet: Training a universal cnn for low-, mid- , and high- level vision using diverse datasets and limited memory", "author": ["I. Kokkinos"], "venue": "In arXiv preprint arXiv:1609.02132,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2016}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "In NIPS,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2012}, {"title": "Learning task grouping and overlap in multi-task", "author": ["A. Kumar", "H. Daume III"], "venue": "In ICML,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2012}, {"title": "Wow! you are so beautiful today", "author": ["L. Liu", "J. Xing", "S. Liu", "H. Xu", "X. Zhou", "S. Yan"], "venue": "ACM Transactions on Multimedia Computing, Communications, and Applications,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2014}, {"title": "Deepfashion: Powering robust clothes recognition and retrieval with rich annotations", "author": ["Z. Liu", "P. Luo", "S. Qiu", "X. Wang", "X. Tang"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2016}, {"title": "Deep learning face attributes in the wild", "author": ["Z. Liu", "P. Luo", "X. Wang", "X. Tang"], "venue": "In ICCV,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2015}, {"title": "Crossstitch networks for multi-task learning", "author": ["I. Misra", "A. Shrivastava", "A. Gupta", "M. Hebert"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2016}, {"title": "Flexible modeling of latent task structures in multitask learning", "author": ["A. Passos", "P. Rai", "J. Wainer", "H. Daume III"], "venue": "arXiv preprint arXiv:1206.6486,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2012}, {"title": "Channel-level acceleration of deep face representations", "author": ["A. Polyak", "L. Wolf"], "venue": "IEEE Access,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2015}, {"title": "Hyperface: A deep multi-task learning framework for face detection, landmark localization, pose estimation, and gender recognition", "author": ["R. Ranjan", "V. Patel", "R. Chellappa"], "venue": "In arXiv preprint arXiv:1603.01249,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2016}, {"title": "Fitnets: Hints for thin deep nets", "author": ["A. Romero", "N. Ballas", "S.E. Kahou", "A. Chassang", "C. Gatta", "Y. Bengio"], "venue": "arXiv preprint arXiv:1412.6550,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2014}, {"title": "Deep expectation of real and apparent age from a single image without facial landmarks", "author": ["R. Rothe", "R. Timofte", "L.V. Gool"], "venue": "International Journal of Computer Vision (IJCV),", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2016}, {"title": "Deep expectation of real and apparent age from a single image without facial landmarks", "author": ["R. Rothe", "R. Timofte", "L.V. Gool"], "venue": "International Journal of Computer Vision (IJCV),", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2016}, {"title": "Moon: A mixed objective optimization network for the recognition of facial attributes", "author": ["E. Rudd", "M. G\u00fcnther", "T. Boult"], "venue": null, "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2016}, {"title": "Low-rank matrix factorization for deep neural network training with high-dimensional output targets", "author": ["T.N. Sainath", "B. Kingsbury", "V. Sindhwani", "E. Arisoy", "B. Ramabhadran"], "venue": "In ICASSP,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2013}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["K. Simonyan", "A. Zisserman"], "venue": null, "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2015}, {"title": "Structured transforms for small-footprint deep learning", "author": ["V. Sindhwani", "T. Sainath", "S. Kumar"], "venue": "In NIPS,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2015}, {"title": "Deep attributes driven multi-camera person re-identification", "author": ["C. Su", "S. Zhang", "J. Xing", "W. Gao", "Q. Tian"], "venue": null, "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2016}, {"title": "Person attribute recognition with a jointly-trained holistic cnn model", "author": ["P. Sudowe", "H. Spitzer", "B. Leibe"], "venue": "In ICCV ChaLearn Looking at People Workshop,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2015}, {"title": "Going deeper with convolutions", "author": ["C. Szegedy", "W. Liu", "Y. Jia", "P. Sermanet", "S. Reed", "D. Anguelov", "D. Erhan", "V. Vanhoucke", "A. Rabinovich"], "venue": "In CVPR,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2015}, {"title": "Convolutional neural networks with low-rank regularization", "author": ["C. Tai", "T. Xiao", "X. Wang"], "venue": "ICLR, 2016", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2016}, {"title": "Learning to learn", "author": ["S. Thrun", "L. Pratt"], "venue": "Kluwer Academic Publishers,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 1998}, {"title": "Algorithms for simultaneous sparse approximation. part ii: Convex relaxation", "author": ["J.A. Tropp"], "venue": "Signal Processing,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2006}, {"title": "Algorithms for simultaneous sparse approximation. part i: Greedy pursuit", "author": ["J.A. Tropp", "A.C. Gilbert", "M.J. Strauss"], "venue": "Signal Processing,", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2006}, {"title": "Attribute-based people search in surveillance environments", "author": ["D.A. Vaquero", "R.S. Feris", "D. Tran", "L. Brown", "A. Hampapur", "M. Turk"], "venue": "In WACV,", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2009}, {"title": "Walk and learn: Facial attribute representation learning from egocentric video and contextual data", "author": ["J. Wang", "Y. Cheng", "R.S. Feris"], "venue": null, "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2016}, {"title": "Multitask learning for classification with dirichlet process priors", "author": ["Y. Xue", "X. Liao", "L. Carin", "B. Krishnapuram"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2007}, {"title": "Hd-cnn: Hierarchical deep convolutional neural network for large scale visual recognition", "author": ["Z. Yan", "H. Zhang", "R. Piramuthu", "V. Jagadeesh", "D. DeCoste", "W. Di", "Y. Yu"], "venue": "In ICCV,", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 2015}, {"title": "From facial parts responses to face detection: A deep learning approach", "author": ["S. Yang", "P. Luo", "C.-C. Loy", "X. Tang"], "venue": "In ICCV,", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 2015}, {"title": "Visualizing and understanding convolutional networks", "author": ["M.D. Zeiler", "R. Fergus"], "venue": "In ECCV,", "citeRegEx": "48", "shortCiteRegEx": "48", "year": 2014}, {"title": "Panda: Pose aligned networks for deep attribute modeling", "author": ["N. Zhang", "M. Paluri", "M. Ranzato", "T. Darrell", "L. Bourdev"], "venue": "In CVPR,", "citeRegEx": "49", "shortCiteRegEx": "49", "year": 2014}, {"title": "Learning deep representation for face alignment with auxiliary attributes", "author": ["Z. Zhang", "P. Luo", "C.C. Loy", "X. Tang"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "50", "shortCiteRegEx": "50", "year": 2016}, {"title": "Clustered multi-task learning via alternating structure optimization", "author": ["J. Zhou", "J. Chen", "J. Ye"], "venue": "In NIPS,", "citeRegEx": "51", "shortCiteRegEx": "51", "year": 2011}], "referenceMentions": [{"referenceID": 27, "context": "To avoid this, most of the multi-task deep architectures share the bottom layers till some layer l after which the sharing is blocked, resulting in task-specific sub-networks or branches beyond it [28, 17, 13].", "startOffset": 197, "endOffset": 209}, {"referenceID": 16, "context": "To avoid this, most of the multi-task deep architectures share the bottom layers till some layer l after which the sharing is blocked, resulting in task-specific sub-networks or branches beyond it [28, 17, 13].", "startOffset": 197, "endOffset": 209}, {"referenceID": 12, "context": "To avoid this, most of the multi-task deep architectures share the bottom layers till some layer l after which the sharing is blocked, resulting in task-specific sub-networks or branches beyond it [28, 17, 13].", "startOffset": 197, "endOffset": 209}, {"referenceID": 24, "context": "However, the space of such possible branching architectures is combinatorially large and current approaches largely make a decision based on limited manual exploration of this space, often biased by designer\u2019s perception of the relationship among different tasks [25].", "startOffset": 263, "endOffset": 267}, {"referenceID": 41, "context": "We also propose a method based on simultaneous orthogonal matching pursuit (SOMP) [42] for initializing a thin network from a pretrained wider network (e.", "startOffset": 82, "endOffset": 86}, {"referenceID": 23, "context": "On the CelebA dataset [24], we match the current top results on facial attribute classification (90% accuracy) with a model 90x more compact and 3x faster than the original VGG-16 model.", "startOffset": 22, "endOffset": 26}, {"referenceID": 22, "context": "We draw similar conclusions for clothing category recognition on the DeepFashion dataset [23], demonstrating that we can perform simultaneous facial and clothing attribute prediction using a single compact multi-task model, while preserving accuracy.", "startOffset": 89, "endOffset": 93}, {"referenceID": 3, "context": "There is a long history of research in multi-task learning [4, 40, 16, 21, 25].", "startOffset": 59, "endOffset": 78}, {"referenceID": 39, "context": "There is a long history of research in multi-task learning [4, 40, 16, 21, 25].", "startOffset": 59, "endOffset": 78}, {"referenceID": 15, "context": "There is a long history of research in multi-task learning [4, 40, 16, 21, 25].", "startOffset": 59, "endOffset": 78}, {"referenceID": 20, "context": "There is a long history of research in multi-task learning [4, 40, 16, 21, 25].", "startOffset": 59, "endOffset": 78}, {"referenceID": 24, "context": "There is a long history of research in multi-task learning [4, 40, 16, 21, 25].", "startOffset": 59, "endOffset": 78}, {"referenceID": 44, "context": "A few methods have addressed the problem of \u201cwith whom\u201d each task should share features [45, 16, 51, 18, 21, 26].", "startOffset": 88, "endOffset": 112}, {"referenceID": 15, "context": "A few methods have addressed the problem of \u201cwith whom\u201d each task should share features [45, 16, 51, 18, 21, 26].", "startOffset": 88, "endOffset": 112}, {"referenceID": 50, "context": "A few methods have addressed the problem of \u201cwith whom\u201d each task should share features [45, 16, 51, 18, 21, 26].", "startOffset": 88, "endOffset": 112}, {"referenceID": 17, "context": "A few methods have addressed the problem of \u201cwith whom\u201d each task should share features [45, 16, 51, 18, 21, 26].", "startOffset": 88, "endOffset": 112}, {"referenceID": 20, "context": "A few methods have addressed the problem of \u201cwith whom\u201d each task should share features [45, 16, 51, 18, 21, 26].", "startOffset": 88, "endOffset": 112}, {"referenceID": 25, "context": "A few methods have addressed the problem of \u201cwith whom\u201d each task should share features [45, 16, 51, 18, 21, 26].", "startOffset": 88, "endOffset": 112}, {"referenceID": 27, "context": "HyperFace [28] simultaneously learns to perform face detection, landmarks localization, pose estimation and gender recognition.", "startOffset": 10, "endOffset": 14}, {"referenceID": 18, "context": "UberNet [19] jointly learns low-, mid-, and high-level computer vision tasks using a compact network model.", "startOffset": 8, "endOffset": 12}, {"referenceID": 2, "context": "MultiNet [3] exploits recurrent networks for transferring information across tasks.", "startOffset": 9, "endOffset": 12}, {"referenceID": 16, "context": "Cross-ResNet [17] connects tasks through residual learning for knowledge transfer.", "startOffset": 13, "endOffset": 17}, {"referenceID": 24, "context": "Cross-stitching networks [25] have been recently proposed to learn an optimal combination of shared and task-specific representations.", "startOffset": 25, "endOffset": 29}, {"referenceID": 45, "context": "We note that other techniques such as HD-CNN [46] and Network of Experts [1] also group related classes to perform hierarchical classification, but these methods are not applicable for the multi-label setting (where labels are not mutually exclusive).", "startOffset": 45, "endOffset": 49}, {"referenceID": 0, "context": "We note that other techniques such as HD-CNN [46] and Network of Experts [1] also group related classes to perform hierarchical classification, but these methods are not applicable for the multi-label setting (where labels are not mutually exclusive).", "startOffset": 73, "endOffset": 76}, {"referenceID": 11, "context": "Methods for compressing and accelerating convolutional networks include knowledge distillation [12, 29], low-rank-factorization [14, 39, 33], pruning and quantization [10, 27], structured matrices [6, 35, 9], and dynamic capacity networks [2].", "startOffset": 95, "endOffset": 103}, {"referenceID": 28, "context": "Methods for compressing and accelerating convolutional networks include knowledge distillation [12, 29], low-rank-factorization [14, 39, 33], pruning and quantization [10, 27], structured matrices [6, 35, 9], and dynamic capacity networks [2].", "startOffset": 95, "endOffset": 103}, {"referenceID": 13, "context": "Methods for compressing and accelerating convolutional networks include knowledge distillation [12, 29], low-rank-factorization [14, 39, 33], pruning and quantization [10, 27], structured matrices [6, 35, 9], and dynamic capacity networks [2].", "startOffset": 128, "endOffset": 140}, {"referenceID": 38, "context": "Methods for compressing and accelerating convolutional networks include knowledge distillation [12, 29], low-rank-factorization [14, 39, 33], pruning and quantization [10, 27], structured matrices [6, 35, 9], and dynamic capacity networks [2].", "startOffset": 128, "endOffset": 140}, {"referenceID": 32, "context": "Methods for compressing and accelerating convolutional networks include knowledge distillation [12, 29], low-rank-factorization [14, 39, 33], pruning and quantization [10, 27], structured matrices [6, 35, 9], and dynamic capacity networks [2].", "startOffset": 128, "endOffset": 140}, {"referenceID": 9, "context": "Methods for compressing and accelerating convolutional networks include knowledge distillation [12, 29], low-rank-factorization [14, 39, 33], pruning and quantization [10, 27], structured matrices [6, 35, 9], and dynamic capacity networks [2].", "startOffset": 167, "endOffset": 175}, {"referenceID": 26, "context": "Methods for compressing and accelerating convolutional networks include knowledge distillation [12, 29], low-rank-factorization [14, 39, 33], pruning and quantization [10, 27], structured matrices [6, 35, 9], and dynamic capacity networks [2].", "startOffset": 167, "endOffset": 175}, {"referenceID": 5, "context": "Methods for compressing and accelerating convolutional networks include knowledge distillation [12, 29], low-rank-factorization [14, 39, 33], pruning and quantization [10, 27], structured matrices [6, 35, 9], and dynamic capacity networks [2].", "startOffset": 197, "endOffset": 207}, {"referenceID": 34, "context": "Methods for compressing and accelerating convolutional networks include knowledge distillation [12, 29], low-rank-factorization [14, 39, 33], pruning and quantization [10, 27], structured matrices [6, 35, 9], and dynamic capacity networks [2].", "startOffset": 197, "endOffset": 207}, {"referenceID": 8, "context": "Methods for compressing and accelerating convolutional networks include knowledge distillation [12, 29], low-rank-factorization [14, 39, 33], pruning and quantization [10, 27], structured matrices [6, 35, 9], and dynamic capacity networks [2].", "startOffset": 197, "endOffset": 207}, {"referenceID": 1, "context": "Methods for compressing and accelerating convolutional networks include knowledge distillation [12, 29], low-rank-factorization [14, 39, 33], pruning and quantization [10, 27], structured matrices [6, 35, 9], and dynamic capacity networks [2].", "startOffset": 239, "endOffset": 242}, {"referenceID": 35, "context": "In the visual surveillance domain, person attributes serve as features for improving person re-identification [36] and enable search of suspects based on their description [43, 8].", "startOffset": 110, "endOffset": 114}, {"referenceID": 42, "context": "In the visual surveillance domain, person attributes serve as features for improving person re-identification [36] and enable search of suspects based on their description [43, 8].", "startOffset": 172, "endOffset": 179}, {"referenceID": 7, "context": "In the visual surveillance domain, person attributes serve as features for improving person re-identification [36] and enable search of suspects based on their description [43, 8].", "startOffset": 172, "endOffset": 179}, {"referenceID": 12, "context": "In e-commerce applications, these attributes have proven effective in improving clothing retrieval [13], and fashion recommendation [22].", "startOffset": 99, "endOffset": 103}, {"referenceID": 21, "context": "In e-commerce applications, these attributes have proven effective in improving clothing retrieval [13], and fashion recommendation [22].", "startOffset": 132, "endOffset": 136}, {"referenceID": 46, "context": "It has also been shown that facial attribute prediction is helpful as an auxiliary task for improving face detection [47] and face alignment [50].", "startOffset": 117, "endOffset": 121}, {"referenceID": 49, "context": "It has also been shown that facial attribute prediction is helpful as an auxiliary task for improving face detection [47] and face alignment [50].", "startOffset": 141, "endOffset": 145}, {"referenceID": 43, "context": "State-of-the-art methods for person attribute prediction are based on deep convolutional neural networks [44, 24, 5, 49].", "startOffset": 105, "endOffset": 120}, {"referenceID": 23, "context": "State-of-the-art methods for person attribute prediction are based on deep convolutional neural networks [44, 24, 5, 49].", "startOffset": 105, "endOffset": 120}, {"referenceID": 4, "context": "State-of-the-art methods for person attribute prediction are based on deep convolutional neural networks [44, 24, 5, 49].", "startOffset": 105, "endOffset": 120}, {"referenceID": 48, "context": "State-of-the-art methods for person attribute prediction are based on deep convolutional neural networks [44, 24, 5, 49].", "startOffset": 105, "endOffset": 120}, {"referenceID": 48, "context": "tribute [49] or perform joint learning with a fully shared network [32].", "startOffset": 8, "endOffset": 12}, {"referenceID": 31, "context": "tribute [49] or perform joint learning with a fully shared network [32].", "startOffset": 67, "endOffset": 71}, {"referenceID": 12, "context": "Multi-task networks have been used with base layers that are shared across all attributes, and branches to encode task-specific features for each attribute category [13, 37].", "startOffset": 165, "endOffset": 173}, {"referenceID": 36, "context": "Multi-task networks have been used with base layers that are shared across all attributes, and branches to encode task-specific features for each attribute category [13, 37].", "startOffset": 165, "endOffset": 173}, {"referenceID": 47, "context": "This is confirmed by previous works on visualization of filters at different layers [48].", "startOffset": 84, "endOffset": 88}, {"referenceID": 19, "context": "Notably, popular deep convolutional network architectures, such as AlexNet [20], VGG [34], Inception [38] and ResNet [11] all use wider layers at the top Algorithm 1: Training with Adaptive Widening", "startOffset": 75, "endOffset": 79}, {"referenceID": 33, "context": "Notably, popular deep convolutional network architectures, such as AlexNet [20], VGG [34], Inception [38] and ResNet [11] all use wider layers at the top Algorithm 1: Training with Adaptive Widening", "startOffset": 85, "endOffset": 89}, {"referenceID": 37, "context": "Notably, popular deep convolutional network architectures, such as AlexNet [20], VGG [34], Inception [38] and ResNet [11] all use wider layers at the top Algorithm 1: Training with Adaptive Widening", "startOffset": 101, "endOffset": 105}, {"referenceID": 10, "context": "Notably, popular deep convolutional network architectures, such as AlexNet [20], VGG [34], Inception [38] and ResNet [11] all use wider layers at the top Algorithm 1: Training with Adaptive Widening", "startOffset": 117, "endOffset": 121}, {"referenceID": 24, "context": "These architectures serve as excellent reference designs in a myriad of domains, but researchers have noted that the width schedule (especially at the top layers) need to be tuned for the underlying set of tasks the network has to perform in order to achieve best accuracy [25].", "startOffset": 273, "endOffset": 277}, {"referenceID": 11, "context": "In the literature a set of general methods for training arbitrarily small networks using an existing larger network and the training data are known as \u201cknowledge distillation\u2019 [12, 29].", "startOffset": 176, "endOffset": 184}, {"referenceID": 28, "context": "In the literature a set of general methods for training arbitrarily small networks using an existing larger network and the training data are known as \u201cknowledge distillation\u2019 [12, 29].", "startOffset": 176, "endOffset": 184}, {"referenceID": 40, "context": "This problem is NP-hard, however, there exist approaches based on convex relaxation [41] and greedy simultaneous orthogonal matching pursuit (SOMP) [42] which can produce approximate solutions.", "startOffset": 84, "endOffset": 88}, {"referenceID": 41, "context": "This problem is NP-hard, however, there exist approaches based on convex relaxation [41] and greedy simultaneous orthogonal matching pursuit (SOMP) [42] which can produce approximate solutions.", "startOffset": 148, "endOffset": 152}, {"referenceID": 23, "context": "We use CelebA [24] dataset for facial attribute classification tasks and Deepfashion [23] for clothing category classification tasks.", "startOffset": 14, "endOffset": 18}, {"referenceID": 22, "context": "We use CelebA [24] dataset for facial attribute classification tasks and Deepfashion [23] for clothing category classification tasks.", "startOffset": 85, "endOffset": 89}, {"referenceID": 22, "context": "We evaluate top-3 and top-5 classification accuracy to directly compare with benchmark results in [23].", "startOffset": 98, "endOffset": 102}, {"referenceID": 29, "context": "The first baseline is a VGG-16 model initialized from the a model trained from imdb-wiki gender classification [30].", "startOffset": 111, "endOffset": 115}, {"referenceID": 6, "context": "This model is also initialized from the imdb-wiki gender pretrained model, but the initialization is through truncated Singular Value Decomposition (SVD) [7].", "startOffset": 154, "endOffset": 157}, {"referenceID": 30, "context": "Most recent works use the VGG face descriptor, whereas in our work we use the pre-trained model from imdb-wiki [31].", "startOffset": 111, "endOffset": 115}, {"referenceID": 14, "context": "For the thin baseline, it is also important to use Batch Normalization (BN) [15].", "startOffset": 76, "endOffset": 80}, {"referenceID": 43, "context": "LNet+ANet and Walk and Learn results are cited from [44].", "startOffset": 52, "endOffset": 56}, {"referenceID": 31, "context": "MOON results are cited from [32].", "startOffset": 28, "endOffset": 32}, {"referenceID": 22, "context": "WTBI and DARN results are cited from [23].", "startOffset": 37, "endOffset": 41}, {"referenceID": 22, "context": "We cite the reported results for clothing category [23].", "startOffset": 51, "endOffset": 55}], "year": 2016, "abstractText": "Multi-task learning aims to improve generalization performance of multiple prediction tasks by appropriately sharing relevant information across them. In the context of deep neural networks, this idea is often realized by handdesigned network architectures with layers that are shared across tasks and branches that encode task-specific features. However, the space of possible multi-task deep architectures is combinatorially large and often the final architecture is arrived at by manual exploration of this space subject to designer\u2019s bias, which can be both error-prone and tedious. In this work, we propose a principled approach for designing compact multi-task deep learning architectures. Our approach starts with a thin network and dynamically widens it in a greedy manner during training using a novel criterion that promotes grouping of similar tasks together. Extensive evaluation on person attributes classification tasks involving facial and clothing attributes suggests that the models produced by the proposed method are fast, compact and can closely match or exceed the state-of-theart accuracy from strong baselines by much more expensive models.", "creator": "LaTeX with hyperref package"}}}