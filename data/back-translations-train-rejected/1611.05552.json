{"id": "1611.05552", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Nov-2016", "title": "DelugeNets: Deep Networks with Efficient and Flexible Cross-layer Information Inflows", "abstract": "Human brains are adept at dealing with the deluge of information they continuously receive, by suppressing the non-essential inputs and focusing on the important ones. Inspired by such capability, we propose Deluge Networks (DelugeNets), a novel class of neural networks facilitating massive cross-layer information inflows from preceding layers to succeeding layers. The connections between layers in DelugeNets are efficiently established through cross-layer depthwise convolutional layers with learnable filters, acting as a flexible selection mechanism. By virtue of the massive cross-layer information inflows, DelugeNets can propagate information across many layers with greater flexibility and utilize network parameters more effectively, compared to existing ResNet models. Experiments show the superior performances of DelugeNets in terms of both classification accuracies and parameter efficiencies. Remarkably, a DelugeNet model with just 20.2M parameters achieve state-of-the-art accuracy of 19.02% on CIFAR-100 dataset, outperforming DenseNet model with 27.2M parameters.", "histories": [["v1", "Thu, 17 Nov 2016 03:45:48 GMT  (118kb,D)", "http://arxiv.org/abs/1611.05552v1", null], ["v2", "Mon, 12 Dec 2016 07:41:33 GMT  (118kb,D)", "http://arxiv.org/abs/1611.05552v2", "Code:this https URL"], ["v3", "Wed, 28 Dec 2016 02:08:45 GMT  (119kb,D)", "http://arxiv.org/abs/1611.05552v3", "Code:this https URL"], ["v4", "Fri, 30 Dec 2016 04:56:02 GMT  (119kb,D)", "http://arxiv.org/abs/1611.05552v4", "Code:this https URL"], ["v5", "Wed, 23 Aug 2017 14:09:55 GMT  (419kb,D)", "http://arxiv.org/abs/1611.05552v5", "Code:this https URL"]], "reviews": [], "SUBJECTS": "cs.CV cs.LG cs.NE", "authors": ["jason kuen", "xiangfei kong", "gang wang", "yap-peng tan"], "accepted": false, "id": "1611.05552"}, "pdf": {"name": "1611.05552.pdf", "metadata": {"source": "CRF", "title": "DelugeNets: Deep Networks with Massive and Flexible Cross-layer Information Inflows", "authors": ["Jason Kuen", "Xiangfei Kong", "Gang Wang"], "emails": ["jkuen001@ntu.edu.sg", "xfkong@ntu.edu.sg", "wanggang@ntu.edu.sg"], "sections": [{"heading": "1. Introduction", "text": "This year, we have reached the point where we feel we are in a position to take the lead without being able to try to find a solution."}, {"heading": "2. Related Work", "text": "This year, it is as far as ever in the history of the city, where it is as far as never before."}, {"heading": "3. Deluge Networks", "text": "Similar to existing CNNs (ResNet [12] [13], VGGNet [28] and AlexNet [20]), DelugeNets gradually decrease the spatial dimensions and increase the functional channels of feature maps from bottom to top, with a linear classification layer attached at the end. Layers that work with the same feature map dimensions can be grouped into a block. In DelugeNets, input comes to a specific layer of all previous layers of the same block. There is no information flowing directly from other blocks. Within a block, the information flows between layers through connections made by the cross-layer depth waves (see Section 3.2)."}, {"heading": "3.1. Composite Layer", "text": "In CNNs, a layer often refers to a composite layer of several basic layers such as Rectified Linear Unit (ReLU), Convolutional (Conv), Batch Normalization (BN) layers. Inspired by [13], we use the narrow-sided composite layer BN-ReLU-Conv-BN-ReLU-Conv-BN-ReLU-Conv in DelugeNets, as illustrated in Figure 1 (a).This type of composite layer is designed to improve parameter efficiency in deep networks by using 1 \u00d7 1 spatial convolutionary layers at the beginning to reduce the channel dimension, and at the end to increase the channel dimension. In the ResNet models proposed by [13], the base channel dimensions are increased fourfold, but in this paper we only increase them twice, for the reason that we can assign more compression and parameter budgets to Deluge deeper."}, {"heading": "3.2. Cross-layer Depthwise Convolutional Layers", "text": "In fact, the fact is that most of them are able to survive themselves, and that they are able to survive themselves, \"he said in an interview with The New York Times, in which he grappled with the question:\" What is this? \"\" What is this? \"\" What is this? \"\" What is this? \"\" What is this? \"\" What is this? \"\" What is this? \"he asks?\" What is this? \"he asks?\" What is this? \"he asks?\" What is this? \"he asks?\" What is this? \"he asks?\" What is this? \"he asks?\" What is this? \"he asks?\" What is this? \"he asks?\" What is this? \"he asks?\" he asks? \"What is this?\" he asks? \"What is this?\" he asks? \"What is this?\" he asks? \"What is this?\" he asks? \"What is this?\""}, {"heading": "3.3. Block Transition", "text": "Different network blocks operate on characteristic maps of different spatial and channel dimensions. For block transitions, there is a need to transform the characteristic map to match the spatial and channel dimensions of the next block. In ResNetlike models, the block transition can be performed either with 1 \u00d7 1 step folding or with average step-by-step pooling with channel padding. These block transition concepts aim to obtain the information of the previous block by having minimal transformations and neglecting any non-linear activation function. Such block transition concepts are suboptimal for DelugeNets because they allow direct information flow only from the last composite layer of the previous block, and they may impede the flow of information from other composite layers. To this end, we propose a new block transition component that has a cross-layer revolutionary layer followed by 3 \u00d7 3 spatial revolutionary layers as the convolutional layer passes through the convolutional spatial layer."}, {"heading": "4. Experiments", "text": "To rigorously evaluate the effectiveness of DelugeNets, we evaluate DelugeNets using three image classification datasets of varying degrees of complexity: CIFAR-10 [19], CIFAR-100 [19], ImageNet [25]. The experimental codes are written in Torch [5] and are available at https: / / github.com / xternalz / DelugeNets."}, {"heading": "4.1. CIFAR-10 and CIFAR-100", "text": "This year it is so far that it will only take one year to move on to the next round."}, {"heading": "4.2. ImageNet", "text": "In fact, most of them will be able to go to another world, where they can go to another world, where they can go to another world, where they can go to another world, where they can go to another world."}, {"heading": "5. Conclusion", "text": "In our DelugeNetworks, we extend the convective layers in depth to the convective layers in depth, which facilitate connections between layers. Information flows between layers in DelugeNetworks are flexible (the convective filters in depth are learned) and yet huge (the output widths of the compound layers are regular).In the future, we would like to investigate regularization techniques (e.g. layer failure [17]) in connection with connectivity between layers and apply DelugeNetworks to other visual applications."}], "references": [{"title": "Learning deep architectures for ai", "author": ["Y. Bengio"], "venue": "Foundations and Trends in Machine Learning, 2(1):1\u2013127", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2009}, {"title": "Listen", "author": ["W. Chan", "N. Jaitly", "Q.V. Le", "O. Vinyals"], "venue": "attend and spell: A neural network for large vocabulary conversational speech recognition. In ICASSP, pages 4960\u20134964", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2016}, {"title": "Xception: Deep learning with depthwise separable convolutions", "author": ["F. Chollet"], "venue": "arXiv preprint arXiv:1610.02357", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2016}, {"title": "Fast and accurate deep network learning by exponential linear units (elus)", "author": ["D.-A. Clevert", "T. Unterthiner", "S. Hochreiter"], "venue": "ICLR", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2015}, {"title": "Torch7: A matlab-like environment for machine learning", "author": ["R. Collobert", "K. Kavukcuoglu", "C. Farabet"], "venue": "BigLearn, NIPS Workshop, number EPFL-CONF-192376", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2011}, {"title": "Maxout networks", "author": ["I.J. Goodfellow", "D. Warde-Farley", "M. Mirza", "A.C. Courville", "Y. Bengio"], "venue": "ICML", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "Fractional max-pooling", "author": ["B. Graham"], "venue": "arXiv preprint arXiv:1412.6071", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "Neural turing machines", "author": ["A. Graves", "G. Wayne", "I. Danihelka"], "venue": "arXiv preprint arXiv:1410.5401", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Recent advances in convolutional neural networks", "author": ["J. Gu", "Z. Wang", "J. Kuen", "L. Ma", "A. Shahroudy", "B. Shuai", "T. Liu", "X. Wang", "G. Wang"], "venue": "arXiv preprint arXiv:1512.07108", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2015}, {"title": "Delving deep into rectifiers: Surpassing human-level performance on imagenet classification", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "CVPR, pages 1026\u20131034", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep residual learning for image recognition", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "In CVPR, June 2016", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2016}, {"title": "Identity mappings in deep residual networks", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "ECCV", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2016}, {"title": "Long short-term memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural computation, 9(8):1735\u20131780", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1997}, {"title": "Some improvements on deep convolutional neural network based image classification", "author": ["A.G. Howard"], "venue": "arXiv preprint arXiv:1312.5402", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2013}, {"title": "Densely connected convolutional networks", "author": ["G. Huang", "Z. Liu", "K.Q. Weinberger"], "venue": "arXiv preprint arXiv:1608.06993", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2016}, {"title": "Deep networks with stochastic depth", "author": ["G. Huang", "Y. Sun", "Z. Liu", "D. Sedra", "K. Weinberger"], "venue": "ECCV", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2016}, {"title": "Flattened convolutional neural networks for feedforward acceleration", "author": ["J. Jin", "A. Dundar", "E. Culurciello"], "venue": "ICLR", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning multiple layers of features from tiny images", "author": ["A. Krizhevsky"], "venue": "Technical report", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2009}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "NIPS, pages 1097\u20131105", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2012}, {"title": "Fractalnet: Ultra-deep neural networks without residuals", "author": ["G. Larsson", "M. Maire", "G. Shakhnarovich"], "venue": "arXiv preprint arXiv:1605.07648", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2016}, {"title": "Gradientbased learning applied to document recognition", "author": ["Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "Proceedings of the IEEE, 86(11):2278\u20132324", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1998}, {"title": "Deeplysupervised nets", "author": ["C.-Y. Lee", "S. Xie", "P. Gallagher", "Z. Zhang", "Z. Tu"], "venue": "AISTATS, volume 2, page 6", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2015}, {"title": "Network in network", "author": ["M. Lin", "Q. Chen", "S. Yan"], "venue": "ICLR", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2014}, {"title": "Imagenet large scale visual recognition challenge", "author": ["O. Russakovsky", "J. Deng", "H. Su", "J. Krause", "S. Satheesh", "S. Ma", "Z. Huang", "A. Karpathy", "A. Khosla", "M. Bernstein", "A.C. Berg", "L. Fei-Fei"], "venue": "IJCV, 115(3):211\u2013252", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep learning in neural networks: An overview", "author": ["J. Schmidhuber"], "venue": "Neural Networks, 61:85 \u2013 117", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep residual networks with exponential linear unit", "author": ["A. Shah", "E. Kadam", "H. Shah", "S. Shinde", "S. Shingade"], "venue": "VisionNet, pages 59\u201365", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2016}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["K. Simonyan", "A. Zisserman"], "venue": "ICLR", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2015}, {"title": "Swapout: Learning an ensemble of deep architectures", "author": ["S. Singh", "D. Hoiem", "D. Forsyth"], "venue": "In NIPS. 2016", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2016}, {"title": "Striving for simplicity: The all convolutional net", "author": ["J. Springenberg", "A. Dosovitskiy", "T. Brox", "M. Riedmiller"], "venue": "ICLR Workshop", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2015}, {"title": "Training very deep networks", "author": ["R.K. Srivastava", "K. Greff", "J. Schmidhuber"], "venue": "In NIPS. 2015", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2015}, {"title": "On the importance of initialization and momentum in deep learning", "author": ["I. Sutskever", "J. Martens", "G.E. Dahl", "G.E. Hinton"], "venue": "ICML", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2013}, {"title": "Going deeper with convolutions", "author": ["C. Szegedy", "W. Liu", "Y. Jia", "P. Sermanet", "S. Reed", "D. Anguelov", "D. Erhan", "V. Vanhoucke", "A. Rabinovich"], "venue": "CVPR, pages 1\u20139", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2015}, {"title": "Rethinking the inception architecture for computer vision", "author": ["C. Szegedy", "V. Vanhoucke", "S. Ioffe", "J. Shlens", "Z. Wojna"], "venue": "CVPR", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2016}, {"title": "80 million tiny images: A large data set for nonparametric object and scene recognition", "author": ["A. Torralba", "R. Fergus", "W.T. Freeman"], "venue": "IEEE TPAMI,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2008}, {"title": "Residual networks are exponential ensembles of relatively shallow networks", "author": ["A. Veit", "M. Wilber", "S. Belongie"], "venue": "NIPS", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2016}, {"title": "Empirical evaluation of rectified activations in convolutional network", "author": ["B. Xu", "N. Wang", "T. Chen", "M. Li"], "venue": "ICML Deep Learning Workshop", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2015}, {"title": "Show", "author": ["K. Xu", "J. Ba", "R. Kiros", "K. Cho", "A. Courville", "R. Salakhudinov", "R. Zemel", "Y. Bengio"], "venue": "attend and tell: Neural image caption generation with visual attention. In ICML, pages 2048\u20132057", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2015}, {"title": "Wide residual networks", "author": ["S. Zagoruyko", "N. Komodakis"], "venue": "BMVC", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2016}], "referenceMentions": [{"referenceID": 0, "context": "Deep learning methods [1][26], particularly convolutional neural networks (CNN) [22] have revolutionized the field of computer vision.", "startOffset": 22, "endOffset": 25}, {"referenceID": 24, "context": "Deep learning methods [1][26], particularly convolutional neural networks (CNN) [22] have revolutionized the field of computer vision.", "startOffset": 25, "endOffset": 29}, {"referenceID": 20, "context": "Deep learning methods [1][26], particularly convolutional neural networks (CNN) [22] have revolutionized the field of computer vision.", "startOffset": 80, "endOffset": 84}, {"referenceID": 8, "context": "CNNs are integral components of many recent computer vision techniques which spread across a diverse range of vision application areas [10].", "startOffset": 135, "endOffset": 139}, {"referenceID": 9, "context": "Some works focus on improving the activation functions [11][37], and some focus on increasing the heterogeneity of convolutional filters within the same layers [33][34].", "startOffset": 55, "endOffset": 59}, {"referenceID": 35, "context": "Some works focus on improving the activation functions [11][37], and some focus on increasing the heterogeneity of convolutional filters within the same layers [33][34].", "startOffset": 59, "endOffset": 63}, {"referenceID": 31, "context": "Some works focus on improving the activation functions [11][37], and some focus on increasing the heterogeneity of convolutional filters within the same layers [33][34].", "startOffset": 160, "endOffset": 164}, {"referenceID": 32, "context": "Some works focus on improving the activation functions [11][37], and some focus on increasing the heterogeneity of convolutional filters within the same layers [33][34].", "startOffset": 164, "endOffset": 168}, {"referenceID": 10, "context": "Lately, the idea of improving CNNs by greatly deepening them has gained much traction, following the immense successes of Residual Networks (ResNets) [12][13] in image classification.", "startOffset": 150, "endOffset": 154}, {"referenceID": 11, "context": "Lately, the idea of improving CNNs by greatly deepening them has gained much traction, following the immense successes of Residual Networks (ResNets) [12][13] in image classification.", "startOffset": 154, "endOffset": 158}, {"referenceID": 14, "context": "Densely connected networks (DenseNets) [16] aim to overcome this drawback of ResNets, by having convolutional layers to consider an extra dimension - the depth/layer dimension, in addition to the spatial and feature channel dimensions used in regular convolutions.", "startOffset": 39, "endOffset": 43}, {"referenceID": 37, "context": "However, it is crucial to have considerable network width as contended by [39], and decreasing output width too much is harmful to networks representational power.", "startOffset": 74, "endOffset": 78}, {"referenceID": 16, "context": "Our proposed DelugeNets are inspired by separable convolutions [18][3].", "startOffset": 63, "endOffset": 67}, {"referenceID": 2, "context": "Our proposed DelugeNets are inspired by separable convolutions [18][3].", "startOffset": 67, "endOffset": 70}, {"referenceID": 16, "context": "The most prevalent type is spatially separable convolution which separates spatial dimension into vertical and horizontal spatial dimensions, as done by [18].", "startOffset": 153, "endOffset": 157}, {"referenceID": 2, "context": "Alternatively, the work in [3] separates combined channel-spatial dimension into channel and spatial dimensions, demonstrating that the tasks of convolution filters to learn cross-channel correlations and spatial correlations can be decoupled.", "startOffset": 27, "endOffset": 30}, {"referenceID": 2, "context": "The decoupling [3] leads to considerable performance gains for an Inception-like [34] network.", "startOffset": 15, "endOffset": 18}, {"referenceID": 32, "context": "The decoupling [3] leads to considerable performance gains for an Inception-like [34] network.", "startOffset": 81, "endOffset": 85}, {"referenceID": 2, "context": "Motivated by [3], DelugeNets are designed such that the depth/layer dimension is processed independently from the rest (channel and spatial dimensions), using a novel variant of convolutional layer called cross-layer depthwise convolutional layer (see Figure 2) as described in Section 3.", "startOffset": 13, "endOffset": 16}, {"referenceID": 21, "context": "[23] incorporate classification losses into intermediate hidden layers, allowing unimpeded supervised signals to reach the layers.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "In a similar spirit as [23], GoogleNets [33] and Inception [34] models attach auxiliary classifiers to a few intermediate layers to encourage feature discriminativeness in lower network layers.", "startOffset": 23, "endOffset": 27}, {"referenceID": 31, "context": "In a similar spirit as [23], GoogleNets [33] and Inception [34] models attach auxiliary classifiers to a few intermediate layers to encourage feature discriminativeness in lower network layers.", "startOffset": 40, "endOffset": 44}, {"referenceID": 32, "context": "In a similar spirit as [23], GoogleNets [33] and Inception [34] models attach auxiliary classifiers to a few intermediate layers to encourage feature discriminativeness in lower network layers.", "startOffset": 59, "endOffset": 63}, {"referenceID": 29, "context": "Highway Networks [31] make use of a Long-Short-Term-Memory (LSTM [14])-inspired gating mechanism to control information flow from linear and nonlinear pathways.", "startOffset": 17, "endOffset": 21}, {"referenceID": 12, "context": "Highway Networks [31] make use of a Long-Short-Term-Memory (LSTM [14])-inspired gating mechanism to control information flow from linear and nonlinear pathways.", "startOffset": 65, "endOffset": 69}, {"referenceID": 10, "context": "[12] propose Residual Networks (ResNets) which compute the residual (additive) functions of the outputs of linear and nonlinear pathways, without complex gating mechanisms.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "Later, a pre-activation variant of residual building block [13] (ResNet-v2) is proposed to significantly enhance information flow and regularization of ResNet models.", "startOffset": 59, "endOffset": 63}, {"referenceID": 37, "context": "Instead of going deeper, Wide-ResNets [39] improve upon originally proposed ResNets by having more convolutional filters/channels (width) and less numbers of layers (depth).", "startOffset": 38, "endOffset": 42}, {"referenceID": 15, "context": "numbers, several \u201cdropping\u201d-based regularization methods [17][29] have been developed for regularizing large ResNet models.", "startOffset": 57, "endOffset": 61}, {"referenceID": 27, "context": "numbers, several \u201cdropping\u201d-based regularization methods [17][29] have been developed for regularizing large ResNet models.", "startOffset": 61, "endOffset": 65}, {"referenceID": 14, "context": "Densely connected networks (DenseNets) [16] which we discuss extensively in Section 1 belong to the same stream of works.", "startOffset": 39, "endOffset": 43}, {"referenceID": 7, "context": "Our proposed DelugeNets are also related to neural networks with attention mechanisms such as [9][38][2].", "startOffset": 94, "endOffset": 97}, {"referenceID": 36, "context": "Our proposed DelugeNets are also related to neural networks with attention mechanisms such as [9][38][2].", "startOffset": 97, "endOffset": 101}, {"referenceID": 1, "context": "Our proposed DelugeNets are also related to neural networks with attention mechanisms such as [9][38][2].", "startOffset": 101, "endOffset": 104}, {"referenceID": 1, "context": "For example, the work in [2] learns attention weights for the speech hidden representations, one for every timestep.", "startOffset": 25, "endOffset": 28}, {"referenceID": 36, "context": "Similarly, for every spatial location in the image feature map, the image captioning model in [38] learns a separate attention weight.", "startOffset": 94, "endOffset": 98}, {"referenceID": 2, "context": "Our proposed weighting mechanism (cross-layer depthwise convolutional layers) works a lot more like convolution/filtering, specifically the depthwise convolution introduced in [3].", "startOffset": 176, "endOffset": 179}, {"referenceID": 10, "context": "Similar to existing CNNs (ResNet [12][13], VGGNet [28], and AlexNet [20]), DelugeNets gradually decrease spatial sizes and increase feature channels of feature maps from bottom to top layers, with a linear classification layer attached to the end.", "startOffset": 33, "endOffset": 37}, {"referenceID": 11, "context": "Similar to existing CNNs (ResNet [12][13], VGGNet [28], and AlexNet [20]), DelugeNets gradually decrease spatial sizes and increase feature channels of feature maps from bottom to top layers, with a linear classification layer attached to the end.", "startOffset": 37, "endOffset": 41}, {"referenceID": 26, "context": "Similar to existing CNNs (ResNet [12][13], VGGNet [28], and AlexNet [20]), DelugeNets gradually decrease spatial sizes and increase feature channels of feature maps from bottom to top layers, with a linear classification layer attached to the end.", "startOffset": 50, "endOffset": 54}, {"referenceID": 18, "context": "Similar to existing CNNs (ResNet [12][13], VGGNet [28], and AlexNet [20]), DelugeNets gradually decrease spatial sizes and increase feature channels of feature maps from bottom to top layers, with a linear classification layer attached to the end.", "startOffset": 68, "endOffset": 72}, {"referenceID": 11, "context": "Inspired by [13], we use the bottleneck-kind of composite layer BN-ReLU-Conv-BN-ReLU-Conv-BN-ReLU-Conv in DelugeNets, as illustrated in Figure 1(a).", "startOffset": 12, "endOffset": 16}, {"referenceID": 11, "context": "In the ResNet models proposed by [13], the base channel dimensions are increased by 4 times.", "startOffset": 33, "endOffset": 37}, {"referenceID": 11, "context": "This reduces internal covariate shift and regularizes the model more effectively [13] than just passing unnormalized multi-source information to the weight layers.", "startOffset": 81, "endOffset": 85}, {"referenceID": 14, "context": "DenseNets [16], on the other hand, require heavy amounts of parameters to connect to preceding layers, through cross-layer output concatenations followed by 3\u00d7 3 spatial convolutions.", "startOffset": 10, "endOffset": 14}, {"referenceID": 17, "context": "To rigorously validate the effectiveness of DelugeNets, we evaluate DelugeNets on 3 image classification datasets with varied degrees of complexity: CIFAR-10 [19], CIFAR-", "startOffset": 158, "endOffset": 162}, {"referenceID": 5, "context": "Maxout Network [7] - 9.", "startOffset": 15, "endOffset": 18}, {"referenceID": 22, "context": "57 Network-in-Network [24] - 8.", "startOffset": 22, "endOffset": 26}, {"referenceID": 21, "context": "68 Deeply Supervised Net [23] - 7.", "startOffset": 25, "endOffset": 29}, {"referenceID": 28, "context": "57 All-CNN [30] - 7.", "startOffset": 11, "endOffset": 15}, {"referenceID": 6, "context": "71 Fractional Max-Pooling [8] - 4.", "startOffset": 26, "endOffset": 29}, {"referenceID": 3, "context": "62 ELU-Net [4] - 6.", "startOffset": 11, "endOffset": 14}, {"referenceID": 29, "context": "28 Highway Network [31] - 7.", "startOffset": 19, "endOffset": 23}, {"referenceID": 19, "context": "FractalNet [21] 38.", "startOffset": 11, "endOffset": 15}, {"referenceID": 10, "context": "ResNet [12] 1.", "startOffset": 7, "endOffset": 11}, {"referenceID": 10, "context": "16 ResNet [12] 10.", "startOffset": 10, "endOffset": 14}, {"referenceID": 25, "context": "ResNet with ELU [27] - 110 5.", "startOffset": 16, "endOffset": 20}, {"referenceID": 11, "context": "ResNet with Identity Mappings [13] 1.", "startOffset": 30, "endOffset": 34}, {"referenceID": 11, "context": "33 ResNet with Identity Mappings [13] 10.", "startOffset": 33, "endOffset": 37}, {"referenceID": 27, "context": "ResNet with Swapout [29] 7.", "startOffset": 20, "endOffset": 24}, {"referenceID": 15, "context": "ResNet with Stochastic Depth [17] 1.", "startOffset": 29, "endOffset": 33}, {"referenceID": 15, "context": "98 ResNet with Stochastic Depth [17] 10.", "startOffset": 32, "endOffset": 36}, {"referenceID": 37, "context": "91 Wide-ResNet (04\u00d7width) [39] 8.", "startOffset": 26, "endOffset": 30}, {"referenceID": 37, "context": "89 Wide-ResNet (08\u00d7width) [39] 11.", "startOffset": 26, "endOffset": 30}, {"referenceID": 37, "context": "07 Wide-ResNet (10\u00d7width) [39] 36.", "startOffset": 26, "endOffset": 30}, {"referenceID": 14, "context": "DenseNet (k = 12) [16] 7.", "startOffset": 18, "endOffset": 22}, {"referenceID": 14, "context": "20 DenseNet (k = 24) [16] 27.", "startOffset": 21, "endOffset": 25}, {"referenceID": 17, "context": "100 [19], ImageNet [25].", "startOffset": 4, "endOffset": 8}, {"referenceID": 23, "context": "100 [19], ImageNet [25].", "startOffset": 19, "endOffset": 23}, {"referenceID": 4, "context": "The experimental codes are written in Torch [5], and made available at https:// github.", "startOffset": 44, "endOffset": 47}, {"referenceID": 33, "context": "Datasets: CIFAR-10 and CIFAR-100 are 2 subsets of the Tiny Images dataset [35] annotated to serve as image classification datasets.", "startOffset": 74, "endOffset": 78}, {"referenceID": 37, "context": "During training, data augmentation is carried out moderately as in [39][16], with horizontal flipping and random crops taken from images padded by 4 pixels on each side.", "startOffset": 67, "endOffset": 71}, {"referenceID": 14, "context": "During training, data augmentation is carried out moderately as in [39][16], with horizontal flipping and random crops taken from images padded by 4 pixels on each side.", "startOffset": 71, "endOffset": 75}, {"referenceID": 11, "context": "Similar to [13][39], all the 3 DelugeNet models have 3 blocks the first block works on spatially 32\u00d7 32 feature maps, followed by 16\u00d716 and 8\u00d78 feature maps for second and third blocks respectively.", "startOffset": 11, "endOffset": 15}, {"referenceID": 37, "context": "Similar to [13][39], all the 3 DelugeNet models have 3 blocks the first block works on spatially 32\u00d7 32 feature maps, followed by 16\u00d716 and 8\u00d78 feature maps for second and third blocks respectively.", "startOffset": 15, "endOffset": 19}, {"referenceID": 30, "context": "To train the models, we run Stochastic Gradient Descent (SGD) over a total of 300 training epochs, with Nestorov Momentum [32] and weight decay rate of 1e\u22124.", "startOffset": 122, "endOffset": 126}, {"referenceID": 9, "context": "All DelugeNet models are initialized using He\u2019s initialization method [11], and they are trained using the same settings.", "startOffset": 70, "endOffset": 74}, {"referenceID": 14, "context": "The training settings are in fact identical to the settings employed in [16] to train DenseNets.", "startOffset": 72, "endOffset": 76}, {"referenceID": 14, "context": "Notably, our largest model Wide-DelugeNet-146 outperforms all existing works on CIFAR-100, and achieves top-1 error comparable to current state-of-the model, DenseNet [16] on CIFAR-10.", "startOffset": 167, "endOffset": 171}, {"referenceID": 34, "context": "Such phenomenon has also been observed in ResNets [36], where upper layers could be deleted without hurting performance much.", "startOffset": 50, "endOffset": 54}, {"referenceID": 23, "context": "Dataset: ImageNet dataset [25] is the most widely used large-scale image classification dataset in recent years.", "startOffset": 26, "endOffset": 30}, {"referenceID": 31, "context": "We follow the data augmentation scheme adopted in GoogleNet/Inception [33][34] and ResNet-v2 [13] with the following augmentation techniques: scale [20] & aspect ratio [33] augmentation, PCA-based lighting augmentation [20], photometric distortions [15], and horizontal flipping.", "startOffset": 70, "endOffset": 74}, {"referenceID": 32, "context": "We follow the data augmentation scheme adopted in GoogleNet/Inception [33][34] and ResNet-v2 [13] with the following augmentation techniques: scale [20] & aspect ratio [33] augmentation, PCA-based lighting augmentation [20], photometric distortions [15], and horizontal flipping.", "startOffset": 74, "endOffset": 78}, {"referenceID": 11, "context": "We follow the data augmentation scheme adopted in GoogleNet/Inception [33][34] and ResNet-v2 [13] with the following augmentation techniques: scale [20] & aspect ratio [33] augmentation, PCA-based lighting augmentation [20], photometric distortions [15], and horizontal flipping.", "startOffset": 93, "endOffset": 97}, {"referenceID": 18, "context": "We follow the data augmentation scheme adopted in GoogleNet/Inception [33][34] and ResNet-v2 [13] with the following augmentation techniques: scale [20] & aspect ratio [33] augmentation, PCA-based lighting augmentation [20], photometric distortions [15], and horizontal flipping.", "startOffset": 148, "endOffset": 152}, {"referenceID": 31, "context": "We follow the data augmentation scheme adopted in GoogleNet/Inception [33][34] and ResNet-v2 [13] with the following augmentation techniques: scale [20] & aspect ratio [33] augmentation, PCA-based lighting augmentation [20], photometric distortions [15], and horizontal flipping.", "startOffset": 168, "endOffset": 172}, {"referenceID": 18, "context": "We follow the data augmentation scheme adopted in GoogleNet/Inception [33][34] and ResNet-v2 [13] with the following augmentation techniques: scale [20] & aspect ratio [33] augmentation, PCA-based lighting augmentation [20], photometric distortions [15], and horizontal flipping.", "startOffset": 219, "endOffset": 223}, {"referenceID": 13, "context": "We follow the data augmentation scheme adopted in GoogleNet/Inception [33][34] and ResNet-v2 [13] with the following augmentation techniques: scale [20] & aspect ratio [33] augmentation, PCA-based lighting augmentation [20], photometric distortions [15], and horizontal flipping.", "startOffset": 249, "endOffset": 253}, {"referenceID": 11, "context": "Similar to ResNet models [13], before being passed to the first block, the feature map (after first layer) is downsampled to spatial dimensions of 56\u00d756 via max-pooling.", "startOffset": 25, "endOffset": 29}, {"referenceID": 11, "context": "ResNet-101 [13] 44.", "startOffset": 11, "endOffset": 15}, {"referenceID": 11, "context": "21 ResNet-152 [13] 60.", "startOffset": 14, "endOffset": 18}, {"referenceID": 30, "context": "Training is carried out with SGD over a total of 100 training epochs, with Nestorov Momentum [32] and weight decay rate of 1e\u22124.", "startOffset": 93, "endOffset": 97}, {"referenceID": 15, "context": ", layer dropout [17]) in the context of cross-layer connectivity, as well as applying DelugeNets to other vision applications.", "startOffset": 16, "endOffset": 20}], "year": 2017, "abstractText": "Human brains are adept at dealing with the deluge of information they continuously receive, by suppressing the non-essential inputs and focusing on the important ones. Inspired by such capability, we propose Deluge Networks (DelugeNets), a novel class of neural networks facilitating massive cross-layer information inflows from preceding layers to succeeding layers. The connections between layers in DelugeNets are efficiently established through cross-layer depthwise convolutional layers with learnable filters, acting as a flexible selection mechanism. By virtue of the massive cross-layer information inflows, DelugeNets can propagate information across many layers with greater flexibility and utilize network parameters more effectively, compared to existing ResNet models. Experiments show the superior performances of DelugeNets in terms of both classification accuracies and parameter efficiencies. Remarkably, a DelugeNet model with just 20.2M parameters achieve state-ofthe-art accuracy of 19.02% on CIFAR-100 dataset, outperforming DenseNet model with 27.2M parameters.", "creator": "LaTeX with hyperref package"}}}