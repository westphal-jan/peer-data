{"id": "1611.05644", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Nov-2016", "title": "Inverting The Generator Of A Generative Adversarial Network", "abstract": "Generative adversarial networks (GANs) learn to synthesise new samples from a high-dimensional distribution by passing samples drawn from a latent space through a generative network. When the high-dimensional distribution describes images of a particular data set, the network should learn to generate visually similar image samples for latent variables that are close to each other in the latent space. For tasks such as image retrieval and image classification, it may be useful to exploit the arrangement of the latent space by projecting images into it, and using this as a representation for discriminative tasks. GANs often consist of multiple layers of non-linear computations, making them very difficult to invert. This paper introduces techniques for projecting image samples into the latent space using any pre-trained GAN, provided that the computational graph is available. We evaluate these techniques on both MNIST digits and Omniglot handwritten characters. In the case of MNIST digits, we show that projections into the latent space maintain information about the style and the identity of the digit. In the case of Omniglot characters, we show that even characters from alphabets that have not been seen during training may be projected well into the latent space; this suggests that this approach may have applications in one-shot learning.", "histories": [["v1", "Thu, 17 Nov 2016 11:55:16 GMT  (500kb,D)", "http://arxiv.org/abs/1611.05644v1", "Accepted at NIPS 2016 Workshop on Adversarial Training"]], "COMMENTS": "Accepted at NIPS 2016 Workshop on Adversarial Training", "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["antonia creswell", "anil anthony bharath"], "accepted": false, "id": "1611.05644"}, "pdf": {"name": "1611.05644.pdf", "metadata": {"source": "CRF", "title": "Inverting The Generator Of A Generative Adversarial Network", "authors": ["Antonia Creswell", "Anil Anthony Bharath"], "emails": ["ac2211@ic.ac.uk"], "sections": [{"heading": "1 Introduction", "text": "In fact, it is a purely mental game, which is about enabling people to put themselves in a position to put themselves in the position they are in, to put themselves in a position to put themselves in the position they are in; indeed, it is about enabling them to put themselves in a position to put themselves in, to put themselves in a position, to put themselves in a position, to put themselves in a position to put themselves in the position they are in."}, {"heading": "2 Method: Inverting The Generator", "text": "For an image x < m \u00b7 m, we want to infer the Z-space representation z \u00b7 z, which generates an image that is very similar to x by the trained generator. We refer to the process of deriving z from x as inversion, which can be formulated as a minimization problem: z \u0445 = min z \u2212 Ex log [G (z)] (1) Provided that the computational graph for G (z) is known, z \u00b2 can be calculated using gradient descendance methods, whereby the gradient of G w.r.t. is detailed in Algorithm 1.Algorithm 1 Algorithm for inferring z \u00b2 < d, the latent representation for an image x < m \u00b7 m. 1: Procedure INFER (x). Let us conclude from z \u00b2 < d from x < m \u00b2 m \u00b2 p \u00b2 p \u00b2 z \u00b7 z by sampling the previous distribution 3: while NOT is a converted representation of 4 \u00b7 L \u00b2 (1)."}, {"heading": "2.1 Effects Of Batch Normalisation", "text": "The GAN training is not trivial, as the optimal solution is a saddle point rather than a minimum [11]. It is suggested by Radford et al. [10] that a batch normalization must be used to achieve a more stable GAN training [7]. Batch normalization involves calculating an average and a standard deviation via a batch of outputs from a sinuous layer and adjusting the mean and the standard deviation using learned weights. If a single z-value is passed through a batch normalization layer, the output of the layer may be meaningless. To counteract this problem, it would be ideal to use a virtual batch normalization [11], in which statistics are computed using a separate batch. However, we would like to allow this technique to be applied to any pre-trained network - where a virtual batch normalization may not have been applied. To counteract the effects of batch normalization, we suggest that we rehearse a batch of a particular time before a batch-input a batch."}, {"heading": "2.2 Inverting A Batch Of Samples", "text": "We will now show that this approach is a legitimate way to update many z * values in one step.Let zb * < B \u00b7 n, zb = {z1, z2,... eg} be a series of b samples of z. This will become a stack of image samples xb * < B * m * m, xb = {x1, x2,... xB}. For each pair (zi, xi) a loss Li can be calculated. Updating for zi would then be zi \u00b2 zi \u2212 \u03b1dLidzi If the rebuild loss is calculated over a stack, then the stack rebuild loss would be normal i = {1.2... B} Li, and the update would be: zbL = Zi \u00b2 zb (eg) a large stack that these stacks rebuild losses are normal, and the update would be: zbL = a valid stack zi (2) (Li + L3) that all stacks Li (+ L4) to just 1 stack (LMB) (LMB) = 1 LMB (LMB)."}, {"heading": "2.3 Using Prior Knowledge Of P(Z)", "text": "If P (Z) is a uniform distribution, regularization terms can be added after updating the cost function, punishing statistics that are not consistent with P (Z) = N [\u00b5, \u03c3]. If each of the d values in z < d is drawn independently and from identical distributions, and provided that d is sufficiently large, we can use statistics of values in z to add regularization terms in z < d. If P (Z) is drawn independently and from identical distributions, we can update the values in z, for example, to achieve an average distribution in z, and if P (Z) is a small distribution with identical distributions, and provided d is sufficiently large, we can use the statistics of values in z to add regularization terms in z."}, {"heading": "3 Relation to Previous Work", "text": "This approach of deriving z from x has similarities to the work of Zhu et al. [12]; we now highlight the differences between the two approaches and the advantages of our approach compared to that of Zhu et al. [12]. Primarily, we deal with issues related to batch normalization by showing that a mixed batch of image samples can be reversed to obtain latent z-codings. Potential problems that arise when using batch normalization are not discussed by Zhu et al. [12] The generator of a GAN is trained to generate image samples x-X from a z-Z pattern drawn from a previous distribution P (Z). This means that some z-values are more likely than other z-values. Therefore, it makes sense that the derived z-samples also come from (or at least near) P (Z). We introduce hard and soft constraints that can be used during the optimization process to manipulate the specifics."}, {"heading": "4 \u201cPre-trained\u201d Models", "text": "We train four models on two different datasets, MNIST and Omniglot [8]. To compare the effects of regularization or clipping using a normal or uniform prior distribution, we train networks on each dataset using each previous one - a total of four models."}, {"heading": "4.1 MNIST", "text": "The MNIST dataset consists of 60k samples of handwritten digits, 0 to 9. The dataset is divided into 50k samples for training and 10k samples for the test. Both the training dataset and the test dataset contain examples of the digits 0 to 9. Generator and discriminator networks for learning MNIST digits are detailed in Table 1. Networks were trained for 500 iterations of batch size 128, learning rate 0.002 with Adam updates. Networks are trained on 50k MNIST training samples covering all 10 category.Fig.1 shows examples of 100 random generations of MNIST networks trained using uniform and normal distributions."}, {"heading": "4.2 Omniglot", "text": "The Omniglot dataset [8] consists of characters from 50 different alphabets, with each alphabet having at least 14 different characters; the Omniglot dataset has a background dataset that is used for training and a test dataset; the background dataset consists of characters from 30 fonts, while the test dataset consists of characters from the other 20. Note that the characters in the training and test dataset come from different fonts; generator and discriminator networks for learning Omniglot characters [8] are the same as in previous work [2]; the network is trained only on the background dataset, for 2000 iterations with random batches of size 128 using Adam updates with a learning rate of 0.002; the latent coding has the dimension d = 100."}, {"heading": "5 Experiments", "text": "These experiments are designed to evaluate the proposed inversion process. A valid inversion process should map an image sample, x-X, to a z-Z, so that when z-Z is passed through the generative part of the GAN, an image is generated, G (z-Z), that is close to the original image, x. In our experiments, we selected a random batch of images, x-X, and applied it to the generator network by reversing this batch of four generators: Two trained to generate MNIST digits, and two trained to generate Omniglot digits. In each case, the networks were trained to generate from z-Z, with P (Z) being either a uniform or a normal distribution. To reverse a batch of image samples, we minimized the cost function described by Eqn."}, {"heading": "5.1 Evaluation Methods", "text": "For quantitative evaluation of the quality of image reconstruction, we take the mean absolute pixel error across all reconstructions for each of the reconstruction methods. For qualitative evaluation, we show pairs of x and their reconstruction, G (z \u043a). By visualizing the reversals, we can assess the extent to which the number or character identity is maintained. In addition, we can visually evaluate with the MNIST dataset whether the number style is also maintained."}, {"heading": "6 Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.1 MNIST", "text": "Each MNIST digit is drawn in a unique style; a successful inversion of the MNIST digits should retain both the style and identity of the digit. In Fig. 2, we show a random set of 20 pairs of original images, x, and their reconstructions, G (z *). In general, the reversals preserve both style and identity well. By visual inspection alone, it is not clear whether or not regulation methods improve the inversion process. Table 2 records the absolute mean reconstruction error. The results suggest that the regulation techniques we use have not improved the inversion. This is a positive result, as it suggests that inversion is possible without regulation, which means that the inversion process can be independent of the noise process used. This also indicates that regions outside P (Z) may be able to produce meaningful examples from the data distribution."}, {"heading": "6.2 Omniglot", "text": "Omniglot inversions are a particular challenge, as we try to find a set of z * for a set of letters, x, from alphabets that were not included in the training data. This presents the inversion process with a challenge of reversing samples from alphabets that it has not seen before, using information about alphabets it has seen. Original and reconstructed samples are shown in Fig. 3. Generally, the reconstructions are sharp and able to capture fine details such as small circles and edges. There is a one case of severe failure in Fig. 3 where the top example did not invert the sample. A comparison of reconstruction errors with and without regulation is shown in Table 3. These results suggest that regulation does not improve inversion and that good inversion without regulation is possible."}, {"heading": "7 Conclusion", "text": "It has also been shown that images along projections in Z-space also have visual similarities [10]. In order to exploit the structure of Z for discriminatory tasks, it is necessary to invert this process in order to obtain a latent encoding for an image x-X, the generator must also show interesting properties of the learned generative model. We propose a process in which the generator is inverted for all pre-learned GAN in order to obtain a latent encoding for the image x-X. We presented candidate regulation methods that can be used depending on the previous distribution of lateral space."}, {"heading": "Acknowledgements", "text": "We would like to thank the Research Council for Engineering and Physics for its support with a doctoral scholarship."}], "references": [{"title": "InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets", "author": ["Xi Chen"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2016}, {"title": "Task Specific Adversarial Cost Function", "author": ["Antonia Creswell", "Anil A Bharath"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2016}, {"title": "Adversarial Feature Learning", "author": ["Jeff Donahue", "Philipp Kr\u00e4henb\u00fchl", "Trevor Darrell"], "venue": "arXiv preprint arXiv:1605.09782", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2016}, {"title": "Long-term recurrent convolutional networks for visual recognition and description", "author": ["Jeffrey Donahue"], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2015}, {"title": "Adversarially Learned Inference", "author": ["Vincent Dumoulin"], "venue": "arXiv preprint arXiv:1606.00704", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2016}, {"title": "Generative adversarial nets", "author": ["Ian Goodfellow"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2014}, {"title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift", "author": ["Sergey Ioffe", "Christian Szegedy"], "venue": "Proceedings of The 32nd International Conference on Machine Learning", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2015}, {"title": "Human-level concept learning through probabilistic program induction", "author": ["Brenden M Lake", "Ruslan Salakhutdinov", "Joshua B Tenenbaum"], "venue": "Science", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "Understanding deep image representations by inverting them", "author": ["Aravindh Mahendran", "Andrea Vedaldi"], "venue": "IEEE conference on computer vision and pattern recognition (CVPR). IEEE", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2015}, {"title": "Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks", "author": ["Alec Radford", "Luke Metz", "Soumith Chintala"], "venue": "Proceedings of the 5th International Conference on Learning Representations (ICLR) - workshop track", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2016}, {"title": "Improved Techniques for Training GANs", "author": ["Tim Salimans"], "venue": "Advances in Neural Information Processing Systems (to appear)", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2016}, {"title": "Generative Visual Manipulation on the Natural Image Manifold", "author": ["Jun-Yan Zhu"], "venue": "European Conference on Computer Vision. Springer", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2016}], "referenceMentions": [{"referenceID": 9, "context": "Generative adversarial networks (GANs) [10, 6] are a class of generative model which are able to generate realistic looking images of faces, digits and street numbers [10].", "startOffset": 39, "endOffset": 46}, {"referenceID": 5, "context": "Generative adversarial networks (GANs) [10, 6] are a class of generative model which are able to generate realistic looking images of faces, digits and street numbers [10].", "startOffset": 39, "endOffset": 46}, {"referenceID": 9, "context": "Generative adversarial networks (GANs) [10, 6] are a class of generative model which are able to generate realistic looking images of faces, digits and street numbers [10].", "startOffset": 167, "endOffset": 171}, {"referenceID": 9, "context": "[10] demonstrated that generative adversarial networks (GANs) learn a \u201crich linear structure\" meaning that algebraic operations in Z-space often lead to meaningful generations in image space.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "Recently, it has also become desirable to be able to access Z-space in order to manipulate original images [12].", "startOffset": 107, "endOffset": 111}, {"referenceID": 9, "context": "Mapping from image space, X , to Z-space is non-trivial, as it requires inversion of the generator, which is often a many layered, non-linear model [10, 6, 1].", "startOffset": 148, "endOffset": 158}, {"referenceID": 5, "context": "Mapping from image space, X , to Z-space is non-trivial, as it requires inversion of the generator, which is often a many layered, non-linear model [10, 6, 1].", "startOffset": 148, "endOffset": 158}, {"referenceID": 0, "context": "Mapping from image space, X , to Z-space is non-trivial, as it requires inversion of the generator, which is often a many layered, non-linear model [10, 6, 1].", "startOffset": 148, "endOffset": 158}, {"referenceID": 4, "context": "[5] and Donahue et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] proposed learning a third, decoder network alongside the generator and discriminator to map image samples back to Z-space.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4], often fail to preserve style and character class.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "For the case of MNIST digits, our proposed inversion technique ensures that digits generated from inferred Z\u2019s maintain both the style and character class of the image from which the Z was inferred, better than those in previous work [3].", "startOffset": 234, "endOffset": 237}, {"referenceID": 10, "context": "However, it is possible that a single x value may map to several z representations, particularly if the generator collapses [11].", "startOffset": 124, "endOffset": 128}, {"referenceID": 8, "context": "This is very different to a discriminative model, where multiple images, may often be described by the same representation vector [9], particularly when a discriminative model learns representations tolerant to variations.", "startOffset": 130, "endOffset": 133}, {"referenceID": 8, "context": "[9], however instead of inverting a representation to obtain the image that was responsible for it, we invert an image to discover the latent representation that generated it.", "startOffset": 0, "endOffset": 3}, {"referenceID": 10, "context": "GAN training is non-trivial because the optimal solution is a saddle point rather than a minimum [11].", "startOffset": 97, "endOffset": 101}, {"referenceID": 9, "context": "[10] that to achieve more stable GAN training it is necessary to use batch normalisation [7].", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "[10] that to achieve more stable GAN training it is necessary to use batch normalisation [7].", "startOffset": 89, "endOffset": 92}, {"referenceID": 10, "context": "To prevent this problem, it would be ideal to use virtual batch normalisation [11], where statistics are calculated over a separate batch.", "startOffset": 78, "endOffset": 82}, {"referenceID": 9, "context": "100 [10]), it is unrealistic to expect the statistics of a single z to match those of the prescribed prior.", "startOffset": 4, "endOffset": 8}, {"referenceID": 11, "context": "[12]; we now highlight the differences between the two approaches and the benefits of our approach over that of Zhu et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[12].", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[12].", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[12] calculate reconstruction loss, by comparing the features of x and G(z\u2217) extracted from layers of AlexNet, a CNN trained on natural scenes.", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "We train four models on two different datasets, MNIST and Omniglot [8].", "startOffset": 67, "endOffset": 70}, {"referenceID": 7, "context": "The Omniglot dataset [8] consists of characters from 50 different alphabets, where each alphabet has at least 14 different characters.", "startOffset": 21, "endOffset": 24}, {"referenceID": 7, "context": "The generator and discriminator networks for learning Omniglot characters [8] are the same as those used in previous work [2].", "startOffset": 74, "endOffset": 77}, {"referenceID": 1, "context": "The generator and discriminator networks for learning Omniglot characters [8] are the same as those used in previous work [2].", "startOffset": 122, "endOffset": 125}, {"referenceID": 9, "context": "It has been shown that z values that are close in Z-space produce images that are visually similar in image space, X [10].", "startOffset": 117, "endOffset": 121}, {"referenceID": 9, "context": "It has also been shown that images along projections in Z-space also have visual similarities [10].", "startOffset": 94, "endOffset": 98}], "year": 2016, "abstractText": "Generative adversarial networks (GANs) learn to synthesise new samples from a high-dimensional distribution by passing samples drawn from a latent space through a generative network. When the high-dimensional distribution describes images of a particular data set, the network should learn to generate visually similar image samples for latent variables that are close to each other in the latent space. For tasks such as image retrieval and image classification, it may be useful to exploit the arrangement of the latent space by projecting images into it, and using this as a representation for discriminative tasks. GANs often consist of multiple layers of non-linear computations, making them very difficult to invert. This paper introduces techniques for projecting image samples into the latent space using any pre-trained GAN, provided that the computational graph is available. We evaluate these techniques on both MNIST digits and Omniglot handwritten characters. In the case of MNIST digits, we show that projections into the latent space maintain information about the style and the identity of the digit. In the case of Omniglot characters, we show that even characters from alphabets that have not been seen during training may be projected well into the latent space; this suggests that this approach may have applications in one-shot learning.", "creator": "LaTeX with hyperref package"}}}