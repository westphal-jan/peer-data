{"id": "1611.05955", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Nov-2016", "title": "A Characterization of Prediction Errors", "abstract": "Understanding prediction errors and determining how to fix them is critical to building effective predictive systems. In this paper, we delineate four types of prediction errors and demonstrate that these four types characterize all prediction errors. In addition, we describe potential remedies and tools that can be used to reduce the uncertainty when trying to determine the source of a prediction error and when trying to take action to remove a prediction errors.", "histories": [["v1", "Fri, 18 Nov 2016 02:33:10 GMT  (135kb,D)", "http://arxiv.org/abs/1611.05955v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["christopher meek"], "accepted": false, "id": "1611.05955"}, "pdf": {"name": "1611.05955.pdf", "metadata": {"source": "CRF", "title": "A Characterization of Prediction Errors", "authors": ["Christopher Meek"], "emails": [], "sections": [{"heading": "Introduction", "text": "After all, prediction errors arise in interactive machine learning systems (e.g. Fails and Olsen 2003), in machine learning (e.g. Simard et al 2014), and when statisticians, scientists, and engineers build prediction systems. Our goal in this paper is to provide a comprehensive categorization of the types of prediction errors and to provide guidance on actions that can be taken to correct prediction errors. We suspect that this will be helpful for both experts and non-experts who are trying to make machine learning and statistical models usable in the construction of predictive systems.Our characterization of prediction errors includes four top-level categories: error description, representation, learner, and boundary errors. Each of these types of errors is associated with specific defects that can potentially be corrected. In addition, we prove that categorization into these types of errors is sufficient to characterize all prediction errors, and we can also take action to remove them from the target."}, {"heading": "Related Work", "text": "An excellent example of this work is the work of Amershi et al (2015), which also provides references to other related work. Our categorization of predictive errors expands the informal categorization of Amershi et al (2015). In this work, the authors describe potential sources of predictive errors in the development of tools for identifying and researching predictive errors. Specifically, they consider three sources of error: insufficient data, trait defects, and mislabeled data. In our categorization, errors of insufficient data are a specific type of learning errors that we call objective errors (they do not take into account other types of learning errors), trait defects are a specific type of representative Xiv: 161 1.05 955v 1 [cs.L G] 18 Nov 201 6error, which we call feature blindness and mislabeled data. Amershet al (2015) consider epicity not to be a boundary between 1995 (the invention of hell) and 1996 (the formation of the theory)."}, {"heading": "Prediction Errors", "text": "In this section, we define the number of prediction errors that can occur when a teacher provides a machine for classifying objects by providing examples and features. (In addition, we provide essential definitions for the rest of the work.) We are interested in developing a classification of objects that identify certain objects and X. (We use y and yi for certain labels and Y to mark the space of possible labels.) A classification function is a function from X to Y that identifies a series of classification functions designated by C = X \u2192 Y. (We use c) to indicate the target classification that the teacher wants to teach the machine. (An essential element that a teacher offers are functions that turn maps into scalar values values. (or gi) is a function of objects into real numbers (i.e. fi \u2192 R)."}, {"heading": "A Characterization of Prediction Errors", "text": "In this section we develop a categorization for prediction errors taking into account both the training set and generalization errors. We also show that our categorization is exhaustive, that is, we offer a characterization of prediction errors. Our categorization refers to a specific training set T, feature set F, and learning algorithm L. We describe four error categories: errors, presentation errors, learning errors, and boundary errors. Generalization errors are of a different nature than prediction errors from the training set T, feature set F, and learning algorithm L, as they are not included in the training set. This difference is important because the teacher can only recognize a generalization error if they provide a designation for an object that is not included in the training set. We classify the types of generalization errors in relation to a specific training set T, feature set F, and learning algorithm L, using the result of the addition of a training set X (correctly added to the training set X)."}, {"heading": "Mislabeling Errors", "text": "A labeling error is an object labeled in such a way that the label does not match the target classification function (i.e., a labeled example (x, y) that y 6 = c * (x)). At first glance, it is not clear that labeling errors have anything to do with a prediction error, but labeling errors can lead to prediction errors. In particular, if the learned classifier matches the label of a wrongly labeled object, a prediction error occurs. For example, if we have only one labeled object (x, 1) in a training set and it is labeled incorrectly, then any consistent classifier will result in a prediction error. This type of prediction error occurs due to an error by the teacher (a.k.a. labeler) who provided a mislabeled example. We assume that a labeling error, including a 2014 teacher, may occur due to a labeling error in the labeling function."}, {"heading": "Learner Errors", "text": "A learning error is a predictive error arising from the fact that the learner does not find a classification function that correctly predicts the learning sentence when such a learnable classifier exists (i.e., c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-c-t-t-t-t-t-t-t"}, {"heading": "Representation Errors", "text": "A display error is a predictive error that arises from the fact that there is no learnable classification function that correctly predicts the learning sentence (i.e., that we use the advanced learning sentence T.) Display errors arise from a restriction of the learning algorithm, a restriction of the learning algorithm, or both. Specifically, an error may occur due to the characteristic blindness of the learning algorithm - it does not have access to features that distinguish objects - or that the hypotheses class of the learning algorithm is impoverished (e.g. when trying to learn the X-ray value or function with a linear classifier)."}, {"heading": "Boundary Errors", "text": "Our last prediction error is a kind of generalization error. A boundary error is a prediction error for an object x if the addition (x, c \u0445 (x)) to the training set results in a classification function c \u2032 that correctly predicts the extended training set (i.e. c = L (F, T) and c \u2032 = L (F, T) and c (x) 6 = c \u2032 (x) = c \u0445 (x)))."}, {"heading": "Characterization of Prediction Errors", "text": "We predict this section with the prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-forecast-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-prediction-forecast-forecast-forecast-forecast-forecast-forecast-forecast-forecast-forecast-forecast-forecast-forecast-forecast-forecast-forecast-forecast-"}, {"heading": "Detecting and Removing Types of Prediction Errors", "text": "In this section, we discuss the problem of identifying the type of prediction error that occurs while a teacher teaches a classification function. We also discuss a possible approach to reducing the effort required by the teacher to detect and eliminate prediction errors."}, {"heading": "Detecting Boundary Errors", "text": "A borderline error can only occur in a teaching protocol where there are labeled examples that are not included in a training set. A most common scenario in which this occurs is when there is a test set that is used to get an estimate of the predictive function of the classification function learned. A teaching protocol can automatically detect whether a predictive error is a borderline error by including the example in the training set and determining whether the resulting classification function correctly predicts the error. A teaching protocol can potentially use such a test to select, for example, if it samples more examples in a region with demonstrable ignorance of the borderline. This is related to the motivation to use uncertainty samples as an active learning strategy (Settles 2012)."}, {"heading": "Detecting and Removing Learner Errors", "text": "It is possible to eliminate learning errors completely by opting for consistent learning algorithm = consistent learning functions, as the following sentence shows. Proposition 3. If there is a training set predictive error for traits F and a consistent learning algorithm L, then the error must be a misnomer or representational error. Proof Recall the definition of a consistent learning algorithm; a consistent learning algorithm gives a classification function that does this. To prove the thesis, we assume that there is an objective predictive error that is not a mislabeling or representational error. From Proposition 1 we know that there must be a learning error that can be faulty. In this case, there is a learnable classification function that correctly classifies the learning set. From the consistency of L and the lack of representational or mislabeling errors, we know that L (F) is the error that T can be correctly classified as a contradiction."}, {"heading": "Representation and Mislabeling Errors", "text": "Next, we look at the problem of recognition of representation and labeling errors under the assumption that we do not have learning errors. To see this, we consider, for example, from proposal 3, that this is the situation when we use a consistent learning algorithm. In general, we cannot distinguish between labeling errors and presentation errors. To see this, we consider a set of binary classification exercises with two objects {(x1, 1), (x2, 0)}. In this situation, it is possible that the target classification function is the constant function c-x-1 and the designation for x2 is a labeling error, or that there is a function f1 that distinguishes the two objects (e.g. f1 (x1) = 5 and f1 (x2) = 7). In this case, there is a representation error. While one cannot hope to automatically distinguish labeling and display errors, one can hope that the teacher will recognize such errors and be presented to the teacher."}, {"heading": "Discussion", "text": "We begin our discussion with the presentation of a teaching protocol by which a teacher could teach a classification function to a machine, providing a means of both summarizing our results and highlighting outstanding problems.Algorithm 1 Error-Driven-Teaching-Protocol Input Consistent learning algorithm L, Set of objects X. T = {} / Training Set T-X \u00d7 Y F = {} / Feature Set F-F = L (T, F); while! Terminate () do (x, y) = Add-labeled-example (X, F, L); T = T-labeled (x, y); c = L (T, F); Removal of boundary errors by retraining while (x, y)."}, {"heading": "Proofs", "text": "We assume that the reader is familiar with basic concepts and elementary results from convex geometry and linear algebra."}, {"heading": "Acknowledgments", "text": "Thanks to Patrice Simard, Max Chickering, Jina Suh, Carlos Garcia Jurado Suarez and Xanda Schofield for helpful discussions about prediction errors."}], "references": [{"title": "Modeltracker: Redesigning performance analysis tools for machine learning", "author": ["S. Amershi", "M. Chickering", "S.M. Drucker", "B. Lee", "P. Simard", "J. Suh"], "venue": "Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems, CHI \u201915, 337\u2013346. New York, NY, USA: ACM.", "citeRegEx": "Amershi et al\\.,? 2015", "shortCiteRegEx": "Amershi et al\\.", "year": 2015}, {"title": "Queries revisited", "author": ["D. Angluin"], "venue": "Theor. Comput. Sci. 313(2):175\u2013194.", "citeRegEx": "Angluin,? 2004", "shortCiteRegEx": "Angluin", "year": 2004}, {"title": "Interactive machine learning", "author": ["J.A. Fails", "Olsen", "D.R. Jr."], "venue": "Proceedings of the 8th International Conference on Intelligent User Interfaces, IUI \u201903, 39\u201345. New York, NY, USA: ACM.", "citeRegEx": "Fails et al\\.,? 2003", "shortCiteRegEx": "Fails et al\\.", "year": 2003}, {"title": "Generalized teaching dimensions and the query complexity of learning", "author": ["T. Heged\u0171s"], "venue": "Proceedings of the Eighth Annual Conference on Computational Learning Theory, COLT \u201995, 108\u2013117. New York, NY, USA: ACM.", "citeRegEx": "Heged\u0171s,? 1995", "shortCiteRegEx": "Heged\u0171s", "year": 1995}, {"title": "How many queries are needed to learn? J", "author": ["L. Hellerstein", "K. Pillaipakkamnatt", "V. Raghavan", "D. Wilkins"], "venue": "ACM 43(5):840\u2013862.", "citeRegEx": "Hellerstein et al\\.,? 1996", "shortCiteRegEx": "Hellerstein et al\\.", "year": 1996}, {"title": "\u00dcber tschebyscheffsche ann\u00e4herungsmethoden", "author": ["P. Kirchberger"], "venue": "Mathematishe Annalen 57:509\u2013540.", "citeRegEx": "Kirchberger,? 1903", "shortCiteRegEx": "Kirchberger", "year": 1903}, {"title": "Structured labeling for facilitating concept evolution in machine learning", "author": ["T. Kulesza", "S. Amershi", "R. Caruana", "D. Fisher", "D. Charles"], "venue": "Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI \u201914, 3075\u20133084. New York, NY, USA: ACM.", "citeRegEx": "Kulesza et al\\.,? 2014", "shortCiteRegEx": "Kulesza et al\\.", "year": 2014}, {"title": "Active Learning", "author": ["B. Settles"], "venue": "Synthesis Lectures on Artificial Intelligence and Machine Learning. Morgan & Claypool.", "citeRegEx": "Settles,? 2012", "shortCiteRegEx": "Settles", "year": 2012}, {"title": "Simple proof of a theorem of P", "author": ["M. Shimrat"], "venue": "Kirchberger. Pacific J. Math. 5(3):361\u2013362.", "citeRegEx": "Shimrat,? 1955", "shortCiteRegEx": "Shimrat", "year": 1955}, {"title": "ICE: Enabling Non-Experts to Build Models Interactively for Large-Scale Lopsided Problems", "author": ["P. Simard", "D. Chickering", "A. Lakshmiratan", "D. Charles", "L. Bottou", "C. Suarez", "D. Grangier", "S. Amershi", "J. Verwey", "J. Suh"], "venue": "ArXiv e-prints.", "citeRegEx": "Simard et al\\.,? 2014", "shortCiteRegEx": "Simard et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 7, "context": "This is related to the motivation for using uncertainty sampling as an active learning strategy (Settles 2012).", "startOffset": 96, "endOffset": 110}, {"referenceID": 5, "context": "Lemma 1 [Kirchberger 1903; Shimrat 1955] Two finite sets S, T \u2282 R are strictly separable by some hyperplane if and only if for every set U consisting of at most d+2 points from S \u222a T the sets U \u2229 S and U \u2229 T can be strictly separated.", "startOffset": 8, "endOffset": 40}, {"referenceID": 8, "context": "Lemma 1 [Kirchberger 1903; Shimrat 1955] Two finite sets S, T \u2282 R are strictly separable by some hyperplane if and only if for every set U consisting of at most d+2 points from S \u222a T the sets U \u2229 S and U \u2229 T can be strictly separated.", "startOffset": 8, "endOffset": 40}], "year": 2016, "abstractText": "Understanding prediction errors and determining how to fix them is critical to building effective predictive systems. In this paper, we delineate four types of prediction errors (mislabeling, representation, learner and boundary errors) and demonstrate that these four types characterize all prediction errors. In addition, we describe potential remedies and tools that can be used to reduce the uncertainty when trying to determine the source of a prediction error and when trying to take action to remove a prediction error.", "creator": "LaTeX with hyperref package"}}}