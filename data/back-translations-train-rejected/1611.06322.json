{"id": "1611.06322", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Nov-2016", "title": "Spotting Rumors via Novelty Detection", "abstract": "Rumour detection is hard because the most accurate systems operate retrospectively, only recognizing rumours once they have collected repeated signals. By then the rumours might have already spread and caused harm. We introduce a new category of features based on novelty, tailored to detect rumours early on. To compensate for the absence of repeated signals, we make use of news wire as an additional data source. Unconfirmed (novel) information with respect to the news articles is considered as an indication of rumours. Additionally we introduce pseudo feedback, which assumes that documents that are similar to previous rumours, are more likely to also be a rumour. Comparison with other real-time approaches shows that novelty based features in conjunction with pseudo feedback perform significantly better, when detecting rumours instantly after their publication.", "histories": [["v1", "Sat, 19 Nov 2016 07:23:10 GMT  (69kb,D)", "http://arxiv.org/abs/1611.06322v1", null]], "reviews": [], "SUBJECTS": "cs.SI cs.CL cs.IR", "authors": ["yumeng qin", "dominik wurzer", "victor lavrenko", "cunchen tang"], "accepted": false, "id": "1611.06322"}, "pdf": {"name": "1611.06322.pdf", "metadata": {"source": "CRF", "title": "Spotting Rumors via Novelty Detection", "authors": ["Yumeng Qin", "Dominik Wurzer"], "emails": ["yumeng.qin@whu.edu.cn", "s1157979@sms.ed.ac.uk", "vlavrenk@inf.ed.ac.uk", "cctang@whu.edu.cn"], "sections": [{"heading": "1 Introduction", "text": "In social media, news is decentralized because it provides everyone with the means to efficiently report and disseminate information. Unlike traditional news wires, information is disseminated through social media without intensive investigation, fact-checking and background checks, and the combination of ease and quick sharing of information provides fertile breeding ground for rumor, misinformation and disinformation. Social media users tend to share controversial information in order to verify it, and ask for the opinions of their followers (Zhao et. al, 2015), which increases the pace of dissemination of rumor and the reach of rumor. Rumor and deliberate disinformation have already led to public statements to verify it. Cases in Germany and Austria show how misleading and false information about refugees is."}, {"heading": "1.1 Related Work", "text": "Prior to the detection of rumors, scientists were already investigating the related problem of assessing the credibility of information (Castillo et. al. 2011; Richardson et. al., 2003). Unfortunately, automated detection of rumors on social media has become a popular field of research that is also immediately based on assessing the credibility of news and its sources. The most successful methods proposed focus on classifying lexical, user-centric, graphically-based graphics based on a study by Castillo et. al (2011), which pioneered technical features for assessing credibility on Twitter (Liu et. al, 2015). They observed a significant correlation between the trustworthiness of a tweet with more contextual characteristics, including polarized tags."}, {"heading": "2 Rumour Detection", "text": "The Cambridge Dictionary defines a rumor as information of dubious or unconfirmed truth. We rely on a classification using SVM, the state-of-the-art approach to detecting novelties. Numerous features for detecting rumors in social media have been proposed, many of which stem from an original study on the credibility of information by Castillo et. al (2011). Unfortunately, the most successful features currently are based on information based on graph distribution and clusters that can only be calculated retrospectively, rendering them virtually useless in detecting rumors early on. We are introducing two new classes of features, one based on novelty, the other on pseudo-feedback. Both categories of features improve detection accuracy early on when information is limited."}, {"heading": "2.1 Problem Statement", "text": "Therefore, the prediction takes place in real time with a single pass over the data. Formally, we label the document coming from the stream S with dt: {d0, d1,... dn} at the time of publication. After the arrival of the document dt, we calculate its corresponding characteristic vector fd, t. Based on fd, t and the weight vector w obtained previously, we calculate the rumor value RSd, t = wT \u00b7 fd, t. The rumor prediction is based on a fixed threshold strategy in relation to the profile value. We predict that the message dt is likely to become a rumor if its rumor value exceeds the detection threshold RSd, t > profile value. The optimal parameter setting for the weight vector w and detection threshold in the short term are learned on a test to maximize the prediction accuracy."}, {"heading": "2.2 Novelty-based Features", "text": "In order to increase the performance of immediate detection, we compensate for the lack of future information by consulting additional data sources. In particular, we use news articles that are considered to be of high credibility. This is reasonable, since, according to Petrovic et. al (2013), in most cases, news wires guide social media for news coverage. When a message arrives from a social media stream, we build features based on their novelty in terms of confirmed information in trusted sources. In short, the presence of information that is not confirmed by the official media is interpreted as an indication that it is a rumor. Note that this is similar to the definition of what is a rumor."}, {"heading": "2.3 Novelty Feature Construction", "text": "We examine two approaches to novelty calculation: one based on vector proximity, the other on kterm hashing. Calculation of novelties based on traditional vector proximity alone does not yield adequate performance due to the discrepancy between the length of messages and social media messages. To make the vector proximity applicable, we push a term level-based window whose length is similar to the average length of the social media message through each of the news articles, resulting in subdocuments whose length is similar to those of social media messages. Novelty is calculated using the term weighted tf-dot products between the social media subdocuments and all news subdocuments. Reversing the minimal similarity to the closest neighbor corresponds to the degree of novelty. The second approach to calculating novelty is based on kashing (Wurzer et. al, 2015), a recent advance in novelty that improves efficiency."}, {"heading": "2.4 Pseudo Feedback", "text": "The concept is based on the idea that documents that exhibit similar characteristics to previously detected rumors are also likely to be rumors. During detection, feedback about which of the previous documents describes a rumor is not provided. Therefore, we rely on \"pseudo\" feedback and consider all documents whose rumor rating exceeds a threshold to be true rumors. The PF function describes the maximum similarity between a new document and those previously considered as rumors. Similarities are measured by vector proximity in the termspace. Conceptually, PF relies on evidence of repetitive signals by increasing the rumor rating of future documents when they resemble a recently detected rumor."}, {"heading": "3 Experiments", "text": "The previous sections introduced two new categories of characteristics for detecting rumors. Now, we are testing their performance and impact on the effectiveness and efficiency of detection. In a streaming setting, documents continuously arrive one by one. We need our characteristics to calculate the Aumour score for each document instantly in a single pass across the data. Messages with high rumor values are considered likely to be rumors. The classification decision is based on an optimal threshold strategy based on the training set."}, {"heading": "3.1 Evaluation metrics", "text": "In addition, we use the standard TDT evaluation method (Allan et. al, 2000; NIST, 2008) with the official TDT3 evaluation scripts (NIST, 2008) using default settings. This method evaluates detection tasks using Detection Error Trade-off (DET) curves that show the trade-off between false and false alarm probability. DET diagrams provide a more comprehensive representation of effectiveness as stand-alone metrics (Allan et. al, 2000) and evaluate the efficiency of calculating proposed features, measured by throughput per second, when applied to a large number of messages."}, {"heading": "3.2 Data set", "text": "Social media rumor detection is a novel field of research with no official records. As license agreements prohibit data redistribution, no records from previous publications are available. Therefore, we followed previous researchers such as Liu et. al (2015) and Yang et. al (2012) and created our own dataset. Trusted Resources: We randomly collected 200 news articles on general topics commonly reported by news wires in our target period, ranging from news about celebrities and disasters to financial and political matters as shown in Table 1. Being active in Chinese social media, we collected news articles from Xinhua NewsAgency2, the leading news agency in China. To ensure fair evaluation, we collected the news articles before judging rumors without knowing what rumors we would later find. We also only look at news articles prior to the timestamps of social media messags.For our social media stream, we chose Newsina service with 15,000 active social media users, a social media agent."}, {"heading": "3.3 Rumour detection effectiveness", "text": "In fact, most of us are able to play by the rules that they have imposed on themselves, \"he said.\" But it's not like they are able to play by the rules. \"He added,\" It's not like they play by the rules. \"He added,\" It's not like they play by the rules. \"He added,\" It's not like they play by the rules. \"He added,\" It's not like they play by the rules, but it's like they play by the rules. \""}, {"heading": "3.4 Feature analysis", "text": "We group our 57 features into 7 categories, as shown in Table 6, and analyze their contribution by feature ablation, as illustrated in Table 5. Feature ablation illustrates the importance of a feature by measuring performance when it is removed from the feature set. Novelty features based on kterm hashing have been found to be dominant for instant detection of rumors (p < 0.05). \"Sentence char\" features, which include punctuation, hashtags, user symbols and URLs, accounted for the largest share of traditional features, followed by Part of Speech (\"POS\") and \"Extreme Word\" features. Our experiments found that \"sentiment\" and \"emotion\" features contribute the least to this. As they both result in significant performance declines, we conclude that they capture comparable information and are therefore compensated for any other information."}, {"heading": "3.5 Detecting unpopular rumours", "text": "Previous approaches to detecting rumors relied on repeated signals to form propagation graphs or cluster methods. In addition to causing detection delays, these methods are also blind to less popular rumors that do not go viral. In contrast, novel features require only a single message that allows them to detect even the smallest rumors. Examples of such small rumors are shown in Table 3. 3.6 Efficiency and scalability To demonstrate the high efficiency of computer novelties and pseudo-features, we implement a rumor detection system and measure its throughput when applied to 100k Weibos. We implement our system in C and run it with a single core on a 2.2GHz Intel Core i7-4702HQ. We measure throughput on an idle machine and the average observed performance over 5 runs. Figure 2 shows the performance in processing more and more Weibos. The average throughput of our Twittersystem is 7,000 tweets per second, or 27.5 tweets per volume, which is the average of the full volume."}, {"heading": "4 Conclusion", "text": "We have introduced two new categories of features that significantly improve the performance of instant detection of rumors: Novelty-based features consider the increased presence of unconfirmed information within a message to be indicative of a rumor. Pseudo-feedback features consider messages that resemble previously detected rumors to be more likely, even a rumor. Pseudo-feedback and its variant, recursive pseudo-feedback, allow the use of repeated signals without having to operate retrospectively. Our evaluation has shown that novelty and pseudo-feedback-based features are significantly more effective than other real-time and early detection bases when rumors are detected immediately after they are published. This advantage disappears when allowing increased detection delay. We have also shown that the proposed features can be calculated efficiently enough to work with the average Twitter and Sina Weiam, while maintaining space."}], "references": [{"title": "First story detection in TDT is hard", "author": ["James Allan", "Victor Lavrenko", "Hubert Jin"], "venue": "In Proceedings of the ninth international conference on Information and knowledge management", "citeRegEx": "Allan et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Allan et al\\.", "year": 2000}, {"title": "Topic Detection and Tracking: EventBased Information Organization", "author": ["James Allan"], "venue": null, "citeRegEx": "Allan.,? \\Q2002\\E", "shortCiteRegEx": "Allan.", "year": 2002}, {"title": "lv, rumours Detection in Chinese via Crowd Responses", "author": ["G. Cai", "R.H. Wu"], "venue": "ASONAM", "citeRegEx": "Cai and Wu,? \\Q2014\\E", "shortCiteRegEx": "Cai and Wu", "year": 2014}, {"title": "Information Credibility On Twitter[C", "author": ["C Castillo", "M Mendoza", "B. Poblete"], "venue": "The 20th International Conference on World Wide Web,", "citeRegEx": "Castillo et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Castillo et al\\.", "year": 2011}, {"title": "Prominent features of rumor propagation in online social media", "author": ["S. Kwon", "M. Cha", "K. Jung", "W. Chen", "Y. Wang"], "venue": "Data Mining (ICDM),", "citeRegEx": "Kwon et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Kwon et al\\.", "year": 2013}, {"title": "Real-time rumor debunking on twitter", "author": ["X. Liu", "A. Nourbakhsh", "Q. Li", "R. Fang", "S. Shah"], "venue": "Proceedings of the 24th ACM International Conference on Information and Knowledge Management. ACM,", "citeRegEx": "Liu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2015}, {"title": "Twitter Under Crisis: Can we Trust What we RT", "author": ["Mendoza M", "B Poblete", "C Castillo"], "venue": "The 1st Workshop on Social Media Analytics,", "citeRegEx": "M. et al\\.,? \\Q2010\\E", "shortCiteRegEx": "M. et al\\.", "year": 2010}, {"title": "Data streams: Algorithms and applications", "author": ["S. Muthukrishnan"], "venue": "Now Publishers Inc,", "citeRegEx": "Muthukrishnan.,? \\Q2005\\E", "shortCiteRegEx": "Muthukrishnan.", "year": 2005}, {"title": "Can Twitter replace Newswire for breaking news", "author": ["S. Petrovic", "M. Osborne", "R. McCreadie", "C. Macdonald", "I. Ounis", "L. Shrimpton"], "venue": "In Proc. of ICWSM,", "citeRegEx": "Petrovic et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Petrovic et al\\.", "year": 2013}, {"title": "rumour has it: Identifying Misinformation in Microblogs", "author": ["V. Qazvinian", "E. Rosengren", "D.R. Radev", "Q. Mei"], "venue": "EMNLP, July 27-31,", "citeRegEx": "Qazvinian et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Qazvinian et al\\.", "year": 2011}, {"title": "Trust Management for the Semantic Web", "author": ["M Richardson", "R Agrawal", "P Domingos"], "venue": "Lecture Notes in Computer Science,", "citeRegEx": "Richardson et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Richardson et al\\.", "year": 2003}, {"title": "False rumours Detection on Sina Weibo by Propagation Structures", "author": ["K. Wu", "S. Yang", "K. Zhu"], "venue": "In the Proceedings of ICDE,", "citeRegEx": "Wu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wu et al\\.", "year": 2015}, {"title": "Detecting rumour patterns in streaming social media, Guimi", "author": ["Shihan Wang", "Takao Terano"], "venue": null, "citeRegEx": "Wang and Terano,? \\Q2015\\E", "shortCiteRegEx": "Wang and Terano", "year": 2015}, {"title": "Tracking unbounded Topic Streams", "author": ["Dominik Wurzer", "Victor Lavrenko", "Miles Osborne"], "venue": "In the Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Wurzer et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wurzer et al\\.", "year": 2015}, {"title": "Twitter-scale New Event Detection via K-term Hashing", "author": ["Dominik Wurzer", "Victor Lavrenko", "Miles Osborne"], "venue": "In the Proceedings of the Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Wurzer et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wurzer et al\\.", "year": 2015}, {"title": "Enquiring Minds: Early Detection of Rumors in Social Media from Enquiry Posts", "author": ["Z. Zhao", "P. Resnick", "Q. Mei"], "venue": "In the Proceedings of WWW,", "citeRegEx": "Zhao et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Zhao et al\\.", "year": 2015}, {"title": "Realtime news certification system on sina weibo", "author": ["X. Zhou", "J. Cao", "Z. Jin", "X. Fei", "Y. Su", "J. Zhang", "D. Chu", "X Cao"], "venue": null, "citeRegEx": "Zhou et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Zhou et al\\.", "year": 2015}], "referenceMentions": [], "year": 2016, "abstractText": "Rumour detection is hard because the most accurate systems operate retrospectively, only recognising rumours once they have collected repeated signals. By then the rumours might have already spread and caused harm. We introduce a new category of features based on novelty, tailored to detect rumours early on. To compensate for the absence of repeated signals, we make use of news wire as an additional data source. Unconfirmed (novel) information with respect to the news articles is considered as an indication of rumours. Additionally we introduce pseudo feedback, which assumes that documents that are similar to previous rumours, are more likely to also be a rumour. Comparison with other real-time approaches shows that novelty based features in conjunction with pseudo feedback perform significantly better, when detecting rumours instantly after their publication.", "creator": "TeX"}}}