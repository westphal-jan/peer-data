{"id": "1611.06453", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Nov-2016", "title": "Fast Video Classification via Adaptive Cascading of Deep Models", "abstract": "Recent advances have enabled \"oracle\" classifiers that can classify across many classes and input distributions with high accuracy without retraining. However, these classifiers are relatively heavyweight, so that applying them to classify video is costly. We show that day-to-day video exhibits highly skewed class distributions over the short term, and that these distributions can be classified by much simpler models. We formulate the problem of detecting the short-term skews online and exploiting models based on it as a new sequential decision making problem dubbed the Online Bandit Problem, and present a new algorithm to solve it. When applied to recognizing faces in TV shows and movies, we realize end-to-end classification speedups of 2.5-8.5x/2.8-12.7x (on GPU/CPU) relative to a state-of-the-art convolutional neural network, at competitive accuracy.", "histories": [["v1", "Sun, 20 Nov 2016 00:21:32 GMT  (4052kb,D)", "http://arxiv.org/abs/1611.06453v1", null], ["v2", "Sun, 2 Jul 2017 02:17:00 GMT  (4068kb,D)", "http://arxiv.org/abs/1611.06453v2", "Accepted at IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017"]], "reviews": [], "SUBJECTS": "cs.CV cs.LG cs.NE", "authors": ["haichen shen", "seungyeop han", "matthai philipose", "arvind krishnamurthy"], "accepted": false, "id": "1611.06453"}, "pdf": {"name": "1611.06453.pdf", "metadata": {"source": "CRF", "title": "Fast Video Classification via Adaptive Cascading of Deep Models", "authors": ["Haichen Shen", "Seungyeop Han", "Matthai Philipose", "Arvind Krishnamurthy"], "emails": ["arvind}@cs.washington.edu,", "seungyeop.han@rubrik.com,", "matthaip@microsoft.com"], "sections": [{"heading": "1. Introduction", "text": "In fact, most people who are able to realize themselves, to put themselves in the center, have to put themselves in the center. In fact, it is so that they are able to realize themselves by putting themselves in the center, by putting themselves in the center, by putting themselves in the center."}, {"heading": "2. Related work", "text": "There is a long line of work on cost-sensitive classifications, epitomized perhaps by the cascading classification work of Viola and Jones [23]. The essence of this work is to treat classification as a sequential process that is reflected in its conclusion, typically through learning sequences that have low costs in terms of training data. [15] Cascades of CNNs have even been proposed, as we do. All of these techniques assume that the test data is i.e., non-sequential, that all training takes place before each exam, and that sketches are used to capture the cost structure."}, {"heading": "3. Class skew in day-to-day video", "text": "In this section, we analyze the skew in videos of everyday life that have been evaluated by YouTube. We have compiled a series of 30 videos ranging in length from 3 minutes to 20 minutes from five classes of daily activities: socialization, home repairs, cycling in urban areas, cooking and home tours. We expect this type of footage to come from a variety of sources such as movies, amateur productions of the kind, YouTube and portable videos.We try one in three frames consistent from these videos and apply state-of-the-art face (derived from [16]), scene [29] and object detectors that dominate in each sampled frame and portable videos.We assume that these \"oracle\" detectors can detect up to 2622 faces, 205 scenes and 1000 objects. \"For facial recognition, we draw the top scoring label for each face detected, and for the other, we just put the top scoring class on each object for detection."}, {"heading": "4. Specializing Models", "text": "This year, it is closer than ever before in the history of the country."}, {"heading": "5. Sequential Model Specialization", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1. The Oracle Bandit Problem (OBP)", "text": "Let us classify the cost of dividing up the individual epochs, in which the elements from each epoch are drawn independently of the corresponding distribution, into a sequence of \"epochs,\" in which elements from each epoch are drawn independently of the respective distribution. Thus, for the entire series, patterns are drawn from an abruptly altered, piecemeal stationary distribution. In the test period, neither the results nor the partitions are known.Let h have a classification that is called classifier."}, {"heading": "5.2. The Windowed -Greedy (WEG) Algorithm", "text": "The DM property is at the core of the minimization costs, which result in a good estimate of the actual distribution costs. (...) Essentially, if we can empirically estimate the current distribution costs (...) and ensure that the distribution costs (...) are not too high if the distribution costs (...) are not too high. \"(...) Note: The (high) one-time distribution rate (...) prohibits us from using a new distribution method (...) if the measures for researching and exploiting T-changes.The strategies discussed above could alternate between the current distribution and exploitation of a specialized classifier. (...) Unlike the standard bandit settings (...), where the actions are part of exploration and exploitation, so that the exploration would include random other specialized classifiers, in our\" oracle bandit \"setting other random specialized classifiers - and both will likely have high execution costs."}, {"heading": "6. Evaluation", "text": "We implemented the WAY algorithm with a classification runtime based on Caffe. [10] The system can be fed with videos to achieve classification results by detecting frames. Our goal was to measure both how well the large specialized model accelerations could be transferred from Table 1 to accelerations in different environments and to long, real-world videos, and to describe how elements of our design contributed to these accelerations."}, {"heading": "6.1. Synthetic experiments", "text": "First, we evaluate our system with synthetically generated data to study multiple settings. For this experiment, we generate a time series of images from standard large validation sets of CNNs that we use. Each test set consists of one or two segments in which a segment is defined by the number of dominant classes, the skew, and the duration in minutes. For each segment, we assume that the images appear at a fixed interval (1 / 6 seconds) and that each image from the test set is selected based on the slant of the segment. For a segment with 5 dominant classes and 90% skew, we select 5 classes as dominant classes and select an image with 90% probability from the dominant classes and an image with 10% probability from the other classes of image arrival lasting over 5 minutes. Images in a class are selected in a uniform random manner."}, {"heading": "6.2. Video experiments", "text": "This year, it has come to the point that it has never come as far as it has this year."}, {"heading": "7. Conclusion", "text": "We characterize imbalance in daily video, demonstrated that inclined distributions require much simpler CNNs, and developed new, very fast specialized CNNs. We formalize \"bandit\" style sequential model selection as an Oracle Bandit problem, and provide a new exploration / exploitation-based algorithm, Windowed - Greedy (WEG). Our solution accelerates face recognition in TV episodes and movies by 2.5-8.5 x on a GPU (2.8-12.7 x on a CPU) with little loss of accuracy compared to a modern revolutionary neural network."}], "references": [{"title": "Finite-time analysis of the multiarmed bandit problem", "author": ["P. Auer", "N. Cesa-Bianchi", "P. Fischer"], "venue": "Mach. Learn.,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2002}, {"title": "Do deep nets really need to be deep? In Advances in neural information processing", "author": ["J. Ba", "R. Caruana"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2014}, {"title": "Detecting actions, poses, and objects with relational phraselets", "author": ["C. Desai", "D. Ramanan"], "venue": "In Proceedings of the 12th European Conference on Computer Vision - Volume Part IV,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2012}, {"title": "Fast feature pyramids for object detection", "author": ["P. Doll\u00e1r", "R. Appel", "S. Belongie", "P. Perona"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "Long-term recurrent convolutional networks for visual recognition and description", "author": ["J. Donahue", "L.A. Hendricks", "S. Guadarrama", "M. Rohrbach", "S. Venugopalan", "K. Saenko", "T. Darrell"], "venue": "In CVPR,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "On upper-confidence bound policies for non-stationary bandit problems", "author": ["A. Garivier", "E. Moulines"], "venue": "In Proceedings of the 22nd International Conference on Algorithmic Learning Theory (ALT),", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2011}, {"title": "Deep compression: Compressing deep neural network with pruning, trained quantization and huffman coding", "author": ["S. Han", "H. Mao", "W.J. Dally"], "venue": "In Proceedings of the International Conference on Learning Representations (ICLR),", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2016}, {"title": "Learning both weights and connections for efficient neural network", "author": ["S. Han", "J. Pool", "J. Tran", "W. Dally"], "venue": "Proceedings of the Twentyninth Annual Conference on Neural Information Processing Systems (NIPS),", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "Struck: Structured output tracking with kernels", "author": ["S. Hare", "A. Saffari", "P.H.S. Torr"], "venue": "In 2011 International Conference on Computer Vision,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2011}, {"title": "Caffe: Convolutional architecture for fast feature embedding", "author": ["Y. Jia", "E. Shelhamer", "J. Donahue", "S. Karayev", "J. Long", "R. Girshick", "S. Guadarrama", "T. Darrell"], "venue": "In Proceedings of the 22nd ACM international conference on Multimedia (MM),", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "Large-scale video classification with convolutional neural networks", "author": ["A. Karpathy", "G. Toderici", "S. Shetty", "T. Leung", "R. Sukthankar", "L. Fei-Fei"], "venue": "In CVPR,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "Learning from a single labeled face and a stream of unlabeled data", "author": ["B. Kveton", "M. Valko"], "venue": "In Automatic Face and Gesture Recognition (FG),", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "Asymptotically efficient adaptive allocation rules", "author": ["T. Lai", "H. Robbins"], "venue": "Adv. Appl. Math.,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1985}, {"title": "Asymptotically efficient adaptive allocation rules", "author": ["T.L. Lai", "H. Robbins"], "venue": "Advances in applied mathematics,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1985}, {"title": "A convolutional neural network cascade for face detection", "author": ["H. Li", "Z. Lin", "X. Shen", "J. Brandt", "G. Hua"], "venue": "In CVPR,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2015}, {"title": "Deep face recognition", "author": ["O.M. Parkhi", "A. Vedaldi", "A. Zisserman"], "venue": "In BMVC,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2015}, {"title": "Detecting activities of daily living in first-person camera views", "author": ["H. Pirsiavash", "D. Ramanan"], "venue": "In Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2012}, {"title": "XNOR-Net: ImageNet Classification", "author": ["M. Rastegari", "V. Ordonez", "J. Redmon", "A. Farhadi"], "venue": "Using Binary Convolutional Neural Networks", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2016}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["K. Simonyan", "A. Zisserman"], "venue": "In Proceedings of the International Conference on Learning Representations (ICLR),", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2015}, {"title": "Reinforcement Learning, an introduction", "author": ["R. Sutton", "A. Barto"], "venue": "MIT Press/Bradford Books,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1998}, {"title": "Going deeper with convolutions", "author": ["C. Szegedy", "W. Liu", "Y. Jia", "P. Sermanet", "S. Reed", "D. Anguelov", "D. Erhan", "V. Vanhoucke", "A. Rabinovich"], "venue": "CoRR, abs/1409.4842,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2014}, {"title": "Online semi-supervised learning on quantized graphs", "author": ["M. Valko", "B. Kveton", "L. Huang", "D. Ting"], "venue": "In Proceedings of the Twenty-Sixth Conference Annual Conference on Uncertainty in Artificial Intelligence (UAI-", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2010}, {"title": "Rapid object detection using a boosted cascade of simple features", "author": ["P. Viola", "M. Jones"], "venue": "In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2001}, {"title": "A scalable approach to activity recognition based on object use", "author": ["J. Wu", "A. Osuntogun", "T. Choudhury", "M. Philipose", "J.M. Rehg"], "venue": "IEEE 11th International Conference on Computer Vision,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2007}, {"title": "Cost-sensitive tree of classifiers", "author": ["Z. Xu", "M. Kusner", "M. Chen", "K.Q. Weinberger"], "venue": "In ICML,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2013}, {"title": "Classifier cascades and trees for minimizing feature evaluation cost", "author": ["Z.E. Xu", "M.J. Kusner", "K.Q. Weinberger", "M. Chen", "O. Chapelle"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2014}, {"title": "Testcost sensitive classification on data with missing values", "author": ["Q. Yang", "C.X. Ling", "X. Chai", "R. Pan"], "venue": "IEEE Trans. Knowl. Data Eng.,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2006}, {"title": "Places: An image database for deep scene understanding", "author": ["B. Zhou", "A. Khosla", "A. Lapedriza", "A. Torralba", "A. Oliva"], "venue": "arXiv preprint arXiv:1610.02055,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2016}, {"title": "Learning deep features for scene recognition using places database", "author": ["B. Zhou", "A. Lapedriza", "J. Xiao", "A. Torralba", "A. Oliva"], "venue": "In Proceedings of the Twentyeighth Annual Conference on Neural Information Processing Systems (NIPS),", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2014}], "referenceMentions": [{"referenceID": 22, "context": "Since the seminal work of Viola and Jones [23] on face detection, one of the best-known techniques to speed up classification has been to structure the classifier as a cascade (or tree [26]) of simple classifiers such that \u201ceasy\u201d examples lead to early exits and are therefore classified faster.", "startOffset": 42, "endOffset": 46}, {"referenceID": 25, "context": "Since the seminal work of Viola and Jones [23] on face detection, one of the best-known techniques to speed up classification has been to structure the classifier as a cascade (or tree [26]) of simple classifiers such that \u201ceasy\u201d examples lead to early exits and are therefore classified faster.", "startOffset": 185, "endOffset": 189}, {"referenceID": 3, "context": "In fact, traditional cascades are most applicable in detection tasks [4], where the background is both much more common and easier to classify than the foreground.", "startOffset": 69, "endOffset": 72}, {"referenceID": 15, "context": "Distinct from the (two-class) detection setting in traditional cascading, recent advances in convolutional neural networks (CNNs) [16,21,29] have opened up the possibility of using a single, pre-trained \u201coracle\u201d classifier to recognize thousands of classes such as people, objects and scenes.", "startOffset": 130, "endOffset": 140}, {"referenceID": 20, "context": "Distinct from the (two-class) detection setting in traditional cascading, recent advances in convolutional neural networks (CNNs) [16,21,29] have opened up the possibility of using a single, pre-trained \u201coracle\u201d classifier to recognize thousands of classes such as people, objects and scenes.", "startOffset": 130, "endOffset": 140}, {"referenceID": 28, "context": "Distinct from the (two-class) detection setting in traditional cascading, recent advances in convolutional neural networks (CNNs) [16,21,29] have opened up the possibility of using a single, pre-trained \u201coracle\u201d classifier to recognize thousands of classes such as people, objects and scenes.", "startOffset": 130, "endOffset": 140}, {"referenceID": 20, "context": "When training such oracle classifiers, such as GoogLeNet [21] of VGGFace [16]), a small number of classes do not usually dominate the training set: for broad applicability, the classifier is trained assuming that all classes are more or less equally likely.", "startOffset": 57, "endOffset": 61}, {"referenceID": 15, "context": "When training such oracle classifiers, such as GoogLeNet [21] of VGGFace [16]), a small number of classes do not usually dominate the training set: for broad applicability, the classifier is trained assuming that all classes are more or less equally likely.", "startOffset": 73, "endOffset": 77}, {"referenceID": 15, "context": "For instance, we present a CNN that executes 60\u00d7 fewer FLOPs than the state-of-the art VGGFace [16] model, but has comparable accuracy when over 50% of faces come from the same 10 or fewer people.", "startOffset": 95, "endOffset": 99}, {"referenceID": 22, "context": "There is a long line of work on cost-sensitive classification, the epitome of which is perhaps the cascaded classification work of Viola and Jones [23].", "startOffset": 147, "endOffset": 151}, {"referenceID": 24, "context": "The essence of this line of work [25, 27] is to treat classification as a sequential process that may exit early if it is confident in its inference, typically by learning sequences that have low cost in expectation over training data.", "startOffset": 33, "endOffset": 41}, {"referenceID": 26, "context": "The essence of this line of work [25, 27] is to treat classification as a sequential process that may exit early if it is confident in its inference, typically by learning sequences that have low cost in expectation over training data.", "startOffset": 33, "endOffset": 41}, {"referenceID": 14, "context": "Recent work [15] has even proposed cascading CNNs as we do.", "startOffset": 12, "endOffset": 16}, {"referenceID": 2, "context": "Traditional sequential models such as probabilistic models [3, 17, 24] and Recurrent Neural Networks (RNNs) [5,11] are aimed at classifying instances that are not independent of each other.", "startOffset": 59, "endOffset": 70}, {"referenceID": 16, "context": "Traditional sequential models such as probabilistic models [3, 17, 24] and Recurrent Neural Networks (RNNs) [5,11] are aimed at classifying instances that are not independent of each other.", "startOffset": 59, "endOffset": 70}, {"referenceID": 23, "context": "Traditional sequential models such as probabilistic models [3, 17, 24] and Recurrent Neural Networks (RNNs) [5,11] are aimed at classifying instances that are not independent of each other.", "startOffset": 59, "endOffset": 70}, {"referenceID": 4, "context": "Traditional sequential models such as probabilistic models [3, 17, 24] and Recurrent Neural Networks (RNNs) [5,11] are aimed at classifying instances that are not independent of each other.", "startOffset": 108, "endOffset": 114}, {"referenceID": 10, "context": "Traditional sequential models such as probabilistic models [3, 17, 24] and Recurrent Neural Networks (RNNs) [5,11] are aimed at classifying instances that are not independent of each other.", "startOffset": 108, "endOffset": 114}, {"referenceID": 8, "context": "Similar to adaptive cascading, online learning methods [9, 12, 22] customize models at test time.", "startOffset": 55, "endOffset": 66}, {"referenceID": 11, "context": "Similar to adaptive cascading, online learning methods [9, 12, 22] customize models at test time.", "startOffset": 55, "endOffset": 66}, {"referenceID": 21, "context": "Similar to adaptive cascading, online learning methods [9, 12, 22] customize models at test time.", "startOffset": 55, "endOffset": 66}, {"referenceID": 0, "context": "Estimating distributions in sequential data and exploiting it is the focus of the multi-armed bandit (MAB) community [1, 13].", "startOffset": 117, "endOffset": 124}, {"referenceID": 12, "context": "Estimating distributions in sequential data and exploiting it is the focus of the multi-armed bandit (MAB) community [1, 13].", "startOffset": 117, "endOffset": 124}, {"referenceID": 5, "context": "Our Windowed -Greedy algorithm is strongly informed by the use of windows in [6] to handle non-stationarities and the well-known [20] -greedy scheme to balance exploration and exploitation.", "startOffset": 77, "endOffset": 80}, {"referenceID": 19, "context": "Our Windowed -Greedy algorithm is strongly informed by the use of windows in [6] to handle non-stationarities and the well-known [20] -greedy scheme to balance exploration and exploitation.", "startOffset": 129, "endOffset": 133}, {"referenceID": 1, "context": "Finally, much recent work has focused on reducing the resource consumption of (convolutional) neural networks [2, 7, 8, 18].", "startOffset": 110, "endOffset": 123}, {"referenceID": 6, "context": "Finally, much recent work has focused on reducing the resource consumption of (convolutional) neural networks [2, 7, 8, 18].", "startOffset": 110, "endOffset": 123}, {"referenceID": 7, "context": "Finally, much recent work has focused on reducing the resource consumption of (convolutional) neural networks [2, 7, 8, 18].", "startOffset": 110, "endOffset": 123}, {"referenceID": 17, "context": "Finally, much recent work has focused on reducing the resource consumption of (convolutional) neural networks [2, 7, 8, 18].", "startOffset": 110, "endOffset": 123}, {"referenceID": 15, "context": "[16]), scene [29] and object recognizers [19] to every sampled frame.", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "[16]), scene [29] and object recognizers [19] to every sampled frame.", "startOffset": 13, "endOffset": 17}, {"referenceID": 18, "context": "[16]), scene [29] and object recognizers [19] to every sampled frame.", "startOffset": 41, "endOffset": 45}, {"referenceID": 20, "context": "Object (1000 classes) [21] 68.", "startOffset": 22, "endOffset": 26}, {"referenceID": 27, "context": "Scene (205) [28] 58.", "startOffset": 12, "endOffset": 16}, {"referenceID": 15, "context": "Face (2622) [16] 95.", "startOffset": 12, "endOffset": 16}, {"referenceID": 9, "context": "Execution time is feedforward time of a single image without batching on Caffe [10], a Linux server with a 24-core Intel Xeon E5-2620 and an NVIDIA K20c GPU.", "startOffset": 79, "endOffset": 83}, {"referenceID": 20, "context": "In particular, we use the GoogLeNet [21] as our oracle model, for object recognition; the VGG Net 16-layer version for scene recognition [29]; and the VGGFace network [16] for face recognition.", "startOffset": 36, "endOffset": 40}, {"referenceID": 28, "context": "In particular, we use the GoogLeNet [21] as our oracle model, for object recognition; the VGG Net 16-layer version for scene recognition [29]; and the VGGFace network [16] for face recognition.", "startOffset": 137, "endOffset": 141}, {"referenceID": 15, "context": "In particular, we use the GoogLeNet [21] as our oracle model, for object recognition; the VGG Net 16-layer version for scene recognition [29]; and the VGGFace network [16] for face recognition.", "startOffset": 167, "endOffset": 171}, {"referenceID": 13, "context": "Unlike standard \u201cbandit\u201d settings [14], where the actions for exploration and exploitation belong to the same set, so that exploration would involve trying out random other specialized classifiers, in our \u201coracle bandit\u201d setting other random specialized classifiers are likely to have both low accuracy and high execution cost.", "startOffset": 34, "endOffset": 38}, {"referenceID": 5, "context": "Borrowing from the literature on non-stationary bandits [6], we therefore maintain a window Sj of samples initialized when we determine a new epoch j has started.", "startOffset": 56, "endOffset": 59}, {"referenceID": 9, "context": "We implemented the WEG algorithm with a classification runtime based on Caffe [10].", "startOffset": 78, "endOffset": 82}], "year": 2017, "abstractText": "Recent advances have enabled \u201coracle\u201d classifiers that can classify across many classes and input distributions with high accuracy without retraining. However, these classifiers are relatively heavyweight, so that applying them to classify video is costly. We show that day-to-day video exhibits highly skewed class distributions over the short term, and that these distributions can be classified by much simpler models. We formulate the problem of detecting the short-term skews online and exploiting models based on it as a new sequential decision making problem dubbed the Online Bandit Problem, and present a new algorithm to solve it. When applied to recognizing faces in TV shows and movies, we realize end-toend classification speedups of 2.5-8.5\u00d7/2.8-12.7\u00d7 (on GPU/CPU) relative to a state-of-the-art convolutional neural network, at competitive accuracy.", "creator": "LaTeX with hyperref package"}}}