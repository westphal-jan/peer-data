{"id": "1611.06468", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Nov-2016", "title": "Generating machine-executable plans from end-user's natural-language instructions", "abstract": "It is critical for advanced manufacturing machines to autonomously execute a task by following an end-user's natural language (NL) instructions. However, NL instructions are usually ambiguous and abstract so that the machines may misunderstand and incorrectly execute the task. To address this NL-based human-machine communication problem and enable the machines to appropriately execute tasks by following the end-user's NL instructions, we developed a Machine-Executable-Plan-Generation (exePlan) method. The exePlan method conducts task-centered semantic analysis to extract task-related information from ambiguous NL instructions. In addition, the method specifies machine execution parameters to generate a machine-executable plan by interpreting abstract NL instructions. To evaluate the exePlan method, an industrial robot Baxter was instructed by NL to perform three types of industrial tasks {'drill a hole', 'clean a spot', 'install a screw'}. The experiment results proved that the exePlan method was effective in generating machine-executable plans from the end-user's NL instructions. Such a method has the promise to endow a machine with the ability of NL-instructed task execution.", "histories": [["v1", "Sun, 20 Nov 2016 04:06:47 GMT  (1155kb)", "http://arxiv.org/abs/1611.06468v1", "16 pages, 10 figures, article submitted to Robotics and Computer-Integrated Manufacturing, 2016 Aug"]], "COMMENTS": "16 pages, 10 figures, article submitted to Robotics and Computer-Integrated Manufacturing, 2016 Aug", "reviews": [], "SUBJECTS": "cs.AI cs.CL cs.RO", "authors": ["rui liu", "xiaoli zhang"], "accepted": false, "id": "1611.06468"}, "pdf": {"name": "1611.06468.pdf", "metadata": {"source": "CRF", "title": "Generating machine-executable plans from end-user\u2019s natural-language instructions", "authors": ["Rui Liu", "Xiaoli Zhang"], "emails": ["xlzhang}@mines.edu"], "sections": [{"heading": null, "text": "In fact, it is such that most of them will be able to survive themselves without there being a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in"}, {"heading": "4.1. Task Knowledge Collection", "text": "This year, it has come to the point where it is a reactionary party that is able to establish itself in the region."}, {"heading": "4.2. Evaluation of Intruction Disambiguation", "text": "A new set of 20 volunteers was recruited to train the Baxter robot in the environment (shown in Fig. 6). Each of the volunteers had to perform three tasks for the robot, which were shown in Fig. 10. Supported by the exePlan method, the Baxter robot was able to understand task-related logic from unclear human instructions. To evaluate the performance of task-related semantic analysis, the exePlan method was used, an algorithm level was selected as Na\u00efve Bayesian (NB). This is efficient and classic in performing classifications, and a method-level baseline was selected as nonTC [8]."}, {"heading": "4.3. Evaluation of Intruction Interpretation and Executability Assessment", "text": "It was the only way to explore the executability of the plan, which was implemented in the recent research of NL-based human-robot interactions [8]. In the LI method, a plan was included in exePlan, in which the instructions of NL instructions were literally understood, and the plan type was interpreted by literally understanding NL instructions, and the plan type was identified by purely human instructions in a first-order logic. For example, drill \u2192 clean task types \"clean.\" MES detection in this basic method was keyword-based on the LI method with the literal understanding of LI instructions. The exePlan method first classified the plan type and then selected the appropriate MES parameters for each method. MES detection in the LI method was keyword-based on the LI method."}], "references": [{"title": "Collaborative Manufacturing with physical human-robot interaction", "author": ["A. Cherubini", "R. Passama", "A. Crosnier", "A. Lasnier", "P. Fraisse"], "venue": "Robotics and Computer-Integrated Manufacturing,vol.40, pp. 1-13, 2016.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2016}, {"title": "Recovering from failure by asking for help.", "author": ["R.A. Knepper", "S. Tellex", "A. Li", "N. Roy", "D. Rus"], "venue": "Autonomous Robots,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2015}, {"title": "The Motion Grammar: Analysis of a Linguistic Method for Robot Control", "author": ["N. Dantam", "M. Stilman"], "venue": "IEEE Transactions on Robotics, vol. 29, no. 3, pp. 704-718, 2013.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2013}, {"title": "Facilitating knowledge sharing and reuse in building and construction domain: an ontology-based approach.", "author": ["R. Costa", "C. Lima", "J. Sarraipa", "R. Jardim-Gon\u00e7alves"], "venue": "Journal of Intelligent Manufacturing,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2016}, {"title": "Automated generation of training sets for object recognition in robotic applications", "author": ["M. Schoeler", "F. W\u00f6rg\u00f6tter", "M.J. Aein", "T. Kulvicius"], "venue": "Robotics in Alpe-Adria-Danube Region 23rd International Conference, 2014, pp 1-7.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}, {"title": "Natural language programming of industrial robots", "author": ["M. Stenmark", "P. Nugues"], "venue": "In Robotics 44th International Symposium, 2013, pp. 1-5.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "Effective and Robust Natural Language Understanding for Human-Robot Interaction", "author": ["E. Bastianelli", "G. Castellucci", "D. Croce", "R. Basili", "D. Nardi"], "venue": "ECAI, 2014, pp. 57-62.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "Hand force adjustment: robust control of force-coupled human\u2013robot-interaction in assembly processes", "author": ["J. Kruger", "D. Surdilovic"], "venue": "CIRP Annals - Manufacturing Technology, vol. 57, no. 1, pp. 41-44, 2008.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2008}, {"title": "An Analysis of Contact Instability in Terms of Passive Physical Equivalents", "author": ["E. Colgate", "N. Hogan"], "venue": "IEEE International Conference on Robotics and Automation (ICRA), pp. 404-409, 1989.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1989}, {"title": "Hand Gesture-Based Manipulation of a Personalized Avatar Robot in Remote Communication", "author": ["T. Ito"], "venue": "Symposium on Human Interface, pp. 425-434, 2011.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2011}, {"title": "A Proposed Gesture Set for the Control of Industrial Collaborative Robots", "author": ["P. Barattini", "C. Morand", "N. Robertson"], "venue": "IEEE International Symposium on Robot and Human Interactive Communication (IEEE RO-MAN), PP. 132-137, 2012.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2012}, {"title": "Augmented reality applications in design and manufacturing", "author": ["A. Nee", "S. Ong", "G. Chryssolouris", "D. Mourtzis"], "venue": "CIRP Annals - Manufacturing Technology, vol. 61, no. 2, pp. 657-679, 2012.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2012}, {"title": "Assembly Strategy Modeling and Selection for Human and Robot Coordinated Cell Assembly", "author": ["F. Chen", "K. Sekiyama", "H. Sasaki", "J. Huang", "B. Sun", "T. Fukuda"], "venue": "IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 4670-4675, 2011.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2011}, {"title": "Understanding Human Behaviors with an Object Functional Role Perspective for Robotics", "author": ["R. Liu", "X. Zhang"], "venue": "IEEE Transactions on Cognitive and Developmental Systems, vol. 8, no. 2, pp. 115-127, 2016.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2016}, {"title": "Fuzzy-Context-Specific Intention Inference for Robotic Caregiving", "author": ["R. Liu", "X. Zhang"], "venue": "International Journal of Advanced Robotic System, DOI: 10.1177/1729881416662780, 2016.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2016}, {"title": "Make it so: Continuous, flexible natural language interaction with an autonomous robot", "author": ["D.J. Brooks", "C. Lignos", "C. Finucane", "M.S. Medvedev", "I. Perera", "V. Raman", "H. Kress-Gazit", "M. Marcus", "H.A. Yanco"], "venue": "AAAI, pp. 2-8, 2012.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2012}, {"title": "An effective personal mobile robot agent through symbiotic human-robot interaction", "author": ["S. Rosenthal", "J. Biswas", "M. Veloso"], "venue": "AAMAS 2010, pages 915-922, 2010.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2010}, {"title": "Open Language Learning for Information Extraction", "author": ["M. Schmitz", "R. Bart", "S. Soderland", "O. Etzioni"], "venue": "2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pp. 523-534, 2012.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2012}, {"title": "The Stanford CoreNLP Natural Language Processing Toolkit", "author": ["C. Manning", "M. Surdeanu", "J. Bauer", "J. Finkel", "S. Bethard", "D. McClosky"], "venue": "Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstration, pp. 55-60, 2014.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}, {"title": "Action database for categorizing and inferring human poses from video sequences", "author": ["W. Takano", "Y. Nakamura"], "venue": "Robotics and Autonomous Systems, vol. 70, pp. 116-125, 2015.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2015}, {"title": "A Probabilistic Approach for Enabling Robots to Acquire Information From Human Partners Using Language", "author": ["S. Tellex", "P. Thaker", "R. Deits", "D. Simeonov", "T. Kollar", "N. Roy"], "venue": "http://hdl.handle.net/1721.1/68651, 2012.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2012}, {"title": "Nardi,\u201cTeaching Robots Parametrized Executable Plans Through Spoken Interaction,", "author": ["G. Gemignani", "E. Bastianelli"], "venue": "Proceedings of the 2015 International Conference on Autonomous Agents and Multiagent Systems,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2015}, {"title": "Spoken Language Processing in a Conversational System for Child-Robot Interaction", "author": ["I. Kruijff-Korbayova", "H. Cuayahuitl", "B. Kiefer", "M. Schroder", "P. Cosi", "G. Paci", "G. Sommavilla", "F. Tesser", "H.Sahli", "G. Athanasopoulos", "W. Wang"], "venue": "Workshop on Child, Computer and Interaction (WOCCI), pp. 32-39, 2012.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2012}, {"title": "An Emotional Storyteller Robot", "author": ["A. Chella", "R.E. Barone", "G. Pilato", "R. Sorbello"], "venue": "AAAI Spring Symposium: Emotion, Personality, and Social Behavior, pp.17-22, 2008.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2008}, {"title": "Toward Open Knowledge Enabling for Human- Robot Interaction", "author": ["X. Chen", "J. Xie", "J. Ji", "Z. Sui"], "venue": "Journal of Human-Robot Interaction,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2013}, {"title": "Natural-Language-Instructed Industrial Task Execution", "author": ["R. Liu", "J. Webb", "X. Zhang"], "venue": "Proceedings of the ASME 2016 International Design Engineering Technical Conferences & Computers & Information in Engineering Conference (IDETC/CIE 2016), August 21-24, 2016, Charlotte, North Carolina, USA.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2016}, {"title": "The production and comprehension of referring expressions", "author": ["E. Graf", "C. Davies"], "venue": "Pragmatic Development in First Language Acquisition, pp. 161, 2014.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2014}, {"title": "Going Beyond Literal Command-Based Instructions: Extending Robotic Natural Language Interaction Capabilities", "author": ["T. Williams", "G. Briggs", "B. Oosterveld", "M. Scheutz"], "venue": "AAAI, pp. 1387-1393, 2015.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2015}, {"title": "Tell me Dave: Context-sensitive grounding of natural language to mobile manipulation instructions", "author": ["D.K. Misra", "J. Sung", "K. Lee", "A. Saxena"], "venue": "Robotics: Science and Systems, 2014.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2014}, {"title": "Context-specific intention awareness through web query in robotic caregiving", "author": ["R. Liu", "X. Zhang", "J. Webb", "S. Li"], "venue": "IEEE International Conference on Robotics and Automation (ICRA), pp. 1962-1967, 2015.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 1962}, {"title": "Context-Specific Grounding of Web Natural Descriptions to Human-centered Situations", "author": ["R. Liu", "X. Zhang"], "venue": "Knowledge-based Systems, in press July 2016.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2016}, {"title": "An interactive approach for situated task specification through verbal instructions", "author": ["C. Meri\u00e7li", "S.D. Klee", "M.J. Paparian", "Veloso"], "venue": "Proceedings of the 2014 international conference on Autonomous agents and multi-agent systems, pp. 1069-1076, 2014.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2014}, {"title": "Inferring maps and behaviors from natural language instructions", "author": ["F. Duvallet", "M.R. Walter", "T. Howard", "S. Hemachandra", "J. Oh", "S. Teller", "N. Roy", "A. Stentz"], "venue": "Experimental Robotics, pp. 373-388, 2016.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2016}, {"title": "Learning the spatial semantics of manipulation actions through preposition grounding", "author": ["K. Zampogiannis", "Y. Yang", "C. Fermuller", "Y. Aloimonos"], "venue": "Robotics and Automation (ICRA), 2015 IEEE International Conference, pp. 1389-1396, 2015.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning to recognize novel objects in one shot through human-robot interactions in natural language dialogues", "author": ["E.A. Krause", "M. Zillich", "T.E. Williams", "M. Sche utz"], "venue": "AAAI, pp. 2796-2802, 2014.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2014}, {"title": "Semantic representation for navigation in large-scale environments", "author": ["R. Drouilly", "P. Rives", "B. Morisset"], "venue": "IEEE International Conference Robotics and Automation (ICRA), pp. 1106-1111, 2015.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2015}, {"title": "Speech and language Processing, 2nd ed", "author": ["D. Jurafsky", "J.H. Martin"], "venue": null, "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2008}, {"title": "Toward interpreting spatial language discourse with grounding graphs", "author": ["D. Simeonov", "S. Tellex", "T. Kollar", "N. Roy"], "venue": "RSS Workshop on Grounding Human-Robot Dialog for Spatial Tasks, 2011.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2011}, {"title": "Cakmak,\u201cRobot programming by demonstration with situated spatial language understanding,", "author": ["M. Forbes", "R.P. Rao", "L. Zettlemoyer"], "venue": "IEEE Conference,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2015}, {"title": "Grounding verbs of motion in natural language commands to robots", "author": ["T. Kollar", "S. Tellex", "D. Roy", "N. Roy"], "venue": "Experimental Robotics, Springer Berlin Heidelberg, pp. 31-47, 2014.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2014}, {"title": "Using semantic fields to model dynamic spatial relations in a robot architecture for natural language instruction of service robots", "author": ["J. Fasola", "M.J. Mataric"], "venue": "Intelligent Robots and Systems (IROS), 2013 IEEE/RSJ International Conference, pp. 143-150, 2013.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2013}, {"title": "Imitation learning for natural language direction following through unknown environments", "author": ["F. Duvallet", "T. Kollar", "A. Stentz"], "venue": "Robotics and Automation (ICRA), 2013 IEEE International Conference, pp. 1047-1053, 2013.", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2013}, {"title": "Unsupervised and Semi-supervised Multi-class Support Vector Machines", "author": ["L. Xu", "D. Schuurmans"], "venue": "AAAI Conference on Artificial Intelligence, vol. 5, 2005.", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2005}, {"title": "SVM soft margin classifiers: liner programming versus quadratic programming", "author": ["Q. Wu", "D. Zhou"], "venue": "Neural Computation, vol. 17, no. 5, pp. 11160-1187, 2005.", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2005}, {"title": "Learning spatial-semantic representations from natural language descriptions and scene classifications", "author": ["S. Hemachandra", "M.R. Walter", "S. Tellex", "S. Teller"], "venue": "IEEE International Conference Robotics and Automation (ICRA), pp. 2623-2630, 2014.", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning semantic maps from natural language descriptions", "author": ["M.R. Walter", "S. Hemachandra", "B. Homberg", "S. Tellex", "S. Teller"], "venue": "Proc. Robotics: Science and Systems (RSS), 2013.", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2013}, {"title": "Markov Logic Networks", "author": ["M. Richardson", "P. Domingos"], "venue": "Machine Learning, vol. 62, no. 1-2, pp. 107-136, 2006.", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2006}, {"title": "Max-Margin Weight Learning for Markov Logic Networks", "author": ["T. Huynh", "R. mooney"], "venue": "Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pp. 564-579, 2009.", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2009}, {"title": "Cutting-Plane Training of Structural SVM", "author": ["T. Joachims", "T. Finley"], "venue": "Machine Learning, vol. 77, no. 1, pp.27-59, 2009.", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2009}, {"title": "Training Structural SVMs when Exact Inference is Intractable", "author": ["T. Joachims", "T. Finley"], "venue": "International conference on Machine learning, pp. 304-311, 2008.", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2008}, {"title": "Learning to Parse Natural Language to a Robot Control System", "author": ["C. Matuszek", "E. Herbst", "L. Zettlemoyer", "D. Fox"], "venue": "Experimental Robotics, pp. 403-415, 2013.", "citeRegEx": "54", "shortCiteRegEx": null, "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": ", precision and speed) on low-level task execution [1].", "startOffset": 51, "endOffset": 54}, {"referenceID": 1, "context": "Toward this direction, intuitive and natural communication between the human and the machine has been an active research area in the last decade with the goal to enable seamless human-machine cooperation [2][3].", "startOffset": 204, "endOffset": 207}, {"referenceID": 2, "context": "Toward this direction, intuitive and natural communication between the human and the machine has been an active research area in the last decade with the goal to enable seamless human-machine cooperation [2][3].", "startOffset": 207, "endOffset": 210}, {"referenceID": 3, "context": "Natural-Language-instructed human-machine interaction is expected to enable an advanced manufacturing machine, such as a Computer Numerical Control machine or an industrial robot, to autonomously perform tasks such as rough/fine finishing [4][5], assembly [2][6] and packaging [7][8] according to the end-user\u2019s NL instructions, which are given based on the user\u2019s judgement of the task progress and environmental situations.", "startOffset": 242, "endOffset": 245}, {"referenceID": 1, "context": "Natural-Language-instructed human-machine interaction is expected to enable an advanced manufacturing machine, such as a Computer Numerical Control machine or an industrial robot, to autonomously perform tasks such as rough/fine finishing [4][5], assembly [2][6] and packaging [7][8] according to the end-user\u2019s NL instructions, which are given based on the user\u2019s judgement of the task progress and environmental situations.", "startOffset": 256, "endOffset": 259}, {"referenceID": 4, "context": "Natural-Language-instructed human-machine interaction is expected to enable an advanced manufacturing machine, such as a Computer Numerical Control machine or an industrial robot, to autonomously perform tasks such as rough/fine finishing [4][5], assembly [2][6] and packaging [7][8] according to the end-user\u2019s NL instructions, which are given based on the user\u2019s judgement of the task progress and environmental situations.", "startOffset": 259, "endOffset": 262}, {"referenceID": 5, "context": "Natural-Language-instructed human-machine interaction is expected to enable an advanced manufacturing machine, such as a Computer Numerical Control machine or an industrial robot, to autonomously perform tasks such as rough/fine finishing [4][5], assembly [2][6] and packaging [7][8] according to the end-user\u2019s NL instructions, which are given based on the user\u2019s judgement of the task progress and environmental situations.", "startOffset": 277, "endOffset": 280}, {"referenceID": 6, "context": "Natural-Language-instructed human-machine interaction is expected to enable an advanced manufacturing machine, such as a Computer Numerical Control machine or an industrial robot, to autonomously perform tasks such as rough/fine finishing [4][5], assembly [2][6] and packaging [7][8] according to the end-user\u2019s NL instructions, which are given based on the user\u2019s judgement of the task progress and environmental situations.", "startOffset": 280, "endOffset": 283}, {"referenceID": 7, "context": "Compared with other input methods, including human hand force [9][10], hand gesture [11][12], and body motions [13][14][15][16], the NL instruction method has two main advantages.", "startOffset": 62, "endOffset": 65}, {"referenceID": 8, "context": "Compared with other input methods, including human hand force [9][10], hand gesture [11][12], and body motions [13][14][15][16], the NL instruction method has two main advantages.", "startOffset": 65, "endOffset": 69}, {"referenceID": 9, "context": "Compared with other input methods, including human hand force [9][10], hand gesture [11][12], and body motions [13][14][15][16], the NL instruction method has two main advantages.", "startOffset": 84, "endOffset": 88}, {"referenceID": 10, "context": "Compared with other input methods, including human hand force [9][10], hand gesture [11][12], and body motions [13][14][15][16], the NL instruction method has two main advantages.", "startOffset": 88, "endOffset": 92}, {"referenceID": 11, "context": "Compared with other input methods, including human hand force [9][10], hand gesture [11][12], and body motions [13][14][15][16], the NL instruction method has two main advantages.", "startOffset": 111, "endOffset": 115}, {"referenceID": 12, "context": "Compared with other input methods, including human hand force [9][10], hand gesture [11][12], and body motions [13][14][15][16], the NL instruction method has two main advantages.", "startOffset": 115, "endOffset": 119}, {"referenceID": 13, "context": "Compared with other input methods, including human hand force [9][10], hand gesture [11][12], and body motions [13][14][15][16], the NL instruction method has two main advantages.", "startOffset": 119, "endOffset": 123}, {"referenceID": 14, "context": "Compared with other input methods, including human hand force [9][10], hand gesture [11][12], and body motions [13][14][15][16], the NL instruction method has two main advantages.", "startOffset": 123, "endOffset": 127}, {"referenceID": 15, "context": "Non-expert users without prior programming training could command a machine to perform their desired tasks [17][18].", "startOffset": 107, "endOffset": 111}, {"referenceID": 16, "context": "Non-expert users without prior programming training could command a machine to perform their desired tasks [17][18].", "startOffset": 111, "endOffset": 115}, {"referenceID": 17, "context": "Second, the inherent linguistic structure of NL, as a predefined information encoder, provides a standard, informative data source to generate structured machine language [19][20].", "startOffset": 171, "endOffset": 175}, {"referenceID": 18, "context": "Second, the inherent linguistic structure of NL, as a predefined information encoder, provides a standard, informative data source to generate structured machine language [19][20].", "startOffset": 175, "endOffset": 179}, {"referenceID": 2, "context": "Currently, typical industrial applications involving NL include NL-based control in which the working statuses such as \u201con/off\u201d and \u201cquickly/slowly\u201d are selected orally to control a machine in navigation [3][21], NL-based task execution in which the task operation methods such as \u201cgoTo + Location; then drop + object\u201d is described orally to help a machine with object finding/placing [22][23], and NL-based execution personalization in which human\u2019s preferences and moods in oral dialogs were considered to adjust a machine\u2019s execution manners [24][25].", "startOffset": 204, "endOffset": 207}, {"referenceID": 19, "context": "Currently, typical industrial applications involving NL include NL-based control in which the working statuses such as \u201con/off\u201d and \u201cquickly/slowly\u201d are selected orally to control a machine in navigation [3][21], NL-based task execution in which the task operation methods such as \u201cgoTo + Location; then drop + object\u201d is described orally to help a machine with object finding/placing [22][23], and NL-based execution personalization in which human\u2019s preferences and moods in oral dialogs were considered to adjust a machine\u2019s execution manners [24][25].", "startOffset": 207, "endOffset": 211}, {"referenceID": 20, "context": "Currently, typical industrial applications involving NL include NL-based control in which the working statuses such as \u201con/off\u201d and \u201cquickly/slowly\u201d are selected orally to control a machine in navigation [3][21], NL-based task execution in which the task operation methods such as \u201cgoTo + Location; then drop + object\u201d is described orally to help a machine with object finding/placing [22][23], and NL-based execution personalization in which human\u2019s preferences and moods in oral dialogs were considered to adjust a machine\u2019s execution manners [24][25].", "startOffset": 385, "endOffset": 389}, {"referenceID": 21, "context": "Currently, typical industrial applications involving NL include NL-based control in which the working statuses such as \u201con/off\u201d and \u201cquickly/slowly\u201d are selected orally to control a machine in navigation [3][21], NL-based task execution in which the task operation methods such as \u201cgoTo + Location; then drop + object\u201d is described orally to help a machine with object finding/placing [22][23], and NL-based execution personalization in which human\u2019s preferences and moods in oral dialogs were considered to adjust a machine\u2019s execution manners [24][25].", "startOffset": 389, "endOffset": 393}, {"referenceID": 22, "context": "Currently, typical industrial applications involving NL include NL-based control in which the working statuses such as \u201con/off\u201d and \u201cquickly/slowly\u201d are selected orally to control a machine in navigation [3][21], NL-based task execution in which the task operation methods such as \u201cgoTo + Location; then drop + object\u201d is described orally to help a machine with object finding/placing [22][23], and NL-based execution personalization in which human\u2019s preferences and moods in oral dialogs were considered to adjust a machine\u2019s execution manners [24][25].", "startOffset": 545, "endOffset": 549}, {"referenceID": 23, "context": "Currently, typical industrial applications involving NL include NL-based control in which the working statuses such as \u201con/off\u201d and \u201cquickly/slowly\u201d are selected orally to control a machine in navigation [3][21], NL-based task execution in which the task operation methods such as \u201cgoTo + Location; then drop + object\u201d is described orally to help a machine with object finding/placing [22][23], and NL-based execution personalization in which human\u2019s preferences and moods in oral dialogs were considered to adjust a machine\u2019s execution manners [24][25].", "startOffset": 549, "endOffset": 553}, {"referenceID": 6, "context": "NL is usually polysemous, homophonic and expression-manner diverse so that the same meaning could be expressed in various ways, and different meanings could be expressed in similar ways [8][26].", "startOffset": 186, "endOffset": 189}, {"referenceID": 24, "context": "NL is usually polysemous, homophonic and expression-manner diverse so that the same meaning could be expressed in various ways, and different meanings could be expressed in similar ways [8][26].", "startOffset": 189, "endOffset": 193}, {"referenceID": 25, "context": "For example, \u201cdrill a hole\u201d could be expressed as \u201cbore one hole\u201d, \u201cdrilling one bore\u201d, \u201ccreate an unthreaded hole\u201d, and so on [27].", "startOffset": 127, "endOffset": 131}, {"referenceID": 20, "context": "In addition, humans usually use referring, outlining, and omitting in NL instructions [22][28].", "startOffset": 86, "endOffset": 90}, {"referenceID": 26, "context": "In addition, humans usually use referring, outlining, and omitting in NL instructions [22][28].", "startOffset": 90, "endOffset": 94}, {"referenceID": 25, "context": "cannot be known merely from a word \u2018the\u2019 [27].", "startOffset": 41, "endOffset": 45}, {"referenceID": 21, "context": "Second, human instruction is abstract [23][29].", "startOffset": 38, "endOffset": 42}, {"referenceID": 27, "context": "Second, human instruction is abstract [23][29].", "startOffset": 42, "endOffset": 46}, {"referenceID": 25, "context": "\u201d is missing [27].", "startOffset": 13, "endOffset": 17}, {"referenceID": 28, "context": "In addition to specific-knowledge missing, a reasonable and flexible knowledge structure, which is implicitly embedded in NL descriptions to guide correct task execution, is difficult to extract [30][31][32].", "startOffset": 195, "endOffset": 199}, {"referenceID": 29, "context": "In addition to specific-knowledge missing, a reasonable and flexible knowledge structure, which is implicitly embedded in NL descriptions to guide correct task execution, is difficult to extract [30][31][32].", "startOffset": 199, "endOffset": 203}, {"referenceID": 30, "context": "In addition to specific-knowledge missing, a reasonable and flexible knowledge structure, which is implicitly embedded in NL descriptions to guide correct task execution, is difficult to extract [30][31][32].", "startOffset": 203, "endOffset": 207}, {"referenceID": 31, "context": "By obeying the human instructions, one task could be flexibly executed by several methods, which were formulated according to an individual\u2019s cognitive logics [33][34].", "startOffset": 159, "endOffset": 163}, {"referenceID": 32, "context": "By obeying the human instructions, one task could be flexibly executed by several methods, which were formulated according to an individual\u2019s cognitive logics [33][34].", "startOffset": 163, "endOffset": 167}, {"referenceID": 1, "context": "However, usually these cognitive logics in NL instructions are difficult to understand as to a machine, for that literal information directly extracted from NL instructions is insufficient to explain the logics [2][35].", "startOffset": 211, "endOffset": 214}, {"referenceID": 33, "context": "However, usually these cognitive logics in NL instructions are difficult to understand as to a machine, for that literal information directly extracted from NL instructions is insufficient to explain the logics [2][35].", "startOffset": 214, "endOffset": 218}, {"referenceID": 6, "context": "For example, in the sentence \u201cbring the can in the trash bin\u201d the task goal \u201cin the trash bin\u201d was extracted based on the keywords \u201cbring, can\u201d and their corresponding PoS tags \u201cVB, NN\u2019[8].", "startOffset": 185, "endOffset": 188}, {"referenceID": 34, "context": "\u201cAttached\u201d was the constraint relation between the object \u201ccontainer\u201d and object part \u201chandle\u201d [36][37].", "startOffset": 95, "endOffset": 99}, {"referenceID": 35, "context": "\u201cAttached\u201d was the constraint relation between the object \u201ccontainer\u201d and object part \u201chandle\u201d [36][37].", "startOffset": 99, "endOffset": 103}, {"referenceID": 20, "context": "Pick it up\u201d for an example, with co-reference resolution the uncertain expression \u201cit\u201d was identified as \u201cthe second crate on the right\u201d [22][38].", "startOffset": 137, "endOffset": 141}, {"referenceID": 36, "context": "Pick it up\u201d for an example, with co-reference resolution the uncertain expression \u201cit\u201d was identified as \u201cthe second crate on the right\u201d [22][38].", "startOffset": 141, "endOffset": 145}, {"referenceID": 1, "context": "a robot, a query such as \u201cwhich pallet?\u201d was launched to ask the human for disambiguation [2][39].", "startOffset": 90, "endOffset": 93}, {"referenceID": 37, "context": "a robot, a query such as \u201cwhich pallet?\u201d was launched to ask the human for disambiguation [2][39].", "startOffset": 93, "endOffset": 97}, {"referenceID": 34, "context": "By exploring the features such as perceivable properties \u201ccylindrical\u201d and \u201cround\u201d, the ambiguous descriptions \u201ccylindrical container with a round handle attached on one side\u201d for the object \u201ccontainer\u201d was understood [36].", "startOffset": 218, "endOffset": 222}, {"referenceID": 38, "context": "By exploring the spatial relations \u201cbehind\u201d in NL descriptions \u201cNavigate to the building behind the pole\u201d, named entities \u201cbuilding, pole\u201d were identified in the real world [40][41].", "startOffset": 173, "endOffset": 177}, {"referenceID": 39, "context": "By exploring the spatial relations \u201cbehind\u201d in NL descriptions \u201cNavigate to the building behind the pole\u201d, named entities \u201cbuilding, pole\u201d were identified in the real world [40][41].", "startOffset": 177, "endOffset": 181}, {"referenceID": 2, "context": "To interpret abstract expressions in NL instructions, motion grammars were first designed for establishing the word-action correlations such as word \u201cgrasp\u201d \u2014 action \u201cGrasp\u201d [3][21][23].", "startOffset": 174, "endOffset": 177}, {"referenceID": 19, "context": "To interpret abstract expressions in NL instructions, motion grammars were first designed for establishing the word-action correlations such as word \u201cgrasp\u201d \u2014 action \u201cGrasp\u201d [3][21][23].", "startOffset": 177, "endOffset": 181}, {"referenceID": 21, "context": "To interpret abstract expressions in NL instructions, motion grammars were first designed for establishing the word-action correlations such as word \u201cgrasp\u201d \u2014 action \u201cGrasp\u201d [3][21][23].", "startOffset": 181, "endOffset": 185}, {"referenceID": 15, "context": "Real-world preconditions such as \u201cstay in the kitchen\u201d were defined for triggering specific types of executions such as \u201cvisiting the kitchen\u201d [17].", "startOffset": 143, "endOffset": 147}, {"referenceID": 40, "context": "The NL descriptions were marked by landmark objects such as \u201cstaircase, box\u201d in the real world to enable the execution of tasks such as \u201creach in a spot\u201d [42][43].", "startOffset": 154, "endOffset": 158}, {"referenceID": 41, "context": "The NL descriptions were marked by landmark objects such as \u201cstaircase, box\u201d in the real world to enable the execution of tasks such as \u201creach in a spot\u201d [42][43].", "startOffset": 158, "endOffset": 162}, {"referenceID": 20, "context": "50)}[22][43].", "startOffset": 4, "endOffset": 8}, {"referenceID": 41, "context": "50)}[22][43].", "startOffset": 8, "endOffset": 12}, {"referenceID": 44, "context": "In [46][47], a semantic topological model was developed to explore the internal logic correlations of sub-steps in a reasonable task-execution plan.", "startOffset": 3, "endOffset": 7}, {"referenceID": 45, "context": "In [46][47], a semantic topological model was developed to explore the internal logic correlations of sub-steps in a reasonable task-execution plan.", "startOffset": 7, "endOffset": 11}, {"referenceID": 18, "context": "Second, text corpus is split into independent sentences, words, PoS tags and dependences by using the NLP tool Stanford CoreNLP [20].", "startOffset": 128, "endOffset": 132}, {"referenceID": 42, "context": "Given that the amount of the text corpus is potentially large and the desired output predictions (sub-goals involved in task plans) are multiple, a semi-supervised multi-class Support Vector Machine algorithm (smSVM) [44] is adopted.", "startOffset": 217, "endOffset": 221}, {"referenceID": 30, "context": "A semi-supervised classification method merely needs a small amount of labeled samples (usually 1%~5% of the total samples) for classifier training [32].", "startOffset": 148, "endOffset": 152}, {"referenceID": 43, "context": "intercept value bsm \u2217 are solved by a quadratic programming (QP) solver [45] and they define an optimal hyperplane to", "startOffset": 72, "endOffset": 76}, {"referenceID": 46, "context": "The task-centered logic framework is modeled by a Markov Logic Network (MLN) algorithm [49][50] (shown in equation (4)).", "startOffset": 87, "endOffset": 91}, {"referenceID": 47, "context": "The task-centered logic framework is modeled by a Markov Logic Network (MLN) algorithm [49][50] (shown in equation (4)).", "startOffset": 91, "endOffset": 95}, {"referenceID": 47, "context": "The second step is adopting a Structural Support Vector Machine (SSVM) method [50] to learn the formula involvements and their corresponding weights given a task.", "startOffset": 78, "endOffset": 82}, {"referenceID": 48, "context": "SSVM is good at learning complex structures, which are constructed by knowledge entity involvements and their weights [51][52].", "startOffset": 118, "endOffset": 122}, {"referenceID": 49, "context": "SSVM is good at learning complex structures, which are constructed by knowledge entity involvements and their weights [51][52].", "startOffset": 122, "endOffset": 126}, {"referenceID": 48, "context": "This weight learning problem could be formulized as a 1-slack SSVM problem and solved by an efficient cutting plane method [51], formulized by the objective function in equation (9), where C denotes the trade-off parameters between the error \u03be and the margin W.", "startOffset": 123, "endOffset": 127}, {"referenceID": 6, "context": "To evaluate the performances of the task-centered semantic analysis by using the exePlan method, an algorithm-level baseline was selected as Na\u00efve Bayesian (NB) [55] which is efficient and classic in performing classification and a method-level baseline was selected as nonTC [8][54] which only considers the keyword-related features in semantic understanding.", "startOffset": 276, "endOffset": 279}, {"referenceID": 50, "context": "To evaluate the performances of the task-centered semantic analysis by using the exePlan method, an algorithm-level baseline was selected as Na\u00efve Bayesian (NB) [55] which is efficient and classic in performing classification and a method-level baseline was selected as nonTC [8][54] which only considers the keyword-related features in semantic understanding.", "startOffset": 279, "endOffset": 283}, {"referenceID": 6, "context": "machine-execution-specification method included in exePlan, a baseline method was selected as Literally Interpretation method (\u201cLI\u201d for short), which was implemented in recent research of NL-based human-robot interactions [8][54].", "startOffset": 222, "endOffset": 225}, {"referenceID": 50, "context": "machine-execution-specification method included in exePlan, a baseline method was selected as Literally Interpretation method (\u201cLI\u201d for short), which was implemented in recent research of NL-based human-robot interactions [8][54].", "startOffset": 225, "endOffset": 229}], "year": 2016, "abstractText": "It is critical for advanced manufacturing machines to autonomously execute a task by following an end-user\u2019s natural language (NL) instructions. However, NL instructions are usually ambiguous and abstract so that the machines may misunderstand and incorrectly execute the task. To address this NL-basedso that the machines may misunderstand and incorrectly execute the task. To address this NL-based human-machine communication problem and enable the machines to appropriately execute tasks by following the end-user\u2019s NL instructions, we developed a Machine-Executable-Plan-Generation (exePlan) method. The exePlan method conducts task-centered semantic analysis to extract task-related information from ambiguous NL instructions. In addition, the method specifies machine execution parameters to generate a machine-executable plan by interpreting abstract NL instructions. To evaluate the exePlan method, an industrial robot Baxter was instructed by NL to perform three types of industrial tasks {\u201cdrill a hole\u201d, \u201cclean a spot\u201d, \u201cinstall a screw\u201d}. The experiment results proved that the exePlan method was effective in generating machine-executable plans from the end-user\u2019s NL instructions. Such a method has the promise to endow a machine with the ability of NL-instructed task execution.", "creator": "Microsoft\u00ae Word 2013"}}}