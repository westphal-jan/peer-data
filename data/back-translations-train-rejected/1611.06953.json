{"id": "1611.06953", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Nov-2016", "title": "Associative Adversarial Networks", "abstract": "We propose a higher-level associative memory for learning adversarial networks. Generative adversarial network (GAN) framework has a discriminator and a generator network. The generator (G) maps white noise (z) to data samples while the discriminator (D) maps data samples to a single scalar. To do so, G learns how to map from high-level representation space to data space, and D learns to do the opposite. We argue that higher-level representation spaces need not necessarily follow a uniform probability distribution. In this work, we use Restricted Boltzmann Machines (RBMs) as a higher-level associative memory and learn the probability distribution for the high-level features generated by D. The associative memory samples its underlying probability distribution and G learns how to map these samples to data space. The proposed associative adversarial networks (AANs) are generative models in the higher-levels of the learning, and use adversarial non-stochastic models D and G for learning the mapping between data and higher-level representation spaces. Experiments show the potential of the proposed networks.", "histories": [["v1", "Fri, 18 Nov 2016 02:11:40 GMT  (1388kb,D)", "http://arxiv.org/abs/1611.06953v1", "NIPS 2016 Workshop on Adversarial Training"]], "COMMENTS": "NIPS 2016 Workshop on Adversarial Training", "reviews": [], "SUBJECTS": "cs.LG cs.AI", "authors": ["tarik arici", "asli celikyilmaz"], "accepted": false, "id": "1611.06953"}, "pdf": {"name": "1611.06953.pdf", "metadata": {"source": "CRF", "title": "Associative Adversarial Networks", "authors": ["Tarik Arici"], "emails": ["aslicel}@microsoft.com"], "sections": [{"heading": "1 Introduction", "text": "Generative convergence is a new goal that leads G to the most diverse aspects of discrimination. It is a relatively new type of framework that introduces a generator G and a discriminator D, both of which are often chosen to be a kind of multi-layered perception (MLP), in such a way that they are able to label training examples as true, while GAN models are designed to maximize the likelihood of D's classification errors. Recent work has reported that models trained with the GAN framework can generate excellent examples [2]. Nevertheless, it is widely reported that GAN models are difficult to train and different techniques are proposed (which are summarized). Most of this work attempts to deal with the difficulty of addressing the difficulties of optimizing G and D's simultaneously in a synchronized form."}, {"heading": "2 Related Work", "text": "The generative adversarial networks (GANs) [1], variable autoencoders (UAE) [8], generative maximum mean discrepeancy networks [9], deep generative models [10], generative moment matching networks [11], etc., have shown that a deep generative network can learn to distribute across samples. GANs have been a promising family of generative models in the field of computer vision because they can produce sharp images by applying stochastic gradient descendence to well-defined loss functions. Some GAN extensions have considered laplaciatory pyramid extensions [12], which show higher quality images, a recursive network approach [13], and a deconventional network approach [14], which demonstrates a reasonable success with generative images."}, {"heading": "3 Generative Adversarial Networks (GAN)", "text": "GANs [1] are a class of generative models that represent the training process as a game between a generator network (G) and a discriminator network (D), both of which are non-stochastic models. The generator network, G (z; \u03b8 (G)), is typically selected, depending on the task, as a forward or a revolutionary neural network. It generates samples by transforming vectors of noise z as x = G (z; \u03b8 (G). discriminator D is trained by taking samples from the generator, pG (x), as negative instances and from the real data pdata (x) as positive instances. The learning framework is trained to distinguish generated samples from the real (training) data. D takes the output of G and maps it to a binary classification probability. The generator then tries to \"trick\" the discriminator by revaluing fake samples (pdata px) as the minimum effectiveness of a player's learning network and generating it as a generator of two instances."}, {"heading": "4 Using RBMs as an Associative Memory for GANs", "text": "An RBM is an energy-based model for unattended learning with an underlying undirected graph. It consists of two layers of binary stochastic units: a visible layer v representing the data, and a hidden layer h for the latent variables. wij determines the strength of the interaction between the hidden hj and visible vi units. An energy function between visible and hidden variables E (v, h), the probability P (v, h), and the partition function Z is defined as below: E (v, h) = 12 \u2211 i v2i \u2212 \u2211 i \u2212 \u2211 i, j vihjwij \u2212 \u2211 i vibi \u2212 jcj; P (v, h) = e \u2212 E (v, h) Z \u2212 Z p (v \u2212 E \u2212 E (x, y \u2212 y (y, y, y) The probability of a data point (represented by the visible state v) vihjwij \u2212 jj \u2212 is marginalized by the marginalized one, whereby P \u2212."}, {"heading": "5 Associative Adversarial Networks (AAN)", "text": "The discriminator model D tries to distinguish between the real and the fake data. In contrast to conventional approaches, we do not consider the input of G as flat space, but as a middle but superior representation, which corresponds to one of the intermediate layers of D. In contrast to conventional approaches, we use an RBM to learn a distribution in this space. Samples generated by contrast divergence to update the RBM model are used as input to G. Therefore, we connect D and G by a high-level feature distance. F (x) denotes an interlayer activation of D, while C (y) uses the operations in the remaining layers in D. Then D (x) = p (F (x)) is used as input. Associative memory learns the distribution of f = F (x). Similar to the regular protocol G (max."}, {"heading": "6 Details of Associative Adversarial Training", "text": "We trained the AANs on Large-scale CelebFaces Attributes (CelebA) and the MNIST dataset. Images in the dataset are scaled linearly to the [-1, 1] range. GAN models are trained with mini-batch sizes of 256. Similar to [2] we used an Adam optimizer. For RBM learning, we used the same mini-batch size with a learning rate of 0.001 and a stochastic gradient descent (SGD) with dynamics. We chose a pulse rate of 0.8. A contrasting two-step divergence is used to generate the negative samples. We used leaky linear activations (LeakyReLU) [22] for D with one exception to be discussed below, and reacted linear activation [23] for G as activation functions."}, {"heading": "6.1 CelebA", "text": "The differentiating factor for this dataset consists of four meandering layers with a depth of 64, 128, 256, 512 as the first four layers; the increment is set to correspond to the filter width and height, both of which are five layers; the last two meandering layers are transformed into a one-dimensional representation f, which is fully connected to a layer that has the same dimension as the visible layer of the RBM. After this layer, there are two other layers of size 500. The last two layers can be considered as hidden layers of a classification network C as defined in Section 5, which has f as input, so that its cascaded application consists of D (i.e. D (x) = C (F (x)))). F defines an assignment to a feature space, and the RBM model learns the distribution of the dataset patterns in that space. Figure 3 shows some facial images that are generated from negative samples of the RM by increasing the number of the Gibbs to one."}, {"heading": "6.2 Convergence Analysis of the Generator and the Discriminator", "text": "G implicitly defines a probability distribution pG as the distribution of the sample G (f) it generates when f \u0445 pf. The goal is to obtain a pG that represents a good approximation to pdata. The Minimax game, which emphasizes opposing learning, has a global optimum, but pG = pdata and logD (x) = 1 / 2. Therefore, the value function log 4 given in 1 is the optimal solution. As discussed in the introductory section, one of the difficulties in opposing learning is that D improves its costs significantly faster than G, and G lags so far behind that it cannot obtain good gradients that propagate backwards from D and lose the game. For good opposing training, one would expect G to lag behind at an acceptable level, so that D G. To analyze the convergence of opposing models, we need to monitor the Ex dimension data (x), [D (x) and Ef-dimensions."}, {"heading": "7 Conclusion and Future Work", "text": "In this paper, we argue that entering sounds into the generator makes the task of learning G more difficult. Instead, we propose to use an additional network, the associative memory network RBM, which connects the two networks of the GAN, the discriminator and the generator. Associative memory networks can learn and evaluate a probabilistic model based on a higher representation discovered by the discriminator to generate input factors for the generator network. Although we have empirically tested the effectiveness of the proposed associative adversary networks, we hope to develop a more rigorous theoretical understanding in future work. If we look at the equation (1), we can see that it is possible for associative memory to collapse into a degenerated probability distribution, similar to the collapse of G."}], "references": [{"title": "Generative adversarial nets", "author": ["Ian Goodfellow", "Jean Pouget-Abadie", "Mehdi Mirza", "Bing Xu", "Warde-Farley David", "Sherjil Ozair", "Courville Aaron", "Yoshua Bengio"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "Unsupervised representation learning with deep convolutional generative adversarial networks", "author": ["Alec Radford", "Luke Metz", "Soumith Chintala"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2015}, {"title": "Improved techniques for training gans", "author": ["Tim Salimans", "Ian Goodfellow", "Wojciech Zaremba", "Vicki Cheung", "Alex Radfors", "Xi Chen"], "venue": "arXiv preprint arXiv:1606.03498,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2016}, {"title": "Connecting generative adversarial networks and actor-critic methods", "author": ["David Pfau", "Oriol Vinyals"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1945}, {"title": "On distinguishability criteria for estimating generative models", "author": ["Ian Goodfellow"], "venue": "ICLR 2015,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2014}, {"title": "Better mixing via deep representations", "author": ["Yann Dauphin Yoshua Bengio", "Gr\u00e9goire Mesnil", "Salah Rifai"], "venue": "Proc. of the ICML,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2013}, {"title": "Auto-encoding variational bayes", "author": ["Diederik P Kingma", "Max Welling"], "venue": "ICLR,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}, {"title": "Training generative neural networks via maximum mean discrepancy optimization", "author": ["Gintare Karolina Dziugaite", "Daniel M. Roy", "Zoubin Ghahramani"], "venue": "Uncertainty in Artificial Intelligence (UAI),", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2015}, {"title": "Stochastic backpropagation and approximate inference in deep generative models", "author": ["Daan Wierstra"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "Generative moment matching networks", "author": ["Yujia Li", "Kevin Swersky", "Richard Zemel"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2016}, {"title": "Deep generative image models using a laplacian pyramid of adversarial networks", "author": ["Emily Denton", "Soumith Chintala", "Arthur Szlam", "Rob Fergus"], "venue": "arXiv preprint arXiv:1506.05751,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2015}, {"title": "Draw: A recurrent neural network for image generation", "author": ["Karol Gregor", "Ivo Danihelka", "Alex Graves", "Daan Wierstra"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2015}, {"title": "Learning to generate chairs with convolutional neural networks", "author": ["Jost Tobias Dosovitskiy", "Alexey Springenberg", "Brox Thomas"], "venue": "arXiv preprint arXiv:1411.5928,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "Generating images with recurrent adversarial networks", "author": ["Daniel Jiwoong Im", "Chris Dongjoo Kim", "Hui Jiang", "Roland Memisevic"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2016}, {"title": "Pixel-level domain transfer", "author": ["Donggeun Yoo", "Namil Kim", "Sunggyun Park", "Anthony Paek", "In-So Kweon"], "venue": "arXiv preprint arXiv:1603.07442,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2016}, {"title": "A fast learning algorithm for deep belief nets", "author": ["Geoffrey E. Hinton", "Simon Osindero", "Yee Whye Teh"], "venue": "Neural Computation,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2006}, {"title": "Training products of experts by minimizing contrastive divergence", "author": ["G.E. Hinton"], "venue": "Neural Computation, pages 1771\u20131800", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2002}, {"title": "A practicle guide to restricted boltzmann machines", "author": ["G.E. Hinton"], "venue": "Technical Report: UTML TR 2010\u2013003", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2010}, {"title": "Training restricted boltzmann machines using approximations to the likelihood gradient", "author": ["Tijmen Tieleman"], "venue": "In Proceedings of the 25th International Conference on Machine Learning,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2008}, {"title": "Rectifier nonlinearities improve neural network acoustic models", "author": ["A.Y. Hannun A.L. Maas", "A.Y. Ng"], "venue": "Proc. of the ICML,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2013}, {"title": "Rectifier linear units improve restricted boltsmann machines", "author": ["V. Nair", "G.E. Hinton"], "venue": "ICML", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2010}, {"title": "Ising model", "author": ["K. Binder"], "venue": "Hazewinkel, Michiel, Encyclopedia of Mathematics, Springer", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2001}], "referenceMentions": [{"referenceID": 0, "context": "The generative adversarial network (GAN) framework [1] is a relatively new type of framework that introduces a generator G and a discriminator D, both of which are often chosen to be a type of multilayer perceptron (MLP) network, and are trained in an adversarial manner.", "startOffset": 51, "endOffset": 54}, {"referenceID": 1, "context": "Recent works have reported that models trained using the GAN framework (especially for the image generation task) can generate excellent samples [2].", "startOffset": 145, "endOffset": 148}, {"referenceID": 2, "context": "Nevertheless, it is widely reported that GAN models are difficult to train and different techniques are proposed (which are summarized in [3, 4, 5]).", "startOffset": 138, "endOffset": 147}, {"referenceID": 3, "context": "Nevertheless, it is widely reported that GAN models are difficult to train and different techniques are proposed (which are summarized in [3, 4, 5]).", "startOffset": 138, "endOffset": 147}, {"referenceID": 4, "context": "Most of these work try to deal with the difficulty of optimizing the G and D simultaneously in a synchronized manner and their joint convergence[6].", "startOffset": 144, "endOffset": 147}, {"referenceID": 2, "context": "[3] proposes to train the generator by a new objective that guides G to match the statistics of features on an intermediate layer of the discriminator.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] uses minibatch discrimination so that D can generate different gradients for data samples and continue guiding G via backpropagation and force G to diversify its outputs and avoid collapsing.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "In [7], a strong evidence is presented for better disentangling of the underlying factors of variation in data by higher-level representation spaces, and this might explain why a uniformly distributed random noise as input to G works.", "startOffset": 3, "endOffset": 6}, {"referenceID": 5, "context": "Also, mapping data samples to a lower dimensional but higher-level representation space by using D and then learning an associative memory model causes the Markov chain (used in the model training) to mix faster - thanks to a more uniform distribution in this new space [7].", "startOffset": 270, "endOffset": 273}, {"referenceID": 0, "context": "The generative adversarial networks (GANs) [1], variational autoencoders (VAE) [8], generative maximum mean discrepeancy networks [9], deep generative models[10], generative moment matching networks [11], etc.", "startOffset": 43, "endOffset": 46}, {"referenceID": 6, "context": "The generative adversarial networks (GANs) [1], variational autoencoders (VAE) [8], generative maximum mean discrepeancy networks [9], deep generative models[10], generative moment matching networks [11], etc.", "startOffset": 79, "endOffset": 82}, {"referenceID": 7, "context": "The generative adversarial networks (GANs) [1], variational autoencoders (VAE) [8], generative maximum mean discrepeancy networks [9], deep generative models[10], generative moment matching networks [11], etc.", "startOffset": 130, "endOffset": 133}, {"referenceID": 8, "context": "The generative adversarial networks (GANs) [1], variational autoencoders (VAE) [8], generative maximum mean discrepeancy networks [9], deep generative models[10], generative moment matching networks [11], etc.", "startOffset": 157, "endOffset": 161}, {"referenceID": 9, "context": "The generative adversarial networks (GANs) [1], variational autoencoders (VAE) [8], generative maximum mean discrepeancy networks [9], deep generative models[10], generative moment matching networks [11], etc.", "startOffset": 199, "endOffset": 203}, {"referenceID": 10, "context": "Some GAN extensions have looked at laplacian pyramid extensions [12] showing higher quality images, a recurrent network approach [13] and a de-convolution network approach [14] demonstrating reasonable success with generating natural images.", "startOffset": 64, "endOffset": 68}, {"referenceID": 11, "context": "Some GAN extensions have looked at laplacian pyramid extensions [12] showing higher quality images, a recurrent network approach [13] and a de-convolution network approach [14] demonstrating reasonable success with generating natural images.", "startOffset": 129, "endOffset": 133}, {"referenceID": 12, "context": "Some GAN extensions have looked at laplacian pyramid extensions [12] showing higher quality images, a recurrent network approach [13] and a de-convolution network approach [14] demonstrating reasonable success with generating natural images.", "startOffset": 172, "endOffset": 176}, {"referenceID": 1, "context": "Several recent papers focus on improving the stability of training and the quality of generated GAN samples [2, 12, 15, 16].", "startOffset": 108, "endOffset": 123}, {"referenceID": 10, "context": "Several recent papers focus on improving the stability of training and the quality of generated GAN samples [2, 12, 15, 16].", "startOffset": 108, "endOffset": 123}, {"referenceID": 13, "context": "Several recent papers focus on improving the stability of training and the quality of generated GAN samples [2, 12, 15, 16].", "startOffset": 108, "endOffset": 123}, {"referenceID": 14, "context": "Several recent papers focus on improving the stability of training and the quality of generated GAN samples [2, 12, 15, 16].", "startOffset": 108, "endOffset": 123}, {"referenceID": 3, "context": "Among recent ones (as recently summarized in [5]) the following pop out for stabilizing GAN training: balancing/freezing: to prevent the generator or discriminator to outpace one another, minibatch discrimination: to prevent the generator to collapse on to a single sample and enable back-propagation of gradients to improve weights, historical averaging [3], a technique common used in game theory that uses a historical average of parameters as a regularization term in optimization.", "startOffset": 45, "endOffset": 48}, {"referenceID": 2, "context": "Among recent ones (as recently summarized in [5]) the following pop out for stabilizing GAN training: balancing/freezing: to prevent the generator or discriminator to outpace one another, minibatch discrimination: to prevent the generator to collapse on to a single sample and enable back-propagation of gradients to improve weights, historical averaging [3], a technique common used in game theory that uses a historical average of parameters as a regularization term in optimization.", "startOffset": 355, "endOffset": 358}, {"referenceID": 1, "context": "[2], which uses strided convolutions in the initial layers of the discriminator and fractional-strided convolutions in the later layers of the generator, which will be discussed in the experiments section.", "startOffset": 0, "endOffset": 3}, {"referenceID": 15, "context": "In a way, our proposed technique resembles the learning algorithm for deep belief nets presented in [17], which utilizes a contrastive version of the wake-sleep algorithm proposed in [18].", "startOffset": 100, "endOffset": 104}, {"referenceID": 16, "context": "In a way, our proposed technique resembles the learning algorithm for deep belief nets presented in [17], which utilizes a contrastive version of the wake-sleep algorithm proposed in [18].", "startOffset": 183, "endOffset": 187}, {"referenceID": 0, "context": "GANs [1] are a class of generative models that pose the training process as a game between a generator network (G) and a discriminator network (D) both of which are non-stochastic models.", "startOffset": 5, "endOffset": 8}, {"referenceID": 4, "context": "The GAN problem can be formulated as a zero-sum game (minimax) which has a distinguishability game value function, V (D,G) [6]:", "startOffset": 123, "endOffset": 126}, {"referenceID": 17, "context": "Contrastive Divergence (CD) algorithm [20] runs the Markov chain for a few steps after clamping the visible layer to data examples.", "startOffset": 38, "endOffset": 42}, {"referenceID": 18, "context": "Another technique is to use persistent chains without clamping the visible layer [21].", "startOffset": 81, "endOffset": 85}, {"referenceID": 0, "context": "Images in the dataset are linearly scaled to the [-1, 1] range.", "startOffset": 49, "endOffset": 56}, {"referenceID": 1, "context": "Similar to [2], we used an Adam optimizer.", "startOffset": 11, "endOffset": 14}, {"referenceID": 19, "context": "We used leaky rectified linear activations (LeakyReLU) [22] for D with one exception to be discussed below and rectified linear activation [23] for G as activation functions.", "startOffset": 55, "endOffset": 59}, {"referenceID": 20, "context": "We used leaky rectified linear activations (LeakyReLU) [22] for D with one exception to be discussed below and rectified linear activation [23] for G as activation functions.", "startOffset": 139, "endOffset": 143}, {"referenceID": 21, "context": "We chose binary variable states as (-1) and (+1) similar to spin states in an Ising model [24].", "startOffset": 90, "endOffset": 94}, {"referenceID": 2, "context": "This is in agreement with the idea proposed in [3], which suggest changing G\u2019s objective to match an intermediate discriminator layer\u2019s statistics.", "startOffset": 47, "endOffset": 50}], "year": 2016, "abstractText": "We propose a higher-level associative memory for learning adversarial networks. Generative adversarial network (GAN) framework has a discriminator and a generator network. The generator (G) maps white noise (z) to data samples while the discriminator (D) maps data samples to a single scalar. To do so, G learns how to map from high-level representation space to data space, and D learns to do the opposite. We argue that higher-level representation spaces need not necessarily follow a uniform probability distribution. In this work, we use Restricted Boltzmann Machines (RBMs) as a higher-level associative memory and learn the probability distribution for the high-level features generated by D. The associative memory samples its underlying probability distribution and G learns how to map these samples to data space. The proposed associative adversarial networks (AANs) are generative models in the higher-levels of the learning, and use adversarial nonstochastic models D and G for learning the mapping between data and higher-level representation spaces. Experiments show the potential of the proposed networks.", "creator": "LaTeX with hyperref package"}}}