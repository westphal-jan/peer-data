{"id": "1611.07804", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Nov-2016", "title": "ATR4S: Toolkit with State-of-the-art Automatic Terms Recognition Methods in Scala", "abstract": "Automatically recognized terminology is widely used for various domain-specific texts processing tasks, such as machine translation, information retrieval or sentiment analysis. However, there is still no agreement on which methods are best suited for particular settings and, moreover, there is no reliable comparison of already developed methods. We believe that one of the main reasons is the lack of state-of-the-art methods implementations, which are usually non-trivial to recreate. In order to address these issues, we present ATR4S, an open-source software written in Scala that comprises more than 15 methods for automatic terminology recognition (ATR) and implements the whole pipeline from text document preprocessing, to term candidates collection, term candidates scoring, and finally, term candidates ranking. It is highly scalable, modular and configurable tool with support of automatic caching. We also compare 10 state-of-the-art methods on 7 open datasets by average precision and processing time. Experimental comparison reveals that no single method demonstrates best average precision for all datasets and that other available tools for ATR do not contain the best methods.", "histories": [["v1", "Wed, 23 Nov 2016 14:14:52 GMT  (20kb)", "http://arxiv.org/abs/1611.07804v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["n astrakhantsev"], "accepted": false, "id": "1611.07804"}, "pdf": {"name": "1611.07804.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Nikita Astrakhantsev"], "emails": ["astrakhantsev@ispras.ru"], "sections": [{"heading": null, "text": "ar Xiv: 161 1.07 804v 1 [cs.C L] 23 Nov 2To solve these problems, we introduce ATR4S, an open source software written in Scala that includes more than 15 methods for automatic terminology recognition (ATR) and implements the entire pipeline from pre-processing of text documents to term candidate capture, term candidate evaluation and finally term candidate ranking. It is highly scalable, modular and configurable and supports automatic caching. We also compare 13 state-of-the-art methods on 7 open data sets according to average precision and processing time. Experimental comparison shows that no single method demonstrates the best average precision for all data sets and that other available tools for ATR do not include the best methods.Keyword Automatic Term Recognition \u00b7 Terminology Extraction \u00b7 Open Source SoftwareThe reported study was conducted by RFBR, Research Project No. 14-Alantul."}, {"heading": "1 Introduction", "text": "This year, it is closer than ever before in the history of the country."}, {"heading": "3 Architecture", "text": "In fact, most of them will be able to abide by the rules that they have imposed on themselves, and that they will be able to abide by the rules that they have imposed on themselves. (...) Most of them are able to abide by the rules. (...) Most of them are able to abide by the rules. (...) Most of them are not able to abide by the rules. (...) Most of them are not able to abide by the rules. (...) Most of them are not able to abide by the rules. (...) Most of them are not able to abide by the rules. (...) Most of them are not able to abide by the rules. (...) Most of them are not able to abide by the rules. (...)"}, {"heading": "3.3.1 Methods based on occurrences frequencies", "text": "Most methods for evaluating term candidates are based on the intuition that the more common a word or collocation occurs in the domain-specific text collection, the more likely it is that it is a term for that domain. This section describes methods that only use this intuition, i.e. those that only take into account the frequency of words that make up term candidates and ignore other information.In addition to term frequency (TF) itself, this group contains average term frequency (ATF) [47], TF-IDF [15], Residual IDF [47], CValue [18], Basic [6] and ComboBasic [3]. ATF simply normalizes term frequency based on the number of documents containing this term applicator.TF-IDF is a classical information retrieval that has high values for term applicants that frequently occur in few documents: TF \u00b7 DF (t) = TF (TF) (TF) (Dt) (DD), where a candidate is a DF (DT)."}, {"heading": "3.3.2 Methods based on occurrences contexts", "text": "The methods from this group follow the distribution hypothesis [20] and try to distinguish terms from non-terms by taking their context into account. We know of only two such methods: NC value [18] and domain coherence [6]; since the latter is a modification of the former and has proven to be better [6], ATR4S includes only these. Domain coherence works in 3 steps. First, it extracts 200 best term candidates by applying the Basic method. Then, words are filtered from contexts of previously extracted 200 terms: it records only nouns, adjectives, verbs and adverbs that occur in at least a quarter of all documents and are similar to these 200 term candidates, i.e. they rank in the top 50 by average standardized PMI words: s (w) = 1 | T | T | T | T TNPMI (t, w) is a word in the context in which the best (w) is."}, {"heading": "3.3.3 Methods based on reference corpora", "text": "There are several methods that are based on the assumption that terms can be distinguished from other words and collocations by comparing the occurrence statistics of the domain-specific collection under consideration with statistics of a reference corpus (usually from the general domain). DomainPertinence [33] is the simplest implementation of this idea: DomainPertinence (t) = TFtarget (t) TFreference (t), (7) where TFtarget (t) is a frequency of the term candidate t in the target-specific (domain-specific) collection; TFreference is a frequency in the reference collection. Weirdness [1] normalizes it by the size (in words) of the document collections: Weirdness (t) = NTFtarget (t) NTFreference (t) and NTFreference (t) are frequencies of t normalized by the size of the target and reference collections, corresponding to the variation of 11.Relevance of T38, [where] they are normalized by the size of the target group (11), and (where) by Ttarget group (11)."}, {"heading": "3.3.4 Methods based on topic modeling", "text": "These methods are based on the idea that topic modeling reveals semantic information useful for term recognition; in particular, that the distribution of words over topics found by topic modeling is a less noisy signal than the simple frequency of occurrence. To our knowledge, this group contains only one method capable of extracting terms of any length, namely the Novel Topic Model [27]. Initially, it obtains the probability distribution of words over the following topics: throut - general topics (1 \u2264 t 20); \u03c6B - background topic; \u03c6D - document-specific topic. Then, it extracts 200 words most likely for each topic: Vt, VB, VD, accordingly; finally, for each thermal candidate its weight is calculated as the sum of the maximum probabilities for each of its Li-words (wi1wiLi): NTM (ci) = Log (TFi) \u00b7 TEST-TEST-TEST-TEST-TEST-TEST-TEST-TEST-TEST-TEST-TEST-TEST-TEST-TEST-TEST-TEST-TEST-TEST-TEST-TEST-TEST-TEST-TEST-TEST-TEST-TEST-TEST-TEST-TEST TEST TEST TEST TEST TEST TEST TEST TEST TEST TEST TEST TEST TEST TEST TEST TEST TEST TEST TEST TEST TEST TEST TEST TEST TEST TEST TEST TEST TEST TEST TEST TEST TEST TTEST TEST TTEST TEST TEST TTEST TEST TTTTEST TEST TTTTEST TR-Tr."}, {"heading": "3.3.5 Methods based on Wikipedia", "text": "In fact, most of them will be able to move to another world, in which they are able, in which they are able to move, and in which they are able to change the world."}, {"heading": "5 Conclusion", "text": "ATR4S includes more than 15 methods for ATR, supports caching and human-readable configuration; it is written in Scala with parallel collections where appropriate, and therefore uses all CPU cores. Experimental comparison confirms observations that (1) no single method is best for all data sets [46] and (2) several features should be combined for better quality [17]; it also shows that other available tools lack the best methods, i.e. actual state-of-the-art methods, namely PU-ATR [3], KeyConceptRelatedness [3], NovelTopicModel [27] and Basic [6]. It is obvious that ATR4S does not include all methods that are capable of outperforming already implemented methods in some settings. However, we believe that these implementations can be used as a valuable basis for developing new methods or at least for comparing other methods."}], "references": [{"title": "University of surrey participation in trec8: Weirdness indexing for logical document extrapolation and retrieval (wilder)", "author": ["K. Ahmad", "L. Gillam", "L Tostevin"], "venue": "The Eighth Text REtrieval Conference (TREC-8)", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1999}, {"title": "Automatic term acquisition from domain-specific text collection by using wikipedia", "author": ["N. Astrakhantsev"], "venue": "Proceedings of the Institute for System Programming 26(4), 7\u201320", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2014}, {"title": "Methods and software for terminology extraction from domainspecific text collection", "author": ["N. Astrakhantsev"], "venue": "Ph.D. thesis, Institute for System Programming of Russian Academy of Sciences", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}, {"title": "Automatic enrichment of informal ontology by analyzing a domain-specific text collection", "author": ["N. Astrakhantsev", "D. Fedorenko", "D. Turdakov"], "venue": "Computational Linguistics and Intellectual Technologies: Papers from the Annual International Conference Dialogue 13, 29\u201342", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2014}, {"title": "Methods for automatic term recognition in domain-specific text collections: A survey", "author": ["N. Astrakhantsev", "D. Fedorenko", "D.Y. Turdakov"], "venue": "Programming and Computer Software 41(6), 336\u2013349", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2015}, {"title": "Domain-independent term extraction through domain modelling", "author": ["G. Bordea", "P. Buitelaar", "T. Polajnar"], "venue": "the 10th International Conference on Terminology and Artificial Intelligence (TIA 2013), Paris, France", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "Expertise mining from scientific literature", "author": ["P. Buitelaar", "T. Eigner"], "venue": "Proceedings of the Fifth International Conference on Knowledge Capture, K-CAP \u201909, pp. 171\u2013172. ACM, New York, NY, USA", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2009}, {"title": "Inverse document frequency (idf): A measure of deviations from poisson", "author": ["K. Church", "W. Gale"], "venue": "Natural language processing using very large corpora, pp. 283\u2013295. Springer", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1999}, {"title": "6", "author": ["K. Church", "W. Gale", "P. Hanks", "D. Kindle"], "venue": "using statistics in lexical analysis. Lexical acquisition: exploiting on-line resources to build a lexicon p. 115", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1991}, {"title": "Word association norms, mutual information, and lexicography", "author": ["K.W. Church", "P. Hanks"], "venue": "Computational linguistics 16(1), 22\u201329", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1990}, {"title": "Termsuite: Terminology extraction with term variant detection", "author": ["D. Cram", "B. Daille"], "venue": "ACL 2016 p. 13", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2016}, {"title": "The construction of a thesaurus automatically from a sample of text", "author": ["S.F. Dennis"], "venue": "Proceedings of the Symposium on Statistical Association Methods For Mechanized Documentation, Washington, DC, pp. 61\u2013148", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1965}, {"title": "Accurate methods for the statistics of surprise and coincidence", "author": ["T. Dunning"], "venue": "Computational linguistics 19(1), 61\u201374", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1993}, {"title": "Kp-miner: Participation in semeval-2", "author": ["S.R. El-Beltagy", "A. Rafea"], "venue": "Proceedings of the 5th international workshop on semantic evaluation, pp. 190\u2013193. Association for Computational Linguistics", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2010}, {"title": "Clarit-trec experiments", "author": ["D.A. Evans", "R.G. Lefferts"], "venue": "Information processing & management 31(3), 385\u2013395", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1995}, {"title": "Growing multi-domain glossaries from a few seeds using probabilistic topic models", "author": ["S. Faralli", "R. Navigli"], "venue": "EMNLP, pp. 170\u2013181", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2013}, {"title": "Automatic recognition of domainspecific terms: an experimental evaluation", "author": ["D. Fedorenko", "N. Astrakhantsev", "D. Turdakov"], "venue": "Proceedings of SYRCoDIS 2013, pp. 15\u201323", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2013}, {"title": "Automatic recognition of multi-word terms", "author": ["K. Frantzi", "S. Ananiadou", "H. Mima"], "venue": "the c-value/nc-value method. International Journal on Digital Libraries 3(2), 115\u2013130", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2000}, {"title": "Flow network models for word alignment and terminology extraction from bilingual corpora", "author": ["\u00c9. Gaussier"], "venue": "Proceedings of the 17th international conference on Computational linguistics-Volume 1, pp. 444\u2013450. Association for Computational Linguistics", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1998}, {"title": "Distributional structure", "author": ["Z.S. Harris"], "venue": "Word 10(2-3), 146\u2013162", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1954}, {"title": "Unsupervised training set generation for automatic acquisition of technical terminology in patents", "author": ["A. Judea", "H. Sch\u00fctze", "S. Bruegmann"], "venue": "Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers, pp. 290\u2013300. Dublin City University and Association for Computational Linguistics, Dublin, Ireland", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2014}, {"title": "Methods of automatic term recognition: A review", "author": ["K. Kageura", "B. Umino"], "venue": "Terminology 3(2), 259\u2013289", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1996}, {"title": "Genia corpus\u2013a semantically annotated corpus for bio-textmining", "author": ["J.D. Kim", "T. Ohta", "Y. Tateisi", "J. Tsujii"], "venue": "Bioinformatics 19(Suppl 1), i180\u2013i182", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2003}, {"title": "Europarl: A parallel corpus for statistical machine translation", "author": ["P. Koehn"], "venue": "MT summit, vol. 5, pp. 79\u201386", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2005}, {"title": "Glossary extraction and utilization in the information search and delivery system for ibm technical support", "author": ["L. Kozakov", "Y. Park", "T. Fin", "Y. Drissi", "Y. Doganata", "T. Cofino"], "venue": "IBM Systems Journal 43(3), 546\u2013563", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2004}, {"title": "Large dataset for keyphrases extraction", "author": ["M. Krapivin", "A. Autaeu", "M. Marchese"], "venue": null, "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2009}, {"title": "A novel topic model for automatic term extraction", "author": ["S. Li", "J. Li", "T. Song", "W. Li", "B. Chang"], "venue": "Proceedings of the 36th international ACM SIGIR conference on Research and development in information retrieval, pp. 885\u2013888. ACM", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2013}, {"title": "Improving retrieval effectiveness by using key terms in top retrieved documents", "author": ["Y. Lingpeng", "J. Donghong", "Z. Guodong", "N. Yu"], "venue": "Advances in Information Retrieval, pp. 169\u2013184. Springer", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2005}, {"title": "Partially supervised classification of text documents", "author": ["B. Liu", "W.S. Lee", "P.S. Yu", "X. Li"], "venue": "ICML, vol. 2, pp. 387\u2013394. Citeseer", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2002}, {"title": "The Stanford CoreNLP natural language processing toolkit", "author": ["C.D. Manning", "M. Surdeanu", "J. Bauer", "J. Finkel", "S.J. Bethard", "D. McClosky"], "venue": "Association for Computational Linguistics (ACL) System Demonstrations, pp. 55\u201360", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2014}, {"title": "A high precision method for aspect extraction in russian", "author": ["V. Mayorov", "I. Andrianov", "N. Astrakhantsev", "V. Avanesov", "I. Kozlov", "D. Turdakov"], "venue": "Proceedings of International Conference Dialog, vol. 2", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2015}, {"title": "Domain-independent automatic keyphrase indexing with small training sets", "author": ["O. Medelyan", "I.H. Witten"], "venue": "Journal of the American Society for Information Science and Technology 59(7), 1026\u20131040", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2008}, {"title": "A semantic approach for extracting domain taxonomies from text", "author": ["K. Meijer", "F. Frasincar", "F. Hogenboom"], "venue": "Decision Support Systems 62, 78\u201393", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2014}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["T. Mikolov", "I. Sutskever", "K. Chen", "G.S. Corrado", "J. Dean"], "venue": "Advances in neural information processing systems, pp. 3111\u20133119", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2013}, {"title": "An experimental study of term extraction for real information-retrieval thesauri", "author": ["M. Nokel", "N. Loukachevitch"], "venue": "Proceedings of 10th International Conference on Terminology and Artificial Intelligence, pp. 69\u201376", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2013}, {"title": "Automatic glossary extraction: beyond terminology identification", "author": ["Y. Park", "R. Byrd", "B. Boguraev"], "venue": "Proceedings of the 19th international conference on Computational linguistics-Volume 1, pp. 1\u20137. Association for Computational Linguistics", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2002}, {"title": "Terminology extraction: an analysis of linguistic and statistical approaches", "author": ["M. Pazienza", "M. Pennacchiotti", "F. Zanzotto"], "venue": "Knowledge Mining pp. 255\u2013279", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2005}, {"title": "Corpus-based terminology extraction applied to information access", "author": ["A. Pe\u00f1as", "F. Verdejo", "J Gonzalo"], "venue": "Proceedings of Corpus Linguistics, vol. 2001. Citeseer", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2001}, {"title": "The ACL RD-TEC", "author": ["B. QasemiZadeh", "A.K. Schumann"], "venue": null, "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2016}, {"title": "The SMART Retrieval System\u2014Experiments in Automatic Document Processing", "author": ["G. Salton"], "venue": "Prentice-Hall, Inc., Upper Saddle River, NJ, USA", "citeRegEx": "40", "shortCiteRegEx": null, "year": 1971}, {"title": "Flexiterm: a flexible term recognition method", "author": ["I. Spasi\u0107", "M. Greenwood", "A. Preece", "N. Francis", "G. Elwyn"], "venue": "Journal of biomedical semantics 4(1), 1", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2013}, {"title": "Texterra: A framework for text analysis", "author": ["D.Y. Turdakov", "N. Astrakhantsev", "Y.R. Nedumov", "A. Sysoev", "I. Andrianov", "V. Mayorov", "D. Fedorenko", "A. Korshunov", "S.D. Kuznetsov"], "venue": "Programming and Computer Software 40(5), 288\u2013295", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2014}, {"title": "Combining c-value and keyword extraction methods for biomedical terms extraction", "author": ["J.A.L. Ventura", "C. Jonquet", "M. Roche", "M Teisseire"], "venue": "LBM\u20192013: International Symposium on Languages in Biology and Medicine, pp. 45\u201349", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2013}, {"title": "You can\u2019t beat frequency (unless you use linguistic knowledge): a qualitative evaluation of association measures for collocation and term extraction", "author": ["J. Wermter", "U. Hahn"], "venue": "Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, pp. 785\u2013792. Association for Computational Linguistics", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2006}, {"title": "The acl rd-tec: A dataset for benchmarking terminology extraction and classification in computational linguistics", "author": ["B.Q. Zadeh", "S. Handschuh"], "venue": "COLING 2014: Proceedings of the 4th International Workshop on Computational Terminology (CompuTerm\u201914). Dublin, Ireland", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2014}, {"title": "A comparative evaluation of term recognition algorithms", "author": ["Z. Zhang", "C. Brewster", "F. Ciravegna"], "venue": "Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC08), Marrakech, Morocco", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2008}, {"title": "Jate 2.0: Java automatic term extraction with apache solr", "author": ["Z. Zhang", "J. Gao", "F. Ciravegna"], "venue": "The LREC 2016 Proceedings", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 2016}], "referenceMentions": [{"referenceID": 18, "context": "Extracted terms then can be used for many tasks including machine translation [19], information retrieval [28], sentiment analysis [31], ontology construction and ontology enrichment [5].", "startOffset": 78, "endOffset": 82}, {"referenceID": 27, "context": "Extracted terms then can be used for many tasks including machine translation [19], information retrieval [28], sentiment analysis [31], ontology construction and ontology enrichment [5].", "startOffset": 106, "endOffset": 110}, {"referenceID": 30, "context": "Extracted terms then can be used for many tasks including machine translation [19], information retrieval [28], sentiment analysis [31], ontology construction and ontology enrichment [5].", "startOffset": 131, "endOffset": 135}, {"referenceID": 4, "context": "Extracted terms then can be used for many tasks including machine translation [19], information retrieval [28], sentiment analysis [31], ontology construction and ontology enrichment [5].", "startOffset": 183, "endOffset": 186}, {"referenceID": 16, "context": "Despite this importance, the ATR task is still far from being solved: researches continue to propose new methods for ATR, which usually show average precision below 80% even on top 500-1000 terms [17,46,47] and thus are hardly used in practice.", "startOffset": 196, "endOffset": 206}, {"referenceID": 45, "context": "Despite this importance, the ATR task is still far from being solved: researches continue to propose new methods for ATR, which usually show average precision below 80% even on top 500-1000 terms [17,46,47] and thus are hardly used in practice.", "startOffset": 196, "endOffset": 206}, {"referenceID": 46, "context": "Despite this importance, the ATR task is still far from being solved: researches continue to propose new methods for ATR, which usually show average precision below 80% even on top 500-1000 terms [17,46,47] and thus are hardly used in practice.", "startOffset": 196, "endOffset": 206}, {"referenceID": 2, "context": "Modification of KeyConceptRelatedness method [3] by replacing proprietary module for semantic relatedness computation with open-source tool word2vec [34].", "startOffset": 45, "endOffset": 48}, {"referenceID": 33, "context": "Modification of KeyConceptRelatedness method [3] by replacing proprietary module for semantic relatedness computation with open-source tool word2vec [34].", "startOffset": 149, "endOffset": 153}, {"referenceID": 2, "context": "In particular, more correct evaluation of unsupervised methods with many parameters (namely, PU-ATR [3] and aforementioned KeyConceptRelatedness) by adapting the cross-validation strategy.", "startOffset": 100, "endOffset": 103}, {"referenceID": 21, "context": "The first survey by Kageura and Umino [22] devoted to ATR distinguished all methods into linguistic and statistical.", "startOffset": 38, "endOffset": 42}, {"referenceID": 36, "context": "[37] of 2005, it was argued that all modern algorithms include linguistic methods", "startOffset": 0, "endOffset": 4}, {"referenceID": 4, "context": "[5] identified the general pipeline of ATR methods: preprocessing, term candidates collection, term candidates scoring, and term candidates ranking.", "startOffset": 0, "endOffset": 3}, {"referenceID": 20, "context": "Preprocessing transforms input text into a sequence of elements needed for further term candidates extraction; most often, each of such elements consists of lemmatized token with attached part of speech tag; some works [21,47] use instead noun phrases obtained by shallow parsing.", "startOffset": 219, "endOffset": 226}, {"referenceID": 46, "context": "Preprocessing transforms input text into a sequence of elements needed for further term candidates extraction; most often, each of such elements consists of lemmatized token with attached part of speech tag; some works [21,47] use instead noun phrases obtained by shallow parsing.", "startOffset": 219, "endOffset": 226}, {"referenceID": 3, "context": "Another set of works [4,17,35] apply supervised machine learning.", "startOffset": 21, "endOffset": 30}, {"referenceID": 16, "context": "Another set of works [4,17,35] apply supervised machine learning.", "startOffset": 21, "endOffset": 30}, {"referenceID": 34, "context": "Another set of works [4,17,35] apply supervised machine learning.", "startOffset": 21, "endOffset": 30}, {"referenceID": 40, "context": "For example, TerMine is based on CValue/NC-Value methods (and academic usage only); FlexiTerm contains C-Value and \u201da simple term variant normalisation method\u201d [41]; TOPIA lists only one method without algorithm description and it is not updated since 2009; TermRider utilizes TF-IDF only; TermSuite [11] ranks candidates by Weirdness method, but focuses on recognizing term variants based on syntactic and morphological patterns.", "startOffset": 160, "endOffset": 164}, {"referenceID": 10, "context": "For example, TerMine is based on CValue/NC-Value methods (and academic usage only); FlexiTerm contains C-Value and \u201da simple term variant normalisation method\u201d [41]; TOPIA lists only one method without algorithm description and it is not updated since 2009; TermRider utilizes TF-IDF only; TermSuite [11] ranks candidates by Weirdness method, but focuses on recognizing term variants based on syntactic and morphological patterns.", "startOffset": 300, "endOffset": 304}, {"referenceID": 41, "context": "Some tools are limited by searching for mentions of (named) entities (for example, OpenCalais) or named entites and Wikipedia concepts (Texterra [42]).", "startOffset": 145, "endOffset": 149}, {"referenceID": 46, "context": "0 [47] is the most similar tool to ATR4S: it is written in Java and also can be natively used in any JVM-based language, contains many ATR algorithms and multiple methods for term candidates collection; it is highly modular and adaptable.", "startOffset": 2, "endOffset": 6}, {"referenceID": 45, "context": "However, it lacks a lot of actual state-of-the-art methods, namely those based on occurrences contexts, topic models, Wikipedia, and non-trivial ranking algorithms such as Voting [46] and PU-ATR [3].", "startOffset": 179, "endOffset": 183}, {"referenceID": 2, "context": "However, it lacks a lot of actual state-of-the-art methods, namely those based on occurrences contexts, topic models, Wikipedia, and non-trivial ranking algorithms such as Voting [46] and PU-ATR [3].", "startOffset": 195, "endOffset": 198}, {"referenceID": 29, "context": "In order to perform these tasks, ATR4S incorporated 3 external NLP libraries: Stanford CoreNLP [30], Emory nlp4j and Apache OpenNLP.", "startOffset": 95, "endOffset": 99}, {"referenceID": 39, "context": "By default, we use stop words list from the SMART retrieval system [40].", "startOffset": 67, "endOffset": 71}, {"referenceID": 6, "context": "By default, we apply the commonly-used pattern [7] extended by allowing prepositions between nouns: (NN(S)?|JJ|NNP|NN(S?)IN)*(NN(S)?)", "startOffset": 47, "endOffset": 50}, {"referenceID": 46, "context": "Besides Term frequency (TF) itself, this group contains Average term frequency (ATF) [47], TF-IDF [15], Residual IDF (RIDF) [47], CValue [18], Basic [6], and ComboBasic [3].", "startOffset": 85, "endOffset": 89}, {"referenceID": 14, "context": "Besides Term frequency (TF) itself, this group contains Average term frequency (ATF) [47], TF-IDF [15], Residual IDF (RIDF) [47], CValue [18], Basic [6], and ComboBasic [3].", "startOffset": 98, "endOffset": 102}, {"referenceID": 46, "context": "Besides Term frequency (TF) itself, this group contains Average term frequency (ATF) [47], TF-IDF [15], Residual IDF (RIDF) [47], CValue [18], Basic [6], and ComboBasic [3].", "startOffset": 124, "endOffset": 128}, {"referenceID": 17, "context": "Besides Term frequency (TF) itself, this group contains Average term frequency (ATF) [47], TF-IDF [15], Residual IDF (RIDF) [47], CValue [18], Basic [6], and ComboBasic [3].", "startOffset": 137, "endOffset": 141}, {"referenceID": 5, "context": "Besides Term frequency (TF) itself, this group contains Average term frequency (ATF) [47], TF-IDF [15], Residual IDF (RIDF) [47], CValue [18], Basic [6], and ComboBasic [3].", "startOffset": 149, "endOffset": 152}, {"referenceID": 2, "context": "Besides Term frequency (TF) itself, this group contains Average term frequency (ATF) [47], TF-IDF [15], Residual IDF (RIDF) [47], CValue [18], Basic [6], and ComboBasic [3].", "startOffset": 169, "endOffset": 172}, {"referenceID": 7, "context": "RIDF was originally proposed for keywords extraction [8] and than re-used for term recognition [47].", "startOffset": 53, "endOffset": 56}, {"referenceID": 46, "context": "RIDF was originally proposed for keywords extraction [8] and than re-used for term recognition [47].", "startOffset": 95, "endOffset": 99}, {"referenceID": 42, "context": "[43] that supports one-word term candidates as well:", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "Note that ATR4S does not include methods based on word association measures like z-test [12], t-test [9], \u03c7-test, Loglikelihood [13], Mutual Information (MI) [10], Lexical Cohesion [36], Term Cohesion [25], because they were repeatedly shown to obtain not better results than simple frequency [44,35,47].", "startOffset": 88, "endOffset": 92}, {"referenceID": 8, "context": "Note that ATR4S does not include methods based on word association measures like z-test [12], t-test [9], \u03c7-test, Loglikelihood [13], Mutual Information (MI) [10], Lexical Cohesion [36], Term Cohesion [25], because they were repeatedly shown to obtain not better results than simple frequency [44,35,47].", "startOffset": 101, "endOffset": 104}, {"referenceID": 12, "context": "Note that ATR4S does not include methods based on word association measures like z-test [12], t-test [9], \u03c7-test, Loglikelihood [13], Mutual Information (MI) [10], Lexical Cohesion [36], Term Cohesion [25], because they were repeatedly shown to obtain not better results than simple frequency [44,35,47].", "startOffset": 128, "endOffset": 132}, {"referenceID": 9, "context": "Note that ATR4S does not include methods based on word association measures like z-test [12], t-test [9], \u03c7-test, Loglikelihood [13], Mutual Information (MI) [10], Lexical Cohesion [36], Term Cohesion [25], because they were repeatedly shown to obtain not better results than simple frequency [44,35,47].", "startOffset": 158, "endOffset": 162}, {"referenceID": 35, "context": "Note that ATR4S does not include methods based on word association measures like z-test [12], t-test [9], \u03c7-test, Loglikelihood [13], Mutual Information (MI) [10], Lexical Cohesion [36], Term Cohesion [25], because they were repeatedly shown to obtain not better results than simple frequency [44,35,47].", "startOffset": 181, "endOffset": 185}, {"referenceID": 24, "context": "Note that ATR4S does not include methods based on word association measures like z-test [12], t-test [9], \u03c7-test, Loglikelihood [13], Mutual Information (MI) [10], Lexical Cohesion [36], Term Cohesion [25], because they were repeatedly shown to obtain not better results than simple frequency [44,35,47].", "startOffset": 201, "endOffset": 205}, {"referenceID": 43, "context": "Note that ATR4S does not include methods based on word association measures like z-test [12], t-test [9], \u03c7-test, Loglikelihood [13], Mutual Information (MI) [10], Lexical Cohesion [36], Term Cohesion [25], because they were repeatedly shown to obtain not better results than simple frequency [44,35,47].", "startOffset": 293, "endOffset": 303}, {"referenceID": 34, "context": "Note that ATR4S does not include methods based on word association measures like z-test [12], t-test [9], \u03c7-test, Loglikelihood [13], Mutual Information (MI) [10], Lexical Cohesion [36], Term Cohesion [25], because they were repeatedly shown to obtain not better results than simple frequency [44,35,47].", "startOffset": 293, "endOffset": 303}, {"referenceID": 46, "context": "Note that ATR4S does not include methods based on word association measures like z-test [12], t-test [9], \u03c7-test, Loglikelihood [13], Mutual Information (MI) [10], Lexical Cohesion [36], Term Cohesion [25], because they were repeatedly shown to obtain not better results than simple frequency [44,35,47].", "startOffset": 293, "endOffset": 303}, {"referenceID": 19, "context": "Methods from this group follows the distributional hypothesis [20] and try to distinguish terms from non-terms by considering their contexts.", "startOffset": 62, "endOffset": 66}, {"referenceID": 17, "context": "We are aware of only 2 such methods: NC-Value [18] and DomainCoherence [6]; since the latter is a modification of the former and was shown to work better [6], ATR4S includes only it.", "startOffset": 46, "endOffset": 50}, {"referenceID": 5, "context": "We are aware of only 2 such methods: NC-Value [18] and DomainCoherence [6]; since the latter is a modification of the former and was shown to work better [6], ATR4S includes only it.", "startOffset": 71, "endOffset": 74}, {"referenceID": 5, "context": "We are aware of only 2 such methods: NC-Value [18] and DomainCoherence [6]; since the latter is a modification of the former and was shown to work better [6], ATR4S includes only it.", "startOffset": 154, "endOffset": 157}, {"referenceID": 32, "context": "DomainPertinence [33] is the simplest implementation of this idea:", "startOffset": 17, "endOffset": 21}, {"referenceID": 0, "context": "Weirdness [1] normalizes it by sizes (in number of words) of document collections:", "startOffset": 10, "endOffset": 13}, {"referenceID": 37, "context": "Relevance [38] further updates it by taking into account fraction of documents, where term candidate occur:", "startOffset": 10, "endOffset": 14}, {"referenceID": 26, "context": "To the best of our knowledge, this group contains only one method capable to extract terms of arbitrary length, that is Novel Topic Model [27].", "startOffset": 138, "endOffset": 142}, {"referenceID": 2, "context": "Example of its usage is an additional filter for other methods [3].", "startOffset": 63, "endOffset": 66}, {"referenceID": 1, "context": "LinkProbability [2] is a normalized frequency of being hyperlink in Wikipedia pages:", "startOffset": 16, "endOffset": 19}, {"referenceID": 1, "context": "KeyConceptsRelatedness [2] interprets domain-specific terms as words and collocations that are semantically related to knowingly domain-specific concepts.", "startOffset": 23, "endOffset": 26}, {"referenceID": 33, "context": "We modified this: instead of Dice measure, we use cosine distance between word embedding vectors [34] corresponding to Wikipedia concepts.", "startOffset": 97, "endOffset": 101}, {"referenceID": 13, "context": "We propose to use simplified version of KP-Miner [14]: In order to be considered as a candidate to key concept, a word or a collocation must: (a) occur at least twice; (b) have an occurrence among the first 800 words; (c) be a valid term candidate, i.", "startOffset": 49, "endOffset": 53}, {"referenceID": 5, "context": "Examples include PostRankDC [6] and GlossEx [36].", "startOffset": 28, "endOffset": 31}, {"referenceID": 35, "context": "Examples include PostRankDC [6] and GlossEx [36].", "startOffset": 44, "endOffset": 48}, {"referenceID": 45, "context": "Voting algorithm [46] considers values of all term candidates and it was shown [46] to outperform single methods and weighted average (i.", "startOffset": 17, "endOffset": 21}, {"referenceID": 45, "context": "Voting algorithm [46] considers values of all term candidates and it was shown [46] to outperform single methods and weighted average (i.", "startOffset": 79, "endOffset": 83}, {"referenceID": 1, "context": "More sophisticated approach is PU-ATR [2], which is based on the ideas of bootstrapping (like NC-Value and DomainCoherence) and positive unlabeled (PU) learning.", "startOffset": 38, "endOffset": 41}, {"referenceID": 2, "context": "ComboBasic is recommended [3] as a seed method, because (a) it lets to adjust the level of specificity of seed terms and thus indirectly affects the level of specificity of all terms; (b) it is simple enough to include terms of different nature, i.", "startOffset": 26, "endOffset": 29}, {"referenceID": 2, "context": "Thus, following the previous work [3], we assume that scoring methods from different groups weakly correlate and choose them as features: C-Value (occurrences frequencies), DomainCoherence (occurrences contexts), Relevance (reference corpora), NovelTopicModel (topic modeling), LinkProbability (Wikipedia, domain-independent specificity), KeyConceptRelatedness (Wikipedia, domain-specificity).", "startOffset": 34, "endOffset": 37}, {"referenceID": 2, "context": "Different Positive-Unlabeled algorithms were shown [3] to work similarly for this task, so we chose the simplest one [29], with Logistic Regression as an internal probabilistic classifier (during preliminary experiments we found it outperforming Random Forest classifier).", "startOffset": 51, "endOffset": 54}, {"referenceID": 28, "context": "Different Positive-Unlabeled algorithms were shown [3] to work similarly for this task, so we chose the simplest one [29], with Logistic Regression as an internal probabilistic classifier (during preliminary experiments we found it outperforming Random Forest classifier).", "startOffset": 117, "endOffset": 121}, {"referenceID": 22, "context": "We evaluate ATR4S on 7 datasets: GENIA [23], FAO [32], Krapivin [26], Patents [21], ACL RD-TEC [45], ACL RD-TEC 2.", "startOffset": 39, "endOffset": 43}, {"referenceID": 31, "context": "We evaluate ATR4S on 7 datasets: GENIA [23], FAO [32], Krapivin [26], Patents [21], ACL RD-TEC [45], ACL RD-TEC 2.", "startOffset": 49, "endOffset": 53}, {"referenceID": 25, "context": "We evaluate ATR4S on 7 datasets: GENIA [23], FAO [32], Krapivin [26], Patents [21], ACL RD-TEC [45], ACL RD-TEC 2.", "startOffset": 64, "endOffset": 68}, {"referenceID": 20, "context": "We evaluate ATR4S on 7 datasets: GENIA [23], FAO [32], Krapivin [26], Patents [21], ACL RD-TEC [45], ACL RD-TEC 2.", "startOffset": 78, "endOffset": 82}, {"referenceID": 44, "context": "We evaluate ATR4S on 7 datasets: GENIA [23], FAO [32], Krapivin [26], Patents [21], ACL RD-TEC [45], ACL RD-TEC 2.", "startOffset": 95, "endOffset": 99}, {"referenceID": 38, "context": "0 [39], EuroParl [24] with Eurovoc thesaurus.", "startOffset": 2, "endOffset": 6}, {"referenceID": 23, "context": "0 [39], EuroParl [24] with Eurovoc thesaurus.", "startOffset": 17, "endOffset": 21}, {"referenceID": 15, "context": "Krapivin Computer Science 2304 21189 8766 Authors\u2019 keywords and Protodog [16] glossary Patents Engineering 12 120 1595 Manual markup", "startOffset": 73, "endOffset": 77}, {"referenceID": 45, "context": "Experimental comparison confirms observations that (1) no single method is best for all datasets [46] and (2) multiple features should be combined for better quality [17]; also it shows that other available tools lack the best methods, i.", "startOffset": 97, "endOffset": 101}, {"referenceID": 16, "context": "Experimental comparison confirms observations that (1) no single method is best for all datasets [46] and (2) multiple features should be combined for better quality [17]; also it shows that other available tools lack the best methods, i.", "startOffset": 166, "endOffset": 170}, {"referenceID": 2, "context": "actual state-of-the-art methods, namely PU-ATR [3], KeyConceptRelatedness [3], NovelTopicModel [27], and Basic [6].", "startOffset": 47, "endOffset": 50}, {"referenceID": 2, "context": "actual state-of-the-art methods, namely PU-ATR [3], KeyConceptRelatedness [3], NovelTopicModel [27], and Basic [6].", "startOffset": 74, "endOffset": 77}, {"referenceID": 26, "context": "actual state-of-the-art methods, namely PU-ATR [3], KeyConceptRelatedness [3], NovelTopicModel [27], and Basic [6].", "startOffset": 95, "endOffset": 99}, {"referenceID": 5, "context": "actual state-of-the-art methods, namely PU-ATR [3], KeyConceptRelatedness [3], NovelTopicModel [27], and Basic [6].", "startOffset": 111, "endOffset": 114}], "year": 2016, "abstractText": "Automatically recognized terminology is widely used for various domain-specific texts processing tasks, such as machine translation, information retrieval or ontology construction. However, there is still no agreement on which methods are best suited for particular settings and, moreover, there is no reliable comparison of already developed methods. We believe that one of the main reasons is the lack of state-of-the-art methods implementations, which are usually non-trivial to recreate. In order to address these issues, we present ATR4S, an open-source software written in Scala that comprises more than 15 methods for automatic terminology recognition (ATR) and implements the whole pipeline from text document preprocessing, to term candidates collection, term candidates scoring, and finally, term candidates ranking. It is highly scalable, modular and configurable tool with support of automatic caching. We also compare 13 state-of-the-art methods on 7 open datasets by average precision and processing time. Experimental comparison reveals that no single method demonstrates best average precision for all datasets and that other available tools for ATR do not contain the best methods.", "creator": "LaTeX with hyperref package"}}}