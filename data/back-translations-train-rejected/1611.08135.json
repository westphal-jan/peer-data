{"id": "1611.08135", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Nov-2016", "title": "Question Retrieval for Community-based Question Answering via Heterogeneous Network Integration Learning", "abstract": "Community based question answering platforms have attracted substantial users to share knowledge and learn from each other. As the rapid enlargement of CQA platforms, quantities of overlapped questions emerge, which makes users confounded to select a proper reference. It is urgent for us to take effective automated algorithms to reuse historical questions with corresponding answers. In this paper we focus on the problem with question retrieval, which aims to match historical questions that are relevant or semantically equivalent to resolve one s query directly. The challenges in this task are the lexical gaps between questions for the word ambiguity and word mismatch problem. Furthermore, limited words in queried sentences cause sparsity of word features. To alleviate these challenges, we propose a novel framework named HNIL which encodes not only the question contents but also the askers social interactions to enhance the question embedding performance. More specifically, we apply random walk based learning method with recurrent neural network to match the similarities between askers question and historical questions proposed by other users. Extensive experiments on a large scale dataset from a real world CQA site show that employing the heterogeneous social network information outperforms the other state of the art solutions in this task.", "histories": [["v1", "Thu, 24 Nov 2016 11:01:32 GMT  (2201kb,D)", "http://arxiv.org/abs/1611.08135v1", null]], "reviews": [], "SUBJECTS": "cs.IR cs.CL", "authors": ["zheqian chen", "chi zhang", "zhou zhao", "deng cai"], "accepted": false, "id": "1611.08135"}, "pdf": {"name": "1611.08135.pdf", "metadata": {"source": "CRF", "title": "Question Retrieval for Community-based Question Answering via Heterogeneous Network Integration Learning", "authors": ["Zheqian Chen", "Chi Zhang", "Deng Cai"], "emails": ["zheqianchen@gmail.com", "wellyzhangc@zju.edu.cn", "zhaozhou@zju.edu.cn", "dengcai@gmail.com", "permissions@acm.org."], "sections": [{"heading": null, "text": "Tags CQA; Question Retrieval; Deep Learning; Social Network"}, {"heading": "1. INTRODUCTION", "text": "This year, we are in a position to write a new, never-ending story in the United States, in which the world is at stake, to see the world and to experience how the world moves into a new world, in which the world is at stake, to see the world and to experience how the world is changing, to change the world, to change the world, to change the world, to change the world, to change the world, to change the world, to change the world, to save the world, to save the world, to save the world, to save the world, to save the world, to save the world, to save the world, to save the world, to save the world, to save the world, to save the world, to save the world, to the world, to the world, to the world, to the world, to the world, to the world, to the world, to the world, to the world, to save the world, to the world, to the world, to the world, to save the world, to the world, to the world, to save the world, to the world, to the world, to the world, to save the world, to the world, to the world, to the world, to the world, to the world, to the world, to save the world, to the world, to the world, to the world, to the world, to the world, to the world, to the world, to the world, to the world, to the world, to the world, to the world, to the world, to the world, to the world, to the world, to the world, to the world, to the world, to the world, to the world, to save, to the world, to the world, to the world, to the world, to the world, to the world, to the world, to the world, to the world, to the world, to the world, to the world, to the world, to the world, to the world, to the world, to the world, to the world, to save, to the world, to the world, to the world, to the world, to the world, to the world, to the world, to the world, to the world, to the world, to the world, to save, to the world, to the world, to the world, to the world, to the world, to the"}, {"heading": "2. RELATED WORK", "text": "In fact, most of them are able to play by the rules that they have set themselves in order to play by the rules."}, {"heading": "3. QUESTION RETRIEVAL VIA HETEROGENEOUS NETWORK RANKING LEARNING", "text": "In this section, we will formulate the problem of the question and propose our HNIL framework with details. Finally, we will present how to use a random walk together with a relapsing neural network to train our model."}, {"heading": "3.1 The Problem", "text": "We look at the problem of the question not only from the point of view of integrating heterogeneous social networks with question content textual information. First, we refer to the questions with correct semantic embedding. Since the proposed questions include variable length sequential data, we construct recurrent neural networks to encode the question of textual content in fixed lengths. We represent the question words through word2vec embedded neural networks, which have shown great superiority in handling variable word sequence length. [13] and then we get the latent semantic embedding with fixed length characteristics vectors from recurrent neural networks, which we call Q = {q1, q2, q3, qn}. In our model, we use not only the question of textual information, but also the side of the information that we call social interaction."}, {"heading": "3.2 Heterogeneous Network Ranking Learning with Recurrent Neural Networks", "text": "In this section, we introduce the blended nodes in mutiple ths, and then we look at the amplified contexts as the context in which we look at the sentences. In this section, we introduce the blended nodes in mutiple ths. We look at the amplified neural networks as the contexts we propose for questions retrieval. In this section, we introduce the blended nodes in mutiple ths. In this section, we look at how we exploit the rich interaction information from heterogeneous CQA networks. Inspired by DeepWalk method proposed by Perozzi et al. [15] we use deep random walks to combine the blended nodes in mutiple, and then we look at the amplified contexts as the amplified contexts as the amplified contexts."}, {"heading": "3.3 Heterogeneous Network Ranking Learning", "text": "In this section, we describe the details of learning our proposed framework and suggest heuristic approaches in adopting heterogeneous social information to improve model performance.We integrate the textual content of the question and the relative relationships of the questioners into a unified CQA network that embeds the framework for retrieving questions.The integration of users \"social information can help solve the question questions. (We then summarize the most important training process of the algorithm in the algorithm and incorporate more page information to understand the question that is critical to retrieving the question similarity.) The model can directly classify the question similarities for a given question. We then summarize the most important training processes of the algorithm in the algorithm. (The framework is illustrated by Figure 3.) Before training over the heterogeneous CQA network, we try the node paths through a deep random walker. We assign the algorithm H1 NIL to retrieve the question Cire in the QA."}, {"heading": "4. EXPERIMENTS", "text": "In this section, we present experiments to evaluate the performance of the proposed methodology based on the Quora service and the Twitter social network."}, {"heading": "4.1 Data Preparation", "text": "The data set includes 50451 questions, 4415 users and their following relationships. Each question in this collected corpus consists of three fields: information about the question content and tag, and the Twitter ID of the questioner and his following friends. The data set is split into training set and test set without overlapping, the size of the test set is set at 20% and the size of the training set varies from 20% to 80%."}, {"heading": "4.2 Evaluation Criteria", "text": "To evaluate the performance of different models, we use Mean Average Precision (MAP = Q q), Precision at K (P @ k) and Mean Reciprocal Rank (MRR) as benchmarks. These benchmarks are often used in the evaluation of the retrieval performance of questions in CQA. MAP reports on the relevance ranking capability of a model for a ranking of documents. \u2022 MAP (Mean Average Precision) corresponds to the number of relevant results in top k search results. MRR evaluates a sequence of possible responses to a sample of queries, ordered by probability of correctness. We will now introduce the rating criteria in the details below. \u2022 MAP (Mean Average Precision) for a number of queried questions Q is the mean of the average precision values for each query, ordered by the probability of the correctness of the query."}, {"heading": "4.3 Performance Comparisons", "text": "In order to test the performance of our approach, we compare our proposed methods with others, which address the question of how far they are able to move."}, {"heading": "4.4 Experimental Results and Analysis", "text": "In order to evaluate the performance of our proposed framework, we perform several experiments on four metrics described above. Tables 1, 2, 3 and 4 show the evaluation results on MAP, Precision @ 1, Precision @ 5 and MRR, respectively. We conduct the experiments by separating all the data into a different ratio of 20%, 40%, 60% and 80%. We select the parameters that achieve the best performance to implement the test evaluation. We then report on several interesting analyses that we have observed on the evaluation results. \u2022 The monitored methods HNIL, DRML, RCNNs, DeepWalk exceed the unmonitored VSM, BM25 and doc2vec methods, which indicate that in question on-demand problem it is crucial to use monitored information such as question categories to improve the internal similarities of the questions under the same category. \u2022 Since DeepWalk performs worse than DRLM in most cases, we can conclude that the use category plays a larger role as the question of content analysis."}, {"heading": "5. CONCLUSION", "text": "In this paper, we discuss a new framework that is capable of using category information associated with social attributions of questioners to enhance the ability to embed question content. We are developing a randomized method with recurring neural networks to evaluate question similarities in heterogeneous CQA networks. Our approach can easily be applied to existing question-retrieval models and extended to other retrieval fields. Experiments conducted with a large CQA dataset from Quora and Twitter demonstrate the effectiveness of the proposed technique. This work opens up several interesting approaches for future work. First, it is important to apply the proposed technique to other question-retrieval approaches and even other retrieval fields. Second, the connection with heterogeneous social networks can be exploited to further improve the performance of our proposed model. Finally, it is of interest to examine other question information and to combine global relevance and local performance."}, {"heading": "6. REFERENCES", "text": "[1] X. Cao, G. Cong, B. Cui, and C. S. Jensen. Ageneralized framework of exploring category information for question retrieval in community question answer archives. In Proceedings of the 19th international conference on World wide web, pages 201-210. ACM, 2010. [2] X. Cao, G. Cong, B. Cui, C. S. Jensen, and Q. Yuan. Approaches to exploring category information for question retrieval in community question-answer archives. ACM Transactions on Information Systems (TOIS), 30 (2): 7, 2012. [3] X. Cao, G. Cong, B. Cui, C. S. Jensen, and C. Zhang. The use of categorization information in language models for question retrieval. In Proceedings of the 18th ACM conference on Information and knowledge management, pages 265-274. ACM, 2009. [4] T. De Nies, C. Beecks, W. De Neve, T. Seidl, E. Mannsimiens V."}], "references": [{"title": "A generalized framework of exploring category information for question retrieval in community question answer archives", "author": ["X. Cao", "G. Cong", "B. Cui", "C.S. Jensen"], "venue": "In Proceedings of the 19th international conference on World wide web,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2010}, {"title": "Approaches to exploring category information for question retrieval in community question-answer archives", "author": ["X. Cao", "G. Cong", "B. Cui", "C.S. Jensen", "Q. Yuan"], "venue": "ACM Transactions on Information Systems (TOIS),", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "The use of categorization information in language models for question retrieval", "author": ["X. Cao", "G. Cong", "B. Cui", "C.S. Jensen", "C. Zhang"], "venue": "In Proceedings of the 18th ACM conference on Information and knowledge management,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2009}, {"title": "Towards named-entity-based similarity measures: Challenges and opportunities", "author": ["T. De Nies", "C. Beecks", "W. De Neve", "T. Seidl", "E. Mannens", "V.D.W. Rik"], "venue": "In The Workshop on Exploiting Semantic Annotations in Information Retrieval,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "Searching questions by identifying question topic and question focus", "author": ["H. Duan", "Y. Cao", "C.-Y. Li", "Y. Yu"], "venue": "In ACL,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2008}, {"title": "Long short-term memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural computation,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1997}, {"title": "Finding similar questions in large question and answer archives", "author": ["J. Jeon", "W.B. Croft", "J.H. Lee"], "venue": "In Proceedings of the 14th ACM international conference on Information and knowledge management,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2005}, {"title": "Question-answer topic model for question retrieval in community question answering", "author": ["Z. Ji", "F. Xu", "B. Wang", "B. He"], "venue": "In Proceedings of the 21st ACM international conference on Information and knowledge management,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2012}, {"title": "Social recommendation with cross-domain transferable knowledge", "author": ["M. Jiang", "P. Cui", "X. Chen", "F. Wang"], "venue": "IEEE Transactions on Knowledge & Data Engineering,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2015}, {"title": "Distributed representations of sentences and documents", "author": ["Q.V. Le", "T. Mikolov"], "venue": "arXiv preprint arXiv:1405.4053,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "Bridging lexical gaps between queries and questions on large online q&a collections with compact translation models", "author": ["J.-T. Lee", "S.-B. Kim", "Y.-I. Song", "H.-C. Rim"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2008}, {"title": "Semi-supervised question retrieval with gated convolutions", "author": ["T. Lei", "H. Joshi", "R. Barzilay", "T. Jaakkola", "K. Tymoshenko", "A. Moschitti", "L. Marquez"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2015}, {"title": "Efficient estimation of word representations in vector space", "author": ["T. Mikolov", "K. Chen", "G. Corrado", "J. Dean"], "venue": "Computer Science,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2013}, {"title": "Sparse topical coding with sparse groups", "author": ["M. Peng", "Q. Xie", "J. Huang", "J. Zhu", "S. Ouyang", "G. Tian"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2016}, {"title": "Deepwalk: Online learning of social representations", "author": ["B. Perozzi", "R. Al-Rfou", "S. Skiena"], "venue": "In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2014}, {"title": "Convolutional neural tensor network architecture for community-based question answering", "author": ["X. Qiu", "X. Huang"], "venue": "In Proceedings of the 24th International Joint Conference on Artificial Intelligence (IJCAI),", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2015}, {"title": "Okapi at trec-3", "author": ["S.E. Robertson", "S. Walker", "S. Jones", "M. Hancock-Beaulieu", "M. Gatford"], "venue": "In TREC,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1994}, {"title": "Question/answer matching for cqa system via combining lexical and sequential information", "author": ["Y. Shen", "W. Rong", "Z. Sun", "Y. Ouyang", "Z. Xiong"], "venue": "In Twenty-Ninth AAAI Conference on Artificial Intelligence,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2015}, {"title": "Sequence to sequence learning with neural networks", "author": ["I. Sutskever", "O. Vinyals", "Q.V. Le"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2014}, {"title": "Wisdom in the social crowd: an analysis of quora", "author": ["G. Wang", "K. Gill", "M. Mohanlal", "H. Zheng", "B.Y. Zhao"], "venue": "In Proceedings of the 22nd international conference on World Wide Web,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2013}, {"title": "Retrieval models for question and answer archives", "author": ["X. Xue", "J. Jeon", "W.B. Croft"], "venue": "In Proceedings of the 31st annual international ACM SIGIR conference,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2008}, {"title": "Learning distributed representations of data in community question answering for question retrieval", "author": ["K. Zhang", "W. Wu", "F. Wang", "M. Zhou", "Z. Li"], "venue": "In ACM International Conference on Web Search and Data Mining,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2016}, {"title": "Question retrieval with high quality answers in community question answering", "author": ["K. Zhang", "W. Wu", "H. Wu", "Z. Li", "M. Zhou"], "venue": "In Proceedings of the 23rd ACM International Conference on CIKM,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2014}, {"title": "Expert finding for question answering via graph regularized matrix completion", "author": ["Z. Zhao", "L. Zhang", "X. He", "W. Ng"], "venue": "IEEE Transactions on Knowledge & Data Engineering,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2015}, {"title": "Phrase-based translation model for question retrieval in community question answer archives", "author": ["G. Zhou", "L. Cai", "J. Zhao", "K. Liu"], "venue": "In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2011}, {"title": "Towards faster and better retrieval models for question search", "author": ["G. Zhou", "Y. Chen", "D. Zeng", "J. Zhao"], "venue": "In Proceedings of the 22nd ACM international conference on CIKM,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2013}, {"title": "Group non-negative matrix factorization with natural categories for question retrieval in community question answer archives", "author": ["G. Zhou", "Y. Chen", "D. Zeng", "J. Zhao"], "venue": "In COLING,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2014}, {"title": "Learning continuous word embedding with metadata for question retrieval in community question answering", "author": ["G. Zhou", "T. He", "J. Zhao", "P. Hu"], "venue": "In Proceedings of ACL,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2015}, {"title": "Improving question retrieval in community question answering using world knowledge", "author": ["G. Zhou", "Y. Liu", "F. Liu", "D. Zeng", "J. Zhao"], "venue": "In IJCAI,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2013}, {"title": "Learning semantic representation with neural networks for community question answering retrieval", "author": ["G. Zhou", "Y. Zhou", "T. He", "W. Wu"], "venue": "Knowledge-Based Systems,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2016}, {"title": "Learning to rank for question-oriented software text retrieval (t)", "author": ["Y. Zou", "T. Ye", "Y. Lu", "J. Mylopoulos", "L. Zhang"], "venue": "In Automated Software Engineering (ASE),", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2015}], "referenceMentions": [{"referenceID": 19, "context": "Over the past years, CQA services like Yahoo! Answers, Baidu Knows, Wiki Answers, Zhihu and Quora have accumulated substantial question-answer pairs [20].", "startOffset": 149, "endOffset": 153}, {"referenceID": 11, "context": "However, large quantities of proposed questions are highly overlapped and redundant, which weakens users query efficiency [12].", "startOffset": 122, "endOffset": 126}, {"referenceID": 6, "context": "The critical problem of question retrieval is to help users to retrieve historical questions which precisely match their questions semantically equivalent or relevant [7].", "startOffset": 167, "endOffset": 170}, {"referenceID": 27, "context": "However, challenges still remain due to the lexical gaps between questions caused by word ambiguity and word mismatch problem [28].", "startOffset": 126, "endOffset": 130}, {"referenceID": 3, "context": "Even for the same word may cause ambiguity, for instance when we mention the word \u2018apple\u2019, we can not easily tell whether it is about the apple company or the apple fruit [4] unless we classify through context information.", "startOffset": 171, "endOffset": 174}, {"referenceID": 13, "context": "Another challenge in question retrieval is the feature sparsity issue [14].", "startOffset": 70, "endOffset": 74}, {"referenceID": 1, "context": "Most of the existing works consider the question retrieval task as a supervised learning method, which utilizes both the question textual content and its belonging category to train an evaluating model [2], [29], [31].", "startOffset": 202, "endOffset": 205}, {"referenceID": 28, "context": "Most of the existing works consider the question retrieval task as a supervised learning method, which utilizes both the question textual content and its belonging category to train an evaluating model [2], [29], [31].", "startOffset": 207, "endOffset": 211}, {"referenceID": 30, "context": "Most of the existing works consider the question retrieval task as a supervised learning method, which utilizes both the question textual content and its belonging category to train an evaluating model [2], [29], [31].", "startOffset": 213, "endOffset": 217}, {"referenceID": 26, "context": "Recent works on question retrieval in CQA data employ different retrieval models to learn semantic representations, including the language model [27], the translation model [25] and learning-to-rank model [31].", "startOffset": 145, "endOffset": 149}, {"referenceID": 24, "context": "Recent works on question retrieval in CQA data employ different retrieval models to learn semantic representations, including the language model [27], the translation model [25] and learning-to-rank model [31].", "startOffset": 173, "endOffset": 177}, {"referenceID": 30, "context": "Recent works on question retrieval in CQA data employ different retrieval models to learn semantic representations, including the language model [27], the translation model [25] and learning-to-rank model [31].", "startOffset": 205, "endOffset": 209}, {"referenceID": 9, "context": "Inspired by the flourish of deep learning application in natural language processing [10], various embedding methods are proposed for learning the semantics of similar words and encode the word sequence into low-dimensional continuous embedding space.", "startOffset": 85, "endOffset": 89}, {"referenceID": 5, "context": "Since the question contents are always sequential data with variant length, recurrent neural network [6] is an ideal choice to learn the semantic representation.", "startOffset": 101, "endOffset": 104}, {"referenceID": 2, "context": "[3], [1], [2] embodied three language models to exploit question categories smoothing for estimating questions similarities under the same category.", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "[3], [1], [2] embodied three language models to exploit question categories smoothing for estimating questions similarities under the same category.", "startOffset": 5, "endOffset": 8}, {"referenceID": 1, "context": "[3], [1], [2] embodied three language models to exploit question categories smoothing for estimating questions similarities under the same category.", "startOffset": 10, "endOffset": 13}, {"referenceID": 25, "context": "[26], [27], [28] proposed several methods in employing category side-information.", "startOffset": 0, "endOffset": 4}, {"referenceID": 26, "context": "[26], [27], [28] proposed several methods in employing category side-information.", "startOffset": 6, "endOffset": 10}, {"referenceID": 27, "context": "[26], [27], [28] proposed several methods in employing category side-information.", "startOffset": 12, "endOffset": 16}, {"referenceID": 25, "context": "In [26] they leveraged user chosen category and filter irrelevant questions under leaf categories.", "startOffset": 3, "endOffset": 7}, {"referenceID": 26, "context": "In [27] they developed group non-negative matrix factorization with learning the category-specific topics for each category as well as shared topics across all categories.", "startOffset": 3, "endOffset": 7}, {"referenceID": 27, "context": "[28] also employed fisher kernel to aggregate word embedding vectors from variable size into fixed-length, thus learnt a continuous word embedding model.", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "[7] discussed a method that refers to the similarities between answers to estimate question semantically similar probabilities.", "startOffset": 0, "endOffset": 3}, {"referenceID": 20, "context": "[21] combined the question part with a query likelihood approach by incorporating word-to-word translation probabilities.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[11] investigated empirical methods to eliminate non-topical or unimportant words in order to construct compact translation models for retrieval purposes.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "[25] learnt a phrase-based translation model which aims to capture question contextual information rather than word-based in isolation.", "startOffset": 0, "endOffset": 4}, {"referenceID": 4, "context": "[5] identified the question topic and focus into a consisting data structure.", "startOffset": 0, "endOffset": 3}, {"referenceID": 22, "context": "[23] assumed that questions and answers share some common latent topics and through this way the model can match questions on a topic level.", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "[8] assumption is quite similar to Zhang et al [23].", "startOffset": 0, "endOffset": 3}, {"referenceID": 22, "context": "[8] assumption is quite similar to Zhang et al [23].", "startOffset": 47, "endOffset": 51}, {"referenceID": 29, "context": "[30] learnd the semantic representation of queries and answers by using a neural network architec-", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[16] encoded questions and answers in semantic space and model their interactions in a convolutional neural tensor network architecture.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[18] utilized a similarity matrix which contains both lexical and sequential information to effectively model the complicated matching relations between questions and answers.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[24] implemented a graph-regularized matrix completion algorithm by integrating the user model to improve expert finding performance.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "[9].", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "Recurrent neural network have shown great superiority in dealing with variable word sequence length [10].", "startOffset": 100, "endOffset": 104}, {"referenceID": 12, "context": "[13] and then obtain the latent semantic embedding with fixed length feature vectors from recurrent neural network, which denote as Q = {q1, q2, q3, .", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[15], we use deep random walk to combine the blended nodes into mutiple paths, and then we consider the sampled paths as the context windows for the vertex embedding in networks.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13], we formulate the vetex as the optimization problem as follows:", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13], it uses one word to predict the context instead of using context to predict a missing word.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[15] is an unsupervised learning framework which only learns nodes embedding from structured graph.", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "We choose long-short term memory [6] instead of traditional recurrent neural network to learn question embeddings.", "startOffset": 33, "endOffset": 36}, {"referenceID": 18, "context": "[19].", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "We manage to minimize the total loss by using stochastic gradient descent(SGD) with diagonal variant of AdaGrad [16].", "startOffset": 112, "endOffset": 116}, {"referenceID": 16, "context": "[17] (BM stands for Best Matching) is a ranking function used to rank matching documents according to their relevance to a given search query.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": ") [10] modifies the word2vec algorithm to unsupervised learning of continuous representations for larger blocks of documents.", "startOffset": 2, "endOffset": 6}, {"referenceID": 21, "context": ") [22] simultaneously learn vectors of words and vectors of question categories by optimizing an objective function.", "startOffset": 2, "endOffset": 6}, {"referenceID": 11, "context": "[12] apply a recurrent and convolutional model(gated convolution) to effectively map questions to their semantic representations.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "\u2022 DeepWalk DeepWalk [15] proposed by Perozzi et al.", "startOffset": 20, "endOffset": 24}, {"referenceID": 12, "context": "The input words of our methods are initialized by pre-trained word embeddings [13] and the weights of LSTMs are randomly by a Gaussian distribution with zero mean.", "startOffset": 78, "endOffset": 82}], "year": 2016, "abstractText": "Community-based question answering platforms have attracted substantial users to share knowledge and learn from each other. As the rapid enlargement of CQA platforms, quantities of overlapped questions emerge, which makes users confounded to select a proper reference. It is urgent for us to take effective automated algorithms to reuse historical questions with corresponding answers. In this paper we focus on the problem with question retrieval, which aims to match historical questions that are relevant or semantically equivalent to resolve one\u2019s query directly. The challenges in this task are the lexical gaps between questions for the word ambiguity and word mismatch problem. Furthermore, limited words in queried sentences cause sparsity of word features. To alleviate these challenges, we propose a novel framework named HNIL which encodes not only the question contents but also the asker\u2019s social interactions to enhance the question embedding performance. More specifically, we apply random walk based learning method with recurrent neural network to match the similarities between asker\u2019s question and historical questions proposed by other users. Extensive experiments on a large-scale dataset from a real world CQA site Quora show that employing the heterogeneous social network information outperforms the other state-of-the-art solutions in this task.", "creator": "LaTeX with hyperref package"}}}