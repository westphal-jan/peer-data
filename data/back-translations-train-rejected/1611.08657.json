{"id": "1611.08657", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Nov-2016", "title": "Convolutional Experts Constrained Local Model for Facial Landmark Detection", "abstract": "Among the well-established methods for facial landmark detection is the family of Constrained Local Models (CLMs). An important part of CLM landmark alignment pipeline are the local detectors that estimate the alignment probability of each individual landmark over the facial region. In this paper we present Deep Constrained Local Model (DCLM) algorithm and the novel Dense-Projection Network (DPN) as a local detector. DPN is a deep neural network that consists of two important layers: Template Projection layer and Dense Aggregate layer. In Template Projection layer, patches of facial region are mapped to a higher dimensional space allowing the pose and rotation variations to be captured accurately. In Dense Aggregate layer an ensemble of experts is simulated within one network to make the landmark localization task more robust. In our extensive set of experiments we show that DPNs outperform previously proposed local detectors. Furthermore, we demonstrate that our proposed DCLM algorithm is state-of-the-art in facial landmark detection. We significantly outperform competitive baselines, that use both CLM-based and cascaded regression approaches, by a large margin on three publicly-available datasets for image and video landmark detection.", "histories": [["v1", "Sat, 26 Nov 2016 04:47:34 GMT  (1882kb,D)", "http://arxiv.org/abs/1611.08657v1", null], ["v2", "Tue, 29 Nov 2016 16:00:45 GMT  (1882kb,D)", "http://arxiv.org/abs/1611.08657v2", null], ["v3", "Wed, 30 Nov 2016 18:03:56 GMT  (1882kb,D)", "http://arxiv.org/abs/1611.08657v3", null], ["v4", "Sun, 23 Jul 2017 10:15:06 GMT  (6334kb,D)", "http://arxiv.org/abs/1611.08657v4", "Accepted at CVPR-W 2017"], ["v5", "Wed, 26 Jul 2017 19:46:15 GMT  (6386kb,D)", "http://arxiv.org/abs/1611.08657v5", "Accepted at CVPR-W 2017"]], "reviews": [], "SUBJECTS": "cs.CV cs.AI", "authors": ["amir zadeh", "tadas baltru\\v{s}aitis", "louis-philippe morency"], "accepted": false, "id": "1611.08657"}, "pdf": {"name": "1611.08657.pdf", "metadata": {"source": "CRF", "title": "Deep Constrained Local Models for Facial Landmark Detection", "authors": ["Amir Zadeh", "Tadas Baltruaitis"], "emails": ["abagherz@cs.cmu.edu", "tbaltrus@cs.cmu.edu", "morency@cs.cmu.edu"], "sections": [{"heading": "1. Introduction", "text": "It is a well-researched problem with large amounts of annotated data and has seen an increase in interest in the last few years. Popular methods for recognizing facial characteristics include the family of strained local models [26, 3]. Probably the most important step in the CLM pipeline is the local recognition of individual landmarks with local detectors (also referred to as patch experts), which assign landmarks, which assign the likelihood of alignment to different regions of the face. Local recognition is also the firstar Xiv: 161 1.08 657v 1 [cs.C V] 26 nstep, the precise recognition of landmarks of crucial importance for the rest of the pipeline; and the creation of patch expert projects, which form an active and challenging area of research. Based on the probability maps populated by the application of patch experts in different areas of the picture of the problem. The position of landmarks we will update, by using a model analytics-analytics-analytics-analytics-analyses-analytics-analytics-analytics-analytics-analytics-analytics-analytics-analytics-analytics-analytics-analytics-analytics-analytics-analytics-analytics-analytics-analytics-analytics-analytics-analytics-analytics-analytics-analytics-analytics-analytics-analytics-analytics-analytics-analytics-using-analytics-analytics-analytics-analytics-analytics-analytics-analytics-analytics-analytics-using-analytics-analytics-analytics-analytics-analytics-analytics-analytics-analytics-analytics-analytics-using-analytics-analytics-analytics-analytics-analytics-analytics-analytics-analytics-using-analytics-analytics-analytics-analytics-analytics-analytics-analytics-analytics-using-analytics-analytics-analytics-analytics-analytics-analytics-analytics-analytics-analytics-analytics-analytics-analytics-analytics-are used-analytics-analytics-analytics-analytics-analytics-analytics-analytics-analytics-are used-analytics-analytics-analytics-analytics-analytics"}, {"heading": "2. Related Work", "text": "A variety of new approaches and techniques have been proposed, especially for the recognition of facial features from RGB images. A complete overview of the work in the recognition of facial features and the assessment of head posture is not the subject of this paper, we refer the reader to some recent reports on this topic [10, 34]."}, {"heading": "2.1. Facial landmark detection", "text": "Modern facial recognition approaches can be divided into two main categories - model-based and regression. Model-based approaches often model the appearance and shape of facial landmarks with the latter providing a form of regulation. Regression approaches, on the other hand, do not require an explicit shape model and recognition of landmarks is performed directly after appearance. We provide a brief overview of current models and regression-based methods. Model-based approaches often consist of two steps: extract an appearance descriptor by specific areas of interest and compute local response maps; customize a form model based on local predictions. Such areas are often defined by the current estimation of facial landmarks. A popular local method for recognizing landmarks is the restricted local model [26] and its various extensions such as Constrained Local Neural Fields [2] and Discriminative Response Map Fitting [1], which use more advanced ways of calculating local landmarks."}, {"heading": "3. Deep Constrained Local Model", "text": "The algorithm of the Deep Constrained Local Model (DCLM) consists of two main parts: local recognition and shape regulation. In local recognition, individual landmarks are detected regardless of the position of other landmarks. In shape regulation, the position of all landmarks is considered together, and irregular shapes are discouraged using a point distribution model. Thus, the following objective function is optimized within the DCLM framework: p \u0445 = argmin p [n \u2211 i = 1 Di (xi; I) + R (p)] (1) In the above equation, p \u0445 is the optimal set of parameters controlling the position of landmarks, where p is the current estimate. D is inversely proportional to the performance of the DPN network as the alignment probability of Landmark i in position xi for entering the face image I (section 3.1). R is the one forced by the Point Distribution Model (section 3.2). The optimization of a megorithm is not performed using a uniform section 3.3."}, {"heading": "3.1. Dense-Projection Network Patch Experts", "text": "The first and most important step in the DCLM algorithm is the precise localization of individual landmarks = DA layer (DA layer 2) by evaluating the orientation of landmarks across different regions of an input image. This can be done by calculating the alignment probability of a particular landmark across different regions of the image by means of folding. A local detector is moved across the image and assigns probability to each region of the image. If the probability is high, the evidence for the presence of landmarks is strong. For this task, we select the family of fully connected deep neural networks (DNN) and perform a specially tailored deep network called Dense-Projection Network (DPN) patch expert (Figure 2) for this task. The first layer (shown as blue in Figure 2) is referred to as Template Projection (TP) layer, which is designed to capture the diversity of facial appearance and poses by projecting onto 500 dimensions of a much larger dimension than the one."}, {"heading": "3.2. Point Distribution Model Shape Regularization", "text": "Point distribution models [8, 26] are used as shape adjusters in the DCLM framework. Complex and irregular shapes for definitively recognized landmarks are punished with the term R (p) in Equation 1. If xi = [xi, yi] T is the location for the face marking, then PDM parameters are controlled using the following equation: xi = s \u00b7 R2D \u00b7 (x-i + \u03a6i) + t (3), where x-i = [x-i, y-i, z-i] T is the mean of the ith landmark, \u03a6i is a 3 m main component matrix and q is a dimensional vector of parameters controlling the non-rigid form; s, R and t are the rigid parameters in 2D: s is the scale parameter and a scalar, R is the rotation on axis angles w = [wx, wy, wz] T and is a 3-3 matrix in this system."}, {"heading": "3.3. Non-Uniform Regularized Landmark Mean", "text": "ShiftThe most common method for solving Eq.1 is the use of non-uniform Regulated Limit Shift (NURLMS) [2]. Starting from an initial estimate of the DCLM parameters p (which denotes the 68 facial limit value positions), the goal is to find an updating parameter \u2206 p so that p = p0 + p and optimal parameters are achieved on the basis of Eq.1. On this basis, RLMS finds the solution to the following problem: argmin \u2206 p (\u0394\u0430p0 + \u0445 p) for non-rigid form and uniform limit value parameters (4), where J in Eq.4 is the jacobinic of the limit value positions with respect to parameters p."}, {"heading": "4. Experiments", "text": "In our experiments, we first demonstrate that DPN networks function significantly better than LNF [2] and SVR [26] lo-scale detectors (patch experts), and we also evaluate the importance of TP and DA layers for DPN performance. Our final facial recognition experiments examine the use of our model in two scenarios - images and videos. All of our experiments were conducted on sophisticated publicly available data sets and compared with a number of state-of-the-art baselines."}, {"heading": "4.1. DPN Experiments", "text": "In this section we first describe training and inference methodology of the DPN patch experts. We then compare the performance of DPN with LNF [2] and SVR [26] patch experts followed by an ablation study to determine the crucial role of TP and DA layers.For all the experiments DPN patch experts were trained on LFPW and Helen training sets as well as MultiPIE Dataset. To train patch experts we have studied around the true location of the landmark and far from it for negative samples. Each of the samples was an 11 \u00d7 11 pixel support region and was contrasted with their Zscore. If the landmark was located in the middle of the 11 \u00d7 11 region of interest, then the probability of landmark presence is high, otherwise low. A total of 4 \u00d7 106 regions were extracted for train and 5 \u00d7 105 for test set. We traced 28 sets of patch experts per landmark: at seven orientations \u00b1 70 percent, \u00b1 20 percent."}, {"heading": "4.2. DCLM Experiments", "text": "In this section, we first describe the data sets used to train and evaluate our DCLM facial recognition method in images and videos, then briefly discuss comparable state-of-the-art approaches to face recognition, and finally present the results of facial recognition."}, {"heading": "4.2.1 Datasets", "text": "300-W [23, 25] is a metadata dataset of four different Faces Landmark datasets: Annotated Faces in the Wild (AFW) [39], iBUG [24], and LFPW + Helen [5, 19] datasets. We used the full iBUG dataset and the test partitions of LFPW and HELEN. This resulted in 135, 224, and 330 images for subjects. They all contain uncontrolled images of faces in the wild: indoor and outdoor environments, under different lighting, in the presence of occlusions, in different poses, and from different quality cameras.IJB-FL [14] is a dataset that contains a significant proportion of non-frontal images. It is a subset of IJB-A [17] that is a face recognition yardstick and includes chalene-slow datasets in full pose."}, {"heading": "4.2.2 Baselines", "text": "We compared our approach to a number of established baselines for visual mark recognition, including both cascaded regression and local model-based approaches. (CFSS) [38] - Coarse to Fine Shape Search is a cascaded regression approach that attempts to avoid local optimal execution of a coarse to fine shape search. It is the latest state-of-the-art approach to the 300W competitive data [23, 7]. We use the implementation provided by the authors, which is trained on Helen and LFPW training sets and AFW.CLNF is an extension of the restricted local model that uses continuous conditional neural fields as patch experts [3].PO-CR [32] - is another current cascaded regression approach that updates the shape model parameters rather than directly predicting locations in a projected space."}, {"heading": "4.2.3 Landmark Detection Results", "text": "In fairness to the model comparison, all approaches were initialized using the same protocol. For the 300W dataset, we initialized all approaches using the Bounding Boxes provided by the Challenge organizers. For the IJB-FL, we initialized the approaches by generating a Bounding Field by adding Truth Characteristics to the ground (based on the noise characteristics of the Bounding Boxes in the 300W dataset). To make the boundary detection more robust to represent variations, we initialized DCLM at five different orientations by creating a Bounding Field - frontal, \u00b1 30 \u0445 yaw, and \u00b1 30 \u0445 Pitch. We selected the boundary stones with the highest converged maximum a posteriori score as the final detection. For 300VW, we discovered the face in each 30th frame of each video using the dlib [15] library. If the face was not detected in the frame, we used the next successful frame with a data set."}, {"heading": "5. Conclusion", "text": "In this article, we introduced the Deep Constrained Local Model (DCLM), a new member of the CLM family that uses a carefully designed and trained depth detector called the Dense-Projection Network (DPN). We compared DPN with the patch experts of related model-based approaches and showed significant performance improvements. The DPN network was designed with two objectives: 1) capture input visibility and orientation variations, and 2) display reliability should be similar to the performance of many models to be robust against detection errors. The Template Projection Layer was designed to capture the appearance variations of the input and density aggregate layer, simulating a mix of experts. We demonstrated its critical role with a deposit study. We brought state-of-art results in three publicly available datasets, and we show a great performance improvement for detecting dense and density aggregate layers."}], "references": [{"title": "Robust discriminative response map fitting with constrained local models", "author": ["A. Asthana", "S. Zafeiriou", "S. Cheng", "M. Pantic"], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 3444\u20133451,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2013}, {"title": "Constrained local neural fields for robust facial landmark detection in the wild", "author": ["T. Baltrusaitis", "L.-P. Morency", "P. Robinson"], "venue": "IEEE International Conference on Computer Vision Workshops,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2013}, {"title": "Continuous conditional neural fields for structured regression", "author": ["T. Baltru\u0161aitis", "P. Robinson", "L.-P. Morency"], "venue": "Computer Vision\u2013ECCV 2014, pages 593\u2013608. Springer,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2014}, {"title": "3D Constrained Local Model for Rigid and Non-Rigid Facial Tracking", "author": ["T. Baltru\u0161aitis", "P. Robinson", "L.-P. Morency"], "venue": "CVPR,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2012}, {"title": "Localizing parts of faces using a consensus of exemplars", "author": ["P.N. Belhumeur", "D.W. Jacobs", "D.J. Kriegman", "N. Kumar"], "venue": "CVPR,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2011}, {"title": "Face alignment by Explicit Shape Regression", "author": ["X. Cao", "Y. Wei", "F. Wen", "J. Sun"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition, pages 2887\u20132894. Ieee, jun", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2012}, {"title": "A Comprehensive Performance Evaluation of Deformable Face Tracking \u201dIn-the-Wild", "author": ["G.G. Chrysos", "E. Antonakos", "P. Snape", "A. Asthana", "S. Zafeiriou"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2016}, {"title": "Active appearance models", "author": ["T. Cootes", "G. Edwards", "C. Taylor"], "venue": "TPAMI, 23(6):681\u2013685, Jun", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2001}, {"title": "Feature detection and tracking with constrained local models", "author": ["D. Cristinacce", "T. Cootes"], "venue": "BMVC,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2006}, {"title": "Active Media Technology: 10th International Conference, AMT 2014, Warsaw, Poland, August 11-14, 2014", "author": ["B. Czupry\u0144ski", "A. Strupczewski"], "venue": "Proceedings, chapter High Accuracy Head Pose Tracking Survey, pages 407\u2013420. Springer International Publishing, Cham,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}, {"title": "Multi-pie", "author": ["R. Gross", "I. Matthews", "J. Cohn", "T. Kanade", "S. Baker"], "venue": "IVC, 28(5):807 \u2013 813,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2010}, {"title": "Labeled Faces in the Wild: A Database for Studying Face Recognition in Unconstrained Environments", "author": ["G.B. Huang", "M. Ramesh", "T. Berg", "E. Learned-Miller"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2007}, {"title": "Dense 3d face alignment from 2d video for real-time use", "author": ["L.A. Jeni", "J.F. Cohn", "T. Kanade"], "venue": "Image and Vision Computing,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2016}, {"title": "Holistically constrained local model: Going beyond frontal poses for facial landmark detection", "author": ["K. KangGeon", "T. Baltru\u0161aitis", "A. Zadeh", "L.-P. Morency", "G. Medioni"], "venue": "British Machine Vision Conference (BMVC),", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}, {"title": "Dlib-ml: A machine learning toolkit", "author": ["D.E. King"], "venue": "JMLR,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2009}, {"title": "Pushing the frontiers of unconstrained face detection and recognition: Iarpa janus benchmark a", "author": ["B.F. Klare", "B. Klein", "E. Taborsky", "A. Blanton", "J. Cheney", "K. Allen", "P. Grother", "A. Mah", "M. Burge", "A.K. Jain"], "venue": "Computer Vision and Pattern Recognition (CVPR), 2015 IEEE Conference on, pages 1931\u20131939. IEEE,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2015}, {"title": "Attribute and simile classifiers for face verification", "author": ["N. Kumar", "A.C. Berg", "P.N. Belhumeur", "S.K. Nayar"], "venue": "Proceedings of the IEEE International Conference on Computer Vision, pages 365\u2013372,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2009}, {"title": "Interactive facial feature localization", "author": ["V. Le", "J. Brandt", "Z. Lin", "L. Bourdev", "T.S. Huang"], "venue": "Computer Vision\u2013ECCV 2012, pages 679\u2013692. Springer,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2012}, {"title": "Distinctive image features from scale invariant keypoints", "author": ["D.G. Lowe"], "venue": "Int\u2019l Journal of Computer Vision, 60:91\u2013 11020042,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2004}, {"title": "Advances, challenges, and opportunities in automatic facial expression recognition", "author": ["B. Martinez", "M. Valstar"], "venue": "B. S. M. Kawulok, E. Celebi, editor, Advances in Face Detection and Facial Image Analysis, pages 63 \u2013 100. Springer,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2016}, {"title": "300 faces in-the-wild challenge: The first facial landmark localization challenge", "author": ["C. Sagonas", "G. Tzimiropoulos", "S. Zafeiriou", "M. Pantic"], "venue": "Proceedings of the IEEE International Conference on Computer Vision Workshops, pages 397\u2013403,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2013}, {"title": "300 faces in-the-wild challenge: The first facial landmark localization challenge", "author": ["C. Sagonas", "G. Tzimiropoulos", "S. Zafeiriou", "M. Pantic"], "venue": "ICCV,", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2013}, {"title": "A semi-automatic methodology for facial landmark annotation", "author": ["C. Sagonas", "G. Tzimiropoulos", "S. Zafeiriou", "M. Pantic"], "venue": "Proceedings of the IEE Conference on Computer Vision and Pattern Recognition Workshops (CVPR-W), Workshop on Analysis and Modeling of Faces and Gestures,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2013}, {"title": "Deformable Model Fitting by Regularized Landmark Mean-Shift", "author": ["J. Saragih", "S. Lucey", "J. Cohn"], "venue": "IJCV,", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2011}, {"title": "Automatic analysis of facial affect: A survey of registration, representation and recognition", "author": ["E. Sariyanidi", "H. Gunes", "A. Cavallaro"], "venue": "IEEE TPAMI,", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2014}, {"title": "The First Facial Landmark Tracking in-the-Wild Challenge: Benchmark and Results", "author": ["J. Shen", "S. Zafeiriou", "G.G. Chrysos", "J. Kossaifi", "G. Tzimiropoulos", "M. Pantic"], "venue": "2015 IEEE International Conference on Computer Vision Workshop (ICCVW),", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep convolutional network cascade for facial point detection", "author": ["Y. Sun", "X. Wang", "X. Tang"], "venue": "Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, pages 3476\u20133483,", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2013}, {"title": "Project-Out Cascaded Regression with an application to Face Alignment", "author": ["G. Tzimiropoulos"], "venue": "CVPR,", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2015}, {"title": "Gauss-newton deformable part models for face alignment in-the-wild", "author": ["G. Tzimiropoulos", "M. Pantic"], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1851\u20131858,", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2014}, {"title": "Facial Feature Point Detection: A Comprehensive Survey", "author": ["N. Wang", "X. Gao", "D. Tao", "X. Li"], "venue": "page 32,", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2014}, {"title": "Supervised descent method and its applications to face alignment", "author": ["X. Xiong", "F. Torre"], "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition, pages 532\u2013539,", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2013}, {"title": "Multimodal Sentiment Intensity Analysis in Videos: Facial Gestures and Verbal Messages", "author": ["A. Zadeh", "R. Zellers", "E. Pincus", "L.-P. Morency"], "venue": "2016 IEEE Intelligent Systems,", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2016}, {"title": "Coarse-to-fine auto-encoder networks (cfan) for real-time face alignment", "author": ["J. Zhang", "S. Shan", "M. Kan", "X. Chen"], "venue": "ECCV. Springer,", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2014}, {"title": "Face Alignment by Coarse-to-Fine Shape Searching", "author": ["S. Zhu", "C. Li", "C.C. Loy", "X. Tang"], "venue": "CVPR,", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2015}, {"title": "Face detection, pose estimation, and landmark localization in the wild", "author": ["X. Zhu", "D. Ramanan"], "venue": "Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on, pages 2879\u20132886. IEEE,", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2012}], "referenceMentions": [{"referenceID": 8, "context": "Facial landmark detection is an essential initial step for a number of research areas such as facial expression analysis, face 3D modeling, facial attribute analysis, emotion recognition and person identification [9, 22, 27].", "startOffset": 213, "endOffset": 224}, {"referenceID": 19, "context": "Facial landmark detection is an essential initial step for a number of research areas such as facial expression analysis, face 3D modeling, facial attribute analysis, emotion recognition and person identification [9, 22, 27].", "startOffset": 213, "endOffset": 224}, {"referenceID": 24, "context": "Facial landmark detection is an essential initial step for a number of research areas such as facial expression analysis, face 3D modeling, facial attribute analysis, emotion recognition and person identification [9, 22, 27].", "startOffset": 213, "endOffset": 224}, {"referenceID": 23, "context": "is the family of Constrained Local Models [26, 3].", "startOffset": 42, "endOffset": 49}, {"referenceID": 2, "context": "is the family of Constrained Local Models [26, 3].", "startOffset": 42, "endOffset": 49}, {"referenceID": 1, "context": "In our experiments we compare DPN with Local Neural Field local detector [2] trained on the same data showing a significant improvement in performance across all landmarks.", "startOffset": 73, "endOffset": 76}, {"referenceID": 20, "context": "We demonstrate the benefits of our DCLM facial landmark detection algorithm through extensive experiments on three publicly available datasets, 300W [23], 300VW [29], and a newly introduced dataset, IJB-FL [14] (a subset of IJB-A [17]), which includes a large proportion of profile face poses with extremely challenging conditions for landmark detection.", "startOffset": 149, "endOffset": 153}, {"referenceID": 25, "context": "We demonstrate the benefits of our DCLM facial landmark detection algorithm through extensive experiments on three publicly available datasets, 300W [23], 300VW [29], and a newly introduced dataset, IJB-FL [14] (a subset of IJB-A [17]), which includes a large proportion of profile face poses with extremely challenging conditions for landmark detection.", "startOffset": 161, "endOffset": 165}, {"referenceID": 13, "context": "We demonstrate the benefits of our DCLM facial landmark detection algorithm through extensive experiments on three publicly available datasets, 300W [23], 300VW [29], and a newly introduced dataset, IJB-FL [14] (a subset of IJB-A [17]), which includes a large proportion of profile face poses with extremely challenging conditions for landmark detection.", "startOffset": 206, "endOffset": 210}, {"referenceID": 15, "context": "We demonstrate the benefits of our DCLM facial landmark detection algorithm through extensive experiments on three publicly available datasets, 300W [23], 300VW [29], and a newly introduced dataset, IJB-FL [14] (a subset of IJB-A [17]), which includes a large proportion of profile face poses with extremely challenging conditions for landmark detection.", "startOffset": 230, "endOffset": 234}, {"referenceID": 16, "context": "Facial landmark detection has been used in number of research directions such as facial attribute detection [18], facial expression analysis [22], emotion recognition and sentiment analysis [36], and 3D facial reconstruction [13].", "startOffset": 108, "endOffset": 112}, {"referenceID": 19, "context": "Facial landmark detection has been used in number of research directions such as facial attribute detection [18], facial expression analysis [22], emotion recognition and sentiment analysis [36], and 3D facial reconstruction [13].", "startOffset": 141, "endOffset": 145}, {"referenceID": 31, "context": "Facial landmark detection has been used in number of research directions such as facial attribute detection [18], facial expression analysis [22], emotion recognition and sentiment analysis [36], and 3D facial reconstruction [13].", "startOffset": 190, "endOffset": 194}, {"referenceID": 12, "context": "Facial landmark detection has been used in number of research directions such as facial attribute detection [18], facial expression analysis [22], emotion recognition and sentiment analysis [36], and 3D facial reconstruction [13].", "startOffset": 225, "endOffset": 229}, {"referenceID": 9, "context": "A full review of work in facial landmark detection and head pose estimation is outside the scope of this paper, we refer the reader to some recent reviews of the field [10, 34].", "startOffset": 168, "endOffset": 176}, {"referenceID": 29, "context": "A full review of work in facial landmark detection and head pose estimation is outside the scope of this paper, we refer the reader to some recent reviews of the field [10, 34].", "startOffset": 168, "endOffset": 176}, {"referenceID": 23, "context": "A popular local method for landmark detection is the Constrained Local Model [26] and its various extensions such as Constrained Local Neural Fields [2] and Discriminative Response Map Fitting [1] that use more advanced ways of computing local response maps and inferring the landmark locations.", "startOffset": 77, "endOffset": 81}, {"referenceID": 1, "context": "A popular local method for landmark detection is the Constrained Local Model [26] and its various extensions such as Constrained Local Neural Fields [2] and Discriminative Response Map Fitting [1] that use more advanced ways of computing local response maps and inferring the landmark locations.", "startOffset": 149, "endOffset": 152}, {"referenceID": 0, "context": "A popular local method for landmark detection is the Constrained Local Model [26] and its various extensions such as Constrained Local Neural Fields [2] and Discriminative Response Map Fitting [1] that use more advanced ways of computing local response maps and inferring the landmark locations.", "startOffset": 193, "endOffset": 196}, {"referenceID": 27, "context": "Project out Cascaded regression (PO-CR) [32] is another example of a local approach, but one that uses a cascaded regression to update the shape model parameters rather than predicting landmark locations directly.", "startOffset": 40, "endOffset": 44}, {"referenceID": 34, "context": "Another noteworthy local approach is the mixture of trees model [39] that uses a tree based deformable parts model to jointly perform face detection, pose estimation and facial landmark detection.", "startOffset": 64, "endOffset": 68}, {"referenceID": 28, "context": "A notable extension to this approach is the Gauss-Newton Deformable Part Model (GNDPM) [33] which jointly optimizes a part-based flexible appearance model along with a global shape using GaussNewton optimization.", "startOffset": 87, "endOffset": 91}, {"referenceID": 5, "context": "in explicit shape regression [6].", "startOffset": 29, "endOffset": 32}, {"referenceID": 30, "context": "Other cascaded regression approaches include the Stochastic Descent Method (SDM) [35] which uses SIFT [21] features with linear regression to compute the shape update and Coarse-to-Fine Shape Searching (CFSS) [38] which attempts to avoid a local optima in cascade regression by performing a coarse to fine shape search.", "startOffset": 81, "endOffset": 85}, {"referenceID": 18, "context": "Other cascaded regression approaches include the Stochastic Descent Method (SDM) [35] which uses SIFT [21] features with linear regression to compute the shape update and Coarse-to-Fine Shape Searching (CFSS) [38] which attempts to avoid a local optima in cascade regression by performing a coarse to fine shape search.", "startOffset": 102, "endOffset": 106}, {"referenceID": 33, "context": "Other cascaded regression approaches include the Stochastic Descent Method (SDM) [35] which uses SIFT [21] features with linear regression to compute the shape update and Coarse-to-Fine Shape Searching (CFSS) [38] which attempts to avoid a local optima in cascade regression by performing a coarse to fine shape search.", "startOffset": 209, "endOffset": 213}, {"referenceID": 32, "context": "Coarse-to-Fine Auto-encoder Networks (CFAN) [37] use visual features extracted by an auto-encoder together with linear regression.", "startOffset": 44, "endOffset": 48}, {"referenceID": 26, "context": "[31] proposed a Convolutional Neural Network (CNN) based cascaded regression approach for sparse landmark detection; however while their approach is robust it is not very accurate.", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "Point Distribution Models [8, 26] are used as shape regularizers in DCLM framework.", "startOffset": 26, "endOffset": 33}, {"referenceID": 23, "context": "Point Distribution Models [8, 26] are used as shape regularizers in DCLM framework.", "startOffset": 26, "endOffset": 33}, {"referenceID": 1, "context": "The most common method to solve equation 1 is using Non-Uniform Regularized Landmark Mean Shift (NURLMS) [2].", "startOffset": 105, "endOffset": 108}, {"referenceID": 1, "context": "8 DPN patch experts LNF patch experts [2] SVR patch experts [26] DPN (no TP) patch expert DPN (no DA) patch expert", "startOffset": 38, "endOffset": 41}, {"referenceID": 23, "context": "8 DPN patch experts LNF patch experts [2] SVR patch experts [26] DPN (no TP) patch expert DPN (no DA) patch expert", "startOffset": 60, "endOffset": 64}, {"referenceID": 1, "context": "DPN consistently and significantly outperforms LNF [2] and SVR [26].", "startOffset": 51, "endOffset": 54}, {"referenceID": 23, "context": "DPN consistently and significantly outperforms LNF [2] and SVR [26].", "startOffset": 63, "endOffset": 67}, {"referenceID": 1, "context": "In our experiments we first we show that DPN networks significantly perform better than LNF [2] and SVR [26] local detectors (patch experts).", "startOffset": 92, "endOffset": 95}, {"referenceID": 23, "context": "In our experiments we first we show that DPN networks significantly perform better than LNF [2] and SVR [26] local detectors (patch experts).", "startOffset": 104, "endOffset": 108}, {"referenceID": 1, "context": "We then compare the performance of DPN with LNF [2] and SVR [26] patch experts followed by an ablation study to investigate the crucial role of TP and DA layers.", "startOffset": 48, "endOffset": 51}, {"referenceID": 23, "context": "We then compare the performance of DPN with LNF [2] and SVR [26] patch experts followed by an ablation study to investigate the crucial role of TP and DA layers.", "startOffset": 60, "endOffset": 64}, {"referenceID": 20, "context": "300-W [23, 25] is a meta-dataset of four different facial landmark datasets: Annotated Faces in the Wild (AFW) [39], iBUG [24], and LFPW + Helen [5, 19] datasets.", "startOffset": 6, "endOffset": 14}, {"referenceID": 22, "context": "300-W [23, 25] is a meta-dataset of four different facial landmark datasets: Annotated Faces in the Wild (AFW) [39], iBUG [24], and LFPW + Helen [5, 19] datasets.", "startOffset": 6, "endOffset": 14}, {"referenceID": 34, "context": "300-W [23, 25] is a meta-dataset of four different facial landmark datasets: Annotated Faces in the Wild (AFW) [39], iBUG [24], and LFPW + Helen [5, 19] datasets.", "startOffset": 111, "endOffset": 115}, {"referenceID": 21, "context": "300-W [23, 25] is a meta-dataset of four different facial landmark datasets: Annotated Faces in the Wild (AFW) [39], iBUG [24], and LFPW + Helen [5, 19] datasets.", "startOffset": 122, "endOffset": 126}, {"referenceID": 4, "context": "300-W [23, 25] is a meta-dataset of four different facial landmark datasets: Annotated Faces in the Wild (AFW) [39], iBUG [24], and LFPW + Helen [5, 19] datasets.", "startOffset": 145, "endOffset": 152}, {"referenceID": 17, "context": "300-W [23, 25] is a meta-dataset of four different facial landmark datasets: Annotated Faces in the Wild (AFW) [39], iBUG [24], and LFPW + Helen [5, 19] datasets.", "startOffset": 145, "endOffset": 152}, {"referenceID": 13, "context": "IJB-FL [14] is a dataset which has a substantial proportion of non-frontal images.", "startOffset": 7, "endOffset": 11}, {"referenceID": 15, "context": "It is a subset of IJB-A [17] which is a face recognition benchmark and includes chal-", "startOffset": 24, "endOffset": 28}, {"referenceID": 25, "context": "300-VW[29] is a dataset with 114 videos labeled for 68 facial landmarks for every frame.", "startOffset": 6, "endOffset": 10}, {"referenceID": 33, "context": "(CFSS) [38] \u2013 Coarse to Fine Shape Search is a cascaded regression approach which attempts to avoid a local optima", "startOffset": 7, "endOffset": 11}, {"referenceID": 20, "context": "It is the most recent state-of-the-art approach on the 300W competition data [23, 7].", "startOffset": 77, "endOffset": 84}, {"referenceID": 6, "context": "It is the most recent state-of-the-art approach on the 300W competition data [23, 7].", "startOffset": 77, "endOffset": 84}, {"referenceID": 2, "context": "CLNF is an extension of the Constrained Local Model that uses Continuous Conditional Neural Fields as patch experts [3].", "startOffset": 116, "endOffset": 119}, {"referenceID": 27, "context": "PO-CR [32] \u2013 is another recent cascaded regression approach that updates the shape model parameters rather than predicting landmark locations directly in a projected-out space.", "startOffset": 6, "endOffset": 10}, {"referenceID": 0, "context": "We use the implementation provided by the authors [1] that was trained on LFPW [5] and Multi-PIE [11] datasets.", "startOffset": 50, "endOffset": 53}, {"referenceID": 4, "context": "We use the implementation provided by the authors [1] that was trained on LFPW [5] and Multi-PIE [11] datasets.", "startOffset": 79, "endOffset": 82}, {"referenceID": 10, "context": "We use the implementation provided by the authors [1] that was trained on LFPW [5] and Multi-PIE [11] datasets.", "startOffset": 97, "endOffset": 101}, {"referenceID": 30, "context": "We use implementation from the authors [35].", "startOffset": 39, "endOffset": 43}, {"referenceID": 11, "context": "This approach is trained on the MultiPIE and LFW [12] datasets.", "startOffset": 49, "endOffset": 53}, {"referenceID": 28, "context": "GNDPM [33] \u2013 is a deformable parts model which jointly optimizes a part-based flexible appearance model.", "startOffset": 6, "endOffset": 10}, {"referenceID": 34, "context": "Tree based face and landmark detector, is a deformable parts model for jointly detecting faces, landmarks and head orientation proposed by Zhu and Ramanan [39].", "startOffset": 155, "endOffset": 159}, {"referenceID": 0, "context": "We used a model trained on in-the-wild datasets [1].", "startOffset": 48, "endOffset": 51}, {"referenceID": 23, "context": "CLM+ model uses linear SVR patch experts and regularised landmark mean-shift fitting [26].", "startOffset": 85, "endOffset": 89}, {"referenceID": 23, "context": "[26], as our model includes a multimodal (patch experts trained on raw pixel and gradient images) and multi-scale formulation leading to more accurate landmark detection.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "We use a freely available implementation [4].", "startOffset": 41, "endOffset": 44}, {"referenceID": 14, "context": "For 300VW we detected the face in every 30th frame of each video using the dlib [15] library.", "startOffset": 80, "endOffset": 84}, {"referenceID": 33, "context": "Figure 8: Example images where our DCLM approach outperforms CFSS [38] and CLNF [2].", "startOffset": 66, "endOffset": 70}, {"referenceID": 1, "context": "Figure 8: Example images where our DCLM approach outperforms CFSS [38] and CLNF [2].", "startOffset": 80, "endOffset": 83}], "year": 2017, "abstractText": "Among the well-established methods for facial landmark detection is the family of Constrained Local Models (CLMs). An important part of CLM landmark alignment pipeline are the local detectors that estimate the alignment probability of each individual landmark over the facial region. In this paper we present Deep Constrained Local Model (DCLM) algorithm and the novel Dense-Projection Network (DPN) as a local detector. DPN is a deep neural network that consists of two important layers: Template Projection layer and Dense Aggregate layer. In Template Projection layer, patches of facial region are mapped to a higher dimensional space allowing the pose and rotation variations to be captured accurately. In Dense Aggregate layer an ensemble of experts is simulated within one network to make the landmark localization task more robust. In our extensive set of experiments we show that DPNs outperform previously proposed local detectors. Furthermore, we demonstrate that our proposed DCLM algorithm is stateof-the-art in facial landmark detection. We significantly outperform competitive baselines, that use both CLM-based and cascaded regression approaches, by a large margin on three publicly-available datasets for image and video landmark detection.", "creator": "LaTeX with hyperref package"}}}