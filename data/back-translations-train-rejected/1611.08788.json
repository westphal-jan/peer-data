{"id": "1611.08788", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Nov-2016", "title": "SAD-GAN: Synthetic Autonomous Driving using Generative Adversarial Networks", "abstract": "Autonomous driving is one of the most recent topics of interest which is aimed at replicating human driving behavior keeping in mind the safety issues. We approach the problem of learning synthetic driving using generative neural networks. The main idea is to make a controller trainer network using images plus key press data to mimic human learning. We used the architecture of a stable GAN to make predictions between driving scenes using key presses. We train our model on one video game (Road Rash) and tested the accuracy and compared it by running the model on other maps in Road Rash to determine the extent of learning.", "histories": [["v1", "Sun, 27 Nov 2016 05:01:39 GMT  (188kb,D)", "http://arxiv.org/abs/1611.08788v1", "5 pages; 4 figures; Accepted at the Deep Learning for Action and Interaction Workshop, 30th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain; All authors have equal contribution"]], "COMMENTS": "5 pages; 4 figures; Accepted at the Deep Learning for Action and Interaction Workshop, 30th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain; All authors have equal contribution", "reviews": [], "SUBJECTS": "cs.CV cs.AI", "authors": ["arna ghosh", "biswarup bhattacharya", "somnath basu roy chowdhury"], "accepted": false, "id": "1611.08788"}, "pdf": {"name": "1611.08788.pdf", "metadata": {"source": "META", "title": "SAD-GAN: Synthetic Autonomous Driving using Generative Adversarial Networks", "authors": ["Arna Ghosh", "Biswarup Bhattacharya", "Somnath Basu Roy Chowdhury"], "emails": ["arnaghosh@iitkgp.ac.in", "biswarup@iitkgp.ac.in", "brcsomnath@ee.iitkgp.ernet.in"], "sections": [{"heading": "1 Introduction", "text": "In fact, it is such that most of the people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to dance, to move, to dance, to dance, to move, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to move, to move, to dance, to move, to move, to move, to move, to move, to dance, to dance, to dance, to"}, {"heading": "2 Methodology", "text": "All our work in the field of synthetic driving has been carried out in the following sequential order: data acquisition, generative network, predictive wrinkle-shaped network, training and testing process."}, {"heading": "2.1 Data Collection", "text": "In fact, most of them are able to survive on their own if they do not put themselves in a position to survive on their own."}, {"heading": "2.3 Training and Workflow", "text": "The authors use the collected data set to train a generator network to predict images that yield an image and a key press. The discriminator is trained to distinguish between generated images and images from the data set. After receiving a sufficiently efficient generator, the generator network is used in action to predict all three images from a given image. The three images are the images that should result from a left, right and right key press of the given situation. The three generated images are classified as \"safe\" or \"unsafe.\" For this task, the authors train a simple network from the above data set of images collected from Road Rash. The network is trained to predict the key press that the user would have chosen from a given scene. Thus, the network is to predict for a given image left, right or top like the key press. The results are significant motivating, but it depends on the \"playing platform\" that needs to be safely placed or trained in the network."}, {"heading": "3 Results", "text": "An interesting step is to keep all the folding layers above the generator, discriminator and the \"safe\" or \"unsafe\" label network constant, which would allow a shift into latent space in the near future. Overall, the network used to predict \"safe\" or \"unsafe\" yielded an accuracy of 90% using three classes of 200 images each after training the model for 25 epochs. The training error for 20 epochs is shown below in Figure 4. The training process took about an hour."}, {"heading": "4 Further Work", "text": "A litmus test for this method would be to include natural images from the KITTI dataset [3] along with a first-person motion vector quantified enough to fit into the architecture presented here and observe the outcomes. Our network does not rely on standard methods such as object detection or scene labeling for decision making. Once we are trained on well-labeled real-world data over a limited period of time, we can use the generator model to predict more than one image [x (t), x (t + 1),..., x (t + n)] and make decisions based on the entire image cluster. We can also add other real-world driving parameters to the system such as gearbox, acceleration, braking, etc., using an auto encoder."}, {"heading": "5 Conclusion", "text": "Our algorithm provides insight into the improvement of modern algorithms in autonomous driving by predicting future driving scenes using generative methods. The network also trains itself on the behaviour of the driver whose data is fed into the network. If this idea is extended, the presented network can also be used in the case of manual driving, where it can act as a recommendation system for the driver by predicting different situations as soon as it is trained for real driving scenarios."}], "references": [{"title": "Road rash", "author": ["E. Arts"], "venue": "[CD-ROM]", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1991}, {"title": "Monte-carlo tree search: A new framework for game ai", "author": ["G. Chaslot", "S. Bakkes", "I. Szita", "P. Spronck"], "venue": "C. Darken and M. Mateas, editors, AIIDE. The AAAI Press", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2008}, {"title": "Vision meets robotics: The kitti dataset", "author": ["A. Geiger", "P. Lenz", "C. Stiller", "R. Urtasun"], "venue": "International Journal of Robotics Research (IJRR)", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2013}, {"title": "Generative adversarial networks", "author": ["I.J. Goodfellow", "J. Pouget-Abadie", "M. Mirza", "B. Xu", "D. Warde-Farley", "S. Ozair", "A. Courville", "Y. Bengio"], "venue": "ArXiv e-prints,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "Profiling drivers based on driver dependent vehicle driving features", "author": ["Z. Halim", "R. Kalsoom", "A.R. Baig"], "venue": "Applied Intelligence, 44(3):645\u2013664", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2016}, {"title": "Evolving large-scale neural networks for vision-based reinforcement learning", "author": ["J. Koutn\u00edk", "G. Cuccu", "J. Schmidhuber", "F. Gomez"], "venue": "Proceedings of the 15th Annual Conference on Genetic and Evolutionary Computation, GECCO \u201913, pages 1061\u20131068, New York, NY, USA", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "F. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger, editors, Advances in Neural Information Processing Systems 25, pages 1097\u20131105. Curran Associates, Inc.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2012}, {"title": "Learning hand-eye coordination for robotic grasping with deep learning and large-scale data collection", "author": ["S. Levine", "P. Pastor", "A. Krizhevsky", "D. Quillen"], "venue": "CoRR, abs/1603.02199", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2016}, {"title": "Human-level control through deep reinforcement learning", "author": ["V. Mnih", "K. Kavukcuoglu", "D. Silver", "A.A. Rusu", "J. Veness", "M.G. Bellemare", "A. Graves", "M. Riedmiller", "A.K. Fidjeland", "G. Ostrovski", "S. Petersen", "C. Beattie", "A. Sadik", "I. Antonoglou", "H. King", "D. Kumaran", "D. Wierstra", "S. Legg", "D. Hassabis"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2015}, {"title": "Unsupervised representation learning with deep convolutional generative adversarial networks", "author": ["A. Radford", "L. Metz", "S. Chintala"], "venue": "CoRR, abs/1511.06434", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2015}, {"title": "Generative adversarial text to image synthesis", "author": ["S.E. Reed", "Z. Akata", "X. Yan", "L. Logeswaran", "B. Schiele", "H. Lee"], "venue": "CoRR, abs/1605.05396", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2016}, {"title": "Playing for data: Ground truth from computer games", "author": ["S.R. Richter", "V. Vineet", "S. Roth", "V. Koltun"], "venue": "CoRR, abs/1608.02192", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2016}, {"title": "Learning a driving simulator", "author": ["E. Santana", "G. Hotz"], "venue": "CoRR, abs/1608.01230", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2016}, {"title": "Mastering the game of Go with deep neural networks and tree search", "author": ["D. Silver", "A. Huang", "C.J. Maddison", "A. Guez", "L. Sifre", "G. van den Driessche", "J. Schrittwieser", "I. Antonoglou", "V. Panneershelvam", "M. Lanctot", "S. Dieleman", "D. Grewe", "J. Nham", "N. Kalchbrenner", "I. Sutskever", "T. Lillicrap", "M. Leach", "K. Kavukcuoglu", "T. Graepel", "D. Hassabis"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2016}], "referenceMentions": [{"referenceID": 4, "context": "Autonomous driving is a well-established problem and the use of large amounts of labeled and contextually rich data to solve the problems of road detection and prediction of vehicle parameters like accelerator, clutch and brake positions have already been explored [5].", "startOffset": 265, "endOffset": 268}, {"referenceID": 11, "context": "A solution proposed to aid the issue is the use of synthetic data along with natural data to train the system [12].", "startOffset": 110, "endOffset": 114}, {"referenceID": 5, "context": "Vision based controls and reinforcement learning had recent success in the literature [6], [9], [14], [8] mostly due to (deep, recurrent) neural networks and unbounded access to world or game interaction.", "startOffset": 86, "endOffset": 89}, {"referenceID": 8, "context": "Vision based controls and reinforcement learning had recent success in the literature [6], [9], [14], [8] mostly due to (deep, recurrent) neural networks and unbounded access to world or game interaction.", "startOffset": 91, "endOffset": 94}, {"referenceID": 13, "context": "Vision based controls and reinforcement learning had recent success in the literature [6], [9], [14], [8] mostly due to (deep, recurrent) neural networks and unbounded access to world or game interaction.", "startOffset": 96, "endOffset": 100}, {"referenceID": 7, "context": "Vision based controls and reinforcement learning had recent success in the literature [6], [9], [14], [8] mostly due to (deep, recurrent) neural networks and unbounded access to world or game interaction.", "startOffset": 102, "endOffset": 105}, {"referenceID": 3, "context": "The use of Generative Adversarial Networks [4] for the same has been explored in [13] and acts as a good motivation for the work presented.", "startOffset": 43, "endOffset": 46}, {"referenceID": 12, "context": "The use of Generative Adversarial Networks [4] for the same has been explored in [13] and acts as a good motivation for the work presented.", "startOffset": 81, "endOffset": 85}, {"referenceID": 1, "context": "Once a satisfactory generative network is obtained, the generator can be used to generate a variety of images to explore the next steps similar to that used in Atari games [2], thus building an alpha-beta pruned game tree.", "startOffset": 172, "endOffset": 175}, {"referenceID": 0, "context": "For the purpose of the paper, we used frames from the popular racing game Road Rash [1].", "startOffset": 84, "endOffset": 87}, {"referenceID": 9, "context": "The architecture of a stable deep convolutional generative adversarial network (DCGAN) is utilized [10].", "startOffset": 99, "endOffset": 103}, {"referenceID": 10, "context": "The generator and discriminator architecture are inspired from [11].", "startOffset": 63, "endOffset": 67}, {"referenceID": 6, "context": "The training of the neural network is performed on a standard AlexNet architecture [7].", "startOffset": 83, "endOffset": 86}, {"referenceID": 6, "context": "The input image x(t) and the generated image x(t+1) is then fed to the neural network architecture [7] to predict the key press from the trained network.", "startOffset": 99, "endOffset": 102}, {"referenceID": 2, "context": "A litmus test to this method would be to include natural images from the KITTI dataset [3] along with an ego-motion vector quantified enough to fit the architecture presented here and observe the results.", "startOffset": 87, "endOffset": 90}], "year": 2016, "abstractText": "Autonomous driving is one of the most recent topics of interest which is aimed at replicating human driving behavior keeping in mind the safety issues. We approach the problem of learning synthetic driving using generative neural networks. The main idea is to make a controller trainer network using images plus key press data to mimic human learning. We used the architecture of a stable GAN to make predictions between driving scenes using key presses. We train our model on one video game (Road Rash) and tested the accuracy and compared it by running the model on other maps in Road Rash to determine the extent of learning.", "creator": "LaTeX with hyperref package"}}}