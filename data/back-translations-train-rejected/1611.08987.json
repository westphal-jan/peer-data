{"id": "1611.08987", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Nov-2016", "title": "Exploiting Unlabeled Data for Neural Grammatical Error Detection", "abstract": "Identifying and correcting grammatical errors in the text written by non-native writers has received increasing attention in recent years. Although a number of annotated corpora have been established to facilitate data-driven grammatical error detection and correction approaches, they are still limited in terms of quantity and coverage because human annotation is labor-intensive, time-consuming, and expensive. In this work, we propose to utilize unlabeled data to train neural network based grammatical error detection models. The basic idea is to cast error detection as a binary classification problem and derive positive and negative training examples from unlabeled data. We introduce an attention-based neural network to capture long-distance dependencies that influence the word being detected. Experiments show that the proposed approach significantly outperforms SVMs and convolutional networks with fixed-size context window.", "histories": [["v1", "Mon, 28 Nov 2016 05:32:35 GMT  (232kb,D)", "https://arxiv.org/abs/1611.08987v1", null], ["v2", "Tue, 29 Nov 2016 06:08:59 GMT  (232kb,D)", "http://arxiv.org/abs/1611.08987v2", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["zhuoran liu", "yang liu"], "accepted": false, "id": "1611.08987"}, "pdf": {"name": "1611.08987.pdf", "metadata": {"source": "CRF", "title": "Exploiting Unlabeled Data for Neural Grammatical Error Detection", "authors": ["Zhuoran Liu", "Yang Liu"], "emails": ["liuzhuoran17@163.com,", "liuyang2011@tsinghua.edu.cn"], "sections": [{"heading": "1 Introduction", "text": "This year it is so far that it will be able to erenie.n the aforementioned lcihsrcsrVo"}, {"heading": "2 Background", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Problem Statement", "text": "The goal of grammatical error detection at the word level is to identify grammatical errors at the word level. For example, a grammatical error detection system is expected to correctly identify the erroneous word \"birds,\" which is highlighted by underlining:"}, {"heading": "An ugly birds was observed by the man yesterday .", "text": "The task of grammatical error detection at the word level is formalized as such: Faced with a sequence of characters X = (x1, x2,..., xn) as input, the error detector outputs its prediction Y = (y1, y2,..., yn), where yi denotes the grammatical correctness of xi. We treat this problem as a problem of binary classification. To predict yt against the current word xt and the whole sentence X = (x1, x2,..., xn), we must find a function g (\u00b7) to calculate the conditional probability of each yt given text and the entire input sequence X: p (yt | xt) = g (xt, X), (1) where eyt = {1 is correct 0. (2) Our goal is to build a suitable classification model for g (\u00b7)."}, {"heading": "2.2 Support Vector Machines", "text": "A natural approach is to use the Support Vector Machine (SVM) for classification (Boser, Guyon and Vapnik [1992]; Cortes and Vapnik [1995]). SVM receives a training data set in the form of {(x1, y1),..., (xn, yn)}, where xi represents a symbol with a set of selected linguistic features and yi denotes the grammatical correctness of the token. It finds a hyperplane with a maximum margin that separates correct words from wrong ones. The problem with this approach is that we have to manually design features in xi. Since humans cannot accurately say which features are relevant, human-designed features are inadequate in some aspects and redundant in others. As a result, these designed features are unable to capture all regularities, which could affect the performance of our fault detector."}, {"heading": "2.3 Convolution Network with Fixed Window Size", "text": "To get around the feature engineering problem, a natural thought is to use the neural network's ability to automatically extract features (Collobert and Weston [2008]). The simplest way is to consider a window with fixed-size words around the current word as context by applying the temporal folding over the fixed-size window. In the example sentence from Section 2.1, when considering the grammatical correctness of the word \"a fixed-size window is given, the context window would be considered birds.\" The assumption underlying this method is that only adjacent words are grammatically related to the current word. Here, we formalize the method of the neural network with a fixed-size window. Given a word xi whose context is ci isci = (xi \u2212 w / 2,..., xi + w / 2)..., xi + w / 2), only adjacent words are grammatically associated with the current word (3), we call the input-size of the window-time operation equal to the input-size of the window-size (p)."}, {"heading": "3 Approach", "text": "In this section, we describe our uncontrolled approach to detecting grammatical errors at the word level."}, {"heading": "3.1 Model Architecture", "text": "Our intuition is to first encode the input sequence into a sequence of hidden states that contain relevant grammatical information, and then make predictions that contain a word and its context (see Figure 1). Thus, our model consists of two parts: an encoder that adopts a typical architecture of the bidirectional LSTM network (Hochreiter and Schmidhuber [1997]), and a classifier that makes predictions based on hidden states of the encoder."}, {"heading": "3.1.1 Encoder", "text": "In a recursive neural LSTM network, input X is processed over time and generates a series of memory states (c1, c2,..., cn) and hidden states (h1, h2,..., hn). To counteract the influence of time on hidden states, we process input X twice, forwards and backwards to fully encode the required information classifier. (4) Forward-looking LSTM updates its memory state \u2212 ci and hidden state \u2212 \u2192 hi at each time step t: [\u2212 \u2192 ct] = \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2192 LSTM ([\u2212 ht \u2212 1; \u2212 \u2212 ct \u2212 1]). (4) Likewise, the memory state \u2212 ci and hidden state \u2212 hi are updated in time step by backward-directed LSTM: \u2212 ht; \u2212 ht] = \u2212 ht \u2212 \u2212 \u2212 t (\u2212 \u2212 \u2212 ct \u2212 1])."}, {"heading": "3.1.2 Classifier with Intra-attention", "text": "To predict whether the word t is grammatically problematic, the classifier calculates a score given to the current word xt and its context. This score st then passes through a sigmoid layer and makes a binary prediction, with 1 grammatically correct and 0 incorrect. Note that the classifier does not have its own state as a decoder in a traditional encoder decoder architecture. To solve the problem of remote dependence, we include an intra-sentence attention mechanism (Bahdanau, Cho and Bengio [2014]) in our classifier, which takes into account all the hidden states of the encoder and dynamically adjusts the attention of the classifier to all positions of the sentence. To formally describe the context, we calculate the word xt around the word xt as a weighted sum of {h, h, h, 2, h, xxt} as an exact grammaticality."}, {"heading": "3.2 Noise Generation", "text": "Traditionally, a large set of {< X (n), Y (n) >} Nn = 1 is required to effectively train such a grammatical error detector. However, in an unattended approach, only {X (n)} Nn = 1 is given. The central question is how the corresponding {Y (n)} Nn = 1 could be achieved. We adopted the idea of using artificial errors for training. It is crucial to find a suitable algorithm for the error generator to produce realistic grammatical errors, as the performance of the model depends heavily on the paradigm it saw during training. As our task is to detect grammatical errors at the word level, we will only consider replacement errors. We are comparing two ways of replacing the original word with an incorrect one."}, {"heading": "3.2.1 Uniform random substitution", "text": "The easiest way is to replace a word in a random position with a random word from the vocabulary. The problem with this approach is that some artificial errors created in this way are apparently irrelevant."}, {"heading": "An ugly bird was observed by the man yesterday .", "text": "Algorithm 1 Build Substitution Set PoS-tag the input text Create a dictionary D of (Token, PoS-Tag) for all (Token, PoS-Tag) in D doif pos in {CC} or {DT, PDT} or {PRP, PRP $} or {IN, TO, RP} or {WDT, WP, WP $, WRB} then insert tokens into the corresponding substitution set if pos is added in {NN, NNP, NNNPS, NNS} or {VB, VBD, VBG, VBP, VBZ} then insert tokens into the corresponding substitution set if pos is added in {YY, JR, JtoD, VBG, VBG, VBG, VBZ} or {VBZ} if the corresponding substitution element is not present in {YY, JS} or Ytow} or a sentence {BG}."}, {"heading": "3.2.2 Substitution with linguistic knowledge", "text": "We carefully examined a number of erroneous paradigms and found some characteristics common to all grammatical errors, regardless of the terminology and frequently observed patterns of the domain. To sum it up briefly, errors usually occur when a correct word is replaced by another word that comes from a finite set of words and is linguistically related to it, either because it has the same lemmas or the same part of the speech tag. There is an inexhaustible list of how linguistic knowledge works in substitution. At this point, we present only a few examples in Table.1.Combining these two methods of error generation, we are able to generate 16 types of grammatical errors specified by 28 in CoNLL-2014 Shared Task (Ng et al. [2014]). 1 Details are described by Algorithm 1, which formalizes the construction of substitution sets, and Algorithm 2, which formalizes the process of error generation with iformalized knowledge."}, {"heading": "4 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Settings", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1.1 Data", "text": "We used data mainly from three sources (Table 2): \u2022 ACL Anthology2 (> > > Errors): Training Set. \u2022 AESW Shared Task Dataset (AESW) (Daudaravicius et al. [2016]): Development and Test Sets. \u2022 CCL Anthology3 (CCL): Development and Test Sets. For training, we used sets of papers that appear in ACL Anthology. We crawled through all papers until 2015 and then chose sets that have a length of more than 5, but no longer than 50, containing several clauses separated by commas, colons or semicolons. Formulas and references are removed with a special < num > token and parentheses."}, {"heading": "4.1.2 Baselines", "text": "To the best of our knowledge, the task of detecting grammatical errors at the word level has never been explored before. Therefore, we are using the two methods described in 2.2 and 2.3. We have compared our method with two baselines, both of which are trained on the ACL training set. \u2022 Support Vector Machine (SVM). \u2022 Convolutional Network (Conv).SVM takes into account the context in a fixed window of size 5 around the current word and predicts whether the current word is grammatically correct in the sentence. In our experiment, we first have an n-gram model with KenLM (Heafield [2011]) on the entire training set without artificial errors with n up to 3. We then use n-gram values as input characteristics in the SVM. In our experiment, we used the open source tool LibLinear (Fan et al. [2008]). In Conv, we use word embedding, which was previously determined on the basis of the 2d2c model in Soek-sik and gensik-ehu (2008)."}, {"heading": "4.1.3 BiLSTM with Intra-attention", "text": "Our model is implemented with Tensorflow.5 We used cross-entropy as our loss function for optimization. We perform gradient clipping according to global standards (Pascanu, Mikolov and Bengio [2013]) using the function provided in Tensorflow. Mention of word embedding and hidden state is set to 150, as a trade-off between performance and training time. The word embedding matrix is initialized with a random even distribution in the range of \u00b1 0.05."}, {"heading": "4.2 Results and Discussion", "text": "Tables 3 and 4 present the results of experiments of two baselines (SVM and T-Conv) and our model (BiLSTM) using uniform random errors (uni.) or linguistic errors (ling.) The two tables show that our model outperformed the two baselines in both human-annotated datasets (AESW and CCL).The F0.5 value may seem low, but they are actually good results, as these models are trained without supervision. 4http: / / torch.ch / 5https: / / www.tensorflow.org /"}, {"heading": "4.2.1 Effect of Error Types", "text": "If we focus on the task of detecting a limited number of error types (verb form, noun number, preposition abuse, article abuse), the model would perform better in the CCL test set, but weaker or only comparable to the AESW test set. This is probably because we focused heavily on these common error types during the annotation phase of the CCL test set, and some other error types are neglected. Results are shown in Tables 5 and 6."}, {"heading": "4.2.2 Effect of Attention", "text": "Comparison of models with and without attention is shown in Tables 5 and 6. Although the intra-attention mechanism has worked, it may fail in some cases. We believe that a more sophisticated way of generating errors is needed, as currently only positions where a substitution takes place have a chance of being called wrong (\"on-site error\" paradigms), but for the model to learn grammatical relationships through attention mechanisms, we need massive paradigms where substitution leads to another position being called wrong (\"off-site error\" paradigms)."}, {"heading": "An ugly bird was observed by the man yesterday .", "text": "If we replace ugly with beautiful, our system will automatically comment beautiful as wrong (on-site error) A beautiful bird was observed yesterday by the man, but our model will never know why it is wrong. Instead, what we need are off-site errors: A beautiful bird was observed yesterday by the man. So that the model knows that nice is fine with \"A,\" but not with \"An.\" Unfortunately, our method does not provide such a mechanism to produce mass \"off-site errors,\" so our model has to rely on very few randomly generated \"off-site errors\" that are too economical. Our current method also introduced some substitutions that should not be counted as errors. For example, if yesterday is replaced by today: An ugly bird was observed by the man today. \"Today\" is commented wrong according to our method, while it is not really a grammatical error, which affects the performance of the model to some extent."}, {"heading": "4.2.3 Examples", "text": "It works well with collocations, as in Ex.1. It also works well with morphological problems, as in Ex.2. However, it is not able to detect errors of the genre as in Ex.3. In Ex.4, it confused wrong words from the field of training data. In Ex.5, it shows that our model is aware of the missing between polarities and the opposite. 6The table contains only an incomplete list of the error type determined by our model. Since we only detect errors without being able to infer their types, we are not able to provide the complete list of error types that our model can detect. However, it reports errors elsewhere. There are other error types that our model could not cope with well, such as redundant determinators as in Ex.6."}, {"heading": "5 Related Work", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Grammatical Error Detection and Correction", "text": "In recent years, several common tasks have been performed to detect or correct grammatical errors, including HOO-2011 (Dale and Kilgarriff [2011]), HOO-2012 (Dale, Anisimoff and Narroway [2012]), CoNLL-2013 (Ng et al. [2013]) and CoNLL-2014 (Ng et al. [2014]). These four common tasks all focused on grammatical error correction of English written by non-native speakers. AESW's common task (Daudaravicius et al. [2016]) proposed to automatically evaluate scientific papers based on sentence-level error detection. In contrast to these common tasks, we focused on grammatical error detection at word level, which is a pilot step towards an uncontrolled approach to error correction.To address the problem of grammatical errors, researchers investigated and used various methods."}, {"heading": "5.2 Error Generation", "text": "In order to obtain sufficient training data, various approaches were used to generate artificial errors. Markov's logic network was used to simulate statistical grammatical errors (Lee and Lee [2009]), an automatic error generation tool was developed (Foster and Andersen [2009]) using a corpus and error generation rules as input, and artificial errors in the UI system (Rozovskaya, Sammons and Roth [2012]) were used in the joint task HOO-2012 to increase the training set, and a similar method was used in Japanese (Imamura et al. [2012]). To increase the size of the training set, artificial errors were injected into the corpus of Yuan and Felice in the joint task CoNLL-2013 (Yuan and Felice [2013]), and later they further investigated the probable nature of artificial error generation with linguistic information (Felice and Yuan automatically added to the corpus of Yuan and Yuan [In contrast to Yuan and Yuan] during a substitution of Yuan and Yuan in 2009."}, {"heading": "5.3 RNNs and LSTM Units", "text": "Recurrent Neural Network (RNN) with Long Short-Term Memory (LSTM) or Gated Recurrent Unit (GRU) has shown that it is capable of encoding information about long sequences (Cho et al. [2014]). The attention mechanism enabled a bidirectional RNN with GRU to achieve even better performance in machine translation (Bahdanau, Cho and Bengio [2014]) by allowing the decoder to explicitly use the encoder memory. After the emergence of attention mechanisms, it was applied to many other NLP topics than machine translation. Grammatic error correction is no exception. Schmaltz et al. used a unidirectional LSTM network with attention mechanism and achieved the best performance in the common task of the AESW (Schmaltz et al. [2016]). Contrary to them, we do not need a code correction, therefore, because we do not need to include a coding from the STM."}, {"heading": "6 Conclusion and Future Work", "text": "We have shown that learning grammatical relationships and predicting grammatical errors is a viable method for machines, and this inspires us to expand the unattended approach to grammatical error correction. In the future, we plan to explore new methods for creating artificial errors to enable our model to gain better attention within a sentence."}], "references": [{"title": "Neural machine translation by jointly learning to align and translate", "author": ["D. Bahdanau", "K. Cho", "Y. Bengio"], "venue": "CoRR abs/1409.0473.", "citeRegEx": "Bahdanau et al\\.,? 2014", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2014}, {"title": "A training algorithm for optimal margin classifiers", "author": ["B.E. Boser", "I. Guyon", "V. Vapnik"], "venue": "COLT.", "citeRegEx": "Boser et al\\.,? 1992", "shortCiteRegEx": "Boser et al\\.", "year": 1992}, {"title": "Learning phrase representations using rnn encoder-decoder for statistical machine translation", "author": ["K. Cho", "B. van Merrienboer", "aglar G\u00fclehre", "D. Bahdanau", "F. Bougares", "H. Schwenk", "Y. Bengio"], "venue": null, "citeRegEx": "Cho et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Cho et al\\.", "year": 2014}, {"title": "A unified architecture for natural language processing: deep neural networks with multitask learning", "author": ["R. Collobert", "J. Weston"], "venue": "ICML.", "citeRegEx": "Collobert and Weston,? 2008", "shortCiteRegEx": "Collobert and Weston", "year": 2008}, {"title": "Support-vector networks", "author": ["C. Cortes", "V. Vapnik"], "venue": "Machine Learning 20:273\u2013297.", "citeRegEx": "Cortes and Vapnik,? 1995", "shortCiteRegEx": "Cortes and Vapnik", "year": 1995}, {"title": "A beam-search decoder for grammatical error correction", "author": ["D. Dahlmeier", "H.T. Ng"], "venue": "EMNLP-CoNLL.", "citeRegEx": "Dahlmeier and Ng,? 2012", "shortCiteRegEx": "Dahlmeier and Ng", "year": 2012}, {"title": "Building a large annotated corpus of learner english: The nus corpus of learner english", "author": ["D. Dahlmeier", "H.T. Ng", "S.M. Wu"], "venue": null, "citeRegEx": "Dahlmeier et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Dahlmeier et al\\.", "year": 2013}, {"title": "Helping our own: The hoo 2011 pilot shared task", "author": ["R. Dale", "A. Kilgarriff"], "venue": "In Proc. of ENLG.", "citeRegEx": "Dale and Kilgarriff,? 2011", "shortCiteRegEx": "Dale and Kilgarriff", "year": 2011}, {"title": "Hoo 2012: A report on the preposition and determiner error correction", "author": ["R. Dale", "I. Anisimoff", "G. Narroway"], "venue": null, "citeRegEx": "Dale et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Dale et al\\.", "year": 2012}, {"title": "A report on the automatic evaluation of scientific writing shared task", "author": ["V. Daudaravicius", "R.E. Banchs", "E. Volodina", "C. Napoles"], "venue": "Proceedings of the 11th Workshop on Innovative Use of NLP for Building Educational Applications, 53\u201362. San Diego, CA: Association for Computational Linguistics.", "citeRegEx": "Daudaravicius et al\\.,? 2016", "shortCiteRegEx": "Daudaravicius et al\\.", "year": 2016}, {"title": "Liblinear: A library for large linear classification", "author": ["R.-E. Fan", "K.-W. Chang", "C.-J. Hsieh", "X.-R. Wang", "C.-J. Lin"], "venue": "Journal of Machine Learning Research 9:1871\u20131874.", "citeRegEx": "Fan et al\\.,? 2008", "shortCiteRegEx": "Fan et al\\.", "year": 2008}, {"title": "Generating artificial errors for grammatical error correction", "author": ["M. Felice", "Z. Yuan"], "venue": "EACL.", "citeRegEx": "Felice and Yuan,? 2014", "shortCiteRegEx": "Felice and Yuan", "year": 2014}, {"title": "Grammatical error correction using hybrid systems and type filtering", "author": ["M. Felice", "Z. Yuan", "O.E. Andersen", "H. Yannakoudakis", "E. Kochmar"], "venue": "CONLL.", "citeRegEx": "Felice et al\\.,? 2014", "shortCiteRegEx": "Felice et al\\.", "year": 2014}, {"title": "Automated evaluation of scientific writing: Aesw shared task proposal", "author": ["H. Ford"], "venue": null, "citeRegEx": "Ford,? \\Q2015\\E", "shortCiteRegEx": "Ford", "year": 2015}, {"title": "Generrate: Generating errors for use in grammatical error detection", "author": ["J. Foster", "O.E. Andersen"], "venue": null, "citeRegEx": "Foster and Andersen,? \\Q2009\\E", "shortCiteRegEx": "Foster and Andersen", "year": 2009}, {"title": "KenLM: faster and smaller language model queries", "author": ["K. Heafield"], "venue": "Proceedings of the EMNLP 2011 Sixth Workshop on Statistical Machine Translation, 187\u2013197.", "citeRegEx": "Heafield,? 2011", "shortCiteRegEx": "Heafield", "year": 2011}, {"title": "Long short-term memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural Computation 9:1735\u20131780.", "citeRegEx": "Hochreiter and Schmidhuber,? 1997", "shortCiteRegEx": "Hochreiter and Schmidhuber", "year": 1997}, {"title": "Grammar error correction using pseudo-error sentences and domain adaptation", "author": ["K. Imamura", "K. Saito", "K. Sadamitsu", "H. Nishikawa"], "venue": "ACL.", "citeRegEx": "Imamura et al\\.,? 2012", "shortCiteRegEx": "Imamura et al\\.", "year": 2012}, {"title": "Realistic grammar error simulation using markov logic", "author": ["S. Lee", "G.G. Lee"], "venue": "ACL.", "citeRegEx": "Lee and Lee,? 2009", "shortCiteRegEx": "Lee and Lee", "year": 2009}, {"title": "The conll-2013 shared task on grammatical error correction", "author": ["H.T. Ng", "S.M. Wu", "Y. Wu", "C. Hadiwinoto", "J.R. Tetreault"], "venue": "CONLL.", "citeRegEx": "Ng et al\\.,? 2013", "shortCiteRegEx": "Ng et al\\.", "year": 2013}, {"title": "The conll-2014 shared task on grammatical error correction", "author": ["H.T. Ng", "S.M. Wu", "T. Briscoe", "C. Hadiwinoto", "R.H. Susanto", "C. Bryant"], "venue": "CONLL.", "citeRegEx": "Ng et al\\.,? 2014", "shortCiteRegEx": "Ng et al\\.", "year": 2014}, {"title": "The cambridge learner corpus -error coding and analysis for lexicography and elt", "author": ["D. Nicholls"], "venue": null, "citeRegEx": "Nicholls,? \\Q2003\\E", "shortCiteRegEx": "Nicholls", "year": 2003}, {"title": "On the difficulty of training recurrent neural networks", "author": ["R. Pascanu", "T. Mikolov", "Y. Bengio"], "venue": "ICML.", "citeRegEx": "Pascanu et al\\.,? 2013", "shortCiteRegEx": "Pascanu et al\\.", "year": 2013}, {"title": "Software Framework for Topic Modelling with Large Corpora", "author": ["R. \u0158eh\u016f\u0159ek", "P. Sojka"], "venue": "Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks, 45\u201350. Valletta, Malta: ELRA.", "citeRegEx": "\u0158eh\u016f\u0159ek and Sojka,? 2010", "shortCiteRegEx": "\u0158eh\u016f\u0159ek and Sojka", "year": 2010}, {"title": "Generating confusion sets for context-sensitive error correction", "author": ["A. Rozovskaya", "D. Roth"], "venue": "EMNLP.", "citeRegEx": "Rozovskaya and Roth,? 2010", "shortCiteRegEx": "Rozovskaya and Roth", "year": 2010}, {"title": "The university of illinois system in the conll2013 shared task", "author": ["A. Rozovskaya", "K.-W. Chang", "M. Sammons", "D. Roth"], "venue": "CONLL.", "citeRegEx": "Rozovskaya et al\\.,? 2013", "shortCiteRegEx": "Rozovskaya et al\\.", "year": 2013}, {"title": "The ui system in the hoo 2012 shared task on error correction", "author": ["A. Rozovskaya", "M. Sammons", "D. Roth"], "venue": null, "citeRegEx": "Rozovskaya et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Rozovskaya et al\\.", "year": 2012}, {"title": "Sentence-level grammatical error identification as sequence-to-sequence correction", "author": ["A. Schmaltz", "Y. Kim", "A.M. Rush", "S.M. Shieber"], "venue": "CoRR abs/1604.04677.", "citeRegEx": "Schmaltz et al\\.,? 2016", "shortCiteRegEx": "Schmaltz et al\\.", "year": 2016}, {"title": "End-to-end memory networks", "author": ["S. Sukhbaatar", "A. Szlam", "J. Weston", "R. Fergus"], "venue": "NIPS.", "citeRegEx": "Sukhbaatar et al\\.,? 2015", "shortCiteRegEx": "Sukhbaatar et al\\.", "year": 2015}, {"title": "Constrained grammatical error correction using statistical machine translation", "author": ["Z. Yuan", "M. Felice"], "venue": "CONLL.", "citeRegEx": "Yuan and Felice,? 2013", "shortCiteRegEx": "Yuan and Felice", "year": 2013}], "referenceMentions": [{"referenceID": 5, "context": "There are a large number of English learners around the world who need instantaneous accurate feedback to help improve their writings (Dahlmeier and Ng [2012]).", "startOffset": 135, "endOffset": 159}, {"referenceID": 5, "context": "There are a large number of English learners around the world who need instantaneous accurate feedback to help improve their writings (Dahlmeier and Ng [2012]). In the domain of scientific paper writing in which English is the main language, authors also need effective grammar checkers to help them in composing scientific articles (Ford [2015]).", "startOffset": 135, "endOffset": 346}, {"referenceID": 5, "context": "There are a large number of English learners around the world who need instantaneous accurate feedback to help improve their writings (Dahlmeier and Ng [2012]). In the domain of scientific paper writing in which English is the main language, authors also need effective grammar checkers to help them in composing scientific articles (Ford [2015]). There have been several shared tasks addressing grammar errors in recent years. HOO-2011 (Dale and Kilgarriff [2011]), HOO-2012 (Dale, Anisimoff, and Narroway [2012]), CoNLL-2013 (Ng et al.", "startOffset": 135, "endOffset": 465}, {"referenceID": 5, "context": "There are a large number of English learners around the world who need instantaneous accurate feedback to help improve their writings (Dahlmeier and Ng [2012]). In the domain of scientific paper writing in which English is the main language, authors also need effective grammar checkers to help them in composing scientific articles (Ford [2015]). There have been several shared tasks addressing grammar errors in recent years. HOO-2011 (Dale and Kilgarriff [2011]), HOO-2012 (Dale, Anisimoff, and Narroway [2012]), CoNLL-2013 (Ng et al.", "startOffset": 135, "endOffset": 514}, {"referenceID": 5, "context": "There are a large number of English learners around the world who need instantaneous accurate feedback to help improve their writings (Dahlmeier and Ng [2012]). In the domain of scientific paper writing in which English is the main language, authors also need effective grammar checkers to help them in composing scientific articles (Ford [2015]). There have been several shared tasks addressing grammar errors in recent years. HOO-2011 (Dale and Kilgarriff [2011]), HOO-2012 (Dale, Anisimoff, and Narroway [2012]), CoNLL-2013 (Ng et al. [2013]) and CoNLL2014 (Ng et al.", "startOffset": 135, "endOffset": 545}, {"referenceID": 5, "context": "There are a large number of English learners around the world who need instantaneous accurate feedback to help improve their writings (Dahlmeier and Ng [2012]). In the domain of scientific paper writing in which English is the main language, authors also need effective grammar checkers to help them in composing scientific articles (Ford [2015]). There have been several shared tasks addressing grammar errors in recent years. HOO-2011 (Dale and Kilgarriff [2011]), HOO-2012 (Dale, Anisimoff, and Narroway [2012]), CoNLL-2013 (Ng et al. [2013]) and CoNLL2014 (Ng et al. [2014]) shared tasks all aimed to correct grammar errors.", "startOffset": 135, "endOffset": 578}, {"referenceID": 5, "context": "There are a large number of English learners around the world who need instantaneous accurate feedback to help improve their writings (Dahlmeier and Ng [2012]). In the domain of scientific paper writing in which English is the main language, authors also need effective grammar checkers to help them in composing scientific articles (Ford [2015]). There have been several shared tasks addressing grammar errors in recent years. HOO-2011 (Dale and Kilgarriff [2011]), HOO-2012 (Dale, Anisimoff, and Narroway [2012]), CoNLL-2013 (Ng et al. [2013]) and CoNLL2014 (Ng et al. [2014]) shared tasks all aimed to correct grammar errors. The AESW shared task (Daudaravicius et al. [2016]) aimed to identify sentence-level grammar error.", "startOffset": 135, "endOffset": 679}, {"referenceID": 5, "context": "There are a large number of English learners around the world who need instantaneous accurate feedback to help improve their writings (Dahlmeier and Ng [2012]). In the domain of scientific paper writing in which English is the main language, authors also need effective grammar checkers to help them in composing scientific articles (Ford [2015]). There have been several shared tasks addressing grammar errors in recent years. HOO-2011 (Dale and Kilgarriff [2011]), HOO-2012 (Dale, Anisimoff, and Narroway [2012]), CoNLL-2013 (Ng et al. [2013]) and CoNLL2014 (Ng et al. [2014]) shared tasks all aimed to correct grammar errors. The AESW shared task (Daudaravicius et al. [2016]) aimed to identify sentence-level grammar error. These shared tasks helped advanced the research of grammatical error detection or correction. Despite these advances, the scarcity of annotated data is still a major limitation on research of grammatical error detection and correction. Researchers need mass annotated data to train a grammar checker, but unfortunately for them, there are only a small amount of annotated corpora available in a limited number of domains. Most annotated corpora are in the domain of learner English, e.g. NUCLE (Dahlmeier, Ng, and Wu [2013]) and CLC (Nicholls [2003]), and others are from domains such as scientific papers, e.", "startOffset": 135, "endOffset": 1252}, {"referenceID": 5, "context": "There are a large number of English learners around the world who need instantaneous accurate feedback to help improve their writings (Dahlmeier and Ng [2012]). In the domain of scientific paper writing in which English is the main language, authors also need effective grammar checkers to help them in composing scientific articles (Ford [2015]). There have been several shared tasks addressing grammar errors in recent years. HOO-2011 (Dale and Kilgarriff [2011]), HOO-2012 (Dale, Anisimoff, and Narroway [2012]), CoNLL-2013 (Ng et al. [2013]) and CoNLL2014 (Ng et al. [2014]) shared tasks all aimed to correct grammar errors. The AESW shared task (Daudaravicius et al. [2016]) aimed to identify sentence-level grammar error. These shared tasks helped advanced the research of grammatical error detection or correction. Despite these advances, the scarcity of annotated data is still a major limitation on research of grammatical error detection and correction. Researchers need mass annotated data to train a grammar checker, but unfortunately for them, there are only a small amount of annotated corpora available in a limited number of domains. Most annotated corpora are in the domain of learner English, e.g. NUCLE (Dahlmeier, Ng, and Wu [2013]) and CLC (Nicholls [2003]), and others are from domains such as scientific papers, e.", "startOffset": 135, "endOffset": 1278}, {"referenceID": 5, "context": "There are a large number of English learners around the world who need instantaneous accurate feedback to help improve their writings (Dahlmeier and Ng [2012]). In the domain of scientific paper writing in which English is the main language, authors also need effective grammar checkers to help them in composing scientific articles (Ford [2015]). There have been several shared tasks addressing grammar errors in recent years. HOO-2011 (Dale and Kilgarriff [2011]), HOO-2012 (Dale, Anisimoff, and Narroway [2012]), CoNLL-2013 (Ng et al. [2013]) and CoNLL2014 (Ng et al. [2014]) shared tasks all aimed to correct grammar errors. The AESW shared task (Daudaravicius et al. [2016]) aimed to identify sentence-level grammar error. These shared tasks helped advanced the research of grammatical error detection or correction. Despite these advances, the scarcity of annotated data is still a major limitation on research of grammatical error detection and correction. Researchers need mass annotated data to train a grammar checker, but unfortunately for them, there are only a small amount of annotated corpora available in a limited number of domains. Most annotated corpora are in the domain of learner English, e.g. NUCLE (Dahlmeier, Ng, and Wu [2013]) and CLC (Nicholls [2003]), and others are from domains such as scientific papers, e.g. AESW dataset (Ford [2015]).", "startOffset": 135, "endOffset": 1366}, {"referenceID": 5, "context": "There are a large number of English learners around the world who need instantaneous accurate feedback to help improve their writings (Dahlmeier and Ng [2012]). In the domain of scientific paper writing in which English is the main language, authors also need effective grammar checkers to help them in composing scientific articles (Ford [2015]). There have been several shared tasks addressing grammar errors in recent years. HOO-2011 (Dale and Kilgarriff [2011]), HOO-2012 (Dale, Anisimoff, and Narroway [2012]), CoNLL-2013 (Ng et al. [2013]) and CoNLL2014 (Ng et al. [2014]) shared tasks all aimed to correct grammar errors. The AESW shared task (Daudaravicius et al. [2016]) aimed to identify sentence-level grammar error. These shared tasks helped advanced the research of grammatical error detection or correction. Despite these advances, the scarcity of annotated data is still a major limitation on research of grammatical error detection and correction. Researchers need mass annotated data to train a grammar checker, but unfortunately for them, there are only a small amount of annotated corpora available in a limited number of domains. Most annotated corpora are in the domain of learner English, e.g. NUCLE (Dahlmeier, Ng, and Wu [2013]) and CLC (Nicholls [2003]), and others are from domains such as scientific papers, e.g. AESW dataset (Ford [2015]). In order to train their system with enough data, researchers use multiple corpus instead of one (Felice et al. [2014]).", "startOffset": 135, "endOffset": 1486}, {"referenceID": 11, "context": "Previously, efforts have been made to explore how realistic grammatical errors could be counterfeited automatically from error-free texts and therefore obtain large amount of annotated data (Felice and Yuan [2014]; Foster and Andersen [2009]; Lee and Lee [2009]; Imamura et al.", "startOffset": 191, "endOffset": 214}, {"referenceID": 11, "context": "Previously, efforts have been made to explore how realistic grammatical errors could be counterfeited automatically from error-free texts and therefore obtain large amount of annotated data (Felice and Yuan [2014]; Foster and Andersen [2009]; Lee and Lee [2009]; Imamura et al.", "startOffset": 191, "endOffset": 242}, {"referenceID": 11, "context": "Previously, efforts have been made to explore how realistic grammatical errors could be counterfeited automatically from error-free texts and therefore obtain large amount of annotated data (Felice and Yuan [2014]; Foster and Andersen [2009]; Lee and Lee [2009]; Imamura et al.", "startOffset": 191, "endOffset": 262}, {"referenceID": 11, "context": "Previously, efforts have been made to explore how realistic grammatical errors could be counterfeited automatically from error-free texts and therefore obtain large amount of annotated data (Felice and Yuan [2014]; Foster and Andersen [2009]; Lee and Lee [2009]; Imamura et al. [2012]).", "startOffset": 191, "endOffset": 285}, {"referenceID": 4, "context": "2 Support Vector Machines A natural approach is to use Support Vector Machine (SVM) to perform classification (Boser, Guyon, and Vapnik [1992]; Cortes and Vapnik [1995]).", "startOffset": 144, "endOffset": 169}, {"referenceID": 3, "context": "3 Convolution Network with Fixed Window Size To circumvent the problem with feature engineering, a natural thought is to utilize the capability of neural networks in automatic feature extraction (Collobert and Weston [2008]).", "startOffset": 196, "endOffset": 224}, {"referenceID": 16, "context": "Thus our model consists of two parts: an encoder that adopts a typical architecture of bi-directional LSTM network (Hochreiter and Schmidhuber [1997]), and a classifier that makes predictions based on hidden states of the encoder.", "startOffset": 116, "endOffset": 150}, {"referenceID": 19, "context": "of 28 specified by CoNLL-2014 Shared Task (Ng et al. [2014]).", "startOffset": 43, "endOffset": 60}, {"referenceID": 9, "context": "\u2022 AESW Shared Task Dataset (AESW) (Daudaravicius et al. [2016]) : development and test sets.", "startOffset": 35, "endOffset": 63}, {"referenceID": 14, "context": "We first trained an n-gram model with KenLM (Heafield [2011]) on the whole training set without artificial errors, with n up to 3.", "startOffset": 45, "endOffset": 61}, {"referenceID": 10, "context": "In our experiment we used the open-source tool LibLinear (Fan et al. [2008]).", "startOffset": 58, "endOffset": 76}, {"referenceID": 10, "context": "In our experiment we used the open-source tool LibLinear (Fan et al. [2008]). In Conv, we use word-embeddings pre-trained using word2vec model in gensim (\u0158eh\u016f\u0159ek and Sojka [2010]), the dimensionality of which we set to 50 empirically.", "startOffset": 58, "endOffset": 179}, {"referenceID": 6, "context": "1 Grammatical Error Detection and Correction Several shared tasks on grammatical error detection or correction have been carried out in recent years, including HOO-2011 (Dale and Kilgarriff [2011]), HOO-2012 (Dale, Anisimoff, and Narroway [2012]) , CoNLL-2013 (Ng et al.", "startOffset": 170, "endOffset": 197}, {"referenceID": 6, "context": "1 Grammatical Error Detection and Correction Several shared tasks on grammatical error detection or correction have been carried out in recent years, including HOO-2011 (Dale and Kilgarriff [2011]), HOO-2012 (Dale, Anisimoff, and Narroway [2012]) , CoNLL-2013 (Ng et al.", "startOffset": 170, "endOffset": 246}, {"referenceID": 6, "context": "1 Grammatical Error Detection and Correction Several shared tasks on grammatical error detection or correction have been carried out in recent years, including HOO-2011 (Dale and Kilgarriff [2011]), HOO-2012 (Dale, Anisimoff, and Narroway [2012]) , CoNLL-2013 (Ng et al. [2013]), and CoNLL-2014 (Ng et al.", "startOffset": 170, "endOffset": 278}, {"referenceID": 6, "context": "1 Grammatical Error Detection and Correction Several shared tasks on grammatical error detection or correction have been carried out in recent years, including HOO-2011 (Dale and Kilgarriff [2011]), HOO-2012 (Dale, Anisimoff, and Narroway [2012]) , CoNLL-2013 (Ng et al. [2013]), and CoNLL-2014 (Ng et al. [2014]).", "startOffset": 170, "endOffset": 313}, {"referenceID": 6, "context": "1 Grammatical Error Detection and Correction Several shared tasks on grammatical error detection or correction have been carried out in recent years, including HOO-2011 (Dale and Kilgarriff [2011]), HOO-2012 (Dale, Anisimoff, and Narroway [2012]) , CoNLL-2013 (Ng et al. [2013]), and CoNLL-2014 (Ng et al. [2014]). These four shared tasks all focused on grammatical error correction of English written by non-native speakers. The AESW shared task (Daudaravicius et al. [2016]) proposed to evaluate scientific writing automatically based on sentence-level error identification.", "startOffset": 170, "endOffset": 476}, {"referenceID": 6, "context": "1 Grammatical Error Detection and Correction Several shared tasks on grammatical error detection or correction have been carried out in recent years, including HOO-2011 (Dale and Kilgarriff [2011]), HOO-2012 (Dale, Anisimoff, and Narroway [2012]) , CoNLL-2013 (Ng et al. [2013]), and CoNLL-2014 (Ng et al. [2014]). These four shared tasks all focused on grammatical error correction of English written by non-native speakers. The AESW shared task (Daudaravicius et al. [2016]) proposed to evaluate scientific writing automatically based on sentence-level error identification. Different from these shared tasks, we focus on word-level grammatical error detection, which is a pilot step towards unsupervised approach to error correction. To address the issue of grammatical error, researchers explored and utilized various methods. For example classification method was used by the top ranking team (Rozovskaya et al. [2013]) in CoNLL-2013 shared task.", "startOffset": 170, "endOffset": 924}, {"referenceID": 6, "context": "1 Grammatical Error Detection and Correction Several shared tasks on grammatical error detection or correction have been carried out in recent years, including HOO-2011 (Dale and Kilgarriff [2011]), HOO-2012 (Dale, Anisimoff, and Narroway [2012]) , CoNLL-2013 (Ng et al. [2013]), and CoNLL-2014 (Ng et al. [2014]). These four shared tasks all focused on grammatical error correction of English written by non-native speakers. The AESW shared task (Daudaravicius et al. [2016]) proposed to evaluate scientific writing automatically based on sentence-level error identification. Different from these shared tasks, we focus on word-level grammatical error detection, which is a pilot step towards unsupervised approach to error correction. To address the issue of grammatical error, researchers explored and utilized various methods. For example classification method was used by the top ranking team (Rozovskaya et al. [2013]) in CoNLL-2013 shared task. The top ranking team (Felice et al. [2014]) of CoNLL-2014 shared task incorporated in their system a Statistical Machine Translation (SMT) component, which translates erroneous English into correct English.", "startOffset": 170, "endOffset": 995}, {"referenceID": 6, "context": "1 Grammatical Error Detection and Correction Several shared tasks on grammatical error detection or correction have been carried out in recent years, including HOO-2011 (Dale and Kilgarriff [2011]), HOO-2012 (Dale, Anisimoff, and Narroway [2012]) , CoNLL-2013 (Ng et al. [2013]), and CoNLL-2014 (Ng et al. [2014]). These four shared tasks all focused on grammatical error correction of English written by non-native speakers. The AESW shared task (Daudaravicius et al. [2016]) proposed to evaluate scientific writing automatically based on sentence-level error identification. Different from these shared tasks, we focus on word-level grammatical error detection, which is a pilot step towards unsupervised approach to error correction. To address the issue of grammatical error, researchers explored and utilized various methods. For example classification method was used by the top ranking team (Rozovskaya et al. [2013]) in CoNLL-2013 shared task. The top ranking team (Felice et al. [2014]) of CoNLL-2014 shared task incorporated in their system a Statistical Machine Translation (SMT) component, which translates erroneous English into correct English. With the development of Neural Machine Translation (NMT) and attention mechanism (Bahdanau, Cho, and Bengio [2014]), the top team (Schmaltz et al.", "startOffset": 170, "endOffset": 1274}, {"referenceID": 6, "context": "1 Grammatical Error Detection and Correction Several shared tasks on grammatical error detection or correction have been carried out in recent years, including HOO-2011 (Dale and Kilgarriff [2011]), HOO-2012 (Dale, Anisimoff, and Narroway [2012]) , CoNLL-2013 (Ng et al. [2013]), and CoNLL-2014 (Ng et al. [2014]). These four shared tasks all focused on grammatical error correction of English written by non-native speakers. The AESW shared task (Daudaravicius et al. [2016]) proposed to evaluate scientific writing automatically based on sentence-level error identification. Different from these shared tasks, we focus on word-level grammatical error detection, which is a pilot step towards unsupervised approach to error correction. To address the issue of grammatical error, researchers explored and utilized various methods. For example classification method was used by the top ranking team (Rozovskaya et al. [2013]) in CoNLL-2013 shared task. The top ranking team (Felice et al. [2014]) of CoNLL-2014 shared task incorporated in their system a Statistical Machine Translation (SMT) component, which translates erroneous English into correct English. With the development of Neural Machine Translation (NMT) and attention mechanism (Bahdanau, Cho, and Bengio [2014]), the top team (Schmaltz et al. [2016]) of AESW shared task adopted the NMT approach to grammatical error correction.", "startOffset": 170, "endOffset": 1313}, {"referenceID": 6, "context": "1 Grammatical Error Detection and Correction Several shared tasks on grammatical error detection or correction have been carried out in recent years, including HOO-2011 (Dale and Kilgarriff [2011]), HOO-2012 (Dale, Anisimoff, and Narroway [2012]) , CoNLL-2013 (Ng et al. [2013]), and CoNLL-2014 (Ng et al. [2014]). These four shared tasks all focused on grammatical error correction of English written by non-native speakers. The AESW shared task (Daudaravicius et al. [2016]) proposed to evaluate scientific writing automatically based on sentence-level error identification. Different from these shared tasks, we focus on word-level grammatical error detection, which is a pilot step towards unsupervised approach to error correction. To address the issue of grammatical error, researchers explored and utilized various methods. For example classification method was used by the top ranking team (Rozovskaya et al. [2013]) in CoNLL-2013 shared task. The top ranking team (Felice et al. [2014]) of CoNLL-2014 shared task incorporated in their system a Statistical Machine Translation (SMT) component, which translates erroneous English into correct English. With the development of Neural Machine Translation (NMT) and attention mechanism (Bahdanau, Cho, and Bengio [2014]), the top team (Schmaltz et al. [2016]) of AESW shared task adopted the NMT approach to grammatical error correction. In comparison, we adopted a typical architecture of bi-directional LSTM (Hochreiter and Schmidhuber [1997]) on the encoder side (Cho et al.", "startOffset": 170, "endOffset": 1499}, {"referenceID": 2, "context": "In comparison, we adopted a typical architecture of bi-directional LSTM (Hochreiter and Schmidhuber [1997]) on the encoder side (Cho et al. [2014]), but replace the decoder with a classifier.", "startOffset": 129, "endOffset": 147}, {"referenceID": 15, "context": "Markov logic network was used for statistical grammar error simulation (Lee and Lee [2009]).", "startOffset": 72, "endOffset": 91}, {"referenceID": 13, "context": "An automatic tool for error generation was developed (Foster and Andersen [2009]), which take as input a corpus and error generation rules.", "startOffset": 54, "endOffset": 81}, {"referenceID": 13, "context": "An automatic tool for error generation was developed (Foster and Andersen [2009]), which take as input a corpus and error generation rules. Error inflation was used in UI system (Rozovskaya, Sammons, and Roth [2012]) in HOO-2012 shared task, and similar method was performed on Japanese (Imamura et al.", "startOffset": 54, "endOffset": 216}, {"referenceID": 13, "context": "An automatic tool for error generation was developed (Foster and Andersen [2009]), which take as input a corpus and error generation rules. Error inflation was used in UI system (Rozovskaya, Sammons, and Roth [2012]) in HOO-2012 shared task, and similar method was performed on Japanese (Imamura et al. [2012]).", "startOffset": 54, "endOffset": 310}, {"referenceID": 13, "context": "An automatic tool for error generation was developed (Foster and Andersen [2009]), which take as input a corpus and error generation rules. Error inflation was used in UI system (Rozovskaya, Sammons, and Roth [2012]) in HOO-2012 shared task, and similar method was performed on Japanese (Imamura et al. [2012]). To enlarge the size of training set, artificial errors were injected into the corpus by Yuan and Felice in CoNLL-2013 shared task (Yuan and Felice [2013]).", "startOffset": 54, "endOffset": 466}, {"referenceID": 11, "context": "Later they further researched the probabilistic manner of artificial error generation with linguistic information (Felice and Yuan [2014]).", "startOffset": 115, "endOffset": 138}, {"referenceID": 11, "context": "Later they further researched the probabilistic manner of artificial error generation with linguistic information (Felice and Yuan [2014]). Different from (Foster and Andersen [2009]), we build substitution set automatically from un-annotated corpus based on POS tag or lemma, while their tools require a set of rules to work.", "startOffset": 115, "endOffset": 183}, {"referenceID": 11, "context": "Later they further researched the probabilistic manner of artificial error generation with linguistic information (Felice and Yuan [2014]). Different from (Foster and Andersen [2009]), we build substitution set automatically from un-annotated corpus based on POS tag or lemma, while their tools require a set of rules to work. To compare with (Rozovskaya, Sammons, and Roth [2012]; Yuan and Felice [2013]; Felice and Yuan [2014]), their methods of error generation are based on annotated corpus, while we used only un-annotated error-free texts without any supervision.", "startOffset": 115, "endOffset": 381}, {"referenceID": 11, "context": "Later they further researched the probabilistic manner of artificial error generation with linguistic information (Felice and Yuan [2014]). Different from (Foster and Andersen [2009]), we build substitution set automatically from un-annotated corpus based on POS tag or lemma, while their tools require a set of rules to work. To compare with (Rozovskaya, Sammons, and Roth [2012]; Yuan and Felice [2013]; Felice and Yuan [2014]), their methods of error generation are based on annotated corpus, while we used only un-annotated error-free texts without any supervision.", "startOffset": 115, "endOffset": 405}, {"referenceID": 11, "context": "Later they further researched the probabilistic manner of artificial error generation with linguistic information (Felice and Yuan [2014]). Different from (Foster and Andersen [2009]), we build substitution set automatically from un-annotated corpus based on POS tag or lemma, while their tools require a set of rules to work. To compare with (Rozovskaya, Sammons, and Roth [2012]; Yuan and Felice [2013]; Felice and Yuan [2014]), their methods of error generation are based on annotated corpus, while we used only un-annotated error-free texts without any supervision.", "startOffset": 115, "endOffset": 429}, {"referenceID": 2, "context": "3 RNNs and LSTM Units Recurrent Neural Network (RNN) with Long Short-term Memory (LSTM) or Gated Recurrent Unit (GRU) has shown a mighty capability to encode informations over long sequences (Cho et al. [2014]).", "startOffset": 192, "endOffset": 210}, {"referenceID": 2, "context": "3 RNNs and LSTM Units Recurrent Neural Network (RNN) with Long Short-term Memory (LSTM) or Gated Recurrent Unit (GRU) has shown a mighty capability to encode informations over long sequences (Cho et al. [2014]). The attention mechanism has enabled a Bi-directional RNN with GRU to achieve even better performance in machine translation (Bahdanau, Cho, and Bengio [2014]) by allowing the decoder to explicitly make use of the memory of encoder.", "startOffset": 192, "endOffset": 370}, {"referenceID": 2, "context": "3 RNNs and LSTM Units Recurrent Neural Network (RNN) with Long Short-term Memory (LSTM) or Gated Recurrent Unit (GRU) has shown a mighty capability to encode informations over long sequences (Cho et al. [2014]). The attention mechanism has enabled a Bi-directional RNN with GRU to achieve even better performance in machine translation (Bahdanau, Cho, and Bengio [2014]) by allowing the decoder to explicitly make use of the memory of encoder. Upon the emergence of attention mechanisms, it has been applied to many NLP topics other than machine translation. Grammatical error correction is of no exception. Schmaltz et al. used a uni-directional LSTM network with attention mechanism and achieved the best performance in the AESW shared task (Schmaltz et al. [2016]).", "startOffset": 192, "endOffset": 767}], "year": 2016, "abstractText": "Identifying and correcting grammatical errors in the text written by non-native writers has received increasing attention in recent years. Although a number of annotated corpora have been established to facilitate data-driven grammatical error detection and correction approaches, they are still limited in terms of quantity and coverage because human annotation is labor-intensive, time-consuming, and expensive. In this work, we propose to utilize unlabeled data to train neural network based grammatical error detection models. The basic idea is to cast error detection as a binary classification problem and derive positive and negative training examples from unlabeled data. We introduce an attention-based neural network to capture long-distance dependencies that influence the word being detected. Experiments show that the proposed approach significantly outperforms SVMs and convolutional networks with fixed-size context window.", "creator": "LaTeX with hyperref package"}}}