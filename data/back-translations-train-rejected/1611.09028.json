{"id": "1611.09028", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Nov-2016", "title": "Analyzing Features for the Detection of Happy Endings in German Novels", "abstract": "With regard to a computational representation of literary plot, this paper looks at the use of sentiment analysis for happy ending detection in German novels. Its focus lies on the investigation of previously proposed sentiment features in order to gain insight about the relevance of specific features on the one hand and the implications of their performance on the other hand. Therefore, we study various partitionings of novels, considering the highly variable concept of \"ending\". We also show that our approach, even though still rather simple, can potentially lead to substantial findings relevant to literary studies.", "histories": [["v1", "Mon, 28 Nov 2016 08:56:04 GMT  (288kb)", "http://arxiv.org/abs/1611.09028v1", null]], "reviews": [], "SUBJECTS": "cs.IR cs.AI cs.CL", "authors": ["fotis jannidis", "isabella reger", "albin zehe", "martin becker", "lena hettinger", "reas hotho"], "accepted": false, "id": "1611.09028"}, "pdf": {"name": "1611.09028.pdf", "metadata": {"source": "CRF", "title": "Analyzing Features for the Detection of Happy Endings in German Novels", "authors": ["Fotis Jannidis", "Isabella Reger", "Albin Zehe", "Martin Becker", "Lena Hettinger", "Andreas Hotho", "Mark Finlayson", "Matthew Jockers", "Micha Elsner"], "emails": [], "sections": [{"heading": null, "text": "Sentiment analysis for the recognition of happy endings in German novels. It focuses on the study of previously proposed sensory characteristics in order to gain insights into the meaning of certain characteristics on the one hand and the implications of their execution on the other. Therefore, we examine different divisions of novels taking into account the highly variable concept of the \"end.\" We also show that our approach, although still relatively simple, can potentially lead to significant results for literary studies."}, {"heading": "Introduction", "text": "The plot is of fundamental importance for the structure of literary works. Methods for the computational representation of plot or specific plot elements would therefore be a major achievement for digital literary studies. This paper deals with one such element: happy endings. We use mood analysis to detect happy endings, but focus on a qualitative analysis of certain characteristics and their performance in order to gain deeper insights into automatic classification. Furthermore, we show how the applied method can be used for subsequent research questions that lead to interesting results in terms of the publication periods of the novels."}, {"heading": "Related Work", "text": "One of the first works dealt with folkloristic narratives by Mark Finlayson, who developed an algorithm for recognizing events and higher-level abstractions such as malice or reward (Finlayson 2012). Reiter et al., also on fairy tales, identified events, their participants and order, and used machine learning methods to find structural similarities between texts (Reiter 2013, Reiter et al. 2014). Lately, much attention was paid to emotional analysis when Matthew Jocker proposed emotional arousal as a new \"method for recognizing actions\" (Jockers 2014). He described his idea to break novels down into segments and use them to form plot lines (Jockers 2015). Despite general acceptance of the idea of using emotional analysis, his use of the Fourier transformation to smooth the resulting plot curves was criticized (Swafford 2015, Schmidt 2015). Micha Elsner (Elsner 2015, based on novels) is based on storytelling."}, {"heading": "Corpus and Resources", "text": "Our data set consists of 212 German-language novels, mostly from the 19th century. Each novel has been commented manually so that it either has a happy ending (50%) or not (50%). The relevant information comes from summaries of the Kindler Literary Dictionary Online and Wikipedia. If no summary was available, the corresponding parts of novel 2 were read by the commentators. A sensation analysis requires a resource that lists mood values that human readers normally associate with certain words or phrases in a text. This essay is based on the NRC Sentiment Lexicon (Mohammad and Turney 2013), which is available in an automatically translated German version. A noteworthy feature of this lexicon is that in addition to specifying binary 3 values (0 or 1) for negative and positive connotations (2 characteristics) words, it also categorizes into 8 basic emotions (anger, fear, disgust, joy, expectation, trust and sadness), see a table of 1 for an example of polarity, where an additional value is created by adding an 11 word."}, {"heading": "Experiments", "text": "This year, we will be able to put ourselves at the top, \"he said in an interview with\" Welt am Sonntag. \""}, {"heading": "Conclusion and Future Work", "text": "The automatic recognition of happy endings as an essential plot element of novels is a valuable step towards a comprehensive computer-aided representation of literary actions. Our experiments show that different traits can predict happy endings in novels of varying but reasonable quality based on mood analysis. Although our approach is still relatively simple, we have shown that it can potentially lead to substantial insights for literary scholars. Future work could extend to improving our classification by taking into account the high variability of endings in novels, and also to further using our approach to thoroughly examine the characteristics of different collections of novels."}, {"heading": "Zehe, Albin / Becker, Martin / Hettinger, Lena / Hotho, Andreas / Reger, Isabella /", "text": "Jannidis, Fotis (2016): \"Prediction of Happy Endings in German Novels,\" in: Processes of the Workshop on Interactions between Data Mining and Natural Language Processing 2016."}], "references": [{"title": "Abstract Representations of Plot Structure", "author": ["Elsner", "Micha"], "venue": "in: \u200bLinguistic Issues in Language Technology", "citeRegEx": "Elsner and Micha\u200b,? \\Q2015\\E", "shortCiteRegEx": "Elsner and Micha\u200b", "year": 2015}, {"title": "Crowdsourcing a Word-Emotion Association Lexicon", "author": ["Mohammad", "Saif / Turney", "Peter"], "venue": "in: \u200bComputational Intelligence", "citeRegEx": "Mohammad et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Mohammad et al\\.", "year": 2016}, {"title": "Commodius vici of recirculation: the real problem with Syuzhet", "author": ["Schmidt", "Benjamin M"], "venue": "http://benschmidt.org/2015/04/03/commodius-vici-of-recirculation-the-real-problem-with-syuz het/\u200b [Access date", "citeRegEx": "Schmidt and M.\u200b,? \\Q2015\\E", "shortCiteRegEx": "Schmidt and M.\u200b", "year": 2015}, {"title": "Problems with the Syuzhet Package", "author": ["Swafford", "Annie"], "venue": null, "citeRegEx": "Swafford and Annie\u200b,? \\Q2015\\E", "shortCiteRegEx": "Swafford and Annie\u200b", "year": 2015}], "referenceMentions": [], "year": 0, "abstractText": "With regard to a computational representation of literary plot, this paper looks at the use of sentiment analysis for happy ending detection in German novels. Its focus lies on the investigation of previously proposed sentiment features in order to gain insight about the relevance of specific features on the one hand and the implications of their performance on the other hand. Therefore, we study various partitionings of novels, considering the highly variable concept of \"ending\". We also show that our approach, even though still rather simple, can potentially lead to substantial findings relevant to literary studies. Introduction Plot is fundamental for the structure of literary works. Methods for the computational representation of plot or special plot elements would therefore be a great achievement for digital literary studies. This paper looks at one such element: happy endings. We employ sentiment analysis for the detection of happy endings, but focus on a qualitative analysis of specific features and their performance in order to gain deeper insight into the automatic classification. In addition, we show how the applied method can be used for subsequent research questions, yielding interesting results with regard to publishing periods of the novels. Related Work One of the first works was on folkloristic tales, done by Mark Finlayson, who created an algorithm capable of detecting events and higher-level abstractions, such as villainy or reward (Finlayson 2012). Reiter et al., again on tales, identify events, their participants and order and use machine learning methods to find structural similarities across texts (Reiter 2013, Reiter et al. 2014). Recently, a significant amount of attention has been paid to sentiment analysis, when Matthew Jockers proposed emotional arousal as a new \u201cmethod for detecting plot\u201d (Jockers 2014). He described his idea to split novels into segments and use those to form plot trajectories (Jockers 2015). Despite general acceptance of the idea to employ sentiment analysis, his use of the Fourier Transformation to smooth the resulting plot curves was criticized (Swafford 2015, Schmidt 2015). Among other features, Micha Elsner (Elsner 2015) builds plot representations of romantic novels, again by using sentiment trajectories. He also links such trajectories with specific characters and looks at character co-occurrences. To evaluate his approach, he distinguishes real novels from artificially reordered surrogates with considerable success, showing that his methods indeed capture certain aspects of plot structure. In previous work, we used sentiment features to detect happy endings as a major plot element in German novels, reaching an F1-score of 73% (Zehe et al. 2016). Corpus and Resources Our dataset consists of 212 novels in German language mostly from the 19th century . Each 1 novel has been manually annotated as either having a happy ending (50%) or not (50%). The relevant information has been obtained from summaries of the Kindler Literary Lexikon Online and Wikipedia. If no summary was available, the corresponding parts of the novel 2 have been read by the annotators. Sentiment analysis requires a resource which lists sentiment values that human readers typically associate with certain words or phrases in a text. This paper relies on the NRC Sentiment Lexicon (Mohammad and Turney 2013), which is available in an automatically translated German version . A notable feature of this lexicon is that besides specifying binary 3 values (0 or 1) for negative and positive connotations (2 features) it also categorizes words into 8 basic emotions (anger, fear, disgust, surprise, joy, anticipation, trust and sadness), see Table 1 for an example. We add another value (the polarity) by subtracting the negative from the positive value (e.g. a word with a positive value of 0 and a negative value of 1 has a polarity value of -1). The polarity serves as an overall sentiment score, which results in 11 features. Table 1 \u200b : Example entries from the NRC Sentiment Lexicon Word/Dimension verabscheuen (to detest) bewundernswert (admirable) Zufall (coincidence) Positive 0 1 0 Negative 1 0 0 Polarity -1 1 0 Anger 1 0 0 Anticipation 0 0 0 Disgust 1 0 0 Fear 1 0 0 Joy 0 1 0 Sadness 0 0 0 Surprise 0 0 1 Trust 0 1 0 Experiments The goal of this paper is to investigate features that have been used for the detection of happy endings in novels in order to gain insight about the relevance of specific feature sets on the one hand and the implications of their performance on the other hand. To that end, we adopt the features and methods presented in Zehe et al. (2016). The parameters of the linear SVM and the partitioning into 75 segments are also adopted from this paper. 1 Source: https://textgrid.de/digitale-bibliothek 2 www.kll-online.de 3 http://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm Features. Since reliable chapter annotations were not available, each novel has been split into 75 equally sized blocks, called \u200bsegments \u200b . For each lemmatized word, we look up the 11 sentiment values (including polarity, see above). Then, for each segment, we calculate the respective averages, resulting in 11 scores per segment. We group those 11 scores into one feature set. Qualitative Feature Analysis \u200b . As our corpus consists of an equal number of novels with and without happy ending, the random baseline as well the majority vote baseline amount to 50% classification accuracy. Since we assumed that the relevant information for identifying happy endings can be found at the end of a novel, we first used the sentiment scores of the final segment ( ) as the fd,n only feature set, reaching an F1-score of 67%. Following the intuition that not only the last segment by itself, but also its relation to the rest of the novel are meaningful for the classification, we introduced the notion of \u200bsections \u200b : the last segment of a novel constitutes the \u200bfinal section \u200b , whereas the remaining segments belong to the \u200bmain section \u200b . Averages were also calculated for the sections by taking the mean of each feature over all segments in the section. To further emphasize the relation between these sections, we added the differences between the sentiment scores of the final section and the average sentiment scores over all segments in the main section. However, this change did not influence the results. This led us to believe that our notion of an \u201cending\u201d was not accurate enough, as the number of segments for each novel and therefore the boundaries of the final segment have been chosen rather arbitrarily. To approach this issue, we varied the partitioning into main and final section so that the final section can contain more than just the last segment. Figure 1\u200b: \u200bClassification F1-score for different partitionings into main and final section. The dashed line represents a random baseline, the dotted line shows where the maximum F1-score is reached. Figure 1 shows that classification accuracy improves when at least 75% of the segments are in the main section and reaches a peak at about 95% (this means 4 segments in the final section and 71 segments in the main section, for a total of 75 segments). With this partitioning strategy, we improve the F1-score to 68% using only the feature set for the final section ( ) and reach an F1-score of 69% when also including the differences to the fd, f inal average sentiment scores of the main section ( ). fd, main\u2212f inal Since adding the relation between the main section and the final section improved our results in the previous setting, we tried to model the development of the sentiments towards the end of the novel in a more profound way. For example, a catastrophic event might happen shortly before the end of a novel and finally be resolved in a happy ending. To capture this intuition, we introduced one more section, namely the \u200blate-main section, which focuses on the segments right \u200bbefore the final section, and used the difference between the feature sets for the late-main and the final section as an additional feature set ( ). fd, late\u2212f inal Using those three feature sets, the classification of happy endings reaches an F1-score of 70% and increases to 73% when including the feature set for the final segment. Table 2 \u200b : Classification F1-score for the different feature sets", "creator": null}}}