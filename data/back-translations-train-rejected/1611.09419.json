{"id": "1611.09419", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Nov-2016", "title": "Safety-Aware Robot Damage Recovery Using Constrained Bayesian Optimization and Simulated Priors", "abstract": "The recently introduced Intelligent Trial-and-Error (IT&amp;E) algorithm showed that robots can adapt to damage in a matter of a few trials. The success of this algorithm relies on two components: prior knowledge acquired through simulation with an intact robot, and Bayesian optimization (BO) that operates on-line, on the damaged robot. While IT&amp;E leads to fast damage recovery, it does not incorporate any safety constraints that prevent the robot from attempting harmful behaviors. In this work, we address this limitation by replacing the BO component with a constrained BO procedure. We evaluate our approach on a simulated damaged humanoid robot that needs to crawl as fast as possible, while performing as few unsafe trials as possible. We compare our new \"safety-aware IT&amp;E\" algorithm to IT&amp;E and a multi-objective version of IT&amp;E in which the safety constraints are dealt as separate objectives. Our results show that our algorithm outperforms the other approaches, both in crawling speed within the safe regions and number of unsafe trials.", "histories": [["v1", "Mon, 28 Nov 2016 22:56:24 GMT  (1438kb,D)", "https://arxiv.org/abs/1611.09419v1", "Accepted at the BayesOpt 2016 NIPS workshop, 5 pages, 2 figures, 1 algorithm"], ["v2", "Wed, 30 Nov 2016 23:28:57 GMT  (1429kb,D)", "http://arxiv.org/abs/1611.09419v2", "Accepted at the BayesOpt 2016 NIPS workshop, 5 pages, 2 figures, 1 algorithm"], ["v3", "Fri, 2 Dec 2016 09:33:07 GMT  (1429kb,D)", "http://arxiv.org/abs/1611.09419v3", "Accepted at the BayesOpt 2016 NIPS workshop, 5 pages, 2 figures, 1 algorithm"]], "COMMENTS": "Accepted at the BayesOpt 2016 NIPS workshop, 5 pages, 2 figures, 1 algorithm", "reviews": [], "SUBJECTS": "cs.RO cs.LG", "authors": ["vaios papaspyros", "konstantinos chatzilygeroudis", "vassilis vassiliades", "jean-baptiste mouret"], "accepted": false, "id": "1611.09419"}, "pdf": {"name": "1611.09419.pdf", "metadata": {"source": "CRF", "title": "Safety-Aware Robot Damage Recovery Using Constrained Bayesian Optimization and Simulated Priors", "authors": ["Vaios Papaspyros", "Konstantinos Chatzilygeroudis", "Vassilis Vassiliades", "Jean-Baptiste Mouret"], "emails": ["jean-baptiste.mouret@inria.fr"], "sections": [{"heading": "1 Introduction", "text": "Current robots would greatly benefit from being able to continue their mission if damaged, as the recent DARPA Robotics Challenge [1, 4] shows. If damaged, most robots will attempt to diagnose the fault and look for an emergency plan; but they could also exploit a reinforcement learning algorithm to find compensatory behaviors without \"understanding\" the damage. If they follow this second approach, robots will need learning algorithms that are highly data-efficient [5] because too many studies would waste valuable time to accomplish the mission. One of the most promising approaches to data-efficient robot damage is the recently introduced intelligent Trial-and-Error (IT & E) algorithm, which combines two ideas: (1) a Bayesian optimization algorithm (BO) that optimizes a reward function because it is a generic, data-efficient search algorithm algorithm function."}, {"heading": "2 Safety-aware Intelligent Trial & Error Algorithm", "text": "The first step of IT & E is to create a low-dimensional behavior map with a simulation of the intact robot. (This step is accomplished using an evolutionary algorithm called MAP-Elites [14], which instead of a search for a single, best solution, such as standard optimization algorithms, is achieved by searching for the most powerful individual for each point in a custom space. (This custom space is often referred to as a behavioral space, because the dimensions of variation (behavioral descriptors) usually measure behavioral traits. For example, by defining a dimension for the amount of time each leg spends on the ground, MAP-Elites produces a wide variety of walking movements for a hexapod robot [7]. To search for the best behavior on the damaged robot, IT & E ages the classic BO scheme [7] by (1) searching for behavior on the map, rather than for the best political parameters (2)."}, {"heading": "3 Crawling humanoid robot experiments", "text": "To evaluate our algorithms, we use a simulated iCub robot [13, 17], which performs a crawling task."}, {"heading": "4 Conclusion", "text": "Our experiments show that the Vanilla IT & E algorithm finds powerful behaviors in a few experiments, but most of the behaviors tested, including the best, last ones, are unsafe for the robot. By contrast, as the multi-objective approach looks for a number of Pareto-optimal targets, it can find safe and powerful behaviors; however, this approach still tests many unsafe behaviors during the learning phase. In contrast, the sIT & E algorithm finds gaits that are both safe and powerful with only a handful of unsafe experiments. thanks to this property, we are confident that sIT & E will do less harm to the real iCub than IT & E or BO. In future work, we will compare our results with approaches that are based on security regions [2], which are safer but can prove to be too conservative in terms of performance. Overall, this work shows that security is a critical component for any robot learning algorithm and that limited data base can provide both a good BO to develop as well as efficient algorithms."}, {"heading": "Acknowledgments", "text": "This work was funded by the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme (funding agreement 637972, \"ResiBots\" project)."}], "references": [{"title": "What happened at the DARPA robotics challenge, and why? submitted to the DRC", "author": ["Christopher G. Atkeson"], "venue": "Finals Special Issue of the Journal of Field Robotics,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2016}, {"title": "Bayesian optimization with safety constraints: safe and automatic parameter tuning in robotics", "author": ["Felix Berkenkamp", "Andreas Krause", "Angela P Schoellig"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2016}, {"title": "An experimental comparison of Bayesian optimization for bipedal locomotion", "author": ["Roberto Calandra", "Andr\u00e9 Seyfarth", "Jan Peters", "Marc Peter Deisenroth"], "venue": "In 2014 IEEE International Conference on Robotics and Automation (ICRA),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2014}, {"title": "How UGVs physically fail in the field", "author": ["Jennifer Carlson", "Robin R. Murphy"], "venue": "IEEE Transactions on Robotics,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2005}, {"title": "Reset-free Trial-and-Error Learning for Data-Efficient Robot Damage Recovery", "author": ["Konstantinos Chatzilygeroudis", "Vassilis Vassiliades", "Jean-Baptiste Mouret"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2016}, {"title": "Limbo: A fast and flexible library for bayesian optimization", "author": ["Antoine Cully", "Konstantinos Chatzilygeroudis", "Federico Allocati", "Jean-Baptiste Mouret"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2016}, {"title": "Robots that can adapt like animals", "author": ["Antoine Cully", "Jeff Clune", "Danesh Tarapore", "Jean-Baptiste Mouret"], "venue": "Nature, 521(7553):503\u2013507,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2015}, {"title": "Multi-objective optimization. In Search methodologies, pages 403\u2013449", "author": ["Kalyanmoy Deb"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}, {"title": "Bayesian optimization with inequality constraints", "author": ["Jacob R Gardner", "Matt J Kusner", "Zhixiang Eddie Xu", "Kilian Q Weinberger", "John Cunningham"], "venue": "In ICML,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "Faster exact algorithms for computing expected hypervolume improvement", "author": ["Iris Hupkens", "Andr\u00e9 Deutz", "Kaifeng Yang", "Michael Emmerich"], "venue": "In International Conference on Evolutionary Multi-Criterion Optimization,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2015}, {"title": "Noise and the reality gap: The use of simulation in evolutionary robotics", "author": ["Nick Jakobi", "Phil Husbands", "Inman Harvey"], "venue": "In European Conference on Artificial Life,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1995}, {"title": "The transferability approach: Crossing the reality gap in evolutionary robotics", "author": ["Sylvain Koos", "Jean-Baptiste Mouret", "St\u00e9phane Doncieux"], "venue": "IEEE Transactions on Evolutionary Computation,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "The iCub humanoid robot: an open platform for research in embodied cognition", "author": ["Giorgio Metta", "Giulio Sandini", "David Vernon", "Lorenzo Natale", "Francesco Nori"], "venue": "In Proceedings of the 8th workshop on performance metrics for intelligent systems,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2008}, {"title": "Illuminating search spaces by mapping elites", "author": ["Jean-Baptiste Mouret", "Jeff Clune"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2015}, {"title": "Multiple chaotic central pattern generators with learning for legged locomotion and malfunction compensation", "author": ["Guanjiao Ren", "Weihai Chen", "Sakyasingha Dasgupta", "Christoph Kolodziejski", "Florentin W\u00f6rg\u00f6tter", "Poramate Manoonpong"], "venue": "Information Sciences,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2015}, {"title": "Taking the human out of the loop: A review of Bayesian optimization", "author": ["Bobak Shahriari", "Kevin Swersky", "Ziyu Wang", "Ryan P Adams", "Nando de Freitas"], "venue": "Proceedings of the IEEE,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2016}, {"title": "iCub: the design and realization of an open humanoid platform for cognitive and neuroscience research", "author": ["Nikolaos G. Tsagarakis", "Giorgio Metta", "Giulio Sandini", "David Vernon", "Ricardo Beira", "Francesco Becchi", "Ludovic Righetti", "Jose Santos-Victor", "Auke Jan Ijspeert", "Maria Chiara Carrozza", "Darwin G. Caldwell"], "venue": "Advanced Robotics,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2007}, {"title": "Expected hypervolume improvement algorithm for PID controller tuning and the multiobjective dynamical control of a biogas plant", "author": ["Kaifeng Yang", "Daniel Gaida", "Thomas B\u00e4ck", "Michael Emmerich"], "venue": "IEEE Congress on Evolutionary Computation (CEC),", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "Current robots would greatly benefit from being capable of carrying on with their mission when they are damaged, as illustrated by the recent DARPA Robotics Challenge [1, 4].", "startOffset": 167, "endOffset": 173}, {"referenceID": 3, "context": "Current robots would greatly benefit from being capable of carrying on with their mission when they are damaged, as illustrated by the recent DARPA Robotics Challenge [1, 4].", "startOffset": 167, "endOffset": 173}, {"referenceID": 6, "context": "When damaged, most robots attempt to diagnose the fault and search for a contingency plan; but they could also exploit a reinforcement learning algorithm so that they can find compensatory behaviors without having to \"understand\" the damage [7, 15].", "startOffset": 241, "endOffset": 248}, {"referenceID": 14, "context": "When damaged, most robots attempt to diagnose the fault and search for a contingency plan; but they could also exploit a reinforcement learning algorithm so that they can find compensatory behaviors without having to \"understand\" the damage [7, 15].", "startOffset": 241, "endOffset": 248}, {"referenceID": 4, "context": "If they follow this second approach, robots need learning algorithms that are highly data-efficient [5] because too many trials would waste precious time to achieve the mission.", "startOffset": 100, "endOffset": 103}, {"referenceID": 6, "context": "One of the most promising approaches for data-efficient robot damage recovery is the recently introduced Intelligent Trial-and-Error algorithm (IT&E) [7].", "startOffset": 150, "endOffset": 153}, {"referenceID": 15, "context": "It combines two ideas: (1) a Bayesian optimization (BO) algorithm [16] that optimizes a reward function, because it is a generic, dataefficient policy search algorithm [3], and (2) a behavior-performance map generated before the mission with a simulation of the intact robot, which acts both as a prior for the Bayesian optimization algorithm and as a dimension reduction algorithm.", "startOffset": 66, "endOffset": 70}, {"referenceID": 2, "context": "It combines two ideas: (1) a Bayesian optimization (BO) algorithm [16] that optimizes a reward function, because it is a generic, dataefficient policy search algorithm [3], and (2) a behavior-performance map generated before the mission with a simulation of the intact robot, which acts both as a prior for the Bayesian optimization algorithm and as a dimension reduction algorithm.", "startOffset": 168, "endOffset": 171}, {"referenceID": 6, "context": "This combination allowed a damaged 6-legged robot to find a new gait in about a dozen of trials (less than 2 minutes), and a robotic arm to overcome several blocked joints in a few minutes [7].", "startOffset": 189, "endOffset": 192}, {"referenceID": 12, "context": "This issue is especially concerning for expensive prototypes like the iCub robot [13, 17]: these robots are too expensive (around 250k euros for the iCub) and too fragile to try risky behaviors.", "startOffset": 81, "endOffset": 89}, {"referenceID": 16, "context": "This issue is especially concerning for expensive prototypes like the iCub robot [13, 17]: these robots are too expensive (around 250k euros for the iCub) and too fragile to try risky behaviors.", "startOffset": 81, "endOffset": 89}, {"referenceID": 1, "context": "While recent methods, like SafeOPT [2], tackle this issue successfully, they require an initial safe set of parameters, that is hard to estimate in an unknown damage setting.", "startOffset": 35, "endOffset": 38}, {"referenceID": 6, "context": "In this paper, we extend the IT&E algorithm [7] by adding safety constraints [9] and automatically computing priors over the safety of controller parameters, so that the probability of breaking the robot during the learning process is as low as possible.", "startOffset": 44, "endOffset": 47}, {"referenceID": 8, "context": "In this paper, we extend the IT&E algorithm [7] by adding safety constraints [9] and automatically computing priors over the safety of controller parameters, so that the probability of breaking the robot during the learning process is as low as possible.", "startOffset": 77, "endOffset": 80}, {"referenceID": 13, "context": "This step is achieved with an evolutionary algorithm called MAP-Elites [14], which, instead of searching for a single, best solution, like standard optimization algorithms, searches for the highest-performing individual for each point in a user-defined space.", "startOffset": 71, "endOffset": 75}, {"referenceID": 6, "context": "For example, by defining one dimension for each leg\u2019s fraction of time spent on the ground, MAP-Elites produces a wide variety of walking gaits for a hexapod robot [7].", "startOffset": 164, "endOffset": 167}, {"referenceID": 6, "context": "To search for the best behavior on the damaged robot, IT&E alters the classical BO scheme [7] by (1) searching a behavior in the map, instead of searching the best policy parameters, and (2) modeling the difference between the performance predicted by the map (M(\u00b7)) and the actual performance, instead of directly modeling the performance function.", "startOffset": 90, "endOffset": 93}, {"referenceID": 6, "context": "This approach leads to short adaptation times in several experiments with damaged robots [7], but it has a serious limitation that prevents it from being used with expensive robots: it lacks safety constraints, that is, nothing prevents the robot from trying dangerous behaviors.", "startOffset": 89, "endOffset": 92}, {"referenceID": 10, "context": "To make matters worse, a damage recovery algorithm would have to compensate for the reality gap [11, 12] as well3.", "startOffset": 96, "endOffset": 104}, {"referenceID": 11, "context": "To make matters worse, a damage recovery algorithm would have to compensate for the reality gap [11, 12] as well3.", "startOffset": 96, "endOffset": 104}, {"referenceID": 8, "context": "sIT&E uses a constrained BO procedure [9] in which each user-defined safety constraint, ci(x), is modeled as a separate GP.", "startOffset": 38, "endOffset": 41}, {"referenceID": 8, "context": "The next sample is selected by optimizing the Expected Constrained Improvement (ECI) acquisition function [9]:", "startOffset": 106, "endOffset": 109}, {"referenceID": 8, "context": "where x\u0302 is the candidate point, ci(x\u0302), i \u2208 {1, \u00b7 \u00b7 \u00b7 , n} are the n constraint functions and EI(x\u0302) is the standard expected improvement [9].", "startOffset": 139, "endOffset": 142}, {"referenceID": 12, "context": "To evaluate our algorithm, we use a simulated iCub robot [13, 17] performing a crawling task.", "startOffset": 57, "endOffset": 65}, {"referenceID": 16, "context": "To evaluate our algorithm, we use a simulated iCub robot [13, 17] performing a crawling task.", "startOffset": 57, "endOffset": 65}, {"referenceID": 7, "context": "We compare 3 algorithms in terms of the best safe performance observed and unsafe trials attempted: (1) IT&E maximizing crawling speed; (2) a multi-objective [8] IT&E algorithm (MO-IT&E; based on the Expected Hypervolume Improvement [10, 18]), that maximizes the crawling speed and minimizes the sum of contact point forces, therefore, building a Pareto front from which the safest behavior can be chosen; and (3) sIT&E maximizing crawling speed within the safe region as described above.", "startOffset": 158, "endOffset": 161}, {"referenceID": 9, "context": "We compare 3 algorithms in terms of the best safe performance observed and unsafe trials attempted: (1) IT&E maximizing crawling speed; (2) a multi-objective [8] IT&E algorithm (MO-IT&E; based on the Expected Hypervolume Improvement [10, 18]), that maximizes the crawling speed and minimizes the sum of contact point forces, therefore, building a Pareto front from which the safest behavior can be chosen; and (3) sIT&E maximizing crawling speed within the safe region as described above.", "startOffset": 233, "endOffset": 241}, {"referenceID": 17, "context": "We compare 3 algorithms in terms of the best safe performance observed and unsafe trials attempted: (1) IT&E maximizing crawling speed; (2) a multi-objective [8] IT&E algorithm (MO-IT&E; based on the Expected Hypervolume Improvement [10, 18]), that maximizes the crawling speed and minimizes the sum of contact point forces, therefore, building a Pareto front from which the safest behavior can be chosen; and (3) sIT&E maximizing crawling speed within the safe region as described above.", "startOffset": 233, "endOffset": 241}, {"referenceID": 5, "context": "All experiments were conducted using the limbo framework [6].", "startOffset": 57, "endOffset": 60}, {"referenceID": 1, "context": "In future work, we will compare our results to approaches based on safety regions [2], which might be safer, but may prove too conservative performance-wise.", "startOffset": 82, "endOffset": 85}], "year": 2016, "abstractText": "The recently introduced Intelligent Trial-and-Error (IT&E) algorithm showed that robots can adapt to damage in a matter of a few trials. The success of this algorithm relies on two components: prior knowledge acquired through simulation with an intact robot, and Bayesian optimization (BO) that operates on-line, on the damaged robot. While IT&E leads to fast damage recovery, it does not incorporate any safety constraints that prevent the robot from attempting harmful behaviors. In this work, we address this limitation by replacing the BO component with a constrained BO procedure. We evaluate our approach on a simulated damaged humanoid robot that needs to crawl as fast as possible, while performing as few unsafe trials as possible. We compare our new \u201csafety-aware IT&E\u201d algorithm to IT&E and a multi-objective version of IT&E in which the safety constraints are dealt as separate objectives. Our results show that our algorithm outperforms the other approaches, both in crawling speed within the safe regions and number of unsafe trials.", "creator": "LaTeX with hyperref package"}}}