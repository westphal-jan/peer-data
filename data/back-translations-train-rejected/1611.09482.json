{"id": "1611.09482", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Nov-2016", "title": "Fast Wavenet Generation Algorithm", "abstract": "This paper presents an efficient implementation of the Wavenet generation process called Fast Wavenet. Compared to a naive implementation that has complexity O(2^L) (L denotes the number of layers in the network), our proposed approach removes redundant convolution operations by caching previous calculations, thereby reducing the complexity to O(L) time. Timing experiments show significant advantages of our fast implementation over a naive one. While this method is presented for Wavenet, the same scheme can be applied anytime one wants to perform autoregressive generation or online prediction using a model with dilated convolution layers. The code for our method is publicly available.", "histories": [["v1", "Tue, 29 Nov 2016 04:16:44 GMT  (249kb,D)", "http://arxiv.org/abs/1611.09482v1", "Technical Report"]], "COMMENTS": "Technical Report", "reviews": [], "SUBJECTS": "cs.SD cs.DS cs.LG", "authors": ["tom le paine", "pooya khorrami", "shiyu chang", "yang zhang", "prajit ramachandran", "mark a hasegawa-johnson", "thomas s huang"], "accepted": false, "id": "1611.09482"}, "pdf": {"name": "1611.09482.pdf", "metadata": {"source": "CRF", "title": "FAST WAVENET GENERATION ALGORITHM", "authors": ["Tom Le Paine", "Pooya Khorrami", "Shiyu Chang", "Yang Zhang", "Prajit Ramachandran", "Mark A. Hasegawa-Johnson", "Thomas S. Huang"], "emails": ["t-huang1}@illinois.edu", "shiyu.chang@ibm.com"], "sections": [{"heading": "1 INTRODUCTION", "text": "Wavenet (Oord et al., 2016), a profound generative model of raw audio waveforms, has attracted a tremendous amount of attention since its initial release. It changed existing paradigms in audio generation by directly modelling the raw waveform of audio signals, resulting in state-of-the-art performance in text-to-speech and other general audio generation settings, including music. Wavenet models the conditional probability via a stack of dilated causal revolutionary layers for the next audio generation, since the audio samples are known for all timestamps, the conditional predictions can of course be made in parallel. However, each time audio is generated using a trained model, the predictions are sequential. Each time an output evaluation is predicted, the prediction is then fed back to the input of the network to show the next sample value. In a toy node image, we use a single node in the network."}, {"heading": "2 FAST WAVENET", "text": "The most important finding about Fast Wavenet is this: Given a certain number of nodes in the graph, we have sufficient information to calculate the current output. We refer to these nodes as the recurring states in relation to recurring neural networks (RNNs) (Graves, 2013). An efficient algorithm can be implemented by caching these recurring states, rather than recalculating them each time a new sample is created."}, {"heading": "2.1 A GRAPHICAL ILLUSTRATION", "text": "The graph shown in Figure 2 illustrates the idea of the recurring states. This graph, like the one shown in Figure 1, shows how a single output sample is generated, except now in relation to the pre-calculated (\"recurring\") states. In fact, on closer inspection, the reader will find that the graph shown in Figure 2 looks exactly like a single step of a multi-layer RNN. For a certain time t, the incoming input sample (h0e) can be considered the \"embedding\" and receives the subscript \"e.\" Likewise, the recurring states receive the subscript \"r.\" Since these recurring states have already been calculated, we simply need to cache them using a queue. From Figure 2, we see through the use of cached values that the generation process now has complexity O (L). However, it is worth noting that due to the dilatated outputs, we are not used as the first one of the previous outputs on each level, the first one of the recurring states is determined."}, {"heading": "2.2 ALGORITHM", "text": "Our algorithm consists of two main components: \u2022 Generation Model \u2022 Convolution QueuesThey are seen visually in Figure 4. As we have already described, the generation model resembles and behaves like a single step of a multi-layered RNN. Specifically, it takes the current input along with a list of recursive states and generates the current output along with the new recursive states. The convolution queues store the recursive states and are updated when the new recursive states are computed. To generate audio, we first initialize the generation model using the weights of a trained Wavenet model. Next, we initialize the convolution queues by setting all their recursive states to zero. Then, when generating each output sample, we perform the following steps: \u2022 Pop Phase \u2022 Push PhaseDuring the pop phase, the first recursive state from each convolution queue is clipped and then converted to the corresponding position of the current model state."}, {"heading": "3 COMPLEXITY ANALYSIS", "text": "In this section we will show the advantage of our Fast Wavenet algorithm over a na\u00efve implementation of the generation process, both theoretically and experimentally."}, {"heading": "3.1 THEORETICAL ANALYSIS", "text": "In terms of computational complexity, the simplified implementation requires O (L), while a prior implementation of the algorithm in Figure 1 requires O (2L). In terms of spatial complexity, the simplified implementation needs to maintain L queues, which altogether take up O (2L) additional space. On the other hand, the na\u00efve implementation needs to store hidden intermediate results. Assuming the intermediate results of the lower hidden layer, these are deleted after those of the higher layer have been calculated, the additional space that the na\u00efve implementation needs is also O (2L). In short, the proposed implementation dramatically saves computational complexity without compromising the spatial complexity. It is also worth noting that the proposed implementation scales well to more general architectures. For an architecture with filter width w and conversion of the longest layer, assuming the proposed implementation is smaller (L) and the proposed complexity (L is very narrow)."}, {"heading": "3.2 EXPERIMENTAL ANALYSIS", "text": "We are now comparing the speed of our proposed implementation with the na\u00efve implementation. In Figure 7, we have generated samples from a model that contains 2 blocks of L-layers each, using the previous implementation and ours. On average, the results will be over 100 repetitions. If L is small, the na\u00efve implementation performs better than expected due to the parallelization of convolution operations by the GPU. However, when L is large, our efficient implementation begins to significantly outperform the na\u00efve method."}, {"heading": "4 CONCLUSIONS", "text": "In this paper, we introduced Fast Wavenet, an implementation of the Wavenet generation process that significantly reduces computational complexity without sacrificing spatial complexity. The same fast generation scheme can be applied at any time if you want to perform automatic regressive generation or online prediction based on a model with extended folding layers, and the authors hope that readers will find the algorithm useful for their future research."}, {"heading": "ACKNOWLEDGMENTS", "text": "The authors would like to thank Wei Han and Yuchen Fan for their insightful discussions."}], "references": [{"title": "Generating sequences with recurrent neural networks", "author": ["Alex Graves"], "venue": "arXiv preprint arXiv:1308.0850,", "citeRegEx": "Graves.,? \\Q2013\\E", "shortCiteRegEx": "Graves.", "year": 2013}, {"title": "Wavenet: A generative model for raw audio", "author": ["Aaron van den Oord", "Sander Dieleman", "Heiga Zen", "Karen Simonyan", "Oriol Vinyals", "Alex Graves", "Nal Kalchbrenner", "Andrew Senior", "Koray Kavukcuoglu"], "venue": "arXiv preprint arXiv:1609.03499,", "citeRegEx": "Oord et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Oord et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 1, "context": "Wavenet (Oord et al., 2016), a deep generative model of raw audio waveforms, has drawn a tremendous amount of attention since it was first released.", "startOffset": 8, "endOffset": 27}, {"referenceID": 0, "context": "We call these nodes the recurrent states in reference to recurrent neural networks (RNNs) (Graves, 2013).", "startOffset": 90, "endOffset": 104}], "year": 2016, "abstractText": "This paper presents an efficient implementation of the Wavenet generation process called Fast Wavenet. Compared to a na\u0131\u0308ve implementation that has complexity O(2) (L denotes the number of layers in the network), our proposed approach removes redundant convolution operations by caching previous calculations, thereby reducing the complexity to O(L) time. Timing experiments show significant advantages of our fast implementation over a na\u0131\u0308ve one. While this method is presented for Wavenet, the same scheme can be applied anytime one wants to perform autoregressive generation or online prediction using a model with dilated convolution layers. The code for our method is publicly available.", "creator": "LaTeX with hyperref package"}}}