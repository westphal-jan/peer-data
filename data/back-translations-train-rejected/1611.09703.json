{"id": "1611.09703", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Nov-2016", "title": "Semantic Parsing of Mathematics by Context-based Learning from Aligned Corpora and Theorem Proving", "abstract": "We study methods for automated parsing of informal mathematical expressions into formal ones, a main prerequisite for deep computer understanding of informal mathematical texts. We propose a context-based parsing approach that combines efficient statistical learning of deep parse trees with their semantic pruning by type checking and large-theory automated theorem proving. We show that the methods very significantly improve on previous results in parsing theorems from the Flyspeck corpus.", "histories": [["v1", "Tue, 29 Nov 2016 16:20:24 GMT  (97kb,D)", "http://arxiv.org/abs/1611.09703v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.AI", "authors": ["cezary kaliszyk", "josef urban", "ji\\v{r}\\'i vysko\\v{c}il"], "accepted": false, "id": "1611.09703"}, "pdf": {"name": "1611.09703.pdf", "metadata": {"source": "META", "title": "Semantic Parsing of Mathematics by Context-based Learning from Aligned Corpora and Theorem Proving", "authors": ["Cezary Kaliszyk", "Josef Urban", "Ji\u0159\u0131\u0301 Vysko\u010dil"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "Computer-comprehensible (formal) mathematics (Harrison, Urban, and Wiedijk 2014) is still far from entering the mathematical mainstream. Despite recent impressive formalizations such as the formal proof of the Kepler conjecture (Flyspeck) (Hales et al. 2015), FeitThompson (Gonthier et al. 2013), seL4 (Klein et al. 2010), CompCert (Leroy 2009), and CCL (Bancerek and Rudnicki 2002), the formalization of evidence is still largely unattractive to mathematicians. While research on artificial intelligence and strong automation of major theories has gained momentum over the past decade (Blanchette et al. 2016), little progress has been made in automating the understanding of informal LATEX-written and ambiguous mathematical writings."}, {"heading": "Contributions", "text": "In this paper, we will first present the informal to formal setting (paragraph 2), summarize the probabilistic context-free grammar (PCFG) of the approach of (Kaliszyk, Urban and Vyskocil 2015b) (paragraph 3) and expand this approach with fast context analysis mechanisms. \u2022 Limitations of the context-free approach. We will demonstrate with a minimal example that the context-free setting is not strong enough to ultimately learn the correct parsing of relatively simple informal mathematical formulas (paragraph 4). \u2022 Efficient context inclusion via discrimination trees. We will propose modifications of the CYK algorithm and implement them efficiently, taking into account larger sub-trees (context) and their probabilities (paragraph 5). This modification is motivated by an analogy with large-theoretical argumentation systems and their efficient implementation is based on a novel use of fast-probable parameters of data enhancement (the strong data structures)."}, {"heading": "2 Informalized Flyspeck and PCFG", "text": "The ultimate goal of informal to formal translation is to automatically learn to parse on informal LATEX formulas aligned with their formal counterparts, as Hales has done for his informal and formal flyspeck texts, for example (Hales 2012; Tankink et al. 2013). Instead of starting with LATEX, where only hundreds of coordinated examples of flyspeck are currently available, we are using the first large informal / formal corpus introduced in (Kaliszyk, Urban, andar Xiv: 161 1.09 703v 1 [cs.C L] 29 November 201 6Vyskocil 2015b) based on informalized (or ambiguous) formal statements from the HOL Light theorems in flyspeck, providing approximately 22,000 informal / formal pairs of flyspeck theorems."}, {"heading": "Informalized Flyspeck", "text": "The following transformations are applied to the HOL parse trees in (Kaliszyk, Urban, and Vyskocil 2015b) to get the aligned corpus: \u2022 Use the 72 overloaded instances defined in HOL Light / Flyspeck, such as (\"+,\" \"vector _ add\"), so the constant vector _ add would be replaced by + in the resulting sentence. \u2022 Get all the \"prefixed\" symbols from the list of 1000 most common symbols by looking for: real _, int _, vector _, nadd _, hreal _, complex _ and making them ambiguous by the prefix symbols from the list of 1000 most frequent symbols by searching for: real _, treal _, hreal _, matrix _ and make them ambigual the prefix."}, {"heading": "Probabilistic Context Free Grammars", "text": "With a large corpus of corresponding informal / formal formulas, how can we train an AI system to transform the next informal formula into a formal one? The informal-formal domain is different from the natural-language domains, where millions of examples of paired sentences (e.g. English-German) for machine translation are available. Natural languages also have many more words (concepts) than in mathematics, and sentences usually lack the recursive structure commonly found in mathematics. Given that there are currently only thousands of informal / formal examples, purely statistical alignment methods based on n-grams seem inadequate. Instead, the methods must learn how to compose larger parcels of parcels from smaller ones based on the limited number of examples. A well-known approach that ensures such compositionality is the use of CFG (Context Free Grammar) parsers."}, {"heading": "3 PCFG for the Informal-To-Formal Task", "text": "The simplest PCFG-based approach would be the direct use of native HOL Light parse trees (Fig. 2) to extract the PCFG. However, terms and types are only commented with a few nonterminals such as Comb (Application), Abs (Abstraction), Const (Constant of Higher Order), Var (Variable), Tyapp (Type Application) and Tyvar (Type Variable). This would lead to many possible parses in the context-free environment, as the learned rules are very universal, e.g.:"}, {"heading": "Comb -> Const Var. Comb -> Const Const. Comb -> Comb Comb.", "text": "The type information does not help to restrict the applications, and the last rule allows to give an arbitrary application order to a set of constants, resulting in an uncontrolled explosion."}, {"heading": "HOL Types as Nonterminals", "text": "The approach in (Kaliszyk, Urban, and Vyskocil 2015b) is first to rearrange and simplify the HOL Light parse trees to propagate the type of information in appropriate locations, giving the context-free rules a chance to provide meaningful pruning of information, which in turn makes the parse tree of REAL _ NEGNEG in (see also Fig. 1,2).Instead of directly very general rules like Comb - > Const Abs, each type is first compressed into an opaque nonterminal, which makes the parse tree of REAL _ NEGNEG in (see also Fig. 3): (Type bool). \""}, {"heading": "Semantic Concepts as Nonterminals", "text": "The last part of the original setting includes ambiguous symbols such as \"\" -- \"in its unique semantic / formal concept of nonterminals. In this case, $# real _ neg would be wrapped around\" \"--\" in the training tree if \"\" -- \"is used as a subtraction to reals. While the type designation is often sufficient for disambiguity, such explicit disambiguity of nonterminals is more precise and enables easier extraction of HOL semantics from the constructed parse trees. The actual tree of REAL _ NEGNEG used for grammar training is as follows (see also Fig. 4): (\" (Type bool) \"! (\" (Type (fun real bool)) \"(Abs (\" (Type real) \"(Var A0)) (Var A0) ($) (real)) (Apereal)\" () ($# neg)"}, {"heading": "Modified CYK Parsing and Its Initial Performance", "text": "The semantic checks are performed to require the compatibility of the types of free variables in subtrees analyzed, and the most likely parse trees are then typed by HOL Light. This is followed by evidence and refutation attempts by the HOL (y) Hammer system (Kaliszyk and Urban 2014) using all the semantic knowledge available in the Flyspeck library (about 22,000 theorems).The first large-scale disambiguation experiment, conducted with \"ambiguous\" flyspeck in (Kaliszyk, Urban and Vyskocil 2015b), showed that about 40% of the ambiguous sets had their correct parses among the top 20 parse trees produced by the trained parser. This is encouraging, but certainly invites further research to improve statistical / setic parse methods."}, {"heading": "4 Limits of the Context-Free Grammars", "text": "This is most obvious when using only the low term constructors as non-terminals, but it is often also apparent in the more advanced environments described above. In some cases, no matter how good the training data is, there is no way to set the probabilities of the parsing rules so that the required parse tree has the highest probability. We show this with the following simple examples. Example: Consider the following term t: 1 * x + 2 * x, with the following simplified parse tree T0 (t) (see also Fig. 5)."}, {"heading": "5 Using Probabilities of Deeper Subtrees", "text": "In fact, it is the case that most of them are able to stick to the rules that they have given themselves. (...) Most of them are able to stick to the rules. (...) Most of them are not able to stick to the rules. (...) Most of them are not able to stick to the rules. (...) Most of them are not able to stick to the rules. (...) Most of them are not able to stick to the rules. (...) Most of them are not able to think for themselves. (...) Most of them are not able to stick to the rules. (...) Most of them are not able to stick to the rules. (...) Most of them are not able to stick to the rules. (...) Most of them are not able to stick to themselves. (...) Most of them are not able to stand up for themselves. (...) Most of them are not able to stand up for themselves. (...) Most of them are not able to stand up for themselves."}, {"heading": "6 Experimental Evaluation", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Machine Learning Evaluation", "text": "The main evaluation is done in the same cross-validation scenario as in (Kaliszyk, Urban, and Vyskocil 2015b). We create the ambiguous sentences (Sec. 2) and the ambiguous grammar trees from all 21695 flyback theorems, 2 randomly permutate them and divide them into 100 equal sized chunks of about 217 trees and their corresponding sentences. The grammar trees are used for training and the ambiguous sentences for evaluation. For each chunk Ci (i.. 1.. 100) of 217 sentences, we train the probable grammar Pi on the union of the remaining 99 chunks of grammar trees (a total of about 21478 trees). Then, we try to get the best 20 parse trees for all 217 sentences in Ci using the grammar Pi. This is done for the simple context-free version (Depth 2) of the algorithm, as well as for the versions using deeper subsections (Ci), using the variant 217 in the grammar."}, {"heading": "ATP Evaluation", "text": "In the ATP evaluation, we measure how many of the correctly analyzed formulas the HOL (y) Hammer system can detect and thus contribute to confirming their validity. While the machine-like evaluation is based on simplicity through randomization, the theory test task becomes too simple, since the premise selection algorithm probably selects the theorems themselves as the most relevant assumptions. As this involves large amounts of calculation, we compare only the best new subtree-based methods (depth 6) with the old context-free method (subtree-2).In the ATP evaluation, the number of theorems itself is selected as the most relevant premise."}, {"heading": "7 Conclusion and Future Work", "text": "Compared to the initial results of (Kaliszyk, Urban, and Vyskocil 2015b), we have significantly increased the success rate of the informal-formal translation task on the flyspeck corpus; the overall improvement in the number of correct parses in the top 20 is 64% and is even higher if duplicates and definitions are omitted; the average rank of the correct parse has fallen by 44%; we believe that the contextual approach to improving the CYK process is more natural (especially more natural than lexicography), the discrimination tree indices to this task and the performance improvement is very impressive."}], "references": [{"title": "A Compendium of Continuous Lattices in MIZAR", "author": ["G. Bancerek", "P. Rudnicki"], "venue": "J. Autom. Reasoning 29(3-4):189\u2013224.", "citeRegEx": "Bancerek and Rudnicki,? 2002", "shortCiteRegEx": "Bancerek and Rudnicki", "year": 2002}, {"title": "Hammering towards QED", "author": ["J.C. Blanchette", "C. Kaliszyk", "L.C. Paulson", "J. Urban"], "venue": "J. Formalized Reasoning 9(1):101\u2013148.", "citeRegEx": "Blanchette et al\\.,? 2016", "shortCiteRegEx": "Blanchette et al\\.", "year": 2016}, {"title": "Three generative, lexicalised models for statistical parsing", "author": ["M. Collins"], "venue": "Cohen, P. R., and Wahlster, W., eds., 35th Annual Meeting of the Association for Computational Linguistics and 8th Conference of the European Chapter of the Association for Computational Linguistics, Proceedings of the Conference, 7-12 July", "citeRegEx": "Collins,? 1997", "shortCiteRegEx": "Collins", "year": 1997}, {"title": "Indexing by Latent Semantic Analysis", "author": ["S.C. Deerwester", "S.T. Dumais", "T.K. Landauer", "G.W. Furnas", "R.A. Harshman"], "venue": "JASIS 41(6):391\u2013407.", "citeRegEx": "Deerwester et al\\.,? 1990", "shortCiteRegEx": "Deerwester et al\\.", "year": 1990}, {"title": "The distance-weighted k-nearest-neighbor rule", "author": ["S.A. Dudani"], "venue": "Systems, Man and Cybernetics, IEEE Transactions on SMC6(4):325\u2013327.", "citeRegEx": "Dudani,? 1976", "shortCiteRegEx": "Dudani", "year": 1976}, {"title": "Packaging mathematical structures", "author": ["F. Garillot", "G. Gonthier", "A. Mahboubi", "L. Rideau"], "venue": "Berghofer, S.; Nipkow, T.; Urban, C.; and Wenzel, M., eds., Theorem Proving in Higher Order Logics, 22nd International Conference, TPHOLs 2009, Munich, Germany, August 17-20, 2009. Proceedings, volume 5674 of", "citeRegEx": "Garillot et al\\.,? 2009", "shortCiteRegEx": "Garillot et al\\.", "year": 2009}, {"title": "A language of patterns for subterm selection", "author": ["G. Gonthier", "E. Tassi"], "venue": "Beringer, L., and Felty, A. P., eds., Interactive Theorem Proving - Third International Conference, ITP 2012, Princeton, NJ, USA, August 13-15, 2012. Proceedings, volume 7406 of Lecture Notes in Computer Science, 361\u2013376. Springer.", "citeRegEx": "Gonthier and Tassi,? 2012", "shortCiteRegEx": "Gonthier and Tassi", "year": 2012}, {"title": "A machine-checked proof of the Odd Order Theorem", "author": ["G. Gonthier", "A. Asperti", "J. Avigad", "Y. Bertot", "C. Cohen", "F. Garillot", "S.L. Roux", "A. Mahboubi", "R. O\u2019Connor", "S.O. Biha", "I. Pasca", "L. Rideau", "A. Solovyev", "E. Tassi", "L. Th\u00e9ry"], "venue": null, "citeRegEx": "Gonthier et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Gonthier et al\\.", "year": 2013}, {"title": "Mizar in a nutshell", "author": ["A. Grabowski", "A. Korni\u0142owicz", "A. Naumowicz"], "venue": "J. Formalized Reasoning 3(2):153\u2013245.", "citeRegEx": "Grabowski et al\\.,? 2010", "shortCiteRegEx": "Grabowski et al\\.", "year": 2010}, {"title": "Input transformations and resolution implementation techniques for theorem-proving in first-order logic", "author": ["S. Greenbaum"], "venue": "Ph.D. Dissertation, University of Illinois at Urbana-Champaign.", "citeRegEx": "Greenbaum,? 1986", "shortCiteRegEx": "Greenbaum", "year": 1986}, {"title": "Constructive type classes in isabelle", "author": ["F. Haftmann", "M. Wenzel"], "venue": "Altenkirch, T., and McBride, C., eds., Types for Proofs and Programs, International Workshop, TYPES 2006, Nottingham, UK, April 18-21, 2006, Revised Selected Papers, volume 4502 of Lecture Notes in Computer Science, 160\u2013174. Springer.", "citeRegEx": "Haftmann and Wenzel,? 2006", "shortCiteRegEx": "Haftmann and Wenzel", "year": 2006}, {"title": "A formal proof of the Kepler", "author": ["T.C. Hales", "M. Adams", "G. Bauer", "D.T. Dang", "J. Harrison", "T.L. Hoang", "C. Kaliszyk", "V. Magron", "S. McLaughlin", "T.T. Nguyen", "T.Q. Nguyen", "T. Nipkow", "S. Obua", "J. Pleso", "J. Rute", "A. Solovyev", "A.H.T. Ta", "T.N. Tran", "D.T. Trieu", "J. Urban", "K.K. Vu", "R. Zumkeller"], "venue": null, "citeRegEx": "Hales et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Hales et al\\.", "year": 2015}, {"title": "Dense Sphere Packings: A Blueprint for Formal Proofs, volume 400 of London Mathematical Society Lecture Note Series", "author": ["T. Hales"], "venue": "Cambridge University Press.", "citeRegEx": "Hales,? 2012", "shortCiteRegEx": "Hales", "year": 2012}, {"title": "History of interactive theorem proving", "author": ["J. Harrison", "J. Urban", "F. Wiedijk"], "venue": "Siekmann, J. H., ed., Computational Logic, volume 9 of Handbook of the History of Logic. Elsevier. 135\u2013214.", "citeRegEx": "Harrison et al\\.,? 2014", "shortCiteRegEx": "Harrison et al\\.", "year": 2014}, {"title": "HOL Light: A tutorial introduction", "author": ["J. Harrison"], "venue": "Srivas, M. K., and Camilleri, A. J., eds., FMCAD, volume 1166 of LNCS, 265\u2013269. Springer.", "citeRegEx": "Harrison,? 1996", "shortCiteRegEx": "Harrison", "year": 1996}, {"title": "Stronger automation for Flyspeck by feature weighting and strategy evolution", "author": ["C. Kaliszyk", "J. Urban"], "venue": "Blanchette, J. C., and Urban, J., eds., PxTP 2013, volume 14 of EPiC Series, 87\u201395. EasyChair.", "citeRegEx": "Kaliszyk and Urban,? 2013", "shortCiteRegEx": "Kaliszyk and Urban", "year": 2013}, {"title": "Learning-assisted automated reasoning with Flyspeck", "author": ["C. Kaliszyk", "J. Urban"], "venue": "J. Autom. Reasoning 53(2):173\u2013213.", "citeRegEx": "Kaliszyk and Urban,? 2014", "shortCiteRegEx": "Kaliszyk and Urban", "year": 2014}, {"title": "Efficient semantic features for automated reasoning over large theories", "author": ["C. Kaliszyk", "J. Urban", "J. Vyskocil"], "venue": "Yang, Q., and Wooldridge, M., eds., IJCAI\u201915, 3084\u20133090. AAAI Press.", "citeRegEx": "Kaliszyk et al\\.,? 2015a", "shortCiteRegEx": "Kaliszyk et al\\.", "year": 2015}, {"title": "Learning to parse on aligned corpora (rough diamond)", "author": ["C. Kaliszyk", "J. Urban", "J. Vyskocil"], "venue": "Urban, C., and Zhang, X., eds., Interactive Theorem Proving - 6th International Conference, ITP 2015, Nanjing, China, August 24-27, 2015, Proceedings, volume 9236 of Lecture Notes in Computer Science, 227\u2013233.", "citeRegEx": "Kaliszyk et al\\.,? 2015b", "shortCiteRegEx": "Kaliszyk et al\\.", "year": 2015}, {"title": "seL4: formal verification of an operating-system kernel", "author": ["G. Klein", "J. Andronick", "K. Elphinstone", "G. Heiser", "D. Cock", "P. Derrin", "D. Elkaduwe", "K. Engelhardt", "R. Kolanski", "M. Norrish", "T. Sewell", "H. Tuch", "S. Winwood"], "venue": "Commun. ACM 53(6):107\u2013 115.", "citeRegEx": "Klein et al\\.,? 2010", "shortCiteRegEx": "Klein et al\\.", "year": 2010}, {"title": "First-order theorem proving and Vampire", "author": ["L. Kov\u00e1cs", "A. Voronkov"], "venue": "Sharygina, N., and Veith, H., eds., CAV, volume 8044 of LNCS, 1\u201335. Springer.", "citeRegEx": "Kov\u00e1cs and Voronkov,? 2013", "shortCiteRegEx": "Kov\u00e1cs and Voronkov", "year": 2013}, {"title": "To CNF or not to CNF? an efficient yet presentable version of the CYK algorithm", "author": ["M. Lange", "H. Lei\u00df"], "venue": "Informatica Didactica 8.", "citeRegEx": "Lange and Lei\u00df,? 2009", "shortCiteRegEx": "Lange and Lei\u00df", "year": 2009}, {"title": "Formal verification of a realistic compiler", "author": ["X. Leroy"], "venue": "Commun. ACM 52(7):107\u2013115.", "citeRegEx": "Leroy,? 2009", "shortCiteRegEx": "Leroy", "year": 2009}, {"title": "Handbook of Automated Reasoning (in 2 volumes)", "author": ["J.A. Robinson", "A. Voronkov", "eds"], "venue": null, "citeRegEx": "Robinson et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Robinson et al\\.", "year": 2001}, {"title": "Commutative algebra in the Mizar system", "author": ["P. Rudnicki", "C. Schwarzweller", "A. Trybulec"], "venue": "J. Symb. Comput. 32(1/2):143\u2013 169.", "citeRegEx": "Rudnicki et al\\.,? 2001", "shortCiteRegEx": "Rudnicki et al\\.", "year": 2001}, {"title": "Formal mathematics on display: A wiki for Flyspeck", "author": ["C. Tankink", "C. Kaliszyk", "J. Urban", "H. Geuvers"], "venue": "Carette, J.; Aspinall, D.; Lange, C.; Sojka, P.; and Windsteiger, W., eds., MKM/Calculemus/DML, volume 7961 of LNCS, 152\u2013167. Springer.", "citeRegEx": "Tankink et al\\.,? 2013", "shortCiteRegEx": "Tankink et al\\.", "year": 2013}, {"title": "The Isabelle framework", "author": ["M. Wenzel", "L.C. Paulson", "T. Nipkow"], "venue": "Mohamed, O. A.; Mu\u00f1oz, C. A.; and Tahar, S., eds., TPHOLs, volume 5170 of LNCS, 33\u201338. Springer.", "citeRegEx": "Wenzel et al\\.,? 2008", "shortCiteRegEx": "Wenzel et al\\.", "year": 2008}, {"title": "Recognition and parsing of context-free languages in time n\u02c63", "author": ["D.H. Younger"], "venue": "Information and Control 10(2):189\u2013208.", "citeRegEx": "Younger,? 1967", "shortCiteRegEx": "Younger", "year": 1967}, {"title": "Understanding informal mathematical discourse", "author": ["C. Zinn"], "venue": "Ph.D. Dissertation, University of Erlangen-Nuremberg.", "citeRegEx": "Zinn,? 2004", "shortCiteRegEx": "Zinn", "year": 2004}], "referenceMentions": [{"referenceID": 11, "context": "Despite recent impressive formalizations such as the Formal Proof of the Kepler conjecture (Flyspeck) (Hales et al. 2015), FeitThompson (Gonthier et al.", "startOffset": 102, "endOffset": 121}, {"referenceID": 7, "context": "2015), FeitThompson (Gonthier et al. 2013), seL4 (Klein et al.", "startOffset": 20, "endOffset": 42}, {"referenceID": 19, "context": "2013), seL4 (Klein et al. 2010), CompCert (Leroy 2009), and CCL (Bancerek and Rudnicki 2002), formalizing proofs is still largely unappealing to mathematicians.", "startOffset": 12, "endOffset": 31}, {"referenceID": 22, "context": "2010), CompCert (Leroy 2009), and CCL (Bancerek and Rudnicki 2002), formalizing proofs is still largely unappealing to mathematicians.", "startOffset": 16, "endOffset": 28}, {"referenceID": 0, "context": "2010), CompCert (Leroy 2009), and CCL (Bancerek and Rudnicki 2002), formalizing proofs is still largely unappealing to mathematicians.", "startOffset": 38, "endOffset": 66}, {"referenceID": 1, "context": "While research on AI and strong automation over large theories has taken off in the last decade (Blanchette et al. 2016), there has been so far little progress in automating the understanding of informal LTEX-written and ambiguous mathematical writings.", "startOffset": 96, "endOffset": 120}, {"referenceID": 14, "context": "Among the state-of-the-art Interactive Theorem Proving (ITP) systems such as HOL (Light) (Harrison 1996), Isabelle (Wenzel, Paulson, and Nipkow 2008), Mizar (Grabowski, Korni\u0142owicz, and Naumowicz 2010) and Coq (coq ), none includes automated parsing, instead relying on sophisticated formal languages and mechanisms (Garillot et al.", "startOffset": 89, "endOffset": 104}, {"referenceID": 5, "context": "Among the state-of-the-art Interactive Theorem Proving (ITP) systems such as HOL (Light) (Harrison 1996), Isabelle (Wenzel, Paulson, and Nipkow 2008), Mizar (Grabowski, Korni\u0142owicz, and Naumowicz 2010) and Coq (coq ), none includes automated parsing, instead relying on sophisticated formal languages and mechanisms (Garillot et al. 2009; Gonthier and Tassi 2012; Haftmann and Wenzel 2006; Rudnicki, Schwarzweller, and Trybulec 2001).", "startOffset": 316, "endOffset": 433}, {"referenceID": 6, "context": "Among the state-of-the-art Interactive Theorem Proving (ITP) systems such as HOL (Light) (Harrison 1996), Isabelle (Wenzel, Paulson, and Nipkow 2008), Mizar (Grabowski, Korni\u0142owicz, and Naumowicz 2010) and Coq (coq ), none includes automated parsing, instead relying on sophisticated formal languages and mechanisms (Garillot et al. 2009; Gonthier and Tassi 2012; Haftmann and Wenzel 2006; Rudnicki, Schwarzweller, and Trybulec 2001).", "startOffset": 316, "endOffset": 433}, {"referenceID": 10, "context": "Among the state-of-the-art Interactive Theorem Proving (ITP) systems such as HOL (Light) (Harrison 1996), Isabelle (Wenzel, Paulson, and Nipkow 2008), Mizar (Grabowski, Korni\u0142owicz, and Naumowicz 2010) and Coq (coq ), none includes automated parsing, instead relying on sophisticated formal languages and mechanisms (Garillot et al. 2009; Gonthier and Tassi 2012; Haftmann and Wenzel 2006; Rudnicki, Schwarzweller, and Trybulec 2001).", "startOffset": 316, "endOffset": 433}, {"referenceID": 28, "context": "The past work in this direction \u2013 most notably by Zinn (Zinn 2004) \u2013 has often been cited as discouraging from such efforts.", "startOffset": 55, "endOffset": 66}, {"referenceID": 12, "context": "Suitable aligned corpora are starting to appear today, the major example being the Flyspeck project and in particular its alignment (by Hales) with the detailed informal Blueprint for Formal Proofs (Hales 2012).", "startOffset": 198, "endOffset": 210}, {"referenceID": 12, "context": "2 Informalized Flyspeck and PCFG The ultimate goal of the informal-to-formal traslation is to automatically learn parsing on informal LTEX formulas that have been aligned with their formal counterparts, as for example done by Hales for his informal and formal Flyspeck texts (Hales 2012; Tankink et al. 2013).", "startOffset": 275, "endOffset": 308}, {"referenceID": 25, "context": "2 Informalized Flyspeck and PCFG The ultimate goal of the informal-to-formal traslation is to automatically learn parsing on informal LTEX formulas that have been aligned with their formal counterparts, as for example done by Hales for his informal and formal Flyspeck texts (Hales 2012; Tankink et al. 2013).", "startOffset": 275, "endOffset": 308}, {"referenceID": 27, "context": "A frequently used CFG algorithm is the CYK (Cocke\u2013Younger\u2013Kasami) chart-parser (Younger 1967), based on bottom-up parsing.", "startOffset": 79, "endOffset": 93}, {"referenceID": 21, "context": "The transformation to CNF can cause an exponential blowup of the grammar, however, an improved version of CYK gets around this issue (Lange and Lei\u00df 2009).", "startOffset": 133, "endOffset": 154}, {"referenceID": 3, "context": "It is however likely that even better semantic categories can be developed, based on more involved statistical and semantic analysis of the data such as latent semantics (Deerwester et al. 1990).", "startOffset": 170, "endOffset": 194}, {"referenceID": 16, "context": "This is followed by proof and disproof attempts by the HOL(y)Hammer system (Kaliszyk and Urban 2014), using all the semantic knowledge available in the Flyspeck library (about 22000 theorems).", "startOffset": 75, "endOffset": 100}, {"referenceID": 2, "context": "One method that is frequently used for dealing with similar problems in the NLP domain is grammar lexicalization (Collins 1997).", "startOffset": 113, "endOffset": 127}, {"referenceID": 9, "context": "Efficient Implementation of Deeper Subtrees Discrimination trees (Robinson and Voronkov 2001), as first implemented by Greenbaum (Greenbaum 1986), index terms in a trie, which keeps single path-strings at each of the indexed terms.", "startOffset": 129, "endOffset": 145}, {"referenceID": 4, "context": "For actual theorem proving, we only use a single (strongest) HOL(y)Hammer method: the distance-weighted k-nearest neighbor (k-NN) (Dudani 1976) using the strongest combination of features (Kaliszyk, Urban, and Vyskocil 2015a), with IDF-based feature weighting (Kaliszyk and Urban 2013) and 128 premises, and running Vampire 4.", "startOffset": 130, "endOffset": 143}, {"referenceID": 15, "context": "For actual theorem proving, we only use a single (strongest) HOL(y)Hammer method: the distance-weighted k-nearest neighbor (k-NN) (Dudani 1976) using the strongest combination of features (Kaliszyk, Urban, and Vyskocil 2015a), with IDF-based feature weighting (Kaliszyk and Urban 2013) and 128 premises, and running Vampire 4.", "startOffset": 260, "endOffset": 285}, {"referenceID": 20, "context": "0 (Kov\u00e1cs and Voronkov 2013).", "startOffset": 2, "endOffset": 28}], "year": 2016, "abstractText": "We study methods for automated parsing of informal mathematical expressions into formal ones, a main prerequisite for deep computer understanding of informal mathematical texts. We propose a context-based parsing approach that combines efficient statistical learning of deep parse trees with their semantic pruning by type checking and large-theory automated theorem proving. We show that the methods very significantly improve on previous results in parsing theorems from the Flyspeck corpus.", "creator": "TeX"}}}