{"id": "1611.09904", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Nov-2016", "title": "C-RNN-GAN: Continuous recurrent neural networks with adversarial training", "abstract": "Generative adversarial networks have been proposed as a way of efficiently training deep generative neural networks. We propose a generative adversarial model that works on continuous sequential data, and apply it by training it on a collection of classical music. We conclude that it generates music that sounds better and better as the model is trained, report statistics on generated music, and let the reader judge the quality by downloading the generated songs.", "histories": [["v1", "Tue, 29 Nov 2016 21:53:09 GMT  (117kb,D)", "http://arxiv.org/abs/1611.09904v1", "Accepted to Constructive Machine Learning Workshop (CML) at NIPS 2016 in Barcelona, Spain, December 10"]], "COMMENTS": "Accepted to Constructive Machine Learning Workshop (CML) at NIPS 2016 in Barcelona, Spain, December 10", "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["olof mogren"], "accepted": false, "id": "1611.09904"}, "pdf": {"name": "1611.09904.pdf", "metadata": {"source": "CRF", "title": "C-RNN-GAN: Continuous recurrent neural networks with adversarial training", "authors": ["Olof Mogren"], "emails": ["olof@mogren.one"], "sections": [{"heading": "1 Introduction", "text": "This year it has come to the point where it will be able to take the lead, \"he said in an interview with the German Press Agency.\" We have never hesitated so long, \"he said.\" We have never hesitated so long until we were able to retaliate, \"he said."}, {"heading": "2 C-RNN-GAN: A continuous recurrent network with adversarial training", "text": "The proposed model is a recursive neural network with opposing training; the opponents are two different deep recursive neural models, a generator (G) and a discriminator (D); the generator is trained to generate data that cannot be distinguished from real data, while the discriminator is trained to identify the generated data; the training becomes a zero-sum game in which the Nash equilibrium is created when the generator produces data that the discriminator cannot distinguish from real data. We define the following loss functions LD and LG: LG = 1m m \u2211 i = 1 protocol (1 \u2212 D (G (i))))) LD = 1m m \u2211 i = 1 [\u2212 logD (x (i)) \u2212 (log (1 \u2212 D (G (i)))))) (where z (i) is a sequence of uniform random vectors in [0, 1] k and x (i) is a sequence of training data."}, {"heading": "2.1 Modelling music", "text": "Inspired by the time-honored MIDI format for communicating signals between digital musical instruments, we model the signal with four real scalars at each data point: pitch length, frequency, intensity and time taken since the previous tone. Modelling the data in this way allows the network to display polyphonic chords (with zero time between two tones). To evaluate its effect on polyphony, we have also experimented with up to three tones, which are displayed as output from each LSTM cell in G (with appropriate modifications to D). Each tone is then displayed with its own quadrupling of the values described above. We call this version C-RNN-GAN-3. Similar to the MIDI format, the absence of a tone is represented by the output without intensity."}, {"heading": "3 Experimental setup", "text": "In fact, most of them will be able to feel as if they are able to survive on their own."}, {"heading": "3.1 Evaluation", "text": "The evaluation of C-RNN-GAN was based on a series of measurements of the output generated. Polyphony measures how often (at least) two notes are played simultaneously (their start time is exactly the same), and it is a rather limited measurement because it can give a low score to music with simultaneous tones that do not start at exactly the same time. Scale consistency was calculated by counting the fraction of tones that were part of a standard scale and specifying the number for the best match with such a scale. Repetitions of short subsequences were counted, giving a score for how many repetitions there is in a sample. This measurement only takes into account the tones and their order, not their timing.Tone span is the number of semitone steps between the lowest and highest notes in a sample.To calculate these estimates, a tool was implemented that will be used on Giub-2 along with the entire source code of the work."}, {"heading": "4 Results", "text": "The results of the experimental study are shown in Figure 3. Adversarial training helps the model learn patterns with greater variability, tonal range and intensity range. Allowing the model to output more than one tone per LSTM cell helps produce music with a higher polyphony score."}, {"heading": "4.1 Listening impressions", "text": "Although we have not yet done a thorough listening study of this work, the impression of the author and his colleagues is that the feature matching-trained model achieves a better compromise between structure and surprise than the other variants. Versions with only the most likely pretraining tend not to offer enough surprises, and versions with mini-batch functions tend to sample music with too little structure to be interesting to the real listener. That's something surprising and something we want to look at more closely. Music files created with C-RNN-GAN can be downloaded from http: / / mogren.one / publications / 2016 / c-rnn-gan /."}, {"heading": "5 Discussion and conclusions", "text": "In this paper, we proposed a recursive neural model for continuous data that was trained using an approach based on generative adversarial networks. Although further experiments are required, we believe the results are promising. We found that adversarial training helps the recursive neural network to produce music that varies more in both the number of tones used and the range of tones played. According to human judgement, the music produced cannot yet be compared with the music in the training data, the reasons for which have yet to be investigated. However, the evaluation (see Figure 3) indicates that the scores of music produced with C-RNN-GAN are more similar to scores of real music than to music produced using the baseline. The music produced is polyphonic, but in the polyphony score in our experimental assessment, which measures how often two tones can be played at the exact time, the number of points NC-N has a low score."}, {"heading": "Acknowledgments", "text": "This work was carried out as part of the project \"Data-driven secure business intelligence,\" which is funded by the Swedish Foundation for Strategic Research (SSF). 2https: / / github.com / olofmogren / c-rnn-gan"}], "references": [{"title": "Unsupervised representation learning with deep convolutional generative adversarial networks", "author": ["Soumith Chintala Alec Radford", "Luke Metz"], "venue": "In International Conference on Learning Representations,", "citeRegEx": "Radford and Metz.,? \\Q2016\\E", "shortCiteRegEx": "Radford and Metz.", "year": 2016}, {"title": "Learning long-term dependencies with gradient descent is difficult", "author": ["Yoshua Bengio", "Patrice Simard", "Paolo Frasconi"], "venue": "Neural Networks, IEEE Transactions on,", "citeRegEx": "Bengio et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 1994}, {"title": "Deep generative image models using a laplacian pyramid of adversarial networks", "author": ["Emily L Denton", "Soumith Chintala", "Rob Fergus"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Denton et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Denton et al\\.", "year": 2015}, {"title": "Finding temporal structure in music: Blues improvisation with lstm recurrent networks", "author": ["Douglas Eck", "Juergen Schmidhuber"], "venue": "In Neural Networks for Signal Processing,", "citeRegEx": "Eck and Schmidhuber.,? \\Q2002\\E", "shortCiteRegEx": "Eck and Schmidhuber.", "year": 2002}, {"title": "Generative adversarial nets", "author": ["Ian Goodfellow", "Jean Pouget-Abadie", "Mehdi Mirza", "Bing Xu", "David Warde-Farley", "Sherjil Ozair", "Aaron Courville", "Yoshua Bengio"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Goodfellow et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2014}, {"title": "Generating sequences with recurrent neural networks", "author": ["Alex Graves"], "venue": "arXiv preprint arXiv:1308.0850,", "citeRegEx": "Graves.,? \\Q2013\\E", "shortCiteRegEx": "Graves.", "year": 2013}, {"title": "The vanishing gradient problem during learning recurrent neural nets and problem solutions", "author": ["Sepp Hochreiter"], "venue": "International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems,", "citeRegEx": "Hochreiter.,? \\Q1998\\E", "shortCiteRegEx": "Hochreiter.", "year": 1998}, {"title": "Generating images with recurrent adversarial networks", "author": ["Daniel Jiwoong Im", "Chris Dongjoo Kim", "Hui Jiang", "Roland Memisevic"], "venue": "arXiv preprint arXiv:1602.05110,", "citeRegEx": "Im et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Im et al\\.", "year": 2016}, {"title": "Recurrent neural network based language model", "author": ["Tomas Mikolov", "Martin Karafi\u00e1t", "Lukas Burget", "Jan Cernock\u1ef3", "Sanjeev Khudanpur"], "venue": "In Interspeech,", "citeRegEx": "Mikolov et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2010}, {"title": "Modeling temporal dependencies in high-dimensional sequences: Application to polyphonic music generation and transcription", "author": ["Yoshua Bengio"], "venue": "In Proceedings of the 29th International Conference on Machine Learning (ICML),", "citeRegEx": "Boulanger.Lewandowski and Bengio.,? \\Q2012\\E", "shortCiteRegEx": "Boulanger.Lewandowski and Bengio.", "year": 2012}, {"title": "Improved techniques for training gans", "author": ["Tim Salimans", "Ian Goodfellow", "Wojciech Zaremba", "Vicki Cheung", "Alec Radford", "Xi Chen"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Salimans et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Salimans et al\\.", "year": 2016}, {"title": "Long short-term memory", "author": ["J\u00fcrgen Schmidhuber", "Sepp Hochreiter"], "venue": "Neural computation,", "citeRegEx": "Schmidhuber and Hochreiter.,? \\Q1997\\E", "shortCiteRegEx": "Schmidhuber and Hochreiter.", "year": 1997}, {"title": "Sequence to sequence learning with neural networks", "author": ["Ilya Sutskever", "Oriol Vinyals", "Quoc V Le"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Sutskever et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "Seqgan: Sequence generative adversarial nets with policy gradient", "author": ["Lantao Yu", "Weinan Zhang", "Jun Wang", "Yong Yu"], "venue": "arXiv preprint arXiv:1609.05473,", "citeRegEx": "Yu et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Yu et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 4, "context": "Generative adversarial networks (GANs) are a class of neural network architectures designed with the aim of generating realistic data [Goodfellow et al., 2014].", "startOffset": 134, "endOffset": 159}, {"referenceID": 5, "context": "By sampling from this conditional distribution, one can generate reasonably realistic sequences [Graves, 2013].", "startOffset": 96, "endOffset": 110}, {"referenceID": 12, "context": "The sampling is non-trivial and you usually resort to beam-search to generate good sequences in tasks such as machine translation [Sutskever et al., 2014].", "startOffset": 130, "endOffset": 154}, {"referenceID": 3, "context": "Work using RNNs for music generation includes [Eck and Schmidhuber, 2002], modelling blues songs with 25 discrete tone values, and [Nicolas Boulanger-Lewandowski, 2012], combining the RNN with restricted Boltzmann machines, representing 88 distinct tones.", "startOffset": 46, "endOffset": 73}, {"referenceID": 2, "context": "The LAPGAN model [Denton et al., 2015] is another sequential model with adversarial training, that generates images in a coarse-to-fine fashion.", "startOffset": 17, "endOffset": 38}, {"referenceID": 2, "context": "Work using RNNs for music generation includes [Eck and Schmidhuber, 2002], modelling blues songs with 25 discrete tone values, and [Nicolas Boulanger-Lewandowski, 2012], combining the RNN with restricted Boltzmann machines, representing 88 distinct tones. Yu et al. [2016] trained an RNN with adversarial training, applying policy gradient methods to cope with the discrete nature of the symbolic representation they employed.", "startOffset": 47, "endOffset": 273}, {"referenceID": 2, "context": "Work using RNNs for music generation includes [Eck and Schmidhuber, 2002], modelling blues songs with 25 discrete tone values, and [Nicolas Boulanger-Lewandowski, 2012], combining the RNN with restricted Boltzmann machines, representing 88 distinct tones. Yu et al. [2016] trained an RNN with adversarial training, applying policy gradient methods to cope with the discrete nature of the symbolic representation they employed. In contrast to this, our work represents tones using real valued continuous quadruplets of frequency, length, intensity, and timing. This allows us to use standard backpropagation to train the whole model end-to-end. Im et al. [2016] presented a recurrent model with adversarial training to generate images.", "startOffset": 47, "endOffset": 661}, {"referenceID": 8, "context": "Feeding the output from the previous cell is common practice when training RNNs as language models [Mikolov et al., 2010], and has also been used in music composition [Eck and Schmidhuber, 2002].", "startOffset": 99, "endOffset": 121}, {"referenceID": 3, "context": ", 2010], and has also been used in music composition [Eck and Schmidhuber, 2002].", "startOffset": 53, "endOffset": 80}, {"referenceID": 11, "context": "In this work, the recurrent network used is the Long short-term memory (LSTM) [Schmidhuber and Hochreiter, 1997].", "startOffset": 78, "endOffset": 112}, {"referenceID": 10, "context": "For this reason, we apply freezing [Salimans et al., 2016], which means stopping the updates of D whenever its training loss is less than 70% of the training loss of G.", "startOffset": 35, "endOffset": 58}, {"referenceID": 10, "context": "We also employ feature matching [Salimans et al., 2016], an approach to encourage greater variance in G, and avoid overfitting to the current discriminator by replacing the standard generator loss, LG.", "startOffset": 32, "endOffset": 55}], "year": 2016, "abstractText": "Generative adversarial networks have been proposed as a way of efficiently training deep generative neural networks. We propose a generative adversarial model that works on continuous sequential data, and apply it by training it on a collection of classical music. We conclude that it generates music that sounds better and better as the model is trained, report statistics on generated music, and let the reader judge the quality by downloading the generated songs.", "creator": "LaTeX with hyperref package"}}}