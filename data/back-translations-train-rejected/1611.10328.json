{"id": "1611.10328", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Nov-2016", "title": "The observer-assisted method for adjusting hyper-parameters in deep learning algorithms", "abstract": "This paper presents a concept of a novel method for adjusting hyper-parameters in Deep Learning (DL) algorithms. An external agent-observer monitors a performance of a selected Deep Learning algorithm. The observer learns to model the DL algorithm using a series of random experiments. Consequently, it may be used for predicting a response of the DL algorithm in terms of a selected quality measurement to a set of hyper-parameters. This allows to construct an ensemble composed of a series of evaluators which constitute an observer-assisted architecture. The architecture may be used to gradually iterate towards to the best achievable quality score in tiny steps governed by a unit of progress. The algorithm is stopped when the maximum number of steps is reached or no further progress is made.", "histories": [["v1", "Wed, 30 Nov 2016 19:37:48 GMT  (112kb,D)", "http://arxiv.org/abs/1611.10328v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.AI", "authors": ["maciej wielgosz"], "accepted": false, "id": "1611.10328"}, "pdf": {"name": "1611.10328.pdf", "metadata": {"source": "CRF", "title": "The observer-assisted method for adjusting hyper-parameters in deep learning algorithms", "authors": ["Maciej Wielgosza"], "emails": ["wielgosz@agh.edu.pl"], "sections": [{"heading": null, "text": "This paper introduces a concept of a novel method for adapting hyperparameters in deep learning (DL) algorithms. An external agent observer monitors the performance of a selected deep learning algorithm. The observer learns to model the DL algorithm using a series of random experiments. Consequently, it can be used to predict a response of the DL algorithm in the form of a selected quality measurement to a set of hyperparameters. This allows the construction of an ensemble consisting of a series of evaluators that form an observer-supported architecture. The architecture can be used to iterate gradually towards the best possible quality value in tiny steps, controlled by a progress unit. The algorithm is stopped when the maximum number of steps is reached or no further progress is made. Keywords: deep learning, hyperparameters, optimization"}, {"heading": "1. Introduction", "text": "Adapting hyperparameters is a demanding task, which has been addressed in many papers [1-4]. It is important because virtually all algorithms currently used have macro parameters that shape their final architecture, which in turn has a direct impact on the performance of solutions based on these algorithms. Unfortunately, despite the fact that deep learning algorithms have been around for a long time, there are no well-established methods for matching hyperparameters, such as back-propagation for model training [5]. Instead, most DL system designers have developed and applied a number of user-defined techniques, such as grid, random and heuristic search [6, 7]. In the author's view, a process for adjusting hyperparameters should take into account both data and algorithm, which in turn requires an external agent referred to here as an \"observer.\" Such an observer learns how a particular set of hyperparameters affects the performance of a deep idea."}, {"heading": "2. Algorithm", "text": "The observer learns a response from a deep learning algorithm for different groups of hyperparameters in relation to a selected quality measurement value (Fig. 1). Based on this information, he can think about the best set of hyperparameters. However, in order to learn a relationship between the hyperparameters and performance, a series of experiments must be performed with a random set of parameters. The more experiments are performed, the more reliable predictions can be made by the observer. However, it is worth taking into account that the observer models the deep learning algorithm. Therefore, the quality of a model used as an observer has a significant influence on the hyperparameters that are adapted.A key component of the observer algorithm is presented in Fig. 2, where a series of evaluators are shown. Each of the evaluators provides information about a value of a selected hyperparameter and quality algorithm as a prediction algorithm."}, {"heading": "2.1. Basic algorithm", "text": "The hyperparameter adjustment algorithm supported by the observer, represented in Alg. 1, assumes predefined values such as max _ iterations, max _ idle, and min _ contribution, as well as the expected (target) quality value q _ ex. The author of the paper assumes that the threshold can be arbitrarily chosen, but in practice there are probably very few cases where a designer expects a quality value q _ ex <. In the first part of the algorithm, the hyperparameters hp0, hp1,... are initialized with random values from corresponding ranges, setting iteration counter, iteration counter, and current quality value to 0. The iteration counter is used to prevent the algorithm from running indefinitely. The iteration counter is used to stop the fit process after a certain time if there is no progress. The main work of the algorithm is performed within the while loop. In steps 7 - 9, each better mapper evaluates a hyteration counter on a proposed basis of the hyteration counter."}, {"heading": "2.2. Algorithm with increasing expected quality score (multi-pass approach)", "text": "The proposed Alg. 1 approaches hyperparameters that adapt the problem in a single pass, i.e. it sets the expected quality value q q q to the highest possible value (e.g. q _ ex = \u2190). Another option is to achieve the target quality value in several passes (represented in Alg. 3), algorithm 1 q q q q q q selection is previously unfeasible. Prerequisite: q _ ex Ensure: q _ best, hp _ best1: hp \u2190 get _ random _ hyperparams () 2: hp _ best \u2190 hp 3: Iterations \u2190 0 4: Idle \u2190 0 5: q _ best \u2190 0 5: q _ map _ q (hp0,.., hpn \u2212 best1) 6: while q _ best < q _ ex < max _ idle and iterations < max _ nation < max _ iterations < for i = Nation 7: for i = 0 to n \u2212 hp _ evali."}, {"heading": "2.3. Algorithm with a modified updated hyper-parameter selection (cost-based)", "text": "In the basic version of the algorithm, the selection of the updated hyperparameter is evaluated using a simple criterion of q, with hyperparameters yielding the highest quality value (see Alg. 2). The numerical value of the selection criteria for each hpidx hyperparameter, which is henceforth referred to as \"contribution,\" can be expressed as in Eq.1: The numerical value of the selection criteria for each hpidx hyperparameter [\u2212 1, 1], where higher values are desirable. However, a deep learning algorithm can have a number of hyperparameters that are usually related to the network structure, an increase (or decrease) in computing costs. Using the contribution formula above could potentially cause a huge increase in deep learning algorithm hardware requirements or computation time for a very small gain in relation to the Quidx value."}, {"heading": "3. Conclusions and Future Work", "text": "This paper presents the concept of a new method to be used in a demanding and important task of hyperparameter adjustment of deep learning algorithms, based on an external agent called an \"observer,\" who learns about the efficiency of the algorithm in terms of the chosen quality score, which allows to model the performance of the algorithm in terms of its hyperparameters. Furthermore, the author proposes a method for integrating hardware resource consumption into the process of adjusting hyperparameters. In a future paper, the author will implement the described method and conduct a series of experiments to compare its efficiency with other methods [2, 7]."}], "references": [{"title": "Random search for hyper-parameter optimization", "author": ["J. Bergstra", "Y. Bengio"], "venue": "Journal of Machine Learning Research", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2012}, {"title": "Hyper-parameter optimization of deep convolutional networks for object recognition", "author": ["S.S. Talathi"], "venue": "in: Image Processing (ICIP),", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2015}, {"title": "Practical bayesian optimization of machine learning algorithms", "author": ["J. Snoek", "H. Larochelle", "R.P. Adams"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2012}, {"title": "Practical recommendations for gradient-based training of deep architectures (Jun", "author": ["Y. Bengio"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2012}, {"title": "Brief Introduction of Back Propagation (BP) Neural Network Algorithm and Its Improvement", "author": ["J. Li", "J.-h. Cheng", "J.-y. Shi", "F. Huang"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2012}, {"title": "A Framework for Selecting Deep Learning Hyperparameters", "author": ["J.O. Donoghue", "M. Roantree"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "Optimizing deep learning hyper-parameters through an evolutionary algorithm, in: Proceedings of the Workshop on Machine Learning in High-Performance Computing Environments, MLHPC \u201915", "author": ["S. Young", "D.C. Rose", "T.P. Karnowski", "S.-H. Lim", "R.M. Patton"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2015}, {"title": "How do neurons operate on sparse distributed representations? A mathematical theory of sparsity, neurons and active dendrites (jan 2016)", "author": ["S. Ahmad", "J. Hawkins"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2016}, {"title": "Properties of Sparse Distributed Representations and their Application to Hierarchical Temporal Memory (mar", "author": ["S. Ahmad", "J. Hawkins"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2015}, {"title": "Using Spatial Pooler of Hierarchical Temporal Memory for object classification in noisy video streams", "author": ["M. Wielgosz", "M. Pietro\u0144", "K. Wiatr"], "venue": "Proceedings of the 2016 Federated Conference on Computer Science and Information Systems,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2016}, {"title": "Visualizing and Understanding Convolutional Networks, Springer International Publishing", "author": ["M.D. Zeiler", "R. Fergus"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "Hyper-parameters adjusting is a challenging task which was addressed in many papers [1\u20134].", "startOffset": 84, "endOffset": 89}, {"referenceID": 1, "context": "Hyper-parameters adjusting is a challenging task which was addressed in many papers [1\u20134].", "startOffset": 84, "endOffset": 89}, {"referenceID": 2, "context": "Hyper-parameters adjusting is a challenging task which was addressed in many papers [1\u20134].", "startOffset": 84, "endOffset": 89}, {"referenceID": 3, "context": "Hyper-parameters adjusting is a challenging task which was addressed in many papers [1\u20134].", "startOffset": 84, "endOffset": 89}, {"referenceID": 4, "context": "Unfortunately, despite the fact that deep learning algorithms have been around for a long time, there are no wellestablished procedures for hyper-parameters tuning, such as back-propagation for a model training [5].", "startOffset": 211, "endOffset": 214}, {"referenceID": 5, "context": "Instead, a set of custom techniques, such as grid, random and heuristic search [6, 7], have been developed and used by most of DL systems designers.", "startOffset": 79, "endOffset": 85}, {"referenceID": 6, "context": "Instead, a set of custom techniques, such as grid, random and heuristic search [6, 7], have been developed and used by most of DL systems designers.", "startOffset": 79, "endOffset": 85}, {"referenceID": 3, "context": "The basic idea is to offset a learning process from a complex AI algorithm which is hard to control to a simpler one with easily adjustable set of hyper-parameters [4].", "startOffset": 164, "endOffset": 167}, {"referenceID": 7, "context": "(HTM) [8\u201310] is very time consuming and demanding process.", "startOffset": 6, "endOffset": 12}, {"referenceID": 8, "context": "(HTM) [8\u201310] is very time consuming and demanding process.", "startOffset": 6, "endOffset": 12}, {"referenceID": 9, "context": "(HTM) [8\u201310] is very time consuming and demanding process.", "startOffset": 6, "endOffset": 12}, {"referenceID": 10, "context": "In general, mappers may be implemented as any kind of an algorithm such as CNN, linear or logistic regression [11].", "startOffset": 110, "endOffset": 114}, {"referenceID": 0, "context": ", hp_bestn\u22121 evaluated hyper-parameters yielding best quality score during algorithm lifetime q_ex expected quality score; q_ex \u2208 [0, 1] q_eval0, q_eval1, .", "startOffset": 130, "endOffset": 136}, {"referenceID": 0, "context": ", q_evaln\u22121 evaluated quality scores; q_evalidx \u2208 [0, 1]", "startOffset": 50, "endOffset": 56}, {"referenceID": 0, "context": "q_best best evaluated quality score during algorithm lifetime; q_best \u2208 [0, 1]", "startOffset": 72, "endOffset": 78}, {"referenceID": 0, "context": "\u03b8idx : hp_evalidx \u2192 cost \u2227 cost \u2208 [0, 1] (3) Exact mapping done by the cost function can depend on factors such as observed deep-learning algorithm, hyper-parameter being adjusted, hardware being used etc.", "startOffset": 34, "endOffset": 40}, {"referenceID": 1, "context": "As a future work the author is going to implement the described method and conduct a series of experiments in order to compare its efficiency with other methods [2, 7].", "startOffset": 161, "endOffset": 167}, {"referenceID": 6, "context": "As a future work the author is going to implement the described method and conduct a series of experiments in order to compare its efficiency with other methods [2, 7].", "startOffset": 161, "endOffset": 167}], "year": 2016, "abstractText": "This paper presents a concept of a novel method for adjusting hyper-parameters in Deep Learning (DL) algorithms. An external agent-observer monitors a performance of a selected Deep Learning algorithm. The observer learns to model the DL algorithm using a series of random experiments. Consequently, it may be used for predicting a response of the DL algorithm in terms of a selected quality measurement to a set of hyper-parameters. This allows to construct an ensemble composed of a series of evaluators which constitute an observer-assisted architecture. The architecture may be used to gradually iterate towards to the best achievable quality score in tiny steps governed by a unit of progress. The algorithm is stopped when the maximum number of steps is reached or no further progress is made.", "creator": "LaTeX with hyperref package"}}}