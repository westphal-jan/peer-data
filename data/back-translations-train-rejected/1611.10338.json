{"id": "1611.10338", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Nov-2016", "title": "SLA Violation Prediction In Cloud Computing: A Machine Learning Perspective", "abstract": "Service level agreement (SLA) is an essential part of cloud systems to ensure maximum availability of services for customers. With a violation of SLA, the provider has to pay penalties. In this paper, we explore two machine learning models: Naive Bayes and Random Forest Classifiers to predict SLA violations. Since SLA violations are a rare event in the real world (~0.2 %), the classification task becomes more challenging. In order to overcome these challenges, we use several re-sampling methods. We find that random forests with SMOTE-ENN re-sampling have the best performance among other methods with the accuracy of 99.88 % and F_1 score of 0.9980.", "histories": [["v1", "Wed, 30 Nov 2016 20:07:34 GMT  (2584kb,D)", "http://arxiv.org/abs/1611.10338v1", null]], "reviews": [], "SUBJECTS": "cs.DC cs.LG", "authors": ["reyhane askari hemmat", "abdelhakim hafid"], "accepted": false, "id": "1611.10338"}, "pdf": {"name": "1611.10338.pdf", "metadata": {"source": "CRF", "title": "SLA Violation Prediction In Cloud Computing: A Machine Learning Perspective", "authors": ["Reyhane Askari Hemmat", "Abdelhakim Hafid"], "emails": ["reyhane.askari.hemmat@umontreal.ca", "ahafid@iro.umontreal.ca"], "sections": [{"heading": null, "text": "It is hard to imagine many services and applications being used without cloud computing. Cloud computing reduces the service's maintenance costs and allows users to access on-demand services without being involved in technical implementation details. A service level agreement (SLA) defines the level of service and associated costs for the relationship between a cloud provider and a customer. SLA typically includes specific parameters and a minimum level of quality for each element of the service negotiated between the provider and the customer. An SLA is an important part of any contract as a provider wants to allocate the least resources to each customer in order to reduce the cost of its server infrastructure, while at the same time the provider must avoid penalties for failure to provide the agreed service."}, {"heading": "II. RELATED WORKS", "text": "In recent years, many models have been proposed to address SLA management issues. Imran et al. [5] use a map-reduced model to identify violations and identify the most likely causes of SLA violations using Holt-Winter's forecast. In [6], the authors propose an SLA-aware resource planning model that determines how to assign incoming requests without explicitly predicting violations. Likewise, in [7], Mohammed et al. an SLA-based cloud trust model is proposed that selects the provider based on a selection scheme. In this scheme, no violations are predicted, customers are grouped by business requirements, and the most trusted cloud providers are selected."}, {"heading": "III. DATASET", "text": "The dataset we report on contains 29 days of traceability of Google's Cloud Compute Table. For security reasons, part of the track has been omitted or blurred. For example, the values for CPU, disk and memory have been redefined by dividing the individual memory areas. Also, the names of the applications have been hacked. The application is subject to six separate tables: Job Events, Task Events, Task Attributes and Task Attributes. The entity of the database is shown in the form of images."}, {"heading": "IV. SLA VIOLATION DEFINITION", "text": "To identify SLA violations, we need specific details about QoS parameters and Service Level Objectives (SLOs). SLOs are quantitative parameters of an SLA such as availability, throughput, and response time. Although we do not have access to the details of the SLA for this record, we can trace service availability violations. Figure 2 shows the transition chart for jobs and tasks in the trace. We define a breach in service availability when a task is vacated and never rescheduled. According to trace [3] documentation, the eviction of a task is due to \"scheduling overload,\" or because the machine on which it was executed became unusable (e.g. taken offline for repairs), or because a disk holding the data of the tasks was lost."}, {"heading": "V. PREDICTION MODELS", "text": "We formulate the detection of SLA violations as follows: taking into account a set of characteristics extracted from cluster traces, what is the failure probability of a task submitted? 2 To work towards this goal, we establish a classification model and use two algorithms as the main classifiers: Naive Bayes models and Random Forest models."}, {"heading": "A. Naive Bayes Models", "text": "From a probabilistic point of view, the conditional probability of class k among the K of different classes with a vector representation of the n of different characters x = {x1,..., xn} can be written as P (Ck | x). According to the Bayes theorem [14], the above probability can be reformulated as follows: P (Ck | x) = P (x | Ck) P (Ck) P (x), (1) in which P (Ck | x) is the lower sense of our updated knowledge conditioned by the observed data. Two probabilities P (x | Ck) and P (Ck) are designated as probabilities and the previous one accordingly. In a classification arrangement, the denominator P (x) is constant. In practice, the formation of such a Bayesian classification is limited to the maximizing property Cxxx1."}, {"heading": "B. Random Forest Model", "text": "Decision tree is the main building block of the Random Forest model. As a result, we first briefly introduce Decision Tree and then explain Random Forest.2 Failure is defined in Section IV.1) Decision Tree: Decision Tree is a family of scalable classifiers that enjoys the benefit of human interpretable results. Formally, a classification decision tree is a tree in which each leaf represents a target class, each internal node represents a state, and each branch corresponds to the result of the condition in the parent node. As a simple example, we consider a number of features {Outlook, Moisture, Wind} and the goal is PlayTennis, the value of \"Yes\" or \"No.\" A trained decision tree is shown in Figure 5.2) Decision Tree Learning: Building a decision tree boils down to finding the appropriate conditions as a node and arranging them from root to leaves."}, {"heading": "VI. EXPERIMENTAL SETUP", "text": "In our experiments, we fed the historical data to Naive Bayes and Random Forest Machine Learning models to predict future violations. The task of prediction is modeled as a classification task where we have two classes. Class zero (injury = 0) is the case of uninjured tasks and class one (injury = 1) is the case of injured tasks. As the availability rate is very high (97.8%), our classes are highly unbalanced. This is called skew in the data set, which makes the classification task very difficult as the classifier always tends to predict the dominant class."}, {"heading": "A. Overcoming Data Skewness", "text": "In fact, most of them are able to play by the rules that they need for their work, and they are able to play by the rules that they need for their work."}, {"heading": "B. Error Metrics", "text": "To measure the performance of the models, error measurements are required. To show that the results are not distorted and remain roughly the same with the new data, the data set is randomly divided into two groups: Training and Test. The training set is fed into a machine learning model, and the trained model is then used to predict violations of the test set that was intact during the training, and its true target values are known. This approach helps us select a model that performs well on invisible data. To split the data set into traction and test sets, a triple cross validation is used. The data set is randomly divided into three partitions, and the prediction model is trained three times. During each training session, two thirds of the data set is used as a training set and fed into the model, and a third as a test set. The aggregate results of the three runs on the model are evaluated positively."}, {"heading": "VII. RESULTS AND DISCUSSION", "text": "The ROC curves of the Random Forest Classifier are also shown in Figure 7.It is worth mentioning why other error metrics are used as accuracy. In distorted data sets, accuracy cannot be a good error metric to find the best-performing classifier. There are two classes available: 0.2% of samples are presented as a violated class and 0.98% of samples are presented as intact. Consider a classifier that predicts that there will be no violations. It has an accuracy of 0.98%, but precision and zero recovery. Thus, precision, recall and f\u03b2 score will help us find the better-performing algorithm. The best powerful model in relation to the F1 score is the random forest classification algorithm on the data set that has been re-sampled using the SMOTE + ENN method."}, {"heading": "VIII. CONCLUSION AND FUTURE WORKS", "text": "The results in Section VII suggest that the Random Forest Algorithm works best when SMOTE + ENN is used as the over-sampling method. Among other proposed models for tasks to predict or avoid SLA violations, our models are trained on a real-world dataset that introduces new challenges that have been neglected to the best of our knowledge in previous work. It is worth noting that the Random Forest Model is not a black box and the trained model is human interpretable, as the results suggest that mem _ requested is the most important feature in predicting violations. Furthermore, due to the relatively high speed of random forest species, it can be used to predict violations. Although the random results of the Random Forest Study cannot be updated by random predictions, it is possible that another disadvantage of future forest cultivation is achieved on the basis of random data."}, {"heading": "APPENDIX A", "text": "The complete results table can be found in the following table."}], "references": [{"title": "Mechanisms for SLA provisioning in cloud-based service providers.", "author": ["Casalicchio", "Emiliano", "Luca Silvestri"], "venue": "Computer Networks", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2013}, {"title": "Service level agreements in virtualised service platforms.", "author": ["Gallizo", "Georgina"], "venue": "eChallenges", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2009}, {"title": "J", "author": ["C. Reiss"], "venue": "Wilkes and J. L. Hellerstein, \u201dGoogle cluster-usage traces: format+ schema\u201d", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2011}, {"title": "Elements of Statistical Learning Ed", "author": ["T. Hastie", "R. Tibshirani", "J. Friedman"], "venue": "2\u201d, p592-593, Springer", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2009}, {"title": "Diagnosing cloud performance anomalies using large time series dataset analysis.", "author": ["Jehangiri", "Ali Imran"], "venue": "IEEE 7th International Conference on Cloud Computing", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "SLA-aware Resource Scheduling for Cloud Storage, 2014", "author": ["Zhihao Yao", "Ioannis Papapanagiotou", "RobertD. Callaway"], "venue": "IEEE 3rd International Conference on Cloud Networking (Cloud- Net)", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2014}, {"title": "Sla-based trust model for cloud computing.", "author": ["Alhamad", "Mohammed", "Tharam Dillon", "Elizabeth Chang"], "venue": "Network-Based Information Systems (NBiS),", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2010}, {"title": "Runtime prediction of service level agreement violations for composite services.", "author": ["Leitner", "Philipp"], "venue": "Service-Oriented Computing. IC- SOC/ServiceWave 2009 Workshops", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "Host load prediction in a Google compute cloud with a Bayesian model.", "author": ["Di", "Sheng", "Derrick Kondo", "Walfredo Cirne"], "venue": "Proceedings of the International Conference on High Performance Computing,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2012}, {"title": "Efficient provisioning of bursty scientific workloads on the cloud using adaptive elasticity control.", "author": ["Ali-Eldin", "Ahmed"], "venue": "Proceedings of the 3rd workshop on Scientific Cloud Computing Date. ACM,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2012}, {"title": "Service clustering for autonomic clouds using random forest.", "author": ["Uriarte", "Rafael Brundo", "Sotirios Tsaftaris", "Francesco Tiezzi"], "venue": "Cluster, Cloud and Grid Computing (CCGrid),", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2015}, {"title": "Bayesian network, and probabilistic ontology driven trust model for sla management of cloud services.", "author": ["Jules", "Obed", "Abdelhakim Hafid", "Mohamed Adel Serhani"], "venue": "Cloud Networking (CloudNet),", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2014}, {"title": "A multiple resampling method for learning from imbalanced data sets.", "author": ["Estabrooks", "Andrew", "Taeho Jo", "Nathalie Japkowicz"], "venue": "Computational intelligence", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2004}, {"title": "Statistical learning theory", "author": ["Vapnik", "Vladimir Naumovich", "Vlamimir Vapnik"], "venue": "New York: Wiley,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1998}, {"title": "SMOTE: synthetic minority over-sampling technique.", "author": ["Chawla", "Nitesh V"], "venue": "Journal of artificial intelligence research", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2002}, {"title": "Two Modifications of CNN", "author": ["I. Tomek"], "venue": "IEEE Transactions on Systems Man and Communications", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1976}, {"title": "Addressing the curse of imbalanced training sets: one-sided selection.", "author": ["Kubat", "Miroslav", "Stan Matwin"], "venue": "ICML. Vol", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1997}, {"title": "Improving identification of difficult small classes by balancing class distribution.", "author": ["Laurikkala", "Jorma"], "venue": "Conference on Artificial Intelligence in Medicine in Europe", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2001}, {"title": "kNN approach to unbalanced data distributions: a case study involving information extraction.", "author": ["Mani", "Inderjeet", "I. Zhang"], "venue": "Proceedings of workshop on learning from imbalanced datasets", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2003}, {"title": "Balancing Training Data for Automated Annotation of Keywords: a Case Study.", "author": ["Batista", "Gustavo EAPA", "Ana LC Bazzan", "Maria Carolina Monard"], "venue": "WOB", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2003}, {"title": "A study of the behavior of several methods for balancing machine learning training data.", "author": ["Batista", "Gustavo EAPA", "Ronaldo C. Prati", "Maria Carolina Monard"], "venue": "ACM Sigkdd Explorations Newsletter", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2004}], "referenceMentions": [{"referenceID": 0, "context": "SLA usually contains specific parameters and a minimum level of quality for each element of the service that is negotiated between the provider and the customer [1].", "startOffset": 161, "endOffset": 164}, {"referenceID": 1, "context": "According to [2], SLA management has six phases: SLA contract definition, basic schema with the Quality of Service (QoS) parameters, SLA negotiation, SLA monitoring, SLA violation detection and SLA enforcement.", "startOffset": 13, "endOffset": 16}, {"referenceID": 2, "context": "We report our results on a subset of the Google Cloud Cluster trace dataset [3].", "startOffset": 76, "endOffset": 79}, {"referenceID": 3, "context": "The results presented in Section VII show that the best performance is achieved using the Random Forest [4] method with an accuracy of 99.", "startOffset": 104, "endOffset": 107}, {"referenceID": 4, "context": "[5] use a map-reduce model to detect violations and find the most probable causes of SLA violations using Holt-Winters forecasting.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "In [6], the authors proposed an SLA aware resource scheduling model that determines how to allocate coming requests without explicit prediction of violations.", "startOffset": 3, "endOffset": 6}, {"referenceID": 6, "context": "Similarly, in [7] , Mohammed et al.", "startOffset": 14, "endOffset": 17}, {"referenceID": 7, "context": "In a similar work for predicting SLA violations in composite services, in [8] the authors propose a regression machine", "startOffset": 74, "endOffset": 77}, {"referenceID": 8, "context": "In [9], the authors proposed a model for predicting host load using real data of Google Compute Cluster.", "startOffset": 3, "endOffset": 6}, {"referenceID": 9, "context": "The authors in [10] propose a provisioning method that monitors and also predicts future loads.", "startOffset": 15, "endOffset": 19}, {"referenceID": 10, "context": "The authors in [11], use unsupervised learning to cluster the resource usage and duration of services to avoid violations of Google Cluster trace dataset.", "startOffset": 15, "endOffset": 19}, {"referenceID": 11, "context": "The authors in [12] use a Naive Bayes model to predict SLA violations.", "startOffset": 15, "endOffset": 19}, {"referenceID": 2, "context": "Machine attributes table shows the attributes of each machine such as kernel version, clock speed and presence of an external IP address[3].", "startOffset": 136, "endOffset": 139}, {"referenceID": 2, "context": "The state transition diagram of a task on Google Cluster machines[3].", "startOffset": 65, "endOffset": 68}, {"referenceID": 12, "context": "There has been some methods in machine learning to handle such data such as over sampling and under sampling; also it has been recommenced to use generative models[13].", "startOffset": 163, "endOffset": 167}, {"referenceID": 2, "context": "According to the documentation of the trace [3], eviction of a task is due to \u201dovercommiting of the scheduler or because the machine on which it was running became unusable (e.", "startOffset": 44, "endOffset": 47}, {"referenceID": 13, "context": "According to the Bayes theorem [14], the above probability can be reformulated as follows:", "startOffset": 31, "endOffset": 35}, {"referenceID": 14, "context": "SMOTE (Synthetic Minority Over-sampling Technique) [15],", "startOffset": 51, "endOffset": 55}, {"referenceID": 14, "context": "3) SMOTE [15]: is a re-sampling method that generates new synthetic datapoints of the minority class using interpolation between the current datapoints.", "startOffset": 9, "endOffset": 13}, {"referenceID": 15, "context": "4) Tomek links [16]: is an under sampling method.", "startOffset": 15, "endOffset": 19}, {"referenceID": 16, "context": "5) One-sided Selection [17]: uses the combination of Tomek links and CNN (Condensed Nearest Neighbor Rule) to find the safe samples and removes the unsafe samples from the majority class.", "startOffset": 23, "endOffset": 27}, {"referenceID": 17, "context": "6) Neighborhood Cleaning Rule [18]: removes some datapoints from the majority class.", "startOffset": 30, "endOffset": 34}, {"referenceID": 18, "context": "7) NearMiss [19]: NearMiss 1, 2 and 3 algorithms are under-sampling methods.", "startOffset": 12, "endOffset": 16}, {"referenceID": 19, "context": "8) SMOTE-Tomek links [20]: Since SMOTE over-sampling might lead to over-fitting and Tomek links under sampling might remove important datapoints, the ensemble of these two methods provide better results.", "startOffset": 21, "endOffset": 25}, {"referenceID": 20, "context": "9) SMOTE-ENN [21]: is also the ensemble of SMOTE and ENN.", "startOffset": 13, "endOffset": 17}], "year": 2016, "abstractText": "Service level agreement (SLA) is an essential part of cloud systems to ensure maximum availability of services for customers. With a violation of SLA, the provider has to pay penalties. Thus, being able to predict SLA violations favors both the customers and the providers. In this paper, we explore two machine learning models: Naive Bayes and Random Forest Classifiers to predict SLA violations. Since SLA violations are a rare event in the real world (\u223c 0.2%), the classification task becomes more challenging. In order to overcome these challenges, we use several re-sampling methods such as Random Over and Under Sampling, SMOTH, NearMiss (1,2,3), One-sided Selection, Neighborhood Cleaning Rule, etc. to re-balance the dataset. We use the Google Cloud Cluster trace as the dataset to examine these different methods. We find that random forests with SMOTE-ENN re-sampling have the best performance among other methods with the accuracy of 0.9988% and F1 score of 0.9980.", "creator": "LaTeX with hyperref package"}}}