{"id": "1612.00092", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Dec-2016", "title": "Computer Assisted Composition with Recurrent Neural Networks", "abstract": "Sequence modeling with neural networks has lead to powerful models of symbolic music data. We address the problem of exploiting these models to reach creative musical goals. To this end we generalise previous work, which sampled Markovian sequence models under the constraint that the sequence belong to the language of a given finite state machine. We consider more expressive non-Markov models, thereby requiring approximate sampling which we provide in the form of an efficient sequential Monte Carlo method. In addition we provide and compare with a beam search strategy for conditional probability maximisation. Our algorithms are capable of convincingly re-harmonising famous musical works. To demonstrate this we provide visualisations, quantitative experiments, a human listening test and illustrative audio examples. We find both the sampling and optimisation procedures to be effective, yet complementary in character. For the case of highly permissive constraint sets, we find that sampling is to be preferred due to the overly regular nature of the optimisation based results.", "histories": [["v1", "Thu, 1 Dec 2016 00:49:19 GMT  (612kb,D)", "http://arxiv.org/abs/1612.00092v1", null], ["v2", "Fri, 29 Sep 2017 23:38:35 GMT  (505kb,D)", "http://arxiv.org/abs/1612.00092v2", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["christian walder", "dongwoo kim"], "accepted": false, "id": "1612.00092"}, "pdf": {"name": "1612.00092.pdf", "metadata": {"source": "CRF", "title": "Computer Assisted Composition with Recurrent Neural Networks", "authors": ["Christian Walder", "Dongwoo Kim"], "emails": [], "sections": [{"heading": null, "text": "In this context, it should be noted that most of the people who are able to see themselves are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to dance, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move,"}, {"heading": "1 I will argue that today\u2019s composers are more frequently gardeners than architects and, further, that the composer as architect", "text": "This metaphor was a temporary historical blip - Schmido 10.is most closely related to the work of19, which imposes the restriction that the resulting sequence must be a member of a language defined by a finite state machine. This is a rather general restriction that provides a rich language for human creativity beyond the partial specification of music. In this work, the close relationship between Markov models and finite state machines was used to derive a simple but exact faith reproduction algorithm. Here, we loosen the restriction that our underlying sequence model must be Markovian, and instead use approximate scanning techniques, namely the sequential Monte Carlo8,12 (SMC). In addition to scanning, we compare and contrast with a maximum conditional probability approach based on a beam search. (Given the finite state machine restriction). In which we allow, the models that are not more complete, are less algorithmic models."}, {"heading": "II. SET-UP AND MOTIVATION", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Required Background", "text": "The algorithms we present are applicable to any model that is explicitly considered as (1) below. However, we use the model of Walder 25, which is a necessary complement to the present work for those who wish to replicate our results. Furthermore, the formalism of the finite state machine limitation that we apply is closely related to Papadopoulos et al. 19, which we recommend as background material."}, {"heading": "B. Assumed Music Model", "text": "We represent a musical composition by a series of n triples, {(xi, ti, di)} ni = 1 \u0445 X \u00b7 T \u00b7 T. Here, X represents the set of possible pitches (from the Western 12-tet music system, including the note name and octave).The set T represents the time where ti and di indicate the start time and duration of the i-th tone event or the duration of the i-th tone event.Following Walder 25, we assume that the timing of the indices is given, so that we have a model p ({xi} ni = 1 | n, {(ti, di)} n = 1. This model p is based on a reduction to a non-Markov sequence model. This means that (for a certain order of indices, see Walder 25) the conditionalities on {(ti, di)} mi = 1 are neglected, we have (x1: 1) = 1 (xxi | 1) where \u2212 alicities are represented."}, {"heading": "C. Assumption of Fixed Rhythmic Information", "text": "Ideally, we would model the rhythmic structure, but this turns out to be quite difficult. In fact, modeling pitches is already quite trivial given the rhythmic structure, so it is reasonable to divide the problem. Note that some authors have modelled timing information by, for example, not distinguishing two-eighths from a single quarter note (which is two-eighths long).2. A simplified compilation of possible durations, as in Colombo et al. 6, Mozer 16. This approach is sound, but requires a more complex machinery to model a realistic range of emergency durations and start times. Furthermore, sampling conditional constraints, as is our current focus, can be used for technical purposes. In fact, point processing machinery and novel sampling techniques are needed to model a realistic range of emergency durations and start times."}, {"heading": "D. Finite State Machine Constraint Formulation", "text": "Following Papadopoulos et al. 19, we formulate human input as the limitation that sequence x1: n belongs to the language of any finite state machine, A. This has the advantage of being extremely general, but nevertheless susceptible to belief propagation (for Markov p as for Papadopoulos et al. 19) and particle filtering / beam search (as in the present work).The experiments in Section III use a fraction of the generality of this approach. We imagine a series of limitations that users can experiment with to discover interesting new music, and our algorithms facilitate this. For example, one could force the repetition of patterns, transform relationships between partial sequences (such as inversion / regression), etc., with arbitrarily complex implications such as strange polymetric patterns, etc. Concrete examples can be found in Roy and Pachet 22, which impose metric structures, and Papadopoulos, avoiding partial repetition, 20."}, {"heading": "E. Harmonisation by Sampling / Optimisation", "text": "5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5%, 5, 5%, 5, 5%, 5, 5%, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5 (A), 1, 5, 1, 5, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1"}, {"heading": "III. RESULTS", "text": "During the experiments, we use finite state machines that only fix certain tones xi to predetermined values and prevent unison intervals from occurring within a single part (which would be impossible on the piano, for example).Visualization A known difficulty in particle filtering is the breakdown of particles into a small number of unique paths. However, we observe little evidence of this in our environment, which exhibits a reasonable degree of uncertainty in the final particle distribution (Figure 1, upper chart).As expected, the bar search (Figure 1, lower chart) behaves very differently, with the majority of the solutions being identical except for a few isolated time intervals."}, {"heading": "B. Quantitative Investigation", "text": "Both the beam search and the particle filtering algorithms have a single key free parameter S, the number of paths to store that act as accuracy for the computation time. In this subsection, we examine this trade-off. For reasons of reason, we limit our analysis to the sixteen shortest pieces (according to the number of notes) from these pieces in the MuseData test, that of Boulanger-Lewandowski et al. 2, which consist of exactly four voices (all of which have proven to be Bach chorales). For each piece, and for each piece, we fix m of the voices to the original piece, and apply our algorithms to select the remaining (4 \u2212 m) parts. We have done this in all possible ways, showing in Figure 2 the mean and standard error over all 16 \u00d7 C4m possibilities of two different quantities, as a function of the number of paths represented. < The two quantities shown are: Figure 2 l.h.s.: the probability that we fixed the parts are the probability that we fixed the probability that the parts are fixed."}, {"heading": "C. Human Listening Test", "text": "We also examined the effectiveness of our algorithms as assessed by human evaluators using an online survey using the Amazon Mechanical Turk2."}, {"heading": "1. Methodology", "text": "As a basis for the survey, we created harmonizations as in the previous section III B, setting the number of candidate paths S at 4096. We excluded two of the sixteen previously considered pieces due to the expanded use of a pure pedal point (repetition of a single note) in three out of four voices of the original compositions, which in most cases resulted in uninteresting limitations. For each of the remaining fourteen pieces and for m \u00b2 {0, 1, 2, 3} we harmonized the pieces with m of four voices. As before, we did this in all possible ways, both for the particle filter and for the beam detection method. Each of these editions was compared with the original piece from which it was derived. This comparison was performed by ten unique human subjects per piece (not the same ten for each piece; there were 67 unique answers to each piece; there were 67 unique participants), resulting in a total of 16 x 3n = 0 C 4 n x 2 x 200 x 200 minutes per piece (not the same ten for each piece; there were 67 unique answers to each piece; there were 67 unique participants)."}, {"heading": "2. Findings", "text": "A summary of the results is presented in Figure 3, which presents frequentistic confidence intervals on the unknown binomial probability.3 The clearest result is that the beam search algorithm without fixed parts tends to produce worse results, in line with the experience of our informal experiment with the beam search approach, which, in the absence of fixed notes, tended to produce excessively regular patterns with long sequences of repeated notes, etc. This is not a flawed result, but a natural consequence of maximizing sequence probability rather than filtering from the distribution.3 It is worth noting that this excessively regular beam search behavior can be observed not only in this case of unconditional sampling, but also in pieces where the parts attached to this probability of distribution are relatively insufficient."}, {"heading": "3. Discussion", "text": "One goal of our work is to create tools that facilitate the further development of the musical art form. We believe that this is possible through creative manipulation3 informal thought experiment: Consider the stochastic relationship yi = xi + N (0, 1). We imagine the analogy that the xi represents the temporal sequence and pitch of a set of notes ({yi} ni = 1 | {xi} x = 1.of the constraint set by skilled people. Ideally, we would use the superhuman ability of the computer to simmer through a large number of possible solutions. In this way, we create new musical forms that are too complex and too closely linked to human investigation. The evaluation of such a scheme probably goes beyond the current framework."}, {"heading": "IV. CONCLUSIONS", "text": "We presented algorithms for combining complex probabilistic models of polyphonic music with human input. We presented human input as a finite state machine that accepts permitted compositions, a limitation that is fairly general and yet susceptible to both sequential Monte Carlo sampling (to sampling from implicit conditional distribution) and beam search optimization (to maximizing the same conditional distribution).We demonstrated the effectiveness of the methods both quantitatively and through a listening experiment with human subjects. If the limitations are very permissive, it seems that conditional sampling is preferable to probability maximization, as the latter tends to produce excessively regular results in this case. Furthermore, both approaches lead to a different style of musical result, as the accompanying audio example shows."}, {"heading": "Appendix A: Sequential Monte Carlo Details", "text": "We describe detailed sequential sampling methods. In Section A 1 we look at partially observed sequences, and then in Section A 2 we expand them to more general constraints represented by an arbitrary finite state machine."}, {"heading": "1. Partially Observed Sequences", "text": "Let x1: n be a random sequence drawn from the NonMarkov process with discrete state space = 1: 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 (sample (1: 1: n) = 1 = 1 = 1 = 1: 1 (sample) = 1 = 1 (sample) = 1: 1 (sample) = 1: 1 (sample), which can be included in condition fi, the respective distribution of all previous states x1: i \u2212 1. Our goal is to calculate the back part of x1: n with partial observations x. Let zi be 1 if xi and 0 are otherwise observed. The rear distribution of the unobserved part is: p x x x: 1 x x x: 1 x x: 1 x x x."}, {"heading": "2. General Constraints", "text": "Here we extend the set-up of the previous section to the more general case of sampling with the hard constraint that the sampled sequence lies within a particular regular language. In particular, we want an example from (A) (x1: n), p (1: n), p (1: n), p (x1: n), p (1: n), p (1: n), p (1: n), p (1: n), p (1: n), p (1: n), p (1: n), p (1: n), p (1: n), p (1: n), p (1: n), p (1: n), x (1: n), x (1: n), x (1: n), p (1: n), x (1: n), p (1: n), p (1: n), p (1: n), p (1: n), p (1: n), p (1: n), p (1: n), p (1: n), p (1: n), x (1: n), x (1: n), x (1: n), x (1: n), x (1: n), x (1: n), x (1: n), p (1: n), x (1: n), x (1: n), x (1: n), x (1: n), x (1: n), x (1: n), x (1: n), x (1: n), x (1: n), x (1: n), p (1: n), x (1: n), x (1: n), x (1: n), x (1: n), x (1: n), x (1: n), x (1: n), x (1: n), x (1: n), x (1: n), x (1: n), x (1: n), p (1: n), x (1: n), x (1: n), p (1: n), x (1"}], "references": [], "referenceMentions": [], "year": 2016, "abstractText": "Sequence modeling with neural networks has lead to powerful models of symbolic music data. We address the problem of exploiting these models to reach creative musical goals. To this end we generalise previous work, which sampled Markovian sequence models under the constraint that the sequence belong to the language of a given finite state machine. We consider more expressive non-Markov models, thereby requiring approximate sampling which we provide in the form of an efficient sequential Monte Carlo method. In addition we provide and compare with a beam search strategy for conditional probability maximisation. Our algorithms are capable of convincingly re-harmonising famous musical works. To demonstrate this we provide visualisations, quantitative experiments, a human listening test and illustrative audio examples. We find both the sampling and optimisation procedures to be effective, yet complementary in character. For the case of highly permissive constraint sets, we find that sampling is to be preferred due to the overly regular nature of the optimisation based results.", "creator": "LaTeX with hyperref package"}}}