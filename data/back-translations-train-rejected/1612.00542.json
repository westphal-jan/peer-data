{"id": "1612.00542", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Dec-2016", "title": "Breast Mass Classification from Mammograms using Deep Convolutional Neural Networks", "abstract": "Mammography is the most widely used method to screen breast cancer. Because of its mostly manual nature, variability in mass appearance, and low signal-to-noise ratio, a significant number of breast masses are missed or misdiagnosed. In this work, we present how Convolutional Neural Networks can be used to directly classify pre-segmented breast masses in mammograms as benign or malignant, using a combination of transfer learning, careful pre-processing and data augmentation to overcome limited training data. We achieve state-of-the-art results on the DDSM dataset, surpassing human performance, and show interpretability of our model.", "histories": [["v1", "Fri, 2 Dec 2016 02:06:15 GMT  (4891kb,D)", "http://arxiv.org/abs/1612.00542v1", "NIPS 2016 ML4HC Workshop"]], "COMMENTS": "NIPS 2016 ML4HC Workshop", "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["daniel l\\'evy", "arzav jain"], "accepted": false, "id": "1612.00542"}, "pdf": {"name": "1612.00542.pdf", "metadata": {"source": "CRF", "title": "Breast Mass Classification from Mammograms using Deep Convolutional Neural Networks", "authors": ["Daniel L\u00e9vy"], "emails": ["danilevy@cs.stanford.edu", "ajain@cs.stanford.edu"], "sections": [{"heading": "1 Introduction", "text": "According to the International Agency for Research on Cancer, breast cancer is responsible for 22.9% of invasive cancers and 13.7% of cancer-related deaths in women worldwide [5]. In the United States, one in eight women is expected to develop invasive breast cancer during their lifetime [7]. Routine mammography is standard for screening and detecting breast cancer before biopsy, but it is still a manual process prone to human error due to high variability in mass occurrence [2] and low signal-to-noise ratio, and can therefore cause unnecessary biopsies or worse missed malignant masses. Moreover, effectiveness is often strongly correlated to radiological expertise and workload [10]. Convolutionary Neural Networks (CNN) have achieved impressive results in processing computer visions that include classification [16], object recognition [11] and mass segmentation."}, {"heading": "2 Related Work", "text": "While medical images differ significantly from natural images, traditional feature-engineering techniques such as Scale-Invariant Feature Transform (SIFT) and Histogram of Oriented Gradients (HOG) have found application and success in applying to medical images. More recently, learning-based approaches using CNNs have begun to perform impressively in medical tasks such as detecting breast pathologies in X-rays and CT scans [3, 23] and detecting breast lymph nodes and classifying interstitial lung disease [20]. In the context of mammography, [8, 9] detect breast masses using a combination of R-CNN and random forests. Several papers deal with the problem of classifying breast lesions, but typically take a multi-step approach. [24] Extracts hand-made semantic (such as calcification) and textual features, and [6] classifies a complete mammogram of information through the extraction of each feature from the conference."}, {"heading": "3 Dataset", "text": "In our experiments, we use the Digital Database for Screening Mammography (DDSM) [4], a collaboratively managed public dataset from the University of South Florida. It includes approximately 2500 studies, each containing both mediolateral oblique (MLO) and craniocaudal (CC) views of each breast. Each image is grayscale and is accompanied by a mask indicating the region of presegmented mass, if any. Examples of benign and malignant masses are shown in Fig. 1. We only look at mammograms that contain masses, resulting in 1820 images of 997 patients, and randomly divide them into patient training, validation and test kits (80%, 10% and 10% of the full dataset), balancing validation and test kits."}, {"heading": "4 Methods", "text": "We train three different CNN architectures for classifying breast mass and analyze the impact of a number of models that we describe below."}, {"heading": "4.1 CNN architectures", "text": "We evaluate three network architectures: a flat CNN (the base model), an AlexNet [16] and a GoogLeNet [22]. For both AlexNet and GoogLeNet, we use the same base architecture as the original, but replace the last fully connected (FC) layer to output two classes. We also remove the two auxiliary classifiers from the GoogLeNet that have impaired our training in practice. The architecture of the baseline model is inspired by the early layers of AlexNet [16]. Additionally, we use batch normalization [13]. The network takes a 224 x 224 x 3 image as input. It consists of 3 revolutionary blocks consisting of 3 x 3 x 3 x 3 Convolutions - Batch Norm - ReLU - Max Pooling, each with 32, 32 and 64 filters, followed by 3 FC layers of size 128, 64 and 2. The last layer is a soft-max layer for binary classification [We use weighting-XU functions to update] and a 64-X15."}, {"heading": "4.2 Aspects of model analysis", "text": "We analyze the effects of initializing networks with pre-training on the ImageNet dataset [19], and then fine-tuning mammography images. For the AlexNet model, we initialize the Convolutionary Layers with upstream weights and a smaller learning rate multiplier of 0.1 and randomly initialize the 3 FC layers. For the GoogLeNet model, we use the same weight initialization scheme. We use a learning rate multiplier of 0.1 for the layers before the Inception _ 5a module, 1 for the Inception _ 5a and Inception _ 5b modules, and 10 for the last FC layer for more aggressive learning. We train the AlexNet with the base learning rate 10 \u2212 3 and the dropout rate 0.5. We train the GoogLeNet with Vanilla SGD, the base learning rate 10 \u2212 2, and the dropout rate 0.2."}, {"heading": "5 Results", "text": "First, we present empirical analysis of our model design using the AlexNet base architecture, then we show quantitative results of our best models. Finally, we use saliency map visualization techniques to ensure the interpretability of the model. All experiments are performed with Caffe [14], and the analyses and results are presented on the validation and test sets."}, {"heading": "5.1 Empirical analysis", "text": "The effectiveness of CNN-based image representations learned from large-scale annotated data sets has proven to be a useful form of pre-training that can be effectively applied to other computer vision tasks with limited training data [18]. More recently, properties derived from natural images have proven effective for classifying medical images [3, 20, 23]. In Table 1, we emphatically confirm this claim by showing that a finely tuned AlexNet is significantly better than our base model. Context Influence To understand the impact of context on mass, we fine-fine-tune an AlexNet to two different sets of data - one with fixed padding and the other with proportional padding. The results in Table 2 show that proportional padding contains a greater signal for classification, and we consequently use this for the remaining experiments. Influence of data augmentation Limited amounts of training data are a more common bottleneck when evaluating data loss from data machines for learning problems."}, {"heading": "5.2 Performance", "text": "Our final results based on the model selection described in paragraph 5.1 and all base architectures are presented in Table 3. GoogLeNet significantly outperforms the other models, is also better suited for fine-tuning, and is less susceptible to overfitting due to its relatively small number of parameters, about 5 million compared to 100 million for AlexNet.An important metric for diagnostic applications is to maximize recall, as the cost of a false negative (patient who has not been diagnosed) is much higher than a false positive (an additional biopsy).Our best model achieves 0.934 recall responses at 0.924 accuracy, ranking human performance in a study showing a radiologist recall between 0.745 and 0.923 [10], a result that is promising for the real-world use of such models in clinical practice."}, {"heading": "5.3 Interpretability", "text": "Deep learning models are often incomprehensible and therefore difficult to apply in practice in medical environments. [21] describe a method for visualizing highlighting maps that show the regions of an image to which the network is sensitive when making predictions, by calculating the image gradient with respect to the unstandardized class values. Regions with larger gradients indicate a higher contribution to prediction (brighter in Fig. 3). Both AlexNet and GoogLeNet learn to pay attention to the edges of the mass, which is a high-signal criterion for diagnosis, while also paying attention to the context."}, {"heading": "6 Conclusion", "text": "In this paper, we propose an end-to-end deep-learning model for classifying already mammogram breast masses. We demonstrate how careful pre-processing, data enlargement, and transfer learning can overcome the data bottleneck common to medical computer vision tasks, and also provide a method for improving the interpretability of network predictions. Our approach achieves state-of-the-art results, outperforms trained radiologists, and interpretability allows for more convenient adoption into real-world environments. Future work will include exploring other architectures and integrating attention mechanisms that are harder to train, but could offer even more concrete interpretations."}, {"heading": "Acknowledgements", "text": "We thank Justin Johnson for continuous feedback and guidance throughout the project and Serena Yeung for revealing comments on the draft. The authors also thank the AWS Educate program for generously providing free instances with GPUs."}], "references": [{"title": "Representation learning for mammography mass lesion classification with convolutional neural networks", "author": ["J. Arevalo", "F.A. Gonz\u00e1lez", "R. Ramos-Poll\u00e1n", "J.L. Oliveira", "M.A.G. Lopez"], "venue": "Computer methods and programs in biomedicine, 127:248\u2013257", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2016}, {"title": "Digital mammographic computer aided diagnosis (cad) using adaptive level set segmentation", "author": ["J.E. Ball", "L.M. Bruce"], "venue": "2007 29th Annual International Conference of the IEEE Engineering in Medicine and Biology Society, pages 4973\u20134978. IEEE", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2007}, {"title": "Chest pathology detection using deep learning with non-medical training", "author": ["Y. Bar", "I. Diamant", "L. Wolf", "S. Lieberman", "E. Konen", "H. Greenspan"], "venue": "2015 IEEE 12th International Symposium on Biomedical Imaging (ISBI), pages 294\u2013297. IEEE", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}, {"title": "The digital database for screening mammography", "author": ["K. Bowyer", "D. Kopans", "W. Kegelmeyer", "R. Moore", "M. Sallam", "K. Chang", "K. Woods"], "venue": "Third international workshop on digital mammography, volume 58, page 27", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1996}, {"title": "et al", "author": ["P. Boyle", "B. Levin"], "venue": "World cancer report 2008. IARC Press, International Agency for Research on Cancer", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2008}, {"title": "Unregistered multiview mammogram analysis with pre-trained deep learning models", "author": ["G. Carneiro", "J. Nascimento", "A.P. Bradley"], "venue": "International Conference on Medical Image Computing and Computer-Assisted Intervention, pages 652\u2013660. Springer International Publishing", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "Breast cancer statistics", "author": ["C. DeSantis", "J. Ma", "L. Bryan", "A. Jemal"], "venue": "2013. CA: a cancer journal for clinicians, 64(1):52\u201362", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "Automated mass detection in mammograms using cascaded deep learning and random forests", "author": ["N. Dhungel", "G. Carneiro", "A.P. Bradley"], "venue": "Digital Image Computing: Techniques and Applications (DICTA), 2015 International Conference on, pages 1\u20138. IEEE", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep learning and structured prediction for the segmentation of mass in mammograms", "author": ["N. Dhungel", "G. Carneiro", "A.P. Bradley"], "venue": "International Conference on Medical Image Computing and Computer-Assisted Intervention, pages 605\u2013612. Springer International Publishing", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2015}, {"title": "et al", "author": ["J.G. Elmore", "S.L. Jackson", "L. Abraham", "D.L. Miglioretti", "P.A. Carney", "B.M. Geller", "B.C. Yankaskas", "K. Kerlikowske", "T. Onega", "R.D. Rosenberg"], "venue": "Variability in interpretive performance at screening mammography and radiologists\u2019 characteristics associated with accuracy 1. Radiology, 253(3):641\u2013651", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2009}, {"title": "Rich feature hierarchies for accurate object detection and semantic segmentation", "author": ["R. Girshick", "J. Donahue", "T. Darrell", "J. Malik"], "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition, pages 580\u2013587", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2014}, {"title": "Understanding the difficulty of training deep feedforward neural networks", "author": ["X. Glorot", "Y. Bengio"], "venue": "Aistats, volume 9, pages 249\u2013256", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2010}, {"title": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "author": ["S. Ioffe", "C. Szegedy"], "venue": "arXiv preprint arXiv:1502.03167", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2015}, {"title": "Caffe: Convolutional architecture for fast feature embedding", "author": ["Y. Jia", "E. Shelhamer", "J. Donahue", "S. Karayev", "J. Long", "R. Girshick", "S. Guadarrama", "T. Darrell"], "venue": "Proceedings of the 22nd ACM international conference on Multimedia, pages 675\u2013678. ACM", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2014}, {"title": "Adam: A method for stochastic optimization", "author": ["D. Kingma", "J. Ba"], "venue": "arXiv preprint arXiv:1412.6980", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2014}, {"title": "ImageNet Classification with Deep Convolutional Neural Networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "NIPS", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2012}, {"title": "Fully convolutional networks for semantic segmentation", "author": ["J. Long", "E. Shelhamer", "T. Darrell"], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 3431\u20133440", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning and transferring mid-level image representations using convolutional neural networks", "author": ["M. Oquab", "L. Bottou", "I. Laptev", "J. Sivic"], "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition, pages 1717\u20131724", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2014}, {"title": "et al", "author": ["O. Russakovsky", "J. Deng", "H. Su", "J. Krause", "S. Satheesh", "S. Ma", "Z. Huang", "A. Karpathy", "A. Khosla", "M. Bernstein"], "venue": "Imagenet large scale visual recognition challenge. International Journal of Computer Vision, 115(3):211\u2013252", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep convolutional neural networks for computer-aided detection: Cnn architectures", "author": ["H.-C. Shin", "H.R. Roth", "M. Gao", "L. Lu", "Z. Xu", "I. Nogues", "J. Yao", "D. Mollura", "R.M. Summers"], "venue": "dataset characteristics and transfer learning. IEEE transactions on medical imaging, 35(5): 1285\u20131298", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2016}, {"title": "Deep inside convolutional networks: Visualising image classification models and saliency maps", "author": ["K. Simonyan", "A. Vedaldi", "A. Zisserman"], "venue": "arXiv preprint arXiv:1312.6034", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2013}, {"title": "Going deeper with convolutions", "author": ["C. Szegedy", "W. Liu", "Y. Jia", "P. Sermanet", "S. Reed", "D. Anguelov", "D. Erhan", "V. Vanhoucke", "A. Rabinovich"], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1\u20139", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2015}, {"title": "Off-the-shelf convolutional neural network features for pulmonary nodule detection in computed tomography scans", "author": ["B. van Ginneken", "A.A. Setio", "C. Jacobs", "F. Ciompi"], "venue": "In 2015 IEEE 12th International Symposium on Biomedical Imaging (ISBI),", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2015}, {"title": "Discrimination of breast cancer with microcalcifications on mammography by deep learning", "author": ["J. Wang", "X. Yang", "H. Cai", "W. Tan", "C. Jin", "L. Li"], "venue": "Scientific reports, 6:27327", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2016}], "referenceMentions": [{"referenceID": 4, "context": "7% of cancer-related deaths in women worldwide [5].", "startOffset": 47, "endOffset": 50}, {"referenceID": 6, "context": ", 1 in 8 women is expected to develop invasive breast cancer over the course of her lifetime [7].", "startOffset": 93, "endOffset": 96}, {"referenceID": 1, "context": "However, it is still a manual process, prone to human error due to high variability in mass appearance [2] and low signal-to-noise ratio, and thus can cause unnecessary biopsies or worse, missed malignant masses.", "startOffset": 103, "endOffset": 106}, {"referenceID": 9, "context": "Furthermore, efficacy is often highly correlated with radiologist expertise and workload [10].", "startOffset": 89, "endOffset": 93}, {"referenceID": 15, "context": "Convolutional Neural Networks (CNN) have achieved impressive results on computer visions tasks spanning classification [16], object detection [11], and segmentation [17].", "startOffset": 119, "endOffset": 123}, {"referenceID": 10, "context": "Convolutional Neural Networks (CNN) have achieved impressive results on computer visions tasks spanning classification [16], object detection [11], and segmentation [17].", "startOffset": 142, "endOffset": 146}, {"referenceID": 16, "context": "Convolutional Neural Networks (CNN) have achieved impressive results on computer visions tasks spanning classification [16], object detection [11], and segmentation [17].", "startOffset": 165, "endOffset": 169}, {"referenceID": 0, "context": "For breast mass diagnosis, deep learning techniques have been explored [1, 6, 8, 9, 24], but never in a fully end-to-end manner (directly classifying from pixel space) because of the scarcity of available data and lack of interpretability.", "startOffset": 71, "endOffset": 87}, {"referenceID": 5, "context": "For breast mass diagnosis, deep learning techniques have been explored [1, 6, 8, 9, 24], but never in a fully end-to-end manner (directly classifying from pixel space) because of the scarcity of available data and lack of interpretability.", "startOffset": 71, "endOffset": 87}, {"referenceID": 7, "context": "For breast mass diagnosis, deep learning techniques have been explored [1, 6, 8, 9, 24], but never in a fully end-to-end manner (directly classifying from pixel space) because of the scarcity of available data and lack of interpretability.", "startOffset": 71, "endOffset": 87}, {"referenceID": 8, "context": "For breast mass diagnosis, deep learning techniques have been explored [1, 6, 8, 9, 24], but never in a fully end-to-end manner (directly classifying from pixel space) because of the scarcity of available data and lack of interpretability.", "startOffset": 71, "endOffset": 87}, {"referenceID": 23, "context": "For breast mass diagnosis, deep learning techniques have been explored [1, 6, 8, 9, 24], but never in a fully end-to-end manner (directly classifying from pixel space) because of the scarcity of available data and lack of interpretability.", "startOffset": 71, "endOffset": 87}, {"referenceID": 2, "context": "More recently, deep learning-based approaches using CNNs have begun to achieve impressive performance on medical tasks such as chest pathology identification in X-Ray and CT [3, 23], and thoraco-abdominal lymph node detection and interstitial lung disease classification [20].", "startOffset": 174, "endOffset": 181}, {"referenceID": 22, "context": "More recently, deep learning-based approaches using CNNs have begun to achieve impressive performance on medical tasks such as chest pathology identification in X-Ray and CT [3, 23], and thoraco-abdominal lymph node detection and interstitial lung disease classification [20].", "startOffset": 174, "endOffset": 181}, {"referenceID": 19, "context": "More recently, deep learning-based approaches using CNNs have begun to achieve impressive performance on medical tasks such as chest pathology identification in X-Ray and CT [3, 23], and thoraco-abdominal lymph node detection and interstitial lung disease classification [20].", "startOffset": 271, "endOffset": 275}, {"referenceID": 7, "context": "In the context of mammography, [8, 9] detect breast masses using a combination of R-CNN and random forests.", "startOffset": 31, "endOffset": 37}, {"referenceID": 8, "context": "In the context of mammography, [8, 9] detect breast masses using a combination of R-CNN and random forests.", "startOffset": 31, "endOffset": 37}, {"referenceID": 23, "context": "[24] extracts hand-engineered semantic (such as calcification) and textual features, and [6] classifies a full mammogram by extracting features from each view of the breast", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "[24] extracts hand-engineered semantic (such as calcification) and textual features, and [6] classifies a full mammogram by extracting features from each view of the breast", "startOffset": 89, "endOffset": 92}, {"referenceID": 0, "context": "[1] performs extensive pre-processing using domain knowledge before training a CNN.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "In our experiments, we use the Digital Database for Screening Mammography (DDSM) [4], a collaboratively maintained public dataset at the University of South Florida.", "startOffset": 81, "endOffset": 84}, {"referenceID": 15, "context": "We evaluate three network architectures: a shallow CNN (the baseline model), an AlexNet [16] and a GoogLeNet [22].", "startOffset": 88, "endOffset": 92}, {"referenceID": 21, "context": "We evaluate three network architectures: a shallow CNN (the baseline model), an AlexNet [16] and a GoogLeNet [22].", "startOffset": 109, "endOffset": 113}, {"referenceID": 15, "context": "The baseline model\u2019s architecture is inspired by the early layers of AlexNet [16].", "startOffset": 77, "endOffset": 81}, {"referenceID": 12, "context": "We additionally use batch normalization [13].", "startOffset": 40, "endOffset": 44}, {"referenceID": 11, "context": "We use ReLU activation functions, Xavier [12] weight initialization, and the Adam [15] update rule with a base learning rate of 10\u22123 and batch size 64.", "startOffset": 41, "endOffset": 45}, {"referenceID": 14, "context": "We use ReLU activation functions, Xavier [12] weight initialization, and the Adam [15] update rule with a base learning rate of 10\u22123 and batch size 64.", "startOffset": 82, "endOffset": 86}, {"referenceID": 18, "context": "2 Aspects of model analysis Transfer learning We analyze the effect of initializing networks with pre-training on the ImageNet dataset [19], and then fine-tuning on mammography images.", "startOffset": 135, "endOffset": 139}, {"referenceID": 13, "context": "All experiments are implemented with Caffe [14], and the analysis and results are presented on the validation and test sets, respectively.", "startOffset": 43, "endOffset": 47}, {"referenceID": 17, "context": "Effectiveness of transfer learning CNN-based image representations learned on large-scale annotated datasets have proven to to be a useful form of pre-training that can be effectively transferred to other computer vision tasks with limited training data [18].", "startOffset": 254, "endOffset": 258}, {"referenceID": 2, "context": "More recently, low-level features learned from natural images have shown to be effective for medical image classification [3, 20, 23].", "startOffset": 122, "endOffset": 133}, {"referenceID": 19, "context": "More recently, low-level features learned from natural images have shown to be effective for medical image classification [3, 20, 23].", "startOffset": 122, "endOffset": 133}, {"referenceID": 22, "context": "More recently, low-level features learned from natural images have shown to be effective for medical image classification [3, 20, 23].", "startOffset": 122, "endOffset": 133}, {"referenceID": 9, "context": "923 [10].", "startOffset": 4, "endOffset": 8}, {"referenceID": 20, "context": "[21] describe a methodology to visualize saliency maps which show the regions of an image the network is sensitive to when making predictions.", "startOffset": 0, "endOffset": 4}], "year": 2016, "abstractText": "Mammography is the most widely used method to screen breast cancer. Because of its mostly manual nature, variability in mass appearance, and low signal-to-noise ratio, a significant number of breast masses are missed or misdiagnosed. In this work, we present how Convolutional Neural Networks can be used to directly classify pre-segmented breast masses in mammograms as benign or malignant, using a combination of transfer learning, careful pre-processing and data augmentation to overcome limited training data. We achieve state-of-the-art results on the DDSM dataset, surpassing human performance, and show interpretability of our model.", "creator": "LaTeX with hyperref package"}}}