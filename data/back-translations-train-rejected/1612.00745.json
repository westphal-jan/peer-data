{"id": "1612.00745", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Dec-2016", "title": "Cognitive Deep Machine Can Train Itself", "abstract": "Machine learning is making substantial progress in diverse applications. The success is mostly due to advances in deep learning. However, deep learning can make mistakes and its generalization abilities to new tasks are questionable. We ask when and how one can combine network outputs, when (i) details of the observations are evaluated by learned deep components and (ii) facts and confirmation rules are available in knowledge based systems. We show that in limited contexts the required number of training samples can be low and self-improvement of pre-trained networks in more general context is possible. We argue that the combination of sparse outlier detection with deep components that can support each other diminish the fragility of deep methods, an important requirement for engineering applications. We argue that supervised learning of labels may be fully eliminated under certain conditions: a component based architecture together with a knowledge based system can train itself and provide high quality answers. We demonstrate these concepts on the State Farm Distracted Driver Detection benchmark. We argue that the view of the Study Panel (2016) may overestimate the requirements on `years of focused research' and `careful, unique construction' for `AI systems'.", "histories": [["v1", "Fri, 2 Dec 2016 16:49:07 GMT  (6235kb,D)", "http://arxiv.org/abs/1612.00745v1", "14 pages, 8 figures"]], "COMMENTS": "14 pages, 8 figures", "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.NE", "authors": ["andr\\'as l\\h{o}rincz", "m\\'at\\'e cs\\'akv\\'ari", "\\'aron f\\'othi", "zolt\\'an \\'ad\\'am milacski", "r\\'as s\\'ark\\'any", "zolt\\'an t\\h{o}s\\'er"], "accepted": false, "id": "1612.00745"}, "pdf": {"name": "1612.00745.pdf", "metadata": {"source": "CRF", "title": "COGNITIVE DEEP MACHINE CAN TRAIN ITSELF", "authors": ["A. L\u0151rincz"], "emails": [], "sections": [{"heading": null, "text": "Keywords: deep learning, knowledge-based system, component recognition, episodic description"}, {"heading": "1 INTRODUCTION", "text": "The reason why it could come to this is due to the fact that most people are able to survive themselves. (...) Most people are able to survive themselves. (...) Most people are able to survive themselves. (...) Most people are able to survive themselves. (...) Most people are able to survive themselves. (...) Most people are able to survive themselves. (...) Most people are able to survive themselves. (...) Most people are able to survive themselves. (...) Most people are able to survive themselves. (...) Most people are able to survive themselves. (...) Most people are able to survive themselves. (...) Most people are able to survive themselves. (...) Most people are able to survive themselves. \"(...) Most people are able to survive themselves.\" (...) Most people are able to survive themselves. \""}, {"heading": "2 METHODS", "text": "In the following, we describe outlier detection and temporal segmentation schemes (Section 2.1-2.2), optical flow and its unattended way of finding components (Section 2.3), followed by the list of pre-formed deep networks we use and their fine-tuning by self-monitoring (Section 2.4)."}, {"heading": "2.1 ROBUST PRINCIPAL COMPONENT ANALYSIS", "text": "It is well known that classical Principal Component Analysis (PCA) essentially works with the standard estimation of ECF (Frobenius) and thus decays in the presence of additional coarse but sparse outliers. Cand\u00e8s et al. (2011) showed that it is possible to extend this architecture by a term that collects such components and thus separates what they call Robust Principal Component Analysis (RPCA). Accordingly, in view of X-RD \u00d7 T, the following convex optimization problem can be defined: min U, S1 2-X-U \u2212 U-S-2F + In so far (U), 1 + \u00b5-Vec (S), (1) i.e. U-RD \u00d7 T approaches X with low rank (via the first '1 regulator for its singular value vector), while S-RD \u00d7 T represents an additional sparse outlier (due to the second' 1 regulation problem)."}, {"heading": "2.2 GROUP FUSED LASSO", "text": "Detection of convex multiple change points for multivariate time series is also based on \"1,2 regulated Frobenius standard estimates,\" whereby the regulator acts on the finite difference of the optimization variables, i.e. for input X-RD-T and weight matrix W-RD-T, Solution: min V1 2-W-W-W-W-W-W-W-W-W-W-W-T-T-p-T = 1-VQ, t-2 (2) This problem is often referred to as Group Fused LASSO (Bleakley & Vert, 2011)."}, {"heading": "2.3 OPTICAL FLOW AND COMPONENT SEARCH", "text": "We used Optical Flow (Lucas & Kanade, 1985), which was implemented in OpenCV4, to search for components over time by estimating the movement of the Bounding Boxes between adjacent frames in the video. First, we used an object detector (Section 2.4) to determine the coordinates of the Bounding Boxes for each frame, then we scaled the Bounds to identical size. Next, for the original frames, we estimated the movement of the feature points within the Bounding Boxes. This allowed for similarity measurement between successive frames. If the similarity was above a threshold, we grouped Bounding Boxes together, doing so over several time steps. Finally, we also merged groups that were similar. The original method of (Lucas & Kanade, 1985) was improved in many ways, including pyramid-like ratings that start at low resolution and work on higher, Dense Optical Flow Methods 5 and deep architectures, including combinations used in Fischer's 2015 and 30 illustrations."}, {"heading": "2.4 PRE-TRAINED SUPERVISED DEEP NETWORKS", "text": "The introduction and details of the theory of different networks can be found in the recent book by Goodfellow et al. (2016). Consequently, we refer the interested reader to this excellent work and limit this technical report to the collection of references of the papers and associated software tools that we have used in the course of our work: 1. Faster R-CNN6 (Ren et al., 2015) for object suggestions; 2. Regional Fully Convolutional Network7 (Dai et al., 2016) for object and hand detection; 3. Convolutional Pose Machine8 (Wei et al., 2016) for body position detection (we have also injected hand detection to improve the thermal maps of this network); 4. Libfacetracker (To Kribfacetracker et al al al al al al al al al al al al al al al al al al al al al al al al al al., 2016) for face detection."}, {"heading": "2.5 KAGGLE STATE FARM DISTRACTED DRIVER DETECTION DATASET", "text": "We conducted and evaluated our methodology at the Kaggle State Farm Distracted Driver Detection Challenge, which was completed a few months ago on August 1, 201614. The database contains 26 subjects, each with a video. The original benchmark consisted of frames, but was later sorted and assembled into videos by Gilberto Titericz Junior15. The recordings consist of driving scenarios viewed from the passenger seat with the camera facing the driver. The world outside the window is foggy and bright; the driver's chair, body and dashboard barely move; the labels of the State Farm Distracted Driver Detection Challenge are ambiguous and can be misleading; for example, the image of Fig. 2 may correspond to safe driving when the driver looks back to overcome the boundaries of the mirrors and directly monitor the blind spots thereof; on the other hand, there are samples with safe labels when the passenger seat is distracted and the system is clearly looking at the driver's destination, and the driver is aware of it."}, {"heading": "3 EXPERIMENTS AND RESULTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 PIXEL BASED ROBUST PRINCIPAL COMPONENT ANALYSIS", "text": "The following are examples from the RPCA analysis (Section 2.1), which was applied to each grayscale video independently with standard parameters. Figure 3 consists of four groups of three sub-figures. The left, middle and right sub-figures represent the original image, its low rank or outlier components. A large portion of the images are stationary; these parts form the low-dimensional sub-space of the RPCA analysis. The outliers usually correspond to short time intervals within driving phases, such as \"radio operation\" (3 (a), \"SMS with the right hand\" (3 (b), \"drinking\" (3 (c), \"talking to the passenger\" (3 (d) and a few more. Note that both the outlier parts and the low-dimensional sub-space parts differ: they are projections on the PCA sub-space, and these projections depend on the inputs. 14 Database: https: / / kaggle.com / just-farm / detected-state: http: / kaggle.com /"}, {"heading": "3.2 EPISODIC SEGMENTATION WITH GROUP FUSED LASSO", "text": "Similar to outliers that are correlated with floor markings in Section 3.1, we point out that the driver's body positions are also linked, and such information can be determined using a pose detector such as the Convolutional Pose Machine (Section 2.4). We applied the Convolutional Pose Machine to each original image independently of each other to extract the coordinates of the arm joints. The network was primarily prepared for frontal 2D body samples, but still performs reasonably well for side views and upper body configurations. As network outputs were extremely loud over time, we attempted to extract the underlying time segments with a constant pose using the Group Fused LASSO (Section 2.2).The result - a near-perfect match with ground truth markings - was normalized and weighted despite the high proportion of noise. Since CVXPY Diamond & Boyd, 2016, did not really provide a sparse solution, the strengths were further attenuated."}, {"heading": "3.3 EPISODIC SEGMENTATION WITH OPTICAL FLOW", "text": "We applied the optical flow (Section 2.3) with the region-based hand detector Fully Convolutional Network (Section 2.4) to raw videos. Figure 5 illustrates the results and our point of view. Figure (a) represents an almost periodic movement within a larger image. In the Kaggle database, it is referred to as \"drinking\": the driver holds a cup as he begins and takes turns to stop drinking. As described in Section 2.3, the relevant parts of the images are segmented by our hand detector, the motion coherence is made visible in Figures (b) - (d) by the green arrows indicating the movement of each feature. The arrows change direction in the two drinking phases (not shown) and the optical flow itself can serve episodic segmentation, especially when dense optical flow algorithms are used."}, {"heading": "3.4 RULE-BASED COMBINATION OF OBJECT DETECTION AND THE CONVOLUTIONAL POSE MACHINE", "text": "This year it is more than ever before."}, {"heading": "4 DISCUSSION", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 SELF-TRAINING BY DEEP NETWORKS HAVING BACKING KNOWLEDGE BASES", "text": "The results of the various input-output systems (e.g. deep networks) can be used for self-training. Our example is the Convolutionary Positioning Machine and the Hand Detector: We improved their performance by linking them together (Section 3.4). The Cognitive Machine can use high-score poses and hand detector outputs to improve the detection of the left and right hand within the Kaggle scenarios. It can know that in the context of driving a hand the most time is at the steering wheel. It can use the information to give the left and right hand and the training itself the correct labels. It can go further by applying the same conclusion and injecting the information about the left and / or right hand into the Convolutionary Positioning Machine. The derived pose can serve the further training of the Convolutionary Positioning Machine within the benchmark scenarios. We note that the above line of thought is one of many other general methods that can better serve the goal of having a common climate, whereby the objective is to successfully match the actual one."}, {"heading": "4.2 THE ENGINEERING VIEW: BACK TO RULE BASED SYSTEMS", "text": "We can recognize the pose, separate the movements of the left and the right hand, one can follow the face and the hand, even with high precision. Object recognition can be raised to a high level, and thus the recognition of mobile phones, cups / cups should not be a big problem.The result of these considerations is that classification according to the Kaggle labels is a simple - rules-based - task that does not require further training. The importance of a label is sufficient for proper classification. In addition, one can filter the ambiguous cases, for example, when talking to the passenger and word processing takes place simultaneously. This is the main reason why we think that the Study Panel (2016) overestimates the complexity of developing new applications. It is not the deep technology alone that can serve new applications, but also the knowledge of the components and their relationships, i.e., the semantic and ontological knowledge that has been collected over many years."}, {"heading": "4.3 THE GESTALT VIEW", "text": "The principles we applied are the hundred-year-old design principles (Todorovic, 2008), also referred to as the design laws of grouping, such as proximity, similarity, continuity, closeness, and connectedness. They can be used by AI to detect spatio-temporal phenomena or episodes, to characterize and predict them, and, if possible, to compress them into meaningful concepts for human intelligence. Tactically, we took advantage of determinism when we used high values and temporal relationships from Optical Flow and Group Fused LASSO. The key hypothesis is that failed recognition and determinism together are powerful tools to learn when we recognize components and have (episodic) knowledge of their spatio-temporal relationships. From the point of view of learning, recognition can help us understand the object and learn its interactions, for example, that a phone can be picked up."}, {"heading": "4.4 COGNITION IN THE COGNITIVE DEEP MACHINE", "text": "In our view, a deep network is incapable of discerning. We think that cognition is more than input-output mapping, it includes the ability to think and uses reasoning to acquire knowledge. Note that we do not use the word understanding because it goes beyond our current formulation. Reasoning concerns considerations of the components, the reliability of the observations associated with them, and the spatio-temporal context. Cognition has at least five components: (i) holistic and component-oriented observations, e.g. through deep networks, (ii) failed detection of these observations, (ii) considerations of the best labels using the components observed, (iv) considerations of outliers and collecting such examples, and (v) self-training using the anomalies collected."}, {"heading": "4.5 OUTLOOK: REINFORCEMENT LEARNING", "text": "Supervised learning concerns input-output mapping. We think that there is a big difference between supervised learning of components, such as the case of the pose machine, and the unsupervised search for spatio-temporal structures. We think that the latter can be gradually constructed from basic elements using design principles, such as the horse, zebra, giraffe and cow, which look very similar but change in texture, length of neck, shape of body, including mane and hoof, and the environment in which they live (Section 1). Reduction of variables (here, components or spatio-temporal structures) can put attachment learning into work, since attachment learning, in the absence of such highly compressed factors, is limited to those that may be relevant to decision-making, explodes exponentially (section of components or spatio-temporal structures)."}, {"heading": "5 CONCLUSION", "text": "We looked at the development of deep learning technologies combined with traditional AI and component-based thinking. We provided examples through the State Farm Distracted Driver Detection benchmark. We argued that this benchmark requires only components and that they can be learned through in-depth learning in problems outside the benchmark itself. If we have these components, the benchmark requires no further learning, but reasoning, unattended anomaly detection, data collection related to the detected anomalies, searching for time segments, and finally self-training in the context of the Distracted Driver Detection problem. We concluded that novel applications can be addressed through artificial intelligence and that the bottleneck lies in sensory information, not in the learning system itself. We also argue that component-based design has several advantages: \u2022 it can work when some of the information is missing, such as when the hand is not visible; \u2022 it can be combined with enhanced learning to optimize decision-making."}, {"heading": "ACKNOWLEDGMENTS", "text": "This work was partially supported by the EIT Digital Grant No 16527 on Cyber-Physical Systems for Smart Factories."}], "references": [{"title": "Recognition-by-components: a theory of human image understanding", "author": ["Irving Biederman"], "venue": "Psychological Review,", "citeRegEx": "Biederman.,? \\Q1987\\E", "shortCiteRegEx": "Biederman.", "year": 1987}, {"title": "The Group Fused LASSO for Multiple Change-point Detection", "author": ["Kevin Bleakley", "Jean-Philippe Vert"], "venue": "arXiv preprint arXiv:1106.4199,", "citeRegEx": "Bleakley and Vert.,? \\Q2011\\E", "shortCiteRegEx": "Bleakley and Vert.", "year": 2011}, {"title": "Robust Principal Component Analysis", "author": ["Emmanuel J Cand\u00e8s", "Xiaodong Li", "Yi Ma", "John Wright"], "venue": "Journal of the ACM (JACM),", "citeRegEx": "Cand\u00e8s et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Cand\u00e8s et al\\.", "year": 2011}, {"title": "R-FCN: Object detection via region-based fully convolutional networks", "author": ["Jifeng Dai", "Yi Li", "Kaiming He", "Jian Sun"], "venue": "arXiv preprint arXiv:1605.06409,", "citeRegEx": "Dai et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Dai et al\\.", "year": 2016}, {"title": "CVXPY: A python-embedded modeling language for convex optimization", "author": ["Steven Diamond", "Stephen Boyd"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Diamond and Boyd.,? \\Q2016\\E", "shortCiteRegEx": "Diamond and Boyd.", "year": 2016}, {"title": "The Pascal Visual Object Classes (VOC) challenge", "author": ["Mark Everingham", "Luc Van Gool", "Christopher KI Williams", "John Winn", "Andrew Zisserman"], "venue": "International Journal of Computer Vision,", "citeRegEx": "Everingham et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Everingham et al\\.", "year": 2010}, {"title": "Flownet: Learning optical flow with convolutional networks", "author": ["Philipp Fischer", "Alexey Dosovitskiy", "Eddy Ilg", "Philip H\u00e4usser", "Caner Hazirbas", "Vladimir Golkov", "Patrick van der Smagt", "Daniel Cremers", "Thomas Brox"], "venue": "IEEE International Conference on Computer Vision (ICCV),", "citeRegEx": "Fischer et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Fischer et al\\.", "year": 2015}, {"title": "Deep learning. Book in preparation for MIT Press, 2016", "author": ["Ian Goodfellow", "Yoshua Bengio", "Aaron Courville"], "venue": "URL http://www.deeplearningbook.org", "citeRegEx": "Goodfellow et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2016}, {"title": "Visual Genome: Connecting language and vision using crowdsourced dense image annotations", "author": ["Ranjay Krishna", "Yuke Zhu", "Oliver Groth", "Justin Johnson", "Kenji Hata", "Joshua Kravitz", "Stephanie Chen", "Yannis Kalantidis", "Li-Jia Li", "David A Shamma"], "venue": "arXiv preprint arXiv:1602.07332,", "citeRegEx": "Krishna et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Krishna et al\\.", "year": 2016}, {"title": "Microsoft COCO: Common objects in context", "author": ["Tsung-Yi Lin", "Michael Maire", "Serge Belongie", "James Hays", "Pietro Perona", "Deva Ramanan", "Piotr Doll\u00e1r", "C Lawrence Zitnick"], "venue": "In European Conference on Computer Vision,", "citeRegEx": "Lin et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Lin et al\\.", "year": 2014}, {"title": "The Augmented Lagrange Multiplier Method for Exact Recovery of Corrupted Low-rank Matrices", "author": ["Zhouchen Lin", "Minming Chen", "Yi Ma"], "venue": "arXiv preprint arXiv:1009.5055,", "citeRegEx": "Lin et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Lin et al\\.", "year": 2010}, {"title": "Estimating Cartesian compression via deep learning", "author": ["Andr\u00e1s L\u0151rincz", "Andr\u00e1s S\u00e1rk\u00e1ny", "Zolt\u00e1n \u00c1 Milacski", "Zolt\u00e1n T\u0151s\u00e9r"], "venue": "In Lecture Notes in Computer Science,", "citeRegEx": "L\u0151rincz et al\\.,? \\Q2016\\E", "shortCiteRegEx": "L\u0151rincz et al\\.", "year": 2016}, {"title": "Optical navigation by the method of differences", "author": ["Bruce D Lucas", "Takeo Kanade"], "venue": "In International Joint Conference on Artificial Intelligence,", "citeRegEx": "Lucas and Kanade.,? \\Q1985\\E", "shortCiteRegEx": "Lucas and Kanade.", "year": 1985}, {"title": "Hearing lips and seeing", "author": ["Harry McGurk", "John MacDonald"], "venue": "voices. Nature,", "citeRegEx": "McGurk and MacDonald.,? \\Q1976\\E", "shortCiteRegEx": "McGurk and MacDonald.", "year": 1976}, {"title": "Hand detection using multiple proposals", "author": ["Arpit Mittal", "Andrew Zisserman", "Philip HS Torr"], "venue": "In British Machine Vision Conference,", "citeRegEx": "Mittal et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Mittal et al\\.", "year": 2011}, {"title": "Human-level control through deep reinforcement learning", "author": ["Volodymyr Mnih", "Koray Kavukcuoglu", "David Silver", "Andrei A Rusu", "Joel Veness", "Marc G Bellemare", "Alex Graves", "Martin Riedmiller", "Andreas K Fidjeland", "Georg Ostrovski"], "venue": "Nature, 518(7540):529\u2013533,", "citeRegEx": "Mnih et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Mnih et al\\.", "year": 2015}, {"title": "Deep neural networks are easily fooled: High confidence predictions for unrecognizable images", "author": ["Anh Nguyen", "Jason Yosinski", "Jeff Clune"], "venue": "In International Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "Nguyen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Nguyen et al\\.", "year": 2015}, {"title": "Faster R-CNN: Towards real-time object detection with region proposal networks", "author": ["Shaoqing Ren", "Kaiming He", "Ross Girshick", "Jian Sun"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Ren et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ren et al\\.", "year": 2015}, {"title": "Deep learning in neural networks: An overview", "author": ["J\u00fcrgen Schmidhuber"], "venue": "Neural Networks,", "citeRegEx": "Schmidhuber.,? \\Q2015\\E", "shortCiteRegEx": "Schmidhuber.", "year": 2015}, {"title": "Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition", "author": ["Mahmood Sharif", "Sruti Bhagavatula", "Lujo Bauer", "Michael K Reiter"], "venue": "In Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security,", "citeRegEx": "Sharif et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Sharif et al\\.", "year": 2016}, {"title": "Mastering the game of Go with deep neural networks and tree", "author": ["David Silver", "Aja Huang", "Chris J Maddison", "Arthur Guez", "Laurent Sifre", "George Van Den Driessche", "Julian Schrittwieser", "Ioannis Antonoglou", "Veda Panneershelvam", "Marc Lanctot"], "venue": "search. Nature,", "citeRegEx": "Silver et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Silver et al\\.", "year": 2016}, {"title": "Learning to play using low-complexity rule-based policies: Illustrations through Ms. Pac-Man", "author": ["Istv\u00e1n Szita", "Andr\u00e1s L\u0151rincz"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Szita and L\u0151rincz.,? \\Q2007\\E", "shortCiteRegEx": "Szita and L\u0151rincz.", "year": 2007}, {"title": "\u03b5-MDPs: Learning in varying environments", "author": ["Istv\u00e1n Szita", "B\u00e1lint Tak\u00e1cs", "Andr\u00e1s L\u0151rincz"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Szita et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Szita et al\\.", "year": 2002}, {"title": "Features, configuration, and holistic face processing", "author": ["James W Tanaka", "Iris Gordon"], "venue": "The Oxford Handbook of Face Perception,", "citeRegEx": "Tanaka and Gordon.,? \\Q2011\\E", "shortCiteRegEx": "Tanaka and Gordon.", "year": 2011}, {"title": "The Cyber-Physical System approach towards artificial general intelligence", "author": ["Zolt\u00e1n T\u0151s\u00e9r", "Andr\u00e1s L\u0151rincz"], "venue": "In Lecture Notes in Computer Science,", "citeRegEx": "T\u0151s\u00e9r and L\u0151rincz.,? \\Q2015\\E", "shortCiteRegEx": "T\u0151s\u00e9r and L\u0151rincz.", "year": 2015}, {"title": "Personalization of gaze direction estimation with deep learning. In Lecture Notes in Computer Science, volume 9904, chapter KI 2016", "author": ["Zolt\u00e1n T\u0151s\u00e9r", "R\u00f3bert A Rill", "Kinga Farag\u00f3", "L\u00e1szl\u00f3 A Jeni", "Andr\u00e1s L\u0151rincz"], "venue": "Advances in Artificial Intelligence,", "citeRegEx": "T\u0151s\u00e9r et al\\.,? \\Q2016\\E", "shortCiteRegEx": "T\u0151s\u00e9r et al\\.", "year": 2016}, {"title": "Convolutional pose machines", "author": ["Shih-En Wei", "Varun Ramakrishna", "Takeo Kanade", "Yaser Sheikh"], "venue": "arXiv preprint arXiv:1602.00134,", "citeRegEx": "Wei et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Wei et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 18, "context": "Success stories demonstrate that superhuman performance can be reached this way (Schmidhuber, 2015).", "startOffset": 80, "endOffset": 99}, {"referenceID": 0, "context": "However, if we take a look at human information processing, for example, we learn that it has two basic routes: (i) holistic recognition (Tanaka & Gordon, 2011) and (ii) recognition by components (Biederman, 1987).", "startOffset": 196, "endOffset": 213}, {"referenceID": 0, "context": "However, if we take a look at human information processing, for example, we learn that it has two basic routes: (i) holistic recognition (Tanaka & Gordon, 2011) and (ii) recognition by components (Biederman, 1987). These processing methodologies are competing and also complementing each other. Deep learning methods, on the other hand, tend to favor endto-end learning, which corresponds to holistic recognition and are missing the advantages of the component based approach. Furthermore, holistic recognition and thus end-to-end learning is fragile. The fragility has been shown in a number of studies., e.g., (i) deep networks can be fooled as described by Nguyen et al. (2015), when inputs that differ enormously for a human observer from a given class are assigned the label of that class with extremely high confidence, or as demonstrated in Sharif et al.", "startOffset": 197, "endOffset": 681}, {"referenceID": 0, "context": "However, if we take a look at human information processing, for example, we learn that it has two basic routes: (i) holistic recognition (Tanaka & Gordon, 2011) and (ii) recognition by components (Biederman, 1987). These processing methodologies are competing and also complementing each other. Deep learning methods, on the other hand, tend to favor endto-end learning, which corresponds to holistic recognition and are missing the advantages of the component based approach. Furthermore, holistic recognition and thus end-to-end learning is fragile. The fragility has been shown in a number of studies., e.g., (i) deep networks can be fooled as described by Nguyen et al. (2015), when inputs that differ enormously for a human observer from a given class are assigned the label of that class with extremely high confidence, or as demonstrated in Sharif et al. (2016) showing that (ii) barely visible watermark-like modifications may change the class label, and that (iii) small additional components can be designed to change the class index to another desired one, making the network prone to attacks.", "startOffset": 197, "endOffset": 869}, {"referenceID": 2, "context": "Cand\u00e8s et al. (2011) showed that it is possible to augment this architecture with a term that collects and thus separates such components, which they call Robust Principal Component Analysis (RPCA).", "startOffset": 0, "endOffset": 21}, {"referenceID": 10, "context": "We utilized the Inexact Augmented Lagrangian Multiplier (Lin et al., 2010) solver for this problem implemented in Python2.", "startOffset": 56, "endOffset": 74}, {"referenceID": 11, "context": "The `1,2 regularizer promotes The task of learning of such components has been tackled recently by L\u0151rincz et al. (2016). https://kastnerkyle.", "startOffset": 99, "endOffset": 121}, {"referenceID": 6, "context": ", the work of Fischer et al. (2015) and the references therein.", "startOffset": 14, "endOffset": 36}, {"referenceID": 17, "context": "Deep learning is thoroughly reviewed by Schmidhuber (2015). Introduction and details of the theory of the different networks can be found in the very recent book from Goodfellow et al.", "startOffset": 40, "endOffset": 59}, {"referenceID": 7, "context": "Introduction and details of the theory of the different networks can be found in the very recent book from Goodfellow et al. (2016). Consequently, we refer the interested reader to these excellent works and restrict this technical report to the collection of the references of the papers and the related software tools that we applied during the course of our work:", "startOffset": 107, "endOffset": 132}, {"referenceID": 17, "context": "Faster R-CNN6 (Ren et al., 2015) for object proposals; 2.", "startOffset": 14, "endOffset": 32}, {"referenceID": 3, "context": "Region-based Fully Convolutional Network7 (Dai et al., 2016) for object and hand detection; 3.", "startOffset": 42, "endOffset": 60}, {"referenceID": 26, "context": "Convolutional Pose Machine8 (Wei et al., 2016) for body pose detection (we also injected hand detection for improving the heat maps of this network); 4.", "startOffset": 28, "endOffset": 46}, {"referenceID": 25, "context": "Libfacetracker (T\u0151s\u00e9r et al., 2016) for face detection.", "startOffset": 15, "endOffset": 35}, {"referenceID": 9, "context": "MS COCO9 (Lin et al., 2014) for object detection; 2.", "startOffset": 9, "endOffset": 27}, {"referenceID": 5, "context": "PASCAL Visual Object Classes10 (Everingham et al., 2010) with twenty classes for training Faster R-CNN; 3.", "startOffset": 31, "endOffset": 56}, {"referenceID": 8, "context": "Visual Genome11 (Krishna et al., 2016) for changing backgrounds; 4.", "startOffset": 16, "endOffset": 38}, {"referenceID": 14, "context": "Mittal\u2019s Hand Dataset12 (Mittal et al., 2011) for hand detection; 5.", "startOffset": 24, "endOffset": 45}, {"referenceID": 15, "context": "Success stories on reinforcement learning using deep networks are already numerous, including Atari games (Mnih et al., 2015) and the game Go (Silver et al.", "startOffset": 106, "endOffset": 125}, {"referenceID": 20, "context": ", 2015) and the game Go (Silver et al., 2016).", "startOffset": 24, "endOffset": 45}, {"referenceID": 20, "context": "Such concepts have been formulated within the event learning framework for single episodic series Szita et al. (2002) and by Szita & L\u0151rincz (2007) for multiple events.", "startOffset": 98, "endOffset": 118}, {"referenceID": 20, "context": "Such concepts have been formulated within the event learning framework for single episodic series Szita et al. (2002) and by Szita & L\u0151rincz (2007) for multiple events.", "startOffset": 98, "endOffset": 148}, {"referenceID": 15, "context": "Success stories on reinforcement learning using deep networks are already numerous, including Atari games (Mnih et al., 2015) and the game Go (Silver et al., 2016). In turn, we conjecture that new applications built on deep learning technology based reinforcement learning, although technologically might be challenging regarding the sensory and the control systems, but may appear relatively fast as opposed to the view expressed in Study Panel (2016).", "startOffset": 107, "endOffset": 453}], "year": 2016, "abstractText": "Machine learning is making substantial progress in diverse applications. The success is mostly due to advances in deep learning. However, deep learning can make mistakes and its generalization abilities to new tasks are questionable. We ask when and how one can combine network outputs, when (i) details of the observations are evaluated by learned deep components and (ii) facts and confirmation rules are available in knowledge based systems. We show that in limited contexts the required number of training samples can be low and selfimprovement of pre-trained networks in more general context is possible. We argue that the combination of sparse outlier detection with deep components that can support each other diminish the fragility of deep methods, an important requirement for engineering applications. We argue that supervised learning of labels may be fully eliminated under certain conditions: a component based architecture together with a knowledge based system can train itself and provide high quality answers. We demonstrate these concepts on the State Farm Distracted Driver Detection benchmark. We argue that the view of the Study Panel (2016) may overestimate the requirements on \u2018years of focused research\u2019 and \u2018careful, unique construction\u2019 for \u2018AI systems\u2019.", "creator": "LaTeX with hyperref package"}}}