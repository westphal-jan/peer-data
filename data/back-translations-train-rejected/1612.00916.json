{"id": "1612.00916", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Dec-2016", "title": "A Matrix Splitting Perspective on Planning with Options", "abstract": "We show that the Bellman operator underlying the options framework leads to a matrix splitting, an approach traditionally used to speed up convergence of iterative solvers for large linear systems of equations. Based on standard comparison theo- rems for matrix splittings, we then show how the asymptotic rate of convergence varies as a function of the inherent timescales of the options. This new perspective highlights a trade-off between asymptotic performance and the cost of computation associated with building a good set of options.", "histories": [["v1", "Sat, 3 Dec 2016 02:57:36 GMT  (12kb)", "https://arxiv.org/abs/1612.00916v1", "Accepted at the Continual Learning and Deep Networks Workshop, NIPS 2016"], ["v2", "Mon, 10 Jul 2017 19:28:32 GMT  (13kb)", "http://arxiv.org/abs/1612.00916v2", "The results presented in the previous version of this paper were found be applicable only to \"gating execution\" and not \"call-and-return\". We made this distinction clear in the text and added an extension to the call-and-return model"]], "COMMENTS": "Accepted at the Continual Learning and Deep Networks Workshop, NIPS 2016", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["pierre-luc bacon", "doina precup"], "accepted": false, "id": "1612.00916"}, "pdf": {"name": "1612.00916.pdf", "metadata": {"source": "CRF", "title": "A Matrix Splitting Perspective on Planning with Options", "authors": [], "emails": ["dprecup}@cs.mcgill.ca", "@s"], "sections": [{"heading": null, "text": "ar Xiv: 161 2.00 916v 2 [cs.A I] 1.0Ju l 2We show that the Bellman operator underlying the option framework leads to matrix splitting, an approach traditionally used to accelerate the convergence of iterative solvers for large linear equation systems. Based on standard comparison theories for matrix splitting, we then show how the asymptotic convergence rate varies depending on the inherent timescales of the options. This new perspective highlights a trade-off between asymptotic performance and the cost of calculation associated with building a good set of options."}, {"heading": "1 Introduction", "text": "The Options Framework [Sutton et al., 1999; Precup, 2000] formalized this idea and showed how extended-time actions can be used for learning and planning reinforcement learning systems. Options can sometimes lead to better and faster exploration, learning, planning, and transfer [Sutton et al., 1999], while there is a robust handling of misinformation and uncertainty [He et al., 2011]. While efficient algorithms for learning options have recently been proposed [Bacon et al., 2016; Mankowitz et al., 2016; Vezhnevets et al., 2016; Daniel et al., 2016], there is still no consensus on what constitutes good options. In this paper, we show that choosing the options is equivalent to choosing iterative algorithms to solve the Markov decision problems, reaching this conclusion by noting that the generalized Bellman operator options and its 1971 model represent a solution to varga formation, the year 1962 being the year of varga options."}, {"heading": "2 Background and Notation", "text": "We limit our attention to the class of discounted Markovian decision-making problems with finite states and spaces of action. A discounted Markov decision-making process is defined by a finite series of states S, a finite series of measures A, a reward function R: S \u00b2 A \u00b2 R, a transitional function P: S \u00b2 A \u00d1 pS \u00b2 r0, 1sq and a discount factor \u03b3 P r0, 1q. We write \u03c0 pa | sq to indicate the probability of taking measures taken within the framework of stochastic policies: this is \u0159 aPA \u03c0 pa | sq \"1, @ s P S. The value function v\u03c0: S \u00b2 R represents the expected sum of discounted rewards taken along the paths induced by the MDP and politics."}, {"heading": "3 Generalized Bellman Equations for Gating Execution", "text": "\"We must be prepared to be able to increase the number of backups by making the number of Bellman backups a random variable determined by the termination events of an option-based process. Let's be a random variable representing the number of backups performed per iteration. We can then define our generalized Bellman operators as follows: pLvqpsq 9\" E \"E\" E \"E\" E \"E\" E \"E\" E \"E\" E \"E\" E \"E\" E \"E\" E \"E\" E \"E\" E \"E\" E \"E\" E \"E\" E \"E\" E \"E\" E \"E.\""}, {"heading": "4 Matrix Splitting", "text": "For A \"M\" N P Rn\u00c9 n and assuming that A and M are not singular, Varga [1962] has shown that the iterates xk \"1\" M \"1Nxk\" M \"1b,\" i.e. the unique solution of the linear system of the equation Ax \"b.\" In policy assessment issues, we work with the linear system of equations pI. \"Theorem 1 (matrix splitting in the gating model), whose goal policy is to be evaluated. We now show that the reward and transition models (4) exactly match the notion of a matrix splitting for matrix I.\" Theorem 1 (matrix splitting in the gating model)."}, {"heading": "5 Call-and-Return Execution Model", "text": "The previously adopted gating execution model does not take into account the notion of the time commitment provided by the call-and-return model. \"Since at each step of the gating model a choice of option is made, the policy via the option can be decoupled from the termination functions. This gives us the ability to express the value function as a solution to a matrix split across states. However, it is known that [Sutton et al., 1999] that a number of options with call-and-return execution and an MDP can trigger a Semi-Markov decision process (SMDP), even in the case of Markov options. This means that the trajectories over the state and actions generated with options may no longer correspond to the dynamics of a Markov process. Therefore, the existence of an equivalent marginal policy cannot be guaranteed."}, {"heading": "6 Implications", "text": "Given the interpretation of options in terms of matrix splitting, and thus as preconditioners q, it is no surprise that preconditioning methods share the same goals as options. In fact, in both cases we are looking for a representation of the problem that is easier to solve than the original one. As Herbert Simon wrote in his Science of the Artificial: \"[...] Solving a problem simply means presenting it in order to make the solution transparent.\" [Simon, 1969] Therefore, the problem of finding good options or preconditioners is closely related to the representational learning problem [Minsky, 1961]. As with options, the design of general and fast preconditioners is a long-standing problem of numerical analysis. In some cases, good preconditioners can be found when problem-specific knowledge or preconditioners is available. However, the manual design of preconditioners and options quickly becomes a lengthy process for major problems or when only partial knowledge of the domain is available."}], "references": [{"title": "Learning with options: Just deliberate and relax", "author": ["Pierre-Luc Bacon", "Doina Precup"], "venue": "In NIPS Bounded Optimality and Rational Metareasoning Workshop,", "citeRegEx": "Bacon and Precup.,? \\Q2015\\E", "shortCiteRegEx": "Bacon and Precup.", "year": 2015}, {"title": "The option-critic architecture", "author": ["Pierre-Luc Bacon", "Jean Harb", "Doina Precup"], "venue": "In Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence, February", "citeRegEx": "Bacon et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Bacon et al\\.", "year": 2017}, {"title": "Nonnegative Matrices in the Mathematical Sciences", "author": ["A. Berman", "R.J. Plemmons"], "venue": null, "citeRegEx": "Berman and Plemmons.,? \\Q1979\\E", "shortCiteRegEx": "Berman and Plemmons.", "year": 1979}, {"title": "Probabilistic inference for determining options in reinforcement learning", "author": ["C. Daniel", "H. van Hoof", "J. Peters", "G. Neumann"], "venue": "Machine Learning, Special Issue,", "citeRegEx": "Daniel et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Daniel et al\\.", "year": 2016}, {"title": "Efficient planning under uncertainty with macroactions", "author": ["Ruijie He", "Emma Brunskill", "Nicholas Roy"], "venue": "J. Artif. Intell. Res. (JAIR),", "citeRegEx": "He et al\\.,? \\Q2011\\E", "shortCiteRegEx": "He et al\\.", "year": 2011}, {"title": "Bias-variance error bounds for temporal difference updates", "author": ["Michael J. Kearns", "Satinder P. Singh"], "venue": "In Proceedings of the Thirteenth Annual Conference on Computational Learning Theory,", "citeRegEx": "Kearns and Singh.,? \\Q2000\\E", "shortCiteRegEx": "Kearns and Singh.", "year": 2000}, {"title": "Adaptive skills, adaptive partitions (ASAP)", "author": ["Daniel J. Mankowitz", "Timothy Arthur Mann", "Shie Mannor"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Mankowitz et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Mankowitz et al\\.", "year": 2016}, {"title": "Steps toward artificial intelligence", "author": ["Marvin Minsky"], "venue": "In Computers and Thought,", "citeRegEx": "Minsky.,? \\Q1961\\E", "shortCiteRegEx": "Minsky.", "year": 1961}, {"title": "Bounds and transformations for discounted finite markov decision chains", "author": ["Evan L. Porteus"], "venue": "Oper. Res.,", "citeRegEx": "Porteus.,? \\Q1975\\E", "shortCiteRegEx": "Porteus.", "year": 1975}, {"title": "Multi-time models for temporally abstract planning", "author": ["Doina Precup", "Richard S Sutton"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "Precup and Sutton.,? \\Q1998\\E", "shortCiteRegEx": "Precup and Sutton.", "year": 1998}, {"title": "Temporal abstraction in reinforcement learning", "author": ["Doina Precup"], "venue": "PhD thesis, University of Massachusetts,", "citeRegEx": "Precup.,? \\Q2000\\E", "shortCiteRegEx": "Precup.", "year": 2000}, {"title": "Markov Decision Processes: Discrete Stochastic Dynamic Programming", "author": ["Martin L. Puterman"], "venue": null, "citeRegEx": "Puterman.,? \\Q1994\\E", "shortCiteRegEx": "Puterman.", "year": 1994}, {"title": "Preconditioned Iterations, chapter 9, pages 261\u2013281", "author": ["Yousef Saad"], "venue": null, "citeRegEx": "Saad.,? \\Q2003\\E", "shortCiteRegEx": "Saad.", "year": 2003}, {"title": "The Sciences of the Artificial", "author": ["H.A. Simon"], "venue": "Karl Taylor Compton lectures. M.I.T. Press,", "citeRegEx": "Simon.,? \\Q1969\\E", "shortCiteRegEx": "Simon.", "year": 1969}, {"title": "Optimal behavioral hierarchy", "author": ["Alec Solway", "Carlos Diuk", "Natalia C\u00f3rdova", "Debbie Yee", "Andrew G. Barto", "Yael Niv", "Matthew M. Botvinick"], "venue": "PLoS Comput Biol,", "citeRegEx": "Solway et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Solway et al\\.", "year": 2014}, {"title": "Between mdps and semi-mdps: A framework for temporal abstraction in reinforcement learning", "author": ["Richard S. Sutton", "Doina Precup", "Satinder P. Singh"], "venue": "Artif. Intell.,", "citeRegEx": "Sutton et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Sutton et al\\.", "year": 1999}, {"title": "TD models: Modeling the world at a mixture of time scales", "author": ["Richard S. Sutton"], "venue": "In Machine Learning, Proceedings of the Twelfth International ConferenceVa on Machine Learning,", "citeRegEx": "Sutton.,? \\Q1995\\E", "shortCiteRegEx": "Sutton.", "year": 1995}, {"title": "Stopping times and markov programming", "author": ["J.A.E.E. van Nunen", "J. Wessels"], "venue": "Technical Report 76-22,", "citeRegEx": "Nunen and Wessels.,? \\Q1976\\E", "shortCiteRegEx": "Nunen and Wessels.", "year": 1976}, {"title": "Matrix iterative analysis", "author": ["Richard S. Varga"], "venue": "Prentice-Hall, Englewood Cliffs,", "citeRegEx": "Varga.,? \\Q1962\\E", "shortCiteRegEx": "Varga.", "year": 1962}, {"title": "Strategic attentive writer for learning macro-actions", "author": ["Alexander (Sasha) Vezhnevets", "Volodymyr Mnih", "John Agapiou", "Simon Osindero", "Alex Graves", "Oriol Vinyals", "Koray Kavukcuoglu"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Vezhnevets et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Vezhnevets et al\\.", "year": 2016}, {"title": "Iterative solution of large linear systems", "author": [], "venue": null, "citeRegEx": "Rheinboldt.,? \\Q1971\\E", "shortCiteRegEx": "Rheinboldt.", "year": 1971}], "referenceMentions": [{"referenceID": 15, "context": "The options framework [Sutton et al., 1999; Precup, 2000] formalized this idea and showed how temporally extended actions can be used for learning and planning in reinforcement learning.", "startOffset": 22, "endOffset": 57}, {"referenceID": 10, "context": "The options framework [Sutton et al., 1999; Precup, 2000] formalized this idea and showed how temporally extended actions can be used for learning and planning in reinforcement learning.", "startOffset": 22, "endOffset": 57}, {"referenceID": 15, "context": "Options can sometimes lead to better and faster exploration, learning, planning and transfer [Sutton et al., 1999] while being robust to model misspecifications and uncertainty [He et al.", "startOffset": 93, "endOffset": 114}, {"referenceID": 4, "context": ", 1999] while being robust to model misspecifications and uncertainty [He et al., 2011].", "startOffset": 70, "endOffset": 87}, {"referenceID": 6, "context": "While efficient algorithms for learning options have recently been proposed [Bacon et al., 2016; Mankowitz et al., 2016; Vezhnevets et al., 2016; Daniel et al., 2016], there is still no consensus on what constitute good options.", "startOffset": 76, "endOffset": 166}, {"referenceID": 19, "context": "While efficient algorithms for learning options have recently been proposed [Bacon et al., 2016; Mankowitz et al., 2016; Vezhnevets et al., 2016; Daniel et al., 2016], there is still no consensus on what constitute good options.", "startOffset": 76, "endOffset": 166}, {"referenceID": 3, "context": "While efficient algorithms for learning options have recently been proposed [Bacon et al., 2016; Mankowitz et al., 2016; Vezhnevets et al., 2016; Daniel et al., 2016], there is still no consensus on what constitute good options.", "startOffset": 76, "endOffset": 166}, {"referenceID": 18, "context": "We reach this conclusion by noting that the generalized Bellman operator underlying options and their models admits a linear representation as a matrix splitting [Varga, 1962; Young and Rheinboldt, 1971; Puterman, 1994], a notion which comes in pair with that of matrix preconditioning.", "startOffset": 162, "endOffset": 219}, {"referenceID": 11, "context": "We reach this conclusion by noting that the generalized Bellman operator underlying options and their models admits a linear representation as a matrix splitting [Varga, 1962; Young and Rheinboldt, 1971; Puterman, 1994], a notion which comes in pair with that of matrix preconditioning.", "startOffset": 162, "endOffset": 219}, {"referenceID": 9, "context": "We can extend this idea [Precup and Sutton, 1998] by making the number of Bellman backups a random variable which is determined by the termination events of an options-based process.", "startOffset": 24, "endOffset": 49}, {"referenceID": 14, "context": "Rather than backing up values for only one step ahead, Sutton [1995] showed that multi-steps backups can equally be used for planning as long as the corresponding generalized Bellman operators satisfy the Bellman equations.", "startOffset": 55, "endOffset": 69}, {"referenceID": 11, "context": "van Nunen and Wessels [1976] showed that the basic iterative methods such as the Gauss-Seidel, Jacobi, Successive Overrelaxation, or Richardson\u2019s variants [Puterman, 1994] of value iteration can be obtained through different stopping time functions in an operator of the same form as (1), or equivalently, as a linear transformation of an MDP into an equivalent one.", "startOffset": 155, "endOffset": 171}, {"referenceID": 18, "context": "The pre-inverse transform as well as the basic iterative methods can also be studied more generally via the notion of matrix splittings [Varga, 1962] developed in the context of matrix iterative analysis.", "startOffset": 136, "endOffset": 149}, {"referenceID": 15, "context": "van Nunen and Wessels [1976] showed that the basic iterative methods such as the Gauss-Seidel, Jacobi, Successive Overrelaxation, or Richardson\u2019s variants [Puterman, 1994] of value iteration can be obtained through different stopping time functions in an operator of the same form as (1), or equivalently, as a linear transformation of an MDP into an equivalent one.", "startOffset": 4, "endOffset": 29}, {"referenceID": 8, "context": "This perspective was leveraged by Porteus [1975] to derive better bounds by transforming an MDP into one which has the same optimal policy but whose spectral radius is smaller.", "startOffset": 34, "endOffset": 49}, {"referenceID": 17, "context": "4 Matrix Splitting For A \u201c M  \u0301 N P R and provided that A and M are nonsingular, Varga [1962] showed that the iterates xk`1 \u201c M Nxk ` M b converge to the unique solution of the linear system of equation Ax \u201c b.", "startOffset": 81, "endOffset": 94}, {"referenceID": 2, "context": "Proof: M is an \u201cM-matrix\u201d (see chapter 6 of Berman and Plemmons [1979]).", "startOffset": 44, "endOffset": 71}, {"referenceID": 2, "context": "Proof: M is an \u201cM-matrix\u201d (see chapter 6 of Berman and Plemmons [1979]). M-matrices have the property of being inverse-positive, that is M exists with M \u011b 0, fulfilling the definition of a regular splitting (see def. 3.5 of Varga [1962]) Corollary 1.", "startOffset": 44, "endOffset": 237}, {"referenceID": 18, "context": "Using comparison theorems for regular matrix splittings [Varga, 1962] we can better understand the effect of modelling the world at different timescales on the asymptotic performance of the induced algorithms.", "startOffset": 56, "endOffset": 69}, {"referenceID": 12, "context": "This also becomes apparent when writing (5) in the following form: pI  \u0301 \u03b3P7qv \u201c pI  \u0301 \u03b3P7qv ` pr\u03c3  \u0301 pI  \u0301 \u03b3P\u03c3qvq v \u201c v ` pI  \u0301 \u03b3P7q pr\u03c3  \u0301 pI  \u0301 \u03b3P\u03c3qvq (6) Therefore, options enter the linear system of equations pI \u0301\u03b3P\u03c3qv \u201c r\u03c3 through the preconditioning matrixM [Saad, 2003] and yield the following transformed linear system of equations: pI  \u0301 \u03b3P7q pI  \u0301 \u03b3P\u03c3qv \u201c pI  \u0301 \u03b3P7q r\u03c3 (7) As the options timescales increase and \u03b2wpsq \u201c 0 @w P W , s P S, then P7 \u201c P\u03c3 and the solution is obtained directly on the right hand side of (7).", "startOffset": 265, "endOffset": 277}, {"referenceID": 15, "context": "However, it is known [Sutton et al., 1999] that a set of options with call-and-return execution and an MDP induce a semi-Markov Decision Process (SMDP), even in the case of Markov options.", "startOffset": 21, "endOffset": 42}, {"referenceID": 1, "context": "The resulting process defines a Markov chain in an augmented state space over state-option pairs [Bacon et al., 2017].", "startOffset": 97, "endOffset": 117}, {"referenceID": 1, "context": "The resulting process defines a Markov chain in an augmented state space over state-option pairs [Bacon et al., 2017]. This conditioning on both states and options is key to the derivation of the Bellman-like expressions of Sutton et al. [1999] for the reward and transition models of options.", "startOffset": 98, "endOffset": 245}, {"referenceID": 1, "context": "The resulting process defines a Markov chain in an augmented state space over state-option pairs [Bacon et al., 2017]. This conditioning on both states and options is key to the derivation of the Bellman-like expressions of Sutton et al. [1999] for the reward and transition models of options. In the following, we show that the solution to these equations also yields a matrix splitting. Sutton et al. [1999] showed that the reward model of an option can be written recursively as:", "startOffset": 98, "endOffset": 410}], "year": 2017, "abstractText": "We show that the Bellman operator underlying the options framework leads to a matrix splitting, an approach traditionally used to speed up convergence of iterative solvers for large linear systems of equations. Based on standard comparison theorems for matrix splittings, we then show how the asymptotic rate of convergence varies as a function of the inherent timescales of the options. This new perspective highlights a trade-off between asymptotic performance and the cost of computation associated with building a good set of options.", "creator": "LaTeX with hyperref package"}}}