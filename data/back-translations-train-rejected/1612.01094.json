{"id": "1612.01094", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Dec-2016", "title": "Learning to superoptimize programs - Workshop Version", "abstract": "Superoptimization requires the estimation of the best program for a given computational task. In order to deal with large programs, superoptimization techniques perform a stochastic search. This involves proposing a modification of the current program, which is accepted or rejected based on the improvement achieved. The state of the art method uses uniform proposal distributions, which fails to exploit the problem structure to the fullest. To alleviate this deficiency, we learn a proposal distribution over possible modifications using Reinforcement Learning. We provide convincing results on the superoptimization of \"Hacker's Delight\" programs.", "histories": [["v1", "Sun, 4 Dec 2016 10:39:49 GMT  (758kb,D)", "http://arxiv.org/abs/1612.01094v1", "Workshop version for the NIPS NAMPI Workshop. Extended version atarXiv:1611.01787"]], "COMMENTS": "Workshop version for the NIPS NAMPI Workshop. Extended version atarXiv:1611.01787", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["rudy bunel", "alban desmaison", "m pawan kumar", "philip h s torr", "pushmeet kohli"], "accepted": false, "id": "1612.01094"}, "pdf": {"name": "1612.01094.pdf", "metadata": {"source": "CRF", "title": "Learning to superoptimize programs", "authors": ["Rudy Bunel", "Alban Desmaison", "M. Pawan Kumar"], "emails": ["rudy@robots.ox.ac.uk,", "alban@robots.ox.ac.uk,", "pawan@robots.ox.ac.uk,", "philip.torr@eng.ox.ac.uk", "pkohli@microsoft.com", "@NIPS"], "sections": [{"heading": null, "text": "Super optimization requires the estimation of the best program for a given calculation task. In order to deal with large programs, super optimization techniques perform a stochastic search, proposing a modification of the current program, which is accepted or rejected due to the improvement achieved. The state-of-the-art method uses uniform application distributions that do not fully exploit the problem structure. To address this deficiency, we learn how to distribute applications via possible modifications using Reinforcement Learning. We provide convincing results for super optimization of Hacker's Delight programs."}, {"heading": "1 Introduction", "text": "An alternative approach is to search over the space of all possible programs that correspond to the output of the compiler, and to select the program that is most efficient. To address this problem, recent approaches have begun to apply a stochastic search method inspired by sampling by Markov Chain Monte Carlo. [15] One of the most important factors determining the efficiency of this stochastic search is the choice of a supply distribution. Surprisingly, the state of the art is based on Stoke [15] having a uniform distribution of individual components."}, {"heading": "2 Related Works", "text": "The earliest approach to super-optimization was the brut force search. By sequentially enumerating all programs of increasing length, the shortest program that met the specification was guaranteed to be found. Predictably, this approach scaled poorly to longer programs or to large instruction sets. The longest reported synthetic program was 12 instructions long, limited to a limited set of commands. Trade in completeness for efficiency, stochastic methods [15] reduced the number of programs to be tested using the observed quality of the programs as a guide. However, the use of a generic, non-specific exploration policy blinded optimization to the problem at hand. We propose to address this problem by directing the efficient implementation of the programs into space."}, {"heading": "3 Learning Stochastic Superoptimization", "text": "To find the optimum of this function, Cgorithler runs. \"Each statement originally consists of an opcode that specifies what to execute and some operands that specify the appropriate registers. Therefore, each given input program T defines a cost function. For a candidate called R, the associated costs are determined by the following factors: Cost (R, T) = Implementation of costs when executed, which can be achieved either by running a symbolic validator or by executing test cases. the other term perf (R) is a measure of the program's execution time. An approximation can be the sum of the latency of all statements in the program. Alternatively, the timing of the program can be used on some test cases."}, {"heading": "4 Experiments", "text": "We have conducted our experiments on the basis of the joy of the hacker [17] corpus, a collection of 25-bit manipulation programs used as a benchmark for program synthesis [7, 9, 15]. A detailed description of the task is given in Appendix C. Some examples include determining whether an integer from its binary representation is a power of two by counting the number of bits activated in a register or calculating the maximum of two integers. To have a larger corpus than the originally obtained twenty-five programs, we generate different starting points for each optimization. This is achieved by running Stoke with a cost function where perspecp = 0 in (1), only maintaining the correct programs and filtering out duplicates. This allows us to create a larger data set. We divide the HackerDelight tasks into two sets. We train on the first group and evaluate only the performance on the second to evaluate the generalization of our suggested distribution."}, {"heading": "5 Conclusion", "text": "It is interesting to compare our approach with the synthesis-style approaches that have recently emerged in the deep learning community [6], which aim to learn programs directly from differentiated representations of programs. We note an advantage that such a stochastic search-based approach offers: the resulting program can be run independently of the neural network used to discover it. Several improvements are possible over the approach presented above. Turning the probability distribution into a neural network that depends on the original input or current state of rewriting would lead to a more meaningful model, while it essentially has a similar training complexity, but will require a richer, more diverse dataset to make evaluation meaningful."}, {"heading": "A Generative model of the program transformations", "text": "In Stoke [15], the 64-bit data of the registers is replaced by selected 32-bit data, a process that has been analyzed using publicly available code [3]. First, one type of transformation is sampled uniformly from the following suggestions: 1. Add a NOP statement at a random position in the program; 2. Delete a statement that removes one of the program's statements; 3. Instruction Transform replaces one existing line (statement + operand) with another (New statement and new operand); 4. Opcode Transform replaces one statement with another, retaining the sameoperand; the new statement is sampled from the set of compatible statements; 5. Opcode Width Transform replaces one statement with another, with the same memonical statement; this means that these statements do the same thing except that they do not operate on the same part of the registers (for example)."}, {"heading": "B Metropolis algorithm as a Stochastic Computation Graph", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "C Hacker\u2019s delight tasks", "text": "The 25 tasks of the joy of the hacker [17] data sets are as follows: 1. Turn off a bit on the far right 2. Test whether an unsigned integer of the form 2 (n \u2212 1) is 3. Isolate the far right bit 4. Form a mask that identifies a bit on the far right and zeros behind it 5. Test whether the number of leading zeros of two words is the same bit 11. Test whether the number of leading zeros of one word is strictly smaller than that of another work 12. Test whether the number of leading zeros of one word is smaller than that of another work 13. Character function 14. Floor of the average number of two integers without overflow 15. Veil of the average number of two integers without overflow 16. Test max."}], "references": [{"title": "Learning to learn by gradient descent by gradient descent", "author": ["Marcin Andrychowicz", "Misha Denil", "Sergio Gomez", "Matthew W Hoffman", "David Pfau", "Tom Schaul", "Nando de Freitas"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2016}, {"title": "Adaptive neural compilation", "author": ["Rudy Bunel", "Alban Desmaison", "Pushmeet Kohli", "Philip HS Torr", "M Pawan Kumar"], "venue": "In NIPS", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2016}, {"title": "Hc-search: A learning framework for search-based structured prediction", "author": ["Janardhan Rao Doppa", "Alan Fern", "Prasad Tadepalli"], "venue": "JAIR,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "Eliminating branches using a superoptimizer and the GNU C compiler", "author": ["Torbj\u00f6rn Granlund", "Richard Kenner"], "venue": "ACM SIGPLAN Notices,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1992}, {"title": "Synthesis of loop-free programs", "author": ["Sumit Gulwani", "Susmit Jha", "Ashish Tiwari", "Ramarathnam Venkatesan"], "venue": "In PLDI,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2011}, {"title": "The informed sampler: A discriminative approach to bayesian inference in generative computer vision models", "author": ["Varun Jampani", "Sebastian Nowozin", "Matthew Loper", "Peter V Gehler"], "venue": "Computer Vision and Image Understanding,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "Oracle-guided component-based program synthesis", "author": ["Susmit Jha", "Sumit Gulwani", "Sanjit A Seshia", "Ashish Tiwari"], "venue": "In International Conference on Software Engineering,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2010}, {"title": "Picture: A probabilistic programming language for scene perception", "author": ["Tejas D Kulkarni", "Pushmeet Kohli", "Joshua B Tenenbaum", "Vikash Mansinghka"], "venue": "In CVPR,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2015}, {"title": "Learning to optimize", "author": ["Ke Li", "Jitendra Malik"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2016}, {"title": "Superoptimizer: A look at the smallest program", "author": ["Henry Massalin"], "venue": "In ACM SIGPLAN Notices,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1987}, {"title": "Equation of state calculations by fast computing machines", "author": ["Nicholas Metropolis", "Arianna W Rosenbluth", "Marshall N Rosenbluth", "Augusta H Teller", "Edward Teller"], "venue": "The journal of chemical physics,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1953}, {"title": "Inference networks for sequential Monte Carlo in graphical models", "author": ["Brookes Paige", "Frank Wood"], "venue": "In ICML,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2016}, {"title": "Gradient estimation using stochastic computation graphs", "author": ["John Schulman", "Nicolas Heess", "Theophane Weber", "Pieter Abbeel"], "venue": "In NIPS,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2015}, {"title": "Simple statistical gradient-following algorithms for connectionist reinforcement learning", "author": ["Ronald J Williams"], "venue": "Machine learning,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1992}, {"title": "Learning to discover efficient mathematical identities", "author": ["Wojciech Zaremba", "Karol Kurach", "Rob Fergus"], "venue": "In NIPS", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2014}], "referenceMentions": [{"referenceID": 13, "context": "Using training data, which consists of a set of input programs, the parameters are learnt via the REINFORCE algorithm [18].", "startOffset": 118, "endOffset": 122}, {"referenceID": 3, "context": "By sequentially enumerating all programs in increasing length orders [5, 12], the shortest program meeting the specification is guaranteed to be found.", "startOffset": 69, "endOffset": 76}, {"referenceID": 9, "context": "By sequentially enumerating all programs in increasing length orders [5, 12], the shortest program meeting the specification is guaranteed to be found.", "startOffset": 69, "endOffset": 76}, {"referenceID": 9, "context": "The longest reported synthesized program was 12 instructions long, on a restricted instruction set [12].", "startOffset": 99, "endOffset": 103}, {"referenceID": 14, "context": "Similar work was done to discover efficient implementation of computation of value of degree k polynomials [19].", "startOffset": 107, "endOffset": 111}, {"referenceID": 1, "context": "[2] attempted this by simulating program execution using recurrent Neural Networks.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[4] proposed methods to deal with structured output spaces, in a \u201cLearning to search\u201d framework.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "Li and Malik [11] and Andrychowicz et al.", "startOffset": 13, "endOffset": 17}, {"referenceID": 0, "context": "[1] learns how to improve on first-order gradient descent algorithms, making use of neural networks.", "startOffset": 0, "endOffset": 3}, {"referenceID": 11, "context": "The training of a Neural Network to generate a proposal distribution to be used in sequential Monte-Carlo was also proposed by Paige and Wood [14] as a way to accelerate inference in graphical models.", "startOffset": 142, "endOffset": 146}, {"referenceID": 5, "context": "Additionally, similar approaches were successfully employed in computer vision problems where data driven proposals allowed to make inference feasible [8, 10, 20].", "startOffset": 151, "endOffset": 162}, {"referenceID": 7, "context": "Additionally, similar approaches were successfully employed in computer vision problems where data driven proposals allowed to make inference feasible [8, 10, 20].", "startOffset": 151, "endOffset": 162}, {"referenceID": 13, "context": "These can be obtained using the REINFORCE algorithm [18].", "startOffset": 52, "endOffset": 56}, {"referenceID": 12, "context": "A helpful way to derive them is to consider the execution traces of the search procedure under the formalism of stochastic computation graphs [16].", "startOffset": 142, "endOffset": 146}, {"referenceID": 4, "context": "4 Experiments We ran our experiments on the Hacker\u2019s delight [17] corpus, a collection of 25 bit-manipulation programs, used as benchmark in program synthesis [7, 9, 15].", "startOffset": 159, "endOffset": 169}, {"referenceID": 6, "context": "4 Experiments We ran our experiments on the Hacker\u2019s delight [17] corpus, a collection of 25 bit-manipulation programs, used as benchmark in program synthesis [7, 9, 15].", "startOffset": 159, "endOffset": 169}, {"referenceID": 0, "context": "[1] Marcin Andrychowicz, Misha Denil, Sergio Gomez, Matthew W Hoffman, David Pfau, Tom Schaul, and Nando de Freitas.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] Rudy Bunel, Alban Desmaison, Pushmeet Kohli, Philip HS Torr, and M Pawan Kumar.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[4] Janardhan Rao Doppa, Alan Fern, and Prasad Tadepalli.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[5] Torbj\u00f6rn Granlund and Richard Kenner.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[7] Sumit Gulwani, Susmit Jha, Ashish Tiwari, and Ramarathnam Venkatesan.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[8] Varun Jampani, Sebastian Nowozin, Matthew Loper, and Peter V Gehler.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[9] Susmit Jha, Sumit Gulwani, Sanjit A Seshia, and Ashish Tiwari.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[10] Tejas D Kulkarni, Pushmeet Kohli, Joshua B Tenenbaum, and Vikash Mansinghka.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "[11] Ke Li and Jitendra Malik.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "[12] Henry Massalin.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[13] Nicholas Metropolis, Arianna W Rosenbluth, Marshall N Rosenbluth, Augusta H Teller, and Edward Teller.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[14] Brookes Paige and Frank Wood.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[16] John Schulman, Nicolas Heess, Theophane Weber, and Pieter Abbeel.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[18] Ronald J Williams.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[19] Wojciech Zaremba, Karol Kurach, and Rob Fergus.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "In that case, in the limit, the distribution of states visited by the sampler will be p, making the optimal program the most sampled [13].", "startOffset": 133, "endOffset": 137}, {"referenceID": 10, "context": "As a consequence, the proposal distribution is not symmetric and the properties of the Metropolis algorithm [13] won\u2019t apply.", "startOffset": 108, "endOffset": 112}], "year": 2016, "abstractText": "Superoptimization requires the estimation of the best program for a given computational task. In order to deal with large programs, superoptimization techniques perform a stochastic search. This involves proposing a modification of the current program, which is accepted or rejected based on the improvement achieved. The state of the art method uses uniform proposal distributions, which fails to exploit the problem structure to the fullest. To alleviate this deficiency, we learn a proposal distribution over possible modifications using Reinforcement Learning. We provide convincing results on the superoptimization of \u201cHacker\u2019s Delight\u201d programs.", "creator": "LaTeX with hyperref package"}}}