{"id": "1701.01614", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Jan-2017", "title": "Enumeration of Extractive Oracle Summaries", "abstract": "To analyze the limitations and the future directions of the extractive summarization paradigm, this paper proposes an Integer Linear Programming (ILP) formulation to obtain extractive oracle summaries in terms of ROUGE-N. We also propose an algorithm that enumerates all of the oracle summaries for a set of reference summaries to exploit F-measures that evaluate which system summaries contain how many sentences that are extracted as an oracle summary. Our experimental results obtained from Document Understanding Conference (DUC) corpora demonstrated the following: (1) room still exists to improve the performance of extractive summarization; (2) the F-measures derived from the enumerated oracle summaries have significantly stronger correlations with human judgment than those derived from single oracle summaries.", "histories": [["v1", "Fri, 6 Jan 2017 12:28:15 GMT  (120kb)", "http://arxiv.org/abs/1701.01614v1", "12 pages"]], "COMMENTS": "12 pages", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["tsutomu hirao", "masaaki nishino", "jun suzuki", "masaaki nagata"], "accepted": false, "id": "1701.01614"}, "pdf": {"name": "1701.01614.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["hirao.tsutomu@lab.ntt.co.jp", "nishino.masaaki@lab.ntt.co.jp", "suzuki.jun@lab.ntt.co.jp", "nagata.masaaki@lab.ntt.co.jp"], "sections": [{"heading": null, "text": "ar Xiv: 170 1.01 614v 1 [cs.C L] 6J an2 017"}, {"heading": "1 Introduction", "text": "In fact, the majority of people who have chosen the EU in the last ten years have chosen a different EU than another EU, for another EU, for another EU, for another EU, for another EU, for another EU, for another EU, for another EU, for another EU, for another EU, for another EU, for another EU, for another EU, for another EU, for another EU, for another EU, for another EU, for another EU, for another EU, for another EU, for another EU, for another EU, for another EU, for another EU, for another EU, for another EU. \""}, {"heading": "2 Definition of Extractive Oracle Summaries", "text": "In view of the summary R and the summary of the system S, ROUGEn is defined as follows: ROUGEn (R, S) = | R | \u2211 k = 1 | U (Rk) | \u2211 j = 1min {N (gnj, Rk), N (g n j, S)} | R (g n j, S)} | E (k = 1 | U (Rk) | \u2211 j = 1N (gnj, Rk). (1) Rk returns the number of n-grams occurring in the summary of the k-th reference word Rk, and S the multiple of n-grams occurring in the system-generated summary S (a series of sentences). N (gnj, Rk) and N (g n j, S) indicate the number of occurrences of the n-gram gnj in the summary of the k-th reference word, and S denotes the multiple summary of the summary of the system."}, {"heading": "3 Related Work", "text": "Lin and Hovy (2003) used an approximate, exhaustive search method to obtain summary summaries relating to ROUGEn and used it to understand the limitations of extractive summaries. Ceylan et al. (2010) proposed another naive, exhaustive search method to derive a probability density function from the ROUGEn summaries of oracle summaries for the areas to which source documents belong. The computational complexity of naive, exhaustive methods is exponential to the size of the sentence. Thus, it may be possible to apply it to individual document summary tasks comprising a dozen sentences, but it is impracticable to apply it to multiple document summary tasks comprising several hundred sentences. To describe the difference between ROUGEn summaries of oracle and system summaries in multiple documents, the non-optimum summary tasks are to find Riehammer al al al al al al (2008) al al al algorithm al al al al al to a dangerous GA al al."}, {"heading": "4 Oracle Summary Extraction as an Integer Linear Programming (ILP) Problem", "text": "To extract a summary of the oracle from document (s) and a given set of reference summaries, we begin by deriving an Integer Linear Programming (ILP) problem. Since the denominator of Eq. (1) is constant for a given set of reference summaries, we can find a summary of the oracle by maximizing the counter of Eq. (1). Thus, the ILP formulation is defined as: Maximize z | R | x k = 1 | U (Rk)."}, {"heading": "5 Branch and Bound Technique for Enumerating Oracle Summaries", "text": "Since we have a summary of the sentences s1, s2, we can make a summary of the answers to the question of the origin of the search results. (...) Since we have a summary of the origin of the origin node in Fig. 1 shows an example of a search tree created in a naive search. (...) The nodes represent sentences and the path from the origin node to the origin node. (...) For example, the red path in Fig. 1 shows an example of an origin tree. (...) The origin nodes represent sentences and the path of the origin nodes represent a summary. (...) The red path in Fig. 1 represents a summary of the origin nodes. (...) By using the tree, we can make a summary of the origin nodes in Fig. (...)"}, {"heading": "13: U \u2190 U +", "text": "ROUGE \u2032 n (R, V, {w}) ({w}) \u00b7 Lmax14: Breaking the loop 15: End max.: End max.: End 17: Return U 18: endSince the second term on the right in Eq. (11) is a NP-hard problem, we address the following relationship by introducing inequality, ROUGE \u2032 n (R, V, E)."}, {"heading": "5.3 Initial Score for Search", "text": "Since the branch and binding technique truncates the search by comparing the best solution found to date with the upper limits, obtaining a good solution in the early stage is crucial for increasing search efficiency. Since ROUGEn is a monotonous submodular function (Lin and Bilmes, 2011), we can obtain a good approximate solution through a greedy algorithm (Khuller et al., 1999). It is guaranteed that the score of the approximate solution obtained is greater than 12 (1 \u2212 1e) OPT, where OPT is the score of the optimal solution. We use the solution as the initial ROUGEn score of the candidate oracle Summary. Algorithm 2 indicates the greedy algorithm. In it, S denotes a summary and D denotes a series of sentences. The algorithm adds sentences that bring the greatest gain in the ROUGEn score iteratively to the current summary. Algorithm S adds Uassuming the maximum length of the summary does not exceed the US by 4 lengths (while the US does not exceed the maximum by 4)."}, {"heading": "5.4 Enumeration of Oracle summaries", "text": "By introducing thresholds (R, V) 16: Endpoints (R, D, Lmax) we have achieved the following three conditions (R, D, Lmax): Algorithm 3 (R, D, Lmax) 3: for each s, D, D, Lmax) 3: for each s, D, D, O, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D,"}, {"heading": "6 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.1 Experimental Setting", "text": "We conducted experiments with the corpora developed for a task of summarizing several documents in the DUC 2001-2007. Table 1 shows the statistics of the data. In particular, the data sets of the DUC-2005-2007 have not only a very large number of sentences and words, but also a long target length (the reference summary) of 250 words. All words in the documents came from Porters Stemmer (Porter, 1980). We calculated ROUGE1 values, without stopwords, and calculated ROUGE2 values and retained them. Owczarzak et al. (2012) suggested using ROUGE1 and stopwords. However, like Takamura et al. argued (Takamura and Okumura, 2009) that the summaries optimized with non-content words did not take into account the actual quality."}, {"heading": "6.2 Results and Discussion", "text": "In fact, most of them are able to play by the rules that they have imposed on themselves, and they are able to play by the rules that they have imposed on themselves."}, {"heading": "6.2.3 Impact of Enumeration", "text": "\"Table 5 shows the mean number of oracle summaries and the quotas of reference sums that have multiple oracle summaries for each data set.\" \"Over 80% of the reference sums and about 60% to 90% of the topics have multiple oracle summaries. Since the source documents of multiple document summaries are based on the unweighted count of n-grams when many sentences have similar meanings, the number of oracle summaries that have the same ROUGEn results is higher. The source documents of the multiple document summary tasks are prone to have many such redundant sentences, and the amount of oracle summaries is large.The oracle summaries provide significant utility in terms of evaluating the extracted sentences. Since both the oracle and the system summary sentences are sets, it is easy to check whether each sentence is included in the system summary."}, {"heading": "6.2.4 Search Efficiency", "text": "In order to demonstrate the efficiency of our search algorithm against the na\u00efve, exhaustive search method, we compared the number of feasible solutions (sentences that meet the length limitation) with the number of summaries that were checked in our search algorithm. The algorithm that counts the number of feasible solutions is shown in Appendix B. Table 7, the mean number of feasible solutions and verified summaries that result from our method for each data set (in the case of \"individuals\"), however, the differences in the number of feasible solutions between ROUGE1 and ROUGE2 are very large. Input (| D |) of ROUGE1 is much larger than the summary of ROUGE1. On the other hand, the differences between ROUGE1 and ROUGE2 in our method are in the order of 10 to 102. Comparing our method with na\u00efve, exhaustive search results, the search space is significantly smaller. The differences are in the order of magnitude UGE1 to 107, the problem we have summarized with GROGE101 and the efficiency of GE101 and GE1."}, {"heading": "7 Conclusions", "text": "To analyze the limitations and future direction of extractive summaries, this paper (1) proposed Integer Linear Programming (ILP) to obtain extractive oracle summaries in the form of ROUGEn scores, and (2) an algorithm that lists all oracle summaries to use F measures to evaluate the sentences extracted from systems. Assessment results from the corpora of the DUCs from 2001 to 2007 showed the following: (1) There is still room to improve the ROUGEn scores of extractive summaries, even though the ROUGEn scores of oracle summaries fell below the theoretical ceiling of ROUGEn = 1. (2) More than 80% of the reference summaries and 60% to 90% of the reference summaries had multiple oracle summaries, and the F measures calculated by using the enumerated oracle summaries had stronger correlations with the human judgment capability than the oracle."}, {"heading": "Appendix A.", "text": "Proof. We can rewrite the right side of the equation (9) as follows: ROUGE (R, V) = > k (max.) + ROUGE (max.) + n (R, V, W) = | R | k (max.) # n (Rk, W). (13) Here, f (tn, Rk, V, W) is defined as follows: f (tn, Rk, V, W) = min {N (f, Rk, W) = min {N (tn, N). (14) N (tn, Rk, W)\\ V) is the number of times tn (V, Rk\\ V) = min {n (n, Rk), the number of times tn (V, Rk\\ V). Equation (14) is rewritten asf (tn, Rk\\ V, W) = min N (n, W)."}, {"heading": "Appendix B.", "text": "We propose an algorithm to calculate the number of feasible solutions below the length constraint by extending the dynamic, programmable approach to the subsum problem (Cormen et al., 2009). We define C [i] [j] (0 \u2264 i \u2264 | D |, 0 \u2264 j \u2264 Lmax), which stores the number of feasible solutions (length is less than j), which can be determined from sentence {s1,..., si} as follows: \u2022 Initialization C [0] [j] = 0 (0 \u2264 j \u2264 Lmax) (18) \u2022 Repeat (1 \u2264 i \u2264 | D |) C [i] [j] = {C [i \u2212 1] [j \u2212 (si)], if j \u2212 (si) \u2265 0 C [i \u2212 1] [j] otherwise (19) Algorithm 4 is a dynamic program that fills the (| D | + 1) x (Lmax + 1) x (m), after the first table contains the feasible number \u2212 1."}], "references": [{"title": "Fast and robust compressive summarization with dual decomposition and", "author": ["Almeida", "Martins2013] Miguel B. Almeida", "Andr\u00e9 F.T. Martins"], "venue": null, "citeRegEx": "Almeida et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Almeida et al\\.", "year": 2013}, {"title": "Multidocument abstractive summarization using ILP based multi-sentence compression", "author": ["Prasenjit Mitra", "Kazunari Sugiyama"], "venue": "In Proc. of the 24th International Joint Conference on Artificial In-", "citeRegEx": "Banerjee et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Banerjee et al\\.", "year": 2015}, {"title": "Abstractive multi-document summarization via phrase selection and merging", "author": ["Bing et al.2015] Lidong Bing", "Piji Li", "Yi Liao", "Wai Lam", "Weiwei Guo", "Rebecca J. Passonneau"], "venue": "In Proc. of the 53rd Annual Meeting of the Association for Compu-", "citeRegEx": "Bing et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Bing et al\\.", "year": 2015}, {"title": "Quantifying the limits and success of extractive summarization systems across domains", "author": ["Ceylan et al.2010] Hakan Ceylan", "Rada Mihalcea", "Umut \u00d6zertem", "Elena Lloret", "Manuel Palomar"], "venue": "In Proc. of the Human Language Technologies:", "citeRegEx": "Ceylan et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Ceylan et al\\.", "year": 2010}, {"title": "Left-brain/right-brain multi-document summarization", "author": ["Jade Goldstein", "Judith D. Schlesinger", "Dianne P. O\u2019Leary"], "venue": "In Proc. of the Document Understanding Conference (DUC)", "citeRegEx": "Conroy et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Conroy et al\\.", "year": 2004}, {"title": "Classy 2011 at TAC: Guided and multi-lingual summaries and evaluation metrics", "author": ["Judith D. Schlesinger", "Jeff Kubina", "Peter A. Rankel", "Dianne P. O\u2019Leary"], "venue": "In Proc. of the Text Analysis Conference", "citeRegEx": "Conroy et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Conroy et al\\.", "year": 2011}, {"title": "Multilingual summarization: Dimensionality reduction and a step towards optimal term coverage", "author": ["Sashka T. Davis", "Jeff Kubina", "Yi-Kai Liu", "Dianne P. O\u2019Leary", "Judith D Schlesinger"], "venue": "In Proc. of the MultiL-", "citeRegEx": "Conroy et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Conroy et al\\.", "year": 2013}, {"title": "Introduction to Algorithms", "author": ["Clifford Stein", "Ronald L. Rivest", "Charles E. Leiserson"], "venue": null, "citeRegEx": "Cormen et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Cormen et al\\.", "year": 2009}, {"title": "OCCAMS - an optimal combinatorial covering algorithm for multidocument summarization", "author": ["John M. Conroy", "Judith D. Schlesinger"], "venue": "In Proc. of the 12th IEEE International Conference on Data Mining Work-", "citeRegEx": "Davie et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Davie et al\\.", "year": 2012}, {"title": "A scalable global model for summarization", "author": ["Gillick", "Favre2009] Dan Gillick", "Benoit Favre"], "venue": "In Proc. of the Workshop on Integer Linear Programming for Natural Language Processing,", "citeRegEx": "Gillick et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Gillick et al\\.", "year": 2009}, {"title": "The ICSI/UTD summarization system at TAC", "author": ["Gillick et al.2009] Dan Gillick", "Benoit Favre", "Dilek Hakkani-Tur", "Berndt Bohnet", "Yang Liu", "Shasha Xie"], "venue": "In Proc. of the Text Analysis Conference (TAC)", "citeRegEx": "Gillick et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Gillick et al\\.", "year": 2009}, {"title": "Extracting import sentences with support vector machines", "author": ["Hirao et al.2002] Tsutomu Hirao", "Hideki Isozaki", "Eisaku Maeda", "Yuji Matsumoto"], "venue": "In Proc. of the 19th International Conference on Computational Linguistics (COLING),", "citeRegEx": "Hirao et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Hirao et al\\.", "year": 2002}, {"title": "Improving the estimation of word importance for news multi-document summarization", "author": ["Hong", "Nenkova2014] Kai Hong", "Ani Nenkova"], "venue": "In Proc. of the 14th Conference of the European Chapter of the Association for Computational Linguistics,", "citeRegEx": "Hong et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hong et al\\.", "year": 2014}, {"title": "A repository of state of the art and competitive baseline summaries for generic news summarization", "author": ["Hong et al.2014] Kai Hong", "John Conroy", "Benoit Favre", "Alex Kulesza", "Hui Lin", "Ani Nenkova"], "venue": "In Proc. of the Ninth International", "citeRegEx": "Hong et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hong et al\\.", "year": 2014}, {"title": "System combination for multidocument summarization", "author": ["Hong et al.2015] Kai Hong", "Mitchell Marcus", "Ani Nenkova"], "venue": "In Proc. of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Hong et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Hong et al\\.", "year": 2015}, {"title": "The budgeted maximum coverage problem", "author": ["Anna Moss", "Joseph Naor"], "venue": "Information Processing Letters,", "citeRegEx": "Khuller et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Khuller et al\\.", "year": 1999}, {"title": "Learning determinantal point process", "author": ["Kulesza", "Tasker2011] Alex Kulesza", "Ben Tasker"], "venue": "In Proc. of the 27th Conference on Uncertainty in Artificial Intelligence", "citeRegEx": "Kulesza et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Kulesza et al\\.", "year": 2011}, {"title": "A class of submodular functions for document summarization", "author": ["Lin", "Bilmes2011] Hui Lin", "Jeff Bilmes"], "venue": "In Proc. of the 49th Association for Computational Linguistics: Human Language Technologies,", "citeRegEx": "Lin et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Lin et al\\.", "year": 2011}, {"title": "Learning mixtures of submodular shells with application to document summarization", "author": ["Lin", "Bilmes2012] Hui Lin", "Jeff Bilmes"], "venue": "In Proc. of the 28th Conference on Uncertainty in Artificial Intelligence (UAI2012)", "citeRegEx": "Lin et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Lin et al\\.", "year": 2012}, {"title": "The potential and limitations of automatic sentence extraction for summarization", "author": ["Lin", "Hovy2003] Chin-Yew Lin", "Eduard Hovy"], "venue": "In Proc. of the HLT-NAACL 03 Text Summarization Workshop,", "citeRegEx": "Lin et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Lin et al\\.", "year": 2003}, {"title": "Machine learning of generic and user-focused summarization", "author": ["Mani", "Bloedorn1998] Inderjeet Mani", "Eric Bloedorn"], "venue": null, "citeRegEx": "Mani et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Mani et al\\.", "year": 1998}, {"title": "On evaluation of automatically generated clinical discharge summaries", "author": ["Moen et al.2014] Hans Moen", "Juho Heimonen", "LauraMaria Murtola", "Antti Airola", "Tapio Pahikkala", "Virpi Terv", "Riitta Danielsson-Ojala", "Tapio Salakoski", "Sanna Salanter"], "venue": null, "citeRegEx": "Moen et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Moen et al\\.", "year": 2014}, {"title": "Using maximum entropy for sentence extraction", "author": ["Miles Osborne"], "venue": "In Proceedings of the ACL-02 Workshop on Automatic Summarization,", "citeRegEx": "Osborne.,? \\Q2002\\E", "shortCiteRegEx": "Osborne.", "year": 2002}, {"title": "An assessment of the accuracy of automatic evaluation in summarization", "author": ["John M. Conroy", "Hoa Trang Dang", "Ani Nenkova"], "venue": "In Proc. of Workshop on Evaluation Metrics and System Comparison", "citeRegEx": "Owczarzak et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Owczarzak et al\\.", "year": 2012}, {"title": "Topical coherence for graph-based extractive summarization", "author": ["Hans-Martin Ramsl", "Michael Strube"], "venue": "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Parveen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Parveen et al\\.", "year": 2015}, {"title": "Optimizing an approximation of rouge - a problem-reduction approach to extractive multi-document summarization", "author": ["Peyrard", "Eckle-Kohler2016] Maxime Peyrard", "Judith Eckle-Kohler"], "venue": "In Proceedings of the 54th Annual Meeting of the Associa-", "citeRegEx": "Peyrard et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Peyrard et al\\.", "year": 2016}, {"title": "An algorithm for suffix stripping", "author": ["Martin F. Porter"], "venue": null, "citeRegEx": "Porter.,? \\Q1980\\E", "shortCiteRegEx": "Porter.", "year": 1980}, {"title": "Fast joint compression and summarization via graph cuts", "author": ["Qian", "Liu2013] Xian Qian", "Yang Liu"], "venue": "In Proc. of the 2013 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Qian et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Qian et al\\.", "year": 2013}, {"title": "Packing the meeting summarization knapsack", "author": ["Dan Gillick", "Benoit Favre", "Dilek Hakkani-T\u00fcr"], "venue": "In Proc. of the 9th Annual Conference of the International Speech Communication", "citeRegEx": "Riedhammer et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Riedhammer et al\\.", "year": 2008}, {"title": "Large-margin learning of submodular summarization models", "author": ["Sipos et al.2012] Ruben Sipos", "Pannaga Shivaswamy", "Thorsten Joachims"], "venue": "In Proc. of the 13th Conference of the European Chapter of the Association for Computational Linguistics,", "citeRegEx": "Sipos et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Sipos et al\\.", "year": 2012}, {"title": "Text summarization model based on maximum coverage problem and its variant", "author": ["Takamura", "Okumura2009] Hiroya Takamura", "Manabu Okumura"], "venue": "In Proc. of the 12th Conference of the European of the Association for Computational Linguis-", "citeRegEx": "Takamura et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Takamura et al\\.", "year": 2009}, {"title": "Compressive document summarization via sparse optimization", "author": ["Yao et al.2015] Jin-ge Yao", "Xiaojun Wan", "Jianguo Xiao"], "venue": "In Proc. of the 24th International Joint Conference on Artificial Intelligence (IJCAI", "citeRegEx": "Yao et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Yao et al\\.", "year": 2015}, {"title": "Extractive summarization by maximizing semantic volume", "author": ["Fei Liu", "Noah A. Smith"], "venue": "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Yogatama et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Yogatama et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 25, "context": ", Almeida and Martins (2013), Qian and Liu (2013), Yao et al. (2015), Banerjee et al.", "startOffset": 51, "endOffset": 69}, {"referenceID": 1, "context": "(2015), Banerjee et al. (2015), Bing et al.", "startOffset": 8, "endOffset": 31}, {"referenceID": 1, "context": "(2015), Banerjee et al. (2015), Bing et al. (2015)).", "startOffset": 8, "endOffset": 51}, {"referenceID": 1, "context": "(2015), Banerjee et al. (2015), Bing et al. (2015)). However, extractive summarization remains a primary research topic because the linguistic quality of the resultant summaries is guaranteed, at least at the sentence level, which is a key requirement for practical use (e.g., Hong and Nenkova (2014), Hong et al.", "startOffset": 8, "endOffset": 301}, {"referenceID": 1, "context": "(2015), Banerjee et al. (2015), Bing et al. (2015)). However, extractive summarization remains a primary research topic because the linguistic quality of the resultant summaries is guaranteed, at least at the sentence level, which is a key requirement for practical use (e.g., Hong and Nenkova (2014), Hong et al. (2015), Yogatama et al.", "startOffset": 8, "endOffset": 321}, {"referenceID": 1, "context": "(2015), Banerjee et al. (2015), Bing et al. (2015)). However, extractive summarization remains a primary research topic because the linguistic quality of the resultant summaries is guaranteed, at least at the sentence level, which is a key requirement for practical use (e.g., Hong and Nenkova (2014), Hong et al. (2015), Yogatama et al. (2015), Parveen et al.", "startOffset": 8, "endOffset": 345}, {"referenceID": 1, "context": "(2015), Banerjee et al. (2015), Bing et al. (2015)). However, extractive summarization remains a primary research topic because the linguistic quality of the resultant summaries is guaranteed, at least at the sentence level, which is a key requirement for practical use (e.g., Hong and Nenkova (2014), Hong et al. (2015), Yogatama et al. (2015), Parveen et al. (2015)).", "startOffset": 8, "endOffset": 368}, {"referenceID": 22, "context": "As a result, F-measures, which are available to evaluate a system summary, are useful for evaluating classification-based extractive summarization (Mani and Bloedorn, 1998; Osborne, 2002; Hirao et al., 2002).", "startOffset": 147, "endOffset": 207}, {"referenceID": 11, "context": "As a result, F-measures, which are available to evaluate a system summary, are useful for evaluating classification-based extractive summarization (Mani and Bloedorn, 1998; Osborne, 2002; Hirao et al., 2002).", "startOffset": 147, "endOffset": 207}, {"referenceID": 3, "context": "Ceylan et al. (2010) proposed another naive exhaustive search method to derive a probability density function from the ROUGEn scores of oracle summaries for the domains to which source documents belong.", "startOffset": 0, "endOffset": 21}, {"referenceID": 27, "context": "To describe the difference between the ROUGEn scores of oracle and system summaries in multiple document summarization tasks, Riedhammer et al. (2008) proposed an approximate algorithm with a genetic algorithm (GA) to find oracle summaries.", "startOffset": 126, "endOffset": 151}, {"referenceID": 21, "context": "Moen et al. (2014) utilized a greedy algorithm for the same purpose.", "startOffset": 0, "endOffset": 19}, {"referenceID": 29, "context": "and Sipos et al. (2012) trained their summarizers with oracle summaries found by a greedy algorithm.", "startOffset": 4, "endOffset": 24}, {"referenceID": 29, "context": "and Sipos et al. (2012) trained their summarizers with oracle summaries found by a greedy algorithm. Peyrard and Eckle-Kohler (2016) proposed a method to find a summary that approximates a ROUGE score based on the ROUGE scores of individual sentences and exploited the framework to train their summarizer.", "startOffset": 4, "endOffset": 133}, {"referenceID": 15, "context": "Since ROUGEn is a monotone submodular function (Lin and Bilmes, 2011), we can obtain a good approximate solution by a greedy algorithm (Khuller et al., 1999).", "startOffset": 135, "endOffset": 157}, {"referenceID": 26, "context": "All the words in the documents were stemmed by Porter\u2019s stemmer (Porter, 1980).", "startOffset": 64, "endOffset": 78}, {"referenceID": 23, "context": "Owczarzak et al. (2012) suggested using ROUGE1 and keeping stopwords.", "startOffset": 0, "endOffset": 24}, {"referenceID": 12, "context": "Since the systems in Table 2 were developed over many years, we compared the ROUGEn scores of the oracle summaries with those of the current state-of-the-art systems using the DUC-2004 corpus and obtained summaries generated by different systems from a public repository1 (Hong et al., 2014).", "startOffset": 272, "endOffset": 291}, {"referenceID": 4, "context": "The repository includes summaries produced by the following seven state-of-the-art summarization systems: CLASSY04 (Conroy et al., 2004), CLASSY11 (Conroy et al.", "startOffset": 115, "endOffset": 136}, {"referenceID": 5, "context": ", 2004), CLASSY11 (Conroy et al., 2011), Submodular (Lin and Bilmes, 2012), DPP (Kulesza and Tasker, 2011), RegSum (Hong and Nenkova, 2014), OCCAMS V (Davie et al.", "startOffset": 18, "endOffset": 39}, {"referenceID": 8, "context": ", 2011), Submodular (Lin and Bilmes, 2012), DPP (Kulesza and Tasker, 2011), RegSum (Hong and Nenkova, 2014), OCCAMS V (Davie et al., 2012; Conroy et al., 2013), and ICSISumm (Gillick and Favre, 2009; Gillick et al.", "startOffset": 118, "endOffset": 159}, {"referenceID": 6, "context": ", 2011), Submodular (Lin and Bilmes, 2012), DPP (Kulesza and Tasker, 2011), RegSum (Hong and Nenkova, 2014), OCCAMS V (Davie et al., 2012; Conroy et al., 2013), and ICSISumm (Gillick and Favre, 2009; Gillick et al.", "startOffset": 118, "endOffset": 159}, {"referenceID": 9, "context": ", 2013), and ICSISumm (Gillick and Favre, 2009; Gillick et al., 2009).", "startOffset": 22, "endOffset": 69}, {"referenceID": 9, "context": "331 result, while ICSISumm (Gillick and Favre, 2009; Gillick et al., 2009) (a compressive summarizer) achieved the best result with ROUGE2=0.", "startOffset": 27, "endOffset": 74}, {"referenceID": 9, "context": "331 result, while ICSISumm (Gillick and Favre, 2009; Gillick et al., 2009) (a compressive summarizer) achieved the best result with ROUGE2=0.098. These systems outperformed the best systems (Peers 65 and 67 in Table 2), but the differences in the ROUGEn scores between the systems and the oracle summaries are still large. More recently, Hong et al. (2015) demonstrated that their system\u2019s combination approach achieved the current best ROUGE2 score, 0.", "startOffset": 53, "endOffset": 357}, {"referenceID": 22, "context": "Thus, we can exploit the F-measures, which are useful for evaluating classification-based extractive summarization (Mani and Bloedorn, 1998; Osborne, 2002; Hirao et al., 2002).", "startOffset": 115, "endOffset": 175}, {"referenceID": 11, "context": "Thus, we can exploit the F-measures, which are useful for evaluating classification-based extractive summarization (Mani and Bloedorn, 1998; Osborne, 2002; Hirao et al., 2002).", "startOffset": 115, "endOffset": 175}, {"referenceID": 7, "context": "We propose an algorithm to compute the number of feasible solutions under the length constraint by extending the dynamic programming based approach for the subset sum problem (Cormen et al., 2009).", "startOffset": 175, "endOffset": 196}], "year": 2017, "abstractText": "To analyze the limitations and the future directions of the extractive summarization paradigm, this paper proposes an Integer Linear Programming (ILP) formulation to obtain extractive oracle summaries in terms of ROUGEn. We also propose an algorithm that enumerates all of the oracle summaries for a set of reference summaries to exploit F-measures that evaluate which system summaries contain how many sentences that are extracted as an oracle summary. Our experimental results obtained from Document Understanding Conference (DUC) corpora demonstrated the following: (1) room still exists to improve the performance of extractive summarization; (2) the F-measures derived from the enumerated oracle summaries have significantly stronger correlations with human judgment than those derived from single oracle summaries.", "creator": "LaTeX with hyperref package"}}}