{"id": "1701.01724", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Jan-2017", "title": "DeepStack: Expert-Level Artificial Intelligence in No-Limit Poker", "abstract": "Artificial intelligence has seen a number of breakthroughs in recent years, with games often serving as significant milestones. A common feature of games with these successes is that they involve information symmetry among the players, where all players have identical information. This property of perfect information, though, is far more common in games than in real-world problems. Poker is the quintessential game of imperfect information, and it has been a longstanding challenge problem in artificial intelligence. In this paper we introduce DeepStack, a new algorithm for imperfect information settings such as poker. It combines recursive reasoning to handle information asymmetry, decomposition to focus computation on the relevant decision, and a form of intuition about arbitrary poker situations that is automatically learned from self-play games using deep learning. In a study involving dozens of participants and 44,000 hands of poker, DeepStack becomes the first computer program to beat professional poker players in heads-up no-limit Texas hold'em. Furthermore, we show this approach dramatically reduces worst-case exploitability compared to the abstraction paradigm that has been favored for over a decade.", "histories": [["v1", "Fri, 6 Jan 2017 18:56:49 GMT  (334kb,D)", "http://arxiv.org/abs/1701.01724v1", null], ["v2", "Tue, 10 Jan 2017 04:35:28 GMT  (349kb,D)", "http://arxiv.org/abs/1701.01724v2", null], ["v3", "Fri, 3 Mar 2017 21:17:05 GMT  (383kb,D)", "http://arxiv.org/abs/1701.01724v3", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["matej morav\\v{c}\\'ik", "martin schmid", "neil burch", "viliam lis\\'y", "dustin morrill", "nolan bard", "trevor davis", "kevin waugh", "michael johanson", "michael bowling"], "accepted": false, "id": "1701.01724"}, "pdf": {"name": "1701.01724.pdf", "metadata": {"source": "CRF", "title": "DeepStack: Expert-Level Artificial Intelligence in No-Limit Poker", "authors": ["Matej Morav\u010d\u0131\u0301k", "Martin Schmid", "Neil Burch", "Viliam Lis\u00fd", "Dustin Morrill", "Nolan Bard", "Trevor Davis", "Kevin Waugh", "Michael Johanson", "Michael Bowling"], "emails": ["bowling@cs.ualberta.ca"], "sections": [{"heading": null, "text": "This year, it has come to the point that it has never come as far as it has this year."}, {"heading": "DeepStack", "text": "DeepStack is a general-purpose algorithm for a large class of imperfect information games."}, {"heading": "Continuous Re-Solving", "text": "Suppose we have a solution for the whole game, but then we forget this strategy. Can we reconstruct a solution for the subtree without solving the whole game again? We can reconstruct a strategy for the rest of the game that does not increase our total yield. Any value in the opposite direction is a counterproductive value."}, {"heading": "Limited Lookahead and Sparse Trees", "text": "The real situation is not always a complete strategy, but the solution itself is insoluble, except near the end of the game. There are only a limited number of actions that require an approximate solution for the whole game. To achieve a continuous new solution in practice, we need the second and third components of Deepstack.S \"n so that we can replace iterative improvement with an explicit response. Using explicit strategies for both players means that the strategy of each individual player is improved locally in every way. Results in CFR-D (17), solving a game that saves space by using sublimited strategies for both players."}, {"heading": "Deep Counterfactual Value Networks", "text": "In recent years, it has been shown that the number of players who are able, are able, are able to move, and that they are able, are able to move, and that they are able, are able to move. In recent years, the number of players who are able to move has multiplied. In recent years, the number of players who are able to move, to move, to move, to move has skyrocketed. \"The number of players who are able to move up has multiplied. The number of players who are able to move up has multiplied."}, {"heading": "Evaluating DeepStack", "text": "We rated DeepStack by playing it against a pool of professional poker players recruited by the International Federation of Poker (34). Thirty-three players from 17 countries were recruited, and each was asked to complete a 3,000-game game game over a four-week period between November 7 and December 12, 2016. However, cash incentives were awarded to the top three players ($5,000, $2,500, and $1,250 CAD). Assessing performance in HUNL is difficult due to the large differences in results per game due to randomly dealt private and public cards, and stochastic decisions made by players."}, {"heading": "Exploitability", "text": "The main objective of DeepStack is to approximate Nash's equilibrium game, i.e. minimize recoverability. While the exact recoverability of a HUNL poker strategy is difficult to calculate, the most recent local best-response technique (LBR) can provide a lower limit on the recoverability of a strategy (20), since it has full access to its action probabilities. LBR uses the action probabilities to calculate the reach of the strategy in each public state. Using this range, it selects its response measures from a fixed set, assuming that no more bets will be placed for the rest of the game. Thus, it responds best locally to the opponent's actions and provides a lower limit on their overall recoverability. As mentioned above, abstraction-based programs in LBR's annual computer poker contest are highly exploitable: four times more usable than any game."}, {"heading": "Discussion", "text": "DeepStack is the first computer program to defeat professional poker players heads-up, where there is no limit to Texas Hold'em, an imperfect information game with 10,160 decision points. Remarkably, it achieves this goal with almost no expertise or training from expert human games.The implications go beyond the mere fact of being a significant milestone for artificial intelligence. DeepStack is a paradigmatic shift in the approach of solutions to large, sequential, imperfect information games. These are two of the core principles that have driven success in perfect information games, though more conceptually simple to implement in these environments. As a result, DeepStack allows for the first time that the gap between the largest perfect and imperfect information games that have been mastered to focus on specific situations, two of the core principles that have driven success in perfect information games, even if they are easier to implement conceptually."}, {"heading": "Game of Heads-Up No-Limit Texas Hold\u2019em", "text": "In fact, most of the players who are able to outdo themselves are not able to outdo themselves; most of them are able to outlive themselves; most of them are able to outlive themselves; and most of them are able to outlive themselves; and most of them are able to outlive themselves; most of them are able to outlive themselves; and most of them are not able to outlive themselves; most of them are able to outlive themselves; and most of them are able to outlive themselves, and most of them are able to outlive themselves; most of them are not able to outlive themselves; and most of them are able to outlive themselves."}, {"heading": "Poker Glossary", "text": "s stack. The only response of the opponent can be callor fold.bet The first bet in a round; more chips in the pot.big blind initial bet made by the non-dealer before all the cards are dealt. The big blind is twice the size of the small blind.call Put enough chips in the pot to match the current bet; ends the round.check Decline to place all chips if they are not faced with a bet.Chip marker, the value used for bets; all bets must include an integral number of chips. Dealer The player who places the small blind in the pot is made first in round 1 and then in later rounds.Traditionally, they would distribute public and private cards from the deck.flop The second round; can refer either to the 3 revealed public cards, or the betting round after these cards are revealed. Give up the pot, all bets celebrated in the current betting."}, {"heading": "Performance Against Professional Players", "text": "To evaluate DeepStack against professionals, professional poker players were recruited by wire transfer from the International Federation of Poker (34), giving players four weeks to complete a game of 3,000 games. To motivate players, cash prizes of $5,000, $2,500, and $1,250 (CAD) were awarded to the top three players (as measured by AIVAT) who completed their game. Games were played between November 7 and December 12, 2016, and played through an online user interface (41), giving players the option to play up to four games simultaneously, as is customary on online poker websites. A total of 33 players from 17 countries played against DeepStack. DeepStack's performance against each individual is presented in Table 1, providing complete game histories with the complementary online materials. DeepStack implementation details Here, we describe the specifics of how DeepStack continuously dissolves and its deep counterfactual value networks were built."}, {"heading": "Continuous Re-Solving", "text": "This year it is more than ever before."}, {"heading": "Deep Counterfactual Value Networks", "text": "To train the networks, we generated random poker situations at the start of the flop and turned around. Each poker situation is defined by the top size, is enough for both players and deals with public cards. Complete betting history is not necessary as the pot and the areas represent a sufficient representation.The outputs of the network are vectors of mutual values, one for each player. Output values are interpreted as fragments of the pot size to improve generalization across poker situations.The training situations were generated by first selecting a pot size that was designed to approximate pot sizes from older HUNL programs.The player areas for the training situations must cover the space of the possible areas where CFR could occur during re-solving, not just those that are part of a solution."}, {"heading": "Local Best Response of DeepStack", "text": "Local Best Response (LBR) is a simple but effective technique to draw a lower limit on the usefulness of a strategy (20), which examines a set number of options to find a \"locally\" good action against the strategy. Although it seems natural that more options would be better, this is not always true. More options can lead to finding a locally good action that misses a future opportunity to exploit an even greater error in the opponent. In fact, LBR sometimes leads to the largest margins when no bets are taken in the early rounds to increase the size of the pot and thus the order of magnitude of future errors in a strategy. As mentioned in Table 4, LBR was recently used to show that abstraction-based agents are significantly usable. In all the cases tested, the strategies proved to be even more exploitable than simply folding every game.As shown in Table 4, this does not apply to DeepStack. In all the options available in the DeepStack 350, this stack is not found to be more flawed because this stack is not full."}, {"heading": "Proof of Theorem 1", "text": "Formal proof of the counterproductive value, which is the solidity of DeepStack's Deep-limited Continuous Re-Solving, is conceptually easy to follow. First, we must note that the exploitability introduced in a re-solving step has two linear components; a dueto solution of the subgame strategies (see Lemma 6), and one due to the bug in DeepStack's counterproductive value network (see Lemma 6). Together, we can create DeepStack's counterproductive value network for a single re-solve.8 Finally, we show that using the opposing values from the best action rather than the observed action does not increase overall exploitability (see Lemma 7)."}], "references": [{"title": "The ascent of man, Documentary", "author": ["J. Bronowski"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1973}, {"title": "Searching for solutions in games and artificial intelligence", "author": ["V.L. Allis"], "venue": "Ph.D. thesis,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1994}, {"title": "Measuring the size of large no-limit poker games, Technical Report TR13-01", "author": ["M. Johanson"], "venue": "Department of Computing Science, University of Alberta", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2013}, {"title": "Polk and team beat Claudico to win $100,000 from Microsoft & The Rivers Casino, Pokerfuse", "author": ["J. Wood", "Doug"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2015}, {"title": "Annual computer poker competition poker GUI client, https://github.com/dmorrill10/acpc poker gui client/tree/v1.2", "author": ["D. Morrill"], "venue": null, "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2012}], "referenceMentions": [], "year": 2017, "abstractText": "Artificial intelligence has seen a number of breakthroughs in recent years, with games often serving as significant milestones. A common feature of games with these successes is that they involve information symmetry among the players, where all players have identical information. This property of perfect information, though, is far more common in games than in real-world problems. Poker is the quintessential game of imperfect information, and it has been a longstanding challenge problem in artificial intelligence. In this paper we introduce DeepStack, a new algorithm for imperfect information settings such as poker. It combines recursive reasoning to handle information asymmetry, decomposition to focus computation on the relevant decision, and a form of intuition about arbitrary poker situations that is automatically learned from selfplay games using deep learning. In a study involving dozens of participants and 44,000 hands of poker, DeepStack becomes the first computer program to beat professional poker players in heads-up no-limit Texas hold\u2019em. Furthermore, we show this approach dramatically reduces worst-case exploitability compared to the abstraction paradigm that has been favored for over a decade.", "creator": "LaTeX with hyperref package"}}}