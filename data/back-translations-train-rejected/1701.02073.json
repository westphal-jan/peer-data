{"id": "1701.02073", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Jan-2017", "title": "Neural Personalized Response Generation as Domain Adaptation", "abstract": "In this paper, we focus on the personalized response generation for conversational systems. Based on the sequence to sequence learning, especially the encoder-decoder framework, we propose a two-phase approach, namely initialization then adaptation, to model the responding style of human and then generate personalized responses. For evaluation, we propose a novel human aided method to evaluate the performance of the personalized response generation models by online real-time conversation and offline human judgement. Moreover, the lexical divergence of the responses generated by the 5 personalized models indicates that the proposed two-phase approach achieves good results on modeling the responding style of human and generating personalized responses for the conversational systems.", "histories": [["v1", "Mon, 9 Jan 2017 06:42:57 GMT  (367kb,D)", "http://arxiv.org/abs/1701.02073v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["weinan zhang", "ting liu", "yifa wang", "qingfu zhu"], "accepted": false, "id": "1701.02073"}, "pdf": {"name": "1701.02073.pdf", "metadata": {"source": "CRF", "title": "Neural Personalized Response Generation as Domain Adaptation", "authors": ["Wei-Nan Zhang", "Ting Liu", "Yifa Wang", "Qingfu Zhu"], "emails": ["wnzhang@ir.hit.edu.cn"], "sections": [{"heading": null, "text": "In this paper, we focus on personalized response generation for voice systems. Based on the sequence learning sequence, in particular the encoder decoder framework, we propose a two-phase approach, namely initialization and customization, to model the responsive style of human responses and then generate personalized responses. To evaluate, we propose a novel, human-assisted method to evaluate the performance of personalized response generation models through online real-time conversations and offline human judgment. Furthermore, the lexical divergence of responses generated by the five personalized models suggests that the proposed two-phase approach achieves good results in modeling the responsive style of human responses and generates personalized responses for voice systems.Keywords: Personalized response generation, Conversational systems, Sequence to Sequence Learning, Domain Adaptation"}, {"heading": "1. Introduction", "text": "Conversation system, which is also referred to as conversation robot, virtual agent or chatbot, etc., is an interesting and challenging research of artificial intelligence. It can be applied to a large number of scenarios of human-computer interaction, such as answering questions [1], negotiations [2, 3], e-starts [4], tutoring [5], etc. Lately, conversation system usually plays the role of a virtual companion or assistant of Hu's email address: wnzhang @ ir.hit.edu.cn (Wei-Nan Zhang) Preprint to arXiv January 10, 2017ar Xiv: 170 1,02 073v 1 [cs.C L] 9J anman. For example, the virtual assistant on the mobile phone is one of the most popular application of d system, such as Siri, Cortana, Facebook M, Viv, etc."}, {"heading": "2. Our Approach", "text": "Recently, a series of research papers has been proposed to generate sentences or answers based on the relapsing neural network (RNN) [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]. The aim of this work is for the RNN-based model to attempt to generate an initial set y that can maximize the conditional probability of p (y | x). For the reaction generation of a conversation system, this approach usually consists of two parts, namely the encoder and the decoder. The encoder is to convert the input set into a vector that represents the complete semantics of the input set. The decoder then generates the initial set letter by letter (or word by word) according to the information about the encoding phase."}, {"heading": "2.1. Personalized Response Generation", "text": "Inspired by the RNN encoder decoder framework proposed by [17] and [6], we will propose in this paper a personalized response generation approach for voice systems.Figure 1 shows the framework of the proposed approach. From Figure 1, we can see that the proposed approach consists of two components, namely initialization and customization, the first of which is the responsive model of the call system using large-scale general training data and the second step fine-tuning the model based on the small size of personalized training data.We will also detail the proposed personalized response generation model. Typically, the encoder and decoder implemented by the GRU [22, 23] or LSTM [24, 25] based on the RNN model are called H, which is also referred to as annotations. The encoder reads the input sentence word by word and displays the hidden state of each word."}, {"heading": "2.2. Generation Quality Optimization", "text": "Compared to the response generated by the general RNN encoder decoding model, the two-phase training approach could generate different and personalized responses. However, we found another problem that when the first word is decoded into a high-frequency word in the vocabulary, such as \"we,\" \"I,\" \"yes,\" etc., the personalized response model tends to generate a generic response. To generate the first word in the decoding process, we use a learning scheme, namely the Learning to Start (LTS) model [28]. Unlike the classic RNN encoder decoding model, which \"uses\" a special character to generate the first word in the decoding process, the first word learns to predict using the context vector generated from the encoding process."}, {"heading": "3. Experiments and Analysis", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1. Experiment Data and Settings", "text": "Since the proposed approach to personalized response generation comprises two phases, there are two separate training data sets, namely general training data and personalized training data (see Figure 1). General training data is collected in several Chinese online forums. It contains 1 million one-to-one posts and pairs of responses, and the vocabulary contains 35 thousand words. For personalized training, we have invited 5 volunteers who have each shared 2,000 messages of their chain history from the use of instant messaging services without any privacy information. General messages, such as \"Hello,\" \"Good Morning,\" \"\" See you, \"will be removed from the personalized training data."}, {"heading": "3.2. Test and Evaluation", "text": "It is a non-trivial task to automatically evaluate the performance of a response model. As [7] said, \"Automatic evaluation of response generation is still an open problem.\" The BLEU socre [33], which is widely used in machine translation, is not an appropriate evaluation technique for response generation. Since the answers to the same Post1http: / / lucene.apache.org / 2http: / / www.sogou.com / labs / dl / cs.htmlmay share less common words, it is impossible to construct a reference set with adequate coverage. Meanwhile, the perplexity that is a rating metric for language modeling is also not useful for evaluating the relevance between mail and response. To address the above problems, we are designing a novel human evaluation method based on online chat and human judgment."}, {"heading": "3.3. Experimental Results", "text": "In fact, the fact is that most of them will be able to move to a different world, in which they are able to live than in another world, in which they are able to, and in which they are able to change the world."}, {"heading": "4. Related Work", "text": "In this context, it should be noted that most of them will be able to abide by the rules that they themselves have established, and that they will not be able to abide by the rules that they have established."}, {"heading": "5. Conclusion", "text": "In this paper, we proposed an approach to neural response generation based on the encoder decoder framework to learn the human (volunteer) response style and then generate personalized responses for conversation systems. The proposed approach extends the traditional encoder decoder approach to response generation through the introduction of a domain adaptation program, initialization-then-adaptation. We also proposed a novel human-assisted method to evaluate the chatbot's ability to mimic volunteers \"response styles. Experimental results validating lexical distribution and word overlaps suggest that the five responding models can capture the personalized response styles of the five volunteers. In the future, we will further improve the performance of personalized response models by introducing contextual information."}], "references": [{"title": "An artificially intelligent chat agent that answers adolescents\u2019 questions related to sex", "author": ["R. Crutzen", "G.Y. Peters", "S.D. Portugal", "E.M. Fisser", "J.J.J. Grolleman"], "venue": "drugs, and alcohol: An exploratory study, Journal of Adolescent Health 48 (5) ", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2011}, {"title": "Negochat-a: a chat-based negotiation agent with bounded rationality", "author": ["A. Rosenfeld", "I. Zuckerman", "E. Segalhalevi", "O. Drein", "S. Kraus"], "venue": "Autonomous Agents and Multi-Agent Systems 30 (1) ", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}, {"title": "Live-chat agent assignments to heterogeneous e-customers under imperfect classification", "author": ["P. Goes", "N. Ilk", "W.T. Yue", "J.L. Zhao"], "venue": "ACM TMIS 2 (4) ", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2011}, {"title": "Lsa for intuitive chat agents tutoring system", "author": ["G. Pilato", "G. Vassallo", "M. Gentile", "A. Augello", "S. Gaglio"], "venue": "", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2005}, {"title": "Sequence to sequence learning with neural networks", "author": ["I. Sutskever", "O. Vinyals", "Q.V. Le", "I. Sutskever", "O. Vinyals", "Q.V. Le"], "venue": "NIPS 4 ", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}, {"title": "A persona-based neural conversation model", "author": ["J. Li", "M. Galley", "C. Brockett", "G. Spithourakis", "J. Gao", "B. Dolan"], "venue": "in: ACL", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2016}, {"title": "Long short-term memory", "author": ["A. Graves"], "venue": "Neural Computation 9 (8) ", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1997}, {"title": "Learning to forget: Continual prediction with lstm, Neural Computation", "author": ["A. Gers F", "J. Schmidhuber", "F. Cummins"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1999}, {"title": "Maxout networks", "author": ["I.J. Goodfellow", "D. Warde-Farley", "M. Mirza", "A. Courville", "Y. Bengio"], "venue": "ICML ", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2013}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["T. Mikolov", "I. Sutskever", "K. Chen", "G. Corrado", "J. Dean"], "venue": "NIPS 26 ", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2013}, {"title": "Automatic online news issue construction in web environment", "author": ["C. Wang", "M. Zhang", "S. Ma", "L. Ru"], "venue": "in: WWW", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2008}, {"title": "Theano: Deep learning on gpus with python", "author": ["J. Bergstra", "F. Bastien", "O. Breuleux", "P. Lamblin", "R. Pascanu", "O. Delalleau", "G. Desjardins", "D. Warde-Farley", "I.J. Goodfellow", "A. Bergeron", "Y. Bengio"], "venue": "in: NIPS", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2011}, {"title": "Pomdp-based statistical spoken dialog systems: A review", "author": ["S. Young", "M. Gasic", "B. Thomson", "J.D. Williams"], "venue": "Proceedings of the IEEE 101 (5) ", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2013}, {"title": "Exploiting a probabilistic hierarchical model for generation", "author": ["S. Bangalore", "O. Rambow"], "venue": "in: COLING", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2000}, {"title": "Automatic generation of weather forecast texts using comprehensive probabilistic generation-space models", "author": ["A. Belz"], "venue": "Natural Language Engineering 14 (4) ", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2008}, {"title": "Individuality and alignment in generated dialogues", "author": ["A. Isard", "C. Brockmann", "J. Oberlander"], "venue": "in: INLG", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2006}, {"title": "Natural language generation as planning under uncertainty for spoken dialogue systems", "author": ["V. Rieser", "O. Lemon"], "venue": "in: EACL", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2009}, {"title": "M", "author": ["F. Mairesse"], "venue": "A. Walker, Trainable generation of big-five personality styles through data-driven parameter estimation., in: ACL", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2008}, {"title": "Training a sentence planner for spoken dialogue using boosting", "author": ["M.A. Walker", "O.C. Rambow", "M. Rogati"], "venue": "Computer Speech & Language 16 (3C4) ", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2002}, {"title": "R", "author": ["D.S. Paiva"], "venue": "Evans, Empirically-based control of natural language generation., in: ACL", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2005}, {"title": "M", "author": ["F. Mairesse"], "venue": ", Jurcicek, F. Ek, S. Keizer, B. Thomson, K. Yu, S. Young, Phrasebased statistical language generation using graphical models and active learning, in: ACL", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2010}, {"title": "Stochastic language generation in dialogue using factored language models", "author": ["F. Mairesse", "S. Young"], "venue": "Computational Linguistics 40 (4) ", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2014}, {"title": "Data-driven response generation in social media", "author": ["A. Ritter", "C. Cherry", "W.B. Dolan"], "venue": "in: EMNLP", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2011}, {"title": "Iris: a chat-oriented dialogue system based on the vector space model", "author": ["R.E. Banchs", "H. Li"], "venue": "in: ACL", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2012}, {"title": "Movie-dic: a movie dialogue corpus for research and development", "author": ["R.E. Banchs"], "venue": "in: ACL", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2012}, {"title": "Luke", "author": ["D. Ameixa", "L. Coheur", "P. Fialho", "P. Quaresma"], "venue": "I am Your Father: Dealing with Out-of-Domain Requests by Using Movies Subtitles", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2014}, {"title": "A hierarchical recurrent encoder-decoder for generative context-aware query suggestion", "author": ["A. Sordoni", "Y. Bengio", "H. Vahabi", "C. Lioma", "J. Grue Simonsen", "J.Y. Nie"], "venue": "in: CIKM", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "It can be applied to a large number of scenarios of human-computer interaction, such as question answering [1], negotiation [2, 3], e-commence [4], tutoring [5], etc.", "startOffset": 107, "endOffset": 110}, {"referenceID": 1, "context": "It can be applied to a large number of scenarios of human-computer interaction, such as question answering [1], negotiation [2, 3], e-commence [4], tutoring [5], etc.", "startOffset": 124, "endOffset": 130}, {"referenceID": 2, "context": "It can be applied to a large number of scenarios of human-computer interaction, such as question answering [1], negotiation [2, 3], e-commence [4], tutoring [5], etc.", "startOffset": 143, "endOffset": 146}, {"referenceID": 3, "context": "It can be applied to a large number of scenarios of human-computer interaction, such as question answering [1], negotiation [2, 3], e-commence [4], tutoring [5], etc.", "startOffset": 157, "endOffset": 160}, {"referenceID": 4, "context": "Recently, a number of research works have been proposed to generate sentence or response based on the recurrent neural network (RNN) [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21].", "startOffset": 133, "endOffset": 193}, {"referenceID": 5, "context": "Recently, a number of research works have been proposed to generate sentence or response based on the recurrent neural network (RNN) [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21].", "startOffset": 133, "endOffset": 193}, {"referenceID": 4, "context": "Personalized Response Generation Inspired by the RNN encoder-decoder framework, which is proposed by [17] and [6], in this paper, we proposed a personalized response generation approach for conversational systems.", "startOffset": 110, "endOffset": 113}, {"referenceID": 6, "context": "Typically, the encoder and decoder are implemented by the GRU [22, 23] or LSTM [24, 25, 26] based RNN.", "startOffset": 79, "endOffset": 91}, {"referenceID": 7, "context": "Typically, the encoder and decoder are implemented by the GRU [22, 23] or LSTM [24, 25, 26] based RNN.", "startOffset": 79, "endOffset": 91}, {"referenceID": 4, "context": ", hT } (1) Here, T equals to the length (the number of words) of the input sentence and f is a non-linear function which can be implemented as LSTM [6] or GRU [23].", "startOffset": 148, "endOffset": 151}, {"referenceID": 4, "context": "Where, c can be implemented in many ways, such as [6] set c = hT .", "startOffset": 50, "endOffset": 53}, {"referenceID": 4, "context": "Note that the context vector c, which is generated from the encoder, is also used to initialize the first hidden state [6] or all of the hidden states [17] of the decoder to make sure that the decoder can be conditioned by the encoder.", "startOffset": 119, "endOffset": 122}, {"referenceID": 8, "context": "The output of the decoder at the state st is to map to a distribution over the vocabulary by using the maxout activation function [27] In the proposed approach, the response generation model is implemented by an RNN encoder-decoder framework, which is inspired by [18].", "startOffset": 130, "endOffset": 134}, {"referenceID": 9, "context": "The dimension of the word embedding is 500 which is obtained by using the word2vec toolkit [29].", "startOffset": 91, "endOffset": 95}, {"referenceID": 10, "context": "The word2vec is trained with the SogouCS&CA corpus (2008 version)2, which is widely used for Chinese text analysis [30, 31].", "startOffset": 115, "endOffset": 123}, {"referenceID": 11, "context": "The encoder-decoder framework is implemented by using Theano toolkit [32].", "startOffset": 69, "endOffset": 73}, {"referenceID": 12, "context": "\u2022 Task-oriented Dialogue Generation The most successful research on the task-oriented dialogue system is mainly based on the partially observed Markov decision process (POMDP) [34].", "startOffset": 176, "endOffset": 180}, {"referenceID": 13, "context": "Previous research on taskoriented dialogue generation usually employed handcrafted generator to define the generation decision space with the handcrafted features or statistical models [35, 36, 37, 38, 39, 40, 41, 42].", "startOffset": 185, "endOffset": 217}, {"referenceID": 14, "context": "Previous research on taskoriented dialogue generation usually employed handcrafted generator to define the generation decision space with the handcrafted features or statistical models [35, 36, 37, 38, 39, 40, 41, 42].", "startOffset": 185, "endOffset": 217}, {"referenceID": 15, "context": "Previous research on taskoriented dialogue generation usually employed handcrafted generator to define the generation decision space with the handcrafted features or statistical models [35, 36, 37, 38, 39, 40, 41, 42].", "startOffset": 185, "endOffset": 217}, {"referenceID": 16, "context": "Previous research on taskoriented dialogue generation usually employed handcrafted generator to define the generation decision space with the handcrafted features or statistical models [35, 36, 37, 38, 39, 40, 41, 42].", "startOffset": 185, "endOffset": 217}, {"referenceID": 17, "context": "Previous research on taskoriented dialogue generation usually employed handcrafted generator to define the generation decision space with the handcrafted features or statistical models [35, 36, 37, 38, 39, 40, 41, 42].", "startOffset": 185, "endOffset": 217}, {"referenceID": 18, "context": "Previous research on taskoriented dialogue generation usually employed handcrafted generator to define the generation decision space with the handcrafted features or statistical models [35, 36, 37, 38, 39, 40, 41, 42].", "startOffset": 185, "endOffset": 217}, {"referenceID": 19, "context": "Previous research on taskoriented dialogue generation usually employed handcrafted generator to define the generation decision space with the handcrafted features or statistical models [35, 36, 37, 38, 39, 40, 41, 42].", "startOffset": 185, "endOffset": 217}, {"referenceID": 20, "context": "[43] proposed a statistical language generator which used a dynamic Bayesian networks to generate dialogue response.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "[44] learned to generate paraphrases in dialogue through a factored language model that was training from the data collected by crowdsourcing.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "They then presented an end-to-end dialogue response generator by using a phrase-based statistical machine translation model [46].", "startOffset": 124, "endOffset": 128}, {"referenceID": 23, "context": "[47] introduced a search-based system, namely IRIS, to generate dialogues using vector space model and then released the experimental corpus for research and development [48].", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "[47] introduced a search-based system, namely IRIS, to generate dialogues using vector space model and then released the experimental corpus for research and development [48].", "startOffset": 170, "endOffset": 174}, {"referenceID": 25, "context": "[49] introduced the knowledge bases that obtained from the Web to deal with the out-of-domain request.", "startOffset": 0, "endOffset": 4}, {"referenceID": 4, "context": "Recently, benefit from the advantages of the sequence to sequence learning framework with neural networks [6], [7] and [19] had drawn inspiration from the neural machine translation [17, 18] and proposed an RNN encoder-decoder based approach to generate dialogue by considering the last one sentence and a larger range of context respectively.", "startOffset": 106, "endOffset": 109}, {"referenceID": 26, "context": "[8] presented a hierarchical neural network, which is inspired by [50], to build an end-to-end dialogue system.", "startOffset": 66, "endOffset": 70}, {"referenceID": 5, "context": "The most similar work to this paper is [21].", "startOffset": 39, "endOffset": 43}], "year": 2017, "abstractText": "In this paper, we focus on the personalized response generation for conversational systems. Based on the sequence to sequence learning, especially the encoder-decoder framework, we propose a two-phase approach, namely initialization then adaptation, to model the responding style of human and then generate personalized responses. For evaluation, we propose a novel human aided method to evaluate the performance of the personalized response generation models by online real-time conversation and offline human judgement. Moreover, the lexical divergence of the responses generated by the 5 personalized models indicates that the proposed two-phase approach achieves good results on modeling the responding style of human and generating personalized responses for the conversational systems.", "creator": "LaTeX with hyperref package"}}}