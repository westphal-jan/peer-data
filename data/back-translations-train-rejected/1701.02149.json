{"id": "1701.02149", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Jan-2017", "title": "Task-Specific Attentive Pooling of Phrase Alignments Contributes to Sentence Matching", "abstract": "This work studies comparatively two typical sentence matching tasks: textual entailment (TE) and answer selection (AS), observing that weaker phrase alignments are more critical in TE, while stronger phrase alignments deserve more attention in AS. The key to reach this observation lies in phrase detection, phrase representation, phrase alignment, and more importantly how to connect those aligned phrases of different matching degrees with the final classifier. Prior work (i) has limitations in phrase generation and representation, or (ii) conducts alignment at word and phrase levels by handcrafted features or (iii) utilizes a single framework of alignment without considering the characteristics of specific tasks, which limits the framework's effectiveness across tasks. We propose an architecture based on Gated Recurrent Unit that supports (i) representation learning of phrases of arbitrary granularity and (ii) task-specific attentive pooling of phrase alignments between two sentences. Experimental results on TE and AS match our observation and show the effectiveness of our approach.", "histories": [["v1", "Mon, 9 Jan 2017 12:03:11 GMT  (250kb,D)", "http://arxiv.org/abs/1701.02149v1", "EACL'2017 long paper. arXiv admin note: substantial text overlap witharXiv:1604.06896"]], "COMMENTS": "EACL'2017 long paper. arXiv admin note: substantial text overlap witharXiv:1604.06896", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["wenpeng yin", "hinrich sch\\\"utze"], "accepted": false, "id": "1701.02149"}, "pdf": {"name": "1701.02149.pdf", "metadata": {"source": "CRF", "title": "Task-Specific Attentive Pooling of Phrase Alignments Contributes to Sentence Matching\u2217", "authors": ["Wenpeng Yin", "Hinrich Sch\u00fctze"], "emails": ["wenpeng@cis.lmu.de"], "sections": [{"heading": null, "text": "Previous work has shown (i) limitations in phrase generation and presentation, or (ii) alignment at the word and phrase level by technical characteristics, or (iii) use a single alignment framework without taking into account the characteristics of specific tasks, which limits the effectiveness of the framework across task areas. We propose an architecture based on a gated recurrent unit that supports (i) learning to render phrases of arbitrary granularity, and (ii) task-specific, attentive matching of phrase alignments between two sentences. TE and AS experimental results are consistent with our observations and demonstrate the effectiveness of our approach."}, {"heading": "1 Introduction", "text": "In fact, most of them are able to trump themselves, and they are able to trump themselves. (...) Most of them are not able to trump themselves. (...) Most of them are able to trump themselves. (...) Most of them are able to trump themselves. (...) Most of them are able to trump themselves. \"(...) Most of them are able to trump themselves.\" (...) Most of them are able to trump themselves. \"(...) Most of them are able to trump themselves.\" (...) Most of them are able to trump themselves. \""}, {"heading": "2 Related Work", "text": "This year it is as if it is a model in which the different edits should influence the model's decisions about sentence relationships. However, Wang and Manning (2010) can handle alignment between a sentence pair by applying a probabilistic model that identifies the degree of sentence similarity by modelling the missing words. Their model treats alignments as structured latent variables and provides a principled framework for the inclusion of complex linguistic features. Guo and Diab (2012) identify the degree of sentence similarity by modelling the missing words that are not in the sentence, thus relieving the sparse question of sentence modeling. Yih etal try to improve the flat semantic component, lexical semantic semantics by formulating the sentence pair as a latent word fitting problem."}, {"heading": "3 Model", "text": "This section first gives a brief introduction to GRU and how it performs phrase rendering learning, and then describes the various alert pools for phrase alignment with TE and AS tasks."}, {"heading": "3.1 GRU Introduction", "text": "GRU is a simplified version of LSTM. Both are effective in sequence modeling because they are order-sensitive and can capture a broad context; the trade-offs between GRU and its competitor LSTM have not yet been fully explored; according to empirical analysis in (Chung et al., 2014; Jozefowicz et al., 2015), there is no clear winner. In many tasks, both architectures provide comparable performance, and tuning hyperparameters such as layer size is probably more important than choosing the ideal architecture. GRU have fewer parameters and may therefore require a little faster or less data to generalize. Therefore, as shown in Figure 2, we use GRU to model text: z = circuit (xtU z + st \u2212 1W z) (1) r = circuit (xtU r + st \u2212 1W r) (1)."}, {"heading": "3.2 Representation Learning for Phrases", "text": "For a general sentence s with five consecutive words: ABCDE, where each word is represented by a word that embeds the dimensionality d, we first create four forged sentences, s1: \"BCDEA,\" s2: \"CDEAB,\" s3: \"DEABC,\" and s4: \"EABCD,\" then we place them in a matrix (Figure 3, left). We run GRUs in parallel on each line of this matrix. Since GRU is able to encode the entire sequence up to the current position, this step generates representations for any consecutive sentences in original sentences. (Figure 3, left) The hidden state of the GRU at position \"E\" at the coordinates (i.e., 1st line, 5th column) is the representation of the phrase \"ABCDE,\" which is in fact s itself, the hidden state at \"E\" (2,4) stands for the representation of the phrase \"BCDE,\" the hidden state of \"the\" E."}, {"heading": "3.3 Attentive Pooling", "text": "In fact, it is as if most of them are able to trump themselves when they see themselves able to trump themselves and to trump themselves. (...) It is as if they are able to trump themselves. (...) It is as if they are able to trump each other. (...) It is as if they are able to trump themselves. (...) It is as if they are able to trump themselves. (...) It is as if they are able to trump themselves. (...) It is as if they are able to trump each other. \"(...). (...) It is as if they are able to trump themselves. (...) It is as if they are able to trump themselves. (...)"}, {"heading": "3.4 The Whole Architecture", "text": "s take the sentences s1 \"ABC\" and s2 \"DEFG\" as an example. Each character, i.e. A to F, in the figure is indicated by an embedding vector, so each sentence is represented as an order 3 tensor as input (they are presented as rectangles for convenience only). Based on tensor-like sentence input, we have described the phrase representation by GRU1 in Section 3.2 and attentive pooling in Section 3.3. Attentive pooling generates a new feature map for each sentence, as in Figure 4 (the third layer from below), and each column representation in the feature sketch denotes a key sentence in this sentence, which should be a good basis for the correct final decision based on our modeling assumptions."}, {"heading": "4 Experiments", "text": "We test the proposed architectures for TE and AS benchmark datasets."}, {"heading": "4.1 Common Setup", "text": "For both TE and AS, words are initialized by 300-dimensional GloVe embedding (Pennington et al., 2014) and are not changed during training. For all unknown words, a single randomly initialized embedding is generated by uniform sampling from [\u2212.01,.01]. We use ADAM (Kingma et al., 2015), with a first impulse coefficient of 0.9 and a second impulse coefficient of 0.999.2 L2 regulation and diversity regulation (Xie et al., 2015). Table 1 shows the values of hyperparameters tuned to dev.Classifier. Following Yin et al. (2016a), we use three classifiers - logistic regression in DNN, logistic regression and linear SVM embedding with standard parameters 3 directly on the feature vector and reporting performance of the best.1nlp.stanford.edu / projects / 2standard configuration of the Kingliners and SVM system (SVM)."}, {"heading": "4.2 Textual Entailment", "text": "SemEval 2014 Task 1 (Marelli et al., 2014a) evaluates system predictions of textual relationships based on set pairs from the SICK dataset (Marelli et al., 2014b). The three classes are interconnected, contradictory and neutral. SICK train, development and test sets are 4439, 495 and 4906 pairs, respectively. We select the SICK benchmark dataset so that our result is directly comparable to that of (Yin et al., 2016a), where non-overlapping text is explicitly used to increase performance. This trick inspires this work. After Lai and Hockenmaier (2014) we train our final system (after setting hyperparameters) at both train and development level (4,934 pairs)."}, {"heading": "4.2.1 Feature Vector", "text": "The final feature vector as input of the classifier contains three parts: rep, simi, extra.Rep. A total of five vectors, three of which are the representation of the uppermost sentence s1, s2 and the uppermost sentence pair sp (shown in green in Figure 4), two are s01, s 0 2 from the addition baseline.Similarly. Four similarity values, cosine similarity and euclidean distance between s1 and s2, cosine similarity and euclidean distance between s01 and s02. Euclidean distance is transformed into 1 / (1 +). Extra. We include the same 22 linguistic features as Yin et al. (2016a). They cover 15 metrics of machine translation between the two sentences; whether the two sentences contain negation marks such as \"no,\" \"not,\" etc.; whether they contain synonyms, hypernyms or antonyms; two sentence lengths. See Ya (al for details)."}, {"heading": "4.2.2 Results", "text": "Table 2 shows that GRU provides state-of-the-art performance with k-min-max-pooling on SICK, significantly exceeding k-max-pooling and full-pooling. Full-pooling has more phrase input than the combination of k-max-max-pooling and k-min-max-pooling, which could cause two problems: (i) Loud alignments increase in pairs; (ii) the representation of sentence pairs sp is no longer discriminatory - sp does not know that its semantics is derived from phrases from s1 or s2: Since different sentences have different lengths, the boundary position between two sentences varies in pairs. However, this is crucial to determine whether s1 s2.ABCNN (Yin et al., 2016a) is based on assumptions similar to those of k-max-max-max-pooling: Words / phrases with higher match values should contribute more to this task. However, CNN achieves the optimum performance by creating a superimposed SICK version of two superpooling units in fact."}, {"heading": "4.3 Answer Selection", "text": "This data set consists of 20,360, 1130 and 2352 question-candidate pairs in train, development and test. Following Yang et al. (2015), we shorten the answers to 40 tokens and report on mean precision (MAP) and reciprocal rank (MRR). Apart from the common basic terms addition, ALSTM and ABCNN, we compare further with: (i) CNN-Cnt (Yang et al., 2015): combine CNN with two linguistic characteristics \"WordCnt\" (the number of non-stop words in the question that also occur in the answer) and \"WgtWordCnt\" (reweighting of the counts according to the IDF values of the questioners); (ii) AP-CNN (Santos et al., 2016)."}, {"heading": "4.3.1 Feature Vector", "text": "The last feature in AS has the same (rep, simi, extra) structure as Sm... Sm, except that Sm... Sm consists of only two kosine similarity scores, and additionally consists of four entries: two sentence lengths, WordCnt and WgtWordCnt.4http: / / aka.ms / WikiQA (Yang et al., 2015). e.. l Se.. l Se.. l Se.. l Se.. l Se.. l Se.. l Se.. l Se.. l Se.. l Se.. l Se.. l Se."}, {"heading": "4.3.2 Results", "text": "Table 3 shows that GRU with k-max-maxpooling is significantly better than its k-min-max-pooling and full-pooling versions. GRU with k-max-maxpooling assumes similar assumptions to ABCNN (Yin et al., 2016a) and AP-CNN (Santos et al., 2016): Units with higher matching values should contribute more to this task. Our improvement may be due to: i) Our linguistic units cover broader phrases, enabling alignments in a larger range; ii) we have two max-pooling steps in our attention pooling, especially the second one being able to remove some noisily aligned phrases. Both ABCNN and AP-CNN are based on revolutionary layers, the phrase detection is limited by filter sizes. Although ABCNN tries to detect a second CNN layer, their phrases may not be aligned in different CNN layers as they cannot be aligned directly in that space."}, {"heading": "4.4 Visual Analysis", "text": "In this subsection, we visualize the attention distributions by phrases, i.e., ai in Equation 5, from example sentences in Figure 1 (for space boundaries, we only show this for TE examples). Figure 5 (a) 5 (b) each show the attention values of each phrase in (Q, C +) pairs in TE examples in Figure 1. We can find that k-min-pooling through these distributions can actually detect some key phrases that are supposed to determine the pair relationships. Taking Figure 5 (a) as an example, phrases \"boy,\" phrases that are identified with \"and\" smiling, \"\" smiling, \"\" close \"and a few phrases that end with\" near, \"have lowest attention values. According to our k-min-pooling step, these phrases are recognized as key phrases that are close to phrases.\" Continue to Figure 5, \"if we are a couple of phrases,\" and \"if we are a couple of phrases with a smile.\""}, {"heading": "4.5 Effects of Pooling Size k", "text": "The basic idea of the proposed method is achieved by k-min / max pooling. We show how the hyperparameter k influences the results by adjusting it to the dev sets. In Figure 6 we see the performance trends when changing the k value between 1 and 10. Coarse k > 4 can provide competitive results, but larger values lead to a drop in performance."}, {"heading": "5 Conclusion", "text": "In this paper, we examine the contribution of different intensities of phrase matching to different tasks. We argue that it is not true that stronger matching is increasingly important. We found that TE tasks prefer weaker matching, while AS tasks prefer stronger matching. We proposed flexible mindfulness pools in the GRU system to meet the different needs of different tasks. Experimental results show the validity of our reasoning and the effectiveness of our attention-based GRU system. As future work, we plan to examine learning phrase matching in the context of how mindful pooling can be performed automatically regardless of the categories of tasks."}, {"heading": "Acknowledgments", "text": "We thank the German Research Foundation (DFG) for its support of this work (SCHU 2246 / 8-2)."}], "references": [{"title": "Neural machine translation by jointly learning to align and translate", "author": ["Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio."], "venue": "Proceedings of ICLR.", "citeRegEx": "Bahdanau et al\\.,? 2015", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2015}, {"title": "A comparison of vector-based representations for semantic composition", "author": ["William Blacoe", "Mirella Lapata."], "venue": "Proceedings of EMNLP-CoNLL, pages 546\u2013556.", "citeRegEx": "Blacoe and Lapata.,? 2012", "shortCiteRegEx": "Blacoe and Lapata.", "year": 2012}, {"title": "A large annotated corpus for learning natural language inference", "author": ["Samuel R Bowman", "Gabor Angeli", "Christopher Potts", "Christopher D Manning."], "venue": "Proceedings of EMNLP, pages 632\u2013642.", "citeRegEx": "Bowman et al\\.,? 2015a", "shortCiteRegEx": "Bowman et al\\.", "year": 2015}, {"title": "Recursive neural networks can learn logical semantics", "author": ["Samuel R Bowman", "Christopher Potts", "Christopher D Manning."], "venue": "Proceedings of CVSC workshop, pages 12\u201321.", "citeRegEx": "Bowman et al\\.,? 2015b", "shortCiteRegEx": "Bowman et al\\.", "year": 2015}, {"title": "Discriminative learning over constrained latent representations", "author": ["Ming-Wei Chang", "Dan Goldwasser", "Dan Roth", "Vivek Srikumar."], "venue": "Proceedings of NAACL-HLT, pages 429\u2013437.", "citeRegEx": "Chang et al\\.,? 2010", "shortCiteRegEx": "Chang et al\\.", "year": 2010}, {"title": "On the properties of neural machine translation: Encoder-decoder approaches", "author": ["Kyunghyun Cho", "Bart van Merri\u00ebnboer", "Dzmitry Bahdanau", "Yoshua Bengio."], "venue": "Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation.", "citeRegEx": "Cho et al\\.,? 2014", "shortCiteRegEx": "Cho et al\\.", "year": 2014}, {"title": "Empirical evaluation of gated recurrent neural networks on sequence modeling", "author": ["Junyoung Chung", "Caglar Gulcehre", "KyungHyun Cho", "Yoshua Bengio."], "venue": "arXiv preprint arXiv:1412.3555.", "citeRegEx": "Chung et al\\.,? 2014", "shortCiteRegEx": "Chung et al\\.", "year": 2014}, {"title": "Applying deep learning to answer selection: A study and an open task", "author": ["Minwei Feng", "Bing Xiang", "Michael R Glass", "Lidan Wang", "Bowen Zhou."], "venue": "Proceedings of IEEE ASRU Workshop.", "citeRegEx": "Feng et al\\.,? 2015", "shortCiteRegEx": "Feng et al\\.", "year": 2015}, {"title": "Modeling sentences in the latent space", "author": ["Weiwei Guo", "Mona Diab."], "venue": "Proceedings of ACL, pages 864\u2013872.", "citeRegEx": "Guo and Diab.,? 2012", "shortCiteRegEx": "Guo and Diab.", "year": 2012}, {"title": "Tree edit models for recognizing textual entailments, paraphrases, and answers to questions", "author": ["Michael Heilman", "Noah A Smith."], "venue": "Proceedings of NAACL-HLT, pages 1011\u20131019.", "citeRegEx": "Heilman and Smith.,? 2010", "shortCiteRegEx": "Heilman and Smith.", "year": 2010}, {"title": "Long short-term memory", "author": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber."], "venue": "Neural computation, 9(8):1735\u20131780.", "citeRegEx": "Hochreiter and Schmidhuber.,? 1997", "shortCiteRegEx": "Hochreiter and Schmidhuber.", "year": 1997}, {"title": "Convolutional neural network architectures for matching natural language sentences", "author": ["Baotian Hu", "Zhengdong Lu", "Hang Li", "Qingcai Chen."], "venue": "Proceedings of NIPS, pages 2042\u20132050.", "citeRegEx": "Hu et al\\.,? 2014", "shortCiteRegEx": "Hu et al\\.", "year": 2014}, {"title": "Unal-nlp: Combining soft cardinality features for semantic textual similarity, relatedness and entailment", "author": ["Sergio Jimenez", "George Duenas", "Julia Baquero", "Alexander Gelbukh", "Av Juan Dios B\u00e1tiz", "Av Mendiz\u00e1bal."], "venue": "SemEval, pages 732\u2013", "citeRegEx": "Jimenez et al\\.,? 2014", "shortCiteRegEx": "Jimenez et al\\.", "year": 2014}, {"title": "An empirical exploration of recurrent network architectures", "author": ["Rafal Jozefowicz", "Wojciech Zaremba", "Ilya Sutskever."], "venue": "Proceedings of ICML, pages 2342\u20132350.", "citeRegEx": "Jozefowicz et al\\.,? 2015", "shortCiteRegEx": "Jozefowicz et al\\.", "year": 2015}, {"title": "Adam: A method for stochastic optimization", "author": ["Diederik Kingma", "Jimmy Ba."], "venue": "Proceedings of ICLR.", "citeRegEx": "Kingma and Ba.,? 2015", "shortCiteRegEx": "Kingma and Ba.", "year": 2015}, {"title": "Illinois-lh: A denotational and distributional approach to semantics", "author": ["Alice Lai", "Julia Hockenmaier."], "venue": "SemEval, pages 329\u2013334.", "citeRegEx": "Lai and Hockenmaier.,? 2014", "shortCiteRegEx": "Lai and Hockenmaier.", "year": 2014}, {"title": "Gradient-based learning applied to document recognition", "author": ["Yann LeCun", "L\u00e9on Bottou", "Yoshua Bengio", "Patrick Haffner."], "venue": "Proceedings of the IEEE, 86(11):2278\u20132324.", "citeRegEx": "LeCun et al\\.,? 1998", "shortCiteRegEx": "LeCun et al\\.", "year": 1998}, {"title": "A hierarchical neural autoencoder for paragraphs and documents", "author": ["Jiwei Li", "Minh-Thang Luong", "Dan Jurafsky."], "venue": "Proceedings of ACL, pages 1106\u20131115.", "citeRegEx": "Li et al\\.,? 2015", "shortCiteRegEx": "Li et al\\.", "year": 2015}, {"title": "Effective approaches to attentionbased neural machine translation", "author": ["Minh-Thang Luong", "Hieu Pham", "Christopher D Manning."], "venue": "Proceedings of EMNLP, pages 1412\u20131421.", "citeRegEx": "Luong et al\\.,? 2015", "shortCiteRegEx": "Luong et al\\.", "year": 2015}, {"title": "Semeval-2014 task 1: Evaluation of compositional distributional semantic models on full sentences through semantic relatedness and tex", "author": ["Marco Marelli", "Luisa Bentivogli", "Marco Baroni", "Raffaella Bernardi", "Stefano Menini", "Roberto Zamparelli"], "venue": null, "citeRegEx": "Marelli et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Marelli et al\\.", "year": 2014}, {"title": "A sick cure for the evaluation of compositional distributional semantic models", "author": ["Marco Marelli", "Stefano Menini", "Marco Baroni", "Luisa Bentivogli", "Raffaella Bernardi", "Roberto Zamparelli."], "venue": "Proceedings of LREC, pages 216\u2013223.", "citeRegEx": "Marelli et al\\.,? 2014b", "shortCiteRegEx": "Marelli et al\\.", "year": 2014}, {"title": "Wordnet: A lexical database for english", "author": ["George A. Miller."], "venue": "Commun. ACM, 38(11):39\u201341.", "citeRegEx": "Miller.,? 1995", "shortCiteRegEx": "Miller.", "year": 1995}, {"title": "GloVe: Global vectors for word representation", "author": ["Jeffrey Pennington", "Richard Socher", "Christopher D Manning."], "venue": "Proceedings of EMNLP, pages 1532\u20131543.", "citeRegEx": "Pennington et al\\.,? 2014", "shortCiteRegEx": "Pennington et al\\.", "year": 2014}, {"title": "Reasoning about entailment with neural attention", "author": ["Tim Rockt\u00e4schel", "Edward Grefenstette", "Karl Moritz Hermann", "Tom\u00e1\u0161 Ko\u010disk\u1ef3", "Phil Blunsom."], "venue": "Proceedings of ICLR.", "citeRegEx": "Rockt\u00e4schel et al\\.,? 2016", "shortCiteRegEx": "Rockt\u00e4schel et al\\.", "year": 2016}, {"title": "A neural attention model for abstractive sentence summarization", "author": ["Alexander M Rush", "Sumit Chopra", "Jason Weston."], "venue": "Proceedings of EMNLP, pages 379\u2013389.", "citeRegEx": "Rush et al\\.,? 2015", "shortCiteRegEx": "Rush et al\\.", "year": 2015}, {"title": "Attentive pooling networks", "author": ["Cicero dos Santos", "Ming Tan", "Bing Xiang", "Bowen Zhou."], "venue": "arXiv preprint arXiv:1602.03609.", "citeRegEx": "Santos et al\\.,? 2016", "shortCiteRegEx": "Santos et al\\.", "year": 2016}, {"title": "Dynamic pooling and unfolding recursive autoencoders for paraphrase detection", "author": ["Richard Socher", "Eric H Huang", "Jeffrey Pennin", "Christopher D Manning", "Andrew Y Ng."], "venue": "Proceedings of NIPS, pages 801\u2013809.", "citeRegEx": "Socher et al\\.,? 2011", "shortCiteRegEx": "Socher et al\\.", "year": 2011}, {"title": "Lstmbased deep learning models for non-factoid answer selection", "author": ["Ming Tan", "Bing Xiang", "Bowen Zhou."], "venue": "arXiv preprint arXiv:1511.04108.", "citeRegEx": "Tan et al\\.,? 2015", "shortCiteRegEx": "Tan et al\\.", "year": 2015}, {"title": "Convolutional neural networks vs", "author": ["Kateryna Tymoshenko", "Daniele Bonadiman", "Alessandro Moschitti."], "venue": "convolution kernels: Feature engineering for answer sentence reranking. In Proceedings of NAACL-HLT, pages 1268\u20131278.", "citeRegEx": "Tymoshenko et al\\.,? 2016", "shortCiteRegEx": "Tymoshenko et al\\.", "year": 2016}, {"title": "A deep architecture for semantic matching with multiple positional sentence representations", "author": ["Shengxian Wan", "Yanyan Lan", "Jiafeng Guo", "Jun Xu", "Liang Pang", "Xueqi Cheng."], "venue": "Proceedings of AAAI, pages 2835\u20132841.", "citeRegEx": "Wan et al\\.,? 2016", "shortCiteRegEx": "Wan et al\\.", "year": 2016}, {"title": "Learning natural language inference with LSTM", "author": ["Shuohang Wang", "Jing Jiang."], "venue": "Proceedings of NAACL, pages 1442\u20131451.", "citeRegEx": "Wang and Jiang.,? 2016", "shortCiteRegEx": "Wang and Jiang.", "year": 2016}, {"title": "Probabilistic tree-edit models with structured latent variables for textual entailment and question answering", "author": ["Mengqiu Wang", "Christopher D Manning."], "venue": "Proceedings of Coling, pages 1164\u20131172.", "citeRegEx": "Wang and Manning.,? 2010", "shortCiteRegEx": "Wang and Manning.", "year": 2010}, {"title": "Probase: A probabilistic taxonomy for text understanding", "author": ["Wentao Wu", "Hongsong Li", "Haixun Wang", "Kenny Q Zhu."], "venue": "Proceedings of SIGMOD, pages 481\u2013492.", "citeRegEx": "Wu et al\\.,? 2012", "shortCiteRegEx": "Wu et al\\.", "year": 2012}, {"title": "On the generalization error bounds of neural networks under diversity-inducing mutual angular regularization", "author": ["Pengtao Xie", "Yuntian Deng", "Eric Xing."], "venue": "arXiv preprint arXiv:1511.07110.", "citeRegEx": "Xie et al\\.,? 2015", "shortCiteRegEx": "Xie et al\\.", "year": 2015}, {"title": "Wikiqa: A challenge dataset for open-domain question answering", "author": ["Yi Yang", "Wen-tau Yih", "Christopher Meek."], "venue": "Proceedings of EMNLP, pages 2013\u20132018.", "citeRegEx": "Yang et al\\.,? 2015", "shortCiteRegEx": "Yang et al\\.", "year": 2015}, {"title": "Semi-markov phrasebased monolingual alignment", "author": ["Xuchen Yao", "Benjamin Van Durme", "Chris CallisonBurch", "Peter Clark."], "venue": "Proceedings of EMNLP, pages 590\u2013600.", "citeRegEx": "Yao et al\\.,? 2013", "shortCiteRegEx": "Yao et al\\.", "year": 2013}, {"title": "Question answering using enhanced lexical semantic models", "author": ["Wen-tau Yih", "Ming-Wei Chang", "Christopher Meek", "Andrzej Pastusiak."], "venue": "Proceedings of ACL, pages 1744\u20131753.", "citeRegEx": "Yih et al\\.,? 2013", "shortCiteRegEx": "Yih et al\\.", "year": 2013}, {"title": "Convolutional neural network for paraphrase identification", "author": ["Wenpeng Yin", "Hinrich Sch\u00fctze."], "venue": "Proceedings of NAACL, pages 901\u2013911, May\u2013 June.", "citeRegEx": "Yin and Sch\u00fctze.,? 2015a", "shortCiteRegEx": "Yin and Sch\u00fctze.", "year": 2015}, {"title": "Multigrancnn: An architecture for general matching of text chunks on multiple levels of granularity", "author": ["Wenpeng Yin", "Hinrich Sch\u00fctze."], "venue": "Proceedings of ACL-IJCNLP, pages 63\u201373.", "citeRegEx": "Yin and Sch\u00fctze.,? 2015b", "shortCiteRegEx": "Yin and Sch\u00fctze.", "year": 2015}, {"title": "ABCNN: Attention-based convolutional neural network for modeling sentence pairs", "author": ["Wenpeng Yin", "Hinrich Sch\u00fctze", "Bing Xiang", "Bowen Zhou."], "venue": "TACL, 4:259\u2013272.", "citeRegEx": "Yin et al\\.,? 2016a", "shortCiteRegEx": "Yin et al\\.", "year": 2016}, {"title": "Simple question answering by attentive convolutional neural network", "author": ["Wenpeng Yin", "Mo Yu", "Bing Xiang", "Bowen Zhou", "Hinrich Sch\u00fctze."], "venue": "Proceedings of COLING, pages 1746\u20131756.", "citeRegEx": "Yin et al\\.,? 2016b", "shortCiteRegEx": "Yin et al\\.", "year": 2016}, {"title": "Deep learning for answer sentence selection", "author": ["Lei Yu", "Karl Moritz Hermann", "Phil Blunsom", "Stephen Pulman."], "venue": "NIPS Deep Learning Workshop.", "citeRegEx": "Yu et al\\.,? 2014", "shortCiteRegEx": "Yu et al\\.", "year": 2014}, {"title": "Ecnu: One stone two birds: Ensemble of heterogenous measures for semantic relatedness and textual entailment", "author": ["Jiang Zhao", "Tian Tian Zhu", "Man Lan."], "venue": "SemEval, pages 271\u2013277.", "citeRegEx": "Zhao et al\\.,? 2014", "shortCiteRegEx": "Zhao et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 2, "context": "How to model a pair of sentences is a critical issue in many NLP tasks, including textual entailment (Marelli et al., 2014a; Bowman et al., 2015a; Yin et al., 2016a) and answer selection (Yu et al.", "startOffset": 101, "endOffset": 165}, {"referenceID": 39, "context": "How to model a pair of sentences is a critical issue in many NLP tasks, including textual entailment (Marelli et al., 2014a; Bowman et al., 2015a; Yin et al., 2016a) and answer selection (Yu et al.", "startOffset": 101, "endOffset": 165}, {"referenceID": 41, "context": ", 2016a) and answer selection (Yu et al., 2014; Yang et al., 2015; Santos et al., 2016).", "startOffset": 30, "endOffset": 87}, {"referenceID": 34, "context": ", 2016a) and answer selection (Yu et al., 2014; Yang et al., 2015; Santos et al., 2016).", "startOffset": 30, "endOffset": 87}, {"referenceID": 25, "context": ", 2016a) and answer selection (Yu et al., 2014; Yang et al., 2015; Santos et al., 2016).", "startOffset": 30, "endOffset": 87}, {"referenceID": 36, "context": "Alignments at word level (Yih et al., 2013) or phrase level (Yao et al.", "startOffset": 25, "endOffset": 43}, {"referenceID": 35, "context": ", 2013) or phrase level (Yao et al., 2013) both have been studied before.", "startOffset": 24, "endOffset": 42}, {"referenceID": 21, "context": "(2013) make use of WordNet (Miller, 1995) and Probase (Wu et al.", "startOffset": 27, "endOffset": 41}, {"referenceID": 32, "context": "(2013) make use of WordNet (Miller, 1995) and Probase (Wu et al., 2012) for identifying hyper- and hyponymy.", "startOffset": 54, "endOffset": 71}, {"referenceID": 33, "context": ", 2013) or phrase level (Yao et al., 2013) both have been studied before. For example, Yih et al. (2013) make use of WordNet (Miller, 1995) and Probase (Wu et al.", "startOffset": 25, "endOffset": 105}, {"referenceID": 21, "context": "(2013) make use of WordNet (Miller, 1995) and Probase (Wu et al., 2012) for identifying hyper- and hyponymy. Yao et al. (2013) use POS tags, WordNet and paraphrase database for alignment identification.", "startOffset": 28, "endOffset": 127}, {"referenceID": 1, "context": "DNNs have been intensively investigated in sentence pair classifications (Blacoe and Lapata, 2012; Socher et al., 2011; Yin and Sch\u00fctze, 2015b), and attention mechanisms are also applied to individual tasks (Santos et al.", "startOffset": 73, "endOffset": 143}, {"referenceID": 26, "context": "DNNs have been intensively investigated in sentence pair classifications (Blacoe and Lapata, 2012; Socher et al., 2011; Yin and Sch\u00fctze, 2015b), and attention mechanisms are also applied to individual tasks (Santos et al.", "startOffset": 73, "endOffset": 143}, {"referenceID": 38, "context": "DNNs have been intensively investigated in sentence pair classifications (Blacoe and Lapata, 2012; Socher et al., 2011; Yin and Sch\u00fctze, 2015b), and attention mechanisms are also applied to individual tasks (Santos et al.", "startOffset": 73, "endOffset": 143}, {"referenceID": 25, "context": ", 2011; Yin and Sch\u00fctze, 2015b), and attention mechanisms are also applied to individual tasks (Santos et al., 2016; Rockt\u00e4schel et al., 2016; Wang and Jiang, 2016); however, most attention-based DNNs have implicit assumption that stronger alignments deserve more attention (Yin et al.", "startOffset": 95, "endOffset": 164}, {"referenceID": 23, "context": ", 2011; Yin and Sch\u00fctze, 2015b), and attention mechanisms are also applied to individual tasks (Santos et al., 2016; Rockt\u00e4schel et al., 2016; Wang and Jiang, 2016); however, most attention-based DNNs have implicit assumption that stronger alignments deserve more attention (Yin et al.", "startOffset": 95, "endOffset": 164}, {"referenceID": 30, "context": ", 2011; Yin and Sch\u00fctze, 2015b), and attention mechanisms are also applied to individual tasks (Santos et al., 2016; Rockt\u00e4schel et al., 2016; Wang and Jiang, 2016); however, most attention-based DNNs have implicit assumption that stronger alignments deserve more attention (Yin et al.", "startOffset": 95, "endOffset": 164}, {"referenceID": 39, "context": ", 2016; Wang and Jiang, 2016); however, most attention-based DNNs have implicit assumption that stronger alignments deserve more attention (Yin et al., 2016a; Santos et al., 2016; Yin et al., 2016b).", "startOffset": 139, "endOffset": 198}, {"referenceID": 25, "context": ", 2016; Wang and Jiang, 2016); however, most attention-based DNNs have implicit assumption that stronger alignments deserve more attention (Yin et al., 2016a; Santos et al., 2016; Yin et al., 2016b).", "startOffset": 139, "endOffset": 198}, {"referenceID": 40, "context": ", 2016; Wang and Jiang, 2016); however, most attention-based DNNs have implicit assumption that stronger alignments deserve more attention (Yin et al., 2016a; Santos et al., 2016; Yin et al., 2016b).", "startOffset": 139, "endOffset": 198}, {"referenceID": 39, "context": "We can treat the pre-processing in (Yin et al., 2016a) as a hard way, and ours as a soft way, as our phrases have more flexible lengths and the existence of overlapping phrases decreases the risk of losing important alignments.", "startOffset": 35, "endOffset": 54}, {"referenceID": 5, "context": "(i) We use GRU (Gated Recurrent Unit (Cho et al., 2014)) to learn representations for phrases of arbitrary granularity.", "startOffset": 37, "endOffset": 55}, {"referenceID": 1, "context": "DNNs have been intensively investigated in sentence pair classifications (Blacoe and Lapata, 2012; Socher et al., 2011; Yin and Sch\u00fctze, 2015b), and attention mechanisms are also applied to individual tasks (Santos et al., 2016; Rockt\u00e4schel et al., 2016; Wang and Jiang, 2016); however, most attention-based DNNs have implicit assumption that stronger alignments deserve more attention (Yin et al., 2016a; Santos et al., 2016; Yin et al., 2016b). Our examples in Figure 1, instead, show that this assumption does not hold invariably. Weaker alignments in certain tasks such as TE can be the indicator of the final decision. Our inspiration comes from the analysis of some prior work. For TE, Yin et al. (2016a) show that considering the pairs in which overlapping tokens are removed can give a boost.", "startOffset": 74, "endOffset": 711}, {"referenceID": 1, "context": "DNNs have been intensively investigated in sentence pair classifications (Blacoe and Lapata, 2012; Socher et al., 2011; Yin and Sch\u00fctze, 2015b), and attention mechanisms are also applied to individual tasks (Santos et al., 2016; Rockt\u00e4schel et al., 2016; Wang and Jiang, 2016); however, most attention-based DNNs have implicit assumption that stronger alignments deserve more attention (Yin et al., 2016a; Santos et al., 2016; Yin et al., 2016b). Our examples in Figure 1, instead, show that this assumption does not hold invariably. Weaker alignments in certain tasks such as TE can be the indicator of the final decision. Our inspiration comes from the analysis of some prior work. For TE, Yin et al. (2016a) show that considering the pairs in which overlapping tokens are removed can give a boost. This simple trick matches our motivation that weaker alignment should be given more attention in TE. However, Yin et al. (2016a) remove overlapping tokens completely, potentially obscuring complex alignment configurations.", "startOffset": 74, "endOffset": 930}, {"referenceID": 1, "context": "DNNs have been intensively investigated in sentence pair classifications (Blacoe and Lapata, 2012; Socher et al., 2011; Yin and Sch\u00fctze, 2015b), and attention mechanisms are also applied to individual tasks (Santos et al., 2016; Rockt\u00e4schel et al., 2016; Wang and Jiang, 2016); however, most attention-based DNNs have implicit assumption that stronger alignments deserve more attention (Yin et al., 2016a; Santos et al., 2016; Yin et al., 2016b). Our examples in Figure 1, instead, show that this assumption does not hold invariably. Weaker alignments in certain tasks such as TE can be the indicator of the final decision. Our inspiration comes from the analysis of some prior work. For TE, Yin et al. (2016a) show that considering the pairs in which overlapping tokens are removed can give a boost. This simple trick matches our motivation that weaker alignment should be given more attention in TE. However, Yin et al. (2016a) remove overlapping tokens completely, potentially obscuring complex alignment configurations. In addition, Yin et al. (2016a) use the same attention mechanism for TE and AS, which is less optimal based on our observations.", "startOffset": 74, "endOffset": 1056}, {"referenceID": 8, "context": "Heilman and Smith (2010) describe tree edit models that generalize tree edit distance by allowing operations that better account for complex reordering phenomena and by learning from data how different edits should affect the model\u2019s decisions about sentence relations.", "startOffset": 0, "endOffset": 25}, {"referenceID": 8, "context": "Heilman and Smith (2010) describe tree edit models that generalize tree edit distance by allowing operations that better account for complex reordering phenomena and by learning from data how different edits should affect the model\u2019s decisions about sentence relations. Wang and Manning (2010) cope with the alignment between a sentence pair by using a probabilistic model that models tree-edit operations on dependency parse trees.", "startOffset": 0, "endOffset": 294}, {"referenceID": 8, "context": "Guo and Diab (2012) identify the degree of sentence similarity by modeling the missing words (words that are not in the sentence) so as to relieve the sparseness issue of sentence modeling.", "startOffset": 0, "endOffset": 20}, {"referenceID": 4, "context": "(2013) try to improve the shallow semantic component, lexical semantics, by formulating sentence pair as a semantic matching problem with a latent word-alignment structure as in (Chang et al., 2010).", "startOffset": 178, "endOffset": 198}, {"referenceID": 15, "context": "More fine-grained word overlap and alignment between two sentences are explored in (Lai and Hockenmaier, 2014), in which negation, hypernym/hyponym, synonym and antonym relations are used.", "startOffset": 83, "endOffset": 110}, {"referenceID": 20, "context": "(2015b) employ recursive DNN to encode entailment on SICK (Marelli et al., 2014b).", "startOffset": 58, "endOffset": 81}, {"referenceID": 2, "context": "(2016) present an attention-based LSTM (long short-term memory, Hochreiter and Schmidhuber (1997)) for the SNLI corpus (Bowman et al., 2015a).", "startOffset": 119, "endOffset": 141}, {"referenceID": 2, "context": "(2013) try to improve the shallow semantic component, lexical semantics, by formulating sentence pair as a semantic matching problem with a latent word-alignment structure as in (Chang et al., 2010). More fine-grained word overlap and alignment between two sentences are explored in (Lai and Hockenmaier, 2014), in which negation, hypernym/hyponym, synonym and antonym relations are used. Yao et al. (2013) extend word-toword alignment to phrase-to-phrase alignment by a semi-Markov CRF.", "startOffset": 179, "endOffset": 407}, {"referenceID": 2, "context": "For TE, Bowman et al. (2015b) employ recursive DNN to encode entailment on SICK (Marelli et al.", "startOffset": 8, "endOffset": 30}, {"referenceID": 2, "context": "For TE, Bowman et al. (2015b) employ recursive DNN to encode entailment on SICK (Marelli et al., 2014b). Rockt\u00e4schel et al. (2016) present an attention-based LSTM (long short-term memory, Hochreiter and Schmidhuber (1997)) for the SNLI corpus (Bowman et al.", "startOffset": 8, "endOffset": 131}, {"referenceID": 2, "context": "For TE, Bowman et al. (2015b) employ recursive DNN to encode entailment on SICK (Marelli et al., 2014b). Rockt\u00e4schel et al. (2016) present an attention-based LSTM (long short-term memory, Hochreiter and Schmidhuber (1997)) for the SNLI corpus (Bowman et al.", "startOffset": 8, "endOffset": 222}, {"referenceID": 16, "context": "(2014) present a bigram CNN (convolutional neural network (LeCun et al., 1998)) to model question and answer candidates.", "startOffset": 58, "endOffset": 78}, {"referenceID": 26, "context": "Other sentence matching tasks such as paraphrase identification (Socher et al., 2011; Yin and Sch\u00fctze, 2015a), question \u2013 Freebase fact matching (Yin et al.", "startOffset": 64, "endOffset": 109}, {"referenceID": 37, "context": "Other sentence matching tasks such as paraphrase identification (Socher et al., 2011; Yin and Sch\u00fctze, 2015a), question \u2013 Freebase fact matching (Yin et al.", "startOffset": 64, "endOffset": 109}, {"referenceID": 40, "context": ", 2011; Yin and Sch\u00fctze, 2015a), question \u2013 Freebase fact matching (Yin et al., 2016b) etc.", "startOffset": 67, "endOffset": 86}, {"referenceID": 30, "context": "For AS, Yu et al. (2014) present a bigram CNN (convolutional neural network (LeCun et al.", "startOffset": 8, "endOffset": 25}, {"referenceID": 14, "context": "(2014) present a bigram CNN (convolutional neural network (LeCun et al., 1998)) to model question and answer candidates. Yang et al. (2015) extend this method and get state-of-the-art performance on the WikiQA dataset.", "startOffset": 59, "endOffset": 140}, {"referenceID": 7, "context": "Feng et al. (2015) test various setups of a bi-CNN architecture on an insurance domain QA dataset.", "startOffset": 0, "endOffset": 19}, {"referenceID": 7, "context": "Feng et al. (2015) test various setups of a bi-CNN architecture on an insurance domain QA dataset. Tan et al. (2015) explore bidirectional LSTM on the same dataset.", "startOffset": 0, "endOffset": 117}, {"referenceID": 7, "context": "Feng et al. (2015) test various setups of a bi-CNN architecture on an insurance domain QA dataset. Tan et al. (2015) explore bidirectional LSTM on the same dataset. Other sentence matching tasks such as paraphrase identification (Socher et al., 2011; Yin and Sch\u00fctze, 2015a), question \u2013 Freebase fact matching (Yin et al., 2016b) etc. are also investigated. Some prior work aims to solve a general sentence matching problem. Hu et al. (2014) present two CNN architectures for paraphrasing, sentence completion (SC), tweet-response matching tasks.", "startOffset": 0, "endOffset": 442}, {"referenceID": 7, "context": "Feng et al. (2015) test various setups of a bi-CNN architecture on an insurance domain QA dataset. Tan et al. (2015) explore bidirectional LSTM on the same dataset. Other sentence matching tasks such as paraphrase identification (Socher et al., 2011; Yin and Sch\u00fctze, 2015a), question \u2013 Freebase fact matching (Yin et al., 2016b) etc. are also investigated. Some prior work aims to solve a general sentence matching problem. Hu et al. (2014) present two CNN architectures for paraphrasing, sentence completion (SC), tweet-response matching tasks. Yin and Sch\u00fctze (2015b) propose the MultiGranCNN architecture to model general sentence matching based on phrase matching on multiple levels of granularity.", "startOffset": 0, "endOffset": 571}, {"referenceID": 7, "context": "Feng et al. (2015) test various setups of a bi-CNN architecture on an insurance domain QA dataset. Tan et al. (2015) explore bidirectional LSTM on the same dataset. Other sentence matching tasks such as paraphrase identification (Socher et al., 2011; Yin and Sch\u00fctze, 2015a), question \u2013 Freebase fact matching (Yin et al., 2016b) etc. are also investigated. Some prior work aims to solve a general sentence matching problem. Hu et al. (2014) present two CNN architectures for paraphrasing, sentence completion (SC), tweet-response matching tasks. Yin and Sch\u00fctze (2015b) propose the MultiGranCNN architecture to model general sentence matching based on phrase matching on multiple levels of granularity. Wan et al. (2016) try to match two sentences in AS and SC by multiple sentence representations, each coming from the local representations of two LSTMs.", "startOffset": 0, "endOffset": 722}, {"referenceID": 0, "context": ", in machine translation (Bahdanau et al., 2015; Luong et al., 2015) and text reconstruction (Li et al.", "startOffset": 25, "endOffset": 68}, {"referenceID": 18, "context": ", in machine translation (Bahdanau et al., 2015; Luong et al., 2015) and text reconstruction (Li et al.", "startOffset": 25, "endOffset": 68}, {"referenceID": 17, "context": ", 2015) and text reconstruction (Li et al., 2015; Rush et al., 2015).", "startOffset": 32, "endOffset": 68}, {"referenceID": 24, "context": ", 2015) and text reconstruction (Li et al., 2015; Rush et al., 2015).", "startOffset": 32, "endOffset": 68}, {"referenceID": 0, "context": ", in machine translation (Bahdanau et al., 2015; Luong et al., 2015) and text reconstruction (Li et al., 2015; Rush et al., 2015). In addition, attention-based alignment is also applied in natural language inference (e.g., Rockt\u00e4schel et al. (2016),Wang and Jiang (2016)).", "startOffset": 26, "endOffset": 249}, {"referenceID": 0, "context": ", in machine translation (Bahdanau et al., 2015; Luong et al., 2015) and text reconstruction (Li et al., 2015; Rush et al., 2015). In addition, attention-based alignment is also applied in natural language inference (e.g., Rockt\u00e4schel et al. (2016),Wang and Jiang (2016)).", "startOffset": 26, "endOffset": 271}, {"referenceID": 6, "context": "According to empirical evaluations in (Chung et al., 2014; Jozefowicz et al., 2015), there is not a clear winner.", "startOffset": 38, "endOffset": 83}, {"referenceID": 13, "context": "According to empirical evaluations in (Chung et al., 2014; Jozefowicz et al., 2015), there is not a clear winner.", "startOffset": 38, "endOffset": 83}, {"referenceID": 22, "context": "For both TE and AS, words are initialized by 300dimensional GloVe embeddings1 (Pennington et al., 2014) and not changed during training.", "startOffset": 78, "endOffset": 103}, {"referenceID": 14, "context": "We use ADAM (Kingma and Ba, 2015), with a first momentum coefficient of 0.", "startOffset": 12, "endOffset": 33}, {"referenceID": 33, "context": "999,2 L2 regularization and Diversity Regularization (Xie et al., 2015).", "startOffset": 53, "endOffset": 71}, {"referenceID": 14, "context": "We use ADAM (Kingma and Ba, 2015), with a first momentum coefficient of 0.9 and a second momentum coefficient of 0.999,2 L2 regularization and Diversity Regularization (Xie et al., 2015). Table 1 shows the values of the hyperparameters, tuned on dev. Classifier. Following Yin et al. (2016a), we use three classifiers \u2013 logistic regression in DNN, logistic regression and linear SVM with default parameters3 directly on the feature vector \u2013 and report performance of the best.", "startOffset": 13, "endOffset": 292}, {"referenceID": 23, "context": "The pioneering attention based LSTM system for a specific sentence pair classification task \u201cnatural language inference\u201d (Rockt\u00e4schel et al., 2016).", "startOffset": 121, "endOffset": 147}, {"referenceID": 39, "context": "(iii) ABCNN (Yin et al., 2016a).", "startOffset": 12, "endOffset": 31}, {"referenceID": 20, "context": ", 2014a) evaluates system predictions of textual entailment (TE) relations on sentence pairs from the SICK dataset (Marelli et al., 2014b).", "startOffset": 115, "endOffset": 138}, {"referenceID": 39, "context": "We choose SICK benchmark dataset so that our result is directly comparable with that of (Yin et al., 2016a), in which nonoverlapping text are utilized explicitly to boost the performance.", "startOffset": 88, "endOffset": 107}, {"referenceID": 15, "context": "Following Lai and Hockenmaier (2014), we train our final system (after fixing of hyperparameters) on train and dev (4,934 pairs).", "startOffset": 10, "endOffset": 37}, {"referenceID": 12, "context": "To p3 (Jimenez et al., 2014) 83.", "startOffset": 6, "endOffset": 28}, {"referenceID": 42, "context": "1 (Zhao et al., 2014) 83.", "startOffset": 2, "endOffset": 21}, {"referenceID": 15, "context": "6 (Lai and Hockenmaier, 2014) 84.", "startOffset": 2, "endOffset": 29}, {"referenceID": 3, "context": "6 TrRNTN (Bowman et al., 2015b) 76.", "startOffset": 9, "endOffset": 31}, {"referenceID": 39, "context": "7 ABCNN (Yin et al., 2016a) 86.", "startOffset": 8, "endOffset": 27}, {"referenceID": 39, "context": "We include the same 22 linguistic features as Yin et al. (2016a). They cover 15 machine translation metrics between the two sentences; whether or not the two sentences contain negation tokens like \u201cno\u201d, \u201cnot\u201d etc; whether or not they contain synonyms, hypernyms or antonyms; two sentence lengths.", "startOffset": 46, "endOffset": 65}, {"referenceID": 39, "context": "We include the same 22 linguistic features as Yin et al. (2016a). They cover 15 machine translation metrics between the two sentences; whether or not the two sentences contain negation tokens like \u201cno\u201d, \u201cnot\u201d etc; whether or not they contain synonyms, hypernyms or antonyms; two sentence lengths. See Yin et al. (2016a) for details.", "startOffset": 46, "endOffset": 320}, {"referenceID": 39, "context": "ABCNN (Yin et al., 2016a) is based on assumptions similar to k-max-max-pooling: words/phrases with higher matching values should contribute more in this task.", "startOffset": 6, "endOffset": 25}, {"referenceID": 28, "context": "88 (MRR) in (Tymoshenko et al., 2016)", "startOffset": 12, "endOffset": 37}, {"referenceID": 34, "context": "Apart from the common baselines Addition, ALSTM and ABCNN, we compare further with: (i) CNN-Cnt (Yang et al., 2015): combine CNN with two linguistic features \u201cWordCnt\u201d (the number of non-stopwords in the question that also occur in the answer) and \u201cWgtWordCnt\u201d (reweight the counts by the IDF values of the question words); (ii) AP-CNN (Santos et al.", "startOffset": 96, "endOffset": 115}, {"referenceID": 25, "context": ", 2015): combine CNN with two linguistic features \u201cWordCnt\u201d (the number of non-stopwords in the question that also occur in the answer) and \u201cWgtWordCnt\u201d (reweight the counts by the IDF values of the question words); (ii) AP-CNN (Santos et al., 2016).", "startOffset": 228, "endOffset": 249}, {"referenceID": 33, "context": "Following Yang et al. (2015), we truncate answers to 40 tokens and report mean average precision (MAP) and mean reciprocal rank (MRR).", "startOffset": 10, "endOffset": 29}, {"referenceID": 34, "context": "ms/WikiQA (Yang et al., 2015)", "startOffset": 10, "endOffset": 29}, {"referenceID": 39, "context": "GRU with k-max-maxpooling has similar assumption with ABCNN (Yin et al., 2016a) and AP-CNN (Santos et al.", "startOffset": 60, "endOffset": 79}, {"referenceID": 25, "context": ", 2016a) and AP-CNN (Santos et al., 2016): units with higher matching scores are supposed to contribute more in this task.", "startOffset": 20, "endOffset": 41}], "year": 2017, "abstractText": "This work studies comparatively two typical sentence matching tasks: textual entailment (TE) and answer selection (AS), observing that weaker phrase alignments are more critical in TE, while stronger phrase alignments deserve more attention in AS. The key to reach this observation lies in phrase detection, phrase representation, phrase alignment, and more importantly how to connect those aligned phrases of different matching degrees with the final classifier. Prior work (i) has limitations in phrase generation and representation, or (ii) conducts alignment at word and phrase levels by handcrafted features or (iii) utilizes a single framework of alignment without considering the characteristics of specific tasks, which limits the framework\u2019s effectiveness across tasks. We propose an architecture based on Gated Recurrent Unit that supports (i) representation learning of phrases of arbitrary granularity and (ii) task-specific attentive pooling of phrase alignments between two sentences. Experimental results on TE and AS match our observation and show the effectiveness of our approach.", "creator": "TeX"}}}