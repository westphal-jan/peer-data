{"id": "1701.02543", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Jan-2017", "title": "Predicting Citywide Crowd Flows Using Deep Spatio-Temporal Residual Networks", "abstract": "Forecasting the flow of crowds is of great importance to traffic management and public safety, and very challenging as it is affected by many complex factors, including spatial dependencies (nearby and distant), temporal dependencies (closeness, period, trend), and external conditions (e.g., weather and events). We propose a deep-learning-based approach, called ST-ResNet, to collectively forecast two types of crowd flows (i.e. inflow and outflow) in each and every region of a city. We design an end-to-end structure of ST-ResNet based on unique properties of spatio-temporal data. More specifically, we employ the residual neural network framework to model the temporal closeness, period, and trend properties of crowd traffic. For each property, we design a branch of residual convolutional units, each of which models the spatial properties of crowd traffic. ST-ResNet learns to dynamically aggregate the output of the three residual neural networks based on data, assigning different weights to different branches and regions. The aggregation is further combined with external factors, such as weather and day of the week, to predict the final traffic of crowds in each and every region. We have developed a real-time system based on Microsoft Azure Cloud, called UrbanFlow, providing the crowd flow monitoring and forecasting in Guiyang City of China. In addition, we present an extensive experimental evaluation using two types of crowd flows in Beijing and New York City (NYC), where ST-ResNet outperforms nine well-known baselines.", "histories": [["v1", "Tue, 10 Jan 2017 12:12:39 GMT  (6773kb,D)", "http://arxiv.org/abs/1701.02543v1", "21 pages, 16 figures. arXiv admin note: substantial text overlap witharXiv:1610.00081"]], "COMMENTS": "21 pages, 16 figures. arXiv admin note: substantial text overlap witharXiv:1610.00081", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["junbo zhang", "yu zheng", "dekang qi", "ruiyuan li", "xiuwen yi", "tianrui li"], "accepted": false, "id": "1701.02543"}, "pdf": {"name": "1701.02543.pdf", "metadata": {"source": "CRF", "title": "Predicting Citywide Crowd Flows Using Deep Spatio-Temporal Residual Networks", "authors": ["Junbo Zhanga", "Yu Zhenga", "Dekang Qib", "Ruiyuan Lic", "Xiuwen Yib", "Tianrui Lib"], "emails": [], "sections": [{"heading": null, "text": "Predicting mass flows is very important for traffic management and public safety, and very difficult as it is influenced by many complex factors, including spatial dependencies (near and far), time dependencies (proximity, period, trend), and external conditions (e.g. weather and events).We propose a deep learning approach called ST-ResNet to collectively predict two types of mass flows (i.e. inflow and outflow) in each region of a city.We design an end-to-end structure of ST-ResNet based on unique properties of spatio-temporal data. Specifically, we use the residual neural network framework to model the temporal proximity, period, and trend characteristics of mass transit. For each property, we design a branch of residual revolutionary units, each of which models the spatial properties of the human flow. ST-ResNet learns to dynamically aggregate the results of the three remaining neural networks based on the characteristics of the human stream, with the Azores and Azores being assigned to different units."}, {"heading": "1. Introduction", "text": "In fact, the fact is that most of them are able to survive on their own, in the way they do it: in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it, in the way they do it."}, {"heading": "2. Preliminary", "text": "We will first briefly return to the problem of predicting mass flows [3] and then introduce in-depth residual learning [5]."}, {"heading": "2.1. Formulation of Crowd Flow Prediction Problem", "text": "Definition 1 (Region [3]): There are many definitions of a place in terms of different granularities and semantic meanings. In this study, we divide a city into an I \u00b7 J grid map based on longitude and latitude, in which a grid denotes a region, as shown in Figure 2 (a). Definition 2 (inflow / outflow [3]: Let P be a collection of trajectories in the tenth time interval. For a grid (i, j) located at the ith row and the jth column, the inflow and outflow of human masses in the time interval t are each defined asxin, i, jt = Tr P | [k > 1 | gk \u2212 1 < (i, j) gk (i, j) and the jth column."}, {"heading": "2.2. Deep Residual Learning", "text": "Deep residual learning [6] enables neural folding networks to have a super-deep structure of 100 layers, even more than 1000 layers. And this method has shown state-of-the-art results in several demanding recognition tasks, including image classification, object recognition, segmentation and localization [6]. Formally, a residual unit with identity mapping [5] is defined as: X (l + 1) = X (l) + F (X (l))) (1), where X (l) and X (l + 1) are the input or output of the lth residual unit; F is a residual function, e.g. a stack of two 3 x 3 folding layers in [6]. The central idea of residual learning is to learn the additive residual function F in relation to X (l) [5]."}, {"heading": "3. System Architecture", "text": "Figure 3 shows the framework of our system, which consists of three main parts: local GPU servers and the cloud, as well as users (e.g. website and QR code), resulting in an offline or online flow of data. Local GPU servers store historical observations, such as taxi histories, meteorological data. The cloud receives real-time data, including real-time traffic data (e.g. trajectories) within a time interval, as well as meteorological data. Users access the input / output data and display it on websites or smartphones by scanning QR codes."}, {"heading": "3.1. The Cloud", "text": "A virtual machine (VM) in the cloud pulls this data from the redis and then calculates the crowd flows according to the GPS trajectories for each region of a city. Meanwhile, the VM extracts the features from meteorological data, event data and others. Then, the VM stores the crowd flow data and extracts features into memory (part of the VM). To store the resources in the cloud (additional storage requires more expensive payments), we store the crowd flow data and features only in the past two days. Historical data can be periodically moved to local servers. We use the Azure platform as a service (PaaS). Table 1 describes Azure3 resources for our system as well as prices4. We use an app called A2 Standard in Azure that provides 2 correct and 3.5 GB of storage space for potential results close to CrowdFlows in the past."}, {"heading": "3.2. Local GPU Servers", "text": "While all jobs can be done in the cloud, GPU services in the cloud are not supported in some areas (such as China). On the other hand, we have to pay for other cloud services such as storage and I / O bandwidth. Saving unnecessary costs is critical for a research prototype. In addition, migrating massive data from local servers to the cloud is time-consuming, given the limited network bandwidth. Thus, historical trajectories can amount to hundreds of gigabytes, even terabytes, which leads to a very long time for copying data from local servers to the cloud. Therefore, we use a hybrid framework that combines local GPU servers with the cloud. Local GPU servers mainly handle offline training (learning), including three tasks: \u2022 Convert trajectories to the inflow / outflow: We first use the massive historical trajectories and use a spreadsheet module to store crowd-flow data, and then we store it in external applications (the crowd-flow data, and then extract them locally)."}, {"heading": "3.3. User Interface", "text": "Figure 4 (a) shows the UrbanFlow [7] website, where each grid on the map represents a region and the associated number indicates the inflow or outflow of crowds. The user can view the inflow or outflow via the top right-hand button called \"InFlow / OutFlow.\" The smaller the number, the lower the flow of crowds. The color of each grid is determined in accordance with their crowds, e.g. \"red\" means \"dense\" Crowdflow and \"green\" means \"sparse\" Crowdflow. The upper right-hand corner of the website shows the buttons that can be switched between different types of crowds. A user can select any grid (representing a region) on the website and click on them to see the detailed flows of the region, as shown in Figure 4 (b), where blue, black and green curves show the flows of yesterday, yesterday, yesterday and the past, and the future, and in the same time points on each of the following times.The subpage shows some time points."}, {"heading": "4. Deep Spatio-Temporal Residual Networks", "text": "Recursive neural networks (RNNs), such as long-term short-term memory (LSTM), are able to learn long-term temporal dependencies (see Section 5.2 for empirical evaluation). According to ST domain knowledge, we know that only a few previous keyframes influence the next keyframe. Therefore, we use temporal proximity, period, trend to select keyframes for modeling. Figure 5 presents the ST-ResNet architecture, which consists of four important components that model temporal proximity, period, trend, and external influences. As illustrated in Figure 5, neuralisms are first divided into time."}, {"heading": "4.1. Structures of the First Three Components", "text": "The first three components (i.e. the proximity, the period, the trend) share the same network structure, which consists of two subcomponents, while the three subcomponents are not connected, as shown in Figure 6.Convolution. A city usually has a very large size, containing many regions with different distances. Intuitively, the flow of masses in nearby regions can affect each other, which can be effectively handled by the Convolutionary Neural Network (CNN), which has shown its strong ability to capture spatial structural information [9]. In addition, metro systems and highways connect two locations with a long distance, leading to dependence between distant regions. To capture the spatial dependence of each region, we need to design CNN with many layers that take into account only spatial dependencies limited by the size of their cores. The same problem was also found in the video sequence, where the input and output resolution have the resolution."}, {"heading": "4.2. The Structure of the External Component", "text": "Traffic flows can be influenced by many complex external factors, such as weather and event. Figure 8 (a) shows that traffic flows during the holidays (Chinese Spring Festival) can differ significantly from traffic flows during normal days. Figure 8 (b) shows that heavy rain significantly reduces traffic flows in the office area compared to the same day last week. Let's not be the feature vector that represents these external factors in the predicted time interval. In our implementation, we mainly take into account weather, holiday event and metadata (i.e. day of the week, day of the week / weekend).The details are presented in Table 2. To predict traffic flows in the time interval, the holiday event and metadata can be determined directly. However, the weather in the future time interval is unknown. Instead, you can use the forecast weather in the time interval t or the approximate weather in the time interval. Formally, we stack two completely connected layers on top of each other, each of which can be followed for the first layer of activation."}, {"heading": "4.3. Fusion", "text": "In this section, we discuss how to merge four components of Figure 5. First, we merge the first three components of the q method with a parametric matrix-based fusion method, which is then further combined with the external component. Figure 9 (a) and (d) show the Beijing trajectory data quotient curves presented in Table 2, with the x-axis time gap between two time intervals and the y-axis being the mean quotient value between two arbitrary inflows having the same time gap. The curves from two different regions all show an empirical time correlation in time series, namely the inflows of the most recent time intervals are more relevant than the inflows of the distant time intervals, which implies temporal proximity."}, {"heading": "4.4. Algorithms and Optimization", "text": "Algorithm 1 sketches the ST-ResNet training process. We first construct the training processes \u00b7 \u00b7 q = q = q = q = 6 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7"}, {"heading": "5. Experiments", "text": "In this section, we evaluate our ST-ResNet based on two types of crowdflows in Beijing and NYC based on 9 baselines."}, {"heading": "5.1. Settings", "text": "In fact, it is a way in which people are able to determine for themselves how they want to behave."}, {"heading": "5.2. Evaluation of Single-step Ahead Prediction", "text": "In this section we assess the prediction of a single step, namely the prediction of mass flows in due time t using historical observations. Table 5 shows the RMSE of all methods on both TaxiBJ and BikeNYC. Our ST-ResNet consistently and significantly outperforms all baselines. In particular, the results on TaxiBJ show that STResNet (with 12 residual units) is relatively 26% better than ARIMA, 37% better than SARIMA, 26% better than VAR, 14% better than ST-ANN, 7% better than DeepST, 28% to 64% better than RNN, 18.1% to 45.7% better than LSTM, 17.4% to 46.1% better than GRU. ST-ResNet-noExt is a degraded version of ST-ResNet that does not take into account external factors (e.g. the meteorological data)."}, {"heading": "5.3. Results of Different ST-ResNet Variants", "text": "Here we present the results of different ST-ResNet variants, including changing network configurations, network depth and various components used."}, {"heading": "5.3.1. Impage of different network configurations", "text": "Figure 11 shows the results of different network configurations. The same hyperparameters: lc = 3, lp = 1, lq = 1, number of residual units = 12.8The smaller the better. \u2022 Effect of batch normalization (BN): We try to incorporate BN into each residual unit and find that the RMSE slightly improves in the single-stage prediction, as shown in Figure 11 (a). \u2022 Effect of parametric matrix-based fusion: We use a parametric matrix-based fusion mechanism (see Equation 4) to merge temporal proximity, periodic and trend components. Simply put, one can also apply a simple method of merging, i.e. X (L + 2) c + X (L + 2) p + X (L + 2) q. Figure 11 (b) shows that ours is significantly better than the simple method of adjusting the effectiveness of our proposed parametric model (X + 2) and we (L + 2) resistant to the unit (1)."}, {"heading": "5.3.2. Impact of network depth", "text": "Figure 12 shows the effects of network depth. The deeper the network goes (i.e. the number of residual units increases), the smaller and larger the RMSE of the model, which shows that the deeper network often achieves a better result because it can detect not only spatial dependencies near, but also remotely. However, if the network is very deep (e.g. the number of residual units \u2265 14), the training becomes very difficult."}, {"heading": "5.3.3. Impact of filter size and number", "text": "The receptive field of a fold is determined by the size of the filter used. Here, we change the size of the filter from 2 x 2 to 5 x 5. Figure 13 (a) shows that the larger filter size has the lower RMSE, which shows that a larger receptive field has a better ability to model spatial dependencies."}, {"heading": "5.3.4. Impact of temporal closeness, period, trend", "text": "Here we examine the effects of temporal proximity, period, trend components on TaxiBJ, as shown in Figure 14. Figure 14 (a) shows the effect of temporal proximity, where we fix lp = 1 and lq = 1, but change lc. For example, lc = 0 means that we do not use the proximity component, which results in a very bad RMSE: 35.04. We can observe that RMSE first decreases and then increases when the length of the proximity increases, suggesting that lc = 4 performs best. Figure 14 (b) shows the effect of the period in which we set lc as 3 and lq as 1, but change lp. We can see that lp = 1 has the best RMSE. The model without the period component (i.e. lp = 0) is worse than the model with lp = 2, 3, but better than the model lp = 4, which means that short-term periods are always beneficial."}, {"heading": "5.4. Evaluation of Multi-step Ahead Prediction", "text": "According to algorithm 2, we can use historical observations and recently forecasted data to predict mass flows in subsequent time intervals related to multi-step predictions. Figure 16 shows multi-step prediction results from 13 different models on TaxiBJ. Among these models, ST-ResNet [BN], ST-ResNet [CP], and STResNet [C] are three variants of ST-ResNet (12 residual units), of which ST-ResNet [BN] uses BN in all residual units, ST-ResNet [CP] uses not the trend component, but three others, ST-ResNet [C] only uses proximity and external components. LSTM-3, LSTM-6, and LSTM-12 are three variants of LSTM (see details in Section 5.1). In real-world applications, ResNet-ahead ResNet-ResNet-11 is very good, Resource-Resource-2 is more important resource resource-2."}, {"heading": "5.5. Efficiency and Resources", "text": "As introduced in Section 3.1, there are four main steps to predict crowd flows for each region of a city: (1) pulling trajectories out of Redis; (2) converting trajectories into crowd flow data; (3) predicting crowd flows in the near future; (4) pushing results into Redis. We also report the time taken to complete over four steps. Overall, A2 Standard VM completes the entire prediction process in 18.56 seconds. It takes 10.93 seconds on D4 Standard VM, which is more powerful but more expensive. You can opt for A2 Standard because it costs only 20% money but achieves more than 50% performance."}, {"heading": "6. Related Work", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.1. Crowd Flow Prediction", "text": "There is some already published work on predicting the movement of an individual on the basis of his local history [23, 24], predicting mainly millions, even billions, of traces of individual mobility rather than the aggregated mass flows in a region. Such a task can require enormous computational resources, and it is not always necessary for the application scenario of public safety. Some other researchers aim at predicting the speed and volume of traffic on the road [25, 26, 27]. Most of them predict single or multiple sections of road and not city-wide [27, 28]. Recently, researchers have focused on predicting traffic flow on an urban scale [22, 29]. Both work differ from ours, where the proposed methods naturally focus on the individual region, not the city, and they do not divide the city by a grid-based method that requires a more complex method to find irregular regions at first."}, {"heading": "6.2. Classical Models for Time Series Prediction", "text": "The prediction of mass flows can be considered a kind of prediction problem of time series. However, there are several conventional linear models for such a problem. The historical average model is portable, which only uses the average of historical time series to predict the future value of time series. However, the model cannot respond to dynamic changes such as incidents [30]. The Auto-Regressive Integrated Moving Average (ARIMA) model assumes that the future value of time series is a linear combination of previous values and residuals. Furthermore, the non-stationary time series should be differentiated prior to analysis [31]. ARIMA is not suitable for time series with missing data as it relies on continuous time series and the data filling technique could be problematic as the complexity of the situation increases [32]. The additional seasonal difference is often applied to seasonal time series before ARIMA is used, which is called SIMA."}, {"heading": "6.3. Deep Neural Networks", "text": "Neural networks and deep learning [4, 38, 39] have achieved numerous successes in areas such as computing, vision [13, 40], speech recognition [41, 42] and natural language processing [43]. Convolutionary neural networks have won the ImageNet [44] competition since 2012, helping AlphaGo [45] to defeat Go. Recursive neural networks (RNNNs) are successfully used for sequence learning tasks [46]. Incorporating long-term memory (LSTM) [18] or gated recurrent unit (GRU) [19] enables RNNs to learn long-term time dependencies. However, both types of neural networks can only capture spatial or temporal dependencies. Recently, researchers combined networks and proposed a revolutionary LSTM network [47] that learns spatial and temporal dependencies simultaneously."}, {"heading": "6.4. Urban Computing", "text": "Urban computing [2] has become a new area of research aimed at addressing urban challenges (e.g. traffic congestion, energy consumption and pollution) by using data generated in cities (e.g. geographical data, traffic flows and human mobility).A branch of research also splits a city into grids and then examines traffic flow in each region of the city, such as predicting urban air quality [49, 50], detecting abnormal traffic patterns [51], concluding that air quality is not good [52], predicting spatio-temporal data [3]. In addition, some researchers have begun exploring deep learning methods for urban computer applications. Song et al., for example, proposed a recurrent neural network-based model to predict the future movement of people [53]. Chen et al. proposes a deep learning model to understand how human mobility will affect the risk of traffic accidents."}, {"heading": "7. Conclusion and Future Work", "text": "Our ST-ResNet is capable of learning all spatial (near and far) and temporal (proximity, period and trend) dependencies, as well as external factors (e.g. weather, event).We evaluate our model on two types of crowd flows in Beijing and NYC and achieve performance well above 9 base methods, confirming that our model is better and better applicable to crowd flows forecasting.The code and data sets have been published at: https: / / www.microsoft.com / en-us / research / publication / deepspatio-temporal-residual-networks-for-citywide-crowd-flows-prediction. We are developing a cloud-based system called UrbanFlow that monitors crowd flows in real time and will take into account the prediction of crowd flows in the near future using our Resourc.ST data flows and future data types (e.g. the use of truck data streams, net maps and their future use)."}, {"heading": "8. Acknowledgments", "text": "This work was supported by the National Natural Science Foundation of China (grant no. 61672399 and no. U1401258) and the National Basic Research Programme of China (973 Program, no. 2015CB352400) 10https: / / en.wikipedia.org / wiki / AlphaGo _ versus _ Lee _ Sedol"}], "references": [{"title": "Deep spatio-temporal residual networks for citywide crowd flows prediction", "author": ["J. Zhang", "Y. Zheng", "D. Qi"], "venue": "in: Thirty-First AAAI Conference on Artificial Intelligence", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2017}, {"title": "Urban computing: concepts", "author": ["Y. Zheng", "L. Capra", "O. Wolfson", "H. Yang"], "venue": "methodologies, and applications, ACM Transactions on Intelligent Systems and Technology (TIST) 5 (3) ", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2014}, {"title": "DNN-based prediction model for spatio-temporal data", "author": ["J. Zhang", "Y. Zheng", "D. Qi", "R. Li", "X. Yi"], "venue": "in: Proceedings of the 24th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems, GIS 2016, Burlingame, California, USA, October 31 - November 3, 2016", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2016}, {"title": "Deep learning", "author": ["Y. LeCun", "Y. Bengio", "G. Hinton"], "venue": "Nature 521 (7553) ", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2015}, {"title": "J", "author": ["K. He", "X. Zhang", "S. Ren"], "venue": "Sun, Identity mappings in deep residual networks ", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2016}, {"title": "J", "author": ["K. He", "X. Zhang", "S. Ren"], "venue": "Sun, Deep residual learning for image recognition ", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2016}, {"title": "Efficient backprop", "author": ["Y.A. LeCun", "L. Bottou", "G.B. Orr", "K.-R. M\u00fcller"], "venue": "in: Neural networks: Tricks of the trade, Springer", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Gradient-based learning applied to document recognition", "author": ["Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "Proceedings of the IEEE 86 (11) ", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1998}, {"title": "Fully convolutional networks for semantic segmentation", "author": ["J. Long", "E. Shelhamer", "T. Darrell"], "venue": "in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2015}, {"title": "Supervised learning of image restoration with convolutional networks", "author": ["V. Jain", "J.F. Murray", "F. Roth", "S. Turaga", "V. Zhigulin", "K.L. Briggman", "M.N. Helmstaedter", "W. Denk", "H.S. Seung"], "venue": "in: 2007 IEEE 11th International Conference on Computer Vision, IEEE", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2007}, {"title": "ImageNet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "in: Advances in neural information processing systems", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2012}, {"title": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "author": ["S. Ioffe", "C. Szegedy"], "venue": "in: Proceedings of the 32nd International Conference on Machine Learning, ICML 2015, Lille, France, 6-11 July 2015", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2015}, {"title": "Rectified linear units improve restricted boltzmann machines", "author": ["V. Nair", "G.E. Hinton"], "venue": "in: Proceedings of the 27th International Conference on Machine Learning (ICML-10)", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2010}, {"title": "Deep learning", "author": ["Y. Bengio", "I.J. Goodfellow", "A. Courville"], "venue": "book in preparation for mit press ", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2015}, {"title": "Long short-term memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural computation 9 (8) ", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1997}, {"title": "B", "author": ["K. Cho"], "venue": "van Merrienboer, \u00c7. G\u00fcl\u00e7ehre, D. Bahdanau, F. Bougares, H. Schwenk, Y. Bengio, Learning phrase representations using RNN encoder-decoder for statistical machine translation ", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "Keras", "author": ["F. Chollet"], "venue": "https://github.com/fchollet/keras ", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2015}, {"title": "Forecasting citywide crowd flows based on big data", "author": ["M.X. Hoang", "Y. Zheng", "A.K. Singh"], "venue": "ACM SIGSPATIAL 2016", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2016}, {"title": "Citymomentum: an online approach for crowd behavior prediction at a citywide level", "author": ["Z. Fan", "X. Song", "R. Shibasaki", "R. Adachi"], "venue": "in: Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing, ACM", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2015}, {"title": "Prediction of human emergency behavior and their mobility following large-scale disaster", "author": ["X. Song", "Q. Zhang", "Y. Sekimoto", "R. Shibasaki"], "venue": "in: Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining, ACM", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2014}, {"title": "Traffic flow prediction for road transportation networks with limited traffic data", "author": ["A. Abadi", "T. Rajabioun", "P.A. Ioannou"], "venue": "IEEE Transactions on Intelligent Transportation Systems 16 (2) ", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2015}, {"title": "Predicting traffic volumes and estimating the effects of shocks in massive transportation systems", "author": ["R. Silva", "S.M. Kang", "E.M. Airoldi"], "venue": "Proceedings of the National Academy of Sciences 112 (18) ", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2015}, {"title": "Accurate and interpretable bayesian mars for traffic flow prediction", "author": ["Y. Xu", "Q.-J. Kong", "R. Klette", "Y. Liu"], "venue": "IEEE Transactions on Intelligent Transportation Systems 15 (6) ", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2014}, {"title": "Road traffic congestion monitoring in social media with hinge-loss markov random fields", "author": ["P.-T. Chen", "F. Chen", "Z. Qian"], "venue": "in: 2014 IEEE International Conference on Data Mining, IEEE", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2014}, {"title": "Traffic prediction in a bike-sharing system", "author": ["Y. Li", "Y. Zheng", "H. Zhang", "L. Chen"], "venue": "in: Proceedings of the 23rd SIGSPATIAL International Conference on Advances in Geographic Information Systems, ACM", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2015}, {"title": "Traffic flow forecasting: comparison of modeling approaches", "author": ["B.L. Smith", "M.J. Demetsky"], "venue": "Journal of transportation engineering 123 (4) ", "citeRegEx": "30", "shortCiteRegEx": null, "year": 1997}, {"title": "Time series analysis: forecasting and control", "author": ["G.E. Box", "G.M. Jenkins", "G.C. Reinsel", "G.M. Ljung"], "venue": "John Wiley & Sons", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2015}, {"title": "Comparison of parametric and nonparametric models for traffic flow forecasting", "author": ["B.L. Smith", "B.M. Williams", "R.K. Oswald"], "venue": "Transportation Research Part C: Emerging Technologies 10 (4) ", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2002}, {"title": "Predictions of freeway traffic speeds and volumes using vector autoregressive models", "author": ["S.R. Chandra", "H. Al-Deek"], "venue": "Journal of Intelligent Transportation Systems 13 (2) ", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2009}, {"title": "Neural-network models for classification and forecasting of freeway traffic flow stability", "author": ["L. Florio", "L. Mussone"], "venue": "Control Engineering Practice 4 (2) ", "citeRegEx": "34", "shortCiteRegEx": null, "year": 1996}, {"title": "Short-term inter-urban traffic forecasts using neural networks", "author": ["M.S. Dougherty", "M.R. Cobbett"], "venue": "International journal of forecasting 13 (1) ", "citeRegEx": "35", "shortCiteRegEx": null, "year": 1997}, {"title": "Time series forecasting using a hybrid arima and neural network model", "author": ["G.P. Zhang"], "venue": "Neurocomputing 50 ", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2003}, {"title": "Neural network forecasting for seasonal and trend time series", "author": ["G.P. Zhang", "M. Qi"], "venue": "European journal of operational research 160 (2) ", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2005}, {"title": "Deep learning in neural networks: An overview", "author": ["J. Schmidhuber"], "venue": "Neural Networks 61 ", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2015}, {"title": "Faster r-cnn: Towards real-time object detection with region proposal networks", "author": ["S. Ren", "K. He", "R. Girshick", "J. Sun"], "venue": "in: Advances in neural information processing systems", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2015}, {"title": "Speech recognition with deep recurrent neural networks, in: 2013", "author": ["A. Graves", "A.-r. Mohamed", "G. Hinton"], "venue": "IEEE international conference on acoustics, speech and signal processing,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2013}, {"title": "Automatic Speech Recognition", "author": ["D. Yu", "L. Deng"], "venue": "Springer", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2012}, {"title": "T", "author": ["Q.V. Le"], "venue": "Mikolov, Distributed representations of sentences and documents., in: ICML, Vol. 14", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2014}, {"title": "ImageNet Large Scale Visual Recognition Challenge", "author": ["O. Russakovsky", "J. Deng", "H. Su", "J. Krause", "S. Satheesh", "S. Ma", "Z. Huang", "A. Karpathy", "A. Khosla", "M. Bernstein", "A.C. Berg", "L. Fei-Fei"], "venue": "International Journal of Computer Vision (IJCV) 115 (3) ", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2015}, {"title": "G", "author": ["D. Silver", "A. Huang", "C.J. Maddison", "A. Guez", "L. Sifre"], "venue": "Van Den Driessche, J. Schrittwieser, I. Antonoglou, V. Panneershelvam, M. Lanctot, et al., Mastering the game of go with deep neural networks and tree search, Nature 529 (7587) ", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2016}, {"title": "Sequence to sequence learning with neural networks", "author": ["I. Sutskever", "O. Vinyals", "Q.V. Le"], "venue": "in: Advances in neural information processing systems", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2014}, {"title": "H", "author": ["S. Xingjian", "Z. Chen"], "venue": "Wang, D.-Y. Yeung, W.-k. Wong, W.-c. WOO, Convolutional lstm network: A machine learning approach for precipitation nowcasting, in: Advances in Neural Information Processing Systems", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2015}, {"title": "Methodologies for cross-domain data fusion: An overview", "author": ["Y. Zheng"], "venue": "IEEE transactions on big data 1 (1) ", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2015}, {"title": "U-air: When urban air quality inference meets big data", "author": ["Y. Zheng", "F. Liu", "H.-P. Hsieh"], "venue": "in: Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining, ACM", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2013}, {"title": "Forecasting fine-grained air quality based on big data", "author": ["Y. Zheng", "X. Yi", "M. Li", "R. Li", "Z. Shan", "E. Chang", "T. Li"], "venue": "in: Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ACM", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2015}, {"title": "On detection of emerging anomalous traffic patterns using gps data", "author": ["L.X. Pang", "S. Chawla", "W. Liu", "Y. Zheng"], "venue": "Data & Knowledge Engineering 87 ", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2013}, {"title": "ST-MVL: filling missing values in geo-sensory time series data", "author": ["X. Yi", "Y. Zheng", "J. Zhang", "T. Li"], "venue": "in: Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence, IJCAI 2016, New York, NY, USA, 9-15 July 2016", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2016}, {"title": "DeepTransport: Prediction and simulation of human mobility and transportation mode at a citywide level", "author": ["X. Song", "H. Kanasugi", "R. Shibasaki"], "venue": "IJCAI", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2016}, {"title": "Learning deep representation from big and heterogeneous data for traffic accident inference", "author": ["Q. Chen", "X. Song", "H. Yamada", "R. Shibasaki"], "venue": "in: Thirtieth AAAI Conference on Artificial Intelligence", "citeRegEx": "54", "shortCiteRegEx": null, "year": 2016}], "referenceMentions": [{"referenceID": 1, "context": "Predicting crowd flows in a city is of great importance to traffic management, risk assessment, and public safety [2].", "startOffset": 114, "endOffset": 117}, {"referenceID": 2, "context": "In this paper, we predict two types of crowd flows [3]: inflow and outflow, as shown in Figure 1(a).", "startOffset": 51, "endOffset": 54}, {"referenceID": 0, "context": "This paper is an expanded version of [1], which has been accepted for presentation at the 31st AAAI Conference on Artificial Intelligence (AAAI-17).", "startOffset": 37, "endOffset": 40}, {"referenceID": 1, "context": "Apparently, predicting crowd flows can be viewed as a kind of spatio-temporal prediction problem [2].", "startOffset": 97, "endOffset": 100}, {"referenceID": 3, "context": "Deep learning [4] has been used successfully in many applications, and is considered to be one of the most cuttingedge artificial intelligence (AI) techniques.", "startOffset": 14, "endOffset": 17}, {"referenceID": 1, "context": "Exploring these techniques for spatio-temporal data is of great importance to a series of various spatio-temporal applications, including urban planning, transportation, the environment, energy, social, economy, public safety and security [2].", "startOffset": 239, "endOffset": 242}, {"referenceID": 0, "context": "The differences between this paper and our earlier work [1] are four aspects.", "startOffset": 56, "endOffset": 59}, {"referenceID": 2, "context": "We first briefly revisit the crowd flow prediction problem [3] and then introduce deep residual learning [5].", "startOffset": 59, "endOffset": 62}, {"referenceID": 4, "context": "We first briefly revisit the crowd flow prediction problem [3] and then introduce deep residual learning [5].", "startOffset": 105, "endOffset": 108}, {"referenceID": 2, "context": "Formulation of Crowd Flow Prediction Problem Definition 1 (Region [3]).", "startOffset": 66, "endOffset": 69}, {"referenceID": 2, "context": "Definition 2 (Inflow/outflow [3]).", "startOffset": 29, "endOffset": 32}, {"referenceID": 5, "context": "Deep Residual Learning Deep residual learning [6] allows convolution neural networks to have a super deep structure of 100 layers, even over-1000 layers.", "startOffset": 46, "endOffset": 49}, {"referenceID": 5, "context": "And this method has shown state-of-the-art results on multiple challenging recognition tasks, including image classification, object detection, segmentation and localization [6].", "startOffset": 174, "endOffset": 177}, {"referenceID": 4, "context": "Formally, a residual unit with an identity mapping [5] is defined as:", "startOffset": 51, "endOffset": 54}, {"referenceID": 5, "context": ", a stack of two 3 \u00d7 3 convolution layers in [6].", "startOffset": 45, "endOffset": 48}, {"referenceID": 4, "context": "The central idea of the residual learning is to learn the additive residual function F with respect to X(l) [5].", "startOffset": 108, "endOffset": 111}, {"referenceID": 6, "context": "Finally, the aggregation is mapped into [\u22121, 1] by a Tanh function, which yields a faster convergence than the standard logistic function in the process of back-propagation learning [8].", "startOffset": 182, "endOffset": 185}, {"referenceID": 7, "context": "Intuitively, the flow of crowds in nearby regions may affect each other, which can be effectively handled by the convolutional neural network (CNN) that has shown its powerful ability to hierarchically capture the spatial structural information [9].", "startOffset": 245, "endOffset": 248}, {"referenceID": 8, "context": "Several methods have been introduced to avoid the loss of resolution brought about by subsampling while preserving distant dependencies [11].", "startOffset": 136, "endOffset": 140}, {"referenceID": 9, "context": "Being different from the classical CNN, we do not use subsampling, but only convolutions [12].", "startOffset": 89, "endOffset": 93}, {"referenceID": 10, "context": "the rectifier f (z) := max(0, z) [13]; W (1) c , b (1) c are the learnable parameters in the first layer.", "startOffset": 33, "endOffset": 37}, {"referenceID": 11, "context": "ReLU) and regularization techniques are applied [14, 13, 15].", "startOffset": 48, "endOffset": 60}, {"referenceID": 10, "context": "ReLU) and regularization techniques are applied [14, 13, 15].", "startOffset": 48, "endOffset": 60}, {"referenceID": 12, "context": "ReLU) and regularization techniques are applied [14, 13, 15].", "startOffset": 48, "endOffset": 60}, {"referenceID": 5, "context": "To address this issue, we employ residual learning [6] in our model, which have been demonstrated to be very effective for training super deep neural networks of over-1000 layers.", "startOffset": 51, "endOffset": 54}, {"referenceID": 11, "context": "We also attempt Batch Normalization (BN) [14] that is added before ReLU.", "startOffset": 41, "endOffset": 45}, {"referenceID": 2, "context": "\u2022 DeepST [3]: a deep neural network (DNN)-based prediction model for spatio-temporal data, which shows state-of-the-art results on the crowd flow prediction.", "startOffset": 9, "endOffset": 12}, {"referenceID": 13, "context": "\u2022 RNN [17]: recurrent neural network (RNN), a deep learning model, which can capture temporal dependencies.", "startOffset": 6, "endOffset": 10}, {"referenceID": 14, "context": "\u2022 LSTM [18]: Long-short-term-memory network (LSTM), a special kind of RNN, capable of learning long-term temporal dependencies.", "startOffset": 7, "endOffset": 11}, {"referenceID": 15, "context": "\u2022 GRU [19]: Gated-recurrent-unit network, a new kind of RNN, can be used to capture long-term temporal dependencies.", "startOffset": 6, "endOffset": 10}, {"referenceID": 0, "context": ", DayOfWeek, Weekend/Weekday), holidays and weather conditions into binary vectors, and use Min-Max normalization to scale the Temperature and Wind speed into the range [0, 1].", "startOffset": 169, "endOffset": 175}, {"referenceID": 16, "context": "The learnable parameters are initialized using a uniform distribution with the default parameter in Keras [20].", "startOffset": 106, "endOffset": 110}, {"referenceID": 16, "context": "The python libraries, including Theano [21] and Keras [20], are used to build our models.", "startOffset": 54, "endOffset": 58}, {"referenceID": 17, "context": "Being different from TaxiBJ, BikeNYC consists of two different types of crowd flows, including new-flow and end-flow [22].", "startOffset": 117, "endOffset": 121}, {"referenceID": 2, "context": "We here adopt a total of 4-residual-unit ST-ResNet, and consider the metadata as external features like DeepST [3].", "startOffset": 111, "endOffset": 114}, {"referenceID": 2, "context": "The results of ARIMA, SARIMA, VAR and DeepST on BikeNYC are taken from [3].", "startOffset": 71, "endOffset": 74}, {"referenceID": 18, "context": "Crowd Flow Prediction There are some previously published works on predicting an individual\u2019s movement based on their location history [23, 24].", "startOffset": 135, "endOffset": 143}, {"referenceID": 19, "context": "Crowd Flow Prediction There are some previously published works on predicting an individual\u2019s movement based on their location history [23, 24].", "startOffset": 135, "endOffset": 143}, {"referenceID": 20, "context": "Some other researchers aim to predict travel speed and traffic volume on the road [25, 26, 27].", "startOffset": 82, "endOffset": 94}, {"referenceID": 21, "context": "Some other researchers aim to predict travel speed and traffic volume on the road [25, 26, 27].", "startOffset": 82, "endOffset": 94}, {"referenceID": 22, "context": "Some other researchers aim to predict travel speed and traffic volume on the road [25, 26, 27].", "startOffset": 82, "endOffset": 94}, {"referenceID": 22, "context": "Most of them are predicting single or multiple road segments, rather than citywide ones [27, 28].", "startOffset": 88, "endOffset": 96}, {"referenceID": 23, "context": "Most of them are predicting single or multiple road segments, rather than citywide ones [27, 28].", "startOffset": 88, "endOffset": 96}, {"referenceID": 17, "context": "Recently, researchers have started to focus on city-scale traffic flow prediction [22, 29].", "startOffset": 82, "endOffset": 90}, {"referenceID": 24, "context": "Recently, researchers have started to focus on city-scale traffic flow prediction [22, 29].", "startOffset": 82, "endOffset": 90}, {"referenceID": 25, "context": "However, the model unable to respond to dynamic changes, such as incidents [30].", "startOffset": 75, "endOffset": 79}, {"referenceID": 26, "context": "The Auto-Regressive Integrated Moving Average (ARIMA) model assumes that the future value of time series is a linear combination of previous values and residuals, furthermore, in order to obtain stationarity, the nonstationary time series should be differenced before analysis [31].", "startOffset": 277, "endOffset": 281}, {"referenceID": 27, "context": "ARIMA is not suite for time series with missing data, since they relying on uninterrupted time series, and data filling technique might be problematic as the complexity of the situation increase [32].", "startOffset": 195, "endOffset": 199}, {"referenceID": 27, "context": "The disadvantage of SARIMA is time consuming [32].", "startOffset": 45, "endOffset": 49}, {"referenceID": 28, "context": "The Vector Autoregressive (VAR) models capture the linear inter dependencies among interrelated time series [33].", "startOffset": 108, "endOffset": 112}, {"referenceID": 29, "context": "Being different from the above linear models, the artificial neural network (ANN) model is a nonlinear model and commonly used in time series prediction [34, 35, 36].", "startOffset": 153, "endOffset": 165}, {"referenceID": 30, "context": "Being different from the above linear models, the artificial neural network (ANN) model is a nonlinear model and commonly used in time series prediction [34, 35, 36].", "startOffset": 153, "endOffset": 165}, {"referenceID": 31, "context": "Being different from the above linear models, the artificial neural network (ANN) model is a nonlinear model and commonly used in time series prediction [34, 35, 36].", "startOffset": 153, "endOffset": 165}, {"referenceID": 32, "context": "ANNs have excellent nonlinear modeling ability, but not enough for linear modeling ability [37].", "startOffset": 91, "endOffset": 95}, {"referenceID": 3, "context": "Deep Neural Networks Neural networks and deep learning [4, 38, 39] have gained numerous success in the fields such as compute vision [13, 40], speech recognition [41, 42], and natural language processing [43].", "startOffset": 55, "endOffset": 66}, {"referenceID": 33, "context": "Deep Neural Networks Neural networks and deep learning [4, 38, 39] have gained numerous success in the fields such as compute vision [13, 40], speech recognition [41, 42], and natural language processing [43].", "startOffset": 55, "endOffset": 66}, {"referenceID": 10, "context": "Deep Neural Networks Neural networks and deep learning [4, 38, 39] have gained numerous success in the fields such as compute vision [13, 40], speech recognition [41, 42], and natural language processing [43].", "startOffset": 133, "endOffset": 141}, {"referenceID": 34, "context": "Deep Neural Networks Neural networks and deep learning [4, 38, 39] have gained numerous success in the fields such as compute vision [13, 40], speech recognition [41, 42], and natural language processing [43].", "startOffset": 133, "endOffset": 141}, {"referenceID": 35, "context": "Deep Neural Networks Neural networks and deep learning [4, 38, 39] have gained numerous success in the fields such as compute vision [13, 40], speech recognition [41, 42], and natural language processing [43].", "startOffset": 162, "endOffset": 170}, {"referenceID": 36, "context": "Deep Neural Networks Neural networks and deep learning [4, 38, 39] have gained numerous success in the fields such as compute vision [13, 40], speech recognition [41, 42], and natural language processing [43].", "startOffset": 162, "endOffset": 170}, {"referenceID": 37, "context": "Deep Neural Networks Neural networks and deep learning [4, 38, 39] have gained numerous success in the fields such as compute vision [13, 40], speech recognition [41, 42], and natural language processing [43].", "startOffset": 204, "endOffset": 208}, {"referenceID": 38, "context": "For example, convolutional neural networks won the ImageNet [44] competition since 2012, and help AlphaGo [45] beat Go human champion10.", "startOffset": 60, "endOffset": 64}, {"referenceID": 39, "context": "For example, convolutional neural networks won the ImageNet [44] competition since 2012, and help AlphaGo [45] beat Go human champion10.", "startOffset": 106, "endOffset": 110}, {"referenceID": 40, "context": "Recurrent neural networks (RNNs) have been used successfully for sequence learning tasks [46].", "startOffset": 89, "endOffset": 93}, {"referenceID": 14, "context": "The incorporation of long short-term memory (LSTM) [18] or gated recurrent unit (GRU) [19] enables RNNs to learn long-term temporal dependency.", "startOffset": 51, "endOffset": 55}, {"referenceID": 15, "context": "The incorporation of long short-term memory (LSTM) [18] or gated recurrent unit (GRU) [19] enables RNNs to learn long-term temporal dependency.", "startOffset": 86, "endOffset": 90}, {"referenceID": 41, "context": "Recently, researchers combined above networks and proposed a convolutional LSTM network [47] that learns spatial and temporal dependencies simultaneously.", "startOffset": 88, "endOffset": 92}, {"referenceID": 2, "context": "In our previous work [3], a general prediction model based on DNNs was proposed for spatio-temporal data.", "startOffset": 21, "endOffset": 24}, {"referenceID": 42, "context": "A survey on data fusion methodologies can be found at [48].", "startOffset": 54, "endOffset": 58}, {"referenceID": 1, "context": "Urban Computing Urban computing [2], has emerged as a new research area, which aims to tackle urban challenges (e.", "startOffset": 32, "endOffset": 35}, {"referenceID": 43, "context": "A branch of research also partitions a city into grids, and then studies the traffic flow in each region of the city, such as predicting urban air quality [49, 50], detecting anomalous traffic patterns [51], inferring missing air quality [52], forecasting of spatio-temporal data [3].", "startOffset": 155, "endOffset": 163}, {"referenceID": 44, "context": "A branch of research also partitions a city into grids, and then studies the traffic flow in each region of the city, such as predicting urban air quality [49, 50], detecting anomalous traffic patterns [51], inferring missing air quality [52], forecasting of spatio-temporal data [3].", "startOffset": 155, "endOffset": 163}, {"referenceID": 45, "context": "A branch of research also partitions a city into grids, and then studies the traffic flow in each region of the city, such as predicting urban air quality [49, 50], detecting anomalous traffic patterns [51], inferring missing air quality [52], forecasting of spatio-temporal data [3].", "startOffset": 202, "endOffset": 206}, {"referenceID": 46, "context": "A branch of research also partitions a city into grids, and then studies the traffic flow in each region of the city, such as predicting urban air quality [49, 50], detecting anomalous traffic patterns [51], inferring missing air quality [52], forecasting of spatio-temporal data [3].", "startOffset": 238, "endOffset": 242}, {"referenceID": 2, "context": "A branch of research also partitions a city into grids, and then studies the traffic flow in each region of the city, such as predicting urban air quality [49, 50], detecting anomalous traffic patterns [51], inferring missing air quality [52], forecasting of spatio-temporal data [3].", "startOffset": 280, "endOffset": 283}, {"referenceID": 47, "context": "proposed a recurrentneural-network-based model to predict the person\u2019s future movement [53].", "startOffset": 87, "endOffset": 91}, {"referenceID": 48, "context": "proposes a deep learning model to understand how human mobility will affect traffic accident risk [54].", "startOffset": 98, "endOffset": 102}], "year": 2017, "abstractText": "Forecasting the flow of crowds is of great importance to traffic management and public safety, and very challenging as it is affected by many complex factors, including spatial dependencies (nearby and distant), temporal dependencies (closeness, period, trend), and external conditions (e.g. weather and events). We propose a deep-learning-based approach, called ST-ResNet, to collectively forecast two types of crowd flows (i.e. inflow and outflow) in each and every region of a city. We design an end-to-end structure of ST-ResNet based on unique properties of spatio-temporal data. More specifically, we employ the residual neural network framework to model the temporal closeness, period, and trend properties of crowd traffic. For each property, we design a branch of residual convolutional units, each of which models the spatial properties of crowd traffic. ST-ResNet learns to dynamically aggregate the output of the three residual neural networks based on data, assigning different weights to different branches and regions. The aggregation is further combined with external factors, such as weather and day of the week, to predict the final traffic of crowds in each and every region. We have developed a real-time system based on Microsoft Azure Cloud, called UrbanFlow, providing the crowd flow monitoring and forecasting in Guiyang City of China. In addition, we present an extensive experimental evaluation using two types of crowd flows in Beijing and New York City (NYC), where ST-ResNet outperforms nine well-known baselines.", "creator": "LaTeX with hyperref package"}}}