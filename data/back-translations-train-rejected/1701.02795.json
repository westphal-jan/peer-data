{"id": "1701.02795", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Jan-2017", "title": "Bidirectional American Sign Language to English Translation", "abstract": "We outline a bidirectional translation system that converts sentences from American Sign Language (ASL) to English, and vice versa. To perform machine translation between ASL and English, we utilize a generative approach. Specifically, we employ an adjustment to the IBM word-alignment model 1 (IBM WAM1), where we define language models for English and ASL, as well as a translation model, and attempt to generate a translation that maximizes the posterior distribution defined by these models. Then, using these models, we are able to quantify the concepts of fluency and faithfulness of a translation between languages.", "histories": [["v1", "Tue, 10 Jan 2017 21:45:56 GMT  (238kb,D)", "http://arxiv.org/abs/1701.02795v1", "7 pages"]], "COMMENTS": "7 pages", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["hardie cate", "zeshan hussain"], "accepted": false, "id": "1701.02795"}, "pdf": {"name": "1701.02795.pdf", "metadata": {"source": "CRF", "title": "Bidirectional American Sign Language to English Translator", "authors": ["Hardie Cate", "Zeshan Hussain"], "emails": ["ccate@stanford.edu", "zeshanmh@stanford.edu"], "sections": [{"heading": null, "text": "Bidirectional American Sign Language to English TranslatorHardie Cate ccate @ stanford.eduZeshan Hussain zeshanmh @ stanford.edu11 December 2015"}, {"heading": "1 Introduction", "text": "In the United States alone, there are approximately 900,000 hearing impaired people whose primary mode of conversation is sign language. For these people, communication with non-signatories is a daily struggle, and they are often at a disadvantage when it comes to finding a job, access to healthcare, etc. There are a few new technologies designed to translate sign language into English in real time, but most current research attempts attempt to convert raw characters into English words. This aspect of translation is certainly necessary, but it does not take into account the grammatical differences between signed languages and spoken languages. In this essay, we outline our bi-directional translation system that converts sentences from American sign language (ASL) into English and vice versa. To perform machine translation between ASL and English, we use a generative approach. Specifically, we use an adaptation to IBM Word Alignment Model 1 (IBM WAM1) [14], in which we define language models for ASL and English, as well as an attempt to create a translation model between ASL and an ASL and an attempt to translate."}, {"heading": "2 Related Work", "text": "The few new technologies trying to tackle this problem are only able to translate single words or short sentences of ASL into English. In fact, most approaches focus on analyzing videos of characters and converting them into words, which a number of recent CS229 projects have done. However, several teams from the University of Pennsylvania have taken a more grammatical approach [15] to the problem of translating from English to ASL, but not in the other direction. There was also an Italian team that designed a provisional translation system for the Italian sign language, [7] but there are very few parallels in terms of grammatical structures that we can draw for this project. In short, there was relatively little em-phasis in the literature on the conversion between grammars of the languages we are examining in this project."}, {"heading": "3 Task Definition", "text": "Let us formalize the notation for this task. For the sake of simplicity, we will use ASL as our \"source language\" and English as our \"target language.\" Generally, S will refer to the sentence in ASL, where S is a sequence of characters S1..., Sm and m is the length of the sentence. Each character is represented by a word with capital letters. We will also include special \"gesture tokens,\" which represent gestures or hand movements that are not characters in and of themselves, but modify other characters in the sentence. As a special case that we will address later, commas are treated as single characters tokens. Likewise, we will refer to the English sentence, where E is a sequence of words.., El and l is the length of the punishment."}, {"heading": "4 Data", "text": "Our data consists of 579 ASL / English translation pairs taken from a repository at lifeprint.com [12], a website dedicated to ASL education. Each pair is a single precise translation of an ASL sentence or question into English. Many of the ASL sentences contain gesture tokens. These pairs are not specifically designed for translation from English to ASL, and in general, the translation between languages is not symmetrical. However, simplistically, we assume that this translation is primarily symmetrical because we do not have a thorough understanding of ASL to translate from English to ASL. To test our algorithms, we divide the data into two main groups - a training set (80% of the original data) and a test set (remaining 20%). We also have a third sentence, the so-called development set, which we use to adjust our hyperparameters. This sentence is constructed by taking 10 examples from the training set and treating it as our development set."}, {"heading": "5 Technical Approach", "text": "In the following we describe the baselines, oracles and the IBM method of word alignment for this problem."}, {"heading": "5.1 Baseline and Oracle", "text": "Due to the bidirectional nature of the problem, we have two basic lines: For a basic line in English-ASL direction, we use a universal cost function over English to recognize the \"most important\" words in the sentence and translate each word directly into ASL, maintaining the order of those words. To select the most important words, our base line selects the words with the highest cost above a certain threshold based on our universal cost function. In this case, a higher price implies a lower frequency in the English language, indicating a higher importance. For our basic line in the other direction, we translate each character directly into English and insert small auxiliary words (such as \"a,\" the, \"\" and \"etc.), treating this as a search problem that seeks to minimize the cost of the English sentence by using a bigram cost function. To test these basics, we have used the same BLEU values as for the results generated by our IBM word alignment system."}, {"heading": "5.2 Custom WAM", "text": "IBM WAM1 is a common machine translation model that we adapt to take advantage of common constructions in ASL and modify the construction of the translation model and language models. The custom model is designed to give us flexibility in our translations. We now describe the general workflow of our model in the ASL in the English direction. This workflow also applies in the other direction, unless E is switched with S: 1. For each potential translation, we calculate p (E) 2).Then, in this channel input, we calculate p (S | E) in the \"loud channel\" 3).Finally, we select the E that gives the highest probability in the face of these two probabilities (probabilities and before).The p (E) is represented by the language model, while the p (S | E) is represented by the translation model. We derive this formulation below."}, {"heading": "5.2.1 Modeling", "text": "s look at the following gold standard translations of ASL into English: Sinput: YOU LIKE LERN SIGN? Eoutput: Do you like to learn sign language? To derive the models we use in the translation, we look at the following optimization problem (note that we write this derivative back in the ASL direction into English, but the same derivative applies to the other direction): If we use a sentence S in the ASL, we want to find an English sentence that reads: E = arg max E'EnglishP (E | S) E = arg max E'EnglishP (S | E) P (E) The probability P (E) represents the fluidity of E in English, i.e., how much the translation yields for a native speaker, while P (S | E) represents the fidelity of the translation from S into English, i.e., the ASL reflects the actual meaning of the translation."}, {"heading": "5.2.2 Language Model", "text": "To calculate P (E) for a given English sentence E, we use an n-gram cost function. For example, in our example sentence E above, we treat n = 3, p (E) = p3 (zero, zero, \"do\") \u00b7 p3 (zero, \"do,\" \"you\") \u00b7 p3 (\"learning,\" \"sign,\" \"language?\"), where p3 is a 3-gram cost function. We have n-gram cost functions from http: / / www.ngrams.info / [8] for n = 2, 3, 4, 5. However, there are a few caveats with the above approach when we try to create a language model for ASL that is necessary for translation in the other direction (i.e. for calculating P (S)). The first is that our ASL language model is basically an unigrammatic model that has additional components. In addition to any character that has an associated probability that is a comma, we add a comma comma."}, {"heading": "5.2.3 Translation Model", "text": "We present this model as a mapping of \"character-English\" pairs on probabilities (of these pairs) using a dictionary in Python. Formation of this model requires the introduction of a sentence A = a1,.., aJ of alignment variables where aj represents the index of the word in the English sentence that translates to the jth word sj into S. We also allow these variables to assume a value of 0 that represents a \"zero\" word in the English sentence. This zero word allows the possibility that there is no word in the English sentence that directly translates to a character sj into S. In the case of our example above, if A specifies that \"learning\" in E can be translated to \"LEARN\" in S, then a3 = 4, since \"LEARN\" is the third word in S and \"learning\" alizing \"in the fourth position of E. Thus, A can be assumed as a multiple mapping of common characters in E."}, {"heading": "5.2.4 Algorithms", "text": "The two primary algorithms used in our implementation are an EM algorithm to train our translation model, in which we do not estimate the data (S | E) and our deciphering algorithms. The deciphering algorithms are a modified version of the deciphering in IBM WAM1, which is a variant of the beam search findarg max EP (S | E) P (E).First, we describe the deciphering algorithms, which are each a mapping t of pairs (s, e), where s is a character and e is an English word, to the probabilities t (s, e) = p (s) = p (s).Given our training data, which contain a list of m translation pairs (S, E), we can rewrite our estimate of a single transition perspective asp (s) = m (s)."}, {"heading": "5.2.5 Algorithms Commentary", "text": "One of the most important aspects of the algorithm is that a hypothesis h can generate a new hypothesis h, which is put in the same queue as h when it is generated by the translation of a character already translated into h. This is important because it allows us to translate a single character into several English words. In particular, this allows the translated English sentence to be longer than the sentence with the input characters, which is the case with most English translations. Another important note concerns the weight of the language model. If this weight is set to 1, the priority is simply p (E | S), i.e. the value we are trying to maximize. However, if we try to maximize this value, the probabilities of the language model \"outweigh\" the probabilities of the translation model. In fact, the character set is probably translated as a series of ordinary English n-grams that have nothing to do with the original sentence."}, {"heading": "6 Results", "text": "As mentioned in the Data section, we divide the data set into three separate sets: a training set, a development set, and a test set. For both directions, we train our models on a training set, match the hyperparameters (i.e. the weight of the language model, the size of the k queue, and the type of n-gram model we use for the language model [Unigram, BigChart, Trigram]) on a development set, and finally find the average BLEU-2 score on a test set. In addition, our measure of translation accuracy on the test set or development set is the average of the individual BLEU-2 scores of the translations. Each BLEU-2 score shown in tables or numbers is the mean BLEU-2 score."}, {"heading": "6.1 Hyperparameter Tuning Results", "text": "In order to find the optimal hyperparameter combinations, we conducted several experiments. The initial set of experiments was performed to find the optimal hyperparameter for translating ASL into English. First, we found the BLEU-2 score for development by keeping the queue size constant and adjusting the weight of the language model using the English model Bigram. Next, we performed the same experiment except for the English trigram. The results of these experiments are reported in Tables 2 and 3. We find that the optimal weight of the language model is 0.1, the optimal queue size for ASL translation is 20, and the optimal language model type is a trigram model model. Using this combination gives us a BLEU-2 score of 0.276 (see Table 3), which is the highest BLEU-2 score we obtain while tuning hyperparameters. To give us some intuition on the choice of the optimal parameters for the experiments, we argue that"}, {"heading": "6.2 Experiments for ASL Constructions", "text": "The last two experiments test how our system performs when translating certain ASL constructions. First, we conduct an experiment in which we only translate the common comma construction described in the modeling above by filtering for these test examples in the test set and using the optimal ASL hyperparameters when using the filtered test set. BLEU-2 result for this test is 0.1201 (see Table 1). Finally, the last experiment tests how our system translates strings with gesture tokens. We create a test set for this experiment in a similar way to that for comma constructions by filtering the original test set to include only strings with gesture tokens. The BLEU-2 score for this test is 0.1232 (see Table 1)."}, {"heading": "7 Analysis", "text": "As a health check for our results, it is important to note that our translation system outperforms the basic implementations in both directions. We also observe a performance difference between the two translation directions. The ASL direction into English produces an average BLEU-2 score of 0.12, while the English ASL yields a higher score of 0.18. The behavior is in line with our expectations that flow into the project, as we essentially filter out unnecessary information, while the other direction requires the generation of information in the effect. After running our tuning experiments on the hyperparameters, we noticed a few interesting trends. First, instances where we use a trigram model for English tend to produce higher BLEU-2 results than with corresponding English Bigram models, especially when the maximum size of the queue in decoding algorithms is large, the trigram model naturally results in more information than the Bigram model."}, {"heading": "8 Conclusion & Future Work", "text": "Although we want our translations to be as accurate as possible, it is important to note that it is virtually impossible for even an oracle to find a perfect translation. Words and sentences have a contextual meaning in each language that may not be accurately expressed in another language. The problem of translating between sign languages and natural languages is extremely difficult, and we are probably the first to tackle it this way. Although we have faced numerous challenges, we have shown that this approach is a reasonably effective improvement to our basic algorithms. With a more thorough understanding of ASL and its grammatical structure, and a larger corpus of training, our approach has the potential to be an effective translation system between ASL and English."}, {"heading": "9 References", "text": "[1] American Sign Language Dictionary. http: / / www. signasl.org g. Accessed: 2015-12-11. [2] American Sign Language Grammar. http: / / www. lifeprint.com / asl101 / pages-layout / grammar.htm. Accessed: 2015-12-11. [3] Steven Bird, Ewan Klein, and Edward Loper. Natural language processing with Python. \"O'Reilly Media, Inc. [4] Introduction to Statistical MT. https: / / sparkpublic.s3.amazonaws.com / cs124 / slides / mt2.pdf. Accessed: 2015-12-translation, Inc."}], "references": [{"title": "Natural language processing with Python. ", "author": ["Steven Bird", "Ewan Klein", "Edward Loper"], "venue": "O\u2019Reilly Media,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2009}, {"title": "Generalized stack decoding algorithms for statistical machine translation", "author": ["Daniel Ortiz Mart\u0301\u0131nez", "Ismael Gar\u0107\u0131a Varea", "Francisco Casacuberta Nolla"], "venue": "Proceedings of the Workshop on Statistical Machine Translation. Association for Computational Linguistics", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2006}, {"title": "Deep Natural Language Processing for Italian Sign Language Translation", "author": ["Alessandro Mazzei"], "venue": "AI* IA 2013: Advances in Artificial Intelligence. Springer,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2013}, {"title": "BLEU: a method for automatic evaluation of machine translation", "author": ["Kishore Papineni"], "venue": "Proceedings of the 40th annual meeting on association for computational linguistics. Association for Computational Linguistics", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2002}, {"title": "Sign language recognition and translation: A multidisciplined approach from the field of artificial intelligence", "author": ["Becky Sue Parton"], "venue": "Journal of deaf studies and deaf education", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2006}, {"title": "A machine translation system from English to American Sign Language", "author": ["Liwei Zhao"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2000}], "referenceMentions": [{"referenceID": 5, "context": "However, several teams at the University of Pennsylvania have taken a more grammatical approach [15] to the problem of English-to-ASL translation but not in the other direction.", "startOffset": 96, "endOffset": 100}, {"referenceID": 2, "context": "There has also been an Italian team that has designed a tentative translation system for Italian sign language,[7] but there are very few parallels with respect to grammatical structures that we can draw for this project.", "startOffset": 111, "endOffset": 114}, {"referenceID": 3, "context": "To evaluate translations generated by our system as well as the baselines in both directions, we use the BLEU2 score,[10] which takes in a predicted sentence and a reference sentence, both in the target language.", "startOffset": 117, "endOffset": 121}], "year": 2017, "abstractText": "In the US alone, there are approximately 900,000 hearingimpaired people whose primary mode of conversation is sign language. For these people, communication with non-signers is a daily struggle, and they are often disadvantaged when it comes to finding a job, accessing health care, etc. There are a few emerging technologies designed to translate sign language to English in real time, but most of the current research attempts to convert raw signs into English words. This aspect of the translation is certainly necessary, but it does not take into account the grammatical differences between signed languages and spoken languages. In this paper, we outline our bidirectional translation system that converts sentences from American Sign Language (ASL) to English, and vice versa. To perform machine translation between ASL and English, we utilize a generative approach. Specifically, we employ an adjustment to the IBM word-alignment model 1 (IBM WAM1)[14] where we define language models for English and ASL, as well as a translation model, and attempt to generate a translation that maximizes the posterior distribution defined by these models. Using these models, we are able to quantify the concepts of fluency and faithfulness of a translation between languages.", "creator": "LaTeX with hyperref package"}}}