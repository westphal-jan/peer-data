{"id": "1701.02901", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Jan-2017", "title": "A Multifaceted Evaluation of Neural versus Phrase-Based Machine Translation for 9 Language Directions", "abstract": "We aim to shed light on the strengths and weaknesses of the newly introduced neural machine translation paradigm. To that end, we conduct a multifaceted evaluation in which we compare outputs produced by state-of-the-art neural machine translation and phrase-based machine translation systems for 9 language directions across a number of dimensions. Specifically, we measure the similarity of the outputs, their fluency and amount of reordering, the effect of sentence length and performance across different error categories. We find out that translations produced by neural machine translation systems are considerably different, more fluent and more accurate in terms of word order compared to those produced by phrase-based systems. Neural machine translation systems are also more accurate at producing inflected forms, but they perform poorly when translating very long sentences.", "histories": [["v1", "Wed, 11 Jan 2017 09:32:47 GMT  (55kb,D)", "http://arxiv.org/abs/1701.02901v1", "Conference of the European Chapter of the Association for Computational Linguistics (EACL). April 2017, Val\\`encia, Spain"]], "COMMENTS": "Conference of the European Chapter of the Association for Computational Linguistics (EACL). April 2017, Val\\`encia, Spain", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["antonio toral", "v\\'ictor m s\\'anchez-cartagena"], "accepted": false, "id": "1701.02901"}, "pdf": {"name": "1701.02901.pdf", "metadata": {"source": "CRF", "title": "A Multifaceted Evaluation of Neural versus Phrase-Based Machine Translation for 9 Language Directions", "authors": ["Antonio Toral", "V\u0131\u0301ctor M. S\u00e1nchez-Cartagena"], "emails": ["a.toral.ruiz@rug.nl", "vmsanchez@prompsit.com"], "sections": [{"heading": "1 Introduction", "text": "In fact, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new, a new"}, {"heading": "2 Experimental Setup", "text": "The experiments are carried out on the best2 PBMT3 and NMT-restricted systems subjected to the message translation task of WMT16. Of the 12 language directions in the translation task, we run experiments on 9.4 These are the language pairs between English (EN) and Czech (CS), German (DE), Finnish (FI), Romanian (RO) and Russian (RU) in both directions (with the exception of Finnish, where only the direction EN \u2192 FI is covered, since no NMT system has been submitted for the opposite direction, FI \u2192 EN). Finally, there was an additional language in the common task, Turkish, which is not taken into account here, either because none of the submitted systems was neural (Turkish \u2192 EN), or because such a system existed, but its performance was extremely low (EN \u2192 Turkish) and therefore most likely not representative of the state of art in NMT.Table 1 shows the most important features of the 2 after human evaluation."}, {"heading": "2.1 Overall Evaluation", "text": "First, and to contextualize our analysis below, we report on the BLEU scores achieved by the best NMT and PBMT systems for each language direction in the message translation task of WMT16 in Table 2.5. The best NMT system performs significantly better in all language directions than English (relative improvements range from 5.5% for EN \u2192 RO to 17.6% for EN \u2192 FI) and the human rating (Bojar et al., 2016, Sec. 3.4) confirms these results. Conversely, the human rating shows that the best NMT system outperforms the best PBMT system for all language directions, except when the source language is Russian. This differs slightly from the automatic rating according to which NMT exceeds the PBMT scores for translations from Czech (3.3% relative improvement) and German (9.9%) for translations from Romanian (-3.7%) and Russian (-3.8%)."}, {"heading": "3 Output Similarity", "text": "The aim of this analysis is to assess to what extent translations produced by NMT systems differ from those produced by PBMT systems. We measure this by taking the results of the top n6 NMT and PBMT systems submitted to each linguistics7 and taking into account their paired overlaps with respect to the chrF1 (Popovic, 2015) automatic evaluation metrics. 8We would look at NMT outputs considerably differently (in relation to PBMT) if they are similar (i.e. high pair overlaps between NMT outputs) more than they do PBMT systems (i.e. low overlaps between one output of NMT and another of PBMT). This analysis is carried out only for language directions from English because for all language directions transmitted to English, there was at most one NMT system, 1 NMT differentiation between PT systems."}, {"heading": "4 Fluency", "text": "In this experiment, we want to find out whether the results produced by NMT systems are more or less fluid than those produced by PBMT systems. To this end, we take the perplexity of MT outputs to Neural Language Models (LMs) as a proxy for fluidity. LMs are built using TheanoLM (Enarvi and Kurimo, 2016), containing 100 units in the projection layer, 300 units in the LSTM layer and 300 units in the Tanh layer, following the setup described by Enarvi and Kurimo (2016, Sec. 3.2). The training algorithm is Adagrad (Duchi et al., 2011) and we used 1000 word classes translated with mkcls from the training corpus. Vocabulary systems are limited to the most common 50,000 tokens.LMs trained on the flow speed of MMs."}, {"heading": "5 Reordering", "text": "This year it is so far that it will only be a matter of time before we will be able again, until we will be able to find a solution that we are able to find a solution, \"he said."}, {"heading": "6 Sentence Length", "text": "In this experiment, we want to find out whether the performance of NMT and PBMT is somehow sensitive to sentence length. In this context, Bentivogli et al. (2016) found that, regardless of sentence length, the performance of NMT decreases faster for transcribed speeches than that of PBMT with increasing sentence length. However, it should be noted that sentences in our content type, the messages, are significantly longer than sentences in transcribed speeches. [11] Therefore, the current experiment will determine to what extent the results in transcribed speeches also stand for texts that consist of longer sentences. We will divide the source side of the test sentence into subsets of varying lengths: 1 to 5 words (1-5), 6 to 10 and so on up to 46 to 50 and finally longer than 50 words (> 50). We will then evaluate the results of the top PBMT and NMT subsets in different lengths."}, {"heading": "7 Error Categories", "text": "In this experiment, we evaluate the performance of NMT compared to PBMT systems based on a series of error categories, each corresponding to five literal error classes: inflection errors, reordering errors, missing words, additional words, and incorrect lexical decisions. These errors are then defined as: \u2022 Word error rate (WHO), precision-based and retrieval-based error rates (hPER and rPER), the full form of which is marked as hPER error, while the basic form corresponds to the basic form of the language (Popovic, 2011). These error classes are then defined as: \u2022 Diffraction error (hINFer), a word for which its full form is marked as hPER error, while its basic form corresponds to the basic form of the language (hRer), a word that corresponds to the reference but is marked as WER error."}, {"heading": "8 Conclusions", "text": "We have carried out a multi-faceted evaluation to reduce the number of job-related redundancies."}, {"heading": "Acknowledgments", "text": "The research leading to these results is supported by the Seventh Framework Programme of the European Union FP7 / 2007-2013 under the grant agreement PIAP-GA-2012-324414 (Abu-MaTran) and by the Science Foundation Ireland under the CNGL Programme (Grant 12 / CE / I2267) at the ADAPT Centre (www.adaptcentre.ie) at Dublin City University."}], "references": [{"title": "Neural Machine Translation by Jointly Learning to Align and Translate", "author": ["Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio."], "venue": "arXiv preprint arXiv:1409.0473.", "citeRegEx": "Bahdanau et al\\.,? 2015", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2015}, {"title": "Neural versus phrasebased machine translation quality: a case study", "author": ["Luisa Bentivogli", "Arianna Bisazza", "Mauro Cettolo", "Marcello Federico."], "venue": "arXiv preprint arXiv:1608.04631.", "citeRegEx": "Bentivogli et al\\.,? 2016", "shortCiteRegEx": "Bentivogli et al\\.", "year": 2016}, {"title": "Reordering metrics for statistical machine translation", "author": ["Alexandra Birch."], "venue": "Ph.D. thesis, The University of Edinburgh.", "citeRegEx": "Birch.,? 2011", "shortCiteRegEx": "Birch.", "year": 2011}, {"title": "Findings of the 2016 conference on machine translation", "author": ["Post", "Raphael Rubino", "Carolina Scarton", "Lucia Specia", "Marco Turchi", "Karin Verspoor", "Marcos Zampieri."], "venue": "Proceedings of the First Conference on Machine Translation, pages 131\u2013", "citeRegEx": "Post et al\\.,? 2016", "shortCiteRegEx": "Post et al\\.", "year": 2016}, {"title": "Empirical evaluation of gated recurrent neural networks on sequence modeling", "author": ["Junyoung Chung", "\u00c7aglar G\u00fcl\u00e7ehre", "KyungHyun Cho", "Yoshua Bengio."], "venue": "arXiv preprint arXiv:1412.3555.", "citeRegEx": "Chung et al\\.,? 2014", "shortCiteRegEx": "Chung et al\\.", "year": 2014}, {"title": "A character-level decoder without explicit segmentation for neural machine translation", "author": ["Junyoung Chung", "Kyunghyun Cho", "Yoshua Bengio."], "venue": "arXiv preprint arXiv:1603.06147.", "citeRegEx": "Chung et al\\.,? 2016", "shortCiteRegEx": "Chung et al\\.", "year": 2016}, {"title": "Character-based neural machine translation", "author": ["Marta R. Costa-Juss\u00e0", "Jos\u00e9 A.R. Fonollosa."], "venue": "arXiv preprint arXiv:1603.00810.", "citeRegEx": "Costa.Juss\u00e0 and Fonollosa.,? 2016", "shortCiteRegEx": "Costa.Juss\u00e0 and Fonollosa.", "year": 2016}, {"title": "Fast and robust neural network joint models for statistical machine translation", "author": ["Jacob Devlin", "Rabih Zbib", "Zhongqiang Huang", "Thomas Lamar", "Richard Schwartz", "John Makhoul."], "venue": "Proceedings of the 52nd Annual Meeting of the Association for Compu-", "citeRegEx": "Devlin et al\\.,? 2014", "shortCiteRegEx": "Devlin et al\\.", "year": 2014}, {"title": "The JHU Machine Translation Systems for WMT 2016", "author": ["Shuoyang Ding", "Kevin Duh", "Huda Khayrallah", "Philipp Koehn", "Matt Post."], "venue": "Proceedings of the First Conference on Machine Translation, pages 272\u2013280, Berlin, Germany, August.", "citeRegEx": "Ding et al\\.,? 2016", "shortCiteRegEx": "Ding et al\\.", "year": 2016}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["John Duchi", "Elad Hazan", "Yoram Singer."], "venue": "Journal of Machine Learning Research, 12(Jul):2121\u20132159.", "citeRegEx": "Duchi et al\\.,? 2011", "shortCiteRegEx": "Duchi et al\\.", "year": 2011}, {"title": "A Joint Sequence Translation Model with Integrated Reordering", "author": ["Nadir Durrani", "Helmut Schmid", "Alexander Fraser."], "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages", "citeRegEx": "Durrani et al\\.,? 2011", "shortCiteRegEx": "Durrani et al\\.", "year": 2011}, {"title": "TheanoLM \u2013 An Extensible Toolkit for Neural Network Language Modeling", "author": ["Seppo Enarvi", "Mikko Kurimo."], "venue": "Proceedings of the 17th Annual Conference of the International Speech Communication Association.", "citeRegEx": "Enarvi and Kurimo.,? 2016", "shortCiteRegEx": "Enarvi and Kurimo.", "year": 2016}, {"title": "Appraise: An opensource toolkit for manual evaluation of machine translation output", "author": ["Christian Federmann."], "venue": "The Prague Bulletin of Mathematical Linguistics, 98:25\u201335, September.", "citeRegEx": "Federmann.,? 2012", "shortCiteRegEx": "Federmann.", "year": 2012}, {"title": "Parallel implementations of word alignment tool", "author": ["Qin Gao", "Stephan Vogel."], "venue": "Software Engineering, Testing, and Quality Assurance for Natural", "citeRegEx": "Gao and Vogel.,? 2008", "shortCiteRegEx": "Gao and Vogel.", "year": 2008}, {"title": "Can machine translation systems be evaluated by the crowd alone", "author": ["Yvette Graham", "Timothy Baldwin", "Alistair Moffat", "Justin Zobel."], "venue": "Natural Language Engineering, FirstView:1\u201328, 1.", "citeRegEx": "Graham et al\\.,? 2016", "shortCiteRegEx": "Graham et al\\.", "year": 2016}, {"title": "Long short-term memory", "author": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber."], "venue": "Neural computation, 9(8):1735\u20131780.", "citeRegEx": "Hochreiter and Schmidhuber.,? 1997", "shortCiteRegEx": "Hochreiter and Schmidhuber.", "year": 1997}, {"title": "The AMU-UEDIN Submission to the WMT16 News Translation Task: Attentionbased NMT Models as Feature Functions in Phrasebased SMT", "author": ["Marcin Junczys-Dowmunt", "Tomasz Dwojak", "Rico Sennrich."], "venue": "Proceedings of the First Conference", "citeRegEx": "Junczys.Dowmunt et al\\.,? 2016", "shortCiteRegEx": "Junczys.Dowmunt et al\\.", "year": 2016}, {"title": "Character-aware neural language models", "author": ["Yoon Kim", "Yacine Jernite", "David Sontag", "Alexander Rush."], "venue": "Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, pages 2741\u20132749, Phoenix, Arizona, USA, February.", "citeRegEx": "Kim et al\\.,? 2016", "shortCiteRegEx": "Kim et al\\.", "year": 2016}, {"title": "Statistical significance tests for machine translation evaluation", "author": ["Philipp Koehn."], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing, volume 4, pages 388\u2013395, Barcelona, Spain.", "citeRegEx": "Koehn.,? 2004", "shortCiteRegEx": "Koehn.", "year": 2004}, {"title": "Statistical Machine Translation", "author": ["Philipp Koehn."], "venue": "Cambridge University Press, New York, NY, USA, 1st edition.", "citeRegEx": "Koehn.,? 2010", "shortCiteRegEx": "Koehn.", "year": 2010}, {"title": "NRC Russian-English Machine Translation System for WMT 2016", "author": ["Chi-kiu Lo", "Colin Cherry", "George Foster", "Darlene Stewart", "Rabib Islam", "Anna Kazantseva", "Roland Kuhn."], "venue": "Proceedings of the First Conference on Machine Translation, pages", "citeRegEx": "Lo et al\\.,? 2016", "shortCiteRegEx": "Lo et al\\.", "year": 2016}, {"title": "Effective approaches to attentionbased neural machine translation", "author": ["Minh-Thang Luong", "Hieu Pham", "Christopher D. Manning."], "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1412\u20131421, Lisbon,", "citeRegEx": "Luong et al\\.,? 2015", "shortCiteRegEx": "Luong et al\\.", "year": 2015}, {"title": "Bleu: a method for automatic evaluation of machine translation", "author": ["Kishore Papineni", "Salim Roukos", "Todd Ward", "WeiJing Zhu."], "venue": "Proceedings of 40th Annual Meeting of the Association for Computational Linguistics, pages 311\u2013318, Philadelphia,", "citeRegEx": "Papineni et al\\.,? 2002", "shortCiteRegEx": "Papineni et al\\.", "year": 2002}, {"title": "Towards automatic error analysis of machine translation output", "author": ["Maja Popovi\u0107", "Hermann Ney."], "venue": "Comput. Linguist., 37(4):657\u2013688, December.", "citeRegEx": "Popovi\u0107 and Ney.,? 2011", "shortCiteRegEx": "Popovi\u0107 and Ney.", "year": 2011}, {"title": "Hjerson: An open source tool for automatic error classification of machine translation output", "author": ["Maja Popovi\u0107."], "venue": "The Prague Bulletin of Mathematical Linguistics, 96:59\u201367.", "citeRegEx": "Popovi\u0107.,? 2011", "shortCiteRegEx": "Popovi\u0107.", "year": 2011}, {"title": "chrF: character n-gram F-score for automatic MT evaluation", "author": ["Maja Popovi\u0107."], "venue": "Proceedings of the Tenth Workshop on Statistical Machine Translation, pages 392\u2013395, Lisbon, Portugal, September.", "citeRegEx": "Popovi\u0107.,? 2015", "shortCiteRegEx": "Popovi\u0107.", "year": 2015}, {"title": "Complexity of spoken versus written language for machine translation", "author": ["Nicholas Ruiz", "Marcello Federico."], "venue": "17th Annual Conference of the European Association for Machine Translation, EAMT, pages 173\u2013180, Dubrovnik, Croatia, June.", "citeRegEx": "Ruiz and Federico.,? 2014", "shortCiteRegEx": "Ruiz and Federico.", "year": 2014}, {"title": "Abu-matran at wmt 2016 translation task: Deep learning, morphological segmentation and tuning on character sequences", "author": ["V\u0131\u0301ctor M. S\u00e1nchez-Cartagena", "Antonio Toral"], "venue": "In Proceedings of the First Conference on Machine Translation,", "citeRegEx": "S\u00e1nchez.Cartagena and Toral.,? \\Q2016\\E", "shortCiteRegEx": "S\u00e1nchez.Cartagena and Toral.", "year": 2016}, {"title": "Improving Neural Machine Translation Models with Monolingual Data", "author": ["Rico Sennrich", "Barry Haddow", "Alexandra Birch."], "venue": "arXiv preprint arXiv:1511.06709.", "citeRegEx": "Sennrich et al\\.,? 2015", "shortCiteRegEx": "Sennrich et al\\.", "year": 2015}, {"title": "Edinburgh Neural Machine Translation Systems for WMT 16", "author": ["Rico Sennrich", "Barry Haddow", "Alexandra Birch."], "venue": "Proceedings of the First Conference on Machine Translation, pages 371\u2013376, Berlin, Germany, August.", "citeRegEx": "Sennrich et al\\.,? 2016", "shortCiteRegEx": "Sennrich et al\\.", "year": 2016}, {"title": "A study of translation edit rate with targeted human annotation", "author": ["Matthew Snover", "Bonnie Dorr", "Richard Schwartz", "Linnea Micciulla", "John Makhoul."], "venue": "Proceedings of AMTA, pages 223\u2013231.", "citeRegEx": "Snover et al\\.,? 2006", "shortCiteRegEx": "Snover et al\\.", "year": 2006}, {"title": "Edinburgh\u2019s statistical machine translation systems for wmt16", "author": ["Philip Williams", "Rico Sennrich", "Maria Nadejde", "Matthias Huck", "Barry Haddow", "Ond\u0159ej Bojar."], "venue": "Proceedings of the First Conference on Machine Translation, pages 399\u2013410,", "citeRegEx": "Williams et al\\.,? 2016", "shortCiteRegEx": "Williams et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 28, "context": "(Sennrich et al., 2015; Luong et al., 2015; Costa-Juss\u00e0 and Fonollosa, 2016; Chung et al., 2016).", "startOffset": 0, "endOffset": 96}, {"referenceID": 21, "context": "(Sennrich et al., 2015; Luong et al., 2015; Costa-Juss\u00e0 and Fonollosa, 2016; Chung et al., 2016).", "startOffset": 0, "endOffset": 96}, {"referenceID": 6, "context": "(Sennrich et al., 2015; Luong et al., 2015; Costa-Juss\u00e0 and Fonollosa, 2016; Chung et al., 2016).", "startOffset": 0, "endOffset": 96}, {"referenceID": 5, "context": "(Sennrich et al., 2015; Luong et al., 2015; Costa-Juss\u00e0 and Fonollosa, 2016; Chung et al., 2016).", "startOffset": 0, "endOffset": 96}, {"referenceID": 19, "context": "In PBMT (Koehn, 2010) different models (translation, reordering, target language, etc.", "startOffset": 8, "endOffset": 21}, {"referenceID": 15, "context": "long short-term memory (LSTM) (Hochreiter and Schmidhuber, 1997) or gated recurrent units (Chung et al.", "startOffset": 30, "endOffset": 64}, {"referenceID": 4, "context": "long short-term memory (LSTM) (Hochreiter and Schmidhuber, 1997) or gated recurrent units (Chung et al., 2014).", "startOffset": 90, "endOffset": 110}, {"referenceID": 22, "context": "1 In this translation task, outputs produced by participant MT systems, the vast majority of which fall under either the phrase-based or neural approaches, were evaluated (i) automatically with the BLEU (Papineni et al., 2002) and TER (Snover et al.", "startOffset": 203, "endOffset": 226}, {"referenceID": 30, "context": ", 2002) and TER (Snover et al., 2006) metrics, and (ii) manually by means of ranking translations (Federmann, 2012) and monolingual semantic similarity (Graham et al.", "startOffset": 16, "endOffset": 37}, {"referenceID": 12, "context": ", 2006) metrics, and (ii) manually by means of ranking translations (Federmann, 2012) and monolingual semantic similarity (Graham et al.", "startOffset": 68, "endOffset": 85}, {"referenceID": 14, "context": ", 2006) metrics, and (ii) manually by means of ranking translations (Federmann, 2012) and monolingual semantic similarity (Graham et al., 2016).", "startOffset": 122, "endOffset": 143}, {"referenceID": 1, "context": "In order to understand better the new NMT paradigm and in what respects it provides better (or worse) translation quality than state-of-theart PBMT, Bentivogli et al. (2016) conducted a detailed analysis for the English-to-German language direction.", "startOffset": 149, "endOffset": 174}, {"referenceID": 1, "context": "Hereunder we specify the main differences and similarities between this work and that of Bentivogli et al. (2016):", "startOffset": 89, "endOffset": 114}, {"referenceID": 26, "context": "Previous research has shown that these two types of content pose different challenges for MT (Ruiz and Federico, 2014).", "startOffset": 93, "endOffset": 118}, {"referenceID": 8, "context": "EN\u2192CS PBMT Phrase-based, word clusters (Ding et al., 2016) NMT Unsupervised word segmentation and backtranslated monolingual corpora (Sennrich et al.", "startOffset": 39, "endOffset": 58}, {"referenceID": 29, "context": ", 2016) NMT Unsupervised word segmentation and backtranslated monolingual corpora (Sennrich et al., 2016)", "startOffset": 82, "endOffset": 105}, {"referenceID": 31, "context": "EN\u2192DE hierarchical PBMT String-to-tree, neural and dependency language models (Williams et al., 2016) NMT Same as for EN\u2192CS EN\u2192FI PBMT Phrase-based, rule-based and unsupervised word segmentation, operation sequence model (Durrani et al.", "startOffset": 78, "endOffset": 101}, {"referenceID": 10, "context": ", 2016) NMT Same as for EN\u2192CS EN\u2192FI PBMT Phrase-based, rule-based and unsupervised word segmentation, operation sequence model (Durrani et al., 2011), bilingual neural language model (Devlin et al.", "startOffset": 127, "endOffset": 149}, {"referenceID": 7, "context": ", 2011), bilingual neural language model (Devlin et al., 2014), re-ranked with a recurrent neural language model (S\u00e1nchez-Cartagena and Toral, 2016) NMT Rule-based word segmentation, backtranslated monolingual corpora (S\u00e1nchez-Cartagena and Toral, 2016)", "startOffset": 41, "endOffset": 62}, {"referenceID": 27, "context": ", 2014), re-ranked with a recurrent neural language model (S\u00e1nchez-Cartagena and Toral, 2016) NMT Rule-based word segmentation, backtranslated monolingual corpora (S\u00e1nchez-Cartagena and Toral, 2016)", "startOffset": 58, "endOffset": 93}, {"referenceID": 27, "context": ", 2014), re-ranked with a recurrent neural language model (S\u00e1nchez-Cartagena and Toral, 2016) NMT Rule-based word segmentation, backtranslated monolingual corpora (S\u00e1nchez-Cartagena and Toral, 2016)", "startOffset": 163, "endOffset": 198}, {"referenceID": 31, "context": "EN\u2192RO PBMT Phrased-based, operation sequence model, monolingual and bilingual neural language models (Williams et al., 2016) NMT Same as for EN\u2192CS EN\u2192RU PBMT Phrase-based, word clusters, bilingual neural language model (Ding et al.", "startOffset": 101, "endOffset": 124}, {"referenceID": 8, "context": ", 2016) NMT Same as for EN\u2192CS EN\u2192RU PBMT Phrase-based, word clusters, bilingual neural language model (Ding et al., 2016) NMT Same as for EN\u2192CS CS\u2192EN PBMT Same as for EN\u2192CS NMT Same as for EN\u2192CS DE\u2192EN PBMT Phrase-based, pre-reordering, compound splitting (Williams et al.", "startOffset": 102, "endOffset": 121}, {"referenceID": 31, "context": ", 2016) NMT Same as for EN\u2192CS CS\u2192EN PBMT Same as for EN\u2192CS NMT Same as for EN\u2192CS DE\u2192EN PBMT Phrase-based, pre-reordering, compound splitting (Williams et al., 2016) NMT Same as for EN\u2192CS plus reranked with a right-to-left model RO\u2192EN PBMT Phrase-based, operation sequence model, monolingual neural language model (Williams et al.", "startOffset": 141, "endOffset": 164}, {"referenceID": 31, "context": ", 2016) NMT Same as for EN\u2192CS plus reranked with a right-to-left model RO\u2192EN PBMT Phrase-based, operation sequence model, monolingual neural language model (Williams et al., 2016) NMT Same as for EN\u2192CS RU\u2192EN PBMT Phrase-based, lemmas in word alignment, sparse features, bilingual neural language model and transliteration (Lo et al.", "startOffset": 156, "endOffset": 179}, {"referenceID": 20, "context": ", 2016) NMT Same as for EN\u2192CS RU\u2192EN PBMT Phrase-based, lemmas in word alignment, sparse features, bilingual neural language model and transliteration (Lo et al., 2016) NMT Same as for EN\u2192CS", "startOffset": 150, "endOffset": 167}, {"referenceID": 0, "context": "It should be noted that all the NMT systems listed in the table fall under the encoder-decoder architecture with attention (Bahdanau et al., 2015) and operate on subword units.", "startOffset": 123, "endOffset": 146}, {"referenceID": 27, "context": "Word segmentation is carried out with the help of a lexicon in the EN\u2192FI direction (S\u00e1nchez-Cartagena and Toral, 2016) and in an unsupervised way in the remaining directions (Sennrich et al.", "startOffset": 83, "endOffset": 118}, {"referenceID": 29, "context": "Word segmentation is carried out with the help of a lexicon in the EN\u2192FI direction (S\u00e1nchez-Cartagena and Toral, 2016) and in an unsupervised way in the remaining directions (Sennrich et al., 2016).", "startOffset": 174, "endOffset": 197}, {"referenceID": 18, "context": "If the difference between them is statistically significant according to paired bootstrap resampling (Koehn, 2004) with p = 0.", "startOffset": 101, "endOffset": 114}, {"referenceID": 25, "context": "We measure this by taking the outputs of the top n6 NMT and PBMT systems submitted to each language direction7 and checking their pairwise overlap in terms of the chrF1 (Popovi\u0107, 2015) automatic evaluation metric.", "startOffset": 169, "endOffset": 184}, {"referenceID": 25, "context": "Throughout our analyses we use this metric as it has been shown to correlate better with human judgements than the de facto standard automatic metric, BLEU, when the target language is a morphologically rich language such as Finnish, while its correlation is on par with BLEU for languages with simpler morphology such as English (Popovi\u0107, 2015).", "startOffset": 330, "endOffset": 345}, {"referenceID": 11, "context": "The LMs are built using TheanoLM (Enarvi and Kurimo, 2016).", "startOffset": 33, "endOffset": 58}, {"referenceID": 9, "context": "The training algorithm is Adagrad (Duchi et al., 2011) and we used 1 000 word classes obtained with mkcls from the training corpus.", "startOffset": 34, "endOffset": 54}, {"referenceID": 27, "context": "The only exception is translation into Finnish, in which perplexity on the PBMT output is slightly lower, probably because its fluency was improved by reranking it with a neural LM similar to the one we use in this experiment (S\u00e1nchez-Cartagena and Toral, 2016).", "startOffset": 226, "endOffset": 261}, {"referenceID": 0, "context": "One may argue that the perplexity obtained for NMT outputs is lower than that for PBMT outputs because the LMs we used to measure perplexity follow the same model as the decoder of the NMT architecture (Bahdanau et al., 2015) and hence perplexity on a neural LM is not a valid proxy for fluency.", "startOffset": 202, "endOffset": 225}, {"referenceID": 17, "context": "\u2022 Neural LMs consistently outperform n-gram based LMs when assessing the fluency of real text (Kim et al., 2016; Enarvi and Kurimo, 2016).", "startOffset": 94, "endOffset": 137}, {"referenceID": 11, "context": "\u2022 Neural LMs consistently outperform n-gram based LMs when assessing the fluency of real text (Kim et al., 2016; Enarvi and Kurimo, 2016).", "startOffset": 94, "endOffset": 137}, {"referenceID": 18, "context": "If the difference between the distances depicted in the two last columns is statistically significant according to paired bootstrap resampling (Koehn, 2004) with p = 0.", "startOffset": 143, "endOffset": 156}, {"referenceID": 13, "context": "For each language direction, we computed word alignments between the source-language side of the test set and the target-language reference, the PBMT output and the NMT output by means of MGIZA++ (Gao and Vogel, 2008).", "startOffset": 196, "endOffset": 217}, {"referenceID": 2, "context": "A permutation between a source-language sentence and a target-language sentence is defined as the set of operations that need to be carried out over the words in the sourcelanguage sentence to reflect the order of the words in the target-language sentence (Birch, 2011, Sec. 5.2). a monotone word alignment. The similarity between the reorderings produced by each MT system and the reorderings in the reference translation can also be estimated as the distance between the corresponding word alignments. Table 5 shows the value of these distances for the language pairs included in our evaluation. The average over all the sentences in the test set of the distance proposed by Birch (2011) is depicted.", "startOffset": 257, "endOffset": 690}, {"referenceID": 31, "context": "A possible explanation for these two exceptions is the following: in the former language pair, the PBMT system is hierarchical (Williams et al., 2016) while in the latter, the output was reranked with neural LMs.", "startOffset": 127, "endOffset": 150}, {"referenceID": 1, "context": "In this regard, Bentivogli et al. (2016) found that, for transcribed speeches, NMT outperformed PBMT regardless of sentence length while also noted that NMT\u2019s performance degraded faster than PBMT\u2019s as sentence length increases.", "startOffset": 16, "endOffset": 41}, {"referenceID": 24, "context": "independent error rates (hPER and rPER, respectively) as implemented in Hjerson (Popovi\u0107, 2011).", "startOffset": 80, "endOffset": 95}, {"referenceID": 23, "context": "Due to the fact that it is difficult to disambiguate between three of these categories, namely missing words, extra words and lexical choice errors (Popovi\u0107 and Ney, 2011), we group them in a unique category, which we refer to as lexical errors.", "startOffset": 148, "endOffset": 171}, {"referenceID": 1, "context": "This corroborates the findings on reordering by Bentivogli et al. (2016).", "startOffset": 48, "endOffset": 73}, {"referenceID": 1, "context": "The latter was not the case in the work by Bentivogli et al. (2016). We believe the reason behind this different finding is twofold.", "startOffset": 43, "endOffset": 68}, {"referenceID": 1, "context": "We thus confirm that the findings of Bentivogli et al. (2016) regarding these two error types apply to a wide range of language directions.", "startOffset": 37, "endOffset": 62}], "year": 2017, "abstractText": "We aim to shed light on the strengths and weaknesses of the newly introduced neural machine translation paradigm. To that end, we conduct a multifaceted evaluation in which we compare outputs produced by state-of-the-art neural machine translation and phrase-based machine translation systems for 9 language directions across a number of dimensions. Specifically, we measure the similarity of the outputs, their fluency and amount of reordering, the effect of sentence length and performance across different error categories. We find out that translations produced by neural machine translation systems are considerably different, more fluent and more accurate in terms of word order compared to those produced by phrase-based systems. Neural machine translation systems are also more accurate at producing inflected forms, but they perform poorly when translating very long sentences.", "creator": "TeX"}}}