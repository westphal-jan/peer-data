{"id": "1701.02925", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Jan-2017", "title": "Question Analysis for Arabic Question Answering Systems", "abstract": "The first step of processing a question in Question Answering(QA) Systems is to carry out a detailed analysis of the question for the purpose of determining what it is asking for and how to perfectly approach answering it. Our Question analysis uses several techniques to analyze any question given in natural language: a Stanford POS Tagger &amp; parser for Arabic language, a named entity recognizer, tokenizer,Stop-word removal, Question expansion, Question classification and Question focus extraction components. We employ numerous detection rules and trained classifier using features from this analysis to detect important elements of the question, including: 1) the portion of the question that is a referring to the answer (the focus); 2) different terms in the question that identify what type of entity is being asked for (the lexical answer types); 3) Question expansion ; 4) a process of classifying the question into one or more of several and different types; and We describe how these elements are identified and evaluate the effect of accurate detection on our question-answering system using the Mean Reciprocal Rank(MRR) accuracy measure.", "histories": [["v1", "Wed, 11 Jan 2017 11:12:24 GMT  (379kb)", "http://arxiv.org/abs/1701.02925v1", "10 pages, 3 figures, published article in IJNLC"]], "COMMENTS": "10 pages, 3 figures, published article in IJNLC", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["waheeb ahmed", "dr anto p babu"], "accepted": false, "id": "1701.02925"}, "pdf": {"name": "1701.02925.pdf", "metadata": {"source": "CRF", "title": "QUESTION ANALYSIS FOR ARABIC QUESTION ANSWERING SYSTEMS", "authors": ["Waheeb Ahmed"], "emails": [], "sections": [{"heading": null, "text": "DOI: 10.5121 / ijnlc.2016.5603 21The first step in working on a question in QA systems is to perform a detailed analysis of the question to determine what it requires and how it can be answered perfectly. Our question analysis uses several techniques to analyze each question asked in natural language: a Stanford POS tagger & parser for Arabic language, a so-called entity recognition, tokenizer, stop word removal, question extension, question classification and question focus extraction components. We use numerous recognition rules and trained classifiers to identify important elements of the question, including: 1) the part of the question that refers to the answer (the focus); 2) different terms in the question that identify what kind of entity is being asked (the lexical answer types); 3) question expansion; 4) a process of classifying the question in terms of the question and identifying the different types of question (the MR); and 2) the different types of question in the question."}, {"heading": "1. INTRODUCTION", "text": "Question analysis is the first stage of any QA system, and the accuracy of its results has a significant impact on the following phases of information gathering and extraction. To achieve a better result, the semantic information contained in questions should be extracted for question analysis. The question-answering process in most question-answering systems begins with a phase of question analysis that attempts to determine what the question is looking for and how it can be answered effectively [1]. In general, the Question Analysis Module receives the unstructured text question as input and identifies the syntactic and semantic elements of the question that are stored as structured information that will later be used by the many components of our QA system. Almost all components of our QA system rely in some way on the information generated by the question analysis phase [2]. Question analysis is based on the top of the parsing, meeting and semantic analysis components. We use numerous recognition rules and numerous critical elements to identify the question."}, {"heading": "2. QUESTION ANALYSIS MODULE", "text": "This module is responsible for carefully analyzing the question before sending it to the information retrieval module. The question processing module consists of three submodules, the tokenizer, the class extractor and the focus detector as shown in Figure 1. The first module is used to divide the question into individual tokens, the second module to identify the class of the question and the third module to extract the question focus. The focus of the question specifies what the given question is looking for exactly. The following figure shows the architecture of our proposed QA system together with the various submodules used for the question processing. Figure 1 shows the different stages in which the question is processed until the final answer is extracted and generated to the user. In the following sections, the various subtasks applied to the question are explained in order to extract relevant information that could support the subsequent phases of the QA system."}, {"heading": "2.1. Question tokenization", "text": "The first step in question analysis is the identification of symbols or elementary units that do not need to be dissected in subsequent processing [3]. Tokenization is a crucial step in QA. It can be considered a kind of symbol for all other tasks of processing natural language. Tokenization is the task of separating words (morphemes) from the running text [4]. Word segmentation (tokenization) gets words from the text. Space is a good separator for this purpose, but it does not work as compound words with special cases [5]. Some compound words are written with a space in the middle, even though they are single words. Tokenization (tokenization) is a necessary and non-trivial step in natural language processing [6]."}, {"heading": "2.2. Stop Words Removal", "text": "This submodule removes the prepositions, conjunctions and question words. As the prepositions and conjunctions occur very frequently in the documents, these words may be beneficial for the information retrieval module IR) [8ooo] [10]. The IR module identifies the target documents based on the terms that very rarely occur in the documents. After removing the stop words, the important terms remain in the question."}, {"heading": "2.3. Question Expansion", "text": "In order to get rid of these limitations, we need to apply semantic information gathering techniques, which focus on the meaning the user is looking for rather than on the exact words of the question the user is asking. We will consider four main characteristics by which users prefer semantic search systems to keyword-based ones: dealing with generalizations, dealing with morphological variants, dealing with conceptual similarity, and dealing with synonyms with the right sense (literally disambiguation) [11] [12]. In the question extension, synonyms for nouns and adjectives are added to the question list of question terms. As the documents that may contain the answer to the question may not contain the terms the user has used in his question, expanding the user question by adding synonyms to the nouns and adjectives of the question will increase the likelihood that we will get the answer to that question [14]."}, {"heading": "2.4. Class Extraction", "text": "We used a trained Support Vector Machine (VSM) classifier from our previous paper [15]. The classifier receives the question and gives the question a label. She is trained to produce a label based on a two-step classification. For example, \"Why do heavier objects go downhill faster?\" The classifier's output will be \"DESCRIPTON: Reason,\" that is, the question is asked for a descriptive answer and this is the rough grain type of the answer. The fine-grain type of the answer is \"Reason.\" The class extraction module sends its results to the question-type module (AE) to apply the correct technique for extracting the answer. Table 1 shows the different classes according to the proposed scheme of Li & Roth [16]. Table 1. Question-type class (Level 1) Question-type (Level 2) Question-type (Level 2) HUMANGroup Individual Title Description LOCATIONCountry Mountain Mountain & UMERIC1 (Level 1): 1)"}, {"heading": "2.5. Focus identification", "text": "The main point of the question is the amount of nouns and noun sentences (NPs) available in the question. (\"Who was the first American in space?\") Class Extraction: HUMAN: individual FOCUS terms are used to rank candidates. Example: Question 3: \"(the first American in space) FOCUS-HEAD =\" (American) FOCUS-MODIFIERS = ADJ \"(first), COMP\" seven + 45 \"(first American in space) FOCUS-HEAD =\" (first) FOCUS-MODIFIERS = ADJ \"(first), COMP\" seven + 45 \"(second) Question 4:\" the first American in space \"FOCUS-HEAD =\" (first) FOCUS-MODIFIERS terms are used for the question."}, {"heading": "3. DOCUMENT RETRIEVAL", "text": "The extended list of terms extracted from the question is sent together with the synonyms to the IR module for retrieval of documents. We implemented our IR module with the Vector Space Model due to its simplicity of implementation and also its efficiency. [19] The system first extracts text from the top 10 of the retrieved documents from which the top three documents are selected for further processing by the AE module."}, {"heading": "4. ANSWER EXTRACTION", "text": "It starts with processing a document using several procedures: First, the raw text of the document is divided into sentences using a sentence segmentator, and each sentence is further divided into words (tokens) using a tokenizer. Next, each sentence is provided with sub-terms that help the named entity recognize it. [20] This module uses different techniques to get different types of answers. Questions given by the class extraction module are \"HUMAN: individual\" which means that the question is searched for a person name. Thus, the AE module will use named entity recognition technology to get the answer. Questions that ask for a pattern merge technology are used. To select the answer from the top 5 generated answers / sets, the QE selection and the order of questions are used."}, {"heading": "5. RESULTS AND EVALUATION", "text": "In this study, we presented a combination of question analysis techniques used in a closed-domain Arabic question-and-answer system. Our question analysis module consists of several subtasks that are important to focus on the extraction and classification of questions. We have several rule-based approaches to focus extraction based on the results of the Stanford POS Tagger for Arabic. In addition, we have also used a number of manually commented questions to test the system. Answer extraction evaluation methods for the different types of questions provided to the QA system are based on a text repetition conference (TREC), using MRR (Mean Reciprocal Rank) standards shown in the following formula: MRR = 3), n refers to the number of questions to be reviewed, and ri refers to the position of the first correct answer to the number of Qi questions when there are no correct questions."}, {"heading": "6. CONCLUSION", "text": "In this thesis, we have developed a question analysis module for the analysis of a question of natural language. Our question analysis module is mainly concerned with the identification of four important factors, namely focus, question expansion, question classification and Q-term extraction. It is a comprehensive analysis of the question from which all necessary information is extracted, which is used as input for the other components to answer questions. We evaluated our implementation of our module in terms of its performance based on the focus identification and tasks of the question classification, assessing its impact on the accuracy of our QA system. Our proposed method achieved an average accuracy of 65% for the five types of questions with a total of 250 questions submitted to the system."}], "references": [{"title": "A Survey of Arabic Question Answering: challenges, Tasks, Approaches, Tools, and Future Trends", "author": ["Ezzeldin A.M", "Shaheen M"], "venue": "In Proceedings of the 13th International Arab Conference on Information Technology", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "Tokenization as The initial phase in NLP", "author": ["J. Jonathan", "K. Chunyu"], "venue": "In Proceedings of COLING-92,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1992}, {"title": "Speech and Language Processing: An Introduction to Natural Language Processing", "author": ["D. Jurafsky", "H. James Martin"], "venue": "Computational Linguistics, and Speech Recognition. Prentice Hall, 2000.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2000}, {"title": "Tokenization as Pre-processing for Arabic Tagging System", "author": ["Ahmed H. Aliwy"], "venue": "International Journal of Information and Education Technology,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2012}, {"title": "Natural Language Processing with Python.", "author": ["S. Bird", "E. Klein", "E. Loper"], "venue": "O\u2019Reilly Media,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2009}, {"title": "A non-deterministic tokeniser for finite-state parsing", "author": ["J-P Chanod", "P. Tapanainen"], "venue": "ECAI 96. 12th European Conference on Artificial Intelligence, 1996.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1996}, {"title": "Arabic tokenization, part-of-speech tagging and morphological disambiguation in one fell swoop", "author": ["N. Habash", "O. Rambow"], "venue": "Proceedings of the 43rd Annual Meeting of the ACL., pp. 573\u2013 580, 2005.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2005}, {"title": "Arabic Stop Words:Towards a Generalisation and Standardisation", "author": ["K. Bouzoubaa", "H. Baidouri", "T. Loukili", "T. El Yazidi"], "venue": "In Proceedings of the 13th International Business Information Management Association Conference (IBIMA),", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2009}, {"title": "Stop-word removal algorithm for Arabic language\u201d, Proceedings", "author": ["R. Al-Shalabi", "G. Kanan", "J.M. Jaam", "Eyad Hailat"], "venue": "Of the International Conference on Information and Communication Technologies: From Theory to Applications,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2004}, {"title": "Semantic Query Expansion for Arabic Information Retrieval", "author": ["A. Mahgoub", "M. Rashwan", "H. Raafat", "Mohamed A. Zahran", "Magda B. Fayek"], "venue": "Proceedings of the EMNLP 2014 Workshop on Arabic Natural Language Processing", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "Enhanced semantic arabic Question Answering system based on Khoja stemmer and AWN", "author": ["F. Noha", "M. Hamdy", "E. Ashraf"], "venue": "9th International Computer Engineering Conference (ICENCO),", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "Semantic Based Query Expansion for Arabic Question Answering Systems", "author": ["A. Hani", "K. Santosh", "S. Khaled"], "venue": "In Proceedings of the First International Conference on Arabic Computational Linguistics (ACLing),", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2015}, {"title": "Classification of Arabic Questions Using Multinomial Na\u00efve Bayes And Support Vector Machines", "author": ["A. Waheeb", "A. Babu"], "venue": "International Journal of Latest Trends In Engineering And Technology,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2016}, {"title": "Learning Question Classifiers: The Role of Semantic Information", "author": ["X. Li", "D. Roth"], "venue": "Journal of Natural Language Engineering,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2006}, {"title": "Automatic Text Processing: the transformation, analysis, and retrieval of information by computer", "author": ["G. Salton"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1989}, {"title": "A Survey on Approaches to Text Mining using Information Extraction", "author": ["R. Dukhi", "A. Bhattacharya"], "venue": "IOSR Journal of Computer Engineering (IOSR-JCE),", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2016}, {"title": "NERA: Named Entity Recognition for Arabic", "author": ["K. Shaalan", "H. Raza"], "venue": "Journal of The American Society for Information Science & Technology,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2009}, {"title": "Named Entity Recognition for Question Answering", "author": ["D. Moll \u0301a", "Menno V", "D. Smith"], "venue": "Proceedings of the 2006 Australasian Language Technology Workshop,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2007}, {"title": "Reducing question answering input data using named entity recognition", "author": ["E. Noguera", "A. Toral", "F. Llopis", "R. Mu\u2019noz"], "venue": "In Proceedings of the 8th International Conference on Text, Speech & Dialogue,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2005}, {"title": "The Use of Sentence Similarity as a Semantic Relevance Metric for Question Answering", "author": ["M. De Boni", "S. Manandhar"], "venue": "The York Research Database,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2003}, {"title": "Answer Extraction and Passage Retrieval for Question Answering Systems", "author": ["Waheeb", "A. Babu"], "venue": "International Journal of Advanced Research in Computer Engineering & Technology (IJARCET),", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2016}, {"title": "Answer Extraction Technique for Question Answering Systems", "author": ["A. Waheeb", "A. Babu"], "venue": "International Journal of Innovative Research in Computer and Communication Engineering(IJIRCCE),", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2016}, {"title": "Overview of the TREC 2001 question answering track,", "author": ["E. Voorhees"], "venue": "Proceedings of the 10th Text Retrieval Conference,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2001}], "referenceMentions": [{"referenceID": 0, "context": "Almost all of our QA system components rely in some way on the information generated by question analysis stage[2].", "startOffset": 111, "endOffset": 114}, {"referenceID": 1, "context": "The entity word is defined as one kind of token for Natural Language Processing(NLP) in general and specifically in QA, the most basic one[3].", "startOffset": 138, "endOffset": 141}, {"referenceID": 2, "context": "Tokenization is the task of splitting words (morphemes) from running text [4].", "startOffset": 74, "endOffset": 77}, {"referenceID": 3, "context": "The space is a good separator for this purpose but it will not work with special cases as compound words[5].", "startOffset": 104, "endOffset": 107}, {"referenceID": 4, "context": "Therefore, tokenization is a necessary and non-trivial step in natural language processing [6].", "startOffset": 91, "endOffset": 94}, {"referenceID": 5, "context": "It is much related to the morphological analysis but usually it has been considered as an independent process [7].", "startOffset": 110, "endOffset": 113}, {"referenceID": 6, "context": "On average, a word form in the Arabic Tree Bank(ATB) has about 2 morphological analyses [8].", "startOffset": 88, "endOffset": 91}, {"referenceID": 7, "context": "Then, tokenization is similar/equivalent to word segmentation in Chinese language where Arabic word is as a sentence in Chinese language[9].", "startOffset": 136, "endOffset": 139}, {"referenceID": 8, "context": "Since the prepositions and conjunctions occurs very frequently in the documents, these words can add any benefit for the information retrieval IR) module[8ooo][10].", "startOffset": 159, "endOffset": 163}, {"referenceID": 9, "context": "We consider four main features that make users prefer semantic based search systems over keyword-based: Handling Generalizations, Handling Morphological Variants, Handling Concept matches, and Handling synonyms with the correct sense (Word Sense Disambiguation)[11][12].", "startOffset": 261, "endOffset": 265}, {"referenceID": 10, "context": "We consider four main features that make users prefer semantic based search systems over keyword-based: Handling Generalizations, Handling Morphological Variants, Handling Concept matches, and Handling synonyms with the correct sense (Word Sense Disambiguation)[11][12].", "startOffset": 265, "endOffset": 269}, {"referenceID": 11, "context": "24 question will increase the chance of getting the answer[13] and for this we used the Arabic WordNet[14].", "startOffset": 58, "endOffset": 62}, {"referenceID": 12, "context": "We used a trained Support Vector Machine(VSM) Classifier from our previous work[15].", "startOffset": 79, "endOffset": 83}, {"referenceID": 13, "context": "Table 1 shows the different classes as per the proposed scheme by Li & Roth[16].", "startOffset": 75, "endOffset": 79}, {"referenceID": 14, "context": "The expanded list of terms extracted from the question along with the synonyms will be sent to the IR module for document retrieval, We implemented our IR module using the Vector Space Model for its simplicity of implementation and also its efficiency[19].", "startOffset": 251, "endOffset": 255}, {"referenceID": 15, "context": "Next, each sentence is tagged with partof-speech tags, which will help the named entity detection[20].", "startOffset": 97, "endOffset": 101}, {"referenceID": 16, "context": "For the most part, such a system is simply recognizing instances of linguistic patterns and collating them[21].", "startOffset": 106, "endOffset": 110}, {"referenceID": 17, "context": "[22] The positive impact of NE recognition in QA is widely acknowledged and there are studies that confirm it The positive impact of NE recognition in QA is widely acknowledged and there are studies that confirm it [23].", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "[22] The positive impact of NE recognition in QA is widely acknowledged and there are studies that confirm it The positive impact of NE recognition in QA is widely acknowledged and there are studies that confirm it [23].", "startOffset": 215, "endOffset": 219}, {"referenceID": 19, "context": "\u2022 For extraction answer types of \u201cDESCRIPTION\u201d we use semantic similarity measure between the question terms and the document sentences[25].", "startOffset": 135, "endOffset": 139}, {"referenceID": 20, "context": "We developed answer extraction and passage retrieval techniques for Arabic language in our previous works[26][27].", "startOffset": 105, "endOffset": 109}, {"referenceID": 21, "context": "We developed answer extraction and passage retrieval techniques for Arabic language in our previous works[26][27].", "startOffset": 109, "endOffset": 113}, {"referenceID": 22, "context": "The assessment methods of answer extraction for the different types of questions supplied to the QA system is based on Text Retrieval Conference(TREC)[28], using MRR (Mean Reciprocal Rank) standards shown in the following formula:", "startOffset": 150, "endOffset": 154}], "year": 2016, "abstractText": "The first step of processing a question in Question Answering(QA) Systems is to carry out a detailed analysis of the question for the purpose of determining what it is asking for and how to perfectly approach answering it. Our Question analysis uses several techniques to analyze any question given in natural language: a Stanford POS Tagger & parser for Arabic language, a named entity recognizer, tokenizer, Stop-word removal, Question expansion, Question classification and Question focus extraction components. We employ numerous detection rules and trained classifier using features from this analysis to detect important elements of the question, including: 1) the portion of the question that is a referring to the answer (the focus); 2) different terms in the question that identify what type of entity is being asked for (the lexical answer types); 3) Question expansion ; 4) a process of classifying the question into one or more of several and different types; and We describe how these elements are identified and evaluate the effect of accurate detection on our question-answering system using the Mean Reciprocal Rank(MRR) accuracy measure.", "creator": "PScript5.dll Version 5.2.2"}}}