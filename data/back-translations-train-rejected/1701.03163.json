{"id": "1701.03163", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Jan-2017", "title": "Parsing Universal Dependencies without training", "abstract": "We propose UDP, the first training-free parser for Universal Dependencies (UD). Our algorithm is based on PageRank and a small set of head attachment rules. It features two-step decoding to guarantee that function words are attached as leaf nodes. The parser requires no training, and it is competitive with a delexicalized transfer system. UDP offers a linguistically sound unsupervised alternative to cross-lingual parsing for UD, which can be used as a baseline for such systems. The parser has very few parameters and is distinctly robust to domain change across languages.", "histories": [["v1", "Wed, 11 Jan 2017 20:56:29 GMT  (33kb)", "http://arxiv.org/abs/1701.03163v1", "EACL 2017, 8+2 pages"]], "COMMENTS": "EACL 2017, 8+2 pages", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["h\\'ector mart\\'inez alonso", "\\v{z}eljko agi\\'c", "barbara plank", "anders s{\\o}gaard"], "accepted": false, "id": "1701.03163"}, "pdf": {"name": "1701.03163.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["hector.martinez-alonso@inria.fr"], "sections": [{"heading": null, "text": "ar Xiv: 170 1.03 163v 1 [cs.C L] 11 Jan 2017"}, {"heading": "1 Introduction", "text": "This year, it has never been as good as it has been this year."}, {"heading": "2 Related work", "text": "It is. (it is.) It is. (it is.) It is. (it is.) It is. (it is.) It is. (it is.) It is. (it is.) It is. (it is.) It is. (it is.) It is. (it is.) It is. (it is.) It is. (it is.) It is. (it is.) It is. (it is.) It is. (it is.) It is. (it is.) It is. (it.) It is. (it.) It is. (it.) It is. (it.) It is. (it.) It is. (it.) It is. (it.) It is. (it.) It is. (it.) It is. (it. (it.) It is. (it.) It is. (it. (it.) It is. (it. (it.) It is. (it. (it.) It is. (it. (it.) It is. (it. (it.) It. (it. (it.) It. (it. (it.)"}, {"heading": "3 Method", "text": "Our approach does not use training or unmarked data. We used the English tree bank during development to evaluate the contribution of individual head rules and to adjust PageRank parameters (paragraph 3.1) and functional wordability (paragraph 3.2). Adposition direction is calculated during runtime. We refer to our UD parser as UDP from now on."}, {"heading": "3.1 PageRank setup", "text": "Our system uses the PageRank (PR) algorithm (Page et al., 1999) to estimate the relevance of the content words of a sentence. PR uses a random walk to estimate which nodes in the graph are more likely to be visited, and so there is a higher ranking for nodes with more incoming edges, as well as for nodes connected to them. PR requires an effective graphics strategy. We have experimented with the strategies of S\u00f8gaard (2012b), such as words connected to adjacent words, but our system behaves best using the dependency rules in Table 1 to build the graph. UD trees are often very flat, and a strongly connected graph yields a distribution that is closer to the difference in word meaning. We build a multigraph of all the words in the sentence that covers the header-dependent rules in Table 1."}, {"heading": "3.2 Head direction", "text": "Head direction is an important feature in the dependency syntax (Tesni\u00e8re, 1959). In fact, the inventory of UD functions includes a feature to distinguish the general ADP adposition label in pre- and post-positions. Instead of relying on this feature from the tree banks, which is not always available, we estimate the frequency of ADP-NOMINAL vs. NOMINALADP bigrams.3 We calculate this estimate directly from the input data at runtime to keep the system training-free. In addition, we require very few examples of convergence (10-15 sentences). If a language has more ADP-NOMINAL bigrams, we consider all its ADP prepositions (and thus depending on elements on the right side); otherwise, we consider them postpositions. For other function words, we have determined from the English dev data whether we have them strictly right or left-aligned, or whether they start in both directions."}, {"heading": "3.3 Decoding", "text": "It has two blocks, namely a first block (3-11), in which we assign the header of the content words according to their proximity, direction of attachment and dependency rules. The algorithm requires: 1. The PR-sorted list of content words C. 2. The group of function words F, sorting is irrel-evant because function assignments are interdependent. 3. A group H for the current possible heads and a group D for the dependencies that are assigned with each iteration. 2. The group of function words F, sorting is irrel-evant because function assignments are interdependent. 3. A group H for the current possible heads and a group D for the dependencies that we represent as head-dependent tuples (h, d). 4. A symbol root for the root node. 5. A function."}, {"heading": "4 Parser run example", "text": "This section illustrates the full sequence of the UDP for the sample sentence from the English test data: \"They also had a special connection to some extremists.\""}, {"heading": "4.1 PageRank", "text": "Table 2 returns the sentence, the POS of each word, the number of incoming edges for each word after we have created the graph with the head rules of paragraph 3.1, and the personalization vector for PR on that sentence. Note that all nodes have the same personalization weight, except the estimated main predicate, the verb \"had.\" Table 4 shows in detail the directed multigraph used for PR. For example, we can see that the four incoming edges for the verb \"had\" consist of the two nouns, plus the adverb \"also\" and the pronoun \"she.\" After executing PR, we get the following order for substantive words: C = < had, connection, extremists, special > Although the verb has four incoming edges and the nouns each have five, the personalization makes the verb the highest ranking word."}, {"heading": "4.2 Decoding", "text": "Once C is calculated, we can follow the algorithm in Fig. 1 to get a dependency parse. Table 3 shows a track of the algorithm with C = < had, connection, extremists, special > and F = {They, also a, to, some}. The first four iterations compute the header of the content words according to their PR, and the following iterations append the function words in F. Finally, Fig. 2 shows the resulting dependency tree. In the first block, full lines are assigned (Content Dependent), in the second block (Function Dependent) dotted lines. The edge labels indicate in which iteration the algorithm assigned each dependency. Note that the algorithm is deterministic for a certain input sequence at the POS. Any 10-token set with the POS labels shown in Table 2 would spread the same dependency.4"}, {"heading": "5 Experiments", "text": "This section describes the data, metrics and comparison systems used to evaluate the performance of UDP. We evaluate the test sections of the UD1.2 tree banks (Nivre et al., 2015) that contain word forms. If there is more than one tree bank per language, we use the tree bank with the anonymous language name (e.g. Finnish instead of Finnish FTB). We use standard unlabeled file values (UAS) and evaluate all sets of the canonical UD test sets."}, {"heading": "5.1 Baseline", "text": "We compare our UDP system to the performance of a rules-based baseline that uses the head rules in Table 5. The baseline identifies the first verb (or the first word of contents if there are no verbs) as the main predicate and assigns heads to all words according to the rules in Table 1. We have chosen the head rules to maximize the precision of the development sentence, and they do not provide full coverage. The system makes any word that is not covered by the rules (e.g. a word with a POS like X or SYM) depending on either its left or right neighbor, according to the estimated runtime parameters. We report on the best head direction and its score for each language in Table 5. This baseline finds the head of each token based on its closest possible head or on its immediate left or right neighbor, when there is no head rule available for the POS, meaning that this system does not necessarily produce well-shaped tress."}, {"heading": "5.2 Evaluation setup", "text": "Our system is based exclusively on POS tags. In order to estimate the quality deterioration of our system under non-golden POS scenarios, we evaluate UDP using two alternative scenarios: the first is the predicted POS scenario (UDPP), in which we mark the respective test set with TnT (Brants, 2000) that has been trained on the training set of each language; the second is a naive, scripted scenario with two POS tags (UDPN) and corresponds to a lower limit. We give each word either CONTENT or FUNCTION tag depending on the word frequency. The 100 most common words in the input bar section receive the FUNCTION day.Finally, we compare our Parser UDP with a monitored lingual system (MSD). It is a delicate transmission parser from multiple sources, which is referred to as multi-dir in the original paper by McDonald et al. (2011)."}, {"heading": "5.3 Results", "text": "Table 5 shows that UDP is a competitive system; because UDPG comes remarkably close to the monitored MSDG system, with an average difference of 6.4%. It is noteworthy that UDP even outperforms MSD in one language (Hindi). More interesting is that in the evaluation scenario with predicted POS, we observe that our system falls only slightly (2.2%) compared to MSD (2.7%). In the least robust rule-based setup, the error spread rate from POS to dependence would double, as either a mistagged head or dependent would violate the dependency rules. However, with an average POS accuracy of TnT of 94.1%, the error spread is 0.37, i.e. each POS error causes 0.37 additional dependency errors. In contrast, this error spread is 0.46, which is higher for MSD."}, {"heading": "6 Discussion", "text": "In this section we present another error analysis of the UDP parser. We examine the contribution to the overall results of the use of PageRank for the evaluation of words with content, the behaviour of the system in different language ranges and assess the robustness of UDP for texts from different ranges. 5Err. prop. = (E (ParseP) \u2212 E (ParseG)) / E (POSP), where E (x) = 1 \u2212 Accuracy (x)."}, {"heading": "6.1 PageRank contribution", "text": "In this section, we isolate the narrowing of both parts by comparing the performance of BL, UDP and UDPNoPR, a version of UDP in which we disable PR and classify content words according to their order of reading, i.e. the first word in the ranking is the first word to be read regardless of the script direction of the respective language. BL, the base line described in 5.1, already ensures that function words are leaf nodes, since they do not have dependent POS words in the header rules. However, the task of the decryption steps is mainly to ensure that the resulting structures are well-formed dependency contracts. If we measure the difference between UDPNoPR and BL, we see that UDPNoPR contributes 4 UAS points on average above the baseline. Nevertheless, the baseline is informed by oracle about the best branching of the language, a property that UDPNoPR points have in comparison to the first level of SDP."}, {"heading": "6.2 Breakdown by POS", "text": "UD is a constantly improving effort, and not all v1.2 Treebanks have the same level of formality compliance. Therefore, the interpretation of e.g. AUX-VERB or DET-PRON distinctions between Treebanks may vary. However, we ignore these differences in our analysis and consider all Treebanks to be equivalent. Root accuracy oscillates by an average of 69%, with Arabic and Tamil (26%) and Estonian (93%) as outliers. Given the PR personalization (Sec. 3.1), UDP has a strong bias for choosing the first verb as the main predicate. Without personalization, performance drops by an average of 2%. This difference is consistent even for verbal termination languages like Hindi, since the main verb of a simple clause will be its only verb, regardless of where it appears."}, {"heading": "6.3 Cross-domain consistency", "text": "In fact, it is as if most of us are able to keep to the rules that they had in the past. (...) It is as if they had been able to break the rules. \"(...)\" It is as if. \"(...)\" It is as if. \"(...)\" It is as if. \"(...)\" It is as if. \"(...)\" It is as if. \"(...)\" It is as if. \"(...)\" It is as if. \"(...)\" It is as if. \"(...)\" (...). \"(It is.\" (...). \"It is.\" (...). \"(It is.\" (...). \"(It is.\" (...). \"(It is.\" (...). \"(It is.\" (...). \"(It is.\" (...). \"(It is.\" (...). \"(It is.\" (...). \"(It is.\" (...). \"(It is.\" (It is. \").\" (It is. \"(...).\" (It is. \"(It is.\" (...). \"(It is.\" (It is. \").\" (It is. \"(It is.\"). (It is. \"(It is.\"). \"(It is.\" (It is. \"(It is.\"). (It is. (It is. \"). (it. (It is. (It is.\"). (it. (It is. \"). (It is. (it.\"). (it. (It is. \"). (It is. (It is.\"). (it. (it. \"). (It is. (It is.\"). (It is. \"). (it. (It is. (It is.\"). (It is. (it. (It is.). (it. \"). (It is.\"). (It is. (It is. (it. \"). (it. (It is.\"). (It is. \"). (It is. (it. (It is.\"). (It is. \"). (it."}, {"heading": "6.4 Comparison to full supervision", "text": "To assess how much information the simple principles in the UDP provide, we measure how many gold annotated sentences are needed to achieve its performance, i.e., from what size the tree bank provides enough information for training beyond the simple linguistic principles outlined in Section 3.For this comparison, we use a first-order non-projective turbo-parser (Martins et al., 2013) after the setup of Agic \u0301 et al. (2016). The supervised parsers need about 100 sentences to achieve comparable performance in the UDP, namely an average of 300 sentences and an average of 100 sentences, with Bulgarian (3k), Czech (1k) and German (1.5k) as outliers. The difference between mean and median shows a wide variety, while the UDP provides very consistent results, also in terms of POS and domain variation."}, {"heading": "7 Conclusion", "text": "We have introduced UDP, an unattended Universal Dependency Parser (UD) that also uses a personalized PageRank and a small set of head-dependent rules; the parser does not require training data and estimates the direction of adoption directly from the input; our results show that UDP is competitive in all but two UD languages, and even beats a multi-source delicalized parser (MSD) in Hindi. Considering how much of the entire dependency structure can be explained by this fair system, we propose UDP as an additional UD parsing baseline; the parser, the internal annotated test kits, and the domain data splits are made freely available."}, {"heading": "Acknowledgments", "text": "H\u00e9ctor Mart\u00ednez Alonso is funded by the French DGA project VerDi. Barbara Plank thanks the Centre for Information Technology of the University of Groningen for the HPC cluster. \u017deljko Agic \u0301 and Barbara Plank thank the Nvidia Corporation for supporting their research. Anders S\u00f8gaard is funded by the ERC Starting Grant LOWLANDS No. 313695.6https: / / github.com / hectormartinez / ud _ unsup _ parser."}], "references": [{"title": "The English noun phrase in its sentential aspect", "author": ["Steven Paul Abney"], "venue": "Ph.D. thesis,", "citeRegEx": "Abney.,? \\Q1987\\E", "shortCiteRegEx": "Abney.", "year": 1987}, {"title": "Multilingual Projection for Parsing Truly Low-Resource Languages", "author": ["Agi\u0107 et al.2016] \u017deljko Agi\u0107", "Anders Johannsen", "Barbara Plank", "H\u00e9ctor Alonso Mart\u00ednez", "Natalie Schluter", "Anders S\u00f8gaard"], "venue": null, "citeRegEx": "Agi\u0107 et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Agi\u0107 et al\\.", "year": 2016}, {"title": "If All You Have is a Bit of the Bible: Learning POS Taggers for Truly LowResource Languages", "author": ["Agi\u0107 et al.2015] \u017deljko Agi\u0107", "Dirk Hovy", "Anders S\u00f8gaard"], "venue": null, "citeRegEx": "Agi\u0107 et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Agi\u0107 et al\\.", "year": 2015}, {"title": "Linguistically na\u00cfve != language independent: Why NLP needs linguistic typology", "author": ["Emily M. Bender"], "venue": "In Proceedings of the EACL 2009 Workshop on the Interaction Between Linguistics and Computational Linguistics: Virtuous,", "citeRegEx": "Bender.,? \\Q2009\\E", "shortCiteRegEx": "Bender.", "year": 2009}, {"title": "TnT \u2013 A Statistical Part-of-Speech Tagger. In ANLP", "author": ["Thorsten Brants"], "venue": null, "citeRegEx": "Brants.,? \\Q2000\\E", "shortCiteRegEx": "Brants.", "year": 2000}, {"title": "Reprint of: The Anatomy of a Large-Scale Hypertextual Web Search Engine", "author": ["Brin", "Page2012] Sergey Brin", "Lawrence Page"], "venue": "Computer networks,", "citeRegEx": "Brin et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Brin et al\\.", "year": 2012}, {"title": "Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections", "author": ["Das", "Petrov2011] Dipanjan Das", "Slav Petrov"], "venue": null, "citeRegEx": "Das et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Das et al\\.", "year": 2011}, {"title": "Universal Stanford Dependencies: A Cross-Linguistic Typology", "author": ["Timothy Dozat", "Natalia Silveira", "Katri Haverinen", "Filip Ginter", "Joakim Nivre", "Christopher D Manning"], "venue": null, "citeRegEx": "Marneffe et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Marneffe et al\\.", "year": 2014}, {"title": "The Pascal Challenge on Grammar Induction", "author": ["Trevor Cohn", "Phil Blunsom", "Joao Gra\u00e7a"], "venue": "In Proceedings of the NAACL-HLT Workshop on the Induction of Linguistic Structure", "citeRegEx": "Gelling et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Gelling et al\\.", "year": 2012}, {"title": "Sparsity in Dependency Grammar Induction", "author": ["Kuzman Ganchev", "Joao Gra\u00e7a", "Fernando Pereira", "Ben Taskar"], "venue": null, "citeRegEx": "Gillenwater et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Gillenwater et al\\.", "year": 2010}, {"title": "Bootstrapping Parsers via Syntactic Projection Across Parallel Texts", "author": ["Hwa et al.2005] Rebecca Hwa", "Philip Resnik", "Amy Weinberg", "Clara Cabezas", "Okan Kolak"], "venue": "Natural Language Engineering,", "citeRegEx": "Hwa et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Hwa et al\\.", "year": 2005}, {"title": "Universal dependencies for Danish", "author": ["H\u00e9ctor Mart\u00ednez Alonso", "Barbara Plank"], "venue": "In International Workshop on Treebanks and Linguistic Theories", "citeRegEx": "Johannsen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Johannsen et al\\.", "year": 2015}, {"title": "Joint Part-of-Speech and Dependency Projection from Multiple Sources", "author": ["\u017deljko Agi\u0107", "Anders S\u00f8gaard"], "venue": null, "citeRegEx": "Johannsen et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Johannsen et al\\.", "year": 2016}, {"title": "Questionbank: Creating a Corpus of Parse-Annotated Questions", "author": ["Judge et al.2006] John Judge", "Aoife Cahill", "Josef Van Genabith"], "venue": null, "citeRegEx": "Judge et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Judge et al\\.", "year": 2006}, {"title": "Corpus-Based Induction of Syntactic Structure: Models of Dependency and Constituency", "author": ["Klein", "Manning2004] Dan Klein", "Christopher Manning"], "venue": null, "citeRegEx": "Klein et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Klein et al\\.", "year": 2004}, {"title": "Efficient Algorithms for Personalized PageRank. CoRR, abs/1512.04633", "author": ["Peter Lofgren"], "venue": null, "citeRegEx": "Lofgren.,? \\Q2015\\E", "shortCiteRegEx": "Lofgren.", "year": 2015}, {"title": "Unsupervised Dependency Parsing with Transferring Distribution via Parallel Guidance and Entropy Regularization", "author": ["Ma", "Xia2014] Xuezhe Ma", "Fei Xia"], "venue": null, "citeRegEx": "Ma et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Ma et al\\.", "year": 2014}, {"title": "Turning on the Turbo: Fast Third-Order Non-Projective Turbo Parsers", "author": ["Miguel Almeida", "Noah A. Smith"], "venue": null, "citeRegEx": "Martins et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Martins et al\\.", "year": 2013}, {"title": "Multi-Source Transfer of Delexicalized Dependency Parsers", "author": ["Slav Petrov", "Keith Hall"], "venue": null, "citeRegEx": "McDonald et al\\.,? \\Q2011\\E", "shortCiteRegEx": "McDonald et al\\.", "year": 2011}, {"title": "Using Universal Linguistic Knowledge to Guide Grammar Induction", "author": ["Naseem et al.2010] Tahira Naseem", "Harr Chen", "Regina Barzilay", "Mark Johnson"], "venue": null, "citeRegEx": "Naseem et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Naseem et al\\.", "year": 2010}, {"title": "Universal dependencies v1: A multilingual", "author": ["Nivre et al.2016] Joakim Nivre", "Marie-Catherine de Marneffe", "Filip Ginter", "Yoav Goldberg", "Jan Hajic", "Christopher D Manning", "Ryan McDonald", "Slav Petrov", "Sampo Pyysalo", "Natalia Silveira"], "venue": null, "citeRegEx": "Nivre et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Nivre et al\\.", "year": 2016}, {"title": "The PageRank Citation Ranking: Bringing Order to the Web", "author": ["Page et al.1999] Lawrence Page", "Sergey Brin", "Rajeev Motwani", "Terry Winograd"], "venue": null, "citeRegEx": "Page et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Page et al\\.", "year": 1999}, {"title": "Grammar-Driven versus DataDriven: Which Parsing System Is More Affected by Domain Shifts", "author": ["Plank", "van Noord2010] Barbara Plank", "Gertjan van Noord"], "venue": "In Proceedings of the 2010 Workshop on NLP and Linguistics: Finding the Common", "citeRegEx": "Plank et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Plank et al\\.", "year": 2010}, {"title": "Density-Driven Cross-Lingual Transfer of Dependency Parsers", "author": ["Rasooli", "Michael Collins"], "venue": null, "citeRegEx": "Rasooli et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Rasooli et al\\.", "year": 2015}, {"title": "From Baby Steps to Leapfrog: How Less is More in Unsupervised Dependency Parsing", "author": ["Hiyan Alshawi", "Daniel Jurafsky"], "venue": null, "citeRegEx": "Spitkovsky et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Spitkovsky et al\\.", "year": 2010}, {"title": "Viterbi Training Improves Unsupervised Dependency Parsing", "author": ["Hiyan Alshawi", "Daniel Jurafsky", "Christopher Manning"], "venue": "In CoNLL", "citeRegEx": "Spitkovsky et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Spitkovsky et al\\.", "year": 2010}, {"title": "Data Point Selection for Cross-Language Adaptation of Dependency Parsers", "author": ["Anders S\u00f8gaard"], "venue": "In NAACL", "citeRegEx": "S\u00f8gaard.,? \\Q2011\\E", "shortCiteRegEx": "S\u00f8gaard.", "year": 2011}, {"title": "Two Baselines for Unsupervised Dependency Parsing", "author": ["Anders S\u00f8gaard"], "venue": "In Proceedings of the NAACL-HLT Workshop on the Induction of Linguistic Structure", "citeRegEx": "S\u00f8gaard.,? \\Q2012\\E", "shortCiteRegEx": "S\u00f8gaard.", "year": 2012}, {"title": "Unsupervised dependency parsing without training", "author": ["Anders S\u00f8gaard"], "venue": "Natural Language Engineering,", "citeRegEx": "S\u00f8gaard.,? \\Q2012\\E", "shortCiteRegEx": "S\u00f8gaard.", "year": 2012}, {"title": "Rediscovering Annotation Projection for Cross-Lingual Parser Induction", "author": ["J\u00f6rg Tiedemann"], "venue": "In COLING", "citeRegEx": "Tiedemann.,? \\Q2014\\E", "shortCiteRegEx": "Tiedemann.", "year": 2014}, {"title": "Inducing Multilingual Text Analysis Tools via Robust Projection Across Aligned Corpora", "author": ["Grace Ngai", "Richard Wicentowski"], "venue": "In HLT", "citeRegEx": "Yarowsky et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Yarowsky et al\\.", "year": 2001}, {"title": "Cross-Language Parser Adaptation Between Related Languages", "author": ["Zeman", "Resnik2008] Daniel Zeman", "Philip Resnik"], "venue": "In IJCNLP", "citeRegEx": "Zeman et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Zeman et al\\.", "year": 2008}], "referenceMentions": [{"referenceID": 8, "context": "Grammar induction and unsupervised dependency parsing are active fields of research in natural language processing (Klein and Manning, 2004; Gelling et al., 2012).", "startOffset": 115, "endOffset": 162}, {"referenceID": 0, "context": "used a DP analysis (Abney, 1987).", "startOffset": 19, "endOffset": 32}, {"referenceID": 18, "context": "Even supervised transfer approaches (McDonald et al., 2011) suffer from target adaptation problems when facing word order differences.", "startOffset": 36, "endOffset": 59}, {"referenceID": 20, "context": "The Universal Dependencies (UD) project (Nivre et al., 2015; Nivre et al., 2016) offers a dependency formalism that aims at providing a consistent representation across languages, while enforcing a few hard constraints.", "startOffset": 40, "endOffset": 80}, {"referenceID": 11, "context": "Johannsen et al. (2015) for more details, we expect that such a formalism lends itself more naturally to a simple and linguistically sound rulebased approach to cross-lingual parsing.", "startOffset": 0, "endOffset": 24}, {"referenceID": 3, "context": "We ascribe our work to the viewpoints of Bender (2009) about the incorporation of linguistic knowledge in language-independent systems.", "startOffset": 41, "endOffset": 55}, {"referenceID": 18, "context": "Cross-lingual learning Recent years have seen exciting developments in cross-lingual linguistic structure prediction based on transfer or projection of POS and dependencies (Das and Petrov, 2011; McDonald et al., 2011).", "startOffset": 173, "endOffset": 218}, {"referenceID": 30, "context": "The first group of approaches deals with annotation projection (Yarowsky et al., 2001), whereby parallel corpora are used to transfer annotations between resource-rich source languages and lowresource target languages.", "startOffset": 63, "endOffset": 86}, {"referenceID": 10, "context": "Hwa et al. (2005) were the first to project syntactic dependencies, and Tiedemann et al.", "startOffset": 0, "endOffset": 18}, {"referenceID": 25, "context": "S\u00f8gaard (2011) and McDonald et al.", "startOffset": 0, "endOffset": 15}, {"referenceID": 18, "context": "S\u00f8gaard (2011) and McDonald et al. (2011) independently extended the approach by using multiple sources, requiring uniform POS and dependency representations (McDonald et al.", "startOffset": 19, "endOffset": 42}, {"referenceID": 1, "context": "Agi\u0107 et al. (2015; 2016) exposed some of these biases in their proposal for realistic cross-lingual tagging and parsing, as they emphasized the lack of perfect sentence- and word-splitting for truly low-resource languages. Further, Johannsen et al. (2016) introduced joint projection of POS and dependencies from multiple sources while sharing the outlook on bias removal in real-world multilingual processing.", "startOffset": 0, "endOffset": 256}, {"referenceID": 9, "context": "Our work builds on the line of research on rule-aided unsupervised dependency parsing by Gillenwater et al. (2010) and Naseem et al.", "startOffset": 89, "endOffset": 115}, {"referenceID": 9, "context": "Our work builds on the line of research on rule-aided unsupervised dependency parsing by Gillenwater et al. (2010) and Naseem et al. (2010), and also relates to S\u00f8gaard\u2019s (2012a; 2012b) work.", "startOffset": 89, "endOffset": 140}, {"referenceID": 15, "context": "i) the usage of PageRank personalization (Lofgren, 2015), and of ii) two-step decoding to treat content and func-", "startOffset": 41, "endOffset": 56}, {"referenceID": 21, "context": "Our system uses the PageRank (PR) algorithm (Page et al., 1999) to estimate the relevance of the content words of a sentence.", "startOffset": 44, "endOffset": 63}, {"referenceID": 21, "context": "Our system uses the PageRank (PR) algorithm (Page et al., 1999) to estimate the relevance of the content words of a sentence. PR uses a random walk to estimate which nodes in the graph are more likely to be visited often, and thus, it gives higher rank to nodes with more incoming edges, as well as to nodes connected to those. Using PR to score word relevance requires an effective graphbuilding strategy. We have experimented with the strategies by S\u00f8gaard (2012b), such as words being connected to adjacent words, but our system fares best strictly using the dependency rules in Table 1 to build the graph.", "startOffset": 45, "endOffset": 467}, {"referenceID": 4, "context": "The first is predicted POS (UDPP ), where we tag the respective test set with TnT (Brants, 2000) trained on each language\u2019s training set.", "startOffset": 82, "endOffset": 96}, {"referenceID": 17, "context": "For this baseline we train TurboParser (Martins et al., 2013) on a delexicalized training set of 20k sentences, sampled uniformly from the UD training data excluding the target language.", "startOffset": 39, "endOffset": 61}, {"referenceID": 17, "context": "It is a multi-source delexicalized transfer parser, referred to as multi-dir in the original paper by McDonald et al. (2011). For this baseline we train TurboParser (Martins et al.", "startOffset": 102, "endOffset": 125}, {"referenceID": 13, "context": "a magazine, and 75 sentences from the test split in QuestionBank (Judge et al., 2006).", "startOffset": 65, "endOffset": 85}, {"referenceID": 17, "context": "For this comparison we use a first-order nonprojective TurboParser (Martins et al., 2013) following the setup of Agi\u0107 et al.", "startOffset": 67, "endOffset": 89}, {"referenceID": 1, "context": ", 2013) following the setup of Agi\u0107 et al. (2016). The supervised parsers require around 100 sentences to reach UDP-comparable performance, namely a mean of 300 sentences and a median of 100 sentences, with Bulgarian (3k), Czech (1k), and Ger-", "startOffset": 31, "endOffset": 50}], "year": 2017, "abstractText": "We propose UDP, the first training-free parser for Universal Dependencies (UD). Our algorithm is based on PageRank and a small set of head attachment rules. It features two-step decoding to guarantee that function words are attached as leaf nodes. The parser requires no training, and it is competitive with a delexicalized transfer system. UDP offers a linguistically sound unsupervised alternative to cross-lingual parsing for UD, which can be used as a baseline for such systems. The parser has very few parameters and is distinctly robust to domain change across languages.", "creator": "LaTeX with hyperref package"}}}