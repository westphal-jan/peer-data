{"id": "1701.04271", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jan-2017", "title": "Fast Rates for Empirical Risk Minimization of Strict Saddle Problems", "abstract": "We derive bounds on the sample complexity of empirical risk minimization (ERM) in the context of minimizing non-convex risks that admit the strict saddle property. Recent progress in non-convex optimization has yielded efficient algorithms for minimizing such functions. Our results imply that these efficient algorithms are statistically stable and also generalize well. In particular, we derive fast rates which resemble the bounds that are often attained in the strongly convex setting. We specify our bounds to Principal Component Analysis and Independent Component Analysis. Our results and techniques may pave the way for statistical analyses of additional strict saddle problems.", "histories": [["v1", "Mon, 16 Jan 2017 12:55:23 GMT  (20kb)", "https://arxiv.org/abs/1701.04271v1", null], ["v2", "Thu, 16 Feb 2017 14:45:29 GMT  (21kb)", "http://arxiv.org/abs/1701.04271v2", null], ["v3", "Wed, 8 Mar 2017 19:47:45 GMT  (21kb)", "http://arxiv.org/abs/1701.04271v3", null], ["v4", "Sun, 4 Jun 2017 16:11:24 GMT  (22kb)", "http://arxiv.org/abs/1701.04271v4", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["alon gonen", "shai shalev-shwartz"], "accepted": false, "id": "1701.04271"}, "pdf": {"name": "1701.04271.pdf", "metadata": {"source": "CRF", "title": "Fast Rates for Empirical Risk Minimization of Strict Saddle Problems", "authors": ["Alon Gonen", "S. Shalev-Shwartz", "GONEN SHALEV-SHWARTZ"], "emails": ["ALONGNN@CS.HUJI.AC.IL", "SHAIS@CS.HUJI.AC.IL"], "sections": [{"heading": null, "text": "ar Xiv: 170 1.04 271v 4 [cs.L G] 4J un2 01 Minimizing non-convex risks that allow for strict saddle characteristics. Recent advances in non-convex optimization have produced efficient algorithms to minimize such functions. Our results suggest that these efficient algorithms are statistically stable and can also be generalized well. In particular, we derive fast rates similar to those often achieved in highly convex environments. We specify our limits for Principal Component Analysis and Independent Component Analysis. Our results and techniques can pave the way for statistical analysis of additional strict saddle problems."}, {"heading": "1. Introduction", "text": "Stability analysis is a central tool in statistical learning theory (Bousquet and Elisseeff (2002)). Broadly speaking, a learning algorithm is stable if a slight change in the input of the algorithm does not change much in its performance. It has been shown (Shalev-Shwartz et al. (2010); Mukherjee et al. (2006) that stability characterizes learning ability, and in particular stability corresponds to the error in the estimation of empirical risk minimization (2015). Stability analysis was carried out largely in the context of convex risk minimization. Specifically, some forms of strong convexity are often assumed (e.g. excessive concavity in Koren and Levy (2015); Gonen and Shalev-Shwartz (2016). The crux of the technique is to show that the minimum of two similarly strongly convective (and lipschitz / smooth) functions must be closed."}, {"heading": "2. Our contribution", "text": "We consider the problem of minimizing a risk of formF (w) = Ez \u0445 D (w, z)] (1) c (2017 A. Gonen & S. Shalev-Shwartz.where for each z-Z (\u00b7, z) a double, continuously differentiable loss function is defined, using the closed group W (w) = 1fzi (w)}, (2) The sample complexity of the ERM is the minimum size of a sample S (w) \u2212 minw (w).W F (w).2 We make the following assumptions about the loss functions: (A1) For each z, f (z) is."}, {"heading": "2.1. Applications", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1.1. PCA", "text": "In Section 6 we apply Theorem 1 to a stochastic formulation of the Principal Component Analysis (PKA). Our goal is to approximately restore the leading self-vector of the correlation matrix E [xx], where x is drawn according to some unknown distribution D with limited support. However, the standard measure of success is given by the non-convexe target min. (2016). Better limits can be reached under self-assumptions: There is a gap that exists G1.2 between the two leading inherent values of E [xx]. We may use the matrix amber inequality to show that i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i.i"}, {"heading": "2.1.2. ICA", "text": "In section 6, we apply theorem 2 to a stochastic formulation of Independent Component Analysis (ICA). Let A be an orthonormal linear transformation. Suppose that x is uniform to {\u00b1 1} d and let y = Ax. Our goal is to recover matrix A using observations y. As shown in Ge et al. (2015), this problem can be reduced to the decomposition of the tensor. Furthermore, the latter can be formulated as a strict saddle target of form (1), which can be efficiently minimized with the help of the SGD. Theorem 5 The sample complexity of ICA in the form formulated above is O (poly (d) + d 5 / 2gte). This result is significant in the regime in which d is small and we are interested in a high-precision solution."}, {"heading": "2.2. Our approach", "text": "Strict saddle targets are similar to strongly convex functions in the following sense: it is assumed that the restriction of the lens to a small neighborhood around a local minimum is strongly convex, but there are several key differences. First, unlike strongly convex functions, there may be several minima. More importantly, there are regions of the area where the function is not convex. Our analysis is essentially reduced to the strongly convex environment by excluding the other scenarios listed in Definition 8. Indeed, we set limits on how many examples are needed to ensure that a minimizer corresponding to a slight change in input must be in a strongly convex region around a local minimum w \u00b2. There is another subtlety that we need to address; there is no guarantee that the minimizer of (unmodified) empirical risk matches the corresponding value."}, {"heading": "3. Preliminaries", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1. Stability and generalization error", "text": "Definition 6 Let (z1,.., zn) and let (zn) be an ERM (see Equation (2)). For each i [n], let (z1,.., zn) and let (i) be an ERM (see Equation (2). 4 We say that the ERM algorithm is on average stable, with a stability rate of (z1,..., zn). For (z1,.., zn) and (i = 1, i). Here and subsequently, the expectation is taken both about the randomness of the algorithm and about the draw of (z1,..., zn). For (zn), we define the generalization error of the ERM by (n) = E [F (w) \u2212 gen (w). The next dilemma relates to the stability rate on the generalization (z1,.., zn) Dn, we define the generalization error of the ERM by (Kn)."}, {"heading": "3.2. Strict saddle functions", "text": "Due to their similarity to local extremes, saddle points are a fundamental challenge for optimization algorithms. Intuitively, the simpler saddle points are those for which the second-order inrormation indicates a clear downhill direction. The following definition based on Sun et al. (2015); Ge et al. (2015) captures this idea. Definition 8 A twice continuously differentiable function F: Rd \u2192 R is called (\u03b1, \u03b3, \u0442) -strict saddle if it does not have an incorrect local minimum, and for each point x-Rd at least one of the following conditions applies. Definition 8 A twice continuously differentiable function F: Rd \u2192 R is called (\u03b1, \u03b3, \u0442) -strict saddle if it does not have an incorrect local minimum, and for each point x-Rd applies: 1. Definition 8 A twice continuously differentiable function F: Rd \u00b2 4. We do not assume clarity. The definition applies to any minimum of 2."}, {"heading": "4. Stability Bounds for Strict Saddle Empirical Risks: Unconstrained Setting", "text": "In this section we consider the unrestricted setting (i.e., W = Rd). Our main result (Theorem 1) results from the following theory. (Theorem 1) Let us assume that the empirical risk F (1) nbsp; nbsp; (Definition 8) nbsp; (Definition 8) nbsp; (Definition 8) nbsp; (Definition 8) nbsp; (Definition 8) nbsp; (Definition 8) nbsp; (Definition 8) nbsp; (Definition 8) nbsp; (Definition 8) nbsp; (Definition 2) nbsp; (Definition 2) nbsp; (Definition 2) nbsp; (Definition 2) nbsp; (Definition 2) nbsp; (Definition 8) nbsp; (Definition 8) nbsp; (Definition 8) nbsp; (Definition 8) nbsp; (Definition 8) nbsp; (Definition 8) nbsp; (Definition 8) nbsp; (Definition 8) nbsp) nbsp; (Definition 2) nbsp; (Definition 2) nbsp; (Definition 2) nbsp; (Definition 2) nbsp; (Definition 2) nbsp; (Definition 2) nbsp; (Definition 2) nbsp; (Definition 2) nbsnbsp; (Definition 2) bsnbsnbsnbsnbsp; bsnbsp; bsnbsp; (Definition 2) bsnbsnbsp; (Definition 2) nbsnbsp; nbsp; (Definition nbsnbsnbsp) nbsp; (Definition nbsp; nbsp; (Definition nbsp) nbsp nbsp nbsp) nbsp; nbsp; (Definition nbsp nbsp nbsp) nbsp nbsp nbsp; nbsp bsp bsp"}, {"heading": "5. Stability Bounds for Strict Saddle Empirical Risks: Constrained Setting", "text": "We now consider the case in which W is described with equal limitations: W = {w-Rd: ci (w) = 0, i = 1,.., m}, where for each i ci (w) is continuously distinguishable twice."}, {"heading": "5.1. First and second-order conditions", "text": "In this part we remember basic facts about the conditions of the first and second order in the confined environment (see for example Borwein and Lewis (2010). We introduce the Lagrange multiplier for w-W if w is a critical point of L-W. A vector w-W fulfills the Linear Restriction of Independence (LICQ) if the theorem i-Z-W-W is linearly independent. Theorem 14 (KKT conditions) If w-W is a local minimum of F-W and LICQ holds w, then there is a Lagrange multiplier for w-W-W-W-W-W that can be found analytically. Theorem 14 (KKT conditions) If w-W is a local minimum of F-W and LICQ holds w-W, then there is a Lagrange multiplier for w-W-W-W-W-W conditions."}, {"heading": "5.2. Strict saddle property in the constrained setting", "text": "W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W in the restricted environment. Definition 16 A twice continuously differentiable function F: W \u2192 R with restrictions ci (w) and related Lagrange-L is referred to as (\u03b1, \u03b3, \u03c4) -stringer saddle, if it has no false local minimum, and for each point w: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W: W:"}, {"heading": "5.3. Analysis in the constrained setting", "text": "Throughout the section, we prove that theorem 1 also applies in the restricted environment. We assume that W is described with m equality constraints of the form ci (w) = 0 and that the LICQ applies to all w-W. \u2212 As in the restricted environment, we first specified the number of examples required to exclude the first two scenarios listed in Definition 16.Lemma 17. \u2212 As in the restricted environment, we then specified for all i-Z the number of i-Z examples required to exclude the first two scenarios. Since w-i minimizes the risk, we have 1 n-Z-Z 6 = i-Z (w), we have thatg-Z 6 = i-Z-Z 6 = i-Z-Z (w-Z) \u2212 m-Z (w-Z)."}, {"heading": "6. Application to PCA", "text": "Consider the following stochastic formulation of PCA = 1. Consider D as a distribution over Z Rd. We are interested in minimizing the intrinsic risk (w) = 12 Ez \u00b2 D over all possible unit vectors w Rd. For the sake of simplicity, we assume that Z is contained in the Euclidean unit sphere. It is well known that the minimum is the leading eigenvector of the positive definitive matrix E [zz]. As we will see, this problem becomes severe once we make the following standard assumption: (A4) There is a positive gap between the two leading eigenvalues of E [xx \u00b2]. In the face of a sample (z1,., zn) of Gn, let us assume A = 1n = 1 ziz \u00b2 i."}, {"heading": "7. Sample Complexity Bounds for Strict Saddle Expected Risks", "text": "In some cases, it may be easier to determine the strict saddle characteristic of the expected risk (Equation (1)). We now assume that F is a (\u03b1, \u03c4, \u03b3) -severe saddle. We look at the restricted saddle characteristic and designate Lagrangian from F to L. We add the following limit assumption: (A4) The sentence W is contained in {w: \u27e9 w = \u2264 B}. The proof for Theorem 2 is given in Appendix C. In the following, we give the main idea. Proof Theorem 2 We use the matrix-amber inequality together with the cover to show that points with a high probability do not form minima F. Similar arguments show that strict saddle points of F will not become minima of L. Then we can limit ourselves to strongly convex regions of F and show that any w with F (w) \u2212 minw \u00b2 W (w \u00b2) > no minima of F can be."}, {"heading": "8. Application to ICA Through Tensor Decomposition", "text": "It is only a matter of time before we find a solution. (...) We can present the tensor T with a multilinear form. (...) Given that the vectors u, z, w, z, w, w, w, i2, i3, i4Ti1, i4Vi2ai4. (...) We can equip the tensor T with a multilinear form. (...) The tensor T has an orthogonal decomposition when it can be written. (..., i4Ti1, i1vi2wi4The tensor T has an orthogonal decomposition. (...)"}, {"heading": "9. Related Work", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "9.1. Efficient ERM for Strict Saddle Functions", "text": "There is a growing interest in developing efficient algorithms to minimize strict saddle functions. We mention two key approaches: Intuitively, one can escape a saddle point by moving towards the eigenvector corresponding to the minimum eigenvalue, an intuition that has been specified by Nesterov and Polyak (Nesterov and Polyak (2006)). More surprisingly, it was shown in Ge et al. (2015) that a variant of the SGD also converges to a local minimum."}, {"heading": "9.2. Stability of SGD", "text": "Recently, Hardt et al. (2015) analyzed the stability of the SGD algorithm in both a convex and a non-convex environment. As mentioned above, SGD is an empirical risk minimizer in our environment. Our limitations regarding the stability rate of SGD in this environment improve beyond the (more general) limits of Hardt et al. (2015). In particular, our limitations imply that SGD can be trained for any length of time."}, {"heading": "9.3. Generalization Bounds using SGD", "text": "It is well known that generalization limits can be reached directly with SGD (Shalev-Shwartz and Ben-David (2014) [Chapter 14]). Therefore, the time complexity limit of Ge et al. (2015) results in identical sample complexity limits. However, their limits, which scale to 1 / 4, are inferior to our limits when high accuracy is desired."}, {"heading": "9.4. Fast rates for PCA", "text": "Generalization limits for stochastic PCA have been studied in Bousquet and Elisseeff (2002); Gonen et al. (2016). Both papers demonstrate an upper limit of 1 / \u221a n for generalization errors in general cases. The latter paper (which also takes into account the challenge of partial information) sets a suitable lower limit. The former paper also considers the case of a positive eigengap between the leading eigenvalues of E [xx] 7 and establishes fast rates similar to our limits by using local wheel-maker complexities. We believe that these techniques are much more involved than our techniques and do not have any geometric interpretation."}, {"heading": "Acknowledgments", "text": "We thank Kfir Levy for bringing Remark 3 to our attention. We also thank Nati Srebro for helpful discussions. 7. More generally, this work looks at the task of approaching the k-leading eigenvectors. It is not difficult to extend our results to this task as well."}, {"heading": "Appendix A. PCA Is Strict Saddle: Complete Proof", "text": "This section is dedicated to the proof of Theorem 21. Let's start with some basic calculations. It is obvious that both the domain and the destination are not convex. The following problem is immediate. Lemma 24 The restriction of F to the unit in Rd is 1-2 w-value and 1-smooth. It turns out that both the domain and the destination are not convex. Lagrangian is given by L-value (w, f) = F-value (w) = 2 w-value (w) and 1-smooth. It results that the Lagrangian is given by L-value (w, f-value)."}, {"heading": "Appendix B. ICA is Strict Saddle: Establishing Strong Convexity", "text": "We have now shown that Lemma 22 (+ 1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1 (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1 (1) ew (1 (1) ew (1) ew (1) ew (1) ew (1) ew (1) ew (1 (1) ew (1 (1) ew (1) ew (1) e (1 (1) e (1) e (1"}, {"heading": "Appendix C. Omitted Proofs", "text": "In this case, it is that we see ourselves as being able to show ourselves to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able."}], "references": [{"title": "Finding local minima for nonconvex optimization in linear time", "author": ["Naman Agarwal", "Zeyuan Allen-Zhu", "Brian Bullins", "Elad Hazan", "Tengyu Ma"], "venue": "arXiv preprint arXiv:1611.01146,", "citeRegEx": "Agarwal et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Agarwal et al\\.", "year": 2016}, {"title": "Homotopy method for tensor principal component analysis", "author": ["Anima Anandkumar", "Yuan Deng", "Rong Ge", "Hossein Mobah"], "venue": "arXiv preprint arXiv:1610.09322,", "citeRegEx": "Anandkumar et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Anandkumar et al\\.", "year": 2016}, {"title": "Tensor decompositions for learning latent variable models", "author": ["Animashree Anandkumar", "Rong Ge", "Daniel Hsu", "Sham M Kakade", "Matus Telgarsky"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Anandkumar et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Anandkumar et al\\.", "year": 2014}, {"title": "Global optimality of local search for low rank matrix recovery", "author": ["Srinadh Bhojanapalli", "Behnam Neyshabur", "Nathan Srebro"], "venue": "arXiv preprint arXiv:1605.07221,", "citeRegEx": "Bhojanapalli et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Bhojanapalli et al\\.", "year": 2016}, {"title": "Statistical properties of kernel principal component analysis", "author": ["Gilles Blanchard", "Olivier Bousquet", "Laurent Zwald"], "venue": "Machine Learning,", "citeRegEx": "Blanchard et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Blanchard et al\\.", "year": 2007}, {"title": "Convex analysis and nonlinear optimization: theory and examples", "author": ["Jonathan M Borwein", "Adrian S Lewis"], "venue": "Springer Science & Business Media,", "citeRegEx": "Borwein and Lewis.,? \\Q2010\\E", "shortCiteRegEx": "Borwein and Lewis.", "year": 2010}, {"title": "Stability and generalization", "author": ["Olivier Bousquet", "Andr\u00e9 Elisseeff"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Bousquet and Elisseeff.,? \\Q2002\\E", "shortCiteRegEx": "Bousquet and Elisseeff.", "year": 2002}, {"title": "Escaping from saddle points-online stochastic gradient descent for tensor decomposition", "author": ["Rong Ge", "Furong Huang", "Chi Jin", "Yang Yuan"], "venue": "In Proceedings of The 29th Conference on Learning Theory,", "citeRegEx": "Ge et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ge et al\\.", "year": 2015}, {"title": "Matrix completion has no spurious local minimum", "author": ["Rong Ge", "Jason D Lee", "Tengyu Ma"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Ge et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Ge et al\\.", "year": 2016}, {"title": "Average stability is invariant to data preconditioning. implications to exp-concave empirical risk minimization", "author": ["Alon Gonen", "Shai Shalev-Shwartz"], "venue": "arXiv preprint arXiv:1601.04011,", "citeRegEx": "Gonen and Shalev.Shwartz.,? \\Q2016\\E", "shortCiteRegEx": "Gonen and Shalev.Shwartz.", "year": 2016}, {"title": "Subspace learning with partial information", "author": ["Alon Gonen", "Dan Rosenbaum", "Yonina C Eldar", "Shai Shalev-Shwartz"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Gonen et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Gonen et al\\.", "year": 2016}, {"title": "Train faster, generalize better: Stability of stochastic gradient descent", "author": ["Moritz Hardt", "Benjamin Recht", "Yoram Singer"], "venue": "arXiv preprint arXiv:1509.01240,", "citeRegEx": "Hardt et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Hardt et al\\.", "year": 2015}, {"title": "Fast rates for exp-concave empirical risk minimization", "author": ["Tomer Koren", "Kfir Levy"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Koren and Levy.,? \\Q2015\\E", "shortCiteRegEx": "Koren and Levy.", "year": 2015}, {"title": "The power of normalization: Faster evasion of saddle points", "author": ["Kfir Y Levy"], "venue": "arXiv preprint arXiv:1611.04831,", "citeRegEx": "Levy.,? \\Q2016\\E", "shortCiteRegEx": "Levy.", "year": 2016}, {"title": "Learning theory: stability is sufficient for generalization and necessary and sufficient for consistency of empirical risk minimization", "author": ["Sayan Mukherjee", "Partha Niyogi", "Tomaso Poggio", "Ryan Rifkin"], "venue": "Advances in Computational Mathematics,", "citeRegEx": "Mukherjee et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Mukherjee et al\\.", "year": 2006}, {"title": "Cubic regularization of newton method and its global performance", "author": ["Yurii Nesterov", "Boris T Polyak"], "venue": "Mathematical Programming,", "citeRegEx": "Nesterov and Polyak.,? \\Q2006\\E", "shortCiteRegEx": "Nesterov and Polyak.", "year": 2006}, {"title": "Understanding Machine Learning: From Theory to Algorithms", "author": ["Shai Shalev-Shwartz", "Shai Ben-David"], "venue": null, "citeRegEx": "Shalev.Shwartz and Ben.David.,? \\Q2014\\E", "shortCiteRegEx": "Shalev.Shwartz and Ben.David.", "year": 2014}, {"title": "Learnability, stability and uniform convergence", "author": ["Shai Shalev-Shwartz", "Ohad Shamir", "Nathan Srebro", "Karthik Sridharan"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Shalev.Shwartz et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Shalev.Shwartz et al\\.", "year": 2010}, {"title": "When are nonconvex problems not scary", "author": ["Ju Sun", "Qing Qu", "John Wright"], "venue": "arXiv preprint arXiv:1510.06096,", "citeRegEx": "Sun et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Sun et al\\.", "year": 2015}, {"title": "An introduction to matrix concentration inequalities", "author": ["Joel A Tropp"], "venue": "arXiv preprint arXiv:1501.01571,", "citeRegEx": "Tropp.,? \\Q2015\\E", "shortCiteRegEx": "Tropp.", "year": 2015}], "referenceMentions": [{"referenceID": 3, "context": "Introduction Stability analysis is a central tool in statistical learning theory (Bousquet and Elisseeff (2002)).", "startOffset": 82, "endOffset": 112}, {"referenceID": 3, "context": "Introduction Stability analysis is a central tool in statistical learning theory (Bousquet and Elisseeff (2002)). Roughly speaking, a learning algorithm is stable if a slight change in the input of the algorithm does not change its output much. It was shown (Shalev-Shwartz et al. (2010); Mukherjee et al.", "startOffset": 82, "endOffset": 288}, {"referenceID": 3, "context": "Introduction Stability analysis is a central tool in statistical learning theory (Bousquet and Elisseeff (2002)). Roughly speaking, a learning algorithm is stable if a slight change in the input of the algorithm does not change its output much. It was shown (Shalev-Shwartz et al. (2010); Mukherjee et al. (2006)) that stability characterizes learnability, and in particular, stability is equivalent to the estimation error of empirical risk minimization.", "startOffset": 82, "endOffset": 313}, {"referenceID": 3, "context": "Introduction Stability analysis is a central tool in statistical learning theory (Bousquet and Elisseeff (2002)). Roughly speaking, a learning algorithm is stable if a slight change in the input of the algorithm does not change its output much. It was shown (Shalev-Shwartz et al. (2010); Mukherjee et al. (2006)) that stability characterizes learnability, and in particular, stability is equivalent to the estimation error of empirical risk minimization. Stability analysis has been mostly carried out in the context of convex risk minimization. More concretely, some form of strong convexity is often assumed (e.g., exp-concavity in Koren and Levy (2015); Gonen and Shalev-Shwartz (2016)).", "startOffset": 82, "endOffset": 657}, {"referenceID": 3, "context": "Introduction Stability analysis is a central tool in statistical learning theory (Bousquet and Elisseeff (2002)). Roughly speaking, a learning algorithm is stable if a slight change in the input of the algorithm does not change its output much. It was shown (Shalev-Shwartz et al. (2010); Mukherjee et al. (2006)) that stability characterizes learnability, and in particular, stability is equivalent to the estimation error of empirical risk minimization. Stability analysis has been mostly carried out in the context of convex risk minimization. More concretely, some form of strong convexity is often assumed (e.g., exp-concavity in Koren and Levy (2015); Gonen and Shalev-Shwartz (2016)).", "startOffset": 82, "endOffset": 690}, {"referenceID": 3, "context": "Introduction Stability analysis is a central tool in statistical learning theory (Bousquet and Elisseeff (2002)). Roughly speaking, a learning algorithm is stable if a slight change in the input of the algorithm does not change its output much. It was shown (Shalev-Shwartz et al. (2010); Mukherjee et al. (2006)) that stability characterizes learnability, and in particular, stability is equivalent to the estimation error of empirical risk minimization. Stability analysis has been mostly carried out in the context of convex risk minimization. More concretely, some form of strong convexity is often assumed (e.g., exp-concavity in Koren and Levy (2015); Gonen and Shalev-Shwartz (2016)). The crux of the technique is to show that minima of two similar strongly convex (and Lipschitz/smooth) functions must be close ((Shalev-Shwartz and Ben-David, 2014, Section 13.3)). In this paper we address the non-convex setting while restricting our attention to recently studied \u201cnice\u201d non-convex problems. Namely, we will consider non-convex functions which satisfy the strict saddle property (a.k.a. ridable or X -functions, see Sun et al. (2015)).", "startOffset": 82, "endOffset": 1143}, {"referenceID": 3, "context": "Introduction Stability analysis is a central tool in statistical learning theory (Bousquet and Elisseeff (2002)). Roughly speaking, a learning algorithm is stable if a slight change in the input of the algorithm does not change its output much. It was shown (Shalev-Shwartz et al. (2010); Mukherjee et al. (2006)) that stability characterizes learnability, and in particular, stability is equivalent to the estimation error of empirical risk minimization. Stability analysis has been mostly carried out in the context of convex risk minimization. More concretely, some form of strong convexity is often assumed (e.g., exp-concavity in Koren and Levy (2015); Gonen and Shalev-Shwartz (2016)). The crux of the technique is to show that minima of two similar strongly convex (and Lipschitz/smooth) functions must be close ((Shalev-Shwartz and Ben-David, 2014, Section 13.3)). In this paper we address the non-convex setting while restricting our attention to recently studied \u201cnice\u201d non-convex problems. Namely, we will consider non-convex functions which satisfy the strict saddle property (a.k.a. ridable or X -functions, see Sun et al. (2015)). Roughly speaking, a strict saddle function has no spurious local minimum and its saddle points are strict, in the sense that second-order information suffices for identifying a descent direction. We also assume that the restriction of the function to a certain neighborhood of each of its minima is strongly convex. Many important non-convex problems such as Principal Component Analysis (PCA), complete dictionary recovery (Sun et al. (2015)), tensor decomposition, ICA (Ge et al.", "startOffset": 82, "endOffset": 1588}, {"referenceID": 3, "context": "Introduction Stability analysis is a central tool in statistical learning theory (Bousquet and Elisseeff (2002)). Roughly speaking, a learning algorithm is stable if a slight change in the input of the algorithm does not change its output much. It was shown (Shalev-Shwartz et al. (2010); Mukherjee et al. (2006)) that stability characterizes learnability, and in particular, stability is equivalent to the estimation error of empirical risk minimization. Stability analysis has been mostly carried out in the context of convex risk minimization. More concretely, some form of strong convexity is often assumed (e.g., exp-concavity in Koren and Levy (2015); Gonen and Shalev-Shwartz (2016)). The crux of the technique is to show that minima of two similar strongly convex (and Lipschitz/smooth) functions must be close ((Shalev-Shwartz and Ben-David, 2014, Section 13.3)). In this paper we address the non-convex setting while restricting our attention to recently studied \u201cnice\u201d non-convex problems. Namely, we will consider non-convex functions which satisfy the strict saddle property (a.k.a. ridable or X -functions, see Sun et al. (2015)). Roughly speaking, a strict saddle function has no spurious local minimum and its saddle points are strict, in the sense that second-order information suffices for identifying a descent direction. We also assume that the restriction of the function to a certain neighborhood of each of its minima is strongly convex. Many important non-convex problems such as Principal Component Analysis (PCA), complete dictionary recovery (Sun et al. (2015)), tensor decomposition, ICA (Ge et al. (2015), Anandkumar et al.", "startOffset": 82, "endOffset": 1634}, {"referenceID": 1, "context": "(2015), Anandkumar et al. (2016)) and matrix completion (Ge et al.", "startOffset": 8, "endOffset": 33}, {"referenceID": 1, "context": "(2015), Anandkumar et al. (2016)) and matrix completion (Ge et al. (2016); Bhojanapalli et al.", "startOffset": 8, "endOffset": 74}, {"referenceID": 1, "context": "(2015), Anandkumar et al. (2016)) and matrix completion (Ge et al. (2016); Bhojanapalli et al. (2016)) are strict-saddle.", "startOffset": 8, "endOffset": 102}, {"referenceID": 4, "context": "It is known that the sample complexity of ERM for this problem is \u03a9(1/\u01eb2) (Blanchard et al. (2007); Gonen et al.", "startOffset": 75, "endOffset": 99}, {"referenceID": 4, "context": "It is known that the sample complexity of ERM for this problem is \u03a9(1/\u01eb2) (Blanchard et al. (2007); Gonen et al. (2016)).", "startOffset": 75, "endOffset": 120}, {"referenceID": 7, "context": "As was shown in Ge et al. (2015), this problem can be reduced to tensor decomposition.", "startOffset": 16, "endOffset": 33}, {"referenceID": 16, "context": "The following definition due to Sun et al. (2015); Ge et al.", "startOffset": 32, "endOffset": 50}, {"referenceID": 7, "context": "(2015); Ge et al. (2015) captures this idea.", "startOffset": 8, "endOffset": 25}, {"referenceID": 7, "context": "While Ge et al. (2015); Sun et al.", "startOffset": 6, "endOffset": 23}, {"referenceID": 7, "context": "While Ge et al. (2015); Sun et al. (2015) also require a lower bound on the magnitude of \u03bd (which appears in the last condition), it turns out that this quantity does not play any role in our analysis.", "startOffset": 6, "endOffset": 42}, {"referenceID": 5, "context": "First and second-order conditions In this part we recall basic facts on first and second-order conditions in the constrained setting (see for example Borwein and Lewis (2010)).", "startOffset": 150, "endOffset": 175}, {"referenceID": 7, "context": "While our last condition is slightly different from its counterparts in Ge et al. (2015); Sun et al.", "startOffset": 72, "endOffset": 89}, {"referenceID": 7, "context": "While our last condition is slightly different from its counterparts in Ge et al. (2015); Sun et al. (2015), we argue that it is often easier to establish the condition stated here (e.", "startOffset": 72, "endOffset": 108}, {"referenceID": 7, "context": "While our last condition is slightly different from its counterparts in Ge et al. (2015); Sun et al. (2015), we argue that it is often easier to establish the condition stated here (e.g., see Appendix B). 6. Actually, it seems that our condition is also required in the proof of Ge et al. (2015)[Lemma 34] (see equation 121).", "startOffset": 72, "endOffset": 296}, {"referenceID": 19, "context": "The following lemma, which follows from a simple application of the Matrix Bernstein inequality (Tropp (2015)[Section 1.", "startOffset": 97, "endOffset": 110}, {"referenceID": 1, "context": "A central problem in machine learning is to compute the tensor decomposition of a given tensor T (Anandkumar et al. (2014)).", "startOffset": 98, "endOffset": 123}, {"referenceID": 1, "context": "A central problem in machine learning is to compute the tensor decomposition of a given tensor T (Anandkumar et al. (2014)). While we have exponentially many equivalent solutions, the average of two solutions does not form a solution. Hence, any reasonable formulation of this problem must be non-convex. Luckily, as was shown in Ge et al. (2015), there exists a strict saddle formulation of this problem.", "startOffset": 98, "endOffset": 347}, {"referenceID": 7, "context": "Lemma 22 (Ge et al. (2015)) Suppose that T admits a Tensor decomposition as in (3).", "startOffset": 10, "endOffset": 27}, {"referenceID": 7, "context": "Although our definition of strict saddle functions in the constrained setting is slightly different from its counterpart in Ge et al. (2015), it is not hard to show that Lemma 22 still holds (see Appendix B).", "startOffset": 124, "endOffset": 141}, {"referenceID": 7, "context": "Although our definition of strict saddle functions in the constrained setting is slightly different from its counterpart in Ge et al. (2015), it is not hard to show that Lemma 22 still holds (see Appendix B). In applications, we often have access to T only through a stochastic oracle. Following Ge et al. (2015), we consider the following formulation of ICA.", "startOffset": 124, "endOffset": 313}, {"referenceID": 7, "context": "Furthermore, as was shown in Ge et al. (2015), one can efficiently compute a stochastic gradient and use SGD to optimize this objective.", "startOffset": 29, "endOffset": 46}, {"referenceID": 11, "context": "This intuition has been made precise by Nesterov and Polyak (Nesterov and Polyak (2006)).", "startOffset": 40, "endOffset": 88}, {"referenceID": 6, "context": "More surprisingly, in Ge et al. (2015) it was shown that a variant of SGD also converges to a local minimum.", "startOffset": 22, "endOffset": 39}, {"referenceID": 0, "context": "Recent improvements in terms of runtime are given in Agarwal et al. (2016); Levy (2016).", "startOffset": 53, "endOffset": 75}, {"referenceID": 0, "context": "Recent improvements in terms of runtime are given in Agarwal et al. (2016); Levy (2016).", "startOffset": 53, "endOffset": 88}, {"referenceID": 11, "context": "Stability of SGD Recently, Hardt et al. (2015) analyzed the stability of the SGD algorithm both in a convex and nonconvex setting.", "startOffset": 27, "endOffset": 47}, {"referenceID": 11, "context": "Stability of SGD Recently, Hardt et al. (2015) analyzed the stability of the SGD algorithm both in a convex and nonconvex setting. As we mentioned above, in our setting, SGD forms an empirical risk minimizer. Our bounds on the stability rate of SGD in this setting improve over the (more general) bounds of Hardt et al. (2015). In particular, our bounds imply that SGD can be trained for arbitrarily long time.", "startOffset": 27, "endOffset": 327}, {"referenceID": 14, "context": "Generalization Bounds using SGD It is known that one can obtain generalization bounds directly using SGD (Shalev-Shwartz and Ben-David (2014)[Chapter 14]).", "startOffset": 106, "endOffset": 142}, {"referenceID": 7, "context": "Hence, the time complexity bound of Ge et al. (2015) translates into identical sample complexity bound.", "startOffset": 36, "endOffset": 53}, {"referenceID": 6, "context": "Fast rates for PCA Generalization bounds for stochastic PCA have been studied in Bousquet and Elisseeff (2002); Gonen et al.", "startOffset": 81, "endOffset": 111}, {"referenceID": 6, "context": "Fast rates for PCA Generalization bounds for stochastic PCA have been studied in Bousquet and Elisseeff (2002); Gonen et al. (2016). Both works prove an upper bound of 1/ \u221a n on the generalization error in the general case.", "startOffset": 81, "endOffset": 132}], "year": 2017, "abstractText": "We derive bounds on the sample complexity of empirical risk minimization (ERM) in the context of minimizing non-convex risks that admit the strict saddle property. Recent progress in non-convex optimization has yielded efficient algorithms for minimizing such functions. Our results imply that these efficient algorithms are statistically stable and also generalize well. In particular, we derive fast rates which resemble the bounds that are often attained in the strongly convex setting. We specify our bounds to Principal Component Analysis and Independent Component Analysis. Our results and techniquesmay pave the way for statistical analyses of additional strict saddle problems.", "creator": "LaTeX with hyperref package"}}}