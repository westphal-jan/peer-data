{"id": "1701.04290", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jan-2017", "title": "Machine Translation Approaches and Survey for Indian Languages", "abstract": "In this study, we present an analysis regarding the performance of the state-of-art Phrase-based Statistical Machine Translation (SMT) on multiple Indian languages. We report baseline systems on several language pairs. The motivation of this study is to promote the development of SMT and linguistic resources for these language pairs, as the current state-of-the-art is quite bleak due to sparse data resources. The success of an SMT system is contingent on the availability of a large parallel corpus. Such data is necessary to reliably estimate translation probabilities. We report the performance of baseline systems translating from Indian languages (Bengali, Guajarati, Hindi, Malayalam, Punjabi, Tamil, Telugu and Urdu) into English with average 10% accurate results for all the language pairs.", "histories": [["v1", "Mon, 16 Jan 2017 13:55:01 GMT  (462kb)", "http://arxiv.org/abs/1701.04290v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["nadeem jadoon khan", "waqas anwar", "nadir durrani"], "accepted": false, "id": "1701.04290"}, "pdf": {"name": "1701.04290.pdf", "metadata": {"source": "CRF", "title": "Machine Translation Approaches and Survey for Indian Languages", "authors": ["Nadeem Jadoon Khan", "Waqas Anwar", "Nadir Durrani"], "emails": [], "sections": [{"heading": null, "text": "The motivation of this study is to promote the development of SMT and linguistic resources for these language pairs, since the current state of the art is rather bleak due to the scarcity of data resources. Success of an SMT system depends on the availability of a large parallel corpus. Such data is necessary to reliably estimate the translation probabilities. We report on the performance of base systems translating from Indian languages (Bengali, Guajarati, Hindi, Malayalam, Punjabi, Tamil, Telugu and Urdu) into English, with an average of 10% accuracy for all language pairs. Keywords: Statistical Machine Translation (SMT), Parallel Corpus, Natural Language Processing (NLP), Phrase-based Translation (Phrase-based Translation)"}, {"heading": "1. Introduction", "text": "This section gives a brief background on the rules-based approach to machine translation, and an overview of machine translation (MT) approaches is then discussed with the SMT approach used to perform this work. Indian languages we have chosen for this work are also briefly discussed. 1.1. Machine Translation Machine Translation (MT) can be defined as an automated system that analyzes text from a source language (Koehn, 2010), applies some calculation models to this input, and ideally produces equivalent text in a required target language (TL) without any kind of human intervention. It is one of the most interesting and difficult problems in the field of NLP (Koehn, 2010). The two challenges in machine translation are adequacy and fluctuation. The former is to develop a system that represents the ideas expressed in the source language in the target language, the latter being intended to represent these ideas grammatically."}, {"heading": "1.3. Related Work", "text": "Most of the focussed sentences, however, are still rules-based due to the unavailability of parallel data to build SMT systems for these languages. (Dasgupta et al., 2004) proposed an approach for English to Bangla MT that uses syntactical transmission of English sentences to Bangla with optimal time complexity. At the stage of generating the phrases, they used a dictionary to generate subject, object and also other entities such as person, number and target sentences. (Naskar et al., 2006) presented an example-based machine translation system for English to Bangla. Their work identifies the phrases in input through a flat analysis, retrieves the target formulations and finally combines the target sentences based on the use of some heuristic phrases. They also discussed some syntactical problems between English and Bangla."}, {"heading": "2. Evaluation", "text": "In this section we discuss various data sets used in our experiments, followed by discussions about training, tuning and testing of various model components, and finally about results and related discussions."}, {"heading": "2.1. Dataset", "text": "This year we will be able to put ourselves at the top, \"he said.\" We have to put ourselves at the top, \"he said.\" We have to put ourselves at the top, \"he said.\" We have to put ourselves at the top, \"he said.\" We have to put ourselves at the top, \"he said."}, {"heading": "2.2. Experimental Setup", "text": "For EMILLE Corpus we performed k-fold cross validation method for sampling of the corpus for all language pairs. Here k = 5 was selected by using 4 / 5 of the entire corpus as training and 1 / 5 as tuning and test set for experiments on all folds. Each fold includes over 800 segments for tuning and the same number of sentences for testing along with over 6500 segments for training in all source languages except Hindi. For Hindi we got over 9000 segments in total. Over 7000 selected for training and about 950 sentences for tuning and testing Hindi on the English translation system. All of these statistics can be clearly seen in Table 1. The first step in our work is sampling data. Next, tuning and test sets are for all folds. Finally, all datasets are converted into lowercase letters. This process is repeated for all language pairs by decoding scripts from Moses (Koehn et al 2007)."}, {"heading": "2.3. Results", "text": "Since the languages used in this paper are sparsely equipped, we achieved relatively low values for BLEU (Papineni, 2002), we achieved BLEU values with a mean of 0.12 and a standard deviation of 0.06 for the given test sets using the 5-fold cross-validation method. Table 4 presents the results of the experiments for all language pairs. The results are composed of the BLEU and NIST values, which are evaluated via the test corpora, and the UNK value (OOV words) for this test corpus for all selected language pairs. In the following subsections, evaluation results for all language pairs are presented for both the seen and the invisible, i.e. actual test data."}, {"heading": "Bangla-English:", "text": "For Bengali-English language pairs, we achieved decent BLEU values with an average of X = 0.118 and a standard deviation \u03c3 = 0.043 for invisible data and X = 0.364 for a standard deviation \u03c3 = 0.018 for seen data. For NIST, we reached X = 3.786 and a standard deviation \u03c3 = 0.522 for invisible data and X = 7.878 for a standard deviation \u03c3 = 0.328 for seen data. In counting the unknown words in the translation of our SMT system, we reached X = 610 and a standard deviation \u03c3 = 59 for invisible data and X = 130 for standard deviation \u03c3 = 8 for seen data. An example of translation output from the trained system is given below. The example is based on the source segment with its reference translation from the test corpus. A segmented output of translation output is also given."}, {"heading": "Example:", "text": "The indices in the output represent which source words produced this output, for example \"the department of\" was produced by a source phrase containing source words indexed between 0 and 5.S. A clear difference can be observed between the reference translation and the reference translation obtained from the developed system. Translation output is segmented into different phrases and the decoder retrieves the translation from the developed phrase table. The rearrangement model also yielded bad results for such a small amount of data. In the output, the first six words of the source are decoded in \"The department of the next three to\" the environment \"decoding the translation from the developed phrase table. The rearrangement model also yielded bad results for such a small amount of data."}, {"heading": "Gujarati-English:", "text": "For this pair, too, we obtained decent BLEU values compared to our small training corpus with an average of X = 0.119 and a standard deviation \u03c3 = 0.059 for invisible data and X = 0.403 and a standard deviation \u03c3 = 0.012 for seen data. For NIST, we obtained X = 3.674 and a standard deviation \u03c3 = 0.701 for invisible data and X = 8.136 and a standard deviation \u03c3 = 0.153 for seen data. In counting the unknown words in the translation of our SMT system, we achieved X = 678 and a standard deviation \u03c3 = 77 for invisible data and X = 117 and a standard deviation \u03c3 = 16 for seen data. An example of the translation output from the trained system is given below. The example consists of the source segment with its reference translation from the test corpus. A segmented output of the translation output is also given."}, {"heading": "Example:", "text": "In fact, it is that it is a matter of a way in which people are able to survive themselves, and in which people are able to put themselves in the position in which they live. (...) It is that people are able to survive themselves. (...) It is that people are able to survive themselves. (...) It is that people are able to survive themselves. (...) It is that people are able to survive themselves. (...) It is that people are able to survive themselves. (...) It is as if they are able to survive themselves. (...) It is as if they are able to survive themselves. (...) It is as if they are able to survive themselves. (...) It is as if they are able to survive themselves. (...) It is as if they are able to survive themselves. (...) It is as if they are able to survive themselves. (...) It is as if they are able to survive themselves. (...) It is as if they are able to survive themselves."}, {"heading": "Example:", "text": "\"We have a clear difference between the developed system and the developed system.\" \"The difference between the developed system and the developed system.\" \"The difference between the individual words.\" \"The difference between the words.\" \"The difference between the words.\" \"The difference between the words.\" \"The difference between the words.\" \"The difference between the words.\" \"The difference between the words.\" \"\" The difference between the words. \"\" \"The difference between the words.\" \"\" The difference between the words. \"\" \"\" The difference between the words. \"\" \"\".. \"\" \"\".. \"\" \"\" \"..\". \"\" \"\" \"..\" \"\". \"\" \"\" \"..\" \"\" \"\". \"\" \"\" \"The difference between the words.\". \"\" \"\" \"\".. \"\" \"\" \"\".. \"\". \"\" \"\" \"..\" \"\". \".\" \".\" \".\" \".\" \".\" \".\" \".\". \"\""}, {"heading": "Urdu-English", "text": "For this language pair, we got BLEU points with an average of X = 0.14 and a standard deviation of 0: 38 for invisible data and X = 0.371 and a standard deviation of 0: 27 for seen data. For NIST, we got X = 4.26 and a standard deviation of 0: 535 for invisible data and X = 7.54 and a standard deviation of 0: 53 for seen data with a very small amount of seen parallel corpus. If we count the unknown words in the translation of our SMT system, we get X = 550 and a standard deviation of 45 for invisible data and X = 117 and a standard deviation of 12 for seen data. The example below shows the different types of problems that have occurred in the translation of our system. Example: Source:.20 This deviation from the standard deviation results for invisible data and X = 45 for invisible data and X = 117 and a standard deviation from the standard deviation."}, {"heading": "3. Future Work & Conclusion", "text": "The developed SMT system takes the Indian language sentences as input and generates a corresponding closest translation into English. The translation of over 800 sentences was evaluated using automatic evaluation metric, i.e. BLEU evaluation. For all languages, an average BLEU score of 10% to 20% was reported. From these low BLEU scores, it can be concluded that the quality of the translation directly depends on the scope and quality of parallel language corpora. In this thesis, we have introduced all the less researched languages from India, which pair with English. Since all Indian languages used in this thesis have a rich morphology, leading to sparse estimates that cause poor translation quality, our results are therefore not as good as those for the European languages (Koehn et al., 2005), for which parallel and monolingual data are abundantly available. In this thesis, we are working with a phrase-based model for training and using MERT for the coordination of our system. We have carried out a series of experiments in parallel between the English language and the large difference between the two."}], "references": [], "referenceMentions": [], "year": 2017, "abstractText": "In this study, we present an analysis regarding the performance of the state-of-art Phrasebased Statistical Machine Translation (SMT) on multiple Indian languages. We report baseline systems on several language pairs. The motivation of this study is to promote the development of SMT and linguistic resources for these language pairs, as the current state-of-the-art is quite bleak due to sparse data resources. The success of an SMT system is contingent on the availability of a large parallel corpus. Such data is necessary to reliably estimate translation probabilities. We report the performance of baseline systems translating from Indian languages (Bengali, Guajarati, Hindi, Malayalam, Punjabi, Tamil, Telugu and Urdu) into English with average 10% accurate results for all the language pairs.", "creator": "PScript5.dll Version 5.2.2"}}}