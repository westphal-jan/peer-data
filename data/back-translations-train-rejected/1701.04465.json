{"id": "1701.04465", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jan-2017", "title": "The Incredible Shrinking Neural Network: New Perspectives on Learning Representations Through The Lens of Pruning", "abstract": "How much can pruning algorithms teach us about the fundamentals of learning representations in neural networks? A lot, it turns out. Neural network model compression has become a topic of great interest in recent years, and many different techniques have been proposed to address this problem. In general, this is motivated by the idea that smaller models typically lead to better generalization. At the same time, the decision of what to prune and when to prune necessarily forces us to confront our assumptions about how neural networks actually learn to represent patterns in data. In this work we set out to test several long-held hypotheses about neural network learning representations and numerical approaches to pruning. To accomplish this we first reviewed the historical literature and derived a novel algorithm to prune whole neurons (as opposed to the traditional method of pruning weights) from optimally trained networks using a second-order Taylor method. We then set about testing the performance of our algorithm and analyzing the quality of the decisions it made. As a baseline for comparison we used a first-order Taylor method based on the Skeletonization algorithm and an exhaustive brute-force serial pruning algorithm. Our proposed algorithm worked well compared to a first-order method, but not nearly as well as the brute-force method. Our error analysis led us to question the validity of many widely-held assumptions behind pruning algorithms in general and the trade-offs we often make in the interest of reducing computational complexity. We discovered that there is a straightforward way, however expensive, to serially prune 40-70% of the neurons in a trained network with minimal effect on the learning representation and without any re-training.", "histories": [["v1", "Mon, 16 Jan 2017 21:49:47 GMT  (2716kb,D)", "http://arxiv.org/abs/1701.04465v1", "30 pages, 36 figures, submission to ICLR 2017"]], "COMMENTS": "30 pages, 36 figures, submission to ICLR 2017", "reviews": [], "SUBJECTS": "cs.NE cs.LG", "authors": ["nikolas wolfe", "aditya sharma", "lukas drude", "bhiksha raj"], "accepted": false, "id": "1701.04465"}, "pdf": {"name": "1701.04465.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Nikolas Wolfe", "Aditya Sharma"], "emails": ["bhiksha}@cs.cmu.edu,", "adityasharma@cmu.edu", "drude@nt.upb.de"], "sections": [{"heading": "1 INTRODUCTION", "text": "In fact, it is in such a way that most of them are able to survive themselves without there being a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process, to a process in which there is a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process,"}, {"heading": "2 LITERATURE REVIEW", "text": "Circumcision algorithms, as extensively studied by Reed (1993), are a useful set of heuristics designed to identify and remove elements from a neural network that are either redundant or do not significantly contribute to the output of the network, motivated by the observed tendency of neural networks to adapt to the specifics of their training data, since too many trainable parameters or too few input patterns are available for generalization, as indicated by Chauvin (1990). Network architecture design and hyperparameter selection are inherently difficult tasks that are typically addressed with a few well-known rules of thumb, such as different weight initialization procedures, the choice of width and number of layers, different activation functions, learning rates, dynamics, etc. Some of these \"black arts\" seem inevitable; for problems that cannot be solved with linear threshold units alone, Baum & Haussler (1989) demonstrate that neural networks will not be able to determine the exact size of a set, if there is no way to do so."}, {"heading": "2.1 NON-PRUNING BASED GENERALIZATION & COMPRESSION TECHNIQUES", "text": "The generalization behavior of neural networks has been well studied, and apart from pruning algorithms, many heuristics have been used to avoid overmatching, including dropout (Srivastava et al. (2014)), Maxout (Goodfellow et al. (2013), and cascade correlation (Fahlman & Lebiere (1989)). While the cascade correlation specifically attempts to construct minimal networks, many techniques for improving network generalization do not explicitly attempt to eliminate the total number of parameters or the memory footprint of a trained network per sec. Of course, model compression often has advantages in terms of generalization power and portability of neural networks to operate in memory-constrained or embedded environments. Without explicitly removing parameters from the network, weight quantification allows a reduction in the number of bytes used to compress each weight parameter of neural networks, as proposed in 1991 and 1991 (Balzer)."}, {"heading": "2.2 PRUNING TECHNIQUES", "text": "This year it is so far that it only takes a few days to reach an agreement."}, {"heading": "3 PRUNING NEURONS TO SHRINK NEURAL NETWORKS", "text": "As discussed in Section 1, our goal is to use the highly unequal distribution of learning representation in upstream neural networks to eliminate redundant neurons without focusing on individual weight sizes, and with this approach, we can remove all weights (incoming and outgoing) associated with a non-contributing neuron at once. We would like to note at this point that in an ideal scenario, based on Mozer & Smolensky's Neuron Interdependence Theory (1989a), one would evaluate all possible combinations of neurons to find the optimal subset of neurons to be preserved, which is mathematically unacceptable, and so we will focus only on removing one neuron each and exploring more \"greedy\" algorithms in order to do so in a more efficient manner. The general approach used to create an optimally trained neural network consists of ranking all."}, {"heading": "3.1 BRUTE FORCE REMOVAL APPROACH", "text": "This is perhaps the most naive, but also the most accurate method of cutting the network. It is also the slowest and therefore possibly the most useless method in large-scale neural networks with thousands of neurons. This method explicitly evaluates every neuron in the network. The idea is to manually check the effect of each individual neuron on the output by executing a forward propagation to the specified K times (where K is the total number of neurons in the network), turning off exactly one neuron each time (keeping all other neurons active) and recording the error change. Switching off a neuron can be achieved simply by setting its output to 0, which causes all outgoing weights of that neuron to be switched off. This error change is then used to generate the ranking."}, {"heading": "3.2 TAYLOR SERIES REPRESENTATION OF ERROR", "text": "Let us consider the aggregate error from the optimally formed neural network for each given validation dataset of E. E can be considered a function of O, where O is the output of any generic neuron in the network. By the output of a particular neuron (say, Ok) using the 2nd order Taylor series, this error can be called \"E\" (O) \u2248 E (Ok) + (O \u2212 Ok) \u00b7 \"E\" (O \u2212 Ok) \u00b7 \"Ok\" (O \u2212 Ok) 2 \u00b7 \"2E\" (Ok). When a neuron is truncated, its output O is replaced by \"O\" (O \u2212 Ok) in equation 1, indicating that the error is perfectly approximated by equation 1 at Ok. Thus: \"Ek = E\" (0) \u2212 E \"(Ok) =\" E \"(Ok) =\" E \"(Ok) (E\" (Ok) = \"E\" (Ok)."}, {"heading": "3.2.1 LINEAR APPROXIMATION APPROACH", "text": "We can use Equation 2 to obtain the linear error approximation of the error change due to the deactivation of the kth neuron, and represent it as follows: \u2206 E1k = \u2212 Ok \u00b7 \u2202 E \u2202 O minute Ok (3) The above derived term is the first-order gradient representing the error change in relation to the output of a given neuron. This term can be collected during the reverse propagation. As we will see in this section, linear approximations are not reliable indicators of error changes, but they provide an interesting basis for comparison with the other methods discussed in this paper."}, {"heading": "3.2.2 QUADRATIC APPROXIMATION APPROACH", "text": "As described above, we can use Equation 2 to obtain the quadratic error approximation of the error change due to the shutdown of the kth neuron and represent it as follows: \u2206 E2k = \u2212 Ok \u00b7 \u2202 E \u2202 O Minute error approximation due to the shutdown of the kth neuron. This additional second-order gradient term that appears above represents the quadratic error change in relation to the output of a given neuron. This expression can be generated by backpropagation using second-order derivatives. Collecting these quadratic gradients requires some non-trivial mathematics, the entire step-by-step derivation procedure of which is provided as an appendix in the supplementary material."}, {"heading": "3.3 PROPOSED PRUNING ALGORITHM", "text": "Figure 1 shows a random error function plotted against the output of a particular neuron. Note that this number is illustrative only, and the error function is minimized to a certain value of neuron output, as shown in the figure. Essentially, the process of forming a neural network is the process of determining these minimizing output values for all neurons in the network. Circumcision of this particular neuron (meaning that it produces zero output) results in a change in the total error of the first order. This error change is represented by the distance between the initial minimal error (represented by the dashed line) and the uppermost red arrow. This neuron is clearly a poor candidate for distance, as the distance will result in an enormous error. The straight red line in the figure represents the approximation of the first order of error using the Taylor series, as described above, while the parabola represents an approximation of the second order."}, {"heading": "3.3.1 ALGORITHM I: SINGLE OVERALL RANKING", "text": "The complete algorithm is presented in algorithm 1. The idea here is to create a single ranking based on the values of \u2206 Ek. This involves a single run of second-order reverse propagation (without weight updates) to capture the gradients for each neuron. The neurons from this ranking (with the lowest values of \u0445 Ek) are then truncated according to the specified stop criterion. We note here that this algorithm is intentionally naive and is only used for comparation.Data: optimally trained network, training set Result: A truncated network initializes and defines stop criterion; performs forward propagation via the training set; performs second-order reverse propagation without updating weights and collects linear and square gradients; classifies the remaining neurons based on \u0445 Ek; while the stop criterion is not met; end algorithm 1: Overall"}, {"heading": "3.3.2 ALGORITHM II: ITERATIVE RE-RANKING", "text": "In this greedy variant of the algorithm (algorithm 2), the remaining network goes through a single forward and backward path of second-order reverse propagation after each neuron removal (without weight updates) and the ranking is reconstructed, so each distance includes a new pass through the network. This method is more expensive in arithmetic terms, but takes into account the dependencies that the neurons may have with each other, which would result in a change in the error contribution each time a dependent neuron is removed. Data: optimally trained network, training set Result: A truncated network initializes and defines stop criterion; while the stop criterion is not met, the doperative forward propagation via the training set is not met; performs second-order backward propagation without updating weights and collects linear and square gradients; arranges the remaining neurons based on the ranking; removes the worst neuron based on the ranking algorithm; Iteration terminates;"}, {"heading": "4 EXPERIMENTAL RESULTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 EXAMPLE REGRESSION PROBLEM", "text": "This year, it has come to the point that it has never come as far as it has this year."}, {"heading": "4.2 RESULTS ON MNIST DATASET", "text": "For all the results presented in this section, the MNIST database of handwritten digits from LeCun & Cortes (2010) was used. It should be noted that due to the time taken by the brute force algorithm, we preferred to use a subset of 5000 images from the MNIST database, in which we normalized the pixel values between 0 and 1.0 and compressed the image size to 20x20 images, rather than 28x28, so that the accuracy of the initial test given here appears higher than that of LeCun et al. We do not believe that this will affect the interpretation of the presented results, as the basic learning problem does not change with a larger dataset or larger input dimension."}, {"heading": "4.3 PRUNING A 1-LAYER NETWORK", "text": "The network architecture in this case consisted of 1 layer, 100 neurons, 10 outputs, logistic sigmoid activations and a starting accuracy of 0.998."}, {"heading": "4.3.1 SINGLE OVERALL RANKING ALGORITHM", "text": "First, we present the results for a single-layer neural network in Figure 3 using the Single Overall Algorithm (Algorithm 1) as proposed in Section 3. (We reiterate that this algorithm is intentionally naive and used only for comparison, and one should expect its performance to be poor.) After training, each neuron is assigned its permanent ranking based on the three criteria discussed above: a ranking of ground truth and two approximations of this ranking based on first and second order Taylor estimates of changes in network output errors resulting from the removal of each neuron.An interesting observation is that with just one layer, no criteria for the ranking of neurons in the network (Brute Force or the two Taylor variants) are superior using algorithm 1, suggesting that the Taylor methods 1st and 2nd order are indeed reasonable approximations of the brute force method under certain conditions."}, {"heading": "4.3.2 ITERATIVE RE-RANKING ALGORITHM", "text": "In Figure 4, we present our results using algorithm 2 (The iterative re-ranking algorithm), in which all remaining neurons are reordered after each successive neuron is switched off. We calculate the same brute force rankings and Taylor series approximations of error deltas over the remaining active neurons in the network after each circumcision decision, taking into account the effects of interrupting interactions between neurons. Here, there are two important observations: Using the criteria of the brute force ranking, almost 60% of the neurons in the network can be removed without major loss of power; the other noteworthy observation is that the approximation of the Taylor series 2nd order of error consistently performs better in most situations than its 1st order version, although Figure 21 is a good counter example."}, {"heading": "4.3.3 VISUALIZATION OF ERROR SURFACE & PRUNING DECISIONS", "text": "As explained in Section 3, these graphs represent a visualization of the error interface of network output with respect to the neurons selected for removal, each of the three ranking criteria representing intervals of 10 neurons. In each graph, the error interface of network output is represented in logspace (left) and real space (right) with respect to each neuron selected for removal. We create these graphs during circumcision by selecting a neuron to disable it, and then multiply its output by a scalar amplification value adjusted from 0.0 to 10.0 with a step size of 0.001. If the value is \u03b1 > 1.0, this represents the undisturbed neuron output learned during training. Between 0.0 and 1.0, we represent the literal effect of disabling the neuron (\u03b1 = 0), and if \u03b1 > 1.0 we simulate an increase in the value of the network, i.e., we simulate the impact of the network in its sparing."}, {"heading": "4.3.4 VISUALIZATION OF BRUTE FORCE PRUNING DECISIONS", "text": "In Figure?? we see how deep and flat most of the curves are. It is not until the neuron is 90 years away that we see a higher curve with a more convex shape (clearly a more sensitive, more influential part of the network)."}, {"heading": "4.3.5 VISUALIZATION OF 1ST ORDER APPROXIMATION PRUNING DECISIONS", "text": "Figure 6 shows that most choices have flat or negatively inclined curves, suggesting that the first-order approximation seems to be quite good, but the study of raw force choices shows that they could be better."}, {"heading": "4.3.6 VISUALIZATION OF 2ND ORDER APPROXIMATION PRUNING DECISIONS", "text": "The method in Figure 7 is similar to the methods of the brute force method, but is clearly not as good (they are more widespread). Note the difference in convexity between the method choice 2nd and 1st order. It is clear that the 1st order method fits a line and the 2nd order method fits a parabola in its approximation."}, {"heading": "4.4 PRUNING A 2-LAYER NETWORK", "text": "The network architecture in this case consisted of 2 layers, 50 neurons per layer, 10 outputs, logistic sigmoid activations and a start test accuracy of 1,000."}, {"heading": "4.4.1 SINGLE OVERALL RANKING ALGORITHM", "text": "Figure 8 shows the cut-off results for algorithm 1 on a 2-layer network. The ranking method is identical to the one used to create Figure 3. (Again, we note that this algorithm is intentionally naive and is only used for comparison. It is to be expected that its performance is poor.) Unsurprisingly, a 2-layer network is more difficult to prune, since a single overall ranking will never capture the interdependencies between neurons in different layers. It makes sense that this is worse than performance on the 1-layer network, even though this method is already known to be bad, and we would probably never use it in practice."}, {"heading": "4.4.2 ITERATIVE RE-RANKING ALGORITHM", "text": "Figure 9 shows the results of using Algorithm 2 on a 2-layer network. We calculate the same brute force rankings and Taylor series approximations of error deltas over the remaining active neurons in the network after each circumcision decision used to generate Figure 4. Again, this is to take into account the effects of interruption of neuron interactions. It is clear that it is becoming more difficult to remove neurons 1-to-1 with a deeper network (which makes sense because the neurons in a deeper network have more interdependencies), but overall we see better 2nd order performance compared to 1st order, except for the first 20% of the neurons (but this does not seem to make much difference for classification accuracy.) Perhaps a more important observation here is that even with a more complex network it is possible to remove up to 40% of the neurons without major power losses, which is clearly illustrated by the brute force curve."}, {"heading": "4.4.3 VISUALIZATION OF ERROR SURFACE & PRUNING DECISIONS", "text": "As can be seen in the case of a single-layer network, these graphs are a visualization of the error interface of the network output in relation to the neurons selected for removal, with each algorithm represented in intervals of 10 neurons."}, {"heading": "4.4.4 VISUALIZATION OF BRUTE FORCE PRUNING DECISIONS", "text": "In Figure 10 it is clear why these neurons were selected, their diagrams clearly show little change when neurons are removed, are mostly near the ground and show a convex behavior of the fault surface, which suggests rationalization of the use of 2nd order methods for estimating error differences when switching off."}, {"heading": "4.4.5 VISUALIZATION OF 1ST ORDER APPROXIMATION PRUNING DECISIONS", "text": "Drawing a flat line at the interface of the individual neurons with the red vertical line (no change in amplification) shows that the first derived method for estimating the error change in these cases is indeed correct, but still ultimately leads to poor decisions."}, {"heading": "4.4.6 VISUALIZATION OF 2ND ORDER APPROXIMATION PRUNING DECISIONS", "text": "These neurons are clearly not obvious bad candidates for removal (errors do not change much between 1.0 and zero intersection on the left), but could be better (as described above in the discussion of the brute force criterion)."}, {"heading": "4.5 INVESTIGATION OF PRUNING PERFORMANCE WITH IMPERFECT STARTING CONDITIONS", "text": "In our experiments so far, we have tacitly assumed that we start with a network that has learned an \"optimal\" representation of the training target, i.e. that it has been trained to accept its performance on the test set. Here, we explore what happens when we work with a sub-optimal start network. If the assumptions of this work regarding the nature of learning neural networks are correct, we expect that two processes are essentially at work during the back-propagation training. First, we expect that the neurons directly involved in basic learning representation (even if they are redundant) work together to reduce errors on the training data. Second, we expect that neurons not directly participating in learning representation cancel out the negative impact of each other. Furthermore, we expect that these two groups are essentially different, evidenced by the fact that multiple neurons can often be removed as a group with little or no impact on network output."}, {"heading": "4.5.1 MNIST SINGLE DIGIT CLASSIFICATION: DIGIT 0", "text": "Figure 13 shows the degradation in the square error after removing neurons from a network trained to distinguish the digit 0. What we observe is that the methods of the first and second order both fail in different ways, although clearly the second order makes better decisions overall. The method of the first order explodes spectacularly in the first few iterations. Brute Force's method, in stark contrast, actually improves in the first few iterations and remains essentially flat to about the 60% mark at which it begins to gradually rise and hit the other curves. The behavior of the Brute Force method here shows that the network essentially works to neutralize the effect of some bad neurons when the training convergence criteria were met, i.e. the network was no longer able to make progress on the training set. After removing these neurons during the cut, the output improved. We can investigate this by looking at the error interface in relation to the neurons selected for each method from the distance."}, {"heading": "4.5.2 MNIST SINGLE DIGIT CLASSIFICATION: DIGIT 1", "text": "If we look at Figure 17, we see a much clearer example of the previous phenomenon where the brute force method further improves the performance of the network after removing 80% of the neurons in the network. First and second order methods fail early and proceed in seizures and starts (clearly indicating contiguous groups of noise-suppressing neurons) and never fully recover. It should be noted that it would be impossible to see curves of this kind if neural networks were to distribute learning representation evenly or evenly across their hidden units. One of the most striking things about the blue curve in Figure 17 is the fact that the network never falls below its initial error until it exceeds the 80% mark, suggesting that only 20% of the neurons in that network are actually indispensable for learning the training target. In this sense, we can only wonder how much of the training time in Figure 17 was spent to get the error out of the remaining 80% of the network decisions we can make by winding the respective 20% in Figure 18."}, {"heading": "4.5.3 MNIST SINGLE DIGIT CLASSIFICATION: DIGIT 2", "text": "Figure 21 is an interesting case because it shakes our confidence in the reliability of the second-order method for good circumcision decisions, and also shows the phenomenon by how much the error can improve when the correct neurons are removed after training. In this case, although overall still a poor performance, the first-order method far outperforms the second-order method. Figure 22 shows us a clear example of how the first circumcision decision can be removed by having a negative pruning tendency, and improves the result. Obviously, there is not much scope for a deterioration given our starting point with a suboptimal network, and we see that the final sum of square errors is not much higher than the starting point, which keeps the yield relatively flat. However, there is not much scope for a deterioration given our starting point with a suboptimal network, and we see that the final sum of square errors is not much higher than the starting point. At the same time, we can see the contrast between the optimal performance and the poor pruning systems, although we are still able to make the decision in most of the circumcision systems."}, {"heading": "4.5.4 ASIDE: IMPLICATIONS OF THIS EXPERIMENT", "text": "From the three examples above, we see that in any case, starting from a suboptimal network, a method of brute force removal continuously improves the performance of the first few circumcision iterations, and the sum of square errors only deteriorates beyond the starting point when about 60-80% of the neurons are removed. This is only possible if we have an essentially strict dichotomy between the roles of different neurons during the training. If the network requires only 20-40% of the neurons it started with, the training process is essentially dominated by the task of eliminating the residual noise of redundant neurons. Furthermore, the network can get stuck in training with redundant units and distort the end result. This is strong evidence for our thesis that learning representation is neither evenly or evenly distributed, and that most neurons that are not directly involved in learning representation can be removed without retraining."}, {"heading": "4.6 EXPERIMENTS ON TOY DATASETS", "text": "As can be seen from the experiments at MNIST, the 2nd order approximation criterion is consistently better than 1st order, but its performance is not nearly as good as the ranking based on brute force, especially beyond the first layer. Interestingly, from some other experiments with toy data sets (which predict whether a certain point within a certain form would be on the Cartesian level), the performance of 2nd order method was exceptionally good and produced results very close to the method of brute force."}, {"heading": "5 CONCLUSIONS & FUTURE WORK", "text": "This year, it has reached the stage where it will be able to take the lead."}], "references": [{"title": "Weight quantization in boltzmann machines", "author": ["Wolfgang Balzer", "Masanobu Takahashi", "Jun Ohta", "Kazuo Kyuma"], "venue": "Neural Networks,", "citeRegEx": "Balzer et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Balzer et al\\.", "year": 1991}, {"title": "What size net gives valid generalization", "author": ["Eric B Baum", "David Haussler"], "venue": "Neural computation,", "citeRegEx": "Baum and Haussler.,? \\Q1989\\E", "shortCiteRegEx": "Baum and Haussler.", "year": 1989}, {"title": "Generalization performance of overtrained back-propagation networks", "author": ["Yves Chauvin"], "venue": "In Neural Networks,", "citeRegEx": "Chauvin.,? \\Q1990\\E", "shortCiteRegEx": "Chauvin.", "year": 1990}, {"title": "The effects of quantization on multilayer neural networks", "author": ["Gunhan Dundar", "Kenneth Rose"], "venue": "IEEE transactions on neural networks/a publication of the IEEE Neural Networks Council,", "citeRegEx": "Dundar and Rose.,? \\Q1994\\E", "shortCiteRegEx": "Dundar and Rose.", "year": 1994}, {"title": "The cascade-correlation learning architecture", "author": ["Scott E Fahlman", "Christian Lebiere"], "venue": null, "citeRegEx": "Fahlman and Lebiere.,? \\Q1989\\E", "shortCiteRegEx": "Fahlman and Lebiere.", "year": 1989}, {"title": "Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding", "author": ["Song Han", "Huizi Mao", "William J Dally"], "venue": "arXiv preprint arXiv:1510.00149v5,", "citeRegEx": "Han et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Han et al\\.", "year": 2016}, {"title": "Second order derivatives for network pruning: Optimal brain surgeon", "author": ["Babak Hassibi", "David G Stork"], "venue": null, "citeRegEx": "Hassibi and Stork.,? \\Q1993\\E", "shortCiteRegEx": "Hassibi and Stork.", "year": 1993}, {"title": "Learning with limited numerical precision using the cascade-correlation algorithm", "author": ["Markus Hoehfeld", "Scott E Fahlman"], "venue": "IEEE Transactions on Neural Networks,", "citeRegEx": "Hoehfeld and Fahlman.,? \\Q1992\\E", "shortCiteRegEx": "Hoehfeld and Fahlman.", "year": 1992}, {"title": "Optimal brain damage", "author": ["Yann LeCun", "John S Denker", "Sara A Solla", "Richard E Howard", "Lawrence D Jackel"], "venue": "In NIPs,", "citeRegEx": "LeCun et al\\.,? \\Q1989\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 1989}, {"title": "Skeletonization: A technique for trimming the fat from a network via relevance assessment", "author": ["Michael C Mozer", "Paul Smolensky"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Mozer and Smolensky.,? \\Q1989\\E", "shortCiteRegEx": "Mozer and Smolensky.", "year": 1989}, {"title": "Using relevance to reduce network size automatically", "author": ["Michael C Mozer", "Paul Smolensky"], "venue": "Connection Science,", "citeRegEx": "Mozer and Smolensky.,? \\Q1989\\E", "shortCiteRegEx": "Mozer and Smolensky.", "year": 1989}, {"title": "Reducing communication overhead in distributed learning by an order of magnitude (almost)", "author": ["Anders \u00d8land", "Bhiksha Raj"], "venue": "In IEEE International Conference on Acoustics, Speech and Signal Processing,", "citeRegEx": "\u00d8land and Raj.,? \\Q2015\\E", "shortCiteRegEx": "\u00d8land and Raj.", "year": 2015}, {"title": "On the compression of recurrent neural networks with an application to lvcsr acoustic modeling for embedded speech recognition", "author": ["Rohit Prabhavalkar", "Ouais Alsharif", "Antoine Bruguier", "Lan McGraw"], "venue": "In 2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP),", "citeRegEx": "Prabhavalkar et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Prabhavalkar et al\\.", "year": 2016}, {"title": "Pruning algorithms-a survey", "author": ["Russell Reed"], "venue": "Neural Networks, IEEE Transactions on,", "citeRegEx": "Reed.,? \\Q1993\\E", "shortCiteRegEx": "Reed.", "year": 1993}, {"title": "Fault tolerance of pruned multilayer networks", "author": ["Bruce E Segee", "Michael J Carter"], "venue": "In Neural Networks,", "citeRegEx": "Segee and Carter.,? \\Q1991\\E", "shortCiteRegEx": "Segee and Carter.", "year": 1991}, {"title": "Dropout: A simple way to prevent neural networks from overfitting", "author": ["Nitish Srivastava", "Geoffrey Hinton", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan Salakhutdinov"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Srivastava et al\\.,? \\Q1929\\E", "shortCiteRegEx": "Srivastava et al\\.", "year": 1929}], "referenceMentions": [{"referenceID": 12, "context": "Pruning algorithms, as comprehensively surveyed by Reed (1993), are a useful set of heuristics designed to identify and remove elements from a neural network which are either redundant or do not significantly contribute to the output of the network.", "startOffset": 51, "endOffset": 63}, {"referenceID": 2, "context": "This is motivated by the observed tendency of neural networks to overfit to the idiosyncrasies of their training data given too many trainable parameters or too few input patterns from which to generalize, as stated by Chauvin (1990). Network architecture design and hyperparameter selection are inherently difficult tasks typically approached using a few well-known rules of thumb, e.", "startOffset": 219, "endOffset": 234}, {"referenceID": 2, "context": "This is motivated by the observed tendency of neural networks to overfit to the idiosyncrasies of their training data given too many trainable parameters or too few input patterns from which to generalize, as stated by Chauvin (1990). Network architecture design and hyperparameter selection are inherently difficult tasks typically approached using a few well-known rules of thumb, e.g. various weight initialization procedures, choosing the width and number of layers, different activation functions, learning rates, momentum, etc. Some of this \u201cblack art\u201d appears unavoidable. For problems which cannot be solved using linear threshold units alone, Baum & Haussler (1989) demonstrate that there is no way to precisely determine the appropriate size of a neural network a priori given any random set of training instances.", "startOffset": 219, "endOffset": 675}, {"referenceID": 0, "context": "Without explicitly removing parameters from the network, weight quantization allows for a reduction in the number of bytes used to represent each weight parameter, as investigated by Balzer et al. (1991), Dundar & Rose (1994), and Hoehfeld & Fahlman (1992).", "startOffset": 183, "endOffset": 204}, {"referenceID": 0, "context": "Without explicitly removing parameters from the network, weight quantization allows for a reduction in the number of bytes used to represent each weight parameter, as investigated by Balzer et al. (1991), Dundar & Rose (1994), and Hoehfeld & Fahlman (1992).", "startOffset": 183, "endOffset": 226}, {"referenceID": 0, "context": "Without explicitly removing parameters from the network, weight quantization allows for a reduction in the number of bytes used to represent each weight parameter, as investigated by Balzer et al. (1991), Dundar & Rose (1994), and Hoehfeld & Fahlman (1992). A recently proposed method for compressing recurrent neural networks (Prabhavalkar et al.", "startOffset": 183, "endOffset": 257}, {"referenceID": 0, "context": "Without explicitly removing parameters from the network, weight quantization allows for a reduction in the number of bytes used to represent each weight parameter, as investigated by Balzer et al. (1991), Dundar & Rose (1994), and Hoehfeld & Fahlman (1992). A recently proposed method for compressing recurrent neural networks (Prabhavalkar et al. (2016)) uses the singular values of a trained weight matrix as basis vectors from which to derive a compressed hidden layer.", "startOffset": 183, "endOffset": 355}, {"referenceID": 0, "context": "Without explicitly removing parameters from the network, weight quantization allows for a reduction in the number of bytes used to represent each weight parameter, as investigated by Balzer et al. (1991), Dundar & Rose (1994), and Hoehfeld & Fahlman (1992). A recently proposed method for compressing recurrent neural networks (Prabhavalkar et al. (2016)) uses the singular values of a trained weight matrix as basis vectors from which to derive a compressed hidden layer. \u00d8land & Raj (2015) successfully implemented network compression through weight quantization with an encoding step while others such as Han et al.", "startOffset": 183, "endOffset": 492}, {"referenceID": 0, "context": "Without explicitly removing parameters from the network, weight quantization allows for a reduction in the number of bytes used to represent each weight parameter, as investigated by Balzer et al. (1991), Dundar & Rose (1994), and Hoehfeld & Fahlman (1992). A recently proposed method for compressing recurrent neural networks (Prabhavalkar et al. (2016)) uses the singular values of a trained weight matrix as basis vectors from which to derive a compressed hidden layer. \u00d8land & Raj (2015) successfully implemented network compression through weight quantization with an encoding step while others such as Han et al. (2016) have tried to expand on this by adding weight-pruning as a preceding step to quantization and encoding.", "startOffset": 183, "endOffset": 626}, {"referenceID": 8, "context": "Alternatively, we might accomplish this using any number of much faster off-the-shelf pruning algorithms, such as Skeletonization (Mozer & Smolensky (1989a)), Optimal Brain Damage (LeCun et al. (1989)), or later variants such as Optimal Brain Surgeon (Hassibi & Stork (1993)).", "startOffset": 181, "endOffset": 201}, {"referenceID": 8, "context": "Alternatively, we might accomplish this using any number of much faster off-the-shelf pruning algorithms, such as Skeletonization (Mozer & Smolensky (1989a)), Optimal Brain Damage (LeCun et al. (1989)), or later variants such as Optimal Brain Surgeon (Hassibi & Stork (1993)).", "startOffset": 181, "endOffset": 275}, {"referenceID": 8, "context": "Alternatively, we might accomplish this using any number of much faster off-the-shelf pruning algorithms, such as Skeletonization (Mozer & Smolensky (1989a)), Optimal Brain Damage (LeCun et al. (1989)), or later variants such as Optimal Brain Surgeon (Hassibi & Stork (1993)). In fact, we borrow much of our inspiration from these algorithms, with one major variation: Instead of pruning individual weights, we prune entire neurons, thereby eliminating all of their incoming and outgoing weight parameters in one go, resulting in more memory saved, faster. The algorithm developed for this paper is targeted at reducing the total number of neurons in a trained network, which is one way of reducing its computational memory footprint. This is often a desirable criteria to minimize in the case of resource-constrained or embedded devices, and also allows us to probe the limitations of pruning down to the very last essential network elements. In terms of generalization as well, we can measure the error of the network on the test set as each element is sequentially removed from the network. With an oracle pruning algorithm, what we expect to observe is that the output of the network remains stable as the first few superfluous neurons are removed, and as we start to bite into the more crucial members of the function approximation, the error should start to rise dramatically. In this paper, the brute-force approach described at the beginning of this section serves as a proxy for an oracle pruning algorithm. One reason to choose to rank and prune individual neurons as opposed to weights is that there are far fewer elements to consider. Furthermore, the removal of a single weight from a large network is a drop in the bucket in terms of reducing a network\u2019s core memory footprint. If we want to reduce the size of a network as efficiently as possible, we argue that pruning neurons instead of weights is more efficient computationally as well as practically in terms of quickly reaching a hypothetical target reduction in memory consumption. This approach also offers downstream applications a realistic expectation of the minimal increase in error resulting from the removal of a specified percentage of neurons. Such trade-offs are unavoidable, but performance impacts can be limited if a principled approach is used to find the best candidate neurons for removal. It is well known that too many free parameters in a neural network can lead to overfitting. Regardless of the number of weights used in a given network, as Segee & Carter (1991) assert, the representation of a learned function approximation is almost never evenly distributed over the hidden units, and thus the removal of any single hidden unit at random can actually result in a network fault.", "startOffset": 181, "endOffset": 2556}, {"referenceID": 8, "context": "Alternatively, we might accomplish this using any number of much faster off-the-shelf pruning algorithms, such as Skeletonization (Mozer & Smolensky (1989a)), Optimal Brain Damage (LeCun et al. (1989)), or later variants such as Optimal Brain Surgeon (Hassibi & Stork (1993)). In fact, we borrow much of our inspiration from these algorithms, with one major variation: Instead of pruning individual weights, we prune entire neurons, thereby eliminating all of their incoming and outgoing weight parameters in one go, resulting in more memory saved, faster. The algorithm developed for this paper is targeted at reducing the total number of neurons in a trained network, which is one way of reducing its computational memory footprint. This is often a desirable criteria to minimize in the case of resource-constrained or embedded devices, and also allows us to probe the limitations of pruning down to the very last essential network elements. In terms of generalization as well, we can measure the error of the network on the test set as each element is sequentially removed from the network. With an oracle pruning algorithm, what we expect to observe is that the output of the network remains stable as the first few superfluous neurons are removed, and as we start to bite into the more crucial members of the function approximation, the error should start to rise dramatically. In this paper, the brute-force approach described at the beginning of this section serves as a proxy for an oracle pruning algorithm. One reason to choose to rank and prune individual neurons as opposed to weights is that there are far fewer elements to consider. Furthermore, the removal of a single weight from a large network is a drop in the bucket in terms of reducing a network\u2019s core memory footprint. If we want to reduce the size of a network as efficiently as possible, we argue that pruning neurons instead of weights is more efficient computationally as well as practically in terms of quickly reaching a hypothetical target reduction in memory consumption. This approach also offers downstream applications a realistic expectation of the minimal increase in error resulting from the removal of a specified percentage of neurons. Such trade-offs are unavoidable, but performance impacts can be limited if a principled approach is used to find the best candidate neurons for removal. It is well known that too many free parameters in a neural network can lead to overfitting. Regardless of the number of weights used in a given network, as Segee & Carter (1991) assert, the representation of a learned function approximation is almost never evenly distributed over the hidden units, and thus the removal of any single hidden unit at random can actually result in a network fault. Mozer & Smolensky (1989b) argue that only a subset of the hidden units in a neural network actually", "startOffset": 181, "endOffset": 2800}, {"referenceID": 8, "context": "Our algorithm relies on a combination of assumptions similar to the ones made by Mozer & Smolensky (1989a) and LeCun et al. (1989) in the formulation of the Skeletonization and Optimal Brain Damage algorithms.", "startOffset": 111, "endOffset": 131}, {"referenceID": 8, "context": "Our algorithm relies on a combination of assumptions similar to the ones made by Mozer & Smolensky (1989a) and LeCun et al. (1989) in the formulation of the Skeletonization and Optimal Brain Damage algorithms. First, we assumed that the error function with respect to each individual neuron can be approximated with a straight line or more precisely with a parabola. Second, for second derivative terms we consider only the diagonal elements of the Hessian matrix, i.e. we assume that each neuron-weight connection can be treated independently of the other elements in the network. Third, we assumed that pruning could be done in a serial fashion in which we find the single least productive element in the network, remove it, and move on. We found that all of these assumptions are deeply flawed in the sense that the true relevance of a neuron can only be partially approximated by a first or second order method, and only at certain stages of the pruning process. For most problems, these methods can usually remove between 10-30% of the neurons in a trained network, but beyond this point their reliability breaks down. For certain problems, none of the described methods seem to perform very well, though for obvious reasons the brute-force method always exhibits the best results. The reason for this is that the error function with respect to each hidden unit is more complex than a simple second-order Taylor series can approximate. Furthermore, we have not directly taken into account the interdependence of elements within a network, though the work of Hassibi & Stork (1993) could provide some guidance in this regard.", "startOffset": 111, "endOffset": 1586}], "year": 2017, "abstractText": "How much can pruning algorithms teach us about the fundamentals of learning representations in neural networks? A lot, it turns out. Neural network model compression has become a topic of great interest in recent years, and many different techniques have been proposed to address this problem. In general, this is motivated by the idea that smaller models typically lead to better generalization. At the same time, the decision of what to prune and when to prune necessarily forces us to confront our assumptions about how neural networks actually learn to represent patterns in data. In this work we set out to test several long-held hypotheses about neural network learning representations and numerical approaches to pruning. To accomplish this we first reviewed the historical literature and derived a novel algorithm to prune whole neurons (as opposed to the traditional method of pruning weights) from optimally trained networks using a second-order Taylor method. We then set about testing the performance of our algorithm and analyzing the quality of the decisions it made. As a baseline for comparison we used a first-order Taylor method based on the Skeletonization algorithm and an exhaustive brute-force serial pruning algorithm. Our proposed algorithm worked well compared to a first-order method, but not nearly as well as the brute-force method. Our error analysis led us to question the validity of many widely-held assumptions behind pruning algorithms in general and the trade-offs we often make in the interest of reducing computational complexity. We discovered that there is a straightforward way, however expensive, to serially prune 40-70% of the neurons in a trained network with minimal effect on the learning representation and without any re-training.", "creator": "LaTeX with hyperref package"}}}