{"id": "1701.04508", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Jan-2017", "title": "Online Learning with Regularized Kernel for One-class Classification", "abstract": "This paper presents an online learning with regularized kernel based one-class extreme learning machine (ELM) classifier and is referred as online RK-OC-ELM. The baseline kernel hyperplane model considers whole data in a single chunk with regularized ELM approach for offline learning in case of one-class classification (OCC). Further, the basic hyper plane model is adapted in an online fashion from stream of training samples in this paper. Two frameworks viz., boundary and reconstruction are presented to detect the target class in online RKOC-ELM. Boundary framework based one-class classifier consists of single node output architecture and classifier endeavors to approximate all data to any real number. However, one-class classifier based on reconstruction framework is an autoencoder architecture, where output nodes are identical to input nodes and classifier endeavor to reconstruct input layer at the output layer. Both these frameworks employ regularized kernel ELM based online learning and consistency based model selection has been employed to select learning algorithm parameters. The performance of online RK-OC-ELM has been evaluated on standard benchmark datasets as well as on artificial datasets and the results are compared with existing state-of-the art one-class classifiers. The results indicate that the online learning one-class classifier is slightly better or same as batch learning based approaches. As, base classifier used for the proposed classifiers are based on the ELM, hence, proposed classifiers would also inherit the benefit of the base classifier i.e. it will perform faster computation compared to traditional autoencoder based one-class classifier.", "histories": [["v1", "Tue, 17 Jan 2017 01:40:07 GMT  (756kb,D)", "http://arxiv.org/abs/1701.04508v1", "Paper has been submitted to special issue of IEEE Transactions on Systems, Man and Cybernetics: Systems with Manuscript ID: SMCA-16-09-1033"]], "COMMENTS": "Paper has been submitted to special issue of IEEE Transactions on Systems, Man and Cybernetics: Systems with Manuscript ID: SMCA-16-09-1033", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["chandan gautam", "aruna tiwari", "sundaram suresh", "kapil ahuja"], "accepted": false, "id": "1701.04508"}, "pdf": {"name": "1701.04508.pdf", "metadata": {"source": "CRF", "title": "Online Learning with Regularized Kernel for One-Class Classification", "authors": ["Chandan Gautam", "Aruna Tiwari", "Sundaram Suresh", "Kapil Ahuja"], "emails": ["chandangautam31@gmail.com).", "artiwari@iiti.ac.in).", "ssundaram@ntu.edu.sg).", "kahuja@iiti.ac.in"], "sections": [{"heading": null, "text": "This year, it has reached the point where it will be able to put itself at the top of the list."}, {"heading": "II. ONLINE LEARNING WITH REGULARIZED KERNEL FOR", "text": "OCCIn this section, the ELM-based sequential single-class classifier is modeled taking into account both factors, namely regularization and nuclearization, which is referred to in this paper as online learning with a regulated kernel for a class ELM (Online RK-OCELM).The regularization factor helps the classifier to achieve a better generalization capability for noisy data.Tikhonov regularization [32] has been applied due to its ability to address poorly posed and singular problems that generally arise in solving the inverse problem. Below, two types of framework, boundary and reconstruction, are discussed:"}, {"heading": "A. Online RK-OC-ELM: Boundary Framework Based Approach", "text": "In this case, it is only a matter of time until there is an agreement. (...) In this case, it is only a matter of time until there is an agreement. (...) In this case, it is only a matter of time until there is an agreement. (...) In this case, it is only a matter of time until there is an agreement. (...) In this case, it is only a matter of time until there is an agreement. (...) In this case, it is a matter of time until there is an agreement. (...) It is a matter of time until there is an agreement. (...) It is a matter of time until there is an agreement. (...) It is a matter of time until there is an agreement. (...) It is a matter of time until there is an agreement. (...) It is a matter of time until there is an agreement. (...) It is a question of time. (...) It is a question of time. (...) It is a question of time."}, {"heading": "B. Online RK-OC-ELM: Reconstruction Based Approach", "text": "In reconstruction frames based on RK-OC-ELM, the model is predicted only by target data and attempts to approximate all data per se. Fig. 2 shows the architecture for reconstruction frames based on online RK-ELM. Fig. 2 defines a stream of training data X as described above. (Fig. 2 shows the input layer data for tth input sample as (xt, xt) because the target is identical to the input layer. Furthermore, a kernel feature mapping between input and hidden layer is used. (Figure, hidden layer output or kernel matrix results are used as square symmetrix matrix of size.) Output weight is identical to the input layer. (Figure) is used between input and hidden layer."}, {"heading": "C. Parameter Selection for ELM based One-Class Classifier", "text": "Various selection criteria have been suggested in the literature for handling kernel parameters, but most of them are developed specifically for Gaussian kernel selection [36]. Among various methods, consistency-based model selection [37] is only suitable for any kind of kernel parameters. Therefore, consistency-based model selection has been applied for both frameworks based on OCC. There are two parameters for the kernel function mapping with a Gaussian kernel i.e. Regulatory parameters (\u03bb) and consistency-based model selection [37] also concerns K-fold cross-validation within the system (see Equation (22). 5-fold cross-validation is used with all single-class classifiers. This model works mainly on the basis of 2-sigma bound classification models."}, {"heading": "III. PERFORMANCE EVALUATION", "text": "In this section we will first discuss the performance of the proposed classifiers on two artificial datasets and then discuss the performance on six benchmark datasets. All experiments for this work were conducted on MATLAB 2011a in Windows 7 (64 bit) environment with 4GB RAM, 3.10GHz processor and Intel i5 processor. To implement the existing classifiers, two toolboxes are used, proposed by Tax [10] and Gautam [30]."}, {"heading": "A. Performance Comparison on Artificial Datasets", "text": "This section discusses the impact of the online regulated kernel on boundary creation for two artificial datasets. Artificial datasets are created using PRToolBox [38] and each dataset is of the size of a hundred. The boundary is then generated by artificial datasets with and without kernel feature mapping. However, without kernel feature mapping, it is noted that random feature mapping is used instead of kernel feature mapping. Online R-OC-ELM is discussed for both frameworks in the supplementary class provided with this paper. Furthermore, the effects of the threshold on boundary creation for artificial datasets are discussed."}, {"heading": "B. Performance Comparison on Benchmark Datasets", "text": "The performance of the proposed methods has been tested using six benchmark data sets, as they are called in Table I. Benchmark data sets are available at the UCI Machine Learning Repository (39) in original format and in a single-class format on the Delft University of Technology website [40]. The data sets are prepared for OCC in the same way as those provided by Leng et al. [28] and Gautam et al. [30] Dataset is divided by their classes and assumes that normal samples are used as the target class and remaining of the classes as the outlier class. And the same procedure is followed for each dataset. Furthermore, randomly selected 50% of the target data for training and the remaining 50% is combined with the outlier class for testing. It is noted that optimal parameters are only calculated in the first run. Hence, it speeds up execution and saves a lot of time. Data is normalized between 0 and 1 using max-min normalization."}, {"heading": "C. Discussion", "text": "In the previous section, the performance of the proposed classifiers for boundary and reconstruction frameworks was discussed separately on the basis of approaches. This section will provide the general discussion on both frameworks together. Table II-VII presents all the results achieved on six benchmark data sets. In the tables, it can be seen that proposed online single-class classifiers perform similarly to offline single-class classifiers with kernels for two reasons: firstly, because of the random selection of training and test data for each classifier in each run; secondly, the method of inverse calculation differs between online and offline classifiers; the proposed classifiers were tested with different benchmark data sets and it was found that reconstruction based on single-class classifiers works better than the method of inverse calculation between online and offline classifiers."}, {"heading": "IV. CONCLUSION", "text": "This paper has so far discussed three methods based on boundary and reconstruction frameworks, but not based on boundary frameworks based on classifiers. Our proposed classifier can handle data online, and the performance evaluation of these classifiers has shown that these online classifiers are as capable as offline classifiers. Since the proposed classifiers are online, there is no need to train the model from scratch on new classifiers. Our proposed classifier can process data online, and the performance evaluation of these classifiers have shown that these online classifiers are as capable as offline classifiers. Since the proposed classifiers are online, there is no need to train the model from scratch on a new classifier of data. Simply, submit newly arrived data with the proposed classifiers and they will take care of the rest."}, {"heading": "ACKNOWLEDGMENT", "text": "This research was supported by the Department of Electronics and Information Technology (DeITY, Govt. of India) within the Visvesvaraya PHD Programme for Electronics & IT."}], "references": [{"title": "One-class classifier networks for target recognition applications", "author": ["M.M. Moya", "M.W. Koch", "L.D. Hostetler"], "venue": "Technical report, Sandia National Labs., Albuquerque, NM (United States)", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1993}, {"title": "A review of novelty detection", "author": ["M.A. Pimentel", "D.A. Clifton", "L. Clifton", "L. Tarassenko"], "venue": "Signal Processing, 99:215\u2013249", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2014}, {"title": "Design and analysis of multimodel-based anomaly intrusion detection systems in industrial process automation", "author": ["C. Zhou", "S. Huang", "N. Xiong", "S.-H. Yang", "H. Li", "Y. Qin", "X. Li"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics: Systems, 45(10):1345\u20131360", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}, {"title": "Gramophone noise detection and reconstruction using time delay artificial neural networks", "author": ["C.F. Stallmann", "A.P. Engelbrecht"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics: Systems, PP(99):1\u201313", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2016}, {"title": "Sliding window-based fault detection from high-dimensional data streams", "author": ["L. Zhang", "J. Lin", "R. Karim"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics: Systems, PP(99):1\u201315", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2016}, {"title": "Animal-vehicle collision mitigation system for automated vehicles", "author": ["A. Mammeri", "D. Zhou", "A. Boukerche"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics: Systems, 46(9):1287\u20131299", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2016}, {"title": "Support vector method for novelty detection", "author": ["B. Sch\u00f6lkopf", "R.C. Williamson", "A.J. Smola", "J. Shawe-Taylor", "J.C. Platt"], "venue": "NIPS, volume 12, pages 582\u2013588", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1999}, {"title": "Support vector domain description", "author": ["D.M.J. Tax", "R.P.W. Duin"], "venue": "Pattern recognition letters, 20(11):1191\u20131199", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1999}, {"title": "Online SVM learning: from classification to data description and back", "author": ["D.M.J. Tax", "P. Laskov"], "venue": "IEEE 13th Workshop on Neural Networks for Signal Processing, 2003 (NNSP\u201903), pages 499\u2013508. IEEE", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2003}, {"title": "DDtools, the data description toolbox for MATLAB, version 2.1.2", "author": ["D.M.J. Tax"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2015}, {"title": "A survey of recent trends in one class classification", "author": ["S.S. Khan", "M.G. Madden"], "venue": "Irish conference on Artificial Intelligence and Cognitive Science, pages 188\u2013197. Springer", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2009}, {"title": "Concept-learning in the absence of counter-examples: An autoassociation-based approach to classification", "author": ["N. Japkowicz"], "venue": "PhD thesis, Rutgers, The State University of New Jersey", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1999}, {"title": "One-class document classification via neural networks", "author": ["L. Manevitz", "M. Yousef"], "venue": "Neurocomputing, 70(7):1466\u20131481", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2007}, {"title": "Extreme learning machine: theory and applications", "author": ["G.-B. Huang", "Q.-Y. Zhu", "C.-K. Siew"], "venue": "Neurocomputing, 70(1):489\u2013501", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2006}, {"title": "Extreme learning machine for regression and multiclass classification", "author": ["G.-B. Huang", "H. Zhou", "X. Ding", "R. Zhang"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics, 42(2):513\u2013529", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2012}, {"title": "A fast and accurate online sequential learning algorithm for feedforward networks", "author": ["N.-Y. Liang", "G.-B. Huang", "P. Saratchandran", "N. Sundararajan"], "venue": "IEEE Transactions on Neural Networks, 17(6):1411\u20131423", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2006}, {"title": "Online sequential extreme learning machine with kernels", "author": ["S. Scardapane", "D. Comminiello", "M. Scarpiniti", "A. Uncini"], "venue": "IEEE Transactions on Neural Networks and Learning Systems, 26(9):2214\u20132220", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2015}, {"title": "Online sequential extreme learning machine with kernels for nonstationary time series prediction", "author": ["X. Wang", "M. Han"], "venue": "Neurocomputing, 145:90\u201397", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2014}, {"title": "Online regularized and kernelized extreme learning machines with forgetting mechanism", "author": ["X. Zhou", "Z. Liu", "C. Zhu"], "venue": "Mathematical Problems in Engineering, 2014:1\u201311", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "Sparse extreme learning machine for classification", "author": ["Z. Bai", "G.-B. Huang", "D. Wang", "H. Wang", "M.B. Westover"], "venue": "IEEE Transactions on Cybernetics, 44(10):1858\u20131870", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}, {"title": "Stacked extreme learning machines", "author": ["H. Zhou", "G.-B. Huang", "Z. Lin", "H. Wang", "Y.C. Soh"], "venue": "IEEE Transactions on Cybernetics, 45(9):2013\u2013 2025", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2015}, {"title": "Graph embedded extreme learning machine", "author": ["A. Iosifidis", "A. Tefas", "I. Pitas"], "venue": "IEEE Transactions on Cybernetics, 46(1):311\u2013324", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2016}, {"title": "A meta-cognitive learning algorithm for an extreme learning machine classifier", "author": ["R. Savitha", "S. Suresh", "H.J. Kim"], "venue": "Cognitive Computation, 6(2):253\u2013263", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2014}, {"title": "Domain adaptation extreme learning machines for drift compensation in e-nose systems", "author": ["L. Zhang", "D. Zhang"], "venue": "IEEE Transactions on Instrumentation and Measurement, 64(7):1790\u20131801", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2015}, {"title": "Performance enhancement of extreme learning machine for multi-category sparse data classification problems", "author": ["S. Suresh", "S. Saraswathi", "N. Sundararajan"], "venue": "Engineering Applications of Artificial Intelligence, 23(7):1149\u20131157", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2010}, {"title": "No-reference image quality assessment using modified extreme learning machine classifier", "author": ["S. Suresh", "R. Venkatesh Babu", "H.J. Kim"], "venue": "Applied Soft Computing, 9(2):541\u2013552", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2009}, {"title": "Trends in extreme learning machines: a review", "author": ["G. Huang", "G.-B. Huang", "S. Song", "K. You"], "venue": "Neural Networks, 61:32\u201348", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2015}, {"title": "One-class classification with extreme learning machine", "author": ["Q. Leng", "H. Qi", "J. Miao", "W. Zhu", "G. Su"], "venue": "Mathematical Problems in Engineering, pages 1\u201311", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2014}, {"title": "One-class classification based on extreme learning and geometric class information", "author": ["A. Iosifidis", "V. Mygdalis", "A. Tefas", "I. Pitas"], "venue": "Neural Processing Letters, pages 1\u201316", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2016}, {"title": "On the construction of extreme learning machine for online and offline one class classifier - An expanded toolbox", "author": ["C. Gautam", "A. Tiwari", "Q. Leng"], "venue": "Neurocomputing,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2016}, {"title": "On the construction of extreme learning machine for one class classifier", "author": ["C. Gautam", "A. Tiwari"], "venue": "Proceedings of ELM-2015 Volume 1, pages 447\u2013461. Springer", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2016}, {"title": "Matrix computations", "author": ["G.H. Golub", "C.F. Van Loan"], "venue": "volume 3. JHU Press", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2012}, {"title": "Fast and efficient strategies for model selection of Gaussian support vector machine", "author": ["Z. Xu", "M. Dai", "D. Meng"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics), 39(5):1292\u20131307", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2009}, {"title": "Parameter selection of Gaussian kernel for one-class SVM", "author": ["Y. Xiao", "H. Wang", "W. Xu"], "venue": "IEEE Transactions on Cybernetics, 45(5):941\u2013953", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2015}, {"title": "A consistency-based model selection for one-class classification", "author": ["D.M.J. Tax", "K.-R. M\u00fcller"], "venue": "Proceedings of the 17th International Conference on Pattern Recognition ", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2004}, {"title": "PRTools", "author": ["R.P.W. Duin", "P. Juszczak", "D. Ridder", "P. Paclik", "E. Pekalska", "D.M.J. Tax"], "venue": "a MATLAB toolbox for pattern recognition", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2004}], "referenceMentions": [{"referenceID": 0, "context": "[1].", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "The OCC has been generally employed to solve the problem of novelty, outlier, intrusion or fault detection [2].", "startOffset": 107, "endOffset": 110}, {"referenceID": 2, "context": "These problems are also solved by multi-class classification when samples of both classes, normal and outlier class, are available [3] [4] [5] [6].", "startOffset": 131, "endOffset": 134}, {"referenceID": 3, "context": "These problems are also solved by multi-class classification when samples of both classes, normal and outlier class, are available [3] [4] [5] [6].", "startOffset": 135, "endOffset": 138}, {"referenceID": 4, "context": "These problems are also solved by multi-class classification when samples of both classes, normal and outlier class, are available [3] [4] [5] [6].", "startOffset": 139, "endOffset": 142}, {"referenceID": 5, "context": "These problems are also solved by multi-class classification when samples of both classes, normal and outlier class, are available [3] [4] [5] [6].", "startOffset": 143, "endOffset": 146}, {"referenceID": 6, "context": "Two types of SVM based one-class classifier have been proposed, namely, One-Class SVM (OCSVM) [7] and Support Vector Domain Description (SVDD) [8].", "startOffset": 94, "endOffset": 97}, {"referenceID": 7, "context": "Two types of SVM based one-class classifier have been proposed, namely, One-Class SVM (OCSVM) [7] and Support Vector Domain Description (SVDD) [8].", "startOffset": 143, "endOffset": 146}, {"referenceID": 1, "context": "After surveying various papers, it has been observed that SVM based one-class classifier has been explored more compared to other one class methods [2].", "startOffset": 148, "endOffset": 151}, {"referenceID": 8, "context": "SVM based one-class classifier has also been developed for incremental and online learning [9].", "startOffset": 91, "endOffset": 94}, {"referenceID": 9, "context": ", a toolbox is available in [10].", "startOffset": 28, "endOffset": 32}, {"referenceID": 10, "context": "Based on different nature of data used during learning hyperplane of OCC, it can be classified as [11] (i) with positive examples only, (ii) with the positive and small amount of negative examples only, and (iii) with positive and unlabeled data.", "startOffset": 98, "endOffset": 102}, {"referenceID": 11, "context": "Neural network with backpropagation has been explored in past for OCC task [12] [13].", "startOffset": 75, "endOffset": 79}, {"referenceID": 12, "context": "Neural network with backpropagation has been explored in past for OCC task [12] [13].", "startOffset": 80, "endOffset": 84}, {"referenceID": 13, "context": "[14] [15] also developed a single layer feed-forward network, called as Extreme Learning Machine (ELM).", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[14] [15] also developed a single layer feed-forward network, called as Extreme Learning Machine (ELM).", "startOffset": 5, "endOffset": 9}, {"referenceID": 15, "context": "Online version of ELM has also been developed for multi-class classification and regression tasks with random [16] and kernel feature mapping [17] [18] [19].", "startOffset": 110, "endOffset": 114}, {"referenceID": 16, "context": "Online version of ELM has also been developed for multi-class classification and regression tasks with random [16] and kernel feature mapping [17] [18] [19].", "startOffset": 142, "endOffset": 146}, {"referenceID": 17, "context": "Online version of ELM has also been developed for multi-class classification and regression tasks with random [16] and kernel feature mapping [17] [18] [19].", "startOffset": 147, "endOffset": 151}, {"referenceID": 18, "context": "Online version of ELM has also been developed for multi-class classification and regression tasks with random [16] and kernel feature mapping [17] [18] [19].", "startOffset": 152, "endOffset": 156}, {"referenceID": 19, "context": "In past decades, ELM has been well expanded in both dimensions: theory [20] [21] [22] [23] and application [24] [18] [25] [26].", "startOffset": 71, "endOffset": 75}, {"referenceID": 20, "context": "In past decades, ELM has been well expanded in both dimensions: theory [20] [21] [22] [23] and application [24] [18] [25] [26].", "startOffset": 76, "endOffset": 80}, {"referenceID": 21, "context": "In past decades, ELM has been well expanded in both dimensions: theory [20] [21] [22] [23] and application [24] [18] [25] [26].", "startOffset": 81, "endOffset": 85}, {"referenceID": 22, "context": "In past decades, ELM has been well expanded in both dimensions: theory [20] [21] [22] [23] and application [24] [18] [25] [26].", "startOffset": 86, "endOffset": 90}, {"referenceID": 23, "context": "In past decades, ELM has been well expanded in both dimensions: theory [20] [21] [22] [23] and application [24] [18] [25] [26].", "startOffset": 107, "endOffset": 111}, {"referenceID": 17, "context": "In past decades, ELM has been well expanded in both dimensions: theory [20] [21] [22] [23] and application [24] [18] [25] [26].", "startOffset": 112, "endOffset": 116}, {"referenceID": 24, "context": "In past decades, ELM has been well expanded in both dimensions: theory [20] [21] [22] [23] and application [24] [18] [25] [26].", "startOffset": 117, "endOffset": 121}, {"referenceID": 25, "context": "In past decades, ELM has been well expanded in both dimensions: theory [20] [21] [22] [23] and application [24] [18] [25] [26].", "startOffset": 122, "endOffset": 126}, {"referenceID": 26, "context": "A detailed survey on ELM and its application can be found in [27].", "startOffset": 61, "endOffset": 65}, {"referenceID": 27, "context": "[28] developed ELM for OCC due to its fast learning speed, which supports only offline learning.", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "[28] tested their model with only one type of threshold deciding criteria, i.", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "Later, Iosifidis [29] improvised ELM based one-class classifier based on geometric information of class for offline learning.", "startOffset": 17, "endOffset": 21}, {"referenceID": 29, "context": "[30]1 [31] explored further ELM based one-class classifier for mainly offline learning and tested it with three different threshold criteria.", "startOffset": 0, "endOffset": 4}, {"referenceID": 30, "context": "[30]1 [31] explored further ELM based one-class classifier for mainly offline learning and tested it with three different threshold criteria.", "startOffset": 6, "endOffset": 10}, {"referenceID": 29, "context": "[30] have shown particularly two aspects: (i) random feature mapping based offline methods have been outperformed by kernel feature mapping based offline methods (ii) the possibility of", "startOffset": 0, "endOffset": 4}, {"referenceID": 31, "context": "Further, compute the inverse in Equation (8) using block matrix inverse formula [34].", "startOffset": 80, "endOffset": 84}, {"referenceID": 31, "context": "P11 can be expanded by employing Woodbury formula [34] as: P11 = (\u03c6u \u2212 \u03c6u,v\u03c6\u22121 v \u03c6u,v) = \u03c6\u22121 u \u2212 \u03c6\u22121 u \u03c6u,v(\u03c6u,v\u03c6 u \u03c6u,v + \u03c6\u22121 v ) \u03c6u,v\u03c6 \u22121 u (12)", "startOffset": 50, "endOffset": 54}, {"referenceID": 32, "context": "Various model selection criteria have been proposed in literature for handling parameters of the kernel, however, most of them are developed especially for Gaussian kernel only [35] [36].", "startOffset": 177, "endOffset": 181}, {"referenceID": 33, "context": "Various model selection criteria have been proposed in literature for handling parameters of the kernel, however, most of them are developed especially for Gaussian kernel only [35] [36].", "startOffset": 182, "endOffset": 186}, {"referenceID": 34, "context": "Among various methods, consistency based model selection [37] is only suitable for any type of Kernels.", "startOffset": 57, "endOffset": 61}, {"referenceID": 34, "context": "Consistency based model selection [37] also employs K-fold cross validation within it (see Equation (22) below).", "startOffset": 34, "endOffset": 38}, {"referenceID": 9, "context": "For implementing the existing classifiers, two toolboxes is used, which is proposed by Tax [10] and Gautam [30].", "startOffset": 91, "endOffset": 95}, {"referenceID": 29, "context": "For implementing the existing classifiers, two toolboxes is used, which is proposed by Tax [10] and Gautam [30].", "startOffset": 107, "endOffset": 111}, {"referenceID": 35, "context": "Artificial datasets are created with the help of PRToolBox [38] and each dataset is of size hundred.", "startOffset": 59, "endOffset": 63}, {"referenceID": 29, "context": "[30] (ii) Performance of kernel feature mapping is superior over random feature mapping, therefore, it was necessary to implement it with online ELM based one-class classifiers.", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "[28] and Gautam et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 29, "context": "[30].", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "incsvdd [6] 94.", "startOffset": 8, "endOffset": 11}, {"referenceID": 23, "context": "OCKELM \u03b81 [24] 93.", "startOffset": 10, "endOffset": 14}, {"referenceID": 25, "context": "13) OS-OCELM \u03b81 [26] 86.", "startOffset": 16, "endOffset": 20}, {"referenceID": 5, "context": "autoenc dd [6] 92.", "startOffset": 11, "endOffset": 14}, {"referenceID": 25, "context": "AAKELM \u03b81 [26] 93.", "startOffset": 10, "endOffset": 14}, {"referenceID": 25, "context": "5) AAKELM \u03b82 [26] 94.", "startOffset": 13, "endOffset": 17}, {"referenceID": 25, "context": "5) OS-AAELM \u03b81 [26] 90.", "startOffset": 15, "endOffset": 19}, {"referenceID": 25, "context": "37) OS-AAELM \u03b82 [26] 89.", "startOffset": 16, "endOffset": 20}, {"referenceID": 5, "context": "incsvdd [6] 66.", "startOffset": 8, "endOffset": 11}, {"referenceID": 23, "context": "OCKELM \u03b81 [24] 68.", "startOffset": 10, "endOffset": 14}, {"referenceID": 25, "context": "03) OS-OCELM \u03b81 [26] 61.", "startOffset": 16, "endOffset": 20}, {"referenceID": 5, "context": "autoenc dd [6] 66.", "startOffset": 11, "endOffset": 14}, {"referenceID": 25, "context": "AAKELM \u03b81 [26] 67.", "startOffset": 10, "endOffset": 14}, {"referenceID": 25, "context": "AAKELM \u03b82 [26] 59.", "startOffset": 10, "endOffset": 14}, {"referenceID": 25, "context": "62) OS-AAELM \u03b81 [26] 63.", "startOffset": 16, "endOffset": 20}, {"referenceID": 25, "context": "32) OS-AAELM \u03b82 [26] 60.", "startOffset": 16, "endOffset": 20}, {"referenceID": 5, "context": "incsvdd [6] 57.", "startOffset": 8, "endOffset": 11}, {"referenceID": 23, "context": "OCKELM \u03b81 [24] 56.", "startOffset": 10, "endOffset": 14}, {"referenceID": 25, "context": "OS-OCELM \u03b81 [26] 54.", "startOffset": 12, "endOffset": 16}, {"referenceID": 27, "context": "Proposed classifier online RK-OC-ELM \u03b81 is the online version of the existing OCKELM \u03b81 [28] classifier.", "startOffset": 88, "endOffset": 92}, {"referenceID": 29, "context": ", OS-OCELM \u03b81 [30].", "startOffset": 14, "endOffset": 18}, {"referenceID": 27, "context": "[28] and [30] had also exhibited the same trend in their work for offline classifiers.", "startOffset": 0, "endOffset": 4}, {"referenceID": 29, "context": "[28] and [30] had also exhibited the same trend in their work for offline classifiers.", "startOffset": 9, "endOffset": 13}, {"referenceID": 5, "context": "autoenc dd [6] 48.", "startOffset": 11, "endOffset": 14}, {"referenceID": 25, "context": "AAKELM \u03b81 [26] 49.", "startOffset": 10, "endOffset": 14}, {"referenceID": 25, "context": "21) AAKELM \u03b82 [26] 62.", "startOffset": 14, "endOffset": 18}, {"referenceID": 25, "context": "OS-AAELM \u03b81 [26] 56.", "startOffset": 12, "endOffset": 16}, {"referenceID": 25, "context": "OS-AAELM \u03b82 [26] 39.", "startOffset": 12, "endOffset": 16}], "year": 2017, "abstractText": "This paper presents an online learning with regularized kernel based one-class extreme learning machine (ELM) classifier and is referred as \u201conline RK-OC-ELM\u201d. The baseline kernel hyperplane model considers whole data in a single chunk with regularized ELM approach for offline learning in case of one-class classification (OCC). Further, the basic hyper plane model is adapted in an online fashion from stream of training samples in this paper. Two frameworks viz., boundary and reconstruction are presented to detect the target class in online RKOC-ELM. Boundary framework based one-class classifier consists of single node output architecture and classifier endeavors to approximate all data to any real number. However, one-class classifier based on reconstruction framework is an autoencoder architecture, where output nodes are identical to input nodes and classifier endeavor to reconstruct input layer at the output layer. Both these frameworks employ regularized kernel ELM based online learning and consistency based model selection has been employed to select learning algorithm parameters. The performance of online RK-OC-ELM has been evaluated on standard benchmark datasets as well as on artificial datasets and the results are compared with existing state-of-the art oneclass classifiers. The results indicate that the online learning oneclass classifier is slightly better or same as batch learning based approaches. As, base classifier used for the proposed classifiers are based on the ELM, hence, proposed classifiers would also inherit the benefit of the base classifier i.e. it will perform faster computation compared to traditional autoencoder based one-class classifier.", "creator": "LaTeX with hyperref package"}}}