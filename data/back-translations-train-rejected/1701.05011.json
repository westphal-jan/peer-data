{"id": "1701.05011", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Jan-2017", "title": "Assessing User Expertise in Spoken Dialog System Interactions", "abstract": "Identifying the level of expertise of its users is important for a system since it can lead to a better interaction through adaptation techniques. Furthermore, this information can be used in offline processes of root cause analysis. However, not much effort has been put into automatically identifying the level of expertise of an user, especially in dialog-based interactions. In this paper we present an approach based on a specific set of task related features. Based on the distribution of the features among the two classes - Novice and Expert - we used Random Forests as a classification approach. Furthermore, we used a Support Vector Machine classifier, in order to perform a result comparison. By applying these approaches on data from a real system, Let's Go, we obtained preliminary results that we consider positive, given the difficulty of the task and the lack of competing approaches for comparison.", "histories": [["v1", "Wed, 18 Jan 2017 11:10:59 GMT  (28kb)", "http://arxiv.org/abs/1701.05011v1", "10 pages"]], "COMMENTS": "10 pages", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["eug\\'enio ribeiro", "fernando batista", "isabel trancoso", "jos\\'e lopes", "ricardo ribeiro", "david martins de matos"], "accepted": false, "id": "1701.05011"}, "pdf": {"name": "1701.05011.pdf", "metadata": {"source": "CRF", "title": "Assessing User Expertise in Spoken Dialog System Interactions", "authors": ["Eug\u00e9nio Ribeiro", "Fernando Batista", "Isabel Trancoso", "Jos\u00e9 Lopes", "Ricardo Ribeiro", "David Martins de Matos"], "emails": ["eugenio.ribeiro@l2f.inesc-id.pt"], "sections": [{"heading": null, "text": "ar Xiv: 170 1.05 011v 1 [cs.C L] 1Keywords: User Competence \u00b7 Let's Go \u00b7 SVM \u00b7 Random Forest"}, {"heading": "1 Introduction", "text": "Users of a dialog system have different levels of expertise, i.e. knowledge of the system's capabilities and experience with its application. Therefore, it is important for a dialog system to identify a user's expertise, as it provides customization tips that can improve the flow of dialogue and overall user satisfaction. For example, by identifying an inexperienced user, the system can provide help with the first signs of a struggle and adjust its instructions to provide further information. In addition, user competence information can be used to adjust the system's parameters, such as the timeout values of automatic speech recognition (ASR), which reduces the number of misinterpretations and interruptions. In addition, it can be used in offline processes to identify problems caused by a lack of expertise, which is important for the development of better dialog systems.In this article, we present an analysis of different features and how they can be used to identify a user's expertise on the rest of the Section 15, as described in this section below."}, {"heading": "2 Related Work", "text": "A system that behaves the same for all users, regardless of their expertise, however, cannot provide a truly usable user interface for any of them. Knowing the level of expertise of its users, a system could improve the quality of interaction through customization techniques at this level [13]. However, not much effort has been put into determining the level of expertise of a user, especially in dialogue-based interactions.Hjalmarsson [9] analyzed the dialogue dynamics and discussed the benefits of creating adaptive spoken dialogue systems and individual user models. She suggests that such models can be created using both rule-based and statistical approaches [8]. Given the correct set of rules, rule-based models perform well on specific tasks. However, they must be handcrafted by the intuition of the designer or expert, which is a time-consuming process."}, {"heading": "3 Relevant Features", "text": "Since expertise depends on the task to be accomplished, it cannot be identified by large quantities of generic acoustic characteristics as extracted from openSMILE [5]. Therefore, a small set of task-oriented characteristics needs to be designed. These characteristics can be divided into different categories depending on their origin and the aspects they intend to cover. In the following sections, we will describe each of these categories."}, {"heading": "3.1 Interruptions", "text": "Experienced users can interrupt the system if they are aware of the full dialog flow. However, this is not a good approach if system utterances are confirmation prompts that contain only the information to be confirmed at the end. In this case, interruptions usually signal a novice. In addition, cases where the system interrupts the user may also reveal a novice using long sentences or pauses that exceed the system's waiting times."}, {"heading": "3.2 Delays", "text": "Negative delays between the system and the utterances of the user mean an interruption that has the effects described above. On the other hand, long delays indicate that the user is still processing the utterance of the system and is not sure what to say, and can therefore show inexperience."}, {"heading": "3.3 Durations", "text": "Long call times are typically more discriminatory than short ones and can indicate inexperience. Thus, a long call usually means that something went wrong during the dialog. Long statements also indicate inexperience, as they are more susceptible to detection errors and system interruptions."}, {"heading": "3.4 Speech Rate", "text": "The language rate is also a possible indicator of a user's expertise, as both high and low language rates can lead to communication problems. While high language rates lead to higher error rates in recognition, low language rates are associated with pauses, which are more susceptible to being interrupted by the system. Therefore, expert users generally maintain a balanced language rate."}, {"heading": "3.5 Help Requests", "text": "When a user is new to a system and unsure of how it works, he or she typically asks for help, revealing inexperience. This is especially evident in cases where the system offers help and the user accepts it immediately. Unfortunately, some systems do not offer help functionality or the user is unaware of its existence."}, {"heading": "4 Experimental Setup", "text": "This section describes our experimental setup, starting with the data sets used. Subsequently, the characteristics used and their distribution in the training data set are thoroughly presented and then the classification and evaluation approaches used are descripted.4"}, {"heading": "4.1 Datasets", "text": "In our experiments, we used the LEGO [16] corpus. This corpus is a subset of 347 Let's Go calls during 2006. However, the corpus contains user-level notes to identify expertise, such as information and duration. At the expert level, the original corpus is not annotated, so we annotated each call with two labels - Expert and Novice. Of the 347 calls, 80 were marked as vice."}, {"heading": "4.2 Features", "text": "This year, the time has come for an agreement to be reached, and it will only take a few days."}, {"heading": "4.3 Classification", "text": "The distinction between beginners and experts is a binary classification task. Of the various classification approaches that can be used, we chose Support Vector Machines (SVMs) [3] because it is a widely used approach and usually produces acceptable results, and Random Forest (RF) [2], an approach based on decision trees specified for this task based on the distribution of our properties between the two classes. To train our SVMs, we used the Sequential Minimal Optimization (SMO) algorithm [14] provided by the Weka toolkit [6]. We used the linear kernel and kept the C parameter at its default value of 1.0. 7 We opted for an RF approach because of its improved performance compared to a classic decision tree algorithm. We also used the implementation of the Weka toolkit to train our RFs. We used 1,000 of the generated trees as a good compromise between classification time and training time."}, {"heading": "4.4 Evaluation", "text": "Since there is no standard division of the LEGO corpus into training sets and test sets, we obtained results through ten-fold cross-validation. In addition, we used the 2014 data to assess the generalizability of our classifiers. In terms of metrics, we use Accuracy and Kappa statistics, as they are the most indicated metrics to evaluate the performance and relevance of this task. Accuracy is the ratio between the number of correct predictions and the total number of predictions. The Kappa statistics indicates the weighted match between the predictions of the classifier and the gold standard in relation to those of a random classifier."}, {"heading": "5 Results", "text": "In fact, most of them are able to determine for themselves what they want and what they want."}, {"heading": "6 Conclusions", "text": "In this article, we presented an approach to automatically distinguish between beginners and experts based on certain task-related characteristics. Given the distribution of characteristics, a decision-tree-based classification approach was demonstrated, which was confirmed when the RF approach outperformed the widely used SVMs in both versions of the LEGO corpus. Since this is a relatively unexplored task and the data set has not previously been commented on based on expertise, we cannot compare our results with other work. Nevertheless, we believe that the results obtained are positive, as our approach focused on determining the level of expertise from a single session without prior information about the user, which is a difficult task. In addition, we were able to obtain relevant results based on characteristics extracted only from the first round of each dialogue. This is important for quickly adapting the system to the user's expert level, as it provides a preliminary classification of this level that can be improved over the course of the dialogue."}, {"heading": "Acknowledgements", "text": "This work was supported by national funding from the Fundac, the Universidade de Lisboa and the EC H2020 project RAGE with reference UID / CEC / 50021 / 2013."}], "references": [{"title": "Random Forests", "author": ["L. Breiman"], "venue": "Machine Learning 45(1), 5\u201332", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2001}, {"title": "Support-Vector Networks", "author": ["C. Cortes", "V. Vapnik"], "venue": "Machine Learning. pp. 273\u2013 297", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1995}, {"title": "Mind over Machine: The Power of Human Intuition and Expertise in the Era of the Computer", "author": ["H.L. Dreyfus", "S.E. Dreyfus"], "venue": "The Free Press, New York, NY, USA", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1986}, {"title": "Recent Developments in openSMILE, the Munich Open-source Multimedia Feature Extractor", "author": ["F. Eyben", "F. Weninger", "F. Gross", "B. Schuller"], "venue": "Proceedings of the 21st ACM International Conference on Multimedia. pp. 835\u2013838", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "The WEKA Data Mining Software: An Update", "author": ["M. Hall", "E. Frank", "G. Holmes", "B. Pfahringer", "P. Reutemann", "I.H. Witten"], "venue": "SIGKDD Exploration Newsletter 11(1), 10\u201318", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2009}, {"title": "Adaptation of an Automotive Dialogue System to Users\u2019 Expertise and Evaluation of the System", "author": ["L. Hassel", "E. Hagen"], "venue": "Language Resources and Evaluation 40(1), 67\u201385", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2006}, {"title": "Adaptive Spoken Dialogue Systems (2005), available at http://www.speech.kth.se/~rolf/NGSLT/gslt_papers_2004/annah_termpaper_05.pdf on", "author": ["A. Hjalmarsson"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "Towards User Modelling in Conversational Dialogue Systems: A Qualitative Study of the Dynamics of Dialogue Parameters", "author": ["A. Hjalmarsson"], "venue": "Proceedings of INTERSPEECH 2005. pp. 869\u2013872", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2005}, {"title": "User Expertise Modeling and Adaptivity in a Speech-Based E-Mail System", "author": ["K. Jokinen", "K. Kanto"], "venue": "Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics. pp. 87\u201394", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2004}, {"title": "The SpeDial Datasets: Datasets for Spoken Dialogue System Analytics", "author": ["J. Lopes", "A. Chorianopoulou", "E. Palogiannidi", "H. Moniz", "A. Abad", "K. Louka", "E. Iosif", "A. Potamianos"], "venue": "Proceedings of the 10th International Conference on Language Resources and Evaluation (LREC)", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2016}, {"title": "Evaluation of a Live Broadcast News Subtitling System for Portuguese", "author": ["H. Meinedo", "M. Viveiros", "Neto", "J.a."], "venue": "Proceedings of INTERSPEECH 2008. pp. 508\u2013511", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2008}, {"title": "Usability Engineering", "author": ["J. Nielsen"], "venue": "Morgan Kaufmann Publishers Inc., San Francisco, CA, USA", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1993}, {"title": "Fast Training of Support Vector Machines using Sequential Minimal Optimization", "author": ["J. Platt"], "venue": "Advances in Kernel Methods - Support Vector Learning. MIT Press", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1998}, {"title": "Doing Research on a Deployed Spoken Dialogue System: One Year of Lets Go! Experience", "author": ["A. Raux", "D. Bohus", "B. Langner", "A.W. Black", "M. Eskenazi"], "venue": "Proceedings of INTERSPEECH 2006. pp. 65\u201368", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2006}, {"title": "A Parameterized and Annotated Spoken Dialog Corpus of the CMU Let\u2019s Go Bus Information System", "author": ["A. Schmitt", "S. Ultes", "W. Minker"], "venue": "Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC)", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2012}], "referenceMentions": [{"referenceID": 13, "context": "In this article we present an analysis of different features and how they can be used to identify the level of expertise of a user on Let\u2019s Go [15] data.", "startOffset": 143, "endOffset": 147}, {"referenceID": 11, "context": "By knowing the level of expertise of its users, a system could improve the quality of the interaction through adaptation techniques based on that level [13].", "startOffset": 152, "endOffset": 156}, {"referenceID": 7, "context": "Hjalmarsson [9] analyzed dialog dynamics and discussed the utility of creating adaptive spoken dialog systems and individual user models.", "startOffset": 12, "endOffset": 15}, {"referenceID": 6, "context": "She suggests that such models can be created using both rule-based and statistical approaches [8].", "startOffset": 94, "endOffset": 97}, {"referenceID": 5, "context": "Hassel and Hagen [7] developed an automotive dialog system that adapts to its users\u2019 expertise.", "startOffset": 17, "endOffset": 20}, {"referenceID": 8, "context": "Jokinen and Kanto [10] used user expertise modelling to enable the adaptation of a speech-based e-mail system.", "startOffset": 18, "endOffset": 22}, {"referenceID": 2, "context": "They distinguish three levels of expertise \u2013 Novice, Competent, and Expert \u2013, a subset of the five proposed by Dreyfus and Dreyfus [4] in their studies about the behaviour of expert systems.", "startOffset": 131, "endOffset": 134}, {"referenceID": 3, "context": "Since expertise depends on the task being performed, it cannot be identified by large sets of generic acoustic features such as the ones extracted by openSMILE [5].", "startOffset": 160, "endOffset": 163}, {"referenceID": 13, "context": "We explored user expertise on data extracted from interactions with the Let\u2019s Go Bus Information System [15], which provides information about bus schedules, through spoken telephonic interaction with a dialog system.", "startOffset": 104, "endOffset": 108}, {"referenceID": 14, "context": "In our experiments we used the LEGO [16] corpus.", "startOffset": 36, "endOffset": 40}, {"referenceID": 9, "context": "This set was annotated for expertise at KTH using the same two labels \u2013 Expert and Novice [11].", "startOffset": 90, "endOffset": 94}, {"referenceID": 10, "context": "The phones for each utterance were obtained using the neural networks included in the AUDIMUS [12] ASR system.", "startOffset": 94, "endOffset": 98}, {"referenceID": 1, "context": "From the multiple classification approaches that could be used, we opted Support Vector Machines (SVMs)[3], since it is a widely used approach and typically produces acceptable results, and Random Forest (RF) [2], an approach based on decision trees, which are indicated for this task, given the distribution of our features among the two classes.", "startOffset": 103, "endOffset": 106}, {"referenceID": 0, "context": "From the multiple classification approaches that could be used, we opted Support Vector Machines (SVMs)[3], since it is a widely used approach and typically produces acceptable results, and Random Forest (RF) [2], an approach based on decision trees, which are indicated for this task, given the distribution of our features among the two classes.", "startOffset": 209, "endOffset": 212}, {"referenceID": 12, "context": "To train our SVMs, we took advantage of the Sequential Minimal Optimization (SMO) algorithm [14] implementation provided by the Weka Toolkit [6].", "startOffset": 92, "endOffset": 96}, {"referenceID": 4, "context": "To train our SVMs, we took advantage of the Sequential Minimal Optimization (SMO) algorithm [14] implementation provided by the Weka Toolkit [6].", "startOffset": 141, "endOffset": 144}], "year": 2017, "abstractText": "Identifying the level of expertise of its users is important for a system since it can lead to a better interaction through adaptation techniques. Furthermore, this information can be used in offline processes of root cause analysis. However, not much effort has been put into automatically identifying the level of expertise of an user, especially in dialog-based interactions. In this paper we present an approach based on a specific set of task related features. Based on the distribution of the features among the two classes \u2013 Novice and Expert \u2013 we used Random Forests as a classification approach. Furthermore, we used a Support Vector Machine classifier, in order to perform a result comparison. By applying these approaches on data from a real system, Let\u2019s Go, we obtained preliminary results that we consider positive, given the difficulty of the task and the lack of competing approaches for comparison.", "creator": "LaTeX with hyperref package"}}}