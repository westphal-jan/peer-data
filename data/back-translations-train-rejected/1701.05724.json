{"id": "1701.05724", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Jan-2017", "title": "Logical Inferences with Contexts of RDF Triples", "abstract": "Logical inference, an integral feature of the Semantic Web, is the process of deriving new triples by applying entailment rules on knowledge bases. The entailment rules are determined by the model-theoretic semantics. Incorporating context of an RDF triple (e.g., provenance, time, and location) into the inferencing process requires the formal semantics to be capable of describing the context of RDF triples also in the form of triples, or in other words, RDF contextual triples about triples. The formal semantics should also provide the rules that could entail new contextual triples about triples. In this paper, we propose the first inferencing mechanism that allows context of RDF triples, represented in the form of RDF triples about triples, to be the first-class citizens in the model-theoretic semantics and in the logical rules. Our inference mechanism is well-formalized with all new concepts being captured in the model-theoretic semantics. This formal semantics also allows us to derive a new set of entailment rules that could entail new contextual triples about triples. To demonstrate the feasibility and the scalability of the proposed mechanism, we implement a new tool in which we transform the existing knowledge bases to our representation of RDF triples about triples and provide the option for this tool to compute the inferred triples for the proposed rules. We evaluate the computation of the proposed rules on a large scale using various real-world knowledge bases such as Bio2RDF NCBI Genes and DBpedia. The results show that the computation of the inferred triples can be highly scalable. On average, one billion inferred triples adds 5-6 minutes to the overall transformation process. NCBI Genes, with 20 billion triples in total, took only 232 minutes for the transformation of 12 billion triples and added 42 minutes for inferring 8 billion triples to the overall process.", "histories": [["v1", "Fri, 20 Jan 2017 08:51:41 GMT  (263kb,D)", "http://arxiv.org/abs/1701.05724v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.DB", "authors": ["vinh nguyen", "amit sheth"], "accepted": false, "id": "1701.05724"}, "pdf": {"name": "1701.05724.pdf", "metadata": {"source": "CRF", "title": "Logical Inferences with Contexts of RDF Triples", "authors": ["Vinh Nguyen", "Amit Sheth"], "emails": ["vinh@knoesis.org", "amit@knoesis.org", "info@vldb.org."], "sections": [{"heading": null, "text": "In this paper, we propose the first follow-up mechanism that enables the context of the RDF triples, represented in the form of RDF triples over triples, to be world-class citizens in model theoretical semantics and logical rules. Our follow-up mechanism is well formalized, as all new concepts are captured in model theoretical semantics. This formal semantics also allows us to derive a new set of follow-up rules that could entail new contextual triples over triples. To demonstrate the feasibility and scalability of the proposed mechanism, we implement a new tool in which we apply the existing knowledge base to our representation of RDF triples over triples and provide the option for this tool to calculate the resulting triples for the proposed rules."}, {"heading": "1. INTRODUCTION", "text": "In fact, most of them will be able to play by the rules they have set themselves."}, {"heading": "1.1 Motivating Example", "text": "Given a statement \"Barack Obama is married to Michelle Obama\" (T1), and a sub-ownership relationship between isMarriedTo and isSpouseOf (T2), applying rule rdfs7 [14] ar Xiv: 170 1,05 724v 1 [cs.A I] 2 0Ja n20 17for rdfs: subPropertyOf on the two triples will be the new triple \"Barack Obama is a spouse of Michelle Obama\" (T3).T1: BarackObama isMarriedTo MichelleObama. T2: isMarriedTo subPropertyOf isSpouseOf. T3: BarackObama isSpouseOf MichelleObama. These triples would provide enough knowledge to answer simple questions. Who is Barack Obama married to? Or who is spouse of Barack Obama? However, these triples do not provide enough knowledge to provide answers to more complex questions."}, {"heading": "1.2 Approach", "text": "This year, it is closer than ever before to being able to reform and reform itself."}, {"heading": "2. CONCEPTUAL MODEL", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Preliminaries", "text": "Here we recall the singleton property concept with its syntax and semantics from [22]. A singleton property is a specific property instance that represents a unique relationship in a specific context. In this example, the singleton property MarriedTo # 1 is clearly the isMarriedTo relationship between BarackObama and MichelleObama. This singleton property can be asserted with contextual information \"in Chicago\" about the relationship as follows: SP1: Barackleton Obama is MarriedTo # 1 MichelleObama. SP2: isMarriedTo # 1 singletonPropertyOf isMarriedTo. SP3: isMarriedTo # 1 occurred in Chicago. Formal semantics. Here we recall the mapping function IEXT from current model theoretical semantics [15]. A property mapping function IEXT is a binary relationship that is a property on a set of resources.Formally a property is a property."}, {"heading": "2.2 Property Types", "text": "A generic property asserts the relationship between the subject and the object without additional contextual information about the relationship. This property groups together all singleton properties that have the same properties across contexts, and is available via the property singletonPropertyOf.SP2: isMarriedTo # 1 singletonPropertyOf isMarriedTo. In this example, isMarriedTo is a generic property. Here we propose to add the new class GenericProperty to represent the set of generic properties, in addition to the class SingletonProperty from [22]. Any property that is not defined as a singleton property can become a generic property. Intuitively, a generic property is mapped to a set of pairs, while the singleton property is mapped to a single pair. If a singleton property also plays the role of a generic property, it will appear as a generic property of a generic property."}, {"heading": "2.3 Triple Types", "text": "Similar to distinguishing property types, we can distinguish the type of a triple based on the type of its property, the three types of properties form three types of triples: Singleton, Generic and Regular Triple. A Singleton Triple is the only triple whose singleton property occurs as a predicate. A generic triple is a triple in which its predicate is asserted as a generic trait. A regular triple is a triple in which its predicate is not a generic or singleton property. Singleton: BarackObama is Married To # 1 MichelleObama. Generic: BarackObama is Married To MichelleObama. Regulatory: Chicago partOf Illinois. Distinguishing triple types based on context. The three types of properties form three types of triples: context-associated, context-disassociated and contextagnostic Triple. A contextual triple is a triple that can have singleton-related information about it."}, {"heading": "2.4 Contextual triple instantiation", "text": "Back to the motivational example: We have presented the original statement \"Barack Obama married to Michelle Obama in Chicago\" as follows: T1: BarackObama isMarriedTo MichelleObama. T4: T1 happened in Chicago. We use the Singleton property diagram to bridge the gap between the primary Triple T1 and its identifier as explained in Section 2.1.SP1: BarackObama isMarriedTo # 1 MichelleObama. SP2: isMarriedTo # 1 singletonPropertyOf isMarriedTo # 1 happenIn Chicago. This Singleton property diagram represents the primary Triple T1 and its Meta Triple T4 by creating a Singleton property isMarriedTo # 1 and using it as a triple identification for the claim of Meta-TripledTo. Of Triple SP2, MarriedTo # 1 is the Singleton property and isMarriedTo is the generic form."}, {"heading": "3. MODEL-THEORETIC SEMANTICS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Mapping Functions", "text": "& & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & &"}, {"heading": "3.2 Simple Interpretation", "text": "In simple interpretation, we formalize the three types of properties as described in Section 2. We also use the mapping functions described in Section 3.1 to assign each property to a semantic construct. Given Vocabulary V, simple interpretation I consists of: 1. IR, a non-empty set of resources, alternatively as the domain or discourse universe of I, 2. IP, the set of properties of I, 3. IPs, referred to as the set of singleton properties of I, as a subset of IP, 4. IPg, referred to as the set of generic properties of I, as a subset of IP, IPs and IPs, namely IPg, 5. IPr, referred to as the set of regular properties, IPr = IP (IPs and IPg), 6. IG, a function that assigns a generic property to a group of its singleton properties, 7. IEXT, a mapping function that assigns a group of IR to each property."}, {"heading": "3.3 RDF Interpretation", "text": "In the RDF interpretation, we formalize the definition of singleton ownership, generic ownership, and how to derive generic ownership from a singleton diagram. < g) If it meets the criteria of the current RDF interpretation (15) and the following criteria: 1. Define singleton ownership xs-IPs iff < xs, rdf: singleton ownership I > IR (rdf: type I >.2 singleton condition If xs-IPs condition). < u, v > xs: < u, v > IS EXT (xs), and u, v: ownership IR. This forces the singleton condition on the property IPs."}, {"heading": "3.4 RDFS Interpretation", "text": "rE \"s guides for the lead, for the lead, for the lead, for the lead, for the lead, for the lead, for the lead, for the lead, for the lead, for the lead, for the lead, for the lead, for the lead, for the lead, for the lead, for the lead, for the lead, for the lead, for the lead, for the lead, for the lead, for the lead, for the lead, for the lead, for the lead, for the lead, for the lead, for the lead, for the lead, for the lead, for the lead, for the lead, for the lead, for the lead, for the lead, for the lead, for the lead, for the lead.\""}, {"heading": "3.5 OWL 2 RDF-based Semantic Conditions", "text": "From the RDF-based semantics of OWL 2 Full [23], we consider the semantic conditions of the OWL classes and properties that are relevant for individual properties. < S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S) S (S) S (S) S) S (S) S (S) S (S) S (S) S \"S (S) S\" S (S) S \"S (S) S\" S \"S (S) S\" S (S) S \"S (S) S (S) S (S) S (S) S\" S (S) S \"S (S) S\" S (S) S \"S (S) S (S) S\" S (S) S (S) S (S) S \"S (S) S (S) S (S) S\" S) S (S) S (S) S (S) S (S) S (S) S) S (S) S (S) S (S) S (S) S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S (S) S (S) S \"S (S) S\" S (S) S \"S (S) S\" S (S) S (S \"S\" S (S) S \"S (S) S (S (S) S (S (S) S (S) S (S) S\" S (S) S (S (S) S (S) S (S (S) S (S) S (S) S (S) S (S) S (S) S (S (S) S (S) S (S) S (S (S) S (S) S (S) S (S (S) S (S) S (S) S (S) S ("}, {"heading": "4. CONTEXTUAL INFERENCES", "text": "In the full interpretations of EBS, EFSF and OWL 2, we have several deduction rules in Section 3. Here we present a number of these rules in Section 4.1 and show how these rules can be applied to derive the conclusions described in the motivational example in Section 4.2."}, {"heading": "4.1 Contextual Entailment Rules", "text": "The three following rdf-sp rules are from the RDF interpretation.u rdf: singletonPropertyOf v.u rdf: type rdf: SingletonProperty. (rdf-sp-1) u rdf: singletonPropertyOf v.v rdf: type rdf: GenericProperty. (rdf-sp-2) u rdf: singletonPropertyOf v. v rdfs: domain x.u rdfs: domain x. (rdf-sp-3) u rdf: Property: singletonProperty of v: Genericy.u The four rdf-sp-sp rules are from the RDFS interpretation.u rdf: Property: Property dfs-df: Property-df."}, {"heading": "4.2 Contextual Inferencing", "text": "Returning to the motivational example, from the contextual statement \"BarackObama is married to Michelle Obama in Chicago,\" we as humans can derive a list of statements (S1 to S5) as shown in Table 1. Here, step by step, we show how to deduce statements Michelle Obama S1 to S5 from the original explanation. Our initial knowledge base includes the singleton property diagrams that represent the original contextual statement and background knowledge as follows: SP1: BarackObama-MarriedTo # 1 MichelleObama-S5 singletonPropertyOf isMarriedTo # 3: isMarriedTo # 1 happenedIn Chicago # 1 happened.T2: isMarriedTo subPropertyOf isSpouseOf Illinois Illinois-Obama. T6: Illinois-PropertyOf USA.Assume that we also have a partOf rule, the x rule that happens in a place that is part of a larger place, then x also happens in the place z."}, {"heading": "5. IMPLEMENTATION", "text": "Here we explain how to calculate all derived triples based on the proposed follow-up rules for existing knowledge databases in two steps. First, we describe how to transform the existing knowledge databases into the singleton property representation, then, Section 5.2 describes how all proposed rules for each triples in the resulting knowledge databases are calculated."}, {"heading": "5.1 Transforming Representation", "text": "As we discussed in Section 1 above, knowledge databases such as DBpedia and Bio2RDF represent contextual information such as quad provenance. Before calculating the derived triples for these records, we need to prepare the knowledge databases by transforming them into the Singleton property representation. Faced with a quad in the form of (s, p, o, g), we transform them into the Singleton property representation by creating a Singleton property representation (spi, singletonPropertyOf, p) and asserting the Singleton property representation (s, spi, o). We use the property wasDerivedFrom of PROV ontology [19] to represent the provenance of the triple (spi, prov: wasDerivedFrom, g). The Singleton property URIs are constructed by appending a unique string to the total number of datasets with a unique property."}, {"heading": "5.2 Computing Inferred Triples", "text": "Running all context-dependent rules on each singleton triple generates at least two more triples (rdf-sp-1 and rdfsp-3), increasing the number of context-dependent triples to several billion with datasets such as DBpedia and Bio2RDF. This amount of derived triples does not fit an in-memory argumentator such as Jena [10]. The proposed context rules can also be calculated in the argumentators with the support of user-defined rules such as Oracle [18]. However, for the rules that generate a large number of derived triples, optimization is necessary, since Oracle has optimized the calculation of the large number of derived triples for the owl: sameAs [18]. Without performing such an optimization step in the existing motors, it is time consuming to query the rule patterns and insert the derived triples into memory, because the proposed context rules are always expensive."}, {"heading": "6. EVALUATION", "text": "With the tool rdf-contextualizer based on real knowledge, we evaluate the performance of the triple calculators derived from the proposed rules on a large scale."}, {"heading": "6.1 Experiment Setup", "text": "We use a single server installed with Ubuntu 12.04. It has 24 cores, each core is Intel Xeon CPU 2.60GHz. We use two hard drives, one SSD 220GB for storing input data and one hard drive 2.7T for writing output. This server has 256GB of RAM, limiting 60GB for each Java program."}, {"heading": "6.2 Datasets", "text": "We have downloaded the ontologies and RDF quad datasets from DBpedia [6] and four Bio2RDF datasets, including NCBI genes [4], PharmGKB [5], CTD [1] and GO Annotations [2], in our review. We have chosen these quad datasets because they are large and used with great effect in the community. For Bio2RDF datasets, we have also downloaded the Bio2RDF mapping files [3]. We have specified the number of RDF quads per dataset in the first and second columns of Table 2. The dataset identifier is taken from the first 3 letters of its name. We have observed that there were too many duplicate quads among the files within each dataset. We also believe that the duplicates can be created intentionally. Each of these datasets has a number of files and each file contains a number of DF quads for a theme."}, {"heading": "6.3 Results", "text": "We consider four dimensions in our assessment: number of individual cases, number of individual cases, number of individual cases, number of individual cases, number of individual cases, number of individual cases, number of individual cases, number of individual cases, number of individual cases, number of individual cases, number of individual cases, number of individual cases, number of individual cases, number of individual cases, number of individual cases, number of individual cases, number of individual cases, number of individual cases, number of individual cases, number of individual cases, number of individual cases, number of individual cases, number of individual cases, number of individual cases, number of individual cases, number of individual cases, number of individual cases, number of individual cases, number of individual cases, number of individual cases, number of individual cases, number of individual cases, number of individual cases, number of individual cases, number of individual cases, number of individual cases, number of individual cases, number of detail, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of details, number of"}, {"heading": "7. RELATED WORK", "text": "We can divide these approaches into three categories: triple (reification, singleton property), quadruple (named graph), and fivefold (RDF + [24]). However, logical conclusions with contextual information about triple remain largely underdeveloped due to the lack of a model theoretical semantics that would determine the rules of dissociation. Without such model theoretical semantics, we can come up with some rules by using the syntax of RDF reification to simulate our proposed rules. Nevertheless, these syntactic rules are not logically valid, since they are neither logically derived from model theoretical semantics nor proven in model theoretical semantics. Therefore, we have chosen the singleton property approach over other approaches to develop the proposed mechanism of deduction, which is mainly associated with formal semantics of temporality."}, {"heading": "8. DISCUSSION AND FUTURE WORK", "text": "The proposed conclusions with the proposed rules can also be implemented in the triple stores for answering SPARQL queries based on the triples derived from the proposed rules. We also believe that the proposed inference mechanism will benefit several applications, such as streaming reasoning, time reasoning, tracking context of derived triples and answering questions based on extracted knowledge and logical conclusions. Performance is the real challenge for semantic web reasoning in general, and also for the proposed inferencing mechanism, especially on the web scale. Derived triples can be calculated using SPARQL INSERT query to find the rule patterns and insert the matching triples into triple stores. However, this approach is not scalable as quantification is costly."}, {"heading": "9. CONCLUSION", "text": "Our proposed mechanism is theoretically sound and computationally scalable. Our model theoretical semantics represents the contextual statements as first-class citizens and enables them to be derived with the proposed entropy rules. Furthermore, we demonstrated the feasibility and scalability of calculating inferred triples based on the proposed entropy rules in various real knowledge bases."}, {"heading": "10. REFERENCES", "text": "[1] Bio2rdf ctd release 3.http: / / download.bio2rdf.org / release / J. Hoffory 93 / 3 / ctd /. [2] Bio2rdf goa release 3. http: / / download.bio2rdf.org / release / 3 / goa /. [3] Bio2rdf mappings. https: / / github.com / bio2rdf / bio2rdf-mapping. [4] Bio2rdf ncbi genes release 3. http: / / download.bio2rdf.org / release / 3 / ncbigene. 2012 Bio2rdf pharmacgkb release 3. / download.bio2rdf G. ncbi genes release 3. P. bio2rdf.org / release."}], "references": [{"title": "Bio2rdf: towards a mashup to build bioinformatics knowledge systems", "author": ["F. Belleau", "M. Nolin", "N. Tourigny", "P. Rigault", "J. Morissette"], "venue": "Journal of biomedical informatics,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2008}, {"title": "Named graphs. Web Semantics: Science, Services and Agents on the World", "author": ["J.J. Carroll", "C. Bizer", "P. Hayes", "P. Stickler"], "venue": "Wide Web,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2005}, {"title": "Jena: implementing the semantic web recommendations", "author": ["J.J. Carroll", "I. Dickinson", "C. Dollin", "D. Reynolds", "A. Seaborne", "K. Wilkinson"], "venue": "In Proceedings of  the 13th international World Wide Web conference on Alternate track papers & posters,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2004}, {"title": "Knowledge vault: A web-scale approach to probabilistic knowledge fusion", "author": ["X. Dong", "E. Gabrilovich", "G. Heitz", "W. Horn", "N. Lao", "K. Murphy", "T. Strohmann", "S. Sun", "W. Zhang"], "venue": "In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "Exposing provenance metadata using different RDF models", "author": ["G. Fu", "E. Bolton", "N. Queralt-Rosinach", "L.I. Furlong", "V. Nguyen", "A.P. Sheth", "O. Bodenreider", "M. Dumontier"], "venue": "In Proceedings of the 8th SWAT4LS,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2015}, {"title": "Temporal rdf", "author": ["C. Gutierrez", "C. Hurtado", "A. Vaisman"], "venue": "In The Semantic Web: Research and Applications,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2005}, {"title": "Foundations of semantic web technologies", "author": ["P. Hitzler", "M. Krotzsch", "S. Rudolph"], "venue": "Chapman and Hall/CRC,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2011}, {"title": "Yago2: A spatially and temporally enhanced knowledge base from wikipedia", "author": ["J. Hoffart", "F.M. Suchanek", "K. Berberich", "G. Weikum"], "venue": "Artificial Intelligence,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2013}, {"title": "Optimizing enterprise-scale owl 2 rl reasoning in a relational database system", "author": ["V. Kolovski", "Z. Wu", "G. Eadon"], "venue": "In International Semantic Web Conference,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2010}, {"title": "Prov-o: The prov ontology", "author": ["T. Lebo", "S. Sahoo", "D. McGuinness"], "venue": "W3C. http://www. w3. org/TR/prov-o,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2012}, {"title": "Dbpedia\u2013a large-scale, multilingual knowledge base extracted from wikipedia", "author": ["J. Lehmann", "R. Isele", "M. Jakob", "A. Jentzsch", "D. Kontokostas", "P.N. Mendes", "S. Hellmann", "M. Morsey", "P. van Kleef", "S. Auer"], "venue": "Semantic Web,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2015}, {"title": "Slubm: An extended lubm benchmark for stream reasoning", "author": ["T.N. Nguyen", "W. Siberski"], "venue": "In OrdRing@ ISWC,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2013}, {"title": "Don\u2019t like rdf reification?: Making statements about statements using singleton property", "author": ["V. Nguyen", "O. Bodenreider", "A. Sheth"], "venue": "In Proceedings of the 23rd International Conference on World Wide Web,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2014}, {"title": "Owl 2 web ontology language: Rdf-based semantics (second edition)", "author": ["M. Schneider", "J. Carroll", "I. Herman", "P.F. Patel-Schneider"], "venue": "W3C Recommendation (December", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2012}, {"title": "Querying for meta knowledge", "author": ["B. Schueler", "S. Sizov", "S. Staab", "D.T. Tran"], "venue": "In Proceedings of the 17th World Wide Web Conference,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2008}, {"title": "Implementing an inference engine for rdfs/owl constructs and user-defined rules in oracle", "author": ["Z. Wu", "G. Eadon", "S. Das", "E.I. Chong", "V. Kolovski", "M. Annamalai", "J. Srinivasan"], "venue": "In Data Engineering,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2008}], "referenceMentions": [{"referenceID": 0, "context": ", Bio2RDF [8] and PubChem [12]).", "startOffset": 10, "endOffset": 13}, {"referenceID": 4, "context": ", Bio2RDF [8] and PubChem [12]).", "startOffset": 26, "endOffset": 30}, {"referenceID": 3, "context": ", Google Knowledge Vault [11], Yago2S [17], and DBpedia [20]).", "startOffset": 25, "endOffset": 29}, {"referenceID": 7, "context": ", Google Knowledge Vault [11], Yago2S [17], and DBpedia [20]).", "startOffset": 38, "endOffset": 42}, {"referenceID": 10, "context": ", Google Knowledge Vault [11], Yago2S [17], and DBpedia [20]).", "startOffset": 56, "endOffset": 60}, {"referenceID": 1, "context": "To bridge this gap and fulfill the requirement of representing contextual statements in machine-understandable form as discussed earlier, several approaches such as named graph [9], RDF reification [14], and singleton property [22] can be used for representing the relationship between a triple and its identifier.", "startOffset": 177, "endOffset": 180}, {"referenceID": 12, "context": "To bridge this gap and fulfill the requirement of representing contextual statements in machine-understandable form as discussed earlier, several approaches such as named graph [9], RDF reification [14], and singleton property [22] can be used for representing the relationship between a triple and its identifier.", "startOffset": 227, "endOffset": 231}, {"referenceID": 12, "context": "Here we recall the singleton property concept with its syntax and semantics from [22].", "startOffset": 81, "endOffset": 85}, {"referenceID": 12, "context": "Here we propose to add the new class GenericProperty to represent the set of generic properties, in addition to the class SingletonProperty from [22].", "startOffset": 145, "endOffset": 149}, {"referenceID": 6, "context": "We specify three interpretations: simple, RDF and RDFS by extending the model-theoretic semantics described in [16, 22].", "startOffset": 111, "endOffset": 119}, {"referenceID": 12, "context": "We specify three interpretations: simple, RDF and RDFS by extending the model-theoretic semantics described in [16, 22].", "startOffset": 111, "endOffset": 119}, {"referenceID": 6, "context": "While we explain the new vocabulary elements in detail, elements without further explanation remain as they are in the original model-theoretic semantics described in [16, 22].", "startOffset": 167, "endOffset": 175}, {"referenceID": 12, "context": "While we explain the new vocabulary elements in detail, elements without further explanation remain as they are in the original model-theoretic semantics described in [16, 22].", "startOffset": 167, "endOffset": 175}, {"referenceID": 13, "context": "From the RDF-based semantics of OWL 2 Full [23], we consider the semantic conditions of the OWL classes and properties that are relevant to singleton properties.", "startOffset": 43, "endOffset": 47}, {"referenceID": 13, "context": "OWL 2 RDF-based interpretation of a vocabulary V is an RDFS interpretation I of the vocabulary V \u222a VOWL that satisfies criteria from the OWL interpretation [23] and the following semantic conditions:", "startOffset": 156, "endOffset": 160}, {"referenceID": 9, "context": "We use the property wasDerivedFrom from the PROV ontology [19] to represent the provenance of the triple (spi, prov:wasDerivedFrom, g).", "startOffset": 58, "endOffset": 62}, {"referenceID": 2, "context": "That amount of inferred triples cannot fit an in-memory reasoner such as Jena [10].", "startOffset": 78, "endOffset": 82}, {"referenceID": 15, "context": "The proposed entailment rules can also be computed in the reasoners with the support for user-defined rules such as Oracle [25].", "startOffset": 123, "endOffset": 127}, {"referenceID": 8, "context": "However, for the rules generating a large number of inferred triples, optimization is necessary as Oracle has optimized the computation of large number of inferred triples for owl:sameAs [18].", "startOffset": 187, "endOffset": 191}, {"referenceID": 14, "context": "We can classify these approaches into three categories: triple (reification, singleton property), quadruple (named graph), and quintuple (RDF+ [24]).", "startOffset": 143, "endOffset": 147}, {"referenceID": 11, "context": "The stream reasoning [21] where the temporal dimension is not represented directly in RDF may benefit from our work as it allows the temporal dimension to be incorporated within the RDF syntax.", "startOffset": 21, "endOffset": 25}, {"referenceID": 5, "context": "The temporal RDF [13] incorporates temporal reasoning into RDF using reification.", "startOffset": 17, "endOffset": 21}], "year": 2017, "abstractText": "Logical inference, an integral feature of the Semantic Web, is the process of deriving new triples by applying entailment rules on knowledge bases. The entailment rules are determined by the model-theoretic semantics. Incorporating context of an RDF triple (e.g., provenance, time, and location) into the inferencing process requires the formal semantics to be capable of describing the context of RDF triples also in the form of triples, or in other words, RDF contextual triples about triples. The formal semantics should also provide the rules that could entail new contextual triples about triples. In this paper, we propose the first inferencing mechanism that allows context of RDF triples, represented in the form of RDF triples about triples, to be the first-class citizens in the model-theoretic semantics and in the logical rules. Our inference mechanism is well-formalized with all new concepts being captured in the model-theoretic semantics. This formal semantics also allows us to derive a new set of entailment rules that could entail new contextual triples about triples. To demonstrate the feasibility and the scalability of the proposed mechanism, we implement a new tool in which we transform the existing knowledge bases to our representation of RDF triples about triples and provide the option for this tool to compute the inferred triples for the proposed rules. We evaluate the computation of the proposed rules on a large scale using various real-world knowledge bases such as Bio2RDF NCBI Genes and DBpedia. The results show that the computation of the inferred triples can be highly scalable. On average, one billion inferred triples adds 5-6 minutes to the overall transformation process. NCBI Genes, with 20 billion triples in total, took only 232 minutes for the transformation of 12 billion triples and added 42 minutes for inferring 8 billion triples to the overall process.", "creator": "LaTeX with hyperref package"}}}