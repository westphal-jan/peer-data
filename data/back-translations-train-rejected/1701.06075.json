{"id": "1701.06075", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Jan-2017", "title": "Label Propagation on K-partite Graphs with Heterophily", "abstract": "In this paper, for the first time, we study label propagation in heterogeneous graphs under heterophily assumption. Homophily label propagation (i.e., two connected nodes share similar labels) in homogeneous graph (with same types of vertices and relations) has been extensively studied before. Unfortunately, real-life networks are heterogeneous, they contain different types of vertices (e.g., users, images, texts) and relations (e.g., friendships, co-tagging) and allow for each node to propagate both the same and opposite copy of labels to its neighbors. We propose a $\\mathcal{K}$-partite label propagation model to handle the mystifying combination of heterogeneous nodes/relations and heterophily propagation. With this model, we develop a novel label inference algorithm framework with update rules in near-linear time complexity. Since real networks change over time, we devise an incremental approach, which supports fast updates for both new data and evidence (e.g., ground truth labels) with guaranteed efficiency. We further provide a utility function to automatically determine whether an incremental or a re-modeling approach is favored. Extensive experiments on real datasets have verified the effectiveness and efficiency of our approach, and its superiority over the state-of-the-art label propagation methods.", "histories": [["v1", "Sat, 21 Jan 2017 19:47:38 GMT  (228kb,D)", "http://arxiv.org/abs/1701.06075v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.SI", "authors": ["dingxiong deng", "fan bai", "yiqi tang", "shuigeng zhou", "cyrus shahabi", "linhong zhu"], "accepted": false, "id": "1701.06075"}, "pdf": {"name": "1701.06075.pdf", "metadata": {"source": "CRF", "title": "Label Propagation on K-partite Graphs with Heterophily", "authors": ["Dingxiong Deng", "Fan Bai", "Yiqi Tang", "Shuigeng Zhou", "Cyrus Shahabi", "Linhong Zhu"], "emails": ["dingxiod@usc.edu", "sgzhou@fudan.edu.cn", "shahabi@usc.edu", "linhong@isi.edu"], "sections": [{"heading": "1. INTRODUCTION", "text": "It is a process that each vertex has undergone in many areas, such as spam detection [1], fraud detection [10], sentiment analysis [15], and graph score sharing [35], but which has recently received renewed interest from academia and industry, as a result of which different forms of application have been proposed in many areas, such as spam detection [1], fraud detection [15], and graph sharing [11, 19, 33, 41, 44] all of these traditional algorithms simply assume that they are all of the same nature and limited to a single pair similarity. Unfortunately, many real networks, such as heterogenetic systems [3, 32, 38] are interlinked objects of different types and relationships."}, {"heading": "2. RELATED WORKS", "text": "In this section, we first present a comprehensive (but not exhaustive) overview of state-of-the-art approaches to label propagation and then discuss related work on the heterogeneous representation of graphs using K-partite graphs."}, {"heading": "2.1 Label Propagation", "text": "This year it has come to the point where one is able to remain in the first phase of ascension in the second phase of ascension to the second phase, and then remain in the second phase of ascension to the third phase."}, {"heading": "3. PROBLEM FORMULATION", "text": "It is not the first time that we have grappled with the question of to what extent we are able to identify with the question, to what extent we are able to identify with the question, to what extent we are able to identify with the question, to what extent we are able to identify with the question, to what extent we are able to identify with the question, to what extent we are able to identify with the question, to what extent we are able to identify with the question, to what extent we are able to identify with the question, to what extent we are able to identify with the question, to what extent we are able to identify with the question, to what extent we are able to identify with the question, to what extent we are able to identify with the question, to what extent we are able to identify with the question, to what extent we are able to move in the question, to what extent we are able to identify with the question, to what extent we are able to move in the question, to what question after question after question after question after question after question after question after question after question, to what degree we are able to identify with the question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question and to what sense after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after question after meaning and purpose after question after meaning and purpose after question after question after question after meaning and purpose after question after question after question after question after question after meaning and purpose after question after question after question after question after question after meaning and purpose after question after question after question after sense after sense after meaning and purpose after meaning and purpose after question after sense after sense after question after question after sense after sense after sense after sense after sense after sense after sense after sense after meaning and sense after"}, {"heading": "4. LABEL INFERENCE ALGORITHMS", "text": "In this section, we discuss the algorithmic issues related to label fraud. Specifically, our label fraud problem leads to an optimization problem that seeks the optimal weighted dispersion matrix. (1) Given these non-relativistic constraints, which require different approaches, it is necessary to propose the individual approaches to solve this non-convex optimization problem. (2) Among them, the multiplicative update rules [26] are the most popular approaches to achieving their effectiveness. (3) The multiplicative update approaches of the matrix are complemented by the multiplication of a positive coefficient at each point, while the additive update approach is a method of descent. To achieve the best of our knowledge, there is no existing work that unifies different updating rules in a framework.In this paper, we propose to combine these two updating rules in a uniform framework."}, {"heading": "4.1 Initialization", "text": "In order to achieve a better local optimum, a label inference algorithm should start from one or more relatively good initial assumptions. In this thesis, we focus on chart proximity-based initialization for label assignment matrix Y; while B matrix is initialized with observed label propagation information between the labeled seed verticals. Initialization Y Given the amount of labeled corners V L with soil truth label Y-Rnl-k, we can use the chart proximity to initialize the unlabeled corners with similarly labeled and the same type corners. Specifically, the label assignment matrix Y-type Y-0 can be labeled with the following label: Y-Rnl-k (u) if u-V L avgv-Vt (u) sim (u, v, G) Y-corners (v) otherwise (2) we can define the label assignment matrix Y-type Y-0 as the following labeling: Y-Rnl-k (u) if u-type is unified Eximity (u)."}, {"heading": "4.2 Update Y", "text": "As previously introduced, we perform vertex-centric updates for Y. That is, in each iteration, we focus on minimizing the following sub-targets: J (Y (u)) = [v] N (u) (G (u, v) \u2212 Y (u) T (u) T (u) T (v) Y (v) 2 + (v) N (u), t (v) 6 = t (u) (u) T (u) T (u) T (u) T (u) T (u) T (u) Y (u) Y (u) Y (u) - Y (u) - Y (u) - (u) N (4), where 1A (x) is the indicator function that is one when x (u) A \u2212 A and otherwise zero, N (u) is the neighbors of the vertex."}, {"heading": "4.3 Update B", "text": "Below we present the detailed rules for reproduction of B.Lemma 3 (multiplication rule for B. B). B can be derived from the following rule for updating: Btt \u2032 = Btt \u2032 - Y Tt \"Yt\" Y Tt \"Yt\" Yt \"+ (8) Proof: The proof for this rule is similar to Lemma 1 as shown in Appendix 7.3.Lemma 4 (additive rule for B. An alternative approximate solution for B can be derived from the following additive rule: Btt\" = max (, Btt \"+ 2\u03b7b (Y T\" Yt \"\u2212 Y Tt YtBtt\" Y Tt \"Yt\" Yt \"Yt\") (9), where \"b\" in turn denotes the step size. Proof this rule is easily derived by replacing the deviation from J (Btt \") with the standard gradient pedigree rule."}, {"heading": "4.4 Comparison and Analysis", "text": "We first show that the solution Y by the proposed multiplicative rule is identical to that by the traditional multiplicative rule, resulting in the following lemma.Lemma 5 Updating label assignment Y vertex by vertex using Lemma 1 is identical to the following traditional multiplicative rule [42]: Yt = Yt \"n is the label indicator matrix, from which Suu = 1 when u\" V \"l and zero for all other interventions, and St is the sub-matrix of S\" t. \"StYtwhere S\" Rn \"n is the label indicator matrix, from the Suu\" V \"L\" and zero for the sub-matrix of S for t-type vertices.Proof: The detailed proof is shown in Appendix 7.5. We then analyze the time complexity of calculating each basic operator in a single iteration."}, {"heading": "5. INCREMENTAL LABEL INFERENCE", "text": "In this section, we present our solution to the fundamental research question with practical relevance: How can we support fast, incremental updates of graph updates such as new labels and / or new nodes / edges? This is because charts and labels are constantly changing in practice. In the following, we will first develop an incremental algorithm that adaptively updates label mapping to new data, allowing us to control the trade-off between efficiency and accuracy. Then, we will explore another interesting question: under what condition is it faster to perform incremental updates than recalculate from scratch? To solve this problem, we propose a service function that examines the reward and cost of both update processes."}, {"heading": "5.1 Incremental Update Algorithm", "text": "Our incremental update supports both graph changes and label changes. The first scenario involves vertex / edge insertion and deletion; while label changes involve additional labels or correction of noise labels, we can assign labels for each vertex. A simple approach to graph / label updates is to revisit our label inference algorithms for the entire graph. However, this can be mathematically expensive. We therefore suggest incremental label mappings, where we do partial updates instead of full updates for each vertex. Our incremental algorithm is built on the intuition that even with graphics and label changes, the majority of label changes tend to keep or not change the label mappings."}, {"heading": "5.2 To Re-compute or Not?", "text": "In fact, it is the case that one sees oneself in a position to fix and correct the aforementioned bugs."}, {"heading": "6. EXPERIMENTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.1 Datasets and Settings", "text": "This year it has come to the point that it has never come as far as this year."}, {"heading": "6.2 Static Approach Evaluation", "text": "This year it has come to the point that it has never come as far as this year."}, {"heading": "6.3 Incremental Approach Evaluation", "text": "We justify the advantage of our incremental approaches in terms of guaranteed acceleration and decent classification Prop 30 Prop 37 MovieLen PubMedProp 30 Prop 37 MovieLen PubMeda.quality compared to the re-computing approach. In the recomputing approach, we apply algorithm 1 to the entire network, in addition to the old label mappings. Since the purpose of this group of experiments is to evaluate the incremental framework, not the inference algorithm, we simply choose a representative algorithm MRG in all subsequent experiments. Question 6 In terms of efficiency and quality, what is the effect of trust parameters? Result 6 The runtime accelerates, in particular when the accuracy decreases with the others. The accuracy decreases with the others, we predict the percentage of new data, which we first fix the percentage of new data with 10% accuracy, what is the effect of reliability and reliability of reliability of reliability of reliability, what is the accuracy, what is the accuracy of accuracy, what is the effect of accuracy, the accuracy of the accuracy, the accuracy of the accuracy, the accuracy of the accuracy of the accuracy, the accuracy of the accuracy of the accuracy, what are we expect, the accuracy of the accuracy, the accuracy of the accuracy of the accuracy, the accuracy of the accuracy of the accuracy, the accuracy of the accuracy, the accuracy of the accuracy of the accuracy, the accuracy of the accuracy, the accuracy of the accuracy, the accuracy of the accuracy, the accuracy of the accuracy of the accuracy, the accuracy, the accuracy of the accuracy, the accuracy of the accuracy, the accuracy of the accuracy, the accuracy, the accuracy of the effects of the accuracy, the accuracy, the accuracy, the accuracy, the accuracy, the accuracy, the accuracy of the accuracy, the accuracy, the accuracy, the accuracy, the accuracy, the accuracy of the accuracy, the accuracy, the accuracy, the accuracy of the accuracy, the accuracy we expect."}, {"heading": "7. CONCLUSIONS AND FUTURE WORKS", "text": "In this paper, we investigated the problem of label propagation in K-partite graphs. We proposed a comprehensive label propagation model that supports both heterogeneity and heterophilic propagation by allowing two interconnected nodes of different types to have either similar or opposite labels. We developed a uniform label inference system with two representative update rules. To support the dynamic property of real networks, we also presented a fast algorithm that assigns labels incrementally to new data or updates old labels to new feedback. Instead of using the percentage of new data, a service function has been further developed to determine when an incremental approach is preferred. In the future, we plan to develop an effective adaptive seeding approach that selects the minimum number of labeled corners but achieves the highest guaranteed accuracy, which will significantly reduce the effort and cost of human labeling."}, {"heading": "7.1 Proof of Lemma 1", "text": "We first consider the general solution to Eq. (1) without the regulation function. With the observed graph structure (u = u) (u = u) (u = u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (v) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (v) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u) (u (u) (u) (u) (u) (u) (u (u) (u) (u) (u (u) (u) (u) (u (u) (u) (u (u) (u) (u) (u) (u (u) (u) (u) (u) (u) (u) (u) (Y) (u) (u) (u) (u) (u) (u) (u) (Y) (u) (u) (u) (u) (u) (u) (Y) (u) (u) (u) (u) (Y) (u) (u) (u) (Y) (u) (u) (Y) (u (u) (Y) (u) (u) (Y) (u) (u) (Y) (u) (u) (Y) (u) (Y) (u (u) (u) (u) (u n n n n n) (n) (n n n n n) (n ("}, {"heading": "7.3 Proof of Lemma 3", "text": "Similar to the proof for Lemma 1, we first introduce the Largan multiplier for non-negative constraints, which leads to the following Largan function J (B): J (Btt) = \"Gtt\" \u2212 YtBtt \"Y Tt\" 2 + tr (\"Btt\" B T \") (18) The next step is to optimize the above conditions w.r.t. Btt.\" We set \"J (Btt\") = 0, and get: \"Btt\" = 2Y T \"Yt\" \u2212 2Y Tt \"Yt\" Yt \"\u2212 2Y Tt\" Yt \"Yt\" With the K.K.T. condition [23], \"Btt\" \u2212 Btt \"= 0, we have: (Y Tt\" Gtt \"Yt\" \u2212 Y Tt \"Y Tt\" Yt \"Yt\")."}, {"heading": "7.4 Lipschitz constant for \u2207J(B)", "text": "Similar to the proof shown in section 7.2, if we consider that B1, B2 represent different values of Btt \u00b2, we have the following: | | J (B1) \u2212 J (B2) | | 2 = | 2Y Tt \u00b2 Tt \u00b2 Yt \u00b2 \u2212 2Y T \u00b2 Yt \u00b2 Yt \u00b2 | 2 \u2264 tr (2Y Tt \u00b2 Y T \u00b2 Yt \u00b2 Yt) | | B1 \u2212 B2 | | 2Y J (B1) \u2212 J (B2) | | F \u2264 2 | | Y Tt \u00b2 Y Tt \u00b2 Yt | | F | B1 \u2212 B2 | | F, and thus the Lipschitz constant is 2 | | Y Tt \u00b2 Y Tt \u00b2 Yt \u00b2 | F."}, {"heading": "7.5 Proof of Lemma 6", "text": "Lemma 6 Update label Y Vertex by Vertex using Lemma 1 is identical to the following traditional multiplicative rule (u) (u) (u) (u) (u) (42): Yt = Yt (n), where S (t), Rn (n), the label matrix is, of which Suu = 1, if u) V is L and zero for all other entries, and St is the submatrix of S (t) (v), v (t), v (t), v (t), v (t), v (t), v (t), v (t), v (t), v (t), v (t), v (t), v (t), v (t), v (t), v (t), t (t), v (t), v (t), t (t), v (t, t, t (t), v (t), v (t, t, t, t (t), v (t), v (t)."}, {"heading": "7.6 Additional tables", "text": "Table 7 contains additional results for supply functions."}, {"heading": "Acknowledgment", "text": "We are very grateful to Dr. Kristina Lerman and Dr. Wolfgang Gatterbauer for their insightful discussions."}, {"heading": "8. REFERENCES", "text": "[1] J. Abernethy, O. Chapelle, and C. Castillo. Graph regularization methods for web spam detection. Machine Learning, 81 (2): 207-225, 2010. [2] L. A. Adamic and E. Adar. Friends and neighbors on the web. SOCIAL NETWORKS, 25: 211-230, 2001. [3] S. Amer-Yahia, M. Fernandez, R. Greer, and D. Srivastava. Logical and physical support for heterogeneous data. In CIKM Conference, pp. 270-281. ACM, 2002. [4] A. Blum, J. Lafferty, M. Rwebangira, and R. Reddy. Semi-supervised learning using randomized mincuts. In ICML Conference, 2004. [5] D. Cai, X. He, J. Han, and T. Huang."}], "references": [{"title": "Graph regularization methods for web spam detection", "author": ["J. Abernethy", "O. Chapelle", "C. Castillo"], "venue": "Machine Learning,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2010}, {"title": "Friends and neighbors on the web", "author": ["L.A. Adamic", "E. Adar"], "venue": "SOCIAL NETWORKS,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2001}, {"title": "Logical and physical support for heterogeneous data", "author": ["S. Amer-Yahia", "M. Fernandez", "R. Greer", "D. Srivastava"], "venue": "In CIKM Conference,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2002}, {"title": "Semi-supervised learning using randomized mincuts", "author": ["A. Blum", "J. Lafferty", "M.R. Rwebangira", "R. Reddy"], "venue": "In ICML Conference,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2004}, {"title": "Graph regularized nonnegative matrix factorization for data representation", "author": ["D. Cai", "X. He", "J. Han", "T.S. Huang"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell.,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2011}, {"title": "Projected gradient methods for linearly constrained problems", "author": ["P.H. Calamai", "J.J. Mor\u00e9"], "venue": "Math. Program.,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1987}, {"title": "Joint inference of multiple label types in large networks", "author": ["D. Chakrabarti", "S. Funiak", "J. Chang", "S.A. Macskassy"], "venue": "In ICML Conference,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "Orthogonal nonnegative matrix t-factorizations for clustering", "author": ["C. Ding", "T. Li", "W. Peng", "H. Park"], "venue": "In SIGKDD Conference,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2006}, {"title": "Label propagation on k-partite graphs", "author": ["C. Ding", "T. Li", "D. Wang"], "venue": "In ICMLA Conference,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2009}, {"title": "Large graph mining: Patterns, cascades, fraud detection, and algorithms", "author": ["C. Faloutsos"], "venue": "In WWW Conference,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "Efficient belief propagation for early vision", "author": ["P.F. Felzenszwalb", "D.P. Huttenlocher"], "venue": "International journal of computer vision,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2006}, {"title": "A survey on concept drift adaptation", "author": ["J. a. Gama", "I. \u017dliobait\u0117", "A. Bifet", "M. Pechenizkiy", "A. Bouchachia"], "venue": "ACM Comput. Surv.,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2014}, {"title": "Linearized and single-pass belief propagation", "author": ["W. Gatterbauer", "S. G\u00fcnnemann", "D. Koutra", "C. Faloutsos"], "venue": "Proc. VLDB Endow.,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2015}, {"title": "Guided learning for role discovery (glrd): Framework, algorithms, and applications", "author": ["S. Gilpin", "T. Eliassi-Rad", "I. Davidson"], "venue": "In SIGKDD Conference,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2013}, {"title": "Seeing stars when there aren\u2019t many stars: graph-based semi-supervised learning for sentiment categorization", "author": ["A.B. Goldberg", "X. Zhu"], "venue": "In Graph Based Methods for Natural Language Processing,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2006}, {"title": "Co-clustering on manifolds", "author": ["Q. Gu", "J. Zhou"], "venue": "In SIGKDD Conference,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2009}, {"title": "Nenmf: An optimal gradient method for nonnegative matrix factorization", "author": ["N. Guan", "D. Tao", "Z. Luo", "B. Yuan"], "venue": "IEEE Trans. on Signal Processing,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2012}, {"title": "NONNEGATIVE MATRIX FACTORIZATION ALGORITHMS AND APPLICATIONS", "author": ["N.-D. Ho"], "venue": "PhD thesis,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2008}, {"title": "Loopy belief propagation: Convergence and effects of message errors", "author": ["A.T. Ihler", "J. Iii", "A.S. Willsky"], "venue": "In Journal of Machine Learning Research,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2005}, {"title": "Learning latent representations of nodes for classifying in heterogeneous social networks", "author": ["Y. Jacob", "L. Denoyer", "P. Gallinari"], "venue": "In WSDM Conference,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2014}, {"title": "Algorithms for nonnegative matrix and tensor factorizations: A unified view based on block coordinate descent framework", "author": ["J. Kim", "Y. He", "H. Park"], "venue": "J. of Global Optimization,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2014}, {"title": "The competition numbers of complete tripartite graphs", "author": ["S.-R. Kim", "Y. Sano"], "venue": "Discrete Applied Mathematics,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2008}, {"title": "Nonlinear programming", "author": ["H.W. Kuhn", "A.W. Tucker"], "venue": "In Proceedings of the 2nd Berkeley Symposium on Mathematical Statistics and Probability,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1950}, {"title": "Algorithms for non-negative matrix factorization", "author": ["D.D. Lee", "H.S. Seung"], "venue": "In NIPS  Conference,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2000}, {"title": "Projected gradient methods for nonnegative matrix factorization", "author": ["C.-J. Lin"], "venue": "Neural Comput.,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2007}, {"title": "Unsupervised learning on k-partite graphs", "author": ["B. Long", "X. Wu", "Z.M. Zhang", "P.S. Yu"], "venue": "In SIGKDD Conference,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2006}, {"title": "Introductory lectures on convex optimization : a basic course", "author": ["Y. Nesterov"], "venue": null, "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2004}, {"title": "Nonnegative matrix tri-factorization with graph regularization for community detection in social networks. In IJCAI, pages 2083\u20132089", "author": ["Y. Pei", "N. Chakraborty", "K.P. Sycara"], "venue": null, "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2015}, {"title": "Automatic pitch accent prediction for text-to-speech synthesis", "author": ["I. Read", "S. Cox"], "venue": "In Interspeech,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2007}, {"title": "Tagommenders: Connecting users to items through tags", "author": ["S. Sen", "J. Vig", "J. Riedl"], "venue": "In WWW Conference,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2009}, {"title": "A survey of heterogeneous information network analysis", "author": ["C. Shi", "Y. Li", "J. Zhang", "Y. Sun", "P.S. Yu"], "venue": "CoRR, abs/1511.04854,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2015}, {"title": "Semi-supervised learning with measure propagation", "author": ["A. Subramanya", "J. Bilmes"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2011}, {"title": "New regularized algorithms for transductive learning", "author": ["P.P. Talukdar", "K. Crammer"], "venue": "In Machine Learning and Knowledge Discovery in Databases,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2009}, {"title": "Balanced label propagation for partitioning massive graphs", "author": ["J. Ugander", "L. Backstrom"], "venue": "In WSDM Conference,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2013}, {"title": "On the complexity of nonnegative matrix factorization", "author": ["S.A. Vavasis"], "venue": "J. on Optimization,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2009}, {"title": "Omni-prop: Seamless node classification on arbitrary label correlation", "author": ["Y. Yamaguchi", "C. Faloutsos", "H. Kitagawa"], "venue": "In AAAI Conference,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2015}, {"title": "A graph-based hybrid framework for modeling complex heterogeneity", "author": ["P. Yang", "J. He"], "venue": "In ICDM Conference,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2015}, {"title": "Understanding belief propagation and its generalizations", "author": ["J.S. Yedidia", "W.T. Freeman", "Y. Weiss"], "venue": "Exploring artificial intelligence in the new millennium,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2003}, {"title": "Recommendation diversification using explanations", "author": ["C. Yu", "L.V. Lakshmanan", "S. Amer-Yahia"], "venue": "In IEEE 25th International Conference on Data Engineering,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2009}, {"title": "Learning with local and global consistency", "author": ["D. Zhou", "O. Bousquet", "T.N. Lal", "J. Weston", "B. Sch\u00f6lkopf"], "venue": "In NIPS Conference,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2003}, {"title": "Tripartite graph clustering for dynamic sentiment analysis on social media", "author": ["L. Zhu", "A. Galstyan", "J. Cheng", "K. Lerman"], "venue": "In SIGMOD Conference,", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2014}, {"title": "Scalable temporal latent space inference for link 14  prediction in dynamic social networks", "author": ["L. Zhu", "D. Guo", "J. Yin", "G.V. Steeg", "A. Galstyan"], "venue": "IEEE Transactions on Knowledge and Data Engineering,", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2016}, {"title": "Semi-supervised learning using gaussian fields and harmonic functions", "author": ["X. Zhu", "Z. Ghahramani", "J. Lafferty"], "venue": "In ICML Conference,", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2003}, {"title": "Learning under concept drift: an overview", "author": ["I. \u017dliobait\u0117"], "venue": "arXiv preprint arXiv:1010.4784,", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2010}], "referenceMentions": [{"referenceID": 42, "context": "Label propagation [44] is one of the classic algorithms to learn the label information for each vertex in a network (or graph).", "startOffset": 18, "endOffset": 22}, {"referenceID": 0, "context": "Recently, label propagation has received renewed interests from both academia and industry due to its various applications in many domains such as in spam detection [1], fraud detection [10], sentiment analysis [15], and graph partitioning [35].", "startOffset": 165, "endOffset": 168}, {"referenceID": 9, "context": "Recently, label propagation has received renewed interests from both academia and industry due to its various applications in many domains such as in spam detection [1], fraud detection [10], sentiment analysis [15], and graph partitioning [35].", "startOffset": 186, "endOffset": 190}, {"referenceID": 14, "context": "Recently, label propagation has received renewed interests from both academia and industry due to its various applications in many domains such as in spam detection [1], fraud detection [10], sentiment analysis [15], and graph partitioning [35].", "startOffset": 211, "endOffset": 215}, {"referenceID": 33, "context": "Recently, label propagation has received renewed interests from both academia and industry due to its various applications in many domains such as in spam detection [1], fraud detection [10], sentiment analysis [15], and graph partitioning [35].", "startOffset": 240, "endOffset": 244}, {"referenceID": 10, "context": "ent algorithms [11, 19, 33, 39, 41, 44] have been proposed to perform label propagation on trees or arbitrary graphs.", "startOffset": 15, "endOffset": 39}, {"referenceID": 18, "context": "ent algorithms [11, 19, 33, 39, 41, 44] have been proposed to perform label propagation on trees or arbitrary graphs.", "startOffset": 15, "endOffset": 39}, {"referenceID": 31, "context": "ent algorithms [11, 19, 33, 39, 41, 44] have been proposed to perform label propagation on trees or arbitrary graphs.", "startOffset": 15, "endOffset": 39}, {"referenceID": 37, "context": "ent algorithms [11, 19, 33, 39, 41, 44] have been proposed to perform label propagation on trees or arbitrary graphs.", "startOffset": 15, "endOffset": 39}, {"referenceID": 39, "context": "ent algorithms [11, 19, 33, 39, 41, 44] have been proposed to perform label propagation on trees or arbitrary graphs.", "startOffset": 15, "endOffset": 39}, {"referenceID": 42, "context": "ent algorithms [11, 19, 33, 39, 41, 44] have been proposed to perform label propagation on trees or arbitrary graphs.", "startOffset": 15, "endOffset": 39}, {"referenceID": 2, "context": "Unfortunately, many real networks such as social networks are heterogeneous systems [3, 32, 38] that contain objects of multiple types and are interlinked via various relations.", "startOffset": 84, "endOffset": 95}, {"referenceID": 30, "context": "Unfortunately, many real networks such as social networks are heterogeneous systems [3, 32, 38] that contain objects of multiple types and are interlinked via various relations.", "startOffset": 84, "endOffset": 95}, {"referenceID": 36, "context": "Unfortunately, many real networks such as social networks are heterogeneous systems [3, 32, 38] that contain objects of multiple types and are interlinked via various relations.", "startOffset": 84, "endOffset": 95}, {"referenceID": 40, "context": "In addition, the label information of users is much more reliable than that of words in terms of deciding the labels of tweets [42], and thus the user vertices should have stronger propagation strengths than word vertices.", "startOffset": 127, "endOffset": 131}, {"referenceID": 8, "context": "There are few notable exceptions [9, 13, 20] (see more in related works) that support either heterogeneous types of vertices or heterophily propagation, but not both.", "startOffset": 33, "endOffset": 44}, {"referenceID": 12, "context": "There are few notable exceptions [9, 13, 20] (see more in related works) that support either heterogeneous types of vertices or heterophily propagation, but not both.", "startOffset": 33, "endOffset": 44}, {"referenceID": 19, "context": "There are few notable exceptions [9, 13, 20] (see more in related works) that support either heterogeneous types of vertices or heterophily propagation, but not both.", "startOffset": 33, "endOffset": 44}, {"referenceID": 23, "context": "To infer our model, we first propose a framework that supports both multiplicative [25] and addictive rules [18] (i.", "startOffset": 83, "endOffset": 87}, {"referenceID": 17, "context": "To infer our model, we first propose a framework that supports both multiplicative [25] and addictive rules [18] (i.", "startOffset": 108, "endOffset": 112}, {"referenceID": 3, "context": "Method H-V H-P Auto Incre Joint [4] [11] [33] [34] X X X X X [39] [41] [44] [7] X X X X X [9] [20] X X X X ? [13] [37] X X X X X Proposed X X X X X", "startOffset": 32, "endOffset": 35}, {"referenceID": 10, "context": "Method H-V H-P Auto Incre Joint [4] [11] [33] [34] X X X X X [39] [41] [44] [7] X X X X X [9] [20] X X X X ? [13] [37] X X X X X Proposed X X X X X", "startOffset": 36, "endOffset": 40}, {"referenceID": 31, "context": "Method H-V H-P Auto Incre Joint [4] [11] [33] [34] X X X X X [39] [41] [44] [7] X X X X X [9] [20] X X X X ? [13] [37] X X X X X Proposed X X X X X", "startOffset": 41, "endOffset": 45}, {"referenceID": 32, "context": "Method H-V H-P Auto Incre Joint [4] [11] [33] [34] X X X X X [39] [41] [44] [7] X X X X X [9] [20] X X X X ? [13] [37] X X X X X Proposed X X X X X", "startOffset": 46, "endOffset": 50}, {"referenceID": 37, "context": "Method H-V H-P Auto Incre Joint [4] [11] [33] [34] X X X X X [39] [41] [44] [7] X X X X X [9] [20] X X X X ? [13] [37] X X X X X Proposed X X X X X", "startOffset": 61, "endOffset": 65}, {"referenceID": 39, "context": "Method H-V H-P Auto Incre Joint [4] [11] [33] [34] X X X X X [39] [41] [44] [7] X X X X X [9] [20] X X X X ? [13] [37] X X X X X Proposed X X X X X", "startOffset": 66, "endOffset": 70}, {"referenceID": 42, "context": "Method H-V H-P Auto Incre Joint [4] [11] [33] [34] X X X X X [39] [41] [44] [7] X X X X X [9] [20] X X X X ? [13] [37] X X X X X Proposed X X X X X", "startOffset": 71, "endOffset": 75}, {"referenceID": 6, "context": "Method H-V H-P Auto Incre Joint [4] [11] [33] [34] X X X X X [39] [41] [44] [7] X X X X X [9] [20] X X X X ? [13] [37] X X X X X Proposed X X X X X", "startOffset": 76, "endOffset": 79}, {"referenceID": 8, "context": "Method H-V H-P Auto Incre Joint [4] [11] [33] [34] X X X X X [39] [41] [44] [7] X X X X X [9] [20] X X X X ? [13] [37] X X X X X Proposed X X X X X", "startOffset": 90, "endOffset": 93}, {"referenceID": 19, "context": "Method H-V H-P Auto Incre Joint [4] [11] [33] [34] X X X X X [39] [41] [44] [7] X X X X X [9] [20] X X X X ? [13] [37] X X X X X Proposed X X X X X", "startOffset": 94, "endOffset": 98}, {"referenceID": 12, "context": "Method H-V H-P Auto Incre Joint [4] [11] [33] [34] X X X X X [39] [41] [44] [7] X X X X X [9] [20] X X X X ? [13] [37] X X X X X Proposed X X X X X", "startOffset": 109, "endOffset": 113}, {"referenceID": 35, "context": "Method H-V H-P Auto Incre Joint [4] [11] [33] [34] X X X X X [39] [41] [44] [7] X X X X X [9] [20] X X X X ? [13] [37] X X X X X Proposed X X X X X", "startOffset": 114, "endOffset": 118}, {"referenceID": 10, "context": "as belief propagation [11] [39], loopy belief propagation [19], Gaussian Random Field (GRF) [44], MP [33], MAD [34], and local consistency [41].", "startOffset": 22, "endOffset": 26}, {"referenceID": 37, "context": "as belief propagation [11] [39], loopy belief propagation [19], Gaussian Random Field (GRF) [44], MP [33], MAD [34], and local consistency [41].", "startOffset": 27, "endOffset": 31}, {"referenceID": 18, "context": "as belief propagation [11] [39], loopy belief propagation [19], Gaussian Random Field (GRF) [44], MP [33], MAD [34], and local consistency [41].", "startOffset": 58, "endOffset": 62}, {"referenceID": 42, "context": "as belief propagation [11] [39], loopy belief propagation [19], Gaussian Random Field (GRF) [44], MP [33], MAD [34], and local consistency [41].", "startOffset": 92, "endOffset": 96}, {"referenceID": 31, "context": "as belief propagation [11] [39], loopy belief propagation [19], Gaussian Random Field (GRF) [44], MP [33], MAD [34], and local consistency [41].", "startOffset": 101, "endOffset": 105}, {"referenceID": 32, "context": "as belief propagation [11] [39], loopy belief propagation [19], Gaussian Random Field (GRF) [44], MP [33], MAD [34], and local consistency [41].", "startOffset": 111, "endOffset": 115}, {"referenceID": 39, "context": "as belief propagation [11] [39], loopy belief propagation [19], Gaussian Random Field (GRF) [44], MP [33], MAD [34], and local consistency [41].", "startOffset": 139, "endOffset": 143}, {"referenceID": 19, "context": "[20] focused on learning the unified latent space representation through supervised learning for heterogeneous networks.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "[9] proposed a cross propagation algorithm for K-partite graphs, which distinguishes vertices of different types, and propagates label information from vertices of one type to vertices of another type.", "startOffset": 0, "endOffset": 3}, {"referenceID": 12, "context": "[13] proposed a heterophily belief propagation algorithm for homogeneous graphs with the same type of vertices (e.", "startOffset": 0, "endOffset": 4}, {"referenceID": 35, "context": "[37] also proposed a heterophily propagation algorithm that connects to random walk and Gaussian Random Field.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13] proposed a heuristic incremental belief propagation algorithm with new data.", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "[7] proposed a framework with joint inference of label types such as hometown, current city, and employers, for users connected in a social network.", "startOffset": 0, "endOffset": 3}, {"referenceID": 25, "context": "2 K-partite Graphs K-partite graph analysis has wide applications in many domains such as topic modeling [27], community detection [29], and sentiment analysis [42].", "startOffset": 105, "endOffset": 109}, {"referenceID": 27, "context": "2 K-partite Graphs K-partite graph analysis has wide applications in many domains such as topic modeling [27], community detection [29], and sentiment analysis [42].", "startOffset": 131, "endOffset": 135}, {"referenceID": 40, "context": "2 K-partite Graphs K-partite graph analysis has wide applications in many domains such as topic modeling [27], community detection [29], and sentiment analysis [42].", "startOffset": 160, "endOffset": 164}, {"referenceID": 25, "context": "[27] proposed a general model, the relation summary network, to find the hidden structures (the local cluster structures and the global community structures) from a K-partite graph; Zhu et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 40, "context": "[42] addressed both static tripartite graph clustering and online tripartite graph clustering with matrices co-factorization.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "There are other works which study theoretical issues such as competition numbers of tripartite graphs [22].", "startOffset": 102, "endOffset": 106}, {"referenceID": 4, "context": "where t denotes the type of vertex, Yt denote a sub matrix of Y , which gives the label assignment for the set of t-type vertices Vt, \u03b2 and \u03bb are parameters that control the contribution of different terms, and regularizer(G,Y ) denotes a regularization approach such as graph regularization [5], sparsity [14], diversity [40], and complexity regularization.", "startOffset": 292, "endOffset": 295}, {"referenceID": 13, "context": "where t denotes the type of vertex, Yt denote a sub matrix of Y , which gives the label assignment for the set of t-type vertices Vt, \u03b2 and \u03bb are parameters that control the contribution of different terms, and regularizer(G,Y ) denotes a regularization approach such as graph regularization [5], sparsity [14], diversity [40], and complexity regularization.", "startOffset": 306, "endOffset": 310}, {"referenceID": 38, "context": "where t denotes the type of vertex, Yt denote a sub matrix of Y , which gives the label assignment for the set of t-type vertices Vt, \u03b2 and \u03bb are parameters that control the contribution of different terms, and regularizer(G,Y ) denotes a regularization approach such as graph regularization [5], sparsity [14], diversity [40], and complexity regularization.", "startOffset": 322, "endOffset": 326}, {"referenceID": 34, "context": "First, the NP-hardness of Problem 1 (the sub problem of nonnegative matrix factorization is NP-hard [36]) requires efficient solutions for largescale real problems.", "startOffset": 100, "endOffset": 104}, {"referenceID": 17, "context": "Considering these nonnegative constraints, different approaches [18, 26, 21] have been proposed to solve this non-convex optimization problem.", "startOffset": 64, "endOffset": 76}, {"referenceID": 24, "context": "Considering these nonnegative constraints, different approaches [18, 26, 21] have been proposed to solve this non-convex optimization problem.", "startOffset": 64, "endOffset": 76}, {"referenceID": 20, "context": "Considering these nonnegative constraints, different approaches [18, 26, 21] have been proposed to solve this non-convex optimization problem.", "startOffset": 64, "endOffset": 76}, {"referenceID": 23, "context": "Among them, the multiplicative update [25] and additive update rules [26] are two most popular approaches because of their effectiveness.", "startOffset": 38, "endOffset": 42}, {"referenceID": 24, "context": "Among them, the multiplicative update [25] and additive update rules [26] are two most popular approaches because of their effectiveness.", "startOffset": 69, "endOffset": 73}, {"referenceID": 24, "context": "This transformation allows us to unify both rules under the same vertex-centric label propagation framework because many addictive rules are updating each row per iterations [26, 21].", "startOffset": 174, "endOffset": 182}, {"referenceID": 20, "context": "This transformation allows us to unify both rules under the same vertex-centric label propagation framework because many addictive rules are updating each row per iterations [26, 21].", "startOffset": 174, "endOffset": 182}, {"referenceID": 1, "context": "In our experiments, we define sim(u, v,G) as the normalized Admic-Adar score [2].", "startOffset": 77, "endOffset": 80}, {"referenceID": 0, "context": "(3), and then normalize all the scores into the range [0, 1].", "startOffset": 54, "endOffset": 60}, {"referenceID": 23, "context": "Proof : The proof can be derived in spirit of the classic multiplicative algorithm [25] for Non-negative matrix factorization with the KKT condition [23].", "startOffset": 83, "endOffset": 87}, {"referenceID": 22, "context": "Proof : The proof can be derived in spirit of the classic multiplicative algorithm [25] for Non-negative matrix factorization with the KKT condition [23].", "startOffset": 149, "endOffset": 153}, {"referenceID": 16, "context": "We use Nesterov\u2019s method [17],[28] and [43] to compute the step size \u03b7, which can be estimated using the Lipschitz constant L for \u2207J(Y (u)), see Appendix 7.", "startOffset": 25, "endOffset": 29}, {"referenceID": 26, "context": "We use Nesterov\u2019s method [17],[28] and [43] to compute the step size \u03b7, which can be estimated using the Lipschitz constant L for \u2207J(Y (u)), see Appendix 7.", "startOffset": 30, "endOffset": 34}, {"referenceID": 41, "context": "We use Nesterov\u2019s method [17],[28] and [43] to compute the step size \u03b7, which can be estimated using the Lipschitz constant L for \u2207J(Y (u)), see Appendix 7.", "startOffset": 39, "endOffset": 43}, {"referenceID": 40, "context": "Lemma 5 Updating label assignment Y vertex by vertex using Lemma 1 is identical to the following traditional multiplicative rule [42]:", "startOffset": 129, "endOffset": 133}, {"referenceID": 40, "context": "[42], it leads to O(nanbk+ nanck+ nbnck) computation complexity per iteration.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "Based on Corollary 1, 2 and 3 [21], any limited point of the sequence generated by Algorithm 1 reaches the stationary point if the update rules remain non-zero and achieve optimum.", "startOffset": 30, "endOffset": 34}, {"referenceID": 5, "context": "4 [6], the proposed additive rules still converge into a stationary point.", "startOffset": 2, "endOffset": 5}, {"referenceID": 40, "context": "[42] have proved that the value of objective function is non-increasing with the traditional multiplicative rules.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "In order to proceed, we estimate the information loss by examining the similarity between old data and new data, which is inspired by the concept drift modeling [12, 45] for supervised learning.", "startOffset": 161, "endOffset": 169}, {"referenceID": 43, "context": "In order to proceed, we estimate the information loss by examining the similarity between old data and new data, which is inspired by the concept drift modeling [12, 45] for supervised learning.", "startOffset": 161, "endOffset": 169}, {"referenceID": 40, "context": "Among the four datasets, Prop 30 and Prop 37 are two tripartite graphs created from 2012 November California Ballot Twitter Data [42], each of which consists of tweet vertices, user vertices, and word vertices.", "startOffset": 129, "endOffset": 133}, {"referenceID": 29, "context": "The MovieLen dataset [31] represents the folksonomy information among users, movies, and tags.", "startOffset": 21, "endOffset": 25}, {"referenceID": 42, "context": "We compare our approaches with three baselines: GRF [44], MHV [9] and BHP [13].", "startOffset": 52, "endOffset": 56}, {"referenceID": 8, "context": "We compare our approaches with three baselines: GRF [44], MHV [9] and BHP [13].", "startOffset": 62, "endOffset": 65}, {"referenceID": 12, "context": "We compare our approaches with three baselines: GRF [44], MHV [9] and BHP [13].", "startOffset": 74, "endOffset": 78}, {"referenceID": 28, "context": "Therefore, we also use Balanced Error Rate [30] to evaluate the classification quality.", "startOffset": 43, "endOffset": 47}, {"referenceID": 22, "context": "Using the KKT condition \u039bY (u) \u25e6 Y (u)=0 [23], where \u25e6 denotes the element-wise multiplicative, we obtain:", "startOffset": 41, "endOffset": 45}, {"referenceID": 7, "context": "Following the updating rules proposed and proved in [8] [16] [42], we have:", "startOffset": 52, "endOffset": 55}, {"referenceID": 15, "context": "Following the updating rules proposed and proved in [8] [16] [42], we have:", "startOffset": 56, "endOffset": 60}, {"referenceID": 40, "context": "Following the updating rules proposed and proved in [8] [16] [42], we have:", "startOffset": 61, "endOffset": 65}, {"referenceID": 22, "context": "condition [23], \u039bBtt\u2032 \u25e6Btt\u2032=0, we have: (Y T t Gtt\u2032Yt\u2032 \u2212 Y T t YtBtt\u2032Y T t\u2032 Yt\u2032) \u25e6Btt\u2032 = 0", "startOffset": 10, "endOffset": 14}, {"referenceID": 7, "context": "Following the updating rules proposed and proved in [8] [16] [42], we have:", "startOffset": 52, "endOffset": 55}, {"referenceID": 15, "context": "Following the updating rules proposed and proved in [8] [16] [42], we have:", "startOffset": 56, "endOffset": 60}, {"referenceID": 40, "context": "Following the updating rules proposed and proved in [8] [16] [42], we have:", "startOffset": 61, "endOffset": 65}, {"referenceID": 40, "context": "Lemma 6 Updating label assignment Y vertex by vertex using Lemma 1 is identical to the following traditional multiplicative rule [42]:", "startOffset": 129, "endOffset": 133}, {"referenceID": 40, "context": "[42], we obtain an optimization algorithm which iterates the following multiplicative update rule for Yt:", "startOffset": 0, "endOffset": 4}], "year": 2017, "abstractText": "In this paper, for the first time, we study label propagation in heterogeneous graphs under heterophily assumption. Homophily label propagation (i.e., two connected nodes share similar labels) in homogeneous graph (with same types of vertices and relations) has been extensively studied before. Unfortunately, real-life networks are heterogeneous, they contain different types of vertices (e.g., users, images, texts) and relations (e.g., friendships, co-tagging) and allow for each node to propagate both the same and opposite copy of labels to its neighbors. We propose a K-partite label propagation model to handle the mystifying combination of heterogeneous nodes/relations and heterophily propagation. With this model, we develop a novel label inference algorithm framework with update rules in near-linear time complexity. Since real networks change over time, we devise an incremental approach, which supports fast updates for both new data and evidence (e.g., ground truth labels) with guaranteed efficiency. We further provide a utility function to automatically determine whether an incremental or a remodeling approach is favored. Extensive experiments on real datasets have verified the effectiveness and efficiency of our approach, and its superiority over the state-of-the-art label propagation methods.", "creator": "LaTeX with hyperref package"}}}