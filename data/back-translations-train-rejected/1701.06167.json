{"id": "1701.06167", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Jan-2017", "title": "Binary Matrix Guessing Problem", "abstract": "We introduce the Binary Matrix Guessing Problem and provide two algorithms to solve this problem. The first algorithm we introduce is Elementwise Probing Algorithm (EPA) which is very fast under a score which utilizes Frobenius Distance. The second algorithm is Additive Reinforcement Learning Algorithm which combines ideas from perceptron algorithm and reinforcement learning algorithm. This algorithm is significantly slower compared to first one, but less restrictive and generalizes better. We compare computational performance of both algorithms and provide numerical results.", "histories": [["v1", "Sun, 22 Jan 2017 14:19:25 GMT  (8kb)", "http://arxiv.org/abs/1701.06167v1", "9 pages, 4 tables"]], "COMMENTS": "9 pages, 4 tables", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["\\c{c}a\\u{g}r{\\i} latifo\\u{g}lu"], "accepted": false, "id": "1701.06167"}, "pdf": {"name": "1701.06167.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["cagri.latifoglu@tedu.edu.tr"], "sections": [{"heading": null, "text": "ar Xiv: 170 1.06 167v 1 [cs.A I] 2 2Ja n20 17"}, {"heading": "1 Introduction", "text": "Consider the following game: Alice creates a n \u00b7 n square binary matrix A with elements [aij], [aij], [i], [i], [i], [i]. A is hidden by Bob. \u2212 Bob tries to guess A. \u00b7 Alice never shows a result when Bob makes a guess where [Bij], [i], [i], [i], [i], [n]. The measurement function f takes A and B as inputs and returns. \u00b7 Note that Bob knows no scoring function f or A and can only observe s values for his guess B1. We assume that the maximum value of the score s, smax, is known by both parties, and is reached when we use the function f to provide \"informative\" values of s for partially correct guesses."}, {"heading": "2 Elementwise Probing", "text": "Consider this: Let B0 and B1 be identical n \u00b7 n binary matrices except for index {l, m}, i.e. B0i, j = B1i, j \u0441 (i, j). For the other indices, these two matrices are exactly the same. Let's consider the values they would get if evaluated against an arbitrary target binary matrix, A: s0 = f (A, B0) and s1 = f (A, B1). Let's consider the values they would get if evaluated against any target binary matrix, A: s0 = f (A, B0) and s1 = f (A, B1). It's trivial to see that s0 6 = s1 and either s0 > s1 < s0 < s1 < s1 < s1 = Elemental matrix)."}, {"heading": "3 Additive Reinforcement Learning Algorithm", "text": "The question that arises is whether it is a way in which it is a way in which people are able to understand the world and understand what they are doing. (...) The question is whether people are able to understand and understand the world. (...) The question is whether people are able to understand the world. (...) The question is only whether people are able to understand the world. (...) The question is whether people are able to understand the world. (...) The question is whether people are able to understand and understand the world. (...) The question is not whether people are able to understand the world. (...) The question is whether people are able to understand the world. (...)"}, {"heading": "4 Conclusion", "text": "We introduced the binary matrix guessing game and provided two algorithms to solve this problem: the Elementwise Probing Algorithm (EPA) and the Additive Learning Algorithm (ARLA). EPA is very fast and can be made even faster when paralleled, but requires a scoring metric that responds to elementary changes. ARLA can also be used to solve the same problem and generalizes better when compared to EPA, although it is slower when compared to EPA, but can be improved faster due to its embarrassing parallelism. We have used ARLA to design a photonic crystal with very good focusing / coupling properties [see quote here] where the scoring function does not necessarily have good qualities, such as elemental sensitivity, such as we have at Frobenius distance. As a future work, ARLA will be expanded to take into account the rewards from complements. Let's assume a zero matrix B is the binary matrix, which is the binary matrix B."}, {"heading": "5 Acknowledgements", "text": "The author thanks Dr. Tayfun Ku'c-u-ky\u0131lmaz, Dr. Mirbek Turduev, Dr. Utku I-nan Tu-rkmen and Dr. Sinan Hanay from TED University for the helpful discussions. We designed these algorithms to solve a problem raised by Dr. Mirbek Turduev. Dr. Tayfun Ku'c-nan Tu-rkmen made sharp observations during the EPA design process. Dr. Utku I-nan Tu-rkmen made helpful comments on the ARLA algorithm. Dr. Sinan Hanay provided helpful comments throughout the development process."}, {"heading": "Appendix B Matrix Proof", "text": "Consider two binary matrices K and L, which are used as our conjecture matrices: K2 \u00b7 2 = (a b0 d), L2 \u00b7 2 = (a b1 d). Note that K and L are identical except in the index (2, 1). K (2, 1) = 0 and L (2, 1) = 1. Also note that smax = 2 since n = 2. Consider the 2 \u00d7 2 binary matrix M, which is used as our target matrix: M2 \u00d7 2 = (e fg h).FD (K, M) = 7-4 (a) 2 + (b \u2212 f) 2 + (0 \u2212 g) 2 + (d \u2212 g) 2 + (d \u2212 g) 2 + (d \u2212 g) 2."}], "references": [{"title": "The perceptron: A probabilistic model for information storage and organization in the brain", "author": ["F. Rosenblatt"], "venue": "Psych. Rev.,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1958}, {"title": "Introduction to Reinforcement Learning", "author": ["Richard S. Sutton", "Andrew G. Barto"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1998}], "referenceMentions": [{"referenceID": 0, "context": "For solving the binary matrix guessing problem, we have developed a perceptron-like [1] learning algorithm, called Additive Reinforcement Learning Algorithm (ARLA) which learns the target matrix after making a certain number of queries.", "startOffset": 84, "endOffset": 87}, {"referenceID": 1, "context": "ARLA, in spirit, is close to perceptron and reinforcement learning [2], as close matches between the guess and the target reinforces ARLA\u2019s current guess of the positions of 0s and 1s in the target matrix.", "startOffset": 67, "endOffset": 70}], "year": 2017, "abstractText": "We introduce the Binary Matrix Guessing Problem and provide two algorithms to solve this problem. The first algorithm we introduce is Elementwise Probing Algorithm (EPA) which is very fast under a score which utilizes Frobenius Distance. The second algorithm is Additive Reinforcement Learning Algorithm which combines ideas from perceptron algorithm and reinforcement learning algorithm. This algorithm is significantly slower compared to first one, but less restrictive and generalizes better. We compare computational performance of both algorithms and provide numerical results.", "creator": "LaTeX with hyperref package"}}}