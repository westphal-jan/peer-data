{"id": "1701.06247", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Jan-2017", "title": "A Multichannel Convolutional Neural Network For Cross-language Dialog State Tracking", "abstract": "The fifth Dialog State Tracking Challenge (DSTC5) introduces a new cross-language dialog state tracking scenario, where the participants are asked to build their trackers based on the English training corpus, while evaluating them with the unlabeled Chinese corpus. Although the computer-generated translations for both English and Chinese corpus are provided in the dataset, these translations contain errors and careless use of them can easily hurt the performance of the built trackers. To address this problem, we propose a multichannel Convolutional Neural Networks (CNN) architecture, in which we treat English and Chinese language as different input channels of one single CNN model. In the evaluation of DSTC5, we found that such multichannel architecture can effectively improve the robustness against translation errors. Additionally, our method for DSTC5 is purely machine learning based and requires no prior knowledge about the target language. We consider this a desirable property for building a tracker in the cross-language context, as not every developer will be familiar with both languages.", "histories": [["v1", "Mon, 23 Jan 2017 01:36:10 GMT  (179kb)", "http://arxiv.org/abs/1701.06247v1", "Copyright 2016 IEEE. Published in the 2016 IEEE Workshop on Spoken Language Technology (SLT 2016)"]], "COMMENTS": "Copyright 2016 IEEE. Published in the 2016 IEEE Workshop on Spoken Language Technology (SLT 2016)", "reviews": [], "SUBJECTS": "cs.CL cs.AI cs.LG", "authors": ["hongjie shi", "takashi ushio", "mitsuru endo", "katsuyoshi yamagami", "noriaki horii"], "accepted": false, "id": "1701.06247"}, "pdf": {"name": "1701.06247.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Hongjie Shi", "Takashi Ushio", "Mitsuru Endo", "Katsuyoshi Yamagami"], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 170 1.06 247v 1 [cs.C L] 23 Jan 2017 Published at IEEE SLT 2016Index Terms - Convolutional Neural Networks, Multichannel Architecture, dialog state tracking, dialog systems"}, {"heading": "1. INTRODUCTION", "text": "The reason for this is that most of them are able to survive on their own; most of them are not able to survive on their own because they are not able to survive on their own; most of them are not able to survive on their own because they are not able to survive on their own; most of them are able to survive on their own; and most of them are not able to survive on their own; and most of them are not able to survive on their own; and most of them are able to survive on their own."}, {"heading": "2. DATASET AND PROBLEM DESCRIPTION", "text": "The Fifth Dialog State Tracking Challenge (DSTC5) uses the entire data set (including Train / Dev / Test records) of the 2016 IEEE Copyright. Published in the IEEE Workshop on Spoken Language Technology (SLT 2016).DSTC4 as a training dataset. This dataset contains 35 dialog sessions on Singapore tourist information collected by English speakers. In addition to the training dataset, a development set is provided that includes two dialog sessions collected by Chinese speakers to test and tune the trackers \"cross-language performance prior to the final evaluation. Both the training and development sets are labeled with the dialogue state tags and come with the 5th-best hypothesis of English or Chinese translation systems. In the evaluation phase of the challenge, a test set of 8 unlabeled Chinese dialogues is distributed to each participant, and all prediction results submitted by each participant are evaluated by comparison with the true designations."}, {"heading": "3. METHOD", "text": "In DSTC4, we proposed a method based on the Convolutionary Neural Networks originally proposed by Kim [5], which enabled us to achieve the best performance in tracking the INFO slot. CNN's model, which we used in this method, was modified from the outset by adding a structure of multi-topic Convolutionary Layers so that it could better handle the information presented in different dialog topics. This model is characterized by its high performance for limited training data, since it can be trained across different topics. Further details on this multi-topic model can be found in [2]. In DSTC5, the training data is 75% more than in DSTC4, so the situation of limited training data is improved. To focus more on the new cross-language problem and keep our method simple, instead of using the more complex multi-topic model that we proposed last time, we have trained individual CNN models for each slot theme combination. \"For example, we can make the FINO and the FINO slot independent of each other.\""}, {"heading": "3.1. Motivation", "text": "The main challenge of DSTC5 is that the training and test corpora are originally collected in different languages. Computer-generated translations into Chinese or English are provided in the training and test data set, a simple approach is to train a model with an English corpus and use it for the English translation in the test data. Alternatively, a model that was trained in Chinese translations in the training data set can be used for Chinese expressions in the test data. However, both methods waste the originally collected expressions either in the training or in the test data. To make full use of the corpus resource in both the English and Chinese language, we proposed the following multi-channel model, which can be considered a combination of English and Chinese models."}, {"heading": "3.2. Model architecture", "text": "In this model, the input of each channel is a two-dimensional matrix, each line of which is the embedding vector of the corresponding word: s = - w1 - w2 -... - wn -, (1) where the embedding vectors for the i-word are in the input text. This 2-dimensional array s is a matrix representation of the input text. We used three different word embedding in our model - two for the Chinese and one for the English. Details of this embedding will be explained later in the sect. 3.3 For each line is the matrix representation of the input copy."}, {"heading": "3.3. Embedding models", "text": "The word2vec [7] model is one of the most common methods for creating word embedding in Chinese. In DSTC5, we applied this method and trained three different models with different training corpus. Details of these models are listed as follows: 1. English word model: 200-dimensional word2vec model trains in English Wikipedia, splitting all text by word boundaries using \"jieba\" module2. This model contains 457806 Chinese words and 53743 English words that are able to be used in Chinese Wikipedia.3. Chinese text model: 200-dimensional word2vec model trains in Chinese Wikipedia, splitting all texts into single Chinese characters. This model contains 12145 Chinese characters and 53743 English words that are able to be used in Chinese Wikipedia.The reason why we trained two models for the Chinese language word boundaries in the Chinese word ved2vec model is split into single Chinese characters, with the entire text being Chinese characters."}, {"heading": "4. RESULTS", "text": "Our multi-channel CNN model achieves the best score among all 9 teams: The result of input-3 outperforms the second-best team by 50% 2https: / / github.com / fxsjy / jieba (0.0956 / 0.0635) in accuracy and 15% (0.4519 / 0.3945) in Fmeasure with the sub-dialog rating. Our five entries are the results of 5 different hyperparameter settings determined by a rough grid search3, and these settings are summarized in Table 4. Comparing these results, it is easy to see that among these hyperparameters, the drop-out rate is a key factor. Drop-out is known as a technique for reducing overmatch in neural networks [9], and in our case, reducing the drop-out rate always improves precision while degrading the recall rate. An explanation for this is that the results are not only used for the other well-distributed data, but also for the labels."}, {"heading": "4.1. Multichannel model & single channel model & model combination", "text": "To investigate how the proposed multi-channel architecture contributes to these results, we compared the performance between the multi-channel and ordinary single-channel CNN models. For this comparison, we trained three different monolingual single-channel CNN models, using each of the embedding models mentioned in Section 3.3. These models used the same parameter setting as \"multi-channel # 3\" in Table 4 and were trained only on the basis of the monolingual results of machine translation. Fig.4 shows the comparison results: The Chinese character model achieves the best overall accuracy among single-channel models, while the multi-channel model exceeds all three single-channel models. In the previous DSTC, a simple model combination technique was used to further improve prediction performance, with the final output calculated by averaging the results of different models [10]."}, {"heading": "4.2. Discussion", "text": "We think that the above results can be partially explained from the point of view of ensemble learning. Although, in a multi-channel model, each channel provides a different view of the data, and one example is described with different feature sets that provide different, complementary information about the instance. The fully connected layer in the multi-channel model also provides optimization to use this information for prediction, and thus the resulting model is in principle better able to deal with the translation errors that have occurred in different channels. Table 5 is one of the examples showing this idea. In this specific sub-dialog segment, none of the 3 single-channel models is able to output the correct labels, while the multi-channel model gives the correct prediction. As seen in this example, the model combination behaves like a simple tuning, meaning that it only picks up the labels that are supported by the majority of single-channel models. The multi-channel model, on the other hand, is able to give the correct multiple-channel model during the correct prediction."}, {"heading": "5. CONCLUSION", "text": "This multi-channel model proves resilient to translation errors and outperforms any single channel model. In addition, our method does not require prior knowledge of new languages and can therefore be easily applied to available corpus resources of different languages, which can not only reduce the cost of adapting to a new language, but also provides the ability to build multilingual dialogue status trackers with large cross-lingual corporations. In this paper, we have applied three different embedding models, while there is another one we have not tried - the English character model. Recently, several character-conscious language models have been proposed that are superior in dealing with subword information, rare words and spelling errors [12, 13]. We believe that integration into the multi-channel model is a promising research direction. As our method is purely machine learning, it cannot deal with invisible terms in the test data."}, {"heading": "6. REFERENCES", "text": "[1] Seokhwan Kim, Luis Fernando D'Haro, Rafael E. Banchs, Jason Williams, Matthew Henderson, andKoichiro Yoshino, \"The Fifth Dialog State Tracking Challenge,\" in Proceedings of the 2016 IEEE Workshop on Spoken Language Technology (SLT), 2016. [2] Hongjie Shi, Takashi Ushio, Mitsuru Endo, Katsuyoshi Yamagami, and Noriaki Horii, \"Convolutional neural networks for multi-topic dialog state tracking,\" Proceedings of the 7th International Workshop on Spoken Dialogue Systems (IWSDS), 2016. [3] Franck Dernoncourt, Ji Young Lee, Trung H Bui, and Hung H Bui \"Robust dialog state tracking for large ontologies,\" arXiv preprint arXiv: 1605.02130, 2016. [4] Ilya Sutskever, Oriol Vinyals, and Le Quoc networks. \""}], "references": [{"title": "The Fifth Dialog State Tracking Challenge", "author": ["Seokhwan Kim", "Luis Fernando D\u2019Haro", "Rafael E. Banchs", "Jason Williams", "Matthew Henderson", "Koichiro Yoshino"], "venue": "Proceedings of the 2016 IEEE Workshop on Spoken Language Technology (SLT), 2016.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2016}, {"title": "Convolutional neural networks for multi-topic dialog state tracking", "author": ["Hongjie Shi", "Takashi Ushio", "Mitsuru Endo", "Katsuyoshi Yamagami", "Noriaki Horii"], "venue": "Proceedings of the 7th International Workshop on Spoken Dialogue Systems (IWSDS), 2016.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2016}, {"title": "Robust dialog state tracking for large ontologies", "author": ["Franck Dernoncourt", "Ji Young Lee", "Trung H Bui", "Hung H Bui"], "venue": "arXiv preprint arXiv:1605.02130, 2016.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2016}, {"title": "Sequence to sequence learning with neural networks", "author": ["Ilya Sutskever", "Oriol Vinyals", "Quoc V Le"], "venue": "Advances in neural information processing systems, 2014, pp. 3104\u20133112.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2014}, {"title": "Convolutional neural networks for sentence classification", "author": ["Yoon Kim"], "venue": "arXiv preprint arXiv:1408.5882, 2014.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2014}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E Hinton"], "venue": "Advances in neural information processing systems, 2012, pp. 1097\u20131105.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2012}, {"title": "Efficient estimation of word representations in vector space", "author": ["Tomas Mikolov", "Kai Chen", "Greg Corrado", "Jeffrey Dean"], "venue": "arXiv preprint arXiv:1301.3781, 2013.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "A sensitivity analysis of (and practitioners\u2019 guide to) convolutional neural networks for sentence classification", "author": ["Ye Zhang", "Byron Wallace"], "venue": "arXiv preprint arXiv:1510.03820, 2015.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2015}, {"title": "Improving neural networks by preventing co-adaptation of feature detectors", "author": ["Geoffrey E Hinton", "Nitish Srivastava", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan R Salakhutdinov"], "venue": "arXiv preprint arXiv:1207.0580, 2012.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2012}, {"title": "Word-based dialog state tracking with recurrent neural networks", "author": ["Matthew Henderson", "Blaise Thomson", "Steve Young"], "venue": "Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), 2014, pp. 292\u2013299.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}, {"title": "Error analysis of statistical machine translation output", "author": ["David Vilar", "Jia Xu", "Luis Fernando dHaro", "Hermann Ney"], "venue": "Proceedings of LREC, 2006, pp. 697\u2013702.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2006}, {"title": "Character-aware neural language models", "author": ["Yoon Kim", "Yacine Jernite", "David Sontag", "Alexander M Rush"], "venue": "arXiv preprint arXiv:1508.06615, 2015.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2015}, {"title": "Character-level convolutional networks for text classification", "author": ["Xiang Zhang", "Junbo Zhao", "Yann LeCun"], "venue": "Advances in Neural Information Processing Systems, 2015, pp. 649\u2013657.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "To provide a common testbed for this task, the series of Dialog State Tracking Challenges (DSTC) was initiated [1].", "startOffset": 111, "endOffset": 114}, {"referenceID": 1, "context": "One lesson we learned from DSTC4 is the difficulty of building a high performance tracker for human-human dialog with very limited training corpus, no matter whether using machine learning or hand-crafted rule-based approaches [2, 3].", "startOffset": 227, "endOffset": 233}, {"referenceID": 2, "context": "One lesson we learned from DSTC4 is the difficulty of building a high performance tracker for human-human dialog with very limited training corpus, no matter whether using machine learning or hand-crafted rule-based approaches [2, 3].", "startOffset": 227, "endOffset": 233}, {"referenceID": 3, "context": "On the other hand, although the machine translation technology has achieved great progress recently, the translation quality is still not satisfactory [4].", "startOffset": 151, "endOffset": 154}, {"referenceID": 4, "context": "In DSTC4 we proposed a method which is based on the convolutional neural networks originally proposed by Kim [5].", "startOffset": 109, "endOffset": 112}, {"referenceID": 1, "context": "More details about this multi-topic model can be found in [2].", "startOffset": 58, "endOffset": 61}, {"referenceID": 5, "context": "Our model is inspired by the multichannel convolutional neural networks commonly used in the image processing [6].", "startOffset": 110, "endOffset": 113}, {"referenceID": 6, "context": "The word2vec [7] is one of the most common methods for producing word embeddings.", "startOffset": 13, "endOffset": 16}, {"referenceID": 8, "context": "The dropout is known as a technique for reducing overfitting in neural networks [9], and in our case reducing the dropout rate always improves the Precision while degrading the Recall score.", "startOffset": 80, "endOffset": 83}, {"referenceID": 7, "context": "3A guide for setting these hyperparameters can be found in [8] 4These are the evaluation results using \u2018Schedule 2\u2019 described in the challenge handbook [1].", "startOffset": 59, "endOffset": 62}, {"referenceID": 0, "context": "3A guide for setting these hyperparameters can be found in [8] 4These are the evaluation results using \u2018Schedule 2\u2019 described in the challenge handbook [1].", "startOffset": 152, "endOffset": 155}, {"referenceID": 9, "context": "In the earlier DSTC, a simple model combination technique has been used to further improve the predictive performance, where the final output is computed by averaging the scores output by different models [10].", "startOffset": 205, "endOffset": 209}, {"referenceID": 10, "context": "Another problem is that the translation quality often varies by reversing the translation direction, due to the difference in inflections, word order and grammars [11].", "startOffset": 163, "endOffset": 167}, {"referenceID": 11, "context": "There are several character-aware language models proposed recently, which are superior in dealing with subword information, rare words and misspelling [12, 13].", "startOffset": 152, "endOffset": 160}, {"referenceID": 12, "context": "There are several character-aware language models proposed recently, which are superior in dealing with subword information, rare words and misspelling [12, 13].", "startOffset": 152, "endOffset": 160}], "year": 2017, "abstractText": "The fifth Dialog State Tracking Challenge (DSTC5) introduces a new cross-language dialog state tracking scenario, where the participants are asked to build their trackers based on the English training corpus, while evaluating them with the unlabeled Chinese corpus. Although the computer-generated translations for both English and Chinese corpus are provided in the dataset, these translations contain errors and careless use of them can easily hurt the performance of the built trackers. To address this problem, we propose a multichannel Convolutional Neural Networks (CNN) architecture, in which we treat English and Chinese language as different input channels of one single CNN model. In the evaluation of DSTC5, we found that such multichannel architecture can effectively improve the robustness against translation errors. Additionally, our method for DSTC5 is purely machine learning based and requires no prior knowledge about the target language. We consider this a desirable property for building a tracker in the cross-language context, as not every developer will be familiar with both languages.", "creator": "LaTeX with hyperref package"}}}