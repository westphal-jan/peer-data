{"id": "1701.07103", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Jan-2017", "title": "Artificial Intelligence Approaches To UCAV Autonomy", "abstract": "This paper covers a number of approaches that leverage Artificial Intelligence algorithms and techniques to aid Unmanned Combat Aerial Vehicle (UCAV) autonomy. An analysis of current approaches to autonomous control is provided followed by an exploration of how these techniques can be extended and enriched with AI techniques including Artificial Neural Networks (ANN), Ensembling and Reinforcement Learning (RL) to evolve control strategies for UCAVs.", "histories": [["v1", "Tue, 24 Jan 2017 23:11:15 GMT  (271kb,D)", "http://arxiv.org/abs/1701.07103v1", "12 pages, 3 figures, 1 table"]], "COMMENTS": "12 pages, 3 figures, 1 table", "reviews": [], "SUBJECTS": "cs.AI cs.RO", "authors": ["amir husain", "bruce porter sparkcognition inc department of computer science", "university of texas at austin)"], "accepted": false, "id": "1701.07103"}, "pdf": {"name": "1701.07103.pdf", "metadata": {"source": "CRF", "title": "Artificial Intelligence Approaches To UCAV Autonomy", "authors": ["Amir Husain", "Bruce Porter"], "emails": ["amir@sparkcognition.com,", "porter@cs.utexas.edu"], "sections": [{"heading": null, "text": "Artificial Intelligence Approaches UCAV AutonomyAmir Husain, Bruce Porter, January 26, 2017amir @ sparkcognition.com, porter @ cs.utexas.edu"}, {"heading": "1 Abstract", "text": "This paper discusses a number of approaches that use artificial intelligence algorithms and techniques to support the autonomy of Unmanned Combat Aerial Vehicle (UCAV). An analysis of current approaches to autonomous control is followed by an exploration of how these techniques can be extended and enriched with AI techniques such as Artificial Neural Networks (ANN), Ensembling and Reinforcement Learning (RL) to develop control strategies for UCAVs."}, {"heading": "2 Introduction", "text": "Current drones have limited autonomous capabilities, mainly comprising the following GPS waypoints, and some control functions, such as maintaining stability in the face of environmental factors such as wind. More recently, some autonomous capabilities have also been demonstrated, such as the ability of an unmanned aircraft to land on the deck of an aircraft carrier. [1] These capabilities are merely the tip of the spear in terms of what is possible and what will undoubtedly be developed in the near future in light of commercial and military applications and interests. In particular, flexibility in reactions that can mimic the unpredictability of human responses is one way in which autonomous systems of the future will differ from rules-based control systems. The unpredictability of human-style action opens the door to solutions that may not have been conceivable at the time the system was programmed. In addition, this type of unpredictability can create difficulties in combat systems designed as countermeasures."}, {"heading": "3 Existing Control Systems", "text": "This year, it has come to the point where there is only one person who is able to move around the world."}, {"heading": "4 Advanced Autonomous Capabilities", "text": "The purpose of this section is to outline some areas of potential further development which may be expected of autonomous systems of the future. This list is neither exhaustive nor complete with respect to the current conception of all such advanced capabilities of the Author. It concerns a subset of possible functions which are listed to illuminate the broad contours of what is possible with respect to applications of artificial intelligence in relation to UCAV autonomy. Some features include: 1. Knowledge & evaluation updates (a) Identification of potential threats outside of pre-programmed mission missions (b) Autonomous exploration and evaluation of identified targets which autonomous control considers a high priority. (c) Extension and updating of intelligence supplied as part of the mission plan and plan, based on actual observation2. Autonomous navigation and swarm coordination (a) Ability to adapt to environmental conditions, which a system or associated swarm systems cause to adapt to the expectations of potential (potential only)."}, {"heading": "5 The Need for a New Approach", "text": "In the previous sections, we examined the current state of autonomous systems and the rules-based approach that is often used in the development of these systems; we also looked at a number of advanced capabilities that would be desirable in future autonomous control systems; a fundamental challenge in developing these future capabilities is that the range of scenarios that an autonomous system would have to confront in order to perform the required maneuvers effectively is enormous; coping with such a wide range of possibilities with a rules-based system would be impractical not only because of the combinatorial explosion of possibilities that individual rules would require, but also because human designers of such a system may simply not be able to imagine any imaginable scenario in which the autonomous system might find itself. Another challenge is that rules-based systems are hard coded to measure certain criteria or sensor values, and then act on those predetermined criteria. This hard coding means that each rule is bound to a set of sensors."}, {"heading": "6 An Architecture for Advanced Autonomy", "text": "The basic architecture we propose in this paper is based on multiple independent control systems connected to an Action Optimizer Neural Network. Each of the multiple independent control systems can be a neural control system or a non-ANN rule-based control system that outputs a proposed action vector or control activations.The Action Optimizer ANN generates and weighs the inputs supplied by each independent control system.Let's be an independent control system, and it should be an Action Optimizer Neural network to which c1.. ncontrol networks are connected. In addition, let the sentence E contain a collection e1.. mof environmental inputs supplied to s. then we designate the specific configuration of all environmental inputs at a given time t by etand the output of s among these environmental inputs and based on the inputs of all independent control networks as follows: s (Et, Ct) = AtThe goal of our system is to optimize the selection of action sequences."}, {"heading": "7 Evolving Mission Specific Controllers", "text": "The actual training and development of the RNN represented by s is not the subject of this paper and will be documented in a later publication. In summary, this can be done in a way that combines the real world and simulator environments. However, in a more detailed future exploration, we intend to cover questions such as whether individual control networks, c1.. n, can be trained independently and how a training set that reflects the wide range of scenarios that the UCAV could experience is put together. For the purpose of the current discussion, our basic approach is to use Reinforcement Learning (RL) techniques [4] to train the RNN in a simulated environment until a basic level of competence has been reached, and then to allow the developed network to control a real craft."}, {"heading": "8 Semantic Interpretation of Sensor Data", "text": "In fact, we will be able to do so without having to manoeuvre ourselves into an impasse."}, {"heading": "9 Knowledge Representation For Advanced Autonomy", "text": "As the more complete diagram of the proposed autonomy architecture shows, the controller receives input from a number of controllers c1.. nand is also connected to the sensor bus and the cognitive corpus. A state map stored in the cognitive corpus reflects the complete environmental picture available to the autonomous asset. For example, it contains an estimate of the own position of the asset, the positions of allied assets, marked mission objectives, paths, preferred trajectories at the time of mission planning, territories and locations through which flight can be avoided, as well as other relevant data that can assist in route planning, objective fulfillment and avoidance of obstacles. This state map is another important input for the controller as it chooses the optimal sequence of actions. The image below shows a visual representation of what the state map could represent."}, {"heading": "10 Conclusion", "text": "The subtle changes in flight patterns, the identification of new threats, self-guided changes in mission profile and target selection require autonomous systems that go beyond pre-defined instructions. Machine learning and AI techniques provide a viable way for autonomous systems to learn and develop behaviors that go beyond programming them. Semantic information transmitted by sensors via a sensor bus to a collection of decision-making controllers ensures the exchange of individual controllers. An artificial neural network such as an RNN can merge and combine inputs from multiple controllers to generate a single, coherent control signal. In this approach, some of the individual controllers may be rule-based, but the RNN is really evolving into autonomous intelligence that can address a variety of concerns and factors about inputs from the control system, and decide on the most optimal actions."}], "references": [{"title": "Autonomous navigation for low-altitude UAVs in urban areas, arxiv.org", "author": ["Casteli et. al"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2016}, {"title": "Hybrid Genetic Algorithm fuzzy rule based guidance and control for launch vehicle, Intelligent Systems Design and Applications (ISDA) Conference", "author": ["Ansari", "Alam"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2011}, {"title": "Learning to Reinforcement Learn, arxiv.org", "author": ["Wang et. al"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2016}, {"title": "An Introduction to the Kalman Filter, SIGGRAPH", "author": ["Welch", "Bishop"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2001}, {"title": "Swarm Control in Unmanned Aerial Vehicles, ICAI", "author": ["Hexmoor et. al"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2005}, {"title": "Particle Swarm Optimization", "author": ["Kennedy", "Eberhart"], "venue": "Proceedings of IEEE International Conference on Neural Networks. IV. pp", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1995}, {"title": "A Survey on Transfer Learning, IEEE Transactions on Knowledge and Data Engineering", "author": ["Pan", "Yang"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2009}], "referenceMentions": [{"referenceID": 3, "context": "Many of these systems use rule-based, or fuzzy-rule based control, incorporating sensor-fusion techniques such as Kalman filters [7].", "startOffset": 129, "endOffset": 132}, {"referenceID": 4, "context": "While basic swarm algorithms [10] are effective in providing coverage over an area, and automatically repositioning all nodes when one is lost to maintain coverage, they do not provide much guidance on how to divide mission responsibilities and burdens, and to effectively delegate them to", "startOffset": 29, "endOffset": 33}, {"referenceID": 5, "context": "Some of the reasons why we propose this conclusion regarding the inadequacy of existing swarm algorithms is that most biologically inspired algorithms, such as Particle Swarm Optimization (PSO) [12] or Artificial Bee Colony Algorithm (ABC) [13], are search or optimization techniques that do not account for the role of an individual particle (or node) in the swarm.", "startOffset": 194, "endOffset": 198}, {"referenceID": 1, "context": "The question obviously arises, how do we build the function s? Conventionally, control functions have been built in various ways, for example as fuzzy rule based systems [3].", "startOffset": 170, "endOffset": 173}, {"referenceID": 2, "context": "For the purpose of the present discussion, our basic approach is to use Reinforcement Learning (RL) techniques [4] to train the RNN in a simulated environment until a basic level of competence has been achieved, and to then allow the evolved network to control a real craft.", "startOffset": 111, "endOffset": 114}, {"referenceID": 6, "context": "This reconciliation would benefit from applications of Transfer Learning [14].", "startOffset": 73, "endOffset": 77}, {"referenceID": 0, "context": "Work has already been done to use search algorithms such as A* to find viable paths around objects to be avoided[2]and this type of constraint can be implemented by one of the independent control networks (ck,as presented in the previous section).", "startOffset": 112, "endOffset": 115}], "year": 2017, "abstractText": "This paper covers a number of approaches that leverage Artificial Intelligence algorithms and techniques to aid Unmanned Combat Aerial Vehicle (UCAV) autonomy. An analysis of current approaches to autonomous control is provided followed by an exploration of how these techniques can be extended and enriched with AI techniques including Artificial Neural Networks (ANN), Ensembling and Reinforcement Learning (RL) to evolve control strategies for UCAVs.", "creator": "LaTeX with hyperref package"}}}