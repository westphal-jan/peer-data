{"id": "1701.07232", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Jan-2017", "title": "Learn&Fuzz: Machine Learning for Input Fuzzing", "abstract": "Fuzzing consists of repeatedly testing an application with modified, or fuzzed, inputs with the goal of finding security vulnerabilities in input-parsing code. In this paper, we show how to automate the generation of an input grammar suitable for input fuzzing using sample inputs and neural-network-based statistical machine-learning techniques. We present a detailed case study with a complex input format, namely PDF, and a large complex security-critical parser for this format, namely, the PDF parser embedded in Microsoft's new Edge browser. We discuss (and measure) the tension between conflicting learning and fuzzing goals: learning wants to capture the structure of well-formed inputs, while fuzzing wants to break that structure in order to cover unexpected code paths and find bugs. We also present a new algorithm for this learn&amp;fuzz challenge which uses a learnt input probability distribution to intelligently guide where to fuzz inputs.", "histories": [["v1", "Wed, 25 Jan 2017 10:01:39 GMT  (422kb,D)", "http://arxiv.org/abs/1701.07232v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.CR cs.LG cs.PL cs.SE", "authors": ["patrice godefroid", "hila peleg", "rishabh singh"], "accepted": false, "id": "1701.07232"}, "pdf": {"name": "1701.07232.pdf", "metadata": {"source": "CRF", "title": "Learn&Fuzz: Machine Learning for Input Fuzzing", "authors": ["Patrice Godefroid", "Hila Peleg", "Rishabh Singh"], "emails": ["pg@microsoft.com", "risin@microsoft.com", "hilap@cs.technion.ac.il"], "sections": [{"heading": "1 Introduction", "text": "In fact, most of them are able to play by the rules that they need for their work, and they are able to play by the rules that they need for their work."}, {"heading": "2 The Structure of PDF Documents", "text": "The fact is that it will be able to find a solution that is able to find a solution that is able to find a solution that is able to find a solution that is able to find a solution and that is able to find a solution that is able to find a solution that is able to find a solution that is able to find a solution that is able to find a solution that is able to find a solution that is able to find a solution that is able to find a solution that is able to find a solution that is able to find a solution. \""}, {"heading": "3 Statistical Learning of Object Contents", "text": "We will now describe our statistical learning approach to learning a generative model of PDF objects. The main idea is to learn a generative language model through the set of PDF object characters with a large corpus of objects. We use a sequence-to-sequence network model (seq2seq) [5, 26] that has been proven to provide state-of-the-art results for many different learning tasks, such as machine translation [26] and speech recognition [6]. The seq2seq model allows learning any length contexts to predict the next string, which is compared with conventional n-gram-based approaches limited by contexts of finite length. Given a corpus of PDF objects, the seq2seq model can be trained in an unattended manner to learn a generative model to generate new PDF objects by means of a series of input and output sequences (the input sequences of the PDF sequences correspond to the input sequences in the corresponding sequences in the source model)."}, {"heading": "3.1 Sequence-to-Sequence Neural Network Models", "text": "A recursive neural network (RNN) is a neural network that operates with a variable length input sequence. < x1, x2, \u00b7 \u00b7, xT > and consists of a hidden state h and output y. the RNN processes the input sequence in a series of timestamps (one for each element in the sequence).For a given timestamp t, the hidden state at that time is sequence and the output sequence yt is calculated as: ht = f (ht \u2212 1, xt) yt = (ht), where f is a nonlinear activation function such as sigmoid, tanh, etc., and the sequence is a function such as softmax, which conditions the output sequence probability distribution over a given vocabulary state. RNNs can learn a probability distribution over a character sequence that < x1, x1, x2, and x1 are trained to predict the next sequence >."}, {"heading": "3.2 Generating new PDF objects", "text": "We use the learned seq2seq model to generate new PDF objects. There are many different strategies for q q = PDF generation, depending on the sampling strategy used to capture the learned distribution. We always start with a prefix of the \"obj\" sequence (which marks the beginning of an object instance) and then query the model to generate a sequence of output marks until it produces \"endobj\" that corresponds to the end of the object instance. We now describe three different sampling strategies we use to generate new object instances. NoSample: In this generation strategy, we use the learned distribution to greedily predict the best character with a prefix. This strategy leads to the generation of PDF objects that are most likely well formed and consistent, but it also limits the number of objects that can be generated. Given a prefix like \"j,\" the next sequence is not the best one of the next sequence. \""}, {"heading": "3.3 SampleFuzz: Sampling with Fuzzing", "text": "A perfect learning method would always produce well-shaped objects that would not exert faulty code, while a bad learning method would result in badly-shaped objects that would be quickly rejected by the parser in the first place. To explore this trade-off, we present a new algorithm, called SampleFuzz, to perform some fuzzing while scanning new objects. We use the learned model to generate new PDF object instances, but at the same time introduce anomalies to execute error codes. The SampleFuzz algorithm is shown in Algorithm 1. It takes as input the learned distribution D (x, \u03b8), the probability of merging a character, and a threshold probability used to decide whether to modify the predicted character."}, {"heading": "3.4 Training the Model", "text": "Since we train the seq2seq model in an unsupervised learning environment, we do not have test labels to explicitly determine how well the learned models perform. Instead, we train several models that are parameterized by the number of passes the learning algorithm makes over the training data set. Therefore, an epoch is defined as an iteration of the learning algorithm to go through the entire training data set. We evaluate the seq2seq models that are trained for five different epoch numbers: 10, 20, 30, 40 and 50. In our environment, an epoch takes about 12 minutes to train the seq2seq model, and the 50 epoch model about 10 hours. We use an LSTM model [15] (a variant of RNN) with 2 hidden layers, each layer consisting of 128 hidden states."}, {"heading": "4 Experimental Evaluation", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Experiment Setup", "text": "In this section, we present the results of various fuzzing experiments with the PDF viewer included in Microsoft's new Edge browser. We used a self-contained single-process test driver provided by the Windows team for testing / fuzzing. This executable takes a PDF file as an input argument, executes the PDF parser included in the Microsoft Edge browser, and then stops. If the executable file detects a parsing error due to the PDF input file being incorrect, it prints an error message in an execution log. Hereafter, we simply refer to it as the Edge PDF parser. All the experiments were conducted on 4-core 64-bit Windows 10 VMs with 20 Gb of RAM. We use three main standard metrics to measure the confusing effectiveness: Coverage. For each test run, we measure the coverage of the statements, that is, the set of unique statements that are executed during this test."}, {"heading": "4.2 Training Data", "text": "These 534 files themselves were provided to us by the Windows Fuzzing Team and were used for the previous extended fuzzing of the Edge PDF Parser. This set of 534 files was itself the result of seed minimization, the process of calculating a subset of a larger set of input files that provides the same command coverage as the larger set. Seed minimization is a standard first step that was used before fuzzing files [27, 12]. The larger set of PDF files comes from different sources, such as earlier PDF files used for fuzzing, but also other PDF files collected from the public website. These 63,000 non-binary objects are the training set for the RNNNs we used in this work. Binary objects embedded in PDF files (typically representing images in various image formats) were not included in this work."}, {"heading": "4.3 Baseline Coverage", "text": "To allow for a meaningful interpretation of the coverage results, we randomly selected 1,000 PDF files from our 63,000 training objects, and we measured their coverage with the edge PDF parser, which is used as the baseline for later experiments. A first question is which PDF file we should use in our experiments: Since each PDF file will have some objects in it, a new attached object will interfere with other objects already present in the host, thus affecting the overall coverage and pass rate. To investigate this question, we have selected the smallest three PDF files in our set of 534 files and used them as hosts. These three hosts are respectful of the sizes 26Kb, 33Kb and 16Kb. Figure 4 shows the coverage by running the edge PDF parser on the three hosts, the hosts 1, Host2 and Host3."}, {"heading": "4.4 Learning PDF Objects", "text": "When training the RNN, an important parameter is the number of used epochs (see section 3). We report here on the results of the experiments obtained after training the RNN for 10, 20, 30, 40 and 50 epochs. After the training, we used each learned RNN model to generate 1,000 unique PDF objects. We also compared the generated objects with the 63,000 objects used for training the model and did not find exact comparisons. As explained in section 3, we consider two main modes of the RNN generation: the sample mode, where we scan the distribution at each character position, and the SampleSpace mode, where we scan the distribution only after spaces and generate the top predicted character for other positions."}, {"heading": "4.5 Coverage with Learned PDF Objects", "text": "Figure 6 shows the coverage obtained with SampleSpace and SampleSpace from 10 to 50 epochs using Host1 (top left), Host2 (top right), Host3 (bottom left) and the total coverage of all Host123 hosts (bottom right). The figure also shows the coverage obtained with the corresponding baseline. We observe the following: - In contrast to the pass rate, the host significantly influences the coverage, as previously shown. In addition, the shapes of each line differ from Host1 and Host2 from Host1 to Host2. - The coverage of Sample and SampleSpace is above the base coverage for most epoch results, while they are mostly below the base coverage of Host3 and Host123. - The best overall coverage is also achieved with SampleSpace with 40 epochs (see Host123 data bottom right). - The base coverage is second overall behind SampleSpace 40 epochs after SampleSpace - The best overall coverage is also achieved with 40 epochs."}, {"heading": "4.6 Comparing Coverage Sets", "text": "So far, we have simply counted the number of unique statements covered. We will now look at the total host123 coverage data from Figure 6 and calculate the overlap between the total coverage sets we obtained with our 40-epoch winner Sample-40e and SampleSpace-40e, as well as the baseline123 and host123 total coverage. The results will be shown in Figure 7. We observe the following: - All sets are expected to be almost supersets of host123 (see host123 series), with the exception of a few hundred statements each. - Sample-40e and SampleSpace-40e have almost a superset of all other sets, with the exception of 1680 statements compared to SampleSpace-40e and a few hundred statements compared to baseline123 and host123 (see Sample-40e column). - Sample-40e and SampleSpace-40e have much more statements in common than they differ (10,799 and 1,680), with Sample-40e having a better coverage than SampleSpace-40e."}, {"heading": "4.7 Combining Learning and Fuzzing", "text": "In this section, we will consider several ways to combine learning with fuzzing, and evaluate its effectiveness. In addition, we will consider a widely used simple black box random fuzzing algorithm, called random, which randomly selects a position in a file and then replaces the byte value with a random value between 0 and 255. The algorithm uses a fuzzfactor of 100: the length of the file divided by 100 is the average number of bytes that are fuzzed in that file. We will use random to generate 10 variants of each PDF object generated by each of 40 epochs Sample-40e, SampleSpace-40e, and Baseline. The resulting fuzzed objects will be recombined with our 3 host files to obtain three sets of 30,000 new PDF files, designated by Sample + Random, Samplezz + Random, and Baseline + Random Sample-40e, and Baseline Samplezz instructions, and Baseline Samplezz."}, {"heading": "4.8 Main Takeaway: Tension between Coverage and Pass Rate", "text": "The most important effect of all our experiments is the tension we observe between the coverage and the pass rate. This tension is visible in Figure 8, but it is also visible in previous results: If we relate the coverage results of Figure 6 to the pass rate results of Figure 5, we can clearly see that SampleSpace has a better pass rate than Sample, but Sample has better overall coverage than SampleSpace (see host123 bottom right in Figure 6). Intuitively, this tension can be explained as follows: A pure learning algorithm with a near-perfect pass rate (such as SampleSpace) produces almost only well-shaped objects and exercises little error-handling code. In contrast, a rougher learning algorithm (such as Sample) with a lower pass rate can not only produce many well-shaped objects, but it also produces some poorly-shaped objects that practice error-handling and exercise a little error-handling code."}, {"heading": "4.9 Bugs", "text": "No bugs were found during the experiments previously reported in this section. Note that prior to conducting this study, the edge PDF parser had been thoroughly messed up with other fuzzers (including SAGE [12]) for months, and that all bugs found during these previous fuzzings had been fixed in the version of the PDF parser we used for this study. However, during a longer experiment with Sample + Random, 100,000 objects and 300,000 PDF files (which took nearly 5 days), a stack overflow bug was found in the edge PDF parser: A regular PDF file is generated (its size is 33Kb), but it triggers an unexpected recursion in the parser, which ultimately leads to a stack overflow. This bug was later confirmed and fixed by the Microsoft Edge development team. We plan to conduct further longer experiments in the near future."}, {"heading": "5 Related Work", "text": "This year, it has come to the point where it only takes one year for it to come to a conclusion."}, {"heading": "6 Conclusion and Future Work", "text": "This paper describes the first attempt to automatically generate input grammatics from sample inputs using neural network-based statistical learning techniques. We presented and evaluated algorithms that take advantage of recent advances in neural network sequence learning, namely seq2seq recurring neural networks, to automatically learn a generative model of PDF objects. We developed several sampling techniques to generate new PDF objects from the learned distribution. We show that the learned models are not only able to generate a large number of new well-shaped objects, but also lead to increased coverage of the PDF parser used in our experiments, compared with various forms of random fuzzing. While the results presented in Section 4 may vary for other applications, our general observations of the tension between conflicting learning and fuzzing objectives can vary."}], "references": [{"title": "Synthesizing program input grammars", "author": ["Osbert Bastani", "Rahul Sharma", "Alex Aiken", "Percy Liang"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2016}, {"title": "Automated correction for syntax errors in programming assignments using recurrent neural networks", "author": ["Sahil Bhatia", "Rishabh Singh"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2016}, {"title": "Adaptive neural compilation", "author": ["Rudy R. Bunel", "Alban Desmaison", "Pawan Kumar Mudigonda", "Pushmeet Kohli", "Philip H.S. Torr"], "venue": "In NIPS,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2016}, {"title": "Learning phrase representations using RNN encoder-decoder for statistical machine translation", "author": ["Kyunghyun Cho", "Bart van Merrienboer", "\u00c7aglar G\u00fcl\u00e7ehre", "Dzmitry Bahdanau", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio"], "venue": "In EMNLP,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "Attention-based models for speech recognition", "author": ["Jan K Chorowski", "Dzmitry Bahdanau", "Dmitriy Serdyuk", "Kyunghyun Cho", "Yoshua Bengio"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "QuickCheck: A Lightweight Tool for Random Testing of Haskell Programs", "author": ["K. Claessen", "J. Hughes"], "venue": "In Proceedings of ICFP\u20192000,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2000}, {"title": "yagg: an easy-to-use generator for structured test inputs", "author": ["D. Coppit", "J. Lian"], "venue": "In ASE,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2005}, {"title": "Tupni: Automatic reverse engineering of input formats", "author": ["Weidong Cui", "Marcus Peinado", "Karl Chen", "Helen J Wang", "Luis Irun-Briz"], "venue": "In Proceedings of the 15th ACM conference on Computer and communications security,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2008}, {"title": "Automated testing of refactoring engines", "author": ["Brett Daniel", "Danny Dig", "Kely Garcia", "Darko Marinov"], "venue": "In FSE,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2007}, {"title": "Grammar-based Whitebox Fuzzing", "author": ["P. Godefroid", "A. Kiezun", "M.Y. Levin"], "venue": "In Proceedings of PLDI\u20192008 (ACM SIGPLAN 2008 Conference on Programming Language Design and Implementation), pages 206\u2013215, Tucson, June", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2008}, {"title": "Automated Whitebox Fuzz Testing", "author": ["P. Godefroid", "M.Y. Levin", "D. Molnar"], "venue": "In Proceedings of NDSS\u20192008 (Network and Distributed Systems Security), pages 151\u2013166, San Diego, February", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2008}, {"title": "Deepfix: Fixing common c language errors by deep learning", "author": ["Rahul Gupta", "Soham Pal", "Aditya Kanade", "Shirish Shevade"], "venue": "In AAAI,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2017}, {"title": "Automatic Generation of Test Cases", "author": ["K.V. Hanford"], "venue": "IBM Systems Journal, 9(4),", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1970}, {"title": "Long short-term memory", "author": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber"], "venue": "Neural computation,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1997}, {"title": "Mining input grammars from dynamic taints", "author": ["Matthias H\u00f6schele", "Andreas Zeller"], "venue": "In ASE,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2016}, {"title": "Neural random-access machines", "author": ["Karol Kurach", "Marcin Andrychowicz", "Ilya Sutskever"], "venue": "arXiv preprint arXiv:1511.06392,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2015}, {"title": "Controllable combinatorial coverage in grammar-based testing", "author": ["R. L\u00e4mmel", "W. Schulte"], "venue": "In TestCom,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2006}, {"title": "Directed Test Generation using Symbolic Grammars", "author": ["R. Majumdar", "R. Xu"], "venue": "In ASE,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2007}, {"title": "Generating test data with enhanced context-free grammars", "author": ["P.M. Maurer"], "venue": "IEEE Software, 7(4),", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1990}, {"title": "Neuro-symbolic program synthesis", "author": ["Emilio Parisotto", "Abdel-rahman Mohamed", "Rishabh Singh", "Lihong Li", "Dengyong Zhou", "Pushmeet Kohli"], "venue": null, "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2016}, {"title": "sk p: a neural program corrector for moocs", "author": ["Yewen Pu", "Karthik Narasimhan", "Armando Solar-Lezama", "Regina Barzilay"], "venue": null, "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2016}, {"title": "A sentence generator for testing parsers", "author": ["P. Purdom"], "venue": "BIT Numerical Mathematics, 12(3),", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1972}, {"title": "Using production grammars in software testing", "author": ["E.G. Sirer", "B.N. Bershad"], "venue": "In DSL,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 1999}, {"title": "Sequence to sequence learning with neural networks", "author": ["Ilya Sutskever", "Oriol Vinyals", "Quoc V Le"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2014}, {"title": "Fuzzing: Brute Force Vulnerability Discovery", "author": ["M. Sutton", "A. Greene", "P. Amini"], "venue": "Addison-Wesley,", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2007}, {"title": "A Taxonomy of Model-Based Testing", "author": ["M. Utting", "A. Pretschner", "B. Legeard"], "venue": "Department of Computer Science, The University of Waikato, New Zealand, Tech. Rep, 4,", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2006}], "referenceMentions": [{"referenceID": 24, "context": "There are three main types of fuzzing techniques in use today: (1) blackbox random fuzzing [27], (2) whitebox constraint-based fuzzing [12], and (3) grammar-based fuzzing [23, 27], which can be viewed as a variant of model-based testing [28].", "startOffset": 91, "endOffset": 95}, {"referenceID": 10, "context": "There are three main types of fuzzing techniques in use today: (1) blackbox random fuzzing [27], (2) whitebox constraint-based fuzzing [12], and (3) grammar-based fuzzing [23, 27], which can be viewed as a variant of model-based testing [28].", "startOffset": 135, "endOffset": 139}, {"referenceID": 21, "context": "There are three main types of fuzzing techniques in use today: (1) blackbox random fuzzing [27], (2) whitebox constraint-based fuzzing [12], and (3) grammar-based fuzzing [23, 27], which can be viewed as a variant of model-based testing [28].", "startOffset": 171, "endOffset": 179}, {"referenceID": 24, "context": "There are three main types of fuzzing techniques in use today: (1) blackbox random fuzzing [27], (2) whitebox constraint-based fuzzing [12], and (3) grammar-based fuzzing [23, 27], which can be viewed as a variant of model-based testing [28].", "startOffset": 171, "endOffset": 179}, {"referenceID": 25, "context": "There are three main types of fuzzing techniques in use today: (1) blackbox random fuzzing [27], (2) whitebox constraint-based fuzzing [12], and (3) grammar-based fuzzing [23, 27], which can be viewed as a variant of model-based testing [28].", "startOffset": 237, "endOffset": 241}, {"referenceID": 3, "context": "We use a sequence-to-sequence (seq2seq) [5, 26] network model that has been shown to produce state-of-the-art results for many different learning tasks such as machine translation [26] and speech recognition [6].", "startOffset": 40, "endOffset": 47}, {"referenceID": 23, "context": "We use a sequence-to-sequence (seq2seq) [5, 26] network model that has been shown to produce state-of-the-art results for many different learning tasks such as machine translation [26] and speech recognition [6].", "startOffset": 40, "endOffset": 47}, {"referenceID": 23, "context": "We use a sequence-to-sequence (seq2seq) [5, 26] network model that has been shown to produce state-of-the-art results for many different learning tasks such as machine translation [26] and speech recognition [6].", "startOffset": 180, "endOffset": 184}, {"referenceID": 4, "context": "We use a sequence-to-sequence (seq2seq) [5, 26] network model that has been shown to produce state-of-the-art results for many different learning tasks such as machine translation [26] and speech recognition [6].", "startOffset": 208, "endOffset": 211}, {"referenceID": 3, "context": "[5] introduced a sequence-to-sequence (seq2seq) model that consists of two recurrent neural networks, an encoder RNN that processes a variable dimensional input sequence to a fixed dimensional representation, and a decoder RNN that takes the fixed dimensional input sequence representation and generates the variable dimensional output sequence.", "startOffset": 0, "endOffset": 3}, {"referenceID": 13, "context": "We use an LSTM model [15] (a variant of RNN) with 2 hidden layers, where each layer consists of 128 hidden states.", "startOffset": 21, "endOffset": 25}, {"referenceID": 10, "context": "Each test execution is performed under the monitoring of the tool AppVerifier, a free runtime monitoring tool that can catch memory corruptions bugs (such as buffer overflows) with a low runtime overhead (typically a few percent runtime overhead) and that is widely used for fuzzing on Windows (for instance, this is how SAGE [12] detects bugs).", "startOffset": 326, "endOffset": 330}, {"referenceID": 24, "context": "Seed minimization is a standard first step applied before file fuzzing [27, 12].", "startOffset": 71, "endOffset": 79}, {"referenceID": 10, "context": "Seed minimization is a standard first step applied before file fuzzing [27, 12].", "startOffset": 71, "endOffset": 79}, {"referenceID": 10, "context": "Note that the Edge PDF parser had been thoroughly fuzzed for months with other fuzzers (including SAGE [12]) before we performed this study, and that all the bugs found during this prior fuzzing had been fixed in the version of the PDF parser we used for this study.", "startOffset": 103, "endOffset": 107}, {"referenceID": 24, "context": ", Peach and SPIKE, among many others [27].", "startOffset": 37, "endOffset": 41}, {"referenceID": 12, "context": "Work on grammar-based test input generation started in the 1970\u2019s [14, 23] and is related to model-based testing [28].", "startOffset": 66, "endOffset": 74}, {"referenceID": 21, "context": "Work on grammar-based test input generation started in the 1970\u2019s [14, 23] and is related to model-based testing [28].", "startOffset": 66, "endOffset": 74}, {"referenceID": 25, "context": "Work on grammar-based test input generation started in the 1970\u2019s [14, 23] and is related to model-based testing [28].", "startOffset": 113, "endOffset": 117}, {"referenceID": 18, "context": "Test generation from a grammar is usually either random [20, 25, 8] or exaustive [18].", "startOffset": 56, "endOffset": 67}, {"referenceID": 22, "context": "Test generation from a grammar is usually either random [20, 25, 8] or exaustive [18].", "startOffset": 56, "endOffset": 67}, {"referenceID": 6, "context": "Test generation from a grammar is usually either random [20, 25, 8] or exaustive [18].", "startOffset": 56, "endOffset": 67}, {"referenceID": 16, "context": "Test generation from a grammar is usually either random [20, 25, 8] or exaustive [18].", "startOffset": 81, "endOffset": 85}, {"referenceID": 5, "context": "Imperative generation [7, 10] is a related approach in which a custom-made program generates the inputs (in effect, the program encodes the grammar).", "startOffset": 22, "endOffset": 29}, {"referenceID": 8, "context": "Imperative generation [7, 10] is a related approach in which a custom-made program generates the inputs (in effect, the program encodes the grammar).", "startOffset": 22, "endOffset": 29}, {"referenceID": 17, "context": "Grammar-based fuzzing can also be combined with whitebox fuzzing [19, 11].", "startOffset": 65, "endOffset": 73}, {"referenceID": 9, "context": "Grammar-based fuzzing can also be combined with whitebox fuzzing [19, 11].", "startOffset": 65, "endOffset": 73}, {"referenceID": 0, "context": "[2] present an algorithm to synthesize a context-free grammar given a set of input examples, which is then used to generate new inputs for fuzzing.", "startOffset": 0, "endOffset": 3}, {"referenceID": 14, "context": "AUTOGRAM [16] also learns (non-probabilistic) context-free grammars given a set of inputs but by dynamically observing how inputs are processed in a program.", "startOffset": 9, "endOffset": 13}, {"referenceID": 7, "context": "Tupni [9] is another system that reverse engineers an input format from examples using a taint tracking mechanism that associate data structures with addresses in the application address space.", "startOffset": 6, "endOffset": 9}, {"referenceID": 15, "context": "Several neural architectures have been proposed to learn simple algorithms such as array sorting and copying [17, 24].", "startOffset": 109, "endOffset": 117}, {"referenceID": 19, "context": "Neural FlashFill [21] uses novel neural architectures for encoding input-output examples and generating regular-expression-based programs in a domain specific language.", "startOffset": 17, "endOffset": 21}, {"referenceID": 1, "context": "Several seq2seq based models have been developed for learning to repair syntax errors in programs [3, 13, 22].", "startOffset": 98, "endOffset": 109}, {"referenceID": 11, "context": "Several seq2seq based models have been developed for learning to repair syntax errors in programs [3, 13, 22].", "startOffset": 98, "endOffset": 109}, {"referenceID": 20, "context": "Several seq2seq based models have been developed for learning to repair syntax errors in programs [3, 13, 22].", "startOffset": 98, "endOffset": 109}, {"referenceID": 2, "context": "Other related work optimizes assembly programs using neural representations [4].", "startOffset": 76, "endOffset": 79}], "year": 2017, "abstractText": "Fuzzing consists of repeatedly testing an application with modified, or fuzzed, inputs with the goal of finding security vulnerabilities in input-parsing code. In this paper, we show how to automate the generation of an input grammar suitable for input fuzzing using sample inputs and neural-network-based statistical machine-learning techniques. We present a detailed case study with a complex input format, namely PDF, and a large complex security-critical parser for this format, namely, the PDF parser embedded in Microsoft\u2019s new Edge browser. We discuss (and measure) the tension between conflicting learning and fuzzing goals: learning wants to capture the structure of well-formed inputs, while fuzzing wants to break that structure in order to cover unexpected code paths and find bugs. We also present a new algorithm for this learn&fuzz challenge which uses a learnt input probability distribution to intelligently guide where to fuzz inputs.", "creator": "TeX"}}}