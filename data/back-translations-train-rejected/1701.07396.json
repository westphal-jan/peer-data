{"id": "1701.07396", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Jan-2017", "title": "LAREX - A semi-automatic open-source Tool for Layout Analysis and Region Extraction on Early Printed Books", "abstract": "A semi-automatic open-source tool for layout analysis on early printed books is presented. LAREX uses a rule based connected components approach which is very fast, easily comprehensible for the user and allows an intuitive manual correction if necessary. The PageXML format is used to support integration into existing OCR workflows. Evaluations showed that LAREX provides an efficient and flexible way to segment pages of early printed books.", "histories": [["v1", "Fri, 20 Jan 2017 09:48:59 GMT  (1852kb)", "http://arxiv.org/abs/1701.07396v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.AI", "authors": ["christian reul", "uwe springmann", "frank puppe"], "accepted": false, "id": "1701.07396"}, "pdf": {"name": "1701.07396.pdf", "metadata": {"source": "CRF", "title": "LAREX \u2013 A semi-automatic open-source Tool for Layout Analysis and Region Extraction on Early Printed Books", "authors": ["Christian Reul", "Uwe Springmann", "Frank Puppe"], "emails": ["christian.reul@uni-", "springmann@cis.uni-", "frank.puppe@uni-"], "sections": [{"heading": null, "text": "Categories and technical descriptions Applied Informatics: Document Management and Word Processing - Document Analysis, Optical Character Recognition.General Terms Algorithms, Experiments, Human Factors, Performance Keywords Layout Analysis, Segmentation, Old Printed Products"}, {"heading": "1. INTRODUCTION", "text": "With the large amount of historical documents that have been available as scanned images in recent years, the race is now open to unlock this obtained data and make it available as fully electronic, machine-transferable research data. Several hurdles need to be overcome; the first sub-goal is high-quality recognition of printed (and manuscript) texts with properties (unusual glyphs, fonts, background noise, etc.) that have recently been achieved through recursive neural networks with LSTM architecture (see [1] and [2] for printed books with recognition rates above 95% and [3] for manuscripts."}, {"heading": "2. RELATED WORK", "text": "Given our focus on open source tools and workflows, it makes sense to divide existing tools into open source and proprietary software. Among the proprietary tools are the ABBYY2 OCR (Finereader and Recognition Server) products, which define the status quo of the available automatic products with a variety of layouts, the disadvantage being that they cannot be customized by the end user. The company has no interest in the relatively low volume of historical documents and, less importantly, is still interested in them being assigned a fee."}, {"heading": "3. LAREX", "text": "The aim of LAREX (Layout Analysis and Region Extraction), currently being developed at the University of W\u00fcrzburg, is to assist end users in segmenting and classifying regions in images. In this article, we discuss its application for analysing previously printed books. The segmentation process is user-oriented and uses an approach of networked components. It is based on two main assumptions: First, it is based on the premise that related characters, words and lines of text tend to be closer together than unrelated ones; second, it expects most pages within the same book to have similar layouts or to belong to at least one of only a few layout categories. LAREX is not designed to be able to automatically segment a particular document to perfection. In contrast, it aims to provide the user with a quick and easy-to-understand way to adapt to a particular layout, receive a segmentation suggestion and, if necessary, provide manual correction."}, {"heading": "3.1 Overview", "text": "The aim of the proposed approach is to identify and classify different regions on a scanned page (see Figure 1).7 https: / / sites.google.com / site / paradiitproject / homeThese regions are interconnected areas on a page such as image, running text (paragraph), headers, marginals, page numbers, etc. LAREX uses PageXML format 8 type definitions to designate regions. The segmentation workflow consists of the following main steps, illustrated in Figure 2: Input: scanned page. Output: scanned segments as PageXML. 1. Pre-processing: Input \u2192 Reduced Binary Size ([A in Figure 2]).1.1. Conversion into binary. 1.2. Definition of a region of interest (optional). 1.3. Resizing of image segments as PageXML. 1. Image processing: Input \u2192 Reduced Binary Size (A in Figure 1.1) in Figure 1.1."}, {"heading": "3.2 Detailed Description of the Algorithm", "text": "This section describes the steps of the basic workflow: Optional manual customization and advanced text recognition are discussed separately in Section 3.3 and 3.4.8 http: / / www.primaresearch.org / tools / PAGELibraries"}, {"heading": "3.2.1 Preprocessing", "text": "LAREX accepts color, grayscale, and binary images as input, but upcoming growth and contour detection operations require the binary format, so conversion may be performed. Obviously, the resulting segmentation still matches the original input image. Users can work on the entire binary image or specify a region of interest by drawing a rectangle, for example, to exclude artifacts from the input image by scanning it. Anything outside the specified range is painted white and has no effect on the rest of the segmentation process. A region of interest can be specified for a single page or applied to the entire book. It can be customized at any time. The image is resized to a preset resolution (default: 1600 pixels in height) to speed up the segmentation process and normalize parameters such as the upcoming size catchments or the required minimum area of the regions."}, {"heading": "3.2.2 Image Detection", "text": "Images are expected to have a certain minimum area and are either very compact or have a border. First, an expansion operation is performed that also uses small core values to prevent the merging of letters and words. It can be thought of as a growing process in which black foreground pixels merge within a defined core. All connected components larger than the default image area threshold (3000 pixels) are marked as images. To further edit, either only the contours themselves or the straight or rotated boundary rectangles around them are removed from the image."}, {"heading": "3.2.3 Coarse text region detection", "text": "In step 3.2, the newly created regions are assigned a type by enforcing multiple constraints, so the constraints on type classification (Table 4) use the region attributes shown in Table 1, constants in Table 2, and functions in Table 3.9 Default case for marginals: Rectangle must be within the left or right side of the page.Table 4 Restrictions on standard text types.Type constraints paragraph Region.area > minAreaParagraphmarginalia Region.area > minAreaMarginalia, inside (region.rectangle, marginalia.rectangles) 9page numberregion.area > minAreaPageNumber, inside (region.rectangle, pageNumber, within the region.rectangle, pageNumber.rectangles) 10, max-occurrence = top Table 4 shows constraints of three region types: minAreaPageNumber, inside (region.rectangle, pagenumber, pumber, pagentype, within the regional.page.getrectangles, the page.page.page)."}, {"heading": "3.2.4 Conversion to output format", "text": "If the user is satisfied, the segmentation result can be saved as an XML file in PageXML format. Thus, the segmentation result is recalculated to the actual size of the input image. Subsequently, the resulting file is stored in the same folder as the input using the same filename."}, {"heading": "3.3 Manual Adaptions", "text": "In many cases, the default parameters are not sufficient to achieve a satisfactory segmentation result. In the following sections, global and local operations are presented to improve the results."}, {"heading": "3.3.1 Global Adjustments to the given Book", "text": "Figure 3 shows a sample result of the default setup, which consists of four regions (Figure: green, can appear anywhere on the page; paragraph: red, everywhere; marginal areas: yellow, left and right 25%; page number: cyan, top and bottom 25%). Obviously, there is still some work to be done. The initial letter has been correctly recognized as well as the page number. However, the marginal areas have been classified as paragraphs because their outer contour was not completely within the marginal areas. In addition, there is a signature at the very bottom of the page. This is because the vertical distance between the text lines is relatively large, resulting in the unwanted separation of text blocks. It is worth noting that the marginal group at the bottom right is not classified as a page number, although it is in a legitimate position, because the maximum occurrence value of the page number region is 1 and the priority position is above. The default setting can be easily adjusted by a few clicks on the top page, the top page is always moved to the top page and the top page."}, {"heading": "3.3.2 Local Manual Corrections", "text": "In special cases, the user can make changes, such as adjusting regional parameters or manually adjusting the obtained segment result by deleting segments, changing their type and columns or merging. Figure 3, for example, links the signature cursor to the lower text block, which is difficult to correct in global parameter optimization. There are several ways to deal with such problems (see Figure 4): You can cut the segments by drawing a line or string, and automatically assign the right type to the separated block when it is within the appropriate position. Alternatively, you can mark segments by drawing a rectangle or polygon around them and assigning them a type that remains fixed for the entire segmentation process and is unaffected by other parameters."}, {"heading": "3.4 Text Sub-Region Segmentation", "text": "Sometimes it is necessary to trim a found block of text along one or more lines, for example when a headline or highlighted first line of a paragraph needs to be trimmed off from the rest of the text. It can be done by dragging an intersection line. If strong line segmentation is required, you can use Tesseract's page segmentation algorithm and correct it manually instead of doing it entirely manually."}, {"heading": "3.4.1 Locating the Lines", "text": "If a segment is too small for Tesseract to predict the required angle, the weighted average of the remaining segments is used. Now, line segmentation can take place. Afterwards, the resulting lines are rotated back to their original position. This process can be quite time consuming: In a test on an image of the size 5100 x 7800 pixels, it took a PC (i7-6700) at 3.40 GHz about 20 seconds to complete line segmentation. Reducing the image resolution usually significantly deteriorates the result. Therefore, it is recommended to collect any number of temporary segmentation results and then process them all at once, e.g. during nighttime. The resulting line coordinates are stored in a separate PageXML file and automatically adapted to the original segmentation result as soon as the corresponding image is drawn on the corresponding page, or the segmentation tool is moved directly over the line."}, {"heading": "3.4.2 Putting the Line Segmentation to Use", "text": "While manually separating a block of text is a tedious task, it is much easier when using the lines of text. After selecting a line with a mouse click, the user can cut out the segment below or above the selected line. A third option is to change the line type, which automatically triggers both clippings.Figure 6 shows line segmentation in action. In this special book, each chapter begins with a heading that looks like standard text but is slightly indented. It is followed by the first line of the paragraph, which is printed in a larger, more prominent font. The standard segmentation process recognizes a single block (top left) because the gaps around these specific parts of the text correspond to those of the standard text. The task is to separate these segments from the text and assign them the correct types. It can be done by a few simple actions: After line segmentation (top right), the first line of the paragraph is marked as the desired type (bottom left; the line will be cut blue)."}, {"heading": "4. EVALUATION", "text": "Due to its interactive design, it would be misleading to compare LAREX with approaches that use evaluation metrics for fully automated tools. Furthermore, for an interactive tool, the overall time and user effort required for satisfactory segmentation is important. Therefore, both the number of problems and the time taken to correct them were evaluated. We report two evaluations: the first with the standard tool and the second with minor extensions for specific requirements. In addition to time exposure, the OCR accuracy of the resulting text regions was compared with that obtained by fully manual segmentation."}, {"heading": "4.1 Evaluating the Standard Functionality", "text": "The first assessment was made on \"The Shyp of Folys\" 11 as part of an effort to support the Digital Narragonia Project. The book consists of 570 pages and switches between English and Latin text. Figure 7 shows the segmentation guidelines for this task: images and initials must be marked while the ornaments around the image must be discarded. All text regions, marginals, signatures and page numbers / sheet titles must be recorded. Image descriptions must be classified as normal text. The segmentation process was performed by a student research assistant of the Digital Narragonia Project who had some prior experience with LAREX but no background in computer science, image editing or layout analysis. In total, 378 corrections were made on the first 200 of the 570 scanned pages (see Table 5)."}, {"heading": "4.2 Application to \u2018Der Heiligen Leben\u2019", "text": "LAREX was also used for the book \"Der Heilige Leben\" (The Holy Life), which Anton Koberger printed in Nuremberg in 148813. (For an incomplete description see Reul et al.: Case Study of a high automated Layout Analysis and OCR of an incunabulum: \"Der Heilige Leben\" (1488) (submitted to this conference). Figure 8 shows a representative selection of page layouts occurring in the book. A slight change in the standard structure was necessary to achieve an appealing rough segmentation. However, at this point several headlines, i.e. lines consisting of more prominent letters, were often 12 http: / / kallimachos.de / kallimachos / index.php / Narragonien 13 http: / / vb.uni-wuerzburg.de / ub / itf954 / ueber.htmlquietly associated with or even surrounded by running text."}, {"heading": "5. DISCUSSION", "text": "The evaluation showed that, due to its interactivity and flexibility, LAREX is a powerful tool for segmentation of previously printed books. Assessing the required user actions made it clear that LAREX enables the user to greatly influence the result with minimal effort and without changing the setup itself. A common error is, for example, the non-separation of small text blocks such as signature marks or keywords from the running text. Such errors would be avoided with considerable effort by adjusting the expected region positions or dilation core, as there is no real spatial separation from the neighboring region. However, it is very easy to correct these errors manually. Assessing and optimizing such trade-offs is part of our future work. Application to \"The Holy Life\" showed that further functionality can drastically reduce the required user effort and only slightly reduce OCR accuracy."}, {"heading": "6. CONCLUSION AND FUTURE WORK", "text": "A semi-automatic tool for layout analysis and region extraction has been proposed. LAREX uses parameters to be flexible enough to adapt to different book layouts; it provides maximum value for books with an extensive number of pages whose layouts are complex but consist of clearly spatially separated segments; the manual corrections can be made in a simple and time-efficient manner. LAREX does not offer near-pixel-perfect segmentation like Aletheia. However, as the experiments on \"The Holy Life\" have shown, there are cases where a much faster but slightly less accurate segmentation may be quite sufficient. Although LAREX is already a fully functional tool, there are many things that could be added or refined to further improve it: first, the rule functionality as described in Chapter 5 is extended to provide more parameters and make the tool more flexible for the user."}, {"heading": "7. ACKNOWLEDGMENTS", "text": "The authors thank Maximilian Wehner and Maximilian N\u00f6th for their test efforts, Marco Dittrich and Martin Gruner for their helpful hints about the tool and the University Library W\u00fcrzburg for providing the necessary scans."}, {"heading": "8. REFERENCES", "text": "[1] Springmann, U. and L\u00fcdeling, A. 2016. OCR of historicalprintings with an application to building diachronic corpora: A case study using the RIDGES herbal corpus. ArXiv e-prints. URL = http ps: / / arxiv.org / abs / 1608.02153. Accepted by Digital Humanities Quarterly. [2] Springmann, U., Fink, F. and Schulz, K. U. 2016. Automatic quality evaluation and (semi-) automatic improvement of OCR models for historical printings. ArXiv e-prints. ArXiv e-prints. URL = https / / arxiv.org / abs / 1606.05157. [3] Fischer, A., W\u00fctherich, Liwicki, M., Frinken, V., Bunke, H., Viehhauser, G. and Stolz, M. 2009."}], "references": [{"title": "OCR of historical printings with an application to building diachronic corpora: A case study using the RIDGES herbal corpus. ArXiv e-prints", "author": ["U. Springmann", "A. L\u00fcdeling"], "venue": "URL = https://arxiv.org/abs/1608.02153", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2016}, {"title": "Automatic quality evaluation and (semi-) automatic improvement of OCR models for historical printings", "author": ["U. Springmann", "F. Fink", "K.U. Schulz"], "venue": "ArXiv e-prints", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2016}, {"title": "Automatic transcription of handwritten medieval documents", "author": ["A. Fischer", "M. W\u00fctherich", "M. Liwicki", "V. Frinken", "H. Bunke", "G. Viehhauser", "M. Stolz"], "venue": "15th Int. Conf. on Virtual Systems and Multimedia (VSMM\u201909)", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2009}, {"title": "Aletheia \u2013 An Advanced Document Layout and Text Ground-Truthing System for Production Enviroments", "author": ["C. Clausner", "S. Pletschacher", "A. Antonacopoulos"], "venue": "Int. Conf. on Document Analysis and Recognition (ICDAR", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2011}, {"title": "The SCRIBO Module of the OLENA Platform: A Free Software Framework for Document Image Analysis", "author": ["G. Lazzara", "R. Levillain", "T. Geraud", "Y. Jacquelet", "J. Marquegnies", "A. Crepin-Leblond"], "venue": "Int. Conf. on Document Analysis and Recognition (ICDAR", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2011}, {"title": "Historical Document Layout Analysis Competition", "author": ["A. Antonacopoulos"], "venue": "Int. Conf. on Document Analysis and Recognition (ICDAR", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2011}, {"title": "AGORA: the Interactive Document Image Analysis Tool of the BVH Project", "author": ["J.Y. Ramel", "S. Busson", "M.L. Demonet"], "venue": "Proceedings of the 2nd Int. Conf. on Document Analysis for Libraries (DIAL \u201906)", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2006}, {"title": "Automatic Assessment of OCR Quality in Historical Documents", "author": ["A. Gupta", "R. Gutierrez-Osuna", "M. Christy", "B. Capitanu", "L. Auvil", "L. Grumbach", "R. Furuta", "L. Mandell"], "venue": "Proceedings of the 29th AAAI Conference on Artificial Intelligence (AAAI", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "This has recently been achieved by trained recurrent neural networks with LSTM architecture (see [1] and [2] for printed books with character recognition rates above 95% and [3] for manuscripts).", "startOffset": 97, "endOffset": 100}, {"referenceID": 1, "context": "This has recently been achieved by trained recurrent neural networks with LSTM architecture (see [1] and [2] for printed books with character recognition rates above 95% and [3] for manuscripts).", "startOffset": 105, "endOffset": 108}, {"referenceID": 2, "context": "This has recently been achieved by trained recurrent neural networks with LSTM architecture (see [1] and [2] for printed books with character recognition rates above 95% and [3] for manuscripts).", "startOffset": 174, "endOffset": 177}, {"referenceID": 3, "context": "Aletheia4 (see [4]) is a highly functional proprietary product from PRIMA research group at the University of Salford.", "startOffset": 15, "endOffset": 18}, {"referenceID": 4, "context": "The SCRIBO module of the OLENA platform (see [5]) is an opensource layout analysis framework which finished second at the", "startOffset": 45, "endOffset": 48}, {"referenceID": 5, "context": "2011 competition on historical book recognition (see [6]).", "startOffset": 53, "endOffset": 56}, {"referenceID": 6, "context": "Agora is an open-source software developed in the PARADIIT project7 of the University of Tours (see [7]).", "startOffset": 100, "endOffset": 103}, {"referenceID": 7, "context": "[8] proposed a method that utilizes Tesseract\u2019s automatic segmentation in order to perform a text/noise classification on the obtained word bounding boxes.", "startOffset": 0, "endOffset": 3}], "year": 2017, "abstractText": "A semi-automatic open-source tool for layout analysis on early printed books is presented. LAREX uses a rule based connected components approach which is very fast, easily comprehensible for the user and allows an intuitive manual correction if necessary. The PageXML format is used to support integration into existing OCR workflows. Evaluations showed that LAREX provides an efficient and flexible way to segment pages of early printed books.", "creator": "Acrobat PDFMaker 15 f\u00fcr Word"}}}