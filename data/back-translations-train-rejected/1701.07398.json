{"id": "1701.07398", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Jan-2017", "title": "Learning an attention model in an artificial visual system", "abstract": "The Human visual perception of the world is of a large fixed image that is highly detailed and sharp. However, receptor density in the retina is not uniform: a small central region called the fovea is very dense and exhibits high resolution, whereas a peripheral region around it has much lower spatial resolution. Thus, contrary to our perception, we are only able to observe a very small region around the line of sight with high resolution. The perception of a complete and stable view is aided by an attention mechanism that directs the eyes to the numerous points of interest within the scene. The eyes move between these targets in quick, unconscious movements, known as \"saccades\". Once a target is centered at the fovea, the eyes fixate for a fraction of a second while the visual system extracts the necessary information. An artificial visual system was built based on a fully recurrent neural network set within a reinforcement learning protocol, and learned to attend to regions of interest while solving a classification task. The model is consistent with several experimentally observed phenomena, and suggests novel predictions.", "histories": [["v1", "Tue, 24 Jan 2017 09:07:59 GMT  (3394kb,D)", "http://arxiv.org/abs/1701.07398v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.AI", "authors": ["alon hazan", "yuval harel", "ron meir"], "accepted": false, "id": "1701.07398"}, "pdf": {"name": "1701.07398.pdf", "metadata": {"source": "CRF", "title": "Learning an Attention Model in an Artificial Visual System", "authors": ["Alon Hazan", "Yuval Harel", "Ron Meir"], "emails": [], "sections": [{"heading": null, "text": "Most scientists have many tools at their disposal to study the brain and neural networks in general, including electroencephalography (EEG), single-photon emission computed tomography (SPECT), functional magnetic resonance imaging (fMRI), and microelectrode arrays (MEA), to name a few. The amount of information and level of control provided by these tools is nowhere near what is available to an engineer working on an artificial neural network. An engineer can manipulate any neuron at any time by making specific stimuli and collecting as much data across the network as necessary."}, {"heading": "II. THE ARTIFICIAL VISUAL SYSTEM", "text": "It is a simplified model of the human visual system, consisting of a small region in the center with high resolution, analogous to the human fovea, and two larger concentric regions, which are subsampled at a lower resolution and analogous to the peripheral visual system in humans. AVS has been trained and tested for classification of handwritten digits from the MNIST dataset [8]. Only a small portion of the image is visible to the AVS at all times. Specifically, the full resolution is only available at the fovea, which is 9-by-9 pixels, as in the [7], or 5-by-5 pixels (about 69% smaller)."}, {"heading": "III. RESULTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Use of memory", "text": "Since information that the neural network has accumulated over time is mixed into the state of the network, it is not obvious that the potential to extract useful historical information can be exploited within the solution of the attention model. To test the use of memory by the trained network, two similar AVS were trained to perform the task of attention classification. In the first AVS, recurring weights were random, while the second AVS was designed to \"forget\" historical information by setting the recurring weight matrix to zero. Memory use depended on the size of the fovea. Fig. 2 shows the performance of the system over training periods, while the case of a large (9 \u00d7 9 pixels) fovea, which is the last parameter of the fovea. Originally, the AVS with the memory has the advantage that the attention model is still poor, resulting in relatively little informative results."}, {"heading": "B. Gathering Information", "text": "To assess whether our AVS behaves similarly, we need to characterize the relevant information in the context of our task. As the network classification yID depends linearly on the network state in the final step, we quantify the task information as the best linear separation of the network state between each class and the other classes. Accordingly, we use the Linear Discrimination Analysis (LDA) [13], which aims to find the projection that minimizes the distance between the samples of the same cluster Sw while maximizing the distance between the clusters Sb. Distance within each class is measured by the variance of the samples belonging to that class, and Sw is considered the mean of these distances across all classes. Distance between classes Sb is defined as the variance of the class centers."}, {"heading": "C. Transfer learning", "text": "In fact, the majority of people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move"}, {"heading": "E. Learning aided by demonstration (guidance)", "text": "Learning by Demonstration (or Learning with Guidance) was implemented in AVS. Demonstration differs from monitoring in two ways: First, demonstration is not continuous and is applied only sparsely in a timely manner to propose new paths to the system. Second, demonstration is not required to provide the best solution for the system because the system retains its freedom to explore and even improve it. Demonstration was achieved by making to the network a sparse and naive proposal for the attention model. For example, at 10% of the paths at last view, the system was steered into the center of the digit. Such a partial direction resulted in a significant improvement in both the learning speed and the final success rate, as shown in Figure 8.Demonstration in the AVS system allows by manipulating the exploration noise. Exploratory noise is a Gaussian white noise and as such, the probability that the exploration system will accept a value of more than zero. Since the output of the system at a given time will allow for the attention to be given to a specific feature of this noise, we can force the output of the exploration system by specifying the noise in a particular output is determined in the exploration system."}, {"heading": "IV. CONCLUSION", "text": "We have shown that a simple artificial visual system implemented by a relapsing neural network using political gradient enhancement learning can be trained to perform the classification of objects much larger than the central region with high visual acuity. Although the system receives only classification-based rewards, it develops an active vision solution that directs attention to relevant parts of the image in a task-dependent manner. Importantly, internal network memory plays an essential role in maintaining information across saccades, so that the final classification is achieved by combing information from the current visual input and from earlier inputs represented in the network state. Within a generic active vision system without specifically designed features, we were able to explain several characteristic features of biological vision: (i) Good classification performance through amplification learning based on severely restricted central and low resolution peripheral vision (ii) identification by performing tasks relevant to (ii)."}], "references": [{"title": "How people look at pictures: a study of the psychology and perception in art", "author": ["G T Buswell"], "venue": "Chicago University of Chicago Press,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1935}, {"title": "Portable eyetracking: a study of natural eye movements", "author": ["Jeff B. Pelz", "Roxanne L. Canosa", "Diane Kucharczyk", "Jason Babcock", "Amy Silver", "Daisei Konno"], "venue": "Proceedings of SPIE,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2000}, {"title": "The knowledge base of the oculomotor system", "author": ["M F Land", "S Furneaux"], "venue": "Philosophical transactions of the Royal Society of London. Series B, Biological sciences,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1997}, {"title": "Multiple reward signals in the brain", "author": ["W Schultz"], "venue": "Nature reviews. Neuroscience,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2000}, {"title": "Eye movements in natural behavior", "author": ["Mary Hayhoe", "Dana Ballard"], "venue": "Trends in Cognitive Sciences,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2005}, {"title": "Recurrent Models of Visual Attention", "author": ["Volodymyr Mnih", "Nicolas Heess", "Alex Graves", "Koray Kavukcuoglu"], "venue": "Advances in Neural Information Processing Systems,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "Gradient-based learning applied to document recognition", "author": ["Yann LeCun", "Leon Bottou", "Yoshua Bengio", "Patrick Haffner"], "venue": "Proceedings of the IEEE,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1998}, {"title": "What\u2019 and \u2019where\u2019 in the human brain", "author": ["L Ungerleider"], "venue": "Current Opinion in Neurobiology,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1994}, {"title": "The \u201cecho state\u201d approach to analysing and training recur- rent neural networks. GMD-Forschungszentrum Informationstechnik", "author": ["H Jaeger"], "venue": "Report 148,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2001}, {"title": "Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning", "author": ["Ronald J. Williams"], "venue": "Machine Learning,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1992}, {"title": "Human gaze control during real-world scene perception", "author": ["John M. Henderson"], "venue": "Trends in Cognitive Sciences,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2003}, {"title": "Introduction to Statistical Pattern Recognition", "author": ["Keinosuke Fukunaga"], "venue": "Pattern Recognition,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1990}, {"title": "Neural correlates of motor learning, transfer of learning, and learning to learn", "author": ["Rachael D Seidler"], "venue": "Exercise and sport sciences reviews,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2010}], "referenceMentions": [{"referenceID": 0, "context": "Saccadic eye movements are quick, unconscious, task-dependent [1] motions following the demand of attention [2], that direct the eye to new targets that require the high resolution of the fovea.", "startOffset": 108, "endOffset": 111}, {"referenceID": 1, "context": "These targets are usually detected within the peripheral visual system [3].", "startOffset": 71, "endOffset": 74}, {"referenceID": 2, "context": "Most eye movements are proactive rather than reactive, predict actions in advance and do not merely respond to visual stimuli [4].", "startOffset": 126, "endOffset": 129}, {"referenceID": 3, "context": "There is good evidence that much of the active vision in humans results from Reinforcement Learning (RL) [5], as part of and organism\u2019s attempt to maximize its performance while interacting with the environment [6].", "startOffset": 105, "endOffset": 108}, {"referenceID": 4, "context": "There is good evidence that much of the active vision in humans results from Reinforcement Learning (RL) [5], as part of and organism\u2019s attempt to maximize its performance while interacting with the environment [6].", "startOffset": 211, "endOffset": 214}, {"referenceID": 5, "context": "The AVS is similar in many ways to that presented in [7].", "startOffset": 53, "endOffset": 56}, {"referenceID": 6, "context": "The AVS was trained and tested on the classification of handwritten digits from the MNIST data set [8] .", "startOffset": 99, "endOffset": 102}, {"referenceID": 5, "context": "Specifically, full resolution is only available at the fovea, which is 9-by-9 pixels, as in [7], or 5-by-5 pixels (about 69% smaller).", "startOffset": 92, "endOffset": 95}, {"referenceID": 5, "context": "(unlike [7]), and movements of the observation location are not constrained to image boundaries.", "startOffset": 8, "endOffset": 11}, {"referenceID": 5, "context": "3) The observation (called \u2018glimpse\u2019 [7]) from the current location is projected upon the network through Win, along with any pre-existing information within the network state through the recurrent weights W .", "startOffset": 37, "endOffset": 40}, {"referenceID": 8, "context": "Its network topology is similar the Echo State Network (ESN) [10] in that the recurrent neural connections are drawn randomly and are not constrained to a particular topology such as in layered feedforward networks, or long short-term memory networks.", "startOffset": 61, "endOffset": 65}, {"referenceID": 9, "context": "The gradient of the expected reward J is estimated as in [11],", "startOffset": 57, "endOffset": 61}, {"referenceID": 9, "context": "where \u03c4 = (s0, w1, (on, sn, y n , y ID n ) Ng n=1) is a random trajectory of Ng glimpses, p (\u03c4) is the probability of trajectory \u03c4 , r (\u03c4) the observed (usually binary) reward, b a fixed baseline computed as in [11], w1 is the random location of the first glimpse, and \u3008\u00b7\u3009 indicates averaging over trajectories.", "startOffset": 211, "endOffset": 215}, {"referenceID": 10, "context": "The human visual system acts to maximize the information relevant to the task [12].", "startOffset": 78, "endOffset": 82}, {"referenceID": 11, "context": "Accordingly, we use Linear Discriminant Analysis (LDA) [13], which acts to find the projection that minimizes the distance between samples of the same cluster Sw while at the same time maximizes the distance between clusters Sb.", "startOffset": 55, "endOffset": 59}, {"referenceID": 12, "context": ", proficiency at tennis is beneficial when learning racquetball and even seemingly unrelated tasks such as skiing for example [14].", "startOffset": 126, "endOffset": 130}, {"referenceID": 4, "context": "The eyes are not directed to the most visually salient points in the field of view, but rather to the ones that are most relevant for the task at hand [6].", "startOffset": 151, "endOffset": 154}], "year": 2017, "abstractText": "The Human visual perception of the world is of a large fixed image that is highly detailed and sharp. However, receptor density in the retina is not uniform: a small central region called the fovea is very dense and exhibits high resolution, whereas a peripheral region around it has much lower spatial resolution. Thus, contrary to our perception, we are only able to observe a very small region around the line of sight with high resolution. The perception of a complete and stable view is aided by an attention mechanism that directs the eyes to the numerous points of interest within the scene. The eyes move between these targets in quick, unconscious movements, known as \u201csaccades\u201d. Once a target is centered at the fovea, the eyes fixate for a fraction of a second while the visual system extracts the necessary information. An artificial visual system was built based on a fully recurrent neural network set within a reinforcement learning protocol, and learned to attend to regions of interest while solving a classification task. The model is consistent with several experimentally observed phenomena, and suggests novel predictions.", "creator": "LaTeX with hyperref package"}}}