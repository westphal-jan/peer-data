{"id": "1701.07570", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Jan-2017", "title": "Strongly Adaptive Regret Implies Optimally Dynamic Regret", "abstract": "To cope with changing environments, recent literature in online learning has introduced the concepts of adaptive regret and dynamic regret independently. In this paper, we illustrate an intrinsic connection between these two concepts by showing that the dynamic regret can be expressed in terms of the adaptive regret and the functional variation. This observation implies that strongly adaptive algorithms can be directly leveraged to minimize the dynamic regret. As a result, we present a series of strongly adaptive algorithms whose dynamic regrets are minimax optimal for convex functions, exponentially concave functions, and strongly convex functions, respectively. To the best of our knowledge, this is first time that such kind of dynamic regret bound is established for exponentially concave functions. Moreover, all of those adaptive algorithms do not need any prior knowledge of the functional variation, which is a significant advantage over previous specialized methods for minimizing dynamic regret.", "histories": [["v1", "Thu, 26 Jan 2017 03:54:21 GMT  (18kb)", "https://arxiv.org/abs/1701.07570v1", null], ["v2", "Wed, 22 Feb 2017 15:12:55 GMT  (20kb)", "http://arxiv.org/abs/1701.07570v2", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["lijun zhang", "tianbao yang", "rong jin", "zhi-hua zhou"], "accepted": false, "id": "1701.07570"}, "pdf": {"name": "1701.07570.pdf", "metadata": {"source": "CRF", "title": "Strongly Adaptive Regret Implies Optimally Dynamic Regret", "authors": ["Lijun Zhang", "Tianbao Yang", "Rong Jin", "Zhi-Hua Zhou"], "emails": ["zhanglj@lamda.nju.edu.cn", "tianbao-yang@uiowa.edu", "jinrong.jr@alibaba-inc.com", "zhouzh@lamda.nju.edu.cn"], "sections": [{"heading": null, "text": "ar Xiv: 170 1,07 570v 2 [cs.L G"}, {"heading": "1. Introduction", "text": "It is not only the way in which the learner responds to the question of the way he responds to the question of the way he responds to the question of the way he responds to the question of the way he responds to the question of the way he responds to the question of the way he responds to the question of the way he responds to the question of the way he responds to the question of the way he responds to the question of the way he responds to the question of the way he responds to the question of the way he responds to the question of the way he responds to the question of the way he responds to the question of the way he responds to the question of the way he responds to the question of the way he responds to the way he responds to the question of the way he responds to the question of the way he responds to the question of the way he responds to the question of the way he responds to the question of the way he responds to the way he responds to the question of the way he responds to the question of the way he responds to the question of the way he responds to the way he responds to the question of the way he responds to the way he responds to the question of the way he responds to the way he responds to the question of the way he responds to the way he responds to the question of the way he responds to the question of the way he responds to the way he responds to the question of the way he responds to the way he responds to the question of the way he responds to the question of the way he responds to the way he responds to the question of the way he responds to the way he responds to the question of the way he responds to the question of the way he responds to the way he responds to the question of the way he responds to the way he responds to the question of the way he responds to the way he responds to the question of the way he responds to the way he responds to the question of the way he responds to the way he responds to the way he responds to the way he responds to the question of the question of the way he responds to the way he responds to the way he responds to the question of the way he responds to the"}, {"heading": "2. Related Work", "text": "In this section we give a brief introduction to previous work on static, adaptive and dynamic regrets in the context of convex online optimization."}, {"heading": "2.1 Static Regret", "text": "The majority of studies on online learning focus on static regret Shalev-Shwartz and Singer (2007); Langford et al. (2009). For general convex functions, the classic online gradient descent reaches O (\u221a T) or O (log T) remorse limits for convex or strongly convex functions (Zinkevich et al., 2003; Hazan et al., 2007; Shalev-Shwartz et al., 2007). Both O (\u221a T) and O (log T) rates are known to be minimally optimal (Abernethy et al., 2009). When functions are exponentially concave, another algorithm is developed called the online Newton step and has an O (log T) remorse limit (Hazan et al., 2007)."}, {"heading": "2.2 Adaptive Regret", "text": "The concept of adaptive regret is introduced by Hazan and Seshadhri (2007) and later reinforced by Daniely et al. (2015). To distinguish between them, we refer to the definition of Hazan and Seshadhri (2007) as strongly adaptive regret and Daniely et al. (2015) as strongly adaptive regret. WA-Regret (T) = max [s, q] s presents the weak version as strongly adaptive regret and Daniely et al. (2015) as strongly adaptive regret. To minimize adaptive regret, Hazan and Seshadhri (2007) have developed two meta algorithm: an efficient algorithm with O (log T) computational complexity per iteration and an inefficient one with O (T) computational complexity per iteration."}, {"heading": "2.3 Dynamic Regret", "text": "In a secondary work, Zinkevich (2003) has proposed to asP the path length defined (u1,.. 2016, uT) = T + T + T (1,.., uT) = T + T (1,., uT). Another regularity of the comparator sequence, which resembles the path length, is defined asP \u00b2 (u1,.., uT) = T + T = 2, ut \u2212 T (ut \u2212 1,.) is a dynamic model that predicts a reference point for the t-th round. Hall and Willett (2013) developed a novel algorithm called dynamic mirror descent and proved that its dynamic remorse in the order of TP \u00b2. (u1,.,. uT) The advantage of t-th round. Hall and Willett (2013) developed a new algorithm called dynamic mirror descent and proved that its dynamic remorse in the order of TP \u00b2."}, {"heading": "3. From Adaptive to Dynamic", "text": "In this section, we first present a general sentence limiting the dynamic regret by adaptive regret, and then derive specific regret limits for convex functions, exponentially concave functions, and strongly convex functions."}, {"heading": "3.1 Adaptive-to-Dynamic Conversion", "text": "Let I1 = [s1, q1], I2 = [s2, q2],.., Ik = [sk, qk] be a division of [1, T], that is, they are consecutive intervals such as: 1 = 1, qi + 1 = si + 1, i = k \u2212 1 (w) and qk = T. (4) Define the local function variation of the i-th interval asVT (i) = Qi + 1max w = Qi + Qi-ft \u2212 1 (w) | and it is obvious that we have the following theorem to limit the dynamic regret in relation to the strongly adaptive regret and the function variation. Theorem 1 Let us have w-argminw intervals intervals (w-intervals) which are the intervals."}, {"heading": "3.2 Convex Functions", "text": "For convex functions, we choose the meta-algorithm of Jun et al. (2016) and take the online gradient descent as a subroutine. The following theorem on adaptive regret can be found in this paper.Theorem 2 Assuming 1, the meta-algorithm of Jun et al. (2016) is highly adaptive with SA-Regret (T, \u03c4) \u2264 (12BG \u221a 2 \u2212 1 + 8 \u221a 7 log T + 5) \u0432 = O (\u221a log T).3. Note that in certain cases the sum of local functional variation zi = 1 VT (i) can be much smaller than the total functional variation VT. For example, if the sequence of functions changes only k times, we can construct the intervals based on the changing rounds so that k i = 1 VT (i) = 0.From theorems 1 and 2, we derive the following limit for dynamic functions."}, {"heading": "3.3 Exponentially Concave Functions", "text": "The first definition of exponential complexity per iteration (abbr. exp-concave) Functions (Cesa-Bianchi and Lugosi, 2006).Definition 2 A Function f (\u00b7): D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D + D +"}, {"heading": "3.4 Strongly Convex Functions", "text": "In the following, we examine strongly convex functions, defined by the following definition: Definition 3A function f (\u00b7): \"7\" \u2192 \"R\" is \"strongly convex iff (y)\" f (x) + < \"f (x),\" \"y \u2212 x > +\" 2 \"y \u2212 x\" 22, \"\" x \", y.\" It is easy to verify that strongly convex functions with limited gradients are also exponcave (Hazan et al., 2007). Lemma 4 \"Suppose f\" (\u00b7): \"7\" R \"is\" strongly convex \"and\" f \"(w) \u2264 G\" for all w. \"Then\" f \"(\u00b7) is\" G2 \"-exp-concave.Thus, episode 4 can be applied directly to strongly convex functions and results in a dynamic regret of O\" (\u221a TVT log T)."}, {"heading": "4. An Unified Adaptive Algorithm", "text": "In this section we present a unified approach to minimizing the adaptive regret of expconcave functions = > expconcave functions, as well as strongly convex functions.Let E be an online learning algorithm that is designed to minimize the static regret of exp-concave functions or strong convex functions, e.g., online Newton step (Hazan et al., 2007) or online gradient descent (Zinkevich, 2003).Similar to the approach of the following leading story (FLH) (Hazan and Seshadhri, 2007), anytime t, we will instantiate an expert by applying the online learning algorithm E to the sequence of loss functionft, ft + 1,."}, {"heading": "In other words, the ending time is the number represented by the new sequence obtained by setting the first nonzero elements in the sequence \u03b10, \u03b11, . . . to be 0 and adding 1 to the element after it.", "text": "s take the decimal system as an example (i.e., K = 10)."}, {"heading": "5. Analysis", "text": "We present here the proofs of the most important theorems. The omitted proofs are included in the supplement."}, {"heading": "5.1 Proof of Theorem 1", "text": "First, we have broken down the dynamic regret in the following order: D-Regret (w) = ft = ft = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p"}, {"heading": "5.2 Proof of Corollary 3", "text": "To simplify the upper limit in theorem 1, we limit ourselves to intervals of the same length \u03c4, and in this case k = T / \u221a. Then we have D-regret (w \u0445 1,.., w \u0445 T) \u2264 min 1 \u2264 \u03c4 \u2264 Tk \u2211 i = 1 (SA-regret (T, \u03c4) + 2\u03c4VT (i)) = min1 \u2264 T (SA-regret (T, \u03c4) T\u03c4 + 2\u03c4k (i)) \u2264 min 1 \u2264 T (SA-regret (T, \u03c4) T\u03c4 + 2\u03c4VT). Combined with theorem 2, we have D-regret (w \u0445 1,."}, {"heading": "6. Proof of Theorem 6", "text": "From the second part of Lemma 6 we know that it is m segmentsIj = [tj, e tj \u2212 1] and etm > s.Furthermore, the expert Etj is alive during the period [tj, e tj \u2212 1]. Using claim 3.1 of Hazan and Seshadhri (2009), we have a t = tjft (wt) \u2212 ft (wtjt) \u2264 1\u03b1 log tj + 2 etj \u2212 1 t = tj + 11t. [m \u2212 1], where w tj tj tj (2009),.., w tj etj \u2212 1 is the sequence of solutions provided by the expert Etj (wtjt) \u2264 t \u2212 t t t t t = tj + tj t t t. [m \u2212 t] wo w tj tj tj,."}, {"heading": "7. Proof of Corollary 4", "text": "The first part of conclusion 4 is a direct sequence of theorem 6 by setting K = T 1 / \u03b3. Now we prove the second part. After similar analysis of conclusion 3, we have D remorse (w * 1,..., w * T) \u2264 min1 \u2264 \u03c4 T {(((5d + 1) (\u03b3 + 1) + 2\u03b1 + 5d (\u03b3 + 1) GB) T log T\u03c4 + 2\u03c4VT}. Then we consider two cases. If VT \u2265 log T / T, we choose T log T {(((5d + 1) (\u03b3 + 1) GB) \u2264 Tand haveD reset (w * 1,.., w * T) \u2264 (((5d + 1) + 2\u03b1 + 5d + 1) GB + 2) \u221a TVT log T (T).Otherwise, we choose \u03c4 = T, and haveD reset (w * 1,..., w * T) \u2264 (5d + 1) + 5d + 1 (1 + 1 + 1) + 5 + 1 GB + 5% T (T) + 5% T (T) (T) + 5% (T)."}, {"heading": "8. Proof of Theorem 7", "text": "Lemma 4 implies that all \u03bb-strongly convex functions are also \u03bb G2 -exp-concave. Consequently, we can reuse the proof for theorem 6. Specifically: (8) with \u03b1 = \u03bb G2 comesm \u2212 1 \u2211 j = 1 etj \u2212 1 \u2211 t = tjft (wt) \u2212 ft (wtjt) + s \u2211 t = tmft (wtmt) \u2212 ft (m + 2) G2\u03bb log T. (11) According to the property of the online gradient drop (Hazan et al., 2007, theorem 1) we have etj \u2212 1 \u2211 t = tjft (w tj t) \u2212 ft (w) \u2264 G2 2\u03bb (1 + log T), \u0445j [m \u2212 1] (12) and s \u0432t = tmft (w tm t) \u2212 ft (w) \u2264 G2 2\u043c (1 + T)."}, {"heading": "9. Proof of Corollary 5", "text": "The first part of conclusion 5 is a direct sequence of theorem 7 by setting K = T 1 / \u03b3. Evidence of the second part is similar to that of conclusion 4. First, we have D remorse (w * 1,..., w * T) \u2264 min1 \u2264 \u2264 T {G22\u03bb (\u03b3 + 1 + (3\u03b3 + 7) log T) T \u03c4 + 2\u03c4VT} \u2264 min 1 \u2264 \u03c4 T {(\u03b3 + 5\u03b3 log T) G2T\u03bb\u0442 + 2\u03c4VT}, where the last inequality is due to condition \u03b3 > 1. Then, we consider two cases. If VT \u2264 log T / T, we choose TVT \u2264 Tand haveD reset (w \u00b2 1,..., w \u00b2 T) \u2264 G2\u03bb (TVT log T + 5\u03b3G2) and T \u00b2 (T \u00b2)."}, {"heading": "10. Conclusions and Future Work", "text": "In this paper, we show that dynamic regret can be limited upwards by adaptive regret and functional variation, which implies strongly adaptive algorithms automatically endowed with narrow dynamic regret limits. As a result, we are able to derive dynamic regret limits for convex functions, exponentially concave functions, and strongly convex functions, all of which are nearly minimax optimal, and this is the first time that such a dynamic regret limit has been demonstrated for exponentially concave functions. Adaptive-dynamic conversion leads to a number of dynamic regret limits in terms of functional variation. As we have mentioned in Section 2.3, dynamic regret can also be limited by other regularities such as the path length upwards. It is interesting to examine whether this type of upper limit can also be set for strongly adaptive algorithms. As we are trying to derive dynamic regret from adaptive regret, we suspect that future will be adaptive and substantive evidence."}, {"heading": "Appendix A. Proof of Theorem 2", "text": "As Daniely et al. (2015) have shown, the static regret of an online gradient descent (Zinkevich, 2003) is limited over an arbitrary length interval \u03c4 by 3BG \u221a \u03c4. If we combine this fact with theorem 2 of Jun et al. (2016), we get theorem 2 in this paper."}, {"heading": "Appendix B. Proof of Lemma 4", "text": "The slope of exp (\u2212 f (w)) is: exp (\u2212 f (w)) = exp (\u2212 f (w)) \u2212 \u03b1 exp (w) = \u2212 \u03b1 exp (\u2212 f (w)).and the Hessian is: 2 exp (\u2212 f (w) = \u2212 \u03b1 exp (\u2212 f (w)) = --\u03b1 exp (\u2212 f (w)) = \u2212 \u03b1 f (w) \u2212 \u03b1 exp (w) \u2212 \u03b1 exp (w)), 2f (w) = \u03b1 exp (\u2212 f (w)) (\u03b1 f (w))."}, {"heading": "Appendix C. Proof of Lemma 6", "text": "We first prove the first part of Lemma 6. Leave m = logK t. Then integers t in the base K number system ast = m j = 0\u03b1jK j. From the definition of base K end time are integers not greater than t and living at t, 1 K0 + m j = 1 K j, 2 K0 + m j = 1 jK j,.. \u2212 0 K0 + m j = 1 jK 1 K1 + m j = 2 jK j, 2 K1 + m j = 2 jK,. \u2212 K1 K1 + m j j = 2 Km jK j. 1 Km \u2212 1 + m mKm j and 1 Km Km j."}], "references": [{"title": "A stochastic view of optimal regret through minimax duality", "author": ["Jacob Abernethy", "Alekh Agarwal", "Peter L. Bartlett", "Alexander Rakhlin"], "venue": "In Proceedings of the 22nd Annual Conference on Learning Theory,", "citeRegEx": "Abernethy et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Abernethy et al\\.", "year": 2009}, {"title": "A closer look at adaptive regret", "author": ["Dmitry Adamskiy", "Wouter M. Koolen", "Alexey Chernov", "Vladimir Vovk"], "venue": "In Proceedings of the 23rd International Conference on Algorithmic Learning Theory,", "citeRegEx": "Adamskiy et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Adamskiy et al\\.", "year": 2012}, {"title": "Non-stationary stochastic optimization", "author": ["Omar Besbes", "Yonatan Gur", "Assaf Zeevi"], "venue": "Operations Research,", "citeRegEx": "Besbes et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Besbes et al\\.", "year": 2015}, {"title": "Prediction, Learning, and Games", "author": ["Nicol\u00f2 Cesa-Bianchi", "G\u00e1bor Lugosi"], "venue": null, "citeRegEx": "Cesa.Bianchi and Lugosi.,? \\Q2006\\E", "shortCiteRegEx": "Cesa.Bianchi and Lugosi.", "year": 2006}, {"title": "Mirror descent meets fixed share (and feels no regret)", "author": ["Nicol\u00f2 Cesa-bianchi", "Pierre Gaillard", "Gabor Lugosi", "Gilles Stoltz"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Cesa.bianchi et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Cesa.bianchi et al\\.", "year": 2012}, {"title": "Strongly adaptive online learning", "author": ["Amit Daniely", "Alon Gonen", "Shai Shalev-Shwartz"], "venue": "In Proceedings of The 32nd International Conference on Machine Learning,", "citeRegEx": "Daniely et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Daniely et al\\.", "year": 2015}, {"title": "Efficient tracking of large classes of experts", "author": ["Andr\u00e1s Gy\u00f6rgy", "Tam\u00e1s Linder", "G\u00e1bor Lugosi"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Gy\u00f6rgy et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Gy\u00f6rgy et al\\.", "year": 2012}, {"title": "Dynamical models and tracking regret in online convex programming", "author": ["Eric C. Hall", "Rebecca M. Willett"], "venue": "In Proceedings of the 30th International Conference on Machine Learning,", "citeRegEx": "Hall and Willett.,? \\Q2013\\E", "shortCiteRegEx": "Hall and Willett.", "year": 2013}, {"title": "Adaptive algorithms for online decision problems", "author": ["Elad Hazan", "C. Seshadhri"], "venue": "Electronic Colloquium on Computational Complexity,", "citeRegEx": "Hazan and Seshadhri.,? \\Q2007\\E", "shortCiteRegEx": "Hazan and Seshadhri.", "year": 2007}, {"title": "Efficient learning algorithms for changing environments", "author": ["Elad Hazan", "C. Seshadhri"], "venue": "In Proceedings of the 26th Annual International Conference on Machine Learning,", "citeRegEx": "Hazan and Seshadhri.,? \\Q2009\\E", "shortCiteRegEx": "Hazan and Seshadhri.", "year": 2009}, {"title": "Logarithmic regret algorithms for online convex optimization", "author": ["Elad Hazan", "Amit Agarwal", "Satyen Kale"], "venue": "Machine Learning,", "citeRegEx": "Hazan et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Hazan et al\\.", "year": 2007}, {"title": "Tracking the best expert", "author": ["Mark Herbster", "Manfred K. Warmuth"], "venue": "Machine Learning,", "citeRegEx": "Herbster and Warmuth.,? \\Q1998\\E", "shortCiteRegEx": "Herbster and Warmuth.", "year": 1998}, {"title": "Tracking the best linear predictor", "author": ["Mark Herbster", "Manfred K. Warmuth"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Herbster and Warmuth.,? \\Q2001\\E", "shortCiteRegEx": "Herbster and Warmuth.", "year": 2001}, {"title": "Online optimization : Competing with dynamic comparators", "author": ["Ali Jadbabaie", "Alexander Rakhlin", "Shahin Shahrampour", "Karthik Sridharan"], "venue": "In Proceedings of the 18th International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "Jadbabaie et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Jadbabaie et al\\.", "year": 2015}, {"title": "Improved strongly adaptive online learning using coin betting", "author": ["Kwang-Sung Jun", "Francesco Orabona", "Rebecca Willett", "Stephen Wright"], "venue": "ArXiv e-prints,", "citeRegEx": "Jun et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Jun et al\\.", "year": 2016}, {"title": "Open problem: Fast stochastic exp-concave optimization", "author": ["Tomer Koren"], "venue": "In Proceedings of the 26th Annual Conference on Learning Theory, pages 1073\u20131075,", "citeRegEx": "Koren.,? \\Q2013\\E", "shortCiteRegEx": "Koren.", "year": 2013}, {"title": "Sparse online learning via truncated gradient", "author": ["John Langford", "Lihong Li", "Tong Zhang"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Langford et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Langford et al\\.", "year": 2009}, {"title": "The weighted majority algorithm", "author": ["Nick Littlestone", "Manfred K. Warmuth"], "venue": "Information and Computation,", "citeRegEx": "Littlestone and Warmuth.,? \\Q1994\\E", "shortCiteRegEx": "Littlestone and Warmuth.", "year": 1994}, {"title": "Online optimization in dynamic environments: Improved regret rates for strongly convex problems", "author": ["Aryan Mokhtari", "Shahin Shahrampour", "Ali Jadbabaie", "Alejandro Ribeiro"], "venue": "ArXiv e-prints,", "citeRegEx": "Mokhtari et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Mokhtari et al\\.", "year": 2016}, {"title": "Online learning and online convex optimization", "author": ["Shai Shalev-Shwartz"], "venue": "Foundations and Trends in Machine Learning,", "citeRegEx": "Shalev.Shwartz.,? \\Q2011\\E", "shortCiteRegEx": "Shalev.Shwartz.", "year": 2011}, {"title": "A primal-dual perspective of online learning algorithms", "author": ["Shai Shalev-Shwartz", "Yoram Singer"], "venue": "Machine Learning,", "citeRegEx": "Shalev.Shwartz and Singer.,? \\Q2007\\E", "shortCiteRegEx": "Shalev.Shwartz and Singer.", "year": 2007}, {"title": "Pegasos: primal estimated subgradient solver for SVM", "author": ["Shai Shalev-Shwartz", "Yoram Singer", "Nathan Srebro"], "venue": "In Proceedings of the 24th International Conference on Machine Learning,", "citeRegEx": "Shalev.Shwartz et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Shalev.Shwartz et al\\.", "year": 2007}, {"title": "Tracking slowly moving clairvoyant: Optimal dynamic regret of online learning with true and noisy gradient", "author": ["Tianbao Yang", "Lijun Zhang", "Rong Jin", "Jinfeng Yi"], "venue": "In Proceedings of the 33rd International Conference on Machine Learning,", "citeRegEx": "Yang et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Yang et al\\.", "year": 2016}, {"title": "Improved dynamic regret for non-degeneracy functions", "author": ["Lijun Zhang", "Tianbao Yang", "Jinfeng Yi", "Rong Jin", "Zhi-Hua Zhou"], "venue": "ArXiv e-prints,", "citeRegEx": "Zhang et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2016}, {"title": "Online convex programming and generalized infinitesimal gradient ascent", "author": ["Martin Zinkevich"], "venue": "In Proceedings of the 20th International Conference on Machine Learning,", "citeRegEx": "Zinkevich.,? \\Q2003\\E", "shortCiteRegEx": "Zinkevich.", "year": 2003}], "referenceMentions": [{"referenceID": 19, "context": "Introduction Online convex optimization is a powerful paradigm for sequential decision making (Shalev-Shwartz, 2011).", "startOffset": 94, "endOffset": 116}, {"referenceID": 3, "context": "This study focuses on the full-information setting (Cesa-Bianchi and Lugosi, 2006), where the function ft(\u00b7) is revealed to the leaner at the end of each round.", "startOffset": 51, "endOffset": 82}, {"referenceID": 24, "context": "To address this limitation, new forms of performance measure, including adaptive regret (Hazan and Seshadhri, 2007, 2009) and dynamic regret (Zinkevich, 2003), were proposed and received significant interest recently.", "startOffset": 141, "endOffset": 158}, {"referenceID": 13, "context": "It is well-known that in the worst case, a sublinear dynamic regret is impossible unless we impose some regularities on the comparator sequence or the function sequence (Jadbabaie et al., 2015).", "startOffset": 169, "endOffset": 193}, {"referenceID": 14, "context": "\u2022 For convex functions, we show that the strongly adaptive algorithm of Jun et al. (2016) has a dynamic regret of O(T 2/3V 1/3 T log 1/3 T ), which matches the minimax rate, up to a polylogarithmic factor.", "startOffset": 72, "endOffset": 90}, {"referenceID": 24, "context": "For general convex functions, the classical online gradient descent achieves O( \u221a T ) and O(log T ) regret bounds for convex and strongly convex functions, respectively (Zinkevich, 2003; Hazan et al., 2007; Shalev-Shwartz et al., 2007).", "startOffset": 169, "endOffset": 235}, {"referenceID": 10, "context": "For general convex functions, the classical online gradient descent achieves O( \u221a T ) and O(log T ) regret bounds for convex and strongly convex functions, respectively (Zinkevich, 2003; Hazan et al., 2007; Shalev-Shwartz et al., 2007).", "startOffset": 169, "endOffset": 235}, {"referenceID": 21, "context": "For general convex functions, the classical online gradient descent achieves O( \u221a T ) and O(log T ) regret bounds for convex and strongly convex functions, respectively (Zinkevich, 2003; Hazan et al., 2007; Shalev-Shwartz et al., 2007).", "startOffset": 169, "endOffset": 235}, {"referenceID": 0, "context": "Both the O( \u221a T ) and O(log T ) rates are known to be minimax optimal (Abernethy et al., 2009).", "startOffset": 70, "endOffset": 94}, {"referenceID": 10, "context": "When functions are exponentially concave, a different algorithm, named online Newton step, is developed and enjoys an O(log T ) regret bound (Hazan et al., 2007).", "startOffset": 141, "endOffset": 161}, {"referenceID": 16, "context": "1 Static Regret The majority of studies in online learning are focused on static regret Shalev-Shwartz and Singer (2007); Langford et al.", "startOffset": 88, "endOffset": 121}, {"referenceID": 14, "context": "1 Static Regret The majority of studies in online learning are focused on static regret Shalev-Shwartz and Singer (2007); Langford et al. (2009). For general convex functions, the classical online gradient descent achieves O( \u221a T ) and O(log T ) regret bounds for convex and strongly convex functions, respectively (Zinkevich, 2003; Hazan et al.", "startOffset": 122, "endOffset": 145}, {"referenceID": 7, "context": "2 Adaptive Regret The concept of adaptive regret is introduced by Hazan and Seshadhri (2007), and later strengthened by Daniely et al.", "startOffset": 66, "endOffset": 93}, {"referenceID": 5, "context": "2 Adaptive Regret The concept of adaptive regret is introduced by Hazan and Seshadhri (2007), and later strengthened by Daniely et al. (2015). To distinguish between them, we refer to the definition of Hazan and Seshadhri (2007) as weakly adaptive regret and the one of Daniely et al.", "startOffset": 120, "endOffset": 142}, {"referenceID": 5, "context": "2 Adaptive Regret The concept of adaptive regret is introduced by Hazan and Seshadhri (2007), and later strengthened by Daniely et al. (2015). To distinguish between them, we refer to the definition of Hazan and Seshadhri (2007) as weakly adaptive regret and the one of Daniely et al.", "startOffset": 120, "endOffset": 229}, {"referenceID": 5, "context": "2 Adaptive Regret The concept of adaptive regret is introduced by Hazan and Seshadhri (2007), and later strengthened by Daniely et al. (2015). To distinguish between them, we refer to the definition of Hazan and Seshadhri (2007) as weakly adaptive regret and the one of Daniely et al. (2015) as strongly adaptive regret.", "startOffset": 120, "endOffset": 292}, {"referenceID": 8, "context": "To minimize the adaptive regret, Hazan and Seshadhri (2007) have developed two metaalgorithms: an efficient algorithm with O(log T ) computational complexity per iteration and an inefficient one with O(T ) computational complexity per iteration.", "startOffset": 33, "endOffset": 60}, {"referenceID": 5, "context": "To overcome this limitation, Daniely et al. (2015) proposed a refined adaptive regret that takes the length of the interval as a parameter \u03c4 , as indicated in (1).", "startOffset": 29, "endOffset": 51}, {"referenceID": 5, "context": "To overcome this limitation, Daniely et al. (2015) proposed a refined adaptive regret that takes the length of the interval as a parameter \u03c4 , as indicated in (1). If the strongly adaptive regret is small for all \u03c4 < T , we can guarantee the learner has small regret over any interval of any length. In particular, Daniely et al. (2015) introduced the following definition.", "startOffset": 29, "endOffset": 337}, {"referenceID": 5, "context": "To overcome this limitation, Daniely et al. (2015) proposed a refined adaptive regret that takes the length of the interval as a parameter \u03c4 , as indicated in (1). If the strongly adaptive regret is small for all \u03c4 < T , we can guarantee the learner has small regret over any interval of any length. In particular, Daniely et al. (2015) introduced the following definition. Definition 1 Let R(\u03c4) be the minimax static regret bound of the learning problem over \u03c4 periods. An algorithm is strongly adaptive, if SA-Regret(T, \u03c4) = O(poly(log T ) \u00b7R(\u03c4)). It is easy to verify that the meta-algorithms of Hazan and Seshadhri (2007) are strongly adaptive for exponentially concave functions,2 but not for convex functions.", "startOffset": 29, "endOffset": 626}, {"referenceID": 5, "context": "To overcome this limitation, Daniely et al. (2015) proposed a refined adaptive regret that takes the length of the interval as a parameter \u03c4 , as indicated in (1). If the strongly adaptive regret is small for all \u03c4 < T , we can guarantee the learner has small regret over any interval of any length. In particular, Daniely et al. (2015) introduced the following definition. Definition 1 Let R(\u03c4) be the minimax static regret bound of the learning problem over \u03c4 periods. An algorithm is strongly adaptive, if SA-Regret(T, \u03c4) = O(poly(log T ) \u00b7R(\u03c4)). It is easy to verify that the meta-algorithms of Hazan and Seshadhri (2007) are strongly adaptive for exponentially concave functions,2 but not for convex functions. Thus, Daniely et al. (2015) developed a new meta-algorithm that satisfies SA-Regret(T, \u03c4) = O( \u221a \u03c4 log T ) for convex functions, and thus is strongly adaptive.", "startOffset": 29, "endOffset": 744}, {"referenceID": 5, "context": "To overcome this limitation, Daniely et al. (2015) proposed a refined adaptive regret that takes the length of the interval as a parameter \u03c4 , as indicated in (1). If the strongly adaptive regret is small for all \u03c4 < T , we can guarantee the learner has small regret over any interval of any length. In particular, Daniely et al. (2015) introduced the following definition. Definition 1 Let R(\u03c4) be the minimax static regret bound of the learning problem over \u03c4 periods. An algorithm is strongly adaptive, if SA-Regret(T, \u03c4) = O(poly(log T ) \u00b7R(\u03c4)). It is easy to verify that the meta-algorithms of Hazan and Seshadhri (2007) are strongly adaptive for exponentially concave functions,2 but not for convex functions. Thus, Daniely et al. (2015) developed a new meta-algorithm that satisfies SA-Regret(T, \u03c4) = O( \u221a \u03c4 log T ) for convex functions, and thus is strongly adaptive. The algorithm is also efficient and the computational complexity per iteration is O(log T ). Later, the strongly adaptive regret of convex functions was improved to O( \u221a \u03c4 log T ) by Jun et al. (2016).", "startOffset": 29, "endOffset": 1077}, {"referenceID": 24, "context": "3 Dynamic Regret In a seminal work, Zinkevich (2003) proposed to use the path-length defined as", "startOffset": 36, "endOffset": 53}, {"referenceID": 24, "context": "Specifically, Zinkevich (2003) proved that for any sequence of convex functions, the dynamic regret of online gradient descent can be upper bounded by O( \u221a TP(u1, .", "startOffset": 14, "endOffset": 31}, {"referenceID": 7, "context": "Hall and Willett (2013) developed a novel algorithm named dynamic mirror descent and proved that its dynamic regret is on the order of \u221a TP (u1, .", "startOffset": 0, "endOffset": 24}, {"referenceID": 13, "context": ",w \u2217 T ) (Jadbabaie et al., 2015; Mokhtari et al., 2016; Yang et al., 2016; Zhang et al., 2016).", "startOffset": 9, "endOffset": 95}, {"referenceID": 18, "context": ",w \u2217 T ) (Jadbabaie et al., 2015; Mokhtari et al., 2016; Yang et al., 2016; Zhang et al., 2016).", "startOffset": 9, "endOffset": 95}, {"referenceID": 22, "context": ",w \u2217 T ) (Jadbabaie et al., 2015; Mokhtari et al., 2016; Yang et al., 2016; Zhang et al., 2016).", "startOffset": 9, "endOffset": 95}, {"referenceID": 23, "context": ",w \u2217 T ) (Jadbabaie et al., 2015; Mokhtari et al., 2016; Yang et al., 2016; Zhang et al., 2016).", "startOffset": 9, "endOffset": 95}, {"referenceID": 22, "context": ",w T )) (Yang et al., 2016).", "startOffset": 8, "endOffset": 27}, {"referenceID": 18, "context": ",w T )) (Mokhtari et al., 2016).", "startOffset": 8, "endOffset": 31}, {"referenceID": 22, "context": ",w T )) rate is also achievable when all the functions are convex and smooth, and all the minimizersw t \u2019s lie in the interior of \u03a9 (Yang et al., 2016).", "startOffset": 132, "endOffset": 151}, {"referenceID": 13, "context": ",w \u2217 T ) (Jadbabaie et al., 2015; Mokhtari et al., 2016; Yang et al., 2016; Zhang et al., 2016). When a prior knowledge of P(w\u2217 1, . . . ,w T ) is available, D-Regret(w 1, . . . ,w T ) can be upper bounded by O( \u221a TP(w\u2217 1, . . . ,w T )) (Yang et al., 2016). If all the functions are strongly convex and smooth, the upper bound can be improved to O(P(w\u2217 1, . . . ,w T )) (Mokhtari et al., 2016). The O(P(w\u2217 1, . . . ,w T )) rate is also achievable when all the functions are convex and smooth, and all the minimizersw t \u2019s lie in the interior of \u03a9 (Yang et al., 2016). In a recent study, Zhang et al. (2016) introduced a new regularity\u2014squared pathlength", "startOffset": 10, "endOffset": 607}, {"referenceID": 17, "context": "In the literature, dynamic regret is also referred to as tracking regret or shifting regret (Littlestone and Warmuth, 1994; Herbster and Warmuth, 1998, 2001).", "startOffset": 92, "endOffset": 157}, {"referenceID": 18, "context": "Zhang et al. (2016) developed a novel algorithm named online multiple gradient descent, and proved that D-Regret(w 1, .", "startOffset": 0, "endOffset": 20}, {"referenceID": 1, "context": "In the setting of \u201cprediction with expert advice\u201d, Adamskiy et al. (2012) have shown that the tracking regret can be derived from the adaptive regret.", "startOffset": 51, "endOffset": 74}, {"referenceID": 1, "context": "In the setting of \u201cprediction with expert advice\u201d, Adamskiy et al. (2012) have shown that the tracking regret can be derived from the adaptive regret. In the setting of \u201conline linear optimization in the simplex\u201d, Cesa-bianchi et al. (2012) introduced a generalized notion of shifting regret which unifies adaptive regret and shifting regret.", "startOffset": 51, "endOffset": 241}, {"referenceID": 2, "context": "The above theorem is analogous to Proposition 2 of Besbes et al. (2015), which provides an upper bound for a special choice of the interval sequence.", "startOffset": 51, "endOffset": 72}, {"referenceID": 14, "context": "2 Convex Functions For convex functions, we choose the meta-algorithm of Jun et al. (2016) and take the online gradient descent as its subroutine.", "startOffset": 73, "endOffset": 91}, {"referenceID": 14, "context": "2 Convex Functions For convex functions, we choose the meta-algorithm of Jun et al. (2016) and take the online gradient descent as its subroutine. The following theorem regarding the adaptive regret can be obtained from that paper. Theorem 2 Under Assumption 1, the meta-algorithm of Jun et al. (2016) is strongly adaptive with SA-Regret(T, \u03c4) \u2264 ( 12BG \u221a 2\u2212 1 + 8 \u221a 7 log T + 5 )\u221a \u03c4 = O( \u221a \u03c4 log T ).", "startOffset": 73, "endOffset": 302}, {"referenceID": 14, "context": "Corollary 3 Under Assumption 1, the meta-algorithm of Jun et al. (2016) satisfies", "startOffset": 54, "endOffset": 72}, {"referenceID": 2, "context": "According to Theorem 2 of Besbes et al. (2015), we know that the minimax dynamic regret of convex functions is O(T 2/3V 1/3 T ).", "startOffset": 26, "endOffset": 47}, {"referenceID": 2, "context": "According to Theorem 2 of Besbes et al. (2015), we know that the minimax dynamic regret of convex functions is O(T 2/3V 1/3 T ). Thus, our upper bound is minimax optimal up to a polylogarithmic factor. The key advantage of the meta-algorithm of Jun et al. (2016) over the restarted online gradient descent of Besbes et al.", "startOffset": 26, "endOffset": 263}, {"referenceID": 2, "context": "According to Theorem 2 of Besbes et al. (2015), we know that the minimax dynamic regret of convex functions is O(T 2/3V 1/3 T ). Thus, our upper bound is minimax optimal up to a polylogarithmic factor. The key advantage of the meta-algorithm of Jun et al. (2016) over the restarted online gradient descent of Besbes et al. (2015) is that the former one do not need any prior knowledge of the functional variation VT .", "startOffset": 26, "endOffset": 330}, {"referenceID": 2, "context": "According to Theorem 2 of Besbes et al. (2015), we know that the minimax dynamic regret of convex functions is O(T 2/3V 1/3 T ). Thus, our upper bound is minimax optimal up to a polylogarithmic factor. The key advantage of the meta-algorithm of Jun et al. (2016) over the restarted online gradient descent of Besbes et al. (2015) is that the former one do not need any prior knowledge of the functional variation VT . Notice that the meta-algorithm of Daniely et al. (2015) can also be used here, and its dynamic regret is on the order of max {\u221a T log T, T 2/3V 1/3 T log 2/3 T } .", "startOffset": 26, "endOffset": 474}, {"referenceID": 3, "context": "exp-concave) functions (Cesa-Bianchi and Lugosi, 2006).", "startOffset": 23, "endOffset": 54}, {"referenceID": 15, "context": "It can be used to model many popular losses used in machine learning, such as the square loss in regression, logistic loss in classification and negative logarithm loss in portfolio management (Koren, 2013).", "startOffset": 193, "endOffset": 206}, {"referenceID": 8, "context": "For exp-concave functions, Hazan and Seshadhri (2007) have developed two meta-algorithms that take the online Newton step as its subroutine, and proved the following properties.", "startOffset": 27, "endOffset": 54}, {"referenceID": 8, "context": "\u2022 WhenK = 2, we recover the guarantee of the efficient algorithm of Hazan and Seshadhri (2007), and when K = T , we obtain the inefficient one.", "startOffset": 68, "endOffset": 95}, {"referenceID": 8, "context": "\u2022 WhenK = 2, we recover the guarantee of the efficient algorithm of Hazan and Seshadhri (2007), and when K = T , we obtain the inefficient one. \u2022 By setting K = T 1/\u03b3 where \u03b3 > 1 is a small constant, such as 10, the strongly adaptive regret can be viewed as O(log T ), and at the same time, the computational complexity is also very low for a large range of T . According to Definition 1, Algorithm 1 in this paper, as well as the two meta-algorithms of Hazan and Seshadhri (2007), is strongly adaptive.", "startOffset": 68, "endOffset": 481}, {"referenceID": 10, "context": "It is easy to verify that strongly convex functions with bounded gradients are also expconcave (Hazan et al., 2007).", "startOffset": 95, "endOffset": 115}, {"referenceID": 2, "context": "According to Theorem 4 of Besbes et al. (2015), the minimax dynamic regret of strongly convex functions is O( \u221a TVT ), which implies our upper bound is almost minimax optimal.", "startOffset": 26, "endOffset": 47}, {"referenceID": 10, "context": ", online Newton step (Hazan et al., 2007) or online gradient descent (Zinkevich, 2003).", "startOffset": 21, "endOffset": 41}, {"referenceID": 24, "context": ", 2007) or online gradient descent (Zinkevich, 2003).", "startOffset": 35, "endOffset": 52}, {"referenceID": 8, "context": "Similar to the approach of following the leading history (FLH) (Hazan and Seshadhri, 2007), at any time t, we will instantiate an expert by applying the online learning algorithm E to the sequence of loss functions", "startOffset": 63, "endOffset": 90}, {"referenceID": 11, "context": ", and utilize the strategy of learning from expert advice to combine solutions of different experts (Herbster and Warmuth, 1998).", "startOffset": 100, "endOffset": 128}, {"referenceID": 6, "context": "We note that a similar strategy for deciding the ending time was proposed by Gy\u00f6rgy et al. (2012), and a discussion about the difference is given in the supplementary.", "startOffset": 77, "endOffset": 98}, {"referenceID": 2, "context": "To upper bound bi, we follow the analysis of Proposition 2 of Besbes et al. (2015).", "startOffset": 62, "endOffset": 83}, {"referenceID": 8, "context": "1 of Hazan and Seshadhri (2009), we have ej\u22121 \u2211 t=tj ft(wt)\u2212 ft(w t ) \u2264 1 \u03b1 \uf8eb \uf8edlog tj + 2 ej\u22121 \u2211", "startOffset": 5, "endOffset": 32}], "year": 2017, "abstractText": "To cope with changing environments, recent developments in online learning have introduced the concepts of adaptive regret and dynamic regret independently. In this paper, we illustrate an intrinsic connection between these two concepts by showing that the dynamic regret can be expressed in terms of the adaptive regret and the functional variation. This observation implies that strongly adaptive algorithms can be directly leveraged to minimize the dynamic regret. As a result, we present a series of strongly adaptive algorithms whose dynamic regrets are minimax optimal for convex functions, exponentially concave functions, and strongly convex functions, respectively. To the best of our knowledge, this is the first time that such kind of dynamic regret bound is established for exponentially concave functions. Moreover, all of those adaptive algorithms do not need any prior knowledge of the functional variation, which is a significant advantage over previous specialized methods for minimizing dynamic regret.", "creator": "LaTeX with hyperref package"}}}