{"id": "1701.08096", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Jan-2017", "title": "Efficiently Summarising Event Sequences with Rich Interleaving Patterns", "abstract": "Discovering the key structure of a database is one of the main goals of data mining. In pattern set mining we do so by discovering a small set of patterns that together describe the data well. The richer the class of patterns we consider, and the more powerful our description language, the better we will be able to summarise the data. In this paper we propose \\ourmethod, a novel greedy MDL-based method for summarising sequential data using rich patterns that are allowed to interleave. Experiments show \\ourmethod is orders of magnitude faster than the state of the art, results in better models, as well as discovers meaningful semantics in the form patterns that identify multiple choices of values.", "histories": [["v1", "Fri, 27 Jan 2017 16:02:54 GMT  (226kb,D)", "http://arxiv.org/abs/1701.08096v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.DB", "authors": ["apratim bhattacharyya", "jilles vreeken"], "accepted": false, "id": "1701.08096"}, "pdf": {"name": "1701.08096.pdf", "metadata": {"source": "CRF", "title": "Efficiently Summarising Event Sequences with Rich Interleaving Patterns", "authors": ["Apratim Bhattacharyya", "Jilles Vreeken"], "emails": ["abhattac@mpi-inf.mpg.de", "jilles@mpi-inf.mpg.de"], "sections": [{"heading": "1 Introduction", "text": "The discovery of key patterns from a database is one of the main objectives of data mining. Furthermore, modern approaches do not require all patterns that meet a local interest restriction, such as frequency [2, 10], but rather patterns that are optimal for the available data. There are various ways to define this optimum. The principle of minimum description length (MDL) [14, 5] has proved particularly successful [22, 16]. Free from MDL, we say that the best set of patterns is the set that compresses the data best. How well we can compress or better describe the data depends on the description language we use. The richer this language, the more relevant the structure we can identify. At the same time, a richer language means a larger search space and therefore requires a more efficient search."}, {"heading": "2 Preliminaries", "text": "2.1 Notation We look at databases of event sequences. Such a database D consists of | D | sequences. A sequence D consists of | S | events drawn from an alphabet. The total number of events occurring in the database is simply the number of events of e in S, i.e. supp (e | S) = DL | S | S. \"We write S [j] to refer to the jth event in the sequence S. Supporting an event e in a sequence S is simply the number of occurrences of e in S, i.e. supp (e) in the sequence L. Support of e in a database D is defined as Supp (e)."}, {"heading": "3 MDL for Event Sequences", "text": "In fact, it is in such a way that it is a matter of a way in which people act in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world,"}, {"heading": "4 Covering a Database", "text": "This year, it is more than ever before in the history of the city in which we find ourselves."}, {"heading": "5 Mining Good Code Tables", "text": "In fact, it is as if it were a matter of a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a world, a world, a world, a world, a world, a world, a world, a world, a world, a world, a world, a world, a world, a world, a world, a world, a world, a world, a world, a world, a world, a world, a world, a world, a world, a world, a world, a world, a country, a country, a world, a world, a world, a world, a world, a world, a world, a world, a country, a world, a world, a world, a country, a country, a country, a country, a country, a country, a world, a world, a world, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way, a way,"}, {"heading": "6 Related Work", "text": "The discovery of sequential patterns is an active research topic. Traditionally, there has been a focus on frequent sequential patterns, with different definitions of how to count incidents [10, 23, 8]. Consequently, research focuses on mineral subclasses of episodes, such as episodes with unique designations [1, 12], strict episodes [1], and injective episodes [1]. Traditional patterns lead to overly many and highly redundant results. Once the approach to these patterns of episodes is statistically significant, such as episodes with unique designations [1, 12], strict episodes [1], and injective episodes that result in overly many and highly redundant results."}, {"heading": "7 Experiments", "text": "Are we concerned with the future of humanity? \"is the question whether it is a question of a way in which it is a question of the future of humanity:\" It is a question of the future of humanity, the future of the world, the future of the world, the future of the world, the future of the world, the future of the world, the future of the world, the future of the world, the future of the world, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the way, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the way, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the way, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the"}, {"heading": "8 Conclusion", "text": "We have proposed the FINDWIN algorithm to efficiently search for pattern occurrences, and the greedy GREEDYCOVER algorithm to efficiently cover the data. Experiments show that SQUISH works well in practice, significantly exceeding the state of the art in terms of score and speed, while discovering pattern sets that are both more concise and easier to interpret.For future work, we consider parallel episodes, patterns in which certain events are disordered, e.g. a {b, c} d [10]. Discovering such a structure presents a significant arithmetic challenge and requires novel scores and algorithms."}, {"heading": "Acknowledgements", "text": "Apratim Bhattacharyya and Jilles Vreeken are supported by the Cluster of Excellence \"Multimodal Computing and Interaction\" within the Excellence Initiative of the Federal Government."}, {"heading": "A Appendix", "text": "We need to make two crucial observations: First, we need two different windows for P and Q, each occurring in C. Each of these windows is vi = {v1,..., vN} and W = {w1,..., wN} will be two windows for P and Q, each in C. Each of these windows vi and wi occur in the same order. Given the starting positions and end positions of the pattern in the order ki, we can call them vi = (ai, bi, P, ki) and wi = (ci, di, ki). Let's leave the number of windows produced by the combination of them, U = (a1, d1, R, k1),... (aN, dN, R, kN)."}], "references": [{"title": "Discovering injective episodes with general partial orders", "author": ["A. Achar", "S. Laxman", "R. Viswanathan", "P. Sastry"], "venue": "Data Min. Knowl. Disc., 25(1):67\u2013108,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "Fast algorithms for mining association rules", "author": ["R. Agrawal", "R. Srikant"], "venue": "VLDB, pages 487\u2013499,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1994}, {"title": "Keeping it short and simple: Summarising complex event sequences with multivariate patterns", "author": ["R. Bertens", "J. Vreeken", "A. Siebes"], "venue": "KDD, pages 735\u2013744,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2016}, {"title": "A subsequence interleaving model for sequential pattern mining", "author": ["J. Fowkes", "C. Sutton"], "venue": "KDD,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2016}, {"title": "The Minimum Description Length Principle", "author": ["P. Gr\u00fcnwald"], "venue": "MIT Press,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2007}, {"title": "KDD-Cup 2000 organizers\u2019 report: Peeling the onion", "author": ["R. Kohavi", "C. Brodley", "B. Frasca", "L. Mason", "Z. Zheng"], "venue": "SIGKDD Explor., 2(2):86\u201398,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2000}, {"title": "Mining compressing sequential patterns", "author": ["H.T. Lam", "F. M\u00f6rchen", "D. Fradkin", "T. Calders"], "venue": "SDM,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2012}, {"title": "A fast algorithm for finding frequent episodes in event streams", "author": ["S. Laxman", "P. Sastry", "K. Unnikrishnan"], "venue": "KDD, pages 410\u2013419. ACM,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2007}, {"title": "An Introduction to Kolmogorov Complexity and its Applications", "author": ["M. Li", "P. Vit\u00e1nyi"], "venue": "Springer,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1993}, {"title": "Discovery of frequent episodes in event sequences", "author": ["H. Mannila", "H. Toivonen", "A.I. Verkamo"], "venue": "Data Min. Knowl. Disc., 1(3):259\u2013289,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1997}, {"title": "Discovering frequent arrangements of temporal intervals", "author": ["P. Papapetrou", "G. Kollios", "S. Sclaroff", "D. Gunopulos"], "venue": "ICDM, pages 354\u2013361. IEEE,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2005}, {"title": "Discovering frequent closed partial orders from strings", "author": ["J. Pei", "H. Wang", "J. Liu", "K. Wang", "J. Wang", "P.S. Yu"], "venue": "IEEE TKDE, 18(11):1467\u20131481,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2006}, {"title": "Skopus: Mining top-k sequential patterns under leverage", "author": ["F. Petitjean", "T. Li", "N. Tatti", "G.I. Webb"], "venue": "Data Min. Knowl. Disc., 30(5):1086\u20131111,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2016}, {"title": "Modeling by shortest data description", "author": ["J. Rissanen"], "venue": "Automatica, 14(1):465\u2013471,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1978}, {"title": "A universal prior for integers and estimation by minimum description length", "author": ["J. Rissanen"], "venue": "Annals Stat., 11(2):416\u2013431,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1983}, {"title": "SLIM: Directly mining descriptive patterns", "author": ["K. Smets", "J. Vreeken"], "venue": "SDM, pages 236\u2013247. SIAM,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2012}, {"title": "Ranking episodes using a partition model", "author": ["N. Tatti"], "venue": "Data Min. Knowl. Disc., 29(5):1312\u20131342,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2015}, {"title": "Mining closed episodes with simultaneous events", "author": ["N. Tatti", "B. Cule"], "venue": "KDD, pages 1172\u20131180,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2011}, {"title": "Mining closed strict episodes", "author": ["N. Tatti", "B. Cule"], "venue": "Data Min. Knowl. Disc., 25(1):34\u201366,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2012}, {"title": "The long and the short of it: Summarizing event sequences with serial episodes", "author": ["N. Tatti", "J. Vreeken"], "venue": "KDD, pages 462\u2013470. ACM,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2012}, {"title": "Kolmogorov\u2019s structure functions and model selection", "author": ["N. Vereshchagin", "P. Vitanyi"], "venue": "IEEE TIT, 50(12):3265\u2013 3290,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2004}, {"title": "KRIMP: Mining itemsets that compress", "author": ["J. Vreeken", "M. van Leeuwen", "A. Siebes"], "venue": "Data Min. Knowl. Disc.,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2011}, {"title": "Bide: Efficient mining of frequent closed sequences", "author": ["J. Wang", "J. Han"], "venue": "ICDE, 0:79,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2004}], "referenceMentions": [{"referenceID": 1, "context": "Modern approaches do not to ask for all patterns that satisfy a local interestingness constraint, such as frequency [2, 10], but instead ask for that set of patterns that is optimal for the data at hand.", "startOffset": 116, "endOffset": 123}, {"referenceID": 9, "context": "Modern approaches do not to ask for all patterns that satisfy a local interestingness constraint, such as frequency [2, 10], but instead ask for that set of patterns that is optimal for the data at hand.", "startOffset": 116, "endOffset": 123}, {"referenceID": 13, "context": "The Minimum Description Length (MDL) principle [14, 5] has proven to be particularly successful [22, 16].", "startOffset": 47, "endOffset": 54}, {"referenceID": 4, "context": "The Minimum Description Length (MDL) principle [14, 5] has proven to be particularly successful [22, 16].", "startOffset": 47, "endOffset": 54}, {"referenceID": 21, "context": "The Minimum Description Length (MDL) principle [14, 5] has proven to be particularly successful [22, 16].", "startOffset": 96, "endOffset": 104}, {"referenceID": 15, "context": "The Minimum Description Length (MDL) principle [14, 5] has proven to be particularly successful [22, 16].", "startOffset": 96, "endOffset": 104}, {"referenceID": 19, "context": "In this paper we consider databases of event sequences, and are after that set of sequential patterns that together describe the data best\u2014as we did previously with SQS [20].", "startOffset": 169, "endOffset": 173}, {"referenceID": 3, "context": "It is much better at retrieving interleaving patterns than the very recent proposal by Fowkes and Sutton [4], and obtains much better compression rates than SQS [20], while being orders of magnitude faster than both.", "startOffset": 105, "endOffset": 108}, {"referenceID": 19, "context": "It is much better at retrieving interleaving patterns than the very recent proposal by Fowkes and Sutton [4], and obtains much better compression rates than SQS [20], while being orders of magnitude faster than both.", "startOffset": 161, "endOffset": 165}, {"referenceID": 13, "context": "2 Brief introduction to MDL The Minimum Description Length principle (MDL) [14, 5] is a practical version of Kolmogorov Complexity [9].", "startOffset": 75, "endOffset": 82}, {"referenceID": 4, "context": "2 Brief introduction to MDL The Minimum Description Length principle (MDL) [14, 5] is a practical version of Kolmogorov Complexity [9].", "startOffset": 75, "endOffset": 82}, {"referenceID": 8, "context": "2 Brief introduction to MDL The Minimum Description Length principle (MDL) [14, 5] is a practical version of Kolmogorov Complexity [9].", "startOffset": 131, "endOffset": 134}, {"referenceID": 4, "context": "In refined MDL model and data are encoded together [5].", "startOffset": 51, "endOffset": 54}, {"referenceID": 21, "context": "As models we will consider code tables [22, 20].", "startOffset": 39, "endOffset": 47}, {"referenceID": 19, "context": "As models we will consider code tables [22, 20].", "startOffset": 39, "endOffset": 47}, {"referenceID": 0, "context": "If it is a non-singleton, we append its first event, X[1], D.", "startOffset": 54, "endOffset": 57}, {"referenceID": 0, "context": "We read codep(p) from codep, append p[1] = a to D, and add (p, 2) to the context list.", "startOffset": 37, "endOffset": 40}, {"referenceID": 0, "context": "We read codep(q) from Cp, write q[1] = b to D, and insert context (q, 2) to \u039b.", "startOffset": 33, "endOffset": 36}, {"referenceID": 1, "context": "As for context (q, 2) we read a fill code, we write q[2] = d to D, and increment its pointer to 3.", "startOffset": 53, "endOffset": 56}, {"referenceID": 19, "context": "We build upon and extend the encoding on Tatti & Vreeken [20] for richer covers and patterns.", "startOffset": 57, "endOffset": 61}, {"referenceID": 4, "context": "To avoid arbitrary choices in the model encoding, we use prequential codes [5] to encode the meta stream.", "startOffset": 75, "endOffset": 78}, {"referenceID": 4, "context": "5 is a constant by which we initialize the distribution [5], fills(X) and gaps(X) are the number of times codef (X) resp.", "startOffset": 56, "endOffset": 59}, {"referenceID": 14, "context": "We do this using LN, the MDL optimal code for integers n \u2265 1 [15].", "startOffset": 61, "endOffset": 65}, {"referenceID": 20, "context": "We encode these using a data to model code\u2014an index over a canonically ordered enumeration of all possibilities [21]; here it is the number of possible supports of |\u03a9| alphabets over a database length of ||D||, (||D|| |\u03a9| ) .", "startOffset": 112, "endOffset": 116}, {"referenceID": 19, "context": "To find good disjoint covers, Tatti & Vreeken [20] use an EM-style approach.", "startOffset": 46, "endOffset": 50}, {"referenceID": 2, "context": "3 Candidate Order In the first step of our greedy strategy, we sort the set of patterns in a fixed order, similar to [3].", "startOffset": 117, "endOffset": 120}, {"referenceID": 19, "context": "As we shall see GREEDYCOVER is very competitive in its execution time compared to SQS [20].", "startOffset": 86, "endOffset": 90}, {"referenceID": 19, "context": "We build upon and extend SQS-SEARCH [20].", "startOffset": 36, "endOffset": 40}, {"referenceID": 19, "context": "We use the heuristic algorithm ESTIMATE from [20] that can find good candidates, with likely decrease in code length if added, in O(|P|+ |\u03a9|+ ||D||) time.", "startOffset": 45, "endOffset": 49}, {"referenceID": 9, "context": "Traditionally there was a focus on mining frequent sequential patterns, with different definitions of how to count occurrences [10, 23, 8].", "startOffset": 127, "endOffset": 138}, {"referenceID": 22, "context": "Traditionally there was a focus on mining frequent sequential patterns, with different definitions of how to count occurrences [10, 23, 8].", "startOffset": 127, "endOffset": 138}, {"referenceID": 7, "context": "Traditionally there was a focus on mining frequent sequential patterns, with different definitions of how to count occurrences [10, 23, 8].", "startOffset": 127, "endOffset": 138}, {"referenceID": 17, "context": "Even testing whether a sequence contains a pattern is NP-complete [18].", "startOffset": 66, "endOffset": 70}, {"referenceID": 0, "context": "Consequently, research has focused on mining subclasses of episodes, such as, episodes with unique labels [1, 12], strict episodes [19], and injective episodes [1].", "startOffset": 106, "endOffset": 113}, {"referenceID": 11, "context": "Consequently, research has focused on mining subclasses of episodes, such as, episodes with unique labels [1, 12], strict episodes [19], and injective episodes [1].", "startOffset": 106, "endOffset": 113}, {"referenceID": 18, "context": "Consequently, research has focused on mining subclasses of episodes, such as, episodes with unique labels [1, 12], strict episodes [19], and injective episodes [1].", "startOffset": 131, "endOffset": 135}, {"referenceID": 0, "context": "Consequently, research has focused on mining subclasses of episodes, such as, episodes with unique labels [1, 12], strict episodes [19], and injective episodes [1].", "startOffset": 160, "endOffset": 163}, {"referenceID": 16, "context": "puting the expected frequency of a sequential pattern under a null hypothesis is very complex, however [17, 13].", "startOffset": 103, "endOffset": 111}, {"referenceID": 12, "context": "puting the expected frequency of a sequential pattern under a null hypothesis is very complex, however [17, 13].", "startOffset": 103, "endOffset": 111}, {"referenceID": 19, "context": "SQUISH builds upon and extends SQS [20].", "startOffset": 35, "endOffset": 39}, {"referenceID": 21, "context": "Both draw inspiration from the KRIMP [22] and SLIM [16] algorithms.", "startOffset": 37, "endOffset": 41}, {"referenceID": 15, "context": "Both draw inspiration from the KRIMP [22] and SLIM [16] algorithms.", "startOffset": 51, "endOffset": 55}, {"referenceID": 15, "context": "The SLIM algorithm [16] mines KRIMP code table directly from data.", "startOffset": 19, "endOffset": 23}, {"referenceID": 6, "context": "introduced GOKRIMP [7] for mining sets of serial episodes.", "startOffset": 19, "endOffset": 22}, {"referenceID": 3, "context": "Recently, Fowkes and Sutton proposed the ISM algorithm [4].", "startOffset": 55, "endOffset": 58}, {"referenceID": 19, "context": "We compare against SQS [20] and ISM [4].", "startOffset": 23, "endOffset": 27}, {"referenceID": 3, "context": "We compare against SQS [20] and ISM [4].", "startOffset": 36, "endOffset": 39}, {"referenceID": 3, "context": "To evaluate the ability of SQUISH to discover interleaved and nested patterns, we consider the Parallel database [4].", "startOffset": 113, "endOffset": 116}, {"referenceID": 5, "context": "Gazelle is clickstream data from an e-commerce website [6].", "startOffset": 55, "endOffset": 58}, {"referenceID": 10, "context": "The Sign database is a list of American sign language utterances [11].", "startOffset": 65, "endOffset": 69}, {"referenceID": 9, "context": "a {b, c} d [10].", "startOffset": 11, "endOffset": 15}], "year": 2017, "abstractText": "Discovering the key structure of a database is one of the main goals of data mining. In pattern set mining we do so by discovering a small set of patterns that together describe the data well. The richer the class of patterns we consider, and the more powerful our description language, the better we will be able to summarise the data. In this paper we propose SQUISH, a novel greedy MDL-based method for summarising sequential data using rich patterns that are allowed to interleave. Experiments show SQUISHis orders of magnitude faster than the state of the art, results in better models, as well as discovers meaningful semantics in the form patterns that identify multiple choices of values.", "creator": "LaTeX with hyperref package"}}}