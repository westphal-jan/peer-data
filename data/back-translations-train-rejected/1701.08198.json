{"id": "1701.08198", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Jan-2017", "title": "Adversarial Evaluation of Dialogue Models", "abstract": "The recent application of RNN encoder-decoder models has resulted in substantial progress in fully data-driven dialogue systems, but evaluation remains a challenge. An adversarial loss could be a way to directly evaluate the extent to which generated dialogue responses sound like they came from a human. This could reduce the need for human evaluation, while more directly evaluating on a generative task. In this work, we investigate this idea by training an RNN to discriminate a dialogue model's samples from human-generated samples. Although we find some evidence this setup could be viable, we also note that many issues remain in its practical application. We discuss both aspects and conclude that future work is warranted.", "histories": [["v1", "Fri, 27 Jan 2017 21:28:57 GMT  (57kb)", "http://arxiv.org/abs/1701.08198v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["anjuli kannan", "oriol vinyals"], "accepted": false, "id": "1701.08198"}, "pdf": {"name": "1701.08198.pdf", "metadata": {"source": "CRF", "title": "Adversarial Evaluation of Dialogue Models", "authors": ["Anjuli Kannan"], "emails": ["anjuli@google.com", "vinyals@google.com"], "sections": [{"heading": null, "text": "ar Xiv: 170 1.08 198v 1 [cs.C L] 27 Jan 20The recent application of RNN encoder decoder models has led to significant advances in fully data-driven dialog systems, but evaluation remains a challenge. An adversarial loss could be a way to directly assess the extent to which generated dialog responses sound as if they came from a human. This could reduce the need for human evaluation, while a more direct evaluation of a generative task is required. In this work, we examine this idea by training an RNN to distinguish samples of a dialogue model from human-made samples. Although we find some evidence that this setup may be workable, we also note that many questions remain in its practical application. We discuss both aspects and come to the conclusion that future work is warranted."}, {"heading": "1 Introduction", "text": "It is not only a matter of time before it happens, but also of time before it happens, until it happens, \"he told the German Press Agency in an interview with\" Welt am Sonntag \":\" I don't think we will be able to solve the problem. \"He added:\" I don't think we will be able to get to grips with the problem. \"He added:\" I don't think we will be able to get to grips with the problem, but I don't think we will be able to solve it. \""}, {"heading": "1.1 Related work", "text": "In many recent works, RNN encoder decoder models have been used to translate from enunciation to response ([9], [8], [11]). Work in [5] has used a political gradient, but the rewards are manually defined as useful conversation characteristics such as redundancy. Evaluation remains a significant challenge [6]. The hostile structure we describe is inspired by working on GANs for image generation [2]; however, we apply the concept to dialogue modeling, which raises the challenges of sequential inputs / outputs and conditional generation. To support our goal of understanding the discriminator, we also do not train the generator and discriminator together. Contrary loss of language understanding is also used in [1] as a means of evaluation; however, the metric is not applied to any real task, nor are the characteristics of the discriminator itself investigated and evaluated, as we will in this work."}, {"heading": "2 Model", "text": "As with a GAN, our architecture consists of a generator and a discriminator, but these are two separate models that are not trained on a single object. The generator is a sequence-to-sequence model, consisting of an RNN encoder and an RNN decoder. Faced with a corpus of message pairs (o, r), where o, the original message, consists of tokens {o1,..., on} and r, the reply message, consists of tokens {r1,..., rm}, this model is trained to maximize the overall log probability of the observed response message based on their respective original messages. Faced with a corpus of message pairs and values (o, r, y), where y = 1, when r is sampled from the data, has only one encoder followed by a binary classifier."}, {"heading": "3 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Data and training", "text": "We examine the proposed loss of an opponent using a corpus of e-mail response pairs (o, r). The generator is trained on the same data and in the same way as the production model used in the Smart Reply function in the inbox of Gmail [3]. 1The discriminator is then trained on a reserved sentence of the e-mail corpus. For half of the pairs (o, r) in the reserved sentence, we leave the example unchanged and assign a 1. For the other half, we replace r with a message sampled by the generator and assign a score of 0 to the pair (o, r). Then the discriminator is trained as described in the previous section."}, {"heading": "3.2 Discriminator performance", "text": "We observe that in 62.5% of cases, the discriminator can distinguish between generator samples and human samples, subject to an original message. This may be somewhat unexpected in itself: 1 In particular, from [3]: \"All e-mail data (raw data, pre-processed data and training data) was encrypted. Engineers could only view aggregated statistics on anonymized records that occurred across many users and did not identify any user.\" Since the discriminator is only as powerful as the generator, it would not be able to distinguish its distribution from the training distribution. A full precision callback curve is shown in Figure 1."}, {"heading": "3.3 Comparison with perplexity", "text": "A qualitative analysis shows that the discriminator lens favors different characteristics than the generator lens. To demonstrate this, we sample 100 responses from the generator for each of 100 donated e-mails, which are then ranked according to both the discriminator score and the generator's assigned log probability, and the two rankings are compared.First, we see that the discriminator's preferences are strongly correlated with length (Figure 1).This is relevant because it has already been documented that sequence-to-sequence models have a length bias [10]. The discriminator relies too heavily on this signal and favors longer responses even if they are not internally coherent. Nevertheless, it is noteworthy that it identifies something that humans have documented as a key weakness of the model [11].The discriminator does not assign the same probability to all responses of equal length. When comparing responses of equal length, we find that it has a significantly different order of precedence from the generator, namely the one that we have weighted with the weakness of the 002."}, {"heading": "4 Discussion", "text": "In this research note, we examined whether the discriminator can be used in GANs to automatically evaluate dialog systems. However, we see a natural evolution toward the use of discriminators: 1. Ask people to evaluate each published system in a uniform way. Although ideal, it would also be time-consuming and prohibitively costs.2. Note a large dataset of dialogues, learn a \"critic\" (e.g. a neural network) and use it to evaluate each new system (so that additional human work would not be required). However, this critic would probably not perform well if evaluated outside of politics, and there could be a revision, as researchers naturally find its weaknesses. 3. Use the discriminator of a GAN as a substitute to give similar feedback to a human. Since training such a critic would be easy for each dialog system, each research group could evaluate its and each new system with a variety of discriminators."}], "references": [{"title": "Generating sentences from a continuous space", "author": ["S.R. Bowman", "L. Vilnis", "O. Vinyals", "A.M. Dai", "R. Jozefowicz", "S. Bengio"], "venue": "In arXiv preprint arXiv:1511.06349,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "Generative adversarial nets", "author": ["I. Goodfellow", "J. Pouget-Abadie", "M. Mirza", "B. Xu", "D. Warde-Farley", "S. Ozair", "A. Courville", "Y. Bengio"], "venue": "In Proceedings of NIPS,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2014}, {"title": "Smart reply: Automated response suggestion for email", "author": ["A. Kannan", "K. Kurach", "S. Ravi", "T. Kaufmann", "B. Miklos", "G. Corrado"], "venue": "In Proceedings of KDD,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2016}, {"title": "A diversity-promoting objective function for neural conversation models", "author": ["J. Li", "M. Galley", "C. Brockett", "J. Gao", "B. Dolan"], "venue": "In Proceedings of NAACL-HLT,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2016}, {"title": "Deep reinforcement learning for dialogue generation", "author": ["J. Li", "W. Monroe", "A. Ritter", "M. Galley", "J. Gao", "D. Jurafsky"], "venue": "In arXiv preprint arXiv:1606.01541,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2016}, {"title": "How not to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation", "author": ["C.-W. Liu", "R. Lowe", "I.V. Serban", "M. Noseworthy", "L. Charlin", "J. Pineau"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2016}, {"title": "Improved techniques for training gans", "author": ["T. Salimans", "I. Goodfellow", "W. Zaremba", "V. Cheung", "A. Radford", "Z. Chen"], "venue": "In arXiv preprint arXiv:1606.03498,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2016}, {"title": "Hierarchical neural network generative models for movie dialogues", "author": ["I.V. Serban", "A. Sordoni", "Y. Bengio", "A. Courville", "J. Pineau"], "venue": "In arXiv preprint arXiv:1507.04808,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "A neural network approach to context-sensitive generation of conversation responses", "author": ["A. Sordoni", "M. Galley", "M. Auli", "C. Brockett", "Y. Ji", "M. Mitchell", "J.-Y. Nie", "J. Gao", "B. Dolan"], "venue": "Proceedings of NAACL-HLT,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2015}, {"title": "Length bias in encoder decoder models and a case for global conditioning", "author": ["P. Sountsov", "S. Sarawagi"], "venue": "In Proceedings of EMNLP,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2016}, {"title": "A neural conversation model", "author": ["O. Vinyals", "Q.V. Le"], "venue": "In ICML Deep Learning Workshop,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2015}, {"title": "Seqgan: Sequence generative adversarial nets with policy gradient", "author": ["L. Yu", "W. Zhang", "J. Wang", "Y. Yu"], "venue": "In arXiv preprint arXiv:1609.05473,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2016}], "referenceMentions": [{"referenceID": 8, "context": "This sort of approach has been shown to improve significantly over both a statistical machine translation baseline [9] and traditional rule-based chatbots [11].", "startOffset": 115, "endOffset": 118}, {"referenceID": 10, "context": "This sort of approach has been shown to improve significantly over both a statistical machine translation baseline [9] and traditional rule-based chatbots [11].", "startOffset": 155, "endOffset": 159}, {"referenceID": 2, "context": "Human evaluation may be ideal, but does not scale well, and can also be problematic in applications like Smart Reply [3], where data cannot be viewed by humans.", "startOffset": 117, "endOffset": 120}, {"referenceID": 1, "context": "Inspired by the success of generative adversarial networks (GANs) for image generation ([2], and others), we propose that one measure of a model\u2019s quality is how easily its output is distinguished from a human\u2019s output.", "startOffset": 88, "endOffset": 91}, {"referenceID": 8, "context": "Much recent work has employed RNN encoder-decoder models to translate from utterance to response ([9], [8], [11]).", "startOffset": 98, "endOffset": 101}, {"referenceID": 7, "context": "Much recent work has employed RNN encoder-decoder models to translate from utterance to response ([9], [8], [11]).", "startOffset": 103, "endOffset": 106}, {"referenceID": 10, "context": "Much recent work has employed RNN encoder-decoder models to translate from utterance to response ([9], [8], [11]).", "startOffset": 108, "endOffset": 112}, {"referenceID": 4, "context": "Work in [5] has used policy gradient but the rewards are manually defined as useful conversational properties such as non-redundancy.", "startOffset": 8, "endOffset": 11}, {"referenceID": 5, "context": "Evaluation remains a significant challenge [6].", "startOffset": 43, "endOffset": 46}, {"referenceID": 1, "context": "The adversarial setup we describe is inspired by work on GANs for image generation [2]; however, we apply the concept to dialogue modeling, which raises the challenges of sequential inputs/outputs and conditional generation.", "startOffset": 83, "endOffset": 86}, {"referenceID": 0, "context": "An adversarial loss for language understanding is also used in [1] as a means of evaluation; however, the metric is not applied to any real world task, nor are the properties of the discriminator itself explored and evaluated, as we will do in this work.", "startOffset": 63, "endOffset": 66}, {"referenceID": 2, "context": "The generator is trained on the same data and in the same manner as the production-scale model that is deployed as part of the Smart Reply feature in Inbox by Gmail [3].", "startOffset": 165, "endOffset": 168}, {"referenceID": 2, "context": "This in itself may be somewhat unexepcted: In particular, from [3]: \"All email data (raw data, preprocessed data and training data) was encrypted.", "startOffset": 63, "endOffset": 66}, {"referenceID": 9, "context": "This is relevant because it has been previously documented that sequence-to-sequence models have a length bias [10].", "startOffset": 111, "endOffset": 115}, {"referenceID": 10, "context": "Still, it is noteworthy that it identifies something humans have documented as a key weakness of the model [11].", "startOffset": 107, "endOffset": 111}, {"referenceID": 2, "context": "The lack of diverse generated language has been documented as a weakness of these dialogue models in [3] and [4], both of which incorporate significant post-processing and re-ranking to overcome this noted weakness.", "startOffset": 101, "endOffset": 104}, {"referenceID": 3, "context": "The lack of diverse generated language has been documented as a weakness of these dialogue models in [3] and [4], both of which incorporate significant post-processing and re-ranking to overcome this noted weakness.", "startOffset": 109, "endOffset": 112}, {"referenceID": 6, "context": "Future work might incorporate minibatch discrimination [7] to more explicitly address the diversity weakness.", "startOffset": 55, "endOffset": 58}, {"referenceID": 11, "context": "Despite the fact that GANs do not use any extra information than what\u2019s already present in the training dataset, some have argued that it is a better loss than likelihood [12].", "startOffset": 171, "endOffset": 175}], "year": 2017, "abstractText": "The recent application of RNN encoder-decoder models has resulted in substantial progress in fully data-driven dialogue systems, but evaluation remains a challenge. An adversarial loss could be a way to directly evaluate the extent to which generated dialogue responses sound like they came from a human. This could reduce the need for human evaluation, while more directly evaluating on a generative task. In this work, we investigate this idea by training an RNN to discriminate a dialogue model\u2019s samples from human-generated samples. Although we find some evidence this setup could be viable, we also note that many issues remain in its practical application. We discuss both aspects and conclude that future work is warranted.", "creator": "LaTeX with hyperref package"}}}