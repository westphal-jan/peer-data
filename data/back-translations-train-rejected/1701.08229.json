{"id": "1701.08229", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Jan-2017", "title": "Feature Studies to Inform the Classification of Depressive Symptoms from Twitter Data for Population Health", "abstract": "The utility of Twitter data as a medium to support population-level mental health monitoring is not well understood. In an effort to better understand the predictive power of supervised machine learning classifiers and the influence of feature sets for efficiently classifying depression-related tweets on a large-scale, we conducted two feature study experiments. In the first experiment, we assessed the contribution of feature groups such as lexical information (e.g., unigrams) and emotions (e.g., strongly negative) using a feature ablation study. In the second experiment, we determined the percentile of top ranked features that produced the optimal classification performance by applying a three-step feature elimination approach. In the first experiment, we observed that lexical features are critical for identifying depressive symptoms, specifically for depressed mood (-35 points) and for disturbed sleep (-43 points). In the second experiment, we observed that the optimal F1-score performance of top ranked features in percentiles variably ranged across classes e.g., fatigue or loss of energy (5th percentile, 288 features) to depressed mood (55th percentile, 3,168 features) suggesting there is no consistent count of features for predicting depressive-related tweets. We conclude that simple lexical features and reduced feature sets can produce comparable results to larger feature sets.", "histories": [["v1", "Sat, 28 Jan 2017 00:32:40 GMT  (209kb,D)", "http://arxiv.org/abs/1701.08229v1", null]], "reviews": [], "SUBJECTS": "cs.IR cs.CL cs.CY cs.SI", "authors": ["danielle mowery", "craig bryan", "mike conway"], "accepted": false, "id": "1701.08229"}, "pdf": {"name": "1701.08229.pdf", "metadata": {"source": "CRF", "title": "Feature Studies to Inform the Classification of Depressive Symptoms from Twitter Data for Population Health", "authors": ["Danielle Mowery", "Craig Bryan", "Mike Conway"], "emails": ["danielle.mowery@utah.edu", "craig.bryan@utah.edu", "mike.conway@utah.edu"], "sections": [{"heading": null, "text": "CCS concepts \u2022 computer methods \u2192 feature selection; supervised learning by classification; support vector machines; natural language processing; keywords depression; natural language processing; social media"}, {"heading": "1. INTRODUCTION", "text": "In recent years, there has been a movement to use social media data to monitor social risks such as prescription drugs and smoking behavior [15, 11, 4] as well as a variety of mental health disorders, including suicidal thoughts [10], attention deficit hyperactivity disorder [8], and severe depressive disorders [9]. In the case of severe depressive disorders, recent efforts range from characterizing linguistic phenomena associated with depression [7] and their subtypes, such as postpartum depression [10], to identifying specific depressive symptoms [3, 12], such as depressive moods. However, more research is needed to understand the predictive power of monitored machine learning classifiers and the influence of feature sets for efficiently classifying depressive tweets, such as supporting mental health monitoring at the level of the most important symptoms of population classification [6]."}, {"heading": "2. METHODS", "text": "Specifically, we conducted a feature ablation study to evaluate the informativeness of each feature group, and a feature elimination study to determine the optimal feature sets for classifying Twitter tweets. We used an existing annotated Twitter data set built on a hierarchical model of depression-related symptoms [13, 14]. The data set contains 9,473 annotations on 9,300 tweets. Each tweet is further commented on with one or more depressive symptoms, such as depressive mood (e.g. \"citizens fear an economic depression\") or evidence of depression (e.g. \"another restless night\") or exhaustion or loss of energy (e.g. \"fatigue is unbearable\")."}, {"heading": "2.1 Features", "text": "In addition, this dataset of 7 characteristic groups with associated characteristic values has been binarized (i.e., present = 1 or absence = 0) to represent potentially informative characteristics for the classification of depressive classes. We describe the characteristic groups by type, subtype, and provide one or more examples of words representing the characteristic subtype of a tweet: ar Xiv: 170 1.08 229v 1 [cs.I R] 28 January 2017 \u2022 lexical characteristics, unigrams, e.g. \"depressive\"; \u2022 syntactic characteristics, speech proportions, e.g. \"screamed,\" encoded as V for verb; \u2022 emotional characteristics, emoticons, e.g.: (encoded as SAD; \u2022 demographic characteristics, age and gender e.g. \"this semester\" encodes as an indicator for 19-22 years of age; and \"my girlfriend\" encodes as an indicator for male gender; \u2022 LIC characteristics and subjectivity sensitivity sensitivities, e.g. \"we have sensitivities,\" with a sense of strength. \""}, {"heading": "2.2 Feature Contribution", "text": "Feature ablation studies are conducted to assess the informativity of a feature group by quantifying the change in predictive power when comparing the performance of a classifier trained with all feature groups with performance without a specific feature group. We conducted a feature ablation study by taking each feature group (sans) in hand and testing the support vector model using a linear kernel and a 5x layered cross validation. We report the average F1 score from our baseline approach (all feature groups) and report the point difference (+ or -) in the performance observed by ablation of each feature set."}, {"heading": "2.3 Feature Elimination", "text": "Often, trait elimination strategies are used to remove irrelevant or disruptive traits, 2) to improve the performance of the classifier, and 3) to reduce training and runtime. We conducted an experiment to determine whether we could maintain or improve the trait performance of the classifier by applying the following three-step approach to trait elimination: \u2022 Reduction We reduced the data set for each class by eliminating traits that occur less than twice in the whole data set. \u2022 Selection We applied iteratively the chi-square trait selection to the reduced data set, selecting the top percentile of the best placed traits in increments of 5 percent to train and test the support vector model using a linear kernel and a 5x layered cross validation. \u2022 Ranking We cumulatively determined the average performance of each step-added percentric to report the highest number of traits for each Scientile to the first Scientile."}, {"heading": "3. RESULTS", "text": "From our annotated data set of Twitter tweets (n = 9,300 tweets), we conducted two feature studies to better understand the predictive power of multiple feature groups, to classify whether or not a tweet contained evidence of depression (n = 6,829 tweets) or signs of depression (n = 2,644 tweets). If there was evidence of depression, we determined whether the tweet contained one or more depressive symptoms (n = 1,656 tweets) and further classified the symptomatic subtype of depressive mood (n = 1,010 tweets), sleep disturbances (n = 98 tweets), or fatigue or energy loss (n = 427 tweets) using support vector machines. From our previous work [12] and in Figure 1, we report on the performance of predictive models created by training a support vector engine with 5-fold layered cross-validation of all feature groups as the basis for each class."}, {"heading": "3.1 Feature Contribution", "text": "By subtracting each trait group from the complete data set, we observed the following number of traits - sans lexical: 185.2http: / / scikit-learn.org / stable / sans syntactic: 16,935, sans emotion: 16,954, sans demographics: 16,946, sans sentiment: 16,950, sans personality: 16,946 and sans LIWC: 16,832. In Figure 1, compared to initial performance, there were also significant declines in F1 values from sans lexical for depressive mood (-35 points), disturbed sleep (-43 points) and depressive symptoms (-45 points). Less pronounced declines also occurred in evidence of depression (-14 points) and exhaustion or loss of energy (-3 points). In contrast, a 3-point gain in F1 scores for depression (-35 points), disturbed sleep (-45 points) and significant declines in scores for depression (-5 points) and non-identical demographic scores for depression (7 points)."}, {"heading": "3.2 Feature Elimination", "text": "The initial matrices of nearly 17,000 features were reduced by eliminating features that occurred only once in the complete dataset, resulting in 5,761 features. We applied the Chi Square feature selection and recorded the first-place subset of features for each percentile (cumulatively added at intervals of 5 percent) and evaluated their predictive contribution using the linear core support vector machine with layered, 5x cross validation. In Figure 2, we observed optimal performance of the F1 score using the following peak features: no signs of depression: F1: 87 (15th percentile, 864 features), evidence of depression: F1: 59 (30th percentile, 1728 features), depressive symptoms: F1: 55 (15th percentile, 864 features), depressive mood: F1: 39 (55th percentile, 3,168 features), sleep disorders F1: 5th percentile, and F1 (5th percentile, 5th percentile, 285th percentile, or energy loss)."}, {"heading": "4. DISCUSSION", "text": "We conducted two experiments with feature studies: 1) a feature ablation study to evaluate the contribution of feature groups and 2) a feature elimination study to determine the optimal percentile of the best placed features for classifying Twitter tweets in the hierarchy of the depression scheme."}, {"heading": "4.1 Feature Contribution", "text": "Not surprisingly, lexical traits are also critical for the identification of depressive symptoms, particularly depressive moods and sleep disorders. For the higher classes in the hierarchy - no evidence of depression, signs of depression, and depressive symptoms - the classifier yielded consistent F1 values, even slightly above the baseline of depressive symptoms and slight fluctuations in the change in memory and precision in removing other trait groups, suggesting that the contribution of non-lexical traits to the classification performance was limited. However, notable changes in the F1 score were observed for the classes at the lower end of the hierarchy, including sleep disorders and fatigue or energy loss. For example, changes in both memory and precision-related F1 values for disturbed sleep were observed, removing demographic traits, emotions, and sentient traits, suggesting that age or gender (\"semester grades may have made me less subjective\") and emotional (which may be unfatal for both polarity)."}, {"heading": "4.2 Feature Elimination", "text": "We observed peaks in the F1 score at low percentiles for fatigue or loss of energy (5th percentile), disturbed sleep (10th percentile), and depressive symptoms, and no signs of depression (both 15th percentiles), suggesting that fewer features are needed to achieve optimal performance. In contrast, peaks in the F1 score occurred at moderate percentiles to indicate depression (30th percentile) and depressive mood (55th percentile), suggesting that more features are needed to achieve optimal performance. However, a notable difference between these two classes is the dramatic improvement in the F1score for depressive mood, i.e. a 20 point increase from the 1st percentile to the 20th percentile, compared to the more gradual improvements in the F1 score to detect depression, i.e. an 11 point increase from the 1st percentile to the 20th percentile. This result suggests that a variety of depressive features may be observed before identifying."}, {"heading": "5. FUTURE WORK", "text": "Our next step is to classify rare depressive symptoms indicating severe depressive disorder from our data set and hierarchy, including inappropriate guilt, difficulty concentrating, psychomotor agitation or slowdown, weight loss or gain, and anhedonia. We are developing a population-level monitoring system designed to estimate the prevalence of depression (and depression-related symptoms and psychosocial stressors) across millions of tweets in the United States."}, {"heading": "6. CONCLUSIONS", "text": "In summary, we conducted two experiments with feature studies to assess the contribution of feature groups and determine the optimal percentiles of the best placed features for classifying Twitter tweets in the hierarchy of the depression scheme. From these experiments, we conclude that simple lexical features and reduced feature sets can provide comparable results with the much larger feature dataset."}, {"heading": "7. ACKNOWLEDGMENTS", "text": "The research reported in this publication was supported by the National Library of Medicine of the [United States] National Institutes of Health under premium numbers K99LM011393 and R00LM011393. This study was excluded from review by the University of Utah Institutional Review Board (IRB 00076188). Note that we did not reproduce tweets verbatim to protect Twitter anonymity; sample tweets were generated only by the researchers. Finally, we would like to thank the anonymous reviewers of this publication for their valuable comments."}, {"heading": "8. REFERENCES", "text": "[1] American Psychiatric Association. Diagnostic andStatistical Manual of Mental Disorders, 4th Edition, Text Revision (DSM-IV-TR) 2nd Psychical 2016. American Psychiatric Association, Washington, DC, 2000. [2] American Psychiatric Association. Diagnostic and Statistical Manual of Mental Disorders, Fifth Edition (DSM-5). American Psychiatric Association, Washington, DC, 2013. [3] P. A. Cavazos-Rehg, M. J. Krauss, S. Connolly, C. Rosa, M. Bharadwaj, and L. J. Bierut. A content analysis of depression-related tweets. Computers in Human Behavior., 54: 351-357, 2016. [4] A. Chen, S. Zhu, and M. Conway. What online communities can tell us about electronic cigarettes and hookah use: A study using text mining and visualization techniques."}], "references": [{"title": "A content analysis of depression-related tweets", "author": ["P.A. Cavazos-Rehg", "M.J. Krauss", "S. Sowles", "S. Connolly", "C. Rosa", "M. Bharadwaj", "L.J. Bierut"], "venue": "Computers in Human Behavior.,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2016}, {"title": "What online communities can tell us about electronic cigarettes and hookah use: A study using text mining and visualization techniques", "author": ["A. Chen", "S. Zhu", "M. Conway"], "venue": "J Med Internet Res,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2015}, {"title": "Omg u got flu? analysis of shared health messages for bio-surveillance", "author": ["N. Collier", "N.T. Son", "N.M. Nguyen"], "venue": "J Biomed Semantics,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2011}, {"title": "Social media, big data, and mental health: Current advances and ethical implications", "author": ["M. Conway", "D. O\u2019Conner"], "venue": "Current Opinion in Psychology.,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2016}, {"title": "Quantifying mental health signals in Twitter", "author": ["G. Coppersmith", "M. Dredze", "C. Harman"], "venue": "In Proceedings of the Workshop on Computational Linguistics and Clinical Psychology: From Linguistic Signal to Clinical Reality,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "From ADHD to SAD: Analyzing the language of mental health on Twitter through self-reported diagnoses", "author": ["G. Coppersmith", "M. Dredze", "C. Harman", "K. Hollingshead"], "venue": "In Proceedings of the 2nd Workshop on Computational Linguistics and Clinical Psychology: From Linguistic Signal to Clinical Reality,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "Characterizing and predicting postpartum depression from shared Facebook data", "author": ["M. De Choudhury", "S. Counts", "E.J. Horvitz", "A. Hoff"], "venue": "In Proceedings of the 17th ACM Conference on Computer Supported Cooperative Work & Social Computing - CSCW", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "Discovering shifts to suicidal ideation from mental health content in social media", "author": ["M. De Choudhury", "E. Kiciman", "M. Dredze", "G. Coppersmith", "M. Kumar"], "venue": "In the 2016 CHI Conference on Human Factors in Computing Systems,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2016}, {"title": "An exploration of social circles and prescription drug abuse through Twitter", "author": ["C. Hanson", "B. Cannon", "S. Burton", "C. Giraud-Carrier"], "venue": "J Med Internet Res,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2013}, {"title": "Towards automatically classifying depressive symptoms from Twitter data for population health", "author": ["D. Mowery", "A. Park", "C. Bryan", "M. Conway"], "venue": "In Proceedings of the Workshop on Computational Modeling of People\u2019s Opinions, Personality, and  Emotions in Social Media,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2016}, {"title": "Toward developing an annotation scheme for depressive disorder symptoms: A preliminary study using Twitter data", "author": ["D.L. Mowery", "C. Bryan", "M. Conway"], "venue": "In Proceeding of 2nd Workshop on Computational Linguistics and Clinical Psychology - From Linguistic Signal to Clinical Reality,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2015}, {"title": "Using Twitter to examine smoking behavior and perceptions of emerging tobacco products", "author": ["M. Mys\u013a\u0131n", "S.-H. Zhu", "W.W. Chapman", "M. Conway"], "venue": "J Med Internet Res,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2013}, {"title": "Linguistic Inquiry and Word Count [computer software", "author": ["J. Pennebaker", "M. Francis", "R. Booth"], "venue": "Mahwah, NJ: Erlbaum Publishers,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2001}, {"title": "Twitter: a good place to detect health conditions", "author": ["V. Prieto", "S. Matos", "M. \u00c1lvarez", "F. Cacheda", "J.L. Oliveira"], "venue": "PLoS One,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2014}], "referenceMentions": [{"referenceID": 13, "context": "For example, eating disorders in Spanish language Twitter tweets [17] and influenza surveillance [5].", "startOffset": 65, "endOffset": 69}, {"referenceID": 2, "context": "For example, eating disorders in Spanish language Twitter tweets [17] and influenza surveillance [5].", "startOffset": 97, "endOffset": 100}, {"referenceID": 11, "context": "More recently, social media has been leveraged to monitor social risks such as prescription drug and smoking behaviors [15, 11, 4] as well as a variety of mental health disorders including suicidal ideation [10], attention deficient hyperactivity disorder [8] and major depressive disorder [9].", "startOffset": 119, "endOffset": 130}, {"referenceID": 8, "context": "More recently, social media has been leveraged to monitor social risks such as prescription drug and smoking behaviors [15, 11, 4] as well as a variety of mental health disorders including suicidal ideation [10], attention deficient hyperactivity disorder [8] and major depressive disorder [9].", "startOffset": 119, "endOffset": 130}, {"referenceID": 1, "context": "More recently, social media has been leveraged to monitor social risks such as prescription drug and smoking behaviors [15, 11, 4] as well as a variety of mental health disorders including suicidal ideation [10], attention deficient hyperactivity disorder [8] and major depressive disorder [9].", "startOffset": 119, "endOffset": 130}, {"referenceID": 7, "context": "More recently, social media has been leveraged to monitor social risks such as prescription drug and smoking behaviors [15, 11, 4] as well as a variety of mental health disorders including suicidal ideation [10], attention deficient hyperactivity disorder [8] and major depressive disorder [9].", "startOffset": 207, "endOffset": 211}, {"referenceID": 5, "context": "More recently, social media has been leveraged to monitor social risks such as prescription drug and smoking behaviors [15, 11, 4] as well as a variety of mental health disorders including suicidal ideation [10], attention deficient hyperactivity disorder [8] and major depressive disorder [9].", "startOffset": 256, "endOffset": 259}, {"referenceID": 6, "context": "More recently, social media has been leveraged to monitor social risks such as prescription drug and smoking behaviors [15, 11, 4] as well as a variety of mental health disorders including suicidal ideation [10], attention deficient hyperactivity disorder [8] and major depressive disorder [9].", "startOffset": 290, "endOffset": 293}, {"referenceID": 4, "context": "In the case of major depressive disorder, recent efforts range from characterizing linguistic phenomena associated with depression [7] and its subtypes e.", "startOffset": 131, "endOffset": 134}, {"referenceID": 7, "context": ", postpartum depression [10], to identifying specific depressive symptoms [3, 12] e.", "startOffset": 24, "endOffset": 28}, {"referenceID": 0, "context": ", postpartum depression [10], to identifying specific depressive symptoms [3, 12] e.", "startOffset": 74, "endOffset": 81}, {"referenceID": 9, "context": ", postpartum depression [10], to identifying specific depressive symptoms [3, 12] e.", "startOffset": 74, "endOffset": 81}, {"referenceID": 3, "context": "However, more research is needed to better understand the predictive power of supervised machine learning classifiers and the influence of feature groups and feature sets for efficiently classifying depression-related tweets to support mental health monitoring at the population-level [6].", "startOffset": 285, "endOffset": 288}, {"referenceID": 10, "context": "We leveraged an existing, annotated Twitter dataset that was constructed based on a hierarchical model of depression-related symptoms [13, 14].", "startOffset": 134, "endOffset": 142}, {"referenceID": 9, "context": ", \u201cthe fatigue is unbearable\u201d) [12].", "startOffset": 31, "endOffset": 35}, {"referenceID": 9, "context": "A more detailed description of leveraged features and their values, including LIWC categories, can be found in [12].", "startOffset": 111, "endOffset": 115}, {"referenceID": 9, "context": "Based on our prior initial experiments using these feature groups [12], we learned that support vector machines perform with the highest F1-score compared to other supervised approaches.", "startOffset": 66, "endOffset": 70}, {"referenceID": 12, "context": "Linguistic Inquiry and Word Count [16]", "startOffset": 34, "endOffset": 38}, {"referenceID": 9, "context": "From our prior work [12] and in Figure 1, we report the performance for prediction models built by training a support vector machine using 5fold, stratified cross-validation with all feature groups as a baseline for each class.", "startOffset": 20, "endOffset": 24}], "year": 2017, "abstractText": "The utility of Twitter data as a medium to support populationlevel mental health monitoring is not well understood. In an effort to better understand the predictive power of supervised machine learning classifiers and the influence of feature sets for efficiently classifying depression-related tweets on a large-scale, we conducted two feature study experiments. In the first experiment, we assessed the contribution of feature groups such as lexical information (e.g., unigrams) and emotions (e.g., strongly negative) using a feature ablation study. In the second experiment, we determined the percentile of top ranked features that produced the optimal classification performance by applying a three-step feature elimination approach. In the first experiment, we observed that lexical features are critical for identifying depressive symptoms, specifically for depressed mood (-35 points) and for disturbed sleep (-43 points). In the second experiment, we observed that the optimal F1-score performance of top ranked features in percentiles variably ranged across classes e.g., fatigue or loss of energy (5th percentile, 288 features) to depressed mood (55th percentile, 3,168 features) suggesting there is no consistent count of features for predicting depressive-related tweets. We conclude that simple lexical features and reduced feature sets can produce comparable results to larger feature sets.", "creator": "LaTeX with hyperref package"}}}