{"id": "1701.08306", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Jan-2017", "title": "Practical Reasoning with Norms for Autonomous Software Agents (Full Edition)", "abstract": "Autonomous software agents operating in dynamic environments need to constantly reason about actions in pursuit of their goals, while taking into consideration norms which might be imposed on those actions. Normative practical reasoning supports agents making decisions about what is best for them to (not) do in a given situation. What makes practical reasoning challenging is the interplay between goals that agents are pursuing and the norms that the agents are trying to uphold. We offer a formalisation to allow agents to plan for multiple goals and norms in the presence of durative actions that can be executed concurrently. We compare plans based on decision-theoretic notions (i.e. utility) such that the utility gain of goals and utility loss of norm violations are the basis for this comparison. The set of optimal plans consists of plans that maximise the overall utility, each of which can be chosen by the agent to execute. We provide an implementation of our proposal in Answer Set Programming, thus allowing us to state the original problem in terms of a logic program that can be queried for solutions with specific properties. The implementation is proven to be sound and complete.", "histories": [["v1", "Sat, 28 Jan 2017 17:55:04 GMT  (771kb,D)", "http://arxiv.org/abs/1701.08306v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["zohreh shams", "marina de vos", "julian padget", "wamberto w vasconcelos"], "accepted": false, "id": "1701.08306"}, "pdf": {"name": "1701.08306.pdf", "metadata": {"source": "CRF", "title": "Practical Reasoning with Norms for Autonomous Software Agents (Full Edition)", "authors": ["Zohreh Shamsa", "Marina De Vos", "Julian Padget", "Wamberto W. Vasconcelos"], "emails": ["z.shams@bath.ac.uk", "m.d.vos@bath.ac.uk", "j.a.padget@bath.ac.uk", "wvasconcelos@acm.org"], "sections": [{"heading": null, "text": "Autonomous software agents operating in dynamic environments must constantly think about measures to pursue their goals, taking into account norms that could be imposed on these actions. Normal practical thinking helps agents make decisions about what is best for them in a given situation (not). What makes practical thinking challenging is the interaction between the goals that agents pursue and the norms that agents try to adhere to. We offer a formalization that allows agents to plan multiple goals and norms in the presence of permanent actions that can be executed simultaneously. We compare plans based on decision theory (i.e. utility), so that the gain in goals and the loss in benefits of norm violations are the basis for this comparison. The set of optimal plans consists of plans that maximize the overall benefits, each of which can be selected by the agent to execute them. We offer an implementation of our proposal in Answer Set, naming the logic program that allows us to relate the original problem to a specific one."}, {"heading": "1. Introduction", "text": "The need to control undesirable behavior has led to consideration of the concept of norms that provide a way to define the ideal behavior of autonomous software agents in open environments. Such norms often define obligations and prohibitions that express what the agent has to do and what prevents the agent from performing his task. Depending on their computational interpretation, norms can be considered soft or hard constraints. If they are modeled as hard constraints, the agent is subjected to norms in which the agent has no choice but blindly follows the norms (Esteva et al). Although regulation guarantees compliance with norms, it severely limits the autonomy of agents."}, {"heading": "2. Illustrative Scenario", "text": "In order to illustrate our approach and to motivate the normative practical thinking model in the next section, we consider a scenario in which a software agent acts as a monitoring system in a disaster rescue mission and supports human decision-making in response to an emergency. The responsibility of the software agent is to provide people with different courses of action and to help them decide which course of action to take. In our scenario, the agent plans for a group of human actors responsible for responding to an emergency caused by an earthquake. The agent monitors the current situation (e.g. contamination of water, detection of shocks, etc.) and draws up potential plans for meeting the goals set by human actors. In our scenario, we assume the following two objectives: 1. Leadership of a hospital to help injured people: This goal is fulfilled when doctors are present to offer help and they have access to water and medicines. 2. Organization of a survival camp: This is fulfilled when the area of the camp is secured and a shelter is built."}, {"heading": "3. A Model for Normative Practical Reasoning", "text": "In this research, we take STRIPS (Fikes and Nilsson, 1971) as the basis of our normative practical argumentation model. In STRIPS, a planning problem is defined in terms of a starting state, a target state and a series of operators (e.g. measures).Each operator has a set of preconditions that represent the circumstances / context in which the operator can be executed, and a set of subsequent conditions that arise from the application of the operator.Any sequence of measures that fulfil the goal is a solution to the planning problem. In order to grasp the characteristics of the normative practical reasoning problem that we will model, we extend the classical planning problem by: (i) Replacing atomic measures with permanent measures: often the nature of the actions is non-atomic, which means that the system state in which they are executed is not necessarily the same as in which they began (Nunes al, 1997)."}, {"heading": "3.1. Architecture", "text": "The architecture shown in Figure 1 shows how replanning can be considered when an ongoing plan is interrupted due to changing circumstances, which may be the result of a change in the environment or unexpected actions by other actors in the system. As is customary with multi-agent systems, the actor regularly reviews the feasibility of his plan. Frequency depends on the type of system in which the actor operates, the actor's commitment to his intentions and the impact of the recalculation on the actor's overall performance. If an actor decides that a redesign is in order, he assumes the state in which the plan is interrupted as the initial state for the new plan, and his current goal is set as the goals to work towards. The current goal need not be the same as the goal for which the original plan was set. Goals can already be achieved in the interrupted plan, previous goals can no longer be relevant, and others will be added."}, {"heading": "3.2. Syntax", "text": "We begin this section by describing an extended STRIPS planning problem defined in (Shams, 2016) and comprising (i) permanent measures, (ii) multiple objectives and (iii) multiple standards. Definition 1 (Normative Practical Reasoning Problem) A normative practical reasoning problem is a triple P = (FL, \u2206, A, G, N) where (i) FL is a set of liquids, (ii) \u0445 the initial state, (iii) A is a finite, not empty set of permanent measures for the agent, (iv) G is the objective of the agent, (v) N is a set of norms. In the following sections, we each describe the components of a normative practical reasoning problem."}, {"heading": "3.2.1. Fluents and Initial State", "text": "A literal l is a flowing state or its negation, i.e. l = fl or l = \u00ac fl for a series of flows in L or L. L is well defined if there is no flowing flow in L, so that fl, fl, fl and L, i.e. if L and L are not present, are considered false. The semantics of the initial practical argumentation problem is defined by a series of states: one state is determined by fluxes that are valid at a given time, while the other fluxes (that are not present) are considered false. A state s that satisfies fl and FL is determined by fluxes that are true at a given time, while the other fluxes (that are not) are considered false."}, {"heading": "3.3. Durative Actions", "text": "Component A of our normative practical argumentation problem P = (FL, \u2206, A, G, N) is a set of permanent measures. A permanent act has pre-conditions and after-conditions. The effects of an act (as covered by its after-conditions) are not immediate, that is, it does not take a period of time for the effects of an act to take place.Definition 2 (permanent acts) and d \u00b2 N is the duration of the act. < pr, ps, d > where pr and ps may be empty and finite sentences of well-defined letters, each representing the pre and after-conditions of the act, and d \u00b2 N, is the duration of the act. In the face of an act a = < pr, ps, d > we can also refer to its three components, pr (a), ps (a) and da. Furthermore, we use pr (a) and pr (a) \u2212 to refer to the respective positive and negative letters."}, {"heading": "3.4. Goals", "text": "Various types of objectives and their properties have been classified in the literature (van Riemsdijk et al., 2008; de Boer et al., 2002; Nigam and Leite et al., 2006; van Riemsdijk et al., 2002). Objectives for the purpose of this research are achievement objectives. We define below the elements of group G of P = (FL, E, A, G, N). Definition 3 (objectives). A goal g is the pair < r, v >, where r is a possibly empty and finite group of well-defined dictionaries representing the target requirements, and v \u00b2 N, v > 0, represents the benefit / gain for achieving the goal.Objective g requirements and value are presented as r (g) and v (below)."}, {"heading": "3.5. Norms", "text": "In fact, it is as if it is a matter of a way in which people blame themselves and others. (...) In fact, it is as if people are able to survive themselves. (...) In fact, it is as if they were able to survive themselves. (...) It is not as if they were able to survive themselves. (...) It is as if they were able to survive themselves. (...) It is as if they were able to survive themselves. (...) It is as if they were able to survive themselves. (...) (...) It is as if they were able to survive themselves. (...) It is as if they are able to survive themselves. (...) It is as if they are able to survive themselves. (...) It is as if they are able to survive themselves. (...) It is as if they are able to survive themselves. (...) It is as if they are able to survive themselves. (...)"}, {"heading": "3.6. Semantics", "text": "After explaining the syntax of the model, we will now focus on semantics. To this end, we must describe a normative practical argumentation problem P = (FL, \u2206, A, G, N): (i) What are the possible procedures for the agent and what characteristics each procedure has. Properties are defined in terms of goals that a sequence of actions fulfills, norms that it complies with, and the norms that it violates. This point is discussed in Section 3.6.1. (ii) What different types of conflicts the actor may experience while trying to fulfill his goals and comply with the norms to which he is subject. In Section 3.6.2, we will examine this point. (iii) What a sequence of actions is defined as a solution / plan for problem P. Plans are defined in Section 3.6.3."}, {"heading": "3.6.1. Sequences of Actions and their Properties", "text": "Let P = (FL, G, N) be a normative practical problem in terms of how we define the individual measures."}, {"heading": "3.6.2. Conflict", "text": "In the past, we have always had problems with the fact that we could not stick to the rules that we had imposed on ourselves, but to the rules that we had imposed on ourselves. (...) In the past, we have always had problems with the fact that we did not stick to the rules. (...) In the past, we have always had problems with the fact that we did not stick to the rules. (...) In the past, we kept sticking to the rules. (...) In the past, we kept sticking to the rules. (...) In the past, we kept sticking to the rules. (...) In the past, we kept sticking to the rules. \"(...) We kept sticking to the rules.\" (...) We didn't stick to the rules. \""}, {"heading": "3.6.3. Plans", "text": "In classical planning, a sequence of actions \u03c0 = < (a0, 0), \u00b7 \u00b7, (an, tn) > is identified as a plan if all fluctuations in the initial state apply at a time of 0 and to each i, with the preconditions of action ai at the time of tai and the goal of the planning problem being fulfilled in time, with m = Makespan (\u03c0). Extending the conventional planning problem by several potentially conflicting goals and norms requires the definition of additional conditions in order to make a sequence of actions a plan and a solution for P. In the following, we define what is required to identify a sequence of actions as a plan. Definition 15 (plan). A sequence of actions \u03c0 = < (a0, 0),., (an, tan) > s.t. @ (ai, tai), (aj, taj), (aj, taj), the sequence of actions is to be defined as a plan."}, {"heading": "4. Implementation", "text": "In this section we show how a normative practical argumentation problem P = (FL, \u2206, A, G, N) (cf. Def. 1) can be implemented. To propose such an implementation, we use Answer Set Programming (ASP) (Gelfond and Lifschitz, 1988). Recent work on planning in ASP (To et al., 2015) shows that ASP is a viable competitor in terms of general planners. Event Calculation (EC) (Kowalski and Sergot, 1986) forms the basis for the implementation of some normative argumentation frameworks, such as those by Alrawagfeh and Meneguzzi (2014) and Articis et al. (2009) Our proposed formal model is language-independent and could therefore be translated into a computational model."}, {"heading": "4.1. Answer Set Programming", "text": "Like all declarative paradigms, it has the advantage of describing the constraints and solutions, rather than writing an algorithm to find solutions to a problem. \u00b7 \u00b7 A variety of programming languages for ASP exist, and we use AnsProlog (Baral, 2003). There are several efficient approaches to AnsProlog, of which Clingo (Gebser et al., 2011) and DLV (Eiter et al., 1999) are currently the most widely used. AnsProlog's basic components are atoms, which are constructs to which one can assign a truth value. An atom can be negated by assuming negation as failure (naf), which states that a negated atom is not true if there is no evidence to prove an atom."}, {"heading": "4.2. Translating the Normative Practical Reasoning Problem into ASP", "text": "Before describing the figure (Figure 2) of the normative practical thinking problem P = (FL, \u2206, A, G, N) in ASP, we list the atoms we use in the figure in Table 1. The description of the figure is presented in the following sections with references to Figure 2. Note that variables are large and grounded variables are small italic."}, {"heading": "4.2.1. States", "text": "In Section 3.6 we described the semantics P = (FL, \u2206, A, G, N) over a series of states. The facts generated by line 1 provide the program with all available states for plans of maximum length q. Currently, the length of the plans must be determined experimentally. We plan to automate this using incremental features of the ASP solver clingo4 (Gebser et al., 2011). Line 2 encodes that the initial flows (x) must be kept at state 0, which is achieved by the fact stocks (x, 0). Rivers are sluggish, they persist if they are not terminated. Inertia is terminated in lines 3-4. Termination is modelled by the predicate (X, S)."}, {"heading": "4.2.2. Actions", "text": "This section describes the details of the encoding of actions. Each durative action is encrypted as an action (a, d) (line 5), where a is the name of the action and d is its duration. The prerequisites pr (a) of the action are a stop in state s, if s | = pr (a). This is expressed in line 6 using Atom pre (a, S). To make the encoding more readable, we introduce the abbreviation EX (X, S) a set of flows that should be kept in state S. For all x-X, EX (X, S) is translated into holdsat (x, S), and for all \u00ac x-X-X-X the execution is not EX (x, S) using negation as a failure. The agent has the choice to perform one of his actions in any state."}, {"heading": "4.2.3. Goals and Norms", "text": "This is expressed in line 18 where g + and g \u2212 the positive and negative letters in the sentence g.For the norms it should be noted that the following definitions 11-14, the compliance and violation of a norm (< compliance and violation of a norm (< compliance and violation of a norm (< compliance and violation of a norm (< compliance and violation of a norm) (< compliance)) (< compliance with the norm) (< compliance with the norm) (< compliance with the norm (X, S2): - holdsat (X, S1), not terminated (X, S1), 4 state (S1), S2 state (S2), S2 state (S1), S2 state (S1), S2 state (S1), S2 state (S1)."}, {"heading": "4.2.4. Mapping Answer Sets to Plans", "text": "After implementing the components of P = (FL, \u2206, A, G, N), we now encode the criteria for a sequence of actions to be identified as a plan and solution for P. The rule in line 41 is responsible for limiting the response rates to those that meet at least one goal, by excluding answers that do not meet a goal. Input for this rule is in line 40, where goals are marked as met if they are met in at least one state. Avoiding simultaneous conflicting actions is achieved on lines 42-43, which specify that two such actions cannot be performed at the same time. This includes mapping a formal planning problem to its mathematical counterpart in AnsProlog. For a problem P, we refer to the program that consists of lines 1-43, as Appendix B. As mentioned in section 2, the formulation of our disaster scenario in Appendix A. The figure of scenario B. follows its model B. in Appendix B."}, {"heading": "4.2.5. Soundness and Completeness of Implementation", "text": "The following theorems show the agreement between the solutions to problem P and the solution theories of the program \u043fPBase.Theorem 1 (solidity).Let P = (FL, I, A, G, N) be a normative practical argumentation problem, with \u043fPBase as the corresponding AnsProlog program. Let Ans be a response group of \u0421PBase, then a group of atoms of the form to be executed (ai, tai).Theorem 2 (completeness) encodes a solution for P. The proof for this theorem is presented in Appendix C. This is a structural proof explaining how the structure of \u0421PBase meets the conditions that identify a sequence of actions as a plan.Theorem 2 (completeness) Let \u03c0 = < (a0, 0), \u00b7 \u00b7, (an, tan) > a plan for P = (FL, I, A, G, N).Then there is an answer to a series of action atoms (ai) that are executed."}, {"heading": "4.2.6. Optimal Plans", "text": "To find optimal plans in Figure 3, we show how to encode the utility function defined by Eq.19. The sum of the values of the goals fulfilled in a plan is calculated in line 44 using an ASP-built total volume # sum. This sum is an operation based on a set of weighted literals evaluated on the sum of the weights of the literals. We first assign the value of the goals as the weight of the fulfilled literals (G) and then use # sum to calculate the sum of the values of all objectives. The sum of the costs of the standards violated in a plan is calculated in line 47 using the same total value. However, the weight of the letter is the cost of punishing the norms. Input for this line is given in lines 45 and 46, where violated norms are calculated based on the combination of the norm id n and the state in which they are used."}, {"heading": "5. Related Work", "text": "In this section, we will first consider a series of architectures that aim to integrate normative thinking into practical thinking, grouped in BDI (Section 5.1) and Non-BDI (Section 5.2), and then, in Section 5.3, we will examine different classifications of these architectures according to the approaches chosen, and in the same section, we will also compare these approaches with the approach proposed here."}, {"heading": "5.1. BDI Architectures with Normative Reasoning", "text": "It is an essential part of the work to integrate standards into the BDI architecture (Rao and Georgeff, 1995), but the motivation, theory and practice vary considerably. An important assumption here is that a plan library (i.e. a set of predefined plans) exists and the agent applies normative considerations to select and / or adapt a provided plan rather than generating a normative plan. We review several normative BDI frameworks and compare them with the approach proposed here. BOID architecture (Broersen et al., 2001) expands BDI with the concept of commitment and uses agent types such as social, selfish, etc. to handle the conflicts between beliefs, wishes, intentions and obligations. For example, selfish agents prioritise their wishes in the event of conflict, whereas social agents prioritise their obligations. Since beliefs, desires, intentions and obligations are all presented as a set of rules, priorities are assigned to resolve the conflict."}, {"heading": "5.2. Non-BDI Architectures with Normative Reasoning", "text": "A second, smaller group of research papers looks at the problem either from a non-BDI perspective or is agnostic about agent architecture. A result of not being bound by BDI is not necessarily to rely on a pre-generated plan library that raises questions about how standards-compliant plans are generated. Oren et al. (2011) use a pre-generated plan, like the list above, but take standards into account when deciding how the plan should be executed with respect to the norms triggered by this plan. Specifically, the approach aims to align the chosen plan with the norms that govern the planning measures at any point in time when the standard expresses limitations on the values that variables can be assigned in a planning action. Adjustments of the values in actions specify how the agent should execute a plan, so that the costs of the violated norms are standardized by rewarding the standard."}, {"heading": "5.3. Normative Reasoning Mechanisms", "text": "eSi rf\u00fc ide eeisrrrrrrreeeeeeeeteeteecnlrrrrrrllhsrteee\u00fccnlhsrteeeeee\u00fccnlhsrteee\u00fccnlhsrteeeeeeeeeeeeeerrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrlrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr"}, {"heading": "6. Conclusions and Future Work", "text": "rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr"}, {"heading": "Appendix A. Formulation of the Disaster Scenario", "text": "We offer a formalization of the scenario in accordance with Section 2. Let P = (FL, LB, A, G, N) be the normative practical justification for the disaster scenario as follows: \u2022 FL = ShockDetect, PoisonDetect, Water Supply, Provided, Secure, Evacuated, Shaken, Housed Built, Inhabited, Wounded, Earthquake Detected, Medication Supply, Present Pharmaceuticals \u2022 A = {detectShock, DetectGift, Plug Water, Building Shelter, Evacuated, GetMedicine, Safe DetectionShock = < {detectShock}, {shockDetected}, 1 >."}, {"heading": "Appendix B. Mapping of Our Disaster Scenario", "text": "The formal specification of our disaster scenario (section 2), as provided in the previous section, can be assigned to the corresponding Application Prolog program in accordance with the rules given in Figure 2 on page 25. The corresponding program is shown in Figures B.4-B.8. The optimization conditions are shown in Figure B.9. the visualization of the three sets of answers of the program is shown in Figures B.10-B.12, where arcs show the ongoing actions and the fields under each state show the liquids occurring in that state. In bold are the liquids added to the State, while the crossed liquids are the ended applicability. Standards violated in a state are highlighted in red and satisfied objectives are highlighted in green. \u2212 Applicability of any plan presented in each group of responses, as calculated below, is applicability, applicability, to the optimal plannability of the plannability of the plan = (Figure B.9), the benefit of any plan presented in each group of responses, as shown below, is applicability, to the optimal plannability, (Applicability = hospital)."}, {"heading": "1 violated(n1,S1) :- vol(f(n1,S1,buildShelter ,DL),S2),", "text": "In fact, we see ourselves in a position to save the world, and we see ourselves in a position to save the world. (...) We are not in a position to save the world. (...) We are not in a position to save the world. (...) We are not in a position to save the world. (...) We are not in a position to save the world. (...) We are not in a position to save the world. (...) We are not in a position to save the world. (...) We are not in a position to save the world. (...) We are not in a position to save the world. (...) We are not in a position to save it. (...) We are not in a position to save it. (...)"}, {"heading": "Appendix C. Proof of Theorem 1", "text": "Theorem (Soundness).Let P = (FL, I, A, G, N) be a normative practical argumentation problem with (ai, tai).Let Ans be a response sentence with (ai, tai).Let Ans be a set of atoms in the form that is executed (ai, tai).Ans encode a solution for P.Proof. We must prove that the action sequence that is part of the answer series meets all the criteria to be a solution for the encrypted plan program.Actions and more precisely the postal conditions of actions are the cause of the change from one state to another. Line 7 generates all action sequences that do not end the state. Rows 13-14 change a state in which some actions en.Actions and more precisely the postal conditions of actions are the cause of the change from one state to another. Line 7 generates all action sequences."}, {"heading": "Appendix D. Proof of Theorem 2", "text": "The question which has arisen in recent years is whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, whether it is a system, a system, a system, a system, whether it is a system, whether it is a system, whether it is a system, a system, whether it is a system, a system, a system, a system, a system, whether it is a system, a system, a system, a system, a system, a"}], "references": [{"title": "Normative system games", "author": ["T. \u00c5gotnes", "W. van der Hoek", "M. Wooldridge"], "venue": "International Conference on Autonomous Agents and Multiagent Systems. IFAAMAS,", "citeRegEx": "\u00c5gotnes et al\\.,? \\Q2007\\E", "shortCiteRegEx": "\u00c5gotnes et al\\.", "year": 2007}, {"title": "Operationalisation of norms for usage in electronic institutions", "author": ["H. Aldewereld", "F. Dignum", "A. Gar\u0107\u0131a-Camino", "P. Noriega", "J.A. Rod\u0155\u0131guezAguilar", "C. Sierra"], "venue": "International Conference on Autonomous Agents and Multiagent Systems", "citeRegEx": "Aldewereld et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Aldewereld et al\\.", "year": 2006}, {"title": "Programming norm-aware agents", "author": ["N. Alechina", "M. Dastani", "B. Logan"], "venue": "International Conference on Autonomous Agents and Multiagent Systems. IFAAMAS,", "citeRegEx": "Alechina et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Alechina et al\\.", "year": 2012}, {"title": "Utilizing permission norms in BDI practical normative reasoning. In: International Workshop on Coordination, Organizations, Institutions, and Norms", "author": ["W. Alrawagfeh", "F. Meneguzzi"], "venue": null, "citeRegEx": "Alrawagfeh and Meneguzzi,? \\Q2014\\E", "shortCiteRegEx": "Alrawagfeh and Meneguzzi", "year": 2014}, {"title": "Specifying norm-governed computational societies", "author": ["A. Artikis", "M.J. Sergot", "J.V. Pitt"], "venue": "ACM Transactions on Computational Logic", "citeRegEx": "Artikis et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Artikis et al\\.", "year": 2009}, {"title": "Knowledge Representation, Reasoning, and Declarative Problem Solving", "author": ["C. Baral"], "venue": null, "citeRegEx": "Baral,? \\Q2003\\E", "shortCiteRegEx": "Baral", "year": 2003}, {"title": "Fast planning through planning graph analysis", "author": ["A.L. Blum", "M.L. Furst"], "venue": "Artificial Intelligence", "citeRegEx": "Blum and Furst,? \\Q1997\\E", "shortCiteRegEx": "Blum and Furst", "year": 1997}, {"title": "Programming MultiAgent Systems in AgentSpeak using Jason", "author": ["R.H. Bordini", "M. Wooldridge", "J.F. H\u00fcbner"], "venue": null, "citeRegEx": "Bordini et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Bordini et al\\.", "year": 2007}, {"title": "Asynchronous multi-agent asms. In: Abstract State Machines", "author": ["E. B\u00f6rger", "R. St\u00e4rk"], "venue": null, "citeRegEx": "B\u00f6rger and St\u00e4rk,? \\Q2003\\E", "shortCiteRegEx": "B\u00f6rger and St\u00e4rk", "year": 2003}, {"title": "The BOID architecture: Conflicts between beliefs, obligations, intentions and desires", "author": ["J. Broersen", "M. Dastani", "J. Hulstijn", "Z. Huang", "L. van der Torre"], "venue": "International Conference on Autonomous Agents", "citeRegEx": "Broersen et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Broersen et al\\.", "year": 2001}, {"title": "Goal generation in the BOID architecture", "author": ["J. Broersen", "M. Dastani", "J. Hulstijn", "L. van der Torre"], "venue": "Cognitive Science Quarterly", "citeRegEx": "Broersen et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Broersen et al\\.", "year": 2002}, {"title": "Representing and monitoring social commitments using the event calculus", "author": ["F. Chesani", "P. Mello", "M. Montali", "P. Torroni"], "venue": "Autonomous Agents and Multi-Agent Systems", "citeRegEx": "Chesani et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Chesani et al\\.", "year": 2013}, {"title": "Answer set programming for representing and reasoning about virtual institutions", "author": ["O. Cliffe", "M. De Vos", "J.A. Padget"], "venue": "International Workshop on Computational Logic in Multi-Agent", "citeRegEx": "Cliffe et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Cliffe et al\\.", "year": 2006}, {"title": "Using norms to control open multi-agent systems", "author": ["N. Criado"], "venue": "Ph.D. thesis,", "citeRegEx": "Criado,? \\Q2012\\E", "shortCiteRegEx": "Criado", "year": 2012}, {"title": "A BDI architecture for normative decision making", "author": ["N. Criado", "E. Argente", "V.J. Botti"], "venue": "International Conference on Autonomous Agents and Multiagent Systems. IFAAMAS,", "citeRegEx": "Criado et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Criado et al\\.", "year": 2010}, {"title": "2APL: a practical agent programming language", "author": ["M. Dastani"], "venue": "Autonomous Agents and Multi-Agent Systems", "citeRegEx": "Dastani,? \\Q2008\\E", "shortCiteRegEx": "Dastani", "year": 2008}, {"title": "Agent programming with declarative goals. CoRR cs.AI/0207008", "author": ["F.S. de Boer", "K.V. Hindriks", "W. van der Hoek", "J.C. Meyer"], "venue": null, "citeRegEx": "Boer et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Boer et al\\.", "year": 2002}, {"title": "Combining event-and state-based norms", "author": ["M. De Vos", "T. Balke", "K. Satoh"], "venue": "In: International conference on Autonomous Agents and MultiAgent Systems", "citeRegEx": "Vos et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Vos et al\\.", "year": 2013}, {"title": "TAL: temporal action logics language specification and tutorial", "author": ["P. Doherty", "J. Gustafsson", "L. Karlsson", "J. Kvarnstr\u00f6m"], "venue": "Electronic Transactions on Artificial Intelligence (2),", "citeRegEx": "Doherty et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Doherty et al\\.", "year": 1998}, {"title": "The diagnosis frontend of the DLV system", "author": ["T. Eiter", "W. Faber", "N. Leone", "G. Pfeifer"], "venue": "AI Communications", "citeRegEx": "Eiter et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Eiter et al\\.", "year": 1999}, {"title": "On the formal specifications of electronic institutions", "author": ["M. Esteva", "J.A. Rod\u0155\u0131guez-Aguilar", "C. Sierra", "P. Garcia", "J.L. Arcos"], "venue": "Agent Mediated Electronic Commerce, The European AgentLink Perspective. Vol", "citeRegEx": "Esteva et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Esteva et al\\.", "year": 2001}, {"title": "Strips: A new approach to the application of theorem proving to problem solving", "author": ["R.E. Fikes", "N.J. Nilsson"], "venue": "International Joint Conference on Artificial Intelligence", "citeRegEx": "Fikes and Nilsson,? \\Q1971\\E", "shortCiteRegEx": "Fikes and Nilsson", "year": 1971}, {"title": "PDDL2.1: An extension to pddl for expressing temporal planning domains", "author": ["M. Fox", "D. Long"], "venue": "Artificial Intelligence Research", "citeRegEx": "Fox and Long,? \\Q2003\\E", "shortCiteRegEx": "Fox and Long", "year": 2003}, {"title": "A temporal planning system for durative actions of PDDL2.1", "author": ["A. Garrido", "M. Fox", "D. Long"], "venue": null, "citeRegEx": "Garrido et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Garrido et al\\.", "year": 2002}, {"title": "Verifying normative system specification containing collective imperatives and deadlines", "author": ["L. Gasparini", "T.J. Norman", "M.J. Kollingbaum", "L. Chen", "J.C. Meyer"], "venue": "International Conference on Autonomous Agents and Multiagent Systems", "citeRegEx": "Gasparini et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Gasparini et al\\.", "year": 2015}, {"title": "Potassco: The Potsdam answer set solving collection", "author": ["M. Gebser", "R. Kaminski", "B. Kaufmann", "M. Ostrowski", "T. Schaub", "M. Schneider"], "venue": "AI Communications", "citeRegEx": "Gebser et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Gebser et al\\.", "year": 2011}, {"title": "The stable model semantics for logic programming", "author": ["M. Gelfond", "V. Lifschitz"], "venue": "International Conference and Symposium on Logic Programming", "citeRegEx": "Gelfond and Lifschitz,? \\Q1988\\E", "shortCiteRegEx": "Gelfond and Lifschitz", "year": 1988}, {"title": "The FF planning system: Fast plan generation through heuristic search", "author": ["J. Hoffmann", "B. Nebel"], "venue": "Artificial Intelligence Research,", "citeRegEx": "Hoffmann and Nebel,? \\Q2001\\E", "shortCiteRegEx": "Hoffmann and Nebel", "year": 2001}, {"title": "Combining goal generation and planning in an argumentation framework", "author": ["J. Hulstijn", "L.W.N. van der Torre"], "venue": "Non Monotonic Reasoning", "citeRegEx": "Hulstijn and Torre,? \\Q2004\\E", "shortCiteRegEx": "Hulstijn and Torre", "year": 2004}, {"title": "GOSU: computing goal support with commitments in multiagent systems", "author": ["\u00d6. Kafali", "A. G\u00fcnay", "P. Yolum"], "venue": "European Conference on Artificial Intelligence. Vol. 263 of Frontiers in Artificial Intelligence and Applications", "citeRegEx": "Kafali et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kafali et al\\.", "year": 2014}, {"title": "Generating parallel execution plans with a partialorder planner", "author": ["C.A. Knoblock"], "venue": "International Conference on Artificial Intelligence Planning Systems", "citeRegEx": "Knoblock,? \\Q1994\\E", "shortCiteRegEx": "Knoblock", "year": 1994}, {"title": "Norm-governed practical reasonig agents", "author": ["M. Kollingbaum"], "venue": "Ph.D. thesis,", "citeRegEx": "Kollingbaum,? \\Q2005\\E", "shortCiteRegEx": "Kollingbaum", "year": 2005}, {"title": "A logic-based calculus of events", "author": ["R. Kowalski", "M. Sergot", "Jan."], "venue": "New Generation Computing. 4(1), 67\u201395.", "citeRegEx": "Kowalski et al\\.,? 1986", "shortCiteRegEx": "Kowalski et al\\.", "year": 1986}, {"title": "A reductive semantics for counting and choice in answer set programming", "author": ["J. Lee", "V. Lifschitz", "R. Palla"], "venue": "International Conference on Artificial Intelligence. AAAI Press,", "citeRegEx": "Lee et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Lee et al\\.", "year": 2008}, {"title": "N-Jason: Run-time norm compliance in AgentSpeak(L)", "author": ["J. Lee", "J. Padget", "B. Logan", "D. Dybalova", "N. Alechina"], "venue": "International Workshop in Engineering MultiAgent Systems. Vol. 8758 of Lecture Notes in Computer Science", "citeRegEx": "Lee et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Lee et al\\.", "year": 2014}, {"title": "Reformulating temporal action logics in answer set programming", "author": ["J. Lee", "R. Palla"], "venue": "Conference on Artificial Intelligence", "citeRegEx": "Lee and Palla,? \\Q2012\\E", "shortCiteRegEx": "Lee and Palla", "year": 2012}, {"title": "Reformulating the situation calculus and the event calculus in the general theory of stable models and in answer set programming", "author": ["J. Lee", "R. Palla"], "venue": "CoRR abs/1401.4607", "citeRegEx": "Lee and Palla,? \\Q2014\\E", "shortCiteRegEx": "Lee and Palla", "year": 2014}, {"title": "Answer set programming and plan generation", "author": ["V. Lifschitz"], "venue": "Artificial Intelligence 138(1-2),", "citeRegEx": "Lifschitz,? \\Q2002\\E", "shortCiteRegEx": "Lifschitz", "year": 2002}, {"title": "What is answer set programming", "author": ["V. Lifschitz"], "venue": "International Conference on Artificial Intelligence", "citeRegEx": "Lifschitz,? \\Q2008\\E", "shortCiteRegEx": "Lifschitz", "year": 2008}, {"title": "A normative framework for agent-based systems. In: Normative Multi-Agent Systems (NORMAS)", "author": ["F. L\u00f3pez y L\u00f3pez", "M. Luck", "M. d\u2019Inverno"], "venue": null, "citeRegEx": "L\u00f3pez et al\\.,? \\Q2005\\E", "shortCiteRegEx": "L\u00f3pez et al\\.", "year": 2005}, {"title": "Simplified reduct for choice rules in ASP", "author": ["M. Law", "A. Russo", "Broda"], "venue": "Technical Report.,", "citeRegEx": "Law et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Law et al\\.", "year": 2015}, {"title": "BDI reasoning with normative considerations", "author": ["F. Meneguzzi", "O. Rodrigues", "N. Oren", "W.W. Vasconcelos", "M. Luck"], "venue": "Engineering Application of Artificial Intelligence", "citeRegEx": "Meneguzzi et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Meneguzzi et al\\.", "year": 2015}, {"title": "Argumentation based resolution of conflicts between desires and normative goals", "author": ["S. Modgil", "M. Luck"], "venue": "Argumentation in Multi-Agent Systems. Vol. 5384 of Lecture Notes in Computer Science", "citeRegEx": "Modgil and Luck,? \\Q2008\\E", "shortCiteRegEx": "Modgil and Luck", "year": 2008}, {"title": "A dynamic logic programming based system for agents with declarative goals", "author": ["V. Nigam", "J. Leite"], "venue": "International Workshop on Declarative Agent Languages and Technologies", "citeRegEx": "Nigam and Leite,? \\Q2006\\E", "shortCiteRegEx": "Nigam and Leite", "year": 2006}, {"title": "Coordination durative actions", "author": ["I. Nunes", "J.L. Fiadeiro", "W.M. Turski"], "venue": "International Conference on Coordination Languages and Models. Vol. 1282 of Lecture Notes in Computer Science", "citeRegEx": "Nunes et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Nunes et al\\.", "year": 1997}, {"title": "Understanding permissions through graphical norms", "author": ["N. Oren", "M. Croitoru", "S. Miles", "M. Luck"], "venue": "Declarative Agent Languages and Technologies", "citeRegEx": "Oren et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Oren et al\\.", "year": 2010}, {"title": "Acting on norm constrained plans", "author": ["N. Oren", "W. Vasconcelos", "F. Meneguzzi", "M. Luck"], "venue": "Computational Logic in Multi-Agent Systems. Vol. 6814 of Lecture Notes in Computer Science. Springer,", "citeRegEx": "Oren et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Oren et al\\.", "year": 2011}, {"title": "Reasoning over norm compliance via planning", "author": ["S. Panagiotidi", "J. V\u00e1zquez-Salceda", "F. Dignum"], "venue": "International Workshop on Coordination, Organizations, Institutions, and Norms in Agent Systems. Vol. 7756 of Lecture Notes in Computer Science", "citeRegEx": "Panagiotidi et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Panagiotidi et al\\.", "year": 2012}, {"title": "Contextual norm-based plan evaluation via answer set programming", "author": ["S. Panagiotidi", "J. V\u00e1zquez-Salceda", "W. Vasconcelos"], "venue": null, "citeRegEx": "Panagiotidi et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Panagiotidi et al\\.", "year": 2012}, {"title": "Formal models of social processes: The pursuit of computational justice in self-organising multiagent systems", "author": ["J. Pitt", "D. Busquets", "R. Riveret", "Sept"], "venue": "In: International Conference on Self-Adaptive and SelfOrganizing Systems. pp. 269\u2013270.", "citeRegEx": "Pitt et al\\.,? 2013", "shortCiteRegEx": "Pitt et al\\.", "year": 2013}, {"title": "A goal deliberation strategy for BDI agent systems", "author": ["A. Pokahr", "L. Braubach", "W. Lamersdorf"], "venue": "German Conference on Multiagent System Technologies. Vol. 3550 of Lecture Notes in Computer Science", "citeRegEx": "Pokahr et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Pokahr et al\\.", "year": 2005}, {"title": "An argumentation-based approach for practical reasoning", "author": ["I. Rahwan", "L. Amgoud"], "venue": "International Workshop on Argumentation in Multi-Agent Systems. Vol. 4766 of Lecture Notes in Computer Science", "citeRegEx": "Rahwan and Amgoud,? \\Q2006\\E", "shortCiteRegEx": "Rahwan and Amgoud", "year": 2006}, {"title": "BDI agents: From theory to practice", "author": ["A.S. Rao", "M.P. Georgeff"], "venue": "In: International Conference On Multi-Agent Systems", "citeRegEx": "Rao and Georgeff,? \\Q1995\\E", "shortCiteRegEx": "Rao and Georgeff", "year": 1995}, {"title": "Agent programming in dribble: From beliefs to goals with plans", "author": ["M.B. van Riemsdijk", "W. van der Hoek", "J.C. Meyer"], "venue": "Formal Approaches to Agent-Based Systems", "citeRegEx": "Riemsdijk et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Riemsdijk et al\\.", "year": 2002}, {"title": "Goals in agent", "author": ["M.B. van Riemsdijk", "M. Dastani", "M. Winikoff"], "venue": null, "citeRegEx": "Riemsdijk et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Riemsdijk et al\\.", "year": 2008}, {"title": "Goals in conflict", "author": ["M.B. van Riemsdijk", "M. Dastani", "J.C. Meyer"], "venue": "Agents and Multiagent Systems,", "citeRegEx": "Riemsdijk et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Riemsdijk et al\\.", "year": 2008}, {"title": "A generic approach to planning", "author": ["S.T. To", "T.C. Son", "E. Pontelli"], "venue": null, "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2015}, {"title": "Normative conflict resolution in multi-agent systems", "author": ["W.W. Vasconcelos", "M.J. Kollingbaum", "T.J. Norman"], "venue": "Autonomous Agents and MultiAgent Systems", "citeRegEx": "Vasconcelos et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Vasconcelos et al\\.", "year": 2009}], "referenceMentions": [{"referenceID": 20, "context": "When modelled as hard constraints, the agent subject to the norms is said to be regimented, in which case the agent has no choice but blindly to follow the norms (Esteva et al., 2001).", "startOffset": 162, "endOffset": 183}, {"referenceID": 49, "context": "However, in order to encourage norm compliance, there are consequences associated, namely a punishment when agents violate a norm (L\u00f3pez y L\u00f3pez et al., 2005; Pitt et al., 2013) or a reward when agents comply with a norm (Aldewereld et al.", "startOffset": 130, "endOffset": 177}, {"referenceID": 1, "context": ", 2013) or a reward when agents comply with a norm (Aldewereld et al., 2006).", "startOffset": 51, "endOffset": 76}, {"referenceID": 1, "context": ", (Aldewereld et al., 2006; Alrawagfeh and Meneguzzi, 2014; Oren et al., 2011)) there is a utility gain/loss associated with respecting norm or not, whereas in the pressured norm compliance approaches (e.", "startOffset": 2, "endOffset": 78}, {"referenceID": 3, "context": ", (Aldewereld et al., 2006; Alrawagfeh and Meneguzzi, 2014; Oren et al., 2011)) there is a utility gain/loss associated with respecting norm or not, whereas in the pressured norm compliance approaches (e.", "startOffset": 2, "endOffset": 78}, {"referenceID": 46, "context": ", (Aldewereld et al., 2006; Alrawagfeh and Meneguzzi, 2014; Oren et al., 2011)) there is a utility gain/loss associated with respecting norm or not, whereas in the pressured norm compliance approaches (e.", "startOffset": 2, "endOffset": 78}, {"referenceID": 46, "context": "(Oren et al., 2011; Panagiotidi et al., 2012a; Criado et al., 2010; Meneguzzi et al., 2015)) on normative practical reasoning using enforcement either consider plan generation or plan selection where there is a set of pre-generated plans available to the agent.", "startOffset": 0, "endOffset": 91}, {"referenceID": 14, "context": "(Oren et al., 2011; Panagiotidi et al., 2012a; Criado et al., 2010; Meneguzzi et al., 2015)) on normative practical reasoning using enforcement either consider plan generation or plan selection where there is a set of pre-generated plans available to the agent.", "startOffset": 0, "endOffset": 91}, {"referenceID": 41, "context": "(Oren et al., 2011; Panagiotidi et al., 2012a; Criado et al., 2010; Meneguzzi et al., 2015)) on normative practical reasoning using enforcement either consider plan generation or plan selection where there is a set of pre-generated plans available to the agent.", "startOffset": 0, "endOffset": 91}, {"referenceID": 1, "context": ", 2013) or a reward when agents comply with a norm (Aldewereld et al., 2006). In some approaches (e.g., (Aldewereld et al., 2006; Alrawagfeh and Meneguzzi, 2014; Oren et al., 2011)) there is a utility gain/loss associated with respecting norm or not, whereas in the pressured norm compliance approaches (e.g., (L\u00f3pez y L\u00f3pez et al., 2005)), the choice to violate a norm or not is determined by how the norm affects the satisfaction or hindrance of the agent\u2019s goals. Existing work (e.g. (Oren et al., 2011; Panagiotidi et al., 2012a; Criado et al., 2010; Meneguzzi et al., 2015)) on normative practical reasoning using enforcement either consider plan generation or plan selection where there is a set of pre-generated plans available to the agent. In these works, the attitude agents have toward norms is often one of compliance, meaning that their plans are often selected or, in some approaches, customised, to ensure norm compliance (e.g., Kollingbaum (2005); Alechina et al.", "startOffset": 52, "endOffset": 963}, {"referenceID": 1, "context": ", 2013) or a reward when agents comply with a norm (Aldewereld et al., 2006). In some approaches (e.g., (Aldewereld et al., 2006; Alrawagfeh and Meneguzzi, 2014; Oren et al., 2011)) there is a utility gain/loss associated with respecting norm or not, whereas in the pressured norm compliance approaches (e.g., (L\u00f3pez y L\u00f3pez et al., 2005)), the choice to violate a norm or not is determined by how the norm affects the satisfaction or hindrance of the agent\u2019s goals. Existing work (e.g. (Oren et al., 2011; Panagiotidi et al., 2012a; Criado et al., 2010; Meneguzzi et al., 2015)) on normative practical reasoning using enforcement either consider plan generation or plan selection where there is a set of pre-generated plans available to the agent. In these works, the attitude agents have toward norms is often one of compliance, meaning that their plans are often selected or, in some approaches, customised, to ensure norm compliance (e.g., Kollingbaum (2005); Alechina et al. (2012); Oren et al.", "startOffset": 52, "endOffset": 987}, {"referenceID": 1, "context": ", 2013) or a reward when agents comply with a norm (Aldewereld et al., 2006). In some approaches (e.g., (Aldewereld et al., 2006; Alrawagfeh and Meneguzzi, 2014; Oren et al., 2011)) there is a utility gain/loss associated with respecting norm or not, whereas in the pressured norm compliance approaches (e.g., (L\u00f3pez y L\u00f3pez et al., 2005)), the choice to violate a norm or not is determined by how the norm affects the satisfaction or hindrance of the agent\u2019s goals. Existing work (e.g. (Oren et al., 2011; Panagiotidi et al., 2012a; Criado et al., 2010; Meneguzzi et al., 2015)) on normative practical reasoning using enforcement either consider plan generation or plan selection where there is a set of pre-generated plans available to the agent. In these works, the attitude agents have toward norms is often one of compliance, meaning that their plans are often selected or, in some approaches, customised, to ensure norm compliance (e.g., Kollingbaum (2005); Alechina et al. (2012); Oren et al. (2011)).", "startOffset": 52, "endOffset": 1007}, {"referenceID": 46, "context": "We extend current work on normative plan generation such that the agent attempts to satisfy a set of potentially conflicting goals in the presence of norms, as opposed to conventional planning problems that generate plans for a single goal (Oren et al., 2011; Panagiotidi et al., 2012a).", "startOffset": 240, "endOffset": 286}, {"referenceID": 21, "context": "Such an extension is made on top of STRIPS (Fikes and Nilsson, 1971), the most established planning domain language that lays the foundation of many automated planning languages.", "startOffset": 43, "endOffset": 68}, {"referenceID": 26, "context": "Both plan generation and plan selection mechanisms proposed in this paper are implemented using Answer Set Programming (ASP) (Gelfond and Lifschitz, 1988).", "startOffset": 125, "endOffset": 154}, {"referenceID": 37, "context": "The existence of efficient solvers to generate the answers to the problems provided has increased the use of ASP in different domains of autonomous agents and multi-agent systems such as planning (Lifschitz, 2002) and normative reasoning (Cliffe et al.", "startOffset": 196, "endOffset": 213}, {"referenceID": 12, "context": "The existence of efficient solvers to generate the answers to the problems provided has increased the use of ASP in different domains of autonomous agents and multi-agent systems such as planning (Lifschitz, 2002) and normative reasoning (Cliffe et al., 2006; Panagiotidi et al., 2012b).", "startOffset": 238, "endOffset": 286}, {"referenceID": 18, "context": "Several action and planning languages such as event calculus (Kowalski and Sergot, 1986), A (and its descendants B and C (Gelfond and Lifschitz, 1998), Temporal Action Logics (TAL) (Doherty et al., 1998), have been implemented in ASP (Lee and Palla, 2012, 2014), indicating that ASP is appropriate for reasoning about actions.", "startOffset": 181, "endOffset": 203}, {"referenceID": 21, "context": "This provides motive and justification for an implementation of STRIPS (Fikes and Nilsson, 1971) that serves as the foundation of our model in ASP.", "startOffset": 71, "endOffset": 96}, {"referenceID": 21, "context": "A Model for Normative Practical Reasoning In this research, we take STRIPS (Fikes and Nilsson, 1971) as the basis of our normative practical reasoning model.", "startOffset": 75, "endOffset": 100}, {"referenceID": 44, "context": "to capture the features of the normative practical reasoning problem that we are going to model, we extend the classical planning problem by: (i) replacing atomic actions with durative actions: often the nature of the actions is non-atomic, which means that although executed atomically in a state, the system state in which they finish executing is not necessarily the same in which they started (Nunes et al., 1997).", "startOffset": 397, "endOffset": 417}, {"referenceID": 8, "context": "Refinement of atomic actions to durative actions reflects the real time that a machine takes to execute certain actions, which is also known as \u201creal-time duration\u201d of actions (B\u00f6rger and St\u00e4rk, 2003).", "startOffset": 176, "endOffset": 200}, {"referenceID": 30, "context": "Some approaches take the view that it is sufficient for the preconditions of the action to hold at the start state and it does not matter whether they hold while the action is in progress (Knoblock, 1994), whereas others hold the view that the preconditions of an action should be satisfied while the action is in progress (Blum and Furst, 1997).", "startOffset": 188, "endOffset": 204}, {"referenceID": 6, "context": "Some approaches take the view that it is sufficient for the preconditions of the action to hold at the start state and it does not matter whether they hold while the action is in progress (Knoblock, 1994), whereas others hold the view that the preconditions of an action should be satisfied while the action is in progress (Blum and Furst, 1997).", "startOffset": 323, "endOffset": 345}, {"referenceID": 23, "context": "Moreover, some planning languages, such as Planning Domain Description Language (PDDL) (Garrido et al., 2002; Fox and Long, 2003), distinguish between preconditions and those conditions that have to hold while the action is in progress.", "startOffset": 87, "endOffset": 129}, {"referenceID": 22, "context": "Moreover, some planning languages, such as Planning Domain Description Language (PDDL) (Garrido et al., 2002; Fox and Long, 2003), distinguish between preconditions and those conditions that have to hold while the action is in progress.", "startOffset": 87, "endOffset": 129}, {"referenceID": 43, "context": "Achievement goals are the most common type of goals modelled in the agent literature and have therefore received the most attention (van Riemsdijk et al., 2008; de Boer et al., 2002; Nigam and Leite, 2006; van Riemsdijk et al., 2002).", "startOffset": 132, "endOffset": 233}, {"referenceID": 13, "context": "In order to provide a context for the norm specification we explain how our norm specification corresponds to the five elements identified by Criado (2012) that distinguish norm specification languages.", "startOffset": 142, "endOffset": 156}, {"referenceID": 44, "context": ", Oren et al. (2011); Panagiotidi et al.", "startOffset": 2, "endOffset": 21}, {"referenceID": 44, "context": ", Oren et al. (2011); Panagiotidi et al. (2012a)) and pressure-based (L\u00f3pez y L\u00f3pez et al.", "startOffset": 2, "endOffset": 49}, {"referenceID": 6, "context": "Blum and Furst (1997) define that two actions ai and aj cannot be executed concurrently, if at least one of the following holds: 1.", "startOffset": 0, "endOffset": 22}, {"referenceID": 43, "context": "An agent may pursue multiple goals or desires at the same time and it is likely that some of these goals conflict (van Riemsdijk et al., 2002; Nigam and Leite, 2006; Pokahr et al., 2005; Thangarajah et al., 2003; van Riemsdijk et al., 2009).", "startOffset": 114, "endOffset": 240}, {"referenceID": 50, "context": "An agent may pursue multiple goals or desires at the same time and it is likely that some of these goals conflict (van Riemsdijk et al., 2002; Nigam and Leite, 2006; Pokahr et al., 2005; Thangarajah et al., 2003; van Riemsdijk et al., 2009).", "startOffset": 114, "endOffset": 240}, {"referenceID": 39, "context": ", 2002; Nigam and Leite, 2006; Pokahr et al., 2005; Thangarajah et al., 2003; van Riemsdijk et al., 2009). Conflict between the agent\u2019s goals or desires, especially for BDI agents, has been addressed by several authors. Hulstijn and van der Torre (2004) describe two goals as conflicting if achieving them requires taking two conflicting actions, where conflicting actions are encoded using integrity constraints.", "startOffset": 8, "endOffset": 254}, {"referenceID": 39, "context": ", 2002; Nigam and Leite, 2006; Pokahr et al., 2005; Thangarajah et al., 2003; van Riemsdijk et al., 2009). Conflict between the agent\u2019s goals or desires, especially for BDI agents, has been addressed by several authors. Hulstijn and van der Torre (2004) describe two goals as conflicting if achieving them requires taking two conflicting actions, where conflicting actions are encoded using integrity constraints. Rahwan and Amgoud (2006) on the other hand, define two desires as conflicting if the sets of beliefs that supports the achievement of desires are contradictory.", "startOffset": 8, "endOffset": 439}, {"referenceID": 39, "context": ", 2002; Nigam and Leite, 2006; Pokahr et al., 2005; Thangarajah et al., 2003; van Riemsdijk et al., 2009). Conflict between the agent\u2019s goals or desires, especially for BDI agents, has been addressed by several authors. Hulstijn and van der Torre (2004) describe two goals as conflicting if achieving them requires taking two conflicting actions, where conflicting actions are encoded using integrity constraints. Rahwan and Amgoud (2006) on the other hand, define two desires as conflicting if the sets of beliefs that supports the achievement of desires are contradictory. Like Rahwan and Amgoud (2006), Broersen et al.", "startOffset": 8, "endOffset": 605}, {"referenceID": 9, "context": "Like Rahwan and Amgoud (2006), Broersen et al. (2002) argue that for a set of goals not to be conflicting, a consistent mental attitude (e.", "startOffset": 31, "endOffset": 54}, {"referenceID": 9, "context": "Like Rahwan and Amgoud (2006), Broersen et al. (2002) argue that for a set of goals not to be conflicting, a consistent mental attitude (e.g. beliefs and norms) is required. Some (e.g., (Toniolo, 2013)) have adopted a static view on goal conflict, in which conflicting goals are mutually-exclusive, hence impossible to satisfy in the same plan regardless of the order or choice of actions in the plan. Limited and bounded resources (e.g. time, budget, etc.) are debated as another cause of conflict between goals (Thangarajah et al., 2002). L\u00f3pez y L\u00f3pez et al. (2005) discuss conflict between goals and norms in terms of goals being hindered by norms or vice-versa.", "startOffset": 31, "endOffset": 569}, {"referenceID": 9, "context": "Like Rahwan and Amgoud (2006), Broersen et al. (2002) argue that for a set of goals not to be conflicting, a consistent mental attitude (e.g. beliefs and norms) is required. Some (e.g., (Toniolo, 2013)) have adopted a static view on goal conflict, in which conflicting goals are mutually-exclusive, hence impossible to satisfy in the same plan regardless of the order or choice of actions in the plan. Limited and bounded resources (e.g. time, budget, etc.) are debated as another cause of conflict between goals (Thangarajah et al., 2002). L\u00f3pez y L\u00f3pez et al. (2005) discuss conflict between goals and norms in terms of goals being hindered by norms or vice-versa. The same applies to the approach offered by Modgil and Luck (2008), suggesting a mechanism to resolve the conflicts between desires and normative goals.", "startOffset": 31, "endOffset": 734}, {"referenceID": 57, "context": ", Vasconcelos et al. (2009)) as well as other domains such as legal reasoning (e.", "startOffset": 2, "endOffset": 28}, {"referenceID": 57, "context": ", Vasconcelos et al. (2009)) as well as other domains such as legal reasoning (e.g., (Sartor, 1992)). When faced with conflicting norms, the agent cannot comply with both of them and hence one of the norms is violated. In terms of action-based norms, Shams et al. (2015) define two obligations conflicting if they oblige the agent to take two conflicting actions (cf.", "startOffset": 2, "endOffset": 271}, {"referenceID": 26, "context": "We use Answer Set Programming (ASP) (Gelfond and Lifschitz, 1988) to propose such an implementation.", "startOffset": 36, "endOffset": 65}, {"referenceID": 3, "context": "The Event Calculus (EC) (Kowalski and Sergot, 1986) forms the basis for the implementation of some normative reasoning frameworks, such as those of Alrawagfeh and Meneguzzi (2014) and Artikis et al.", "startOffset": 148, "endOffset": 180}, {"referenceID": 3, "context": "The Event Calculus (EC) (Kowalski and Sergot, 1986) forms the basis for the implementation of some normative reasoning frameworks, such as those of Alrawagfeh and Meneguzzi (2014) and Artikis et al. (2009). Our proposed formal model is independent of language and could be translated to EC and hence to a computational model.", "startOffset": 148, "endOffset": 206}, {"referenceID": 38, "context": "Answer Set Programming ASP is a declarative programming paradigm using logic programs under Answer Set semantics (Lifschitz, 2008).", "startOffset": 113, "endOffset": 130}, {"referenceID": 5, "context": "A variety of programming languages for ASP exist, and we use AnsProlog (Baral, 2003).", "startOffset": 71, "endOffset": 84}, {"referenceID": 25, "context": "There are several efficient solvers for AnsProlog, of which Clingo (Gebser et al., 2011) and DLV (Eiter et al.", "startOffset": 67, "endOffset": 88}, {"referenceID": 19, "context": ", 2011) and DLV (Eiter et al., 1999) are currently the most widely used.", "startOffset": 16, "endOffset": 36}, {"referenceID": 5, "context": "A variety of programming languages for ASP exist, and we use AnsProlog (Baral, 2003). There are several efficient solvers for AnsProlog, of which Clingo (Gebser et al., 2011) and DLV (Eiter et al., 1999) are currently the most widely used. The basic components of AnsProlog are atoms that are constructs to which one can assign a truth value. An atom can be negated, adopting negation as failure (naf), which establishes that a negated atom not a is true if there is no evidence to prove a. Literals are atoms a or negated atoms not a (referred to as naf-literals). Atoms and literals are used to create rules of the general form \u201ca :\u2212 b1, ..., bm, not c1, ..., not cn.\u201d where a, bi and cj are atoms. Intuitively, a rule means that if all atoms bi are known/true and no atom cj is known/true, then a must be known/true. We refer to a as the head of the rule and b1, ..., bm, not c1, ..., not cn as the body of the rule. A rule with an empty body is called a fact and a rule with an empty head is called a constraint, indicating that no solution should be able to satisfy the body. Another type of rules are called choice rules and are denoted as l{h0, \u00b7 \u00b7 \u00b7 , hk}u : \u2212 l1, \u00b7 \u00b7 \u00b7 , lm, not lm+1, \u00b7 \u00b7 \u00b7 , not ln., in which his and lis are atoms. l and u are integers and the default values for them are 0 and 1, respectively. A choice rule is satisfied if the number of atoms belonging to {h0, \u00b7 \u00b7 \u00b7 , hk} that are true/known is between the lower bound l and upper bound u. A program is a set of rules representing their conjunction. The semantics of AnsProlog is defined in terms of answer sets, i.e. assignments of true and false to all atoms in the program that satisfy the rules in a minimal and consistent fashion. A program may have zero or more answer sets, each corresponding to a solution. We refer to Appendix D and Baral (2003) for a formal treatment of the semantics of ASP.", "startOffset": 72, "endOffset": 1837}, {"referenceID": 25, "context": "We plan to automate this using incremental features of ASP solver clingo4 (Gebser et al., 2011).", "startOffset": 74, "endOffset": 95}, {"referenceID": 6, "context": "Following the approach in Blum and Furst (1997), we assume that the preconditions of a durative action should be preserved when it is in progress.", "startOffset": 26, "endOffset": 48}, {"referenceID": 52, "context": "BDI Architectures with Normative Reasoning There is a substantial body of work on the integration of norms into the BDI architecture (Rao and Georgeff, 1995), but motivation, theory and practice vary substantially.", "startOffset": 133, "endOffset": 157}, {"referenceID": 9, "context": "The BOID architecture (Broersen et al., 2001) extends BDI with the concept of obligation and uses agent types such as social, selfish, etc.", "startOffset": 22, "endOffset": 45}, {"referenceID": 31, "context": "NoA (Kollingbaum, 2005) is a normative language and agent architecture.", "startOffset": 4, "endOffset": 23}, {"referenceID": 41, "context": "\u03bd-BDI (Meneguzzi et al., 2015) enables BDI agents to perform normative reasoning for the purpose of customising pre-existing plans that ensure compliance with the set of norms imposed on the agent.", "startOffset": 6, "endOffset": 30}, {"referenceID": 2, "context": "N-2APL (Alechina et al., 2012) is a norm-aware agent programming language based on 2APL (Dastani, 2008) that supports representation of and reasoning about beliefs, goals, plans, norms, sanctions and deadlines.", "startOffset": 7, "endOffset": 30}, {"referenceID": 15, "context": ", 2012) is a norm-aware agent programming language based on 2APL (Dastani, 2008) that supports representation of and reasoning about beliefs, goals, plans, norms, sanctions and deadlines.", "startOffset": 65, "endOffset": 80}, {"referenceID": 34, "context": "N-Jason (Lee et al., 2014) sets out an extension of the Jason (Bordini et al.", "startOffset": 8, "endOffset": 26}, {"referenceID": 7, "context": ", 2014) sets out an extension of the Jason (Bordini et al., 2007) variant of the BDI architecture to account for norms in plan selection and to handle priorities in plan scheduling.", "startOffset": 43, "endOffset": 65}, {"referenceID": 22, "context": "1 (Fox and Long, 2003).", "startOffset": 2, "endOffset": 22}, {"referenceID": 27, "context": "The normative state of the agent is checked, using the planning tool MetricFF (Hoffmann and Nebel, 2001), after each individual action; then the planner decides if the agent should comply with a norm or not based on a linear cost function specified in terms of constraints on the states achieved during each plan.", "startOffset": 78, "endOffset": 104}, {"referenceID": 42, "context": "Oren et al. (2011) do utilise a pre-generated plan, like the list above, but take norms into consideration when deciding how to execute the plan with respect to the norms triggered by that plan.", "startOffset": 0, "endOffset": 19}, {"referenceID": 42, "context": "Oren et al. (2011) do utilise a pre-generated plan, like the list above, but take norms into consideration when deciding how to execute the plan with respect to the norms triggered by that plan. Specifically, the approach aims to adjust the chosen plan to account for the norms that govern the plan actions at each point in time, where the norm expresses constraints on the values that can be assigned to variables in a plan action. The adjustments of values in actions specify how the agent should execute a plan, such that the cost of violated norms is outweighed by the reward from norm compliance. The most preferred plan is therefore the one that maximises this metric. Panagiotidi et al. (2012a) take norms into account in plan generation where the planning problem is specified in PDDL 2.", "startOffset": 0, "endOffset": 702}, {"referenceID": 22, "context": "1 (Fox and Long, 2003). The normative state of the agent is checked, using the planning tool MetricFF (Hoffmann and Nebel, 2001), after each individual action; then the planner decides if the agent should comply with a norm or not based on a linear cost function specified in terms of constraints on the states achieved during each plan. Although this mechanism enables an agent to cope with the dynamics of operating in an open environment, checking the normative position of an agent after each action imposes a high computational cost on the plan generation phase. Shams et al. (2015) define an approach to practical reasoning that considers norms in both plan generation and plan selection.", "startOffset": 3, "endOffset": 588}, {"referenceID": 22, "context": "1 (Fox and Long, 2003). The normative state of the agent is checked, using the planning tool MetricFF (Hoffmann and Nebel, 2001), after each individual action; then the planner decides if the agent should comply with a norm or not based on a linear cost function specified in terms of constraints on the states achieved during each plan. Although this mechanism enables an agent to cope with the dynamics of operating in an open environment, checking the normative position of an agent after each action imposes a high computational cost on the plan generation phase. Shams et al. (2015) define an approach to practical reasoning that considers norms in both plan generation and plan selection. The agent attempts to satisfy a set of potentially conflicting goals in the presence of norms, as opposed to conventional planning problems that generate plans for a single goal. The main contributions of Shams et al. (2015) are (i) the introduction of an enforcement approach that is a combination of utility-based and pressure-based compliance methods (L\u00f3pez y L\u00f3pez et al.", "startOffset": 3, "endOffset": 920}, {"referenceID": 31, "context": ", NoA (Kollingbaum, 2005)), which is a one-off process, that may fail delivering the best (where \u201cbest\u201d can be defined in various ways) plan available for the situation from those available, and which requires starting again when a plan step fails and the remainder of the plan is invalidated.", "startOffset": 6, "endOffset": 25}, {"referenceID": 46, "context": ", (Oren et al., 2011)) is potentially more flexible in making use of available plans (also helping customize existing plans into optimal norm-compliant plans), but otherwise has the same replanning drawback.", "startOffset": 2, "endOffset": 21}, {"referenceID": 31, "context": ", NoA (Kollingbaum, 2005)), which is a one-off process, that may fail delivering the best (where \u201cbest\u201d can be defined in various ways) plan available for the situation from those available, and which requires starting again when a plan step fails and the remainder of the plan is invalidated. The main points of difference between NoA and the work presented here are that (i) NoA agents are BDI specific, (ii) they do not have internal motivations such as goals or values that might conflict with norms, which therefore enables the NoA agent to always comply with norms (iii) plans are pre-existing rather than generated. 2. Customising a plan to make it norm compliant (e.g., (Oren et al., 2011)) is potentially more flexible in making use of available plans (also helping customize existing plans into optimal norm-compliant plans), but otherwise has the same replanning drawback. In common with Oren et al. (2011), we use the utility of the entire plan in the selection process, but differ in that we generate plans rather than use plans from a library.", "startOffset": 7, "endOffset": 918}, {"referenceID": 31, "context": ", NoA (Kollingbaum, 2005)), which is a one-off process, that may fail delivering the best (where \u201cbest\u201d can be defined in various ways) plan available for the situation from those available, and which requires starting again when a plan step fails and the remainder of the plan is invalidated. The main points of difference between NoA and the work presented here are that (i) NoA agents are BDI specific, (ii) they do not have internal motivations such as goals or values that might conflict with norms, which therefore enables the NoA agent to always comply with norms (iii) plans are pre-existing rather than generated. 2. Customising a plan to make it norm compliant (e.g., (Oren et al., 2011)) is potentially more flexible in making use of available plans (also helping customize existing plans into optimal norm-compliant plans), but otherwise has the same replanning drawback. In common with Oren et al. (2011), we use the utility of the entire plan in the selection process, but differ in that we generate plans rather than use plans from a library. 3. Generating a plan that is norm compliant (e.g., (Panagiotidi et al., 2012a; Shams et al., 2015)). The former addresses on-going compliance and re-planning, putting a high computational overhead on each plan step. Of necessity, Panagiotidi et al. (2012a) can only compute utility on a step-by-step basis, whereas we consider the utility of the whole plan.", "startOffset": 7, "endOffset": 1315}, {"referenceID": 31, "context": ", NoA (Kollingbaum, 2005)), which is a one-off process, that may fail delivering the best (where \u201cbest\u201d can be defined in various ways) plan available for the situation from those available, and which requires starting again when a plan step fails and the remainder of the plan is invalidated. The main points of difference between NoA and the work presented here are that (i) NoA agents are BDI specific, (ii) they do not have internal motivations such as goals or values that might conflict with norms, which therefore enables the NoA agent to always comply with norms (iii) plans are pre-existing rather than generated. 2. Customising a plan to make it norm compliant (e.g., (Oren et al., 2011)) is potentially more flexible in making use of available plans (also helping customize existing plans into optimal norm-compliant plans), but otherwise has the same replanning drawback. In common with Oren et al. (2011), we use the utility of the entire plan in the selection process, but differ in that we generate plans rather than use plans from a library. 3. Generating a plan that is norm compliant (e.g., (Panagiotidi et al., 2012a; Shams et al., 2015)). The former addresses on-going compliance and re-planning, putting a high computational overhead on each plan step. Of necessity, Panagiotidi et al. (2012a) can only compute utility on a step-by-step basis, whereas we consider the utility of the whole plan. Shams et al. (2015) attempt to balance compliance on the part of the agent (where the agent chooses a norm-compliant action in preference) with enforcement (where the agent is discouraged from non-norm-compliance via punishments for norm violation), but is not robust to plan failure.", "startOffset": 7, "endOffset": 1436}, {"referenceID": 31, "context": ", NoA (Kollingbaum, 2005)), which is a one-off process, that may fail delivering the best (where \u201cbest\u201d can be defined in various ways) plan available for the situation from those available, and which requires starting again when a plan step fails and the remainder of the plan is invalidated. The main points of difference between NoA and the work presented here are that (i) NoA agents are BDI specific, (ii) they do not have internal motivations such as goals or values that might conflict with norms, which therefore enables the NoA agent to always comply with norms (iii) plans are pre-existing rather than generated. 2. Customising a plan to make it norm compliant (e.g., (Oren et al., 2011)) is potentially more flexible in making use of available plans (also helping customize existing plans into optimal norm-compliant plans), but otherwise has the same replanning drawback. In common with Oren et al. (2011), we use the utility of the entire plan in the selection process, but differ in that we generate plans rather than use plans from a library. 3. Generating a plan that is norm compliant (e.g., (Panagiotidi et al., 2012a; Shams et al., 2015)). The former addresses on-going compliance and re-planning, putting a high computational overhead on each plan step. Of necessity, Panagiotidi et al. (2012a) can only compute utility on a step-by-step basis, whereas we consider the utility of the whole plan. Shams et al. (2015) attempt to balance compliance on the part of the agent (where the agent chooses a norm-compliant action in preference) with enforcement (where the agent is discouraged from non-norm-compliance via punishments for norm violation), but is not robust to plan failure. Furthermore, in Shams et al. (2015), conflict is formulated in advance by taking a static view about conflicts.", "startOffset": 7, "endOffset": 1737}, {"referenceID": 9, "context": "BOID (Broersen et al., 2001) o N/A N/A NoA (Kollingbaum, 2005) o, f, p state, action state, action \u03bd-BDI (Meneguzzi et al.", "startOffset": 5, "endOffset": 28}, {"referenceID": 31, "context": ", 2001) o N/A N/A NoA (Kollingbaum, 2005) o, f, p state, action state, action \u03bd-BDI (Meneguzzi et al.", "startOffset": 22, "endOffset": 41}, {"referenceID": 41, "context": ", 2001) o N/A N/A NoA (Kollingbaum, 2005) o, f, p state, action state, action \u03bd-BDI (Meneguzzi et al., 2015) o, f state state N-2APL (Alechina et al.", "startOffset": 84, "endOffset": 108}, {"referenceID": 2, "context": ", 2015) o, f state state N-2APL (Alechina et al., 2012) o, f state state3 N-Jason (Lee et al.", "startOffset": 32, "endOffset": 55}, {"referenceID": 34, "context": ", 2012) o, f state state3 N-Jason (Lee et al., 2014) o, p, w4 N/A temporal constraint Oren et al.", "startOffset": 34, "endOffset": 52}, {"referenceID": 2, "context": ", 2015) o, f state state N-2APL (Alechina et al., 2012) o, f state state3 N-Jason (Lee et al., 2014) o, p, w4 N/A temporal constraint Oren et al. (2011) o, f N/A N/A Panagiotidi et al.", "startOffset": 33, "endOffset": 153}, {"referenceID": 2, "context": ", 2015) o, f state state N-2APL (Alechina et al., 2012) o, f state state3 N-Jason (Lee et al., 2014) o, p, w4 N/A temporal constraint Oren et al. (2011) o, f N/A N/A Panagiotidi et al. (2012a) o, f state state Shams et al.", "startOffset": 33, "endOffset": 193}, {"referenceID": 2, "context": ", 2015) o, f state state N-2APL (Alechina et al., 2012) o, f state state3 N-Jason (Lee et al., 2014) o, p, w4 N/A temporal constraint Oren et al. (2011) o, f N/A N/A Panagiotidi et al. (2012a) o, f state state Shams et al. (2015) o, f action temporal constraint This work o, f action temporal constraint", "startOffset": 33, "endOffset": 230}, {"referenceID": 11, "context": "5, associating a deadline with temporal properties is considered to be realistic and dynamic, in particular when the norms capture the requirements of realworld scenarios (Chesani et al., 2013; Kafali et al., 2014; Gasparini et al., 2015), such as the disaster scenario we have modelled in this paper.", "startOffset": 171, "endOffset": 238}, {"referenceID": 29, "context": "5, associating a deadline with temporal properties is considered to be realistic and dynamic, in particular when the norms capture the requirements of realworld scenarios (Chesani et al., 2013; Kafali et al., 2014; Gasparini et al., 2015), such as the disaster scenario we have modelled in this paper.", "startOffset": 171, "endOffset": 238}, {"referenceID": 24, "context": "5, associating a deadline with temporal properties is considered to be realistic and dynamic, in particular when the norms capture the requirements of realworld scenarios (Chesani et al., 2013; Kafali et al., 2014; Gasparini et al., 2015), such as the disaster scenario we have modelled in this paper.", "startOffset": 171, "endOffset": 238}, {"referenceID": 9, "context": ", (Broersen et al., 2001; Kollingbaum, 2005; Meneguzzi et al., 2015)).", "startOffset": 2, "endOffset": 68}, {"referenceID": 31, "context": ", (Broersen et al., 2001; Kollingbaum, 2005; Meneguzzi et al., 2015)).", "startOffset": 2, "endOffset": 68}, {"referenceID": 41, "context": ", (Broersen et al., 2001; Kollingbaum, 2005; Meneguzzi et al., 2015)).", "startOffset": 2, "endOffset": 68}, {"referenceID": 31, "context": ", (Kollingbaum, 2005; Alechina et al., 2012; Oren et al., 2011)).", "startOffset": 2, "endOffset": 63}, {"referenceID": 2, "context": ", (Kollingbaum, 2005; Alechina et al., 2012; Oren et al., 2011)).", "startOffset": 2, "endOffset": 63}, {"referenceID": 46, "context": ", (Kollingbaum, 2005; Alechina et al., 2012; Oren et al., 2011)).", "startOffset": 2, "endOffset": 63}, {"referenceID": 3, "context": "It is also used as a means to handle the uncertainty and incompleteness of the knowledge of the environment the agents operate in (Alrawagfeh and Meneguzzi, 2014).", "startOffset": 130, "endOffset": 162}, {"referenceID": 0, "context": "\u00c5gotnes et al. (2007)).", "startOffset": 0, "endOffset": 22}, {"referenceID": 0, "context": "\u00c5gotnes et al. (2007)). Another possibility to explore in a multi-agent setting is to infer conflicts between goals, between norms and between goals and norms by analysing the overall set of possible plans. The inferred conflicts can guide the process of re-engineering of the system toward a more social and norm compliant system (e.g. (Savarimuthu et al., 2013)). We note the relative limitations of our norm representation. Although our approach addressed action-based norms, we envisage how it can be extended and adapted to handle state-based norms. Our Def. 4 needs to cater for formulae to represent both the norm activation condition, acon, and the norm subject, asub, instead of actions. A combination of action- and statebased norms (e.g. De Vos et al. (2013)) enriches the norm representation as well as normative reasoning.", "startOffset": 0, "endOffset": 770}, {"referenceID": 0, "context": "\u00c5gotnes et al. (2007)). Another possibility to explore in a multi-agent setting is to infer conflicts between goals, between norms and between goals and norms by analysing the overall set of possible plans. The inferred conflicts can guide the process of re-engineering of the system toward a more social and norm compliant system (e.g. (Savarimuthu et al., 2013)). We note the relative limitations of our norm representation. Although our approach addressed action-based norms, we envisage how it can be extended and adapted to handle state-based norms. Our Def. 4 needs to cater for formulae to represent both the norm activation condition, acon, and the norm subject, asub, instead of actions. A combination of action- and statebased norms (e.g. De Vos et al. (2013)) enriches the norm representation as well as normative reasoning. Also, the norm representation language can be extended to cater for deadlines that are expressed as reaching a state rather than a time instance. For instance, an obligation to open a dam on a river can come in force when the water level is above a certain point, and subsequently terminated when the water level drops below a certain level, regardless of how long it takes for that to happen. We would also like to include permission norms in addition to obligations and prohibitions. The modelling of permissions as exceptions to obligations and prohibitions has been used to justify violations under specific circumstances, (e.g. Oren et al. (2010); Criado (2012)).", "startOffset": 0, "endOffset": 1488}, {"referenceID": 0, "context": "\u00c5gotnes et al. (2007)). Another possibility to explore in a multi-agent setting is to infer conflicts between goals, between norms and between goals and norms by analysing the overall set of possible plans. The inferred conflicts can guide the process of re-engineering of the system toward a more social and norm compliant system (e.g. (Savarimuthu et al., 2013)). We note the relative limitations of our norm representation. Although our approach addressed action-based norms, we envisage how it can be extended and adapted to handle state-based norms. Our Def. 4 needs to cater for formulae to represent both the norm activation condition, acon, and the norm subject, asub, instead of actions. A combination of action- and statebased norms (e.g. De Vos et al. (2013)) enriches the norm representation as well as normative reasoning. Also, the norm representation language can be extended to cater for deadlines that are expressed as reaching a state rather than a time instance. For instance, an obligation to open a dam on a river can come in force when the water level is above a certain point, and subsequently terminated when the water level drops below a certain level, regardless of how long it takes for that to happen. We would also like to include permission norms in addition to obligations and prohibitions. The modelling of permissions as exceptions to obligations and prohibitions has been used to justify violations under specific circumstances, (e.g. Oren et al. (2010); Criado (2012)).", "startOffset": 0, "endOffset": 1503}, {"referenceID": 5, "context": "and it has the following elements (Baral, 2003): Term: A term is a constant or a variable or a n-ary function f(t1, \u00b7 \u00b7 \u00b7 , tn), where f is the function symbol and t1, \u00b7 \u00b7 \u00b7 , tn are terms.", "startOffset": 34, "endOffset": 47}, {"referenceID": 26, "context": "This transformation is referred to as Gelfond-Lifschitz (Gelfond and Lifschitz, 1988) transformation.", "startOffset": 56, "endOffset": 85}, {"referenceID": 26, "context": "Gelfond-Lifschitz (Gelfond and Lifschitz, 1988) transformation \u03a0 is obtained by deleting: 1.", "startOffset": 18, "endOffset": 47}, {"referenceID": 33, "context": "The transformation (reduct) of choice rules was not a part of original GelfondLifschitz transformation and was introduced later in (Lee et al., 2008).", "startOffset": 131, "endOffset": 149}, {"referenceID": 26, "context": "Gelfond-Lifschitz (Gelfond and Lifschitz, 1988) transformation \u03a0 is obtained by deleting: 1. each rule that has a not L in its body with L \u2208 S, and 2. literals of form not L in the bodies of the remaining rules. The transformation (reduct) of choice rules was not a part of original GelfondLifschitz transformation and was introduced later in (Lee et al., 2008). Recently a simplified reduct for programs including choice rules is proposed by Mark Law and Broda (2015) as follows.", "startOffset": 19, "endOffset": 469}], "year": 2017, "abstractText": "Autonomous software agents operating in dynamic environments need to constantly reason about actions in pursuit of their goals, while taking into consideration norms which might be imposed on those actions. Normative practical reasoning supports agents making decisions about what is best for them to (not) do in a given situation. What makes practical reasoning challenging is the interplay between goals that agents are pursuing and the norms that the agents are trying to uphold. We offer a formalisation to allow agents to plan for multiple goals and norms in the presence of durative actions that can be executed concurrently. We compare plans based on decision-theoretic notions (i.e. utility) such that the utility gain of goals and utility loss of norm violations are the basis for this comparison. The set of optimal plans consists of plans that maximise the overall utility, each of which can be chosen by the agent to execute. We provide an implementation of our proposal in Answer Set Programming, thus allowing us to state the original problem in terms of a logic program that can be queried for solutions with specific properties. The implementation is proven to be sound and complete.", "creator": "LaTeX with hyperref package"}}}