{"id": "1701.08533", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Jan-2017", "title": "Graph-Based Semi-Supervised Conditional Random Fields For Spoken Language Understanding Using Unaligned Data", "abstract": "We experiment graph-based Semi-Supervised Learning (SSL) of Conditional Random Fields (CRF) for the application of Spoken Language Understanding (SLU) on unaligned data. The aligned labels for examples are obtained using IBM Model. We adapt a baseline semi-supervised CRF by defining new feature set and altering the label propagation algorithm. Our results demonstrate that our proposed approach significantly improves the performance of the supervised model by utilizing the knowledge gained from the graph.", "histories": [["v1", "Mon, 30 Jan 2017 10:28:49 GMT  (411kb)", "http://arxiv.org/abs/1701.08533v1", "Workshop of The Australasian Language Technology Association"]], "COMMENTS": "Workshop of The Australasian Language Technology Association", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["mohammad aliannejadi", "masoud kiaeeha", "shahram khadivi", "saeed shiry ghidary"], "accepted": false, "id": "1701.08533"}, "pdf": {"name": "1701.08533.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Shahram Khadivi"], "emails": ["m.aliannejadi@aut.ac.ir", "kiaeeha@ce.sharif.edu", "shiry}@aut.ac.ir"], "sections": [{"heading": null, "text": "ar Xiv: 170 1.08 533v 1 [cs.C L] 30 Jan 2017"}, {"heading": "1 Introduction", "text": "In fact, most of them are able to decide for themselves what they want."}, {"heading": "2 Semi-supervised Spoken Language Understanding", "text": "The input data is not aligned and is presented as a semantic tree, as described in He and Young, 2005. Training sets and associated semantic trees can be monotonously aligned, so we chose IBM Model 5 (Khadivi and Ney, 2005) to find the best alignment between the words and nodes of the semantic tree (label), thus avoiding the problem of unaligned data. A more detailed explanation of this process can be found in our previous paper (Aliannejadi et al., 2014), which is then used to train the monitored and semi-monitored CRFs."}, {"heading": "2.1 Semi-supervised CRF", "text": "The proposed Semi-Supervised Learning algorithm is based on (Subramanya et al., 2010). Here we quickly follow this algorithm (algorithm 1). In the first step, the CRF model is rendered according to (1): (n = 0) = Argmin (RK) 2: G = BuildGraph (Dl) 3: (r) = CalcEmpiricalDistribution (Dl) 4: While not converging 5: {m) = CalcMarginals (Du, n) 6: {q} = AverageMarginals (m) 7: {q} = LabelPropagation (r, r) 8: Dvu = Vitaminals (R)."}, {"heading": "2.2 CRF Features", "text": "By aligning the training data, many informative labels are stored that are omitted in other work (Wang and Acero, 2006; Raymond and Riccardi, 2007). By storing this information, dependence on first-order labels helps the model predict the labels more accurately. Thus, the model succeeds in predicting labels with less lexical features, and the feature window that was in previous work [-4, + 2] is reduced to [0, + 2]."}, {"heading": "2.3 Similarity Graph", "text": "In our work, we considered trigrams as nodes of the graph and extracted characteristics of each trigram x2 x3 x4 according to the 5-word context x1 x2 x3 x4 x5 in which it appears. These characteristics are carefully selected so that nodes are placed correctly in the neighborhood of those that have similar names. Table 1 presents the characteristic set we used to construct the similarity graph. IsClass characteristic significantly affects the structure of the graph. In pre-processing, phase-specific words are marked as classes according to the corresponding database of the corpus. As an example, city names such as Dallas and Baltimore are presented as city names that are a class type. As these classes play an important role in calculating the similarity of the nodes, IsClass characteristic is used to determine whether a given position in a context is a class type. In addition, prepositions such as \"between Dallas,\" for example, \"between two and Washington\" are important. \""}, {"heading": "2.4 Label Propagation", "text": "The use of traditional label distribution algorithms causes an error spread over the entire graph and impairs the performance of the entire system. Therefore, we use the Modified Adsorption (MAD) algorithm for label propagation. The MAD algorithm controls the label propagation more strictly by limiting the amount of information that can be obtained from one node to another (Talukdar and Pereira, 2010). Soft label distribution vectors Y are found by solving the unrestricted optimization problem in (4): min Y-1 (Yl-Y-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l"}, {"heading": "2.5 System Overview", "text": "We have implemented the graph construction in Java and the CRF is implemented by modifying the CRFSuite source code (Okazaki, 2007). We have also modified the Junto toolkit (Talukdar and Pereira, 2010) and used it to distribute graphs.The entire source code of our system is available online.1 The input expressions and associated semantic trees are aligned using GIZA + + (Och and Ney, 2000) and then used to train the CRF base model.The graph is constructed from the labeled and unlabeled data and the main loop of the algorithm continues until convergence. The last parameters of the CRF are retained for decoding in the test phase."}, {"heading": "3 Experimental Results", "text": "In this section we evaluate our results on Air Travel Information Service (ATIS) dataset (Dahl et al., 1994), which consists of 4478 trainings, 500 development and 896 test statements. The development group was selected at random. To evaluate our work, we compared our results with the results of Supervised CRF and Self-trained CRF (Yarowsky, 1995). For our experiments, we set hyper parameters as follows: for graph propagation, \u00b51 = 1, \u00b52 = 0.01, for viterbi decoding, \u03b1 = 0.1, for CRF retraining, \u03b7 = 0.01."}, {"heading": "4 Conclusion", "text": "We introduced a simple algorithm to train CRF in a semi-supervised way using non-aligned data for SLU. By storing many informative labels during the alignment phase, the base model is trained with fewer features. CRF model parameters are estimated using much less marked data by regulating the model from a diagram near the nearest neighbor. Results show that our proposed algorithm significantly improves performance compared to supervised and self-trained CRF."}], "references": [{"title": "Discriminative spoken language understanding using statistical machine translation alignment models", "author": ["Shahram Khadivi", "SaeedShiry Ghidary", "MohammadHadi Bokaei"], "venue": null, "citeRegEx": "Aliannejadi et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Aliannejadi et al\\.", "year": 2014}, {"title": "Expanding the scope of the atis task: The atis-3 corpus", "author": ["Dahl et al.1994] Deborah A. Dahl", "Madeleine Bates", "Michael Brown", "William Fisher", "Kate HunickeSmith", "David Pallett", "Christine Pao", "Alexander Rudnicky", "Elizabeth Shriberg"], "venue": null, "citeRegEx": "Dahl et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Dahl et al\\.", "year": 1994}, {"title": "Graph-based lexicon expansion with sparsity-inducing penalties", "author": ["Das", "Smith2012] Dipanjan Das", "Noah A. Smith"], "venue": "In Proceedings of the 2012 Conference of the North American Chapter of the Association", "citeRegEx": "Das et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Das et al\\.", "year": 2012}, {"title": "Learning a part-of-speech tagger from two hours of annotation", "author": ["Garrette", "Baldridge2013] Dan Garrette", "Jason Baldridge"], "venue": "In Proceedings of NAACL-HLT,", "citeRegEx": "Garrette et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Garrette et al\\.", "year": 2013}, {"title": "Semantic processing using the hidden vector state model", "author": ["He", "Young2005] Yulan He", "Steve Young"], "venue": "Computer Speech & Language,", "citeRegEx": "He et al\\.,? \\Q2005\\E", "shortCiteRegEx": "He et al\\.", "year": 2005}, {"title": "Automatic filtering of bilingual corpora for statistical machine translation", "author": ["Khadivi", "Ney2005] Shahram Khadivi", "Hermann Ney"], "venue": "Natural Language Processing", "citeRegEx": "Khadivi et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Khadivi et al\\.", "year": 2005}, {"title": "Automatic retrieval and clustering of similar words", "author": ["Dekang Lin"], "venue": "In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics", "citeRegEx": "Lin.,? \\Q1998\\E", "shortCiteRegEx": "Lin.", "year": 1998}, {"title": "Giza++: Training of statistical translation models", "author": ["Och", "Ney2000] Franz Josef Och", "Hermann Ney"], "venue": null, "citeRegEx": "Och et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Och et al\\.", "year": 2000}, {"title": "Crfsuite: a fast implementation of conditional random fields (crfs). URL http://www.chokkan.org/software/crfsuite", "author": ["Naoaki Okazaki"], "venue": null, "citeRegEx": "Okazaki.,? \\Q2007\\E", "shortCiteRegEx": "Okazaki.", "year": 2007}, {"title": "A speech understanding system based on statistical representation of semantics", "author": ["E. Tzoukermann", "Z. Gorelov", "J. Gauvain", "E. Levin", "Chin-Hui Lee", "J.G. Wilpon"], "venue": "In Acoustics, Speech, and Signal Processing,", "citeRegEx": "Pieraccini et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Pieraccini et al\\.", "year": 1992}, {"title": "Generative and discriminative algorithms for spoken language understanding", "author": ["Raymond", "Riccardi2007] Christian Raymond", "Giuseppe Riccardi"], "venue": "In International Conference on Speech Communication and Technologies,", "citeRegEx": "Raymond et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Raymond et al\\.", "year": 2007}, {"title": "Graph propagation for paraphrasing out-ofvocabulary words in statistical machine translation", "author": ["Maryam Siahbani", "Gholamreza Haffari", "Anoop Sarkar"], "venue": "In Proceedings of the Conference of the Association", "citeRegEx": "Razmara et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Razmara et al\\.", "year": 2013}, {"title": "Efficient graph-based semi-supervised learning of structured tagging models", "author": ["Slav Petrov", "Fernando Pereira"], "venue": "In Proceedings of the 2010 Conference on Empirical Methods in Natural Language", "citeRegEx": "Subramanya et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Subramanya et al\\.", "year": 2010}, {"title": "New regularized algorithms for transductive learning", "author": ["Talukdar", "Koby Crammer"], "venue": null, "citeRegEx": "Talukdar et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Talukdar et al\\.", "year": 2009}, {"title": "Experiments in graphbased semi-supervised learning methods for classinstance acquisition", "author": ["Talukdar", "Fernando Pereira"], "venue": "In Proceedings of the 48th Annual Meeting of the Association", "citeRegEx": "Talukdar et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Talukdar et al\\.", "year": 2010}, {"title": "Weakly-supervised acquisition of labeled class instances using graph random walks", "author": ["Joseph Reisinger", "Marius Pa\u015fca", "Deepak Ravichandran", "Rahul Bhagat", "Fernando Pereira"], "venue": null, "citeRegEx": "Talukdar et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Talukdar et al\\.", "year": 2008}, {"title": "Discriminative models for spoken language understanding", "author": ["Wang", "Acero2006] Ye-Yi Wang", "Alex Acero"], "venue": "In International Conference on Speech Communication and Technologies", "citeRegEx": "Wang et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2006}, {"title": "Unsupervised word sense disambiguation rivaling supervised methods", "author": ["David Yarowsky"], "venue": "In Proceedings of the 33rd Annual Meeting on Association for Computational Linguistics,", "citeRegEx": "Yarowsky.,? \\Q1995\\E", "shortCiteRegEx": "Yarowsky.", "year": 1995}, {"title": "Graphbased semi-supervised model for joint chinese word segmentation and part-of-speech tagging", "author": ["Zeng et al.2013] Xiaodong Zeng", "Derek F Wong", "Lidia S Chao", "Isabel Trancoso"], "venue": "In ACL,", "citeRegEx": "Zeng et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Zeng et al\\.", "year": 2013}, {"title": "Semi-supervised learning using gaussian fields and harmonic functions", "author": ["Zhu et al.2003] Xiaojin Zhu", "Zoubin Ghahramani", "John Lafferty"], "venue": "In ICML,", "citeRegEx": "Zhu et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Zhu et al\\.", "year": 2003}], "referenceMentions": [{"referenceID": 9, "context": "The first statistical SLU system was based on hidden Markov model and modeled using a finite state semantic tagger employed in AT&T\u2019s CHRONUS system (Pieraccini et al., 1992).", "startOffset": 149, "endOffset": 174}, {"referenceID": 9, "context": "The first statistical SLU system was based on hidden Markov model and modeled using a finite state semantic tagger employed in AT&T\u2019s CHRONUS system (Pieraccini et al., 1992). Their semantic representation was flat-concept; but, later He and Young (2005) extended the representation to a hierarchical structure and modeled the problem using a push-down automaton.", "startOffset": 150, "endOffset": 255}, {"referenceID": 9, "context": "The first statistical SLU system was based on hidden Markov model and modeled using a finite state semantic tagger employed in AT&T\u2019s CHRONUS system (Pieraccini et al., 1992). Their semantic representation was flat-concept; but, later He and Young (2005) extended the representation to a hierarchical structure and modeled the problem using a push-down automaton. There are other works which have dealt with SLU as a sequential labeling problem. Raymond and Riccardi (2007) and Wang and Acero (2006) have fully annotated the data and trained the model in discriminative frameworks such as CRF.", "startOffset": 150, "endOffset": 474}, {"referenceID": 9, "context": "The first statistical SLU system was based on hidden Markov model and modeled using a finite state semantic tagger employed in AT&T\u2019s CHRONUS system (Pieraccini et al., 1992). Their semantic representation was flat-concept; but, later He and Young (2005) extended the representation to a hierarchical structure and modeled the problem using a push-down automaton. There are other works which have dealt with SLU as a sequential labeling problem. Raymond and Riccardi (2007) and Wang and Acero (2006) have fully annotated the data and trained the model in discriminative frameworks such as CRF.", "startOffset": 150, "endOffset": 500}, {"referenceID": 19, "context": "The computed similarities are then assigned as the weight of the edges connecting the nodes (Zhu et al., 2003).", "startOffset": 92, "endOffset": 110}, {"referenceID": 18, "context": "Garrette and Baldridge, 2013), and sparsity (Das and Smith, 2012; Zeng et al., 2013).", "startOffset": 44, "endOffset": 84}, {"referenceID": 0, "context": "More detailed explanation about this process can be found in our previous work (Aliannejadi et al., 2014).", "startOffset": 79, "endOffset": 105}, {"referenceID": 12, "context": "The proposed semi-supervised learning algorithm is based on (Subramanya et al., 2010).", "startOffset": 60, "endOffset": 85}, {"referenceID": 0, "context": "Using smaller feature window improves the generalization of the model (Aliannejadi et al., 2014).", "startOffset": 70, "endOffset": 96}, {"referenceID": 6, "context": "The PMI measure transforms the independence assumption into a ratio (Lin, 1998; Razmara et al., 2013).", "startOffset": 68, "endOffset": 101}, {"referenceID": 11, "context": "The PMI measure transforms the independence assumption into a ratio (Lin, 1998; Razmara et al., 2013).", "startOffset": 68, "endOffset": 101}, {"referenceID": 11, "context": "The first term of the summation is related to label score injection from the initial score of the node and makes the output match the seed labels Yl (Razmara et al., 2013).", "startOffset": 149, "endOffset": 171}, {"referenceID": 12, "context": "Many errors of the alignment model are corrected through label propagation using the MAD algorithm; whereas, those errors are propagated in traditional label propagation algorithms such as the one mentioned in (Subramanya et al., 2010).", "startOffset": 210, "endOffset": 235}, {"referenceID": 8, "context": "We have implemented the Graph Construction in Java and the CRF is implemented by modifying the source code of CRFSuite (Okazaki, 2007).", "startOffset": 119, "endOffset": 134}, {"referenceID": 1, "context": "In this section we evaluate our results on Air Travel Information Service (ATIS) data-set (Dahl et al., 1994) which consists of 4478 training, 500 development and 896 test utterances.", "startOffset": 90, "endOffset": 109}, {"referenceID": 17, "context": "To evaluate our work, we have compared our results with results from Supervised CRF and Self-trained CRF (Yarowsky, 1995).", "startOffset": 105, "endOffset": 121}], "year": 2017, "abstractText": "We experiment graph-based SemiSupervised Learning (SSL) of Conditional Random Fields (CRF) for the application of Spoken Language Understanding (SLU) on unaligned data. The aligned labels for examples are obtained using IBM Model. We adapt a baseline semisupervised CRF by defining new feature set and altering the label propagation algorithm. Our results demonstrate that our proposed approach significantly improves the performance of the supervised model by utilizing the knowledge gained from the graph.", "creator": "LaTeX with hyperref package"}}}