{"id": "1701.08734", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Jan-2017", "title": "PathNet: Evolution Channels Gradient Descent in Super Neural Networks", "abstract": "For artificial general intelligence (AGI) it would be efficient if multiple users trained the same giant neural network, permitting parameter reuse, without catastrophic forgetting. PathNet is a first step in this direction. It is a neural network algorithm that uses agents embedded in the neural network whose task is to discover which parts of the network to re-use for new tasks. Agents are pathways (views) through the network which determine the subset of parameters that are used and updated by the forwards and backwards passes of the backpropogation algorithm. During learning, a tournament selection genetic algorithm is used to select pathways through the neural network for replication and mutation. Pathway fitness is the performance of that pathway measured according to a cost function. We demonstrate successful transfer learning; fixing the parameters along a path learned on task A and re-evolving a new population of paths for task B, allows task B to be learned faster than it could be learned from scratch or after fine-tuning. Paths evolved on task B re-use parts of the optimal path evolved on task A. Positive transfer was demonstrated for binary MNIST, CIFAR, and SVHN supervised learning classification tasks, and a set of Atari and Labyrinth reinforcement learning tasks, suggesting PathNets have general applicability for neural network training. Finally, PathNet also significantly improves the robustness to hyperparameter choices of a parallel asynchronous reinforcement learning algorithm (A3C).", "histories": [["v1", "Mon, 30 Jan 2017 18:06:07 GMT  (7199kb,D)", "http://arxiv.org/abs/1701.08734v1", null]], "reviews": [], "SUBJECTS": "cs.NE cs.LG", "authors": ["chrisantha fernando", "dylan banarse", "charles blundell", "yori zwols", "david ha", "rei a rusu", "alexander pritzel", "daan wierstra"], "accepted": false, "id": "1701.08734"}, "pdf": {"name": "1701.08734.pdf", "metadata": {"source": "CRF", "title": "PathNet: Evolution Channels Gradient Descent in Super Neural Networks", "authors": ["Chrisantha Fernando", "Dylan Banarse", "Charles Blundell", "Yori Zwols", "David Ha", "Andrei A. Rusu", "Alexander Pritzel", "Daan Wierstra"], "emails": ["chrisantha@google.com"], "sections": [{"heading": null, "text": "Tags Gigantic networks, Path Evolution Algorithm, Evolution and Learning, Continual Learning, Transfer Learning, MultiTask Learning, Basal Ganglia"}, {"heading": "1. INTRODUCTION", "text": "This year is the highest in the history of the country."}, {"heading": "2. METHODS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 PathNet Architecture", "text": "A PathNet is a modular deep neural network with L-layers on each layer, consisting of M-modules. Each module itself is a neural network, here either corrugated or linear, followed by a transfer function, using fluted linear units. For each layer, the results of the modules in that layer are added before they are transferred to the active modules of the next layer. A module is active if it is present in the currently evaluated path genotype (see below). Maximum N-specific modules per layer are allowed on one path (typically N = 3 or 4). The last layer is unique and not divided for each task to be solved. In the case in question, it is a single linear layer for each task, and in the A3C case each task (e.g. Atari game) has a value function and a guideline reading (see [12] for a full description of the A3C algorithm used)."}, {"heading": "2.2 Pathway Evolution: Serial and Parallel", "text": "P genotypes (paths) are randomly initialized, with each genotype being at most a N-L matrix of integers describing the active modules in each layer on that path. In the serially monitored implementation, a binary tournament selection algorithm is implemented in series as follows: A random genotype is selected, and its path is trained for T epochs, with its fitness being the negative classification error during that training period. Then, another random genotype is selected and its path is trained for T epochs. A copy of the winning genotype overrides the losing path genotype. The copy of the winning path genotype is then overwritten by independent selection of each element with a probability of 1 / [N-L] and addition of an integer in the range [\u2212 2, 2] so that the genotype as a whole is negative. A local neighborhood was used to promote spatial localization."}, {"heading": "2.3 Transfer Learning Paradigm", "text": "All other parameters that are not in an optimal path will be re-initialized, and we found that without re-initialization, the transfer performance did not exceed fine-tuning. In the A3C case (but not in the monitored learning cases), the path that was initially most suitable, in addition to the newly developed path, will always be active during the forward movement of the network, but its parameters will not be modified by reverse. A new set of random paths will then be initialized and further developed / trained at task B. In both thesauration and reinforcement settings, pathNet will be compared with two alternative arrangements: an independent learning control where the target task is learned de novo, and a fine-tuning control where the second task is learned with the same path that learned the first task (but with a new value function and a new policy reading)."}, {"heading": "2.4 Binary MNIST classification tasks", "text": "A binary MNIST classification involves distinguishing two classes of MNIST digits from each other, for example 5 verses 6 [11]. To make the task more difficult, a salt and pepper sound of 50% is added to the MNIST digits. A transmission experiment involves training and developing paths at the first task until a complete classification of the training set is achieved. At this point, a new population of path genotypes is initialized and further developed at the second task until a perfect performance is achieved on the training set. Between the tasks, the following changes are made to the underlying network. The parameters contained in the optimal path are set at the first task, and all other parameters are reset to their random initial values. The reported result measures the training times required to achieve this classification accuracy. The entire PathNet consists of L = 3 layers, each forming a linear layer of 20 units each, each containing fictitious M = each layer."}, {"heading": "2.5 CIFAR and SVHN classification tasks", "text": "The larger version of the aforementioned network is used to train on CIFAR and to trim SVHN [13] of the standard size 28 x 28 with L = 3 and M = 20 modules per layer, each with 20 neurons, and with paths that can contain up to 5 modules per shift. In this case, the networks were not trained to a certain accuracy, but to a fixed period of 500 generations. Each generation consisted of the evaluation of two paths, each for 50 mini-stacks of 16 images. The measure of performance here was the accuracy achieved after this fixed training period. Evidence of positive transmission in this case is provided by the second task, which has a higher final accuracy than the first one."}, {"heading": "2.6 Atari games", "text": "In fact, it is the case that most of us are able to put ourselves in a different world, in which they are able to move, in which they move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they, in which they live, in which they, in which they live, in which they, in which they live, in which they, in which they are able to put themselves into another world, in which they are able to move, in which they live, in which they live in which they live, in which they live in which they live, in which they live in which they live, in which they live in which they live, in which they live in which they live, in which they live in which they live, in which they live in which they live, in which they live in which they live, in which they live in which they live, in which they live in which they live, in which they live in which they live, in which they live in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they, in which they live, in which they, in which they"}, {"heading": "3. RESULTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Binary MNIST Classification", "text": "Figure 3 shows that with PathNet, learning a source MNIST classification task helps to accelerate learning in the target MNIST classification task (Mean Time to Solution = 167 generations); greater than the acceleration that can be achieved by fine-tuning a fixed path originally trained at the source task (Mean Time to Solution = 229), and also compared to de novo learning the target task from scratch (Mean Time to Solution = 195). PathNet (Bottom Graph) learns in fewer generations with less data than the fine-tuning (Middle) and independent learning control (Top); the control networks consisted of exactly the same learning algorithm, but with no evolution of paths and only a fixed maximum size path through the network. The total acceleration ratio compared to the independent controls was 1.18 videos that elegantly show the performance of PathNet, which can be achieved online via HTTP / Jo: Voogps / Jo."}, {"heading": "3.2 CIFAR and SVHN", "text": "In this experiment, we only compare the accuracy that PathNet achieves after a short fixed number of 500 generations. Generally, a fully connected network of this size is not sufficient to perform well on these datasets. After 500 generations, when cSVHN and CIFAR are learned from the ground up with an average accuracy of 25.5% and 35.3%, see Figure 5. But after the first task is learned with this accuracy, learning the second task is faster, so that when cSVHN and CIFAR are learned as the second task with PathNet, accuracies of 35.7% and 39.8% are achieved, respectively."}, {"heading": "3.3 Atari Games", "text": "Transfer performance on PathNet is compared to fixed maximum size path de novo training and fine-tuning controls, for which a hyperparameter sweep was performed with learning rates [0.0001,005,001] and entropy costs [0.01, 0.0001, 0.0001]. In Figure 6, the performance of PathNet (blue) is compared with independent and fine-tuning controls (green) on 4 target games after RiverRaid was first learned. In all cases, the top 5 passes of a hyperparameter search are shown. Generally, we found that a strong selection with tournament sizes of B = 10, T = 10 game phases per evaluation and low mutation rates of 0.01-0.001 are optimal, allowing rapid convergence of paths to a single path."}, {"heading": "3.4 Labyrinth Games", "text": "In recent years it has been shown that people in the US and in other parts of the world are able to survive themselves if they are not able to survive themselves, \"he said.\" I don't think they will be able to save the world. \"He pointed out that the US is able to save the world.\" I don't think they are able to save the world, \"he said.\" I don't think they will be able to save the world. \"He pointed out\" that the world is able to save the world. \"He pointed out that people are able to save the world,\" to save the world, to save the world. \""}, {"heading": "4. CONCLUSION", "text": "This year, it is only a matter of time before an agreement is reached."}, {"heading": "5. ACKNOWLEDGMENTS", "text": "Thanks to Hubert Soyer, Arka Pal, Gabriel Dulac-Arnold, Gabriel Barth-Maron, Matteo Hessel, Alban Rustrani, Stephen Gaffney, Joel Leibo, Eors Szathmary"}, {"heading": "6. REFERENCES", "text": "[1]. J. E. Auerbach, C. Fernando, and D. Floreano. Onlineextreme evolutionary learning machines. In Artificial Life 14: Proceedings of the Fourteenth International Conference on the Synthesis and Simulation of Living Systems, number EPFL-CONF-200273, pp. 465-472. The MIT Press, 2014. [2] R. Caruana. Multitask learning. In Learning to learn, pp. 95-133. Springer, 1998. [3] T. Chen, I. Goodfellow, and J. Shlens. Net2net: Accelerating learning via knowledge transfer. arXiXiv preprint arXiv: XiXiXiv preprint arXiv: 1511,05641, 2015. [4] C. Fernando, V. Vasas, E. Szathma, ry, and P. Husbands. Evolvable neuronal paths: a novel basis for information and search in the brain. PloS one, 6 (8): e23534, 2011. [5] T. E. Fernando, P. Szathmary and Husbands."}], "references": [{"title": "Online extreme evolutionary learning machines", "author": ["J.E. Auerbach", "C. Fernando", "D. Floreano"], "venue": "Artificial Life 14: Proceedings of the Fourteenth International Conference on the Synthesis and Simulation of Living Systems, number EPFL-CONF-200273, pages 465\u2013472. The MIT Press,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2014}, {"title": "Multitask learning", "author": ["R. Caruana"], "venue": "Learning to learn, pages 95\u2013133. Springer,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1998}, {"title": "Net2net: Accelerating learning via knowledge transfer", "author": ["T. Chen", "I. Goodfellow", "J. Shlens"], "venue": "arXiv preprint arXiv:1511.05641,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}, {"title": "Evolvable neuronal paths: a novel basis for information and search in the brain", "author": ["C. Fernando", "V. Vasas", "E. Szathm\u00e1ry", "P. Husbands"], "venue": "PloS one, 6(8):e23534,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2011}, {"title": "Selectionist and evolutionary approaches to brain function: a critical appraisal", "author": ["C.T. Fernando", "E. Szathmary", "P. Husbands"], "venue": "Frontiers in computational neuroscience, 6:24,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2012}, {"title": "Interactions between frontal cortex and basal ganglia in working memory: a computational model", "author": ["M.J. Frank", "B. Loughry", "R.C. O\u00e2\u0102\u0179Reilly"], "venue": "Cognitive, Affective, & Behavioral Neuroscience, 1(2):137\u2013160,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2001}, {"title": "The microbial genetic algorithm", "author": ["I. Harvey"], "venue": "Advances in artificial life. Darwin Meets von Neumann, pages 126\u2013133. Springer,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2011}, {"title": "Towards an executive without a homunculus: computational models of the prefrontal cortex/basal ganglia system", "author": ["T.E. Hazy", "M.J. Frank", "R.C. O\u2019Reilly"], "venue": "Philosophical Transactions of the Royal Society B: Biological Sciences,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2007}, {"title": "Distilling the knowledge in a neural network", "author": ["G. Hinton", "O. Vinyals", "J. Dean"], "venue": "arXiv preprint arXiv:1503.02531,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2015}, {"title": "Reinforcement learning with unsupervised auxiliary tasks", "author": ["M. Jaderberg", "V. Mnih", "W.M. Czarnecki", "T. Schaul", "J.Z. Leibo", "D. Silver", "K. Kavukcuoglu"], "venue": "arXiv preprint arXiv:1611.05397,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2016}, {"title": "Gradient-based learning applied to document recognition", "author": ["Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "Proceedings of the IEEE, 86(11):2278\u20132324,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1998}, {"title": "Asynchronous methods for deep reinforcement learning", "author": ["V. Mnih", "A.P. Badia", "M. Mirza", "A. Graves", "T.P. Lillicrap", "T. Harley", "D. Silver", "K. Kavukcuoglu"], "venue": "arXiv preprint arXiv:1602.01783,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2016}, {"title": "Making working memory work: a computational model of learning in the prefrontal cortex and basal ganglia", "author": ["R.C. O\u2019Reilly", "M.J. Frank"], "venue": "Neural computation,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2006}, {"title": "Deep exploration via bootstrapped dqn", "author": ["I. Osband", "C. Blundell", "A. Pritzel", "B. Van Roy"], "venue": "arXiv preprint arXiv:1602.04621,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2016}, {"title": "Continual Learning in Reinforcement Environments", "author": ["M.B. Ring"], "venue": "PhD thesis, University of Texas at Austin,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1994}, {"title": "Progressive neural networks", "author": ["A.A. Rusu", "N.C. Rabinowitz", "G. Desjardins", "H. Soyer", "J. Kirkpatrick", "K. Kavukcuoglu", "R. Pascanu", "R. Hadsell"], "venue": "arXiv preprint arXiv:1606.04671,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2016}, {"title": "Convolutional neural fabrics", "author": ["S. Saxena", "J. Verbeek"], "venue": "arXiv preprint arXiv:1606.02492,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2016}, {"title": "Outrageously large neural networks: A sparsely-gated mixture-of-experts", "author": ["N. Shazeer", "A. Mirhoseini", "K. Maziarz", "A. Davis", "Q. Le", "G. Hinton", "J. Dean"], "venue": "[ICAR submission]", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2017}, {"title": "Swapout: Learning an ensemble of deep architectures", "author": ["S. Singh", "D. Hoiem", "D. Forsyth"], "venue": "arXiv preprint arXiv:1605.06465,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2016}, {"title": "Dropout: a simple way to prevent neural networks from overfitting", "author": ["N. Srivastava", "G.E. Hinton", "A. Krizhevsky", "I. Sutskever", "R. Salakhutdinov"], "venue": "Journal of Machine Learning Research, 15(1):1929\u20131958,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2014}, {"title": "An introduction to intertask transfer for reinforcement learning", "author": ["M.E. Taylor", "P. Stone"], "venue": "AI Magazine, 32(1):15,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2011}], "referenceMentions": [{"referenceID": 3, "context": "Each agent may itself be controlled by an arbitrarily complex reinforcement learning algorithm, but here we chose the very simplest possible \u2018agent\u2019, a unit of evolution [4].", "startOffset": 170, "endOffset": 173}, {"referenceID": 20, "context": "The framework for AGI described above includes aspects of transfer learning [22], continual learning [16] and multitask learning [2].", "startOffset": 76, "endOffset": 80}, {"referenceID": 14, "context": "The framework for AGI described above includes aspects of transfer learning [22], continual learning [16] and multitask learning [2].", "startOffset": 101, "endOffset": 105}, {"referenceID": 1, "context": "The framework for AGI described above includes aspects of transfer learning [22], continual learning [16] and multitask learning [2].", "startOffset": 129, "endOffset": 132}, {"referenceID": 17, "context": "Our work shares a motivation with a recent paper \u201cOutrageously large neural networks\u201d in which the authors write that \u201cthe capacity of a neural network to absorb information is limited by its number of parameters\u201d [19].", "startOffset": 214, "endOffset": 218}, {"referenceID": 16, "context": "Our work is related also to \u201cConvolutional Neural Fabrics\u201d in which connection strengths between modules in the fabric are learned, but where (unlike PathNet) the whole fabric is used all the time [18].", "startOffset": 197, "endOffset": 201}, {"referenceID": 15, "context": "PathNets evolve a population of pathways through a neural network that scaffolds and channels any desired gradientdescent-based learning algorithm towards a limited subset of the neural network\u2019s parameters and then fixes these parameters after learning so that functionality can never be lost; it resembles progressive neural networks, in that catastrophic forgetting is prevented by design [17].", "startOffset": 392, "endOffset": 396}, {"referenceID": 11, "context": "64 asynchronously updated workers that simultaneously share and update the parameters of a single network[12].", "startOffset": 105, "endOffset": 109}, {"referenceID": 4, "context": "The concept of the PathNet was first conceived of within the framework of Darwinian Neurodynamics as an attempt to envisage how evolutionary algorithms could be implemented in the brain [5].", "startOffset": 186, "endOffset": 189}, {"referenceID": 3, "context": "However, in that original work both the topology and the weights of the path were evolved and there was no gradient descent learning [4].", "startOffset": 133, "endOffset": 136}, {"referenceID": 11, "context": "Atari game) has a value function readout and a policy readout (see [12] for a complete description of the A3C algorithm used).", "startOffset": 67, "endOffset": 71}, {"referenceID": 10, "context": "A binary MNIST classification involves distinguishing two classes of MNIST digits from one another, for example 5 verses 6 [11].", "startOffset": 123, "endOffset": 127}, {"referenceID": 0, "context": "The genotype describing this pathway is a 3\u00d73 matrix of integers in the range [1, 10].", "startOffset": 78, "endOffset": 85}, {"referenceID": 9, "context": "The genotype describing this pathway is a 3\u00d73 matrix of integers in the range [1, 10].", "startOffset": 78, "endOffset": 85}, {"referenceID": 6, "context": "This is a binary tournament selection algorithm (B = 2) [7].", "startOffset": 56, "endOffset": 59}, {"referenceID": 9, "context": "Labyrinth is a 3D first person game environment [10].", "startOffset": 48, "endOffset": 52}, {"referenceID": 2, "context": "In the Labyrinth model we enabled PathNet to copy the weights of modules to other modules within the same layer, emulating Net2Net [3] or a distillation [9] like operation.", "startOffset": 131, "endOffset": 134}, {"referenceID": 8, "context": "In the Labyrinth model we enabled PathNet to copy the weights of modules to other modules within the same layer, emulating Net2Net [3] or a distillation [9] like operation.", "startOffset": 153, "endOffset": 156}, {"referenceID": 0, "context": "The following hyperparameters were investigated for PathNet: evaluation time T [1,10,50], mutation rate [0.", "startOffset": 79, "endOffset": 88}, {"referenceID": 9, "context": "The following hyperparameters were investigated for PathNet: evaluation time T [1,10,50], mutation rate [0.", "startOffset": 79, "endOffset": 88}, {"referenceID": 1, "context": "001] and tournament size B [2, 10, 20].", "startOffset": 27, "endOffset": 38}, {"referenceID": 9, "context": "001] and tournament size B [2, 10, 20].", "startOffset": 27, "endOffset": 38}, {"referenceID": 18, "context": "001] and tournament size B [2, 10, 20].", "startOffset": 27, "endOffset": 38}, {"referenceID": 1, "context": "5] (per episode completed by worker 0) and tournament size B [2, 10].", "startOffset": 61, "endOffset": 68}, {"referenceID": 9, "context": "5] (per episode completed by worker 0) and tournament size B [2, 10].", "startOffset": 61, "endOffset": 68}, {"referenceID": 3, "context": "PathNet extends our original work on the Path Evolution Algorithm [4] to Deep Learning whereby the weights and biases of the network are learned by gradient descent, but evolution determines which subset of parameters is to be trained.", "startOffset": 66, "endOffset": 69}, {"referenceID": 19, "context": "PathNet may be thought of as implementing a form of \u2018evolutionary dropout\u2019 in which instead of randomly dropping out units and their connections, dropout samples or \u2018thinned networks\u2019 are evolved [21].", "startOffset": 196, "endOffset": 200}, {"referenceID": 18, "context": "PathNet also resembles \u2018evolutionary swapout\u2019 [20], in fact we have experimented with having standard linear modules, skip modules and residual modules in the same layer and found that path evolution was capable of discovering effective structures within this diverse network.", "startOffset": 46, "endOffset": 50}, {"referenceID": 16, "context": "PathNet is related also to recent work on convolutional neural fabrics, but there the whole network is always used and so the principle cannot scale to giant networks [18].", "startOffset": 167, "endOffset": 171}, {"referenceID": 0, "context": "Other approaches to combining evolution and learning have involved parameter copying, whereas there is no such copying in the current implementation of PathNet [1][3].", "startOffset": 160, "endOffset": 163}, {"referenceID": 2, "context": "Other approaches to combining evolution and learning have involved parameter copying, whereas there is no such copying in the current implementation of PathNet [1][3].", "startOffset": 163, "endOffset": 166}, {"referenceID": 13, "context": "Firstly, a possibility is that mutable paths provide a more useful form of diverse exploration in RL tasks [15].", "startOffset": 107, "endOffset": 111}, {"referenceID": 7, "context": "cortex are to be active and trainable as a function of goal/subgoal signals from the prefrontal cortex, a hypothesis related to others in the literature [8] [14] [6].", "startOffset": 153, "endOffset": 156}, {"referenceID": 12, "context": "cortex are to be active and trainable as a function of goal/subgoal signals from the prefrontal cortex, a hypothesis related to others in the literature [8] [14] [6].", "startOffset": 157, "endOffset": 161}, {"referenceID": 5, "context": "cortex are to be active and trainable as a function of goal/subgoal signals from the prefrontal cortex, a hypothesis related to others in the literature [8] [14] [6].", "startOffset": 162, "endOffset": 165}], "year": 2017, "abstractText": "For artificial general intelligence (AGI) it would be efficient if multiple users trained the same giant neural network, permitting parameter reuse, without catastrophic forgetting. PathNet is a first step in this direction. It is a neural network algorithm that uses agents embedded in the neural network whose task is to discover which parts of the network to re-use for new tasks. Agents are pathways (views) through the network which determine the subset of parameters that are used and updated by the forwards and backwards passes of the backpropogation algorithm. During learning, a tournament selection genetic algorithm is used to select pathways through the neural network for replication and mutation. Pathway fitness is the performance of that pathway measured according to a cost function. We demonstrate successful transfer learning; fixing the parameters along a path learned on task A and re-evolving a new population of paths for task B, allows task B to be learned faster than it could be learned from scratch or after fine-tuning. Paths evolved on task B re-use parts of the optimal path evolved on task A. Positive transfer was demonstrated for binary MNIST, CIFAR, and SVHN supervised learning classification tasks, and a set of Atari and Labyrinth reinforcement learning tasks, suggesting PathNets have general applicability for neural network training. Finally, PathNet also significantly improves the robustness to hyperparameter choices of a parallel asynchronous reinforcement learning algorithm (A3C).", "creator": "LaTeX with hyperref package"}}}