{"id": "1701.08744", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Jan-2017", "title": "Click Through Rate Prediction for Contextual Advertisment Using Linear Regression", "abstract": "This research presents an innovative and unique way of solving the advertisement prediction problem which is considered as a learning problem over the past several years. Online advertising is a multi-billion-dollar industry and is growing every year with a rapid pace. The goal of this research is to enhance click through rate of the contextual advertisements using Linear Regression. In order to address this problem, a new technique propose in this paper to predict the CTR which will increase the overall revenue of the system by serving the advertisements more suitable to the viewers with the help of feature extraction and displaying the advertisements based on context of the publishers. The important steps include the data collection, feature extraction, CTR prediction and advertisement serving. The statistical results obtained from the dynamically used technique show an efficient outcome by fitting the data close to perfection for the LR technique using optimized feature selection.", "histories": [["v1", "Mon, 30 Jan 2017 18:32:59 GMT  (829kb)", "http://arxiv.org/abs/1701.08744v1", "8 pages, 13 Figures, 11 Tables"]], "COMMENTS": "8 pages, 13 Figures, 11 Tables", "reviews": [], "SUBJECTS": "cs.IR cs.AI cs.LG", "authors": ["muhammad junaid effendi", "syed abbas ali"], "accepted": false, "id": "1701.08744"}, "pdf": {"name": "1701.08744.pdf", "metadata": {"source": "CRF", "title": "Click Through Rate Prediction for Contextual Advertisment Using Linear Regression", "authors": ["Muhammad Junaid Effendi", "Syed Abbas Ali"], "emails": ["junaidfnd@gmail.com", "saaj@neduet.edu.pk"], "sections": [{"heading": null, "text": "This year, it is as far as ever in the history of the city, where it is as far as never before in the history of the city."}, {"heading": "II. BRIEF OVERVIEW OF SYSTEM", "text": "When a viewer visits a website where the advertisement is published, the characteristics are extracted from the website, the understanding of the content through keyword capture, ad size, ad placement (above or below the fold), the location of the viewer and many other important features. These factors are then fed into the ad server from where the data processing takes place, based on several factors. These factors are usually the order of the advertisements displayed to the viewer in the past, the behavior of the viewer extracted from the browser, and most importantly the click rate of the advertisements being delivered. This can be easily understood with the help of Fig. 1. This whole process must be completed in a few milliseconds, otherwise the viewer leaves the website without seeing the ad in the ad space. Other features such as ad placement play a crucial role, because an advertisement is not for the purpose when it is unreachable to the viewer [24]."}, {"heading": "III. COLLECTION OF VIEWERS\u2019 ACTIVITY", "text": "This section introduces the technology used in later machine learning to predict the click rate of advertisements.Since capture is a necessary step in predicting the CTR for future advertisements, a simple algorithm is developed to serve the ads and collect the data in raw form through our practical project and process the collected data later on. Below, the pseudo-code is used for the algorithm used. Algorithm 1: Contextual Ad Serving based on highest bidder inputs: ad placement, ad size, location, keywords, categoryFor i From 1 To N doIf (ad placement & & & & & ad location & & & & category) / Adjustment of ads poolAdsi < - AdEnd If"}, {"heading": "End For", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "For All \ud835\udc22 in Ads do", "text": "For all displays content based on Adi < - Adsi (number (keywords) = = max (keywords)) If Adj count (keywords) = = Adi count (keywords) / / Adi count (keywords) / / Adi (bid = = max (bid)) End IfDisplay < - Ad / / display the selected AdEnd For"}, {"heading": "End For", "text": "The purpose of this algorithm is to select the ad based on the context of the publisher plus the highest bidder within that contextual ad pool. Simply put, it prefers an ad that is more relevant to the content and then selects the highest bidder from the contextual ad pool. Therefore, the data it collects will be used in the next sections to perform a linear regression."}, {"heading": "IV. RESEARCH METHODOLOGY AND TECHNIQUES", "text": "There are several ways to make ad click predictions, and the method and techniques may vary between different datasets. Starting from the figure 1 discussed in Section III, we have modified the feature selection and machine learning blocks with different techniques to serve the same purpose. In this section, the main methods and techniques used to predict the ad click rate are explained step by step with proper proof in an appropriate manner."}, {"heading": "A. Feature Extraction And Selection", "text": "This section covers two types of attributes, one of which is collected in the previous section and used to advertise using a context and bidding algorithm, and the second is extracted during runtime from the viewer for which the system will predict a CTR. Whenever data is collected over runtime, it has several attributes, the first task being to obtain the necessary attributes that are most suitable for the learning algorithm. The data obtained is not in an appropriate form before processing and must be converted to avoid regression problems such as over- and undermatch [11]. As there are three distinct units, the advertiser, publisher and viewer are linked, so many attributes are extracted. The following table shows the attributes extracted from three different sources."}, {"heading": "Features", "text": "The above features can be categorical, nominal and ordinary, can also be discrete or continuous in nature. Now, the extracted features must be efficiently selected for the learning purpose. The above table contains many features that are irrelevant for learning and have no significance for the click rate, output. Advertising ID, campaign ID and some other features have no effect on the CTR, so they can be removed from the ad list. To the editor, all features are important, although the keywords are meaningless for the regression problems, but our job is to make them meaningful, as they are an important feature for context-related advertising. This will be discussed in the next part of the current section. User-extracted features are important, but not in this scenario due to the severity of the regression problems, adding them would overfit the model and thus reduce the efficiency of the system."}, {"heading": "Features", "text": "The features selected above must now be converted into a suitable form, a form that can be easily processed for the regression learning algorithm. Since regression only works with continuous values, the bid remains a perfect feature, so there is no need to work on it. But features such as ad size, keywords, ad placement must be converted into a proper form. Ad size and ad placement are categorical features that these can be mapped as an example: Ad size in integer, \"300x250\" to 1. The next part focuses on keyword conversion in continuous stream example \"Above the Fold\" to 1. Keywords are values that need to be converted in a continuous stream, as there is no limit and each keyword can be generated by the advertiser. The next part focuses on keyword conversion in continuous stream clustering to 1. Keywords are values that need to be converted in a continuous stream, as there is no limit and each keyword can be generated by the advertiser."}, {"heading": "B. Keywords To Integer Mapping Using Association Rule", "text": "The next step is to translate the characteristic keywords meaningfully and meaningfully to the data. As discussed, the keywords cannot be converted to a numerical value due to their random generation. For example, we have a keyword \"football\" and we have to assign it to a numerical value that is assumed to be 21st. However, for the next keyword \"football,\" this can be assigned to a value that is twice as high as the value of the \"football\" keyword 42 or any other value that is not repeated in the system, but the rating here will have no useful impact and will be of meaningless value, this would lead to an overpass problem. To solve this problem, the association rule can be used to make it meaningful and avoid fitting problems [12]. This function can also be ignored, but to add a different dynamic to the problem that we have considered an important part of learning. Also, because the focus on the contextual value-defining keywords on the page must be predicted here."}, {"heading": "Categories", "text": "The focus is only on the category of sports and all analyses are based on this category. Below, the keywords from the category of sports are summarized. At the moment, these keywords look like this: The three different colors (purple, yellow, blue) shown in Fig. 4 are the three keywords that were selected; they are the keywords that represent the clusters, for example, cricket. And the keywords are found using the association rule on the data set collected at the beginning of this research paper. Zentroids are selected as the most commonly used keywords. For example, football, cricket and tennis are the most frequently used terms with other keywords. FA rule mining is a technique for finding the relationship between certain data sets [16]. Using this technique, categorization can be performed efficiently until and unless the data set has these keywords. The dark colored keywords are the keywords that intersect the two circles, the two of which are related."}, {"heading": "Football", "text": "The table above shows how much each keyword is related to the distance value. The more keywords, the closer the value would be. Values may vary each time, as this technique is applied every time the learning needs to be done."}, {"heading": "C. CTR Prediction Using Machine Learning", "text": "The properties discussed in the previous section are now sent to calculate the CTR of the ads, but the ads are selected according to the position of the viewer and the category of the site. The problem has been solved in two respects, the linear regression equation and the normal equation presented by [10]. Predictions are made in both ways and will be compared in the next part of this section."}, {"heading": "V. EXPERIMENTAL RESULTS AND PERFORMANCE EVALUATION", "text": "This section illustrates the demonstrative experiments to improve the click rate through the contextual displays using the Linear Regression = 52 predicted points of issue 09. It helps to understand the context of the publisher and evaluates the performance of the proposed technique in terms of accuracy and standard errors.1. Simple linear regression The ad size and placement are categorical in this section so that they can be ignored for simple linear regression. However, all continuous based properties such as offer and keywords are used to show the direct relationship with the result of the CTR using a graphical view. the simple linear regression was defined earlier in this section to find the relationship for the following two relations. The data used were converted into a normalized form. Figure 9 shows a linear relationship between supply and click rate. The increase of the means an increase in the CTR and vice versa. Parameters found: 0.034421, 0.030570. For bid = 22, the predicted relationship between CT364that there is no such a CTR and 364wordplay."}, {"heading": "R squared:", "text": "R2 = 1 \u2212 \u2211 (yi \u2212 y \u2032) 2n i = 1 \u2211 (yi \u2212 ym) 2ni = 1 \u2212 SSESSTO (10) SSE is the sum of the square errors, SSTO is the sum of the squares. The last row is the mean of the respective column. R squared corresponds to 0.836581861, which means that 83.65% of the data correctly fit the model. Accuracy can be increased by removing the keyword from the attribute set, but this is about converting the dynamically converted keyword as a attribute into a meaningful value in order to achieve the best possible results."}, {"heading": "VI. CONCLUSION", "text": "This research presented a new technique for predicting the click rate for online advertising using linear regression along with a dynamically added function, the keyword. The proposed technique helps to calculate the CTR from a different perspective, although it causes a slight decrease in efficiency; the accuracy found is 83% and removing this function could increase this accuracy to 95%, which is a significant increase and fits perfectly with the model, but the CTR is also dependent on the keywords, as the research is based on the contextual advertisements. For future research, these results may help to combine and uncover other techniques to improve the performance of advertising sent over the Internet."}], "references": [{"title": "Machine Learning in the Real World", "author": ["V. Chaoji", "R. Rastogi", "G. Roy"], "venue": "Proc. VLDB Endow., Vol. 9, No. 13, 2016.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2016}, {"title": "Feature extraction for regression problems and an example application for pose estimation of a face", "author": ["N. Kwak", "S.-I. Choi", "C.-H. Choi"], "venue": "International Conference Image Analysis and Recognition, pp. 435\u2013444. 2008.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2008}, {"title": "Ad click prediction: a view from the trenches", "author": ["H.B. McMahan"], "venue": "Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining,, pp. 1222\u20131230,2013.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2013}, {"title": "Predicting clicks: estimating the click-through rate for new ads", "author": ["M. Richardson", "E. Dominowska", "R. Ragno"], "venue": "Proceedings of the 16th international conference on World Wide Web, pp. 521\u2013530, 2007.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2007}, {"title": "Web-scale bayesian click-through rate prediction for sponsored search advertising in microsoft\u2019s bing search engine", "author": ["T. Graepel", "J.Q. Candela", "T. Borchert", "R. Herbrich"], "venue": "Proceedings of the 27th International Conference on Machine Learning (ICML-10), pp. 13\u201320. 2010.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2010}, {"title": "Simple and scalable response prediction for display advertising", "author": ["O. Chapelle", "E. Manavoglu", "R. Rosales"], "venue": "ACM Trans. Intell. Syst. Technol. TIST, Vol. 5, No. 4, p. 61, 2015.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "Regression for ordinal variables without underlying continuous variables", "author": ["V. Torra", "J. Domingoferrer", "J. Mateosanz", "M. Ng"], "venue": "Inf. Sci., Vol. 176, No. 4, pp. 465\u2013474, Feb. 2006.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2006}, {"title": "A Logistic Regression Approach to Ad Click Prediction", "author": ["G. Kondakindi", "S. Rana", "A. Rajkumar", "S.K. Ponnekanti", "V. Parakh"], "venue": "Mach. Learn.-Cl. Proj., 2014.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "Using logistic regression to predict customer retention", "author": ["A.H. Karp"], "venue": "Proceedings of the Eleventh Northeast SAS Users Group Conference. http://www. lexjansen. om/nesug/nesug98/solu/p095. pdf, 1998.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1998}, {"title": "Linear Regression", "author": ["A. Ng"], "venue": "CS229 Lect. Notes, vol. 1, no. 1, pp. 1\u20133, 2000.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2000}, {"title": "What you see may not be what you get: a brief, nontechnical introduction to overfitting in regression-type models", "author": ["M.A. Babyak"], "venue": "Psychosom. Med., Vol. 66, No. 3, pp. 411\u2013421, 2004.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2004}, {"title": "The general inefficiency of batch training for gradient descent learning", "author": ["D.R. Wilson", "T.R. Martinez"], "venue": "Neural Netw., Vol. 16, No. 10, pp. 1429\u20131451, Dec. 2003.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2003}, {"title": "Clustering the tagged web", "author": ["D. Ramage", "P. Heymann", "C.D. Manning", "H. Garcia-Molina"], "venue": "Proceedings of the Second ACM  International Conference on Web Search and Data Mining, pp. 54\u201363, 2009.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2009}, {"title": "Fast Algorithms for Mining Association Rules in Datamining", "author": ["P. Usharani"], "venue": "Int. J. of Scientific & Technology research, Vol. 2, pp. 13\u201324, 2013.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}, {"title": "An improved K-Means Algorithm Based on Association Rules", "author": ["G. Liu", "S. Huang", "C. Lu", "Y. Du"], "venue": "Int. J. Comput. Theory Eng., Vol. 6, No. 2, p. 146, 2014.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2014}, {"title": "Flow classification using clustering and association rule mining", "author": ["U.K. Chaudhary", "I. Papapanagiotou", "M. Devetsikiotis"], "venue": "2010 15th IEEE International Workshop on Computer Aided Modeling, Analysis and Design of Communication Links and Networks (CAMAD), pp. 76\u2013 80, 2010.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2010}, {"title": "Data Quality in Linear Regression Models: Effect of Errors in Test Data and Errors in Training Data on Predictive Accuracy.", "author": ["B.D. Klein", "D.F. Rossin"], "venue": "InformingSciJ,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1999}, {"title": "A general and simple method for obtaining R 2 from generalized linear mixed-effects models", "author": ["S. Nakagawa", "H. Schielzeth"], "venue": "Methods Ecol. Evol., Vol. 4, No. 2, pp. 133\u2013142, Feb. 2013.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2013}, {"title": "Estimation and accuracy after model selection", "author": ["B. Efron"], "venue": "J. Am. Stat. Assoc., vol. 109, no. 507, pp. 991\u20131007, 2014.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "Click-through Prediction for Advertising in Twitter Timeline", "author": ["C. Li", "Y. Lu", "Q. Mei", "D. Wang", "S. Pandey"], "venue": "pp. 1959\u20131968, 2015.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1959}, {"title": "Practical Lessons from Predicting Clicks on Ads at Facebook", "author": ["X. He"], "venue": "pp. 1\u20139, 2014.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2014}, {"title": "Association rules mining: A recent overview", "author": ["S. Kotsiantis", "D. Kanellopoulos"], "venue": "GESTS Int. Trans. Comput. Sci. Eng.,Vol. 32, No. 1, pp. 71\u2013 82, 2006.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2006}, {"title": "Machine learning for targeted display advertising: Transfer learning in action", "author": ["B. Dalessandro", "F. Provost", "T. Raeder", "C. Perlich", "O. Stitelman"], "venue": "2013.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2013}, {"title": "If an Advertisement Runs Online And No One Sees It, Is It Still an Ad? Empirical Generalizations in Digital Advertising", "author": ["S. Flosi", "G. Fulgoni", "A. Vollman"], "venue": "J. Advert. Res., Vol. 53, No. 2, pp. 192\u2013199, Jun. 2013.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2013}, {"title": "An introduction to regression analysis", "author": ["A.O. Sykes"], "venue": "1993.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 1993}], "referenceMentions": [{"referenceID": 0, "context": "Machine Learning has played an important part in the online serving of advertisements, a paper presented by [1] explains how important the machine learning is in the real world.", "startOffset": 108, "endOffset": 111}, {"referenceID": 1, "context": "This step has been done in wide variety of ways for the regression problems, linear discriminant analysis (LDA) which is used for classification problem was modified to solve regressions problems by [2].", "startOffset": 199, "endOffset": 202}, {"referenceID": 13, "context": "The mapping of ordinal data into a meaningful continuous stream for linear regression to avoid fitting problems in this research has been done using the concept of k-mean clustering and association rule as presented by [14], [15], respectively.", "startOffset": 219, "endOffset": 223}, {"referenceID": 14, "context": "The mapping of ordinal data into a meaningful continuous stream for linear regression to avoid fitting problems in this research has been done using the concept of k-mean clustering and association rule as presented by [14], [15], respectively.", "startOffset": 225, "endOffset": 229}, {"referenceID": 15, "context": "The clustering and rule mining for textual categorization has been previously researched by [16], [17] but have not used to solve the regression problems.", "startOffset": 92, "endOffset": 96}, {"referenceID": 16, "context": "The clustering and rule mining for textual categorization has been previously researched by [16], [17] but have not used to solve the regression problems.", "startOffset": 98, "endOffset": 102}, {"referenceID": 6, "context": "Whereas [7] presented the conversion of ordinal data into nominal data and ignored the continuous variables for the regression.", "startOffset": 8, "endOffset": 11}, {"referenceID": 2, "context": "It has been done using Logistic Regression by various researchers such as [3], further na\u00efve Bayes has played a vital part in the building of ad click prediction, this can be seen in [4], [5].", "startOffset": 74, "endOffset": 77}, {"referenceID": 3, "context": "It has been done using Logistic Regression by various researchers such as [3], further na\u00efve Bayes has played a vital part in the building of ad click prediction, this can be seen in [4], [5].", "startOffset": 183, "endOffset": 186}, {"referenceID": 4, "context": "It has been done using Logistic Regression by various researchers such as [3], further na\u00efve Bayes has played a vital part in the building of ad click prediction, this can be seen in [4], [5].", "startOffset": 188, "endOffset": 191}, {"referenceID": 5, "context": "The estimation of response for the display advertisements is presented by [6].", "startOffset": 74, "endOffset": 77}, {"referenceID": 22, "context": "Similarly, the more the viewers the ad serving becomes hard to solve, the research presented by [23] has focused on the targeting display advertisements using massive-scale machine learning.", "startOffset": 96, "endOffset": 100}, {"referenceID": 7, "context": "Another research in this filed was done by [8] in which the focus is on the comparison of different machine Learning techniques including the logistic regression.", "startOffset": 43, "endOffset": 46}, {"referenceID": 19, "context": "The recent growth in the social networking on the internet has produced some great examples of ad serving technologies, Twitter advertising model is also based on the logistic regression, [20].", "startOffset": 188, "endOffset": 192}, {"referenceID": 20, "context": "While, another top network Facebook has used decision trees with logistic regression presented in [21] to serve the ads to their millions of users daily.", "startOffset": 98, "endOffset": 102}, {"referenceID": 8, "context": "The importance of logistic regression in finding the customers behavior can be seen in the paper written by [9].", "startOffset": 108, "endOffset": 111}, {"referenceID": 18, "context": "Estimating the errors and accuracy after model selection is one of the important parts of it according to [19].", "startOffset": 106, "endOffset": 110}, {"referenceID": 23, "context": "Further feature like ad placement plays a vital role because an advertisement is not serving the purpose if it is unreachable for the viewer [24].", "startOffset": 141, "endOffset": 145}, {"referenceID": 2, "context": "The past researches have shown that this is a regression problem and perfectly fits to the logistic model [3, 8], however our goal is to use linear regression with a little variance in the feature selection method where we will use techniques like clustering to make the feature meaningful in order to avoid over fitting and under fitting problems.", "startOffset": 106, "endOffset": 112}, {"referenceID": 7, "context": "The past researches have shown that this is a regression problem and perfectly fits to the logistic model [3, 8], however our goal is to use linear regression with a little variance in the feature selection method where we will use techniques like clustering to make the feature meaningful in order to avoid over fitting and under fitting problems.", "startOffset": 106, "endOffset": 112}, {"referenceID": 10, "context": "before processing it must be converted to avoid regression problems like over fitting and under fitting [11].", "startOffset": 104, "endOffset": 108}, {"referenceID": 11, "context": "In order to solve this problem Association Rule can be used to make it meaningful and to avoid fitting problems [12].", "startOffset": 112, "endOffset": 116}, {"referenceID": 15, "context": "The association rule mining is a technique to find the relationship among certain data set [16].", "startOffset": 91, "endOffset": 95}, {"referenceID": 9, "context": "The problem has been carried out in two ways, the linear regression equation and the normal equation presented by [10].", "startOffset": 114, "endOffset": 118}, {"referenceID": 24, "context": "This value is set to 1 which is passed as the interception value, often called as constant [25].", "startOffset": 91, "endOffset": 95}, {"referenceID": 10, "context": "It is the response or the output value when all parameters are set to zero [11], [12].", "startOffset": 75, "endOffset": 79}, {"referenceID": 11, "context": "It is the response or the output value when all parameters are set to zero [11], [12].", "startOffset": 81, "endOffset": 85}, {"referenceID": 12, "context": "The greater the value of \u03b1 the less iterations would be required and vice versa [13].", "startOffset": 80, "endOffset": 84}, {"referenceID": 17, "context": "These types of errors have a direct effect on the accuracy of the training and test data and this is usually found in linear regression [18].", "startOffset": 136, "endOffset": 140}, {"referenceID": 18, "context": "R squared is a useful statistical measure which helps in finding the accuracy of the model [19].", "startOffset": 91, "endOffset": 95}], "year": 2016, "abstractText": "This research presents an innovative and unique way of solving the advertisement prediction problem which is considered as a learning problem over the past several years. Online advertising is a multi-billion-dollar industry and is growing every year with a rapid pace. The goal of this research is to enhance click through rate of the contextual advertisements using Linear Regression. In order to address this problem, a new technique propose in this paper to predict the CTR which will increase the overall revenue of the system by serving the advertisements more suitable to the viewers with the help of feature extraction and displaying the advertisements based on context of the publishers. The important steps include the data collection, feature extraction, CTR prediction and advertisement serving. The statistical results obtained from the dynamically used technique show an efficient outcome by fitting the data close to perfection for the LR technique using optimized feature selection. Keywords-Click Through Rate(CTR), Contextual Advertisements, Machine Learning, Web advertisements, Regression Problem.", "creator": "Microsoft\u00ae Word 2013"}}}