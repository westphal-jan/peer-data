{"id": "1701.08886", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-Jan-2017", "title": "SenseGen: A Deep Learning Architecture for Synthetic Sensor Data Generation", "abstract": "Our ability to synthesize sensory data that preserves specific statistical properties of the real data has had tremendous implications on data privacy and big data analytics. The synthetic data can be used as a substitute for selective real data segments,that are sensitive to the user, thus protecting privacy and resulting in improved analytics.However, increasingly adversarial roles taken by data recipients such as mobile apps, or other cloud-based analytics services, mandate that the synthetic data, in addition to preserving statistical properties, should also be difficult to distinguish from the real data. Typically, visual inspection has been used as a test to distinguish between datasets. But more recently, sophisticated classifier models (discriminators), corresponding to a set of events, have also been employed to distinguish between synthesized and real data. The model operates on both datasets and the respective event outputs are compared for consistency. In this paper, we take a step towards generating sensory data that can pass a deep learning based discriminator model test, and make two specific contributions: first, we present a deep learning based architecture for synthesizing sensory data. This architecture comprises of a generator model, which is a stack of multiple Long-Short-Term-Memory (LSTM) networks and a Mixture Density Network. second, we use another LSTM network based discriminator model for distinguishing between the true and the synthesized data. Using a dataset of accelerometer traces, collected using smartphones of users doing their daily activities, we show that the deep learning based discriminator model can only distinguish between the real and synthesized traces with an accuracy in the neighborhood of 50%.", "histories": [["v1", "Tue, 31 Jan 2017 01:59:58 GMT  (483kb,D)", "http://arxiv.org/abs/1701.08886v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.CV", "authors": ["moustafa alzantot", "supriyo chakraborty", "mani b srivastava"], "accepted": false, "id": "1701.08886"}, "pdf": {"name": "1701.08886.pdf", "metadata": {"source": "CRF", "title": "SenseGen: A Deep Learning Architecture for Synthetic Sensor Data Generation", "authors": ["Moustafa Alzantot", "Supriyo Chakraborty", "Mani Srivastava"], "emails": ["malzantot@ucla.edu", "supriyo@us.ibm.com", "mbs@ucla.edu"], "sections": [{"heading": null, "text": "This year, as never before in the history of a country in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in"}, {"heading": "II. MODEL DESIGN", "text": "Sensor data, e.g. accelerometers, gyroscopes, barometers, etc., are represented as a sequence of values x = (x1, x2,..., xT), where xi-Rd, for i = 1,.., | T | where d is the dimensionality of the time series (i.e. d = 3 in the case of a 3-axis accelerometer) and T is the number of time steps for which the data was collected. SenseGen consists of two deep learning models: \u2022 Generator (G): Generator G is able to generate new synthetic time series data from random noise input. \u2022 Discriminator (D): The aim of discriminator D is to improve the quality of examples generated by generator G. Both G and D are based on recursive neural network models that have shown a lot of success in sequential data modeling."}, {"heading": "A. Generative Model", "text": "Recurrent neural networks (RNN) are a class of neural networks characterized by a multitude of feedback cycles that make it possible to maintain a memory of the previous input factors. (This also makes them responsible for dealing with problems with sequential time series that are applied in each step after the new input and previous internal state unit. (Whhht \u2212 1 + Wxhxt + bh) The recurrent neural input time series are applied in each step after the new input and previous internal state memory unit. (Whhht \u2212 1 + Wxhxt + bh) The recurrent way in which it is the sigmoid mode of operation (x).xEach unit also generates a different time series of outputs ot as a function of the internal memory state, which is calculated according to the following equation: ot = tanh. (Where + WNN) neural networks (where the recurrent neural networks are located)."}, {"heading": "B. Discriminative Model", "text": "To quantify the similarity between the generated time series and the real sensor time series collected by the users, we build another Model D, the goal of which is to distinguish between samples generated by G. The discriminatory Model D is trained to distinguish between samples originating from the data set for real sensor time series Xtrue and other samples from the data set Xgen generated by the Model G. The architecture of Model D consists of a layer of 64 LSTM units followed by a completely hidden layer of 16 hidden units using the sigmoid activation function and an output layer with a single unit with sigmoid activation function. The output value of this discriminatory model, when a given input sensor measures time series xtest, is interpreted as the probability that the given input time series are generated from the real data set Xtrue.D (xtest) Pr = Output test (x) data (xx1) by using the Xtruch data (xx1)."}, {"heading": "III. RESULTS AND ANALYSIS", "text": "For our experiments and evaluation studies, we use the Human Activity Recognition Database [18] as our training data; the HAR database contains accelerometers and gyroscopes of 30 individuals as they perform everyday activities (ADL); the accelerometer and gyroscope are pre-processed to calculate linear acceleration (by removing the gravitational component); and we train the Deep Learning Model with Google TensorFlow [19], which has deep learning frames r0.11 on Nvidia GTX GPU with 3.584 CUDA values to calculate the gravitational component."}, {"heading": "IV. CONCLUSION", "text": "In this paper, we outlined our initial experience of using a deep learning architecture to synthesize time series of sensory data. We determined that the synthesized data should be able to pass a deep, learning-based discriminator test designed to distinguish between synthesized and true data. Subsequently, we demonstrated that our generator can be successfully used to beat such a discriminator by limiting its accuracy to about 50%. Our generator-discriminator model pair is a GAN-like architecture. However, due to the difficulties in backpropagating through the MDN-based stochastic network, we are not yet integrating hostile training by returning the discriminator output to the generator orbit. We hope to close the feedback loop between the discriminator and the generator model to synthesize even more effective data samples."}, {"heading": "ACKNOWLEDGEMENT", "text": "The views and conclusions contained in this document are those of the authors and should not be interpreted to represent, either explicitly or implicitly, the official policy of the US Army Research Laboratory, the US Government, the Department of Defense, or the UK Government. US and UK Governments have the power to reproduce and distribute reprints for government purposes, regardless of any copyright notice."}], "references": [{"title": "Fitbit R  \u00a9: An accurate and reliable device for wireless physical activity tracking.", "author": ["K.M. Diaz", "D.J. Krupka", "M.J. Chang", "J. Peacock", "Y. Ma", "J. Goldsmith", "J.E. Schwartz", "K.W. Davidson"], "venue": "International journal of cardiology,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "No need to war-drive: unsupervised indoor localization", "author": ["H. Wang", "S. Sen", "A. Elgohary", "M. Farid", "M. Youssef", "R.R. Choudhury"], "venue": "Proceedings of the 10th international conference on Mobile systems, applications, and services. ACM, 2012, pp. 197\u2013210.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2012}, {"title": "Crowdinside: automatic construction of indoor floorplans", "author": ["M. Alzantot", "M. Youssef"], "venue": "Proceedings of the 20th International Conference on Advances in Geographic Information Systems. ACM, 2012, pp. 99\u2013108.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "Generative adversarial nets", "author": ["I. Goodfellow", "J. Pouget-Abadie", "M. Mirza", "B. Xu", "D. Warde-Farley", "S. Ozair", "A. Courville", "Y. Bengio"], "venue": "Advances in Neural Information Processing Systems, 2014, pp. 2672\u2013 2680.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2014}, {"title": "Nips 2016 tutorial: Generative adversarial networks", "author": ["I. Goodfellow"], "venue": "arXiv preprint arXiv:1701.00160, 2016.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2016}, {"title": "Auto-encoding variational bayes", "author": ["D.P. Kingma", "M. Welling"], "venue": "arXiv preprint arXiv:1312.6114, 2013.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "Improved techniques for training gans", "author": ["T. Salimans", "I. Goodfellow", "W. Zaremba", "V. Cheung", "A. Radford", "X. Chen"], "venue": "Advances in Neural Information Processing Systems, 2016, pp. 2226\u20132234.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2016}, {"title": "Photo-realistic single image super-resolution using a generative adversarial network", "author": ["C. Ledig", "L. Theis", "F. Husz\u00e1r", "J. Caballero", "A. Cunningham", "A. Acosta", "A. Aitken", "A. Tejani", "J. Totz", "Z. Wang"], "venue": "arXiv preprint arXiv:1609.04802, 2016.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2016}, {"title": "Generative adversarial text to image synthesis", "author": ["S. Reed", "Z. Akata", "X. Yan", "L. Logeswaran", "B. Schiele", "H. Lee"], "venue": "arXiv preprint arXiv:1605.05396, 2016.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2016}, {"title": "Seqgan: sequence generative adversarial nets with policy gradient", "author": ["L. Yu", "W. Zhang", "J. Wang", "Y. Yu"], "venue": "arXiv preprint arXiv:1609.05473, 2016.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2016}, {"title": "Generating sentences from a continuous space", "author": ["S.R. Bowman", "L. Vilnis", "O. Vinyals", "A.M. Dai", "R. Jozefowicz", "S. Bengio"], "venue": "arXiv preprint arXiv:1511.06349, 2015.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2015}, {"title": "Backpropagation through time: what it does and how to do it", "author": ["P.J. Werbos"], "venue": "Proceedings of the IEEE, vol. 78, no. 10, pp. 1550\u20131560, 1990.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1990}, {"title": "Long short-term memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural computation, vol. 9, no. 8, pp. 1735\u20131780, 1997.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1997}, {"title": "Gated feedback recurrent neural networks", "author": ["J. Chung", "C. G\u00fcl\u00e7ehre", "K. Cho", "Y. Bengio"], "venue": "CoRR, abs/1502.02367, 2015.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2015}, {"title": "Mixture density networks", "author": ["C.M. Bishop"], "venue": "1994.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1994}, {"title": "Generating sequences with recurrent neural networks", "author": ["A. Graves"], "venue": "arXiv preprint arXiv:1308.0850, 2013.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2013}, {"title": "Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude", "author": ["T. Tieleman", "G. Hinton"], "venue": "COURSERA: Neural Networks for Machine Learning, vol. 4, no. 2, 2012.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2012}, {"title": "Human activity recognition on smartphones using a multiclass hardware-friendly support vector machine", "author": ["D. Anguita", "A. Ghio", "L. Oneto", "X. Parra", "J.L. Reyes-Ortiz"], "venue": "International Workshop on Ambient Assisted Living. Springer, 2012, pp. 216\u2013223.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2012}], "referenceMentions": [{"referenceID": 0, "context": ", mobile apps, and other cloud-based big-data analytics) rely on the collection of personal sensory data from devices such as smartphones, wearables, and home IoT devices to provide services such as remote health monitoring [1], location tracking [2], automatic indoor map construction and navigation [3] and so on.", "startOffset": 224, "endOffset": 227}, {"referenceID": 1, "context": ", mobile apps, and other cloud-based big-data analytics) rely on the collection of personal sensory data from devices such as smartphones, wearables, and home IoT devices to provide services such as remote health monitoring [1], location tracking [2], automatic indoor map construction and navigation [3] and so on.", "startOffset": 247, "endOffset": 250}, {"referenceID": 2, "context": ", mobile apps, and other cloud-based big-data analytics) rely on the collection of personal sensory data from devices such as smartphones, wearables, and home IoT devices to provide services such as remote health monitoring [1], location tracking [2], automatic indoor map construction and navigation [3] and so on.", "startOffset": 301, "endOffset": 304}, {"referenceID": 3, "context": "However, recent work on generative models such as Generative Adversarial Networks [4], [5] (GAN) and variational auto-encoders [6], [7] have shown that it is possible to train these models with moderate sized datasets.", "startOffset": 82, "endOffset": 85}, {"referenceID": 4, "context": "However, recent work on generative models such as Generative Adversarial Networks [4], [5] (GAN) and variational auto-encoders [6], [7] have shown that it is possible to train these models with moderate sized datasets.", "startOffset": 87, "endOffset": 90}, {"referenceID": 5, "context": "However, recent work on generative models such as Generative Adversarial Networks [4], [5] (GAN) and variational auto-encoders [6], [7] have shown that it is possible to train these models with moderate sized datasets.", "startOffset": 127, "endOffset": 130}, {"referenceID": 6, "context": "However, recent work on generative models such as Generative Adversarial Networks [4], [5] (GAN) and variational auto-encoders [6], [7] have shown that it is possible to train these models with moderate sized datasets.", "startOffset": 132, "endOffset": 135}, {"referenceID": 7, "context": "GANs have proven successful in generating different types of data including photo-realistic high resolution images [8], realistic images from text description [9], and even for new text and music composition [10], [11].", "startOffset": 115, "endOffset": 118}, {"referenceID": 8, "context": "GANs have proven successful in generating different types of data including photo-realistic high resolution images [8], realistic images from text description [9], and even for new text and music composition [10], [11].", "startOffset": 159, "endOffset": 162}, {"referenceID": 9, "context": "GANs have proven successful in generating different types of data including photo-realistic high resolution images [8], realistic images from text description [9], and even for new text and music composition [10], [11].", "startOffset": 208, "endOffset": 212}, {"referenceID": 10, "context": "GANs have proven successful in generating different types of data including photo-realistic high resolution images [8], realistic images from text description [9], and even for new text and music composition [10], [11].", "startOffset": 214, "endOffset": 218}, {"referenceID": 11, "context": "Like other neural networks, we train a recurrent neural networks possible by using a modified version of back-propagation known as back-propagation through time (BPTT) algorithm [12].", "startOffset": 178, "endOffset": 182}, {"referenceID": 12, "context": "To solve the exploding gradient problem, the gradient value is clipped at each unit, while modified architectures of RNN units such as the Long Short Term Memory (LSTM) [13] and Gated Recurrent Units (GRU) [14] have been introduced to come over the vanishing gradient problem.", "startOffset": 169, "endOffset": 173}, {"referenceID": 13, "context": "To solve the exploding gradient problem, the gradient value is clipped at each unit, while modified architectures of RNN units such as the Long Short Term Memory (LSTM) [13] and Gated Recurrent Units (GRU) [14] have been introduced to come over the vanishing gradient problem.", "startOffset": 206, "endOffset": 210}, {"referenceID": 14, "context": "As a solution for these issues, we use Mixture Density Network (MDN) [15].", "startOffset": 69, "endOffset": 73}, {"referenceID": 15, "context": "[16] shows how MDN with Gaussian mixture model (GMM) defined on top of a recurrent neural network is successful in learning how to generate highly realistic handwriting by predicting the pen location one point at a time.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "The whole model is trained end-to-end by RMSProp [17] and truncated back-propagation through time with a cost function L(\u03b8G) defined to increase the likelihood of generating the next timestep value.", "startOffset": 49, "endOffset": 53}, {"referenceID": 17, "context": "For our experiments and evaluation studies, We use the Human Activity Recognition database [18] as our training data.", "startOffset": 91, "endOffset": 95}], "year": 2017, "abstractText": "Our ability to synthesize sensory data that preserves specific statistical properties of the real data has had tremendous implications on data privacy and big data analytics. The synthetic data can be used as a substitute for selective real data segments \u2013 that are sensitive to the user \u2013 thus protecting privacy and resulting in improved analytics. However, increasingly adversarial roles taken by data recipients such as mobile apps, or other cloud-based analytics services, mandate that the synthetic data, in addition to preserving statistical properties, should also be \u201cdifficult to distinguish from the real data. Typically, visual inspection has been used as a test to distinguish between datasets. But more recently, sophisticated classifier models (discriminators), corresponding to a set of events, have also been employed to distinguish between synthesized and real data. The model operates on both datasets and the respective event outputs are compared for consistency. Prior work on data synthesis have often focussed on classifiers that are built for features explicitly preserved by the synthetic data. This suggests that an adversary can build classifiers that can exploit a potentially disjoint set of features for differentiating between the two datasets. In this paper, we take a step towards generating sensory data that can pass a deep learning based discriminator model test, and make two specific contributions: first, we present a deep learning based architecture for synthesizing sensory data. This architecture comprises of a generator model, which is a stack of multiple Long-Short-Term-Memory (LSTM) networks and a Mixture Density Network (MDN); second, we use another LSTM network based discriminator model for distinguishing between the true and the synthesized data. Using a dataset of accelerometer traces, collected using smartphones of users doing their daily activities, we show that the deep learning based discriminator model can only distinguish between the real and synthesized traces with an accuracy in the neighborhood of 50%.", "creator": "TeX"}}}