{"id": "1702.00758", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Feb-2017", "title": "HashNet: Deep Learning to Hash by Continuation", "abstract": "Learning to hash has been widely applied to approximate nearest neighbor search for large-scale multimedia retrieval, due to its computation efficiency and retrieval quality. Deep learning to hash, which improves retrieval quality by end-to-end representation learning and hash encoding, has received increasing attention recently. Subject to the vanishing gradient difficulty in the optimization with binary activations, existing deep learning to hash methods need to first learn continuous representations and then generate binary hash codes in a separated binarization step, which suffer from substantial loss of retrieval quality. This paper presents HashNet, a novel deep architecture for deep learning to hash by continuation method, which learns exactly binary hash codes from imbalanced similarity data where the number of similar pairs is much smaller than the number of dissimilar pairs. The key idea is to attack the vanishing gradient problem in optimizing deep networks with non-smooth binary activations by continuation method, in which we begin from learning an easier network with smoothed activation function and let it evolve during the training, until it eventually goes back to being the original, difficult to optimize, deep network with the sign activation function. Comprehensive empirical evidence shows that HashNet can generate exactly binary hash codes and yield state-of-the-art multimedia retrieval performance on standard benchmarks.", "histories": [["v1", "Thu, 2 Feb 2017 17:29:24 GMT  (2794kb,D)", "http://arxiv.org/abs/1702.00758v1", null], ["v2", "Sun, 23 Apr 2017 22:14:09 GMT  (3001kb,D)", "http://arxiv.org/abs/1702.00758v2", null], ["v3", "Thu, 20 Jul 2017 14:59:45 GMT  (1900kb,D)", "http://arxiv.org/abs/1702.00758v3", null], ["v4", "Sat, 29 Jul 2017 17:55:50 GMT  (1900kb,D)", "http://arxiv.org/abs/1702.00758v4", null]], "reviews": [], "SUBJECTS": "cs.LG cs.CV", "authors": ["zhangjie cao", "mingsheng long", "jianmin wang", "philip s yu"], "accepted": false, "id": "1702.00758"}, "pdf": {"name": "1702.00758.pdf", "metadata": {"source": "CRF", "title": "HashNet: Deep Learning to Hash by Continuation", "authors": ["Zhangjie Cao", "Mingsheng Long", "Jianmin Wang", "Philip S. Yu"], "emails": ["caozhangjie14@gmail.com", "mingsheng@tsinghua.edu.cn", "jimwang@tsinghua.edu.cn", "psyu@uic.edu"], "sections": [{"heading": "1. Introduction", "text": "This year it is so far that it will only be a matter of time before it is so far, until it is so far."}, {"heading": "2. Related Work", "text": "In fact, most of the people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to play, to dance, to dance, to dance, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move"}, {"heading": "3. HashNet", "text": "In similarity retrieval systems we get a series of N-points {xi} Ni = 1, each represented by a D-dimensional feature vector xi \u03b2RD. Some pairs of dots xi and xj are provided with similarity labels sij, where sij = 1 if xi and xj are similar, while sij = 0 if xi and xj are unequal. The goal of deep learning about the hash is to learn non-linear hash function f: x 7 \u2192 h (x) in such a way that the similarity information between the given pairs S in the input space RD to the hamming space {\u2212 1} K using deep neural networks that encode each point x in compact K-bit binary hash code h (x) in such a way that the similarity information between the given pairs S in the compact hash codes compressed hash codes compressed hash codes compressed hash codes can be preserved from the compressed hash system {reversible hash system}."}, {"heading": "3.1. Model Formulation", "text": "Considering the number of pairwise similarities, S = {sij}, the weighted maximum likelihood labels (WML) estimate of hash codes H = [h1, hN] for all training points islogP (S | H) for all training points islogP (S | H) for all training points."}, {"heading": "3.2. Learning by Continuation", "text": "However, these binary processes can only be performed if the drawing function is not smooth and non-convex, but their gradient is zero for all nonzero inputs and is ill- defined at zero, making standard back propagation unfeasible for deep network training. This is known as the vanishing gradient problem, which has been a key difficulty in forming deep neural networks [14]. Many optimization methods have been proposed to circumvent the disappearing gradient problem and enable effective training."}, {"heading": "4. Experiment", "text": "We conduct extensive experiments to evaluate the effectiveness of the HashNet approach against various modern hash methods on three standard benchmark datasets, and the codes and configurations are made available online."}, {"heading": "4.1. Setup", "text": "The idea behind this is that people in the USA and in other parts of the world in which they live and work, go to another world, in which they do not feel able to integrate themselves, in which they go to another world, in which they go to another world, in which they find themselves in another world, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live."}, {"heading": "4.2. Results", "text": "The rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the r"}, {"heading": "4.3. Discussion", "text": "This year, it has reached the stage where it will be able to take the lead in order to achieve the objectives I have mentioned."}, {"heading": "5. Conclusion", "text": "This paper dealt with \"deep learning to hash from imbalanced similarity data by the continuation method.\" The proposed HashNet can learn binary hash codes accurately by optimizing a novel pair-weighted cross-entropy loss function in deep Constitutional Neural Networks. HashNet can be effectively trained through the multi-level pre-training algorithm carefully created by the continuation method. Comprehensive empirical evidence shows that HashNet can generate binary hash codes accurately and deliver state-of-the-art multimedia retrieval performance based on standard benchmarks."}], "references": [{"title": "Numerical continuation methods: an introduction, volume 13", "author": ["E.L. Allgower", "K. Georg"], "venue": "Springer Science & Business Media,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2012}, {"title": "Representation learning: A review and new perspectives", "author": ["Y. Bengio", "A. Courville", "P. Vincent"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI),", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2013}, {"title": "Greedy layer-wise training of deep networks", "author": ["Y. Bengio", "P. Lamblin", "D. Popovici", "H. Larochelle"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2007}, {"title": "Nus-wide: A real-world web image database from national university of singapore", "author": ["T.-S. Chua", "J. Tang", "R. Hong", "H. Li", "Z. Luo", "Y.-T. Zheng"], "venue": "In ICMR. ACM,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2009}, {"title": "Binarynet: Training deep neural networks with weights and activations constrained to +1 or -1", "author": ["M. Courbariaux", "Y. Bengio"], "venue": "In NIPS,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2016}, {"title": "Maximum likelihood in cost-sensitive learning: Model specification, approximations, and upper bounds", "author": ["J.P. Dmochowski", "P. Sajda", "L.C. Parra"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2010}, {"title": "Decaf: A deep convolutional activation feature for generic visual recognition", "author": ["J. Donahue", "Y. Jia", "O. Vinyals", "J. Hoffman", "N. Zhang", "E. Tzeng", "T. Darrell"], "venue": "In ICML,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "Deep hashing for compact binary codes learning", "author": ["V. Erin Liong", "J. Lu", "G. Wang", "P. Moulin", "J. Zhou"], "venue": "In CVPR,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "Fast search in hamming space with multi-index hashing", "author": ["D.J. Fleet", "A. Punjani", "M. Norouzi"], "venue": "In CVPR. IEEE,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2012}, {"title": "Similarity search in high dimensions via hashing", "author": ["A. Gionis", "P. Indyk", "R. Motwani"], "venue": "In VLDB,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1999}, {"title": "Learning binary codes for high-dimensional data using bilinear projections", "author": ["Y. Gong", "S. Kumar", "H. Rowley", "S. Lazebnik"], "venue": "In CVPR,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2013}, {"title": "Iterative quantization: A procrustean approach to learning binary codes", "author": ["Y. Gong", "S. Lazebnik"], "venue": "In CVPR,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2011}, {"title": "Deep residual learning for image recognition", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "CVPR, 2016", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2016}, {"title": "A fast learning algorithm for deep belief nets", "author": ["G.E. Hinton", "S. Osindero", "Y.-W. Teh"], "venue": "Neural Computation,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2006}, {"title": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "author": ["S. Ioffe", "C. Szegedy"], "venue": "In ICML,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2015}, {"title": "Product quantization for nearest neighbor search", "author": ["H. Jegou", "M. Douze", "C. Schmid"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI),", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2011}, {"title": "Caffe: Convolutional architecture for fast feature embedding", "author": ["Y. Jia", "E. Shelhamer", "J. Donahue", "S. Karayev", "J. Long", "R. Girshick", "S. Guadarrama", "T. Darrell"], "venue": "In ACM Multimedia", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2014}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "In NIPS,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2012}, {"title": "Learning to hash with binary reconstructive embeddings", "author": ["B. Kulis", "T. Darrell"], "venue": "In NIPS, pages 1042\u20131050,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2009}, {"title": "Simultaneous feature learning and hash coding with deep neural networks", "author": ["H. Lai", "Y. Pan", "Y. Liu", "S. Yan"], "venue": "In CVPR. IEEE,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2015}, {"title": "Content-based multimedia information retrieval: State of the art and challenges", "author": ["M.S. Lew", "N. Sebe", "C. Djeraba", "R. Jain"], "venue": "ACM Trans. Multimedia Comput. Commun. Appl.,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2006}, {"title": "Microsoft coco: Common objects in context", "author": ["T.-Y. Lin", "M. Maire", "S. Belongie", "J. Hays", "P. Perona", "D. Ramanan", "P. Doll\u00e1r", "C.L. Zitnick"], "venue": "In ECCV,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2014}, {"title": "Supervised hashing with kernels", "author": ["W. Liu", "J. Wang", "R. Ji", "Y.-G. Jiang", "S.-F. Chang"], "venue": "In CVPR. IEEE,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2012}, {"title": "Hashing with graphs", "author": ["W. Liu", "J. Wang", "S. Kumar", "S.-F. Chang"], "venue": "In ICML. ACM,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2011}, {"title": "Hash bit selection: a unified solution for selection problems in hashing", "author": ["X. Liu", "J. He", "B. Lang", "S.-F. Chang"], "venue": "In CVPR,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2013}, {"title": "Rectified linear units improve restricted boltzmann machines", "author": ["V. Nair", "G.E. Hinton"], "venue": "In J. Fu\u0308rnkranz and T. Joachims, editors,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2010}, {"title": "Minimal loss hashing for compact binary codes", "author": ["M. Norouzi", "D.M. Blei"], "venue": "In ICML,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2011}, {"title": "Hamming distance metric learning", "author": ["M. Norouzi", "D.M. Blei", "R.R. Salakhutdinov"], "venue": "In NIPS, pages 1061\u20131069,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2012}, {"title": "ImageNet Large Scale Visual Recognition Challenge", "author": ["O. Russakovsky", "J. Deng", "H. Su", "J. Krause", "S. Satheesh", "S. Ma", "Z. Huang", "A. Karpathy", "A. Khosla", "M. Bernstein", "A.C. Berg", "L. Fei-Fei"], "venue": "International Journal of Computer Vision (IJCV),", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2015}, {"title": "Learning a nonlinear embedding by preserving class neighbourhood structure", "author": ["R. Salakhutdinov", "G.E. Hinton"], "venue": "In AISTATS,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2007}, {"title": "Supervised discrete hashing", "author": ["F. Shen", "C. Shen", "W. Liu", "H. Tao Shen"], "venue": "In CVPR", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2015}, {"title": "Content-based image retrieval at the end of the early years", "author": ["A.W. Smeulders", "M. Worring", "S. Santini", "A. Gupta", "R. Jain"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI),", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2000}, {"title": "Dropout: A simple way to prevent neural networks from overfitting", "author": ["N. Srivastava", "G. Hinton", "A. Krizhevsky", "I. Sutskever", "R. Salakhutdinov"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 1929}, {"title": "Semi-supervised hashing for large-scale search", "author": ["J. Wang", "S. Kumar", "S.-F. Chang"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI),", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2012}, {"title": "Hashing for similarity search: A survey", "author": ["J. Wang", "H.T. Shen", "J. Song", "J. Ji"], "venue": "Arxiv, 2014", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2014}, {"title": "Spectral hashing", "author": ["Y. Weiss", "A. Torralba", "R. Fergus"], "venue": "In NIPS,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2009}, {"title": "Supervised hashing for image retrieval via image representation learning", "author": ["R. Xia", "Y. Pan", "H. Lai", "C. Liu", "S. Yan"], "venue": "In AAAI, pages 2156\u20132162", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2014}, {"title": "Circulant binary embedding", "author": ["F.X. Yu", "S. Kumar", "Y. Gong", "S.-F. Chang"], "venue": "In ICML, pages 353\u2013360", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2014}, {"title": "Supervised hashing with latent factor models", "author": ["P. Zhang", "W. Zhang", "W.-J. Li", "M. Guo"], "venue": "In SIGIR,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2014}, {"title": "Deep hashing network for efficient similarity retrieval", "author": ["H. Zhu", "M. Long", "J. Wang", "Y. Cao"], "venue": "In AAAI. AAAI,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2016}], "referenceMentions": [{"referenceID": 20, "context": "Parallel to the traditional indexing methods [21], another advantageous solution is hashing methods [35], which transform high-dimensional media data into compact binary codes and generate similar binary codes for similar data items.", "startOffset": 45, "endOffset": 49}, {"referenceID": 34, "context": "Parallel to the traditional indexing methods [21], another advantageous solution is hashing methods [35], which transform high-dimensional media data into compact binary codes and generate similar binary codes for similar data items.", "startOffset": 100, "endOffset": 104}, {"referenceID": 34, "context": "In this paper, we will focus on learning to hash methods [35] that build data-dependent hash encoding schemes for efficient image retrieval, which have shown better performance than data-independent hashing methods, e.", "startOffset": 57, "endOffset": 61}, {"referenceID": 9, "context": "Locality-Sensitive Hashing (LSH) [10].", "startOffset": 33, "endOffset": 37}, {"referenceID": 18, "context": "Many learning to hash methods have been proposed to enable efficient ANN search of high-dimensional data by ranking the Hamming distance across compact binary hash codes [19, 12, 27, 9, 23, 34, 25, 11, 38, 39].", "startOffset": 170, "endOffset": 209}, {"referenceID": 11, "context": "Many learning to hash methods have been proposed to enable efficient ANN search of high-dimensional data by ranking the Hamming distance across compact binary hash codes [19, 12, 27, 9, 23, 34, 25, 11, 38, 39].", "startOffset": 170, "endOffset": 209}, {"referenceID": 26, "context": "Many learning to hash methods have been proposed to enable efficient ANN search of high-dimensional data by ranking the Hamming distance across compact binary hash codes [19, 12, 27, 9, 23, 34, 25, 11, 38, 39].", "startOffset": 170, "endOffset": 209}, {"referenceID": 8, "context": "Many learning to hash methods have been proposed to enable efficient ANN search of high-dimensional data by ranking the Hamming distance across compact binary hash codes [19, 12, 27, 9, 23, 34, 25, 11, 38, 39].", "startOffset": 170, "endOffset": 209}, {"referenceID": 22, "context": "Many learning to hash methods have been proposed to enable efficient ANN search of high-dimensional data by ranking the Hamming distance across compact binary hash codes [19, 12, 27, 9, 23, 34, 25, 11, 38, 39].", "startOffset": 170, "endOffset": 209}, {"referenceID": 33, "context": "Many learning to hash methods have been proposed to enable efficient ANN search of high-dimensional data by ranking the Hamming distance across compact binary hash codes [19, 12, 27, 9, 23, 34, 25, 11, 38, 39].", "startOffset": 170, "endOffset": 209}, {"referenceID": 24, "context": "Many learning to hash methods have been proposed to enable efficient ANN search of high-dimensional data by ranking the Hamming distance across compact binary hash codes [19, 12, 27, 9, 23, 34, 25, 11, 38, 39].", "startOffset": 170, "endOffset": 209}, {"referenceID": 10, "context": "Many learning to hash methods have been proposed to enable efficient ANN search of high-dimensional data by ranking the Hamming distance across compact binary hash codes [19, 12, 27, 9, 23, 34, 25, 11, 38, 39].", "startOffset": 170, "endOffset": 209}, {"referenceID": 37, "context": "Many learning to hash methods have been proposed to enable efficient ANN search of high-dimensional data by ranking the Hamming distance across compact binary hash codes [19, 12, 27, 9, 23, 34, 25, 11, 38, 39].", "startOffset": 170, "endOffset": 209}, {"referenceID": 38, "context": "Many learning to hash methods have been proposed to enable efficient ANN search of high-dimensional data by ranking the Hamming distance across compact binary hash codes [19, 12, 27, 9, 23, 34, 25, 11, 38, 39].", "startOffset": 170, "endOffset": 209}, {"referenceID": 31, "context": "While unsupervised methods are more general and can be trained without semantic labels or relevance information, they are subject to the semantic gap dilemma [32] that high-level semantic description of an object often differs from low-level feature descriptors.", "startOffset": 158, "endOffset": 162}, {"referenceID": 36, "context": "Recently, deep learning to hash methods [37, 20, 31, 8, 40] have shown that end-to-end learning of feature representation and hash coding can be more effective using deep neural networks [18, 2], which can naturally encode any nonlinear hash functions.", "startOffset": 40, "endOffset": 59}, {"referenceID": 19, "context": "Recently, deep learning to hash methods [37, 20, 31, 8, 40] have shown that end-to-end learning of feature representation and hash coding can be more effective using deep neural networks [18, 2], which can naturally encode any nonlinear hash functions.", "startOffset": 40, "endOffset": 59}, {"referenceID": 30, "context": "Recently, deep learning to hash methods [37, 20, 31, 8, 40] have shown that end-to-end learning of feature representation and hash coding can be more effective using deep neural networks [18, 2], which can naturally encode any nonlinear hash functions.", "startOffset": 40, "endOffset": 59}, {"referenceID": 7, "context": "Recently, deep learning to hash methods [37, 20, 31, 8, 40] have shown that end-to-end learning of feature representation and hash coding can be more effective using deep neural networks [18, 2], which can naturally encode any nonlinear hash functions.", "startOffset": 40, "endOffset": 59}, {"referenceID": 39, "context": "Recently, deep learning to hash methods [37, 20, 31, 8, 40] have shown that end-to-end learning of feature representation and hash coding can be more effective using deep neural networks [18, 2], which can naturally encode any nonlinear hash functions.", "startOffset": 40, "endOffset": 59}, {"referenceID": 17, "context": "Recently, deep learning to hash methods [37, 20, 31, 8, 40] have shown that end-to-end learning of feature representation and hash coding can be more effective using deep neural networks [18, 2], which can naturally encode any nonlinear hash functions.", "startOffset": 187, "endOffset": 194}, {"referenceID": 1, "context": "Recently, deep learning to hash methods [37, 20, 31, 8, 40] have shown that end-to-end learning of feature representation and hash coding can be more effective using deep neural networks [18, 2], which can naturally encode any nonlinear hash functions.", "startOffset": 187, "endOffset": 194}, {"referenceID": 39, "context": "In particular, it proves crucial to jointly learn similarity-preserving representations and control quantization error of binarizing continuous representations to binary codes [40].", "startOffset": 176, "endOffset": 180}, {"referenceID": 13, "context": "This is known as the vanishing gradient problem, which is the key difficulty in training deep neural networks via back-propagation [14].", "startOffset": 131, "endOffset": 135}, {"referenceID": 0, "context": "Specifically, this paper attacks the vanishing gradient problem in the nonconvex optimization of the deep networks with non-smooth sign activation by continuation methods [1], which address a complex optimization problem by smoothing the original function, turning it into a different problem that is easier to optimize.", "startOffset": 171, "endOffset": 174}, {"referenceID": 34, "context": "Please refer to [35] for a comprehensive survey.", "startOffset": 16, "endOffset": 20}, {"referenceID": 29, "context": "Typical learning criteria include reconstruction error minimization [30, 12, 16] and graph learning[36, 24].", "startOffset": 68, "endOffset": 80}, {"referenceID": 11, "context": "Typical learning criteria include reconstruction error minimization [30, 12, 16] and graph learning[36, 24].", "startOffset": 68, "endOffset": 80}, {"referenceID": 15, "context": "Typical learning criteria include reconstruction error minimization [30, 12, 16] and graph learning[36, 24].", "startOffset": 68, "endOffset": 80}, {"referenceID": 35, "context": "Typical learning criteria include reconstruction error minimization [30, 12, 16] and graph learning[36, 24].", "startOffset": 99, "endOffset": 107}, {"referenceID": 23, "context": "Typical learning criteria include reconstruction error minimization [30, 12, 16] and graph learning[36, 24].", "startOffset": 99, "endOffset": 107}, {"referenceID": 18, "context": "Binary Reconstruction Embedding (BRE) [19] pursues hash functions by minimizing the squared errors between the distances of data points and the distances of their corresponding hash codes.", "startOffset": 38, "endOffset": 42}, {"referenceID": 26, "context": "Minimal Loss Hashing (MLH) [27] and Hamming Distance Metric Learning [28] learn hash codes by minimizing hinge-like loss functions based on similarity of data points.", "startOffset": 27, "endOffset": 31}, {"referenceID": 27, "context": "Minimal Loss Hashing (MLH) [27] and Hamming Distance Metric Learning [28] learn hash codes by minimizing hinge-like loss functions based on similarity of data points.", "startOffset": 69, "endOffset": 73}, {"referenceID": 22, "context": "Supervised Hashing with Kernels (KSH) [23] builds compact binary hash codes by minimizing the Hamming distances across similar pairs and maximizing the Hamming distances across dissimilar pairs.", "startOffset": 38, "endOffset": 42}, {"referenceID": 17, "context": "As deep convolutional neural network (CNN) [18, 13] yield breakthrough performance on many computer vision tasks, deep learning to hash has attracted attention recently.", "startOffset": 43, "endOffset": 51}, {"referenceID": 12, "context": "As deep convolutional neural network (CNN) [18, 13] yield breakthrough performance on many computer vision tasks, deep learning to hash has attracted attention recently.", "startOffset": 43, "endOffset": 51}, {"referenceID": 36, "context": "CNNH [37] adopts a two-stage strategy in which the first stage learns hash codes and the second stage learns a deepnetwork based hash function to fit the codes.", "startOffset": 5, "endOffset": 9}, {"referenceID": 19, "context": "DNNH [20] improved the two-stage CNNH with a simultaneous feature learning and hash coding pipeline such that representations and hash codes can be optimized in a joint learning process.", "startOffset": 5, "endOffset": 9}, {"referenceID": 39, "context": "DHN [40] further improves DNNH by a cross-entropy loss and a quantization loss which preserve the pairwise similarity and control the quantization error simultaneously.", "startOffset": 4, "endOffset": 8}, {"referenceID": 5, "context": "To perform deep learning to hash from imbalanced data, we jointly preserve similarity information of pairwise images and generate binary hash codes by weighted maximum likelihood [6].", "startOffset": 179, "endOffset": 182}, {"referenceID": 5, "context": "where P (S|H) is the weighted likelihood function, and cij is the weight for each training pair (xi,xj , sij), which is used to tackle the data imbalance problem by weighting the training pairs according to the importance of misclassifying that pair [6].", "startOffset": 250, "endOffset": 253}, {"referenceID": 13, "context": "This is known as the vanishing gradient problem, which has been a key difficulty in training deep neural networks via back-propagation [14].", "startOffset": 135, "endOffset": 139}, {"referenceID": 13, "context": "Many optimization methods have been proposed to circumvent the vanishing gradient problem and enable effective network training with back-propagation, including unsupervised pre-training [14, 3], dropout [33], batch normalization [15], and deep residual learning [13].", "startOffset": 187, "endOffset": 194}, {"referenceID": 2, "context": "Many optimization methods have been proposed to circumvent the vanishing gradient problem and enable effective network training with back-propagation, including unsupervised pre-training [14, 3], dropout [33], batch normalization [15], and deep residual learning [13].", "startOffset": 187, "endOffset": 194}, {"referenceID": 32, "context": "Many optimization methods have been proposed to circumvent the vanishing gradient problem and enable effective network training with back-propagation, including unsupervised pre-training [14, 3], dropout [33], batch normalization [15], and deep residual learning [13].", "startOffset": 204, "endOffset": 208}, {"referenceID": 14, "context": "Many optimization methods have been proposed to circumvent the vanishing gradient problem and enable effective network training with back-propagation, including unsupervised pre-training [14, 3], dropout [33], batch normalization [15], and deep residual learning [13].", "startOffset": 230, "endOffset": 234}, {"referenceID": 12, "context": "Many optimization methods have been proposed to circumvent the vanishing gradient problem and enable effective network training with back-propagation, including unsupervised pre-training [14, 3], dropout [33], batch normalization [15], and deep residual learning [13].", "startOffset": 263, "endOffset": 267}, {"referenceID": 25, "context": "In particular, Rectifier Linear Unit (ReLU) [26] activation function makes deep networks much easier to train and enables end-to-end learning algorithms.", "startOffset": 44, "endOffset": 48}, {"referenceID": 4, "context": "A very recent work, BinaryNet [5], focuses on training deep networks with activations constrained to +1 or \u22121.", "startOffset": 30, "endOffset": 33}, {"referenceID": 0, "context": "recent studies in continuation methods [1], which address a complex optimization problem by smoothing the original function, turning it into a different problem that is easier to optimize.", "startOffset": 39, "endOffset": 42}, {"referenceID": 28, "context": "ImageNet1 is a benchmark image dataset for Large Scale Visual Recognition Challenge (ILSVRC 2015) [29].", "startOffset": 98, "endOffset": 102}, {"referenceID": 3, "context": "NUS-WIDE2 [4] is a public Web image dataset which contains 269,648 images downloaded from Flickr.", "startOffset": 10, "endOffset": 13}, {"referenceID": 39, "context": "We follow similar experimental protocols as DHN [40] and randomly sample 5,000 images as queries, with the remaining images used as the database; furthermore, we randomly sample 10,000 images from the database as training points.", "startOffset": 48, "endOffset": 52}, {"referenceID": 21, "context": "MS COCO3 [22] is an image recognition, segmentation, and captioning dataset.", "startOffset": 9, "endOffset": 13}, {"referenceID": 36, "context": "Following standard evaluation protocol as previous work [37, 20, 40], the similarity information for hash function learning and for ground-truth evaluation is constructed from image labels: if two images i and j share at least one label, they are similar and sij = 1; otherwise, they are dissimilar and sij = 0.", "startOffset": 56, "endOffset": 68}, {"referenceID": 19, "context": "Following standard evaluation protocol as previous work [37, 20, 40], the similarity information for hash function learning and for ground-truth evaluation is constructed from image labels: if two images i and j share at least one label, they are similar and sij = 1; otherwise, they are dissimilar and sij = 0.", "startOffset": 56, "endOffset": 68}, {"referenceID": 39, "context": "Following standard evaluation protocol as previous work [37, 20, 40], the similarity information for hash function learning and for ground-truth evaluation is constructed from image labels: if two images i and j share at least one label, they are similar and sij = 1; otherwise, they are dissimilar and sij = 0.", "startOffset": 56, "endOffset": 68}, {"referenceID": 9, "context": "We compare the retrieval performance of HashNet with nine conventional or state-of-the-art hashing methods: unsupervised methods LSH [10], SH [36] and ITQ [12], supervised shallow methods BRE [19], KSH [23], and ITQ-CCA [12], and supervised deep methods CNNH [37], DNNH [20], and DHN [40].", "startOffset": 133, "endOffset": 137}, {"referenceID": 35, "context": "We compare the retrieval performance of HashNet with nine conventional or state-of-the-art hashing methods: unsupervised methods LSH [10], SH [36] and ITQ [12], supervised shallow methods BRE [19], KSH [23], and ITQ-CCA [12], and supervised deep methods CNNH [37], DNNH [20], and DHN [40].", "startOffset": 142, "endOffset": 146}, {"referenceID": 11, "context": "We compare the retrieval performance of HashNet with nine conventional or state-of-the-art hashing methods: unsupervised methods LSH [10], SH [36] and ITQ [12], supervised shallow methods BRE [19], KSH [23], and ITQ-CCA [12], and supervised deep methods CNNH [37], DNNH [20], and DHN [40].", "startOffset": 155, "endOffset": 159}, {"referenceID": 18, "context": "We compare the retrieval performance of HashNet with nine conventional or state-of-the-art hashing methods: unsupervised methods LSH [10], SH [36] and ITQ [12], supervised shallow methods BRE [19], KSH [23], and ITQ-CCA [12], and supervised deep methods CNNH [37], DNNH [20], and DHN [40].", "startOffset": 192, "endOffset": 196}, {"referenceID": 22, "context": "We compare the retrieval performance of HashNet with nine conventional or state-of-the-art hashing methods: unsupervised methods LSH [10], SH [36] and ITQ [12], supervised shallow methods BRE [19], KSH [23], and ITQ-CCA [12], and supervised deep methods CNNH [37], DNNH [20], and DHN [40].", "startOffset": 202, "endOffset": 206}, {"referenceID": 11, "context": "We compare the retrieval performance of HashNet with nine conventional or state-of-the-art hashing methods: unsupervised methods LSH [10], SH [36] and ITQ [12], supervised shallow methods BRE [19], KSH [23], and ITQ-CCA [12], and supervised deep methods CNNH [37], DNNH [20], and DHN [40].", "startOffset": 220, "endOffset": 224}, {"referenceID": 36, "context": "We compare the retrieval performance of HashNet with nine conventional or state-of-the-art hashing methods: unsupervised methods LSH [10], SH [36] and ITQ [12], supervised shallow methods BRE [19], KSH [23], and ITQ-CCA [12], and supervised deep methods CNNH [37], DNNH [20], and DHN [40].", "startOffset": 259, "endOffset": 263}, {"referenceID": 19, "context": "We compare the retrieval performance of HashNet with nine conventional or state-of-the-art hashing methods: unsupervised methods LSH [10], SH [36] and ITQ [12], supervised shallow methods BRE [19], KSH [23], and ITQ-CCA [12], and supervised deep methods CNNH [37], DNNH [20], and DHN [40].", "startOffset": 270, "endOffset": 274}, {"referenceID": 39, "context": "We compare the retrieval performance of HashNet with nine conventional or state-of-the-art hashing methods: unsupervised methods LSH [10], SH [36] and ITQ [12], supervised shallow methods BRE [19], KSH [23], and ITQ-CCA [12], and supervised deep methods CNNH [37], DNNH [20], and DHN [40].", "startOffset": 284, "endOffset": 288}, {"referenceID": 39, "context": "We adopt MAP@1000 for ImageNet dataset as each category has at most 1,300 images, and adopt MAP@5000 for the other two datasets as [40].", "startOffset": 131, "endOffset": 135}, {"referenceID": 6, "context": "For shallow hashing methods, we use AlexNet-fc7 deep features [7] as input, and for deep hashing methods, we directly use raw image pixels as input.", "startOffset": 62, "endOffset": 65}, {"referenceID": 17, "context": "We adopt the AlexNet architecture [18] for all deep hashing methods, and implement the proposed HashNet based on the open-source Caffe framework [17].", "startOffset": 34, "endOffset": 38}, {"referenceID": 16, "context": "We adopt the AlexNet architecture [18] for all deep hashing methods, and implement the proposed HashNet based on the open-source Caffe framework [17].", "startOffset": 145, "endOffset": 149}, {"referenceID": 39, "context": "7362 DHN [40] 0.", "startOffset": 9, "endOffset": 13}, {"referenceID": 19, "context": "6944 DNNH [20] 0.", "startOffset": 10, "endOffset": 14}, {"referenceID": 36, "context": "6099 CNNH [37] 0.", "startOffset": 10, "endOffset": 14}, {"referenceID": 22, "context": "5671 KSH [23] 0.", "startOffset": 9, "endOffset": 13}, {"referenceID": 11, "context": "5361 ITQ-CCA [12] 0.", "startOffset": 13, "endOffset": 17}, {"referenceID": 11, "context": "5019 ITQ [12] 0.", "startOffset": 9, "endOffset": 13}, {"referenceID": 18, "context": "6574 BRE [19] 0.", "startOffset": 9, "endOffset": 13}, {"referenceID": 35, "context": "6336 SH [36] 0.", "startOffset": 8, "endOffset": 12}, {"referenceID": 9, "context": "5101 LSH [10] 0.", "startOffset": 9, "endOffset": 13}, {"referenceID": 8, "context": "It is worth noting that, when using longer hash codes, the Hamming space will become increasingly sparse and very few data points fall within the Hamming ball with radius 2 [9].", "startOffset": 173, "endOffset": 176}, {"referenceID": 36, "context": "The standard maximum likelihood estimation has been widely adopted in previous work [37, 40].", "startOffset": 84, "endOffset": 92}, {"referenceID": 39, "context": "The standard maximum likelihood estimation has been widely adopted in previous work [37, 40].", "startOffset": 84, "endOffset": 92}, {"referenceID": 0, "context": "The histograms can be plotted by evenly dividing [0, 1] into 100 bins, and calculating the frequency of codes falling into each bin.", "startOffset": 49, "endOffset": 55}, {"referenceID": 0, "context": "The histograms in Figure 6 show that the DHN method can only generate continuous codes spanning across the whole range of [0, 1].", "startOffset": 122, "endOffset": 128}, {"referenceID": 6, "context": "Visualization of Hash Codes: We visualize the t-SNE [7] of hash codes generated by HashNet and DHN on ImageNet (for ease of visualization, we sample 10 categories) in Figure 7.", "startOffset": 52, "endOffset": 55}], "year": 2017, "abstractText": "Learning to hash has been widely applied to approximate nearest neighbor search for large-scale multimedia retrieval, due to its computation efficiency and retrieval quality. Deep learning to hash, which improves retrieval quality by end-to-end representation learning and hash encoding, has received increasing attention recently. Subject to the vanishing gradient difficulty in the optimization with binary activations, existing deep learning to hash methods need to first learn continuous representations and then generate binary hash codes in a separated binarization step, which suffer from substantial loss of retrieval quality. This paper presents HashNet, a novel deep architecture for deep learning to hash by continuation method, which learns exactly binary hash codes from imbalanced similarity data where the number of similar pairs is much smaller than the number of dissimilar pairs. The key idea is to attack the vanishing gradient problem in optimizing deep networks with non-smooth binary activations by continuation method, in which we begin from learning an easier network with smoothed activation function and let it evolve during the training, until it eventually goes back to being the original, difficult to optimize, deep network with the sign activation function. Comprehensive empirical evidence shows that HashNet can generate exactly binary hash codes and yield state-of-the-art multimedia retrieval performance on standard benchmarks.", "creator": "LaTeX with hyperref package"}}}