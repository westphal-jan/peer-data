{"id": "1702.00858", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Feb-2017", "title": "The Value of Inferring the Internal State of Traffic Participants for Autonomous Freeway Driving", "abstract": "Safe interaction with human drivers is one of the primary challenges for autonomous vehicles. In order to plan driving maneuvers effectively, the vehicle's control system must infer and predict how humans will behave based on their latent internal state (e.g., intentions and aggressiveness). This research uses a simple model for human behavior with unknown parameters that make up the internal states of the traffic participants and presents a method for quantifying the value of estimating these states and planning with their uncertainty explicitly modeled. An upper performance bound is established by an omniscient Monte Carlo Tree Search (MCTS) planner that has perfect knowledge of the internal states. A baseline lower bound is established by planning with MCTS assuming that all drivers have the same internal state. MCTS variants are then used to solve a partially observable Markov decision process (POMDP) that models the internal state uncertainty to determine whether inferring the internal state offers an advantage over the baseline. Applying this method to a freeway lane changing scenario reveals that there is a significant performance gap between the upper bound and baseline. POMDP planning techniques come close to closing this gap, especially when important hidden model parameters are correlated with measurable parameters.", "histories": [["v1", "Thu, 2 Feb 2017 22:38:10 GMT  (628kb,D)", "http://arxiv.org/abs/1702.00858v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["zachary sunberg", "christopher ho", "mykel kochenderfer"], "accepted": false, "id": "1702.00858"}, "pdf": {"name": "1702.00858.pdf", "metadata": {"source": "CRF", "title": "The Value of Inferring the Internal State of Traffic Participants for Autonomous Freeway Driving", "authors": ["Zachary N. Sunberg", "Christopher J. Ho", "Mykel J. Kochenderfer"], "emails": ["zsunberg@stanford.edu.", "cho3@stanford.edu.", "mykel@stanford.edu."], "sections": [{"heading": null, "text": "In fact, most people who are able to surpass themselves, to surpass themselves, to surpass themselves, and to survive, \"he said.\" I don't think they feel able to surpass themselves. \"He added,\" I don't think they are able to surpass themselves. \"He added,\" I don't think they are able to surpass themselves. \"He added,\" I don't think they are able to survive themselves. \"He added,\" I don't think they are able to surpass themselves, to be able to survive themselves, to survive themselves, to survive themselves, to penetrate themselves. \""}, {"heading": "II. MODEL", "text": "The focus of this work is on driving. We examine a scenario in which a vehicle must navigate from the outermost to the outermost lane of a four-lane highway as quickly as possible, while maintaining safety and comfort.During this section, x denotes the position in the longitudinal direction, i.e. the direction in which the cars move along the road in meters, and y the position in the transverse direction, i.e. the lane the car occupies in roadway units. The problem can be defined as a discrete time defined by the tuple (S, A, T, R, O, Z), which consists of \u2022 the state space, S: A system state, s = (q0, (qi, \u03b8i)} i \u2022 S, consists of the physical state of the first-person vehicle (q0) and the physical state and behavioral model for each of the other cars in the scene."}, {"heading": "A. Driver Modeling", "text": "The driver models for each car have two components: an acceleration model that regulates longitudinal movement, and a lane change model that determines lateral movement. In this paper, the acceleration model is the Intelligent Driver Model (IDM) [15], and the lane change model is the Minimizing Overall Breking Induced by Lane Change (MOBIL) model [16]. Both models have a small number of parameters that determine the driver's behavior.1) IDM: The IDM model was developed as a simple model for \"microscopic\" simulations of traffic flows and is able to reproduce some phenomena observed in real traffic flows. \u2212 It determines longitudinal acceleration for a human-driven car, x \"based on the desired distance gap to the previous car, g, absolute speed, x\" and speed relative to the previous car, x. \"Longitudinal acceleration is regulated by the following equation: x...\""}, {"heading": "B. Physical Dynamics", "text": "Physical dynamics is simplified for the sake of computational efficiency; time is divided into separate longitudinal steps; longitudinal dynamics assumes constant acceleration; and transverse dynamics assumes constant speed over time, which means that the speed may change immediately because cars on a motorway can achieve the lateral speed required to change lanes much shorter in time than by steering. If MOBIL determines that a lane change is to be made near the acceleration, the lateral speed is changed immediately because cars on a motorway can achieve the lateral speed required to change lanes much shorter in time than by steering. If MOBIL determines that a lane change is to be made near the lane, the lateral speed, y, is adjusted to the speed. If a lane change in the middle is not possible, the lane must not be reversed; y, y, y, y, y, y, y, c, if the lane change remains unchanged until the lane change is completed."}, {"heading": "C. Action Space for Crash-Free Driving", "text": "For the sake of simplicity, the vehicle selects up to ten individual measures. The vehicle can make an incremental decrease or increase in speed or maintain speed, and it can initiate a change of left or right lane or maintain the current lane. Combining these adjustments constitutes nine of the measures. The last measure is a braking action dynamically determined on the basis of the speed and position of the vehicle in front. At each step, the maximum allowable acceleration, amax, is the maximum acceleration that the ego could perform in such a way that if the vehicle in front brakes immediately at the physical limit, bmax, to a standstill, the ego will still be able to stop without exceeding the physical braking limits itself. The braking effect is (x, y, e) = (min {amax, \u2212 bnominal}, 0).The inclusion of the dynamic braking action guarantees that there is always an action to avoid a crash step that is not taken into account."}, {"heading": "D. Reward Function and Objectives", "text": "The qualitative objectives in solving this problem are to reach the target lane as quickly as possible and to increase the comfort and safety of both the ego and the other vehicles in the vicinity. Therefore, the following two measures are used to evaluate the planning performance: 1) the average time the ego takes to reach the target lane, and 2) the number of hard braking manoeuvres each vehicle makes during the time the ego takes to reach the target lane. A hard braking manoeuvre occurs whenever x < \u2212 bhard is selected, which is an unpleasantly abrupt deceleration. The number of hard braking manoeuvres is a proxy for both safety and comfort. To encourage the planner to take measures that maximize these indicators, the reward function for the POMDP is defined as follows: R (s, s \") = 1 (ye = ytarget) \u2212 N \u00b2 i = (x) < b \u00b2 b is then calculated for each initial lane as follows:"}, {"heading": "III. SOLUTION APPROACHES", "text": "Monte Carlo tree search (MCTS) is one of the most widely used and effective methods for solving decision-making problems online [13]. MCTS creates a tree consisting of alternating levels of nodes corresponding to actions and states. Value estimates (expected discounted cumulative rewards) are maintained for each action node. In this essay, we consider four variants of MCTS to solve different versions of the problem. All variants use the upper trust tree (UCT) [13] and double progressive magnification (DPW) [18], [19] changes to MCTS. When building the tree, UCT extends the action nodes that maximize an upper trust ratio, UCB (s, u) = Q (s, u) + c, lnN (s) N (s, u), with Q (s, u) increasing the action value function achieved by rollout simulations and tree searches, N (u) is the number of actionspaces inherited."}, {"heading": "A. Approach 1: Static Assumed Behavior (SAB)", "text": "The design defines a performance base, as if all cars behave according to a single static \"normal\" internal state (see Table I). In this case, it is an MDP that is solved using the MCTS-DPW algorithm."}, {"heading": "B. Approach 2: Most Likely Model Predictive Control (MLMPC)", "text": "Since information about the inner state of the human being can be derived by observing the physical movement of the car, performance can be higher than the SAB baseline by estimating what is possible online. This is achieved with a particle filter. \"Filtering is independent for each car, but all the behavior parameters for a particular car are estimated together. There are two versions of the filter. In the first version, the behavior parameters are assumed to be uncorrelated, so that a particle particle is used, so that a particle parameter consists of the values of all the model parameters. In the second version, all the parameters are assumed to be perfectly correlated (see section IV-A), so that a particle parameter consists of only one value, which is called\" aggressiveness. \"The belief at a given time consists of the exactly known physical state, q, and a collection of M particles, which are perfectly correlated (see section IV-A)."}, {"heading": "C. Approach 3: POMCP with Double Progressive Widening", "text": "The MCTS algorithm has been extended to handle domains with state uncertainty in the partially observable Monte Carlo Planning (POMCP) algorithm [22]. The root node of a POMCP tree corresponds to the current belief about the state maintained by the particle filter described above. Instead of the state nodes of the MCTS, POMCP uses history nodes that correspond to the sequence of actions and observations required to reach the node from the root. At each historical node, POMCP represents the current belief based on a collection of unweighted particles. In order to meet the challenges posed by the branching factor when using MCTS with continuous state points, we have adjusted POMCP to the use of DPW. Equation (7) is used to limit the number of children of each action node. In cases where a new history node is not generated, the next history node is selected from the previously known one, and the next history node is not generated in the current state."}, {"heading": "IV. RESULTS AND DISCUSSION", "text": "The calculation results of this study are designed to meet the two objectives: 1) quantify the size of the gap between the basic control algorithm and the maximum potential track change power, and 2) show in which cases the internal condition estimation and POMDP planning can approach the upper power limit. Experiments are conducted in three scenarios, each with different distribution of internal states. In each of these scenarios, each of the three solution methods described in Section III is compared with an approximate upper power limit, which is achieved by planning with perfect knowledge of the behavioral models."}, {"heading": "A. Driver Model Distribution Scenarios", "text": "We examined three scenarios of internal state distribution. In all of these scenarios, drivers behave aggressively according to the models IDM and MOBIL presented in Section II-A, but the parameter values IDM and MOBIL are distributed differently. Table I shows typical parameter values for aggressive, anxious and normal drivers. The values come from [17], but some have been slightly adjusted so that the parameters for the normal driver are exactly halfway between the values for anxious and aggressive drivers. In Scenario 1, all parameters are distributed independently of each other. In Scenario 2, all parameters are evenly distributed between the aggressive and anxious values. The difference between the scenarios is the correlation of the parameter values. In Scenario 1, all parameters are distributed independently of each other. In Scenario 2, all parameters are perfectly correlated to parameters 1, so that all parameters represent deterministic functions of the aggressiveness of the driver."}, {"heading": "B. Performance Results", "text": "Since the conservativeness of all solution techniques can essentially be adapted by changing \u03bb in (6), 500 simulations using a reward function with \u03bb were set to the values in Table II. The average time required to achieve the target track and the average number of braking operations per episode, however, is assigned, and a linear interpolation between these points yields an approximation to the Pareto-optimal limit. In all cases, there is a significant performance gap between the upper limit and the average number of braking operations per episode, which behave all cars according to the normal values of the driver model, and a linear interpolation between these points leads to an approximation of the Pareto-optimal limit. In Scenario 1, if it is acceptable to have an average of 0.5 hard braking operations per episode, then the omnicient planner is able to achieve the track in an average of 9.0 s (50% less time than the base line if the vehicle is SAB)."}, {"heading": "V. CONCLUSION", "text": "In the simplified case we have examined, this gap has been found to be significant. Furthermore, we have shown that using a simple particle filter can provide significantly improved performance, especially when internal state characteristics are highly correlated, and planning with a POMDP model can further reduce the gap. The method described in this paper is extremely flexible and adaptable, all you need to do is define a generative model for states, rewards, and observations, and possibly adjust some algorithm parameters to adapt them to a new domain, making it useful as a preliminary analytical tool to decide what control approach to adopt on an actual vehicle. In the specific case of lane change, the most important finding of this research is that the distribution of behavior models in the driver population is a critical factor in determining the performance improvement that can be achieved by estimating internal state and planning in a way that takes into account uncertainty in the actual states in which internal states are correlated."}], "references": [{"title": "A preliminary analysis of real-world crashes involving self-driving vehicles", "author": ["B. Schoettle", "M. Sivak"], "venue": "University of Michigan Transportation Research Institute, Tech. Rep. UMTRI-2015-34, 2015.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2015}, {"title": "Decision making under uncertainty: Theory and application", "author": ["M.J. Kochenderfer"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2015}, {"title": "Solving continuous POMDPs: Value iteration with incremental learning of an efficient space representation", "author": ["S. Brechtel", "T. Gindele", "R. Dillmann"], "venue": "International Conference on Machine Learning (ICML), 2013.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2013}, {"title": "Information gathering actions over human internal state", "author": ["D. Sadigh", "S.S. Sastry", "S.A. Seshia", "A. Dragan"], "venue": "IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2016.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2016}, {"title": "Intention-aware online POMDP planning for autonomous driving in a crowd", "author": ["H. Bai", "S. Cai", "N. Ye", "D. Hsu", "W.S. Lee"], "venue": "IEEE International Conference on Robotics and Automation (ICRA), 2015.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2015}, {"title": "Improving human-in-the-loop decision making in multi-mode driver assistance systems using hidden mode stochastic hybrid systems", "author": ["C.-P. Lam", "A.Y. Yang", "K. Driggs-Campbell", "R. Bajcsy", "S.S. Sastry"], "venue": "IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2015.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "Identifying modes of intent from driver behaviors in dynamic environments", "author": ["K. Driggs-Campbell", "R. Bajcsy"], "venue": "IEEE International Conference on Intelligent Transportation Systems (ITSC), 2015.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning driver behavior models from traffic observations for decision making and planning", "author": ["T. Gindele", "S. Brechtel", "R. Dillmann"], "venue": "IEEE Intelligent Transportation Systems Magazine, vol. 7, no. 1, pp. 69\u201379, 2015.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2015}, {"title": "A probabilistic framework for microscopic traffic propagation", "author": ["T.A. Wheeler", "P. Robbel", "M.J. Kochenderfer"], "venue": "IEEE International Conference on Intelligent Transportation Systems (ITSC), 2015.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2015}, {"title": "Data-driven probabilistic modeling and verification of human driver behavior", "author": ["D. Sadigh", "K. Driggs-Campbell", "A. Puggelli", "V.S.W. Li", "R. Bajcsy", "A.L. Sangiovanni-Vincentelli", "S.S. Sastry", "S.A. Seshia"], "venue": "AAAI Spring Symposium on Formal Verification and Modeling in Human-Machine Systems, 2014.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}, {"title": "Continuous inverse optimal control with locally optimal examples", "author": ["S. Levine", "V. Koltun"], "venue": "International Conference on Machine Learning (ICML), 2012.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2012}, {"title": "Planning for autonomous cars that leverage effects on human actions", "author": ["D. Sadigh", "S.S. Sastry", "S.A. Seshia", "A. Dragan"], "venue": "Robotics: Science and Systems, 2016.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2016}, {"title": "A survey of Monte Carlo tree search methods", "author": ["C.B. Browne", "E. Powley", "D. Whitehouse", "S.M. Lucas", "P.I. Cowling", "P. Rohlfshagen", "S. Tavener", "D. Perez", "S. Samothrakis", "S. Colton"], "venue": "IEEE Transactions on Computational Intelligence and AI in Games, vol. 4, no. 1, pp. 1\u201343, 2012.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2012}, {"title": "Humans are slamming into driverless cars and exposing a key flaw, [Online]. Available: http://bloom.bg/1Qw8fjB", "author": ["K. Naughton"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2015}, {"title": "Congested traffic states in empirical observations and microscopic simulations", "author": ["M. Treiber", "A. Hennecke", "D. Helbing"], "venue": "Physical Review E, vol. 62, no. 2, pp. 1805\u20131824, 2 2000.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1805}, {"title": "General lane-changing model MOBIL for car-following models", "author": ["A. Kesting", "M. Treiber", "D. Helbing"], "venue": "Transportation Research Record, vol. 1999, pp. 86\u201394, 2007.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1999}, {"title": "Agents for traffic simulation", "author": ["\u2014\u2014"], "venue": "Multi Agent Systems: Simulation and Applications, A. M. Uhrmacher and D. Weyns, Eds., CRC Press, 2009, ch. 11, pp. 325\u2013356.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2009}, {"title": "A comparison of Monte Carlo tree search and mathematical optimization for large scale dynamic resource allocation", "author": ["D. Bertsimas", "J.D. Griffith", "V. Gupta", "M.J. Kochenderfer", "V.V. Mi\u0161i\u0107", "R. Moss"], "venue": "ArXiv e-prints, May 2014. arXiv: 1405.5498.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2014}, {"title": "Continuous upper confidence trees", "author": ["A. Cou\u00ebtoux", "J.-B. Hoock", "N. Sokolovska", "O. Teytaud", "N. Bonnard"], "venue": "Learning and Intelligent Optimization, 2011.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2011}, {"title": "Model predictive control: Theory and practicea survey", "author": ["C.E. Garcia", "D.M. Prett", "M. Morari"], "venue": "Automatica, vol. 25, no. 3, pp. 335\u2013348, 1989.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1989}, {"title": "Monte-Carlo planning in large POMDPs", "author": ["D. Silver", "J. Veness"], "venue": "Advances in Neural Information Processing Systems (NIPS), 2010.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2010}, {"title": "DESPOT: Online POMDP planning with regularization", "author": ["A. Somani", "N. Ye", "D. Hsu", "W.S. Lee"], "venue": "Advances in Neural Information Processing Systems (NIPS), 2013.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2013}, {"title": "Heterogeneity in car-following behavior: Theory and empirics", "author": ["S. Ossen", "S.P. Hoogendoorn"], "venue": "Transportation Research Part C: Emerging Technologies, vol. 19, no. 2, pp. 182\u2013195, 2011.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2011}, {"title": "Driver intent inference at urban intersections using the intelligent driver model", "author": ["M. Liebner", "M. Baumann", "F. Klanner", "C. Stiller"], "venue": "Intelligent Vehicles Symposium, 2012.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2012}], "referenceMentions": [{"referenceID": 0, "context": "However, the autonomous vehicles actually had a higher accident rate than average for a conventional vehicle in the United States because of accidents for which they were not legally responsible [1].", "startOffset": 195, "endOffset": 198}, {"referenceID": 1, "context": "This paper explores techniques based on Markov decision processes (MDPs) and partially observable Markov decision processes (POMDPs) [2].", "startOffset": 133, "endOffset": 136}, {"referenceID": 2, "context": "POMDPs are particularly well suited for modeling decisions for autonomous vehicles because it explicitly captures the limitations of the vehicle\u2019s sensors in measuring the relevant state variables [3]\u2013[5].", "startOffset": 197, "endOffset": 200}, {"referenceID": 4, "context": "POMDPs are particularly well suited for modeling decisions for autonomous vehicles because it explicitly captures the limitations of the vehicle\u2019s sensors in measuring the relevant state variables [3]\u2013[5].", "startOffset": 201, "endOffset": 204}, {"referenceID": 3, "context": ", intentions and aggressiveness) of other drivers and road users can only be indirectly inferred [4]\u2013[7].", "startOffset": 97, "endOffset": 100}, {"referenceID": 6, "context": ", intentions and aggressiveness) of other drivers and road users can only be indirectly inferred [4]\u2013[7].", "startOffset": 101, "endOffset": 104}, {"referenceID": 7, "context": "uses a very simple model, there has been significant work on creating better models in recent years [8]\u2013[10], and the POMDP planning methods that we use can easily be adapted to use these new models.", "startOffset": 100, "endOffset": 103}, {"referenceID": 9, "context": "uses a very simple model, there has been significant work on creating better models in recent years [8]\u2013[10], and the POMDP planning methods that we use can easily be adapted to use these new models.", "startOffset": 104, "endOffset": 108}, {"referenceID": 10, "context": "For these cases, inverse reinforcement learning can be used to determine a suitable reward function based on data of how human drivers act [11], [12].", "startOffset": 139, "endOffset": 143}, {"referenceID": 11, "context": "For these cases, inverse reinforcement learning can be used to determine a suitable reward function based on data of how human drivers act [11], [12].", "startOffset": 145, "endOffset": 149}, {"referenceID": 12, "context": "This paper presents a method that involves comparing solutions obtained from several variations of Monte Carlo Tree Search [13].", "startOffset": 123, "endOffset": 127}, {"referenceID": 13, "context": "For this research, we have chosen to investigate these ideas in the context of making lane changes on a freeway (a situation that has been anecdotally noted to be difficult [14]).", "startOffset": 173, "endOffset": 177}, {"referenceID": 14, "context": "In this paper, the acceleration model is the Intelligent Driver Model (IDM) [15], and the lane change model is the \u201cMinimizing Overall Braking Induced by Lane change\u201d (MOBIL) model [16].", "startOffset": 76, "endOffset": 80}, {"referenceID": 15, "context": "In this paper, the acceleration model is the Intelligent Driver Model (IDM) [15], and the lane change model is the \u201cMinimizing Overall Braking Induced by Lane change\u201d (MOBIL) model [16].", "startOffset": 181, "endOffset": 185}, {"referenceID": 0, "context": "The parameter p \u2208 [0, 1] is the politeness factor, which represents how much the driver values allowing other vehicles to increase their acceleration.", "startOffset": 18, "endOffset": 24}, {"referenceID": 16, "context": "Since the IDM and MOBIL models are both crash-free [17], and actions that lead to crashes for the ego are not considered, no crashes occur in the simulation.", "startOffset": 51, "endOffset": 55}, {"referenceID": 12, "context": "Monte Carlo tree search (MCTS) is one of the most widely used and effective methods for solving decisionmaking problems online [13].", "startOffset": 127, "endOffset": 131}, {"referenceID": 12, "context": "All of the variants make use of the upper confidence tree (UCT) [13] and double progressive widening (DPW) [18], [19] modifications to MCTS.", "startOffset": 64, "endOffset": 68}, {"referenceID": 17, "context": "All of the variants make use of the upper confidence tree (UCT) [13] and double progressive widening (DPW) [18], [19] modifications to MCTS.", "startOffset": 107, "endOffset": 111}, {"referenceID": 18, "context": "All of the variants make use of the upper confidence tree (UCT) [13] and double progressive widening (DPW) [18], [19] modifications to MCTS.", "startOffset": 113, "endOffset": 117}, {"referenceID": 0, "context": "where \u1e8b\u2032 and y\u2032 are taken from the observation, \u02c6\u0307 x\u2032 and \u02c6\u0307 y\u2032 are from \u015dk\u2032, the exponential expression is proportional to the Gaussian probability density function (from the acceleration noise), and \u03b3lane \u2208 [0, 1] is a hand-tuned parameter that penalizes incorrect lane changes.", "startOffset": 209, "endOffset": 215}, {"referenceID": 19, "context": "Model predictive control (MPC) is a widely used family of control techniques that use an imperfect model and feedback measurements to choose actions [21].", "startOffset": 149, "endOffset": 153}, {"referenceID": 20, "context": "Monte Carlo planning (POMCP) algorithm [22].", "startOffset": 39, "endOffset": 43}, {"referenceID": 16, "context": "The values are taken from [17],", "startOffset": 26, "endOffset": 30}, {"referenceID": 21, "context": "be beneficial to try more advanced POMDP solvers such as DESPOT [23].", "startOffset": 64, "endOffset": 68}, {"referenceID": 22, "context": "Thus far, only inter-vehicle internal state heterogeneity has been considered, but real drivers also change their behavior over time and in response to stimuli [24], and it may be useful to model this when planning.", "startOffset": 160, "endOffset": 164}, {"referenceID": 23, "context": "Moreover, it may be even more beneficial to take a driver\u2019s specific intentions into account when planning [25].", "startOffset": 107, "endOffset": 111}], "year": 2017, "abstractText": "Safe interaction with human drivers is one of the primary challenges for autonomous vehicles. In order to plan driving maneuvers effectively, the vehicle\u2019s control system must infer and predict how humans will behave based on their latent internal state (e.g., intentions and aggressiveness). This research uses a simple model for human behavior with unknown parameters that make up the internal states of the traffic participants and presents a method for quantifying the value of estimating these states and planning with their uncertainty explicitly modeled. An upper performance bound is established by an omniscient Monte Carlo Tree Search (MCTS) planner that has perfect knowledge of the internal states. A baseline lower bound is established by planning with MCTS assuming that all drivers have the same internal state. MCTS variants are then used to solve a partially observable Markov decision process (POMDP) that models the internal state uncertainty to determine whether inferring the internal state offers an advantage over the baseline. Applying this method to a freeway lane changing scenario reveals that there is a significant performance gap between the upper bound and baseline. POMDP planning techniques come close to closing this gap, especially when important hidden model parameters are correlated with measurable parameters.", "creator": "LaTeX with hyperref package"}}}