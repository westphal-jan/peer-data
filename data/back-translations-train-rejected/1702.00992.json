{"id": "1702.00992", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Feb-2017", "title": "Automatic Prediction of Discourse Connectives", "abstract": "Accurate prediction of suitable discourse connectives (however, furthermore, etc.) is a key component of any system aimed at building coherent and fluent discourses from shorter sentences and passages. As an example, a dialog system might assemble a long and informative answer by sampling passages extracted from different documents retrieved from the web. We formulate the task of discourse connective prediction and release a dataset of 2.9M sentence pairs separated by discourse connectives for this task. Then, we evaluate the hardness of the task for human raters, apply a recently proposed decomposable attention (DA) model to this task and observe that the automatic predictor has a higher F1 than human raters (32 vs. 30). Nevertheless, under specific conditions the raters still outperform the DA model, suggesting that there is headroom for future improvements. Finally, we further demonstrate the usefulness of the connectives dataset by showing that it improves implicit discourse relation prediction when used for model pre-training.", "histories": [["v1", "Fri, 3 Feb 2017 13:06:25 GMT  (135kb,D)", "http://arxiv.org/abs/1702.00992v1", "9 pages"]], "COMMENTS": "9 pages", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["eric malmi", "daniele pighin", "sebastian krause", "mikhail kozhevnikov"], "accepted": false, "id": "1702.00992"}, "pdf": {"name": "1702.00992.pdf", "metadata": {"source": "CRF", "title": "Automatic Prediction of Discourse Connectives", "authors": ["Eric Malmi", "Daniele Pighin", "Sebastian Krause", "Mikhail Kozhevnikov"], "emails": ["eric.malmi@aalto.fi", "biondo@google.com", "qnan@google.com", "sebastian.krause@dfki.de"], "sections": [{"heading": "1 Introduction", "text": "Discourse connectors, also referred to as discourse markers, are used to link problems with each other and to explicate the relationship between pieces of text. It is a common linguistic class exercise that must be asked to imply appropriate connectives to a text in order to improve the flow of text. Similarly, for computerized summarization and text fitting systems, it is important to imply appropriate connectives that appear at the beginning of a sentence during an internship at Google.course to produce connective connectives that have an automatic discourse-linking prediction, many concrete use cases. For example, in a questioning setting, it could help to generate answers by collecting sentences from multiple sources, which could be used to extract text marker rates."}, {"heading": "2 Related Work", "text": "The problem of identifying implicit discourse relationships has attracted considerable attention in recent years, but to the best of our knowledge there is no previous work focusing on predicting discourse connections. Both problems can be seen as examples of the broader class of bi-sequence classification tasks (Laha and Raykar, 2016).Currently, the best working methods for the relation prediction task are those introduced by Liu and Li (2016), who proposed a bi-directional LSTM with multi-level attention, and by Rutherford and Xue (2014), who used Brown cluster pairs and co-reference patterns. Pitler et al. (2008) showed that when a discourse connection-related discourse relationship is known, the (explicit) discourse relationship can be derived with an accuracy of 93.09%, which has inspired several efforts to predict connectives in order to improve implicit discourse relationships."}, {"heading": "3 Data Collection", "text": "We compile a list of 79 discourse connectors based on the Penn Discourse Treebank (PDTB) (Prasad et al., 2008). Since our focus is on sentence concatenation, we ignore the connectors that typically refer to the following sentence (forward) rather than the previous one, such as \"After the election.\" But for several ambiguous connectors, forward use can be excluded by asking for a comma after the connective (e.g.); we include such connectors in our data. Discontinuitative connectors, such as \"If [...] then [.] are not included.\" Data samples for discourse connectivity can be collected from any large uncommented text corpus. In this case, we use English Wikipedia2 and collect each pair of consecutive sentences within the same paragraph, the latter sentence beginning with one of the 79 discourse connectors."}, {"heading": "3.1 Comparison with the Penn Discourse Treebank", "text": "The most commonly used dataset for computational discourse studies is the Penn Discourse Treebank (PDTB) (Prasad et al., 2008), which is based on a series of 2,159 articles in the Wall Street Journal, while our dataset is based on all articles in Wikipedia.PDTB 18,459 contains explicit discourse relationships in which the discourse connective exists, and 16,224 implicit discourse relationships. Human commentators have divided the relationships into four major semantic classes, which have also assigned implicit connections to the implicit discourse relationships. Most discourse studies focus on the implicit discourse relationships by dividing the prediction task into four major binary problems along the four major classes. PDTB is divided into 22 sections, and it is common practice to use sections 2-20 to develop implicit connections for the most important data relationships, Table 21-1, and the two new ones are the two most important data sets."}, {"heading": "4 Connective prediction models", "text": "The decomposable attention model (DA) was recently introduced by Parikh et al. (2016) for the problem of natural language inference (NLI), which aims to classify relationships and contradictions between a premise and a hypothesis. Discourse-connective predictions are related to the NLI3For example, the PDTB test theorem contains only 55 positive examples of the temporal relationship. Nevertheless, studies on implicit discourse relationships often present the results without statistical significance tests to measure whether the differences between the models are significant. H () + +... + = in the park alice playsso meo nepl ayin gm usicou tsid flowed a solo G (,) G (,) park outsidealice someoneflute + solo music... G (,) = = flute music F (,) Figure 2: Overview of the decomposable attention model."}, {"heading": "4.1 The Decomposable Attention Model", "text": "The DA model consists of three steps performed by three different forward-facing neural networks F, G, and H, as shown in Figure 2. As input, the model takes two sets a and b, which are represented by sequences of word embeddings. \"NULL\" characters are added to the sequences to set their lengths to 50 tokens. In the procedure (Network F), the model calculates non-negative attention values for each input token pair over the two input sentences. This calculation ignores the order of the tokens and generates soft alignments from a to b and vice versa. In the comparison step (Network G), the model calculates comparison vectors between each input token character and its aligned subphrase. The aligned subphrase is a linear combination of the embedded vectors of the other model, weighted by attention."}, {"heading": "4.2 The Word-Pair Baseline", "text": "The WORDPAIRS method takes into account all word pairs that occur via the two arguments (e.g. word A appears in Arg 1 and word B in Arg 2) in at least five samples of the training data set. Furthermore, it contains individual word characteristics (e.g. word A appears in Arg 2), as these slightly improved the results. We use these characteristics to train logistic regressors that use the one-on-one scheme to predict one of the 20 different connections. 4"}, {"heading": "5 Experiments", "text": "Next, we present experimental results on the discourse-linking prediction using human raters, the DA model, and the WORDPAIRS base model 4We trained two versions of the WORDPAIRS model: one with stochastic gradient descent with mini-batches, and another with LIBLINEAR with 100k samples (i.e. 25% of the training data) that we were able to insert into the memory of a single 256GB machine. The results we report are those obtained using the latter approach, which worked better. For this task, we remove the connecting (if any) set from each test pair and measure the ability of the model (or the raters) to identify the remote connecting (or [no connecting] set if the second set does not start with one). In addition, we present results on the implicit discourse relationship prediction using the data set collected to pre-train the DA model."}, {"heading": "5.1 Accuracy of Human Raters", "text": "A manual inspection of the data set shows that it is often difficult to deduce from it the connecting sentence that appears in the Wikipedia article. In some cases, the relationship between the two sentences may be unclear, or there may be several appropriate options. In other cases, a larger context than the previous sentence is required to infer the connecting sentence. For example, to correctly decide whether the two sentences are ultimately more suitable than then, one needs to examine a larger context. To better understand what is to be expected from an automatic predictor, we use a crowdsourcing platform to ask human raters to reconstruct the remote connectors for each of the 10,000 test set pairs. Each sentence pair is commented by three guesses to whom the two sentences are shown, the latter starting with a [Connective goes here] placeholder and being asked to select the most suitable connectors from the 20 options, including [No Connective]."}, {"heading": "5.2 Accuracy of the Models", "text": "In this section, the DA model is used to perform the same task as the human raters, i.e. to learn to reconstruct the connective tissue that may have been removed from the beginning of the second set in each test pair. A balanced dataset is used for both training and testing the models as in Section 3. The DA model is evaluated using the following hyperparameters optimized on the development set: network size (a hidden layer of 200 neurons), batch size (64), failure rates for the F, G and H networks (0.68, 0.14 and 0.44, respectively) and learning rate (0.0018). The model is implemented in TensorFlow (Abadi et al., 2015) and the training is performed in 300,000 batch increments. The results recorded in Table 2 show that DA significantly exceeds the WORDPAIRS baseline with an F1 score of 31.80 vs. 14.81."}, {"heading": "5.3 Comparison between the Raters and the Decomposable Attention Model", "text": "Table 3 compares the accuracy of the DA predictions with the rate decisions. However, the macro-averaged F1 value of human raters is 23.72, which is remarkably lower than the F1 value of the DAmodel, 31.80. The difference is smaller if one considers majority decisions only for the 5,714 tasks for which there is consensus among at least 2 out of 3 rating groups, resulting in a 30.36 F1 value for the raters. However, in these less ambivalent cases, the model performance is expected to increase to 32.68. As we mentioned in Section 5.1, human raters are significantly less eager to introduce a connective than Wikipedia editors. Therefore, we also evaluate the environment in which either the Ground Truth Designation or the Rater Assigned Majority Designation or the Model Assigned Labeling is [non-connective]. The results listed in the last row of Table 3 show that the human model conditions actually perform better under these model conditions than those human ones."}, {"heading": "5.4 Model Interpretation", "text": "One advantage of the DA model is that it is possible to examine which words the model pays attention to when concluding a binder. In some cases, the words visited are clearly significant semantically or linguistically, while in other cases the matrix of soft alignment is more difficult to interpret. Examples of the first case are shown in Figure 4, which shows the alignment matrices from the signs of the first sentence (y-axis) to the signs of the second sentence (x-axis), so that lines 1 result. However, in the first example, the model correctly predicts as a binder after aligning the word experiment with waste and not. These word pairs indicate contrast, but a probable connection. In the second case, the model aligns the phrase with which it disappeared and correctly predicts as a binder at that point in time. The corresponding tendencies, i.e. past or past perfect, are probable indications of its presence up to that point."}, {"heading": "5.5 Implicit Discourse Relation Prediction", "text": "In this section, we will examine the usefulness of connecting datasets for the related task of implicit discourse relationships, which have been extensively studied in the literature (Marcu and Echihabi, 2002; Pitler et al., 2009; Rutherford and Xue, 2014). This work typically uses the PDTB datasets described in Section 3.1 to train and evaluate the models. Various studies have shown that the performance of relation predictions can be improved by using discourse connection data (Zhou et al., 2012; Liu et al., Rutherford and Xue, 2015), which are at the center of these experiments. Model Fine-Tuning: We adopt a method similar to Rutherford and Xue."}, {"heading": "6 Conclusions", "text": "We have collected and made publicly available a data set of 2.9 million pairs of consecutive sets and connectives to facilitate further research into this problem and other related classification tasks. We have shown that the recently proposed disassembled attention model performs surprisingly well in the connective prediction task, even better than human raters in the same representative test set, which consists of 10,000 samples. In contrast to the model, human raters have a preference for implicit connectives because they outperform the model when the comparison is limited to cases where the majority of raters agree on an explicit connective. Alignment matrices generated by the model indicate that the predictor picks up relevant lexical, syntactical and semantic cues."}], "references": [{"title": "Tensorflow: Large-scale machine learning on heterogeneous systems", "author": ["Mart\u0131n Abadi", "Ashish Agarwal", "Paul Barham", "Eugene Brevdo", "Zhifeng Chen", "Craig Citro", "Greg S Corrado", "Andy Davis", "Jeffrey Dean", "Matthieu Devin"], "venue": null, "citeRegEx": "Abadi et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Abadi et al\\.", "year": 2015}, {"title": "Layer normalization", "author": ["Jimmy Lei Ba", "Jamie Ryan Kiros", "Geoffrey E Hinton."], "venue": "arXiv preprint arXiv:1607.06450 .", "citeRegEx": "Ba et al\\.,? 2016", "shortCiteRegEx": "Ba et al\\.", "year": 2016}, {"title": "An empirical evaluation of various deep learning architectures for bi-sequence classification tasks", "author": ["Anirban Laha", "Vikas Raykar."], "venue": "Proc. COLING.", "citeRegEx": "Laha and Raykar.,? 2016", "shortCiteRegEx": "Laha and Raykar.", "year": 2016}, {"title": "Reducing sparsity improves the recognition of implicit discourse relations", "author": ["Junyi Jessy Li", "Ani Nenkova."], "venue": "Proc. SIGDIAL.", "citeRegEx": "Li and Nenkova.,? 2014", "shortCiteRegEx": "Li and Nenkova.", "year": 2014}, {"title": "Recognizing implicit discourse relations via repeated reading: Neural networks with multi-level attention", "author": ["Yang Liu", "Sujian Li."], "venue": "Proc. EMNLP.", "citeRegEx": "Liu and Li.,? 2016", "shortCiteRegEx": "Liu and Li.", "year": 2016}, {"title": "Implicit discourse relation classification via multi-task neural networks", "author": ["Yang Liu", "Sujian Li", "Xiaodong Zhang", "Zhifang Sui."], "venue": "Proc. AAAI.", "citeRegEx": "Liu et al\\.,? 2016", "shortCiteRegEx": "Liu et al\\.", "year": 2016}, {"title": "An unsupervised approach to recognizing discourse relations", "author": ["Daniel Marcu", "Abdessamad Echihabi."], "venue": "Proc. ACL.", "citeRegEx": "Marcu and Echihabi.,? 2002", "shortCiteRegEx": "Marcu and Echihabi.", "year": 2002}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean."], "venue": "Proc. NIPS.", "citeRegEx": "Mikolov et al\\.,? 2013", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "A decomposable attention model for natural language inference", "author": ["Ankur P Parikh", "Oscar T\u00e4ckstr\u00f6m", "Dipanjan Das", "Jakob Uszkoreit."], "venue": "Proc. EMNLP.", "citeRegEx": "Parikh et al\\.,? 2016", "shortCiteRegEx": "Parikh et al\\.", "year": 2016}, {"title": "Predicting the presence of discourse connectives", "author": ["Gary Patterson", "Andrew Kehler."], "venue": "Proc. EMNLP.", "citeRegEx": "Patterson and Kehler.,? 2013", "shortCiteRegEx": "Patterson and Kehler.", "year": 2013}, {"title": "Automatic sense prediction for implicit discourse relations in text", "author": ["Emily Pitler", "Annie Louis", "Ani Nenkova."], "venue": "Proc. ACL-IJCNLP.", "citeRegEx": "Pitler et al\\.,? 2009", "shortCiteRegEx": "Pitler et al\\.", "year": 2009}, {"title": "Easily identifiable discourse relations", "author": ["Emily Pitler", "Mridhula Raghupathy", "Hena Mehta", "Ani Nenkova", "Alan Lee", "Aravind K Joshi."], "venue": "Proc. Coling 2008: Companion volume: Posters and Demonstrations.", "citeRegEx": "Pitler et al\\.,? 2008", "shortCiteRegEx": "Pitler et al\\.", "year": 2008}, {"title": "The penn discourse treebank", "author": ["Rashmi Prasad", "Nikhil Dinesh", "Alan Lee", "Eleni Miltsakaki", "Livio Robaldo", "Aravind K Joshi", "Bonnie L Webber"], "venue": null, "citeRegEx": "Prasad et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Prasad et al\\.", "year": 2008}, {"title": "Discovering implicit discourse relations through brown cluster pair representation and coreference patterns", "author": ["Attapol Rutherford", "Nianwen Xue."], "venue": "Proc. EACL.", "citeRegEx": "Rutherford and Xue.,? 2014", "shortCiteRegEx": "Rutherford and Xue.", "year": 2014}, {"title": "Improving the inference of implicit discourse relations via classifying explicit discourse connectives", "author": ["Attapol Rutherford", "Nianwen Xue."], "venue": "Proc. NAACL-HLT .", "citeRegEx": "Rutherford and Xue.,? 2015", "shortCiteRegEx": "Rutherford and Xue.", "year": 2015}, {"title": "Using automatically labelled examples to classify rhetorical relations: An assessment", "author": ["Caroline Sporleder", "Alex Lascarides."], "venue": "Natural Language Engineering 14(03):369\u2013416.", "citeRegEx": "Sporleder and Lascarides.,? 2008", "shortCiteRegEx": "Sporleder and Lascarides.", "year": 2008}, {"title": "Connective prediction using machine learning for implicit discourse relation classification", "author": ["Yu Xu", "Man Lan", "Yue Lu", "Zheng Yu Niu", "Chew Lim Tan."], "venue": "Proc. IJCNN.", "citeRegEx": "Xu et al\\.,? 2012", "shortCiteRegEx": "Xu et al\\.", "year": 2012}, {"title": "The effects of discourse connectives prediction on implicit discourse relation recognition", "author": ["Zhi Min Zhou", "Man Lan", "Zheng Yu Niu", "Yu Xu", "Jian Su."], "venue": "Proc. SIGDIAL.", "citeRegEx": "Zhou et al\\.,? 2010", "shortCiteRegEx": "Zhou et al\\.", "year": 2010}], "referenceMentions": [{"referenceID": 17, "context": "In the literature, discourse connective prediction has been mainly studied as an intermediate step for the well-studied problem of implicit discourse relation prediction (Zhou et al., 2010; Xu et al., 2012).", "startOffset": 170, "endOffset": 206}, {"referenceID": 16, "context": "In the literature, discourse connective prediction has been mainly studied as an intermediate step for the well-studied problem of implicit discourse relation prediction (Zhou et al., 2010; Xu et al., 2012).", "startOffset": 170, "endOffset": 206}, {"referenceID": 8, "context": "We show that a recently proposed decomposable attention model (Parikh et al., 2016) yields a good experimental performance on the connective prediction task.", "startOffset": 62, "endOffset": 83}, {"referenceID": 2, "context": "Both problems can be seen as instances of the broader class of bi-sequence classification tasks (Laha and Raykar, 2016).", "startOffset": 96, "endOffset": 119}, {"referenceID": 2, "context": "Both problems can be seen as instances of the broader class of bi-sequence classification tasks (Laha and Raykar, 2016). The currently best performing methods for the relation prediction task are those introduced by Liu and Li (2016), who proposed a bidirectional LSTM with multi-level attention, and by Rutherford and Xue (2014), who employed Brown cluster pairs and co-reference patterns.", "startOffset": 97, "endOffset": 234}, {"referenceID": 2, "context": "Both problems can be seen as instances of the broader class of bi-sequence classification tasks (Laha and Raykar, 2016). The currently best performing methods for the relation prediction task are those introduced by Liu and Li (2016), who proposed a bidirectional LSTM with multi-level attention, and by Rutherford and Xue (2014), who employed Brown cluster pairs and co-reference patterns.", "startOffset": 97, "endOffset": 330}, {"referenceID": 2, "context": "Both problems can be seen as instances of the broader class of bi-sequence classification tasks (Laha and Raykar, 2016). The currently best performing methods for the relation prediction task are those introduced by Liu and Li (2016), who proposed a bidirectional LSTM with multi-level attention, and by Rutherford and Xue (2014), who employed Brown cluster pairs and co-reference patterns. Pitler et al. (2008) showed that if a discourse connective is known, the (explicit) discourse relation can be inferred with a 93.", "startOffset": 97, "endOffset": 412}, {"referenceID": 2, "context": "Both problems can be seen as instances of the broader class of bi-sequence classification tasks (Laha and Raykar, 2016). The currently best performing methods for the relation prediction task are those introduced by Liu and Li (2016), who proposed a bidirectional LSTM with multi-level attention, and by Rutherford and Xue (2014), who employed Brown cluster pairs and co-reference patterns. Pitler et al. (2008) showed that if a discourse connective is known, the (explicit) discourse relation can be inferred with a 93.09% accuracy, which has inspired several efforts at predicting connectives to improve implicit discourse relation prediction. Zhou et al. (2010) predicted connectives using an N -gram language model1, whereas Xu et al.", "startOffset": 97, "endOffset": 665}, {"referenceID": 2, "context": "Both problems can be seen as instances of the broader class of bi-sequence classification tasks (Laha and Raykar, 2016). The currently best performing methods for the relation prediction task are those introduced by Liu and Li (2016), who proposed a bidirectional LSTM with multi-level attention, and by Rutherford and Xue (2014), who employed Brown cluster pairs and co-reference patterns. Pitler et al. (2008) showed that if a discourse connective is known, the (explicit) discourse relation can be inferred with a 93.09% accuracy, which has inspired several efforts at predicting connectives to improve implicit discourse relation prediction. Zhou et al. (2010) predicted connectives using an N -gram language model1, whereas Xu et al. (2012) employed word pairs and a selection of linguistically informed features.", "startOffset": 97, "endOffset": 746}, {"referenceID": 2, "context": "Both problems can be seen as instances of the broader class of bi-sequence classification tasks (Laha and Raykar, 2016). The currently best performing methods for the relation prediction task are those introduced by Liu and Li (2016), who proposed a bidirectional LSTM with multi-level attention, and by Rutherford and Xue (2014), who employed Brown cluster pairs and co-reference patterns. Pitler et al. (2008) showed that if a discourse connective is known, the (explicit) discourse relation can be inferred with a 93.09% accuracy, which has inspired several efforts at predicting connectives to improve implicit discourse relation prediction. Zhou et al. (2010) predicted connectives using an N -gram language model1, whereas Xu et al. (2012) employed word pairs and a selection of linguistically informed features. Liu et al. (2016) showed that predicting both connectives and relations using a convolutional neural network in a multi-task setting improves the relation prediction performance.", "startOffset": 97, "endOffset": 837}, {"referenceID": 8, "context": "The decomposable attention (DA) model was recently proposed for the natural language inference (NLI) problem which is also closely related to discourse connective prediction (Parikh et al., 2016).", "startOffset": 174, "endOffset": 195}, {"referenceID": 6, "context": "Already in 2002, Marcu and Echihabi (2002) proposed to map certain unambiguous connectives to discourse relations in order to collect a large discourse relation dataset.", "startOffset": 17, "endOffset": 43}, {"referenceID": 6, "context": "Already in 2002, Marcu and Echihabi (2002) proposed to map certain unambiguous connectives to discourse relations in order to collect a large discourse relation dataset. Sporleder and Lascarides (2008), however, showed that models trained using such automatically collected training data do not generalize well.", "startOffset": 17, "endOffset": 202}, {"referenceID": 6, "context": "Already in 2002, Marcu and Echihabi (2002) proposed to map certain unambiguous connectives to discourse relations in order to collect a large discourse relation dataset. Sporleder and Lascarides (2008), however, showed that models trained using such automatically collected training data do not generalize well. Nevertheless, by classifying freely-omissible connectives and only using those, Rutherford and Xue (2015) obtained improved relation prediction results.", "startOffset": 17, "endOffset": 418}, {"referenceID": 6, "context": "Already in 2002, Marcu and Echihabi (2002) proposed to map certain unambiguous connectives to discourse relations in order to collect a large discourse relation dataset. Sporleder and Lascarides (2008), however, showed that models trained using such automatically collected training data do not generalize well. Nevertheless, by classifying freely-omissible connectives and only using those, Rutherford and Xue (2015) obtained improved relation prediction results. In this work, we show that even a simpler approach using automatically collected data to pre-train a model and then human-annotated domain data to fine-tune it yields statistically significant improvements on relation prediction compared to a model trained only on the domain data. Predicting the presence of discourse connectives based on linguistic features of the arguments and their discourse relation was studied by Patterson and Kehler (2013). The decomposable attention (DA) model was recently proposed for the natural language inference (NLI) problem which is also closely related to discourse connective prediction (Parikh et al.", "startOffset": 17, "endOffset": 914}, {"referenceID": 12, "context": "We compile a list of 79 discourse connectives based on the Penn Discourse Treebank (PDTB) (Prasad et al., 2008).", "startOffset": 90, "endOffset": 111}, {"referenceID": 12, "context": "The most commonly used dataset for computational discourse studies is the Penn Discourse Treebank (PDTB) (Prasad et al., 2008).", "startOffset": 105, "endOffset": 126}, {"referenceID": 3, "context": "However, the small size of the dataset causes sparsity issues (Li and Nenkova, 2014) which hinder the development of new models, particularly complex neural models that often require large training datasets to generalize well.", "startOffset": 62, "endOffset": 84}, {"referenceID": 8, "context": "The decomposable attention (DA) model was recently introduced by Parikh et al. (2016) for the natural language inference (NLI) problem which aims to classify entailment and contradiction relations between a premise and a hypothesis.", "startOffset": 65, "endOffset": 86}, {"referenceID": 8, "context": "Figure reproduced with permission from (Parikh et al., 2016).", "startOffset": 39, "endOffset": 60}, {"referenceID": 6, "context": "Marcu and Echihabi (2002) proposed to use word pairs as the features of a model which predicted discourse relations based on discourse connectives mapped to these relations.", "startOffset": 0, "endOffset": 26}, {"referenceID": 7, "context": "(2016): (i) we do not use the self-attention mechanism which was reported to provide only a small improvement over the vanilla version of DA; (ii) we do not project down the embedding vectors but use 100-dimensional word2vec embeddings (Mikolov et al., 2013) which are updated during the training; (iii) we use layer normalization (Ba et al.", "startOffset": 236, "endOffset": 258}, {"referenceID": 1, "context": ", 2013) which are updated during the training; (iii) we use layer normalization (Ba et al., 2016) which makes the model converge faster.", "startOffset": 80, "endOffset": 97}, {"referenceID": 6, "context": "Our implementation of the DA model has the following differences compared to the original model described by Parikh et al. (2016): (i) we do not use the self-attention mechanism which was reported to provide only a small improvement over the vanilla version of DA; (ii) we do not project down the embedding vectors but use 100-dimensional word2vec embeddings (Mikolov et al.", "startOffset": 109, "endOffset": 130}, {"referenceID": 0, "context": "The model is implemented in TensorFlow (Abadi et al., 2015) and the training is run for 300 000 batch steps.", "startOffset": 39, "endOffset": 59}, {"referenceID": 6, "context": "In this section, we study the usefulness of the connective dataset for the related task of implicit discourse relation prediction, which has been extensively studied in the literature (Marcu and Echihabi, 2002; Pitler et al., 2009; Rutherford and Xue, 2014).", "startOffset": 184, "endOffset": 257}, {"referenceID": 10, "context": "In this section, we study the usefulness of the connective dataset for the related task of implicit discourse relation prediction, which has been extensively studied in the literature (Marcu and Echihabi, 2002; Pitler et al., 2009; Rutherford and Xue, 2014).", "startOffset": 184, "endOffset": 257}, {"referenceID": 13, "context": "In this section, we study the usefulness of the connective dataset for the related task of implicit discourse relation prediction, which has been extensively studied in the literature (Marcu and Echihabi, 2002; Pitler et al., 2009; Rutherford and Xue, 2014).", "startOffset": 184, "endOffset": 257}, {"referenceID": 17, "context": "Various studies have shown that the performance of relation prediction models can be improved by leveraging discourse connective data (Zhou et al., 2010; Xu et al., 2012; Liu et al., 2016; Rutherford and Xue, 2015) which is also the focus of this experiment.", "startOffset": 134, "endOffset": 214}, {"referenceID": 16, "context": "Various studies have shown that the performance of relation prediction models can be improved by leveraging discourse connective data (Zhou et al., 2010; Xu et al., 2012; Liu et al., 2016; Rutherford and Xue, 2015) which is also the focus of this experiment.", "startOffset": 134, "endOffset": 214}, {"referenceID": 5, "context": "Various studies have shown that the performance of relation prediction models can be improved by leveraging discourse connective data (Zhou et al., 2010; Xu et al., 2012; Liu et al., 2016; Rutherford and Xue, 2015) which is also the focus of this experiment.", "startOffset": 134, "endOffset": 214}, {"referenceID": 14, "context": "Various studies have shown that the performance of relation prediction models can be improved by leveraging discourse connective data (Zhou et al., 2010; Xu et al., 2012; Liu et al., 2016; Rutherford and Xue, 2015) which is also the focus of this experiment.", "startOffset": 134, "endOffset": 214}, {"referenceID": 13, "context": "Model Fine-Tuning: We adopt a method similar to Rutherford and Xue (2015) and map unambiguous connectives to the corresponding discourse relations (for instance, however is mapped to COMPARISON).", "startOffset": 48, "endOffset": 74}, {"referenceID": 13, "context": "Model Fine-Tuning: We adopt a method similar to Rutherford and Xue (2015) and map unambiguous connectives to the corresponding discourse relations (for instance, however is mapped to COMPARISON). We treat a connective as unambiguous when the most frequent relation among the explicit PDTB samples accounts for more than 90% of the samples with this connective. The resulting samples are treated as weakly labeled additional training data. Rutherford and Xue (2015) found out that using the weakly labeled training data indiscriminately in the training phase harms the performance, and hence, they introduce criteria to classify freely-omissible connectives and only use those.", "startOffset": 48, "endOffset": 465}, {"referenceID": 13, "context": "Results: The results for implicit discourse relation prediction using the DA model trained on PDTB data alone, another DA model pretrained with discourse connective data, and a state-of-theart model by Rutherford and Xue (2015) which also leverages weakly labeled training data are shown in Table 5.", "startOffset": 202, "endOffset": 228}, {"referenceID": 13, "context": "The results show that our implementation of the DA model does not perform as well as the method by Rutherford and Xue (2015), which is specifically designed for the task of relation prediction.", "startOffset": 99, "endOffset": 125}, {"referenceID": 13, "context": "The results show that our implementation of the DA model does not perform as well as the method by Rutherford and Xue (2015), which is specifically designed for the task of relation prediction. Nevertheless, pre-training the DA model with discourse connective data is shown to improve the prediction of COMPARISON and TEMPORAL relations, the two least frequent relations in the PDTB corpus. For CONTINGENCY, pretraining the model with weakly labeled data decreases the F1 score, which is in line with the results by Rutherford and Xue (2015).", "startOffset": 99, "endOffset": 542}, {"referenceID": 13, "context": "Table 5: Implicit discourse relation prediction results using the decomposable attention (DA) model with and without pre-training along with results from Rutherford and Xue (2015). Average F1 scores (and standard deviations) over ten random initializations of the DA model parameters are reported.", "startOffset": 154, "endOffset": 180}], "year": 2017, "abstractText": "Accurate prediction of suitable discourse connectives (however, furthermore, etc.) is a key component of any system aimed at building coherent and fluent discourses from shorter sentences and passages. As an example, a dialog system might assemble a long and informative answer by sampling passages extracted from different documents retrieved from the web. We formulate the task of discourse connective prediction and release a dataset of 2.9M sentence pairs separated by discourse connectives for this task. Then, we evaluate the hardness of the task for human raters, apply a recently proposed decomposable attention (DA) model to this task and observe that the automatic predictor has a higher F1 than human raters (32 vs. 30). Nevertheless, under specific conditions the raters still outperform the DA model, suggesting that there is headroom for future improvements. Finally, we further demonstrate the usefulness of the connectives dataset by showing that it improves implicit discourse relation prediction when used for model pre-training.", "creator": "LaTeX with hyperref package"}}}