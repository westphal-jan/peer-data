{"id": "1702.01182", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Feb-2017", "title": "Uncertainty-Aware Reinforcement Learning for Collision Avoidance", "abstract": "Reinforcement learning can enable complex, adaptive behavior to be learned automatically for autonomous robotic platforms. However, practical deployment of reinforcement learning methods must contend with the fact that the training process itself can be unsafe for the robot. In this paper, we consider the specific case of a mobile robot learning to navigate an a priori unknown environment while avoiding collisions. In order to learn collision avoidance, the robot must experience collisions at training time. However, high-speed collisions, even at training time, could damage the robot. A successful learning method must therefore proceed cautiously, experiencing only low-speed collisions until it gains confidence. To this end, we present an uncertainty-aware model-based learning algorithm that estimates the probability of collision together with a statistical estimate of uncertainty. By formulating an uncertainty-dependent cost function, we show that the algorithm naturally chooses to proceed cautiously in unfamiliar environments, and increases the velocity of the robot in settings where it has high confidence. Our predictive model is based on bootstrapped neural networks using dropout, allowing it to process raw sensory inputs from high-bandwidth sensors such as cameras. Our experimental evaluation demonstrates that our method effectively minimizes dangerous collisions at training time in an obstacle avoidance task for a simulated and real-world quadrotor, and a real-world RC car. Videos of the experiments can be found at", "histories": [["v1", "Fri, 3 Feb 2017 21:57:13 GMT  (8323kb,D)", "http://arxiv.org/abs/1702.01182v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.RO", "authors": ["gregory kahn", "adam villaflor", "vitchyr pong", "pieter abbeel", "sergey levine"], "accepted": false, "id": "1702.01182"}, "pdf": {"name": "1702.01182.pdf", "metadata": {"source": "CRF", "title": "Uncertainty-Aware Reinforcement Learning for Collision Avoidance", "authors": ["Gregory Kahn", "Adam Villaflor", "Vitchyr Pong", "Pieter Abbeel", "Sergey Levine"], "emails": [], "sections": [{"heading": null, "text": "In fact, we will be able to change the world without destroying it, \"he said in an interview with the German Press Agency.\" I am very satisfied, \"he said,\" but it is too early to say that the world is in order. \""}, {"heading": "II. RELATED WORK", "text": "In fact, most of the people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance"}, {"heading": "III. PRELIMINARIES", "text": "Our goal is to control a mobile robot that depends on the environment and the collision costs CCOL (relatively high collision costs), trying to navigate in an unknown environment. The task can be formally defined in terms of states x, actions u, Dynamics xt + 1 = f (xt, ut), and observations o. We use M to represent the environment, including all possible obstacles. We assume that the goal of the robot will be represented as a scalable cost function of form C (xt, ut, M) = CTASK (xt, ut) + 1COLL (xt, M) + the cost of an approximate collision. That is, the cost consists of an uncertain task CTASK (xt, ut), which could include, for example, a flight to a desired position or in a desired direction, as well as a hindrance-related collision cost given by the product of a collision 1COLL (xt), which is the only one that depends on the environment."}, {"heading": "IV. UNCERTAINTY-AWARE COLLISION PREDICTION", "text": "Training this collision prediction model from experience presents a dilemma: the robot must first experience collisions in order to learn how to avoid collisions. We formulate a speed-dependent collision prediction model that uses safety-conscious collision estimates, which results in the robot examining carefully when there is high uncertainty and moving faster when the uncertainty is low. This naturally occurring behavior allows the robot to detect collisions without experiencing catastrophic failures, and then use these safe collision experiences to act more aggressively in the future.One scope and the desired application of the safety-conscious collision prediction model is the following: Consider a quadrotor navigation task where the goal is to fly quickly and avoid collisions in an unknown environment.The quadrotor attempts to learn a collision prediction model that predicts an image and a sequence of speed commands as quadruple speed associated with the speed associated with a collision rotor that initially flies."}, {"heading": "A. Collision Prediction with Uncertainty", "text": "The collision prediction model Pledge takes as input the current state xt and observation ot, a sequence of H controls ut: t + H, and gives the probability that the robot will experience a collision within the horizon. We formulate Pledge as a discriminatory model with the logistic collision L (y) = 1 + exp (\u2212 y)), so the probability that the robot will experience a collision within the horizon. (F + H, ot). (F + H, ut: t + H, ot) is a random variable that corresponds to the real value of our stochastic model, which in our case corresponds to a modified neural network model that can generate uncertainty estimates. Generally, a variety of alternative models, including stochastic Bayesian models, could be used. Under this model, we can also define a risk-avoiding collision estimator P (COLL)."}, {"heading": "C. Neural Network Collision Prediction Model", "text": "To predict collisions from rich, high-dimensional sensory input factors such as cameras or LIDAR measurements, we use deep neural networks to estimate the likelihood of a collision. In the case of a standard deterministic, discriminatory trained neural network, the preactivation values in the network would be represented on the last layer, while P\u03b8 is achieved by applying a sigmoidal nonlinearity to the preactivations. Such a network can be trained on previous trajectories experienced by the robot, simply splitting all previous data into subsequences of length H and entering the states xt, observations ot, and the bundled sequence of controls ut: t + H. The probability of collision labels are binary values recorded by the robot to indicate whether a collision has occurred, and we can get the designation for each sub-sequence by simply checking whether a collision between the network and the gradient steps can then occur."}, {"heading": "D. Estimating Uncertainty with Neural Networks", "text": "In fact, we are able to go in search of a solution that enables us to go in search of a solution that enables us to go in search of a solution that enables us, that enables us to find a solution that enables us, that enables us to put ourselves in a position, that enables us to find a solution that enables us, that enables us to put ourselves in a position, that enables us to put ourselves in a position, that enables us to put ourselves in the position we are in, that we are in. \""}, {"heading": "E. Reinforcement Learning with Risk-Averse Collision Estimation", "text": "Alg. 2 provides an overview of how the safety-conscious collision prediction model is used in a model-based reinforcement learning algorithm. Each iteration of the algorithm, the cost function C, is formed using the current safety-conscious collision prediction model P-\u03b8. The model-based prediction controller is random based on cost C. These sample trajectories are aggregated into a data set containing all previously sampled trajectories. Afterwards, P-\u03b8 is trained on the data set according to Alg. 1 and the next iteration begins."}, {"heading": "V. EXPERIMENTS", "text": "We present simulated and real experiments to evaluate our uncertainty-conscious collision prediction model, as well as our proposed model-based RL algorithm. We compare different settings for the parameters in our model and evaluate its performance against a model-based approach that directly estimates the likelihood of a collision without explicitly taking into account the uncertainty. Videos of the experiments can be found at https: / / sites.google.com / site / probcoll /. Our collision prediction model P-\u03b8 (COLL | xt, ut: t + H, ot) is a fully connected neural network with two layers, each with 40 ReLU [21] hidden units. Activation of the last layer, which gives the collision probability, is a sigmoid (see Eqn. 1). The model inputs are the concatenation of xt, ut: t + H and ot. We trained the network using ADAM [12] a standard and minimum cross-section ratio of 50% for each of the loss of time."}, {"heading": "A. Quadrotor experiments", "text": "The simulated and real quadrotors have the same states, controls and observations. We therefore use a high-level representation of the quadrotor in which the control u R2 simply has an increased planar linear velocity, and therefore we assume that the state x is estimated to be feasible for this level of control. However, we do not provide the state x as input to the collision forecasting model. The observation o R256 is a 16 by 16 grayscale picture. The action sequences observed by the MPC planners at each time step consist of 190 straight, constant velocity curves at different angles and velocity ranges. The quadrotor simulation: We first evaluate our uncertainty model in a simulated environment consisting of a cylindrical obstacle of radius 0.2m (Fig. 3) The objective CTASK is to fly forward by 0.5 m / s, which is marked as a standard 2."}, {"heading": "B. Real-world RC car experiments", "text": "We evaluated our approach to an RC car (Fig. 8) in a simple obstacle avoidance task (Fig. 1). The car is parameterized by controlling u-R2 consisting of speed and steering angle and observation o-R576 consisting of a 32 by 18 grayscale image. We do not assume access to an underlying state x. The goal of the car CTASK is to drive at 1.2 m / s in any direction encoded as \"2 standard.\" The time horizon was set at H = 4 and each discrete time step corresponds to an accuracy of 0 seconds. The set of action sequences considered by the MPC planner in each time step consists of 49 curves, constant speed curves at different steering angles and speeds. All experiments consist of 10 training iterations, each iteration consisting of 5 on-policy rollouts of 4 different starting states. Each rollout ended either after a collision or after 10 time steps."}, {"heading": "VI. DISCUSSION AND FUTURE WORK", "text": "We have presented a model-based combined perception and control method for learning strategies to avoid obstacles that uses uncertainty estimates to automatically generate safe strategies. Our method is based on predicting the likelihood of a collision based on raw sensory input factors and a sequence of collisions using deep neural networks. This predictor can be used within a model predictive control pipeline to choose high probability collision avoidance measures. In regions of high uncertainty, our risk-averse cost function naturally leads the robot to revert to a cautious low-speed strategy without explicit manual engineering of safety controllers or fail-safe mechanisms. We show that our approach is safer than methods without uncertainty estimates in both a simulated and real quadrotory obstacle avoidance task as well as in a real RC auto task. Although our predictive algorithm does not result in unsafe behavior, it may not result in a positive outcome from a local attempt."}, {"heading": "VII. ACKNOWLEDGEMENTS", "text": "This research was partially funded by the Army Research Office through the MAST program, the National Science Foundation under IIS-1637443 and IIS-1614653, and the Berkeley Deep Drive Consortium."}], "references": [{"title": "Bayesian Optimization with Safety Constraints: Safe and Automatic Parameter Tuning in Robotics", "author": ["F. Berkenkamp", "A. Krause", "A. Schoellig"], "venue": "arXiv:1602.04450", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2016}, {"title": "Introspective Perception: Learning to Predict Failures in Vision Systems", "author": ["S. Daftry", "S. Zeng", "J.A. Bagnell", "M. Hebert"], "venue": "IROS", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2016}, {"title": "PILCO: A Modelbased and Data-Efficient Approach to Policy Search", "author": ["M. Deisenroth", "C. Rasmussen"], "venue": "ICML", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2011}, {"title": "A Survey on Policy Search for Robotics", "author": ["M.P. Deisenroth", "G. Neumann", "J. Peters"], "venue": "Foundations and Trends in Robotics", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2013}, {"title": "The Jackknife", "author": ["B. Efron", "R. Tibshirani"], "venue": "the Bootstrap and Other Resampling Plans. In SIAM", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1982}, {"title": "An introduction to the bootstrap", "author": ["B. Efron", "R. Tibshirani"], "venue": "CRC press", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1994}, {"title": "Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning", "author": ["Y. Gal", "Z. Ghahramani"], "venue": "ICML", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2016}, {"title": "Improving PILCO with Bayesian Neural Network Dynamics Models", "author": ["Y. Gal", "R. Mcallister", "C. Rasmussen"], "venue": "Data-Efficient Machine Learning workshop, ICML", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2016}, {"title": "Guaranteed Safe Online Learning via Reachability: Tracking a Ground Target using a Quadrotor", "author": ["J. Gillula", "C. Tomlin"], "venue": "ICRA", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2012}, {"title": "Reducing Conservativeness in Safety Guarantees by Learning Disturbances Online: Iterated Guaranteed Safe Online Learning", "author": ["J. Gillula", "C. Tomlin"], "venue": "RSS", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}, {"title": "PLATO: Policy Learning using Adaptive Trajectory Optimization", "author": ["G. Kahn", "C. Zhang", "S. Levine", "P. Abbeel"], "venue": "ICRA", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2017}, {"title": "Adam: A Method for Stochastic Optimization", "author": ["D.P. Kingma", "J. Ba"], "venue": "ICLR", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2015}, {"title": "The Big Data Bootstrap", "author": ["A. Kleiner", "A. Talwalkar", "P. Sarkar", "M.I. Jordan"], "venue": "ICML", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2012}, {"title": "In Reinforcement learning in robotics: A survey", "author": ["J. Kober", "J.A. Bagnell", "J. Peters"], "venue": "volume 32, pages 1238\u2013 1274", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}, {"title": "End-to-End Training of Deep Visuomotor Policies", "author": ["S. Levine", "C. Finn", "T. Darrell", "P. Abbeel"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2016}, {"title": "Continuous control  with deep reinforcement learning", "author": ["T.P. Lillicrap", "J.J. Hunt", "A. Pritzel", "N. Heess", "T. Erez", "Y. Tassa", "D. Silver", "D. Wierstra"], "venue": "arXiv:1411.0247", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2015}, {"title": "Funnel Libraries for Real-Time Robust Feedback Motion Planning", "author": ["A. Majumdar", "R. Tedrake"], "venue": "arXiv:1601.04037", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2016}, {"title": "and Riedmiller M", "author": ["V. Mnih", "K. Kavukcuoglu", "D. Silver", "A. Graves", "I. Antonoglou", "D. Wierstra"], "venue": "Playing Atari with Deep Reinforcement Learning. In Workshop on Deep Learning, NIPS", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2013}, {"title": "Safe Exploration in Markov Decision Processes", "author": ["T. Moldovan", "P. Abbeel"], "venue": "ICML", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2012}, {"title": "Relaxed hover solutions for multicopters: Application to algorithmic redundancy and novel vehicles", "author": ["M. Mueller", "R. D\u2019Andrea"], "venue": "The International Journal of Robotics Research,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2015}, {"title": "Rectified Linear Units Improve Restricted Boltzmann Machines", "author": ["V. Nair", "G. Hinton"], "venue": "ICML", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2010}, {"title": "Deep Exploration via Bootstrapped DQN", "author": ["I. Osband", "C. Blundell", "A. Pritzel", "B. Van Roy"], "venue": "NIPS", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2016}, {"title": "Lyapunov Design for Safe Reinforcement Learning", "author": ["T. Perkins", "A. Barto"], "venue": "JMLR", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2002}, {"title": "Policy Gradient Methods for Robotics", "author": ["J. Peters", "S. Schaal"], "venue": "IROS", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2006}, {"title": "Bayesian Learning for Safe High-Speed Navigation in Unknown Environments", "author": ["C. Richter", "W. Vega-Brown", "N. Roy"], "venue": "ISRR", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2015}, {"title": "Exploiting Model Uncertainty Estimates for Safe Dynamic Control Learning", "author": ["J. Schneider"], "venue": "NIPS", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1997}, {"title": "Trust Region Policy Optimization", "author": ["J. Schulman", "S. Levine", "P. Moritz", "M.I. Jordan", "P. Abbeel"], "venue": "ICML", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2015}, {"title": "Dropout: A Simple Way to Prevent Neural Networks from Overfitting", "author": ["N. Srivastava", "G. Hinton", "A. Krizhevsky", "I. Sutskever", "R. Salakhutidnov"], "venue": "JMLR", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2014}, {"title": "Autonomous Driving in Urban Environments: Boss and the Urban Challenge", "author": ["C. Urmson", "et. al"], "venue": "In Journal of Field Robotics,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2008}, {"title": "Safe receding horizon control for aggressive MAV flight with limited range sensing", "author": ["M. Watterson", "V. Kumar"], "venue": "IROS", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2015}, {"title": "Viability and Predictive Control for Safe Locomotion", "author": ["P. Wieber"], "venue": "IROS", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2008}], "referenceMentions": [{"referenceID": 4, "context": "To obtain uncertainty estimates from the neural network, we leverage uncertainty estimation methods for discriminatively trained neural networks based on a combination of bootstrapping [5] and dropout [28, 7].", "startOffset": 185, "endOffset": 188}, {"referenceID": 27, "context": "To obtain uncertainty estimates from the neural network, we leverage uncertainty estimation methods for discriminatively trained neural networks based on a combination of bootstrapping [5] and dropout [28, 7].", "startOffset": 201, "endOffset": 208}, {"referenceID": 6, "context": "To obtain uncertainty estimates from the neural network, we leverage uncertainty estimation methods for discriminatively trained neural networks based on a combination of bootstrapping [5] and dropout [28, 7].", "startOffset": 201, "endOffset": 208}, {"referenceID": 13, "context": "Reinforcement learning has been applied to a wide range of robotic problems, ranging from locomotion and manipulation to autonomous helicopter flight [14, 4].", "startOffset": 150, "endOffset": 157}, {"referenceID": 3, "context": "Reinforcement learning has been applied to a wide range of robotic problems, ranging from locomotion and manipulation to autonomous helicopter flight [14, 4].", "startOffset": 150, "endOffset": 157}, {"referenceID": 23, "context": "Model-free methods have been particularly popular due to their simplicity and favorable computational properties [24].", "startOffset": 113, "endOffset": 117}, {"referenceID": 2, "context": "known to be more sample-efficient [3].", "startOffset": 34, "endOffset": 37}, {"referenceID": 2, "context": "Several model-based robotic learning algorithms have been proposed that explicitly reason about uncertainty [3, 26].", "startOffset": 108, "endOffset": 115}, {"referenceID": 25, "context": "Several model-based robotic learning algorithms have been proposed that explicitly reason about uncertainty [3, 26].", "startOffset": 108, "endOffset": 115}, {"referenceID": 18, "context": "averse and risk-seeking, optimistic exploration [19].", "startOffset": 48, "endOffset": 52}, {"referenceID": 24, "context": "Uncertainty-aware model-based reinforcement learning has been explored in previous work using Bayesian models [25, 1].", "startOffset": 110, "endOffset": 117}, {"referenceID": 0, "context": "Uncertainty-aware model-based reinforcement learning has been explored in previous work using Bayesian models [25, 1].", "startOffset": 110, "endOffset": 117}, {"referenceID": 7, "context": "Recent work has proposed to use a Bayesian formulation of neural networks based on dropout [8], as well as to use the bootstrap for exploration [22], but not, to the best of our knowledge, for uncertainty estimation for the purpose of safety.", "startOffset": 91, "endOffset": 94}, {"referenceID": 21, "context": "Recent work has proposed to use a Bayesian formulation of neural networks based on dropout [8], as well as to use the bootstrap for exploration [22], but not, to the best of our knowledge, for uncertainty estimation for the purpose of safety.", "startOffset": 144, "endOffset": 148}, {"referenceID": 28, "context": "critical systems such as autonomous cars [29], legged robots [31], and quadrotors [20, 30, 9].", "startOffset": 41, "endOffset": 45}, {"referenceID": 30, "context": "critical systems such as autonomous cars [29], legged robots [31], and quadrotors [20, 30, 9].", "startOffset": 61, "endOffset": 65}, {"referenceID": 19, "context": "critical systems such as autonomous cars [29], legged robots [31], and quadrotors [20, 30, 9].", "startOffset": 82, "endOffset": 93}, {"referenceID": 29, "context": "critical systems such as autonomous cars [29], legged robots [31], and quadrotors [20, 30, 9].", "startOffset": 82, "endOffset": 93}, {"referenceID": 8, "context": "critical systems such as autonomous cars [29], legged robots [31], and quadrotors [20, 30, 9].", "startOffset": 82, "endOffset": 93}, {"referenceID": 22, "context": "rich sensory input and are often difficult to scale to highdimensional systems [23, 17, 10].", "startOffset": 79, "endOffset": 91}, {"referenceID": 16, "context": "rich sensory input and are often difficult to scale to highdimensional systems [23, 17, 10].", "startOffset": 79, "endOffset": 91}, {"referenceID": 9, "context": "rich sensory input and are often difficult to scale to highdimensional systems [23, 17, 10].", "startOffset": 79, "endOffset": 91}, {"referenceID": 1, "context": "Several works have suggested using discriminative models, including neural networks, to learn safety predictors [2].", "startOffset": 112, "endOffset": 115}, {"referenceID": 17, "context": "in recent years, with applications to video game playing [18], control of simulated robots [27, 16], and manipulation [15].", "startOffset": 57, "endOffset": 61}, {"referenceID": 26, "context": "in recent years, with applications to video game playing [18], control of simulated robots [27, 16], and manipulation [15].", "startOffset": 91, "endOffset": 99}, {"referenceID": 15, "context": "in recent years, with applications to video game playing [18], control of simulated robots [27, 16], and manipulation [15].", "startOffset": 91, "endOffset": 99}, {"referenceID": 14, "context": "in recent years, with applications to video game playing [18], control of simulated robots [27, 16], and manipulation [15].", "startOffset": 118, "endOffset": 122}, {"referenceID": 10, "context": "ground truth state information [11].", "startOffset": 31, "endOffset": 35}, {"referenceID": 0, "context": "Note that we use the variance of the sigmoid pre-activation value f\u03b8, since sigmoid probabilities are always in the range [0, 1].", "startOffset": 122, "endOffset": 128}, {"referenceID": 1, "context": "While it is possible to train a neural network model that outputs a mean and a variance as its prediction [2], this model is not in general guaranteed to output high variances for unfamiliar inputs because the network is by definition trained only on the datapoints that are in the training set.", "startOffset": 106, "endOffset": 109}, {"referenceID": 4, "context": "Bootstrapping: Bootstrapping [5, 6] is a simple and effective method of estimating model uncertainty using resampling that can be used with any discriminatively trained model.", "startOffset": 29, "endOffset": 35}, {"referenceID": 5, "context": "Bootstrapping: Bootstrapping [5, 6] is a simple and effective method of estimating model uncertainty using resampling that can be used with any discriminatively trained model.", "startOffset": 29, "endOffset": 35}, {"referenceID": 12, "context": "This intuition is backed with theoretical guarantees [13].", "startOffset": 53, "endOffset": 57}, {"referenceID": 6, "context": "Dropout: Dropout [7] is, by comparison, a computationally cheap method to improve uncertainty estimates.", "startOffset": 17, "endOffset": 20}, {"referenceID": 27, "context": "commonly used to reduce overfitting in neural networks by randomly dropping units from the neural network during training [28].", "startOffset": 122, "endOffset": 126}, {"referenceID": 6, "context": "However, Gal and Ghahramani [7] showed that dropout can be used to obtain uncertainty estimates at test time by calculating the sample mean and standard deviation of multiple stochastic forward passes of", "startOffset": 28, "endOffset": 31}, {"referenceID": 6, "context": "However, dropout underestimates the uncertainy because it acts roughly as a variational lower bound [7].", "startOffset": 100, "endOffset": 103}, {"referenceID": 20, "context": "Our collision prediction model P\u0303\u03b8(COLL|xt,ut:t+H ,ot) is a fully connected neural network with two layers with 40 ReLU [21] hidden units each.", "startOffset": 120, "endOffset": 124}, {"referenceID": 11, "context": "We trained the network using ADAM [12] and a standard", "startOffset": 34, "endOffset": 38}], "year": 2010, "abstractText": "Reinforcement learning can enable complex, adaptive behavior to be learned automatically for autonomous robotic platforms. However, practical deployment of reinforcement learning methods must contend with the fact that the training process itself can be unsafe for the robot. In this paper, we consider the specific case of a mobile robot learning to navigate an a priori unknown environment while avoiding collisions. In order to learn collision avoidance, the robot must experience collisions at training time. However, high-speed collisions, even at training time, could damage the robot. A successful learning method must therefore proceed cautiously, experiencing only low-speed collisions until it gains confidence. To this end, we present an uncertainty-aware model-based learning algorithm that estimates the probability of collision together with a statistical estimate of uncertainty. By formulating an uncertainty-dependent cost function, we show that the algorithm naturally chooses to proceed cautiously in unfamiliar environments, and increases the velocity of the robot in settings where it has high confidence. Our predictive model is based on bootstrapped neural networks using dropout, allowing it to process raw sensory inputs from high-bandwidth sensors such as cameras. Our experimental evaluation demonstrates that our method effectively minimizes dangerous collisions at training time in an obstacle avoidance task for a simulated and real-world quadrotor, and a realworld RC car. Videos of the experiments can be found at https://sites.google.com/site/probcoll.", "creator": "LaTeX with hyperref package"}}}