{"id": "1702.01504", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Feb-2017", "title": "Optimizing Cost-Sensitive SVM for Imbalanced Data :Connecting Cluster to Classification", "abstract": "Class imbalance is one of the challenging problems for machine learning in many real-world applications, such as coal and gas burst accident monitoring: the burst premonition data is extreme smaller than the normal data, however, which is the highlight we truly focus on. Cost-sensitive adjustment approach is a typical algorithm-level method resisting the data set imbalance. For SVMs classifier, which is modified to incorporate varying penalty parameter(C) for each of considered groups of examples. However, the C value is determined empirically, or is calculated according to the evaluation metric, which need to be computed iteratively and time consuming. This paper presents a novel cost-sensitive SVM method whose penalty parameter C optimized on the basis of cluster probability density function(PDF) and the cluster PDF is estimated only according to similarity matrix and some predefined hyper-parameters. Experimental results on various standard benchmark data sets and real-world data with different ratios of imbalance show that the proposed method is effective in comparison with commonly used cost-sensitive techniques.", "histories": [["v1", "Mon, 6 Feb 2017 06:14:29 GMT  (733kb)", "http://arxiv.org/abs/1702.01504v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["qiuyan yan", "shixiong xia", "fanrong meng"], "accepted": false, "id": "1702.01504"}, "pdf": {"name": "1702.01504.pdf", "metadata": {"source": "CRF", "title": "Optimizing Cost-Sensitive SVM for Imbalanced Data :Connecting Cluster to Classification", "authors": ["Qiuyan Yan", "Fanrong Meng"], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 170 2.01 504v 1 [cs.L G] 6F eb"}, {"heading": "1 Introduction", "text": "In fact, most people who are able to identify themselves, identify themselves, identify themselves and understand what they want and what they want are able to identify and understand themselves. It's like they don't do it. It's like they do it, as if they do it. It's like they do it, as if they do it. It's like they do it, as if they do it. It's like they don't do it, as if they do it. It's like they do it, as if they do it, as if they do it, as if they do it, as if they do it, as if they do it, as if they do it, as if they do it, as if they do it, as if they do it, as if they don't do it, if they do it, if they do it, if they do it, if they do it, if they do it, if they do it, if they do it, if they do it, if they do it, if they do it, if they do it, if they do it, if they do it, if they do it, if they do it, if they do it, if they do it, if they do it, if they do it, if they do it, if they do it, if they do it, if they do it, if they do it, if they do it, if they do it, if they do it."}, {"heading": "2 Related works", "text": "In previous work, the strategies for correcting the class imbalance for SVM mainly included resampling [4], cost-sensitive [5,6], adjustment of the decision threshold [7], and hybrid methods [8]. Resampling can be achieved either by over-sampling the minority class or by under-sampling the majority class. To avoid this problem, an SVS-based oversampling method for unbalanced time series data has been developed taking into account the sequence structure and distribution. \u2212 Sampling often leads to loss of information. [4] Proposed SVS-based oversampling method for unbalanced time series data taking into account the sequence structure and distribution is the trend in this area. The Different Error Costs (DEC) method is a cost-sensitive learning solution proposed in [9] to overcome the same costs (i.e. C) for both positive and negative misclassification within the penalty term."}, {"heading": "3 Proposed method", "text": "3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3"}, {"heading": "4 Complexity analysis", "text": "The PCS-SVM method comprises three steps: First, the development of the first SVM model by training the original dataset; second, the calculation of the new C value; third, the use of the optimization C value. The SVM complexity is O (dn2), d is the characteristic dimension and n is the size of the dataset. Calculation of the rear distribution for the latent variables taking into account the observed similarity matrix and hyperparameters has the complexity of O (n). While the complexity of our proposed method is O (dn2).9"}, {"heading": "5 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Data sets and compared methods", "text": "We tested the proposed algorithm on 16 keel datasets and our coal and gas burst monitoring data in the first example. We focus on the binary class unbalanced problem, but our method can easily be extended to multi-class imbalance classification. Information on standard benchmark datasets records is given in Table 1. First, we tested our proposed algorithm compared to five other individual classification algorithms based on SVM, including: 1. Standard SVM (SSVM) classifiers without class imbalance correction technologies. 2. SVM with random subsample (SVM-RUS): It adopts RUS to prepare the initial training, then trains SVM classifiers with the balanced training data. 3. SVM with random overlinks (SVM-ROS): It first takes the ROS subsample (SVM-RUS) to work on the RUS-RUS."}, {"heading": "5.2 Standard benchmark datasets experiment results", "text": "In Table 2 to Table 7, seven SVM methods are evaluated based on three metrics on sixteen standard benchmark data sets, and each metric is divided into two groups based on two core functions: Polynomial Kernel (Tables 2, 4, and 6) and RBF Kernel (Tables 3, 5, and 7). In the last row of each table, we list the number of recovery methods for all sixteen data sets. In terms of gain ratios in general, the PCSSVM and PCS-SMOTE-SVM methods gain more data sets with polynomial kernel than the RBF kernel. In SVM methods at the algorithm level, PCS-SVM has the clear superiority in F measurement and G-mean and in AUS measurement. In SVM methods at the sample level, SVM-SMS-SVM are all metrics at the middle level SVM measurement variables, and SVM-SVM measurement variables at the mean level SVM and SVM-level SVM-SVM-level."}, {"heading": "5.3 Coal and gas burst monitoring data set experiment results", "text": "In this section, we evaluate PCS-SVM and PCS-SMOTE-SVM on our real dataset: Coal and Gas Burst electromagnetic monitoring data, as shown in Fig. 1. Coal and 12Gas Burst is a kind of harmful accident in coal mining. Electromagnetic data can effectively reflect the foreshadowing of coal and gas explosions. Thus, if we find the foreshadowing of a burst accident from the electromagnetic data accurately and in time, we can anticipate the burst accident. In our example, the dataset is electromagnetic monitoring data for one month with the number 7989, and there are only 210 foreshadowing data, with the imbalance ratio of 37.04. The dataset has two features: electromagnetic intensity and electromagnetic pulse. We set the foreshadowing data with positive class SMS and the other normal data of the PCM are negative."}, {"heading": "6 Conclusion and future work", "text": "This paper presents a novel C-value optimization method based on the cluster probability density function, which is estimated only using similarity matrix and some predefined hyperparameters. Experimental results on various standard benchmark datasets and real data with different imbalances show that the proposed method is effective compared to commonly used cost-sensitive techniques. For future work, we plan to use multiview feature representations [16,17,18,19] to improve the performance of SVMs for unbalanced datasets."}], "references": [{"title": "Robust Subspace Clustering for Multi-View Data by Exploiting Correlation Consensus", "author": ["Yang Wang", "Xuemin Lin", "Lin Wu", "Wenjie Zhang", "Qing Zhang", "Xiaodi Huang"], "venue": "IEEE Trans. Image Processing", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "Shifting Hypergraphs by Probabilistic Voting", "author": ["Yang Wang", "Xuemin Lin", "Qing Zhang", "Lin Wu"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2014}, {"title": "Effective Multi-Query Expansions: Collaborative Deep Networks for Robust Landmark Retrieval", "author": ["Yang Wang", "Xuemin Lin", "Lin Wu", "Wenjie Zhang"], "venue": "IEEE Trans Image Processing", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2017}, {"title": "and H", "author": ["Z. Gon"], "venue": "Chen, \u201cModel-Based Oversampling for Imbalanced Sequence Classification,\u201d in Proceedings of the 25th ACM International on Conference on Information and Knowledge Management - CIKM \u201916,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2016}, {"title": "and C", "author": ["F. Cheng", "J. Zhang"], "venue": "Wen, \u201cCost-Sensitive Large margin Distribution Machine for classification of imbalanced data.,\u201d Pattern Recognit. Lett., vol. 80, pp. 107\u2013112,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2016}, {"title": "and O", "author": ["P. Cao", "D. Zhao"], "venue": "R. Za\u0131\u0308ane, \u201cA PSO-Based Cost-Sensitive Neural Network for Imbalanced Data Classification. BT - Trends and Applications in Knowledge Discovery and Data Mining - PAKDD 2013 International Workshops: DMApps, DANTH, QIMIE, BDM, CDA, CloudSD, Gold Coast, QLD, Australia, A.\u201d pp. 452\u2013463,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "and J", "author": ["G. Ristanoski", "W. Liu"], "venue": "Bailey, \u201cDiscrimination aware classification for imbalanced datasets,\u201d in Proceedings of the 22nd ACM international conference on Conference on information & knowledge management - CIKM \u201913,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "and J", "author": ["H. Cao", "V.Y.F. Tan"], "venue": "Z. F. Pang, \u201cA Parsimonious Mixture of Gaussian Trees Model for Oversampling in Imbalanced and Multimodal Time-Series Classification.,\u201d IEEE Trans. Neural Netw. Learn. Syst., vol. 25, no. 12, pp. 2226\u20132239,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "Veropoulos, \u201cControlling the sensivity of support vector machines,", "author": ["C.N.C.K. C"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1999}, {"title": "Applying Support Vector Machines to Imbalanced Datasets BT - Machine Learning: ECML 2004: 15th European Conference on Machine Learning, Pisa, Italy, September 20-24, 2004", "author": ["R. Akbani", "S. Kwek", "N. Japkowicz"], "venue": "Proceedings,\u201d J.-F. Boulicaut, F. Esposito, F. Giannotti, and D. Pedreschi, Eds. Berlin, Heidelberg: Springer Berlin Heidelberg,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2004}, {"title": "Extreme Re-balancing for SVMs: A Case Study,\u201d SIGKDD Explor", "author": ["B. Raskutti", "A. Kowalczyk"], "venue": "Newsl., vol. 6, no. 1, pp. 60\u201369,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2004}, {"title": "One Class SVM for Yeast Regulation Prediction,\u201d SIGKDD Explor", "author": ["A. Kowalczyk", "B. Raskutti"], "venue": "Newsl., vol. 4, no. 2, pp. 99\u2013100,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2002}, {"title": "z-SVM: An SVM for Improved Classification of Imbalanced Data,\u201d in AI 2006: Advances in Artificial Intelligence: 19th Australian Joint Conference on Artificial Intelligence, Hobart, Australia, December 4-8, 2006", "author": ["T. Imam", "K.M. Ting", "J. Kamruzzaman"], "venue": "Proceedings, A. Sattar and B. Kang, Eds. Berlin, Heidelberg: Springer Berlin Heidelberg,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2006}, {"title": "and J", "author": ["J. Che"], "venue": "Dy, A Generative Block-diagonal Model for Clustering, in Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2016}, {"title": "SMOTE: Synthetic Minority Over-sampling Technique, J", "author": ["N. V Chawla", "K.W. Bowyer", "L.O. Hall", "W.P. Kegelmeyer"], "venue": "Artif. Int. Res., vol. 16, no. 1, pp. 321C357,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2002}, {"title": "Effective Multi-Query Expansions: Robust Landmark Retrieval", "author": ["Yang Wang", "Xuemin Lin", "Lin Wu", "Wenjie Zhang"], "venue": "ACM Multimedia", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2015}, {"title": "Shifting multihypergraphs via collaborative probabilistic voting", "author": ["Yang Wang", "Xuemin Lin", "Lin Wu", "Qing Zhang", "Wenjie Zhang"], "venue": "Knowl. Inf. Syst", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2016}, {"title": "Iterative Views Agreement: An Iterative Low-Rank Based Structured Optimization Method to Multi-View Spectral Clustering", "author": ["Yang Wang", "Wenjie Zhang", "Lin Wu", "Xuemin Lin", "Meng Fang", "Shirui Pan"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2016}], "referenceMentions": [{"referenceID": 0, "context": "Imbalanced learning not only presents significant new challenges to the data research community [1,2,3] but also raises many critical questions in real-world data intensive applications.", "startOffset": 96, "endOffset": 103}, {"referenceID": 1, "context": "Imbalanced learning not only presents significant new challenges to the data research community [1,2,3] but also raises many critical questions in real-world data intensive applications.", "startOffset": 96, "endOffset": 103}, {"referenceID": 2, "context": "Imbalanced learning not only presents significant new challenges to the data research community [1,2,3] but also raises many critical questions in real-world data intensive applications.", "startOffset": 96, "endOffset": 103}, {"referenceID": 3, "context": "In previous work, the class imbalance correction strategies for SVM mainly includes resampling [4] ,cost-sensitive [5,6], decision threshold adjustment [7], and hybrid methods [8].", "startOffset": 95, "endOffset": 98}, {"referenceID": 4, "context": "In previous work, the class imbalance correction strategies for SVM mainly includes resampling [4] ,cost-sensitive [5,6], decision threshold adjustment [7], and hybrid methods [8].", "startOffset": 115, "endOffset": 120}, {"referenceID": 5, "context": "In previous work, the class imbalance correction strategies for SVM mainly includes resampling [4] ,cost-sensitive [5,6], decision threshold adjustment [7], and hybrid methods [8].", "startOffset": 115, "endOffset": 120}, {"referenceID": 6, "context": "In previous work, the class imbalance correction strategies for SVM mainly includes resampling [4] ,cost-sensitive [5,6], decision threshold adjustment [7], and hybrid methods [8].", "startOffset": 152, "endOffset": 155}, {"referenceID": 7, "context": "In previous work, the class imbalance correction strategies for SVM mainly includes resampling [4] ,cost-sensitive [5,6], decision threshold adjustment [7], and hybrid methods [8].", "startOffset": 176, "endOffset": 179}, {"referenceID": 3, "context": "In order to bypass this problem, [4] proposed a Model-Based Oversampling method for imbalanced time series data considering the sequence structure when oversampling.", "startOffset": 33, "endOffset": 36}, {"referenceID": 8, "context": "The Different Error Costs (DEC) method is a cost-sensitive learning solution proposed in [9] to overcome the same cost (i.", "startOffset": 89, "endOffset": 92}, {"referenceID": 9, "context": "As a rule of thumb, [10] have reported that reasonably good classification results could be retained from the DEC method by setting the C\u2212/C+ equal to the minority-to-majority class ratio.", "startOffset": 20, "endOffset": 24}, {"referenceID": 10, "context": "One-class Learning [11] trained an SVM model only with the minority class examples.", "startOffset": 19, "endOffset": 23}, {"referenceID": 11, "context": "[12] assigned C\u2212 = 0 and C+ = 1/N+, these methods have been observed to be more effective than general data rebalancing", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "zSVM is another algorithm modification proposed for SVMs in [13] to learn from imbalance datasets, which is an typical decision threshold adjustment method.", "startOffset": 60, "endOffset": 64}, {"referenceID": 13, "context": "According to the reference [14], the similarity matrix W is modeled as", "startOffset": 27, "endOffset": 31}, {"referenceID": 14, "context": "SVM with SMOTE (SVM-SMOTE) [15]: It firstly adopts SMOTE algorithm to oversampling the minority class instances and to make the data set balance, then trains SVM classifier using the balanced training data.", "startOffset": 27, "endOffset": 31}, {"referenceID": 9, "context": "Weighted SVM (CS-SVM) [10] : It assigns different values for the penalty factor C belong to different classes, to guarantee the fairness of classifier modeling, we make C+/C\u2212 equal to imbalance ratio (IR).", "startOffset": 22, "endOffset": 26}, {"referenceID": 15, "context": "For future work, we plan to leverage multi-view feature representations [16,17,18,19] to improve the performance of SVMs for imbalanced data set.", "startOffset": 72, "endOffset": 85}, {"referenceID": 16, "context": "For future work, we plan to leverage multi-view feature representations [16,17,18,19] to improve the performance of SVMs for imbalanced data set.", "startOffset": 72, "endOffset": 85}, {"referenceID": 17, "context": "For future work, we plan to leverage multi-view feature representations [16,17,18,19] to improve the performance of SVMs for imbalanced data set.", "startOffset": 72, "endOffset": 85}], "year": 2017, "abstractText": "Class imbalance is one of the challenging problems for machine learning in many real-world applications, such as coal and gas burst accident monitoring: the burst premonition data is extreme smaller than the normal data, however, which is the highlight we truly focus on. Cost-sensitive adjustment approach is a typical algorithm-level method resisting the data set imbalance. For SVMs classifier, which is modified to incorporate varying penalty parameter(C) for each of considered groups of examples. However, the C value is determined empirically, or is calculated according to the evaluation metric, which need to be computed iteratively and time consuming. This paper presents a novel cost-sensitive SVM method whose penalty parameter C optimized on the basis of cluster probability density function(PDF) and the cluster PDF is estimated only according to similarity matrix and some predefined hyper-parameters. Experimental results on various standard benchmark data sets and real-world data with different ratios of imbalance show that the proposed method is effective in comparison with commonly used cost-sensitive techniques.", "creator": "LaTeX with hyperref package"}}}