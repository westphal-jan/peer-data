{"id": "1702.01721", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Feb-2017", "title": "View Independent Vehicle Make, Model and Color Recognition Using Convolutional Neural Network", "abstract": "This paper describes the details of Sighthound's fully automated vehicle make, model and color recognition system. The backbone of our system is a deep convolutional neural network that is not only computationally inexpensive, but also provides state-of-the-art results on several competitive benchmarks. Additionally, our deep network is trained on a large dataset of several million images which are labeled through a semi-automated process. Finally we test our system on several public datasets as well as our own internal test dataset. Our results show that we outperform other methods on all benchmarks by significant margins. Our model is available to developers through the Sighthound Cloud API at", "histories": [["v1", "Mon, 6 Feb 2017 17:47:08 GMT  (3772kb,D)", "http://arxiv.org/abs/1702.01721v1", "7 Pages"]], "COMMENTS": "7 Pages", "reviews": [], "SUBJECTS": "cs.CV cs.AI", "authors": ["afshin dehghan", "syed zain masood", "guang shu", "enrique g ortiz"], "accepted": false, "id": "1702.01721"}, "pdf": {"name": "1702.01721.pdf", "metadata": {"source": "CRF", "title": "View Independent Vehicle Make, Model and Color Recognition Using Convolutional Neural Network", "authors": ["Afshin Dehghan", "Syed Zain Masood", "Guang Shu", "Enrique G. Ortiz"], "emails": ["egortiz}@sighthound.com"], "sections": [{"heading": "1 Introduction", "text": "This fine-grained visual classification task [4,5,6,7,8,9] has traditionally been a difficult task for computers. The biggest challenge is the subtle differences between classes (e.g. BMW 3 Series and BMW 5 Series) compared to some traditional classification tasks such as ImageNet. In addition, many researchers have focused on collecting large data sets to facilitate research in this area [4]. However, the complexity of current methods and / or the small size of current data sets leads to suboptimal results in real cases. [1] and Hsieh et al. [2] In addition, many researchers have focused on collecting large data sets to facilitate research in this area [4]. The complexity of current methods and / or the small size of current data sets lead to suboptimal results in real-world use cases."}, {"heading": "2 System Overview", "text": "Our training consists of a three-stage processing pipeline that includes data acquisition, data pre-processing and deep training. Data capture plays an important role in our final results, so collecting data that requires the least amount of labeling effort is of great importance. We have collected a large dataset with two different annotations; all images are annotated with the appropriate vehicle brand and model, and part of the data is provided with vehicle colors.2 To prepare the final training data, we further process the images to eliminate the effect of the background. Finally, these images are fed into two separate deep neural networks to train the final model."}, {"heading": "3 Training", "text": "The following describes in detail various components of our 3-step training procedure. Data Collection: Data Collection plays an important role in forming any deep neural network, especially when it comes to fine-grained classification tasks. To address this problem, we collected the largest known vehicle data, where each image is labeled with appropriate brands and models of the vehicle. We initially collected over 5 million images from various sources. We developed a semi-automatic process to partially crop the data and remove the unwanted images. Finally, we used a team of human markers to remove any remaining errors from the data set. The final set of data contains over 3 million images of vehicles with their respective brands and model designations. In addition, we designated a portion of this data with the corresponding color of the vehicle, selected from a set of 10 colors; blue, black, beige, red, white, yellow, purple and gray."}, {"heading": "4 Experiments on SIN 2014 Test set", "text": "In this section we report on experimental results on two publicly available datasets; the Stanford Cars dataset [10] and the Comprehensive Car (compCar) dataset [4]. The Stanford Cars dataset consists of 196 classes of cars with a total of 16, 185 images. The data is divided into almost a 50-50 train / test split with 8, 144 training images and 8, 041 test images. Categories are usually at the level of make, model, year. This means that several categories contain the same model of a brand, and the only difference is the year in which the car is manufactured. Our original model is not designed to classify vehicle models based on the year of their production. However, after fine-tuning our model to the Stanford Cars training data, we find that we can achieve better results compared to previously published methods. This is mainly due to the sophistication in the design of our proprietary deep neural network as well as the considerable amount of data that are used to quantify this network, which we are demonstrating in recent results."}, {"heading": "5 Quantitative Results", "text": "Figure 2 and 3 show some quantitative results in capturing different scenarios. Figure 2 shows results in images mostly taken by humans. Figure 3 shows a surveillance-like scenario where the camera is mounted at a greater distance from the ground. These images illustrate the robustness of our large training data set, which comes from different sources, compared to real scenarios."}, {"heading": "6 Conclusions", "text": "In this paper, we introduced an end-to-end system for vehicle manufacturing, model and color recognition. Combining Greyhound's novel approach to designing and implementing deep neural networks, and a sizable data set for training, allows us to identify vehicles in real time with high accuracy. We conducted several experiments for both classification and verification tasks on public benchmarks and showed significant improvements over previous methods."}], "references": [{"title": "Boxcars: 3d boxes as cnn input for improved fine-grained vehicle recognition", "author": ["J. Sochor", "A. Herout", "J. Havel."], "venue": "CVPR.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2016}, {"title": "Symmetrical surf and its applications to vehicle detection and vehicle make and model recognition", "author": ["J.W. Hsieh", "L.C. Chen", "D.Y. Chen"], "venue": "IEEE Transactions on intelligent transportation systems.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2014}, {"title": "Car model recognition by utilizing symmetric property to overcome severe pose variation", "author": ["H.Z. Gu", "S.Y. Lee."], "venue": "Machine vision and applications.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2013}, {"title": "A large-scale car dataset for fine-grained categorization and verification", "author": ["Yang", "Linjie", "e.a."], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2015}, {"title": "Bilinear cnn models for fine-grained visual recognition", "author": ["T.Y. Lin", "A. RoyChowdhury", "S. Maji."], "venue": "Proceedings of the IEEE International Conference on Computer Vision.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2015}, {"title": "Hyper-class augmented and regularized deep learning for finegrained image classification", "author": ["Xie", "Saining", "e.a."], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "3d object representations for finegrained categorization", "author": ["J. Krause", "M. Stark", "J. Deng", "L. Fei-Fei"], "venue": "4th IEEE Workshop on 3D Representation and Recognition, ICCV.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "Learning features and parts for fine-grained recognition", "author": ["Jonathan Krause", "e.a."], "venue": "Pattern Recognition (ICPR), 2014 22nd International Conference on.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "Jointly optimizing 3d model fitting and fine-grained classification", "author": ["Yen-Liang Lin", "e.a."], "venue": "ECCV.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Fine-grained recognition without part annotations", "author": ["Krause", "Jonathan", "e.a."], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2015}, {"title": "Embedding label structures for fine-grained feature representation", "author": ["X.Z. et al."], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2016}, {"title": "Re-visiting the fisher vector for fine-grained classification", "author": ["P.H. Gosselin", "N. Murray", "H. Jegou", "F. Perronnin."], "venue": "Pattern Recognition Letters.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "Make, model and color recognition (MMCR) of vehicles [1,2,3] is of great interest in several applications such as law-enforcement, driver assistance, surveillance and traffic monitoring.", "startOffset": 53, "endOffset": 60}, {"referenceID": 1, "context": "Make, model and color recognition (MMCR) of vehicles [1,2,3] is of great interest in several applications such as law-enforcement, driver assistance, surveillance and traffic monitoring.", "startOffset": 53, "endOffset": 60}, {"referenceID": 2, "context": "Make, model and color recognition (MMCR) of vehicles [1,2,3] is of great interest in several applications such as law-enforcement, driver assistance, surveillance and traffic monitoring.", "startOffset": 53, "endOffset": 60}, {"referenceID": 3, "context": "This fine-grained visual classification task [4,5,6,7,8,9] has been traditionally a difficult task for computers.", "startOffset": 45, "endOffset": 58}, {"referenceID": 4, "context": "This fine-grained visual classification task [4,5,6,7,8,9] has been traditionally a difficult task for computers.", "startOffset": 45, "endOffset": 58}, {"referenceID": 5, "context": "This fine-grained visual classification task [4,5,6,7,8,9] has been traditionally a difficult task for computers.", "startOffset": 45, "endOffset": 58}, {"referenceID": 6, "context": "This fine-grained visual classification task [4,5,6,7,8,9] has been traditionally a difficult task for computers.", "startOffset": 45, "endOffset": 58}, {"referenceID": 7, "context": "This fine-grained visual classification task [4,5,6,7,8,9] has been traditionally a difficult task for computers.", "startOffset": 45, "endOffset": 58}, {"referenceID": 8, "context": "This fine-grained visual classification task [4,5,6,7,8,9] has been traditionally a difficult task for computers.", "startOffset": 45, "endOffset": 58}, {"referenceID": 0, "context": "Recently, there have been efforts to design more accurate algorithms for MMCR such as those in the works of Sochor et al in [1] and Hsieh et al [2].", "startOffset": 124, "endOffset": 127}, {"referenceID": 1, "context": "Recently, there have been efforts to design more accurate algorithms for MMCR such as those in the works of Sochor et al in [1] and Hsieh et al [2].", "startOffset": 144, "endOffset": 147}, {"referenceID": 3, "context": "Moreover, many researchers have focused on collecting large datasets to facilitate research in this area [4].", "startOffset": 105, "endOffset": 108}, {"referenceID": 9, "context": "In this section, we report experimental results on two publicly available datasets; the Stanford Cars dataset [10] and the Comprehensive Car (compCar) dataset [4].", "startOffset": 110, "endOffset": 114}, {"referenceID": 3, "context": "In this section, we report experimental results on two publicly available datasets; the Stanford Cars dataset [10] and the Comprehensive Car (compCar) dataset [4].", "startOffset": 159, "endOffset": 162}, {"referenceID": 9, "context": "[10] 92.", "startOffset": 0, "endOffset": 4}, {"referenceID": 4, "context": "[5] 91.", "startOffset": 0, "endOffset": 3}, {"referenceID": 10, "context": "[11] 88.", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "[6] 86.", "startOffset": 0, "endOffset": 3}, {"referenceID": 11, "context": "[12] 82.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "We compare our results with the popular deep network architectures reported in [4].", "startOffset": 79, "endOffset": 82}, {"referenceID": 3, "context": "We compare our results with popular deep networks of GoogLeNet, Overfeat and AlexNet reported in [4]", "startOffset": 97, "endOffset": 100}, {"referenceID": 3, "context": "GoogLeNet [4] 91.", "startOffset": 10, "endOffset": 13}, {"referenceID": 3, "context": "1% Overfeat [4] 87.", "startOffset": 12, "endOffset": 15}, {"referenceID": 3, "context": "9% AlexNet [4] 81.", "startOffset": 11, "endOffset": 14}, {"referenceID": 3, "context": "Verification accuracy of three different sets, easy, medium and hard in [4].", "startOffset": 72, "endOffset": 75}, {"referenceID": 3, "context": "[4] 83.", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "[1] 85.", "startOffset": 0, "endOffset": 3}], "year": 2017, "abstractText": null, "creator": "LaTeX with hyperref package"}}}