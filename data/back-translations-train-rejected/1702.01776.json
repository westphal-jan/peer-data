{"id": "1702.01776", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Feb-2017", "title": "Multi-task memory networks for category-specific aspect and opinion terms co-extraction", "abstract": "In aspect-based sentiment analysis, most existing methods either focus on aspect/opinion terms extraction or aspect terms categorization. However, each task by itself only provides partial information to end users. To generate more detailed and structured opinion analysis, we propose a finer-grained problem, which we call category-specific aspect and opinion terms extraction. This problem involves the identification of aspect and opinion terms within each sentence, as well as the categorization of the identified terms. To this end, we propose an end-to-end multi-task attention model, where each task corresponds to aspect/opinion terms extraction for a specific category. Our model benefits from exploring the commonalities and relationships among different tasks to address the data sparsity issue. We demonstrate its state-of-the-art performance on three benchmark datasets.", "histories": [["v1", "Mon, 6 Feb 2017 19:55:51 GMT  (901kb)", "http://arxiv.org/abs/1702.01776v1", null], ["v2", "Mon, 5 Jun 2017 06:39:37 GMT  (297kb)", "http://arxiv.org/abs/1702.01776v2", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["wenya wang", "sinno jialin pan", "daniel dahlmeier"], "accepted": false, "id": "1702.01776"}, "pdf": {"name": "1702.01776.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Wenya Wang", "Sinno Jialin Pan", "Daniel Dahlmeier"], "emails": ["sinnopan}@ntu.edu.sg,", "d.dahlmeier@sap.com"], "sections": [{"heading": null, "text": "ar Xiv: 170 2.01 776v 1 [cs.C L] 6F eb2 017"}, {"heading": "1 Introduction", "text": "In this area, most work has been proposed for the extraction of aspects / concepts of opinion (Hu and Liu, 2004; Qiu et al., 2011; Wang et al., 2016), where one aspect refers to a word or phrase that describes a particular characteristic of a company, and one concept of opinion refers to the expression that triggers subjective emotions. For example, in which the soup is served with a nice part, the service is prompt. \"Soup, part and service are aspect concepts, while nice and prompt are opinion concepts that simply extract the above terms without classifying them into different categories that should be useful for generating structured aspect-based summaries. On the other hand, some work focusing on the categorization of aspect concepts will ov and the early work (Carenini et al)."}, {"heading": "2 Related Work", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Fine-grained Sentiment Analysis", "text": "There are four main approaches to the task of extracting aspects / opinion concepts. The first approach aims to exploit syntactical dependence relations between aspect concepts and opinion concepts for information extraction (Hu and Liu, 2004; Popescu and Etzioni, 2005; Zhuang et al., 2006; Wu et al., 2009; Qiu et al., 2011). A second approach models the extraction of target concepts as a monitored sequence characterization problem with exhaustive human-developed features (Jin and Ho, 2009; Li et al., 2010; Jakob and Gurevych, 2010). To reduce the effort of feature engineering, a third approach aims to automatically learn high-grade features (Liu et al., 2015a; Yin et al., 2016; Wang et al., 2016, 2017)."}, {"heading": "2.2 Deep Multi-task Learning", "text": "Multi-task learning aims to improve the generalization for each task by exploiting the relationships between different tasks (Caruana, 1997). A common assumption in multi-task learning is that the parameters for different tasks are located in a low-dimensional subspace (Argyriou et al., 2008; Kumar et al., 2012), which is achieved either by a low-threshold constraint or matrix factorization. By factorizing, the model of each task becomes a linear combination of a small set of latent tasks. Following this idea, a multilinear model was proposed in (Romera-Paredes et al., 2013) to handle multimodal tasks with multiple indices. Furthermore, this tensor factoring idea promotes a deep multi-task learning model (Yang et al., 2016), in which the parameters in different layers of a CNN for different tasks form a tensor that could be factored over multiple tasks."}, {"heading": "3 Preliminary", "text": "The basic component of the CMLA is a pair of coupled attention aspects, which combines an aspect of attention and an opinion attention that is interactively learned.The idea behind the coupled attention is to exploit the relationships between the aspect concepts and opinion concepts for double propagation (Qiu et al., 2011; Wang et al., 2016).Through the layered design, both direct and indirect relations between the concepts can be grasped.Specifically, a sentence with forward word embedding {xi} s, Gated Recurrent Unit (GRU et al., 2014) is applied to obtain an input function, H = {h1, hni}. The architecture for the first layer of the CMLA is shown in Figure 1, where an aspect of attention and a transformed view is one aspect."}, {"heading": "4 Problem Statement and Motivation", "text": "The fact is that we will find ourselves in a position to be in a position to be in the position we are in."}, {"heading": "5 Proposed Methodology", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Coupled Attentions with Shared Tensors", "text": "Similar to section 3, for each task Tc, a pair of embeddings uc = {uac, u p} 2 is created to randomly generate the distributed representations of aspect prototypes and opinion prototypes for each category2We initialize all category embeddings uc = {uac, u p} 2 on the basis of a uniform distribution: uc \u0445 U [\u2212 0,2, 0,2] for each task Tc. Here, different Tc corresponds to different tensors {Gc, Dc}, where Gc = {Gac, G p} i) = g (hi, u a c, u p c; u p c; Gc, Dc, \u03b8GRU). Here, different Tc corresponds to the different tensors {Gc, Dc}, where Gc = {Gac, G p} and Dc = {Dac, D p, c} for all interaction factors."}, {"heading": "5.2 Context-aware Feature Sharing", "text": "In addition to syntactic relationships, we examine other similarities between tasks or categories to get more attention for different tasks. (For example: \"FOOD # PRICE\" is more akin to \"DRINK # PRICE\" than \"SERVICE # GENERAL\" because the first two categories can share some common aspects / opinions, such as expensive ones. (To do this, we construct context-conscious category representations that capture not only the general category information, but also the context in which they lie. (4) We get general context representations oc i, o p) for Tc, o c) for attention scores: oac \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c. \""}, {"heading": "5.3 Multiple Layers", "text": "In order to grasp the non-obvious relationships between concepts of aspect and opinion, we construct several layers of attention. In the face of a sentence, each layer produces t its own {r, c, c = 1 for the i-th character and {o, c, t} C = 1 for the whole sentence. Note that different layers use the same H but different prototype vectors uc, t as input, with uac, t (similar for u p c, t) updated by: uac, t = tanh (V auac, t \u2212 1) + o, a c, t \u2212 1. (9) The final character representations result in the sum of the features of each layer: \u03b3 (c, a) i = T; t = 1r (c, a) i, g (c, p) i = T; c (c, p), c (c) for the final representations, while i (c) and c (c) stand for the final representations."}, {"heading": "5.4 Auxiliary Task", "text": "To better address the problem of data sparseness, we aim to use additional global information at the sentence level. Considering the following motivating example, if we know the sentence \"The soup is served with a nice part, the service is prompt\" has aspects / opinions from the categories \"DRINKS # STYLE OPTIONS\" and \"SERVICE # GENERAL,\" we can conclude that some words in the sentence should belong to one of these two categories. In order to use this information, we also need to elaborate an additional task for predicting the categories of a sentence. Let's keep in mind that in the training data Sentencelevel labels can be obtained by integrating token labels. In addition to the token loss for our prediction tasks, we also need to define sentence losses for the auxiliary task."}, {"heading": "5.5 Training", "text": "As shown in Figure 2, the training is performed by propagating the errors from top to bottom in an end-to-end manner. Specifically, we first get the loss from both the token-level prediction and the set-level prediction, which are propagated in each level backwards to r-ci, t and o-c, t respectively for each Tc. Together, these update Sa, Sp, which is combined with the error of o-c, t to update oc, t. Then, the error of r-c, t and oc-t is used to update all parameters for the coupled presences up to word embedding."}, {"heading": "6 Experiments", "text": "The experiments are performed using three benchmark datasets from subtask 1 in SemEval Challenge 2015 task 12 (Pontiki et al., 2015), SemEval Challenge 2016 task 5 (Pontiki et al., 2016), and SemEval Challenge 2014 task 4 (Pontiki et al., 2014), each designated by S1, S2, and S3. Note that S1 and S2 are restaurant reviews, and S3 is in laptop domain3. We use term-level aspect opinion comments provided by (Wang et al., 2017) for S1 and S3, and manually comment on opinion terms for S2. To facilitate our experiment, we also make additional annotations on category labels for target terms, except for the aspect terms categories for S1 and S2 provided by SemEval and S2. Statistics for each dataset are shown in Table 1, where text and tuples each contain the number of the categories and the number of each of the number of the tuples."}, {"heading": "6.1 Experimental Results", "text": "This year, it has reached the point where it will be able to retaliate."}, {"heading": "7 Conclusion", "text": "In this paper, we present a finer-grained task that includes both the prediction of aspect / opinion concepts and the corresponding aspect categories, and offer a novel multi-task deep learning model, MTCA, to solve the problem. The model is able to exploit syntactic similarities and task simularities through attention mechanisms. Finally, we demonstrate the effectiveness of our model using three benchmark data sets."}], "references": [{"title": "Convex multi-task feature learning", "author": ["Andreas Argyriou", "Theodoros Evgeniou", "Massimiliano Pontil."], "venue": "Mach. Learn. 73(3):243\u2013272.", "citeRegEx": "Argyriou et al\\.,? 2008", "shortCiteRegEx": "Argyriou et al\\.", "year": 2008}, {"title": "K-cap", "author": ["Giuseppe Carenini", "Raymond T. Ng", "Ed Zwart."], "venue": "pages 11\u201318.", "citeRegEx": "Carenini et al\\.,? 2005", "shortCiteRegEx": "Carenini et al\\.", "year": 2005}, {"title": "Multitask learning", "author": ["Rich Caruana."], "venue": "Mach. Learn. 28(1):41\u201375.", "citeRegEx": "Caruana.,? 1997", "shortCiteRegEx": "Caruana.", "year": 1997}, {"title": "Clustering for simultaneous extraction of aspects and features from reviews", "author": ["Lu Chen", "Justin Martineau", "Doreen Cheng", "Amit P. Sheth."], "venue": "NAACLHLT. pages 789\u2013799.", "citeRegEx": "Chen et al\\.,? 2016", "shortCiteRegEx": "Chen et al\\.", "year": 2016}, {"title": "Aspect extraction with automated prior knowledge learning", "author": ["Zhiyuan Chen", "Arjun Mukherjee", "Bing Liu."], "venue": "ACL. pages 347\u2013358.", "citeRegEx": "Chen et al\\.,? 2014", "shortCiteRegEx": "Chen et al\\.", "year": 2014}, {"title": "Learning phrase representations using rnn encoder-decoder for statistical machine translation", "author": ["Kyunghyun Cho", "Bart van Merrienboer", "Caglar Gulcehre", "Dzmitry Bahdanau", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio."], "venue": "EMNLP. pages", "citeRegEx": "Cho et al\\.,? 2014", "shortCiteRegEx": "Cho et al\\.", "year": 2014}, {"title": "Product feature categorization with multilevel latent semantic association", "author": ["Honglei Guo", "Huijia Zhu", "Zhili Guo", "XiaoXun Zhang", "Zhong Su."], "venue": "CIKM. pages 1087\u20131096.", "citeRegEx": "Guo et al\\.,? 2009", "shortCiteRegEx": "Guo et al\\.", "year": 2009}, {"title": "Mining and summarizing customer reviews", "author": ["Minqing Hu", "Bing Liu."], "venue": "KDD. pages 168\u2013177.", "citeRegEx": "Hu and Liu.,? 2004", "shortCiteRegEx": "Hu and Liu.", "year": 2004}, {"title": "Extracting opinion targets in a single- and cross-domain setting with conditional random fields", "author": ["Niklas Jakob", "Iryna Gurevych."], "venue": "EMNLP. pages 1035\u20131045.", "citeRegEx": "Jakob and Gurevych.,? 2010", "shortCiteRegEx": "Jakob and Gurevych.", "year": 2010}, {"title": "A novel lexicalized hmm-based learning framework for web opinion mining", "author": ["Wei Jin", "Hung Hay Ho."], "venue": "ICML. pages 465\u2013472.", "citeRegEx": "Jin and Ho.,? 2009", "shortCiteRegEx": "Jin and Ho.", "year": 2009}, {"title": "Learning task grouping and overlap in multi-task learning", "author": ["Abhishek Kumar", "Hal Daum III."], "venue": "ICML.", "citeRegEx": "Kumar and III.,? 2012", "shortCiteRegEx": "Kumar and III.", "year": 2012}, {"title": "Structure-aware review mining and summarization", "author": ["Fangtao Li", "Chao Han", "Minlie Huang", "Xiaoyan Zhu", "Ying-Ju Xia", "Shu Zhang", "Hao Yu."], "venue": "COLING. pages 653\u2013661.", "citeRegEx": "Li et al\\.,? 2010", "shortCiteRegEx": "Li et al\\.", "year": 2010}, {"title": "Fine-grained opinion mining with recurrent neural networks and word embeddings", "author": ["Pengfei Liu", "Shafiq Joty", "Helen Meng."], "venue": "EMNLP. pages 1433\u20131443.", "citeRegEx": "Liu et al\\.,? 2015a", "shortCiteRegEx": "Liu et al\\.", "year": 2015}, {"title": "Representation learning using multi-task deep neural networks for semantic classification and information retrieval", "author": ["Xiaodong Liu", "Jianfeng Gao", "Xiaodong He", "Li Deng", "Kevin Duh", "Ye-Yi Wang."], "venue": "NAACL. pages 912\u2013921.", "citeRegEx": "Liu et al\\.,? 2015b", "shortCiteRegEx": "Liu et al\\.", "year": 2015}, {"title": "Rated aspect summarization of short comments", "author": ["Yue Lu", "ChengXiang Zhai", "Neel Sundaresan."], "venue": "WWW. pages 131\u2013140.", "citeRegEx": "Lu et al\\.,? 2009", "shortCiteRegEx": "Lu et al\\.", "year": 2009}, {"title": "Image-based recommendations on styles and substitutes", "author": ["Julian McAuley", "Christopher Targett", "Qinfeng Shi", "Anton van den Hengel."], "venue": "SIGIR. pages 43\u201352.", "citeRegEx": "McAuley et al\\.,? 2015", "shortCiteRegEx": "McAuley et al\\.", "year": 2015}, {"title": "Cross-stitch networks for multi-task learning", "author": ["Ishan Misra", "Abhinav Shrivastava", "Abhinav Gupta", "Martial Hebert"], "venue": null, "citeRegEx": "Misra et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Misra et al\\.", "year": 2016}, {"title": "SemEval-2016 task 5: Aspect based sentiment analysis", "author": ["talia Loukachevitch", "Evgeny Kotelnikov", "Nuria Bel", "Salud Mara Jimnez-Zafra", "Glen Eryiit"], "venue": "SemEval", "citeRegEx": "Loukachevitch et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Loukachevitch et al\\.", "year": 2016}, {"title": "SemEval-2015 task 12: Aspect based sentiment analysis", "author": ["Maria Pontiki", "Dimitris Galanis", "Haris Papageorgiou", "Suresh Manandhar", "Ion Androutsopoulos."], "venue": "SemEval 2015. pages 486\u2013495.", "citeRegEx": "Pontiki et al\\.,? 2015", "shortCiteRegEx": "Pontiki et al\\.", "year": 2015}, {"title": "Semeval-2014 task 4: Aspect based sentiment analysis", "author": ["Maria Pontiki", "Dimitris Galanis", "John Pavlopoulos", "Harris Papageorgiou", "Ion Androutsopoulos", "Suresh Manandhar."], "venue": "SemEval. pages 27\u201335.", "citeRegEx": "Pontiki et al\\.,? 2014", "shortCiteRegEx": "Pontiki et al\\.", "year": 2014}, {"title": "Extracting product features and opinions from reviews", "author": ["Ana-Maria Popescu", "Oren Etzioni."], "venue": "EMNLP. pages 339\u2013346.", "citeRegEx": "Popescu and Etzioni.,? 2005", "shortCiteRegEx": "Popescu and Etzioni.", "year": 2005}, {"title": "Opinion word expansion and target extraction through double propagation", "author": ["Guang Qiu", "Bing Liu", "Jiajun Bu", "Chun Chen."], "venue": "Comput. Linguist. 37(1):9\u201327.", "citeRegEx": "Qiu et al\\.,? 2011", "shortCiteRegEx": "Qiu et al\\.", "year": 2011}, {"title": "Multilinear multitask learning", "author": ["Bernardino Romera-Paredes", "Hane Aung", "Nadia Bianchi-Berthouze", "Massimiliano Pontil."], "venue": "ICML (3). volume 28 of JMLR Workshop and Conference Proceedings, pages 1444\u20131452.", "citeRegEx": "Romera.Paredes et al\\.,? 2013", "shortCiteRegEx": "Romera.Paredes et al\\.", "year": 2013}, {"title": "Hidden sentiment association in chinese web opinion mining", "author": ["Qi Su", "Xinying Xu", "Honglei Guo", "Zhili Guo", "Xian Wu", "Xiaoxun Zhang", "Bin Swen", "Zhong Su."], "venue": "WWW. pages 959\u2013968.", "citeRegEx": "Su et al\\.,? 2008", "shortCiteRegEx": "Su et al\\.", "year": 2008}, {"title": "Modeling online reviews with multi-grain topic models", "author": ["Ivan Titov", "Ryan McDonald."], "venue": "www. pages 111\u2013120.", "citeRegEx": "Titov and McDonald.,? 2008a", "shortCiteRegEx": "Titov and McDonald.", "year": 2008}, {"title": "A joint model of text and aspect ratings for sentiment summarization", "author": ["Ivan Titov", "Ryan T. McDonald."], "venue": "ACL. pages 308\u2013316.", "citeRegEx": "Titov and McDonald.,? 2008b", "shortCiteRegEx": "Titov and McDonald.", "year": 2008}, {"title": "Recursive neural conditional random fields for aspect-based sentiment analysis", "author": ["Wenya Wang", "Sinno Jialin Pan", "Daniel Dahlmeier", "Xiaokui Xiao."], "venue": "EMNLP.", "citeRegEx": "Wang et al\\.,? 2016", "shortCiteRegEx": "Wang et al\\.", "year": 2016}, {"title": "Coupled multi-layer tensor network for co-extraction of aspect and opinion terms", "author": ["Wenya Wang", "Sinno Jialin Pan", "Daniel Dahlmeier", "Xiaokui Xiao."], "venue": "AAAI.", "citeRegEx": "Wang et al\\.,? 2017", "shortCiteRegEx": "Wang et al\\.", "year": 2017}, {"title": "Phrase dependency parsing for opinion mining", "author": ["Yuanbin Wu", "Qi Zhang", "Xuanjing Huang", "Lide Wu."], "venue": "EMNLP. pages 1533\u20131541.", "citeRegEx": "Wu et al\\.,? 2009", "shortCiteRegEx": "Wu et al\\.", "year": 2009}, {"title": "Hierarchical attention networks for document classification", "author": ["Zichao Yang", "Diyi Yang", "Chris Dyer", "Xiaodong He", "Alex Smola", "Eduard Hovy."], "venue": "NAACL. pages 1480\u20131489.", "citeRegEx": "Yang et al\\.,? 2016", "shortCiteRegEx": "Yang et al\\.", "year": 2016}, {"title": "Unsupervised word and dependency path embeddings for aspect term extraction", "author": ["Yichun Yin", "Furu Wei", "Li Dong", "Kaimeng Xu", "Ming Zhang", "Ming Zhou."], "venue": "IJCAI.", "citeRegEx": "Yin et al\\.,? 2016", "shortCiteRegEx": "Yin et al\\.", "year": 2016}, {"title": "Aspect ranking: Identifying important product aspects from online consumer reviews", "author": ["Jianxing Yu", "Zheng-Jun Zha", "Meng Wang", "TatSeng Chua."], "venue": "ACL.", "citeRegEx": "Yu et al\\.,? 2011", "shortCiteRegEx": "Yu et al\\.", "year": 2011}, {"title": "Grouping product features using semi-supervised learning with soft-constraints", "author": ["Zhongwu Zhai", "Bing Liu", "Hua Xu", "Peifa Jia."], "venue": "COLING. pages 1272\u20131280.", "citeRegEx": "Zhai et al\\.,? 2010", "shortCiteRegEx": "Zhai et al\\.", "year": 2010}, {"title": "Clustering product features for opinion mining", "author": ["Zhongwu Zhai", "Bing Liu", "Hua Xu", "Peifa Jia."], "venue": "WSDM. pages 347\u2013354.", "citeRegEx": "Zhai et al\\.,? 2011", "shortCiteRegEx": "Zhai et al\\.", "year": 2011}, {"title": "Jointly modeling aspects and opinions with a maxent-lda hybrid", "author": ["Wayne Xin Zhao", "Jing Jiang", "Hongfei Yan", "Xiaoming Li."], "venue": "EMNLP. pages 56\u201365.", "citeRegEx": "Zhao et al\\.,? 2010", "shortCiteRegEx": "Zhao et al\\.", "year": 2010}, {"title": "Movie review mining and summarization", "author": ["Li Zhuang", "Feng Jing", "Xiao-Yan Zhu."], "venue": "CIKM. pages 43\u201350.", "citeRegEx": "Zhuang et al\\.,? 2006", "shortCiteRegEx": "Zhuang et al\\.", "year": 2006}], "referenceMentions": [{"referenceID": 7, "context": "Under this branch, most work has been proposed for aspect/opinion terms extraction (Hu and Liu, 2004; Qiu et al., 2011; Wang et al., 2016), where an aspect term refers to a word or a phrase describing some feature of an entity, and an opinion term refers to the expression carrying subjective emotions.", "startOffset": 83, "endOffset": 138}, {"referenceID": 21, "context": "Under this branch, most work has been proposed for aspect/opinion terms extraction (Hu and Liu, 2004; Qiu et al., 2011; Wang et al., 2016), where an aspect term refers to a word or a phrase describing some feature of an entity, and an opinion term refers to the expression carrying subjective emotions.", "startOffset": 83, "endOffset": 138}, {"referenceID": 26, "context": "Under this branch, most work has been proposed for aspect/opinion terms extraction (Hu and Liu, 2004; Qiu et al., 2011; Wang et al., 2016), where an aspect term refers to a word or a phrase describing some feature of an entity, and an opinion term refers to the expression carrying subjective emotions.", "startOffset": 83, "endOffset": 138}, {"referenceID": 1, "context": "Given an extracted aspect term, early work (Carenini et al., 2005; Yu et al., 2011) applied lexicon and taxonomybased methods to classify it to a category according to some distance measures.", "startOffset": 43, "endOffset": 83}, {"referenceID": 31, "context": "Given an extracted aspect term, early work (Carenini et al., 2005; Yu et al., 2011) applied lexicon and taxonomybased methods to classify it to a category according to some distance measures.", "startOffset": 43, "endOffset": 83}, {"referenceID": 6, "context": "Although topic models (Guo et al., 2009; Titov and McDonald, 2008a) can achieve both grouping and extraction at the same time, they mainly focused on grouping and can only identify general and coarse-grained aspect terms.", "startOffset": 22, "endOffset": 67}, {"referenceID": 24, "context": "Although topic models (Guo et al., 2009; Titov and McDonald, 2008a) can achieve both grouping and extraction at the same time, they mainly focused on grouping and can only identify general and coarse-grained aspect terms.", "startOffset": 22, "endOffset": 67}, {"referenceID": 27, "context": "Inspired by (Wang et al., 2017), we model each task with coupled multi-layer attentions to extract the relations between aspect terms and opinion terms within each category.", "startOffset": 12, "endOffset": 31}, {"referenceID": 7, "context": "The first approach aims to exploit syntactic dependency relations among aspect terms and opinion terms for information extraction (Hu and Liu, 2004; Popescu and Etzioni, 2005; Zhuang et al., 2006; Wu et al., 2009; Qiu et al., 2011).", "startOffset": 130, "endOffset": 231}, {"referenceID": 20, "context": "The first approach aims to exploit syntactic dependency relations among aspect terms and opinion terms for information extraction (Hu and Liu, 2004; Popescu and Etzioni, 2005; Zhuang et al., 2006; Wu et al., 2009; Qiu et al., 2011).", "startOffset": 130, "endOffset": 231}, {"referenceID": 35, "context": "The first approach aims to exploit syntactic dependency relations among aspect terms and opinion terms for information extraction (Hu and Liu, 2004; Popescu and Etzioni, 2005; Zhuang et al., 2006; Wu et al., 2009; Qiu et al., 2011).", "startOffset": 130, "endOffset": 231}, {"referenceID": 28, "context": "The first approach aims to exploit syntactic dependency relations among aspect terms and opinion terms for information extraction (Hu and Liu, 2004; Popescu and Etzioni, 2005; Zhuang et al., 2006; Wu et al., 2009; Qiu et al., 2011).", "startOffset": 130, "endOffset": 231}, {"referenceID": 21, "context": "The first approach aims to exploit syntactic dependency relations among aspect terms and opinion terms for information extraction (Hu and Liu, 2004; Popescu and Etzioni, 2005; Zhuang et al., 2006; Wu et al., 2009; Qiu et al., 2011).", "startOffset": 130, "endOffset": 231}, {"referenceID": 9, "context": "A second approach models the extraction of target terms as a supervised sequence labeling problem with exhaustive human-engineered features (Jin and Ho, 2009; Li et al., 2010; Jakob and Gurevych, 2010).", "startOffset": 140, "endOffset": 201}, {"referenceID": 11, "context": "A second approach models the extraction of target terms as a supervised sequence labeling problem with exhaustive human-engineered features (Jin and Ho, 2009; Li et al., 2010; Jakob and Gurevych, 2010).", "startOffset": 140, "endOffset": 201}, {"referenceID": 8, "context": "A second approach models the extraction of target terms as a supervised sequence labeling problem with exhaustive human-engineered features (Jin and Ho, 2009; Li et al., 2010; Jakob and Gurevych, 2010).", "startOffset": 140, "endOffset": 201}, {"referenceID": 12, "context": "To reduce the effort of feature engineering, a third approach aims to utilize deep learning to learn high-level features automatically (Liu et al., 2015a; Yin et al., 2016; Wang et al., 2016, 2017).", "startOffset": 135, "endOffset": 197}, {"referenceID": 30, "context": "To reduce the effort of feature engineering, a third approach aims to utilize deep learning to learn high-level features automatically (Liu et al., 2015a; Yin et al., 2016; Wang et al., 2016, 2017).", "startOffset": 135, "endOffset": 197}, {"referenceID": 25, "context": "A forth approach adopts topic models (Titov and McDonald, 2008b; Lu et al., 2009; Zhao et al., 2010; Chen et al., 2014) or clustering techniques (Su et al.", "startOffset": 37, "endOffset": 119}, {"referenceID": 14, "context": "A forth approach adopts topic models (Titov and McDonald, 2008b; Lu et al., 2009; Zhao et al., 2010; Chen et al., 2014) or clustering techniques (Su et al.", "startOffset": 37, "endOffset": 119}, {"referenceID": 34, "context": "A forth approach adopts topic models (Titov and McDonald, 2008b; Lu et al., 2009; Zhao et al., 2010; Chen et al., 2014) or clustering techniques (Su et al.", "startOffset": 37, "endOffset": 119}, {"referenceID": 4, "context": "A forth approach adopts topic models (Titov and McDonald, 2008b; Lu et al., 2009; Zhao et al., 2010; Chen et al., 2014) or clustering techniques (Su et al.", "startOffset": 37, "endOffset": 119}, {"referenceID": 23, "context": ", 2014) or clustering techniques (Su et al., 2008; Yu et al., 2011; Chen et al., 2016) to group potential aspect terms into different clusters (not explicit categories).", "startOffset": 33, "endOffset": 86}, {"referenceID": 31, "context": ", 2014) or clustering techniques (Su et al., 2008; Yu et al., 2011; Chen et al., 2016) to group potential aspect terms into different clusters (not explicit categories).", "startOffset": 33, "endOffset": 86}, {"referenceID": 3, "context": ", 2014) or clustering techniques (Su et al., 2008; Yu et al., 2011; Chen et al., 2016) to group potential aspect terms into different clusters (not explicit categories).", "startOffset": 33, "endOffset": 86}, {"referenceID": 1, "context": "For the task of aspect categorization, most existing methods assume the aspect terms be extracted in advance, and aim to predict their corresponding categories (Carenini et al., 2005; Yu et al., 2011; Zhai et al., 2010, 2011).", "startOffset": 160, "endOffset": 225}, {"referenceID": 31, "context": "For the task of aspect categorization, most existing methods assume the aspect terms be extracted in advance, and aim to predict their corresponding categories (Carenini et al., 2005; Yu et al., 2011; Zhai et al., 2010, 2011).", "startOffset": 160, "endOffset": 225}, {"referenceID": 2, "context": "Multi-task learning aims to improve generalization for each individual task by exploiting relatedness among different tasks (Caruana, 1997).", "startOffset": 124, "endOffset": 139}, {"referenceID": 0, "context": "One common assumption in multi-task learning is that parameters for different tasks lie in a low-dimensional subspace (Argyriou et al., 2008; Kumar and III, 2012) which is achieved either by imposing low-rank constraint or matrix factorization.", "startOffset": 118, "endOffset": 162}, {"referenceID": 10, "context": "One common assumption in multi-task learning is that parameters for different tasks lie in a low-dimensional subspace (Argyriou et al., 2008; Kumar and III, 2012) which is achieved either by imposing low-rank constraint or matrix factorization.", "startOffset": 118, "endOffset": 162}, {"referenceID": 22, "context": "Following this idea, a multi-linear model was proposed in (Romera-Paredes et al., 2013) to deal with multi-modal tasks with multiple indexes.", "startOffset": 58, "endOffset": 87}, {"referenceID": 29, "context": "This tensor factorization idea also promotes a deep multitask learning model (Yang et al., 2016) where the parameters in different layers of a CNN for different tasks form a tensor that could be factorized across tasks.", "startOffset": 77, "endOffset": 96}, {"referenceID": 13, "context": "Moreover, many deep learning models have been introduced for multi-task learning (Liu et al., 2015b; Misra et al., 2016) with an aim to learn shared hidden representation that are regularized from different tasks.", "startOffset": 81, "endOffset": 120}, {"referenceID": 16, "context": "Moreover, many deep learning models have been introduced for multi-task learning (Liu et al., 2015b; Misra et al., 2016) with an aim to learn shared hidden representation that are regularized from different tasks.", "startOffset": 81, "endOffset": 120}, {"referenceID": 27, "context": "The base classifier used in our deep multi-task learning model is the coupled multi-layer attentions (CMLA) (Wang et al., 2017), which is proposed for aspect-opinion terms co-extraction.", "startOffset": 108, "endOffset": 127}, {"referenceID": 21, "context": "The idea behind the coupled attentions is to exploit the relations among the aspect terms and opinion terms for double propagation (Qiu et al., 2011; Wang et al., 2016).", "startOffset": 131, "endOffset": 168}, {"referenceID": 26, "context": "The idea behind the coupled attentions is to exploit the relations among the aspect terms and opinion terms for double propagation (Qiu et al., 2011; Wang et al., 2016).", "startOffset": 131, "endOffset": 168}, {"referenceID": 5, "context": "Specifically, given a sentence with pre-trained word embeddings {xi}\u2019s, Gated Recurrent Unit (GRU) (Cho et al., 2014) is applied on top of xi to obtain input feature representations H = {h1, .", "startOffset": 99, "endOffset": 117}, {"referenceID": 18, "context": "The experiments are conducted on three benchmark datasets from subtask 1 in SemEval Challenge 2015 task 12 (Pontiki et al., 2015), SemEval Challenge 2016 task 5 (Pontiki et al.", "startOffset": 107, "endOffset": 129}, {"referenceID": 19, "context": ", 2016), and SemEval Challenge 2014 task 4 (Pontiki et al., 2014), which are denoted by S1, S2, and S3, respectively.", "startOffset": 43, "endOffset": 65}, {"referenceID": 27, "context": "We use term-level aspect-opinion annotations provided by (Wang et al., 2017) for S1 and S3, and manually annotate opinion terms for S2.", "startOffset": 57, "endOffset": 76}, {"referenceID": 27, "context": "Follow (Wang et al., 2017), we first obtain word embeddings by applying word2vec4 on Yelp Challenge dataset5 and electronic domain in Amazon reviews (McAuley et al.", "startOffset": 7, "endOffset": 26}, {"referenceID": 15, "context": ", 2017), we first obtain word embeddings by applying word2vec4 on Yelp Challenge dataset5 and electronic domain in Amazon reviews (McAuley et al., 2015) for restaurant and laptop datasets, respectively.", "startOffset": 130, "endOffset": 152}, {"referenceID": 26, "context": "RNCRF+: We modify RNCRF (Wang et al., 2016), which is for aspect-opinion terms extraction, by defining finer-grained categories as labels.", "startOffset": 24, "endOffset": 43}, {"referenceID": 27, "context": "CMLA+: Similar to RNCRF+, we modify CMLA (Wang et al., 2017) by defining finergrained categories as labels.", "startOffset": 41, "endOffset": 60}], "year": 2017, "abstractText": "In aspect-based sentiment analysis, most existing methods either focus on aspect/opinion terms extraction or aspect terms categorization. However, each task by itself only provides partial information to end users. To generate more detailed and structured opinion analysis, we propose a finer-grained problem, which we call category-specific aspect and opinion terms extraction. This problem involves the identification of aspect and opinion terms within each sentence, as well as the categorization of the identified terms. To this end, we propose an end-to-end multitask attention model, where each task corresponds to aspect/opinion terms extraction for a specific category. Our model benefits from exploring the commonalities and relationships among different tasks to address the data sparsity issue. We demonstrate its state-of-the-art performance on three benchmark datasets.", "creator": "LaTeX with hyperref package"}}}