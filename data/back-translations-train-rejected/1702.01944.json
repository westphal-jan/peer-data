{"id": "1702.01944", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Feb-2017", "title": "EliXa: A Modular and Flexible ABSA Platform", "abstract": "This paper presents a supervised Aspect Based Sentiment Analysis (ABSA) system. Our aim is to develop a modular platform which allows to easily conduct experiments by replacing the modules or adding new features. We obtain the best result in the Opinion Target Extraction (OTE) task (slot 2) using an off-the-shelf sequence labeler. The target polarity classification (slot 3) is addressed by means of a multiclass SVM algorithm which includes lexical based features such as the polarity values obtained from domain and open polarity lexicons. The system obtains accuracies of 0.70 and 0.73 for the restaurant and laptop domain respectively, and performs second best in the out-of-domain hotel, achieving an accuracy of 0.80.", "histories": [["v1", "Tue, 7 Feb 2017 10:18:07 GMT  (19kb)", "http://arxiv.org/abs/1702.01944v1", "5 pages, conference"]], "COMMENTS": "5 pages, conference", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["i\\~naki san vicente", "xabier saralegi", "rodrigo agerri"], "accepted": false, "id": "1702.01944"}, "pdf": {"name": "1702.01944.pdf", "metadata": {"source": "CRF", "title": "EliXa: A modular and flexible ABSA platform", "authors": ["I\u00f1aki San Vicente", "Xabier Saralegi", "Rodrigo Agerri"], "emails": ["i.sanvicente@elhuyar.com", "x.saralegi@elhuyar.com", "rodrigo.agerri@ehu.eus"], "sections": [{"heading": null, "text": "ar Xiv: 170 2.01 944v 1 [cs.C L] 7F ebThis paper presents a monitored system of Aspect Based Sentiment Analysis (ABSA). Our goal is to develop a modular platform that makes it easy to conduct experiments by replacing the modules or adding new features. We achieve the best result in the Opinion Target Extraction (OTE) (slot 2) task with a standard sequence marker. Target polarity classification (slot 3) is performed using a multi-level SVM algorithm that includes lexical features such as polarity values obtained from domains and open polarity lexicons. The system achieves accuracies of 0.70 and 0.73 for the restaurant and laptop domains, respectively, and performs best in hotels outside the domain with an accuracy of 0.80."}, {"heading": "1 Introduction", "text": "The growing interest is also reflected in the number of related common tasks: TASS (Villena-Roma \u0301 n et al., 2012; Villena-Roma \u0301 n et al., 2014), SemEval (Nakov et al., 2013; Pontiki et al., 2014; Rosenthal et al., 2014) or the SemSA Challenge at ESWC20141. Research has also evolved toward specific opinion elements, such as entities or characteristics of a specific opinion goal, also known as ABSA. Semeval1http: / / challenges.2014.eswcconferences.org / index.php / SemSA2015 ABSA common tasks include the most common problems in an ABSA task: identifying the specific topics that concern an opinion (slot1); extracting the opinion goals (slot2); combining the topic and target identification (ABSA2015 ABSA shared); and mapping the common goals (ABSA)."}, {"heading": "2 External Resources", "text": "For the unrestricted versions of our systems, several polarity dictionaries and different corpora have been used. To facilitate the reproducibility of the results, each resource listed here is publicly accessible."}, {"heading": "2.1 Corpora", "text": "Below (Kiritchenko et al., 2014), we manually filtered 2http: / / www.yelp.com / dataset challengeout categories that do not correspond to food-related companies (173 out of 720 were eventually selected).A total of 997 721 reviews (117.1 million tokens) comprise what we henceforth call Yelp Food Corpus (CY elp).For the laptop domain, we used a corpus of Amazon reviews of electronic devices (Jo and Oh, 2011).Although only 17.53% of reviews concern laptop products, early experiments showed the advantage of using the full corpus for both slot 2 and slot 3 subtasks.The Amazon Electronics Corpus (CAmazon) consists of 24,259 reviews (4.4 million tokens).Finally, the English Wikipedia was also used to induce word clusters using word2vec (Mikolov, 2013)."}, {"heading": "2.2 Polarity Lexicons", "text": "We created two types of polarity lexicon to represent polarity in the Slot3 subtasks: universal and domain-specific polarity lexicon. A universal polarity lexicon Lgen was created by combining four well-known polarity lexicon: SentiWordSWN (Baccianella et al., 2010), General Inquirer GI (Stone et al., 1966), Opinion Finder OF (Wilson et al., 2005) and Liu's Mood lexicon Liu (Hu and Liu, 2004). If a problem occurs in multiple lexicon, its polarity is resolved according to the following priority order: Liu > OF > GI > SWN. The order was determined based on the results of (San Vicente et al., 2014). All polarity weights were set to [\u2212 1, 1] interval and polarity categories Likon \u2192 2, [1] -0.0; \u2212 0.8; \u2212 0.0; \u2212 0.9."}, {"heading": "3 Slot2 Subtask: Opinion Target Extraction", "text": "The result is a fairly simple but competitive system that achieves the best results. It is addressed as a sequence labeling problem. We use the ixa-pipe-nerc Named Entity Recognition system3 (Agerri et al., 2014) off-the-shelf to train our OTE models; the system learns supervised models using the Perceptron algorithm as described by (Collins, 2002). ixa-pipe-nerc implements basic non-linguistic local features and a combination of word class representations, some of which are derived from (Turian et al., 2010) the word representations use large amounts of unlabeled data. The result is a fairly simple but competitive system that provides the best results and the first and third best overall results."}, {"heading": "4 Slot3 Subtask: Sentiment Polarity", "text": "The EliXa system implements a single SVM multi-class classifier. We use the SMO implementation of the Weka library (Hall et al., 2009). All classifiers based on the training data were evaluated by 10-fold cross-validation and the complexity parameter was optimized as (C = 1.0). Many configurations were tested in these experiments, but in the following we will only describe the final setting."}, {"heading": "4.1 Baseline", "text": "The first features we introduced into our classifier were tokens. Initial experiments showed that lemmings (lgrams) performed better than raw form grams. One feature per lgram is added to the vector representation, and the lemmings frequency is stored. In terms of the Ngram size used, we tested up to 4 gram features, and improvements were made in the laptop domain, but only if they were not combined with other features."}, {"heading": "4.2 PoS", "text": "PoS tag and Lemma information obtained using the IXA Pipes tools (Agerri et al., 2014) were also included as features. One feature per PoS tag was added again and saves the number of occurrences of a tag in the set. Compared to the underlying value, these features only slightly improve in the restaurant sector."}, {"heading": "4.3 Window", "text": "Since a sentence may contain multiple opinions, we define a period of time around a particular opinion target (5 words before and 5 words after). If the target of an opinion is zero, the whole sentence is taken as a span. Only the restaurant and hotel domains contained gold target comments, so we did not use this feature in the laptop domain."}, {"heading": "4.4 Polarity Lexicons", "text": "The positive and negative values that we extracted as traits from both universal and domain-specific lexicon are calculated as the sum of all positive / negative values in the corresponding lexicon divided by the number of words in the sentence. Characteristics derived from the general lexicon represent a slight improvement. Lgenres is better for restaurant domains, while lengths are better for laptops. Domain-specific lexicon LAmazon and LY elp are also helpful, as shown in Tables 3 and 4."}, {"heading": "4.5 Word Clusters", "text": "Word2vec cluster functions are best combined with the rest, such as Table 3. These functions were only useful for the restaurant domain, perhaps due to the small size of the laptop domain data."}, {"heading": "4.6 Feature combinations", "text": "Some of these, such as the I & A features (using the gold information from the Slot1 subtask) for the laptop domain, only help in combination with others, and the best performance is achieved by combining several features. As Tables 4 and 5 show, the improvement over the base domain ranges from 2.8% to 1.9% in the laptop and restaurant domains respectively."}, {"heading": "4.7 Results", "text": "Table 5 shows the result of our Sentiment Polarity Classifier. Although we get results above the baseline for both restaurant and laptop domains, both performances are modest. In contrast, our system receives the third highest score for the out-domain track, which was evaluated in hotel ratings. Due to the similarity of the domains, we applied our restaurant domain models in a straightforward manner. The good results of the restricted system could mean that the feature combination used can be robust across domains. With regard to the unrestricted system, we suspect that such a good performance is achieved due to the fact that the word cluster information was very appropriate for the hotel domain, as Cyelp contains 10.55% of hotel reviews."}, {"heading": "5 Conclusions", "text": "We presented a modular and supervised ABSA platform designed to facilitate future experiments in the field. We submitted runs corresponding to the sub-tasks of Slot2 and Slot3, achieving competitive results. In particular, in Slot2 (OTE) we achieved the best results and in Slot3 we achieved the third best result in the out-of-domain route, which is nice for a supervised system. Finally, a theme recognition system (Slot1) is currently under development."}, {"heading": "6 Acknowledgments", "text": "This work was supported by the following projects: ADi project (Etortek grant No. IE-14-382), NewsReader (FP7-ICT 2011-8-316404), SKaTer (TIN2012-38584-C06-02) and Tacardi (TIN201238523-C02-01)."}], "references": [{"title": "Ixa pipeline: Efficient and ready to use multilingual nlp tools", "author": ["Josu Bermudez", "German Rigau"], "venue": "In Proceedings of the 9th Language Resources and Evaluation Conference", "citeRegEx": "Agerri et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Agerri et al\\.", "year": 2014}, {"title": "SentiWordNet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining", "author": ["A. Esuli", "F. Sebastiani"], "venue": "In Seventh conference on International Language Resources and Evaluation (LREC-", "citeRegEx": "Baccianella et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Baccianella et al\\.", "year": 2010}, {"title": "Class-based n-gram models of natural language", "author": ["Brown et al.1992] Peter F Brown", "Peter V Desouza", "Robert L Mercer", "Vincent J Della Pietra", "Jenifer C Lai"], "venue": null, "citeRegEx": "Brown et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Brown et al\\.", "year": 1992}, {"title": "Combining distributional and morphological information for part of speech induction", "author": ["Alexander Clark"], "venue": "In Proceedings of the tenth conference on European chapter of the Association for Computational Linguistics-Volume", "citeRegEx": "Clark.,? \\Q2003\\E", "shortCiteRegEx": "Clark.", "year": 2003}, {"title": "Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms. In Proceedings of the ACL-02 conference on Empirical methods in natural language processing-Volume", "author": ["Michael Collins"], "venue": null, "citeRegEx": "Collins.,? \\Q2002\\E", "shortCiteRegEx": "Collins.", "year": 2002}, {"title": "Accurate methods for the statistics of surprise and coincidence", "author": ["Ted Dunning"], "venue": "Computacional Linguistics,", "citeRegEx": "Dunning.,? \\Q1993\\E", "shortCiteRegEx": "Dunning.", "year": 1993}, {"title": "The WEKA data mining software: an update", "author": ["Hall et al.2009] Mark Hall", "Eibe Frank", "Geoffrey Holmes", "Bernhard Pfahringer", "Peter Reutemann", "Ian H. Witten"], "venue": "SIGKDD Explor. Newsl.,", "citeRegEx": "Hall et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Hall et al\\.", "year": 2009}, {"title": "Mining and summarizing customer reviews", "author": ["Hu", "Liu2004] M. Hu", "B. Liu"], "venue": "In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "Hu et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Hu et al\\.", "year": 2004}, {"title": "Aspect and sentiment unification model for online review", "author": ["Jo", "Oh2011] Yohan Jo", "Alice H. Oh"], "venue": null, "citeRegEx": "Jo et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Jo et al\\.", "year": 2011}, {"title": "NRCcanada-2014: Detecting aspects and sentiment in customer reviews", "author": ["Xiaodan Zhu", "Colin Cherry", "Saif Mohammad"], "venue": "In Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval", "citeRegEx": "Kiritchenko et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kiritchenko et al\\.", "year": 2014}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "SemEval-2013 task 2: Sentiment analysis in twitter", "author": ["Nakov et al.2013] Preslav Nakov", "Sara Rosenthal", "Zornitsa Kozareva", "Veselin Stoyanov", "Alan Ritter", "Theresa Wilson"], "venue": "In Proceedings of the Seventh International Workshop on Semantic Evaluation (Se-", "citeRegEx": "Nakov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Nakov et al\\.", "year": 2013}, {"title": "Semeval2014 task 4: Aspect based sentiment analysis", "author": ["Dimitrios Galanis", "John Pavlopoulos", "Harris Papageorgiou", "Ion Androutsopoulos", "Suresh Manandhar"], "venue": "In Proceedings of the International Workshop on Semantic", "citeRegEx": "Pontiki et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Pontiki et al\\.", "year": 2014}, {"title": "Semeval2014 task 9: Sentiment analysis in twitter", "author": ["Preslav Nakov", "Alan Ritter", "Veselin Stoyanov"], "venue": "In Proceedings of the 8th International Workshop on Semantic Evaluation, SemEval,", "citeRegEx": "Rosenthal et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Rosenthal et al\\.", "year": 2014}, {"title": "Simple, robust and (almost) unsupervised generation of polarity lexicons for multiple languages", "author": ["Rodrigo Agerri", "German Rigau"], "venue": "In Proceedings of the 14th Conference of the European Chapter of the Associa-", "citeRegEx": "Vicente et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Vicente et al\\.", "year": 2014}, {"title": "The General Inquirer: A Computer Approach to Content Analysis", "author": ["Stone et al.1966] P. Stone", "D. Dunphy", "M. Smith", "D. Ogilvie"], "venue": null, "citeRegEx": "Stone et al\\.,? \\Q1966\\E", "shortCiteRegEx": "Stone et al\\.", "year": 1966}, {"title": "Word representations: A simple and general method for semi-supervised learning", "author": ["Turian et al.2010] Joseph Turian", "Lev-Arie Ratinov", "Yoshua Bengio"], "venue": "In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Turian et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Turian et al\\.", "year": 2010}, {"title": "Recognizing contextual polarity in phrase-level sentiment analysis", "author": ["Paul Hoffmann."], "venue": "Proceedings", "citeRegEx": "Hoffmann.,? 2005", "shortCiteRegEx": "Hoffmann.", "year": 2005}], "referenceMentions": [{"referenceID": 11, "context": ", 2014), SemEval (Nakov et al., 2013; Pontiki et al., 2014; Rosenthal et al., 2014), or the SemSA Challenge at ESWC20141.", "startOffset": 17, "endOffset": 83}, {"referenceID": 12, "context": ", 2014), SemEval (Nakov et al., 2013; Pontiki et al., 2014; Rosenthal et al., 2014), or the SemSA Challenge at ESWC20141.", "startOffset": 17, "endOffset": 83}, {"referenceID": 13, "context": ", 2014), SemEval (Nakov et al., 2013; Pontiki et al., 2014; Rosenthal et al., 2014), or the SemSA Challenge at ESWC20141.", "startOffset": 17, "endOffset": 83}, {"referenceID": 0, "context": "The EliXa system consists of three independent supervised modules based on the IXA pipes tools (Agerri et al., 2014) and Weka (Hall et al.", "startOffset": 95, "endOffset": 116}, {"referenceID": 6, "context": ", 2014) and Weka (Hall et al., 2009).", "startOffset": 17, "endOffset": 36}, {"referenceID": 9, "context": "Following (Kiritchenko et al., 2014), we manually filtered", "startOffset": 10, "endOffset": 36}, {"referenceID": 10, "context": "Finally, the English Wikipedia was also used to induce word clusters using word2vec (Mikolov et al., 2013).", "startOffset": 84, "endOffset": 106}, {"referenceID": 1, "context": "A general purpose polarity lexicon Lgen was built by combining four well known polarity lexicons: SentiWordnet SWN (Baccianella et al., 2010), General Inquirer GI (Stone et al.", "startOffset": 115, "endOffset": 141}, {"referenceID": 15, "context": ", 2010), General Inquirer GI (Stone et al., 1966), Opinion Finder OF (Wilson et al.", "startOffset": 29, "endOffset": 49}, {"referenceID": 5, "context": "Using the Log-likelihood ratio (LLR) (Dunning, 1993) we obtained the ranking of the words which occur more with negative and positive reviews respectively.", "startOffset": 37, "endOffset": 52}, {"referenceID": 0, "context": "We use the ixa-pipe-nerc Named Entity Recognition system3 (Agerri et al., 2014) off-the-shelf to train our OTE models; the system learns supervised models via the Perceptron algorithm as described by (Collins, 2002).", "startOffset": 58, "endOffset": 79}, {"referenceID": 4, "context": ", 2014) off-the-shelf to train our OTE models; the system learns supervised models via the Perceptron algorithm as described by (Collins, 2002).", "startOffset": 128, "endOffset": 143}, {"referenceID": 16, "context": "Specifically, ixa-pipe-nerc implements basic nonlinguistic local features and on top of those a combination of word class representation features partially inspired by (Turian et al., 2010).", "startOffset": 168, "endOffset": 189}, {"referenceID": 2, "context": "\u2022 Brown (Brown et al., 1992) clusters, taking the 4th, 8th, 12th and 20th node in the path.", "startOffset": 8, "endOffset": 28}, {"referenceID": 3, "context": "\u2022 Clark (Clark, 2003) clusters, using the standard configuration to induce 200 clusters on the Yelp reviews dataset and 100 clusters on the food portion of the Yelp reviews dataset.", "startOffset": 8, "endOffset": 21}, {"referenceID": 10, "context": "\u2022 Word2vec (Mikolov et al., 2013) clusters, based on K-means applied over the extracted word vectors using the skip-gram algorithm6; 400 clusters were induced using the Wikipedia.", "startOffset": 11, "endOffset": 33}, {"referenceID": 6, "context": "We use the SMO implementation provided by the Weka library (Hall et al., 2009).", "startOffset": 59, "endOffset": 78}, {"referenceID": 0, "context": "PoS tag and lemma information, obtained using the IXA pipes tools (Agerri et al., 2014), were also included as features.", "startOffset": 66, "endOffset": 87}], "year": 2017, "abstractText": "This paper presents a supervised Aspect Based Sentiment Analysis (ABSA) system. Our aim is to develop a modular platform which allows to easily conduct experiments by replacing the modules or adding new features. We obtain the best result in the Opinion Target Extraction (OTE) task (slot 2) using an off-the-shelf sequence labeler. The target polarity classification (slot 3) is addressed by means of a multiclass SVM algorithm which includes lexical based features such as the polarity values obtained from domain and open polarity lexicons. The system obtains accuracies of 0.70 and 0.73 for the restaurant and laptop domain respectively, and performs second best in the out-of-domain hotel, achieving an accuracy of 0.80.", "creator": "LaTeX with hyperref package"}}}