{"id": "1702.02363", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Feb-2017", "title": "Automatically Annotated Turkish Corpus for Named Entity Recognition and Text Categorization using Large-Scale Gazetteers", "abstract": "Turkish Wikipedia Named-Entity Recognition and Text Categorization (TWNERTC) dataset is a collection of automatically categorized and annotated sentences obtained from Wikipedia. We constructed large-scale gazetteers by using a graph crawler algorithm to extract relevant entity and domain information from a semantic knowledge base, Freebase. The constructed gazetteers contains approximately 300K entities with thousands of fine-grained entity types under 77 different domains. Since automated processes are prone to ambiguity, we also introduce two new content specific noise reduction methodologies. Moreover, we map fine-grained entity types to the equivalent four coarse-grained types: person, loc, org, misc. Eventually, we construct six different dataset versions and evaluate the quality of annotations by comparing ground truths from human annotators. We make these datasets publicly available to support studies on Turkish named-entity recognition (NER) and text categorization (TC).", "histories": [["v1", "Wed, 8 Feb 2017 10:45:23 GMT  (108kb,D)", "https://arxiv.org/abs/1702.02363v1", "10 page, 1 figure, white paper"], ["v2", "Thu, 9 Feb 2017 08:35:12 GMT  (103kb,D)", "http://arxiv.org/abs/1702.02363v2", "10 page, 1 figure, white paper, update: added correct download link for dataset"]], "COMMENTS": "10 page, 1 figure, white paper", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["h bahadir sahin", "caglar tirkaz", "eray yildiz", "mustafa tolga eren", "ozan sonmez"], "accepted": false, "id": "1702.02363"}, "pdf": {"name": "1702.02363.pdf", "metadata": {"source": "CRF", "title": "Automatically Annotated Turkish Corpus for Named Entity Recognition and Text Categorization using Large-Scale Gazetteers", "authors": ["H. Bahadir Sahin", "Caglar Tirkaz", "Eray Yildiz", "Mustafa Tolga Eren", "Ozan Sonmez"], "emails": ["eray.yildiz@huawei.com", "osonmez@gmail.com"], "sections": [{"heading": "1 Introduction", "text": "In fact, the goal of Text Categorization (TC) is to define correct categories for texts based on their contents. It is difficult to construct data sets for these tasks that require excessive human effort, time and budget. In this paper, our motivation is to construct an automatically annotated data collection that would be very useful for research in Turkey. It is difficult to construct data sets for these tasks that require excessive human effort, time and budget."}, {"heading": "2 Related Work", "text": "There are few studies dealing with the problem of \"finegrained,\" which capture the challenge of more than four entity types (Pasca et al., 2006; Ekbal et al., 2010; Yogatama et al., 2015).How research on the limits of automated systems that drive the \"named\" designations and designations is important."}, {"heading": "3 Dataset Construction Methodology", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Constructing Gazetteers", "text": "USA, in the USA, in Europe, in the USA, in the USA, in the USA, in Europe, in the USA, in Europe, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in Europe, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA,"}, {"heading": "4 Automatic Annotation Generation", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Fine-Grained Annotations", "text": "A knowledge diagram consists of nodes and edges between nodes defined by the schema of a domain. Nodes are entities and edges represent relationships between nodes that are properties in Freebase. Examples of entities and relationships are shown in Figure 1, for \"film\" and \"people\" domains. The central node that has the most relationships in the film domain is the \"movie name.\" We name directly connected relationships to the central node as first-order relationships. The name of the director who directed the movie is \"film director\" relationship. Since directors are human, they also have relationships in the \"person\" domain. Through such a relationship, we can get second-order relationships over a movie. We benefit from the raw texts that are commented on and categorized."}, {"heading": "4.2 Statistics of the FGA", "text": "TWNERTC contains a total of 300K units, of which 110K have Turkish descriptions (from Freebase or Wikipedia dump). There are a total of 700171 annotated sets from 49 different domains, with the largest and smallest domains being persons (139K sets) and fashion (493 sets). TWNERTC consists of 10997037 non-punctuated tokens, and among these tokens, about 2M of them are commented. 16K of the tags are unique, resulting in an average of about 332 unique entity types per domain. Note that even if a sentence is categorized into the movie domain, it may contain units from other domains, such as person and time. Location is the domain with the highest number of unique tags (1051), while physics has the lowest set of unique tags (15)."}, {"heading": "4.3 Disambiguate Noisy Entity Types", "text": "We refine the gazettes to minimize the impact of noise in the annotations generated and the domains assigned to them. However, due to the nature of the automated algorithm, we find that entity annotations still have inconsistent or missing types, while the categorization process is generally conducted with more precision. To reduce the remaining noise, we apply both domain-dependent and domain-independent noise reduction. Domain-dependent approaches find the most common entity type of each entity according to the domain of the records. Subsequently, entities with common entity types are recommented. Domain-independent approaches follow the same procedure without using domain information, while the loud information is eliminated. Statistics on these two versions of the data set are presented in Table 1."}, {"heading": "4.4 Transform FGA to Coarse-Grained Annotation", "text": "FGA provides fine-grained annotations with many detailed entity types and properties. However, the number of different entity types negatively affects learning algorithms. Furthermore, it is difficult to evaluate the quality of annotations when most literature recognizes coarse-grained entity types. Therefore, we offer a coarse-grained version of the FGA datasets. To convert the FGA into coarse-grained annotations (CGA), we assign each fine-grained entity type in each domain to a coarse-grained entity type, i.e. person, organization, location, and other. We retain IOB notations in types and convert the type. In this process, we eliminate multiple domains, such as meteorology, interests, and chemistry, due to the lack of types that can be assigned to a coarse entity."}, {"heading": "5 Evaluation", "text": "Dre rf\u00fc ide rf\u00fc ide rf\u00fc the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the"}, {"heading": "5.1 Evaluation Results for Coarse-Grained Annotations", "text": "In Table 3, we present the number of entity types that exist in automatically and manually annotated sets, with the number of changes that annotators have made. Type O changes to any other type are defined as addition, and the opposite of this action is removal. Misc is the most frequently added, removed, and modified type of annotator. It is an acceptable result, since this specific type covers a large number of entities except for person, place, and organization. We do not consider the number of added entity types to be a major problem, since our annotators do not have infinite information and we have future plans to improve them. However, incorrectly annotated types are the real danger, because if the number of such errors increases, the performance of the learning algorithms will be negatively affected."}, {"heading": "5.2 Evaluation Results for Fine-Grained Annotations", "text": "As we have already discussed, we train an external fine-grained algorithm, FIGER, to create Turkish NER models for all versions of the TWNERTC. Using the resulting models, we take five possible predicted types for each unit represented in test sets, and provide them to five human commentators as basic truths. Obviously, FIGER was developed to solve fine-grained NER in English; however, to evaluate the automated fine-grained types in a reasonable time, we use predictions of this algorithm. In Table 5, we present the F1 values of trained models on each test set. We provide these values to give researchers a better insight into basic truths. Note that the strict F1score formula represents the original F1score formula, while loose macro and loose mi-cro values represent variations of the same formula (Ling and Weld, 2012). It is noted that the model trained with the original TWNERTC can only verify that the non-graded DI does not work in comparison."}, {"heading": "5.3 Evaluation Results for TC", "text": "The number of domains causes ambiguities in categorizing sentences according to context, so we evaluate three levels of accuracy. Table 7 shows that automatically assigned domains have relatively low direct matches with commentators according to the top-1 rating. However, when we look at top-3, the accuracy scores double. In addition, the error rate is less than% 2 when all five basic truths are taken into account. Note, for example, that in top-3 and top-5, we only take into account whether an automatically assigned domain exists or not in the basic truth list. The difference between top-1 and top-3 values is mainly caused by commentators \"different understanding of the sentence context. For example, a sentence about Lionel Messi's place of birth is categorized as people in the test group, whereas basic truths start with football, followed by people and places. Furthermore, similar domains, such as sports and football, are the reason for this inaccuracy."}, {"heading": "6 Conclusion and Future Research Directions", "text": "We have described six publicly available corporas for NER and TC tasks in Turkish. The data consists of Wikipedia texts, which are commented on and categorized according to the entity and domain information extracted from Freebase. We explain the structure of the data sets and introduce methods to eliminate noisy and false data. We provide comprehensive statistics on the content of the data sets. We analyzed subsets of these data sets and value automatically generated annotations and domains against manually generated truths. The end results show that automatic annotations and domains are quite similar to the fundamentals.The obvious next step is to develop learning algorithms for NER and TC tasks to find baselines using traditional machine learning algorithms and expand on these foundations with approaches. As TWNERTC provides an enormous amount of structured data for researchers, profound learning methods can be used to solve grainy NERS problems."}, {"heading": "7 Acknowledgments", "text": "This project is partly funded by the 3140951 numbered TUBITAK-TEYDEB (The Scientific and Technological Research Council of Turkey - Technology and Innovation Funding Programs Directorate)."}], "references": [{"title": "Categorization of turkish news documents with morphological analysis", "author": ["Akku\u015f", "\u00c7ak\u0131c\u01312013] Burak Kerim Akku\u015f", "Ruket \u00c7ak\u0131c\u0131"], "venue": "In ACL (Student Research Workshop),", "citeRegEx": "Akku\u015f et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Akku\u015f et al\\.", "year": 2013}, {"title": "Rule-based sentence detection method (rbsdm) for turkish", "author": ["Akta\u015f", "\u00c7ebi2013] \u00d6zlem Akta\u015f", "Yal\u00e7\u0131n \u00c7ebi"], "venue": "International Journal of Language and Linguistics,", "citeRegEx": "Akta\u015f et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Akta\u015f et al\\.", "year": 2013}, {"title": "Automatic turkish text categorization in terms of author, genre and gender", "author": ["Amasyal\u0131", "Diri2006] M Fatih Amasyal\u0131", "Banu Diri"], "venue": "In Natural Language Processing and Information Systems,", "citeRegEx": "Amasyal\u0131 et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Amasyal\u0131 et al\\.", "year": 2006}, {"title": "Large-scale named entity disambiguation based on wikipedia data", "author": ["Silviu Cucerzan"], "venue": "In EMNLP-CoNLL,", "citeRegEx": "Cucerzan.,? \\Q2007\\E", "shortCiteRegEx": "Cucerzan.", "year": 2007}, {"title": "Improving named entity recognition for morphologically rich languages using word embeddings", "author": ["Demir", "\u00d6zgur2014] Hakan Demir", "Arzucan \u00d6zgur"], "venue": "In Machine Learning and Applications (ICMLA),", "citeRegEx": "Demir et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Demir et al\\.", "year": 2014}, {"title": "Assessing the challenge of fine-grained named entity recognition and classification", "author": ["Ekbal et al.2010] Asif Ekbal", "Eva Sourjikova", "Anette Frank", "Simone Paolo Ponzetto"], "venue": "In proceedings of the 2010 Named Entities Workshop,", "citeRegEx": "Ekbal et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Ekbal et al\\.", "year": 2010}, {"title": "Toruno\u011flu, and G\u00fcl\u015fen Eryi\u011fit", "author": ["Dilara"], "venue": null, "citeRegEx": "\u00c7elikkaya and Dilara,? \\Q2013\\E", "shortCiteRegEx": "\u00c7elikkaya and Dilara", "year": 2013}, {"title": "Real-time rdf extraction from unstructured data streams", "author": ["Gerber et al.2013] Daniel Gerber", "Sebastian Hellmann", "Lorenz B\u00fchmann", "Tommaso Soru", "Ricardo Usbeck", "Axel-Cyrille Ngonga Ngomo"], "venue": "In The Semantic Web\u2013ISWC", "citeRegEx": "Gerber et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Gerber et al\\.", "year": 2013}, {"title": "Leveraging knowledge graphs for", "author": ["Heck et al.2013] Larry P Heck", "Dilek Hakkani-T\u00fcr", "G\u00f6khan T\u00fcr"], "venue": null, "citeRegEx": "Heck et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Heck et al\\.", "year": 2013}, {"title": "Robust disambiguation of named entities in text", "author": ["Mohamed Amir Yosef", "Ilaria Bordino", "Hagen F\u00fcrstenau", "Manfred Pinkal", "Marc Spaniol", "Bilyana Taneva", "Stefan Thater", "Gerhard Weikum"], "venue": null, "citeRegEx": "Hoffart et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Hoffart et al\\.", "year": 2011}, {"title": "Ttc-3600: A new benchmark dataset for turkish text categorization", "author": ["K\u0131l\u0131n\u00e7 et al.2015] Deniz K\u0131l\u0131n\u00e7", "Ak\u0131n \u00d6z\u00e7ift", "Fatma Bozyigit", "Pelin Y\u0131ld\u0131r\u0131m", "Fatih Y\u00fccalar", "Emin Borandag"], "venue": "Journal of Information Science,", "citeRegEx": "K\u0131l\u0131n\u00e7 et al\\.,? \\Q2015\\E", "shortCiteRegEx": "K\u0131l\u0131n\u00e7 et al\\.", "year": 2015}, {"title": "Experiments to improve named entity recognition on turkish tweets", "author": ["K\u00fc\u00e7\u00fck", "Steinberger2014] Dilek K\u00fc\u00e7\u00fck", "Ralf Steinberger"], "venue": "arXiv preprint arXiv:1410.8668", "citeRegEx": "K\u00fc\u00e7\u00fck et al\\.,? \\Q2014\\E", "shortCiteRegEx": "K\u00fc\u00e7\u00fck et al\\.", "year": 2014}, {"title": "Named entity recognition on turkish tweets", "author": ["K\u00fc\u00e7\u00fck et al.2014] Dilek K\u00fc\u00e7\u00fck", "Guillaume Jacquet", "Ralf Steinberger"], "venue": "In LREC,", "citeRegEx": "K\u00fc\u00e7\u00fck et al\\.,? \\Q2014\\E", "shortCiteRegEx": "K\u00fc\u00e7\u00fck et al\\.", "year": 2014}, {"title": "Rcv1: A new benchmark collection for text categorization research", "author": ["Lewis et al.2004] David D Lewis", "Yiming Yang", "Tony G Rose", "Fan Li"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Lewis et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Lewis et al\\.", "year": 2004}, {"title": "Fine-grained entity recognition", "author": ["Ling", "Weld2012] Xiao Ling", "Daniel S Weld"], "venue": "In AAAI", "citeRegEx": "Ling et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Ling et al\\.", "year": 2012}, {"title": "Automated rule selection for aspect extraction in opinion mining", "author": ["Liu et al.2015] Qian Liu", "Zhiqiang Gao", "Bing Liu", "Yuanlin Zhang"], "venue": "In International Joint Conference on Artificial Intelligence (IJCAI)", "citeRegEx": "Liu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2015}, {"title": "Dbpedia spotlight: shedding light on the web of documents", "author": ["Max Jakob", "Andr\u00e9s Garc\u0131\u0301a-Silva", "Christian Bizer"], "venue": "In Proceedings of the 7th International Conference on Semantic Systems,", "citeRegEx": "Mendes et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Mendes et al\\.", "year": 2011}, {"title": "Improving gender classification of blog authors", "author": ["Mukherjee", "Liu2010] Arjun Mukherjee", "Bing Liu"], "venue": "In Proceedings of the 2010 conference on Empirical Methods in natural Language Processing,", "citeRegEx": "Mukherjee et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Mukherjee et al\\.", "year": 2010}, {"title": "Named entity recognition from scratch on social media", "author": ["\u00d6nal", "Karag\u00f6z2015] Kezban Dilek \u00d6nal", "Pinar Karag\u00f6z"], "venue": null, "citeRegEx": "\u00d6nal et al\\.,? \\Q2015\\E", "shortCiteRegEx": "\u00d6nal et al\\.", "year": 2015}, {"title": "Organizing and searching the world wide web of factsstep one: the one-million fact extraction challenge", "author": ["Pasca et al.2006] Marius Pasca", "Dekang Lin", "Jeffrey Bigham", "Andrei Lifchits", "Alpa Jain"], "venue": "In AAAI,", "citeRegEx": "Pasca et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Pasca et al\\.", "year": 2006}, {"title": "The reuters corpus volume 1-from", "author": ["Rose et al.2002] Tony Rose", "Mark Stevenson", "Miles Whitehead"], "venue": null, "citeRegEx": "Rose et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Rose et al\\.", "year": 2002}, {"title": "Machine learning in automated text categorization. ACM computing surveys (CSUR), 34(1):1\u201347", "author": ["Fabrizio Sebastiani"], "venue": null, "citeRegEx": "Sebastiani.,? \\Q2002\\E", "shortCiteRegEx": "Sebastiani.", "year": 2002}, {"title": "Large-scale cross-document coreference using distributed inference and hierarchical models", "author": ["Singh et al.2011] Sameer Singh", "Amarnag Subramanya", "Fernando Pereira", "Andrew McCallum"], "venue": "In Proceedings of the 49th Annual Meeting of the Associa-", "citeRegEx": "Singh et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Singh et al\\.", "year": 2011}, {"title": "Statistical analyses of named entity disambiguation benchmarks. In NLPDBPEDIA@ ISWC", "author": ["Magnus Knuth", "Harald Sack"], "venue": null, "citeRegEx": "Steinmetz et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Steinmetz et al\\.", "year": 2013}, {"title": "Introduction to the conll-2003 shared task: Language-independent named entity recognition", "author": ["Tjong Kim Sang", "Fien De Meulder"], "venue": "In Proceedings of the seventh conference on Natural language learning", "citeRegEx": "Sang et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Sang et al\\.", "year": 2003}, {"title": "Developing a text categorization template for turkish news portals", "author": ["Fazl\u0131 Can", "Seyit Ko\u00e7berber"], "venue": "In Innovations in Intelligent Systems and Applications (INISTA),", "citeRegEx": "Toraman et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Toraman et al\\.", "year": 2011}, {"title": "A statistical information extraction system for turkish", "author": ["T\u00fcr et al.2003] G\u00f6khan T\u00fcr", "Dilek Hakkani-T\u00fcr", "Kemal Oflazer"], "venue": "Natural Language Engineering,", "citeRegEx": "T\u00fcr et al\\.,? \\Q2003\\E", "shortCiteRegEx": "T\u00fcr et al\\.", "year": 2003}, {"title": "Embedding methods for fine grained entity type classification", "author": ["Dan Gillick", "Nevena Lazic"], "venue": "In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint", "citeRegEx": "Yogatama et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Yogatama et al\\.", "year": 2015}, {"title": "Aida: An online tool for accurate disambiguation of named entities in text and tables", "author": ["Johannes Hoffart", "Ilaria Bordino", "Marc Spaniol", "Gerhard Weikum"], "venue": "Proceedings of the VLDB Endowment,", "citeRegEx": "Yosef et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Yosef et al\\.", "year": 2011}], "referenceMentions": [{"referenceID": 8, "context": "(Heck et al., 2013; Gerber et al., 2013; Hoffart et al., 2011; Mendes et al., 2011).", "startOffset": 0, "endOffset": 83}, {"referenceID": 7, "context": "(Heck et al., 2013; Gerber et al., 2013; Hoffart et al., 2011; Mendes et al., 2011).", "startOffset": 0, "endOffset": 83}, {"referenceID": 9, "context": "(Heck et al., 2013; Gerber et al., 2013; Hoffart et al., 2011; Mendes et al., 2011).", "startOffset": 0, "endOffset": 83}, {"referenceID": 16, "context": "(Heck et al., 2013; Gerber et al., 2013; Hoffart et al., 2011; Mendes et al., 2011).", "startOffset": 0, "endOffset": 83}, {"referenceID": 21, "context": "TC research predates to \u201960s; however, it is accepted as a research field in \u201990s with the advances in technology and learning algorithms (Sebastiani, 2002).", "startOffset": 138, "endOffset": 156}, {"referenceID": 23, "context": "(Steinmetz et al., 2013) published benchmark evaluations that compare three datasets that use semantic information from KBs: DBpedia Spotlight (Mendes et al.", "startOffset": 0, "endOffset": 24}, {"referenceID": 16, "context": ", 2013) published benchmark evaluations that compare three datasets that use semantic information from KBs: DBpedia Spotlight (Mendes et al., 2011), KORE50 (Hoffart et al.", "startOffset": 126, "endOffset": 147}, {"referenceID": 9, "context": ", 2011), KORE50 (Hoffart et al., 2011; Yosef et al., 2011) and the Wikilinks Corpus (Singh et al.", "startOffset": 16, "endOffset": 58}, {"referenceID": 28, "context": ", 2011), KORE50 (Hoffart et al., 2011; Yosef et al., 2011) and the Wikilinks Corpus (Singh et al.", "startOffset": 16, "endOffset": 58}, {"referenceID": 22, "context": ", 2011) and the Wikilinks Corpus (Singh et al., 2011).", "startOffset": 33, "endOffset": 53}, {"referenceID": 9, "context": "There are other methodologies which leverages KBs to named entity extraction and linking; however, most of them are not available to public (Hoffart et al., 2011; Heck et al., 2013).", "startOffset": 140, "endOffset": 181}, {"referenceID": 8, "context": "There are other methodologies which leverages KBs to named entity extraction and linking; however, most of them are not available to public (Hoffart et al., 2011; Heck et al., 2013).", "startOffset": 140, "endOffset": 181}, {"referenceID": 15, "context": "In general, there are many TC datasets available in English for many different problems such as sentiment analysis (Liu et al., 2015) and categorizing gender (Mukherjee and Liu, 2010).", "startOffset": 115, "endOffset": 133}, {"referenceID": 20, "context": "Corpus Volume 1 (RCV1) which consists of manually categorized 800K news stories with over 100 sub-categories under three different main categories (Rose et al., 2002).", "startOffset": 147, "endOffset": 166}, {"referenceID": 13, "context": "propose an improved version of this dataset with reduced categorization mistakes and provide a better documentation (Lewis et al., 2004).", "startOffset": 116, "endOffset": 136}, {"referenceID": 26, "context": "(T\u00fcr et al., 2003).", "startOffset": 0, "endOffset": 18}, {"referenceID": 11, "context": "Due to the research focus in the field, several Twitter-based coarse-grained NER datasets are published (K\u00fc\u00e7\u00fck et al., 2014; K\u00fc\u00e7\u00fck and Steinberger, 2014; Tantug, 2015).", "startOffset": 104, "endOffset": 167}, {"referenceID": 25, "context": "tain and classify manually (Akku\u015f and \u00c7ak\u0131c\u0131, 2013; Toraman et al., 2011; K\u0131l\u0131n\u00e7 et al., 2015).", "startOffset": 27, "endOffset": 94}, {"referenceID": 10, "context": "tain and classify manually (Akku\u015f and \u00c7ak\u0131c\u0131, 2013; Toraman et al., 2011; K\u0131l\u0131n\u00e7 et al., 2015).", "startOffset": 27, "endOffset": 94}, {"referenceID": 8, "context": "(Heck et al., 2013) who employ a method that takes advantage of user click logs of a web search engine in order to improve precision of gazetteers while maintaining recall.", "startOffset": 0, "endOffset": 19}, {"referenceID": 8, "context": "Inspired by the approach of (Heck et al., 2013), we create a graph crawling algorithm that is capable of categorizing sentences into Freebase domains and annotate named entities within the sentences with", "startOffset": 28, "endOffset": 47}], "year": 2017, "abstractText": "Turkish Wikipedia Named-Entity Recognition and Text Categorization (TWNERTC) dataset is a collection of automatically categorized and annotated sentences obtained from Wikipedia. We constructed large-scale gazetteers by using a graph crawler algorithm to extract relevant entity and domain information from a semantic knowledge base, Freebase1. The constructed gazetteers contains approximately 300K entities with thousands of fine-grained entity types under 77 different domains. Since automated processes are prone to ambiguity, we also introduce two new content specific noise reduction methodologies. Moreover, we map fine-grained entity types to the equivalent four coarse-grained types, person, loc, org, misc. Eventually, we construct six different dataset versions and evaluate the quality of annotations by comparing ground truths from human annotators. We make these datasets publicly available to support studies on Turkish named-entity recognition (NER) and text categorization (TC).", "creator": "LaTeX with hyperref package"}}}