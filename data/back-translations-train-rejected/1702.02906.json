{"id": "1702.02906", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Feb-2017", "title": "Switching EEG Headsets Made Easy: Reducing Offline Calibration Effort Using Active Weighted Adaptation Regularization", "abstract": "Electroencephalography (EEG) headsets are the most commonly used sensing devices for Brain-Computer Interface. In real-world applications, there are advantages to extrapolating data from one user session to another. However, these advantages are limited if the data arise from different hardware systems, which often vary between application spaces. Currently, this creates a need to recalibrate classifiers, which negatively affects people's interest in using such systems. In this paper, we employ active weighted adaptation regularization (AwAR), which integrates weighted adaptation regularization (wAR) and active learning, to expedite the calibration process. wAR makes use of labeled data from the previous headset and handles class-imbalance, and active learning selects the most informative samples from the new headset to label. Experiments on single-trial event-related potential classification show that AwAR can significantly increase the classification accuracy, given the same number of labeled samples from the new headset. In other words, AwAR can effectively reduce the number of labeled samples required from the new headset, given a desired classification accuracy, suggesting value in collating data for use in wide scale transfer-learning applications.", "histories": [["v1", "Thu, 9 Feb 2017 17:24:22 GMT  (935kb)", "http://arxiv.org/abs/1702.02906v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.HC", "authors": ["dongrui wu", "vernon j lawhern", "w david hairston", "brent j lance"], "accepted": false, "id": "1702.02906"}, "pdf": {"name": "1702.02906.pdf", "metadata": {"source": "CRF", "title": "Switching EEG Headsets Made Easy: Reducing Offline Calibration Effort Using Active Weighted Adaptation Regularization", "authors": ["Dongrui Wu"], "emails": ["drwu09@gmail.com).", "vernon.j.lawhern.civ@mail.mil).", "william.d.hairston4.civ@mail.mil,", "brent.j.lance.civ@mail.mil)."], "sections": [{"heading": null, "text": "The views and justifications of the authors of these documents are essentially the terms \"EEG\" and \"EEG,\" which encompass the potential and the potentials of the individual areas, namely both the manner and the manner in which they move, as well as the way in which they move, as well as the way in which they move, as well as the way in which they move, and the way in which they move, as well as the way in which they move, and in which they move, in which they themselves and the way in which they move, in which they themselves and the way in which they move, in which they engage in the way and the way in which they move, in which they let themselves be understood, in which they let themselves be understood, in which they let themselves be understood, in which they let themselves be understood, in which they let themselves be understood, in which they let themselves be understood, in which they let themselves be understood, in which they let themselves be understood, in which they let themselves, in which they let themselves be understood, in which they let themselves be understood, in which they let themselves be understood, in which they let themselves be understood, in which they let themselves be understood, in which they let themselves, in which they let themselves be understood, in which they let themselves be understood, in which they let themselves, in which they let themselves be understood, in which they let themselves, in which they let themselves be understood, in which they let themselves, in which they let themselves be understood, in which they let themselves, in which they let themselves be understood, in which they let themselves, in which they let themselves be understood, in which they let themselves, in which they let themselves, in which they let themselves, in which they let themselves be understood, in which they let themselves, in which they let themselves be understood, in which they let themselves, in which they let themselves be understood, in which they let themselves, in which they let themselves be understood, in which they let themselves, in which they let themselves, in which they let themselves be understood, in which they let themselves, in which they let themselves, in which they let themselves be understood, in which they let themselves, in which they let themselves, in which they let themselves, in which they let themselves, in which they let themselves, in which they let themselves, in which they let themselves, in which they let themselves, in which they let themselves,"}, {"heading": "II. WEIGHTED ADAPTATION REGULARIZATION (WAR)", "text": "This section introduces the details of the WAR algorithms. We consider a two-class classification of the EEG data, but the algorithms can also be generalized to other calibration problems."}, {"heading": "A. Problem Definition", "text": "Given a large amount of EEG epochs from one headset, how can this data be used to adapt a classifier for another headset? Although EEG epochs from the two headsets are not usually completely consistent, previous data still contain useful information, due to the fact that they came from the same subject. (As a result, the amount of calibration data can be reduced if these auxiliary EEG epochs are used.) A domain D consists of a framework for addressing the above issue. (Some notations used in TL and wAR are nex.Definition 1: (Domain) xxxxxxxx.s Domain D is defined by a d-dimensional feature Space X and a marginal probability distribution P (x), i.e., D = {X, P (x)}, where x.If two domains and Dt are different."}, {"heading": "B. The Learning Framework", "text": "The question we have to ask ourselves is whether we are able to take into account the differences between the two target areas: F = argmin f = hKn = 1ws, i (f (xi), yi), yi (yi), yi), yi (wtn + ml), yi (i), yi (i), yi (i), yi (i), yi (i), yi (i), yi (i), yi (i), yi (i), yi (i), i (i), i (i), i (i)."}, {"heading": "C. Loss Functions Minimization", "text": "Two common loss functions are squared loss for regularized micro-squares (RLS =): (f (xi), yi) = (yi \u2212 f (xi)) 2 (6) and hinge loss for support vector machines (SVMs): (f (xi), yi) = max (0, 1 \u2212 yif (xi) (7) Both are taken into account in this paper. \u2212 \u2212 \u2212 In the following, we refer to the square loss classifier as wAR-RLS and the loss determined with hinge loss as wAR-SVM.4 (1) (Eiy = [y1,..., yn + ml + mu] T (8), where {y1,..., yn} are known designations in the source domain, {yn + 1, yn + ml} are known designations in the target domain, and {yn + ml} are known designations in the target domain, and {yn + ml} are known designations in the target domain..."}, {"heading": "D. Structural Risk Minimization", "text": "As in [23], [45] we define structural risk as the square norm of f in HK, i.e. we define [f] 2K = n + ml + mu \u2211 i = 1n + ml + mu \u0445 j = 1\u03b1i\u03b1jK (xi, xj) = \u03b1 TK\u03b1 (14)."}, {"heading": "E. Marginal Probability Distribution Adaptation", "text": "Similar to [23], [28] we calculate Df, K (Ps, Pt) using the projected maximum mean discrepancy (MMD): Df, K (Ps, Pt) = [1nn \u2211 i = 1f (xi) \u2212 1ml + mun + ml + mu \u2211 i = n + 1f (xi)] 2 = \u03b1TKM0K\u03b1 (15), where M0-R (n + ml + mu) \u00b7 (n + ml + mu) is the MMD matrix: (M0) ij = 1 n2, 1 \u2264 i \u2264 n, 1 \u2264 j \u2264 n (ml + mu) 2, n + 1 \u2264 i + ml + mu, n + 1 \u2264 n + ml + mu \u2212 1n (ml + mu), otherwise (16)"}, {"heading": "F. Conditional Probability Distribution Adaptation", "text": "Similar to the idea proposed in [23], we must first calculate pseudo-labels for the unmarked target domain samples and construct the label vector y in (8). These pseudo-labels can be borrowed directly from the estimates of the previous iteration if the algorithm is used iteratively or is estimated with another classifier, e.g. an SVM. Then we calculate the projected MMD w.r.t. Each class calculates the distance between the conditional probability distributions in source and target domains as: Df, K (Qs, Qt) = 2 \u2211 c = 11nc; Substitution (5) in (17) \u2212 1mc, xxi \u2212 xj \u00b2 Dt, cf (xj) 2 (17), with Ds, c, Dt, c, nc, nc and mc defined under (4)."}, {"heading": "G. wAR-RLS: The Closed-Form Solution", "text": "By replacing (10), (14), (15) and (18) with (2), it follows that f = argmin f-HK (yT \u2212 \u03b1TK) E (y \u2212 K\u03b1) + \u03c3\u03b1TK\u03b1 + \u03b1TK (\u03bbPM0 + \u03bbQM) K\u03b1 (21) Setting the above derivative of the objective function to 0 leads to \u03b1 = [(E + \u03bbPM1 + \u03bbQM) K + \u03c3I] \u2212 1Ey (22)."}, {"heading": "H. wAR-SVM Solution", "text": "The substitution (13), (14), (15) and (18) in (2), then (1) in (5) can be called: \u03b1 = argmin (1) s.t. yin + ml + mu.Rn + mln + ml \u2211 i = 1Eii\u0432i + \u03c3\u03b1 TK\u03b1 + \u03b1TK (\u03bbPM0 + \u03bbQM) K\u03b1 (23) s.t. yin + ml + mu \u2211 j = 1\u03b1jK (xi, xj) + b \u2265 1 \u2212 \u043fi\u0412i \u2265 0, i = 1,..., n + mlDefine\u03b2 = [\u03b1; b] f = [01 \u00d7 (n + ml + mu) ws, 1 \u00b7 ws, n wtwt, 1 \u00b7 \u00b7 wtwt, ml 0] H = [\u03c3K + K (\u03bbPM0 + \u03bbQM) K 0 (n + seu.m) \u00b7 n (n + ml + programmed).In the first and second (n \u00b7 ml) the (n \u00b7 ml) is shown."}, {"heading": "III. ACTIVE WEIGHTED ADAPTATION REGULARIZATION", "text": "(AWAR) As mentioned in the introduction, wAR can be integrated with AL [33] to achieve better performance. AL tries to select the most informative samples so that a certain learning performance can be achieved with less labeling effort. TheAlgorithm 1: The algorithm of active weighted fit regularization (AwAR) algorithm (AwAR) ml (Input: n labeled source domain samples, {xi, yi} ni = 1; ml labeled target domain samples, {xj} n + ml j = n + 1; mu unlabeled target domain samples, {xj} n terms, {xi, yi} ni = 1; ml labeled target domain samples, {xj} n terms, number of unlabeled target domain samples tolable. Output: {y \u2032 j} n + ml labeled target domain samples, {xj} n terms, the unlabeled target domain samples, {xj} n terms, the unlabeled target domain samples, {+ ml, + xj} n terms, the labeled target domain samples {+, xml)."}, {"heading": "A. Active Learning", "text": "Our AL for identifying the most informative samples is a two-step process: the first step identifies the most volatile, unlabeled samples from the target domain, and the second step continues to select the most insecure samples from the previous iteration. Remember that at the beginning of WAR we tried the active learning approaches in [5], [16], but did not observe a better performance than the method proposed in this section. 6 {y \u2032 j} n + ml + ml + 1, the updated estimates of these samples. If y \u2032 j differs from yj for a particular sample, then there is evidence that this sample is volatile, probably because it is close to the decision limit. In accordance with the volatility of the unlabeled samples from the target domain, we have divided them into two groups: Jd = hj | yj = 6 ml = jm \u00b2 and jm + \u2264 1 ml | ml = jm \u00b2."}, {"heading": "B. The Complete AwAR Algorithm", "text": "The full AwAR algorithm is specified in Algorithm 1. We refer to the algorithm based on wAR-RLS as AwAR-RLS and the one based on wAR-SVM as AwAR-SVM. In each algorithm, we first use WAR to classify the unmarked target domain samples, and then AL to identify k samples that are most volatile and uncertain. AwAR-RLS and AwAR-SVM can easily be embedded in an iterative procedure (Section IV-C) so that k target domain samples are labeled in each iteration until the maximum number of iterations is reached or the desired classification performance is achieved."}, {"heading": "C. Make Use of the Extra Channels", "text": "In algorithm 1, we assume that the source and target domains have consistent characteristics, i.e. that the old and new AL samples have the same channels, so that the characteristics extracted from them have the same dimensionality and meaning. This works even if the old headset has more channels, but it covers all the channels of the new headset, in which case only the common channels are used for feature extraction. However, things get more complicated if the new headset has channels that are not included in the old headset. We can again use the common channels for feature extraction and then apply algorithm 1, but there is information loss if the additional channels in the new headset are completely ignored. Next, we propose a solution to this problem. The additional channels are difficult to use in wAR because the target domain does not contain them. However, it is possible to use them in AL, as shown in algorithm 2, which can be used to replace the algorithm 2 in the algorithm part 1."}, {"heading": "IV. EXPERIMENTS AND DISCUSSIONS", "text": "In this section, experimental results are presented to compare wAR-RLS, wAR-SVM, AwAR-RLS and AwAR-SVM with several other algorithms."}, {"heading": "A. Experiment Setup", "text": "We used data from a VEP head-ball task [30], in which subjects were presented with image stimuli at 0.5 Hz (one image every two seconds), representing either an enemy fighter [target; an example is shown in Figure 1 (a) or a US soldier [non-target; an example is shown in Figure 1 (b))), and were instructed to identify each image as quickly but as accurately as possible as a target or non-target with a single push of a button. A total of 270 images per subject were presented, 34 of which were targets, and the experiments were approved by the Institutional Review Board of the US Army Research Laboratory (ARL) (Protocol # 20098-10027). Voluntary, fully informed consent of the subjects used in this study was obtained, as required by federal and Army regulations."}, {"heading": "B. Preprocessing and Feature Extraction", "text": "We used EEGLAB [10] for the pre-processing of EEG signals and the extraction of features. To switch between BioSemi and Emotiv headsets, we used their 14 common channels (AF3, AF4, F3, F4, F7, F8, FC5, FC6, O1, O2, P7, P8, T7, T8). To switch between BioSemi and ABM headsets, we used their nine common channels (C3, C4, Cz, F3, F4, Fz, P3, P4, POz). For each headset, we first transferred the EEG signals to [1, 50] Hz, then we lowered them to 64 Hz, carried out average references and then insisted on the [0, 0.7] second interval."}, {"heading": "C. Evaluation Process and Performance Measures", "text": "Although we know the labels of all EEG epochs of all headsets for each subject, we simulate a different scenario, as shown in Fig. 2: All EEG epochs of the old headset are labeled, but none of the epochs of the new headset are labeled first. Our approach is to iterate some epochs of the new headset and then build a classifier to label the rest of the epochs. The goal is to achieve the highest classification accuracy for the epochs of the new headset, labeling as few epochs as possible. 2) False Negative Rate (FNR), that is, the number of false positives (the number of non-targets wrongly classified as targets) divided by the number of true negatives (non-targets). 2) False Negative Rate (FNR), that is the number of false negatives (the number of targets that can be falsely classified as non-targets)."}, {"heading": "D. Algorithms", "text": "We compared the performance of wAR-RLS, wAR-SVM, AwAR-RLS and AwAR-SVM with three other algorithms: 1) Baseline (BL), which is a simple iterative procedure: in each iteration, we randomly select a few unmarked training samples collected with the new headset, ask the subject to label them, add them to the labeled training set, and then form an SVM classifier by 5-fold cross-validation. We iterate until the maximum number of iterations is reached. 2) The simple TL (TL) algorithm introduced in [51] is very similar to BL except that in each iteration it combines labeled samples from the old and new headsets."}, {"heading": "E. Experimental Results", "text": "This year it has come to the point that it has never come as far as this year."}, {"heading": "F. Statistical Analysis", "text": "We also conducted comprehensive statistical tests to verify whether the BCA differences between the algorithms were statistically significant. Although the SVLS pair was significantly significant between all the algorithms, a measurement called Area-underperformance-curve (AUPC) [25] was calculated. AUPC is the area below the curve of the SVLS values plotted in each of the 30 random runs and is normalized to [0, 1]. Larger AUPC values indicate better overall classification performance. First, we used Friedman's test, a two-way non-parametric variance analysis (ANOVA), where column effects are tested for significant differences after adjusting for possible sequence effects. We treated the algorithm type (BL, TL, wARRLS, wAR-SVM, AwAR-SVM-RLS, AwAR-SVM-SVM-SVM) as column effects."}, {"heading": "G. Make Use of the Extra Channels (ECs)", "text": "In the above experiments, we used only the common channels between the old and new headsets. That's fine if all channels of the new headset are integrated into the old one; however, there is information loss if the new headset has channels that are not present in the old headset. For example, if the switch from Emotiv to BioSemi, the additional 64 \u2212 14 channels are completely ignored while containing valuable information. In this subsection, we replace the AL part in algorithm 1 by using the additional channels, and the corresponding algorithms are called AwAR-RLS and AwAR-SVM."}, {"heading": "H. Robustness Analysis", "text": "In this subsection, we examine the robustness of AwAR-RLS and AwAR-SVM for three different factors: the number of linear PC features, the character sets extracted by other methods, and the parameters \u03c3 and \u03bbP (\u03bbQ). To save space, we show the BCA results only when switching from BioSemi to ABM. Similar results have been obtained in other switching scenarios. AwAR-RLS and AwAR-SVM average BCAs for different numbers of linear PCs are shown in Fig. 6. Note that AwAR-RLS and AwAR-SVM are very robust for the number of PCs. 20 PCs were mainly used in this essay for the calculation cost.Two other feature sets were applied to examine the robustness of AwAR-RLS and AwAR-SVM for different ATS features."}, {"heading": "I. Discussions", "text": "Extensive experimental results have shown that AwAR-RLS and AwAR-SVM can actually reduce the calibration effort when migrating to a new EEG headset, and they are very robust. However, they still have some limitations that will be taken into account in our future research: 1) AwAR-RLS and AwAR-SVM assume that the old and new headsets have enough common channels. We need to quantify the minimum number of common channels for them to work well, and develop approaches. 7 We have always assigned them the same value because they are conceptually close to each other. 12 transfers for headsets with no or very few common channels, such as more complex extraction methods that allow compensation from nearby electrodes. 2) In the current study, each subject performed the same task in three sessions on three different days, with the subject wearing a different headset each day."}, {"heading": "V. CONCLUSIONS", "text": "In this paper, we have introduced two active, weighted adjustment regularization approaches that integrate domain adaptation transfer learning and active learning to speed up the calibration process when a subject switches to a new EEG headset. Domain adaptation uses marked data from the subject's previous headset, while active learning selects the most informative samples from the new headset to be labeled. Experiments to classify ERPs with three different EEG headsets have shown that active weighted adjustment regularization can significantly improve classification performance, as the same number of labeled samples originates from the new headset; or, likewise, it can effectively reduce the number of labeled samples from the new headset, as the desired classification accuracy is given. While the current examples are based on intra-subject transfer, different headsets are based, our final goal is to implement this piercing application."}, {"heading": "ACKNOWLEDGEMENT", "text": "The authors thank Scott Kerick, Jean Vettel and Anthony Ries from the US Army Research Laboratory (ARL) for designing the experiment and collecting the data."}], "references": [{"title": "Improving session-tosession transfer performance of motor imagery-based BCI using adaptive extreme learning machine", "author": ["A. Bamdadian", "C. Guan", "K.K. Ang", "J. Xu"], "venue": "Proc. 35th Annual Int\u2019l Conf. of the IEEE Engineering in Medicine and Biology Society (EMBC), Osaka, Japan, July 2013, pp. 2188\u20132191.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2013}, {"title": "Manifold regularization: A geometric framework for learning from labeled and unlabeled examples", "author": ["M. Belkin", "P. Niyogi", "V. Sindhwani"], "venue": "Journal of Machine Learning Research, vol. 7, pp. 2399\u20132434, 2006.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2006}, {"title": "Learning deep architectures for AI", "author": ["Y. Bengio"], "venue": "Foundations and Trends in Machine Learning, vol. 2, no. 1, pp. 1\u2013127, 2009.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2009}, {"title": "Controlling the false discovery rate: A practical and powerful approach to multiple testing", "author": ["Y. Benjamini", "Y. Hochberg"], "venue": "Journal of the Royal Statistical Society, Series B (Methodological), vol. 57, pp. 289\u2013 300, 1995.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1995}, {"title": "Adaptive batch mode active learning", "author": ["S. Chakraborty", "V. Balasubramanian", "S. Panchanathan"], "venue": "IEEE Trans. on Neural Networks and Learning Systems, vol. 26, no. 8, pp. 1747\u20131760, 2015.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2015}, {"title": "LIBSVM: A library for support vector machines", "author": ["C.-C. Chang", "C.-J. Lin"], "venue": "ACM Trans. on Intelligent Systems and Technology, vol. 2, no. 3, pp. 27:1\u201327:27, 2011, software available at http://www.csie.ntu.edu.tw/$\\sim$cjlin/libsvm.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "Joint transfer and batch-mode active learning", "author": ["R. Chattopadhyay", "W. Fan", "I. Davidson", "S. Panchanathan", "J. Ye"], "venue": "Proc. 30th Int\u2019l. Conf. on Machine Learning (ICML), Atlanta, GA, June 2013.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "Co-training for domain adaptation", "author": ["M. Chen", "K. Weinberger", "J. Blitzer"], "venue": "Proc. 25th Conf. on Neural Information Processing Systems (NIPS), Granada, Spain, December 2011.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2011}, {"title": "Batch mode active learning algorithm combining with self-training for multiclass brain-computer interfaces", "author": ["M. Chen", "X. Tan"], "venue": "Journal of Information & Computational Science, vol. 12, no. 6, pp. 2351\u20132359, 2015.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2015}, {"title": "EEGLAB: an open source toolbox for analysis of single-trial EEG dynamics including independent component analysis", "author": ["A. Delorme", "S. Makeig"], "venue": "Journal of Neuroscience Methods, vol. 134, pp. 9\u201321, 2004.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2004}, {"title": "Multisubject learning for common spatial patterns in motor-imagery BCI", "author": ["D. Devlaminck", "B. Wyns", "M. Grosse-Wentrup", "G. Otte", "P. Santens"], "venue": "Computational intelligence and neuroscience, vol. 20, no. 8, 2011.  13", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2011}, {"title": "Multiple comparisons among means", "author": ["O. Dunn"], "venue": "Journal of the American Statistical Association, vol. 56, pp. 62\u201364, 1961.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1961}, {"title": "Multiple comparisons using rank sums", "author": ["O. Dunn"], "venue": "Technometrics, vol. 6, pp. 214\u2013252, 1964.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1964}, {"title": "Usability of four commerciallyoriented EEG systems", "author": ["W.D. Hairston", "K.W. Whitaker", "A.J. Ries", "J.M. Vettel", "J.C. Bradford", "S.E. Kerick", "K. McDowell"], "venue": "Journal of Neural Engineering, vol. 11, no. 4, 2014.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2014}, {"title": "Brain-computer interface (BCI) literature \u2013 a bibliometric study", "author": ["B. Hamadicharef"], "venue": "Proc. 10th Int\u2019l. Conf. on Information Sciences Signal Processing and their Applications, Kuala Lumpur, May 2010, pp. 626\u2013 629.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2010}, {"title": "Active learning by querying informative and representative examples", "author": ["S.-J. Huang", "R. Jin", "Z.-H. Zhou"], "venue": "IEEE Trans. on Pattern Analysis and Machine Intelligence, vol. 36, no. 10, pp. 1936\u20131949, 2014.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1936}, {"title": "Composite common spatial pattern for subject-to-subject transfer", "author": ["H. Kang", "Y. Nam", "S. Choi"], "venue": "Signal Processing Letters, vol. 16, no. 8, pp. 683\u2013686, 2009.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2009}, {"title": "Brain-computer interface technologies in the coming decades", "author": ["B.J. Lance", "S.E. Kerick", "A.J. Ries", "K.S. Oie", "K. McDowell"], "venue": "Proc. of the IEEE, vol. 100, no. 3, pp. 1585\u20131599, 2012.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2012}, {"title": "Efficient labeling of EEG signal artifacts using active learning", "author": ["V.J. Lawhern", "D.J. Slayback", "D. Wu", "B.J. Lance"], "venue": "Proc. IEEE Int\u2019l. Conf. on Systems, Man and Cybernetics, Hong Kong, October 2015.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2015}, {"title": "Group nonnegative matrix factorization for EEG classification", "author": ["H. Lee", "S. Choi"], "venue": "Proc. Int\u2019l. Conf. on Artificial Intelligence and Statistics, Clearwater Beach, FL, April 2009, pp. 320\u2013327.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2009}, {"title": "Application of covariate shift adaptation techniques in brain-computer interfaces", "author": ["Y. Li", "H. Kambara", "Y. Koike", "M. Sugiyama"], "venue": "IEEE Trans. on Biomedical Engineering, vol. 57, no. 6, pp. 1318\u20131324, 2010.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2010}, {"title": "A framework of adaptive brain computer interfaces", "author": ["Y. Li", "Y. Koike", "M. Sugiyama"], "venue": "Proc. 2nd IEEE Int\u2019l. Conf. on Biomedical Engineering and Informatics (BMEl), Tianjin, China, October 2009.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2009}, {"title": "Adaptation regularization: A general framework for transfer learning", "author": ["M. Long", "J. Wang", "G. Ding", "S.J. Pan", "P.S. Yu"], "venue": "IEEE Trans. on Knowledge and Data Engineering, vol. 26, no. 5, pp. 1076\u20131089, 2014.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning from other subjects helps reducing brain-computer interface calibration time", "author": ["F. Lotte", "C. Guan"], "venue": "Proc. IEEE Int\u2019l. Conf. on Acoustics Speech and Signal Processing (ICASSP), Dallas, TX, March 2010.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2010}, {"title": "Improved neural signal classification in a rapid serial visual presentation task using active learning", "author": ["A. Marathe", "V. Lawhern", "D. Wu", "D. Slayback", "B. Lance"], "venue": "IEEE Trans. on Neural Systems and Rehabilitation Engineering, vol. 24, no. 3, pp. 333\u2013343, 2016.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2016}, {"title": "Real-world neuroimaging technologies", "author": ["K. McDowell", "C.-T. Lin", "K. Oie", "T.-P. Jung", "S. Gordon", "K. Whitaker", "S.-Y. Li", "S.-W. Lu", "W. Hairston"], "venue": "IEEE Access, vol. 1, pp. 131\u2013149, 2013.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2013}, {"title": "A survey on transfer learning", "author": ["S.J. Pan", "Q. Yang"], "venue": "IEEE Trans. on Knowledge and Data Engineering, vol. 22, no. 10, pp. 1345\u20131359, 2010.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2010}, {"title": "Large margin transductive transfer learning", "author": ["B. Quanz", "J. Huan"], "venue": "Proc. 18th ACM Conf. on Information and Knowledge Management (CIKM), Hong Kong, November 2009.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2009}, {"title": "Domain adaptation meets active learning", "author": ["P. Rai", "A. Saha", "III H. Daum\u00e9", "S. Venkatasubramanian"], "venue": "Proc. NAACL HLT 2010 Workshop on Active Learning for Natural Language Processing, Los Angeles, CA, June 2010, pp. 27\u201332.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2010}, {"title": "A comparison of electroencephalography signals acquired from conventional and mobile systems", "author": ["A.J. Ries", "J. Touryan", "J. Vettel", "K. McDowell", "W.D. Hairston"], "venue": "Journal of Neuroscience and Neuroengineering, vol. 3, no. 1, pp. 10\u201320, 2014.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2014}, {"title": "Transferring subspaces between subjects in brain-computer interfacing", "author": ["W. Samek", "F. Meinecke", "K.-R. Muller"], "venue": "IEEE Trans. on Biomedical Engineering, vol. 60, no. 8, pp. 2289\u20132298, 2013.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2013}, {"title": "A covariate shift minimisation method to alleviate non-stationarity effects for an adaptive braincomputer interface", "author": ["A. Satti", "C. Guan", "D. Coyle", "G. Prasad"], "venue": "Proc. 20th IEEE Int\u2019l. Conf. on Pattern Recognition (ICPR), Istanbul, Turkey, August 2010, pp. 105\u2013108.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2010}, {"title": "Active learning literature survey", "author": ["B. Settles"], "venue": "University of Wisconsin\u2013 Madison, Computer Sciences Technical Report 1648, 2009.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2009}, {"title": "Actively transfer domain knowledge", "author": ["X. Shi", "W. Fan", "J. Ren"], "venue": "Proc. European Conf. on Machine Learning (ECML), Antwerp, Belgium, September 2008, pp. 342\u2013357.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2008}, {"title": "Principal component based covariate shift adaption to reduce non-stationarity in a MEG-based  brain-computer interface", "author": ["M. Spuler", "W. Rosenstiel", "M. Bogdan"], "venue": "EURASIP Journal on Advances in Signal Processing, vol. 2012, no. 1, pp. 1\u20137, 2012.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2012}, {"title": "Regularization, Optimization, Kernels, and Support Vector Machines", "author": ["J.A. Suykens", "M. Signoretto", "A. Argyriou", "Eds"], "venue": null, "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2014}, {"title": "A regularized discriminative framework for EEG analysis with application to brain-computer interface", "author": ["R. Tomioka", "K.-R. Muller"], "venue": "NeuroImage, vol. 49, pp. 415\u2013432, 2010.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2010}, {"title": "Dynamical ensemble learning with model-friendly classifiers for domain adaptation", "author": ["W. Tu", "S. Sun"], "venue": "Proc. 21st Int\u2019l. Conf. on Pattern Recognition (ICPR), Tsukuba, Japan, November 2012.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2012}, {"title": "A subject transfer framework for EEG classification", "author": ["W. Tu", "S. Sun"], "venue": "Neurocomputing, vol. 82, pp. 109\u2013116, 2012.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2012}, {"title": "Code of federal regulations protection of human subjects", "author": ["US Department of Defense Office of the Secretary of Defense"], "venue": "Government Printing Office, no. 32 CFR 19, 1999.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 1999}, {"title": "Use of volunteers as subjects of research", "author": ["US Department of the Army"], "venue": "Government Printing Office, no. AR 70-25, 1990.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 1990}, {"title": "An iterative framework for EEG-based image search: Robust retrieval with weak classifiers", "author": ["M. Uscumlic", "R. Chavarriaga", "J. del R. Millan"], "venue": "PLoS One, vol. 8, no. 8, 2013.", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2013}, {"title": "Brain-computer interfaces: Beyond medical applications", "author": ["J. van Erp", "F. Lotte", "M. Tangermann"], "venue": "Computer, vol. 45, no. 4, pp. 26\u201334, 2012.", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2012}, {"title": "Statistical Learning Theory", "author": ["V. Vapnik"], "venue": null, "citeRegEx": "45", "shortCiteRegEx": "45", "year": 1998}, {"title": "Toward unsupervised adaptation of LDA for brain-computer interfaces", "author": ["C. Vidaurre", "M. Kawanabe", "P.V. Bunau", "B. Blankertz", "K. Muller"], "venue": "IEEE Trans. on Biomedical Engineering, vol. 58, no. 3, pp. 587\u2013597, 2011.", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2011}, {"title": "A review on transfer learning for brain-computer interface classification", "author": ["P. Wang", "J. Lu", "B. Zhang", "Z. Tang"], "venue": "Prof. 5th Int\u2019l. Conf. on Information Science and Technology (IC1ST), Changsha, China, April 2015.", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2015}, {"title": "The use of fast Fourier transform for the estimation of power spectra: A method based on time averaging over short, modified periodograms", "author": ["P. Welch"], "venue": "IEEE Trans. on Audio Electroacoustics, vol. 15, pp. 70\u2013 73, 1967.", "citeRegEx": "48", "shortCiteRegEx": null, "year": 1967}, {"title": "Online driver\u2019s drowsiness estimation using domain adaptation with model fusion", "author": ["D. Wu", "C.-H. Chuang", "C.-T. Lin"], "venue": "Proc. Int\u2019l. Conf. on Affective Computing and Intelligent Interaction, Xi\u2019an, China, September 2015.", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2015}, {"title": "Active transfer learning for reducing calibration data in single-trial classification of visually-evoked potentials", "author": ["D. Wu", "B.J. Lance", "V.J. Lawhern"], "venue": "Proc. IEEE Int\u2019l. Conf. on Systems, Man, and Cybernetics, San Diego, CA, October 2014.", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2014}, {"title": "Collaborative filtering for braincomputer interaction using transfer learning and active class selection", "author": ["D. Wu", "B.J. Lance", "T.D. Parsons"], "venue": "PLoS ONE, 2013.", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2013}, {"title": "Reducing BCI calibration effort in RSVP tasks using online weighted adaptation regularization with source domain selection", "author": ["D. Wu", "V.J. Lawhern", "B.J. Lance"], "venue": "Proc. Int\u2019l. Conf. on Affective Computing and Intelligent Interaction, Xi\u2019an, China, September 2015.", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2015}, {"title": "Reducing offline BCI calibration effort using weighted adaptation regularization with source domain selection", "author": ["D. Wu", "V.J. Lawhern", "B.J. Lance"], "venue": "Proc. IEEE Int\u2019l. Conf. on Systems, Man and Cybernetics, Hong Kong, October 2015.", "citeRegEx": "54", "shortCiteRegEx": null, "year": 2015}, {"title": "Inductive transfer learning for handling individual differences in affective computing", "author": ["D. Wu", "T.D. Parsons"], "venue": "Proc. 4th Int\u2019l Conf. on Affective Computing and Intelligent Interaction, vol. 2, Memphis, TN, October 2011, pp. 142\u2013151.", "citeRegEx": "55", "shortCiteRegEx": null, "year": 2011}, {"title": "Improving SVM accuracy by training on auxiliary data sources", "author": ["P. Wu", "T.G. Dietterich"], "venue": "Proc. Int\u2019l Conf. on Machine Learning, Banff, Alberta, Canada, July 2004, pp. 871\u2013878.", "citeRegEx": "56", "shortCiteRegEx": null, "year": 2004}, {"title": "L1regularized multiway canonical correlation analysis for SSVEP-based BCI", "author": ["Y. Zhang", "G. Zhou", "J. Jin", "M. Wang", "X. Wang", "A. Cichocki"], "venue": "IEEE Trans. on Neural Systems and Rehabilitation Engineering, vol. 21, no. 6, pp. 887\u2013896, 2013.", "citeRegEx": "57", "shortCiteRegEx": null, "year": 2013}], "referenceMentions": [{"referenceID": 14, "context": "INTRODUCTION ELECTROENCEPHALOGRAPHY (EEG) headsets are the most commonly used sensing devices for BrainComputer Interface (BCI), which have been employed in many applications, such as healthcare and gaming [15], [18], [26],", "startOffset": 206, "endOffset": 210}, {"referenceID": 17, "context": "INTRODUCTION ELECTROENCEPHALOGRAPHY (EEG) headsets are the most commonly used sensing devices for BrainComputer Interface (BCI), which have been employed in many applications, such as healthcare and gaming [15], [18], [26],", "startOffset": 212, "endOffset": 216}, {"referenceID": 25, "context": "INTRODUCTION ELECTROENCEPHALOGRAPHY (EEG) headsets are the most commonly used sensing devices for BrainComputer Interface (BCI), which have been employed in many applications, such as healthcare and gaming [15], [18], [26],", "startOffset": 218, "endOffset": 222}, {"referenceID": 42, "context": "[44], [49], because of the general ease of setup for normal individuals.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "There are many existing EEG headsets, with new models and styles continually becoming available [14].", "startOffset": 96, "endOffset": 100}, {"referenceID": 29, "context": "However, evidence comparing the performance of various classifiers when using different headsets has shown that often performance is not equal across systems; that is, the headset does in fact matter [30].", "startOffset": 200, "endOffset": 204}, {"referenceID": 42, "context": "Thus, it is not surprising that currently switching to a new or different headset requires the subject to re-calibrate it, which can take anywhere from 5-20 minutes [44].", "startOffset": 165, "endOffset": 169}, {"referenceID": 26, "context": "In this paper, we specifically attempt to address the problem of developing classifiers that can account for variation due to different EEG headsets within a transfer learning (TL) [27] framework.", "startOffset": 181, "endOffset": 185}, {"referenceID": 45, "context": "According to a recent literature review [47], there are mainly three types of TL approaches for BCI applications: 1) Feature representation transfer [11], [17], [20], [24], [31], [32], [35], which encodes the knowledge across different subjects or sessions as features.", "startOffset": 40, "endOffset": 44}, {"referenceID": 10, "context": "According to a recent literature review [47], there are mainly three types of TL approaches for BCI applications: 1) Feature representation transfer [11], [17], [20], [24], [31], [32], [35], which encodes the knowledge across different subjects or sessions as features.", "startOffset": 149, "endOffset": 153}, {"referenceID": 16, "context": "According to a recent literature review [47], there are mainly three types of TL approaches for BCI applications: 1) Feature representation transfer [11], [17], [20], [24], [31], [32], [35], which encodes the knowledge across different subjects or sessions as features.", "startOffset": 155, "endOffset": 159}, {"referenceID": 19, "context": "According to a recent literature review [47], there are mainly three types of TL approaches for BCI applications: 1) Feature representation transfer [11], [17], [20], [24], [31], [32], [35], which encodes the knowledge across different subjects or sessions as features.", "startOffset": 161, "endOffset": 165}, {"referenceID": 23, "context": "According to a recent literature review [47], there are mainly three types of TL approaches for BCI applications: 1) Feature representation transfer [11], [17], [20], [24], [31], [32], [35], which encodes the knowledge across different subjects or sessions as features.", "startOffset": 167, "endOffset": 171}, {"referenceID": 30, "context": "According to a recent literature review [47], there are mainly three types of TL approaches for BCI applications: 1) Feature representation transfer [11], [17], [20], [24], [31], [32], [35], which encodes the knowledge across different subjects or sessions as features.", "startOffset": 173, "endOffset": 177}, {"referenceID": 31, "context": "According to a recent literature review [47], there are mainly three types of TL approaches for BCI applications: 1) Feature representation transfer [11], [17], [20], [24], [31], [32], [35], which encodes the knowledge across different subjects or sessions as features.", "startOffset": 179, "endOffset": 183}, {"referenceID": 34, "context": "According to a recent literature review [47], there are mainly three types of TL approaches for BCI applications: 1) Feature representation transfer [11], [17], [20], [24], [31], [32], [35], which encodes the knowledge across different subjects or sessions as features.", "startOffset": 185, "endOffset": 189}, {"referenceID": 20, "context": "2) Instance transfer [21], [22], [52], [55], which uses certain parts of the data from other subjects or sessions to help the learning for the current subject or session.", "startOffset": 21, "endOffset": 25}, {"referenceID": 21, "context": "2) Instance transfer [21], [22], [52], [55], which uses certain parts of the data from other subjects or sessions to help the learning for the current subject or session.", "startOffset": 27, "endOffset": 31}, {"referenceID": 49, "context": "2) Instance transfer [21], [22], [52], [55], which uses certain parts of the data from other subjects or sessions to help the learning for the current subject or session.", "startOffset": 33, "endOffset": 37}, {"referenceID": 52, "context": "2) Instance transfer [21], [22], [52], [55], which uses certain parts of the data from other subjects or sessions to help the learning for the current subject or session.", "startOffset": 39, "endOffset": 43}, {"referenceID": 0, "context": "3) Classifier transfer, which includes domain adaptation [1], [35], [46], i.", "startOffset": 57, "endOffset": 60}, {"referenceID": 34, "context": "3) Classifier transfer, which includes domain adaptation [1], [35], [46], i.", "startOffset": 62, "endOffset": 66}, {"referenceID": 44, "context": "3) Classifier transfer, which includes domain adaptation [1], [35], [46], i.", "startOffset": 68, "endOffset": 72}, {"referenceID": 37, "context": ", handling the different data distributions for different subjects or sessions, and ensemble learning [39], [40], i.", "startOffset": 102, "endOffset": 106}, {"referenceID": 38, "context": ", handling the different data distributions for different subjects or sessions, and ensemble learning [39], [40], i.", "startOffset": 108, "endOffset": 112}, {"referenceID": 47, "context": ", combining multiple classifiers from multiple subjects or sessions, and their combinations [50], [53], [54].", "startOffset": 92, "endOffset": 96}, {"referenceID": 50, "context": ", combining multiple classifiers from multiple subjects or sessions, and their combinations [50], [53], [54].", "startOffset": 98, "endOffset": 102}, {"referenceID": 51, "context": ", combining multiple classifiers from multiple subjects or sessions, and their combinations [50], [53], [54].", "startOffset": 104, "endOffset": 108}, {"referenceID": 35, "context": "In our case, data acquired from one style of headset is used to facilitate classification of data currently being acquired from a different one, through domain adaptation and regularized optimization [36], [38], [57].", "startOffset": 200, "endOffset": 204}, {"referenceID": 36, "context": "In our case, data acquired from one style of headset is used to facilitate classification of data currently being acquired from a different one, through domain adaptation and regularized optimization [36], [38], [57].", "startOffset": 206, "endOffset": 210}, {"referenceID": 54, "context": "In our case, data acquired from one style of headset is used to facilitate classification of data currently being acquired from a different one, through domain adaptation and regularized optimization [36], [38], [57].", "startOffset": 212, "endOffset": 216}, {"referenceID": 41, "context": ", BCI applications focused on labeling images, using EEG data [37], [43].", "startOffset": 68, "endOffset": 72}, {"referenceID": 32, "context": "This is the idea of active learning (AL) [33], which has also started to find application in BCI [9], [19], [25].", "startOffset": 41, "endOffset": 45}, {"referenceID": 8, "context": "This is the idea of active learning (AL) [33], which has also started to find application in BCI [9], [19], [25].", "startOffset": 97, "endOffset": 100}, {"referenceID": 18, "context": "This is the idea of active learning (AL) [33], which has also started to find application in BCI [9], [19], [25].", "startOffset": 102, "endOffset": 106}, {"referenceID": 24, "context": "This is the idea of active learning (AL) [33], which has also started to find application in BCI [9], [19], [25].", "startOffset": 108, "endOffset": 112}, {"referenceID": 18, "context": "For example, in our recent work on EEG artifacts classification [19], we showed that classification accuracy equivalent to classifiers trained on full data annotation can be obtained while labeling less than 25% of the data by AL.", "startOffset": 64, "endOffset": 68}, {"referenceID": 24, "context": "In another study [25], we applied AL to a simulated BCI system for target identification using data from a rapid serial visual presentation paradigm, and showed that it can produce similar overall classification accuracy with significantly less labeled data (in some cases less than 20%) when compared to alternative calibration approaches.", "startOffset": 17, "endOffset": 21}, {"referenceID": 33, "context": "The idea of integrating TL and AL was proposed recently [34] and is beginning to be explored [7], [8], [29], [51], [58].", "startOffset": 56, "endOffset": 60}, {"referenceID": 6, "context": "The idea of integrating TL and AL was proposed recently [34] and is beginning to be explored [7], [8], [29], [51], [58].", "startOffset": 93, "endOffset": 96}, {"referenceID": 7, "context": "The idea of integrating TL and AL was proposed recently [34] and is beginning to be explored [7], [8], [29], [51], [58].", "startOffset": 98, "endOffset": 101}, {"referenceID": 28, "context": "The idea of integrating TL and AL was proposed recently [34] and is beginning to be explored [7], [8], [29], [51], [58].", "startOffset": 103, "endOffset": 107}, {"referenceID": 48, "context": "The idea of integrating TL and AL was proposed recently [34] and is beginning to be explored [7], [8], [29], [51], [58].", "startOffset": 109, "endOffset": 113}, {"referenceID": 48, "context": "In our previous work [51], we investigated how TL and AL can be integrated to reduce the amount of subject-specific calibration data in a Visual-Evoked Potential (VEP) task, by making use of data collected using the same headset but from other subjects; in contrast, this paper considers the problem of reducing subjectspecific calibration data when the same subject switches from one headset to another.", "startOffset": 21, "endOffset": 25}, {"referenceID": 48, "context": "Using a single-trial ERP experiment, we demonstrate that wAR can achieve improved performance over the TL approach used in [51], and active weighted adaptation regularization (AwAR), which integrates wAR and AL, can further reduce the offline calibration effort when switching between different EEG headsets.", "startOffset": 123, "endOffset": 127}, {"referenceID": 26, "context": "TL [27], [56], particularly wAR, is a framework for addressing the aforementioned problem.", "startOffset": 3, "endOffset": 7}, {"referenceID": 53, "context": "TL [27], [56], particularly wAR, is a framework for addressing the aforementioned problem.", "startOffset": 9, "endOffset": 13}, {"referenceID": 22, "context": "Definition 1: (Domain) [23], [27] A domain D is composed of a d-dimensional feature space X and a marginal probability distribution P (x), i.", "startOffset": 23, "endOffset": 27}, {"referenceID": 26, "context": "Definition 1: (Domain) [23], [27] A domain D is composed of a d-dimensional feature space X and a marginal probability distribution P (x), i.", "startOffset": 29, "endOffset": 33}, {"referenceID": 22, "context": ", Ps(x) 6= Pt(x) [23].", "startOffset": 17, "endOffset": 21}, {"referenceID": 22, "context": "Definition 2: (Task) [23], [27] Given a domain D, a task T is composed of a label space Y and a prediction function f(x), i.", "startOffset": 21, "endOffset": 25}, {"referenceID": 26, "context": "Definition 2: (Task) [23], [27] Given a domain D, a task T is composed of a label space Y and a prediction function f(x), i.", "startOffset": 27, "endOffset": 31}, {"referenceID": 22, "context": ", Qs(y|x) 6= Qt(y|x) [23].", "startOffset": 21, "endOffset": 25}, {"referenceID": 1, "context": "By the Representer Theorem [2], [23], the solution of (2) admits an expression:", "startOffset": 27, "endOffset": 30}, {"referenceID": 22, "context": "By the Representer Theorem [2], [23], the solution of (2) admits an expression:", "startOffset": 32, "endOffset": 36}, {"referenceID": 22, "context": "Note that our algorithm formulation and derivation closely resemble those in [23]; however, there are several major differences: 1) We consider the scenario that there are a few labeled samples in the target domain, whereas [23] assumes there are no labeled samples in the target domain.", "startOffset": 77, "endOffset": 81}, {"referenceID": 22, "context": "Note that our algorithm formulation and derivation closely resemble those in [23]; however, there are several major differences: 1) We consider the scenario that there are a few labeled samples in the target domain, whereas [23] assumes there are no labeled samples in the target domain.", "startOffset": 224, "endOffset": 228}, {"referenceID": 22, "context": "3) wAR is iterative and we further design an AL algorithm for it, whereas in [23] domain adaptation is performed only once and there is no AL.", "startOffset": 77, "endOffset": 81}, {"referenceID": 22, "context": "4) [23] also considers manifold regularization [2].", "startOffset": 3, "endOffset": 7}, {"referenceID": 1, "context": "4) [23] also considers manifold regularization [2].", "startOffset": 47, "endOffset": 50}, {"referenceID": 51, "context": "Also note that one of the wAR algorithms (wAR-RLS) described in this paper was introduced in our previous publication [54]; however, this paper includes a new wAR algorithm (wAR-SVM), and shows how AL can be integrated with wAR-RLS and wAR-SVM.", "startOffset": 118, "endOffset": 122}, {"referenceID": 22, "context": "Structural Risk Minimization As in [23], [45], we define the structural risk as the squared norm of f in HK , i.", "startOffset": 35, "endOffset": 39}, {"referenceID": 43, "context": "Structural Risk Minimization As in [23], [45], we define the structural risk as the squared norm of f in HK , i.", "startOffset": 41, "endOffset": 45}, {"referenceID": 22, "context": "Marginal Probability Distribution Adaptation Similar to [23], [28], we compute Df,K(Ps, Pt) using the projected maximum mean discrepancy (MMD):", "startOffset": 56, "endOffset": 60}, {"referenceID": 27, "context": "Marginal Probability Distribution Adaptation Similar to [23], [28], we compute Df,K(Ps, Pt) using the projected maximum mean discrepancy (MMD):", "startOffset": 62, "endOffset": 66}, {"referenceID": 22, "context": "Conditional Probability Distribution Adaptation Similar to the idea proposed in [23], we first need to compute pseudo labels for the unlabeled target domain samples and construct the label vector y in (8).", "startOffset": 80, "endOffset": 84}, {"referenceID": 32, "context": "ACTIVE WEIGHTED ADAPTATION REGULARIZATION (AWAR) As mentioned in the Introduction, wAR can be integrated with AL [33] for better performance.", "startOffset": 113, "endOffset": 117}, {"referenceID": 32, "context": "There are many different heuristics for this purpose [33].", "startOffset": 53, "endOffset": 57}, {"referenceID": 4, "context": "2We attempted the active learning approaches in [5], [16] but failed to observe better performance than the method proposed in this section.", "startOffset": 48, "endOffset": 51}, {"referenceID": 15, "context": "2We attempted the active learning approaches in [5], [16] but failed to observe better performance than the method proposed in this section.", "startOffset": 53, "endOffset": 57}, {"referenceID": 29, "context": "Experiment Setup We used data from a VEP oddball task [30].", "startOffset": 54, "endOffset": 58}, {"referenceID": 39, "context": "The voluntary, fully informed consent of the persons used in this research was obtained as required by federal and Army regulations [41], [42].", "startOffset": 132, "endOffset": 136}, {"referenceID": 40, "context": "The voluntary, fully informed consent of the persons used in this research was obtained as required by federal and Army regulations [41], [42].", "startOffset": 138, "endOffset": 142}, {"referenceID": 9, "context": "Preprocessing and Feature Extraction We used EEGLAB [10] for EEG signal preprocessing and feature extraction.", "startOffset": 52, "endOffset": 56}, {"referenceID": 0, "context": "For each headset, we first band-passed the EEG signals to [1, 50] Hz, then downsampled them to 64 Hz, performed average reference, and next epoched them to the [0, 0.", "startOffset": 58, "endOffset": 65}, {"referenceID": 47, "context": "For each headset, we first band-passed the EEG signals to [1, 50] Hz, then downsampled them to 64 Hz, performed average reference, and next epoched them to the [0, 0.", "startOffset": 58, "endOffset": 65}, {"referenceID": 0, "context": "We then normalized each feature dimension separately to [0, 1] for each subject.", "startOffset": 56, "endOffset": 62}, {"referenceID": 48, "context": "2) The simple TL (TL) algorithm introduced in [51], which is very similar to BL, except that in each iteration it combines labeled samples from the old and new headsets in building an SVM classifier and then applies it to the unlabeled samples from the new headset.", "startOffset": 46, "endOffset": 50}, {"referenceID": 48, "context": "3) The active TL (ATL) algorithm introduced in [51], which adds AL to the above TL: instead of randomly selecting unlabeled samples from the new headset to label, it selects those closest to the SVM decision boundary.", "startOffset": 47, "endOffset": 51}, {"referenceID": 5, "context": "Weighted LIBSVM [6] with a linear kernel was used as the classifier in BL, TL, ATL, wAR-SVM, and AwAR-SVM.", "startOffset": 16, "endOffset": 19}, {"referenceID": 22, "context": "1 and \u03bbP = \u03bbQ = 10, following the practice in [23].", "startOffset": 46, "endOffset": 50}, {"referenceID": 22, "context": "This is also consistent with the observations in [23].", "startOffset": 49, "endOffset": 53}, {"referenceID": 24, "context": "To assess overall performance differences among all the algorithms, a measure called the area-underperformance-curve (AUPC) [25] was calculated.", "startOffset": 124, "endOffset": 128}, {"referenceID": 0, "context": "The AUPC is the area under the curve of the BCA values plotted at each of the 30 random runs and is normalized to [0, 1].", "startOffset": 114, "endOffset": 120}, {"referenceID": 11, "context": "Then, non-parametric multiple comparison tests using Dunn\u2019s procedure [12], [13] were used to determine if the difference between any pair of algorithms was statistically significant, with a p-value correction using the False Discovery Rate method by [4].", "startOffset": 70, "endOffset": 74}, {"referenceID": 12, "context": "Then, non-parametric multiple comparison tests using Dunn\u2019s procedure [12], [13] were used to determine if the difference between any pair of algorithms was statistically significant, with a p-value correction using the False Discovery Rate method by [4].", "startOffset": 76, "endOffset": 80}, {"referenceID": 3, "context": "Then, non-parametric multiple comparison tests using Dunn\u2019s procedure [12], [13] were used to determine if the difference between any pair of algorithms was statistically significant, with a p-value correction using the False Discovery Rate method by [4].", "startOffset": 251, "endOffset": 254}, {"referenceID": 2, "context": "Two other feature sets were employed to study the robustness of AwAR-RLS and AwAR-SVM to different feature extraction methods: 1) 20 nonlinear PCA features extracted from an auto-encoder [3]; and, 2) 18 power spectral density features [theta band (4-7.", "startOffset": 187, "endOffset": 190}, {"referenceID": 46, "context": "5-12Hz)] from the 9 common channels using Welch\u2019s method [48].", "startOffset": 57, "endOffset": 61}], "year": 2017, "abstractText": "Electroencephalography (EEG) headsets are the most commonly used sensing devices for Brain-Computer Interface. In real-world applications, there are advantages to extrapolating data from one user session to another. However, these advantages are limited if the data arise from different hardware systems, which often vary between application spaces. Currently, this creates a need to recalibrate classifiers, which negatively affects people\u2019s interest in using such systems. In this paper, we employ active weighted adaptation regularization (AwAR), which integrates weighted adaptation regularization (wAR) and active learning, to expedite the calibration process. wAR makes use of labeled data from the previous headset and handles class-imbalance, and active learning selects the most informative samples from the new headset to label. Experiments on single-trial event-related potential classification show that AwAR can significantly increase the classification accuracy, given the same number of labeled samples from the new headset. In other words, AwAR can effectively reduce the number of labeled samples required from the new headset, given a desired classification accuracy, suggesting value in collating data for use in wide scale transfer-learning applications.", "creator": "LaTeX with hyperref package"}}}