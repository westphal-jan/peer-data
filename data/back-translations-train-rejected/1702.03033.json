{"id": "1702.03033", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Feb-2017", "title": "Local System Voting Feature for Machine Translation System Combination", "abstract": "In this paper, we enhance the traditional confusion network system combination approach with an additional model trained by a neural network. This work is motivated by the fact that the commonly used binary system voting models only assign each input system a global weight which is responsible for the global impact of each input system on all translations. This prevents individual systems with low system weights from having influence on the system combination output, although in some situations this could be helpful. Further, words which have only been seen by one or few systems rarely have a chance of being present in the combined output. We train a local system voting model by a neural network which is based on the words themselves and the combinatorial occurrences of the different system outputs. This gives system combination the option to prefer other systems at different word positions even for the same sentence.", "histories": [["v1", "Fri, 10 Feb 2017 01:27:00 GMT  (60kb,D)", "http://arxiv.org/abs/1702.03033v1", "published WMT 2015"]], "COMMENTS": "published WMT 2015", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["markus freitag", "jan-thorsten peter", "stephan peitz", "minwei feng", "hermann ney"], "accepted": false, "id": "1702.03033"}, "pdf": {"name": "1702.03033.pdf", "metadata": {"source": "CRF", "title": "Local System Voting Feature for Machine Translation System Combination", "authors": ["Markus Freitag", "Jan-Thorsten Peter", "Stephan Peitz", "Minwei Feng"], "emails": ["<surname>@cs.rwth-aachen.de"], "sections": [{"heading": "1 Introduction", "text": "The reason for this is that all of these models were already applied during the decryption process of the individual systems (which serve as input hypotheses for system combinations) and were therefore fired before the system combination. In order to improve the system component, we need to define a model that cannot be applied by a single system. In this case, the following models are commonly used: system coordination (globalVote) models for each word that is intended for the system."}, {"heading": "2 Related Work", "text": "In the Confusion Network Deciphering, pairs of alignments between all system outputs are generated. From the computed alignment information, a confusion network is constructed from which the system combination output is determined by majority selection and additional models. The hypothesis algorithm is a crucial part of the construction of the confusion network and many alternatives have been proposed in the literature: (Bangalore et al., 2001) Using a multiple string algorithm (MSA) to identify the unity of the consensus and apply a posterior language model to extract the consensus translations. In contrast to the following approaches, MSA is not able to capture word reordering. (Matusov et al., 2006) produce pairs of word alignments using the statistical algorithm tool kit GIZA +, which explicitly models word reordering models."}, {"heading": "3 Novel Local System Voting Model", "text": "In the following sections, we present a novel local voting model (localVote) that is trained by a neural network. The purpose of this model is to prefer a specific path in the confusion network and thus all local word decisions between two nodes leading to this particular path. Specifically, we want the neural network to learn an oracle path that is extracted from the confusion network diagram and leads to the lowest error value. In Section 3.1, we describe a polynomic approximation algorithm to extract the best sentence level BLEU (SBLEU) path in a confusion network. Starting from this path, we define the model in Section 3.2 followed by its integration into the linear model combination in Section 3.3."}, {"heading": "3.1 Finding SBLEU-optimal Hypotheses", "text": "In this section we describe a polynomial approximation algorithm to extract the best SBLEU hypotheses from a network of confusion. (Leusch et al., 2008) showed that this problem is generally NP-hard for the popular BLEU (Papineni et al., 2002) metric. However, we need some paths that serve as \"reference paths.\" Using BLEU as a metric to extract the best possible path is problematic as in the original BLEU definition, there is no smoothing for the geometric mean. This has the disadvantage that the BLEU score already becomes zero when the four-gram precision is zero, which obviously can very often happen with short or difficult translations. To allow a summary evaluation, we use the SBLEU metric (Lin and Och, 2004), which basically becomes BLEU score zero when the four-gram precision is zero, which is something to note."}, {"heading": "3.2 localVote Model Training", "text": "The purpose of the new localVote model is to prefer the best SBLEU path and therefore to learn the word choices between all adjacent nodes that lead to this particular path. While extracting the best SBLEU hypotheses from the confusion network, we track all arc decisions. This gives us the ability to generate local training examples based only on the I-arcs between two nodes. For the confusion network illustrated in Figure 2, we generate two training examples for neural network training. Based on the Arcs cab, train, car and car we learn the output car.In all upcoming system setups, we use the open source toolkit NPLM et al., 2013) for training and testing neural network models. We use the standard setup training as described in the paper and use the neural network with a projection layer and a hidden layer."}, {"heading": "3.3 localVote model Integration", "text": "Using a trained localVote model, we then insert it into the confusion network as an additional model. We calculate the probability of the word in the trained neural network for each arc. For example, for Figure 1, we extract the probabilities for all arcs through the strings shown in Table 3. Finally, we add the values as a new model and assign it a weight that is trained with MERT in addition to the standard model weights."}, {"heading": "3.4 Word Classes", "text": "The training sets for neural networks are relatively small, as all sentences have to be translated by each individual system engine, resulting in many invisible words in the test sentences. To solve this problem, we use word classes (Och, 1999) instead of words that have been trained in some experiments on the target part of the bilingual training corpus (10 iterations). We use the trained word classes at both the input and output levels."}, {"heading": "4 Experiments", "text": "All experiments were performed with the open source system combination toolkit Jane (Freitag et al., 2014). For training and evaluation of neural networks, we use the open source toolkit NPLM (Vaswani et al., 2013). NPLM is a toolkit for training and using feedback-forward neural language models. Variations in the neural network architecture were tested. We tried different hidden layer sizes as well as projection layer sizes. We achieved similar results for all setups and decided to stick to a hidden layer with a size of 200, a learning rate of 0.08, and to run the training in all experiments for 20 epochs. Translation quality is measured in lowercase letters with BLEU (Papineni et al., 2002) and TER (Snover et al., 2006), while the performance of each setup is the best score for training, a learning rate of 0.08 and the training weights of the ER20 system combinations in all experiments."}, {"heading": "4.1 BOLT Chinese\u2192English", "text": "In fact, it is that we are able to assert ourselves, that we are able, that we are able to hide ourselves, and that we are able, that we are able to hide ourselves, \"he said."}, {"heading": "4.2 BOLT Arabic\u2192English", "text": "The test sets consist of text from \"discussion forums\" in Egyptian Arabic. We train the neural network using 6,591,158 training examples extracted from the 1510 sets tune (NN) dev set. Model weights are optimized based on a 1080 sets tune set. All results are system combinations of five individual systems. The test set has a word size of 3491 within 1510 words (43.25%) that are not present in the neural network training set (tune (NN)). For the MERT tune set 1549 words (43.24%) are not part of the neural network training set.We maintain the same experiment pipeline as for Chinese \u2192 English and first determine the k-best threshold for reaching the oracular paths in the confusion networks. The Arabic \u2192 English system combination is only based on 5 individual systems, the confusion networks are much smaller. We set the time threshold for the BLER-1000 results."}, {"heading": "5 Analysis", "text": "In this section, we compare the final translations of the Chinese \u2192 English system combination + bigram wcNN with the baseline. The word occurrence distributions for both setups are illustrated in Table 8. This table shows how many input systems produce a particular word and finally, if it is part of the system combination. Since the original idea of the system combination is based on majority votes, it should be more likely that a word produced by more input systems lies in the final system combination than a word produced by only a few input systems. For example, 11008 words were produced by all 9 individual systems, all of which are in the system combination Baseline and the advanced system + bigram wcNN. If a word is produced by only 8 individual systems, a ninth system does not produce that word. 98.9% of the words produced by only 8 different individual systems are present in the final combination."}, {"heading": "6 Conclusion", "text": "Unlike the traditional globalVote model, the presented localVote model takes into account word contents and their combinatorial occurrences and not only promotes global preferences for some individual systems, this advantage gives the confusion network the ability to prefer other systems in different positions even in the same sentence. As all words are projected into a continuous space, the neural network also provides a useful probability for invisible word sequences. Due to the relatively small neural network, we use word classes in some experiments to tackle the problem of data sparseness. Experiments were conducted with high-quality input systems for BOLT Chinese \u2192 English and Arabic \u2192 English translation tasks. Training an additional model by a neural with word classes leads to a translation improvement of up to + 0.9 points in BLEU and -0.5 points in TER. We also took into account the word context and added the precursors of the individual systems likely to be translated by the network."}, {"heading": "Acknowledgement", "text": "This material is based in part on work supported by the DARPA-BOLT project under contract number HR0011-12-C-0015. Any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of DARPA. Furthermore, this work has been funded by the European Union's Horizon 2020 research and innovation programme under grant agreement No. 645452 (QT21)."}], "references": [{"title": "Computing consensus translation from multiple machine translation systems", "author": ["Srinivas Bangalore", "German Bordel", "Giuseppe Riccardi."], "venue": "IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU), pages 351\u2013354, Madonna", "citeRegEx": "Bangalore et al\\.,? 2001", "shortCiteRegEx": "Bangalore et al\\.", "year": 2001}, {"title": "Neural probabilistic language models", "author": ["Yoshua Bengio", "Holger Schwenk", "Jean-S\u00e9bastien Sen\u00e9cal", "Fr\u00e9deric Morin", "Jean-Luc Gauvain."], "venue": "Innovations in Machine Learning, pages 137\u2013186. Springer.", "citeRegEx": "Bengio et al\\.,? 2006", "shortCiteRegEx": "Bengio et al\\.", "year": 2006}, {"title": "Jane: Open source machine translation system combination", "author": ["Markus Freitag", "Matthias Huck", "Hermann Ney."], "venue": "Conference of the European Chapter of the Association for Computational Linguistics (EACL), pages 29\u201332, Gothenburg, Sweden,", "citeRegEx": "Freitag et al\\.,? 2014", "shortCiteRegEx": "Freitag et al\\.", "year": 2014}, {"title": "Indirect-HMMbased Hypothesis Alignment for Combining Outputs from Machine Translation Systems", "author": ["Xiaodong He", "Mei Yang", "Jianfeng Gao", "Patrick Nguyen", "Robert Moore."], "venue": "Conference on Empirical Methods in Natural Language", "citeRegEx": "He et al\\.,? 2008", "shortCiteRegEx": "He et al\\.", "year": 2008}, {"title": "Combining Machine Translation Output with Open Source: The Carnegie Mellon Multi-Engine Machine Translation Scheme", "author": ["Kenneth Heafield", "Alon Lavie."], "venue": "The Prague Bulletin of Mathematical Linguistics, 93:27\u201336.", "citeRegEx": "Heafield and Lavie.,? 2010", "shortCiteRegEx": "Heafield and Lavie.", "year": 2010}, {"title": "i rover: improving system combination with classification", "author": ["Dustin Hillard", "Bj\u00f6rn Hoffmeister", "Mari Ostendorf", "Ralf Schl\u00fcter", "Hermann Ney."], "venue": "Conference of the North American Chapter of the Association for Computational Linguistics", "citeRegEx": "Hillard et al\\.,? 2007", "shortCiteRegEx": "Hillard et al\\.", "year": 2007}, {"title": "Machine translation system combination using ITG-based alignments", "author": ["Damianos Karakos", "Jason Eisner", "Sanjeev Khudanpur", "Markus Dreyer."], "venue": "46th Annual Meeting of the Association for Computational Linguistics on Human Language Technolo-", "citeRegEx": "Karakos et al\\.,? 2008", "shortCiteRegEx": "Karakos et al\\.", "year": 2008}, {"title": "Statistical significance tests for machine translation evaluation", "author": ["Philipp Koehn."], "venue": "Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 388\u2013395, Barcelona, Spain, July.", "citeRegEx": "Koehn.,? 2004", "shortCiteRegEx": "Koehn.", "year": 2004}, {"title": "Complexity of finding the bleu-optimal hypothesis in a confusion network", "author": ["Gregor Leusch", "Evgeny Matusov", "Hermann Ney."], "venue": "Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 839\u2013847, Honolulu, HI, USA, Oc-", "citeRegEx": "Leusch et al\\.,? 2008", "shortCiteRegEx": "Leusch et al\\.", "year": 2008}, {"title": "Automatic evaluation of machine translation quality using longest common subsequence and skip-bigram statistics", "author": ["Chin-Yew Lin", "Franz Josef Och."], "venue": "The 42nd Annual Meeting on Association for Computational Linguistics (ACL), page 605,", "citeRegEx": "Lin and Och.,? 2004", "shortCiteRegEx": "Lin and Och.", "year": 2004}, {"title": "Computing Consensus Translation from Multiple Machine Translation Systems Using Enhanced Hypotheses Alignment", "author": ["Evgeny Matusov", "Nicola Ueffing", "Hermann Ney."], "venue": "Conference of the European Chapter of the Association for Computa-", "citeRegEx": "Matusov et al\\.,? 2006", "shortCiteRegEx": "Matusov et al\\.", "year": 2006}, {"title": "An Efficient Method for Determining Bilingual Word Classes", "author": ["Franz Josef Och."], "venue": "Ninth Conference on European Chapter of the Association for Computational Linguistics (EACL), pages 71\u2013 76, Bergen, Norway, June.", "citeRegEx": "Och.,? 1999", "shortCiteRegEx": "Och.", "year": 1999}, {"title": "Bleu: a method for automatic evaluation of machine translation", "author": ["Kishore Papineni", "Salim Roukos", "Todd Ward", "WeiJing Zhu."], "venue": "40th Annual Meeting on Association for Computational Linguistics (ACL), pages 311\u2013318, Philadelphia, PA, USA,", "citeRegEx": "Papineni et al\\.,? 2002", "shortCiteRegEx": "Papineni et al\\.", "year": 2002}, {"title": "Combining outputs from multiple machine translation systems", "author": ["Antti-Veikko Rosti", "Necip Fazil Ayan", "Bing Xiang", "Spyridon Matsoukas", "Richard Schwartz", "Bonnie Dorr."], "venue": "The Annual Conference of the North American Chapter of the Associ-", "citeRegEx": "Rosti et al\\.,? 2007", "shortCiteRegEx": "Rosti et al\\.", "year": 2007}, {"title": "Connectionist language modeling for large vocabulary continuous speech recognition", "author": ["Holger Schwenk", "Jean-Luc Gauvain."], "venue": "IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), volume 1, pages I\u2013765, Or-", "citeRegEx": "Schwenk and Gauvain.,? 2002", "shortCiteRegEx": "Schwenk and Gauvain.", "year": 2002}, {"title": "Consensus Network Decoding for Statistical Machine", "author": ["Khe Chai Sim", "William J. Byrne", "Mark J.F. Gales", "Hichem Sahbi", "Phil C. Woodland"], "venue": null, "citeRegEx": "Sim et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Sim et al\\.", "year": 2007}, {"title": "A Study of Translation Edit Rate with Targeted Human Annotation", "author": ["Matthew Snover", "Bonnie Dorr", "Richard Schwartz", "Linnea Micciula", "John Makhoul."], "venue": "Association for Machine Translation in the Americas (AMTA), pages 223\u2013231, Cambridge,", "citeRegEx": "Snover et al\\.,? 2006", "shortCiteRegEx": "Snover et al\\.", "year": 2006}, {"title": "Continuous space translation models with neural networks", "author": ["Le Hai Son", "Alexandre Allauzen", "Fran\u00e7ois Yvon."], "venue": "The 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Tech-", "citeRegEx": "Son et al\\.,? 2012", "shortCiteRegEx": "Son et al\\.", "year": 2012}, {"title": "Decoding with largescale neural language models improves translation", "author": ["Ashish Vaswani", "Yinggong Zhao", "Victoria Fossum", "David Chiang."], "venue": "Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1387\u20131392,", "citeRegEx": "Vaswani et al\\.,? 2013", "shortCiteRegEx": "Vaswani et al\\.", "year": 2013}, {"title": "Stochastic inversion transduction grammars and bilingual parsing of parallel corpora", "author": ["Dekai Wu."], "venue": "Computational linguistics, 23(3):377\u2013403.", "citeRegEx": "Wu.,? 1997", "shortCiteRegEx": "Wu.", "year": 1997}], "referenceMentions": [{"referenceID": 17, "context": ", 2006, Schwenk and Gauvain, 2002) and translation modelling (Son et al., 2012), we choose feedforward neural networks to train the novel model.", "startOffset": 61, "endOffset": 79}, {"referenceID": 0, "context": "(Bangalore et al., 2001) use a multiple string alignment (MSA) algorithm to identify the unit of consensus and applied a posterior language model to extract the consensus translations.", "startOffset": 0, "endOffset": 24}, {"referenceID": 10, "context": "(Matusov et al., 2006) produce pairwise word alignments with the statistical alignment algorithm toolkit GIZA++ that explicitly models word reordering.", "startOffset": 0, "endOffset": 22}, {"referenceID": 15, "context": "(Sim et al., 2007) construct a consensus network by using TER (Snover et al.", "startOffset": 0, "endOffset": 18}, {"referenceID": 16, "context": ", 2007) construct a consensus network by using TER (Snover et al., 2006) alignments.", "startOffset": 51, "endOffset": 72}, {"referenceID": 13, "context": "(Rosti et al., 2007) extend the TER alignment approach and introduce an incremental TER alignment which aligns one system at a time to all previously aligned hypotheses.", "startOffset": 0, "endOffset": 20}, {"referenceID": 6, "context": "(Karakos et al., 2008) use the inversion transduction grammar (ITG) formalism (Wu, 1997) and treat the alignment problem as a problem of bilingual parsing to generate the pairwise alignments.", "startOffset": 0, "endOffset": 22}, {"referenceID": 19, "context": ", 2008) use the inversion transduction grammar (ITG) formalism (Wu, 1997) and treat the alignment problem as a problem of bilingual parsing to generate the pairwise alignments.", "startOffset": 63, "endOffset": 73}, {"referenceID": 3, "context": "(He et al., 2008) propose an indirect hidden markov model (IHMM) alignment approach to address the synonym matching and word ordering issues in hypothesis alignment.", "startOffset": 0, "endOffset": 17}, {"referenceID": 4, "context": "(Heafield and Lavie, 2010) use the METEOR toolkit to calculate pairwise alignments between the hypotheses.", "startOffset": 0, "endOffset": 26}, {"referenceID": 5, "context": "(Hillard et al., 2007) Similar work has been presented for system combination of speech recognitions systems: the authors train a classifier to learn which system should be selected for each output word.", "startOffset": 0, "endOffset": 22}, {"referenceID": 8, "context": "(Leusch et al., 2008) showed that this problem is generally NP-hard for the popular BLEU (Papineni et al.", "startOffset": 0, "endOffset": 21}, {"referenceID": 12, "context": ", 2008) showed that this problem is generally NP-hard for the popular BLEU (Papineni et al., 2002) metric.", "startOffset": 75, "endOffset": 98}, {"referenceID": 9, "context": "To allow for sentence-wise evaluation, we use the SBLEU metric (Lin and Och, 2004), which is basically BLEU where all n-gram counts are initialized with 1 instead of 0.", "startOffset": 63, "endOffset": 82}, {"referenceID": 18, "context": "In all upcoming system setups, we use the open source toolkit NPLM (Vaswani et al., 2013) for training and testing the neural network models.", "startOffset": 67, "endOffset": 89}, {"referenceID": 11, "context": "To overcome this problem, we use word classes (Och, 1999) instead of words which were trained (10 iterations) on the target part of the bilingual training corpus in some experiments.", "startOffset": 46, "endOffset": 57}, {"referenceID": 2, "context": "All experiments have been conducted with the open source system combination toolkit Jane (Freitag et al., 2014).", "startOffset": 89, "endOffset": 111}, {"referenceID": 18, "context": "For training and scoring neural networks, we use the open source toolkit NPLM (Vaswani et al., 2013).", "startOffset": 78, "endOffset": 100}, {"referenceID": 12, "context": "Translation quality is measured in lowercase with BLEU (Papineni et al., 2002) and TER (Snover et al.", "startOffset": 55, "endOffset": 78}, {"referenceID": 16, "context": ", 2002) and TER (Snover et al., 2006) whereas the performance of each setup is the best score on the tune set across five different MERT runs.", "startOffset": 16, "endOffset": 37}, {"referenceID": 2, "context": "The baseline is a system combination run without any localVote model of nine individual systems using the standard models as described in (Freitag et al., 2014).", "startOffset": 138, "endOffset": 160}, {"referenceID": 7, "context": "Significance is marked with \u2020 for 95% confidence and \u2021 for 99% confidence, and is measured with the bootstrap resampling method as described in (Koehn, 2004).", "startOffset": 144, "endOffset": 157}, {"referenceID": 2, "context": "The baseline is a system combination run without any localVote model of five individual systems using the standard models as described in (Freitag et al., 2014).", "startOffset": 138, "endOffset": 160}, {"referenceID": 7, "context": "Significance is marked with \u2021 for 99% confidence and is measured with the bootstrap resampling method as described in (Koehn, 2004).", "startOffset": 118, "endOffset": 131}], "year": 2017, "abstractText": "In this paper, we enhance the traditional confusion network system combination approach with an additional model trained by a neural network. This work is motivated by the fact that the commonly used binary system voting models only assign each input system a global weight which is responsible for the global impact of each input system on all translations. This prevents individual systems with low system weights from having influence on the system combination output, although in some situations this could be helpful. Further, words which have only been seen by one or few systems rarely have a chance of being present in the combined output. We train a local system voting model by a neural network which is based on the words themselves and the combinatorial occurrences of the different system outputs. This gives system combination the option to prefer other systems at different word positions even for the same sentence.", "creator": "TeX"}}}