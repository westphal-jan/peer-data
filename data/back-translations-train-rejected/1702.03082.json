{"id": "1702.03082", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Feb-2017", "title": "UsingWord Embedding for Cross-Language Plagiarism Detection", "abstract": "This paper proposes to use distributed representation of words (word embeddings) in cross-language textual similarity detection. The main contributions of this paper are the following: (a) we introduce new cross-language similarity detection methods based on distributed representation of words; (b) we combine the different methods proposed to verify their complementarity and finally obtain an overall F1 score of 89.15% for English-French similarity detection at chunk level (88.5% at sentence level) on a very challenging corpus.", "histories": [["v1", "Fri, 10 Feb 2017 07:22:08 GMT  (287kb,D)", "http://arxiv.org/abs/1702.03082v1", "Accepted to EACL 2017 (short)"]], "COMMENTS": "Accepted to EACL 2017 (short)", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["j ferrero", "f agnes", "l besacier", "d schwab"], "accepted": false, "id": "1702.03082"}, "pdf": {"name": "1702.03082.pdf", "metadata": {"source": "CRF", "title": "Using Word Embedding for Cross-Language Plagiarism Detection", "authors": ["J\u00e9r\u00e9my Ferrero", "Didier Schwab"], "emails": ["jeremy.ferrero@imag.fr", "frederic@compilatio.net", "laurent.besacier@imag.fr", "didier.schwab@imag.fr"], "sections": [{"heading": "1 Introduction", "text": "In a monolingual context, this problem is fairly well addressed by several recent research (Potthast et al., 2014). Nevertheless, the expansion of the Internet, which facilitates access to documents around the world and increasingly efficient (freely available) machine translation tools, is contributing to the spread of plagiarism across languages. Cross-lingual plagiarism means plagiarism through translation, i.e. a text has been plagiarized (manually or automatically) during translation. The challenge in detecting this type of plagiarism is that the suspect document is no longer in the same language as its source. We are investigating how distributed word representations can help to toproporize new cross-linguistic similarity measures that are helpful for the detection of plagiarism. We use word embedding (Mikolov et al., 2013), which provide promising performance for all types of NLP tasks as demonstrated in 2016 (plagiarism proof 8and synchronized)."}, {"heading": "2 Evaluation Conditions", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Dataset", "text": "The reference dataset used during our study is the new dataset recently introduced by Ferrero et al.ar Xiv: 170 2.03 082v 1 [cs.C L] 10 Fe (2016) 1. The dataset was specifically designed for a rigorous evaluation of cross-language recognition of textual similarity. Specifically, the characteristics of the dataset are as follows: \u2022 it is multilingual: it contains French, English and Spanish texts; \u2022 it proposes cross-language adaptations for different granularities: document level, sentence level and piece level; \u2022 it is based on both parallel and comparable corpora (a mixture of Wikipedia, conference papers, product reviews, Europarl and JRC); \u2022 it contains both texts translated by man and machine; \u2022 it contains different percentages of named entities; \u2022 a part of which has been obscured (to make linguistic similarity more difficult), while the rest remains without interferences; the technical documents were partially translated into French and French by various specialists."}, {"heading": "2.2 Overview of State-of-the-Art Methods", "text": "Plagiarism is a statement that someone has intentionally copied text without assignment, whereas these methods only recognize textual similarities. However, detection of textual similarities can be used to detect plagiarism. The goal of cross-language detection of textual similarities is to estimate whether or not two textual units in different languages express the same thing. We quickly check below the state-of-the-art methods used in this essay, see Ferrero et al. (2016) for more details. Cross-Language Character N-Gram (CL-CnG) is based on Mcnamee and Mayfield (2004) models. We use the Potthast et al al al al al al al. (2011) implementation that represents two textual units among their 3-gram vectors. Cross-Language Character N-Gram (CL-CnG) is based on Mcnamee and Mayfield (2004) models. We use the Potthast et al al al al al al. We use the Pottuast et al al al model that represents two textual units under their 3 gram."}, {"heading": "2.3 Evaluation Protocol", "text": "We use the same evaluation protocol as in the work of Ferrero et al. (2016). We create a distance matrix of the size N xM with M = 1,000 and N = | S |, where S is the weighted subcorpus. Each textual unit of S is compared with itself (with the corresponding unit in the target language, as it is the recognition of cross-lingual similarities) and with M -1 other units randomly selected from S. Subsequently, for each comparison performed, a matching score is obtained that leads to the distance matrix. To determine the threshold that results in the best F1 score, the F1 score is used as a harmonious means of precision and memory. Precision is defined as the percentage of relevant matrices (similar cross-linguistic units) that are determined taking into account all the matrices found. Recall relevant matrices are the proportion of the matrices retrieved from all relevant matrices."}, {"heading": "3 Proposed Methods", "text": "The main idea of word embedding is that it is presented according to the context (the words around it), the words are projected onto a continuous space, and the words with similar context should be close in that multidimensional space. Similarities between two word vectors can be measured by cosinal similarity, so it is appealing to use plagiarism detection words as they can be used to calculate similarities between sentences in the same or two different languages (they capture synonymous and morphological proximity in themselves).We use the MultiVec toolkit (Berard et al., 2016) to calculate and manage the continuous representation of texts. It includes word2vec (Mikolov et al., 2013), paragraph vector (Le and Mikolov, 2014) and bilingual distributed representations (Luong et al., 2015).The corpus used to build the vectors is the message comment model of 100, a corpus of W with a corpus size of 0.05."}, {"heading": "3.1 Improving Textual Similarity Using", "text": "Word Embeddings (CL-CTS-WE and CL-WES) We introduce two new methods. First, we propose to replace the lexical resource used in CL-CTS (i.e. DBNary) with a distributed representation of words. We call this new implementation CL-CTS-WE. Specifically, CL-CTS-WE uses the 10 closest words in the embedding model to form the BOW of a word. Secondly, we implement a simpler method (CL-WES) that performs a direct comparison between two sentences in different languages, using word embeddings. It consists of a comfortable similarity on distributed representations of the sentences, which are the sum of the embedding vectors of each word of the sentences. Let U make a textual unit, the n words of the unit are represented by ui as: U = {u1, u2, u3, Utuelle, U.un} (if two units are HES and two)."}, {"heading": "3.2 Cross-Language Word Embedding-based Syntax Similarity (CL-WESS)", "text": "Our next innovation is to improve CL-WES by introducing a syntax property in it. Let's form a textual unit, the n words of the unit are represented by ui, as expressed in formula (1). First, we mark U syntactically with a part-of-speech tagger (TreeTagger (Schmid, 1994) and normalize the tags with Universal Tagset of Petrov et al. (2012). Then we assign a weight to each type of tag: This weight is used to calculate the final vector representation of the unit. Finally, we optimize the weights with the help of Condor (Berghen and Bersini, 2005). Condor applies a Newton method using a trust region algorithm to determine the weights that optimize the F1 score. We use the first two folds of each subbody to determine the optimal weights. The formula of syntactic aggregation is: V = n-i = 1 (pos."}, {"heading": "4 Combining multiple methods", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Weighted Fusion", "text": "In weighted fusion, we assign a weight to the similarity value of each method and calculate a (weighted) composite value. We optimize the distribution of weights with Condor (Berghen and Bersini, 2005). We use the first two folds of each subbody to determine the optimal weights, while the other eight folds evaluate the fusion. We also try an average fusion, i.e. a weighted fusion in which all weights are equal."}, {"heading": "4.2 Decision Tree Fusion", "text": "Regardless of their ability to predict a (false) match, an interesting feature of the methods is their clustering capacity, i.e. their ability to correctly separate the positives (similar units) and the negatives (different units) to minimize doubts about the classification. Distribution histograms in Figure 1 underscore the fact that each method has its own fingerprint. Although two methods look the same in terms of final performance, their distribution may be different. One explanation is that the methods do not process in the same way (Figure 1 (a)), while others capture the context with word vectors by aligning concepts (semantic) and still others. For example, CL-C3G has a narrow distribution of negatives and a broad distribution for positives (Figure 1 (a)), while the opposite is true for CL-ASA (Figure 1 (b). We are trying to exploit this complementarity by means of decision tree fusion."}, {"heading": "5 Results and Discussion", "text": "The use of word embedding. We can see in Table 1 that the use of distributed representation of words instead of lexical resources improves CL-CTS (CL-CTS-WE achieves an overall performance increase of + 3.83% for chunks and + 3.19% for sentences). Despite this improvement, CL-CTS-WE remains less efficient than CL-C3G. While the use of bilingual sentence vector (CL-WES) is simple and elegant, its performance is lower than three state-of-the-art methods. However, its syntactically weighted version (CL-WESS) looks very promising and increases the overall performance of CL-WES by + 11.78% for chunks and + 14.92% for sentences. Thanks to this improvement, CL-WESS is significantly better than the CL-C3G minimum decision (+ 2.97% for chunks and + 7.01% for combination art)."}, {"heading": "6 Conclusion and Perspectives", "text": "The most promising approach is a cosmic similarity in the syntactically weighted distributed representation of the sentence (CL-WESS), which overall exceeds the best state-of-the-art method. Finally, we have also shown that all methods are complementary and their fusion significantly contributes to the recognition of cross-linguistic text similarity. At the chunk level, decision tree fusion leads to an overall result of 89.15%, while precedent best-weighted fusion reaches 80.01% and the best single method only 53.73%. The trend is the same at the sentence level, where decision tree fusion largely outperforms any other method. Our future short-term goal is to work on improving CL-WESS by analyzing syntactical weights or even adjusting them according to the plagiarist's style."}], "references": [{"title": "Massively Multilingual Word Embeddings", "author": ["Waleed Ammar", "George Mulcaire", "Yulia Tsvetkov", "Guillaume Lample", "Chris Dyer", "Noah A. Smith."], "venue": "arXiv.org: http://arxiv.org/pdf/1602.01925v2.pdf. Computing Research Repository.", "citeRegEx": "Ammar et al\\.,? 2016", "shortCiteRegEx": "Ammar et al\\.", "year": 2016}, {"title": "On Cross-lingual Plagiarism Analysis using a Statistical Model", "author": ["Alberto Barr\u00f3n-Cede\u00f1o", "Paolo Rosso", "David Pinto", "Alfons Juan."], "venue": "Benno Stein and Efstathios Stamatatos and Moshe Koppel, editor, Proceedings of the ECAI\u201908 PAN Workshop:", "citeRegEx": "Barr\u00f3n.Cede\u00f1o et al\\.,? 2008", "shortCiteRegEx": "Barr\u00f3n.Cede\u00f1o et al\\.", "year": 2008}, {"title": "On the Mono- and Cross-Language Detection of Text Re-Use and Plagiarism", "author": ["Alberto Barr\u00f3n-Cede\u00f1o."], "venue": "PhD thesis, Val\u00e8ncia, Spain.", "citeRegEx": "Barr\u00f3n.Cede\u00f1o.,? 2012", "shortCiteRegEx": "Barr\u00f3n.Cede\u00f1o.", "year": 2012}, {"title": "MultiVec: a Multilingual and Multilevel Representation Learning Toolkit for NLP", "author": ["Alexandre Berard", "Christophe Servan", "Olivier Pietquin", "Laurent Besacier."], "venue": "Proceedings of the Tenth International Conference on Language Resources and Evalua-", "citeRegEx": "Berard et al\\.,? 2016", "shortCiteRegEx": "Berard et al\\.", "year": 2016}, {"title": "CONDOR, a new parallel, constrained extension of Powell\u2019s UOBYQA algorithm: Experimental results and comparison with the DFO algorithm", "author": ["Frank Vanden Berghen", "Hugues Bersini."], "venue": "Journal of Computational and Applied Mathematics, 181:157\u2013", "citeRegEx": "Berghen and Bersini.,? 2005", "shortCiteRegEx": "Berghen and Bersini.", "year": 2005}, {"title": "A Fast and Accurate Dependency Parser using Neural Networks", "author": ["Danqi Chen", "Christopher D. Manning."], "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, EMNLP 2014, pages 740\u2013750, Doha, Qatar.", "citeRegEx": "Chen and Manning.,? 2014", "shortCiteRegEx": "Chen and Manning.", "year": 2014}, {"title": "A Multilingual, Multi-style and Multi-granularity Dataset for Cross-language Textual Similarity Detection", "author": ["J\u00e9r\u00e9my Ferrero", "Fr\u00e9d\u00e9ric Agn\u00e8s", "Laurent Besacier", "Didier Schwab."], "venue": "Proceedings of the Tenth International Conference on Language", "citeRegEx": "Ferrero et al\\.,? 2016", "shortCiteRegEx": "Ferrero et al\\.", "year": 2016}, {"title": "Computing Semantic Relatedness using Wikipediabased Explicit Semantic Analysis", "author": ["Evgeniy Gabrilovich", "Shaul Markovitch."], "venue": "Proceedings of the 20th International Joint Conference on Artifical Intelligence (IJCAI\u201907), pages 1606\u20131611, Hyder-", "citeRegEx": "Gabrilovich and Markovitch.,? 2007", "shortCiteRegEx": "Gabrilovich and Markovitch.", "year": 2007}, {"title": "Word Embedding Evaluation and Combination", "author": ["Sahar Ghannay", "Benoit Favre", "Yannick Est\u00e8ve", "Nathalie Camelin."], "venue": "Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC\u201916), Portoroz, Slovenia,", "citeRegEx": "Ghannay et al\\.,? 2016", "shortCiteRegEx": "Ghannay et al\\.", "year": 2016}, {"title": "The WEKA Data Mining Software: An Update", "author": ["Mark Hall", "Eibe Frank", "Geoffrey Holmes", "Bernhard Pfahringer", "Peter Reutemann", "Ian H. Witten."], "venue": "SIGKDD Explorations, volume 11, pages 10\u201318, July.", "citeRegEx": "Hall et al\\.,? 2009", "shortCiteRegEx": "Hall et al\\.", "year": 2009}, {"title": "Distributed Representations of Sentences and Documents", "author": ["Quoc V. Le", "Tomas Mikolov."], "venue": "Proceedings of the 31th International Conference on Machine Learning (ICML\u201914), volume 32, pages 1188\u20131196, Beijing, China, June. JMLR Proceed-", "citeRegEx": "Le and Mikolov.,? 2014", "shortCiteRegEx": "Le and Mikolov.", "year": 2014}, {"title": "Bilingual Word Representations with Monolingual Quality in Mind", "author": ["Minh-Thang Luong", "Hieu Pham", "Christopher D. Manning."], "venue": "Proceedings of the 1st NAACL Workshop on Vector Space Modeling for Natural Language Processing, Denver, Col-", "citeRegEx": "Luong et al\\.,? 2015", "shortCiteRegEx": "Luong et al\\.", "year": 2015}, {"title": "Character N-Gram Tokenization for European Language Text Retrieval", "author": ["Paul Mcnamee", "James Mayfield."], "venue": "Information Retrieval Proceedings, volume 7, pages 73\u201397. Kluwer Academic Publishers.", "citeRegEx": "Mcnamee and Mayfield.,? 2004", "shortCiteRegEx": "Mcnamee and Mayfield.", "year": 2004}, {"title": "Distributed Representations of Words and Phrases and their Compositionality", "author": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Gregory S. Corrado", "Jeffrey Dean."], "venue": "Proceedings of the 27th Annual Conference on Neural Information Processing Systems", "citeRegEx": "Mikolov et al\\.,? 2013", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "External and Intrinsic Plagiarism Detection Using a Cross-Lingual Retrieval and Segmentation System - Lab Report for PAN at CLEF 2010", "author": ["Markus Muhr", "Roman Kern", "Mario Zechner", "Michael Granitzer."], "venue": "Martin Braschler, Donna Har-", "citeRegEx": "Muhr et al\\.,? 2010", "shortCiteRegEx": "Muhr et al\\.", "year": 2010}, {"title": "A New Approach for Searching Translated Plagiarism", "author": ["M\u00e0t\u00e9 Pataki."], "venue": "Proceedings of the 5th International Plagiarism Conference, Newcastle, UK.", "citeRegEx": "Pataki.,? 2012", "shortCiteRegEx": "Pataki.", "year": 2012}, {"title": "A universal part-of-speech tagset", "author": ["Slav Petrov", "Dipanjan Das", "Ryan McDonald."], "venue": "Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC\u201912), Istanbul, Turkey, May. European Language Resources", "citeRegEx": "Petrov et al\\.,? 2012", "shortCiteRegEx": "Petrov et al\\.", "year": 2012}, {"title": "A Statistical Approach to Crosslingual Natural Language Tasks", "author": ["David Pinto", "Jorge Civera", "Alfons Juan", "Paolo Rosso", "Alberto Barr\u00f3n-Cede\u00f1o."], "venue": "CEUR Workshop Proceedings, volume 64 of Journal of Algorithms, pages 51\u201360, January.", "citeRegEx": "Pinto et al\\.,? 2009", "shortCiteRegEx": "Pinto et al\\.", "year": 2009}, {"title": "A Wikipedia-Based Multilingual Retrieval Model", "author": ["Martin Potthast", "Benno Stein", "Maik Anderka."], "venue": "30th European Conference on IR Research (ECIR\u201908), volume 4956 of LNCS of Lecture Notes in Computer Science, pages 522\u2013530, Glas-", "citeRegEx": "Potthast et al\\.,? 2008", "shortCiteRegEx": "Potthast et al\\.", "year": 2008}, {"title": "Cross-Language Plagiarism Detection", "author": ["Martin Potthast", "Alberto Barr\u00f3n-Cede\u00f1o", "Benno Stein", "Paolo Rosso."], "venue": "Language Resources and Evaluation, volume 45, pages 45\u201362.", "citeRegEx": "Potthast et al\\.,? 2011", "shortCiteRegEx": "Potthast et al\\.", "year": 2011}, {"title": "Overview of the 6th International Competition on Plagiarism Detection", "author": ["Martin Potthast", "Matthias Hagen", "Anna Beyer", "Matthias Busse", "Martin Tippmann", "Paolo Rosso", "Benno Stein."], "venue": "PAN at CLEF 2014, Sheffield, UK, September.", "citeRegEx": "Potthast et al\\.,? 2014", "shortCiteRegEx": "Potthast et al\\.", "year": 2014}, {"title": "C4.5: Programs for Machine Learning. The Morgan Kaufmann series in machine learning", "author": ["J. Ross Quinlan"], "venue": null, "citeRegEx": "Quinlan.,? \\Q1993\\E", "shortCiteRegEx": "Quinlan.", "year": 1993}, {"title": "Probabilistic Part-of-Speech Tagging Using Decision Trees", "author": ["Helmut Schmid."], "venue": "Proceedings of the International Conference on New Methods in Language Processing, Manchester, UK.", "citeRegEx": "Schmid.,? 1994", "shortCiteRegEx": "Schmid.", "year": 1994}, {"title": "DBnary: Wiktionary as a Lemon-Based Multilingual Lexical Resource in RDF", "author": ["Gilles S\u00e9rasset."], "venue": "Semantic Web Journal (special issue on Multilingual Linked Open Data), volume 6, pages 355\u2013361.", "citeRegEx": "S\u00e9rasset.,? 2015", "shortCiteRegEx": "S\u00e9rasset.", "year": 2015}, {"title": "Cross-lingual Models of Word Embeddings: An Empirical Comparison", "author": ["Shyam Upadhyay", "Manaal Faruqui", "Chris Dyer", "Dan Roth."], "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL\u201916),", "citeRegEx": "Upadhyay et al\\.,? 2016", "shortCiteRegEx": "Upadhyay et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 20, "context": "In monolingual context, this problem is rather well treated by several recent researches (Potthast et al., 2014).", "startOffset": 89, "endOffset": 112}, {"referenceID": 13, "context": "We use word embeddings (Mikolov et al., 2013) that have shown promising performances for all kinds of NLP tasks, as shown in Upadhyay et al.", "startOffset": 23, "endOffset": 45}, {"referenceID": 11, "context": "We use word embeddings (Mikolov et al., 2013) that have shown promising performances for all kinds of NLP tasks, as shown in Upadhyay et al. (2016), Ammar et al.", "startOffset": 24, "endOffset": 148}, {"referenceID": 0, "context": "(2016), Ammar et al. (2016) and Ghannay et al.", "startOffset": 8, "endOffset": 28}, {"referenceID": 0, "context": "(2016), Ammar et al. (2016) and Ghannay et al. (2016), for instance.", "startOffset": 8, "endOffset": 54}, {"referenceID": 6, "context": "We quickly review below the state-of-the-art methods used in this paper, for more details, see Ferrero et al. (2016).", "startOffset": 95, "endOffset": 117}, {"referenceID": 12, "context": "is based on Mcnamee and Mayfield (2004) model.", "startOffset": 12, "endOffset": 40}, {"referenceID": 12, "context": "is based on Mcnamee and Mayfield (2004) model. We use the Potthast et al. (2011) implementation which compares two textual units under their 3-grams vectors representation.", "startOffset": 12, "endOffset": 81}, {"referenceID": 15, "context": "Similarity (CL-CTS) (Pataki, 2012) aims to measure the semantic similarity using abstract con-", "startOffset": 20, "endOffset": 34}, {"referenceID": 23, "context": "In our implementation, these concepts are given by a linked lexical resource called DBNary (S\u00e9rasset, 2015).", "startOffset": 91, "endOffset": 107}, {"referenceID": 17, "context": "(2008), Pinto et al. (2009)).", "startOffset": 8, "endOffset": 28}, {"referenceID": 7, "context": "(CL-ESA) is based on the explicit semantic analysis model (Gabrilovich and Markovitch, 2007), which represents the meaning of a document by a vector based on concepts derived from Wikipedia.", "startOffset": 58, "endOffset": 92}, {"referenceID": 7, "context": "(CL-ESA) is based on the explicit semantic analysis model (Gabrilovich and Markovitch, 2007), which represents the meaning of a document by a vector based on concepts derived from Wikipedia. It was reused by Potthast et al. (2008) in the context of cross-language document retrieval.", "startOffset": 59, "endOffset": 231}, {"referenceID": 2, "context": "consists in translating the two units into the same language, in order to operate a monolingual comparison between them (Barr\u00f3n-Cede\u00f1o, 2012).", "startOffset": 120, "endOffset": 141}, {"referenceID": 23, "context": "(2010) approach using DBNary (S\u00e9rasset, 2015), followed by monolingual matching based on bags of words.", "startOffset": 29, "endOffset": 45}, {"referenceID": 2, "context": "consists in translating the two units into the same language, in order to operate a monolingual comparison between them (Barr\u00f3n-Cede\u00f1o, 2012). We use the Muhr et al. (2010) approach using DBNary (S\u00e9rasset, 2015), followed by monolingual matching based on bags of words.", "startOffset": 121, "endOffset": 173}, {"referenceID": 6, "context": "We apply the same evaluation protocol as in Ferrero et al. (2016)\u2019s paper.", "startOffset": 44, "endOffset": 66}, {"referenceID": 3, "context": "We use the MultiVec (Berard et al., 2016) toolkit for computing and managing the continuous representations of the texts.", "startOffset": 20, "endOffset": 41}, {"referenceID": 13, "context": "It includes word2vec (Mikolov et al., 2013), paragraph vector (Le and Mikolov, 2014) and bilingual distributed representations (Luong et al.", "startOffset": 21, "endOffset": 43}, {"referenceID": 10, "context": ", 2013), paragraph vector (Le and Mikolov, 2014) and bilingual distributed representations (Luong et al.", "startOffset": 26, "endOffset": 48}, {"referenceID": 11, "context": ", 2013), paragraph vector (Le and Mikolov, 2014) and bilingual distributed representations (Luong et al., 2015) features.", "startOffset": 91, "endOffset": 111}, {"referenceID": 3, "context": "This feature is available in MultiVec3 (Berard et al., 2016).", "startOffset": 39, "endOffset": 60}, {"referenceID": 22, "context": "First, we syntactically tag U with a part-of-speech tagger (TreeTagger (Schmid, 1994)) and we normalize the tags with Universal Tagset of Petrov et al.", "startOffset": 71, "endOffset": 85}, {"referenceID": 4, "context": "Finally, we optimize the weights with the help of Condor (Berghen and Bersini, 2005).", "startOffset": 57, "endOffset": 84}, {"referenceID": 15, "context": "First, we syntactically tag U with a part-of-speech tagger (TreeTagger (Schmid, 1994)) and we normalize the tags with Universal Tagset of Petrov et al. (2012). Then, we assign a weight to each type of tag: this weight will be used to compute the final vector representation of the unit.", "startOffset": 138, "endOffset": 159}, {"referenceID": 3, "context": "We call this method CL-WESS and we have implemented it in MultiVec (Berard et al., 2016).", "startOffset": 67, "endOffset": 88}, {"referenceID": 4, "context": "We optimize the distribution of the weights with Condor (Berghen and Bersini, 2005).", "startOffset": 56, "endOffset": 83}, {"referenceID": 21, "context": "5 algorithm (Quinlan, 1993) implemented in Weka 3.", "startOffset": 12, "endOffset": 27}, {"referenceID": 9, "context": "0 (Hall et al., 2009).", "startOffset": 2, "endOffset": 21}], "year": 2017, "abstractText": "This paper proposes to use distributed representation of words (word embeddings) in cross-language textual similarity detection. The main contributions of this paper are the following: (a) we introduce new cross-language similarity detection methods based on distributed representation of words; (b) we combine the different methods proposed to verify their complementarity and finally obtain an overall F1 score of 89.15% for English-French similarity detection at chunk level (88.5% at sentence level) on a very challenging corpus.", "creator": "TeX"}}}