{"id": "1702.03724", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Feb-2017", "title": "On Seeking Consensus Between Document Similarity Measures", "abstract": "This paper investigates the application of consensus clustering and meta-clustering to the set of all possible partitions of a data set. We show that when using a \"complement\" of Rand Index as a measure of cluster similarity, the total-separation partition, putting each element in a separate set, is chosen.", "histories": [["v1", "Mon, 13 Feb 2017 11:46:04 GMT  (58kb,D)", "http://arxiv.org/abs/1702.03724v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["mieczys{\\l}aw k{\\l}opotek"], "accepted": false, "id": "1702.03724"}, "pdf": {"name": "1702.03724.pdf", "metadata": {"source": "CRF", "title": "On Seeking Consensus Between Document Similarity Measures", "authors": [], "emails": ["klopotek@ipipan.waw.pl"], "sections": [{"heading": null, "text": "Index terms - cluster analysis, partitioning, clustering, consensus functions, totality, reuse of knowledge, unattended learning, meta-clustering"}, {"heading": "1 Introduction", "text": "Consensus clustering and meta-clustering are two well-known techniques that help select the best one among the competing partitions. It is also known that by changing the geometry of the data space, we can even obtain all the possible partitions of the data set. In this essay, we examine which partition would be selected if we applied consensus clustering or meta-clustering to the totality of all possible partitions. Specifically, we formulate (in Section 3) and prove (in Section 4) that, using the so-called Rand index as a measure of partition similarity by means of consensus clustering, we declare the partition to be a \"consensus metric\" between these partitions by classifying each element into a separate group (which we will then designate as a total partition)."}, {"heading": "2 Previous work", "text": "It is indeed the case that most of us are able to outdo ourselves. (...) It is not as if they are able to outdo themselves. \"(...) It is not as if they are able to outdo themselves.\" (...) It is as if they are able to outdo themselves. \"(...) It is as if they are able to outdo themselves.\" (...) It is as if they are able to outdo themselves. \"(...) It is as if they are able to outdo themselves.\""}, {"heading": "3 Theorem on consensus clustering", "text": "It is well known that if we handle all possible geometries of the dataset, we can get all possible partitions of the dataset. Which one should we choose? Under these circumstances, as we will show, consensus clustering is not useful for the selection process of the partition closest to all the others, because the closest partition is a partition that places each element (object, document) in a separate cluster. Specifically, we will prove the following theorem 1. For all n objects, among all partitions, the partition where each object falls into a separate cluster (hereinafter called total partition) must have the least average distance to the other partitions in terms of cluster difference CD.Since we are looking at a fixed n, we will focus on the non-normalized version unCD. First, let us consider one of the most serious implications of this theorem: We are looking at a world of all possible partitions, so that one might think that this world is perfectly symmetrical, and each partition may not have a similar function in each case, but that some of the other elements may have a similar function."}, {"heading": "4 The proof", "text": "It is assumed that all elements (objects, documents) of a group to be divided have identifiers starting with 1. Proof is performed by induction in a cyclical manner, combined with a narrowing of the group of candidates for the nearest element. The first step to verify the validity of the theorem (subsection 4.1) for small n = 2, 3 is trivial but still necessary. Subsequent subsections try the4It can be said that we use Rand Index rather than internal and non-external quality measurement. Induction step by demonstrating a special role of the so-called simple extension of a partition (which is to be introduced in subsection 4.2, along with the concept of reduction).The important feature here is that the complete separation of n + 1 elements is a simple extension of n elements. In addition, as shown in subsection 4.3, differences between the partitions of n elements are."}, {"heading": "4.1 Cases n = 2, 3", "text": "Consider the unnormalized version of the cluster difference. If n = 2, then there are only two partitions: 1; 2 = {1}, {2} and 2 = {1, 2} The unCD (as well as the CD) between them equals 1. So the average is identical and minimal. With n = 3 we get partitions \u2022 1; 3 = {1}, {2}, {3} (average unCD distance to other partitions 1.5, (normalized CD 0.5), \u2022 2; 3 = {1, 3}, {2} (average unCD distance to other partitions 1.75) \u2022 3 = {1, 3} (average unCD distance to other partitions 1.75) \u2022 3 = {2, 3} (average unCD distance to other partitions 1.75) \u2022 4; 3 = {1, 2} (average unCD distance to other partitions 1.75) \u2022 5; 3 = {1, 3} (average unCD distance to other partitions 1.75)."}, {"heading": "4.2 Case n\u2192 n + 1 - reducts and extensions", "text": "Now consider what happens when we have calculated the unnormalized cluster difference between partitions for n elements and want to calculate it for n + 1 elements. Each partition of n + 1 elements has a unique partition with n elements (called its reduction), from which it can be derived by adding the (n + 1) st element to an existing cluster or by forming a new one. On the other hand, if a partition of n + 1 elements is called an extension of [n + 1], then it becomes a simple extension of [n] and a reduction of [n] formal.Definition 1. Let it be a partition of n elements. \u2022 If it is a partition of n + 1 elements, so that it is an extension of [n + 1], then it is called a simple extension of [n]."}, {"heading": "4.3 Distances between partitions and their reducts", "text": "So consider partitions 1, 2 of n + 1 elements as extensions of two partitions 1, 2 of n elements, or the fact that both partitions are defined by the sentence {1,..., n}. Note that the unnormalized cluster difference unCD (1, 2; n + 1) = n [i = 1 n + 1 x j = i + 1 Iij (4) = n [j] = i + 1 Iij + n [i] = 1 Ii, n + 1 [n] = 1 n [j] = i + 1 Iij + n] = 1 Ii, n [n] = 1 Ii, n [n] = 1 Ii, n [n]."}, {"heading": "4.4 Centricity of a simple extension among all extensions", "text": "In this evidence, extensions of a partition play a very special role, since they are units for which properties of cumulative distances can be derived in a closed form. In particular, in this subsection we show that among the extensions of a partition, the simple extension comes closest to the other extensions, but we believe that by separating these cases the derivatives are easier to understand. Now, let us consider all extensions with n + 1 elements of a partition. Let us consider k-Cluster S1,..., Sk. 0 to be the simple extension and a complex extension containing the clusters Sl + 1. Let us now consider all extensions with n + 1 elements of a partition."}, {"heading": "4.5 Distance from a simple and a complex extension", "text": "Let us now calculate a simple extension (0) and a complex extension (0) (7) Let us calculate the complex extension (1) (1). (1) Let us calculate the complex extension (1). (1) Let us calculate the sum of the distances of the simple extension (0) (0) for all extensions of the CD (1). (k) l = 0 unCD (0, x) l = k) l = 0 (unCD, x) l = 0 (unCD) l = 0 (unCD, x) l = 0 (unCD, x) l = 0 (unCD, x) l = 0 (unCD, x). (n) + card (n) (S) l = n + k) l = n (k)."}, {"heading": "4.6 The partition closest to all the others", "text": "Thus, we can summarize sections 4.4 and 4.5 as follows: Lemma 1. A partition of n + 1 elements that are (on average) closest to all other partitions is among the simple extensions of all partitions of n elements. We can strengthen Lemma 1 by saying: Lemma 2. If, among the extensions of the partitions of n elements in the partition {} {1} {2}, we consider a partition of n + 1 elements that is (on average) closest to all other partitions of n + 1 elements, then such a partition is ready to prove by simple extensions of n elements that the total partition partition partition is on average closest to all partitions. Our working hypothesis is as follows: For all i = 0,... n, to find the solution to the problem of the partition of n + 1 elements, we are ready to prove by induction that the total partition of n elements is closest to the average of all partitions."}, {"heading": "5 Practical implications", "text": "This year, it will only take one year for an agreement to be reached."}, {"heading": "6 Imposing a limit on the number of clusters to", "text": "The question is: Would a restriction on the number of clusters k < kmax change in relation to the previous results? Note that for a partition consisting of K-sets, K-sets are also included, but the simple extension contains k + 1 sets. Therefore, there is nothing to change in the discussion of sections 4.4 and 4.5. But for k = kmax we need to update equations (6), (7) and (8) because we will no longer consider the simple extensions. So the equation (6) needs to be replaced."}, {"heading": "7 Remarks on meta-clustering", "text": "The formulas derived in the preceding sections are also a light on possible results of meta-clustering. It is obvious that the assumption of a sufficiently \"large\" number of clusters, the simple expansions will be cluster centers and clusters that will consist of expansions of the same kind. If it is a simple expansion, then it is the first simple expansion, then it is the first simple expansion, then it is the first simple expansion, then it is the first simple expansion, then it is the first simple expansion, then it is the first simple expansion. If it is a p-te expansion, which is a p-te expansion of the p-ten, and the second expansion of the p-ten, and the second expansion of the expansion is a reduction of the first class, then it is the first expansion of the first order."}, {"heading": "8 Conclusions and future work", "text": "As the number of available cluster algorithms applicable to the same data increases and potential outcomes can vary significantly, methods are currently being developed to reconcile them, such as meta-clustering or consensus clustering. In this paper, we have shown that both consensus clustering and meta-clustering, using cluster difference (derived from Rand Index) as a measure of the distance between partitions when applied to the universe of all possible partitions, point to the partition that contains each element in a separate set as the best compromise, suggesting that the user performing the task of clustering must have at least an approximate idea of the geometry of the data space. Only in this case can the techniques mentioned be helpful in choosing a suitable compromise cluster."}, {"heading": "Acknowledgements", "text": "The author thanks the Institute of Computer Science of the Polish Academy of Sciences for the promotion and funding of this research."}], "references": [{"title": "Cluster Analysis for Applications", "author": ["M. Anderberg"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1973}, {"title": "The median procedure for partition, Partitioning Data Sets (I", "author": ["Barthelemy", "J.-P", "B. Leclerc"], "venue": "C. et al, Ed.), AMS DIMACS Series in Discrete Mathematics,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1995}, {"title": "Multiple data structure discovery through global optimisation, meta clustering and consensus methods, International", "author": ["I. Bifulco", "C. Fedullo", "F. Napolitano", "G. Raiconi", "R. Tagliaferri"], "venue": "Journal of Knowledge Engineering and Soft Data Paradigms,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2009}, {"title": "Interactive Visualization Tools for Meta-Clustering", "author": ["I. Bifulco", "F. Iorio", "F. Napolitano", "G. Raiconi", "R. Tagliaferri"], "venue": "Proceedings of the 2009 conference on New Directions in Neural Networks: 18th Italian Workshop on Neural Networks: WIRN", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2008}, {"title": "Learning multiple nonredundant clusterings", "author": ["Y. Cui", "X.Z. Fern", "J.G. Dy"], "venue": "ACM Transactions on Knowledge Discovery from Data (TKDD),", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2010}, {"title": "Which clustering do you want? inducing your ideal clustering with minimal feedback", "author": ["S. Dasgupta", "V. Ng"], "venue": "J. Artif. Int. Res.,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2010}, {"title": "Cluster ensembles, Wiley Interdisc", "author": ["J. Ghosh", "A. Acharya"], "venue": "Rew.: Data Mining and Knowledge Discovery,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2011}, {"title": "Clustering Aggregation", "author": ["A. Gionis", "H. Mannila", "P. Tsaparas"], "venue": "ACM Trans. Knowl. Discov. Data,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2007}, {"title": "Consensus Clustering Algorithms: Comparison and Refinement, Proceedings of the Workshop on Algorithm Engineering and Experiments", "author": ["A. Goder", "V. Filkov"], "venue": "ALENEX", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2008}, {"title": "Consensus Clustering Algorithms: Comparison and Refinement", "author": ["A. Goder", "V. Filkov"], "venue": "Alenex,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2008}, {"title": "Partitions of partitions", "author": ["A. Gordon", "M. Vichi"], "venue": "Journal of Classification,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1998}, {"title": "A scalable framework for cluster ensembles", "author": ["P. Hore", "L.O. Hall", "D.B. Goldgof"], "venue": "Pattern Recogn.,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2009}, {"title": "Weighted consensus clustering", "author": ["T. Li", "C. Ding"], "venue": "Proceedings of 2008 SIAM International Conference on Data Mining (SDM 2008), Atlanta, April", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2008}, {"title": "Consensus Clustering: A Resampling-Based Method for Class Discovery and Visualization of Gene Expression Microarray", "author": ["S. Monti", "P. Tamayo", "J. Mesirov", "T. Golub"], "venue": "Data, Mach. Learn.,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2003}, {"title": "Comparing Approaches for Clustering Mixed Mode Data: An Application in Marketing Research, Data Analysis and Classification", "author": ["I. Morlini", "S. Zani"], "venue": "Proceedings of the 6th Conference (F. Palumbo,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2010}, {"title": "Consensus Clusterings", "author": ["N. Nguyen", "R. Caruana"], "venue": "Proceedings of the 7th IEEE International Conference on Data Mining (ICDM", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2007}, {"title": "Multiple Non-Redundant Spectral Clustering Views", "author": ["D. Niu", "J.G. Dy", "M.I. Jordan"], "venue": null, "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2010}, {"title": "Consensus Based Ensembles of Soft Clusterings", "author": ["K. Punera", "J. Ghosh"], "venue": "Applied Artificial Intelligence: An International Journal,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2008}, {"title": "Standardized Mutual Information for Clustering Comparisons: One Step Further in Adjustment for Chance", "author": ["Simone Romano", "James Bailey", "V.N.K. V"], "venue": "Proceedings of The 31st International Conference on Machine Learning,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2014}, {"title": "Cluster ensembles \u2014 a knowledge reuse framework for combining multiple partitions", "author": ["A. Strehl", "J. Ghosh"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2003}, {"title": "Clustering ensembles: Models of consensus and weak partitions", "author": ["A. Topchy", "A.K. Jain", "W. Punch"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2005}, {"title": "Semi-Supervised Consensus Clustering: Reducing Human Effort", "author": ["T. Vogel", "F. Naumann"], "venue": "Proceedings of the International Workshop on Data Integration and Applications,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2014}, {"title": "Bayesian cluster ensembles", "author": ["H. Wang", "H. Shan", "A. Banerjee"], "venue": "Statistical Analysis and Data Mining,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2011}, {"title": "Semi-Supervised Consensus Clustering for Gene Expression Data Analysis", "author": ["Y. Wang", "Y. Pan"], "venue": "BioData Mining,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2014}], "referenceMentions": [{"referenceID": 22, "context": "\u2022 the consensus clustering (called also in various brands ensemble clustering [27] or cluster aggregation [10])", "startOffset": 78, "endOffset": 82}, {"referenceID": 7, "context": "\u2022 the consensus clustering (called also in various brands ensemble clustering [27] or cluster aggregation [10])", "startOffset": 106, "endOffset": 110}, {"referenceID": 16, "context": "To facilitate user selection of the right clustering, [5] (also compare [21, 4, 3, 7, 6]) suggests to provide the user with meta-clusters (clusters of partitions) in order that the user better understands the choices.", "startOffset": 72, "endOffset": 88}, {"referenceID": 3, "context": "To facilitate user selection of the right clustering, [5] (also compare [21, 4, 3, 7, 6]) suggests to provide the user with meta-clusters (clusters of partitions) in order that the user better understands the choices.", "startOffset": 72, "endOffset": 88}, {"referenceID": 2, "context": "To facilitate user selection of the right clustering, [5] (also compare [21, 4, 3, 7, 6]) suggests to provide the user with meta-clusters (clusters of partitions) in order that the user better understands the choices.", "startOffset": 72, "endOffset": 88}, {"referenceID": 5, "context": "To facilitate user selection of the right clustering, [5] (also compare [21, 4, 3, 7, 6]) suggests to provide the user with meta-clusters (clusters of partitions) in order that the user better understands the choices.", "startOffset": 72, "endOffset": 88}, {"referenceID": 4, "context": "To facilitate user selection of the right clustering, [5] (also compare [21, 4, 3, 7, 6]) suggests to provide the user with meta-clusters (clusters of partitions) in order that the user better understands the choices.", "startOffset": 72, "endOffset": 88}, {"referenceID": 19, "context": "In consensus clustering [24] a kind of optimisation problem (combinatorial optimisation) is formulated and solved.", "startOffset": 24, "endOffset": 28}, {"referenceID": 8, "context": "A number of other techniques in this direction was reviewed in [11, 14, 9, 16, 22, 18, 25, 20, 28, 26].", "startOffset": 63, "endOffset": 102}, {"referenceID": 11, "context": "A number of other techniques in this direction was reviewed in [11, 14, 9, 16, 22, 18, 25, 20, 28, 26].", "startOffset": 63, "endOffset": 102}, {"referenceID": 6, "context": "A number of other techniques in this direction was reviewed in [11, 14, 9, 16, 22, 18, 25, 20, 28, 26].", "startOffset": 63, "endOffset": 102}, {"referenceID": 12, "context": "A number of other techniques in this direction was reviewed in [11, 14, 9, 16, 22, 18, 25, 20, 28, 26].", "startOffset": 63, "endOffset": 102}, {"referenceID": 17, "context": "A number of other techniques in this direction was reviewed in [11, 14, 9, 16, 22, 18, 25, 20, 28, 26].", "startOffset": 63, "endOffset": 102}, {"referenceID": 13, "context": "A number of other techniques in this direction was reviewed in [11, 14, 9, 16, 22, 18, 25, 20, 28, 26].", "startOffset": 63, "endOffset": 102}, {"referenceID": 20, "context": "A number of other techniques in this direction was reviewed in [11, 14, 9, 16, 22, 18, 25, 20, 28, 26].", "startOffset": 63, "endOffset": 102}, {"referenceID": 15, "context": "A number of other techniques in this direction was reviewed in [11, 14, 9, 16, 22, 18, 25, 20, 28, 26].", "startOffset": 63, "endOffset": 102}, {"referenceID": 23, "context": "A number of other techniques in this direction was reviewed in [11, 14, 9, 16, 22, 18, 25, 20, 28, 26].", "startOffset": 63, "endOffset": 102}, {"referenceID": 21, "context": "A number of other techniques in this direction was reviewed in [11, 14, 9, 16, 22, 18, 25, 20, 28, 26].", "startOffset": 63, "endOffset": 102}, {"referenceID": 1, "context": "We are particularly interested in the one initiated by [2, 13], and further studied [12] and applied [19].", "startOffset": 55, "endOffset": 62}, {"referenceID": 10, "context": "We are particularly interested in the one initiated by [2, 13], and further studied [12] and applied [19].", "startOffset": 55, "endOffset": 62}, {"referenceID": 9, "context": "We are particularly interested in the one initiated by [2, 13], and further studied [12] and applied [19].", "startOffset": 84, "endOffset": 88}, {"referenceID": 14, "context": "We are particularly interested in the one initiated by [2, 13], and further studied [12] and applied [19].", "startOffset": 101, "endOffset": 105}, {"referenceID": 14, "context": "(again) as the averaged Rand Index [19].", "startOffset": 35, "endOffset": 39}, {"referenceID": 0, "context": "2 More precisely, [1] shows that this number amounts to", "startOffset": 18, "endOffset": 21}, {"referenceID": 18, "context": "[23].", "startOffset": 0, "endOffset": 4}], "year": 2017, "abstractText": "This paper investigates the application of consensus clustering and meta-clustering to the set of all possible partitions of a data set. We show that when using a \u201dcomplement\u201d of Rand Index as a measure of cluster similarity, the total-separation partition, putting each element in a separate set, is chosen.", "creator": "LaTeX with hyperref package"}}}