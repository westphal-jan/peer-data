{"id": "1702.03791", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Feb-2017", "title": "DNN Filter Bank Cepstral Coefficients for Spoofing Detection", "abstract": "With the development of speech synthesis techniques, automatic speaker verification systems face the serious challenge of spoofing attack. In order to improve the reliability of speaker verification systems, we develop a new filter bank based cepstral feature, deep neural network filter bank cepstral coefficients (DNN-FBCC), to distinguish between natural and spoofed speech. The deep neural network filter bank is automatically generated by training a filter bank neural network (FBNN) using natural and synthetic speech. By adding restrictions on the training rules, the learned weight matrix of FBNN is band-limited and sorted by frequency, similar to the normal filter bank. Unlike the manually designed filter bank, the learned filter bank has different filter shapes in different channels, which can capture the differences between natural and synthetic speech more effectively. The experimental results on the ASVspoof {2015} database show that the Gaussian mixture model maximum-likelihood (GMM-ML) classifier trained by the new feature performs better than the state-of-the-art linear frequency cepstral coefficients (LFCC) based classifier, especially on detecting unknown attacks.", "histories": [["v1", "Mon, 13 Feb 2017 14:44:17 GMT  (2659kb,D)", "http://arxiv.org/abs/1702.03791v1", null]], "reviews": [], "SUBJECTS": "cs.SD cs.CR cs.LG", "authors": ["hong yu", "zheng-hua tan", "zhanyu ma", "jun guo"], "accepted": false, "id": "1702.03791"}, "pdf": {"name": "1702.03791.pdf", "metadata": {"source": "CRF", "title": "DNN Filter Bank Cepstral Coefficients for Spoofing Detection", "authors": ["Hong Yu", "Zheng-Hua Tan", "Zhanyu Ma", "Jun Guo"], "emails": [], "sections": [{"heading": null, "text": "In fact, it is a matter of a way in which people are able to determine themselves how they have behaved. (...) It is not as if people are able to behave. (...) It is as if people are able to behave. (...) \"It is as if people are able to behave.\" (...) \"It is as if people are able to behave themselves.\" (...) \"It is as if people are able to survive themselves.\" (...) \"It is as if people are able to survive themselves.\" (...) \"It is as if they are able to survive themselves.\" (...), (...)) It is as if they have survived themselves. (...) It is as if they have survived themselves. (...) It is as if they have survived themselves. (...)"}, {"heading": "II. FILTER BANK NEURAL NETWORKS", "text": "As a hot area of research, in which deep neural networks are used in many areas of language processing, such as language recognition (25), in which it is a question (26), how it is a question (26), how it is a question, how far it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question,"}, {"heading": "III. EXPERIMENTAL RESULTS AND DISCUSSIONS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Database and Data Preparation", "text": "The performance of spoofing detection using the DNN-FBCC feature is evaluated on the ASVspoof 2015 database [17]. As shown in TABLE I, the database contains three partial sets of data without overlapping with target speakers: the training set, the development set and the assessment set. We used the training set for FBNN and the human-parody classification training. The development set and the assessment set were used for testing purposes. Training set and development set are attacked by the same five spoofing methods, with S1, S2 and S5 being part of the VC method and S3, S4 part of the SS methodology. Regarding the assessment set, in addition to the five known spoofing methods, there are another five unknown methods where S6-S9 are VC methods and S10 is an SS methodology. The speech signals were segmented into frames with 20 ms length and 10 ms increment. Prior to the detection, an emphasis window and a gathering window were applied to the frames before the detection."}, {"heading": "B. FBNN Training", "text": "The ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the re"}, {"heading": "C. Classifier", "text": "In the development of the classifier, we form two separate GMMs with 512 mixtures in order to model natural or forged language. As an evaluation criterion, the log probability ratio is used, which is defined as follows: ML (X) = 1T T \u2211 i = 1 {logP (Xi | \u03bbhuman) \u2212 logP (Xi | \u03bbspoof)}, (8) where X stands for character vectors with T-frame, \u03bbhuman and \u03bbspoof are the GMM parameters of the human or false model, respectively."}, {"heading": "D. Results and Discussions", "text": "We compare the spoofing performance between four manually designed Cep features and four DNN-FBCC features. 6As in Table II, manually designed Cep features: LFCC, RFCC (Linear Frequency), GFCC (ERB Space Gammatone Filter Bank cepstral coefficient) and IGFCC (Inverted ERB Space Gammatone Filter Bank cepstral coefficient) are created by manually designed filter banks TFB, GFB and IGFB described in Section III-B. Four DNN-FBCC features, DNN-LFCC, DNN-GFCC and DNN-IGFCC are generated by learned filter banks DNN-TFB, DNN-RFB, DNN-GFB, DNN-GFB, DNN-GFB."}, {"heading": "IV. CONCLUSIONS", "text": "In this thesis, we presented a neural filter bank network with two hidden layers for spoofing detection. During the training, a non-negative, band-delimited and frequency-ordered constraint function and a band-delimiting mask matrix were applied to the weight matrix between the entry layer 7 and the first hidden layer. The weight matrix can be used as a filter bank for conception analysis. Experimental results show that the Cep traits produced by the learned filter banks were able to distinguish natural and synthetic language more precisely and robustly than the manually developed Cep traits and the general DNN traits."}], "references": [{"title": "Synthetic speech detection using temporal modulation feature", "author": ["Z. Wu", "X. Xiao", "E.S. Chng", "H. Li"], "venue": "Processing of IEEE International Conference on Acoustics, Speech and Signal (ICASSP), pp. 7234\u20137238, 2013.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2013}, {"title": "Conditional restricted boltzmann machine for voice conversion", "author": ["Z. Wu", "E.S. Chng", "H. Li"], "venue": "Processing of IEEE China Summit & International Conference on Signal and Information Processing (ChinaSIP), pp. 104\u2013108, 2013.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2013}, {"title": "Voice conversion using dynamic kernel partial least squares regression", "author": ["E. Helander", "H. Sil\u00e9n", "T. Virtanen", "M. Gabbouj"], "venue": "IEEE Transactions on Audio, Speech, and Language Processing, vol. 20, no. 3, pp. 806\u2013817, 2012.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "Unit selection in a concatenative speech synthesis system using a large speech database", "author": ["A.J. Hunt", "A.W. Black"], "venue": "Processing of IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), vol. 1, pp. 373\u2013376, 1996.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1996}, {"title": "Statistical parametric speech synthesis using deep neural networks", "author": ["H. Ze", "A. Senior", "M. Schuster"], "venue": "Processing of IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 7962\u20137966, 2013.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "Joint speaker verification and antispoofing in the-vector space", "author": ["A. Sizov", "E. Khoury", "T. Kinnunen", "Z. Wu", "S. Marcel"], "venue": "IEEE Transactions on Information Forensics and Security, vol. 10, no. 4, pp. 821\u2013832, 2015.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "Spoofing detection from a feature representation perspective", "author": ["X. Tian", "Z. Wu", "X. Xiao", "E.S. Chng", "H. Li"], "venue": "Processing of IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), 2016.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2016}, {"title": "Toward a universal synthetic speech spoofing detection using phase information", "author": ["J. Sanchez", "I. Saratxaga", "I. Hernaez", "E. Navas", "D. Erro", "T. Raitio"], "venue": "IEEE Transactions on Information Forensics and Security, vol. 10, no. 4, pp. 810\u2013820, 2015.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2015}, {"title": "Vulnerability of speaker verification systems against voice conversion spoofing attacks: The case of telephone speech", "author": ["T. Kinnunen", "Z.-Z. Wu", "K.A. Lee", "F. Sedlak", "E.S. Chng", "H. Li"], "venue": "Processing of IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 4401\u2013 4404, 2012.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2012}, {"title": "Evaluation of speaker verification security and detection of hmm-based synthetic speech", "author": ["P.L. De Leon", "M. Pucher", "J. Yamagishi", "I. Hernaez", "I. Saratxaga"], "venue": "IEEE Transactions on Audio, Speech, and Language Processing, vol. 20, no. 8, pp. 2280\u20132290, 2012.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}, {"title": "Vulnerability in speaker verification-a study of technical impostor techniques", "author": ["J. Lindberg", "M. Blomberg"], "venue": "Eurospeech, vol. 99, pp. 1211\u20131214, 1999.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1999}, {"title": "Integrated spoofing countermeasures and automatic speaker verification: an evaluation on asvspoof 2015", "author": ["M. Sahidullah", "H. Delgado", "M. Todisco", "H. Yu", "T. Kinnunen", "N. Evans", "Z.-H. Tan"], "venue": "INTERSPEECH, 2016.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2016}, {"title": "Detecting converted speech and natural speech for anti-spoofing attack in speaker recognition", "author": ["Z. Wu", "C.E. Siong", "H. Li"], "venue": "INTERSPEECH, pp. 1700\u20131703, 2012.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2012}, {"title": "Toward a universal synthetic speech spoofing detection using phase information", "author": ["J. Sanchez", "I. Saratxaga", "I. Hernaez", "E. Navas", "D. Erro", "T. Raitio"], "venue": "IEEE Transactions on Information Forensics and Security, vol. 10, no. 4, pp. 810\u2013820, 2015.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2015}, {"title": "Toward a universal synthetic speech spoofing detection using phase information", "author": ["J. Sanchez", "I. Saratxaga", "I. Hernez", "E. Navas", "D. Erro", "T. Raitio"], "venue": "IEEE Transactions on Information Forensics and Security, vol. 10, pp. 810\u2013820, April 2015.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2015}, {"title": "A comparison of features for synthetic speech detection", "author": ["M. Sahidullah", "T. Kinnunen", "C. Hanil\u00e7i"], "venue": "Sixteenth Annual Conference of the International Speech Communication Association, 2015.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2015}, {"title": "Asvspoof 2015: the first automatic speaker verification spoofing and countermeasures challenge", "author": ["Z. Wu", "T. Kinnunen", "N. Evans", "J. Yamagishi", "C. Hanil\u00e7i", "M. Sahidullah", "A. Sizov"], "venue": "Training, vol. 10, no. 15, p. 3750, 2015.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2015}, {"title": "Spoofing speech detection using high dimensional magnitude and phase features: The ntu approach for asvspoof 2015 challenge", "author": ["X. Xiao", "X. Tian", "S. Du", "H. Xu", "E.S. Chng", "H. Li"], "venue": "Sixteenth Annual Conference of the International Speech Communication Association, 2015.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2015}, {"title": "Spoofing detection with dnn and one-class svm for the asvspoof 2015 challenge", "author": ["J. Villalba", "A. Miguel", "A. Ortega", "E. Lleida"], "venue": "Sixteenth Annual Conference of the International Speech Communication Association, 2015.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2015}, {"title": "Robust deep feature for spoofing detection-the sjtu system for asvspoof 2015 challenge", "author": ["N. Chen", "Y. Qian", "H. Dinkel", "B. Chen", "K. Yu"], "venue": "Sixteenth Annual Conference of the International Speech Communication Association, 2015.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2015}, {"title": "Improved bottleneck features using pretrained deep neural networks", "author": ["D. Yu", "M.L. Seltzer"], "venue": "Processing of IEEE International Conference on INTERSPEECH, vol. 237, p. 240, 2011.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2011}, {"title": "Auto-encoder bottleneck features using deep belief networks", "author": ["T.N. Sainath", "B. Kingsbury", "B. Ramabhadran"], "venue": "Processing of IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 4153\u20134156, 2012.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2012}, {"title": "Data driven design of filter bank for speech recognition", "author": ["L. Burget", "H. He\u0159mansk\u1ef3"], "venue": "International Conference on Text, Speech and Dialogue, pp. 299\u2013304, Springer, 2001.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2001}, {"title": "Learning filter banks within a deep neural network framework", "author": ["T.N. Sainath", "B. Kingsbury", "A.-r. Mohamed", "B. Ramabhadran"], "venue": "Automatic Speech Recognition and Understanding (ASRU), 2013 IEEE Workshop on, pp. 297\u2013302, IEEE, 2013.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2013}, {"title": "Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups", "author": ["G. Hinton", "L. Deng", "D. Yu", "G.E. Dahl", "A.-r. Mohamed", "N. Jaitly", "A. Senior", "V. Vanhoucke", "P. Nguyen", "T.N. Sainath"], "venue": "IEEE Transactions on Signal Processing Magazine, vol. 29, no. 6, pp. 82\u201397, 2012.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2012}, {"title": "Context-dependent pre-trained deep neural networks for large-vocabulary speech recognition", "author": ["G.E. Dahl", "D. Yu", "L. Deng", "A. Acero"], "venue": "IEEE Transactions on Audio, Speech, and Language Processing, vol. 20, no. 1, pp. 30\u201342, 2012.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2012}, {"title": "Deep neural networks for small footprint text-dependent speaker verification", "author": ["E. Variani", "X. Lei", "E. McDermott", "I. Lopez Moreno", "J. Gonzalez-Dominguez"], "venue": "Processing of IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 4052\u20134056, 2014.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2014}, {"title": "Unsupervised feature learning for audio classification using convolutional deep belief networks", "author": ["H. Lee", "P. Pham", "Y. Largman", "A.Y. Ng"], "venue": "Advances in neural information processing systems, pp. 1096\u20131104, 2009.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2009}, {"title": "An experimental study on speech enhancement based on deep neural networks", "author": ["Y. Xu", "J. Du", "L.-R. Dai", "C.-H. Lee"], "venue": "IEEE Transactions on Signal Processing Letters, vol. 21, no. 1, pp. 65\u201368, 2014.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2014}, {"title": "Neural network-based adaptive noise cancellation for enhancement of speech auditory brainstem responses", "author": ["S. Gholami-Boroujeny", "A. Fallatah", "B.P. Heffernan", "H.R. Dajani"], "venue": "Signal, Image and Video Processing, vol. 10, no. 2, pp. 389\u2013395, 2016.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2016}, {"title": "Learning representations by back-propagating errors", "author": ["D.E. Rumelhart", "G.E. Hinton", "R.J. Williams"], "venue": "Cognitive modeling, vol. 5, no. 3, p. 1, 1988.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 1988}, {"title": "An introduction to computational networks and the computational network toolkit", "author": ["D. Yu", "A. Eversole", "M. Seltzer", "K. Yao", "Z. Huang", "B. Guenter", "O. Kuchaiev", "Y. Zhang", "F. Seide", "H. Wang"], "venue": "tech. rep., Tech. Rep. MSR, Microsoft Research, 2014, http://codebox/cntk, 2014.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2014}, {"title": "Effect of multi-condition training and speech enhancement methods on spoofing detection", "author": ["H. Yu", "A. Sarkar", "D.A.L. Thomsen", "Z.-H. Tan", "Z. Ma", "J. Guo"], "venue": "2016 First International Workshop on Sensing, Processing and Learning for Intelligent Machines (SPLINE), pp. 1\u20135, IEEE, 2016. 8", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2016}, {"title": "Gammatone wavelet cepstral coefficients for robust speech recognition", "author": ["A. Adiga", "M. Magimai", "C.S. Seelamantula"], "venue": "TENCON 2013-2013 IEEE Region 10 Conference (31194), pp. 1\u20134, 2013.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2013}, {"title": "Gammatone cepstral coefficients: biologically inspired features for non-speech audio classification", "author": ["X. Valero", "F. Alias"], "venue": "IEEE Transactions on Multimedia, vol. 14, no. 6, pp. 1684\u20131689, 2012.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2012}], "referenceMentions": [{"referenceID": 0, "context": "INTRODUCTION AS a low-cost and flexible biometric solution to person authentication, automatic speaker verification (ASV) has been used in many telephone or network access control systems, such as telephone banking [1].", "startOffset": 215, "endOffset": 218}, {"referenceID": 1, "context": "Recently, with the improvement of automatic speech generation methods, speech produced by voice conversion (VC) [2][3] and speech synthesis (SS) [4][5] techniques has been used to attack ASV systems.", "startOffset": 112, "endOffset": 115}, {"referenceID": 2, "context": "Recently, with the improvement of automatic speech generation methods, speech produced by voice conversion (VC) [2][3] and speech synthesis (SS) [4][5] techniques has been used to attack ASV systems.", "startOffset": 115, "endOffset": 118}, {"referenceID": 3, "context": "Recently, with the improvement of automatic speech generation methods, speech produced by voice conversion (VC) [2][3] and speech synthesis (SS) [4][5] techniques has been used to attack ASV systems.", "startOffset": 145, "endOffset": 148}, {"referenceID": 4, "context": "Recently, with the improvement of automatic speech generation methods, speech produced by voice conversion (VC) [2][3] and speech synthesis (SS) [4][5] techniques has been used to attack ASV systems.", "startOffset": 148, "endOffset": 151}, {"referenceID": 5, "context": "Over the past few years, much research has been devoted to protect ASV systems against spoofing attack [6][7][8].", "startOffset": 103, "endOffset": 106}, {"referenceID": 6, "context": "Over the past few years, much research has been devoted to protect ASV systems against spoofing attack [6][7][8].", "startOffset": 106, "endOffset": 109}, {"referenceID": 7, "context": "Over the past few years, much research has been devoted to protect ASV systems against spoofing attack [6][7][8].", "startOffset": 109, "endOffset": 112}, {"referenceID": 8, "context": "Unfortunately, research has shown that all the existing ASV systems are vulnerable to spoofing attacks [9][10][11].", "startOffset": 103, "endOffset": 106}, {"referenceID": 9, "context": "Unfortunately, research has shown that all the existing ASV systems are vulnerable to spoofing attacks [9][10][11].", "startOffset": 106, "endOffset": 110}, {"referenceID": 10, "context": "Unfortunately, research has shown that all the existing ASV systems are vulnerable to spoofing attacks [9][10][11].", "startOffset": 110, "endOffset": 114}, {"referenceID": 11, "context": "The other more popular strategy is to build a separated spoofing detection system which only focuses on distinguishing between natural and synthetic speech [12].", "startOffset": 156, "endOffset": 160}, {"referenceID": 5, "context": "Because of the advantage of being easily incorporated into existing ASV systems, spoofing detection has become an important research topic in anti-spoofing [6][10][13][14].", "startOffset": 156, "endOffset": 159}, {"referenceID": 9, "context": "Because of the advantage of being easily incorporated into existing ASV systems, spoofing detection has become an important research topic in anti-spoofing [6][10][13][14].", "startOffset": 159, "endOffset": 163}, {"referenceID": 12, "context": "Because of the advantage of being easily incorporated into existing ASV systems, spoofing detection has become an important research topic in anti-spoofing [6][10][13][14].", "startOffset": 163, "endOffset": 167}, {"referenceID": 13, "context": "Because of the advantage of being easily incorporated into existing ASV systems, spoofing detection has become an important research topic in anti-spoofing [6][10][13][14].", "startOffset": 167, "endOffset": 171}, {"referenceID": 14, "context": "In [15], relative phase shift (RPS) and Mel-frequency cepstral coefficients (MFCC) were used to detect SS attacks.", "startOffset": 3, "endOffset": 7}, {"referenceID": 0, "context": "A fusion system combining MFCC and group delay cepstral coefficients (GDCC) was applied to resist VC spoofing in [1].", "startOffset": 113, "endOffset": 116}, {"referenceID": 15, "context": "Paper [16] compared the spoofing detection performance of 11 different features on the ASVspoof 2015 database [17].", "startOffset": 6, "endOffset": 10}, {"referenceID": 16, "context": "Paper [16] compared the spoofing detection performance of 11 different features on the ASVspoof 2015 database [17].", "startOffset": 110, "endOffset": 114}, {"referenceID": 17, "context": "In [18][19][20], spoofing detection systems based on deep neural networks (DNNs) were proposed and tested, where a DNN was used as a classifier or feature extractor.", "startOffset": 3, "endOffset": 7}, {"referenceID": 18, "context": "In [18][19][20], spoofing detection systems based on deep neural networks (DNNs) were proposed and tested, where a DNN was used as a classifier or feature extractor.", "startOffset": 7, "endOffset": 11}, {"referenceID": 19, "context": "In [18][19][20], spoofing detection systems based on deep neural networks (DNNs) were proposed and tested, where a DNN was used as a classifier or feature extractor.", "startOffset": 11, "endOffset": 15}, {"referenceID": 18, "context": ", Gaussian mixture model (GMM) or support vector machine (SVM) [19][21][22].", "startOffset": 63, "endOffset": 67}, {"referenceID": 20, "context": ", Gaussian mixture model (GMM) or support vector machine (SVM) [19][21][22].", "startOffset": 67, "endOffset": 71}, {"referenceID": 21, "context": ", Gaussian mixture model (GMM) or support vector machine (SVM) [19][21][22].", "startOffset": 71, "endOffset": 75}, {"referenceID": 22, "context": "Some filter bank learning methods such as LDA (Linear discriminant analysis) filter learning [23] and log Mel-scale filters learning [24] have been introduced in the literatures.", "startOffset": 93, "endOffset": 97}, {"referenceID": 23, "context": "Some filter bank learning methods such as LDA (Linear discriminant analysis) filter learning [23] and log Mel-scale filters learning [24] have been introduced in the literatures.", "startOffset": 133, "endOffset": 137}, {"referenceID": 16, "context": "Experimental results show that the GMM-ML classifier based on DNN-FBCC feature outperforms the LFCC feature and DNN feature on the ASVspoof 2015 data base [17].", "startOffset": 155, "endOffset": 159}, {"referenceID": 24, "context": "FILTER BANK NEURAL NETWORKS As a hot research area, deep neural networks have been successfully used in many speech processing tasks such as speech recognition [25][26], speaker verification [27][28] and speech enhancement [29][30].", "startOffset": 160, "endOffset": 164}, {"referenceID": 25, "context": "FILTER BANK NEURAL NETWORKS As a hot research area, deep neural networks have been successfully used in many speech processing tasks such as speech recognition [25][26], speaker verification [27][28] and speech enhancement [29][30].", "startOffset": 164, "endOffset": 168}, {"referenceID": 26, "context": "FILTER BANK NEURAL NETWORKS As a hot research area, deep neural networks have been successfully used in many speech processing tasks such as speech recognition [25][26], speaker verification [27][28] and speech enhancement [29][30].", "startOffset": 191, "endOffset": 195}, {"referenceID": 27, "context": "FILTER BANK NEURAL NETWORKS As a hot research area, deep neural networks have been successfully used in many speech processing tasks such as speech recognition [25][26], speaker verification [27][28] and speech enhancement [29][30].", "startOffset": 195, "endOffset": 199}, {"referenceID": 28, "context": "FILTER BANK NEURAL NETWORKS As a hot research area, deep neural networks have been successfully used in many speech processing tasks such as speech recognition [25][26], speaker verification [27][28] and speech enhancement [29][30].", "startOffset": 223, "endOffset": 227}, {"referenceID": 29, "context": "FILTER BANK NEURAL NETWORKS As a hot research area, deep neural networks have been successfully used in many speech processing tasks such as speech recognition [25][26], speaker verification [27][28] and speech enhancement [29][30].", "startOffset": 227, "endOffset": 231}, {"referenceID": 30, "context": "L is the cost function and \u2202L \u2202H1c can be computed by the standard back propagation equations for neural networks [31].", "startOffset": 114, "endOffset": 118}, {"referenceID": 16, "context": "Database and Data Preparation The performance of spoofing detection using the DNN-FBCC feature is evaluated on the ASVspoof 2015 database [17].", "startOffset": 138, "endOffset": 142}, {"referenceID": 15, "context": "Paper [16] showed that all the frames of speech are useful for spoofing detection, so we did not apply any voice activity detection method.", "startOffset": 6, "endOffset": 10}, {"referenceID": 31, "context": "FBNN Training The FBNN described in Section II was built and trained with computational network toolkit (CNTK) [32].", "startOffset": 111, "endOffset": 115}, {"referenceID": 32, "context": "Some experimental results published in paper [33] and [16], show that the high frequency spectrum of speech is more effective for synthetic detection.", "startOffset": 45, "endOffset": 49}, {"referenceID": 15, "context": "Some experimental results published in paper [33] and [16], show that the high frequency spectrum of speech is more effective for synthetic detection.", "startOffset": 54, "endOffset": 58}, {"referenceID": 33, "context": "In order to investigate the affect of different band-limiting and shape restrictions to the learned filter banks, we use four different manually designed filter banks to generate Mbl: the linear frequency triangular filter bank (TFB) with 20 channels, the linear frequency rectangular filter bank (RFB) with 20 channels, the equivalent rectangular bandwidth (ERB) space Gammatone filter bank (GFB) with 128 channels, and the inverted ERB space Gammatone filter bank (IGFB) with 128 channels, according to the recommended in paper [34] [16].", "startOffset": 530, "endOffset": 534}, {"referenceID": 15, "context": "In order to investigate the affect of different band-limiting and shape restrictions to the learned filter banks, we use four different manually designed filter banks to generate Mbl: the linear frequency triangular filter bank (TFB) with 20 channels, the linear frequency rectangular filter bank (RFB) with 20 channels, the equivalent rectangular bandwidth (ERB) space Gammatone filter bank (GFB) with 128 channels, and the inverted ERB space Gammatone filter bank (IGFB) with 128 channels, according to the recommended in paper [34] [16].", "startOffset": 535, "endOffset": 539}, {"referenceID": 33, "context": "GFB which has been successfully used in audio recognition [34][35], has denser spacing in the low-frequency region (Fig.", "startOffset": 58, "endOffset": 62}, {"referenceID": 34, "context": "GFB which has been successfully used in audio recognition [34][35], has denser spacing in the low-frequency region (Fig.", "startOffset": 62, "endOffset": 66}, {"referenceID": 15, "context": "Inspired by the work in [16], we use \u2206 and \u2206 (first- and second-order frame-to-frame difference) coefficients to train the GMM-ML classifier.", "startOffset": 24, "endOffset": 28}, {"referenceID": 32, "context": "This is inline with the finding in paper [33].", "startOffset": 41, "endOffset": 45}, {"referenceID": 22, "context": "We also compare the DNN-FBCC feature with other three data driven features which have been successfully used in speaker verification and speech recognition task: LDA filter bank feature (LDA-FB) [23], log-normalized learned Mel-scale filter bank feature (l-LMFB) [24] and DNN bottle neck feature (DNN-BN) [21].", "startOffset": 195, "endOffset": 199}, {"referenceID": 23, "context": "We also compare the DNN-FBCC feature with other three data driven features which have been successfully used in speaker verification and speech recognition task: LDA filter bank feature (LDA-FB) [23], log-normalized learned Mel-scale filter bank feature (l-LMFB) [24] and DNN bottle neck feature (DNN-BN) [21].", "startOffset": 263, "endOffset": 267}, {"referenceID": 20, "context": "We also compare the DNN-FBCC feature with other three data driven features which have been successfully used in speaker verification and speech recognition task: LDA filter bank feature (LDA-FB) [23], log-normalized learned Mel-scale filter bank feature (l-LMFB) [24] and DNN bottle neck feature (DNN-BN) [21].", "startOffset": 305, "endOffset": 309}, {"referenceID": 23, "context": "l-LMFB is generated by a neural network introduced by [24] which uses a 20 channel mel-scale rectangle filter bank to generate Mbl and chooses exponential function e as a non-negative restriction function.", "startOffset": 54, "endOffset": 58}], "year": 2017, "abstractText": "With the development of speech synthesis techniques, automatic speaker verification systems face the serious challenge of spoofing attack. In order to improve the reliability of speaker verification systems, we develop a new filter bank based cepstral feature, deep neural network filter bank cepstral coefficients (DNN-FBCC), to distinguish between natural and spoofed speech. The deep neural network filter bank is automatically generated by training a filter bank neural network (FBNN) using natural and synthetic speech. By adding restrictions on the training rules, the learned weight matrix of FBNN is band-limited and sorted by frequency, similar to the normal filter bank. Unlike the manually designed filter bank, the learned filter bank has different filter shapes in different channels, which can capture the differences between natural and synthetic speech more effectively. The experimental results on the ASVspoof 2015 database show that the Gaussian mixture model maximum-likelihood (GMM-ML) classifier trained by the new feature performs better than the state-of-the-art linear frequency cepstral coefficients (LFCC) based classifier, especially on detecting unknown attacks. Index Terms speaker verification, spoofing detection, DNN filter bank cepstral coefficients, filter bank neural network.", "creator": "LaTeX with hyperref package"}}}