{"id": "1702.03964", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Feb-2017", "title": "The Parallel Meaning Bank: Towards a Multilingual Corpus of Translations Annotated with Compositional Meaning Representations", "abstract": "The Parallel Meaning Bank is a corpus of translations annotated with shared, formal meaning representations comprising over 11 million words divided over four languages (English, German, Italian, and Dutch). Our approach is based on cross-lingual projection: automatically produced (and manually corrected) semantic annotations for English sentences are mapped onto their word-aligned translations, assuming that the translations are meaning-preserving. The semantic annotation consists of five main steps: (i) segmentation of the text in sentences and lexical items; (ii) syntactic parsing with Combinatory Categorial Grammar; (iii) universal semantic tagging; (iv) symbolization; and (v) compositional semantic analysis based on Discourse Representation Theory. These steps are performed using statistical models trained in a semi-supervised manner. The employed annotation models are all language-neutral. Our first results are promising.", "histories": [["v1", "Mon, 13 Feb 2017 19:52:02 GMT  (208kb,D)", "http://arxiv.org/abs/1702.03964v1", "To appear at EACL 2017"]], "COMMENTS": "To appear at EACL 2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["lasha abzianidze", "johannes bjerva", "kilian evang", "hessel haagsma", "rik van noord", "pierre ludmann", "duc-duy nguyen", "johan bos"], "accepted": false, "id": "1702.03964"}, "pdf": {"name": "1702.03964.pdf", "metadata": {"source": "CRF", "title": "The Parallel Meaning Bank: Towards a Multilingual Corpus of Translations Annotated with Compositional Meaning Representations", "authors": ["Lasha Abzianidze", "Johannes Bjerva", "Kilian Evang", "Hessel Haagsma", "Rik van Noord", "Pierre Ludmann", "Duc-Duy Nguyen", "Johan Bos"], "emails": ["l.abzianidze@rug.nl", "j.bjerva@rug.nl", "k.evang@rug.nl", "hessel.haagsma@rug.nl", "r.i.k.van.noord@rug.nl", "johan.bos@rug.nl", "pierre.ludmann@ens-cachan.fr", "ducduy.nguyen@studenti.unitn.it"], "sections": [{"heading": "1 Introduction", "text": "There is no reason to believe that the ingredients of a representation of meaning for one language should be different from those for another. Therefore, a meaningful translation from one sentence to another language should probably have equivalent representations of meaning. Therefore, the aim of this paper is to present a method that puts this idea into practice by creating a parallel body with common formal representations of meaning, that is, the parallel meaning of the bank (PMB)."}, {"heading": "2 Languages and Corpora", "text": "The basis of the PMB is a large set of raw, parallel texts. Ideally, each text has a parallel version in each language of the meaning bank, but in practice one version for the pivot language (here: English) and another language is sufficient for our purposes. Another criterion for selection is that freely distributable texts are preferable texts that are subject to copyright and require a (paid) license. In addition to English, we chose two other Germanic languages, Dutch and German, because they are similar to English. We also include a Romance language, Italian, to test whether our method works for languages that are more typologically different from English. The texts in the PMB come from twelve different corporas from a wide range of genres, including: Tatoeba1, NewsCommentary (via OPUS, Tiedemann, 2012), Recognizing Textual Entailment (Giampiccolo et al, 2007), Sherlock Holmes Stesgazing, US, and Christobel (2012)."}, {"heading": "3 Automatic Annotation Pipeline", "text": "Our goal is to begin by extensively commenting on the English corpus with annotations ranging from segmentation to deep semantics, and then project these annotations onto the other languages using alignment. Annotations consist of several layers, each of which is presented in detail below. Figure 1 provides an overview of the pipeline, while Figure 2 shows the annotation example."}, {"heading": "3.1 Segmentation", "text": "The text segmentation includes word and sentence boundary recognition. Multiword expressions representing components are treated as single characters. Closed compound words with a semantically transparent structure are decomposed. For example, the impossible is decomposed into In and Possible, while Las Vegas and 2 pm are analyzed as single characters. In this way, we want to assign token \"atomic\" meanings and avoid redundant lexicalic semantics. Segmentation follows an IOB annotation scheme at character level, with four terms: beginning of sentence, beginning of word, inside a word and outside of a word. we use the same statistical tokenizer, Elefant (Evang et al., 2013), for all four languages, but with language-specific models.NP Ercucucucucucucuccucuccu.NP (S\\ NP)\\ NP (S\\ NP)\\ NP (S\\ NP)\\ ccucucucucuccu.ccucucucucS\\ cucucucucS\\ cP\\ ccucucucuccuccucS\\ P\\ ccuccuccuccucccccccS\\ P\\ P\\ ccucucuccccccccccccccccccccu\\ S\\ P\\ ccccccccccccccu\\ cu\\ cu\\ cu\\ cu\\ cu\\ cu\\ cu\\ cu\\ cp\\ cu\\ cu\\ cu\\ cu\\ cu\\ cu\\ cu\\ cu\\ cu\\ cu\\ p\\ cu\\ cu\\ cu\\ cu\\ cu\\ cu\\ cu\\ cu\\ cu\\ cp\\ cu\\ cp\\ cccccccccu\\ cbr\\ cccccu\\ ccccbr\\ cccbr\\ cbr\\ ccbr\\ cccbr\\ ccccccbr\\ cccccbr\\ cccbr\\ cbr\\ cbr\\ cccbr\\ cccbr\\ ccc"}, {"heading": "3.2 Syntactic Analysis", "text": "We use CCG-based derivatives for syntactical analysis. CCG's transparent syntax-semantic interface makes the derivatives suitable for far-reaching compositional semantics (Bos et al., 2004). CCG is also a lexicalized theory of grammar that makes cross-lingual projection of grammatical information more convenient from source to target sentence (see Section 4). The version of CCG that we use differs from the standard CCG: to facilitate the cross-lingual projection process and maintain compositionality, typical changing rules of a CCG parser are explained by inserting (unprojected) blank elements that have their own semantics (see token scheme in Figure 2). To parse, we use EasyCCG (Lewis and Steedman, 2014), which was selected for its accuracy, does not require annotation of any part of the language (which would require different annotations for each language) and is easy to adapt to our grammar."}, {"heading": "3.3 Universal Semantic Tagging", "text": "In order to facilitate the organization of a broad semantic lexicon for cross-language semantic analysis, we are developing a universal semantic tagset. Semtags are language-neutral, generalize about parts of the language and designated entity classes, and also add more specific information when needed from a semantic perspective. In view of a CCG category of a token, we specify a general scheme for its lexical semantics by marking the token with a semtag. Currently, the tagset includes 80 different fine-grained semtags divided into 13 coarse-grained classes (Bjerva et al., 2016). We do not list all possible semtags here, but give some examples instead. Thus, the semtag does NOT mark negation triggers, e.g. none, without and affixes, e.g. impossible semantic labels."}, {"heading": "3.4 Symbolization", "text": "The meanings we use contain logical symbols and non-logical symbols. The latter are based on the words mentioned in the input text. We refer to this process as symbolism. It combines lemmatization with normalization, and 3 rolls are largely compatible with each other, while concepts are absent. Thus, a unit can be a boxer and a semantic at the same time, but not a wheel and a tablet. It performs some lexical disambiguations. For example, the symbol of the pronouns he uses and himself is Europe of the adjective European, and 14: 00 for the time expression 2 pm. A symbol together with a CCG category and a semantag is sufficient to determine the lexical semantics of a tok (see Figure 2). Some function words do not need symbols because they are associated with logical symbols, not in the form of symbols."}, {"heading": "3.5 Semantic Interpretation", "text": "Discourse Representation Theory (DRT, Kamp and Reyle, 1993) is the semantic formalism used as semantic representation in the PMB. It is a well-researched theory from a linguistic semantic point of view and suitable for compositional semantics.5 Expressions in DRT, called Discourse4http: / / unece.org / cefact / codesfortrade 5Specifically, we use projective DRT (Venhuizen, 2015) - an extension of DRT that takes into account pre-supplementary representation structures (DRSs), have a recursive structure and are commonly presented as nesting. An upper part of a DRS contains a series of references, while the lower part lists a combination of atomic or compound conditions via these referents (see an example of a DRS in the lower part of Figure 2). Boxer (Bos, 2015) is a system in which compositional tags are used to construct DRS in an English part."}, {"heading": "4 Cross-lingual Projection", "text": "The initial annotation for Dutch, German, and Italian words is skipped via word guidelines. Any non-English text is automatically word-tagged, and non-English words are first given semi-labels, CCG categories, and symbols based on those of their English counterparts (see Figure 2). CCG slashes are reversed when needed, and 2: 1 slashes are handled by functional composition. Then, CCG derivatives and DRSs can be corrected manually by applying CCG's combinatorial rules to apply the same DRS as for the English sentence (Evang and Bos, 2016; Evang, 2016). If the alignment is wrong, it can be corrected by manual correction (see Section 5). The idea behind this type of bootstrapping is to use the advanced state-of-the-art NLP for English and promote parallelism between syntactical and analytical analysis of different languages."}, {"heading": "5 Adding Bits of Wisdom", "text": "These annotations are referred to as Bits of Wisdom (BoWs, according to Basile et al. (2012) and override the models \"annotations if they conflict. Based on the BoWs, we distinguish three disjointed classes of annotation levels: gold standard (manually checked), silver standard (including at least one BoW), and bronze standard (no BoWs). Table 1 shows how these classes are distributed across languages and documents. In addition to adding BoWs in general, we also use annotations to better target models by focusing on annotation conflicts. Annotation conflicts arise when a particular annotation level for a document is manually checked and marked as\" gold. \"If the automatic annotation of such a level changes, e.g. after retraining a model, new annotation errors can be introduced, and these are marked as annotation levels for a document if it is manually checked and marked as\" gold. \""}, {"heading": "6 Conclusion", "text": "In the pipeline we presented in this paper, we laid the groundwork for achieving this goal, and for each task in the pipeline - tokenization, parsing, semantic tagging, symbolization, semantic interpretation - we have a single component that uses a language-specific model, we have proposed new language-neutral tagging systems to achieve this goal (e.g. for tokenization and semantic tagging), and we have adapted existing formalities (making CCGs more general by introducing lexical categories for empty elements), and our initial results for Dutch show that our method is promising (Evang and Bos, 2016), but we have yet to assess how much manual effort is being made in other languages such as German and Italian. We will also explore the idea of combining CCG with the analysis of semantic ole labeling, following Lewis et al. (2015), and whether we would evaluate word perceptions in a data-driven mode (now a net cost projection of 1997, instead of the MB available)."}, {"heading": "Acknowledgements", "text": "This work was funded by the NWO-VICI scholarship \"Lost in Translation - Found in Meaning\" (288-89-003).The Tesla K40 GPU used for this research was donated by NVIDIA Corporation. We would also like to thank the two anonymous reviewers for their comments.6http: / / pmb.let.rug.nl"}], "references": [{"title": "Abstract Meaning Representation for sembanking", "author": ["Laura Banarescu", "Claire Bonial", "Shu Cai", "Madalina Georgescu", "Kira Griffitt", "Ulf Hermjakob", "Kevin Knight", "Philipp Koehn", "Martha Palmer", "Nathan Schneider."], "venue": "Proceedings of the 7th Linguis-", "citeRegEx": "Banarescu et al\\.,? 2013", "shortCiteRegEx": "Banarescu et al\\.", "year": 2013}, {"title": "A platform for collaborative semantic annotation", "author": ["Valerio Basile", "Johan Bos", "Kilian Evang", "Noortje Venhuizen."], "venue": "Proceedings of the Demonstrations at the 13th Conference of the European Chapter of the Association for Computational", "citeRegEx": "Basile et al\\.,? 2012", "shortCiteRegEx": "Basile et al\\.", "year": 2012}, {"title": "Semantic tagging with deep residual networks", "author": ["Johannes Bjerva", "Barbara Plank", "Johan Bos."], "venue": "Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers, pages 3531\u20133541, Osaka, Japan.", "citeRegEx": "Bjerva et al\\.,? 2016", "shortCiteRegEx": "Bjerva et al\\.", "year": 2016}, {"title": "A hierarchical unification of LIRICS and VerbNet semantic roles", "author": ["Claire Bonial", "William J. Corvey", "Martha Palmer", "Volha Petukhova", "Harry Bunt."], "venue": "Proceedings of the 5th IEEE International Conference on Semantic Computing (ICSC 2011),", "citeRegEx": "Bonial et al\\.,? 2011", "shortCiteRegEx": "Bonial et al\\.", "year": 2011}, {"title": "Widecoverage semantic representations from a CCG parser", "author": ["Johan Bos", "Stephen Clark", "Mark Steedman", "James R. Curran", "Julia Hockenmaier."], "venue": "Proceedings of the 20th International Conference on Computational Linguistics (COLING", "citeRegEx": "Bos et al\\.,? 2004", "shortCiteRegEx": "Bos et al\\.", "year": 2004}, {"title": "The Groningen Meaning Bank", "author": ["Johan Bos", "Valerio Basile", "Kilian Evang", "Noortje Venhuizen", "Johannes Bjerva."], "venue": "Nancy Ide and James Pustejovsky, editors, Handbook of Linguistic Annotation. Springer Netherlands.", "citeRegEx": "Bos et al\\.,? 2017", "shortCiteRegEx": "Bos et al\\.", "year": 2017}, {"title": "Open-domain semantic parsing with Boxer", "author": ["Johan Bos."], "venue": "Be\u00e1ta Megyesi, editor, Proceedings of the 20th Nordic Conference of Computational Linguistics (NODALIDA 2015), pages 301\u2013304.", "citeRegEx": "Bos.,? 2015", "shortCiteRegEx": "Bos.", "year": 2015}, {"title": "A massively parallel corpus: the Bible in 100 languages", "author": ["Christos Christodouloupoulos", "Mark Steedman."], "venue": "Language Resources and Evaluation, 49(2):375\u2013395.", "citeRegEx": "Christodouloupoulos and Steedman.,? 2015", "shortCiteRegEx": "Christodouloupoulos and Steedman.", "year": 2015}, {"title": "Cross-lingual learning of an open-domain semantic parser", "author": ["Kilian Evang", "Johan Bos."], "venue": "Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers, pages 579\u2013588, Osaka, Japan.", "citeRegEx": "Evang and Bos.,? 2016", "shortCiteRegEx": "Evang and Bos.", "year": 2016}, {"title": "Elephant: Sequence labeling for word and sentence segmentation", "author": ["Kilian Evang", "Valerio Basile", "Grzegorz Chrupa\u0142a", "Johan Bos."], "venue": "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1422\u2013", "citeRegEx": "Evang et al\\.,? 2013", "shortCiteRegEx": "Evang et al\\.", "year": 2013}, {"title": "Cross-lingual Semantic Parsing with Categorial Grammars", "author": ["Kilian Evang."], "venue": "Ph.D. thesis, University of Groningen.", "citeRegEx": "Evang.,? 2016", "shortCiteRegEx": "Evang.", "year": 2016}, {"title": "WordNet. An Electronic Lexical Database", "author": ["Christiane Fellbaum", "editor"], "venue": null, "citeRegEx": "Fellbaum and editor.,? \\Q1998\\E", "shortCiteRegEx": "Fellbaum and editor.", "year": 1998}, {"title": "The third PASCAL Recognizing Textual Entailment challenge", "author": ["Danilo Giampiccolo", "Bernardo Magnini", "Ido Dagan", "Bill Dolan."], "venue": "Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing, pages 1\u20139.", "citeRegEx": "Giampiccolo et al\\.,? 2007", "shortCiteRegEx": "Giampiccolo et al\\.", "year": 2007}, {"title": "From Discourse to Logic; An Introduction to Modeltheoretic Semantics of Natural Language, Formal Logic and DRT", "author": ["Hans Kamp", "Uwe Reyle."], "venue": "Kluwer, Dordrecht.", "citeRegEx": "Kamp and Reyle.,? 1993", "shortCiteRegEx": "Kamp and Reyle.", "year": 1993}, {"title": "I don\u2019t believe in word senses", "author": ["Adam Kilgarriff."], "venue": "Computers and the Humanities, 31(2):91\u2013 113.", "citeRegEx": "Kilgarriff.,? 1997", "shortCiteRegEx": "Kilgarriff.", "year": 1997}, {"title": "Vertalen wat er staat", "author": ["Arthur Langeveld."], "venue": "Synthese, De Arbeiderspers.", "citeRegEx": "Langeveld.,? 1986", "shortCiteRegEx": "Langeveld.", "year": 1986}, {"title": "A* CCG parsing with a supertag-factored model", "author": ["Mike Lewis", "Mark Steedman."], "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 990\u20131000, Doha, Qatar.", "citeRegEx": "Lewis and Steedman.,? 2014", "shortCiteRegEx": "Lewis and Steedman.", "year": 2014}, {"title": "Joint A* CCG parsing and semantic role labeling", "author": ["Mike Lewis", "Luheng He", "Luke Zettlemoyer."], "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1444\u20131454.", "citeRegEx": "Lewis et al\\.,? 2015", "shortCiteRegEx": "Lewis et al\\.", "year": 2015}, {"title": "Applied morphological processing of English", "author": ["Guido Minnen", "John Carroll", "Darren Pearce."], "venue": "Natural Language Engineering, 7(3):207\u2013223.", "citeRegEx": "Minnen et al\\.,? 2001", "shortCiteRegEx": "Minnen et al\\.", "year": 2001}, {"title": "A systematic comparison of various statistical alignment models", "author": ["Franz Josef Och", "Hermann Ney."], "venue": "Computational Linguistics, 29(1):19\u201351.", "citeRegEx": "Och and Ney.,? 2003", "shortCiteRegEx": "Och and Ney.", "year": 2003}, {"title": "The Syntactic Process", "author": ["Mark Steedman."], "venue": "The MIT Press, Cambridge, Ma., USA.", "citeRegEx": "Steedman.,? 2001", "shortCiteRegEx": "Steedman.", "year": 2001}, {"title": "Parallel data, tools and interfaces in OPUS", "author": ["J\u00f6rg Tiedemann."], "venue": "Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC 2012), pages 2214\u20132218, Istanbul, Turkey.", "citeRegEx": "Tiedemann.,? 2012", "shortCiteRegEx": "Tiedemann.", "year": 2012}, {"title": "Projection in Discourse: A data-driven formal semantic analysis", "author": ["Noortje Joost Venhuizen."], "venue": "Ph.D. thesis, University of Groningen.", "citeRegEx": "Venhuizen.,? 2015", "shortCiteRegEx": "Venhuizen.", "year": 2015}, {"title": "Not an interlingua, but close: Comparison of English AMRs to Chinese and Czech", "author": ["Nianwen Xue", "Ondrej Bojar", "Jan Hajic", "Martha Palmer", "Zdenka Uresova", "Xiuhong Zhang."], "venue": "Proceedings of the Ninth International Conference on Language Re-", "citeRegEx": "Xue et al\\.,? 2014", "shortCiteRegEx": "Xue et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "The AMR banks of Abstract Meaning Representations for English (Banarescu et al., 2013) or Chinese and Czech (Xue et al.", "startOffset": 62, "endOffset": 86}, {"referenceID": 23, "context": ", 2013) or Chinese and Czech (Xue et al., 2014) sentences, for instance, are the result of manual annotation efforts.", "startOffset": 29, "endOffset": 47}, {"referenceID": 5, "context": "Another example is the development of the Groningen Meaning Bank (Bos et al., 2017), a corpus of English texts annotated with formal, compositional meaning representations, which took advantage of existing semantic parsing tools, combining them with human corrections.", "startOffset": 65, "endOffset": 83}, {"referenceID": 1, "context": "On the conceptual level we follow the approach of the Groningen Meaning Bank project (Basile et al., 2012), and use some of the tools developed in it.", "startOffset": 85, "endOffset": 106}, {"referenceID": 15, "context": "Human translators purposely change meaning in translation to yield better translations (Langeveld, 1986).", "startOffset": 87, "endOffset": 104}, {"referenceID": 12, "context": "The texts in the PMB are sourced from twelve different corpora from a wide range of genres, including, among others: Tatoeba1, NewsCommentary (via OPUS, Tiedemann, 2012), Recognizing Textual Entailment (Giampiccolo et al., 2007), Sherlock Holmes stories2, and the Bible (Christodouloupoulos and Steedman, 2015).", "startOffset": 202, "endOffset": 228}, {"referenceID": 7, "context": ", 2007), Sherlock Holmes stories2, and the Bible (Christodouloupoulos and Steedman, 2015).", "startOffset": 49, "endOffset": 89}, {"referenceID": 9, "context": "We use the same statistical tokenizer, Elephant (Evang et al., 2013), for all four languages, but with language-specific models.", "startOffset": 48, "endOffset": 68}, {"referenceID": 4, "context": "The transparent syntax-semantic interface of CCG makes the derivations suitable for widecoverage compositional semantics (Bos et al., 2004).", "startOffset": 121, "endOffset": 139}, {"referenceID": 16, "context": "For parsing, we use EasyCCG (Lewis and Steedman, 2014), which was chosen because it is accurate, does not require part-of-speech annotation (which would require different annotation schemes for each language) and is easily adaptable to our modified grammar formalism.", "startOffset": 28, "endOffset": 54}, {"referenceID": 2, "context": "Currently the tagset comprises 80 different finegrained semtags divided into 13 coarse-grained classes (Bjerva et al., 2016).", "startOffset": 103, "endOffset": 124}, {"referenceID": 2, "context": "6%, are reported by Bjerva et al. (2016).", "startOffset": 20, "endOffset": 41}, {"referenceID": 18, "context": "We are currently investigating how the performance of machine learning-based symbolizer compares to a rule-based one incorporating the lemmatizer Morpha (Minnen et al., 2001).", "startOffset": 153, "endOffset": 174}, {"referenceID": 22, "context": "org/cefact/codesfortrade In particular, we employ Projective DRT (Venhuizen, 2015)\u2014an extension of DRT that accounts for presupposiRepresentation Structures (DRSs), have a recursive structure and are usually depicted as boxes.", "startOffset": 65, "endOffset": 82}, {"referenceID": 6, "context": "Boxer (Bos, 2015), a system that employs \u03bb-calculus to construct DRSs in a compositional way, is used to derive meaning representations of the documents.", "startOffset": 6, "endOffset": 17}, {"referenceID": 3, "context": "Boxer also assigns VerbNet/LIRICS thematic roles (Bonial et al., 2011) to verbs so that the lexical semantics of verbs include the corresponding thematic predicates (see came in Figure 2).", "startOffset": 49, "endOffset": 70}, {"referenceID": 8, "context": "Then, the CCG derivations and DRSs can be obtained by applying CCG\u2019s combinatory rules in such a way that the same DRS as for the English sentence results (Evang and Bos, 2016; Evang, 2016).", "startOffset": 155, "endOffset": 189}, {"referenceID": 10, "context": "Then, the CCG derivations and DRSs can be obtained by applying CCG\u2019s combinatory rules in such a way that the same DRS as for the English sentence results (Evang and Bos, 2016; Evang, 2016).", "startOffset": 155, "endOffset": 189}, {"referenceID": 19, "context": "Subsequently, we automatically align words in the aligned sentences using GIZA++ (Och and Ney, 2003).", "startOffset": 81, "endOffset": 100}, {"referenceID": 1, "context": "These annotations are called Bits of Wisdom (BoWs, following Basile et al. (2012)), and they overrule the annotations of the models if they are in conflict.", "startOffset": 61, "endOffset": 82}, {"referenceID": 8, "context": "Our first results for Dutch show that our method is promising (Evang and Bos, 2016), but we still need to assess how much manual effort is involved in other languages, such as German and Italian.", "startOffset": 62, "endOffset": 83}, {"referenceID": 14, "context": "(2015), and whether we can derive word senses in a data-driven fashion (Kilgarriff, 1997) rather than using WordNet.", "startOffset": 71, "endOffset": 89}, {"referenceID": 6, "context": "Our first results for Dutch show that our method is promising (Evang and Bos, 2016), but we still need to assess how much manual effort is involved in other languages, such as German and Italian. We will also explore the idea of combining CCG parsing with Semantic Role Labelling, following Lewis et al. (2015), and whether we can derive word senses in a data-driven fashion (Kilgarriff, 1997) rather than using WordNet.", "startOffset": 73, "endOffset": 311}], "year": 2017, "abstractText": "The Parallel Meaning Bank is a corpus of translations annotated with shared, formal meaning representations comprising over 11 million words divided over four languages (English, German, Italian, and Dutch). Our approach is based on cross-lingual projection: automatically produced (and manually corrected) semantic annotations for English sentences are mapped onto their word-aligned translations, assuming that the translations are meaning-preserving. The semantic annotation consists of five main steps: (i) segmentation of the text in sentences and lexical items; (ii) syntactic parsing with Combinatory Categorial Grammar; (iii) universal semantic tagging; (iv) symbolization; and (v) compositional semantic analysis based on Discourse Representation Theory. These steps are performed using statistical models trained in a semisupervised manner. The employed annotation models are all language-neutral. Our first results are promising.", "creator": "LaTeX with hyperref package"}}}