{"id": "1702.04280", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Feb-2017", "title": "DAGER: Deep Age, Gender and Emotion Recognition Using Convolutional Neural Network", "abstract": "This paper describes the details of Sighthound's fully automated age, gender and emotion recognition system. The backbone of our system consists of several deep convolutional neural networks that are not only computationally inexpensive, but also provide state-of-the-art results on several competitive benchmarks. To power our novel deep networks, we collected large labeled datasets through a semi-supervised pipeline to reduce the annotation effort/time. We tested our system on several public benchmarks and report outstanding results. Our age, gender and emotion recognition models are available to developers through the Sighthound Cloud API at", "histories": [["v1", "Tue, 14 Feb 2017 16:34:05 GMT  (9242kb,D)", "http://arxiv.org/abs/1702.04280v1", "10 Pages"], ["v2", "Sat, 4 Mar 2017 01:43:04 GMT  (9242kb,D)", "http://arxiv.org/abs/1702.04280v2", "10 Pages"]], "COMMENTS": "10 Pages", "reviews": [], "SUBJECTS": "cs.CV cs.AI", "authors": ["afshin dehghan", "enrique g ortiz", "guang shu", "syed zain masood"], "accepted": false, "id": "1702.04280"}, "pdf": {"name": "1702.04280.pdf", "metadata": {"source": "CRF", "title": "DAGER: Deep Age, Gender and Emotion Recognition Using Convolutional Neural Networks", "authors": ["Afshin Dehghan", "Enrique G. Ortiz", "Guang Shu", "Syed Zain Masood"], "emails": ["zainmasood}@sighthound.com"], "sections": [{"heading": "1 Introduction", "text": "The recognition of facial attributes, including age, gender and emotion [1,2,3,4,5,6,7] has been a topic of interest among computer vision researchers for over a decade. One of the main reasons for this is the numerous applications of this challenging problem, ranging from security control to person identification to human-computer interaction. However, due to the publication of large data sets with labels and advances in the design of Convolutionary Neural Networks, error rates have fallen significantly. In many cases, these systems are able to outperform people [5]. However, this remains a difficult problem and existing commercial systems lag behind expectations in dealing with real-world scenarios. In this paper, we present an end-to-end system that is capable of estimating facial attributes including age, gender and emotion with low error rates. To support our claims, we tested our system on several benchmarks and achieved better results than previous state-of-the-art contributions to this work are summarized below."}, {"heading": "2 System Overview", "text": "The pipeline of our system is in Figure 1. Our first in-depth model is trained on a large dataset of four million images for the task of facial recognition, which serves as the backbone of our facial recognition and fine-tunes networks for four tasks: real age assessment, apparent age assessment, gender recognition and emotion recognition. What follows explains the steps in detail."}, {"heading": "2.1 Training", "text": "It is indeed the case that we are able to manoeuvre ourselves into a situation where we have to put ourselves at the centre."}, {"heading": "3 Experiments", "text": "In this section we report on experimental results on several publicly available datasets as well as our internal datasets."}, {"heading": "3.1 Real Age Estimation", "text": "For real age estimates, we report two publicly available datasets, the group dataset [5] and the Adience dataset [11]. The images in these datasets are labeled with their respective age groups. To further evaluate our system, we present quantitative results on our greyhound dataset, which contains 3,800 test images. Each image is labeled with its corresponding age of 10 to 90 years. Unlike the Adience and Group datasets, our dataset includes the exact age labels and not the age datasets, which contain 3,800 test images. Each image is labeled with its corresponding age."}, {"heading": "3.2 Apparent Age Estimation", "text": "The apparent age of a person could be very different from the real age of a person. Recently, thanks to the availability of the Chalearn LAP Apparent Age Estimation dataset and the challenge [19], several researchers have focused on developing models that focus on predicting the apparent age rather than the actual age. In the latest version of the competition, the size of the dataset was expanded to 7, 591 images, of which 4, 113 are used for training and 1, 500 or 1, 978 for validation or verification. Each image in the dataset is recorded with at least 10 human voices and the mean (\u00b5) and the standard deviation (\u03c3) of the voices and released with the dataset. Given the prediction for each image (x), the error for each image is calculated using = 1 \u2212 exp \u2212 (x-\u00b5) 22\u04452. This means that the apparent age on an image with a small standard deviation is punished more than a larger standard deviation."}, {"heading": "3.3 Emotion Recognition", "text": "There are several public data sets for emotion recognition. FER-2013 [22] and EmotiW are among the most popular data sets. The FER data set contains low-quality grayscale images of 48 x 48, which are not very representative for real scenarios. Access to the EmotiW data set was not granted to us. Therefore, we collected our own data set of 2,156 images. Each image is labeled with one of the 7 labels \"happy,\" \"sad,\" \"neutral,\" \"disgusted,\" \"surprised,\" \"anxious\" and \"angry.\" The data is fairly evenly distributed across the 7 emotions. We compared our method with the Microsoft Face API [13]. The results and the confusion tables are shown in Table 5 and Figure 4. As shown, the greyhound emotion recognition system outperforms Microsoft by 15%. 4"}, {"heading": "3.4 Gender Recognition", "text": "The Adience benchmark contains 17,492 faces labeled with their respective gender. Faces are divided into 5 folds. However, we used the same model across all folds without further fine-tuning. Together with the published state-of-the-art results, we compared our method to a few commercial APIs such as [15] and [14]. The results listed in Table 6 clearly show 4 Microsoft API failed to detect a face in 193 images. To be fair to Microsoft, we removed these images when evaluating their method."}, {"heading": "4 Conclusions", "text": "In this paper, we present an end-to-end system for detecting age, gender and emotions. We show that our novel deep architecture, together with our large, internally collected data, can outperform commercial and academic algorithms in several benchmarks."}], "references": [{"title": "Analysis of emotion recognition using facial expressions, speech and multimodal information", "author": ["Busso", "Carlos", "e.a."], "venue": "Proceedings of the 6th international conference on Multimodal interfaces.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2004}, {"title": "Emotion recognition in the wild via convolutional neural networks and mapped binary patterns", "author": ["G. Levi", "T. Hassner."], "venue": "Proceedings of the 2015 ACM on International Conference on Multimodal Interaction. ACM.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2015}, {"title": "Mutlimodal learning with deep boltzmann machine for emotion prediction in user generated videos", "author": ["L. Pang", "C.W. Ngo."], "venue": "Proceedings of the 2015 ACM on International Conference on Multimodal Retrieval. ACM.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}, {"title": "Dex: Deep expectation of apparent age from a single image", "author": ["R. Rothe", "L.V.G. Radu Timofte"], "venue": "International Conference on Computer Vision (ICCV),.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2015}, {"title": "Understanding images of groups of people", "author": ["A.C. Gallagher", "T. Chen."], "venue": "CVPR.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2009}, {"title": "Apparent age estimation from face images combining general and children-specialized deep learning models", "author": ["Antipov", "Grigory", "e.a."], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2016}, {"title": "Deeply-learned feature for age estimation", "author": ["X. Wang", "R. Guo", "C. Kambhamettu"], "venue": "WACV.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2015}, {"title": "View independent vehicle make, model and color recognition using convolutional neural network", "author": ["A. Dehghan", "S.Z. Masood", "G. Shu", "E.G. Ortiz."], "venue": "arXiv:1702.01721.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2017}, {"title": "Imagenet: A large-scale hierarchical image database", "author": ["Deng", "Jia", "e.a."], "venue": "Computer Vision and Pattern Recognition.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2009}, {"title": "The pascal visual object classes challenge: A retrospective", "author": ["M. Everingham", "E.S.M.A.V.G.L.W.C.K.I.W.J.", "A. Zisserman"], "venue": "International Journal of Computer Vision.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2015}, {"title": "Age and gender estimation of unfiltered faces", "author": ["E. Eidinger", "R. Enbar", "T. Hassner."], "venue": "IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2013}, {"title": "An all-in-one convolutional neural network for face analysis", "author": ["R. Ranjan", "S. Sankaranarayanan", "C.D. Castillo", "R. Chellappa"], "venue": "arXiv:1611.00851.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2016}, {"title": "Squared earth mover\u2019s distance-based loss for training deep neural networks", "author": ["L. Hou", "C.P. Yu", "D. Samaras."], "venue": "arXiv.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2016}, {"title": "Automatic age estimation based on deep learning algorithm", "author": ["D. Yuan", "Y. Liu", "S. Lian."], "venue": "Neurocomputing.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2016}, {"title": "Age and gender classification using convolutional neural networks", "author": ["G. Levi", "T. Hassner."], "venue": "CVPRW.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2015}, {"title": "Chalearn looking at people and faces of the world: Face analysis workshop and challenge 2016", "author": ["Escalera", "Sergio", "e.a."], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2016}, {"title": "Deep age distribution learning for apparent age estimation", "author": ["Z. Huo", "X. Yang", "C. Xing", "Y. Zhou", "P. Hou", "J. Lv", "X. Geng"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition Workshops", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2016}, {"title": "Structured output SVM prediction of apparent age, gender and smile from deep features", "author": ["M. U\u0159i\u010d\u00e1\u0159", "R. Timofte", "R. Rothe", "J. Matas", "L.V. Gool"], "venue": "Proceedings of IEEE conference on Computer Vision and Pattern Recognition Workshops, Las Vegas, USA", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2016}, {"title": "Challenges in representation learning: A report on three machine learning contests", "author": ["I.J. Goodfellow"], "venue": "International Conference on Neural Information Processing.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "Facial attribute recognition, including age, gender and emotion, [1,2,3,4,5,6,7] has been a topic of interest among computer vision researchers for over a decade.", "startOffset": 65, "endOffset": 80}, {"referenceID": 1, "context": "Facial attribute recognition, including age, gender and emotion, [1,2,3,4,5,6,7] has been a topic of interest among computer vision researchers for over a decade.", "startOffset": 65, "endOffset": 80}, {"referenceID": 2, "context": "Facial attribute recognition, including age, gender and emotion, [1,2,3,4,5,6,7] has been a topic of interest among computer vision researchers for over a decade.", "startOffset": 65, "endOffset": 80}, {"referenceID": 3, "context": "Facial attribute recognition, including age, gender and emotion, [1,2,3,4,5,6,7] has been a topic of interest among computer vision researchers for over a decade.", "startOffset": 65, "endOffset": 80}, {"referenceID": 4, "context": "Facial attribute recognition, including age, gender and emotion, [1,2,3,4,5,6,7] has been a topic of interest among computer vision researchers for over a decade.", "startOffset": 65, "endOffset": 80}, {"referenceID": 5, "context": "Facial attribute recognition, including age, gender and emotion, [1,2,3,4,5,6,7] has been a topic of interest among computer vision researchers for over a decade.", "startOffset": 65, "endOffset": 80}, {"referenceID": 6, "context": "Facial attribute recognition, including age, gender and emotion, [1,2,3,4,5,6,7] has been a topic of interest among computer vision researchers for over a decade.", "startOffset": 65, "endOffset": 80}, {"referenceID": 4, "context": "In many cases, these systems are able to outperform humans [5].", "startOffset": 59, "endOffset": 62}, {"referenceID": 7, "context": "Collecting labeled data for some tasks, such as real age estimation, is much more challenging compared to popular classification [8,9] or detection [10] problems.", "startOffset": 129, "endOffset": 134}, {"referenceID": 8, "context": "Collecting labeled data for some tasks, such as real age estimation, is much more challenging compared to popular classification [8,9] or detection [10] problems.", "startOffset": 129, "endOffset": 134}, {"referenceID": 9, "context": "Collecting labeled data for some tasks, such as real age estimation, is much more challenging compared to popular classification [8,9] or detection [10] problems.", "startOffset": 148, "endOffset": 152}, {"referenceID": 4, "context": "Age estimation: Recently there have been some efforts in collecting data with corresponding age labels [5,11,4].", "startOffset": 103, "endOffset": 111}, {"referenceID": 10, "context": "Age estimation: Recently there have been some efforts in collecting data with corresponding age labels [5,11,4].", "startOffset": 103, "endOffset": 111}, {"referenceID": 3, "context": "Age estimation: Recently there have been some efforts in collecting data with corresponding age labels [5,11,4].", "startOffset": 103, "endOffset": 111}, {"referenceID": 3, "context": "in [4] is the largest dataset that contains 523, 051 images and is available for research purposes.", "startOffset": 3, "endOffset": 6}, {"referenceID": 3, "context": "This led to the authors using only half of the data for training in the original paper [4].", "startOffset": 87, "endOffset": 90}, {"referenceID": 3, "context": "In contrast to some previous works, which do not use any face alignment [4], we found this to be important in our final accuracy numbers.", "startOffset": 72, "endOffset": 75}, {"referenceID": 1, "context": "Our face recognition model is not only computationally inexpensive (with feature extraction time of 70ms using just the CPU), but also achieves outstanding results on the LFW dataset [2].", "startOffset": 183, "endOffset": 186}, {"referenceID": 11, "context": "In some recent works [12], researchers try to design a network which performs all tasks at the same time, and they have shown marginal improvements.", "startOffset": 21, "endOffset": 25}, {"referenceID": 11, "context": "Additionally running all models combined takes less time compared to the all-in-one model of [12] and we achieve better results.", "startOffset": 93, "endOffset": 97}, {"referenceID": 4, "context": "For real age estimation, we report results on two publicly available datasets, the Group dataset [5] and the Adience dataset [11].", "startOffset": 97, "endOffset": 100}, {"referenceID": 10, "context": "For real age estimation, we report results on two publicly available datasets, the Group dataset [5] and the Adience dataset [11].", "startOffset": 125, "endOffset": 129}, {"referenceID": 3, "context": "[4] 7.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "We compare our results with [4], whose model is trained on the IMDB-Wiki dataset.", "startOffset": 28, "endOffset": 31}, {"referenceID": 3, "context": "For quantitative comparison, we used the Mean Absolute Error (MAE) which is commonly used in the literature [4].", "startOffset": 108, "endOffset": 111}, {"referenceID": 4, "context": "We followed the setup in [5] where", "startOffset": 25, "endOffset": 28}, {"referenceID": 12, "context": "[16] 65.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "[4] 62.", "startOffset": 0, "endOffset": 3}, {"referenceID": 13, "context": "[17] 56.", "startOffset": 0, "endOffset": 4}, {"referenceID": 4, "context": "[5] 42.", "startOffset": 0, "endOffset": 3}, {"referenceID": 12, "context": "[16] 61.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[11] 45.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "6% Levi and Hassner [18] 50.", "startOffset": 20, "endOffset": 24}, {"referenceID": 15, "context": "Recently, thanks to the availability of the Chalearn LAP Apparent Age Estimation dataset and challenge [19], several researchers have focused on designing models that are focused on predicting the apparent age, rather than the", "startOffset": 103, "endOffset": 107}, {"referenceID": 5, "context": "The winner of the competition [6] used a multi CNN framework and achieved a test error of 0.", "startOffset": 30, "endOffset": 33}, {"referenceID": 5, "context": "However, this method [6] has several limitations.", "startOffset": 21, "endOffset": 24}, {"referenceID": 5, "context": "319 No OrangeLabs [6] 0.", "startOffset": 18, "endOffset": 21}, {"referenceID": 16, "context": "2411 Yes Palm-seu [20] 0.", "startOffset": 18, "endOffset": 22}, {"referenceID": 17, "context": "3214 Yes CMP+ETH [21] 0.", "startOffset": 17, "endOffset": 21}, {"referenceID": 15, "context": "Table 4: Results for ChaLearn [19] apparent age estimation 2016 challenge.", "startOffset": 30, "endOffset": 34}, {"referenceID": 18, "context": "FER-2013 [22] and EmotiW are among the popular ones.", "startOffset": 9, "endOffset": 13}, {"referenceID": 3, "context": "[4] 88.", "startOffset": 0, "endOffset": 3}, {"referenceID": 14, "context": "Levi and Hassner [18] 86.", "startOffset": 17, "endOffset": 21}, {"referenceID": 10, "context": "Table 6: Results for gender recognition on the Adience benchmark [11].", "startOffset": 65, "endOffset": 69}], "year": 2017, "abstractText": "This paper describes the details of Sighthound\u2019s fully automated age, gender and emotion recognition system. The backbone of our system consists of several deep convolutional neural networks that are not only computationally inexpensive, but also provide state-of-theart results on several competitive benchmarks. To power our novel deep networks, we collected large labeled datasets through a semi-supervised pipeline to reduce the annotation effort/time. We tested our system on several public benchmarks and report outstanding results. Our age, gender and emotion recognition models are available to developers through the Sighthound Cloud API at https://www.sighthound.com/products/cloud", "creator": "LaTeX with hyperref package"}}}