{"id": "1702.04423", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Feb-2017", "title": "Efficient Multi-task Feature and Relationship Learning", "abstract": "In this paper we propose a multi-convex framework for multi-task learning that improves predictions by learning relationships both between tasks and between features. Our framework is a generalization of related methods in multi-task learning, that either learn task relationships, or feature relationships, but not both. We start with a hierarchical Bayesian model, and use the empirical Bayes method to transform the underlying inference problem into a multi-convex optimization problem. We propose a coordinate-wise minimization algorithm that has a closed form solution for each block subproblem. Naively these solutions would be expensive to compute, but by using the theory of doubly stochastic matrices, we are able to reduce the underlying matrix optimization subproblem into a minimum weight perfect matching problem on a complete bipartite graph, and solve it analytically and efficiently. To solve the weight learning subproblem, we propose three different strategies, including a gradient descent method with linear convergence guarantee when the instances are not shared by multiple tasks, and a numerical solution based on Sylvester equation when instances are shared. We demonstrate the efficiency of our method on both synthetic datasets and real-world datasets. Experiments show that the proposed optimization method is orders of magnitude faster than an off-the-shelf projected gradient method, and our model is able to exploit the correlation structures among multiple tasks and features.", "histories": [["v1", "Tue, 14 Feb 2017 23:43:32 GMT  (186kb,D)", "http://arxiv.org/abs/1702.04423v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.AI", "authors": ["han zhao", "otilia stretcu", "renato negrinho", "alex smola", "geoff gordon"], "accepted": false, "id": "1702.04423"}, "pdf": {"name": "1702.04423.pdf", "metadata": {"source": "CRF", "title": "Efficient Multi-task Feature and Relationship Learning", "authors": ["Han Zhao", "Otilia Stretcu", "Renato Negrinho", "Alex Smola", "Geoff Gordon"], "emails": ["HAN.ZHAO@CS.CMU.EDU", "OSTRETCU@CS.CMU.EDU", "NEGRINHO@CS.CMU.EDU", "ALEX@SMOLA.ORG", "GGORDON@CS.CMU.EDU"], "sections": [{"heading": "1. Introduction", "text": "In fact, it is such that most of them will be able to move into another world, in which they are able to move, in which they move, in which they move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they, in which they live, in which they, in which they live, in which they, in which they live, in which they, in which they live."}, {"heading": "2. Multi-task Feature and Relationship Learning", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Notation and Setup", "text": "We use Sm + and Sm + + to mark the m-dimensional symmetrical positive semidefinitive cone or the m-dimensional symmetrical positive definitive cone. We write tr (A) for the track of a matrix A. Finally, we use G = (A, B, E, w) to mark a weighted bipartite graph with vertex sets A, B, edge set E and weight function w: E \u2192 R +. [d] denotes the set {1, 2,...,., d. Let's consider the following construction. Suppose we get m-learning tasks {Ti} mi = 1, in which we have access to a learning set Di with ni data instances for each task Ti (xji, y j i), j [ni]. Here, we focus on the supervised learning setting, in which xji, Xi and y i, i, i, i, i, Yi, Yi, for the task."}, {"heading": "2.2 Hierarchical Bayes model", "text": "Based on the linear regression model, the probability function for task i is given by: yji | x j i, wi, i \u0445 N (wTi x, 2i) (1), where N (m, \u03a3) is the multivariate normal distribution with mean m and covariance matrix. Let W = (w1,.., wm) be the model parameter (regression weights) for m different tasks. Using a hierarchical Bayes approach, we specify a previous distribution using the model parameter W. Specifically, we define the previous distribution via W | 2, where the previous distribution via liquidity on beW | 2, as well as the previous distribution variance (m \u00b2 i = 1N))) q (W | 1, 2) (2), where Id is an optimal identity matrix and 0% Rd is a d-dimensional vector of all s."}, {"heading": "2.3 Empirical Bayes method", "text": "In fact, it is not that we are able to put ourselves at the top, but that we put ourselves at the top of society. (...) We have to put ourselves at the top of society. (...) We have to put ourselves at the top of society. (...) We have to put ourselves at the top of society. (...) We have to put ourselves at the top of society. (...) We have to put ourselves at the top of society. (...) We have to put ourselves at the top of society. (...) We have to put ourselves at the top of society. (...) We have to put ourselves at the top of society. (...) We have to put ourselves at the top of society. (...)"}, {"heading": "3. Multi-convex Optimization", "text": "In this section we first show that (5) can be converted into a multi-convex optimization problem. A multi-convex function is a generalization of a bi-convex function (Gorski et al., 2007) into multiple variables or variable blocks. Definition 3.1 (multi-convex function (Xu and Yin, 2013). A function g (x1,..., xk) is called multi-convex if for each variable block xi, g is a convex function of xi, while all other variable blocks remain fixed."}, {"heading": "3.1 Multi-convex Formulation", "text": "It is not difficult to see that the optimization problem in (5) is not convex, as we analyzed it in the last section. To solve these technical problems, we introduce a limitation of the constraints in the constraints that consist of (1) and (2). More specifically, instead of restricting it to (1) 0 and (2) 0, we make 1uId (1) 1l Id and (1) 1uIm (2) 1l Im, where u > l > 0 are constants. One can understand this constraint to imply a uniform prior distribution p (1, 2) over the objective set by the constraint. Technically, the constraints of the constraints of the constraints of the constraints make the feasible rates for (1) and (2) compact, i.e. by the extreme value of the theoretical minimum."}, {"heading": "3.2 Block Coordinate Minimization", "text": "Based on the multi-convex formulation developed in the last section, we propose a changing direction algorithm that provides block-by-block minimization to optimize the goal specified in (6). In each iteration k, we alternatively minimize the value of W with \"1\" and \"2,\" then minimize the value of \"1\" with \"W\" and \"2,\" and finally minimize \"2\" with \"W\" and \"1.\" The entire procedure is repeated until a stationary point is found or the reduction of the objective function is less than a pre-determined threshold. In the following, we assume that n = ni, \"i [m] is used to simplify notation. Let Y = (y1,.., ym)\" Rn \u00b7 m \"be the label matrix and\" Rn \u00b7 d \"be the feature matrix common to all tasks."}, {"heading": "3.2.1 OPTIMIZATION W.R.T W", "text": "The first guarantees that we can find an exact solution in closed form in O (m3d3) time by using the isomorphism between Rd \u00b7 m and Rdm; the second makes it possible to find gradients with fixed step size, and we show that in our case a linear convergence velocity can be guaranteed; the third finds the optimal solution by solving the Sylvester equation (Bartels and Stewart, 1972)."}, {"heading": "3.2.2 OPTIMIZATION W.R.T. \u03a31 AND \u03a32", "text": "Before delving into the detailed analysis, we will first list the final algorithms we use to optimize the problem (1 and 2 in Alg. 1 and 2 in Alg. 2), which are remarkably simple: each algorithm contains only one SVD, one truncation, and two matrix multiplications; the computational complexity of Alg. 1 (Alg. 2) is limited by O (m2d + md2 + d3) (O (m2d + md2 + m3)); algorithm 1 minimize 1 input: W, 2 and l, u.1: [V, k.]."}, {"heading": "4. Experiments", "text": "In this section, we analyze the statistical performance of FETR and the efficiency of the proposed coordinate minimization algorithm to solve the underlying multi-convex optimization problem."}, {"heading": "4.1 Convergence Analysis", "text": "For this purpose, we generate a synthetic dataset for each experiment consisting of n = 104 instances divided between all the tasks. All instances are randomly unified from [0, 1] d. We gradually increase the dimension of the characteristics, d, and the number of tasks, m, to test scalability; the first algorithm implements the closed form solution (21) by explicitly calculating the d \u00b7 md tensor product matrix and then solving the linear system; the second is the proposed gradient descent, the stop condition of which is met if either the standard of the gradient has passed less than 0.01 or the algorithm has passed more than 50 iterations; the last uses the Bartels-Stewart algorithm to solve the equivalent Sylvester equation to compile W."}, {"heading": "4.2 Synthetic Toy Problem", "text": "Before proceeding with experiments on real data sets, we create a toy data set and perform a synthetic experiment to show that the proposed model can learn the relationships between task vectors and feature detectors simultaneously. We randomly generate 10 data points uniformly from the range [0, 100] 2. We consider the following three regression tasks: y1 = 10x1 + 10x2 + 10, y2 \u2212 0 and y3 = \u2212 8x1 \u2212 8x2 \u2212 8. The results of these regression functions are corrupted by Gaussian noise with mean 0 and variance 1. The true weight matrix is expressed by W \u043c = (10 0 \u2212 8 10 0 \u2212 8) For this problem, the first row of W \u00b2 corresponds to the weight vector of function x1 across the tasks and the second row corresponds to the weight vector of x2. Each column represents a task vector. Therefore, we expect the correlation between x1 and x2 to be 0.0 and function, and we expect the relationship between the first row and x1 to be 0.0."}, {"heading": "4.3 Robot Inverse Dynamics", "text": "We have made it our mission that we will be able to change the world, \"he told the German Press Agency in an interview with\" Welt am Sonntag. \"\" We have managed to get a grip on the world, \"he said,\" but we have not managed to get a grip on the world. \"He added:\" We have managed to get a grip on the world, but we have not managed to get a grip on the world. \""}, {"heading": "5. Related Work", "text": "In fact, it is a way in which people are able to determine for themselves how they want to behave."}, {"heading": "6. Discussion and future work", "text": "We are developing a multi-convex framework for multi-task learning that improves prediction by learning both between tasks and between characteristics. Our framework is a generalization of related approaches to multi-task learning that either learn task relationships or have relationships. We are developing a multi-convex formulation of the problem and an algorithm for block-by-block coordinative minimization. By using the theory of double stochastic matrices, we are able to reduce the underlying partial problem of matrix optimization to a minimum of perfectly fitting problems on a complete two-sided diagram and solve it in a closed form. Our method is orders of magnitude faster than a standard projected gradient descending method, and it shows improved performance on synthetic datasets as well as on a real dataset for robotic modeling. While the current work discusses our approach in the context of linear regression, it can be expanded to other types of pre-logistic regression, such as SVR."}, {"heading": "Appendix A. Proofs", "text": "The objective function in (6) is multiconvex. In the first place, it is easy to verify whether the objective function with respect to (2) the objective function with respect to (2) the objective function with respect to (2) the objective function with respect to (2) the objective function with respect to (2) the objective function with respect to (2) the objective function with respect to (2) the objective function with respect to (2) the objective function with respect to (2) the objective function with respect to (2)."}], "references": [{"title": "A spectral regularization framework for multi-task structure learning", "author": ["A. Argyriou", "M. Pontil", "Y. Ying", "C.A. Micchelli"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Argyriou et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Argyriou et al\\.", "year": 2007}, {"title": "Convex multi-task feature learning", "author": ["A. Argyriou", "T. Evgeniou", "M. Pontil"], "venue": "Machine Learning,", "citeRegEx": "Argyriou et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Argyriou et al\\.", "year": 2008}, {"title": "Solution of the matrix equation AX+ XB= C [F4", "author": ["R.H. Bartels", "G. Stewart"], "venue": "Communications of the ACM,", "citeRegEx": "Bartels and Stewart.,? \\Q1972\\E", "shortCiteRegEx": "Bartels and Stewart.", "year": 1972}, {"title": "Introduction to linear optimization, volume 6", "author": ["D. Bertsimas", "J.N. Tsitsiklis"], "venue": "Athena Scientific Belmont, MA,", "citeRegEx": "Bertsimas and Tsitsiklis.,? \\Q1997\\E", "shortCiteRegEx": "Bertsimas and Tsitsiklis.", "year": 1997}, {"title": "How and why to solve the operator equation ax- xb=", "author": ["R. Bhatia", "P. Rosenthal"], "venue": "y. Bulletin of the London Mathematical Society,", "citeRegEx": "Bhatia and Rosenthal.,? \\Q1997\\E", "shortCiteRegEx": "Bhatia and Rosenthal.", "year": 1997}, {"title": "Kernel multi-task learning using task-specific features", "author": ["E.V. Bonilla", "F.V. Agakov", "C. Williams"], "venue": "In International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "Bonilla et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Bonilla et al\\.", "year": 2007}, {"title": "Multi-task gaussian process prediction", "author": ["E.V. Bonilla", "K.M. Chai", "C. Williams"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Bonilla et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Bonilla et al\\.", "year": 2007}, {"title": "Bayes and empirical bayes methods for data analysis", "author": ["B.P. Carlin", "T.A. Louis"], "venue": "Statistics and Computing,", "citeRegEx": "Carlin and Louis.,? \\Q1997\\E", "shortCiteRegEx": "Carlin and Louis.", "year": 1997}, {"title": "Multitask learning", "author": ["R. Caruana"], "venue": "Machine learning,", "citeRegEx": "Caruana.,? \\Q1997\\E", "shortCiteRegEx": "Caruana.", "year": 1997}, {"title": "Notes on birkhoff\u2013von neumann decomposition of doubly stochastic matrices", "author": ["F. Dufoss\u00e9", "B. U\u00e7ar"], "venue": "Linear Algebra and its Applications,", "citeRegEx": "Dufoss\u00e9 and U\u00e7ar.,? \\Q2016\\E", "shortCiteRegEx": "Dufoss\u00e9 and U\u00e7ar.", "year": 2016}, {"title": "Multi-task feature learning", "author": ["A. Evgeniou", "M. Pontil"], "venue": "Advances in neural information processing systems,", "citeRegEx": "Evgeniou and Pontil.,? \\Q2007\\E", "shortCiteRegEx": "Evgeniou and Pontil.", "year": 2007}, {"title": "Regularized multi\u2013task learning", "author": ["T. Evgeniou", "M. Pontil"], "venue": "In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "Evgeniou and Pontil.,? \\Q2004\\E", "shortCiteRegEx": "Evgeniou and Pontil.", "year": 2004}, {"title": "Learning multiple tasks with kernel methods", "author": ["T. Evgeniou", "C.A. Micchelli", "M. Pontil"], "venue": "In Journal of Machine Learning Research,", "citeRegEx": "Evgeniou et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Evgeniou et al\\.", "year": 2005}, {"title": "Biconvex sets and optimization with biconvex functions: a survey and extensions", "author": ["J. Gorski", "F. Pfeuffer", "K. Klamroth"], "venue": "Mathematical Methods of Operations Research,", "citeRegEx": "Gorski et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Gorski et al\\.", "year": 2007}, {"title": "Matrix variate distributions, volume 104", "author": ["A.K. Gupta", "D.K. Nagar"], "venue": "CRC Press,", "citeRegEx": "Gupta and Nagar.,? \\Q1999\\E", "shortCiteRegEx": "Gupta and Nagar.", "year": 1999}, {"title": "Multi-task learning via conic programming", "author": ["T. Kato", "H. Kashima", "M. Sugiyama", "K. Asai"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Kato et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Kato et al\\.", "year": 2008}, {"title": "Multi-task model and feature joint learning", "author": ["Y. Li", "X. Tian", "T. Liu", "D. Tao"], "venue": "In Proceedings of the 24th International Conference on Artificial Intelligence,", "citeRegEx": "Li et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Li et al\\.", "year": 2015}, {"title": "Multi-task feature learning via efficient l 2, 1-norm minimization", "author": ["J. Liu", "S. Ji", "J. Ye"], "venue": "In Proceedings of the twenty-fifth conference on uncertainty in artificial intelligence,", "citeRegEx": "Liu et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2009}, {"title": "Introductory lectures on convex optimization: A basic course, volume 87", "author": ["Y. Nesterov"], "venue": "Springer Science & Business Media,", "citeRegEx": "Nesterov.,? \\Q2013\\E", "shortCiteRegEx": "Nesterov.", "year": 2013}, {"title": "An introduction to the conjugate gradient method without the agonizing pain", "author": ["J.R. Shewchuk"], "venue": null, "citeRegEx": "Shewchuk,? \\Q1994\\E", "shortCiteRegEx": "Shewchuk", "year": 1994}, {"title": "Explanation-based neural network learning. In Explanation-Based Neural Network Learning, pages 19\u201348", "author": ["S. Thrun"], "venue": null, "citeRegEx": "Thrun.,? \\Q1996\\E", "shortCiteRegEx": "Thrun.", "year": 1996}, {"title": "Is earning the n-th thing any easier than learning the first? Advances in neural information processing", "author": ["S. Thrun"], "venue": null, "citeRegEx": "Thrun.,? \\Q1996\\E", "shortCiteRegEx": "Thrun.", "year": 1996}, {"title": "A block coordinate descent method for regularized multiconvex optimization with applications to nonnegative tensor factorization and completion", "author": ["Y. Xu", "W. Yin"], "venue": "SIAM Journal on imaging sciences,", "citeRegEx": "Xu and Yin.,? \\Q2013\\E", "shortCiteRegEx": "Xu and Yin.", "year": 2013}, {"title": "Learning gaussian processes from multiple tasks", "author": ["K. Yu", "V. Tresp", "A. Schwaighofer"], "venue": "In Proceedings of the 22nd international conference on Machine learning,", "citeRegEx": "Yu et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Yu et al\\.", "year": 2005}, {"title": "Learning multiple tasks with a sparse matrix-normal penalty", "author": ["Y. Zhang", "J.G. Schneider"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Zhang and Schneider.,? \\Q2010\\E", "shortCiteRegEx": "Zhang and Schneider.", "year": 2010}, {"title": "A convex formulation for learning task relationships in multi-task learning", "author": ["Y. Zhang", "D.-Y. Yeung"], "venue": null, "citeRegEx": "Zhang and Yeung.,? \\Q2010\\E", "shortCiteRegEx": "Zhang and Yeung.", "year": 2010}, {"title": "Multi-task learning using generalized t process", "author": ["Y. Zhang", "D.-Y. Yeung"], "venue": "In AISTATS,", "citeRegEx": "Zhang and Yeung.,? \\Q2010\\E", "shortCiteRegEx": "Zhang and Yeung.", "year": 2010}], "referenceMentions": [{"referenceID": 8, "context": "Introduction Multi-task learning has received considerable interest in the past decades (Caruana, 1997; Evgeniou and Pontil, 2004; Argyriou et al., 2007, 2008; Kato et al., 2008; Liu et al., 2009; Zhang and Yeung, 2010a; Zhang and Schneider, 2010; Li et al., 2015).", "startOffset": 88, "endOffset": 264}, {"referenceID": 11, "context": "Introduction Multi-task learning has received considerable interest in the past decades (Caruana, 1997; Evgeniou and Pontil, 2004; Argyriou et al., 2007, 2008; Kato et al., 2008; Liu et al., 2009; Zhang and Yeung, 2010a; Zhang and Schneider, 2010; Li et al., 2015).", "startOffset": 88, "endOffset": 264}, {"referenceID": 15, "context": "Introduction Multi-task learning has received considerable interest in the past decades (Caruana, 1997; Evgeniou and Pontil, 2004; Argyriou et al., 2007, 2008; Kato et al., 2008; Liu et al., 2009; Zhang and Yeung, 2010a; Zhang and Schneider, 2010; Li et al., 2015).", "startOffset": 88, "endOffset": 264}, {"referenceID": 17, "context": "Introduction Multi-task learning has received considerable interest in the past decades (Caruana, 1997; Evgeniou and Pontil, 2004; Argyriou et al., 2007, 2008; Kato et al., 2008; Liu et al., 2009; Zhang and Yeung, 2010a; Zhang and Schneider, 2010; Li et al., 2015).", "startOffset": 88, "endOffset": 264}, {"referenceID": 24, "context": "Introduction Multi-task learning has received considerable interest in the past decades (Caruana, 1997; Evgeniou and Pontil, 2004; Argyriou et al., 2007, 2008; Kato et al., 2008; Liu et al., 2009; Zhang and Yeung, 2010a; Zhang and Schneider, 2010; Li et al., 2015).", "startOffset": 88, "endOffset": 264}, {"referenceID": 16, "context": "Introduction Multi-task learning has received considerable interest in the past decades (Caruana, 1997; Evgeniou and Pontil, 2004; Argyriou et al., 2007, 2008; Kato et al., 2008; Liu et al., 2009; Zhang and Yeung, 2010a; Zhang and Schneider, 2010; Li et al., 2015).", "startOffset": 88, "endOffset": 264}, {"referenceID": 8, "context": "Another strand of work assumes common feature representations to be shared among multiple tasks, and the goal is to learn the shared representation as well as task-specific parameters simultaneously (Thrun, 1996a; Caruana, 1997; Evgeniou and Pontil, 2007; Argyriou et al., 2008).", "startOffset": 199, "endOffset": 278}, {"referenceID": 10, "context": "Another strand of work assumes common feature representations to be shared among multiple tasks, and the goal is to learn the shared representation as well as task-specific parameters simultaneously (Thrun, 1996a; Caruana, 1997; Evgeniou and Pontil, 2007; Argyriou et al., 2008).", "startOffset": 199, "endOffset": 278}, {"referenceID": 1, "context": "Another strand of work assumes common feature representations to be shared among multiple tasks, and the goal is to learn the shared representation as well as task-specific parameters simultaneously (Thrun, 1996a; Caruana, 1997; Evgeniou and Pontil, 2007; Argyriou et al., 2008).", "startOffset": 199, "endOffset": 278}, {"referenceID": 11, "context": ", 2007a) or a task similarity graph (Evgeniou and Pontil, 2004), regularizers can often be incorporated into the learning formulation to explicitly penalize hypotheses that are not consistent with the given structure.", "startOffset": 36, "endOffset": 63}, {"referenceID": 1, "context": "There have been several attempts to improve predictions along this direction by either learning the relationships between different tasks (Zhang and Yeung, 2010a), known as Multi-Task Relationship Learning (MTRL), or by exploiting the relationships between different features (Argyriou et al., 2008), which is known as Multi-Task Feature Learning (MTFL).", "startOffset": 276, "endOffset": 299}, {"referenceID": 24, "context": "Compared to the sparse regularization approach in Zhang and Schneider (2010), our framework is free of the sparsity assumption, and as a result, it admits an efficient optimization scheme where we are able to derive analytic solutions to each subproblem, whereas in (Zhang and Schneider, 2010) iterative methods have to be used for each subproblem.", "startOffset": 266, "endOffset": 293}, {"referenceID": 0, "context": "There have been several attempts to improve predictions along this direction by either learning the relationships between different tasks (Zhang and Yeung, 2010a), known as Multi-Task Relationship Learning (MTRL), or by exploiting the relationships between different features (Argyriou et al., 2008), which is known as Multi-Task Feature Learning (MTFL). Zhang and Schneider (2010) proposed a multi-task learning framework where both the task and feature relationships are inferred from data by assuming a sparse matrix-normal penalty on both the task and feature representations.", "startOffset": 277, "endOffset": 382}, {"referenceID": 0, "context": "There have been several attempts to improve predictions along this direction by either learning the relationships between different tasks (Zhang and Yeung, 2010a), known as Multi-Task Relationship Learning (MTRL), or by exploiting the relationships between different features (Argyriou et al., 2008), which is known as Multi-Task Feature Learning (MTFL). Zhang and Schneider (2010) proposed a multi-task learning framework where both the task and feature relationships are inferred from data by assuming a sparse matrix-normal penalty on both the task and feature representations. As in that paper, our multi-task learning framework is a generalization of both MTRL and MTFL, which learns the relationships both between tasks and between features simultaneously. This property is favorable for applications where we not only aim for better generalization, but also seek to have a clear understanding about the relationships among different tasks. Compared to the sparse regularization approach in Zhang and Schneider (2010), our framework is free of the sparsity assumption, and as a result, it admits an efficient optimization scheme where we are able to derive analytic solutions to each subproblem, whereas in (Zhang and Schneider, 2010) iterative methods have to be used for each subproblem.", "startOffset": 277, "endOffset": 1024}, {"referenceID": 7, "context": "We apply an empirical Bayes (Carlin and Louis, 1997) method to approximate the exact posterior distribution, leading to a learning formulation where the goal is to optimize over both the model parameters, i.", "startOffset": 28, "endOffset": 52}, {"referenceID": 14, "context": "The form of q(W | \u03a91,\u03a92) is given by q(W | \u03a91,\u03a92) =MN d\u00d7m(W | 0d\u00d7m,\u03a91,\u03a92) where MN d\u00d7m(M,A,B) denotes a matrix-variate normal distribution (Gupta and Nagar, 1999) with mean M \u2208 Rd\u00d7m, row covariance matrix A \u2208 S++ and column covariance matrix B \u2208 S++.", "startOffset": 139, "endOffset": 162}, {"referenceID": 17, "context": "It is worth pointing out that one can specify other forms of prior distributions instead of (2), as in (Liu et al., 2009) and (Zhang and Yeung, 2010b) where the authors use a Laplacian prior and a generalized t process, respectively.", "startOffset": 103, "endOffset": 121}, {"referenceID": 13, "context": "A multi-convex function is a generalization of a bi-convex function (Gorski et al., 2007) into multiple variables or blocks of variables.", "startOffset": 68, "endOffset": 89}, {"referenceID": 22, "context": "1 (Multi-convex function (Xu and Yin, 2013)).", "startOffset": 25, "endOffset": 43}, {"referenceID": 2, "context": "The third one finds the optimal solution by solving the Sylvester equation (Bartels and Stewart, 1972) characterized by the first-order optimality condition, after a proper transformation.", "startOffset": 75, "endOffset": 102}, {"referenceID": 4, "context": "In the field of control theory, a Sylvester equation (Bhatia and Rosenthal, 1997) is a matrix equation of the form AX + XB = C, where the goal is to find a solution matrix X given A,B and C.", "startOffset": 53, "endOffset": 81}, {"referenceID": 2, "context": "For example, the BartelsStewart algorithm (Bartels and Stewart, 1972) solves the Sylvester equation by first transforming A and B into Schur forms by QR factorization, and then solves the resulting triangular system via back-substitution.", "startOffset": 42, "endOffset": 69}, {"referenceID": 16, "context": "Our proof technique is adapted from Nesterov (2013) where we extend it to matrix function.", "startOffset": 36, "endOffset": 52}, {"referenceID": 9, "context": "Surprisingly, we can find a closed form optimal solution to this problem as well, using tools from the theory of doubly stochastic matrices (Dufoss\u00e9 and U\u00e7ar, 2016) and perfect bipartite graph matching.", "startOffset": 140, "endOffset": 164}, {"referenceID": 9, "context": "Since K is an orthonormal matrix, we have the following two equations: \u2211d j=1 Pij = \u2211d j=1K 2 ij = 1, \u2200i \u2208 [d], \u2211d i=1 Pij = \u2211d i=1K 2 ij = 1, \u2200j \u2208 [d], which implies that P is a doubly stochastic matrix (Dufoss\u00e9 and U\u00e7ar, 2016).", "startOffset": 204, "endOffset": 228}, {"referenceID": 3, "context": "2 (Optimality of extreme points (Bertsimas and Tsitsiklis, 1997)).", "startOffset": 32, "endOffset": 64}, {"referenceID": 10, "context": "We compare FETR with multi-task feature learning (Evgeniou and Pontil, 2007) (MTFL) and multitask relationship learning (Zhang and Yeung, 2010a) (MTRL), which can be treated as two different special cases of our model.", "startOffset": 49, "endOffset": 76}, {"referenceID": 8, "context": "Multi-task learning is an area of active research in machine learning and has received a lot of attention in the past years (Thrun, 1996b; Caruana, 1997; Yu et al., 2005; Bonilla et al., 2007a,b; Argyriou et al., 2007, 2008; Zhang and Yeung, 2010a).", "startOffset": 124, "endOffset": 248}, {"referenceID": 23, "context": "Multi-task learning is an area of active research in machine learning and has received a lot of attention in the past years (Thrun, 1996b; Caruana, 1997; Yu et al., 2005; Bonilla et al., 2007a,b; Argyriou et al., 2007, 2008; Zhang and Yeung, 2010a).", "startOffset": 124, "endOffset": 248}, {"referenceID": 8, "context": "Early work focuses on sharing knowledge in separate tasks by sharing hidden representations, for example, hidden layer of units in neural networks (Caruana, 1997).", "startOffset": 147, "endOffset": 162}, {"referenceID": 12, "context": "Covariance matrices in MTFL and MTRL are not restricted to have specific parametrized forms, and from this perspective, (Evgeniou et al., 2005; Evgeniou and Pontil, 2004; Kato et al., 2008) can be understood as special cases of MTFL and MTRL where the covariance matrices are constrained to be (weighted) graph Laplacians.", "startOffset": 120, "endOffset": 189}, {"referenceID": 11, "context": "Covariance matrices in MTFL and MTRL are not restricted to have specific parametrized forms, and from this perspective, (Evgeniou et al., 2005; Evgeniou and Pontil, 2004; Kato et al., 2008) can be understood as special cases of MTFL and MTRL where the covariance matrices are constrained to be (weighted) graph Laplacians.", "startOffset": 120, "endOffset": 189}, {"referenceID": 15, "context": "Covariance matrices in MTFL and MTRL are not restricted to have specific parametrized forms, and from this perspective, (Evgeniou et al., 2005; Evgeniou and Pontil, 2004; Kato et al., 2008) can be understood as special cases of MTFL and MTRL where the covariance matrices are constrained to be (weighted) graph Laplacians.", "startOffset": 120, "endOffset": 189}, {"referenceID": 0, "context": ", 2007a,b; Argyriou et al., 2007, 2008; Zhang and Yeung, 2010a). Research on multi-task learning has been carried in several strands. Early work focuses on sharing knowledge in separate tasks by sharing hidden representations, for example, hidden layer of units in neural networks (Caruana, 1997). Another stream of works constructs a Gaussian process prior over the regression functions in different tasks and the transfer of knowledge between tasks is enforced by the structure of the covariance functions/kernels of the Gaussian process prior. Bonilla et al. (2007a) presents a kernel multi-task learning approach with Gaussian process prior where task-specific features are assumed to be available.", "startOffset": 11, "endOffset": 570}, {"referenceID": 0, "context": ", 2007a,b; Argyriou et al., 2007, 2008; Zhang and Yeung, 2010a). Research on multi-task learning has been carried in several strands. Early work focuses on sharing knowledge in separate tasks by sharing hidden representations, for example, hidden layer of units in neural networks (Caruana, 1997). Another stream of works constructs a Gaussian process prior over the regression functions in different tasks and the transfer of knowledge between tasks is enforced by the structure of the covariance functions/kernels of the Gaussian process prior. Bonilla et al. (2007a) presents a kernel multi-task learning approach with Gaussian process prior where task-specific features are assumed to be available. They concatenate the feature for input instance with the task feature and then define a kernel covariance function over the regression functions among different tasks. The learning is reduced to inferring the hyperparameters of the kernel function by maximizing the marginal log-likelihood of the instances by either EM or gradient ascent. This approach essentially decomposes the joint kernel function over regression functions into two separate kernels: one measures the similarity among tasks and the other measures the similarity among instances. A closely related approach in this strand is to consider a nonparametric kernel matrix over the tasks rather than a parametrized kernel function (Bonilla et al., 2007b). However, the kernel over input instances is still restricted to be parametrized in order to avoid the expensive computation of semidefinite programming over input features. In contrast, FETR optimizes both of the feature and task covariance matrices directly without assumption about their parametrized forms. Argyriou et al. (2008) and (Zhang and Yeung, 2010a) develop MTFL and MTRL, which can be viewed as convex frameworks of learning the feature and the task-relatedness covariance matrices, respectively.", "startOffset": 11, "endOffset": 1757}, {"referenceID": 0, "context": ", 2007a,b; Argyriou et al., 2007, 2008; Zhang and Yeung, 2010a). Research on multi-task learning has been carried in several strands. Early work focuses on sharing knowledge in separate tasks by sharing hidden representations, for example, hidden layer of units in neural networks (Caruana, 1997). Another stream of works constructs a Gaussian process prior over the regression functions in different tasks and the transfer of knowledge between tasks is enforced by the structure of the covariance functions/kernels of the Gaussian process prior. Bonilla et al. (2007a) presents a kernel multi-task learning approach with Gaussian process prior where task-specific features are assumed to be available. They concatenate the feature for input instance with the task feature and then define a kernel covariance function over the regression functions among different tasks. The learning is reduced to inferring the hyperparameters of the kernel function by maximizing the marginal log-likelihood of the instances by either EM or gradient ascent. This approach essentially decomposes the joint kernel function over regression functions into two separate kernels: one measures the similarity among tasks and the other measures the similarity among instances. A closely related approach in this strand is to consider a nonparametric kernel matrix over the tasks rather than a parametrized kernel function (Bonilla et al., 2007b). However, the kernel over input instances is still restricted to be parametrized in order to avoid the expensive computation of semidefinite programming over input features. In contrast, FETR optimizes both of the feature and task covariance matrices directly without assumption about their parametrized forms. Argyriou et al. (2008) and (Zhang and Yeung, 2010a) develop MTFL and MTRL, which can be viewed as convex frameworks of learning the feature and the task-relatedness covariance matrices, respectively. Both MTFL and MTRL are essentially convex regularization methods that exploit the feature and task relatedness by imposing trace constraints on W after proper transformations. Covariance matrices in MTFL and MTRL are not restricted to have specific parametrized forms, and from this perspective, (Evgeniou et al., 2005; Evgeniou and Pontil, 2004; Kato et al., 2008) can be understood as special cases of MTFL and MTRL where the covariance matrices are constrained to be (weighted) graph Laplacians. However, in MTFL only the feature covariance matrix is being optimized and the task-relatedness covariance matrix is assumed to be the identity, while in MTRL only the task-relatedness covariance matrix is being optimized and the feature covariance matrix is, again, assumed to be the identity. We take inspiration from these two previous works and propose a general regularization framework, FETR, that models and optimizes both task and feature relationships directly. It is worth emphasizing here that both MTFL and MTRL can be treated as special cases of FETR where one of the two covariance matrices are assumed to be the identity, which corresponds to left/right spherical matrix normal distributions. The objective function of FETR is not convex, but multi-convex. Efficient coordinate-wise minimization algorithm with closed form solutions for each subproblem is designed to tackle the multi-convex objective in FETR. Perhaps the most related work to FETR is Zhang and Schneider (2010). Both that work and our approach consider a multi-task learning framework where both the task and feature covariance matrices are inferred from data.", "startOffset": 11, "endOffset": 3427}, {"referenceID": 24, "context": "This makes our approach computationally more efficient than the one used in Zhang and Schneider (2010), and statistically our approach makes less assumption than the framework proposed in Zhang and Schneider (2010).", "startOffset": 76, "endOffset": 103}, {"referenceID": 24, "context": "This makes our approach computationally more efficient than the one used in Zhang and Schneider (2010), and statistically our approach makes less assumption than the framework proposed in Zhang and Schneider (2010).", "startOffset": 76, "endOffset": 215}], "year": 2017, "abstractText": "In this paper we propose a multi-convex framework for multi-task learning that improves predictions by learning relationships both between tasks and between features. Our framework is a generalization of related methods in multi-task learning, that either learn task relationships, or feature relationships, but not both. We start with a hierarchical Bayesian model, and use the empirical Bayes method to transform the underlying inference problem into a multi-convex optimization problem. We propose a coordinate-wise minimization algorithm that has a closed form solution for each block subproblem. Naively these solutions would be expensive to compute, but by using the theory of doubly stochastic matrices, we are able to reduce the underlying matrix optimization subproblem into a minimum weight perfect matching problem on a complete bipartite graph, and solve it analytically and efficiently. To solve the weight learning subproblem, we propose three different strategies, including a gradient descent method with linear convergence guarantee when the instances are not shared by multiple tasks, and a numerical solution based on Sylvester equation when instances are shared. We demonstrate the efficiency of our method on both synthetic datasets and real-world datasets. Experiments show that the proposed optimization method is orders of magnitude faster than an off-the-shelf projected gradient method, and our model is able to exploit the correlation structures among multiple tasks and features.", "creator": "LaTeX with hyperref package"}}}