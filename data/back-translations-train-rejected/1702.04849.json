{"id": "1702.04849", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Feb-2017", "title": "Theoretical and Practical Advances on Smoothing for Extensive-Form Games", "abstract": "Sparse iterative methods, in particular first-order methods, are known to be among the most effective in solving large-scale two-player zero-sum extensive-form games. The convergence rates of these methods depend heavily on the properties of the distance-generating function that they are based on. We investigate the acceleration of first-order methods for solving extensive-form games through better design of the dilated entropy function---a class of distance-generating functions related to the domains associated with the extensive-form games. By introducing a new weighting scheme for the dilated entropy function, we develop the first distance-generating function for the strategy spaces of sequential games that has no dependence on the branching factor of the player. This result improves the convergence rate of several first-order methods by a factor of $\\Omega(b^dd)$, where $b$ is the branching factor of the player, and $d$ is the depth of the game tree.", "histories": [["v1", "Thu, 16 Feb 2017 03:39:07 GMT  (58kb,D)", "https://arxiv.org/abs/1702.04849v1", null], ["v2", "Tue, 9 May 2017 02:24:32 GMT  (4893kb,D)", "http://arxiv.org/abs/1702.04849v2", null]], "reviews": [], "SUBJECTS": "cs.GT cs.AI", "authors": ["christian kroer", "kevin waugh", "fatma kilinc-karzan", "tuomas sandholm"], "accepted": false, "id": "1702.04849"}, "pdf": {"name": "1702.04849.pdf", "metadata": {"source": "CRF", "title": "Theoretical and Practical Advances on Smoothing for Extensive-Form Games", "authors": ["Christian Kroer", "Kevin Waugh"], "emails": ["ckroer@cs.cmu.edu", "kevin.waugh@gmail.com", "fkilinc@andrew.cmu.edu", "sandholm@cs.cmu.edu"], "sections": [{"heading": null, "text": "So far, counterfactual repentance minimization methods have been faster and more popular in practice than first-order methods, despite their theoretically inferior convergence rates. Using our new weighting scheme and practical tuning, we show that excessive gap technology can be made faster in practice for the first time than the fastest counterfactual repentance minimization algorithm, CFR +."}, {"heading": "1 Introduction", "text": "In recent years, it has become clear that the problem is a global problem, which is a global problem, which is primarily a global problem, namely a global, a global, a global, a global, a global, a global, a global, a global, a global, a global, a global, a global, a global, a global, a global, a global, a global, a global, a global, a global, a global, a global, a global, a global, a global, a global, a global, a global, a global, a global, a global, a global, a global, a global, a global, a global, a global, a global, a global, a global, a global, a global, a global, a global, o, a global, a global, a global, a global, an o, a global, a global, a, a global, a, a global, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a"}, {"heading": "2 Related work", "text": "Nash equilibrium computation has received extensive attention in the literature [Littman and Stone, 2003, Lipton et al., 2003, Gilpin and Sandholm, 2007, Zinkevich et al., 2007, Daskalakis et al., 2009, Jiang and Leyton-Brown, 2011, Kroer and Sandholm, 2014, Daskalakis et al., 2015]. Balance finding problems vary quite widely due to their characteristics; here we limit our attention to two-player zero-sum sequence games. Koller et al. [1996] present an LP whose size is linear in the size of the game tree. This approach, coupled with lossless abstraction techniques, has been used to solve Rhode Island hold'em [Shi and Littman, 2002, Gilpin and Sandholm, 2007], a game with 3.1 billion knots (approximately size 5 \u00b7 107 according to lossless abstraction)."}, {"heading": "3 Problem setup", "text": "Calculation of a Nash equilibrium in a two-player zero-sum EFG with perfect recall can be formulated as a two-dimensional saddle point problem (BSPP): min x-X max y-Y < x, Ay > = max y-Y min x-X < x, Ay >. (1) This is known as sequential formulation [Romanovskii, 1962, Koller et al., 1996, von Stengel, 1996]. In this formulation, x and y correspond to the non-negative strategy vectors for players 1 and 2 and the quantities X, Y are convex polyhedral reformulations of the sequential strategy space of these players. Here, X, Y are defined by the constraints Ex = e, Fy = f, with each series of E, F encoding part of the sequential nature of the strategy vectors, the right-sided vectors e, f are | I1 | I-2 | -dimensional FG, and we find the complete structure of the IP for the development of the results."}, {"heading": "3.1 Basic notation", "text": "We let < x, y > specify the internal standard product of the vectors x, y. If we specify a vector x-Rn, we let it specify its \"p-norm,\" which is given by the vector x-p: = (\u2211 n i = 1 | xi | p) 1 / p for p-1 [1, \u221e) and vice versa: = maxi-x-p: = maxi-n [n] | xi | for p = \u221e. During this work we use the matlab notation to denote vector and matrices, i.e. [x; y] denotes the concatenation of two column vectors x, y. For a given set Q we let ri (Q) specify its relative interior. If we specify n-N, we denote the simplex-Rn: = {x-Rn +: servation n i = 1 xi = 1}."}, {"heading": "4 Optimization setup", "text": "In its most general form, a BSPP is defined as an opt: = max y Y min x X\u03c6 (x, y), (S), where X, Y non-empty convex compact clauses in the Euclidean spaces Ex, Ey and \u03c6 (x, y) = equity + < a1, x > + < a2, y > + < y, Ax >. We leave Z: = X \u00b7 Y; so? (x, y): Z \u2192 R. In connection with the EFG solution, \u03c6 (x, y) is simply the inner product specified in (1). BSPP (S) leads to two mutually dependent convex optimization problems: Opt (P) = minx X (x)."}, {"heading": "4.1 General framework for FOMs", "text": "Most FOMs that are able to solve BSPP (S) are quite flexible in terms of adapting to the geometry of the problem characterised by the X, Y and BSPP (S) domains. The following components are standard in the constellation design for such FOMs (we introduce components for X, analogue components are used for Y): \u2022 Vector standard: \u2022 Vector standard: \u2022 Vector standard: \u2022 Vector standard: \u2022 Vector standard: \u2022 Vector standard: \u2022 Vector standard: \u2022 Vector standard: \u2022 Vector standard: \u2022 Vector standard: \u2022 Vector standard: \u2022 Vector standard: \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 Vector standard: \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 Vector standard: \u2022 Vector standard: \u2022 Vector standard: \u2022 Vector standard: \u2022 Vector standard: \u2022 Vector standard: \u2022 Vector standard: \u2022 Norm: \u2022 Vector standard: \u2022 Vector standard \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 Norm: \u2022 \u2022"}, {"heading": "5 Treeplexes", "text": "It is the question of whether it is a purely formal solution or a purely formal solution. (It is the question of whether it is a purely formal solution or a purely formal solution.) It is the question of whether it is a purely formal solution. (It is the question of whether it is a purely formal solution.) It is the question of whether it is a solution. (It is the question of whether it is a solution.) It is the question of whether it is a solution. (It is the question of whether it is a solution.) It is the question of whether it is a solution. (It is the question of whether it is a solution.) It is the question of whether it is a solution. (It is the question of whether it is a solution.)"}, {"heading": "6 Dilated entropy functions with bounded strong convexity", "text": "We will show that a suitable modification of this function leads to a desirable strong convexity."}, {"heading": "6.1 Preliminary results for the proofs of our main results", "text": "Fact 1 > Fact 1: Facing a treeplex Q: (a) MQj: (b) MQ: (a) MQ: (a) MQ: (b) MQ: (b) MQ: (b) MQ: (b) MQ: (b) MQ: (c) MQj: (c) MQj: (c). The first inequality was noted in Kroer et al. [2015, Lemma 5.7]. The second follows by replacing MQ = (b) MQ = (c) for some q: (c) and inductively the terms belonging to simplexes j with MQj. The result follows because branched operations are summarized in 1.Our next observation follows from Fact 1 (a) and is advantageous by suggesting a practically useful choice of weights that can be used for Theorem 2 to arrive at Corollary 1.Fact 2."}, {"heading": "6.2 Proofs of our main theorems", "text": "The majority of the work for our strong convexity stems from the following problem, from which our strong convexity results are easily derived. (1) The enhanced entropy function with the weights satisfactory recurrence (6) fulfills the following inequality: h > 2p (q) h + 2 (2) h + 2 (2) h + 2 (2) h + 2 (2) h + 2 (4). (8) We will first apply the following inductive hypothesis about the amount of non-rotating simplexes S = {j) SQ = {j) SQ > 0 (2) pjQ > 0) for each depth d (0). (4) We will apply the following hypotheses about the amount of non-rotating simplexes S + h2p (2)."}, {"heading": "6.3 Treeplex width", "text": "The convergence rates of FOMs such as MP- and EGT-algorithms depend on the ratio of diameter to strong convexity, as described in Section 4.1. To get complete results on the convergence rates of these FOMs, we now bind this ratio using the sequence 1. Theorem 3. For a Treeplex Q, the extended entropy function with simplex weights \u03b2j = MQ (2 + \u2211 dj r = 1 2 r (MQj, r \u2212 1)) for each j-SQ results in a log, where m is the dimension of the largest Simplex-J for j-SQ in the treeplex structure."}, {"heading": "7 EGT for extensive-form game solving", "text": "We will now describe how to instantiate EGT for solving two-player zero-sum EFGs of form (1) with treeplex domains. Below, we will describe the adaptation of all definitions from Section 4 for our problem. We will use the \"1 standard for both embedding spaces Ex, Ey. Since our DGFs for X, Y are compatible with the\" 1 standard, it is immediately obvious that they are closed, convex and limited. Then, we will use the \"1 standard for both embedding spaces Ex, Ey. As our DGFs for X, Y are compatible with the\" 1 standard, we will use the advanced entropy DGF scaled with the weights from Theorem 3. Then, Theorem 3 gives our bound knowledge for XX and Y Y. Since the dual standard of the \"1 standard for the\" 2 standard is the \"the\" the \"the matrix for the\" standard."}, {"heading": "7.1 Improvements in extensive-form game convergence rate", "text": "The ratio in which the Base Treeplex products are located is an instance of the Base Treeplex operation leading to depth. 2) At each depth, a Cartesian product of size k is applied. 3) Each element in a Cartesian product is an instance of the Base Treeplex operation leading to depth. 3) Each element in a Cartesian product is an instance of the Base Treeplex branch with a Base branch leading to depth. 3) Each element in a Cartesian product is an instance of the Base Treeplex branch with a Base branch leading to depth. 3) Each element in a Cartesian product is an instance of the Base Treeplex branch with a Base branch leading to depth. 3) Each element in a Cartesian product is an instance of the Base Treeplex branch with a Base branch leading to depth."}, {"heading": "8 Numerical experiments", "text": "In fact, it is such that most of them will be able to move into another world, in which they are able to move, in which they move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they, in which they live, in which they, in which they live, in which they, in which they live, in which they, in which they, in which they live, in which they live."}, {"heading": "9 Conclusions", "text": "On the theoretical side, we analyzed the strong convexity properties of extended entropy DGF via treeplexes. By introducing specific weights linked to the structure of the treeplex, we improved previous results on the treeplex diameter from O (| SQ | MQd2d logm) to O (M2Q2dQ + 2 logm), eliminating all logarithmic dependencies associated with the branching operator. These results result in significant improvements in the convergence rates of many FOMs equipped with advanced entropy DGFs that can be used for solving EFG, including but not limited to EGT, MP, and stochastic MP.We numerically examined the performance of EGT and compared it with the practical state of the art."}, {"heading": "A Omitted proofs", "text": "For each of the two countries there is the second sequence. (11) in which the last sequence applies because the last sequence applies because k = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = j = j = j = j = j = j and j = j = j = j = j = j = j = j = j and j = j = j = j = j = j = j = j = j = j = j = j = j = j = j = k = k = k = j = j = k = j = j = k = j = j = j = j = j = k = j = j = j = j = j = j = j = j = j = j = j = j = j = j = j = j = j and j = j = k = j = j = j = j = j = j = j = j =, j = j = j = j = j = j = k = j = j = j = j = j = j = j = j = j = j = j = j = j = j = j = j = j = j = j = j = j = j =, and j = j = j = j = j = k = j = j = j = j = j = j = j = j = j = j = j = j = j = j = j = j = j = j = j = j = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q = q"}], "references": [{"title": "An exact doubleoracle algorithm for zero-sum extensive-form games with imperfect information", "author": ["Branislav Bosansky", "Christopher Kiekintveld", "Viliam Lisy", "Michal Pechoucek"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Bosansky et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bosansky et al\\.", "year": 2014}, {"title": "Heads-up limit hold\u2019em poker is solved", "author": ["Michael Bowling", "Neil Burch", "Michael Johanson", "Oskari Tammelin"], "venue": "Science,", "citeRegEx": "Bowling et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Bowling et al\\.", "year": 2015}, {"title": "Regret transfer and parameter optimization", "author": ["Noam Brown", "Tuomas Sandholm"], "venue": "In AAAI Conference on Artificial Intelligence (AAAI),", "citeRegEx": "Brown and Sandholm.,? \\Q2014\\E", "shortCiteRegEx": "Brown and Sandholm.", "year": 2014}, {"title": "Strategy-based warm starting for regret minimization in games", "author": ["Noam Brown", "Tuomas Sandholm"], "venue": "In AAAI Conference on Artificial Intelligence (AAAI),", "citeRegEx": "Brown and Sandholm.,? \\Q2016\\E", "shortCiteRegEx": "Brown and Sandholm.", "year": 2016}, {"title": "Hierarchical abstraction, distributed equilibrium computation, and post-processing, with application to a champion no-limit Texas Hold\u2019em agent", "author": ["Noam Brown", "Sam Ganzfried", "Tuomas Sandholm"], "venue": "In International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS),", "citeRegEx": "Brown et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Brown et al\\.", "year": 2015}, {"title": "Dynamic thresholding and pruning for regret minimization", "author": ["Noam Brown", "Christian Kroer", "Tuomas Sandholm"], "venue": "In AAAI Conference on Artificial Intelligence (AAAI),", "citeRegEx": "Brown et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Brown et al\\.", "year": 2017}, {"title": "The complexity of computing a nash equilibrium", "author": ["Constantinos Daskalakis", "Paul W Goldberg", "Christos H Papadimitriou"], "venue": "SIAM Journal on Computing,", "citeRegEx": "Daskalakis et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Daskalakis et al\\.", "year": 2009}, {"title": "Near-optimal no-regret algorithms for zero-sum games", "author": ["Constantinos Daskalakis", "Alan Deckelbaum", "Anthony Kim"], "venue": "Games and Economic Behavior,", "citeRegEx": "Daskalakis et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Daskalakis et al\\.", "year": 2015}, {"title": "Lossless abstraction of imperfect information games", "author": ["Andrew Gilpin", "Tuomas Sandholm"], "venue": "Journal of the ACM,", "citeRegEx": "Gilpin and Sandholm.,? \\Q2007\\E", "shortCiteRegEx": "Gilpin and Sandholm.", "year": 2007}, {"title": "First-order algorithm with O(ln(1/ )) convergence for -equilibrium in two-person zero-sum games", "author": ["Andrew Gilpin", "Javier Pe\u00f1a", "Tuomas Sandholm"], "venue": "Mathematical Programming,", "citeRegEx": "Gilpin et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Gilpin et al\\.", "year": 2012}, {"title": "Automated action abstraction of imperfect information extensive-form games", "author": ["John Hawkin", "Robert Holte", "Duane Szafron"], "venue": "In AAAI Conference on Artificial Intelligence (AAAI),", "citeRegEx": "Hawkin et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Hawkin et al\\.", "year": 2011}, {"title": "Using sliding windows to generate action abstractions in extensive-form games", "author": ["John Hawkin", "Robert Holte", "Duane Szafron"], "venue": "In AAAI Conference on Artificial Intelligence (AAAI),", "citeRegEx": "Hawkin et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Hawkin et al\\.", "year": 2012}, {"title": "Fundamentals of convex analysis", "author": ["Jean-Baptiste Hiriart-Urruty", "Claude Lemar\u00e9chal"], "venue": null, "citeRegEx": "Hiriart.Urruty and Lemar\u00e9chal.,? \\Q2001\\E", "shortCiteRegEx": "Hiriart.Urruty and Lemar\u00e9chal.", "year": 2001}, {"title": "Smoothing techniques for computing Nash equilibria of sequential games", "author": ["Samid Hoda", "Andrew Gilpin", "Javier Pe\u00f1a", "Tuomas Sandholm"], "venue": "Mathematics of Operations Research,", "citeRegEx": "Hoda et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Hoda et al\\.", "year": 2010}, {"title": "Polynomial-time computation of exact correlated equilibrium in compact games", "author": ["Albert Jiang", "Kevin Leyton-Brown"], "venue": "In Proceedings of the ACM Conference on Electronic Commerce (EC),", "citeRegEx": "Jiang and Leyton.Brown.,? \\Q2011\\E", "shortCiteRegEx": "Jiang and Leyton.Brown.", "year": 2011}, {"title": "Accelerating best response calculation in large extensive games", "author": ["Michael Johanson", "Kevin Waugh", "Michael Bowling", "Martin Zinkevich"], "venue": "In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI),", "citeRegEx": "Johanson et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Johanson et al\\.", "year": 2011}, {"title": "First order methods for nonsmooth convex large-scale optimization, i: general purpose methods", "author": ["Anatoli Juditsky", "Arkadi Nemirovski"], "venue": "Optimization for Machine Learning,", "citeRegEx": "Juditsky and Nemirovski.,? \\Q2011\\E", "shortCiteRegEx": "Juditsky and Nemirovski.", "year": 2011}, {"title": "First order methods for nonsmooth convex large-scale optimization, ii: utilizing problems structure", "author": ["Anatoli Juditsky", "Arkadi Nemirovski"], "venue": "Optimization for Machine Learning,", "citeRegEx": "Juditsky and Nemirovski.,? \\Q2011\\E", "shortCiteRegEx": "Juditsky and Nemirovski.", "year": 2011}, {"title": "Efficient computation of equilibria for extensive two-person games", "author": ["Daphne Koller", "Nimrod Megiddo", "Bernhard von Stengel"], "venue": "Games and Economic Behavior,", "citeRegEx": "Koller et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Koller et al\\.", "year": 1996}, {"title": "Extensive-form game abstraction with bounds", "author": ["Christian Kroer", "Tuomas Sandholm"], "venue": "In Proceedings of the ACM Conference on Economics and Computation (EC),", "citeRegEx": "Kroer and Sandholm.,? \\Q2014\\E", "shortCiteRegEx": "Kroer and Sandholm.", "year": 2014}, {"title": "Imperfect-recall abstractions with bounds in games", "author": ["Christian Kroer", "Tuomas Sandholm"], "venue": "In Proceedings of the ACM Conference on Economics and Computation", "citeRegEx": "Kroer and Sandholm.,? \\Q2016\\E", "shortCiteRegEx": "Kroer and Sandholm.", "year": 2016}, {"title": "Faster first-order methods for extensive-form game solving", "author": ["Christian Kroer", "Kevin Waugh", "Fatma K\u0131l\u0131n\u00e7-Karzan", "Tuomas Sandholm"], "venue": "In Proceedings of the ACM Conference on Economics and Computation (EC),", "citeRegEx": "Kroer et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kroer et al\\.", "year": 2015}, {"title": "Monte Carlo sampling for regret minimization in extensive games", "author": ["Marc Lanctot", "Kevin Waugh", "Martin Zinkevich", "Michael Bowling"], "venue": "In Proceedings of the Annual Conference on Neural Information Processing Systems (NIPS),", "citeRegEx": "Lanctot et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Lanctot et al\\.", "year": 2009}, {"title": "No-regret learning in extensive-form games with imperfect recall", "author": ["Marc Lanctot", "Richard Gibson", "Neil Burch", "Martin Zinkevich", "Michael Bowling"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "Lanctot et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Lanctot et al\\.", "year": 2012}, {"title": "Playing large games using simple strategies", "author": ["Richard Lipton", "Evangelos Markakis", "Aranyak Mehta"], "venue": "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC),", "citeRegEx": "Lipton et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Lipton et al\\.", "year": 2003}, {"title": "A polynomial-time Nash equilibrium algorithm for repeated games", "author": ["Michael Littman", "Peter Stone"], "venue": "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC),", "citeRegEx": "Littman and Stone.,? \\Q2003\\E", "shortCiteRegEx": "Littman and Stone.", "year": 2003}, {"title": "Deepstack: Expert-level artificial intelligence in no-limit poker", "author": ["Matej Morav\u010d\u0301\u0131k", "Martin Schmid", "Neil Burch", "Viliam Lis\u1ef3", "Dustin Morrill", "Nolan Bard", "Trevor Davis", "Kevin Waugh", "Michael Johanson", "Michael Bowling"], "venue": "arXiv preprint arXiv:1701.01724,", "citeRegEx": "Morav\u010d\u0301\u0131k et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Morav\u010d\u0301\u0131k et al\\.", "year": 2017}, {"title": "Prox-method with rate of convergence o (1/t) for variational inequalities with lipschitz continuous monotone operators and smooth convex-concave saddle point problems", "author": ["Arkadi Nemirovski"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "Nemirovski.,? \\Q2004\\E", "shortCiteRegEx": "Nemirovski.", "year": 2004}, {"title": "Excessive gap technique in nonsmooth convex minimization", "author": ["Yurii Nesterov"], "venue": "SIAM Journal of Optimization,", "citeRegEx": "Nesterov.,? \\Q2005\\E", "shortCiteRegEx": "Nesterov.", "year": 2005}, {"title": "Smooth minimization of non-smooth functions", "author": ["Yurii Nesterov"], "venue": "Mathematical Programming,", "citeRegEx": "Nesterov.,? \\Q2005\\E", "shortCiteRegEx": "Nesterov.", "year": 2005}, {"title": "Reduction of a game with complete memory to a matrix game", "author": ["I. Romanovskii"], "venue": "Soviet Mathematics,", "citeRegEx": "Romanovskii.,? \\Q1962\\E", "shortCiteRegEx": "Romanovskii.", "year": 1962}, {"title": "The state of solving large incomplete-information games, and application to poker", "author": ["Tuomas Sandholm"], "venue": "AI Magazine,", "citeRegEx": "Sandholm.,? \\Q2010\\E", "shortCiteRegEx": "Sandholm.", "year": 2010}, {"title": "Abstraction for solving large incomplete-information games", "author": ["Tuomas Sandholm"], "venue": "In AAAI Conference on Artificial Intelligence (AAAI),", "citeRegEx": "Sandholm.,? \\Q2015\\E", "shortCiteRegEx": "Sandholm.", "year": 2015}, {"title": "Lossy stochastic game abstraction with bounds", "author": ["Tuomas Sandholm", "Satinder Singh"], "venue": "In Proceedings of the ACM Conference on Electronic Commerce (EC),", "citeRegEx": "Sandholm and Singh.,? \\Q2012\\E", "shortCiteRegEx": "Sandholm and Singh.", "year": 2012}, {"title": "Abstraction methods for game theoretic poker", "author": ["Jiefu Shi", "Michael Littman"], "venue": "In CG \u201900: Revised Papers from the Second International Conference on Computers and Games,", "citeRegEx": "Shi and Littman.,? \\Q2002\\E", "shortCiteRegEx": "Shi and Littman.", "year": 2002}, {"title": "bluff: Opponent modelling in poker", "author": ["Finnegan Southey", "Michael Bowling", "Bryce Larson", "Carmelo Piccione", "Neil Burch", "Darse Billings", "Chris Rayner. Bayes"], "venue": "In Proceedings of the 21st Annual Conference on Uncertainty in Artificial Intelligence (UAI),", "citeRegEx": "Southey et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Southey et al\\.", "year": 2005}, {"title": "Solving heads-up limit Texas hold\u2019em", "author": ["Oskari Tammelin", "Neil Burch", "Michael Johanson", "Michael Bowling"], "venue": "In Proceedings of the 24th International Joint Conference on Artificial Intelligence (IJCAI),", "citeRegEx": "Tammelin et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Tammelin et al\\.", "year": 2015}, {"title": "Efficient computation of behavior strategies", "author": ["Bernhard von Stengel"], "venue": "Games and Economic Behavior,", "citeRegEx": "Stengel.,? \\Q1996\\E", "shortCiteRegEx": "Stengel.", "year": 1996}, {"title": "A unified view of large-scale zero-sum equilibrium computation", "author": ["Kevin Waugh", "Drew Bagnell"], "venue": "In Computer Poker and Imperfect Information Workshop at the AAAI Conference on Artificial Intelligence (AAAI),", "citeRegEx": "Waugh and Bagnell.,? \\Q2015\\E", "shortCiteRegEx": "Waugh and Bagnell.", "year": 2015}, {"title": "Regret minimization in games with incomplete information", "author": ["Martin Zinkevich", "Michael Bowling", "Michael Johanson", "Carmelo Piccione"], "venue": "In Proceedings of the Annual Conference on Neural Information Processing Systems (NIPS),", "citeRegEx": "Zinkevich et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Zinkevich et al\\.", "year": 2007}], "referenceMentions": [{"referenceID": 31, "context": "Second, even when it does, the iterations of interior-point methods or the simplex algorithm are prohibitively expensive [Sandholm, 2010].", "startOffset": 121, "endOffset": 137}, {"referenceID": 31, "context": "Practical methods for EFG solving tackle this issue through two complementary approaches: Abstraction and iterative game solvers with low memory requirements [Sandholm, 2010].", "startOffset": 158, "endOffset": 174}, {"referenceID": 27, "context": "The classical FOMs to solve BSPPs such as mirror prox (MP) [Nemirovski, 2004] or the excessive gap technique (EGT) [Nesterov, 2005a] utilize distance-generating functions (DGFs) to measure appropriate notions of distances over the domains.", "startOffset": 59, "endOffset": 77}, {"referenceID": 36, "context": "Finally, we complement our theoretical results with numerical experiments to investigate the speed up of FOMs with convergence rate O( ) and compare the performance of these algorithms with the premier regret-based methods CFR and CFR+ [Tammelin et al., 2015].", "startOffset": 236, "endOffset": 259}, {"referenceID": 12, "context": ", 2009] achieving a convergence rate on the order of O( 1 2 ), and (ii) first-order methods (FOMs) [Hoda et al., 2010, Kroer et al., 2015] achieving a convergence rate of O( ). The better convergence rate of FOMs makes them more attractive from a theoretical viewpoint. This paper investigates the acceleration of such FOMs for EFGs, from both a theoretical and a numerical perspective. Nash equilibrium computation of a two-player zero-sum EFG with perfect recall admits a Bilinear Saddle Point Problem (BSPP) formulation where the domains are given by the polytopes that encode strategy spaces of the players. The most efficient FOMs are designed to solve this BSPP. The classical FOMs to solve BSPPs such as mirror prox (MP) [Nemirovski, 2004] or the excessive gap technique (EGT) [Nesterov, 2005a] utilize distance-generating functions (DGFs) to measure appropriate notions of distances over the domains. Then the convergence rate of these FOMs relies on the DGFs and their relation to the domains in three critical ways: Through the strong convexity parameters of the DGFs, the norm associated with the strong convexity parameter, and set widths of the domains as measured by the DGFs. Hoda et al. [2010] introduced a general framework for constructing DGFs for treeplexes\u2014a class of convex polytopes that generalize the domains associated with the strategy spaces of an EFG.", "startOffset": 100, "endOffset": 1210}, {"referenceID": 12, "context": ", 2009] achieving a convergence rate on the order of O( 1 2 ), and (ii) first-order methods (FOMs) [Hoda et al., 2010, Kroer et al., 2015] achieving a convergence rate of O( ). The better convergence rate of FOMs makes them more attractive from a theoretical viewpoint. This paper investigates the acceleration of such FOMs for EFGs, from both a theoretical and a numerical perspective. Nash equilibrium computation of a two-player zero-sum EFG with perfect recall admits a Bilinear Saddle Point Problem (BSPP) formulation where the domains are given by the polytopes that encode strategy spaces of the players. The most efficient FOMs are designed to solve this BSPP. The classical FOMs to solve BSPPs such as mirror prox (MP) [Nemirovski, 2004] or the excessive gap technique (EGT) [Nesterov, 2005a] utilize distance-generating functions (DGFs) to measure appropriate notions of distances over the domains. Then the convergence rate of these FOMs relies on the DGFs and their relation to the domains in three critical ways: Through the strong convexity parameters of the DGFs, the norm associated with the strong convexity parameter, and set widths of the domains as measured by the DGFs. Hoda et al. [2010] introduced a general framework for constructing DGFs for treeplexes\u2014a class of convex polytopes that generalize the domains associated with the strategy spaces of an EFG. While they also established bounds on the strong convexity parameter for their DGFs in some special cases, these lead to very weak bounds and result in slow convergence rates. Kroer et al. [2015] developed explicit strong convexity-parameter bounds for entropy-based DGFs (a particular subclass of DGFs) for general EFGs, and improved the bounds for the special cases considered by Hoda et al.", "startOffset": 100, "endOffset": 1577}, {"referenceID": 12, "context": ", 2009] achieving a convergence rate on the order of O( 1 2 ), and (ii) first-order methods (FOMs) [Hoda et al., 2010, Kroer et al., 2015] achieving a convergence rate of O( ). The better convergence rate of FOMs makes them more attractive from a theoretical viewpoint. This paper investigates the acceleration of such FOMs for EFGs, from both a theoretical and a numerical perspective. Nash equilibrium computation of a two-player zero-sum EFG with perfect recall admits a Bilinear Saddle Point Problem (BSPP) formulation where the domains are given by the polytopes that encode strategy spaces of the players. The most efficient FOMs are designed to solve this BSPP. The classical FOMs to solve BSPPs such as mirror prox (MP) [Nemirovski, 2004] or the excessive gap technique (EGT) [Nesterov, 2005a] utilize distance-generating functions (DGFs) to measure appropriate notions of distances over the domains. Then the convergence rate of these FOMs relies on the DGFs and their relation to the domains in three critical ways: Through the strong convexity parameters of the DGFs, the norm associated with the strong convexity parameter, and set widths of the domains as measured by the DGFs. Hoda et al. [2010] introduced a general framework for constructing DGFs for treeplexes\u2014a class of convex polytopes that generalize the domains associated with the strategy spaces of an EFG. While they also established bounds on the strong convexity parameter for their DGFs in some special cases, these lead to very weak bounds and result in slow convergence rates. Kroer et al. [2015] developed explicit strong convexity-parameter bounds for entropy-based DGFs (a particular subclass of DGFs) for general EFGs, and improved the bounds for the special cases considered by Hoda et al. [2010]. These bounds from Kroer et al.", "startOffset": 100, "endOffset": 1782}, {"referenceID": 12, "context": ", 2009] achieving a convergence rate on the order of O( 1 2 ), and (ii) first-order methods (FOMs) [Hoda et al., 2010, Kroer et al., 2015] achieving a convergence rate of O( ). The better convergence rate of FOMs makes them more attractive from a theoretical viewpoint. This paper investigates the acceleration of such FOMs for EFGs, from both a theoretical and a numerical perspective. Nash equilibrium computation of a two-player zero-sum EFG with perfect recall admits a Bilinear Saddle Point Problem (BSPP) formulation where the domains are given by the polytopes that encode strategy spaces of the players. The most efficient FOMs are designed to solve this BSPP. The classical FOMs to solve BSPPs such as mirror prox (MP) [Nemirovski, 2004] or the excessive gap technique (EGT) [Nesterov, 2005a] utilize distance-generating functions (DGFs) to measure appropriate notions of distances over the domains. Then the convergence rate of these FOMs relies on the DGFs and their relation to the domains in three critical ways: Through the strong convexity parameters of the DGFs, the norm associated with the strong convexity parameter, and set widths of the domains as measured by the DGFs. Hoda et al. [2010] introduced a general framework for constructing DGFs for treeplexes\u2014a class of convex polytopes that generalize the domains associated with the strategy spaces of an EFG. While they also established bounds on the strong convexity parameter for their DGFs in some special cases, these lead to very weak bounds and result in slow convergence rates. Kroer et al. [2015] developed explicit strong convexity-parameter bounds for entropy-based DGFs (a particular subclass of DGFs) for general EFGs, and improved the bounds for the special cases considered by Hoda et al. [2010]. These bounds from Kroer et al. [2015] generate the current state-of-the-art parameters associated with the convergence rate for FOMs with O( ) convergence.", "startOffset": 100, "endOffset": 1821}, {"referenceID": 12, "context": ", 2009] achieving a convergence rate on the order of O( 1 2 ), and (ii) first-order methods (FOMs) [Hoda et al., 2010, Kroer et al., 2015] achieving a convergence rate of O( ). The better convergence rate of FOMs makes them more attractive from a theoretical viewpoint. This paper investigates the acceleration of such FOMs for EFGs, from both a theoretical and a numerical perspective. Nash equilibrium computation of a two-player zero-sum EFG with perfect recall admits a Bilinear Saddle Point Problem (BSPP) formulation where the domains are given by the polytopes that encode strategy spaces of the players. The most efficient FOMs are designed to solve this BSPP. The classical FOMs to solve BSPPs such as mirror prox (MP) [Nemirovski, 2004] or the excessive gap technique (EGT) [Nesterov, 2005a] utilize distance-generating functions (DGFs) to measure appropriate notions of distances over the domains. Then the convergence rate of these FOMs relies on the DGFs and their relation to the domains in three critical ways: Through the strong convexity parameters of the DGFs, the norm associated with the strong convexity parameter, and set widths of the domains as measured by the DGFs. Hoda et al. [2010] introduced a general framework for constructing DGFs for treeplexes\u2014a class of convex polytopes that generalize the domains associated with the strategy spaces of an EFG. While they also established bounds on the strong convexity parameter for their DGFs in some special cases, these lead to very weak bounds and result in slow convergence rates. Kroer et al. [2015] developed explicit strong convexity-parameter bounds for entropy-based DGFs (a particular subclass of DGFs) for general EFGs, and improved the bounds for the special cases considered by Hoda et al. [2010]. These bounds from Kroer et al. [2015] generate the current state-of-the-art parameters associated with the convergence rate for FOMs with O( ) convergence. In this paper we construct a new weighting scheme for such entropy-based DGFs. This weighting scheme leads to new and improved bounds on the strong convexity parameter associated with general treeplex domains. In particular, our new bounds are first-of-their kind as they have no dependence on the branching operation of the treeplex. Informally, our strong convexity result allows us to improve the convergence rate of FOMs by a factor of \u03a9(bdd) (where b is the average branching factor for a player and d is the depth of the EFG) compared to the prior state-of-the-art results from Kroer et al. [2015]. Our bounds parallel the simplex case for matrix games where the entropy function achieves a logarithmic dependence on the dimension of the simplex domain.", "startOffset": 100, "endOffset": 2543}, {"referenceID": 1, "context": "Bowling et al. [2015] used it to essentially solve the game limit Texas hold\u2019em.", "startOffset": 0, "endOffset": 22}, {"referenceID": 25, "context": "A slight variation2 of CFR+ was used in the DeepStack agent Morav\u010d\u0301\u0131k et al. [2017], which beat a group of professional players.", "startOffset": 60, "endOffset": 84}, {"referenceID": 21, "context": "We also test the impact of stronger bounds on the strong convexity parameter: we instantiate EGT with the parameters developed in this paper, and compare the performance to the parameters developed by Kroer et al. [2015]. These experiments illustrate that the tighter parameters developed here lead to better practical convergence rate.", "startOffset": 201, "endOffset": 221}, {"referenceID": 31, "context": "These techniques fall into two categories: iterative -Nash equilibrium-finding algorithms and game abstraction techniques [Sandholm, 2010].", "startOffset": 122, "endOffset": 138}, {"referenceID": 39, "context": "The most popular iterative Nash equilibrium algorithm is the counterfactual-regret-minimization framework instantiated with regret matching (CFR) [Zinkevich et al., 2007], its sampling-based variant monte-carlo CFR (MCCFR) [Lanctot et al.", "startOffset": 146, "endOffset": 170}, {"referenceID": 22, "context": ", 2007], its sampling-based variant monte-carlo CFR (MCCFR) [Lanctot et al., 2009], and CFR instantitated with a new regret minimization technique called regret matching plus (CFR+).", "startOffset": 60, "endOffset": 82}, {"referenceID": 6, "context": ", 2007, Daskalakis et al., 2009, Jiang and Leyton-Brown, 2011, Kroer and Sandholm, 2014, Daskalakis et al., 2015]. The equilibrium-finding problems vary quite a bit based on their characteristics; here we restrict our attention to two-player zero-sum sequential games. Koller et al. [1996] present an LP whose size is linear in the size of the game tree.", "startOffset": 8, "endOffset": 290}, {"referenceID": 6, "context": ", 2007, Daskalakis et al., 2009, Jiang and Leyton-Brown, 2011, Kroer and Sandholm, 2014, Daskalakis et al., 2015]. The equilibrium-finding problems vary quite a bit based on their characteristics; here we restrict our attention to two-player zero-sum sequential games. Koller et al. [1996] present an LP whose size is linear in the size of the game tree. This approach, coupled with lossless abstraction techniques, was used to solve Rhode-Island hold\u2019em [Shi and Littman, 2002, Gilpin and Sandholm, 2007], a game with 3.1 billion nodes (roughly size 5 \u00b7 107 after lossless abstraction). However, for games larger than this, the resulting LPs tend to not fit in the computer memory thus requiring approximate solution techniques. These techniques fall into two categories: iterative -Nash equilibrium-finding algorithms and game abstraction techniques [Sandholm, 2010]. The most popular iterative Nash equilibrium algorithm is the counterfactual-regret-minimization framework instantiated with regret matching (CFR) [Zinkevich et al., 2007], its sampling-based variant monte-carlo CFR (MCCFR) [Lanctot et al., 2009], and CFR instantitated with a new regret minimization technique called regret matching plus (CFR+). These regret-minimization algorithms perform local regret-based updates at each information set. Despite their slow convergence rate of O( 1 2 ), they perform very well in pratice, especially CFR+. Recently, Waugh and Bagnell [2015] showed, with some caveats, an interpretation of CFR as a FOM with O( 1 2 ) rate.", "startOffset": 8, "endOffset": 1449}, {"referenceID": 6, "context": ", 2007, Daskalakis et al., 2009, Jiang and Leyton-Brown, 2011, Kroer and Sandholm, 2014, Daskalakis et al., 2015]. The equilibrium-finding problems vary quite a bit based on their characteristics; here we restrict our attention to two-player zero-sum sequential games. Koller et al. [1996] present an LP whose size is linear in the size of the game tree. This approach, coupled with lossless abstraction techniques, was used to solve Rhode-Island hold\u2019em [Shi and Littman, 2002, Gilpin and Sandholm, 2007], a game with 3.1 billion nodes (roughly size 5 \u00b7 107 after lossless abstraction). However, for games larger than this, the resulting LPs tend to not fit in the computer memory thus requiring approximate solution techniques. These techniques fall into two categories: iterative -Nash equilibrium-finding algorithms and game abstraction techniques [Sandholm, 2010]. The most popular iterative Nash equilibrium algorithm is the counterfactual-regret-minimization framework instantiated with regret matching (CFR) [Zinkevich et al., 2007], its sampling-based variant monte-carlo CFR (MCCFR) [Lanctot et al., 2009], and CFR instantitated with a new regret minimization technique called regret matching plus (CFR+). These regret-minimization algorithms perform local regret-based updates at each information set. Despite their slow convergence rate of O( 1 2 ), they perform very well in pratice, especially CFR+. Recently, Waugh and Bagnell [2015] showed, with some caveats, an interpretation of CFR as a FOM with O( 1 2 ) rate. Nonetheless, in this paper we make a distinction between regret-based methods and O( ) FOMs for ease of exposition. Hoda et al. [2010] initially proposed DGFs for EFGs leading to O( ) convergence rate when used with EGT.", "startOffset": 8, "endOffset": 1665}, {"referenceID": 6, "context": ", 2007, Daskalakis et al., 2009, Jiang and Leyton-Brown, 2011, Kroer and Sandholm, 2014, Daskalakis et al., 2015]. The equilibrium-finding problems vary quite a bit based on their characteristics; here we restrict our attention to two-player zero-sum sequential games. Koller et al. [1996] present an LP whose size is linear in the size of the game tree. This approach, coupled with lossless abstraction techniques, was used to solve Rhode-Island hold\u2019em [Shi and Littman, 2002, Gilpin and Sandholm, 2007], a game with 3.1 billion nodes (roughly size 5 \u00b7 107 after lossless abstraction). However, for games larger than this, the resulting LPs tend to not fit in the computer memory thus requiring approximate solution techniques. These techniques fall into two categories: iterative -Nash equilibrium-finding algorithms and game abstraction techniques [Sandholm, 2010]. The most popular iterative Nash equilibrium algorithm is the counterfactual-regret-minimization framework instantiated with regret matching (CFR) [Zinkevich et al., 2007], its sampling-based variant monte-carlo CFR (MCCFR) [Lanctot et al., 2009], and CFR instantitated with a new regret minimization technique called regret matching plus (CFR+). These regret-minimization algorithms perform local regret-based updates at each information set. Despite their slow convergence rate of O( 1 2 ), they perform very well in pratice, especially CFR+. Recently, Waugh and Bagnell [2015] showed, with some caveats, an interpretation of CFR as a FOM with O( 1 2 ) rate. Nonetheless, in this paper we make a distinction between regret-based methods and O( ) FOMs for ease of exposition. Hoda et al. [2010] initially proposed DGFs for EFGs leading to O( ) convergence rate when used with EGT. Kroer et al. [2015] improved these result for the dilated entropy function.", "startOffset": 8, "endOffset": 1771}, {"referenceID": 33, "context": "Sequential game abstraction approaches with solution quality bounds have also emerged for stochastic [Sandholm and Singh, 2012] and extensive-form [Lanctot et al.", "startOffset": 101, "endOffset": 127}, {"referenceID": 0, "context": "Finally, Bosansky et al. [2014] develop an iterative double-oracle algorithm for exact equilibrium computation.", "startOffset": 9, "endOffset": 32}, {"referenceID": 16, "context": "This is known as the sequence-form formulation [Romanovskii, 1962, Koller et al., 1996, von Stengel, 1996]. In this formulation, x and y correspond to the nonnegative strategy vectors for players 1 and 2 and the sets X ,Y are convex polyhedral reformulations of the sequential strategy space of these players. Here X ,Y are defined by the constraints Ex = e, Fy = f , where each row of E,F encodes part of the sequential nature of the strategy vectors, the right hand-side vectors e, f are |I1| , |I2|-dimensional vectors, and Ii is the information sets for player i. For a complete treatment of this formulation, see von Stengel [1996]. Our theoretical developments mainly exploit the treeplex domain structure and are independent of other structural assumptions resulting from EFGs.", "startOffset": 67, "endOffset": 637}, {"referenceID": 16, "context": "We follow the presentation and notation of Juditsky and Nemirovski [2011a,b] for BSPPs. For notation and presentation of treeplex structure, we follow Kroer et al. [2015].", "startOffset": 43, "endOffset": 171}, {"referenceID": 28, "context": "Nesterov [2005b] shows that the gradients of the functions \u03c6\u03bc2(x) and \u03c6 \u03bc1 (y) exist and are Lipschitz continuous.", "startOffset": 0, "endOffset": 17}, {"referenceID": 28, "context": "Based on this setup, we formally state the Excessive Gap Technique (EGT) of Nesterov [2005a] in Algorithm 1.", "startOffset": 76, "endOffset": 93}, {"referenceID": 37, "context": "For treeplexes, von Stengel [1996] has suggested a polyhedral representation of the form Eu = e where the matrix E has its entries from {\u22121, 0, 1} and the vector e has its entries in {0, 1}.", "startOffset": 20, "endOffset": 35}, {"referenceID": 20, "context": "Note that we allow more than two-way branches; hence our formulation follows that of Kroer et al. [2015] and differs from that of Hoda et al.", "startOffset": 85, "endOffset": 105}, {"referenceID": 13, "context": "[2015] and differs from that of Hoda et al. [2010]. As discussed in Hoda et al.", "startOffset": 32, "endOffset": 51}, {"referenceID": 13, "context": "[2015] and differs from that of Hoda et al. [2010]. As discussed in Hoda et al. [2010], it is possible to model sequence-form games by treeplexes that use only two-way branches.", "startOffset": 32, "endOffset": 87}, {"referenceID": 12, "context": "The treeplex structure is naturally related to the dilation operation [Hiriart-Urruty and Lemar\u00e9chal, 2001] defined as follows: Given a compact set K \u2286 Rd and a function f : K \u2192 R, we first define", "startOffset": 70, "endOffset": 107}, {"referenceID": 15, "context": "It is well-known that \u03c9e(\u00b7) is strongly convex with modulus 1 with respect to the `1 norm on \u2206n (see Juditsky and Nemirovski [2011a]).", "startOffset": 101, "endOffset": 133}, {"referenceID": 13, "context": "Hoda et al. [2010] show that for any dilated function, its prox operator on a treeplex can be easily computed through a recursive bottom-up traversal involving the prox mappings associated with the function being dilated on individual simplexes.", "startOffset": 0, "endOffset": 19}, {"referenceID": 13, "context": "Hoda et al. [2010] show that for any dilated function, its prox operator on a treeplex can be easily computed through a recursive bottom-up traversal involving the prox mappings associated with the function being dilated on individual simplexes. Since the entropy prox function can be computed in closed form on a simplex, the dilated entropy function can be computed by a single treeplex traversal involving closed-form expressions on each simplex. Definition 3 above leads to a subset of the DGFs considered by Hoda et al. [2010]. Our main theoretical result shows that by a careful selection of the weights \u03b2j , we can significantly improve the strong convexity bounds associated with the dilated entropy function.", "startOffset": 0, "endOffset": 532}, {"referenceID": 21, "context": "To our knowledge, the best strong convexity bounds for general treeplexes were proved in Kroer et al. [2015]. Using weights \u03b2j = 2 MQj they show strong convexity modulus 1 |SQ| w.", "startOffset": 89, "endOffset": 109}, {"referenceID": 21, "context": "To our knowledge, the best strong convexity bounds for general treeplexes were proved in Kroer et al. [2015]. Using weights \u03b2j = 2 MQj they show strong convexity modulus 1 |SQ| w.r.t. the `1 norm. Corollary 1 improves the prior bounds by exchanging a factor of |SQ| with a factor of MQ. Note that |SQ| is tied to the branching factor associated with branching operations in the treeplex Q whereas MQ is not. Thus, our result removes the dependence of the strong convexity parameter on the branching factor and hence significantly improves upon Kroer et al. [2015]. In Theorem 3 we use our strong convexity result to establish a polytope diameter that has only a logarithmic dependence on the branching factor.", "startOffset": 89, "endOffset": 564}, {"referenceID": 21, "context": "Compared to the rate obtained by [Kroer et al., 2015], we get the following improvement: for simplicity, assume that the number of actions available at each information set is on average a, then our bound improves the convergence rate of [Kroer et al.", "startOffset": 33, "endOffset": 53}, {"referenceID": 21, "context": ", 2015], we get the following improvement: for simplicity, assume that the number of actions available at each information set is on average a, then our bound improves the convergence rate of [Kroer et al., 2015] by a factor of \u03a9(dX \u00b7 adX + dY \u00b7 adY ).", "startOffset": 192, "endOffset": 212}, {"referenceID": 13, "context": "As mentioned previously, Hoda et al. [2010] proved only explicit bounds for the special case of uniform treeplexes that are constructed as follows: 1) A base treeplex Qb along with a subset of b indices from it for branching operations is chosen.", "startOffset": 25, "endOffset": 44}, {"referenceID": 13, "context": "As mentioned previously, Hoda et al. [2010] proved only explicit bounds for the special case of uniform treeplexes that are constructed as follows: 1) A base treeplex Qb along with a subset of b indices from it for branching operations is chosen. 2) At each depth d, a Cartesian product operation of size k is applied. 3) Each element in a Cartesian product is an instance of the base treeplex with a size b branching operation leading to depth d \u2212 1 uniform treeplexes constructed in the same way. Given bounds \u03a9b, \u03c6b for the base treeplex, the bound of Hoda et al. [2010] for a uniform treeplex with d uniform treeplex levels (note that the total depth of the constructed treeplex is d \u00b7 dQb , where dQb is the depth of the base treeplex Qb) is", "startOffset": 25, "endOffset": 574}, {"referenceID": 22, "context": "CFR has a O( 1 2 ) convergence rate; but its dependence on the number of information sets is only linear (and sometimes sublinear [Lanctot et al., 2009]).", "startOffset": 130, "endOffset": 152}, {"referenceID": 22, "context": "MCCFR and CFR+ have a similar convergence rate [Lanctot et al., 2009], though MCCFR has cheaper iterations.", "startOffset": 47, "endOffset": 69}, {"referenceID": 9, "context": "Gilpin et al. [2012] give an equilibrium-finding algorithm presented as O(ln( )); but this form of their bound has a dependence on a certain condition number of the A matrix.", "startOffset": 0, "endOffset": 21}, {"referenceID": 9, "context": "Gilpin et al. [2012] give an equilibrium-finding algorithm presented as O(ln( )); but this form of their bound has a dependence on a certain condition number of the A matrix. Specifically, their iteration bound for sequential games is O( \u2016A\u20162,2\u00b7ln(\u2016A\u20162,2/ )\u00b7 \u221a D \u03b4(A) ), where \u03b4(A) is the condition number of A, \u2016A\u20162,2 = supx 6=0 \u2016Ax\u20162 \u2016x\u20162 is the Euclidean matrix norm, and D = maxx,x\u0304\u2208X ,y,\u0233\u2208Y \u2016(x, y) \u2212 (x\u0304, \u0233)\u20162. Unfortunately, the condition number \u03b4(A) is only shown to be finite for these games. Without any such unknown quantities based on condition numbers, Gilpin et al. [2012] establish a convergence rate of O( \u2016A\u20162,2\u00b7D ).", "startOffset": 0, "endOffset": 587}, {"referenceID": 35, "context": "We test these algorithms on a scaled up variant of the poker game Leduc holdem [Southey et al., 2005], a benchmark problem in the imperfect-information game-solving community.", "startOffset": 79, "endOffset": 101}, {"referenceID": 35, "context": "We compare the performance of EGT to that of CFR and CFR+ algorithms on a scaled up variant of the poker game Leduc hold\u2019em [Southey et al., 2005], a benchmark problem in the", "startOffset": 124, "endOffset": 146}, {"referenceID": 21, "context": "First, we investigate the impact of applying the weights used in recurrence (6), as compared to the previous scheme introduced in Kroer et al. [2015]. To instantiate recurrence (6) we have to choose a way to set \u03b2j relative to \u03b1j .", "startOffset": 130, "endOffset": 150}, {"referenceID": 21, "context": "First, we investigate the impact of applying the weights used in recurrence (6), as compared to the previous scheme introduced in Kroer et al. [2015]. To instantiate recurrence (6) we have to choose a way to set \u03b2j relative to \u03b1j . Experimentally, we found that the best way to instantiate the recurrence is to use \u03b2j = \u03b1j for all j, in spite of the strict inequality required for our proof. This scheme will henceforth be referred to as new weights. We compare these new weights to the weights used in Kroer et al. [2015] (henceforth referred to as old weights).", "startOffset": 130, "endOffset": 523}, {"referenceID": 21, "context": "First, we investigate the impact of applying the weights used in recurrence (6), as compared to the previous scheme introduced in Kroer et al. [2015]. To instantiate recurrence (6) we have to choose a way to set \u03b2j relative to \u03b1j . Experimentally, we found that the best way to instantiate the recurrence is to use \u03b2j = \u03b1j for all j, in spite of the strict inequality required for our proof. This scheme will henceforth be referred to as new weights. We compare these new weights to the weights used in Kroer et al. [2015] (henceforth referred to as old weights). Figure 2 shows the result of running EGT with the old and the new weights. For both the old and the new weights, we found that the scalars MQ and |SQ| applied to each DGF in order to achieve strong convexity modulus 1 according to Corollary 1 and Theorem 5.4 of Kroer et al. [2015], respectively, are too conservative.", "startOffset": 130, "endOffset": 846}, {"referenceID": 21, "context": "Figure 2: Regret as a function of the number of iterations for EGT with our weighting scheme (EGT new) and with the weighting scheme from Kroer et al. [2015] (EGT old).", "startOffset": 138, "endOffset": 158}, {"referenceID": 19, "context": "In Kroer et al. [2015] it was found that, while EGT has better convergence rate, CFR (which performs worse than CFR+) had better initial performance, and it was only after a certain number of iterations that EGT took over.", "startOffset": 3, "endOffset": 23}, {"referenceID": 2, "context": "This sentiment has been mirrored by Brown and Sandholm [2016]. In contrast to this, we find that our DGF along with proper initialization leads to EGT performing better than", "startOffset": 36, "endOffset": 62}, {"referenceID": 15, "context": "For games where accelerated bestresponse calculation [Johanson et al., 2011] can be applied, e.", "startOffset": 53, "endOffset": 76}, {"referenceID": 4, "context": "But, for some other games, this aspect can be important, though note that Brown et al. [2017] showed experimentally that pruning can be used in EGT as well.", "startOffset": 74, "endOffset": 94}, {"referenceID": 31, "context": "On a separate note, in practice CFR is often paired with an abstraction technique [Sandholm, 2010] such as those mentioned in Section 2.", "startOffset": 82, "endOffset": 98}, {"referenceID": 4, "context": "Effective ways to pair FOMs such as MP and EGT with practical abstraction techniques [Brown et al., 2015] or abstraction techniques that achieve solution-quality guarantees [Lanctot et al.", "startOffset": 85, "endOffset": 105}], "year": 2017, "abstractText": "Sparse iterative methods, in particular first-order methods, are known to be among the most effective in solving large-scale two-player zero-sum extensive-form games. The convergence rates of these methods depend heavily on the properties of the distance-generating function that they are based on. We investigate the acceleration of first-order methods for solving extensive-form games through better design of the dilated entropy function\u2014a class of distance-generating functions related to the domains associated with the extensive-form games. By introducing a new weighting scheme for the dilated entropy function, we develop the first distance-generating function for the strategy spaces of sequential games that only a logarithmic dependence on the branching factor of the player. This result improves the convergence rate of several first-order methods by a factor of \u03a9(bd), where b is the branching factor of the player, and d is the depth of the game tree. Thus far, counterfactual regret minimization methods have been faster in practice, and more popular, than first-order methods despite their theoretically inferior convergence rates. Using our new weighting scheme and practical tuning we show that, for the first time, the excessive gap technique can be made faster than the fastest counterfactual regret minimization algorithm, CFR+, in practice.", "creator": "LaTeX with hyperref package"}}}