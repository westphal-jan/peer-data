{"id": "1702.04938", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Feb-2017", "title": "Fast and unsupervised methods for multilingual cognate clustering", "abstract": "In this paper we explore the use of unsupervised methods for detecting cognates in multilingual word lists. We use online EM to train sound segment similarity weights for computing similarity between two words. We tested our online systems on geographically spread sixteen different language groups of the world and show that the Online PMI system (Pointwise Mutual Information) outperforms a HMM based system and two linguistically motivated systems: LexStat and ALINE. Our results suggest that a PMI system trained in an online fashion can be used by historical linguists for fast and accurate identification of cognates in not so well-studied language families.", "histories": [["v1", "Thu, 16 Feb 2017 12:10:18 GMT  (39kb,D)", "http://arxiv.org/abs/1702.04938v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["taraka rama", "johannes wahle", "pavel sofroniev", "gerhard j\\\"ager"], "accepted": false, "id": "1702.04938"}, "pdf": {"name": "1702.04938.pdf", "metadata": {"source": "CRF", "title": "Fast and unsupervised methods for multilingual cognate clustering", "authors": ["Taraka Rama", "Johannes Wahle", "Pavel Sofroniev", "Gerhard J\u00e4ger"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "It is a question of whether and to what extent the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the EU, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA"}, {"heading": "2 Related work", "text": "Kondrak [2000] introduced a dynamic programming algorithm to calculate the similarity between two sequences based on articulating phonetic characteristics determined by Ladefoged [1975]. The author evaluated his algorithm on a list of English-Latin similarities. In this thesis, we evaluate on the Indo-European dataset, which consists of English and Latin. Hauer and Kondrak [2011] trained a linear SVM on word similarity characteristics and used the SVM model to assign a similarity value to the word pair. For each meaning, a word pair distance matrix is calculated and provided to the average linkage cluster algorithm for inferencing cognate clusters. The authors note that the SVM-trained system performs better than a baseline that bases the similarity of two words on the identity of the first two consonant forms."}, {"heading": "3 Models", "text": "In this section we briefly describe the PMI-weighted Needleman wish algorithm and the Pair Hidden Markov Model (PHMM)."}, {"heading": "3.1 PMI-weighted alignment", "text": "This year, it is only a matter of time before an agreement is reached."}, {"heading": "3.2 Pair Hidden Markov Model", "text": "A Pair Hidden Markov Model (PHMM) uses two output streams instead of a single output stream; one for each of the two sequences matched to each other. In its simplest version, a PHMM consists of five states: an initial state, a final state, a match state (M), which emits symbol pairs; a deletion state (X), which emits a symbol in the first string and a gap in the second string; and an insertion state (Y), which emits a gap in the first string and a symbol in the second string; a deletion state (X), which emits a symbol in the first string and a gap in the second string; and an insertion state (Y), which emits a gap in the second string (see Figure 1). PHMMs, as they are used in historical linguistics, differ from their biological counterpart in the following ways: The PHMM historical model allows a dotted transition between the MX and the MX states (a dotted line)."}, {"heading": "4 Online EM", "text": "The EM algorithm starts with an initial setting of model parameters and uses these model parameters to re-align words in a sentence pair. Model parameters are re-estimated based on word alignments obtained from the previous iteration. The EM algorithm re-aligns the model parameters after each full scan of the training data. Liang and Klein [2009] note that a batch training process can lead to slow convergence. In fact, Ja \u2212 ger [2013] trains its PMI system using the EM standard (also known as StackelEM), which updates the parameters in a PMI scoring matrix only after aligning all word pairs. In contrast, Online EM [Liang and Klein, 2009] is an update of model parameters using the default parameter EM (also known as StackelEM), updating the parameters in a PMI scoring matrix only after aligning all word pairs."}, {"heading": "5 Clustering algorithm", "text": "InfoMap's cluster method is an information theory approach to detecting community structures within a connected network. It uses random walks within a network as a proxy for the flow of information to detect communities, i.e. clusters, without the need for a threshold. A community is a group of nodes with more edges that connect the nodes within the community than they connect them to nodes outside the community [Newman and Girvan, 2004].In our case, a community refers to the words that match and have a higher edge weight between them. The idea behind the algorithm is that the random walk statistically spends more time within a community than the change of communities due to the nature of the network. A pair distance matrix is a complete weighted graph and each edge with a weight < 0.5 and a PMI score < 0 (due to the sigmoid-based remote transformations < that may imply the property transformation of this I)."}, {"heading": "6 Experiments", "text": "In this section we describe the experimental settings, data sets, benchmarks and comparison systems: Baseline, ALINE, PMI-LANG and LexStat."}, {"heading": "6.1 Hyperparameters of Online EM", "text": "We determine the best setting of m and \u03b1 parameters by looking for m in the range of m = 2s, where s [5, 15]; and, \u03b1 [0.5, 1.0] with a step size of 0.05. We fix the penalties for gap opening and expansion at \u2212 2.5 and \u2212 1.75."}, {"heading": "6.2 Datasets", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.2.1 Indo-European database", "text": "The Indo-European Lexical database (IELex) was created by Dyen et al. [1992] and by Michael Dunn.4 The IELex database is not transcribed in a uniform IPA and contains many forms transcribed in the romanized IPA format by Dyen et al. [1992] We cleaned the IELex database of all non-IPA-like transcriptions and converted the purified subset of the database into the ASJP format."}, {"heading": "6.2.2 Austronesian vocabulary database", "text": "The Austronesian Vocabulary Database (ABVD) [Greenhill and Gray, 2009] has word lists for 210 Swadesh concepts and 378 languages. [5] The database does not contain transcriptions in a uniform IPA format. We have removed all symbols that do not appear in the standard IPA and converted the lexical elements into the ASJP format."}, {"heading": "6.2.3 Short word lists with cognacy judgments:", "text": "Wichmann and Holman [2013] and List [2014a] have compiled word lists for subgroups of families from various scientific sources such as comparative manuals and articles of historical linguistics, the details of which are listed in Table 2."}, {"heading": "6.3 Evaluation Measures", "text": "The accuracy of a word is defined as the ratio between the number of 4http: / / ielex.mpi.nl / 5http: / / language.psy.auckland.ac.nz / austronesian / 6LexStat takes many hours to run on a dataset of 100 languages calculated in its cluster to the total number of words in its cluster. The callback of a word is defined as the ratio between the number of cognates in its cluster and the total number of experts designated as cognates. B-cubed precision and callback are defined as the average of word precision and callback for a word in its cluster. Finally, the B-cubed F score is calculated for a meaning, as the harmonic mean of average precision and callback, the [the precision and callback function of the F scale] [the precision and callback values] for the total number of clusters all (over the] clusters."}, {"heading": "6.4 Comparing systems", "text": "Baseline In our experiments we assume the normalized Levenshtein distance as baseline."}, {"heading": "6.4.1 ALINE", "text": "ALINE is a sequence alignment system developed by Kondrak [2000] to calculate similarities between two words by breaking down phonemes into polyvalent and binary phonetic characters. Each phoneme is broken down into polyvalent characters, such as place and type of consonants; height and back of vowels. Polyvalent characters take values on a continuous scale of [0, 1] and the values represent the distance between the sources of articulation. Binary-weighted features consist of nasal, intonation, suction and retroflex. Each feature is weighted by an emphasis value, which is determined manually. The similarity value between two sequences is calculated as the sum of aligned tone segments. Following Downey et al. [2008] we convert ALINE's similarity value between two words a, b into a distance value based on the following formula: 1.0 + 2.0 \u2212 b7."}, {"heading": "6.4.2 PMI-LANG", "text": "Yes \u00bc ger [2013] developed a system that learns PMI tone matrices to optimize a criterion for optimizing language relationships. The basic idea is to combine word similarity with language similarity in such a way that narrow languages such as English / German tend to be more similar than English / Hindi. The language similarity function comes down to maximizing the similarity between likely like-minded people in order to learn a PMI score matrix. Yes \u00bc ger [2013] applies the learned PMI score matrix to derive phylogenetic stem trees from language families."}, {"heading": "6.4.3 LexStat", "text": "LexStat [List, 2012] is part of the LingPy [List and Forkel, 2016] library, which provides state-of-the-art alignment algorithms for aligning and clustering word pairs in contiguous sets. We describe the LexStat system workflow as follows: 1. LexStat uses a handmade tone segment matrix, h, to align and rate the word pairs for each meaning. Leave a segment pair i, j's similarity as hij.2. For each language pair l1, l2, the word pairs that belong to the same meaning are aligned and the frequency of a segment pair i, j belonging to the same meaning is given as aij.3. For l1, l2, the words belonging to one of the language are mixed and realigned using Needleman's wish algorithm. This procedure repeats for all language pairs that belong to the same meaning as aij."}, {"heading": "7 Results", "text": "In this section we present the results of our experiments. We perform two groups of experiments by training with different data sets, which are described below."}, {"heading": "7.1 Out-of-family training", "text": "In this experiment, we train our PHMM and PMI systems on word lists from the ASJP database that do not belong to families with language groups other than those shown in Table 2. We made sure that there was no overlap between the languages present in test records and training records. We extracted a list of probable cognates and trained our PMI and PHMM models on the list of probable cognates. We trained all The8We received the code from https: / / github.com / lingpy. We converted the LexStat similarity values to distance values and used the same formula as ALINE.batch and online systems to enhance the performance of Lexi.batch and online systems on 1151178 word pairs. The results of our experiments are given in Table 3. We report the InfoMap cluster results for a threshold of 0.5 for all systems. We expect LexStat to achieve better results in the case of systems processing sounds from Chinese JASP during the processing of lextones."}, {"heading": "7.2 Within-family training", "text": "In this experiment, we train our PMI and PHMM systems on three largest language families in our PMD and PMD computer families: Mayan, Indo-European and Austronesian language families. We train our systems on word pairs extracted from two different language families.1 The ASJP database has 40-long word lists for more languages (3 times longer) than the languages in cognate databases of the Maya, Indo-European and Austronesian language families. The database allows us to access more word pairs than any other database in the existing database.2. We extract lists of likely word pairs from the IELex, ABVD and Maya language databases. The motivation behind these experiments is to investigate the performance of PMI and PHMM language systems when these word lists belong to the same language family but are compiled by different groups of annotators.A successful experiment shows that this approach to PMJI training can be applied to a PMI."}, {"heading": "8 Discussion", "text": "In this section, we discuss the impact of various parameters on our results."}, {"heading": "8.1 Effect of m and \u03b1", "text": "We also observe that an intermediate value of \u03b1 is usually sufficient to achieve the best results. Figure 2 shows that small values of m in the range of \u03b1 lead to stable F values. Small values of m typically yield better results than larger values of \u03b1. Unlike other NLP tasks that require large m and smaller \u03b1, the task requires matching two words, smaller values of m. The small value of m implies a large number of updates, which is important for a task where the average sequence length (\u0445 5) and average number of word pairs are less than 100,000. Furthermore, an intermediate value of \u03b1 controls the amount of memory that is kept with each update."}, {"heading": "8.2 Speed", "text": "One advantage of our online systems (either PMI or PHMM) is that the training time is typically in the range of 10 minutes on a single thread with i7-6700 processor. In the case of PHMM, online training accelerates convergence and typically delivers better results than the batch variant. In comparison, the PMI-LANG system takes days to train. Finally, our results show that the online algorithm can perform better than LexStat. LexStat and PHMM take more than 5 hours to test the language subset of the Austro language family. In contrast, PMI (both online and batch) takes less than 10 minutes for each value of m, \u03b1 in the case of extra-family training. We also find that 5 scans across the entire data is sufficient for the convergence."}, {"heading": "8.3 Analyzing PHMM\u2019s performance", "text": "Although PHMMs are the most complex of the models tested, the performance of these models is not as good as the conceptually simpler PMI models, and this lack of performance may be due to the characteristics of the PHMM. Transition probability from initial state to match or gap state is the same as transition probability from match state to gap state or even (Figure 1). Although this is desirable for biological purposes, it is a major problem for linguistic applications. Starting an alignment with match state is more likely than starting with a gap. [9] Therefore, the alignments generated by PHMMs tend to have gaps at the end of the string rather than at the beginning, leading to problems for datasets where word length differs greatly. PHMM performs worst for datasets that exhibit a huge difference in word length."}, {"heading": "9 Conclusion", "text": "In this paper, we examined the performance of different sequence algorithms - both learned and linguistically designed - for the task of recognition across different language families. We note that the online training of PMI and PHMM accelerates convergence and delivers comparable or better results than the batch variant and the state-of-the-art LexStat system. The online PMI system shows the best performance across different language families. In summary, PMI systems can be trained faster online and deliver better accuracy than current state-of-the-art systems."}], "references": [{"title": "A comparison of extrinsic clustering evaluation metrics based on formal constraints", "author": ["Enrique Amig\u00f3", "Julio Gonzalo", "Javier Artiles", "Felisa Verdejo"], "venue": "Information retrieval,", "citeRegEx": "Amig\u00f3 et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Amig\u00f3 et al\\.", "year": 2009}, {"title": "Automated reconstruction of ancient languages using probabilistic models of sound change", "author": ["Alexandre Bouchard-C\u00f4t\u00e9", "David Hall", "Thomas L. Griffiths", "Dan Klein"], "venue": "Proceedings of the National Academy of Sciences,", "citeRegEx": "Bouchard.C\u00f4t\u00e9 et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bouchard.C\u00f4t\u00e9 et al\\.", "year": 2013}, {"title": "Mapping the origins and expansion of the IndoEuropean language family", "author": ["Remco Bouckaert", "Philippe Lemey", "Michael Dunn", "Simon J. Greenhill", "Alexander V. Alekseyenko", "Alexei J. Drummond", "Russell D. Gray", "Marc A. Suchard", "Quentin D. Atkinson"], "venue": null, "citeRegEx": "Bouckaert et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Bouckaert et al\\.", "year": 2012}, {"title": "Word association norms, mutual information, and lexicography", "author": ["Kenneth Ward Church", "Patrick Hanks"], "venue": "Computational Linguistics,", "citeRegEx": "Church and Hanks.,? \\Q1990\\E", "shortCiteRegEx": "Church and Hanks.", "year": 1990}, {"title": "Computational feature-sensitive reconstruction of language relationships: Developing the aline distance for comparative historical linguistic reconstruction", "author": ["Sean S Downey", "Brian Hallmark", "Murray P Cox", "Peter Norquest", "J Stephen Lansing"], "venue": "Journal of Quantitative Linguistics,", "citeRegEx": "Downey et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Downey et al\\.", "year": 2008}, {"title": "Biological sequence analysis: probabilistic models of proteins and nucleic acids", "author": ["Richard Durbin", "Sean R Eddy", "Anders Krogh", "Graeme Mitchison"], "venue": null, "citeRegEx": "Durbin et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Durbin et al\\.", "year": 2001}, {"title": "An Indo-European classification: A lexicostatistical experiment", "author": ["Isidore Dyen", "Joseph B. Kruskal", "Paul Black"], "venue": "Transactions of the American Philosophical Society,", "citeRegEx": "Dyen et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Dyen et al\\.", "year": 1992}, {"title": "Language-tree divergence times support the anatolian theory of indo-european origin", "author": ["Russell D Gray", "Quentin D Atkinson"], "venue": "Nature, 426(6965):435\u2013439,", "citeRegEx": "Gray and Atkinson.,? \\Q2003\\E", "shortCiteRegEx": "Gray and Atkinson.", "year": 2003}, {"title": "Levenshtein distances fail to identify language relationships accurately", "author": ["Simon J Greenhill"], "venue": "Computational Linguistics,", "citeRegEx": "Greenhill.,? \\Q2011\\E", "shortCiteRegEx": "Greenhill.", "year": 2011}, {"title": "Austronesian language phylogenies: Myths and misconceptions about Bayesian computational methods. Austronesian Historical Linguistics and Culture History: A Festschrift for Robert Blust", "author": ["Simon J. Greenhill", "Russell D. Gray"], "venue": null, "citeRegEx": "Greenhill and Gray.,? \\Q2009\\E", "shortCiteRegEx": "Greenhill and Gray.", "year": 2009}, {"title": "Clustering semantically equivalent words into cognate sets in multilingual lists", "author": ["Bradley Hauer", "Grzegorz Kondrak"], "venue": "In Proceedings of the 5th International Joint Conference on Natural Language Processing,", "citeRegEx": "Hauer and Kondrak.,? \\Q2011\\E", "shortCiteRegEx": "Hauer and Kondrak.", "year": 2011}, {"title": "Positing language relationships using aline", "author": ["Paul Huff", "Deryle Lonsdale"], "venue": "Language Dynamics and Change,", "citeRegEx": "Huff and Lonsdale.,? \\Q2011\\E", "shortCiteRegEx": "Huff and Lonsdale.", "year": 2011}, {"title": "Phylogenetic inference from word lists using weighted alignment with empirically determined weights", "author": ["Gerhard J\u00e4ger"], "venue": "Language Dynamics and Change,", "citeRegEx": "J\u00e4ger.,? \\Q2013\\E", "shortCiteRegEx": "J\u00e4ger.", "year": 2013}, {"title": "Support for linguistic macrofamilies from weighted sequence alignment", "author": ["Gerhard J\u00e4ger"], "venue": "Proceedings of the National Academy of Sciences,", "citeRegEx": "J\u00e4ger.,? \\Q2015\\E", "shortCiteRegEx": "J\u00e4ger.", "year": 2015}, {"title": "A new algorithm for the alignment of phonetic sequences. In Proceedings of the 1st North American chapter of the Association for Computational Linguistics conference, pages 288\u2013295", "author": ["Grzegorz Kondrak"], "venue": "Association for Computational Linguistics,", "citeRegEx": "Kondrak.,? \\Q2000\\E", "shortCiteRegEx": "Kondrak.", "year": 2000}, {"title": "A course in phonetics", "author": ["Peter Ladefoged"], "venue": "Hardcourt Brace Jovanovich Inc. NY,", "citeRegEx": "Ladefoged.,? \\Q1975\\E", "shortCiteRegEx": "Ladefoged.", "year": 1975}, {"title": "Binary codes capable of correcting deletions, insertions, and reversals", "author": ["V.I. Levenshtein"], "venue": "Soviet Physics Doklady,", "citeRegEx": "Levenshtein.,? \\Q1966\\E", "shortCiteRegEx": "Levenshtein.", "year": 1966}, {"title": "Online em for unsupervised models", "author": ["Percy Liang", "Dan Klein"], "venue": "In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics,", "citeRegEx": "Liang and Klein.,? \\Q2009\\E", "shortCiteRegEx": "Liang and Klein.", "year": 2009}, {"title": "Lexstat: Automatic detection of cognates in multilingual wordlists", "author": ["Johann-Mattis List"], "venue": "In Proceedings of the EACL 2012 Joint Workshop of LINGVIS & UNCLH,", "citeRegEx": "List.,? \\Q2012\\E", "shortCiteRegEx": "List.", "year": 2012}, {"title": "Sequence comparison in historical linguistics. D\u00fcsseldorf University Press, D\u00fcsseldorf, 2014a. URL http://sequencecomparison. github.io", "author": ["Johann-Mattis List"], "venue": null, "citeRegEx": "List.,? \\Q2014\\E", "shortCiteRegEx": "List.", "year": 2014}, {"title": "Investigating the impact of sample size on cognate detection", "author": ["Johann-Mattis List"], "venue": "Journal of Language Relationship,", "citeRegEx": "List.,? \\Q2014\\E", "shortCiteRegEx": "List.", "year": 2014}, {"title": "Lingpy. a python library for historical linguistics, 2016", "author": ["Johann-Mattis List", "Robert Forkel"], "venue": "URL http://lingpy.org", "citeRegEx": "List and Forkel.,? \\Q2016\\E", "shortCiteRegEx": "List and Forkel.", "year": 2016}, {"title": "Using sequence similarity networks to identify partial cognates in multilingual wordlists", "author": ["Johann-Mattis List", "Philippe Lopez", "Eric Bapteste"], "venue": "In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics", "citeRegEx": "List et al\\.,? \\Q2016\\E", "shortCiteRegEx": "List et al\\.", "year": 2016}, {"title": "Computing word similarity and identifying cognates with pair hidden Markov models", "author": ["Wesley Mackay", "Grzegorz Kondrak"], "venue": "CONLL \u201905,", "citeRegEx": "Mackay and Kondrak.,? \\Q2005\\E", "shortCiteRegEx": "Mackay and Kondrak.", "year": 2005}, {"title": "A general method applicable to the search for similarities in the amino acid sequence of two proteins", "author": ["Saul B. Needleman", "Christian D. Wunsch"], "venue": "Journal of Molecular Biology,", "citeRegEx": "Needleman and Wunsch.,? \\Q1970\\E", "shortCiteRegEx": "Needleman and Wunsch.", "year": 1970}, {"title": "Finding and evaluating community structure in networks", "author": ["Mark EJ Newman", "Michelle Girvan"], "venue": "Phys. Rev. E,", "citeRegEx": "Newman and Girvan.,? \\Q2004\\E", "shortCiteRegEx": "Newman and Girvan.", "year": 2004}, {"title": "Automatic cognate identification with gap-weighted string subsequences", "author": ["Taraka Rama"], "venue": "In Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies.,", "citeRegEx": "Rama.,? \\Q2015\\E", "shortCiteRegEx": "Rama.", "year": 2015}, {"title": "Comparative evaluation of string similarity measures for automatic language classification", "author": ["Taraka Rama", "Lars Borin"], "venue": "Sequences in Language and Text,", "citeRegEx": "Rama and Borin.,? \\Q2015\\E", "shortCiteRegEx": "Rama and Borin.", "year": 2015}, {"title": "V-measure: A conditional entropy-based external cluster evaluation measure", "author": ["Andrew Rosenberg", "Julia Hirschberg"], "venue": "In EMNLP-CoNLL,", "citeRegEx": "Rosenberg and Hirschberg.,? \\Q2007\\E", "shortCiteRegEx": "Rosenberg and Hirschberg.", "year": 2007}, {"title": "Maps of random walks on complex networks reveal community structure", "author": ["Martin Rosvall", "Carl T. Bergstrom"], "venue": "Proceedings of the National Academy of Sciences,", "citeRegEx": "Rosvall and Bergstrom.,? \\Q2008\\E", "shortCiteRegEx": "Rosvall and Bergstrom.", "year": 2008}, {"title": "Languages with longer words have more lexical change", "author": ["S\u00f8ren Wichmann", "Eric W Holman"], "venue": "In Approaches to Measuring Linguistic Differences,", "citeRegEx": "Wichmann and Holman.,? \\Q2013\\E", "shortCiteRegEx": "Wichmann and Holman.", "year": 2013}, {"title": "Inducing sound segment differences using Pair Hidden Markov Models. pages 48\u201356", "author": ["Martijn Wieling", "Therese Leinonen", "John Nerbonne"], "venue": "Association for Computational Linguistics,", "citeRegEx": "Wieling et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Wieling et al\\.", "year": 2007}], "referenceMentions": [{"referenceID": 9, "context": ", 2013]1 and cognate databases for Austronesian [Greenhill and Gray, 2009] and Indo-European [Bouckaert et al.", "startOffset": 48, "endOffset": 74}, {"referenceID": 2, "context": ", 2013]1 and cognate databases for Austronesian [Greenhill and Gray, 2009] and Indo-European [Bouckaert et al., 2012].", "startOffset": 93, "endOffset": 117}, {"referenceID": 2, "context": ", 2013]1 and cognate databases for Austronesian [Greenhill and Gray, 2009] and Indo-European [Bouckaert et al., 2012]. The availability of word lists (without cognate judgments) has allowed scholars like Rama and Borin [2015] and J\u00e4ger [2015] to experiment with different weighted string similarity measures for the purpose of inferring the family trees of world\u2019s languages, without explicit cognate identification.", "startOffset": 94, "endOffset": 226}, {"referenceID": 2, "context": ", 2013]1 and cognate databases for Austronesian [Greenhill and Gray, 2009] and Indo-European [Bouckaert et al., 2012]. The availability of word lists (without cognate judgments) has allowed scholars like Rama and Borin [2015] and J\u00e4ger [2015] to experiment with different weighted string similarity measures for the purpose of inferring the family trees of world\u2019s languages, without explicit cognate identification.", "startOffset": 94, "endOffset": 243}, {"referenceID": 2, "context": ", 2013]1 and cognate databases for Austronesian [Greenhill and Gray, 2009] and Indo-European [Bouckaert et al., 2012]. The availability of word lists (without cognate judgments) has allowed scholars like Rama and Borin [2015] and J\u00e4ger [2015] to experiment with different weighted string similarity measures for the purpose of inferring the family trees of world\u2019s languages, without explicit cognate identification. On the other hand, List [2012] proposed a cognate clustering system that combines handcrafted weighted string similarity measures and permutation tests for the purpose of automated cognate identification.", "startOffset": 94, "endOffset": 448}, {"referenceID": 2, "context": ", 2013]1 and cognate databases for Austronesian [Greenhill and Gray, 2009] and Indo-European [Bouckaert et al., 2012]. The availability of word lists (without cognate judgments) has allowed scholars like Rama and Borin [2015] and J\u00e4ger [2015] to experiment with different weighted string similarity measures for the purpose of inferring the family trees of world\u2019s languages, without explicit cognate identification. On the other hand, List [2012] proposed a cognate clustering system that combines handcrafted weighted string similarity measures and permutation tests for the purpose of automated cognate identification. In a different approach, Hauer and Kondrak [2011] experimented Known as Automated Similarity Judgment Program (ASJP).", "startOffset": 94, "endOffset": 672}, {"referenceID": 22, "context": "Finally, Rama [2015] use string kernel inspired features for training a SVM linear classifier for pair-wise cognate identification.", "startOffset": 9, "endOffset": 21}, {"referenceID": 8, "context": "As noted by Hauer and Kondrak [2011], availability of a reliable multilingual cognate identification system can be used to supply the cognate judgments as an input to the phylogenetic inference algorithms introduced by Gray and Atkinson [2003] and reconstruction methods of Bouchard-C\u00f4t\u00e9 et al.", "startOffset": 12, "endOffset": 37}, {"referenceID": 6, "context": "As noted by Hauer and Kondrak [2011], availability of a reliable multilingual cognate identification system can be used to supply the cognate judgments as an input to the phylogenetic inference algorithms introduced by Gray and Atkinson [2003] and reconstruction methods of Bouchard-C\u00f4t\u00e9 et al.", "startOffset": 219, "endOffset": 244}, {"referenceID": 1, "context": "As noted by Hauer and Kondrak [2011], availability of a reliable multilingual cognate identification system can be used to supply the cognate judgments as an input to the phylogenetic inference algorithms introduced by Gray and Atkinson [2003] and reconstruction methods of Bouchard-C\u00f4t\u00e9 et al. [2013].2 The phylogenetic inference methods require cognate judgments which are only available for a small number of well-studied language families such as Indo-European and Austronesian.", "startOffset": 274, "endOffset": 302}, {"referenceID": 10, "context": "The similarity between a word pair can be computed using supervised approaches [Hauer and Kondrak, 2011] or by using sequence alignment algorithms such as Needleman-Wunsch [Needleman and Wunsch, 1970] or Levenshtein distance [Levenshtein, 1966].", "startOffset": 79, "endOffset": 104}, {"referenceID": 24, "context": "The similarity between a word pair can be computed using supervised approaches [Hauer and Kondrak, 2011] or by using sequence alignment algorithms such as Needleman-Wunsch [Needleman and Wunsch, 1970] or Levenshtein distance [Levenshtein, 1966].", "startOffset": 172, "endOffset": 200}, {"referenceID": 16, "context": "The similarity between a word pair can be computed using supervised approaches [Hauer and Kondrak, 2011] or by using sequence alignment algorithms such as Needleman-Wunsch [Needleman and Wunsch, 1970] or Levenshtein distance [Levenshtein, 1966].", "startOffset": 225, "endOffset": 244}, {"referenceID": 23, "context": "[2007] compared Pair Hidden Markov Model (PHMM) [Mackay and Kondrak, 2005] and pointwise mutual information (PMI) [Church and Hanks, 1990] weighted Levenshtein distance for Dutch dialect comparison.", "startOffset": 48, "endOffset": 74}, {"referenceID": 3, "context": "[2007] compared Pair Hidden Markov Model (PHMM) [Mackay and Kondrak, 2005] and pointwise mutual information (PMI) [Church and Hanks, 1990] weighted Levenshtein distance for Dutch dialect comparison.", "startOffset": 114, "endOffset": 138}, {"referenceID": 8, "context": "The similarity between a word pair can be computed using supervised approaches [Hauer and Kondrak, 2011] or by using sequence alignment algorithms such as Needleman-Wunsch [Needleman and Wunsch, 1970] or Levenshtein distance [Levenshtein, 1966]. In dialectometry, Wieling et al. [2007] compared Pair Hidden Markov Model (PHMM) [Mackay and Kondrak, 2005] and pointwise mutual information (PMI) [Church and Hanks, 1990] weighted Levenshtein distance for Dutch dialect comparison.", "startOffset": 80, "endOffset": 286}, {"referenceID": 2, "context": "[2007] compared Pair Hidden Markov Model (PHMM) [Mackay and Kondrak, 2005] and pointwise mutual information (PMI) [Church and Hanks, 1990] weighted Levenshtein distance for Dutch dialect comparison. In historical linguistics, J\u00e4ger [2013] developed a PMI based method for computing the string similarity using the ASJP database.", "startOffset": 115, "endOffset": 239}, {"referenceID": 1, "context": "The cognate clustering system in Bouchard-C\u00f4t\u00e9 et al. [2013] requires the tree structure of the language family to be know beforehand.", "startOffset": 33, "endOffset": 61}, {"referenceID": 18, "context": "Our results show that online training can perform better than a linguistically well-informed system known as LexStat [List, 2012].", "startOffset": 117, "endOffset": 129}, {"referenceID": 12, "context": "Also, the online algorithms allow our systems to be trained in few minutes and give similar accuracies as the batch trained systems of J\u00e4ger [2013]. The paper is organized as follows.", "startOffset": 135, "endOffset": 148}, {"referenceID": 29, "context": "[2016] explore the use of InfoMap [Rosvall and Bergstrom, 2008] for the detection of partial cognates in subgroups of Sino-Tibetan language family.", "startOffset": 34, "endOffset": 63}, {"referenceID": 12, "context": "Moreover, the PMI-LANG [J\u00e4ger, 2013], has not been evaluated at the task of unsupervised cognate clustering.", "startOffset": 23, "endOffset": 36}, {"referenceID": 10, "context": "Hauer and Kondrak [2011] trained a linear SVM on word similarity features and use the SVM model to assign a similarity score to the word pair.", "startOffset": 0, "endOffset": 25}, {"referenceID": 10, "context": "Hauer and Kondrak [2011] trained a linear SVM on word similarity features and use the SVM model to assign a similarity score to the word pair. For each meaning, a word pair distance matrix is computed and supplied to the average linkage clustering algorithm for inferring cognate clusters. The authors observe that the SVM trained system performs better than a baseline that judges the similarity of two words based on the identity of the first two consonants. List [2012] introduced a system known as LexStat (described in section 6) that is sensitive to segment similarities and chance similarities due to borrowing or semantic shift.", "startOffset": 0, "endOffset": 473}, {"referenceID": 10, "context": "Hauer and Kondrak [2011] trained a linear SVM on word similarity features and use the SVM model to assign a similarity score to the word pair. For each meaning, a word pair distance matrix is computed and supplied to the average linkage clustering algorithm for inferring cognate clusters. The authors observe that the SVM trained system performs better than a baseline that judges the similarity of two words based on the identity of the first two consonants. List [2012] introduced a system known as LexStat (described in section 6) that is sensitive to segment similarities and chance similarities due to borrowing or semantic shift. The author tests this system on a number of small-sized (consisting of less than 20 languages) datasets for the purpose of cognate identification and reports that the system performs better than Levenshtein distance. In a recent paper, List et al. [2016] explore the use of InfoMap [Rosvall and Bergstrom, 2008] for the detection of partial cognates in subgroups of Sino-Tibetan language family.", "startOffset": 0, "endOffset": 892}, {"referenceID": 10, "context": "Hauer and Kondrak [2011] trained a linear SVM on word similarity features and use the SVM model to assign a similarity score to the word pair. For each meaning, a word pair distance matrix is computed and supplied to the average linkage clustering algorithm for inferring cognate clusters. The authors observe that the SVM trained system performs better than a baseline that judges the similarity of two words based on the identity of the first two consonants. List [2012] introduced a system known as LexStat (described in section 6) that is sensitive to segment similarities and chance similarities due to borrowing or semantic shift. The author tests this system on a number of small-sized (consisting of less than 20 languages) datasets for the purpose of cognate identification and reports that the system performs better than Levenshtein distance. In a recent paper, List et al. [2016] explore the use of InfoMap [Rosvall and Bergstrom, 2008] for the detection of partial cognates in subgroups of Sino-Tibetan language family. The authors compare the performance of average linkage clustering against InfoMap and find that InfoMap performs better than average linkage clustering. The above listed works test similar datasets using different experimental settings. For instance, Hauer and Kondrak [2011] trained and tested on a subset of language families that were provided by Wichmann and Holman [2013].", "startOffset": 0, "endOffset": 1309}, {"referenceID": 10, "context": "Hauer and Kondrak [2011] trained a linear SVM on word similarity features and use the SVM model to assign a similarity score to the word pair. For each meaning, a word pair distance matrix is computed and supplied to the average linkage clustering algorithm for inferring cognate clusters. The authors observe that the SVM trained system performs better than a baseline that judges the similarity of two words based on the identity of the first two consonants. List [2012] introduced a system known as LexStat (described in section 6) that is sensitive to segment similarities and chance similarities due to borrowing or semantic shift. The author tests this system on a number of small-sized (consisting of less than 20 languages) datasets for the purpose of cognate identification and reports that the system performs better than Levenshtein distance. In a recent paper, List et al. [2016] explore the use of InfoMap [Rosvall and Bergstrom, 2008] for the detection of partial cognates in subgroups of Sino-Tibetan language family. The authors compare the performance of average linkage clustering against InfoMap and find that InfoMap performs better than average linkage clustering. The above listed works test similar datasets using different experimental settings. For instance, Hauer and Kondrak [2011] trained and tested on a subset of language families that were provided by Wichmann and Holman [2013]. At the same time, to the best of our knowledge, the LexStat system has not been evaluated on all the available language families.", "startOffset": 0, "endOffset": 1410}, {"referenceID": 12, "context": "A second parameter known as gap extension penalty has lesser or equal penalty than the gap opening parameter and models the fact that deletions occur in chunks J\u00e4ger [2013]. VNW is not sensitive to segment pairs, but a realistic algorithm should assign higher similarity score to sound correspondences such as /l/ \u223c /r/ than the sound correspondences /p/ \u223c /r/.", "startOffset": 160, "endOffset": 173}, {"referenceID": 12, "context": "We estimated PMI scores from raw data, largely following the method described in J\u00e4ger [2013]. The whole training procedure can be described as follows: 1.", "startOffset": 81, "endOffset": 94}, {"referenceID": 12, "context": "For the gap penalties we used the values proposed in J\u00e4ger [2013]. 5.", "startOffset": 53, "endOffset": 66}, {"referenceID": 5, "context": "2 Pair Hidden Markov Model Pair Hidden Markov Model was first proposed in the context of computational biology as a tool for the comparison of DNA or protein sequences [Durbin et al., 2001].", "startOffset": 168, "endOffset": 189}, {"referenceID": 23, "context": "An alignment of Italian due and Spanish dos \u2018two\u2019 cannot be generated by a PHMM without the transition between X and Y [Mackay and Kondrak, 2005].", "startOffset": 119, "endOffset": 145}, {"referenceID": 23, "context": "Figure 1: Pair Hidden Markov model as proposed by Mackay & Kondrak [Mackay and Kondrak, 2005].", "startOffset": 67, "endOffset": 93}, {"referenceID": 5, "context": "The PHMMs are trained using Baum-Welch expectation maximization algorithm [Durbin et al., 2001].", "startOffset": 74, "endOffset": 95}, {"referenceID": 17, "context": "In contrast, Online EM [Liang and Klein, 2009], updates the model parameters after aligning a subset of word pairs (also known as minibatch in online learning literature).", "startOffset": 23, "endOffset": 46}, {"referenceID": 15, "context": "Liang and Klein [2009] observe that batch training procedure can lead to slow convergence.", "startOffset": 0, "endOffset": 23}, {"referenceID": 12, "context": "As a matter of fact, J\u00e4ger [2013] trains his PMI system using the standard EM (also known as batch EM) which updates the parameters in a PMI scoring matrix only after aligning all the word pairs.", "startOffset": 21, "endOffset": 34}, {"referenceID": 25, "context": "A community is a group of nodes with more edges connecting the nodes within the community than connecting them with nodes outside the community [Newman and Girvan, 2004].", "startOffset": 144, "endOffset": 169}, {"referenceID": 6, "context": "1 Indo-European database The Indo-European Lexical database (IELex) was created by Dyen et al. [1992] and curated by Michael Dunn.", "startOffset": 83, "endOffset": 102}, {"referenceID": 6, "context": "1 Indo-European database The Indo-European Lexical database (IELex) was created by Dyen et al. [1992] and curated by Michael Dunn.4 The IELex database is not transcribed in uniform IPA and retains many forms transcribed in the Romanized IPA format of Dyen et al. [1992]. We cleaned the IELex database of any non-IPA-like transcriptions and converted the cleaned subset of the database into ASJP format.", "startOffset": 83, "endOffset": 270}, {"referenceID": 9, "context": "2 Austronesian vocabulary database The Austronesian Vocabulary Database (ABVD) [Greenhill and Gray, 2009] has word lists for 210 Swadesh concepts and 378 languages.", "startOffset": 79, "endOffset": 105}, {"referenceID": 27, "context": "3 Short word lists with cognacy judgments: Wichmann and Holman [2013] and List [2014a] compiled cognacy wordlists for subsets of families from various scholarly sources such as comparative handbooks and historical linguistics\u2019 articles.", "startOffset": 43, "endOffset": 70}, {"referenceID": 18, "context": "3 Short word lists with cognacy judgments: Wichmann and Holman [2013] and List [2014a] compiled cognacy wordlists for subsets of families from various scholarly sources such as comparative handbooks and historical linguistics\u2019 articles.", "startOffset": 74, "endOffset": 87}, {"referenceID": 0, "context": "3 Evaluation Measures We evaluate the results of clustering analysis using B-cubed F-score [Amig\u00f3 et al., 2009].", "startOffset": 91, "endOffset": 111}, {"referenceID": 28, "context": "The authors show that cluster evaluation measures based on entropy such as Mutual Information and V-measure [Rosenberg and Hirschberg, 2007] and Rand index do not satisfy the four constraints.", "startOffset": 108, "endOffset": 140}, {"referenceID": 0, "context": "Amig\u00f3 et al. [2009] show that the B-cubed F-score satisfies four formal constraints known as cluster homogeneity, cluster completeness, rag bag (robustness to misplacement of a true singleton item), and robustness to variation in cluster size.", "startOffset": 0, "endOffset": 20}, {"referenceID": 0, "context": "Amig\u00f3 et al. [2009] show that the B-cubed F-score satisfies four formal constraints known as cluster homogeneity, cluster completeness, rag bag (robustness to misplacement of a true singleton item), and robustness to variation in cluster size. The authors show that cluster evaluation measures based on entropy such as Mutual Information and V-measure [Rosenberg and Hirschberg, 2007] and Rand index do not satisfy the four constraints. Both Hauer and Kondrak [2011] and List et al.", "startOffset": 0, "endOffset": 467}, {"referenceID": 0, "context": "Amig\u00f3 et al. [2009] show that the B-cubed F-score satisfies four formal constraints known as cluster homogeneity, cluster completeness, rag bag (robustness to misplacement of a true singleton item), and robustness to variation in cluster size. The authors show that cluster evaluation measures based on entropy such as Mutual Information and V-measure [Rosenberg and Hirschberg, 2007] and Rand index do not satisfy the four constraints. Both Hauer and Kondrak [2011] and List et al. [2016] use B-cubed F-scores to evaluate their cognate clustering systems.", "startOffset": 0, "endOffset": 490}, {"referenceID": 14, "context": "1 ALINE ALINE is a sequence alignment system designed by Kondrak [2000] for computing similarity between two words by decomposing phonemes into multivalued and", "startOffset": 57, "endOffset": 72}, {"referenceID": 4, "context": "Following Downey et al. [2008], we convert ALINE\u2019s similarity score sab between two words a, b is converted to a distance score based on the following formula: 1.", "startOffset": 10, "endOffset": 31}, {"referenceID": 12, "context": "2 PMI-LANG J\u00e4ger [2013] developed a system that learns PMI sound matrices to optimize a criterion designed to optimize language relatedness.", "startOffset": 11, "endOffset": 24}, {"referenceID": 12, "context": "2 PMI-LANG J\u00e4ger [2013] developed a system that learns PMI sound matrices to optimize a criterion designed to optimize language relatedness. The core idea is to tie up word similarity to language similarity such that close languages such as English/German tend to have more similarity than English/Hindi. The language similarity function amounts to maximizing similarity between probable cognates to learn a PMI score matrix. J\u00e4ger [2013] applies the learned PMI score matrix to infer phylogenetic trees of language families.", "startOffset": 11, "endOffset": 439}, {"referenceID": 18, "context": "3 LexStat LexStat [List, 2012] is part of LingPy [List and Forkel, 2016] library offering stateof-the-art alignment algorithms for aligning word pairs and clustering them into cognate sets.", "startOffset": 18, "endOffset": 30}, {"referenceID": 21, "context": "3 LexStat LexStat [List, 2012] is part of LingPy [List and Forkel, 2016] library offering stateof-the-art alignment algorithms for aligning word pairs and clustering them into cognate sets.", "startOffset": 49, "endOffset": 72}, {"referenceID": 11, "context": "We use the Python implementation provided by Huff and Lonsdale [2011] which is available at https://sourceforge.", "startOffset": 45, "endOffset": 70}, {"referenceID": 18, "context": "Following List [2014b], we do not report LexStat results for the language groups which have word lists shorter than 100 meanings.", "startOffset": 10, "endOffset": 23}, {"referenceID": 8, "context": "Greenhill [2011] applied Levenshtein distance for the classification of Austronesian languages and argued that Levenshtein distance does not perform well at the task of detecting language relationships.", "startOffset": 0, "endOffset": 17}], "year": 2017, "abstractText": "In this paper we explore the use of unsupervised methods for detecting cognates in multilingual word lists. We use online EM to train sound segment similarity weights for computing similarity between two words. We tested our online systems on geographically spread sixteen different language groups of the world and show that the Online PMI system (Pointwise Mutual Information) outperforms a HMM based system and two linguistically motivated systems: LexStat and ALINE. Our results suggest that a PMI system trained in an online fashion can be used by historical linguists for fast and accurate identification of cognates in not so well-studied language families.", "creator": "LaTeX with hyperref package"}}}