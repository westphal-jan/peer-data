{"id": "1702.05068", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Feb-2017", "title": "Discovering objects and their relations from entangled scene representations", "abstract": "Our world can be succinctly and compactly described as structured scenes of objects and relations. A typical room, for example, contains salient objects such as tables, chairs and books, and these objects typically relate to each other by their underlying causes and semantics. This gives rise to correlated features, such as position, function and shape. Humans exploit knowledge of objects and their relations for learning a wide spectrum of tasks, and more generally when learning the structure underlying observed data. In this work, we introduce relation networks (RNs) - a general purpose neural network architecture for object-relation reasoning. We show that RNs are capable of learning object relations from scene description data. Furthermore, we show that RNs can act as a bottleneck that induces the factorization of objects from entangled scene description inputs, and from distributed deep representations of scene images provided by a variational autoencoder. The model can also be used in conjunction with differentiable memory mechanisms for implicit relation discovery in one-shot learning tasks. Our results suggest that relation networks are a potentially powerful architecture for solving a variety of problems that require object relation reasoning.", "histories": [["v1", "Thu, 16 Feb 2017 18:08:27 GMT  (8935kb,D)", "http://arxiv.org/abs/1702.05068v1", "ICLR Workshop 2017"]], "COMMENTS": "ICLR Workshop 2017", "reviews": [], "SUBJECTS": "cs.LG cs.CV", "authors": ["david raposo", "adam santoro", "david barrett", "razvan pascanu", "timothy lillicrap", "peter battaglia"], "accepted": false, "id": "1702.05068"}, "pdf": {"name": "1702.05068.pdf", "metadata": {"source": "CRF", "title": "DISCOVERING OBJECTS AND THEIR RELATIONS FROM ENTANGLED SCENE REPRESENTATIONS", "authors": ["D. Raposo", "A. Santoro", "D.G.T. Barrett", "R. Pascanu", "T. Lillicrap", "P. Battaglia"], "emails": ["peterbattaglia}@google.com"], "sections": [{"heading": "1 INTRODUCTION", "text": "The ability to reason about objects and relationships is important for solving a variety of tasks (Spelke et al., 1992; Lake et al., 2016). For example, object relationships allow the transfer of learned knowledge about superficial differences. In this work, we present a neural network architecture for learning to reason - or models - objects and their relationships, which we call relationships networks (RNs). RNs adhere to several important design principles. First, RNs are designed to engage with permutations of object descriptions in their inputs. For example, RN representations of the object {table, chair, book} are identical to arbitrary re-orders of the elements of the set."}, {"heading": "2 MODEL", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 DESCRIPTION AND IMPLEMENTATION", "text": "RNs are inspired by interaction networks (INs) (Battaglia et al., 2016), and therefore share similar functional insights. Both operate under the assumption that permutation invariance is a necessary prerequisite for solving relationship problems in a data-efficient manner. However, INs use relationships between objects as input to determine object interactions, mainly for the purpose of thinking about dynamics. RNs calculate object relationships and therefore aim to determine the object-related structure of static inputs. Suppose we have an object oi = (o1i, o 2 i, o n i) represented as a vector of features that include properties such as the object type, color, size, position, etc. A collection of m objects can be collected into an m called a matrix D. Although the term scene description refers to visual information, this need cannot be completely abstract, as the objects that represent the scene, and can imagine."}, {"heading": "3 EXPERIMENTAL TASKS AND DATA", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 DATASETS", "text": "In order to explore the ability of a model to derive relationships from scene descriptions and to use implicit relations that then depend on the objects created to solve more difficult tasks - such as learning once - we first developed datasets of scene descriptions and associated images. To create a scene description, we first define a graph of object relationships (see Figure 2). For example, suppose there are four types of squares, each type being independently identified by its color. A graph description of the relationships between each colored square could identify the blue square as the parent of the orsquare. If the nature of the relationship is \"position,\" then this particular relationship would be manifest as blue squares that are independently positioned in the scene, and orange squares that are positioned close to blue squares. Suppose we have triangles and circles as object types, with color as a relationship. If triangles become parents, then the color becomes triangles, then the color becomes triangles."}, {"heading": "3.2 TASK DESCRIPTIONS", "text": "This year it has come to the point that it has never come as far as this year."}, {"heading": "4 ADDITIONAL MODEL COMPONENTS AND TRAINING DETAILS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 VARIATIONAL AUTOENCODER", "text": "To derive relationships from latent representations of pixels, we used a variational autoencoder (VAE) (Kingma & Welling, 2013) with a Convolutionary Neural Network (CNN) as feature encoder and a deconvolutionary network as decoder (see Figure 3b). CNN consisted of two processing blocks. Input to each block was sent through a four-dimensional gradient layer that allowed parallel gradient streams using 8 cores of size 1x1, 3x3, 5x5, and 7x7, respectively. Outputs from these gradients were routed through a stack normalization layer that reflected and linked linear gradient layers, which was then re-entangled with a down-sampling kernel of size 3x3, 5x5, and 7x7. Outputs from these gradients were placed through a stack normalization layer that refictified gradient layers, and the entire gradient layers were refictified."}, {"heading": "4.2 MEMORY-AUGMENTED NEURAL NETWORK", "text": "In order to implicitly discover connections from scene descriptions, the RN was used as a pre-processor for a memory-enlarged neural network (MANN), as implemented in Santoro et al. (2016), and the reader is focused on full details about the use of networks with external memory. In short, the MANN core module consists of a controller - a long-term short-term memory (LSTM) (Hochreiter & Schmidhuber, 1997) - that interacts with read and write heads that in turn interact with external memory. External memory consists of a number of memory slots, each of which contains a vector of \"memory.\" During reading, the LSTM takes an input and produces a queer vector that the read head uses to query the external memory via a cosine distance across the memory slots, and returns a weighted sum of this vector based on the cosine distance."}, {"heading": "4.3 TRAINING DETAILS", "text": "The size of the RN - in terms of the number of layers and the number of units for both f\u03c6 and g\u0445 - was {200, 200}, {500, 500}, {1000, 1000} or {200, 200, 200, 200} We also trained an MLP baseline (for comparison) using equivalent network sizes. We experimented with different sizes for output of g\u0445. Performance is generally robust compared to the size selection, with similar results for 100, 200 or 500. MAN used an LSTM controller size of 200, 128 memory places, 40 for memory size and 4 read / write heads.The Adam Optimizer was used for optimization (Kingma & Ba, 2014), with a learning rate of 1e \u2212 4 for the scene description tasks and a learning rate of 1e \u2212 5 for the single study assignment. The number of iterations varied for each experiment and the 100 test batches were specified in the relevant numbers for each set of scenarios, whereby all the numbers were given for the performance of the 5% of the scenarios, and the 2% for the performance of the scenarios were specified in each set of the relevant numbers for each scenario."}, {"heading": "5 RESULTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 SUPERVISED LEARNING OF RELATIONAL STRUCTURE FROM SCENE DESCRIPTIONS", "text": "We begin by exploring the ability of RNs to learn the relationship structure of scenes by getting the RNs to classify object relationships (the adjacecy matrix) of a scene description as described in Section 3.2. As a baseline comparison, we compared their performance with that of MLPs of different size and depth. First, we compared the performance of these models in scenes where the relationship structure was defined by position (Figure 4a). Indeed, the RNs achieved a cross-entropy loss of 0.01 on a withheld test set, with MLPs of similar size not matching that performance (Figure 4a, peak)."}, {"heading": "5.2 INFERRING OBJECT RELATIONS FROM NON-SCENE DESCRIPTION INPUTS", "text": "Next, we will examine the ability of RNs to derive object relationships directly from input data that is not well organized into a scene description matrix of factored object representations. This is a difficult problem because RNs require a scene description matrix of objects as input. In most applications, a scene description matrix is not directly available, and therefore we need to add a mechanism to our RN to transform entangled representations (such as pixel images) directly into a representation that has the properties of a scene description matrix. Specifically, we need a transformation that generates a m x n dimensional matrix D, whose rows can be interpreted as objects and whose columns can be interpreted as features. In this section, we will examine architectures that can support the argument of object relations from entangled representations."}, {"heading": "5.2.1 INFERRING RELATIONS FROM ENTANGLED SCENE DESCRIPTIONS", "text": "In this task, we examined the network's ability to classify scenes from entangled scene descriptions. Intuitively, the RN should behave like an architectural bottleneck that can support the unbundling of objects by a downstream perception model to create factorial object representations on which it can operate. To create an entangled scene description, we started with the random permutation matrix B and converted it into a sizemn vector (i.e., a linked vector of objects [o1; o3; om]). We transformed this vector with a random permutation matrix B of size mn. We chose a permutation matrix for entanglement because it receives all input information without scaling between factors, and because it is inadjustable."}, {"heading": "5.2.2 INFERRING RELATIONS FROM PIXELS", "text": "Next, we examine the RN's ability to classify scenes from pixel representations of scenes. We use images from 100 unique scene classes from our position reference dataset (Figure 11 in the appendix).Images of scenes cannot be passed directly to an RN because the objects in images are not represented in a factorized form. We need to expand our RN with an image preprocessing mechanism capable of generating factorized object representations. To this end, we extend our RN with a variable autoencoder (VAE) whose latent variables provide inputs to a linear layer, which in turn provides inputs to the RN (similar to the linear layer in the previous section).Both the UAE and the RN were trained simultaneously - but gradients from the RN were not transferred to the VAE layer to represent the ratio layer as part of the model."}, {"heading": "5.3 IMPLICIT USE OF RELATIONS FOR ONE-SHOT LEARNING", "text": "Finally, we evaluate the potential to use RNs in conjunction with memory-enhanced neural networks to quickly - and implicitly - discover object relationships and use this knowledge for one-time learning. We trained a MAN with an RN pre-processor to perform a one-time classification of scenes as described in Section 3.2. To solve this task, the network must store representations of scenes (which, if class representations are to be unique, should necessarily contain relational information), and the episode-unique designation associated with the scene. Once a new sample of the same class is observed, it must use inferred relational information from that sample to query its memory and the appropriate label. During the training, a sequence of 50 random samples from 5 random classes (from a pool of 1900) was selected to constitute an episode. The test phase consisted of episodes with scenes from 5 randomly selected and 93 previously observed classes (from a pool of 700) to a high (from a pool of 500)."}, {"heading": "6 CONCLUSIONS", "text": "RNs are a powerful architecture for thinking about object relationships. Architecturally, they operate on pairs of objects (or object-like units) and force the invariance of objects by permutation. Of course, this architecture supports the classification of object relationship structures in scenes. RNs can also be extended by additional modules to support a wider range of tasks. Thus, we have shown that RNs can be extended by MANNs to support the learning of one-sided relationships. RNs can be used in conjunction with perception modules to think about object relationships in images and other intertwined representations, inducing factored object representations of intertwined scenes. The shape of these factored \"objects\" can be quite flexible and could allow representations of inputs that are not spatially localized or consist of multiple disjoints. In future work, it would be interesting to explore the range of \"objects\" that modules show are interconnected in a number of relationships."}, {"heading": "ACKNOWLEDGMENTS", "text": "We would like to thank Scott Reed, Daan Wierstra, Nando de Freitas, James Kirkpatrick and many others on the DeepMind team."}], "references": [{"title": "Interaction networks for learning about objects, relations and physics", "author": ["Peter Battaglia", "Razvan Pascanu", "Matthew Lai", "Danilo Jimenez Rezende", "Koray Kavukcuoglu"], "venue": "Advances in Neural Information Processing Systems,", "citeRegEx": "Battaglia et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Battaglia et al\\.", "year": 2016}, {"title": "Spectral networks and locally connected networks on graphs", "author": ["Joan Bruna", "Wojciech Zaremba", "Arthur Szlam", "Yann LeCun"], "venue": "arXiv preprint arXiv:1312.6203,", "citeRegEx": "Bruna et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bruna et al\\.", "year": 2013}, {"title": "Hico: A benchmark for recognizing human-object interactions in images", "author": ["Yu-Wei Chao", "Zhan Wang", "Yugeng He", "Jiaxuan Wang", "Jia Deng"], "venue": "In Proceedings of the IEEE International Conference on Computer Vision, pp", "citeRegEx": "Chao et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Chao et al\\.", "year": 2015}, {"title": "A tree-based context model for object recognition", "author": ["Myung Jin Choi", "Antonio Torralba", "Alan S Willsky"], "venue": "IEEE transactions on pattern analysis and machine intelligence,", "citeRegEx": "Choi et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Choi et al\\.", "year": 2012}, {"title": "Convolutional neural networks on graphs with fast localized spectral filtering", "author": ["Micha\u00ebl Defferrard", "Xavier Bresson", "Pierre Vandergheynst"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Defferrard et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Defferrard et al\\.", "year": 2016}, {"title": "Convolutional networks on graphs for learning molecular fingerprints", "author": ["David K Duvenaud", "Dougal Maclaurin", "Jorge Iparraguirre", "Rafael Bombarell", "Timothy Hirzel", "Al\u00e1n Aspuru-Guzik", "Ryan P Adams"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Duvenaud et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Duvenaud et al\\.", "year": 2015}, {"title": "Graph based convolutional neural network", "author": ["Michael Edwards", "Xianghua Xie"], "venue": "arXiv preprint arXiv:1609.08965,", "citeRegEx": "Edwards and Xie.,? \\Q2016\\E", "shortCiteRegEx": "Edwards and Xie.", "year": 2016}, {"title": "A discriminatively trained, multiscale, deformable part model", "author": ["Pedro Felzenszwalb", "David McAllester", "Deva Ramanan"], "venue": "In Computer Vision and Pattern Recognition,", "citeRegEx": "Felzenszwalb et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Felzenszwalb et al\\.", "year": 2008}, {"title": "Characterizing structural relationships in scenes using graph kernels", "author": ["Matthew Fisher", "Manolis Savva", "Pat Hanrahan"], "venue": "In ACM Transactions on Graphics (TOG),", "citeRegEx": "Fisher et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Fisher et al\\.", "year": 2011}, {"title": "Examplebased synthesis of 3d object arrangements", "author": ["Matthew Fisher", "Daniel Ritchie", "Manolis Savva", "Thomas Funkhouser", "Pat Hanrahan"], "venue": "ACM Transactions on Graphics (TOG),", "citeRegEx": "Fisher et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Fisher et al\\.", "year": 2012}, {"title": "Deep convolutional networks on graph-structured data", "author": ["Mikael Henaff", "Joan Bruna", "Yann LeCun"], "venue": "arXiv preprint arXiv:1506.05163,", "citeRegEx": "Henaff et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Henaff et al\\.", "year": 2015}, {"title": "Long short-term memory", "author": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber"], "venue": "Neural computation,", "citeRegEx": "Hochreiter and Schmidhuber.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter and Schmidhuber.", "year": 1997}, {"title": "Learning to learn using gradient descent", "author": ["Sepp Hochreiter", "A Steven Younger", "Peter R Conwell"], "venue": "In International Conference on Artificial Neural Networks,", "citeRegEx": "Hochreiter et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Hochreiter et al\\.", "year": 2001}, {"title": "Adam: A method for stochastic optimization", "author": ["Diederik Kingma", "Jimmy Ba"], "venue": "arXiv preprint arXiv:1412.6980,", "citeRegEx": "Kingma and Ba.,? \\Q2014\\E", "shortCiteRegEx": "Kingma and Ba.", "year": 2014}, {"title": "Auto-encoding variational bayes", "author": ["Diederik P Kingma", "Max Welling"], "venue": "arXiv preprint arXiv:1312.6114,", "citeRegEx": "Kingma and Welling.,? \\Q2013\\E", "shortCiteRegEx": "Kingma and Welling.", "year": 2013}, {"title": "Semi-supervised classification with graph convolutional networks", "author": ["Thomas N Kipf", "Max Welling"], "venue": "arXiv preprint arXiv:1609.02907,", "citeRegEx": "Kipf and Welling.,? \\Q2016\\E", "shortCiteRegEx": "Kipf and Welling.", "year": 2016}, {"title": "Visual genome: Connecting language and vision using crowdsourced dense image annotations", "author": ["Ranjay Krishna", "Yuke Zhu", "Oliver Groth", "Justin Johnson", "Kenji Hata", "Joshua Kravitz", "Stephanie Chen", "Yannis Kalantidis", "Li-Jia Li", "David A Shamma"], "venue": "arXiv preprint arXiv:1602.07332,", "citeRegEx": "Krishna et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Krishna et al\\.", "year": 2016}, {"title": "Human-level concept learning through probabilistic program induction", "author": ["Brenden M Lake", "Ruslan Salakhutdinov", "Joshua B Tenenbaum"], "venue": null, "citeRegEx": "Lake et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lake et al\\.", "year": 2015}, {"title": "Building machines that learn and think like people", "author": ["Brenden M Lake", "Tomer D Ullman", "Joshua B Tenenbaum", "Samuel J Gershman"], "venue": "arXiv preprint arXiv:1604.00289,", "citeRegEx": "Lake et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Lake et al\\.", "year": 2016}, {"title": "Gated graph sequence neural networks", "author": ["Yujia Li", "Daniel Tarlow", "Marc Brockschmidt", "Richard Zemel"], "venue": "arXiv preprint arXiv:1511.05493,", "citeRegEx": "Li et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Li et al\\.", "year": 2015}, {"title": "Creating consistent scene graphs using a probabilistic grammar", "author": ["Tianqiang Liu", "Siddhartha Chaudhuri", "Vladimir G Kim", "Qixing Huang", "Niloy J Mitra", "Thomas Funkhouser"], "venue": "ACM Transactions on Graphics (TOG),", "citeRegEx": "Liu et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2014}, {"title": "Metalearning with memory-augmented neural networks", "author": ["Adam Santoro", "Sergey Bartunov", "Matthew Botvinick", "Daan Wierstra", "Timothy Lillicrap"], "venue": "In Proceedings of The 33rd International Conference on Machine Learning,", "citeRegEx": "Santoro et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Santoro et al\\.", "year": 2016}, {"title": "The graph neural network model", "author": ["Franco Scarselli", "Marco Gori", "Ah Chung Tsoi", "Markus Hagenbuchner", "Gabriele Monfardini"], "venue": "IEEE Transactions on Neural Networks,", "citeRegEx": "Scarselli et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Scarselli et al\\.", "year": 2009}, {"title": "Origins of knowledge", "author": ["Elizabeth S Spelke", "Karen Breinlinger", "Janet Macomber", "Kristen Jacobson"], "venue": "Psychological review,", "citeRegEx": "Spelke et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Spelke et al\\.", "year": 1992}, {"title": "Learning design patterns with bayesian grammar induction", "author": ["Jerry Talton", "Lingfeng Yang", "Ranjitha Kumar", "Maxine Lim", "Noah Goodman", "Radom\u0131\u0301r M\u011bch"], "venue": "In Proceedings of the 25th annual ACM symposium on User interface software and technology,", "citeRegEx": "Talton et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Talton et al\\.", "year": 2012}, {"title": "How to grow a mind: Statistics, structure, and abstraction", "author": ["Joshua B Tenenbaum", "Charles Kemp", "Thomas L Griffiths", "Noah D Goodman"], "venue": null, "citeRegEx": "Tenenbaum et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Tenenbaum et al\\.", "year": 2011}, {"title": "Matching networks for one shot learning", "author": ["Oriol Vinyals", "Charles Blundell", "Timothy Lillicrap", "Koray Kavukcuoglu", "Daan Wierstra"], "venue": "arXiv preprint arXiv:1606.04080,", "citeRegEx": "Vinyals et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Vinyals et al\\.", "year": 2016}, {"title": "Synthesizing open worlds with constraints using locally annealed reversible jump mcmc", "author": ["Yi-Ting Yeh", "Lingfeng Yang", "Matthew Watson", "Noah D Goodman", "Pat Hanrahan"], "venue": "ACM Transactions on Graphics (TOG),", "citeRegEx": "Yeh et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Yeh et al\\.", "year": 2012}, {"title": "Make it home: automatic optimization of furniture", "author": ["Lap Fai Yu", "Sai Kit Yeung", "Chi Keung Tang", "Demetri Terzopoulos", "Tony F Chan", "Stanley J Osher"], "venue": null, "citeRegEx": "Yu et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Yu et al\\.", "year": 2011}, {"title": "The one-shot learning task proceeds as in Hochreiter et al", "author": ["Santoro"], "venue": null, "citeRegEx": "Santoro,? \\Q2016\\E", "shortCiteRegEx": "Santoro", "year": 2016}], "referenceMentions": [{"referenceID": 23, "context": "The ability to reason about objects and relations is important for solving a wide variety of tasks (Spelke et al., 1992; Lake et al., 2016).", "startOffset": 99, "endOffset": 139}, {"referenceID": 18, "context": "The ability to reason about objects and relations is important for solving a wide variety of tasks (Spelke et al., 1992; Lake et al., 2016).", "startOffset": 99, "endOffset": 139}, {"referenceID": 25, "context": "For example, object relations enable the transfer of learned knowledge across superficial dissimilarities (Tenenbaum et al., 2011): the predator-prey relationship between a lion and a zebra is knowledge that is similarly useful when applied to a bear and a salmon, even though many features of these animals are very different.", "startOffset": 106, "endOffset": 130}, {"referenceID": 0, "context": "In designing the RN architecture, we took inspiration from the recently developed Interaction Network (IN) (Battaglia et al., 2016) which was applied to modelling physical, spatiotemporal interactions.", "startOffset": 107, "endOffset": 131}, {"referenceID": 22, "context": "Our model is also related to various other approaches that apply neural networks directly to graphs (Scarselli et al., 2009; Bruna et al., 2013; Li et al., 2015; Duvenaud et al., 2015; Henaff et al., 2015; Defferrard et al., 2016; Kipf & Welling, 2016; Edwards & Xie, 2016).", "startOffset": 100, "endOffset": 273}, {"referenceID": 1, "context": "Our model is also related to various other approaches that apply neural networks directly to graphs (Scarselli et al., 2009; Bruna et al., 2013; Li et al., 2015; Duvenaud et al., 2015; Henaff et al., 2015; Defferrard et al., 2016; Kipf & Welling, 2016; Edwards & Xie, 2016).", "startOffset": 100, "endOffset": 273}, {"referenceID": 19, "context": "Our model is also related to various other approaches that apply neural networks directly to graphs (Scarselli et al., 2009; Bruna et al., 2013; Li et al., 2015; Duvenaud et al., 2015; Henaff et al., 2015; Defferrard et al., 2016; Kipf & Welling, 2016; Edwards & Xie, 2016).", "startOffset": 100, "endOffset": 273}, {"referenceID": 5, "context": "Our model is also related to various other approaches that apply neural networks directly to graphs (Scarselli et al., 2009; Bruna et al., 2013; Li et al., 2015; Duvenaud et al., 2015; Henaff et al., 2015; Defferrard et al., 2016; Kipf & Welling, 2016; Edwards & Xie, 2016).", "startOffset": 100, "endOffset": 273}, {"referenceID": 10, "context": "Our model is also related to various other approaches that apply neural networks directly to graphs (Scarselli et al., 2009; Bruna et al., 2013; Li et al., 2015; Duvenaud et al., 2015; Henaff et al., 2015; Defferrard et al., 2016; Kipf & Welling, 2016; Edwards & Xie, 2016).", "startOffset": 100, "endOffset": 273}, {"referenceID": 4, "context": "Our model is also related to various other approaches that apply neural networks directly to graphs (Scarselli et al., 2009; Bruna et al., 2013; Li et al., 2015; Duvenaud et al., 2015; Henaff et al., 2015; Defferrard et al., 2016; Kipf & Welling, 2016; Edwards & Xie, 2016).", "startOffset": 100, "endOffset": 273}, {"referenceID": 28, "context": "In graphics, a number of approaches have been used to capture contextual scene structure, such as energy models (Yu et al., 2011), graphical and mixture models (Fisher et al.", "startOffset": 112, "endOffset": 129}, {"referenceID": 8, "context": ", 2011), graphical and mixture models (Fisher et al., 2011; 2012), stochastic grammars (Liu et al.", "startOffset": 38, "endOffset": 65}, {"referenceID": 20, "context": ", 2011; 2012), stochastic grammars (Liu et al., 2014), and probabilistic programs (Talton et al.", "startOffset": 35, "endOffset": 53}, {"referenceID": 24, "context": ", 2014), and probabilistic programs (Talton et al., 2012; Yeh et al., 2012).", "startOffset": 36, "endOffset": 75}, {"referenceID": 27, "context": ", 2014), and probabilistic programs (Talton et al., 2012; Yeh et al., 2012).", "startOffset": 36, "endOffset": 75}, {"referenceID": 21, "context": "Finally, we combine RNs with memoryaugmented neural networks (MANNs) (Santoro et al., 2016) to solve a difficult one-shot learning task, demonstrating the ability of RNs\u2019 to act in conjunction with other neural network architectures to rapidly discover new object relations from entirely new scenes.", "startOffset": 69, "endOffset": 91}, {"referenceID": 6, "context": "(2009) and Zhao & Zhu (2011) modelled relations among image features using stochastic grammars, Felzenszwalb et al. (2008) modelled relations among object parts using the \u201cdeformable parts\u201d model, and Choi et al.", "startOffset": 96, "endOffset": 123}, {"referenceID": 3, "context": "(2008) modelled relations among object parts using the \u201cdeformable parts\u201d model, and Choi et al. (2012) modelled relations among objects in scenes using tree structured context models.", "startOffset": 85, "endOffset": 104}, {"referenceID": 0, "context": "1 DESCRIPTION AND IMPLEMENTATION RNs are inspired by Interaction Networks (INs) (Battaglia et al., 2016), and therefore share similar functional insights.", "startOffset": 80, "endOffset": 104}, {"referenceID": 26, "context": "The final category of tasks tested the implicit use of discovered relations to solve a difficult overarching problem: one-shot relation learning (Vinyals et al., 2016; Santoro et al., 2016; Lake et al., 2015).", "startOffset": 145, "endOffset": 208}, {"referenceID": 21, "context": "The final category of tasks tested the implicit use of discovered relations to solve a difficult overarching problem: one-shot relation learning (Vinyals et al., 2016; Santoro et al., 2016; Lake et al., 2015).", "startOffset": 145, "endOffset": 208}, {"referenceID": 17, "context": "The final category of tasks tested the implicit use of discovered relations to solve a difficult overarching problem: one-shot relation learning (Vinyals et al., 2016; Santoro et al., 2016; Lake et al., 2015).", "startOffset": 145, "endOffset": 208}, {"referenceID": 12, "context": "Sequences \u2013 or episodes \u2013 consisted of 50 random samples generated from five unique graphs, from a pool of 1900 total classes, presented jointly with time-offset label identifiers, as per Hochreiter et al. (2001) and Santoro et al.", "startOffset": 188, "endOffset": 213}, {"referenceID": 12, "context": "Sequences \u2013 or episodes \u2013 consisted of 50 random samples generated from five unique graphs, from a pool of 1900 total classes, presented jointly with time-offset label identifiers, as per Hochreiter et al. (2001) and Santoro et al. (2016). Critically, the labels associated with particular classes change from episode-to-episode.", "startOffset": 188, "endOffset": 239}, {"referenceID": 21, "context": "During writing, the LSTM outputs a vector that the write head uses to write into the memory store using a least recently used memory access mechanism (Santoro et al., 2016).", "startOffset": 150, "endOffset": 172}, {"referenceID": 21, "context": "The MANN was implemented as in Santoro et al. (2016), and the reader is directed here for full details on using networks augmented with external memories.", "startOffset": 31, "endOffset": 53}, {"referenceID": 2, "context": "The utility of the RN as a relation-reasoning module suggests that it has the potential to be useful for solving tasks that require reasoning not only about object-object relations, but also about verbobject relations, as in human-object interaction datasets (Chao et al., 2015) or question-answering tasks that involve reasoning between multiple objects (Krishna et al.", "startOffset": 259, "endOffset": 278}, {"referenceID": 16, "context": ", 2015) or question-answering tasks that involve reasoning between multiple objects (Krishna et al., 2016).", "startOffset": 84, "endOffset": 106}], "year": 2017, "abstractText": "Our world can be succinctly and compactly described as structured scenes of objects and relations. A typical room, for example, contains salient objects such as tables, chairs and books, and these objects typically relate to each other by their underlying causes and semantics. This gives rise to correlated features, such as position, function and shape. Humans exploit knowledge of objects and their relations for learning a wide spectrum of tasks, and more generally when learning the structure underlying observed data. In this work, we introduce relation networks (RNs) a general purpose neural network architecture for object-relation reasoning. We show that RNs are capable of learning object relations from scene description data. Furthermore, we show that RNs can act as a bottleneck that induces the factorization of objects from entangled scene description inputs, and from distributed deep representations of scene images provided by a variational autoencoder. The model can also be used in conjunction with differentiable memory mechanisms for implicit relation discovery in one-shot learning tasks. Our results suggest that relation networks are a potentially powerful architecture for solving a variety of problems that require object relation reasoning.", "creator": "LaTeX with hyperref package"}}}