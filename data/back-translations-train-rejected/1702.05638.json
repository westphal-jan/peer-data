{"id": "1702.05638", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Feb-2017", "title": "A Stylometric Inquiry into Hyperpartisan and Fake News", "abstract": "This paper reports on a writing style analysis of hyperpartisan (i.e., extremely one-sided) news in connection to fake news. It presents a large corpus of 1,627 articles that were manually fact-checked by professional journalists from BuzzFeed. The articles originated from 9 well-known political publishers, 3 each from the mainstream, the hyperpartisan left-wing, and the hyperpartisan right-wing. In sum, the corpus contains 299 fake news, 97% of which originated from hyperpartisan publishers.", "histories": [["v1", "Sat, 18 Feb 2017 18:10:04 GMT  (282kb,D)", "http://arxiv.org/abs/1702.05638v1", "10 pages, 3 figures, 6 tables, submitted to ACL 2017"]], "COMMENTS": "10 pages, 3 figures, 6 tables, submitted to ACL 2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["martin potthast", "johannes kiesel", "kevin reinartz", "janek bevendorff", "benno stein"], "accepted": false, "id": "1702.05638"}, "pdf": {"name": "1702.05638.pdf", "metadata": {"source": "CRF", "title": "A Stylometric Inquiry into Hyperpartisan and Fake News", "authors": ["Martin Potthast", "Johannes Kiesel", "Kevin Reinartz", "Janek Bevendorff", "Benno Stein"], "emails": ["name>@uni-weimar.de"], "sections": [{"heading": null, "text": "We propose a new way to assess the stylistic similarity between text categories by means of unmasking - a meta-learning approach originally designed to verify authorship - and show that the style of left and right news has much more in common than either with the mainstream. In addition, we show that non-partisan news can be easily distinguished from mainstream news by its style (F1 = 0.78), as well as satire from both (F1 = 0.81)."}, {"heading": "1 Introduction", "text": "In fact, it is the case that most of them are able to survive themselves without there being a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there, in a process in which there is a process in which there is a process in which there is a process in which there is a process in a process in which there is a process, in a process in which there, in a process in which there, in a process in a process, in a process"}, {"heading": "2 Related Work", "text": "In this paper, we close this gap and the potential of classifying news according to three paradigms: fake news detection based on knowledge, context, and style. For each of the paradigms, we list specific areas of research that provide different methods for solving the task. However, knowledge-based fake news detection (also known as \"fact checking\") is approached using methods derived from information retrieval, semantic web detection, and associated open data (LOD). Context-based fake news detection and rumors and their containment are investigated. Style-based fake news detection relies on computational linguistics and natural language processing, and more specifically on methods from deception to identify sentence-level statements that constitute false information and lies. One field of research that has hardly been considered in the context of fake news detection is textual categorization."}, {"heading": "3 The BuzzFeed-Webis Fake News", "text": "Corpus 2016 This section introduces the BuzzFeed-Webis Fake News Corpus 2016, whose structure and comments are described in detail by BuzzFeed-employed journalists as well as key figures and statistics."}, {"heading": "3.1 Corpus Construction", "text": "The Corpus Corpus comprises a full sample of the issue of 9 publishers in a week close to the US election. Among the selected publishers are 6 prolific hyper-partisan publishers (three left-wing and three right-wing publishers) and three mainstream publishers (see Table 1). All publishers have earned Facebook's blue tick, indicating authenticity and elevated status within the network. For seven weekdays (September 19 to September 23, 26 and 27), each post and linked news article was fact-checked by the 9 publishers, the claim of 5 BuzzFeed journalists, including about 10% of contributions forwarded by third parties. Silverman et al. (2016) reported key insights as a data journalism article that totaled 2,282 contributions, of which 1,145 were published by mainstream publishers, 471 by hyper-partisan left-wing publishers, and 666 by hyper-partisan right-wing publishers."}, {"heading": "3.2 Corpus Statistics", "text": "Table 1 shows the results of fact-checking and some important statistics per article. Unsurprisingly, none of the mainstream articles is predominantly false, while 8 of all three publishers are a mix of true and false. Aside from non-fact articles, just over a quarter of all left-wing articles were found to be incorrect: 15 articles predominantly false and 51 a mix of true and false. \"The Other 98%\" publisher stands out with an almost perfect score, while almost 45% of right-wing articles are evenly distributed. In terms of the most important statistics per article, it is interesting to note that the articles from all mainstream publishers are on average about 20 paragraphs long, with an average of 550 words on ABC News and 800 on Politico."}, {"heading": "3.3 Operationalizing Fake News", "text": "In our experiments, we operationalize the category of fake news by linking articles that have been largely rated as false with articles that are classified as a mix of false and true. The latter may not be exactly what is colloquially understood as \"fake news\" (as in: a complete fake), but practice shows that fake news is hardly ever free of truth. More often, true facts are misinterpreted using argumentative errors to influence a person's opinion. Thus, in our experiments, we mostly call true articles real news, mostly false plus mixes of true and false, except for satire, fake news, and ignore all articles that are rated as improper."}, {"heading": "4 Methodology", "text": "In this section, we briefly discuss the methodology, including a brief summary of Unmasking by Koppel et al. (2007), for which we examine for the first time how to distinguish genre styles from authors, and what characteristics we use to capture the writing style. For reasons of reproducibility, our entire code is made publicly available."}, {"heading": "4.1 Unmasking Style Categories", "text": "Unmasking, as proposed by Koppel et al. (2007), is a meta-learning approach that was originally intended to verify authorship. In this work, we examine for the first time whether it can be used to assess the similarity of broader style categories to the style of the author, such as left versus right versus mainstream news. In this way, we try to uncover relationships between the writing styles that people may involuntarily adopt according to their political orientation. Originally, unmasking takes two documents as input and expresses confidence in whether they were written by the same author. To achieve this, three steps are taken: first, each document is divided into a series of chunks at least 500-word long; second, reconstruction errors are measured, while the most discriminatory features of a style model that includes 250 common words used to separate the two chunks with a linear classifier; and third, the resulting reconstruction errors are analyzed in terms of their tendency to curve."}, {"heading": "4.2 Style Features and Feature Selection", "text": "Our writing style model includes frequently used style features as well as some specific features of the message range. The former are n-gram characters, stopwords (in order of their appearance in the text) and speech passages with n in [1, 3]. In addition, we use 10 readability ratings 2 as well as dictionary features, each indicating the frequency of words from a tailor-made dictionary in a particular document, using those that are worthwhile based on the General Inquirer Dictionaries (Stone et al., 1966). Domain-specific features include ratios of cited words and external links, as well as the number of paragraphs and their average length in a document. In each of our experiments, we carefully select those that are worth it from the above features. To avoid overmatching, any features that are barely represented in the documents in our corpus (i.e., that occur in less than 10% of the documents) are inaccurate."}, {"heading": "4.3 Baselines", "text": "This approach is less practical, however, as news topics change frequently and drastically. In addition, we provide naive baselines that classify all elements into one of the classes in question and thus relate the results to the class distributions. 2Automated Readability Index, Coleman Liau Index, Flesh Kincaid Grade Level and Reading Ease, Gunning Fog Index, LIX, McAlpine EFLAW Score, RIX, SMOG Grade, Strain Index"}, {"heading": "5 Experiments", "text": "We report on the results of two experiments aimed at examining the stylistic differences and similarities between hyper-partisanship and mainstream, as well as between fake, real, and satire news. Specifically, we examine the following three questions: (1) Is there a common style of hyper-partisanship? Our working hypothesis is that left and right hyper-parties have more in common than they would even admit, and our results actually provide the first evidence that stylistic detection of fake news is practicable? Of course, we do not expect to solve fake news with style alone, but the exploitation of style has the advantage that it can be applied in real-time for screening, and that authors probably have little control over their own writing style by and large. (3) Can non-partisan fake news be distinguished from satire? Examining the specific case of satire news is important as we cannot allow humor to be sacrificed on the altar of truth."}, {"heading": "5.1 Hyperpartisanship vs. Mainstream", "text": "In fact, it is such that most people who stand up for the rights of people, who stand up for the rights of people, who stand up for the rights of people, who stand up for the rights of people, for the rights of people, the rights of people, the rights of people, the rights of people, the rights of people, the rights of people, the rights of people, the rights of people, the rights of people, the rights of people, the rights of people, the rights of people, the rights of people, the rights of people, the rights of people, the rights of people, the rights of people, the rights of people, the rights of people, the rights of people, the rights of people, the rights of people's rights, the rights of people, the rights of people's rights, the rights of people's rights, the rights of people's rights, the rights of people's rights, the rights of people's rights, the rights of people's rights, the rights of people's rights, the rights of people's rights, the rights of people's rights, the rights of people's rights, the rights of people's rights, the rights of people's rights, the freedom of people's rights, the rights of people's rights, the rights of people's rights, the freedom, the rights of people's rights, the freedom of people's rights, the rights of people's rights, the freedom, the rights of people's rights, the freedom, the rights of people's rights, the freedom, the rights of people's rights, the freedom, the rights of people's rights, the freedom, the rights of people's rights, the freedom, the freedom of people's rights, the freedom, the freedom, the freedom, the freedom, the freedom, the freedom, the freedom of the freedom, the freedom, the freedom, the freedom, the freedom, the freedom, the freedom, the freedom of the freedom, the freedom, the freedom, the freedom of the freedom, the freedom, the freedom, the freedom, the freedom, the freedom, the freedom, the freedom, the freedom, the freedom, the freedom, the freedom, the freedom of the freedom, the freedom, the freedom, the freedom, the freedom, the freedom, the freedom, the freedom, the freedom, the freedom of the freedom, the freedom, the freedom, the freedom, the freedom of the freedom, the freedom, the freedom, the freedom, the freedom of the freedom"}, {"heading": "5.2 Fake vs. Real (vs. Satire)", "text": "This year it has come to the point where we see ourselves able to put ourselves at the top, \"he said in an interview with the\" Welt am Sonntag. \""}, {"heading": "6 Conclusion", "text": "Detecting fake news is an interdisciplinary challenge: technology must be in place to extract factual statements from a different perspective, match facts with a knowledge base, dynamically retrieve and maintain knowledge bases from the web, reliably assess the overall veracity of an article rather than individual statements, do so in real time when news events unfold, monitor the spread of fake news within and on social media, measure the reputation of information sources, and raise readers \"awareness. These are perhaps only the most obvious things that can be done to address the problem, and as our cross-section of related work shows, many of them are already being tackled. Given the recent hype surrounding fake news, many more posts - hopefully our own as well - will emerge in the future."}, {"heading": "Acknowledgements", "text": "We thank Craig Silverman, Lauren Strapagiel, Hamza Shaban, Ellie Hall and Jeremy Singer-Vine of BuzzFeed for providing the data that made our research possible."}], "references": [{"title": "Spread of (Mis)Information in Social Networks", "author": ["Daron Acemoglu", "Asuman Ozdaglar", "Ali ParandehGheibi."], "venue": "Games and Economic Behavior, 70(2):194\u2013227.", "citeRegEx": "Acemoglu et al\\.,? 2010", "shortCiteRegEx": "Acemoglu et al\\.", "year": 2010}, {"title": "Detecting Hoaxes, Frauds, and Deception in Writing Style Online", "author": ["Sadia Afroz", "Michael Brennan", "Rachel Greenstadt."], "venue": "2012 IEEE Symposium on Security and Privacy, pages 461\u2013475, May.", "citeRegEx": "Afroz et al\\.,? 2012", "shortCiteRegEx": "Afroz et al\\.", "year": 2012}, {"title": "Style-based text categorization: What newspaper am i reading", "author": ["Shlomo Argamon-Engelson", "Moshe Koppel", "Galit Avneri."], "venue": "Proc. of the AAAI Workshop on Text Categorization, pages 1\u20134.", "citeRegEx": "Argamon.Engelson et al\\.,? 1998", "shortCiteRegEx": "Argamon.Engelson et al\\.", "year": 1998}, {"title": "Identifying real or fake articles: Towards better language modeling", "author": ["Sameer Badaskar", "Sachin Agarwal", "Shilpa Arora."], "venue": "Third International Joint Conference on Natural Language Processing, IJCNLP 2008, Hyderabad, India, January 7-12, 2008, pages", "citeRegEx": "Badaskar et al\\.,? 2008", "shortCiteRegEx": "Badaskar et al\\.", "year": 2008}, {"title": "Limiting the spread of misinformation in social networks", "author": ["Ceren Budak", "Divyakant Agrawal", "Amr El Abbadi."], "venue": "Proceedings of the 20th International Conference on World Wide Web, WWW \u201911, pages 665\u2013674, New York, NY, USA. ACM.", "citeRegEx": "Budak et al\\.,? 2011", "shortCiteRegEx": "Budak et al\\.", "year": 2011}, {"title": "News in an Online World: The Need for an \"Automatic Crap Detector", "author": ["Yimin Chen", "Niall J. Conroy", "Victoria L. Rubin."], "venue": "Proceedings of the 78th ASIS&T Annual Meeting: Information Science with Impact: Research in and for the Community,", "citeRegEx": "Chen et al\\.,? 2015", "shortCiteRegEx": "Chen et al\\.", "year": 2015}, {"title": "Computational Fact Checking from Knowledge Networks", "author": ["Giovanni Luca Ciampaglia", "Prashant Shiralkar", "Luis M Rocha", "Johan Bollen", "Filippo Menczer", "Alessandro Flammini."], "venue": "PloS one, 10(6):e0128193.", "citeRegEx": "Ciampaglia et al\\.,? 2015", "shortCiteRegEx": "Ciampaglia et al\\.", "year": 2015}, {"title": "Open Information Extraction from the Web", "author": ["Oren Etzioni", "Michele Banko", "Stephen Soderland", "Daniel S. Weld."], "venue": "Commun. ACM, 51(12):68\u201374, December. Alexandru L. Ginsca, Adrian Popescu, and Mihai", "citeRegEx": "Etzioni et al\\.,? 2008", "shortCiteRegEx": "Etzioni et al\\.", "year": 2008}, {"title": "Credibility in Information Retrieval", "author": ["Lupu."], "venue": "Found. Trends Inf. Retr., 9(5):355\u2013475, December. Moshe Koppel, Jonathan Schler, and Elisheva Bonchek-Dokow. 2007. Measuring differentiability: Unmasking pseudonymous authors. J. Mach. Learn.", "citeRegEx": "Lupu.,? 2015", "shortCiteRegEx": "Lupu.", "year": 2015}, {"title": "Prominent Features of Rumor Propagation in Online Social Media", "author": ["Res", "8:1261\u20131276. Sejeong Kwon", "Meeyoung Cha", "Kyomin Jung", "Wei Chen", "Yajun Wang"], "venue": "In Data Mining (ICDM),", "citeRegEx": "Res. et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Res. et al\\.", "year": 2013}, {"title": "Web-based Statistical Fact Checking of Textual Documents", "author": ["IEEE. Amr Magdy", "Nayer Wanas"], "venue": "Conference on,", "citeRegEx": "Magdy and Wanas.,? \\Q2010\\E", "shortCiteRegEx": "Magdy and Wanas.", "year": 2010}, {"title": "Collective Attention in the Age of (Mis)Information", "author": ["Delia Mocanu", "Luca Rossi", "Qian Zhang", "Marton Karsai", "Walter Quattrociocchi"], "venue": null, "citeRegEx": "Mocanu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Mocanu et al\\.", "year": 2015}, {"title": "Containment of Misinformation Spread in Online Social Networks", "author": ["Nam P. Nguyen", "Guanhua Yan", "My T. Thai", "Stephan Eidenbenz."], "venue": "Proceedings of the 4th Annual ACM Web Science Conference, WebSci \u201912, pages 213\u2013222, New York,", "citeRegEx": "Nguyen et al\\.,? 2012", "shortCiteRegEx": "Nguyen et al\\.", "year": 2012}, {"title": "Psychological aspects of natural language use: Our words, our selves", "author": ["NY", "USA. ACM. James W. Pennebaker", "Matthias R. Mehl", "Kate G. Niederhoffer."], "venue": "Annual Review of Psychology, 54:547\u2013577.", "citeRegEx": "NY et al\\.,? 2003", "shortCiteRegEx": "NY et al\\.", "year": 2003}, {"title": "Towards News Verification: Deception Detection Methods for News Discourse", "author": ["Victoria Rubin", "Niall Conroy", "Yimin Chen."], "venue": "Proceedings of the Hawaii International Conference on System Sciences (HICSS48) Symposium on Rapid Screening", "citeRegEx": "Rubin et al\\.,? 2015", "shortCiteRegEx": "Rubin et al\\.", "year": 2015}, {"title": "Fake News or Truth? Using Satirical Cues to Detect Potentially Misleading News", "author": ["Technologies", "Deception Detection", "Credibility Assessment Symposium", "Kauai", "USA Hawaii", "January. Victoria Rubin", "Niall Conroy", "Yimin Chen", "Sarah Cornwell."], "venue": "In", "citeRegEx": "Technologies et al\\.,? 2016", "shortCiteRegEx": "Technologies et al\\.", "year": 2016}, {"title": "Association for Computational Linguistics", "author": ["San Diego", "California", "June"], "venue": "Proceedings of the Second Workshop on Computational Approaches to Deception Detection,", "citeRegEx": "Diego et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Diego et al\\.", "year": 2016}, {"title": "Hyperpartisan Facebook Pages are Publishing False and Misleading Information at an Alarming Rate", "author": ["Craig Silverman", "Lauren Strapagiel", "Hamza Shaban", "Ellie Hall", "Jeremy Singer-Vine."], "venue": "https://www.buzzfeed.com/craigsilverman/partisan-fb-", "citeRegEx": "Silverman et al\\.,? 2016", "shortCiteRegEx": "Silverman et al\\.", "year": 2016}, {"title": "The General Inquirer: A Computer Approach to Content Analysis", "author": ["Dexter C. Dunphy", "Marshall S. Smith"], "venue": null, "citeRegEx": "Stone et al\\.,? \\Q1966\\E", "shortCiteRegEx": "Stone et al\\.", "year": 1966}, {"title": "Fact-checking Effect on Viral Hoaxes: A Model of Misinformation Spread in Social Networks", "author": ["Marcella Tambuscio", "Giancarlo Ruffo", "Alessandro Flammini", "Filippo Menczer."], "venue": "Proceedings of the 24th International Conference on World Wide Web, WWW", "citeRegEx": "Tambuscio et al\\.,? 2015", "shortCiteRegEx": "Tambuscio et al\\.", "year": 2015}, {"title": "An empirical study on uncertainty identification in social media context", "author": ["Zhongyu Wei", "Junwen Chen", "Wei Gao", "Binyang Li", "Lanjun Zhou", "Yulan He", "Kam-Fai Wong."], "venue": "Proceedings of the 51st Annual Meeting of the Association for Computational", "citeRegEx": "Wei et al\\.,? 2013", "shortCiteRegEx": "Wei et al\\.", "year": 2013}, {"title": "Association for Computational Linguistics", "author": ["Sofia", "Bulgaria", "August"], "venue": null, "citeRegEx": "Sofia et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sofia et al\\.", "year": 2014}, {"title": "TextRunner: Open information", "author": ["March. Alexander Yates", "Michele Banko", "Matthew Broadhead", "Michael Cafarella", "Oren Etzioni", "Stephen Soderland"], "venue": "Fact-checking. Proc. VLDB Endow.,", "citeRegEx": "Yates et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Yates et al\\.", "year": 2007}], "referenceMentions": [{"referenceID": 22, "context": "(2008) propose to use their well-known tool Text Runner (Yates et al., 2007) to extract and index factual knowledge from the web, and to use the same technology to extract factual statements from a given text in question, matching them against the indexed facts to identify inconsistencies.", "startOffset": 56, "endOffset": 76}, {"referenceID": 7, "context": "For example, Etzioni et al. (2008) propose to use their well-known tool Text Runner (Yates et al.", "startOffset": 13, "endOffset": 35}, {"referenceID": 7, "context": "For example, Etzioni et al. (2008) propose to use their well-known tool Text Runner (Yates et al., 2007) to extract and index factual knowledge from the web, and to use the same technology to extract factual statements from a given text in question, matching them against the indexed facts to identify inconsistencies. Magdy and Wanas (2010) develop a statistical model to check factual statements extracted from a given document in question, analyzing how frequently they are supported by documents retrieved from the web.", "startOffset": 13, "endOffset": 342}, {"referenceID": 6, "context": "Ciampaglia et al. (2015) cast fact-checking as a problem of finding shortest paths between concepts in a knowledge graph; they propose a metric to assess the truth of a statement by analyzing path lengths between the concepts in question.", "startOffset": 0, "endOffset": 25}, {"referenceID": 6, "context": "Ciampaglia et al. (2015) cast fact-checking as a problem of finding shortest paths between concepts in a knowledge graph; they propose a metric to assess the truth of a statement by analyzing path lengths between the concepts in question. Conversely, Shi and Weninger (2016) cast fake news detection as a link prediction task, where a probability is estimated in order to decide whether concepts covered by a to-be-checked statement should be linked.", "startOffset": 0, "endOffset": 275}, {"referenceID": 0, "context": "Acemoglu et al. (2010) model how (mis)information is spread in social networks, and Budak et al.", "startOffset": 0, "endOffset": 23}, {"referenceID": 0, "context": "Acemoglu et al. (2010) model how (mis)information is spread in social networks, and Budak et al. (2011) and Nguyen et al.", "startOffset": 0, "endOffset": 104}, {"referenceID": 0, "context": "Acemoglu et al. (2010) model how (mis)information is spread in social networks, and Budak et al. (2011) and Nguyen et al. (2012) propose algorithms to limit their spread.", "startOffset": 0, "endOffset": 129}, {"referenceID": 0, "context": "Acemoglu et al. (2010) model how (mis)information is spread in social networks, and Budak et al. (2011) and Nguyen et al. (2012) propose algorithms to limit their spread. Kwon et al. (2013) combine social network analysis and linguistic feature obtained from applying LIWC (Pennebaker et al.", "startOffset": 0, "endOffset": 190}, {"referenceID": 0, "context": "Acemoglu et al. (2010) model how (mis)information is spread in social networks, and Budak et al. (2011) and Nguyen et al. (2012) propose algorithms to limit their spread. Kwon et al. (2013) combine social network analysis and linguistic feature obtained from applying LIWC (Pennebaker et al., 2003) to identify rumors as they spread. Studying the spread of misinformation on Facebook during an election, Mocanu et al. (2015) provide evidence that unsubstantiated claims spread as widely as well-established ones, and that user groups with a predisposition to conspiracy theories are more open to sharing misinformation.", "startOffset": 0, "endOffset": 425}, {"referenceID": 0, "context": "Acemoglu et al. (2010) model how (mis)information is spread in social networks, and Budak et al. (2011) and Nguyen et al. (2012) propose algorithms to limit their spread. Kwon et al. (2013) combine social network analysis and linguistic feature obtained from applying LIWC (Pennebaker et al., 2003) to identify rumors as they spread. Studying the spread of misinformation on Facebook during an election, Mocanu et al. (2015) provide evidence that unsubstantiated claims spread as widely as well-established ones, and that user groups with a predisposition to conspiracy theories are more open to sharing misinformation. Tambuscio et al. (2015) also study the spread of misinformation in social media; however, they also study the efficacy", "startOffset": 0, "endOffset": 644}, {"referenceID": 17, "context": "in order to identify or to detect uncertainty in social media posts: Wei et al. (2013) propose a model to detect tweets that convey uncertain information.", "startOffset": 69, "endOffset": 87}, {"referenceID": 4, "context": "Regarding fake news detection, Chen et al. (2015) point out the need for an \u201cautomatic crap detector\u201d for news, but do not report on actual experiments, whereas Rubin et al.", "startOffset": 31, "endOffset": 50}, {"referenceID": 4, "context": "Regarding fake news detection, Chen et al. (2015) point out the need for an \u201cautomatic crap detector\u201d for news, but do not report on actual experiments, whereas Rubin et al. (2015) apply, for the first time, deception detection approaches to fake news detection using rhetorical structure theory as a measure of story coherence.", "startOffset": 31, "endOffset": 181}, {"referenceID": 2, "context": "Style-based text categorization was proposed by Argamon-Engelson et al. (1998) as an alternative to topic-based text categorization in order to tackle tasks ranging from author profiling (by age, gender,", "startOffset": 48, "endOffset": 79}, {"referenceID": 1, "context": "For example, Afroz et al. (2012) attempt to detect texts whose authors tried to obfuscate their writing style to deflect author identification.", "startOffset": 13, "endOffset": 33}, {"referenceID": 1, "context": "For example, Afroz et al. (2012) attempt to detect texts whose authors tried to obfuscate their writing style to deflect author identification. As an early precursor to fake news detection, Badaskar et al. (2008) train models to tell real news apart from news that have been automatically generated using a language model, However, Rubin et al.", "startOffset": 13, "endOffset": 213}, {"referenceID": 1, "context": "For example, Afroz et al. (2012) attempt to detect texts whose authors tried to obfuscate their writing style to deflect author identification. As an early precursor to fake news detection, Badaskar et al. (2008) train models to tell real news apart from news that have been automatically generated using a language model, However, Rubin et al. (2016) contributed the first actual attempt at fake news detection by separating satire news as a representative of humorous fakes from real news in a dataset of 180 news articles each, achieving F -Measure val-", "startOffset": 13, "endOffset": 352}, {"referenceID": 17, "context": "Silverman et al. (2016) reported key insights as a data journalism article, having checked a total of 2,282 posts, 1,145 of which from mainstream publishers, 471 from hy-", "startOffset": 0, "endOffset": 24}, {"referenceID": 18, "context": "Dictionaries as a basis (Stone et al., 1966).", "startOffset": 24, "endOffset": 44}, {"referenceID": 14, "context": "For satire news, we use the 180 articles from the S-n-L News DB (Rubin et al. (2016), Section 2).", "startOffset": 65, "endOffset": 85}, {"referenceID": 14, "context": "Table 6 shows the performance values of our random forest classifier in the satire-detection setting used by Rubin et al. (2016). This setting uses a bal-", "startOffset": 109, "endOffset": 129}, {"referenceID": 14, "context": "results for the best classifier of Rubin et al. (2016).", "startOffset": 35, "endOffset": 55}], "year": 2017, "abstractText": "This paper reports on a writing style analysis of hyperpartisan (i.e., extremely onesided) news in connection to fake news. It presents a large corpus of 1,627 articles that were manually fact-checked by professional journalists from BuzzFeed. The articles originated from 9 well-known political publishers, 3 each from the mainstream, the hyperpartisan left-wing, and the hyperpartisan right-wing. In sum, the corpus contains 299 fake news, 97% of which originated from hyperpartisan publishers. We propose and demonstrate a new way of assessing style similarity between text categories via Unmasking\u2014a meta-learning approach originally devised for authorship verification\u2014, revealing that the style of left-wing and right-wing news have a lot more in common than any of the two have with the mainstream. Furthermore, we show that hyperpartisan news can be discriminated well by its style from the mainstream (F1 = 0.78), as can be satire from both (F1 = 0.81). Unsurprisingly, stylebased fake news detection does not live up to scratch (F1 = 0.46). Nevertheless, the former results are important to implement pre-screening for fake news detectors.", "creator": "TeX"}}}