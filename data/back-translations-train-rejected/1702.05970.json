{"id": "1702.05970", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Feb-2017", "title": "Automatic Liver and Tumor Segmentation of CT and MRI Volumes using Cascaded Fully Convolutional Neural Networks", "abstract": "Automatic segmentation of the liver and hepatic lesions is an important step towards deriving quantitative biomarkers for accurate clinical diagnosis and computer-aided decision support systems. This paper presents a method to automatically segment liver and lesions in CT and MRI abdomen images using cascaded fully convolutional neural networks (CFCNs) enabling the segmentation of a large-scale medical trial or quantitative image analysis. We train and cascade two FCNs for a combined segmentation of the liver and its lesions. In the first step, we train a FCN to segment the liver as ROI input for a second FCN. The second FCN solely segments lesions within the predicted liver ROIs of step 1. CFCN models were trained on an abdominal CT dataset comprising 100 hepatic tumor volumes. Validations on further datasets show that CFCN-based semantic liver and lesion segmentation achieves Dice scores over 94% for liver with computation times below 100s per volume. We further experimentally demonstrate the robustness of the proposed method on an 38 MRI liver tumor volumes and the public 3DIRCAD dataset.", "histories": [["v1", "Mon, 20 Feb 2017 13:52:57 GMT  (3920kb,D)", "http://arxiv.org/abs/1702.05970v1", "Under Review"], ["v2", "Thu, 23 Feb 2017 15:02:59 GMT  (3921kb,D)", "http://arxiv.org/abs/1702.05970v2", "Under Review"]], "COMMENTS": "Under Review", "reviews": [], "SUBJECTS": "cs.CV cs.AI", "authors": ["patrick ferdinand christ", "florian ettlinger", "felix gr\\\"un", "mohamed ezzeldin a elshaera", "jana lipkova", "sebastian schlecht", "freba ahmaddy", "sunil tatavarty", "marc bickel", "patrick bilic", "markus rempfler", "felix hofmann", "melvin d anastasi", "seyed-ahmad ahmadi", "georgios kaissis", "julian holch", "wieland sommer", "rickmer braren", "volker heinemann", "bjoern menze"], "accepted": false, "id": "1702.05970"}, "pdf": {"name": "1702.05970.pdf", "metadata": {"source": "CRF", "title": "Automatic Liver and Tumor Segmentation of CT and MRI Volumes using Cascaded Fully Convolutional Neural Networks", "authors": ["Patrick Christ", "Florian Ettlinger", "Felix Gr\u00fcn", "Mohamed Ezzeldin A. Elshaer", "Jana Lipkov\u00e1", "Sebastian Schlecht", "Freba Ahmaddy", "Sunil Tatavarty", "Marc Bickel", "Patrick Bilic", "Markus Rempfler", "Felix Hofmann", "Melvin D\u2019Anastasi", "Seyed-Ahmad Ahmadi", "Georgios Kaissis", "Julian Holch", "Wieland Sommer", "Rickmer Braren", "Volker Heinemann", "Bjoern Menze"], "emails": [], "sections": [{"heading": null, "text": "Automatic segmentation of the liver and liver lesion is an important step in deriving quantitative biomarkers for accurate clinical diagnosis and computerized decision support systems. This work represents a method for automatic segmentation of liver and lesions in CT and MRI abdominal images using cascaded fully convolutionary neural networks (CFCNs) that allows segmentation of a large medical study or quantitative image analysis. We train and cascade two FCNs for combined segmentation of the liver and its lesions. In the first step, we train an FCN for segmentation of the liver as ROI input for a second FCN. The second FCN exclusively segments lesions within the predicted Level 1 liver ROIs. CFCN models were trained on the basis of an abdominal CT data set with 100 hepatic tumor volumes. Validations based on further sets of hepatic semantic CFCN data show that CN and CN are achieved."}, {"heading": "1. Introduction", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "1.1. Motivation", "text": "Abnormalities in the shape and texture of the liver and visible lesions in CT are important biomarkers for the initial diagnosis and progression of both primary and secondary hepatic tumors. [1] Primary tumors such as breast, colon and pancreatic cancers often spread metastases in the liver during the course of the disease. Therefore, the liver and its lesions are analyzed in the same way in1Authors. [2] Preprint, published on February 21, 2017ar Xiv: 170 2.05 970v 1 [cs.C V] 20 feprimary tumor staging. In addition, the liver is also a site of primary tumor diseases such as hepatocellular carcinoma (HCC). Hepatocellular carcinomas (HCC) are the sixth most common cancer and the third most common cause of cancer-related deaths worldwide. [3] HCC comprises a group of chronic and highly genetic disorders."}, {"heading": "1.2. Related Works", "text": "Nevertheless, several interactive and automatic methods have been developed to segment liver and liver lesions in CT volumes. In 2007 and 2008, two Grand Challenges benchmarks for segmentation of liver and liver lesions were conducted [1,4]. Methods presented in the challenges were largely based on statistical form models. In addition, gray level and texture methods were developed [1]. Recent work on liver and lesion segmentation uses graph section and level set techniques [5, 6, 7], sigmoid edge modeling [8] or manifold and machine learning [9, 10, 11, 12]. However, due to their speed and robustness, these methods are not widely applied in clinics on heterogeneous, high-contrast real CT data. To overcome these weaknesses, interactive methods have been developed [13] to overcome these weaknesses, [to compare the segmentation of high-level segments with high-level medical segmentation]."}, {"heading": "1.3. Contribution:", "text": "In this paper, we demonstrate the combined automatic segmentation of the liver and its lesions in low-contrast heterogeneous medical volumes. Our contributions are threefold: First, we train and apply fully convolutionary CNN for the first time on CT volumes of the liver, demonstrating adaptability to challenging segmentation of hepatic liver lesions. Second, we propose to use a cascaded fully convolutionary neural network (CFCN) on CT volumes, which segments liver and lesions sequentially, resulting in significantly higher segmentation quality, as demonstrated by a public requirement dataset. Third, we demonstrate experimentally the generalization and scalability of our methods to different modalities and various real datasets, including a novel DW-MRI dataset and a clinical CT dataset. A preliminary version of this work was presented in MICC2016 analysis [26] and presented at ISBI 2012, as well as in a preliminary version of this paper."}, {"heading": "2. Methods", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1. Overview of our proposed segmentation workflow", "text": "Our proposed segmentation workflow is shown in Figure 2. The workflow consists of three main parts. The first part (e.g. Section 2.2) deals with data preprocessing and preparation for neural network segmentation Part 2 (e.g. Section 2.3). In the neural network segmentation part, two cascaded, fully convolutionary neural networks segment the liver and then lesions within the region of interest to the liver (ROI). The calculated probabilities of the CFCN are refined using a dense 3D-induced random field to produce the final segmentation result in Part 3."}, {"heading": "2.2. Data preparation", "text": "First, the Hounsfield unit values were displayed in the range [\u2212 100, 400] to exclude irrelevant organs and objects. Figure 3 shows the effect of our applied pre-processing on a raw medical section. We increased the contrast by histogram compensation. Figure 3 also shows the last disc after HU window and contrast enhancement. Contrast within the liver was increased to allow better differentiation of the abnormal liver tissue. For DW-MRI, the data preparation scheme is similar and differs in data normalization, which additionally performs a N4bias correction [27]. As in [18, 22] to provide the network with the desired inventory display properties, several data augmentation steps, such as elastic deformation, transformation, rotation and rotation of the current palate, were used to increase the standard size of the adjacent invariant to the current one."}, {"heading": "2.3. Cascaded Fully Convolutional Neural Network", "text": "In the following section, we refer to the 3D image volume as I, the total number of voxels as N, and the amount of possible labels as L = {0, 1,..., l}. For each voxel i, we define a variable xi-L that identifies the assigned label. In view of the image I, the probability of a voxel i belonging to label k is described by P (xi = k | I) and is modeled by the FCN. In our special study, we use L = {0, 1, 2} for background, liver and lesion, respectively. 3Source codes and models are available at https: / / github.com / IBBM / Cascaded-FCN."}, {"heading": "2.3.1. From AlexNET to UNET", "text": "For a long time, it was necessary to replace the last layers of a classification network, such as the Alexa network, with full pixel layers. By comparison, the Alexa system enables the prediction of complete pixel layers rather than providing them with full pixel layers. Figures 4a and 4b show the training curves for the formation of the Alexa system (without class compensation)."}, {"heading": "2.3.2. From FCN to CFCN", "text": "The UNet architecture enables accurate pixel-by-pixel prediction by combining spatial and contextual information in a network architecture comprising 19 revolutionary layers. Figures 4e and 4f show the training curves for UNet using 3DIRCAD datasets; the overall performance of lesion segmentation is further increased to 53% test cubes; the motivation behind the cascade approach is that UNets and other forms of CNNs have been shown to propose cascaded training of FCNs to learn specific features for solving a segmentation task once per training, resulting in higher segmentation performance; the motivation behind the cascade approach is that UNets and other forms of CNNs can learn a positive liver, while the segmentation layers of Convolutionary Filters are tailored to the desired classification."}, {"heading": "2.3.3. Effect of Class Balancing", "text": "A decisive step in the formation of FCNs is adequate class balancing according to the pixel-wise frequency of each class in the data. Contrary to [15], we observed that the formation of the network for segmentation of small structures such as lesions is not possible without class balancing due to the high class imbalance. Therefore, we introduced an additional weight factor class in the cross entropy loss function L of the FCN.L = \u2212 1 n N \u0445 i = 1 \u03c9classi [P-i logPi + (1 \u2212 P-i) log (1 \u2212 Pi)]. (1) Pi denotes the probability that voxel i belongs in the foreground, P-i represents the fundamental truth."}, {"heading": "2.3.4. Transfer Learning and Pretraining", "text": "A common concept in deep learning is transfer learning using pre-trained neural network models. Neural networks prepared for a different task such as image classification can be used to initialize network weights when training on a new task such as image segmentation, and the intuition behind this idea is that for other tasks or data sets, the first layers of neural networks learn similar concepts to detect basic structures such as blobs and edges. These concepts do not need to be re-trained from scratch when using pre-trained models. In our experiments, we used pre-trained UNet models by Ronneberger et al. (2015), which were trained on cell image segmentation data [18]. We have published our trained liver and lesion segmentation models to allow other researchers to start training with learned liver and lesion concepts 4."}, {"heading": "2.4. 3D Conditional Random Field", "text": "Volumetric FCN implementation with 3D convolutions was severely limited by GPU hardware and available VRAM functionality (21). Recent work such as VNET and 3DUNET nowadays allows 3D FCNs with reduced resolution [28, 29]. Furthermore, the anisotropic resolution of medical volumes (e.g. 0.57-0.8mm in xy and 1.25-4mm in z-voxel dimension in 3DIRCADb) makes discriminatory 3D filters difficult to form. Instead, to grow the location information in discs within the dataset, we use 3D density random fields CRFs as proposed in [30]. To apply all slice-wise predictions of the FCN together in the CRF to the entire volume. 4Source code and models are available at https: / / github.com / IBBM / Cascaded-FCNI."}, {"heading": "2.5. Quality measures", "text": "We evaluated the performance of our proposed method based on the quality metrics introduced in the major liver and lesion segmentation challenges with [1,4]. Our most important measurement is the cube value. Additionally, we report on the Jaccard coefficient (JC), Volume Overlap Error (VOE), Relative Volume Difference (RVD), Average Symmetric Surface Distance (ASD), Symmetric Maximum Surface Distance (MSD). Metrics are applied to binary value volumes, so that a metric calculated based on the lesions, for example, considers only lesion objects as foreground and anything but background. We refer to the foreground object in truth as object A and object B as the predicted object."}, {"heading": "2.5.1. Dice score (DICE)", "text": "The number of dice points or formula 1 is evaluated as follows: DICE (A, B) = 2 | A \u0445 B | | A | + | B | where the number of dice points is in the interval [0,1]. Perfect segmentation results in a number of dice points of 1."}, {"heading": "2.5.2. Jaccard coefficient (JC)", "text": "The Jaccard coefficient is calculated as follows: JC (A, B) = | A-B | | A-B | where the value is in the interval [0, 1]."}, {"heading": "2.5.3. Volume Overlap Error (VOE)", "text": "VOE is only the addition of the Jaccard coefficient: V OE (A, B) = 1 \u2212 JC (A, B)"}, {"heading": "2.5.4. Relative Volume Difference (RVD)", "text": "RVD is an asymmetric measurement. All other measurements are symmetrical and do not indicate whether there are more false-positive or false negatives in the predicted segmentation. It is defined as: RVD (A, B) = | B | \u2212 | A | | A | It is a fraction of the difference between the volume variables and the volume size of the basic truth object. If the predicted 3D object is smaller than the basic truth, the value is negative. Theoretically, the value of RVD is in the range [\u2212 1, \u221e], where 0 is the best value if the volume size of the predicted object is exactly identical to the true object. Note, however, that RVD only measures volume sizes, regardless of whether the objects overlap at all. A negative value indicates a smaller predicted object volume, and a positive value does not fulfill a larger predicted object volume in the real object volume comparison to the VD."}, {"heading": "2.5.5. Average Symmetric Surface Distance (ASD)", "text": "The ASD between two objects is calculated by first calculating the surface of each object (the outer voxels touch the background voxels), then establishing a correspondence between each point on the surface of the first object and the next point on the surface of the second object. Finally, the distances between all pairs are averaged; the denominator of the average is the number of surface points of the first object."}, {"heading": "2.5.6. Maximum Surface Distance (MSD)", "text": "MSD is also known as the Hausdorff Symmetric Distance. The maximum surface distance (MSD) is similar to ASS, except that the maximum distance is taken instead of the average."}, {"heading": "3. Experiments and Results", "text": "For routine clinical use, methods and algorithms need to be developed, trained and evaluated against heterogeneous real-life data. In this work, we want to demonstrate the robustness, generalization and scalability of our proposed method by applying it to a public data set for comparison (Section 3.1), a clinical CT data set (Section 3.2) and finally a clinical MRI data set (Section 3.3)."}, {"heading": "3.1. 3DIRCAD", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1.1. Dataset", "text": "Compared to the major challenges, the 3DIRCADb dataset offers a greater variety and complexity of the liver and its lesions and is available to the public. 3DIRCADb dataset includes 20 venous phase-extended CT volumes from different European hospitals with different CT scanners. For our study, we trained and evaluated our models using the 15 volumes of liver tumors with double cross-validation, and the CT volumes analyzed vary significantly in terms of contrast enhancement, size and number of tumor lesions (1 to 42)."}, {"heading": "3.1.2. Experimental setting", "text": "The CFCN was trained on a current desktop PC using a single NVIDIA Titan X GPU with 12 GB VRAM. Neural networks were implemented and trained using the Deep Learning Framework caffe [32] from the University of Berkeley. As optimizers, we used stochastic gradients with a learning rate of 0.001 and a pulse of 0.8. To reduce overmatching, we applied a weight drop of 0.0005."}, {"heading": "3.1.3. Effect of Class Balancing", "text": "The effect of class adjustment can be seen in Figure 4a-4d. Introducing class adjustment improved liver and lesion segmentation while reducing overadjustment. The effect is smaller for the liver, as the percentage of liver voxels in a CT abdominal dataset is in the order of 7%, compared to 0.25% for lesions. In all subsequent experiments, we addressed the class imbalance by weighting the unbalanced class according to its frequency in the dataset by introducing a weight factor described in Section 2.3.3."}, {"heading": "3.1.4. Qualitative and quantitative results", "text": "The complex and heterogeneous structure of the liver and all lesions was recognized in the images shown, and the cascaded FCN approach resulted in an improvement in lesions in terms of segmentation accuracy compared to a single FCN, as shown in Figure 7. In general, we observed significant 6 additional improvements in disc-like cube overlap of liver segmentation, from an average of 93.1% to 94.3% after using the 3D density test. For lesions, we achieved a cube value of 56% \u00b1 27% with double cross validation. 5The data set is available at http: / / ircad.fr / research / 3d-ircadb-01 6Two-sided paired t-test with p-value < 4 \u00b7 10 \u2212 19."}, {"heading": "3.2. Clinical Dataset CT", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.2.1. Dataset", "text": "The second dataset we evaluated is a real clinical CT dataset of multiple CT scanners. It includes 100 CT scans of different patients. The patients studied suffered from different types of cancer with different manifestations in the liver. The dataset ranges from single HCC lesions to diffuse and confluent metastases. In addition, different contrast agents and therefore different contrast enhancement levels are present in this dataset."}, {"heading": "3.2.2. Experimental setting", "text": "The clinical CT dataset was prepared and expanded in the same way as the 3DIRCAD dataset as described in 2.2. The dataset was divided into 60 for training, 20 for testing and 20 for validation. Neural networks were trained on the same setup and training parameters as the 3DIRCAD dataset. In this experiment, an Adam optimizer with = 0.1 was used [37]."}, {"heading": "3.2.3. Qualitative and quantitative results", "text": "As shown in Table 1, Cascaded FCN and Cascaded FCN + 3DCRF achieve up to 88% and 91% cube scores on this dataset. A comparison of the cube scores between 5 training cases yielded a cube overlap score of 95%. Looking at the cube score between the cubes, the proposed method yields remarkable segmentations. In addition, our proposed method achieves a cube overlap score of 61% \u00b1 25% for lesions on the validation set."}, {"heading": "3.3. Clinical Dataset MRI", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.3.1. Dataset", "text": "To demonstrate the generalization to other modalities, we applied our methods to a DW-MRI clinical dataset. 31 patients underwent clinical evaluation and MR imaging for the primary diagnosis of HCC. Imaging was performed using a 1.5 T-MRI scanner (Avanto, Siemens) with a standard imaging protocol that included axial and coronal T2w, axial T1w images before and after the application of the Gadolinium DTPA contrast agent. Diffusion-weighted imaging was performed with a section thickness of 5mm and a matrix size of 192 x 192."}, {"heading": "3.3.2. Experimental setting", "text": "Compared to the CT data sets, the DW-MRI data set was processed differently, the DW-MRI data set was normalized using the N4Bias correction algorithm [27], and then the same pre-processing steps were performed as for the CT. CFCN for the DW-MRI data set was trained on the same hardware and training setup. Optimizer in this experiment was an Adam optimizer with = 0.1.7www.turtleseg.com"}, {"heading": "3.3.3. Qualitative and quantitative results", "text": "As shown in Figure 8, the CFCN was able to correctly segment the liver lesion. In both cases, the CFCN subsegmented the lesion, resulting in a cube value of 85% in both cases. Quantitative segmentation results are shown in Table 1. Cascaded UNET was able to achieve a cube value for the liver in the MR-DWI of 87%. For the lesion, we found an average cube value of 69.7%."}, {"heading": "3.4. HCC Survival Prediction based on automatic liver and lesion segmentation", "text": "In this paragraph, we would like to present a possible application of our automatic liver and lesion segmentation algorithms in medical imaging. Survival and outcome predictions are important fields in medical imaging. In contrast to previous work, we relied on manual liver and lesion segmentation in DW-MRI to predict patient survival. Unlike previous work, we trained a CFCN to automatically segment liver and lesion segmentation in the DW-MRI to enable automatic survival predictions. We formulate this task as a classification problem with classes representing \"low risk\" and \"high risk\" represented by longer or shorter survival times than median survival. We predict HCC malignancy in two steps: As a first step, we automatically segment the HCC-based HCC and fully transcalize the second step of our HCC-suggested tumor method > N."}, {"heading": "4. Discussion", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1. Combined segmentation and clinical relevance", "text": "Compared to prior art, such as [8, 6, 5, 33], we presented a framework capable of combined segmentation of the liver and its lesion. Furthermore, we demonstrated the clinical relevance of our proposed method by using our automatic segmentation to derive quantitative medical knowledge. In addition, and in contrast to previous work such as [1, 38, 39, 40], our proposed method could be generalized to liver and lesion segmentation in various modalities as well as to multiple organs in medical data. As current results from the segmentation of natural images show, fully-evolutionary networks are able to segment dozens of labels effortlessly. In addition to a runtime per disc of 0.19ms and 0.59ms, our proposed method enables the automatic segmentation of large clinical trials within days, not months 9 using a single desktop PC. 8Reference will be added after publication of Estimating CT 3000 for a large-scale clinical trial laid out for volumes."}, {"heading": "4.2. 3D CNN and FCN Architectures", "text": "Recent work such as DeepMedic [22], V-NET [28] and 3D UNet [29] has been made possible by efficient implementation of 3D windings on GPUs and show promising results in their respective segmentation tasks. The proposed idea of cascaded FCN could also be applied to novel 3D CNN and 3D FCN architectures. Restricting the Region of Interest ROI to relevant organs, as demonstrated for the 2D-UNET, in confining it to liver pixels for segmentation of lesions, significantly increases segmentation accuracy. Intuition that more specific filters could be trained for the underlying problem if the relevant regions are restricted also applies to 3D. Future work will show whether 3D architectures can cope with less available training data for lesion segmentation."}, {"heading": "4.3. 3D Conditional Random Field", "text": "When applying the 3DCRF to our segmentation problem, we showed a statistically significant improvement in segmentation quality. However, matching hyperparameters such as those of the 3DCRF is very time-consuming and task-dependent. We found that it is difficult for highly heterogeneous structures in shape and appearance, such as HCC lesions, to find a hyperparameter set that generalizes to invisible cases in a random search. A similar conclusion was drawn in [22] when a 3DCRF was applied to heterogeneous brain lesions. Recent work successfully integrated learning the CRF hyperparameter into the training process [17]. This approach, combined with additional pair terms that incorporate prior knowledge of the problem, could lead to an improvement in the CRF for this task."}, {"heading": "5. Conclusion", "text": "Cascaded FCNs and dense 3D CRFs trained on CT volumes are suitable for automatic localization and combined volumetric segmentation of the liver and its lesions. Our proposed method competes with the state-of-the-art. We make our trained models available under open source license, which allows fine-tuning for other medical applications in CT data 10. In addition, we have introduced and evaluated dense 3D CRF as a post-processing step for deep learning-based medical image analysis. Unlike previous work such as [8, 6, 5], our proposed method could be generalized to segment multiple organs in medical data using multiple cascaded FCNs. As future work, the application of more cascaded FCNs on lesions ROIs to classify malignant lesions as well as advanced techniques such as data extraction using adversarial networks could further improve the accuracy of segmentation."}], "references": [{"title": "Comparison and evaluation of methods for liver segmentation from ct datasets", "author": ["T. Heimann"], "venue": "IEEE Transactions on Medical Imaging", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2009}, {"title": "Estimates of worldwide burden of cancer in 2008: Globocan 2008", "author": ["J. Ferlay", "H.-R. Shin", "F. Bray", "D. Forman", "C. Mathers", "D.M. Parkin"], "venue": "International Journal of Cancer 127 (12) ", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2010}, {"title": "Editorial: 3d segmentation in the clinic: a grand challenge ii-liver tumor segmentation", "author": ["X. Deng", "G. Du"], "venue": "in: MICCAI Workshop", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2008}, {"title": "Automatic liver segmentation based on shape constraints and deformable graph cut in ct images", "author": ["G. Li", "X. Chen", "F. Shi", "W. Zhu", "J. Tian", "D. Xiang"], "venue": "Image Processing, IEEE Transactions on 24 (12) ", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2015}, {"title": "A likelihood and local constraint level set model for liver tumor segmentation from ct volumes", "author": ["C. Li", "X. Wang", "S. Eberl", "M. Fulham", "Y. Yin", "J. Chen", "D.D. Feng"], "venue": "Biomedical Engineering, IEEE Transactions on 60 (10) ", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "Tumor burden analysis on computed tomography by automated liver and tumor segmentation", "author": ["M.G. Linguraru", "W.J. Richbourg", "J. Liu", "J.M. Watt", "V. Pamulapati", "S. Wang", "R.M. Summers"], "venue": "Medical Imaging, IEEE Transactions on 31 (10) ", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2012}, {"title": "Improved segmentation of low-contrast lesions using sigmoid edge model", "author": ["A.H. Foruzan", "Y.-W. Chen"], "venue": "International Journal of Computer Assisted Radiology and Surgery ", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2015}, {"title": "Metastatic liver tumour segmentation from discriminant grassmannian manifolds", "author": ["S. Kadoury", "E. Vorontsov", "A. Tang"], "venue": "Physics in Medicine and Biology 60 (16) ", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2015}, {"title": "Liver tumors segmentation from cta images using voxels classification and affinity constraint propagation", "author": ["M. Freiman", "O. Cooper", "D. Lischinski", "L. Joskowicz"], "venue": "International Journal of Computer Assisted Radiology and Surgery 6 (2) ", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2011}, {"title": "Automatic liver tumor segmentation in follow-up ct scans: Preliminary method and results", "author": ["R. Vivanti", "A. Ephrat", "L. Joskowicz", "N. Lev-Cohain", "O.A. Karaaslan", "J. Sosna"], "venue": "in: International Workshop on Patch-based Techniques in Medical Imaging, Springer", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2015}, {"title": "Semi-automatic liver tumor segmentation with hidden markov measure field model and non-parametric distribution estimation", "author": ["Y. H\u00e4me", "M. Pollari"], "venue": "Medical Image Analysis 16 (1) ", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2012}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "in: NIPS", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2012}, {"title": "U-net: Convolutional networks for biomedical image segmentation", "author": ["O. Ronneberger", "P. Fischer", "T. Brox"], "venue": "in: MICCAI, Vol. 9351", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2015}, {"title": "Detection of glands and villi by collaboration of domain knowledge and deep learning", "author": ["J. Wang", "J.D. MacKenzie", "R. Ramachandran", "D.Z. Chen"], "venue": "in: MICCAI", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep feature learning for knee cartilage segmentation using a triplanar convolutional neural network", "author": ["A. Prasoon", "K. Petersen", "C. Igel", "F. Lauze", "E. Dam", "M. Nielsen"], "venue": "in: MICCAI, Vol. 16", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2013}, {"title": "18  B", "author": ["K. Kamnitsas", "C. Ledig", "V.F. Newcombe", "J.P. Simpson", "A.D. Kane", "D.K. Menon", "D. Rueckert"], "venue": "Glocker, Efficient multi-scale 3d cnn with fully connected crf for accurate brain lesion segmentation, Medical Image Analysis 36 ", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2017}, {"title": "Deeporgan: Multi-level deep convolutional networks for automated pancreas segmentation", "author": ["H.R. Roth", "L. Lu", "A. Farag", "H.-C. Shin", "J. Liu", "E.B. Turkbey", "R.M. Summers"], "venue": "in: MICCAI", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2015}, {"title": "Parallel multi-dimensional lstm", "author": ["M.F. Stollenga", "W. Byeon", "M. Liwicki", "J. Schmidhuber"], "venue": "with application to fast biomedical volumetric image segmentation, in: Advances in Neural Information Processing Systems", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2015}, {"title": "M", "author": ["P.F. Christ", "M.E.A. Elshaer", "F. Ettlinger", "S. Tatavarty", "M. Bickel", "P. Bilic", "M. Rempfler", "M. Armbruster", "F. Hofmann"], "venue": "D\u2019Anastasi, W. H. Sommer, S.-A. Ahmadi, B. H. Menze, Automatic Liver and Lesion Segmentation in CT Using Cascaded Fully Convolutional Neural Networks and 3D Conditional Random Fields, MICCAI, Cham", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2016}, {"title": "N4ITK: Improved N3 bias correction", "author": ["N.J. Tustison", "B.B. Avants", "P.A. Cook", "Y. Zheng", "A. Egan", "P.A. Yushkevich", "J.C. Gee"], "venue": "IEEE Transactions on Medical Imaging 29 (6) ", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2010}, {"title": "V-net: Fully convolutional neural networks for volumetric medical image segmentation", "author": ["F. Milletari", "N. Navab", "S.-A. Ahmadi"], "venue": "in: 3D Vision (3DV), 2016 Fourth International Conference on, IEEE", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2016}, {"title": "3d u-net: learning dense volumetric segmentation from sparse annotation", "author": ["\u00d6. \u00c7i\u00e7ek", "A. Abdulkadir", "S.S. Lienkamp", "T. Brox", "O. Ronneberger"], "venue": "in: International Conference on Medical Image Computing and Computer-Assisted Intervention, Springer", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2016}, {"title": "Efficient inference in fully connected crfs with gaussian edge potentials", "author": ["P. Kr\u00e4henb\u00fchl", "V. Koltun"], "venue": "in: NIPS", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2011}, {"title": "J", "author": ["L. Soler", "A. Hostettler", "V. Agnus", "A. Charnoz", "J. Fasquel", "J. Moreau", "A. Osswald", "M. Bouhadjar"], "venue": "Marescaux, 3d image reconstruction for comparison of algorithm database: a patient-specific anatomical and medical image database ", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2012}, {"title": "Caffe: Convolutional architecture for fast feature embedding", "author": ["Y. Jia", "E. Shelhamer", "J. Donahue", "S. Karayev", "J. Long", "R. Girshick", "S. Guadarrama", "T. Darrell"], "venue": "in: Proceedings of the ACM International Conference on Multimedia, ACM", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2014}, {"title": "Semi-automated liver ct segmentation using laplacian meshes", "author": ["G. Chartrand", "T. Cresson", "R. Chav", "A. Gotra", "A. Tang", "J. DeGuise"], "venue": "in: ISBI, IEEE", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2014}, {"title": "Fully Convolutional Network for Liver Segmentation and Lesions Detection", "author": ["A. Ben-Cohen", "I. Diamant", "E. Klang", "M. Amitai", "H. Greenspan"], "venue": "Springer International Publishing, Cham", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2016}, {"title": "Spotlight: Automated confidence-based user guidance for increasing efficiency in interactive 3d image segmentation", "author": ["A. Top", "G. Hamarneh", "R. Abugharbieh"], "venue": "in: MICCAI", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2010}, {"title": "Active learning for interactive 3d image segmentation", "author": ["A. Top", "G. Hamarneh", "R. Abugharbieh"], "venue": "in: MICCAI, Vol. 6893", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2011}, {"title": "A 3-d liver segmentation method with parallel computing for selective internal radiation therapy", "author": ["M. Goryawala", "M.R. Guillen", "M. Cabrerizo", "A. Barreto", "S. Gulec", "T.C. Barot", "R.R. Suthar", "R.N. Bhatt", "A. Mcgoron", "M. Adjouadi"], "venue": "Transactions on Information Technology in Biomedicine 16 (1) ", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2012}, {"title": "J", "author": ["F. L\u00f3pez-Mir", "P. Gonz\u00e1lez", "V. Naranjo", "E. Pareja", "S. Morales"], "venue": "Solaz-M\u0131\u0301nguez, A method for liver segmentation on computed tomography images in venous phase suitable for real environments, Journal of Medical Imaging and Health Informatics 5 (6) ", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2015}, {"title": "Liver segmentation with constrained convex variational model", "author": ["J. Peng", "Y. Wang", "D. Kong"], "venue": "Pattern Recognition Letters 43 ", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "Anomalies in the shape and texture of the liver and visible lesions in CT are important biomarkers for initial disease diagnosis and progression in both primary and secondary hepatic tumor disease [1].", "startOffset": 197, "endOffset": 200}, {"referenceID": 1, "context": "Hepatocellular carcinoma (HCC) presents the sixth-most common cancer and the third-most common cause of cancer-related deaths worldwide [2].", "startOffset": 136, "endOffset": 139}, {"referenceID": 0, "context": "In 2007 and 2008, two Grand Challenges benchmarks on liver and liver lesion segmentation have been conducted [1, 4].", "startOffset": 109, "endOffset": 115}, {"referenceID": 2, "context": "In 2007 and 2008, two Grand Challenges benchmarks on liver and liver lesion segmentation have been conducted [1, 4].", "startOffset": 109, "endOffset": 115}, {"referenceID": 0, "context": "Furthermore, grey level and texture based methods have been developed [1].", "startOffset": 70, "endOffset": 73}, {"referenceID": 3, "context": "Recent work on liver and lesion segmentation employs graph cut and level set techniques [5, 6, 7], sigmoid edge modeling [8] or manifold and machine learning [9, 10, 11, 12].", "startOffset": 88, "endOffset": 97}, {"referenceID": 4, "context": "Recent work on liver and lesion segmentation employs graph cut and level set techniques [5, 6, 7], sigmoid edge modeling [8] or manifold and machine learning [9, 10, 11, 12].", "startOffset": 88, "endOffset": 97}, {"referenceID": 5, "context": "Recent work on liver and lesion segmentation employs graph cut and level set techniques [5, 6, 7], sigmoid edge modeling [8] or manifold and machine learning [9, 10, 11, 12].", "startOffset": 88, "endOffset": 97}, {"referenceID": 6, "context": "Recent work on liver and lesion segmentation employs graph cut and level set techniques [5, 6, 7], sigmoid edge modeling [8] or manifold and machine learning [9, 10, 11, 12].", "startOffset": 121, "endOffset": 124}, {"referenceID": 7, "context": "Recent work on liver and lesion segmentation employs graph cut and level set techniques [5, 6, 7], sigmoid edge modeling [8] or manifold and machine learning [9, 10, 11, 12].", "startOffset": 158, "endOffset": 173}, {"referenceID": 8, "context": "Recent work on liver and lesion segmentation employs graph cut and level set techniques [5, 6, 7], sigmoid edge modeling [8] or manifold and machine learning [9, 10, 11, 12].", "startOffset": 158, "endOffset": 173}, {"referenceID": 9, "context": "Recent work on liver and lesion segmentation employs graph cut and level set techniques [5, 6, 7], sigmoid edge modeling [8] or manifold and machine learning [9, 10, 11, 12].", "startOffset": 158, "endOffset": 173}, {"referenceID": 10, "context": "To overcome these weaknesses, interactive methods were still developed [13] to overcome these weaknesses.", "startOffset": 71, "endOffset": 75}, {"referenceID": 11, "context": "Deep Convolutional Neural Networks (CNN) have gained a new attention in the scientific community for solving computer vision tasks such as object recognition, classification and segmentation [14, 15], often out-competing state-of-the art methods.", "startOffset": 191, "endOffset": 199}, {"referenceID": 12, "context": "[18, 19, 20, 21, 22, 23, 24, 25].", "startOffset": 0, "endOffset": 32}, {"referenceID": 13, "context": "[18, 19, 20, 21, 22, 23, 24, 25].", "startOffset": 0, "endOffset": 32}, {"referenceID": 14, "context": "[18, 19, 20, 21, 22, 23, 24, 25].", "startOffset": 0, "endOffset": 32}, {"referenceID": 15, "context": "[18, 19, 20, 21, 22, 23, 24, 25].", "startOffset": 0, "endOffset": 32}, {"referenceID": 16, "context": "[18, 19, 20, 21, 22, 23, 24, 25].", "startOffset": 0, "endOffset": 32}, {"referenceID": 17, "context": "[18, 19, 20, 21, 22, 23, 24, 25].", "startOffset": 0, "endOffset": 32}, {"referenceID": 18, "context": "A preliminary version of this work was presented in MICCAI 2016 [26] and will be presented at ISBI 2017.", "startOffset": 64, "endOffset": 68}, {"referenceID": 19, "context": "For DW-MRI the data preparation scheme is similar and differs in the data normalization, which additionally performs N4bias correction [27].", "startOffset": 135, "endOffset": 139}, {"referenceID": 12, "context": "As in [18, 22], to teach the network the desired invariance properties, several data augmentations steps, such as elastic deformation, translation, rotation and addition of Gaussian noise with standard deviation of the current slice, have been employed to increase the training data for the CFCN.", "startOffset": 6, "endOffset": 14}, {"referenceID": 15, "context": "As in [18, 22], to teach the network the desired invariance properties, several data augmentations steps, such as elastic deformation, translation, rotation and addition of Gaussian noise with standard deviation of the current slice, have been employed to increase the training data for the CFCN.", "startOffset": 6, "endOffset": 14}, {"referenceID": 11, "context": "The main idea in their work is to replace the last fully connected layers of a classification network such as the AlexNet [14] with fully convolutional layers to allow dense pixel-wise predictions.", "startOffset": 122, "endOffset": 126}, {"referenceID": 12, "context": "(2015) [18].", "startOffset": 7, "endOffset": 11}, {"referenceID": 12, "context": "From FCN to CFCN We used the UNet architecture [18] to compute the soft label probability maps P (xi|I).", "startOffset": 47, "endOffset": 51}, {"referenceID": 12, "context": "(2015), which were trained on cell image segmentation data [18].", "startOffset": 59, "endOffset": 63}, {"referenceID": 14, "context": "Volumetric FCN implementation with 3D convolutions was strongly limited by GPU hardware and available VRAM [21].", "startOffset": 107, "endOffset": 111}, {"referenceID": 20, "context": "Recent work such as VNET and 3DUNET, allow nowadays 3D FCNs at decreased resolution [28, 29].", "startOffset": 84, "endOffset": 92}, {"referenceID": 21, "context": "Recent work such as VNET and 3DUNET, allow nowadays 3D FCNs at decreased resolution [28, 29].", "startOffset": 84, "endOffset": 92}, {"referenceID": 22, "context": "Instead, to capitalise on the locality information across slices within the dataset, we utilize 3D dense conditional random fields CRFs as proposed by [30].", "startOffset": 151, "endOffset": 155}, {"referenceID": 22, "context": "We specify the dense CRF following [30] on the complete graph G = (V , E) with vertices i \u2208 V for each voxel in the image and edges eij \u2208 E = {(i, j) \u2200i, j \u2208 V s.", "startOffset": 35, "endOffset": 39}, {"referenceID": 22, "context": "We estimate the best labelling x\u2217 = arg minx\u2208LN E(x) using the efficient mean field approximation algorithm of [30].", "startOffset": 111, "endOffset": 115}, {"referenceID": 0, "context": "We assessed the performance of our proposed method using the quality metrics introduced in the grand challenges for liver and lesion segmentation by [1, 4].", "startOffset": 149, "endOffset": 155}, {"referenceID": 2, "context": "We assessed the performance of our proposed method using the quality metrics introduced in the grand challenges for liver and lesion segmentation by [1, 4].", "startOffset": 149, "endOffset": 155}, {"referenceID": 0, "context": "where the Dice score is in the interval [0,1].", "startOffset": 40, "endOffset": 45}, {"referenceID": 0, "context": "where the value is in the interval [0, 1].", "startOffset": 35, "endOffset": 41}, {"referenceID": 23, "context": "Dataset We evaluated our proposed method on the 3DIRCADb dataset [31].", "startOffset": 65, "endOffset": 69}, {"referenceID": 24, "context": "The neural networks were implemented and trained using the deep learning framework caffe [32] from University of Berkeley.", "startOffset": 89, "endOffset": 93}, {"referenceID": 12, "context": "In the first row, the false positive lesion prediction in B of a single UNet as proposed by [18] were eliminated in C by CFCN as a result of restricting lesion segmentation to the liver ROI region.", "startOffset": 92, "endOffset": 96}, {"referenceID": 12, "context": "UNET as in [18] 3DIRCAD 39 87 19.", "startOffset": 11, "endOffset": 15}, {"referenceID": 3, "context": "[5] (liver-only) 3DIRCAD 9.", "startOffset": 0, "endOffset": 3}, {"referenceID": 25, "context": "[33] (semi-automatic) 3DIRCAD 6.", "startOffset": 0, "endOffset": 4}, {"referenceID": 4, "context": "[6] (liver-only) 3DIRCAD 94.", "startOffset": 0, "endOffset": 3}, {"referenceID": 26, "context": "[34] (liver-only) Own Clinical CT 89 Cascaded UNET MR-DWI 23 14 5.", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "Human rater ground truth was obtained through manual volumetric segmentation using the software TurtleSeg [35, 36].", "startOffset": 106, "endOffset": 114}, {"referenceID": 28, "context": "Human rater ground truth was obtained through manual volumetric segmentation using the software TurtleSeg [35, 36].", "startOffset": 106, "endOffset": 114}, {"referenceID": 19, "context": "The DW-MRI dataset was normalized using the N4Bias correction algorithm [27].", "startOffset": 72, "endOffset": 76}, {"referenceID": 6, "context": "In comparison to state-of-the-art, such as [8, 6, 5, 33], we presented a framework, which is capable of a combined segmentation of the liver and its lesion.", "startOffset": 43, "endOffset": 56}, {"referenceID": 4, "context": "In comparison to state-of-the-art, such as [8, 6, 5, 33], we presented a framework, which is capable of a combined segmentation of the liver and its lesion.", "startOffset": 43, "endOffset": 56}, {"referenceID": 3, "context": "In comparison to state-of-the-art, such as [8, 6, 5, 33], we presented a framework, which is capable of a combined segmentation of the liver and its lesion.", "startOffset": 43, "endOffset": 56}, {"referenceID": 25, "context": "In comparison to state-of-the-art, such as [8, 6, 5, 33], we presented a framework, which is capable of a combined segmentation of the liver and its lesion.", "startOffset": 43, "endOffset": 56}, {"referenceID": 0, "context": "Furthermore, and in contrast to prior work such as [1, 38, 39, 40], our proposed method could be generalized to segment the liver and lesion in different modalities and also multiple organs in medical data.", "startOffset": 51, "endOffset": 66}, {"referenceID": 29, "context": "Furthermore, and in contrast to prior work such as [1, 38, 39, 40], our proposed method could be generalized to segment the liver and lesion in different modalities and also multiple organs in medical data.", "startOffset": 51, "endOffset": 66}, {"referenceID": 30, "context": "Furthermore, and in contrast to prior work such as [1, 38, 39, 40], our proposed method could be generalized to segment the liver and lesion in different modalities and also multiple organs in medical data.", "startOffset": 51, "endOffset": 66}, {"referenceID": 31, "context": "Furthermore, and in contrast to prior work such as [1, 38, 39, 40], our proposed method could be generalized to segment the liver and lesion in different modalities and also multiple organs in medical data.", "startOffset": 51, "endOffset": 66}, {"referenceID": 15, "context": "Recent works such as DeepMedic [22], the V-NET [28] and the 3D UNet [29] became possible due to efficient implementations of 3D convolutions on GPUs, and they show promising results on their respective segmentation tasks.", "startOffset": 31, "endOffset": 35}, {"referenceID": 20, "context": "Recent works such as DeepMedic [22], the V-NET [28] and the 3D UNet [29] became possible due to efficient implementations of 3D convolutions on GPUs, and they show promising results on their respective segmentation tasks.", "startOffset": 47, "endOffset": 51}, {"referenceID": 21, "context": "Recent works such as DeepMedic [22], the V-NET [28] and the 3D UNet [29] became possible due to efficient implementations of 3D convolutions on GPUs, and they show promising results on their respective segmentation tasks.", "startOffset": 68, "endOffset": 72}, {"referenceID": 15, "context": "A similar conclusion was made in [22] when applying a 3DCRF to heterogeneous brain lesions.", "startOffset": 33, "endOffset": 37}, {"referenceID": 6, "context": "Furthermore, and in contrast to prior work such as [8, 6, 5], our proposed method could be generalized to segment multiple organs in medical data using multiple cascaded FCNs.", "startOffset": 51, "endOffset": 60}, {"referenceID": 4, "context": "Furthermore, and in contrast to prior work such as [8, 6, 5], our proposed method could be generalized to segment multiple organs in medical data using multiple cascaded FCNs.", "startOffset": 51, "endOffset": 60}, {"referenceID": 3, "context": "Furthermore, and in contrast to prior work such as [8, 6, 5], our proposed method could be generalized to segment multiple organs in medical data using multiple cascaded FCNs.", "startOffset": 51, "endOffset": 60}], "year": 2017, "abstractText": "Automatic segmentation of the liver and hepatic lesion is an important step towards deriving quantitative biomarkers for accurate clinical diagnosis and computer-aided decision support systems. This paper presents a method to automatically segment liver and lesions in CT and MRI abdomen images using cascaded fully convolutional neural networks (CFCNs) enabling the segmentation of a large-scale medical trial or quantitative image analysis. We train and cascade two FCNs for a combined segmentation of the liver and its lesions. In the first step, we train a FCN to segment the liver as ROI input for a second FCN. The second FCN solely segments lesions within the predicted liver ROIs of step 1. CFCN models were trained on an abdominal CT dataset comprising 100 hepatic tumor volumes. Validations on further datasets show that CFCN-based semantic liver and lesion segmentation achieves Dice scores over 94% for liver with computation times below 100s per volume. We further experimentally demonstrate the robustness of the proposed method on an 38 MRI liver tumor volumes and the public 3DIRCAD dataset.", "creator": "LaTeX with hyperref package"}}}