{"id": "1702.06269", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Feb-2017", "title": "Memory and Communication Efficient Distributed Stochastic Optimization with Minibatch-Prox", "abstract": "We present and analyze statistically optimal, communication and memory efficient distributed stochastic optimization algorithms with near-linear speedups (up to $\\log$-factors). This improves over prior work which includes methods with near-linear speedups but polynomial communication requirements (accelerated minibatch SGD) and communication efficient methods which do not exhibit any runtime speedups over a naive single-machine approach. We first analyze a distributed SVRG variant as a distributed stochastic optimization method and show that it can achieve near-linear speedups with logarithmic rounds of communication, at the cost of high memory requirements. We then present a novel method, stochastic DANE, which trades off memory for communication and still allows for optimization with communication which scales only logarithmically with the desired accuracy while also being memory efficient. Stochastic DANE is based on a minibatch prox procedure, solving a non-linearized subproblem on a minibatch at each iteration. We provide a novel analysis for this procedure which achieves the statistical optimal rate regardless of minibatch size and smoothness, and thus significantly improving on prior work.", "histories": [["v1", "Tue, 21 Feb 2017 05:19:23 GMT  (619kb)", "https://arxiv.org/abs/1702.06269v1", null], ["v2", "Fri, 9 Jun 2017 16:14:48 GMT  (735kb)", "http://arxiv.org/abs/1702.06269v2", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["jialei wang", "weiran wang", "nathan srebro"], "accepted": false, "id": "1702.06269"}, "pdf": {"name": "1702.06269.pdf", "metadata": {"source": "CRF", "title": "Memory and Communication Efficient Distributed Stochastic Optimization with Minibatch-Prox", "authors": ["Jialei Wang", "Weiran Wang", "N. Srebro", "WANG WANG SREBRO"], "emails": ["JIALEI@UCHICAGO.EDU", "WEIRANWANG@TTIC.EDU", "NATI@TTIC.EDU"], "sections": [{"heading": null, "text": "ar Xiv: 170 2.06 269v 2 [cs.L G] 9optimum and achieves near-linear acceleration (up to logarithmic factors).Our approach allows a compromise between communication and memory, either with logarithmic communication but linear memory, or with polynomial communication and a corresponding reduction in memory usage.This compromise between communication and memory is achieved by minibatch-prox iterations (passive aggressive minibatch updates), in which a partial problem on a minibatch is solved with each iteration. We provide a novel analysis for such a minibatch-prox procedure, which achieves the statistically optimal rate regardless of the size and smoothness of a minibatch, significantly improving on previous work."}, {"heading": "1. Introduction", "text": "\"We are not able to achieve optimal data distribution by relying on a single machine, stochastic approach methods such as stochastic gradients (SGD) or stochastic mirror scenarios in general are ideal for the problem, as they typically have optimal sample requirements and run in linear time in the number of samples, and thus have optimal runtimes."}, {"heading": "Our contributions", "text": "Stacks of proximal updates can be of independent interest and can be useful in other contexts and as a basis for other methods.Notations We designate the optimal solution for (1). Throughout the essay, we assume that the immediate function (w,) L-Lipschitz and (w,) L-strongly convex inw is in the field for a certain time (w,) 0. In some cases, we also assume that (w,), (w,), (w,), (w,), (w,), (w,), (w,), (w,), (w,), (w,), (w,), (w,), (w,), (w,), (w,), (w,)."}, {"heading": "2. Distributed SVRG for stochastic convex optimization", "text": "Recently Lee et al. (2015) proposed to use fast randomized finite sum optimization algorithms, and in particular the SVRG algorithm, as a distributed optimization approach for (2).The authors noted that for SVRG, if the sample size n (\u03b5) dominates the condition number \u03b2 / \u03bd, where \u03b2 is the smoothness parameter of (w), the time complexity is dominated by the calculation of the stack progressive.This operation can be trivially parallelized, but the stochastic updates can be implemented on a single machine while the other machines wait, the only caveat being that only sampling-without-substitution can be implemented. Theoretically, the use of non-replacement sampling was justified in a recent analysis by Shamir (2016).In the distributed stochastic convex optimization setting that is considered here, SVDRG achieves some kind of linear duplication."}, {"heading": "3. The minibatch-prox algorithm for stochastic optimization", "text": "In this section, we will describe and analyze the minibatch prox algorithm for stochastic optimization, which allows us to use any minibatch size without slowing down the convergence rate. First, we will introduce the basic version, in which each proximal target is solved exactly for each minibatch, achieving the optimal convergence rate. Then, we will show that if each minibatch target is solved precisely enough, the algorithm will still converge at the optimal rate, opening the possibility for efficient implementations."}, {"heading": "3.1. Exact minibatch-prox", "text": "The \"exact\" data in which we process all the data is defined by the following iterations: \"We have many effectiveness.\" The \"exact\" miniature prox method is derived from the following iterations: \"We have many effects.\" The \"exact\" miniature prox method is derived from the following iterations: \"We have many effects.\" The \"exact\" miniature prox method is derived from the following iterations: \"We do not have any.\" The \"exact\" miniature prox prox process method is derived from the second order process process method. \"It is the\" exact \", exact analysis method\" (3) that we first derive from the first order optimality condition for the first order process condition (3) that is derived from the second order process process process process method (3). \"It is a series of examples we first understand from the first order (To understand the first order) condition."}, {"heading": "3.2. Inexact minibatch-prox", "text": "The \"inexact\" miniature prox uses a possible random algorithm to solve a problem that has to be solved in each iteration process, and generates the following iterations: for t = 1,.., w = 1, w = 1, w = 1, w = 1, b = 1, b = 1, b = 1, b = 1, b = 2, b = 1, b = 1, b = 1, b = 1, b = 1, b = 1, b = 1, b = 1, b = 1, b = 1, b = 1, b = 1, b = 1, b = 1, b = 1, b = b = 1, b =, b = 1, b = 1, b = 2, b = 2, b = 2, b = 1, b =, b = 1, b =, b = 1, b =, b = 1, b = 1, b =, b = 1, b =, b = 1, b = 1, b =, b = 1, b =, b = 1, b = 1, b =, b = 1, b = 1, b =, b = 1, b = 1, b = 1, b =, b = 1, b = 1, b = 1, b = 1, b =, b = 1, b = 1, b =, b = 1, b = 1, b = 1, b = 1, b = 1, b = 1, b = 1, b =, b = 1, b = 1, b =, b = 1, b = 1, b = 1, b = 1, b = 1, b = 1, b = 1, b = 1, b = 1, b = 1, b = 1, b = 1, b = 1, b = 1, b = 1, b = 1, b = 1, b =, b = 1, b = 1, b = 1, b = 1, b = 1, b =, b = 1, b = 1, b = 1, b = 1, b = 1, b = 1, b = 1, b = 1, b = 1, b = 1, b = 1, b = 1, b = 1, b = 1, b = 1, b = 1, b = 1, b = 1, b = 1,"}, {"heading": "4. Communication-efficient distributed minibatch-prox with SVRG", "text": "We apply the theoretical results of minibatch-prox to the distributed stochastic learning environments and propose a novel algorithm that is both communication and computing efficient and capable of exploring trade-offs between memory and communication efficiency. Suppose we have m machines in a distributed environment. In order to apply the minibatch-prox algorithms from the previous section, we need to find an approximate solution to the following problem: min wf (w). It (w) + 1), which contains bm samples. (12) Since the objective (12) includes functions from different machines, we use distributed optimization algorithms for the solution. (2014), the authors propose a simple algorithm solution."}, {"heading": "4.1. Efficiency of MP-DSVRG", "text": "For the distributed stochastic convex optimization problems, we are concerned with efficiency in relation to sample, communication, calculation and memory. Remember that for convex L-Lipshitz, Bbounded problems we need a predictor w * with \u03b5 generalization error, i.e. E [\u03c6 (w *) \u2212 \u03c6 (w *) \u2264 \u03b5 to learn the sample size at least n (\u03b5) = O (L2B2 / \u03b52). This sample complexity corresponds to the lowest limit and can be achieved by Vanilla SGD. The following sentence shows that with careful selection of parameters in the outer and inner loops MP-DSVRG both communication and computing efficiency will be achieved with the optimal sample complexity. Theorem 10 (efficiency of MP-DSVRG): The parameters in Algorithm 1 are set as follows: (outer loop) T = n (procedure) Process. We can maintain the efficiency of an SVRD machine (efficiency of an SVR)."}, {"heading": "5. Discussion and conclusion", "text": "In this paper, we have made progress toward linear acceleration, communication, and memory-efficient methods for distributed stochastic optimization, although we do not yet have an algorithm that achieves the \"ideal\" distributed stochastic optimization performance of linear acceleration with constant or near-constant communication and memory requirements. Nor is there a single known algorithm that dominates all others, preferring different methods with respect to different resources. These compromises, up to log factors, are given in Table 1, and the requirements for memory, communication, and runtime are also schematically represented in Figure 2. In the figure, the horizontal axis corresponds to the minibatch dimensions that can be controlled with accelerated minibatch-SGD and MP-DSVRG, while other methods are batch methods methods that equate the entire data.4. We can equally assume that the entire miniaturistic communication with miniature-sized and batch-drilled is equal to SVRG (see from SVRG to SVRG)."}, {"heading": "Acknowledgement", "text": "The research was partially supported by an Intel ICRI-CI Award and the NSF Awards IIS 1302662 and BIGDATA 1546500. We would like to thank Ohad Shamir for discussing Distributed SVRG and Tong Zhang for discussing minibatch-prox."}, {"heading": "Appendix A. Analysis of exact minibatch-prox", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A.1. Proof of Lemma 1", "text": "Note that (4) implies that \u03b3t (wt \u2212 1 \u2212 wt) is an undergradient when weighting the sum of \u03c6It (w) and the indicator function of \u0418t (which otherwise has a value of 0), and that we therefore have an undergradient for everyone when weighting the sum of \u03c6It (w) \u2212 \u03c6t < wt \u2212 1 \u2212 wt, w \u2212 wt > + \u03bb2 \u00b2 w \u2212 wt \u00b2 2. (14) For anyone, we can determine its distance in weighting \u2212 1 \u2212 w \u00b2 2 = weighting of weighting \u2212 1 \u2212 wt \u2212 wt + wt \u2212 w \u00b2 2 = weighting of weighting \u2212 1 \u2212 wt \u00b2 2 + 2 = weighting of weighting \u2212 1 \u2212 wt \u00b2 2 + 2 < wt \u2212 wt \u2212 1 \u2212 wt, wt \u2212 w > + w > + weighting of weighting by weighting (2) + weighting by weighting of weighting of the weighting of weighting of (0) between weighting (weighting) and (weighting) of (weighting) of (and) of (in function)."}, {"heading": "A.2. Proof of Lemma 2", "text": "The following Problem, which is essentially written by Shalev-Shwartz et al. (2009, Theorem 6), describes the convergence of empirical loss to the population (2009, Theorem 6), (2009, Theorem 6), (2009, Theorem 6), (2009, Theorem 6), (2009, Theorem 6), (2009, Theorem 6), (2009, Theorem 6), (2009, Theorem 6), (2009, Theorem 6), (2009, Theorem 6), (2009, Theorem 6), (2009, Theorem 6), (2009, Theorem 2013), (2013, Theorem 6), (2009, Theorem 6), (2009, Theorem 6), (2009, Theorem 6), (2009, Theorem 6), (2009, Theorem 6), (2009, Theorem 6), (2009, Theorem 6), (2009, Theorem 6), (2009, Theorem 6), (2009, Theorem 6), (2009, Theorem 6), (2009, Theorem 6), (2009, Theorem 6), (2009, Theorem 6), (2009, Theorem 6), (2009, Theorem 6), (2009, Theorem 6), (2009, Theorem 6), (2009, Theorem 6), (2009, Theorem 6), (2009, Theorem 6), (2009, Theorem 6), (2009, Theorem 6), (2013, (2013, 2013, 2013, 2013, 2013, 2013) (Theorem 6), (Theorem 6, (2013, 2013, 2013, 2013, (2013, 2013, 2013), (Theorem 6), (Theorem 6, 2013, 2013, 2013, (Theorem 6), (Theorem 6, 2013, 2013, 2013, 2013, 2013, 2013, (Theorem 6), (Theorem 6), (Theorem 6, 2013, 2013, 2013, 2013, (Theorem 6, 2013, 2013, 2013, 2013, 2013, 2013,"}, {"heading": "A.3. Proof of Lemma 3", "text": "We have proof of this by lexicon 2 that | EIt [\u03c6It (wt) \u2212 \u03c6 (wt)] | \u2264 4L2 (\u03bb + \u03b3t) b. Let us take the expectation of (6) about the random sampling of It and we get that (EIt (wt) \u2212 w \u00b2 2 \u2264% wt \u2212 1 \u2212 w \u00b2 2 \u03b3t (EIt (wt)] \u2212 \u03c6 (w)) = 1 \u2212 w \u00b2 2 \u2212 2\u0445t (EIt (wt) \u2212 \u03c6 (wt)]] + EIt (\u03c6 (wt) \u2212 \u03c6 (w))) \u2264 1 \u2212 w \u00b2 2 \u2212 2\u0445t EIt [\u03c6 (wt) \u00b7 2 \u041at | EIt [throuIt (wt) \u2212 \u03c6 (wt) \u2212 \u0430 (wt) \u00b2 \u00b2 \u00b2 \u00b2."}, {"heading": "A.4. Proof of Theorem 4", "text": "Evidence If (w,) is weakly convex (i.e., \u03bb = 0), we continue to set \u03b3t = \u03b3 for all t \u2265 1. Applying term 3 withw = w, yields EIt [\u03c6 (wt) \u2212 \u03c6 (w,)] \u2264 \u03b32 (\u0445t \u2212 w, 2 \u2212 EIt, wt \u2212 w, 2) + 4L2\u03b32. (20) The summation (20) for t = 1,..., T yields T, t = 1E [\u03c6 (wt) \u2212 \u03c6 (w, 2 \u2212 w,) \u2264 2, w0 \u2212 w, 2 + 4L2T\u03b3b. Minimizing the RHS over \u03b3 yields the optimal Choice\u0430 = \u221a 8Tb \u00b7 L, w0 \u2212 w, with a corresponding regret 1TT, t = 1E [\u03c6 (wt, w, p, w, w, w,)."}, {"heading": "A.5. Proof of Theorem 5", "text": "The proof that \"t\" (w,) \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" \"t\" \"t\" \"t\" \"t\" t \"\" \"t\" \"t\" \"t\" \"\" t \"t."}, {"heading": "Appendix B. Analysis of inexact minibatch-prox", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "B.1. Proof of Lemma 6", "text": "The evidence of strong convexity of f + CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS \u2212 CIS"}, {"heading": "B.2. Proof of Theorem 7", "text": "If we do not know, the non-negative sequence for all T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-"}, {"heading": "B.3. Proof of Theorem 8", "text": "The proof is provided by Lemma 6: \"We have no answer to this question.\" \"We have no answer.\" \"We have no answer.\" \"We have no answer.\" \"We have no answer.\" \"No.\" \"No.\" \"No.\" \"No.\" \"No.\" \"No.\" \"No.\" \"No.\" \"No.\" \"\" No. \"\" \"No.\" \"\" No. \"\" \"No.\" \"\" \"\" No. \"\" \"\" No. \".\" \"\" \"No.\". \"\" \"\" No. \".\" \"\" \"\" \"No.\" \".\" \"\" \"\" No. \".\" \"\" \"\" \"\" \"No.\". \"\".. \"\" \"\".. \"\" \"..\" \"..\" \"\" \"\" No..... \"\" \"\" \"..\" \"\" \"\".. \"\" \"\".. \"\" \".....\" \"\" \"\" \".\". \"\" \"\" No. \".\". \".\" \"\". \"\" \"\" \"\". \"\" \"No.\". \"\" \".\" \"\" \"\". \"\" \".\" \"\" \".\" \"\" \".\" \"\" \".\" \"\". \".\". \".\". \".\". \".\". \".\". \"\" \".\". \".\". \".\". \"\". \"\". \"\". \"\". \".\" \".\" \".\". \"\". \"\". \".\". \"\" \".\". \"\". \".\". \"\". \".\". \".\". \".\". \"\". \".\". \"\". \".\". \".\". \".\" \".\". \".\" \".\" \".\". \".\". \".\" \"\". \"\". \".\" \"\" \".\". \".\" \".\". \".\". \".\". \".\". \".\" \".\". \"\". \".\". \"\".. \".\" \"\".. \".\"..... \"\" \"..\"....... \".\".. \""}, {"heading": "Appendix C. Proof of Theorem 10", "text": "The proof that the inaccuracy conditions in Theorem 7 are fulfilled, i.e. for t = 1,.., T, is required (remember that w \u00b2 t = argminw f \u00b2 t (w)) f \u00b2 t (wt) \u2212 f \u00b2 t (w \u00b2 t) \u2264 1104 \u00b7 min ((Tbm) 1 / 2) \u00b7 LB t3. On the other hand, we can detect the initial sub-optimality of f \u00b2 t (w \u00b2 t) at the initialization of wt \u2212 1. This is because due to the optimality of w \u00b2 t \u2212 w \u00b2 t \u2212 w \u00b2 t \u2212 w \u00b2 t \u2212 w \u00b2 t \u2212 w \u00b2 t \u2212 w \u00b2 t (w \u00b2 t) the initial sub-optimality of f \u00b2 t (w \u00b2 t) as the initial sub-optimality of f \u00b2 t \u00b2 t (wt \u00b2 t) \u2212 b \u00b2 t \u00b2 t \u00b2 t \u00b2 t \u00b2 t \u00b2 t \u00b2 t \u00b2 t \u00b2 t \u00b2."}, {"heading": "Appendix D. Communication-efficient distributed minibatch-prox with DANE", "text": "Here we present a novel method that uses the distributed optimization algorithm DANE (Shamir et al., 2014) and its accelerated variant AIDE (Reddi et al., 2016) to solve (12) that defines better local targets than EMSO and takes into account the similarity between local targets. We detail our algorithm, called MP-DANE, in Algorithm 2. The algorithm consists of three nested loops in which t, r and k iteration counters for minibatch-prox (the outer for-loop), AIDE (the middle for-loop) and DANE (the inner for-loop). The algorithm consists of three nested loops in which t, r and k iteration counters for minibatch-prox (the outer for-loop) and DANE (the inner for-loop)."}, {"heading": "D.1. Efficiency of MP-DANE", "text": "We present the main results of this section (full analysis is deferred in Appendix D.3), which show that with careful selection of minibatch size and desired accuracy in each level of the approxi algorithm 2MP-DANE for distributed stochastic optimization (1, 2,., T doEach machine i prefers a minibatch I (i) t of b samples from the underlying data distribution. Initialize y0 - 1, x0, wt \u2212 1. for r = 1, 2,.,., R doInitialization z0, - 1, - 0, - 2, - 2,., K do 1. All machines perform a round of communication to calculate the average gradient."}, {"heading": "D.3. Analysis of MP-DANE", "text": "To fully analyze algorithm 2, we need several helper lemmas that characterize the iteration complexity of solving the local problem (33) by prox-SVRG (Xiao and Zhang, 2014), the large minibatch problem (12) by DANE (Shamir et al., 2014) and AIDE (Reddi et al., 2016)."}, {"heading": "D.3.1. SOME AUXILIARY LEMMAS", "text": "The advantage of this approach (as opposed to using simple SVRG Johnson and Zhang, 2013) is that the smoothing parameter that determines iteration complexity is simple \u03b2, the same results apply when applying prox-SAGA (Defazio et al., 2014) as well as when capturing without replacing SVRG, the current analysis only works for simple SVRG, so we quote the results from (Shamir, 2016). Lemma 17 (Iteration complexity of SVRG for (33)))) For all target accuracy > 0, with initialization zk \u2212 1, prox SVRG outputs z (i) k) k that the results from (i) k (i) k \u2212 z, k \u2212 z (i) k \u2212 z outputs z (i), k \u2212 z outputs z (i)."}, {"heading": "By initializing from yr\u22121, and setting the number of inner iterations in Algorithm 2 to be", "text": "11, 2, 3, 4, 5, 5, 5, 6, 6, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,"}, {"heading": "D.3.2. PROOF OF THEOREM 14", "text": "Proof First, because R = 1, our algorithm collapses into two nested loops (b). On the one hand, since we select \u03b3 as theorem 7, we only need to check the inaccuracy of the conditions in theorem 7, i.e., for t = 1,.., T, we need (remember that w \u00b2 t = argminw f \u00b2 t (w))) f \u00b2 t (wt) \u2212 f \u00b2 t (w \u00b2 t) \u2264 1104 \u00b7 min (((Tbm) 1 / 2, (Tbm) 3 / 2) \u00b7 2LBt3. On the other hand, we can find the initial suboptimality f \u00b2 t (w) (cf. derivative for (31): f \u00b2 t (w \u00b2 t \u2212 1) \u2212 f \u00b2 t (w \u00b2 t) \u2264 L2 / 2). With the help of Lemma 18, we know that as long as the inequality (37) is met, we have the desired suboptimality in f \u00b2 t (w \u00b2 t) \u2212 f \u00b2 t (w \u00b2 t)."}, {"heading": "D.3.3. PROOF OF THEOREM 16", "text": "Proof Firstly, it is easy to verify condition (37): b (\u03b3 + \u03b2) 2 = 256\u03b22 log (dm).Similar to Theorem 14, we need to consider the ratio between final and initial error for R AIDE iterations to be beratio = O (n (\u03b5).Equation of this ratio to be 800 (\u03b3 + \u03ba) \u03b3 (1 \u2212 910 270 \u03b3 + \u03ba) R + 1, we have the ratio between final and initial error for R AIDE iterations to beratio = O (n (\u03b5) \u00b7 1 ratio) = O (b1 / 4m1 / 2 \u00b7 \u03b21 / 2B1 / 2 n (\u03b5) 1 / 4 \u00b7 L1 / 2 log n (\u03b5).Now according to Lemma 19, the final sub-optimism for f, r (w) we need to have definitive behavior = 29 (1 \u2212 910) p \u00b2 of the condition."}, {"heading": "Appendix E. Experiments", "text": "In this section, we present empirical results to support our theoretical analysis of MP-DANE. We perform regression and classification of the smallest squares on several publicly available datasets; the statistics of these datasets and their losses are summarized in Table 3. For each dataset, we6. https: / / www.csie.ntu.edu.tw / \u02dc cjlin / libsvm / randomized, we select half of the samples for training, and the remaining samples are used for estimating the stochastic object. For MP-DANE, we use SAGA (Defazio et al., 2014) to solve each local DANE subproblem (33) and fix the number of SAGA steps after b (i.e., we only make one pass over the local data) while minimizing the number of DANE rounds K beyond {1, 2, 4, 8, 16}."}], "references": [{"title": "Incremental proximal methods for large scale convex optimization", "author": ["Dimitri P. Bertsekas"], "venue": "Mathematical programming,", "citeRegEx": "Bertsekas.,? \\Q2011\\E", "shortCiteRegEx": "Bertsekas.", "year": 2011}, {"title": "Incremental aggregated proximal and augmented Lagrangian algorithms", "author": ["Dimitri P. Bertsekas"], "venue": "[cs.SY], November", "citeRegEx": "Bertsekas.,? \\Q2015\\E", "shortCiteRegEx": "Bertsekas.", "year": 2015}, {"title": "Distributed optimization and statistical learning via the alternating direction method of multipliers", "author": ["Stephen Boyd", "Neal Parikh", "Eric Chu", "Borja Peleato", "Jonathan Eckstein"], "venue": "Foundations and Trends in Machine Learning,", "citeRegEx": "Boyd et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Boyd et al\\.", "year": 2011}, {"title": "Implicit online learning with kernels", "author": ["Li Cheng", "S.V.N. Vishwanathan", "Dale Schuurmans", "Shaojun Wang", "Terry Caelli"], "venue": "In Proceedings of the 19th International Conference on Neural Information Processing Systems,", "citeRegEx": "Cheng et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Cheng et al\\.", "year": 2006}, {"title": "Better mini-batch algorithms via accelerated gradient methods", "author": ["Andrew Cotter", "Ohad Shamir", "Nathan Srebro", "Karthik Sridharan"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Cotter et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Cotter et al\\.", "year": 2011}, {"title": "Online passive-aggressive algorithms", "author": ["Koby Crammer", "Ofer Dekel", "Joseph Keshet", "Shai Shalev-Shwartz", "Yoram Singer"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Crammer et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Crammer et al\\.", "year": 2006}, {"title": "A simple practical accelerated method for finite sums", "author": ["Aaron Defazio"], "venue": "In Advances In Neural Information Processing Systems,", "citeRegEx": "Defazio.,? \\Q2016\\E", "shortCiteRegEx": "Defazio.", "year": 2016}, {"title": "Saga: A fast incremental gradient method with support for non-strongly convex composite objectives", "author": ["Aaron Defazio", "Francis Bach", "Simon Lacoste-Julien"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Defazio et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Defazio et al\\.", "year": 2014}, {"title": "Optimal distributed online prediction using mini-batches", "author": ["Ofer Dekel", "Ran Gilad-Bachrach", "Ohad Shamir", "Lin Xiao"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Dekel et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Dekel et al\\.", "year": 2012}, {"title": "Accelerating stochastic gradient descent using predictive variance reduction", "author": ["Rie Johnson", "Tong Zhang"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Johnson and Zhang.,? \\Q2013\\E", "shortCiteRegEx": "Johnson and Zhang.", "year": 2013}, {"title": "Implicit online learning", "author": ["Brian Kulis", "Peter L. Bartlett"], "venue": "In Proceedings of the 27th International Conference on Machine Learning", "citeRegEx": "Kulis and Bartlett.,? \\Q2010\\E", "shortCiteRegEx": "Kulis and Bartlett.", "year": 2010}, {"title": "A simpler approach to obtaining an o(1/t) convergence rate for the projected stochastic subgradient method", "author": ["Simon Lacoste-Julien", "Mark Schmidt", "Francis Bach"], "venue": "[cs.LG],", "citeRegEx": "Lacoste.Julien et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Lacoste.Julien et al\\.", "year": 2012}, {"title": "Distributed stochastic variance reduced gradient methods and a lower bound for communication complexity", "author": ["Jason D Lee", "Qihang Lin", "Tengyu Ma", "Tianbao Yang"], "venue": "arXiv preprint arXiv:1507.07595,", "citeRegEx": "Lee et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lee et al\\.", "year": 2015}, {"title": "Efficient mini-batch training for stochastic optimization", "author": ["Mu Li", "Tong Zhang", "Yuqiang Chen", "Alexander J. Smola"], "venue": "In Proc. of the 20th ACM SIGKDD Int. Conf. Knowledge Discovery and Data Mining (SIGKDD", "citeRegEx": "Li et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Li et al\\.", "year": 2014}, {"title": "A universal catalyst for first-order optimization", "author": ["Hongzhou Lin", "Julien Mairal", "Zaid Harchaoui"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Lin et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lin et al\\.", "year": 2015}, {"title": "Paved with good intentions: Analysis of a randomized block kaczmarz method", "author": ["Deanna Needell", "Joel A. Tropp"], "venue": "Linear Algebra and its Applications,", "citeRegEx": "Needell and Tropp.,? \\Q2014\\E", "shortCiteRegEx": "Needell and Tropp.", "year": 2014}, {"title": "Problem complexity and method efficiency", "author": ["A. Nemirovskii", "D.B. Yudin"], "venue": "in optimization,", "citeRegEx": "Nemirovskii and Yudin.,? \\Q1983\\E", "shortCiteRegEx": "Nemirovskii and Yudin.", "year": 1983}, {"title": "Aide: Fast and communication efficient distributed optimization", "author": ["Sashank J Reddi", "Jakub Kone\u010dn\u1ef3", "Peter Richt\u00e1rik", "Barnab\u00e1s P\u00f3cz\u00f3s", "Alex Smola"], "venue": "arXiv preprint arXiv:1608.06879,", "citeRegEx": "Reddi et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Reddi et al\\.", "year": 2016}, {"title": "Convergence rates of inexact proximal-gradient methods for convex optimization", "author": ["Mark Schmidt", "Nicolas Le Roux", "Francis Bach"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Schmidt et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Schmidt et al\\.", "year": 2011}, {"title": "Stochastic convex optimization", "author": ["Shai Shalev-Shwartz", "Ohad Shamir", "Nathan Srebro", "Karthik Sridharan"], "venue": "In Proc. of the 22th Annual Conference on Learning Theory (COLT\u201909),", "citeRegEx": "Shalev.Shwartz et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Shalev.Shwartz et al\\.", "year": 2009}, {"title": "Without-replacement sampling for stochastic gradient methods: Convergence results and application to distributed optimization", "author": ["Ohad Shamir"], "venue": "arXiv preprint arXiv:1603.00570,", "citeRegEx": "Shamir.,? \\Q2016\\E", "shortCiteRegEx": "Shamir.", "year": 2016}, {"title": "Distributed stochastic optimization and learning", "author": ["Ohad Shamir", "Nathan Srebro"], "venue": "In 52nd Annual Allerton Conference on Communication, Control, and Computing (Allerton),", "citeRegEx": "Shamir and Srebro.,? \\Q2014\\E", "shortCiteRegEx": "Shamir and Srebro.", "year": 2014}, {"title": "Communication-efficient distributed optimization using an approximate Newton-type method", "author": ["Ohad Shamir", "Nathan Srebro", "Tong Zhang"], "venue": "In Proc. of the 31st Int. Conf. Machine Learning (ICML", "citeRegEx": "Shamir et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Shamir et al\\.", "year": 2014}, {"title": "Analysis of MP-DANE In order to fully analyze Algorithm 2, we need several auxiliary lemmas that characterize the iteration complexity of solving the local problem (33) by prox-SVRG (Xiao and Zhang, 2014), the large minibatch problem (12) by DANE (Shamir et al., 2014) and AIDE (Reddi", "author": ["memory. D"], "venue": null, "citeRegEx": "D.3.,? \\Q2016\\E", "shortCiteRegEx": "D.3.", "year": 2016}], "referenceMentions": [{"referenceID": 16, "context": "Introduction Consider the stochastic convex optimization (generalized learning) problem (Nemirovskii and Yudin, 1983; Vapnik, 1995; Shalev-Shwartz et al., 2009):", "startOffset": 88, "endOffset": 160}, {"referenceID": 19, "context": "Introduction Consider the stochastic convex optimization (generalized learning) problem (Nemirovskii and Yudin, 1983; Vapnik, 1995; Shalev-Shwartz et al., 2009):", "startOffset": 88, "endOffset": 160}, {"referenceID": 4, "context": "One simple approach for distributed stochastic optimization is minibatch SGD (Cotter et al., 2011; Dekel et al., 2012), where in each update we use a gradient estimate based on mb examples: b examples from each of the m machines.", "startOffset": 77, "endOffset": 118}, {"referenceID": 8, "context": "One simple approach for distributed stochastic optimization is minibatch SGD (Cotter et al., 2011; Dekel et al., 2012), where in each update we use a gradient estimate based on mb examples: b examples from each of the m machines.", "startOffset": 77, "endOffset": 118}, {"referenceID": 2, "context": "A naive approach here is to use accelerate gradient descent, distributing the gradient computations, but this, as well as approaches based on ADMM (Boyd et al., 2011), are dominated by minibatch SGD (Shamir and Srebro 2014 and see also Table 1).", "startOffset": 147, "endOffset": 166}, {"referenceID": 22, "context": "Better alternatives take advantage of the stochastic nature of the problem: DANE (Shamir et al., 2014) requires only O(B2m) rounds of communication for squared loss problems, while DiSCO (Zhang and Lin, 2015) and AIDE (Reddi et al.", "startOffset": 81, "endOffset": 102}, {"referenceID": 17, "context": ", 2014) requires only O(B2m) rounds of communication for squared loss problems, while DiSCO (Zhang and Lin, 2015) and AIDE (Reddi et al., 2016)) reduce this further to O(B1/2m1/4) rounds of communication.", "startOffset": 123, "endOffset": 143}, {"referenceID": 3, "context": "One simple approach for distributed stochastic optimization is minibatch SGD (Cotter et al., 2011; Dekel et al., 2012), where in each update we use a gradient estimate based on mb examples: b examples from each of the m machines. Distributed minibatch SGD attains optimal statistical performance with O (n(\u03b5)/m) runtime, as long as the minibatch size is not too large: Dekel et al. (2012) showed that the minibatch size can be as large as bm = O( \u221a n(\u03b5)), and Cotter et al.", "startOffset": 78, "endOffset": 389}, {"referenceID": 3, "context": "One simple approach for distributed stochastic optimization is minibatch SGD (Cotter et al., 2011; Dekel et al., 2012), where in each update we use a gradient estimate based on mb examples: b examples from each of the m machines. Distributed minibatch SGD attains optimal statistical performance with O (n(\u03b5)/m) runtime, as long as the minibatch size is not too large: Dekel et al. (2012) showed that the minibatch size can be as large as bm = O( \u221a n(\u03b5)), and Cotter et al. (2011) showed that with acceleration this can be increased to bm = O(n(\u03b5)3/4).", "startOffset": 78, "endOffset": 481}, {"referenceID": 5, "context": "This can be viewed as a minibatch generalization to the passive-aggressive algorithm (Crammer et al., 2006) and has been considered in various contexts (Kulis and Bartlett, 2010; Toulis and Airoldi, 2014).", "startOffset": 85, "endOffset": 107}, {"referenceID": 10, "context": ", 2006) and has been considered in various contexts (Kulis and Bartlett, 2010; Toulis and Airoldi, 2014).", "startOffset": 52, "endOffset": 104}, {"referenceID": 5, "context": "This can be viewed as a minibatch generalization to the passive-aggressive algorithm (Crammer et al., 2006) and has been considered in various contexts (Kulis and Bartlett, 2010; Toulis and Airoldi, 2014). We show that such an approach achieves the optimal statistical rate in terms of the number of samples used independent of the number of iterations, i.e. with anyminibatch size. This significantly improves over the previous analysis of Li et al. (2014), as the guarantee is better, it entirely avoid the dependence on the minibatch size and does not rely on additional assumptions as in Li et al.", "startOffset": 86, "endOffset": 458}, {"referenceID": 5, "context": "This can be viewed as a minibatch generalization to the passive-aggressive algorithm (Crammer et al., 2006) and has been considered in various contexts (Kulis and Bartlett, 2010; Toulis and Airoldi, 2014). We show that such an approach achieves the optimal statistical rate in terms of the number of samples used independent of the number of iterations, i.e. with anyminibatch size. This significantly improves over the previous analysis of Li et al. (2014), as the guarantee is better, it entirely avoid the dependence on the minibatch size and does not rely on additional assumptions as in Li et al. (2014). The guarantee holds for any Lipschitz (even non-smooth) objective.", "startOffset": 86, "endOffset": 609}, {"referenceID": 12, "context": "Distributed SVRG for stochastic convex optimization Recently, Lee et al. (2015) suggested using fast randomized optimization algorithms for finite-sums, and in particular the SVRG algorithm, as a distributed optimization approach for (2).", "startOffset": 62, "endOffset": 80}, {"referenceID": 12, "context": "Distributed SVRG for stochastic convex optimization Recently, Lee et al. (2015) suggested using fast randomized optimization algorithms for finite-sums, and in particular the SVRG algorithm, as a distributed optimization approach for (2). The authors noted that, for SVRG, when the the sample size n(\u03b5) dominates the problem\u2019s condition number \u03b2/\u03bd where \u03b2 is the smoothness parameter of l(w, \u03be), the time complexity is dominated by computing the batch gradients. This operation can be trivially parallelized. The stochastic updates, on the other hand, can be implemented on a single machine while the other machines wait, with the only caveat being that only sampling-without-replacement can be implemented this way. The use of without-replacement sampling was theoretically justified in a recent analysis by Shamir (2016).", "startOffset": 62, "endOffset": 823}, {"referenceID": 3, "context": "More general loss functions, still for \u201cbatch sizes\u201d of one, were also analyzed in the online learning setting (Cheng et al., 2006; Kulis and Bartlett, 2010).", "startOffset": 111, "endOffset": 157}, {"referenceID": 10, "context": "More general loss functions, still for \u201cbatch sizes\u201d of one, were also analyzed in the online learning setting (Cheng et al., 2006; Kulis and Bartlett, 2010).", "startOffset": 111, "endOffset": 157}, {"referenceID": 2, "context": "Crammer et al. (2006) proposed the \u201cpassive aggressive\u201d update rule, where a margin-based loss from a single example with a quadratic penalty is minimized\u2014this corresponds to (3) with a \u201cbatch size\u201d of one.", "startOffset": 0, "endOffset": 22}, {"referenceID": 0, "context": "For finite-sum objectives, methods based on incremental/stochastic proximal updates were studied by Bertsekas (2011, 2015); Defazio (2016). Needell and Tropp (2014) analyzed a randomized block Kaczmarz method in the context of solving linear systems, which also minimizes the empirical loss on a randomly sampled minibatch.", "startOffset": 100, "endOffset": 139}, {"referenceID": 0, "context": "For finite-sum objectives, methods based on incremental/stochastic proximal updates were studied by Bertsekas (2011, 2015); Defazio (2016). Needell and Tropp (2014) analyzed a randomized block Kaczmarz method in the context of solving linear systems, which also minimizes the empirical loss on a randomly sampled minibatch.", "startOffset": 100, "endOffset": 165}, {"referenceID": 0, "context": "For finite-sum objectives, methods based on incremental/stochastic proximal updates were studied by Bertsekas (2011, 2015); Defazio (2016). Needell and Tropp (2014) analyzed a randomized block Kaczmarz method in the context of solving linear systems, which also minimizes the empirical loss on a randomly sampled minibatch. To the best of our knowledge, no prior work has analyzed the general minibatch variant of proximal updates for stochastic optimization except Li et al. (2014). However, the analysis of Li et al.", "startOffset": 100, "endOffset": 483}, {"referenceID": 0, "context": "For finite-sum objectives, methods based on incremental/stochastic proximal updates were studied by Bertsekas (2011, 2015); Defazio (2016). Needell and Tropp (2014) analyzed a randomized block Kaczmarz method in the context of solving linear systems, which also minimizes the empirical loss on a randomly sampled minibatch. To the best of our knowledge, no prior work has analyzed the general minibatch variant of proximal updates for stochastic optimization except Li et al. (2014). However, the analysis of Li et al. (2014) assumes a stringent condition which is hard to verify (and is often violated) in practice, which we will discuss in detail in this section.", "startOffset": 100, "endOffset": 526}, {"referenceID": 0, "context": "For finite-sum objectives, methods based on incremental/stochastic proximal updates were studied by Bertsekas (2011, 2015); Defazio (2016). Needell and Tropp (2014) analyzed a randomized block Kaczmarz method in the context of solving linear systems, which also minimizes the empirical loss on a randomly sampled minibatch. To the best of our knowledge, no prior work has analyzed the general minibatch variant of proximal updates for stochastic optimization except Li et al. (2014). However, the analysis of Li et al. (2014) assumes a stringent condition which is hard to verify (and is often violated) in practice, which we will discuss in detail in this section. The following lemma provides the basic property of the update at each iteration. Lemma 1 For any w \u2208 \u03a9, we have \u03bb+ \u03b3t \u03b3t \u2016wt \u2212w\u2016 \u2264 \u2016wt\u22121 \u2212w\u2016 \u2212 \u2016wt\u22121 \u2212wt\u2016 \u2212 2 \u03b3t (\u03c6It(wt)\u2212 \u03c6It(w)) . (6) To derive the convergence guarantee, we need to relate \u03c6It(wt) to \u03c6(w). The analysis of Li et al. (2014) for minibatch-prox made the assumption that for all t \u2265 1: EIt [D\u03c6(wt;wt\u22121)] \u2264 EIt [ D\u03c6It (wt;wt\u22121) ] + \u03b3t 2 \u2016wt \u2212wt\u22121\u2016 , (7)", "startOffset": 100, "endOffset": 956}, {"referenceID": 13, "context": "However, to obtain the optimal convergence rate, Li et al. (2014) needed to set \u03b3t = O( \u221a T/b) which would imply b = O(T ) in order to have \u03b3t \u2265 \u03b2.", "startOffset": 49, "endOffset": 66}, {"referenceID": 13, "context": "However, to obtain the optimal convergence rate, Li et al. (2014) needed to set \u03b3t = O( \u221a T/b) which would imply b = O(T ) in order to have \u03b3t \u2265 \u03b2. In view of this implicit constraint that the minibatch size b can not be too large, the analysis of Li et al. (2014) does not really show advantage of minibatch-prox over minibatch SGD, whose optimal minibatch size is precisely b = O(T ).", "startOffset": 49, "endOffset": 265}, {"referenceID": 19, "context": "Using a stability argument (Shalev-Shwartz et al., 2009), we can establish the \u201cgeneralization\u201d performance for the (inexact) minimizer of the minibatch objective.", "startOffset": 27, "endOffset": 56}, {"referenceID": 13, "context": "In Li et al. (2014), the authors proposed a simple algorithm EMSO to approximately solve (12), where each machine first solve its own local objective, i.", "startOffset": 3, "endOffset": 20}, {"referenceID": 12, "context": "Here we instead use the distributed SVRG (DSVRG) algorithm (Lee et al., 2015; Shamir, 2016) to approximately solve (12), as DSVRG enjoys excellent communication and computation cost when the problem is well conditioned (cf.", "startOffset": 59, "endOffset": 91}, {"referenceID": 20, "context": "Here we instead use the distributed SVRG (DSVRG) algorithm (Lee et al., 2015; Shamir, 2016) to approximately solve (12), as DSVRG enjoys excellent communication and computation cost when the problem is well conditioned (cf.", "startOffset": 59, "endOffset": 91}, {"referenceID": 12, "context": "Although this approach was shown to work well empirically, no convergence guarantee for the original stochastic objective (1) was provided by Li et al. (2014). Here we instead use the distributed SVRG (DSVRG) algorithm (Lee et al.", "startOffset": 142, "endOffset": 159}, {"referenceID": 4, "context": "Figure 2: Illustration of theoretical guarantees for MP-DSVRG and the comparison with accelerated minibatch SGD (Cotter et al., 2011), DiSCO (Zhang and Lin, 2015), AIDE (Reddi et al.", "startOffset": 112, "endOffset": 133}, {"referenceID": 17, "context": ", 2011), DiSCO (Zhang and Lin, 2015), AIDE (Reddi et al., 2016), DSVRG (Lee et al.", "startOffset": 43, "endOffset": 63}, {"referenceID": 12, "context": ", 2016), DSVRG (Lee et al., 2015), and MP-DANE (proposed and analyzed in Appendix D).", "startOffset": 15, "endOffset": 33}, {"referenceID": 11, "context": "This choice is inspired by the stepsize rule of Lacoste-Julien et al. (2012) for stochastic gradient descent.", "startOffset": 48, "endOffset": 77}, {"referenceID": 18, "context": "To resolve the recursion, we need the following lemma by Schmidt et al. (2011).", "startOffset": 57, "endOffset": 79}, {"referenceID": 4, "context": "Following Cotter et al. (2011), we assume that l(w, \u03be) is \u03b2-smooth: \u2225\u2207l(w, \u03be)\u2212\u2207l(w\u2032, \u03be) \u2225\u2225 \u2264 \u03b2 \u2225w \u2212w\u2032 \u2225\u2225 , \u2200w,w\u2032 \u2208 \u03a9.", "startOffset": 10, "endOffset": 31}, {"referenceID": 4, "context": "Proof Our proof closely follows that of Cotter et al. (2011). Due to the smoothness of \u03c6, we have that \u03c6(w\u0303t) \u2264 \u03c6(w\u0303t\u22121) + \u3008\u2207\u03c6(w\u0303t\u22121), w\u0303t \u2212 w\u0303t\u22121\u3009+ \u03b2 2 \u2016w\u0303t \u2212 w\u0303t\u22121\u2016 \u2264 \u03c6(w\u0303t\u22121) + \u3008\u2207\u03c6(w\u0303t\u22121)\u2212\u2207\u03c6It(w\u0303t\u22121), w\u0303t \u2212 w\u0303t\u22121\u3009+ \u03b2 2 \u2016w\u0303t \u2212 w\u0303t\u22121\u2016 + \u3008\u2207\u03c6It(w\u0303t\u22121), w\u0303t \u2212 w\u0303t\u22121\u3009 = \u03c6(w\u0303t\u22121) + \u2016\u2207\u03c6(w\u0303t\u22121)\u2212\u2207\u03c6It(w\u0303t\u22121)\u2016 \u00b7 \u2016w\u0303t \u2212 w\u0303t\u22121\u2016+ \u03b2 2 \u2016w\u0303t \u2212 w\u0303t\u22121\u2016 + \u3008\u2207\u03c6It(w\u0303t\u22121), w\u0303t \u2212 w\u0303t\u22121\u3009 \u2264 \u03c6(w\u0303t\u22121) + 1 2(\u03b3t \u2212 \u03b2) \u2016\u2207\u03c6(w\u0303t\u22121)\u2212\u2207\u03c6It(w\u0303t\u22121)\u2016 + \u03b3t \u2212 \u03b2 2 \u2016w\u0303t \u2212 w\u0303t\u22121\u2016", "startOffset": 40, "endOffset": 61}, {"referenceID": 22, "context": "Here we present a novel method that use the distributed optimization algorithm DANE (Shamir et al., 2014) and its accelerated variant AIDE (Reddi et al.", "startOffset": 84, "endOffset": 105}, {"referenceID": 17, "context": ", 2014) and its accelerated variant AIDE (Reddi et al., 2016) for solving (12), which define better local objectives than EMSO and take into consideration the similarity between local objectives.", "startOffset": 41, "endOffset": 61}, {"referenceID": 14, "context": "On top of that, AIDE uses the idea of universal catalyst (Lin et al., 2015) and adds an extra quadratic term to improve the strong-convexity of the objective for faster convergence, i.", "startOffset": 57, "endOffset": 75}, {"referenceID": 17, "context": "Second, we only approximately solve the local subproblems (33) to sufficient accuracy in each inner loop; the analysis of \u201cinexact DANE\u201d (for the non-stochastic setting) provides guarantee for this approach (Reddi et al., 2016), and enables us to use state-of-the-art SGD methods (e.", "startOffset": 207, "endOffset": 227}, {"referenceID": 22, "context": "Analysis of MP-DANE In order to fully analyze Algorithm 2, we need several auxiliary lemmas that characterize the iteration complexity of solving the local problem (33) by prox-SVRG (Xiao and Zhang, 2014), the large minibatch problem (12) by DANE (Shamir et al., 2014) and AIDE (Reddi et al.", "startOffset": 247, "endOffset": 268}, {"referenceID": 17, "context": ", 2014) and AIDE (Reddi et al., 2016).", "startOffset": 17, "endOffset": 37}, {"referenceID": 7, "context": "The benefit of this approach (as opposed to using plain SVRG Johnson and Zhang, 2013) is that the smoothness parameter that determines the iteration complexity is simply \u03b2, same results hold when applying prox-SAGA (Defazio et al., 2014) as well.", "startOffset": 215, "endOffset": 237}, {"referenceID": 20, "context": "For sampling without replacement SVRG, the current analysis works only for plain SVRG, so we quote the results from (Shamir, 2016).", "startOffset": 116, "endOffset": 130}, {"referenceID": 17, "context": "Next, we state the convergence rates of \u201cinexact DANE\u201d and AIDE, which can be easily derived from Reddi et al. (2016). At the outer loop t and intermediate loop r, let xr = argminw f\u0304t,r(w) be the exact minimizer of the \u201caugmented large minibatch\u201d problem (36), which is approximately solved by the inner DANE iterations.", "startOffset": 98, "endOffset": 118}, {"referenceID": 14, "context": "1 of Lin et al. (2015)) Assume that for all r \u2265 1, we have f\u0304t,r(xr)\u2212 f\u0304t,r(xr) \u2264 2 9 ( 1\u2212 9 10 \u221a \u03b3 \u03b3 + \u03ba )R \u00b7 ( f\u0303t(x0)\u2212 f\u0303t(w t ) ) ,", "startOffset": 5, "endOffset": 23}, {"referenceID": 7, "context": "For MP-DANE, we use SAGA (Defazio et al., 2014) to solve each local DANE subproblem (33) and fix the number of SAGA steps to b (i.", "startOffset": 25, "endOffset": 47}], "year": 2017, "abstractText": "We present and analyze an approach for distributed stochastic optimization which is statistically optimal and achieves near-linear speedups (up to logarithmic factors). Our approach allows a communication-memory tradeoff, with either logarithmic communication but linear memory, or polynomial communication and a corresponding polynomial reduction in required memory. This communication-memory tradeoff is achieved throughminibatch-prox iterations (minibatch passiveaggressive updates), where a subproblem on a minibatch is solved at each iteration. We provide a novel analysis for such a minibatch-prox procedure which achieves the statistical optimal rate regardless of minibatch size and smoothness, thus significantly improving on prior work.", "creator": "LaTeX with hyperref package"}}}