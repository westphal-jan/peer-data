{"id": "1702.06696", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Feb-2017", "title": "One Representation per Word - Does it make Sense for Composition?", "abstract": "In this paper, we investigate whether an a priori disambiguation of word senses is strictly necessary or whether the meaning of a word in context can be disambiguated through composition alone. We evaluate the performance of off-the-shelf single-vector and multi-sense vector models on a benchmark phrase similarity task and a novel task for word-sense discrimination. We find that single-sense vector models perform as well or better than multi-sense vector models despite arguably less clean elementary representations. Our findings furthermore show that simple composition functions such as pointwise addition are able to recover sense specific information from a single-sense vector model remarkably well.", "histories": [["v1", "Wed, 22 Feb 2017 07:41:08 GMT  (363kb,D)", "http://arxiv.org/abs/1702.06696v1", "to appear at the EACL 2017 workshop on Sense, Concept and Entity Representations and their Applications"]], "COMMENTS": "to appear at the EACL 2017 workshop on Sense, Concept and Entity Representations and their Applications", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["thomas kober", "julie weeds", "john wilkie", "jeremy reffin", "david weir"], "accepted": false, "id": "1702.06696"}, "pdf": {"name": "1702.06696.pdf", "metadata": {"source": "CRF", "title": "One Representation per Word \u2014 Does it make Sense for Composition?", "authors": ["Thomas Kober", "Julie Weeds", "John Wilkie", "Jeremy Reffin", "David Weir"], "emails": ["d.j.weir}@sussex.ac.uk"], "sections": [{"heading": "1 Introduction", "text": "In fact, it is that most of us are able to outdo ourselves, and that they do so. (...) Most of us have not managed to outlive ourselves. (...) Most of us have not been able to outlive ourselves. (...) Most of us have not been able to outlive ourselves. (...) Most of us have been able to outlive ourselves. (...) Most of us have not been able to outlive ourselves. (...) \"(...) Most of us have been able to outlive ourselves. (...)\" (...) Most of us have been able to outlive ourselves. (...) \"(...) Most of us have been able to outlive ourselves.\" (...) \"Most of us have been able to outlive ourselves.\" (...) \"(...\" Most of us have been able to outlive ourselves. \"(...).\" (...). \"We have done it.\" (...). \"We have done it. (...\" (...). \"We have done it.\" (... \"We have done it.\" (...). (... \"We have done it. (...).\" We have done it. \"(...\" We have done it. (...). \"We have done it. (...\"). (... \"We have done it. (...).\" We have done it. (... \"We have. (...).\" We have done it. (.). \"We have done it. (...\" We have done. (.). \"We have done. (. (.).). ().\" We have done it. \"We have done. (. (.).\" We have done it. (. \"). ().\" We have done it. (. (.). (). (). \"We have done. (. (.). (. (). (). (.).\" We have done it. (. (.). (.). (. (). (. (.). (. (). (. (.) We have succeeded. (.). (. (.). (.). (.). (.). (. (.). (. (. (.). (.). (. (. ("}, {"heading": "2 Evaluating Distributional Models of Composition", "text": "For the evaluation, we use several readily available off-the-shelf word embeddings that have already proven to be good for a number of different NLP applications. We compare the 300-dimensional word embedding vocabulary word2vec (Mikolov et al., 2013) with the dependency-based version of word2vec - henceforth dep2vec3 (Levy and Goldberg, 2014) - and the1Our task is available at https: / / github.com / tttthomasssss / sense2017Available from: https: / / code.google.com / p / word2vec / 3Available from: https: / / levyomer. wordpress.com / 2014 / 04 / 25 / dependency-based word-embeddings / SENSEMBED model4 by Iacobacci et al."}, {"heading": "3 Phrase Similarity", "text": "Our first evaluation task is the similarity of the phrases Mitchell and Lapata (2010).This data set consists of 108 adjective-noun pairs (AN), 108 noun-noun pairs (NN), and 108 verb-object pairs (VO).The task is to compare the similarity of a compositional model with human judgments by calculating Spearman's determinations.An average of 0.47-0.48 represents the current state of the art in this task (Hashimoto et al., 2014; Kober et al., 2016; Wieting et al., 2015).For single-meaning representations, the strategy for performing this task is simple. For each phrase in each pair, we assemble the constituent representations and then calculate the similarity of each phrase pair using cosmic similarity. For multi-meaning representations, we have adjusted the strategy successfully used in different word similarities to the configuration."}, {"heading": "3.1 Results", "text": "Table 1 shows that the simple strategy of adding high-quality single vector representations is very competitive with the state of the art for this task. None of the strategies for selecting a sense configuration for multi-sense representations could compete with the single sense representations for this task. One possible explanation is that the commonly used strategy of narrowest sense for composition is not effective, as the composition of wrong senses (for two \"implausible\" sense configurations) can lead to flimsy similarities. Table 2 lists a number of example sentences with low averages of human similarity in the Mitchell and Lapata (2010) test theorem. Results show the tendency of the narrowest sense strategy with SENSEMBED (SE) to overestimate the similarity of unequal sentence pairs. To make a comparison, we manually label the lexems in the samples with the corresponding BabelNet senses before composition (SE *)."}, {"heading": "4 Word Sense Discrimination", "text": "This year, it will be able to establish itself in the region in order to pave the way to the region."}, {"heading": "4.1 Task Construction", "text": "For the construction of our dataset, we used data from two English dictionaries (Oxford Dictionary and Collins Dictionary) accessible through their respective Web APIs6, as well as examples from the annotated corpus SemCor (Miller et al., 1993). Our use of dictionary data is motivated by a number of advantageous properties that make it a very suitable data source for our proposed task: \u2022 The content is of very high quality and is curated by expert lexicographers. \u2022 All sample sentences are carefully crafted to illustrate the frequency of use 6https: / / developoper. oxforddictionaries.com for the Oxford Dictionary, https: / / www.collinsdictionary.com / api / for the Collins Dictionary. \u2022 We use NLTK 3.2 to access SemCor.of a specific sense for a particular polysemous lexem. \u2022 The granularity of the meaning resource typically mirrors the web language ary.7 Examples are arbitrary."}, {"heading": "4.2 Task Setup Details", "text": "We collected data for 3 different parts of the speech: adjectives, nouns and verbs. In addition, we created tasks with a different number of senses to distinguish (2-5 senses) for a particular target lexeme, which means assessing how well a model is able to distinguish different degrees of polysemy in a lexeme. For each task that is evaluated for n senses, we included all lexems with > n senses and randomly sampled n senses from its inventory. For each lexeme, we also ensured that it had at least 2 example sentences per sense. For the available senses of a given lexeme, we randomly selected one sense as the target meaning and 2 sentences from its list of example sentences, one as the target example and one as the \"right answer\" for the list of candidate sets. Finally, we again randomly evaluated the required number of other sensory perceptions and example sentences to complete the task."}, {"heading": "4.3 Experimental Setup", "text": "In this thesis, we compared the previously outlined compositional contexts with two baselines, a random baseline and a word-overlap baseline of the extracted contexts. For each vector representation, we composed the target lexeme with all the words in the context window and compared it with the equivalent representation of each of the options (lexem plus context words). The option with the highest cosine resemblance was considered to be the chosen sense. For SENSEMBED, we combined all the meaning vectors of a target lexeme with the given context and then used the narrowest meaning strategy (Iacobacci et al., 2015) in composed representations to select the predicted senses. The Wordoverlap baseline is simply the number of words common between the context window for the target and each of the options. We experimented with symmetrical linear word contexts of size 1, 2 and 4 around the target lexeme."}, {"heading": "4.4 Results", "text": "Table 5 shows the results for all context window sizes across all speech parts and the number of senses. All models essentially exceed the random baseline for each number of senses. Interestingly, the word overlap baseline is competitive for all context window sizes. Although it is a very simple method, it has already been found to be a strong baseline for detecting paraphrases and semantic textual similarity (Dinu and Thater, 2012). One possible explanation for its robust performance on our task is an appearance of the one sense per collocation hypothesis (Yarowsky, 1993). The performance of all other models is roughly in the same ballpark for all speech parts and number of senses, suggesting that they form robust baselines for future models. While the results for adjectives are relatively mixed, word2vec appears to be the strongest model for polysemic nouns and verbs."}, {"heading": "5 Discussion", "text": "Our results suggest that meaningful supplementation in a one-sense vector model such as word2vec is able to distinguish the meaning of an ambiguous lexeme in context in a surprisingly effective way and provides a strong basis for future work. Distributional composition can therefore be interpreted as a process of contextualizing the meaning of a lexeme. Thus, the composition acts not only as a way to represent the meaning of a sentence as a whole, but also as a local discriminator for all lexems in the formulation. For example, the composed representation of dry clothing should only maintain contexts that associate dry stocks with clothing while suppressing contexts that it shares with weather or wine. Therefore, one would expect the same to happen with an ambiguous lexeme such as bank in the context of flow and context."}, {"heading": "6 Related Work", "text": "Most of them can be found in a particular context, in which they have to fill in a suitable word for a particular term."}, {"heading": "7 Conclusion", "text": "While elementary multisense representations of words could capture a finer-grained semantic picture of a multi-layered word, this advantage does not appear to be easily transferable to the distribution composition. Our experiments with a popular phrase similarity benchmark and our novel word-sense-discrimination task have shown that semantic composition does not appear to benefit from a fine-grained sense inventory, but that the ability to contextualize a multi-layered lexeme in one-sense vector models is sufficient for superior performance. Furthermore, we have provided qualitative and quantitative evidence that an intersectional composition function such as point-11, for example, is sufficient for the average standard deviation of human scores in the SCWS dataset on a 10-point scale and can be as high as 4-5 in some cases."}, {"heading": "Acknowledgments", "text": "We would like to thank our anonymous reviewers for their helpful comments."}], "references": [{"title": "Semeval-2007 task 02: Evaluating word sense induction and discrimination systems", "author": ["Eneko Agirre", "Aitor Soroa"], "venue": "In Proceedings of SemEval,", "citeRegEx": "Agirre and Soroa.,? \\Q2007\\E", "shortCiteRegEx": "Agirre and Soroa.", "year": 2007}, {"title": "Semeval-2016 task 1: Semantic textual similarity, monolingual and cross-lingual evaluation", "author": ["Eneko Agirre", "Carmen Banea", "Daniel Cer", "Mona Diab", "Aitor Gonzalez-Agirre", "Rada Mihalcea", "German Rigau", "Janyce Wiebe"], "venue": null, "citeRegEx": "Agirre et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Agirre et al\\.", "year": 2016}, {"title": "Utilizing semantic composition in distributional semantic models for word sense discrimination and word sense disambiguation", "author": ["Cem Akkaya", "Janyce Wiebe", "Rada Mihalcea"], "venue": "In Proceedings of ICSC,", "citeRegEx": "Akkaya et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Akkaya et al\\.", "year": 2012}, {"title": "An enhanced lesk word sense disambiguation algorithm through a distributional semantic model", "author": ["Pierpaolo Basile", "Annalina Caputo", "Giovanni Semeraro"], "venue": "In Proceedings of Coling,", "citeRegEx": "Basile et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Basile et al\\.", "year": 2014}, {"title": "A critique of word similarity as a method of evaluating distributional semantic models", "author": ["Miroslav Batchkarov", "Thomas Kober", "Jeremy Reffin", "Julie Weeds", "David Weir"], "venue": "In Proceedings of the 1st Workshop on Evaluating Vector-Space Representa-", "citeRegEx": "Batchkarov et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Batchkarov et al\\.", "year": 2016}, {"title": "A relatedness benchmark to test the role of determiners in compositional distributional semantics", "author": ["Raffaella Bernardi", "Georgiana Dinu", "Marco Marelli", "Marco Baroni"], "venue": "In Proceedings of ACL,", "citeRegEx": "Bernardi et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bernardi et al\\.", "year": 2013}, {"title": "A unified model for word sense representation and disambiguation", "author": ["Xinxiong Chen", "Zhiyuan Liu", "Maosong Sun"], "venue": "In Proceedings of EMNLP,", "citeRegEx": "Chen et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2014}, {"title": "Measuring distributional similarity in context", "author": ["Georgiana Dinu", "Mirella Lapata"], "venue": "In Proceedings of EMNLP,", "citeRegEx": "Dinu and Lapata.,? \\Q2010\\E", "shortCiteRegEx": "Dinu and Lapata.", "year": 2010}, {"title": "Saarland: Vector-based models of semantic textual similarity", "author": ["Georgiana Dinu", "Stefan Thater"], "venue": "In Proceedings of *SEM/SemEval,", "citeRegEx": "Dinu and Thater.,? \\Q2012\\E", "shortCiteRegEx": "Dinu and Thater.", "year": 2012}, {"title": "An Introduction to the Bootstrap", "author": ["Bradley Efron", "Robert Tibshirani"], "venue": "CRC press", "citeRegEx": "Efron and Tibshirani.,? \\Q1994\\E", "shortCiteRegEx": "Efron and Tibshirani.", "year": 1994}, {"title": "Investigations on word senses and word usages", "author": ["Katrin Erk", "Diana McCarthy", "Nicholas Gaylord"], "venue": "In Proceedings of ACL/AFNLP,", "citeRegEx": "Erk et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Erk et al\\.", "year": 2009}, {"title": "Experimental support for a categorical compositional distributional model of meaning", "author": ["Edward Grefenstette", "Mehrnoosh Sadrzadeh"], "venue": "In Proceedings of EMNLP,", "citeRegEx": "Grefenstette and Sadrzadeh.,? \\Q2011\\E", "shortCiteRegEx": "Grefenstette and Sadrzadeh.", "year": 2011}, {"title": "Jointly learning word representations and composition functions using predicate-argument structures", "author": ["Kazuma Hashimoto", "Pontus Stenetorp", "Makoto Miwa", "Yoshimasa Tsuruoka"], "venue": "In Proceedings of EMNLP,", "citeRegEx": "Hashimoto et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hashimoto et al\\.", "year": 2014}, {"title": "Learning to understand phrases by embedding the dictionary", "author": ["Felix Hill", "KyungHyun Cho", "Anna Korhonen", "Yoshua Bengio"], "venue": null, "citeRegEx": "Hill et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Hill et al\\.", "year": 2016}, {"title": "Improving word representations via global context and multiple word prototypes", "author": ["Eric Huang", "Richard Socher", "Christopher Manning", "Andrew Ng"], "venue": "In Proceedings of ACL,", "citeRegEx": "Huang et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Huang et al\\.", "year": 2012}, {"title": "Sensembed: Learning sense embeddings for word and relational similarity", "author": ["Ignacio Iacobacci", "Mohammad Taher Pilehvar", "Roberto Navigli"], "venue": "In Proceedings of ACL,", "citeRegEx": "Iacobacci et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Iacobacci et al\\.", "year": 2015}, {"title": "Embeddings for word sense disambiguation: An evaluation study", "author": ["Ignacio Iacobacci", "Mohammad Taher Pilehvar", "Roberto Navigli"], "venue": "In Proceedings of ACL,", "citeRegEx": "Iacobacci et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Iacobacci et al\\.", "year": 2016}, {"title": "A study of entanglement in a categorical framework of natural language", "author": ["Dimitri Kartsaklis", "Mehrnoosh Sadrzadeh"], "venue": "In Proceedings of the 11th Workshop on Quantum Physics and Logic (QPL)", "citeRegEx": "Kartsaklis and Sadrzadeh.,? \\Q2014\\E", "shortCiteRegEx": "Kartsaklis and Sadrzadeh.", "year": 2014}, {"title": "A unified sentence space for categorical distributional-compositional semantics: Theory and experiments", "author": ["Dimitri Kartsaklis", "Mehrnoosh Sadrzadeh", "Stephen Pulman"], "venue": "In Proceedings of Coling,", "citeRegEx": "Kartsaklis et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Kartsaklis et al\\.", "year": 2012}, {"title": "Separating disambiguation from composition in distributional semantics", "author": ["Dimitri Kartsaklis", "Mehrnoosh Sadrzadeh", "Stephen Pulman"], "venue": "In Proceedings of CoNLL,", "citeRegEx": "Kartsaklis et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Kartsaklis et al\\.", "year": 2013}, {"title": "Improving sparse word representations with distributional inference for semantic composition", "author": ["Thomas Kober", "Julie Weeds", "Jeremy Reffin", "David Weir"], "venue": "In Proceedings of EMNLP,", "citeRegEx": "Kober et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Kober et al\\.", "year": 2016}, {"title": "Dependencybased word embeddings", "author": ["Omer Levy", "Yoav Goldberg"], "venue": "In Proceedings of ACL,", "citeRegEx": "Levy and Goldberg.,? \\Q2014\\E", "shortCiteRegEx": "Levy and Goldberg.", "year": 2014}, {"title": "Do multi-sense embeddings improve natural language understanding", "author": ["Jiwei Li", "Dan Jurafsky"], "venue": "In Proceedings of EMNLP,", "citeRegEx": "Li and Jurafsky.,? \\Q2015\\E", "shortCiteRegEx": "Li and Jurafsky.", "year": 2015}, {"title": "Semeval-2010 task 14: Word sense induction & disambiguation", "author": ["Suresh Manandhar", "Ioannis Klapaftis", "Dmitriy Dligach", "Sameer Pradhan"], "venue": "In Proceedings of SemEval,", "citeRegEx": "Manandhar et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Manandhar et al\\.", "year": 2010}, {"title": "A sick cure for the evaluation of compositional distributional semantic models", "author": ["Marco Marelli", "Stefano Menini", "Marco Baroni", "Luisa Bentivogli", "Raffaella bernardi", "Roberto Zamparelli"], "venue": null, "citeRegEx": "Marelli et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Marelli et al\\.", "year": 2014}, {"title": "Semeval2007 task 10: English lexical substitution task", "author": ["Diana McCarthy", "Robert Navigli"], "venue": "In Proceedings of SemEval,", "citeRegEx": "McCarthy and Navigli.,? \\Q2007\\E", "shortCiteRegEx": "McCarthy and Navigli.", "year": 2007}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean"], "venue": "In Proceedings of NIPS,", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "A semantic concordance", "author": ["George A. Miller", "Claudia Leacock", "Randee Tengi", "Ross T. Bunker"], "venue": "In Proceedings of the Arpa Workshop on Human Language Technology,", "citeRegEx": "Miller et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Miller et al\\.", "year": 1993}, {"title": "Vector-based models of semantic composition", "author": ["Jeff Mitchell", "Mirella Lapata"], "venue": "In Proceedings of ACL,", "citeRegEx": "Mitchell and Lapata.,? \\Q2008\\E", "shortCiteRegEx": "Mitchell and Lapata.", "year": 2008}, {"title": "Composition in distributional models of semantics", "author": ["Jeff Mitchell", "Mirella Lapata"], "venue": "Cognitive Science,", "citeRegEx": "Mitchell and Lapata.,? \\Q2010\\E", "shortCiteRegEx": "Mitchell and Lapata.", "year": 2010}, {"title": "Towards dynamic word sense discrimination with random indexing", "author": ["Hans Moen", "Erwin Marsi", "Bj\u00f6rn Gamb\u00e4ck"], "venue": "In Proceedings of the Workshop on Continuous Vector Space Models and their Compositionality,", "citeRegEx": "Moen et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Moen et al\\.", "year": 2013}, {"title": "Entity linking meets word sense disambiguation: A unified approach", "author": ["Andrea Moro", "Alessandro Raganato", "Roberto Navigli"], "venue": null, "citeRegEx": "Moro et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Moro et al\\.", "year": 2014}, {"title": "Discovering word senses from text", "author": ["Patrick Pantel", "Dekang Lin"], "venue": "In Proceedings of SIGKDD,", "citeRegEx": "Pantel and Lin.,? \\Q2002\\E", "shortCiteRegEx": "Pantel and Lin.", "year": 2002}, {"title": "A practical and linguistically-motivated approach to compositional distributional semantics", "author": ["Denis Paperno", "Nghia The Pham", "Marco Baroni"], "venue": "In Proceedings of ACL,", "citeRegEx": "Paperno et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Paperno et al\\.", "year": 2014}, {"title": "De-conflated semantic representations", "author": ["Mohammad Taher Pilehvar", "Nigel Collier"], "venue": "In Proceedings of EMNLP,", "citeRegEx": "Pilehvar and Collier.,? \\Q2016\\E", "shortCiteRegEx": "Pilehvar and Collier.", "year": 2016}, {"title": "Improving distributional semantic vectors through context selection and normalisation", "author": ["Tamara Polajnar", "Stephen Clark"], "venue": "In Proceedings of EACL,", "citeRegEx": "Polajnar and Clark.,? \\Q2014\\E", "shortCiteRegEx": "Polajnar and Clark.", "year": 2014}, {"title": "Word sense discrimination by clustering contexts in vector and similarity spaces", "author": ["Amruta Purandare", "Ted Pedersen"], "venue": "In Proceedings of CoNLL,", "citeRegEx": "Purandare and Pedersen.,? \\Q2004\\E", "shortCiteRegEx": "Purandare and Pedersen.", "year": 2004}, {"title": "Dynamic and static prototype vectors for semantic composition", "author": ["Siva Reddy", "Ioannis Klapaftis", "Diana McCarthy", "Suresh Manandhar"], "venue": "In Proceedings of IJCNLP,", "citeRegEx": "Reddy et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Reddy et al\\.", "year": 2011}, {"title": "Multi-prototype vector-space models of word meaning", "author": ["Joseph Reisinger", "Raymond J. Mooney"], "venue": "In Proceedings of NAACL-HLT,", "citeRegEx": "Reisinger and Mooney.,? \\Q2010\\E", "shortCiteRegEx": "Reisinger and Mooney.", "year": 2010}, {"title": "A word embedding approach to predicting the compositionality of multiword expressions", "author": ["Bahar Salehi", "Paul Cook", "Timothy Baldwin"], "venue": "In Proceedings of NAACL-HLT,", "citeRegEx": "Salehi et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Salehi et al\\.", "year": 2015}, {"title": "Automatic word sense discrimination", "author": ["Hinrich Sch\u00fctze"], "venue": "Computational Linguistics,", "citeRegEx": "Sch\u00fctze.,? \\Q1998\\E", "shortCiteRegEx": "Sch\u00fctze.", "year": 1998}, {"title": "The mechanism of additive composition", "author": ["Ran Tian", "Naoaki Okazaki", "Kentaro Inui"], "venue": "CoRR, abs/1511.08407", "citeRegEx": "Tian et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Tian et al\\.", "year": 2015}, {"title": "Using three way data for word sense discrimination", "author": ["Tim Van de Cruys"], "venue": "In Proceedings of Coling,", "citeRegEx": "Cruys.,? \\Q2008\\E", "shortCiteRegEx": "Cruys.", "year": 2008}, {"title": "Aligning packed dependency trees: a theory of composition for distributional semantics", "author": ["David Weir", "Julie Weeds", "Jeremy Reffin", "Thomas Kober"], "venue": "Computational Linguistics, special issue on Formal Distributional Semantics,", "citeRegEx": "Weir et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Weir et al\\.", "year": 2016}, {"title": "From paraphrase database to compositional paraphrase model and back", "author": ["John Wieting", "Mohit Bansal", "Kevin Gimpel", "Karen Livescu"], "venue": null, "citeRegEx": "Wieting et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wieting et al\\.", "year": 2015}, {"title": "One sense per collocation", "author": ["David Yarowsky"], "venue": "In Proceedings of the Workshop on Human Language Technology,", "citeRegEx": "Yarowsky.,? \\Q1993\\E", "shortCiteRegEx": "Yarowsky.", "year": 1993}, {"title": "The microsoft research sentence completion challenge", "author": ["Geoffrey Zweig", "J.C. Chris Burges"], "venue": "Technical report, Microsoft Research", "citeRegEx": "Zweig and Burges.,? \\Q2011\\E", "shortCiteRegEx": "Zweig and Burges.", "year": 2011}], "referenceMentions": [{"referenceID": 38, "context": "One approach (Reisinger and Mooney, 2010; Huang et al., 2012) is to try", "startOffset": 13, "endOffset": 61}, {"referenceID": 14, "context": "One approach (Reisinger and Mooney, 2010; Huang et al., 2012) is to try", "startOffset": 13, "endOffset": 61}, {"referenceID": 35, "context": "Similar approaches are proposed by Reddy et al. (2011) and Kartsaklis et al.", "startOffset": 35, "endOffset": 55}, {"referenceID": 18, "context": "(2011) and Kartsaklis et al. (2013) who show that appropriate sense selection or disambigua-", "startOffset": 11, "endOffset": 36}, {"referenceID": 37, "context": "tion typically improves performance for composition of noun phrases (Reddy et al., 2011) and verb phrases (Kartsaklis et al.", "startOffset": 68, "endOffset": 88}, {"referenceID": 19, "context": ", 2011) and verb phrases (Kartsaklis et al., 2013).", "startOffset": 25, "endOffset": 50}, {"referenceID": 7, "context": "Dinu and Lapata (2010) proposed a model that represents the meaning of a word as a probability distribu-", "startOffset": 0, "endOffset": 23}, {"referenceID": 15, "context": "WordNet to obtain sense labels a priori to creating word representations (Iacobacci et al., 2015), or as a postprocessing step after obtaining initial word representations (Chen et al.", "startOffset": 73, "endOffset": 97}, {"referenceID": 6, "context": ", 2015), or as a postprocessing step after obtaining initial word representations (Chen et al., 2014; Pilehvar and Collier, 2016).", "startOffset": 82, "endOffset": 129}, {"referenceID": 34, "context": ", 2015), or as a postprocessing step after obtaining initial word representations (Chen et al., 2014; Pilehvar and Collier, 2016).", "startOffset": 82, "endOffset": 129}, {"referenceID": 14, "context": "While these approaches have exhibited strong performance on benchmark word similarity tasks (Huang et al., 2012; Iacobacci et al., 2015) and some downstream processing tasks such as part-of-speech tagging and relation identification (Li and Jurafsky, 2015), they have been weaker than the single-vector representations at predicting the compositionality of multi-word expressions (Salehi et al.", "startOffset": 92, "endOffset": 136}, {"referenceID": 15, "context": "While these approaches have exhibited strong performance on benchmark word similarity tasks (Huang et al., 2012; Iacobacci et al., 2015) and some downstream processing tasks such as part-of-speech tagging and relation identification (Li and Jurafsky, 2015), they have been weaker than the single-vector representations at predicting the compositionality of multi-word expressions (Salehi et al.", "startOffset": 92, "endOffset": 136}, {"referenceID": 22, "context": ", 2015) and some downstream processing tasks such as part-of-speech tagging and relation identification (Li and Jurafsky, 2015), they have been weaker than the single-vector representations at predicting the compositionality of multi-word expressions (Salehi et al.", "startOffset": 104, "endOffset": 127}, {"referenceID": 39, "context": ", 2015) and some downstream processing tasks such as part-of-speech tagging and relation identification (Li and Jurafsky, 2015), they have been weaker than the single-vector representations at predicting the compositionality of multi-word expressions (Salehi et al., 2015), and at tasks which require the meaning of a word to be considered in context; e.", "startOffset": 251, "endOffset": 272}, {"referenceID": 16, "context": "g, word sense disambiguation (Iacobacci et al., 2016) and word similarity in context (Iacobacci et al.", "startOffset": 29, "endOffset": 53}, {"referenceID": 15, "context": ", 2016) and word similarity in context (Iacobacci et al., 2015).", "startOffset": 39, "endOffset": 63}, {"referenceID": 26, "context": "We compare the 300-dimensional skip-gram word2vec (Mikolov et al., 2013) word embeddings2 to the dependency based version of word2vec \u2014 henceforth dep2vec3 (Levy and Goldberg, 2014) \u2014 and the", "startOffset": 50, "endOffset": 72}, {"referenceID": 21, "context": ", 2013) word embeddings2 to the dependency based version of word2vec \u2014 henceforth dep2vec3 (Levy and Goldberg, 2014) \u2014 and the", "startOffset": 91, "endOffset": 116}, {"referenceID": 15, "context": "dependency-based-word-embeddings/ SENSEMBED model4 by Iacobacci et al. (2015), which creates word-sense embeddings by per-", "startOffset": 54, "endOffset": 78}, {"referenceID": 31, "context": "On the other hand, SENSEMBED utilises Babelfy (Moro et al., 2014) as an external knowledge source to perform word-sense disambiguation and subsequently creates one vector representation per word sense.", "startOffset": 46, "endOffset": 65}, {"referenceID": 12, "context": "For composition we use pointwise addition for all models as this has been shown to be a strong baseline in a number of studies (Hashimoto et al., 2014; Hill et al., 2016).", "startOffset": 127, "endOffset": 170}, {"referenceID": 13, "context": "For composition we use pointwise addition for all models as this has been shown to be a strong baseline in a number of studies (Hashimoto et al., 2014; Hill et al., 2016).", "startOffset": 127, "endOffset": 170}, {"referenceID": 13, "context": "sition function but, similar to Hill et al. (2016), found its performance to be very poor (results not reported).", "startOffset": 32, "endOffset": 51}, {"referenceID": 12, "context": "48 represents the current state-of-the-art performance on this task (Hashimoto et al., 2014; Kober et al., 2016; Wieting et al., 2015).", "startOffset": 68, "endOffset": 134}, {"referenceID": 20, "context": "48 represents the current state-of-the-art performance on this task (Hashimoto et al., 2014; Kober et al., 2016; Wieting et al., 2015).", "startOffset": 68, "endOffset": 134}, {"referenceID": 44, "context": "48 represents the current state-of-the-art performance on this task (Hashimoto et al., 2014; Kober et al., 2016; Wieting et al., 2015).", "startOffset": 68, "endOffset": 134}, {"referenceID": 26, "context": "similarity task of Mitchell and Lapata (2010). This dataset consists of 108 adjective-noun (AN), 108 noun-noun (NN) and 108 verb-object (VO) pairs.", "startOffset": 19, "endOffset": 46}, {"referenceID": 14, "context": "For multi-sense representations, we adapted the strategy which has been used successfully in various word similarity experiments (Huang et al., 2012; Iacobacci et al., 2015).", "startOffset": 129, "endOffset": 173}, {"referenceID": 15, "context": "For multi-sense representations, we adapted the strategy which has been used successfully in various word similarity experiments (Huang et al., 2012; Iacobacci et al., 2015).", "startOffset": 129, "endOffset": 173}, {"referenceID": 28, "context": "Table 2 lists a number of example phrase pairs with low average human similarity scores in the Mitchell and Lapata (2010) test set.", "startOffset": 95, "endOffset": 122}, {"referenceID": 32, "context": "Pantel and Lin (2002), and Van de Cruys (2008) used automatically extracted words from various newswire sources and evaluated the output of their models in comparison to WordNet and EuroWordNet, respectively.", "startOffset": 0, "endOffset": 22}, {"referenceID": 32, "context": "Pantel and Lin (2002), and Van de Cruys (2008) used automatically extracted words from various newswire sources and evaluated the output of their models in comparison to WordNet and EuroWordNet, respectively.", "startOffset": 0, "endOffset": 47}, {"referenceID": 2, "context": "Akkaya et al. (2012) used the concatenation of the SENSEVAL-2 and SENSEVAL-3 tasks and evaluated their models in terms of cluster purity and accuracy.", "startOffset": 0, "endOffset": 21}, {"referenceID": 2, "context": "Akkaya et al. (2012) used the concatenation of the SENSEVAL-2 and SENSEVAL-3 tasks and evaluated their models in terms of cluster purity and accuracy. Finally, Moen et al. (2013) used the semantic textual similarity (STS) 2012 task, which is based on human judgements of the similarity between two sentences.", "startOffset": 0, "endOffset": 179}, {"referenceID": 2, "context": "successfully used in past works (Akkaya et al., 2012; Basile et al., 2014).", "startOffset": 32, "endOffset": 74}, {"referenceID": 3, "context": "successfully used in past works (Akkaya et al., 2012; Basile et al., 2014).", "startOffset": 32, "endOffset": 74}, {"referenceID": 27, "context": "For the construction of our dataset we made use of data from two english dictionaries (Oxford Dictionary and Collins Dictionary), accessible via their respective web APIs6, as well as examples from the sense annotated corpus SemCor (Miller et al., 1993).", "startOffset": 232, "endOffset": 253}, {"referenceID": 15, "context": "egy (Iacobacci et al., 2015) on composed representations to choose the predicted sense10.", "startOffset": 4, "endOffset": 28}, {"referenceID": 9, "context": "significance between the best performing model and the word overlap baseline is computed by using a randomised pairwise permutation test (Efron and Tibshirani, 1994).", "startOffset": 137, "endOffset": 165}, {"referenceID": 45, "context": "One possible explanation for its robust performance on our task is an occurrence of the one-sense-per-collocation hypothesis (Yarowsky, 1993).", "startOffset": 125, "endOffset": 141}, {"referenceID": 41, "context": "There is furthermore evidence that additive composition in low-dimensional word embeddings approximates an intersection of the contexts of two distributional word vectors (Tian et al., 2015).", "startOffset": 171, "endOffset": 190}, {"referenceID": 25, "context": "text are the english lexical substitution task (McCarthy and Navigli, 2007) and the Microsoft sentence completion challenge (Zweig and Burges, 2011).", "startOffset": 47, "endOffset": 75}, {"referenceID": 46, "context": "text are the english lexical substitution task (McCarthy and Navigli, 2007) and the Microsoft sentence completion challenge (Zweig and Burges, 2011).", "startOffset": 124, "endOffset": 148}, {"referenceID": 18, "context": "Dictionary definitions have previously been used to evaluate compositional distributional semantic models where the goal is to match a dictionary entry with its corresponding definition (Kartsaklis et al., 2012; Polajnar and Clark, 2014).", "startOffset": 186, "endOffset": 237}, {"referenceID": 35, "context": "Dictionary definitions have previously been used to evaluate compositional distributional semantic models where the goal is to match a dictionary entry with its corresponding definition (Kartsaklis et al., 2012; Polajnar and Clark, 2014).", "startOffset": 186, "endOffset": 237}, {"referenceID": 1, "context": "2013; Grefenstette and Sadrzadeh, 2011; Kartsaklis and Sadrzadeh, 2014; Mitchell and Lapata, 2008; Mitchell and Lapata, 2010) or sentences (Agirre et al., 2016; Huang et al., 2012; Marelli et al., 2014) in comparison to human pro-", "startOffset": 139, "endOffset": 202}, {"referenceID": 14, "context": "2013; Grefenstette and Sadrzadeh, 2011; Kartsaklis and Sadrzadeh, 2014; Mitchell and Lapata, 2008; Mitchell and Lapata, 2010) or sentences (Agirre et al., 2016; Huang et al., 2012; Marelli et al., 2014) in comparison to human pro-", "startOffset": 139, "endOffset": 202}, {"referenceID": 24, "context": "2013; Grefenstette and Sadrzadeh, 2011; Kartsaklis and Sadrzadeh, 2014; Mitchell and Lapata, 2008; Mitchell and Lapata, 2010) or sentences (Agirre et al., 2016; Huang et al., 2012; Marelli et al., 2014) in comparison to human pro-", "startOffset": 139, "endOffset": 202}, {"referenceID": 4, "context": "atively high variance of judgements and low interannotator agreement (Batchkarov et al., 2016).", "startOffset": 69, "endOffset": 94}, {"referenceID": 0, "context": "Due to not requiring any models to perform an extra step for sense induction, our task is easier to evaluate as no matching between sense clusters identified by a model and some gold standard sense classes needs to be performed, as typically proposed in the WSI literature (Agirre and Soroa, 2007; Manandhar et al., 2010).", "startOffset": 273, "endOffset": 321}, {"referenceID": 23, "context": "Due to not requiring any models to perform an extra step for sense induction, our task is easier to evaluate as no matching between sense clusters identified by a model and some gold standard sense classes needs to be performed, as typically proposed in the WSI literature (Agirre and Soroa, 2007; Manandhar et al., 2010).", "startOffset": 273, "endOffset": 321}, {"referenceID": 14, "context": "Most closely related to our task are the Stanford Contextual Word Similarity (SCWS) dataset by Huang et al. (2012) and the Usage Similar-", "startOffset": 95, "endOffset": 115}, {"referenceID": 10, "context": "ity (USim) task by Erk et al. (2009). The goal in both tasks is to estimate the similarity of two polysemous words in context in comparison to human provided gold standard judgements.", "startOffset": 19, "endOffset": 37}, {"referenceID": 33, "context": "tional semantic models such as the lexical function model (Paperno et al., 2014) or the Anchored Packed Dependency Tree framework (Weir et al.", "startOffset": 58, "endOffset": 80}, {"referenceID": 43, "context": ", 2014) or the Anchored Packed Dependency Tree framework (Weir et al., 2016).", "startOffset": 57, "endOffset": 76}], "year": 2017, "abstractText": "In this paper, we investigate whether an a priori disambiguation of word senses is strictly necessary or whether the meaning of a word in context can be disambiguated through composition alone. We evaluate the performance of off-the-shelf singlevector and multi-sense vector models on a benchmark phrase similarity task and a novel task for word-sense discrimination. We find that single-sense vector models perform as well or better than multi-sense vector models despite arguably less clean elementary representations. Our findings furthermore show that simple composition functions such as pointwise addition are able to recover sense specific information from a single-sense vector model remark-", "creator": "TeX"}}}