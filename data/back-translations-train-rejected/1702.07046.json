{"id": "1702.07046", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Feb-2017", "title": "Feature Generation for Robust Semantic Role Labeling", "abstract": "Hand-engineered feature sets are a well understood method for creating robust NLP models, but they require a lot of expertise and effort to create. In this work we describe how to automatically generate rich feature sets from simple units called featlets, requiring less engineering. Using information gain to guide the generation process, we train models which rival the state of the art on two standard Semantic Role Labeling datasets with almost no task or linguistic insight.", "histories": [["v1", "Wed, 22 Feb 2017 23:39:03 GMT  (45kb,D)", "http://arxiv.org/abs/1702.07046v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["travis wolfe", "mark dredze", "benjamin van durme"], "accepted": false, "id": "1702.07046"}, "pdf": {"name": "1702.07046.pdf", "metadata": {"source": "CRF", "title": "Feature Generation for Robust Semantic Role Labeling", "authors": ["Travis Wolfe", "Mark Dredze", "Benjamin Van Durme"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "In fact, most of them are able to determine for themselves what they want, and they are able to determine for themselves what they want and what they want."}, {"heading": "2 Featlets", "text": "These units can be composed to produce a wide range of features \u3002 We distinguish the features from features that differ in the way they differ in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do and they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do in the way they do the way in the way they do the way they do the"}, {"heading": "2.1 Finding Legal Templates", "text": "We can use a few heuristics to find out which feature strings form a template (most sequences make no sense, like [ARGSPAN, SHAPE]). We have rules that filter feature strings as follows: \u2022 nothing can come before a token extractor \u2022 if a feature fails or does not change the context, we stop here (this and all feature strings are invalid). We perform a width initial search of all feature strings up to length 6 and collect all strings that are templates: those that produce output on at least 2 out of 50 instances and generate 5241 templates. At this point, it should be noted that feature strings are functions from one context to another and are therefore closed under function composition.10This can be used to measure a variety of distances using linear treadmills, such as ArgSpan width or the distance between ArgHead and TargetHead."}, {"heading": "2.2 Frequency-based Template Transforms", "text": "For each template found, we produce 5 additional templates by appending the following features: TOP10, TOP100, TOP1000, CNT8 CNT16. The TOPN transforms a template by sorting its features by frequency and firing the template only at values that are at least as high as the most common features. CNTC only performs features that are observed at least C times in the training data. These automatic transformations are useful for construction products as they control the number of features created. In our experiments, we found that a TOPN template transformation occurred in slightly less than 50% of our final features and a CNTC function appeared in slightly less than 10%."}, {"heading": "2.3 Template Composition", "text": "To make features bigger than we can see with the brute force enumeration of feature strings, we look at template products. It is common to render them by string concatenation, but we define template products as the same as feature concatenation. This has an important difference: a template may not return any value, in which case the rest of the product will not return any value. With string concatenation, you can render a template that makes another more specific by inserting more information. With Featlet composition, you can have one template modulated when another can fire, but this is weaker than the general feature composition, and the order does not matter."}, {"heading": "2.4 Near Duplicate Removal", "text": "We will create pairs of similar and possibly redundant templates, for example: X1 = [ARGHEAD, LEFTSIBD, WORD] and X2 = [ARGHEAD, LEFTMOSTSIBD, WORD]. Principal approaches such as conditional mutual information I (Y; X2 | X1) could be used to filter, but this would require a lot of calculation. It is faster to use the type level (attribute / template name) rather than the token level (values extracted from instance data). We can construct similarity functions for any of the structural layers we produce. 1. Similarity between two features is the normalized Levenshtein edit space11 between their names, so that LEFTMOSTSIBD LEFTMOSTSIBD is similar to LEFTMOSTSIBD, but not PARENTC.11operations have unit cost, and we divide them by the length of the longer string 2. Similarity between the templates is not related to the two previous alpha functions (3.)."}, {"heading": "3 Feature Selection", "text": "Some of the characteristics we generate may not provide a signal toward a label we are trying to predict. To filter down to a manageable set of informative characteristics, we evaluate each template using mutual information (sometimes referred to as information gain), between a label (Bernoulli) and a template (Multinomial). Mutual information has a natural connection to Bayesian independence tests (Minka, 2003). Since the calculation of mutual information only counts, this task is embarrassingly parallel and can easily be done in frameworks like MapReduce.We select a budget based on how many characteristics we are looking for via B, and divide that budget up into template products in an order in which i-characteristics get a share of the budget. In these experiments, we set B = 3000000 000 and g = 1.5, meaning that the split between characteristics [21%, 32%, 47%].14 For each split, characteristics were sorted according to the maximum heuristic value for each individual template."}, {"heading": "4 Experiments", "text": "In our experiments, we use semantic role clich\u00e9s (SRL) as a case study to test whether our automatic methods are also capable of adapting to people's needs. SRL is a difficult predictive task with more than one structural formulation (type of label); sometimes arguments are presented in a dependency tree (Surdeanu et al., 2008). Correspondence between the arguments and syntactic components may be very close (Kingsbury and Palmer) or not (Carreras and Ma rquez et al., 1998)."}, {"heading": "5 Results", "text": "Overall, our method seems to work about as well as experts who design features for SRL manually. Given the results in Table 5, our approach, which matches the performance of Das et al. (2012) and Pradhan et al. (2013), shows that other systems achieve better performance, but these models use all global information, an orthogonal problem for the local feature set.Looking at the generated feature sets, there is a big difference in the complexity parameters \u03b2. For FrameNet, the best value is \u03b2 10, which means that the features with the highest normalized mutual information were selected, while Propbank and \u03b2 = 0.01, it was better to ignore the entropy of the feature. In retrospect, this makes sense when looking at the size of the training sets, Propbank is about 20 times larger, but it is not clear how much data is needed to justify this shift in the vote by hand. This difference in the selection criteria leads to very different feature sets, the system performance comes down to the question of whether this is another one, but it is a system performance."}, {"heading": "6 Discussion", "text": "The product operator for templates is commutative, but that is not the case with features. Some templates are equivalent and there is no easy way to verify their names, which is costly. Another problem is that many features are needed. The best models we have trained for FrameNet use over 2500 features, which is significantly more than Das et al. (2012), which used 34. When manually reviewing the feature sets we learned, we find most, if not all, of the features that Das et al. (2012) created, 17, but the precision is low."}, {"heading": "7 Related Work", "text": "This work shares a certain motivation with neural methods, such as the desire to avoid domain expert-derived features, but we differ primarily for computer-based reasons. This work is about model generation and scoring, and it is not clear how to evaluate neural models in a way that does not involve the realignment of a model. Feature-based models are an affordable decomposition and information theory analysis in a way that neural models do not know. Within function-based methods, retrograde selection methods are common, including a large body of work on sparse-inducing regulations, the canonical being of the lasso (Tibshirani, 1996). These methods are applicable when the entire feature set can be renumbered on a machine. This is not feasible for this work because we generate features that lie in a combinatorial space that is too large."}, {"heading": "8 Conclusion", "text": "In this paper, we propose a general framework for the creation of feature sets, with the aim of removing expert technology from the loop of machine learning. Our approach is based on the compilation of so-called feature sets for the creation of templates. Featlets are small functions that can be agnostically defined and easily implemented by amateurs. Featlets preserve a multitude of nuanced feature semantics on the one hand and can be automatically enumerated on the other hand to derive an enormous amount of new templates and features."}], "references": [{"title": "The berkeley framenet", "author": ["Baker et al.1998] Collin F Baker", "Charles J Fillmore", "John B Lowe"], "venue": null, "citeRegEx": "Baker et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Baker et al\\.", "year": 1998}, {"title": "Multilingual semantic role labeling", "author": ["Love Hafdell", "Pierre Nugues"], "venue": "In Proceedings of the Thirteenth Conference on Computational Natural Language Learning: Shared Task,", "citeRegEx": "Bj\u00f6rkelund et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Bj\u00f6rkelund et al\\.", "year": 2009}, {"title": "Introduction to the conll-2005 shared task: Semantic role labeling", "author": ["Carreras", "M\u00e0rquez2005] Xavier Carreras", "Llu\u0131\u0301s M\u00e0rquez"], "venue": "In Proceedings of the Ninth Conference on Computational Natural Language Learning,", "citeRegEx": "Carreras et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Carreras et al\\.", "year": 2005}, {"title": "Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms", "author": ["Michael Collins"], "venue": "In Proceedings of the ACL-02 conference on Empirical methods in natural language processing-Volume", "citeRegEx": "Collins.,? \\Q2002\\E", "shortCiteRegEx": "Collins.", "year": 2002}, {"title": "An exact dual decomposition algorithm for shallow semantic parsing with constraints. In SemEval, SemEval \u201912", "author": ["Das et al.2012] Dipanjan Das", "Andr\u00e9 F.T. Martins", "Noah A. Smith"], "venue": null, "citeRegEx": "Das et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Das et al\\.", "year": 2012}, {"title": "Semantic role labelling with neural network factors", "author": ["Oscar T\u00e4ckstr\u00f6m", "Kuzman Ganchev", "Dipanjan Das"], "venue": "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Process-", "citeRegEx": "FitzGerald et al\\.,? \\Q2015\\E", "shortCiteRegEx": "FitzGerald et al\\.", "year": 2015}, {"title": "Large margin classification using the perceptron algorithm", "author": ["Freund", "Schapire1999] Yoav Freund", "Robert E Schapire"], "venue": "Machine learning,", "citeRegEx": "Freund et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Freund et al\\.", "year": 1999}, {"title": "Automatic labeling of semantic roles", "author": ["Gildea", "Jurafsky2002] Daniel Gildea", "Daniel Jurafsky"], "venue": "Computational linguistics,", "citeRegEx": "Gildea et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Gildea et al\\.", "year": 2002}, {"title": "Low-resource semantic role labeling", "author": ["Margaret Mitchell", "Benjamin Van Durme", "Mark Dredze"], "venue": "In Proceedings of ACL, June", "citeRegEx": "Gormley et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Gormley et al\\.", "year": 2014}, {"title": "Semantic frame identification with distributed word representations", "author": ["Dipanjan Das", "Jason Weston", "Kuzman Ganchev"], "venue": "In Proceedings of ACL. Association for Computational Linguistics", "citeRegEx": "Hermann et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hermann et al\\.", "year": 2014}, {"title": "Dependency-based semantic role labeling of propbank", "author": ["Johansson", "Nugues2008] Richard Johansson", "Pierre Nugues"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Johansson et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Johansson et al\\.", "year": 2008}, {"title": "From treebank to propbank", "author": ["Kingsbury", "Palmer2002] Paul Kingsbury", "Martha Palmer"], "venue": "In LREC. Citeseer", "citeRegEx": "Kingsbury et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Kingsbury et al\\.", "year": 2002}, {"title": "Learning a meta-level prior for feature relevance from multiple related tasks", "author": ["Lee et al.2007] Su-In Lee", "Vassil Chatalbashev", "David Vickrey", "Daphne Koller"], "venue": "In Proceedings of the 24th International Conference on Machine Learning,", "citeRegEx": "Lee et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Lee et al\\.", "year": 2007}, {"title": "Low-rank tensors for scoring dependency structures", "author": ["Lei et al.2014] Tao Lei", "Yu Xin", "Yuan Zhang", "Regina Barzilay", "Tommi Jaakkola"], "venue": "In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume", "citeRegEx": "Lei et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Lei et al\\.", "year": 2014}, {"title": "High-order low-rank tensors for semantic role labeling", "author": ["Lei et al.2015] Tao Lei", "Yuan Zhang", "Llu\u0131\u0301s M\u00e0rquez", "Alessandro Moschitti", "Regina Barzilay"], "venue": "In Proceedings of the 2015 Conference of the North American Chapter of the Association", "citeRegEx": "Lei et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lei et al\\.", "year": 2015}, {"title": "Semi-supervised learning for natural language", "author": ["Percy Liang"], "venue": "Master\u2019s thesis, Massachusetts Institute of Technology", "citeRegEx": "Liang.,? \\Q2005\\E", "shortCiteRegEx": "Liang.", "year": 2005}, {"title": "The Stanford CoreNLP natural language processing toolkit", "author": ["Mihai Surdeanu", "John Bauer", "Jenny Finkel", "Steven J. Bethard", "David McClosky"], "venue": null, "citeRegEx": "Manning et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Manning et al\\.", "year": 2014}, {"title": "Semantic role labeling: An introduction", "author": ["Xavier Carreras", "Kenneth C. Litkowski", "Suzanne Stevenson"], "venue": null, "citeRegEx": "M\u00e0rquez et al\\.,? \\Q2008\\E", "shortCiteRegEx": "M\u00e0rquez et al\\.", "year": 2008}, {"title": "Efficiently inducing features of conditional random fields", "author": ["Andrew McCallum"], "venue": "In Proceedings of the Nineteenth Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "McCallum.,? \\Q2003\\E", "shortCiteRegEx": "McCallum.", "year": 2003}, {"title": "Bayesian inference, entropy, and the multinomial distribution", "author": ["Tom Minka"], "venue": "Online tutorial", "citeRegEx": "Minka.,? \\Q2003\\E", "shortCiteRegEx": "Minka.", "year": 2003}, {"title": "Estimation of entropy and mutual information", "author": ["Liam Paninski"], "venue": "Neural computation,", "citeRegEx": "Paninski.,? \\Q2003\\E", "shortCiteRegEx": "Paninski.", "year": 2003}, {"title": "Support vector learning for semantic argument classification", "author": ["Kadri Hacioglu", "Valerie Krugler", "Wayne Ward", "James H Martin", "Daniel Jurafsky"], "venue": "Machine Learning,", "citeRegEx": "Pradhan et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Pradhan et al\\.", "year": 2005}, {"title": "Towards robust linguistic analysis using ontonotes", "author": ["Alessandro Moschitti", "Nianwen Xue", "Hwee Tou Ng", "Anders Bj\u00f6rkelund", "Olga Uryupina", "Yuchen Zhang", "Zhi Zhong"], "venue": "In Proceedings of the Seven-", "citeRegEx": "Pradhan et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Pradhan et al\\.", "year": 2013}, {"title": "The importance of syntactic parsing and inference in semantic role labeling", "author": ["Dan Roth", "Wen-tau Yih"], "venue": null, "citeRegEx": "Punyakanok et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Punyakanok et al\\.", "year": 2008}, {"title": "Framenet ii: Extended theory and practice", "author": ["Michael Ellsworth", "Miriam RL Petruck", "Christopher R Johnson", "Jan Scheffczyk"], "venue": null, "citeRegEx": "Ruppenhofer et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Ruppenhofer et al\\.", "year": 2006}, {"title": "The conll-2008 shared task on joint parsing of syntactic and semantic dependencies", "author": ["Richard Johansson", "Adam Meyers", "Llu\u0131\u0301s M\u00e0rquez", "Joakim Nivre"], "venue": "In Proceedings of the Twelfth Conference on Computa-", "citeRegEx": "Surdeanu et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Surdeanu et al\\.", "year": 2008}, {"title": "Efficient inference and structured learning for semantic role labeling", "author": ["Kuzman Ganchev", "Dipanjan Das"], "venue": "Transactions of the Association for Computational Linguistics,", "citeRegEx": "T\u00e4ckstr\u00f6m et al\\.,? \\Q2015\\E", "shortCiteRegEx": "T\u00e4ckstr\u00f6m et al\\.", "year": 2015}, {"title": "Regression shrinkage and selection via the lasso", "author": ["Robert Tibshirani"], "venue": "Journal of the Royal Statistical Society. Series B (Methodological),", "citeRegEx": "Tibshirani.,? \\Q1996\\E", "shortCiteRegEx": "Tibshirani.", "year": 1996}, {"title": "Joint learning improves semantic role labeling", "author": ["Aria Haghighi", "Christopher D. Manning"], "venue": "In Proceedings of the 43rd Annual Meeting", "citeRegEx": "Toutanova et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Toutanova et al\\.", "year": 2005}, {"title": "Calibrating features for semantic role labeling", "author": ["Xue", "Palmer2004] Nianwen Xue", "Martha Palmer"], "venue": "In EMNLP,", "citeRegEx": "Xue et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Xue et al\\.", "year": 2004}, {"title": "Endto-end learning of semantic role labeling using recurrent neural networks", "author": ["Zhou", "Xu2015] Jie Zhou", "Wei Xu"], "venue": "In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint", "citeRegEx": "Zhou et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Zhou et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 21, "context": "1 Further, discrepancies between authors is not unheard of: Gildea and Jurafsky (2002) report 5% of verbs were passive in the PTB, while Pradhan et al. (2005) report 11%.", "startOffset": 137, "endOffset": 159}, {"referenceID": 19, "context": "1 Gildea and Jurafsky (2002) Xue and Palmer (2004) Pradhan et al. (2005) Toutanova et al.", "startOffset": 51, "endOffset": 73}, {"referenceID": 19, "context": "1 Gildea and Jurafsky (2002) Xue and Palmer (2004) Pradhan et al. (2005) Toutanova et al. (2005) Johansson and Nugues (2008) M\u00e0rquez et al.", "startOffset": 51, "endOffset": 97}, {"referenceID": 19, "context": "1 Gildea and Jurafsky (2002) Xue and Palmer (2004) Pradhan et al. (2005) Toutanova et al. (2005) Johansson and Nugues (2008) M\u00e0rquez et al.", "startOffset": 51, "endOffset": 125}, {"referenceID": 16, "context": "(2005) Johansson and Nugues (2008) M\u00e0rquez et al. (2008) Punyakanok et al.", "startOffset": 35, "endOffset": 57}, {"referenceID": 16, "context": "(2005) Johansson and Nugues (2008) M\u00e0rquez et al. (2008) Punyakanok et al. (2008) Das et al.", "startOffset": 35, "endOffset": 82}, {"referenceID": 4, "context": "(2008) Das et al. (2014) 2.", "startOffset": 7, "endOffset": 25}, {"referenceID": 15, "context": "One featlet for a 256 and a 1000 cluster output of Liang (2005).", "startOffset": 51, "endOffset": 64}, {"referenceID": 4, "context": "\u2022 DASBUCKETS: encodes the bucket widths defined in Das et al. (2014)", "startOffset": 51, "endOffset": 69}, {"referenceID": 19, "context": "Mutual information has a natural connection to Bayesian independence testing (Minka, 2003).", "startOffset": 77, "endOffset": 90}, {"referenceID": 20, "context": "Entropy and mutual information estimation breaks down when the cardinality of the variables is large compared to the number of observations (Paninski, 2003).", "startOffset": 140, "endOffset": 156}, {"referenceID": 20, "context": "Entropy and mutual information estimation breaks down when the cardinality of the variables is large compared to the number of observations (Paninski, 2003). We observed that entropy estimates based on the maximum likelihood estimates of p(y, x) and p(x) from counts of (y, x) yielded very biased estimates of mutual information (high for sparse features). We correct for this problem by using the BUB entropy estimation method described by Paninski (2003).", "startOffset": 141, "endOffset": 457}, {"referenceID": 25, "context": "Sometimes arguments are represented by their head token in a dependency tree (Surdeanu et al., 2008; Haji\u010d et al., 2009) and sometimes they are specified by a span or constituent (Carreras and M\u00e0rquez, 2005; Baker et al.", "startOffset": 77, "endOffset": 120}, {"referenceID": 0, "context": ", 2009) and sometimes they are specified by a span or constituent (Carreras and M\u00e0rquez, 2005; Baker et al., 1998).", "startOffset": 66, "endOffset": 114}, {"referenceID": 24, "context": "For span-based SRL, the correspondence between the argument spans and syntactic constituents can be very tight (Kingsbury and Palmer, 2002) or not (Ruppenhofer et al., 2006).", "startOffset": 147, "endOffset": 173}, {"referenceID": 24, "context": "Sometimes the role labels depend on the predicate sense (Ruppenhofer et al., 2006) and sometimes they don\u2019t (Kingsbury and Palmer, 2002).", "startOffset": 56, "endOffset": 82}, {"referenceID": 24, "context": "5 (Ruppenhofer et al., 2006) and the CoNLL 2012 data derived from the OntoNotes 5.", "startOffset": 2, "endOffset": 28}, {"referenceID": 22, "context": "0 corpus (Pradhan et al., 2013).", "startOffset": 9, "endOffset": 31}, {"referenceID": 16, "context": "Annotations are provided from the Stanford CoreNLP toolset (Manning et al., 2014).", "startOffset": 59, "endOffset": 81}, {"referenceID": 3, "context": "Feature selection is run first on each data set to produce a few feature sets based on \u03b2 and size, then we evaluate their performance using an averaged perceptron (Freund and Schapire, 1999; Collins, 2002).", "startOffset": 163, "endOffset": 205}, {"referenceID": 18, "context": "0 corpus (Pradhan et al., 2013). We used the argument candidate selection method described in Xue and Palmer (2004) as well as the extensions in Hermann et al.", "startOffset": 10, "endOffset": 116}, {"referenceID": 8, "context": "We used the argument candidate selection method described in Xue and Palmer (2004) as well as the extensions in Hermann et al. (2014). Annotations are provided from the Stanford CoreNLP toolset (Manning et al.", "startOffset": 112, "endOffset": 134}, {"referenceID": 4, "context": "6 Das et al. (2012) local 7 67.", "startOffset": 2, "endOffset": 20}, {"referenceID": 4, "context": "6 Das et al. (2012) local 7 67.7 59.8 63.5 Das et al. (2012) constrained 3 70.", "startOffset": 2, "endOffset": 61}, {"referenceID": 20, "context": "2 Pradhan et al. (2013) 7 81.", "startOffset": 2, "endOffset": 24}, {"referenceID": 20, "context": "2 Pradhan et al. (2013) 7 81.3 70.5 75.5 Pradhan et al. (2013) (revised) 7 78.", "startOffset": 2, "endOffset": 63}, {"referenceID": 20, "context": "2 Pradhan et al. (2013) 7 81.3 70.5 75.5 Pradhan et al. (2013) (revised) 7 78.5 76.7 77.5 T\u00e4ckstr\u00f6m et al. (2015) 3 80.", "startOffset": 2, "endOffset": 114}, {"referenceID": 5, "context": "4 FitzGerald et al. (2015) 3 80.", "startOffset": 2, "endOffset": 27}, {"referenceID": 4, "context": "Results in table 5 shows our approach matching the performance of Das et al. (2012) and Pradhan et al.", "startOffset": 66, "endOffset": 84}, {"referenceID": 4, "context": "Results in table 5 shows our approach matching the performance of Das et al. (2012) and Pradhan et al. (2013). Other systems achieve better performance, but these models all use global information, an orthogonal issue to the local feature set.", "startOffset": 66, "endOffset": 110}, {"referenceID": 17, "context": "This is not a new result (M\u00e0rquez et al., 2008), but this work offers a way to respond by applying computational rather than human resources to the problem.", "startOffset": 25, "endOffset": 47}, {"referenceID": 4, "context": "The best models we trained for FrameNet use over 2500 features, which is significantly more than Das et al. (2012), which used 34.", "startOffset": 97, "endOffset": 115}, {"referenceID": 4, "context": "The best models we trained for FrameNet use over 2500 features, which is significantly more than Das et al. (2012), which used 34. Upon manual inspection of the feature sets we learned, we find most if not all of the features that Das et al. (2012) created,17 but precision is low.", "startOffset": 97, "endOffset": 249}, {"referenceID": 27, "context": "Within feature based methods, backwards selection methods are common, including a large body of work on sparsity-inducing regularization, the canonical being the lasso (Tibshirani, 1996).", "startOffset": 168, "endOffset": 186}, {"referenceID": 1, "context": "Bj\u00f6rkelund et al. (2009) used forwards selection for dependency-based SRL (Haji\u010d et al.", "startOffset": 0, "endOffset": 25}, {"referenceID": 4, "context": "For example, the template [TARGETHEAD, LEFTL, TOP10] * [TARGETHEAD, CHILDSEQUENCED, SEQMAPDEPREL, BAG] is likely close to the passive voice template used in Das et al. (2012), since \u201cwas\u201d and \u201cbe\u201d are in the top 10 words to the left of a verb.", "startOffset": 157, "endOffset": 175}, {"referenceID": 4, "context": "For example, the template [TARGETHEAD, LEFTL, TOP10] * [TARGETHEAD, CHILDSEQUENCED, SEQMAPDEPREL, BAG] is likely close to the passive voice template used in Das et al. (2012), since \u201cwas\u201d and \u201cbe\u201d are in the top 10 words to the left of a verb. Technically it is 13 featlets since an OUTPUT featlet is not written after the WNSYNSET and TOP10 featlets, \u00a72. task. McCallum (2003) used forwards selection for named entity recognition, scoring new feature products using approximate model re-fitting (pseudo-likelihood), which also produced good results.", "startOffset": 157, "endOffset": 378}, {"referenceID": 8, "context": "Our method is more similar to the work of Gormley et al. (2014) where every template is scored in parallel irrespective of a trained model.", "startOffset": 42, "endOffset": 64}, {"referenceID": 12, "context": "Future work This work dove-tails with the approach described by Lee et al. (2007), which derives a prior or regularization constant for individual features by looking at properties of the feature (meta features).", "startOffset": 64, "endOffset": 82}, {"referenceID": 13, "context": "Tensor decomposition methods of fixed-order tensors have been used to great effect (Lei et al., 2014; Lei et al., 2015).", "startOffset": 83, "endOffset": 119}, {"referenceID": 14, "context": "Tensor decomposition methods of fixed-order tensors have been used to great effect (Lei et al., 2014; Lei et al., 2015).", "startOffset": 83, "endOffset": 119}], "year": 2017, "abstractText": "Hand-engineered feature sets are a well understood method for creating robust NLP models, but they require a lot of expertise and effort to create. In this work we describe how to automatically generate rich feature sets from simple units called featlets, requiring less engineering. Using information gain to guide the generation process, we train models which rival the state of the art on two standard Semantic Role Labeling datasets with almost no task or linguistic insight.", "creator": "LaTeX with hyperref package"}}}