{"id": "1702.07097", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Feb-2017", "title": "Bidirectional Backpropagation: Towards Biologically Plausible Error Signal Transmission in Neural Networks", "abstract": "The back-propagation (BP) algorithm has been considered the de facto method for training deep neural networks. It back-propagates errors from the output layer to the hidden layers in an exact manner using feedforward weights. In this work, we propose a more biologically plausible paradigm of neural architecture according to biological findings. Specifically, we propose two bidirectional learning algorithms with two sets of trainable weights. Preliminary results show that our models perform best on the MNIST and the CIFAR10 datasets among the asymmetric error signal passing methods, and their performance is more close to that of BP.", "histories": [["v1", "Thu, 23 Feb 2017 05:00:54 GMT  (837kb,D)", "https://arxiv.org/abs/1702.07097v1", null], ["v2", "Sun, 26 Feb 2017 16:41:35 GMT  (971kb,D)", "http://arxiv.org/abs/1702.07097v2", "Extended the paper to the length of a long paper; added references in introduction; corrected the experiments of BFA"], ["v3", "Mon, 20 Mar 2017 01:16:07 GMT  (993kb,D)", "http://arxiv.org/abs/1702.07097v3", "[v2]Extended the paper to the length of a long paper; added references in introduction; corrected the experiments of BFA. [v3] Added link to source code"]], "reviews": [], "SUBJECTS": "cs.NE cs.LG", "authors": ["hongyin luo", "jie fu", "james glass"], "accepted": false, "id": "1702.07097"}, "pdf": {"name": "1702.07097.pdf", "metadata": {"source": "META", "title": "Bidirectional Backpropagation: Towards Biologically Plausible Error Signal Transmission in Neural Networks", "authors": ["Hongyin Luo", "Jie Fu"], "emails": ["hyluo@mit.edu", "jie.fu@u.nus.edu", "glass@mit.edu"], "sections": [{"heading": "1 Introduction", "text": "In fact, it is that we are able to hide, and that we are able, we will be able, we will be able, we will be able."}, {"heading": "2 Background", "text": "Following the representation in [14], (x, y) is a minibatch of input output of size 1. The DNN we are looking at here has 2 hidden layers. wi are the weights (absorbing biases) that connect the previous layer to a unit in the i-th hidden layer. Activations can be calculated either asa1 = w1x, h1 = \u03c3 (a1) (1) a2 = w2h1, h2 = \u03c3 (2) ay = w3h2, y = \u03c3y (ay) (3), where the activation function is used in the output layer and where the activation function is used in the hidden layer. Loss and gradient in the output layer are: l = y \u00b7 logy (1 \u2212 y) \u00b7 log (1 \u2212 y) log \u00b7 (4)."}, {"heading": "3 Biologically Plausible Perceptron", "text": "Classical perceptrons trained with gradient-descent algorithms must re-propagate error signals based on the exact synaptic feedback weights, which is considered impossible in a biological neural system [19]. Long-term potentiation (LTP), on the other hand, is considered an essential component of biological memory and learning in cognitive science [16, 4]. In this section, we first briefly describe the LTP mechanism and then propose a biologically more plausible perceptron paradigm."}, {"heading": "3.1 Long-term Potentiation", "text": "Biological neurons are connected by synapses, including axons and dendrites, where the axons emit signals, and dendrites of the next neuron receive the electrical impulses emitted by the axons [8]. However, axons and dendrites are separated by synaptic columns, and the axons emit electrical impulses by releasing ions into the synaptic slit [5]. The ions are captured by receptors on the cell membrane of the dendrites [4, 13]. Architecture is shown in Figure 2. When a synapse transmits neuronal signals from neuron N1 to neuron N2 and is simulated repeatedly, Neuron N2 will release more receptors on its dendrites and thus capture more ions [4]. This process reduces the ion concentration of the synaptic slit between N1 and N2, thereby encouraging N1 to release more ions [4]. Thus, a stronger link between T2 and NP becomes established [based on a stronger NP-4 process]."}, {"heading": "3.2 Biologically Plausible Perceptron Model", "text": "The first step in synaptic adaptation between neurons N1 and N2 is for NFA to adapt the number of receptors on their dendrites, which is an important observation of the LTP process. Based on this principle, we propose a biologically more plausible perceptron (BioPP) model. The components of the BioPP model are described as follows: \u2022 Signals There are two sets of signals in the BioPP architecture - feedback signals: signals propagated forward in the network for inference tasks - Error signals: signals propagated backwards for synaptic weight adaptation. \u2022 Weights represent the quantity of the signal that a perceptron decides to capture from incoming or adjacent neurons."}, {"heading": "4 Training BioPP Networks Bidirectionally", "text": "Both FA and DFA form neural networks with fixed random weights to propagate error signals. In BioPP, we make these weights adaptive as general input weights. For a DNN with 2 hidden layers, the forward activations are calculated as \u2212 \u2192 a 1 = \u2212 \u2192 w1x, \u2212 \u2192 h 1 = \u03c3 (\u2212 \u2192 a 1) (12) \u2212 \u2192 a 2 = \u2212 \u2212 w2 \u2212 \u2192 h 1, \u2212 h 2 = \u03c3 (\u2212 \u2192 a 2) (13) ay = \u2212 \u2192 w3 \u2212 \u2192 h 2, y = \u03c3y (ay) (14) In this section, we propose bidirectional FA (BFA) and bidirectional DFA (BDFA) and describe their training pipeline. We then provide a preliminary analysis of why adaptive feedback weights perform better than fixed feedback weights."}, {"heading": "4.1 Bidirectional-FA", "text": "DNNs with BFA or BDFA learn two maps between the input and the target feedback in two ways. To learn these two maps, we define two loss functions: \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 l \u2212 \u2212 \u2212 errors in predicting error markers and features in the hidden layers or inputs. \u2212 l \u2212 l \u2212 l \u2212 l \u2212 x \u2212 x \u2212 x \u2212 x \u2212 x \u2212 x \u2212 x \u2212 x \u2212 x \u2212 (1 \u2212 y) (15) \u2190 \u2212 x \u00b2 22 (16), where y and x \u00b2 output and predicted inputs are predicted. y and x \u2212 x \u2212 are target output and target inputs. We define the forward weights as \u2212 W and the feedback weights as \u2190 W. The training pipeline includes a forward learning phase and a feedback phase, and processes them iteratively in each batch.The gradient at the source layer is calculated as a result."}, {"heading": "4.2 Bidirectional-DFA", "text": "For BDFA, the loss functions are as follows: \u2212 \u2192 \u2212 l = \u2212 \u2212 \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 \u2212 p \u2212"}, {"heading": "4.3 Approximating BP Gradients with Adaptive Feedback Weights", "text": "In this section, we analyze why adaptive feedback weights used in bidirectional training models are generally better than fixed feedback weights. We demonstrate that overall training performance can be improved if the feedback weights can improve the mapping of output features to input features. In [14], the authors demonstrate that random feedback weights act like the pseudo-inverse of feed-forward weights in the same layer. After the evidence in [14], we consider a linear network with a hidden layer, h = Ax (43) y = Wh, (44) where input feedback weights are, y = output feedback-forward weights. The feedback weight matrix that transfers error signals from output layer to hidden layer is B.Theorem 2 in [14] describes that in FA the pseudo-dient feedback weights are calculated."}, {"heading": "5 Experiments and Discussions", "text": "In this section we examine whether BFA and BDFA can better represent the results of the MNIST and BDFA than the benchmark data sets with different hyperparameter settings. We train MLPs on MNIST and CIFAR-10 data sets. Indeed, the activation functions for hidden layers are set at 128. To make training more stable, the learning rates in all experiments are fixed and set at 0.0001. All models are trained for 300 epochs. All results are based on 5 independent runs. Both MNIST and CIFAR-10 data sets, we use 50,000 samples for training and 10,000 samples for testing. Experimental results on MNIST data sets are summarized in Table 1. We can observe that the BFA model works best on MNIST and BDFA models."}, {"heading": "6 Conclusion", "text": "In this paper, we proposed a biologically plausible perceptron paradigm based on related literature in neuroscience, and designed and evaluated Bidirection Fa and Bidirectional DFA models on benchmark datasets. To our knowledge, this is the first research to show that adaptive asymmetric feedback channels are more effective than random and fixed feedback channels in DNA. Although it is not clear whether the brain implements this particular form of adaptive feedback, it is a step toward a better understanding of how the brain supports learning from error signals."}], "references": [{"title": "Automatic differentiation in machine learning: a survey", "author": ["A.G. Baydin", "B.A. Pearlmutter", "A.A. Radul"], "venue": "arXiv preprint arXiv:1502.05767,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2015}, {"title": "Towards biologically plausible deep learning", "author": ["Y. Bengio", "D.-H. Lee", "J. Bornschein", "Z. Lin"], "venue": "arXiv preprint arXiv:1502.04156,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2015}, {"title": "Towards biologically plausible deep learning", "author": ["Y. Bengio", "D.-H. Lee", "J. Bornschein", "T. Mesnard", "Z. Lin"], "venue": "arXiv preprint arXiv:1502.04156,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}, {"title": "A synaptic model of memory: long-term potentiation in the hippocampus", "author": ["T.V. Bliss", "G.L. Collingridge"], "venue": "Nature, 361(6407):31,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1993}, {"title": "The time course of glutamate in the synaptic cleft", "author": ["J.D. Clements", "R.A. Lester", "G. Tong", "C.E. Jahr", "G.L. Westbrook"], "venue": "SCIENCE-NEW YORK THEN WASHINGTON-, 258:1498\u2013 1498,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1992}, {"title": "Theoretical neuroscience, volume 806", "author": ["P. Dayan", "L.F. Abbott"], "venue": "Cambridge, MA: MIT Press,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2001}, {"title": "Why does unsupervised pre-training help deep learning", "author": ["D. Erhan", "Y. Bengio", "A. Courville", "P.-A. Manzagol", "P. Vincent", "S. Bengio"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2010}, {"title": "A textbook of physiology", "author": ["M. Foster"], "venue": "part iii,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1897}, {"title": "The free-energy principle: a unified brain theory", "author": ["K. Friston"], "venue": "Nature Reviews Neuroscience,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2010}, {"title": "The ups and downs of hebb synapses", "author": ["G. Hinton"], "venue": "Canadian Psychology/Psychologie canadienne, 44(1):10,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2003}, {"title": "Difference target propagation", "author": ["D.-H. Lee", "S. Zhang", "A. Fischer", "Y. Bengio"], "venue": "Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pages 498\u2013515. Springer,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2015}, {"title": "The neuron: cell and molecular biology", "author": ["I.B. Levitan", "L.K. Kaczmarek"], "venue": "Oxford University Press, USA,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2015}, {"title": "Random feedback weights support learning in deep neural networks", "author": ["T.P. Lillicrap", "D. Cownden", "D.B. Tweed", "C.J. Akerman"], "venue": "arXiv preprint arXiv:1411.0247,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2014}, {"title": "Random synaptic feedback weights support error backpropagation for deep learning", "author": ["T.P. Lillicrap", "D. Cownden", "D.B. Tweed", "C.J. Akerman"], "venue": "Nature Communications, 7,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2016}, {"title": "Long-term potentiation and memory", "author": ["M. Lynch"], "venue": "Physiological reviews, 84(1):87\u2013136,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2004}, {"title": "Direct feedback alignment provides learning in deep neural networks", "author": ["A. N\u00f8kland"], "venue": "arXiv preprint arXiv:1609.01596,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2016}, {"title": "Biologically plausible error-driven learning using local activation differences: The generalized recirculation algorithm", "author": ["R.C. O\u2019Reilly"], "venue": "Neural computation,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1996}, {"title": "Learning representations by backpropagating errors", "author": ["D.E. Rumelhart", "G.E. Hinton", "R.J. Williams"], "venue": "Cognitive modeling, 5(3):1,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1988}, {"title": "Training language models using target-propagation", "author": ["S. Wiseman", "S. Chopra", "M. Ranzato", "A. Szlam", "R. Sun", "S. Chintala", "N. Vasilache"], "venue": "arXiv preprint arXiv:1702.04770,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2017}], "referenceMentions": [{"referenceID": 0, "context": "1 Introduction Back-propagation (BP) algorithm is the combination of reverse-mode automatic differentiation [1] and steepest descent [10] which has been considered the de-facto method for training deep neural networks (DNNs).", "startOffset": 108, "endOffset": 111}, {"referenceID": 5, "context": "However, it has been argued that it is not biologically possible for learning in the brain to involve precise, symmetric backward channels [6, 15, 3, 12].", "startOffset": 139, "endOffset": 153}, {"referenceID": 13, "context": "However, it has been argued that it is not biologically possible for learning in the brain to involve precise, symmetric backward channels [6, 15, 3, 12].", "startOffset": 139, "endOffset": 153}, {"referenceID": 2, "context": "However, it has been argued that it is not biologically possible for learning in the brain to involve precise, symmetric backward channels [6, 15, 3, 12].", "startOffset": 139, "endOffset": 153}, {"referenceID": 10, "context": "However, it has been argued that it is not biologically possible for learning in the brain to involve precise, symmetric backward channels [6, 15, 3, 12].", "startOffset": 139, "endOffset": 153}, {"referenceID": 6, "context": "In the early days of deep learning, unsupervised pre-training with Boltzmann machines used to be applied before fine-tuning with BP [7], which does not involve symmetric weights and is biologically motivated.", "startOffset": 132, "endOffset": 135}, {"referenceID": 18, "context": "In [21], target-propagation (TP)[12], whose objective is to let each layer to reproduce outputs the previous layer, is used to train a recurrent neural network for natural language processing tasks.", "startOffset": 3, "endOffset": 7}, {"referenceID": 10, "context": "In [21], target-propagation (TP)[12], whose objective is to let each layer to reproduce outputs the previous layer, is used to train a recurrent neural network for natural language processing tasks.", "startOffset": 32, "endOffset": 36}, {"referenceID": 13, "context": "The authors in [15] propose feedback-alignment (FA) model and showed that for BP-like methods, the weights used in the feedback pass do not have to be the transpose of feedforward weights.", "startOffset": 15, "endOffset": 19}, {"referenceID": 15, "context": "The direct feedback-alignment (DFA) model proposed in [17] suggest that error signals could be transmitted directly from output layer to any hidden layer with random and fixed matrices.", "startOffset": 54, "endOffset": 58}, {"referenceID": 14, "context": "On the other hand, due to the literature in neuroscience, long-term potentiation (LTP) is considered an essential step in human memory and learning [16, 4].", "startOffset": 148, "endOffset": 155}, {"referenceID": 3, "context": "On the other hand, due to the literature in neuroscience, long-term potentiation (LTP) is considered an essential step in human memory and learning [16, 4].", "startOffset": 148, "endOffset": 155}, {"referenceID": 1, "context": "Based on the principles of LTP and the hypothesis that the feedback weights are plastic [2], we propose a more biological plausible perceptron paradigm and two bidirectional learning models.", "startOffset": 88, "endOffset": 91}, {"referenceID": 15, "context": "(Modified from [17]).", "startOffset": 15, "endOffset": 19}, {"referenceID": 12, "context": "2 Background Following the notation in [14], let (x, y) be a mini-batch of input-output of size 1.", "startOffset": 39, "endOffset": 43}, {"referenceID": 2, "context": "Although FA and DFA with random and fixed feedback weights are more biologically plausible than BP, the feedback weights in the brain are plastic too [3].", "startOffset": 150, "endOffset": 153}, {"referenceID": 13, "context": "It has been shown in [15] that the forward weights wi used in FA learns to resemble the pseudo-inverse of the feedback random weights Bi.", "startOffset": 21, "endOffset": 25}, {"referenceID": 17, "context": "3 Biologically Plausible Perceptron Classical perceptrons trained with gradient descent algorithms need to back-propagate error signals based on the exact feedforward synaptic weights, which is considered impossible in a biological neural system [19].", "startOffset": 246, "endOffset": 250}, {"referenceID": 14, "context": "On the other hand, long-term potentiation (LTP) is considered an essential part of biological memory and learning in cognitive science [16, 4].", "startOffset": 135, "endOffset": 142}, {"referenceID": 3, "context": "On the other hand, long-term potentiation (LTP) is considered an essential part of biological memory and learning in cognitive science [16, 4].", "startOffset": 135, "endOffset": 142}, {"referenceID": 7, "context": "1 Long-term Potentiation Biological neurons are connected by synapse, including axons and dendrites, where axons emit signals, and dendrites of the next neuron receive the electrical impulses released by axons [8].", "startOffset": 210, "endOffset": 213}, {"referenceID": 4, "context": "However, axons and dendrites are separated by synaptic clefts, and the axons send electrical impulses by releasing ions into synaptic cleft [5].", "startOffset": 140, "endOffset": 143}, {"referenceID": 3, "context": "The ions are captured by receptors on the cell membrane of dendrites [4, 13].", "startOffset": 69, "endOffset": 76}, {"referenceID": 11, "context": "The ions are captured by receptors on the cell membrane of dendrites [4, 13].", "startOffset": 69, "endOffset": 76}, {"referenceID": 3, "context": "When a synapse transmits neural signals from neuron N1 to neuron N2 and is repeatedly simulated, neuron N2 will release more receptors on its dendrites and thus capture more ions [4].", "startOffset": 179, "endOffset": 182}, {"referenceID": 3, "context": "This procedure reduces the ion concentration of the synaptic cleft between N1 and N2, which encourages N1 to release more ions [4].", "startOffset": 127, "endOffset": 130}, {"referenceID": 3, "context": "Thus, a stronger connection between neuron N1 and N2 is established due to the LTP procedure [4].", "startOffset": 93, "endOffset": 96}, {"referenceID": 3, "context": "LTP adjusts links among neurons and plays a significant role in forming memory and learning [4].", "startOffset": 92, "endOffset": 95}, {"referenceID": 15, "context": "(Modified from [17]).", "startOffset": 15, "endOffset": 19}, {"referenceID": 10, "context": "The difference between BFA and target propagation (TP) proposed in [12] is that BFA learns the input features and propagate error signal layer by layer, while each layer in TP learns the output of previous layer with an autoencoder.", "startOffset": 67, "endOffset": 71}, {"referenceID": 15, "context": "(Modified from [17]).", "startOffset": 15, "endOffset": 19}, {"referenceID": 12, "context": "In [14] the authors prove that random feedback weights act like the pseudoinverse of feedforward weights in the same layer.", "startOffset": 3, "endOffset": 7}, {"referenceID": 12, "context": "Following the proof in [14], we consider a linear network with one hidden layer,", "startOffset": 23, "endOffset": 27}, {"referenceID": 12, "context": "Theorem 2 in [14] describes that in FA, the pseudogradients \u03b4FAh calculated by the random feedback weights satisfy", "startOffset": 13, "endOffset": 17}, {"referenceID": 12, "context": "As shown in Equation (75) in [14],", "startOffset": 29, "endOffset": 33}, {"referenceID": 0, "context": "For example, the output feature of digit \u201c4\" is [0, 0, 0, 0, 1, 0, 0, 0, 0, 0].", "startOffset": 48, "endOffset": 78}, {"referenceID": 15, "context": "DFA faces the similar issue when learning convolutional weights on CIFAR-10 [17], which tried to learn transmitting error signal from output layer directly to convolutional layers.", "startOffset": 76, "endOffset": 80}, {"referenceID": 9, "context": "This learning process for feedback updating of BDFA is also consistent with the insight [11, 18, 9] that errors can result from mismatches between the actual and the expected perceptions, rather than coming from external teaching signals.", "startOffset": 88, "endOffset": 99}, {"referenceID": 16, "context": "This learning process for feedback updating of BDFA is also consistent with the insight [11, 18, 9] that errors can result from mismatches between the actual and the expected perceptions, rather than coming from external teaching signals.", "startOffset": 88, "endOffset": 99}, {"referenceID": 8, "context": "This learning process for feedback updating of BDFA is also consistent with the insight [11, 18, 9] that errors can result from mismatches between the actual and the expected perceptions, rather than coming from external teaching signals.", "startOffset": 88, "endOffset": 99}], "year": 2017, "abstractText": "The back-propagation (BP) algorithm has been considered the de-facto method for training deep neural networks. It back-propagates errors from the output layer to the hidden layers in an exact manner using the transpose of the feedforward weights. However, it has been argued that this is not biologically plausible because back-propagating error signals with the exact incoming weights is not considered possible in biological neural systems. In this work, we propose a biologically plausible paradigm of neural architecture based on related literature in neuroscience and asymmetric BP-like methods. Specifically, we propose two bidirectional learning algorithms with trainable feedforward and feedback weights. The feedforward weights are used to relay activations from the inputs to target outputs. The feedback weights pass the error signals from the output layer to the hidden layers. Different from other asymmetric BP-like methods, the feedback weights are also plastic in our framework and are trained to approximate the forward activations. Preliminary results show that our models outperform other asymmetric BP-like methods on the MNIST and the CIFAR-10 datasets. The source code of this paper can be obtained from https://github.com/SkTim/bdfa-torch.", "creator": "LaTeX with hyperref package"}}}