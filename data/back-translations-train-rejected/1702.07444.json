{"id": "1702.07444", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Feb-2017", "title": "Bandits with Movement Costs and Adaptive Pricing", "abstract": "We extend the model of Multi-armed Bandit with unit switching cost to incorporate a metric between the actions. We consider the case where the metric over the actions can be modeled by a complete binary tree, and the distance between two leaves is the size of the subtree of their least common ancestor, which abstracts the case that the actions are points on the continuous interval $[0,1]$ and the switching cost is their distance. In this setting, we give a new algorithm that establishes a regret of $\\widetilde{O}(\\sqrt{kT} + T/k)$, where $k$ is the number of actions and $T$ is the time horizon. When the set of actions corresponds to whole $[0,1]$ interval we can exploit our method for the task of bandit learning with Lipschitz loss functions, where our algorithm achieves an optimal regret rate of $\\widetilde{\\Theta}(T^{2/3})$, which is the same rate one obtains when there is no penalty for movements. As our main application, we use our new algorithm to solve an adaptive pricing problem. Specifically, we consider the case of a single seller faced with a stream of patient buyers. Each buyer has a private value and a window of time in which they are interested in buying, and they buy at the lowest price in the window, if it is below their value. We show that with an appropriate discretization of the prices, the seller can achieve a regret of $\\widetilde{O}(T^{2/3})$ compared to the best fixed price in hindsight, which outperform the previous regret bound of $\\widetilde{O}(T^{3/4})$ for the problem.", "histories": [["v1", "Fri, 24 Feb 2017 01:51:48 GMT  (32kb)", "http://arxiv.org/abs/1702.07444v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.GT", "authors": ["tomer koren", "roi livni", "yishay mansour"], "accepted": false, "id": "1702.07444"}, "pdf": {"name": "1702.07444.pdf", "metadata": {"source": "CRF", "title": "Bandits with Movement Costs and Adaptive Pricing", "authors": ["Tomer Koren"], "emails": ["tkoren@google.com", "rlivni@cs.princeton.edu", "mansour@tau.ac.il"], "sections": [{"heading": null, "text": "ar Xiv: 170 2.07 444v 1 [cs.L G] 24 Feb 20? kT'T {kq, where k is the number of actions and T is the time horizon. If the number of actions corresponds to the total r0, 1s interval, we can use our method for the task of bandit learning with Lipschitz loss functions, where our algorithm achieves an optimal rate of repentance of r.pT 2 {3q, which is the same rate you get when there is no penalty for movements. As our main application, we use our new algorithm to solve an adaptive price problem. Specifically, we consider the case of a single seller facing a stream of patient buyers. Each buyer has a private value and a window of time in which he is interested in buying, and he purchases at the lowest price in the window when it is below his value. We show that the seller with a reasonable discrediting of the prices can achieve a rate of repentance {2 T in comparison to the previous price {Opq 3q in comparison to the price fixed price compared to the previous price)."}, {"heading": "1 Introduction", "text": "The question that arises is whether it is actually a \"real\" case or a \"pure\" case in which it is a \"real\" case, a \"pure\" case, a \"real\" case, a \"real\" act, a \"real\" act, a \"real\" act, a \"real\" act, a \"real\" act, \"a\" real \"act,\" a \"real\" act, \"a\" real \"act,\" a \"real\" act, \"a\" real \"act,\" a \"real\" act, \"a\" real \"act,\" a \"real\" act, \"a\" real \"act,\" a \"real\" act, \"a\" real \"act,\" a \"real\" real, \"a\" real, \"a\" real, \"a\" real, \"a\" real, \"a\" real, \"a\" real, \"a\" real, \"a\" real, \"a\" real, \"a\" real, \"a\" real, a \"real,\" a \"real,\" a \"real,\" a \"real,\" a \"real,\" a \"real,\" a \"real,\" a \"real,\" a \"real,\" a \"a\" real, \"a\" real, \"a\" real, \"a\" a \"real,\" a \"real,\" a \"a\" real, a \"real, a\" a \"real, a\" a \"real, a\" real, a \"a\" real, a \"a\""}, {"heading": "1.1 Related Work", "text": "In fact, it is so that the greater of them will be able to interfere in politics, namely in the economy, in the economy, in the economy, in the economy, in the economy, in the economy, in the economy, in the economy, in the economy, in the society, in the society, in the society, in the society, in the society, in the society, in the society, in the society, in the society, in the society, in the society, in the society, in the society, in the society, in the society, in the society, in the society, in the society, in the society, in the society, in the society, in the society, in the society, in the politics, in the society, in the society, in the society, in the society, in the society, in the society, in the society, in the society, in the society, in the society, in the society, in the society, in the society, in the society, in the society, in the society, in the society, in the society, in the society, in the society, in the society, in the society, in the society, in the society, in the society, in the society, in the society, in the society, in the politics, in the society, in the society, in the society, in the society, in the society, in the society, in the society, in the society, the society, in the society, the society, in the society, the society, the society, in the society, the society, the society, in the society, the society, the society, the society, in the society, the society, the society, the society, the society, the society, in the society, the society, the society, the society, the society, the society, the society, the society, the society, the society, the society in the society, the society, the society, the society, the society, the society, the society, the society, the society, the society, the society, the society in the society, the society, the society, the society, the society, the society, the society, the society, the society, the society, the society, the society, the society, the society, the society, the society, the society, the society, the society, the society, the society, the society, the society, the society, the society, the"}, {"heading": "2 Setup and Formal Statement of Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Bandits with Movement Costs", "text": "In this section, we also consider the costs that it incurs for the movement. \"We have the costs that we have to incur for the movement.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"\" We. \"\" \"We.\" \"\" We. \".\" \"\" We. \".\" \"\" We. \".\" \"\" We. \".\" \"\" We. \"\". \"\" \"We.\" \"\" \".\" \"\" We. \"\". \"\" \"We.\" \".\" \"\" \"We.\" \"\". \"\" \"\" We. \"\" \".\" \"\" \".\" \"\" We.... \"\" \"\" \"\". \"\""}, {"heading": "2.2 Adaptive Pricing", "text": "We consider the following model of online learning, in terms of a stream of patient buyers with patience in most places. In our setting the seller posts at the time t \"1. Prices at the time 1,.., 2 for the next two days in advance. Then, at any time step t the seller posts price for the t.\" turnover. Each buyer, in our setting, is a mapping of a sequence of prices on the receipts, parameterized by their value vt and their patience. The buyer proceeds by observing the prices...,. and purchases the item at the lowest price below these prices if it does not exceed their value. Thus, the receipts of the buyer are not exceeded at the time."}, {"heading": "3 Overview of the approach and techniques", "text": "In this section, we give an informal overview of the main ideas in the paper and describe the techniques used in our solution. \"We start with the main ideas behind our main results: an optimal and efficient algorithm for managing movement costs.\" (\"There is only one problem that we are able to reduce costs.\") (\"There is only one problem that we are able to reduce costs.\") As a preliminary stage, we use discretion to capture the scope of action and capture the setting of the MAB framework. \"(\" We reduce the problem of minimizing over the entire r0, 1s interval. \"(\" We regret the minimization of the measures associated with the equivalent points K \"t, 1k, 2 k.)"}, {"heading": "4 The Slowly Moving Bandit Algorithm", "text": "In this section, we introduce the SMB algorithms in Algorithm 1. \"This is the method that is based on the SMB algorithms.\" \"This is the method that is based on the SMB algorithms.\" \"This is the method that is based on the SMB algorithms.\" \"This is the method that we apply at the SMB level.\" \"This is the method that we apply at the SMB level.\" \"This is the method that we apply at the SMB level.\" \"This is the method that we apply at the d-0 level.\" \"The SMB algorithms that we apply at the d-0 level.\" \"The SMB algorithms that we apply at the d-0 level.\" \"The SMB algorithms that we apply at the d-0 level.\" The SMB algorithms that we apply at the MB level. \"The MB algorithms that we apply at the SMB level.\" The SMB level."}, {"heading": "4.1 Rebalancing the marginals", "text": "The first step is to show that the marginals of distributions over the sub-trees of actions are not altered by the algorithm with high probability, as a result of the addition of the compensation vectors, d.Lemma 7 \"If we have the pt.\" 1pAq \"1\" 1 then: \"iPAptpiqe\" 1 \"1.\" \"We need the next technical result over the compensation vectors, d.Lemma 7.\" \"If we have the pt.\".1 \"1\" then: \"iPAptpiqe\" 1. \"\" We need the next technical result over the compensation vectors, d.2. \""}, {"heading": "4.2 Lazy sampling", "text": "\"We must prepare ourselves to move on to the next step.\" \"We must prepare ourselves to be able to do it.\" \"We must do it.\" \"We will do it.\" \"We will do it.\" \"We will do it.\" \"We will do it.\" \"We will do it.\" \"We will do it.\" \"We will do it.\" \"We will do it.\" \"We will do it.\" \"We will do it.\" \"We will do it.\" \"We will do it.\" \"We will do it.\" \"We will do it.\" \"\" We will do it. \"\" We will do it. \"\" We will do it. \"\" \"We will do it.\" \"\" We will do it. \"\" We will do it. \"\" We will do it. \"\" We will do it. \"\""}, {"heading": "4.3 Bounding the bias and variance", "text": "\"Next, we will deal with the losses,\" he said. \"We will not overestimate the losses.\" \"We will not overestimate the losses.\" \"We will not overestimate the losses.\" \"We will not overestimate the losses.\" \"We will not overestimate them.\" \"We will not overestimate them.\" \"We will not overestimate them.\" \"We will not overestimate them.\" \"\" We will not overestimate them. \"\" \"We will not overestimate them.\" \"\" We will not overestimate them. \"\" \"\" \"We will not overestimate them.\" \"\". \"\" \"\". \"\" \".\" \"\" \".\" \"\" \"\". \"\" \"\". \"\" \"\" \".\" \"\" \".\" \"\". \"\" \"\". \"\" \".\" \".\" \".\" \".\" \".\". \"\". \".\". \".\". \".\". \".\" \"\". \".\". \".\" \"\". \"\". \"\". \"\" \".\". \".\". \"\". \".\". \"\". \"\" \".\". \".\" \".\". \".\". \".\". \".\". \".\". \".\". \"..\"......... \".................\" \"\" \"\" \"............................\" \"\" \"\" \"\" \"\" \"\" \"\".............. \"\" \"\" \"\" \"\" \"\" \"\"........ \"\" \"\" \"\"....... \"\" \"\" \"\" \"\" \"\".... \"\". \"\" \"\" \"\". \"\" \".\" \"..\". \"\" \".\" \".\" \".\". \".\" \".\" \".\". \"\". \"\". \".\" \".\". \".\" \".\". \".\". \".\". \".\". \".\". \".\". \""}, {"heading": "4.4 Concluding the proof", "text": "In order to provide proof and obtain a \"regret,\" we will apply the following known \"second order regrets\" with respect to the multiplicative weights (MW), which are essentially conditioned by [15] (see also [2] for the version given here). For completeness, we shall provide proof of this \"regret\" with respect to section 4.5 under \"second order regrets.\" Let us leave \"second order regrets\" with respect to \"regrets\" with respect to \"second order regrets\" with respect to \"regrets\" with regard to \"second order regrets\" with regard to \"regrets\" with regard to \"second order regrets.\" Let us leave \"\" regrets \"with regard to\" terms with regard to \"second order regrets,\" with regard to \"with regard to\" second order regrets, \"with regard to\" with regard to \"terms with regard to\" regret, \"with regard to\" with regard to \"with regard to\" second order, \"with regard to\" with regard to \"with regard to\" with regard to \"regret,\" with regard to \"with regard to\" with regard to \"with regard to\" with regard to \"with regard to\" with regard to \"with regard to\" with regard to \"with regard to\" with regard to \"with regard to\" with regard to \"with regard to\" with regard to \"with regard to\" with regard to \"with regard to\" with regard to \"with regard to\" with regard to \"with regard to\" with regard to \"with regard to\" with regard to \"with regard to\" with regard to terms with regard to \"with regard to\" with regard to \"with regard to\" with regard to \"with regard to\" with regard to \"with regard to terms with regard to\" with regard to \"with regard to\" with regard to \"with regard to\" with regard to \"with regard to\" with regard to \"with regard to terms with regard to\" with regard to \"with regard to\" with regard to terms with regard to \"with regard to\" with regard to \"with regard to\" with regard to \"with regard to\" with regard to \"with regard to\" with regard to terms with regard to \"with regard to terms with regard to\" with regard to \"with regard to\" with regard to \"with regard to\" with regard to \"with regard to\" with regard to \"with regard to\" with regard to"}, {"heading": "4.5 Additional technical proofs", "text": "Here, we provide evidence of our technical problem, which is the order of magnitude of the balancing terms \"Q1,\" \"Q1,\" \"Q1,\" \"Q1,\" \"Q1,\" \"Q1,\" \"Q1,\" \"Q1,\" \"Q1,\" \"Q1,\" \"Q1,\" \"Q1,\" \"\" Q1, \"\" \"Q1,\" \"\" Q1, \"\" \"\" Q1, \"\" \"\" Q1, \"\" \"\" Q1, \"\" \"\" Q1, \"\" \"\", \"\" \",\" \"\", \"\" \",\" \"\", \"\" \",\" \"\" \",\" \"\", \"\" \"\", \"\" \",\" \"\", \"\" \",\" \",\" \"\", \"\", \"\", \"\", \"\" \",\" \",\" \"\", \"\" \",\", \"\" \",\" \",\", \"\", \",\" \",\" \",\" \",\" \"\", \",\" \"\" \",\" \",\", \"\" \",\" \"\" \",\" \"\", \"\", \"\", \"\" \",\" \",\" \",\" \"\" \",\", \"\", \"\" \",\" \"\""}, {"heading": "4.6 Learning Continuum\u2013Arm Bandit with Lipschitz Loss Functions", "text": "In this section, we show how to Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-"}, {"heading": "5 Online Pricing with Patient Buyers", "text": "In this section, we present our reduction of adaptive pricing with patient buyers to a MAB with movement costs. The reduction is presented in algorithm 2 and uses our algorithm for MAB with movement costs (algorithm 1) as a black box. The algorithm divides the time interval T into revenue-related blocks and updates of the price of T \"T\" {turnover round 1. \"In each round, the algorithm publishes a fixed price for the entire block of consecutive days. Then, as feedback, the algorithm receives the mean revenue for these days, which we call Byr1t\" 1kp. \"1kp.\" p., \"1kp.p.,\" which can refer to the algorithms as an online algorithm over T rounds: where in each round the algorithm announces a fixed action, 1t \"1 (the price for the next few days) and receives at the end of the round as feedback r1t.\""}], "references": [{"title": "Online learning in markov decision processes with adversarially chosen transition probability distributions", "author": ["Yasin Abbasi", "Peter L Bartlett", "Varun Kanade", "Yevgeny Seldin", "Csaba Szepesvari"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2013}, {"title": "Online learning with feedback graphs: Beyond bandits", "author": ["Noga Alon", "Nicol\u00f2 Cesa-Bianchi", "Ofer Dekel", "Tomer Koren"], "venue": "In Proceedings of The 28th Conference on Learning Theory,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2015}, {"title": "Minimax policies for adversarial and stochastic bandits", "author": ["Jean-Yves Audibert", "S\u00e9bastien Bubeck"], "venue": "In COLT,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2009}, {"title": "Improved rates for the stochastic continuum-armed bandit problem", "author": ["P. Auer", "R. Ortner", "C. Szepesv\u00e1ri"], "venue": "Proceedings of the 20th Annual Conference on Learning Theory, pages 454\u2013 468", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2007}, {"title": "The nonstochastic multiarmed bandit problem", "author": ["Peter Auer", "Nicolo Cesa-Bianchi", "Yoav Freund", "Robert E Schapire"], "venue": "SIAM Journal on Computing,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2002}, {"title": "Approximation algorithms and online mechanisms for item pricing", "author": ["Maria-Florina Balcan", "Avrim Blum"], "venue": "In Proceedings of the 7th ACM Conference on Electronic Commerce,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2006}, {"title": "Sequential item pricing for unlimited supply", "author": ["Maria-Florina Balcan", "Florin Constantin"], "venue": "In International Workshop on Internet and Network Economics,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2010}, {"title": "Item pricing for revenue maximization", "author": ["Maria-Florina Balcan", "Avrim Blum", "Yishay Mansour"], "venue": "In Proceedings of the 9th ACM conference on Electronic commerce,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2008}, {"title": "Dynamic pricing for impatient bidders", "author": ["Nikhil Bansal", "Ning Chen", "Neva Cherniavsky", "Atri Rurda", "Baruch Schieber", "Maxim Sviridenko"], "venue": "ACM Transactions on Algorithms (TALG),", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2010}, {"title": "Probabilistic approximations of metric spaces and its algorithmic applications", "author": ["Yair Bartal"], "venue": "Annual Symposium on Foundations of Computer Science,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1996}, {"title": "Dynamic pricing without knowing the demand function: Risk bounds and near-optimal algorithms", "author": ["Omar Besbes", "Assaf Zeevi"], "venue": "Operations Research,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2009}, {"title": "X -armed bandits", "author": ["S. Bubeck", "R. Munos", "G. Stoltz", "C. Szepesv\u00e1ri"], "venue": "Journal of Machine Learning Research, 12:1587\u20131627", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2011}, {"title": "Regret analysis of stochastic and nonstochastic multi-armed bandit problems", "author": ["S\u00e9bastien Bubeck", "Nicol\u00f2 Cesa-Bianchi"], "venue": "Foundations and Trends in Machine Learning,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "Kernel-based methods for bandit convex optimization", "author": ["S\u00e9bastien Bubeck", "Ronen Eldan", "Yin Tat Lee"], "venue": "arXiv preprint arXiv:1607.03084,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2016}, {"title": "Improved second-order bounds for prediction with expert advice", "author": ["Nicolo Cesa-Bianchi", "Yishay Mansour", "Gilles Stoltz"], "venue": "Machine Learning,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2007}, {"title": "Regret and convergence bounds for a class of continuum-armed bandit problems", "author": ["E.W. Cope"], "venue": "IEEE Transactions on Automatic Control, 54(6):1243\u20131253", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2009}, {"title": "The price of bandit information for online optimization", "author": ["Varsha Dani", "Sham M Kakade", "Thomas P Hayes"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2007}, {"title": "Bandits with switching costs: T2/3 regret", "author": ["Ofer Dekel", "Jian Ding", "Tomer Koren", "Yuval Peres"], "venue": "In Symposium on Theory of Computing,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2014}, {"title": "The blinded bandit: Learning with adaptive feedback", "author": ["Ofer Dekel", "Elad Hazan", "Tomer Koren"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2014}, {"title": "Online pricing with strategic and patient buyers", "author": ["Michal Feldman", "Tomer Koren", "Roi Livni", "Yishay Mansour", "Aviv Zohar"], "venue": "In Annual Conference on Neural Information Processing Systems,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2016}, {"title": "Multi-armed bandits with metric switching costs", "author": ["Sudipto Guha", "Kamesh Munagala"], "venue": "In International Colloquium on Automata, Languages, and Programming,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2009}, {"title": "Sharp dichotomies for regret minimization in metric spaces. In Proceedings of the twenty-first annual ACM-SIAM symposium on Discrete Algorithms, pages 827\u2013846", "author": ["Robert Kleinberg", "Aleksandrs Slivkins"], "venue": "Society for Industrial and Applied Mathematics,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2010}, {"title": "Multi-armed bandits in metric spaces", "author": ["Robert Kleinberg", "Aleksandrs Slivkins", "Eli Upfal"], "venue": "In Proceedings of the fortieth annual ACM symposium on Theory of computing,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2008}, {"title": "Nearly tight bounds for the continuum-armed bandit problem", "author": ["Robert D. Kleinberg"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2004}, {"title": "The value of knowing a demand curve: Bounds on regret for online posted-price auctions", "author": ["Robert D. Kleinberg", "Frank Thomson Leighton"], "venue": "In 44th Symposium on Foundations of Computer Science FOCS,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2003}, {"title": "Multi-armed bandits on implicit metric spaces", "author": ["Aleksandrs Slivkins"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2011}, {"title": "Ranked bandits in metric spaces: learning diverse rankings over large document collections", "author": ["Aleksandrs Slivkins", "Filip Radlinski", "Sreenivas Gollapudi"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2013}, {"title": "Unimodal bandits", "author": ["J.Y. Yu", "S. Mannor"], "venue": "Proceedings of the 28th International Conference on Machine Learning", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2011}], "referenceMentions": [{"referenceID": 0, "context": "Unfortunately, for the adversarial setting there are mostly hardness results even in limited cases [1].", "startOffset": 99, "endOffset": 102}, {"referenceID": 17, "context": "In such a setting a tight bound of r \u0398pk1{3T 2{3q is known [18].", "startOffset": 59, "endOffset": 63}, {"referenceID": 17, "context": "[18], which applies already for k \u201c 2 actions.", "startOffset": 0, "endOffset": 4}, {"referenceID": 4, "context": "The bound of r \u0398p ? kT q for k \u011b T 1{3 is tight due to the classic lower bound for MAB even without movement costs [5].", "startOffset": 115, "endOffset": 118}, {"referenceID": 19, "context": "The main application of our SMB algorithm is for adaptive pricing with patient buyers [20].", "startOffset": 86, "endOffset": 90}, {"referenceID": 19, "context": "This is in contrast to a regret of r OpT 3{4q which is achieved by applying a standard switching cost technique together with a discretization argument [20].", "startOffset": 152, "endOffset": 156}, {"referenceID": 17, "context": ", when switching between any two actions has a unit cost), it is known that there is a tight r \u03a9pk1{3T 2{3q lower bound for the MAB problem [18], which is in contrast to the Op ? kT q regret upper bound without switching costs.", "startOffset": 140, "endOffset": 144}, {"referenceID": 4, "context": "Classical MAB algorithms such as Exp3 [5] guarantee a regret of r Op ? kT q without movement costs.", "startOffset": 38, "endOffset": 41}, {"referenceID": 19, "context": "[20].", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "There is a slight difference in the exact feedback model between [20] and here: in both models when a buyer arrives, the sell time is uniquely determined; however, in [20] the seller observes the purchase only at the actual time of the sell, whereas here we assume the seller observes the sell when the buyer arrives and decides when to purchase.", "startOffset": 65, "endOffset": 69}, {"referenceID": 19, "context": "There is a slight difference in the exact feedback model between [20] and here: in both models when a buyer arrives, the sell time is uniquely determined; however, in [20] the seller observes the purchase only at the actual time of the sell, whereas here we assume the seller observes the sell when the buyer arrives and decides when to purchase.", "startOffset": 167, "endOffset": 171}, {"referenceID": 19, "context": "We remark, though, that as discussed in [20] all lower bounds derived there apply to the current feedback model too.", "startOffset": 40, "endOffset": 44}, {"referenceID": 24, "context": "For the case of continuous prices and a single seller, when one consider impatient buyers, a simple discretization argument can be used to achieve a regret of r OpT 2{3q, and there exists a similar lower bound of \u03a9pT 2{3q [25].", "startOffset": 222, "endOffset": 226}, {"referenceID": 23, "context": "More generally, learning Lipschitz functions on a closed interval has been studied by Kleinberg [24], where an optimal r \u0398pT 2{3q regret bound is shown via discretization.", "startOffset": 96, "endOffset": 100}, {"referenceID": 23, "context": "There are many works on continuous action MAB [24, 16, 4, 12, 28].", "startOffset": 46, "endOffset": 65}, {"referenceID": 15, "context": "There are many works on continuous action MAB [24, 16, 4, 12, 28].", "startOffset": 46, "endOffset": 65}, {"referenceID": 3, "context": "There are many works on continuous action MAB [24, 16, 4, 12, 28].", "startOffset": 46, "endOffset": 65}, {"referenceID": 11, "context": "There are many works on continuous action MAB [24, 16, 4, 12, 28].", "startOffset": 46, "endOffset": 65}, {"referenceID": 27, "context": "There are many works on continuous action MAB [24, 16, 4, 12, 28].", "startOffset": 46, "endOffset": 65}, {"referenceID": 22, "context": "Specifically, there is an extensive literature on the Lipschitz MAB problem and various variants thereof [23, 26, 27, 22], where the expectation of the reward of arms have a Lipschitz property.", "startOffset": 105, "endOffset": 121}, {"referenceID": 25, "context": "Specifically, there is an extensive literature on the Lipschitz MAB problem and various variants thereof [23, 26, 27, 22], where the expectation of the reward of arms have a Lipschitz property.", "startOffset": 105, "endOffset": 121}, {"referenceID": 26, "context": "Specifically, there is an extensive literature on the Lipschitz MAB problem and various variants thereof [23, 26, 27, 22], where the expectation of the reward of arms have a Lipschitz property.", "startOffset": 105, "endOffset": 121}, {"referenceID": 21, "context": "Specifically, there is an extensive literature on the Lipschitz MAB problem and various variants thereof [23, 26, 27, 22], where the expectation of the reward of arms have a Lipschitz property.", "startOffset": 105, "endOffset": 121}, {"referenceID": 20, "context": "The work of Guha and Munagala [21] discusses a stochastic MAB, in the spirit of the Gittins index, where there is both a switching cost and a play cost, and gives a constant approximation algorithm.", "startOffset": 30, "endOffset": 34}, {"referenceID": 9, "context": ", k-HST) has a long history in the online algorithms literature, starting with the work of Bartal [10].", "startOffset": 98, "endOffset": 102}, {"referenceID": 17, "context": "In any movement cost problem with at least two arms of fixed constant distance, a lower bound regret of 2-arm switching cost applies, hence we observe that these rates are optimal for every k \u010f T [18].", "startOffset": 196, "endOffset": 200}, {"referenceID": 23, "context": "We emphasize that even without movement costs, there is an r \u03a9pT 2{3q lower bound in this setting [24]; hence, the regret bound of Theorem 2 is essentially optimal.", "startOffset": 98, "endOffset": 102}, {"referenceID": 19, "context": "[20] where the buyer buy at day of purchase.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "Indeed, Kleinberg and Leighton [25] showed that optimizing over the continuum r0, 1s leads to a lower bound of \u03a9pT 2{3q, irrespective of the patience of the buyers.", "startOffset": 31, "endOffset": 35}, {"referenceID": 19, "context": "[20] showed that whenever the seller wishes to optimize between more than two prices, a lower bound of \u03a9pT 2{3q holds for patient buyers.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[20] constructed a sequence of buyers that reduces the problem to MAB with switching cost: a step in demonstrating a \u03a9pT 2{3q regret bound: thus a fluctuation in prices is indeed a cause for a high regret.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "We employ a reduction similar to the one used by [25]; however, the patience of the buyers introduce some difficulties, as we discuss below.", "startOffset": 49, "endOffset": 53}, {"referenceID": 4, "context": "The algorithm is based on the multiplicative update method, and in that sense is reminiscent of the Exp3 algorithm [5].", "startOffset": 115, "endOffset": 118}, {"referenceID": 14, "context": "4 Concluding the proof To conclude the proof and obtain a regret bound, we will use the following well-known second-order regret bound for the multiplicative weights (MW) method, essentially due to [15] (see also [2] for the version given here).", "startOffset": 198, "endOffset": 202}, {"referenceID": 1, "context": "4 Concluding the proof To conclude the proof and obtain a regret bound, we will use the following well-known second-order regret bound for the multiplicative weights (MW) method, essentially due to [15] (see also [2] for the version given here).", "startOffset": 213, "endOffset": 216}, {"referenceID": 18, "context": "Algorithm 2 overcomes this issue by employing techniques from [19] for handling adaptive feedback.", "startOffset": 62, "endOffset": 66}], "year": 2017, "abstractText": "We extend the model of Multi-armed Bandit with unit switching cost to incorporate a metric between the actions. We consider the case where the metric over the actions can be modeled by a complete binary tree, and the distance between two leaves is the size of the subtree of their least common ancestor, which abstracts the case that the actions are points on the continuous interval r0, 1s and the switching cost is their distance. In this setting, we give a new algorithm that establishes a regret of r Op ? kT ` T {kq, where k is the number of actions and T is the time horizon. When the set of actions corresponds to whole r0, 1s interval we can exploit our method for the task of bandit learning with Lipschitz loss functions, where our algorithm achieves an optimal regret rate of r \u0398pT 2{3q, which is the same rate one obtains when there is no penalty for movements. As our main application, we use our new algorithm to solve an adaptive pricing problem. Specifically, we consider the case of a single seller faced with a stream of patient buyers. Each buyer has a private value and a window of time in which they are interested in buying, and they buy at the lowest price in the window, if it is below their value. We show that with an appropriate discretization of the prices, the seller can achieve a regret of r OpT 2{3q compared to the best fixed price in hindsight, which outperform the previous regret bound of r OpT 3{4q for the problem.", "creator": "LaTeX with hyperref package"}}}