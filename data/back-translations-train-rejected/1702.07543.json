{"id": "1702.07543", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Feb-2017", "title": "Embedding Knowledge Graphs Based on Transitivity and Antisymmetry of Rules", "abstract": "Representation learning of knowledge graphs encodes entities and relation types into a continuous low-dimensional vector space, learns embeddings of entities and relation types. Most existing methods only concentrate on knowledge triples, ignoring logic rules which contain rich background knowledge. Although there has been some work aiming at leveraging both knowledge triples and logic rules, they ignore the transitivity and antisymmetry of logic rules. In this paper, we propose a novel approach to learn knowledge representations with entities and ordered relations in knowledges and logic rules. The key idea is to integrate knowledge triples and logic rules, and approximately order the relation types in logic rules to utilize the transitivity and antisymmetry of logic rules. All entries of the embeddings of relation types are constrained to be non-negative. We translate the general constrained optimization problem into an unconstrained optimization problem to solve the non-negative matrix factorization. Experimental results show that our model significantly outperforms other baselines on knowledge graph completion task. It indicates that our model is capable of capturing the transitivity and antisymmetry information, which is significant when learning embeddings of knowledge graphs.", "histories": [["v1", "Fri, 24 Feb 2017 11:28:02 GMT  (17kb)", "http://arxiv.org/abs/1702.07543v1", null], ["v2", "Wed, 19 Apr 2017 07:52:39 GMT  (0kb,I)", "http://arxiv.org/abs/1702.07543v2", "This paper has been withdrawn by the authors due to a crucial sign error in equations"]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["mengya wang", "hankui zhuo", "huiling zhu"], "accepted": false, "id": "1702.07543"}, "pdf": {"name": "1702.07543.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 170 2.07 543v 1 [cs.A I] 2 4Fe b20 17"}, {"heading": "1 Introduction", "text": "However, this type of structured data can be interpreted by computers and applied in various fields such as information retrivalry. [Hoffmann et al., 2011] and the literal sense of disambiguity is of great importance in terms of knowledge. To accomplish this task, the symbolic nature of relationships between KGs, especially large-scale rules of KGs, is difficult to manipulate. Predicting missing entries (known as link prediction) is of great importance in terms of knowledge. To accomplish this task, vector space embedding of knowledge graphs has been widely accepted, the key idea being the embedding of entities and relationship types of a vector space. Many approaches have been proposed to learn embedding of entities and relationships, such as E [Bordes]."}, {"heading": "2 Related Work", "text": "In fact, most people who are able to move to another world, to move to another world, to move to another world, to move to another world in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live."}, {"heading": "3 Problem Definition", "text": "In this section we give a formal definition of the problem. A knowledge diagram G is defined as a series of tripartite relationships of the form (s, r, o). s, o \u0441E denote the subject and the object unit or relationship type. E denotes the set of all units and R denotes the set of all relationship types in G. Make a set of logical rules from G: ra \u21d2 rb (in the form of (ra, rb)) means that ra logically implies rb, meaning that two units connected by the relationship ra should also be connected by the relationship rb."}, {"heading": "4 Our Model", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Restricted Triple Model(RTM)", "text": "In RTM, the aim is to embed entities and relationship types in order to capture the correlations between them. Re = Re = Re = Re-Q = Re-Q = Re-Q = Re-Q = Re-Q = Re-Q = Re-Q = Q-Q-Q-Q = Q-Q-Q-Q = Q-Q-Q-Q = Q-Q-Q-Q-Q (s, r, o) (1), where the log-Q-Q-Q-Q-Q-Q-Q (s, o) (s, o) (1), where the log-Q-Q-Q-Q-Q-Q (s, o) denotes the logistical function based on factoring the observed knowledge and on the correlation of r and the entity-Q-Q-Q-Q-Q-Q-Q (s, o)."}, {"heading": "4.2 Approximate Order Logic Model(AOLM)", "text": "(Re) Re (Re) Re (Re) Re (Re) Re (Re) Re (Re) Re (Re) Re (Re) Re (Re) Re (Re) Re (Re) Re (Re) Re (Re) Re (Re) Re (Re) Re (Re) Re (rbi) andd (Im (rai) 6 Im (rai) 6 Im (rbi) rbi (6) andra) rb (0) re (re) Re (rai) 6 Re (rbi) and d) Im (rai) 6 Im (rai) 6 Im (rbi) (7) for all vectors with non-negative coordinates. (Re) Re (rbi) Re (rci) and d) i (rai) Im (rai) Im (rbi) 6 Im (rci) (7) for all vectors with non-negative coordinates."}, {"heading": "4.3 Global Objective", "text": "With modeled knowledge triples and logic rules, embedding is learned by minimizing a global loss compared to this general representation: L = LK + LR (14), where LK is calculated by Gl. (10) and LR by Gl. (12) or Gl. (13). The embedding of relationship types does not have to be negative and can be translated into unlimited complex vector embedding in loss function. Therefore, stochastic gradient drop (SGD) in mini-batch mode and AdaGrad [Duchi et al., 2010] can be used to adjust the learning rate to perform the minimization directly. Learned embedding can be compatible with triples as well as with logic rules, and the embedding of relationship types in logic rules is arranged approximately so that the transitivity and antisymmetry of rules are captured."}, {"heading": "5 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Datasets and Experiment Settings", "text": "We evaluate our knowledge completion model using two commonly used large format knowledge diagrams and a triple learning dataset scale: WN36 WordNet is a large lexical database of English. Nouns, verbs, adjectives, and adverbs are grouped into sentences of cognitive synonyms called synsets. There are short definitions and usage examples, and records that have a number of relationships between these synonyms or their members. WordNet can therefore be considered a combination of dictionary and thesaurus. WN18 datasets are a subset of WordNet containing 40,943 entities, 18 relationship types, and 151,442 binary triples. As there are no logical rules between all relationship types in WN18, we first add the reverse relationships in training sets."}, {"heading": "5.2 Knowledge Base Completion", "text": "In the task of completing the knowledge base, we compare our model with several state-of-the-art models, including TransE [Bordes et al., 2013], TransR [Lin et al., 2015], HOLE [Nickel et al., 2015], ComplEx [Trouillon et al., 2016] and KALEJoint [Shu et al., 2016]. The previous four models focus only on knowledge triples, and KALE-Joint learns embedding through joint modeling of knowledge triples and logical rules. Rules need to be grounded and are not included in KALE joint.We evaluate the performance of our model with Mean Reciprocal Rank (MRR) and Top n (Hits @ n), which are used to evaluate knowledge triples and logical rules."}, {"heading": "5.3 Relational Learning", "text": "We test the relational learning abilities of our model on the basis of the country dataset. Most of the test triple results in the country datasets can be derived by direct application of logical rules to the training set. To evaluate our model, however, we do not use the pure logical conclusion. We randomly divide all countries into train (80%), validation (10%) and test (10%), then the training, validation and test set consists of the relationships that proceed from all countries in the training validation, and test the respective countries. Remove all triples results of the form (c, LocatedIn, r) for each country c in the validation and test group. In the new set S1 (c, LocatedIn, LocatedIn, LocatedIn, LocatedIn, LocatedIn, LocatIn, LocatIn, LocatIn, LocatIn, LocatIn, LocatIn, LocatIn, LocatIn, LocatIn, LocatIn, LocatIn, LocatIn, LocatedIn, LocatedIn, LocatedIn, LocatedIn, LocatIn, LocatIn, LocatIn, LocatIn, In, LocatIn, LocatIn, LocatIn, LocatIn, LocatIn, LocatIn, LocatIn, LocatIn, In, LocatIn, LocatIn, LocatIn, LocatIn, LocatIn, LocatIn, LocatIn, In, LocatIn, LocatIn, LocatIn, LocatIn, LocatIn, LocatIn, LocatIn, LocatIn, LocatedIn, LoIn, LocatedIn, LocatedIn, LocatedIn, LocatedIn, LocatedIn, LocatedIn, LocatedIn, LocatedIn, LoIn, LocatedIn, LocatedIn, LoIn, LocatedIn, LocatedIn, LocatedIn, LocatedIn, LocatedIn, LocatedIn, LocatedIn, LocatedIn, LocatedIn, LocatedIn, LocatedIn, LocatedIn, LocatedIn, LocatedIn, LocatedIn"}, {"heading": "6 Conclusion and Future Work", "text": "In this paper, we propose the TARE model for the representation learning of knowledge graphs by integrating existing relationships and logic rules together. Logic rules are directly integrated into relation type representations, rather than instantiating them with concrete units. We model logic rules by approximating the relation types in logic rules in such a way that the transitivity and antisymmetry of rules become effective, thus obtaining better embeddings for entities and relation types. In order to be ordered, the vector embeddings of relation types do not have to be negative, the general optimization problem is translated into an unrestricted optimization problem in our model. In experiments, we evaluate our models on the basis of knowledge base completion and relational learning tasks. Experimental results show that TARE brings significant and consistent improvements over the exit from modern methods."}], "references": [{"title": "Advances in Neural Information Processing Systems", "author": ["Antoine Bordes", "Nicolas Usunier", "Alberto Garcia-Duran", "Jason Weston", "Oksana Yakhnenko. Translating embeddings for modeling multi-relational data"], "venue": "pages 2787\u20132795,", "citeRegEx": "Bordes et al.. 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "and Tho Trouillon", "author": ["Guillaume Bouchard", "Sameer Singh"], "venue": "On approximate reasoning capabilities of low-rank vector spaces.", "citeRegEx": "Bouchard et al.. 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "Typed tensor decomposition of knowledge bases for relation extraction", "author": ["Kai Wei Chang", "Wen Tau Yih", "Bishan Yang", "Chris Meek"], "venue": "EMNLP,", "citeRegEx": "Chang et al.. 2014", "shortCiteRegEx": null, "year": 2014}, {"title": "Regularized alternating least squares algorithms for non-negative matrix/tensor factorization", "author": ["Cichocki", "Zdunek", "2007] Andrzej Cichocki", "Rafal Zdunek"], "venue": "In Advances in Neural Networks", "citeRegEx": "Cichocki et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Cichocki et al\\.", "year": 2007}, {"title": "Journal of Machine Learning Research", "author": ["John Duchi", "Elad Hazan", "Yoram Singer. Adaptive subgradient methods for online learning", "stochastic optimization"], "venue": "12(7):257\u2013269,", "citeRegEx": "Duchi et al.. 2010", "shortCiteRegEx": null, "year": 2010}, {"title": "Knowledge-based weak supervision for information extraction of overlapping relations. In Meeting of the Association for Computational Linguistics: Human Language", "author": ["Hoffmann et al", "2011] Raphael Hoffmann", "Congle Zhang", "Xiao Ling", "Luke Zettlemoyer", "Daniel S. Weld"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2011\\E", "shortCiteRegEx": "al. et al\\.", "year": 2011}, {"title": "Bioinformatics", "author": ["Hyunsoo Kim", "Haesun Park. Sparse non-negative matrix factorizations via alternating non-negativity-constrained least squares for microarray data analysis"], "venue": "23(12):1495,", "citeRegEx": "Kim and Park. 2007", "shortCiteRegEx": null, "year": 2007}, {"title": "and Volker Tresp", "author": ["Denis Krompa", "Stephan Baier"], "venue": "Type-constrained representation learning in knowledge graphs.", "citeRegEx": "Krompa et al.. 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "In NIPS", "author": ["Daniel D. Lee", "H. Sebastian Seung. Algorithms for non-negative matrix factorization"], "venue": "pages 556\u2013562,", "citeRegEx": "Lee and Seung. 2000", "shortCiteRegEx": null, "year": 2000}, {"title": "and X", "author": ["Y. Lin", "Z. Liu", "M. Sun", "Y. Liu"], "venue": "Zhu. Learning entity and relation embeddings for knowledge graph completion.", "citeRegEx": "Lin et al.. 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "Projected gradient methods for nonnegative matrix factorization", "author": ["C.J. Lin"], "venue": "Neural Computation, 19(10):2756", "citeRegEx": "Lin. 2007", "shortCiteRegEx": null, "year": 2007}, {"title": "ICML 2011", "author": ["Maximilian Nickel", "Volker Tresp", "Hans Peter Kriegel. A three-way model for collective learning on multi-relational data. In International Conference on Machine Learning"], "venue": "Bellevue, Washington, Usa, June 28 - July, pages 809\u2013816,", "citeRegEx": "Nickel et al.. 2011", "shortCiteRegEx": null, "year": 2011}, {"title": "Holographic embeddings of knowledge graphs", "author": ["Maximilian Nickel", "Lorenzo Rosasco", "Tomaso Poggio"], "venue": "Computer Science,", "citeRegEx": "Nickel et al.. 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "In NAACL-HLT", "author": ["Sebastian Riedel", "Limin Yao", "Andrew Mccallum", "Benjamin M Marlin. Relation extraction with matrix factorization", "universal schemas"], "venue": "page xxixxii,", "citeRegEx": "Riedel et al.. 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "Injecting logical background knowledge into embeddings for relation extraction", "author": ["Tim Rocktschel", "Sameer Singh", "Sebastian Riedel"], "venue": "North American Chapter of the Association for Computational Linguistics,", "citeRegEx": "Rocktschel et al.. 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "and Guo Li", "author": ["Guo Shu", "Wang Quan", "Lihong Wang", "Bin Wang"], "venue": "Jointly embedding knowledge graphs and logical rules.", "citeRegEx": "Shu et al.. 2016", "shortCiteRegEx": null, "year": 2016}, {"title": "Reasoning with neural tensor networks for knowledge base completion", "author": ["R. Socher", "D. Chen", "C.D. Manning", "A.Y. Ng"], "venue": "pages 464\u2013469", "citeRegEx": "Socher et al.. 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "ric Gaussier", "author": ["Tho Trouillon", "Johannes Welbl", "Sebastian Riedel"], "venue": "and Guillaume Bouchard. Complex embeddings for simple link prediction.", "citeRegEx": "Trouillon et al.. 2016", "shortCiteRegEx": null, "year": 2016}, {"title": "Knowledge graph embedding by translating on hyperplanes", "author": ["Zhen Wang", "Jianwen Zhang", "Jianlin Feng", "Zheng Chen"], "venue": "AAAI - Association for the Advancement of Artificial Intelligence,", "citeRegEx": "Wang et al.. 2014", "shortCiteRegEx": null, "year": 2014}, {"title": "In International Conference on Artificial Intelligence", "author": ["Quan Wang", "Bin Wang", "Li Guo. Knowledge base completion using embeddings", "rules"], "venue": "pages 1859\u20131865,", "citeRegEx": "Wang et al.. 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "Large-scale knowledge base completion: Inferring via grounding network sampling over selected instances", "author": ["ZhuoyuWei", "Jun Zhao", "Kang Liu", "Zhenyu Qi", "Zhengya Sun", "Guanhua Tian"], "venue": "\u0141\u0141, pages 1331\u20131340,", "citeRegEx": "Wei et al.. 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "and Shizhu He", "author": ["Jun Zhao", "Liheng Xu", "Kang Liu", "Guoliang Ji"], "venue": "Knowledge graph embedding via dynamic mapping matrix.", "citeRegEx": "Zhao et al.. 2015", "shortCiteRegEx": null, "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "Many approaches have been proposed to learn embeddings of entities and relations, such as TransE [Bordes et al., 2013], NTN [Socher et al.", "startOffset": 97, "endOffset": 118}, {"referenceID": 16, "context": ", 2013], NTN [Socher et al., 2013], HOLE [Nickel et al.", "startOffset": 13, "endOffset": 34}, {"referenceID": 12, "context": ", 2013], HOLE [Nickel et al., 2015], ComplEx [Trouillon et al.", "startOffset": 14, "endOffset": 35}, {"referenceID": 17, "context": ", 2015], ComplEx [Trouillon et al., 2016], and so on.", "startOffset": 17, "endOffset": 41}, {"referenceID": 19, "context": "To leverage logic rules in knowledge graph embeddings, [Wang et al., 2015; Wei et al., 2015; Rocktschel et al., 2015; Shu et al., 2016] propose to utilize both knowledge triples and logic rules for KB completion.", "startOffset": 55, "endOffset": 135}, {"referenceID": 20, "context": "To leverage logic rules in knowledge graph embeddings, [Wang et al., 2015; Wei et al., 2015; Rocktschel et al., 2015; Shu et al., 2016] propose to utilize both knowledge triples and logic rules for KB completion.", "startOffset": 55, "endOffset": 135}, {"referenceID": 14, "context": "To leverage logic rules in knowledge graph embeddings, [Wang et al., 2015; Wei et al., 2015; Rocktschel et al., 2015; Shu et al., 2016] propose to utilize both knowledge triples and logic rules for KB completion.", "startOffset": 55, "endOffset": 135}, {"referenceID": 15, "context": "To leverage logic rules in knowledge graph embeddings, [Wang et al., 2015; Wei et al., 2015; Rocktschel et al., 2015; Shu et al., 2016] propose to utilize both knowledge triples and logic rules for KB completion.", "startOffset": 55, "endOffset": 135}, {"referenceID": 11, "context": "Some works explain triples via latent representation of entities and relations such as tensor factorization [Nickel et al., 2011; Riedel et al., 2013; Chang et al., 2014] and multiway neural networks [Socher et al.", "startOffset": 108, "endOffset": 170}, {"referenceID": 13, "context": "Some works explain triples via latent representation of entities and relations such as tensor factorization [Nickel et al., 2011; Riedel et al., 2013; Chang et al., 2014] and multiway neural networks [Socher et al.", "startOffset": 108, "endOffset": 170}, {"referenceID": 2, "context": "Some works explain triples via latent representation of entities and relations such as tensor factorization [Nickel et al., 2011; Riedel et al., 2013; Chang et al., 2014] and multiway neural networks [Socher et al.", "startOffset": 108, "endOffset": 170}, {"referenceID": 16, "context": ", 2014] and multiway neural networks [Socher et al., 2013].", "startOffset": 37, "endOffset": 58}, {"referenceID": 11, "context": "RESCAL [Nickel et al., 2011] is a relational latent feature model which explains triples via pairwise interactions of latent features.", "startOffset": 7, "endOffset": 28}, {"referenceID": 0, "context": "TransE [Bordes et al., 2013] translates the latent feature representations via a relation-specific offset.", "startOffset": 7, "endOffset": 28}, {"referenceID": 18, "context": "To improve the performance of TransE on complicated relations, TransH [Wang et al., 2014], TransR [Lin et al.", "startOffset": 70, "endOffset": 89}, {"referenceID": 9, "context": ", 2014], TransR [Lin et al., 2015] and TransD [Zhao et al.", "startOffset": 16, "endOffset": 34}, {"referenceID": 21, "context": ", 2015] and TransD [Zhao et al., 2015] are proposed.", "startOffset": 19, "endOffset": 38}, {"referenceID": 12, "context": "To combine the power of tensor product with the efficiency and simplicity of TransE, HOLE [Nickel et al., 2015] uses the circular correlation of vectors to represent pairs of entities.", "startOffset": 90, "endOffset": 111}, {"referenceID": 17, "context": "Complex [Trouillon et al., 2016] makes use of embeddings with complex value and is able to handle a large number of binary relations, in particular symmetric and antisymmetric relations.", "startOffset": 8, "endOffset": 32}, {"referenceID": 19, "context": "[Wang et al., 2015; Wei et al., 2015] tries to utilize rules via integer linear programming or Markov logical networks.", "startOffset": 0, "endOffset": 37}, {"referenceID": 20, "context": "[Wang et al., 2015; Wei et al., 2015] tries to utilize rules via integer linear programming or Markov logical networks.", "startOffset": 0, "endOffset": 37}, {"referenceID": 14, "context": "[Rocktschel et al., 2015] proposes a joint model which injects first-order logic into embeddings.", "startOffset": 0, "endOffset": 25}, {"referenceID": 15, "context": "KALE-Joint [Shu et al., 2016] proposes a new approach which learns entity and relation embeddings by jointly modelling knowledge triples and logic rules.", "startOffset": 11, "endOffset": 29}, {"referenceID": 17, "context": "The energy function \u03c6(s, r, o; \u0398) in our model is based on existing model Complex [Trouillon et al., 2016], in which complex vectors ve, vr \u2208 R d are learned for each entity e \u2208 E and each relation type r \u2208 R.", "startOffset": 82, "endOffset": 106}, {"referenceID": 8, "context": "There are many ways to solve Non-negative Matrix Factorization such as Multiplicative Update [Lee and Seung, 2000], Gradient based Update [Lin, 2007] and Alternating Non-negative Least Squares [Kim and Park, 2007; Cichocki and Zdunek, 2007].", "startOffset": 93, "endOffset": 114}, {"referenceID": 10, "context": "There are many ways to solve Non-negative Matrix Factorization such as Multiplicative Update [Lee and Seung, 2000], Gradient based Update [Lin, 2007] and Alternating Non-negative Least Squares [Kim and Park, 2007; Cichocki and Zdunek, 2007].", "startOffset": 138, "endOffset": 149}, {"referenceID": 6, "context": "There are many ways to solve Non-negative Matrix Factorization such as Multiplicative Update [Lee and Seung, 2000], Gradient based Update [Lin, 2007] and Alternating Non-negative Least Squares [Kim and Park, 2007; Cichocki and Zdunek, 2007].", "startOffset": 193, "endOffset": 240}, {"referenceID": 7, "context": "The negative set of knowledges is generated by local closed world assumption(LCWA) proposed in [Krompa et al., 2015].", "startOffset": 95, "endOffset": 116}, {"referenceID": 4, "context": "Therefore, stochastic gradient descent (SGD) in mini-batch mode and AdaGrad [Duchi et al., 2010] for tuning the learning rate can be used to carry out the minimization directly.", "startOffset": 76, "endOffset": 96}, {"referenceID": 0, "context": "We use original training, validation and test set splits as provided by [Bordes et al., 2013].", "startOffset": 72, "endOffset": 93}, {"referenceID": 1, "context": "Countries The countries dataset provided by [Bouchard et al., 2015] consists of 244 countries, 22 subregions and 5 regions.", "startOffset": 44, "endOffset": 67}, {"referenceID": 0, "context": "In the task of knowledge base completion, we compare our model with several state-of-art models including TransE [Bordes et al., 2013], TransR [Lin et al.", "startOffset": 113, "endOffset": 134}, {"referenceID": 9, "context": ", 2013], TransR [Lin et al., 2015], HOLE [Nickel et al.", "startOffset": 16, "endOffset": 34}, {"referenceID": 12, "context": ", 2015], HOLE [Nickel et al., 2015], ComplEx [Trouillon et al.", "startOffset": 14, "endOffset": 35}, {"referenceID": 17, "context": ", 2015], ComplEx [Trouillon et al., 2016] and KALEJoint [Shu et al.", "startOffset": 17, "endOffset": 41}, {"referenceID": 15, "context": ", 2016] and KALEJoint [Shu et al., 2016].", "startOffset": 22, "endOffset": 40}], "year": 2017, "abstractText": "Representation learning of knowledge graphs encodes entities and relation types into a continuous low-dimensional vector space, learns embeddings of entities and relation types. Most existing methods only concentrate on knowledge triples, ignoring logic rules which contain rich background knowledge. Although there has been some work aiming at leveraging both knowledge triples and logic rules, they ignore the transitivity and antisymmetry of logic rules. In this paper, we propose a novel approach to learn knowledge representations with entities and ordered relations in knowledges and logic rules. The key idea is to integrate knowledge triples and logic rules, and approximately order the relation types in logic rules to utilize the transitivity and antisymmetry of logic rules. All entries of the embeddings of relation types are constrained to be non-negative. We translate the general constrained optimization problem into an unconstrained optimization problem to solve the non-negative matrix factorization. Experimental results show that our model significantly outperforms other baselines on knowledge graph completion task. It indicates that our model is capable of capturing the transitivity and antisymmetry information, which is significant when learning embeddings of knowledge graphs.", "creator": "LaTeX with hyperref package"}}}