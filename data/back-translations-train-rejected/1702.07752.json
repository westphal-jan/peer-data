{"id": "1702.07752", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Feb-2017", "title": "A supervised approach to time scale detection in dynamic networks", "abstract": "For any stream of time-stamped edges that form a dynamic network, an important choice is the aggregation granularity that an analyst uses to bin the data. Picking such a windowing of the data is often done by hand, or left up to the technology that is collecting the data. However, the choice can make a big difference in the properties of the dynamic network. This is the time scale detection problem. In previous work, this problem is often solved with a heuristic as an unsupervised task. As an unsupervised problem, it is difficult to measure how well a given algorithm performs. In addition, we show that the quality of the windowing is dependent on which task an analyst wants to perform on the network after windowing. Therefore the time scale detection problem should not be handled independently from the rest of the analysis of the network.", "histories": [["v1", "Fri, 24 Feb 2017 20:45:02 GMT  (64kb,D)", "http://arxiv.org/abs/1702.07752v1", null]], "reviews": [], "SUBJECTS": "cs.SI cs.LG", "authors": ["benjamin fish", "rajmonda s caceres"], "accepted": false, "id": "1702.07752"}, "pdf": {"name": "1702.07752.pdf", "metadata": {"source": "CRF", "title": "A supervised approach to time scale detection in dynamic networks", "authors": ["Benjamin Fish", "Rajmonda S. Caceres"], "emails": ["bfish3@uic.edu"], "sections": [{"heading": null, "text": "For each stream of timestamped edges that form a dynamic network, an important choice is the aggregation granularity that an analyst uses to sort the data. Selecting such a window of data is often done by hand or is left to the technology that collects the data. However, the choice can make a big difference in the properties of the dynamic network. This is the recognition problem on the timescale. In previous work, this problem was often solved with heuristics as an unattended task. As an unattended problem, it is difficult to measure the performance of a given algorithm. Furthermore, we show that the quality of window construction depends on what task an analyst wants to perform after the window in the network. Therefore, the detection problem on the timescale should not be handled independently of the rest of the analysis of the network. We are introducing a framework that tackles both of these problems: by measuring the performance of the detection algorithm on the timescale, based on how well we compare the scale with a given task on the first time scale."}, {"heading": "1 Introduction", "text": "In fact, we will be able to change the world without being able to change the world, \"he said in an interview."}, {"heading": "1.1 Previous Work", "text": "In the numerical time series, this problem is often referred to as \"segmentation,\" and the segmentation of the numerical time series has a long history that is outside the scope of this work. See [10] For dynamic networks, there is some work related to our problem in the field of detecting change points, which aims to locate points in the time when the dynamic network has abruptly changed. Typical methods include the use of generative models of dynamic networks [16] or clustering of similar periods [2]. This literature differs slightly from the problem addressed in this paper."}, {"heading": "1.2 Background", "text": "In fact, it is in such a way that most people are able to feel as if they are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to move, to move, to move, to move, to move, to move, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move,"}, {"heading": "2 Tasks", "text": "Considering a job application window, we evaluate its quality by performing a learning task algorithm on that window. We then evaluate the window based on the performance of the task algorithm when using that window. We consider three task algorithms: link prediction, attribute prediction, and modification point detection. We treat link prediction as an online task, and attribute prediction and modification point detection as offline tasks. We do this to demonstrate window algorithms on both types of tasks. Below, we describe the algorithms we use for each task and how we assess their performance."}, {"heading": "2.1 Link prediction", "text": "In the link prediction algorithm, the goal is to predict the edges that will appear most likely in the future. In the online setting, our goal at each step is to predict the edges that will appear in the next time step (the next step in the first input sequence in front of the window) Although there are many methods for predicting links (see [1] for a survey), the method we use is a simple scoring function that values each pair of vertices exponentially higher than the probability of an edge appearing between them. In this post, we use the cat score, an efficient and powerful score [13]. \u03b2 is a attenuation parameter that values shorter paths exponentially higher than longer paths in the most recent graph in the input sequence. For our experiment results, we use \u03b2 = 0.005, which was already used before [8, 13]. The performance of the link prediction algorithm is predicted using the AUC of precision reset to predict each of the averages [23] as recommended by all."}, {"heading": "2.2 Attribute prediction", "text": "We use the Time Varying Relational Classifier (TVRC) algorithm of Sharan and Neville [19] to determine the unknown value of a binary vertex attribute. As in their work, we assume that attributes do not change over time. The goal is then to derive the missing attribute values by using not only the known attribute values of the vertices, but also the time information in the data. Their method is a Bayesian model that uses knowledge of attributes in the neighborhood of a vertex. This model uses timestamps to weight the impact of each vertice on its neighbors. In our implementation, we use add-one smoothing for categorical characteristics and a Gaussian distribution for continuous characteristics. The goal is then to find a window in which TVRC builds the most powerful model. TVRC requires a kernel to weight edges - as we use them \u2212 3."}, {"heading": "2.3 Change point detection", "text": "We use Graphscope, by Sun et al. [22]. Graphscope recognizes change points by estimating the times when the segmentation of the graph sequence at these times maximizes compressibility. Since our graphs are not split in two, we make the necessary changes to Graphscope so that it can be used in non-split cases. To evaluate a detection algorithm for change points, we need a single score that summarizes how good a set of change points are, but to the best of our knowledge, no such measure has been proposed in the literature, unlike classification tasks that often use AUC or other individual values to summarize quality. We need a single score instead of, say, an accuracy call curve, not only to evaluate, but also because our monitored windowing algorithm requires a single score to directly and automatically compare the quality of different window sizes."}, {"heading": "3 Experimental Setup", "text": "We now describe how we test the performance of the window algorithms. In the offline setting, we set aside a previous dynamic network interval for training, and the next interval for testing. The training interval contains ground truth information. For example, for detecting change points that occurred in that interval, it contains all the change points that occurred in that interval. A window algorithm can use this information to decide on the window size to be used in the test set. A window algorithm, uniform or otherwise, is also allowed to see the edges in the test set to determine the test set window window, but of course there is no basic truth information about the task. Once the test set is complete, we perform our task on the window data and measure its performance, as described in Section 2. The window algorithm score is then only the score that the task algorithm receives, which data set we have in each."}, {"heading": "4 Data sets", "text": "We use five sets of data: Enron, MIT Reality Mining, Badge, Hypertext09, and Haggle. We treat them all as non-directional dynamic networks. For both simplicity and consistency, we keep each of these data sets at an initial window size in a \"natural\" size, i.e. a choice that a data analyst could make, for example, an hour or a day. This means that a window size of w = 1 represents a baseline indicating how well a hand-selected window would perform. We only consider window sizes that are at least as large as that base size. Each of these data sets is suitable for link prediction. Enron, Reality Mining, and Badge are equipped with corner attributes to test prediction of attributes, and Enron and Reality Mining also have change point information from these."}, {"heading": "4.1 Enron", "text": "This is an email network between Enron Inc. employees from January 1999 to July 2002, during the time of the market manipulation scandal and subsequent collapse [11]. We use the emails of 151 employees, with each edge being an email sent by one of those employees to another. Each vertex representing an employee has a binary attribute indicating whether the employee was a manager or not, and 1For Reality Mining, we split it into five instead of six intervals when detecting change points to ensure that each training set contains at least one change point. Fifty integer attributes, which are the number of occurrences in the outgoing emails of each employee of the fifty words used in all emails (a list of stop words was excluded from the fifty words)."}, {"heading": "4.2 Reality Mining", "text": "This is a proximity network of 90 MIT students and faculty that uses data from mobile phones from September 2004 to May 2005 (we use data only until the end of the academic year). [7] As edges, we use both telephone calls between participants and whenever two participants are close together, using Bluetooth. Each participant completed a survey about their mobile phone use, such as how much they use their mobile phone, where they live, etc., which we use as categorical attributes for each vertex. The attribute we use to test the attribute prediction is whether they are part of the Business School or the MIT Media Lab. Change points come from [16], the beginning and end of holidays, semesters, etc. The initial size of the garbage can is one day."}, {"heading": "4.3 Badge", "text": "This is a proximity network of 23 employees of a data server configuration company for one month (the name of the dataset comes from the badges employees wore to keep track of their location at the workplace). [15] Each edge represents when two employees are in close proximity to each other, which is an interaction. Each employee was assigned a certain number of tasks, and data about those tasks was recorded, such as the average completion time, whether or not they took on a difficult task, and so on. For attribute prediction, we say whether or not they made a mistake in one of their tasks."}, {"heading": "4.4 Haggle Infocomm", "text": "This is a proximity network consisting of interactions recorded via Bluetooth between participants of an IEEE Infocomm conference over four days [18]. 41 participants participated in this network."}, {"heading": "4.5 Hypertext09", "text": "This is another proximity network of attendees at the ACM Hypertext 2009 conference, which took place over three days [9]. Each vertex is one of the 113 attendees, and one edge represents an interaction between two attendees that was active for at least 20 seconds."}, {"heading": "5 Task dependence", "text": "Ideally, it would be nice to have only one window algorithm that performs well regardless of whether your target is link prediction, attribute prediction, modifier detection, or any other task. However, we show that this does not seem feasible while still maximizing the performance of the task algorithm. To do this, we evaluate each window size by the performance of each of the three task algorithms when the dataset is displayed in this size, so that we have a value that represents the quality of the window size for each of the three tasks. Table 1 shows the value for the ith task when you select the window size with the highest score for the next task. (The values are calculated for each of the intervals described in Section 3, and the values in Table 1 are the average of the results for each interval.) For example, select the best window size for the link variant. The table shows that the other two tasks do not score as high as you would if you had chosen the best window size for each task."}, {"heading": "6 Windowing algorithms and baselines", "text": "We will now describe the window algorithms that we will compare in both offline and online settings. So that the monitored algorithms we introduce remain useful not only for the three tasks we are looking at, but for each task, our algorithms do not attempt to exploit the specific nature of the task and the corresponding algorithm. In other words, we treat the task algorithms as black boxes. However, as we show in Section 7, despite this self-imposed limitation, the monitored approaches are still able to perform well."}, {"heading": "6.1 Offline supervised algorithms", "text": "Our intuition is very simple: since we know what task we want to perform on the test set, we use the same task algorithm to learn the window size on the training set. In offline setting, to try to prevent overfitting and make the search space smaller, we only look at uniform window surfaces. This allows us to make the algorithm very simple: for each window size, up to the length of the training set, windows with the window size that received the highest score, and use this as input for the task algorithm. Measure the performance of the task algorithm (remember that we have the truth for the training set) and use this as a score for the window size. Window of the test set with the window size that received the highest score. Of course, this means that the task algorithm O (T) times is executed (where T is the length of the training set), which is not particularly efficient."}, {"heading": "6.2 Online supervised algorithms", "text": "In the online setting, we could take a similar approach to each step as in the offline case, resulting in O (i) runs of the task algorithm in the first step, for a total of O (T 2) times, with T being the total length of the sequence. This will often be prohibitively expensive. We are introducing an approximate online window algorithm to solve this problem. We illustrate with the link prediction, as a natural example of an online task. Every time we get a new graph Gi representing the edges that have occurred in the next time step, we can test any window size w by using the sequence so far at size w and then the last graph in the windowlike sequence to predict the edges that will appear in Gi. We then compare the recognized edges with the actual edges in Gi, creating an AUC score for that window size."}, {"heading": "6.3 Other windowing algorithms and baselines", "text": "We compare against ADAGE, the method of Soundarajan et al. [20]. ADAGE needs a metric as a parameter, so we use the degree distribution exponent, which is the metric they use. We also compare against the Jaccard index-based method (Jaccard) of Darst et al. [5] and the entropy-based method (Entropy) of De Domenico et al. [6]. Since this method allows graphs with any kind of layer, we treat each time step as a layer and modify its method to merge only adjacent time steps. We also compare against several baselines: the first always uses a window size of w = 1, which, as mentioned above, represents a \"hand-chosen\" value (which we call the manually selected algorithm), representing the window size that an expert might have chosen."}, {"heading": "7 Results", "text": "This year, we will be able to put ourselves at the top without being able to get angry."}, {"heading": "8 Conclusion and future work", "text": "In this paper, we have demonstrated that window algorithms are task-dependent. In recognition of this, we have created a simple and user-friendly framework for directly comparing the quality of window algorithms and, in addition, have introduced monitored window algorithms that use our ability to test windows. Nevertheless, we leave several challenges for future work: Like any supervised machine learning, the quality of learners depends on the quantity and quality of training data. Improving window algorithms in the face of environments with little training data remains a problem. Even with training data, this can be a mathematically costly procedure when the window algorithm repeatedly has to call an expensive task algorithm. We leave future work to find heuristics that approximate the performance of a window for a given task."}], "references": [{"title": "A survey of link prediction in social networks", "author": ["Mohammad Al Hasan", "Mohammed J. Zaki"], "venue": "In Social Network Data Analytics,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2011}, {"title": "As time goes by: Discovering eras in evolving social networks", "author": ["Michele Berlingerio", "Michele Coscia", "Fosca Giannotti", "Anna Monreale", "Dino Pedreschi"], "venue": "In Pacific-Asia Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2010}, {"title": "Persistence and periodicity in a dynamic proximity network", "author": ["Aaron Clauset", "Nathan Eagle"], "venue": "DIMACS Workshop on Computational Methods for Dynamic Interaction Networks,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2007}, {"title": "Segmentation and automated so- 9  cial hierarchy detection through email network analysis", "author": ["Germ\u00e1n Creamer", "Ryan Rowe", "Shlomo Hershkop", "Salvatore J Stolfo"], "venue": "In Advances in Web Mining and Web Usage Analysis,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2009}, {"title": "Detection of timescales in evolving complex systems", "author": ["Richard K. Darst", "Clara Granell", "Alex Arenas", "Sergio G\u00f3mez", "Jari Saram\u00e4ki", "Santo Fortunato"], "venue": "arXiv preprint arXiv:1604.00758,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2016}, {"title": "Structural reducibility of multilayer networks", "author": ["Manlio De Domenico", "Vincenzo Nicosia", "Alexandre Arenas", "Vito Latora"], "venue": "Nature Communications,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "Reality mining: sensing complex social systems", "author": ["Nathan Eagle", "Alex Sandy Pentland"], "venue": "Personal and Ubiquitous Computing,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2006}, {"title": "Handling oversampling in dynamic networks using link prediction", "author": ["Benjamin Fish", "Rajmonda S. Caceres"], "venue": "In Joint European Conference on Machine Learning and Knowledge Discovery in Databases,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "What\u2019s in a crowd? analysis of face-to-face behavioral networks", "author": ["Lorenzo Isella", "Juliette Stehl\u00e9", "Alain Barrat", "Ciro Cattuto", "Jean-Fran\u00e7ois Pinton", "Wouter Van den Broeck"], "venue": "Journal of Theoretical Biology,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2011}, {"title": "Segmenting time series: A survey and novel approach", "author": ["Eamonn Keogh", "Selina Chu", "David Hart", "Michael Pazzani"], "venue": "Data mining in Time Series Databases,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2004}, {"title": "The enron corpus: A new dataset for email classification research", "author": ["Bryan Klimt", "Yiming Yang"], "venue": "In European Conference on Machine Learning,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2004}, {"title": "Effects of time window size and placement on the structure of an aggregated communication network", "author": ["Gautier Krings", "M\u00e1rton Karsai", "Sebastian Bernhardsson", "Vincent D Blondel", "Jari Saram\u00e4ki"], "venue": "EPJ Data Science,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2012}, {"title": "The link prediction problem for social networks", "author": ["David Liben-Nowell", "Jon Kleinberg"], "venue": "In Proceedings of the Twelfth International Conference on Information and Knowledge Management,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2003}, {"title": "A graph summarization: A survey", "author": ["Yike Liu", "Abhilash Dighe", "Tara Safavi", "Danai Koutra"], "venue": "arXiv preprint arXiv:1612.04883,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2016}, {"title": "Sensible organizations: Technology and methodology  for automatically measuring organizational behavior", "author": ["Daniel Olg\u00fa\u0131n Olg\u00fa\u0131n", "Benjamin N. Waber", "Taemie Kim", "Akshay Mohan", "Koji Ara", "Alex Pentland"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics),", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2009}, {"title": "Detecting change points in the large-scale structure of evolving networks", "author": ["Leto Peel", "Aaron Clauset"], "venue": "In Twenty-Ninth AAAI Conference on Artificial Intelligence,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2015}, {"title": "Quantifying the effect of temporal resolution on timevarying networks", "author": ["Bruno Ribeiro", "Nicola Perra", "Andrea Baronchelli"], "venue": "Scientific Reports,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2013}, {"title": "CRAW- DAD dataset cambridge/haggle (v. 2009-05-29)", "author": ["James Scott", "Richard Gass", "Jon Crowcroft", "Pan Hui", "Christophe Diot", "Augustin Chaintreau"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2009}, {"title": "Temporalrelational classifiers for prediction in evolving domains", "author": ["Umang Sharan", "Jennifer Neville"], "venue": "In Eighth IEEE International Conference on Data Mining, 2008", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2008}, {"title": "Generating graph snapshots from streaming edge data", "author": ["Sucheta Soundarajan", "Acar Tamersoy", "Elias B. Khalil", "Tina Eliassi-Rad", "Duen Horng Chau", "Brian Gallagher", "Kevin Roundy"], "venue": "In Proceedings of the 25th International Conference Companion on World Wide Web,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2016}, {"title": "Meaningful selection of temporal resolution for dynamic networks", "author": ["Rajmonda Sulo", "Tanya Berger-Wolf", "Robert Grossman"], "venue": "In Proceedings of the Eighth Workshop on Mining and Learning with Graphs,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2010}, {"title": "Graphscope: parameter-free mining of large time-evolving graphs", "author": ["Jimeng Sun", "Christos Faloutsos", "Spiros Papadimitriou", "Philip S. Yu"], "venue": "In Proceedings of the 13th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2007}, {"title": "Evaluating link prediction methods", "author": ["Yang Yang", "Ryan N. Lichtenwalter", "Nitesh V. Chawla"], "venue": "Knowledge and Information Systems,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2015}], "referenceMentions": [{"referenceID": 2, "context": "Indeed, the time scale of the network strongly impacts what structures and dynamics may be observed in the network [3, 12, 17].", "startOffset": 115, "endOffset": 126}, {"referenceID": 11, "context": "Indeed, the time scale of the network strongly impacts what structures and dynamics may be observed in the network [3, 12, 17].", "startOffset": 115, "endOffset": 126}, {"referenceID": 16, "context": "Indeed, the time scale of the network strongly impacts what structures and dynamics may be observed in the network [3, 12, 17].", "startOffset": 115, "endOffset": 126}, {"referenceID": 7, "context": "Moreover, the choice of time scale impacts the efficacy of data mining on networks [8].", "startOffset": 83, "endOffset": 86}, {"referenceID": 9, "context": "In numeric time series, this problem is often termed \u2018segmentation,\u2019 and segmentation of numeric times series has a long history which is outside the scope of this work; see [10]", "startOffset": 174, "endOffset": 178}, {"referenceID": 15, "context": "Typical methods include using generative models of dynamic networks [16] or clustering similar time slices [2].", "startOffset": 68, "endOffset": 72}, {"referenceID": 1, "context": "Typical methods include using generative models of dynamic networks [16] or clustering similar time slices [2].", "startOffset": 107, "endOffset": 110}, {"referenceID": 13, "context": "See [14] for a survey of graph summarization techniques.", "startOffset": 4, "endOffset": 8}, {"referenceID": 5, "context": "This approach has been applied, more generally, to multi-layer networks, dynamic or not [6].", "startOffset": 88, "endOffset": 91}, {"referenceID": 20, "context": "maps the dynamic network to a time series using a metric on graphs (such as the number of triangles in each graph) and then determines time scale by finding the scale at which the time series\u2019 compression ratio and variance is balanced [21].", "startOffset": 236, "endOffset": 240}, {"referenceID": 19, "context": "determines a windowing of the data with respect to some metric (such as the exponent of the degree distribution) by measuring when that metric has converged [20].", "startOffset": 157, "endOffset": 161}, {"referenceID": 4, "context": "use a parameterfree approach that seeks to find an appropriate time scale by measuring the similarity between graphs using the Jaccard index [5].", "startOffset": 141, "endOffset": 144}, {"referenceID": 7, "context": "Most closely related to the approach that we take in this paper, Fish and Caceres use the quality of the performance of link prediction algorithms to determine the best time scale [8].", "startOffset": 180, "endOffset": 183}, {"referenceID": 2, "context": "These are parameter-free methods or, relatedly, methods that assume that there is some \u2018ground-truth\u2019 time scale via a generative model or the like, as in [3, 5, 8].", "startOffset": 155, "endOffset": 164}, {"referenceID": 4, "context": "These are parameter-free methods or, relatedly, methods that assume that there is some \u2018ground-truth\u2019 time scale via a generative model or the like, as in [3, 5, 8].", "startOffset": 155, "endOffset": 164}, {"referenceID": 7, "context": "These are parameter-free methods or, relatedly, methods that assume that there is some \u2018ground-truth\u2019 time scale via a generative model or the like, as in [3, 5, 8].", "startOffset": 155, "endOffset": 164}, {"referenceID": 7, "context": "As pointed out in [8, 20, 21], too small a window size may introduce noise and lack the structure necessary for analysis but too large a window size may lose important temporal information.", "startOffset": 18, "endOffset": 29}, {"referenceID": 19, "context": "As pointed out in [8, 20, 21], too small a window size may introduce noise and lack the structure necessary for analysis but too large a window size may lose important temporal information.", "startOffset": 18, "endOffset": 29}, {"referenceID": 20, "context": "As pointed out in [8, 20, 21], too small a window size may introduce noise and lack the structure necessary for analysis but too large a window size may lose important temporal information.", "startOffset": 18, "endOffset": 29}, {"referenceID": 0, "context": "While there are many methods for link prediction (see [1] for a survey), the method we use is a simple scoring function that scores every pair of vertices by how likely an edge is to appear between them.", "startOffset": 54, "endOffset": 57}, {"referenceID": 12, "context": "In this paper, we use the Katz\u03b2 score, an efficient and well-performing score [13].", "startOffset": 78, "endOffset": 82}, {"referenceID": 7, "context": "005, which has been used before [8, 13].", "startOffset": 32, "endOffset": 39}, {"referenceID": 12, "context": "005, which has been used before [8, 13].", "startOffset": 32, "endOffset": 39}, {"referenceID": 22, "context": "The performance of the link prediction algorithm is evaluated using the AUC of the precision-recall curve, as recommended by [23], averaged over all predictions made, one set of predictions for each graph.", "startOffset": 125, "endOffset": 129}, {"referenceID": 18, "context": "We use the Time Varying Relational Classifier (TVRC) algorithm of Sharan and Neville [19] to determine the unknown value of a binary vertex attribute.", "startOffset": 85, "endOffset": 89}, {"referenceID": 21, "context": "[22].", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "Peel and Clauset [16] propose the following notions of precision and recall:", "startOffset": 17, "endOffset": 21}, {"referenceID": 0, "context": "Note this is a [0, 1]-valued measure.", "startOffset": 15, "endOffset": 21}, {"referenceID": 10, "context": "from January 1999 to July 2002, during the period of Enron\u2019s market manipulation scandal and subsequent collapse [11].", "startOffset": 113, "endOffset": 117}, {"referenceID": 3, "context": "The attribute we test on for attribute learning is whether the employee was a manager or not, which we took from [4].", "startOffset": 113, "endOffset": 116}, {"referenceID": 15, "context": "We use the change points from [16], which represent times when the emails undergo substantial shifts, such as the launch of Enron online and changes in the CEO position.", "startOffset": 30, "endOffset": 34}, {"referenceID": 6, "context": "This is a proximity network of 90 MIT students and faculty using data taken from cell phones from September 2004 to May 2005 (we only use data up until the end of the academic year) [7].", "startOffset": 182, "endOffset": 185}, {"referenceID": 15, "context": "points are taken from [16], which are the start and ends of vacations, semesters, etc.", "startOffset": 22, "endOffset": 26}, {"referenceID": 14, "context": "This is a proximity network of 23 employees at a data server configuration firm for a month (the name of the data set comes from the badges the employees wore to track their location at the workplace) [15].", "startOffset": 201, "endOffset": 205}, {"referenceID": 17, "context": "This is a proximity network consisting of interactions, recorded using Bluetooth, among attendees at an IEEE Infocomm conference over four days [18].", "startOffset": 144, "endOffset": 148}, {"referenceID": 8, "context": "This is another proximity network of attendees at the ACM Hypertext 2009 conference, held over three days [9].", "startOffset": 106, "endOffset": 109}, {"referenceID": 19, "context": "[20].", "startOffset": 0, "endOffset": 4}, {"referenceID": 4, "context": "[5] and the entropybased method (Entropy) of De Domenico et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[6].", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "to study the Reality Mining data set [7].", "startOffset": 37, "endOffset": 40}], "year": 2017, "abstractText": "For any stream of time-stamped edges that form a dynamic network, an important choice is the aggregation granularity that an analyst uses to bin the data. Picking such a windowing of the data is often done by hand, or left up to the technology that is collecting the data. However, the choice can make a big difference in the properties of the dynamic network. This is the time scale detection problem. In previous work, this problem is often solved with a heuristic as an unsupervised task. As an unsupervised problem, it is difficult to measure how well a given algorithm performs. In addition, we show that the quality of the windowing is dependent on which task an analyst wants to perform on the network after windowing. Therefore the time scale detection problem should not be handled independently from the rest of the analysis of the network. We introduce a framework that tackles both of these issues: By measuring the performance of the time scale detection algorithm based on how well a given task is accomplished on the resulting network, we are for the first time able to directly compare different time scale detection algorithms to each other. Using this framework, we introduce time scale detection algorithms that take a supervised approach: they leverage ground truth on training data to find a good windowing of the test data. We compare the supervised approach to previous approaches and several baselines on real data.", "creator": "LaTeX with hyperref package"}}}