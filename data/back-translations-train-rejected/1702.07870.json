{"id": "1702.07870", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Feb-2017", "title": "Online Learning with Many Experts", "abstract": "We study the problem of prediction with expert advice when the number of experts in question may be extremely large or even infinite. We devise an algorithm that obtains a tight regret bound of $\\widetilde{O}(\\epsilon T + N + \\sqrt{NT})$, where $N$ is the empirical $\\epsilon$-covering number of the sequence of loss functions generated by the environment. In addition, we present a hedging procedure that allows us to find the optimal $\\epsilon$ in hindsight.", "histories": [["v1", "Sat, 25 Feb 2017 10:27:29 GMT  (18kb)", "http://arxiv.org/abs/1702.07870v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["alon cohen", "shie mannor"], "accepted": false, "id": "1702.07870"}, "pdf": {"name": "1702.07870.pdf", "metadata": {"source": "CRF", "title": "Online Learning with Many Experts", "authors": ["Alon Cohen", "Shie Mannor"], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 170 2.07 870v 1 [cs.L G] Feb 25, 2017? NT q, where N is the empirical number of loss functions produced by the environment. Furthermore, we present a hedging method that allows us to find the optimal number of losses in retrospect. Finally, we discuss some interesting applications of our algorithm. We show how our algorithm applies to the approximately low-level expert model of Hazan et al., 2016, and discuss the case of experts with limited variation, in which there is a surprisingly large gap between the limits of regret obtained in statistical and online settings."}, {"heading": "1 Introduction", "text": "This year, the time has come for most of them to be able to move to another world in which they are unable to integrate."}, {"heading": "1.1 Our contributions", "text": "In this thesis, we examine the problem of prediction with expert advice when the number of experts is very large and even possibly unlimited. We show an online learning algorithm that is a repentance limit of rOptionT'N pB, LT q'a TN pB, LT qQ for a parameter where LT \"pB 1, HB 2,..., HB T q is the consequence of loss functions generated by the environment and N pB, LT q is the covering number of LT below the infinity norm. The algorithm does this by iteratively constructing a pack of experts on LT as it is gradually revealed to the learner. In addition, we will consider several applications and extensions of our algorithm. We will explain how to find the optimal solution automatically without prior knowledge and discuss some applications of our algorithm. In particular, we will discuss the case of binary losses and the application of our algorithm to the low-level expert model. We will also consider the interesting case of the number of experts with an ovariable conduction in the case of the ovariable number of the"}, {"heading": "1.2 Related work", "text": "In this case, although the number of people living in the EU is very high. (...) In the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the USA, in the EU, in the USA, in the EU, in the USA, in the USA, in the EU, in the EU, in the USA, in the USA, in the EU, in the USA, in the EU, in the EU, in the USA, in the EU, in the EU, in the USA, in the USA, in the EU, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the"}, {"heading": "2 Preliminaries and Main Results", "text": "In this section we provide some preliminary information, discuss the algorithm of exponential weights as well as the definition of the terms covering and packaging. Afterwards we present our most important results."}, {"heading": "2.1 Exponential weights", "text": "Algorithm 1 Exponential WeightParameters: Number of Experts K. Sentence: w1piq \"1 for all i\" 1, 2,..., K. for t = 1,2,.. doDefine distribution pt by ptpiq 9 wtpiq. Predictions It \"pt and suffer losses by tpItq. Set: throut\" an 8 logpKq {t.Update: wt '1piq \"wtpiq expp'\u03b7t\u0445 tpiqq for all i\" 1, 2,..., K. quit for exponential weights (Littlestone and Warmuth, 1989; Vovk, 1995; Cesa-Bianchi et al., 1997), also called Hedge and Randomized Weighted Majority, is a celebrated algorithm for predicting with expert advice for a finite number of experts. The variant we give here is presented in Algorithm 1, has an adaptive learning rate and therefore the algorithm.. t The length of predictions for each game is determined according to the random principle."}, {"heading": "2.2 Covering and packing", "text": "A coverage of a sequence of loss functions is a small finite subset of experts, so we intuitively find for each expert an expert in coverage with similar loss.Definition 1 (coverage): A coverage of a sequence of loss functions is a subset of experts S, which fulfills the following: For each expert i (not necessarily in S) there is an expert j P S, so for all t \"1, 2,..., T, however, we have a coverage that decreases monotonously in T. The following definition is in a sense the dual of a coverage, LT q, is the size of the smallest coverage of LT. An important implication of the definition is that the coverage number in T decreases monotonously."}, {"heading": "2.3 Main results", "text": "The first result shows that there is an algorithm that obtains a regret that depends on the empirical coverage number of the sequence of loss functions generated by the environment, without a direct dependence on the number of experts. Theorem 3. Suppose that the environment generates a sequence of loss functions. Suppose that the environment generates a sequence of loss functions. Suppose our algorithm is applicable even if the number of experts is infinite. Suppose that the number of experts reaches an expected regret of RT. \"rO\" N \"N\" N \"a TN\" a TN \"q\" a TN. \"Unlike Algorithm 1, our algorithm is applicable if the number of experts is infinite. Suppose that the number of experts, say K, then the above delimitation becomes significant if N.\" N \"c, LT\" q \"a TN.\""}, {"heading": "3 Algorithm", "text": "Our algorithm is represented in Algorithm 2. The algorithm starts with a group S containing an expert, and gradually builds up a group of experts for the sequence of loss functions generated by the environment. Namely, if there is an expert whose loss is more than 2,000 points away from all the experts in S., the algorithm adds them to S. This brings with it two guarantees for us: firstly, if S is not updated, the loss of any expert who is not in S. is no more than 2,000 points apart from the loss of one of the experts in S. Secondly, since our regret depends on the size of S., Lemma 2 implies that the size of S at the end of the game is at most that of a cover of the order. Furthermore, if S is not updated, the algorithm behaves exactly like Algorithm 1. Nevertheless, the algorithm behaves in the order S: whenever S is updated, the algorithm performs a restart: it sets the weights of the experts as well as the learning rate."}, {"heading": "3.1 Analysis", "text": "This means that the algorithm behaves exactly like algorithm 1 in each phase, within each phase that we have in each phase, in each phase that we have in the second phase. \"We have the length of the r'th phase, then of Lemma 1 the regret of the algorithm in this phase in relation to algorithm 1: Rr 4 a Tr logKr.Additionally, the loss of expert i in most 2s is away from the expert ir, and in between we have a single round in which the instantaneous repentance is realized in most 2s."}, {"heading": "4 Tuning \u01eb Automatically", "text": "In this section we prove to be the cumulative loss of algorithms r, so we do not know what the optimal loss of algorithms is. \"2q q q q q.\" \"2q q q.\" \"2q q.\" \"2q.\" \"2q.\" \"..\" \"..\" \"..\" \"..\" \"\".. \"\" \"..\" \"\".. \"\" \"\".. \"\" \"\".. \"\" \"\".. \"\" \"\".. \"\" \"\".. \"\" \"\".. \"\" \"\".. \"\" \"\".. \"\" \"\".. \"\" \"\" \"..\" \"\" \"..\" \"\" \"..\" \"\" \"\".. \"\" \"\" \"..\" \"\" \"\".. \"\" \"\" \"..\" \"\" \"..\" \"\" \"\".. \"\" \"\" \"\".. \"..\" \"\" \"\".. \"\" \"..\" \"\" \"..\" \"\" \"..\" \"\" \"..\" \"\" \"..\" \"\" \"\".. \"\" \"\".. \"\" \"\" \"..\" \"\" \"\".. \"\" \"\". \"\" \"\" \"\".. \"\" \"\" \"\" \"..\" \"\" \"\" \"\". \"\" \"\" \"\" \"\" \"..\" \"\" \".\" \"\" \"\". \"\" \"\" \"\" \""}, {"heading": "5 Applications", "text": "In this section, we will discuss a number of applications of the algorithm 2. First, we will discuss the case of binary losses, in which we can reach a regret limit depending on the number of experts with different loss sequences. Then, we will discuss the application of our algorithm to the low expert model and its generalization in the form of experts whose losses come from a sparse dictionary. Finally, we will approach the interesting case of experts with limited variation, in which we show a large gap between the regret of the stochastic and the online settings."}, {"heading": "5.1 Binary losses", "text": "Consider an environment in which the losses of the experts are binary, namely -1 or 1. In this case, we can reach a limit of repentance, which depends on the number of experts with different sequences of losses, without paying for an additional term linearly dependent on T. The following is a direct consequence of theorem 3. The following conclusion: Suppose N \"N p0, LT q is the 0-covering number of the sequence LT\" p\u0432 1, \u03942,..."}, {"heading": "5.2 Low rank experts", "text": "Suppose the number of experts K is limited, but very large."}, {"heading": "5.3 Losses from a sparse dictionary", "text": "\"It is not that we are able to accept the losses of the experts,\" says Lee et al, 2007), as well as evidence that the neurons of the V1 optical cortex use similar representations (Olshausen and Field, 1997). Below, we assume that the losses of the experts are approximately so small that the environment can play a strategy that satisfies the following strategies. \"It is a strategy that satisfies the following strategies.\""}, {"heading": "5.4 Experts with bounded variation", "text": "In this section, we assume that the variation of all experts is limited by V. Well-known results about the number of functions of the limited variation (Bartlett et al., 1994) show that in the stochastic i.i.d case, it is possible to learn such functions while one suffers only rOp? V T q regret. However, the situation in the online case is drastically different. For motivation reasons, if one considers the case of binary losses, then V {2 is a limit to the number of losses of an expert changes from -1 to 1 or vice versa during the T rounds of the game. Therefore, the number of experts with significant losses is 2 \u0159V {2i \"T '1 i\" i \"loss tied to the number of losses of an expert changes from -1 to 1 or vice versa during the T rounds of the game. Therefore, the number of experts with significant losses is 2 \u0159V {2i\" T \"i\" i. \"This means that we regret a guarantee for rOpT V {2q on the regret of the algorithm 2, the vial problem we have for the following algorithm?"}, {"heading": "6 Discussion and Open Problems", "text": "In this paper, we have shown an algorithm that reaches a regret limit that is independent of the number of experts. This dependence is replaced by a certain regret number that regulates the complexity of the observed sequence of loss functions. We have also shown how to automatically adjust the accuracy parameters of our algorithm. Finally, we have presented a number of applications of our algorithm, which include binary losses, low-ranking experts and experts with limited variation.Unfortunately, the regret number used by our algorithm can typically be very large for many important applications. Since we ideally want to choose \"op1q,\" it is an interesting direction for future work to try and find an easy way to quantify which classes of environments produce small regret numbers for such values. Furthermore, compared to that of Hazan et al. (2016) in their setting, our result is exponentially worse in the dimension of loss matrix compression. It remains an open problem to find an algorithm that has a narrow direction."}, {"heading": "A Additional Proofs", "text": "In fact, if you assume that everyone is an expert in S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S S"}], "references": [{"title": "rmk-svd: An algorithm for designing overcomplete dictionaries for sparse representation", "author": ["M. Aharon", "M. Elad", "A. Bruckstein"], "venue": "IEEE Transactions on signal processing,", "citeRegEx": "Aharon et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Aharon et al\\.", "year": 2006}, {"title": "The approximate rank of a matrix and its algorithmic applications: approximate rank", "author": ["N. Alon", "T. Lee", "A. Shraibman", "S. Vempala"], "venue": "In Proceedings of the forty-fifth annual ACM symposium on Theory of computing,", "citeRegEx": "Alon et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Alon et al\\.", "year": 2013}, {"title": "Fat-shattering and the learnability of realvalued functions", "author": ["P.L. Bartlett", "P.M. Long", "R.C. Williamson"], "venue": "In Proceedings of the seventh annual conference on Computational learning theory,", "citeRegEx": "Bartlett et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Bartlett et al\\.", "year": 1994}, {"title": "Agnostic online learning", "author": ["S. Ben-David", "D. P\u00e1l", "S. Shalev-Shwartz"], "venue": "In COLT,", "citeRegEx": "Ben.David et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Ben.David et al\\.", "year": 2009}, {"title": "How to use expert advice", "author": ["N. Cesa-Bianchi", "G. Lugosi"], "venue": "Journal of the ACM (JACM),", "citeRegEx": "Cesa.Bianchi and Lugosi,? \\Q1997\\E", "shortCiteRegEx": "Cesa.Bianchi and Lugosi", "year": 1997}, {"title": "Prediction with advice of unknown number of experts", "author": ["A. Chernov", "V. Vovk"], "venue": null, "citeRegEx": "Chernov and Vovk.,? \\Q2009\\E", "shortCiteRegEx": "Chernov and Vovk.", "year": 2009}, {"title": "Sparse coding with an overcomplete basis set: A strategy", "author": ["B.A. Olshausen", "D.J. Field"], "venue": "Computer Science,", "citeRegEx": "Olshausen and Field.,? \\Q1989\\E", "shortCiteRegEx": "Olshausen and Field.", "year": 1989}, {"title": "Statistical learning theory, volume 1", "author": ["V.N. Vapnik"], "venue": "Advances in Neural Information Processing Systems,", "citeRegEx": "Vapnik.,? \\Q1998\\E", "shortCiteRegEx": "Vapnik.", "year": 1998}], "referenceMentions": [{"referenceID": 3, "context": "This can occur, for example, in online supervised learning (Ben-David et al., 2009), adaptive algorithms (van Erven and Koolen,", "startOffset": 59, "endOffset": 83}, {"referenceID": 7, "context": "These include machine learning (Vapnik, 1998), empirical processes (Pollard, 1990) and information theory (Roman, 1992).", "startOffset": 31, "endOffset": 45}, {"referenceID": 0, "context": "This modeling is motivated by the empirical success (Aharon et al., 2006; Lee et al., 2007), as well as evidence that, for example, the neurons of the V1 optical cortex use similar representations (Olshausen and Field, 1997).", "startOffset": 52, "endOffset": 91}, {"referenceID": 2, "context": "Well known results about the covering numbers of functions of bounded variation (Bartlett et al., 1994) show that in the stochastic i.", "startOffset": 80, "endOffset": 103}, {"referenceID": 2, "context": "Well known results about the covering numbers of functions of bounded variation (Bartlett et al., 1994) show that in the stochastic i.i.d case, it is possible to learn such functions while suffering only r Op ? V T q regret. However, the situation is drastically different in the online case. For motivation consider the case of binary losses, then V {2 is a bound on the number of times the loss of an expert changes from -1 to 1 or vice versa, during the T rounds of the game. Therefore, the number of experts with distinct losses is 2 \u0159V {2 i\u201c0 ` T \u03011 i \u0306 \u201c OpT V {2q. This entails that by Corollary 5, we have the a guarantee of r OpT V {2q on the regret of Algorithm 2, which is trivial even for V \u201c 2! This leaves us with the following problem: does there exists an algorithm for online learning that attains r Op ? V T q regret when the variation of all experts is bounded by V ? We answer this question negatively. First note that the interesting regime is when T \u0103 logK, otherwise we can obtain a tight \u0398p ? V logKq bound of Hazan and Kale (2010). However, if T \u0103 logK, even if V \u201c Op1q we cannot expect the desired regret bound, as shown in the following result.", "startOffset": 81, "endOffset": 1056}], "year": 2017, "abstractText": "We study the problem of prediction with expert advice when the number of experts in question may be extremely large or even infinite. We devise an algorithm that obtains a tight regret bound of r Op\u01ebT `N ` ? NT q, where N is the empirical \u01eb-covering number of the sequence of loss functions generated by the environment. In addition, we present a hedging procedure that allows us to find the optimal \u01eb in hindsight. Finally, we discuss a few interesting applications of our algorithm. We show how our algorithm is applicable in the approximately low rank experts model of Hazan et al., 2016, and discuss the case of experts with bounded variation, in which there is a surprisingly large gap between the regret bounds obtained in the statistical and online settings.", "creator": "LaTeX with hyperref package"}}}