{"id": "1702.07983", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Feb-2017", "title": "Maximum-Likelihood Augmented Discrete Generative Adversarial Networks", "abstract": "Despite the successes in capturing continuous distributions, the application of generative adversarial networks (GANs) to discrete settings, like natural language tasks, is rather restricted. The fundamental reason is the difficulty of back-propagation through discrete random variables combined with the inherent instability of the GAN training objective. To address these problems, we propose Maximum-Likelihood Augmented Discrete Generative Adversarial Networks. Instead of directly optimizing the GAN objective, we derive a novel and low-variance objective using the discriminator's output that follows corresponds to the log-likelihood. Compared with the original, the new objective is proved to be consistent in theory and beneficial in practice. The experimental results on various discrete datasets demonstrate the effectiveness of the proposed approach.", "histories": [["v1", "Sun, 26 Feb 2017 03:19:13 GMT  (284kb,D)", "http://arxiv.org/abs/1702.07983v1", "11 pages, 3 figures"]], "COMMENTS": "11 pages, 3 figures", "reviews": [], "SUBJECTS": "cs.AI cs.CL cs.LG", "authors": ["tong che", "yanran li", "ruixiang zhang", "r devon hjelm", "wenjie li", "yangqiu song", "yoshua bengio"], "accepted": false, "id": "1702.07983"}, "pdf": {"name": "1702.07983.pdf", "metadata": {"source": "META", "title": "Maximum-Likelihood Augmented Discrete Generative Adversarial Networks", "authors": ["Tong Che", "Yanran Li", "Ruixiang Zhang", "R Devon Hjelm", "Wenjie Li", "Yangqiu Song", "Yoshua Bengio"], "emails": ["<tong.che@umontreal.ca>."], "sections": [{"heading": "1. Introduction", "text": "This year, it is only a matter of time before there is a result in which there is a result."}, {"heading": "2. Preliminaries and Overview", "text": "The basic framework for discrete sequence generation is the adaptation to a set of data {xi} Ni = 1 derived from an underlying generating distribution pd by using a parameterized autoregressive probabilistic model p\u03b8.In this work, we aim to generate discrete data, especially discrete sequential data, under the GAN setting q (Goodfellow et al., 2014).GAN defines a framework for generative educational models by positioning it as a minimax game against a discriminatory model.The goal of generator G is to match its distribution pg to the real data distribution pd. To achieve this, the generator transforms the noise z executed from p (z) to a data sample G (z).The discriminator D is trained to distinguish between samples from pd and pg, and can be used to provide a training signal to the generator of the standard parameters of the GAN when applying the discrete framework to the updating."}, {"heading": "3. Maximum-Likelihood Augmented Discrete Generative Adversarial Networks", "text": "In this section we present the details of the proposed model. The core of this model is a novel training objective that significantly reduces variance during training, including the theoretical and practical analysis of equivalence and attractive properties of the object. We also show how this core algorithm can be combined with several variance reduction techniques to form the complete MaliGAN algorithm for discrete sequence generation."}, {"heading": "3.1. Basic Model of MaliGAN", "text": "With MaliGAN, we train a discriminator D (x) with the default target that GAN uses. What is different from GANs is a novel target for the generator for optimization, using a delayed copy p \u00b2 (x) of the generator, whose parameters are updated less often to stabilize the training. As for the basic property of the GANs, we know that an optimal D has the property D (x) = pdpd + p \u00b2 distribution, so in this case we have a delayed copy p \u00b2 (x) of the generator, whose parameters are updated less often to stabilize the target distribution."}, {"heading": "3.2. Analysis", "text": "The proposed objective in Eq. 2 is also theoretically assured that we have ownership of almost two billion euros. In the following theory, we show that our training goal roughly optimizes the KL divergence KL (x). (i) If the objective is still meaningful, we have the following two theoretical guarantees for our new training goal. (i) If the objective between delayed generator p (x) and real data distribution pd is optimal, we have the following equation. (ii) If D (x) is well trained but not sufficiently trained, then we have the following two theoretical guarantees for our new training goal. (x) If the results are not balanced, then we can set the objective between delayed generator p (x) and real data distribution pd (x). (ii) If D (x) is well trained but not sufficient, then we are able to range between 0.5 and pdpd (x)."}, {"heading": "3.3. Variance Reduction in MaliGAN", "text": "The proposed renormalized target in MaliGAN supports a much more stable training behavior than the RL target in a standard GAN. However, if the long sequence generation process consists of multiple steps of the sample, we find it better to further integrate the following advanced techniques for variance reduction."}, {"heading": "3.3.1. MONTE CARLO TREE SEARCH", "text": "Instead of using the same weight for all time steps in a sample, we use the following formula, which is well known in the RL literature: Ep\u03b8 [rD (x), p (x)] = Ep\u03b8 [L \u2211 t = 1 Q (at, st), where Q (a, s) stands for the \"expected total reward\" given by rD = D1 \u2212 D for generating tokens of a given previous generation s, which can be estimated e.g. with the Monte Carlo tree search (MCTS, Silver et al. (2016).) Therefore, according to the gradient estimator presented in Theorem 3.1, we derive another gradient estimator: \"LG,\" \"i Lim-Q (ait, s i t) m, Li-i, t Q (ait, s i t),\" log pIS (ait | sit), where m is the size of the mini-batch."}, {"heading": "3.3.2. MIXED MLE-MALI TRAINING", "text": "x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x"}, {"heading": "3.3.3. SINGLE REAL DATA BASED RENORMALIZATION", "text": "Many generative models have multiple layers of random variants; for example, in auto-regressive models, random samples are generated using multiple sampling steps; other examples include hierarchical generative models such as deep Boltzmann machines and deep networks of belief (Salakhutdinov & Hinton, 2009), in which random variables are usually responsible for modelling high-level decisions or \"modes\" of probability distribution, and changing them can have much greater effects than this results from changing low variables. Motivated by this observation, we first draw a mini-batch of samples (e.g. 32) of latent variables at the highest level, and then for each high value we can draw (e.g. 32); then we reestimate the partition function Z from the lower sampling levels generated by each high-level sample."}, {"heading": "4. Experiments", "text": "To investigate the effectiveness of the proposed algorithms, we conduct experiments on three discrete sequence generation tasks. In all three tasks, we achieve promising results, including a standard and challenging language modeling task. Based on the empirical results and the following analysis, we demonstrate the solidity of MaliGAN and demonstrate its robustness to the point of adaptation."}, {"heading": "4.1. Discrete MNIST", "text": "We first evaluate MaliGAN using the task of binarized image generation for the handwritten digit data set of MNIST, similar to Hjelm et al. (2017).The original data sets contain 60,000 and 10,000 samples in the training and test sets, respectively. We divide the training data set and randomly select 10,000 samples for validation. We use as a generator a deep convolutionary neural network based on the DCGAN architecture (Radford et al., 2015).To generate the individual samples, we take samples from the binomial distribution of the generator. We use the MaliGAN algorithm 1 for training and use the single latent variable renormalization technique to reduce variance. In order to compare our proposed MaliGAN models with the models that are trained as a direct reward based on the results of the discriminator, we also train a generator with the same network architecture, but use the output of the discriminator as the weight of the generated samples. We refer to them as the first INFORFAN model and the first two similar losses in the INFORFAN."}, {"heading": "4.2. Poem Generation", "text": "Typically, there are two types of Chinese poems. We refer to those consisting of 5 or 7 Chinese characters, each in a short sentence, with Poem-5 and Poem-7. We use the data set provided in (Zhang & Lapata, 2014) and divide them in the standard method. The generator is a single-layer LSTM (Hochreiter & Juergen Schmidhuber, 1997) with 32 hidden units for Poem-5 and 100 for Poem-7. Our discriminators are two-layer BiLSTMs with 32 hidden neurons. We refer to our models fully trained with Algorithm 1 and Algorithm 2 as MaliGANbasic and MaliGAN. We choose two compared models, the auto-regressive model with the same architecture but with maximum probability of being trained (MLE), and SeqGAN (Yu et al, 2017)."}, {"heading": "4.3. Sentence-Level Language Modeling", "text": "We examine the proposed algorithm for a more difficult task, set-level speech modeling, which can be considered a basic task with applications for different discrete sequence generations. To explore the possibilities and limitations of our algorithm, we conduct extensive experiments on the standard Penn Treebank (PTB) dataset through parameter search and model ablation. For evaluation, we report on set-level perplexity, which is the average perplexity of all sentences in the test set. For simplicity and efficiency, we adopt a 1-layer GRU (Cho et al., 2014) as our generator, and set the same setting for the base model forced with standard teacher (Williams & Zipser, 1989)."}, {"heading": "5. Related Work", "text": "In order to improve the performance of these two topics, the metrics need to be incorporated into the objective training phases, because in 2016 they cannot be discussed in detail in 2016. (Ranzato et al., 2016; Serban et al., 2016; Wiseman & Rush, 2016) The problem occurs when the training algorithms prohibit models from being exposed to their own predictions during training (2016); the second problem is the discrepancy between the targets during training and the evaluation during the test, which are analyzed in Ranzato et al. (2016) and then summarized as a loss-evaluation mismatch by Wiseman & Rush (2016). Typical is the discrepancy between the targets in training are auto-regressive models to maximize the probabilities at word level, while we often evaluate the models using sequence level metrics, such as BLEU et al., 2002)."}, {"heading": "6. Discussions and Future Work", "text": "Despite their great popularity on continuous datasets such as images, GANs have not yet achieved equivalent success in discrete areas such as natural language processing. We observed that the main cause of this gap is that while the discriminator is known to be able to tell the good from the bad samples almost perfectly, it is notoriously difficult to pass this information on to the generator due to the difficulty of lending through discrete calculation and the inherent instability of RL algorithms applied to dynamic environments. However, in this work we take a different approach. We start with the maximum probability training target KL (pd | p\u03b8) and then use importance samples combined with the discriminator output to derive a novel training target. We argue that although this target is similar to the one used in amplification learning, normalization actually reduces the variance of the estimator by ignoring the region in the data space the singularity of D."}], "references": [{"title": "Globally normalized transition-based neural networks", "author": ["Andor", "Daniel", "Alberti", "Chris", "Weiss", "David", "Severyn", "Aliaksei", "Presta", "Alessandro", "Ganchev", "Kuzman", "Petrov", "Slav", "Collins", "Michael"], "venue": null, "citeRegEx": "Andor et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Andor et al\\.", "year": 2016}, {"title": "Towards principled methods for training generative adversarial networks", "author": ["Arjovsky", "Mart\u0131\u0301n", "Bottou", "L\u00e9on"], "venue": null, "citeRegEx": "Arjovsky et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Arjovsky et al\\.", "year": 2017}, {"title": "Scheduled sampling for sequence prediction with recurrent neural networks", "author": ["Bengio", "Samy", "Vinyals", "Oriol", "Jaitly", "Navdeep", "Shazeer", "Noam"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Bengio et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 2015}, {"title": "Reweighted wakesleep", "author": ["Bornschein", "J\u00f6rg", "Bengio", "Yoshua"], "venue": "In Proceedings of the International Conference on Learning Representations (ICLR),", "citeRegEx": "Bornschein et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Bornschein et al\\.", "year": 2015}, {"title": "Generating sentences from a continuous space", "author": ["Bowman", "Samuel R", "Vilnis", "Luke", "Vinyals", "Oriol", "Dai", "Andrew M", "Jozefowicz", "Rafal", "Bengio", "Samy"], "venue": "arXiv preprint arXiv:1511.06349,", "citeRegEx": "Bowman et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Bowman et al\\.", "year": 2015}, {"title": "Mode regularized generative adversarial networks", "author": ["Che", "Tong", "Li", "Yanran", "Jacob", "Athul Paul", "Bengio", "Yoshua", "Wenjie"], "venue": "arXiv preprint arXiv:1612.02136,", "citeRegEx": "Che et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Che et al\\.", "year": 2016}, {"title": "One billion word benchmark for measuring progress in statistical language modeling", "author": ["Chelba", "Ciprian", "Mikolov", "Tomas", "Schuster", "Mike", "Ge", "Qi", "Brants", "Thorsten", "Koehn", "Phillipp"], "venue": "CoRR, abs/1312.3005,", "citeRegEx": "Chelba et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Chelba et al\\.", "year": 2014}, {"title": "On the properties of neural machine translation: Encoder-decoder approaches", "author": ["Cho", "Kyunghyun", "Van Merri\u00ebnboer", "Bart", "Bahdanau", "Dzmitry", "Bengio", "Yoshua"], "venue": "arXiv preprint arXiv:1409.1259,", "citeRegEx": "Cho et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Cho et al\\.", "year": 2014}, {"title": "Generative adversarial nets", "author": ["Goodfellow", "Ian", "Pouget-Abadie", "Jean", "Mirza", "Mehdi", "Xu", "Bing", "Warde-Farley", "David", "Ozair", "Sherjil", "Courville", "Aaron", "Bengio", "Yoshua"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Goodfellow et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2014}, {"title": "Boundary-seeking generative adversarial networks. 2017", "author": ["Hjelm", "R Devon", "Jacob", "Athul", "Che", "Tong", "Cho", "Kyunghyun", "Bengio", "Yoshua"], "venue": null, "citeRegEx": "Hjelm et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Hjelm et al\\.", "year": 2017}, {"title": "Long shortterm memory", "author": ["Hochreiter", "Sepp", "J\u00fcrgen Schmidhuber"], "venue": "Neural Computation,", "citeRegEx": "Hochreiter et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter et al\\.", "year": 1997}, {"title": "Policy gradient methods for reinforcement learning with function approximation", "author": ["C. Igel"], "venue": null, "citeRegEx": "Igel,? \\Q2005\\E", "shortCiteRegEx": "Igel", "year": 2005}, {"title": "Professor forcing: A new algorithm for training recurrent networks", "author": ["Lamb", "Alex", "Goyal", "Anirudh", "Zhang", "Ying", "Saizheng", "Courville", "Aaron C", "Bengio", "Yoshua"], "venue": "In Advances In Neural Information Processing Systems,", "citeRegEx": "Lamb et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Lamb et al\\.", "year": 2016}, {"title": "Photo-realistic single image super-resolution using a generative adversarial network", "author": ["Ledig", "Christian", "Theis", "Lucas", "Husz\u00e1r", "Ferenc", "Caballero", "Jose", "Aitken", "Andrew", "Tejani", "Alykhan", "Totz", "Johannes", "Wang", "Zehan", "Shi", "Wenzhe"], "venue": "arXiv preprint arXiv:1609.04802,", "citeRegEx": "Ledig et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Ledig et al\\.", "year": 2016}, {"title": "Adversarial learning for neural dialogue generation", "author": ["Li", "Jiwei", "Monroe", "Will", "Shi", "Tianlin", "Ritter", "Alan", "Jurafsky", "Dan"], "venue": "arXiv preprint arXiv:1701.06547,", "citeRegEx": "Li et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Li et al\\.", "year": 2017}, {"title": "Optimization of image description metrics using policy gradient methods", "author": ["Liu", "Siqi", "Zhu", "Zhenhai", "Ye", "Ning", "Guadarrama", "Sergio", "Murphy", "Kevin"], "venue": null, "citeRegEx": "Liu et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2016}, {"title": "Building a large annotated corpus of english: The penn treebank", "author": ["Marcus", "Mitchell P", "Marcinkiewicz", "Mary Ann", "Santorini", "Beatrice"], "venue": "Computational linguistics,", "citeRegEx": "Marcus et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Marcus et al\\.", "year": 1993}, {"title": "Deep multi-scale video prediction beyond mean square error", "author": ["Mathieu", "Michael", "Couprie", "Camille", "LeCun", "Yann"], "venue": "In Proceedings of the International Conference on Learning Representations (ICLR),", "citeRegEx": "Mathieu et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Mathieu et al\\.", "year": 2016}, {"title": "Neural variational inference for text processing", "author": ["Miao", "Yishu", "Yu", "Lei", "Blunsom", "Phil"], "venue": null, "citeRegEx": "Miao et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Miao et al\\.", "year": 2016}, {"title": "Conditional generative adversarial nets", "author": ["Mirza", "Mehdi", "Osindero", "Simon"], "venue": "arXiv preprint arXiv:1411.1784,", "citeRegEx": "Mirza et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Mirza et al\\.", "year": 2014}, {"title": "Plug & play generative networks: Conditional iterative generation of images in latent space", "author": ["Nguyen", "Anh", "Yosinski", "Jason", "Bengio", "Yoshua", "Dosovitskiy", "Alexey", "Clune", "Jeff"], "venue": "arXiv preprint arXiv:1612.00005,", "citeRegEx": "Nguyen et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Nguyen et al\\.", "year": 2016}, {"title": "Reward augmented maximum likelihood for neural structured prediction", "author": ["Norouzi", "Mohammad", "Bengio", "Samy", "Chen", "Zhifeng", "Jaitly", "Navdeep", "Schuster", "Mike", "Wu", "Yonghui", "Schuurmans", "Dale"], "venue": "In NIPS,", "citeRegEx": "Norouzi et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Norouzi et al\\.", "year": 2016}, {"title": "Reward augmented maximum likelihood for neural structured prediction", "author": ["Norouzi", "Mohammad", "Bengio", "Samy", "Jaitly", "Navdeep", "Schuster", "Mike", "Wu", "Yonghui", "Schuurmans", "Dale"], "venue": "In Advances In Neural Information Processing Systems,", "citeRegEx": "Norouzi et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Norouzi et al\\.", "year": 2016}, {"title": "Unsupervised representation learning with deep convolutional generative adversarial networks", "author": ["Radford", "Alec", "Metz", "Luke", "Chintala", "Soumith"], "venue": "arXiv preprint arXiv:1511.06434,", "citeRegEx": "Radford et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Radford et al\\.", "year": 2015}, {"title": "Sequence level training with recurrent neural networks", "author": ["Ranzato", "Marc\u2019Aurelio", "Chopra", "Sumit", "Auli", "Michael", "Zaremba", "Wojciech"], "venue": "In Proceedings of the International Conference on Learning Representations (ICLR),", "citeRegEx": "Ranzato et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Ranzato et al\\.", "year": 2016}, {"title": "Generative adversarial text-to-image synthesis", "author": ["Reed", "Scott", "Akata", "Zeynep", "Yan", "Xinchen", "Logeswaran", "Lajanugen", "Schiele", "Bernt", "Lee", "Honglak"], "venue": "In Proceedings of The 33rd International Conference on Machine Learning,", "citeRegEx": "Reed et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Reed et al\\.", "year": 2016}, {"title": "Temporal generative adversarial nets", "author": ["Saito", "Masaki", "Matsumoto", "Eiichi"], "venue": "arXiv preprint arXiv:1611.06624,", "citeRegEx": "Saito et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Saito et al\\.", "year": 2016}, {"title": "Deep boltzmann machines", "author": ["Salakhutdinov", "Ruslan", "Hinton", "Geoffrey E"], "venue": "In AISTATS,", "citeRegEx": "Salakhutdinov et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Salakhutdinov et al\\.", "year": 2009}, {"title": "Improved techniques for training", "author": ["Salimans", "Tim", "Goodfellow", "Ian J", "Zaremba", "Wojciech", "Cheung", "Vicki", "Radford", "Alec", "Chen", "Xi"], "venue": "gans. CoRR,", "citeRegEx": "Salimans et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Salimans et al\\.", "year": 2016}, {"title": "Building end-toend dialogue systems using generative hierarchical neural network models", "author": ["Serban", "Iulian V", "Sordoni", "Alessandro", "Bengio", "Yoshua", "Courville", "Aaron", "Pineau", "Joelle"], "venue": "In AAAI-16,", "citeRegEx": "Serban et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Serban et al\\.", "year": 2016}, {"title": "Mastering the game of go with deep neural networks and tree", "author": ["Sutskever", "Ilya", "Lillicrap", "Timothy", "Leach", "Madeleine", "Kavukcuoglu", "Koray", "Graepel", "Thore", "Hassabis", "Demis"], "venue": "search. Nature,", "citeRegEx": "Sutskever et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2016}, {"title": "Amortised map inference for image super-resolution", "author": ["S\u00f8nderby", "Casper Kaae", "Caballero", "Jose", "Theis", "Lucas", "Shi", "Wenzhe", "Husz\u00e1r", "Ferenc"], "venue": "In Proceedings of the International Conference on Learning Representations (ICLR),", "citeRegEx": "S\u00f8nderby et al\\.,? \\Q2017\\E", "shortCiteRegEx": "S\u00f8nderby et al\\.", "year": 2017}, {"title": "A neural network approach to context-sensitive generation of conversational responses", "author": ["Sordoni", "Alessandro", "Galley", "Michel", "Auli", "Michael", "Brockett", "Chris", "Ji", "Yangfeng", "Mitchell", "Margaret", "Nie", "Jian-Yun", "Gao", "Jianfeng", "Dolan", "William B"], "venue": "In HLT-NAACL,", "citeRegEx": "Sordoni et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Sordoni et al\\.", "year": 2015}, {"title": "Simple statistical gradient-following algorithms for connectionist reinforcement learning", "author": ["Williams", "Ronald J"], "venue": "Machine learning,", "citeRegEx": "Williams and J.,? \\Q1992\\E", "shortCiteRegEx": "Williams and J.", "year": 1992}, {"title": "A learning algorithm for continually running fully recurrent neural networks", "author": ["Williams", "Ronald J", "Zipser", "David"], "venue": "Neural computation,", "citeRegEx": "Williams et al\\.,? \\Q1989\\E", "shortCiteRegEx": "Williams et al\\.", "year": 1989}, {"title": "Sequence-tosequence learning as beam-search optimization", "author": ["Wiseman", "Sam", "Rush", "Alexander M"], "venue": "Proceeddings of Conference on Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Wiseman et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Wiseman et al\\.", "year": 2016}, {"title": "Seqgan: sequence generative adversarial nets with policy gradient", "author": ["Yu", "Lantao", "Zhang", "Weinan", "Wang", "Jun", "Yong"], "venue": "In Thirty-First AAAI Conference on Artificial Intelligence", "citeRegEx": "Yu et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Yu et al\\.", "year": 2017}, {"title": "Variational neural machine translation", "author": ["Zhang", "Biao", "Xiong", "Deyi", "Su", "Jinsong", "Duan", "Hong", "Min"], "venue": "In EMNLP,", "citeRegEx": "Zhang et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2016}, {"title": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "author": ["Zhang", "Han", "Xu", "Tao", "Li", "Hongsheng", "Shaoting", "Huang", "Xiaolei", "Wang", "Xiaogang", "Metaxas", "Dimitris"], "venue": null, "citeRegEx": "Zhang et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2016}, {"title": "Chinese poetry generation with recurrent neural networks", "author": ["Zhang", "Xingxing", "Lapata", "Mirella"], "venue": "In EMNLP, pp", "citeRegEx": "Zhang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2014}, {"title": "Learning temporal transformations from time-lapse videos", "author": ["Zhou", "Yipin", "Berg", "Tamara L"], "venue": "In European Conference on Computer Vision,", "citeRegEx": "Zhou et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Zhou et al\\.", "year": 2016}, {"title": "Generative visual manipulation on the natural image manifold", "author": ["Zhu", "Jun-Yan", "Kr\u00e4henb\u00fchl", "Philipp", "Shechtman", "Eli", "Efros", "Alexei A"], "venue": "In Proceedings of European Conference on Computer Vision (ECCV),", "citeRegEx": "Zhu et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Zhu et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 32, "context": "However, the generated sentences are often unsatisfactory (Sordoni et al., 2015; Bowman et al., 2015; Serban et al., 2017; Wiseman & Rush, 2016).", "startOffset": 58, "endOffset": 144}, {"referenceID": 4, "context": "However, the generated sentences are often unsatisfactory (Sordoni et al., 2015; Bowman et al., 2015; Serban et al., 2017; Wiseman & Rush, 2016).", "startOffset": 58, "endOffset": 144}, {"referenceID": 4, "context": "For example, they often lack of consistency in long-term semantics and have less coherence in high-level topics and syntactics (Bowman et al., 2015; Zhang et al., 2016a).", "startOffset": 127, "endOffset": 169}, {"referenceID": 24, "context": "generate discrete sequences, it is popular to adopt autoregressive models through teacher forcing (Williams & Zipser, 1989) which, nevertheless, causes the exposure bias problem (Ranzato et al., 2016).", "startOffset": 178, "endOffset": 200}, {"referenceID": 24, "context": "It prohibits the trained model to take advantage of learning in the the context of its previous generated words to make the next prediction, resulting in a bias and difficulty in approaching the true underlying distribution (Ranzato et al., 2016; Bengio et al., 2015).", "startOffset": 224, "endOffset": 267}, {"referenceID": 2, "context": "It prohibits the trained model to take advantage of learning in the the context of its previous generated words to make the next prediction, resulting in a bias and difficulty in approaching the true underlying distribution (Ranzato et al., 2016; Bengio et al., 2015).", "startOffset": 224, "endOffset": 267}, {"referenceID": 18, "context": "usual RNNs, LSTMs or GRUs) on multiple tasks (Serban et al., 2017; Miao et al., 2016; Zhang et al., 2016a).", "startOffset": 45, "endOffset": 106}, {"referenceID": 8, "context": "An alternative and attractive solution to training autoregressive models is using generative adversarial networks (GAN) (Goodfellow et al., 2014).", "startOffset": 120, "endOffset": 145}, {"referenceID": 9, "context": "The procedure was discovered independently from us by Hjelm et al. (2017) in the context of image generation.", "startOffset": 54, "endOffset": 74}, {"referenceID": 8, "context": "In this work, we aim to generate discrete data, especially discrete sequential data, under the GAN setting (Goodfellow et al., 2014).", "startOffset": 107, "endOffset": 132}, {"referenceID": 36, "context": "Though the dedicated pre-training and variance reduction mechanisms help (Yu et al., 2017), the RL algorithm based on the moving reward signal still seems very unstable and does not work on large scale datasets.", "startOffset": 73, "endOffset": 90}, {"referenceID": 9, "context": "This importance sampling procedure was discovered independently from us by (Hjelm et al., 2017).", "startOffset": 75, "endOffset": 95}, {"referenceID": 24, "context": "When training auto-regressive models with teacher forcing, a serious problem is exposure bias (Ranzato et al., 2016; Norouzi et al., 2016b; Lamb et al., 2016).", "startOffset": 94, "endOffset": 158}, {"referenceID": 12, "context": "When training auto-regressive models with teacher forcing, a serious problem is exposure bias (Ranzato et al., 2016; Norouzi et al., 2016b; Lamb et al., 2016).", "startOffset": 94, "endOffset": 158}, {"referenceID": 24, "context": "Then during our training procedure, inspired from Ranzato et al. (2016), we slowly move N from T towards 0.", "startOffset": 50, "endOffset": 72}, {"referenceID": 5, "context": "Second, this normalization scheme makes our model robust to mode missing, which is a common failure pattern when training GANs (Che et al., 2016).", "startOffset": 127, "endOffset": 145}, {"referenceID": 23, "context": "We adopted as the generator a deep convolutional neural network based on the DCGAN architecture (Radford et al., 2015).", "startOffset": 96, "endOffset": 118}, {"referenceID": 9, "context": "We first evaluate MaliGAN on the binarized image generation task for the MNIST hand-written digits dataset, similar with Hjelm et al. (2017). The original datasets have 60,000 and 10,000 samples in the training and testing sets, respectively.", "startOffset": 121, "endOffset": 141}, {"referenceID": 36, "context": "We choose two compared models, the auto-regressive model with same architecture but trained with maximum likelihood (MLE), and SeqGAN (Yu et al., 2017).", "startOffset": 134, "endOffset": 151}, {"referenceID": 36, "context": "We choose two compared models, the auto-regressive model with same architecture but trained with maximum likelihood (MLE), and SeqGAN (Yu et al., 2017). Following Yu et al. (2017), we report the BLEU-2 scores in Table 4.", "startOffset": 135, "endOffset": 180}, {"referenceID": 36, "context": "The result of SeqGAN is directly taken from (Yu et al., 2017).", "startOffset": 44, "endOffset": 61}, {"referenceID": 16, "context": "To explore the possibilities and limitations of our algorithm, we conduct extensive experiments on the standard Penn Treebank (PTB) dataset (Marcus et al., 1993) through parameter searching and model ablations.", "startOffset": 140, "endOffset": 161}, {"referenceID": 7, "context": "For simplicity and efficiency, we adopt a 1-layer GRU (Cho et al., 2014) as our generator, and set the same setting for the baseline model trained with standard teacher forcing(Williams & Zipser, 1989).", "startOffset": 54, "endOffset": 72}, {"referenceID": 24, "context": "To improve the performance of discrete auto-regressive models, some researchers aim to tackle the exposure bias problem, which is discussed detailed in (Ranzato et al., 2016; Serban et al., 2016; Wiseman & Rush, 2016).", "startOffset": 152, "endOffset": 217}, {"referenceID": 29, "context": "To improve the performance of discrete auto-regressive models, some researchers aim to tackle the exposure bias problem, which is discussed detailed in (Ranzato et al., 2016; Serban et al., 2016; Wiseman & Rush, 2016).", "startOffset": 152, "endOffset": 217}, {"referenceID": 11, "context": "(2016) shares similar idea and directly optimizes image caption metrics through policy gradient methods (Igel, 2005).", "startOffset": 104, "endOffset": 116}, {"referenceID": 0, "context": "There exists a third issue, namely Label Bias, especially in sequence-to-sequence learning framework, which obstacles the MLE trained models to be optimized globally (Andor et al., 2016; Wiseman & Rush, 2016)", "startOffset": 166, "endOffset": 208}, {"referenceID": 21, "context": "The second issue is the discrepancy between the objective during training and the evaluation metric during testing, which is analyzed in Ranzato et al. (2016) and then summarized as Loss-Evaluation Mismatch by Wiseman & Rush (2016).", "startOffset": 137, "endOffset": 159}, {"referenceID": 21, "context": "The second issue is the discrepancy between the objective during training and the evaluation metric during testing, which is analyzed in Ranzato et al. (2016) and then summarized as Loss-Evaluation Mismatch by Wiseman & Rush (2016). Typically, the objectives in training auto-regressive models are to maximize the word-level probabilities, while in test-time, we often evaluate the models using sequencelevel metrics, such as BLEU (Papineni et al.", "startOffset": 137, "endOffset": 232}, {"referenceID": 21, "context": "The second issue is the discrepancy between the objective during training and the evaluation metric during testing, which is analyzed in Ranzato et al. (2016) and then summarized as Loss-Evaluation Mismatch by Wiseman & Rush (2016). Typically, the objectives in training auto-regressive models are to maximize the word-level probabilities, while in test-time, we often evaluate the models using sequencelevel metrics, such as BLEU (Papineni et al., 2002). To alleviate these two issues, the most straightforward way is to add the evaluation metrics into the objective in the training phase. Because these metrics are often discrete which cannot be utilized through standard back-propagation, researchers generally seek help from reinforcement learning. Ranzato et al. (2016) exploits REINFORCE algorithm (Williams, 1992) and proposes several model variants to well situate the algorithm in text generation applications.", "startOffset": 137, "endOffset": 775}, {"referenceID": 13, "context": "Liu et al. (2016) shares similar idea and directly optimizes image caption metrics through policy gradient methods (Igel, 2005).", "startOffset": 0, "endOffset": 18}, {"referenceID": 25, "context": "Researchers have successfully applied GAN to generate promising images conditionally (Mirza & Osindero, 2014; Reed et al., 2016; Zhang et al., 2016b) and unconditionally (Radford et al.", "startOffset": 85, "endOffset": 149}, {"referenceID": 23, "context": ", 2016b) and unconditionally (Radford et al., 2015; Nguyen et al., 2016), to realize image manipulation and super-resolution (Zhu et al.", "startOffset": 29, "endOffset": 72}, {"referenceID": 20, "context": ", 2016b) and unconditionally (Radford et al., 2015; Nguyen et al., 2016), to realize image manipulation and super-resolution (Zhu et al.", "startOffset": 29, "endOffset": 72}, {"referenceID": 41, "context": ", 2016), to realize image manipulation and super-resolution (Zhu et al., 2016; S\u00f8nderby et al., 2017; Ledig et al., 2016), and to produce video sequences (Mathieu et al.", "startOffset": 60, "endOffset": 121}, {"referenceID": 31, "context": ", 2016), to realize image manipulation and super-resolution (Zhu et al., 2016; S\u00f8nderby et al., 2017; Ledig et al., 2016), and to produce video sequences (Mathieu et al.", "startOffset": 60, "endOffset": 121}, {"referenceID": 13, "context": ", 2016), to realize image manipulation and super-resolution (Zhu et al., 2016; S\u00f8nderby et al., 2017; Ledig et al., 2016), and to produce video sequences (Mathieu et al.", "startOffset": 60, "endOffset": 121}, {"referenceID": 17, "context": ", 2016), and to produce video sequences (Mathieu et al., 2016; Zhou & Berg, 2016; Saito & Matsumoto, 2016).", "startOffset": 40, "endOffset": 106}, {"referenceID": 8, "context": "Initially proposed by Goodfellow et al. (2014), generative adversarial network (GAN) has attracted a lot of attention because it provides a powerful framework to generate promising samples through a min-max game.", "startOffset": 22, "endOffset": 47}, {"referenceID": 24, "context": "The generative models are able to utilize the discriminator\u2019s output to make up the information of its own distribution, which is inaccessible if trained by teacher forcing (Williams & Zipser, 1989; Ranzato et al., 2016).", "startOffset": 173, "endOffset": 220}, {"referenceID": 28, "context": "The instability inherent in GAN training makes things even worse (Salimans et al., 2016; Che et al., 2016; Arjovsky & Bottou, 2017; Arjovsky et al., 2017).", "startOffset": 65, "endOffset": 154}, {"referenceID": 5, "context": "The instability inherent in GAN training makes things even worse (Salimans et al., 2016; Che et al., 2016; Arjovsky & Bottou, 2017; Arjovsky et al., 2017).", "startOffset": 65, "endOffset": 154}, {"referenceID": 1, "context": "The instability inherent in GAN training makes things even worse (Salimans et al., 2016; Che et al., 2016; Arjovsky & Bottou, 2017; Arjovsky et al., 2017).", "startOffset": 65, "endOffset": 154}, {"referenceID": 1, "context": ", 2016; Arjovsky & Bottou, 2017; Arjovsky et al., 2017). Lamb et al. (2016) exploits adversarial domain adaption to regularize the training of recurrent neural networks.", "startOffset": 33, "endOffset": 76}, {"referenceID": 1, "context": ", 2016; Arjovsky & Bottou, 2017; Arjovsky et al., 2017). Lamb et al. (2016) exploits adversarial domain adaption to regularize the training of recurrent neural networks. Yu et al. (2017) applies GAN to discrete sequence generation by directly optimizing the discrete discriminator\u2019s rewards.", "startOffset": 33, "endOffset": 187}, {"referenceID": 1, "context": ", 2016; Arjovsky & Bottou, 2017; Arjovsky et al., 2017). Lamb et al. (2016) exploits adversarial domain adaption to regularize the training of recurrent neural networks. Yu et al. (2017) applies GAN to discrete sequence generation by directly optimizing the discrete discriminator\u2019s rewards. They adopt Monte Carlo tree search technique (Silver et al., 2016). Similar technique has been employed in Li et al. (2017) which improves response generation by using adversarial learning.", "startOffset": 33, "endOffset": 416}, {"referenceID": 21, "context": "Our work is also closely related to Norouzi et al. (2016b). In Norouzi et al.", "startOffset": 36, "endOffset": 59}, {"referenceID": 21, "context": "Our work is also closely related to Norouzi et al. (2016b). In Norouzi et al. (2016b), they propose to work with the objective KL(pd||p\u03b8) in a conditional generation setting.", "startOffset": 36, "endOffset": 86}, {"referenceID": 24, "context": "Practically, this single real sample normalization process combined with mixed training (Ranzato et al., 2016) successfully avoided the missing mode problem by providing equivalent training signal for each mode.", "startOffset": 88, "endOffset": 110}, {"referenceID": 6, "context": "As for future work, we are going to train the model on large datasets such as Google\u2019s one billion words (Chelba et al., 2014) and on conditional generation cases such as dialogue generation.", "startOffset": 105, "endOffset": 126}], "year": 2017, "abstractText": "Despite the successes in capturing continuous distributions, the application of generative adversarial networks (GANs) to discrete settings, like natural language tasks, is rather restricted. The fundamental reason is the difficulty of backpropagation through discrete random variables combined with the inherent instability of the GAN training objective. To address these problems, we propose Maximum-Likelihood Augmented Discrete Generative Adversarial Networks. Instead of directly optimizing the GAN objective, we derive a novel and low-variance objective using the discriminator\u2019s output that follows corresponds to the log-likelihood. Compared with the original, the new objective is proved to be consistent in theory and beneficial in practice. The experimental results on various discrete datasets demonstrate the effectiveness of the proposed approach.", "creator": "LaTeX with hyperref package"}}}