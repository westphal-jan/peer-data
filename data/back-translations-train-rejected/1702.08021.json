{"id": "1702.08021", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Feb-2017", "title": "Friends and Enemies of Clinton and Trump: Using Context for Detecting Stance in Political Tweets", "abstract": "Stance detection, the task of identifying the speaker's opinion towards a particular target, has attracted the attention of researchers. This paper describes a novel approach for detecting stance in Twitter. We define a set of features in order to consider the context surrounding a target of interest with the final aim of training a model for predicting the stance towards the mentioned targets. In particular, we are interested in investigating political debates in social media. For this reason we evaluated our approach focusing on two targets of the SemEval-2016 Task6 on Detecting stance in tweets, which are related to the political campaign for the 2016 U.S. presidential elections: Hillary Clinton vs. Donald Trump. For the sake of comparison with the state of the art, we evaluated our model against the dataset released in the SemEval-2016 Task 6 shared task competition. Our results outperform the best ones obtained by participating teams, and show that information about enemies and friends of politicians help in detecting stance towards them.", "histories": [["v1", "Sun, 26 Feb 2017 11:22:41 GMT  (64kb)", "http://arxiv.org/abs/1702.08021v1", "To appear in MICAI 2016 LNAI Proceedings"]], "COMMENTS": "To appear in MICAI 2016 LNAI Proceedings", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["mirko lai", "delia iraz\\'u hern\\'andez far\\'ias", "viviana patti", "paolo rosso"], "accepted": false, "id": "1702.08021"}, "pdf": {"name": "1702.08021.pdf", "metadata": {"source": "CRF", "title": "Friends and Enemies of Clinton and Trump: Using Context for Detecting Stance in Political Tweets", "authors": ["Mirko Lai", "Paolo Rosso"], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 170 2.08 021v 1 [cs.C L] 26 Fe"}, {"heading": "1 Introduction", "text": "From this type of user-generated content, it is possible to discover relevant information from multiple perspectives, and a wide range of research has been conducted to exploit the enormous amount of data generated by social media. One of the most interesting areas of research concerns the study of how people expose their feelings, ratings, attitudes and emotions. These kinds of aspects are the subject of interest in Sentiment Analysis (SA) [1].Determining the subjective value of a text is the most general task of SA. Lately, the interest in exploring finer and different sentiment aspects in texts in areas such as Aspect based Sentiment Analysis (SA) and Stance Detection (SD), which is at the heart of our work, is the identification of the speaker's opinion towards a particular target. It is not enough to know whether a text is positive / negative / neutral, but it is necessary to shift the twitter's point of view towards a particular target."}, {"heading": "2 Detecting Stance on Tweets", "text": "SemEval 2016 task 6: Steadfastness in Tweets4 was the first common task for recognizing posture from tweets. Mohammad et. al in [3] describe the task as follows: Faced with a tweet text and a target unit (person, organization, movement, politics, etc.), automatic natural language systems must determine whether the tweeter is for the target, against the preset target, or whether an inference is probable.5"}, {"heading": "Support #independent #BernieSanders because he\u2019s not a liar. #POTUS #libcrib #democrats #tlot #republicans #WakeUpAmerica #SemST", "text": "The goal of interest is \"Hillary Clinton.\" Here, the twitter expresses a positive opinion of an opponent of the goal. Consequently, the annotator3 candidates who have won the Democratic and Republican Party presidential primaries have not been directly identified. 4 http: / / alt.qcri.org / semeval2016 / task6 / 5 This tweet was concluded from the training set of SemEval-2016 Task 6 that the twitter expresses a negative opinion of the goal. As can be noted, this tweet does not contain any explicit clues to find the goal. To evaluate the task, the organizers commented on nearly 5,000 English tweets for six commonly known goals in the United States. \"Atheism\" is a real concern, \"feminism movement,\" Hillary Clinton, \"legalization of abortion\" and \"Donald Trump.\" (Stance Dataset, henceforth)."}, {"heading": "3 Our approach", "text": "Our work focuses on identifying the attitudes toward Hillary Clinton and Donald Trump, who are currently engaged in the political campaign for the 2016 US presidential election. An important aspect to mention is the fact that, when the Stance dataset was created, the two goals were still competing in the Democratic and Republican presidential elections. We address the recognition of attitudes in tweets and rate them as a classification task. A number of characteristics that include various aspects have been exploited, the latest of which relates to the extraction of contextual information regarding the goal of interest. Our hypothesis is that domain knowledge could provide useful information to improve the performance of SD systems. For example, to correctly identify the attitudes in a tweet as those mentioned in Section 2, it is necessary to recognize that Bernie Sander was an opponent of Hillary Clinton during the Democratic Party presidential primaries."}, {"heading": "Sentiment-based Features", "text": "We shared the idea that the recognition of viewpoints is strongly related to the sensation analysis [3,16]. As far as we know, there are no lexicographs of sensation analysis that are specifically retrieved in the political sphere, so it is possible to take advantage of the sensation characteristics available in English. We used a set of four lexicographs to cover different facets of affects ranging from the previous polarity of words to fine-grained emotional information: - AFINN. It is an affective lexicon of 2,477 English words that are manually labeled with a polarity value between -5 and + 5. AFINN was collected by Finn A rup Nielsen [28]. We consider a feature from AFINN: the sum of the polarity of the words present in each tweet. - Hu & Liu (HL) comprises approximately 6,800 positive and negative words. We calculate the difference between the positive and negative words in a Tweet WC - LItion."}, {"heading": "Structural Features", "text": "We have experimented with various structural features, but only the most relevant ones have been included in the final approach: - Hashtags. Frequency of hashtags in each tweet. - Mentions. Frequency of screen names (often mentioned) in each tweet. - Punctuation marks. We look at a number of 6 different characteristics: frequency of exclamation marks, question marks, dots, commas, semicolons, and finally the sum of all the previously mentioned punctuation marks. [8] For example, the term vote is strongly related to politics, but it is absent from commonly used SA lexicographs such as AFINN, Hu & Liu, and LIWC."}, {"heading": "Context-based Features", "text": "Our hypothesis is that the context-based functions should capture some domain-related information. An overall perspective of the context that surrounds a target, we can acquire in 2016 through the relationships that exist between the target and other entities in its domain. As mentioned earlier, we are interested in investigating Republican debates: For this reason, we have selected as targets of interest politicians such as Hillary Clinton and Donald Trump. We have manually created a list of entities that are related to the goal of the party to identify primaries for the Democratic and Republican parties by Wikipedia9. We use 6 types of context-based functions that take into account different types of relationships between the target and the entities around the target: - Target of interest that is mentioned by name (targetByName of the party): This feature captures the presence of interest in the target of interest in the tweet. # StopHillary2016 HillaryClinton, if there is a woman with integrity and honesty, would verify the interest of the target of the party's presence, I would be voting for such a woman's tweet as the name of interest in the party's presence, Donald O: The presence of the party's name on the target of the tweet."}, {"heading": "I don\u2019t want to be appointed to an Ambassador post.", "text": "The example also shows how difficult it is to follow the posture without in-depth knowledge of the context. After evaluating the participating systems, the organizers of Semeval-2016 Task 6 commented on the Datataset position for mood and goal to explore the relationship between mood and posture [31.3] 11. In particular, tweets were commented on manually using two additional terms: Sentiment and Opinion Towards, which are used to indicate the overall emotional polarity of the tweet and information about the fact that the opinion is expressed directly towards the goal: - Sentiment. It can be positive, negative, neutral or not at all. - Opinion Target. It can take three different values: (1) when a tweet expresses an opinion about the goal; (2) when a tweet expresses an opinion about an aspect of the goal or refers to something that is not the goal; and (3) when no opinion is expressed."}, {"heading": "4 Evaluation", "text": "We experimented with a series of tweets associated with Hillary Clinton and Donald Trump from the Stance dataset 1. In addition, Table 2 shows the distribution of tweets commenting on attitudes in education and testing for our goals. We evaluated our approach by using the same metric defined in [3] to compare our results with those participating in the task. We trained a Gaussian Naive Bayes classifier [32] implemented in the Scikit Learn Python library12 to create a model for identifying attitudes in tweets. We adopted two experimental settings: a) Experiment1. It means that using the sentiment-based, structural and context-based characteristics in the task assignment.b) It refers to the use of all characteristics described in Section 3, including the positions described in tweets. In addition, we experimented with different combinations of objectives that may be relevant to the task assignment.It refers to the use of all characteristics described in Section 3, including the positions described in tweets."}, {"heading": "5 Conclusions", "text": "In this paper, we have shown that the inclusion of contextual information is critical to improving the performance of position recognition systems. Experiments confirm that position recognition depends to a large extent on the domain knowledge of the target. Our approach relies on the presence of instances associated with a target to try to extract the opinion expressed on it. Furthermore, in both cases, our proposal allows conclusions to be drawn about the position when the target is explicitly mentioned and even when it is not. The results obtained through the exploitation of contextual characteristics exceed those obtained from the best-rated systems of the SemEval2016 task 6. Let us emphasize that we do not use n-grams or any word-based representation, but our approach is mainly based on the context of the target in hand. We plan to examine the performance of our approach in various areas. Exploiting semantic resources to capture additional contextual information may also be of interest to future users, including their social conformations."}, {"heading": "Acknowledgments", "text": "The National Council for Science and Technology (CONACyT Mexico) has financed the research of Delia Irazu 'Herna' ndez Far'\u0131as (218109 / 313683), Paolo Rosso's work was partly financed by the SomEMBED TIN201571147-C2-1-P MINECO research project and by the Generalitat Valenciana as part of the ALMAMATER scholarship (PrometeoII / 2014 / 030), and Viviana Patti's work was partly carried out at the Universitat Polite de Vale Ncia as part of a scholarship from the University of Turin co-financed by Fondazione CRT (World Wide Style Program 2)."}], "references": [{"title": "Sentiment analysis and opinion mining", "author": ["B. Liu"], "venue": "Synthesis Lectures on Human Language Technologies 5", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "Semeval-2016 task 5: Aspect based sentiment analysis", "author": ["M. Pontiki", "D. Galanis", "H. Papageorgiou", "I. Androutsopoulos", "S. Manandhar", "M. AL-Smadi", "M. Al-Ayyoub", "Y. Zhao", "B. Qin", "O. De Clercq", "V. Hoste", "M. Apidianaki", "X. Tannier", "N. Loukachevitch", "E. Kotelnikov", "N. Bel", "S.M. Jim\u00e9nez-Zafra", "G. Eryi\u011fit"], "venue": "Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval2016), ACL", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2016}, {"title": "SemEval-2016 Task 6: Detecting Stance in Tweets", "author": ["S. Mohammad", "S. Kiritchenko", "P. Sobhani", "X. Zhu", "C. Cherry"], "venue": "Bethard et al. [8].", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2016}, {"title": "Tweeting and being ironic in the debate about a political reform: the french annotated corpus twitter-mariagepourtous", "author": ["C. Bosco", "M. Lai", "V. Patti", "D. Virone"], "venue": "Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC 2016), ELRA", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2016}, {"title": "Annotating Sentiment and Irony in the Online Italian Political Debate on #labuonascuola", "author": ["Marco Stranisci", "Cristina Bosco", "Delia Iraz\u00fa Hern\u00e1ndez Fa\u0155\u0131as", "Viviana Patti"], "venue": "Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC 2016), ELRA", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2016}, {"title": "Twitter Predicting the 2012 US Presidential Election?: Lessons Learned from an Unconscious Value Co-Creation Platform", "author": ["M. Maldonado", "V. Sierra"], "venue": "Journal of Organizational and End User Computing (JOEUC) 28", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2016}, {"title": "A readability analysis of campaign speeches from the 2016 US presidential campaign", "author": ["E. Schumacher", "M. Eskenazi"], "venue": "CoRR abs/1603.05739", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2016}, {"title": "Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)", "author": ["Steven Bethard", "Marine Carpuat", "Daniel Cer", "David Jurgens", "Preslav Nakov", "Torsten Zesch", "eds."], "venue": "Association for Computational Linguistics, San Diego, California", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2016}, {"title": "Crowdsourcing a word\u2013emotion association lexicon", "author": ["S.M. Mohammad", "P.D. Turney"], "venue": "Computational Intelligence 29", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2013}, {"title": "Recognizing Contextual Polarity in Phraselevel Sentiment Analysis", "author": ["T. Wilson", "J. Wiebe", "P. Hoffmann"], "venue": "Proceedings of the Conference on HLT and Empirical Methods in Natural Language Processing, ACL", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2005}, {"title": "Mining and Summarizing Customer Reviews", "author": ["M. Hu", "B. Liu"], "venue": "Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. KDD \u201904, Seattle, WA, USA, ACM", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2004}, {"title": "NRC-Canada: Building the State-of-theArt in Sentiment Analysis of Tweets", "author": ["S. Mohammad", "S. Kiritchenko", "X. Zhu"], "venue": "Proceedings of the seventh international workshop on Semantic Evaluation Exercises (SemEval-2013), Atlanta, Georgia, USA", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2013}, {"title": "MITRE at SemEval-2016 Task 6: Transfer Learning for Stance Detection", "author": ["G. Zarrella", "A. Marsh"], "venue": "Bethard et al. [8].", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2016}, {"title": "pkudblab at SemEval-2016 Task 6 : A Specific Convolutional Neural Network System for Effective Stance detection", "author": ["W. Wei", "X. Zhang", "X. Liu", "W. Chen", "T. Wang"], "venue": "Bethard et al. [8].", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2016}, {"title": "TakeLab at SemEval-2016 Task 6: Stance Classification in Tweets Using a Genetic Algorithm Based Ensemble", "author": ["M. Tutek", "I. Sekulic", "P. Gombar", "I. Paljak", "F. Culinovic", "F. Boltuzic", "M. Karan", "D. Alagi\u0107", "J. \u0160najder"], "venue": "Bethard et al. [8].", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2016}, {"title": "ECNU at SemEval 2016 Task 6: Relevant or Not? Supportive or Not? A Two-step Learning System for Automatic Detecting Stance in Tweets", "author": ["Z. Zhang", "M. Lan"], "venue": "Bethard et al. [8].", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2016}, {"title": "CU-GWU Perspective at SemEval-2016 Task 6: Ideological Stance Detection in Informal Text", "author": ["H. Elfardy", "M. Diab"], "venue": "Bethard et al. [8].", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2016}, {"title": "IUCL at SemEval2016 task 6: An Ensemble Model for Stance Detection in Twitter", "author": ["C. Liu", "W. Li", "B. Demarest", "Y. Chen", "S. Couture", "D. Dakota", "N. Haduong", "N. Kaufman", "A. Lamont", "M. Pancholi", "K. Steimel", "S. K\u00fcbler"], "venue": "Bethard et al. [8].", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2016}, {"title": "Deepstance at SemEval-2016 Task 6: Detecting Stance in Tweets Using Character and Word-Level CNNs", "author": ["P. Vijayaraghavan", "I. Sysoev", "S. Vosoughi", "D. Roy"], "venue": "Bethard et al. [8].", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2016}, {"title": "UWB at SemEval-2016 Task 6: Stance Detection", "author": ["P. Krejzl", "J. Steinberger"], "venue": "Bethard et al. [8].", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2016}, {"title": "IDI@NTNU at SemEval-2016 Task 6: Detecting Stance in Tweets Using Shallow Features and GloVe Vectors for Word Representation", "author": ["H. B\u00f8hler", "P. Asla", "E. Marsi", "R. S\u00e6tre"], "venue": "Bethard et al. [8].", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2016}, {"title": "Tohoku at SemEval-2016 Task 6: Feature-based Model versus Convolutional Neural Network for Stance Detection", "author": ["Y. Igarashi", "H. Komatsu", "S. Kobayashi", "N. Okazaki", "K. Inui"], "venue": "Bethard et al. [8].", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2016}, {"title": "ltl.uni-due at SemEval-2016 Task 6: Stance Detection in Social Media Using Stacked Classifiers", "author": ["M. Wojatzki", "T. Zesch"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2016}, {"title": "JU NLP at SemEval-2016 Task 6: Detecting Stance in Tweets using Support Vector Machines", "author": ["B.G. Patra", "D. Das", "S. Bandyopadhyay"], "venue": "Bethard et al. [8].", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2016}, {"title": "NLDS-UCSC at SemEval-2016 Task 6: A Semi-Supervised Approach to Detecting Stance in Tweets", "author": ["A. Misra", "B. Ecker", "T. Handleman", "N. Hahn", "M. Walker"], "venue": "Bethard et al. [8].", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2016}, {"title": "INF-UFRGS-OPINION-MINING at SemEval-2016 Task 6: Automatic Generation of a Training Corpus for Unsupervised Identification of Stance in Tweets", "author": ["M. Dias", "K. Becker"], "venue": "Bethard et al. [8].", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2016}, {"title": "USFD at SemEval-2016 Task 6: AnyTarget Stance Detection on Twitter with Autoencoders", "author": ["I. Augenstein", "A. Vlachos", "K. Bontcheva"], "venue": "Bethard et al. [8].", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2016}, {"title": "A new ANEW: Evaluation of a word list for sentiment analysis in microblogs", "author": ["Finn \u00c5rup Nielsen"], "venue": "CoRR abs/1103.2903", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2011}, {"title": "Linguistic inquiry and word count: LIWC 2001", "author": ["J.W. Pennebaker", "M.E. Francis", "R.J. Booth"], "venue": "Lawrence Erlbaum Associates, Mahwah,NJ", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2001}, {"title": "Using the Revised Dictionary of Affect in Language to Quantify the Emotional Undertones of Samples of Natural Language", "author": ["C. Whissell"], "venue": "Psychological Reports 105", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2009}, {"title": "A dataset for detecting stance in tweets", "author": ["S. Mohammad", "S. Kiritchenko", "P. Sobhani", "X. Zhu", "C. Cherry"], "venue": "Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC 2016), ELRA", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2016}, {"title": "Updating Formulae and a Pairwise Algorithm for Computing Sample Variances", "author": ["T.F. Chan", "G.H. Golub", "R.J. LeVeque"], "venue": "Technical report, Stanford University, Stanford, CA, USA", "citeRegEx": "32", "shortCiteRegEx": null, "year": 1979}, {"title": "Irony detection in twitter: The role of affective content", "author": ["D.I. Hern\u00e1ndez Fa\u0155\u0131as", "V. Patti", "P. Rosso"], "venue": "ACM Trans. Internet Technol. 16", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2016}, {"title": "Figurative messages and affect in twitter: Differences between #irony, #sarcasm and #not", "author": ["E. Sulis", "D.I. Hern\u00e1ndez Fa\u0155\u0131as", "P. Rosso", "V. Patti", "G. Ruffo"], "venue": "Knowledge-Based Systems 108", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2016}], "referenceMentions": [{"referenceID": 0, "context": "These kinds of aspects are the subject of interest of Sentiment Analysis (SA) [1].", "startOffset": 78, "endOffset": 81}, {"referenceID": 1, "context": "Recently, the interest on studying finer-grained and different facets of sentiment in texts has derived in areas such as Aspect based sentiment analysis [2] and Stance Detection (SD) [3], which is the focus of our work.", "startOffset": 153, "endOffset": 156}, {"referenceID": 2, "context": "Recently, the interest on studying finer-grained and different facets of sentiment in texts has derived in areas such as Aspect based sentiment analysis [2] and Stance Detection (SD) [3], which is the focus of our work.", "startOffset": 183, "endOffset": 186}, {"referenceID": 3, "context": ", political reforms [4,5]) or a polarizing person (e.", "startOffset": 20, "endOffset": 25}, {"referenceID": 4, "context": ", political reforms [4,5]) or a polarizing person (e.", "startOffset": 20, "endOffset": 25}, {"referenceID": 5, "context": "Several efforts have been made in order to investigate different aspects related to social media and politics [6].", "startOffset": 110, "endOffset": 113}, {"referenceID": 2, "context": "This year, for the first time a shared task on stance detection in tweets was organized [3].", "startOffset": 88, "endOffset": 91}, {"referenceID": 6, "context": "Both targets have been the focus of different research, for instance in [7] the authors studied their speeches during the 2016 political campaign.", "startOffset": 72, "endOffset": 75}, {"referenceID": 2, "context": "al in [3] describe the task as: Given a tweet text and a target entity (person, organization, movement, policy, etc.", "startOffset": 6, "endOffset": 9}, {"referenceID": 2, "context": "More details about the Stance Dataset can be found in [3].", "startOffset": 54, "endOffset": 57}, {"referenceID": 7, "context": "Further information about the systems in the task can be found in [8].", "startOffset": 66, "endOffset": 69}, {"referenceID": 8, "context": "Besides, some SA features from well-known lexical resources, such as EmoLex [9], MPQA [10], Hu and Liu [11] and NRC Hashtag [12], were used to detect stance in tweets.", "startOffset": 76, "endOffset": 79}, {"referenceID": 9, "context": "Besides, some SA features from well-known lexical resources, such as EmoLex [9], MPQA [10], Hu and Liu [11] and NRC Hashtag [12], were used to detect stance in tweets.", "startOffset": 86, "endOffset": 90}, {"referenceID": 10, "context": "Besides, some SA features from well-known lexical resources, such as EmoLex [9], MPQA [10], Hu and Liu [11] and NRC Hashtag [12], were used to detect stance in tweets.", "startOffset": 103, "endOffset": 107}, {"referenceID": 11, "context": "Besides, some SA features from well-known lexical resources, such as EmoLex [9], MPQA [10], Hu and Liu [11] and NRC Hashtag [12], were used to detect stance in tweets.", "startOffset": 124, "endOffset": 128}, {"referenceID": 7, "context": "6 Notice that not all the reports describing systems and approaches of teams participating at SemEval-2016 Task 6 are available in [8].", "startOffset": 131, "endOffset": 134}, {"referenceID": 12, "context": "MITRE [13] Overall approach: Recurrent neural networks.", "startOffset": 6, "endOffset": 10}, {"referenceID": 13, "context": "pkudblab [14] Overall approach: Convolutional neural network.", "startOffset": 9, "endOffset": 13}, {"referenceID": 14, "context": "TakeLab [15] Overall approach: An ensamble of learning algorithms (such as SVM, random forest) fine-tuned using a genetic algorithm.", "startOffset": 8, "endOffset": 12}, {"referenceID": 15, "context": "ECNU [16] Overall approach: A pipeline-based procedure involving relevance and orientation detection.", "startOffset": 5, "endOffset": 9}, {"referenceID": 16, "context": "CU-GWU [17] Overall approach: Classification using SVM Task A External resources: N-grams, Stanford\u2019s SA system and LIWC.", "startOffset": 7, "endOffset": 11}, {"referenceID": 17, "context": "IUCL-RF [18] Overall approach: Classification algorithms (SVM, random forest, gradient boosting decision trees) and an ensamble classifier (TiMBL).", "startOffset": 8, "endOffset": 12}, {"referenceID": 18, "context": "DeepStance [19] Overall approach: A set of naive bayes classifiers using deep learning.", "startOffset": 11, "endOffset": 15}, {"referenceID": 19, "context": "UWB [20] Overall approach: Maximum entropy classifier.", "startOffset": 4, "endOffset": 8}, {"referenceID": 20, "context": "IDI@NTNU [21] Overall approach: A soft voting classifier approach (naive bayes and logistic regression).", "startOffset": 9, "endOffset": 13}, {"referenceID": 21, "context": "Tohoku [22] Overall approach: Two methods: a feature based approach and a neural network based approach.", "startOffset": 7, "endOffset": 11}, {"referenceID": 22, "context": "uni-due [23] Overall approach: Multidimensional classification problem Tasks A and B External resources: N-grams, punctuation marks, negation, nouns.", "startOffset": 8, "endOffset": 12}, {"referenceID": 23, "context": "JU NLP [24] Overall approach: Classification using SVM Task A External resources: N-Gram and sentiment analysis resources such as: SentiWordNet, EmoLex and NRC Hashtag Emotion Lexicon.", "startOffset": 7, "endOffset": 11}, {"referenceID": 24, "context": "nldsucsc [25] Overall approach: Classification using SVM, J48 and naive bayes.", "startOffset": 9, "endOffset": 13}, {"referenceID": 25, "context": "INF UFRGS [26] Overall approach: Set of rules together with SVM.", "startOffset": 10, "endOffset": 14}, {"referenceID": 26, "context": "USFD [27] Overall approach: Classification using logistic regression.", "startOffset": 5, "endOffset": 9}, {"referenceID": 2, "context": "We shared the idea that stance detection is strongly related to sentiment analysis [3,16].", "startOffset": 83, "endOffset": 89}, {"referenceID": 15, "context": "We shared the idea that stance detection is strongly related to sentiment analysis [3,16].", "startOffset": 83, "endOffset": 89}, {"referenceID": 27, "context": "AFINN was collected by Finn \u00c5rup Nielsen [28].", "startOffset": 41, "endOffset": 45}, {"referenceID": 28, "context": "The Linguistic Inquiry and Word Counts (LIWC) [29] is a dictionary that contains about 4,500 entries distributed in 64 categories that can be further used to analyse psycholinguistic features in texts.", "startOffset": 46, "endOffset": 50}, {"referenceID": 29, "context": "The Dictionary of Affect in Language (DAL) contains 8,742 English words; it was developed by Whissell [30].", "startOffset": 102, "endOffset": 106}, {"referenceID": 30, "context": "After the evaluation of participating systems, the organizers of Semeval-2016 Task 6 annotated the Stance Datataset for sentiment and target in order to explore the relationship between sentiment and stance [31,3].", "startOffset": 207, "endOffset": 213}, {"referenceID": 2, "context": "After the evaluation of participating systems, the organizers of Semeval-2016 Task 6 annotated the Stance Datataset for sentiment and target in order to explore the relationship between sentiment and stance [31,3].", "startOffset": 207, "endOffset": 213}, {"referenceID": 2, "context": "We evaluated our approach by using the same measure defined in [3] in order to compare our results with those participating in the task.", "startOffset": 63, "endOffset": 66}, {"referenceID": 31, "context": "We trained a Gaussian Naive Bayes classifier [32] implemented in Scikit-learn Python library to built a model for identifying stance in tweets.", "startOffset": 45, "endOffset": 49}, {"referenceID": 2, "context": "The obtained results outperform the baselines proposed in [3].", "startOffset": 58, "endOffset": 61}, {"referenceID": 32, "context": "Finally, we think that it could be also interesting to investigate how to fruitfully combine information about stance and information about the presence of figurative devices in tweets, such as irony and sarcasm [33,34], since the use of such devices is very frequent in political debates also in social media and detecting irony and sarcasm have been considered as one of the biggest challenges for sentiment analysis.", "startOffset": 212, "endOffset": 219}, {"referenceID": 33, "context": "Finally, we think that it could be also interesting to investigate how to fruitfully combine information about stance and information about the presence of figurative devices in tweets, such as irony and sarcasm [33,34], since the use of such devices is very frequent in political debates also in social media and detecting irony and sarcasm have been considered as one of the biggest challenges for sentiment analysis.", "startOffset": 212, "endOffset": 219}], "year": 2017, "abstractText": "Stance detection, the task of identifying the speaker\u2019s opinion towards a particular target, has attracted the attention of researchers. This paper describes a novel approach for detecting stance in Twitter. We define a set of features in order to consider the context surrounding a target of interest with the final aim of training a model for predicting the stance towards the mentioned targets. In particular, we are interested in investigating political debates in social media. For this reason we evaluated our approach focusing on two targets of the SemEval-2016 Task 6 on Detecting stance in tweets, which are related to the political campaign for the 2016 U.S. presidential elections: Hillary Clinton vs. Donald Trump. For the sake of comparison with the state of the art, we evaluated our model against the dataset released in the SemEval-2016 Task 6 shared task competition. Our results outperform the best ones obtained by participating teams, and show that information about enemies and friends of politicians help in detecting stance towards them.", "creator": "LaTeX with hyperref package"}}}