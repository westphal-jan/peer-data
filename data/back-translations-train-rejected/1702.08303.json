{"id": "1702.08303", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Feb-2017", "title": "Identifying beneficial task relations for multi-task learning in deep neural networks", "abstract": "Multi-task learning (MTL) in deep neural networks for NLP has recently received increasing interest due to some compelling benefits, including its potential to efficiently regularize models and to reduce the need for labeled data. While it has brought significant improvements in a number of NLP tasks, mixed results have been reported, and little is known about the conditions under which MTL leads to gains in NLP. This paper sheds light on the specific task relations that can lead to gains from MTL models over single-task setups.", "histories": [["v1", "Mon, 27 Feb 2017 14:37:21 GMT  (99kb,D)", "http://arxiv.org/abs/1702.08303v1", "Accepted for publication at EACL 2017"]], "COMMENTS": "Accepted for publication at EACL 2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["joachim bingel", "anders s{\\o}gaard"], "accepted": false, "id": "1702.08303"}, "pdf": {"name": "1702.08303.pdf", "metadata": {"source": "CRF", "title": "Identifying beneficial task relations for multi-task learning in deep neural networks", "authors": ["Joachim Bingel", "Anders S\u00f8gaard"], "emails": ["bingel@di.ku.dk", "soegaard@di.ku.dk"], "sections": [{"heading": "1 Introduction", "text": "The main driver has been empirical results that advance the state of the art in different tasks, but preliminary theoretical results guarantee that multi-task learning works under different conditions. Some approaches to multi-task learning are known, for example, when the tasks share optimal hypotheses classes (Baxter, 2000) or when distributions are taken from related samples (BenDavid and Borberly, 2003). In NLP, multi-task learning typically involves very heterogeneous tasks. However, while major improvements have been reported (Luong et al., 2016; Klerke et al., 2016), the results are also often mixed (Collobert and Weston, 2008; S\u00f8gaard and Goldberg, 2016; Mart\u00ed \u0301 nez nez and Plank, 2017)."}, {"heading": "2 Related work", "text": "Luong et al. (2016) suggest that it is important that the auxiliary data do not exceed the target data, while Benton et al. (2017) suggest that multi-task learning is particularly effective when we have limited access to small amounts of target data. Mart\u00ed \u0301 nez Alonso and Plank (2017) present a study of different task combinations with specific main and auxiliary tasks. Their results suggest, among other things, that success depends on how uniformly the auxiliary task names are distributed. Mou et al. (2016) examine multi-task learning and its relationship to transfer learning and under what conditions they function between a number of sentence classification tasks. Their main finding in relation to multi-task learning is that the successor Xiv: 170 2.08 303v 1 [cs.C L] 27 Feb 2017 largely depends on \"how similar in semantics are the source and target data sets, which are usually similar to learning performance.\""}, {"heading": "3 Multi-task Learning", "text": "Although there are many approaches to multi-task learning, the sharing of hard parameters in deep neural networks (Caruana, 1993) has become extremely popular in recent years. Among the biggest advantages over other methods are (i) that it is known theoretically (Baxter, 2000) as an efficient regulator, and in practice (S\u00f8gaard and Goldberg, 2016); and (ii) that it is easy to implement. The basic idea of sharing hard parameters in deep neural networks is that the different tasks share a part of the hidden layers, so that they learn a common representation for multiple tasks. Another conceptualization is to consider this as regulating our target model by dynamically performing model interpolations with auxiliary models. Linear models with multiple tasks were typically presented as matrix regulators, with the parameters of each task-specific model being identical."}, {"heading": "3.1 Models", "text": "Recent work on multi-task learning of NLP models has focused on sequence marking with recurring neural networks (Klerke et al., 2016; S\u00f8gaard and Goldberg, 2016; Bollman et al., 2016; Plank et al., 2016; Mart\u00ed \u0301 nez Alonso and Plank, 2017), although sequence-to-sequence models have also been shown to benefit from MTL (Luong et al., 2016), our multi-task learning architecture is similar to the former, with a bi-directional LSTM as a single hidden layer of 100 dimensions shared across all tasks. Inputs in this hidden layer are 100-dimensional word vectors initialized with pre-formed GloVe embeddings, but updated during training. Embedding parameters is also common. The model then generates predictions from the 2016 LLSTM task specific meaning that our school parameters are not symmetric."}, {"heading": "3.2 Tasks", "text": "In our experiments below, we look at the following ten NLP tasks, with one data set for each task. Characteristics of the data sets we use are summarized in Table 1.1. CCG tagging (CCG) is a sequence tagging problem that assigns a logical type to each token. We use the standard splits for CCG super tagging from CCGBank (Hockenmaier and Steedman, 2007).2. Chunking (CHU) identifies continuous ranges of tokens that form syntactic units such as noun phrases or verb phrases. We use the standard splits for syntactic chunking from Penn Treebank (Marcus et al., 1993).3. Sentence Compression (COM) We use the publicly available subset of the Google Compression Dataset (Filippova and Altun, 2013)."}, {"heading": "4 Experiments", "text": "We train Bi-LSTMs for each of the ten tasks, as well as a multi-task model for each of the pairs between tasks, resulting in 90 directional pairs of the form < Tmain, {Tmain, Taux} >. Single-task models are trained for 25,000 lots, while multi-task models are trained for 50,000 lots to take into account the uniform drawing of the two tasks at each iteration in the multi-task setup. The relative gains and losses from MTL over the single-task models are illustrated in Figure 1, which shows improvements in 40 out of 90 cases. We see that chunking and high-level semantic tagging usually contribute to other tasks, while hyperlinks do not make significant improvements in other tasks. On the recipients side, we see that multiword and hyperlink detection benefit most from multiple auxiliary tasks."}, {"heading": "4.1 Results", "text": "The mean performance of 100 runs of randomized quintuple cross-validation of our logistical regression1 An experiment in which we tried to predict the extent of losses and gains with linear regression yielded inconclusive results. The model for different combinations of characteristics is in Table 3. The first observation is that there is a strong signal in our meta-learning characteristics. In almost four out of five cases, we can predict the outcome of the MTL experiment from the data and the task experiments, which gives validity to our feature analysis. We also see that the characteristics derived from each task induction are the most important. In fact, the F1 value of the positive class using only data-inherent characteristics is worse than the majority basis."}, {"heading": "4.2 Analysis", "text": "Table 4 lists the coefficients for all 42 characteristics. We find that characteristics describing the learning curves for the main and auxiliary tasks are the best predictors of MTL gains. However, the ratios of the learning curve characteristics seem less predictable, and the gradients by 20-30% seem to be most important after the area where the curve typically flattens a little (about 10%). Interestingly, however, these gradients correlate in the opposite way for the main and auxiliary tasks. In other words, if the main tasks have flatter learning curves (small negative gradients) in the 20-30% percentile, but the auxiliary task curves are still relatively steep, MTL is more likely to work. In other words, multiple task gains are more likely for tasks that are fast plateau and non-plateaulic auxiliary tasks are very good."}, {"heading": "5 Conclusion and Future Work", "text": "We present the first systematic study of when MTL works in the context of shared NLP tasks, when individual task parameter settings are also applied to multi-task learning. Key findings include that MTL gains are predictable based on characteristics of data sets and characteristics derived from the introductions to individual tasks. We also show that the most predictive characteristics relate to the learning curves with individual tasks, suggesting that MTL, when successful, often supports target tasks from local minima. We also observed that label entropy in the helper task was also a good predictor, supporting the hypothesis in Mart\u00ed \u0301 nez Alonso and Plank (2017). However, there was little evidence that the balance of data sets is a reliable predictor, as opposed to what previous work has outlined. In future work, we aim to extend our experiments to an environment where we optimize hyper parameters for single-task and multi-task models."}, {"heading": "Acknowledgments", "text": "We would like to thank Dirk Hovy, Yoav Goldberg, the participants of the second discussion at the Danish Society for Statistics and the anonymous reviewers for their valuable comments. This research was partly financed by the ERC Starting Grant LOWLANDS No. 313695 and by Trygfonden."}], "references": [{"title": "A model of inductive bias learning", "author": ["Jonathan Baxter"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Baxter.,? \\Q2000\\E", "shortCiteRegEx": "Baxter.", "year": 2000}, {"title": "Multitask learning for mental health conditions with limited social media data", "author": ["Benton et al.2017] Adrian Benton", "Margaret Mitchell", "Dirk Hovy"], "venue": null, "citeRegEx": "Benton et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Benton et al\\.", "year": 2017}, {"title": "Improving historical spelling normalization with bi-directional lstms and multitask learning", "author": ["Bollman", "S\u00f8gaard2016] Marcel Bollman", "Anders S\u00f8gaard"], "venue": "In COLING", "citeRegEx": "Bollman et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Bollman et al\\.", "year": 2016}, {"title": "Multi-view and multi-task training of rst discourse parser", "author": ["Braud et al.2016] Chloe Braud", "Barbara Plank", "Anders S\u00f8gaard"], "venue": "In COLING", "citeRegEx": "Braud et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Braud et al\\.", "year": 2016}, {"title": "Multitask learning: a knowledge-based source of inductive bias", "author": ["Rich Caruana"], "venue": "In ICML", "citeRegEx": "Caruana.,? \\Q1993\\E", "shortCiteRegEx": "Caruana.", "year": 1993}, {"title": "A unified architecture for natural language processing: Deep neural networks with multitask learning", "author": ["Collobert", "Weston2008] Ronan Collobert", "Jason Weston"], "venue": null, "citeRegEx": "Collobert et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Collobert et al\\.", "year": 2008}, {"title": "Overcoming the lack of parallel data in sentence compression", "author": ["Filippova", "Altun2013] Katja Filippova", "Yasemin Altun"], "venue": "In EMNLP,", "citeRegEx": "Filippova et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Filippova et al\\.", "year": 2013}, {"title": "Ccgbank: A corpus of ccg derivations and dependency structures extracted from the penn treebank", "author": ["Hockenmaier", "Steedman2007] Julia Hockenmaier", "Mark Steedman"], "venue": "Comput. Linguist.,", "citeRegEx": "Hockenmaier et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Hockenmaier et al\\.", "year": 2007}, {"title": "Improving sentence compression by learning to predict gaze", "author": ["Klerke et al.2016] Sigrid Klerke", "Yoav Goldberg", "Anders S\u00f8gaard"], "venue": null, "citeRegEx": "Klerke et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Klerke et al\\.", "year": 2016}, {"title": "Multi-task sequence to sequence learning", "author": ["Quoc V Le", "Ilya Sutskever", "Oriol Vinyals", "Lukasz Kaiser"], "venue": "In ICLR", "citeRegEx": "Luong et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Luong et al\\.", "year": 2016}, {"title": "Building a large annotated corpus of English: the Penn Treebank", "author": ["Mary Marcinkiewicz", "Beatrice Santorini"], "venue": null, "citeRegEx": "Marcus et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Marcus et al\\.", "year": 1993}, {"title": "Multitask learning for semantic sequence prediction under varying data conditions", "author": ["Mart\u0131\u0301nez Alonso", "Barbara Plank"], "venue": null, "citeRegEx": "Alonso et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Alonso et al\\.", "year": 2017}, {"title": "How transferable are neural networks in nlp applications? arXiv preprint arXiv:1603.06111", "author": ["Mou et al.2016] Lili Mou", "Zhao Meng", "Rui Yan", "Ge Li", "Yan Xu", "Lu Zhang", "Zhi Jin"], "venue": null, "citeRegEx": "Mou et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Mou et al\\.", "year": 2016}, {"title": "A universal part-of-speech tagset", "author": ["Petrov et al.2011] Slav Petrov", "Dipanjan Das", "Ryan McDonald"], "venue": "CoRR abs/1104.2086", "citeRegEx": "Petrov et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Petrov et al\\.", "year": 2011}, {"title": "Keystroke dynamics as signal for shallow syntactic parsing", "author": ["Barbara Plank"], "venue": "In COLING", "citeRegEx": "Plank.,? \\Q2016\\E", "shortCiteRegEx": "Plank.", "year": 2016}, {"title": "A corpus and model integrating multiword expressions and supersenses", "author": ["Schneider", "Smith2015] Nathan Schneider", "Noah A Smith"], "venue": "Proc. of NAACL-HLT", "citeRegEx": "Schneider et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Schneider et al\\.", "year": 2015}, {"title": "Deep multitask learning with low level tasks supervised at lower layers", "author": ["S\u00f8gaard", "Goldberg2016] Anders S\u00f8gaard", "Yoav Goldberg"], "venue": null, "citeRegEx": "S\u00f8gaard et al\\.,? \\Q2016\\E", "shortCiteRegEx": "S\u00f8gaard et al\\.", "year": 2016}, {"title": "Profiting from mark-up: Hyper-text annotations for guided parsing", "author": ["Daniel Jurafsky", "Hiyan Alshawi"], "venue": null, "citeRegEx": "Spitkovsky et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Spitkovsky et al\\.", "year": 2010}], "referenceMentions": [{"referenceID": 0, "context": "Some approaches to multi-task learning are, for example, known to work when the tasks share optimal hypothesis classes (Baxter, 2000) or are drawn from related sample generating distributions (BenDavid and Borberly, 2003).", "startOffset": 119, "endOffset": 133}, {"referenceID": 9, "context": "However, while great improvements have been reported (Luong et al., 2016; Klerke et al., 2016), results are also often mixed (Collobert and Weston, 2008; S\u00f8gaard and Goldberg, 2016; Mart\u0131\u0301nez Alonso and Plank, 2017), and theoretical guarantees no longer apply.", "startOffset": 53, "endOffset": 94}, {"referenceID": 8, "context": "However, while great improvements have been reported (Luong et al., 2016; Klerke et al., 2016), results are also often mixed (Collobert and Weston, 2008; S\u00f8gaard and Goldberg, 2016; Mart\u0131\u0301nez Alonso and Plank, 2017), and theoretical guarantees no longer apply.", "startOffset": 53, "endOffset": 94}, {"referenceID": 8, "context": "We follow previous work (Klerke et al., 2016; S\u00f8gaard and Goldberg, 2016; Bollman and S\u00f8gaard, 2016; Plank, 2016; Braud et al., 2016; Mart\u0131\u0301nez Alonso and Plank, 2017) in studying the set-up where hyperparameters from the single task architectures are reused in the multi-task setup (no additional tuning), which makes predicting gains feasible.", "startOffset": 24, "endOffset": 167}, {"referenceID": 14, "context": "We follow previous work (Klerke et al., 2016; S\u00f8gaard and Goldberg, 2016; Bollman and S\u00f8gaard, 2016; Plank, 2016; Braud et al., 2016; Mart\u0131\u0301nez Alonso and Plank, 2017) in studying the set-up where hyperparameters from the single task architectures are reused in the multi-task setup (no additional tuning), which makes predicting gains feasible.", "startOffset": 24, "endOffset": 167}, {"referenceID": 3, "context": "We follow previous work (Klerke et al., 2016; S\u00f8gaard and Goldberg, 2016; Bollman and S\u00f8gaard, 2016; Plank, 2016; Braud et al., 2016; Mart\u0131\u0301nez Alonso and Plank, 2017) in studying the set-up where hyperparameters from the single task architectures are reused in the multi-task setup (no additional tuning), which makes predicting gains feasible.", "startOffset": 24, "endOffset": 167}, {"referenceID": 8, "context": "Luong et al. (2016) suggest that it is important that the auxiliary data does not outsize the target data, while Benton et al.", "startOffset": 0, "endOffset": 20}, {"referenceID": 1, "context": "(2016) suggest that it is important that the auxiliary data does not outsize the target data, while Benton et al. (2017) suggest that multi-task learning is particularly effective when we only have access to small amounts of target data.", "startOffset": 100, "endOffset": 121}, {"referenceID": 1, "context": "(2016) suggest that it is important that the auxiliary data does not outsize the target data, while Benton et al. (2017) suggest that multi-task learning is particularly effective when we only have access to small amounts of target data. Mart\u0131\u0301nez Alonso and Plank (2017) present a study on different task combinations with dedicated main and auxiliary tasks.", "startOffset": 100, "endOffset": 272}, {"referenceID": 4, "context": "While there are many approaches to multi-task learning, hard parameter sharing in deep neural networks (Caruana, 1993) has become extremely popular in recent years.", "startOffset": 103, "endOffset": 118}, {"referenceID": 0, "context": "Its greatest advantages over other methods include (i) that it is known to be an efficient regularizer, theoretically (Baxter, 2000), as well as in practice (S\u00f8gaard and Goldberg, 2016); and (ii) that it is easy to implement.", "startOffset": 118, "endOffset": 132}, {"referenceID": 8, "context": "Recent work on multi-task learning of NLP models has focused on sequence labeling with recurrent neural networks (Klerke et al., 2016; S\u00f8gaard and Goldberg, 2016; Bollman and S\u00f8gaard, 2016; Plank, 2016; Braud et al., 2016; Mart\u0131\u0301nez Alonso and Plank, 2017), although sequence-to-sequence models have been shown to profit from MTL as well (Luong et al.", "startOffset": 113, "endOffset": 256}, {"referenceID": 14, "context": "Recent work on multi-task learning of NLP models has focused on sequence labeling with recurrent neural networks (Klerke et al., 2016; S\u00f8gaard and Goldberg, 2016; Bollman and S\u00f8gaard, 2016; Plank, 2016; Braud et al., 2016; Mart\u0131\u0301nez Alonso and Plank, 2017), although sequence-to-sequence models have been shown to profit from MTL as well (Luong et al.", "startOffset": 113, "endOffset": 256}, {"referenceID": 3, "context": "Recent work on multi-task learning of NLP models has focused on sequence labeling with recurrent neural networks (Klerke et al., 2016; S\u00f8gaard and Goldberg, 2016; Bollman and S\u00f8gaard, 2016; Plank, 2016; Braud et al., 2016; Mart\u0131\u0301nez Alonso and Plank, 2017), although sequence-to-sequence models have been shown to profit from MTL as well (Luong et al.", "startOffset": 113, "endOffset": 256}, {"referenceID": 9, "context": ", 2016; Mart\u0131\u0301nez Alonso and Plank, 2017), although sequence-to-sequence models have been shown to profit from MTL as well (Luong et al., 2016).", "startOffset": 123, "endOffset": 143}, {"referenceID": 8, "context": "As already mentioned, we keep hyper-parameters fixed across single-task and multi-task settings, making our results only applicable to the scenario where one wants to know whether MTL works in the current parameter setting (Collobert and Weston, 2008; Klerke et al., 2016; S\u00f8gaard and Goldberg, 2016; Bollman and S\u00f8gaard, 2016; Plank, 2016; Braud et al., 2016; Mart\u0131\u0301nez Alonso and Plank, 2017).", "startOffset": 223, "endOffset": 394}, {"referenceID": 14, "context": "As already mentioned, we keep hyper-parameters fixed across single-task and multi-task settings, making our results only applicable to the scenario where one wants to know whether MTL works in the current parameter setting (Collobert and Weston, 2008; Klerke et al., 2016; S\u00f8gaard and Goldberg, 2016; Bollman and S\u00f8gaard, 2016; Plank, 2016; Braud et al., 2016; Mart\u0131\u0301nez Alonso and Plank, 2017).", "startOffset": 223, "endOffset": 394}, {"referenceID": 3, "context": "As already mentioned, we keep hyper-parameters fixed across single-task and multi-task settings, making our results only applicable to the scenario where one wants to know whether MTL works in the current parameter setting (Collobert and Weston, 2008; Klerke et al., 2016; S\u00f8gaard and Goldberg, 2016; Bollman and S\u00f8gaard, 2016; Plank, 2016; Braud et al., 2016; Mart\u0131\u0301nez Alonso and Plank, 2017).", "startOffset": 223, "endOffset": 394}, {"referenceID": 10, "context": "We use the standard splits for syntactic chunking from the English Penn Treebank (Marcus et al., 1993).", "startOffset": 81, "endOffset": 102}, {"referenceID": 13, "context": "POS tagging (POS) We use a dataset of tweets annotated for Universal part-of-speech tags (Petrov et al., 2011).", "startOffset": 89, "endOffset": 110}, {"referenceID": 17, "context": "Hyperlink Prediction (HYP) We use the hypertext corpus from Spitkovsky et al. (2010) and predict what sequences of words have been bracketed with hyperlinks.", "startOffset": 60, "endOffset": 85}, {"referenceID": 14, "context": "The latter supports the hypothesis put forward by Mart\u0131\u0301nez Alonso and Plank (2017) (see Related work).", "startOffset": 71, "endOffset": 84}, {"referenceID": 14, "context": "We also observed that label entropy in the auxiliary task was also a good predictor, lending some support to the hypothesis in Mart\u0131\u0301nez Alonso and Plank (2017); but there was little evidence that dataset balance is a reliable predictor, unlike what previous work has suggested.", "startOffset": 148, "endOffset": 161}], "year": 2017, "abstractText": "Multi-task learning (MTL) in deep neural networks for NLP has recently received increasing interest due to some compelling benefits, including its potential to efficiently regularize models and to reduce the need for labeled data. While it has brought significant improvements in a number of NLP tasks, mixed results have been reported, and little is known about the conditions under which MTL leads to gains in NLP. This paper sheds light on the specific task relations that can lead to gains from MTL models over single-task setups.", "creator": "LaTeX with hyperref package"}}}