{"id": "1702.08533", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Feb-2017", "title": "Competing Bandits: Learning under Competition", "abstract": "Most modern systems strive to learn from interactions with users, and many engage in \\emph{exploration}: making potentially suboptimal choices for the sake of acquiring new information. We initiate a study of the interplay between \\emph{exploration and competition}---how such systems balance the exploration for learning and the competition for users. Here the users play three distinct roles: they are customers that generate revenue, they are sources of data for learning, and they are self-interested agents which choose among the competing systems.", "histories": [["v1", "Mon, 27 Feb 2017 21:13:57 GMT  (39kb)", "http://arxiv.org/abs/1702.08533v1", null]], "reviews": [], "SUBJECTS": "cs.GT cs.LG", "authors": ["yishay mansour", "aleksandrs slivkins", "zhiwei steven wu"], "accepted": false, "id": "1702.08533"}, "pdf": {"name": "1702.08533.pdf", "metadata": {"source": "CRF", "title": "Competing Bandits: Learning under Competition", "authors": ["Yishay Mansour", "Aleksandrs Slivkins", "Zhiwei Steven Wu"], "emails": ["mansour@tau.ac.il", "slivkins@microsoft.com", "wuzhiwei@cis.upenn.edu"], "sections": [{"heading": null, "text": "ar Xiv: 170 2.08 533v 1 [cs.G T] 27 February 20As a model, we consider the competition between two multi-armed bandit algorithms faced with the same instance of bandit. Users come one by one and choose between the two algorithms, so that each algorithm progresses when and only when it is selected. We ask whether and to what extent competition promotes innovation: the introduction of better algorithms. We examine this question using several models of user reaction, as we vary the degree of rationality and competitiveness within the model."}, {"heading": "1 Introduction", "text": "Learning from user interactions is ubiquitous in modern customer-centric systems, from product recommendations to web search to spam detection and content selection to fine-tuning the user interface. Many systems implement targeted exploration: making potentially sub-optimal decisions to gain new information. Randomized controlled trials, also known as A / B tests, are an industry standard where a number of companies such as Optimizely offer tools and platforms to facilitate them. Many companies use more complex exploration methods based on multi-armed bandits, a well-known theoretical framework for exploration and decision-making amid uncertainty. Systems that engage in exploration typically have to compete against each other; most importantly, they compete for users, creating an interesting tension between exploration and competition. In short, while exploration is essential for improving the service of tomorrow, it may be essential for users to leave the quality of tomorrow, and it may be in the hands of tomorrow."}, {"heading": "1.1 Our model", "text": "We define a game in which two companies (principals) participate in the exploration at the same time and compete for the users (agents). These two processes are interconnected, as exploration decisions are experienced by the users and informed by their feedback. We have to define several conceptual parts: how the principals and agents interact, which is the machine learning problem facing each principal, and details of the game between the principals and the agents. Each part can become extremely complicated in isolation, let alone together, so we strive for simplicity. Thus, the game is like this: \u2022 In each round, a new agent arrives and selects between the two principals. The principal selects an action (e.g. a list of web search results shown to the agent), the user experiences this action and reports on a reward. \u2022 Each principal stands in front of a very basic and well-researched version of the multiarmed agent and selects an action (e.g. a list of web search results shown to the agent), the user experiences this action and reports on a reward."}, {"heading": "1.2 Our results", "text": "In fact, most of them will be able to move to a different world in which they are able to escape than to another world in which they are able to escape."}, {"heading": "1.3 Map of the paper.", "text": "We examine the related work (Section 2), define the model and preparatory work (Section 3) and analyze the three main models HardMax, HardMax & Random and SoftMax (in Sections 4, 5, 6 and 6 respectively)."}, {"heading": "2 Related work", "text": "This also applies to other areas in which people are able to develop, not only for themselves, but also for themselves. (Look at what people do in the world.) This also applies to the areas in which people are able to develop themselves. (Look at what people do in the world.) This also applies to the areas in which people in the world can develop themselves. (Look at what people in the world can do.) This also applies to people in the world. (Look at what people do in the world, in the world, in the world, in the world in the world they live, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world. (Look at what people in the world, in the world, in the world, in the world, in the world, in the world.)"}, {"heading": "3 Basic model and preliminaries", "text": "In fact, it is as if it is a reactionary, reactionary, reactionary, reactionary, reactionary, reactionary, reactionary, reactionary, reactionary, reactionary, reactionary and reactionary party."}, {"heading": "3.1 Generalizations", "text": "Our results can be extended in comparison to the basic model described above. First, unless otherwise stated, our results allow a more general idea of the benefit of the principle, which may depend on both the market share and the rewards of the agents. Principally, i collects Ui (rt) units of benefit in each global round t when selected (and 0 otherwise), where Ui (\u00b7) is a fixed, non-diminishing function with Ui (0) > 0. In one formula, Ui means: = \u2211 T = 1 {it = i} \u00b7 Ui (rr). (5) Secondly, our results are transferred to much more general versions of MAB, with little or no modification of the evidence, as long as they fulfil the i.i.d. property. In each round, an algorithm can detect a context before selecting an action (such as in contextual bandits) and / or additional feedback about a reward other than the reward, after the reward component is selected (such as a bandit and an object in a fixed context)."}, {"heading": "3.2 Chernoff Bounds", "text": "We use an elementary concentration inequality known as Chernoff boundaries, in a formulation by Mitzenmacher and (2005) Theorem 3.1 (Chernoff boundaries). Consider n i.i.d. random variables X1... Xn with values in [0,1]. Let X = 1n, n = i = 1Xi be their average and let \u03bd = E [X]. Then: min (Pr [X \u2212 \u03bd > \u03b4\u03bd], Pr [\u03bd \u2212 X > \u03b4\u03bd]) < e \u2212 \u03bdn\u03b42 / 3 for any \u043c (0,1)."}, {"heading": "4 Full rationality (HardMax)", "text": "In this section, we consider the version in which the agents are perfectly rational in the sense that their reaction function is HardMax. We show that principles have no incentive to explore - i.e., deviate from DynamicGreedy. The central technical result is that if one principal adopts DynamicGreedy, the other principal loses all agents as soon as he deviates. To be more precise, we say that two MAB algorithms deviate at (local) step n, if there is an action, the a and a realization h of the step-n story, so that h is feasible for both algorithms, and within the framework of this story, the two algorithms choose an action with different probability. Theorem4.1. Let's assume that HardMax reaction function with fair tie-breaking. Suppose that Alg1 is DynamicGreedy and Alg2 deviates from DynamicGreedy, with each (local step) being T. <"}, {"heading": "4.1 Proof of Theorem 4.1", "text": "The proof starts with two auxiliary lemmas: the deviation from DynamicGreedy implies a strictly smaller Bayesian expected reward, and HardMax implies a \"sudden-death\" property: if an agent chooses Principal 1 with certainty, then all subsequent agents do so. Since the two algorithms agree on the first n0 \u2212 1 steps of the MRMRMRM, it follows symmetry that the histories H1, n0 and H2, n0 and H2 have the same distribution. We assume that the two histories agree, n0 = H2 = H.At local level n0, DynamicGreedy chooses an action a1, n0 that maximizes the."}, {"heading": "5 Relaxed rationality: HardMax & Random", "text": "The most important technical result for this model is that a principal with a maximum probability (1) considers a principal with a maximum probability (1) a principal with a maximum probability (1) a principal with a maximum probability (1). (1) A principal with a maximum probability (1). (1) A principal with a maximum probability (1). (1) A principal with a maximum probability (1). (1) A principal with a maximum probability (1). (1) A principal with a maximum probability (1). (1) A principal with a maximum probability (1). (1) We formulate and prove a cleaner version of the result, followed by a subsequent general formulation that we have developed in a subsequent remark. We must express a property that finally captures Alg1 and exceeds Alg2, even if it initially receives only a fraction of the traffic."}, {"heading": "5.1 A little greedy goes a long way", "text": "In view of the fact that an algorithm other than DynamicGreedy is not able to implement a modified algorithm selection that learns more slowly but nevertheless \"wins the game\" in the sense of Theorem 5.1. As a consequence, we will construct a modified algorithm as a consequence. The modified algorithm coincides with alg1 (and DynamicGreedy) for the first n0 \u2212 1 steps, which differ from step n0 and a \"mixing\" parameter p. The modified algorithm coincides with alg1 (and DynamicGreedy) for the first n0 \u2212 1 steps. In each step n0, alg1 is Alg1 with probability 1 \u2212 p, and with the remaining probability p."}, {"heading": "6 SoftMax response function", "text": "This section is dedicated to SoftMaxModels and the same evidence. We recover from a positive result under the assumptions of Theorem 5.1 (albeit with a weaker conclusion), and then move on to a more difficult result under weaker assumptions."}, {"heading": "7 Economic implications", "text": "In fact, most of them are not an individual, but a group of people who are able to decide whether they are able to get involved or whether they are able to integrate."}, {"heading": "A Background on multi-armed bandits", "text": "This appendix provides some relevant background information on multi-armed bandits (MAB) 2. and 1. we are all randomly assigned. We discuss BIR = > monotonicity of severalMAB algorithms, touch on: DynamicGreedy and StaticGreedy (Section A.1), \"naive\" MAB algorithms that separate exploration and exploitation (Section A.2), and \"intelligent\" MAB algorithms that combine exploration and exploitation (Section A.3).As we have throughout the paper, we focus on MAB with i.e. rewards and a bayesian; we call it Bayesian MAB for brevity.A.1 DynamicGreedy and StaticGreedyWe provide an example of when DynamicGreedy and StaticGreedy have constant BIR, and demonstrate monotonicity of DynamicGreedy. For the example, it is enough to consider deterministic rewards."}], "references": [{"title": "Multiworld testing: A system for experimentation, learning, and decision-making, 2016. A white paper, available at https://github.com/Microsoft/mwt-ds/raw/master/images/MWT-WhitePaper.pdf", "author": ["Alekh Agarwal", "Sarah Bird", "Markus Cozowicz", "Miro Dudik", "John Langford", "Lihong Li", "Luong Hoang", "Dan Melamed", "Siddhartha Sen", "Robert Schapire", "Alex Slivkins"], "venue": null, "citeRegEx": "Agarwal et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Agarwal et al\\.", "year": 2016}, {"title": "Competition and innovation: An inverted u relationship", "author": ["Philippe Aghion", "Nicholas Bloom", "Richard Blundell", "Rachel Griffith", "Peter Howitt"], "venue": "Quaterly J. of Economics,", "citeRegEx": "Aghion et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Aghion et al\\.", "year": 2005}, {"title": "An efficient dynamic mechanism", "author": ["Susan Athey", "Ilya Segal"], "venue": null, "citeRegEx": "Athey and Segal.,? \\Q2013\\E", "shortCiteRegEx": "Athey and Segal.", "year": 2013}, {"title": "Finite-time analysis of the multiarmed bandit problem", "author": ["Peter Auer", "Nicol\u00f2 Cesa-Bianchi", "Paul Fischer"], "venue": "Machine Learning,", "citeRegEx": "Auer et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Auer et al\\.", "year": 2002}, {"title": "The nonstochastic multiarmed bandit problem", "author": ["Peter Auer", "Nicol\u00f2 Cesa-Bianchi", "Yoav Freund", "Robert E. Schapire"], "venue": "SIAM J. Comput.,", "citeRegEx": "Auer et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Auer et al\\.", "year": 2002}, {"title": "Perfect competition in markets with adverse", "author": ["Eduardo Azevedo", "Daniel Gottlieb"], "venue": "selection. Econometrica,", "citeRegEx": "Azevedo and Gottlieb.,? \\Q2017\\E", "shortCiteRegEx": "Azevedo and Gottlieb.", "year": 2017}, {"title": "Characterizing truthful multiarmed bandit mechanisms", "author": ["Moshe Babaioff", "Yogeshwer Sharma", "Aleksandrs Slivkins"], "venue": "SIAM J. on Computing,", "citeRegEx": "Babaioff et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Babaioff et al\\.", "year": 2014}, {"title": "Truthful mechanisms with implicit payment computation", "author": ["Moshe Babaioff", "Robert Kleinberg", "Aleksandrs Slivkins"], "venue": "Journal of the ACM,", "citeRegEx": "Babaioff et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Babaioff et al\\.", "year": 2015}, {"title": "Economic recommendation systems", "author": ["Gal Bahar", "Rann Smorodinsky", "Moshe Tennenholtz"], "venue": "In 16th ACM EC,", "citeRegEx": "Bahar et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Bahar et al\\.", "year": 2016}, {"title": "The dynamic pivot mechanism", "author": ["Dirk Bergemann", "Juuso V\u00e4lim\u00e4ki"], "venue": null, "citeRegEx": "Bergemann and V\u00e4lim\u00e4ki.,? \\Q2010\\E", "shortCiteRegEx": "Bergemann and V\u00e4lim\u00e4ki.", "year": 2010}, {"title": "Crowdsourcing exploration. Management Science, 2017", "author": ["Kostas Bimpikis", "Yiangos Papanastasiou", "Nicos Savva"], "venue": null, "citeRegEx": "Bimpikis et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Bimpikis et al\\.", "year": 2017}, {"title": "Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems", "author": ["S\u00e9bastien Bubeck", "Nicolo Cesa-Bianchi"], "venue": "Foundations and Trends in Machine Learning,", "citeRegEx": "Bubeck and Cesa.Bianchi.,? \\Q2012\\E", "shortCiteRegEx": "Bubeck and Cesa.Bianchi.", "year": 2012}, {"title": "Optimal design for social learning", "author": ["Yeon-Koo Che", "Johannes H\u00f6rner"], "venue": "First draft:", "citeRegEx": "Che and H\u00f6rner.,? \\Q2015\\E", "shortCiteRegEx": "Che and H\u00f6rner.", "year": 2015}, {"title": "The price of truthfulness for pay-per-click auctions", "author": ["Nikhil Devanur", "Sham M. Kakade"], "venue": "In 10th ACM EC,", "citeRegEx": "Devanur and Kakade.,? \\Q2009\\E", "shortCiteRegEx": "Devanur and Kakade.", "year": 2009}, {"title": "Action elimination and stopping conditions for the multi-armed bandit and reinforcement learning problems", "author": ["Eyal Even-Dar", "ShieMannor", "YishayMansour"], "venue": "J. of Machine Learning Research (JMLR),", "citeRegEx": "Even.Dar et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Even.Dar et al\\.", "year": 2006}, {"title": "Incentivizing exploration", "author": ["Peter Frazier", "David Kempe", "Jon M. Kleinberg", "Robert Kleinberg"], "venue": "In ACM EC,", "citeRegEx": "Frazier et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Frazier et al\\.", "year": 2014}, {"title": "The impact of competition on prices with numerous firms", "author": ["Xavier Gabaix", "David Laibson", "Deyuan Li", "Hongyi Li", "Sidney Resnick", "Casper G. de Vries"], "venue": "J. of Economic Theory,", "citeRegEx": "Gabaix et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Gabaix et al\\.", "year": 2016}, {"title": "Learning and incentives in user-generated content: multiarmed bandits with endogenous arms", "author": ["Arpita Ghosh", "Patrick Hummel"], "venue": "In ITCS,", "citeRegEx": "Ghosh and Hummel.,? \\Q2013\\E", "shortCiteRegEx": "Ghosh and Hummel.", "year": 2013}, {"title": "Multi-Armed Bandit Allocation Indices", "author": ["John Gittins", "Kevin Glazebrook", "Richard Weber"], "venue": null, "citeRegEx": "Gittins et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Gittins et al\\.", "year": 2011}, {"title": "Mean field equilibria of multiarmed bandit games", "author": ["Ramakrishna Gummadi", "Ramesh Johari", "Jia Yuan Yu"], "venue": "In 13th ACM EC,", "citeRegEx": "Gummadi et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Gummadi et al\\.", "year": 2012}, {"title": "Adaptive contract design for crowdsourcingmarkets: Bandit algorithms for repeated principal-agent problems", "author": ["Chien-Ju Ho", "Aleksandrs Slivkins", "Jennifer Wortman Vaughan"], "venue": "In 15th ACM EC,", "citeRegEx": "Ho et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Ho et al\\.", "year": 2014}, {"title": "Stability in competition", "author": ["Harold Hotelling"], "venue": "The Economic Journal,", "citeRegEx": "Hotelling.,? \\Q1929\\E", "shortCiteRegEx": "Hotelling.", "year": 1929}, {"title": "Optimal dynamic mechanism design and the virtual-pivot mechanism", "author": ["Sham M. Kakade", "Ilan Lobel", "Hamid Nazerzadeh"], "venue": "Operations Research,", "citeRegEx": "Kakade et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Kakade et al\\.", "year": 2013}, {"title": "Strategic Experimentation with Exponential Bandits", "author": ["Godfrey Keller", "Sven Rady", "Martin Cripps"], "venue": null, "citeRegEx": "Keller et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Keller et al\\.", "year": 2005}, {"title": "Descending price optimally coordinates search", "author": ["Robert D. Kleinberg", "Bo Waggoner", "E. Glen Weyl"], "venue": "Working paper,", "citeRegEx": "Kleinberg et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Kleinberg et al\\.", "year": 2016}, {"title": "Implementing the wisdom of the crowd", "author": ["Ilan Kremer", "Yishay Mansour", "Motty Perry"], "venue": "J. of Political Economy,", "citeRegEx": "Kremer et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kremer et al\\.", "year": 2014}, {"title": "Asymptotically efficient Adaptive Allocation Rules", "author": ["Tze Leung Lai andHerbert Robbins"], "venue": "Advances in Applied Mathematics,", "citeRegEx": "Robbins.,? \\Q1985\\E", "shortCiteRegEx": "Robbins.", "year": 1985}, {"title": "Bayesian incentive-compatible bandit exploration", "author": ["Yishay Mansour", "Aleksandrs Slivkins", "Vasilis Syrgkanis"], "venue": "In 15th ACM EC,", "citeRegEx": "Mansour et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Mansour et al\\.", "year": 2015}, {"title": "Bayesian exploration: Incentivizing exploration in bayesian games", "author": ["Yishay Mansour", "Aleksandrs Slivkins", "Vasilis Syrgkanis", "Steven Wu"], "venue": "Working paper,", "citeRegEx": "Mansour et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Mansour et al\\.", "year": 2016}, {"title": "Information, trade and common knowledge", "author": ["Paul Milgrom", "Nancy Stokey"], "venue": "J. of Economic Theory,", "citeRegEx": "Milgrom and Stokey.,? \\Q1982\\E", "shortCiteRegEx": "Milgrom and Stokey.", "year": 1982}, {"title": "Probability and Computing: Randomized Algorithms and Probabilistic Analysis", "author": ["Michael Mitzenmacher", "Eli Upfal"], "venue": null, "citeRegEx": "Mitzenmacher and Upfal.,? \\Q2005\\E", "shortCiteRegEx": "Mitzenmacher and Upfal.", "year": 2005}, {"title": "Equilibrium with product differentiation", "author": ["Jeffrey M. Perloff", "Steven C. Salop"], "venue": "Review of Economic Studies,", "citeRegEx": "Perloff and Salop.,? \\Q1985\\E", "shortCiteRegEx": "Perloff and Salop.", "year": 1985}, {"title": "Equilibrium in competitive insurance markets: An essay on the economics of imperfect information", "author": ["Michael Rothschild", "Joseph Stiglitz"], "venue": "Quaterly J. of Economics,", "citeRegEx": "Rothschild and Stiglitz.,? \\Q1976\\E", "shortCiteRegEx": "Rothschild and Stiglitz.", "year": 1976}, {"title": "Truthful incentives in crowdsourcing tasks using regret mini", "author": ["Joseph Schumpeter. Capitalism", "Socialism", "Democracy. Harper", "Brothers", "1942. Adish Singla", "Andreas Krause"], "venue": null, "citeRegEx": "2009", "shortCiteRegEx": "2009", "year": 1942}, {"title": "Innovation and competitive pressure", "author": ["2016. Xavier Vives"], "venue": "J. of Industrial Economics,", "citeRegEx": "Vives.,? \\Q2008\\E", "shortCiteRegEx": "Vives.", "year": 2008}], "referenceMentions": [{"referenceID": 11, "context": "MAB problems have been studied in Economics, Operations Research and Computer Science for many decades, see (Bubeck and Cesa-Bianchi, 2012; Gittins et al., 2011) for background on regret-minimizing and Bayesian formulations, respectively.", "startOffset": 108, "endOffset": 161}, {"referenceID": 18, "context": "MAB problems have been studied in Economics, Operations Research and Computer Science for many decades, see (Bubeck and Cesa-Bianchi, 2012; Gittins et al., 2011) for background on regret-minimizing and Bayesian formulations, respectively.", "startOffset": 108, "endOffset": 161}, {"referenceID": 14, "context": ", 2002a) and Successive Elimination (Even-Dar et al., 2006).", "startOffset": 36, "endOffset": 59}, {"referenceID": 12, "context": "The three-way tradeoff between exploration, exploitation and incentives has been studied in several other settings: incentivizing exploration in a recommendation system (Che and H\u00f6rner, 2015; Frazier et al., 2014; Kremer et al., 2014;Mansour et al., 2015; Bimpikis et al., 2017; Bahar et al., 2016;Mansour et al., 2016), dynamic auctions (e.", "startOffset": 169, "endOffset": 319}, {"referenceID": 15, "context": "The three-way tradeoff between exploration, exploitation and incentives has been studied in several other settings: incentivizing exploration in a recommendation system (Che and H\u00f6rner, 2015; Frazier et al., 2014; Kremer et al., 2014;Mansour et al., 2015; Bimpikis et al., 2017; Bahar et al., 2016;Mansour et al., 2016), dynamic auctions (e.", "startOffset": 169, "endOffset": 319}, {"referenceID": 25, "context": "The three-way tradeoff between exploration, exploitation and incentives has been studied in several other settings: incentivizing exploration in a recommendation system (Che and H\u00f6rner, 2015; Frazier et al., 2014; Kremer et al., 2014;Mansour et al., 2015; Bimpikis et al., 2017; Bahar et al., 2016;Mansour et al., 2016), dynamic auctions (e.", "startOffset": 169, "endOffset": 319}, {"referenceID": 27, "context": "The three-way tradeoff between exploration, exploitation and incentives has been studied in several other settings: incentivizing exploration in a recommendation system (Che and H\u00f6rner, 2015; Frazier et al., 2014; Kremer et al., 2014;Mansour et al., 2015; Bimpikis et al., 2017; Bahar et al., 2016;Mansour et al., 2016), dynamic auctions (e.", "startOffset": 169, "endOffset": 319}, {"referenceID": 10, "context": "The three-way tradeoff between exploration, exploitation and incentives has been studied in several other settings: incentivizing exploration in a recommendation system (Che and H\u00f6rner, 2015; Frazier et al., 2014; Kremer et al., 2014;Mansour et al., 2015; Bimpikis et al., 2017; Bahar et al., 2016;Mansour et al., 2016), dynamic auctions (e.", "startOffset": 169, "endOffset": 319}, {"referenceID": 8, "context": "The three-way tradeoff between exploration, exploitation and incentives has been studied in several other settings: incentivizing exploration in a recommendation system (Che and H\u00f6rner, 2015; Frazier et al., 2014; Kremer et al., 2014;Mansour et al., 2015; Bimpikis et al., 2017; Bahar et al., 2016;Mansour et al., 2016), dynamic auctions (e.", "startOffset": 169, "endOffset": 319}, {"referenceID": 28, "context": "The three-way tradeoff between exploration, exploitation and incentives has been studied in several other settings: incentivizing exploration in a recommendation system (Che and H\u00f6rner, 2015; Frazier et al., 2014; Kremer et al., 2014;Mansour et al., 2015; Bimpikis et al., 2017; Bahar et al., 2016;Mansour et al., 2016), dynamic auctions (e.", "startOffset": 169, "endOffset": 319}, {"referenceID": 9, "context": ", 2016), dynamic auctions (e.g., Athey and Segal, 2013; Bergemann and V\u00e4lim\u00e4ki, 2010; Kakade et al., 2013), pay-per-click ad auctions with unknown click probabilities (e.", "startOffset": 26, "endOffset": 106}, {"referenceID": 22, "context": ", 2016), dynamic auctions (e.g., Athey and Segal, 2013; Bergemann and V\u00e4lim\u00e4ki, 2010; Kakade et al., 2013), pay-per-click ad auctions with unknown click probabilities (e.", "startOffset": 26, "endOffset": 106}, {"referenceID": 13, "context": ", 2013), pay-per-click ad auctions with unknown click probabilities (e.g., Babaioff et al., 2014; Devanur and Kakade, 2009; Babaioff et al., 2015), coordinating search andmatching by selfinterested agents (Kleinberg et al.", "startOffset": 68, "endOffset": 146}, {"referenceID": 7, "context": ", 2013), pay-per-click ad auctions with unknown click probabilities (e.g., Babaioff et al., 2014; Devanur and Kakade, 2009; Babaioff et al., 2015), coordinating search andmatching by selfinterested agents (Kleinberg et al.", "startOffset": 68, "endOffset": 146}, {"referenceID": 24, "context": ", 2015), coordinating search andmatching by selfinterested agents (Kleinberg et al., 2016), as well as human computation (e.", "startOffset": 66, "endOffset": 90}, {"referenceID": 17, "context": ", 2016), as well as human computation (e.g., Ho et al., 2014; Ghosh and Hummel, 2013; Singla and Krause, 2013).", "startOffset": 38, "endOffset": 110}, {"referenceID": 0, "context": "A discussion of industrial applications of MAB can be found in Agarwal et al. (2016). The literature on MAB is vast and multi-threaded.", "startOffset": 63, "endOffset": 85}, {"referenceID": 0, "context": "A discussion of industrial applications of MAB can be found in Agarwal et al. (2016). The literature on MAB is vast and multi-threaded. The most related thread concerns regretminimizingMAB formulations with IID rewards (Lai and Robbins, 1985; Auer et al., 2002a). This thread includes \u201csmart\u201d MAB algorithms that combine exploration and exploitation, such as UCB1 (Auer et al., 2002a) and Successive Elimination (Even-Dar et al., 2006). Specific algorithms, and \u2018naive\u201d MAB algorithms that separate exploration and exploitation, such as Explore-thenExploit and \u01eb-Greedy. The three-way tradeoff between exploration, exploitation and incentives has been studied in several other settings: incentivizing exploration in a recommendation system (Che and H\u00f6rner, 2015; Frazier et al., 2014; Kremer et al., 2014;Mansour et al., 2015; Bimpikis et al., 2017; Bahar et al., 2016;Mansour et al., 2016), dynamic auctions (e.g., Athey and Segal, 2013; Bergemann and V\u00e4lim\u00e4ki, 2010; Kakade et al., 2013), pay-per-click ad auctions with unknown click probabilities (e.g., Babaioff et al., 2014; Devanur and Kakade, 2009; Babaioff et al., 2015), coordinating search andmatching by selfinterested agents (Kleinberg et al., 2016), as well as human computation (e.g., Ho et al., 2014; Ghosh and Hummel, 2013; Singla and Krause, 2013). Bolton and Harris (1999); Keller et al.", "startOffset": 63, "endOffset": 1341}, {"referenceID": 0, "context": "A discussion of industrial applications of MAB can be found in Agarwal et al. (2016). The literature on MAB is vast and multi-threaded. The most related thread concerns regretminimizingMAB formulations with IID rewards (Lai and Robbins, 1985; Auer et al., 2002a). This thread includes \u201csmart\u201d MAB algorithms that combine exploration and exploitation, such as UCB1 (Auer et al., 2002a) and Successive Elimination (Even-Dar et al., 2006). Specific algorithms, and \u2018naive\u201d MAB algorithms that separate exploration and exploitation, such as Explore-thenExploit and \u01eb-Greedy. The three-way tradeoff between exploration, exploitation and incentives has been studied in several other settings: incentivizing exploration in a recommendation system (Che and H\u00f6rner, 2015; Frazier et al., 2014; Kremer et al., 2014;Mansour et al., 2015; Bimpikis et al., 2017; Bahar et al., 2016;Mansour et al., 2016), dynamic auctions (e.g., Athey and Segal, 2013; Bergemann and V\u00e4lim\u00e4ki, 2010; Kakade et al., 2013), pay-per-click ad auctions with unknown click probabilities (e.g., Babaioff et al., 2014; Devanur and Kakade, 2009; Babaioff et al., 2015), coordinating search andmatching by selfinterested agents (Kleinberg et al., 2016), as well as human computation (e.g., Ho et al., 2014; Ghosh and Hummel, 2013; Singla and Krause, 2013). Bolton and Harris (1999); Keller et al. (2005); Gummadi et al.", "startOffset": 63, "endOffset": 1363}, {"referenceID": 0, "context": "A discussion of industrial applications of MAB can be found in Agarwal et al. (2016). The literature on MAB is vast and multi-threaded. The most related thread concerns regretminimizingMAB formulations with IID rewards (Lai and Robbins, 1985; Auer et al., 2002a). This thread includes \u201csmart\u201d MAB algorithms that combine exploration and exploitation, such as UCB1 (Auer et al., 2002a) and Successive Elimination (Even-Dar et al., 2006). Specific algorithms, and \u2018naive\u201d MAB algorithms that separate exploration and exploitation, such as Explore-thenExploit and \u01eb-Greedy. The three-way tradeoff between exploration, exploitation and incentives has been studied in several other settings: incentivizing exploration in a recommendation system (Che and H\u00f6rner, 2015; Frazier et al., 2014; Kremer et al., 2014;Mansour et al., 2015; Bimpikis et al., 2017; Bahar et al., 2016;Mansour et al., 2016), dynamic auctions (e.g., Athey and Segal, 2013; Bergemann and V\u00e4lim\u00e4ki, 2010; Kakade et al., 2013), pay-per-click ad auctions with unknown click probabilities (e.g., Babaioff et al., 2014; Devanur and Kakade, 2009; Babaioff et al., 2015), coordinating search andmatching by selfinterested agents (Kleinberg et al., 2016), as well as human computation (e.g., Ho et al., 2014; Ghosh and Hummel, 2013; Singla and Krause, 2013). Bolton and Harris (1999); Keller et al. (2005); Gummadi et al. (2012) studiedmodels with selfinterested agents jointly performing exploration, with no principal to coordinate them.", "startOffset": 63, "endOffset": 1386}, {"referenceID": 34, "context": "innovation relationship and the invertedU shape thereof have been introduced (among many other ideas) in a classic book (Schumpeter, 1942), and remained an important theme in the literature ever since (e.g., Aghion et al., 2005; Vives, 2008).", "startOffset": 201, "endOffset": 241}, {"referenceID": 29, "context": "noise traders) can side-step the \u201cno-trade theorem\u201d (Milgrom and Stokey, 1982), a famous impossibility result in financial economics.", "startOffset": 52, "endOffset": 78}, {"referenceID": 5, "context": "Notable recent papers (Veiga and Weyl, 2016; Azevedo and Gottlieb, 2017) emphasize the distinction between HardMax and versions of SoftMax.", "startOffset": 22, "endOffset": 72}, {"referenceID": 1, "context": ", Aghion et al., 2005; Vives, 2008). Production costs aside, this literature treats innovation as a priori beneficial for the firm. Our setting is very different, as innovation in exploration algorithms may potentially hurt the firm. A line of work on platform competition, starting with Rysman (2009), concerns competition between firms (platforms) that improve as they attract more users (network effect); seeWeyl and White (2014) for a recent survey.", "startOffset": 2, "endOffset": 302}, {"referenceID": 1, "context": ", Aghion et al., 2005; Vives, 2008). Production costs aside, this literature treats innovation as a priori beneficial for the firm. Our setting is very different, as innovation in exploration algorithms may potentially hurt the firm. A line of work on platform competition, starting with Rysman (2009), concerns competition between firms (platforms) that improve as they attract more users (network effect); seeWeyl and White (2014) for a recent survey.", "startOffset": 2, "endOffset": 433}, {"referenceID": 1, "context": ", Aghion et al., 2005; Vives, 2008). Production costs aside, this literature treats innovation as a priori beneficial for the firm. Our setting is very different, as innovation in exploration algorithms may potentially hurt the firm. A line of work on platform competition, starting with Rysman (2009), concerns competition between firms (platforms) that improve as they attract more users (network effect); seeWeyl and White (2014) for a recent survey. This literature is not concerned with innovation, and typically models network effects exogenously, whereas in our model network effects are endogenous (they are created by MAB algorithms, an essential part of the model). Relaxed versions of rationality similar to ours are found in several notable lines of work. For example, \u201crandomagents\u201d (a.k.a. noise traders) can side-step the \u201cno-trade theorem\u201d (Milgrom and Stokey, 1982), a famous impossibility result in financial economics. SoftMax model is closely related to the literature on product differentiation, starting from Hotelling (1929), see Perloff and Salop (1985) for a notable later paper.", "startOffset": 2, "endOffset": 1048}, {"referenceID": 1, "context": ", Aghion et al., 2005; Vives, 2008). Production costs aside, this literature treats innovation as a priori beneficial for the firm. Our setting is very different, as innovation in exploration algorithms may potentially hurt the firm. A line of work on platform competition, starting with Rysman (2009), concerns competition between firms (platforms) that improve as they attract more users (network effect); seeWeyl and White (2014) for a recent survey. This literature is not concerned with innovation, and typically models network effects exogenously, whereas in our model network effects are endogenous (they are created by MAB algorithms, an essential part of the model). Relaxed versions of rationality similar to ours are found in several notable lines of work. For example, \u201crandomagents\u201d (a.k.a. noise traders) can side-step the \u201cno-trade theorem\u201d (Milgrom and Stokey, 1982), a famous impossibility result in financial economics. SoftMax model is closely related to the literature on product differentiation, starting from Hotelling (1929), see Perloff and Salop (1985) for a notable later paper.", "startOffset": 2, "endOffset": 1078}, {"referenceID": 1, "context": ", Aghion et al., 2005; Vives, 2008). Production costs aside, this literature treats innovation as a priori beneficial for the firm. Our setting is very different, as innovation in exploration algorithms may potentially hurt the firm. A line of work on platform competition, starting with Rysman (2009), concerns competition between firms (platforms) that improve as they attract more users (network effect); seeWeyl and White (2014) for a recent survey. This literature is not concerned with innovation, and typically models network effects exogenously, whereas in our model network effects are endogenous (they are created by MAB algorithms, an essential part of the model). Relaxed versions of rationality similar to ours are found in several notable lines of work. For example, \u201crandomagents\u201d (a.k.a. noise traders) can side-step the \u201cno-trade theorem\u201d (Milgrom and Stokey, 1982), a famous impossibility result in financial economics. SoftMax model is closely related to the literature on product differentiation, starting from Hotelling (1929), see Perloff and Salop (1985) for a notable later paper. There is a large literature on non-existence of equilibria due to small deviations (which is related to the corresponding result for HardMax&Random), starting with Rothschild and Stiglitz (1976) in the context of health insurance markets.", "startOffset": 2, "endOffset": 1300}, {"referenceID": 3, "context": "\u2022 \u201csmart\u201dMAB algorithms that combine exploration and exploitation, such as UCB1 Auer et al. (2002a) and Successive Elimination Even-Dar et al.", "startOffset": 80, "endOffset": 100}, {"referenceID": 3, "context": "\u2022 \u201csmart\u201dMAB algorithms that combine exploration and exploitation, such as UCB1 Auer et al. (2002a) and Successive Elimination Even-Dar et al. (2006). These algorithms achieve BIR(n) \u2264 \u00d5(n\u22121/2) for all priors and all (or all but a very few) steps n.", "startOffset": 80, "endOffset": 150}, {"referenceID": 3, "context": "These algorithms have dedicated rounds in which they explore by 2This follows from the lower-bound analysis in Auer et al. (2002b).", "startOffset": 111, "endOffset": 131}, {"referenceID": 11, "context": "All these extensions have been studied extensively in the literature onMAB, and account for a substantial segment thereof; see Bubeck and Cesa-Bianchi (2012) for background and details.", "startOffset": 127, "endOffset": 158}], "year": 2017, "abstractText": "Most modern systems strive to learn from interactions with users, and many engage in exploration: making potentially suboptimal choices for the sake of acquiring new information. We initiate a study of the interplay between exploration and competition\u2014how such systems balance the exploration for learning and the competition for users. Here the users play three distinct roles: they are customers that generate revenue, they are sources of data for learning, and they are self-interested agents which choose among the competing systems. As a model, we consider competition between two multi-armed bandit algorithms faced with the same bandit instance. Users arrive one by one and choose among the two algorithms, so that each algorithm makes progress if and only if it is chosen. We ask whether and to which extent competition incentivizes innovation: adoption of better algorithms. We investigate this issue for several models of user response, as we vary the degree of rationality and competitiveness in the model. Effectively, we map out the \u201ccompetition vs. innovation\u201d relationship, a well-studied theme in economics.", "creator": "LaTeX with hyperref package"}}}