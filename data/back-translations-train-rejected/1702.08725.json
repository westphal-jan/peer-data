{"id": "1702.08725", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Feb-2017", "title": "Bayesian Verification under Model Uncertainty", "abstract": "Machine learning enables systems to build and update domain models based on runtime observations. In this paper, we study statistical model checking and runtime verification for systems with this ability. Two challenges arise: (1) Models built from limited runtime data yield uncertainty to be dealt with. (2) There is no definition of satisfaction w.r.t. uncertain hypotheses. We propose such a definition of subjective satisfaction based on recently introduced satisfaction functions. We also propose the BV algorithm as a Bayesian solution to runtime verification of subjective satisfaction under model uncertainty. BV provides user-definable stochastic bounds for type I and II errors. We discuss empirical results from an example application to illustrate our ideas.", "histories": [["v1", "Tue, 28 Feb 2017 10:14:30 GMT  (408kb,D)", "http://arxiv.org/abs/1702.08725v1", "Accepted at SEsCPS @ ICSE 2017"]], "COMMENTS": "Accepted at SEsCPS @ ICSE 2017", "reviews": [], "SUBJECTS": "cs.SE cs.AI", "authors": ["lenz belzner", "thomas gabor"], "accepted": false, "id": "1702.08725"}, "pdf": {"name": "1702.08725.pdf", "metadata": {"source": "CRF", "title": "Bayesian Verification under Model Uncertainty", "authors": ["Lenz Belzner"], "emails": ["belzner@ifi.lmu.de", "belzner@ifi.lmu.de"], "sections": [{"heading": null, "text": "The system simulates potential tracks on the basis of the domain model in order to establish some statistical guarantees about the properties of interest (see e.g. [5], [6]). Statistical verification is often based on a singular domain model [6]. In particular, Bayesian statistics allow an infinite number of models to be inferred and argued [7]. Bayesian approaches allow to quantify the probability of a particular model, since previous beliefs and observed data are available. A system that checks itself during runtime must deal with the model uncertainty in order to obtain reliable verification results."}, {"heading": "II. PRELIMINARIES", "text": "This section is reminiscent of the Bayean verification and satisfaction functions of parameterized models."}, {"heading": "A. Bayesian Model Checking", "text": "Bayesian model checking (BMC) is based on bayesian sequential hypothesis testing, and aims to infer the posterior distribution of the probability that a system will meet its requirements [3], [4]. In contrast to point estimation (e.g. maximum probability), the posterior Bayesian captures the uncertainty about the actual probability resulting from the fact that only a limited number of system evaluations are performed. Requirements can be formally defined in an appropriate probabilistic time logic [8], [9]. BMC treats a limited simulation of a system with a certain configuration as a Bernoulli experiment: the run can either meet requirements or violate them. Since simulation captures probability domain dynamics, the result of a simulation run is Bernoulli distributed with a probability p [0, 1]."}, {"heading": "B. Satisfaction Functions", "text": "Many modern systems work with models of the environment that are stochastic and parameterized, e.g. models created by machine learning. Classical statistical model verification enables the evaluation of requirement satisfaction for a single parameterization of the model. Recently, the satisfaction function was introduced as a concept to enable an efficient, regressive evaluation of requirement satisfaction for parameterizable models with potentially infinite parameters [10]. In essence, the satisfaction function is defined as the following: fsat (\u03b8) = P (sat | \u03b8) (3) Here, sat denotes a Boolean variable indicating the requirement satisfaction or violation, and \u03b8 are the model parameters. The satisfaction probability depends on the respective parameterization of the model. Note, however, that the definition of the satisfaction function does not make assumptions about the distribution of the parameters themselves. We will now turn to the combination probability of the parameters over the satisfaction function, which are subjective to apply."}, {"heading": "III. SUBJECTIVE SATISFACTION", "text": "Consider a system that has been able to make a limited number of observations about the dynamics of its environment. Consider, for example, a mobile agent whose movements may not have any effect with Bernoulli probabilities. [0; 1] The agent can observe whether his movements are effective or not. Consider a situation in which the agent has observed his movements 10 times, two of which have had no effect. Of course, the following questions arise: \u2022 What is pfail? \u2022 How sure can the agent be in his estimation of pfail? With these two questions in mind, we now consider the situation that the agent finds himself in a grid world with obstacles at certain positions. Also, the agent has a sequence of movements that have to be performed in order to accomplish a certain task, e.g. calculated by a planning component. Consider that there is a requirement that the agent may meet only a limited number of obstacles (e.g. 2)."}, {"heading": "IV. BAYESIAN VERIFICATION UNDER MODEL UNCERTAINTY", "text": "We now define the Bavarian Verification (BV), an algorithm for estimating the subjective q satisfaction through the Monte Carlo simulation. By adopting a Bavarian attitude, we also obtain a confidence measurement for this estimate. In fact, the assessment of satisfaction with a limited number of simulations results in an additional source of uncertainty: The uncertainty about the estimate of the psat. BV creates and updates a probability distribution P (sat) to quantify this uncertainty, and uses it to decide on the termination. \u2022 The current system state s. \u2022 P (\u03b8), the system uncertainty. \u2022 A probabilistic simulation model of the domain dynamics P (sat) to quantify this uncertainty, and uses it to decide on the termination. BV assumes a state, a requirement, and a parameterization and yields a Boolean variable indicating requirement satisfaction."}, {"heading": "V. EMPIRICAL RESULTS", "text": "We examined BV empirically using a toy example. While we modeled a very simple example, it is worth noting that the Bayesian approach to modelling uncertainty generally extends to much larger models. There are versatile and powerful tools for scanning complex, high-dimensional rear P (\u03b8), such as Markov Chain Monte Carlo (see e.g. [11] for a very interesting read) or variation conclusions (e.g. [12])."}, {"heading": "A. Setup", "text": "The state s is formed by a 10 x 10 grid world, in which the agent is at the position (0, 0). Obstacles are randomly positioned, with an obstacle-to-free position ratio of 0.2. A plan \u03c0 (a sequence of actions) of 10 movements (up, down, left, right, with obvious semantics) is presented to the agent. The agent has a Bernoulli probability of action pfail, which is uniformly sampled from [0; 1]. Action failure leads to the reverse movement (e.g. failure down brings yields down). The agent receives a number of observations about his probability of error before executing BV. We build a model of uncertainty P (conceived) over \u03b8 = pfail with a beta distribution (cf. Equation 2 and Section IV). In our setting, this is the prerequisite to hit less than three obstacles while executing the plan. We preq a plan, which means that if an Agent hits 0.9, we accept one."}, {"heading": "B. Results", "text": "An exemplary result of our experiments is in Figure 1. The former shows accumulated type I errors over the course of different setups (i.e. randomly generated environments paired with random plans), the latter type II errors. The dashed line shows the required statistical error limit (0.05 for creq = 0.95). In particular, BV is able to specify the required statistical error limits for both error types, while the MLE approach, which does not explicitly use the model uncertainty for conclusions, does not do so for type II errors. We observed this behavior in various observations submitted to the system."}, {"heading": "VI. RELATED WORK", "text": "BV is an instance of statistical model verification in general [2], and Bayesian statistical model verification in particular [3], [4]. Typically, these approaches are based on a perfectly available model and do not deal with explicitly quantified epistemic model uncertainty. One of the starting points of the present article is the work on the smoothed model verification [10]. SMC approaches a satisfaction function w.r.t. of uncertain model parameters through Gaussian process regression. However, SMC does not include distributions of model parameters for system evaluation. Our definition of subjective satisfaction is a direct consequence of combining quantified model uncertainty with the satisfaction function of SMC. The parameterized Bayesian model verification for DBNs [13] deals with quantified model uncertainty. However, the author does not use the posterior model to limit or estimate errors."}, {"heading": "VII. CONCLUSION", "text": "We have also presented the Bavarian Verification (BV), an approximate Monte Carlo algorithm for assessing subjective system satisfaction based on a simulation. BV allows user-specific confidence limits and thus allows statistically bound verification errors. We have evaluated BV empirically using a toy example with positive results. There are some limitations to the BV algorithm. If psat is close to preq, BV can perform many iterations to determine the required confidence. Note that this property is independent of the absolute value of psat. Similar to the Bavarian model testing based on a fixed model, BV scales well with the required satisfaction probabilities close to one (see e.g. [4]). BV's obtained error limits are statistical: they are not a hard upper problem."}, {"heading": "ACKNOWLEDGMENT", "text": "The authors thank Martin Wirsing and Matthias Ho lzl for many inspiring discussions that led us in the direction of the research presented in this essay."}], "references": [{"title": "and D", "author": ["M. Kwiatkowska", "G. Norman"], "venue": "Parker, \u201cPRISM 4.0: Verification of probabilistic real-time systems,\u201d in Proc. 23rd International Conference on Computer Aided Verification (CAV\u201911), ser. LNCS, G. Gopalakrishnan and S. Qadeer, Eds., vol. 6806. Springer", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2011}, {"title": "and S", "author": ["A. Legay", "B. Delahaye"], "venue": "Bensalem, \u201cStatistical model checking: An overview,\u201d in International Conference on Runtime Verification. Springer", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2010}, {"title": "and P", "author": ["S.K. Jha", "E.M. Clarke", "C.J. Langmead", "A. Legay", "A. Platzer"], "venue": "Zuliani, \u201cA bayesian approach to model checking biological systems,\u201d in International Conference on Computational Methods in Systems Biology. Springer", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2009}, {"title": "and E", "author": ["P. Zuliani", "A. Platzer"], "venue": "M. Clarke, \u201cBayesian statistical model checking with application to simulink/stateflow verification,\u201d in Proceedings of the 13th ACM international conference on Hybrid systems: computation and control. ACM", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2010}, {"title": "Information theory", "author": ["D.J. MacKay"], "venue": "inference and learning algorithms. Cambridge university press", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2003}, {"title": "Deep Learning", "author": ["I. Goodfellow", "Y. Bengio", "A. Courville"], "venue": "MIT Press", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2016}, {"title": "Probability theory: The logic of science", "author": ["E.T. Jaynes"], "venue": "Cambridge university press", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2003}, {"title": "The temporal logic of programs,", "author": ["A. Pnueli"], "venue": "in Foundations of Computer Science,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1977}, {"title": "Principles of model checking", "author": ["C. Baier", "J.-P. Katoen", "K.G. Larsen"], "venue": "MIT press", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2008}, {"title": "and G", "author": ["L. Bortolussi", "D. Milios"], "venue": "Sanguinetti, \u201cSmoothed model checking for uncertain continuous-time Markov chains,\u201d Information and Computation, vol. 247, pp. 235\u2013253", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2016}, {"title": "The Markov chain Monte Carlo revolution,", "author": ["P. Diaconis"], "venue": "Bulletin of the American Mathematical Society,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2009}, {"title": "M", "author": ["M.J. Wainwright"], "venue": "I. Jordan et al., \u201cGraphical models, exponential families, and variational inference,\u201d Foundations and Trends R  \u00a9 in Machine Learning, vol. 1, no. 1\u20132, pp. 1\u2013305", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2008}, {"title": "Generalized queries and bayesian statistical model checking in dynamic bayesian networks: Application to personalized medicine,", "author": ["C.J. Langmead"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2009}, {"title": "and G", "author": ["R. Calinescu", "C. Ghezzi", "K. Johnson", "M. Pezz\u00e9", "Y. Rafiq"], "venue": "Tamburrelli, \u201cFormal verification with confidence intervals to establish quality of service properties of software systems,\u201d IEEE Transactions on Reliability, vol. 65, no. 1, pp. 107\u2013125", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2016}], "referenceMentions": [{"referenceID": 0, "context": "Statistical approaches to model checking and runtime verification exploit a domain model in order to evaluate system properties at design and runtime [1].", "startOffset": 150, "endOffset": 153}, {"referenceID": 1, "context": "Statistical verification is often based on a singular domain model [2], [3], [4].", "startOffset": 67, "endOffset": 70}, {"referenceID": 2, "context": "Statistical verification is often based on a singular domain model [2], [3], [4].", "startOffset": 72, "endOffset": 75}, {"referenceID": 3, "context": "Statistical verification is often based on a singular domain model [2], [3], [4].", "startOffset": 77, "endOffset": 80}, {"referenceID": 4, "context": "[5], [6]).", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[5], [6]).", "startOffset": 5, "endOffset": 8}, {"referenceID": 6, "context": "In particular, Bayesian statistics generally allow to infer and reason about an infinite amount of models [7].", "startOffset": 106, "endOffset": 109}, {"referenceID": 2, "context": "Bayesian model checking (BMC) is based on Bayesian sequential hypothesis testing, and aims to infer the posterior distribution of the probability that a system satisfies its requirements [3], [4].", "startOffset": 187, "endOffset": 190}, {"referenceID": 3, "context": "Bayesian model checking (BMC) is based on Bayesian sequential hypothesis testing, and aims to infer the posterior distribution of the probability that a system satisfies its requirements [3], [4].", "startOffset": 192, "endOffset": 195}, {"referenceID": 7, "context": "Requirements may be formally specified in a suitable probabilistic temporal logic [8], [9].", "startOffset": 82, "endOffset": 85}, {"referenceID": 8, "context": "Requirements may be formally specified in a suitable probabilistic temporal logic [8], [9].", "startOffset": 87, "endOffset": 90}, {"referenceID": 0, "context": "As the simulation captures probabilistic domain dynamics, the result of a simulation run is Bernoulli distributed with a probability p \u2208 [0, 1].", "startOffset": 137, "endOffset": 143}, {"referenceID": 3, "context": "For alternative termination criteria, we refer to [4].", "startOffset": 50, "endOffset": 53}, {"referenceID": 9, "context": "Recently, the satisfaction function was introduced as a concept to allow for efficient, regressive assessment of requirement satisfaction for parametrizable models with potentially infinitely many parameters [10].", "startOffset": 208, "endOffset": 212}, {"referenceID": 4, "context": "This is a widely adopted view, and a vast body of literature and techniques exists for estimating model uncertainty P (\u03b8|D) based on available domain observations D [5], [7].", "startOffset": 165, "endOffset": 168}, {"referenceID": 6, "context": "This is a widely adopted view, and a vast body of literature and techniques exists for estimating model uncertainty P (\u03b8|D) based on available domain observations D [5], [7].", "startOffset": 170, "endOffset": 173}, {"referenceID": 10, "context": "[11] for a very interesting read), or variational inference (e.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[12]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 1, "context": "BV is an instance of statistical model checking in general [2], and Bayesian statistical model checking in particular [3], [4].", "startOffset": 59, "endOffset": 62}, {"referenceID": 2, "context": "BV is an instance of statistical model checking in general [2], and Bayesian statistical model checking in particular [3], [4].", "startOffset": 118, "endOffset": 121}, {"referenceID": 3, "context": "BV is an instance of statistical model checking in general [2], and Bayesian statistical model checking in particular [3], [4].", "startOffset": 123, "endOffset": 126}, {"referenceID": 9, "context": "One of the starting points of the current article is the work on smoothed model checking [10].", "startOffset": 89, "endOffset": 93}, {"referenceID": 12, "context": "Parametrized Bayesian model checking for DBNs [13] does deal with quantified model uncertainty.", "startOffset": 46, "endOffset": 50}, {"referenceID": 13, "context": "A quite different approach to quantitative system assessment under model uncertainty is formal verification with confidence intervals (FACT) [14].", "startOffset": 141, "endOffset": 145}, {"referenceID": 3, "context": "[4]).", "startOffset": 0, "endOffset": 3}], "year": 2017, "abstractText": "Machine learning enables systems to build and update domain models based on runtime observations. In this paper, we study statistical model checking and runtime verification for systems with this ability. Two challenges arise: (1) Models built from limited runtime data yield uncertainty to be dealt with. (2) There is no definition of satisfaction w.r.t. uncertain hypotheses. We propose such a definition of subjective satisfaction based on recently introduced satisfaction functions. We also propose the BV algorithm as a Bayesian solution to runtime verification of subjective satisfaction under model uncertainty. BV provides user-definable stochastic bounds for type I and II errors. We discuss empirical results of a toy experiment.", "creator": "LaTeX with hyperref package"}}}