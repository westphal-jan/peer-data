{"id": "1703.00066", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Feb-2017", "title": "On the Power of Learning from $k$-Wise Queries", "abstract": "Several well-studied models of access to data samples, including statistical queries, local differential privacy and low-communication algorithms rely on queries that provide information about a function of a single sample. (For example, a statistical query (SQ) gives an estimate of $Ex_{x \\sim D}[q(x)]$ for any choice of the query function $q$ mapping $X$ to the reals, where $D$ is an unknown data distribution over $X$.) Yet some data analysis algorithms rely on properties of functions that depend on multiple samples. Such algorithms would be naturally implemented using $k$-wise queries each of which is specified by a function $q$ mapping $X^k$ to the reals. Hence it is natural to ask whether algorithms using $k$-wise queries can solve learning problems more efficiently and by how much.", "histories": [["v1", "Tue, 28 Feb 2017 21:41:09 GMT  (35kb)", "http://arxiv.org/abs/1703.00066v1", "32 pages, Appeared in Innovations in Theoretical Computer Science (ITCS) 2017"]], "COMMENTS": "32 pages, Appeared in Innovations in Theoretical Computer Science (ITCS) 2017", "reviews": [], "SUBJECTS": "cs.LG cs.DS", "authors": ["vitaly feldman", "badih ghazi"], "accepted": false, "id": "1703.00066"}, "pdf": {"name": "1703.00066.pdf", "metadata": {"source": "CRF", "title": "On the Power of Learning from k-Wise Queries", "authors": ["Vitaly Feldman"], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 170 3.00 066v 1 [cs.L G] 28 FeBlum, Kalai, Wasserman [BKW03] showed that for each weak PAC learning problem over a fixed distribution, the complexity of learning with k-wise SQs is less than the (simple) SQ complexity by a factor of no more than 2k. We show that for more general problems over distributions, the picture is much richer. For each k, the complexity of distribution-independent PAC learning with k-wise queries can be exponentially greater than learning with (k + 1) -wise queries. We then give two approaches to simulating a k-wise query with simple queries. The first approach takes advantage of the structure of the problem to be solved. It generalizes and strengthens (exponentially) the results of Blum et al. [BKW03]. It allows us to maintain strong lower limits for learning DNF formulas well as stoic constraints, the work with the second algorithm query."}, {"heading": "1 Introduction 3", "text": "1.1...................................................................................................................."}, {"heading": "2 Preliminaries 6", "text": "3 Separation (k + 1) -wise from k-wise questions 7 3.1 Limit.................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."}, {"heading": "4 Reduction for flat distributions 16", "text": "4.1 Decision problems................................................... 16 4.2 General problems................................. 18. 4.3 Applications for solving CSPs and learning DNF............"}, {"heading": "5 Reduction for low-communication queries 22", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6 Corollaries for other models 24", "text": ""}, {"heading": "A Omitted proofs 28", "text": "A.1 Evidence of dilemma 3.6........................................................................................................................"}, {"heading": "1 Introduction", "text": "In this thesis, we look at several well-studied models of learning i.i.d. samples that limit the algorithm's access to samples of functions of a single sample. The primary model of interest is the statistical query model introduced by Kearns [Kea98] as a limitation of the PAC learning model of Valiant [Val84].The SQ model allows the learning algorithm to access the data only through statistical queries that are estimates of the expectation of any function of the described examples of input distribution. Specifically, if the domain of the functions is Z, then a statistical query is specified by a function that accesses the data: Z \u00d7 {\u00b1 1} \u2192 and by a tolerance parameter. Given that the statistical query oracle has a value of v \u2212 E (z, b)."}, {"heading": "1.1 Previous work", "text": "Blum, Kalai and Wasserman [BKW03] introduced and studied the power of k-wise SQs in the context of weak distribution-specific PAC learning: that is, the learning algorithm observes pairs (z, b), whereby z is randomly selected from any fixed and known distribution P over Z and b = f (z) for any unknown function f from a class of functions C. They showed that if a class of functions C with error 1 / 2 \u2212 \u03bb relative to the distribution P can be learned using q k-wise tolerance \u03c4 SQs, it can be learned with error max {1 / 2 \u2212 \u03bb, 1 / 2 \u2212 \u03c4 / 2k} using O (q \u00b7 2k) of uniform tolerance \u03c4 / 2k. More recently, Steinhardt et al. [SVW16] considered k-wise queries in the b-bit sampling model, in which for each query function either Xk \u2192 {0, 1} an algorithm of tolerance \u03c4 / 2k is determined, or an algorithm of their work (xthin)."}, {"heading": "1.2 Our results", "text": "In this thesis, we examine the relationship between the power of k-wise queries and the simple queries of the complex distribution of K-Q functions. (We argue that the input factors are determined by some unknown input distribution, which solves a (known) family of distributions D over domain X-1. We say that the k-wise SQ complexity of a given problem is problematic if there is the smallest such problem that there is an algorithm that solves the problem by means of m-wise SQs of tolerance 1 / m.Theorem 1.1. (Informal) For each positive integer number p, there is a concept class C of Boolean functions defined over a domain of size pk + 1, so that the (k + 1) - smart SQ complexity of distribution-independent PAC learning C with Ok (log p)."}, {"heading": "2 Preliminaries", "text": "For each distribution D over a domain X and each positive integer k, we designate the distribution over Xk, which we have received to define the distribution of D over a domain of X and a function of D over a domain of X. (D) D (D) D (D) D (S) D (S) D (S) S (S) D (S) D (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S) S (S) S (S) S (S) S S S (S) S S S (S) S S S (S) S S S (S) S S (S) S S (S) S (S) S S (S) S (S) S (S) S (S) S S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S (S) S (S) S (S (S) S (S) S (S (S) S (S) S (S (S) S (S) S (S (S) S (S) S (S) S (S (S) S (S (S) S (S (S) S) S (S (S) S (S) S (S (S) S (S (S) S (S) S (S (S) S (S) S (S) S) S (S) S (S) S (S) S (S (S) S) S (S (S) S (S (S) S (S (S) S) S (S (S) S) S (S (S) S) S (S (S) S (S (S) S (S) S (S) S) S (S (S (S) S (S) S) S (S ("}, {"heading": "3.1 Upper bound", "text": "(1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1. (1). (1). (1). (1). (1). (1. (1). (1). (1). (1. (1). (1). (1). (1. (1). (1). (1). (1). (1. (1). (1). (1.). (1.). (1.). (1.). (1.). (1.). (1.).). (1.). (1.). (1.). (1.). (1.).). (1.). (1.).). (1.).). (1. (1.).). (1.). (1.).). (1.).). (1.).). (1.).). (1.).). (1.).). (1.).).). (1.).). (1.). (1.).).). (1.). (1.).). (1.). (1.).). (1.).).)."}, {"heading": "3.2 Lower bound", "text": "Our proof for the lower limit is a generalization of the lower limit in [Fel16b] (for = 2 and k = 1), based on the notion of a combined randomized statistical dimension (\"combined\" refers to the fact that it examines a single parameter that falls short of both the number of queries and the inverse of tolerance.) To apply this approach, we must extend it to k-wise queries. This extension follows directly from a simple observation. Let's define the domain as X \u2032. = Xk and the input distribution as D \u2032. = Dk then makes a k-wise query: Xk \u2192 [\u2212 1, 1] to STAT (k) D (\u0442) is equivalent to asking for a simple query: X \u2032 \u2192 [\u2212 1, 1] to STAT (k) D. With this observation, we define the k-wise versions of the terms from [Fel16b] and specify their properties required for the detection of 3.2."}, {"heading": "3.2.1 Preliminaries", "text": "Combined randomized statistical dimension is based on the following term of average discrimination. Definition k (k-wise average \u03ba1 discrimination). Let k be any positive integer. Let's measure probability over distributions over X and D0 be a reference distribution over X. Then we call the problem of PAC learning a concept class C of Boolean functions up to errors. Let's Z the domain of Boolean functions in C. For each distribution D0 over highlighted examples (i.e., over Z \u00d7 1}) we define the error rate of Boolean functions up to errors. (D0) Let Z the domain of Boolean functions in C. For each distribution D0 over highlighted examples (i.e.) we define the Bayes error rate from D0 to beerr (D0) = e.g."}, {"heading": "3.2.2 Proof of Lemma 3.2", "text": "Denote X: p \u00b7 {\u00b1 1}. Let us D: the quantity of all distributions over Xk, which can be calculated by sampling from any distribution over (F \u00b7 p) k and labelling of k samples according to any hyperplane indicator. Let D0: \u00b7 Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo (Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b: Hypo \u00b7 b"}, {"heading": "4 Reduction for flat distributions", "text": "To prove theorem 1.3, we use the characterization of the SQ complexity of the problem of estimating Dk [\u03c6] for D-D using a term of the statistical dimension of [Fel16b]. Specifically, we use the characterization of the complexity of solving this problem using simple SQs and also the generalization of this characterization, which characterizes the complexity of solving a problem using k-wise SQs. The latter is equal to 1 (since a single k-wise SQ is sufficient to estimate Dk [\u03c6]). Therefore, the k-wise statistical dimension is equal to 1. We then delimit the non-ary statistical dimension by the k-wise statistical dimension. The characterization then implies that an upper limit on the simple statistical dimension yields an upper limit for the SQ complexity."}, {"heading": "4.1 Decision problems", "text": "The k-wise generalization of the statistical dimension for decision problems of [Fel16b] is defined as the following problem. Definition 4.2. Let k be any positive integer. Consider a series of distributions D \u2212 \u2212 \u2212 and a reference distribution D0 over X. Let \u00b5 be a probability measurement over D and let \u03c4 > 0. The k-wise maximum recorded integer is defined as: 1 \u2212 frac (k-wise randomized statistical dimension of decision problems). Let k be any positive integer over D and let us leave any probability over Dk. [Dk [p] \u2212 Definition 4.3 (k-wise randomized statistical dimension of decision problems). Let k be any positive integer. For each series of distributions D, a reference distribution D0 over X and a reference distribution > 0, let us define the RSD (k)."}, {"heading": "4.2 General problems", "text": "We define the general class of problems via sets of distributions and an idea of the statistical dimension about these types of distribution problems. (Definition) We define the general class of problems via sets of distributions and a set of solutions. (Definition) We define the general class of problems via distribution problems. (Definition) We define the general class of problems via distribution problems and a set of solutions for D. For a solution f, which we characterize by Zf the set of all distributions for which f is a valid solution. (Definition) We define the statistical dimension for search problems. (Definition 4.9) We define the statistical dimension for search problems. (Field16b) For a solution f, a domain X and a search problem Z over a class of distributions D over X and a set of solutions F. (Definition 4.9) We define the wise statistical dimension over distribution problems."}, {"heading": "4.3 Applications to solving CSPs and learning DNF", "text": "We give some examples of how to use our reduction to get lower limits against k-wise SQ algorithms (instead), our applications for stochastic constraints satisfaction problems (CSPs) and DNF learning. We start with defining a stochastic CSP with a planted solution that is a pseudo-random generator based on Gold Kingdom's proposed disposable function [Gol00]. Definition 4.15. Let's apply a sample from this distribution that can be a fixed predicate. We get access to samples from a distribution that corresponds to a (\"planted\") mapping. A sample from this distribution is a uniform t-random (i1)."}, {"heading": "5 Reduction for low-communication queries", "text": "In this section, we will prove Theorem 1.5 using a current result from Steinhardt, Valiant and Wager [SVW16], whose result can be seen as specifying an SQ algorithm that simulates a communication protocol between n parties. Each party holds an example i.i.d. drawn from the distribution D and sends at most b bits via its sample (to all other parties), the bits can be sent over several rounds. Essentially, this is the standard model of multi-party communication complexity (e.g. [KN97]), but with the aim of solving a problem about the unknown distribution D, rather than calculating a specific function of the input. Alternatively, this model can also be considered as a single algorithm that extracts information from D for most b-bits and allows to extract the bits in any order (the b-bit sampling model we will discuss in Section 6.2 and in the b-bit at once)."}, {"heading": "6 Corollaries for other models", "text": "It is a. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \".\" S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S \"S.\" S. \"S.\" S. \"S\" S. \"S\" S. \"S\" S. \"S\" S \"S.\" S. \"S\" S. \"S\" S. \"S\" S \"S.\" S \"S.\" S \"S.\" S \"S\" S. \"S\" S. \"S\" S. \"S\" S. \"S\" S \"S.\" S \"S.\" S \"S\" S. \"S\" S \"S\" S. \"S\" S. \"S\" S. \"S\" S. \"S\" S. \"S\" S \"S.\" S. \"S.\" S \"S\" S \"S.\" S \"S.\" S \"S\" S \"S\" S. \"S.\" S. \"S\" S \"S\" S \""}, {"heading": "A Omitted proofs", "text": "The proof of Lemma 3.6In the following, we denote oc (\u00b7) and \u03c9c (\u00b7) asymptotic functions obtained by taking the limit as parameter c goes into infinity. In particular, oc (1) can be made arbitrarily close to 0 by making c large. Let W be as in the statement of Lemma 3.6. To prove the problem, it is sufficient to show that each bit j in the binary representation of subspace W constructed by Algorithm 2 is equal to the corresponding bit of W. Let us consider the two cases in which bit j of W is equal to 1, and where it is equal to 0.1, let us assume that bit j of W is equal to 1, and prove that it will be the case in the execution of Algorithm 2 that ui, j / vi 1 \u2212 oc (1)."}], "references": [{"title": "General bounds on statistical query learning and pac learning with noise via hypothesis boosting", "author": ["Javed A Aslam", "Scott E Decatur"], "venue": "In Foundations of Computer Science,", "citeRegEx": "Aslam and Decatur.,? \\Q1993\\E", "shortCiteRegEx": "Aslam and Decatur.", "year": 1993}, {"title": "Distributed learning, communication complexity and privacy", "author": ["Maria-Florina Balcan", "Avrim Blum", "Shai Fine", "Yishay Mansour"], "venue": "In COLT 2012 - The 25th Annual Conference on Learning Theory, June 25-27,", "citeRegEx": "Balcan et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Balcan et al\\.", "year": 2012}, {"title": "Learning with restricted focus of attention", "author": ["Shai Ben-David", "Eli Dichterman"], "venue": "J. Comput. Syst. Sci.,", "citeRegEx": "Ben.David and Dichterman.,? \\Q1998\\E", "shortCiteRegEx": "Ben.David and Dichterman.", "year": 1998}, {"title": "Practical privacy: the sulq framework", "author": ["Avrim Blum", "Cynthia Dwork", "Frank McSherry", "Kobbi Nissim"], "venue": "In Proceedings of the Twenty-fourth ACM SIGACTSIGMOD-SIGART Symposium on Principles of Database Systems, June 13-15,", "citeRegEx": "Blum et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Blum et al\\.", "year": 2005}, {"title": "Statistical active learning algorithms for noise tolerance and differential privacy", "author": ["Maria-Florina Balcan", "Vitaly Feldman"], "venue": null, "citeRegEx": "Balcan and Feldman.,? \\Q2015\\E", "shortCiteRegEx": "Balcan and Feldman.", "year": 2015}, {"title": "Weakly learning DNF and characterizing statistical query learning using Fourier analysis", "author": ["A. Blum", "M. Furst", "J. Jackson", "M. Kearns", "Y. Mansour", "S. Rudich"], "venue": "In Proceedings of STOC,", "citeRegEx": "Blum et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Blum et al\\.", "year": 1994}, {"title": "A polynomial-time algorithm for learning noisy linear threshold functions", "author": ["Avrim Blum", "Alan Frieze", "Ravi Kannan", "Santosh Vempala"], "venue": null, "citeRegEx": "Blum et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Blum et al\\.", "year": 1998}, {"title": "Learning by distances", "author": ["Shai Ben-David", "Alon Itai", "Eyal Kushilevitz"], "venue": "In Proceedings of the Third Annual Workshop on Computational Learning Theory, COLT 1990,", "citeRegEx": "Ben.David et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Ben.David et al\\.", "year": 1990}, {"title": "Noise-tolerant learning, the parity problem, and the statistical query model", "author": ["Avrim Blum", "Adam Kalai", "Hal Wasserman"], "venue": "Journal of the ACM (JACM),", "citeRegEx": "Blum et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Blum et al\\.", "year": 2003}, {"title": "Amplification of weak learning over the uniform distribution", "author": ["D. Boneh", "R. Lipton"], "venue": "In Proceedings of the Sixth Annual Workshop on Computational Learning Theory,", "citeRegEx": "Boneh and Lipton.,? \\Q1993\\E", "shortCiteRegEx": "Boneh and Lipton.", "year": 1993}, {"title": "Map-reduce for machine learning on multicore", "author": ["Cheng Chu", "Sang Kyun Kim", "Yi-An Lin", "YuanYuan Yu", "Gary Bradski", "Andrew Y Ng", "Kunle Olukotun"], "venue": "Advances in neural information processing systems,", "citeRegEx": "Chu et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Chu et al\\.", "year": 2007}, {"title": "Learning from satisfying assignments", "author": ["Anindya De", "Ilias Diakonikolas", "Rocco A Servedio"], "venue": "In Proceedings of the Twenty-Sixth Annual ACM-SIAM Symposium on Discrete Algorithms,", "citeRegEx": "De et al\\.,? \\Q2015\\E", "shortCiteRegEx": "De et al\\.", "year": 2015}, {"title": "Generalization in adaptive data analysis and holdout reuse", "author": ["Cynthia Dwork", "Vitaly Feldman", "Moritz Hardt", "Toni Pitassi", "Omer Reingold", "Aaron Roth"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Dwork et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Dwork et al\\.", "year": 2015}, {"title": "Preserving statistical validity in adaptive data analysis", "author": ["Cynthia Dwork", "Vitaly Feldman", "Moritz Hardt", "Toniann Pitassi", "Omer Reingold", "Aaron Leon Roth"], "venue": "In Proceedings of the Forty-Seventh Annual ACM on Symposium on Theory of Computing,", "citeRegEx": "Dwork et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Dwork et al\\.", "year": 2015}, {"title": "Statistical query lower bounds for robust estimation of high-dimensional gaussians and gaussian mixtures", "author": ["Ilias Diakonikolas", "Daniel M. Kane", "Alistair Stewart"], "venue": "CoRR, abs/1611.03473,", "citeRegEx": "Diakonikolas et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Diakonikolas et al\\.", "year": 2016}, {"title": "Calibrating noise to sensitivity in private data analysis", "author": ["Cynthia Dwork", "Frank McSherry", "Kobbi Nissim", "Adam D. Smith"], "venue": "In Theory of Cryptography, Third Theory of Cryptography Conference,", "citeRegEx": "Dwork et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Dwork et al\\.", "year": 2006}, {"title": "Revealing information while preserving privacy", "author": ["Irit Dinur", "Kobbi Nissim"], "venue": "In Proceedings of the Twenty-Second ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, June 9-12,", "citeRegEx": "Dinur and Nissim.,? \\Q2003\\E", "shortCiteRegEx": "Dinur and Nissim.", "year": 2003}, {"title": "Complexity theoretic limitations on learning dnf\u2019s", "author": ["Amit Daniely", "Shai Shalev-Shwartz"], "venue": "In COLT,", "citeRegEx": "Daniely and Shalev.Shwartz.,? \\Q2016\\E", "shortCiteRegEx": "Daniely and Shalev.Shwartz.", "year": 2016}, {"title": "Approximate resilience, monotonicity, and the complexity of agnostic learning", "author": ["Dana Dachman-Soled", "Vitaly Feldman", "Li-Yang Tan", "Andrew Wan", "Karl Wimmer"], "venue": "In Proceedings of SODA,", "citeRegEx": "Dachman.Soled et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Dachman.Soled et al\\.", "year": 2015}, {"title": "A simple polynomial-time rescaling algorithm for solving linear programs", "author": ["John Dunagan", "Santosh Vempala"], "venue": "In Proceedings of the 36th Annual ACM Symposium on Theory of Computing,", "citeRegEx": "Dunagan and Vempala.,? \\Q2004\\E", "shortCiteRegEx": "Dunagan and Vempala.", "year": 2004}, {"title": "RAPPOR: randomized aggregatable privacy-preserving ordinal response", "author": ["\u00dalfar Erlingsson", "Vasyl Pihur", "Aleksandra Korolova"], "venue": "In ACM SIGSAC Conference on Computer and Communications Security,", "citeRegEx": "Erlingsson et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Erlingsson et al\\.", "year": 2014}, {"title": "Evolvability from learning algorithms", "author": ["Vitaly Feldman"], "venue": "In Proceedings of the fortieth annual ACM symposium on Theory of computing,", "citeRegEx": "Feldman.,? \\Q2008\\E", "shortCiteRegEx": "Feldman.", "year": 2008}, {"title": "Dealing with range anxiety in mean estimation via statistical queries", "author": ["Vitaly Feldman"], "venue": "arXiv, abs/1611.06475,", "citeRegEx": "Feldman.,? \\Q2016\\E", "shortCiteRegEx": "Feldman.", "year": 2016}, {"title": "A general characterization of the statistical query complexity", "author": ["Vitaly Feldman"], "venue": "CoRR, abs/1608.02198,", "citeRegEx": "Feldman.,? \\Q2016\\E", "shortCiteRegEx": "Feldman.", "year": 2016}, {"title": "Statistical algorithms and a lower bound for detecting planted cliques", "author": ["Vitaly Feldman", "Elena Grigorescu", "Lev Reyzin", "Santosh Vempala", "Ying Xiao"], "venue": "arXiv, CoRR,", "citeRegEx": "Feldman et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Feldman et al\\.", "year": 2012}, {"title": "Statistical query algorithms for mean vector estimation and stochastic convex optimization", "author": ["Vitaly Feldman", "Cristobal Guzman", "Santosh Vempala"], "venue": "CoRR, abs/1512.09170,", "citeRegEx": "Feldman et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Feldman et al\\.", "year": 2015}, {"title": "Lower bounds and hardness amplification for learning shallow monotone formulas", "author": ["V. Feldman", "H. Lee", "R. Servedio"], "venue": "In COLT,", "citeRegEx": "Feldman et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Feldman et al\\.", "year": 2011}, {"title": "On the complexity of random satisfiability problems with planted solutions", "author": ["Vitaly Feldman", "Will Perkins", "Santosh Vempala"], "venue": "CoRR, abs/1311.4821,", "citeRegEx": "Feldman et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Feldman et al\\.", "year": 2013}, {"title": "Candidate one-way functions based on expander graphs", "author": ["Oded Goldreich"], "venue": "IACR Cryptology ePrint Archive,", "citeRegEx": "Goldreich.,? \\Q2000\\E", "shortCiteRegEx": "Goldreich.", "year": 2000}, {"title": "Efficient noise-tolerant learning from statistical queries", "author": ["Michael Kearns"], "venue": "Journal of the ACM (JACM),", "citeRegEx": "Kearns.,? \\Q1998\\E", "shortCiteRegEx": "Kearns.", "year": 1998}, {"title": "What can we learn privately", "author": ["Shiva Prasad Kasiviswanathan", "Homin K Lee", "Kobbi Nissim", "Sofya Raskhodnikova", "Adam Smith"], "venue": "SIAM Journal on Computing,", "citeRegEx": "Kasiviswanathan et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Kasiviswanathan et al\\.", "year": 2011}, {"title": "Communication complexity", "author": ["Eyal Kushilevitz", "Noam Nisan"], "venue": null, "citeRegEx": "Kushilevitz and Nisan.,? \\Q1997\\E", "shortCiteRegEx": "Kushilevitz and Nisan.", "year": 1997}, {"title": "Multiple source adaptation and the r\u00e9nyi divergence", "author": ["Yishay Mansour", "Mehryar Mohri", "Afshin Rostamizadeh"], "venue": "In UAI,", "citeRegEx": "Mansour et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Mansour et al\\.", "year": 2009}, {"title": "Interactive privacy via the median mechanism", "author": ["Aaron Roth", "Tim Roughgarden"], "venue": "In Proceedings of the forty-second ACM symposium on Theory of computing,", "citeRegEx": "Roth and Roughgarden.,? \\Q2010\\E", "shortCiteRegEx": "Roth and Roughgarden.", "year": 2010}, {"title": "Airavat: Security and privacy for mapreduce", "author": ["Indrajit Roy", "Srinath TV Setty", "Ann Kilzer", "Vitaly Shmatikov", "Emmett Witchel"], "venue": "In NSDI,", "citeRegEx": "Roy et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Roy et al\\.", "year": 2010}, {"title": "Minimax rates for memory-bounded sparse linear regression", "author": ["Jacob Steinhardt", "John C. Duchi"], "venue": "In COLT,", "citeRegEx": "Steinhardt and Duchi.,? \\Q2015\\E", "shortCiteRegEx": "Steinhardt and Duchi.", "year": 2015}, {"title": "Optiml: an implicitly parallel domain-specific language for machine learning", "author": ["Arvind Sujeeth", "HyoukJoong Lee", "Kevin Brown", "Tiark Rompf", "Hassan Chafi", "Michael Wu", "Anand Atreya", "Martin Odersky", "Kunle Olukotun"], "venue": "In Proceedings of the 28th International Conference on Machine Learning", "citeRegEx": "Sujeeth et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Sujeeth et al\\.", "year": 2011}, {"title": "Memory, communication, and statistical queries", "author": ["J. Steinhardt", "G. Valiant", "S. Wager"], "venue": "In COLT,", "citeRegEx": "Steinhardt et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Steinhardt et al\\.", "year": 2016}, {"title": "A theory of the learnable", "author": ["Leslie G Valiant"], "venue": "Communications of the ACM,", "citeRegEx": "Valiant.,? \\Q1984\\E", "shortCiteRegEx": "Valiant.", "year": 1984}, {"title": "All of statistics: a concise course in statistical inference", "author": ["Larry Wasserman"], "venue": "Springer Science & Business Media,", "citeRegEx": "Wasserman.,? \\Q2013\\E", "shortCiteRegEx": "Wasserman.", "year": 2013}, {"title": "Probabilistic computations: Toward a unified measure of complexity", "author": ["Andrew Yao"], "venue": "In FOCS,", "citeRegEx": "Yao.,? \\Q1977\\E", "shortCiteRegEx": "Yao.", "year": 1977}, {"title": "Information-theoretic lower bounds for distributed statistical estimation with communication constraints", "author": ["Yuchen Zhang", "John C. Duchi", "Michael I. Jordan", "Martin J. Wainwright"], "venue": "In Proceedings of NIPS,", "citeRegEx": "Zhang et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2013}], "referenceMentions": [], "year": 2017, "abstractText": "Several well-studied models of access to data samples, including statistical queries, local differential privacy and low-communication algorithms rely on queries that provide information about a function of a single sample. (For example, a statistical query (SQ) gives an estimate of Ex\u223cD[q(x)] for any choice of the query function q : X \u2192 R, where D is an unknown data distribution.) Yet some data analysis algorithms rely on properties of functions that depend on multiple samples. Such algorithms would be naturally implemented using k-wise queries each of which is specified by a function q : X \u2192 R. Hence it is natural to ask whether algorithms using k-wise queries can solve learning problems more efficiently and by how much. Blum, Kalai, Wasserman [BKW03] showed that for any weak PAC learning problem over a fixed distribution, the complexity of learning with k-wise SQs is smaller than the (unary) SQ complexity by a factor of at most 2. We show that for more general problems over distributions the picture is substantially richer. For every k, the complexity of distribution-independent PAC learning with k-wise queries can be exponentially larger than learning with (k + 1)-wise queries. We then give two approaches for simulating a k-wise query using unary queries. The first approach exploits the structure of the problem that needs to be solved. It generalizes and strengthens (exponentially) the results of Blum et al. [BKW03]. It allows us to derive strong lower bounds for learning DNF formulas and stochastic constraint satisfaction problems that hold against algorithms using k-wise queries. The second approach exploits the k-party communication complexity of the k-wise query function. \u2217Work done while at IBM Research Almaden.", "creator": "LaTeX with hyperref package"}}}