{"id": "1703.00247", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Mar-2017", "title": "Learning A Physical Long-term Predictor", "abstract": "Evolution has resulted in highly developed abilities in many natural intelligences to quickly and accurately predict mechanical phenomena. Humans have successfully developed laws of physics to abstract and model such mechanical phenomena. In the context of artificial intelligence, a recent line of work has focused on estimating physical parameters based on sensory data and use them in physical simulators to make long-term predictions. In contrast, we investigate the effectiveness of a single neural network for end-to-end long-term prediction of mechanical phenomena. Based on extensive evaluation, we demonstrate that such networks can outperform alternate approaches having even access to ground-truth physical simulators, especially when some physical parameters are unobserved or not known a-priori. Further, our network outputs a distribution of outcomes to capture the inherent uncertainty in the data. Our approach demonstrates for the first time the possibility of making actionable long-term predictions from sensor data without requiring to explicitly model the underlying physical laws.", "histories": [["v1", "Wed, 1 Mar 2017 11:44:18 GMT  (5705kb,D)", "http://arxiv.org/abs/1703.00247v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.NE", "authors": ["sebastien ehrhardt", "aron monszpart", "niloy j mitra", "andrea vedaldi"], "accepted": false, "id": "1703.00247"}, "pdf": {"name": "1703.00247.pdf", "metadata": {"source": "META", "title": "Learning A Physical Long-term Predictor", "authors": ["Sebastien Ehrhardt", "Aron Monszpart", "Niloy J. Mitra", "Andrea Vedaldi"], "emails": ["<hyenal@robots.ox.ac.uk>,", "<a.monszpart@cs.ucl.ac.uk>,", "<n.mitra@cs.ucl.ac.uk>,", "<vedaldi@robots.ox.ac.uk>."], "sections": [{"heading": "1. Introduction", "text": "This year, it is so far that it is only a matter of time before it is ready, until it is ready."}, {"heading": "2. Related Work", "text": "In this context, it is also worth mentioning the fact that the two of them are involved in a very complex and complex history, in which it is a question of answering a series of questions (for example, whether it is a story that is a story, a story, a story, a story, a story, a story, a story, a story, a story, a story, a history, a story, a story, a story, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history, a history."}, {"heading": "3. Mechanics Networks", "text": "In this section, we present a series of neural network models that can predict the behavior of a simple mechanical system. We begin by describing the physical structure and then present the proposed network architectures."}, {"heading": "3.1. Physical setup", "text": "The physical configuration (Fig. 1) consists of a small object sliding down an inclined plane = \u03b2 q = 64. For notational simplicity, we identify the 3D Euclidean space with the underlying vector space R3 and designate it as p = (px, py, pz).The plane, which for the sake of simplicity passes the origin, has an equation \u03c0 = {p \u00b2 R3: < n, p > = 0}, where n is the plane unit of normal vector. In addition to the normal n, the detection of inclination, the plane also has a coulomb friction coefficient, which is homogeneous in the simple case, but can also be a spatially varying magnitude: \u03c0 \u2192 R +. We set the camera so that it is centered above the plane, at height h > 0."}, {"heading": "3.2. Neural network architectures", "text": "We focus on long-term predictors: XT0 7 \u2192 YT, which input the first T0 = 4 framesXT0 of a video sequenceXT and produce as output a long-term estimate YT of the location of the object center of mass in times t = 0, 1,., T, where T T0.Our method comprises three building blocks (Fig. 2): a feature, a dispersion network and an estimation network. The core of our model is the internal representation of physics initialized by the feature extractor, updated by the dispersion module, and decoded by the estimation module. We compare two types of representation: a vector representation in which each frame is encoded as a C-dimensional vector (or 1 \u00d7 C tensor), and a H \u00b7 W \u00b7 C tensor representation."}, {"heading": "4. Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1. Data generation", "text": "Experiments consider three variants of the physical setup described in Section 3.1, called Scenarios S0, S1 and S2. Various scenarios example experiments \u03b1 = (q0x, q 0 y, n, \u03c1) of increasing difficulty. The parameters of each scenario are summarized in Table 1 and described next. Normal plane n was obtained by rotating the Z axis around the X and Y axis randomly. Scenario S0 uses a fixed inclination. Scenarios S1 and S2, the Coulomb friction coefficient of the plane is homogeneous and samples uniformly."}, {"heading": "4.2. Baseline predictors", "text": "In both cases, we match two polynomials with the smallest squares to the estimated screen space coordinates of the first T = 10 frames. The polynomials are of first or second degree, respectively. We estimate the position of the object in this case by using the maximum position of the red channel of the input image. Note that the ability to observe the first 10 frames is a great advantage over the networks that only see the first T0 = 4 frames. Physics SimNet Simulator. The SimNet baseline is used to evaluate the long-term predictiveness of a neural network that has access to an explicit physical simulator, analogous to the work of (Wu et al., 2015). Similar to the other networks, SimNet observes the first T0 images and aims to scale back the physical parameters necessary to predict the traction of the object."}, {"heading": "4.3. MechaNets", "text": "Experiments look at four different variants of mechanical prediction networks (MechaNet1 to 4 for short): MechaNet1 and MechaNet2 are designed to optimize the L. MechaNet1 uses the LSTM dispersion network and spatially concentrated internal representation, while MechaNet2 uses the simpler Constitutional dispersion network but distributed representation. MechaNet3 and MechaNet4 are similar to MechaNet2, but use probability predictions using the Gauss- or probability maps. The four variants are summarized in Table 2.Implementation Details. Network weights are initialized by random samples from a Gaussian distribution. The training uses a stack size of 50 using the first 10 to 40 images of each video sequence using RMSProp (Tieleman & Hinton, 2012). Training is stopped if there is no improvement in L2 loss after 40 consecutive epochs."}, {"heading": "4.4. Results", "text": "This year, it has reached the point where it will be able to put itself at the top of the group, which is able to put itself at the top of the group."}, {"heading": "5. Conclusions", "text": "In this paper, we have explored the possibility of using a single neural network for long-term prediction of mechanical phenomena. Unlike many other approaches, we do not use the network to predict some physical quantities to be integrated by a simulator, but to directly predict the complete orbit of the object end-to-end. Our results, obtained from an extensive synthetic simulation, suggest that deep neural networks can successfully predict long-term trajectories without requiring explicit modeling of the underlying physics. They can also reliably estimate distribution over such predictions to account for the uncertainty in the data. Remarkably, these models compete with alternative predictors that have access to the physical simulator on the ground, and exceed them when some of the physical parameters are not observable or a priori known."}], "references": [{"title": "TensorFlow: Large-scale machine learning on heterogeneous systems", "author": ["Abadi"], "venue": null, "citeRegEx": "Abadi,? \\Q2015\\E", "shortCiteRegEx": "Abadi", "year": 2015}, {"title": "Learning to Poke by Poking: Experiential Learning of Intuitive Physics", "author": ["Agrawal", "Pulkit", "Nair", "Ashvin V", "Abbeel", "Pieter", "Malik", "Jitendra", "Levine", "Sergey"], "venue": "In Proc. NIPS,", "citeRegEx": "Agrawal et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Agrawal et al\\.", "year": 2016}, {"title": "Interaction networks for learning about objects, relations and physics", "author": ["Battaglia", "Peter", "Pascanu", "Razvan", "Lai", "Matthew", "Rezende", "Danilo Jimenez"], "venue": "In Proc. NIPS,", "citeRegEx": "Battaglia et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Battaglia et al\\.", "year": 2016}, {"title": "Simulation as an engine of physical scene understanding", "author": ["Battaglia", "Peter W", "Hamrick", "Jessica B", "Tenenbaum", "Joshua B"], "venue": "PNAS, 110(45):18327\u201318332,", "citeRegEx": "Battaglia et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Battaglia et al\\.", "year": 2013}, {"title": "A compositional object-based approach to learning physical dynamics", "author": ["Chang", "Michael B", "Ullman", "Tomer", "Torralba", "Antonio", "Tenenbaum", "Joshua B"], "venue": "arXiv preprint arXiv:1612.00341,", "citeRegEx": "Chang et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Chang et al\\.", "year": 2016}, {"title": "Learning phrase representations using RNN encoder\u2013decoder for statistical machine translation", "author": ["Cho", "Kyunghyun", "van Merri\u00ebnboer", "Bart", "G\u00fcl\u00e7ehre", "\u00c7alar", "Bahdanau", "Dzmitry", "Bougares", "Fethi", "Schwenk", "Holger", "Bengio", "Yoshua"], "venue": "In Proc. EMNLP,", "citeRegEx": "Cho et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Cho et al\\.", "year": 2014}, {"title": "Dynamic filter networks", "author": ["De Brabandere", "Bert", "Jia", "Xu", "Tuytelaars", "Tinne", "Van Gool", "Luc"], "venue": "In Proc. NIPS,", "citeRegEx": "Brabandere et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Brabandere et al\\.", "year": 2016}, {"title": "Learning to perform physics experiments via deep reinforcement learning", "author": ["Denil", "Misha", "Agrawal", "Pulkit", "Kulkarni", "Tejas D", "Erez", "Tom", "Battaglia", "Peter", "de Freitas", "Nando"], "venue": "Deep Reinforcement Learning Workshop,", "citeRegEx": "Denil et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Denil et al\\.", "year": 2016}, {"title": "Learning visual predictive models of physics for playing billiards", "author": ["Fragkiadaki", "Katerina", "Agrawal", "Pulkit", "Levine", "Sergey", "Malik", "Jitendra"], "venue": "arXiv preprint arXiv:1511.07404,", "citeRegEx": "Fragkiadaki et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Fragkiadaki et al\\.", "year": 2015}, {"title": "Inferring mass in complex scenes by mental", "author": ["J.B. Hamrick", "P.W. Battaglia", "T.L. Griffiths", "J.B. Tenenbaum"], "venue": "simulation. Cognition,", "citeRegEx": "Hamrick et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Hamrick et al\\.", "year": 2016}, {"title": "Deep residual learning for image recognition", "author": ["He", "Kaiming", "Zhang", "Xiangyu", "Ren", "Shaoqing", "Sun", "Jian"], "venue": "In IEEE CVPR,", "citeRegEx": "He et al\\.,? \\Q2016\\E", "shortCiteRegEx": "He et al\\.", "year": 2016}, {"title": "Long shortterm memory", "author": ["Hochreiter", "Sepp", "Schmidhuber", "J\u00fcrgen"], "venue": "Neural Comput.,", "citeRegEx": "Hochreiter et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter et al\\.", "year": 1997}, {"title": "Data-driven fluid simulations using regression forests", "author": ["Jeong", "SoHyeon", "Solenthaler", "Barbara", "Pollefeys", "Marc", "Gross", "Markus"], "venue": "ACM Trans. on Graphics (TOG),", "citeRegEx": "Jeong et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Jeong et al\\.", "year": 2015}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["Krizhevsky", "Alex", "Sutskever", "Ilya", "Hinton", "Geoffrey E"], "venue": "In Proc. NIPS, pp", "citeRegEx": "Krizhevsky et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "Learning physical intuition of block towers by example", "author": ["Lerer", "Adam", "Gross", "Sam", "Fergus", "Rob"], "venue": "arXiv preprint arXiv:1603.01312,", "citeRegEx": "Lerer et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Lerer et al\\.", "year": 2016}, {"title": "Visual stability prediction and its application to manipulation", "author": ["Li", "Wenbin", "Leonardis", "Ale\u0161", "Fritz", "Mario"], "venue": "arXiv preprint arXiv:1609.04861,", "citeRegEx": "Li et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Li et al\\.", "year": 2016}, {"title": "Fully convolutional networks for semantic segmentation", "author": ["Long", "Jonathan", "Shelhamer", "Evan", "Darrell", "Trevor"], "venue": "In IEEE CVPR,", "citeRegEx": "Long et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Long et al\\.", "year": 2015}, {"title": "SMASH: Physics-guided Reconstruction of Collisions from Videos", "author": ["Monszpart", "Aron", "Thuerey", "Nils", "Mitra", "Niloy"], "venue": "ACM Trans. on Graphics (TOG),", "citeRegEx": "Monszpart et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Monszpart et al\\.", "year": 2016}, {"title": "Newtonian scene understanding: Unfolding the dynamics of objects in static images", "author": ["Mottaghi", "Roozbeh", "Bagherinezhad", "Hessam", "Rastegari", "Mohammad", "Farhadi", "Ali"], "venue": "In IEEE CVPR,", "citeRegEx": "Mottaghi et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Mottaghi et al\\.", "year": 2016}, {"title": "Deep tracking: Seeing beyond seeing using recurrent neural networks", "author": ["Ondruska", "Peter", "Posner", "Ingmar"], "venue": "In Proc. AAAI,", "citeRegEx": "Ondruska et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Ondruska et al\\.", "year": 2016}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["K. Simonyan", "A. Zisserman"], "venue": "In International Conference on Learning Representations,", "citeRegEx": "Simonyan and Zisserman,? \\Q2015\\E", "shortCiteRegEx": "Simonyan and Zisserman", "year": 2015}, {"title": "Label-free supervision of neural networks with physics and domain knowledge", "author": ["Stewart", "Russell", "Ermon", "Stefano"], "venue": null, "citeRegEx": "Stewart et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Stewart et al\\.", "year": 2016}, {"title": "Lecture 6.5\u2014RMSProp: Divide the gradient by a running average of its recent magnitude", "author": ["T. Tieleman", "G. Hinton"], "venue": "COURSERA: Neural Networks for Machine Learning,", "citeRegEx": "Tieleman and Hinton,? \\Q2012\\E", "shortCiteRegEx": "Tieleman and Hinton", "year": 2012}, {"title": "Accelerating Eulerian Fluid Simulation With Convolutional Networks", "author": ["J. Tompson", "K. Schlachter", "P. Sprechmann", "K. Perlin"], "venue": "ArXiv e-print", "citeRegEx": "Tompson et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Tompson et al\\.", "year": 2016}, {"title": "Galileo: Perceiving physical object properties by integrating a physics engine with deep learning", "author": ["Wu", "Jiajun", "Yildirim", "Ilker", "Lim", "Joseph J", "Freeman", "Bill", "Tenenbaum", "Josh"], "venue": "In Proc. NIPS, pp", "citeRegEx": "Wu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wu et al\\.", "year": 2015}, {"title": "Physics 101: Learning physical object properties from unlabeled videos", "author": ["Wu", "Jiajun", "Lim", "Joseph J", "Zhang", "Hongyi", "Tenenbaum", "Joshua B", "Freeman", "William T"], "venue": "In Proc. BMVC,", "citeRegEx": "Wu et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Wu et al\\.", "year": 2016}, {"title": "Visual dynamics: Probabilistic future frame synthesis via cross convolutional networks", "author": ["Xue", "Tianfan", "Wu", "Jiajun", "Bouman", "Katherine L", "Freeman", "William T"], "venue": "In Proc. NIPS,", "citeRegEx": "Xue et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Xue et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 9, "context": "However, the nature of these mental models remains unclear and is being actively investigated (Hamrick et al., 2016).", "startOffset": 94, "endOffset": 116}, {"referenceID": 25, "context": "Among such prior works, by far the most popular approach is to use neural networks (Wu et al., 2016) to extract from sensory data local predictions of physical parameters, such as mass, velocity, or acceleration, that are then integrated by an external mechanism such as a physical simulator to obtain long term predictions.", "startOffset": 83, "endOffset": 100}, {"referenceID": 2, "context": "Other attempts have also tried to replace the physical engine with a neural network (Battaglia et al., 2016) but did not really attempt to observe the physical world and deduce properties from it but rather to integrate the physical equations.", "startOffset": 84, "endOffset": 108}, {"referenceID": 3, "context": "To the best of our knowledge (Battaglia et al., 2013) was the first approach to tackle intuitive physics with the aim to answer a set of intuitive questions (e.", "startOffset": 29, "endOffset": 53}, {"referenceID": 18, "context": "More recently (Mottaghi et al., 2016) also used static images and a graphic rendering engine (Blender) to predict movements and directions of forces from a single RGB image.", "startOffset": 14, "endOffset": 37}, {"referenceID": 13, "context": ", (Krizhevsky et al., 2012; He et al., 2016)) they used a convolutional architecture to understand dynamics and forces acting behind Camera", "startOffset": 2, "endOffset": 44}, {"referenceID": 10, "context": ", (Krizhevsky et al., 2012; He et al., 2016)) they used a convolutional architecture to understand dynamics and forces acting behind Camera", "startOffset": 2, "endOffset": 44}, {"referenceID": 14, "context": "In a different framework (Lerer et al., 2016) and (Li et al.", "startOffset": 25, "endOffset": 45}, {"referenceID": 15, "context": ", 2016) and (Li et al., 2016) also used the power of deep learning to extract an abstract representation of the concept of stability of block towers purely from images.", "startOffset": 12, "endOffset": 29}, {"referenceID": 1, "context": "Other approaches such as (Agrawal et al., 2016) or (Denil et al.", "startOffset": 25, "endOffset": 47}, {"referenceID": 7, "context": ", 2016) or (Denil et al., 2016) also attempted to learn intuitive physics of objects through manipulation.", "startOffset": 11, "endOffset": 31}, {"referenceID": 26, "context": "The idea was further developed in (Xue et al., 2016) in order to generate a next possible image frame from a single static input image.", "startOffset": 34, "endOffset": 52}, {"referenceID": 26, "context": "In the future we also aim to experiment with approaches inspired by (Xue et al., 2016).", "startOffset": 68, "endOffset": 86}, {"referenceID": 24, "context": "Works of (Wu et al., 2015) and its extension (Wu et al.", "startOffset": 9, "endOffset": 26}, {"referenceID": 25, "context": ", 2015) and its extension (Wu et al., 2016) propose methods to learn physical properties of scenes and objects.", "startOffset": 26, "endOffset": 43}, {"referenceID": 24, "context": "However in (Wu et al., 2015) the MCMC sampling based approach assumes a complete knowledge of the physical equations to estimate the correct physical parameters.", "startOffset": 11, "endOffset": 28}, {"referenceID": 25, "context": "In (Wu et al., 2016) deep learning has been used more extensively to replace the MCMC based sampling but this work also employs an explicit encoding and computation of physical laws to regress the output of their tracker.", "startOffset": 3, "endOffset": 20}, {"referenceID": 8, "context": "In another related approach (Fragkiadaki et al., 2015) attempted to build an internal representation of the physical world.", "startOffset": 28, "endOffset": 54}, {"referenceID": 2, "context": "(Battaglia et al., 2016) and (Chang et al.", "startOffset": 0, "endOffset": 24}, {"referenceID": 4, "context": ", 2016) and (Chang et al., 2016) were able to produce accurate estimations of the next state of the world.", "startOffset": 12, "endOffset": 32}, {"referenceID": 23, "context": "Other approaches also focused on learning the production of realistic future scenarios ((Tompson et al., 2016) and (Jeong et al.", "startOffset": 88, "endOffset": 110}, {"referenceID": 12, "context": ", 2016) and (Jeong et al., 2015)), or inferring collision parameters from monocular videos (Monszpart et al.", "startOffset": 12, "endOffset": 32}, {"referenceID": 17, "context": ", 2015)), or inferring collision parameters from monocular videos (Monszpart et al., 2016).", "startOffset": 66, "endOffset": 90}, {"referenceID": 8, "context": "Similarly to (Fragkiadaki et al., 2015), the RGB channels of the images are concatenated in a single Hi \u00d7 Wi \u00d7 3T0 tensor and this is processed by a convolutional neural network \u03c6init, obtaining a \u03c6init(x0, .", "startOffset": 13, "endOffset": 39}, {"referenceID": 8, "context": "Inspired by (Fragkiadaki et al., 2015), we start from the VGG16 network pre-trained on ImageNet (Simonyan & Zisserman, 2015).", "startOffset": 12, "endOffset": 38}, {"referenceID": 5, "context": "This is similar in approach to (Cho et al., 2014), although our output is directly fed to the network without re-embedding.", "startOffset": 31, "endOffset": 49}, {"referenceID": 16, "context": "The layer L is linear and fully-connected layer for L and Lnrm, and a deconvolutional layer similar to (Long et al., 2015) in the", "startOffset": 103, "endOffset": 122}, {"referenceID": 24, "context": "The SimNet baseline is used to evaluate the long term prediction ability of a neural network that has access to an explicit physics simulator, in a manner analogous to the work of (Wu et al., 2015).", "startOffset": 180, "endOffset": 197}], "year": 2017, "abstractText": "Evolution has resulted in highly developed abilities in many natural intelligences to quickly and accurately predict mechanical phenomena. Humans have successfully developed laws of physics to abstract and model such mechanical phenomena. In the context of artificial intelligence, a recent line of work has focused on estimating physical parameters based on sensory data and use them in physical simulators to make long-term predictions. In contrast, we investigate the effectiveness of a single neural network for end-to-end long-term prediction of mechanical phenomena. Based on extensive evaluation, we demonstrate that such networks can outperform alternate approaches having even access to ground-truth physical simulators, especially when some physical parameters are unobserved or not known a-priori. Further, our network outputs a distribution of outcomes to capture the inherent uncertainty in the data. Our approach demonstrates for the first time the possibility of making actionable long-term predictions from sensor data without requiring to explicitly model the underlying physical laws.", "creator": "LaTeX with hyperref package"}}}