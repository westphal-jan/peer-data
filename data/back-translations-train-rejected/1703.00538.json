{"id": "1703.00538", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Mar-2017", "title": "Unsupervised Ensemble Ranking of Terms in Electronic Health Record Notes Based on Their Importance to Patients", "abstract": "Background: Electronic health record (EHR) notes contain abundant medical jargon that can be difficult for patients to comprehend. One way to help patients is to reduce information overload and help them focus on medical terms that matter most to them.", "histories": [["v1", "Wed, 1 Mar 2017 22:37:02 GMT  (1318kb)", "http://arxiv.org/abs/1703.00538v1", null], ["v2", "Sat, 25 Mar 2017 21:34:10 GMT  (1319kb)", "http://arxiv.org/abs/1703.00538v2", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["jinying chen", "hong yu"], "accepted": false, "id": "1703.00538"}, "pdf": {"name": "1703.00538.pdf", "metadata": {"source": "CRF", "title": "Unsupervised Ensemble Ranking of Terms in Electronic Health Record Notes Based on Their Importance to Patients", "authors": ["Jinying Chen", "Hong Yu"], "emails": [], "sections": [{"heading": null, "text": "Results: FIT achieved 0.885 AUC-ROC for ranking candidate terms from EHR notes to identify important terms. Including term identification, FIT's performance for identifying key terms from EHR notes was 0.813 AUC-ROC, both of which significantly exceeded the corresponding scores of the four individual applicants (P <.001). FIT also performed better than the three ensemble evaluators on most key indicators. Its performance is relatively insensitive to their parameters. Conclusions: FIT can automatically identify important EHR terms for patients. It could help develop future interventions to improve quality of care. By using unattended learning and a robust and flexible framework for information fusion, FIT can easily be applied to other areas and applications. Keywords: electronic medical records; natural language processing; information extraction; unattended assembler ranking."}, {"heading": "1. Introduction", "text": "This year, it is only a matter of time before we reach an agreement."}, {"heading": "2. Related Work", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1. NLP Systems Facilitating Concept-level EHR Comprehension", "text": "On the question of which medical terms should be simplified, previous work has dealt with frequency and / or context-based approaches to verify whether a term is unknown to the average patient or whether it has simpler synonyms [11,30,31]. Such work targets medical jargon and treats all jargon terms equally important. Our approach is different because it is important medical terms (which do not correspond to medical jargon, as discussed in the Introduction section) and patient-centered (i.e. it finds important terms for each EHR note from individual patients). It is worth noting that our approach complements previous work; for example, in a real-world application, we can present lay definitions for all medical terms in a patient's EHR and then highlight those terms that are most important to the patient."}, {"heading": "2.2. Unsupervised Single-Document Keyphrase Extraction", "text": "Our problem is more difficult because physicians have written EHR notes for physician-physician communication, and therefore characteristics extracted from EHR notes may not be sufficient to guide an automated system to find topics and terms that are important to patients. Previous work in unattended KE has explored various techniques, including speech modeling, topic clustering, graph-based ranking and simultaneous learning of key sentences and key sentences [33], including graph-based methods such as TextRank [34] and its state-of-the-art variations [33]. We have adapted SingleRank [35] (an extension of TextRank) to clinical key terms, using it as a basis and input for the overall ranking of approaches 36 and Komedical [Komedical] knowledge to a limited extent to the respective domain (an extension of TextRank)."}, {"heading": "3. The FIT System", "text": "In the first step, FIT applies MetaMap [29], a concept recognition tool that automatically maps biomedical text to the concepts of the Unified Medical Language System (UMLS) to find medical terms as candidate terms. FIT's remaining pipeline is described below."}, {"heading": "3.1 Four Single Views of Term Importance", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1.1 Patient Use of Medical Concepts", "text": "One way to quantify the terms used by patients is to collect and analyze patient inquiries on the Internet. The Consumer Health Vocabulary (CHV) is a collection of terms used by patients. It is a rich resource that includes terms extracted from various consumer health sites, such as queries sent to MedLinePlus and postings in health-oriented online discussion forums [40-46]. It contains 152,338 terms, most of which are consumer health terms [44-46]. Zeng et al. [45] mapped these consumer health terms to the UMLS concepts using a semi-automatic approach. As a result of this work, the CHV includes both terms and corresponding medical terms. Although the CHV is a comprehensive patient-centered resource, its reach is limited."}, {"heading": "3.1.2 Document-level Term Salience", "text": "1 Chapman W., University of Pittsburgh NLP Repository. Use of this data requires a licence.FIT uses TF * IDF to represent the highlighting of a candidate term over an individual EHR grade. TF * IDF [60] is commonly used to measure the highlighting of a term over a document d in a corpus D. As defined in (1), the more frequently the term occurs in the document and the less frequently it occurs in other documents, the more important it is for that document. (,) = (,) (,) (,) (,) (,) (,) (,) is the frequency of the reverse document in corpus D; N is the total number of documents in corpus D; d is a document; (,) is the frequency of the data collected in the HE notes."}, {"heading": "3.1.3 Word-occurrence Based Term Relatedness", "text": "We used SingleRank [35] to represent this view. In our case, each EHR note is an undirected, unweighted graph in which words are vertices and are connected when they are simultaneously in a context window of 10. The rank of a word is recursively calculated by (2), () = (1) 1 () (2), where a word is, () is a sentence that contains all neighbors of, d is the attenuation factor set to 0.85 [61], the edge weight corresponding to the number of common occurrences of and within a context window of (). The rank of a single word is the sum of the words of the respective rank contained in that rank."}, {"heading": "3.1.4 Topic Coherence", "text": "From this point of view, the meaning of a candidate for an EHR grade is measured by the theme coherence between the term and the grade. We calculate the theme coherence () by (3) and (), (|) = () () () = () (), where P ()))))."}, {"heading": "3.2 Additional Information about Term Importance", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.2.1 Term Unfamiliarity", "text": "Since familiar terms can occur too often to be important to patients, we assumed that unfamiliar terms are generally more important than familiar terms and should therefore be ranked higher. We used CHV familiarity values to distinguish between unknown and familiar terms. CHV familiarity values give familiarity values to 58% (88,189 out of 152,338) of its terms for extended familiarity. CHV familiarity values estimate the likelihood that a medical term can be understood by the average reader [63] and take values between 0 and 1 (with 1 being the most familiar and 0 the least familiar). CHV provides different types of familiarity values [30]. Following [30] we used the combined score and a score threshold of 0.6 to detect unfamiliar and familiar terms (familiarity value \u2264 0.6 is unfamiliar terms; > 0.6 are familiar terms) Because each term has a partial familiarity value (familiarity value \u2264 0.6 is unfamiliar terms; > 0.6 are familiar terms)."}, {"heading": "3.2.2 Semantic Types of Medical Concepts", "text": "We found that the distribution of UMLS semantics types versus medical concepts in CHV was skewed, suggesting that medical concepts commonly used by patients can focus on certain semantic types (which we called CHV-preferred semantics types), so we assumed that medical terms with CHV-preferred semantics types were more important to patients than terms with other semantics types and should therefore be ranked higher. We used a heuristic, i.e. frequency > 1000, to select 12 CHV-preferred semantics types (see Appendix A)."}, {"heading": "3.3 Combining Heterogeneous Information Resources by Random Walk", "text": "In fact, it is as if it were a way in which it is a way in which it is a way in which it is a way in which it is a way in which it is a way in which it is a way in which it is a way in which it is a way in which it is a way in which it is a way in which it is a way in which it is a way in which it is a way in which it is a way in which it is a way in which it is a way in which it is a way in which it is a way in which it is a way in which it is a way in which it is a way in which it is a way in which it is a way in which it is a way in which it is a way in which it is a way in which it is a way in which it is a way in which it is a way in which it is a way in which it is a way in which it is a way in which it is a way in which it is a way in which it is a way in which it is a way in which it is a way in which it is a way in which it is a way in which it is a way in which it is a way in which it is a way in which it is a way in which it is in which it is a way in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which that way which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in this way which it is in which it is in which it is in which that way that way which it is in which is in which it is in which it is in which"}, {"heading": "4. Experimental Settings", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Evaluation Set", "text": "To maximize representativeness, we selected notes from patients with six different but common primary clinical diagnoses: cancer, COPD, diabetes, heart failure, hypertension, and liver failure. We extracted the notes and asked physicians to identify for each note at least five of the most important medical terms that patients should know to better understand their health and treatment routines. We asked physicians to comment on the notes from a patient perspective, as this task requires a complete understanding of notes that exceed the capacity of the average patient [11-13.30]. We developed an annotation policy (see Appendix B) to instruct physicians to comment on the notes from a patient perspective. For each note, we received notes from two physicians and used both physicians \"consent as the gold standard."}, {"heading": "4.2 Baseline Systems", "text": "To test the effect of the ensemble ranking, we used four single view rankings (see Section 3.1 for details), which are referred to as Patient Vocabulary Model, TF * IDF, Adapted SingleRank, and Topic Coherence, respectively. In addition, we implemented three benchmark methods for unattended ensemble evaluation, CombSum [64], Condorcet-fuse [66], and Reciprocal Rank Fusion [67] as strong baselines. These three methods were widely used in information search and NLP, including document query [64,66-69], web log query [70], opinion extraction [71], summary [72], and entity linkage [65]."}, {"heading": "4.2.1 CombSum", "text": "CombSum [64] is a rank-based ensemble method that calculates the rank score of a candidate term t by adding up the ranking scores obtained by the individual ensemble members as calculated by (9), () = () {| (9), where R is the number of individual ensemble members; () is the rank score of t given by a single ensemble member."}, {"heading": "4.2.2 Condorcet Fuse", "text": "Condorcet Fuse [66] sorts the terms of the candidates according to the pairs of ranks (\u2192) defined in (5). Specifically, it ranks higher than if () > 0. We have implemented the Condorcet Fuse Ranker according to the Quick Sorting Algorithm by using [66].4.2.3 Reciprocal Rank Fusion (RRF) Reciprocal Rank Fusion [67] to calculate the ranking of a candidate term t by using the t ranks assigned by individual ranks, as defined in (10), () (10), where R is the number of individual ranks in the ensemble; r (t) is the rank given by a single Ranker; k is a parameter used to mitigate the effects of high ranks of t assigned by potential outlier systems."}, {"heading": "4.3 Evaluation Metrics", "text": "Precision / Recall / F score at n: the averaged precision, recall and F score at ranks 5 and 10 (abbreviated as P5, R5, F5, P10, R10 and F10). These metrics measure system performance for top positions and are often used to evaluate KE systems. We have calculated these metrics by using as positive examples all the key terms of the gold standard (including terms that would never be taken into account in the phase of extracting the candidate term). Area Under ROC Curve (AUC-ROC): AUC-ROC is a widely used metric for evaluating ranking outputs. It calculates the range under a ROC curve that applies the true positive rate (y coordinate) against the false positive rate (x coordinate) at various threshold settings. When evaluating a system, we calculate its AUC-ROC score for each Rankings, we report the AUC score on both the Rankings and the global Rankings because we measure the AUC score on both the Rankings."}, {"heading": "5. Results", "text": "5.1 Extraction of Applicant Terms On average, FIT extracts 250 Applicant Terms per EHR grade, 89% of which correspond to the gold standard (medically annotated terms)."}, {"heading": "5.2 Evaluation Results", "text": "Our results (in Table 2) show that FIT performs significantly better than any single view ranking (see Table 2 for P values).Furthermore, as shown in Table 3, FIT outperforms the three ensemble methods for all metrics, except that there is an equilibrium with CombSum on AUC ROCKE. The performance difference between FIT and any baseline ensemble method is statistically significant for some metrics (see Table 3 for P values).CombSum 0.302 0.225 0.253 (P <.03) 0.335 0.266 (P =.01) 0.884 0.813 CondorcetFuse 0.264 0.168 0.218 (P <.001) 0.277 (P <.001) 0.225 (P <.001) 0.819 (P <.001) 0.801) 0.753 (P < 007 (P < < < < 030) (030) (0P) 0.030 (030) (0P)."}, {"heading": "6. Discussion", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.1 Principle Results", "text": "Automated ranking of EHR terms based on their meaning to patients is challenging, as the EHR notes contain a plethora of medical terms, of which only a small proportion (in our case 4%) have been rated as important by physicians. Unattended ranking of EHR terms is even more difficult for two reasons: firstly, the ranking officer has no oversight based on annotated data; secondly, and probably most importantly, many factors influence the meaning of a term. As a result, no single criterion or type of information is sufficient to achieve adequate results in terms of candidate ranking (see rows 2-4 in Table 2). Our FIT system addresses this problem by integrating multiple complementary information resources, reaching AUC-ROC 0.885 in terms of candidate ranking and AUC-ROC 0.813 in terms of candidate selection errors. This level of performance is appropriate, especially for unattended systems."}, {"heading": "6.2 FIT vs. Single Rankers", "text": "Our results (Table 2) show that FIT works well across all indicators, significantly outperforming each individual ranking, suggesting that our design of FIT and the selection of each ranking is appropriate and effective. Of the four individual rankings, Topic Coherence performs best (Row 5 in Table 2). Topic modeling was used to expand SingleRank to improve the state of the arts in unattended KE [76,77]. Our results suggest that Topic Coherence, as a standalone ranking, can provide good quality input factors for the final result."}, {"heading": "6.3 FIT vs. Baseline Ensemble Rankers", "text": "CondorcetFuse, Reciprocal Rank Fusion, and CombSum each use pairs of ranks, rankings, and ranks for the ensemble ranking. Previous work has shown that the performance of the three methods varies for different tasks and data sets, and therefore there is no guaranteed winner [66,68,67,69,70,75]. In addition, in real-world tasks, it is likely that we only have certain types of information (e.g. paired ranking relationships from product evaluation) or information from heterogeneous resources (e.g., in our case). Therefore, it is desirable to have a robust ensemble evaluator who can flexibly use different information resources. FIT has the desired characteristics through its design and, as confirmed by our experiments. As shown in Table 4, FIT can use not only the complete information about ranks and ranks given by the patient vocabulary model to improve its performance (2 vs. 1 row), but can also simply confirm the ranks relative to other ranks (1 row)."}, {"heading": "6.4 Error Analysis and Future Work", "text": "We manually examined 22 notes where FIT had either zero recall to rank 10 or a low AUC ROCK (< 0.700). We identified three types of errors: First, we used a relaxed strike match in the assessment, but did not allow a \"part-of-match\" (for the reason described in Section 4.3); however, in some cases, this approach underestimates performance. Second, FIT classified it as an error when MetaMap detected \"invasive\" and \"colorectal cancer\" but not \"invasive colorectal cancer,\" the gold standard term. Second, FIT depends on MetaMap making mistakes. Certain abbreviations were not identified as medical terms, such as A1c (a laboratory test for blood sugar), MRCP (magnetic resonance cholangiopancreatography), CPPD (calcium-phosphosphate accumulation test), and a common disease (TSH)."}, {"heading": "7. Conclusions", "text": "Our work is an important step in enabling patients to understand their own EHR notes in order to improve the quality of care. By using unsupervised learning and robust information techniques, FIT can easily be applied to other areas and applications. Conflicts of interest are not explained. Abbreviations AUC-ROC: Area Under ROC Curve CHV: Consumer Health Vocabulary EHR: electronic health record FIT: Finding Important Terms for patients KE: Keyphrase extraction MeSH: Medical Subject Headings NLP: Natural Language Processing SVM: support vector machines UMLS: Unified Medical Language System"}, {"heading": "Acknowledgments", "text": "This work was partially supported by the Investigator Initiated Research 1I01HX001457-01 of the Health Services Research & Development Program of the United States (U.S.) Department of Veterans Affairs, and we also acknowledge the support of the National Institutes of Health (NIH) Institutional National Research Service Award (T32) 5T32HL120823-02. Content is the sole responsibility of the authors and does not necessarily represent the official views of the U.S. Department of Veterans Affairs, NIH or the U.S. Government. We thank the UMassMed annotation Team, which includes Elaine Freund, Victoria Wang, Andrew Hsu, Barinder Hansra and Sonali Harchandani, for compiling the evaluation corpus, and Weisong Liu for providing technical assistance in collecting EHR notes. We also thank the anonymous critics for their constructive comments and suggestions."}, {"heading": "Appendix A. Twelve semantic types used to prioritize important medical terms in EHR notes", "text": "UMLS semantic type example EHR terms Pharmacologic Substance Advair, Budesonide, Insulin, NSAIDs, Spironolactone Disease or syndrome autoimmune hemolytic anemia, gastroesophageal reflux, pancytopenia, Sjogren syndrome, Osteoporosis Organic chemical Atenolol, Vincristine, Warfarin, Wellbutrin, Zocor Finding alopecia, hematuria, high blood pressure, NSTEMI (Non-ST-elevation myocardial infarction), retinopathy Therapeutic or preventive procedure chemotherapy, dialysis, immunosuppression, kidney transplantation, pancreatomyamino acid, peplasma, or protein2basal insulin, Rituxan, neupogen, synthrophile, haemoglobin sigma, plasma, plasma, plasma insulin insulin, immunosuppression, immunosuppression, immunosuppression"}, {"heading": "Appendix B. Guidelines for annotating medical terms important to patients in EHR notes", "text": "1. Goal / Task: Identify at least five key medical terms per EHR note that patients need to know in order to better understand their EHR notes. In general, the goal can be achieved by selecting the minimum number of medical terms that, when known to patients, have a significant understanding of their clinical illnesses and symptoms without being overwhelmed. To achieve this goal, we provide operational rules in Section 2. 2. Selection criteria (1) Include terms that represent the main concept of each EHR note. Note: The most important medical terms that patients should know are direct clinical knowledge and not complex clinical knowledge that may confuse patients or require additional explanation. (2) Include terms that relate to the main concepts identified in (1) and that may help the patient understand the key clinical concepts in their EHR notes."}, {"heading": "Appendix C. Ranks assigned by different NLP systems to the five important medical terms in the EHR excerpt in Figure 1", "text": "Systems Insulin-dependent diabetic pancreatectomy Pancreaticneoplasm splenectomy Whiplash procedure FIT 58 3 4 22 32PatientVocabularyModel147 50 44 14 64TF * IDF 182 2 2 25 52 31AdaptedSingleRank25 51 7 111 60TopicCoherence8 132 23 133 106CombSum 76 11 6 19 72CondorcetFuse 69 93 10 59 97ReciprocalRank Fusion39 20 4 51 52Appendix D. Effectiveness of d on the FIT Ranking led P5 R5 F5 F5 P10 R10 F10 AUCROCROCROCKE0 (CombSum) 0.302 0.202 0.225 0.253 0.335 0.280.280.280.265 1130.1 0.82Appendix D. Effectiveness of d on the FIT Ranking led P5 R5 F5 F5 F10 F10 F10 AUCROCROCROCROCKE0 (CombSum) 0.300.202 0.225 0.280.8225 0.280.8335 0.280.87ReciprocalRank Fusionabeabeabetics 0.280.280.280.1 0.830.280.8280.280.1 0.8130.8130.8130.1 0.8130.8130.1 0.3270.830.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.8"}], "references": [{"title": "Health care and the American Recovery and Reinvestment Act", "author": ["R. Steinbrook"], "venue": "N. Engl. J. Med. 360 ", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2009}, {"title": "The Medicare Electronic Health Record Incentive Program: provider performance on core and menu measures", "author": ["A. Wright", "J. Feblowitz", "L. Samal", "A.B. McCoy", "D.F. Sittig"], "venue": "Health Serv. Res. 49 ", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2014}, {"title": "Patient Portals and Patient Engagement: A State of the Science Review", "author": ["T. Irizarry", "A. DeVito Dabbs", "C.R. Curran"], "venue": "J. Med. Internet Res. 17 ", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2015}, {"title": "Inviting Patients to Read Their Doctors\u2019 Notes: A Quasi-experimental Study and a Look Ahead", "author": ["T. Delbanco", "J. Walker", "S.K. Bell", "J.D. Darer", "J.G. Elmore", "N. Farag", "H.J. Feldman", "R. Mejilla", "L. Ngo", "J.D. Ralston", "S.E. Ross", "N. Trivedi", "E. Vodicka", "S.G. Leveille"], "venue": "Ann. Intern. Med. 157 ", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2012}, {"title": "Evaluating patient access to Electronic Health Records: results from a survey of veterans", "author": ["K.M. Nazi", "T.P. Hogan", "D.K. McInnes", "S.S. Woods", "G. Graham"], "venue": "Med. Care. 51 ", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2013}, {"title": "Patient experiences with full electronic access to health records and clinical notes through the My HealtheVet Personal Health Record Pilot: qualitative study", "author": ["S.S. Woods", "E. Schwartz", "A. Tuepker", "N.A. Press", "K.M. Nazi", "C.L. Turvey", "W.P. Nichol"], "venue": "J. Med. Internet Res. 15 ", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2013}, {"title": "Text characteristics of clinical reports and their implications for the readability of personal health records", "author": ["Q. Zeng-Treitler", "H. Kim", "S. Goryachev", "A. Keselman", "L. Slaughter", "C.A. Smith"], "venue": "Stud. Health Technol. Inform. 129 ", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2007}, {"title": "A Semantic and Syntactic Text Simplification Tool for Health Content", "author": ["S. Kandula", "D. Curtis", "Q. Zeng-Treitler"], "venue": "AMIA. Annu. Symp. Proc. 2010 ", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2010}, {"title": "Improving patients\u2019 electronic health record comprehension with NoteAid", "author": ["B. Polepalli Ramesh", "T. Houston", "C. Brandt", "H. Fang", "H. Yu"], "venue": "Stud. Health Technol. Inform. 192 ", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2013}, {"title": "Opportunities to improve clinical summaries for patients at hospital discharge", "author": ["E. Sarzynski", "H. Hashmi", "J. Subramanian", "L. Fitzpatrick", "M. Polverento", "M. Simmons", "K. Brooks", "C. Given"], "venue": "BMJ Qual. Saf. ", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2016}, {"title": "Teaching patients with low literacy skills", "author": ["C.C. Doak", "L.G. Doak", "J.H. Root"], "venue": "AJN Am. J. Nurs. 96 ", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1996}, {"title": "Improving comprehension for cancer patients with low literacy skills: strategies for clinicians", "author": ["C.C. Doak", "L.G. Doak", "G.H. Friedell", "C.D. Meade"], "venue": "CA. Cancer J. Clin. 48 ", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1998}, {"title": "Readability assessment of internet-based consumer health information", "author": ["T.M. Walsh", "T.A. Volsko"], "venue": "Respir. Care. 53 ", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2008}, {"title": "Readability of patient education materials on the American Orthopaedic Society for Sports Medicine website", "author": ["A.E.M. Eltorai", "A. Han", "J. Truntzer", "A.H. Daniels"], "venue": "Phys. Sportsmed. 42 ", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2014}, {"title": "Readability of Written Materials for CKD Patients: A Systematic Review", "author": ["S. Morony", "M. Flynn", "K.J. McCaffery", "J. Jansen", "A.C. Webster"], "venue": "Am. J. Kidney Dis. Off. J. Natl. Kidney Found. 65 ", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2015}, {"title": "The literacy divide: health literacy and the use of an internet-based patient portal in an integrated health system-results from the diabetes study of northern California (DISTANCE)", "author": ["U. Sarkar", "A.J. Karter", "J.Y. Liu", "N.E. Adler", "R. Nguyen", "A. Lopez", "D. Schillinger"], "venue": "J. Health Commun. 15 Suppl 2 ", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2010}, {"title": "Consumers\u2019 perceptions of patient-accessible electronic medical records", "author": ["C. Zarcadoolas", "W.L. Vaughon", "S.J. Czaja", "J. Levy", "M.L. Rockoff"], "venue": "J. Med. Internet Res. 15 ", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2013}, {"title": "Barriers and Facilitators to Online Portal Use Among Patients and Caregivers in a Safety Net Health Care System: A Qualitative Study", "author": ["L. Tieu", "U. Sarkar", "D. Schillinger", "J.D. Ralston", "N. Ratanawongsa", "R. Pasick", "C.R. Lyles"], "venue": "J. Med. Internet Res. 17 ", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2015}, {"title": "C", "author": ["C. Pyper", "J. Amery", "M. Watson"], "venue": "Crook, Patients\u2019 experiences when accessing their on-line electronic patient records in primary care., Br J Gen Pr. 54 ", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2004}, {"title": "Lay understanding of terms used in cancer consultations", "author": ["K. Chapman", "C. Abraham", "V. Jenkins", "L. Fallowfield"], "venue": "Psychooncology. 12 ", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2003}, {"title": "Medical communication: do our patients understand", "author": ["E.B. Lerner", "D.V. Jehle", "D.M. Janicke", "R.M. Moscati"], "venue": "Am. J. Emerg. Med. 18 ", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2000}, {"title": "Patient on-line access to medical records in general practice", "author": ["R.B. Jones", "S.M. McGhee", "D. McGhee"], "venue": "Health Bull. (Edinb.). 50 ", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1992}, {"title": "V", "author": ["M. Baldry", "C. Cheal", "B. Fisher", "M. Gillett"], "venue": "Huet, Giving patients their own records in general practice: experience of patients and staff., Br. Med. J. Clin. Res. Ed. 292 ", "citeRegEx": "28", "shortCiteRegEx": null, "year": 1986}, {"title": "An overview of MetaMap: historical perspective and recent advances", "author": ["A.R. Aronson", "F.-M. Lang"], "venue": "J. Am. Med. Inform. Assoc. 17 ", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2010}, {"title": "Making texts in electronic health records comprehensible to consumers: a prototype translator", "author": ["Q. Zeng-Treitler", "S. Goryachev", "H. Kim", "A. Keselman", "D. Rosendale"], "venue": "AMIA Annu. Symp. Proc. AMIA Symp. AMIA Symp. ", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2007}, {"title": "Medical text simplification using synonym replacement: Adapting assessment of word difficulty to a compounding language", "author": ["E. Abrahamsson", "T. Forni", "M. Skeppstedt", "M. Kvist"], "venue": "in: Proc. 3rd Workshop Predict. Improv. Text Readability Target Read. Popul. EACL, Association for Computational Linguistics,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2014}, {"title": "Methods for Linking EHR Notes to Education Materials", "author": ["J. Zheng", "H. Yu"], "venue": "AMIA Jt. Summits Transl. Sci. Proc. AMIA Summit Transl. Sci. 2015 ", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2015}, {"title": "Automatic keyphrase extraction: A survey of the state of the art", "author": ["K.S. Hasan", "V. Ng"], "venue": "in: Proc 52nd Annu. Meet. Assoc. Comput. Linguist. ACL, Citeseer,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2014}, {"title": "TextRank: Bringing order into texts, in: Association for Computational Linguistics", "author": ["R. Mihalcea", "P. Tarau"], "venue": null, "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2004}, {"title": "Single document keyphrase extraction using neighborhood knowledge", "author": ["X. Wan", "J. Xiao"], "venue": "in: Proc. 23rd Natl. Conf. Artif. Intell., AAAI Press,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2008}, {"title": "Identifying important concepts from medical documents", "author": ["Q. Li", "Y.-F.B. Wu"], "venue": "J. Biomed. Inform. 39 ", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2006}, {"title": "Domain-independent automatic keyphrase indexing with small training sets", "author": ["O. Medelyan", "I.H. Witten"], "venue": "J. Am. Soc. Inf. Sci. Technol. 59 ", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2008}, {"title": "Automatic keyphrase extraction from medical documents", "author": ["K. Sarkar"], "venue": "in: Int. Conf. Pattern Recognit. Mach. Intell.,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2009}, {"title": "A Hybrid Approach to Extract Keyphrases from Medical Documents", "author": ["K. Sarkar"], "venue": "Int. J. Comput. Appl. 63 ", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2013}, {"title": "Terminology issues in user access to Web-based medical information", "author": ["A.T. McCray", "R.F. Loane", "A.C. Browne", "A.K. Bangalore"], "venue": "Proc. AMIA Symp. ", "citeRegEx": "40", "shortCiteRegEx": null, "year": 1999}, {"title": "Patient and clinician vocabulary: how different are they", "author": ["Q. Zeng", "S. Kogan", "N. Ash", "R.A. Greenes"], "venue": "Stud. Health Technol. Inform. 84 ", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2001}, {"title": "Evaluation of Controlled Vocabulary Resources for Development of a Consumer Entry Vocabulary for Diabetes", "author": ["T.B. Patrick", "H.K. Monga", "M.C. Sievert", "J.H. Hall", "D.R. Longo"], "venue": "J. Med. Internet Res. 3 ", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2001}, {"title": "others", "author": ["Q. Zeng", "S. Kogan", "N. Ash", "R.A. Greenes", "A.A. Boxwala"], "venue": "Characteristics of consumer terminology for health information retrieval, Methods Inf. Med. 41 ", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2002}, {"title": "Exploring medical expressions used by consumers and the media: an emerging view of consumer health vocabularies", "author": ["T. Tse", "D. Soergel"], "venue": "Proc. AMIA Symp. ", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2003}, {"title": "Identifying consumer-friendly display (CFD) names for health concepts", "author": ["Q.T. Zeng", "T. Tse", "J. Crowell", "G. Divita", "L. Roth", "A.C. Browne"], "venue": "in: Proc. AMIA Annu. Symp.,", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2005}, {"title": "Consumer health concepts that do not map to the UMLS: where do they fit", "author": ["A. Keselman", "C.A. Smith", "G. Divita", "H. Kim", "A.C. Browne", "G. Leroy", "Q. Zeng- Treitler"], "venue": "J. Am. Med. Inform. Assoc. JAMIA. 15 ", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2008}, {"title": "Evaluating word representation features in biomedical named entity recognition tasks", "author": ["B. Tang", "H. Cao", "X. Wang", "Q. Chen", "H. Xu"], "venue": "BioMed Res. Int. 2014 ", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2014}, {"title": "Effects of Semantic Features on Machine Learning-Based Drug Name Recognition Systems: Word Embeddings vs", "author": ["S. Liu", "B. Tang", "Q. Chen", "X. Wang"], "venue": "Manually Constructed Dictionaries, Information. 6 ", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2015}, {"title": "Identifying adverse drug event information in clinical notes with distributional semantic representations of context", "author": ["A. Henriksson", "M. Kvist", "H. Dalianis", "M. Duneld"], "venue": "J. Biomed. Inform. 57 ", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2015}, {"title": "Bidirectional RNN for Medical Event Detection in Electronic Health Records", "author": ["A.N. Jagannatha", "H. Yu"], "venue": "in: Proc. NAACL-HLT 2016,", "citeRegEx": "50", "shortCiteRegEx": "50", "year": 2016}, {"title": "Mining and Ranking Biomedical Synonym Candidates from Wikipedia", "author": ["A.N. Jagannatha", "J. Chen", "H. Yu"], "venue": "in: Proc. Sixth Int. Workshop Health Text Min. Inf. Anal. Louhi,", "citeRegEx": "51", "shortCiteRegEx": "51", "year": 2015}, {"title": "Clinical abbreviation disambiguation using neural word embeddings", "author": ["Y. Wu", "J. Xu", "Y. Zhang", "H. Xu"], "venue": "Proc. BioNLP 2015 Workshop Biomed. Nat. Lang. Process. ACL-IJCNLP 2015. ", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2015}, {"title": "Exploiting Task-Oriented Resources to Learn Word Embeddings for Clinical Abbreviation Expansion", "author": ["Y. Liu", "T. Ge", "K.S. Mathews", "H. Ji", "D.L. McGuinness"], "venue": "Proc. 2015 Workshop Biomed. Nat. Lang. Process. ", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2015}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["T. Mikolov", "I. Sutskever", "K. Chen", "G.S. Corrado", "J. Dean"], "venue": "in: Adv. Neural Inf. Process. Syst.,", "citeRegEx": "54", "shortCiteRegEx": "54", "year": 2013}, {"title": "Efficient Estimation of Word Representations in Vector Space", "author": ["T. Mikolov", "K. Chen", "G. Corrado", "J. Dean"], "venue": "ArXiv13013781 Cs. ", "citeRegEx": "55", "shortCiteRegEx": null, "year": 2013}, {"title": "Comparative analysis of five protein-protein interaction corpora", "author": ["S. Pyysalo", "A. Airola", "J. Heimonen", "J. Bj\u00f6rne", "F. Ginter", "T. Salakoski"], "venue": "BMC Bioinformatics. 9 Suppl 3 ", "citeRegEx": "56", "shortCiteRegEx": null, "year": 2008}, {"title": "LIBSVM: a library for support vector machines", "author": ["C.-C. Chang", "C.-J. Lin"], "venue": "ACM Trans. Intell. Syst. Technol. TIST. 2 ", "citeRegEx": "57", "shortCiteRegEx": null, "year": 2011}, {"title": "Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods", "author": ["J. Platt"], "venue": "Adv. Large Margin Classif. 10 ", "citeRegEx": "58", "shortCiteRegEx": null, "year": 1999}, {"title": "A note on Platt\u2019s probabilistic outputs for support vector machines", "author": ["H.-T. Lin", "C.-J. Lin", "R.C. Weng"], "venue": "Mach. Learn. 68 ", "citeRegEx": "59", "shortCiteRegEx": null, "year": 2007}, {"title": "A statistical interpretation of term specificity and its application in retrieval", "author": ["K. Sparck Jones"], "venue": "J. Doc. 28 ", "citeRegEx": "60", "shortCiteRegEx": null, "year": 1972}, {"title": "Reprint of: The anatomy of a large-scale hypertextual web search engine", "author": ["S. Brin", "L. Page"], "venue": "Comput. Netw. 56 ", "citeRegEx": "61", "shortCiteRegEx": null, "year": 2012}, {"title": "Kachites, MALLET: A Machine Learning for Language Toolkit. http://mallet.cs.umass.edu", "author": ["McCallum", "Andrew"], "venue": null, "citeRegEx": "62", "shortCiteRegEx": "62", "year": 2002}, {"title": "A text corpora-based estimation of the familiarity of health terminology", "author": ["Q. Zeng", "E. Kim", "J. Crowell", "T. Tse"], "venue": "in: Proc. 6th Int. Conf. Biol. Med. Data Anal., Springer,", "citeRegEx": "63", "shortCiteRegEx": "63", "year": 2005}, {"title": "Combining multiple evidence from different properties of weighting schemes", "author": ["J.H. Lee"], "venue": "in: Proc. 18th Annu. Int. ACM SIGIR Conf. Res. Dev. Inf. Retr.,", "citeRegEx": "64", "shortCiteRegEx": "64", "year": 1995}, {"title": "Collaborative ranking: A case study on entity linking", "author": ["Z. Chen", "H. Ji"], "venue": "in: Proc. Conf. Empir. Methods Nat. Lang. Process., Association for Computational Linguistics,", "citeRegEx": "65", "shortCiteRegEx": "65", "year": 2011}, {"title": "Condorcet fusion for improved retrieval", "author": ["M. Montague", "J.A. Aslam"], "venue": "in: Proc. Elev. Int. Conf. Inf. Knowl. Manag.,", "citeRegEx": "66", "shortCiteRegEx": "66", "year": 2002}, {"title": "Buettcher, Reciprocal rank fusion outperforms condorcet and individual rank learning methods", "author": ["G.V. Cormack", "S.C.L. Clarke"], "venue": "in: Proc. 32nd Int. ACM SIGIR Conf. Res. Dev. Inf. Retr.,", "citeRegEx": "67", "shortCiteRegEx": "67", "year": 2009}, {"title": "A unified model for metasearch, pooling, and system evaluation", "author": ["J.A. Aslam", "V. Pavlu", "R. Savell"], "venue": "in: Proc. Twelfth Int. Conf. Inf. Knowl. Manag., ACM,", "citeRegEx": "68", "shortCiteRegEx": "68", "year": 2003}, {"title": "New learning methods for supervised and unsupervised preference aggregation", "author": ["M. Volkovs", "R.S. Zemel"], "venue": "J. Mach. Learn. Res", "citeRegEx": "69", "shortCiteRegEx": "69", "year": 2014}, {"title": "Ranking model selection and fusion for effective microblog search", "author": ["Z. Wei", "W. Gao", "T. El-Ganainy", "W. Magdy", "K.-F. Wong"], "venue": "in: Proc. First Int. Workshop Soc. Media Retr. Anal.,", "citeRegEx": "70", "shortCiteRegEx": "70", "year": 2014}, {"title": "Condorcet fusion for blog opinion retrieval", "author": ["S. Wu", "X. Zeng"], "venue": "in: 2012 23rd Int. Workshop Database Expert Syst. Appl.,", "citeRegEx": "71", "shortCiteRegEx": "71", "year": 2012}, {"title": "iRANK: A rank-learn-combine framework for unsupervised ensemble ranking", "author": ["F. Wei", "W. Li", "S. Liu"], "venue": "J. Am. Soc. Inf. Sci. Technol. 61 ", "citeRegEx": "72", "shortCiteRegEx": null, "year": 2010}, {"title": "Learning algorithm for keyphrase extraction", "author": ["P.D. Turney"], "venue": "Inf. Retr. ", "citeRegEx": "73", "shortCiteRegEx": null, "year": 2000}, {"title": "Approximate Matching for Evaluating Keyphrase Extraction", "author": ["T. Zesch", "I. Gurevych"], "venue": "in: RANLP,", "citeRegEx": "74", "shortCiteRegEx": "74", "year": 2009}, {"title": "A robust approach to optimizing multi-source information for enhancing genomics retrieval performance", "author": ["Q. Hu", "J.X. Huang", "J. Miao"], "venue": "BMC Bioinformatics. 12 Suppl 5 ", "citeRegEx": "75", "shortCiteRegEx": null, "year": 2011}, {"title": "Automatic keyphrase extraction via topic decomposition", "author": ["Z. Liu", "W. Huang", "Y. Zheng", "M. Sun"], "venue": "in: Proc. 2010 Conf. Empir. Methods Nat. Lang. Process., Association for Computational Linguistics,", "citeRegEx": "76", "shortCiteRegEx": "76", "year": 2010}], "referenceMentions": [{"referenceID": 1, "context": "In a nationwide effort to achieve this goal [1\u2013 3], online patient portals have been widely adopted by health systems in the U.", "startOffset": 44, "endOffset": 50}, {"referenceID": 1, "context": "[3,4].", "startOffset": 0, "endOffset": 5}, {"referenceID": 2, "context": "[3,4].", "startOffset": 0, "endOffset": 5}, {"referenceID": 3, "context": "In addition, the OpenNotes initiative [5] and the Blue Button movement [6] allow patients to access their full EHR notes through the portals, with early evidence showing improved medical comprehension, healthcare management, and outcomes [7\u20139].", "startOffset": 238, "endOffset": 243}, {"referenceID": 4, "context": "In addition, the OpenNotes initiative [5] and the Blue Button movement [6] allow patients to access their full EHR notes through the portals, with early evidence showing improved medical comprehension, healthcare management, and outcomes [7\u20139].", "startOffset": 238, "endOffset": 243}, {"referenceID": 5, "context": "In addition, the OpenNotes initiative [5] and the Blue Button movement [6] allow patients to access their full EHR notes through the portals, with early evidence showing improved medical comprehension, healthcare management, and outcomes [7\u20139].", "startOffset": 238, "endOffset": 243}, {"referenceID": 6, "context": "Previous studies showed that EHRs were written at an 8th-12th grade reading level [10\u201313], which is above the average adult patient\u2019s reading level of 7th to 8th grade in the U.", "startOffset": 82, "endOffset": 89}, {"referenceID": 7, "context": "Previous studies showed that EHRs were written at an 8th-12th grade reading level [10\u201313], which is above the average adult patient\u2019s reading level of 7th to 8th grade in the U.", "startOffset": 82, "endOffset": 89}, {"referenceID": 8, "context": "Previous studies showed that EHRs were written at an 8th-12th grade reading level [10\u201313], which is above the average adult patient\u2019s reading level of 7th to 8th grade in the U.", "startOffset": 82, "endOffset": 89}, {"referenceID": 9, "context": "Previous studies showed that EHRs were written at an 8th-12th grade reading level [10\u201313], which is above the average adult patient\u2019s reading level of 7th to 8th grade in the U.", "startOffset": 82, "endOffset": 89}, {"referenceID": 10, "context": "[14\u201318].", "startOffset": 0, "endOffset": 7}, {"referenceID": 11, "context": "[14\u201318].", "startOffset": 0, "endOffset": 7}, {"referenceID": 12, "context": "[14\u201318].", "startOffset": 0, "endOffset": 7}, {"referenceID": 13, "context": "[14\u201318].", "startOffset": 0, "endOffset": 7}, {"referenceID": 14, "context": "[14\u201318].", "startOffset": 0, "endOffset": 7}, {"referenceID": 15, "context": "Limited health literacy has been identified as one of the major barriers to patient portal use (which includes interpreting information from EHRs) [20\u201322].", "startOffset": 147, "endOffset": 154}, {"referenceID": 16, "context": "Limited health literacy has been identified as one of the major barriers to patient portal use (which includes interpreting information from EHRs) [20\u201322].", "startOffset": 147, "endOffset": 154}, {"referenceID": 17, "context": "Limited health literacy has been identified as one of the major barriers to patient portal use (which includes interpreting information from EHRs) [20\u201322].", "startOffset": 147, "endOffset": 154}, {"referenceID": 18, "context": "First, medical terms have been shown to be obstacles for patients [23\u201328].", "startOffset": 66, "endOffset": 73}, {"referenceID": 19, "context": "First, medical terms have been shown to be obstacles for patients [23\u201328].", "startOffset": 66, "endOffset": 73}, {"referenceID": 20, "context": "First, medical terms have been shown to be obstacles for patients [23\u201328].", "startOffset": 66, "endOffset": 73}, {"referenceID": 21, "context": "First, medical terms have been shown to be obstacles for patients [23\u201328].", "startOffset": 66, "endOffset": 73}, {"referenceID": 22, "context": "First, medical terms have been shown to be obstacles for patients [23\u201328].", "startOffset": 66, "endOffset": 73}, {"referenceID": 23, "context": "Although there are many medical terms in this piece of text (here we only highlighted a subset of terms identified by MetaMap [29] for illustration purpose), physicians identified only five terms most important for patients to know, i.", "startOffset": 126, "endOffset": 130}, {"referenceID": 7, "context": "There has been active research on linking medical terms to lay terms [11,30,31] and also on linking them to consumer-oriented definitions [12] and educational materials [32], and showing improved comprehension with such interventions [11,12].", "startOffset": 69, "endOffset": 79}, {"referenceID": 24, "context": "There has been active research on linking medical terms to lay terms [11,30,31] and also on linking them to consumer-oriented definitions [12] and educational materials [32], and showing improved comprehension with such interventions [11,12].", "startOffset": 69, "endOffset": 79}, {"referenceID": 25, "context": "There has been active research on linking medical terms to lay terms [11,30,31] and also on linking them to consumer-oriented definitions [12] and educational materials [32], and showing improved comprehension with such interventions [11,12].", "startOffset": 69, "endOffset": 79}, {"referenceID": 8, "context": "There has been active research on linking medical terms to lay terms [11,30,31] and also on linking them to consumer-oriented definitions [12] and educational materials [32], and showing improved comprehension with such interventions [11,12].", "startOffset": 138, "endOffset": 142}, {"referenceID": 26, "context": "There has been active research on linking medical terms to lay terms [11,30,31] and also on linking them to consumer-oriented definitions [12] and educational materials [32], and showing improved comprehension with such interventions [11,12].", "startOffset": 169, "endOffset": 173}, {"referenceID": 7, "context": "There has been active research on linking medical terms to lay terms [11,30,31] and also on linking them to consumer-oriented definitions [12] and educational materials [32], and showing improved comprehension with such interventions [11,12].", "startOffset": 234, "endOffset": 241}, {"referenceID": 8, "context": "There has been active research on linking medical terms to lay terms [11,30,31] and also on linking them to consumer-oriented definitions [12] and educational materials [32], and showing improved comprehension with such interventions [11,12].", "startOffset": 234, "endOffset": 241}, {"referenceID": 7, "context": "On the issue of determining which medical terms to simplify, previous work explored frequency-based and/or context-based approaches to check if a term is unfamiliar to the average patients or if it has simpler synonyms [11,30,31].", "startOffset": 219, "endOffset": 229}, {"referenceID": 24, "context": "On the issue of determining which medical terms to simplify, previous work explored frequency-based and/or context-based approaches to check if a term is unfamiliar to the average patients or if it has simpler synonyms [11,30,31].", "startOffset": 219, "endOffset": 229}, {"referenceID": 25, "context": "On the issue of determining which medical terms to simplify, previous work explored frequency-based and/or context-based approaches to check if a term is unfamiliar to the average patients or if it has simpler synonyms [11,30,31].", "startOffset": 219, "endOffset": 229}, {"referenceID": 27, "context": "Previous work in unsupervised KE has explored various techniques, including language modeling, topic-clustering, graph-based ranking and simultaneous learning of keyphrases and key sentences [33].", "startOffset": 191, "endOffset": 195}, {"referenceID": 28, "context": "Among them, graph-based methods such as TextRank [34] and its variations are the state-of-the-arts [33].", "startOffset": 49, "endOffset": 53}, {"referenceID": 27, "context": "Among them, graph-based methods such as TextRank [34] and its variations are the state-of-the-arts [33].", "startOffset": 99, "endOffset": 103}, {"referenceID": 29, "context": "We adapted SingleRank [35] (an extension of TextRank) to clinical domain and used it as a baseline as well as an input for the ensemble ranking approaches.", "startOffset": 22, "endOffset": 26}, {"referenceID": 30, "context": "KE in the biomedical domain has been limitedly explored in literature articles and in using domain-specific methods and features [36\u201339].", "startOffset": 129, "endOffset": 136}, {"referenceID": 31, "context": "KE in the biomedical domain has been limitedly explored in literature articles and in using domain-specific methods and features [36\u201339].", "startOffset": 129, "endOffset": 136}, {"referenceID": 32, "context": "KE in the biomedical domain has been limitedly explored in literature articles and in using domain-specific methods and features [36\u201339].", "startOffset": 129, "endOffset": 136}, {"referenceID": 33, "context": "KE in the biomedical domain has been limitedly explored in literature articles and in using domain-specific methods and features [36\u201339].", "startOffset": 129, "endOffset": 136}, {"referenceID": 30, "context": "[36] developed KIP to extract keyphrases from medical articles.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "In the first step, FIT applies MetaMap [29], a concept detection tool that automatically maps biomedical text to the Unified Medical Language System (UMLS) concepts, to find medical terms as candidate terms.", "startOffset": 39, "endOffset": 43}, {"referenceID": 34, "context": "It is a rich resource that incorporates terms extracted from various consumer health sites, such as queries submitted to MedLinePlus and postings in health-focused online discussion forums [40\u201346].", "startOffset": 189, "endOffset": 196}, {"referenceID": 35, "context": "It is a rich resource that incorporates terms extracted from various consumer health sites, such as queries submitted to MedLinePlus and postings in health-focused online discussion forums [40\u201346].", "startOffset": 189, "endOffset": 196}, {"referenceID": 36, "context": "It is a rich resource that incorporates terms extracted from various consumer health sites, such as queries submitted to MedLinePlus and postings in health-focused online discussion forums [40\u201346].", "startOffset": 189, "endOffset": 196}, {"referenceID": 37, "context": "It is a rich resource that incorporates terms extracted from various consumer health sites, such as queries submitted to MedLinePlus and postings in health-focused online discussion forums [40\u201346].", "startOffset": 189, "endOffset": 196}, {"referenceID": 38, "context": "It is a rich resource that incorporates terms extracted from various consumer health sites, such as queries submitted to MedLinePlus and postings in health-focused online discussion forums [40\u201346].", "startOffset": 189, "endOffset": 196}, {"referenceID": 39, "context": "It is a rich resource that incorporates terms extracted from various consumer health sites, such as queries submitted to MedLinePlus and postings in health-focused online discussion forums [40\u201346].", "startOffset": 189, "endOffset": 196}, {"referenceID": 40, "context": "It is a rich resource that incorporates terms extracted from various consumer health sites, such as queries submitted to MedLinePlus and postings in health-focused online discussion forums [40\u201346].", "startOffset": 189, "endOffset": 196}, {"referenceID": 38, "context": "It contains 152,338 terms, most of which are consumer health terms [44\u201346].", "startOffset": 67, "endOffset": 74}, {"referenceID": 39, "context": "It contains 152,338 terms, most of which are consumer health terms [44\u201346].", "startOffset": 67, "endOffset": 74}, {"referenceID": 40, "context": "It contains 152,338 terms, most of which are consumer health terms [44\u201346].", "startOffset": 67, "endOffset": 74}, {"referenceID": 39, "context": "[45] mapped these consumer health terms to the UMLS concepts by a semi-automatic approach.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "We followed [30] (i.", "startOffset": 12, "endOffset": 16}, {"referenceID": 41, "context": "We used word embeddings as learning features because word embedding has emerged as a powerful technique for word representation and has been successfully used in biomedical and clinical NLP tasks such as biomedical named entity recognition [47,48], adverse drug event detection [49,50], ranking biomedical synonyms [51], and disambiguating clinical abbreviations [52,53].", "startOffset": 240, "endOffset": 247}, {"referenceID": 42, "context": "We used word embeddings as learning features because word embedding has emerged as a powerful technique for word representation and has been successfully used in biomedical and clinical NLP tasks such as biomedical named entity recognition [47,48], adverse drug event detection [49,50], ranking biomedical synonyms [51], and disambiguating clinical abbreviations [52,53].", "startOffset": 240, "endOffset": 247}, {"referenceID": 43, "context": "We used word embeddings as learning features because word embedding has emerged as a powerful technique for word representation and has been successfully used in biomedical and clinical NLP tasks such as biomedical named entity recognition [47,48], adverse drug event detection [49,50], ranking biomedical synonyms [51], and disambiguating clinical abbreviations [52,53].", "startOffset": 278, "endOffset": 285}, {"referenceID": 44, "context": "We used word embeddings as learning features because word embedding has emerged as a powerful technique for word representation and has been successfully used in biomedical and clinical NLP tasks such as biomedical named entity recognition [47,48], adverse drug event detection [49,50], ranking biomedical synonyms [51], and disambiguating clinical abbreviations [52,53].", "startOffset": 278, "endOffset": 285}, {"referenceID": 45, "context": "We used word embeddings as learning features because word embedding has emerged as a powerful technique for word representation and has been successfully used in biomedical and clinical NLP tasks such as biomedical named entity recognition [47,48], adverse drug event detection [49,50], ranking biomedical synonyms [51], and disambiguating clinical abbreviations [52,53].", "startOffset": 315, "endOffset": 319}, {"referenceID": 46, "context": "We used word embeddings as learning features because word embedding has emerged as a powerful technique for word representation and has been successfully used in biomedical and clinical NLP tasks such as biomedical named entity recognition [47,48], adverse drug event detection [49,50], ranking biomedical synonyms [51], and disambiguating clinical abbreviations [52,53].", "startOffset": 363, "endOffset": 370}, {"referenceID": 47, "context": "We used word embeddings as learning features because word embedding has emerged as a powerful technique for word representation and has been successfully used in biomedical and clinical NLP tasks such as biomedical named entity recognition [47,48], adverse drug event detection [49,50], ranking biomedical synonyms [51], and disambiguating clinical abbreviations [52,53].", "startOffset": 363, "endOffset": 370}, {"referenceID": 48, "context": "We trained a neural language model to learn word embeddings by using the Word2Vec software [54,55].", "startOffset": 91, "endOffset": 98}, {"referenceID": 49, "context": "We trained a neural language model to learn word embeddings by using the Word2Vec software [54,55].", "startOffset": 91, "endOffset": 98}, {"referenceID": 50, "context": "[56].", "startOffset": 0, "endOffset": 4}, {"referenceID": 51, "context": "We used the RBF-kernel SVM algorithm implemented by LibSVM [57] to learn feature weights and used LibSVM\u2019s probabilistic outputs [58,59] to rank candidate terms in each EHR note.", "startOffset": 59, "endOffset": 63}, {"referenceID": 52, "context": "We used the RBF-kernel SVM algorithm implemented by LibSVM [57] to learn feature weights and used LibSVM\u2019s probabilistic outputs [58,59] to rank candidate terms in each EHR note.", "startOffset": 129, "endOffset": 136}, {"referenceID": 53, "context": "We used the RBF-kernel SVM algorithm implemented by LibSVM [57] to learn feature weights and used LibSVM\u2019s probabilistic outputs [58,59] to rank candidate terms in each EHR note.", "startOffset": 129, "endOffset": 136}, {"referenceID": 54, "context": "TF*IDF [60] is widely used to measure the salience of a term to a document d in a corpus D, as defined in (1).", "startOffset": 7, "endOffset": 11}, {"referenceID": 29, "context": "We used SingleRank [35] to represent this view.", "startOffset": 19, "endOffset": 23}, {"referenceID": 55, "context": "85 [61], \u03c9ji is the edge weight which equals the number of co-occurrences of vi and vj within a context window of 10.", "startOffset": 3, "endOffset": 7}, {"referenceID": 56, "context": "We used the Latent Dirichlet Allocation algorithm implemented by MALLET [62] for topic modeling.", "startOffset": 72, "endOffset": 76}, {"referenceID": 57, "context": "CHV familiarity scores estimate the likelihood that a medical term can be understood by an average reader [63] and take values between 0 and 1 (with 1 being most familiar and 0 being least familiar).", "startOffset": 106, "endOffset": 110}, {"referenceID": 24, "context": "The CHV provides different types of familiarity scores [30].", "startOffset": 55, "endOffset": 59}, {"referenceID": 24, "context": "Following [30], we used the combined score and a score threshold 0.", "startOffset": 10, "endOffset": 14}, {"referenceID": 55, "context": "We used unsupervised ensemble learning and built FIT on an adapted random walk algorithm derived from PageRank [61].", "startOffset": 111, "endOffset": 115}, {"referenceID": 58, "context": "Rank scores, when available, are also useful for ensemble ranking [64,65].", "startOffset": 66, "endOffset": 73}, {"referenceID": 59, "context": "Rank scores, when available, are also useful for ensemble ranking [64,65].", "startOffset": 66, "endOffset": 73}, {"referenceID": 7, "context": "We asked physicians to do the annotation because this task requires a full comprehension of EHR notes which is beyond the capacity of the average patients [11\u201313,30].", "startOffset": 155, "endOffset": 165}, {"referenceID": 8, "context": "We asked physicians to do the annotation because this task requires a full comprehension of EHR notes which is beyond the capacity of the average patients [11\u201313,30].", "startOffset": 155, "endOffset": 165}, {"referenceID": 9, "context": "We asked physicians to do the annotation because this task requires a full comprehension of EHR notes which is beyond the capacity of the average patients [11\u201313,30].", "startOffset": 155, "endOffset": 165}, {"referenceID": 24, "context": "We asked physicians to do the annotation because this task requires a full comprehension of EHR notes which is beyond the capacity of the average patients [11\u201313,30].", "startOffset": 155, "endOffset": 165}, {"referenceID": 58, "context": "In addition, we implemented three benchmark unsupervised ensemble ranking methods, CombSum [64], Condorcet-fuse [66], and Reciprocal rank fusion [67], as strong baselines.", "startOffset": 91, "endOffset": 95}, {"referenceID": 60, "context": "In addition, we implemented three benchmark unsupervised ensemble ranking methods, CombSum [64], Condorcet-fuse [66], and Reciprocal rank fusion [67], as strong baselines.", "startOffset": 112, "endOffset": 116}, {"referenceID": 61, "context": "In addition, we implemented three benchmark unsupervised ensemble ranking methods, CombSum [64], Condorcet-fuse [66], and Reciprocal rank fusion [67], as strong baselines.", "startOffset": 145, "endOffset": 149}, {"referenceID": 58, "context": "The three methods have been widely in information retrieval and NLP, including document retrieval [64,66\u201369], web blog retrieval [70], opinion extraction [71], summarization [72], and entity linking [65].", "startOffset": 98, "endOffset": 108}, {"referenceID": 60, "context": "The three methods have been widely in information retrieval and NLP, including document retrieval [64,66\u201369], web blog retrieval [70], opinion extraction [71], summarization [72], and entity linking [65].", "startOffset": 98, "endOffset": 108}, {"referenceID": 61, "context": "The three methods have been widely in information retrieval and NLP, including document retrieval [64,66\u201369], web blog retrieval [70], opinion extraction [71], summarization [72], and entity linking [65].", "startOffset": 98, "endOffset": 108}, {"referenceID": 62, "context": "The three methods have been widely in information retrieval and NLP, including document retrieval [64,66\u201369], web blog retrieval [70], opinion extraction [71], summarization [72], and entity linking [65].", "startOffset": 98, "endOffset": 108}, {"referenceID": 63, "context": "The three methods have been widely in information retrieval and NLP, including document retrieval [64,66\u201369], web blog retrieval [70], opinion extraction [71], summarization [72], and entity linking [65].", "startOffset": 98, "endOffset": 108}, {"referenceID": 64, "context": "The three methods have been widely in information retrieval and NLP, including document retrieval [64,66\u201369], web blog retrieval [70], opinion extraction [71], summarization [72], and entity linking [65].", "startOffset": 129, "endOffset": 133}, {"referenceID": 65, "context": "The three methods have been widely in information retrieval and NLP, including document retrieval [64,66\u201369], web blog retrieval [70], opinion extraction [71], summarization [72], and entity linking [65].", "startOffset": 154, "endOffset": 158}, {"referenceID": 66, "context": "The three methods have been widely in information retrieval and NLP, including document retrieval [64,66\u201369], web blog retrieval [70], opinion extraction [71], summarization [72], and entity linking [65].", "startOffset": 174, "endOffset": 178}, {"referenceID": 59, "context": "The three methods have been widely in information retrieval and NLP, including document retrieval [64,66\u201369], web blog retrieval [70], opinion extraction [71], summarization [72], and entity linking [65].", "startOffset": 199, "endOffset": 203}, {"referenceID": 58, "context": "CombSum[64] is a rank-score-based ensemble method, which calculates the rank score of a candidate term t by summing t\u2019s rank scores received from single rankers, as calculated by (9),", "startOffset": 7, "endOffset": 11}, {"referenceID": 60, "context": "Condorcet Fuse[66] sorts candidate terms by pairwise rank relation R(tj \u2192 ti) as defined in (5).", "startOffset": 14, "endOffset": 18}, {"referenceID": 60, "context": "We implemented the Condorcet Fuse ranker using the quick sort algorithm by following [66].", "startOffset": 85, "endOffset": 89}, {"referenceID": 61, "context": "Reciprocal Rank Fusion[67] calculates the rank score of a candidate term t by using t\u2019s ranks assigned by single rankers, as defined in (10),", "startOffset": 22, "endOffset": 26}, {"referenceID": 61, "context": "We set k to 60 by following [67].", "startOffset": 28, "endOffset": 32}, {"referenceID": 67, "context": "In evaluation, we use relaxed string match to determine true positives as exact match is known to underestimate performance as perceived by human judges [73].", "startOffset": 153, "endOffset": 157}, {"referenceID": 68, "context": "We allow \u201csubsume\u201d but not \u201cpart-of\u201d match in relaxed string match, as previous work found that the former aligned well with human judges but the latter did not [74].", "startOffset": 161, "endOffset": 165}, {"referenceID": 59, "context": "to each other [65,68].", "startOffset": 14, "endOffset": 21}, {"referenceID": 62, "context": "to each other [65,68].", "startOffset": 14, "endOffset": 21}, {"referenceID": 60, "context": "When this assumption is violated, an ensemble ranker is not guaranteed to outperform the (best) single rankers [66,68,70,75].", "startOffset": 111, "endOffset": 124}, {"referenceID": 62, "context": "When this assumption is violated, an ensemble ranker is not guaranteed to outperform the (best) single rankers [66,68,70,75].", "startOffset": 111, "endOffset": 124}, {"referenceID": 64, "context": "When this assumption is violated, an ensemble ranker is not guaranteed to outperform the (best) single rankers [66,68,70,75].", "startOffset": 111, "endOffset": 124}, {"referenceID": 69, "context": "When this assumption is violated, an ensemble ranker is not guaranteed to outperform the (best) single rankers [66,68,70,75].", "startOffset": 111, "endOffset": 124}, {"referenceID": 70, "context": "Topic modeling has been used to extend SingleRank to improve the state-of-the-arts in unsupervised KE [76,77].", "startOffset": 102, "endOffset": 109}, {"referenceID": 27, "context": "SingleRank is among the state-of-the-arts and TF*IDF is frequently used as a strong baseline in unsupervised KE from scientific literature and news [33].", "startOffset": 148, "endOffset": 152}, {"referenceID": 60, "context": "Previous work shows that the performances of the three methods vary for different tasks and datasets and, therefore, there is no a guaranteed winner [66,68,67,69,70,75].", "startOffset": 149, "endOffset": 168}, {"referenceID": 62, "context": "Previous work shows that the performances of the three methods vary for different tasks and datasets and, therefore, there is no a guaranteed winner [66,68,67,69,70,75].", "startOffset": 149, "endOffset": 168}, {"referenceID": 61, "context": "Previous work shows that the performances of the three methods vary for different tasks and datasets and, therefore, there is no a guaranteed winner [66,68,67,69,70,75].", "startOffset": 149, "endOffset": 168}, {"referenceID": 63, "context": "Previous work shows that the performances of the three methods vary for different tasks and datasets and, therefore, there is no a guaranteed winner [66,68,67,69,70,75].", "startOffset": 149, "endOffset": 168}, {"referenceID": 64, "context": "Previous work shows that the performances of the three methods vary for different tasks and datasets and, therefore, there is no a guaranteed winner [66,68,67,69,70,75].", "startOffset": 149, "endOffset": 168}, {"referenceID": 69, "context": "Previous work shows that the performances of the three methods vary for different tasks and datasets and, therefore, there is no a guaranteed winner [66,68,67,69,70,75].", "startOffset": 149, "endOffset": 168}], "year": 2017, "abstractText": "Background: Allowing patients to access their own electronic health record (EHR) notes through online patient portals has the potential to improve patient-centered care. However, EHR notes contain abundant medical jargon that can be difficult for patients to comprehend. One way to help patients is to reduce information overload and help them focus on medical terms that matter most to them. Targeted education can then be developed to improve patient EHR comprehension and the quality of care. Objective: The aim of this work was to develop FIT (Finding Important Terms for patients), an unsupervised natural language processing (NLP) system that ranks medical terms in EHR notes based on their importance to patients. Methods: We built FIT on a new unsupervised ensemble ranking model derived from the biased random walk algorithm to combine heterogeneous information resources for ranking candidate terms from each EHR note. Specifically, FIT integrates four single views (rankers) for term importance: patient use of medical concepts, document-level term salience, word-occurrence based term relatedness, and topic coherence. It also incorporates partial information of term importance as conveyed by terms\u2019 unfamiliarity levels and semantic types. We evaluated FIT on 90 expert-annotated EHR notes and used the four single-view rankers as baselines. In addition, we implemented three benchmark unsupervised ensemble ranking methods as strong baselines. Results: FIT achieved 0.885 AUC-ROC for ranking candidate terms from EHR notes to identify important terms. When including term identification, the performance of FIT for identifying important terms from EHR notes was 0.813 AUC-ROC. Both performance scores significantly exceeded the corresponding scores from the four single rankers (P<.001). FIT also outperformed the three ensemble rankers for most metrics. Its performance is relatively insensitive to its parameter. Conclusions: FIT can automatically identify EHR terms important to patients. It may help develop future interventions to improve quality of care. By using unsupervised learning as well as a robust and flexible framework for information fusion, FIT can be readily applied to other domains and applications.", "creator": "Microsoft\u00ae Word 2016"}}}