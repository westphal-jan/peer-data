{"id": "1703.00557", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Mar-2017", "title": "Diffusion Independent Semi-Bandit Influence Maximization", "abstract": "We consider \\emph{influence maximization} (IM) in social networks, which is the problem of maximizing the number of users that become aware of a product by selecting a set of \"seed\" users to expose the product to. While prior work assumes a known model of information diffusion, we propose a parametrization in terms of pairwise reachability which makes our framework agnostic to the underlying diffusion model. We give a corresponding monotone, submodular surrogate function, and show that it is a good approximation to the original IM objective. We also consider the case of a new marketer looking to exploit an existing social network, while simultaneously learning the factors governing information propagation. For this, we propose a pairwise-influence semi-bandit feedback model and develop a LinUCB-based bandit algorithm. Our model-independent regret analysis shows that our bound on the cumulative regret has a better (as compared to previous work) dependence on the size of the network. By using the graph Laplacian eigenbasis to construct features, we describe a practical LinUCB implementation. Experimental evaluation suggests that our framework is robust to the underlying diffusion model and can efficiently learn a near-optimal solution.", "histories": [["v1", "Wed, 1 Mar 2017 23:54:40 GMT  (847kb,D)", "http://arxiv.org/abs/1703.00557v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["sharan vaswani", "branislav kveton", "zheng wen", "mohammad ghavamzadeh", "laks lakshmanan", "mark schmidt"], "accepted": false, "id": "1703.00557"}, "pdf": {"name": "1703.00557.pdf", "metadata": {"source": "META", "title": "Diffusion Independent Semi-Bandit Influence Maximization", "authors": ["Sharan Vaswani", "Branislav Kveton", "Zheng Wen", "Mohammad Ghavamzadeh", "Laks V.S. Lakshmanan", "Mark Schmidt"], "emails": ["<sharanv@cs.ubc.ca>."], "sections": [{"heading": "1. Introduction", "text": "The goal of viral marketing is to spread awareness about a specific product about the IMM problem that has been spread through a social network. Specifically, marketers (agents) aim to select a certain number of influential users and provide them with free products or discounts, assuming that these users will influence their neighbors and other users on the social network to accept the product, resulting in information that spreads across the network as more users accept or become aware of the product. The marketer has a budget for the number of free products and must select seeds1University of British Columbia 2Adobe Research. Correspondence to: Sharan Vaswani < sharanv @ cs.ubcs.ubc..... in terms of the expected number of users who become aware of the product. This problem is referred to as affecting the product. Maximization (IM).Existing solutions to the IM problem require input."}, {"heading": "2. Influence Maximization", "text": "The influence of maximizing (IM) problems is characterized by the triple (G, C, D), where G is a real diagram encoding the topology of the social network, C is the collection of possible seed sets, and D is the underlying problem. (G = (V, E), where V = 1, 2,.) and E are the nodes and edge sets of G, and D is the underlying problem. (D =) The collection of feasible seed sets C is determined by a cardinality constraint. (S = 2,.) D is the node and edge sets of G, and possibly any combinatorial constraints (e.g. matroid constraints) that imply some subsets of V. (S: S | \u2264 K}). The diffusion model D specifies the stochastic process under which the influence of the social network is propagated."}, {"heading": "3. Surrogate Objective", "text": "For each set of \"pair probabilities\" p: V \u00b7 V \u00b2 [0, 1], for all nodes v \u00b2 V, we further define f (S, p) = maxu \u00b2 S pu, v (2), where the pair probability is associated with the ordered node pair (u, v). We also define f (S, p) = v \u00b2 S pu (S, p).Note: for all p (S, p), the pair probability is always monotonous and submodular in S (Krause & Golovin, 2012).For each pair of nodes u, v \u00b2 V, we define the pair accessibility from u to v \u00b2 u, v = F ({u}, v), i.e."}, {"heading": "4. Influence Maximization Semi-Bandits", "text": "We will now focus on the case of a new marketer who tries to learn the factors that influence diffusion as he repeatedly interacts with the network, describing the observable feedback (Section 4.2) and the learning framework (Section 4.3)."}, {"heading": "4.1. Influence Maximization Semi-Bandits", "text": "In the case of an influence maximization semi-bandit problem (also characterized by the triple (G, C, D)), the agent (marketer) knows both G and C, but not the diffusion model D. Specifically, the agent knows neither the model class of D (e.g., whether D is IC or LT) nor its parameters. (e.g., influence probabilities for IC, LT) Consider a scenario in which the agent interacts with the social network for T rounds. In each round t {1,.,., T} the agent first selects a seed quantity St-C based on their prior knowledge and past observations, and then nature independently tries a diffusion random vector wt-P. Influence diffuses in the social network from St to D (gew). The reward of the agent in round t is the number of influenced madesrt = v-V-I (St, v, D (gew)."}, {"heading": "4.2. Pairwise Influence Feedback Model", "text": "In this work, we propose a novel IM semi-bandit feedback model, called pairwise feedback. In the framework of this feedback model, at the end of each round, the agent observes t I ({u}, v, D (wt)) for all u-St and all v-V scenarios. In other words, she observes whether v would be influenced or not if the agent selects S = {u} as seed within the diffusion model D (wt). This form of semi-bandit feedback is plausible in most IM scenarios. For example, on sites like Facebook, we can identify the user who prompted another user to \"share\" or \"like\" an article and thus trace the spread to the seed that triggered the diffusion. Similarly, the company tracks navigation behavior during product launch and can identify which other user prompted the person to accept a particular product."}, {"heading": "4.3. Linear Generalization", "text": "The parameterization of the problem in terms of accessibility probabilities results in O (n2) parameters that need to be learned. Without structural assumptions, this becomes insoluble for large networks. In order to develop statistically efficient algorithms for large-scale IM semi-bandits, we assume a linear generalization assumption. Assuming that each node v-V is associated with two vectors of dimension d, the seed (source) property of the commercial v < d and the target function xv < d are assumed to be known and must be learned."}, {"heading": "4.4. Performance Metric", "text": "We measure the performance of an IM semi-bandit algorithm by comparing its spread with the achievable influence, assuming complete knowledge of D. Since different approximations can be used for calculating seed set, similar to (Wen et al., 2016; Chen et al., 2016), we measure the performance of an IM semi-bandit algorithm according to scaled cumulative regret. In particular, if St is the seed selected by the IM semi-bandit algorithm in round t, the cumulative regret algorithm is defined in the first T rounds so that the same sentence in round t (T) = T \u00b7 F (S) \u2212 1; E \u2212 T = 1 F (St)]. (4) Algorithm 1 Diffusion-Independent LinUCB (DILinUCB) Indicator (DILinUCB) 1: Input: G = (V, E), C \u2212 T = Oracle ACLE target algorithm, St \u2212 1 (St \u2212 B) (St \u2212 1) Indicator \u2212 B \u2212 1."}, {"heading": "5. Algorithm", "text": "In this section, we propose a novel LinUCB-based IM semi-bandit algorithm, called Diffusion-Independent LinUCB (DILinUCB), whose pseudo-code is in algorithm 1. As its name implies, DILinUCB is independent of the underlying diffusion model D of the IM semi-bandit and therefore applicable to IM semi-bandits with any diffusion model D. The only prerequisite for using DILinUCB is that the IM-semi bandit provides the pairwise feedback described in Section 4.2. Inputs to DILinUCB include the network topology G, the collection of feasible sets C, a combinatorial optimization algorithm ORACLE, the target feature Matrix X, and three algorithm parameters c, control > 0."}, {"heading": "6. Regret Bound", "text": "In this section, we derive a delay for DILUCB, under (1) assumption 1, (2) perfect linear generalization, i.e. (2) assumptions for all V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V"}, {"heading": "7. Practical Implementation", "text": "In this section we will briefly discuss how to implement our proposed algorithm DILinUCB into practical semi-bandit IM problems. Specifically, in Section 7.1 we will discuss how to construct features, how to improve the practical performance of DILinUCB based on laplac regularization in Section 7.2, and how to implement DILinUCB in real-world problems in Section 7.3 with computational efficiency."}, {"heading": "7.1. Target Feature Construction", "text": "Although DILinUCB can be applied to any target attribute matrix X, its performance in practice depends heavily on the \"quality\" of X. In this subsection, we motivate and propose a systematic attribute construction approach based on the unweighted laplac matrix of the network topology G. For all u-V nodes, p-u- < n should be the vector that encodes the attainments from germ u to all target nodes v-V. Intuitively, we know that a smooth graph function (in this case the attainability from a source) can be smooth in the sense that target nodes v near each other (e.g. in the same community) have similar attainabilities of u. From (Belkin et al., 2006; Valko et al., 2014) we know that a smooth graph function (in this case the attainability from a source) can be expressed as a linear combination of characteristics of the weighted network of the laplaker."}, {"heading": "7.2. Laplacian Regularization", "text": "One limitation of our proposed DILinUCB algorithm is that it does not generalize across the nodes. Specifically, it must learn the source node trait \u00da u separately for each source node u, which is inefficient for large-scale semi-bandit IM problems. Note that the source traits tend to be frictionless, similar to target traits, in that the source traits are frictionless in the sense that they are \"small\" when connecting the nodes u1 \u2212 \u03b8 \u0445 u2 when the nodes u1 and u2 are connected to each other. This idea of laplac regulation was applied in multi-task learning (Evgeniou et al., 2005) and in contextual bandits (Cesa-Bianchi et al., 2013) to link the source traits for different nodes and thus transfer information between them. Specifically, we calculate in each round by doing the following things: minimize Cesa and Biesa al (2013)."}, {"heading": "7.3. Computational Complexity", "text": "We now characterize the computational complexity of DILinUCB and discuss how to implement it efficiently. At any time, DILinUCB must first compute a solution St on the basis of ORACLE and then update the UCBs. Since \u044bu, t is positively semi-definitive, the linear system in line 9 of algorithm 1 can be solved using conjugate gradient in O (d2) time. It is easy to see the computational complexity to update the UCBs to O (Knd2). The computational complexity to compute St depends on ORACLE. For the classical environment in which C = {S V: | S | S | \u2264 K} and ORACLE is the greedy algorithm, the computational complexity O (Kn) is used. To accelerate this, we use the idea of lazy evaluations for submodular maximization proposed in (Minoux, 1978; Leskovec et These results in-term, 2007)."}, {"heading": "8. Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "8.1. Empirical Verification of Surrogate Objective", "text": "In this subsection, we will empirically verify that the capabilities proposed in Section 3 are achieved first. We assume that a good approximation of the actual target F (S) is done in random graphs and charts that capture many approximate properties of the real world (Leskovec et al., 2005). We select D as the IC model and sample each of its probabilities of influence regardless of the uniform distribution U (0, 0.1). We note that this range of probabilities of influence is guided by the empirical evidence in (Goyal et al., 2010). In order to weaken dependence on a particular instance, all results in this subsection above 10 are generated randomly."}, {"heading": "9. Related Work", "text": "They have formulated it as a combinatorial, multi-armed bandit problem and proposed a UCB algorithm (CUCB). They consider only the tabular case and derive from it an O (n3) regret, which also depends on the reciprocity of the minimal probability of observation p of an edge. This can be problematic, for example, if a line chart with L-edges where all edge weights are 0.5. Then 1 / p is 2L \u2212 1 and implies an exponentially large regret. Moreover, they assume that source nodes independently affect the target nodes, which is not true in most practical social networks."}, {"heading": "10. Conclusion", "text": "In this paper, we described a novel model-independent parameterization and a corresponding surrogate objective function for the IM problem. We used this parameterization to propose DILinUCB, a diffusion-independent learning algorithm for IM semi-bandits. We derived a remorse for DILinUCB from this and showed empirically that it is statistically efficient and robust compared to the diffusion model. A future research direction is the development and analysis of a Thompson sampling algorithm based on the proposed surrogate objective. We also plan to investigate the construction of more representative features at the node level. Another research direction is to turn to more sophisticated feedback models at the node level, as in Vaswani et al. (2015)."}, {"heading": "A. Proof of Theorem 1", "text": "Proof: Theorem 1 follows on the basis of the definitions of monotonicity and submodularity. Note that from assumption 1 for each seed quantity S-C every seed node u-S and every target node v-V F ({u}, v-V) \u2264 F (S, v, p-V) is implied, which implies that f-V (S, v, p-V) \u2264 F (S, v-V) implies the first part of theorem 1. We now prove the second part of the theorem. First, note that from the first part we havef (S-V, v-p-V) implicitly F (S-K) implicitly F-S."}, {"heading": "B. Proof of Theorem 2", "text": "We start by defining some useful notations. We use Ht to describe the \"history\" until the end of time. For each pair of nodes (u, v, V, V and any time t, we define the upper trust limit (UCB) Ut (u, v) and the lower trust limit (LCB) Lt (u, v) or asUt (u, v) = Proj [0,1] (< p) and the lower trust limit (LCB) Lt (u, v) Lt (u, v) = Proj [0,1] (< p) = Proj [0,1, xv > \u2212 St u, t \u2212 1, xv > + c) (8) Note that Ut \u2212 St \u2212 1 is the same as the UCB estimate p."}, {"heading": "C. Self-Normalized Bound for Matrix-Valued Martingales", "text": "This result is a natural generalization of Theorem 1 in Abbasi-Yadkori et al. (2011).Theorem 3: (Self-Normalized Bound for Matrix-Valued Martingales) Let {Ht}. [Ht]. [Ht]. [Ht]. [Ht]. [Ht]. [Ht]. [Ht]. [Ht]. [Ht]. [Ht]. [Ht]. [Ht]. [Ht]. [Ht]. [Ht]. [Ht]. [Ht]. [Ht]. [Ht]. [Ht]. [Ht]. [Ht]. [Ht]. [Ht]. [Ht]. [Ht]. [Ht]. [Ht]. [Ht.]. [H................\" [Ht.]. [Ht]. [Ht.]. [Ht.]. [Ht.]. [Ht.]. [Ht.]. [Ht.]. [Ht.].......................... [Ht.]. [Ht.]. [Ht.]. [Ht.]. [Ht.].]. [Ht.]. [Ht.]. [Ht.]...................................... [Ht. [Ht.]. [Ht.]. [Ht.]. [Ht.]. [Ht.]. [Ht.].].....t. [Ht. [Ht.].....t. [Ht..]. [Ht.]. [Ht.].]. [Ht.....t. [Ht.]. [Ht.....t.. [Ht.]. [Ht.]. [Ht.].....t... [Ht.]..... [Ht.. [Ht.].]................t........................"}, {"heading": "D. Laplacian Regularization", "text": "As explained in Section 7, the enforcement of the equation leads to the following optimization problem: \"We have the problem that we are in this system.\" (\"We.\") \"We,\" it says, \"We.\" (\"We.\") \"We.\" (\"We.\") \"We.\" (\"We.\") \"We.\" (\"We.\") \"We.\" (\"We.\") \"We.\" (\"We.\") \"(\" We. \")\" (\"We.\" (\"We.\") \"(\" We. \")\" (\"We.\" (\"We.\") \"(\" We. \").\" (\"We.\" (\"We.\"). \"(\" We. \"(\" We. \").\" (\"We.\" (\"We.\"). \"We.\" (\"We.\"). \"We.\" (. \"We.\" We. \"(.\" We. \").\" We. \"(.\" We. \"We.\"). \"We.\" (. \"We.\" We. \"(.\" We. \").\" We. \"(.\" We. \").\" We. \"(.\" We. \"(.\" We. \"). (.\" We. \"). (.\" We. \"We. (.\"). \"We. (.\" We. \"). (.\" We. (. \"We.\"). (. \"We.\" (. \").\" We. \"(.\" We. \"(.\"). (. \"We. (.\" We. \"). (. (.\" We. \").\" (. \"We. (.\"). \"(.\"). (\"We.\"). (\"We. (. (.\" We. \"). (\" We. (. \"). (\" We. (. (. \"We.\"). (. \"). (. (. (\"). (\"We. (\" We. \"We. (.\"). (. \"). (. (.). (.\" We. \"We. (.\" We.). (. (. (.). (."}], "references": [{"title": "Improved algorithms for linear stochastic bandits", "author": ["Abbasi-Yadkori", "Yasin", "P\u00e1l", "D\u00e1vid", "Szepesv\u00e1ri", "Csaba"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Abbasi.Yadkori et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Abbasi.Yadkori et al\\.", "year": 2011}, {"title": "Topic-aware social influence propagation models", "author": ["Barbieri", "Nicola", "Bonchi", "Francesco", "Manco", "Giuseppe"], "venue": "Knowledge and information systems,", "citeRegEx": "Barbieri et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Barbieri et al\\.", "year": 2013}, {"title": "Manifold regularization: A geometric framework for learning from labeled and unlabeled examples", "author": ["Belkin", "Mikhail", "Niyogi", "Partha", "Sindhwani", "Vikas"], "venue": "Journal of machine learning research,", "citeRegEx": "Belkin et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Belkin et al\\.", "year": 2006}, {"title": "Revealing graph bandits for maximizing local influence", "author": ["Carpentier", "Alexandra", "Valko", "Michal"], "venue": "In International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "Carpentier et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Carpentier et al\\.", "year": 2016}, {"title": "A gang of bandits", "author": ["Cesa-Bianchi", "Nicolo", "Gentile", "Claudio", "Zappella", "Giovanni"], "venue": "In Advances in Neural Information Processing Systems, pp", "citeRegEx": "Cesa.Bianchi et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Cesa.Bianchi et al\\.", "year": 2013}, {"title": "Efficient influence maximization in social networks", "author": ["Chen", "Wei", "Wang", "Yajun", "Yang", "Siyu"], "venue": "In Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "Chen et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2009}, {"title": "Combinatorial multi-armed bandit and its extension to probabilistically triggered arms", "author": ["Chen", "Wei", "Wang", "Yajun", "Yuan", "Yang", "Qinshi"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Chen et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2016}, {"title": "Stochastic linear optimization under bandit feedback", "author": ["Dani", "Varsha", "Hayes", "Thomas P", "Kakade", "Sham M"], "venue": "In COLT, pp", "citeRegEx": "Dani et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Dani et al\\.", "year": 2008}, {"title": "Influence Function Learning in Information Diffusion Networks", "author": ["Du", "Nan", "Liang", "Yingyu", "Balcan", "Maria-Florina", "Song", "Le"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Du et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Du et al\\.", "year": 2014}, {"title": "Learning multiple tasks with kernel methods", "author": ["Evgeniou", "Theodoros", "Micchelli", "Charles A", "Pontil", "Massimiliano"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Evgeniou et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Evgeniou et al\\.", "year": 2005}, {"title": "Networked bandits with disjoint linear payoffs", "author": ["Fang", "Meng", "Tao", "Dacheng"], "venue": "In Internattional Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "Fang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Fang et al\\.", "year": 2014}, {"title": "Online clustering of bandits", "author": ["Gentile", "Claudio", "Li", "Shuai", "Zappella", "Giovanni"], "venue": "In Proceedings of the 31st International Conference on Machine Learning", "citeRegEx": "Gentile et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Gentile et al\\.", "year": 2014}, {"title": "Influence maximization in continuous time diffusion networks", "author": ["M Gomez Rodriguez", "B Sch\u00f6lkopf", "Pineau", "Langford J"], "venue": "In 29th International Conference on Machine Learning (ICML", "citeRegEx": "Rodriguez et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Rodriguez et al\\.", "year": 2012}, {"title": "Learning influence probabilities in social networks", "author": ["Goyal", "Amit", "Bonchi", "Francesco", "Lakshmanan", "Laks VS"], "venue": "In Proceedings of the third ACM international conference on Web search and data mining,", "citeRegEx": "Goyal et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Goyal et al\\.", "year": 2010}, {"title": "A data-based approach to social influence maximization", "author": ["Goyal", "Amit", "Bonchi", "Francesco", "Lakshmanan", "Laks VS"], "venue": "Proceedings of the VLDB Endowment,", "citeRegEx": "Goyal et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Goyal et al\\.", "year": 2011}, {"title": "Simpath: An efficient algorithm for influence maximization under the linear threshold model", "author": ["Goyal", "Amit", "Lu", "Wei", "Lakshmanan", "Laks VS"], "venue": "In Data Mining (ICDM),", "citeRegEx": "Goyal et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Goyal et al\\.", "year": 2011}, {"title": "node2vec: Scalable feature learning for networks", "author": ["Grover", "Aditya", "Leskovec", "Jure"], "venue": "In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "Grover et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Grover et al\\.", "year": 2016}, {"title": "Maximizing the spread of influence through a social network", "author": ["Kempe", "David", "Kleinberg", "Jon", "Tardos", "\u00c9va"], "venue": "In Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "Kempe et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Kempe et al\\.", "year": 2003}, {"title": "Submodular function maximization. Tractability: Practical Approaches to Hard Problems", "author": ["Krause", "Andreas", "Golovin", "Daniel"], "venue": null, "citeRegEx": "Krause et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Krause et al\\.", "year": 2012}, {"title": "Tight regret bounds for stochastic combinatorial semi-bandits", "author": ["Kveton", "Branislav", "Wen", "Zheng", "Ashkan", "Azin", "Szepesvari", "Csaba"], "venue": "In AISTATS,", "citeRegEx": "Kveton et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kveton et al\\.", "year": 2015}, {"title": "Online influence maximization", "author": ["Lei", "Siyu", "Maniu", "Silviu", "Mo", "Luyi", "Cheng", "Reynold", "Senellart", "Pierre"], "venue": "In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data", "citeRegEx": "Lei et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lei et al\\.", "year": 2015}, {"title": "SNAP Datasets: Stanford large network dataset collection", "author": ["Leskovec", "Jure", "Krevl", "Andrej"], "venue": "http://snap. stanford.edu/data,", "citeRegEx": "Leskovec et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Leskovec et al\\.", "year": 2014}, {"title": "Kronecker graphs: An approach to modeling networks", "author": ["Leskovec", "Jure", "Chakrabarti", "Deepayan", "Kleinberg", "Jon", "Faloutsos", "Christos", "Ghahramani", "Zoubin"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Leskovec et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Leskovec et al\\.", "year": 2010}, {"title": "Accelerated greedy algorithms for maximizing submodular set functions", "author": ["Minoux", "Michel"], "venue": "In Optimization Techniques,", "citeRegEx": "Minoux and Michel.,? \\Q1978\\E", "shortCiteRegEx": "Minoux and Michel.", "year": 1978}, {"title": "An analysis of approximations for maximizing submodular set functions", "author": ["Nemhauser", "George L", "Wolsey", "Laurence A", "Fisher", "Marshall L"], "venue": "Mathematical Programming,", "citeRegEx": "Nemhauser et al\\.,? \\Q1978\\E", "shortCiteRegEx": "Nemhauser et al\\.", "year": 1978}, {"title": "Learning the graph of epidemic cascades", "author": ["Netrapalli", "Praneeth", "Sanghavi", "Sujay"], "venue": "In ACM SIGMETRICS Performance Evaluation Review,", "citeRegEx": "Netrapalli et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Netrapalli et al\\.", "year": 2012}, {"title": "Deepwalk: Online learning of social representations", "author": ["Perozzi", "Bryan", "Al-Rfou", "Rami", "Skiena", "Steven"], "venue": "In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "Perozzi et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Perozzi et al\\.", "year": 2014}, {"title": "Prediction of information diffusion probabilities for independent cascade model", "author": ["Saito", "Kazumi", "Nakano", "Ryohei", "Kimura", "Masahiro"], "venue": "In Knowledge-Based Intelligent Information and Engineering Systems,", "citeRegEx": "Saito et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Saito et al\\.", "year": 2008}, {"title": "Influence maximization: Near-optimal time complexity meets practical efficiency", "author": ["Tang", "Youze", "Xiao", "Xiaokui", "Yanchen", "Shi"], "venue": null, "citeRegEx": "Tang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Tang et al\\.", "year": 2014}, {"title": "Influence maximization in near-linear time: A martingale approach", "author": ["Tang", "Youze", "Shi", "Yanchen", "Xiao", "Xiaokui"], "venue": "In Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data,", "citeRegEx": "Tang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Tang et al\\.", "year": 2015}, {"title": "Spectral bandits for smooth graph functions", "author": ["Valko", "Michal", "Munos", "R\u00e9mi", "Kveton", "Branislav", "Koc\u00e1k", "Tom\u00e1\u0161"], "venue": "In 31th International Conference on Machine Learning,", "citeRegEx": "Valko et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Valko et al\\.", "year": 2014}, {"title": "Influence maximization with bandits", "author": ["Vaswani", "Sharan", "Lakshmanan", "Laks. V. S", "Mark Schmidt"], "venue": "Technical report,", "citeRegEx": "Vaswani et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Vaswani et al\\.", "year": 2015}, {"title": "A tutorial on spectral clustering", "author": ["Von Luxburg", "Ulrike"], "venue": "Statistics and computing,", "citeRegEx": "Luxburg and Ulrike.,? \\Q2007\\E", "shortCiteRegEx": "Luxburg and Ulrike.", "year": 2007}, {"title": "Efficient learning in large-scale combinatorial semi-bandits", "author": ["Wen", "Zheng", "Kveton", "Branislav", "Ashkan", "Azin"], "venue": "In Proceedings of the 32nd International Conference on Machine Learning, ICML 2015,", "citeRegEx": "Wen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wen et al\\.", "year": 2015}, {"title": "Influence maximization with semi-bandit feedback", "author": ["Wen", "Zheng", "Kveton", "Branislav", "Valko", "Michal"], "venue": "arXiv preprint arXiv:1605.06593,", "citeRegEx": "Wen et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Wen et al\\.", "year": 2016}, {"title": "Self-Normalized Bound for Matrix-Valued Martingales In this section, we derive a \u201cself-normalized bound\u201d for matrix-valued Martingales. This result is a natural generalization of Theorem 1 in Abbasi-Yadkori et al", "author": [], "venue": null, "citeRegEx": "C.,? \\Q2011\\E", "shortCiteRegEx": "C.", "year": 2011}, {"title": "The following results follow from Lemma 9 of Abbasi-Yadkori et al. (2011), which uses the \u201cmethod of mixtures\u201d technique. Let \u039b be a Gaussian random vector in < with mean 0 and covariance matrix V \u22121, and independent of all the other random variables", "author": [], "venue": null, "citeRegEx": "1.,? \\Q2011\\E", "shortCiteRegEx": "1.", "year": 2011}], "referenceMentions": [{"referenceID": 17, "context": "The IM problem has been studied under various probabilistic diffusion models such as Independent Cascade (IC) and Linear Threshold (LT) models (Kempe et al., 2003).", "startOffset": 143, "endOffset": 163}, {"referenceID": 5, "context": "Under these common models, there has been substantial work on developing efficient heuristics and approximation algorithms (Chen et al., 2009; Leskovec et al., 2007; Goyal et al., 2011b;a; Tang et al., 2014; 2015).", "startOffset": 123, "endOffset": 213}, {"referenceID": 28, "context": "Under these common models, there has been substantial work on developing efficient heuristics and approximation algorithms (Chen et al., 2009; Leskovec et al., 2007; Goyal et al., 2011b;a; Tang et al., 2014; 2015).", "startOffset": 123, "endOffset": 213}, {"referenceID": 17, "context": "In practice, it is not clear how to choose from amongst the increasing number of plausible diffusion models (Kempe et al., 2003; Gomez Rodriguez et al., 2012; Li et al., 2013).", "startOffset": 108, "endOffset": 175}, {"referenceID": 27, "context": "Some papers try to learn these parameters from past propagation data (Saito et al., 2008; Goyal et al., 2010; Netrapalli & Sanghavi, 2012).", "startOffset": 69, "endOffset": 138}, {"referenceID": 13, "context": "Some papers try to learn these parameters from past propagation data (Saito et al., 2008; Goyal et al., 2010; Netrapalli & Sanghavi, 2012).", "startOffset": 69, "endOffset": 138}, {"referenceID": 5, "context": "Under these common models, there has been substantial work on developing efficient heuristics and approximation algorithms (Chen et al., 2009; Leskovec et al., 2007; Goyal et al., 2011b;a; Tang et al., 2014; 2015). Unfortunately, knowledge of the underlying diffusion model and its parameters is essential for the existing IM algorithms to perform well. For example, Du et al. (2014) empirically showed that misspecification of the diffusion model can lead to choosing bad seeds and consequently to a low spread.", "startOffset": 124, "endOffset": 384}, {"referenceID": 5, "context": "Under these common models, there has been substantial work on developing efficient heuristics and approximation algorithms (Chen et al., 2009; Leskovec et al., 2007; Goyal et al., 2011b;a; Tang et al., 2014; 2015). Unfortunately, knowledge of the underlying diffusion model and its parameters is essential for the existing IM algorithms to perform well. For example, Du et al. (2014) empirically showed that misspecification of the diffusion model can lead to choosing bad seeds and consequently to a low spread. In practice, it is not clear how to choose from amongst the increasing number of plausible diffusion models (Kempe et al., 2003; Gomez Rodriguez et al., 2012; Li et al., 2013). Even if we are able to choose a diffusion model according to some prior information, the number of parameters for these models scales with the size of the network (for example, it is equal to the number of edges for both the IC and LT models) and it is not clear how to set these. Goyal et al. (2011a) showed that even when assuming the IC or LT model, correct knowledge of the model parameters is critical to choosing good seeds that lead to a large spread.", "startOffset": 124, "endOffset": 992}, {"referenceID": 31, "context": "This motivates the learning framework of IM semi-bandits (Vaswani et al., 2015; Chen et al., 2016; Wen et al., 2016).", "startOffset": 57, "endOffset": 116}, {"referenceID": 6, "context": "This motivates the learning framework of IM semi-bandits (Vaswani et al., 2015; Chen et al., 2016; Wen et al., 2016).", "startOffset": 57, "endOffset": 116}, {"referenceID": 34, "context": "This motivates the learning framework of IM semi-bandits (Vaswani et al., 2015; Chen et al., 2016; Wen et al., 2016).", "startOffset": 57, "endOffset": 116}, {"referenceID": 6, "context": "Our feedback model is weaker than the edge-level feedback proposed in (Chen et al., 2016; Wen et al., 2016).", "startOffset": 70, "endOffset": 107}, {"referenceID": 34, "context": "Our feedback model is weaker than the edge-level feedback proposed in (Chen et al., 2016; Wen et al., 2016).", "startOffset": 70, "endOffset": 107}, {"referenceID": 24, "context": "Although IM is an NP-hard problem in general, under common diffusion models such as IC and LT, the objective function F (S) is monotone and submodular, and thus, a near-optimal solution can be efficiently computed using a greedy algorithm (Nemhauser et al., 1978).", "startOffset": 239, "endOffset": 263}, {"referenceID": 17, "context": "Note that all progressive diffusion models (models where once the user is influenced, they can not change their state), including those in (Kempe et al., 2003; Gomez Rodriguez et al., 2012; Li et al., 2013) satisfy Assumption 1.", "startOffset": 139, "endOffset": 206}, {"referenceID": 6, "context": "Note that our assumption is strictly weaker than (and implied by) edge level semi-bandit feedback (Chen et al., 2016; Wen et al., 2016), since in that case, we can identify the edges along which the diffusion travelled, and thus, determine whether a particular source node is responsible for activating a target node.", "startOffset": 98, "endOffset": 135}, {"referenceID": 34, "context": "Note that our assumption is strictly weaker than (and implied by) edge level semi-bandit feedback (Chen et al., 2016; Wen et al., 2016), since in that case, we can identify the edges along which the diffusion travelled, and thus, determine whether a particular source node is responsible for activating a target node.", "startOffset": 98, "endOffset": 135}, {"referenceID": 33, "context": "To develop statistically efficient algorithms for large-scale IM semi-bandits, similar to the existing work on linear bandits (Wen et al., 2015; 2016), we make a linear generalization assumption.", "startOffset": 126, "endOffset": 150}, {"referenceID": 34, "context": "Since various approximations might be used for computing the seed set, similar to (Wen et al., 2016; Chen et al., 2016), we measure the performance of an IM semi-bandit algorithm by scaled cumulative regret.", "startOffset": 82, "endOffset": 119}, {"referenceID": 6, "context": "Since various approximations might be used for computing the seed set, similar to (Wen et al., 2016; Chen et al., 2016), we measure the performance of an IM semi-bandit algorithm by scaled cumulative regret.", "startOffset": 82, "endOffset": 119}, {"referenceID": 7, "context": "Notice that (2) is the standard assumption for linear bandit analysis (Dani et al., 2008), and (3) can always be satisfied by rescaling the target features.", "startOffset": 70, "endOffset": 89}, {"referenceID": 19, "context": "Second, note that the \u00d5( \u221a T )-dependence on time is nearoptimal, and the \u00d5( \u221a K)-dependence on the cardinality of the seed sets is standard in the combinatorial semi-bandit literature (Kveton et al., 2015).", "startOffset": 185, "endOffset": 206}, {"referenceID": 7, "context": "Third, for general X , notice that the \u00d5(d)-dependence on feature dimension is standard in linear bandit literature (Dani et al., 2008; Wen et al., 2015).", "startOffset": 116, "endOffset": 153}, {"referenceID": 33, "context": "Third, for general X , notice that the \u00d5(d)-dependence on feature dimension is standard in linear bandit literature (Dani et al., 2008; Wen et al., 2015).", "startOffset": 116, "endOffset": 153}, {"referenceID": 5, "context": "Assuming statistical independence between these reachabilities (similar to Chen et al. (2016)) can shave off this \u00d5( \u221a n) factor.", "startOffset": 75, "endOffset": 94}, {"referenceID": 2, "context": "From (Belkin et al., 2006; Valko et al., 2014), we know that a smooth graph function (in this case, the reachability from a source) can be expressed as a linear combination of eigenvectors of the weighted Laplacian of the network.", "startOffset": 5, "endOffset": 46}, {"referenceID": 30, "context": "From (Belkin et al., 2006; Valko et al., 2014), we know that a smooth graph function (in this case, the reachability from a source) can be expressed as a linear combination of eigenvectors of the weighted Laplacian of the network.", "startOffset": 5, "endOffset": 46}, {"referenceID": 9, "context": "This idea of Laplacian regularization has been used in multi-task learning (Evgeniou et al., 2005) and for contextual-bandits (Cesa-Bianchi et al.", "startOffset": 75, "endOffset": 98}, {"referenceID": 4, "context": ", 2005) and for contextual-bandits (Cesa-Bianchi et al., 2013).", "startOffset": 35, "endOffset": 62}, {"referenceID": 22, "context": "Empirical Verification of Surrogate Objective In this subsection, we empirically verify that the surrogate f(S, p\u2217) proposed in Section 3 is a good approximation of the true IM objective F (S) in random Kronecker graphs, which are known to capture many properties of real-world social networks (Leskovec et al., 2010).", "startOffset": 294, "endOffset": 317}, {"referenceID": 13, "context": "Note that this range of influence probabilities is guided by the empirical evidence in (Goyal et al., 2010; Barbieri et al., 2013).", "startOffset": 87, "endOffset": 130}, {"referenceID": 1, "context": "Note that this range of influence probabilities is guided by the empirical evidence in (Goyal et al., 2010; Barbieri et al., 2013).", "startOffset": 87, "endOffset": 130}, {"referenceID": 28, "context": "We then use the state-of-the-art IM algorithm (Tang et al., 2014) to compute an \u03b1\u2217-approximation solution S\u2217 g to the IM problem maxS F (S).", "startOffset": 46, "endOffset": 65}, {"referenceID": 6, "context": "We compare DILinUCB against the CUCB algorithm (Chen et al., 2016) in both the IC model and the LT model, with K = 10.", "startOffset": 47, "endOffset": 66}, {"referenceID": 11, "context": "Similar to (Gentile et al., 2014), all hyper-parameters for our algorithm are set using an initial validation set of 500 rounds.", "startOffset": 11, "endOffset": 33}, {"referenceID": 34, "context": "Related Work IM semi-bandits have been studied in several recent papers (Wen et al., 2016; Chen et al., 2016; Vaswani et al., 2015; Carpentier & Valko, 2016).", "startOffset": 72, "endOffset": 157}, {"referenceID": 6, "context": "Related Work IM semi-bandits have been studied in several recent papers (Wen et al., 2016; Chen et al., 2016; Vaswani et al., 2015; Carpentier & Valko, 2016).", "startOffset": 72, "endOffset": 157}, {"referenceID": 31, "context": "Related Work IM semi-bandits have been studied in several recent papers (Wen et al., 2016; Chen et al., 2016; Vaswani et al., 2015; Carpentier & Valko, 2016).", "startOffset": 72, "endOffset": 157}, {"referenceID": 6, "context": "In contrast, both our algorithm and analysis are diffusion independent, and our analysis does not require the \u201cindependent influence\u201d assumption made in (Chen et al., 2016).", "startOffset": 153, "endOffset": 172}, {"referenceID": 5, "context": ", 2016; Chen et al., 2016; Vaswani et al., 2015; Carpentier & Valko, 2016). Chen et al. (2016) studied IM semi-bandit under edge-level feedback and the IC diffusion model.", "startOffset": 8, "endOffset": 95}, {"referenceID": 5, "context": ", 2016; Chen et al., 2016; Vaswani et al., 2015; Carpentier & Valko, 2016). Chen et al. (2016) studied IM semi-bandit under edge-level feedback and the IC diffusion model. They formulated it as a combinatorial multi-armed bandit problem and proposed a UCB algorithm (CUCB). They only consider the tabular case, and derive an O(n) regret bound that also depends on the reciprocal of the minimum observation probability p of an edge. This can be problematic in for example, a line graph with L edges where all edge weights are 0.5. Then 1/p is 2L\u22121, implying an exponentially large regret. Moreover, they assume that source nodes influence the target nodes independently, which is not true in most practical social networks. In contrast, both our algorithm and analysis are diffusion independent, and our analysis does not require the \u201cindependent influence\u201d assumption made in (Chen et al., 2016). Our regret bound isO(n) in the tabular case andO(nd) in the general linear bandit case. Vaswani et al. (2015) use \u03b5-greedy and Thompson sampling algorithms for a different and more challenging feedback model, where the learning agent observes influenced nodes but not the edges.", "startOffset": 8, "endOffset": 1007}, {"referenceID": 5, "context": ", 2016; Chen et al., 2016; Vaswani et al., 2015; Carpentier & Valko, 2016). Chen et al. (2016) studied IM semi-bandit under edge-level feedback and the IC diffusion model. They formulated it as a combinatorial multi-armed bandit problem and proposed a UCB algorithm (CUCB). They only consider the tabular case, and derive an O(n) regret bound that also depends on the reciprocal of the minimum observation probability p of an edge. This can be problematic in for example, a line graph with L edges where all edge weights are 0.5. Then 1/p is 2L\u22121, implying an exponentially large regret. Moreover, they assume that source nodes influence the target nodes independently, which is not true in most practical social networks. In contrast, both our algorithm and analysis are diffusion independent, and our analysis does not require the \u201cindependent influence\u201d assumption made in (Chen et al., 2016). Our regret bound isO(n) in the tabular case andO(nd) in the general linear bandit case. Vaswani et al. (2015) use \u03b5-greedy and Thompson sampling algorithms for a different and more challenging feedback model, where the learning agent observes influenced nodes but not the edges. They do not give any theoretical guarantees. Wen et al. (2016) consider a linear generalization model across edges and prove regret bounds for the special case of forests under edge-level feedback.", "startOffset": 8, "endOffset": 1239}, {"referenceID": 5, "context": ", 2016; Chen et al., 2016; Vaswani et al., 2015; Carpentier & Valko, 2016). Chen et al. (2016) studied IM semi-bandit under edge-level feedback and the IC diffusion model. They formulated it as a combinatorial multi-armed bandit problem and proposed a UCB algorithm (CUCB). They only consider the tabular case, and derive an O(n) regret bound that also depends on the reciprocal of the minimum observation probability p of an edge. This can be problematic in for example, a line graph with L edges where all edge weights are 0.5. Then 1/p is 2L\u22121, implying an exponentially large regret. Moreover, they assume that source nodes influence the target nodes independently, which is not true in most practical social networks. In contrast, both our algorithm and analysis are diffusion independent, and our analysis does not require the \u201cindependent influence\u201d assumption made in (Chen et al., 2016). Our regret bound isO(n) in the tabular case andO(nd) in the general linear bandit case. Vaswani et al. (2015) use \u03b5-greedy and Thompson sampling algorithms for a different and more challenging feedback model, where the learning agent observes influenced nodes but not the edges. They do not give any theoretical guarantees. Wen et al. (2016) consider a linear generalization model across edges and prove regret bounds for the special case of forests under edge-level feedback. It not clear how to extend their technique for deriving regret bounds on general graphs. Note that all of the above papers assume the IC diffusion model. Carpentier & Valko (2016); Fang & Tao (2014) consider a simpler local model of influence, in which information does not transitively diffuse across the network.", "startOffset": 8, "endOffset": 1554}, {"referenceID": 5, "context": ", 2016; Chen et al., 2016; Vaswani et al., 2015; Carpentier & Valko, 2016). Chen et al. (2016) studied IM semi-bandit under edge-level feedback and the IC diffusion model. They formulated it as a combinatorial multi-armed bandit problem and proposed a UCB algorithm (CUCB). They only consider the tabular case, and derive an O(n) regret bound that also depends on the reciprocal of the minimum observation probability p of an edge. This can be problematic in for example, a line graph with L edges where all edge weights are 0.5. Then 1/p is 2L\u22121, implying an exponentially large regret. Moreover, they assume that source nodes influence the target nodes independently, which is not true in most practical social networks. In contrast, both our algorithm and analysis are diffusion independent, and our analysis does not require the \u201cindependent influence\u201d assumption made in (Chen et al., 2016). Our regret bound isO(n) in the tabular case andO(nd) in the general linear bandit case. Vaswani et al. (2015) use \u03b5-greedy and Thompson sampling algorithms for a different and more challenging feedback model, where the learning agent observes influenced nodes but not the edges. They do not give any theoretical guarantees. Wen et al. (2016) consider a linear generalization model across edges and prove regret bounds for the special case of forests under edge-level feedback. It not clear how to extend their technique for deriving regret bounds on general graphs. Note that all of the above papers assume the IC diffusion model. Carpentier & Valko (2016); Fang & Tao (2014) consider a simpler local model of influence, in which information does not transitively diffuse across the network.", "startOffset": 8, "endOffset": 1573}, {"referenceID": 5, "context": ", 2016; Chen et al., 2016; Vaswani et al., 2015; Carpentier & Valko, 2016). Chen et al. (2016) studied IM semi-bandit under edge-level feedback and the IC diffusion model. They formulated it as a combinatorial multi-armed bandit problem and proposed a UCB algorithm (CUCB). They only consider the tabular case, and derive an O(n) regret bound that also depends on the reciprocal of the minimum observation probability p of an edge. This can be problematic in for example, a line graph with L edges where all edge weights are 0.5. Then 1/p is 2L\u22121, implying an exponentially large regret. Moreover, they assume that source nodes influence the target nodes independently, which is not true in most practical social networks. In contrast, both our algorithm and analysis are diffusion independent, and our analysis does not require the \u201cindependent influence\u201d assumption made in (Chen et al., 2016). Our regret bound isO(n) in the tabular case andO(nd) in the general linear bandit case. Vaswani et al. (2015) use \u03b5-greedy and Thompson sampling algorithms for a different and more challenging feedback model, where the learning agent observes influenced nodes but not the edges. They do not give any theoretical guarantees. Wen et al. (2016) consider a linear generalization model across edges and prove regret bounds for the special case of forests under edge-level feedback. It not clear how to extend their technique for deriving regret bounds on general graphs. Note that all of the above papers assume the IC diffusion model. Carpentier & Valko (2016); Fang & Tao (2014) consider a simpler local model of influence, in which information does not transitively diffuse across the network. Lei et al. (2015) consider the related problem of maximizing the number of unique nodes across multiple rounds.", "startOffset": 8, "endOffset": 1707}, {"referenceID": 31, "context": "Another research direction is to address more challenging node-level feedback models such as in Vaswani et al. (2015).", "startOffset": 96, "endOffset": 118}, {"referenceID": 0, "context": "This result is a natural generalization of Theorem 1 in Abbasi-Yadkori et al. (2011). Theorem 3.", "startOffset": 56, "endOffset": 85}, {"referenceID": 0, "context": "Similarly as Abbasi-Yadkori et al. (2011), for any \u03bb \u2208 < and any t, we define D t as D t = exp ( \u03bbXt\u03b7t \u2212 K 2 \u2016X t \u03bb\u20162 ) , (35)", "startOffset": 13, "endOffset": 42}, {"referenceID": 0, "context": "Then, following Lemma 8 of Abbasi-Yadkori et al. (2011), we have the following lemma: Lemma 4.", "startOffset": 27, "endOffset": 56}, {"referenceID": 0, "context": "The following results follow from Lemma 9 of Abbasi-Yadkori et al. (2011), which uses the \u201cmethod of mixtures\u201d technique.", "startOffset": 45, "endOffset": 74}, {"referenceID": 0, "context": "The following lemma follows directly from the proof for Lemma 9 of Abbasi-Yadkori et al. (2011), which can be derived by algebra.", "startOffset": 67, "endOffset": 96}], "year": 2017, "abstractText": "We consider influence maximization (IM) in social networks, which is the problem of maximizing the number of users that become aware of a product by selecting a set of \u201cseed\u201d users to expose the product to. While prior work assumes a known model of information diffusion, we propose a parametrization in terms of pairwise reachability which makes our framework agnostic to the underlying diffusion model. We give a corresponding monotone, submodular surrogate function, and show that it is a good approximation to the original IM objective. We also consider the case of a new marketer looking to exploit an existing social network, while simultaneously learning the factors governing information propagation. For this, we propose a pairwise-influence semi-bandit feedback model and develop a LinUCB-based bandit algorithm. Our model-independent regret analysis shows that our bound on the cumulative regret has a better (as compared to previous work) dependence on the size of the network. By using the graph Laplacian eigenbasis to construct features, we describe a practical LinUCB implementation. Experimental evaluation suggests that our framework is robust to the underlying diffusion model and can efficiently learn a near-optimal solution.", "creator": "LaTeX with hyperref package"}}}