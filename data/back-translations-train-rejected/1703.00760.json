{"id": "1703.00760", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Mar-2017", "title": "Sampling Variations of Lead Sheets", "abstract": "Machine-learning techniques have been recently used with spectacular results to generate artefacts such as music or text. However, these techniques are still unable to capture and generate artefacts that are convincingly structured. In this paper we present an approach to generate structured musical sequences. We introduce a mechanism for sampling efficiently variations of musical sequences. Given a input sequence and a statistical model, this mechanism samples a set of sequences whose distance to the input sequence is approximately within specified bounds. This mechanism is implemented as an extension of belief propagation, and uses local fields to bias the generation. We show experimentally that sampled sequences are indeed closely correlated to the standard musical similarity measure defined by Mongeau and Sankoff. We then show how this mechanism can used to implement composition strategies that enforce arbitrary structure on a musical lead sheet generation problem.", "histories": [["v1", "Thu, 2 Mar 2017 12:33:28 GMT  (3294kb,D)", "http://arxiv.org/abs/1703.00760v1", "16 pages, 11 figures"]], "COMMENTS": "16 pages, 11 figures", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["pierre roy", "alexandre papadopoulos", "fran\\c{c}ois pachet"], "accepted": false, "id": "1703.00760"}, "pdf": {"name": "1703.00760.pdf", "metadata": {"source": "CRF", "title": "Sampling Variations of Lead Sheets", "authors": ["Pierre Roy", "Alexandre Papadopoulos", "Fran\u00e7ois Pachet"], "emails": ["roypie@gmail.com,", "pachetcsl@gmail.com,", "alexandre.papadopoulos@lip6.fr"], "sections": [{"heading": "1 Introduction", "text": "In fact, the way we move is very different, which means that we are able to adapt to the needs of the people we need to satisfy them, which means that we have to adapt to the needs of the people, to the needs of the people we need to satisfy them."}, {"heading": "2 Melodic Similarity", "text": "Traditional string editing takes into account three editing operations: substitution, deletion and insertion of a character. [6] Add two operations motivated by the peculiarities of musical sequences and inspired by time compression and expansion operations considered in time distortion. The first operation, ai called fragmentation, involves replacing a note with several, shorter notes. Similarly, the consolidation operation, replacing several notes with a single, longer note.Mongeau and Sankoff proposed an algorithm to calculate the similarity between melodies in polynomial time. Consider melodies as sequences of notes, leave A = a1,..., am and B = b1,.. The algorithm is based on dynamic programming, with the following repeat equation for i = 1,...., m and j = 1,."}, {"heading": "3 A Model for the Generation of Variations", "text": "Faced with an original theme, i.e. a melody or a melody fragment, we create variations on this theme by sampling a particular graphic model, which is a modified version of the general model of lead sheets introduced by [7] We first give a brief overview of this model and then show how we can adapt this model to limit it to the production of lead sheets in a controlled Mongeau & Sankoff similarity measure from the theme."}, {"heading": "3.1 The Model of Lead Sheets", "text": "[7] introduces a general, two-part model of lead leaves, which we summarize briefly; the overall model includes two graphic models, one for chord sequences, one for melodies; both models are based on a factor diagram that combines a Markov model with a finite state machine; the Markov model, which is trained on a body of lead leaves, provides the stylistic model; the finite state machine represents hard time constraints that the generated sequences should meet, such as metric characteristics (e.g. an imposed total duration) or time constraints imposed by the user; and a harmonic model, also trained on a body of lead leaves, is used to \"synchronize\" the chord sequences and the melody, ensuring that melodies contain tones that harmoniously coincide with the chord can synchronize at the same time position."}, {"heading": "3.2 Generating Variations on a Theme", "text": "To create variations on an imposed theme, we use the mechanism used for harmonic synchronization (David). We modify the temporal probabilities by introducing a bias on these temporal probabilities, i.e., a bias \u03b2 (e-t, e-t, e-n). However, the new temporal probabilities are replaced by a factor following the product of the bias \u03b2 (e-t, e-e-t). (Finally, the probability of a bias is modified in the new model corresponding to the product of the biases \u03b2 (e, e-t), for all elements e of the sequence. A bias of 1 does not modify the probability of the element e at a time after e-t, and a bias of less than 1 reduces this probability. We set the value of \u03b2 (e-t, e-t) according to a \"localized\" similarity between the sequence e \"and the fragment of the theme."}, {"heading": "4 Experimental Results", "text": "The approach we propose is based on the intuition that local similarities favored by the biased model lead to a global similarity between the melodies produced and the theme. In this section, we evaluate our approach based on two aspects: First, we evaluate how the choice of the value for the parameter \u03b1 affects the similarity between the melodies produced and the original theme; second, we explain the result more analytically for \u03b1 = 0. First, we show that applying the bias to the localized similarity model of Mongeau & Sankoff is more similar; and then we show that this localized similarity of Mongeau & Sankoff is a good approximation to the actual model of Mongeau & Sankoff."}, {"heading": "4.1 Correlation between the Biases and the Mongeau & Sankoff Distance", "text": "For each sequence, we calculate its probability po in the unbiased model and its probability pb in the distorted model, and then consider the ratio pb / po. This probability ratio shows by how much the sequence was preferred, punished for values greater than 1 or vice versa, for values smaller than 1 in the distorted model. In Figure 4, we note that the points in blue are generated sequences with the distorted model with an \u03b1 = 0, i.e. the strictest possible test. For each sequence, we record their probability ratio on a protocol scale against its similarity to Mongeau & Sankoff with the subject. We observe that the logarithm of the probability ratio tends to decrease linearly as the Mongeau & Sankoff distance from the subject increases."}, {"heading": "4.2 Explaining the Correlation", "text": "We will explain the correlation observed by applying two consecutive approximate values. We will focus on the case in which \u03b1 = 0, but similar results are obtained with other values. We can break down our analysis into three steps: firstly, we will find that for a given sequence, its probability ratio is the same according to the definition of the distorted model with the product of all local distortions applied to each element of the sequence, up to a normalization factor; this has also been confirmed experimentally, although we do not show the graph for space reasons; secondly, we will show how the probability ratio compares to the safe Mongeau & Sankoff similarity measure obtained by summing the localized Mongeau & Sankoff similarity measures; and, for each sequence, we will add up the localized Mongeau & Sankoff ratio used in calculating the distortions, as explained in Section 3.2."}, {"heading": "5 Examples of Variations", "text": "In this section, we show music created using the variation-sampling mechanism; we show melodic variations of a short melodic fragment from \"Solar\" (Section 5.1) and the whole melody (Section 5.2); Section 5.3 shows a 32-bar lead leaf that has the same structure as Duke Ellington's \"In a Sentimental Mood,\" but in a very different style (The Beatles)."}, {"heading": "5.1 First Four Bars of \u201cSolar\u201d", "text": "Figure 7 shows six melodic variations of the first four bars of \"Solar\" by Miles Davis, which are presented according to a model worked out on 29 songs by Miles Davis (see section 4) in increasing order of distance from Mongeau & Sankoff with the original theme (see Figure 3)."}, {"heading": "5.2 Variations of Entire Lead Sheets", "text": "Figure 8 shows a variation of \"Solar\" in the style of Miles Davis (the system was trained with the same body as in Section 4), which contains many more notes than the original melody, i.e. 77 notes instead of 48, including rests and many triplets. bars 2, 4, 6, 8 and 11-12 are unchanged from the original melody. bars 9-10 are similar to each other, very similar to the original theme, but more complex than the original bars. This variation feels like an ornate version of \"Solar,\" which is a \"Solar\" with more notes. \"The mechanism described in this chapter generates variations based on the Mongeau-Sankoff distance between the melodies, but can be applied to other types of sequences and other distances, for example to be able to chord sequences."}, {"heading": "5.3 Composition of Structured Lead Sheets", "text": "As said, the model of melodic variations is an essential tool for the production of lead sheets. We show this with a concrete example: the production of a lead sheet with the structure of \"In a Sentimental Mood\" (Duke Ellington, see Figure 10). It consists of the following elements: \u2022 Sections: \"Pick up\" (A1), \"A2\" (A2), \"A2\" (Bars), \"Bars\" (Bars), \"A2\" (Bars) and \"Bars\" (Bars)."}, {"heading": "6 Conclusion", "text": "This model is based on the measure of melodic similarity proposed by [6]. Technically, we are using an approximate version of the Mongeau & Sankoff similarity measure to favor a more general model for the production of music. Experimental evaluation shows that this approach allows us to distort the model to the production of melodies similar to the imposed theme. Furthermore, the intensity of the distortion measure can be adjusted to control the similarity between the theme and the variations, making this approach a powerful tool for creating pieces that correspond to an imposed musical structure."}], "references": [{"title": "Stochastic Contextual Edit Distance and Probabilistic FSTs", "author": ["Ryan Cotterell", "Nanyun Peng", "Jason Eisner"], "venue": "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "Illusory Transformation from Speech to Song", "author": ["Diana Deutsch", "Trevor Henthorn", "Rachael Lapidis"], "venue": "The Journal of the Acoustical Society of America,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2011}, {"title": "Deepbach: a steerable model for bach chorales generation", "author": ["G Hadjeres", "F. Pachet"], "venue": "Technical report,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2016}, {"title": "Modelling high-dimensional sequences with lstm-rtrbm: Application to polyphonic music generation", "author": ["Qi Lyu", "Zhiyong Wu", "Jun Zhu", "Helen Meng"], "venue": "In Proceedings of the 24th International Conference on Artificial Intelligence,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2015}, {"title": "Aesthetic responses to repetition in unfamiliar music", "author": ["Elizabeth Hellmuth Margulis"], "venue": "Empirical Studies of the Arts,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2013}, {"title": "Comparison of Musical Sequences", "author": ["Marcel Mongeau", "David Sankoff"], "venue": "Computers and the Humanities,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1990}, {"title": "Assisted Lead Sheet Composition using FlowComposer", "author": ["Alexandre Papadopoulos", "Pierre Roy", "Fran\u00e7ois Pachet"], "venue": "In Principles and Practice of Constraint Programming \u2013 CP 2016", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2016}, {"title": "Learning String-Edit Distance", "author": ["Eric Sven Ristad", "Peter N Yianilos"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1998}, {"title": "Generating Long-Term Structure in Songs and Stories", "author": ["Elliot Waite"], "venue": "https://magenta.tensorflow.org/2016/07/15/lookback-rnn-attention-rnn,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2016}], "referenceMentions": [{"referenceID": 2, "context": "Recent advances in machine learning, especially deep recurrent networks such as Long short-term memeory networks (LSTMs), led to major improvements in the quality of music generation [3, 4].", "startOffset": 183, "endOffset": 189}, {"referenceID": 3, "context": "Recent advances in machine learning, especially deep recurrent networks such as Long short-term memeory networks (LSTMs), led to major improvements in the quality of music generation [3, 4].", "startOffset": 183, "endOffset": 189}, {"referenceID": 8, "context": "As a consequence the resulting music lacks a sense of direction and becomes boring to the listener after a short while [9].", "startOffset": 119, "endOffset": 122}, {"referenceID": 1, "context": "In fact, the striking illusion discovered by [2] shows that repetition truly creates music, for instance by turning speech into music.", "startOffset": 45, "endOffset": 48}, {"referenceID": 4, "context": "This is further confirmed by [5] who observed that inserting arbitrary repetition in non-repetitive music improves listeners rating and confidence that the music was written by a human composer.", "startOffset": 29, "endOffset": 32}, {"referenceID": 5, "context": "Although it is impossible to characterise formally the notion of variation, it was shown that some measures of melodic similarity are efficient at detecting variations of a theme [6].", "startOffset": 179, "endOffset": 182}, {"referenceID": 7, "context": "This method is related to work on stochastic edit distances [8, 1], but is integrated as a constraint in a more general model for the generation of musical sequences [7].", "startOffset": 60, "endOffset": 66}, {"referenceID": 0, "context": "This method is related to work on stochastic edit distances [8, 1], but is integrated as a constraint in a more general model for the generation of musical sequences [7].", "startOffset": 60, "endOffset": 66}, {"referenceID": 6, "context": "This method is related to work on stochastic edit distances [8, 1], but is integrated as a constraint in a more general model for the generation of musical sequences [7].", "startOffset": 166, "endOffset": 169}, {"referenceID": 5, "context": "[6] add two operations motivated by the specificities of musical sequences, and inspired by the time compression and expansion operations considered in time warping.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "This graphical model is a modified version of the general model of lead sheets introduced by [7].", "startOffset": 93, "endOffset": 96}, {"referenceID": 6, "context": "[7] introduces a general, two-voice model of lead sheets, which we briefly summarise.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "This is explained in detail in [7].", "startOffset": 31, "endOffset": 34}, {"referenceID": 0, "context": "To convert the distance into a weight between 0 and 1, we rescale those values to the [0, 1] interval, and then invert their order, so that a value of 1 is the closest to the theme, and 0 the furthest away.", "startOffset": 86, "endOffset": 92}, {"referenceID": 6, "context": "This procedure uses the general two-voice model of lead sheets [7] to generate original patterns and the model of variations of Section 3 to generate variations of these patterns.", "startOffset": 63, "endOffset": 66}, {"referenceID": 5, "context": "This model is based on the melodic similarity measure proposed by [6].", "startOffset": 66, "endOffset": 69}], "year": 2017, "abstractText": "Machine-learning techniques have been recently used with spectacular results to generate artefacts such as music or text. However, these techniques are still unable to capture and generate artefacts that are convincingly structured. In this paper we present an approach to generate structured musical sequences. We introduce a mechanism for sampling efficiently variations of musical sequences. Given a input sequence and a statistical model, this mechanism samples a set of sequences whose distance to the input sequence is approximately within specified bounds. This mechanism is implemented as an extension of belief propagation, and uses local fields to bias the generation. We show experimentally that sampled sequences are indeed closely correlated to the standard musical similarity measure defined by Mongeau and Sankoff. We then show how this mechanism can used to implement composition strategies that enforce arbitrary structure on a musical lead sheet generation problem.", "creator": "LaTeX with hyperref package"}}}