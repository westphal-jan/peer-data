{"id": "1703.00978", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Mar-2017", "title": "Compositional Falsification of Cyber-Physical Systems with Machine Learning Components", "abstract": "Cyber-physical systems (CPS), such as automotive systems, are starting to include sophisticated machine learning (ML) components. Their correctness, therefore, depends on properties of the inner ML modules. While learning algorithms aim to generalize from examples, they are only as good as the examples provided, and recent efforts have shown that they can produce inconsistent output under small adversarial perturbations. This raises the question: can the output from learning components can lead to a failure of the entire CPS? In this work, we address this question by formulating it as a problem of falsifying signal temporal logic (STL) specifications for CPS with ML components. We propose a compositional falsification framework where a temporal logic falsifier and a machine learning analyzer cooperate with the aim of finding falsifying executions of the considered model. The efficacy of the proposed technique is shown on an automatic emergency braking system model with a perception component based on deep neural networks.", "histories": [["v1", "Thu, 2 Mar 2017 22:58:10 GMT  (9056kb,D)", "http://arxiv.org/abs/1703.00978v1", null]], "reviews": [], "SUBJECTS": "cs.SY cs.LG", "authors": ["tommaso dreossi", "alexandre donz\\'e", "sanjit a seshia"], "accepted": false, "id": "1703.00978"}, "pdf": {"name": "1703.00978.pdf", "metadata": {"source": "CRF", "title": "Compositional Falsification of Cyber-Physical Systems with Machine Learning Components", "authors": ["Tommaso Dreossi", "Alexandre Donz\u00e9", "Sanjit A. Seshia"], "emails": ["dreossi@berkeley.edu", "sseshia@berkeley.edu", "alex.r.donze@gmail.com"], "sections": [{"heading": null, "text": "Keywords: cyber-physical systems, machine learning, falsification, temporal logic"}, {"heading": "1 Introduction", "text": "This year it is more than ever before."}, {"heading": "2 Background", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 CPSML Models", "text": "In this thesis, we consider models of cyber-physical systems with components of machine learning (CPSML = components of k-classification). We assume that a system model is defined as a simulator in the form of a tuple M = (S, U, sim), where S is a series of system states, U is a set of error examples, and sim: S \u00b7 U \u00b7 T \u2192 S is a simulator that represents a state s (tk) and an input value u (tk) - U to a new state s (tk + 1) = sim (s (s (tk), u (tk), which represents a state s (tk), in which tk + k + - k for a time step k - Q > 0.Given an initial time t- T, an initial state s (t0) - Y (t0) - an initial state s (t0) - S, a sequence of timesteps - 0,"}, {"heading": "2.2 Signal Temporal Logic", "text": "We consider signal time logic [12] (STL) to be the language for defining properties that are verified by a CPSML model. (STL) is an extension of linear time logic (LTL) that is suitable for specifying the properties of CPS. (STL) Signals defined on B are called booleans, while those defined on R are called real. (S) Signals expressed on E. (S) w) is a finite series of real signals defined on the same interval. (S) Signals expressed on E. (S). (S) w) is a finite series of real signals set on E. (S) is a finite series of real signals defined on the same interval. (S)."}, {"heading": "3 Compositional Falsification Framework", "text": "In this section, the falsification problem for the falsification of the CPSML models is formalized as follows: \"We have two different models that we include in the CPSML models.\" (\"We\") \"We.\" (\"We\") \"We.\" (\"We\") \"We.\" (\"We.\") \"We.\" (\"We.\") \"We.\" (\"We.\") \"We.\" (\"We.\") \"We.\" (\"We.\") \"(\" We. \"(\" We. \")\" (\"We.\" (\"We.\") \"We.\" (\"We.\") \"(\" We. \"(\" We. \").\" (\"We.\") \"(\" We. \"(\" We. \").\" We. \"(\" We. \"We.\" (. \"We.\" We. \").\" We. \"We.\" (. \"We.\" We. \"We.\" (. \"We.\"). \"We.\" We. \"(.\" We. \"We.\"). \"We.\" (. \"We.\" We. \"We.\" (. \"We.\"). \"We.\" (. \"We.\" We. \"(.\"). \"We.\" (. \"We.\" We. (. \"We.\"). \"We.\" (. \"We.\" (. \"We. (.\" We. \"). (.\" We. (. \"We.\"). \"We. (.\" We. \"We.\"). (. \"We. (.\" We. \"We.\"). (. (. \"We.\" We. \"). (\" We. \"). (\" We. (. (\"We.\"). (\"We.\"). (\"We. (\" We. \"). (\" We. (. (\"We.\"). (\"We. (. (\" We. \"). (\" We. \"). (\" We. (\"We.\" We. (. \"). (.\" We. \"). (.\" We. (. (.). (. \"We. (.\" We."}, {"heading": "4 Machine Learning Analyzer", "text": "In this section, we define an ML analyzer that adapts the input of a model to its classifiers with spaces and identifies subsets of attribute vectors for which incorrect designations are predicted. Analysis involves constructing an approximation function that is used to study the original classifiers. In the face of a classifier f: X \u2192 Y, the ML analyzer determines a simpler function f: A \u2192 Y that approximates f on abstract domain A. The abstract domain of the function f \u0439 is analyzed and clusters of misclassifying abstract elements are identified. Specifying such elements are subsets of characteristics that are misclassified by the original classifier f."}, {"heading": "4.1 Feature Space Abstraction", "text": "Let X X be a subset of the attribute space of f: X \u2192 Y. Let \u2264 be a total order on a set A called an abstract set. An abstraction function is an injective function \u03b1: X-A that maps each attribute vector s-X to an abstract element \u03b1 (s) B-A. Conversely, we can map the input space of the CPS model to the attribute space of its classifiers. Second, abstract space can be used to analyze the classifiers in a compact area as opposed to intractable attribute spaces. First, they allow us to map the input space of the CPS model to the attribute space of its classifiers. Second, abstract space can be used to analyze the classifiers as opposed to intractable feature spaces. These concepts are illustrated in the following example, where a attribute space of the images is abstracted from a three-dimensional unit."}, {"heading": "4.2 Approximation of Learning Components", "text": "We now describe how the obtained approximation can be used to construct an approximation which vectors.Given a classifier f: X \u2192 Y and a restricted feature space X (1),.. (a), y (l)))), errf: (a), (a), (a), (a), (a), (a), (a), (a), (a), (e), (e), (e), (e), (e), (e), (e), (e), (e), (e), (e), (e), (e), (e), (e), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), c), c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c"}, {"heading": "5 Experimental Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Implementation Details", "text": "The falsification framework presented was implemented in a Matlab toolbox publicly available at http: / / github.com / tommasodreossi / FalsifCPSML. These are simulink models of the CPSML and STL specifications. It consists of a temporal logic falsifier and an ML analyzer that interact to falsify the given STL specification against the dissected Simulink model. As an STL falsifier, we chose the existing Breach [4] tool, while the ML analyzer was implemented from scratch. Implementation of the ML analyzer includes the Feature Space Abstractor and the ML Approximation Algorithm (see Section 4). The Feature Space Abstractor implements an image generator that specifies the abstracted feature vectors. The Approximate calculates the RAM, the Approximation Algorithm, the Approximation Technique of the RAL, the Approximation Polarity of the RAM, the ML, the Approximation Technique of the RAM, the ML, and the Approximation Polarity of the ML."}, {"heading": "5.2 Case Studies", "text": "In fact, most of them are able to save themselves. (...) Most of them are able to save themselves. (...) Most of them are not able to save themselves. (...) Most of them are not able to save themselves. (...) Most of them are not able to save themselves. (...) Most of them are not able to save themselves. (...) Most of them are not able to save themselves. (...) Most of them are not able to save themselves. (...) Most of them are not able to save themselves. (...) Most of them are not able to save themselves. (...) Most of them are not able to save themselves. (...) Most of them are not able to save themselves. (...) Most of them are not able to save themselves. (...)"}, {"heading": "6 Conclusion", "text": "We presented a compositional falsification framework for STL specifications against CPSML models based on the separate analysis of a CPS system and its ML components. We introduced an ML analyzer capable of abstracting feature spaces, approximate ML classifiers, and providing sets of misclassified feature vectors that can be used in the falsification process. We implemented our framework and demonstrated its effectiveness for an autonomous driving controller that uses perceptions based on deep neural networks. This work lays the groundwork for future advancements. We intend to improve our ML analyzer by investigating the automatic generation of feature space abstractions from given training sets. Another direction is to integrate other techniques for generating misclassifications of ML components (e.g. [15,9]) into our approach."}], "references": [{"title": "S-taliro: A tool for temporal logic falsification for hybrid systems", "author": ["Y. Annpureddy", "C. Liu", "G.E. Fainekos", "S. Sankaranarayanan"], "venue": "In Tools and Algorithms for the Construction and Analysis of Systems, TACAS, pages 254\u2013257,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2011}, {"title": "Selection of relevant features and examples in machine learning", "author": ["A.L. Blum", "P. Langley"], "venue": "Artificial intelligence, 97(1):245\u2013271,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1997}, {"title": "et al", "author": ["M. Bojarski", "D. Del Testa", "D. Dworakowski", "B. Firner", "B. Flepp", "P. Goyal", "L.D. Jackel", "M. Monfort", "U. Muller", "J. Zhang"], "venue": "End to end learning for self-driving cars. arXiv preprint arXiv:1604.07316,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2016}, {"title": "Breach, a toolbox for verification and parameter synthesis of hybrid systems", "author": ["A. Donz\u00e9"], "venue": "In Computer Aided Verification, CAV, pages 167\u2013170,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2010}, {"title": "Efficient guiding strategies for testing of temporal properties of hybrid systems", "author": ["T. Dreossi", "T. Dang", "A. Donz\u00e9", "J. Kapinski", "X. Jin", "J. Deshmukh"], "venue": "In NASA Formal Methods, NFM, pages 127\u2013142,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2015}, {"title": "C2E2: a verification tool for stateflow models", "author": ["P.S. Duggirala", "S. Mitra", "M. Viswanathan", "M. Potok"], "venue": "In International Conference on Tools and Algorithms for the Construction and Analysis of Systems, pages 68\u201382. Springer,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "Analysis of classifiers\u2019 robustness to adversarial perturbations", "author": ["A. Fawzi", "O. Fawzi", "P. Frossard"], "venue": "arXiv preprint arXiv:1502.02590,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2015}, {"title": "et al", "author": ["G. Hinto"], "venue": "Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups. IEEE Signal Processing Magazine, 29(6):82\u201397,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Safety verification of deep neural networks", "author": ["X. Huang", "M. Kwiatkowska", "S. Wang", "M. Wu"], "venue": "CoRR, abs/1610.06940,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2016}, {"title": "Caffe: Convolutional architecture for fast feature embedding", "author": ["Y. Jia", "E. Shelhamer", "J. Donahue", "S. Karayev", "J. Long", "R. Girshick", "S. Guadarrama", "T. Darrell"], "venue": "In ACM Multimedia Conference, ACMMM, pages 675\u2013678,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "In Advances in neural information processing systems, pages 1097\u20131105,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2012}, {"title": "Monitoring temporal properties of continuous signals", "author": ["O. Maler", "D. Nickovic"], "venue": "In Formal Techniques, Modelling and Analysis of Timed and Fault-Tolerant Systems, pages 152\u2013166. Springer,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2004}, {"title": "TensorFlow: Large-scale machine learning", "author": ["Mart\u0301\u0131n Abadi"], "venue": "on heterogeneous systems,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2015}, {"title": "Machine learning: An artificial intelligence approach", "author": ["R.S. Michalski", "J.G. Carbonell", "T.M. Mitchell"], "venue": "Springer Science & Business Media,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}, {"title": "Deep neural networks are easily fooled: High confidence predictions for unrecognizable images", "author": ["A. Nguyen", "J. Yosinski", "J. Clune"], "venue": "In Computer Vision and Pattern Recognition, CVPR, pages 427\u2013436. IEEE,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2015}, {"title": "Low-discrepancy and low-dispersion sequences", "author": ["H. Niederreiter"], "venue": "Journal of number theory, 30(1):51\u201370,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1988}, {"title": "Towards verified artificial intelligence", "author": ["S.A. Seshia", "D. Sadigh", "S.S. Sastry"], "venue": "CoRR, abs/1606.08514,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2016}, {"title": "Intriguing properties of neural networks", "author": ["C. Szegedy", "W. Zaremba", "I. Sutskever", "J. Bruna", "D. Erhan", "I. Goodfellow", "R. Fergus"], "venue": "arXiv:1312.6199,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2013}, {"title": "Development and evaluations of advanced emergency braking system algorithm for the commercial vehicle", "author": ["L. Taeyoung", "Y. Kyongsu", "K. Jangseop", "L. Jaewan"], "venue": "In Enhanced Safety of Vehicles Conference, ESV, pages 11\u20130290,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2011}, {"title": "Principles of risk minimization for learning theory", "author": ["V. Vapnik"], "venue": "In NIPS, pages 831\u2013838,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1991}], "referenceMentions": [{"referenceID": 1, "context": ", [2,14,10,8]).", "startOffset": 2, "endOffset": 13}, {"referenceID": 13, "context": ", [2,14,10,8]).", "startOffset": 2, "endOffset": 13}, {"referenceID": 9, "context": ", [2,14,10,8]).", "startOffset": 2, "endOffset": 13}, {"referenceID": 7, "context": ", [2,14,10,8]).", "startOffset": 2, "endOffset": 13}, {"referenceID": 2, "context": ", [3]).", "startOffset": 2, "endOffset": 5}, {"referenceID": 16, "context": "The safety-critical nature of such systems involving ML raises the need for formal methods [18].", "startOffset": 91, "endOffset": 95}, {"referenceID": 11, "context": "We formulate this question as the falsification problem for CPS models with ML components (CPSML): given a formal specification \u03c6 in signal temporal logic (STL) [12], and a CPSML model M , find an input for which M does not satisfy \u03c6.", "startOffset": 161, "endOffset": 165}, {"referenceID": 16, "context": "Third, the formal verification of ML components is a difficult, and somewhat ill-posed problem due to the complexity of the underlying ML algorithms, large feature spaces, and the lack of consensus on a formal definition of correctness [18].", "startOffset": 236, "endOffset": 240}, {"referenceID": 7, "context": "Further, our technique can handle any machine learning technique, including the methods based on deep neural networks [8] that have proved effective in many recent applications.", "startOffset": 118, "endOffset": 121}, {"referenceID": 3, "context": "Specifically, we use a temporal logic falsifier, Breach [4], in Steps (1) and (3) to partition a given input set into values that do and do not satisfy a given specification, and an ML analyzer in Step (2) to determine subsets of feature vectors that are misclassified by the ML components.", "startOffset": 56, "endOffset": 59}, {"referenceID": 9, "context": "5, we demonstrate the effectiveness of our approach on an Automatic Emergency Braking System (AEBS) involving an image classifier for obstacle detection based on deep neural networks using leading software packages Caffe [10] and TensorFlow [13].", "startOffset": 221, "endOffset": 225}, {"referenceID": 12, "context": "5, we demonstrate the effectiveness of our approach on an Automatic Emergency Braking System (AEBS) involving an image classifier for obstacle detection based on deep neural networks using leading software packages Caffe [10] and TensorFlow [13].", "startOffset": 241, "endOffset": 245}, {"referenceID": 3, "context": ", Breach [4], S-TaLiRo [1], RRT-REX [5], C2E2 [6]).", "startOffset": 9, "endOffset": 12}, {"referenceID": 0, "context": ", Breach [4], S-TaLiRo [1], RRT-REX [5], C2E2 [6]).", "startOffset": 23, "endOffset": 26}, {"referenceID": 4, "context": ", Breach [4], S-TaLiRo [1], RRT-REX [5], C2E2 [6]).", "startOffset": 36, "endOffset": 39}, {"referenceID": 5, "context": ", Breach [4], S-TaLiRo [1], RRT-REX [5], C2E2 [6]).", "startOffset": 46, "endOffset": 49}, {"referenceID": 16, "context": "While the verification of ML programs is less well-defined [18], recent efforts [19] show how even well trained neural networks can be sensitive to small adversarial perturbations, i.", "startOffset": 59, "endOffset": 63}, {"referenceID": 17, "context": "While the verification of ML programs is less well-defined [18], recent efforts [19] show how even well trained neural networks can be sensitive to small adversarial perturbations, i.", "startOffset": 80, "endOffset": 84}, {"referenceID": 19, "context": "Other efforts have tried to characterize the correctness of neural networks in terms of risk [21] (i.", "startOffset": 93, "endOffset": 97}, {"referenceID": 6, "context": ", probability of misclassifying a given input) or robustness [7] (i.", "startOffset": 61, "endOffset": 64}, {"referenceID": 14, "context": ", the minimal perturbation leading to a misclassification), while others proposed methods to generate pictures [16] or perturbations [15,9] in such a way to \u201cfool\u201d neural networks.", "startOffset": 111, "endOffset": 115}, {"referenceID": 8, "context": ", the minimal perturbation leading to a misclassification), while others proposed methods to generate pictures [16] or perturbations [15,9] in such a way to \u201cfool\u201d neural networks.", "startOffset": 133, "endOffset": 139}, {"referenceID": 11, "context": "We consider Signal Temporal Logic [12] (STL) as the language to specify properties to be verified against a CPSML model.", "startOffset": 34, "endOffset": 38}, {"referenceID": 3, "context": "This example illustrates how the compositional approach relies on tools, such as Breach [4], that compute validity domains and falsify STL specifications, as well as a ML analyzer.", "startOffset": 88, "endOffset": 91}, {"referenceID": 0, "context": "In this setting, we can define the abstraction and concretization functions \u03b1 and \u03b3 that relate the abstract set A = [0, 1] and X\u0303.", "startOffset": 117, "endOffset": 123}, {"referenceID": 15, "context": ", [17].", "startOffset": 2, "endOffset": 6}, {"referenceID": 9, "context": "We now analyze two image classifiers: the Caffe [10] version of AlexNet [11] and the Inception-v3 model of Tensorflow [13], both trained on the ImageNet database.", "startOffset": 48, "endOffset": 52}, {"referenceID": 10, "context": "We now analyze two image classifiers: the Caffe [10] version of AlexNet [11] and the Inception-v3 model of Tensorflow [13], both trained on the ImageNet database.", "startOffset": 72, "endOffset": 76}, {"referenceID": 12, "context": "We now analyze two image classifiers: the Caffe [10] version of AlexNet [11] and the Inception-v3 model of Tensorflow [13], both trained on the ImageNet database.", "startOffset": 118, "endOffset": 122}, {"referenceID": 3, "context": "As an STL falsifier, we chose the existing tool Breach [4], while the ML analyzer has been implemented from scratch.", "startOffset": 55, "endOffset": 58}, {"referenceID": 9, "context": "Our tool is interfaced with the deep learning frameworks Caffe [10] and Tensorflow [13].", "startOffset": 63, "endOffset": 67}, {"referenceID": 12, "context": "Our tool is interfaced with the deep learning frameworks Caffe [10] and Tensorflow [13].", "startOffset": 83, "endOffset": 87}, {"referenceID": 18, "context": "For the experimental evaluations, we consider a closed-loop Simulink model of a semi-autonomous vehicle with an Advanced Emergency Braking System (AEBS) [20] connected to an image classifier.", "startOffset": 153, "endOffset": 157}, {"referenceID": 0, "context": "Next, let us consider the Caffe image classifier and the ML analyzer presented in Section 4 that generates pictures from the abstract feature space A = [0, 1], where the dimensions of A determine the x and z displacements of a car and the brightness of a generated picture, respectively.", "startOffset": 152, "endOffset": 158}, {"referenceID": 3, "context": "88 and vs(0) \u2208 [4, 40]).", "startOffset": 15, "endOffset": 22}, {"referenceID": 8, "context": "[15,9]) into our approach.", "startOffset": 0, "endOffset": 6}], "year": 2017, "abstractText": "Cyber-physical systems (CPS), such as automotive systems, are starting to include sophisticated machine learning (ML) components. Their correctness, therefore, depends on properties of the inner ML modules. While learning algorithms aim to generalize from examples, they are only as good as the examples provided, and recent efforts have shown that they can produce inconsistent output under small adversarial perturbations. This raises the question: can the output from learning components can lead to a failure of the entire CPS? In this work, we address this question by formulating it as a problem of falsifying signal temporal logic (STL) specifications for CPS with ML components. We propose a compositional falsification framework where a temporal logic falsifier and a machine learning analyzer cooperate with the aim of finding falsifying executions of the considered model. The efficacy of the proposed technique is shown on an automatic emergency braking system model with a perception component based on deep neural networks.", "creator": "LaTeX with hyperref package"}}}