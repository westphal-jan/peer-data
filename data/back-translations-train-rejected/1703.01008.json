{"id": "1703.01008", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Mar-2017", "title": "End-to-End Task-Completion Neural Dialogue Systems", "abstract": "This paper presents an end-to-end learning framework for task-completion neural dialogue systems, which leverages supervised and reinforcement learning with various deep-learning models. The system is able to interface with a structured database, and interact with users for assisting them to access information and complete tasks such as booking movie tickets. Our experiments in a movie-ticket booking domain show the proposed system outperforms a modular-based dialogue system and is more robust to noise produced by other components in the system.", "histories": [["v1", "Fri, 3 Mar 2017 01:29:11 GMT  (1081kb,D)", "http://arxiv.org/abs/1703.01008v1", null], ["v2", "Thu, 9 Mar 2017 05:50:21 GMT  (1079kb,D)", "http://arxiv.org/abs/1703.01008v2", null], ["v3", "Tue, 19 Sep 2017 17:47:23 GMT  (1233kb,D)", "http://arxiv.org/abs/1703.01008v3", "11 pages. arXiv admin note: substantial text overlap witharXiv:1703.07055"]], "reviews": [], "SUBJECTS": "cs.CL cs.AI", "authors": ["xiujun li", "yun-nung chen", "lihong li", "jianfeng gao"], "accepted": false, "id": "1703.01008"}, "pdf": {"name": "1703.01008.pdf", "metadata": {"source": "CRF", "title": "End-to-End Task-Completion Neural Dialogue Systems", "authors": ["Xiujun Li", "Yun-Nung Chen", "Lihong Li", "Jianfeng Gao"], "emails": ["xiul@microsoft.com,", "y.v.chen@ieee.org"], "sections": [{"heading": null, "text": "This paper presents an end-to-end learning framework for neural completion dialog systems that harnesses supervised and enhanced learning with various deep learning models, capable of interacting with a structured database and interacting with users to facilitate access to information and complete tasks such as booking cinema tickets. Our experiments in a cinema ticket booking domain show that the proposed system outperforms a modular dialog system and is more resistant to noise generated by other components of the system."}, {"heading": "1 Introduction", "text": "In fact, the two are the best candidates able to make the shortlist."}, {"heading": "2 Proposed Framework", "text": "The proposed training framework is illustrated in Figure 1, which includes a user simulator (left part) and a neural dialog system (right part). In the user simulator, an agenda-based component is used to model the user at the dialog file level to control the conversation exchange generated to the user target, to ensure that the user behaves in a consistent, goal-oriented manner. An NLG module is used to generate texts in natural language corresponding to the actions of the user dialog. In a neural dialog system, an input phrase (detected utterance or text entry) passes through an LU module and becomes a corresponding semantic framework, and a DM, which includes a state tracker and a policy learner, is used to collect the semantics from each utterance, robust track1The code is available at http: / / github.com / MiuLab / TC-Botdialogue.the states that are generating the next conversation during the action."}, {"heading": "2.1 User Simulation", "text": "In the task fulfillment dialog setting, the user simulator first generates a user target. The agent does not know the user target, but tries to help the user achieve it during conversations, so the entire conversation exchange implicitly revolves around this target. A user target usually consists of two parts: Inform the user about slots for slot value pairs that serve as limitations to the user, and request slots for slots about the value of which the user has no information, but wants to receive the values from the agent during the call. User goals are generated with a labeled set of conversation data from Li et al. (2016) User Agenda Modeling: In the course of a dialogue, the user simulator receives a compact, stack-like representation called user agenda (Treasurer and Young, 2009), whereby the user status su is factored into an agenda and a goal G. The goal consists of constraints C and request R. At each time step, the user simulator generates the next action based on the user action."}, {"heading": "2.2 Neural Dialogue System", "text": "Language Comprehension (LU): A main task of LU is the automatic classification of the domain of a user query together with domain-specific intentions and the filling of a series of slots to form a semantic frame. The popular IOB format (in-out-begin) is used to represent the slot tags, as shown in Figure 2. The LU component is implemented with a single LSTM that simultaneously predicts and fills slots (Hakkani-Tuu et al., 2016). The weights of the LSTM model are trained using backpropagation to maximize the conditional probability of the training set labels. The predicted tag set is a concatenated series of IOB format slot tags and intention tags dialog; therefore, this model can be trained using all available dialog actions and statement pairs in our selected Dataset ner.Dialog (DM): The symbolic dialog LU output of classic DM tags can be used."}, {"heading": "3 End-to-End Reinforcement Learning", "text": "To learn the interaction policy of our system, we apply RL training in multiple ways, in which each component of the neural network can be finely tuned; the policy is presented as a deep Qnetwork (DQN) (Mnih et al., 2015) that takes the state of st as input, and the results Q (st, a) for all actions a. Two important DQN tricks are applied, changing the repetition strategy for the dialogue. During the training, we use greedy exploration and an experience buffer with dynamically varying buffer size. At each simulation stage, we simulate N dialogs and add this state buffer strategy (st, rt, st + 1) to reactivate the experience buffer for the training."}, {"heading": "4 Experiments and Discussions", "text": "During the call, the dialog system collects information about the customer's wishes and ultimately books the movie tickets. The environment then evaluates a binary result (success or failure) at the end of the call, based on (1) whether a movie is booked, and (2) whether the movie meets the user's limitations. Raw conversation data was collected via Amazon Mechanical Turk, with comments from domain experts. In total, we have labeled 280 dialogues, and the average number of turns per dialogue is about 11.2 sets of experiments are conducted in DM training, where two input formats are used to train the RL agents: (1) Framework-level semantics: When training or testing a policy based on semantic frameworks of the user's actions, a sound channel (Schatzmann et al., 2007) is used to simulate the LU errors and loud communication between the user and the agent. (2) Natural user language: At the natural user level, a frame of the system can be trained or a natural user's retention on the system."}, {"heading": "5 Conclusion", "text": "This paper presents an end-to-end learning framework for neural dialog systems for task fulfillment. Our experiments show that reinforcement learning systems outperform rule-based agents and are more robust to enable natural interactions with users in real-world task fulfillment scenarios."}, {"heading": "A Dataset Annotation", "text": "The data includes 11 dialog files and 29 slots. Most slots are informable slots that the user can use to narrow the search, and some are requestable slots, of which the user can query values from the agent. For example, a number of people cannot be a requestable slot because the user knows how many tickets he or she wants to buy. Table 1 lists all annotated dialog files and slots in detail."}, {"heading": "B Experimental Detail", "text": "B.1 Noise Channel Setup There are two types of Noise Channel in the error model: the Intention Level and the Slot Level, where three possible slot errors are introduced: \u2022 Slot deletion: to simulate the scenario that the slot was not detected by the NLU; \u2022 Wrong Slot Value: to simulate the scenario that the slot name was detected correctly but the slot value was not detected correctly, e.g. incorrect word segmentation; \u2022 Wrong Slot: to simulate the scenario that both the slot and its value were not detected correctly. In our setting, we use the Noise Channel error rate 0.05 to randomly simulate the slot errors for user rotations, so that the DM can be more robust to loud input by the learned LU or NLG.B.2 parameter setting In our experiments we use the same parameter setting. For the NLG decoder decoder we use the bar size = 3 to establish a balance between performance and speed."}, {"heading": "C Sample Dialogues", "text": "Table 2 shows a success and failure dialog example generated by the rules-based agent and the RL agent interacting with the user simulator in the movie booking area. To be informative, we also explicitly show the user target at the top of the dialog, but the agent does not know about the user target, his goal is to help the user achieve this goal and book the right movie tickets."}], "references": [{"title": "Learning end-to-end goal-oriented dialog", "author": ["Antoine Bordes", "Jason Weston."], "venue": "arXiv preprint arXiv:1605.07683 .", "citeRegEx": "Bordes and Weston.,? 2016", "shortCiteRegEx": "Bordes and Weston.", "year": 2016}, {"title": "Syntax or semantics? knowledge-guided joint semantic frame parsing", "author": ["Yun-Nung Chen", "Dilek Hakanni-T\u00fcr", "Gokhan Tur", "Asli Celikyilmaz", "Jianfeng Gao", "Li Deng."], "venue": "Proceedings of SLT .", "citeRegEx": "Chen et al\\.,? 2016", "shortCiteRegEx": "Chen et al\\.", "year": 2016}, {"title": "End-to-end reinforcement learning of dialogue agents for information access", "author": ["Bhuwan Dhingra", "Lihong Li", "Xiujun Li", "Jianfeng Gao", "Yun-Nung Chen", "Faisal Ahmed", "Li Deng."], "venue": "arXiv preprint arXiv:1609.00777 .", "citeRegEx": "Dhingra et al\\.,? 2016", "shortCiteRegEx": "Dhingra et al\\.", "year": 2016}, {"title": "Multi-domain joint semantic frame parsing using bi-directional rnn-lstm", "author": ["Dilek Hakkani-T\u00fcr", "Gokhan Tur", "Asli Celikyilmaz", "Yun-Nung Chen", "Jianfeng Gao", "Li Deng", "YeYi Wang."], "venue": "Proceedings of Interspeech. pages 715\u2013719.", "citeRegEx": "Hakkani.T\u00fcr et al\\.,? 2016", "shortCiteRegEx": "Hakkani.T\u00fcr et al\\.", "year": 2016}, {"title": "Extrinsic evaluation of dialog state tracking and predictive metrics for dialog policy optimization", "author": ["Sungjin Lee."], "venue": "15th Annual Meeting of the Special Interest Group on Discourse and Dialogue. page 310.", "citeRegEx": "Lee.,? 2014", "shortCiteRegEx": "Lee.", "year": 2014}, {"title": "A user simulator for task-completion dialogues", "author": ["Xiujun Li", "Zachary C Lipton", "Bhuwan Dhingra", "Lihong Li", "Jianfeng Gao", "Yun-Nung Chen."], "venue": "arXiv preprint arXiv:1612.05688 .", "citeRegEx": "Li et al\\.,? 2016", "shortCiteRegEx": "Li et al\\.", "year": 2016}, {"title": "Human-level control through deep reinforcement learning", "author": ["Dharshan Kumaran", "Daan Wierstra", "Shane Legg", "Demis Hassabis."], "venue": "Nature 518:529\u2013533.", "citeRegEx": "Kumaran et al\\.,? 2015", "shortCiteRegEx": "Kumaran et al\\.", "year": 2015}, {"title": "Creating natural dialogs in the carnegie mellon communicator system", "author": ["Alexander I Rudnicky", "Eric H Thayer", "Paul C Constantinides", "Chris Tchou", "R Shern", "Kevin A Lenzo", "Wei Xu", "Alice Oh."], "venue": "Eurospeech.", "citeRegEx": "Rudnicky et al\\.,? 1999", "shortCiteRegEx": "Rudnicky et al\\.", "year": 1999}, {"title": "Error simulation for training statistical dialogue systems", "author": ["Jost Schatzmann", "Blaise Thomson", "Steve Young."], "venue": "IEEE Workshop on Automatic Speech Recognition & Understanding.", "citeRegEx": "Schatzmann et al\\.,? 2007", "shortCiteRegEx": "Schatzmann et al\\.", "year": 2007}, {"title": "The hidden agenda user simulation model", "author": ["Jost Schatzmann", "Steve Young."], "venue": "IEEE transactions on audio, speech, and language processing 17(4):733\u2013747.", "citeRegEx": "Schatzmann and Young.,? 2009", "shortCiteRegEx": "Schatzmann and Young.", "year": 2009}, {"title": "Prioritized experience replay", "author": ["Tom Schaul", "John Quan", "Ioannis Antonoglou", "David Silver."], "venue": "arXiv:1511.05952 .", "citeRegEx": "Schaul et al\\.,? 2015", "shortCiteRegEx": "Schaul et al\\.", "year": 2015}, {"title": "Continuously learning neural dialogue management", "author": ["Pei-Hao Su", "Milica Gasic", "Nikola Mrksic", "Lina RojasBarahona", "Stefan Ultes", "David Vandyke", "TsungHsien Wen", "Steve Young."], "venue": "arXiv:1606.02689 .", "citeRegEx": "Su et al\\.,? 2016", "shortCiteRegEx": "Su et al\\.", "year": 2016}, {"title": "A networkbased end-to-end trainable task-oriented dialogue system", "author": ["Tsung-Hsien Wen", "Milica Gasic", "Nikola Mrksic", "Lina M Rojas-Barahona", "Pei-Hao Su", "Stefan Ultes", "David Vandyke", "Steve Young."], "venue": "arXiv preprint arXiv:1604.04562 .", "citeRegEx": "Wen et al\\.,? 2016", "shortCiteRegEx": "Wen et al\\.", "year": 2016}, {"title": "Semantically conditioned lstm-based natural language generation for spoken dialogue systems", "author": ["Tsung-Hsien Wen", "Milica Gasic", "Nikola Mrksic", "PeiHao Su", "David Vandyke", "Steve Young."], "venue": "arXiv preprint arXiv:1508.01745 .", "citeRegEx": "Wen et al\\.,? 2015", "shortCiteRegEx": "Wen et al\\.", "year": 2015}, {"title": "The dialog state tracking challenge", "author": ["Jason Williams", "Antoine Raux", "Deepak Ramachandran", "Alan Black."], "venue": "Proceedings of the SIGDIAL 2013 Conference. pages 404\u2013413.", "citeRegEx": "Williams et al\\.,? 2013", "shortCiteRegEx": "Williams et al\\.", "year": 2013}, {"title": "Towards end-to-end learning for dialog state tracking and management using deep reinforcement learning", "author": ["Tiancheng Zhao", "Maxine Eskenazi."], "venue": "arXiv preprint arXiv:1606.02560 .", "citeRegEx": "Zhao and Eskenazi.,? 2016", "shortCiteRegEx": "Zhao and Eskenazi.", "year": 2016}, {"title": "JUPITER: a telephonebased conversational interface for weather information", "author": ["Victor Zue", "Stephanie Seneff", "James R Glass", "Joseph Polifroni", "Christine Pao", "Timothy J Hazen", "Lee Hetherington."], "venue": "IEEE Transactions on speech and audio pro-", "citeRegEx": "Zue et al\\.,? 2000", "shortCiteRegEx": "Zue et al\\.", "year": 2000}, {"title": "Conversational interfaces: Advances and challenges", "author": ["Victor W Zue", "James R Glass."], "venue": "Proceedings of the IEEE 88(8):1166\u20131180.", "citeRegEx": "Zue and Glass.,? 2000", "shortCiteRegEx": "Zue and Glass.", "year": 2000}], "referenceMentions": [{"referenceID": 7, "context": "Traditional systems have a rather complex and modular pipelines, containing a language understanding (LU) module, a dialogue manager (DM), and a natural language generation (NLG) component (Rudnicky et al., 1999; Zue et al., 2000; Zue and Glass, 2000).", "startOffset": 189, "endOffset": 251}, {"referenceID": 16, "context": "Traditional systems have a rather complex and modular pipelines, containing a language understanding (LU) module, a dialogue manager (DM), and a natural language generation (NLG) component (Rudnicky et al., 1999; Zue et al., 2000; Zue and Glass, 2000).", "startOffset": 189, "endOffset": 251}, {"referenceID": 17, "context": "Traditional systems have a rather complex and modular pipelines, containing a language understanding (LU) module, a dialogue manager (DM), and a natural language generation (NLG) component (Rudnicky et al., 1999; Zue et al., 2000; Zue and Glass, 2000).", "startOffset": 189, "endOffset": 251}, {"referenceID": 11, "context": "Wen et al. (2016) and Bordes and Weston (2016) introduced a network-based end-to-end trainable task-oriented dialogue system, which treated dialogue system learning as the problem of learning a mapping from dialogue histories to system responses, and applied an encoder-decoder model to train the whole system.", "startOffset": 0, "endOffset": 18}, {"referenceID": 0, "context": "(2016) and Bordes and Weston (2016) introduced a network-based end-to-end trainable task-oriented dialogue system, which treated dialogue system learning as the problem of learning a mapping from dialogue histories to system responses, and applied an encoder-decoder model to train the whole system.", "startOffset": 11, "endOffset": 36}, {"referenceID": 2, "context": "Dhingra et al. (2016) proposed an end-to-end differentiable KB-Infobot to provide the solutions to the first two issues, but the last one remained.", "startOffset": 0, "endOffset": 22}, {"referenceID": 5, "context": "The user goals are generated using a labeled set of conversational data from Li et al. (2016).", "startOffset": 77, "endOffset": 94}, {"referenceID": 9, "context": "User Agenda Modeling: During the course of a dialogue, the user simulator maintains a compact, stack-like representation called user agenda (Schatzmann and Young, 2009), where the user state su is factored into an agenda A and a goal G.", "startOffset": 140, "endOffset": 168}, {"referenceID": 13, "context": "Then a post-processing scan is performed to replace the slot placeholders with their actual values (Wen et al., 2015).", "startOffset": 99, "endOffset": 117}, {"referenceID": 3, "context": "The LU component is implemented with a single LSTM, which performs intent prediction and slot filling simultaneously (Hakkani-T\u00fcr et al., 2016; Chen et al., 2016).", "startOffset": 117, "endOffset": 162}, {"referenceID": 1, "context": "The LU component is implemented with a single LSTM, which performs intent prediction and slot filling simultaneously (Hakkani-T\u00fcr et al., 2016; Chen et al., 2016).", "startOffset": 117, "endOffset": 162}, {"referenceID": 11, "context": "Instead of explicitly incorporating the state tracking labels, this paper learns the system actions with implicit dialogue states, so that the proposed DM can be more flexible and robust to the noises propagated from the previous components (Su et al., 2016).", "startOffset": 241, "endOffset": 258}, {"referenceID": 4, "context": "Dialogue state tracking is the process of constantly updating the state of the dialogue, and Lee (2014) showed that there is a positive correlation between state tracking performance and dialogue performance.", "startOffset": 93, "endOffset": 104}, {"referenceID": 4, "context": "Dialogue state tracking is the process of constantly updating the state of the dialogue, and Lee (2014) showed that there is a positive correlation between state tracking performance and dialogue performance. Most production systems use rule-based heuristics manually defined by dialogue trees to update the dialogue states based on the highly confident output from LU. Williams et al. (2013) formalized the tracking problem as a supervised sequence labeling task, where the input is LU outputs and the output is the true slot values, and the state tracker\u2019s results can be translated into a dialogue policy.", "startOffset": 93, "endOffset": 393}, {"referenceID": 4, "context": "Dialogue state tracking is the process of constantly updating the state of the dialogue, and Lee (2014) showed that there is a positive correlation between state tracking performance and dialogue performance. Most production systems use rule-based heuristics manually defined by dialogue trees to update the dialogue states based on the highly confident output from LU. Williams et al. (2013) formalized the tracking problem as a supervised sequence labeling task, where the input is LU outputs and the output is the true slot values, and the state tracker\u2019s results can be translated into a dialogue policy. Zhao and Eskenazi (2016) proposed to jointly train the state tracker and the policy in order to optimize the system actions more robustly.", "startOffset": 93, "endOffset": 634}, {"referenceID": 10, "context": "The experience replay strategy is critical for RL training (Schaul et al., 2015).", "startOffset": 59, "endOffset": 80}, {"referenceID": 8, "context": "Two sets of experiments are conducted in DM training, where two input formats are used for training the RL agents: (1) frame-level semantics: when training or testing a policy based on semantic frames of user actions, a noise channel (Schatzmann et al., 2007) is used to simulate LU errors and noisy communications between the user and the agent.", "startOffset": 234, "endOffset": 259}], "year": 2017, "abstractText": "This paper presents an end-to-end learning framework for task-completion neural dialogue systems, which leverages supervised and reinforcement learning with various deep-learning models. The system is able to interface with a structured database, and interact with users for assisting them to access information and complete tasks such as booking movie tickets. Our experiments in a movie-ticket booking domain show the proposed system outperforms a modular-based dialogue system and is more robust to noise produced by other components in the system.", "creator": "LaTeX with hyperref package"}}}