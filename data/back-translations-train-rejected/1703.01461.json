{"id": "1703.01461", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Mar-2017", "title": "Addressing Appearance Change in Outdoor Robotics with Adversarial Domain Adaptation", "abstract": "Appearance changes due to weather and seasonal conditions represent a strong impediment to the robust implementation of machine learning systems in outdoor robotics. While the model is optimised for the training domain it will deliver degraded performance in application domains that underlie distributional shifts caused by these changes. Traditionally, this problem has been addressed via the collection of labelled data in multiple domains or by imposing priors on the type of shift between both domains. We frame the problem in the context of unsupervised domain adaptation and apply an adversarial framework to train a deep neural network with the additional objective to align features across domains. This approach benefits from adding unlabelled data and is generally applicable to many state-of-the-art architectures. Moreover, as adversarial training is notoriously hard to stabilise, we first perform an extensive ablation study on a surrogate classification task underlying the same appearance change and then apply the distilled insights to the problem of free-space segmentation for motion planning.", "histories": [["v1", "Sat, 4 Mar 2017 14:28:51 GMT  (1293kb,D)", "http://arxiv.org/abs/1703.01461v1", null], ["v2", "Sun, 17 Sep 2017 13:44:28 GMT  (1438kb,D)", "http://arxiv.org/abs/1703.01461v2", "In Proceedings of the 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2017)"]], "reviews": [], "SUBJECTS": "cs.RO cs.LG", "authors": ["markus wulfmeier", "alex bewley", "ingmar posner"], "accepted": false, "id": "1703.01461"}, "pdf": {"name": "1703.01461.pdf", "metadata": {"source": "CRF", "title": "Addressing Appearance Change in Outdoor Robotics with Adversarial Domain Adaptation", "authors": ["Markus Wulfmeier", "Alex Bewley", "Ingmar Posner"], "emails": ["ingmar@robots.ox.ac.uk"], "sections": [{"heading": null, "text": "In fact, it is such that most of them will be able to move into another world, in which they are able, in which they are able to integrate themselves, in which they are able, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they, in which they, in which they live, in which they live, in which they live, in which they, in which they are able to change, in which they are able to change, in which they are able to change the world, in which they are able to change, in which they are able to"}, {"heading": "II. RELATED WORK", "text": "While Lai and Fox [4] presented an exemplary approach to aligning spin-image characteristics from web-based 3D models to dense laser scans, color-constant transformation [15] is often applied directly to the image to achieve the invariance of light for localization [16], visual teaching and repetition [1], and segmentation [3]. Other work in localization takes a multiview approach, either exploiting the temporal structure [17] or gaining multiple experiences covering different manifestations [2] to avoid changing the appearance. Neubert et al's work is the next approach in which they interpret synthetic images into the current season."}, {"heading": "III. ADVERSARIAL DOMAIN ADAPTATION", "text": "The primary goal of ADA is to maximize the performance of a supervised task not only in the source domain - where labels are available - but also in the unlabeled target domain. As a domain shift potentially exists between training domains and application domains, the approach attempts to align marginal feature distributions independently of labels for both domains to achieve their goal. Therefore, we train the encoder to attempt to evaluate the domain of a data sample and serve as density modeling. The training process works toward the marginal feature distributions of the source domain and target domain, which implicitly align the partial structural similarity of both domains."}, {"heading": "IV. ABLATION STUDY", "text": "It's not just the way in which people in the US and in other European countries are able to outdo themselves, but also the way in which they present themselves in the US and in other European countries. It's also the way in which they present themselves in the US and in other European countries. It's the way in which they present themselves in the US and in other countries. It's the way in which they present themselves in the US and in other countries. It's the way in which they present themselves in the US and in other countries. It's the way in which they spread in the US and in other countries of the world. It's the way in which they develop in the US and in Europe. It's the way in which they develop in the US and in the USA. It's the way in which they present themselves in the US and in other countries. It's the way in which they present themselves in the US and in other countries. It's the way in which they present themselves in the US and in other countries. It's the way in which way in which they present themselves in the US and in other countries. It's the way in which way in which they present themselves in the USA and in other countries. It's the way in which way in which they present themselves in the US and in which they present themselves in the USA and in other countries. It's the way in which way in which they present themselves in which they present themselves in the US and in which they present themselves in which they present themselves in the US and in which they present in which they present themselves in the USA and in other countries. It's the way in which it's the way in which way in which it's the way in which it's the way in which it's the way in which they present in which they present in the US and in which they present in which they present in the US and in which they present in the US and in which they present in which they present in which they present in which they present themselves in the US and in which they present in which they present themselves in the US and in which they present themselves in which they present themselves in which they present themselves in which they present themselves in the US and in which they present themselves in which they present themselves in which they present in which they present themselves in the US and in which they present in the US and in which they present in which they present themselves in which they present in which they present in which they present in which they"}, {"heading": "V. SEGMENTATION TASK", "text": "After optimizing for our surrogate task, we now apply the distilled insights for optimizing ADA to the task of open space segmentation as possible input data for motion planning systems. We use the fully revolutionary FCN-VGG16 [12] architecture, which - similar to the classification tests - is divided into encoders and classifiers / discriminators. We place the split layer at the center of the architecture after the 4th Maxpool operation (see [12] for the exact architecture) with fixed capacity of the discriminator architecture and apply the confusion losses. Both source and target datasets comprise 1000 training and 100 test images based on a noon to early evening scenario, so that the domain shift is intuitively smaller than during the full day-night transfer of section IV-C. The segment markers are generated for open space / obstacles according to the Barnes et al al al [28] approach."}, {"heading": "VI. LIMITATIONS OF UNSUPERVISED ADVERSARIAL DOMAIN ADAPTATION", "text": "Although we have shown that domain customization is beneficial in many scenarios, it must be noted that the current approach has its limits when the differences between source and target domains are too great. As is evident from the day-to-night transfer scenario, the approach still leads to some improvement, but with greater variation in the underlying domains, the adverse loss of encoders could even lead to a reduction in performance if inappropriately weighted against the monitored loss. If adversarial loss dominates in such situations, the encoder functions may lose more information relevant to the monitored task. Finally, to overcome the limitation of significant domain shifts, semi-monitored approaches can be used to incorporate additional structures and align conditional distributions across characteristic representations comparable to the designations [26]."}, {"heading": "VII. DISCUSSION", "text": "However, a limited number of hyperparameters have a strong impact on a particular problem and can be adapted to stabilize and optimize the training process.While the detailed performance depends on architecture and task, we found the following main factors for performance optimization: \u2022 Using relevant initializations including monitored warmups helps guide the training process. \u2022 Applying the confusion loss for the encoder allows for better balancing and stabilization. \u2022 The optimal position for the split layer is the middle network. Application in earlier layers in particular can significantly reduce the usefulness. In addition to the above main evaluation, we tested the influence of other advancements from the associated GAN framework. It was found that neither mini-batch discriminator [33] nor discriminator noise [33] have made significant advances. This is justified as the former address generator mode breakdown, which will be less problematic in the context of ADA, as the more flexible loss leads to supervised solutions."}, {"heading": "VIII. CONCLUSION AND FUTURE WORK", "text": "In this paper, we raise the common problem of changing the appearance of outdoor robotics as an adaptation problem to the respective field of application and use the current adversary paradigm to improve the performance of existing architectures in unlabeled areas. While instabilities in the adversary training can hinder the expansion to large-scale problems, our extensive tests on a substitution task with moderate complexity reveal the most important factors. With this assessment, we hope to pave the way for further application to tasks in the real world, especially in the context of autonomous mobility, where strong structural similarities between different areas may exist, e.g. based on spatial overlapping of driven routes.Finally, in addition to dealing with changes in appearance, we see many potential applications of ADA in robotics, where sensor models can change or even be transferred from a simulated virtual environment to improve their performance in the real world.Finally, the application of ADA represents a good opportunity to address the use of curriculum to address shifts in these areas, as shown in this paper."}], "references": [{"title": "It\u2019s not easy seeing green: Lighting-resistant stereo visual teach & repeat using color-constant images", "author": ["Michael Paton", "Kirk MacTavish", "Chris J Ostafew", "Timothy D Barfoot"], "venue": "In Robotics and Automation (ICRA),", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "Experience-based Navigation for Long-term Localisation", "author": ["Winston Churchill", "Paul Newman"], "venue": "The International Journal of Robotics Research (IJRR),", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2013}, {"title": "Illumination invariant imaging: Applications in robust vision-based localisation, mapping and classification for autonomous vehicles", "author": ["Will Maddern", "Alex Stewart", "Colin McManus", "Ben Upcroft", "Winston Churchill", "Paul Newman"], "venue": "In Proceedings of the Visual Place Recognition in Changing Environments Workshop, IEEE International Conference on Robotics and Automation", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2014}, {"title": "3d laser scan classification using web data and domain adaptation", "author": ["Kevin Lai", "Dieter Fox"], "venue": "In Robotics: Science and Systems,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2009}, {"title": "Towards adapting deep visuomotor representations from simulated to real environments", "author": ["Eric Tzeng", "Coline Devin", "Judy Hoffman", "Chelsea Finn", "Xingchao Peng", "Sergey Levine", "Kate Saenko", "Trevor Darrell"], "venue": "arXiv preprint arXiv:1511.07111,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "Domain adaptation for statistical classifiers", "author": ["Hal Daume III", "Daniel Marcu"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2006}, {"title": "Direct importance estimation with model selection and its application to covariate shift adaptation", "author": ["Masashi Sugiyama", "Shinichi Nakajima", "Hisashi Kashima", "Paul V Buenau", "Motoaki Kawanabe"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2008}, {"title": "Generative adversarial nets", "author": ["Ian Goodfellow", "Jean Pouget-Abadie", "Mehdi Mirza", "Bing Xu", "David Warde-Farley", "Sherjil Ozair", "Aaron Courville", "Yoshua Bengio"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}, {"title": "Learning from simulated and unsupervised images through adversarial training", "author": ["Ashish Shrivastava", "Tomas Pfister", "Oncel Tuzel", "Josh Susskind", "Wenda Wang", "Russ Webb"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2016}, {"title": "Domain separation networks", "author": ["Konstantinos Bousmalis", "George Trigeorgis", "Nathan Silberman", "Dilip Krishnan", "Dumitru Erhan"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2016}, {"title": "Imagenet classification with deep convolutional neural networks. In Advances in neural information processing", "author": ["Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E Hinton"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2012}, {"title": "Fully convolutional networks for semantic segmentation", "author": ["Jonathan Long", "Evan Shelhamer", "Trevor Darrell"], "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2015}, {"title": "NIPS 2016 tutorial", "author": ["Ian J. Goodfellow"], "venue": "Generative adversarial networks. CoRR,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2017}, {"title": "Towards principled methods for training generative adversarial networks", "author": ["Martin Arjovsky", "L\u00e9on Bottou"], "venue": "In NIPS 2016 Workshop on Adversarial Training. In review for ICLR,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2017}, {"title": "Study of the photodetector characteristics of a camera for color constancy in natural scenes", "author": ["Sivalogeswaran Ratnasingam", "Steve Collins"], "venue": "JOSA A,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2010}, {"title": "Dealing with shadows: Capturing intrinsic scene appearance for imagebased outdoor localisation", "author": ["Peter Corke", "Rohan Paul", "Winston Churchill", "Paul Newman"], "venue": "In Intelligent Robots and Systems (IROS),", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2013}, {"title": "Seqslam: Visual route-based navigation for sunny summer days and stormy winter nights", "author": ["Michael J Milford", "Gordon F Wyeth"], "venue": "In Robotics and Automation (ICRA),", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2012}, {"title": "Appearance change prediction for long-term navigation across seasons", "author": ["Peer Neubert", "Niko Sunderhauf", "Peter Protzel"], "venue": "In Mobile Robots (ECMR),", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2013}, {"title": "Analysis of representations for domain adaptation", "author": ["Shai Ben-David", "John Blitzer", "Koby Crammer", "Fernando Pereira"], "venue": "Advances in neural information processing systems,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2007}, {"title": "Unsupervised pixel-level domain adaptation  with generative adversarial networks", "author": ["Konstantinos Bousmalis", "Nathan Silberman", "David Dohan", "Dumitru Erhan", "Dilip Krishnan"], "venue": "arXiv preprint arXiv:1612.05424,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2016}, {"title": "SSPP- DAN: Deep Domain Adaptation Network for Face Recognition with Single Sample Per Person. page 5, feb 2017", "author": ["Sungeun Hong", "Woobin Im", "Jongbin Ryu", "Hyun S. Yang"], "venue": null, "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2017}, {"title": "Deep transfer learning with joint adaptation", "author": ["Mingsheng Long", "Jianmin Wang", "Michael I. Jordan"], "venue": "networks. CoRR,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2016}, {"title": "Correlation alignment for unsupervised domain adaptation", "author": ["Baochen Sun", "Jiashi Feng", "Kate Saenko"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1939}, {"title": "Domain-Adversarial Training of Neural Networks", "author": ["Yaroslav Ganin", "Evgeniya Ustinova", "Hana Ajakan", "Pascal Germain", "Hugo Larochelle", "Fran\u00e7ois Laviolette", "Mario Marchand", "Victor Lempitsky", "Urun Dogan", "Marius Kloft", "Francesco Orabona", "Tatiana Tommasi"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2016}, {"title": "Simultaneous deep transfer across domains and tasks", "author": ["Eric Tzeng", "Judy Hoffman", "Trevor Darrell", "Kate Saenko"], "venue": "In Proceedings of the IEEE International Conference on Computer Vision,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2015}, {"title": "Unsupervised domain adaptation in brain lesion segmentation with adversarial networks", "author": ["Konstantinos Kamnitsas", "Christian F. Baumgartner", "Christian Ledig", "Virginia F.J. Newcombe", "Joanna P. Simpson", "Andrew D. Kane", "David K. Menon", "Aditya Nori", "Antonio Criminisi", "Daniel Rueckert", "Ben Glocker"], "venue": null, "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2016}, {"title": "Find your own way: Weakly-supervised segmentation of path proposals for urban autonomy", "author": ["Dan Barnes", "William P. Maddern", "Ingmar Posner"], "venue": null, "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2016}, {"title": "Year, 1000km: The Oxford RobotCar Dataset", "author": ["Will Maddern", "Geoff Pascoe", "Chris Linegar", "Paul Newman"], "venue": "The International Journal of Robotics Research (IJRR),", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2016}, {"title": "What makes imagenet good for transfer learning", "author": ["Mi-Young Huh", "Pulkit Agrawal", "Alexei A. Efros"], "venue": null, "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2016}, {"title": "Imagenet large scale visual recognition challenge", "author": ["Olga Russakovsky", "Jia Deng", "Hao Su", "Jonathan Krause", "Sanjeev Satheesh", "Sean Ma", "Zhiheng Huang", "Andrej Karpathy", "Aditya Khosla", "Michael Bernstein"], "venue": "International Journal of Computer Vision,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2015}, {"title": "Image-toimage translation with conditional adversarial networks", "author": ["Phillip Isola", "Jun-Yan Zhu", "Tinghui Zhou", "Alexei A Efros"], "venue": "arXiv preprint arXiv:1611.07004,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2016}, {"title": "Improved techniques for training gans", "author": ["Tim Salimans", "Ian Goodfellow", "Wojciech Zaremba", "Vicki Cheung", "Alec Radford", "Xi Chen"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2016}], "referenceMentions": [{"referenceID": 0, "context": "Dealing with these changes becomes relevant in all modules of the robotic perception system including localisation [1], mapping [2] and obstacle detection [3].", "startOffset": 115, "endOffset": 118}, {"referenceID": 1, "context": "Dealing with these changes becomes relevant in all modules of the robotic perception system including localisation [1], mapping [2] and obstacle detection [3].", "startOffset": 128, "endOffset": 131}, {"referenceID": 2, "context": "Dealing with these changes becomes relevant in all modules of the robotic perception system including localisation [1], mapping [2] and obstacle detection [3].", "startOffset": 155, "endOffset": 158}, {"referenceID": 3, "context": "Methods for domain adaptation have already found success in robotics for transfer from 3D models to laser data [4] or from simulation to real images collected", "startOffset": 111, "endOffset": 114}, {"referenceID": 4, "context": "indoors [5].", "startOffset": 8, "endOffset": 11}, {"referenceID": 5, "context": "adaptation problem have focused on modelling the density of the source and target distributions separately [6] or with imposed prior structure [7].", "startOffset": 107, "endOffset": 110}, {"referenceID": 6, "context": "adaptation problem have focused on modelling the density of the source and target distributions separately [6] or with imposed prior structure [7].", "startOffset": 143, "endOffset": 146}, {"referenceID": 7, "context": "Recently, generative adversarial networks (GAN) were proposed [8] as a framework to model any arbitrary distribution where a generating network is optimised to produce data indistinguishable from real data as considered by a discriminating network.", "startOffset": 62, "endOffset": 65}, {"referenceID": 8, "context": "domain adaption [9], [10].", "startOffset": 16, "endOffset": 19}, {"referenceID": 9, "context": "domain adaption [9], [10].", "startOffset": 21, "endOffset": 25}, {"referenceID": 10, "context": "To demonstrate the widespread applicability of ADA with this schema, we modify two popular network architectures, AlexNet [11] and FCN-VGG16 [12] which are known to work well for the tasks of classification and pixel-wise image segmentation respectively.", "startOffset": 122, "endOffset": 126}, {"referenceID": 11, "context": "To demonstrate the widespread applicability of ADA with this schema, we modify two popular network architectures, AlexNet [11] and FCN-VGG16 [12] which are known to work well for the tasks of classification and pixel-wise image segmentation respectively.", "startOffset": 141, "endOffset": 145}, {"referenceID": 7, "context": "Due to the documented evidence of training instability of adversarial training procedures [8], [13], [14], we first use", "startOffset": 90, "endOffset": 93}, {"referenceID": 12, "context": "Due to the documented evidence of training instability of adversarial training procedures [8], [13], [14], we first use", "startOffset": 95, "endOffset": 99}, {"referenceID": 13, "context": "Due to the documented evidence of training instability of adversarial training procedures [8], [13], [14], we first use", "startOffset": 101, "endOffset": 105}, {"referenceID": 11, "context": "VGG16 [12] baseline.", "startOffset": 6, "endOffset": 10}, {"referenceID": 3, "context": "Lai and Fox [4] presented an exemplar based approach to align spin-image features from web based 3D models to dense laser scan.", "startOffset": 12, "endOffset": 15}, {"referenceID": 14, "context": "For visual appearance, the colour-constant transform [15] is commonly applied directly on the image to achieve lighting invariance for localisation [16], visual teach and repeat [1] and segmentation [3].", "startOffset": 53, "endOffset": 57}, {"referenceID": 15, "context": "For visual appearance, the colour-constant transform [15] is commonly applied directly on the image to achieve lighting invariance for localisation [16], visual teach and repeat [1] and segmentation [3].", "startOffset": 148, "endOffset": 152}, {"referenceID": 0, "context": "For visual appearance, the colour-constant transform [15] is commonly applied directly on the image to achieve lighting invariance for localisation [16], visual teach and repeat [1] and segmentation [3].", "startOffset": 178, "endOffset": 181}, {"referenceID": 2, "context": "For visual appearance, the colour-constant transform [15] is commonly applied directly on the image to achieve lighting invariance for localisation [16], visual teach and repeat [1] and segmentation [3].", "startOffset": 199, "endOffset": 202}, {"referenceID": 16, "context": "Other works in localisation take a multiview approach by either exploiting temporal structure [17] or by accumulating multiple experiences covering different appearances [2] to avoid the issue of modelling appearance change.", "startOffset": 94, "endOffset": 98}, {"referenceID": 1, "context": "Other works in localisation take a multiview approach by either exploiting temporal structure [17] or by accumulating multiple experiences covering different appearances [2] to avoid the issue of modelling appearance change.", "startOffset": 170, "endOffset": 173}, {"referenceID": 17, "context": "[18] is the closest to our approach where they learn synthesise stored images into the current season.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "[19] derived theoretical upper bounds on a classifiers performance.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "While unsupervised domain adaptation is an open research problem in theoretical and practical terms [10], [20], recent successes have shown the", "startOffset": 100, "endOffset": 104}, {"referenceID": 19, "context": "While unsupervised domain adaptation is an open research problem in theoretical and practical terms [10], [20], recent successes have shown the", "startOffset": 106, "endOffset": 110}, {"referenceID": 8, "context": "capability to train expressive, flexible models and address high dimensional input distributions and therefore made first steps in enabling real world applicability [9], [21].", "startOffset": 165, "endOffset": 168}, {"referenceID": 20, "context": "capability to train expressive, flexible models and address high dimensional input distributions and therefore made first steps in enabling real world applicability [9], [21].", "startOffset": 170, "endOffset": 174}, {"referenceID": 21, "context": "Long et al [22] focus on minimising the Maximum Mean Discrepancy for the feature distributions of multiple layers of the network architecture.", "startOffset": 11, "endOffset": 15}, {"referenceID": 22, "context": "[23] align second order statistics of layer activations for source and target domain.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "Recently, the field has been extended with adversarial methods to domain adaptation [24], [25] which have resulted in strong performance benefits [10].", "startOffset": 84, "endOffset": 88}, {"referenceID": 9, "context": "Recently, the field has been extended with adversarial methods to domain adaptation [24], [25] which have resulted in strong performance benefits [10].", "startOffset": 146, "endOffset": 150}, {"referenceID": 23, "context": "While the loss formulation for the discriminator stays consistent between most approaches, different objectives have been applied for the encoder, including the minimax formulation resulting from a \u2018gradient reversal layer\u2019 [24], and the confusion loss [26] that was found to address problems with vanishing gradients based on discriminator saturation in Generative Adversarial Networks (GAN) [8].", "startOffset": 224, "endOffset": 228}, {"referenceID": 24, "context": "While the loss formulation for the discriminator stays consistent between most approaches, different objectives have been applied for the encoder, including the minimax formulation resulting from a \u2018gradient reversal layer\u2019 [24], and the confusion loss [26] that was found to address problems with vanishing gradients based on discriminator saturation in Generative Adversarial Networks (GAN) [8].", "startOffset": 253, "endOffset": 257}, {"referenceID": 7, "context": "While the loss formulation for the discriminator stays consistent between most approaches, different objectives have been applied for the encoder, including the minimax formulation resulting from a \u2018gradient reversal layer\u2019 [24], and the confusion loss [26] that was found to address problems with vanishing gradients based on discriminator saturation in Generative Adversarial Networks (GAN) [8].", "startOffset": 393, "endOffset": 396}, {"referenceID": 25, "context": "These methods have recently been employed to address tasks in medical image segmentation [27], gaze estimation [9] and transfer for reinforcement learning [5].", "startOffset": 89, "endOffset": 93}, {"referenceID": 8, "context": "These methods have recently been employed to address tasks in medical image segmentation [27], gaze estimation [9] and transfer for reinforcement learning [5].", "startOffset": 111, "endOffset": 114}, {"referenceID": 4, "context": "These methods have recently been employed to address tasks in medical image segmentation [27], gaze estimation [9] and transfer for reinforcement learning [5].", "startOffset": 155, "endOffset": 158}, {"referenceID": 7, "context": "An alternative formulation is to train the encoder to maximise the discriminator\u2019s confusion [8], [26] (see Equation 6).", "startOffset": 93, "endOffset": 96}, {"referenceID": 24, "context": "An alternative formulation is to train the encoder to maximise the discriminator\u2019s confusion [8], [26] (see Equation 6).", "startOffset": 98, "endOffset": 102}, {"referenceID": 26, "context": "We focus for our main evaluation on the surrogate task of classification and extend the evaluation subsequently to image segmentation with focus on path proposals for autonomous driving [28].", "startOffset": 186, "endOffset": 190}, {"referenceID": 27, "context": "RobotCar Dataset that includes over 1000 km of driving data including images, LIDAR, GPS and INS data [29].", "startOffset": 102, "endOffset": 106}, {"referenceID": 10, "context": "The network architecture builds on AlexNet [11] and", "startOffset": 43, "endOffset": 47}, {"referenceID": 11, "context": "while we adapt the split between encoder and classifier / discriminator, the overall pipeline from image to location label is kept the same for all experiments, making this approach easy to apply to other common architectures such as FCNVGG [12], which underlies the segmentation experiments.", "startOffset": 241, "endOffset": 245}, {"referenceID": 28, "context": "1) Stabilising: Pretraining and Supervised Warm-up: Initialising network architectures via pretraining of convolutional layers on large and diverse datasets is generally known to speed up the learning process as well as leading to better generalisation [30].", "startOffset": 253, "endOffset": 257}, {"referenceID": 29, "context": "We evaluate pretrained convolutional layers for AlexNet (based on ImageNet classification task [31]) as well as a supervised warmup phase of 15 epochs which, based on a small test run, has been found to work well in a large range of evaluation settings.", "startOffset": 95, "endOffset": 99}, {"referenceID": 13, "context": "2) Balancing: Adversarial Loss: While the discriminator loss stays fixed across most recent work on ADA based on Equation 4, the choice of the encoder loss varies and has been shown to have significant influence on convergence properties and stability of training in Generative Adversarial Networks [14], which have strong similarities with ADA.", "startOffset": 299, "endOffset": 303}, {"referenceID": 23, "context": "two main generator objectives to consider are the minimax formulation (negated discriminator loss) which is equal to the gradient reversal layer [24] and the confusion loss [26], which has found to prevent vanishing gradients with saturated discriminator but displays higher variance in the gradients [14].", "startOffset": 145, "endOffset": 149}, {"referenceID": 24, "context": "two main generator objectives to consider are the minimax formulation (negated discriminator loss) which is equal to the gradient reversal layer [24] and the confusion loss [26], which has found to prevent vanishing gradients with saturated discriminator but displays higher variance in the gradients [14].", "startOffset": 173, "endOffset": 177}, {"referenceID": 13, "context": "two main generator objectives to consider are the minimax formulation (negated discriminator loss) which is equal to the gradient reversal layer [24] and the confusion loss [26], which has found to prevent vanishing gradients with saturated discriminator but displays higher variance in the gradients [14].", "startOffset": 301, "endOffset": 305}, {"referenceID": 23, "context": "The original minimax-loss formulation was successfully employed in a number of recent works [24], [10], however, we have found the tuning process more complex and obtained significantly stronger results based on the confusion loss.", "startOffset": 92, "endOffset": 96}, {"referenceID": 9, "context": "The original minimax-loss formulation was successfully employed in a number of recent works [24], [10], however, we have found the tuning process more complex and obtained significantly stronger results based on the confusion loss.", "startOffset": 98, "endOffset": 102}, {"referenceID": 10, "context": "1) Choice of Split Layer: The following evaluation focuses in particular on AlexNet [11], which we adapt by providing the feature output of a particular layer additionally to a discriminator module.", "startOffset": 84, "endOffset": 88}, {"referenceID": 29, "context": "Note, all models are initialised with pretrained convolutional layers pretrained on ImageNet [31].", "startOffset": 93, "endOffset": 97}, {"referenceID": 11, "context": "We use the fully convolutional FCN-VGG16 [12] architecture, which is split - similar to the classification tests - into encoder and classifier/discriminator.", "startOffset": 41, "endOffset": 45}, {"referenceID": 11, "context": "We set the split layer towards the middle of the architecture after the 4th maxpool operation (see [12] for the exact architecture) with fixed capacity of the discriminator architecture and apply the confusion loss.", "startOffset": 99, "endOffset": 103}, {"referenceID": 26, "context": "The segmentation labels are generated for free-space/obstacles following the approach of Barnes et al [28].", "startOffset": 102, "endOffset": 106}, {"referenceID": 30, "context": "As the segmentation output of the approach has a limited receptive field for each pixel location we additionally evaluate a patch-wise discriminator in line with research on imageto-image translation with conditional Generative Adversarial Networks (cGAN) [32].", "startOffset": 256, "endOffset": 260}, {"referenceID": 30, "context": "While Isola et al [32] have found the patch discriminator to work better for their task based on cGANs, it resulted in reduced accuracy for our application on ADA.", "startOffset": 18, "endOffset": 22}, {"referenceID": 24, "context": "over feature representations given the labels comparable to [26].", "startOffset": 60, "endOffset": 64}, {"referenceID": 31, "context": "It was found that neither mini-batch discriminator [33] nor discriminator noise [33] brought significant advances.", "startOffset": 51, "endOffset": 55}, {"referenceID": 31, "context": "It was found that neither mini-batch discriminator [33] nor discriminator noise [33] brought significant advances.", "startOffset": 80, "endOffset": 84}], "year": 2017, "abstractText": "Appearance changes due to weather and seasonal conditions represent a strong impediment to the robust implementation of machine learning systems in outdoor robotics. While the model is optimised for the training domain it will deliver degraded performance in application domains that underlie distributional shifts caused by these changes. Traditionally, this problem has been addressed via the collection of labelled data in multiple domains or by imposing priors on the type of shift between both domains. We frame the problem in the context of unsupervised domain adaptation and apply an adversarial framework to train a deep neural network with the additional objective to align features across domains. This approach benefits from adding unlabelled data and is generally applicable to many state-of-the-art architectures. Moreover, as adversarial training is notoriously hard to stabilise, we first perform an extensive ablation study on a surrogate classification task underlying the same appearance change and then apply the distilled insights to the problem of free-space segmentation for motion planning.", "creator": "LaTeX with hyperref package"}}}