{"id": "1703.01946", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Mar-2017", "title": "Metric Learning for Generalizing Spatial Relations to New Objects", "abstract": "Human-centered environments are rich with a wide variety of spatial relations between everyday objects. For autonomous robots to operate effectively in such environments, they should be able to reason about these relations and generalize them to objects with different shapes and sizes. For example, having learned to place a toy inside a basket, a robot should be able to generalize this concept using a spoon and a cup. This requires a robot to have the flexibility to learn arbitrary relations in a lifelong manner, making it challenging for an expert to pre-program it with sufficient knowledge to do so beforehand. In this paper, we address the problem of learning spatial relations by introducing a novel method from the perspective of distance metric learning. Our approach enables a robot to reason about the similarity between pairwise spatial relations, thereby enabling it to use its previous knowledge when presented with a new relation to imitate. We show how this makes it possible to learn arbitrary spatial relations from non-expert users using a small number of examples and in an interactive manner. Our extensive evaluation with real-world data demonstrates the effectiveness of our method in reasoning about a continuous spectrum of spatial relations and generalizing them to new objects.", "histories": [["v1", "Mon, 6 Mar 2017 16:13:17 GMT  (5474kb,D)", "https://arxiv.org/abs/1703.01946v1", "Submission to the IEEE/RSJ International Conference on Intelligent Robots and Systems"], ["v2", "Tue, 7 Mar 2017 12:47:56 GMT  (5474kb,D)", "http://arxiv.org/abs/1703.01946v2", "Under review at the 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems. The corresponding demo video can be found atthis http URL"], ["v3", "Mon, 24 Jul 2017 12:24:31 GMT  (5739kb,D)", "http://arxiv.org/abs/1703.01946v3", "Accepted at the 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems. The new Freiburg Spatial Relations Dataset and a demo video of our approach running on the PR-2 robot are available at our project website:this http URL"]], "COMMENTS": "Submission to the IEEE/RSJ International Conference on Intelligent Robots and Systems", "reviews": [], "SUBJECTS": "cs.RO cs.AI cs.LG", "authors": ["oier mees", "nichola abdo", "mladen mazuran", "wolfram burgard"], "accepted": false, "id": "1703.01946"}, "pdf": {"name": "1703.01946.pdf", "metadata": {"source": "CRF", "title": "Metric Learning for Generalizing Spatial Relations to New Objects", "authors": ["Oier Mees", "Nichola Abdo", "Mladen Mazuran", "Wolfram Burgard"], "emails": ["burgard}@informatik.uni-"], "sections": [{"heading": null, "text": "This year, we will be able to look for a solution that will enable us to find a solution, that will enable us to find a solution that will enable us to find a solution, that will enable us to find a solution, that will enable us to find a solution, that will enable us to find a solution, that will enable us to find a solution, that will enable us to find a solution, that will enable us to find a solution, that will enable us to find a solution, that will enable us to find a solution. \""}, {"heading": "II. RELATED WORK", "text": "In the context of robotics, the work focused on the use of predefined relationships in the form of symbolic predicates to solve tasks, as in the case of the combined task and motion planning, or in the context of the relative amplification of learning [4, 8, 12, 22]. Instead of relying on the grounding of existing symbols, other works have focused on learning processes that generalize a relationship to new objects. [1, 2, 10, 14, 20] In contrast to these works, we argue with the similarity of relationships by learning the distance between scenes that generalize a relationship to new objects."}, {"heading": "III. NOTATION AND PROBLEM FORMULATION", "text": "This section formalizes the problem we address in this essay."}, {"heading": "A. Object Representation", "text": "We look at the problem of learning spatial relations between pairs of objects. We designate an object by o.In this work, we assume that we have no semantic knowledge of objects such as their type, e.g. box. Instead, we aim to learn relationships based on object geometries and assume that a 3D model of each object in the form of a point cloud Pk is in order. We only look at points on the surface of the objects. We model the state using the 3D poses of objects in SE (3) and express the pose Tk of ok relative to the space frame as a homogeneous transformation consisting of a translation vector tk-R3 and a rotation matrix Rk-SO (3). We designate the pose of ol relative to ok by kTl. Additionally, we assume that the space frame is determined in such a way that the \u2212 z axis is consistent with the gravity vector g."}, {"heading": "B. Pairwise Relations", "text": "We look at learning pairs of spatial relations between objects, i.e. we look at scenes with only two objects. In this work, we do not address the perception problem and rely on existing techniques to segment the scene and calculate the object positions based on its point clouds. Accordingly, we express a scene with ok and ol as tuples s: = < Pk, Pl, kTl >. In this work, we assume that one of the objects (ok) is referred to as a reference object, and therefore we express the scene with the pose kTl of ol relative to ok. In the face of a scene s, our goal is to express the spatial relationship between the two objects in it. To do this, we rely on a feature function (descriptor) f to express the relationship as a K-dimensional feature vector r, i.e. f (s) = r-RK. Furthermore, our goal is to allow the robot to think about how two scenes are similar in terms of the pair relations."}, {"heading": "C. The Problem", "text": "The problem we are dealing with is threefold. 1) Representative relationships: First, we are looking for a descriptor f = = that enables us to grasp the underlying spatial relationship in a scene based only on the geometries (dot clouds) of the objects, their relative poses and the direction of gravity g.2) Learning the distance between the relationships: Given f, we strive to calculate a metricity matrix Y of size N \u00b7 N with diagonal values. For this, we rely on training data D = {s (1),., s (N)} consisting of scenes shown N. Furthermore, we assume that we represent a symmetrical similarity matrix Y of size N \u00b7 N with diagonal values. The value yi, j in the i-th row and j-th column of Y capture the degree of similarity between scenes s (i) and s (j) in D. In this work we are looking at binary similarities Y of size N \u00b7 N with diagonal values. The value yi, j in the i-th row and j-th column of Y capture the degree of similarity between scenes s (j) in D. We are looking at binary similarities Y of size N \u00b7 N with diagonal values."}, {"heading": "IV. PROPOSED FEATURE REPRESENTATION", "text": "In this section, we present our problem by proposing a description text between the objects on the objects we refer to. (...) In this section, we ask ourselves how to define the relationship between the objects as a signature of the underlying relationship between these objects. (...) The definition of these statements is based solely on a fixed (world) reference frame, which is suboptimal, as this results in a descriptor that is influenced by the transformation and rotation of the scene. (...) Calculation of a local reference frame using the objects (e.g. PCA) presents the challenge of ensuring the consistency and reproducibility of the axions across different scenes."}, {"heading": "V. DISTANCE METRIC LEARNING", "text": "In this section, we will discuss how to learn a metric that models the similarities between relationships that characterize r = f (s) over (see Sec. III-C.2) using a popular metric learning method originally introduced to improve the performance of the k-NN classification: large margin nearest neighbor (LMNN) [25]. We will follow the terminology of Weinberger and Saul and define the group of target neighbors R + i for an example ri as the closest neighbors of ri that are designated as similar, i.e. yi, j = 1 for rj, R + j. These target neighbors define a region around ri. We will point to all examples rk within this region that are not similar to ri (i.e. yi, k = 0) as a poster R \u2212 i. The original LMNN formula identifies R + i and R \u2212 i by adopting training data labeled with predefined classes."}, {"heading": "VI. REPRODUCING A NEW RELATION FROM A FEW DEMONSTRATIONS", "text": "In this section, we present our approach to mimicking a new relationship from a small number of teacher demonstrations (Sec. III-C.3). We assume that the robot is already equipped with a series of relationship scenes D = {s (1),. < s (N)} and a (partially filled in) N \u00b7 N matrix Y consisting of their similarities as in Sec. III-C.2. These are either provided by an expert in advance, or accumulated by the robot as it learns previous relationships over time. Using D and Y, we assume that the robot has already learned a previous distance metrix Y parameterized from 0, as described in Sec. V. This is done offline and without knowledge of the new relationship. We consider a teacher who provides the robot with a small group of demonstrations D \u2032 s for a new, arbitrary relationship."}, {"heading": "B. Sample-Based Pose Optimization", "text": "In this paper, we simplify this problem by assuming that the reference object is ok stationary and, therefore, thinks only about desirable postures of ol relative to it. Due to the discrediting in the calculation of our descriptor f, we cannot rely on gradient-based methods, since our loss function is piecemeal constant. We treat this using a sample-based approach. We discredit the space of poses by looking for a grid of translational sktl from ol relative to ok. For each translation, we try rotations kRl uniformly. We use the resulting kTl to transform Pl and calculate L based on the corresponding characteristic value r \u0445 of the scene. Whenever we find a new local minimum in optimization, we check for collisions between the two objects and reject impracticable solutions."}, {"heading": "VII. EXPERIMENTAL EVALUATION", "text": "In this section, we present the experimental evaluation of our approach. Through our experiments, we show the following: i) our proposed descriptor is able to capture different spatial relationships and generalize them to the shapes and sizes of the objects, ii) we are able to capture the similarities between scenes even for relationships that have not previously occurred, iii) our interactive learning method allows laymen to teach new relationships based on a few examples, and iv) we surpass several baselines that do not learn metrics based on the similarities between scenes."}, {"heading": "A. Baselines", "text": "In our experiments, we used three variants of LMNN-based metrics: vanilla (linear) LMNN, \u03c72-LMNN, and GBLMNN, which we learned as in Section V. We compared these learned metrics with a variety of standard distance metrics, including Euclidean, \u03c72, Bhattacharyya, and correlation divergences, as well as Kullback-Leibler divergence (KL), and Jensen-Shannon divergence (JS)."}, {"heading": "B. Dataset", "text": "We made 3D models of 26 household objects and used SimTrack to detect them and calculate their poses in a scene with a Kinect camera [21]. With this setup, we recorded a series of demonstrations D consisting of 546 scenes, see Figure 4 for examples. For evaluation, we manually labeled the similarities between all scenes with Y."}, {"heading": "C. Nearest Neighbor Classification", "text": "In this experiment, we investigated the ability of remote metric learning to relate scenes based on the similarities of their relationships. We formulated this as a k-NN classification problem with k = 5 and evaluated it based on 15 random splits. For each split, we used 75% of the data for the training set and 25% for the test set. We considered this a success if at least 3 out of 5 of the retrieved closest neighbors were similar to the test example. Results are in Tab. I. LMNN-based metrics exceed baseline, i.e. the learned metrics can better capture the distances between scenes. We achieved the highest success rate of 87.6% with GB-LMNN. Note that by directly calculating the euclidean distance in the original feature space, we can achieve a success rate of 82.32%. This shows that our proposed feature descriptor for encoding arbitrary spatial relationships suitable for nocturnal conditions is a 2.32% absent from the scene and a 2.32% nitric from the location."}, {"heading": "D. Distance to New Relations", "text": "In this qualitative experiment, we investigated the ability of a learned metric to capture the similarities between relationships that were not used for training. We trained LMNN with data from three relationships (top row of Fig. 4) that can be semantically described as \"top,\" \"inside,\" and \"next to.\" We used the learned metric to map all six relationships in Fig. 4 to the new space and visualized the data using t-SNE, a popular nonlinear embedding technique for visualizing high-dimensional data [19]. We show this in Fig. 6. This qualitatively illustrates the separation between the three relationships used for training the metric. In addition, the metric is able to capture the semantic similarity between the relationships used for training and the new relationships that we call \"inclined,\" \"\" in the top corner \"and\" inclined \"(bottom row of Fig. 4)."}, {"heading": "E. Generalizing a Relation to New Objects", "text": "In the past, we have repeatedly dealt with the question of how such a situation could have arisen and how it could have arisen, \"he told the Deutsche Presse-Agentur.\" In the past, we have repeatedly been annoyed that it has come to this, \"he told the Deutsche Presse-Agentur.\" We have not managed to defuse the situation, \"he told the Deutsche Presse-Agentur.\" But we have not managed to get the situation under control. \""}, {"heading": "VIII. CONCLUSION", "text": "Our method is based on distance-metric learning and allows a robot to think about the similarity between scenes in terms of the relationships they represent. To encode a relationship, we have introduced a novel descriptor based on the geometries of the objects. By learning a distance metric using this representation, our method is able to reproduce a new relationship from a small number of teacher demonstrations by reflecting on their similarity to previously encountered ones. In this way, our approach enables a lifelong learning scenario by continuously using its knowledge of relationships to imitate new ones. We have extensively evaluated our approach using real-world data collected from unknowledgeable teachers. Our results demonstrate the effectiveness of our approach in arguing the similarity between relationships and its ability to reproduce arbitrary relationships with new objects by learning from a teacher interactively."}], "references": [{"title": "Learning manipulation actions from a few demonstrations", "author": ["N. Abdo", "H. Kretzschmar", "L. Spinello", "C. Stachniss"], "venue": "In Int. Conf. on Robotics & Automation (ICRA),", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2013}, {"title": "Learning symbolic representations of actions from human demonstrations", "author": ["S.R. Ahmadzadeh", "A. Paikan", "F. Mastrogiovanni", "L. Natale", "P. Kormushev", "D.G. Caldwell"], "venue": "In Robotics and Automation (ICRA),", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2015}, {"title": "Exploiting and modeling local 3d structure for predicting object locations", "author": ["A. Aydemir", "P. Jensfelt"], "venue": "In Int. Conf. on Intelligent Robots and Systems (IROS),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2012}, {"title": "CRAM-A cognitive robot abstract machine for everyday manipulation in human environments", "author": ["M. Beetz", "L. M\u00f6senlechner", "M. Tenorth"], "venue": "In Int. Conf. on Intelligent Robots and Systems (IROS),", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2010}, {"title": "Learning spatial relationships from 3d vision using histograms", "author": ["S. Fichtl", "A. McManus", "W. Mustafa", "D. Kraft", "N. Kr\u00fcger", "F. Guerin"], "venue": "IEEE International Conference on Robotics and Automation (ICRA),", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "Grounding spatial relations for humanrobot interaction", "author": ["S. Guadarrama", "L. Riano", "D. Golland", "D. Go", "Y. Jia", "D. Klein", "P. Abbeel", "T. Darrell"], "venue": "In 2013 IEEE/RSJ International Conference on Intelligent Robots and Systems,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2013}, {"title": "Is that you? metric learning approaches for face identification", "author": ["M. Guillaumin", "J. Verbeek", "C. Schmid"], "venue": "In 2009 IEEE 12th International Conference on Computer Vision,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2009}, {"title": "Coupled learning of action parameters and forward models for manipulation", "author": ["S. H\u00f6fer", "O. Brock"], "venue": "In Int. Conf. on Intelligent Robots and Systems (IROS),", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2016}, {"title": "Semi-supervised distance metric learning for collaborative image retrieval", "author": ["S.C. Hoi", "W. Liu", "S.-F. Chang"], "venue": "In Computer Vision and Pattern Recognition,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2008}, {"title": "Learning grounded relational symbols from continuous data for abstract reasoning", "author": ["N. Jetchev", "T. Lang", "M. Toussaint"], "venue": "ICRA Workshop on Autonomous Learning,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2013}, {"title": "Learning to place new objects in a scene", "author": ["Y. Jiang", "M. Lim", "C. Zheng", "A. Saxena"], "venue": "Int. J. of Robotics Research (IJRR),", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2012}, {"title": "Integrated task and motion planning in belief space", "author": ["L.P. Kaelbling", "T. Lozano-P\u00e9rez"], "venue": "Int. J. of Robotics Research (IJRR),", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "Non-linear metric learning", "author": ["D. Kedem", "S. Tyree", "F. Sha", "G.R. Lanckriet", "K.Q. Weinberger"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "Constructing symbolic representations for high-level planning", "author": ["G. Konidaris", "L.P. Kaelbling", "T. Lozano-Perez"], "venue": "In National Conf. on Artificial Intelligence (AAAI),", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "Predicting object interactions from contact distributions", "author": ["O. Kroemer", "J. Peters"], "venue": "In 2014 IEEE/RSJ International Conference on Intelligent Robots and Systems,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2014}, {"title": "Active learning for teaching a robot grounded relational symbols", "author": ["J. Kulick", "M. Toussaint", "T. Lang", "M. Lopes"], "venue": "In IJCAI,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2013}, {"title": "Sparse distance learning for object recognition combining rgb and depth information", "author": ["K. Lai", "L. Bo", "X. Ren", "D. Fox"], "venue": "In Robotics and Automation (ICRA),", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2011}, {"title": "A sparse texture representation using local affine regions", "author": ["S. Lazebnik", "C. Schmid", "J. Ponce"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2005}, {"title": "Visualizing data using t-sne", "author": ["L. v. d. Maaten", "G. Hinton"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2008}, {"title": "Learning symbolic models of stochastic domains", "author": ["H.M. Pasula", "L.S. Zettlemoyer", "L.P. Kaelbling"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2007}, {"title": "Simtrack: A simulation-based framework for scalable real-time object pose detection and tracking", "author": ["K. Pauwels", "D. Kragic"], "venue": "In Intelligent Robots and Systems (IROS),", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2015}, {"title": "Do what i want, not what i did: Imitation of skills by planning sequences of actions", "author": ["C. Paxton", "F. Jonathan", "M. Kobilarov", "G.D. Hager"], "venue": "In Int. Conf. on Intelligent Robots and Systems (IROS),", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2016}, {"title": "Learning spatial relationships between objects", "author": ["B. Rosman", "S. Ramamoorthy"], "venue": "The International Journal of Robotics Research,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2011}, {"title": "Dtlc: Deeply trained loop closure detections for lifelong visual slam", "author": ["M. Shahid", "T. Naseer", "W. Burgard"], "venue": "Workshop at the Robotics Science and Systems (RSS),", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2016}, {"title": "Distance metric learning for large margin nearest neighbor classification", "author": ["K.Q. Weinberger", "L.K. Saul"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2009}, {"title": "Learning a mahalanobis distance metric for data clustering and classification", "author": ["S. Xiang", "F. Nie", "C. Zhang"], "venue": "Pattern Recognition,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2008}, {"title": "Learning the spatial semantics of manipulation actions through preposition grounding", "author": ["K. Zampogiannis", "Y. Yang", "C. Ferm\u00fcller", "Y. Aloimonos"], "venue": "In 2015 IEEE International Conference on Robotics and Automation (ICRA),", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2015}], "referenceMentions": [{"referenceID": 3, "context": "In the context of robotics, previous work has focused on leveraging predefined relations in the form of symbolic predicates for solving tasks, as in the case of combined task and motion planning or in the context of relational reinforcement learning [4, 8, 12, 22].", "startOffset": 250, "endOffset": 264}, {"referenceID": 7, "context": "In the context of robotics, previous work has focused on leveraging predefined relations in the form of symbolic predicates for solving tasks, as in the case of combined task and motion planning or in the context of relational reinforcement learning [4, 8, 12, 22].", "startOffset": 250, "endOffset": 264}, {"referenceID": 11, "context": "In the context of robotics, previous work has focused on leveraging predefined relations in the form of symbolic predicates for solving tasks, as in the case of combined task and motion planning or in the context of relational reinforcement learning [4, 8, 12, 22].", "startOffset": 250, "endOffset": 264}, {"referenceID": 21, "context": "In the context of robotics, previous work has focused on leveraging predefined relations in the form of symbolic predicates for solving tasks, as in the case of combined task and motion planning or in the context of relational reinforcement learning [4, 8, 12, 22].", "startOffset": 250, "endOffset": 264}, {"referenceID": 0, "context": "Rather than relying on grounding existing symbols, other works have addressed learning symbols and effects of actions to abstract continuous states for the purpose of high-level planning [1, 2, 10, 14, 20].", "startOffset": 187, "endOffset": 205}, {"referenceID": 1, "context": "Rather than relying on grounding existing symbols, other works have addressed learning symbols and effects of actions to abstract continuous states for the purpose of high-level planning [1, 2, 10, 14, 20].", "startOffset": 187, "endOffset": 205}, {"referenceID": 9, "context": "Rather than relying on grounding existing symbols, other works have addressed learning symbols and effects of actions to abstract continuous states for the purpose of high-level planning [1, 2, 10, 14, 20].", "startOffset": 187, "endOffset": 205}, {"referenceID": 13, "context": "Rather than relying on grounding existing symbols, other works have addressed learning symbols and effects of actions to abstract continuous states for the purpose of high-level planning [1, 2, 10, 14, 20].", "startOffset": 187, "endOffset": 205}, {"referenceID": 19, "context": "Rather than relying on grounding existing symbols, other works have addressed learning symbols and effects of actions to abstract continuous states for the purpose of high-level planning [1, 2, 10, 14, 20].", "startOffset": 187, "endOffset": 205}, {"referenceID": 22, "context": "Related to this is the work by Rosman and Ramamoorthy, which proposes constructing a contact point graph to classify spatial relations [23].", "startOffset": 135, "endOffset": 139}, {"referenceID": 4, "context": "train random forest classifiers for relations based on histograms that encode the relative position of surface patches [5].", "startOffset": 119, "endOffset": 122}, {"referenceID": 5, "context": "learn models of pre-defined prepositions by training a multi-class logistic regression model using data gathered from crowdsourcing [6].", "startOffset": 132, "endOffset": 135}, {"referenceID": 15, "context": "for learning relational symbols from a teacher [16].", "startOffset": 47, "endOffset": 51}, {"referenceID": 26, "context": "model spatial relations based on the geometries of objects given their point cloud models [27].", "startOffset": 90, "endOffset": 94}, {"referenceID": 10, "context": "Other methods have also relied on the geometries of objects and scenes to reason about preferred object placements [11] or likely places to find an object [3].", "startOffset": 115, "endOffset": 119}, {"referenceID": 2, "context": "Other methods have also relied on the geometries of objects and scenes to reason about preferred object placements [11] or likely places to find an object [3].", "startOffset": 155, "endOffset": 158}, {"referenceID": 14, "context": "distributions for predicting interactions between objects [15].", "startOffset": 58, "endOffset": 62}, {"referenceID": 6, "context": "applied to address face recognition [7], image classification [9] and image segmentation [26].", "startOffset": 36, "endOffset": 39}, {"referenceID": 8, "context": "applied to address face recognition [7], image classification [9] and image segmentation [26].", "startOffset": 62, "endOffset": 65}, {"referenceID": 25, "context": "applied to address face recognition [7], image classification [9] and image segmentation [26].", "startOffset": 89, "endOffset": 93}, {"referenceID": 16, "context": "In the context of robotics, metric learning has been used to address problems related to object instance or place recognition [17, 24].", "startOffset": 126, "endOffset": 134}, {"referenceID": 23, "context": "In the context of robotics, metric learning has been used to address problems related to object instance or place recognition [17, 24].", "startOffset": 126, "endOffset": 134}, {"referenceID": 17, "context": "methods for computing rotationally-invariant descriptors for 2D images such as RIFT [18].", "startOffset": 84, "endOffset": 88}, {"referenceID": 24, "context": "For this, we leverage a popular metric learning technique originally introduced to improve the performance of k-NN classification: large margin nearest neighbor (LMNN) [25].", "startOffset": 168, "endOffset": 172}, {"referenceID": 24, "context": "In the general form, LMNN learns a metric dist\u03c6 parametrized by \u03c6 by minimizing a loss function with two objectives: i) for each training relation ri, pull target neighbors rj \u2208 R+i close, and ii) push imposters rk \u2208 R \u2212 i away such that they are further than target neighbors rj by at least a large margin \u03b6 (see [25]), i.", "startOffset": 314, "endOffset": 318}, {"referenceID": 24, "context": ", \u03c6(r) = Lr, see [25].", "startOffset": 17, "endOffset": 21}, {"referenceID": 12, "context": "distance, see [13].", "startOffset": 14, "endOffset": 18}, {"referenceID": 12, "context": "Finally, gradient-boosted LMNN (GBLMNN) models arbitrary non-linear mappings \u03c6(r) of the input space using gradient-boosted regression trees, see [13].", "startOffset": 146, "endOffset": 150}, {"referenceID": 20, "context": "We recorded 3D models of 26 household objects and used SimTrack to detect them and compute their poses in a scene using a Kinect camera [21].", "startOffset": 136, "endOffset": 140}, {"referenceID": 18, "context": "4 to the new space and visualized the data using t-SNE, a popular non-linear embedding technique for visualizing high dimensional data [19].", "startOffset": 135, "endOffset": 139}], "year": 2017, "abstractText": "Human-centered environments are rich with a wide variety of spatial relations between everyday objects. For autonomous robots to operate effectively in such environments, they should be able to reason about these relations and generalize them to objects with different shapes and sizes. For example, having learned to place a toy inside a basket, a robot should be able to generalize this concept using a spoon and a cup. This requires a robot to have the flexibility to learn arbitrary relations in a lifelong manner, making it challenging for an expert to pre-program it with sufficient knowledge to do so beforehand. In this paper, we address the problem of learning spatial relations by introducing a novel method from the perspective of distance metric learning. Our approach enables a robot to reason about the similarity between pairwise spatial relations, thereby enabling it to use its previous knowledge when presented with a new relation to imitate. We show how this makes it possible to learn arbitrary spatial relations from non-expert users using a small number of examples and in an interactive manner. Our extensive evaluation with realworld data demonstrates the effectiveness of our method in reasoning about a continuous spectrum of spatial relations and generalizing them to new objects.", "creator": "LaTeX with hyperref package"}}}