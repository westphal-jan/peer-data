{"id": "1703.01970", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Mar-2017", "title": "Concentration Bounds for High Sensitivity Functions Through Differential Privacy", "abstract": "A new line of work [Dwork et al. STOC 2015], [Hardt and Ullman FOCS 2014], [Steinke and Ullman COLT 2015], [Bassily et al. STOC 2016] demonstrates how differential privacy [Dwork et al. TCC 2006] can be used as a mathematical tool for guaranteeing generalization in adaptive data analysis. Specifically, if a differentially private analysis is applied on a sample S of i.i.d. examples to select a low-sensitivity function f, then w.h.p. f(S) is close to its expectation, although f is being chosen based on the data.", "histories": [["v1", "Mon, 6 Mar 2017 16:53:32 GMT  (23kb,D)", "http://arxiv.org/abs/1703.01970v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["kobbi nissim", "uri stemmer"], "accepted": false, "id": "1703.01970"}, "pdf": {"name": "1703.01970.pdf", "metadata": {"source": "CRF", "title": "Concentration Bounds for High Sensitivity Functions Through Differential Privacy*", "authors": ["Kobbi Nissim", "Uri Stemmer"], "emails": ["kobbi.nissim@georgetown.edu.", "stemmer@cs.bgu.ac.il."], "sections": [{"heading": null, "text": "Steinke and Ullman have recently observed that these generalizations can be used to detect concentration limits in the non-adaptive database, where the low-sensitivity function is previously fixed. Specifically, they obtain alternative evidence for classical low-sensitivity concentration limits, such as the Chernoff database and McDiarmid's inquality.In this paper, we investigate the situation for functions with high sensitivity, for which differentiated privacy does not imply general guarantees for adaptive analysis.We show that differentiated privacy can be used to detect concentration limits for such functions in the non-adaptive environment.Keywords: differential privacy, concentration functions, high sensitivity functions * Research by K.N. and the USA is supported by NSF grants No. 1565387. \u2020 Dept. of Computer Science, Georgetown University and Center for Research on Computation and Society (CRR), Harvard University @ getowntownman."}], "references": [{"title": "Typicality-based stability and privacy", "author": ["Raef Bassily", "Yoav Freund"], "venue": "CoRR, abs/1604.03336,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2016}, {"title": "Algorithmic stability for adaptive data analysis", "author": ["Raef Bassily", "Kobbi Nissim", "Adam D. Smith", "Thomas Steinke", "Uri Stemmer", "Jonathan Ullman"], "venue": "In Proceedings of the 48th Annual ACM SIGACT Symposium on Theory of Computing,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2016}, {"title": "A measure of asymptotic efficiency for tests of a hypothesis based on the sum of observations", "author": ["Herman Chernoff"], "venue": "Ann. Math. Statist.,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1952}, {"title": "Adaptive learning with robust generalization guarantees", "author": ["Rachel Cummings", "Katrina Ligett", "Kobbi Nissim", "Aaron Roth", "Zhiwei Steven Wu"], "venue": "In Proceedings of the 29th Conference on Learning Theory, COLT 2016,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2016}, {"title": "Generalization in adaptive data analysis and holdout reuse", "author": ["Cynthia Dwork", "Vitaly Feldman", "Moritz Hardt", "Toniann Pitassi", "Omer Reingold", "Aaron Roth"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "Preserving statistical validity in adaptive data analysis", "author": ["Cynthia Dwork", "Vitaly Feldman", "Moritz Hardt", "Toniann Pitassi", "Omer Reingold", "Aaron Roth"], "venue": "In ACM Symposium on the Theory of Computing (STOC)", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "Our data, ourselves: Privacy via distributed noise generation", "author": ["Cynthia Dwork", "Krishnaram Kenthapadi", "Frank McSherry", "Ilya Mironov", "Moni Naor"], "venue": "In Serge Vaudenay, editor, EUROCRYPT,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2006}, {"title": "Calibrating noise to sensitivity in private data analysis", "author": ["Cynthia Dwork", "Frank McSherry", "Kobbi Nissim", "Adam Smith"], "venue": "In TCC,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2006}, {"title": "Preventing false discovery in interactive data analysis is hard", "author": ["Moritz Hardt", "Jonathan Ullman"], "venue": "In FOCS,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "Probability inequalities for sums of bounded random variables", "author": ["Wassily Hoeffding"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1963}, {"title": "Divide and conquer martingales and the number of triangles in a random graph", "author": ["J.H. Kim", "V.H. Vu"], "venue": "Random Structures and Algorithms,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2004}, {"title": "On the number of iterations for dantzig-wolfe optimization and packing-covering approximation algorithms", "author": ["Philip N. Klein", "Neal E. Young"], "venue": "SIAM J. Comput.,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2015}, {"title": "Concentration in unbounded metric spaces and algorithmic stability", "author": ["Aryeh Kontorovich"], "venue": "In Proceedings of the 31th International Conference on Machine Learning,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Mechanism design via differential privacy", "author": ["Frank McSherry", "Kunal Talwar"], "venue": "In FOCS,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2007}, {"title": "Interactive fingerprinting codes and the hardness of preventing false discovery", "author": ["Thomas Steinke", "Jonathan Ullman"], "venue": "In COLT, pages 1588\u20131628,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2015}, {"title": "Subgaussian tail bounds via stability arguments. ArXiv.org, (arXiv:1701.03493 [cs.DM]), 2017", "author": ["Thomas Steinke", "Jonathan Ullman"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2017}], "referenceMentions": [{"referenceID": 5, "context": "Abstract A new line of work [6, 9, 15, 2] demonstrates how differential privacy [8] can be used as a mathematical tool for guaranteeing generalization in adaptive data analysis.", "startOffset": 28, "endOffset": 41}, {"referenceID": 8, "context": "Abstract A new line of work [6, 9, 15, 2] demonstrates how differential privacy [8] can be used as a mathematical tool for guaranteeing generalization in adaptive data analysis.", "startOffset": 28, "endOffset": 41}, {"referenceID": 14, "context": "Abstract A new line of work [6, 9, 15, 2] demonstrates how differential privacy [8] can be used as a mathematical tool for guaranteeing generalization in adaptive data analysis.", "startOffset": 28, "endOffset": 41}, {"referenceID": 1, "context": "Abstract A new line of work [6, 9, 15, 2] demonstrates how differential privacy [8] can be used as a mathematical tool for guaranteeing generalization in adaptive data analysis.", "startOffset": 28, "endOffset": 41}, {"referenceID": 7, "context": "Abstract A new line of work [6, 9, 15, 2] demonstrates how differential privacy [8] can be used as a mathematical tool for guaranteeing generalization in adaptive data analysis.", "startOffset": 80, "endOffset": 83}, {"referenceID": 15, "context": "Very recently, Steinke and Ullman [16] observed that these generalization guarantees can be used for proving concentration bounds in the non-adaptive setting, where the low-sensitivity function is fixed beforehand.", "startOffset": 34, "endOffset": 38}, {"referenceID": 5, "context": "1 Introduction A new line of work [6, 9, 15, 2] demonstrates how differential privacy [8] can be used as a mathematical tool for guaranteeing statistical validity in data analysis.", "startOffset": 34, "endOffset": 47}, {"referenceID": 8, "context": "1 Introduction A new line of work [6, 9, 15, 2] demonstrates how differential privacy [8] can be used as a mathematical tool for guaranteeing statistical validity in data analysis.", "startOffset": 34, "endOffset": 47}, {"referenceID": 14, "context": "1 Introduction A new line of work [6, 9, 15, 2] demonstrates how differential privacy [8] can be used as a mathematical tool for guaranteeing statistical validity in data analysis.", "startOffset": 34, "endOffset": 47}, {"referenceID": 1, "context": "1 Introduction A new line of work [6, 9, 15, 2] demonstrates how differential privacy [8] can be used as a mathematical tool for guaranteeing statistical validity in data analysis.", "startOffset": 34, "endOffset": 47}, {"referenceID": 7, "context": "1 Introduction A new line of work [6, 9, 15, 2] demonstrates how differential privacy [8] can be used as a mathematical tool for guaranteeing statistical validity in data analysis.", "startOffset": 86, "endOffset": 89}, {"referenceID": 5, "context": "[6] showed how to utilize this connection for the task of answering adaptively chosen queries w.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "1 ([6, 2], informal).", "startOffset": 3, "endOffset": 9}, {"referenceID": 1, "context": "1 ([6, 2], informal).", "startOffset": 3, "endOffset": 9}, {"referenceID": 15, "context": "Very recently, Steinke and Ullman [16] observed that Theorem 1.", "startOffset": 34, "endOffset": 38}, {"referenceID": 4, "context": "[5] showed that if \u03b2 is small enough, then w.", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "However, a stronger notion than differential privacy \u2013 typical stability \u2013 presented by Bassily and Freund [1] does guarantee generalization in this setting.", "startOffset": 107, "endOffset": 110}, {"referenceID": 3, "context": "1A similar notion \u2013 perfect generalization \u2013 was presented in [4].", "startOffset": 62, "endOffset": 65}, {"referenceID": 7, "context": "2 (Differential Privacy [8, 7]).", "startOffset": 24, "endOffset": 30}, {"referenceID": 6, "context": "2 (Differential Privacy [8, 7]).", "startOffset": 24, "endOffset": 30}, {"referenceID": 13, "context": "2 The Exponential Mechanism We next describe the exponential mechanism of McSherry and Talwar [14].", "startOffset": 94, "endOffset": 98}, {"referenceID": 2, "context": "The first two inequalities are known as the multiplicative Chernoff bounds [3], and the last inequality is known as the Hoeffding bound [10].", "startOffset": 75, "endOffset": 78}, {"referenceID": 9, "context": "The first two inequalities are known as the multiplicative Chernoff bounds [3], and the last inequality is known as the Hoeffding bound [10].", "startOffset": 136, "endOffset": 140}, {"referenceID": 11, "context": "6 (Tightness of Chernoff bound [12]).", "startOffset": 31, "endOffset": 35}, {"referenceID": 1, "context": "[2] for the generalization properties of a differentially private algorithm that outputs a low-sensitivity function.", "startOffset": 0, "endOffset": 3}, {"referenceID": 13, "context": "The fact that algorithm B is (\u03b5, (f\u0304 ,1))-differentially private follows from the standard analysis of the Exponential Mechanism of McSherry and Talwar [14].", "startOffset": 152, "endOffset": 156}, {"referenceID": 1, "context": ", [2]).", "startOffset": 2, "endOffset": 5}, {"referenceID": 12, "context": "The following is one such refinement, by Kontorovich [13].", "startOffset": 53, "endOffset": 57}, {"referenceID": 12, "context": "1 ([13]).", "startOffset": 3, "endOffset": 7}, {"referenceID": 12, "context": "In [13], Kontorovich showed the following theorem: Theorem 4.", "startOffset": 3, "endOffset": 7}, {"referenceID": 12, "context": "2 ([13], informal).", "startOffset": 3, "endOffset": 7}, {"referenceID": 12, "context": "As stated in the previous section, the results of [13] can be used to obtain a high probability bound on |f (S)\u2212 f (Dn) | whenever Prx,y\u223cD[\u03c1(x,y) \u2265 t] \u2264 exp ( \u2212t2/\u03c32 ) for some \u03c3 > 0.", "startOffset": 50, "endOffset": 54}, {"referenceID": 10, "context": "Following the work of [17], in 2004 Kim and Vu [11] presented the following sharp bound:", "startOffset": 47, "endOffset": 51}, {"referenceID": 10, "context": "3 ([11], informal).", "startOffset": 3, "endOffset": 7}, {"referenceID": 9, "context": "4 ([10]).", "startOffset": 3, "endOffset": 7}, {"referenceID": 4, "context": "2 (Max-Information [5]).", "startOffset": 19, "endOffset": 22}], "year": 2017, "abstractText": "A new line of work [6, 9, 15, 2] demonstrates how differential privacy [8] can be used as a mathematical tool for guaranteeing generalization in adaptive data analysis. Specifically, if a differentially private analysis is applied on a sample S of i.i.d. examples to select a lowsensitivity function f , then w.h.p. f (S) is close to its expectation, although f is being chosen based on the data. Very recently, Steinke and Ullman [16] observed that these generalization guarantees can be used for proving concentration bounds in the non-adaptive setting, where the low-sensitivity function is fixed beforehand. In particular, they obtain alternative proofs for classical concentration bounds for low-sensitivity functions, such as the Chernoff bound and McDiarmid\u2019s Inequality. In this work, we set out to examine the situation for functions with high-sensitivity, for which differential privacy does not imply generalization guarantees under adaptive analysis. We show that differential privacy can be used to prove concentration bounds for such functions in the non-adaptive setting.", "creator": "LaTeX with hyperref package"}}}