{"id": "1703.02161", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Mar-2017", "title": "Distance Metric Learning using Graph Convolutional Networks: Application to Functional Brain Networks", "abstract": "Evaluating similarity between graphs is of major importance in several computer vision and pattern recognition problems, where graph representations are often used to model objects or interactions between elements. The choice of a distance or similarity metric is, however, not trivial and can be highly dependent on the application at hand. In this work, we propose a novel metric learning method to evaluate distance between graphs that leverages the power of convolutional neural networks, while exploiting concepts from spectral graph theory to allow these operations on irregular graphs. We demonstrate the potential of our method in the field of connectomics, where neuronal pathways or functional connections between brain regions are commonly modelled as graphs. In this problem, the definition of an appropriate graph similarity function is critical to unveil patterns of disruptions associated with certain brain disorders. Experimental results on the ABIDE dataset show that our method can learn a graph similarity metric tailored for a clinical application, improving the performance of a simple k-nn classifier by 11.9% compared to a traditional distance metric.", "histories": [["v1", "Tue, 7 Mar 2017 00:49:27 GMT  (283kb,D)", "https://arxiv.org/abs/1703.02161v1", null], ["v2", "Wed, 14 Jun 2017 11:05:52 GMT  (277kb,D)", "http://arxiv.org/abs/1703.02161v2", "International Conference on Medical Image Computing and Computer-Assisted Interventions (MICCAI) 2017"]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["sofia ira ktena", "sarah parisot", "enzo ferrante", "martin rajchl", "matthew lee", "ben glocker", "daniel rueckert"], "accepted": false, "id": "1703.02161"}, "pdf": {"name": "1703.02161.pdf", "metadata": {"source": "CRF", "title": "Distance Metric Learning using Graph Convolutional Networks: Application to Functional Brain Networks", "authors": ["Sofia Ira Ktena", "Sarah Parisot", "Enzo Ferrante", "Martin Rajchl", "Matthew Lee", "Ben Glocker", "Daniel Rueckert"], "emails": ["ira.ktena@imperial.ac.uk"], "sections": [{"heading": "1 Introduction", "text": "This year is the highest in the history of the country."}, {"heading": "2 Methodology", "text": "Fig. 1 provides an overview of the proposed model for comparing brain diagrams. In this section, we first present the concept of graph waves and filtering in the graph spectral domain in 2.1, as well as the proposed network model and the loss function that we want to minimize in 2.2. Finally, we present the data set used and the method by which functional brain diagrams are derived from fMRI data in 2.3."}, {"heading": "2.1 Spectral Graph Filtering and Convolutions", "text": "The classical definition of a convolution operation cannot simply be generalized to graph adjustment, since traditional convolution operators are defined only for regular grids (e.g. 2D or 3D images).Spectral graph theory enables this generalization by defining filters in the graph spectral domain. An essential operator in spectral graph analysis is the normalized diagram UT [14], defined as L = IR \u2212 D \u2212 1 / 2, where A-RR is the adaptation matrix associated with graph G., D is the diagonal degree matrix and IR is the identity matrix. L can be decomposed as L = Used UT \u2212 1 / 2, where U is the matrix of eigenvectors and the diagonal matrix of eigenvalues associated with G, D is the diagonal degree matrix and IR is the diagonal degree matrix."}, {"heading": "2.2 Loss Function and Network Architecture", "text": "Our Siamese network, illustrated in Fig. 1, consists of two identical groups of identical constituent layers with equal weights, each taking a graph as an input. An inner product layer combines the outputs from the two branches of the network, followed by a single fully connected (FC) output layer with a sigmoid activation function and an output corresponding to the similarity estimation.The FC layer takes into account the integration of global information on the similarity of the graphs from the preceding localized filters.Each revolutionary layer is followed by a nonlinear activation, i.e. a linear unit (ReLU).We train the network using the pair-wise global loss function proposed in [8], providing superior results in learning local image descriptors compared to conventional loss.This loss maximizes the mean similarity + between the embedding of the same class, minimizes the mean similarity \u2212 the deviation between the two different similarities \u2212 the similarities between the different listening classes and the two respectively)."}, {"heading": "2.3 From fMRI Data to Graph Signals", "text": "The data set is provided by the Autism Brain Imaging Data Exchange (ABIDE) initiative [5] and has been pre-processed by the Configurable Pipeline for the Analysis of Connectomes (C-PAC) [2], which includes skull stripes, sectional time correction, motion correction, global normalization of mean intensity, noise regression, bandpass filtering (0.01-0.1Hz) and registration of fMRI images into standard anatomical space (MNI152). It includes N = 871 subjects from different image locations who met image quality and phenotypic information criteria, consisting of 403 subjects with ASD and 468 healthy controls. We then extract the mean time series for a number of regions from the Harvard Oxford (HO) atlas containing R = 110 cortical and subcortical ROIs [4] and normalize them to zero and unit value."}, {"heading": "3 Results", "text": "We evaluate the performance of the proposed model for similarity of metric learning on the ABIDE database. Similar to the experimental setup in [16], we train the network for matching and non-matching pairs. In this context, matching pairs representing individuals of the same class (ASD or controls) correspond, while non-matching pairs represent subjects consisting of different classes. Although the basic truth labels are binary, the network output is a continuous value, so the training is conducted in a poorly monitored environment. To deal with this task, we train a Siamesian network with two different constellations, each consisting of 64 characteristics. A binary feature is introduced in the FC layer, which indicates whether the subjects within the pair have been scanned or not. The different network parameters are optimized using cross-validation."}, {"heading": "4 Discussion", "text": "In this thesis, we propose a novel metric learning method to estimate similarities between irregular graphs. We use the current concept of graph waves through a Siamese architecture and use a loss function tailored to our task. We apply the proposed model to functional brain connectivity graphs from the ABIDE database, with the aim of separating subjects from the same class and subjects from different classes. We achieve promising results across all locations, with significant increases in performance between the same site pairs. While our proposed method is applied to brain networks, it is flexible and general enough to be applied to all problems where graph comparisons arise, such as shape analysis. The proposed model could benefit from several expansions. The architecture of our network is relatively simple, and a further improvement in performance8 could be achieved by exploring more complex networks."}], "references": [{"title": "Deriving reproducible biomarkers from multi-site resting-state data: An autism-based example", "author": ["A. Abraham", "M. Milham", "A. Di Martino", "R.C. Craddock", "D. Samaras", "B. Thirion", "G. Varoquaux"], "venue": "NeuroImage", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2016}, {"title": "Towards automated analysis of connectomes: The configurable pipeline for the analysis of connectomes (C-PAC)", "author": ["C. Craddock", "S. Sikka", "B. Cheung", "R. Khanuja", "S Ghosh"], "venue": "Front Neuroinform 42", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2013}, {"title": "Convolutional neural networks on graphs with fast localized spectral filtering", "author": ["M. Defferrard", "X. Bresson", "P. Vandergheynst"], "venue": "NIPS. pp. 3837\u20133845", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2016}, {"title": "An automated labeling system for subdividing the human cerebral cortex on MRI scans into gyral based regions of interest", "author": ["R.S. Desikan", "F. S\u00e9gonne", "B. Fischl", "B.T. Quinn", "Dickerson", "B.C"], "venue": "NeuroImage 31(3), 968\u2013980", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2006}, {"title": "The autism brain imaging data exchange: towards a large-scale evaluation of the intrinsic brain architecture in autism", "author": ["A. Di Martino", "C.G. Yan", "Q. Li", "E. Denio", "Castellanos", "F.X"], "venue": "Molecular Psychiatry 19(6), 659\u2013667", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2014}, {"title": "Wavelets on graphs via spectral graph theory", "author": ["D.K. Hammond", "P. Vandergheynst", "R. Gribonval"], "venue": "Applied and Computational Harmonic Analysis 30(2)", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "Semi-supervised classification with graph convolutional networks", "author": ["T.N. Kipf", "M. Welling"], "venue": "arXiv preprint arXiv:1609.02907", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2016}, {"title": "Learning local image descriptors with deep siamese and triplet convolutional networks by minimising global loss functions", "author": ["B. Kumar", "G. Carneiro", "I Reid"], "venue": "IEEE CVPR. pp. 5385\u20135394", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2016}, {"title": "The graph matching problem", "author": ["L. Livi", "A. Rizzi"], "venue": "Pattern Analysis and Applications 16(3), 253\u2013283", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2013}, {"title": "Geometric deep learning on graphs and manifolds using mixture model CNNs", "author": ["F. Monti", "D. Boscaini", "J. Masci", "E. Rodol\u00e0", "J. Svoboda", "M.M. Bronstein"], "venue": "arXiv preprint arXiv:1611.08402", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2016}, {"title": "Learning convolutional neural networks for graphs", "author": ["M. Niepert", "M. Ahmed", "K. Kutzkov"], "venue": "ICML", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2016}, {"title": "Network-level analysis of cortical thickness of the epileptic brain", "author": ["A. Raj", "S.G. Mueller", "K. Young", "K.D. Laxer", "M. Weiner"], "venue": "NeuroImage 52(4), 1302\u20131313", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2010}, {"title": "Efficient graphlet kernels for large graph comparison", "author": ["N. Shervashidze", "S. Vishwanathan", "T. Petri", "K. Mehlhorn", "K.M. Borgwardt"], "venue": "AISTATS. vol. 5, pp. 488\u2013495", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2009}, {"title": "The emerging field of signal processing on graphs: Extending high-dimensional data analysis to networks and other irregular domains", "author": ["D.I. Shuman", "S.K. Narang", "P. Frossard", "A. Ortega", "P. Vandergheynst"], "venue": "IEEE Signal Processing Magazine 30(3), 83\u201398", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}, {"title": "Graph-based inter-subject pattern analysis of fMRI data", "author": ["S. Takerkart", "G. Auzias", "B. Thirion", "L. Ralaivola"], "venue": "PloS one 9(8), e104586", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning to compare image patches via convolutional neural networks", "author": ["S. Zagoruyko", "N. Komodakis"], "venue": "IEEE CVPR. pp. 4353\u20134361", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2015}], "referenceMentions": [{"referenceID": 8, "context": "The highly challenging problem of inexact graph matching entails the evaluation of how much two graphs share or, conversely, how much they differ [9].", "startOffset": 146, "endOffset": 149}, {"referenceID": 0, "context": "At the same time, disruptions to this functional network organisation have been associated with neurodevelopmental disorders, such as autism spectrum disorder (ASD) [1].", "startOffset": 165, "endOffset": 168}, {"referenceID": 8, "context": "Related work: The estimation of (dis)similarity between two graphs has, most commonly, been dealt with using four mainstream approaches [9]: graph kernels, graph embedding, motif counting and graph edit distance.", "startOffset": 136, "endOffset": 139}, {"referenceID": 14, "context": "Graph kernels have been employed to compare functional brain graphs [15], but often fail to capture global properties as they compare features of smaller subgraphs.", "startOffset": 68, "endOffset": 72}, {"referenceID": 0, "context": "This method has been widely used to estimate brain graph similarity [1], since it facilitates the application of traditional classification or regression analyses.", "startOffset": 68, "endOffset": 71}, {"referenceID": 12, "context": "occurrences of significant subgraph patterns, has also been used [13], but is a computationally expensive process.", "startOffset": 65, "endOffset": 69}, {"referenceID": 11, "context": "Finally, methods based on graph edit distance neatly model both structural and semantic variation within the graphs and are particularly useful in cases of unknown node correspondences [12], but are limited by the fact that they require the definition of the edit costs in advance.", "startOffset": 185, "endOffset": 189}, {"referenceID": 15, "context": "Recently, different neural network models have been explored to learn a similarity function that compares images patches [16,8].", "startOffset": 121, "endOffset": 127}, {"referenceID": 7, "context": "Recently, different neural network models have been explored to learn a similarity function that compares images patches [16,8].", "startOffset": 121, "endOffset": 127}, {"referenceID": 10, "context": "Recent work has attempted to address this challenge by employing a graph labelling procedure for the construction of a receptive field [11], but requires node features to meet certain criteria dictated by the labelling function (e.", "startOffset": 135, "endOffset": 139}, {"referenceID": 13, "context": "[14] introduced the concept of signal processing on graphs, through the use of computational harmonic analysis to perform data processing tasks, like filtering.", "startOffset": 0, "endOffset": 4}, {"referenceID": 2, "context": "Recent work by [3,7] relies on this property to define polynomial filters that are strictly localised and employ a recursive formulation in terms of Chebyshev polynomials that allows fast filtering operations.", "startOffset": 15, "endOffset": 20}, {"referenceID": 6, "context": "Recent work by [3,7] relies on this property to define polynomial filters that are strictly localised and employ a recursive formulation in terms of Chebyshev polynomials that allows fast filtering operations.", "startOffset": 15, "endOffset": 20}, {"referenceID": 2, "context": "We use a siamese graph convolutional neural network applied to irregular graphs using the polynomial filters formulated in [3].", "startOffset": 123, "endOffset": 126}, {"referenceID": 7, "context": "We employ a global loss function that, according to [8], is robust to outliers and provides better regularisation.", "startOffset": 52, "endOffset": 55}, {"referenceID": 4, "context": "As a proof of concept, we demonstrate the model performance on the functional connectivity graphs of 871 subjects from the challenging Autism Brain Imaging Data Exchange (ABIDE) database [5], which contains heterogeneous rs-fMRI data acquired at multiple", "startOffset": 187, "endOffset": 190}, {"referenceID": 13, "context": "An essential operator in spectral graph analysis is the normalised graph Laplacian [14], defined as L = IR \u2212 D\u22121/2AD\u22121/2, where A \u2208 RR\u00d7R is the adjacency matrix associated with the graph G, D is the diagonal degree matrix and IR is the identity matrix.", "startOffset": 83, "endOffset": 87}, {"referenceID": 6, "context": "g\u03b8(\u039b) [7].", "startOffset": 6, "endOffset": 9}, {"referenceID": 5, "context": "To render the filters K-localised in space and reduce their computational complexity they can be approximated by a truncated expansion in terms of Chebyshev polynomials of order K [6].", "startOffset": 180, "endOffset": 183}, {"referenceID": 7, "context": "We train the network using the pairwise similarity global loss function proposed in [8] that yields superior results in the problem of learning local image descriptors compared to traditional losses.", "startOffset": 84, "endOffset": 87}, {"referenceID": 4, "context": "The dataset is provided by the Autism Brain Imaging Data Exchange (ABIDE) initiative [5] and has been preprocessed by the Configurable Pipeline for the Analysis of Connectomes (C-PAC) [2], which involves skull striping, slice timing correction, motion correction, global mean intensity normalisation, nuisance signal regression, band-pass filtering (0.", "startOffset": 85, "endOffset": 88}, {"referenceID": 1, "context": "The dataset is provided by the Autism Brain Imaging Data Exchange (ABIDE) initiative [5] and has been preprocessed by the Configurable Pipeline for the Analysis of Connectomes (C-PAC) [2], which involves skull striping, slice timing correction, motion correction, global mean intensity normalisation, nuisance signal regression, band-pass filtering (0.", "startOffset": 184, "endOffset": 187}, {"referenceID": 3, "context": "We, subsequently, extract the mean time series for a set of regions from the Harvard Oxford (HO) atlas comprising R = 110 cortical and subcortical ROIs [4] and normalise them to zero mean and unit variance.", "startOffset": 152, "endOffset": 155}, {"referenceID": 15, "context": "Similarly to the experimental setup used in [16], we train the network on matching and non-matching pairs.", "startOffset": 44, "endOffset": 48}, {"referenceID": 9, "context": "Additionally, exploring the use of generalisable GCNs defined in the graph spatial domain [10] would allow to train similarity metrics between graphs of different structures.", "startOffset": 90, "endOffset": 94}], "year": 2017, "abstractText": "Evaluating similarity between graphs is of major importance in several computer vision and pattern recognition problems, where graph representations are often used to model objects or interactions between elements. The choice of a distance or similarity metric is, however, not trivial and can be highly dependent on the application at hand. In this work, we propose a novel metric learning method to evaluate distance between graphs that leverages the power of convolutional neural networks, while exploiting concepts from spectral graph theory to allow these operations on irregular graphs. We demonstrate the potential of our method in the field of connectomics, where neuronal pathways or functional connections between brain regions are commonly modelled as graphs. In this problem, the definition of an appropriate graph similarity function is critical to unveil patterns of disruptions associated with certain brain disorders. Experimental results on the ABIDE dataset show that our method can learn a graph similarity metric tailored for a clinical application, improving the performance of a simple k-nn classifier by 11.9% compared to a traditional distance metric.", "creator": "LaTeX with hyperref package"}}}