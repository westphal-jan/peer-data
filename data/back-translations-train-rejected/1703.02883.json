{"id": "1703.02883", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Mar-2017", "title": "Memory Enriched Big Bang Big Crunch Optimization Algorithm for Data Clustering", "abstract": "Cluster analysis plays an important role in decision making process for many knowledge-based systems. There exist a wide variety of different approaches for clustering applications including the heuristic techniques, probabilistic models, and traditional hierarchical algorithms. In this paper, a novel heuristic approach based on big bang-big crunch algorithm is proposed for clustering problems. The proposed method not only takes advantage of heuristic nature to alleviate typical clustering algorithms such as k-means, but it also benefits from the memory based scheme as compared to its similar heuristic techniques. Furthermore, the performance of the proposed algorithm is investigated based on several benchmark test functions as well as on the well-known datasets. The experimental results show the significant superiority of the proposed method over the similar algorithms.", "histories": [["v1", "Wed, 8 Mar 2017 15:50:35 GMT  (439kb)", "http://arxiv.org/abs/1703.02883v1", "17 pages, 3 figures, 8 tables"]], "COMMENTS": "17 pages, 3 figures, 8 tables", "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["kayvan bijari", "hadi zare", "hadi veisi", "hossein bobarshad"], "accepted": false, "id": "1703.02883"}, "pdf": {"name": "1703.02883.pdf", "metadata": {"source": "CRF", "title": "Memory Enriched Big Bang Big Crunch Optimization Algorithm for Data Clustering", "authors": ["Kayvan Bijari", "Hossein Bobarshad"], "emails": ["h.zare@ut.ac.ir"], "sections": [{"heading": null, "text": "ar Xiv: 170 3.02 883v 1 [cs.A I] 8 Mar 201 7Keywords Evolutionary algorithms \u00b7 Big Bang Big Crunch algorithm \u00b7 Clustering \u00b7 Unmonitored learning"}, {"heading": "1 Introduction", "text": "This year is the highest in the history of the country."}, {"heading": "2 Cluster analysis", "text": "Clustering is the process of dividing a series of objects, each of which is explained by a vector of attributes into a finite number of clusters, in a way that is based on similarity functions, the objects in the same cluster are similar to each other and differ from the objects in other clusters. k-mean is also a computationally efficient cluster method that is widely used [3]. Although it is proven that the process of the algorithm will always converge [29], k-means does not guarantee an optimal solution. The algorithm is also essentially sensitive to the primary cluster centers. In addition, k-mean also suffers from the occurrence of empty clusters during its iterations. If there is a cluster without an instance, k-means is not able to update these cluster centers.The procedure of k-mean is as follows."}, {"heading": "3 An overview of Big Bang-Big Crunch optimization algorithm", "text": "There are many theories about how the universe evolved in the first place, and the two famous theories in this regard are namely Big Bang and Big Crunch, BBBC theories. Erol and Eksin [24] have taken advantage of these theories and introduced the BB-BC optimization algorithm. According to this theory, the BigBang phase begins with the generation of random points around an originally chosen point, while trying to shrink the generated points into a single optimized point through the center of mass in the great crunch phase. Big Bang-Big Crunch algorithm (BB-BC) begins with the big bang phase by generating random points around an originally selected point and attempts to shrink the generated points through the large crunch phase. Finally, after repeating the two phases for a limited number of times, the algorithm converts to an ideal solution."}, {"heading": "4 The proposed algorithm", "text": "In this section, we will first introduce the proposed algorithm and describe the most important elements of the algorithm in Subsection 4.1. Then, the sensitivity of the proposed method will be examined using benchmark functions in Subsection 4.2.Algorithms that deal with the question of whether it is a random starting point in terms of the range of limitations. 3: num of stars such as the number of stars 4: dim = dimensions of the solution 5: Repetition of stars Phase: Creation of mass around starting point 7: for i to num stars do 8: for j to dim do 9: Mass of stars generating a star (3) 10: End for 12: End for Big Crunch Phase: 13: c.o.m Center of mass based on (2) 14: Update to date 15: up to the number of the Ite."}, {"heading": "5 The evaluation of the proposed approach", "text": "In order to evaluate the ME-BB-BC, a number of benchmark functions are used first. Table 1 shows the benchmark functions where the optimal solution for all of them is zero. In addition, statistical tests are performed based on the results obtained to examine the proposed algorithm more closely and check the robustness of its results. The proposed algorithm is compared with the Genetic Algorithm (GA), Particle Swarm Optimization (PSO), Grey Wolf Optimizer (GWO) and the original BB-BC algorithm. Each algorithm has been executed 50 times for each benchmark function and the average, best and standardized deviation of costs has been reported. In this study, the dimension of the benchmark functions is set to 50 and the maximum number of iterations to 100. Table 2 shows the experimental results. The ME-BB-BC-BC results have executed the optimization task efficiently, compared to the other methods based on the cost function."}, {"heading": "6 Clustering using ME-BB-BC", "text": "Based on finding the interesting patterns from the dataset in the clustering situations, meta-heuristics techniques are extensively used to uncover the hidden clusters from the dataset. Some of the advantages of these algorithms for performing the clustering task may be mentioned, such as lower sensitivity to the starting points, reduction in the amount of computation and discovery of clusters of arbitrary shapes [35]. In this paper, memory-enriched big bang big crunch algorithm for clustering task is proposed. Furthermore, in order to improve traditional clustering algorithms such as the kmeans method, the proposed approach efficiently performs the clustering task. < The proposed clustering algorithm works in four main steps, each of which are illustrated in the following steps. 1. Starting point: The proposed algorithm starts with an initial response as the starting point of the procedure. This response consists of a vector of randomly generated centers in the permissible range of values."}, {"heading": "7 Experimental results", "text": "Most people are able to save themselves, most people are able to save themselves, most people are able to save themselves, most people are able to save themselves, most people are able to save themselves, most people are able to save themselves, most people are able to save themselves, most people are able to save themselves, most people are not able to save themselves, most people are able to save themselves, most people are able to save themselves, most people are able to save themselves, most people are able to save themselves, most people are able to save themselves, most people are not able to save themselves, most people are able to save themselves, most people are able to save themselves, most people are able to save themselves, most people are able to save themselves."}, {"heading": "8 Conclusion and future work", "text": "In this work, using a memory-enriched approach based on the classic BB-BC algorithm, we were able to significantly increase its efficiency compared to other standard meta-heuristic approaches for benchmark optimization functions and cluster applications. Not only were the shortcomings of the BB-BC method mitigated by the intelligent way of using the memory of previously created solutions, but these solutions were also combined with new candidates in a likely random walk manner to improve the exploitation and exploration of the proposed method. Furthermore, this algorithm was applied to cluster goals. To evaluate the performance of the proposed algorithm, the experimental results were compared with other similar cluster algorithms. Implementation results on benchmark functions and cluster datasets showed us the superiority of the proposed algorithm over other algorithms. Different directions exist to compare the proposed cluster algorithms as the next evolutionary work."}, {"heading": "Acknowledgments", "text": "The authors would like to thank the anonymous reviewers for helpful comments and recommendations, which substantially improve the essay."}], "references": [{"title": "Machine Learning: A Probabilistic Perspective", "author": ["K. Murphy"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2012}, {"title": "Data clustering: 50 years beyond k-means,", "author": ["A.K. Jain"], "venue": "Pattern recognition letters,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2010}, {"title": "Cluster identification and separation in the growing self-organizing map: application in protein sequence classification,", "author": ["N. Ahmad", "D. Alahakoon", "R. Chau"], "venue": "Neural Computing and Applications,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2010}, {"title": "Adaptive k-means clustering algorithm for mr breast image segmentation,", "author": ["H.M. Moftah", "A.T. Azar", "E.T. Al-Shammari", "N.I. Ghali", "A.E. Hassanien", "M. Shoman"], "venue": "Neural Computing and Applications,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1917}, {"title": "A hybrid particle swarm optimization for feature subset selection by integrating a novel local search strategy,", "author": ["P. Moradi", "M. Gholampour"], "venue": "Applied Soft Computing,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2016}, {"title": "Pso-based k-means clustering with enhanced cluster matching for gene expression data,", "author": ["Y.-K. Lam", "P.W.-M. Tsang", "C.-S. Leung"], "venue": "Neural Computing and Applications,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2013}, {"title": "Clustering based on median and closest string via rank distance with applications on dna,", "author": ["L.P. Dinu", "R.T. Ionescu"], "venue": "Neural Computing and Applications,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}, {"title": "Algorithmic complexity: three np-hard problems in computational statistics,", "author": ["W.J. Welch"], "venue": "Journal of Statistical Computation and Simulation,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1982}, {"title": "Al-Sultan, \u201cA tabu search approach to the clustering problem,", "author": ["S. K"], "venue": "Pattern Recognition,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1995}, {"title": "Genetic k-means algorithm,\u201d Systems, Man, and Cybernetics, Part B: Cybernetics", "author": ["K. Krishna", "M.N. Murty"], "venue": "IEEE Transactions on,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1999}, {"title": "An ant colony approach for clustering,", "author": ["P. Shelokar", "V.K. Jayaraman", "B.D. Kulkarni"], "venue": "Analytica Chimica Acta,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2004}, {"title": "A particle swarm optimization approach to clustering,", "author": ["T. Cura"], "venue": "Expert Systems with Applications,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "An artificial bee colony approach for clustering,", "author": ["C. Zhang", "D. Ouyang", "J. Ning"], "venue": "Expert Systems with Applications,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2010}, {"title": "A hybridized approach to data clustering,", "author": ["Y.-T. Kao", "E. Zahara", "I.-W. Kao"], "venue": "Expert Systems with Applications,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2008}, {"title": "Jordehi, \u201cEnhanced leader pso (elpso): A new pso variant for solving global optimisation problems,", "author": ["R. A"], "venue": "Applied Soft Computing,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2015}, {"title": "Enhanced leader pso (elpso): a new algorithm for allocating distributed tcscs in power systems,", "author": ["A.R. Jordehi", "J. Jasni", "N.A. Wahab", "M. Kadir", "M. Javadi"], "venue": "International Journal of Electrical Power & Energy Systems,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2015}, {"title": "A new particle swarm optimization algorithm with adaptive inertia weight based on bayesian techniques,", "author": ["L. Zhang", "Y. Tang", "C. Hua", "X. Guan"], "venue": "Applied Soft Computing,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2015}, {"title": "Akhlaghian, \u201cAn unsupervised feature selection algorithm based on ant colony optimization,", "author": ["S. Tabakhi", "P. Moradi"], "venue": "Engineering Applications of Artificial Intelligence,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2014}, {"title": "Brainstorm optimisation algorithm (bsoa): An efficient algorithm for finding optimal location and setting of facts devices in electric power systems,", "author": ["A.R. Jordehi"], "venue": "International Journal of Electrical Power & Energy Systems,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2015}, {"title": "Seeker optimisation (human group optimisation) algorithm with chaos,", "author": ["A.R. Jordehi"], "venue": "Journal of Experimental & Theoretical Artificial Intelligence,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2015}, {"title": "Jordehi, \u201cAn efficient chaotic water cycle algorithm for optimization tasks,", "author": ["A.A. Heidari", "R.A. Abbaspour", "A. R"], "venue": "Neural Computing and Applications,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2015}, {"title": "Jordehi, \u201cA chaotic artificial immune system optimisation algorithm for solving global continuous optimisation problems,", "author": ["R. A"], "venue": "Neural Computing and Applications,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2015}, {"title": "A new optimization method: big bang\u2013big crunch,", "author": ["O.K. Erol", "I. Eksin"], "venue": "Advances in Engineering Software,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2006}, {"title": "Tlbo based voltage stable environment friendly economic dispatch considering real and reactive power constraints,", "author": ["H. Verma", "P. Mafidar"], "venue": "Journal of The Institution of Engineers (India): Series B,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2013}, {"title": "Preventive and corrective control applications in power systems via big bang\u2013big crunch optimization,", "author": ["C.F. Kucuktezcan", "V.I. Genc"], "venue": "International Journal of Electrical Power & Energy Systems,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2015}, {"title": "Big bang-big crunch optimization for parameter estimation in structural systems,", "author": ["H. Tang", "J. Zhou", "S. Xue", "L. Xie"], "venue": "Mechanical Systems and Signal Processing,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2010}, {"title": "Jordehi, \u201cA chaotic-based big bang\u2013big crunch algorithm for solving global optimisation problems,", "author": ["R. A"], "venue": "Neural Computing and Applications,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2014}, {"title": "Innovative Computational Intelligence: A Rough Guide to 134 Clever Algorithms", "author": ["B. Xing", "W.-J. Gao"], "venue": "New York, NY: Springer,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2014}, {"title": "Empirical study of particle swarm optimization,", "author": ["Y. Shi", "R.C. Eberhart"], "venue": "Proceedings of the 1999 Congress on Evolutionary Computation,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 1999}, {"title": "A survey on nature inspired metaheuristic algorithms for partitional clustering,", "author": ["S.J. Nanda", "G. Panda"], "venue": "Swarm and Evolutionary Computation,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2014}, {"title": "UCI machine learning repository.", "author": ["M. Lichman"], "venue": "http://archive.ics.uci.edu/ml,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "Unsupervised learning methods can be generally divided into clustering, dimensionality reduction, image segmentation, object recognition, and text mining techniques [1].", "startOffset": 165, "endOffset": 168}, {"referenceID": 1, "context": "Clustering is the task of assigning a set of objects, usually vectors in a multidimensional space, into clusters in such a way that the objects in the same cluster are more similar to each other than to those in other clusters [2].", "startOffset": 227, "endOffset": 230}, {"referenceID": 2, "context": "Cluster analysis has attracted attention of many researchers in different fields, including data mining [3], sequence mining [4], image processing [5], feature selection techniques [6], spatial data analysis [3], bioinformatics [7,8], marketing [3], city planning [3], and earthquake studies [3].", "startOffset": 125, "endOffset": 128}, {"referenceID": 3, "context": "Cluster analysis has attracted attention of many researchers in different fields, including data mining [3], sequence mining [4], image processing [5], feature selection techniques [6], spatial data analysis [3], bioinformatics [7,8], marketing [3], city planning [3], and earthquake studies [3].", "startOffset": 147, "endOffset": 150}, {"referenceID": 4, "context": "Cluster analysis has attracted attention of many researchers in different fields, including data mining [3], sequence mining [4], image processing [5], feature selection techniques [6], spatial data analysis [3], bioinformatics [7,8], marketing [3], city planning [3], and earthquake studies [3].", "startOffset": 181, "endOffset": 184}, {"referenceID": 5, "context": "Cluster analysis has attracted attention of many researchers in different fields, including data mining [3], sequence mining [4], image processing [5], feature selection techniques [6], spatial data analysis [3], bioinformatics [7,8], marketing [3], city planning [3], and earthquake studies [3].", "startOffset": 228, "endOffset": 233}, {"referenceID": 6, "context": "Cluster analysis has attracted attention of many researchers in different fields, including data mining [3], sequence mining [4], image processing [5], feature selection techniques [6], spatial data analysis [3], bioinformatics [7,8], marketing [3], city planning [3], and earthquake studies [3].", "startOffset": 228, "endOffset": 233}, {"referenceID": 7, "context": "Since clustering problem is NP-hard by its nature [9], meta-heuristic methods are proper tools to deal with this issue.", "startOffset": 50, "endOffset": 53}, {"referenceID": 8, "context": "Among many studies in metaheuristic approaches for clustering, one can mention clustering algorithm based on tabu search [10], genetic algorithms [11], ant colony [12], particle swarm optimization [13], and bee colony [14].", "startOffset": 121, "endOffset": 125}, {"referenceID": 9, "context": "Among many studies in metaheuristic approaches for clustering, one can mention clustering algorithm based on tabu search [10], genetic algorithms [11], ant colony [12], particle swarm optimization [13], and bee colony [14].", "startOffset": 146, "endOffset": 150}, {"referenceID": 10, "context": "Among many studies in metaheuristic approaches for clustering, one can mention clustering algorithm based on tabu search [10], genetic algorithms [11], ant colony [12], particle swarm optimization [13], and bee colony [14].", "startOffset": 163, "endOffset": 167}, {"referenceID": 11, "context": "Among many studies in metaheuristic approaches for clustering, one can mention clustering algorithm based on tabu search [10], genetic algorithms [11], ant colony [12], particle swarm optimization [13], and bee colony [14].", "startOffset": 197, "endOffset": 201}, {"referenceID": 12, "context": "Among many studies in metaheuristic approaches for clustering, one can mention clustering algorithm based on tabu search [10], genetic algorithms [11], ant colony [12], particle swarm optimization [13], and bee colony [14].", "startOffset": 218, "endOffset": 222}, {"referenceID": 13, "context": "One common approach which can easily be used along with meta-heuristic techniques is k-means algorithm [15].", "startOffset": 103, "endOffset": 107}, {"referenceID": 14, "context": "There exists many nature inspired algorithms for solving complex optimization problems which are used extensively in research works and technological settings including a variety of particle swarm optimization, PSO, based approaches [16, 17,18], ant colony based method for unsupervised learning [19], algorithms which have emerged from human interactions [20,21], water cycle chaotic behavior [22], and human body systems [23].", "startOffset": 233, "endOffset": 244}, {"referenceID": 15, "context": "There exists many nature inspired algorithms for solving complex optimization problems which are used extensively in research works and technological settings including a variety of particle swarm optimization, PSO, based approaches [16, 17,18], ant colony based method for unsupervised learning [19], algorithms which have emerged from human interactions [20,21], water cycle chaotic behavior [22], and human body systems [23].", "startOffset": 233, "endOffset": 244}, {"referenceID": 16, "context": "There exists many nature inspired algorithms for solving complex optimization problems which are used extensively in research works and technological settings including a variety of particle swarm optimization, PSO, based approaches [16, 17,18], ant colony based method for unsupervised learning [19], algorithms which have emerged from human interactions [20,21], water cycle chaotic behavior [22], and human body systems [23].", "startOffset": 233, "endOffset": 244}, {"referenceID": 17, "context": "There exists many nature inspired algorithms for solving complex optimization problems which are used extensively in research works and technological settings including a variety of particle swarm optimization, PSO, based approaches [16, 17,18], ant colony based method for unsupervised learning [19], algorithms which have emerged from human interactions [20,21], water cycle chaotic behavior [22], and human body systems [23].", "startOffset": 296, "endOffset": 300}, {"referenceID": 18, "context": "There exists many nature inspired algorithms for solving complex optimization problems which are used extensively in research works and technological settings including a variety of particle swarm optimization, PSO, based approaches [16, 17,18], ant colony based method for unsupervised learning [19], algorithms which have emerged from human interactions [20,21], water cycle chaotic behavior [22], and human body systems [23].", "startOffset": 356, "endOffset": 363}, {"referenceID": 19, "context": "There exists many nature inspired algorithms for solving complex optimization problems which are used extensively in research works and technological settings including a variety of particle swarm optimization, PSO, based approaches [16, 17,18], ant colony based method for unsupervised learning [19], algorithms which have emerged from human interactions [20,21], water cycle chaotic behavior [22], and human body systems [23].", "startOffset": 356, "endOffset": 363}, {"referenceID": 20, "context": "There exists many nature inspired algorithms for solving complex optimization problems which are used extensively in research works and technological settings including a variety of particle swarm optimization, PSO, based approaches [16, 17,18], ant colony based method for unsupervised learning [19], algorithms which have emerged from human interactions [20,21], water cycle chaotic behavior [22], and human body systems [23].", "startOffset": 394, "endOffset": 398}, {"referenceID": 21, "context": "There exists many nature inspired algorithms for solving complex optimization problems which are used extensively in research works and technological settings including a variety of particle swarm optimization, PSO, based approaches [16, 17,18], ant colony based method for unsupervised learning [19], algorithms which have emerged from human interactions [20,21], water cycle chaotic behavior [22], and human body systems [23].", "startOffset": 423, "endOffset": 427}, {"referenceID": 22, "context": "A novel optimization algorithm named Big Bang-Big Crunch algorithm(BB-BC) based on these theories is first initiated in [24] which have been applied in many works including economic power systems [25,26] and signal processing [27].", "startOffset": 120, "endOffset": 124}, {"referenceID": 23, "context": "A novel optimization algorithm named Big Bang-Big Crunch algorithm(BB-BC) based on these theories is first initiated in [24] which have been applied in many works including economic power systems [25,26] and signal processing [27].", "startOffset": 196, "endOffset": 203}, {"referenceID": 24, "context": "A novel optimization algorithm named Big Bang-Big Crunch algorithm(BB-BC) based on these theories is first initiated in [24] which have been applied in many works including economic power systems [25,26] and signal processing [27].", "startOffset": 196, "endOffset": 203}, {"referenceID": 25, "context": "A novel optimization algorithm named Big Bang-Big Crunch algorithm(BB-BC) based on these theories is first initiated in [24] which have been applied in many works including economic power systems [25,26] and signal processing [27].", "startOffset": 226, "endOffset": 230}, {"referenceID": 26, "context": "While the BB-BC are used in several works, it suffers from disadvantages such as slow convergence speed and trapping in local optimum solutions available in most of the optimization problems [28].", "startOffset": 191, "endOffset": 195}, {"referenceID": 22, "context": "Erol and Eksin [24] made use of these theories and introduced the BB-BC optimization algorithm.", "startOffset": 15, "endOffset": 19}, {"referenceID": 27, "context": "Similar to other evolutionary algorithms [31], this method has a candidate solution where some new particles are randomly distributed around it based on a uniform manner throughout the search space.", "startOffset": 41, "endOffset": 45}, {"referenceID": 28, "context": "This exploitation refinement idea is similar to the decreasing values of pitch adjustment rate in harmony search algorithm [32] and inertia weight in PSO algorithm [33].", "startOffset": 164, "endOffset": 168}, {"referenceID": 27, "context": "Such strategy results in better performance of the metaheuristic algorithms, due to the fact of more exploration at beginning and more exploitative at the end in the search space of the algorithm [31].", "startOffset": 196, "endOffset": 200}, {"referenceID": 8, "context": "5ixi) 4 [-5, 10] [0, .", "startOffset": 8, "endOffset": 16}, {"referenceID": 8, "context": "i=2 i(2x2i \u2212 xi\u22121) 2 [-10, 10] [0, .", "startOffset": 21, "endOffset": 30}, {"referenceID": 29, "context": "Some advantages of these algorithms to perform clustering task can be mentioned such as less sensitivity to the initial starting points, reduction of the amount of computation, and discover clusters with arbitrary shapes [35].", "startOffset": 221, "endOffset": 225}, {"referenceID": 30, "context": "These datasets have been employed in many works and can be achieved from UCI Machine Learning Repository [36].", "startOffset": 105, "endOffset": 109}, {"referenceID": 0, "context": "The learning parameters of the model based clustering paradigm are usually approximated through an iterative procedure named as Expectation Maximization (EM ) algorithm [1].", "startOffset": 169, "endOffset": 172}], "year": 2017, "abstractText": "Cluster analysis plays an important role in decision making process for many knowledge-based systems. There exist a wide variety of different approaches for clustering applications including the heuristic techniques, probabilistic models, and traditional hierarchical algorithms. In this paper, a novel heuristic approach based on big bang-big crunch algorithm is proposed for clustering problems. The proposed method not only takes advantage of heuristic nature to alleviate typical clustering algorithms such as k-means, but it also benefits from the memory based scheme as compared to its similar heuristic techniques. Furthermore, the performance of the proposed algorithm is investigated based on several benchmark test functions as well as on the well-known datasets. The experimental results shows the significant superiority of the proposed method over the similar algorithms.", "creator": "LaTeX with hyperref package"}}}