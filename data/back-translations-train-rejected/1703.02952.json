{"id": "1703.02952", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Mar-2017", "title": "A Hybrid Deep Learning Architecture for Privacy-Preserving Mobile Analytics", "abstract": "The increasing quality of smartphone cameras and variety of photo editing applications, in addition to the rise in popularity of image-centric social media, have all led to a phenomenal growth in mobile-based photography. Advances in computer vision and machine learning techniques provide a large number of cloud-based services with the ability to provide content analysis, face recognition, and object detection facilities to third parties. These inferences and analytics might come with undesired privacy risks to the individuals.", "histories": [["v1", "Wed, 8 Mar 2017 18:21:03 GMT  (699kb,D)", "https://arxiv.org/abs/1703.02952v1", "Technical Report"], ["v2", "Thu, 23 Mar 2017 11:14:55 GMT  (699kb,D)", "http://arxiv.org/abs/1703.02952v2", "Technical Report"], ["v3", "Mon, 3 Apr 2017 11:43:10 GMT  (699kb,D)", "http://arxiv.org/abs/1703.02952v3", "Technical Report"], ["v4", "Tue, 4 Apr 2017 05:28:20 GMT  (699kb,D)", "http://arxiv.org/abs/1703.02952v4", "Technical Report"]], "COMMENTS": "Technical Report", "reviews": [], "SUBJECTS": "cs.LG cs.CV", "authors": ["seyed ali osia", "ali shahin shamsabadi", "ali taheri", "hamid r rabiee", "nicholas d lane", "hamed haddadi"], "accepted": false, "id": "1703.02952"}, "pdf": {"name": "1703.02952.pdf", "metadata": {"source": "CRF", "title": "A Hybrid Deep Learning Architecture for Privacy-Preserving Mobile Analytics", "authors": ["Seyed Ali Osia", "Ali Shahin Shamsabadi", "Ali Taheri", "Hamid R. Rabiee", "Nicholas D. Lane", "Hamed Haddadi"], "emails": [], "sections": [{"heading": null, "text": "In this paper, we address a fundamental challenge: Can we efficiently use the local processing capabilities of modern smartphones to provide permitted analytics services with desired features, while protecting against unwanted inference attacks and protecting privacy in the cloud? We propose a hybrid architecture for a distributed deep learning model between smartphones and the cloud. We rely on Siamese networking and machine learning approaches based on defined privacy constraints to provide privacy, and we also use transfer learning techniques to evaluate the proposed method."}, {"heading": "1. INTRODUCTION", "text": "This year it is so far that it will only be a matter of time before it will be so far, until it will be so far."}, {"heading": "2. MACHINE LEARNING FRAMEWORK", "text": "To enable the privacy-preserving analyses, we need a classification method with the following functions: \u2022 Retrieve input data (e.g. a picture) from the client device (e.g. a smartphone); \u2022 Perform the primary classification task (e.g. gender classification) on the client device; \u2022 Unload the resource-hungry machine learning operations into the cloud; \u2022 Apply privacy-preserving measures to the data; \u2022 Obtain the information required for a secondary classification task (e.g. face recognition) from the server as much as possible. In this part, we present a general framework for this goal. We define the most important modules between the client device and the cloud server, and the data communication between them. Figure 1 presents an overview of the analysis process in function Extraction and Classification of Modules: \u2022 This module gets the input data based on the input data, operates an algorithm for the input of data."}, {"heading": "3. DEEP PRIV-EMBEDDING", "text": "In fact, it is such that it concerns itself in a manner and manner in which people place themselves and themselves in the centre, in which they place themselves in the centre, in which they place themselves in the centre, in which they place themselves in the centre, in which they place themselves in the centre, in which they place themselves in the centre, in which they place themselves in the centre, in which they place themselves in the centre, in which they place themselves in the centre, in which they place themselves in the centre, in which they place themselves in the centre, in which they place themselves in the centre, in which they place themselves in the centre, in which they place themselves in the centre, in which they place themselves in the centre, in which they place themselves and in which they place themselves in the centre, in which they place themselves in themselves, in which they themselves, in which they enter themselves, in which they enter themselves, in which they enter themselves, in which they enter themselves, in which they enter themselves, in which they enter themselves, in which they enter themselves, in which they, they, they, they, they, they, they, they, in themselves, in which they, they, they, they, in which they enter themselves, they, in which they enter themselves, in which they enter themselves, in which they enter themselves, in which they enter themselves, in which they, in which they enter themselves, in which they enter themselves, in which they enter themselves, in which they, in which they enter themselves, in which they, they, they, they, they, they, they, they, they, in themselves, they, they, they, they, in themselves, they, they, in themselves, they, they, they, in themselves, they, in which, they, they, in which, they, they, they, they, they, in themselves, they, in themselves, they, they, in themselves, they, they, in themselves, in which, they, they, in which, they, they, they, they, they, themselves, in which, they, in which, they, they, they, they, themselves, themselves, in which, they, they, in which, they, they, in which, they, they, in themselves, they, themselves, themselves, in which, in themselves, they, in which, they, they, they, in which, in themselves, in which, they"}, {"heading": "3.1 Siamese Privacy Embedding", "text": "In fact, most of them are able to move to another world, where they can move to another world, where they can find their way to another world."}, {"heading": "3.2 Dimensionality Reduction", "text": "After training with the Siamese structure, the service provider should collect intermediate features from all the training data and apply PCA to it.The service provider should select k as the number of dimensions of reduced space and leave the projection matrix to the mobile client in the most informative k-dimensional linear subspace (space of major k components with higher eigenvalues).The user can use this projection matrix to create a greatly reduced size attribute and send it to the server. Since the projection matrix is known to the service provider, it can reconstruct the attribute from the reduced one based on PCA eigenvectors. The main advantage of this method is the reduction of communication costs. As we will show in Section 6, this method has no significant impact on CT1 accuracy."}, {"heading": "3.3 Noise Addition", "text": "After decreasing the dimensionality of the characteristics, we add a Gaussian noise to each dimension of the characteristic. Deviation of this noise would be determined by the service provider based on their priorities. The effect of the noise mechanism is shown in Figure 5. A Siamese network provides k-anonymity by mapping different objects of the same CT1 classes to the same point in the characteristic space, while in practice these points have a small distance from each other that is probably not negligible. Siamese network cluster objects of the same CT1 classes map them further from each other. Due to this proximity, the CT1 class of a noisy point would remain fixed, while the CT2 class of the noisy point would probably be changed. After fine-tuning with the Siamese network, adding a small amount of Gausan noise in each point leads to a higher privacy of CT2 without a significant reduction in the CT1 accuracy of the noisy point."}, {"heading": "4. PRIVACY MEASUREMENT METHODS", "text": "In this section, we measure the privacy of extracted features for CT1 on the client side. We show how to remove information needed for CT2 and how the extracted feature is specific to CT1. To do this, we use the Transfer Learning approach [47] to determine the degree of generality or specificity of features in each layer of deep networks."}, {"heading": "4.1 Transfer Learning", "text": "To determine the degree of universality or specificity of features in each layer of deep networks, we use Transfer Learning [47]. Suppose we have a trained network N1 for CT1 (Figure 6a). We build and train the network N2 for CT2 (Figure 6b) using the following procedure: \u2022 Copy the weights from the first i-layers of N1 to the first i-layers of N2; \u2022 Initialize the remembering layers of N2 randomly (Figure 6c); \u2022 Freeze the first i-layers of N2 (do not update your weights); \u2022 Train N2 to CT2 (Figure 6d). After the training process, the accuracy achieved for CT2 is directly related to the degree of specificity or universality of the extracted feature from the first layer."}, {"heading": "4.2 Feature Extractor Validation", "text": "Since the client is part of the application in the public domain, we need a method to confirm the privacy of the feature extractor, based on some input examples. In particular, the mechanism of noise addition is necessary and should obviously be known on the client side. Suppose we have a record and we want to validate the privacy of the feature extractor. To do this, we can get all the intermediate features and apply noise to it. If we have all these features and a fixed noise data point such as z, we can calculate the probability of each CT2 privacy class. To do this, we correctly estimate P (z | ci) = x P (z | ci) = x P (z | ci) dx (x | ci) P (x | ci) dx (2) dx (2) conditioned on x, ci is independent of z, so we have the data class xxx.P (z | ci) dx = Ex-class, ci (we can form class x-i with class x)."}, {"heading": "5. DATASETS AND APPLICATIONS", "text": "In this section, we present the data sets used for our evaluations and then discuss the application scenarios. We apply transfer learning and privacy measurements to evaluate the efficiency of our proposed framework. We consider two important applications: gender classification and emotion recognition, which have different deep structures. We consider the opposing classification task (CT2) to be face recognition. To evaluate with transfer learning, we use the state-of-the-art VGG-16 facial recognition model presented in [36]. We refine your pre-trained model and obtain 75% accuracy in a 100-class classification task."}, {"heading": "5.1 Datasets", "text": "We use the IMDB Facial Recognition Dataset, Wiki and LFW Gender Recognition Dataset, and SFEW-2 Face Recognition Dataset. 5.1.1 IMDB This dataset [36] contains 1,000 images from 2,622 celebrities on the IMDB Face Recognition Website. The images are in full height so we can identify and crop the faces for our recognition task. We randomly selected 100 different celebrities from this dataset and split their images into training and validation kits to evaluate our Face Recognition Model. For each person, we use 500 images for training and 100 images for validation. 5.1.2 Wiki Rothe et al. [41] prepared a huge dataset called IMDB Wiki, which is useful for age and gender assessment. We use the wiki part of this dataset, which contains 62,359 images to refine our models."}, {"heading": "5.2 Gender Classification", "text": "In a task to classify the sexes, the goal is to classify the image of an individual as male or female, which is used in various systems such as human-computer interaction systems, surveillance systems, and targeted advertising. [34] Some techniques use the facial image as an input for classification, while others use the entire body image or a silhouette. In this paper, we use tailored facial images for the task to classify the sexes. Recently, deep revolutionary neural networks have been used for this problem [27,38,41]. In this work, we use the model proposed in [41] with 94% accuracy, based on VGG-16, the popular 16-layer depth model for classifying images [43] (see Figure 7)."}, {"heading": "5.3 Emotion Detection", "text": "In this problem, emotions are classified by facial expression in images. Recently, deep learning has been shown to be effective in solving this problem. [28, 32] Different deep models are proposed and compared. [28] We opt for the VGGS RGB model, which is based on the VGG-S structure [9], an 8-layer deep model popular for image classification (see Figure 8).The accuracy of emotion detection using this model is 39.5% based on the SFEW-2 dataset."}, {"heading": "6. EXPERIMENTS", "text": "In this section, we evaluate and analyze the accuracy and privacy of different embedded systems with different layers, using our proposed privacy measurement tools: Transfer Learning and Privacy Measurement. Although all of these embedded systems protect privacy, the application of Siamese fine-tuning is more efficient and significantly increases privacy while not reducing the accuracy of the task in question. Furthermore, we show how reducing dimensionality has a positive impact on privacy. Finally, we evaluate our framework on the mobile phone and discuss its advantages over other solutions."}, {"heading": "6.1 Evaluation of Gender Classification", "text": "In the neeisrcnlhteeSrteeeteeteeteeteeteerrrrrsrrsrsrrrsrrsrrrsrrrsrrsrrrsrrrsrrrsrrrsrrrteeteeteeteersrrsrsrsrrrrsrrrrsrrteeeteeteeteeteersrsrsrsrsrrsrsrrsrrsrrsrteeteeteeteeteeteeteersrsrsrsrsrsrsrsrsrsrsrsrteeoioioiueegnrsrsrteeteeteeteeteeteersrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrrrsrsrsrrsrrrrsrsrsrsrteeoiuioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioirrrrrrrsrrrrrrsrrsrrsrrrrrrsrrrrreteeteeteeteeteeteeteeteeteerrrrrrrrrrrrrsrrrrrrrrrrrrrrrrrrrrrrr"}, {"heading": "6.2 Evaluation of Emotion Detection", "text": "In this part, we want to evaluate our framework for emotion detection so that CT1 is emotion detection and CT2 is face detection. We use the VGG-S RGB network of [28] for simple embedding. We match your model with the Siamese structure on the training part of the SFEW-2 dataset and get the Siamese embedding. Since VGG-S has a smaller structure than VGG-16 (8 layers vs. 16 layers), we only evaluate our embedding on an intermediate layer, which is Conv5. We select 10 as the PCA dimension and get a reduced simple and Siamese embedding. We test different embedding with transfer learning and the result is shown in Figure 12. The accuracy of the face detection model is reduced for all embedding. Similar to the application for gender classification, the Siamese embedding works better than the insufficient embedding and the reduction of privacy."}, {"heading": "6.3 Mobile Evaluation", "text": "As shown in Figure 14, the number of parameters of fully connected layers in the deep network is far higher than the number of parameters of the conventional layers. In our framework, only a few revolutionary layers will be loaded onto the mobile phone, so the amount of memory required will decrease significantly, which will result in a significant reduction in model initialization time and consequently in power consumption. [20] More importantly, by reducing the dimensionality of the interlayer to less than 10, we will only have to send a very small dimensional vector to the cloud. Although we perform some simple calculations on the mobile phone, this will significantly reduce the cost of communication. In terms of execution time, we will use the cloud for the inference stage, so that the only bottleneck occurs through the conventional layers set on the mobile phone. Various methods such as compression [20] and austerity [8] also try to reduce the cost of applying revolutionary layers and can be used in our conventional model."}, {"heading": "7. RELATED WORK", "text": "In this section we describe the previous work on the use of deep learning on mobile phones and on private analysis systems."}, {"heading": "7.1 Deep learning on mobile phone", "text": "In order to increase the accuracy of different mobile sensors, Lane et al. use, for example, in [23] a 3-layer DNN that does not overload the hardware. Complex networks with more layers require more computing power. DNN architectures such as the 16-layer model (VGG-16) proposed in [43] and the 8-layer model (VGG-S) proposed in [9], which are more complex, are implemented on the mobile phone in [20], and resource consumption such as time, CPU and energy consumption are reported. As most state-of-the-art DNNs are quite large, the complete evaluation of all layers on the mobile phone results in serious disadvantages in processing time and memory requirements. Some methods are proposed to compare these complex functions with simpler ones in order to reduce the cost of inference. Kim et al. [20] aim to compress deep models, and in [8] the authors use thrift and kernel separation."}, {"heading": "7.2 Learning with privacy", "text": "Early work in this area focused mainly on the publication of data sets for learning tasks [4, 5, 19, 45], with the main objective of publishing a data set consisting of high-level characteristics for data mining tasks (e.g. medical database consisting of patient data) while respecting the privacy of the individual. Solutions such as randomized supplementation of noise [4, 5], k-anonymity through generalization and suppression [25, 29, 30] are proposed and studied in [3] These methods have some major problems. They are only suitable for low-dimensional data due to the curse of dimensionality [2], so they do not match most of the multimedia data. A variety of attacks makes many of these methods unreliable [3]. Differentiated privacy [14] is another method of publishing statistics on a problem of dimensionality [2], so that they do not match most of the multimedia data."}, {"heading": "7.3 Privacy in image analytics", "text": "A good overview of all the methods attempted to ensure visual privacy can be found in [35], which classifies various methods into five categories: intervention, blind vision, secure processing, redundancy and hiding of data. Our work is in the spirit similar to the deification of privacy, a subcategory of editorial methods. The aim of these methods is to purify the faces of individuals in such a way that they cannot be recognized by a face recognition system. A basic work in this category is presented in [33], which addresses the issue of privacy in video surveillance data. The aim of this work is to publish a transformed dataset in which individuals are unidentifiable. They show that the use of simple image filtering cannot guarantee privacy and suggest an algorithm based on K-anonymity, which aims to create average facial images and replace them with the original ones."}, {"heading": "8. DISCUSSIONS AND NEXT STEPS", "text": "In this paper, we introduced a new hybrid framework for efficient data protection analysis on mobile systems. Our framework consists of a feature extractor and classifier, with the former placed on the client side and the latter on the server side. We embed deep neural networks, especially Convolutionary Neural Networks, into this framework to benefit from their accuracy and layered architecture. To protect privacy from unauthorized tasks, we used the Siamese architecture and created a feature that is specific to the task at hand. This is in contrast to today's deep networks, where the features created are general and can be used for different tasks. Removing the unwanted information from the extracted feature leads to privacy for the user. Assessing our framework by splitting the layers between the mobile phone and cloud and by targeted noise accumulation, we achieved high accuracy in the tasks we currently need to perform while we are trained for other tasks."}, {"heading": "9. REFERENCES", "text": "In fact, it is not as if this is a purely theoretical view, but a purely theoretical view, which is a purely theoretical view, which is a purely theoretical view. [1] It is not as if it is a purely theoretical view. [2] It is as if it were a purely theoretical view. [3] It is as if it were a purely theoretical view. [4] It is as if it were a purely theoretical view. [5] It is as if it were a purely theoretical view. [5] It is as if it were a purely theoretical view. [5] It is as if it were a purely theoretical view."}], "references": [{"title": "Deep Learning with Differential Privacy", "author": ["M. Abadi", "A. Chu", "I. Goodfellow", "H. Brendan McMahan", "I. Mironov", "K. Talwar", "L. Zhang"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2016}, {"title": "On k-anonymity and the curse of dimensionality", "author": ["C.C. Aggarwal"], "venue": "In Proceedings of the 31st international conference on Very large data bases,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2005}, {"title": "A general survey of privacy-preserving data mining models and algorithms", "author": ["C.C. Aggarwal", "S.Y. Philip"], "venue": "In Privacy-preserving data mining,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2008}, {"title": "On the design and quantification of privacy preserving data mining algorithms", "author": ["D. Agrawal", "C.C. Aggarwal"], "venue": "In Proceedings of the twentieth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2001}, {"title": "Privacy-preserving data mining", "author": ["R. Agrawal", "R. Srikant"], "venue": "In ACM Sigmod Record,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2000}, {"title": "Blind vision", "author": ["S. Avidan", "M. Butman"], "venue": "In European Conference on Computer Vision,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2006}, {"title": "Deep learning of representations for unsupervised and transfer learning", "author": ["Y. Bengio"], "venue": "ICML Unsupervised and Transfer Learning,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2012}, {"title": "Sparsification and separation of deep learning layers for constrained resource inference on wearables", "author": ["S. Bhattacharya", "N.D. Lane"], "venue": "In Proceedings of the 14th ACM Conference on Embedded Network Sensor Systems CD-ROM,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2016}, {"title": "Return of the devil in the details: Delving deep into convolutional nets", "author": ["K. Chatfield", "K. Simonyan", "A. Vedaldi", "A. Zisserman"], "venue": "In British Machine Vision Conference,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "Learning a similarity metric discriminatively, with application to face verification", "author": ["S. Chopra", "R. Hadsell", "Y. LeCun"], "venue": "IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR\u201905),", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2005}, {"title": "Static facial expression analysis in tough conditions: Data, evaluation protocol and benchmark", "author": ["A. Dhall", "R. Goecke", "S. Lucey", "T. Gedeon"], "venue": "In Computer Vision Workshops (ICCV Workshops),", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2011}, {"title": "Video and image based  emotion recognition challenges in the wild: Emotiw", "author": ["A. Dhall", "O. Ramana Murthy", "R. Goecke", "J. Joshi", "T. Gedeon"], "venue": "In Proceedings of the 2015 ACM on International Conference on Multimodal Interaction,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2015}, {"title": "A survey of deep learning methods and software tools for image classification and object detection", "author": ["P.N. Druzhkov", "V.D. Kustikova"], "venue": "Pattern Recognition and Image Analysis,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2016}, {"title": "Differential privacy: A survey of results", "author": ["C. Dwork"], "venue": "In International Conference on Theory and Applications of Models of Computation,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2008}, {"title": "Cryptonets: Applying neural networks to encrypted data with high throughput and accuracy", "author": ["R. Gilad-Bachrach", "N. Dowlin", "K. Laine", "K. Lauter", "M. Naehrig", "J. Wernsing"], "venue": "In Proceedings of The 33rd International Conference on Machine Learning,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2016}, {"title": "Dimensionality reduction by learning an invariant mapping", "author": ["R. Hadsell", "S. Chopra", "Y. LeCun"], "venue": "IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR\u201906),", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2006}, {"title": "Privacy leakage in mobile computing: Tools, methods, and characteristics", "author": ["M. Haris", "H. Haddadi", "P. Hui"], "venue": "arXiv preprint arXiv:1410.4978,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2014}, {"title": "Labeled faces in the wild: A database for studying face recognition in unconstrained environments", "author": ["G.B. Huang", "M. Ramesh", "T. Berg", "E. Learned-Miller"], "venue": "Technical Report 07-49,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2007}, {"title": "Transforming data to satisfy privacy constraints", "author": ["V.S. Iyengar"], "venue": "In Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2002}, {"title": "Compression of deep convolutional neural networks for fast and low power mobile applications", "author": ["Y.-D. Kim", "E. Park", "S. Yoo", "T. Choi", "L. Yang", "D. Shin"], "venue": "arXiv preprint arXiv:1511.06530,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2015}, {"title": "Using face morphing to protect privacy", "author": ["P. Korshunov", "T. Ebrahimi"], "venue": "In Advanced Video and Signal Based Surveillance (AVSS),", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2013}, {"title": "Deepx: A software accelerator for low-power deep learning inference on mobile devices", "author": ["N.D. Lane", "S. Bhattacharya", "P. Georgiev", "C. Forlivesi", "L. Jiao", "L. Qendro", "F. Kawsar"], "venue": "In 2016 15th ACM/IEEE International Conference on 13  Information Processing in Sensor Networks (IPSN),", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2016}, {"title": "Can deep learning revolutionize mobile sensing", "author": ["N.D. Lane", "P. Georgiev"], "venue": "In Proceedings of the 16th International Workshop on Mobile Computing Systems and Applications,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2015}, {"title": "Zoe: A cloud-less dialog-enabled continuous sensing wearable exploiting heterogeneous computation", "author": ["N.D. Lane", "P. Georgiev", "C. Mascolo", "Y. Gao"], "venue": "In Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2015}, {"title": "Incognito: Efficient full-domain k-anonymity", "author": ["K. LeFevre", "D.J. DeWitt", "R. Ramakrishnan"], "venue": "In Proceedings of the 2005 ACM SIGMOD international conference on Management of data,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2005}, {"title": "Don\u2019t kill my ads!: balancing privacy in an ad-supported mobile application market", "author": ["I. Leontiadis", "C. Efstratiou", "M. Picone", "C. Mascolo"], "venue": "In Proceedings of ACM HotMobile,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2012}, {"title": "Age and gender classification using convolutional neural networks", "author": ["G. Levi", "T. Hassner"], "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2015}, {"title": "Emotion recognition in the wild via convolutional neural networks and mapped binary patterns", "author": ["G. Levi", "T. Hassner"], "venue": "In Proceedings of the 2015 ACM on International Conference on Multimodal Interaction,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2015}, {"title": "t-closeness: Privacy beyond k-anonymity and l-diversity", "author": ["N. Li", "T. Li", "S. Venkatasubramanian"], "venue": "IEEE 23rd International Conference on Data Engineering,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2007}, {"title": "l-diversity: Privacy beyond k-anonymity", "author": ["A. Machanavajjhala", "D. Kifer", "J. Gehrke", "M. Venkitasubramaniam"], "venue": "ACM Transactions on Knowledge Discovery from Data (TKDD),", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2007}, {"title": "Understanding deep image representations by inverting them", "author": ["A. Mahendran", "A. Vedaldi"], "venue": "IEEE conference on computer vision and pattern recognition (CVPR),", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2015}, {"title": "Going deeper in facial expression recognition using deep neural networks", "author": ["A. Mollahosseini", "D. Chan", "M.H. Mahoor"], "venue": "In 2016 IEEE Winter Conference on Applications of Computer Vision (WACV),", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2016}, {"title": "Preserving privacy by de-identifying face images", "author": ["E.M. Newton", "L. Sweeney", "B. Malin"], "venue": "IEEE transactions on Knowledge and Data Engineering,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2005}, {"title": "Vision-based human gender recognition: A survey", "author": ["C.B. Ng", "Y.H. Tay", "B.M. Goi"], "venue": "arXiv preprint arXiv:1204.1611,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2012}, {"title": "Visual privacy protection methods: A survey", "author": ["J.R. Padilla-L\u00f3pez", "A.A. Chaaraoui", "F. Fl\u00f3rez-Revuelta"], "venue": "Expert Systems with Applications,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2015}, {"title": "Deep face recognition", "author": ["O.M. Parkhi", "A. Vedaldi", "A. Zisserman"], "venue": "In British Machine Vision Conference,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2015}, {"title": "Participant privacy in mobile crowd sensing task management: A survey of methods and challenges", "author": ["L. Pournajaf", "D.A. Garcia-Ulloa", "L. Xiong", "V. Sunderam"], "venue": "ACM SIGMOD Record,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2016}, {"title": "The impact of privacy protection filters on gender recognition. In SPIE Optical Engineering+ Applications, pages 959906\u2013959906", "author": ["N. Rachaud", "G. Antipov", "P. Korshunov", "J.-L. Dugelay", "T. Ebrahimi", "S.-A. Berrani"], "venue": "International Society for Optics and Photonics,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2015}, {"title": "Towards bottom-up analysis of social food", "author": ["J. Rich", "H. Haddadi", "T.M. Hospedales"], "venue": "In Proceedings of the 6th International Conference on Digital Health Conference, DH", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2016}, {"title": "Breaking for commercials: characterizing mobile advertising", "author": ["N.V. Rodriguez", "J. Shah", "A. Finamore", "Y. Grunenberger", "K. Papagiannaki", "H. Haddadi", "J. Crowcroft"], "venue": "In Proceedings of ACM Internet Measurement Conference,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2012}, {"title": "Dex: Deep expectation of apparent age from a single image", "author": ["R. Rothe", "R. Timofte", "L. Van Gool"], "venue": "In Proceedings of the IEEE International Conference on Computer Vision Workshops,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2015}, {"title": "Privacy-preserving deep learning", "author": ["R. Shokri", "V. Shmatikov"], "venue": "In Proceedings of the 22Nd ACM SIGSAC Conference on Computer and Communications Security,", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2015}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["K. Simonyan", "A. Zisserman"], "venue": "CoRR, abs/1409.1556,", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2014}, {"title": "Deep learning face representation by joint identification-verification", "author": ["Y. Sun", "Y. Chen", "X. Wang", "X. Tang"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2014}, {"title": "k-anonymity: A model for protecting privacy", "author": ["L. Sweeney"], "venue": "International Journal of Uncertainty,", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2002}, {"title": "Deep learning for content-based image retrieval: A comprehensive study", "author": ["J. Wan", "D. Wang", "S.C.H. Hoi", "P. Wu", "J. Zhu", "Y. Zhang", "J. Li"], "venue": "In Proceedings of the 22nd ACM  international conference on Multimedia,", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 2014}, {"title": "How transferable are features in deep neural networks? In Advances in neural information processing", "author": ["J. Yosinski", "J. Clune", "Y. Bengio", "H. Lipson"], "venue": null, "citeRegEx": "47", "shortCiteRegEx": "47", "year": 2014}], "referenceMentions": [{"referenceID": 25, "context": "This practice has a number of privacy concerns and resource impacts for the users [26, 40].", "startOffset": 82, "endOffset": 90}, {"referenceID": 39, "context": "This practice has a number of privacy concerns and resource impacts for the users [26, 40].", "startOffset": 82, "endOffset": 90}, {"referenceID": 12, "context": "Recently, deep learning have been used for many image analysis tasks [13, 39, 46].", "startOffset": 69, "endOffset": 81}, {"referenceID": 38, "context": "Recently, deep learning have been used for many image analysis tasks [13, 39, 46].", "startOffset": 69, "endOffset": 81}, {"referenceID": 45, "context": "Recently, deep learning have been used for many image analysis tasks [13, 39, 46].", "startOffset": 69, "endOffset": 81}, {"referenceID": 19, "context": "More recently, a number of works [20,23,24] address the problem of inference using deep models on mobile phones.", "startOffset": 33, "endOffset": 43}, {"referenceID": 22, "context": "More recently, a number of works [20,23,24] address the problem of inference using deep models on mobile phones.", "startOffset": 33, "endOffset": 43}, {"referenceID": 23, "context": "More recently, a number of works [20,23,24] address the problem of inference using deep models on mobile phones.", "startOffset": 33, "endOffset": 43}, {"referenceID": 16, "context": "On the other hand, cloud-based mobile computing models have a number of privacy risks [17, 37].", "startOffset": 86, "endOffset": 94}, {"referenceID": 36, "context": "On the other hand, cloud-based mobile computing models have a number of privacy risks [17, 37].", "startOffset": 86, "endOffset": 94}, {"referenceID": 9, "context": "To do this, we alter the training phase by applying Siamese networks [10] and by employing a noise addition mechanism for increased privacy.", "startOffset": 69, "endOffset": 73}, {"referenceID": 46, "context": "One is to use transfer learning [47] which proves that face recognition is impractical by even using the state of the art models.", "startOffset": 32, "endOffset": 36}, {"referenceID": 30, "context": "In [31], the authors reconstruct an original image from each layer and the accuracy of reconstruction decreases by using higher layers.", "startOffset": 3, "endOffset": 7}, {"referenceID": 46, "context": "As we go up through the deep network layers, the features get more specific to the classification task [47] and irrelevant information to the specific classification will be gradually lost.", "startOffset": 103, "endOffset": 107}, {"referenceID": 6, "context": "Deep networks disentangle the underlying variations in training distribution [7].", "startOffset": 77, "endOffset": 80}, {"referenceID": 9, "context": "We use the Siamese network [10] to accomplish this task.", "startOffset": 27, "endOffset": 31}, {"referenceID": 9, "context": "The Siamese architecture has been used in verification applications for long times [10].", "startOffset": 83, "endOffset": 87}, {"referenceID": 15, "context": "An appropriate such loss function is defined in [16] and we use it in our application:", "startOffset": 48, "endOffset": 52}, {"referenceID": 43, "context": "In [44], Sun et al.", "startOffset": 3, "endOffset": 7}, {"referenceID": 43, "context": "Unlike in [44] where the representations for the same person are forced to be near each other, we force mappings of different persons (objects with different CT2 class) to be near each other.", "startOffset": 10, "endOffset": 14}, {"referenceID": 43, "context": "We could use the previous layer of softmax as in [44], or we can use any other middle layer and define the contrastive loss on that.", "startOffset": 49, "endOffset": 53}, {"referenceID": 46, "context": "In order to do this we use the transfer learning [47] approach for determining the degree of generality or specificity of features in each layer of deep networks", "startOffset": 49, "endOffset": 53}, {"referenceID": 46, "context": "For determining the degree of generality or specificity of features in each layer of deep networks, we use transfer learning [47].", "startOffset": 125, "endOffset": 129}, {"referenceID": 35, "context": "In order to evaluate with transfer learning, we use the state of the art VGG-16 model for face recognition, presented in [36].", "startOffset": 121, "endOffset": 125}, {"referenceID": 35, "context": "This dataset [36] contains 1,000 images from 2,622 highly-ranked celebrities on the IMDB website, for face recognition.", "startOffset": 13, "endOffset": 17}, {"referenceID": 42, "context": "Figure 7: 16 layer VGG-16 structure [43]", "startOffset": 36, "endOffset": 40}, {"referenceID": 40, "context": "[41] prepared a huge dataset, named IMDB-Wiki, which is useful for age and gender estimation.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "Labeled Face in the Wild (LFW) [18] is an unconstrained face database containing 13,233 images from 5,749 individuals.", "startOffset": 31, "endOffset": 35}, {"referenceID": 10, "context": "Static Facial Expression in the Wild (SFEW) is an emotion detection benchmark [11].", "startOffset": 78, "endOffset": 82}, {"referenceID": 11, "context": "We use the latest version [12] which consists of face images in seven emotional classes.", "startOffset": 26, "endOffset": 30}, {"referenceID": 33, "context": "This has various applications in different systems such as human-computer interaction system, surveillance systems and targeted advertising [34].", "startOffset": 140, "endOffset": 144}, {"referenceID": 26, "context": "Recently, deep convolutional neural networks have been used for this problem [27,38,41].", "startOffset": 77, "endOffset": 87}, {"referenceID": 37, "context": "Recently, deep convolutional neural networks have been used for this problem [27,38,41].", "startOffset": 77, "endOffset": 87}, {"referenceID": 40, "context": "Recently, deep convolutional neural networks have been used for this problem [27,38,41].", "startOffset": 77, "endOffset": 87}, {"referenceID": 40, "context": "In this work we use the model proposed in [41] with 94% accuracy, based on VGG-16, the popular 16-layer deep model for Relu6 FC6", "startOffset": 42, "endOffset": 46}, {"referenceID": 8, "context": "Figure 8: 8 layer VGG-S structure [9]", "startOffset": 34, "endOffset": 37}, {"referenceID": 42, "context": "image classification [43] (see Figure 7).", "startOffset": 21, "endOffset": 25}, {"referenceID": 27, "context": "Recently, deep learning has been demonstrated to be effective in solving this problem [28, 32].", "startOffset": 86, "endOffset": 94}, {"referenceID": 31, "context": "Recently, deep learning has been demonstrated to be effective in solving this problem [28, 32].", "startOffset": 86, "endOffset": 94}, {"referenceID": 27, "context": "Different deep models are proposed and compared in [28].", "startOffset": 51, "endOffset": 55}, {"referenceID": 8, "context": "We choose the VGGS RGB model which is based on VGG-S structure [9], an 8-layer deep model which is popular for image classification (see Figure 8).", "startOffset": 63, "endOffset": 66}, {"referenceID": 40, "context": "We use the VGG-16 model proposed at [41] in the simple embedding.", "startOffset": 36, "endOffset": 40}, {"referenceID": 40, "context": "In order to get the Siamese embedding, we use the pre-trained network of [41] and initiate a privacy Siamese structure (Figure 4c) with that.", "startOffset": 73, "endOffset": 77}, {"referenceID": 27, "context": "We use the VGG-S RGB pretrained network of [28] in the simple embedding.", "startOffset": 43, "endOffset": 47}, {"referenceID": 27, "context": "simple [28] 40% Siamese 38% reduced simple 31% reduced Siamese 32%", "startOffset": 7, "endOffset": 11}, {"referenceID": 19, "context": "time and consequently power consumption [20].", "startOffset": 40, "endOffset": 44}, {"referenceID": 19, "context": "Different methods such as compression [20] and sparsification [8] also try to reduce the cost of applying convolutional layers and can be used in our framework.", "startOffset": 38, "endOffset": 42}, {"referenceID": 7, "context": "Different methods such as compression [20] and sparsification [8] also try to reduce the cost of applying convolutional layers and can be used in our framework.", "startOffset": 62, "endOffset": 65}, {"referenceID": 22, "context": "in [23], Lane et al.", "startOffset": 3, "endOffset": 7}, {"referenceID": 42, "context": "DNN architectures such as the 16-layer model (VGG-16 ) proposed in [43] and the 8layer model (VGG-S ) proposed in [9] which are more complex, are implemented on the mobile in [20], and the resource usage such as time, CPU and energy overhead, are reported.", "startOffset": 67, "endOffset": 71}, {"referenceID": 8, "context": "DNN architectures such as the 16-layer model (VGG-16 ) proposed in [43] and the 8layer model (VGG-S ) proposed in [9] which are more complex, are implemented on the mobile in [20], and the resource usage such as time, CPU and energy overhead, are reported.", "startOffset": 114, "endOffset": 117}, {"referenceID": 19, "context": "DNN architectures such as the 16-layer model (VGG-16 ) proposed in [43] and the 8layer model (VGG-S ) proposed in [9] which are more complex, are implemented on the mobile in [20], and the resource usage such as time, CPU and energy overhead, are reported.", "startOffset": 175, "endOffset": 179}, {"referenceID": 19, "context": "[20] aim to compress deep models and in [8] the authors use sparsification and kernel separation.", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "[20] aim to compress deep models and in [8] the authors use sparsification and kernel separation.", "startOffset": 40, "endOffset": 43}, {"referenceID": 19, "context": "The DNN implementation on GPU in [20] has burdens on the battery, hence it is not a feasible solution for some practical applications that either users frequently use it or continuously require it for long periods [22].", "startOffset": 33, "endOffset": 37}, {"referenceID": 21, "context": "The DNN implementation on GPU in [20] has burdens on the battery, hence it is not a feasible solution for some practical applications that either users frequently use it or continuously require it for long periods [22].", "startOffset": 214, "endOffset": 218}, {"referenceID": 21, "context": "[22] have implemented a software accelerator called DeepX for large-scale DNN to reduce the resources while the mobile is doing inference by using different kinds of mobile processor simultaneously.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "ing datasets for learning tasks [4, 5, 19, 45].", "startOffset": 32, "endOffset": 46}, {"referenceID": 4, "context": "ing datasets for learning tasks [4, 5, 19, 45].", "startOffset": 32, "endOffset": 46}, {"referenceID": 18, "context": "ing datasets for learning tasks [4, 5, 19, 45].", "startOffset": 32, "endOffset": 46}, {"referenceID": 44, "context": "ing datasets for learning tasks [4, 5, 19, 45].", "startOffset": 32, "endOffset": 46}, {"referenceID": 3, "context": "Solutions such as randomized noise addition [4, 5], k-anonymity by generalization and suppression [25, 29, 30] are proposed and surveyed in [3].", "startOffset": 44, "endOffset": 50}, {"referenceID": 4, "context": "Solutions such as randomized noise addition [4, 5], k-anonymity by generalization and suppression [25, 29, 30] are proposed and surveyed in [3].", "startOffset": 44, "endOffset": 50}, {"referenceID": 24, "context": "Solutions such as randomized noise addition [4, 5], k-anonymity by generalization and suppression [25, 29, 30] are proposed and surveyed in [3].", "startOffset": 98, "endOffset": 110}, {"referenceID": 28, "context": "Solutions such as randomized noise addition [4, 5], k-anonymity by generalization and suppression [25, 29, 30] are proposed and surveyed in [3].", "startOffset": 98, "endOffset": 110}, {"referenceID": 29, "context": "Solutions such as randomized noise addition [4, 5], k-anonymity by generalization and suppression [25, 29, 30] are proposed and surveyed in [3].", "startOffset": 98, "endOffset": 110}, {"referenceID": 2, "context": "Solutions such as randomized noise addition [4, 5], k-anonymity by generalization and suppression [25, 29, 30] are proposed and surveyed in [3].", "startOffset": 140, "endOffset": 143}, {"referenceID": 1, "context": "They are just appropriate for low-dimensional data due to the curse of dimensionality [2], hence they are not fit most of the multimedia data.", "startOffset": 86, "endOffset": 89}, {"referenceID": 2, "context": "A variety of attacks make many these methods unreliable [3].", "startOffset": 56, "endOffset": 59}, {"referenceID": 13, "context": "Differential privacy [14] is another method provides an exact way to publish statistics of a database with specified amount of privacy.", "startOffset": 21, "endOffset": 25}, {"referenceID": 41, "context": "Recently [42] proposed concern of privacy for deep learning and [1] provided differential private deep learning model.", "startOffset": 9, "endOffset": 13}, {"referenceID": 0, "context": "Recently [42] proposed concern of privacy for deep learning and [1] provided differential private deep learning model.", "startOffset": 64, "endOffset": 67}, {"referenceID": 34, "context": "A good survey of all methods attempted to provide visual privacy, can be found in [35], which classifies different methods to five categories: intervention, blind vision, secure processing, redaction and data hiding.", "startOffset": 82, "endOffset": 86}, {"referenceID": 32, "context": "A fundamental work in this category is presented in [33], which targets privacy issue in video surveillance data.", "startOffset": 52, "endOffset": 56}, {"referenceID": 20, "context": "Most of the works in this area use visual filters or morphing to make the image unrecognizable [21,38].", "startOffset": 95, "endOffset": 102}, {"referenceID": 37, "context": "Most of the works in this area use visual filters or morphing to make the image unrecognizable [21,38].", "startOffset": 95, "endOffset": 102}, {"referenceID": 5, "context": "In [6], the authors provide a secure protocol for machine learning.", "startOffset": 3, "endOffset": 6}, {"referenceID": 14, "context": "In [15], the neural network is held in cloud.", "startOffset": 3, "endOffset": 7}], "year": 2017, "abstractText": "The increasing quality of smartphone cameras and variety of photo editing applications, in addition to the rise in popularity of image-centric social media, have all led to a phenomenal growth in mobile-based photography. Advances in computer vision and machine learning techniques provide a large number of cloud-based services with the ability to provide content analysis, face recognition, and object detection facilities to third parties. These inferences and analytics might come with undesired privacy risks to the individuals. In this paper, we address a fundamental challenge: Can we utilize the local processing capabilities of modern smartphones efficiently to provide desired features to approved analytics services, while protecting against undesired inference attacks and preserving privacy on the cloud? We propose a hybrid architecture for a distributed deep learning model between the smartphone and the cloud. We rely on the Siamese network and machine learning approaches for providing privacy based on defined privacy constraints. We also use transfer learning techniques to evaluate the proposed method. Using the latest deep learning models for Face Recognition, Emotion Detection, and Gender Classification techniques, we demonstrate the effectiveness of our technique in providing highly accurate classification results for the desired analytics, while proving strong privacy guarantees.", "creator": "LaTeX with hyperref package"}}}