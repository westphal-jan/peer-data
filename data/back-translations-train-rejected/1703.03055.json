{"id": "1703.03055", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Mar-2017", "title": "Interpretable Structure-Evolving LSTM", "abstract": "This paper develops a general framework for learning interpretable data representation via Long Short-Term Memory (LSTM) recurrent neural networks over hierarchal graph structures. Instead of learning LSTM models over the pre-fixed structures, we propose to further learn the intermediate interpretable multi-level graph structures in a progressive and stochastic way from data during the LSTM network optimization. We thus call this model the structure-evolving LSTM. In particular, starting with an initial element-level graph representation where each node is a small data element, the structure-evolving LSTM gradually evolves the multi-level graph representations by stochastically merging the graph nodes with high compatibilities along the stacked LSTM layers. In each LSTM layer, we estimate the compatibility of two connected nodes from their corresponding LSTM gate outputs, which is used to generate a merging probability. The candidate graph structures are accordingly generated where the nodes are grouped into cliques with their merging probabilities. We then produce the new graph structure with a Metropolis-Hasting algorithm, which alleviates the risk of getting stuck in local optimums by stochastic sampling with an acceptance probability. Once a graph structure is accepted, a higher-level graph is then constructed by taking the partitioned cliques as its nodes. During the evolving process, representation becomes more abstracted in higher-levels where redundant information is filtered out, allowing more efficient propagation of long-range data dependencies. We evaluate the effectiveness of structure-evolving LSTM in the application of semantic object parsing and demonstrate its advantage over state-of-the-art LSTM models on standard benchmarks.", "histories": [["v1", "Wed, 8 Mar 2017 22:09:38 GMT  (5889kb,D)", "http://arxiv.org/abs/1703.03055v1", "To appear in CVPR 2017 as a spotlight paper"]], "COMMENTS": "To appear in CVPR 2017 as a spotlight paper", "reviews": [], "SUBJECTS": "cs.CV cs.AI cs.LG", "authors": ["xiaodan liang", "liang lin", "xiaohui shen", "jiashi feng", "shuicheng yan", "eric p xing"], "accepted": false, "id": "1703.03055"}, "pdf": {"name": "1703.03055.pdf", "metadata": {"source": "CRF", "title": "Interpretable Structure-Evolving LSTM", "authors": ["Xiaodan Liang", "Liang Lin", "Xiaohui Shen", "Jiashi Feng", "Shuicheng Yan", "Eric P. Xing"], "emails": ["xiaodan1@cs.cmu.edu,", "linliang@ieee.org,", "xshen@adobe.com,", "elefjia@nus.edu.sg,", "eleyans@nus.edu.sg,", "epxing@cs.cmu.edu"], "sections": [{"heading": "1. Introduction", "text": "In fact, most of them will be able to play by the rules they have imposed on themselves."}, {"heading": "2. Related Works", "text": "Long-term short-term memory (LSTM) was first introduced to address sequential prediction tasks [10, 23, 31, 13] and then extended to multi-dimensional image processing tasks [4, 25] such as image generation [27, 25], scene labeling [3] and object parsing [17]. They can maintain long-term memory by training appropriate gate weights and practically showing the effectiveness of a number of problems [4, 3]. For image processing, the prediction of each pixel is designed to be affected by fixed factorization (e.g. 2 or 8 adjacent pixels)."}, {"heading": "3. Structure-evolving LSTM", "text": "Suppose the initialized graph for the data is called G (0) = < V (0), E (0) >, where V (0) and E (0) are the corresponding graph nodes (e.g. data elements) and edges. Each node v0i-V (0), {i-1, \u00b7 \u00b7, N0} is represented by the deep features f (0) i from the underlying CNN model with D dimensions. Based on the LSTM gate outputs and the graph G (t) in the previous T-th LSTM layer, the structural developing LSTM then learns a high-level graph structure G (t + 1) = < V (t + 1), E (t + 1) > for the information propagation in the (t + 1) -th LSTM layer. Learning new graph structures and updating LSTM parameters are performed alternatively at the end of the network parameters."}, {"heading": "3.1. Basic LSTM Units", "text": "It is the manner in which the individual nodes of the individual nodes of the individual nodes of the individual nodes (nodes) of the individual nodes of the individual nodes (nodes) of the individual nodes (nodes) of the individual nodes (nodes) of the individual nodes (nodes) of the individual nodes (nodes) of the individual nodes (nodes) of the individual nodes (nodes) of the individual nodes (nodes) of the individual nodes (nodes) of the individual nodes (nodes) of the individual nodes (nodes) of the individual nodes (nodes) of the individual nodes (nodes) of the individual nodes of the individual nodes (nodes) of the individual nodes of the individual nodes (s) of the various nodes (s) of the various nodes (s) of the various (s) of the various (s) of the (s) of the mixed nodes of the individual nodes of the individual (s) of the (s) of the (s) of the individual (s) of the (s) of the (s) of the (s) of the (s) of) of the (s) of the (s) of the (s) of the (s) of the (s) of) of the (s) of the (s) of the (s) of the (s) of) of the (s) of the (s) of the (s) of the (s) of the (s) of the (s) of the (s) of the (s) of) of the (s) of the (s) of the (s) of the (s) of the (s) of) of the various (s) of the (s) of the (s) of the (s) of the (s) of the (s) of the (s) of the (s) of the (s) of the (s) of the (s) of the various nos of) of the (s) of the (s of) of the various (s of the (s) of the (s) of the (s) of) of the (s) of the (s) of) of the (s) of the various (s of) of the (s of) of"}, {"heading": "3.2. Interpretable Structure Evolving", "text": "Given the graph structure G (t) = < V (t), E (t) > and all merging probabilities (q) (q), < i, j > E (t), the high-level graph structure G (t + 1) can be developed by stochastic merging of some graph nodes and can be studied with an acceptance probability as shown in Figure 2. Specifically, a new graph G (t + 1) is constructed by merging some graph nodes with the merging probability. As there is no deterministic transition path from an initial graph to the final graph, it is intractable to list all possible G (t + 1) for evaluation within the large search space. Therefore, we use a stochastic mechanism instead of a deterministic one to find a good graph. Such a stochastic search scheme is also effective to reduce the risk of getting caught in a bad local optimum."}, {"heading": "4. Experiments", "text": "The proposed structural evolving LSTM aims to create a basic framework for dynamic learning of hierarchical data structures suitable for various tasks (e.g. understanding of natural language and image content).Among all these applications, the task of semantic object analysis, which requires pixel-by-pixel labeling taking into account the complex interactions between different pixels, superpixels or parts, is a perfect complement to better assess the ability of our structural evolving LSTM. Our dynamically developed hierarchical graph structures can effectively capture the complex and diverse contextual dependencies. We therefore evaluate the effectiveness of the proposed structural evolving LSTM model on the task of semantic object analysis (i.e. segmentation of an object in the image into its semantic parts), where the use of multi-level graphs for the image content is very natural and useful for the final analysis result."}, {"heading": "4.1. Semantic Object Parsing Task", "text": "We take object analysis as our application scenario, which aims to generate pixel-by-pixel semantic sub-segmentation for each image, as in Fig. 3. The initial graph G (0) is built on superpixels obtained by over-segmenting the image using SLIC [1] to [16]. Each superpixel displays a graph node and each graph edge connects two spatially adjacent superpixel nodes. The input image first passes through a stack of Constitutional layers to generate Convolutionary Characteristics Maps. Input characteristics f0i of each graph node vi are calculated by averaging the Convolutionary Characteristics of all pixels belonging to the same superpixel node. Five structurally evolving LSTM layers are then stacked to learn multi-level graph representations by subordinating some nodes to a large node with the contiguous meaning."}, {"heading": "4.2. Datasets and Implementation Details", "text": "In fact, most of them are able to survive themselves if they are not able to survive themselves, \"he told the German Press Agency.\" I don't think they are able to survive me, \"he said.\" I don't think they are able to survive me. \"He added,\" I don't think they are able to survive me. \"He added,\" I don't think they are able to survive me. \"He added,\" I don't think they are able to survive themselves. \"He added,\" I don't think they are able to survive themselves. \""}, {"heading": "4.3. Results and Comparisons", "text": "In fact, it is the case that most of them are able to move into another world, in which they are able to move, in which they move, in which they move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they, in which they live, in which they live, in which they are able to move, in which they are able to move, in which they are able to move, in which they are able to move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live."}, {"heading": "5. Conclusion", "text": "We introduced a novel, interpretable, structure-evolving graph LSTM that simultaneously learns multi-level graph representations for the data and LSTM network parameters in an end-to-end manner. As we follow the line of graph-based RNNs, our work improves the way the underlying multi-level graph structures evolve along with parameter learning, allowing the network to learn representations to better match the hidden structure of the data. Furthermore, we propose a principled approach to gradually develop graph structures, which is not easy and may have potential implications for the application of graph-based RNNNs in multiple areas. We have demonstrated its effectiveness in the task of object analysis for an image. In the future, the structure-evolving LSTM may be expanded to allow the reversible transition of graphs (e.g. the splitting of some composite nodes) during network optimization."}], "references": [{"title": "Slic superpixels", "author": ["R. Achanta", "A. Shaji", "K. Smith", "A. Lucchi", "P. Fua", "S. S\u00fcsstrunk"], "venue": "Technical report,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2010}, {"title": "Graph partition by swendsen-wang cuts", "author": ["A. Barbu", "S. Zhu"], "venue": "Computer Vision, 2003. Proceedings. Ninth IEEE International Conference on, pages 320\u2013327,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2003}, {"title": "Scene Labeling with LSTM Recurrent Neural Networks", "author": ["W. Byeon", "T.M. Breuel", "F. Raue", "M. Liwicki"], "venue": "CVPR, pages 3547\u20133555,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}, {"title": "Texture classification using 2d lstm networks", "author": ["W. Byeon", "M. Liwicki", "T.M. Breuel"], "venue": "ICPR, pages 1144\u20131149,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2014}, {"title": "Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs", "author": ["L.-C. Chen", "G. Papandreou", "I. Kokkinos", "K. Murphy", "A.L. Yuille"], "venue": "ICLR,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2015}, {"title": "Attention to scale: Scale-aware semantic image segmentation", "author": ["L.-C. Chen", "Y. Yang", "J. Wang", "W. Xu", "A.L. Yuille"], "venue": "CVPR,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2016}, {"title": "Detect what you can: Detecting and representing objects using holistic models and body parts", "author": ["X. Chen", "R. Mottaghi", "X. Liu", "S. Fidler", "R. Urtasun"], "venue": "In CVPR,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "Multidimensional recurrent neural networks", "author": ["A. Graves", "S. Fernandez", "J. Schmidhuber"], "venue": "ICANN,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2007}, {"title": "Speech recognition with deep recurrent neural networks", "author": ["A. Graves", "A.-r. Mohamed", "G. Hinton"], "venue": "In ICASSP, pages 6645\u20136649,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2013}, {"title": "Offline handwriting recognition with multidimensional recurrent neural networks", "author": ["A. Graves", "J. Schmidhuber"], "venue": "NIPS, pages 545\u2013552,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2009}, {"title": "Caffe: Convolutional architecture for fast feature embedding", "author": ["Y. Jia", "E. Shelhamer", "J. Donahue", "S. Karayev", "J. Long", "R. Girshick", "S. Guadarrama", "T. Darrell"], "venue": "ACM Multimedia,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2014}, {"title": "An empirical exploration of recurrent network architectures", "author": ["R. J\u00f3zefowicz", "W. Zaremba", "I. Sutskever"], "venue": "ICML, pages 2342\u20132350,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2015}, {"title": "Grid long short-term memory", "author": ["N. Kalchbrenner", "I. Danihelka", "A. Graves"], "venue": "arXiv preprint arXiv:1507.01526,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep human parsing with active template regression", "author": ["X. Liang", "S. Liu", "X. Shen", "J. Yang", "L. Liu", "J. Dong", "L. Lin", "S. Yan"], "venue": "TPAMI,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2015}, {"title": "Semantic object parsing with graph lstm", "author": ["X. Liang", "X. Shen", "J. Feng", "L. Lin", "S. Yan"], "venue": "ECCV,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2016}, {"title": "Semantic object parsing with local-global long short-term memory", "author": ["X. Liang", "X. Shen", "D. Xiang", "J. Feng", "L. Lin", "S. Yan"], "venue": "CVPR,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2016}, {"title": "Human parsing with contextualized convolutional neural network", "author": ["X. Liang", "C. Xu", "X. Shen", "J. Yang", "S. Liu", "J. Tang", "L. Lin", "S. Yan"], "venue": "ICCV,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2015}, {"title": "Matching-CNN Meets KNN: Quasi- Parametric Human Parsing", "author": ["S. Liu", "X. Liang", "L. Liu", "X. Shen", "J. Yang", "C. Xu", "L. Lin", "X. Cao", "S. Yan"], "venue": "CVPR,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2015}, {"title": "Fully convolutional networks for semantic segmentation", "author": ["J. Long", "E. Shelhamer", "T. Darrell"], "venue": "arXiv preprint arXiv:1411.4038,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["K. Simonyan", "A. Zisserman"], "venue": "arXiv preprint arXiv:1409.1556,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2014}, {"title": "End-to-end people detection in crowded scenes", "author": ["R. Stewart", "M. Andriluka"], "venue": "NIPS,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2015}, {"title": "Sequence to sequence learning with neural networks", "author": ["I. Sutskever", "O. Vinyals", "Q.V. Le"], "venue": "NIPS, pages 3104\u20133112,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2014}, {"title": "Improved semantic representations from tree-structured long short-term memory networks", "author": ["K.S. Tai", "R. Socher", "C.D. Manning"], "venue": "arXiv preprint arXiv:1503.00075,", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2015}, {"title": "Generative image modeling using spatial lstms", "author": ["L. Theis", "M. Bethge"], "venue": "arXiv preprint arXiv:1506.03478,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2015}, {"title": "Image segmentation by data-driven markov chain monte carlo", "author": ["Z. Tu", "S.-C. Zhu"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on, 24(5):657\u2013673,", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2002}, {"title": "Pixel recurrent neural networks", "author": ["A. van den Oord", "N. Kalchbrenner", "K. Kavukcuoglu"], "venue": "ICML, 2016", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2016}, {"title": "Semantic part segmentation using compositional model combining shape and appearance", "author": ["J. Wang", "A. Yuille"], "venue": "CVPR,", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2015}, {"title": "Joint object and part segmentation using deep learned potentials", "author": ["P. Wang", "X. Shen", "Z. Lin", "S. Cohen", "B. Price", "A. Yuille"], "venue": "ICCV,", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2015}, {"title": "Zoom better to see clearer: Huamn part segmentation with auto zoom net", "author": ["F. Xia", "P. Wang", "L.-C. Chen", "A.L. Yuille"], "venue": "arXiv preprint arXiv:1511.06881,", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2015}, {"title": "Show, attend and tell: Neural image caption generation with visual attention", "author": ["K. Xu", "J. Ba", "R. Kiros", "K. Cho", "A.C. Courville", "R. Salakhutdinov", "R.S. Zemel", "Y. Bengio"], "venue": "ICML, pages 2048\u20132057,", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2015}, {"title": "Paper doll parsing: Retrieving similar styles to parse clothing items", "author": ["K. Yamaguchi", "M. Kiapour", "T. Berg"], "venue": "ICCV,", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2013}, {"title": "Parsing clothing in fashion photographs", "author": ["K. Yamaguchi", "M. Kiapour", "L. Ortiz", "T. Berg"], "venue": "CVPR,", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2012}, {"title": "Conditional random fields as recurrent neural networks", "author": ["S. Zheng", "S. Jayasumana", "B. Romera-Paredes", "V. Vineet", "Z. Su", "D. Du", "C. Huang", "P. Torr"], "venue": "ICCV,", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2015}, {"title": "Long short-term memory over tree structures", "author": ["X. Zhu", "P. Sobhani", "H. Guo"], "venue": "arXiv preprint arXiv:1503.04881,", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2015}], "referenceMentions": [{"referenceID": 8, "context": "Recently, there has been a surge of interest in developing various kinds of Long Short-Term Memory (LSTM) neural networks for modeling complex dependencies within sequential and multi-dimensional data, due to their advantage in a wide range of applications such as speech recognition [9], image generation [27], image-to-caption generation [31] and multi-dimensional image processing [14].", "startOffset": 284, "endOffset": 287}, {"referenceID": 25, "context": "Recently, there has been a surge of interest in developing various kinds of Long Short-Term Memory (LSTM) neural networks for modeling complex dependencies within sequential and multi-dimensional data, due to their advantage in a wide range of applications such as speech recognition [9], image generation [27], image-to-caption generation [31] and multi-dimensional image processing [14].", "startOffset": 306, "endOffset": 310}, {"referenceID": 29, "context": "Recently, there has been a surge of interest in developing various kinds of Long Short-Term Memory (LSTM) neural networks for modeling complex dependencies within sequential and multi-dimensional data, due to their advantage in a wide range of applications such as speech recognition [9], image generation [27], image-to-caption generation [31] and multi-dimensional image processing [14].", "startOffset": 340, "endOffset": 344}, {"referenceID": 12, "context": "Recently, there has been a surge of interest in developing various kinds of Long Short-Term Memory (LSTM) neural networks for modeling complex dependencies within sequential and multi-dimensional data, due to their advantage in a wide range of applications such as speech recognition [9], image generation [27], image-to-caption generation [31] and multi-dimensional image processing [14].", "startOffset": 384, "endOffset": 388}, {"referenceID": 8, "context": "Despite the remarkable success, existing LSTM models such as chain-structured [9] [31], tree-structured LSTM models [35, 24] and graph-structured LSTM [16] can only process data with pre-fixed structures in terms of their internal information propagation route.", "startOffset": 78, "endOffset": 81}, {"referenceID": 29, "context": "Despite the remarkable success, existing LSTM models such as chain-structured [9] [31], tree-structured LSTM models [35, 24] and graph-structured LSTM [16] can only process data with pre-fixed structures in terms of their internal information propagation route.", "startOffset": 82, "endOffset": 86}, {"referenceID": 33, "context": "Despite the remarkable success, existing LSTM models such as chain-structured [9] [31], tree-structured LSTM models [35, 24] and graph-structured LSTM [16] can only process data with pre-fixed structures in terms of their internal information propagation route.", "startOffset": 116, "endOffset": 124}, {"referenceID": 22, "context": "Despite the remarkable success, existing LSTM models such as chain-structured [9] [31], tree-structured LSTM models [35, 24] and graph-structured LSTM [16] can only process data with pre-fixed structures in terms of their internal information propagation route.", "startOffset": 116, "endOffset": 124}, {"referenceID": 14, "context": "Despite the remarkable success, existing LSTM models such as chain-structured [9] [31], tree-structured LSTM models [35, 24] and graph-structured LSTM [16] can only process data with pre-fixed structures in terms of their internal information propagation route.", "startOffset": 151, "endOffset": 155}, {"referenceID": 8, "context": "Compared with existing LSTM structures with pre-fixed chain [9] [31], tree [35, 24] or graph topologies [16], the structure-evolving LSTM has the capability of modeling long-range interactions using the dynamically evolved hierarchical graph topologies to capture the multi-level inherent correlations embedded in the data.", "startOffset": 60, "endOffset": 63}, {"referenceID": 29, "context": "Compared with existing LSTM structures with pre-fixed chain [9] [31], tree [35, 24] or graph topologies [16], the structure-evolving LSTM has the capability of modeling long-range interactions using the dynamically evolved hierarchical graph topologies to capture the multi-level inherent correlations embedded in the data.", "startOffset": 64, "endOffset": 68}, {"referenceID": 33, "context": "Compared with existing LSTM structures with pre-fixed chain [9] [31], tree [35, 24] or graph topologies [16], the structure-evolving LSTM has the capability of modeling long-range interactions using the dynamically evolved hierarchical graph topologies to capture the multi-level inherent correlations embedded in the data.", "startOffset": 75, "endOffset": 83}, {"referenceID": 22, "context": "Compared with existing LSTM structures with pre-fixed chain [9] [31], tree [35, 24] or graph topologies [16], the structure-evolving LSTM has the capability of modeling long-range interactions using the dynamically evolved hierarchical graph topologies to capture the multi-level inherent correlations embedded in the data.", "startOffset": 75, "endOffset": 83}, {"referenceID": 14, "context": "Compared with existing LSTM structures with pre-fixed chain [9] [31], tree [35, 24] or graph topologies [16], the structure-evolving LSTM has the capability of modeling long-range interactions using the dynamically evolved hierarchical graph topologies to capture the multi-level inherent correlations embedded in the data.", "startOffset": 104, "endOffset": 108}, {"referenceID": 1, "context": "Then the graph structure is generated by designing a Metropolis-Hasting algorithm [2, 26].", "startOffset": 82, "endOffset": 89}, {"referenceID": 24, "context": "Then the graph structure is generated by designing a Metropolis-Hasting algorithm [2, 26].", "startOffset": 82, "endOffset": 89}, {"referenceID": 9, "context": "Long Short-Term Memory (LSTM) recurrent networks have been first introduced to address the sequential prediction tasks [10, 23, 31, 13], and then extended to multidimensional image processing tasks [4, 25] such as image generation [27, 25], person detection [22], scene labeling [3] and object parsing [17].", "startOffset": 119, "endOffset": 135}, {"referenceID": 21, "context": "Long Short-Term Memory (LSTM) recurrent networks have been first introduced to address the sequential prediction tasks [10, 23, 31, 13], and then extended to multidimensional image processing tasks [4, 25] such as image generation [27, 25], person detection [22], scene labeling [3] and object parsing [17].", "startOffset": 119, "endOffset": 135}, {"referenceID": 29, "context": "Long Short-Term Memory (LSTM) recurrent networks have been first introduced to address the sequential prediction tasks [10, 23, 31, 13], and then extended to multidimensional image processing tasks [4, 25] such as image generation [27, 25], person detection [22], scene labeling [3] and object parsing [17].", "startOffset": 119, "endOffset": 135}, {"referenceID": 11, "context": "Long Short-Term Memory (LSTM) recurrent networks have been first introduced to address the sequential prediction tasks [10, 23, 31, 13], and then extended to multidimensional image processing tasks [4, 25] such as image generation [27, 25], person detection [22], scene labeling [3] and object parsing [17].", "startOffset": 119, "endOffset": 135}, {"referenceID": 3, "context": "Long Short-Term Memory (LSTM) recurrent networks have been first introduced to address the sequential prediction tasks [10, 23, 31, 13], and then extended to multidimensional image processing tasks [4, 25] such as image generation [27, 25], person detection [22], scene labeling [3] and object parsing [17].", "startOffset": 198, "endOffset": 205}, {"referenceID": 23, "context": "Long Short-Term Memory (LSTM) recurrent networks have been first introduced to address the sequential prediction tasks [10, 23, 31, 13], and then extended to multidimensional image processing tasks [4, 25] such as image generation [27, 25], person detection [22], scene labeling [3] and object parsing [17].", "startOffset": 198, "endOffset": 205}, {"referenceID": 25, "context": "Long Short-Term Memory (LSTM) recurrent networks have been first introduced to address the sequential prediction tasks [10, 23, 31, 13], and then extended to multidimensional image processing tasks [4, 25] such as image generation [27, 25], person detection [22], scene labeling [3] and object parsing [17].", "startOffset": 231, "endOffset": 239}, {"referenceID": 23, "context": "Long Short-Term Memory (LSTM) recurrent networks have been first introduced to address the sequential prediction tasks [10, 23, 31, 13], and then extended to multidimensional image processing tasks [4, 25] such as image generation [27, 25], person detection [22], scene labeling [3] and object parsing [17].", "startOffset": 231, "endOffset": 239}, {"referenceID": 20, "context": "Long Short-Term Memory (LSTM) recurrent networks have been first introduced to address the sequential prediction tasks [10, 23, 31, 13], and then extended to multidimensional image processing tasks [4, 25] such as image generation [27, 25], person detection [22], scene labeling [3] and object parsing [17].", "startOffset": 258, "endOffset": 262}, {"referenceID": 2, "context": "Long Short-Term Memory (LSTM) recurrent networks have been first introduced to address the sequential prediction tasks [10, 23, 31, 13], and then extended to multidimensional image processing tasks [4, 25] such as image generation [27, 25], person detection [22], scene labeling [3] and object parsing [17].", "startOffset": 279, "endOffset": 282}, {"referenceID": 15, "context": "Long Short-Term Memory (LSTM) recurrent networks have been first introduced to address the sequential prediction tasks [10, 23, 31, 13], and then extended to multidimensional image processing tasks [4, 25] such as image generation [27, 25], person detection [22], scene labeling [3] and object parsing [17].", "startOffset": 302, "endOffset": 306}, {"referenceID": 3, "context": "It can keep long-term memory by training proper gating weights and has practically showed the effectiveness on a range of problems [4, 3].", "startOffset": 131, "endOffset": 137}, {"referenceID": 2, "context": "It can keep long-term memory by training proper gating weights and has practically showed the effectiveness on a range of problems [4, 3].", "startOffset": 131, "endOffset": 137}, {"referenceID": 12, "context": ", 2 or 8 neighboring pixels [14][8][17] or diagonal neighborhood [27][25]).", "startOffset": 28, "endOffset": 32}, {"referenceID": 7, "context": ", 2 or 8 neighboring pixels [14][8][17] or diagonal neighborhood [27][25]).", "startOffset": 32, "endOffset": 35}, {"referenceID": 15, "context": ", 2 or 8 neighboring pixels [14][8][17] or diagonal neighborhood [27][25]).", "startOffset": 35, "endOffset": 39}, {"referenceID": 25, "context": ", 2 or 8 neighboring pixels [14][8][17] or diagonal neighborhood [27][25]).", "startOffset": 65, "endOffset": 69}, {"referenceID": 23, "context": ", 2 or 8 neighboring pixels [14][8][17] or diagonal neighborhood [27][25]).", "startOffset": 69, "endOffset": 73}, {"referenceID": 22, "context": "Recently, Tree-LSTM [24] introduces the structure with tree-structured topologies for predicting semantic representations of sentences.", "startOffset": 20, "endOffset": 24}, {"referenceID": 14, "context": "LSTM [16] has been proposed to propagate information on a basic pre-defined graph topology to capture diverse natural visual correlations (e.", "startOffset": 5, "endOffset": 9}, {"referenceID": 12, "context": "Different from using pre-defined data structures in previous LSTMs [14, 8, 17, 16, 25], the proposed structureevolving LSTM targets on automatically learning the hierarchical graph representations by evolving from an initial graph structure.", "startOffset": 67, "endOffset": 86}, {"referenceID": 7, "context": "Different from using pre-defined data structures in previous LSTMs [14, 8, 17, 16, 25], the proposed structureevolving LSTM targets on automatically learning the hierarchical graph representations by evolving from an initial graph structure.", "startOffset": 67, "endOffset": 86}, {"referenceID": 15, "context": "Different from using pre-defined data structures in previous LSTMs [14, 8, 17, 16, 25], the proposed structureevolving LSTM targets on automatically learning the hierarchical graph representations by evolving from an initial graph structure.", "startOffset": 67, "endOffset": 86}, {"referenceID": 14, "context": "Different from using pre-defined data structures in previous LSTMs [14, 8, 17, 16, 25], the proposed structureevolving LSTM targets on automatically learning the hierarchical graph representations by evolving from an initial graph structure.", "startOffset": 67, "endOffset": 86}, {"referenceID": 23, "context": "Different from using pre-defined data structures in previous LSTMs [14, 8, 17, 16, 25], the proposed structureevolving LSTM targets on automatically learning the hierarchical graph representations by evolving from an initial graph structure.", "startOffset": 67, "endOffset": 86}, {"referenceID": 14, "context": "The structure-evolving LSTM (dynamically evolving multi-level graphs) is superior to the most related Graph LSTM [16] (a pre-fixed single-level graph) in two aspects: 1) Structure-evolving LSTM learns more powerful representations as it progressively exploits hierarchical information along stacked LSTM layers; 2) at its later layers, the structure-evolving LSTM captures the inherent structure of the desired output benefiting from the higher-level graph topologies.", "startOffset": 113, "endOffset": 117}, {"referenceID": 14, "context": "These superiorities bring significant improvements on several semantic parsing datasets, which gives apple-to-apple comparison with [16].", "startOffset": 132, "endOffset": 136}, {"referenceID": 14, "context": "Following [16], we randomly specify the node updating sequence to propagate information to all nodes in order to increase the model diversity during learning the LSTM network parameters.", "startOffset": 10, "endOffset": 14}, {"referenceID": 14, "context": "Our structure-evolving LSTM follows the Graph LSTM units [16] to generate hidden and memory cells, and then show how to inject the edge merging probabilities of the nodes into the LSTM units.", "startOffset": 57, "endOffset": 61}, {"referenceID": 1, "context": "To find a better graph transition between two graphs G and G, the acceptance rate of the transition from the graph from G to graph G is defined by a Metropolis-Hastings method [2, 26]:", "startOffset": 176, "endOffset": 183}, {"referenceID": 24, "context": "To find a better graph transition between two graphs G and G, the acceptance rate of the transition from the graph from G to graph G is defined by a Metropolis-Hastings method [2, 26]:", "startOffset": 176, "endOffset": 183}, {"referenceID": 0, "context": "The initial graph G is constructed on superpixels that are obtained through image over-segmentation using SLIC [1] following [16].", "startOffset": 111, "endOffset": 114}, {"referenceID": 14, "context": "The initial graph G is constructed on superpixels that are obtained through image over-segmentation using SLIC [1] following [16].", "startOffset": 125, "endOffset": 129}, {"referenceID": 6, "context": "Comparison of semantic object parsing performance with several state-of-the-art methods on the PASCAL-Person-Part dataset [7] and with other variants of the structure-evolving LSTM model, including using different LSTM structures, the extracted multi-scale superpixel maps and a deterministic policy with different thresholds for the graph transition, respectively.", "startOffset": 122, "endOffset": 125}, {"referenceID": 4, "context": "DeepLab-LargeFOV [5] 78.", "startOffset": 17, "endOffset": 20}, {"referenceID": 4, "context": "78 DeepLab-LargeFOV-CRF [5] 80.", "startOffset": 24, "endOffset": 27}, {"referenceID": 28, "context": "95 HAZN [30] 80.", "startOffset": 8, "endOffset": 12}, {"referenceID": 5, "context": "11 Attention [6] - - - - - - - 56.", "startOffset": 13, "endOffset": 16}, {"referenceID": 12, "context": "Grid LSTM [14] 81.", "startOffset": 10, "endOffset": 14}, {"referenceID": 25, "context": "90 Row LSTM [27] 82.", "startOffset": 12, "endOffset": 16}, {"referenceID": 25, "context": "80 Diagonal BiLSTM [27] 82.", "startOffset": 19, "endOffset": 23}, {"referenceID": 15, "context": "62 LG-LSTM [17] 82.", "startOffset": 11, "endOffset": 15}, {"referenceID": 14, "context": "97 Graph LSTM [16] 82.", "startOffset": 14, "endOffset": 18}, {"referenceID": 14, "context": "Graph LSTM (multi-scale superpixel maps) [16] 83.", "startOffset": 41, "endOffset": 45}, {"referenceID": 6, "context": "The PASCAL-Person-part dataset [7] concentrates on the human part segmentation on images from PASCAL VOC 2010.", "startOffset": 31, "endOffset": 34}, {"referenceID": 26, "context": "The Horse-Cow parsing dataset is a part segmentation benchmark introduced in [28].", "startOffset": 77, "endOffset": 81}, {"referenceID": 13, "context": "Originally, 7,700 images are included in the ATR dataset [15], with 6,000 for training, 1,000 for testing and 700 for validation.", "startOffset": 57, "endOffset": 61}, {"referenceID": 16, "context": "10,000 images are further collected by [18] to cover images with more challenging poses and clothes variations.", "startOffset": 39, "endOffset": 43}, {"referenceID": 6, "context": "Evaluation metric: The standard intersection over union (IOU) criterion and pixel-wise accuracy are adopted for evaluation on PASCAL-Person-Part dataset and HorseCow parsing dataset, following [7].", "startOffset": 193, "endOffset": 196}, {"referenceID": 13, "context": "We use the same evaluation metrics as in [15, 18] for evaluation on the human parsing dataset, including accuracy, average precision, average recall, and average F-1 score.", "startOffset": 41, "endOffset": 49}, {"referenceID": 16, "context": "We use the same evaluation metrics as in [15, 18] for evaluation on the human parsing dataset, including accuracy, average precision, average recall, and average F-1 score.", "startOffset": 41, "endOffset": 49}, {"referenceID": 4, "context": "Network architecture: For fair comparison with [5, 30, 6], our network is based on the publicly available model, DeepLab-CRF-LargeFOV\u201d [5] for the PASCAL-PersonPart and Horse-Cow parsing dataset, which slightly modifies VGG-16 net [21] to FCN [20].", "startOffset": 47, "endOffset": 57}, {"referenceID": 28, "context": "Network architecture: For fair comparison with [5, 30, 6], our network is based on the publicly available model, DeepLab-CRF-LargeFOV\u201d [5] for the PASCAL-PersonPart and Horse-Cow parsing dataset, which slightly modifies VGG-16 net [21] to FCN [20].", "startOffset": 47, "endOffset": 57}, {"referenceID": 5, "context": "Network architecture: For fair comparison with [5, 30, 6], our network is based on the publicly available model, DeepLab-CRF-LargeFOV\u201d [5] for the PASCAL-PersonPart and Horse-Cow parsing dataset, which slightly modifies VGG-16 net [21] to FCN [20].", "startOffset": 47, "endOffset": 57}, {"referenceID": 4, "context": "Network architecture: For fair comparison with [5, 30, 6], our network is based on the publicly available model, DeepLab-CRF-LargeFOV\u201d [5] for the PASCAL-PersonPart and Horse-Cow parsing dataset, which slightly modifies VGG-16 net [21] to FCN [20].", "startOffset": 135, "endOffset": 138}, {"referenceID": 19, "context": "Network architecture: For fair comparison with [5, 30, 6], our network is based on the publicly available model, DeepLab-CRF-LargeFOV\u201d [5] for the PASCAL-PersonPart and Horse-Cow parsing dataset, which slightly modifies VGG-16 net [21] to FCN [20].", "startOffset": 231, "endOffset": 235}, {"referenceID": 18, "context": "Network architecture: For fair comparison with [5, 30, 6], our network is based on the publicly available model, DeepLab-CRF-LargeFOV\u201d [5] for the PASCAL-PersonPart and Horse-Cow parsing dataset, which slightly modifies VGG-16 net [21] to FCN [20].", "startOffset": 243, "endOffset": 247}, {"referenceID": 16, "context": "Co-CNN\u201d structure [18] is used to compare with [15, 18] on one human parsing datasets for fair comparison.", "startOffset": 18, "endOffset": 22}, {"referenceID": 13, "context": "Co-CNN\u201d structure [18] is used to compare with [15, 18] on one human parsing datasets for fair comparison.", "startOffset": 47, "endOffset": 55}, {"referenceID": 16, "context": "Co-CNN\u201d structure [18] is used to compare with [15, 18] on one human parsing datasets for fair comparison.", "startOffset": 47, "endOffset": 55}, {"referenceID": 0, "context": "Training: The SLIC over-segmentation method [1] generates 1,000 superpixels on average for each image.", "startOffset": 44, "endOffset": 47}, {"referenceID": 26, "context": "Comparison of object parsing performance with five stateof-the-art methods over the Horse-Cow object parsing dataset [28].", "startOffset": 117, "endOffset": 121}, {"referenceID": 26, "context": "SPS [28] 79.", "startOffset": 4, "endOffset": 8}, {"referenceID": 27, "context": "18 Joint [29] 87.", "startOffset": 9, "endOffset": 13}, {"referenceID": 15, "context": "49 LG-LSTM [17] 89.", "startOffset": 11, "endOffset": 15}, {"referenceID": 28, "context": "92 HAZN [30] 90.", "startOffset": 8, "endOffset": 12}, {"referenceID": 14, "context": "16 Graph LSTM [16] 91.", "startOffset": 14, "endOffset": 18}, {"referenceID": 26, "context": "SPS [28] 78.", "startOffset": 4, "endOffset": 8}, {"referenceID": 27, "context": "43 Joint [29] 85.", "startOffset": 9, "endOffset": 13}, {"referenceID": 15, "context": "00 LG-LSTM [17] 89.", "startOffset": 11, "endOffset": 15}, {"referenceID": 28, "context": "43 HAZN [30] 90.", "startOffset": 8, "endOffset": 12}, {"referenceID": 14, "context": "94 Graph LSTM [16] 91.", "startOffset": 14, "endOffset": 18}, {"referenceID": 10, "context": "The structureevolving LSTM is implemented by extending the Caffe framework [12].", "startOffset": 75, "endOffset": 79}, {"referenceID": 13, "context": "Performance comparison with state-of-the-art methods when evaluating on ATR dataset [15].", "startOffset": 84, "endOffset": 88}, {"referenceID": 16, "context": "Following [18], we also take the additional 10,000 images in [18] as extra training images, denoted as \u201cOurs (more data)\u201d.", "startOffset": 10, "endOffset": 14}, {"referenceID": 16, "context": "Following [18], we also take the additional 10,000 images in [18] as extra training images, denoted as \u201cOurs (more data)\u201d.", "startOffset": 61, "endOffset": 65}, {"referenceID": 31, "context": "[33] 84.", "startOffset": 0, "endOffset": 4}, {"referenceID": 30, "context": "80 PaperDoll [32] 88.", "startOffset": 13, "endOffset": 17}, {"referenceID": 17, "context": "76 M-CNN [19] 89.", "startOffset": 9, "endOffset": 13}, {"referenceID": 13, "context": "81 ATR [15] 91.", "startOffset": 7, "endOffset": 11}, {"referenceID": 16, "context": "38 Co-CNN [18] 95.", "startOffset": 10, "endOffset": 14}, {"referenceID": 16, "context": "95 Co-CNN (more) [18] 96.", "startOffset": 17, "endOffset": 21}, {"referenceID": 15, "context": "14 LG-LSTM [17] 96.", "startOffset": 11, "endOffset": 15}, {"referenceID": 15, "context": "97 LG-LSTM (more) [17] 96.", "startOffset": 18, "endOffset": 22}, {"referenceID": 32, "context": "12 CRFasRNN (more) [34] 96.", "startOffset": 19, "endOffset": 23}, {"referenceID": 25, "context": "Table 1 gives the performance comparison among different LSTM structures, including Row LSTM [27], Diagonal BiLSTM [27], LG-LSTM [17], Grid LSTM [14] and Graph LSTM [16], which use the same network architecture and number of LSTM layers.", "startOffset": 93, "endOffset": 97}, {"referenceID": 25, "context": "Table 1 gives the performance comparison among different LSTM structures, including Row LSTM [27], Diagonal BiLSTM [27], LG-LSTM [17], Grid LSTM [14] and Graph LSTM [16], which use the same network architecture and number of LSTM layers.", "startOffset": 115, "endOffset": 119}, {"referenceID": 15, "context": "Table 1 gives the performance comparison among different LSTM structures, including Row LSTM [27], Diagonal BiLSTM [27], LG-LSTM [17], Grid LSTM [14] and Graph LSTM [16], which use the same network architecture and number of LSTM layers.", "startOffset": 129, "endOffset": 133}, {"referenceID": 12, "context": "Table 1 gives the performance comparison among different LSTM structures, including Row LSTM [27], Diagonal BiLSTM [27], LG-LSTM [17], Grid LSTM [14] and Graph LSTM [16], which use the same network architecture and number of LSTM layers.", "startOffset": 145, "endOffset": 149}, {"referenceID": 14, "context": "Table 1 gives the performance comparison among different LSTM structures, including Row LSTM [27], Diagonal BiLSTM [27], LG-LSTM [17], Grid LSTM [14] and Graph LSTM [16], which use the same network architecture and number of LSTM layers.", "startOffset": 165, "endOffset": 169}, {"referenceID": 14, "context": "It demonstrates that exploiting more levels of graph structures makes the network parameters learn different levels of semantic abstraction, leading to better parsing results, whereas the previous LSTM model [16] reported that no performance gain is achieved with more than two LSTM layers.", "startOffset": 208, "endOffset": 212}], "year": 2017, "abstractText": "This paper develops a general framework for learning interpretable data representation via Long Short-Term Memory (LSTM) recurrent neural networks over hierarchal graph structures. Instead of learning LSTM models over the pre-fixed structures, we propose to further learn the intermediate interpretable multi-level graph structures in a progressive and stochastic way from data during the LSTM network optimization. We thus call this model the structure-evolving LSTM. In particular, starting with an initial element-level graph representation where each node is a small data element, the structure-evolving LSTM gradually evolves the multi-level graph representations by stochastically merging the graph nodes with high compatibilities along the stacked LSTM layers. In each LSTM layer, we estimate the compatibility of two connected nodes from their corresponding LSTM gate outputs, which is used to generate a merging probability. The candidate graph structures are accordingly generated where the nodes are grouped into cliques with their merging probabilities. We then produce the new graph structure with a Metropolis-Hasting algorithm, which alleviates the risk of getting stuck in local optimums by stochastic sampling with an acceptance probability. Once a graph structure is accepted, a higher-level graph is then constructed by taking the partitioned cliques as its nodes. During the evolving process, representation becomes more abstracted in higher-levels where redundant information is filtered out, allowing more efficient propagation of long-range data dependencies. We evaluate the effectiveness of structure-evolving LSTM in the application of semantic object parsing and demonstrate its advantage over state-of-the-art LSTM models on standard benchmarks.", "creator": "LaTeX with hyperref package"}}}