{"id": "1703.03076", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Mar-2017", "title": "Efficient Simulation of Financial Stress Testing Scenarios with Suppes-Bayes Causal Networks", "abstract": "The most recent financial upheavals have cast doubt on the adequacy of some of the conventional quantitative risk management strategies, such as VaR (Value at Risk), in many common situations. Consequently, there has been an increasing need for verisimilar financial stress testings, namely simulating and analyzing financial portfolios in extreme, albeit rare scenarios. Unlike conventional risk management which exploits statistical correlations among financial instruments, here we focus our analysis on the notion of probabilistic causation, which is embodied by Suppes-Bayes Causal Networks (SBCNs), SBCNs are probabilistic graphical models that have many attractive features in terms of more accurate causal analysis for generating financial stress scenarios. In this paper, we present a novel approach for conducting stress testing of financial portfolios based on SBCNs in combination with classical machine learning classification tools. The resulting method is shown to be capable of correctly discovering the causal relationships among financial factors that affect the portfolios and thus, simulating stress testing scenarios with a higher accuracy and lower computational complexity than conventional Monte Carlo Simulations.", "histories": [["v1", "Wed, 8 Mar 2017 23:54:09 GMT  (842kb,D)", "http://arxiv.org/abs/1703.03076v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.CE", "authors": ["gelin gao", "bud mishra", "daniele ramazzotti"], "accepted": false, "id": "1703.03076"}, "pdf": {"name": "1703.03076.pdf", "metadata": {"source": "CRF", "title": "Efficient Simulation of Financial Stress Testing Scenarios with Suppes-Bayes Causal Networks", "authors": ["Gelin Gao", "Bud Mishra", "Daniele Ramazzotti"], "emails": ["permissions@acm.org."], "sections": [{"heading": null, "text": "In this paper, we present a novel approach to performing stress tests of financial portfolios based on SBCNs in combination with classical classification tools for machine learning, demonstrating that the resulting method is capable of correctly identifying the causal relationships between financial factors that affect portfolios, thereby simulating stress test scenarios with greater accuracy and less computational complexity than traditional Monte Carlo simulations.Key stress tests, Graphic Models, Causality, Causal Networks Suppes-Bayes, Classification, Decision Trees"}, {"heading": "1. INTRODUCTION", "text": "In fact, most of them are able to survive themselves if they do not put themselves in a position to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...)"}, {"heading": "2. METHOD", "text": "In this paper, we use Bayesian Graphical Models [9], popularly known as Bayesian Networks, as a framework for evaluating stress tests, as previously performed by [18] in this context. Bayesian Networks have long been used in biological modeling to determine whether the variables represent genes or financial instruments [2, 10, 14], but their application to financial data analysis has been rare. Roughly speaking, Bayesian Networks seek to exploit the conditional independence between random variables, whether the variables represent genes or financial instruments. In this paper, we adopt a variation of traditional Bayesian Networks, as in [15, 16] where the authors show how the limitation of the search space for valid solutions can be exploited by means of a meaningful theory based on Suppes \"notion of probable cause [23] to develop better learning algorithms."}, {"heading": "2.1 Bayesian networks", "text": "In fact, it is the case that most of them are able to abide by the rules that they have imposed on themselves, and that they are able to abide by the rules that they have imposed on themselves. (...) In fact, it is the case that they are able to abide by the rules. (...) In fact, it is the case that they are able to break the rules in order to break the rules. \"(...)"}, {"heading": "2.2 Suppes-Bayes Causal Networks", "text": "In contrast to [18], our stress test approach is based on Suppes-Bayes causal networks (SBCNs), which are not only more strictly regulated than the general Bayean networks, but also have many other attractive features such as interpretability and refutability. SBCNs use the concept of probable causality originally proposed by Patrick Suppes. In [23], Suppes describes the concept of prima facie causal relationship. A prima facie causal relationship between each event and its effect is verified when the following two conditions apply: (i) temporal priority (TP), i.e., each cause occurs before its effect and (ii) probability increases (PR), i.e. the presence of the cause increases the likelihood of observing its effectiveness."}, {"heading": "2.3 Machine Learning and Classification", "text": "Even if we typically get more sparse DAGs with SBCN than if we use Bayesian networks, the relationships modeled involve both positive and negative financial scenarios, but only in the latter can financial strains occur. Therefore, the extreme events that are central to stress testing are still rare in the data and are unlikely to be simulated in naively generated stress scenarios through direct samples from the SBCN. Therefore, in this work we are improving this basic model with several key ideas of classical machine learning, namely feature classification. Let's remember that in the stress test we want to focus on the unlikely but risky scenarios. In particular, when generating a random sample from an SBCN, in order to obtain possible scenarios, each node in the SBCN can focus on its conditional probability table of any value in its support, with various scenarios being classified from an SBCN to obtain possible scenarios, so that each of the following events can be very profitable, and in order to limit the search space."}, {"heading": "3. RESULTS AND DISCUSSION", "text": "In this section, we will examine the possibilities of our framework based on SBCNs to perform stress tests. We will first describe the generative model used, then present our algorithm and examine its performance, with particular emphasis on the problem of false discoveries."}, {"heading": "3.1 Simulating the Training Data", "text": "In order to evaluate the performance of the algorithm, to learn the SBCNs and the quality of the derived Bayesian networks, a series of training data with embedded causal relationships is developed. If the algorithms performed on the training data are able to accurately restore the causal relationships embedded in them, such accuracy can be expected on real data. To simulate the training data, we adopt a common stock factor model, the Fama French Five Factor Model [7], in which the return on the asset is defined as: (2) r = Rf + \u03b21 (Km \u2212 Rf) + \u03b22SMB + \u03b24RMMMMMM + \u03b24RMMW + \u03b23CMA + \u03b23CMA + \u03b23 temporary distribution, r is the risk-free return on assets normally measured in relation to government funds."}, {"heading": "3.2 Learning the SBCNs", "text": "In this section, we show the results of 100 independent random simulations generated on networks of 15 nodes, i.e., 10 shares and 5 factors using the generative model discussed in the previous section. Each node represents a Bernoulli random variable, the binary values in (0, 1), where 1 represents the stock or the factor that goes up, and 0, the stock or the factor that goes down. In particular, the input of our learning task is a dataset D of n \u00b7 m binary entries. To overcome this problem, we have tried to experiment with our learning algorithms previously described in [14] and [3]. In particular, as in [3], we paint explicitly observed time in the data that are only cross-sector. To overcome this problem, we implied another input to our algorithm that provides information about the time priority between nodes."}, {"heading": "250 50.4 94.9 31.9 95.3 57.0 89.5 39.3 95.2", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "500 51.8 94.7 45.6 96.6 61.6 93.5 51.5 98.7", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "1000 55.2 93.5 47.6 94.5 63.7 85.5 50.4 95.2", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2500 60.3 90.3 54.8 99.9 68.4 85.7 62.4 99.8", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3500 62.5 84.2 58.0 94.3 69.5 85.7 63.7 96.8", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5000 66.6 80.9 65.6 85.7 71.8 85.7 70.7 85.7", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "250 37.6 67.7 24.7 83.3 42.8 40.1 27.9 51.5", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "500 39.6 52.3 36.8 55.9 43.7 38.5 40.9 39.0", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "1000 43.1 39.1 40.7 47.8 47.9 37.6 43.9 38.0", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2500 52.2 50.8 45.1 50.8 57.1 28.5 50.2 38.6", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3500 48.7 33.3 48.7 33.3 58.8 28.5 57.1 28.5", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5000 48.7 33.3 47.5 33.3 57.1 14.3 53.8 19.9", "text": "In this context, it should be noted that this is a very complex and complex matter."}, {"heading": "3.3 Performing Stress Testing", "text": "This year, it is only a matter of time before we reach an agreement."}, {"heading": "4. CONCLUSIONS", "text": "In summary, we find in this paper a novel framework for conducting stress tests, based on target sizes and systematics. We learn SBCNs from data that use algorithms, and assess the quality of the model acquired by changing the target sizes of the SBCNs. We then simulate the stress scenarios by classifying the calculation of the individual nodes in the network as \"profitable\" or \"risky.\" For the simplicity of the paper, the SBCNs are the target sizes and simulate the data using the Fama five-factor model. But the logic of the problem is slightly expanded to deal with the target size situations."}, {"heading": "5. REFERENCES", "text": "[1] H. Akaike. Information Theory and an Extension of the Thematic Maximum Probability Principle. In Selected Papers of Hirotugu Akaike, pp. 199-213. Springer, 1998. [2] N. Beerenwinkel, N. Eriksson, and B. Sturmfels. Subjunctive bayesian networks. Bernoulli, pp. 893-909, 2007. [3] F. Bonchi, S. Hajian, B. Mishra, and D. Ramazzotti G. Exposing the probabilistic causal structure of discrimination. arXiv preprint arXiv: 1510.00552, 2015. [4] G. Caravagna, A. Graudenzi, D. Ramazzotti, R. Sanz-Pamplona, L. De Sano, G. Mauri, V. Moreno, M. Antoniotti, and B. Mishra. Algorithmic Methods for Evolutionary Trajectories in Cancer Progression. PNAS, 2016."}], "references": [{"title": "Information theory and an extension of the maximum likelihood principle", "author": ["H. Akaike"], "venue": "In Selected Papers of Hirotugu Akaike,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1998}, {"title": "Conjunctive bayesian networks", "author": ["N. Beerenwinkel", "N. Eriksson", "B. Sturmfels"], "venue": "Bernoulli, pages 893\u2013909,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2007}, {"title": "Exposing the probabilistic causal structure of discrimination", "author": ["F. Bonchi", "S. Hajian", "B. Mishra", "D. Ramazzotti"], "venue": "arXiv preprint arXiv:1510.00552,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2015}, {"title": "Algorithmic methods to infer the evolutionary trajectories in cancer progression", "author": ["G. Caravagna", "A. Graudenzi", "D. Ramazzotti", "R. Sanz-Pamplona", "L. De Sano", "G. Mauri", "V. Moreno", "M. Antoniotti", "B. Mishra"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2016}, {"title": "Financial crises: Explanations, types and implications", "author": ["S. Claessens", "M.A. Kose"], "venue": "IMF Working Paper Series,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2013}, {"title": "Nonparametric estimates of standard error: the jackknife, the bootstrap and other methods", "author": ["B. Efron"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1981}, {"title": "Multifactor explanations of asset pricing anomalies", "author": ["E.F. Fama", "K.R. French"], "venue": "The journal of finance,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1996}, {"title": "Quantitative Risk Management: Concepts, Techniques and Tools", "author": ["A.J. McNeil", "R. Frey", "P. Embrechts"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "Probabilistic graphical models: principles and techniques", "author": ["D. Koller", "N. Friedman"], "venue": "MIT press,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2009}, {"title": "Inferring tree causal models of cancer progression with probability raising", "author": ["L.O. Loohuis", "G. Caravagna", "A. Graudenzi", "D. Ramazzotti", "G. Mauri", "M. Antoniotti", "B. Mishra"], "venue": "PloS one,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "Value at risk models in finance", "author": ["S. Manganell", "R.F.Engle"], "venue": "European Central Bank Working Paper Series,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2001}, {"title": "Capri: efficient inference of cancer progression models from cross-sectional data", "author": ["D. Ramazzotti", "G. Caravagna", "L.O. Loohuis", "A. Graudenzi", "I. Korsunsky", "G. Mauri", "M. Antoniotti", "B. Mishra"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2015}, {"title": "Modeling cumulative biological phenomena with suppes-bayes causal networks", "author": ["D. Ramazzotti", "A. Graudenzi", "G. Caravagna", "M. Antoniotti"], "venue": "arXiv preprint arXiv:1602.07857,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2016}, {"title": "Learning the probabilistic structure of cumulative phenomena with suppes-bayes causal networks", "author": ["D. Ramazzotti", "M. Nobile S", "A. Graudenzi", "M. Antoniotti"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2016}, {"title": "Introduction to monte carlo simulation", "author": ["S. Raychaudhuri", "S.J. Mason", "R.R. Hill", "L. M\u00c3\u0171nch", "O. Rose", "T. Jefferson", "J.W. Fowler"], "venue": "In 2008 Winter Simulation Conference,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2008}, {"title": "Coherent Stress Testing: a Bayesian approach to the analysis of financial stress", "author": ["R. Rebonato"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2010}, {"title": "Tree: Classification and Regression Trees, 2016. R package version 1.0-37", "author": ["B. Ripley"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2016}, {"title": "A survey of decision tree classifier methodology", "author": ["S.R. Safavian", "D. Landgrebe"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1990}, {"title": "Estimating the dimension of a model", "author": ["G. Schwarz"], "venue": "The annals of statistics,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1978}, {"title": "Learning bayesian networks with the bnlearn r package", "author": ["M. Scutari"], "venue": "arXiv preprint arXiv:0908.3817,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2009}, {"title": "A probabilistic theory of causality", "author": ["P. Suppes"], "venue": "North-Holland Publishing Company Amsterdam,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1970}], "referenceMentions": [{"referenceID": 7, "context": "xxx/xxx x to negative [8].", "startOffset": 22, "endOffset": 25}, {"referenceID": 14, "context": "Depending on different financial agencies, hedge funds, banks or clearing houses, and on different financial instruments, stocks, bonds, or derivatives, the method of risk management may vary, but the central idea behind conventional risk management remains: we assess the statistical distribution of the asset (or portfolio), and estimate the worst-case scenarios, generally by methods such as Monte Carlo Simulation [17].", "startOffset": 418, "endOffset": 422}, {"referenceID": 10, "context": "For example, in the recent 2008 financial crisis, the reserves calculated the risk by using methods such as VaR (Value at Risk) [11] which proved to be painfully inadequate.", "startOffset": 128, "endOffset": 132}, {"referenceID": 4, "context": "Stress testing refers to the analysis or simulation of the response of financial instruments or institutions, given intensely stressed scenarios that may lead to a financial crisis [5].", "startOffset": 181, "endOffset": 184}, {"referenceID": 15, "context": "proposed a sampling approach based on Bayesian networks in [18].", "startOffset": 59, "endOffset": 63}, {"referenceID": 8, "context": "In this work we use Bayesian Graphical Models [9], popularly known as Bayesian networks, as a framework to assess stress testing, as previously done in this context by [18].", "startOffset": 46, "endOffset": 49}, {"referenceID": 15, "context": "In this work we use Bayesian Graphical Models [9], popularly known as Bayesian networks, as a framework to assess stress testing, as previously done in this context by [18].", "startOffset": 168, "endOffset": 172}, {"referenceID": 1, "context": "Bayesian networks have long been used in biological modeling such as -omics data analysis, cancer progression or genetics [2, 10, 14], but their application to financial data analysis has been rare.", "startOffset": 122, "endOffset": 133}, {"referenceID": 9, "context": "Bayesian networks have long been used in biological modeling such as -omics data analysis, cancer progression or genetics [2, 10, 14], but their application to financial data analysis has been rare.", "startOffset": 122, "endOffset": 133}, {"referenceID": 11, "context": "Bayesian networks have long been used in biological modeling such as -omics data analysis, cancer progression or genetics [2, 10, 14], but their application to financial data analysis has been rare.", "startOffset": 122, "endOffset": 133}, {"referenceID": 12, "context": "In this paper we adopt a variation of the traditional Bayesian networks as done in [15, 16], where the authors show how constraining the search space of valid solutions by means of a causal theory grounded in Suppes\u2019 notion of probabilistic causation [23] can be exploited in order to devise better learning algorithms.", "startOffset": 83, "endOffset": 91}, {"referenceID": 13, "context": "In this paper we adopt a variation of the traditional Bayesian networks as done in [15, 16], where the authors show how constraining the search space of valid solutions by means of a causal theory grounded in Suppes\u2019 notion of probabilistic causation [23] can be exploited in order to devise better learning algorithms.", "startOffset": 83, "endOffset": 91}, {"referenceID": 20, "context": "In this paper we adopt a variation of the traditional Bayesian networks as done in [15, 16], where the authors show how constraining the search space of valid solutions by means of a causal theory grounded in Suppes\u2019 notion of probabilistic causation [23] can be exploited in order to devise better learning algorithms.", "startOffset": 251, "endOffset": 255}, {"referenceID": 12, "context": "Moreover, through a maximum likelihood optimization scheme which makes use of a regularization score, we also attempt to only retain edges in the Bayesian network (graphically depicted as a directed acyclic graph, DAG) that correspond to only genuine causation, while eliminating all the spurious causes [15, 16].", "startOffset": 304, "endOffset": 312}, {"referenceID": 13, "context": "Moreover, through a maximum likelihood optimization scheme which makes use of a regularization score, we also attempt to only retain edges in the Bayesian network (graphically depicted as a directed acyclic graph, DAG) that correspond to only genuine causation, while eliminating all the spurious causes [15, 16].", "startOffset": 304, "endOffset": 312}, {"referenceID": 8, "context": "The nodes induce an overall joint distribution that can be written as a product of the conditional distributions associated with each variable [9].", "startOffset": 143, "endOffset": 146}, {"referenceID": 8, "context": "More details about Bayesian networks may be found in [9].", "startOffset": 53, "endOffset": 56}, {"referenceID": 8, "context": "Simply speaking, for any node X in a Bayesian network, given the knowledge of node X\u2019s parents, X is conditionally independent of all nodes that are not its children, or all its predecessors [9].", "startOffset": 191, "endOffset": 194}, {"referenceID": 15, "context": "In the context of stress testing, Rebonato [18] suggests a subjective approach to constructing Bayesian networks.", "startOffset": 43, "endOffset": 47}, {"referenceID": 15, "context": "Please see [18] for details.", "startOffset": 11, "endOffset": 15}, {"referenceID": 15, "context": "Thus, unlike [18], our stress testing approach builds on the foundation of Suppes-Bayes Causal Networks (SBCNs), which are not only more strictly regularized than the general Bayesian networks but also enjoys many other attractive features such as interpretability and refutability.", "startOffset": 13, "endOffset": 17}, {"referenceID": 20, "context": "SBCNs exploit the notion of probabilistic causation, originally proposed by Patrick Suppes [23].", "startOffset": 91, "endOffset": 95}, {"referenceID": 20, "context": "In [23], Suppes described the notion of prima facie causation.", "startOffset": 3, "endOffset": 7}, {"referenceID": 20, "context": "Definition 1 (Probabilistic causation, [23]).", "startOffset": 39, "endOffset": 43}, {"referenceID": 9, "context": "The notion of prima facie causality was fruitfully exploited for the task of modeling cancer evolution in [10, 14, 4], and the SBCNs were finally described for the first time in [3] and, later on, defined in [15, 16] as follow.", "startOffset": 106, "endOffset": 117}, {"referenceID": 11, "context": "The notion of prima facie causality was fruitfully exploited for the task of modeling cancer evolution in [10, 14, 4], and the SBCNs were finally described for the first time in [3] and, later on, defined in [15, 16] as follow.", "startOffset": 106, "endOffset": 117}, {"referenceID": 3, "context": "The notion of prima facie causality was fruitfully exploited for the task of modeling cancer evolution in [10, 14, 4], and the SBCNs were finally described for the first time in [3] and, later on, defined in [15, 16] as follow.", "startOffset": 106, "endOffset": 117}, {"referenceID": 2, "context": "The notion of prima facie causality was fruitfully exploited for the task of modeling cancer evolution in [10, 14, 4], and the SBCNs were finally described for the first time in [3] and, later on, defined in [15, 16] as follow.", "startOffset": 178, "endOffset": 181}, {"referenceID": 12, "context": "The notion of prima facie causality was fruitfully exploited for the task of modeling cancer evolution in [10, 14, 4], and the SBCNs were finally described for the first time in [3] and, later on, defined in [15, 16] as follow.", "startOffset": 208, "endOffset": 216}, {"referenceID": 13, "context": "The notion of prima facie causality was fruitfully exploited for the task of modeling cancer evolution in [10, 14, 4], and the SBCNs were finally described for the first time in [3] and, later on, defined in [15, 16] as follow.", "startOffset": 208, "endOffset": 216}, {"referenceID": 8, "context": "Second, when learning general Bayesian networks, arcs A \u2192 B and A \u2190 B may sometimes be equally acceptable, resulting in an undirected arc A\u2212B (this situation is called Markov Equivalence [9]).", "startOffset": 187, "endOffset": 190}, {"referenceID": 12, "context": "For SBCNs, such a situation does not arise because of the temporal flow being irreversible [15, 16].", "startOffset": 91, "endOffset": 99}, {"referenceID": 13, "context": "For SBCNs, such a situation does not arise because of the temporal flow being irreversible [15, 16].", "startOffset": 91, "endOffset": 99}, {"referenceID": 6, "context": "To simulate the training data, we adopt a common stock factor model, the Fama French Five Factor Model [7], where the return of the asset is defined as follow:", "startOffset": 103, "endOffset": 106}, {"referenceID": 6, "context": "In the equation, r is the return of the asset; Rf is the risk free return, usually measured in terms of government treasury returns; Km stands for market factor, measured as value-weighted market portfolio, similar to stock indexes; SMB (Small Minus Big) stands for company size factor, measured by return on a diversified portfolio of small stocks minus the return on a diversified portfolio of big stocks; HML (High Minus Low) stands for company book-to-market (B/M) ratio factor, measured by difference between the returns on diversified portfolios of high and low B/M stocks, where B/M is the ratio between company\u2019s book value to market value; RMW (Robust Minus Weak) stands for company operating profitability factor, measured by the returns on diversified portfolios of stocks with robust and weak profitability and CMA (Conservative Minus Aggressive) stands for company investment factor, difference between the returns on diversified portfolios of low and high investment stocks, called conservative and aggressive [7].", "startOffset": 1024, "endOffset": 1027}, {"referenceID": 11, "context": "Starting with such an input, we attempted to experiment with our learning algorithms previously described in [14] and [3].", "startOffset": 109, "endOffset": 113}, {"referenceID": 2, "context": "Starting with such an input, we attempted to experiment with our learning algorithms previously described in [14] and [3].", "startOffset": 118, "endOffset": 121}, {"referenceID": 2, "context": "In particular, as in [3], we lacked explicitly observed time in the data, which are only cross-sectional.", "startOffset": 21, "endOffset": 24}, {"referenceID": 11, "context": "For more information about the algorithm, also refer to [14, 3].", "startOffset": 56, "endOffset": 63}, {"referenceID": 2, "context": "For more information about the algorithm, also refer to [14, 3].", "startOffset": 56, "endOffset": 63}, {"referenceID": 2, "context": "Algorithm 1 Learning the SBCN [3]", "startOffset": 30, "endOffset": 33}, {"referenceID": 18, "context": "The explanation for this trend can be found in how the algorithm implements the regularization via Bayesian Information Criterion (BIC) [21], that is:", "startOffset": 136, "endOffset": 140}, {"referenceID": 8, "context": "However, maximum likelihood is known to be susceptible to overfitting [9], especially when, as in our case, it deals with small sample size in the training data.", "startOffset": 70, "endOffset": 73}, {"referenceID": 8, "context": "For additional discussion, see the details in [9].", "startOffset": 46, "endOffset": 49}, {"referenceID": 0, "context": "To reconcile this dilemma, we now next considered an alternative information criterion, the AIC, Akaike Information Criterion [1], defined as in the following:", "startOffset": 126, "endOffset": 129}, {"referenceID": 5, "context": "To improve their performance, now we propose to make use of a bootstrap [6] procedure for model selection.", "startOffset": 72, "endOffset": 75}, {"referenceID": 17, "context": "Here we explore a simple solution of such a task based on decision trees [20].", "startOffset": 73, "endOffset": 77}, {"referenceID": 16, "context": "In our experiments, we used the R \u2018tree\u2019 package [19].", "startOffset": 49, "endOffset": 53}, {"referenceID": 19, "context": "Given the tree of Figure 6, we then used the bnlearn R package [22] to sample from the SBCN.", "startOffset": 63, "endOffset": 67}], "year": 2017, "abstractText": "The most recent financial upheavals have cast doubt on the adequacy of some of the conventional quantitative risk management strategies, such as VaR (Value at Risk), in many common situations. Consequently, there has been an increasing need for verisimilar financial stress testings, namely simulating and analyzing financial portfolios in extreme, albeit rare scenarios. Unlike conventional risk management which exploits statistical correlations among financial instruments, here we focus our analysis on the notion of probabilistic causation, which is embodied by Suppes-Bayes Causal Networks (SBCNs), SBCNs are probabilistic graphical models that have many attractive features in terms of more accurate causal analysis for generating financial stress scenarios. In this paper, we present a novel approach for conducting stress testing of financial portfolios based on SBCNs in combination with classical machine learning classification tools. The resulting method is shown to be capable of correctly discovering the causal relationships among financial factors that affect the portfolios and thus, simulating stress testing scenarios with a higher accuracy and lower computational complexity than conventional Monte Carlo Simulations.", "creator": "LaTeX with hyperref package"}}}