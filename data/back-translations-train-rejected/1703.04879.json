{"id": "1703.04879", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Mar-2017", "title": "Sparse Named Entity Classification using Factorization Machines", "abstract": "Named entity classification is the task of classifying text-based elements into various categories, including places, names, dates, times, and monetary values. A bottleneck in named entity classification, however, is the data problem of sparseness, because new named entities continually emerge, making it rather difficult to maintain a dictionary for named entity classification. Thus, in this paper, we address the problem of named entity classification using matrix factorization to overcome the problem of feature sparsity. Experimental results show that our proposed model, with fewer features and a smaller size, achieves competitive accuracy to state-of-the-art models.", "histories": [["v1", "Wed, 15 Mar 2017 01:54:52 GMT  (320kb,D)", "http://arxiv.org/abs/1703.04879v1", "4+1 pages"]], "COMMENTS": "4+1 pages", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["ai hirata", "mamoru komachi"], "accepted": false, "id": "1703.04879"}, "pdf": {"name": "1703.04879.pdf", "metadata": {"source": "CRF", "title": "Sparse Named Entity Classification using Factorization Machines", "authors": ["Ai Hirata"], "emails": ["hirata-ai@ed.tmu.ac.jp", "komachi@tmu.ac.jp"], "sections": [{"heading": null, "text": "The classification of designated entities is the task of classifying text-based elements into different categories, including places, names, dates, times, and monetary values. However, a bottleneck in classifying designated entities is the data shortage problem, as new designated entities are constantly emerging, making it quite difficult to maintain a dictionary for classifying designated entities. In this paper, we therefore address the problem of classifying designated entities using matrix factorization to overcome the problem of feature sparseness. Experimental results show that our proposed model achieves competitive accuracy with fewer features and a smaller size compared to state-of-the-art models."}, {"heading": "1 Introduction", "text": "Until now, standard approaches to the classification of designated units have been based on monitored models, which typically require a large annotated corpus and a comprehensive dictionary. However, as new designated units arise on a regular basis, it becomes increasingly difficult to maintain a current dictionary and / or adapt a designated classifier to a new domain; for example, sequence labeling techniques that use feature patterns (Finkel et al., 2005; Sarawagi and Cohen, 2004) are not robust for unknown designated units because their feature space is very sparse (Primadhanty et al., 2015). This problem is exacerbated when we attempt to use a combination of features for a sparse classification of designated units. Therefore, in this paper we propose the use of matrix factorizations for designated units to account for the relationships between sparse features. Through our experiments, we have achieved competitive accuracy over models that use designated units (which were developed in previous work on the use of designated units, which is less compact)."}, {"heading": "2 Related Work", "text": "A standard approach to the classification of designated units is to formulate a problem as a sequence labelling problem and to use a monitored method, such as conditional random fields (Lafferty et al., 2001; Finkel et al., 2005; Sarawagi and Cohen, 2004). These studies rely heavily on feature templates for learning combinations of features; however, since feature combinations are treated independently in conventional, monitored learning, this approach is not robust for designated units that do not appear in the training data. To address the problem of classifying unknown designated units, Primadhanty et al. (2015) investigated the use of sparse combinatory features. They proposed a log-bilinear model defining a score function that takes into account interactions between features; the score function is used via a nuclear standard based on a feature matrix regulated by SVS, such as SV8.04, the SV8S is frequently used as a nuclear standard based on a feature matrix regulated matrix."}, {"heading": "3 Factorization Machines", "text": "In this paper, we propose the use of factorization machines (Rendle, 2010) for unknown named entity classifications, with which we can apply the same objective function as SVMs and still perform matrix factorization to handle sparse combinatorial properties. Matrix factorization leads to better generalizations about a sparse feature matrix (Madhyastha et al., 2014). Factorization machines with degree of interaction d = 2 use the following equation for prediction: y (x): w0 + n \"i = 1 wixi + n\" i = 1 n \"j = i + 1 < vi\" vj > xixj \"(1)\" xi \"represents the i-th dimension of the feature x, n\" is the number of features, w \"Rn\" is a weight vector, and w0 \"R is a bias term. Factorization machines contain interactions between variable, j) as a third term (1)."}, {"heading": "4 Experiments", "text": "As described above, we attempt to classify designated units that are rare in a given training corpus. We compared factorization machines with a log-linear model, a polynomial-nucleated SVM, and a state-of-the-art log-bilinear model that uses nuclear standards for regulation (Primadhanty et al., 2015)."}, {"heading": "4.1 Settings", "text": "We used the dataset provided by Primadhanty et al. (2015); this dataset was created to evaluate unknown named entity classifications and is based on the English dataset CoNLL-2003, which omits named entity candidates that appear in the training and test data. Table 1 shows the number of tokens and types in the given dataset. This dataset contains five tags: Person (PER), Location (LOC), Organization (ORG), Miscellaneous (MISC) and Non-Entities (O).Feature. We used a subset of characteristics from experiments conducted by Primadhanty et al. (2015). Table 3 summarizes the characteristics used in our experiment, including context and entity characteristics. Tools. With regard to tools, we used Scikit-learn 0.17 to implement a log-linear model and a polynomic kernel in an SVM."}, {"heading": "4.2 Results", "text": "Table 2 presents the results of our experiments. Note that Primadhanty et al. (2015) used additional features such as Brown clustering and parts-of-speech (POS) features that we did not use. Table 4 and Figure 2 show the performance and precision curves of the classification of named entities for each day, or fewer features. 1http: / / www.libfm.org / We observed here that, apart from LOC, we have achieved competitive results over the state-of-the-art entity classifier with fewer features proposed by Primadhanty et al. (2015). Overall, the micro-averaged F1 value improved by 1.4 points. From these results, we conclude that a classification of unknown named entities can be successfully achieved by considering combinatorial features using factoring machines."}, {"heading": "5 Discussion", "text": "Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Score-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-"}, {"heading": "6 Conclusion", "text": "In this paper, we proposed the use of factorization machines to handle the combinations of sparse features in the classification of unknown named entities. Our experimental results showed that we were able to achieve competitive accuracy over state-of-the-art methods with fewer features and a compact model. In future work, we aim to extend this framework to sequence labeling, thereby improving the overall detection of named entities."}], "references": [{"title": "Online Passive-Agressive Algorithms", "author": ["Crammer et al.2006] Koby Crammer", "Ofer Dekel", "Joseph Keshet", "Shai Shalev-Shwartz", "Yoram Singer"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Crammer et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Crammer et al\\.", "year": 2006}, {"title": "Incorporating Nonlocal Information into Information Extraction Systems by Gibbs Sampling", "author": ["Trond Grenager", "Christopher Manning"], "venue": "In Proceedings of ACL,", "citeRegEx": "Finkel et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Finkel et al\\.", "year": 2005}, {"title": "Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data", "author": ["Andrew McCallum", "Fernando C.N. Pereira"], "venue": "In Proceedings of ICML,", "citeRegEx": "Lafferty et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Lafferty et al\\.", "year": 2001}, {"title": "Learning Task-specific Bilexical Embeddings", "author": ["Xavier Carreras", "Ariadna Quattoni"], "venue": "In Proceedings of COLING,", "citeRegEx": "Madhyastha et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Madhyastha et al\\.", "year": 2014}, {"title": "Learning Combination Features with L1 Regularization", "author": ["Okanohara", "Tsujii2009] Daisuke Okanohara", "Jun\u2019ichi Tsujii"], "venue": "In Proceedings of NAACL,", "citeRegEx": "Okanohara et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Okanohara et al\\.", "year": 2009}, {"title": "Low-Rank Regularization for Sparse Conjunctive Feature Spaces: An Application to Named Entity Classification", "author": ["Xavier Carreras", "Ariadna Quattoni"], "venue": "In Proceedings of ACL-IJCNLP,", "citeRegEx": "Primadhanty et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Primadhanty et al\\.", "year": 2015}, {"title": "Factorization Machines", "author": ["Steffen Rendle"], "venue": "In Proceedings of ICDM,", "citeRegEx": "Rendle.,? \\Q2010\\E", "shortCiteRegEx": "Rendle.", "year": 2010}, {"title": "Factorization Machines with libFM", "author": ["Steffen Rendle"], "venue": "ACM Transactions on Intelligent Systems and Technology,", "citeRegEx": "Rendle.,? \\Q2012\\E", "shortCiteRegEx": "Rendle.", "year": 2012}, {"title": "Semi-Markov Conditional Random Fields for Information Extraction", "author": ["Sarawagi", "Cohen2004] Sunita Sarawagi", "William W. Cohen"], "venue": "In Proceedings of NIPS,", "citeRegEx": "Sarawagi et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Sarawagi et al\\.", "year": 2004}, {"title": "The Nature of Statistical Learning", "author": ["Vladimir N. Vapnik"], "venue": null, "citeRegEx": "Vapnik.,? \\Q1995\\E", "shortCiteRegEx": "Vapnik.", "year": 1995}], "referenceMentions": [{"referenceID": 1, "context": "However, since new named entities arise regularly, it becomes increasingly difficult to maintain an up-to-date dictionary and/or adapt a named entity classifier to a new domain; for example, sequence labeling techniques that use feature templates (Finkel et al., 2005; Sarawagi and Cohen, 2004) are not robust for unknown named entities because their feature space is very sparse (Primadhanty et al.", "startOffset": 247, "endOffset": 294}, {"referenceID": 5, "context": ", 2005; Sarawagi and Cohen, 2004) are not robust for unknown named entities because their feature space is very sparse (Primadhanty et al., 2015).", "startOffset": 119, "endOffset": 145}, {"referenceID": 6, "context": "Through our experiments, we achieved competitive accuracy to models developed in previous works in terms of using fewer features and compactness using factorization machines (Rendle, 2010).", "startOffset": 174, "endOffset": 188}, {"referenceID": 2, "context": "A standard approach to named entity classification is to formulate a task as a sequence labeling problem and use a supervised method, such as conditional random fields (Lafferty et al., 2001; Finkel et al., 2005; Sarawagi and Cohen, 2004).", "startOffset": 168, "endOffset": 238}, {"referenceID": 1, "context": "A standard approach to named entity classification is to formulate a task as a sequence labeling problem and use a supervised method, such as conditional random fields (Lafferty et al., 2001; Finkel et al., 2005; Sarawagi and Cohen, 2004).", "startOffset": 168, "endOffset": 238}, {"referenceID": 1, "context": ", 2001; Finkel et al., 2005; Sarawagi and Cohen, 2004). These studies heavily rely on feature templates for learning combinations of features; however, since combinations of features in conventional supervised learning are treated independently, this approach is not robust for named entities that do not appear in the training data. To address the task of unknown named entity classification, Primadhanty et al. (2015) explored the use of sparse combinatorial features.", "startOffset": 8, "endOffset": 420}, {"referenceID": 9, "context": "Therefore, our proposed method treats sparse features using matrix factorization from a different perspective: we decompose a feature weight matrix using factorization machines as to directly optimize classification accuracy using a large margin method similar to support vector machines (SVMs) and passive-agressive algorithms (Vapnik, 1995; Crammer et al., 2006).", "startOffset": 328, "endOffset": 364}, {"referenceID": 0, "context": "Therefore, our proposed method treats sparse features using matrix factorization from a different perspective: we decompose a feature weight matrix using factorization machines as to directly optimize classification accuracy using a large margin method similar to support vector machines (SVMs) and passive-agressive algorithms (Vapnik, 1995; Crammer et al., 2006).", "startOffset": 328, "endOffset": 364}, {"referenceID": 6, "context": "In this paper, we propose the use of factorization machines (Rendle, 2010) for unknown named entity classification.", "startOffset": 60, "endOffset": 74}, {"referenceID": 3, "context": "Matrix factorization yields better generalizations over a sparse feature matrix (Madhyastha et al., 2014).", "startOffset": 80, "endOffset": 105}, {"referenceID": 5, "context": "obtained from Primadhanty et al. (2015), with the number of", "startOffset": 14, "endOffset": 40}, {"referenceID": 5, "context": "94 log-bilinear model (Primadhanty et al., 2015) 62.", "startOffset": 22, "endOffset": 48}, {"referenceID": 5, "context": "We compared factorization machines with a log-linear model, a polynomial-kernel SVM, and a state-ofthe-art log-bilinear model using nuclear norm for regularization (Primadhanty et al., 2015).", "startOffset": 164, "endOffset": 190}, {"referenceID": 5, "context": "We used the dataset provided by Primadhanty et al. (2015); this dataset was created for evaluating unknown named entity classification and is", "startOffset": 32, "endOffset": 58}, {"referenceID": 5, "context": "Table 3: Features used in our experiment; note that this is a subset of features used in Primadhanty et al. (2015)\u2019s experiment.", "startOffset": 89, "endOffset": 115}, {"referenceID": 5, "context": "We used a subset of features from experiments performed by Primadhanty et al. (2015). Table 3 summarizes the features used in our experiment, including context and entity features.", "startOffset": 59, "endOffset": 85}, {"referenceID": 7, "context": "21 (Rendle, 2012) to build a named entity classifier using factorization machines.", "startOffset": 3, "endOffset": 17}, {"referenceID": 5, "context": "Note that Primadhanty et al. (2015) used additional features such as Brown clustering and parts-of-speech (POS) features, which we did not use.", "startOffset": 10, "endOffset": 36}, {"referenceID": 5, "context": "We observed here that, aside from LOC, we obtained competitive results to the state-of-the-art named entity classifier proposed by Primadhanty et al. (2015) with fewer features.", "startOffset": 131, "endOffset": 157}, {"referenceID": 5, "context": "The accuracy of LOC, however, was lower than that of the log-bilinear model (Primadhanty et al., 2015).", "startOffset": 76, "endOffset": 102}, {"referenceID": 5, "context": "50 log-bilinear model (Primadhanty et al., 2015) 73.", "startOffset": 22, "endOffset": 48}, {"referenceID": 5, "context": "ization using the same development data as that of Primadhanty et al. (2015). Our method yielded the best F1-score (i.", "startOffset": 51, "endOffset": 77}, {"referenceID": 5, "context": "Both our approach and the methods of Primadhanty et al. (2015) address the problem of incorporating sparse combinatorial features by dimension reduction (i.", "startOffset": 37, "endOffset": 63}, {"referenceID": 5, "context": "Both our approach and the methods of Primadhanty et al. (2015) address the problem of incorporating sparse combinatorial features by dimension reduction (i.e., matrix factorization); however, they differ in terms of the objective function to be optimized. Primadhanty et al. (2015) use maximum likelihood estimation as an objective function; whereas other objective functions such as hinge loss can be used in factorization machines.", "startOffset": 37, "endOffset": 282}], "year": 2017, "abstractText": "Named entity classification is the task of classifying text-based elements into various categories , including places, names, dates, times, and monetary values. A bottleneck in named entity classification, however, is the data problem of sparseness, because new named entities continually emerge, making it rather difficult to maintain a dictionary for named entity classification. Thus, in this paper, we address the problem of named entity classification using matrix factorization to overcome the problem of feature sparsity. Experimental results show that our proposed model, with fewer features and a smaller size, achieves competitive accuracy to state-of-the-art models.", "creator": "LaTeX with hyperref package"}}}