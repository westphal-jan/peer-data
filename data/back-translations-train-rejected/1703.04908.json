{"id": "1703.04908", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Mar-2017", "title": "Emergence of Grounded Compositional Language in Multi-Agent Populations", "abstract": "By capturing statistical patterns in large corpora, machine learning has enabled significant advances in natural language processing, including in machine translation, question answering, and sentiment analysis. However, for agents to intelligently interact with humans, simply capturing the statistical patterns is insufficient. In this paper we investigate if, and how, grounded compositional language can emerge as a means to achieve goals in multi-agent populations. Towards this end, we propose a multi-agent learning environment and learning methods that bring about emergence of a basic compositional language. This language is represented as streams of abstract discrete symbols uttered by agents over time, but nonetheless has a coherent structure that possesses a defined vocabulary and syntax. We also observe emergence of non-verbal communication such as pointing and guiding when language communication is unavailable.", "histories": [["v1", "Wed, 15 Mar 2017 03:30:13 GMT  (1262kb,D)", "http://arxiv.org/abs/1703.04908v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.CL", "authors": ["igor mordatch", "pieter abbeel"], "accepted": false, "id": "1703.04908"}, "pdf": {"name": "1703.04908.pdf", "metadata": {"source": "CRF", "title": "Emergence of Grounded Compositional Language in Multi-Agent Populations", "authors": ["Igor Mordatch", "Pieter Abbeel"], "emails": ["<mordatch@opeanai.com>."], "sections": [{"heading": "1. Introduction", "text": "We need to develop communication if it is to be successfully coordinated as a collective. Furthermore, agents will need some language skills if they typically want to interact with people and work productively or make decisions that are interpreted by people. If such a skill is led to artificially imitate language, it could also provide important insights into issues that affect the development of human language and cognition.But if we want to get from the first principles to the formation of communication, it needs to be shaped out of necessity.The approaches that learn to plausibly imitate language using examples of human language while it is enormously useful do not learn why language exists. Such supervised language agents 2UC Berkeley. Correspondence to: Igor Mordatch < mordatch @ opeanai.com >.can capture structural and statistical relationships in language, but they do not capture its functional aspects, or language happens for the purposes of successful coordination between people < mordatch > opemordanai.com."}, {"heading": "2. Related Work", "text": "In recent years, significant advances have been made in practical applications of natural language such as machine translation (Sutskever et al., 2014; Bahdanau et al., 2014), sentiment analysis (Socher et al., 2013), document summary (Durrett et al., 2016), and domain-specific dialogue (Dhingra et al., 2016), much of this success is the result of intelligently designed statistical models based on large static data sets. However, such approaches do not lead to an understanding of language that can lead to productive collaboration with humans. An interest in pragmatic vision of language understanding has long existed (Austin, 1962; Grice, 1975) and was recently proposed in (Gauthier & Mordatch, 2016; Lake et al., 2016; Lazaridou et al., 2016b). Pragmatic linguistic use has been proposed in the context of two player reference games (Golland et al., 2010; Vogel et al., 2016)."}, {"heading": "3. Problem Formulation", "text": "The setting we are considering is a cooperative, partially observable Markov game (Littman, 1994), which is a multi-agent extension of a Markov decision-making process. A Markov game for N agents is defined by a series of states S describing the possible configurations of all agents, a series of actions A1,..., AN, and a series of observations O1,..., ON for each agent. Initial states are determined by a distribution \u03c1: S 7 \u2192 [0, 1]. State transitions are determined by a function T: S \u00d7 A1 \u00d7... \u00d7 AN 7 \u2192 S. For each agent i, rewards are given by function ri: S \u00d7 Ai 7 \u2192 R, observations are given by function oi: S 7 \u2192 Oi. To select measures, each agent i uses a stochastic policy \u03c0i: Oi \u00d7 Ai 7 \u2192 [0, 1]. In this work we assume that all agents have identical actions and observations, and all agents act according to the same policy."}, {"heading": "4. Grounded Communication Environment", "text": "In fact, most of them are able to survive on their own."}, {"heading": "5. Policy Learning with Backpropagation", "text": "There are several common options for finding optimal policy parameters. Unfortunately, the model-free framework of Q-Learning can be used to find the optimal value function of the state and apply policies that greedily pursue the value function. Unfortunately, the dimensionality of Q-Learning scales square with the size of the communication vocabulary, which can quickly become insolubly large. Alternatively, it is possible to learn a policy function directly by using model-free gradient methods that use sampling to estimate the gradient of the political return dRd\u043d. Gradient estimates from these methods can be very varied, and credit allocation becomes a particularly difficult problem when sequential communication activities are available. Instead of using model-free reinforcement methods, we build an end-to-end differentiated model of the dynamics of all agents and environments."}, {"heading": "5.1. Discrete Communication and Gumbel-Softmax Estimator", "text": "In order to use the categorical communication emissions c in our environment, it must be possible to distinguish temperature directly from temperature. There has been a lot of work in machine learning on differentiable models with discrete variables, but we found that the most recent approach in (Jang et al., 2016; Maddison et al., 2016) is particularly effective in our environment. The approach suggests a Gumbel-Softmax distribution, which represents a continuous loosening of a discrete categorical distribution. Given the K-categorical distribution parameters p, a differentiable K-dimensional one-dimensional coding sample G from the Gumbel-Softmax distribution can be calculated as follows: G (logp) k = exp (((logpk + \u03b5) / \u03c4) \u2022 K j = 0 exp (logpj + \u03b5) / \u0456) Where \u03b5 are i.i.d. Samples from the Gumbel-Softmax distribution (0, 1) p = -log (directly from socket \u2212 u, where zero and zero is a socket \u2212 u, where \u03b8 is [)."}, {"heading": "5.2. Policy Architecture", "text": "The political class we are looking at in this paper is stochastic neural networks. Politics gives samples of the physical actions of an agent from u, communication symbol utterance c, and internal memory updates \u0445 m. Politics must consolidate several incoming communication symbol streams emitted by other agents, as well as incoming observations of physical units. To support this, the policy initiates a collection of identical processing modules for each communication stream and each observed physical unit. Each processing module is a fully networked multilayered perceptron. The weights between all communication processing modules are shared between the surrounding instantiations (and similarly for all physical observation modules). The results of individual processing modules are used by the individual processing modules and each observed physical unit."}, {"heading": "5.3. Auxiliary Prediction Reward", "text": "To help avoid local minimums, we found it helpful to include additional tasks for predicting targets, similar to the recent work in the field of reinforcement theory (Dosovitskiy & Koltun, 2016; Silver et al., 2016).In Agent i's prediction, each communication processing module additionally gives a prediction of the targets of Agent j. At the end of the episode, we add a reward for predicting the goals of other agents, which in turn encourages communication expressions that clearly convey the agent's goals to other agents. Across all agents.... m 1m NxcxaCagpoolFC CFC XFC am 0N + MxccN11ocuaFigure 3. Overview of our political architecture, mapping the observations to actions at all times. FC displays a fully connected processing module that shares weights with all other of its labels."}, {"heading": "6. Compositionality and Vocabulary Size", "text": "What leads to compositional syntax formation? We are using a maximum constructive hypothesis, which we have all tested in smaller experiments. We need to rethink the process of speech transmission and acquisition from one generation of agents to the next, in order to identify the next generation of agents, how they can observe the next generation of agents from the previous generation and deduce from it the meaning of invisible symbols. This approach requires the modelling of language acquisition between agents, but when implemented with pre-made rules, multiple iterations between generations are shown to lead to the formation of a compositional vocabulary. Alternatively, it is observed (Nowak et al) that the emergence of compositionality requires the number of concepts that can be over a factor of vocabulary size. In our preliminary environments, the number of concepts to communicate is relatively small and is within the capacity of a non-compositional language."}, {"heading": "7.1. Syntactic Structure", "text": "We observe a compositional syntactic structure created in the flow of symbols expressed by agents. If we are trained in environments with only two agents, but several landmarks and actions, we observe symbols forming for each of the landmarks colors and each of the action types. A typical conversation and configuration of the physical agent is shown in the first row of Figure 4 and is as follows: Green Agent: GOTO, GREEN,... Blue Agent: GOTO, BLUE,... The labels for abstract symbols are selected purely for interpretation and visualization and have no meaning for training. Physical environmental considerations play a role in the syntactic structure. The action type verb GOTO is pronounced first because actions take time to reach in the grounded environment. When the agent receives GOTO symbol, it begins to move toward the centric form of all the other signs."}, {"heading": "7.2. Symbol Vocabulary Usage", "text": "We find that word activation serves to determine the appropriate compositional number of words. That, early in the training, large vocabulary sizes are used to explore the space of communication possibilities before agreeing on the appropriate effective vocabulary sizes, as shown in Figure 6. In this figure, 1x1x3 refers to an environment with two agents and a single action requiring only the communication of one of three landmark identities. 1x2x3 contains two types of actions, and 3x3x3 contains three agents that need to be explicitly referenced."}, {"heading": "7.3. Generalization to Unseen Configurations", "text": "One of the advantages of decentralized execution guidelines is that trained agents can be divided into arbitrarily large groups and still operate reasonably reasonably well. If additional agents in the area with the same color identity are asked, all agents of the same color perform the same task when pointed out to them. If agents of a certain color are asked to perform two conflicting tasks (such as being asked by two different agents to reach two different boundaries), they fulfill the average of the conflicting goals assigned to them. Such cases occur even though they have never been seen in such environments before. Due to the modularized observation architecture, the number of boundaries in the area can also fluctuate between training and execution. Agents conduct reasonable behavior with a different number of boundaries, even though they were not trained in such environments. For example, if there are diverting boundaries of novel colors, agents never move toward them. If there are multiple boundaries of the same color, the agent speaks to the target (the color that is still communicating at the line of the target)."}, {"heading": "7.4. Non-verbal Communication and Other Strategies", "text": "In this series of experiments, we allow the agent to observe the position and focus of other agents, thereby disabling the ability to communicate through the expression of symbols. If agents can observe the gaze of the other agent, a pointing strategy emerges in which the agent can communicate a milestone by looking in the direction the recipient correctly interprets and moves in. If the gaze of other agents cannot be observed, we observe the behavior of a target sender moving to the location assigned to the target recipient (although he does not receive any explicit reward for this) in order to lead the target recipient to that place. Finally, if visual or non-verbal observation is not available on the part of the target receiver, we observe the behavior of the target sender pushing the recipient directly to the destination. Examples of such strategies are shown in Figure 7."}, {"heading": "8. Conclusion", "text": "We have presented a multi-agent environment and learning methods that allow an abstract compositional language to emerge from grounded experience. This abstract language is formed without any contact with human language usage. We investigated how variation in the configuration of the environment and the physical abilities of agents influence the communication strategies that occur. In the future, we would like to experiment with a larger number of actions that require a more complex syntax and larger vocabulary. We also want to integrate exposure to human language to develop communication strategies that are compatible with human use."}, {"heading": "8.1. Physical State and Dynamics", "text": "The physical state of the active substance is specified by x = [p p-v d], where p-v is the velocity of a single active substance. Limit values have a similar state, but without visual and speed components. The physical state transition dynamics for a single active substance are determined by the following factors: xti = pp-v-t = p + p-p-t-t-t-1 iWhere f (x1,..., xN) are the physical interaction forces (such as collision) between all active agents in the environment and all obstacles, \u2206 t is the simulation time (we use 0.1) and (1 \u2212 \u03b3) is a damping coefficient (we use 0.5)."}, {"heading": "8.2. Goal Specification and Reward", "text": "Target for Agent i consists of an action to execute, a location to execute it, and an agent r to execute this action. Action type associated with target gi for Agent i at present t is encoded as uniform vector GType-R3. These target properties are summarized in target description vector g. The physical reward associated with target gi for Agent i at present t is: rti = \u2212 (HPTR-R-2-VTR-R-2 0 gtype + HUTI-2 + HCTI-2) The total return for the episode is R = RC + RG + HT-I-Rti"}], "references": [{"title": "Reasoning about pragmatics with neural listeners and speakers", "author": ["Andreas", "Jacob", "Klein", "Dan"], "venue": "In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Andreas et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Andreas et al\\.", "year": 2016}, {"title": "How to Do Things with Words", "author": ["J.L. Austin"], "venue": null, "citeRegEx": "Austin,? \\Q1962\\E", "shortCiteRegEx": "Austin", "year": 1962}, {"title": "Neural machine translation by jointly learning to align and translate", "author": ["Bahdanau", "Dzmitry", "Cho", "Kyunghyun", "Bengio", "Yoshua"], "venue": "arXiv preprint arXiv:1409.0473,", "citeRegEx": "Bahdanau et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2014}, {"title": "Agent-based models of strategies for the emergence and evolution of grammatical agreement", "author": ["Beuls", "Katrien", "Steels", "Luc"], "venue": "PloS one,", "citeRegEx": "Beuls et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Beuls et al\\.", "year": 2013}, {"title": "Endto-End Reinforcement Learning of Dialogue Agents for Information Access", "author": ["Dhingra", "Bhuwan", "Li", "Lihong", "Xiujun", "Gao", "Jianfeng", "Chen", "Yun-Nung", "Ahmed", "Faisal", "Deng"], "venue": "[cs],", "citeRegEx": "Dhingra et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Dhingra et al\\.", "year": 2016}, {"title": "Learning to act by predicting the future", "author": ["Dosovitskiy", "Alexey", "Koltun", "Vladlen"], "venue": "arXiv preprint arXiv:1611.01779,", "citeRegEx": "Dosovitskiy et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Dosovitskiy et al\\.", "year": 2016}, {"title": "Learning-based single-document summarization with compression and anaphoricity constraints", "author": ["Durrett", "Greg", "Berg-Kirkpatrick", "Taylor", "Klein", "Dan"], "venue": "arXiv preprint arXiv:1603.08887,", "citeRegEx": "Durrett et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Durrett et al\\.", "year": 2016}, {"title": "Learning to Communicate with Deep Multi-Agent Reinforcement Learning", "author": ["Foerster", "Jakob N", "Assael", "Yannis M", "de Freitas", "Nando", "Whiteson", "Shimon"], "venue": null, "citeRegEx": "Foerster et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Foerster et al\\.", "year": 2016}, {"title": "Predicting Pragmatic Reasoning in Language", "author": ["Frank", "Michael C", "Goodman", "Noah D"], "venue": "Games. Science,", "citeRegEx": "Frank et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Frank et al\\.", "year": 2012}, {"title": "A paradigm for situated and goal-driven language learning", "author": ["Gauthier", "Jon", "Mordatch", "Igor"], "venue": null, "citeRegEx": "Gauthier et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Gauthier et al\\.", "year": 2016}, {"title": "A gametheoretic approach to generating spatial descriptions", "author": ["Golland", "Dave", "Liang", "Percy", "Klein", "Dan"], "venue": "In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Golland et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Golland et al\\.", "year": 2010}, {"title": "Logic and conversation", "author": ["H.P. Grice"], "venue": "Syntax and Semantics:", "citeRegEx": "Grice,? \\Q1975\\E", "shortCiteRegEx": "Grice", "year": 1975}, {"title": "Categorical Reparameterization with Gumbel-Softmax", "author": ["E. Jang", "S. Gu", "B. Poole"], "venue": "ArXiv e-prints,", "citeRegEx": "Jang et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Jang et al\\.", "year": 2016}, {"title": "Syntax out of Learning: the cultural evolution of structured communication in a population of induction algorithms", "author": ["Kirby", "Simon"], "venue": null, "citeRegEx": "Kirby and Simon.,? \\Q1999\\E", "shortCiteRegEx": "Kirby and Simon.", "year": 1999}, {"title": "Iterated learning and the evolution of language", "author": ["Kirby", "Simon", "Griffiths", "Tom", "Smith", "Kenny"], "venue": "Current opinion in neurobiology,", "citeRegEx": "Kirby et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kirby et al\\.", "year": 2014}, {"title": "Building machines that learn and think like people", "author": ["Lake", "Brenden M", "Ullman", "Tomer D", "Tenenbaum", "Joshua B", "Gershman", "Samuel J"], "venue": null, "citeRegEx": "Lake et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Lake et al\\.", "year": 2016}, {"title": "Multi-agent cooperation and the emergence of (natural) language", "author": ["Lazaridou", "Angeliki", "Peysakhovich", "Alexander", "Baroni", "Marco"], "venue": "arXiv preprint arXiv:1612.07182,", "citeRegEx": "Lazaridou et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Lazaridou et al\\.", "year": 2016}, {"title": "Towards Multi-Agent Communication-Based Language Learning", "author": ["Lazaridou", "Angeliki", "Pham", "Nghia The", "Baroni", "Marco"], "venue": "May 2016b", "citeRegEx": "Lazaridou et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Lazaridou et al\\.", "year": 2016}, {"title": "Markov games as a framework for multi-agent reinforcement learning", "author": ["Littman", "Michael L"], "venue": "In Proceedings of the eleventh international conference on machine learning,", "citeRegEx": "Littman and L.,? \\Q1994\\E", "shortCiteRegEx": "Littman and L.", "year": 1994}, {"title": "The concrete distribution: A continuous relaxation of discrete random variables", "author": ["Maddison", "Chris J", "Mnih", "Andriy", "Teh", "Yee Whye"], "venue": null, "citeRegEx": "Maddison et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Maddison et al\\.", "year": 2016}, {"title": "Sparse autoencoder", "author": ["Ng", "Andrew"], "venue": "CS294A Lecture notes,", "citeRegEx": "Ng and Andrew.,? \\Q2011\\E", "shortCiteRegEx": "Ng and Andrew.", "year": 2011}, {"title": "The predictron: End-to-end learning and planning", "author": ["Silver", "David", "van Hasselt", "Hado", "Hessel", "Matteo", "Schaul", "Tom", "Guez", "Arthur", "Harley", "Tim", "Dulac-Arnold", "Gabriel", "Reichert", "Rabinowitz", "Neil", "Barreto", "Andre"], "venue": "arXiv preprint arXiv:1612.08810,", "citeRegEx": "Silver et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Silver et al\\.", "year": 2016}, {"title": "A self-organizing spatial vocabulary", "author": ["Steels", "Luc"], "venue": "Artif. Life,", "citeRegEx": "Steels and Luc.,? \\Q1995\\E", "shortCiteRegEx": "Steels and Luc.", "year": 1995}, {"title": "What triggers the emergence of grammar? In AISB\u201905", "author": ["Steels", "Luc"], "venue": "Proceedings of the Second International Symposium on the Emergence and Evolution of Linguistic Communication", "citeRegEx": "Steels and Luc.,? \\Q2005\\E", "shortCiteRegEx": "Steels and Luc.", "year": 2005}, {"title": "Learning multiagent communication with backpropagation", "author": ["Sukhbaatar", "Sainbayar", "Szlam", "Arthur", "Fergus", "Rob"], "venue": "In Advances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing Systems", "citeRegEx": "Sukhbaatar et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Sukhbaatar et al\\.", "year": 2016}, {"title": "Dirichlet process", "author": ["Teh", "Yee Whye"], "venue": "In Encyclopedia of machine learning,", "citeRegEx": "Teh and Whye.,? \\Q2011\\E", "shortCiteRegEx": "Teh and Whye.", "year": 2011}, {"title": "The pragmatics of spatial language", "author": ["Ullman", "Tomer", "Xu", "Yang", "Goodman", "Noah"], "venue": "In Proceedings of the Cognitive Science Society,", "citeRegEx": "Ullman et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Ullman et al\\.", "year": 2016}, {"title": "Learning language games through interaction", "author": ["S.I. Wang", "P. Liang", "C. Manning"], "venue": "In Association for Computational Linguistics (ACL),", "citeRegEx": "Wang et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2016}, {"title": "A procedural model of language understanding", "author": ["Winograd", "Terry"], "venue": null, "citeRegEx": "Winograd and Terry.,? \\Q1973\\E", "shortCiteRegEx": "Winograd and Terry.", "year": 1973}], "referenceMentions": [{"referenceID": 2, "context": "Recent years have seen substantial progress in practical natural language applications such as machine translation (Sutskever et al., 2014; Bahdanau et al., 2014), sentiment analysis (Socher et al.", "startOffset": 115, "endOffset": 162}, {"referenceID": 6, "context": ", 2013), document summarization (Durrett et al., 2016), and domain-specific dialogue (Dhingra et al.", "startOffset": 32, "endOffset": 54}, {"referenceID": 4, "context": ", 2016), and domain-specific dialogue (Dhingra et al., 2016).", "startOffset": 38, "endOffset": 60}, {"referenceID": 1, "context": "An interest in pragmatic view of language understanding has been longstanding (Austin, 1962; Grice, 1975) and has recently argued for in (Gauthier & Mordatch, 2016; Lake et al.", "startOffset": 78, "endOffset": 105}, {"referenceID": 11, "context": "An interest in pragmatic view of language understanding has been longstanding (Austin, 1962; Grice, 1975) and has recently argued for in (Gauthier & Mordatch, 2016; Lake et al.", "startOffset": 78, "endOffset": 105}, {"referenceID": 15, "context": "An interest in pragmatic view of language understanding has been longstanding (Austin, 1962; Grice, 1975) and has recently argued for in (Gauthier & Mordatch, 2016; Lake et al., 2016; Lazaridou et al., 2016b).", "startOffset": 137, "endOffset": 208}, {"referenceID": 10, "context": "Pragmatic language use has been proposed in the context of two-player reference games (Golland et al., 2010; Vogel et al., 2014; Andreas & Klein, 2016) focusing on the task of identifying object references through a learned language.", "startOffset": 86, "endOffset": 151}, {"referenceID": 27, "context": "(Winograd, 1973; Wang et al., 2016) ground language in a physical environment and focusing on language interaction with humans for completion of tasks in the physical environment.", "startOffset": 0, "endOffset": 35}, {"referenceID": 26, "context": "In such a pragmatic setting, language use for communication of spatial concepts has received particular attention in (Steels, 1995; Ullman et al., 2016).", "startOffset": 117, "endOffset": 152}, {"referenceID": 14, "context": "Models such as Rational Speech Acts (Frank & Goodman, 2012) and Iterated Learning (Kirby et al., 2014) have been popular in cognitive science and evolutionary linguistics, but such approaches tend to rely on pre-specified procedures or models that limit their generality.", "startOffset": 82, "endOffset": 102}, {"referenceID": 7, "context": "The recent work that is most similar to ours is the application of reinforcement learning approaches towards the purposes of learning a communication protocol, as exemplified by (Foerster et al., 2016; Sukhbaatar et al., 2016; Lazaridou et al., 2016a).", "startOffset": 178, "endOffset": 251}, {"referenceID": 24, "context": "The recent work that is most similar to ours is the application of reinforcement learning approaches towards the purposes of learning a communication protocol, as exemplified by (Foerster et al., 2016; Sukhbaatar et al., 2016; Lazaridou et al., 2016a).", "startOffset": 178, "endOffset": 251}, {"referenceID": 7, "context": "A similar approach was employed by (Foerster et al., 2016; Sukhbaatar et al., 2016) to compute gradients for communication actions, although the latter still employed modelfree methods for physical action computation.", "startOffset": 35, "endOffset": 83}, {"referenceID": 24, "context": "A similar approach was employed by (Foerster et al., 2016; Sukhbaatar et al., 2016) to compute gradients for communication actions, although the latter still employed modelfree methods for physical action computation.", "startOffset": 35, "endOffset": 83}, {"referenceID": 12, "context": "There has been a wealth of work in machine learning on differentiable models with discrete variables, but we found recent approach in (Jang et al., 2016; Maddison et al., 2016) to be particularly effective in our setting.", "startOffset": 134, "endOffset": 176}, {"referenceID": 19, "context": "There has been a wealth of work in machine learning on differentiable models with discrete variables, but we found recent approach in (Jang et al., 2016; Maddison et al., 2016) to be particularly effective in our setting.", "startOffset": 134, "endOffset": 176}, {"referenceID": 21, "context": "To help policy training avoid local minima, we found it helpful to include auxiliary goal prediction tasks, similar to recent work in reinforcement learning (Dosovitskiy & Koltun, 2016; Silver et al., 2016).", "startOffset": 157, "endOffset": 206}, {"referenceID": 14, "context": "What leads to compositional syntax formation? One known constructive hypothesis requires modeling the process of language transmission and acquisition from one generation of agents to the next iteratively as in (Kirby et al., 2014).", "startOffset": 211, "endOffset": 231}], "year": 2017, "abstractText": "By capturing statistical patterns in large corpora, machine learning has enabled significant advances in natural language processing, including in machine translation, question answering, and sentiment analysis. However, for agents to intelligently interact with humans, simply capturing the statistical patterns is insufficient. In this paper we investigate if, and how, grounded compositional language can emerge as a means to achieve goals in multi-agent populations. Towards this end, we propose a multi-agent learning environment and learning methods that bring about emergence of a basic compositional language. This language is represented as streams of abstract discrete symbols uttered by agents over time, but nonetheless has a coherent structure that possesses a defined vocabulary and syntax. We also observe emergence of non-verbal communication such as pointing and guiding when language communication is unavailable.", "creator": "LaTeX with hyperref package"}}}