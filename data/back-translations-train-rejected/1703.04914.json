{"id": "1703.04914", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Mar-2017", "title": "Ensemble of Neural Classifiers for Scoring Knowledge Base Triples", "abstract": "This paper describes our approach for the triple scoring task at WSDM Cup 2017. The task aims to assign a relevance score for each pair of entities and their types in a knowledge base in order to enhance the ranking results in entity retrieval tasks. We propose an approach wherein the outputs of multiple neural network classifiers are combined using a supervised machine learning model. The experimental results show that our proposed method achieves the best performance in one out of three measures, and performs competitively in the other two measures.", "histories": [["v1", "Wed, 15 Mar 2017 04:00:27 GMT  (44kb)", "https://arxiv.org/abs/1703.04914v1", null], ["v2", "Wed, 5 Apr 2017 13:58:02 GMT  (45kb)", "http://arxiv.org/abs/1703.04914v2", "WSDM Cup 2017"]], "reviews": [], "SUBJECTS": "cs.CL cs.IR", "authors": ["ikuya yamada", "motoki sato", "hiroyuki shindo"], "accepted": false, "id": "1703.04914"}, "pdf": {"name": "1703.04914.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Ikuya Yamada", "Motoki Sato", "Hiroyuki Shindo"], "emails": ["ikuya@ousia.jp", "sato.motoki.sa7@is.naist.jp", "shindo@is.naist.jp"], "sections": [{"heading": null, "text": "ar Xiv: 170 3.04 914v 2 [cs.C L] 5A pr2 01This paper describes our approach to the triple scoring task at the 2017 WSDM Cup. The task required the assignment of a relevance point for each entity pair and its types in a knowledge base to improve the ranking results for entity retrieval tasks. We propose an approach that combines the results of multiple neural network classifiers using a monitored machine learning model. Experimental results showed that our proposed method performed best in one of three metrics (i.e. Kendall rating) and was competitive in the other two metrics (i.e. accuracy and average score difference)."}, {"heading": "1. INTRODUCTION", "text": "In the last ten years, huge online structured knowledge databases (KBs) such as Wikidata [11], Freebase [4] and DBpedia [1] have sprung up. These KBs contain an enormous number of units (e.g. people) and their types (e.g. professions and nationalities).1 These data allow users to easily formulate a complex query on a KB, such as retrieving a list of all scientists who are nationals of Japan. However, the KB also contains many entity types that are rarely useful to people when queriing a KB. For example, Barack Obama has four professions listed on Freebase, namely politicians, lawyers, law professors and authors, but it is assumed that people primarily want to retrieve Barack Obama as a politician."}, {"heading": "2. OUR APPROACH", "text": "Considering a KB unit e and its target type t, our method predicts a score that represents the relevance of affiliation from e to t. We take a two-step approach: the first step is a classification step that aims to estimate the probability of affiliation from e to t (P (t | e)) using multiple neural network classifiers; the second step is a scoring step in which the results of these classifiers are converted into the target relevance value using a supervised machine learning model. In accordance with the task specifications for the 2017 WSDM Cup, our model assigns relevance values to pairs of people and their occupations, as well as people and their nationalities."}, {"heading": "2.1 Classification Step", "text": "In fact, most of them are able to go to another world, to go to another world, to go to another world."}, {"heading": "2.2 Scoring Step", "text": "We are converting the results of the aforementioned studies in relation to the results of previous years."}, {"heading": "2.3 Implementation", "text": "We implemented the classifier described in Section 2.1 with Python, Keras8, and Theano [10], and our scoring model de-8https: / / github.com / fchollet / kerasscribed was implemented in Section 2.2 with Python and Scikitlearn."}, {"heading": "3. EXPERIMENTS", "text": "In this section we first describe the performance evaluation of the adjudicators presented in section 2.1. Afterwards we present the official results of the three-point task at the WSDM Cup 2017."}, {"heading": "3.1 Evaluating Classifiers", "text": "In order to independently evaluate the performance of the proposed classifiers, we randomly selected 10% of the KB units of a single type and measured the accuracy of the classification based on these selected units. Table 1 lists the accuracy of the classifiers corresponding to the various training configurations presented in Section 2.1.3. As shown in the table, the attention mechanism effectively improved performance, whereas the use of class weights generally decreased accuracy. Furthermore, the classifiers trained with the article corpus generally performed more accurately than those trained with the sentence corpus. In our experiments, we also found that the results of classifiers achieving lower accuracies often improved the performance of the goalkeeper. Therefore, we used the results of different classifiers instead of focusing on the results of a single precise classifier."}, {"heading": "3.2 Competition Results", "text": "We subjected our proposed method at the 2017 WSDM Cup to the triple scoring task. In this competition, the submitted methods were evaluated on the basis of the following three metrics: \u2022 Accuracy, which is the percentage for which the estimated score differs from the actual score by at least 2. \u2022 Average score difference, which is the average score between the estimated values and the actual values. \u2022 Kendall's \u03c4, which is the average score 10 between the estimated values and the actual values. \u2022 Average score difference is calculated for each unit, and the final score is averaged across all units. \u2022 The experiments were conducted with the 710 entity-type pairs, which included the cases of 513 professional pairs and 197 nationality pairs. We used different scoring models trained with the corresponding data sets for each domain. Note that the accuracy described here differs from the ellic accuracy of the table we used for the previous ranking of the Kendall (which includes the five official results)."}, {"heading": "4. CONCLUSIONS", "text": "In this study, we proposed an approach to assign a relevance point to each entity-type pair in a specific KB. We trained neural network-based multipliers by directly using the KB data, and converted the results of these classifiers into target relevance values using a monitored machine learning model (i.e. GBRT). It is noteworthy that the item-based attention model we introduced to the neural network model had not previously been applied to this type of task. Experimental results confirmed the superiority of our approach; we achieved the best performance in terms of Kendall's result and performed competitively in terms of accuracy and average score difference. We published the source code of our proposed method at https: / / github.com / wsdm-cup-2017 / lettuce so that it could be used for further academic research."}], "references": [{"title": "DBpedia: A Nucleus for a Web of Open Data", "author": ["S. Auer", "C. Bizer", "G. Kobilarov", "J. Lehmann", "R. Cyganiak", "Z. Ives"], "venue": "The Semantic Web,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2007}, {"title": "Relevance scores for triples from type-like relations", "author": ["H. Bast", "B. Buchhold", "E. Haussmann"], "venue": "In SIGIR,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2015}, {"title": "Overview of the Triple Scoring Task at the WSDM Cup 2017", "author": ["H. Bast", "B. Buchhold", "E. Haussmann"], "venue": "In WSDM Cup,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2017}, {"title": "Freebase: A Collaboratively Created Graph Database for Structuring Human Knowledge", "author": ["K. Bollacker", "C. Evans", "P. Paritosh", "T. Sturge", "J. Taylor"], "venue": "In SIGMOD,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2008}, {"title": "Comparing and Aggregating Rankings with Ties", "author": ["R. Fagin", "R. Kumar", "M. Mahdian", "D. Sivakumar", "E. Vee"], "venue": "In PODS,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2004}, {"title": "Greedy Function Approximation: A Gradient Boosting Machine", "author": ["J.H. Friedman"], "venue": "The Annals of Statistics,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2001}, {"title": "WSDM Cup 2017: Vandalism Detection and Triple Scoring", "author": ["S. Heindorf", "M. Potthast", "H. Bast", "B. Buchhold", "E. Haussmann"], "venue": "In WSDM", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2017}, {"title": "Adam: A Method for Stochastic Optimization", "author": ["D. Kingma", "J. Ba"], "venue": "arXiv preprint arXiv:1412.6980,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}, {"title": "Not All Contexts Are Created Equal: Better Word Representations with Variable Attention", "author": ["W. Ling", "Y. Tsvetkov", "S. Amir", "R. Fermandez", "C. Dyer", "A.W. Black", "I. Trancoso", "C.-C. Lin"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2015}, {"title": "Wikidata: A Free Collaborative Knowledgebase", "author": ["D. Vrande\u010di\u0107", "M. Kr\u00f6tzsch"], "venue": "Communications of the ACM,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}], "referenceMentions": [{"referenceID": 9, "context": "In the last decade, huge online structured knowledge bases (KBs) such asWikidata [11], Freebase [4], and DBpedia [1] have emerged.", "startOffset": 81, "endOffset": 85}, {"referenceID": 3, "context": "In the last decade, huge online structured knowledge bases (KBs) such asWikidata [11], Freebase [4], and DBpedia [1] have emerged.", "startOffset": 96, "endOffset": 99}, {"referenceID": 0, "context": "In the last decade, huge online structured knowledge bases (KBs) such asWikidata [11], Freebase [4], and DBpedia [1] have emerged.", "startOffset": 113, "endOffset": 116}, {"referenceID": 1, "context": "[2] addressed this problem by assigning a relevance score to each pair consisting of an entity and its type in KB.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": ", gradient boosted regression trees (GBRT) [6]) to convert the outputs of these classifiers into the final relevance scores.", "startOffset": 43, "endOffset": 46}, {"referenceID": 2, "context": "The proposed method was applied to the triple scoring task at the WSDM Cup 2017 [3, 7] The results demonstrated that our method achieved the best results in one out of three measures (i.", "startOffset": 80, "endOffset": 86}, {"referenceID": 6, "context": "The proposed method was applied to the triple scoring task at the WSDM Cup 2017 [3, 7] The results demonstrated that our method achieved the best results in one out of three measures (i.", "startOffset": 80, "endOffset": 86}, {"referenceID": 1, "context": "[2].", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "We adopt the neural bag-of-items model with a simple item-level attention mechanism [9] to derive the representa-", "startOffset": 84, "endOffset": 87}, {"referenceID": 7, "context": "We trained the model using stochastic gradient descent (SGD) and the learning rate was controlled by Adam [8].", "startOffset": 106, "endOffset": 109}, {"referenceID": 5, "context": "We converted the outputs of the above-mentioned classifiers into relevance scores by adopting gradient boosted regression trees (GBRT) [6].", "startOffset": 135, "endOffset": 138}, {"referenceID": 1, "context": "[2], we used the modified version of Kendall\u2019s \u03c4 score proposed in Fagin et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5]", "startOffset": 0, "endOffset": 3}], "year": 2017, "abstractText": "This paper describes our approach for the triple scoring task at the WSDM Cup 2017. The task required participants to assign a relevance score for each pair of entities and their types in a knowledge base in order to enhance the ranking results in entity retrieval tasks. We propose an approach wherein the outputs of multiple neural network classifiers are combined using a supervised machine learning model. The experimental results showed that our proposed method achieved the best performance in one out of three measures (i.e., Kendall\u2019s \u03c4 ), and performed competitively in the other two measures (i.e., accuracy and average score difference).", "creator": "LaTeX with hyperref package"}}}