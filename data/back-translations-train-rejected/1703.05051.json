{"id": "1703.05051", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Mar-2017", "title": "Deep learning with convolutional neural networks for EEG decoding and visualization", "abstract": "Deep learning with convolutional neural networks (deep ConvNets) has revolutionized computer vision through end-to-end learning, i.e. learning from the raw data. Now, there is increasing interest in using deep ConvNets for end-to-end EEG analysis. However, little is known about many important aspects of how to design and train ConvNets for end-to-end EEG decoding, and there is still a lack of techniques to visualize the informative EEG features the ConvNets learn.", "histories": [["v1", "Wed, 15 Mar 2017 09:52:58 GMT  (8271kb,D)", "http://arxiv.org/abs/1703.05051v1", null], ["v2", "Mon, 10 Jul 2017 11:06:38 GMT  (8271kb,D)", "http://arxiv.org/abs/1703.05051v2", "A revised manuscript (with the new title) has been accepted at Human Brain Mapping, we will provide the URL once it is available online"], ["v3", "Mon, 7 Aug 2017 16:16:08 GMT  (8271kb,D)", "http://arxiv.org/abs/1703.05051v3", "A revised manuscript (with the new title) has been accepted at Human Brain Mapping, seethis http URL"], ["v4", "Tue, 8 Aug 2017 08:48:58 GMT  (8271kb,D)", "http://arxiv.org/abs/1703.05051v4", "A revised manuscript (with the new title) has been accepted at Human Brain Mapping, seethis http URL"]], "reviews": [], "SUBJECTS": "cs.LG cs.NE", "authors": ["robin tibor schirrmeister", "jost tobias springenberg", "lukas dominique josef fiederer", "martin glasstetter", "katharina eggensperger", "michael tangermann", "frank hutter", "wolfram burgard", "tonio ball"], "accepted": false, "id": "1703.05051"}, "pdf": {"name": "1703.05051.pdf", "metadata": {"source": "CRF", "title": "Deep learning with convolutional neural networks for brain mapping and decoding of movement-related information from the human EEG", "authors": ["Tibor Schirrmeister", "Jost Tobias Springenberg", "Lukas Dominique Josef Fiederer", "Martin Glasstetter", "Katharina Eggensperger", "Michael Tangermann", "Frank Hutter", "Wolfram Burgard"], "emails": ["tonio.ball@uniklinik-freiburg.de"], "sections": [{"heading": null, "text": "Deep learning with convolutional neural networks (deep ConvNets) has revolutionized computer vision through end-to-end learning, i.e. learning from the raw data. Now, there is growing interest in using deep ConvNets for end-to-end EEG analysis. However, little is known about many important aspects of how ConvNets can be designed and trained for end-to-end EEG decoding, and there is still a lack of techniques to visualize the informative EEG characteristics of ConvNets. Here, we investigated deep ConvNets with a range of different architectures designed for decoding imaginary or executed movements from the raw EEG. Our results show that recent advances in machine learning, including batch normalization and exponential linear units, along with a truncated training strategy, increase deep ConvNets decoding performance by decoding frequently used CSF-type patterns."}, {"heading": "1 Introduction", "text": "In recent years, the number of people experiencing severe paralysis has increased in order to communicate (Nijboer et al., 2008), to draw images (Mu \ufffd n\u00dfinger et al., 2010), and to control telepresence robots (Tonin et al., 2011). Such systems can also facilitate stroke rehabilitation (Ramos-Murguialday et al., 2013) and can be used in the treatment of epilepsy (Gadhoumi et al., 2016) (for further examples of potential clinical applications, see Moghimi et al. (2013)."}, {"heading": "2 Methods", "text": "First, we present basic definitions of brain signal decoding as a supervised classification problem used in the remaining Methods sections, followed by the principles of both the Common Spatial Pattern Filter Bank (FBCSP), the established baseline decoding method referred to in this study, and Convolutionary Neural Networks (ConvNets). Next, we describe in detail the ConvNets developed for this study, including the design decisions we evaluated, followed by the training of the ConvNets, including two training strategies, and then we present two new visualizations of trained ConvNets in Section 2.6. For data sets and descriptions of preprocessing, see Section 2.7. Details on statistical analysis, software and hardware can be found in Supplementary Sections A.8 and A.9."}, {"heading": "2.1 Definitions and notation", "text": "This section more formally defines how brain signal decoding can be considered a supervised classification problem, and includes the notation used to describe the methods."}, {"heading": "2.1.1 Input and labels", "text": "Specifically, we obtain the data sets Di = {(X1, y1),..., (XNi, yNi), where Ni is the total number of recorded studies for subjects i. The input matrix Xj-RE \u00b7 T of study j, 1 \u2264 j \u2264 Ni contains the pre-processed signals of the E electrodes and T-discredited time steps recorded per experiment. The corresponding class designation of study j is denoted by yj. It takes values from a group of K class designations L, which in our case correspond to the imaginary or executed movements performed in each study, e.g.: yj-yj: yj-L = {l1 = \"Hand (left),\" l2 = \"Hand (right),\" l3 = \"Feet,\" l4 = \"Rest.\""}, {"heading": "2.1.2 Decoder", "text": "Specifically, we aim to train the decoder to assign the yj label to the Xj experiment, using the output of a parametric classifier f (Xj; \u03b8): RE \u00b7 T \u2192 L with parameters \u03b8.For the remainder of this manuscript, we assume that the classifier f (Xj; \u03b8) is represented by a standard machine learning pipeline, which is split into two parts: a first part, which extracts a (vector-weighted) feature representation \u03c6 (Xj; \u03b8\u043e) with parameters success\u03c6 - which could either be set manually (for hand-designed features) or learned from the data; and a second part, which consists of a classifier g with parameters successg, which is trained on the basis of these characteristics, i.e. f (X j; habi) = g (for hand-designed features), success.As described in the following sections, it is important that FS and FS are separated in short steps:"}, {"heading": "2.2 Filter bank common spatial patterns (FBCSP)", "text": "FBCSP (Ang et al., 2008; Chin et al., 2009) is a widely used method for decoding oscillating EEG data, for example in relation to motion-related information, i.e., the decoding problem we focus on in this study. FBCSP was the most powerful method for the BCI competition IV dataset 2a, whose 5Tonio Ball 2 uses METHODSwe in the present study (hereinafter referred to as the BCI Competition Dataset, see Section 2.7 for a brief description of the datasets). FBCSP also won other similar EEG decoding contests (Tangermann et al., 2012). Therefore, we consider FBCSP to be an appropriate benchmark algorithm for evaluating the performance of ConvNets in the present study. Below, we explain the computational steps of FBBCSP."}, {"heading": "2.3 Convolutional neural networks", "text": "In the following sections, we will first explain the basic ideas of ConvNets. Then, we will describe architectural decisions for ConvNets on EEG, including the representation of the EEG input for a ConvNet, the three different ConvNet architectures used in this study, and several specific design decisions that we evaluated for these architectures. Finally, we will describe how ConvNets are trained, including a description of a trial and a truncated training strategy for our EEG data."}, {"heading": "2.3.1 Basics", "text": "Generally speaking, ConvNets combine two ideas that are useful for many learning tasks on natural signals, such as images and audio signals, which often have an inherent hierarchical structure (e.g., images typically consist of edges that form simple shapes together, which in turn form larger, more complex shapes, etc.).ConvNets can learn local nonlinear characteristics (through coils and nonlinearities) and represent superior characteristics as compositions of lower characteristics (through multiplex 6Tonio Ball 2 METHODS layers of processing).In addition, many ConvNets use pooling layers that represent a coarser intermediate characteristic and can make ConvNet more translation invariant. For more details, see LeCun et al. (2015); Goodfellow et al. (2016); Schmidhuber (2015)."}, {"heading": "2.4 ConvNet architectures and design choices", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.4.1 Input representation", "text": "The first important decision for the application of ConvNets to EEG decoding is how to represent the input Xj-RE-T. One possibility would be to represent the EEG as a time series of topographically organized images, i.e. the voltage distributions across the (flattened) surface of the scalp (this was done for ConvNets, which receive power spectra as input (Bashivan et al., 2016). However, it is assumed that EEG signals approach a linear overlay of spatially global voltage patterns caused by multiple dipolar current sources in the brain (Nunez and Srinivasan, 2006)."}, {"heading": "2.4.2 Deep ConvNet for raw EEG signals", "text": "In order to tackle the task of EEG decoding, we have designed a deep ConvNet architecture inspired by successful computer systems, such as those described in Krizhevsky et al. (2012). The requirements for this architecture are as follows: We want a model that has a wide range of properties and is not limited to specific features (Hertel et al.) We are interested in such a generic architecture for two reasons: we want to find out whether such a generic ConvNet can be developed with limited expertise, and we want support for the idea that it can be used as a general tool for decoding."}, {"heading": "2.4.3 Shallow ConvNet for raw EEG signals", "text": "The transformations performed by the flat ConvNet are similar to the transformations of the FBCSP (see Section 2.2). Specifically, the first two layers of the flat ConvNet perform a temporal and a spatial conversion, as in the deep ConvNet. These steps are analogous to the spatial filter steps of the bandpass and CSP in FBCSP. Unlike the deep ConvNet, the temporal conversion of the flat ConvNet has a larger core size (25 vs 10), which allows a larger bandwidth of transformations in this layer (smaller core sizes for the flat ConvNet led to lower accuracies in preliminary experiments). After the two convolutions of the flat ConvNet, a squaring nonliness, a middle pooling structure and a perforation of these steps within the flat ConvNet (see MEVNet), these steps were not compared in the context of an experiment (MEVII)."}, {"heading": "2.4.4 Design choices for deep and shallow ConvNet", "text": "For both architectures described above, we evaluated several design decisions. We evaluated architectural decisions that we expected to have a potentially large impact on decoding accuracy and / or which we hoped to gain insight into the behavior of ConvNets. Thus, for the deep ConvNet, we compared the design aspects listed in Table 1. Below, we provide additional details for some of these aspects. Batch normalization standardizes the intermediate results of the network to zero mean and unit variance for a number of training examples (Ioffe and Szegedy, 2015) to facilitate optimization by keeping the inputs of the layers closer to a normal distribution during training. We applied batch normalization to the output of the revolutionary layers before non-linearity, as recommended in the original paper (Ioffe and Szegedy, 2015)."}, {"heading": "2.4.5 Hybrid ConvNet", "text": "In addition to the individual design choices for the deep and flat ConvNet, there is of course the question of whether the two ConvNets can be combined into a single ConvNet. Such a hybrid ConvNet could benefit from the more specific feature extraction of the flat ConvNet as well as from the more general feature extraction of the deep ConvNet. Therefore, we also developed a hybrid ConvNet by merging both networks after the last layer. Specifically, we have retrained the four filter softmax classification layers of the two ConvNets with 60 and 40 filter ELU layers for the deep and flat ConvNet respectively, and the resulting 100 feature maps have been linked and used as input into a new Softmax classification layer. We have retrained the entire ConvNet hybrid from scratch and have not used any pre-set deep or flat ConvNet parameters."}, {"heading": "2.4.6 Residual ConvNet for raw EEG signals", "text": "In addition to the flat and deep ConvNets, we examined another network architecture: Residual Networks (ResNets), a ConvNet architecture that recently won several computer vision benchmarks (He et al., 2015). ResNets typically have a very large number of layers, and we wanted to investigate whether similar networks with more layers also perform well in EEG decoding. ResNets adds the input of a revolutionary layer to the output of the same layer, so that the revolutionary layer only has to learn to output a residual layer that changes the output of the previous layers (hence the name Residual Network), which allows ResNets to be successfully trained with a much larger number of layers than conventional Constitutional Networks (He et al., 2015). Our residual blocks are the same as those described in the original paper (see Figure 3). Our ResNet used exponential differential activation functions (the deep conversion of the network, as well as the full conversion of the net) mean a deep one."}, {"heading": "2.5 ConvNet training", "text": "In this section, we first give a definition of how ConvNets are trained in general. Second, we describe two ways to extract training inputs and training labels from the EEG data, which lead to a pro-proof and truncated training strategy. 11Tonio Ball 2 METHODSxF (x) F (x) + x"}, {"heading": "2.5.1 Definition", "text": "To form a ConvNet, all parameters (all weights and biases) of the ConvNet = net probability (j = miniature probability) are formed together. Formally, the ConvNet calculates a function from input data to a real number per class, f (Xj; \u03b8): RE \u00b7 T \u2192 RK, where \u03b8 are the parameters of the function, E is the number of electrodes, T the number of timestamps, and K the number of possible output labels. To use ConvNets for classification, the output is typically converted into conditional probabilities of a label lk, using the input X j with the softmax function: p (lk | f (Xj; junction) = exp (Xj;)).K k = 1 exp (fk (X j; \u03b8).In our case, since we train per subject, the softmax output gives us a subject-specific conditional distribution over the classes K."}, {"heading": "2.5.2 Input and labels", "text": "In this study, we have explored two ways to define the input examples and target labels on which ConvNet is trained: first, an experimental strategy that uses whole studies as input and pro-trial labels as targets; second, a training strategy that uses crops, i.e. time frames within the experiment as input and pro-trial labels as targets (where the label of a plant is identical to the label of the experiment from which the plant was extracted)."}, {"heading": "2.5.3 Trial-wise training", "text": "The usual trial-wise training strategy uses the entire duration of the study and is therefore similar to the way FBCSP is trained. For each study, the trial signal is used as input and the corresponding trial label as target to train the ConvNet. In our study, we had 4.5-second studies for both sets of data (from 500 ms before trial start to the trial-end cue, as this worked best in pre-trials) as input to the network, resulting in 288 training examples per subject for the BCI Competition Dataset and about 880 training examples per subject on the High-Gamma Dataset after their respective train-test split."}, {"heading": "2.5.4 Cropped training", "text": "rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr"}, {"heading": "2.5.5 Optimization and early stopping", "text": "As an optimization method, we used Adam (Kingma and Ba, 2014) together with a special early stop method, which consistently provided good accuracy in our experiments. For details on Adam and our early stop strategy, see Supplementary Section A.4.15Tonio Ball 2 METHODS."}, {"heading": "2.6 Visualization", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.6.1 Correlating Input Features and Unit Outputs: Network Correlation Maps", "text": "As described in the introduction, there is currently a great deal of interest in how ConvNets learn to solve various tasks. To this end, methods of visualizing functional aspects of ConvNets can be helpful, and the development of such methods is an active area of research. Here, we wanted to define which brain signals the ConvNets use and in which layers they extract these traits. The most obvious limitation to possible traits is that units in individual layers of ConvNet can only extract traits from samples they have so named (see Figure 5)."}, {"heading": "2.7 Data sets and preprocessing", "text": "We investigated the decryption accuracy of two EEG datasets, a smaller public dataset (BCI Competition IV dataset 2a) for comparison with previously published accuracies, and a larger new dataset acquired in our laboratory to evaluate the decryption methods with a larger number of training experiments (approximately 880 studies per subject, compared to 288 studies in the public dataset)."}, {"heading": "2.7.1 EEG preprocessing and evaluating different frequency bands", "text": "In addition to the complete dataset (0-fend-Hz), we analyzed data filtered above 4 Hz (what we call the 4-fend-Hz dataset) and filtered using a 3rd order causal Butterworth filter. We included the 4-fend-Hz dataset because the high-pass filter was designed to make it less likely that either the networks or FBCSP would use class-discriminatory eye movement artifacts to decipher the behavioral classes, since eye movements produce the most power at such low frequencies (Gratton, 1998)."}, {"heading": "3 Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Validation of FBCSP baseline", "text": "Result 1 FBCSP Baseline achieved the same results as previously reported in the literature. To validate our FBCSP implementation, we compared its accuracy with those published in the literature for the BCI Competition IV dataset 2a (hereinafter referred to as the BCI Competition Dataset) (Sakhavi et al., 2015). Using the same time window of 0.5-2.5 s (relative to the start of the experiment), we achieved an accuracy of 67.6%, which was not statistically significantly different from theirs (67.0%, p = 0.73, Wilcoxon Signature Rank Test). Note, however, that we used the full test window for subsequent experiments with Constitutional Networks, i.e. 0.5-4 seconds. This resulted in a slightly better accuracy of 67.8%, which was still not significantly different from the original results of 0.5-4 seconds."}, {"heading": "3.2 Architectures and design choices", "text": "This year, it is only a matter of time before an agreement is reached."}, {"heading": "3.3 Training Strategy", "text": "Result 8 Cropped training strategy improved the low ConvNet on higher frequencies. Cropped training sessions statistically significantly increased the accuracy of the low ConvNet on the 4-Fend-Hz data (p < 1e-5, Wilcoxon Signed-Rank test). In all other settings (0-Fend-Hz data, flat ConvNet), the accuracy differences were not statistically significant (p > 0.1) and showed a lot of discrepancies between subjects. Result 9 Training ConvNets took significantly longer than FBCSPFBCSP was significantly faster to train than the ConvNets with cropped training, by a factor of 27-45 on the BCI Competition Dataset and a factor of 5-9 on the High-Gamma Dataset. Training times are end-to-end, i.e., include loading and pre-processing of the data."}, {"heading": "3.4 Visualization", "text": "This year, it is only a matter of time before an agreement is reached."}, {"heading": "4 Discussion", "text": "This study shows that ConvNets enables precise motor decoding from the EEG, that newer deep learning techniques are critical to enhance ConvNet's performance, and that a truncated ConvNet training strategy can further enhance decoding performance. ConvNets can therefore achieve successful end-to-end learning from the EEG with minimal pre-processing, and this study also shows that the novel ConvNets visualization provides new ways of brain mapping informative EEG features."}, {"heading": "4.1 Architectures and design choices", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1.1 ConvNets vs. FBCSP", "text": "Our results show that deep and flat ConvNets, with appropriate design choices, are able to achieve at least the accuracy of FBCSP for motoric decoding from the EEG (see Result 2). In our main comparison for the combined datasets (see Table 2), the accuracy of both deeper and shallower ConvNets is very close and slightly higher than the accuracy of FBCSP. Since common spatial patterns of the filter bank are de facto the standard for motoric decoding from EEG recordings, this strongly suggests that ConvNets is also a suitable method for motoric decoding. While we have shown that deep ConvNets can compete with the FBCSP standard, there are many variants of FBCSP. For example, there are many regulated variants of CSP that can be used within FBCSP (Lotte and Guan, 2011; Samek, 2014); a comparison with these could show the exact target conflict between the constraints between the congeneric and CSP congeners."}, {"heading": "4.1.2 Role of recent deep learning advances", "text": "Success depends on the use of recent developments in deep learning. The increase in accuracy we show in the use of batch normalization, dropout, and exponential linear units implies that general advances in deep learning can also improve the decoding of brain signals. Improvement through the use of these techniques replicates current findings in the field of computer vision and other fields. This is consistent with our observation that the truncated training, which combines revision by increasing the number of training examples, also exhibits drastically increased accuracy in 4-fendHz data (see Result 8). There seemed to be some additional gains when combining both batch normalization and abort, with the differences between these batch tasks and abort, albeit with some discrepancies between architectures and frequency bands. This improvement was not clear from the outset, as batch normalization eliminates the need for abort in some cases."}, {"heading": "4.1.3 ConvNet architectures and interactions with discriminative features", "text": "Another finding of our study was that flat ConvNets performed as well as deep ConvNets as opposed to hybrid and residual architectures (see Results 2, 4 and 7), and these observations could possibly be better understood by examining more closely what discriminatory features are present in the EEG data and which architectures can best utilize them. For example, it would be interesting to study the effects of more layers if the networks mainly use EEG band current characteristics, phaserelated features or a combination of them (see Hammer et al. (2013), for the role of power and phase in motor deciphering) and whether there are features that could benefit from a deeper hierarchical representation. We observed that squaring was important for flat ConvNet, but not for deep ConvNet (see Result 5). The poorer performance of flat ConvNet with ELU instead of squaring oscillation could be explained as follows."}, {"heading": "4.1.4 Possibilities for substantial decoding accuracy improvements?", "text": "In recent years the number of unemployed underage minors inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior inferior"}, {"heading": "4.1.5 Further potential advantages of ConvNets for brain-signal decoding", "text": "Besides deciphering performance, there are other potential benefits of using deep ConvNets for decoding brain signals: First, several use cases that are desirable for decoding brain signals can be easily trained iteratively with deep ConvNets in an end-to-end manner: Deep ConvNets can be applied to other types of tasks such as workload estimation, error or event-related potential decoding (as others have begun (Lawhern et al., 2016)), or even to other types of recordings such as MEG or ECoG. In addition, ConvNets have a natural way of pre-training and fining due to their iterative training; for example, a ConvNet can be pre-trained on data from the past or data from other subjects and then finetuned with new data from a new subject."}, {"heading": "4.2 Training strategy", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.2.1 Cropped training effect on accuracies", "text": "We observed that tailored training for the deep ConvNet was necessary to achieve competitive accuracies on the dataset without very low frequencies (see Result 8).The large increase in accuracy with tailored training for the deep network on the 4-fend-Hz data could indicate that a large number of training examples are needed to learn to extract bandwidth characteristics, which makes sense since the shifted adjacent windows may contain the same, but shifted, oscillatory signals. These shifts may prevent the network from matching phase information within the study, which is less important in the higher frequencies than the lower frequencies (Hammer et al., 2013).This might also explain why other studies of ConvNets for brain signal decoding that used uncut training, but where bandpower supply might be the most discriminatory feature, used fairly flat architectures and sometimes found them superior (2014)."}, {"heading": "4.2.2 Suitability for online decoding", "text": "As described above, it offers performance advantages over conventional (non-pruned) training. In addition, pruned training enables a meaningful calibration of the trade-off between 32Tonio Ball 4 DISCUSSION decoding delay and decoding accuracy in online settings. The duration from the start of the experiment to the last sample of the first harvest should be approximately the minimum time needed to decipher a control signal. Conversely, smaller harvests, which still largely contain timesteps from the experimental room, may result in a longer delay until a control signal is deciphered, and may increase decoding accuracy based on more information contained in the larger harvests. Conversely, larger harvests, which still largely contain timesteps from the experimental room, mean a longer delay until a control signal is deciphered."}, {"heading": "4.3 Visualization", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.3.1 Insights from current visualizations", "text": "In addition to researching how ConvNets can be successfully used to decode information from the EEG, we have also developed and tested two complementary methods to visualize what ConvNets learn from the EEG data. So far, literature on the use of ConvNets to decode brain signals, for example, has visualized weights or outputs of ConvNet layers (Bashivan et al., 2016; Santana et al., 2014; Stober, 2016; Yang et al., 2015), determining inputs that maximally activate certain folding filters (Bashivan et al., 2016), or describing attempts to synthesize the preferred input of a folding filter (Bashivan et al., 2016) (see additional section A.1 for a more comprehensive overview)."}, {"heading": "4.3.2 Feature discovery through more sophisticated visualizations?", "text": "One limitation of the visualizations presented here is that so far we have only designed them to show how ConvNet uses known bandwidth features, but it could be even more interesting to investigate whether new or previously unknown features are used and to characterize them. However, even for tasks where the discriminatory features are less well known than for motor decoding, such as less studied tasks such as task decoding (Meinel et al., 2016), our results show that deep ConvNets use features other than flat ConvNets, as well as FBCSP-based decoding, because there are statistically significant differences between their confusion matrices (see Result 3). This strengthens the motivation to investigate which features the deep ConvNet exploits, for example through visualizations that show which parts of a study are relevant to the classification decision or which specific confusion matrices (see Result 3)."}, {"heading": "4.4 Conclusion", "text": "In summary, ConvNets is not only a novel and promising tool in the toolbox of EEG decoding, but in combination with innovative visualization techniques, it can also open up new windows for EEG-based brain mapping.34Tonio Ball 4 DISCUSSION"}, {"heading": "Acknowledgements", "text": "This work was supported by the Cluster of Excellence BrainLinks-BrainTools (DFG funding EXC1086) and the Federal Ministry of Education and Research (BMBF funding Motor-BIC 13GW0053D). Conflicts of Interest The authors declare that there is no conflict of interest with regard to the publication of this paper.35Tonio Ball REFERENCES"}], "references": [], "referenceMentions": [], "year": 2017, "abstractText": "Deep learning with convolutional neural networks (deep ConvNets) has revolutionized computer vision through end-to-end learning, i.e. learning from the raw data. Now, there is increasing interest in using deep ConvNets for end-to-end EEG analysis. However, little is known about many important aspects of how to design and train ConvNets for end-to-end EEG decoding, and there is still a lack of techniques to visualize the informative EEG features the ConvNets learn. Here, we studied deep ConvNets with a range of different architectures, designed for decoding imagined or executed movements from raw EEG. Our results show that recent advances from the machine learning field, including batch normalization and exponential linear units, together with a cropped training strategy, boosted the deep ConvNets decoding performance, reaching or surpassing that of the widely-used filter bank common spatial patterns (FBCSP) decoding algorithm. While FBCSP is designed to use spectral power modulations, the features used by ConvNets are not fixed a priori. Our novel methods for visualizing the learned features demonstrated that ConvNets indeed learned to use spectral power modulations in the alpha, beta and high gamma frequencies. These methods also proved useful as a technique for spatially mapping the learned features, revealing the topography of the causal contributions of features in different frequency bands to decoding the movement classes. Our study thus shows how to design and train ConvNets to decode movement-related information from the raw EEG without handcrafted features and highlights the potential of deep ConvNets combined with advanced visualization techniques for EEG-based brain mapping. Tonio Ball", "creator": "LaTeX with hyperref package"}}}