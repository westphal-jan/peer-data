{"id": "1703.05320", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Mar-2017", "title": "Legal Question Answering using Ranking SVM and Deep Convolutional Neural Network", "abstract": "This paper presents a study of employing Ranking SVM and Convolutional Neural Network for two missions: legal information retrieval and question answering in the Competition on Legal Information Extraction/Entailment. For the first task, our proposed model used a triple of features (LSI, Manhattan, Jaccard), and is based on paragraph level instead of article level as in previous studies. In fact, each single-paragraph article corresponds to a particular paragraph in a huge multiple-paragraph article. For the legal question answering task, additional statistical features from information retrieval task integrated into Convolutional Neural Network contribute to higher accuracy.", "histories": [["v1", "Thu, 16 Mar 2017 01:06:07 GMT  (346kb,D)", "http://arxiv.org/abs/1703.05320v1", "15 pages, 2 figures, Tenth International Workshop on Juris-informatics (JURISIN 2016) associated with JSAI International Symposia on AI 2016 (IsAI-2016)"]], "COMMENTS": "15 pages, 2 figures, Tenth International Workshop on Juris-informatics (JURISIN 2016) associated with JSAI International Symposia on AI 2016 (IsAI-2016)", "reviews": [], "SUBJECTS": "cs.CL cs.AI", "authors": ["phong-khac do", "huy-tien nguyen", "chien-xuan tran", "minh-tien nguyen", "minh-le nguyen"], "accepted": false, "id": "1703.05320"}, "pdf": {"name": "1703.05320.pdf", "metadata": {"source": "CRF", "title": "Legal Question Answering using Ranking SVM and Deep Convolutional Neural Network", "authors": ["Phong-Khac Do", "Huy-Tien Nguyen", "Chien-Xuan Tran", "Minh-Tien Nguyen", "Minh-Le Nguyen"], "emails": ["nguyenml}@jaist.ac.jp"], "sections": [{"heading": null, "text": "Keywords: Learning to Rank, Ranking SVM, Convolutional Neural Network (CNN), Legal Information Retrieval, Legal Question Answering."}, {"heading": "1 Introduction", "text": "In fact, it is such that most of them are able to move into another world, in which they are able to move, in which they are able to move, in which they are able to move, in which they are able to live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they"}, {"heading": "2 Proposed Method", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Basic Idea", "text": "In the context of COLIEE 2016, our approach is to create a pipeline framework that addresses two important tasks: IR and QA. In Figure 1, a legal text corpus was built up during the training phase based on all articles. Each query / article pair for LIR task and LQA task was presented as a feature vector. These feature vectors were used to train a Learning-to-Rank model (L2R) for IR and a classifier (CNN) for QA. The red arrows indicate that these steps were prepared in advance. In the test phase, the system extracts its features at query q and calculates the relevance score corresponding to each article by using the L2R model. Higher score by SVM rank means that the article is more relevant. As shown in Figure 1, the article takes first place with the highest score, i.e. 2.6 points, followed by others with lower scores."}, {"heading": "2.2 Data Observation", "text": "The published training data set in COLIEE 20163 consists of a text file with the Japanese Civil Code and eight XML files. Each XML file contains several pairs of queries and their relevant articles, and each pair has a label \"YES\" or \"NO\" that confirms the query that corresponds to the relevant articles. In total, there are 412 pairs in eight XML files and 1,105 articles in the file of the Japanese Civil Code, and each query may have more than one relevant article. After analyzing the records in the file of the Civil Code, we found that the content of a query is often more or less related to just one paragraph of an article, rather than to the entire content. Based on this, each article was treated as one of two types: one paragraph or more paragraphs in which a multiple paragraph is found, in which an article consists of more than one paragraph."}, {"heading": "2.3 Legal Question Answering", "text": "In order to conduct a series of experiments to discover the six best characteristics among each characteristic, we need to consider the basic characteristics of each characteristic and other possible characteristics. Therefore, the idea is to build an L2R model that includes various characteristics to generate an optimal ranking order. Under different L2R methods, it is important to consider a combination of basic characteristics and other potential characteristics. [5], a state-of-the-art ranking method and also a strong method for IR [4,18], which is an extended version of the Kim model with two new aspects. First, there is a great distinction between our characteristics and Kim's characteristics. While Kim uses three types of characteristics: lexical words, dependence pairs and TF-IDF score; we have conducted a series of experiments to discover a compilation of the six best characteristics among each characteristic."}, {"heading": "3 Results and Discussion", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Information Retrieval", "text": "This year, it has reached the stage where it will be able to take the lead."}, {"heading": "3.2 Legal Question Answering", "text": "Comparative Results: In the legal QA task, the proposed model was compared with the original CNN model and separate TF-IDF, LSI features. For evaluation, we took 10% samples from the training set for validation and conducted experiments on data sets with balanced label distribution for training set, validation set and test set. In CNN models, we found that these models were sensitive to the initial value of parameters. Different values lead to large differences in results (\u00b1 5%). Therefore, each model was executed n times (n = 10) and we selected the best optimized parameters against the validation set. Table 7 shows that CNN performs better with additional features. Also, CNN with LSI produces a better result compared to CNN with TF-IDF. We suspect that this is because the TF-IDF vector is large but quite sparse (most values are zero), so it increases the number of parameters and makes CNN equipped in the model."}, {"heading": "3.3 Legal Question Answering System", "text": "At this stage, we illustrate our framework using the data from COLIEE 2016. The framework was trained using XML files from H18 to H23 and tested using the XML file H24. Faced with a legal question, the framework first calls the five most important articles and then transfers the question and the relevant articles to the CNN classifier. The sequence of the framework was evaluated using 3 scenarios: Scenario Accuracy% No Voting 45.6 Voting without ratio 49.4 Voting with ratio 48.1 Table 9 shows results with different scenarios. The result of the \"No\" approach is influenced by the performance of the IR task, so the accuracy is not as high as when using votes. The relevant point difference between the first and second relevant article is large, which results in a worse result of the vote with ratio compared to vote without ratio."}, {"heading": "4 Splitting and non-splitting error analysis", "text": "In this section, we will show an example in which our proposed model using individual paragraphs provides a correct answer as opposed to the use of individual paragraphs. In view of a request number H20-26-3: \"A mandate contract is in principle a free contract, but if there is a special provision, the client may request a recount from the client,\" referring to Article 648: Method Article RankSplitting648 (1) 1 653 2 648 (3) 5 648 (2) 29Non-Splitting 653 1 648 6Obviously, three paragraphs and the query share several words, namely mandatory, remuneration, etc. In this case, however, the correct answer is only in paragraph 1, which comes first in this individual paragraph model, whereas the individual paragraph model, as opposed to two remaining paragraph articles with lower ranks, fifth and 29th paragraph, as in Article 11.Contenting653, is terminated by the Mandator (a Mandator)."}, {"heading": "5 Conclusion", "text": "This paper examines the ranking of SVM model and CNN for building a system for answering legal questions under the Japanese Civil Code. Experimental results show that feature selection significantly influences the performance of SVM rank, with a number of features consisting of (LSI, Manhattan, Jaccard) providing promising results for the task of retrieving information. In answering questions, the CNN model responds sensitively to initial values of parameters and exerts greater accuracy when adding additional features. In our current work, we have not yet fully explored the characteristics of legal texts to use these features in building a legal QA system. Properties such as references between articles or structured relationships in court rulings should be examined in more detail. In addition, there should be more evaluations of SVM rank and other L2R methods to observe how they work based on the same features."}, {"heading": "Acknowledgement", "text": "This work was supported by JSPS KAKENHI grant number 15K16048, JSPS KAKENHI grant number JP15K12094 and CREST, JST."}], "references": [{"title": "Concept and Context in Legal Information Retrieval.", "author": ["Maxwell", "K. Tamsin", "Burkhard Schafer"], "venue": "JURIX", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2008}, {"title": "Lexical-Morphological Modeling for Legal Text Analysis", "author": ["Danilo S. Carvalho", "Minh-Tien Nguyen", "Chien-Xuan Tran", "Minh-Le Nguyen"], "venue": "Ninth International Workshop on Juris-informatics (JURISIN),", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2015}, {"title": "A Convolutional Neural Network in Legal Question Answering", "author": ["Mi-Young Kim", "Ying Xu", "Randy Goebel"], "venue": "Ninth International Workshop on Juris-informatics (JURISIN),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2015}, {"title": "Learning to rank: from pairwise approach to listwise approach.", "author": ["Zhe Cao", "Tao Qin", "Tie-Yan Liu", "Ming-Feng Tsai", "Hang Li"], "venue": "Proceedings of the 24th international conference on Machine learning", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2007}, {"title": "Training Linear SVMs in Linear Time Proceedings of the ACM Conference on Knowledge Discovery and Data Mining (KDD).", "author": ["T. Joachims"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2006}, {"title": "Legal Information Retrieval Task: Participation from ISM, Dhanbad", "author": ["Sushmita", "A. Kanapala", "S. Pal"], "venue": "Ninth International Workshop on Juris-informatics (JURISIN),", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "An Approach for Retrieving Legal Texts", "author": ["Vu Duc Tran", "Anh Viet Phan", "Long Hai Trieu", "Minh Le Nguyen"], "venue": "Ninth International Workshop on Juris-informatics (JURISIN),", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2015}, {"title": "Keyword and Snippet Based Yes/No Question Answering System for COLIEE 2015", "author": ["Yoshinobu Kano"], "venue": "Ninth International Workshop on Juris-informatics (JURISIN),", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "Latent dirichlet allocation.", "author": ["Blei", "David M", "Andrew Y. Ng", "Michael I. Jordan"], "venue": "Journal of machine Learning research", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2003}, {"title": "Software framework for topic modelling with large corpora", "author": ["Radim \u0158eh\u030au\u0159ek", "Petr Sojka"], "venue": "Proc. LREC Workshop on New Challenges for NLP Frameworks,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2010}, {"title": "Recognizing textual entailment: Rational, evaluation and approacheserratum.", "author": ["Dagan", "Ido"], "venue": "Natural Language Engineering", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2010}, {"title": "Convolutional neural networks for sentence classification.", "author": ["Kim", "Yoon"], "venue": "arXiv preprint arXiv:1408.5882", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2014}, {"title": "Semantic Parsing for SingleRelation Question Answering.", "author": ["Yih", "Wen-tau", "Xiaodong He", "Christopher Meek"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Learning semantic representations using convolutional neural networks for web search.", "author": ["Shen", "Yelong", "Xiaodong He", "Jianfeng Gao", "Li Deng", "Grgoire Mesnil"], "venue": "Proceedings of the 23rd International Conference on World Wide Web. ACM,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "A convolutional neural network for modelling sentences.", "author": ["Kalchbrenner", "Nal", "Edward Grefenstette", "Phil Blunsom"], "venue": "arXiv preprint arXiv:1404.2188", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2014}, {"title": "Deep learning for answer sentence selection.", "author": ["Yu", "Lei", "Karl Moritz Hermann", "Phil Blunsom", "Stephen Pulman"], "venue": "arXiv preprint arXiv:1412.1632", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2014}, {"title": "A theoretical analysis of feature pooling in visual recognition.", "author": ["Boureau", "Y-Lan", "Jean Ponce", "Yann LeCun"], "venue": "Proceedings of the 27th international conference on machine learning (ICML-10)", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2010}, {"title": "Learning to Rank Questions for Community Question Answering with Ranking SVM.", "author": ["Minh-Tien Nguyen", "Viet-Anh Phan", "Truong-Son Nguyen", "Minh-Le Nguyen"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2016}, {"title": "Recognizing textual entailment in vietnamese text: an experimental study.", "author": ["Minh-Tien Nguyen", "Quang-Thuy Ha", "Thi-Dung Nguyen", "Tri-Thanh Nguyen", "LeMinh Nguyen"], "venue": "Knowledge and Systems Engineering (KSE),", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2015}, {"title": "A desicion-theoretic generalization of online learning and an application to boosting.", "author": ["Freund", "Yoav", "Robert E. Schapire"], "venue": "European conference on computational learning theory. Springer Berlin Heidelberg,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1995}, {"title": "Efficient estimation of word representations in vector space.", "author": ["Tomas Mikolov", "Kai Chen", "Greg Corrado", "Jeffrey Dean"], "venue": "arXiv preprint arXiv:1301.3781", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2013}, {"title": "An Ensemble Based Legal Information Retrieval and Entailment System", "author": ["Kiyoun Kim", "Seongwan Heo", "Sungchul Jung", "Kihyun Hong", "Young-Yik Rhim"], "venue": "Tenth International Workshop on Juris-informatics (JURISIN),", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2016}, {"title": "Civil Code Article Information Retrieval System based on Legal Terminology and Civil Code Article Structure", "author": ["Daiki Onodera", "Masaharu Yoshioka"], "venue": "Tenth International Workshop on Juris-informatics (JURISIN),", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2016}, {"title": "COLIEE-2016: Evaluation of the Competition on Legal Information Extraction and Entailment", "author": ["Mi-Young Kim", "Randy Goebel", "Yoshinobu Kano", "Ken Satoh"], "venue": "Tenth International Workshop on Juris-informatics (JURISIN),", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2016}, {"title": "Legal Question Answering Using Paraphrasing and Entailment Analysis", "author": ["Mi-Young Kim", "Ying Xu", "Yao Lu", "Randy Goebel"], "venue": "Tenth International Workshop on Juris-informatics (JURISIN),", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2016}], "referenceMentions": [{"referenceID": 0, "context": "There are two primary approaches to information retrieval (IR) in the legal domain [1]: manual knowledge engineering (KE) and natural language processing (NLP).", "startOffset": 83, "endOffset": 86}, {"referenceID": 1, "context": "For example, factors and concepts in legal language are applied in a different way from common usage [2].", "startOffset": 101, "endOffset": 104}, {"referenceID": 2, "context": "Hence, in order to effectively answer a legal question, it must compare the semantic connections between the question and sentences in relevant articles found in advance [3].", "startOffset": 170, "endOffset": 173}, {"referenceID": 2, "context": "[3] exploited Ranking SVM with a set of features for legal IR and Convolutional Neural Network (CNN) [12] combining with linguistic features for question answering (QA) task.", "startOffset": 0, "endOffset": 3}, {"referenceID": 11, "context": "[3] exploited Ranking SVM with a set of features for legal IR and Convolutional Neural Network (CNN) [12] combining with linguistic features for question answering (QA) task.", "startOffset": 101, "endOffset": 105}, {"referenceID": 1, "context": "[2] utilized n-gram features to rank articles by using an extension of TF-IDF.", "startOffset": 0, "endOffset": 3}, {"referenceID": 19, "context": "For QA task, the authors adopted AdaBoost [20] with a set of similarity features between a query and an article pair [19] to classify a query-article pair into \u201cYES\u201d or \u201cNO\u201d.", "startOffset": 42, "endOffset": 46}, {"referenceID": 18, "context": "For QA task, the authors adopted AdaBoost [20] with a set of similarity features between a query and an article pair [19] to classify a query-article pair into \u201cYES\u201d or \u201cNO\u201d.", "startOffset": 117, "endOffset": 121}, {"referenceID": 5, "context": "[6] used the voting of Hiemstra, BM25 and PL2F for IR task.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[7] used Hidden Markov model (HMM) as a generative query model for legal IR task.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "Kano [8] addressed legal IR task by using a keyword-based method in which the score of each keyword was computed from a query and its relevant articles using inverse frequency.", "startOffset": 5, "endOffset": 8}, {"referenceID": 1, "context": "In [2], the stopword removal stage was done before the lemmatization", "startOffset": 3, "endOffset": 6}, {"referenceID": 4, "context": "Among different L2R methods, Ranking SVM (SVM-Rank) [5], a state-ofthe-art pairwise ranking method and also a strong method for IR [4,18], was used.", "startOffset": 52, "endOffset": 55}, {"referenceID": 3, "context": "Among different L2R methods, Ranking SVM (SVM-Rank) [5], a state-ofthe-art pairwise ranking method and also a strong method for IR [4,18], was used.", "startOffset": 131, "endOffset": 137}, {"referenceID": 17, "context": "Among different L2R methods, Ranking SVM (SVM-Rank) [5], a state-ofthe-art pairwise ranking method and also a strong method for IR [4,18], was used.", "startOffset": 131, "endOffset": 137}, {"referenceID": 2, "context": "Our model is an extended version of Kim\u2019s model [3] with two new aspects.", "startOffset": 48, "endOffset": 51}, {"referenceID": 8, "context": "2), three basic models were built: TF-IDF, LSI and Latent Dirichlet Allocation (LDA) [9].", "startOffset": 85, "endOffset": 88}, {"referenceID": 9, "context": "Those features were extracted by using gensim library [10].", "startOffset": 54, "endOffset": 58}, {"referenceID": 1, "context": "In [2], if an article has a reference to other articles, the authors expanded it with words of referential ones.", "startOffset": 3, "endOffset": 6}, {"referenceID": 10, "context": "Legal Question Answering is a form of textual entailment problem [11], which can be viewed as a binary classification task.", "startOffset": 65, "endOffset": 69}, {"referenceID": 11, "context": "In the COLLIE 2015, Kim [12] efficiently applied Convolution Neural Network (CNN) for the legal QA task.", "startOffset": 24, "endOffset": 28}, {"referenceID": 2, "context": "The idea behind the QA is that we use CNN [3] with additional features.", "startOffset": 42, "endOffset": 45}, {"referenceID": 12, "context": "This is because: (i) CNN is capable to capture local relationship between neighboring words, which helps CNN to achieve excellent performance in NLP problems [13,3,14,15] and (ii) we can integrate our knowledge in legal domain in the form of statistical features, e.", "startOffset": 158, "endOffset": 170}, {"referenceID": 2, "context": "This is because: (i) CNN is capable to capture local relationship between neighboring words, which helps CNN to achieve excellent performance in NLP problems [13,3,14,15] and (ii) we can integrate our knowledge in legal domain in the form of statistical features, e.", "startOffset": 158, "endOffset": 170}, {"referenceID": 13, "context": "This is because: (i) CNN is capable to capture local relationship between neighboring words, which helps CNN to achieve excellent performance in NLP problems [13,3,14,15] and (ii) we can integrate our knowledge in legal domain in the form of statistical features, e.", "startOffset": 158, "endOffset": 170}, {"referenceID": 14, "context": "This is because: (i) CNN is capable to capture local relationship between neighboring words, which helps CNN to achieve excellent performance in NLP problems [13,3,14,15] and (ii) we can integrate our knowledge in legal domain in the form of statistical features, e.", "startOffset": 158, "endOffset": 170}, {"referenceID": 15, "context": "A sentence represented by a set of words was converted to a word embedding vector v 1 by using bag-of-words model (BOW) [16].", "startOffset": 120, "endOffset": 124}, {"referenceID": 20, "context": "A word embedding model (d = 200) was trained by using Word2Vec[21] on the data of Japanese law corpus[2].", "startOffset": 62, "endOffset": 66}, {"referenceID": 1, "context": "A word embedding model (d = 200) was trained by using Word2Vec[21] on the data of Japanese law corpus[2].", "startOffset": 101, "endOffset": 104}, {"referenceID": 16, "context": "Each feature map was fed to a pooling layer to generate potential features by using the average mechanism [17].", "startOffset": 106, "endOffset": 110}, {"referenceID": 23, "context": "In COLIEE 2016 competition, Table 6 shows the top three systems and the baseline for the formal run in phase 1 [24].", "startOffset": 111, "endOffset": 115}, {"referenceID": 21, "context": "Among 7 submissions, iLis7 [22] was ranked first with outstanding performance (0.", "startOffset": 27, "endOffset": 31}, {"referenceID": 22, "context": "5310 HUKB-2 [23] 0.", "startOffset": 12, "endOffset": 16}, {"referenceID": 21, "context": "5532 iLis7 [22] 0.", "startOffset": 11, "endOffset": 15}, {"referenceID": 22, "context": "HUKB-2 [23] used a fundamental feature BM25 and applied mutatis mutandis for articles.", "startOffset": 7, "endOffset": 11}, {"referenceID": 21, "context": "Method Phase 2 Phase 3 iLis7 [22] 0.", "startOffset": 29, "endOffset": 33}, {"referenceID": 24, "context": "5158 UofA[25] 0.", "startOffset": 9, "endOffset": 13}], "year": 2017, "abstractText": "This paper presents a study of employing Ranking SVM and Convolutional Neural Network for two missions: legal information retrieval and question answering in the Competition on Legal Information Extraction/Entailment. For the first task, our proposed model used a triple of features (LSI, Manhattan, Jaccard), and is based on paragraph level instead of article level as in previous studies. In fact, each single-paragraph article corresponds to a particular paragraph in a huge multiple-paragraph article. For the legal question answering task, additional statistical features from information retrieval task integrated into Convolutional Neural Network contribute to higher accuracy.", "creator": "LaTeX with hyperref package"}}}