{"id": "1703.05921", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Mar-2017", "title": "Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide Marker Discovery", "abstract": "Obtaining models that capture imaging markers relevant for disease progression and treatment monitoring is challenging. Models are typically based on large amounts of data with annotated examples of known markers aiming at automating detection. High annotation effort and the limitation to a vocabulary of known markers limit the power of such approaches. Here, we perform unsupervised learning to identify anomalies in imaging data as candidates for markers. We propose AnoGAN, a deep convolutional generative adversarial network to learn a manifold of normal anatomical variability, accompanying a novel anomaly scoring scheme based on the mapping from image space to a latent space. Applied to new data, the model labels anomalies, and scores image patches indicating their fit into the learned distribution. Results on optical coherence tomography images of the retina demonstrate that the approach correctly identifies anomalous images, such as images containing retinal fluid or hyperreflective foci.", "histories": [["v1", "Fri, 17 Mar 2017 08:27:05 GMT  (1869kb,D)", "http://arxiv.org/abs/1703.05921v1", "To be published in the proceedings of the international conference on Information Processing in Medical Imaging (IPMI), 2017"]], "COMMENTS": "To be published in the proceedings of the international conference on Information Processing in Medical Imaging (IPMI), 2017", "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["thomas schlegl", "philipp seeb\\\"ock", "sebastian m waldstein", "ursula schmidt-erfurth", "georg langs"], "accepted": false, "id": "1703.05921"}, "pdf": {"name": "1703.05921.pdf", "metadata": {"source": "CRF", "title": "Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide Marker Discovery", "authors": ["Thomas Schlegl", "Philipp Seeb\u00f6ck", "Sebastian M. Waldstein", "Ursula Schmidt-Erfurth", "Georg Langs"], "emails": ["thomas.schlegl@meduniwien.ac.at"], "sections": [{"heading": "1 Introduction", "text": "This year, it is closer than ever before in the history of the country."}, {"heading": "2 Generative Adversarial Representation Learning to Identify Anomalies", "text": "To identify anomalies, we learn a model that represents normal anatomical variability based on GANs [13]. This method trains a generative model and discriminator to distinguish between generated and real data at the same time (see Figure 2 (a)). Instead of a single cost function optimization, it aims at the Nash cost equilibrium, increasing the representativity and specificity of the generative model, while becoming more precise in classifying real-from-generated data and improving the corresponding feature sketch. Below, we explain how to build this model (Section 2.1) and how to use it to identify the appearance that is not present in the training data (Sections 2.2 and 2.3)."}, {"heading": "2.1 Unsupervised Manifold Learning of Normal Anatomical Variability", "text": "We get a set of M medical images showing a healthy anatomy, with m = 1, 2,.., M, where Im-Ra \u00b7 b is an intensity image of size a \u00b7 b. From each image Im we extract K 2D image discrimination xk, m of size c \u00b7 c from randomly sampled positions leading to data x = xk, m \u00b2 X, with k = 1, 2,.., K. During the training we only get < Im > and train a generative adversarial model to learn the manifold X (blue region in Figure 2 (b)), which represents the variability of the training images, in an unattended manner. For testing we will < yn, ln >, where yn invisible images of size c \u00b7 c are extracted from new test data J and ln \u00b2 a, which represent a universal ability."}, {"heading": "2.2 Mapping new Images to the Latent Space", "text": "When the training is complete, the generator has updated the mapping function G (z) = q 7 \u2192 x from latent spatial representations z to realistic (normal) images x. but GANs do not automatically produce the inverse mapping function \u00b5 (x) = x 7 \u2192 z for free discrimination. Latent space has smooth transitions [12], so scanning two pixels near the latent space produces two visually similar images. In the face of an image x, in which we find a point z in latent space corresponding to an image G (z), which is visually most similar to the image x and which is located on the manifold X plane. The degree of similarity of x and G depends on the extent to which the query image follows the data distribution used to form the generator. To find the best z, we start with the latent spatial distribution z1 from the latent spatial distribution Z and feed it into the generated image G (z1)."}, {"heading": "2.3 Detection of Anomalies", "text": "In the case of anomalous identification in new data, we evaluate the new query image x as a normal or anomalous image. Our loss function (equivalent (5)), which is used for mapping to the latent space, evaluates in each update image the compatibility of the generated images G (z\u03b3) with images seen during the adversarial training. Thus, an anomaly value expressing the fit of a query image x to the model of normal images can be derived directly from the query loss function (equivalent (5): A (x) = (1 \u2212 \u03bb) \u00b7 R (x) \u00b7 D (x), (6), in which the residual value R (x) and the discrimination value D (x) are defined by the residual loss LR (eg) and the discrimination loss LD (eg) at the last (fourth) update of the iteration of the mapping method to the latent space."}, {"heading": "3 Experiments", "text": "This year, it will be able to fix and fix the mentioned bugs."}, {"heading": "3.1 Results", "text": "The results show the general ability of people to understand themselves and the appropriateness of our approach in terms of susceptibility to disease. We report qualitative and quantitative results in terms of segmentation of people who are able to identify themselves. In the case of people who are able to identify themselves, it shows that they are people who are able to identify themselves, it shows that they are able to generate images that are visually similar to the images presented in the first row of people who are in the second row of people, but in the case of anomalous images and generated images, it shows the obvious intensity or structural differences (see Figure 3)."}, {"heading": "4 Conclusion", "text": "The results show that our approach is capable of detecting various known anomalies, such as retinal fluid and HRF, that have never been observed during training. Therefore, the model is expected to be able to detect new anomalies. While quantitative evaluation based on a subset of anomalies classes is limited, as false positives do not take into account new anomalies, the results show good sensitivity and the ability to segment anomalies. Discovery of anomalies on a scale allows data to be obtained for marker candidates that are subject to future review. Unlike previous work, we show that the use of residual loss alone provides good results for mapping image to latent space and a slight improvement in results can be achieved with the proposed adjustments."}], "references": [], "referenceMentions": [], "year": 2017, "abstractText": "Obtaining models that capture imaging markers relevant for<lb>disease progression and treatment monitoring is challenging. Models are<lb>typically based on large amounts of data with annotated examples of<lb>known markers aiming at automating detection. High annotation ef-<lb>fort and the limitation to a vocabulary of known markers limit the<lb>power of such approaches. Here, we perform unsupervised learning to<lb>identify anomalies in imaging data as candidates for markers. We pro-<lb>pose AnoGAN, a deep convolutional generative adversarial network to<lb>learn a manifold of normal anatomical variability, accompanying a novel<lb>anomaly scoring scheme based on the mapping from image space to a la-<lb>tent space. Applied to new data, the model labels anomalies, and scores<lb>image patches indicating their fit into the learned distribution. Results<lb>on optical coherence tomography images of the retina demonstrate that<lb>the approach correctly identifies anomalous images, such as images con-<lb>taining retinal fluid or hyperreflective foci.", "creator": "LaTeX with hyperref package"}}}