{"id": "1703.06045", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Mar-2017", "title": "Approximation Complexity of Maximum A Posteriori Inference in Sum-Product Networks", "abstract": "We discuss the computational complexity of approximating maximum a posteriori inference in sum-product networks. We first show NP-hardness in three-level trees by a reduction from maximum independent set; this implies non-approximability within a sublinear factor. We show that this is a tight bound, as we can find an approximation within a linear factor in three-level networks. We then show that in four-level trees it is NP-hard to approximate the problem within a factor $2^{f(n)}$ for any sublinear function $f$ of the size of the input $n$. Again, this is bound is tight, as we prove that the usual max-product algorithm finds (in any network) approximations within factor $2^{c n}$ from some constant $c &lt; 1$. Last, we present a simple algorithm, and show that it provably produces solutions at least as good as, and potentially much better than, the max-product algorithm.", "histories": [["v1", "Fri, 17 Mar 2017 15:00:03 GMT  (13kb)", "http://arxiv.org/abs/1703.06045v1", "14 pages"], ["v2", "Mon, 12 Jun 2017 21:52:38 GMT  (17kb)", "http://arxiv.org/abs/1703.06045v2", "18 pages"], ["v3", "Wed, 14 Jun 2017 17:30:18 GMT  (17kb)", "http://arxiv.org/abs/1703.06045v3", "18 pages"], ["v4", "Wed, 23 Aug 2017 16:44:28 GMT  (17kb)", "http://arxiv.org/abs/1703.06045v4", "18 pages"], ["v5", "Tue, 5 Sep 2017 14:15:44 GMT  (18kb)", "http://arxiv.org/abs/1703.06045v5", "18 pages"]], "COMMENTS": "14 pages", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["diarmaid conaty", "denis d mau\\'a", "cassio p de campos"], "accepted": false, "id": "1703.06045"}, "pdf": {"name": "1703.06045.pdf", "metadata": {"source": "CRF", "title": "Approximation Complexity of Maximum A Posteriori Inference in Sum-Product Networks", "authors": ["Denis Deratani Mau\u00e1"], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 170 3.06 045v 1 [cs.A I] 1 7M ar2 017"}, {"heading": "Approximation Complexity of", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Maximum A Posteriori Inference", "text": "in total product networks"}, {"heading": "Denis Deratani Maua\u0301", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Universidade de Sa\u0303o Paulo, Brazil", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Cassio P. de Campos", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Queen\u2019s University Belfast, UK", "text": "We will discuss the computational complexity of approximating the maximum a posteriori inference in sum product networks. First, we will show the np hardness in three-stage tree networks by reducing the maximum independent set; this implies approximation within a sublinear factor. We will show that this is a narrow limit, since we can find approximation within a linear factor in any three-stage network. Then, we will show that in four-stage tree networks it is np-heavy to solve the problem within a factor 2f (n) for each sublinear function f the size of the input. Again, this is narrowly limited, as we will prove that the usual max product algorithm (in any network) approximations within the factor 2cn from any constant c < 1. Finally, we will present a simple algorithm and show that solutions are demonstrably at least as good and potentially much better than the max product algorithm."}, {"heading": "1 Introduction", "text": "In fact, most of them will be able to play by the rules they had in the past, and they will be able to play by the rules that were in place in the past."}, {"heading": "2 Sum-Product Networks", "text": "We use uppercase letters without specifying random vectors (e.g. X) and uppercase letters with subscriptions to designate random variables (e.g. X1). If X is a random vector, we call the sentence X, which consists of the random variables Xi in its scope. The scope of a function of a random vector is the scope of the respective random vector. In this thesis, we consider our discussion of random variables with finite domains; this was achieved by implying properties of consistency and completeness. This definition is more similar to Darwin's arithmetic circuits, which represent the network polynomially of a Bayesian network [4], and allow conclusions about the size of the circuits."}, {"heading": "3 Complexity Results", "text": "As we show in this section, there is a strong link between the height of a spn and the complexity of the map conclusions. First, it should be noted that a spn of height 0 is only a marginal distribution. Thus, we consider a spn of height 1. If the root is then a sum node, then the network encodes a sum of universal distributions (using the same variable), and the map can be solved trivially by enumerating all the values of this variable. If, on the other hand, the root is a product node, then the network encodes a distribution of completely independent variables. Again, we can easily solve the map by optimizing independently for each variable. So, the map in networks of height 1 is solvable in polynomial time.Let us now consider spns of height 2, as discussed in the introduction, Peharz et al. [10] briefly observes that the map problem is np-hard even for treetop networks of height 2."}, {"heading": "4 Conclusion", "text": "We first analyzed the complexity of the maximum a posteriori inference in sum product networks and showed that it is related to the height of the underlying graph. First, we provided an alternative (and more direct) proof of the np hardness of the maximum a posteriori inference in sum product networks. Our proof used a reduction of the maximum independent set in undirected graphs, from which we obtained the non-approximation for each sublinear factor in the size of the input, even in networks of height 2. We then showed that this limit is narrow, i.e. there is a polynomial time algorithm that produces solutions that are at most a linear factor for networks of height 2. We also showed that in networks of height 3 or more the complexity of the approximation increases considerably: There is no approximation within a factor 2f (n), for each sublinear function f of the input size n. This is also a narrow limit, as we have shown that the product algorithm of a max-2 factor within a product is an algorithm of a typical domino-13."}, {"heading": "Acknowledgements", "text": "The first author received financial support from the Sa'o Paulo Research Foundation (FAPESP) Grant # 2016 / 01055-1 and CNPq Scholarship PQ # 303920 / 2016-5."}], "references": [{"title": "Sum product networks for activity recognition", "author": ["M.R. Amer", "S. Todorovic"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2016}, {"title": "The complexity of weighted and unweighted #CSP", "author": ["A. Bulatov", "M. Dyer", "L.A. Goldberg", "M. Jalsenius", "M. Jerrum", "D. Richerby"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "Language modeling with sum-product networks", "author": ["W.-C. Cheng", "S. Kok", "H.V. Pham", "H.L. Chieu", "K.M.A. Chai"], "venue": "In Proceedings of the 15th Annual Conference of the International Speech Communication Association,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2014}, {"title": "A differential approach to inference in bayesian networks", "author": ["A. Darwiche"], "venue": "Journal of the ACM,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2003}, {"title": "Modeling and Reasoning with Bayesian Networks", "author": ["A. Darwiche"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2009}, {"title": "New complexity results for MAP in bayesian networks", "author": ["C.P. de Campos"], "venue": "In Proceedings of the Twenty-Second International Joint Conference on Artificial Intelligence,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2011}, {"title": "Learning the structure of sum-product networks", "author": ["R. Gens", "P. Domings"], "venue": "In Proceedings of 30th International Conferecen on Machine Learning,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2013}, {"title": "Learning tractable probabilistic models for fault localization", "author": ["A. Nath", "P. Domingos"], "venue": "In Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2016}, {"title": "Foundations of sum-product networks for probabilistic modeling", "author": ["R. Peharz"], "venue": "PhD thesis,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2015}, {"title": "On the latent variable interpretation in sum-product networks", "author": ["R. Peharz", "R. Gens", "F. Pernkopf", "P. Domingos"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2016}, {"title": "Modeling speech with sumproduct networks: Application to bandwidth extension", "author": ["R. Peharz", "G. Kapeller", "P. Mowlaee", "F. Pernkopf"], "venue": "In IEEE International Conference on Acoustics, Speech and Signal Processing,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "On theoretical properties of sum-product networks", "author": ["R. Peharz", "S. Tschiatschek", "F. Pernkopf", "P. Domingos"], "venue": "In Proceedings of the 18th International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2015}, {"title": "Sum-product networks: A new deep architecture", "author": ["H. Poon", "P. Domingos"], "venue": "In Proceedings of 27th Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2011}, {"title": "Learning sum-product networks with direct and indirect variable interactions", "author": ["A. Rooshenas", "D. Lowd"], "venue": "In Proceedings of the 31st International Conference on Machine Learning,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "Simplifying, regularizing and strengthening sum-product network structure learning", "author": ["A. Vergari", "N.D. Mauro", "F. Esposito"], "venue": "In Proocedings of the European Converence on Machine Learning and Knowledge Discovery in Databases,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2015}, {"title": "On the relationship between sum-product networks and bayesian networks", "author": ["H. Zhao", "M. Melibari", "P. Poupart"], "venue": "In Proceedings of the 32nd International Conference on Machine Learning,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2015}, {"title": "Linear degree extractors and the inapproximability of max clique and chromatic number", "author": ["D. Zuckerman"], "venue": "Theory of Computing,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2007}], "referenceMentions": [{"referenceID": 12, "context": "Sum-Product Networks (spns) are a relatively new class of graphical models that allow marginal inference in linear time in their size [13].", "startOffset": 134, "endOffset": 138}, {"referenceID": 4, "context": "This is therefore in sharp difference with other graphical models such as Bayesian networks and Markov Random Fields that require #p-hard effort to produce marginal inference [5].", "startOffset": 175, "endOffset": 178}, {"referenceID": 3, "context": "an arithmetic circuit whose evaluation produces a marginal inference [4].", "startOffset": 69, "endOffset": 72}, {"referenceID": 12, "context": "spns have received increasing popularity in applications of machine learning due to their ability to represent complex and highly multidimensional distributions [13, 11, 3, 8, 1].", "startOffset": 161, "endOffset": 178}, {"referenceID": 10, "context": "spns have received increasing popularity in applications of machine learning due to their ability to represent complex and highly multidimensional distributions [13, 11, 3, 8, 1].", "startOffset": 161, "endOffset": 178}, {"referenceID": 2, "context": "spns have received increasing popularity in applications of machine learning due to their ability to represent complex and highly multidimensional distributions [13, 11, 3, 8, 1].", "startOffset": 161, "endOffset": 178}, {"referenceID": 7, "context": "spns have received increasing popularity in applications of machine learning due to their ability to represent complex and highly multidimensional distributions [13, 11, 3, 8, 1].", "startOffset": 161, "endOffset": 178}, {"referenceID": 0, "context": "spns have received increasing popularity in applications of machine learning due to their ability to represent complex and highly multidimensional distributions [13, 11, 3, 8, 1].", "startOffset": 161, "endOffset": 178}, {"referenceID": 9, "context": "[10] noted that np-hardness can be proved by transforming a Bayesian network with a Naive Bayes structure into a distribution-equivalent spn of height two (this is done by adding a sum node to represent the latent root variable and its marginal distribution and product nodes as children to represent the conditional distributions).", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "As map inference in the former is np-hard [6], the result follows.", "startOffset": 42, "endOffset": 45}, {"referenceID": 12, "context": "This a tight bound, as we show that the usual max-product algorithm by Poon and Domingos [13], which replaces sums with maximizations, finds an approximation within a factor 2c\u00b7n for some constant c < 1.", "startOffset": 89, "endOffset": 93}, {"referenceID": 12, "context": "Poon and Domingos [13] originally defined spns as multilinear functions of indicator variables that allow for space and time efficient representation and inference.", "startOffset": 18, "endOffset": 22}, {"referenceID": 3, "context": "This definition more closely resembles Darwiche\u2019s arithmetic circuits which represent the network polynomial of a Bayesian network [4], and also allow inference in the size of the circuit.", "startOffset": 131, "endOffset": 134}, {"referenceID": 6, "context": "Later, Gens and Domingos [7] re-stated spns as complex mixture distributions as follows.", "startOffset": 25, "endOffset": 28}, {"referenceID": 8, "context": "This alternative definition (called generalized spns by Peharz [9]) implies decomposability, a stricter requirement than consistency.", "startOffset": 63, "endOffset": 66}, {"referenceID": 11, "context": "[12] showed that any consistent spn over discrete random variables can be transformed in an equivalent decomposable spn with a polynomial increase in size, and that weighted sums can be restricted to convex combinations without loss of expressivity.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "A similar result was obtained by Zhao, Melibari and Poupart [16].", "startOffset": 60, "endOffset": 64}, {"referenceID": 13, "context": ", Chow-Liu trees) [14, 15].", "startOffset": 18, "endOffset": 26}, {"referenceID": 14, "context": ", Chow-Liu trees) [14, 15].", "startOffset": 18, "endOffset": 26}, {"referenceID": 9, "context": "[10] recently showed that map is tractable in selective spns.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "[10] briefly observed that the map problem is np-hard even for tree-shaped networks of height 2.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[17]): Given an undirected graph G = (V,E) with vertices {1, .", "startOffset": 0, "endOffset": 4}, {"referenceID": 1, "context": "The proof of Theorem 1 encodes a maximum independent set problem and the reduction is a weighted reduction (see Definition 1 in [2]), which is sufficient to prove the result.", "startOffset": 128, "endOffset": 131}, {"referenceID": 16, "context": "We know that there is no n\u03b5-approximation for maximum independent set with 0 \u2264 \u03b5 < 1 unless p equals np [17], so the result follows.", "startOffset": 104, "endOffset": 108}, {"referenceID": 12, "context": "Note that this is the same value returned by the max-product algorithm by Poon and Domingos [13].", "startOffset": 92, "endOffset": 96}, {"referenceID": 12, "context": "If S(e) > 0, then take the max-product algorithm by Poon and Domingos [13], which replaces sums by maximizations in the evaluation of an spn.", "startOffset": 70, "endOffset": 74}, {"referenceID": 12, "context": "The previous result shows that the max-product algorithm by Poon and Domingos [13] achieves tight upper bounds on the approximation factor.", "startOffset": 78, "endOffset": 82}, {"referenceID": 0, "context": "Xi [0, 1] Xi [1, 0] Xi [1, 0] Xi [1, 0] 5/16 11/48 11/48 11/48", "startOffset": 3, "endOffset": 9}, {"referenceID": 0, "context": "Xi [0, 1] Xi [1, 0] Xi [1, 0] Xi [1, 0] 5/16 11/48 11/48 11/48", "startOffset": 13, "endOffset": 19}, {"referenceID": 0, "context": "Xi [0, 1] Xi [1, 0] Xi [1, 0] Xi [1, 0] 5/16 11/48 11/48 11/48", "startOffset": 23, "endOffset": 29}, {"referenceID": 0, "context": "Xi [0, 1] Xi [1, 0] Xi [1, 0] Xi [1, 0] 5/16 11/48 11/48 11/48", "startOffset": 33, "endOffset": 39}, {"referenceID": 12, "context": "This is also tight lower bound, as we showed that the usual max-product algorithm by Poon and Domingos [13] finds an approximation within factor 2c\u00b7n for some constant c < 1.", "startOffset": 103, "endOffset": 107}], "year": 2017, "abstractText": "We discuss the computational complexity of approximating maximum a posteriori inference in sum-product networks. We first show np-hardness in three-level tree networks by a reduction from maximum independent set; this implies non-approximability within a sublinear factor. We show that this is a tight bound, as we can find an approximation within a linear factor in any three-level networks. We then show that in four-level tree networks it is np-hard to approximate the problem within a factor 2f(n) for any sublinear function f of the size of the input n. Again, this is bound is tight, as we prove that the usual max-product algorithm finds (in any network) approximations within factor 2cn from some constant c < 1. Last, we present a simple algorithm, and show that provably produces solutions at least as good as, and potentially much better, than the max-product algorithm.", "creator": "LaTeX with hyperref package"}}}