{"id": "1703.06076", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Mar-2017", "title": "Machine learning approach for early detection of autism by combining questionnaire and home video screening", "abstract": "Existing screening tools for early detection of autism are expensive, cumbersome, time-intensive, and sometimes fall short in predictive value. In this work, we apply Machine Learning (ML) to gold standard clinical data obtained across thousands of children at risk for autism spectrum disorders to create a low-cost, quick, and easy to apply autism screening tool that performs as well or better than most widely used standardized instruments. This new tool combines two screening methods into a single assessment, one based on short, structured parent-report questionnaires and the other on tagging key behaviors from short, semi-structured home videos of children. To overcome the scarcity, sparsity, and imbalance of training data, we apply creative feature selection, feature engineering, and novel feature encoding techniques. We allow for inconclusive determination where appropriate in order to boost screening accuracy when conclusive. We demonstrate a significant accuracy improvement over standard screening tools in a clinical study sample of 162 children.", "histories": [["v1", "Wed, 15 Mar 2017 22:37:41 GMT  (4772kb,D)", "http://arxiv.org/abs/1703.06076v1", null]], "reviews": [], "SUBJECTS": "cs.CY cs.LG", "authors": ["halim abbas", "ford garberson", "eric glover", "dennis p wall"], "accepted": false, "id": "1703.06076"}, "pdf": {"name": "1703.06076.pdf", "metadata": {"source": "CRF", "title": "Machine learning approach for early detection of autism by combining questionnaire and home video screening", "authors": ["Halim Abbas", "Ford Garberson", "Eric Glover", "Dennis P Wall"], "emails": ["g@ericglover.com"], "sections": [{"heading": null, "text": "Existing screening tools for early detection of autism are expensive, cumbersome, time-consuming, and sometimes inadequate in terms of predictive value. In this work, we apply machine learning (ML) to gold standard clinical data collected from thousands of children at risk of autism spectrum disorders to develop a low-cost, fast, and easy-to-use autism screening tool that works as well or better than the most widely used standardized tools. This new tool combines two screening methods into a single assessment, one based on short, structured parent report questionnaires, and the other based on identifying important behaviors from children's short, semi-structured home videos. To overcome the scarcity, scarcity, and imbalance of training data, we apply creative feature selection, feature engineering, and novel feature coding techniques."}, {"heading": "1 Introduction", "text": "This year, it will take only one year to be able to find a solution that adapts to the needs of the people."}, {"heading": "2 Data", "text": "The training data was compiled from several ADOS and ADI-R datasheets of boys and girls ages 18 to 84 months, including the Boston Autism Consortium, the Autism Genetic Resource Exchange, the Autism Treatment Network, the Simons Simplex Collection, and the Vanderbilt Medical Complex. Because these datasheets are highly unbalanced in terms of prevalence of autism, the data sets included ADI-R interviews with a sample of children classified as low for autism by the Cognoa user base, and the clinical validation sample consisted of 230 children who presented at one of three autism centers in the United States, ranging in age from 18 to 72 months. Each child received an ADOS and standard screens such as M-CHAT and CBCL, and a diagnosis was ultimately determined by a licensed psychologist, a sample that corresponds to a clinical study conducted by Kanetal.8 in 2016."}, {"heading": "3 Approach", "text": "We trained two independent ML classifiers and combined their results into a single screening evaluation; the parent questionnaire classifier was trained using data from historical item-level ADI-R scoring tables that are consistent with established clinical diagnoses; the video classifier was trained using ADOS instrument scoring tables and diagnostic labels; in each case, progressive sampling was used to verify a sufficient volume of training as described in Appendix A. The ADI-R and ADOS instruments are designed to be administered by trained professionals in highly standardized clinical environments and typically take hours; in contrast, our screening methods are deliberately designed to be administered by parents without expert supervision at home and take only minutes."}, {"heading": "3.1 Parent questionnaire", "text": "The following are several model variants that represent incremental improvements over a generic ML classification approach; each model has been parameterized independently using a bootstrapped grid search; class names have been used to stratify the cross-validation folds; and (age, label) pairs have been used to weight the samples."}, {"heading": "3.1.1 Generic ML baseline variant", "text": "Each of the instrument's 155 columns was treated as a categorical variable and encoded uniquely. Age and gender of the subject were also included as characteristics, and from the resulting sets of characteristics, the 20 best were selected based on the ranking of characteristics in the decision forest."}, {"heading": "3.1.2 Robust feature selection variant", "text": "Due to the small size and sparseness of the training dataset, generic feature selection across hundreds of binary features was not robust, and the selected features (along with the performance of the resulting model) varied from run to run due to the stochastic nature of the learner's underlying packaging approach. Many ADI-R questions are highly correlated, resulting in several competing feature selections that appeared to perform equally well during training, but exhibited different performance characteristics when the underlying scanning bias was subjected to full bootstrapped cross validation, resulting in a wide range of performance of the variant in Section 3.1.1, as in Table 3.Robust feature selection overcame this limitation using a two-step approach. First, a 100-point bootstrapped feature selection was performed, with a weighted 90% sample selected in each iteration."}, {"heading": "3.1.3 Age silo variant", "text": "This variant built on the improvements made in Section 3.1.2 by exploiting the importance of the dichotomy between prephrasal and full-phrasal language skills in at-risk children. Language development is important in this area because it is known to influence the nature in which autism occurs, and thus the types of behavioral cues that need to be looked for to test them. This variant performed better by providing separate classifiers for children in the younger and older age groups in Table 1. The age dichotomy of < 4, \u2265 4 was selected to serve as the best substitute for language skills. Characteristics selection, model parameter setting and cross-validation were performed independently for each age group classifier. Prior to sitting by age group, the classifier was limited to features that work well in children at both developmental stages. Silosis enabled the classifiers to specialize in features that are most developmental within each age group."}, {"heading": "3.1.4 Severity-level feature encoding variant", "text": "Building on Section 3.1.3, this variant achieves better performance by replacing unilateral encoding with a more context-sensitive technique. Unilateral encoding does not distinguish between values that correspond to the increasing severity of a behavioral symptom and values that do not convey a clear concept of severity, which is particularly troubling because a typical ADI-R instrument question involves selecting answers from both types of values. For example, ADI-R question 37, which focuses on the child's propensity to confuse and confuse pronouns, allows response codes 0,1,2,3,7,8 and 9. Among these decisions, 0 to 3 indicate increasing severity of the severity of the confusion, while 7 refers to any other type of pronouns confusion that is not covered in 0-3, regardless of severity. Codes 8 and 9 indicate the inapplicability of the question (for example, a child who is not yet able to pronouns)."}, {"heading": "3.1.5 Aggregate features variant", "text": "Building on Section 3.1.4, this variant performed better by incorporating aggregated features such as the minimum, maximum and average severity, as well as the number of severity responses in the questions corresponding to the 20 selected features 3 / 11. These new features were particularly useful because of the sparse, flat and wide nature of the training set, any semantically meaningful condensation of the signal can be useful to the trained classifier. Summing up the severity responses is a method used by specialists administering the ADI-R instrument in real life, and is therefore known as semantic benefit."}, {"heading": "3.1.6 Inconclusive results variant", "text": "Patients with more complex symptoms are known to pose a challenge to developmental screening. Because our cost-effective tools for distinguishing complex symptom cases are not based on sophisticated observations, our approach was not to evaluate them as a whole, but instead to try to identify and label them as \"inconclusive.\" Building on 3.1.5, two methods were developed to implement this strategy: The first was to train a binary classifier with a continuous output score, then replace the cutoff threshold with a cutoff range, with values within the cutoff range considered inconclusive. To determine the optimal cutoff range, which represents a compromise between inconclusive determination rate and accuracy compared to conclusive subjects, the second approach was to train and cross a simple binary classifier, to label the samples as conclusive or inconclusive, and then to classify the second method as classifying to classify the second results."}, {"heading": "3.2 Video", "text": "The second of our two methods for early detection of autism is an ML classifier, which uses input responses about the presence and severity of the subject's target behavior, which analysts provide after watching two or three 1-minute home videos of children in semi-structured environments recorded by parents on their mobile phones; the classifier was trained using item-level data from two of the ADOS modules (Module 1: preverbal, Module 2: phrased language) and corresponding clinical diagnoses; two Decision Forest ML classifiers were trained according to each ADOS module; for each classifier, 10 questions were selected using robust feature selection, as in Section 3.1.2, and taking into account the inconclusive results as in Section 3.1.6. Each model was tuned to a bootstrapped grid search regardless of parameters; class markers were used to stratify the cross-validation folds, and we expected to see less of the age and OS issues associated with the sampled pair."}, {"heading": "3.2.1 Presence of behavior encoding", "text": "In order to minimize the potential bias of a video analyst who misinterprets the severity of a symptom in a short cellular phone video, this coding scheme improves the reliability of the features at the expense of the content of the features by summarizing all gradations of the severity of a question into a binary value that represents the presence of the behavior or symptoms in question. Importantly, a value of 1 indicates the presence of a behavior, whether the behavior indicates autism or normality. This rule ensures that a value of 1 corresponds to reliable observation, while a value of 0 does not necessarily indicate the presence of a symptom, but may indicate the failure to observe the symptom within the short observation window."}, {"heading": "3.2.2 Missing value injection to balance the non presence of features for the video screener training data", "text": "For this reason, it is important that the learning algorithm treats a value of 1 as semantically significant and a value of 0 as insignificant. To achieve this, we4 / 11 expanded the training set to include duplicated samples, in which some characteristic values were reversed from 1 to 0. Injection of 0s was randomly performed with probabilities, so that the sample-weighted ratio of positive to negative samples, in which the value of a particular trait is about 50%, was randomly performed. Such ratios ensure that the trees in a random forest are much less likely to draw conclusions from the absence of a trait."}, {"heading": "3.3 Combination", "text": "Numerical responses to each parent questionnaire and the video classifiers were combined using logistic regression. As each of the methods was siloded, separate combinators were formed for each age group silo. Optimal, inconclusive output criteria were selected for each combinator, as discussed in Section 3.1.6. Performance characteristics of the entire screening process compared to conventional alternative screens are presented in Section 4.3."}, {"heading": "4 Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Parent questionnaire performance on training data", "text": "Bootstrapped cross-validation performance metrics for the optimally parameter tuned version of each of the variants in 3.1 are reported in Table 3. The results for the base variant 3.1.1 are given as a confidence interval and not as a single value, as the unreliability of the generic feature selection leads to different set of characteristics selected from run to run, with different performance results."}, {"heading": "4.2 Parent questionnaire performance on clinical data", "text": "Parents of children enrolled in the clinical trial responded to short, age-appropriate questionnaires selected according to the feature selection approach outlined in 3.1.2. Performance indicators for each of the classification variants based on this feature selection scheme are shown in Table 4.ROC curves in Figure 1 as our parent questionnaire classification approach outperforms some of the established screening tools such as MCHAT and CBCL in the clinical sample."}, {"heading": "4.3 Combination screening performance on clinical data", "text": "ROC curves in Figure 2 show how the combination of the questionnaire and the video classifiers in a single assessment further improved the performance of the clinical study participants. Figure 3 shows how an inconclusive determination of up to 25% of the time5 / 11 leads to a further improvement in accuracy over the final cases."}, {"heading": "5 Conclusion", "text": "Machine learning can play a very important role in improving the effectiveness of clinical screening. We have achieved a significant improvement over established screening tools for autism in young children, as demonstrated in a clinical trial. We have also identified some important pitfalls in the use of machine learning in a clinical setting and quantified the benefits of applying appropriate solutions to these problems.6 / 117 / 11"}, {"heading": "A Progressive sampling on training datasets", "text": "Progressive sampling runs were conducted to ensure that available training data was sufficient to create stable ML classifiers, which were performed for each classification variant for both the questionnaire and video-based training samples. In each run, the AUC metric of an optimized random reel trained over increasing portions of the training set was calculated, and the size of the training set proved sufficient for stable learning of ensemble decision trees as shown in the diagrams in Figure 4. A similar conclusion was drawn for the parental questionnaire classifiers for young and old children using similar progressive sampling runs of the appropriate training sets."}, {"heading": "B Differences between training and application environments", "text": "Since the classification labels used to train medical screening algorithms would have to come from professional medical diagnoses, it is not possible to accumulate large training sets that are class-balanced and sufficiently representative of the general population of children. Our approach is to start with historical medical tools from previously diagnosed subjects and use them as training data for screeners who rely on information outside the clinical setting. Since the algorithms are trained on characteristics gained during rigorous clinical evaluations but applied to data that represent proxies of these characteristics acquired in a less controlled environment, we expect the performance of classifiers to deteriorate significantly when used as mobile screeners. More specifically, Table 5 describes the various mechanisms by which confusing distortions can creep into application data in ways that are not present in training data."}, {"heading": "C Age binned results", "text": "The results for small and large children are shown separately in Figures 5 to 8.9 / 1110 / 1111 / 11."}], "references": [{"title": "Socioeconomic inequality in the prevalence of autism spectrum disorder: evidence from a U.S. cross-sectional study", "author": ["M Durkin"], "venue": "PloS One", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2010}, {"title": "Prevalence and characteristics of autism spectrum disorder among children aged 8 years \u2014 autism and developmental disabilities monitoring network, 11 sites", "author": ["D. Christensen", "J. Baio", "K Braun"], "venue": "United States,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "insights from studies of high-risk infants", "author": ["Zwaigenbaum", "L. et al. Clinical assessment", "management of toddlers with suspected autism spectrum disorder"], "venue": "Pediatrics 123, 1383\u20131391", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2009}, {"title": "Diagnosing autism spectrum disorders in primary care", "author": ["R. Bernier", "A. Mao", "J. Yen"], "venue": "Practitioner 255(1745),", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2011}, {"title": "Manual for the ASEBA preschool forms & profiles", "author": ["T. Achenbach", "L. Rescorla"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2000}, {"title": "Clinical evaluation of a novel and mobile autism risk assessment", "author": ["M. Duda", "J. Daniels", "D. Wall"], "venue": "J Autism Dev Disord", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2016}, {"title": "Evaluating a mobile-health screening tool for rapid identification of autism spectrum disorder risk in young children", "author": ["S. Kanne", "L. Carpenter", "Z. Warren"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2016}, {"title": "a revised version of a diagnostic interview for caregivers of individuals with possible pervasive developmental disorders", "author": ["C. Lord", "M. Rutter", "Le Couteur", "A. Autism diagnostic interview-revised"], "venue": "Journal of Autism and Developmental Disorders 24, 659\u2013685", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1994}, {"title": "a standardized observation of communicative and social behavior", "author": ["Lord", "C. et al. Autism diagnostic observation schedule"], "venue": "J Autism Dev Disord 19, 185\u2013212", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1989}, {"title": "A multisite study of the clinical diagnosis of different autism spectrum disorders", "author": ["C Lord"], "venue": "Archives of General Psychiatry", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2012}, {"title": "Use of artificial intelligence to shorten the behavioral diagnosis of autism", "author": ["D. Wall", "R. Dally", "R. Luyster", "J. Jung", "T. Deluca"], "venue": "PLoS One 7(8):e43855", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2012}, {"title": "The potential of accelerating early detection of autism through content analysis of YouTube videos", "author": ["V Fusaro"], "venue": "PLoS One 16;9(4):e93533", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Clinical evaluation of a novel and mobile autism risk assessment", "author": ["M. Duda", "J. Daniels", "D. Wall"], "venue": "Journal of autism developmental disorders", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2016}], "referenceMentions": [], "year": 2017, "abstractText": "Existing screening tools for early detection of autism are expensive, cumbersome, time-intensive, and sometimes fall short in predictive value. In this work, we apply Machine Learning (ML) to gold standard clinical data obtained across thousands of children at risk for autism spectrum disorders to create a low-cost, quick, and easy to apply autism screening tool that performs as well or better than most widely used standardized instruments. This new tool combines two screening methods into a single assessment, one based on short, structured parent-report questionnaires and the other on tagging key behaviors from short, semi-structured home videos of children. To overcome the scarcity, sparsity, and imbalance of training data, we apply creative feature selection, feature engineering, and novel feature encoding techniques. We allow for inconclusive determination where appropriate in order to boost screening accuracy when conclusive. We demonstrate a significant accuracy improvement over standard screening tools in a clinical study sample of 162 children.", "creator": "LaTeX with hyperref package"}}}