{"id": "1703.06207", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Mar-2017", "title": "Cooperating with Machines", "abstract": "Since Alan Turing envisioned Artificial Intelligence (AI) [1], a major driving force behind technical progress has been competition with human cognition. Historical milestones have been frequently associated with computers matching or outperforming humans in difficult cognitive tasks (e.g. face recognition [2], personality classification [3], driving cars [4], or playing video games [5]), or defeating humans in strategic zero-sum encounters (e.g. Chess [6], Checkers [7], Jeopardy! [8], Poker [9], or Go [10]). In contrast, less attention has been given to developing autonomous machines that establish mutually cooperative relationships with people who may not share the machine's preferences. A main challenge has been that human cooperation does not require sheer computational power, but rather relies on intuition [11], cultural norms [12], emotions and signals [13, 14, 15, 16], and pre-evolved dispositions toward cooperation [17], common-sense mechanisms that are difficult to encode in machines for arbitrary contexts. Here, we combine a state-of-the-art machine-learning algorithm with novel mechanisms for generating and acting on signals to produce a new learning algorithm that cooperates with people and other machines at levels that rival human cooperation in a variety of two-player repeated stochastic games. This is the first general-purpose algorithm that is capable, given a description of a previously unseen game environment, of learning to cooperate with people within short timescales in scenarios previously unanticipated by algorithm designers. This is achieved without complex opponent modeling or higher-order theories of mind, thus showing that flexible, fast, and general human-machine cooperation is computationally achievable using a non-trivial, but ultimately simple, set of algorithmic mechanisms.", "histories": [["v1", "Fri, 17 Mar 2017 21:50:16 GMT  (1428kb,D)", "http://arxiv.org/abs/1703.06207v1", null], ["v2", "Tue, 21 Mar 2017 14:26:33 GMT  (1428kb,D)", "http://arxiv.org/abs/1703.06207v2", null], ["v3", "Tue, 17 Oct 2017 01:04:09 GMT  (1428kb,D)", "http://arxiv.org/abs/1703.06207v3", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["jacob w crandall", "mayada oudah", "tennom", "fatimah ishowo-oloko", "sherief abdallah", "jean-fran\\c{c}ois bonnefon", "manuel cebrian", "azim shariff", "michael a goodrich", "iyad rahwan"], "accepted": false, "id": "1703.06207"}, "pdf": {"name": "1703.06207.pdf", "metadata": {"source": "CRF", "title": "Cooperating with Machines", "authors": ["Jacob W. Crandall", "Mayada Oudah", "Fatimah Ishowo-Oloko", "Sherief Abdallah", "Jean-Fran\u00e7ois Bonnefon", "Manuel Cebrian", "Azim Shariff", "Michael A. Goodrich", "Iyad Rahwan"], "emails": ["crandall@cs.byu.edu", "irahwan@mit.edu"], "sections": [{"heading": null, "text": "* Correspondence should be sent to crandall @ cs.byu.edu and irahwan @ mit.eduar Xiv: 170 3.06 207v 1 [cs]"}, {"heading": "1 Introduction", "text": "The emergence of driverless cars, autonomous trading algorithms, and autonomous drone technologies underscore a larger trend in which machines can autonomously perform complex tasks on behalf of their human counterparts. While the majority of AI milestones are focused on human development, most scenarios require interacting with humans and machines that are unable to cooperate with each other."}, {"heading": "2 Results", "text": "The primary contribution of this work is the development and analysis of a new learning system that combines a state-of-the-art machine learning algorithm with novel mechanisms for generating and responding to signals. By means of extensive simulations and user studies, we show that this learning system learns to build and maintain effective relationships with humans and other machines through a variety of repeated interactions at levels that compete with human cooperation, while also investigating the algorithmic mechanisms responsible for its success."}, {"heading": "2.1 Cooperating with People and Other Machines", "text": "In fact, the fact is that most people who are able to move, to move and to move, to move, to move, to move, to move and to move, to move, to move and to move, to move and to move, to move, to move and to move, to move and to move, to move and to move, to move and to move, to move and to move, to move and to move, to move and to move, to move and to move, to move and to move, to move and to move, to move and to move, to move, to move and to move."}, {"heading": "2.2 Distinguishing Algorithmic Mechanisms", "text": "Why is it so successful to forge cooperative relationships with people and other algorithms? Are their algorithmic mechanisms fundamentally different from those of other algorithms for repetitive games? We have identified three algorithmic mechanisms that are responsible for the success of S # s. Clearly, Figure 2 shows that the first of these mechanisms is the ability to generate and respond to relevant signals that people can understand, a trait that is not present in previous learning algorithms designed for repetitive interactions. These signal capabilities extend S # s flexibility, which they also consistently transform into cooperative relationships with people. Figure 3 shows a simple reason why this mechanism is so important: Signals help both S # and people experience mutual cooperation with their partners more quickly."}, {"heading": "2.3 Repeated Stochastic Games", "text": "However, S + + is again distinguished in these games by its ability to adapt to many different machine colleagues in a variety of different scenarios [27]. As in normal form games, S + + can be supplemented by cheap talk to form S #. While S + + does not consistently establish effective relationships with people in these more complex scenarios, our results show that S # does. Representative results are shown in Figure 4, where a spin scenario is considered in which two players must learn how to split a series of blocks. Like humans, S # uses cheap talk to substantially increase its payouts in conjunction with other people in this game (Figure 4b). These results mirror those we observe in normal form games (compare Figure 4b and 2b). See YOU for more results and details."}, {"heading": "3 Discussion", "text": "Our studies on human-machine partnerships were limited to five repetitive games that were carefully selected to represent different classes of games from the periodic table of games (see SI.A.3). Although future work should take into account more scenarios, S # s success in building cooperative relationships with humans in these representative games, along with its consistently high performance in all classes of 2x2 games and various repetitive stochastic games [27] in conjunction with other algorithms, gives us some confidence that these results will extend to many other scenarios. Since Alan Turing envisaged artificial intelligence, important milestones have focused on defeating humans in zero-sum encounters [6, 7, 8, 9, 10]. However, in many scenarios, successful machines must cooperate with humans and other machines rather than compete with each other, even amid conflicting interests and threats, to be exploited. Our work shows how learning autonomous machines can create cooperative relationships with humans, but ultimately having significant interactions with other machines in multiple ways."}, {"heading": "4 Methods", "text": "In this section, we present three different aspects of these methods and analyses: the benchmark of games used to compare algorithms and humans, the results of our comparison of AI algorithms, and a description of S #."}, {"heading": "4.1 Benchmark Games for Studying Cooperation", "text": "As with all historical major challenges in AI, it is important to identify a class of benchmark problems in order to compare the performance of different algorithms. When it comes to human collaboration, a basic benchmark is 2 \u00d7 2, general sums, repeated games [28]. This class has been a workhorse in behavioral economics [29], mathematical biology [30], psychology [32], sociology [33], and political science [34] for decades. These areas have revealed many aspects of human cooperative behavior through canonical games, such as the Prisoner Dilemmas, Chicken, Battle of the Sexes, and the Stag Hunt. Such games therefore provide a well-established, well-researched, and widely understood benchmark for studying the capabilities of machines to develop cooperative relationships."}, {"heading": "4.2 Interacting with Other Machines: AI Algorithms for Repeated Interactions", "text": "In order to identify successful algorithmic mechanisms for playing arbitrary repetitive games, we selected and evaluated 25 existing algorithms (see Figure 6a) in relation to six different performance indicators (see SI.B.2) within the periodic table of 2x2 games. These representative algorithms included classic algorithms such as (generalized) generous tit-for-tat (i.e. GODFATHER) and win-stay-lose-shift (WSLS) [39], evolutionary memory-one and memory-two stochastics strategies [40], machine-learning algorithms (including enhancement of learning), belief-based algorithms [41] and expert algorithms [42, 43]. The results of this evaluation are summarized in Figure 6a. Detailed analyses are provided in SI.B. We make two high-level observations: First, it is interesting to observe which algorithms were less successful in these evaluations."}, {"heading": "4.3 S#: A Machine-Learning Algorithm that Talks", "text": "S # is derived from S + + [43], an expert algorithm that combines different expert groups and builds on decades of research in computer science, economics, and behavioral and social sciences. S + + uses the description of the game environment to calculate different expert groups, each of which uses different mathematics and assumptions to produce a strategy across the entire space of the game. S + + then uses a meta-level control strategy based on the pursuit of learning ability [44, 45, 46] to dynamically reduce this expert group. Formally, E considers the expert group calculated by S + +. In each epoch (starting with round t), S + + calculates the potential risk calculation of each expert ej (t) and compares this potential with its aspiration level \u03b1 (t) to form a reduced group of experts. E (t) ofexperts: E (t) of experts: E (qut) {queer experts: ej: ej @: E @ adt (E @)."}], "references": [{"title": "Computing machinery and intelligence", "author": ["A.M. Turing"], "venue": "Mind, pages 433\u2013460", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1950}, {"title": "Face recognition algorithms surpass humans matching faces over changes in illumination", "author": ["A.J. Toole", "P.J. Phillips", "F. Jiang", "J. Ayyad", "N. Penard", "H. Abdi"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on, 29(9):1642\u20131646", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2007}, {"title": "Computer-based personality judgments are more accurate than those made by humans", "author": ["W. Youyou", "M. Kosinski", "D. Stillwell"], "venue": "Proceedings of the National Academy of Sciences, 112(4):1036\u20131040", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}, {"title": "Junior: The Stanford entry in the urban challenge", "author": ["M. Montemerlo", "J. Becker", "S. Bhat", "H. Dahlkamp", "D. Dolgov", "S. Ettinger", "D. Haehnel", "T. Hilden", "G. Hoffmann", "B. Huhnke", "D. Johnston", "S. Klumpp", "D. Langer", "A. Levandowski", "J. Levinson", "J. Marcil", "D. Orenstein", "J. Paefgen", "I. Penny", "A. Petrovskaya", "M. Pflueger", "G. Stanek", "D. Stavens", "A. Vogt", "S. Thrun"], "venue": "Journal of Field Robotics, 25(9):569\u2013597", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2008}, {"title": "et al", "author": ["V. Mnih", "K. Kavukcuoglu", "D. Silver", "A.A. Rusu", "J. Veness", "M.G. Bellemare", "A. Graves", "M. Riedmiller", "A.K. Fidjeland", "G. Ostrovski"], "venue": "Human-level control through deep reinforcement learning. Nature, 518(7540):529\u2013533", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep blue", "author": ["M. Campbell", "A.J. Hoane", "F. Hsu"], "venue": "Artificial intelligence, 134(1):57\u201383", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2002}, {"title": "Checkers is solved", "author": ["J. Schaeffer", "N. Burch", "Y. Bj\u00f6rnsson", "A. Kishimoto", "M. M\u00fcller", "R. Lake", "P. Lu", "S. Sutphen"], "venue": "Science, 317(5844):1518\u20131522", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2007}, {"title": "et al", "author": ["D. Ferrucci", "E. Brown", "J. Chu-Carroll", "J. Fan", "D. Gondek", "A.A. Kalyanpur", "A. Lally", "J.W. Murdock", "E. Nyberg", "J. Prager"], "venue": "Building Watson: An overview of the DeepQA project. AI Magazine, 31(3):59\u201379", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2010}, {"title": "Heads-up limit holdem poker is solved", "author": ["M. Bowling", "N. Burch", "M. Johanson", "O. Tammelin"], "venue": "Science, 347(6218):145\u2013149", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2015}, {"title": "G", "author": ["D. Silver", "A. Huang", "C.J. Maddison", "A. Guez", "L. Sifre"], "venue": "van den Driessche, J. Schrittwieser, I. Angonoglou, V. Panneershelvam, M. Lanctot, S. Dieleman, D. Grewe, J. Nham, N. Kalchbrenner, I. Sutskever, T. Lillicrap, M. Leach, K. Kavukcuoglu, T. Graepel, and D. Hassabis. Mastering the game of Go with deep neural networks and tree search. Nature, 529:484\u2013489", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2016}, {"title": "Social heuristics shape intuitive cooperation", "author": ["D.G. Rand", "A. Peysakhovich", "G.T. Kraft-Todd", "G.E. Newman", "O. Wurzbacher", "M.A. Nowak", "J.D. Greene"], "venue": "Nature Communications, 5", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2014}, {"title": "Culture and the evolution of human cooperation", "author": ["R. Boyd", "P.J. Richerson"], "venue": "Philosophical Transactions of the Royal Society B: Biological Sciences, 364", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1533}, {"title": "Passions Within Reason: The Strategic Role of the Emotions", "author": ["R.H. Frank"], "venue": "W. W. Norton & Company", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1988}, {"title": "The Stag Hunt and the Evolution of Social Structure", "author": ["B. Skyrms"], "venue": "Cambridge Press", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2003}, {"title": "Conversation and cooperation in social dilemmas a meta-analysis of experiments from 1958 to 1992", "author": ["D. Sally"], "venue": "Rationality and society, 7(1):58\u201392", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1995}, {"title": "Communication and cooperation in social dilemmas: A meta-analytic review", "author": ["D. Balliet"], "venue": "Rationality and society, 54(1):39?57", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2009}, {"title": "Humans display a cooperative phenotype that is domain general and temporally stable", "author": ["A. Peysakhovich", "M. A Nowak", "D.G. Rand"], "venue": "Nature Communications, 5", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2014}, {"title": "Common ground and coordination in joint activity", "author": ["G. Klein", "P.J. Feltovich", "J.M. Bradshaw", "D.D. Woods"], "venue": "Organizational simulation, 53", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2005}, {"title": "Socially intelligent robots: Dimensions of human\u2013robot interaction", "author": ["K. Dautenhahn"], "venue": "Philosophical Transactions of the Royal Society B: Biological Sciences, 362", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1480}, {"title": "Toward sociable robots", "author": ["C. Breazeal"], "venue": "Robotics and autonomous systems, 42(3):167\u2013175", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2003}, {"title": "Modeling information exchange opportunities for effective human\u2013 computer teamwork", "author": ["E. Kamar", "Y. Gal", "B.J. Grosz"], "venue": "Artificial Intelligence, 195:528\u2013550", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2013}, {"title": "Gambling in a rigged casino: the adversarial multi-armed bandit problem", "author": ["P. Auer", "N. Cesa-Bianchi", "Y. Freund", "R.E. Schapire"], "venue": "Proceedings of the 36th Symposium on the Foundations of Computer Science, pages 322\u2013331", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1995}, {"title": "Convergence and no-regret in multiagent learning", "author": ["M. Bowling"], "venue": "Advances in Neural Information Processing Systems 17, pages 209\u2013216", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2004}, {"title": "A decision-theoretic generalization of on-line learning and an application to boosting", "author": ["Y. Freund", "R.E. Schapire"], "venue": "Proceedings of the 2nd European Conference on Computational Learning Theory, pages 23\u201337", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1995}, {"title": "The evolution of representation in simple cognitive networks", "author": ["L. Marstaller", "A. Hintze", "C. Adami"], "venue": "Neural Computation, 25:2079\u20132107", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2013}, {"title": "Recognition-primed decisions", "author": ["G. Klein"], "venue": "W. B. Rouse, editor, Advances in man-machine systems research, volume 5, pages 47\u201392. Greenwhich, CT: JAI Press", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1989}, {"title": "Robust learning in repeated stochastic games using meta-gaming", "author": ["J.W. Crandall"], "venue": "Proceedings of the International Joint Conference on Artificial Intelligence", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2015}, {"title": "A Taxonomy of 2x2 Games", "author": ["A. Rapoport", "M.J. Guyer"], "venue": "Bobbs-Merrill", "citeRegEx": "28", "shortCiteRegEx": null, "year": 1967}, {"title": "Behavioral game theory", "author": ["Colin Camerer"], "venue": "New Age International,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2010}, {"title": "Evolutionary games and population dynamics", "author": ["Josef Hofbauer", "Karl Sigmund"], "venue": "Cambridge university press,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 1998}, {"title": "Human cooperation", "author": ["D.G. Rand", "M.A. Nowak"], "venue": "Trends in Cognitive Sciences, 17(8):413\u2013425", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2013}, {"title": "Social dilemmas: The anatomy of cooperation", "author": ["Peter Kollock"], "venue": "Annual review of sociology,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 1998}, {"title": "A polynomial-time Nash equilibrium algorithm for repeated games", "author": ["M.L. Littman", "P. Stone"], "venue": "Decision Support Systems, 39:55\u201366", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2005}, {"title": "The Evolution of Cooperation", "author": ["R. Axelrod"], "venue": "Basic Books, New York", "citeRegEx": "34", "shortCiteRegEx": null, "year": 1984}, {"title": "The 2x2 Game", "author": ["A. Rapoport", "M.J. Guyer", "D.G. Gordon"], "venue": "The University of Michigan Press", "citeRegEx": "35", "shortCiteRegEx": null, "year": 1976}, {"title": "A Theory of Moves", "author": ["S.J. Brams"], "venue": "Cambridge University Press", "citeRegEx": "36", "shortCiteRegEx": null, "year": 1994}, {"title": "The Topology of the 2x2 Games: A New Period Table", "author": ["D. Robinson", "D. Goforth"], "venue": "Routledge", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2005}, {"title": "Navigating the topology of 2x2 games: An introductory note on payoff families", "author": ["B. Bruns"], "venue": "normalization, and natural order. CoRR, abs/1010.4727", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2010}, {"title": "A strategy of win-stay", "author": ["M. Nowak", "K. Sigmund"], "venue": "lose-shift that outperforms tit-for-tat in the prisoner\u2019s dilemma game. Nature, 364:56\u201358", "citeRegEx": "39", "shortCiteRegEx": null, "year": 1993}, {"title": "Critical dynamics in the evolution of stochastic strategies for the iterated prisoner\u2019s dilemma", "author": ["D. Iliopoulous", "A. Hintze", "C. Adami"], "venue": "PLOS Computational Biology, 6(10):1\u20138", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2010}, {"title": "The Theory of Learning in Games", "author": ["D. Fudenberg", "D.K. Levine"], "venue": "The MIT Press", "citeRegEx": "41", "shortCiteRegEx": null, "year": 1998}, {"title": "Exploration\u2013exploitation tradeoffs for expert algorithms in reactive environments", "author": ["D. de Farias", "N. Megiddo"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2004}, {"title": "Towards minimizing disappointment in repeated games", "author": ["J.W. Crandall"], "venue": "Journal of Artificial Intelligence Research, 49:111\u2013142", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2014}, {"title": "Rational choice and the structure of the environment", "author": ["H.A. Simon"], "venue": "Psychological Review, 63(2):129\u2013 138", "citeRegEx": "44", "shortCiteRegEx": null, "year": 1956}, {"title": "D", "author": ["R. Karandikar", "D. Mookherjee"], "venue": "R., and F. Vega-Redondo. Evolving aspirations and cooperation. Journal of Economic Theory, 80:292\u2013331", "citeRegEx": "45", "shortCiteRegEx": null, "year": 1998}, {"title": "Satisficing and learning cooperation in the prisoner\u2019s dilemma", "author": ["J.R. Stimpson", "M.A. Goodrich", "L.C. Walters"], "venue": "Proceedings of the 17th National Conference on Artificial Intelligence, pages 535\u2013544", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2001}, {"title": "The bargaining problem", "author": ["J.F. Nash"], "venue": "Econometrica, 28:155\u2013162", "citeRegEx": "47", "shortCiteRegEx": null, "year": 1950}], "referenceMentions": [{"referenceID": 0, "context": "Abstract Since Alan Turing envisioned Artificial Intelligence (AI) [1], a major driving force behind technical progress has been competition with human cognition.", "startOffset": 67, "endOffset": 70}, {"referenceID": 1, "context": "face recognition [2], personality classification [3], driving cars [4], or playing video games [5]), or defeating humans in strategic zero-sum encounters (e.", "startOffset": 17, "endOffset": 20}, {"referenceID": 2, "context": "face recognition [2], personality classification [3], driving cars [4], or playing video games [5]), or defeating humans in strategic zero-sum encounters (e.", "startOffset": 49, "endOffset": 52}, {"referenceID": 3, "context": "face recognition [2], personality classification [3], driving cars [4], or playing video games [5]), or defeating humans in strategic zero-sum encounters (e.", "startOffset": 67, "endOffset": 70}, {"referenceID": 4, "context": "face recognition [2], personality classification [3], driving cars [4], or playing video games [5]), or defeating humans in strategic zero-sum encounters (e.", "startOffset": 95, "endOffset": 98}, {"referenceID": 5, "context": "Chess [6], Checkers [7], Jeopardy! [8], Poker [9], or Go [10]).", "startOffset": 6, "endOffset": 9}, {"referenceID": 6, "context": "Chess [6], Checkers [7], Jeopardy! [8], Poker [9], or Go [10]).", "startOffset": 20, "endOffset": 23}, {"referenceID": 7, "context": "Chess [6], Checkers [7], Jeopardy! [8], Poker [9], or Go [10]).", "startOffset": 35, "endOffset": 38}, {"referenceID": 8, "context": "Chess [6], Checkers [7], Jeopardy! [8], Poker [9], or Go [10]).", "startOffset": 46, "endOffset": 49}, {"referenceID": 9, "context": "Chess [6], Checkers [7], Jeopardy! [8], Poker [9], or Go [10]).", "startOffset": 57, "endOffset": 61}, {"referenceID": 10, "context": "A main challenge has been that human cooperation does not require sheer computational power, but rather relies on intuition [11], cultural norms [12], emotions and signals [13, 14, 15, 16], and pre-evolved dispositions toward cooperation [17], common-sense mechanisms that are difficult to encode in machines for arbitrary contexts.", "startOffset": 124, "endOffset": 128}, {"referenceID": 11, "context": "A main challenge has been that human cooperation does not require sheer computational power, but rather relies on intuition [11], cultural norms [12], emotions and signals [13, 14, 15, 16], and pre-evolved dispositions toward cooperation [17], common-sense mechanisms that are difficult to encode in machines for arbitrary contexts.", "startOffset": 145, "endOffset": 149}, {"referenceID": 12, "context": "A main challenge has been that human cooperation does not require sheer computational power, but rather relies on intuition [11], cultural norms [12], emotions and signals [13, 14, 15, 16], and pre-evolved dispositions toward cooperation [17], common-sense mechanisms that are difficult to encode in machines for arbitrary contexts.", "startOffset": 172, "endOffset": 188}, {"referenceID": 13, "context": "A main challenge has been that human cooperation does not require sheer computational power, but rather relies on intuition [11], cultural norms [12], emotions and signals [13, 14, 15, 16], and pre-evolved dispositions toward cooperation [17], common-sense mechanisms that are difficult to encode in machines for arbitrary contexts.", "startOffset": 172, "endOffset": 188}, {"referenceID": 14, "context": "A main challenge has been that human cooperation does not require sheer computational power, but rather relies on intuition [11], cultural norms [12], emotions and signals [13, 14, 15, 16], and pre-evolved dispositions toward cooperation [17], common-sense mechanisms that are difficult to encode in machines for arbitrary contexts.", "startOffset": 172, "endOffset": 188}, {"referenceID": 15, "context": "A main challenge has been that human cooperation does not require sheer computational power, but rather relies on intuition [11], cultural norms [12], emotions and signals [13, 14, 15, 16], and pre-evolved dispositions toward cooperation [17], common-sense mechanisms that are difficult to encode in machines for arbitrary contexts.", "startOffset": 172, "endOffset": 188}, {"referenceID": 16, "context": "A main challenge has been that human cooperation does not require sheer computational power, but rather relies on intuition [11], cultural norms [12], emotions and signals [13, 14, 15, 16], and pre-evolved dispositions toward cooperation [17], common-sense mechanisms that are difficult to encode in machines for arbitrary contexts.", "startOffset": 238, "endOffset": 242}, {"referenceID": 5, "context": "While the majority of AI milestones have focused on developing humanlevel wherewithal to compete with people [6, 7, 8, 9, 10], most scenarios in which AI must interact with people and other machines are not zero-sum interactions.", "startOffset": 109, "endOffset": 125}, {"referenceID": 6, "context": "While the majority of AI milestones have focused on developing humanlevel wherewithal to compete with people [6, 7, 8, 9, 10], most scenarios in which AI must interact with people and other machines are not zero-sum interactions.", "startOffset": 109, "endOffset": 125}, {"referenceID": 7, "context": "While the majority of AI milestones have focused on developing humanlevel wherewithal to compete with people [6, 7, 8, 9, 10], most scenarios in which AI must interact with people and other machines are not zero-sum interactions.", "startOffset": 109, "endOffset": 125}, {"referenceID": 8, "context": "While the majority of AI milestones have focused on developing humanlevel wherewithal to compete with people [6, 7, 8, 9, 10], most scenarios in which AI must interact with people and other machines are not zero-sum interactions.", "startOffset": 109, "endOffset": 125}, {"referenceID": 9, "context": "While the majority of AI milestones have focused on developing humanlevel wherewithal to compete with people [6, 7, 8, 9, 10], most scenarios in which AI must interact with people and other machines are not zero-sum interactions.", "startOffset": 109, "endOffset": 125}, {"referenceID": 10, "context": "While AI relies on computationally intensive search and random exploration to generate strategic behavior, human cooperation appears to rely on intuition [11], cultural norms [12], emotions and signals [13, 14], and pre-evolved dispositions toward cooperation [17].", "startOffset": 154, "endOffset": 158}, {"referenceID": 11, "context": "While AI relies on computationally intensive search and random exploration to generate strategic behavior, human cooperation appears to rely on intuition [11], cultural norms [12], emotions and signals [13, 14], and pre-evolved dispositions toward cooperation [17].", "startOffset": 175, "endOffset": 179}, {"referenceID": 12, "context": "While AI relies on computationally intensive search and random exploration to generate strategic behavior, human cooperation appears to rely on intuition [11], cultural norms [12], emotions and signals [13, 14], and pre-evolved dispositions toward cooperation [17].", "startOffset": 202, "endOffset": 210}, {"referenceID": 13, "context": "While AI relies on computationally intensive search and random exploration to generate strategic behavior, human cooperation appears to rely on intuition [11], cultural norms [12], emotions and signals [13, 14], and pre-evolved dispositions toward cooperation [17].", "startOffset": 202, "endOffset": 210}, {"referenceID": 16, "context": "While AI relies on computationally intensive search and random exploration to generate strategic behavior, human cooperation appears to rely on intuition [11], cultural norms [12], emotions and signals [13, 14], and pre-evolved dispositions toward cooperation [17].", "startOffset": 260, "endOffset": 264}, {"referenceID": 14, "context": ", costless signals) is important to human cooperation in repeated interactions [15, 16], as it helps people coordinate quickly on desirable equilibrium and create shared representations [18, 19, 20, 21].", "startOffset": 79, "endOffset": 87}, {"referenceID": 15, "context": ", costless signals) is important to human cooperation in repeated interactions [15, 16], as it helps people coordinate quickly on desirable equilibrium and create shared representations [18, 19, 20, 21].", "startOffset": 79, "endOffset": 87}, {"referenceID": 17, "context": ", costless signals) is important to human cooperation in repeated interactions [15, 16], as it helps people coordinate quickly on desirable equilibrium and create shared representations [18, 19, 20, 21].", "startOffset": 186, "endOffset": 202}, {"referenceID": 18, "context": ", costless signals) is important to human cooperation in repeated interactions [15, 16], as it helps people coordinate quickly on desirable equilibrium and create shared representations [18, 19, 20, 21].", "startOffset": 186, "endOffset": 202}, {"referenceID": 19, "context": ", costless signals) is important to human cooperation in repeated interactions [15, 16], as it helps people coordinate quickly on desirable equilibrium and create shared representations [18, 19, 20, 21].", "startOffset": 186, "endOffset": 202}, {"referenceID": 20, "context": ", costless signals) is important to human cooperation in repeated interactions [15, 16], as it helps people coordinate quickly on desirable equilibrium and create shared representations [18, 19, 20, 21].", "startOffset": 186, "endOffset": 202}, {"referenceID": 38, "context": ", GODFATHER) and win-stay-lose-shift (WSLS) [39], evolutionarily evolved memory-one and memory-two stochastic strategies [40], machine-learning algorithms (including reinforcement learning), belief-based algorithms [41], and expert algorithms [42, 43].", "startOffset": 44, "endOffset": 48}, {"referenceID": 39, "context": ", GODFATHER) and win-stay-lose-shift (WSLS) [39], evolutionarily evolved memory-one and memory-two stochastic strategies [40], machine-learning algorithms (including reinforcement learning), belief-based algorithms [41], and expert algorithms [42, 43].", "startOffset": 121, "endOffset": 125}, {"referenceID": 40, "context": ", GODFATHER) and win-stay-lose-shift (WSLS) [39], evolutionarily evolved memory-one and memory-two stochastic strategies [40], machine-learning algorithms (including reinforcement learning), belief-based algorithms [41], and expert algorithms [42, 43].", "startOffset": 215, "endOffset": 219}, {"referenceID": 41, "context": ", GODFATHER) and win-stay-lose-shift (WSLS) [39], evolutionarily evolved memory-one and memory-two stochastic strategies [40], machine-learning algorithms (including reinforcement learning), belief-based algorithms [41], and expert algorithms [42, 43].", "startOffset": 243, "endOffset": 251}, {"referenceID": 42, "context": ", GODFATHER) and win-stay-lose-shift (WSLS) [39], evolutionarily evolved memory-one and memory-two stochastic strategies [40], machine-learning algorithms (including reinforcement learning), belief-based algorithms [41], and expert algorithms [42, 43].", "startOffset": 243, "endOffset": 251}, {"referenceID": 36, "context": "2) across the periodic table of 2x2 games [37] (see Methods and SI.", "startOffset": 42, "endOffset": 46}, {"referenceID": 42, "context": "The results show that only S++ [43] was a top-performing algorithm across all metrics at all game lengths when associating with other algorithms.", "startOffset": 31, "endOffset": 35}, {"referenceID": 14, "context": "Humans are known for their ability to effectively coordinate on cooperative equilibria using costless signals called cheap talk [15, 16].", "startOffset": 128, "endOffset": 136}, {"referenceID": 15, "context": "Humans are known for their ability to effectively coordinate on cooperative equilibria using costless signals called cheap talk [15, 16].", "startOffset": 128, "endOffset": 136}, {"referenceID": 15, "context": "Consistent with prior work investigating cheap talk in repeated games [16], messages were limited to the predetermined speech acts available to S#.", "startOffset": 70, "endOffset": 74}, {"referenceID": 31, "context": "Our results open the opportunity to study human-machine cooperation in a way that builds on the rich literature on human cooperation in behavioral economics and evolutionary biology [32].", "startOffset": 182, "endOffset": 186}, {"referenceID": 32, "context": "In particular, as machines become increasingly autonomous, we see human-machine cooperation as a phenomenon that emerges from the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 172, "endOffset": 176}, {"referenceID": 33, "context": "In particular, as machines become increasingly autonomous, we see human-machine cooperation as a phenomenon that emerges from the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 275, "endOffset": 319}, {"referenceID": 34, "context": "In particular, as machines become increasingly autonomous, we see human-machine cooperation as a phenomenon that emerges from the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 275, "endOffset": 319}, {"referenceID": 35, "context": "In particular, as machines become increasingly autonomous, we see human-machine cooperation as a phenomenon that emerges from the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 275, "endOffset": 319}, {"referenceID": 36, "context": "In particular, as machines become increasingly autonomous, we see human-machine cooperation as a phenomenon that emerges from the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 275, "endOffset": 319}, {"referenceID": 37, "context": "In particular, as machines become increasingly autonomous, we see human-machine cooperation as a phenomenon that emerges from the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 275, "endOffset": 319}, {"referenceID": 38, "context": "In particular, as machines become increasingly autonomous, we see human-machine cooperation as a phenomenon that emerges from the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 275, "endOffset": 319}, {"referenceID": 39, "context": "In particular, as machines become increasingly autonomous, we see human-machine cooperation as a phenomenon that emerges from the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 275, "endOffset": 319}, {"referenceID": 40, "context": "In particular, as machines become increasingly autonomous, we see human-machine cooperation as a phenomenon that emerges from the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 275, "endOffset": 319}, {"referenceID": 41, "context": "In particular, as machines become increasingly autonomous, we see human-machine cooperation as a phenomenon that emerges from the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 275, "endOffset": 319}, {"referenceID": 42, "context": "In particular, as machines become increasingly autonomous, we see human-machine cooperation as a phenomenon that emerges from the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 275, "endOffset": 319}, {"referenceID": 43, "context": "In particular, as machines become increasingly autonomous, we see human-machine cooperation as a phenomenon that emerges from the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 275, "endOffset": 319}, {"referenceID": 44, "context": "In light of these findings, greater effort must be placed on developing autonomous machines that can effectively communicate with people, and vice versa, in order to create shared representations [45, 46, 47, 41] and coordinate quickly on desirable equilibria.", "startOffset": 196, "endOffset": 212}, {"referenceID": 45, "context": "In light of these findings, greater effort must be placed on developing autonomous machines that can effectively communicate with people, and vice versa, in order to create shared representations [45, 46, 47, 41] and coordinate quickly on desirable equilibria.", "startOffset": 196, "endOffset": 212}, {"referenceID": 46, "context": "In light of these findings, greater effort must be placed on developing autonomous machines that can effectively communicate with people, and vice versa, in order to create shared representations [45, 46, 47, 41] and coordinate quickly on desirable equilibria.", "startOffset": 196, "endOffset": 212}, {"referenceID": 40, "context": "In light of these findings, greater effort must be placed on developing autonomous machines that can effectively communicate with people, and vice versa, in order to create shared representations [45, 46, 47, 41] and coordinate quickly on desirable equilibria.", "startOffset": 196, "endOffset": 212}, {"referenceID": 45, "context": "Our work emphasizes the importance of this problem, and presents case studies that others can work from to continue to make progress [46].", "startOffset": 133, "endOffset": 137}, {"referenceID": 31, "context": "Our results open the opportunity to study human-machine cooperation in a way that builds on the rich literature on human cooperation in be avioral economics and e oluti nary biology [32].", "startOffset": 182, "endOffset": 186}, {"referenceID": 32, "context": "In particular, as machines b ome incr asingly autonom us, we see human-mac ine cooperation as a phenomenon that emerges fro the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 170, "endOffset": 174}, {"referenceID": 33, "context": "In particular, as machines b ome incr asingly autonom us, we see human-mac ine cooperation as a phenomenon that emerges fro the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 273, "endOffset": 317}, {"referenceID": 34, "context": "In particular, as machines b ome incr asingly autonom us, we see human-mac ine cooperation as a phenomenon that emerges fro the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 273, "endOffset": 317}, {"referenceID": 35, "context": "In particular, as machines b ome incr asingly autonom us, we see human-mac ine cooperation as a phenomenon that emerges fro the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 273, "endOffset": 317}, {"referenceID": 36, "context": "In particular, as machines b ome incr asingly autonom us, we see human-mac ine cooperation as a phenomenon that emerges fro the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 273, "endOffset": 317}, {"referenceID": 37, "context": "In particular, as machines b ome incr asingly autonom us, we see human-mac ine cooperation as a phenomenon that emerges fro the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 273, "endOffset": 317}, {"referenceID": 38, "context": "In particular, as machines b ome incr asingly autonom us, we see human-mac ine cooperation as a phenomenon that emerges fro the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 273, "endOffset": 317}, {"referenceID": 39, "context": "In particular, as machines b ome incr asingly autonom us, we see human-mac ine cooperation as a phenomenon that emerges fro the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 273, "endOffset": 317}, {"referenceID": 40, "context": "In particular, as machines b ome incr asingly autonom us, we see human-mac ine cooperation as a phenomenon that emerges fro the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 273, "endOffset": 317}, {"referenceID": 41, "context": "In particular, as machines b ome incr asingly autonom us, we see human-mac ine cooperation as a phenomenon that emerges fro the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 273, "endOffset": 317}, {"referenceID": 42, "context": "In particular, as machines b ome incr asingly autonom us, we see human-mac ine cooperation as a phenomenon that emerges fro the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 273, "endOffset": 317}, {"referenceID": 43, "context": "In particular, as machines b ome incr asingly autonom us, we see human-mac ine cooperation as a phenomenon that emerges fro the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 273, "endOffset": 317}, {"referenceID": 44, "context": "In light of these findings, greater effort must be placed on developing autonomous machines that can effectively communicate with people, and vice versa, in order to create shared representations [45, 46, 47, 41] and coordinate quickly on desirable equilibria.", "startOffset": 196, "endOffset": 212}, {"referenceID": 45, "context": "In light of these findings, greater effort must be placed on developing autonomous machines that can effectively communicate with people, and vice versa, in order to create shared representations [45, 46, 47, 41] and coordinate quickly on desirable equilibria.", "startOffset": 196, "endOffset": 212}, {"referenceID": 46, "context": "In light of these findings, greater effort must be placed on developing autonomous machines that can effectively communicate with people, and vice versa, in order to create shared representations [45, 46, 47, 41] and coordinate quickly on desirable equilibria.", "startOffset": 196, "endOffset": 212}, {"referenceID": 40, "context": "In light of these findings, greater effort must be placed on developing autonomous machines that can effectively communicate with people, and vice versa, in order to create shared representations [45, 46, 47, 41] and coordinate quickly on desirable equilibria.", "startOffset": 196, "endOffset": 212}, {"referenceID": 45, "context": "Our work emphasizes the importance of this problem, and presents case studies that others can work from to continue to make progress [46].", "startOffset": 133, "endOffset": 137}, {"referenceID": 42, "context": "Figure 1: An overview of S#, an algorithm that interweaves signaling capabilities into S++ [43].", "startOffset": 91, "endOffset": 95}, {"referenceID": 44, "context": "(d) S# selects an expert (using algorithm S [45, 46]) from among those experts that both potentially meet its aspirations (step b) and are congruent with its partner\u2019s latest proposal (step c).", "startOffset": 44, "endOffset": 52}, {"referenceID": 45, "context": "(d) S# selects an expert (using algorithm S [45, 46]) from among those experts that both potentially meet its aspirations (step b) and are congruent with its partner\u2019s latest proposal (step c).", "startOffset": 44, "endOffset": 52}, {"referenceID": 21, "context": ", no expert remembers the full history of play), these experts are more sophisticated than those traditionally considered (though not explicitly excluded) in the discussion of expert algorithms [22, 23, 24].", "startOffset": 194, "endOffset": 206}, {"referenceID": 22, "context": ", no expert remembers the full history of play), these experts are more sophisticated than those traditionally considered (though not explicitly excluded) in the discussion of expert algorithms [22, 23, 24].", "startOffset": 194, "endOffset": 206}, {"referenceID": 23, "context": ", no expert remembers the full history of play), these experts are more sophisticated than those traditionally considered (though not explicitly excluded) in the discussion of expert algorithms [22, 23, 24].", "startOffset": 194, "endOffset": 206}, {"referenceID": 24, "context": "This more sophisticated set of experts permits S# to adapt to a variety of partners and game types, whereas algorithms that rely on a single strategy or a less sophisticated set of experts are only successful in particular kinds of games played with particular partners [25] (Figure 3c).", "startOffset": 270, "endOffset": 274}, {"referenceID": 25, "context": ", Exp3) have permeated algorithm development in the AI community, S# instead uses an expert-selection mechanism closely aligned with recognition-primed decision making [26].", "startOffset": 168, "endOffset": 172}, {"referenceID": 26, "context": "However, S++ also learns effectively in repeated stochastic games [27], which are more complex scenarios in which a round consists of a sequence of moves by both players.", "startOffset": 66, "endOffset": 70}, {"referenceID": 26, "context": "In these games, S++ is distinguished, again, by its ability to adapt to many different machine associates in a variety of different scenarios [27].", "startOffset": 142, "endOffset": 146}, {"referenceID": 26, "context": "Though future work should address more scenarios, S#\u2019s success in establishing cooperative relationships with people in these representative games, along with its consistently high performance across all classes of 2x2 games and various repeated stochastic games [27] when associating with other algorithms, gives us some confidence that these results will generalize to many other scenarios.", "startOffset": 263, "endOffset": 267}, {"referenceID": 5, "context": "Since Alan Turing envisioned Artificial Intelligence, major milestones have focused on defeating humans in zero-sum encounters [6, 7, 8, 9, 10].", "startOffset": 127, "endOffset": 143}, {"referenceID": 6, "context": "Since Alan Turing envisioned Artificial Intelligence, major milestones have focused on defeating humans in zero-sum encounters [6, 7, 8, 9, 10].", "startOffset": 127, "endOffset": 143}, {"referenceID": 7, "context": "Since Alan Turing envisioned Artificial Intelligence, major milestones have focused on defeating humans in zero-sum encounters [6, 7, 8, 9, 10].", "startOffset": 127, "endOffset": 143}, {"referenceID": 8, "context": "Since Alan Turing envisioned Artificial Intelligence, major milestones have focused on defeating humans in zero-sum encounters [6, 7, 8, 9, 10].", "startOffset": 127, "endOffset": 143}, {"referenceID": 9, "context": "Since Alan Turing envisioned Artificial Intelligence, major milestones have focused on defeating humans in zero-sum encounters [6, 7, 8, 9, 10].", "startOffset": 127, "endOffset": 143}, {"referenceID": 27, "context": "When it comes to human cooperation, a fundamental benchmark has been 2\u00d72, general-sum, repeated games [28].", "startOffset": 102, "endOffset": 106}, {"referenceID": 28, "context": "This class of games has been a workhorse for decades in the fields of behavioral economics [29], mathematical biology [30], psychology [31], sociology [32], computer science [33], and political science [34].", "startOffset": 91, "endOffset": 95}, {"referenceID": 29, "context": "This class of games has been a workhorse for decades in the fields of behavioral economics [29], mathematical biology [30], psychology [31], sociology [32], computer science [33], and political science [34].", "startOffset": 118, "endOffset": 122}, {"referenceID": 30, "context": "This class of games has been a workhorse for decades in the fields of behavioral economics [29], mathematical biology [30], psychology [31], sociology [32], computer science [33], and political science [34].", "startOffset": 135, "endOffset": 139}, {"referenceID": 31, "context": "This class of games has been a workhorse for decades in the fields of behavioral economics [29], mathematical biology [30], psychology [31], sociology [32], computer science [33], and political science [34].", "startOffset": 151, "endOffset": 155}, {"referenceID": 32, "context": "This class of games has been a workhorse for decades in the fields of behavioral economics [29], mathematical biology [30], psychology [31], sociology [32], computer science [33], and political science [34].", "startOffset": 174, "endOffset": 178}, {"referenceID": 33, "context": "This class of games has been a workhorse for decades in the fields of behavioral economics [29], mathematical biology [30], psychology [31], sociology [32], computer science [33], and political science [34].", "startOffset": 202, "endOffset": 206}, {"referenceID": 27, "context": "3; [28, 35, 36, 37, 38]) identifies and categorizes 144 unique game structures that present many unique scenarios in which machines may need to cooperate.", "startOffset": 3, "endOffset": 23}, {"referenceID": 34, "context": "3; [28, 35, 36, 37, 38]) identifies and categorizes 144 unique game structures that present many unique scenarios in which machines may need to cooperate.", "startOffset": 3, "endOffset": 23}, {"referenceID": 35, "context": "3; [28, 35, 36, 37, 38]) identifies and categorizes 144 unique game structures that present many unique scenarios in which machines may need to cooperate.", "startOffset": 3, "endOffset": 23}, {"referenceID": 36, "context": "3; [28, 35, 36, 37, 38]) identifies and categorizes 144 unique game structures that present many unique scenarios in which machines may need to cooperate.", "startOffset": 3, "endOffset": 23}, {"referenceID": 37, "context": "3; [28, 35, 36, 37, 38]) identifies and categorizes 144 unique game structures that present many unique scenarios in which machines may need to cooperate.", "startOffset": 3, "endOffset": 23}, {"referenceID": 36, "context": "Figure 5: We compared algorithms across the periodic table of 2x2 games based on the topology of Robinson and Goforth [37] for scenarios in which the players exhibit a strict ordinal preference ordering over the four game outcomes (specified by the values 1, 2, 3, and 4).", "startOffset": 118, "endOffset": 122}, {"referenceID": 46, "context": "The solutions played in the Nash bargaining solution (NBS [47] \u2013 i.", "startOffset": 58, "endOffset": 62}, {"referenceID": 37, "context": "The figure is adapted from the graphic developed by Bruns [38].", "startOffset": 58, "endOffset": 62}, {"referenceID": 38, "context": ", GODFATHER) and win-stay-lose-shift (WSLS) [39], evolutionarily evolved memory-one and memory-two stochastic strategies [40], machine-learning algorithms (including reinforcement learning), belief-based algorithms [41], and expert algorithms [42, 43].", "startOffset": 44, "endOffset": 48}, {"referenceID": 39, "context": ", GODFATHER) and win-stay-lose-shift (WSLS) [39], evolutionarily evolved memory-one and memory-two stochastic strategies [40], machine-learning algorithms (including reinforcement learning), belief-based algorithms [41], and expert algorithms [42, 43].", "startOffset": 121, "endOffset": 125}, {"referenceID": 40, "context": ", GODFATHER) and win-stay-lose-shift (WSLS) [39], evolutionarily evolved memory-one and memory-two stochastic strategies [40], machine-learning algorithms (including reinforcement learning), belief-based algorithms [41], and expert algorithms [42, 43].", "startOffset": 215, "endOffset": 219}, {"referenceID": 41, "context": ", GODFATHER) and win-stay-lose-shift (WSLS) [39], evolutionarily evolved memory-one and memory-two stochastic strategies [40], machine-learning algorithms (including reinforcement learning), belief-based algorithms [41], and expert algorithms [42, 43].", "startOffset": 243, "endOffset": 251}, {"referenceID": 42, "context": ", GODFATHER) and win-stay-lose-shift (WSLS) [39], evolutionarily evolved memory-one and memory-two stochastic strategies [40], machine-learning algorithms (including reinforcement learning), belief-based algorithms [41], and expert algorithms [42, 43].", "startOffset": 243, "endOffset": 251}, {"referenceID": 21, "context": ", Exp3 [22], GIGA-WoLF [23], and WMA [24]), which is the central component of world-champion computer poker algorithms [9], also performed poorly.", "startOffset": 7, "endOffset": 11}, {"referenceID": 22, "context": ", Exp3 [22], GIGA-WoLF [23], and WMA [24]), which is the central component of world-champion computer poker algorithms [9], also performed poorly.", "startOffset": 23, "endOffset": 27}, {"referenceID": 23, "context": ", Exp3 [22], GIGA-WoLF [23], and WMA [24]), which is the central component of world-champion computer poker algorithms [9], also performed poorly.", "startOffset": 37, "endOffset": 41}, {"referenceID": 8, "context": ", Exp3 [22], GIGA-WoLF [23], and WMA [24]), which is the central component of world-champion computer poker algorithms [9], also performed poorly.", "startOffset": 119, "endOffset": 122}, {"referenceID": 42, "context": "Second, while many algorithms had high performance with respect to some measure, only S++ [43] was a top-performing algorithm across all metrics at all game lengths.", "startOffset": 90, "endOffset": 94}, {"referenceID": 42, "context": "3 S#: A Machine-Learning Algorithm that Talks S# is derived from S++ [43], an expert algorithm that combines and builds on decades of research in computer science, economics, and the behavioral and social sciences.", "startOffset": 69, "endOffset": 73}, {"referenceID": 43, "context": "S++ then uses a meta-level control strategy based on aspiration learning [44, 45, 46] to dynamically reduce this set of experts.", "startOffset": 73, "endOffset": 85}, {"referenceID": 44, "context": "S++ then uses a meta-level control strategy based on aspiration learning [44, 45, 46] to dynamically reduce this set of experts.", "startOffset": 73, "endOffset": 85}, {"referenceID": 45, "context": "S++ then uses a meta-level control strategy based on aspiration learning [44, 45, 46] to dynamically reduce this set of experts.", "startOffset": 73, "endOffset": 85}, {"referenceID": 44, "context": "It then selects one expert esel(t) \u2208 E(t) using a satisficing decision rule [45, 46].", "startOffset": 76, "endOffset": 84}, {"referenceID": 45, "context": "It then selects one expert esel(t) \u2208 E(t) using a satisficing decision rule [45, 46].", "startOffset": 76, "endOffset": 84}], "year": 2017, "abstractText": "Since Alan Turing envisioned Artificial Intelligence (AI) [1], a major driving force behind technical progress has been competition with human cognition. Historical milestones have been frequently associated with computers matching or outperforming humans in difficult cognitive tasks (e.g. face recognition [2], personality classification [3], driving cars [4], or playing video games [5]), or defeating humans in strategic zero-sum encounters (e.g. Chess [6], Checkers [7], Jeopardy! [8], Poker [9], or Go [10]). In contrast, less attention has been given to developing autonomous machines that establish mutually cooperative relationships with people who may not share the machine\u2019s preferences. A main challenge has been that human cooperation does not require sheer computational power, but rather relies on intuition [11], cultural norms [12], emotions and signals [13, 14, 15, 16], and pre-evolved dispositions toward cooperation [17], common-sense mechanisms that are difficult to encode in machines for arbitrary contexts. Here, we combine a state-of-the-art machine-learning algorithm with novel mechanisms for generating and acting on signals to produce a new learning algorithm that cooperates with people and other machines at levels that rival human cooperation in a variety of two-player repeated stochastic games. This is the first general-purpose algorithm that is capable, given a description of a previously unseen game environment, of learning to cooperate with people within short timescales in scenarios previously unanticipated by algorithm designers. This is achieved without complex opponent modeling or higher-order theories of mind, thus showing that flexible, fast, and general human-machine cooperation is computationally achievable using a non-trivial, but ultimately simple, set of algorithmic mechanisms. \u2217Correspondence should be addressed to crandall@cs.byu.edu and irahwan@mit.edu ar X iv :1 70 3. 06 20 7v 1 [ cs .A I] 1 7 M ar 2 01 7", "creator": "LaTeX with hyperref package"}}}