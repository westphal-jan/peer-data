{"id": "1703.06541", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Mar-2017", "title": "Native Language Identification using Stacked Generalization", "abstract": "Ensemble methods using multiple classifiers have proven to be the most successful approach for the task of Native Language Identification (NLI), achieving the current state of the art. However, a systematic examination of ensemble methods for NLI has yet to be conducted. Additionally, deeper ensemble architectures such as classifier stacking have not been closely evaluated. We present a set of experiments using three ensemble-based models, testing each with multiple configurations and algorithms. This includes a rigorous application of meta-classification models for NLI, achieving state-of-the-art results on three datasets from different languages. We also present the first use of statistical significance testing for comparing NLI systems, showing that our results are significantly better than the previous state of the art. We make available a collection of test set predictions to facilitate future statistical tests.", "histories": [["v1", "Sun, 19 Mar 2017 23:42:28 GMT  (965kb,D)", "http://arxiv.org/abs/1703.06541v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["shervin malmasi", "mark dras"], "accepted": false, "id": "1703.06541"}, "pdf": {"name": "1703.06541.pdf", "metadata": {"source": "CRF", "title": "Native Language Identification using Stacked Generalization", "authors": ["Shervin Malmasi", "Mark Dras"], "emails": ["shervin.malmasi@mq.edu.au", "mark.dras@mq.edu.au"], "sections": [{"heading": "1 Introduction", "text": "In fact, most of them are able to survive on their own."}, {"heading": "2 Related Work", "text": "This work is based on two major areas of research: ensemble-based classification methods and work in the NLI."}, {"heading": "2.1 Ensemble Classifiers", "text": "Classifier ensembles are a way to combine different classifiers or experts with the aim of improving overall accuracy through improved decision-making. Rather than relying on a single expert's decisions, they try to make a decision using the collective input of an expert committee.1 Traditional text classification methods outperformed all the deep learning approaches of the DSL Shared Task. They have been applied to a wide range of real problems and show better results than classification methods (Oza and Tumer, 2008).By aggregating the results of multiple classifiers in some ways, their results are generally considered more robust. Ensemble methods continue to receive increasing attention from researchers and remain a focus of machine learning research (Woz'niak et al., 2014; Kuncheva and Rodr'\u00edguez, 2014).Such ensemble-based systems often use a parallel architecture in which classifiers operate independently and their results are aggregated by a fusion method."}, {"heading": "2.2 Native Language Identification", "text": "This year, it has reached the stage where it will be able to take the lead."}, {"heading": "3 Data", "text": "We are now presenting the three sets of data used in this study. One of the aims of this study is to assess the generalisability of methods and results across sets of data, using several corporas, all of which have been used in previous NLI work and cover different (second) languages: English, Chinese and Norwegian."}, {"heading": "3.1 The TOEFL11 Corpus", "text": "The Toefl11 Corpus (Blanchard et al., 2013) - also known as the ETS Corpus of Non-Native Written English - is the first data set specifically designed for the task of the NLI and designed to address the aforementioned shortcomings of other previously used corpora. By providing a common set of L1s and evaluation standards, it ensures that all data sets are encrypted and stored in a unified manner. It is available through the Linguistic Data Consortium. 5It consists of 12,100 learning texts written by speakers of 11 different languages. The texts are independent task essays written in response to eight different instructions."}, {"heading": "3.2 The ASK Corpus", "text": "This year, it is only a matter of time before an agreement is reached."}, {"heading": "3.2.1 Part-of-Speech Tagset", "text": "The ASK corpus uses the Oslo-Bergen tagset6, which was developed based on the Norwegian reference grammar (Faarlund et al., 1997). Here, each POS tag consists of a series of constituent morphosyntactic tags. For example, the tag subst-appell-mask-ub-fl means that the token has the categories \"noun common male indeterminate plural.\" Similarly, the tags verb-imp and verb-pres refer to imperative and present. Due to its many morphosyntactic markers and detailed categories, the ASK dataset has a rich tagset of over 300 unique tags."}, {"heading": "3.3 The Jinan Chinese Learner Corpus", "text": "Growing interest has led to the recent development of the Jinan Chinese Learner Corpus (Wang et al., 2015), the first large-format corpus of L2 Chinese, consisting of essays by university students. Students from 59 countries are represented, and achievement levels are sampled representatively between beginner, intermediate and advanced levels. However, texts from students from other Asian countries are disproportionately represented, probably due to geographical proximity and links to China. For this work, we extracted 3.75 million bookmarks from the JCLC in the form of individual sentences. [7] In accordance with the methodology described in the previous section, we combine the sentences from the same L1 to produce texts of an average of 600 characters, with 8 documents available for NLI. Although the corpus contains over 50 L1s, we select the top 11 languages shown in Table 2 to use them in our experiments."}, {"heading": "4 Experimental Setup", "text": "In this study, we use a supervised multi-level classification approach. The learner texts are divided into classes according to the author's L1, and these documents serve for training and testing in our experiments. In this section, we describe our experimental methodology, including evaluation and the algorithms we use. Our classification features are described in \u00a7 5, and the three classification models we create using these algorithms and features are then described in \u00a7 6.6http: / / tekstlab.uio.no / obt-ny / english / tagset.html 7Full texts are not provided, only individual sentences with the relevant metadata (competence / nationality). 8A single Chinese character is considered a token."}, {"heading": "4.1 Evaluation", "text": "Like many previous NLI studies and the NLI 2013 collaborative task, we report our results as classification accuracy with k-fold cross-validation with k = 10. In recent years, this has become de facto the standard for reporting NLI results. To create our wrinkles, we use a layered cross-validation to ensure that the proportion of classes within each partition is the same (Kohavi, 1995). For Toefl11, we also test with the standard test set, which we call the Toefl11 test. For comparison purposes, we use a random baseline and a majority-class baseline to determine the lower limits for accuracy. Oracles, which we describe in \u00a7 6.1.8, are also used to estimate a potential upper limit for accuracy."}, {"heading": "4.2 Classification Algorithms", "text": "In this section we briefly describe the learning algorithms used in our experiments. All these learners are evaluated as meta-classifiers, but for the reasons outlined below (\u00a7 4.2.1) only SVMs are used as basic learners. Although a thorough presentation of the methods goes beyond the scope of this work, important references are provided to the interested reader."}, {"heading": "4.2.1 Linear Support Vector Machine", "text": "Linear Support Vector Machine (SVM) classifiers are a highly robust monitored classification method that has proven to be very effective for text classification (Joachims, 1998). Strong theoretical and empirical arguments have been made for the use of SVMs for text classification, showing that their capabilities are well suited to multiple properties of text data, including extremely large attribute spaces, very high sparseness, and few irrelevant features. In terms of NLI, we have used this learner to generate all base classifiers in this study. SVMs are by nature binary classifiers, and a common way to adapt them to multi-class problems is to use OVA-based systems, also known as one vs classifiers (residual classifiers), which confirm this approach not for all (OVR-1), but for a single VVR method (VVR-1)."}, {"heading": "4.2.2 RBF-Kernel Support Vector Machine", "text": "SVMs with Radial Base Function (RBF) kernels are also popular for non-linearly separable data points, because the kernel maps the data points in a non-linear way, allowing for more flexible decision boundaries (Hsu et al., 2003). It should also be noted that this flexibility increases the risk of overmatching. Furthermore, this type of kernel may not work well for large function spaces. 9 Although they do not work as well as linear SVMs for text classification, they can achieve very competitive results on problems with fewer functions."}, {"heading": "4.2.3 Logistic Regression", "text": "Logistic regression is a kind of linear regression model in which the dependent variables are categorical. Supported by strong theoretical foundations and practical results, logistic regression has most likely evolved into a widely used machine learning algorithm. Although high-dimensional input poses a challenge to these models (Genkin et al., 2007), this problem can be solved to some extent by regularization methods (Zhu and Hastie, 2004), an algorithm that is inherently cross-class, meaning that OVA and OVO approaches are not required. The logistic regression classifier is also probabilistic and provides continuous probability estimates for each classlabel.9 Appendix C by Hsu et al. (2003) explores this problem in more detail."}, {"heading": "4.2.4 Perceptron", "text": "The Perceptron (Rosenblatt, 1958) is another successful linear learning algorithm that learns a weight vector and a bias concept that shifts the decision boundary from the source. However, the algorithm will not converge if the data is not linearly separable. It supports online learning and each training instance is processed according to a defined learning rate and weights updated. Perceptrons have been successfully used for POS tagging (Collins, 2002) and parsing (Collins and Roark, 2004)."}, {"heading": "4.2.5 Ridge Regression", "text": "Burr regression classification is an approach based on a regression model that uses a linear loss function with the smallest squares (Zhang and Oles, 2001).The OVA approach is used for multi-class classification. As it is a linear model, it can be used well for high-dimensional problems, as they are often linearly separable."}, {"heading": "4.2.6 Decision Trees", "text": "As one of the oldest and most commonly used supervised learning methods, decision trees are a non-parametric method that attempts to learn a set of hierarchical decision rules based on input functions (Quinlan, 1993). They are by nature multi-class learners and require little data pre-processing, but the trees can be unstable and may not generalize far beyond the training data."}, {"heading": "4.2.7 Linear Discriminant Analysis", "text": "A classical learning algorithm, the Linear Discriminant Analysis (LDA, not to be confused with the latent Dirichlet allocation), is a method based on a linear decision limit (Fisher, 1936) and widely and successfully applied for classification (Liu and Wechsler, 2002). LDA, a generative classification method, adapts a conditional probability density function to each class and works under the assumption of homoscedasticity, i.e. all classes have the same covariance. It is not parametric and inherently multiclassical."}, {"heading": "4.2.8 Quadratic Discriminant Analysis", "text": "The quadratic discriminant analysis (QDA) is similar to LDA except that it uses a quadratic decision interface (Hastie et al., 2009). Unlike LDA, however, it does not assume equivalent class covariances, allowing it to be class-specific. 4.2.9 k-nearest NeighborsA popular neighborhood-based algorithm, k-nearest Neighbors (k-NN), is an instance classifier that does not build a statistical model (Cover and Hart, 1967). Training data is stored and test instances are labeled by a majority decision of the labels of the k-nearest instances. The k parameter needs to be defined. This value is usually data-dependent and is selected experimentally."}, {"heading": "4.2.10 Nearest Centroid", "text": "The Nearest Centroid (NC) classification algorithm calculates the centric (i.e. mean) vector for each class (Tibshirani et al., 2002). Test instances are assigned to the class with the nearest centrid. It is not parametric, but can work poorly if classes have different deviations for each attribute."}, {"heading": "4.3 Classifier Output Representation", "text": "As described in \u00a7 6, our meta-classifiers are trained on the results generated by each classifier, which are generally divided into two categories: discrete labels and continuous values. In this section, we describe these and how they are used for further classification."}, {"heading": "4.3.1 Discrete Label Values", "text": "The most basic approach is to use discrete class names generated by the classifiers. In the case of multi-class classification, this output is a single discrete value that represents the hypothesis formed by the classifier and is provided by virtually all learning algorithms. The number of possible values is the same as the number of possible classes in the dataset, K. In order to use this categorical value as a classification feature, the results of any classifier must be presented as a feature vector. A common approach here for displaying the values using one-hot encoding. This encoding generates a 1-of-K vector: This is a vector with K elements in which one element is always set to 1 while the rest is 0. This approach allows categorical data to be presented as continuous input, which is the input format expected by most learning algorithms."}, {"heading": "4.3.2 Continuous Output", "text": "Probabilistic classifiers, such as Logistic Regression, can provide confidence estimates for any of the possible K-class designations. Margin-based classifiers, such as Support Vector Machines, can provide the signed distance to the separating hyperlevel.10 Where available, this output information can also be used to form a vector for the classification. For each input, this would result in a K-element vector where each element is the continuous output associated with a class label. For confidence estimates, all elements in the vector would add up 1.The confidence level for each label; by taking into account the values for the other labels, we could make better predictions. They can also help to avoid vocal equality that can occur when only the discrete class designations are used."}, {"heading": "5 Features", "text": "This study focuses on comparing classification methods for NLI and we do not confuse this goal by introducing new features. Different feature types are extracted from each of our three data sets, as shown in Table 3.The feature types for each data set are based on the characteristics of the data set and the availability of NLP resources for the L2.For stylistic classification tasks such as NLI, these content-based features can only be used if the training data is thematically balanced. Otherwise, the topic balance will greatly affect the results and artificially increase accuracy (Malmasi and Dras, 2015b). Accordingly, we use these features only for our experiments with Toefl11, which is thematically balanced. NLP tools used to extract adapter grammar and fragment characteristics of TSG are only available in English, and thus limited to Toefl11. The lack of NLP tools is also not listed in the individual data sets as being equal between the norm and the data set."}, {"heading": "5.1 Word, Lemma and Character n-grams", "text": "We extract frequently used interface features from the texts. These include word unigrams and bigrams, Lemma unigrams and bigrams as well as uni / bi / trigrams."}, {"heading": "5.2 Function Words", "text": "Unlike content words, functional words themselves have no thematic meaning, but can be seen as a reference to the grammatical relationships between other words. In a way, they are the syntactical glue that holds most of the content words together, and their role in assigning syntax to sentences is well-defined linguistically. They usually belong to a set of closed class words and embody relationships more than propositional content. Examples are articles, determinants, conjunctions, and auxiliaries. Function words are considered highly contextual and subject-independent, but other open class words can also have such properties. In practical applications, such as information repetition, such words are often removed because they are not informative, and stop lists for different languages have been developed for this purpose. These lists contain \"stop words\" and formulaic discourse expressions such as the above or on the other hand.Function-word independence has led to their widespread use."}, {"heading": "5.3 Part-of-Speech n-grams", "text": "Parts of the language (POS) are linguistic categories (or word classes) that are associated with words that symbolize their syntactical role. Basic categories include verbs, nouns, and adjectives, but these can be augmented by additional morphosyntactic information. Matching such categories to words in a text gives words a level of linguistic abstraction. We extract POS n-grams of order 1-3, which have proven useful for NLI (Malmasi et al., 2013). These n-grams capture small and very local syntactic patterns of language production and have been used as classification features. Preliminary work and our experiments showed that sequences of size 4 or greater are less accurate, possibly due to the data shortage, so we do not include them. For English and Chinese, the Stanford CoreNLP15 suite of NLP tools (Manning et al., 2014) and the models provided were used for the use of texts."}, {"heading": "5.4 Adaptor grammar collocations", "text": "For the Toefl11 data, we use an adapter grammar to detect any n-gram collocations of length. We examine both the pure n-grammatical parts of the language (POS) and the more promising mixtures of POS and function words. We derive two adapter grammars, each of which is associated with a different vocabulary: either with pure POS words or the mixture of POS and function words. We use the grammar proposed by (Johnson, 2010) to capture thematic collocations: Sentence \u2192 Docj-j-1,..., m Docj-J-1,.., m-Docj-Docj-Topici-1,..., m-Topici-Words-1,.., m-Topici-Words-1,.., t-Words-Docj-J-1,..., m-Docj-Docj-J-Words-1."}, {"heading": "5.5 Stanford dependencies", "text": "In English and Chinese, we use Stanford dependencies as a syntactic attribute: For each text, we extract all the basic dependencies returned by the Stanford parser (de Marneffe et al., 2006), and then we generate all the variations for each of the dependencies (grammatical relations) by replacing each term with the corresponding POS tag. For example, a grammatical relationship of det (knowledge that) yields the following variations: det (NN, die), det (knowledge, DT), and det (NN, DT)."}, {"heading": "5.6 CFG Rules", "text": "Also known as Phrase Structure Rules or Production Rules, these are the rules used to create components of sentences, such as noun sentences. One way to get them is to first generate constituent parses for all sentences, and then extract the production rules without lexicalizations. Figure 4 illustrates this using an example tree and its rules.16http: / / web.science.mq.edu.au / ~ mjohnson / Software.htm\u03b1 \u03b1These context-free phrase structure rules capture the overall structure of grammatical constructions and global syntactic patterns. They can also encode high-chidiosyncratic constructions that are specific to some L1 groups. They have proven useful for NLI (Wong and Dras, 2011)."}, {"heading": "5.7 Tree Substitution Grammar Fragments", "text": "Tree Substitution Grammar (TSG) fragments were proposed by Swanson and Charniak (2012) as another type of syntactic feature for NLI or other syntactically motivated text classification tasks, showing that this type of feature can achieve high classification accuracy. TSGs are a generalization of context-free grammars that allow non-terminals to rewrite fragments that can be any size (Post and Gildea, 2013) rather than being limited to a depth of one. A TSG fragment or elementary tree refers to these rules. Figure 5 shows several sample fragments from a tree substitution grammar that are able to derive the sentences \"George hates broccoli\" and \"George hates shoes.\" We only extract TSG fragments for the Toefl11 data because they contain lexical end nodes."}, {"heading": "6 Classification Models", "text": "We are conducting a series of three experiments, each based on different ensemble structures that we describe in this section: the first model is based on a traditional parallel ensemble structure, while the second model investigates meta-classification by means of classifier stacking."}, {"heading": "6.1 Ensemble Classifiers", "text": "The most common ensemble structure, as already described in \u00a7 2.1, is based on a series of basic classifiers, but their decisions are combined by a predefined method. This is the approach for our first model. Such systems often use a parallel architecture, as illustrated in Figure 6, where the classifiers operate independently of each other and their results are aggregated by a fusion method. The first part of creating an ensemble is the generation of the individual classifiers. Various methods for creating these ensemble elements have been suggested, including the use of different algorithms, parameters or feature types; the application of different pre-processing or feature scaling methods; and the variation (e.g. distortion or resampling) of the training data. For example, bagging (bootstrap aggregation) is a commonly used method for generating ensemble data (Breiman, 1996), which can generate multiple base classifiers. It works by separating several boot strap groups from the original training data and a training data."}, {"heading": "6.1.1 Ensemble Fusion Methods", "text": "Once it has been decided how to generate the set of basic classifiers, the selection of the classification combination method is the next fundamental design question in ensemble construction, and the answer to this question depends on what results are available from each classifier. The two different output types were discussed earlier in Section 4.3. Some combination methods are designed to work with class names, assuming that each student prints a single class name for each data point. Other methods are designed to work with class-based continuous results, which requires that in each case each classifier provides a level of confidence 18 for each class name. These output results can correspond to the probabilities for each class and thus result in a sum of 1 over all classes. If an algorithm can provide both types of results, then all methods can be tested. This is the case for the classifiers we will work with, as they are all SVM."}, {"heading": "6.1.2 Plurality voting", "text": "The votes are counted and the label with the highest number of votes wins. 19 ties are resolved arbitrarily. This method is simple and has no parameters for voting. A comprehensive analysis of the method and its theoretical basis can be found in Kuncheva (2004, p. 112)."}, {"heading": "6.1.3 Mean Probability Rule", "text": "The probability estimates for each class provided by each classifier are added together, and the winner is the class name with the highest average probability. This is shown in Figure 7. This corresponds to the probability sum designation, which does not require calculating the average for each class. An important aspect of using probability outputs in this way is that the support of the classifier for the true class designation is taken into account, even if it is not the predicted label (e.g. it may have the second highest probability).This method has proven to be good on a variety of problems and is generally considered simple, intuitive, stable (Kuncheva, 2014, p. 155) and resistant to estimation errors (Kittler et al., 1998), making it one of the more robust combinations discussed in the literature."}, {"heading": "6.1.4 Median Probability Rule", "text": "Given that the mean probability used in the above rule is susceptible to outliers, an alternative is to use the median as a more robust estimate of the mean value (Kittler et al., 1998), according to which the estimates of each class sign are sorted and the median is selected as the final value for this label. Winner is the label with the highest median value. As with the mean combinator, this method measures the central tendency of support for each label as a means of reaching a consensus decision."}, {"heading": "6.1.5 Product Rule", "text": "For each class label, all probability estimates are multiplied with each other to make the final estimate for the label (Polikar, 2006, p. 37). Select the label with the highest estimate. Theoretically, this rule can provide the best overall estimate of the posterior probability for a label, provided the individual estimates are correct. A compromise is that this method is very sensitive to low probabilities: a single low value for a label of a classifier essentially eliminates this class label."}, {"heading": "6.1.6 Highest Confidence", "text": "In this simple method, the class label that receives the vote with the highest degree of confidence is selected as the final prediction (Kuncheva, 2014, p. 150). In contrast to the previous methods, this combinator disregards the consensus opinion and instead chooses the prediction of the expert with the highest degree of confidence. 19This differs from a majority election combinator where a label must receive over 50% of the votes 0.00 0.1 0.5 0.4 0.0 0.4 0.4 0.4 0.4 0.4 0.4 0.7 0.2 0.00 (0.40) 0.40 0.00 (0.2 0.10) 0.00 0.00 (0.10) 0.00 (0.00) 0.00 0.00 (0.00) (0.00 0.00 0.00) (0.00 0.00) (0.00 0.00 0.00) (0.00 0.00 0.00) (0.00 0.00 0.00) (0.00 0.00 0.00) (0.00 0.00) (0.00 0.00 0.00) (0.00 0.00 0.00) (0.00 0.00 0.00) (0.00 0.00) (0.00 0.00) (0.00) (0.00) (0.00 0.00) (0.00) (0.00) (0.00) (0.00 0.00 0.00 0.00 0.00 (0.00) (0.00) (0.00 0.00) (0.00) (0.00) (0.00 0.00 0.00 0.00 0.00 0.00 (0.00) (0.00) (0.00) (0.00 0.00 0.00 0.00 0.00 0.00) (0.00 0.00 0.00) (0.00 0.00 0.00) (0.00 0.00) (0.00 0.00) (0.00 0.00 0.00 0.00 0.00 0.00) (0.00 0.00) (0.00 0.00 0.00 0.00 0.00 0.00 0.00 (0.00) (0.00) (0.00 0.00 0.00 0.00) (0.00 0.00 0.00 0.00 0.00) (0.00 0.00 0.00 0.00 0.00 (0.00) (0.00 0.00) (0.00 0.00 0.00 0.00) (0.00 0.00 0.00 0.00) (0.00 0.00 0.00 0.00) (0.00 0.00 0.00 0.00 0.00 0.00 (0.00) (0.00 0.00 0.00"}, {"heading": "6.1.7 Borda Count", "text": "This method works by using the confidence estimates of each classifier to compile a ranking of class names in the order of their preferences, with the predicted label ranked first. The winning label is then selected according to the Borda count20 algorithm (Ho et al., 1994). The algorithm works by assigning points to labels based on their ranking order. If there are N different labels, each classifier's preferences are assigned as follows: the best-placed label gets N \u2212 1 points, the second-placed label gets N \u2212 1 points, the third-place gets N \u2212 2 points, and so on. These points are then tallied to select the winner with the highest score. The most obvious advantage of this method is that it takes into account all the preferences of each classifier, allowing a label to win even if another label receives a majority of the first preference votes."}, {"heading": "6.1.8 Oracle Combiners", "text": "Our final composition of the combinators is designed to help in assessing the potential performance limit that could be achieved by a system, given a number of classifications. As such, they are primarily used for evaluation in the same way that baselines help to determine the lower limits for performance. These combinators cannot be used to make predictions about unlabeled data (Kuncheva et al., 2001). An oracle is a type of multiple classification method that can be used to combine the results of an \"oracle\" combinator; this method has previously been used to analyze the boundaries of the majority selection combination of classifiers (Kuncheva et al.) An oracle is a type of multiple classifier fusion method that is used to combine the results of an ensemble of classifiers, all of which are used to classify a dataset."}, {"heading": "6.2 Meta-Classifiers (Stacked Generalization)", "text": "While the combination methods in our first model are not workable, other complex ensemble methods based on meta-learning may have a stacked architecture in which the results of a first layer of classifiers are fed into a second layer (Wolpert, 1992), a methodology that has not been tested for NLI. A meta-classification architecture consists of an ensemble of classifiers, as well as a first model. A major difference is that a rules-based fusion method is not used to form a second layer."}, {"heading": "6.3 Meta-Classifier Ensembles", "text": "The two models described so far are based on a combination of multiple classifiers and meta-learning. Although both have their advantages, would it be possible to combine both approaches? To this end, our final model is a hybrid of the two previous approaches that attempts to answer this question. Results from the set of basic classifiers are made available to an ensemble of meta-classifiers, rather than a single one. Results from the meta-classifiers are then combined with a fusion method to arrive at a final judgement. The layout for this model is shown in Figure 9. Although this approach adds considerable complexity to the model, it could potentially have the benefits of stacking and combinations. In addition, this approach also requires a method for generating the meta-classifier ensemble itself. While the first level is generated with a different characteristic type per classifier, this method cannot be applied here as we use classifier outputs. To this end, we are experimenting with the increase and went as described in Figure 6.1."}, {"heading": "7 Experiments and Results", "text": "We divide our experiments into two parts: comprehensive experiments with the English Toefl11 data (\u00a7 7.1), followed by comparative experiments with Chinese and Norwegian data (\u00a7 7.2)."}, {"heading": "7.1 Experiments on TOEFL11", "text": "This year, it is closer than ever before in the history of the country."}, {"heading": "7.2 Experiments On Other Languages", "text": "The second set of our experiments focuses on investigating the generalizability of our results to date. The patterns observed on Toefl11 have been stable throughout the training and testing set, but we are now applying them to other sets of data to assess their generalizability in different languages and data sources.The experiments in this section are performed on the Chinese and Norwegian sets described in \u00a7 3. Since these sets do not have a predefined test set like Toefl11, these experiments were performed by layered cross-validation, as in \u00a7 4.1. Previous experiments on these corpora have also been performed exclusively by cross-validation. We use the most powerful models tested in \u00a7 7.1: four ensemble combinators, four bagging-based meta-classifiers, and four ensembles of meta-classifiers. These selected models and their results are shown in Table 9.The oracle values for both sets are very similar to Toefl11, with over 90% of toxicity."}, {"heading": "7.3 Statistical Significance Testing", "text": "This year, it is at an all-time high in the history of the European Union."}, {"heading": "8 Discussion", "text": "We have the first comprehensive study of the meta-classification for NLI, which assesses the accuracy of three important data sets for the future. It is the most comprehensive and systematic application of our models. Performance patterns are similar to those of the first two models in which we have achieved the best results, including the work of Ionescu et al."}], "references": [{"title": "Customizing sentiment classifiers to new domains: A case study", "author": ["Anthony Aue", "Michael Gamon"], "venue": "In Proceedings of recent advances in natural language processing (RANLP),", "citeRegEx": "Aue and Gamon.,? \\Q2005\\E", "shortCiteRegEx": "Aue and Gamon.", "year": 2005}, {"title": "A comparison of decision tree ensemble creation techniques", "author": ["Robert E Banfield", "Lawrence O Hall", "Kevin W Bowyer", "W Philip Kegelmeyer"], "venue": "IEEE transactions on pattern analysis and machine intelligence,", "citeRegEx": "Banfield et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Banfield et al\\.", "year": 2007}, {"title": "TOEFL11: A Corpus of Non-Native English", "author": ["Daniel Blanchard", "Joel Tetreault", "Derrick Higgins", "Aoife Cahill", "Martin Chodorow"], "venue": "Technical report, Educational Testing Service,", "citeRegEx": "Blanchard et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Blanchard et al\\.", "year": 2013}, {"title": "Bagging predictors", "author": ["Leo Breiman"], "venue": "In Machine Learning,", "citeRegEx": "Breiman.,? \\Q1996\\E", "shortCiteRegEx": "Breiman.", "year": 1996}, {"title": "Native Language Detection with \u201ccheap\u201d learner corpora. In Twenty Years of Learner Corpus Research", "author": ["Julian Brooke", "Graeme Hirst"], "venue": "Looking Back, Moving Ahead: Proceedings of the First Learner Corpus Research Conference (LCR 2011),", "citeRegEx": "Brooke and Hirst.,? \\Q2011\\E", "shortCiteRegEx": "Brooke and Hirst.", "year": 2011}, {"title": "Measuring interlanguage: Native language identification with L1influence metrics", "author": ["Julian Brooke", "Graeme Hirst"], "venue": "In Proceedings of the Eight International Conference on Language Resources and Evaluation", "citeRegEx": "Brooke and Hirst.,? \\Q2012\\E", "shortCiteRegEx": "Brooke and Hirst.", "year": 2012}, {"title": "Robust, Lexicalized Native Language Identification", "author": ["Julian Brooke", "Graeme Hirst"], "venue": "In Proceedings of COLING", "citeRegEx": "Brooke and Hirst.,? \\Q2012\\E", "shortCiteRegEx": "Brooke and Hirst.", "year": 2012}, {"title": "Exploring Syntactic Features for Native Language Identification: A Variationist Perspective on Feature Encoding and Ensemble Optimization", "author": ["Serhiy Bykh", "Detmar Meurers"], "venue": "In Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,", "citeRegEx": "Bykh and Meurers.,? \\Q2014\\E", "shortCiteRegEx": "Bykh and Meurers.", "year": 2014}, {"title": "Combining shallow and linguistically motivated features in native language identification", "author": ["Serhiy Bykh", "Sowmya Vajjala", "Julia Krivanek", "Detmar Meurers"], "venue": "In Proceedings of the Eighth Workshop on Innovative Use of NLP for Building Educational Applications,", "citeRegEx": "Bykh et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bykh et al\\.", "year": 2013}, {"title": "Linguistic profiling based on general\u2013purpose features and native language identification", "author": ["Andrea Cimino", "Felice Dell\u2019Orletta", "Giulia Venturi", "Simonetta Montemagni"], "venue": "In Proceedings of the Eighth Workshop on Innovative Use of NLP for Building Educational Applications,", "citeRegEx": "Cimino et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Cimino et al\\.", "year": 2013}, {"title": "Conference on Empirical Methods in Natural Language Processing (EMNLP 2002), chapter Discriminative Training Methods for Hidden Markov Models: Theory and Experiments with Perceptron Algorithms", "author": ["Michael Collins"], "venue": null, "citeRegEx": "Collins.,? \\Q2002\\E", "shortCiteRegEx": "Collins.", "year": 2002}, {"title": "Incremental parsing with the perceptron algorithm", "author": ["Michael Collins", "Brian Roark"], "venue": "In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics", "citeRegEx": "Collins and Roark.,? \\Q2004\\E", "shortCiteRegEx": "Collins and Roark.", "year": 2004}, {"title": "Nearest neighbor pattern classification", "author": ["Thomas M Cover", "Peter E Hart"], "venue": "Information Theory, IEEE Transactions on,", "citeRegEx": "Cover and Hart.,? \\Q1967\\E", "shortCiteRegEx": "Cover and Hart.", "year": 1967}, {"title": "Generating typed dependency parses from phrase structure parses", "author": ["Marie-Catherine de Marneffe", "Bill Maccartney", "Christopher D. Manning"], "venue": "In Proceedings of the Fifth International Conference on Language Resources and Evaluation", "citeRegEx": "Marneffe et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Marneffe et al\\.", "year": 2006}, {"title": "Approximate statistical tests for comparing supervised classification learning algorithms", "author": ["Thomas G Dietterich"], "venue": "Neural computation,", "citeRegEx": "Dietterich.,? \\Q1998\\E", "shortCiteRegEx": "Dietterich.", "year": 1998}, {"title": "The Power of Depth for Feedforward Neural Networks", "author": ["Ronen Eldan", "Ohad Shamir"], "venue": "JMLR: Workshop and Conference Proceedings,", "citeRegEx": "Eldan and Shamir.,? \\Q2016\\E", "shortCiteRegEx": "Eldan and Shamir.", "year": 2016}, {"title": "The use of multiple measurements in taxonomic problems", "author": ["Ronald A Fisher"], "venue": "Annals of Eugenics,", "citeRegEx": "Fisher.,? \\Q1936\\E", "shortCiteRegEx": "Fisher.", "year": 1936}, {"title": "Thematic map comparison", "author": ["Giles M Foody"], "venue": "Photogrammetric Engineering & Remote Sensing,", "citeRegEx": "Foody.,? \\Q2004\\E", "shortCiteRegEx": "Foody.", "year": 2004}, {"title": "Experiments with a new boosting algorithm", "author": ["Yoav Freund", "Robert E Schapire"], "venue": "In ICML,", "citeRegEx": "Freund and Schapire.,? \\Q1996\\E", "shortCiteRegEx": "Freund and Schapire.", "year": 1996}, {"title": "Round Robin Classification", "author": ["Johannes F\u00fcrnkranz"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "F\u00fcrnkranz.,? \\Q2002\\E", "shortCiteRegEx": "F\u00fcrnkranz.", "year": 2002}, {"title": "Large-scale Bayesian logistic regression for text", "author": ["Alexander Genkin", "David D Lewis", "David Madigan"], "venue": "categorization. Technometrics,", "citeRegEx": "Genkin et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Genkin et al\\.", "year": 2007}, {"title": "Extremely randomized trees", "author": ["Pierre Geurts", "Damien Ernst", "Louis Wehenkel"], "venue": "Machine learning,", "citeRegEx": "Geurts et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Geurts et al\\.", "year": 2006}, {"title": "A primer on neural network models for natural language processing", "author": ["Yoav Goldberg"], "venue": "The Computing Research Repository (CoRR),", "citeRegEx": "Goldberg.,? \\Q2015\\E", "shortCiteRegEx": "Goldberg.", "year": 2015}, {"title": "Feature space selection and combination for native language identification", "author": ["Cyril Goutte", "Serge L\u00e9ger", "Marine Carpuat"], "venue": "In Proceedings of the Eighth Workshop on Innovative Use of NLP for Building Educational Applications,", "citeRegEx": "Goutte et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Goutte et al\\.", "year": 2013}, {"title": "International Corpus of Learner English (Version 2)", "author": ["Sylviane Granger", "Estelle Dagneaux", "Fanny Meunier", "Magali Paquot"], "venue": "Presses Universitaires de Louvain, Louvian-la-Neuve,", "citeRegEx": "Granger et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Granger et al\\.", "year": 2009}, {"title": "A Closer Look at Skip-gram Modelling", "author": ["David Guthrie", "Ben Allison", "Wei Liu", "Louise Guthrie", "Yorick Wilks"], "venue": "In Proceedings of the Fifth International Conference on Language Resources and Evaluation (LREC", "citeRegEx": "Guthrie et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Guthrie et al\\.", "year": 2006}, {"title": "Native language identification: a simple ngram based approach", "author": ["Binod Gyawali", "Gabriela Ramirez", "Thamar Solorio"], "venue": "In Proceedings of the Eighth Workshop on Innovative Use of NLP for Building Educational Applications,", "citeRegEx": "Gyawali et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Gyawali et al\\.", "year": 2013}, {"title": "The Elements of Statistical Learning: Data Mining, Inference, and Prediction", "author": ["Trevor Hastie", "Robert Tibshirani", "Jerome H. Friedman"], "venue": null, "citeRegEx": "Hastie et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Hastie et al\\.", "year": 2009}, {"title": "Discriminating non-native english with 350 words", "author": ["John Henderson", "Guido Zarrella", "Craig Pfeifer", "John D. Burger"], "venue": "In Proceedings of the Eighth Workshop on Innovative Use of NLP for Building Educational Applications,", "citeRegEx": "Henderson et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Henderson et al\\.", "year": 2013}, {"title": "Feature engineering in the nli shared task 2013: Charles university submission report", "author": ["Barbora Hladka", "Martin Holub", "Vincent Kriz"], "venue": "In Proceedings of the Eighth Workshop on Innovative Use of NLP for Building Educational Applications,", "citeRegEx": "Hladka et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Hladka et al\\.", "year": 2013}, {"title": "Decision combination in multiple classifier systems", "author": ["Tin Kam Ho", "Jonathan J. Hull", "Sargur N. Srihari"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on,", "citeRegEx": "Ho et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Ho et al\\.", "year": 1994}, {"title": "A practical guide to Support Vector classification", "author": ["Chih-Wei Hsu", "Chih-Chung Chang", "Chih-Jen Lin"], "venue": null, "citeRegEx": "Hsu et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Hsu et al\\.", "year": 2003}, {"title": "Can characters reveal your native language? A language-independent approach to native language identification", "author": ["Radu Tudor Ionescu", "Marius Popescu", "Aoife Cahill"], "venue": "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Ionescu et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Ionescu et al\\.", "year": 2014}, {"title": "String Kernels for Native Language Identification: Insights from Behind the Curtains", "author": ["Radu Tudor Ionescu", "Marius Popescu", "Aoife Cahill"], "venue": null, "citeRegEx": "Ionescu et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Ionescu et al\\.", "year": 2016}, {"title": "Approaching Language Transfer Through Text Classification: Explorations in the Detection-based Approach, volume 64", "author": ["Scott Jarvis", "Scott Crossley", "editors"], "venue": "Multilingual Matters Limited,", "citeRegEx": "Jarvis et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Jarvis et al\\.", "year": 2012}, {"title": "Maximizing classification accuracy in native language identification", "author": ["Scott Jarvis", "Yves Bestgen", "Steve Pepper"], "venue": "In Proceedings of the Eighth Workshop on Innovative Use of NLP for Building Educational Applications,", "citeRegEx": "Jarvis et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Jarvis et al\\.", "year": 2013}, {"title": "ECML-98: Proceedings of the 10th European Conference on Machine Learning, chapter Text categorization with Support Vector Machines: Learning with many relevant features, pages 137\u2013142", "author": ["Thorsten Joachims"], "venue": null, "citeRegEx": "Joachims.,? \\Q1998\\E", "shortCiteRegEx": "Joachims.", "year": 1998}, {"title": "Pcfgs, topic models, adaptor grammars and learning topical collocations and the structure of proper names", "author": ["Mark Johnson"], "venue": "In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Johnson.,? \\Q2010\\E", "shortCiteRegEx": "Johnson.", "year": 2010}, {"title": "On combining classifiers", "author": ["Josef Kittler", "Mohamad Hatef", "Robert PW Duin", "Jiri Matas"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Kittler et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Kittler et al\\.", "year": 1998}, {"title": "A study of cross-validation and bootstrap for accuracy estimation and model selection", "author": ["Ron Kohavi"], "venue": "In IJCAI,", "citeRegEx": "Kohavi.,? \\Q1995\\E", "shortCiteRegEx": "Kohavi.", "year": 1995}, {"title": "Automatically determining an anonymous author\u2019s native language", "author": ["Moshe Koppel", "Jonathan Schler", "Kfir Zigdon"], "venue": "In Intelligence and Security Informatics,", "citeRegEx": "Koppel et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Koppel et al\\.", "year": 2005}, {"title": "A theoretical study on six classifier fusion strategies", "author": ["Ludmila I Kuncheva"], "venue": "IEEE Transactions on pattern analysis and machine intelligence,", "citeRegEx": "Kuncheva.,? \\Q2002\\E", "shortCiteRegEx": "Kuncheva.", "year": 2002}, {"title": "Combining Pattern Classifiers: Methods and Algorithms", "author": ["Ludmila I Kuncheva"], "venue": null, "citeRegEx": "Kuncheva.,? \\Q2004\\E", "shortCiteRegEx": "Kuncheva.", "year": 2004}, {"title": "Combining Pattern Classifiers: Methods and Algorithms", "author": ["Ludmila I Kuncheva"], "venue": "Wiley, second edition,", "citeRegEx": "Kuncheva.,? \\Q2014\\E", "shortCiteRegEx": "Kuncheva.", "year": 2014}, {"title": "Rod\u0155\u0131guez. A weighted voting framework for classifiers ensembles", "author": ["Ludmila I Kuncheva", "Juan J"], "venue": "Knowledge and Information Systems,", "citeRegEx": "Kuncheva and J,? \\Q2014\\E", "shortCiteRegEx": "Kuncheva and J", "year": 2014}, {"title": "Decision templates for multiple classifier fusion: an experimental comparison", "author": ["Ludmila I Kuncheva", "James C Bezdek", "Robert PW Duin"], "venue": "Pattern Recognition,", "citeRegEx": "Kuncheva et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Kuncheva et al\\.", "year": 2001}, {"title": "Limits on the majority vote accuracy in classifier fusion", "author": ["Ludmila I Kuncheva", "Christopher J Whitaker", "Catherine A Shipp", "Robert PW Duin"], "venue": "Pattern Analysis & Applications,", "citeRegEx": "Kuncheva et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Kuncheva et al\\.", "year": 2003}, {"title": "Gabor feature based classification using the enhanced fisher linear discriminant model for face recognition", "author": ["Chengjun Liu", "Harry Wechsler"], "venue": "IEEE Transactions on Image processing,", "citeRegEx": "Liu and Wechsler.,? \\Q2002\\E", "shortCiteRegEx": "Liu and Wechsler.", "year": 2002}, {"title": "Arabic Native Language Identification", "author": ["Shervin Malmasi", "Mark Dras"], "venue": "In Proceedings of the Arabic Natural Language Processing Workshop,", "citeRegEx": "Malmasi and Dras.,? \\Q2014\\E", "shortCiteRegEx": "Malmasi and Dras.", "year": 2014}, {"title": "Chinese Native Language Identification", "author": ["Shervin Malmasi", "Mark Dras"], "venue": "Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics,", "citeRegEx": "Malmasi and Dras.,? \\Q2014\\E", "shortCiteRegEx": "Malmasi and Dras.", "year": 2014}, {"title": "Finnish Native Language Identification", "author": ["Shervin Malmasi", "Mark Dras"], "venue": "In Australasian Language Technology Association Workshop", "citeRegEx": "Malmasi and Dras.,? \\Q2014\\E", "shortCiteRegEx": "Malmasi and Dras.", "year": 2014}, {"title": "Large-scale Native Language Identification with Cross-Corpus Evaluation", "author": ["Shervin Malmasi", "Mark Dras"], "venue": "In Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics (NAACL-HLT", "citeRegEx": "Malmasi and Dras.,? \\Q2015\\E", "shortCiteRegEx": "Malmasi and Dras.", "year": 2015}, {"title": "Multilingual Native Language Identification", "author": ["Shervin Malmasi", "Mark Dras"], "venue": "In Natural Language Engineering, pages 1\u201353,", "citeRegEx": "Malmasi and Dras.,? \\Q2015\\E", "shortCiteRegEx": "Malmasi and Dras.", "year": 2015}, {"title": "NLI Shared Task 2013: MQ Submission", "author": ["Shervin Malmasi", "Sze-Meng Jojo Wong", "Mark Dras"], "venue": "In Proceedings of the Eighth Workshop on Innovative Use of NLP for Building Educational Applications,", "citeRegEx": "Malmasi et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Malmasi et al\\.", "year": 2013}, {"title": "Norwegian Native Language Identification", "author": ["Shervin Malmasi", "Mark Dras", "Irina Temnikova"], "venue": "In Proceedings of Recent Advances in Natural Language Processing (RANLP", "citeRegEx": "Malmasi et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Malmasi et al\\.", "year": 2015}, {"title": "Oracle and Human Baselines for Native Language Identification", "author": ["Shervin Malmasi", "Joel Tetreault", "Mark Dras"], "venue": "In Proceedings of the Tenth Workshop on Innovative Use of NLP for Building Educational Applications,", "citeRegEx": "Malmasi et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Malmasi et al\\.", "year": 2015}, {"title": "Discriminating between similar languages and arabic dialect identification: A report on the third dsl shared task", "author": ["Shervin Malmasi", "Marcos Zampieri", "Nikola Ljube\u0161i\u0107", "Preslav Nakov", "Ahmed Ali", "Liling Tan", "J\u00f6rg Tiedemann"], "venue": "In Proceedings of the Joint Workshop on Language Technology for Closely Related Languages, Varieties and Dialects (LT4VarDial),", "citeRegEx": "Malmasi et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Malmasi et al\\.", "year": 2016}, {"title": "Computational Linguistics and Deep Learning", "author": ["Christopher D. Manning"], "venue": "Computational Linguistics,", "citeRegEx": "Manning.,? \\Q2015\\E", "shortCiteRegEx": "Manning.", "year": 2015}, {"title": "Evaluation in information retrieval. In Introduction to Information Retrieval, pages 151\u2013175", "author": ["Christopher D Manning", "Prabhakar Raghavan", "Hinrich Sch\u00fctze"], "venue": null, "citeRegEx": "Manning et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Manning et al\\.", "year": 2008}, {"title": "The Stanford CoreNLP Natural Language Processing Toolkit", "author": ["Christopher D. Manning", "Mihai Surdeanu", "John Bauer", "Jenny Finkel", "Steven J. Bethard", "David McClosky"], "venue": "In Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations,", "citeRegEx": "Manning et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Manning et al\\.", "year": 2014}, {"title": "Note on the sampling error of the difference between correlated proportions or percentages", "author": ["Quinn McNemar"], "venue": null, "citeRegEx": "McNemar.,? \\Q1947\\E", "shortCiteRegEx": "McNemar.", "year": 1947}, {"title": "Inference and Disputed Authorship: The Federalist", "author": ["Frederick Mosteller", "David L. Wallace"], "venue": null, "citeRegEx": "Mosteller and Wallace.,? \\Q1964\\E", "shortCiteRegEx": "Mosteller and Wallace.", "year": 1964}, {"title": "Understanding Second Language Acquisition", "author": ["Lourdes Ortega"], "venue": "Hodder Education, Oxford,", "citeRegEx": "Ortega.,? \\Q2009\\E", "shortCiteRegEx": "Ortega.", "year": 2009}, {"title": "Classifier ensembles: Select real-world applications", "author": ["Nikunj C Oza", "Kagan Tumer"], "venue": "Information Fusion,", "citeRegEx": "Oza and Tumer.,? \\Q2008\\E", "shortCiteRegEx": "Oza and Tumer.", "year": 2008}, {"title": "Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods", "author": ["John Platt"], "venue": "Advances in Large Margin Classifiers,", "citeRegEx": "Platt.,? \\Q2000\\E", "shortCiteRegEx": "Platt.", "year": 2000}, {"title": "Ensemble based systems in decision making", "author": ["Robi Polikar"], "venue": "Circuits and Systems Magazine, IEEE,", "citeRegEx": "Polikar.,? \\Q2006\\E", "shortCiteRegEx": "Polikar.", "year": 2006}, {"title": "The story of the characters, the dna and the native language", "author": ["Marius Popescu", "Radu Tudor Ionescu"], "venue": "In Proceedings of the Eighth Workshop on Innovative Use of NLP for Building Educational Applications,", "citeRegEx": "Popescu and Ionescu.,? \\Q2013\\E", "shortCiteRegEx": "Popescu and Ionescu.", "year": 2013}, {"title": "Bayesian tree substitution grammars as a usage-based approach", "author": ["Matt Post", "Daniel Gildea"], "venue": "Language and speech,", "citeRegEx": "Post and Gildea.,? \\Q2013\\E", "shortCiteRegEx": "Post and Gildea.", "year": 2013}, {"title": "The perceptron: a probabilistic model for information storage and organization in the brain", "author": ["Frank Rosenblatt"], "venue": "Psychological review,", "citeRegEx": "Rosenblatt.,? \\Q1958\\E", "shortCiteRegEx": "Rosenblatt.", "year": 1958}, {"title": "Native Language Detection with Tree Substitution Grammars. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 193\u2013197", "author": ["Benjamin Swanson", "Eugene Charniak"], "venue": null, "citeRegEx": "Swanson and Charniak.,? \\Q2012\\E", "shortCiteRegEx": "Swanson and Charniak.", "year": 2012}, {"title": "The \u201dHows\u201d and the \u201dWhys\u201d of Coding Categories in a Learner Corpus (or \u201dHow and Why an Error-Tagged Learner Corpus is not ipso facto One Big Comparative Fallacy\u201d)", "author": ["Kari Tenfjord", "Hilde Johansen", "Jon Erik Hagen"], "venue": "Rivista di psicolinguistica applicata,", "citeRegEx": "Tenfjord et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Tenfjord et al\\.", "year": 2006}, {"title": "The ASK corpus: A language learner corpus of Norwegian as a second language", "author": ["Kari Tenfjord", "Paul Meurer", "Knut Hofland"], "venue": "In Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC),", "citeRegEx": "Tenfjord et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Tenfjord et al\\.", "year": 2006}, {"title": "Norsk andrespr\u030aakskorpus - A corpus of Norwegian as a second language", "author": ["Kari Tenfjord", "Paul Meurer", "Silje Ragnhildstveit"], "venue": "In Learner Corpus Research Conference (LCR", "citeRegEx": "Tenfjord et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Tenfjord et al\\.", "year": 2013}, {"title": "Native Tongues, Lost and Found: Resources and Empirical Evaluations in Native Language Identification", "author": ["Joel Tetreault", "Daniel Blanchard", "Aoife Cahill", "Martin Chodorow"], "venue": "In Proceedings of COLING", "citeRegEx": "Tetreault et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Tetreault et al\\.", "year": 2012}, {"title": "A report on the first native language identification shared task", "author": ["Joel Tetreault", "Daniel Blanchard", "Aoife Cahill"], "venue": "In Proceedings of the Eighth Workshop on Innovative Use of NLP for Building Educational Applications,", "citeRegEx": "Tetreault et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Tetreault et al\\.", "year": 2013}, {"title": "Diagnosis of multiple cancer types by shrunken centroids of gene expression", "author": ["Robert Tibshirani", "Trevor Hastie", "Balasubramanian Narasimhan", "Gilbert Chu"], "venue": "Proceedings of the National Academy of Sciences,", "citeRegEx": "Tibshirani et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Tibshirani et al\\.", "year": 2002}, {"title": "The Jinan Chinese Learner Corpus", "author": ["Maolin Wang", "Shervin Malmasi", "Mingxuan Huang"], "venue": "In Proceedings of the Tenth Workshop on Innovative Use of NLP for Building Educational Applications,", "citeRegEx": "Wang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2015}, {"title": "Neural network credit scoring models", "author": ["David West"], "venue": "Computers & Operations Research,", "citeRegEx": "West.,? \\Q2000\\E", "shortCiteRegEx": "West.", "year": 2000}, {"title": "Stacked Generalization", "author": ["David H Wolpert"], "venue": "Neural Networks,", "citeRegEx": "Wolpert.,? \\Q1992\\E", "shortCiteRegEx": "Wolpert.", "year": 1992}, {"title": "Contrastive Analysis and Native Language Identification", "author": ["Sze-Meng Jojo Wong", "Mark Dras"], "venue": "In Proceedings of the Australasian Language Technology Association Workshop (ALTA),", "citeRegEx": "Wong and Dras.,? \\Q2009\\E", "shortCiteRegEx": "Wong and Dras.", "year": 2009}, {"title": "Exploiting Parse Structures for Native Language Identification", "author": ["Sze-Meng Jojo Wong", "Mark Dras"], "venue": "In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Wong and Dras.,? \\Q2011\\E", "shortCiteRegEx": "Wong and Dras.", "year": 2011}, {"title": "A survey of multiple classifier systems as hybrid systems", "author": ["l Wo\u017aniak", "Manuel Gra\u00f1a", "Emilio Corchado"], "venue": "Information Fusion,", "citeRegEx": "Wo\u017aniak et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Wo\u017aniak et al\\.", "year": 2014}, {"title": "Text categorization based on regularized linear classification methods", "author": ["Tong Zhang", "Frank J Oles"], "venue": "Information retrieval,", "citeRegEx": "Zhang and Oles.,? \\Q2001\\E", "shortCiteRegEx": "Zhang and Oles.", "year": 2001}, {"title": "Classification of gene microarrays by penalized logistic regression", "author": ["Ji Zhu", "Trevor Hastie"], "venue": "Biostatistics, 5(3):427\u2013443,", "citeRegEx": "Zhu and Hastie.,? \\Q2004\\E", "shortCiteRegEx": "Zhu and Hastie.", "year": 2004}], "referenceMentions": [{"referenceID": 62, "context": "This relates to cross-linguistic influence (CLI), a key topic in the field of Second Language Acquisition (SLA) that analyzes transfer effects from the L1 on later learned languages (Ortega, 2009).", "startOffset": 182, "endOffset": 196}, {"referenceID": 74, "context": "Recently this has motivated studies in NLI, a subtype of text classification where the goal is to determine the native language of an author using texts they have written in a second language or L2 (Tetreault et al., 2013).", "startOffset": 198, "endOffset": 222}, {"referenceID": 57, "context": "This has links to the idea of adding layers to increase power in neural network-based deep learning, which has come to be an important approach in NLP over the last couple of years (Manning, 2015); Eldan and Shamir (2016) note that \u201cOverwhelming empirical evidence as well as intuition indicates that having depth in the neural network is indeed important\u201d.", "startOffset": 181, "endOffset": 196}, {"referenceID": 22, "context": "Deep neural networks can in fact be seen as layered classifiers (Goldberg, 2015), and ensemble methods as an alternative way of adding power via additional layers.", "startOffset": 64, "endOffset": 80}, {"referenceID": 56, "context": "In this article we look just at ensemble methods: deep learning has not yet produced state-of-the-art results on related tasks (Malmasi et al., 2016), and our goal is to understand what it is that has made ensemble methods to date in NLI so successful.", "startOffset": 127, "endOffset": 149}, {"referenceID": 15, "context": "This has links to the idea of adding layers to increase power in neural network-based deep learning, which has come to be an important approach in NLP over the last couple of years (Manning, 2015); Eldan and Shamir (2016) note that \u201cOverwhelming empirical evidence as well as intuition indicates that having depth in the neural network is indeed important\u201d.", "startOffset": 198, "endOffset": 222}, {"referenceID": 63, "context": "They have been applied to a wide range of real-world problems and shown to achieve better results compared to single-classifier methods (Oza and Tumer, 2008).", "startOffset": 136, "endOffset": 157}, {"referenceID": 81, "context": "Ensemble methods continue to receive increasing attention from investigators and remain a focus of machine learning research (Wo\u017aniak et al., 2014; Kuncheva and Rod\u0155\u0131guez, 2014).", "startOffset": 125, "endOffset": 177}, {"referenceID": 74, "context": "A detailed review of NLI methods is omitted here for reasons of space, but a thorough exposition is presented in the report from the very first NLI Shared Task that was held in 2013 (Tetreault et al., 2013).", "startOffset": 182, "endOffset": 206}, {"referenceID": 24, "context": "The International Corpus of Learner English (Granger et al., 2009) was widely used until recently, despite its shortcomings being widely noted (Brooke and Hirst, 2012a).", "startOffset": 44, "endOffset": 66}, {"referenceID": 2, "context": "More recently, Toefl11, the first corpus designed for NLI was released (Blanchard et al., 2013).", "startOffset": 71, "endOffset": 95}, {"referenceID": 76, "context": "Recently, Malmasi and Dras (2014b) introduced the Jinan Chinese Learner Corpus (Wang et al., 2015) for NLI and their results indicate that feature performance may be similar across corpora and even L1-L2 pairs.", "startOffset": 79, "endOffset": 98}, {"referenceID": 2, "context": "More recently, Toefl11, the first corpus designed for NLI was released (Blanchard et al., 2013). While it is the largest NLI dataset available, it only contains argumentative essays, limiting analyses to this genre. Research has also expanded to use non-English learner corpora (Malmasi and Dras, 2014a,c). Recently, Malmasi and Dras (2014b) introduced the Jinan Chinese Learner Corpus (Wang et al.", "startOffset": 72, "endOffset": 342}, {"referenceID": 2, "context": "More recently, Toefl11, the first corpus designed for NLI was released (Blanchard et al., 2013). While it is the largest NLI dataset available, it only contains argumentative essays, limiting analyses to this genre. Research has also expanded to use non-English learner corpora (Malmasi and Dras, 2014a,c). Recently, Malmasi and Dras (2014b) introduced the Jinan Chinese Learner Corpus (Wang et al., 2015) for NLI and their results indicate that feature performance may be similar across corpora and even L1-L2 pairs. Similarly, Malmasi et al. (2015a) also proposed using the ASK corpus to conduct NLI research using L2 Norwegian data.", "startOffset": 72, "endOffset": 552}, {"referenceID": 2, "context": "More recently, Toefl11, the first corpus designed for NLI was released (Blanchard et al., 2013). While it is the largest NLI dataset available, it only contains argumentative essays, limiting analyses to this genre. Research has also expanded to use non-English learner corpora (Malmasi and Dras, 2014a,c). Recently, Malmasi and Dras (2014b) introduced the Jinan Chinese Learner Corpus (Wang et al., 2015) for NLI and their results indicate that feature performance may be similar across corpora and even L1-L2 pairs. Similarly, Malmasi et al. (2015a) also proposed using the ASK corpus to conduct NLI research using L2 Norwegian data. In this study we make use of three of these aforementioned corpora: Toefl11, JCLC and ASK; detailed descriptions will be provided in \u00a73. As mentioned earlier, some of the most successful approaches to NLI have used ensemble learning methods. We now present an overview of this ensemble-based NLI research. Tetreault et al. (2012) were the first to propose the use of classifier ensembles for NLI and performed a comprehensive evaluation of the feature types used until that point.", "startOffset": 72, "endOffset": 966}, {"referenceID": 2, "context": "More recently, Toefl11, the first corpus designed for NLI was released (Blanchard et al., 2013). While it is the largest NLI dataset available, it only contains argumentative essays, limiting analyses to this genre. Research has also expanded to use non-English learner corpora (Malmasi and Dras, 2014a,c). Recently, Malmasi and Dras (2014b) introduced the Jinan Chinese Learner Corpus (Wang et al., 2015) for NLI and their results indicate that feature performance may be similar across corpora and even L1-L2 pairs. Similarly, Malmasi et al. (2015a) also proposed using the ASK corpus to conduct NLI research using L2 Norwegian data. In this study we make use of three of these aforementioned corpora: Toefl11, JCLC and ASK; detailed descriptions will be provided in \u00a73. As mentioned earlier, some of the most successful approaches to NLI have used ensemble learning methods. We now present an overview of this ensemble-based NLI research. Tetreault et al. (2012) were the first to propose the use of classifier ensembles for NLI and performed a comprehensive evaluation of the feature types used until that point. In their study they used an ensemble of logistic regression learners using a wide range of features that included character and word n-grams, function words, parts of speech, spelling errors and writing quality markers. With regard to syntactic features, they also investigated the use of Tree Substitution Grammars and dependency features extracted using the Stanford parser. Furthermore, they also proposed using language models for this task and in their system used language model perplexity scores based on lexical 5-grams from each language in the corpus. The set of features used here was the largest of any NLI study to date. With this system, the authors reported state of the art accuracies of 90.1% and 80.9% on the ICLE and Toefl11 corpora, respectively. Tetreault et al. (2012) also conducted cross-corpus evaluation, using the 7 common L1 classes between the ICLE and Toefl11 corpora.", "startOffset": 72, "endOffset": 1908}, {"referenceID": 2, "context": "More recently, Toefl11, the first corpus designed for NLI was released (Blanchard et al., 2013). While it is the largest NLI dataset available, it only contains argumentative essays, limiting analyses to this genre. Research has also expanded to use non-English learner corpora (Malmasi and Dras, 2014a,c). Recently, Malmasi and Dras (2014b) introduced the Jinan Chinese Learner Corpus (Wang et al., 2015) for NLI and their results indicate that feature performance may be similar across corpora and even L1-L2 pairs. Similarly, Malmasi et al. (2015a) also proposed using the ASK corpus to conduct NLI research using L2 Norwegian data. In this study we make use of three of these aforementioned corpora: Toefl11, JCLC and ASK; detailed descriptions will be provided in \u00a73. As mentioned earlier, some of the most successful approaches to NLI have used ensemble learning methods. We now present an overview of this ensemble-based NLI research. Tetreault et al. (2012) were the first to propose the use of classifier ensembles for NLI and performed a comprehensive evaluation of the feature types used until that point. In their study they used an ensemble of logistic regression learners using a wide range of features that included character and word n-grams, function words, parts of speech, spelling errors and writing quality markers. With regard to syntactic features, they also investigated the use of Tree Substitution Grammars and dependency features extracted using the Stanford parser. Furthermore, they also proposed using language models for this task and in their system used language model perplexity scores based on lexical 5-grams from each language in the corpus. The set of features used here was the largest of any NLI study to date. With this system, the authors reported state of the art accuracies of 90.1% and 80.9% on the ICLE and Toefl11 corpora, respectively. Tetreault et al. (2012) also conducted cross-corpus evaluation, using the 7 common L1 classes between the ICLE and Toefl11 corpora. Training on the ICLE data, they report an accuracy of 26.6%. The very first shared task focusing on Native Language Identification was held in 2013, bringing further focus, interest and attention to the field. The NLI Shared Task 2013 was co-located with the eighth instalment of the Building Educational Applications Workshop at NAACL-HLT 2013. The competition attracted entries from 29 teams. The winning entry for the shared task was that of Jarvis et al. (2013), with an accuracy of 83.", "startOffset": 72, "endOffset": 2482}, {"referenceID": 28, "context": "The MITRE system (Henderson et al., 2013) is another highly lexicalized system where the primary features used are word, part-of-speech and character n-grams.", "startOffset": 17, "endOffset": 41}, {"referenceID": 23, "context": "Gyawali et al. (2013) utilized lexical and syntactic features based on n-grams of characters, words and part-of-speech tags (using both the Penn TreeBank and Universal Parts Of Speech tagsets), along with perplexity values of character n-grams to build four different models.", "startOffset": 0, "endOffset": 22}, {"referenceID": 8, "context": "In the system designed by Cimino et al. (2013) the authors use a wide set of general purpose features that are designed to be portable across languages, domains and tasks.", "startOffset": 26, "endOffset": 47}, {"referenceID": 8, "context": "In the system designed by Cimino et al. (2013) the authors use a wide set of general purpose features that are designed to be portable across languages, domains and tasks. This set includes features that are lexical (sentence length, document length, type/token ration, character and word n-grams), morphosyntactic (coarse and fine-grained part-of-speech tag n-grams) and syntactic (parse tree and dependencybased features). They report that they found distributional differences across the L1s for many of these features, including average word and sentence lengths. However, we note that many of these differences are not of a large magnitude, and the authors did not run any statistical tests to measure the significance levels of these differences. Using this feature set, they experiment with a single-classifier system as well as classifier ensembles, using SVM and Maximum Entropy classifiers. In their ensemble, they experiment with using a majority voting system as well as a meta-classifier approach. The authors report that the ensemble methods outperform all single-classifier systems (by around 2%), and their best performance of 77.9% is provided by the meta-classifier system which used linear SVM and MaxEnt as the component classifiers and combined the results using a polynomial kernel SVM classifier. While the set of features used in this experiment is not widely different to other reported NLI research, their use of a meta-classifier is an interesting approach that warrants further study. In their system, Goutte et al. (2013) used character, word and part-of-speech n-grams along with syntactic dependencies.", "startOffset": 26, "endOffset": 1551}, {"referenceID": 8, "context": "In the system designed by Cimino et al. (2013) the authors use a wide set of general purpose features that are designed to be portable across languages, domains and tasks. This set includes features that are lexical (sentence length, document length, type/token ration, character and word n-grams), morphosyntactic (coarse and fine-grained part-of-speech tag n-grams) and syntactic (parse tree and dependencybased features). They report that they found distributional differences across the L1s for many of these features, including average word and sentence lengths. However, we note that many of these differences are not of a large magnitude, and the authors did not run any statistical tests to measure the significance levels of these differences. Using this feature set, they experiment with a single-classifier system as well as classifier ensembles, using SVM and Maximum Entropy classifiers. In their ensemble, they experiment with using a majority voting system as well as a meta-classifier approach. The authors report that the ensemble methods outperform all single-classifier systems (by around 2%), and their best performance of 77.9% is provided by the meta-classifier system which used linear SVM and MaxEnt as the component classifiers and combined the results using a polynomial kernel SVM classifier. While the set of features used in this experiment is not widely different to other reported NLI research, their use of a meta-classifier is an interesting approach that warrants further study. In their system, Goutte et al. (2013) used character, word and part-of-speech n-grams along with syntactic dependencies. They used an ensemble of SVM classifiers trained on each feature space, using a majority vote combiner method. To represent the feature values, they use two value normalization methods based on TF-IDF and cosine normalization. Their best entry achieved an accuracy of 81.8%, higher than many systems using the same standard features and more, demonstrating the effectiveness of using ensemble classifiers and appropriate feature value representation. The authors, like many others, also note that lexical features provided the best performance for a single feature in their system, but that this can be boosted by combining multiple predictors. The MITRE system (Henderson et al., 2013) is another highly lexicalized system where the primary features used are word, part-of-speech and character n-grams. In this system, these features are used by independent classifiers (logistic regression, Winnow2 and language models) whose output is then combined into a final prediction using a N\u00e4\u0131ve Bayes model. Their best performing ensemble was 82.6% accurate in the shared task and the authors emphasize the value of ensemble methods that combine independent systems. Furthermore, the authors also optimized the parameters of their Naive Bayes model using a grid search over the development data. Hladka et al. (2013) developed an ensemble classifier system using some standard features (lemma, word and part-of-speech n-grams, word skipgrams) with SVM classifiers.", "startOffset": 26, "endOffset": 2946}, {"referenceID": 8, "context": "Another system that utilizes an ensemble is that of Bykh et al. (2013), where they used a probabilitybased ensemble.", "startOffset": 52, "endOffset": 71}, {"referenceID": 33, "context": "Recently they expanded their approach with additional experiments (Ionescu et al., 2016), although they did not achieve further improvements on Toefl11-Test.", "startOffset": 66, "endOffset": 88}, {"referenceID": 7, "context": "Following the shared task, Bykh and Meurers (2014) further explored the use of lexicalized and non-lexicalized phrase structure rules for NLI.", "startOffset": 27, "endOffset": 51}, {"referenceID": 7, "context": "Following the shared task, Bykh and Meurers (2014) further explored the use of lexicalized and non-lexicalized phrase structure rules for NLI. They show that the inclusion of lexicalized production rules (i.e. preterminal nodes and terminals) provides improved results. In addition to the standard normalized frequency and binary feature representations they also propose two new representations based on a \u201cvariationist sociolinguistic\u201d perspective. Although they show that these representations outperform the normalized frequency approach, they do not compare this to other representations which have been shown to improve NLI accuracy, such as TF-IDF. They combine their lexicalized production rules feature with additional surface n-gram features in a tuned and optimized ensemble, reporting an accuracy of 84.82% on the Toefl11-Test set. Ionescu et al. (2014) extend the previous work of Popescu and Ionescu (2013) which used string kernels to perform NLI using only character n-gram features.", "startOffset": 27, "endOffset": 866}, {"referenceID": 7, "context": "Following the shared task, Bykh and Meurers (2014) further explored the use of lexicalized and non-lexicalized phrase structure rules for NLI. They show that the inclusion of lexicalized production rules (i.e. preterminal nodes and terminals) provides improved results. In addition to the standard normalized frequency and binary feature representations they also propose two new representations based on a \u201cvariationist sociolinguistic\u201d perspective. Although they show that these representations outperform the normalized frequency approach, they do not compare this to other representations which have been shown to improve NLI accuracy, such as TF-IDF. They combine their lexicalized production rules feature with additional surface n-gram features in a tuned and optimized ensemble, reporting an accuracy of 84.82% on the Toefl11-Test set. Ionescu et al. (2014) extend the previous work of Popescu and Ionescu (2013) which used string kernels to perform NLI using only character n-gram features.", "startOffset": 27, "endOffset": 921}, {"referenceID": 2, "context": "1 The TOEFL11 Corpus The Toefl11 corpus (Blanchard et al., 2013) \u2014 also known as the ETS Corpus of Non-Native Written English \u2014 is the first dataset designed specifically for the task of NLI and developed with the aim of addressing the above-mentioned deficiencies of other previously used corpora.", "startOffset": 40, "endOffset": 64}, {"referenceID": 2, "context": "Diagram reproduced from Blanchard et al. (2013).", "startOffset": 24, "endOffset": 48}, {"referenceID": 4, "context": "Following a similar methodology to that of (Brooke and Hirst, 2011), we randomly select and combine the sentences from the same L1 to generate texts of approximately 300 tokens on average, creating a set of documents suitable for NLI.", "startOffset": 43, "endOffset": 67}, {"referenceID": 2, "context": "Figure reproduced from Blanchard et al. (2013).", "startOffset": 23, "endOffset": 47}, {"referenceID": 76, "context": "Growing interest has led to the recent development of the Jinan Chinese Learner Corpus (Wang et al., 2015), the first large-scale corpus of L2 Chinese consisting of university student essays.", "startOffset": 87, "endOffset": 106}, {"referenceID": 39, "context": "For creating our folds, we employ stratified crossvalidation which aims to ensure that the proportion of classes within each partition is equal (Kohavi, 1995).", "startOffset": 144, "endOffset": 158}, {"referenceID": 36, "context": "Linear Support Vector Machine (SVM) classifiers are a highly robust supervised classification method that has proven to be very effective for text classification (Joachims, 1998).", "startOffset": 162, "endOffset": 178}, {"referenceID": 64, "context": "Additionally, an SVM is a margin-based classifier and does not output probability estimates for each class label, although there are additional methods to map the outputs to probabilities (Platt, 2000).", "startOffset": 188, "endOffset": 201}, {"referenceID": 31, "context": "This is because the kernel maps the data points in a non-linear manner, allowing for more flexible decision boundaries (Hsu et al., 2003).", "startOffset": 119, "endOffset": 137}, {"referenceID": 20, "context": "Although high-dimensional input poses a challenge for these models (Genkin et al., 2007), this issue can be addressed to some degree using regularization methods (Zhu and Hastie, 2004).", "startOffset": 67, "endOffset": 88}, {"referenceID": 83, "context": ", 2007), this issue can be addressed to some degree using regularization methods (Zhu and Hastie, 2004).", "startOffset": 81, "endOffset": 103}, {"referenceID": 20, "context": "Although high-dimensional input poses a challenge for these models (Genkin et al., 2007), this issue can be addressed to some degree using regularization methods (Zhu and Hastie, 2004). This algorithm is inherently multi-class, meaning that OVA and OVO approaches are not required. The logistic regression classifier is also probabilistic and provides continuous probability estimates for each class label. 9Appendix C of Hsu et al. (2003) examines this issue in greater detail.", "startOffset": 68, "endOffset": 440}, {"referenceID": 68, "context": "4 Perceptron The Perceptron (Rosenblatt, 1958) is another linear learning algorithm that has been successful The algorithm learns a weight vector and a bias term which shifts the decision boundary from the origin.", "startOffset": 28, "endOffset": 46}, {"referenceID": 10, "context": "Perceptrons have been successfully used for POS tagging (Collins, 2002) and parsing (Collins and Roark, 2004).", "startOffset": 56, "endOffset": 71}, {"referenceID": 11, "context": "Perceptrons have been successfully used for POS tagging (Collins, 2002) and parsing (Collins and Roark, 2004).", "startOffset": 84, "endOffset": 109}, {"referenceID": 82, "context": "5 Ridge Regression Classification using ridge regression is an approach based on a regression model that uses a linear least squares loss function (Zhang and Oles, 2001).", "startOffset": 147, "endOffset": 169}, {"referenceID": 16, "context": "A classic learning algorithm, Linear Discriminant Analysis (LDA, not to be confused with Latent Dirichlet Allocation) is a method based on a linear decision boundary (Fisher, 1936).", "startOffset": 166, "endOffset": 180}, {"referenceID": 47, "context": "It has been widely and successfully used for classification (Liu and Wechsler, 2002).", "startOffset": 60, "endOffset": 84}, {"referenceID": 27, "context": "Quadratic Discriminant Analysis (QDA) is similar to LDA, except that it uses a quadratic decision surface (Hastie et al., 2009).", "startOffset": 106, "endOffset": 127}, {"referenceID": 12, "context": "9 k-nearest Neighbors A popular neighbor-based algorithm, k-nearest Neighbors (k-NN) is an instance-based classifier that does not build a statistical model (Cover and Hart, 1967).", "startOffset": 157, "endOffset": 179}, {"referenceID": 75, "context": "mean) vector for each class (Tibshirani et al., 2002).", "startOffset": 28, "endOffset": 53}, {"referenceID": 64, "context": "10There exist additional methods to map these distances to probabilities (Platt, 2000).", "startOffset": 73, "endOffset": 86}, {"referenceID": 61, "context": "Function words\u2019 topic independence has led them to be widely used in studies of authorship attribution (Mosteller and Wallace, 1964) as well as NLI and they have been established to be informative for these tasks.", "startOffset": 103, "endOffset": 132}, {"referenceID": 47, "context": "For Chinese, we utilize the function word list described in Malmasi and Dras (2014b). In addition to single function words, we also extract function word bigrams, as described by Malmasi et al.", "startOffset": 60, "endOffset": 85}, {"referenceID": 47, "context": "For Chinese, we utilize the function word list described in Malmasi and Dras (2014b). In addition to single function words, we also extract function word bigrams, as described by Malmasi et al. (2013). Function word bigrams are a type of word n-gram where content words are skipped: they are thus a specific subtype of the skip-grams discussed by Guthrie et al.", "startOffset": 60, "endOffset": 201}, {"referenceID": 25, "context": "Function word bigrams are a type of word n-gram where content words are skipped: they are thus a specific subtype of the skip-grams discussed by Guthrie et al. (2006). For example, the sentence \u201cWe should all start taking the bus\u201d would be reduced to \u201cwe should all the\u201d, from which we would extract the n-grams.", "startOffset": 145, "endOffset": 167}, {"referenceID": 53, "context": "We extract POS n-grams of order 1\u20133, which have been shown to be useful for NLI (Malmasi et al., 2013).", "startOffset": 80, "endOffset": 102}, {"referenceID": 59, "context": "For English and Chinese, the Stanford CoreNLP suite of NLP tools (Manning et al., 2014) and the provided models were used to tokenize, POS tag and parse the unsegmented corpus texts.", "startOffset": 65, "endOffset": 87}, {"referenceID": 53, "context": "Additionally, we extract a second set of POS n-grams for the Toefl11 data using the CLAWS dataset, which has been shown to perform well for NLI (Malmasi et al., 2013).", "startOffset": 144, "endOffset": 166}, {"referenceID": 52, "context": "We extract POS n-grams of order 1\u20133, which have been shown to be useful for NLI (Malmasi et al., 2013). These n-grams capture small and very local syntactic patterns of language production and were used as classification features. Previous work and our experiments showed that sequences of size 4 or greater achieve lower accuracy, possibly due to data sparsity, so we do not include them. For English and Chinese, the Stanford CoreNLP suite of NLP tools (Manning et al., 2014) and the provided models were used to tokenize, POS tag and parse the unsegmented corpus texts. We did not use any NLP tools for Norwegian as the corpus we use is already annotated with POS tags. Additionally, we extract a second set of POS n-grams for the Toefl11 data using the CLAWS dataset, which has been shown to perform well for NLI (Malmasi et al., 2013). 11For example, the largest list used by Wong and Dras (2009) was a stopword list from Information Retrieval; given the size of their list, this was presumably also the case for Koppel et al.", "startOffset": 81, "endOffset": 902}, {"referenceID": 40, "context": "11For example, the largest list used by Wong and Dras (2009) was a stopword list from Information Retrieval; given the size of their list, this was presumably also the case for Koppel et al. (2005), although the source there was not given.", "startOffset": 177, "endOffset": 198}, {"referenceID": 37, "context": "We use the grammar proposed by (Johnson, 2010) for capturing topical collocations: Sentence\u2192 Docj j \u2208 1, .", "startOffset": 31, "endOffset": 46}, {"referenceID": 37, "context": "We use the grammar proposed by (Johnson, 2010) for capturing topical collocations: Sentence\u2192 Docj j \u2208 1, . . . ,m Docj \u2192 j j \u2208 1, . . . ,m Docj \u2192 Docj Topici i \u2208 1, . . . , t; j \u2208 1, . . . ,m Topici \u2192Words i \u2208 1, . . . , t Words\u2192Word Words\u2192Words Word Word\u2192 w w \u2208 Vpos; w \u2208 Vpos+fw Vpos contains 119 distinct POS tags based on the Brown tagset and Vpos+fw is extended with 398 function words. The number of topics t is set to 50. The inference algorithm for the adaptor grammars are based on the Markov Chain Monte Carlo technique made available by Johnson (2010).", "startOffset": 32, "endOffset": 563}, {"referenceID": 69, "context": "Reproduced from Swanson and Charniak (2012).", "startOffset": 16, "endOffset": 44}, {"referenceID": 80, "context": "They have been found to be useful for NLI (Wong and Dras, 2011).", "startOffset": 42, "endOffset": 63}, {"referenceID": 67, "context": "TSGs are a generalization of context-free grammars that allow non-terminals to rewrite as fragments which can have an arbitrary size (Post and Gildea, 2013), instead of being limited to a depth of one.", "startOffset": 133, "endOffset": 156}, {"referenceID": 68, "context": "Tree Substitution Grammar (TSG) fragments have been proposed by Swanson and Charniak (2012) as yet another type of syntactic feature for NLI or other syntactically motivated text classification tasks.", "startOffset": 64, "endOffset": 92}, {"referenceID": 3, "context": "For example, Bagging (bootstrap aggregating) is a commonly used method for ensemble generation (Breiman, 1996) that can create multiple base classifiers.", "startOffset": 95, "endOffset": 110}, {"referenceID": 18, "context": "with the AdaBoost algorithm) is another method where the base models are created with different weight distributions over the training data with the aim of assigning higher weights to training instances that are misclassified (Freund and Schapire, 1996).", "startOffset": 226, "endOffset": 253}, {"referenceID": 65, "context": "Although a number of different fusion methods have been proposed and tested, there is no single dominant method (Polikar, 2006).", "startOffset": 112, "endOffset": 127}, {"referenceID": 65, "context": "Our selected methods are described below; a variety of other methods exist and the interested reader can refer to the thorough exposition by (Polikar, 2006).", "startOffset": 141, "endOffset": 156}, {"referenceID": 38, "context": "155) and resilient to estimation errors (Kittler et al., 1998), making it one of the more robust combiners discussed in the literature.", "startOffset": 40, "endOffset": 62}, {"referenceID": 38, "context": "Given that the mean probability used in the above rule is sensitive to outliers, an alternative is to use the median as a more robust estimate of the mean (Kittler et al., 1998).", "startOffset": 155, "endOffset": 177}, {"referenceID": 30, "context": "The winning label is then selected using the Borda count algorithm (Ho et al., 1994).", "startOffset": 67, "endOffset": 84}, {"referenceID": 45, "context": "This method has previously been used to analyze the limits of majority vote classifier combination (Kuncheva et al., 2001).", "startOffset": 99, "endOffset": 122}, {"referenceID": 41, "context": "Oracles are usually used in comparative experiments and to gauge the performance and diversity of the classifiers chosen for an ensemble (Kuncheva, 2002; Kuncheva et al., 2003).", "startOffset": 137, "endOffset": 176}, {"referenceID": 46, "context": "Oracles are usually used in comparative experiments and to gauge the performance and diversity of the classifiers chosen for an ensemble (Kuncheva, 2002; Kuncheva et al., 2003).", "startOffset": 137, "endOffset": 176}, {"referenceID": 58, "context": "This method is inspired by the \u201cPrecision at k\u201d metric from Information Retrieval (Manning et al., 2008) which measures precision at fixed low levels of results (e.", "startOffset": 82, "endOffset": 104}, {"referenceID": 78, "context": "For our second model we expand our methodology to such a meta-classifier, also referred to as stacked generalization or classifier stacking (Wolpert, 1992).", "startOffset": 140, "endOffset": 155}, {"referenceID": 21, "context": "These methods have been widely used for creating decision tree ensembles (Geurts et al., 2006); we will experiment with random forests, extra trees and the AdaBoost algorithm.", "startOffset": 73, "endOffset": 94}, {"referenceID": 35, "context": "We also compare these results against the winning system from the 2013 NLI shared task (Jarvis et al., 2013) and two systems by (Bykh and Meurers, 2014) and (Ionescu et al.", "startOffset": 87, "endOffset": 108}, {"referenceID": 7, "context": ", 2013) and two systems by (Bykh and Meurers, 2014) and (Ionescu et al.", "startOffset": 27, "endOffset": 51}, {"referenceID": 32, "context": ", 2013) and two systems by (Bykh and Meurers, 2014) and (Ionescu et al., 2014) which presented state-of-the-art results following the task.", "startOffset": 56, "endOffset": 78}, {"referenceID": 7, "context": "Baselines Random Baseline 9\u00b71 9\u00b71 2013 Shared Task Winner 84\u00b75 83\u00b70 Bykh and Meurers (2014) \u2014 84\u00b78 Ionescu et al.", "startOffset": 68, "endOffset": 92}, {"referenceID": 7, "context": "Baselines Random Baseline 9\u00b71 9\u00b71 2013 Shared Task Winner 84\u00b75 83\u00b70 Bykh and Meurers (2014) \u2014 84\u00b78 Ionescu et al. (2014) 84\u00b71 85\u00b73", "startOffset": 68, "endOffset": 121}, {"referenceID": 7, "context": "Baselines Random Baseline 9\u00b71 9\u00b71 2013 Shared Task Winner 84\u00b75 83\u00b70 Bykh and Meurers (2014) \u2014 84\u00b78 Ionescu et al.", "startOffset": 68, "endOffset": 92}, {"referenceID": 7, "context": "Baselines Random Baseline 9\u00b71 9\u00b71 2013 Shared Task Winner 84\u00b75 83\u00b70 Bykh and Meurers (2014) \u2014 84\u00b78 Ionescu et al. (2014) 84\u00b71 85\u00b73 Our LDA Meta-classifier (continuous) 85\u00b72 86\u00b78 Decision Tree Ensembles Random Forest 84\u00b72 84\u00b76 Extra Trees 81\u00b70 82\u00b77 AdaBoost 75\u00b73 76\u00b72", "startOffset": 68, "endOffset": 121}, {"referenceID": 1, "context": "Although a single decision tree was not a good meta-classifier, it has been shown that ensembles of trees can perform very well (Banfield et al., 2007).", "startOffset": 128, "endOffset": 151}, {"referenceID": 14, "context": "An important question that arises in various contexts within machine learning deals with determining which methods outperform others on a given problem (Dietterich, 1998).", "startOffset": 152, "endOffset": 170}, {"referenceID": 60, "context": "McNemar\u2019s test (McNemar, 1947) is a non-parametric method to test for significant differences in proportions for paired nominal data.", "startOffset": 15, "endOffset": 30}, {"referenceID": 14, "context": "In the context of machine learning it is often used to compare the performance of distinct algorithms on the same data (Dietterich, 1998) as it does not assume independent samples and has a low Type I error rate (F\u00fcrnkranz, 2002).", "startOffset": 119, "endOffset": 137}, {"referenceID": 19, "context": "In the context of machine learning it is often used to compare the performance of distinct algorithms on the same data (Dietterich, 1998) as it does not assume independent samples and has a low Type I error rate (F\u00fcrnkranz, 2002).", "startOffset": 212, "endOffset": 229}, {"referenceID": 77, "context": "It is the most commonly used for pairwise classifier comparison and has been used in a wide range of machine learning applications (West, 2000; Aue and Gamon, 2005).", "startOffset": 131, "endOffset": 164}, {"referenceID": 0, "context": "It is the most commonly used for pairwise classifier comparison and has been used in a wide range of machine learning applications (West, 2000; Aue and Gamon, 2005).", "startOffset": 131, "endOffset": 164}, {"referenceID": 0, "context": "It is the most commonly used for pairwise classifier comparison and has been used in a wide range of machine learning applications (West, 2000; Aue and Gamon, 2005). This is also the test we propose for use within NLI. In this section we briefly describe the test and demonstrate its application for NLI. The interested reader can find more details about methods for evaluating the statistical significance of classifier differences in the work of Foody (2004). McNemar\u2019s test is a non-parametric method based on creating a 2\u00d72 contingency table for the outcomes of a pair of tests (classifiers in our case), tabulating the number of instances where their predictions agree or disagree.", "startOffset": 144, "endOffset": 461}, {"referenceID": 14, "context": "The test statistic is based on a chi-square distribution, with additional continuity correction to account for the fact that a continuous distribution is being used to represent a discrete one (Dietterich, 1998; Foody, 2004).", "startOffset": 193, "endOffset": 224}, {"referenceID": 17, "context": "The test statistic is based on a chi-square distribution, with additional continuity correction to account for the fact that a continuous distribution is being used to represent a discrete one (Dietterich, 1998; Foody, 2004).", "startOffset": 193, "endOffset": 224}, {"referenceID": 51, "context": "The work of Malmasi et al. (2015b) was an initial step in this direction by making available all 144 submissions from the 2013 shared task, including that of the winning system.", "startOffset": 12, "endOffset": 35}, {"referenceID": 32, "context": "During the course of this research, Ionescu et al. (2014) also provided us with the predictions from their state-ofthe-art system, which we also make available.", "startOffset": 36, "endOffset": 58}, {"referenceID": 32, "context": "During the course of this research, Ionescu et al. (2014) also provided us with the predictions from their state-ofthe-art system, which we also make available. The availability of this data can become increasingly important as state-of-the-art results move closer towards the oracle upper bounds. We now evaluate the performance of our top model against that of the two previous state-of-the-art systems which were used as baselines in our experiments, using the aforementioned prediction data. We report the pairwise p values for the test, as listed in Table 11. They show that the improvement in our results is significantly better than both of the baselines. In contrast, they also show that the results of Ionescu et al. (2014) were not significantly better than the previous best result.", "startOffset": 36, "endOffset": 733}, {"referenceID": 32, "context": "Ionescu et al. Our Method Jarvis et al. (2013) \u2014 0.", "startOffset": 0, "endOffset": 47}, {"referenceID": 32, "context": "Ionescu et al. Our Method Jarvis et al. (2013) \u2014 0.1082 0.0001* Ionescu et al. (2014) \u2013 \u2014 0.", "startOffset": 0, "endOffset": 86}, {"referenceID": 31, "context": "This differs to the work of Ionescu et al. (2014), where their best results on different sets were achieved using different parameters, or that of Bykh and Meurers (2014), who did not test their method on different datasets.", "startOffset": 28, "endOffset": 50}, {"referenceID": 7, "context": "(2014), where their best results on different sets were achieved using different parameters, or that of Bykh and Meurers (2014), who did not test their method on different datasets.", "startOffset": 104, "endOffset": 128}], "year": 2017, "abstractText": "Ensemble methods using multiple classifiers have proven to be the most successful approach for the task of Native Language Identification (NLI), achieving the current state of the art. However, a systematic examination of ensemble methods for NLI has yet to be conducted. Additionally, deeper ensemble architectures such as classifier stacking have not been closely evaluated. We present a set of experiments using three ensemble-based models, testing each with multiple configurations and algorithms. This includes a rigorous application of meta-classification models for NLI, achieving state-of-the-art results on three datasets from different languages. We also present the first use of statistical significance testing for comparing NLI systems, showing that our results are significantly better than the previous state of the art. We make available a collection of test set predictions to facilitate future statistical tests.", "creator": "LaTeX with hyperref package"}}}