{"id": "1703.06565", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Mar-2017", "title": "Evidence Updating for Stream-Processing in Big-Data: Robust Conditioning in Soft and Hard Fusion Environments", "abstract": "Conditioning is the primary method for belief revision in data fusion systems employing probabilistic inferencing. However, big-data environments, where soft (i.e., human or human-based) sources are commonly utilized in addition to hard (i.e., physics-based sensors, pose several challenges to traditional conditioning tasks primarily due to the numerous data/source imperfections that are characteristic of such data. The objective of this paper is to investigate the most natural extension of Bayes conditioning based evidence updates in the presence of such large-scale data uncertainties and source/sensor imperfections. By viewing the evidence updating process as a thought experiment, we devise an elegant strategy for robust evidence updating in the presence of extreme uncertainties characteristic of big-data environments. In particular, we look at the formulation of a belief theoretic evidence updating mechanism that is derived as a natural extension of Bayes conditional approach when the incoming evidence takes the form of a general belief function. Proposed method generalizes the belief theoretic Fagin-Halpern conditional notion, and provides a novel evidence updating strategy that is derived as a natural extension of Bayes conditional applied in a highly uncertain and complex fusion scenario that is characteristic of big-data environments. The presented extension differs fundamentally from the previously published work on Conditional Update Equation (CUE) as well as authors own work. An overview of this development is provided via illustrative examples. Furthermore, insights into parameter selection under various fusion contexts are also provided.", "histories": [["v1", "Mon, 20 Mar 2017 02:29:53 GMT  (604kb,D)", "https://arxiv.org/abs/1703.06565v1", null], ["v2", "Sat, 10 Jun 2017 12:28:43 GMT  (615kb,D)", "http://arxiv.org/abs/1703.06565v2", "The 20th IEEE International Conference on Information Fusion (Fusion'17)"]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["thanuka wickramarathne"], "accepted": false, "id": "1703.06565"}, "pdf": {"name": "1703.06565.pdf", "metadata": {"source": "CRF", "title": "Evidence Updating for Stream-Processing in Big-Data: Robust Conditioning in Soft and Hard Data Fusion Environments", "authors": ["Thanuka Wickramarathne"], "emails": ["thanuka@uml.edu"], "sections": [{"heading": null, "text": "This year it has come to the point that it has never come as far as this year."}, {"heading": "II. PRELIMINARIES", "text": "a) Basic terms: \"A,\" \"A,\" \"B,\" \"A,\" \"B,\" \"B,\" \"B,\" \"B,\" \"B,\" \"B,\" \"B,\" \"B,\" \"B,\" \"B,\" \"B,\" \"B,\" \"B,\" \"B,\" \"B,\" \"B,\" \"B,\" \"B,\" \"B,\" \"B,\" \"B,\" \"B,\" B, \"\" B, \"B,\" B, \"B,\" B, \"B,\" B, \"B,\" B, \"B,\" B, \"B,\" B, \"B,\" B, \"B,\" B, \"B,\" B, \"B,\" B, \"B,\" B, \"B,\" B, \"B,\" B, \"B,\" B, \"B,\" B, \"B,\" B, \"B,\" B, \"B,\" B, \",\" B, B, \"B,\" B, B, \"B, B,\", B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B,"}, {"heading": "III. CONDITIONING IN SOFT/HARD FUSION ENVIRONMENTS", "text": "Since, in many big data environments, preferences (i.e., human or human-generated) data play a critical role in inferring tasks that are primarily due to their ability to provide complementary (too hard) and critical as well as time-sensitive information, one cannot sacrifice the integrity of the follow-up task simply by conditioning an existing trust. Soft evidence is developed through an experiment to develop a generalized conditioning operation as a direct extension of the Bayes conditioning operation to take these challenges into account. The case of Conditioning EventLet us look at a case where the new evidence comes in the form of an occurrence of one event, but not necessarily with 100% certainty as in the traditional Bayesian conditioning.Example 2 (MVP Poll v.2)."}, {"heading": "IV. BEHAVIOR OF GCU", "text": "Understanding how conditioning affects the focal elements in the current BoE is crucial for a correct understanding of any updating process. (B) The focal elements generated by conditioning can only be used for this task (B). (B) > 0 iff B can be expressed as B = X, for some X (A) and Y (A). (B) > 0 iff B can be expressed as B = X (B). (B) > 0 iff B can be expressed as B = X (A), for some X (A) and Y (A)."}, {"heading": "V. CONCLUDING REMARKS", "text": "Robust verification methods are critical when it comes to streaming data situations, updating existing knowledge or beliefs with new incoming evidence. If the process of evidence updating is viewed as a thought experiment, a novel evidence updating strategy known as the GCU (i.e., generalized conditional updating) is derived, especially in terms of efficient verification and dealing with uncertainty in big data stream processing applications. The proposed enhancement is fundamentally different from previously published work on the conditional approach known as the CUE (i.e. conditional update equation), and allows authors to consider various data / source imperfections characteristic of complex big data fusion environments. The GCU, the proposed evidence updating strategy based on a belief theory conditional approach, has several intuitively responsive features that indicate the quantities of data that appear unsuitable for large-scale scenarios."}, {"heading": "ACKNOWLEDGMENT", "text": "The author thanks Prof. Kamal Premaratne (University of Miami, Coral Gables) for insightful discussions on numerous related topics and the reviewers for their valuable feedback."}], "references": [{"title": "It\u2019s a streaming world! reasoning upon rapidly changing information", "author": ["E.D. Valle", "S. Ceri", "F. v. Harmelen", "D. Fensel"], "venue": "IEEE Intelligent Systems, vol. 24, no. 6, pp. 83\u201389, Nov 2009.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2009}, {"title": "A knowledgebased platform for big data analytics based on publish/subscribe services and stream processing", "author": ["C. Esposito", "M. Ficco", "F. Palmieri", "A. Castiglione"], "venue": "Knowledge-Based Systems, vol. 79, pp. 3 \u2013 17, 2015.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2015}, {"title": "An Uncertainty-Aware Approach to Optimal Configuration of Stream Processing Systems", "author": ["P. Jamshidi", "G. Casale"], "venue": "June 2016. [Online]. Available: https://doi.org/10.5281/zenodo.56238", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2016}, {"title": "Performance modeling and predictive scheduling for distributed stream data processing", "author": ["T. Li", "J. Tang", "J. Xu"], "venue": "IEEE Transactions on Big Data, vol. 2, no. 4, pp. 353\u2013364, Dec 2016.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2016}, {"title": "Predictive complex event processing based on evolving bayesian networks", "author": ["Y. Wang", "H. Gao", "G. Chen"], "venue": "Pattern Recognition Letters, 2017.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2017}, {"title": "Kalman filter versus IMM estimator: When do we need the latter?", "author": ["T. Kirubarajan", "Y. Bar-Shalom"], "venue": "IEEE Transactions on Aerospace and Electronic Systems,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2003}, {"title": "Mathematical Techniques in Multisensor Data Fusion", "author": ["D.L. Hall"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1992}, {"title": "Consensusbased credibility estimation of soft evidence for robust data fusion", "author": ["T.L. Wickramarathne", "K. Premaratne", "M.N. Murthi"], "venue": "Belief Functions, ser. Advances in Intelligent and Soft Computing, T. Denoeux and M.-H. Masson, Eds. Compi\u00e9gne, France: Springer Berlin / Heidelberg, May 2012, vol. 164, pp. 301\u2013309.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Learning Bayesian belief networks: An approach based on the MDL principle", "author": ["W. Lam", "F. Bacchus"], "venue": "Computational Intelligence, vol. 10, pp. 269\u2013293, July 1994.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1994}, {"title": "Learning Bayesian networks: The combination of knowledge and statistical data", "author": ["D. Heckerman", "D. Geiger", "D. Chickering"], "venue": "Machine Learning, vol. 20, no. 3, pp. 197\u2013243, 1994.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1994}, {"title": "Bayesian network classifiers", "author": ["N. Friedman", "D. Geiger", "M. Goldszmidt"], "venue": "Machine Learning, vol. 29, no. 2/3, pp. 131\u2013163, 1997.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1997}, {"title": "Bayesian Networks and Decision Graphs, 1st ed", "author": ["F.V. Jensen"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2001}, {"title": "Bayesian classification for data from the same unknown class", "author": ["H.-J. Huang", "C.-N. Hsu"], "venue": "IEEE Transactions on Systems, Man and Cybernetics, Part B: Cybernetics, vol. 32, no. 2, pp. 137\u2013145, Apr. 2002.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2002}, {"title": "Building Bayesian network models in medicine: The MENTOR experience", "author": ["S. Mani", "M. Valtorta", "S. McDermott"], "venue": "Applied Intelligence, vol. 22, no. 2, pp. 93\u2013108, 2005.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2005}, {"title": "A new approach to updating beliefs", "author": ["R. Fagin", "J.Y. Halpern"], "venue": "Proc. Conference on Uncertainty in Artificial Intelligence (UAI), P. P. Bonissone, M. Henrion, L. N. Kanal, and J. F. Lemmer, Eds. New York, NY: Elsevier Science, 1991, pp. 347\u2013374.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1991}, {"title": "Computational aspects of the M\u00f6bius transformation of graphs", "author": ["R. Kennes"], "venue": "IEEE Transactions on Systems, Man and Cybernetics, vol. 22, no. 2, pp. 201\u2013223, Mar. 1992.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1992}, {"title": "Incremental conditioning of lower and upper probabilities", "author": ["L. Chrisman"], "venue": "International Journal of Approximate Reasoning, vol. 13, no. 1, pp. 1\u201325, July 1995.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1995}, {"title": "Data Fusion in Robotics and Machine Intelligence", "author": ["M.A. Abidi", "R.C. Gonzalez"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1992}, {"title": "Shafer-Demspter reasoning with applications to multisensor target identification systems", "author": ["P.L. Bogler"], "venue": "IEEE Transactions on Systems, Man and Cybernetics, vol. 17, no. 6, pp. 968\u2013977, 1987.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1987}, {"title": "Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference", "author": ["J. Pearl"], "venue": null, "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1988}, {"title": "Belief decision trees: theoretical foundations", "author": ["Z. Elouedi", "K. Mellouli", "P. Smets"], "venue": "International Journal of Approximate Reasoning, vol. 28, no. 2/3, pp. 91\u2013124, Nov. 2001.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2001}, {"title": "Target identification based on the transferable belief model interpretation of Dempster-Shafer model", "author": ["F. Delmotte", "P. Smets"], "venue": "IEEE Transactions on Systems, Man and Cybernetics, Part A: Systems and Humans, vol. 34, no. 4, pp. 457\u2013471, July 2004.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2004}, {"title": "Demspter-Shafer theory for intrusion detection in ad hoc networks", "author": ["T.M. Chen", "V. Venkataramanan"], "venue": "IEEE Internet Computing, vol. 9, no. 6, pp. 35\u201341, Nov./Dec. 2005.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2005}, {"title": "Target identification using belief functions and implication rules", "author": ["B. Ristic", "P. Smets"], "venue": "IEEE Transactions on Aerospace and Electronic Systems, vol. 41, no. 3, pp. 1097\u20131103, July 2005.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2005}, {"title": "Classification using belief functions: the relationship between the case-based and model-based approaches", "author": ["T. Denoeux", "P. Smets"], "venue": "IEEE Transaction on Systems, Man and Cybernetics, Part B: Cybernetics, vol. 36, no. 6, pp. 1395\u20131406, 2006.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2006}, {"title": "Human experts fusion for image classification", "author": ["A. Martin", "C. Osswald"], "venue": "Information and Security: An International Journal, Special Issue on Fusing Uncertain, Imprecise and Conflicting Information, vol. 20, pp. 122\u2013141, May 2006.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2006}, {"title": "Ensemble clustering in the belief functions framework", "author": ["M.H. Masson", "T. Denoeux"], "venue": "International Journal of Approximate Reasoning, vol. 52, no. 1, pp. 92\u2013109, Jan. 2011.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2011}, {"title": "Participatory sensing", "author": ["J. Burke", "D. Estrin", "M. Hansen", "A. Parker", "N. Ramanathan", "S. Reddy", "M.B. Srivastava"], "venue": "Proc. Workshop on World-Sensor-Web (WSW): Mobile Device Centric Sensor Networks and Applications, 2006, pp. 117\u2013134.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2006}, {"title": "Distributed Data Fusion for Network-Centric Operations", "author": ["D. Hall", "M.L. II", "C.-Y. Chong", "J. Linas"], "venue": "Boca Raton, FL: CRC Press,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2012}, {"title": "A Mathematical Theory of Evidence", "author": ["G. Shafer"], "venue": null, "citeRegEx": "31", "shortCiteRegEx": "31", "year": 1976}, {"title": "Evidence combination in an environment with heterogeneous sources", "author": ["K. Premaratne", "D.A. Dewasurendra", "P.H. Bauer"], "venue": "IEEE Transactions on Systems, Man and Cybernetics, Part A: Systems and Humans, vol. 37, no. 3, pp. 298\u2013309, 2007.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2007}, {"title": "A Dempster-Shafer theoretic conditional approach to evidence updating for fusion of hard and soft data", "author": ["K. Premaratne", "M.N. Murthi", "J. Zhang", "M. Scheutz", "P.H. Bauer"], "venue": "Proc. International Conference on Information Fusion (FUSION), Seattle, WA, July 2009, pp. 2122\u20132129.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2009}, {"title": "A Dempster-Shafer theoretic evidence updating strategy for non-identical frames of discernment", "author": ["T.L. Wickramarathne", "K. Premaratne", "M.N. Murthi", "M. Scheutz"], "venue": "Proc. Workshop on the Theory of Belief Functions (BELIEF), Brest, France, Apr. 2010.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2010}, {"title": "Convergence analysis of consensus belief functions within asynchronous ad-hoc fusion networks", "author": ["T.L. Wickramarathne", "K. Premaratne", "M.N. Murthi"], "venue": "Proc. International Conference on Statistical Signal Processing (ICASSP), Vancouver, Canada, May 2013.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2013}, {"title": "Conditioning and updating evidence", "author": ["E.C. Kulasekere", "K. Premaratne", "D.A. Dewasurendra", "M.-L. Shyu", "P.H. Bauer"], "venue": "International Journal of Approximate Reasoning, vol. 36, no. 1, pp. 75\u2013108, Apr. 2004.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2004}, {"title": "Practical uses of belief functions", "author": ["P. Smets"], "venue": "Proc. Conference on Uncertainty in Artificial Intelligence (UAI), K. B. Laskey and H. Prade, Eds. San Francisco, CA: Morgan Kaufmann, 1999, pp. 612\u2013621.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 1999}, {"title": "Focal elements generated by the Dempster-Shafer theoretic conditionals: A complete characterization", "author": ["T.L. Wickramarathne", "K. Premaratne", "M.N. Murthi"], "venue": "Proc. International Conference on Information Fusion (FUSION), Scotland, UK, July 2010.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2010}, {"title": "Toward efficient computation of the dempster-shafer belief theoretic conditionals", "author": ["\u2014\u2014"], "venue": "IEEE Transactions on Cybernetics, vol. 43, no. 2, pp. 712\u2013724, Apr. 2012.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2012}], "referenceMentions": [{"referenceID": 0, "context": "It\u2019s a streaming world\u2014from financial markets to transportation to health monitoring to e-commerce applications, most of today\u2019s data are generated and received in real-time as streams [1].", "startOffset": 185, "endOffset": 188}, {"referenceID": 1, "context": "With real-time processing bearing the promise of improved efficiency and creating new opportunities many application domains, stream processing [2]\u2013[4] has become the latest trend in the big-data world.", "startOffset": 144, "endOffset": 147}, {"referenceID": 3, "context": "With real-time processing bearing the promise of improved efficiency and creating new opportunities many application domains, stream processing [2]\u2013[4] has become the latest trend in the big-data world.", "startOffset": 148, "endOffset": 151}, {"referenceID": 4, "context": "to predict future system states from real-time data streams while automatically accounting for data distribution drifts via a \u2018single-pass\u2019 processing of data [5] is a critical step in developing robust streaming processing methods for reasoning upon rapidly changing information.", "startOffset": 159, "endOffset": 162}, {"referenceID": 5, "context": "the system), commonly referred to as evidence updating (or belief revision) as new evidence is generated [6].", "startOffset": 105, "endOffset": 108}, {"referenceID": 6, "context": "To preserve the integrity of data fusion [7], adequately accounting for numerous uncertainties [8] is paramount, especially in big-data environments where soft (i.", "startOffset": 41, "endOffset": 44}, {"referenceID": 7, "context": "To preserve the integrity of data fusion [7], adequately accounting for numerous uncertainties [8] is paramount, especially in big-data environments where soft (i.", "startOffset": 95, "endOffset": 98}, {"referenceID": 8, "context": "In this paper, we present a new evidence updating scheme that is derived as a natural extension of Bayes conditioning, the primary belief revision mechanism utilized in probability theory [9]\u2013[14], to tackle the challenges associated with belief revision in such big-data environments.", "startOffset": 188, "endOffset": 191}, {"referenceID": 13, "context": "In this paper, we present a new evidence updating scheme that is derived as a natural extension of Bayes conditioning, the primary belief revision mechanism utilized in probability theory [9]\u2013[14], to tackle the challenges associated with belief revision in such big-data environments.", "startOffset": 192, "endOffset": 196}, {"referenceID": 14, "context": "Conditioning [15]\u2013[17] is the primary method for belief revision in a vast majority of data fusion [7], [18], [19] systems which employ probabilistic inferencing [20]\u2013 [28].", "startOffset": 13, "endOffset": 17}, {"referenceID": 16, "context": "Conditioning [15]\u2013[17] is the primary method for belief revision in a vast majority of data fusion [7], [18], [19] systems which employ probabilistic inferencing [20]\u2013 [28].", "startOffset": 18, "endOffset": 22}, {"referenceID": 6, "context": "Conditioning [15]\u2013[17] is the primary method for belief revision in a vast majority of data fusion [7], [18], [19] systems which employ probabilistic inferencing [20]\u2013 [28].", "startOffset": 99, "endOffset": 102}, {"referenceID": 17, "context": "Conditioning [15]\u2013[17] is the primary method for belief revision in a vast majority of data fusion [7], [18], [19] systems which employ probabilistic inferencing [20]\u2013 [28].", "startOffset": 104, "endOffset": 108}, {"referenceID": 18, "context": "Conditioning [15]\u2013[17] is the primary method for belief revision in a vast majority of data fusion [7], [18], [19] systems which employ probabilistic inferencing [20]\u2013 [28].", "startOffset": 162, "endOffset": 166}, {"referenceID": 26, "context": "Conditioning [15]\u2013[17] is the primary method for belief revision in a vast majority of data fusion [7], [18], [19] systems which employ probabilistic inferencing [20]\u2013 [28].", "startOffset": 168, "endOffset": 172}, {"referenceID": 27, "context": "single event in complex sensing and fusion situations that are characteristic of big-data environments [29], especially when non-traditional sources of evidence (e.", "startOffset": 103, "endOffset": 107}, {"referenceID": 28, "context": ") are also being used for gathering evidence [30].", "startOffset": 45, "endOffset": 49}, {"referenceID": 29, "context": "With a belief theoretic [31] core, our proposed method generalizes the belief theoretic Fagin-Halpern conditional notions [15], thus allowing one to account for various data/source imperfections that are characteristic to complex soft/hard data", "startOffset": 24, "endOffset": 28}, {"referenceID": 14, "context": "With a belief theoretic [31] core, our proposed method generalizes the belief theoretic Fagin-Halpern conditional notions [15], thus allowing one to account for various data/source imperfections that are characteristic to complex soft/hard data", "startOffset": 122, "endOffset": 126}, {"referenceID": 30, "context": "The presented extension differs fundamentally from the previously published work on Conditional Update Equation (CUE) as appeared in [32], [33], including the authors own work in [8], [34], [35].", "startOffset": 133, "endOffset": 137}, {"referenceID": 31, "context": "The presented extension differs fundamentally from the previously published work on Conditional Update Equation (CUE) as appeared in [32], [33], including the authors own work in [8], [34], [35].", "startOffset": 139, "endOffset": 143}, {"referenceID": 7, "context": "The presented extension differs fundamentally from the previously published work on Conditional Update Equation (CUE) as appeared in [32], [33], including the authors own work in [8], [34], [35].", "startOffset": 179, "endOffset": 182}, {"referenceID": 32, "context": "The presented extension differs fundamentally from the previously published work on Conditional Update Equation (CUE) as appeared in [32], [33], including the authors own work in [8], [34], [35].", "startOffset": 184, "endOffset": 188}, {"referenceID": 33, "context": "The presented extension differs fundamentally from the previously published work on Conditional Update Equation (CUE) as appeared in [32], [33], including the authors own work in [8], [34], [35].", "startOffset": 190, "endOffset": 194}, {"referenceID": 34, "context": "However, it can be thought of as an extension of [36].", "startOffset": 49, "endOffset": 53}, {"referenceID": 0, "context": "The mapping m : 2 7\u2192 [0, 1] is a BPA for the FoD \u0398 if m(\u2205) = 0 and \u2211 B\u2286\u0398m(B) = 1.", "startOffset": 21, "endOffset": 27}, {"referenceID": 0, "context": "For B \u2286 \u0398 in the BoE {\u0398,F ,m}, Bl : 2 7\u2192 [0, 1] where Bl(B) = \u2211C\u2286Bm(C) is the belief of B; and Pl : 2 7\u2192 [0, 1] where Pl(B) = 1\u2212Bl(B) is the plausibility of B.", "startOffset": 41, "endOffset": 47}, {"referenceID": 0, "context": "For B \u2286 \u0398 in the BoE {\u0398,F ,m}, Bl : 2 7\u2192 [0, 1] where Bl(B) = \u2211C\u2286Bm(C) is the belief of B; and Pl : 2 7\u2192 [0, 1] where Pl(B) = 1\u2212Bl(B) is the plausibility of B.", "startOffset": 105, "endOffset": 111}, {"referenceID": 35, "context": "such a probability distribution is the pignistic probability distribution BetP(\u00b7) [37]", "startOffset": 82, "endOffset": 86}, {"referenceID": 14, "context": "The Fagin-Halpern (FH) conditional notions in DS theory [15] are applicable whenever the conditioning proposition A belongs to F\u0302.", "startOffset": 56, "endOffset": 60}, {"referenceID": 14, "context": "[15] For the conditioning event A \u2208 F\u0302 and B \u2282 \u0398 in the BoE E = {\u0398,F,m}, the conditional belief Bl(B|A) : 2 7\u2192 [0, 1] and the conditional plausibility Pl(B|A) : 2 7\u2192 [0, 1] of B given A are", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "[15] For the conditioning event A \u2208 F\u0302 and B \u2282 \u0398 in the BoE E = {\u0398,F,m}, the conditional belief Bl(B|A) : 2 7\u2192 [0, 1] and the conditional plausibility Pl(B|A) : 2 7\u2192 [0, 1] of B given A are", "startOffset": 111, "endOffset": 117}, {"referenceID": 0, "context": "[15] For the conditioning event A \u2208 F\u0302 and B \u2282 \u0398 in the BoE E = {\u0398,F,m}, the conditional belief Bl(B|A) : 2 7\u2192 [0, 1] and the conditional plausibility Pl(B|A) : 2 7\u2192 [0, 1] of B given A are", "startOffset": 166, "endOffset": 172}, {"referenceID": 0, "context": "Thus F\u0398|A = {B \u2286 \u0398 | m(B|A) > 0}, where A \u2208 F\u0302 and m(\u00b7|A) : 2 7\u2192 [0, 1] is the corresponding conditional BPA related to Bl(\u00b7|A) via the M\u00f6bius transformation [31]", "startOffset": 65, "endOffset": 71}, {"referenceID": 29, "context": "Thus F\u0398|A = {B \u2286 \u0398 | m(B|A) > 0}, where A \u2208 F\u0302 and m(\u00b7|A) : 2 7\u2192 [0, 1] is the corresponding conditional BPA related to Bl(\u00b7|A) via the M\u00f6bius transformation [31]", "startOffset": 158, "endOffset": 162}, {"referenceID": 31, "context": "[33] The", "startOffset": 0, "endOffset": 4}, {"referenceID": 31, "context": "The CUE proposed in [33] provides several interesting properties applicable to the task at hand.", "startOffset": 20, "endOffset": 24}, {"referenceID": 34, "context": "Then, as proposed in [36] for updating in belief functions, one may employ a linear combination to generate the updated KB:", "startOffset": 21, "endOffset": 25}, {"referenceID": 34, "context": "Now, when A is specified with less than 100% confidence as in Example 2, one may utilize updating strategy similar to [36] to obtain,", "startOffset": 118, "endOffset": 122}, {"referenceID": 34, "context": "In fact, depending on the maturity of the KB, one may choose an \u03b1k not fully committing to incoming evidence (see [36] for a detailed discussion).", "startOffset": 114, "endOffset": 118}, {"referenceID": 31, "context": "Remarks: The updating equations given by GCU proposed in this paper and CUE in [33] have similar functional form.", "startOffset": 79, "endOffset": 83}, {"referenceID": 36, "context": "A theorem that explains the focal elements generated by conditioning referred to as Conditional Core Theorem [38], [39] can be utilized for this task.", "startOffset": 109, "endOffset": 113}, {"referenceID": 37, "context": "A theorem that explains the focal elements generated by conditioning referred to as Conditional Core Theorem [38], [39] can be utilized for this task.", "startOffset": 115, "endOffset": 119}, {"referenceID": 36, "context": "[38] Given A \u2208 F\u0302 in the BoE E = {\u0398,F,m}, m(B|A) > 0 iff B can be expressed as B = X \u222a Y , for some X \u2208 in(A) and Y \u2208 OUT(A)\u222a{\u2205}.", "startOffset": 0, "endOffset": 4}, {"referenceID": 37, "context": "discussion on CCT, we refer the interested reader to [39].", "startOffset": 53, "endOffset": 57}, {"referenceID": 36, "context": "The following example [38] illustrates the application of the CCT.", "startOffset": 22, "endOffset": 26}, {"referenceID": 36, "context": "[38] Consider the BoE, Ek \u2261 {\u0398,Fk,mk( )} with \u0398 = {a, b, c, d, e, f, g, h, i}, mk = {a, b, h, df, beg,\u0398} and mk(B) = {0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 31, "context": "The work in [33], [34], [36] details several parameter selection strategies for CUE-based evidence updating.", "startOffset": 12, "endOffset": 16}, {"referenceID": 32, "context": "The work in [33], [34], [36] details several parameter selection strategies for CUE-based evidence updating.", "startOffset": 18, "endOffset": 22}, {"referenceID": 34, "context": "The work in [33], [34], [36] details several parameter selection strategies for CUE-based evidence updating.", "startOffset": 24, "endOffset": 28}, {"referenceID": 30, "context": "We do not intend to repeat a detailed description of these strategies here; the interested reader may refer to [32], [34], [36].", "startOffset": 111, "endOffset": 115}, {"referenceID": 32, "context": "We do not intend to repeat a detailed description of these strategies here; the interested reader may refer to [32], [34], [36].", "startOffset": 117, "endOffset": 121}, {"referenceID": 34, "context": "We do not intend to repeat a detailed description of these strategies here; the interested reader may refer to [32], [34], [36].", "startOffset": 123, "endOffset": 127}, {"referenceID": 34, "context": "a) Selection of \u03b1k: The work in [36] provides several strategies for selection of \u03b1k w.", "startOffset": 32, "endOffset": 36}, {"referenceID": 30, "context": "Two very interesting choices that are inspired by the work in [32], [34], [36] are the following: (i) The receptive strategy: \u03b2k(A) = Kkmk(A), \u2200A \u2208 Fk, where Kk 6= 0 is a constant.", "startOffset": 62, "endOffset": 66}, {"referenceID": 32, "context": "Two very interesting choices that are inspired by the work in [32], [34], [36] are the following: (i) The receptive strategy: \u03b2k(A) = Kkmk(A), \u2200A \u2208 Fk, where Kk 6= 0 is a constant.", "startOffset": 68, "endOffset": 72}, {"referenceID": 34, "context": "Two very interesting choices that are inspired by the work in [32], [34], [36] are the following: (i) The receptive strategy: \u03b2k(A) = Kkmk(A), \u2200A \u2208 Fk, where Kk 6= 0 is a constant.", "startOffset": 74, "endOffset": 78}], "year": 2017, "abstractText": "Robust belief revision methods are crucial in streaming data situations for updating existing knowledge (or beliefs) with new incoming evidence. Bayes conditioning is the primary mechanism in use for belief revision in data fusion systems that use probabilistic inference. However, traditional conditioning methods face several challenges due to inherent data/source imperfections in big-data environments that harness soft (i.e., human or human-based) sources in addition to hard (i.e., physicsbased) sensors. The objective of this paper is to investigate the most natural extension of Bayes conditioning that is suitable for evidence updating in the presence of such uncertainties. By viewing the evidence updating process as a thought experiment, an elegant strategy is derived for robust evidence updating in the presence of extreme uncertainties that are characteristic of big-data environments. In particular, utilizing the Fagin-Halpern conditional notions, a natural extension to Bayes conditioning is derived for evidence that takes the form of a general belief function. The presented work differs fundamentally from the Conditional Update Equation (CUE) and authors own extensions of it. An overview of this development is provided via illustrative examples. Furthermore, insights into parameter selection under various fusion contexts are also provided.", "creator": "LaTeX with hyperref package"}}}