{"id": "1703.06959", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Mar-2017", "title": "CSI: A Hybrid Deep Model for Fake News Detection", "abstract": "In the recent political climate, the topic of fake news has drawn attention both from the public and the academic communities. Such misinformation has been cited to have a strong impact on public opinion, presenting the opportunity for malicious manipulation. Detecting fake news is an important, yet challenging problem since it is often difficult for humans to distinguish misinformation. However, there have been three generally agreed upon characteristics of fake news: the text, the response received, and the source users promoting it. Existing work has largely focused on tailoring solutions to a particular characteristic, but the complexity of the fake news epidemic limited their success and generality.", "histories": [["v1", "Mon, 20 Mar 2017 20:33:32 GMT  (3600kb,D)", "https://arxiv.org/abs/1703.06959v1", null], ["v2", "Sun, 26 Mar 2017 17:29:45 GMT  (3601kb,D)", "http://arxiv.org/abs/1703.06959v2", null], ["v3", "Thu, 1 Jun 2017 06:00:56 GMT  (3762kb,D)", "http://arxiv.org/abs/1703.06959v3", null], ["v4", "Sun, 3 Sep 2017 22:05:42 GMT  (3736kb,D)", "http://arxiv.org/abs/1703.06959v4", "In Proceedings of the 26th ACM International Conference on Information and Knowledge Management (CIKM) 2017"]], "reviews": [], "SUBJECTS": "cs.LG cs.SI", "authors": ["natali ruchansky", "sungyong seo", "yan liu"], "accepted": false, "id": "1703.06959"}, "pdf": {"name": "1703.06959.pdf", "metadata": {"source": "META", "title": "CSI: A Hybrid Deep Model for Fake News Detection", "authors": ["Natali Ruchansky", "Sungyong Seo", "Yan Liu"], "emails": ["natalir@bu.edu", "sungyons@usc.edu", "yanliu.cs@usc.edu", "permissions@acm.org."], "sections": [{"heading": null, "text": "In this paper, we propose a model that combines all three characteristics for a more accurate and automated prediction. Specifically, we include the behavior of both parties, users and articles, as well as the group behavior of users who spread fake news. Motivated by these three characteristics, we propose a model called CSI, which consists of three modules: capture, score and integrate. e first module is based on response and text; it uses a recursive neural network to capture the temporal effects of user activity on a particular article. e second module learns the source characteristics based on user behavior, and the two are integrated with the third module to classify an article as fake or not. Experimental analysis of real data shows that CSI achieves higher accuracy than existing models and meaningful latent representations of both users and articles extracted. KEYWORDS Fake news, Neural Networks, Deep Group, Temporal Detection, Social Networks, Anomy."}, {"heading": "1 INTRODUCTION", "text": "In fact, it is so that the authors are a group of people who are able to surpass themselves by being able to surpass themselves. (...) It is a group of people who are able to surpass themselves. (...) It is a group of people who are able to survive themselves. (...) It is a group of people who are able to survive themselves. (...) It is a group of people who are able to survive themselves. (...) It is a group of people who are able to survive themselves. (...) It is a group of people who are able to survive themselves. (...) It is a group of people who are able to survive themselves. (...) It is a group of people who are able to survive themselves. (...) It is a group of people who are able to survive themselves. (...) It is a group of people who are able to survive themselves. (...) It is a group of people who are able to survive themselves. (...) It is a group of people who are able to survive themselves. (...) It is a group of people who are able to survive themselves. (...) It is a group of people who are able to survive themselves. (...) It is a group of people who are able to survive themselves."}, {"heading": "2 RELATEDWORK", "text": "In fact, it is the case that most of them are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight."}, {"heading": "3 PROBLEM", "text": "In this section, we first set out provisionals and then discuss the context of the fake news we address. Preliminary: We consider a series of temporal obligations that have occurred between n users with m news articles over time [1, T]. Any engagement between a user and an article aj in due time t is represented as ei jt = (ui, aj, t). Specifically, an engagement is composed of text information provided by the user ui about article aj, at due time t; for example, a tweet or a Facebook post. Figure 2 illustrates the meaning. In addition, we assume that each news article is associated with a label L (aj) = 0 if the message is true, and L (aj) = 1 if it is false. Everywhere we will publish italic characters x for scalars, bold characters h for vectors and bold characters h for vectors, and large letters W for matrices.story as a temporary target."}, {"heading": "4 MODEL", "text": "In this area, we are able to differentiate ourselves in the most diverse forms, both in the way in which we move, and in the way in which we move, as well as in the way in which we behave, in the way in which we behave, in the way in which we behave, in the way in which we behave, in the way in which we behave, in the way in which we behave, in the way in which we behave, in the way in which we behave, in the way in which we behave, in the way in which we behave, in the way in which we behave, in the way in which we behave, in the way in which we behave, in the way in which we behave, in the world, in the way in which we behave, in which we behave, in which we behave, in which we behave, in which we behave, in which we behave, in which we behave, in which we behave, in which we behave, in the way in which we behave, in which we behave, in which we behave, in which we behave, in which we behave, in which we behave in which we behave, in which we behave, in which we behave in which we behave, in which we behave, in which we behave in which we behave, in which we behave, in which we behave, in which we behave in which we behave, in which we behave, in which we behave, in which we behave, in which we behave in which we behave, in which we behave, how we behave, how we behave, in which we behave, how we behave, how we behave, how we behave, how we behave, how we behave, how we behave, how we behave, how we behave, how we behave, how we behave, how we behave, how we behave, how we behave, how we behave, how we behave, how we behave, how we behave, how we behave, how we behave, in which we behave, how we behave, how we behave, how we behave, in which we behave, how we behave, how we behave,"}, {"heading": "4.4 Generality", "text": "We presented the CSI model in the context of fake news; however, our model can easily be generalized to each data set. Let's consider a series of obligations between an Actor Qi and a Target Qi over time, in other words, the article in Figure 3b is a target and each user is an actor. The e-capture module can be used to capture the temporal aspects of obligations shown by actors at targets, and Score can be used to extract a score and representation of each Actor Qi that captures participation in group behavior. e-capture module finally combines the first two modules to improve the predictive quality of targets. Consider, for example, access to a number of databases. e-capture module can identify databases that have received unusual access, and Score can highlight users who were likely to be responsible. In addition, the interchangeability of CSI enables the integration of additional expertise."}, {"heading": "5 EXPERIMENTS", "text": "In this section, we will demonstrate the quality of CSI using two real data sets. In the main experiment, we will evaluate the accuracy of the classification produced by CSI. In addition, we will examine the quality of the values and representations generated by the Score module and show that they are highly related to the score feature. Finally, we will demonstrate the robustness of our model when the labeled data is limited, and examine the temporal behavior of suspicious users. To make a fair comparison, we will use two realworld social media data sets used in previous work, Twitter and Weibo [24]. To date, these are the only publicly available data sets that contain all three features: reaction, text, and user information. Each data set has a number of articles labeled L (aj); in Twitter, the articles are news and in Weibo are discussion topics. In each article, there is also a series of engagement (tweets) listed by a user at a given time table. A summary of the statistics is 1."}, {"heading": "5.1 Model setup", "text": "We first describe the details of two important components in CSI: 1) how to get the temporal partitions discussed in sections 4 and 2 and the specific characteristics for each dataset. Partitioning: As mentioned in section 4, treating each timestamp as its own input to a cell can be extremely precise and reduce the usefulness. Therefore, we propose to partition the data into segments, each of which will be an input to a cell. We apply natural partitioning by changing the temporal granularity from seconds to hours. Hyperparameters: We use cross-validation to set the regularization parameters for the loss function in sections 4.3 to \u03bb = 0.01, the failure probability as 0.2, the learning rate as 0.001, and use the Adam optimizer. Features: Recall from section 4 that Capture Operations on xt = (\u03b7, \u0445t, xu, xcent) - temporal, user-defined and textual features."}, {"heading": "5.2 Fake news classi cation accuracy", "text": "In the main series of experiments, we use two real data sets, Twitter and Weibo, to compare the proposed CSI model with the state-of-the-art models used for similar class-specific tasks discussed in Section 2: SVM-TS [25], DT-Rank [45], DTC [6], LSTM-1 [24] and GRU-2 [24]. Furthermore, we consider CI to be the CSI model that uses only textual properties, CI-t as the use of textual and temporal features xt = (1), and nally CSI with textual, temporal features xT and temporal features xT."}, {"heading": "5.3 Model complexity", "text": "In practice, the availability of labeled examples of true and fake news may be limited, so in this section we will examine the usability of CSI in terms of the number of parameters required and the amount of labeled training samples. Although CSI relies on deep neural networks, the compact set of features used by Capture results in less required parameters than other models. In addition, user relationships can provide in-score compressed representations that cannot be captured by an RNN, which means CSI may have fewer parameters than other RNN-based models. In particular, the model has an order of magnitude of 52K parameters, while GRU-2 has 621K parameters. To examine the number of labeled samples on which CSI is based, we will examine the accuracy depending on the size of the training set. Figure 4 shows that even if only 10% of training samples are available, CSI may have a comparable performance to GRU-2 and therefore be easier to train with the CSI model."}, {"heading": "5.4 Interpreting user representations", "text": "In this section, we analyze the results of Score, which is a score si and a representation y i for each user. Since the available data does not have basic truth markers for users, we perform a qualitative assessment of the information contained in (si, y, i) regarding suspicious behavior of users in relation to the promotion of fake news and group behavior. Although we lack user identifiers, the dataset still contains information that can be used as a proxy. Specifically, we want to evaluate whether (si, y, i) captures the suspicious behavior of users in relation to fake news and group behavior. For the former, a reasonable proxy is the faction of fake news that a user is denoted with, \"i\" with 0.0 meaning the user has never responded to fake news, and 1.0 meaning of engagements are exclusively associated with fake news. In addition, we consider the corresponding scores for articles as average about users, namely pj is the average of si and the average number of users."}, {"heading": "5.5 Characterizing user behavior", "text": "In this section, we ask if the users marked as suspicious by CSI exhibit characteristic behavior. On the basis of each user's si-values, we select about 25 users from the most suspicious groups and the same amount from the least suspicious group.We look at two properties of user behavior: (1) the delay and (2) the activity. To measure the delay for each user, we calculate the time span between the publication of an article and the time when the user is most concerned with it. We then plot the distribution of user delays by the most and least suspicious as well as true and fake messages. Figure 7 shows the CDF of the results. Immediately, we see that the most suspicious users in each data set are among the most frequently counterfeit content - which supports the source characteristics. In contrast, both types of users behave similar behavior to real messaging. Next, we measure user activity as the time between the engagements that user had with an article 8 showing CDi."}, {"heading": "5.6 Utilizing temporal article representations", "text": "In this section, we will examine the vector vj, which is the output of capture for each article aj. Intuitively, these vectors are a low-dimensional representation of the temporal and textual response that an article has received, as well as the types of users from which the answer has come. In the general sense, it is therefore obvious to ask whether these vectors provide a deeper insight into the space of the articles. As an example, we consider the application of spectral clustering to a finer-grained partition as two classes. We will consider the set of vj associated with the test set of Twitter and Weibo articles, and set k = 5 clusters according to the elbow curve. Figure 9 shows the results in the space of the first two singular vectors (\u00b51 and \u00b52) of the true insight that the two vectors each represent a true classification of four stereotypes."}, {"heading": "6 CONCLUSION", "text": "In this thesis, we examine the timely problem of fake news detection. While the existing work has typically addressed the problem by focusing either on the text, the response an article receives, or the users who refer to it, we argue that it is important to consider all three. We propose the CSI model, which consists of three modules. The first module, Capture, captures the abstract temporal behavior of user encounters with articles, as well as temporal text and user functions to measure the response as well as the text. The second component, Score, estimates a presumed source value for each user, which is then combined with the first module of Integrate to produce a predicted label for each article.e separation into modules allows CSI to output a prediction separately on user and article, incorporating each of the three properties, while combining the information for Classi - coupling - news information - coupling the information to the CSI to show the combination of the user information in the two experiments."}, {"heading": "ACKNOWLEDGMENTS", "text": "is a work partially supported by NSF Research Grant IIS-1619458 and IIS-1254206. e views and conclusions are those of the authors and should not be interpreted as representing the policies of the funding agency or the US government."}], "references": [{"title": "Copycatch: stopping group a\u008aacks by spo\u008aing lockstep behavior in social networks", "author": ["Alex Beutel", "Wanhong Xu", "Venkatesan Guruswami", "Christopher Palow", "Christos Faloutsos"], "venue": "In Proceedings of the 22nd international conference on World Wide Web", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2013}, {"title": "Characterizing the life cycle of online news stories using social media reactions", "author": ["Carlos Castillo", "Mohammed El-Haddad", "J\u00fcrgen Pfe\u0082er", "Ma\u008a Stempeck"], "venue": "In Proceedings of the 17th ACM conference on Computer supported cooperative work & social computing", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "Information credibility on twi\u008aer", "author": ["Carlos Castillo", "Marcelo Mendoza", "Barbara Poblete"], "venue": "In Proceedings of the 20th international conference on World wide web", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2011}, {"title": "DeBot: Twi\u008aer Bot Detection via Warped Correlation", "author": ["Nikan Chavoshi", "Hossein Hamooni", "Abdullah Mueen"], "venue": "IEEE 16th International Conference on Data Mining (ICDM)", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2016}, {"title": "Misleading online content: Recognizing clickbait as false news", "author": ["Yimin Chen", "Niall J Conroy", "Victoria L Rubin"], "venue": "In Proceedings of the 2015 ACM on Workshop on Multimodal Deception Detection", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "Americans Believe \u008cey Can Detect Fake News", "author": ["Bre\u008a Edkins"], "venue": "Studies Show \u008cey Can\u2019t. (December", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2016}, {"title": "Detecting Deceptive Opinions with Pro\u0080le Compatibility", "author": ["Vanessa Wei Feng", "Graeme Hirst"], "venue": "In IJCNLP", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2013}, {"title": "Emergent: a novel data-set for stance classi\u0080cation", "author": ["William Ferreira", "Andreas Vlachos"], "venue": "In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language  Technologies. ACL", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2016}, {"title": "Rumor Cascades", "author": ["Adrien Friggeri", "Lada A Adamic", "Dean Eckles", "Justin Cheng"], "venue": "In ICWSM", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2014}, {"title": "Tweetcred: Real-time credibility assessment of content on twi\u008aer", "author": ["Aditi Gupta", "Ponnurangam Kumaraguru", "Carlos Castillo", "Patrick Meier"], "venue": "In International Conference on Social Informatics", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Recurrent neural networks for time series classi\u0080cation", "author": ["Michael H\u00fcsken", "Peter Stagge"], "venue": "Neurocomputing", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2003}, {"title": "Suspicious behavior detection: Current trends and future directions", "author": ["Meng Jiang", "Peng Cui", "Christos Faloutsos"], "venue": "IEEE Intelligent Systems 31,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2016}, {"title": "Epidemiological modeling of news and rumors on twi\u008aer", "author": ["Fang Jin", "Edward Dougherty", "Parang Saraf", "Yang Cao", "Naren Ramakrishnan"], "venue": "In Proceedings of the 7th Workshop on Social Network Mining and Analysis. ACM,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2013}, {"title": "Disinformation on the web: Impact, characteristics, and detection of wikipedia hoaxes", "author": ["Srijan Kumar", "Robert West", "Jure Leskovec"], "venue": "In Proceedings of the 25th International Conference on World Wide Web. International World Wide Web Conferences Steering Commi\u008aee,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2016}, {"title": "Rumor Detection over Varying Time Windows", "author": ["Sejeong Kwon", "Meeyoung Cha", "Kyomin Jung"], "venue": "PLOS ONE 12,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2017}, {"title": "Distributed Representations of Sentences and Documents", "author": ["\u008boc V Le", "Tomas Mikolov"], "venue": "In ICML,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2014}, {"title": "Sequential short-text classi- \u0080cation with recurrent and convolutional neural networks", "author": ["Ji Young Lee", "Franck Dernoncourt"], "venue": "arXiv preprint arXiv:1603.03827", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2016}, {"title": "Mining of massive datasets", "author": ["Jure Leskovec", "Anand Rajaraman", "Je\u0082rey David Ullman"], "venue": null, "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2014}, {"title": "Fake News Is Not the Only Problem. (November 2016)", "author": ["Gilad Lotan"], "venue": null, "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2016}, {"title": "Identifying infection sources and regions in large networks", "author": ["Wuqiong Luo", "Wee Peng Tay", "Mei Leng"], "venue": "IEEE Transactions on Signal Processing 61,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2013}, {"title": "Detecting rumors from microblogs with recurrent neural networks", "author": ["Jing Ma", "Wei Gao", "Prasenjit Mitra", "Sejeong Kwon", "Bernard J Jansen", "Kam-Fai Wong", "Meeyoung Cha"], "venue": "Proceedings of IJCAI", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2016}, {"title": "Detect rumors using time series of social context information on microblogging websites", "author": ["Jing Ma", "Wei Gao", "Zhongyu Wei", "Yueming Lu", "Kam-Fai Wong"], "venue": "In Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2015}, {"title": "How Fake News Goes Viral: A Case Study", "author": ["Sapa Maheshwari"], "venue": null, "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2016}, {"title": "Social spam detection", "author": ["Benjamin Markines", "Ciro Ca\u008auto", "Filippo Menczer"], "venue": "In Proceedings of the 5th International Workshop on Adversarial Information Retrieval on the Web", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2009}, {"title": "Linguistic traces of a scienti\u0080c fraud: \u008ce case of Diederik Stapel", "author": ["David M Markowitz", "Je\u0082rey T Hancock"], "venue": "PloS one 9,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2014}, {"title": "How to tell fake news from real news. (January 2017)", "author": ["Laura McClure"], "venue": null, "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2017}, {"title": "One-class support measure machines for group anomaly detection", "author": ["Krikamol Muandet", "Bernhard Sch\u00f6lkopf"], "venue": "arXiv preprint arXiv:1303.0309", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2013}, {"title": "Spo\u008aing fake reviewer groups in consumer reviews", "author": ["Arjun Mukherjee", "Bing Liu", "Natalie Glance"], "venue": "In Proceedings of the 21st international conference on World Wide Web", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2012}, {"title": "A systematic comparison and evaluation of biclustering methods for gene expression data", "author": ["Amela Preli\u0107", "Stefan Bleuler", "Philip Zimmermann", "Anja Wille", "Peter B\u00fchlmann", "Wilhelm Gruissem", "Lars Hennig", "Lothar \u008ciele", "Eckart Zitzler"], "venue": "Bioinformatics 22,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2006}, {"title": "Deception Detection and Rumor Debunking for Social Media", "author": ["Victoria L Rubin"], "venue": null, "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2017}, {"title": "Deception detection for news: three types of fakes", "author": ["Victoria L Rubin", "Yimin Chen", "Niall J Conroy"], "venue": "Proceedings of the Association for Information Science and Technology", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2015}, {"title": "Rumors, false \u0083ags, and digital vigilantes: Misinformation on twi\u008aer a\u0089er the 2013 boston marathon bombing", "author": ["Kate Starbird", "Jim Maddock", "Mania Orand", "Peg Achterman", "Robert M Mason"], "venue": "iConference 2014 Proceedings", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2014}, {"title": "Sequence to sequence learning with neural networks. In Advances in neural information processing", "author": ["Ilya Sutskever", "Oriol Vinyals", "\u008boc V Le"], "venue": null, "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2014}, {"title": "Google has banned 200 publishers since it passed a new policy against fake news. (January 2017)", "author": ["Tess Townsend"], "venue": "google-adsense-advertisers-publishers-fake-news", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2017}, {"title": "Online human-bot interactions: Detection, estimation, and characterization", "author": ["Onur Varol", "Emilio Ferrara", "Clayton A Davis", "Filippo Menczer", "Alessandro Flammini"], "venue": null, "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2017}, {"title": "A Long Short-Term Memory Model for Answer Sentence Selection in \u008bestion Answering", "author": ["Di Wang", "Eric Nyberg"], "venue": "In ACL", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2015}, {"title": "Rumor source detection with multiple observations: Fundamental limits and algorithms", "author": ["Zhaoxu Wang", "Wenxiang Dong", "Wenyi Zhang", "Chee Wei Tan"], "venue": "In ACM SIGMETRICS Performance Evaluation Review,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2014}, {"title": "False rumors detection on sina weibo by propagation structures", "author": ["Ke Wu", "Song Yang", "Kenny Q Zhu"], "venue": "In Data Engineering (ICDE),", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2015}, {"title": "Group anomaly detection using \u0083exible genre models", "author": ["Liang Xiong", "Barnab\u00e1s P\u00f3czos", "Je\u0082 G Schneider"], "venue": "In Advances in neural information processing systems", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2011}, {"title": "Hierarchical Probabilistic Models for Group Anomaly Detection", "author": ["Liang Xiong", "Barnab\u00e1s P\u00f3czos", "Je\u0082 G Schneider", "Andrew J Connolly", "Jake VanderPlas"], "venue": "AISTATS", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2011}, {"title": "Glad: group anomaly detection in social media analysis", "author": ["Rose Yu", "Xinran He", "Yan Liu"], "venue": "ACM Transactions on Knowledge Discovery from Data (TKDD) 10,", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2015}, {"title": "Enquiring minds: Early detection of rumors in social media from enquiry posts", "author": ["Zhe Zhao", "Paul Resnick", "Qiaozhu Mei"], "venue": "In Proceedings of the 24th International Conference on World Wide Web", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2015}, {"title": "Information source detection in the SIR model: A sample-path-based approach", "author": ["Kai Zhu", "Lei Ying"], "venue": "IEEE/ACM Transactions on Networking (TON) 24,", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 2016}], "referenceMentions": [{"referenceID": 5, "context": "\u008ce di\u0081culty comes in part from the fact that even the human eye cannot accurately distinguish true from false news; for example, one study found that when shown a fake news article, respondents found it \u201c\u2018somewhat\u2019 or \u2018very\u2019 accurate 75% of the time\u201d, and another found that 80% of high school students had a hard time determining whether an article was fake [2, 9].", "startOffset": 359, "endOffset": 365}, {"referenceID": 25, "context": "As a response, numerous articles and blogs have been wri\u008aen to raise public awareness and provide tips on di\u0082erentiating truth from falsehood [29].", "startOffset": 142, "endOffset": 146}, {"referenceID": 7, "context": "A\u008aempts to automate the evaluation of text have manifested in sophisticated natural language processing and machine learning techniques that rely on hand-cra\u0089ed and data-speci\u0080c textual features to classify a piece of text as true or false [11, 13, 24, 27, 28, 34].", "startOffset": 240, "endOffset": 264}, {"referenceID": 9, "context": "A\u008aempts to automate the evaluation of text have manifested in sophisticated natural language processing and machine learning techniques that rely on hand-cra\u0089ed and data-speci\u0080c textual features to classify a piece of text as true or false [11, 13, 24, 27, 28, 34].", "startOffset": 240, "endOffset": 264}, {"referenceID": 20, "context": "A\u008aempts to automate the evaluation of text have manifested in sophisticated natural language processing and machine learning techniques that rely on hand-cra\u0089ed and data-speci\u0080c textual features to classify a piece of text as true or false [11, 13, 24, 27, 28, 34].", "startOffset": 240, "endOffset": 264}, {"referenceID": 23, "context": "A\u008aempts to automate the evaluation of text have manifested in sophisticated natural language processing and machine learning techniques that rely on hand-cra\u0089ed and data-speci\u0080c textual features to classify a piece of text as true or false [11, 13, 24, 27, 28, 34].", "startOffset": 240, "endOffset": 264}, {"referenceID": 24, "context": "A\u008aempts to automate the evaluation of text have manifested in sophisticated natural language processing and machine learning techniques that rely on hand-cra\u0089ed and data-speci\u0080c textual features to classify a piece of text as true or false [11, 13, 24, 27, 28, 34].", "startOffset": 240, "endOffset": 264}, {"referenceID": 30, "context": "A\u008aempts to automate the evaluation of text have manifested in sophisticated natural language processing and machine learning techniques that rely on hand-cra\u0089ed and data-speci\u0080c textual features to classify a piece of text as true or false [11, 13, 24, 27, 28, 34].", "startOffset": 240, "endOffset": 264}, {"referenceID": 4, "context": "Advice columns encourage readers to consider how a story makes them feel \u2013 does it provoke either anger or an emotional response? \u008ce advice stems from the observation that fake news o\u0089en contains opinionated and in\u0083ammatory language, cra\u0089ed as click bait or to incite confusion [8, 33].", "startOffset": 278, "endOffset": 285}, {"referenceID": 29, "context": "Advice columns encourage readers to consider how a story makes them feel \u2013 does it provoke either anger or an emotional response? \u008ce advice stems from the observation that fake news o\u0089en contains opinionated and in\u0083ammatory language, cra\u0089ed as click bait or to incite confusion [8, 33].", "startOffset": 278, "endOffset": 285}, {"referenceID": 22, "context": "New York Times cited examples of people pro\u0080ting from publishing fake stories online; the more provoking, the greater the response, and the larger the pro\u0080t [26].", "startOffset": 157, "endOffset": 161}, {"referenceID": 8, "context": "social graph [12, 16, 17, 35], or use hand-cra\u0089ed features that are social-network dependent, such as the number of Facebook likes, combined with a traditional classi\u0080er [6, 18, 25, 27, 41, 45].", "startOffset": 13, "endOffset": 29}, {"referenceID": 12, "context": "social graph [12, 16, 17, 35], or use hand-cra\u0089ed features that are social-network dependent, such as the number of Facebook likes, combined with a traditional classi\u0080er [6, 18, 25, 27, 41, 45].", "startOffset": 13, "endOffset": 29}, {"referenceID": 13, "context": "social graph [12, 16, 17, 35], or use hand-cra\u0089ed features that are social-network dependent, such as the number of Facebook likes, combined with a traditional classi\u0080er [6, 18, 25, 27, 41, 45].", "startOffset": 13, "endOffset": 29}, {"referenceID": 31, "context": "social graph [12, 16, 17, 35], or use hand-cra\u0089ed features that are social-network dependent, such as the number of Facebook likes, combined with a traditional classi\u0080er [6, 18, 25, 27, 41, 45].", "startOffset": 13, "endOffset": 29}, {"referenceID": 2, "context": "social graph [12, 16, 17, 35], or use hand-cra\u0089ed features that are social-network dependent, such as the number of Facebook likes, combined with a traditional classi\u0080er [6, 18, 25, 27, 41, 45].", "startOffset": 170, "endOffset": 193}, {"referenceID": 14, "context": "social graph [12, 16, 17, 35], or use hand-cra\u0089ed features that are social-network dependent, such as the number of Facebook likes, combined with a traditional classi\u0080er [6, 18, 25, 27, 41, 45].", "startOffset": 170, "endOffset": 193}, {"referenceID": 21, "context": "social graph [12, 16, 17, 35], or use hand-cra\u0089ed features that are social-network dependent, such as the number of Facebook likes, combined with a traditional classi\u0080er [6, 18, 25, 27, 41, 45].", "startOffset": 170, "endOffset": 193}, {"referenceID": 23, "context": "social graph [12, 16, 17, 35], or use hand-cra\u0089ed features that are social-network dependent, such as the number of Facebook likes, combined with a traditional classi\u0080er [6, 18, 25, 27, 41, 45].", "startOffset": 170, "endOffset": 193}, {"referenceID": 37, "context": "social graph [12, 16, 17, 35], or use hand-cra\u0089ed features that are social-network dependent, such as the number of Facebook likes, combined with a traditional classi\u0080er [6, 18, 25, 27, 41, 45].", "startOffset": 170, "endOffset": 193}, {"referenceID": 41, "context": "social graph [12, 16, 17, 35], or use hand-cra\u0089ed features that are social-network dependent, such as the number of Facebook likes, combined with a traditional classi\u0080er [6, 18, 25, 27, 41, 45].", "startOffset": 170, "endOffset": 193}, {"referenceID": 33, "context": "task [37].", "startOffset": 5, "endOffset": 9}, {"referenceID": 18, "context": "In fact, several small-scale analyses have observed that there are o\u0089en groups of users that heavily publicize fake news, particularly just a\u0089er its publication [1, 22].", "startOffset": 161, "endOffset": 168}, {"referenceID": 27, "context": "Approaches here typically focus on data-dependent user behaviors, or identifying the source of an epidemic, and disregard the fake news articles themselves [31, 40].", "startOffset": 156, "endOffset": 164}, {"referenceID": 36, "context": "Approaches here typically focus on data-dependent user behaviors, or identifying the source of an epidemic, and disregard the fake news articles themselves [31, 40].", "startOffset": 156, "endOffset": 164}, {"referenceID": 15, "context": "information such as the temporal spacing of user activity on the article and a doc2vec [19] representation of the text generated in this activity (such as a tweet).", "startOffset": 87, "endOffset": 91}, {"referenceID": 6, "context": "by \u0080nding anomalous pa\u008aerns of pronouns, conjunctions, and words associated with negative emotional word usage [10, 28].", "startOffset": 111, "endOffset": 119}, {"referenceID": 24, "context": "by \u0080nding anomalous pa\u008aerns of pronouns, conjunctions, and words associated with negative emotional word usage [10, 28].", "startOffset": 111, "endOffset": 119}, {"referenceID": 9, "context": "[13] found that fake news o\u0089en contain an", "startOffset": 0, "endOffset": 4}, {"referenceID": 2, "context": "Branching o\u0082 of the core linguistic analysis, many have combined the approach with traditional classi\u0080ers to label an article as true or false [6, 11, 18, 25, 27, 41, 45].", "startOffset": 143, "endOffset": 170}, {"referenceID": 7, "context": "Branching o\u0082 of the core linguistic analysis, many have combined the approach with traditional classi\u0080ers to label an article as true or false [6, 11, 18, 25, 27, 41, 45].", "startOffset": 143, "endOffset": 170}, {"referenceID": 14, "context": "Branching o\u0082 of the core linguistic analysis, many have combined the approach with traditional classi\u0080ers to label an article as true or false [6, 11, 18, 25, 27, 41, 45].", "startOffset": 143, "endOffset": 170}, {"referenceID": 21, "context": "Branching o\u0082 of the core linguistic analysis, many have combined the approach with traditional classi\u0080ers to label an article as true or false [6, 11, 18, 25, 27, 41, 45].", "startOffset": 143, "endOffset": 170}, {"referenceID": 23, "context": "Branching o\u0082 of the core linguistic analysis, many have combined the approach with traditional classi\u0080ers to label an article as true or false [6, 11, 18, 25, 27, 41, 45].", "startOffset": 143, "endOffset": 170}, {"referenceID": 37, "context": "Branching o\u0082 of the core linguistic analysis, many have combined the approach with traditional classi\u0080ers to label an article as true or false [6, 11, 18, 25, 27, 41, 45].", "startOffset": 143, "endOffset": 170}, {"referenceID": 41, "context": "Branching o\u0082 of the core linguistic analysis, many have combined the approach with traditional classi\u0080ers to label an article as true or false [6, 11, 18, 25, 27, 41, 45].", "startOffset": 143, "endOffset": 170}, {"referenceID": 30, "context": "[34] explained that there are many types of fake news, each with di\u0082erent potential textual indicators.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "[24] proposed a model based on recurrent neural networks that uses mainly linguistic features.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "In contrast to [24], the CSI model we propose captures all three characteristics, is able to isolate suspicious users, and requires fewer parameters for a more accurate classi\u0080cation.", "startOffset": 15, "endOffset": 19}, {"referenceID": 1, "context": "[5] showed that the temporal pa\u008aern of user response to news articles plays an important role in understanding the properties of the content itself.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "From a slightly di\u0082erent point of view, one popular approach has been to measure the response an article received by studying its propagation on a social graph [12, 16, 17, 35].", "startOffset": 160, "endOffset": 176}, {"referenceID": 12, "context": "From a slightly di\u0082erent point of view, one popular approach has been to measure the response an article received by studying its propagation on a social graph [12, 16, 17, 35].", "startOffset": 160, "endOffset": 176}, {"referenceID": 13, "context": "From a slightly di\u0082erent point of view, one popular approach has been to measure the response an article received by studying its propagation on a social graph [12, 16, 17, 35].", "startOffset": 160, "endOffset": 176}, {"referenceID": 31, "context": "From a slightly di\u0082erent point of view, one popular approach has been to measure the response an article received by studying its propagation on a social graph [12, 16, 17, 35].", "startOffset": 160, "endOffset": 176}, {"referenceID": 2, "context": "Another approach has been to utilize hand-cra\u0089ed socialnetwork dependent behaviors, such as the number of Facebook likes, as features in a classi\u0080er [6, 18, 25, 27, 41, 45].", "startOffset": 149, "endOffset": 172}, {"referenceID": 14, "context": "Another approach has been to utilize hand-cra\u0089ed socialnetwork dependent behaviors, such as the number of Facebook likes, as features in a classi\u0080er [6, 18, 25, 27, 41, 45].", "startOffset": 149, "endOffset": 172}, {"referenceID": 21, "context": "Another approach has been to utilize hand-cra\u0089ed socialnetwork dependent behaviors, such as the number of Facebook likes, as features in a classi\u0080er [6, 18, 25, 27, 41, 45].", "startOffset": 149, "endOffset": 172}, {"referenceID": 23, "context": "Another approach has been to utilize hand-cra\u0089ed socialnetwork dependent behaviors, such as the number of Facebook likes, as features in a classi\u0080er [6, 18, 25, 27, 41, 45].", "startOffset": 149, "endOffset": 172}, {"referenceID": 37, "context": "Another approach has been to utilize hand-cra\u0089ed socialnetwork dependent behaviors, such as the number of Facebook likes, as features in a classi\u0080er [6, 18, 25, 27, 41, 45].", "startOffset": 149, "endOffset": 172}, {"referenceID": 41, "context": "Another approach has been to utilize hand-cra\u0089ed socialnetwork dependent behaviors, such as the number of Facebook likes, as features in a classi\u0080er [6, 18, 25, 27, 41, 45].", "startOffset": 149, "endOffset": 172}, {"referenceID": 19, "context": "\u008ce \u0080nal characteristic, source, has been studied as the task of identifying the source of an epidemic on a graph [23, 40, 46], or isolating bots based on certain documented behaviors [7, 38].", "startOffset": 113, "endOffset": 125}, {"referenceID": 36, "context": "\u008ce \u0080nal characteristic, source, has been studied as the task of identifying the source of an epidemic on a graph [23, 40, 46], or isolating bots based on certain documented behaviors [7, 38].", "startOffset": 113, "endOffset": 125}, {"referenceID": 42, "context": "\u008ce \u0080nal characteristic, source, has been studied as the task of identifying the source of an epidemic on a graph [23, 40, 46], or isolating bots based on certain documented behaviors [7, 38].", "startOffset": 113, "endOffset": 125}, {"referenceID": 3, "context": "\u008ce \u0080nal characteristic, source, has been studied as the task of identifying the source of an epidemic on a graph [23, 40, 46], or isolating bots based on certain documented behaviors [7, 38].", "startOffset": 183, "endOffset": 190}, {"referenceID": 34, "context": "\u008ce \u0080nal characteristic, source, has been studied as the task of identifying the source of an epidemic on a graph [23, 40, 46], or isolating bots based on certain documented behaviors [7, 38].", "startOffset": 183, "endOffset": 190}, {"referenceID": 27, "context": "Early work in group anomaly detection assumed that the groups were known a priori, and the goal was to detect which of them were anomalous [31].", "startOffset": 139, "endOffset": 143}, {"referenceID": 38, "context": "Such information is not feasible in practice, hence later works propose variants of mixtures models for the data, where the learned parameters are used to identify the anomalous groups [42, 43].", "startOffset": 185, "endOffset": 193}, {"referenceID": 39, "context": "Such information is not feasible in practice, hence later works propose variants of mixtures models for the data, where the learned parameters are used to identify the anomalous groups [42, 43].", "startOffset": 185, "endOffset": 193}, {"referenceID": 26, "context": "[30] took a similar approach by combining kernel embedding with an SVM classi\u0080er.", "startOffset": 0, "endOffset": 4}, {"referenceID": 40, "context": "[44] proposed a uni\u0080ed hierarchical Bayes model to infer the groups", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "\u008cere has also been a strong line of work surrounding detecting suspicious user behavior of various types; a nice overview is given in [15].", "startOffset": 134, "endOffset": 138}, {"referenceID": 0, "context": "Of this line, the most related is the CopyCatch model proposed in [4], which identi\u0080es temporal bipartite cores of user activity on pages.", "startOffset": 66, "endOffset": 69}, {"referenceID": 17, "context": "In line with existing literature on information retrieval and recommender systems [21], we construct the binary incidence matrix of which articles a user", "startOffset": 82, "endOffset": 86}, {"referenceID": 15, "context": "To avoid hand-cra\u0089ed textual feature selection for x\u03c4 , we use doc2vec [19] on the text of each engagement.", "startOffset": 71, "endOffset": 75}, {"referenceID": 10, "context": "For the sake of brevity we do not discuss the well-established LSTM model here, but refer the interested reader to [14] for more detail.", "startOffset": 115, "endOffset": 119}, {"referenceID": 20, "context": "Datasets In order to have a fair comparison, we use two realworld social media datasets that have been used in previous work, Twitter and Weibo [24].", "startOffset": 144, "endOffset": 148}, {"referenceID": 15, "context": "To apply doc2vec[19] to the Weibo data, we \u0080rst apply Chinese text segmentation.", "startOffset": 16, "endOffset": 20}, {"referenceID": 21, "context": "In the main set of experiments, we use two real-world datasets, Twitter and Weibo, to compare the proposed CSI model with \u0080ve state-of-the-art models that have been used for similar classi\u0080cation tasks and were discussed in Section 2: SVM-TS [25] , DT-Rank [45], DTC [6] , LSTM-1 [24], and GRU-2 [24].", "startOffset": 242, "endOffset": 246}, {"referenceID": 41, "context": "In the main set of experiments, we use two real-world datasets, Twitter and Weibo, to compare the proposed CSI model with \u0080ve state-of-the-art models that have been used for similar classi\u0080cation tasks and were discussed in Section 2: SVM-TS [25] , DT-Rank [45], DTC [6] , LSTM-1 [24], and GRU-2 [24].", "startOffset": 257, "endOffset": 261}, {"referenceID": 2, "context": "In the main set of experiments, we use two real-world datasets, Twitter and Weibo, to compare the proposed CSI model with \u0080ve state-of-the-art models that have been used for similar classi\u0080cation tasks and were discussed in Section 2: SVM-TS [25] , DT-Rank [45], DTC [6] , LSTM-1 [24], and GRU-2 [24].", "startOffset": 267, "endOffset": 270}, {"referenceID": 20, "context": "In the main set of experiments, we use two real-world datasets, Twitter and Weibo, to compare the proposed CSI model with \u0080ve state-of-the-art models that have been used for similar classi\u0080cation tasks and were discussed in Section 2: SVM-TS [25] , DT-Rank [45], DTC [6] , LSTM-1 [24], and GRU-2 [24].", "startOffset": 280, "endOffset": 284}, {"referenceID": 20, "context": "In the main set of experiments, we use two real-world datasets, Twitter and Weibo, to compare the proposed CSI model with \u0080ve state-of-the-art models that have been used for similar classi\u0080cation tasks and were discussed in Section 2: SVM-TS [25] , DT-Rank [45], DTC [6] , LSTM-1 [24], and GRU-2 [24].", "startOffset": 296, "endOffset": 300}, {"referenceID": 20, "context": "\u008ce AdaGrad algorithm is used as an optimizer for LSTM-1 and GRU-2 as per [24].", "startOffset": 73, "endOffset": 77}, {"referenceID": 28, "context": "[32] to search for biclusters in the adjacency matrix.", "startOffset": 0, "endOffset": 4}, {"referenceID": 32, "context": "In a general sense, the output of an LSTM has been used for a variety of tasks such as machine translation [36], question answering [39], and text classi\u0080cation [20].", "startOffset": 107, "endOffset": 111}, {"referenceID": 35, "context": "In a general sense, the output of an LSTM has been used for a variety of tasks such as machine translation [36], question answering [39], and text classi\u0080cation [20].", "startOffset": 132, "endOffset": 136}, {"referenceID": 16, "context": "In a general sense, the output of an LSTM has been used for a variety of tasks such as machine translation [36], question answering [39], and text classi\u0080cation [20].", "startOffset": 161, "endOffset": 165}], "year": 2017, "abstractText": "\u008ce topic of fake news has drawn a\u008aention both from the public and the academic communities. Such misinformation has the potential of a\u0082ecting public opinion, providing an opportunity for malicious parties to manipulate the outcomes of public events such as elections. Because such high stakes are at play, automatically detecting fake news is an important, yet challenging problem that is not yet well understood. Nevertheless, there are three generally agreed upon characteristics of fake news: the text of an article, the user response it receives, and the source users promoting it. Existing work has largely focused on tailoring solutions to one particular characteristic which has limited their success and generality. In this work, we propose a model that combines all three characteristics for a more accurate and automated prediction. Speci\u0080cally, we incorporate the behavior of both parties, users and articles, and the group behavior of users who propagate fake news. Motivated by the three characteristics, we propose a model called CSI which is composed of three modules: Capture, Score, and Integrate. \u008ce \u0080rst module is based on the response and text; it uses a Recurrent Neural Network to capture the temporal pa\u008aern of user activity on a given article. \u008ce second module learns the source characteristic based on the behavior of users, and the two are integrated with the third module to classify an article as fake or not. Experimental analysis on real-world data demonstrates that CSI achieves higher accuracy than existing models, and extracts meaningful latent representations of both users and articles.", "creator": "LaTeX with hyperref package"}}}