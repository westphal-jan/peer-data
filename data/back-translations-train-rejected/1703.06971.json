{"id": "1703.06971", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Mar-2017", "title": "Active Decision Boundary Annotation with Deep Generative Models", "abstract": "This paper is on active learning where the goal is to reduce the data annotation burden by interacting with a (human) oracle during training. Standard active learning methods ask the oracle to annotate data samples. Instead, we take a profoundly different approach: we ask for annotations of the decision boundary. We achieve this using a deep generative model to create novel instances along a 1d line. A point on the decision boundary is revealed where the instances change class. Experimentally we show on three data sets that our method can be plugged-in to other active learning schemes, that human oracles can effectively annotate points on the decision boundary, that our method is robust to annotation noise, and that decision boundary annotations improve over annotating data samples.", "histories": [["v1", "Mon, 20 Mar 2017 21:20:21 GMT  (971kb,D)", "http://arxiv.org/abs/1703.06971v1", "ICCV submission"], ["v2", "Wed, 2 Aug 2017 09:36:55 GMT  (993kb,D)", "http://arxiv.org/abs/1703.06971v2", "ICCV 2017"]], "COMMENTS": "ICCV submission", "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["miriam w huijser", "jan c van gemert"], "accepted": false, "id": "1703.06971"}, "pdf": {"name": "1703.06971.pdf", "metadata": {"source": "CRF", "title": "Active Decision Boundary Annotation with Deep Generative Models", "authors": ["Miriam W. Huijser", "Jan C. van Gemert"], "emails": [], "sections": [{"heading": "1. Introduction", "text": "When data is king, annotations are their crown jewels. Large image datasets are relatively easy to obtain; it is the basic truth markers that are expensive [8, 21]. With the enormous success of deep learning methods that critically depend on large annotated datasets, there is a strong demand for a reduction in annotation [17, 23, 25]. In active learning, the goal is to train a good predictor while minimizing the human annotation effort on large unlabeled datasets. During training, the model can interact with a human oracle that provides annotations on the basic truth on demand. The challenge is that the model automatically selects a small set of informative annotations to maximize predictive power. In this paper, we harness the power of deep generative models for active learning."}, {"heading": "2. Related work", "text": "In fact, most of them will be able to play by the rules they have adopted in recent years."}, {"heading": "3. Active decision boundary annotation", "text": "We have the data that we have embedded in a manifold variable Gz (x). (D) We have the data that we provide in a manifold way. (D) We have the data that we provide in a manifold way. (D) We have the data that we provide in a manifold way. (D) We have the data that we provide in a certain way. (D) We have the data that we provide in a different way. (D) We have the data that we provide in a different way. (D) We have the data that we provide in a different way. (D) We have the data that we have provided in a different way. (D) We can point the real decisions that we make to a single data point that contains all the latent variables. (D) Every type of active learning estimates a decision limit. (D) We can minimize the real decision limit while we minimize the number of iterations. (D) We show an overview of our method. (D) Each image is embedded in a latent (D)."}, {"heading": "4. Experiments", "text": "We conduct active learning experiments on three sets of data. MNIST contains 60,000 binary images, 50k to train and 10k in the test set. SVHN dataset [22] contains challenging digit images from Google Streetview, it has 73,257 moves and 26,032 test images. In addition, SVHN dataset has 531,131 additional images that we use to train embedding. For the third set, we want to evaluate our method for more variable images than digits. We create the shoe bag datasets of 40,000 moves and 14,000 test images by taking subsets from the handbag datasets [37] and evaluating the shoe datasets."}, {"heading": "4.1. Exp 1: Evaluating various query strategies", "text": "We evaluate three random sample-based query strategies. Uncertainty samples select the least certain sample point [19]. Uncertainty density samples [28] select samples that are not only unsafe but also located in dense areas of data distribution. K cluster centers [30] uses stacks of K samples where we use K = 5. We insert each query strategy into our approach to line query construction, which is used to note decision boundaries. The results in Table 1 show that our boundary annotations for all three sets of data and for all three query strategies exceed the sample's annotations. In the uncertain density method, the improvement is the largest that can be attributed to this method, samples from dense areas of distribution, and boundary annotations complement each other."}, {"heading": "4.2. Exp 2: Evaluating generative model quality", "text": "The generative model that we include in our method should be able to construct recognizable row queries so that human oracles can comment on them. In Figure 3, we show some row queries generated for all three sets of data by our method of active learning using uncertainty samples. Some row queries are difficult to comment on, as shown in Figure 3 (b), and others are of good quality, as shown in Figure 3 (a). We quantitatively evaluate the generational quality per row by having 10 people comment on the same 10 row queries per line. As the row queries intersect in different locations, they are very long. Line queries are subsampled to have a sample resolution rs = 0.25, i.e. the distance between each image on the line. Human annotators will therefore present with more images for longer line queries and fewer images for shorter lines, so that we will evaluate all the rows for less of the query."}, {"heading": "4.3. Exp 3: Evaluating annotation noise", "text": "In Experiment 2, we show that there are discrepancies in the annotations between human oracles. At this point, we want to answer the question whether this discrepancy is significant. We evaluate the impact of the annotation noise of query lines on classification performance. We vary the degree of additive annotation noise in relation to the marginal annotations of the SVM oracle decision in the one-dimensional line query. We vary the standard deviation of Gaussian noise in image samples that are removed from the oracle. The results in Table 3 show that adding sampling noise of up to the SVM oracle annotations of up to approximately \u03c3 = 4 images has a slightly negative effect on the performance of our annotation method, but is still significantly better than the annotation method of samples. Comparing these results with the consistency between human annotations results in Table 2 shows that the annotation variation of Shoe-Bag 9 is approximately equal to the quality of the SVN, and therefore the negative performance of the SVN should indicate the consistency of the SVN."}, {"heading": "4.4. Exp 4: Evaluating a human oracle", "text": "In this experiment, we evaluate the classification performance with a human oracle. For all three sets of data, we selected a human oracle to comment on the first 10 line queries using uncertainty samples. We repeat the same sample-based active learning experimental setup, averaging over 15 repetitions. The results in Table 4 show that an oracle SVM outperforms a human annotator. This is probably because the active learning method being trained is also an SVM, and since the oracle is also an SVM, it selects the perfect samples. In humans, the annotation of the boundaries relative to the annotation of the sample is always improving. However, for SVHN and ShoeBag, this improvement is not significant, especially due to the low number of queries where our method has not yet reached peak performance after only 10 iterations, as confirmed by the learning curves in Figure 4."}, {"heading": "4.5. Exp 5: Generalization over classes", "text": "So far, we have shown that our methodology outperforms sample-based active learning on a subset of MNIST and SVHN. To see if our methodology generalizes to the other classes, we evaluate the average performance of all SVHN and MNIST class pairs using uncertainty samples as a query strategy. We show the results in Table 5 and plot the learning curves in Figure 4. The results show that our methodology actually generalizes to the other SVHN and MNIST classes. Looking at all data sets and class pairs, our methodology is significantly better than the stab-based approach."}, {"heading": "5. Discussion", "text": "We extend active learning with a method of annotating the decision boundaries. We use a deep generative model to synthesize new images along a 1-dimensional query line, and ask an oracle to comment on the point at which the images change class: This point is a comment on the decision boundary. A disadvantage of our method is that it is very easy to annotate changes visually, but this is not so easy in other areas. In principle, the core of our method can also be used on all input data, but in fact a human oracle is used to detect a class change for non-visual data."}], "references": [{"title": "Efficient active learning of halfspaces via query synthesis", "author": ["I.M. Alabdulmohsin", "X. Gao", "X. Zhang"], "venue": "In AAAI,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "Queries and concept learning", "author": ["D. Angluin"], "venue": "Machine learning,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1988}, {"title": "Training connectionist networks with queries and selective sampling", "author": ["L.E. Atlas", "D.A. Cohn", "R.E. Ladner", "M.A. El-Sharkawi", "R.J. Marks", "M. Aggoune", "D. Park"], "venue": "In NIPS,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1989}, {"title": "Query learning can work poorly when a human oracle is used", "author": ["E.B. Baum", "K. Lang"], "venue": "In International Joint Conference on Neural Networks,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1992}, {"title": "Query learning with large margin classifiers", "author": ["C. Campbell", "N. Cristianini", "A. Smola"], "venue": "In ICML, pages 111\u2013118,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2000}, {"title": "Dimension coupling: Optimal active learning of halfspaces via query synthesis", "author": ["L. Chen", "H. Hassani", "A. Karbasi"], "venue": "arXiv preprint arXiv:1603.03515,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2016}, {"title": "Improving generalization with active learning", "author": ["D. Cohn", "L. Atlas", "R. Ladner"], "venue": "Machine learning,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1994}, {"title": "Imagenet: A large-scale hierarchical image database", "author": ["J. Deng", "W. Dong", "R. Socher", "L.-J. Li", "K. Li", "L. Fei- Fei"], "venue": "In CVPR. IEEE,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2009}, {"title": "Deep generative image models using a laplacian pyramid of adversarial networks", "author": ["E.L. Denton", "S. Chintala", "a. szlam", "R. Fergus"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2015}, {"title": "Adversarial feature learning", "author": ["J. Donahue", "P. Kr\u00e4henb\u00fchl", "T. Darrell"], "venue": "arXiv preprint arXiv:1605.09782,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2016}, {"title": "Adversarially learned inference", "author": ["V. Dumoulin", "I. Belghazi", "B. Poole", "A. Lamb", "M. Arjovsky", "O. Mastropietro", "A. Courville"], "venue": "arXiv preprint arXiv:1606.00704,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2016}, {"title": "Selecting influential examples: Active learning with expected model output changes", "author": ["A. Freytag", "E. Rodner", "J. Denzler"], "venue": "In European Conference on Computer Vision,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2014}, {"title": "Active transfer learning with zero-shot priors: Reusing past datasets for future tasks", "author": ["E. Gavves", "T. Mensink", "T. Tommasi", "C.G.M. Snoek", "T. Tuytelaars"], "venue": "In ICCV,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2015}, {"title": "Generative adversarial nets", "author": ["I. Goodfellow", "J. Pouget-Abadie", "M. Mirza", "B. Xu", "D. Warde-Farley", "S. Ozair", "A. Courville", "Y. Bengio"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "Discriminative batch mode active learning", "author": ["Y. Guo", "D. Schuurmans"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2008}, {"title": "Active learning and discovery of object categories in the presence of unnameable instances", "author": ["C. Kading", "A. Freytag", "E. Rodner", "P. Bodesheim", "J. Denzler"], "venue": "In CVPR,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2015}, {"title": "Semi-supervised learning with deep generative models", "author": ["D.P. Kingma", "S. Mohamed", "D.J. Rezende", "M. Welling"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2014}, {"title": "Auto-encoding variational bayes", "author": ["D.P. Kingma", "M. Welling"], "venue": "ICLR,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2014}, {"title": "A sequential algorithm for training text classifiers", "author": ["D. Lewis", "G.A. William"], "venue": "In Proceedings of the 17th annual international ACM SIGIR conference on Research and development in information retrieval,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1994}, {"title": "Heterogeneous uncertainty sampling for supervised learning", "author": ["D.D. Lewis", "J. Catlett"], "venue": "In Proceedings of the eleventh international conference on machine learning,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1994}, {"title": "Microsoft coco: Common objects in context", "author": ["T.-Y. Lin", "M. Maire", "S. Belongie", "J. Hays", "P. Perona", "D. Ramanan", "P. Doll\u00e1r", "C.L. Zitnick"], "venue": "In ECCV,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2014}, {"title": "Reading digits in natural images with unsupervised feature learning", "author": ["Y. Netzer", "T. Wang", "A. Coates", "A. Bissacco", "B. Wu", "A.Y. Ng"], "venue": "In NIPS workshop on deep learning and unsupervised feature learning,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2011}, {"title": "Ambient sound provides supervision for visual learning", "author": ["A. Owens", "J. Wu", "J.H. McDermott", "W.T. Freeman", "A. Torralba"], "venue": "In ECCV. Springer,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2016}, {"title": "Model-free and model-based active learning for regression", "author": ["J. ONeill", "S.J. Delany", "B. MacNamee"], "venue": "In Advances in Computational Intelligence Systems,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2017}, {"title": "Context encoders: Feature learning by inpainting", "author": ["D. Pathak", "P. Krahenbuhl", "J. Donahue", "T. Darrell", "A.A. Efros"], "venue": "In CVPR,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2016}, {"title": "Unsupervised representation learning with deep convolutional generative adversarial networks", "author": ["A. Radford", "L. Metz", "S. Chintala"], "venue": "arXiv preprint arXiv:1511.06434,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2015}, {"title": "Active learning literature survey", "author": ["B. Settles"], "venue": "University of Wisconsin, Madison,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2010}, {"title": "An analysis of active learning strategies for sequence labeling tasks. In Proceedings of the conference on empirical methods in natural language processing, pages 1070\u20131079", "author": ["B. Settles", "M. Craven"], "venue": "Association for Computational Linguistics,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2008}, {"title": "Query by committee", "author": ["H.S. Seung", "M. Opper", "H. Sompolinsky"], "venue": "In Proceedings of the fifth annual workshop on Computational learning theory,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 1992}, {"title": "Active feedback in ad hoc information retrieval", "author": ["X. Shen", "C. Zhai"], "venue": "In Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2005}, {"title": "Support vector machine active learning with applications to text classification", "author": ["S. Tong", "D. Koller"], "venue": "Journal of machine learning research,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2001}, {"title": "Multi-label active learning based on maximum correntropy criterion: Towards robust and discriminative labeling", "author": ["Z. Wang", "B. Du", "L. Zhang", "M. Fang", "D. Tao"], "venue": "In ECCV,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2016}, {"title": "Incorporating diversity and density in active learning for relevance feedback", "author": ["Z. Xu", "R. Akella", "Y. Zhang"], "venue": "In European Conference on Information Retrieval,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2007}, {"title": "Fine-grained visual comparisons with local learning", "author": ["A. Yu", "K. Grauman"], "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2014}, {"title": "Active learning with sampling by uncertainty and density for data annotations", "author": ["J. Zhu", "H. Wang", "B.K. Tsou", "M. Ma"], "venue": "IEEE Transactions on audio, speech, and language processing,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2010}, {"title": "Generative adversarial active learning", "author": ["J.-J. Zhu", "J. Bento"], "venue": "arXiv preprint arXiv:1702.07956,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2017}, {"title": "Generative visual manipulation on the natural image manifold", "author": ["J.-Y. Zhu", "P. Kr\u00e4henb\u00fchl", "E. Shechtman", "A.A. Efros"], "venue": "In European Conference on Computer Vision,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2016}], "referenceMentions": [{"referenceID": 7, "context": "Big image data sets are relatively easy to obtain; it\u2019s the ground truth labels that are expensive [8, 21].", "startOffset": 99, "endOffset": 106}, {"referenceID": 20, "context": "Big image data sets are relatively easy to obtain; it\u2019s the ground truth labels that are expensive [8, 21].", "startOffset": 99, "endOffset": 106}, {"referenceID": 16, "context": "With the huge success of deep learning methods critically depending on large annotated datasets, there is a strong demand for reducing the annotation effort [17, 23, 25].", "startOffset": 157, "endOffset": 169}, {"referenceID": 22, "context": "With the huge success of deep learning methods critically depending on large annotated datasets, there is a strong demand for reducing the annotation effort [17, 23, 25].", "startOffset": 157, "endOffset": 169}, {"referenceID": 24, "context": "With the huge success of deep learning methods critically depending on large annotated datasets, there is a strong demand for reducing the annotation effort [17, 23, 25].", "startOffset": 157, "endOffset": 169}, {"referenceID": 26, "context": "In active learning [27] the goal is to train a good predictor while minimizing the human annotation effort for large unlabeled data sets.", "startOffset": 19, "endOffset": 23}, {"referenceID": 18, "context": "Existing active learning methods [19, 27, 31] typically ask the oracle to label an existing data sample.", "startOffset": 33, "endOffset": 45}, {"referenceID": 26, "context": "Existing active learning methods [19, 27, 31] typically ask the oracle to label an existing data sample.", "startOffset": 33, "endOffset": 45}, {"referenceID": 30, "context": "Existing active learning methods [19, 27, 31] typically ask the oracle to label an existing data sample.", "startOffset": 33, "endOffset": 45}, {"referenceID": 26, "context": "Active learning [27] is an iterative framework and starts with the initialization of a prediction model either by training on a small set of labeled samples or by random initialization.", "startOffset": 16, "endOffset": 20}, {"referenceID": 11, "context": "Active learning in computer vision includes work on selecting the most influential images [12], refraining from labeling unclear visuals [16], zero-shot transfer learning [13], multi-label active learning [32].", "startOffset": 90, "endOffset": 94}, {"referenceID": 15, "context": "Active learning in computer vision includes work on selecting the most influential images [12], refraining from labeling unclear visuals [16], zero-shot transfer learning [13], multi-label active learning [32].", "startOffset": 137, "endOffset": 141}, {"referenceID": 12, "context": "Active learning in computer vision includes work on selecting the most influential images [12], refraining from labeling unclear visuals [16], zero-shot transfer learning [13], multi-label active learning [32].", "startOffset": 171, "endOffset": 175}, {"referenceID": 31, "context": "Active learning in computer vision includes work on selecting the most influential images [12], refraining from labeling unclear visuals [16], zero-shot transfer learning [13], multi-label active learning [32].", "startOffset": 205, "endOffset": 209}, {"referenceID": 18, "context": "A poolbased setting [19, 31] assumes the availability of a large set of unlabeled instances.", "startOffset": 20, "endOffset": 28}, {"referenceID": 30, "context": "A poolbased setting [19, 31] assumes the availability of a large set of unlabeled instances.", "startOffset": 20, "endOffset": 28}, {"referenceID": 2, "context": "Instead, a stream-based setting [3, 7] is favorable for online learning where a query is selectively sampled from an incoming data stream.", "startOffset": 32, "endOffset": 38}, {"referenceID": 6, "context": "Instead, a stream-based setting [3, 7] is favorable for online learning where a query is selectively sampled from an incoming data stream.", "startOffset": 32, "endOffset": 38}, {"referenceID": 1, "context": "Alternatively, in a query synthesis setting [2, 4, 36] the system is input with a data distribution and queries to the oracle are generated to lie in the input space.", "startOffset": 44, "endOffset": 54}, {"referenceID": 3, "context": "Alternatively, in a query synthesis setting [2, 4, 36] the system is input with a data distribution and queries to the oracle are generated to lie in the input space.", "startOffset": 44, "endOffset": 54}, {"referenceID": 35, "context": "Alternatively, in a query synthesis setting [2, 4, 36] the system is input with a data distribution and queries to the oracle are generated to lie in the input space.", "startOffset": 44, "endOffset": 54}, {"referenceID": 0, "context": "Recently, [1] and [6] proposed methods for efficiently learning halfspaces, i.", "startOffset": 10, "endOffset": 13}, {"referenceID": 5, "context": "Recently, [1] and [6] proposed methods for efficiently learning halfspaces, i.", "startOffset": 18, "endOffset": 21}, {"referenceID": 26, "context": "Much work has been done on this topic [27], here we describe a few prominent strategies.", "startOffset": 38, "endOffset": 42}, {"referenceID": 18, "context": "Uncertainty sampling [19] is a query strategy that selects the unlabeled sample of which the current model is least certain.", "startOffset": 21, "endOffset": 25}, {"referenceID": 4, "context": "This could be obtained by sampling closest to the decision boundary [5, 31] or based on entropy [20].", "startOffset": 68, "endOffset": 75}, {"referenceID": 30, "context": "This could be obtained by sampling closest to the decision boundary [5, 31] or based on entropy [20].", "startOffset": 68, "endOffset": 75}, {"referenceID": 19, "context": "This could be obtained by sampling closest to the decision boundary [5, 31] or based on entropy [20].", "startOffset": 96, "endOffset": 100}, {"referenceID": 27, "context": "The Uncertainty-dense sampling method [28, 35] aims to correct for the problems associated with uncertainty sampling by selecting samples that are not only uncertain but that also lie in dense areas of the data distribution and are thus representative of the data.", "startOffset": 38, "endOffset": 46}, {"referenceID": 34, "context": "The Uncertainty-dense sampling method [28, 35] aims to correct for the problems associated with uncertainty sampling by selecting samples that are not only uncertain but that also lie in dense areas of the data distribution and are thus representative of the data.", "startOffset": 38, "endOffset": 46}, {"referenceID": 14, "context": "In Batch methods [15, 30, 33], not a single sample is queried at each iteration, but a set of samples.", "startOffset": 17, "endOffset": 29}, {"referenceID": 29, "context": "In Batch methods [15, 30, 33], not a single sample is queried at each iteration, but a set of samples.", "startOffset": 17, "endOffset": 29}, {"referenceID": 32, "context": "In Batch methods [15, 30, 33], not a single sample is queried at each iteration, but a set of samples.", "startOffset": 17, "endOffset": 29}, {"referenceID": 28, "context": "In Queryby-committee [29] multiple models are used as a committee and queries the samples where the disagreement is highest.", "startOffset": 21, "endOffset": 25}, {"referenceID": 16, "context": "Probabilistic generative models such as variational autoencoders [17, 18], learn an inference model to map images to a latent space and a decoder to map from latent space back again to image space.", "startOffset": 65, "endOffset": 73}, {"referenceID": 17, "context": "Probabilistic generative models such as variational autoencoders [17, 18], learn an inference model to map images to a latent space and a decoder to map from latent space back again to image space.", "startOffset": 65, "endOffset": 73}, {"referenceID": 13, "context": "Non-probabilistic models such as the generative adversarial nets [14], produce higher-quality images than variational autoencoders [9, 26], but can only map from latent space to image space.", "startOffset": 65, "endOffset": 69}, {"referenceID": 8, "context": "Non-probabilistic models such as the generative adversarial nets [14], produce higher-quality images than variational autoencoders [9, 26], but can only map from latent space to image space.", "startOffset": 131, "endOffset": 138}, {"referenceID": 25, "context": "Non-probabilistic models such as the generative adversarial nets [14], produce higher-quality images than variational autoencoders [9, 26], but can only map from latent space to image space.", "startOffset": 131, "endOffset": 138}, {"referenceID": 9, "context": "Fortunately, recent generative adversarial models can produce high-quality images and provide efficient inference [10, 11].", "startOffset": 114, "endOffset": 122}, {"referenceID": 10, "context": "Fortunately, recent generative adversarial models can produce high-quality images and provide efficient inference [10, 11].", "startOffset": 114, "endOffset": 122}, {"referenceID": 13, "context": "We make use of GANs (Generative Adversarial Nets) [14] to obtain a high-quality embedding.", "startOffset": 50, "endOffset": 54}, {"referenceID": 13, "context": "The generator and discriminator are simultaneously trained by playing a two-player minimax game, for details see [14].", "startOffset": 113, "endOffset": 117}, {"referenceID": 9, "context": "Thus, in addition to a mapping from latent space to images (decoding) as in a standard GAN, we also need an inference model to map images to latent space (encoding) [10, 11].", "startOffset": 165, "endOffset": 173}, {"referenceID": 10, "context": "Thus, in addition to a mapping from latent space to images (decoding) as in a standard GAN, we also need an inference model to map images to latent space (encoding) [10, 11].", "startOffset": 165, "endOffset": 173}, {"referenceID": 10, "context": "This is achieved by playing an adversarial game to try and match the encoder and decoder joint distributions where the adversarial game is played between the encoder and decoder on the one side and the discriminator on the other side, for details see [11].", "startOffset": 251, "endOffset": 255}, {"referenceID": 21, "context": "The SVHN dataset [22] contains challenging digit images from Google streetview, it has 73,257 train and 26,032 test images.", "startOffset": 17, "endOffset": 21}, {"referenceID": 36, "context": "We create the Shoe-Bag dataset of 40,000 train and 14,000 test images by taking subsets from the Handbags dataset [37] and the Shoes dataset [34].", "startOffset": 114, "endOffset": 118}, {"referenceID": 33, "context": "We create the Shoe-Bag dataset of 40,000 train and 14,000 test images by taking subsets from the Handbags dataset [37] and the Shoes dataset [34].", "startOffset": 141, "endOffset": 145}, {"referenceID": 10, "context": "For every dataset we train a deep generative embedding following [11].", "startOffset": 65, "endOffset": 69}, {"referenceID": 10, "context": "All embeddings are trained on the train data, except for the SVHN embedding; which is trained on the larger \u201cextra\u201d dataset following [11].", "startOffset": 134, "endOffset": 138}, {"referenceID": 23, "context": "We evaluate active learning with the Area Under the (accuracy) Learning Curve (AULC) measure [24, 28].", "startOffset": 93, "endOffset": 101}, {"referenceID": 27, "context": "We evaluate active learning with the Area Under the (accuracy) Learning Curve (AULC) measure [24, 28].", "startOffset": 93, "endOffset": 101}, {"referenceID": 18, "context": "Uncertainty sampling selects the least confident sample point [19].", "startOffset": 62, "endOffset": 66}, {"referenceID": 27, "context": "Uncertainty-dense sampling [28] selects samples that are not only uncertain but that also lie in dense areas of the data distribution.", "startOffset": 27, "endOffset": 31}, {"referenceID": 29, "context": "The K-cluster centroid [30] uses batches of K samples, where we set K = 5.", "startOffset": 23, "endOffset": 27}], "year": 2017, "abstractText": "This paper is on active learning where the goal is to reduce the data annotation burden by interacting with a (human) oracle during training. Standard active learning methods ask the oracle to annotate data samples. Instead, we take a profoundly different approach: we ask for annotations of the decision boundary. We achieve this using a deep generative model to create novel instances along a 1d line. A point on the decision boundary is revealed where the instances change class. Experimentally we show on three data sets that our method can be plugged-in to other active learning schemes, that human oracles can effectively annotate points on the decision boundary, that our method is robust to annotation noise, and that decision boundary annotations improve over annotating data samples.", "creator": "LaTeX with hyperref package"}}}