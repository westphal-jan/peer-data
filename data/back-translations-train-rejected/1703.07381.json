{"id": "1703.07381", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Mar-2017", "title": "Improving Statistical Multimedia Information Retrieval Model by using Ontology", "abstract": "A typical IR system that delivers and stores information is affected by problem of matching between user query and available content on web. Use of Ontology represents the extracted terms in form of network graph consisting of nodes, edges, index terms etc. The above mentioned IR approaches provide relevance thus satisfying users query. The paper also emphasis on analyzing multimedia documents and performs calculation for extracted terms using different statistical formulas. The proposed model developed reduces semantic gap and satisfies user needs efficiently.", "histories": [["v1", "Tue, 21 Mar 2017 18:29:05 GMT  (997kb)", "http://arxiv.org/abs/1703.07381v1", null]], "reviews": [], "SUBJECTS": "cs.IR cs.AI", "authors": ["gagandeep singh narula", "vishal jain"], "accepted": false, "id": "1703.07381"}, "pdf": {"name": "1703.07381.pdf", "metadata": {"source": "META", "title": "Improving Statistical Multimedia Information Retrieval (MIR) Model by using Ontology", "authors": ["Gagandeep Singh Narula", "Vishal Jain"], "emails": [], "sections": [{"heading": null, "text": "Multimedia documents include various elements of different data types, including visible and audible data types (text, images, and video documents), structural elements, and interactive elements. In this paper, we have proposed a statistical high-level multimedia IR model that is unaware of the inadequacies caused by the classical statistical model. It includes the use of ontology and various statistical IR approaches (Extended Boolean Approach, Bayesian Network Model, etc.) to display extracted text-image terms or phrases. A typical IR system that delivers and stores information is affected by the problem of matching user queries and available content on the Web."}, {"heading": "Index Terms", "text": "Information Retrieval (IR), OWL, Statistical Approaches (BI model, extended Boolean approach, Bayesian network model), Query Expansion and Refinement."}, {"heading": "State of Art", "text": "The research on multimedia information extraction seems to be a gigantic and challenging task, and its fields are so diverse that it has led to independent research in its own components. Firstly, there used to be human-centric systems that focused on the behavior and needs of the user. Instead, various experiments and studies were conducted, asking users to present a number of valuable things in their daily lives. It was done on the basis of user similarity; some of the decisions are the same, while some are different; few of them prefer the use of images instead of text labels; in further experiments, new users received feedback from previous users; and it leads to a concept of the Relevance Feedback Module in the Information Model. In the early years, most research on content-based image extraction was conducted; the existing models are of varying levels and scope; these models are semantically distinct."}, {"heading": "1. INTRODUCTION", "text": "Human knowledge is the richest multimedia storage system. There are various mechanisms such as vision, language that expresses knowledge, and information that is extracted from it must be efficiently processed by the system. There must be systems that interpret and process human queries, thereby achieving relevant results. It is often seen that users are confused when searching for the results of their queries, for reasons that are: the content of the information is unclear and the user must refine this information. Data stored on systems may or may not be updated regularly. There is less interaction between user request and stored information on systems. The low linkages are called Semantic Gap.Statistical approaches involve retrieving documents that closely correspond to the query, i.e. they must have statistical models, calculations, and analyses. These approaches break down given queries in TERMS. Terms are words that occur in the collection of documents and are automatically extracted. To reduce inconsistencies and multimedia gaps, it is necessary to differentiate between word forms and inconsistent forms in TERMS."}, {"heading": "2. CONCEPT OF MULTIMEDIA IR SYSTEM", "text": "The classical multimedia infrared system has not proved effective in extracting relevant terms from document collections. Conventional infrared systems are not intelligent enough to produce accurate results; these systems use human perception to process queries and return results; the results may or may not be relevant because these systems align queries with information in information databases.The syntax of multimedia documents differs from text documents. Multimedia documents do not contain information symbols or keywords that help to print information.They consist of: Visible and Audible data types: - They include text, images, graphics, videos and audio. Structural elements: - They are not visible. They describe the organization of other data types. The outstanding features of multimedia information [4] are listed below: The information stored in documents to be searched may be audio, image, video, etc. that communicate a variety of messages and emotions that help to understand easily."}, {"heading": "2.1 Layout of Classical Multimedia Ir Model", "text": "Since multimedia documents do not contain keywords or symbols that facilitate the simple process of document search, this classic model consists of the query processing module, which translates multimedia information markers into symbols / keywords that are easily understood by the system. The model has the following modules: - Analysis module: - IR system first analyzes multimedia documents and extracts functions from them. Characteristics include low and high level features. Indexing module: - The module that stores features or terms retrieved from multimedia documents is called the index module. Query module: - This module translates multimedia information symbols such as audio, text pairs, videos, etc. into information symbols that are now understood by the system. Query module: - It finds the rank of stored documents on the basis of similar terms used in the query. Following the ranking of the documents, the results are presented satisfactorily."}, {"heading": "Results Documents", "text": "UserFigure1: A classic multimedia IR model [5]"}, {"heading": "2.2 Shortcomings of Classical Multimedia", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "IR Model", "text": "They are explained below: The classical model treats terms or information symbols rather than maintaining relationships between them. There is no information about concepts used in extracted terms or pairs of images. It creates a semantic gap [6] between user and system due to the availability of irrelevant and superfluous information terms stored in the information database of the IR system. It does not include a concept of ontology and semantic associations to represent terms in the document. Terms that are relevant and similar to each other are identified at the end of the phase by the RETRIEVAL module. The good model is one that is able to distinguish between relevant and non-relevant terms in the middle of the phase in order to avoid confusion."}, {"heading": "3. PROPOSED HIGH LEVEL", "text": "This year, it is closer than ever before to a major U-turn."}, {"heading": "3.1 Multimedia Document Analysis Module", "text": "The IR system used in the model performs structural analysis of documents and extracts text modules from them. [8] At this stage, it is not possible to fully determine whether randomly selected documents are relevant or not. The classical model uses low-level multimedia analysis. The proposed multimedia model uses high-level multimedia analysis algorithms and not low-level multimedia analysis for the following reasons: Table1: Features of High-Level Multimedia AnalysisLow-Level Multimedia AnalysisHigh-Level Multimedia Analysis1. It produces low-level features such as text and image terms. 1. It produces high-level features as it describes concepts associated with extracted low-level text terms. 2. It only extracts relevant terms from information stored in the information database on the system. 2. It extracts terms from derived documents, even if information is not stored on the system. 3. It uses information symbols to index information."}, {"heading": "3.2 Indexing Module", "text": "The indexing module decides the location of these extracted terms (relevant / irrelevant) by means of the index that stores the generated terms. This module has the ability to store high-dimensional information, i.e. it can also resolve structured indexes or trees together with information symbols."}, {"heading": "3.3 Extraction Module", "text": "This module uses two or more statistical approaches to extract relevant terms or phrases from retrieved documents. It is a module that determines the relevance of the IR system. It is able to distinguish between relevant and non-relevant terms based on the results of statistical approaches."}, {"heading": "3.3.1 Extended Boolean Approach", "text": "The classic Boolean condition i.e. True / False produces both relevant and non-relevant results, providing a solution in response to the entire document. If some text or image terms in the document are relevant and some are not relevant, then the Boolean condition results in irrelevant results because it results in whole documents.Solution: - Extended Boolean ApproachAnalysis: - A number of extended Boolean terms have been developed to provide a ranking of results, i.e. the documents that meet the user's query. These models use advanced Boolean operators, called Soft Boolean operators, to find relevant text / image pairs. This approach assigns different weights to other terms and calculates relevance. The classic Boolean operators differ from soft operators as follows: Table2: Classical Operators vs. Soft Operators vs. Soft Operators Extended Operators."}, {"heading": "3.3.2 Bayesian Probability Models / Conditional Probability Models", "text": "This year it is as far as never before in the history of the Federal Republic of Germany."}, {"heading": "3.4 Ontology Module", "text": "This module is used to represent concepts and conceptual relationships between nodes described by inference network graphs in the previous module, using the concept of ontology. Ontology is defined as formal, explicit and SharedD1T1CR1D2T2CR2Dn-1Tn-1CRn-1DnTnCRn."}, {"heading": "CR1 CR2", "text": "Q1r2CRn-1Qn-1rnQnCRnr1Conceptualization of concepts: - (a) Creation of Ontology or Ontology Representation: - Inference Graph consisting of document nodes (root nodes). Each document node has concept nodes that are treated as vertices. An edge from one node to another node represents a relationship between concepts. Di has concept nodes as CRi. Edges represent a relationship between them. (b) Ontology Building: - It uses an algorithm to develop ontology for inference graphs. It requires the use of OWL (Ontology Web Language) that is used to write ontology. It is used to create objects as CRi. Edges represent a relationship between them (b) Ontology Building: - It uses an algorithm to develop ontology for inference graphs. It requires the use of ontology to write (WL) the Web Language."}, {"heading": "Relationship.Id= \u201c \u201c", "text": "For each vertex of graphRelationship.Id = Relationship.Id + C.label; end for resultsDP.AddDomain (Relationship) end for"}, {"heading": "3.5 Query Processing Module", "text": "A query is called a need for information. It is the end result with optimal and effective terms. This module deals with extending and refining the query, either automatically or manually, with user interaction. It analyzes the query according to the query language, extracts information symbols from it, and passes them to the query module for searching for index terms. Query enhancement by manual methods: It includes: Sketch query: - It is one of the methods for querying a multimedia database. With t, the query of the user is a visual sketch given by the user, and then the system processes this drawing to extract its characteristics and searches the index for similar images. Search for example: - Here, the user gives the query as an example of an image he tends to find. A query then extracts low-level functions. Search for keywords: - It is the most popular method. The user describes information with a set of relevant text terms, and the system searches it through local documents (it includes CA)."}, {"heading": "LCA = Local Feedback Analysis + Global Analysis", "text": "It is local because conceptual terms are retrieved only from globally retrieved documents. It is global because documents relating to a specific query topic are randomly selected from a huge collection of documents available on the web (as we have selected three documents relating to the semantic web from the web). If we type the query into Google and press ENTER, the query is executed and some documents are retrieved. It is global activity. LCA is a concept-based scheme of fixed length. It expands the user query and retrieves top n relevant terms that closely satisfy the query. It returns only a fixed number of terms. Accordingly, the retrieved terms are classified as follows: Faith (Q, C) = [+ log (af (c, ta)) idfaWhere C = concepts relating to the query, QBelief (Q, C) = Ranking FunctionDitaRita Tifc = 1ftmac = 1ftmata * 3t *"}, {"heading": "3.5.1 Query Refinement", "text": "Query Refinement means calculation of the old weights of advanced query tens to create new weights of the same query tens. These query terms are converted into dummy documents used for indexing. Here, a formula is used that calculates new weights of query tens and achieves optimal results by discarding non-relevant terms. Aim: - The objective of this formula is to increase the weights of terms appearing in relevant documents and to reduce the weights of terms appearing in non-relevant documents. Equation: -Qa (new) = x * Qa (old) + y * 1 / (RD) * \u2211 wtaRD - z * 1 / (NRD) * \u2211 wtaNRDWhere Qa (new) = New weight of query terms aQa (old) + y * tataRD *."}, {"heading": "3.6 Retrieval Module", "text": "It is a module that retrieves the final results / optimal queries extracted after passing through different phases. It categorizes the document according to similar queries and introduces the index according to the information symbols contained in that query."}, {"heading": "3.6.1 Re-Use of Queries", "text": "Necessity to reuse queries: - The queries that have already been expanded and refined according to the needs of the user are optimized and stored everywhere. If the user needs information about the future, how can one retrieve those documents that fulfill the query? Solution: - Reuse queries. Analysis: - The advanced and refined queries are stored in a database called a query bank. The query bank contains queries about previously retrieved documents. These queries are referred to as persistent queries."}, {"heading": "How to Use Persistent Queries with new Query?", "text": "(a) If a new query is similar to a persistent query, then the result of a new query is related to a persistent query. (b) If the user's new query is not in any way similar to the persistent query, the system must find a persistent query from the database that meets the new query to some extent."}, {"heading": "How to check similar queries?", "text": "Using the concept of the solution region: - When the search for an optimal query begins, the system retrieves the number of queries instead of just one query. All of these queries are described in the query area. The region that contains this query area is referred to as the solution region.We can check the similarity between queries because the new queries are compared with queries in the solution region, and if they match, then both queries are referred to as similar."}, {"heading": "4. EXPERIMENTAL ANALYSIS AND CALCULATIONS", "text": "We have to calculate the probabilities of relevant and non-relevant terms and therefore calculate the weight function for each term. Given data: Total number of relevant documents (R) = 10Documents with documents without term tk (r) = 4 Term tk (R - r) = 6Total number of documents with terms tkn-r + r = 9n = 9Total number of non-relevant documents (N-r) = 15Documents with documents without term tk (R - r) = 6Total number of documents with term tk (N-r) - (n-r) Total number of documents without term tk (N-r) - (Rr) + (Rr) = 16According to BI model, Total number of documents N = 25 Total number of documents with term tk (n) = 9 Total number of relevant documents with relevant documents (R) = 10 Total number of relevant documents with term tk (r) = 10 Total number of relevant data, Pk = Documents with Term (r)."}, {"heading": "5. CONCLUSION", "text": "This module offers the extraction of relevant terms from a vast collection of multimedia documents. As multimedia documents generate information marks that differ from bookmarks, these statistical approaches are presented in papers that analyze multimedia documents and retrieve multimedia terms (text, images and videos) from them. The new model can replace the ambiguities of the traditional multimedia IR model, which only deals with information symbols rather than maintaining relationships between them. It is advantageous in several aspects, such as the introduction of a module to maintain conceptual relationships between extracted terms and their ontological representation. The model uses probabilistic approaches to calculate the order of documents and retrieves optimal queries, and the results are then presented to the user."}, {"heading": "6. REFERENCES", "text": "[1] International Press Telecommunications Council:\\ IPTCCore \"Schema for XMP Version 1.0 Specification document (2005) [2] Technical Standardization Committee on AV & IT Storage Systems and Equipment: Exchangeable image _ le format for digital still cameras: Exif Version 2.2. Technical Report JEITA CP-3451 (April 2002) [3] Borgo, S., S.: Masolo, C.: Foundational Choices in DOLCE. In: Handbook on Ontologies. 2nd edn. Springer (2009) [4] Joao Miguel Costa Magalhaes:\" Statistical Models for Semantic - S., S.: Retrieval, September 2008.01020300 5 10 15N on Rel. D o cu m en tsRelevant DocumentsGraph for BI modelTotal no. of relevant documentsTotal no. of non-relevant documentsTotal of documents [5] Meghini C, Sebastiani F, and Straccia. \""}, {"heading": "ABOUT THE AUTHORS", "text": "Gagandeep Singh holds a B.Tech (CSE) from the GTBIT associated with Guru Gobind Singh Indraprastha University, Delhi. His research areas include Semantic Web, Information Retrieval, Data Mining, Remote Sensing (GIS) and Knowledge Engineering.Vishal Jain holds an M.Tech (CSE) degree from USIT, Guru Gobind Singh Indraprastha University, Delhi, and a Ph.D. in Computer Science and Engineering from Lingaya's University, Faridabad. He is currently an Assistant Professor at Bharati Vidyapeeth's Institute of Computer Applications and Management, (BVICAM), New Delhi. His research area includes web technology, semantic web and information retrieval. He is also associated with CSI, ISTE.. IJCATM: www.ijcaonline.org."}], "references": [{"title": "Foundational choices in DOLCE", "author": ["S. Borgo", "C. Masolo"], "venue": "Handbook on Ontologies. 2nd edn. Springer", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2009}, {"title": "Statistical Models for Semantic \u2013 Multimedia Information Retrieval", "author": ["Joao Miguel Costa Magalhaes"], "venue": "Total no of documents  International Journal of Computer Applications", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2008}, {"title": "A model of multimedia information retrieval", "author": ["C Meghini", "F Sebastiani", "U Straccia"], "venue": "Journal of ACM (JACM),", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2001}, {"title": "Negotiating the semantic gap: From feature maps to semantic landscape", "author": ["W.I. Grosky", "R. Zhao"], "venue": "Lecture Notes in Computer Science", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2001}, {"title": "Semantic indexing of multimedia content using visual, audio and text cues", "author": ["W.H. Adams", "G. Iyengart", "C.Y. Lin", "M.R. Naphade", "C. Neti", "H.J. Nock", "Smith"], "venue": "EURASIP Journal on Applied Signal Processing", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2003}, {"title": "Image retrieval: ideas, influences, and trends of the new age", "author": ["R. Datta", "D. Joshi", "J. Li", "J.Z. Wang"], "venue": "ACM Computing Surveys,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2008}, {"title": "Statistical models for cooccurrence data", "author": ["T. Hofmann", "Puzicha"], "venue": "Technical Report\u201f, Massachusetts Institute of Technology,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1998}, {"title": "Combining Retrieval with Ontology Browsing", "author": ["M. Preethi", "Dr. J. Akilandeswari"], "venue": "International Journal of Internet Computing, Vol.1,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2011}, {"title": "The use of phrases and structured queries in information retrieval", "author": ["W.B. Croft", "H.R. Turtle", "D.D. Lewis"], "venue": "In ACM SIGIR Conf. on research and development in information retrieval,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2004}, {"title": "Concept Based Information Access using Ontologies and Latent Semantic Analysis", "author": ["Rifat Ozcan", "Y. Alp"], "venue": "Technical Report,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2004}, {"title": "Is this document relevant", "author": ["F. Crestani", "M. Lalmas", "C.J. van Rijsbergen", "I. Campbell"], "venue": "ACM Computing Surveys,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1998}, {"title": "An Introduction to Information Retrieval", "author": ["C.D. Manning", "P. Raghavan", "H Schu \u0308tze"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2007}, {"title": "Extracting content structure for Web pages based on visual Representation", "author": ["D. CAI", "Yu", "S. Wen", "J.-R", "Ma", "W.-Y"], "venue": "In Asia Pacific Web Conference", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2003}, {"title": "An inference network approach to image retrieval", "author": ["Metzler", "R D. Manmatha"], "venue": "In Enser,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2004}, {"title": "Efficient and effective querying by image content", "author": ["C. Faloutsos", "R. Barber", "M. Flickner", "J. Hafner", "W Niblack"], "venue": "J. Intell. Inform. Syst.,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1994}, {"title": "Kadi: \u201eCombined Statistical and Model based texture features for improved image classification", "author": ["O.S. Al"], "venue": "IET International Conference on Advances in Medical, Signal and Information Processing (MEDSIP", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2008}, {"title": "Bertoa: \u201eImproving interpretation of component-based systems quality through visualization techniques", "author": ["M.A. Moraga", "C.Calero", "M.F"], "venue": "IET Software,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2008}, {"title": "Content-based Multimedia Information Retrieval: State of Art and Challenges", "author": ["Michael S.Lew", "Nicu Sebu", "Chabane Djeraba", "Ramesh Jain"], "venue": "In ACM Transactions on Multimedia Computing, Communications, and Applications (TOMCCAP),", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2006}, {"title": "Content- based retrieval of 3D Models", "author": ["Alberto Del Bimbo", "Pietro Pala"], "venue": "In ACM Transactions on Multimedia Computing, Communications, and Applications (TOMCCAP),", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2006}, {"title": "Straccia: \u201eA model of multimedia information retrieval", "author": ["Carlo Meghini", "Fabrizio Sebastiani", "Umberto"], "venue": "Journal of ACM (JACM),", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2001}, {"title": "Efficient Computation of queries on feature streams", "author": ["Simone Sanitini"], "venue": "In ACM Transactions on Multimedia Computing, Communications, and Applications (TOMCCAP),", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2011}, {"title": "A comparative study of probabilistic and language models for information retrieval", "author": ["Graham Bennett", "Falk Scholer", "Alexandra"], "venue": "Proceedings of nineteenth conference on Australian database ADC\u201f08,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2068}], "referenceMentions": [{"referenceID": 0, "context": "The third model developed was Dublin Core [3] that deals with semantic as well as structural content of image and text but it failed to depict relationship between text and image.", "startOffset": 42, "endOffset": 45}, {"referenceID": 1, "context": "The salient features of multimedia information [4] are given below:", "startOffset": 47, "endOffset": 50}, {"referenceID": 2, "context": "Figure1: A Classical Multimedia IR Model [5]", "startOffset": 41, "endOffset": 44}, {"referenceID": 3, "context": "\uf0b7 It creates semantic gap [6] between user and system due to availability of irrelevant and superfluous information terms stored in information database of IR system.", "startOffset": 26, "endOffset": 29}, {"referenceID": 4, "context": "Figure3: Extraction of Image Terms [7]", "startOffset": 35, "endOffset": 38}, {"referenceID": 5, "context": "The IR systems used in model performs structural analysis of documents and extracts textimage terms from them [8].", "startOffset": 110, "endOffset": 113}, {"referenceID": 6, "context": "The statistical probabilistic models [9] are categorized into two parts:", "startOffset": 37, "endOffset": 40}, {"referenceID": 7, "context": "42 Conceptualization of concepts, thus organizing them in hierarchical fashion [10].", "startOffset": 79, "endOffset": 83}], "year": 2014, "abstractText": "The process of retrieval of relevant information from massive collection of documents, either multimedia or text documents is still a cumbersome task. Multimedia documents include various elements of different data types including visible and audible data types (text, images and video documents), structural elements as well as interactive elements. In this paper, we have proposed a statistical high level multimedia IR model that is unaware of the shortcomings caused by classical statistical model. It involves use of ontology and different statistical IR approaches (Extended Boolean Approach, Bayesian Network Model etc) for representation of extracted text-image terms or phrases. A typical IR system that delivers and stores information is affected by problem of matching between user query and available content on web. Use of Ontology represents the extracted terms in form of network graph consisting of nodes, edges, index terms etc. The above mentioned IR approaches provide relevance thus satisfying user\u201fs query. The paper also emphasis on analyzing multimedia documents and performs calculation for extracted terms using different statistical formulas. The proposed model developed reduces semantic gap and satisfies user needs efficiently. Index Terms Information Retrieval (IR), OWL, Statistical Approaches (BI model, Extended Boolean Approach, Bayesian Network Model), Query Expansion and Refinement. State of Art Research on multimedia information retrieval seems to be gargantuan and challenging task. Its areas are so diversified that it has lead to independent research in its own components. Firstly, there used to be human centered systems that focus on user\u201fs behavior and needs. Various experiments and studies were conducted in lieu of these systems. The users were asked to present a set of valuable things in daily life. It was done on similarity of users. Some of choices are same while some are different. Few of them prefer to use images instead of text caption. In further experiments, it was noticed that new users were taking feedback from previous users. It leads to concept of relevance feedback module in information model. In early years, most research was done on contentbased image retrieval. The existing models are of different level and scope. These models are semantically unambiguous. For e.g.: IPTC model [1] uses location fields that focus on location of data but this model also failed due to lack of statistical approach. Another metadata model was developed i.e. EXIF [2] to support features of images but it did not tell anything about relationship and associations between different contents of image. It also resulted in vain. The third model developed was Dublin Core [3] that deals with semantic as well as structural content of image and text but it failed to depict relationship between text and image. With advancement in technology and predictions, some probabilistic and futuristic models were also developed. In following paper, statistical multimedia IR model has been proposed and compared with classical multimedia IR model.", "creator": "Microsoft\u00ae Office Word 2007"}}}