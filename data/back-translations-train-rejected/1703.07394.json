{"id": "1703.07394", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Mar-2017", "title": "Deep Learning for Explicitly Modeling Optimization Landscapes", "abstract": "In all but the most trivial optimization problems, the structure of the solutions exhibit complex interdependencies between the input parameters. Decades of research with stochastic search techniques has shown the benefit of explicitly modeling the interactions between sets of parameters and the overall quality of the solutions discovered. We demonstrate a novel method, based on learning deep networks, to model the global landscapes of optimization problems. To represent the search space concisely and accurately, the deep networks must encode information about the underlying parameter interactions and their contributions to the quality of the solution. Once the networks are trained, the networks are probed to reveal parameter combinations with high expected performance with respect to the optimization task. These estimates are used to initialize fast, randomized, local search algorithms, which in turn expose more information about the search space that is subsequently used to refine the models. We demonstrate the technique on multiple optimization problems that have arisen in a variety of real-world domains, including: packing, graphics, job scheduling, layout and compression. The problems include combinatoric search spaces, discontinuous and highly non-linear spaces, and span binary, higher-cardinality discrete, as well as continuous parameters. Strengths, limitations, and extensions of the approach are extensively discussed and demonstrated.", "histories": [["v1", "Tue, 21 Mar 2017 19:12:35 GMT  (526kb,D)", "http://arxiv.org/abs/1703.07394v1", null]], "reviews": [], "SUBJECTS": "cs.NE cs.AI cs.LG", "authors": ["shumeet baluja"], "accepted": false, "id": "1703.07394"}, "pdf": {"name": "1703.07394.pdf", "metadata": {"source": "CRF", "title": "Deep Learning for Explicitly Modeling Optimization Landscapes", "authors": ["Shumeet Baluja"], "emails": ["shumeet@google.com"], "sections": [{"heading": "1 Introduction to Optimization via Search Space Modeling", "text": "In the nineties of the twentieth century, when the world was still in order, the world was still in order."}, {"heading": "1.1 Predecessors to Deep Modeling of Optimization Landscapes", "text": "In fact, it is the case that most of them are able to abide by the rules they have imposed on themselves. (...) Most of them are able to abide by the rules. (...) Most of them are not able to abide by the rules. (...) Most of them are not able to abide by the rules. (...) Most of them are not able to abide by the rules. (...) Most of them are not able to abide by the rules. (...) Most of them are not able to abide by the rules. (...) Most of them are not able to abide by the rules. (...) Most of them are not able to abide by the rules. (...)"}, {"heading": "2 Deep Learning for Search Space Modeling", "text": "This year is the highest in the history of the country."}, {"heading": "2.1 Integration with Fast Local Search Heuristics", "text": "In the simplest implementation, the candidate solutions generated by the network inversion are evaluated and the cycle continues. Although this method will work, there are disadvantages. Firstly, this is a slow process; forming a complete network to map the points collected to their ratings is an expensive procedure, as is scanning the network. Secondly, a post-processing step of local optimization, where small changes are made to the generated solutions, will improve the solutions found. This is because both the interpolation and the extrapolation capabilities of the tracted networks are not perfect; there will be discrepancies between the estimated \"quality\" (evaluation) of a candidate solution and its actual evaluation. Two early works in probabilistic model-based optimization [16] suggested that the probability models are used as methods to initialize faster local search procedures."}, {"heading": "2.2 Putting it all Together", "text": "This year, the time has come for most of them not to be able to retaliate."}, {"heading": "2.3 Visualizing the Learning", "text": "This year, it has reached the stage where it will be able to take the lead."}, {"heading": "3 Empirical Results", "text": "In this section, we examine the advantages of the probabilistic model in selecting interesting starting points for the NASH optimization process to address a number of real-world issues. As previously described, when using the model, M samples are generated, the best of which are used to initialize NASH. To ensure that the model actually provides useful information, and that it is not just the process of examining M samples before starting a new run of NASH that produces the improved performance, three variants of NASH are examined. Although they vary in seemingly small implementation details, the impact on performance can be dramatic. \u2022 NASH-V1: This is exactly NASH shown in Figure 3. \u2022 NASH-V2: Before starting the NASH run, M samples are randomly generated and evaluated."}, {"heading": "3.1 Noisy Evaluations", "text": "This year it is as far as never before in the history of the Federal Republic of Germany."}, {"heading": "3.3 Graph Bandwidth", "text": "For a diagram with V-corners and E-edges, the bandwidth problem of the diagram is to label the corners of the diagram with unique integers, minimizing the difference between the labels between any connected corners. Formally, as described in [36], the p-corners of a diagram G are labeled with unique integers f (vi), minimizing the amount max {| f (vi) \u2212 f (vj) |: vivj-E} (E is the edge set of G). More details on the complexity of this problem can be found in [37]. Interest in this problem stems from a variety of sources, including satisfaction with constraints [38] and minimizing the propagation delay in the layout of electronic cells. The solution is coded as follows: each vertex is assigned a real parameter (full coding of length V |). The corners are weighted according to their respective vertex."}, {"heading": "3.4 Graph-Based Constraint Satisfaction", "text": "Constraint Satisfaction has numerous applications in the real world. Recently, we used it for resource allocation and work scheduling. It is presented here in its simplest form. Simply put, in this problem, there are P = 100 real value parameters in the range [0,1,0]. These parameters are mapped to the vertices in a diagram.The graph contains 2,000 randomly selected directed edges that specify a condition that the origin node must have a value greater than the destination node. The optimization problem is to assign values to the node in such a way that as many of the 2,000 constraints are fulfilled as possible.If the condition is not met, the error is the absolute difference between the two values. The error that is to be minimized is summarized across all constraints. The results are shown in Table 4."}, {"heading": "3.5 Graph-Based Discrete Constraint Satisfaction", "text": "This variant of the previous graph-based satisfaction problem uses exactly the same configuration as in Section 3.4, but each node can only accommodate 1 out of 16 letters - A.. P. With regard to the real application of the above-mentioned work schedule, jobs in this version of the problem can only be entered into the system at specific, synchronized times. This makes the problem closer to a selection problem (selecting one of the 16 values for each of the nodes) compared to the previous instance, where a real value was assigned to each node. Although conceptually there is a small difference from the above encoding, discrediting has huge implications in the solution coding. The simplest encoding is to use 100 real output, one for each node, and to divide the [0.1] region into 16 equally divided regions, with each node assigned to a single letter. However, for the reasons explained in Section 4.1, this encoding is poor."}, {"heading": "3.6 Two Dimensional Layout Problems", "text": "This section examines the limitations of the deep opt approach. A number of problems that involved abandoning the two-dimensional layout have not significantly improved the modeling of the search space."}, {"heading": "3.6.1 Minimizing Crossings", "text": "The goal is to find a planar layout of the nodes of a graph that minimizes edge crossings. See [39] for more details. In general, the edges can be drawn in any shape. In our implementation, the edges were drawn only with straight lines, this is called a linear number of crossings. For our tests, each node was represented with two parameters (x, y coordinates).Small graphs were tested with 25 nodes, resulting in a solution that encoded 50 real values that specified the coordinates of each point on a plane.Each graph had 50 randomly chosen connections. 20 randomly generated problem instantiations were investigated.One of the interesting results is that NASH-2 surpassed NASH-3. In most previous experiments, this was reversed. NASH-2 received a higher score than NASH-2 in 12 of the 20 problems."}, {"heading": "3.6.2 Image Approximation via Triangle Covering", "text": "This is the only problem in the paper for which the parameters for NASH have been modified to be optimized for this problem. Accordingly, Deep-Opt also used the same parameters. If these parameters had not been reset, neither NASH nor Deep-Opt would perform as well as shown here, with Deep-Opt NASH performing poorly on its own. In this problem, there is an intensity target image (only black and white, no color information), I, that is N \u00d7 N pixels. The goal is to find T triangles and their intensities that are close to the image. Specifically, each triangle must specify three vertices between [0, N] in X & Y and an intensity value; the triangles are drawn on an initially blank canvas; the triangles may overlap; their intensities are additive; after all the T triangles are drawn, the resulting image is scaled back to the corresponding space (0.. 25xels)."}, {"heading": "4 Extensions & Alternatives", "text": "In this section we briefly describe three extensions and further tests of the deep opt. Although the results are promising, they are preliminary."}, {"heading": "4.1 Discrete/Binary Parameters", "text": "This year it is more than ever before."}, {"heading": "4.2 The Role of Scaling Examples and Their Outputs", "text": "Deep opt, as used in this paper, works by scaling back the neural network inputs to change the network to open up 1.0 at its starting point. Remember that the ratings of the solutions generated in S are scaled before each workout session, some of the newly found solutions are removed from S and other solutions. Often, in the early parts of the search, the range of actual ratings in S extends to new, higher ratings."}, {"heading": "4.3 Alternative Underlying Search Algorithms", "text": "In this paper we have the use of deep net models with an extremely simple localized search algorithm, NASH. It is important to also consider the possibility of using alternative search algorithms using the same methods. Although we do not enter into the general debate about these simple methods, this is an active area for discussion about the future."}, {"heading": "5 Discussion and Future Work", "text": "This year, it has come to the point that it will only be a matter of time before it is ready, until it is ready."}, {"heading": "Acknowledgments", "text": "The author thanks Sergey Ioffe and Rif A. Saurous for their valuable comments."}], "references": [{"title": "Population-based incremental learning. a method for integrating genetic search based function optimization and competitive learning", "author": ["S. Baluja"], "venue": "CMU-CS-94-163. Carnegie Mellon University, Dept. of Computer Science, Tech. Rep., 1994.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1994}, {"title": "Topics in black-box combinatorial optimization", "author": ["A. Juels"], "venue": "University of California, Berkeley,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1996}, {"title": "From recombination of genes to the estimation of distributions i. binary parameters", "author": ["H. M\u00fchlenbein", "G. Paass"], "venue": "International Conference on Parallel Problem Solving from Nature. Springer, 1996, pp. 178\u2013187.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1996}, {"title": "The compact genetic algorithm", "author": ["G.R. Harik", "F.G. Lobo", "D.E. Goldberg"], "venue": "IEEE transactions on evolutionary computation, vol. 3, no. 4, pp. 287\u2013297, 1999.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1999}, {"title": "Genetic algorithms in search, optimization, and machine learning", "author": ["D.E. Goldberg"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1989}, {"title": "Adaptation in natural and artificial systems: an introductory analysis with applications to biology, control, and artificial intelligence", "author": ["J.H. Holland"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1975}, {"title": "Genetic algorithms: a 30 year perspective", "author": ["K. De Jong"], "venue": "Perspectives on Adaptation in Natural and Artificial Systems, vol. 11, 2005.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2005}, {"title": "Simulated crossover in genetic algorithms", "author": ["G. Syswerda"], "venue": "Foundations of Genetic Algorithms, vol. 2, pp. 239\u2013255, 1993.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1993}, {"title": "Learning optimal discriminant functions through a cooperative game of automata", "author": ["M.A. Thathachar", "P.S. Sastry"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics, vol. 17, no. 1, pp. 73\u201385, 1987.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1987}, {"title": "Hill climbing with learning (an abstraction of genetic algorithm)", "author": ["V. Kvasnicka", "M. Pelik\u00e1n", "J. Pospichal"], "venue": "Neural Network World, 6. Citeseer, 1995.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1995}, {"title": "Towards a theory of population based incremental learning", "author": ["M. Hohfeld", "G. Rudolph"], "venue": "Proceedings of the International Conference on Evolutionary Computation, 1997.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1997}, {"title": "A convergence proof for the population based incremental learning algorithm", "author": ["R. Rastegar", "A. Hariri", "M. Mazoochi"], "venue": "17th IEEE International Conference on Tools with Artificial Intelligence (ICTAI\u201905). IEEE, 2005, pp. 387\u2013391.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2005}, {"title": "The convergence behavior of the pbil algorithm: a preliminary approach", "author": ["C. Gonzalez", "J.A. Lozano", "P. Larra\u00f1aga"], "venue": "Artificial Neural Nets and Genetic Algorithms. Springer, 2001, pp. 228\u2013231.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2001}, {"title": "Analyzing the population based incremental learning algorithm by means of discrete dynamical systems", "author": ["C. Gonz\u00e1lez", "J.A. Lozano", "P. Larranaga"], "venue": "Complex Systems, vol. 12, pp. 465\u2013479, 2000. 23", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2000}, {"title": "Mimic: Finding optima by estimating probability densities", "author": ["J.S. De Bonet", "C.L. Isbell", "P. Viola"], "venue": "Advances in neural information processing systems, pp. 424\u2013430, 1997.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1997}, {"title": "Fast probabilistic modeling for combinatorial optimization", "author": ["S. Baluja", "S. Davies"], "venue": "AAAI/IAAI. Madison, WI, USA, 1998, pp. 469\u2013476.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1998}, {"title": "Approximating discrete probability distributions with dependence trees", "author": ["C. Chow", "C. Liu"], "venue": "IEEE transactions on Information Theory, vol. 14, no. 3, pp. 462\u2013467, 1968.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1968}, {"title": "Using optimal dependency-trees for combinatorial optimization", "author": ["S. Baluja", "S. Davies"], "venue": "International Conference on Machine Learning (ICML), 1997, pp. 30\u201338.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1997}, {"title": "A tutorial on learning with bayesian networks", "author": ["D. Heckerman"], "venue": "Innovations in Bayesian networks. Springer, 2008, pp. 33\u201382.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2008}, {"title": "Bayesian networks", "author": ["J. Pearl", "S. Russell"], "venue": "Department of Statistics, UCLA, 2000.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2000}, {"title": "Boa: The bayesian optimization algorithm", "author": ["M. Pelikan", "D.E. Goldberg", "E. Cant\u00fa-Paz"], "venue": "Proceedings of the 1st Annual Conference on Genetic and Evolutionary Computation-Volume 1. Morgan Kaufmann Publishers Inc., 1999, pp. 525\u2013532.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1999}, {"title": "Bayesian optimization algorithm based on incremental model building", "author": ["J. Yao", "Y. Kong", "L. Yang"], "venue": "International Symposium on Intelligence Computation and Applications. Springer, 2015, pp. 202\u2013209.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2015}, {"title": "Global optimization using bayesian networks", "author": ["R. Etxeberria", "P. Larranaga"], "venue": "Second Symposium on Artificial Intelligence (CIMAF-99). Habana, Cuba, 1999, pp. 332\u2013339.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1999}, {"title": "Learning evaluation functions to improve optimization by local search", "author": ["J. Boyan", "A.W. Moore"], "venue": "Journal of Machine Learning Research, vol. 1, no. Nov, pp. 77\u2013112, 2000.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2000}, {"title": "Multilayer feedforward networks are universal approximators", "author": ["K. Hornik", "M. Stinchcombe", "H. White"], "venue": "Neural networks, vol. 2, no. 5, pp. 359\u2013366, 1989.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1989}, {"title": "Inversion of multilayer nets", "author": ["A. Linden", "J. Kindermann"], "venue": "Neural Networks, 1989. IJCNN., International Joint Conference on. IEEE, 1989, pp. 425\u2013430.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1989}, {"title": "Texture synthesis using convolutional neural networks", "author": ["L. Gatys", "A.S. Ecker", "M. Bethge"], "venue": "Advances in Neural Information Processing Systems, 2015, pp. 262\u2013270.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2015}, {"title": "A neural algorithm of artistic style", "author": ["L.A. Gatys", "A.S. Ecker", "M. Bethge"], "venue": "arXiv preprint arXiv:1508.06576, 2015.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2015}, {"title": "Adam: A method for stochastic optimization", "author": ["D.P. Kingma", "J. Ba"], "venue": "CoRR, vol. abs/1412.6980, 2014. [Online]. Available: http://arxiv.org/abs/1412.6980", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2014}, {"title": "Stochastic hillclimbing as a baseline method for evaluating genetic algorithms", "author": ["A. Juels", "M. Wattenberg"], "venue": "Proceedings of the 1995 Conference on Neural Information Processing Systems (NIPS), vol. 8, 1996, p. 430.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 1995}, {"title": "An empirical comparison of seven iterative and evolutionary function optimzation heuristics", "author": ["S. Baluja"], "venue": "Computer Science Department, Tech. Rep. CMU-CS-95-193, September 1995.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 1995}, {"title": "When will a genetic algorithm outperform hill climbing", "author": ["M. Mitchell", "J.H. Holland", "S. Forrest"], "venue": "Advances in Neural Information Processing Systems 6, J. D. Cowan, G. Tesauro, and J. Alspector, Eds. Morgan-Kaufmann, 1994, pp. 51\u201358. [Online]. Available: http://papers.nips.cc/paper/ 836-when-will-a-genetic-algorithm-outperform-hill-climbing.pdf", "citeRegEx": "33", "shortCiteRegEx": null, "year": 1994}, {"title": "Micro-auction based traffic light control: Responsive, local decision making", "author": ["M. Covell", "S. Baluja", "R. Sukthankar"], "venue": "IEEE Intelligent Transportation Systems Conference-2015, 2015.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2015}, {"title": "The bandwidth problem for graphs and matrices\u2014a survey", "author": ["P.Z. Chinn", "J. Chv\u00e1talov\u00e1", "A.K. Dewdney", "N.E. Gibbs"], "venue": "Journal of Graph Theory, vol. 6, no. 3, pp. 223\u2013254, 1982.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 1982}, {"title": "Some applications of graph bandwidth to constraint satisfaction problems.", "author": ["R. Zabih"], "venue": "in AAAI,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 1990}, {"title": "Techniques for learning binary stochastic feedforward neural networks", "author": ["T. Raiko", "M. Berglund", "G. Alain", "L. Dinh"], "venue": "arXiv preprint arXiv:1406.2989, 2014.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2014}, {"title": "Optimization by simulated annealing", "author": ["S. Kirkpatrick", "C.D. Gelatt", "M.P. Vecchi"], "venue": "Science, vol. 220, no. 4598, pp. 671\u2013680, 1983.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 1983}, {"title": "Tabu search-part i", "author": ["F. Glover"], "venue": "ORSA Journal on computing, vol. 1, no. 3, pp. 190\u2013206, 1989.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 1989}, {"title": "Hill climbing beats genetic search on a boolean circuit synthesis problem of koza\u2019s", "author": ["K.J. Lang"], "venue": "Proceedings of the Twelfth International Conference on Machine Learning, 1995, pp. 340\u2013343.", "citeRegEx": "43", "shortCiteRegEx": null, "year": 1995}, {"title": "Comparing genetic algorithms, simulated annealing, and stochastic hillclimbing on timetabling problems", "author": ["P. Ross", "D. Corne"], "venue": "AISB Workshop on Evolutionary Computing. Springer, 1995, pp. 94\u2013102.", "citeRegEx": "44", "shortCiteRegEx": null, "year": 1995}, {"title": "When hillclimbers beat genetic algorithms in multimodal optimization", "author": ["F.G. Lobo", "M. Bazargani"], "venue": "Proceedings of the Companion Publication of the 2015 Annual Conference on Genetic and Evolutionary Computation. ACM, 2015, pp. 1421\u20131422.", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2015}, {"title": "Genetic algorithms are not function optimizers", "author": ["K.A. De Jong"], "venue": "Foundations of genetic algorithms, vol. 2, pp. 5\u201317, 1993. 25", "citeRegEx": "46", "shortCiteRegEx": null, "year": 1993}], "referenceMentions": [{"referenceID": 0, "context": "In the 1990s, a number of researchers [1] [2] [3] [4] independently started employing probabilistic models to guide heuristic stochastic based-search algorithms.", "startOffset": 38, "endOffset": 41}, {"referenceID": 1, "context": "In the 1990s, a number of researchers [1] [2] [3] [4] independently started employing probabilistic models to guide heuristic stochastic based-search algorithms.", "startOffset": 42, "endOffset": 45}, {"referenceID": 2, "context": "In the 1990s, a number of researchers [1] [2] [3] [4] independently started employing probabilistic models to guide heuristic stochastic based-search algorithms.", "startOffset": 46, "endOffset": 49}, {"referenceID": 3, "context": "In the 1990s, a number of researchers [1] [2] [3] [4] independently started employing probabilistic models to guide heuristic stochastic based-search algorithms.", "startOffset": 50, "endOffset": 53}, {"referenceID": 4, "context": "Probabilistic models for optimization were motivated with three goals: as a new optimization method, as a method to incorporate simple learning (Hebbian style probability updates) into hillclimbing, and as a method to explain how genetic algorithms [5] [6] [7] might work.", "startOffset": 249, "endOffset": 252}, {"referenceID": 5, "context": "Probabilistic models for optimization were motivated with three goals: as a new optimization method, as a method to incorporate simple learning (Hebbian style probability updates) into hillclimbing, and as a method to explain how genetic algorithms [5] [6] [7] might work.", "startOffset": 253, "endOffset": 256}, {"referenceID": 6, "context": "Probabilistic models for optimization were motivated with three goals: as a new optimization method, as a method to incorporate simple learning (Hebbian style probability updates) into hillclimbing, and as a method to explain how genetic algorithms [5] [6] [7] might work.", "startOffset": 257, "endOffset": 260}, {"referenceID": 7, "context": "Within the GA literature, one of the first attempts at using population level statistics was the \u201cBit-Based Simulated Crossover (BSC)\u201d operator [8].", "startOffset": 144, "endOffset": 147}, {"referenceID": 0, "context": "Extending the above idea and incorporating Hebbian learning, another early probabilistic optimization was the Population-Based Incremental Learning algorithm (PBIL) [1].", "startOffset": 165, "endOffset": 168}, {"referenceID": 8, "context": "PBIL is akin to a cooperative system of discrete learning automata in which the automata choose their actions independently, but all automata receive a common reinforcement dependent upon all their actions [9].", "startOffset": 206, "endOffset": 209}, {"referenceID": 1, "context": "A more theoretical analysis of PBIL can be found in [2][10][11][12][13][14].", "startOffset": 52, "endOffset": 55}, {"referenceID": 9, "context": "A more theoretical analysis of PBIL can be found in [2][10][11][12][13][14].", "startOffset": 55, "endOffset": 59}, {"referenceID": 10, "context": "A more theoretical analysis of PBIL can be found in [2][10][11][12][13][14].", "startOffset": 59, "endOffset": 63}, {"referenceID": 11, "context": "A more theoretical analysis of PBIL can be found in [2][10][11][12][13][14].", "startOffset": 63, "endOffset": 67}, {"referenceID": 12, "context": "A more theoretical analysis of PBIL can be found in [2][10][11][12][13][14].", "startOffset": 67, "endOffset": 71}, {"referenceID": 13, "context": "A more theoretical analysis of PBIL can be found in [2][10][11][12][13][14].", "startOffset": 71, "endOffset": 75}, {"referenceID": 14, "context": "Mutual Information Maximization for Input Clustering (MIMIC) [15] was one of the first to do this.", "startOffset": 61, "endOffset": 65}, {"referenceID": 15, "context": "In [16], MIMIC\u2019s probabilistic model was extended to a larger class of dependency graphs: trees in which each variable is conditioned on at most one parent.", "startOffset": 3, "endOffset": 7}, {"referenceID": 16, "context": "As shown in 1968, this created the optimal tree-shaped network for a maximum-likelihood model of the data [17].", "startOffset": 106, "endOffset": 110}, {"referenceID": 17, "context": "The trend indicated that more accurate probabilistic models increased the probability of generating new candidate solutions in promising regions of the search space [18].", "startOffset": 165, "endOffset": 169}, {"referenceID": 18, "context": "Bayesian networks are a popular method for efficiently representing dependencies [19] [20].", "startOffset": 81, "endOffset": 85}, {"referenceID": 19, "context": "Bayesian networks are a popular method for efficiently representing dependencies [19] [20].", "startOffset": 86, "endOffset": 90}, {"referenceID": 20, "context": "Numerous researchers have taken the step of combining full Bayesian networks with stochastic search [21] [22] [23].", "startOffset": 100, "endOffset": 104}, {"referenceID": 21, "context": "Numerous researchers have taken the step of combining full Bayesian networks with stochastic search [21] [22] [23].", "startOffset": 105, "endOffset": 109}, {"referenceID": 22, "context": "Numerous researchers have taken the step of combining full Bayesian networks with stochastic search [21] [22] [23].", "startOffset": 110, "endOffset": 114}, {"referenceID": 23, "context": "An alternate model building approach, termed STAGE, was presented in [25].", "startOffset": 69, "endOffset": 73}, {"referenceID": 23, "context": "We also describe how the model is integrated with fast-search heuristics, following the work of [25] and [16].", "startOffset": 96, "endOffset": 100}, {"referenceID": 15, "context": "We also describe how the model is integrated with fast-search heuristics, following the work of [25] and [16].", "startOffset": 105, "endOffset": 109}, {"referenceID": 24, "context": ") Although the architecture of the neural network used for modeling is manually specified, the actual dependencies that the network encodes need not be the same form for all parameters, nor are they deeply tied to architecture of the network [26].", "startOffset": 242, "endOffset": 246}, {"referenceID": 16, "context": "With models with dependencies, such as the dependency-trees [17], the sampling is simply conditioned on the variables on which the parameter is dependent (as specified in the tree-based model).", "startOffset": 60, "endOffset": 64}, {"referenceID": 25, "context": "This method was first presented in [27] and has recently been popularized within the context of texture and style generation with neural networks [28] [29].", "startOffset": 35, "endOffset": 39}, {"referenceID": 26, "context": "This method was first presented in [27] and has recently been popularized within the context of texture and style generation with neural networks [28] [29].", "startOffset": 146, "endOffset": 150}, {"referenceID": 27, "context": "This method was first presented in [27] and has recently been popularized within the context of texture and style generation with neural networks [28] [29].", "startOffset": 151, "endOffset": 155}, {"referenceID": 25, "context": "As described in [27], the procedure addresses the following question: \u201cWhich input should be fed into the net to produce an output which approximates the given target vector T\u2019 (in our case the the target vector T is a simple scalar of 1.", "startOffset": 16, "endOffset": 20}, {"referenceID": 28, "context": "In general, modest learning-rates for the gradient descent algorithm were found to work best for the network-inversion process (we used the Adam Optimizer [30] with learning-rate = 0.", "startOffset": 155, "endOffset": 159}, {"referenceID": 15, "context": "Two early works in probabilistic model-based optimization [16] [25] suggested the use of the probabilistic models as methods to initialize faster local-search optimization techniques.", "startOffset": 58, "endOffset": 62}, {"referenceID": 23, "context": "Two early works in probabilistic model-based optimization [16] [25] suggested the use of the probabilistic models as methods to initialize faster local-search optimization techniques.", "startOffset": 63, "endOffset": 67}, {"referenceID": 29, "context": "[31] [32] [33] [34].", "startOffset": 0, "endOffset": 4}, {"referenceID": 30, "context": "[31] [32] [33] [34].", "startOffset": 5, "endOffset": 9}, {"referenceID": 31, "context": "[31] [32] [33] [34].", "startOffset": 10, "endOffset": 14}, {"referenceID": 32, "context": "[31] [32] [33] [34].", "startOffset": 15, "endOffset": 19}, {"referenceID": 15, "context": "To keep S a constant size, after every NASH run, the last 1000 unique solutions from the NASH run are added to S, and S is pruned back by removing the members that have been in S the longest (this implements a simple first-in-first-out scheme), as was suggested in previous studies [16].", "startOffset": 282, "endOffset": 286}, {"referenceID": 23, "context": "Using problem-specific hand-crafted features, such as done with STAGE [25], may help.", "startOffset": 70, "endOffset": 74}, {"referenceID": 33, "context": "More details of the complexity of this problem can be found in [37].", "startOffset": 63, "endOffset": 67}, {"referenceID": 34, "context": "Interest in this problem stems from a variety of sources, including constraint satisfaction [38] and minimizing propagation delay in the layout of electronic cells.", "startOffset": 92, "endOffset": 96}, {"referenceID": 0, "context": "The simplest encoding is to use 100 real-valued outputs, one for each node, and divide the [0,1] region into 16 evenly spaced regions, each assigned to a single letter.", "startOffset": 91, "endOffset": 96}, {"referenceID": 15, "context": "To ground the discussion, let\u2019s examine a simple two dimensional checkerboard problem [16].", "startOffset": 86, "endOffset": 90}, {"referenceID": 35, "context": "To do this, we use a technique similar to stochastic sigmoid units in training the neural network to model the search space (for a recent paper on this and related topics, see [40]).", "startOffset": 176, "endOffset": 180}, {"referenceID": 36, "context": "It is obvious how alternative search heuristics such as simulated annealing [41] and TABU search [42] can easily be substituted as they are often used to search neighborhoods around a single point in a manner similar to NASH.", "startOffset": 76, "endOffset": 80}, {"referenceID": 37, "context": "It is obvious how alternative search heuristics such as simulated annealing [41] and TABU search [42] can easily be substituted as they are often used to search neighborhoods around a single point in a manner similar to NASH.", "startOffset": 97, "endOffset": 101}, {"referenceID": 29, "context": "Although we will not delve into the general debate of the merits of these simple techniques with more sophisticated search techniques, as this has been an active area of discussion for several decades [31] [43] [32] [33] [44] [45] [46], it is interesting, to consider the use of the probabilistic models with very different search paradigms, such as genetic algorithms.", "startOffset": 201, "endOffset": 205}, {"referenceID": 38, "context": "Although we will not delve into the general debate of the merits of these simple techniques with more sophisticated search techniques, as this has been an active area of discussion for several decades [31] [43] [32] [33] [44] [45] [46], it is interesting, to consider the use of the probabilistic models with very different search paradigms, such as genetic algorithms.", "startOffset": 206, "endOffset": 210}, {"referenceID": 30, "context": "Although we will not delve into the general debate of the merits of these simple techniques with more sophisticated search techniques, as this has been an active area of discussion for several decades [31] [43] [32] [33] [44] [45] [46], it is interesting, to consider the use of the probabilistic models with very different search paradigms, such as genetic algorithms.", "startOffset": 211, "endOffset": 215}, {"referenceID": 31, "context": "Although we will not delve into the general debate of the merits of these simple techniques with more sophisticated search techniques, as this has been an active area of discussion for several decades [31] [43] [32] [33] [44] [45] [46], it is interesting, to consider the use of the probabilistic models with very different search paradigms, such as genetic algorithms.", "startOffset": 216, "endOffset": 220}, {"referenceID": 39, "context": "Although we will not delve into the general debate of the merits of these simple techniques with more sophisticated search techniques, as this has been an active area of discussion for several decades [31] [43] [32] [33] [44] [45] [46], it is interesting, to consider the use of the probabilistic models with very different search paradigms, such as genetic algorithms.", "startOffset": 221, "endOffset": 225}, {"referenceID": 40, "context": "Although we will not delve into the general debate of the merits of these simple techniques with more sophisticated search techniques, as this has been an active area of discussion for several decades [31] [43] [32] [33] [44] [45] [46], it is interesting, to consider the use of the probabilistic models with very different search paradigms, such as genetic algorithms.", "startOffset": 226, "endOffset": 230}, {"referenceID": 41, "context": "Although we will not delve into the general debate of the merits of these simple techniques with more sophisticated search techniques, as this has been an active area of discussion for several decades [31] [43] [32] [33] [44] [45] [46], it is interesting, to consider the use of the probabilistic models with very different search paradigms, such as genetic algorithms.", "startOffset": 231, "endOffset": 235}, {"referenceID": 4, "context": "The newly created solutions are further randomly perturbed (mutated) to reveal the \u2019children\u2019 solutions that are the candidate solutions to evaluate next [5].", "startOffset": 154, "endOffset": 157}, {"referenceID": 4, "context": "To learn more about GAs, please see [5].", "startOffset": 36, "endOffset": 39}], "year": 2017, "abstractText": "In all but the most trivial optimization problems, the structure of the solutions exhibit complex interdependencies between the input parameters. Decades of research with stochastic search techniques has shown the benefit of explicitly modeling the interactions between sets of parameters and the overall quality of the solutions discovered. We demonstrate a novel method, based on learning deep networks, to model the global landscapes of optimization problems. To represent the search space concisely and accurately, the deep networks must encode information about the underlying parameter interactions and their contributions to the quality of the solution. Once the networks are trained, the networks are probed to reveal parameter combinations with high expected performance with respect to the optimization task. These estimates are used to initialize fast, randomized, local search algorithms, which in turn expose more information about the search space that is subsequently used to refine the models. We demonstrate the technique on multiple optimization problems that have arisen in a variety of real-world domains, including: packing, graphics, job scheduling, layout and compression. The problems include combinatoric search spaces, discontinuous and highly non-linear spaces, and span binary, higher-cardinality discrete, as well as continuous parameters. Strengths, limitations, and extensions of the approach are extensively discussed and demonstrated.", "creator": "LaTeX with hyperref package"}}}