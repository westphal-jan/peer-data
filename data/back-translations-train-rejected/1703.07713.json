{"id": "1703.07713", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Mar-2017", "title": "Hierarchical RNN with Static Sentence-Level Attention for Text-Based Speaker Change Detection", "abstract": "Traditional speaker change detection in dialogues is typically based on audio input. In some scenarios, however, researchers can only obtain text, and do not have access to raw audio signals. Moreover, with the increasing need of deep semantic processing, text-based dialogue understanding is attracting more attention in the community. These raise the problem of text-based speaker change detection. In this paper, we formulate the task as a matching problem of utterances before and after a certain decision point; we propose a hierarchical recurrent neural network (RNN) with static sentence-level attention. Our model comprises three main components: a sentence encoder with a long short term memory (LSTM)-based RNN, a context encoder with another LSTM-RNN, and a static sentence-level attention mechanism, which allows rich information interaction. Experimental results show that neural networks consistently achieve better performance than feature-based approaches, and that our attention-based model significantly outperforms non-attention neural networks.", "histories": [["v1", "Wed, 22 Mar 2017 15:42:28 GMT  (948kb,D)", "http://arxiv.org/abs/1703.07713v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["zhao meng", "lili mou", "zhi jin"], "accepted": false, "id": "1703.07713"}, "pdf": {"name": "1703.07713.pdf", "metadata": {"source": "CRF", "title": "Hierarchical RNN with Static Sentence-Level Attention for Text-Based Speaker Change Detection", "authors": ["Zhao Meng", "Lili Mou", "Zhi Jin"], "emails": ["zhaomeng.pku@outlook.com,", "doublepower.mou@gmail.com,", "zhijin@sei.pku.edu.cn"], "sections": [{"heading": null, "text": "Index terms: detection of loudspeaker changes, recurrent neural network, attention at sentence level"}, {"heading": "1. Introduction", "text": "This year it has come to the point that it has never come as far as it has this year, and it is only a matter of time before it comes to a solution."}, {"heading": "2. Related Work", "text": "It is a typical approach to compare successive input sliding windows - with spectral characteristics [14], say - with metrics encompassing the Bayesian information criterion. [15], generalized probability [16], and Kullback-Leibler-Diver-2Because our task is text-based (rather than online speaker recognition), we actually have access to the \"future context\" after the decision point."}, {"heading": "3. Approach", "text": "In this section, we describe the proposed approach in detail. Figure 1 illustrates our neural architecture, which consists of three parts. \u2022 First, an LSTM-based RNN encodes each piece of information around the decision point into a real vector (Figure 1a and Figure 3.1). \u2022 Then another LSTM-based RNN integrates the contextual information by traversing the sentence vectors on both sides of the current decision point (Figure 1b and Figure 3.2). \u2022 We also add a static attention mechanism at the sentence level to make better use of the context by focusing on more relevant information (Figure 1c and Figure 3.3)."}, {"heading": "3.1. Sentence Encoder", "text": "We use a recursive neural network (RNN) with long-term short-term memory (LSTM) to encode a sentence as a vector (also known as the embedding of a sentence), as shown in Figure 1a. An RNN is suitable for processing sequential data (e.g. a sentence consisting of several words) because it maintains a hidden state that changes at each step based on its previous state and current input. However, vanilla RNN with perceptron-like hidden states suffer from the problem of disappearing or exploding sequences [29, 30] as they are less effective at modelling long dependencies. LSTM units [31] alleviate the problem by better balancing the input and its previous state with gating mechanisms. Formally, we leave x (t) the embedding of the t-th word in a sentence and its last state \u2212 1."}, {"heading": "3.2. Context Encoder", "text": "Another LSTM-RNN encodes context information about sentence vectors, as shown in Figure 1b. As we model our task as a matching problem, we apply the RNN to both sides of the decision point separately, linking the resulting vectors as input of predictions. It should be noted that our LSTM-RNN moves from distant sentences to the next (so-called critical sentences) on both sides of the current decision point. We observe that closer sentences play a more important role in predicting; that a RNN by their nature stores newer input information better. Therefore, our treatment is appropriate. Furthermore, our neural network is hierarchical in composing sentences with words and discourses 3 with sentences. It is similar to the hierarchical auto-encoder in [32]. Other studies apply a single RNN via a discourse and also achieve high performance in tasks such as mood analysis [33] and machine understanding [34]."}, {"heading": "3.3. Our Attention Mechanism", "text": "We use an attention mechanism to make better use of contextual information. Attention-based neural networks are first proposed to dynamically focus on relevant words in the source sentence in machine translation. [11] In our scenario, we would like to align a critical sentence with all utterances on the other side of the decision point (Figure 1c), that is, the attention mechanism is applied to the sentence level, unlike other work that uses attention at the word level [12, 13]. Our method is much more efficient because a context of several sentences could contain hundreds of words.If we look at the t sentences (context size is t \u2212 1) before and after the decision point, we have 2 t sentences in total, namelys (1) p \u2192 s (2) p \u2192 \u00b7 \u00b7 \u00b7 s (t) p s (t) p \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 s (2 \u00b7 f), where \u00b7 f is the \u00b7 f (7)."}, {"heading": "4. Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1. Dataset Collection", "text": "In our experiments, we combed through transcripts of nearly 3,000 TV talk shows on the cable network's website4 (example shown in Figure 2) and extracted main content from the original HTML files. We used the Natural Language Toolkit5 to segment sentences and words. Transcripts contain speaker identities (highlighted by red rectangles) that we used to trigger speaker changes in the dialogue. In other words, each episode appears either in the training set or in the val / test sets. This avoids overlaps between training and prediction and is therefore a more realistic setting than splitting by utterance. Table 1 presents relevant statistics. We note that our corpus is larger than the previous metrics: the 1997 HUB4 dataset, and thus any changes are suitable for training."}, {"heading": "4.2. Settings", "text": "Because our data set is large, we randomly initialized word embeddings that were tuned during the training. We used the Adam Optimizer [35] with mini-batch update (batch size 100). Other hyperparameters were selected by validation: drop-out rate of {0.1, 0.3} and initial learning rate of 4http: / / transcripts.cnn.com 5http: / / www.nltk.org 6Each episode takes about an hour. {3 \u00d7 10 \u2212 4, 9 \u00d7 10 \u2212 4}. We also had several baselines with handmade features: We extracted unigram and bigram features of the critical sentences as two vectors that are concatenated for prediction. We applied logistic regression and a 3-layer deep neural network (DNN) as classifier. The former is a linear model, whereas the latter is non-linear. DNs hidden comparison for the networks (all 3) are included."}, {"heading": "4.3. Performance", "text": "As shown, all modern neural networks (CNNs / word-embedded RNNs) are consistently better than methods that use the craftsmanship characteristics of uniques and bigrams. Since we have applied a 3-layer DNN to these characteristics, we believe that the performance improvement is caused not only by the use of a better classifier, but also by the automatic function / representation of the learning nature of modern neural networks. For neural network-based sentence coders, we compared LSTM-RNN with CNN.7 The results show that LSTM-RNN outperforms CNN by 6% in terms of accuracy and F1measure. To cope with the context, the simplest approach is to use a word-level RNN as above to describe the surrounding expressions of critical sentences that are considered non-hierarchical."}, {"heading": "5. Conclusion", "text": "In this paper, we proposed a static attention at the sentence level LSTM-RNN for the detection of text-based speaker changes. Our model uses an LSTM-RNN to encode each utterance into a vector on the basis of which a different LSTM-RNN integrates context information, before and after a particular decision point. A static attention mechanism at the sentence level is also applied to improve information interaction. We trawled through dialog logs from cable news network TV talk shows for evaluation. Experimental results show the effectiveness of our approach. In particular, an in-depth analysis confirms that context-related information is actually helpful for the detection of speaker changes and that our tailored model can make better use of context than other neural networks."}, {"heading": "6. References", "text": "In recent years, the number of people receiving social benefits has multiplied in recent years."}], "references": [{"title": "Speaker diarization: A review of recent research", "author": ["X. Anguera Miro", "S. Bozonnet", "N. Evans", "C. Fredouille", "G. Friedland", "O. Vinyals"], "venue": "IEEE Transactions on Audio Speech and Language Processing, vol. 20, no. 2, pp. 356\u2013370, 2012.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "The Cambridge University March 2005 speaker diarisation system", "author": ["R. Sinha", "S.E. Tranter", "M.J. Gales", "P.C. Woodland"], "venue": "Proceedings of INTERSPEECH, 2005, pp. 2437\u20132440.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2005}, {"title": "Multi-domain dialog state tracking using recurrent neural networks", "author": ["N. Mrk\u0161i\u0107", "D. \u00d3 S\u00e9aghdha", "B. Thomson", "M. Gasic", "P.-H. Su", "D. Vandyke", "T.-H. Wen", "S. Young"], "venue": "Proceedings of the Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, vol. 2, 2015, pp. 794\u2013799.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}, {"title": "Speaker, environment and channel change detection and clustering via the Bayesian information criterion", "author": ["S. Chen", "P. Gopalakrishnan"], "venue": "Proceedings of DARPA Broadcast News Transcription and Understanding Workshop, 1998, pp. 127\u2013132.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1998}, {"title": "Speaker change detection using a new weighted distance measure", "author": ["S. Kwon", "S.S. Narayanan"], "venue": "Proceedings of INTER- SPEECH, 2002, pp. 2537\u20132540.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2002}, {"title": "A neural conversational model", "author": ["O. Vinyals", "Q. Le"], "venue": "ICML Workshop, 2015.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "A diversitypromoting objective function for neural conversation models", "author": ["J. Li", "M. Galley", "C. Brockett", "J. Gao", "B. Dolan"], "venue": "Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 2016, pp. 110\u2013119.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2016}, {"title": "News from OPUS-A collection of multilingual parallel corpora with tools and interfaces", "author": ["J. Tiedemann"], "venue": "Proceedings of Recent Advances in Natural Language Processing, 2009, pp. 237\u2013 248.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2009}, {"title": "Unsupervised speaker segmentation and tracking in real-time audio content analysis", "author": ["L. Lu", "H.-J. Zhang"], "venue": "Multimedia Systems, vol. 10, no. 4, pp. 332\u2013343, 2005.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2005}, {"title": "Strategies for automatic segmentation of audio data", "author": ["T. Kemp", "M. Schmidt", "M. Westphal", "A. Waibel"], "venue": "Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing, 2000, pp. 1423\u20131426.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2000}, {"title": "Neural machine translation by jointly learning to align and translate", "author": ["D. Bahdanau", "K. Cho", "Y. Bengio"], "venue": "Proceedings of the International Conference on Learning Representations, 2015.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2015}, {"title": "Effective approaches to attention-based neural machine translation", "author": ["T. Luong", "H. Pham", "C.D. Manning"], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing, 2015, pp. 1412\u20131421.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2015}, {"title": "Attention-based recurrent neural network models for joint intent detection and slot filling", "author": ["B. Liu", "I. Lane"], "venue": "Proceedings of INTERSPEECH, 2016, pp. 685\u2013689.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2016}, {"title": "Speaker change detection and tracking in real-time news broadcasting analysis", "author": ["L. Lu", "H.-J. Zhang"], "venue": "Proceedings of the Tenth ACM International Conference on Multimedia, 2002, pp. 602\u2013610.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2002}, {"title": "Speaker change detection and speaker clustering using VQ distortion for broadcast news speech recognition", "author": ["K. Mori", "S. Nakagawa"], "venue": "Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing, 2001, pp. 413\u2013416.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2001}, {"title": "Segregation of speakers for speech recognition and speaker identification", "author": ["H. Gish", "M.-H. Siu", "R. Rohlicek"], "venue": "Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing, 1991, pp. 873\u2013876.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1991}, {"title": "Automatic segmentation, classification and clustering of broadcast news audio", "author": ["M.A. Siegler", "U. Jain", "B. Raj", "R.M. Stern"], "venue": "Proceedings of DARPA Speech Recognition Workshop, 1997.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1997}, {"title": "Improving speaker segmentation via speaker identification and text segmentation.", "author": ["R. Li", "T. Schultz", "Q. Jin"], "venue": "Proceedings of INTERSPEECH,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2009}, {"title": "Wikipedia-based kernels for dialogue topic tracking", "author": ["S. Kim", "R.E. Banchs", "H. Li"], "venue": "Proceedings of IEEE International Conference on Acoustics, Speech and Signal Processing, 2014, pp. 131\u2013135.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "Neural attention models for sequence classification: Analysis and application to key term extraction and dialogue act detection", "author": ["S.-S. Shen", "H.-Y. Lee"], "venue": "Proceedings of INTERSPEECH, 2016, pp. 2716\u20132720.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2016}, {"title": "Sequential convolutional neural networks for slot filling in spoken language understanding", "author": ["N.T. Vu"], "venue": "Proceedings of INTER- SPEECH, 2016, pp. 3250\u20133254.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2016}, {"title": "Unsupervised user intent modeling by feature-enriched matrix factorization", "author": ["Y.-N. Chen", "M. Sun", "A.I. Rudnicky", "A. Gershman"], "venue": "Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing, 2016, pp. 6150\u20136154.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2016}, {"title": "Dialogue session segmentation by embedding-enhanced texttiling", "author": ["Y. Song", "L. Mou", "R. Yan", "L. Yi", "Z. Zhu", "X. Hu", "M. Zhang"], "venue": "Proceedings of INTERSPEECH, 2016, pp. 2706\u20132710.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2016}, {"title": "Convolutional neural network architectures for matching natural language sentences", "author": ["B. Hu", "Z. Lu", "H. Li", "Q. Chen"], "venue": "Advances in Neural Information Processing Systems, 2014, pp. 2042\u20132050.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2014}, {"title": "Natural language inference by tree-based convolution and heuristic matching", "author": ["L. Mou", "R. Men", "G. Li", "Y. Xu", "L. Zhang", "R. Yan", "Z. Jin"], "venue": "Proceedings of the Annual Meeting of the Association for Computational Linguistics, vol. 2, 2016, pp. 130\u2013136.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2016}, {"title": "A large annotated corpus for learning natural language inference", "author": ["S.R. Bowman", "G. Angeli", "C. Potts", "C.D. Manning"], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing, 2015, pp. 632\u2013642.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2015}, {"title": "Reasoning about entailment with neural attention", "author": ["T. Rockt\u00e4schel", "E. Grefenstette", "K.M. Hermann", "T. Ko\u010disk\u1ef3", "P. Blunsom"], "venue": "Proceedings of the International Conference on Learning Representations, 2016.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2016}, {"title": "Learning to respond with deep neural networks for retrieval-based human-computer conversation system", "author": ["R. Yan", "Y. Song", "H. Wu"], "venue": "Proceedings of the 39th International ACM SI- GIR Conference on Research and Development in Information Retrieval, 2016, pp. 55\u201364.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2016}, {"title": "Learning long-term dependencies with gradient descent is difficult", "author": ["Y. Bengio", "P. Simard", "P. Frasconi"], "venue": "IEEE Transactions on Neural Networks, vol. 5, no. 2, pp. 157\u2013166, 1994.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1994}, {"title": "The vanishing gradient problem during learning recurrent neural nets and problem solutions", "author": ["S. Hochreiter"], "venue": "International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems, vol. 6, no. 02, pp. 107\u2013116, 1998.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 1998}, {"title": "Long short-term memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural Computation, vol. 9, no. 8, pp. 1735\u20131780, 1997.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 1997}, {"title": "A hierarchical neural autoencoder for paragraphs and documents", "author": ["J. Li", "T. Luong", "D. Jurafsky"], "venue": "Proceedings of the Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, 2015, pp. 1106\u20131115.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2015}, {"title": "Cached long short-term memory neural networks for document-level sentiment classification", "author": ["J. Xu", "D. Chen", "X. Qiu", "X. Huang"], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing, 2016, pp. 1660\u20131669.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2016}, {"title": "Bidirectional attention flow for machine comprehension", "author": ["M. Seo", "A. Kembhavi", "A. Farhadi", "H. Hajishirzi"], "venue": "arXiv preprint arXiv:1611.01603, 2016.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2016}, {"title": "Adam: A method for stochastic optimization", "author": ["D. Kingma", "J. Ba"], "venue": "Proceedings of the International Conference for Learning Representations, 2014.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "Specifically, a speaker change occurs when the current and the next sentences are not uttered by the same speaker [1].", "startOffset": 114, "endOffset": 117}, {"referenceID": 1, "context": "Detecting speaker changes plays an important role in dialogue processing, and is a premise of speaker clustering [2], dialogue understanding [3], etc.", "startOffset": 113, "endOffset": 116}, {"referenceID": 2, "context": "Detecting speaker changes plays an important role in dialogue processing, and is a premise of speaker clustering [2], dialogue understanding [3], etc.", "startOffset": 141, "endOffset": 144}, {"referenceID": 3, "context": "Traditional speaker change detection typically uses audio input [4, 5].", "startOffset": 64, "endOffset": 70}, {"referenceID": 4, "context": "Traditional speaker change detection typically uses audio input [4, 5].", "startOffset": 64, "endOffset": 70}, {"referenceID": 5, "context": "Further, the fast development of dialogue analysis puts high demands on understanding textual data [6, 7], as human-computer conversation involves deep semantics, requiring complicated natural language processing (NLP).", "startOffset": 99, "endOffset": 105}, {"referenceID": 6, "context": "Further, the fast development of dialogue analysis puts high demands on understanding textual data [6, 7], as human-computer conversation involves deep semantics, requiring complicated natural language processing (NLP).", "startOffset": 99, "endOffset": 105}, {"referenceID": 5, "context": "[6] and Li et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[7], for example, train sequence-to-sequence neural networks to automatically generate replies in an open-domain dialogue system.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "They use OpenSubtitle [8] as the corpus, but assume every two consecutive sentences are uttered by different speakers (which brings much noise to their training data).", "startOffset": 22, "endOffset": 25}, {"referenceID": 8, "context": ", pitch [9] and silence points [10], which provide", "startOffset": 8, "endOffset": 11}, {"referenceID": 9, "context": ", pitch [9] and silence points [10], which provide", "startOffset": 31, "endOffset": 35}, {"referenceID": 10, "context": "To better explore the context, we further apply an attention mechanism [11] over sentences to focus on relevant information during context integration.", "startOffset": 71, "endOffset": 75}, {"referenceID": 10, "context": "Our attention is static in that only the nearest two sentences around the decision point search for relevant information; it differs from previous research that uses dynamic attention [11, 12], which buries more important sentences under less important context.", "startOffset": 184, "endOffset": 192}, {"referenceID": 11, "context": "Our attention is static in that only the nearest two sentences around the decision point search for relevant information; it differs from previous research that uses dynamic attention [11, 12], which buries more important sentences under less important context.", "startOffset": 184, "endOffset": 192}, {"referenceID": 11, "context": "Compared with word-level attention [12, 13], our sentence-level attention is more efficient because there could be hundreds of words in the context within only a few sentences.", "startOffset": 35, "endOffset": 43}, {"referenceID": 12, "context": "Compared with word-level attention [12, 13], our sentence-level attention is more efficient because there could be hundreds of words in the context within only a few sentences.", "startOffset": 35, "endOffset": 43}, {"referenceID": 0, "context": "Traditional speaker change detection deals with audio input and is a key step for speaker diarization (determining \u201cwho spoke when?\u201d) [1].", "startOffset": 134, "endOffset": 137}, {"referenceID": 13, "context": "A typical approach is to compare consecutive sliding windows of input\u2014with spectral features [14], say\u2014 using metrics including the Bayesian information criterion [15], generalized likelihood ratio [16], and Kullback-Leibler diver-", "startOffset": 93, "endOffset": 97}, {"referenceID": 14, "context": "A typical approach is to compare consecutive sliding windows of input\u2014with spectral features [14], say\u2014 using metrics including the Bayesian information criterion [15], generalized likelihood ratio [16], and Kullback-Leibler diver-", "startOffset": 163, "endOffset": 167}, {"referenceID": 15, "context": "A typical approach is to compare consecutive sliding windows of input\u2014with spectral features [14], say\u2014 using metrics including the Bayesian information criterion [15], generalized likelihood ratio [16], and Kullback-Leibler diver-", "startOffset": 198, "endOffset": 202}, {"referenceID": 16, "context": "gence [17].", "startOffset": 6, "endOffset": 10}, {"referenceID": 6, "context": ", OpenSubtitle) [7], and enhancing audio speaker change detection with textual information [18].", "startOffset": 16, "endOffset": 19}, {"referenceID": 17, "context": ", OpenSubtitle) [7], and enhancing audio speaker change detection with textual information [18].", "startOffset": 91, "endOffset": 95}, {"referenceID": 18, "context": "Previous research has addressed a variety of tasks, ranging from topic tracking [19], dialogue act classification [20], slot filling [21], to user intent modeling [22].", "startOffset": 80, "endOffset": 84}, {"referenceID": 19, "context": "Previous research has addressed a variety of tasks, ranging from topic tracking [19], dialogue act classification [20], slot filling [21], to user intent modeling [22].", "startOffset": 114, "endOffset": 118}, {"referenceID": 20, "context": "Previous research has addressed a variety of tasks, ranging from topic tracking [19], dialogue act classification [20], slot filling [21], to user intent modeling [22].", "startOffset": 133, "endOffset": 137}, {"referenceID": 21, "context": "Previous research has addressed a variety of tasks, ranging from topic tracking [19], dialogue act classification [20], slot filling [21], to user intent modeling [22].", "startOffset": 163, "endOffset": 167}, {"referenceID": 22, "context": "In our previous study, we address the problem of session segmentation in text-based human-computer conversations [23].", "startOffset": 113, "endOffset": 117}, {"referenceID": 17, "context": "[18] enhance audio-based speaker change detection with transcribed text, and they are also in the unsupervised regime.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": ", paraphrase and logical entailment) between two sentences [24, 25, 26]; Rockt\u00e4schel et al.", "startOffset": 59, "endOffset": 71}, {"referenceID": 24, "context": ", paraphrase and logical entailment) between two sentences [24, 25, 26]; Rockt\u00e4schel et al.", "startOffset": 59, "endOffset": 71}, {"referenceID": 25, "context": ", paraphrase and logical entailment) between two sentences [24, 25, 26]; Rockt\u00e4schel et al.", "startOffset": 59, "endOffset": 71}, {"referenceID": 26, "context": "[27] equip RNN with attention mechanisms.", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "[28] rerank candidate replies based on a user-issued query; they enhance sentence-pair modeling with previous utterances as context.", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "But vanilla RNNs with perceptron-like hidden states suffer from the problem of vanishing or exploding gradients [29, 30], being less effective to model long dependencies.", "startOffset": 112, "endOffset": 120}, {"referenceID": 29, "context": "But vanilla RNNs with perceptron-like hidden states suffer from the problem of vanishing or exploding gradients [29, 30], being less effective to model long dependencies.", "startOffset": 112, "endOffset": 120}, {"referenceID": 30, "context": "LSTM units [31] alleviate the problem by better balancing input and its previous state with gating mechanisms.", "startOffset": 11, "endOffset": 15}, {"referenceID": 31, "context": "It is similar to the hierarchical autoencoder in [32].", "startOffset": 49, "endOffset": 53}, {"referenceID": 32, "context": "Other studies apply a single RNN over a discourse, also achieving high performance in tasks like sentiment analysis [33] and machine comprehension [34].", "startOffset": 116, "endOffset": 120}, {"referenceID": 33, "context": "Other studies apply a single RNN over a discourse, also achieving high performance in tasks like sentiment analysis [33] and machine comprehension [34].", "startOffset": 147, "endOffset": 151}, {"referenceID": 10, "context": "Attention-based neural networks are first proposed to dynamically focus on relevant words of the source sentence in machine translation [11].", "startOffset": 136, "endOffset": 140}, {"referenceID": 11, "context": "That is to say, the attention mechanism is applied to the sentence level, different from other work that uses word-level attention [12, 13].", "startOffset": 131, "endOffset": 139}, {"referenceID": 12, "context": "That is to say, the attention mechanism is applied to the sentence level, different from other work that uses word-level attention [12, 13].", "startOffset": 131, "endOffset": 139}, {"referenceID": 26, "context": "It resembles a variant in [27], but differs from common attention where two LSTMs interact dynamically along their propagations (Figure 1d).", "startOffset": 26, "endOffset": 30}, {"referenceID": 34, "context": "We used the Adam optimizer [35] with mini-batch update (batch size being 100).", "startOffset": 27, "endOffset": 31}, {"referenceID": 10, "context": "We also tried a dynamic sentence-by-sentence attention mechanism, similar to most existing work [11, 12, 13].", "startOffset": 96, "endOffset": 108}, {"referenceID": 11, "context": "We also tried a dynamic sentence-by-sentence attention mechanism, similar to most existing work [11, 12, 13].", "startOffset": 96, "endOffset": 108}, {"referenceID": 12, "context": "We also tried a dynamic sentence-by-sentence attention mechanism, similar to most existing work [11, 12, 13].", "startOffset": 96, "endOffset": 108}], "year": 2017, "abstractText": "Traditional speaker change detection in dialogues is typically based on audio input. In some scenarios, however, researchers can only obtain text, and do not have access to raw audio signals. Moreover, with the increasing need of deep semantic processing, text-based dialogue understanding is attracting more attention in the community. These raise the problem of textbased speaker change detection. In this paper, we formulate the task as a matching problem of utterances before and after a certain decision point; we propose a hierarchical recurrent neural network (RNN) with static sentence-level attention. Our model comprises three main components: a sentence encoder with a long short term memory (LSTM)-based RNN, a context encoder with another LSTM-RNN, and a static sentence-level attention mechanism, which allows rich information interaction. Experimental results show that neural networks consistently achieve better performance than feature-based approaches, and that our attention-based model significantly outperforms nonattention neural networks.", "creator": "LaTeX with hyperref package"}}}