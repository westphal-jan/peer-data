{"id": "1703.07822", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Mar-2017", "title": "Information-theoretic Model Identification and Policy Search using Physics Engines with Application to Robotic Manipulation", "abstract": "We consider the problem of a robot learning the mechanical properties of objects through physical interaction with the object, and introduce a practical, data-efficient approach for identifying the motion models of these objects. The proposed method utilizes a physics engine, where the robot seeks to identify the inertial and friction parameters of the object by simulating its motion under different values of the parameters and identifying those that result in a simulation which matches the observed real motions. The problem is solved in a Bayesian optimization framework. The same framework is used for both identifying the model of an object online and searching for a policy that would minimize a given cost function according to the identified model. Experimental results both in simulation and using a real robot indicate that the proposed method outperforms state-of-the-art model-free reinforcement learning approaches.", "histories": [["v1", "Wed, 22 Mar 2017 19:08:48 GMT  (7221kb,D)", "http://arxiv.org/abs/1703.07822v1", null]], "reviews": [], "SUBJECTS": "cs.RO cs.AI cs.LG", "authors": ["shaojun zhu", "rew kimmel", "abdeslam boularias"], "accepted": false, "id": "1703.07822"}, "pdf": {"name": "1703.07822.pdf", "metadata": {"source": "CRF", "title": "Information-theoretic Model Identification and Policy Search using Physics Engines with Application to Robotic Manipulation", "authors": ["Shaojun Zhu", "Andrew Kimmel", "Abdeslam Boularias"], "emails": ["abdeslam.boularias}@cs.rutgers.edu"], "sections": [{"heading": null, "text": "I. INTRODUCTIONConsider the scenario shown in Figure 1, where a robot (Motoman) helps another robot (Baxter) that cannot reach its desired object. Due to the positioning of the robots in the scene, the intersection of the reachable working area of each robot is empty, which prevents the robots from performing a \"direct hand-off\" maneuver. In this case, the Motoman robot must take advantage of the dynamic physical properties of the object to \"push\" it onto the Baxter robot. Ideally, this action would occur without the intervention or assistance of an external operator, such as a human. Learning the physical properties of an object and predicting its movement under physical interaction is a critical aspect of this challenge. If the robot simply performs a maximum speed on the object, the result could cause the object to leave the working area of the robot (i.e. that it falls off the table), the automatic optimization of the system will be negated."}, {"heading": "II. RELATED WORK", "text": "Several physics models have been used to simulate robots, as well as the objects with which they interact. Examples of this are Bullet [2], MuJoCo [3], DART [4], Havok [5], and Grassi [5]. An investigation and comparison of these tools can be found in [5]. Data acquisition is a popular approach that lies at the core of control techniques. Examples are model reinforcement measures."}, {"heading": "III. PROPOSED APPROACH", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. System Overview", "text": "To solve the problem of modeling mechanical properties of objects, this paper proposes an online learning approach for identifying mass and sliding models of objects by Bayesian optimization, with the aim of enabling the robot to use predefined models of objects in the form of previous distributions and to improve the accuracy of these models by interacting with the objects. This learning process must take place in real time, since it takes place simultaneously with the physical interaction.Figure 2 shows an overview of the proposed approach. The first step is to use a pre-formed object detector to detect the various objects present in the scene and to estimate their poses by mapping them to a knowledge base of existing 3D mesh models. The proposed method extends the 3D mesh models of each object with the mechanical properties, which correspond to the mass of the object as well as the static and kinetic friction parameters as initial parameters."}, {"heading": "B. Model Identification", "text": "In view of a previous distribution Pt and a new observation (xt + 1, xt + 1), a physical engine is used to estimate a subordinate distribution Pt + 1 on the model parameters p + 1. We are currently using the bullet physics engine [2]. The goal is to identify the model parameters that make the result x + 1 of the simulation as close as possible to the actual observed result xt + 1. In other terms, the following black box optimization problem is solved: p = arg minute distribution def = 1 \u2212 f (xt, \u00b5t)."}, {"heading": "C. Policy Optimization", "text": "Considering a distribution Pt on the model (e.g., friction parameters and mass) and cost function J: emerging \u2192 R, where \u03c4 = (x0, \u00b50, x1, \u00b51,... xH \u2212 1, \u00b5H \u2212 1, xH) is a path of predicted object positions and applied forces, the robot must find a feedback velocity along a given thrust direction, which returns an action \u00b5t in pose of the object. Since the transition parameter used by the physics machine is deterministic, the transition model is defined as function f, which parameterizes as input an initial pose x0 and an applied technique (e.g., end effector velocity along a given thrust direction).Since the physics machine we use is deterministic, the transition parameter used by the physics machine can be a function f, which takes as input an initial pose x0 and a applied technique, a model parameter."}, {"heading": "IV. EXPERIMENTS", "text": "For all experiments we used Blender [35], which uses the physics engine Bullet [2]. PHYSIM 6DPose [36] was used to track the object and to provide the initial and final positions of the object by means of a RealSense depth camera on the fuselage of the Motoman robot. Videos of the experiments can be found here: https: / / goo.gl / 8Pi2Gu."}, {"heading": "A. Learning Physical Properties for Motion Prediction", "text": "1) Data Collection and Evaluation Metrics: In this preliminary experiment, a Reflex SF robotic error was mounted with the hand on the right arm of a Motoman SDA10F manipulator to randomly push a simple rigid object on a tabletop, as shown in Figure 3. We learn the parameters of the object model \u03b8 (mass and coefficient of friction) of an expo eraser. During data acquisition, no human effort is required to reset the scene, since both the speed and the sliding alignment were controlled so that the object was always in the working area of the robot hand. On the basis of the collected slider data, the physical properties of the object were learned to predict the movement of the object under new actions. Fifteen random sliding actions were performed, as due to inaccurate tracking caused by incidents, discarded. Of the remaining nine actions, six were used for training and the other three for testing. In order to measure the accuracy of the learned model, the final object was recorded between the predicted position and the predicted error."}, {"heading": "B. Policy Optimization using the Motion Prediction Model", "text": "1) Structure: In this experiment, the task is to push the object from a starting region to a fixed target position, similar to IV-A, a motomanic manipulator that pushes an expo eraser with the help of a reflex hand. In each attempt, we push the object twice towards the target, as in Figure 6. In this experiment, the political parameter \u03b7 is the push direction. 25 random actions are scanned and the action that can push the object closest to the target position is selected to be executed. 2) Results: We compare the slide results using a motion prediction model with two parameters: one is learned using Greedy Entropy Search, the other using Random Search. Figure 7 shows that the model using Greedy Entropy Search enabled the robot to push the object close to target position 7 out of 10 attempts, while the other only did so 4 times."}, {"heading": "C. High Speed Push Policy Optimization using Model Trained with Low Speed Push", "text": "Previously, the actions were limited to low speeds, so the object was always within the reachable working range of the robot. However, to solve the challenge shown in Figure 1, faster push actions are required. However, the friction between the object and the contact surface varies as the object moves at different speeds. We can collect data by using a higher speed push in a manner similar to IV-A.1. However, this also means that much more human resets are required, as the robot would push the object away from its working area, sometimes even from the table. In this experiment, we avoid human resets and aim to optimize a high speed policy that pushes the data at a low speed. 1) Setup: In this experiment, the task is to push the bottle from one side of the table to the other, which is about one meter away, as in Figure 8. We aim to find the optimal policy with parameters that represent the pushing speed of the robotic hand."}, {"heading": "V. CONCLUSION AND FUTURE WORK", "text": "In this paper, we presented a data-efficient online learning method for identifying mechanical properties of objects. Experimental results, both in simulation and using a real robot, show that the method exceeds model-free learning methods for amplification. An important aspect of robot learning is how much real roll-out data is sufficient to achieve a certain success rate. We are currently working on evaluating model safety by calculating the expected success rate using the uncertainty of the model. In the future, more efficient methods for handling model parameters of non-homogeneous objects could be an interesting direction for the future, which may help to support scaling into more complex environments. While this work only takes into account random exploratory measures, a smarter method for exploring the action space could be helpful. Furthermore, it would be interesting to investigate the combination of the trained deep models with a high efficiency of online data generation."}], "references": [{"title": "Learning to poke by poking: Experiential learning of intuitive physics", "author": ["Pulkit Agrawal", "Ashvin Nair", "Pieter Abbeel", "Jitendra Malik", "Sergey Levine"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2016}, {"title": "Graspit!: A Versatile Simulator for Robotic Grasping", "author": ["Andrew Miller", "Peter K. Allen"], "venue": "IEEE Robotics and Automation Magazine,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2004}, {"title": "Simulation tools for model-based robotics: Comparison of bullet, havok, mujoco, ODE and physx", "author": ["Tom Erez", "Yuval Tassa", "Emanuel Todorov"], "venue": "In IEEE International Conference on Robotics and Automation,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2015}, {"title": "Introduction to Reinforcement Learning", "author": ["Richard S. Sutton", "Andrew G. Barto"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1998}, {"title": "Inferring mass in complex scenes by mental", "author": ["J. Hamrick", "P.W. Battaglia", "T.L. Griffiths", "J.B. Tenenbaum"], "venue": "simulation. Cognition,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2016}, {"title": "A compositional object-based approach to learning physical dynamics. Under review as a conference paper for ICLR, 2017", "author": ["M.B. Chang", "T. Ullman", "A. Torralba", "J.B. Tenenbaum"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2017}, {"title": "Interaction networks for learning about objects, relations and physics", "author": ["P. Battaglia", "R. Pascanu", "M. Lai", "D.J. Rezende", "K. Koray"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2016}, {"title": "Physics-Based Grasp Planning Through Clutter", "author": ["Mehmet Dogar", "Kaijen Hsiao", "Matei Ciocarlie", "Siddhartha Srinivasa"], "venue": "In Robotics: Science and Systems VIII,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2012}, {"title": "Stable pushing: Mechanics, controllability, and planning", "author": ["K.M. Lynch", "M.T. Mason"], "venue": "IJRR,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1996}, {"title": "Push-manipulation of Complex Passive Mobile Objects Using Experimentally Acquired Motion Models", "author": ["Tekin Merili", "Manuela Veloso", "H.Levent Akin"], "venue": "Autonomous Robots,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2014}, {"title": "A Physics-Based Model Prior for Object-Oriented MDPs", "author": ["Jonathan Scholz", "Martin Levihn", "Charles L. Isbell", "David Wingate"], "venue": "In Proceedings of the 31st International Conference on Machine Learning (ICML),", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2014}, {"title": "A convex polynomial force-motion model for planar sliding: Identification and application", "author": ["Jiaji Zhou", "Robert Paolini", "J. Andrew Bagnell", "Matthew T. Mason"], "venue": "In 2016 IEEE International Conference on Robotics and Automation,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2016}, {"title": "Learning to Control a Low-Cost Manipulator using Data-Efficient Reinforcement Learning", "author": ["M. Deisenroth", "C. Rasmussen", "D. Fox"], "venue": "In Robotics: Science and Systems (RSS),", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2011}, {"title": "Attend, infer, repeat: Fast scene understanding with generative models", "author": ["S.M. Ali Eslami", "Nicolas Heess", "Theophane Weber", "Yuval Tassa", "Koray Kavukcuoglu", "Geoffrey E. Hinton"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2016}, {"title": "Learning visual predictive models of physics for playing billiards", "author": ["Katerina Fragkiadaki", "Pulkit Agrawal", "Sergey Levine", "Jitendra Malik"], "venue": "In ICLR,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2016}, {"title": "Learning physics from dynamical scenes", "author": ["Tomer D. Ullman", "Andreas Stuhlm\u00fcller", "Noah D. Goodman", "Joshua B. Tenenbaum"], "venue": "In Proceedings of the Thirty-Sixth Annual Conference of the Cognitive Science Society,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2014}, {"title": "Se3-nets: Learning rigid body motion using deep neural networks", "author": ["Arunkumar Byravan", "Dieter Fox"], "venue": null, "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2016}, {"title": "Deep visual foresight for planning robot motion. ICRA 2017", "author": ["Chelsea Finn", "Sergey Levine"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2017}, {"title": "A comparative evaluation of approximate probabilistic simulation and deep neural networks as accounts of human physical scene understanding", "author": ["Renqiao Zhang", "Jiajun Wu", "Chengkai Zhang", "William T. Freeman", "Joshua B. Tenenbaum"], "venue": null, "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2016}, {"title": "To fall or not to fall: A visual approach to physical stability prediction", "author": ["Wenbin Li", "Seyedmajid Azimi", "Ales Leonardis", "Mario Fritz"], "venue": null, "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2016}, {"title": "Learning physical intuition of block towers by example", "author": ["Adam Lerer", "Sam Gross", "Rob Fergus"], "venue": "In Proceedings of the 33nd International Conference on Machine Learning,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2016}, {"title": "The curious robot: Learning visual representations via physical interactions", "author": ["Lerrel Pinto", "Dhiraj Gandhi", "Yuanfeng Han", "Yong-Lae Park", "Abhinav Gupta"], "venue": null, "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2016}, {"title": "Visual stability prediction and its application to manipulation", "author": ["Wenbin Li", "Ales Leonardis", "Mario Fritz"], "venue": null, "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2016}, {"title": "Learning to Perform Physics Experiments via Deep Reinforcement Learning, 2016", "author": ["Misha Denil", "Pulkit Agrawal", "Tejas D. Kulkarni", "Tom Erez", "Peter Battaglia", "Nando de Freitas"], "venue": null, "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2016}, {"title": "Shape and pose recovery from planar pushing", "author": ["Kuan-Ting Yu", "John J. Leonard", "Alberto Rodriguez"], "venue": "In 2015 IEEE/RSJ International Conference on Intelligent Robots and Systems,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2015}, {"title": "Entropy Search for Information-Efficient Global Optimization", "author": ["Philipp Hennig", "Christian J. Schuler"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2012}, {"title": "Gaussian Processes for Machine Learning", "author": ["Carl Edward Rasmussen", "Christopher K.I. Williams"], "venue": null, "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2005}, {"title": "More than a million ways to be pushed: A high-fidelity experimental data set of planar pushing", "author": ["Kuan-Ting Yu", "Maria Bauza", "Nima Fazeli", "Alberto Rodriguez"], "venue": "arXiv preprint arXiv:1604.04038,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2016}, {"title": "Policy search for motor primitives in robotics", "author": ["Jens Kober", "Jan R Peters"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2009}], "referenceMentions": [{"referenceID": 0, "context": "First, a real robot is used to perform some random pushing action with an object on a tabletop [1].", "startOffset": 95, "endOffset": 98}, {"referenceID": 1, "context": "Examples of popular physics engines frequently used in robotics include Bullet [2], MuJoCo [3], DART [4], PhysX [5], Havok [6], ODE [7], and GraspIt! [8].", "startOffset": 150, "endOffset": 153}, {"referenceID": 2, "context": "A survey and a comparison of these tools are given in [9].", "startOffset": 54, "endOffset": 57}, {"referenceID": 3, "context": "Examples of these techniques include model-based reinforcement learning for instance [10].", "startOffset": 85, "endOffset": 89}, {"referenceID": 4, "context": "Several cognitive models that combine Bayesian inference with approximate knowledge of Newtonian physics have been proposed recently [11]\u2013[13].", "startOffset": 133, "endOffset": 137}, {"referenceID": 6, "context": "Several cognitive models that combine Bayesian inference with approximate knowledge of Newtonian physics have been proposed recently [11]\u2013[13].", "startOffset": 138, "endOffset": 142}, {"referenceID": 7, "context": "Model-based approaches [14]\u2013[18] rely on accurate models for objects and their properties.", "startOffset": 23, "endOffset": 27}, {"referenceID": 11, "context": "Model-based approaches [14]\u2013[18] rely on accurate models for objects and their properties.", "startOffset": 28, "endOffset": 32}, {"referenceID": 7, "context": "A physics-based simulation was used in [14] for predicting the effects of pushing actions, but the authors considered only flat, well-separated objects on a smooth surface.", "startOffset": 39, "endOffset": 43}, {"referenceID": 9, "context": "A nonparametric approach was used in [16] for learning the outcome of pushing large objects (furniture).", "startOffset": 37, "endOffset": 41}, {"referenceID": 10, "context": "A Markov Decision Process (MDP) is used in [17] for modeling interactions between objects, however, only simulation results on pushing were reported in that work.", "startOffset": 43, "endOffset": 47}, {"referenceID": 12, "context": "Other Bayesian model-based techniques, such as PILCO [19], have been proven efficient in utilizing a small amount of data for learning dynamical models and optimal policies.", "startOffset": 53, "endOffset": 57}, {"referenceID": 0, "context": "Another alternative, which is becoming increasingly popular, addresses these challenges through end-to-end learning [1], [20]\u2013[31].", "startOffset": 116, "endOffset": 119}, {"referenceID": 13, "context": "Another alternative, which is becoming increasingly popular, addresses these challenges through end-to-end learning [1], [20]\u2013[31].", "startOffset": 121, "endOffset": 125}, {"referenceID": 23, "context": "Another alternative, which is becoming increasingly popular, addresses these challenges through end-to-end learning [1], [20]\u2013[31].", "startOffset": 126, "endOffset": 130}, {"referenceID": 8, "context": "Note that there is a significant body of work on learning sliding models of objects using white-box optimization [15], [18], [32].", "startOffset": 113, "endOffset": 117}, {"referenceID": 11, "context": "Note that there is a significant body of work on learning sliding models of objects using white-box optimization [15], [18], [32].", "startOffset": 119, "endOffset": 123}, {"referenceID": 24, "context": "Note that there is a significant body of work on learning sliding models of objects using white-box optimization [15], [18], [32].", "startOffset": 125, "endOffset": 129}, {"referenceID": 11, "context": "A drawback of white-box methods is that they are often used only in simple setups, such as pushing planar objects [18].", "startOffset": 114, "endOffset": 118}, {"referenceID": 25, "context": "This paper formulates this challenge in a Bayesian optimization framework, which uses the Entropy Search technique presented in [33].", "startOffset": 128, "endOffset": 132}, {"referenceID": 26, "context": "Readers can find more details in textbooks on how Gaussian processes are updated from data and how to get the GP belief p on unknown function E from data points E(\u03b8i) [34].", "startOffset": 167, "endOffset": 171}, {"referenceID": 27, "context": "Additionally, a large scale planar push dataset [37] was also used to validate the proposed method.", "startOffset": 48, "endOffset": 52}, {"referenceID": 27, "context": "Greedy Entropy Search achieved lower error in both (a) the data collected with Motoman and (b) the planar push dataset [37].", "startOffset": 119, "endOffset": 123}, {"referenceID": 27, "context": "The proposed method was also tested using a large scale pushing dataset [37].", "startOffset": 72, "endOffset": 76}, {"referenceID": 28, "context": "approach with a model-free reinforcement learning method: Policy learning by Weighting Exploration with the Returns (PoWER) [38].", "startOffset": 124, "endOffset": 128}], "year": 2017, "abstractText": "We consider the problem of a robot learning the mechanical properties of objects through physical interaction with the object, and introduce a practical, data-efficient approach for identifying the motion models of these objects. The proposed method utilizes a physics engine, where the robot seeks to identify the inertial and friction parameters of the object by simulating its motion under different values of the parameters and identifying those that result in a simulation which matches the observed real motions. The problem is solved in a Bayesian optimization framework. The same framework is used for both identifying the model of an object online and searching for a policy that would minimize a given cost function according to the identified model. Experimental results both in simulation and using a real robot indicate that the proposed method outperforms state-of-the-art model-free reinforcement learning approaches.", "creator": "LaTeX with hyperref package"}}}