{"id": "1703.08013", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Mar-2017", "title": "Content-based similar document image retrieval using fusion of CNN features", "abstract": "Text content can have different visual presentation ways with roughly similar characters. While conventional text image retrieval depends on complex model of OCR-based text recognition and text similarity detection, this paper proposes a new learning-based approach to text image retrieval with the purpose of finding out the original or similar text through a query text image. Firstly, features of text images are extracted by the CNN network to obtain the deep visual representations. Then, the dimension of CNN features is reduced by PCA method to improve the efficiency of similarity detection. Based on that, an improved similarity metrics with article theme relevance filtering is proposed to improve the retrieval accuracy. In experimental procedure, we collect a group of academic papers both including English and Chinese as the text database, and cut them into pieces of text image. A text image with changed text content is used as the query image, experimental results show that the proposed approach has good ability to retrieve the original text content.", "histories": [["v1", "Thu, 23 Mar 2017 11:35:27 GMT  (707kb)", "https://arxiv.org/abs/1703.08013v1", null], ["v2", "Fri, 24 Mar 2017 09:30:41 GMT  (0kb,I)", "http://arxiv.org/abs/1703.08013v2", "There are some details to be corrected in this article, and they are not suitable for open now"], ["v3", "Fri, 1 Sep 2017 00:34:52 GMT  (636kb)", "http://arxiv.org/abs/1703.08013v3", null]], "reviews": [], "SUBJECTS": "cs.CV cs.IR cs.LG", "authors": ["mao tan", "si-ping yuan", "yong-xin su"], "accepted": false, "id": "1703.08013"}, "pdf": {"name": "1703.08013.pdf", "metadata": {"source": "CRF", "title": "Content-based similar document image retrieval using fusion of CNN features", "authors": ["Mao Tan", "Siping Yuan", "Yongxin Su"], "emails": ["mr.tanmao@gmail.com", "201610171906@smail.xtu.edu.cn", "su_yong_xin@163.com"], "sections": [{"heading": null, "text": "While traditional approaches to image acquisition rely on complex OCR-based text recognition and text similarity recognition, this paper proposes a new content-based approach that pays more attention to feature extraction and fusion. In the proposed approach, multiple features of document images are extracted by different CNN models, then the extracted CNN features are reduced and merged into a weighted average feature. Finally, document images are classified into a supplied query image based on feature similarity, and the experimental procedure is performed on a group of document images that have been transformed from scientific papers containing both English and Chinese documents. Results show that the proposed approach has good capabilities to retrieve document images with similar text content, and the merging of CNN features can effectively improve retrieval accuracy. CCS CONCEPTS \u2022 Computing Multifunctional Methodologies \u2192 Artificial Network; Computer eveveval intelligence; Computer rexibility tasks; Visual vision;"}, {"heading": "1 INTRODUCTION", "text": "Due to the evolution of digital media technology, the scope of multimedia resources, including document illustrations, is getting bigger and bigger. The task, which is to find useful information or similar document illustrations from a large dataset for a particular user request, is to develop a variety of approaches based on the recognition of optical character (OCR), has some weaknesses that recognize text content from images and then apply the image resolution to implement document illustrations. Conventional image editing depends on complex models of the OCR-based approach, which has some weaknesses, such as high computer-related costs, language dependence and it is an explicit image resolution. Direct recommendation and retrieval based on arbitrary multi-character text in an unrestricted image require a recognizable representation."}, {"heading": "2 METHODOLOGY", "text": "In this section, we mainly discuss some key steps in retrieving the image similarity of a document based on multiple CNN models in order to improve the fusion characteristics of images. First, we match the pre-trained CNN models with MatConvNet and repeatedly specify the cutout size of the experimental document image. Then, we use several different, fine-tuned CNN models to extract various CNN characteristics from the experimental document image dataset that can convert the visual content into a deep representation. Since the CNN feature matrix trained by the CNN model is high-dimensional, we continue the PCA method to reduce the dimensions and make each CNN feature matrix identical in order to enable subsequent model fusion. Then, we merge the multiple CNN feature matrix with appropriate combination coefficients calculated from the rank _ age of its CNN network to obtain a weighted query function based on the fusion cosinput."}, {"heading": "2.1 CNN Feature Extraction", "text": "It is necessary to extract the primitive features of the document image as a constructive parameter of the training model. The quality of the feature extraction directly determines the retrieval effect. Recently, CNNs have achieved impressive results in some areas, such as image detection and object detection. You can enter images directly into the network by avoiding the complex feature extraction and data reconstruction process in the traditional network detection algorithm. As described above, we select some state-of-the-art CNN models submitted in the last 5 years for the ImageNet challenge, such as the training network. Among them, AlexNet, the first entry to use a deep neural network in 2012, has a strong generating capability in computer vision tasks. VGGNet is a preferred multi-layer neural network model for the extraction of CNN functions of the image. The VGNet uses small-format convolution network layering and we will train the network layering during the training of the high-level network layering, also by exercising the high level of the network layering, while many others can train the high level of the network image."}, {"heading": "2.2 Dimension Reduction by PCA", "text": "After CNN feature extraction with different CNN models, we get a high-dimensional image depth representation. We use the PCA method to compress the influence of the CNN feature matrix on 256-D and to simplify the calculation of the covariance matrix, we use the PCA method to find the 256 largest variation feature vectors in this matrix. Therefore, the covariance matrix C can be calculated according to each feature vector xi in the normalized CNN feature matrix, which can be expressed with 11 =, nn Ti ii C x x (1), where C represents the covariance matrix of the feature matrix, and n represents the number of feature vectors. Afterwards, the property value equation based on C can be expressed as i iC (2)."}, {"heading": "2.3 Fusion of CNN Features", "text": "Using the above method, we obtain various finely twisted CNN models to extract image characteristics. It has been confirmed that creating ensembles from multiple individual files can reduce generalization errors. Therefore, we merge the characteristics from several different existing models and propose the fusion method of multiple models based on Rank _ age. The characteristics trained by different CNN models could represent different characteristics of the document image, and the effective use of different characteristics by the fusion method of multiple models will have a positive impact on restoring image similarity of the document. We improve the fusion method of the model, which is based on Rank _ age in [15], by combining the characteristics from multiple models with corresponding combination coefficients calculated from the rank _ age of its model network. A small-size document set is created in advance to calculate the Rank _ age of each model, which includes 422 pairs of similar document images and the index of each image pair."}, {"heading": "2.4 Similarity Metric", "text": "The cosinal similarity [z1, z2,..., zn] T could describe the most important CNN characteristics of the document images in the dataset, where n is the number of document images in the datasets. Cosinal similarity calculated from the CNN character vector can roughly measure the similarity between the document images, for each pair of character vectors (To, Zv) in which the pair cosinal similarity Ts can be expressed as 12 21 1, *, *, ku i v iis u v k ku i v ii iF Z vT Z ZF Z u F Z v (5), where K = 256 and F (To, ui) is the value of the i-th column element of the 256-D dimension characteristic corresponding to the document image To. Ts (To, ZF Z u F Z v (5), where K = 256 and F (To, ui) is the value of the document that is in some way similar."}, {"heading": "3 EXPERIMENTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Data Collection and Evaluation Metric", "text": "In this thesis, to evaluate the proposed method, we collect a group of English and Chinese scientific papers as a text database and cut them into many small portions of a heterogeneous document image to create a training dataset containing a total of 2017 images. We then select some paragraphs of text from the original article and edit them in different ways. We then save the edited text paragraphs as images to create a query dataset with a total of 422 images, which is used to evaluate the accuracy of the proposed approach in different situations. In addition, we select the 422 query images and their original images to construct a small-format document image record, and create a < query image name, original image name > index to calculate the rank _ age of each CNN network in advance. We conducted various experiments with various CNN models. 422 query document images are selected to evaluate the similar document images in image sets based on the top 10 of the image values suggested by the method of the image below."}, {"heading": "3.2 Experimental Results and Analyses", "text": "The training and query data set includes English and Chinese document images, and there are 10 types of net net result net result net result, including retranslation by Google, changing font color, adding another statement in the content, omitting much content, adjusting the line spacing of the text and inverting the word order, and so on. Therefore, each time we retrieve different images separately to see the retrieval effect of different text language and content or local deformation of the layout. First, we select an English document image as a query image that is converted from the summary of an English article, the query document image is shown as Figure 2 (a). Then we calculate the similarity of the query document image with each document in the training dataset by using MMF (VGNet-D + VGNet-E + GoogLeNet), the original document image that is shown in Figure 2 (b)."}, {"heading": "4 CONCLUSIONS", "text": "All the experimental results indicate that the proposed approach is effective in achieving a document image recognition-free query for different linguistic characters without using OCR. Using Rank _ age to merge the features of multiple classic CNN models can significantly improve retrieval accuracy under most conditions with different transformations of text content or layout. In our next work, more methods will be chosen and tested to merge multiple CNN models to achieve greater retrieval accuracy. If this approach is further improved to adapt more complex transformations, it is expected to be applied to paper plagiarism identification or literature recommendations."}], "references": [{"title": "Segmentation-free word spotting in historical printed documents", "author": ["B Gatos", "I. Pratikakis"], "venue": "Document Analysis and Recognition,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2009}, {"title": "A novel word spotting method based on recurrent neural networks", "author": ["V Frinken", "A Fischer", "R Manmatha"], "venue": "IEEE transactions on pattern analysis and machine intelligence,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "Unified photo enhancement by discovering aesthetic communities from flickr", "author": ["R Hong", "L Zhang", "D. Tao"], "venue": "IEEE transactions on Image Processing", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2016}, {"title": "Texture synthesis and the controlled generation of natural stimuli using convolutional neural networks. arXiv:1505.07376, http://arxiv.org/abs/1505.07376", "author": ["L.A. Gatys", "A.S. Ecker", "M. Bethge"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2015}, {"title": "You Only Look Once: Unified, Real- Time Object Detection", "author": ["J Redmon", "S Divvala", "R Girshick"], "venue": "Computer Science,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2016}, {"title": "Going deeper with convolutions", "author": ["C Szegedy", "W Liu", "Y Jia"], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "Multi-digit Number Recognition from Street View Imagery using Deep Convolutional Neural Networks", "author": ["J Goodfellow I", "Y Bulatov", "J Ibarz"], "venue": "Computer Science", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2013}, {"title": "MatConvNet: Convolutional Neural Networks for MATLAB", "author": ["A Vedaldi", "K. Lenc"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "Learning visual semantic relationships for efficient visual retrieval", "author": ["R Hong", "Y Yang", "M Wang", "XS. Hua"], "venue": "IEEE Transactions on Big Data", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2015}, {"title": "Return of the Devil in the Details: Delving Deep into Convolutional Nets", "author": ["K Chatfield", "K Simonyan", "A Vedaldi"], "venue": "Computer Science", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2014}, {"title": "Combining predictions for accurate recommender systems", "author": ["M Jahrer", "A T\u00f6scher", "R. Legenstein"], "venue": "Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2010}, {"title": "Using rank aggregation for expert search in academic digital libraries", "author": ["C Moreira", "B Martins", "P. Calado"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2015}, {"title": "Image recommendation based on keyword relevance using absorbing Markov chain and image features", "author": ["D Sejal", "V Rashmi", "R. Venugopal K"], "venue": "International Journal of Multimedia Information Retrieval,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2016}], "referenceMentions": [{"referenceID": 0, "context": "In some cases, converting colourful images to grayscale images, adjustment of images' sizes, border removal and normalization of the text line width in the initial steps can enhance document images [1-3].", "startOffset": 198, "endOffset": 203}, {"referenceID": 1, "context": "In some cases, converting colourful images to grayscale images, adjustment of images' sizes, border removal and normalization of the text line width in the initial steps can enhance document images [1-3].", "startOffset": 198, "endOffset": 203}, {"referenceID": 2, "context": "In some cases, converting colourful images to grayscale images, adjustment of images' sizes, border removal and normalization of the text line width in the initial steps can enhance document images [1-3].", "startOffset": 198, "endOffset": 203}, {"referenceID": 3, "context": "When CNNs are trained in images database, a deep representation of the image is constructed to make object information increasingly explicit along the processing hierarchy [4].", "startOffset": 172, "endOffset": 175}, {"referenceID": 4, "context": "[5] proposed an improved model that inspired by the GoogLeNet model[6] for image classification.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[5] proposed an improved model that inspired by the GoogLeNet model[6] for image classification.", "startOffset": 67, "endOffset": 70}, {"referenceID": 6, "context": "[9] proposed a unified approach that integrates the localization, segmentation, and recognition steps via the use of a deep convolutional neural network that operates directly on the image pixels.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[10] studied the efficacy of the conceptual relationships by applying them to augment imperfect image tags, and then the relevant results are subsequently used in contentbased image retrieval for improving efficiency.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "Fortunately, there are some open pretrained models that we can easily use, such as MatConvNet [11].", "startOffset": 94, "endOffset": 98}, {"referenceID": 9, "context": "Besides that, training the CNN features on a large dataset and fine-tuning by target dataset can significantly improve the performance [12].", "startOffset": 135, "endOffset": 139}, {"referenceID": 10, "context": "In this case, the combination coefficients have to be determined by some optimization procedure [14].", "startOffset": 96, "endOffset": 100}, {"referenceID": 11, "context": "[16] specifically tested two un-supervised rank aggregation", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "An efficient and widespread method is computing pair-wise image cosine similarity based on visual features of all images, and then used this parameter value to retrieve the high similarity images [17].", "startOffset": 196, "endOffset": 200}], "year": 2017, "abstractText": "Rapid increase of digitized document give birth to high demand of document image retrieval. While conventional document image retrieval approaches depend on complex OCR-based text recognition and text similarity detection, this paper proposes a new content-based approach, in which more attention is paid to features extraction and fusion. In the proposed approach, multiple features of document images are extracted by different CNN models. After that, the extracted CNN features are reduced and fused into weighted average feature. Finally, the document images are ranked based on feature similarity to a provided query image. Experimental procedure is performed on a group of document images that transformed from academic papers, which contain both English and Chinese document, the results show that the proposed approach has good ability to retrieve document images with similar text content, and the fusion of CNN features can effectively improve the retrieval accuracy.", "creator": "Microsoft\u00ae Word 2010"}}}