{"id": "1703.08245", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Mar-2017", "title": "On the Robustness of Convolutional Neural Networks to Internal Architecture and Weight Perturbations", "abstract": "Deep convolutional neural networks are generally regarded as robust function approximators. So far, this intuition is based on perturbations to external stimuli such as the images to be classified. Here we explore the robustness of convolutional neural networks to perturbations to the internal weights and architecture of the network itself. We show that convolutional networks are surprisingly robust to a number of internal perturbations in the higher convolutional layers but the bottom convolutional layers are much more fragile. For instance, Alexnet shows less than a 30% decrease in classification performance when randomly removing over 70% of weight connections in the top convolutional or dense layers but performance is almost at chance with the same perturbation in the first convolutional layer. Finally, we suggest further investigations which could continue to inform the robustness of convolutional networks to internal perturbations.", "histories": [["v1", "Thu, 23 Mar 2017 22:25:05 GMT  (257kb,D)", "http://arxiv.org/abs/1703.08245v1", "under review at ICML 2017"]], "COMMENTS": "under review at ICML 2017", "reviews": [], "SUBJECTS": "cs.LG cs.CV", "authors": ["nicholas cheney", "martin schrimpf", "gabriel kreiman"], "accepted": false, "id": "1703.08245"}, "pdf": {"name": "1703.08245.pdf", "metadata": {"source": "META", "title": "On the Robustness of Convolutional Neural Networksto Internal Architecture and Weight Perturbations", "authors": ["Nicholas Cheney", "Martin Schrimpf", "Gabriel Kreiman"], "emails": ["<gabriel.kreiman@childrens.harvard.edu>."], "sections": [{"heading": "1. Introduction", "text": "In fact, it is so that most of them are able to survive themselves, and that they are able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...)"}, {"heading": "2. Background", "text": "Regulators such as weight loss (Moody et al., 1991) or dropouts (Srivastava et al., 2014a) can be used during training to simulate weight changes with slowly decreasing parameter values or randomly dropped units. During the test period, analyses such as contrast imaging disorders (Goodfellow et al., 2014; Nguyen et al., 2015) and randomised labels (Zhang et al., 2016) have shed light on the robustness of neural networks in terms of data changes. Learning curves of neural network performance during training are extensively studied (including Convolutionary neural Networks; e.g. (Hinton et al., 2012)), as performance increases asymptotically due to intended and directed internal parameter changes from learning."}, {"heading": "3. Methodology", "text": "We mainly study topology and weight disorders of the deep convolutionary neural network \"Alexnet\" (Krizhevsky et al., 2012), but later we also generalize the results of the VGG-16 (Simonyan & Zisserman, 2014), which is publicly available in the Caffe Zoo (Jia et al., 2014).All models are implemented with Keras (Chollet, 2015), with a theano backend (Team et al., 2016)."}, {"heading": "4. Robustness to Topology Changes", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1. Synapse Knockouts", "text": "The simplest topological change to a conventional network is the removal of a synapse. This method sets the weight of a portion of the synapses in a given layer to zero and removes information evenly and randomly from all nodes in that layer. Fig. 1 shows the decline in classification performance due to the increasing number of synapses in different layers of the conventional mesh."}, {"heading": "4.2. Node Knockouts", "text": "This year, it is so far that it is only a matter of time before it is ready, until it is ready."}, {"heading": "5. Robustness to Weight Changes from Random Perturbations", "text": "Rather than removing synapses completely and setting their weight to zero, both biological sound sources and computational applications can lead to scenarios where interference from a network changes weights by a certain amount. These weight-changing situations are likely to be a problem in the case of unattended (or semi-supervised) learning rules, where weights change in an undesirable (or simply random) direction, or in the case of damage or interference in embedded circuits. Such sources of noise or weight fluctuations can only cause short-term damage to network performance - but in critical applications, the characterization of short-term effects can be significant. In this treatment, all synapses that lead to a particular layer are modified, and the size of these interference for each individual synapse is randomly pulled from a particular layer."}, {"heading": "6. Generalization to Other Metrics and Architectures", "text": "While the top 5 classification performance of the Alexnet architecture in the ILSVRC2012 validation set was the focus of our initial studies, these results can be generalized to various implementation decisions.Preliminary studies for other thresholds of classification rigor show qualitatively consistent results with the top 5 results used in this paper - with absolute performance indicators varying, but relational trends and qualitative outcomes remaining consistent. For comparison, the top 1 performance of the Alexnet classification in ILSVRC2012 in Fig. 4 shows a very similar trend to Fig. 3. Preliminary results indicate that the performance decline is qualitatively similar in other network architectures. Fig. 5 shows a comparable effect of weight disorders on the VGG-16 Convolutionary Neural Network (Simonyan & Zisserman, 2014), which exhibits increased network share (16 layers compared to Alexnets)."}, {"heading": "7. Discussion", "text": "The results of this study are based on a number of factors that have become the focus of public attention in recent years: for example, the fact that the number of people in the USA, in the USA, in the USA, in the USA, in the USA, in Europe, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the"}, {"heading": "8. Conclusion", "text": "We investigated the robustness of a pre-trained Convolutionary Neural Network against internal weight and architecture disorders. We demonstrated the effects of internal disorders that removed nodes, removed synapses, and modified synaptic weights on classification performance. We demonstrated that Convolutionary Networks exhibited a significant degree of robustness against such changes. Disturbances to lower Convolutionary Layers were significantly more effective than disturbances to higher layers. These results help us understand how information is encoded within the nodes and layers of deep Convolutionary Neural Networks."}], "references": [{"title": "Unsupervised feature learning and deep learning: A review and new perspectives", "author": ["Bengio", "Yoshua", "Courville", "Aaron C", "Vincent", "Pascal"], "venue": "CoRR, abs/1206.5538,", "citeRegEx": "Bengio et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 2012}, {"title": "Large scale online learning", "author": ["Bottou", "L\u00e9on", "LeCun", "Yann"], "venue": "In NIPS,", "citeRegEx": "Bottou et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Bottou et al\\.", "year": 2003}, {"title": "The brain has a body: adaptive behavior emerges from interactions of nervous system, body and environment", "author": ["Chiel", "Hillel J", "Beer", "Randall D"], "venue": "Trends in neurosciences,", "citeRegEx": "Chiel et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Chiel et al\\.", "year": 1997}, {"title": "URL https:// github.com/fchollet/keras", "author": ["Chollet", "Fran\u00e7ois"], "venue": "Keras,", "citeRegEx": "Chollet and Fran\u00e7ois.,? \\Q2015\\E", "shortCiteRegEx": "Chollet and Fran\u00e7ois.", "year": 2015}, {"title": "Naturally occurring neuron death and its regulation by developing neural pathways", "author": ["Cunningham", "Timothy J"], "venue": "International review of cytology,", "citeRegEx": "Cunningham and J.,? \\Q1982\\E", "shortCiteRegEx": "Cunningham and J.", "year": 1982}, {"title": "Imagenet: A large-scale hierarchical image database", "author": ["Deng", "Jia", "Dong", "Wei", "Socher", "Richard", "Li", "Li-Jia", "Kai", "Fei-Fei"], "venue": "In Computer Vision and Pattern Recognition,", "citeRegEx": "Deng et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Deng et al\\.", "year": 2009}, {"title": "Neurogenesis in the adult human hippocampus", "author": ["Eriksson", "Peter S", "Perfilieva", "Ekaterina", "Bj\u00f6rk-Eriksson", "Thomas", "Alborn", "Ann-Marie", "Nordborg", "Claes", "Peterson", "Daniel A", "Gage", "Fred H"], "venue": "Nature medicine,", "citeRegEx": "Eriksson et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Eriksson et al\\.", "year": 1998}, {"title": "Explaining and harnessing adversarial examples", "author": ["Goodfellow", "Ian J", "Shlens", "Jonathon", "Szegedy", "Christian"], "venue": "arXiv preprint arXiv:1412.6572,", "citeRegEx": "Goodfellow et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2014}, {"title": "The organization of behavior: A neuropsychological theory", "author": ["Hebb", "Donald Olding"], "venue": null, "citeRegEx": "Hebb and Olding.,? \\Q2005\\E", "shortCiteRegEx": "Hebb and Olding.", "year": 2005}, {"title": "Improving neural networks by preventing co-adaptation of feature detectors", "author": ["Hinton", "Geoffrey E", "Srivastava", "Nitish", "Krizhevsky", "Alex", "Sutskever", "Ilya", "Salakhutdinov", "Ruslan R"], "venue": "arXiv preprint arXiv:1207.0580,", "citeRegEx": "Hinton et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2012}, {"title": "Multilayer feedforward networks are universal approximators", "author": ["Hornik", "Kurt", "Stinchcombe", "Maxwell", "White", "Halbert"], "venue": "Neural networks,", "citeRegEx": "Hornik et al\\.,? \\Q1989\\E", "shortCiteRegEx": "Hornik et al\\.", "year": 1989}, {"title": "An empirical evaluation of deep learning on highway driving", "author": ["Huval", "Brody", "Wang", "Tao", "Tandon", "Sameep", "Kiske", "Jeff", "Song", "Will", "Pazhayampallil", "Joel", "Andriluka", "Mykhaylo", "Rajpurkar", "Pranav", "Migimatsu", "Toki", "Cheng-Yue", "Royce"], "venue": "arXiv preprint arXiv:1504.01716,", "citeRegEx": "Huval et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Huval et al\\.", "year": 2015}, {"title": "Weight perturbation: An optimal architecture and learning technique for analog vlsi feedforward and recurrent multilayer networks", "author": ["Jabri", "Marwan", "Flower", "Barry"], "venue": "IEEE Transactions on Neural Networks,", "citeRegEx": "Jabri et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Jabri et al\\.", "year": 1992}, {"title": "Imagenet classification with deep convolutional neural networks. In Advances in neural information processing", "author": ["Krizhevsky", "Alex", "Sutskever", "Ilya", "Hinton", "Geoffrey E"], "venue": null, "citeRegEx": "Krizhevsky et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "Efficient backprop", "author": ["LeCun", "Yann A", "Bottou", "L\u00e9on", "Orr", "Genevieve B", "M\u00fcller", "Klaus-Robert"], "venue": "In Neural networks: Tricks of the trade,", "citeRegEx": "LeCun et al\\.,? \\Q2012\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 2012}, {"title": "End-to-end training of deep visuomotor policies", "author": ["Levine", "Sergey", "Finn", "Chelsea", "Darrell", "Trevor", "Abbeel", "Pieter"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Levine et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Levine et al\\.", "year": 2016}, {"title": "Robust stability for interval hopfield neural networks with time delay", "author": ["Liao", "Xiaofeng", "Yu", "Jeubang"], "venue": "IEEE Transactions on Neural Networks,", "citeRegEx": "Liao et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Liao et al\\.", "year": 1998}, {"title": "Analog VLSI implementation of neural systems, volume 80", "author": ["Mead", "Carver", "Ismail", "Mohammed"], "venue": "Springer Science & Business Media,", "citeRegEx": "Mead et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Mead et al\\.", "year": 2012}, {"title": "The effective number of parameters: An analysis of generalization and regularization in nonlinear learning systems", "author": ["Moody", "John E"], "venue": "In NIPS,", "citeRegEx": "Moody and E,? \\Q1991\\E", "shortCiteRegEx": "Moody and E", "year": 1991}, {"title": "Deep neural networks are easily fooled: High confidence predictions for unrecognizable images", "author": ["Nguyen", "Anh", "Yosinski", "Jason", "Clune", "Jeff"], "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "Nguyen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Nguyen et al\\.", "year": 2015}, {"title": "Learning monocular reactive uav control in cluttered natural environments", "author": ["Ross", "St\u00e9phane", "Melik-Barkhudarov", "Narek", "Shankar", "Kumar Shaurya", "Wendel", "Andreas", "Dey", "Debadeepta", "Bagnell", "J Andrew", "Hebert", "Martial"], "venue": "In Robotics and Automation (ICRA),", "citeRegEx": "Ross et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Ross et al\\.", "year": 2013}, {"title": "Deep boltzmann machines", "author": ["Salakhutdinov", "Ruslan", "Hinton", "Geoffrey E"], "venue": "In AISTATS,", "citeRegEx": "Salakhutdinov et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Salakhutdinov et al\\.", "year": 2009}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["Simonyan", "Karen", "Zisserman", "Andrew"], "venue": "arXiv preprint arXiv:1409.1556,", "citeRegEx": "Simonyan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Simonyan et al\\.", "year": 2014}, {"title": "Competitive hebbian learning through spike-timingdependent synaptic plasticity", "author": ["Song", "Sen", "Miller", "Kenneth D", "Abbott", "Larry F"], "venue": "Nature neuroscience,", "citeRegEx": "Song et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Song et al\\.", "year": 2000}, {"title": "Dropout: A Simple Way to Prevent Neural Networks from Overfitting", "author": ["Srivastava", "Nitish", "Hinton", "Geoffrey", "Krizhevsky", "Alex", "Sutskever", "Ilya", "Salakhutdinov", "Ruslan"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Srivastava et al\\.,? \\Q1958\\E", "shortCiteRegEx": "Srivastava et al\\.", "year": 1958}, {"title": "Dropout: a simple way to prevent neural networks from overfitting", "author": ["Srivastava", "Nitish", "Hinton", "Geoffrey E", "Krizhevsky", "Alex", "Sutskever", "Ilya", "Salakhutdinov", "Ruslan"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Srivastava et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Srivastava et al\\.", "year": 2014}, {"title": "Hierarchical organization and functional streams in the visual cortex", "author": ["Van Essen", "David C", "Maunsell", "John HR"], "venue": "Trends in neurosciences,", "citeRegEx": "Essen et al\\.,? \\Q1983\\E", "shortCiteRegEx": "Essen et al\\.", "year": 1983}, {"title": "30 years of adaptive neural networks: perceptron, madaline, and backpropagation", "author": ["Widrow", "Bernard", "Lehr", "Michael A"], "venue": "Proceedings of the IEEE,", "citeRegEx": "Widrow et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Widrow et al\\.", "year": 1990}, {"title": "Individual comparisons by ranking methods", "author": ["Wilcoxon", "Frank"], "venue": "Biometrics bulletin,", "citeRegEx": "Wilcoxon and Frank.,? \\Q1945\\E", "shortCiteRegEx": "Wilcoxon and Frank.", "year": 1945}, {"title": "Modular self-reconfigurable robot systems [grand challenges of robotics", "author": ["Yim", "Mark", "Shen", "Wei-Min", "Salemi", "Behnam", "Rus", "Daniela", "Moll", "Lipson", "Hod", "Klavins", "Eric", "Chirikjian", "Gregory S"], "venue": "IEEE Robotics & Automation Magazine,", "citeRegEx": "Yim et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Yim et al\\.", "year": 2007}, {"title": "Visualizing and understanding convolutional networks", "author": ["Zeiler", "Matthew D", "Fergus", "Rob"], "venue": "In European conference on computer vision,", "citeRegEx": "Zeiler et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zeiler et al\\.", "year": 2014}, {"title": "Understanding deep learning requires rethinking generalization", "author": ["Zhang", "Chiyuan", "Bengio", "Samy", "Hardt", "Moritz", "Recht", "Benjamin", "Vinyals", "Oriol"], "venue": "arXiv preprint arXiv:1611.03530,", "citeRegEx": "Zhang et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2016}, {"title": "Perturbation method for deleting redundant inputs of perceptron", "author": ["Zurada", "Jacek M", "Malinowski", "Aleksander", "Usui", "Shiro"], "venue": "networks. Neurocomputing,", "citeRegEx": "Zurada et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Zurada et al\\.", "year": 1997}], "referenceMentions": [{"referenceID": 0, "context": "Unsupervised (or semi-supervised) deep learning algorithms are also highly desirable (Salakhutdinov & Hinton, 2009; Lee et al., 2009; Bengio et al., 2012), as they allow neural networks to approach problems that do not have an abundance of labeled data and vastly scale their real world applicability.", "startOffset": 85, "endOffset": 154}, {"referenceID": 11, "context": "Especially in high-risk scenarios \u2013 such as driverless cars (Huval et al., 2015), UAVs (Ross et al.", "startOffset": 60, "endOffset": 80}, {"referenceID": 20, "context": ", 2015), UAVs (Ross et al., 2013), or autonomous robotics (Levine et al.", "startOffset": 14, "endOffset": 33}, {"referenceID": 15, "context": ", 2013), or autonomous robotics (Levine et al., 2016) \u2013 it is important to understand how internal changes to a deep network during its execution will impact its immediate performance.", "startOffset": 32, "endOffset": 53}, {"referenceID": 29, "context": "Embodied machines, especially those with plastic morphologies such as modular robotics (Yim et al., 2007), may benefit from neurogenesis (Chiel & Beer, 1997).", "startOffset": 87, "endOffset": 105}, {"referenceID": 6, "context": "Neurons die every day and, at least in some parts of the brain, new neurons are formed (Cunningham, 1982; Eriksson et al., 1998).", "startOffset": 87, "endOffset": 128}, {"referenceID": 23, "context": "Synapses are subject to learning mechanisms \u2013 such as spike-timing dependent plasticity (Song et al., 2000; Hebb, 2005) \u2013 that directly and dynamically modify the magnitude of connection strengths.", "startOffset": 88, "endOffset": 119}, {"referenceID": 7, "context": "During test time, analyses like adversarial perturbations of the images (Goodfellow et al., 2014; Nguyen et al., 2015) and randomized labels (Zhang et al.", "startOffset": 72, "endOffset": 118}, {"referenceID": 19, "context": "During test time, analyses like adversarial perturbations of the images (Goodfellow et al., 2014; Nguyen et al., 2015) and randomized labels (Zhang et al.", "startOffset": 72, "endOffset": 118}, {"referenceID": 31, "context": ", 2015) and randomized labels (Zhang et al., 2016) have shed light onto the robustness of neural networks to changes in the data.", "startOffset": 30, "endOffset": 50}, {"referenceID": 9, "context": "(Hinton et al., 2012)), as the performance increases asymptotically due to the intentional and directed internal parameter changes from learning.", "startOffset": 0, "endOffset": 21}, {"referenceID": 32, "context": "The robustness to perturbations to the internal architecture of neural networks have been studied in fully-connected neural networks (Widrow & Lehr, 1990), including: perceptron networks (Zurada et al., 1997), Hopfield networks (Liao & Yu, 1998), recurrent neural networks (Jabri & Flower, 1992).", "startOffset": 187, "endOffset": 208}, {"referenceID": 13, "context": "We mainly examine topology and weight perturbations to the deep convolutional neural network \u201cAlexnet\u201d (Krizhevsky et al., 2012), pretrained on the 2012 ImageNet Large Scale Visual Recognition Challenge (ILSVRC2012) (Deng et al.", "startOffset": 103, "endOffset": 128}, {"referenceID": 5, "context": ", 2012), pretrained on the 2012 ImageNet Large Scale Visual Recognition Challenge (ILSVRC2012) (Deng et al., 2009; Russakovsky et al., 2015) but later also generalize results to VGG-16 (Simonyan & Zisserman, 2014).", "startOffset": 95, "endOffset": 140}, {"referenceID": 10, "context": "One possible explanation for this may be that node knockout effectively reduces the size of a hidden layer, and that the function approximation abilities of a neural network can be constrained by its hidden layer size (Hornik et al., 1989).", "startOffset": 218, "endOffset": 239}], "year": 2017, "abstractText": "Deep convolutional neural networks are generally regarded as robust function approximators. So far, this intuition is based on perturbations to external stimuli such as the images to be classified. Here we explore the robustness of convolutional neural networks to perturbations to the internal weights and architecture of the network itself. We show that convolutional networks are surprisingly robust to a number of internal perturbations in the higher convolutional layers but the bottom convolutional layers are much more fragile. For instance, Alexnet shows less than a 30% decrease in classification performance when randomly removing over 70% of weight connections in the top convolutional or dense layers but performance is almost at chance with the same perturbation in the first convolutional layer. Finally, we suggest further investigations which could continue to inform the robustness of convolutional networks to internal perturbations.", "creator": "LaTeX with hyperref package"}}}