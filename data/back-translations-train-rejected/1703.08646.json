{"id": "1703.08646", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Mar-2017", "title": "Simplifying the Bible and Wikipedia Using Statistical Machine Translation", "abstract": "I started this work with the hope of generating a text synthesizer (like a musical synthesizer) that can imitate certain linguistic styles. Most of the report focuses on text simplification using statistical machine translation (SMT) techniques. I applied MOSES to a parallel corpus of the Bible (King James Version and Easy-to-Read Version) and that of Wikipedia articles (normal and simplified). I report the importance of the three main components of SMT---phrase translation, language model, and recording---by changing their weights and comparing the resulting quality of simplified text in terms of METEOR and BLEU. Toward the end of the report will be presented some examples of text \"synthesized\" into the King James style.", "histories": [["v1", "Sat, 25 Mar 2017 04:25:21 GMT  (502kb)", "http://arxiv.org/abs/1703.08646v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["yohan jo"], "accepted": false, "id": "1703.08646"}, "pdf": {"name": "1703.08646.pdf", "metadata": {"source": "CRF", "title": "Simplifying the Bible and Wikipedia Using Statistical Machine Translation (Toward a Text Synthesizer via Machine Translation)", "authors": ["Yohan Jo"], "emails": ["yohanj@cs.cmu.edu"], "sections": [{"heading": null, "text": "Yohan Jo Language Technologies Instituteyohanj @ cs.cmu.eduSummaryI started this work in the hope of creating a text synthesizer (like a music synthesizer) capable of mimicking certain linguistic styles.Most of the report focuses on text simplification using statistical machine translation techniques (SMT).I applied MOSES to a parallel corpus of the Bible (King James version and easy-to-read version) and Wikipedia articles (normal and simplified). I report on the importance of the three main components of SMT - phrase translation, language model and recording - by changing their weighting and comparing the resulting quality of simplified text with METEOR and BLEU. Towards the end of the report, some examples of text are presented in King James style."}, {"heading": "1. INTRODUCTION", "text": "In fact, most people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to"}, {"heading": "2. RELATED WORK", "text": "In fact, it is such that most of them will be able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move"}, {"heading": "3. METHOD", "text": "This section describes two machine translation models I use: phrases and syntax models. These models are trained with normal text (source language) and simple text (target language), and the two parallel corpora, i.e. the Bible and Wikipedia, are also described in this section."}, {"heading": "3.1. MT Models", "text": "The following figure shows an overview of the phrase-based model and the syntax-based model (i.e., the tree-to-tree matching model). And the Lord said to Cain: Where is your brother Abel? Later, the Lord said to Cain: Where is your brother Abel? Phrase Translation ReorderingLanguage ModelPhrase-based modelsThese models essentially consist of three components: phrase translation, language model, and reordering. Although Moses offers more options, such as word length punishment, only these three components are used in this work. Phrase translation is the translation between phrases, which involves converting an archaic word (e.g. \"thy\") into a modern word (e.g. \"your\") and word drops within a sentence. Syntactical rules are considered phrase translation in syntax-based models (e.g. the translation of phrases between phrases)."}, {"heading": "3.2. Data", "text": "Two sets of data are used to simplify texts: the Bible and Wikipedia. Basic statistics are given in the following table.Bible WikipediaNormal Text King James Version2 \u2211 \u2211 Authorized by King James I in 1604 \u2211 Most read translation in the U.S. (Goff et al., 2014) www.wikipedia.org \u2211 Free-access, free content Internet encyclopediaSimple Text Easy-to-Read Version3 \u2211 Originally published as the English version for the Deafsimple.wikipedia.org \u2211 Wikipedia encyclopedia with simpler sets & grammar2 https: / www.biblegateway.com / versions / King James Version-KJV-Bible / 3 https: / www.biblegateway.com / versions / Easy-to-Read-Version-ERV-Bible / (EVD) by BakerBooks and Revised by World BibleTranslation Center in 2004."}, {"heading": "3.2.1. Bible", "text": "To my knowledge, there is no published work that uses the Bible to simplify the English text. It uses the King James Version (KJV) as a normal text and the Easy-toRead Version (ERV) as a simple text. KJV has not only a more difficult vocabulary, but also unique stylistic signs. It uses many archaic words (e.g. \"you,\" \"you,\" \"you,\" \"you,\" \"have,\" \"dwelleth\") and a prose rhythm. ERV, on the other hand, has simpler and more direct sentences. Note that ERV has, on average, a greater number of words in verse than KJV. This is because ERV splits a sentence into shorter sentences, maintaining its original meaning, i.e. it is more wordy than the KJV. On the contrary, Simple Wikipedia has fewer words in verse on average, because it drops less important words and loses some of their original meaning."}, {"heading": "3.2.2. Wikipedia", "text": "The simplified English Wikipedia (SEW) uses simpler sentences and grammar, and some articles are written only in Basic English. However, the change is not significant. As the table shows, 31.5% of the original sentences in the SWE remain the same, and structural changes are not common either. Most changes in the SEW are word drops. This is very different from the case of the Bible, as the SEW does not strictly retain the original meaning. Simplified text has on average two fewer words. As most changes are local and related to word drops in Wikipedia, I suspected that phrase-based models would work better than syntax-based models, and reordering could be harmful."}, {"heading": "4. EXPERIMENTAL SETTINGS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1. Training MT Models", "text": "That's why it's come to this, \"he said.\" It's too early to say it's not there yet, \"he said.\" But it's too early to say it's not there yet, \"he said.\" It's too early to realize it's too late. \""}, {"heading": "4.2. Data Processing", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.2.1. Bible", "text": "For ERV, I searched http: / / bibleabc.net / bible / erv /. Most chapter and verse numbers are marked with specific HTML tags, but there are exceptions. For example, some verses are under the same label (e.g. \"11-14\"), and some chapter numbers are missing. In these cases, I tried my best to correct information, but there are some verses that I could not automatically restore. Finally, I managed to align 30,346 verses from the entire contents of the Bible. (I used verses instead of sentence alignment.) ERV requires some pre-processing. First, double quotation marks were removed because the KJV does not contain double quotes. Second, all content was removed in parentheses; ERV uses parentheses to add explanations."}, {"heading": "4.2.2. Wikipedia", "text": "I used a publicly accessible parallel corpus for Wikipedia (Kauchak, 2013) with 167,689 sentence pairs aligned. After cleansing by Moses' clean-corpus-n.perl script, a total of 165,609 sentences remained."}, {"heading": "4.3. Evaluation", "text": "I use two automatic evaluation methods: METEOR (Denkowski and Lavie, 2014) and BLEU (Papineni et al., 2002). METEOR takes into account four components: exact word match, stem match, synonym match and paraphrase. I excluded synonym match because the inclusion of synonyms contradicts the goal of simplification."}, {"heading": "5. RESULTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1. Example Output", "text": "In this section, I randomly select sentences from the test set results and display them."}, {"heading": "5.1.1. Bible", "text": "6 http: / / www.gutenberg.org / KJV (Normal) ERV (Simple) Phrase-based Syntax-based This is an evil among all things done under the sun, that there is an event for all: yes, even the hearts of the sons of men are full of evil, and madness is in their hearts while they live, and after that they go to the dead. Of all things that happen in this life, the worst is that all people end in the same way. But it is also very bad that people always think evil and foolish thoughts, and these thoughts lead to death. This is an evil among all things that are done in the sun, that there is an event for all people. Yes, even the heart of the sons of men is full of evil, and it is crazy in their hearts as long as they live, and after that they go to the dead. This is not true. Bad things among all things that are done under the sun, which are accelerated."}, {"heading": "5.1.2. Wikipedia", "text": "In fact, most people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move and to move."}, {"heading": "5.2. MT Components Importance", "text": "This experiment aims to examine the meaning of each component in the MT models. I varied the weight of each component and compared the quality of the results. Specifically, for the phrase model I compared the weights of the phrase translation, the language model and the reorder between {0.2, 1}, {0.5, 1} and {0.3, 1}, respectively, a total of 8 combinations. I then compared two weights for each component by averaging the other components. For example, for the weight of the phrase translation 0.2, the values of all combinations where the weight of the phrase translation is 0.2 were averaged. For the syntax-based model, the weights of the phrase translation and the language model are not weighted."}, {"heading": "5.2.2. Wikipedia", "text": "As in the case of the Bible, phrase translation and reordering have little impact on the quality of results. However, the language model does have a significant impact. Further analysis shows that higher weights of phrase translation and reordering for the phrase model result in constantly higher values for each combination of the other weights. Again, the hypothesis that reordering would be harmful is not supported, but this trend was not found in the syntax-based model, which could indicate that the syntax-based approach in Wikipedia is fundamentally flawed."}, {"heading": "5.3. Performance On Test Set", "text": "The weight combination that achieves the highest score on the test set was selected for the test on the test set."}, {"heading": "5.3.1. Bible", "text": "That is, this is the score when the MT model has done nothing and instead prints the original text as it is. For METEOR, the phrase-based model performs best, followed by the syntax-based model and then the original text. Next, I looked at the results more closely using METEOR X-rays, but the syntax-based model works worse than the original text. The hypothesis that the syntax-based model would work better than the phrase-based model is not supported. The result is that I take a closer look at the results with METEOR X-rays. The following graphs show the histogram of the sentences in terms of METEOR scores, precision and memory. System-1 is the phrase-based model and System-2 is the syntax-based model.The general trend is fairly simple."}, {"heading": "5.3.2. Wikipedia", "text": "Interestingly, the original text performs best, followed by the phrase model and then the syntax-based model. This is because the original text is too similar to the simplified text. Data statistics in Section 3.2 show that 30% of the entire sentence remains the same in the simplified version. This pattern is widespread across sentences of any length except for those with more than 50 words. The left histogram below shows that both models perform poorly on longer sentences because these sentences require extensive modifications. It is confirmed by the right graph showing the length of the simple text in the test set, except for sentences with more than 50 words. The left histogram below shows that both models perform poorly because these sentences require extensive modifications. It shows the length of the simple text in the test set relative to the length of the original text."}, {"heading": "5.4. Converting Plain Text to King James Style", "text": "(...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...).). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...)."}, {"heading": "6. CONCLUSION", "text": "Overall, unfortunately, the Bible has produced a lower quality of translations than Wikipedia, because simplification of the Bible requires a significant restructuring of phrases and syntax. On the other hand, Simple English Wikipedia is already very similar to the standard Wikipedia. This has also resulted in a lower quality of translations than idleness. There have been surprising results that contradict the original intuition. First, the sentences produced by the syntax-based model were less fluent (less grammatical) than those produced by the phrase-based model. Evaluation errors contribute significantly to this phenomenon. Also, the syntax-based model produced worse results than the phrase-based model for both corporations, which is contrary to my original expectation that the tax-based model for the Bible would perform better. Analysis of the MT components showed that the emphasis on the language model impairs the quality of the results. In my parameter decisions, the phrase translation component shows an improvement in simplification quality."}, {"heading": "7. REFERENCES", "text": "In the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the"}], "references": [], "referenceMentions": [], "year": 2017, "abstractText": "I started this work with the hope of generating a text synthesizer (like a musical synthesizer) that can imitate certain linguistic styles. Most of the report focuses on text simplification using statistical machine translation (SMT) techniques. I applied MOSES to a parallel corpus of the Bible (King James Version and Easy-to-Read Version) and that of Wikipedia articles (normal and simplified). I report the importance of the three main components of SMT\u2014phrase translation, language model, and recording\u2014by changing their weights and comparing the resulting quality of simplified text in terms of METEOR and BLEU. Toward the end of the report will be presented some examples of text \u201csynthesized\u201d into the King James style.", "creator": "easyPDF SDK 7 7.0"}}}