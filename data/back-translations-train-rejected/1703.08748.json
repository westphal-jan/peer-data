{"id": "1703.08748", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Mar-2017", "title": "LEPOR: An Augmented Machine Translation Evaluation Metric", "abstract": "Machine translation (MT) was developed as one of the hottest research topics in the natural language processing (NLP) literature. One important issue in MT is that how to evaluate the MT system reasonably and tell us whether the translation system makes an improvement or not. The traditional manual judgment methods are expensive, time-consuming, unrepeatable, and sometimes with low agreement. On the other hand, the popular automatic MT evaluation methods have some weaknesses. Firstly, they tend to perform well on the language pairs with English as the target language, but weak when English is used as source. Secondly, some methods rely on many additional linguistic features to achieve good performance, which makes the metric unable to replicate and apply to other language pairs easily. Thirdly, some popular metrics utilize incomprehensive factors, which result in low performance on some practical tasks. In this thesis, to address the existing problems, we design novel MT evaluation methods and investigate their performances on different languages. Firstly, we design augmented factors to yield highly accurate evaluation.Secondly, we design a tunable evaluation model where weighting of factors can be optimised according to the characteristics of languages. Thirdly, in the enhanced version of our methods, we design concise linguistic feature using POS to show that our methods can yield even higher performance when using some external linguistic resources. Finally, we introduce the practical performance of our metrics in the ACL-WMT workshop shared tasks, which show that the proposed methods are robust across different languages.", "histories": [["v1", "Sun, 26 Mar 2017 00:30:38 GMT  (1130kb)", "http://arxiv.org/abs/1703.08748v1", "132 pages, thesis"]], "COMMENTS": "132 pages, thesis", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["lifeng han"], "accepted": false, "id": "1703.08748"}, "pdf": {"name": "1703.08748.pdf", "metadata": {"source": "CRF", "title": "LEPOR: An Augmented Machine Translation Evaluation Metric", "authors": ["Lifeng Han", "Aaron Master", "LiFeng Han", "Lidia S. Chao", "Derek F. Wong"], "emails": ["hanlifengaaron@gmail.com"], "sections": [{"heading": null, "text": "LEPOR: An advanced evaluation method for machine translation"}, {"heading": "Lifeng Han, Aaron", "text": "Master of Science in Software Engineering2014"}, {"heading": "Faculty of Science and Technology", "text": "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _"}, {"heading": "TABLE OF CONTENTS", "text": "LISTOF-FIGURES-Evaluation..................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."}, {"heading": "LISTOF FIGURES", "text": "Figure 3-1: N-gram Word Alignment Algorithm....... Figure 3-3: NPD calculation example...... 63Figure 3-2: Constituent structure for an English sentence....... 65Figure 3-3: NPD calculation example....... 65Figure 3-4: N-gram word alignment example with multi-references....... 66Figure 4-1: N-gram block alignment example...... 69Figure 4-2: N-gram POS sequence alignment example....... 72Figure 7-1: Parsing of the French and English Sentences."}, {"heading": "LIST OF TABLES", "text": "Table 2-1: Fluency and Adequacy Criteria........... 74Table 5-2: Spearman Correlation Scores of LEPOR and Other......... 76Table 5-3: Tuned Parameters of hLEPOR Metric......... 74Table 5-2: Spearman Correlation Scores of hLEPOR and Other......... 76Table 5-3: Tuned Parameters of hLEPOR Metric......... 77Table 5-4: Spearman Correlation Scores of hLEPOR and Other........ 78Table 6-1: Participated MT Systems in WMT 2013."}, {"heading": "LIST OF ABBREVIATIONS", "text": "ACL Association for Computational LinguisticsHMM Hidden Markov ModelsITG Inverse Transducer GrammarLM Language ModelML Machine LearningMT Machine TranslationMTE Machine Translation EvaluationNP Noun PhraseNLP Natural Language ProcessingPOS Part-of-SpeechPP Preposition PhraseSIG Special Interest GroupSMT Statistical Machine TranslationVP Verb PhraseWMT International Workshop of SMTix"}, {"heading": "ACKNOWLEDGEMENTS", "text": "I would like to thank my doctoral students, Dr. Derek F. Wong and Dr. Lidia S. Chao, who have given me a lot of valuable advice and suggestions during my research periods, who have always encouraged and supported me to go on. This work would not have been possible without their guidance. I also thank my colleagues in our NLP 2 CT laboratory, who succeeded Mr. Liang Tian & Mr. Xiaodong Zeng, from whom I learned a lot during the three years of research in the laboratory, Mr. Liangye Er (Yervant), Mr. YiLu, and Mr. Junwen Xing Xing, who gave me a lot of technical and programming help in our laboratory."}, {"heading": "DEDICATION", "text": "I would like to dedicate this thesis to my parents and sister. 1CHAPTER 1: INTRODUCTIONMachine translation (MT) began as early as the 1950s (Weaver, 1955), and gained rapid development since the 1990s due to the development of computer technology, such as expanded storage capacity and computing power, and the advanced bilingual translation method (Mari\u00f1o et al., 2006). We will first introduce several MTevents that promote MT technology, and then it is the importance of the MT evaluation (MTE evaluation), followed by a brief introduction to the theories of each chapter. 1.1 MT eventsThere are several events that promote the development of MT and MT evaluation research.One of these is the Open Machine Translation (OpenMT) evaluation series by the National Institute of Standards and Technology (NIST), which are highly regarded evaluation campaigns, including the company Arabic-English-English-English-English-Language-English-English-Language-Research (NIST) evaluation series."}, {"heading": "POS information", "text": "In grammar, part of the speech, also called lexical category, is a linguistic category of words or lexical terms generally defined by the syntactic or morphological behavior of the lexical term. Common linguistic categories of lexical terms include noun, verb, adjective, adverb and preposition, etc. In order to reflect the syntactic quality of automatically translated sentences, some researchers use the POS information in their evaluation. This evaluation metric MP4IBM1 relies on the large parallel bilingual instance by calculating the similarity values of source and target (translated) without using the reference translation based on morphems, 4-gram POS and lexicon probabilities. (This evaluation metric MP4IBM1 relies on the large bilingual corpus to extract the lexicon probability, other terms related to the English, other specific year, and the POS-related results in 2011, and very English."}, {"heading": "Phrase information", "text": "The fact is that we are going to be able to assert ourselves, that we are going to be able, that we are going to be able, that we are going to be able, that we are going to be able, that we are going to be able, that we are going to be able, that we are going to be able, that we are going to be able, that we are going to be able, that we are going to be able, that we are going to be able, that we are going to be able, that we are going to be able, that we are going to be able, that we are going to be able, that we are going to be able, that we are going to be able, that we are going to be able, that we are going to be able, that we are going to be able, that we are going to be able, that we are going to be able, that we are going to be able."}, {"heading": "Sentence structure information", "text": "To account for the general quality of the structure of the translated sentence, Liu and Gildea (2005) use constituent labels and head-modifier dependencies on the language parser as syntactical features for the MT evaluation. They calculate the similarity of the dependency trees between the candidate translation and the reference translations using their designed methods HWCM (Headword Chain Based Metric), STM (Subtree Metric), DSTM (Dependency Sub-tree Metric), TKM (kernel-based sub-tree Metric) and DTKM (Dependency Tree Kernel Metric). Overall experiments prove that adding syntactical information can improve evaluation performance, especially for predicting the frequency of hypotheses translations. Featuring that valid syntactic variations in the translationet, that translationis the unfairly penalize, Owczarak zal et al al (2007)."}, {"heading": "Named entity information", "text": "To capture the semantic equivalence of sentences or text fragments, the designated entity knowledge is taken from the literature of so-called entity recognition, also known as entity extraction or entity identification, which aims to identify and classify atomic elements in the text into different entity categories (Marsh and Perzanowski, 1998; Guo et al., 2009). Commonly used entity categories include the names of persons, places, organizations, and times, etc. In MEDAR, an international collaboration between the EU and the Mediterranean region in the field of language and language technologies for Arabic, evaluation campaign 2011, two SMT systems based on Moses (Koehn et al., 2007) are used as baseline lines for English-Arabic and Arabic-English directions. Baseline-1 system fits SRILM (Stockle, 2002), GIZA + Och + (Baseline, 2003 + Ophey and Arabic-1) and an Arabic-English translation system."}, {"heading": "Synonym information", "text": "Synonyms are used to specify the words that have the same or near meaning. One of the widely used synonym databases in NLP literature is WordNet (Miller et al., 1990; Fellbaum, 1998), an English lexical database that groups English words into synonyms. WordNet mainly organizes the words into four types of language components (POS), including nouns, verb, adjective and adverb without prepositions, determinants, etc. Synonyms or phrases are organized using the synthesis unit. Each synthesis is a hierarchical structure, with the words applied at different levels according to their semantic relationships. Thus, the words at the upper level belong to the words (hypernym) at a lower level. The use of the WordNet and the semantic distance designed by (Wu and Palmer, 1994) to identify synonyms as nonyme, syme, and Kit (2012)."}, {"heading": "Semantic roles", "text": "Semantic roles are used by some researchers as linguistic characteristics in MT evaluation. In order to use the semantic roles, sentences are usually analyzed shallow and marked with entities, and then the semantic roles are used to specify the arguments and additions that occur in both candidate translation and reference translation. Semantic roles introduced by Gim\u00e9nez and M\u00e1rquez (2007, 2008) include causal agent, adverbial addition, directional addition, negation marker and prediction addition, etc. In further development, Lo and Wu (2011a and 2011b) design the metric MEANT to capture predicate-argument relationships as structural relationships in semantic frames, which is not reflected in the flat semantic role characteristics in the work of (Gim\u00e9nez and M\u00e1rquez, 2007)."}, {"heading": "Textual entailment", "text": "When the truth of a text fragment TA follows another text fragment TB, then there is a directional relationship between TA and TB (TB = > TA). Instead of the purely logical or 29 mathematical relationship, the textual relationship in natural language processing (NLP) is usually done with a loose or loose definition (Dagan et al., 2005; 2006). For example, if the TB text fragment can be inferred that the text fragment TA is most likely true, then the relationship TB = > TA is also established. That the relationship is directive also means that the inverse inference (TA = > TB) is not certain (Dagan and Glickman, 2004). To address the task of dealing with unknown terms in SMT, Mirkin et al. (2009) propose a source language context model (LLLZ)."}, {"heading": "Paraphrase features", "text": "It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. It is. (...) It is. (...) It is. It is. (...) It is. (...) It is not that people are able to identify themselves. (...) It is not that people are able to identify themselves. (...) It is not that people are able to identify themselves. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. \"It is. (...) It is.\" It is. (...) It is. (...) It is. \"It is.\" It is. (...) It is. It is. (...) It is. It is. (...) It is. It is. It is. (...) It is. It is. (...) It is. It is. (... It is. It is. It is. (...) It is. It is. It is. (...) It is. It is. It is. (... It is. It is. It is. (...) It is. It is. (... It is. It is. It is. It is. (... It is. It is. It is. It is. It is. (...) It is. It is. It is. It is. (...) It is. It is. It is. It is. It is. It is. () It is. It is. It is. It is. It is. () It is. () It is. It is. It is. It is. () It is. It is. It is. () It is. It is. It is. () It is. It is. It is. It is. It is. () It is. It is. It is. It is. It is."}, {"heading": "On the other hand, no simple meaning can be attributed to Spearman\u2019s rank", "text": "This year, it has reached the point where it will be able to retaliate until it is able to retaliate."}, {"heading": "ADJ ADP ADV CONJ DET NOUN NUM PRON PRT VERB X .", "text": "For the set results, which we have undertaken, we have focused on the 12 universal buzzwords, which were developed in the individual countries (Petrov et al., 2012). In addition, we have developed an innovative evaluation method, by which we determine the length of the trousers, the length of the trousers, the length of the trousers, the length of the trousers, the length of the trousers, the length of the trousers, the length of the trousers, the length of the trousers, the length of the trousers, the length of the trousers, the length of the trousers, the length of the trousers, the height of the trousers, the length of the trousers, the height of the trousers, the height of the trousers, the height of the trousers, the height of the trousers, the height of the trousers, the height of the trousers, the height of the trousers and the height of the trousers, the height of the trousers and the height of the height, the height of the height of the height, the height of the height, the height of the height, the height of the height, the height of the height, the height of the"}, {"heading": "NP, CLP, QP, LCP,", "text": "WHNP np NPNPper, NPloc, NPtmp, NP, NP.focVP VP VPVP, VCD, VCP, VNV, VPT, VRD, VSBvp VN, VP, VPpart, VPinfVP.foc, VP, VPcnd, VPfinAJP ADJP, WHADJP ADJP, DP, DNP ap, adjp AP AP.foc, AP, APcndAVP ADVP, WHAVP, WHAVP, PRT, WHADVP ADVP, DVP advp AdPADVP.foc, ADVPPP PP PP PP PP, WHPP PP pp PPPPP, PP.foc, PPnom, PPPgen, PPaccS, SBAR, SBARQ, SINV, SQS, SBAR, SBARQ, SINV, SPRQ, FRC RC"}, {"heading": "IP, CP, PRN, FRAG,", "text": "INCfcl, icl, acl, cu, x, sqSENT, Ssub, Sint, Srel, S S, SSCONJP CONJPCOP UCP COORDX X, INTJ, LST"}, {"heading": "LST, FLR, DFL,", "text": "& & & & # 10 & & & & # 10; & & & & # 10; & & & & # 10; & & & # 10; & & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & & # 10; & & # 10; & & & # 10; & & & & # 10; & & & & & & # 10; & & & & # 10; & & & & & # 10; & & & & & & & # 10; & & & & & & & & # 10; & & & & & & & & & # 10; & & & & & & & # 10; & & & & & & & # 10; & & & & & & & # 10; & & & & & # 10; & & & & & & # 10; & & & & & # 10; & & & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & & & # 10; & # 10; & # 10; & & & # 10; & & # 10; & & # 10; & & & & # 10; & & & & & # 10; & & & # 10; & # 10; & & & # 10; & & & & & & & # 10; & # 10; & & & & & # 10; & & & & & # 10; & & & & & # 10; & & & # 10; & & & & & & # 10; & # 10; & & & & # 10; & & & & & & & & & # 10; & &"}, {"heading": "VITA", "text": "Aaron Li-Feng HanUniversity of Macau 2014"}, {"heading": "Award", "text": "2nd Prize in the National Post-Graduate Mathematical Contest in Modeling (NPGMCM2011) 2011. National Post-Graduate Mathematical Competition in the Modeling Committee. First and second prizes occupy 20.45% of the total of 2,245 teams from 242 universities and research institutes across the country, including over 300 PhD students. (Essay).http: / / www.shumo.com / home / html / 1317.htmlProfessional InformationOpen Source Tools: Homepage: https: / / github.com / aaronlifenghanGoogle scholar ciitation: http: / / scholar.google.com / citations? hl = en & user = _ vf3E2QAAAJ"}, {"heading": "Selected Publications:", "text": "1. Aaron Li Feng Han, Derek F. Wong, Lidia S. Chao, Liangye.org.org and Yi Lu.Unsupervised Quality Estimation Model for English to German Translation and Its Application in Extensive Supervised Evaluation. http: / / www.Scientific World Journal, Issue: Recent Advances in Information Technology. Page 1-12, April 2014.Hindawi Publishing Corporation. ISSN: 1537-744X. http: / / www.hindawi.com / journals / tswj / 760301 / 1122. Aaron Li-Feng Han, Derek F. Wong, Lidia S. Chao, Liangye He, Yi Lu Xingand Xiaodong Zeng. Language-independent Model for Machine Translation Evaluation with Reinforced Factors. Proceedings of the 14th International Conference of Machine Translation Summit (MT Summit), pp. 215-222. Nice, France."}], "references": [], "referenceMentions": [], "year": 2014, "abstractText": "LEPOR: AN AUGMENTED MACHINE TRANSLATION EVALUATION METRIC by LiFeng Han, Aaron Thesis Supervisors: Dr. Lidia S. Chao and Dr. Derek F. Wong Master of Science in Software Engineering Machine translation (MT) was developed as one of the hottest research topics in the natural language processing (NLP) literature. One important issue in MT is that how to evaluate the MT system reasonably and tell us whether the translation system makes an improvement or not. The traditional manual judgment methods are expensive, time-consuming, unrepeatable, and sometimes with low agreement. On the other hand, the popular automatic MT evaluation methods have some weaknesses. Firstly, they tend to perform well on the language pairs with English as the target language, but weak when English is used as source. Secondly, some methods rely on many additional linguistic features to achieve good performance, which makes the metric unable to replicateand apply to other language pairs easily. Thirdly, some popular metrics utilize incomprehensive factors, which result in low performance on some practical tasks. In this thesis, to address the existing problems, we design novel MT evaluation methods and investigate their performances on different languages. Firstly, we design augmented factors to yield highly accurate evaluation.Secondly, we design a tunable evaluation model where weighting of factors can be optimized according to the characteristics of languages. Thirdly, in the enhanced version of our methods, we design concise linguistic feature using POS to show that our methods can yield even higher performance when using some external linguistic resources. Finally, we introduce the practical performance of our metrics in the ACL-WMT workshop shared tasks, which show that the proposed methods are robust across different languages.", "creator": "Online2PDF.com"}}}