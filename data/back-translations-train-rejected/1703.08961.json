{"id": "1703.08961", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Mar-2017", "title": "Scaling the Scattering Transform: Deep Hybrid Networks", "abstract": "We use the scattering network as a generic and fixed initialization of the first layers of a supervised hybrid deep network. We show that early layers do not necessarily need to be learned, providing the best results to-date with pre-defined representations while being competitive with Deep CNNs. Using a shallow cascade of 1x1 convolutions, which encodes scattering coefficients that correspond to spatial windows of very small sizes, permits to obtain AlexNet accuracy on the imagenet ILSVRC2012. We demonstrate that this local encoding explicitly learns in-variance w.r.t. rotations. Combining scattering networks with a modern ResNet, we achieve a single-crop top 5 error of 11.4% on imagenet ILSVRC2012, comparable to the Resnet-18 architecture, while utilizing only 10 layers. We also find that hybrid architectures can yield excellent performance in the small sample regime, exceeding their end-to-end counterparts, through their ability to incorporate geometrical priors. We demonstrate this on subsets of the CIFAR-10 dataset and by setting a new state-of-the-art on the STL-10 dataset.", "histories": [["v1", "Mon, 27 Mar 2017 07:49:43 GMT  (412kb)", "https://arxiv.org/abs/1703.08961v1", null], ["v2", "Tue, 4 Apr 2017 06:13:22 GMT  (408kb)", "http://arxiv.org/abs/1703.08961v2", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["edouard oyallon", "eugene belilovsky", "sergey zagoruyko"], "accepted": false, "id": "1703.08961"}, "pdf": {"name": "1703.08961.pdf", "metadata": {"source": "CRF", "title": "Scaling the Scattering Transform: Deep Hybrid Networks", "authors": ["Edouard Oyallon"], "emails": ["edouard.oyallon@ens.fr", "eugene.belilovsky@inria.fr", "sergey.zagoruyko@enpc.fr"], "sections": [{"heading": null, "text": "ar Xiv: 170 3.08 961v 2 [cs.C V] 4A prWe use the scatter network as a generic and fixed initialization of the first layers of a monitored hybrid deep network. We show that early layers do not necessarily need to be learned and provide the best results to date with predefined representations while competing with deep CNNs. By using a flat cascade of 1 x 1 turns encoding scatter coefficients that correspond to spatial windows of very small size, we can achieve AlexNet accuracy on the Imagenet ILSVRC2012. We show that this local coding explicitly learns inventory without rotation. By combining scatter networks with a modern ResNet, we achieve a top-5 error of 11.4% on the Imagenet ILSVRC2012, comparable to the Resnet 18 architecture, while using only 10 layers at the same time. We also find that hybrid architectures can be measured at the bottom of their net by having an excellent performance measured with a modern resAR system."}, {"heading": "1. Introduction", "text": "The fact is that most of us are able to behave in the way they have done in the past: in the way they have done it, in the way they have done it, in the way they have done it, in the way they have done it, in the way they have done it, in the way they have done it, in the way they have done it, in the way they have done it. \""}, {"heading": "2. Scattering Networks and Hybrid Architectures", "text": "We introduce scattering transformation and motivate its use as a generic input for supervised tasks. A scattering network belongs to the class of CNNs whose filters are fixed as wavelengths [27]. The construction of this network has strong mathematical foundations [24], which means that it is well understood, based on few parameters and stable against a large class of geometric transformations. In general, the parameters of this representation do not need to be adapted to the bias of the dataset [27], which makes its output a suitable generic representation. We then propose the use of supervised CNNs built over the scattering network and motivate them. Finally, we propose a supervised coding of scattering coefficients using 1x1 windings that can maintain interperability and locality properties."}, {"heading": "2.1. Scattering Networks", "text": "In this section, the definition of waves is a complex, complex and complex waveform. (u) We have the ability to capture the waves of waves. (u) We have the wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave. (u) We have the wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave, the wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave, the wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave, the wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave, the wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-the wave-wave-wave-wave-wave, the wave-wave-wave-wave-wave-wave-wave-wave-wave, the wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-wave-the wave-wave-wave-wave-wave-wave-wave-wave-wave-the-wave-wave-wave-wave-wave-wave-the-wave-wave-wave-wave-wave, the-wave-wave-wave-wave-wave-wave-the-wave-wave-wave-wave-wave-the-wave-wave-wave-wave-the-wave-wave-wave-the-wave-wave-wave-wave-wave-the-wave-wave-wave-the-wave-wave-wave-wave-wave-wave-wave-the-wave-wave-wave-the-wave-wave-wave-wave-wave-the-wave-wave-wave-the-wave-wave-wave-the-wave-wave-wave-wave-wave-the-wave-wave-wave-wave-the-wave-wave-the-wave-wave"}, {"heading": "2.2. Cascading a supervised Deep architecture", "text": "We have proposed the use of a supervised architecture on top of a scattering network. These transformations have yielded excellent numerical results in which the variabilities are fully known, such as MNIST or FERET. In these cases, the problems that arise in relation to variant diversity are interlinked, and this leads to a solution to these problems. However, the classification of tasks on more complex screens means that this variant diversity is only partially known, as there are no geometric variables."}, {"heading": "2.3. SharedLocal Encoder for ScatteringRepresentations", "text": "We discuss the spatial support of different approaches to motivate our local encoders. In fact, the representations in a specific place and in depth are very different; the specific representations that emanate from the screen recognition are often used in the way they take place in other countries."}, {"heading": "3. Local Encoding of Scattering", "text": "We evaluate the monitored SLE on the Imagenet ILSVRC2012 dataset. This is a large and sophisticated natural color dataset consisting of 1.2 million training images and 50,000 validation images, divided into 1000 classes. We then show some of the unique properties of this network and evaluate its properties in a separate task."}, {"heading": "3.1. Shared Local Encoder on Imagenet", "text": "This year, it has reached the stage where it will be able to take the lead in order to achieve the objectives I have mentioned."}, {"heading": "3.2. Interprating SLE\u2019s first layer", "text": "There are few empirical analyses that shed light on the structure of the individual layers starting from the first level of our SLE f. We analyze and show that it explicitly involves local rotations, but also that the Fourier fundamentals associated with rotation are natural foundations of our rotation. It is a promising direction to understand the nature of the next two layers. 3https: / / github.com / BVLC / caffe / caffe-precision-on-ImageNet-valWe establish some mathematical terms that we use in our analysis."}, {"heading": "4. Numerical performances of hybrid networks", "text": "We now show that cascading modern CNN architectures over the scatter network can generate high-performance classification systems. We use hybrid Convolutionary Networks on the Imagenet ILSVRC 2012 dataset and the CIFAR-10 dataset, and show that they can achieve performance comparable to modern end-to-end learning approaches. We then evaluate the hybrid networks in determining limited data by using a subset of CIFAR10 and the STL-10 dataset, and show that we can achieve a significant performance improvement over analog end-to-end learned CNNs."}, {"heading": "4.1. Deep Hybrid CNNs on ILSVRC2012", "text": "We have shown in the previous section that an SLE followed by FC layers can produce results comparable to AlexNet [19] in the Imagenet classification task. At this point, we will consider the cascading of the scatter transformation using a modern CNN architecture, such as Resnet [41, 13]. We will take Resnet-18 [41] as a reference and construct a similar architecture with only 10 layers above the scatter network. We will use a scatter transformation with J = 3, so that CNN is learned over a spatial dimension of 28 x 28 and a channel size of 651 (3 color channels of 217 each). ResNet-18 typically has 4 residual layers of 2 blocks each, which gradually decrease the spatial resolution [41]. Since we use scatter as the first step, we will remove two blocks from our model. The network is in Table 4.We will use the same optimization and data augmentation techniques described in Section 3.1, but with learning rates of 860 and 830, but with learning rates of M in the previous section."}, {"heading": "4.2. Hybrid Supervised and Unsupervised Representations on CIFAR-10", "text": "We are considering increasing the number of people of working age who are able to stay in the city, many times more than in other cities."}, {"heading": "4.3. Limited samples setting", "text": "An important application of a hybrid representation is the definition of limited data. Here, the learning algorithm is limited in the variations it can observe or learn from the data, so the introduction of a geometric predecessor can greatly improve performance. We evaluate our algorithm based on the limited sample setting using a subset of CIFAR-10 and the STL-10 dataset."}, {"heading": "4.3.1 CIFAR-10", "text": "We take subsets of decreasing size of the CIFAR dataset and train both CNNs and counterparts that use scattering as the first stage. We conduct experiments with subsets of 1000, 500 and 100 samples evenly distributed among the 10 classes. We use the Wide ResNet [41] of depth 16 and width 8 as the starting point, which shows an almost state-of-the-art performance at the complete CIFAR-10 task in the monitored environment. This network consists of 4 stages of decreasing spatial resolution described in Table 1 of [41]. We construct a comparable hybrid architecture that removes a single step and all steps, as the scattering has already sampled down the spatial resolution. This architecture is described in Table 5. Unlike the baseline, we refer from here to the same number of WRN 16-8, our architecture has 12 layers and a corresponding width, while keeping the spatial resolution constant in all stages before the final schedule."}, {"heading": "4.3.2 STL-10", "text": "The SLT-10 dataset consists of 96 \u00d7 96 color images, with only 5000 labeled images in the training set dividequally divided into 10 classes and 8000 images in the test set. The larger size of the images and the small number of samples available make this a challenging image classification task. The dataset also provides 100,000 blank images for unattended learning. We do not use these images in our experiments, but we find that we can surpass all methods that use unattended images by achieving very competitive results on the STL-10 datasets. We apply a hybrid Convolutionary Architecture applied in the small CIFAR task, adapted to the size of 96 \u00d7 96. The architecture is described in Table 5 and is similar to the one used in the CIFAR small sample task."}, {"heading": "5. Conclusion", "text": "Compared to unattended representation on CIFAR-10 or small data regimes on CIFAR-10 and STL-10, we are showing state-of-the-art results. We are building a supervised shared local encoder that allows the scatter networks to outperform other local encryption methods on ILSVRC2012. This network of only three learned layers allows an analysis of the operations performed. Our work also suggests that predefined features are still of interest and can shed light on deep learning techniques and make them more interpretable. Combined with appropriate learning methods, they could provide more theoretical guarantees needed to develop better deep models and stable representations."}, {"heading": "Acknowledgments", "text": "The authors thank Mathieu Andreux, Matthew Blaschko, Carmine Cella, Bogdan Cirstea, Michael Eickenberg, Ste \ufffd phane Mallat for helpful discussions and support, Rafael Marini and Nikos Paragios for using computer resources and Florent Perronnin for providing important details of their work. This work is funded by the ERC scholarship InvariantClass 320959, a scholarship for doctoral students from the Conseil re \ufffd gional d'Ile-de-France (RDM-IdF), Internal Funds KU Leuven, FP7-MC-CIG 334380, an Amazon Academic Research Award and DIGITEO 2013-0788D - SOPRANO."}], "references": [{"title": "Generalized analytic signals in image processing: comparison, theory and applications", "author": ["S. Bernstein", "J.-L. Bouchot", "M. Reinhardt", "B. Heise"], "venue": "Quaternion and Clifford Fourier Transforms and Wavelets, pages 221\u2013246. Springer,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2013}, {"title": "Multipath sparse coding using hierarchical matching pursuit", "author": ["L. Bo", "X. Ren", "D. Fox"], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 660\u2013667,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2013}, {"title": "Unsupervised feature learning for rgb-d based object recognition", "author": ["L. Bo", "X. Ren", "D. Fox"], "venue": "Experimental Robotics, pages 387\u2013402. Springer,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2013}, {"title": "Ask the locals: multi-way local pooling for image recognition", "author": ["Y.-L. Boureau", "N. Le Roux", "F. Bach", "J. Ponce", "Y. LeCun"], "venue": "Computer Vision (ICCV), 2011 IEEE International Conference on, pages 2651\u20132658. IEEE,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2011}, {"title": "Audio texture synthesis with scattering moments", "author": ["J. Bruna", "S. Mallat"], "venue": "arXiv preprint arXiv:1311.0407,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "Invariant scattering convolution networks", "author": ["J. Bruna", "S. Mallat"], "venue": "IEEE transactions on pattern analysis and machine intelligence, 35(8):1872\u20131886,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "Learning stable group invariant representations with convolutional networks", "author": ["J. Bruna", "A. Szlam", "Y. LeCun"], "venue": "arXiv preprint arXiv:1301.3537,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "Selecting receptive fields in deep networks", "author": ["A. Coates", "A.Y. Ng"], "venue": "Advances in Neural Information Processing Systems, pages 2528\u20132536,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2011}, {"title": "Histograms of oriented gradients for human detection", "author": ["N. Dalal", "B. Triggs"], "venue": "Computer Vision and Pattern Recognition, 2005. CVPR 2005. IEEE Computer Society Conference on, volume 1, pages 886\u2013893. IEEE,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2005}, {"title": "Inverse problems with invariant multiscale statistics", "author": ["I. Dokmani\u0107", "J. Bruna", "S. Mallat", "M. de Hoop"], "venue": "arXiv preprint arXiv:1609.05502,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2016}, {"title": "Discriminative unsupervised feature learning with convolutional neural networks", "author": ["A. Dosovitskiy", "J.T. Springenberg", "M. Riedmiller", "T. Brox"], "venue": "Advances in Neural Information Processing Systems, pages 766\u2013774,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning both weights and connections for efficient neural network", "author": ["S. Han", "J. Pool", "J. Tran", "W. Dally"], "venue": "Advances in Neural Information Processing Systems, pages 1135\u20131143,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep residual learning for image recognition", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "arXiv preprint arXiv:1512.03385,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep unsupervised learning through spatial contrasting", "author": ["E. Hoffer", "I. Hubara", "N. Ailon"], "venue": "arXiv preprint arXiv:1610.00243,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2016}, {"title": "What makes imagenet good for transfer learning", "author": ["M. Huh", "P. Agrawal", "A.A. Efros"], "venue": "arXiv preprint arXiv:1608.08614,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2016}, {"title": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "author": ["S. Ioffe", "C. Szegedy"], "venue": "arXiv preprint arXiv:1502.03167,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2015}, {"title": "Multiscale hierarchical convolutional networks", "author": ["J.-H. Jacobsen", "E. Oyallon", "S. Mallat", "A.W. Smeulders"], "venue": "arXiv preprint arXiv:1703.01775,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2017}, {"title": "The structure of locally orderless images", "author": ["J.J. Koenderink", "A.J. Van Doorn"], "venue": "International Journal of Computer Vision, 31(2-3):159\u2013168,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1999}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "Advances in neural information processing systems, pages 1097\u20131105,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2012}, {"title": "Beyond bags of features: Spatial pyramid matching for recognizing natural  scene categories", "author": ["S. Lazebnik", "C. Schmid", "J. Ponce"], "venue": "Computer vision and pattern recognition, 2006 IEEE computer society conference on, volume 2, pages 2169\u20132178. IEEE,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2006}, {"title": "Learning hierarchical invariant spatio-temporal features for action recognition with independent subspace analysis", "author": ["Q.V. Le", "W.Y. Zou", "S.Y. Yeung", "A.Y. Ng"], "venue": "Computer Vision and Pattern Recognition (CVPR), 2011 IEEE Conference on, pages 3361\u20133368. IEEE,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2011}, {"title": "Convolutional networks and applications in vision", "author": ["Y. LeCun", "K. Kavukcuoglu", "C. Farabet"], "venue": "In ISCAS,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2010}, {"title": "Object recognition from local scale-invariant features", "author": ["D.G. Lowe"], "venue": "Computer vision, 1999. The proceedings of the seventh IEEE international conference on, volume 2, pages 1150\u20131157. Ieee,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1999}, {"title": "Group invariant scattering", "author": ["S. Mallat"], "venue": "Communications on Pure and Applied Mathematics, 65(10):1331\u20131398,", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2012}, {"title": "Understanding deep convolutional networks", "author": ["S. Mallat"], "venue": "Phil. Trans. R. Soc. A, 374(2065):20150203,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2016}, {"title": "Building a regular decision boundary with deep networks", "author": ["E. Oyallon"], "venue": "arXiv preprint arXiv:1703.01775,", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2017}, {"title": "Deep roto-translation scattering for object classification", "author": ["E. Oyallon", "S. Mallat"], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2865\u2013 2873,", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2015}, {"title": "Fisher vectors meet neural networks: A hybrid classification architecture", "author": ["F. Perronnin", "D. Larlus"], "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition, pages 3743\u20133752,", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2015}, {"title": "Unsupervised representation learning with deep convolutional generative adversarial networks", "author": ["A. Radford", "L. Metz", "S. Chintala"], "venue": "arXiv preprint arXiv:1511.06434,", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2015}, {"title": "High-dimensional signature compression for large-scale image classification", "author": ["J. S\u00e1nchez", "F. Perronnin"], "venue": "Computer Vision and Pattern Recognition (CVPR), 2011 IEEE Conference on, pages 1665\u20131672. IEEE,", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2011}, {"title": "Image classification with the fisher vector: Theory and practice", "author": ["J. S\u00e1nchez", "F. Perronnin", "T. Mensink", "J. Verbeek"], "venue": "International journal of computer vision, 105(3):222\u2013245,", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2013}, {"title": "Realistic modeling of simple and complex cell tuning in the hmax model, and implications for invariant object recognition in cortex", "author": ["T. Serre", "M. Riesenhuber"], "venue": "Technical report, DTIC Document,", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2004}, {"title": "Rotation, scaling and deformation invariant scattering for texture discrimination", "author": ["L. Sifre", "S. Mallat"], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1233\u20131240,", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2013}, {"title": "Striving for simplicity: The all convolutional net", "author": ["J.T. Springenberg", "A. Dosovitskiy", "T. Brox", "M. Riedmiller"], "venue": "arXiv preprint arXiv:1412.6806,", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2014}, {"title": "Highway networks", "author": ["R.K. Srivastava", "K. Greff", "J. Schmidhuber"], "venue": "arXiv preprint arXiv:1505.00387,", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2015}, {"title": "Unitary representations and harmonic analysis: an introduction, volume 44", "author": ["M. Sugiura"], "venue": "Elsevier,", "citeRegEx": "36", "shortCiteRegEx": null, "year": 1990}, {"title": "Multi-task bayesian optimization", "author": ["K. Swersky", "J. Snoek", "R.P. Adams"], "venue": "Advances in neural information processing systems, pages 2004\u20132012,", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2013}, {"title": "Intriguing properties of neural networks", "author": ["C. Szegedy", "W. Zaremba", "I. Sutskever", "J. Bruna", "D. Erhan", "I. Goodfellow", "R. Fergus"], "venue": "arXiv preprint arXiv:1312.6199,", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2013}, {"title": "These de doctorat de lEcole normale sup\u00e9rieure", "author": ["I. Waldspurger"], "venue": "PhD thesis, \u00c9cole normale sup\u00e9rieure,", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2015}, {"title": "How transferable are features in deep neural networks", "author": ["J. Yosinski", "J. Clune", "Y. Bengio", "H. Lipson"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2014}, {"title": "Wide residual networks", "author": ["S. Zagoruyko", "N. Komodakis"], "venue": "arXiv preprint arXiv:1605.07146,", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2016}, {"title": "Visualizing and understanding convolutional networks", "author": ["M.D. Zeiler", "R. Fergus"], "venue": "European conference on computer vision, pages 818\u2013833. Springer,", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2014}, {"title": "Stacked what-where auto-encoders", "author": ["J. Zhao", "M. Mathieu", "R. Goroshin", "Y. LeCun"], "venue": "arXiv preprint arXiv:1506.02351,", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2016}], "referenceMentions": [{"referenceID": 12, "context": "Deep architectures build representations that lead to state-of-the-art results on image classification tasks [13].", "startOffset": 109, "endOffset": 113}, {"referenceID": 21, "context": "These architectures are designed as very deep cascades of non-linear end-to-end learned modules [22].", "startOffset": 96, "endOffset": 100}, {"referenceID": 41, "context": "When trained on large-scale datasets they have been shown to produce representations that are transferable to other datasets [42, 15], which indicate they have captured generic properties of a supervised task that consequently do not need to be learned.", "startOffset": 125, "endOffset": 133}, {"referenceID": 14, "context": "When trained on large-scale datasets they have been shown to produce representations that are transferable to other datasets [42, 15], which indicate they have captured generic properties of a supervised task that consequently do not need to be learned.", "startOffset": 125, "endOffset": 133}, {"referenceID": 18, "context": "Indeed several works indicate geometrical structures in the filters of the earlier layers [19, 39] of Deep CNNs.", "startOffset": 90, "endOffset": 98}, {"referenceID": 38, "context": "Indeed several works indicate geometrical structures in the filters of the earlier layers [19, 39] of Deep CNNs.", "startOffset": 90, "endOffset": 98}, {"referenceID": 37, "context": "However, understanding the precise operations performed by those early layers is a complicated [38, 26] and possibly intractable task.", "startOffset": 95, "endOffset": 103}, {"referenceID": 25, "context": "However, understanding the precise operations performed by those early layers is a complicated [38, 26] and possibly intractable task.", "startOffset": 95, "endOffset": 103}, {"referenceID": 22, "context": "A potential candidate for an image representation is the SIFT descriptor [23] that was widely used before 2012 as a feature extractor in classification pipelines [30, 31].", "startOffset": 73, "endOffset": 77}, {"referenceID": 29, "context": "A potential candidate for an image representation is the SIFT descriptor [23] that was widely used before 2012 as a feature extractor in classification pipelines [30, 31].", "startOffset": 162, "endOffset": 170}, {"referenceID": 30, "context": "A potential candidate for an image representation is the SIFT descriptor [23] that was widely used before 2012 as a feature extractor in classification pipelines [30, 31].", "startOffset": 162, "endOffset": 170}, {"referenceID": 20, "context": "However, several works indicate that this is not a generic enough representation to build further modules on top of [21, 2].", "startOffset": 116, "endOffset": 123}, {"referenceID": 1, "context": "However, several works indicate that this is not a generic enough representation to build further modules on top of [21, 2].", "startOffset": 116, "endOffset": 123}, {"referenceID": 23, "context": "A major improvement over SIFT can be found in the scattering transform [24, 6, 33], which is a type of deep convolutional network, which permits to retain discriminative information normally discarded by methods like SIFT while introducing geometric invariances and stability.", "startOffset": 71, "endOffset": 82}, {"referenceID": 5, "context": "A major improvement over SIFT can be found in the scattering transform [24, 6, 33], which is a type of deep convolutional network, which permits to retain discriminative information normally discarded by methods like SIFT while introducing geometric invariances and stability.", "startOffset": 71, "endOffset": 82}, {"referenceID": 32, "context": "A major improvement over SIFT can be found in the scattering transform [24, 6, 33], which is a type of deep convolutional network, which permits to retain discriminative information normally discarded by methods like SIFT while introducing geometric invariances and stability.", "startOffset": 71, "endOffset": 82}, {"referenceID": 26, "context": "Scattering transforms have been shown to already produce representations that lead to the top results on complex image datasets when compared to other unsupervised representations (even learned ones) [27].", "startOffset": 200, "endOffset": 204}, {"referenceID": 27, "context": "Related to our work [28] proposed a hybrid representation for large scale image recognition combining a prede-", "startOffset": 20, "endOffset": 24}, {"referenceID": 26, "context": "A scattering network belongs to the class of CNNs whose filters are fixed as wavelets [27].", "startOffset": 86, "endOffset": 90}, {"referenceID": 23, "context": "The construction of this network has strong mathematical foundations [24], meaning it is well understood, relies on few parameters and is stable to a large class of geometric transformations.", "startOffset": 69, "endOffset": 73}, {"referenceID": 26, "context": "In general, the parameters of this representation do not need to be adapted to the bias of the dataset [27], making its output a suitable generic representation.", "startOffset": 103, "endOffset": 107}, {"referenceID": 26, "context": "With appropriate discretization [27], {AJx,W1x} is approximatively an isometry on the set of signals with limited bandwidth, and this implies the energy of the signal is preserved.", "startOffset": 32, "endOffset": 36}, {"referenceID": 0, "context": "Here, the mother wavelet is analytic, thus |W1x| is regular [1] which implies that the energy in Fourier of |W1x| is more likely to be contained in a lower frequency domain than W1x.", "startOffset": 60, "endOffset": 63}, {"referenceID": 5, "context": "j1 < j2 because non-increasing paths have been shown to bear no energy [6].", "startOffset": 71, "endOffset": 74}, {"referenceID": 5, "context": "We do not compute higher order scatterings, because their energy is negligible [6].", "startOffset": 79, "endOffset": 82}, {"referenceID": 5, "context": ", and the original image is down-sampled by a factor 2 [6].", "startOffset": 55, "endOffset": 58}, {"referenceID": 23, "context": "This representation is proved to linearize small deformations [24] of images, be non-expansive and almost complete [10, 5], which makes it an ideal input to a deep network algorithm, that can build invariants to this local variability via a first linear operator.", "startOffset": 62, "endOffset": 66}, {"referenceID": 9, "context": "This representation is proved to linearize small deformations [24] of images, be non-expansive and almost complete [10, 5], which makes it an ideal input to a deep network algorithm, that can build invariants to this local variability via a first linear operator.", "startOffset": 115, "endOffset": 122}, {"referenceID": 4, "context": "This representation is proved to linearize small deformations [24] of images, be non-expansive and almost complete [10, 5], which makes it an ideal input to a deep network algorithm, that can build invariants to this local variability via a first linear operator.", "startOffset": 115, "endOffset": 122}, {"referenceID": 5, "context": "Scattering transforms have yielded excellent numerical results [6] on datasets where the variabilities are completely known, such as MNIST or FERET.", "startOffset": 63, "endOffset": 66}, {"referenceID": 26, "context": "Although applying the scattering transform on datasets like CIFAR or Caltech leads to nearly state-of-the-art results in comparison to other unsupervised representations there is a large gap in performance when comparing to supervised representations [27].", "startOffset": 251, "endOffset": 255}, {"referenceID": 24, "context": "Recent works [25, 7, 17] have suggested that deep networks could build an approximation of the group of symmetries of a classification task and apply transformations along the orbits of this group, like convolutions.", "startOffset": 13, "endOffset": 24}, {"referenceID": 6, "context": "Recent works [25, 7, 17] have suggested that deep networks could build an approximation of the group of symmetries of a classification task and apply transformations along the orbits of this group, like convolutions.", "startOffset": 13, "endOffset": 24}, {"referenceID": 16, "context": "Recent works [25, 7, 17] have suggested that deep networks could build an approximation of the group of symmetries of a classification task and apply transformations along the orbits of this group, like convolutions.", "startOffset": 13, "endOffset": 24}, {"referenceID": 24, "context": "[25] motivates that to each layer corresponds an approximated Lie group of symmetry, and this approximation is progressive, in the sense that the dimension of these groups is increasing with depth.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "Discovering explicitly the next new and non-geometrical groups of symmetry is however a difficult task [17]; nonetheless, the roto-translation group seems to be a good initialization for the first layers.", "startOffset": 103, "endOffset": 107}, {"referenceID": 12, "context": "The second, referred to as a hybrid CNN, is a cascade of a scattering network and a standard CNN architecture, such as a ResNet [13].", "startOffset": 128, "endOffset": 132}, {"referenceID": 18, "context": "For example, at depth 2 of [19], the effective spatial support of the corresponding filter is already 32 pixels (out of 224).", "startOffset": 27, "endOffset": 31}, {"referenceID": 39, "context": "The specific representations derived from CNNs trained on large scale image recognition are often used as representations in other computer vision tasks or datasets [40, 42].", "startOffset": 165, "endOffset": 173}, {"referenceID": 41, "context": "The specific representations derived from CNNs trained on large scale image recognition are often used as representations in other computer vision tasks or datasets [40, 42].", "startOffset": 165, "endOffset": 173}, {"referenceID": 29, "context": "On the other hand prior to 2012 local encoding methods led to state of the art performance on large scale visual recognition tasks [30].", "startOffset": 131, "endOffset": 135}, {"referenceID": 22, "context": "In these approaches local neighborhoods of an image were encoded using method such as SIFT descriptors [23], HOG [9], and wavelet transforms [32].", "startOffset": 103, "endOffset": 107}, {"referenceID": 8, "context": "In these approaches local neighborhoods of an image were encoded using method such as SIFT descriptors [23], HOG [9], and wavelet transforms [32].", "startOffset": 113, "endOffset": 116}, {"referenceID": 31, "context": "In these approaches local neighborhoods of an image were encoded using method such as SIFT descriptors [23], HOG [9], and wavelet transforms [32].", "startOffset": 141, "endOffset": 145}, {"referenceID": 3, "context": "They were also often combined with an unsupervised encoding, such as sparse coding [4] or Fisher Vectors(FVs) [30].", "startOffset": 83, "endOffset": 86}, {"referenceID": 29, "context": "They were also often combined with an unsupervised encoding, such as sparse coding [4] or Fisher Vectors(FVs) [30].", "startOffset": 110, "endOffset": 114}, {"referenceID": 17, "context": "Indeed, many works in classical image processing or classification [18, 4, 30, 28] suggests that the local encoding of an image permit to describe efficiently an image.", "startOffset": 67, "endOffset": 82}, {"referenceID": 3, "context": "Indeed, many works in classical image processing or classification [18, 4, 30, 28] suggests that the local encoding of an image permit to describe efficiently an image.", "startOffset": 67, "endOffset": 82}, {"referenceID": 29, "context": "Indeed, many works in classical image processing or classification [18, 4, 30, 28] suggests that the local encoding of an image permit to describe efficiently an image.", "startOffset": 67, "endOffset": 82}, {"referenceID": 27, "context": "Indeed, many works in classical image processing or classification [18, 4, 30, 28] suggests that the local encoding of an image permit to describe efficiently an image.", "startOffset": 67, "endOffset": 82}, {"referenceID": 22, "context": "Additionally for some algorithms that rely on local neighbourhoods, the use of local descriptors is essential [23].", "startOffset": 110, "endOffset": 114}, {"referenceID": 18, "context": "Nevertheless, on large scale classification, this approach was surpassed by fully supervised learned methods [19].", "startOffset": 109, "endOffset": 113}, {"referenceID": 27, "context": "We show that it is possible to apply, a similarly local, yet supervised encoding algorithm to a scattering transform, as suggested in the conclusion of [28].", "startOffset": 152, "endOffset": 156}, {"referenceID": 40, "context": "We first describe our training pipeline, which is similar to [41].", "startOffset": 61, "endOffset": 65}, {"referenceID": 12, "context": "During the training process, each image is randomly rescaled, cropped, and flipped as in [13].", "startOffset": 89, "endOffset": 93}, {"referenceID": 27, "context": "FV + FC [28] 55.", "startOffset": 8, "endOffset": 12}, {"referenceID": 29, "context": "4 FV + SVM [30] 54.", "startOffset": 11, "endOffset": 15}, {"referenceID": 27, "context": "[28] single-crop result was", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "For all learned layers we use batch normalization [16] followed by a ReLU [19] non-linearity.", "startOffset": 50, "endOffset": 54}, {"referenceID": 18, "context": "For all learned layers we use batch normalization [16] followed by a ReLU [19] non-linearity.", "startOffset": 74, "endOffset": 78}, {"referenceID": 18, "context": "The performance is analogous to the AlexNet [19].", "startOffset": 44, "endOffset": 48}, {"referenceID": 29, "context": "In term of architecture, our hybrid model is analogous, and comparable to that of [30, 28], for which SIFT features are extracted followed by FV [31] encoding.", "startOffset": 82, "endOffset": 90}, {"referenceID": 27, "context": "In term of architecture, our hybrid model is analogous, and comparable to that of [30, 28], for which SIFT features are extracted followed by FV [31] encoding.", "startOffset": 82, "endOffset": 90}, {"referenceID": 30, "context": "In term of architecture, our hybrid model is analogous, and comparable to that of [30, 28], for which SIFT features are extracted followed by FV [31] encoding.", "startOffset": 145, "endOffset": 149}, {"referenceID": 19, "context": "Two approaches are then used: either the spatial localization is handled either by a Spatial Pyramid Pooling [20], which is then fed to a linear SVM, either the spatial variables are directly encoded in the FVs, and classified with a stack of four fully connected layers.", "startOffset": 109, "endOffset": 113}, {"referenceID": 29, "context": "In Top 1, [30] and [28] obtain respectively 44.", "startOffset": 10, "endOffset": 14}, {"referenceID": 27, "context": "In Top 1, [30] and [28] obtain respectively 44.", "startOffset": 19, "endOffset": 23}, {"referenceID": 3, "context": "We followed the standard protocol for evaluation [4] with 10 folds and evaluate per class accuracy, with 30 training samples per class, using a linear SVM used with the SLE descriptors.", "startOffset": 49, "endOffset": 52}, {"referenceID": 41, "context": "4, similar to that reported for the final AlexNet final layer in [42] and sparse coding with SIFT [4].", "startOffset": 65, "endOffset": 69}, {"referenceID": 3, "context": "4, similar to that reported for the final AlexNet final layer in [42] and sparse coding with SIFT [4].", "startOffset": 98, "endOffset": 101}, {"referenceID": 19, "context": "However in both cases spatial variability is removed, either by Spatial Pyramid Pooling [20], or the cascade of large filters.", "startOffset": 88, "endOffset": 92}, {"referenceID": 38, "context": "Finding structure in the kernel of the layers of depth less than 2 [39, 42] is a complex task, and few empirical analyses exist that shed light on the structure [17] of deeper layers.", "startOffset": 67, "endOffset": 75}, {"referenceID": 41, "context": "Finding structure in the kernel of the layers of depth less than 2 [39, 42] is a complex task, and few empirical analyses exist that shed light on the structure [17] of deeper layers.", "startOffset": 67, "endOffset": 75}, {"referenceID": 16, "context": "Finding structure in the kernel of the layers of depth less than 2 [39, 42] is a complex task, and few empirical analyses exist that shed light on the structure [17] of deeper layers.", "startOffset": 161, "endOffset": 165}, {"referenceID": 26, "context": "A scattering transform with scale J can be interpreted as a CNN with depth J [27], whose channels indexes correspond to different scattering frequency indexes, which is a structuration.", "startOffset": 77, "endOffset": 81}, {"referenceID": 35, "context": "Unitary representation framework [36] permits the building of a Fourier transform on compact group, like rotations.", "startOffset": 33, "endOffset": 37}, {"referenceID": 32, "context": "It is even possible to build a scattering transform on the rototranslation group [33].", "startOffset": 81, "endOffset": 85}, {"referenceID": 11, "context": "1 61M VGG-16 [12] 68.", "startOffset": 13, "endOffset": 17}, {"referenceID": 40, "context": "7M Resnet-200 [41] 78.", "startOffset": 14, "endOffset": 18}, {"referenceID": 26, "context": "Roto-Scat + SVM [27] 82.", "startOffset": 16, "endOffset": 20}, {"referenceID": 10, "context": "3 ExemplarCNN [11] 84.", "startOffset": 14, "endOffset": 18}, {"referenceID": 28, "context": "3 DCGAN [29] 82.", "startOffset": 8, "endOffset": 12}, {"referenceID": 34, "context": "1 Highway network [35] 92.", "startOffset": 18, "endOffset": 22}, {"referenceID": 33, "context": "4 All-CNN [34] 92.", "startOffset": 10, "endOffset": 14}, {"referenceID": 40, "context": "8 WRN 16 - 8 [41] 95.", "startOffset": 13, "endOffset": 17}, {"referenceID": 40, "context": "7 WRN 28 - 10 [41] 96.", "startOffset": 14, "endOffset": 18}, {"referenceID": 18, "context": "We showed in the previous section that a SLE followed by FC layers can produce results comparable with the AlexNet [19] on the Imagenet classification task.", "startOffset": 115, "endOffset": 119}, {"referenceID": 40, "context": "Here we consider cascading the scattering transform with a modern CNN architecture, such as Resnet [41, 13].", "startOffset": 99, "endOffset": 107}, {"referenceID": 12, "context": "Here we consider cascading the scattering transform with a modern CNN architecture, such as Resnet [41, 13].", "startOffset": 99, "endOffset": 107}, {"referenceID": 40, "context": "We take the Resnet-18 [41], as a reference and construct a similar architecture with only 10 layers on top of the scattering network.", "startOffset": 22, "endOffset": 26}, {"referenceID": 40, "context": "The ResNet-18 typically has 4 residual stages of 2 blocks each which gradually decrease the spatial resolution [41].", "startOffset": 111, "endOffset": 115}, {"referenceID": 40, "context": "Taking the convention of [41] we describe the convolution size and channels in the Stage details", "startOffset": 25, "endOffset": 29}, {"referenceID": 40, "context": "We follow the training procedure prescribed in [41] utilizing SGD with momentum of 0.", "startOffset": 47, "endOffset": 51}, {"referenceID": 15, "context": "We utilize batch normalization techniques at all layers which lead to a better conditioning of the optimization [16].", "startOffset": 112, "endOffset": 116}, {"referenceID": 40, "context": "We use a similar hybrid architecture to the successful wide residual network (WRN) [41].", "startOffset": 83, "endOffset": 87}, {"referenceID": 40, "context": "2 as specified in [41].", "startOffset": 18, "endOffset": 22}, {"referenceID": 12, "context": "This is superior to several benchmarks but performs worse than the original ResNet [13] and the wide resnet [41].", "startOffset": 83, "endOffset": 87}, {"referenceID": 40, "context": "This is superior to several benchmarks but performs worse than the original ResNet [13] and the wide resnet [41].", "startOffset": 108, "endOffset": 112}, {"referenceID": 40, "context": "We use as a baseline the Wide ResNet [41] of depth 16 and width 8, which shows near state-of-the-art performance on the full CIFAR-10 task in the supervised setting.", "startOffset": 37, "endOffset": 41}, {"referenceID": 40, "context": "This network consists of 4 stages of progressively decreasing spatial resolution detailed in Table 1 of [41].", "startOffset": 104, "endOffset": 108}, {"referenceID": 36, "context": "6 CNN[37] 70.", "startOffset": 5, "endOffset": 9}, {"referenceID": 10, "context": "Exemplar CNN [11] 75.", "startOffset": 13, "endOffset": 17}, {"referenceID": 42, "context": "3 Stacked what-where AE [43] 74.", "startOffset": 24, "endOffset": 28}, {"referenceID": 2, "context": "33 Hierarchical Matching Pursuit (HMP) [3] 64.", "startOffset": 39, "endOffset": 42}, {"referenceID": 7, "context": "5\u00b11 Convolutional K-means Network [8] 60.", "startOffset": 34, "endOffset": 37}, {"referenceID": 36, "context": "The best reported result in the purely supervised case is a CNN [37, 11] whose hyper parameters have been automatically tuned using 4000 images for validation achieving 70.", "startOffset": 64, "endOffset": 72}, {"referenceID": 10, "context": "The best reported result in the purely supervised case is a CNN [37, 11] whose hyper parameters have been automatically tuned using 4000 images for validation achieving 70.", "startOffset": 64, "endOffset": 72}, {"referenceID": 13, "context": "To compare with [14] we also train on the full training set of 5000 images obtaining an accuracy of 87.", "startOffset": 16, "endOffset": 20}, {"referenceID": 13, "context": "3% reported in [14] using unsupervised learning and the full unlabeled and labeled training set.", "startOffset": 15, "endOffset": 19}], "year": 2017, "abstractText": "We use the scattering network as a generic and fixed initialization of the first layers of a supervised hybrid deep network. We show that early layers do not necessarily need to be learned, providing the best results to-date with pre-defined representations while being competitive with Deep CNNs. Using a shallow cascade of 1 \u00d7 1 convolutions, which encodes scattering coefficients that correspond to spatial windows of very small sizes, permits to obtain AlexNet accuracy on the imagenet ILSVRC2012. We demonstrate that this local encoding explicitly learns invariance w.r.t. rotations. Combining scattering networks with a modern ResNet, we achieve a single-crop top 5 error of 11.4% on imagenet ILSVRC2012, comparable to the Resnet-18 architecture, while utilizing only 10 layers. We also find that hybrid architectures can yield excellent performance in the small sample regime, exceeding their endto-end counterparts, through their ability to incorporate geometrical priors. We demonstrate this on subsets of the CIFAR-10 dataset and on the STL-10 dataset.", "creator": "LaTeX with hyperref package"}}}