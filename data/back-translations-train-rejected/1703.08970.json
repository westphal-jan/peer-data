{"id": "1703.08970", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Mar-2017", "title": "Multimodal deep learning approach for joint EEG-EMG data compression and classification", "abstract": "In this paper, we present a joint compression and classification approach of EEG and EMG signals using a deep learning approach. Specifically, we build our system based on the deep autoencoder architecture which is designed not only to extract discriminant features in the multimodal data representation but also to reconstruct the data from the latent representation using encoder-decoder layers. Since autoencoder can be seen as a compression approach, we extend it to handle multimodal data at the encoder layer, reconstructed and retrieved at the decoder layer. We show through experimental results, that exploiting both multimodal data intercorellation and intracorellation 1) Significantly reduces signal distortion particularly for high compression levels 2) Achieves better accuracy in classifying EEG and EMG signals recorded and labeled according to the sentiments of the volunteer.", "histories": [["v1", "Mon, 27 Mar 2017 08:37:35 GMT  (586kb,D)", "http://arxiv.org/abs/1703.08970v1", "IEEE Wireless Communications and Networking Conference (WCNC), 2017"]], "COMMENTS": "IEEE Wireless Communications and Networking Conference (WCNC), 2017", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["ahmed ben said", "amr mohamed", "tarek elfouly", "khaled harras", "z jane wang"], "accepted": false, "id": "1703.08970"}, "pdf": {"name": "1703.08970.pdf", "metadata": {"source": "CRF", "title": "Multimodal deep learning approach for joint EEG-EMG data compression and classification", "authors": ["Ahmed Ben Said", "Amr Mohamed", "Tarek Elfouly", "Khaled Harras", "Z. Jane Wang"], "emails": ["tarekfouly}@qu.edu.qa", "kharras@qatar.cmu.edu", "zjanew@ece.ubc.ca"], "sections": [{"heading": null, "text": "This year it is more than ever before in the history of the city."}, {"heading": "II. BACKGROUND", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Autoencoder", "text": "An autoencoder, shown in Fig. 1, is a special type of neural network, consisting of three layers. First, the data is fed into the input layer, transferred to a second layer, which is called a hidden or bottleneck layer, and then reconstructed on a third layer, which is called a reconstruction layer. The encoder transforms the set of data vectors x-RX into a hidden representation h-RH via an activation function f: h = f (Wx + b) (1) The decoder transforms the hidden representation h into reconstruction data r-RX via an activation function g: r (W-h + b) (2) The parameters W-RX-H and W-RH-X are essentially labeled as weight matrices. b-RH and b-RX-RX-RX-RX are labeled as the bias vectors. f and g are typically hyperbolic functions W-X-H (X-X-Rx-X-Rx / RH-X-X-Rx) or RH-X-X-X-X-Rx (RH-X-Rx)."}, {"heading": "B. Stacked autoencoder", "text": "Stacked Autoencoder (SAE), as shown in Fig. 2, is a neural network consisting of several layers of autoencoders. Output of each layer is fed to the next layer. SAE is trained through a greedy layer-by-layer training [21]. Specifically, this is done one layer at a time. On each layer, we look at the auto encoder composed of the current layer and its previous layer, which is the output of the previous layer. Once N \u2212 1 layers are trained, we can calculate the output of the N-th layer wired to it. This unattended step is followed by a supervised fine-tuning of the parameters, adding a Softmax layer to the SAE. 1You will find the same subspace as PCA, but the projection direction essentially does not correspond to the guidelines of the main components."}, {"heading": "III. MULTIMODAL AUTOENCODER FOR EEG-EMG COMPRESSION AND CLASSIFICATION", "text": "Fig. 3 shows the multimodal autoencoder architecture. It consists of two paths for EEG and EMG. Each path represents an unimodal stacked autoencoder, which is designed to learn the intramodal correlation of the data, while the common layer merges the superordinate features."}, {"heading": "A. Unimodal data pre-training", "text": "SAE is applied separately for each modality, we use the sigmoid activation function and the square euclidean distance as a loss function regulated by a weight disintegration concept. We also use the bound weight configuration. The output of the Ith layer is as follows: z1 = sigmoid (W1x1 + b1) i = 1 zi = sigmoid (Wixi + bi) i = 2.. N (4) The SAE approach is trained with the greedy, layered training approach, where we feed the latent representation of the auto encoder underneath to the current layer. This deep architecture makes the system more scalable and efficient, while gradually extracting higher features from the high-dimensional data."}, {"heading": "B. Deep multimodal learning", "text": "The single modal pre-training does not include an intermodality correlation, which can contribute to a better representation of the superordinate characteristics. In particular, it enables the encoding of the multiple modalities in a single common representation achieved by the common layer. Output of this layer includes the contribution of each modality in the code representing the compressed data. Common representation results as follows: z = \u2211 i, m} sigmoid (W iN + 1z i N + 1 + b i N + 1) (5) Where e and m refer respectively to EEG and EMG, we train the multimodal auto-encoder with extended, noisy data, where additional examples are added leading to samples with only one modality. In practice, we add zero values examples of one modality, while maintaining the original values for the other modality and vice versa. Thus, one third of the training data is EEG, another third is EMG, and the rest has both EEG and EMG data, which is then inspired by the individual modality strategy."}, {"heading": "C. Fine-tuning", "text": "The compressed data can be used for classification tasks, i.e. to refine the layers in relation to a monitored criterion by connecting the bottleneck layer to a Softmax classifier [23]: p = exp (Wy + b) \u2211 Ll = 1 exp (W ly + bl) (6) Where p is the predicted object name, y represents the compressed data and L the number of classification names. Therefore, the overall objective function to be minimized is: = (x, r, p, p) = J\u0443 (x, r) + L (p, p) (7) Where p is the true label and L (p, p) can be an entropic loss function."}, {"heading": "IV. EXPERIMENTAL RESULTS", "text": "mHealth systems collect, process, store, secure and transport medical data, and the data transmission should be as efficient and optimized as possible in terms of energy consumption and bandwidth usage.A typical system consists of a portable mHealth device that detects vital signals, collected from a PDA and sent to a remote server managed by a medical unit [24]. At the server level, a multimodal autocoder is already in place and the optimal configuration has already been found. This configuration is also known to the PDA, which should apply it to the collected data for compression.In this section, we present several experimental results comparing our compression scheme with some modern compression methods.In addition, we compare our multimodal strategy with the unimodal strategy to highlight the importance of using intermodality correlation."}, {"heading": "A. Dataset", "text": "We conduct our experiments with the DEAP dataset [25]. It consists of EEG, EMG and multiple physiological signals recorded by 32 participants during 63 seconds at 128 Hz. In the experiments, volunteers watched 40 music videos and rated them on a scale of 1 to 9 based on four criteria: similarity (dislike, like), valence (ranging from unpleasant to pleasant), arousal (ranging from uninterested or bored to aroused) and dominance (ranging from helpless and weak feelings to empowered feelings). The signals are segmented into 6-second segments, softened and normalized between 0 and 1. For both EEEEG and EMG data, we have 23040 samples with 896 dimensions. These data should then be divided into training and test sets."}, {"heading": "B. Compression tasks", "text": "We compare our compression method with the discretion Wavelet Transform (DWT) [26], Compressed Sensing (CS) [27] and the 2D compression approach based on SPIHT and FastICA [28]. For the latter algorithm, we use two configurations of 3 and 6 independent components called 2D SPIHT ICs and 2D SPIHT ICs."}, {"heading": "C. Classification task", "text": "The aim of this experiment is to demonstrate the importance of the multimodal approach. We perform a binary classification of the EEG and EMG in relation to two of the four labelling possibilities: dominance and excitation. We follow the same approach as in [25]: video ratings are divided into two classes. On the scale of 1 to 9, we simply place the threshold in the middle. We compare our approach with two-layer SAE and Deep Boltzmann Machine (DBM) architectures [15] with the Softmax classifier above it. For SAE, we use the sigmoid activation function. We select 75% training testing partition. Figures 8 and 9 illustrate the classification results in terms of dominance and excitation. By exploiting the intermodality correlation, the proposed approach achieves the best results with 78.1%. The single modality approaches are less precise. These results confirm that if several modalities are available, they can provide a better understanding of the underlying characteristics even if different."}, {"heading": "D. Discussion", "text": "In a typical mHealth system, a client-server architecture is the usual choice, where the system relies on the available networks to deliver the data. Generally, the healthcare provider relies on multiple vital signs for accurate diagnosis. The proposed approach is flexible in that an additional modality captured by the PDA via a portable device can be easily compressed and classified into the architecture shown in Figure 3. Deep neural networks can be trained offline. Once it achieves good performance, the customer side applies the optimal configuration (weights and distortions) for efficient data delivery."}, {"heading": "V. CONCLUSION", "text": "Our strategy focuses on the use of inter- and intracorrelation between several modalities to improve the compression and classification of data in the context of the mHealth application. The core of the proposed method is based on the classic autoencoder, originally designed for data encoding. For each modality presented, we dedicate a stacked autoencoder to extract high-grade abstraction of data by modelling the intracorrelation. A common layer is added to each part of the stacked autoencoder to model data intercorrelation. We have conducted compression and classification experiments, and the comparison with DWT and CS has shown that our approach works better at high compression rates. We have also demonstrated the effectiveness of the multimodal approach to classifying EEEEG and EMG."}, {"heading": "ACKNOWLEDGMENT", "text": "This publication was made possible by NPRP grant no. 7-684-1-127 of the Qatar National Research Fund (a member of the Qatar Foundation)."}], "references": [{"title": "A two-dimensional approach for lossless eeg compression", "author": ["K. Srinivasan", "J. Dauwels", "M.R. Reddy"], "venue": "Biomedical Signal Processing and Control, 2011.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2011}, {"title": "A new, fast, and efficient image codec based on set partitioning in hierarchical trees", "author": ["A. Said", "W.A. Pearlman"], "venue": "IEEE Transactions on Circuits and Systems for Video Technology, 1996.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1996}, {"title": "Scalable real-time energy-efficient eeg compression scheme for wireless body area sensor network", "author": ["R. Hussein", "A. Mohamed", "M. Alghoniemy"], "venue": "Biomedical Signal Processing and Control, 2015.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "Row-sparse blind compressed sensing for reconstructing multi-channel eeg signals", "author": ["A. Shukla", "A. Majumdar"], "venue": "Biomedical Signal Processing and Control, 2015.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2015}, {"title": "Bregman iterative algorithms for L1-minimization with applications to compressed sensing", "author": ["W. Yin", "S. Osher", "D. Goldfarb", "J. Darbon"], "venue": "SIAM Journal on Imaging Sciences, 2008.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2008}, {"title": "A low-rank matrix recovery approach for energy efficient eeg acquisition for a wireless body area network", "author": ["A. Majumdar", "A. Gogna", "R. Ward"], "venue": "Sensors, 2014.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Examining associations between fmri and eeg data using correlation analysis", "author": ["N. Correa", "Y.-O. Li", "T. Adali", "V.D. Calhoun"], "venue": "In proceeding of 5th IEEE international symposium on biomedical imaging: From nano to macro,, 2008.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2008}, {"title": "Multimodal deep learning", "author": ["J. Ngiam", "A. Khosla", "M. Kim", "J. Nam", "H. Lee", "A.Y. Ng"], "venue": "Proceedings of the 28th International Conference on Machine Learning, 2011.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2011}, {"title": "Learning representations for multimodal data with deep belief nets", "author": ["N. Srivastava", "R. Salakhutdinov"], "venue": "Proceedings of the 29th International Conference on Machine Learning, 2012.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2012}, {"title": "Deep belief networks. [Online]. Available: www. scholarpedia.org/article/Deep belief networks", "author": ["G.E. Hinton"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2009}, {"title": "Multimodal learning with deep boltzmann machines", "author": ["N. Srivastava", "R. Salakhutdinov"], "venue": "Advances in neural information processing systems, 2012.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2012}, {"title": "Deep boltzman machines", "author": ["R. Salakhutdinov", "G.E. Hinton"], "venue": "In Proceedings of the International Conference on Artificial Intelligence and Statistics, 2009.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2009}, {"title": "Multimodal video classification with stacked contractive autoencoders", "author": ["Y. Liu", "X. Feng", "Z. Zhou"], "venue": "Signal Processing, 2016.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2016}, {"title": "Reducing the dimensionality ofdata with neural networks", "author": ["G.E. Hinton", "R. Salakhutdinov"], "venue": "Science, 2006.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2006}, {"title": "Auto-encoders: reconstruction versus compression", "author": ["Y. Ollivier"], "venue": "2014, working paper or preprint. [Online]. Available: https://hal. archives-ouvertes.fr/hal-01104268", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2014}, {"title": "Using autoencoders for mammogram compression", "author": ["C.C. Tan", "C. Eswaran"], "venue": "Journal of Medical Systems, 2011.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2011}, {"title": "Lightweight lossy compression of biometric patterns via denoising autoencoders", "author": ["D.D. Testa", "M. Rossi"], "venue": "IEEE Signal Processing Letters, vol. 22, pp. 2304\u20132308, 2015.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2015}, {"title": "Greedy layerwise training of deep networks", "author": ["Y. Bengio", "P. Lamblin", "D. Popovici", "H. Larochelle"], "venue": "Inproceedings of Advances in Neural Information Processing Systems, 2006.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2006}, {"title": "Extracting and composing robust features with denoising autoencoders", "author": ["P. Vincent", "H. Larochelle", "Y. Bengio", "P.-A. Manzagol"], "venue": "International Conference on Machine Learning, 2008.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2008}, {"title": "Learning deep architectures for AI", "author": ["Y. Bengio"], "venue": "Foundations and Trends in Machine Learning, vol. 2, pp. 1\u2013127, 2009.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2009}, {"title": "User-centric network selection in multi-rat systems", "author": ["A. Awad", "A. Mohamed", "C.-F. Chiasserini"], "venue": "2016 IEEE Wireless Communications and Networking Conference Workshops (WCNCW), April 2016, pp. 97\u2013 102.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2016}, {"title": "Deap: A database for emotion analysis ;using physiological signals", "author": ["S. Koelstra", "C. Muhl", "M. Soleymani", "J.-S. Lee", "A. Yazdani", "T. Ebrahimi", "T. Pun", "A. Nijholt", "I. Patras"], "venue": "IEEE Transactions on Affective Computing, vol. 3, pp. 18\u201331, 2012.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2012}, {"title": "Compressed sensing", "author": ["D.L. Donoho"], "venue": "IEEE Transactions on Information Theory, vol. 52, no. 4, pp. 1289\u20131306, 2006.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2006}, {"title": "Independent component analysis: algorithms and applications", "author": ["A. Hyvarinen", "E. Oja"], "venue": "Neural Networks, vol. 13, no. 45, pp. 411\u2013430, 2000.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2000}], "referenceMentions": [{"referenceID": 0, "context": "[4] designed a 2-D lossless EEG compression where the signal is arranged in 2-D matrix as a preprocessing.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "Compression is achieved through a two-stage coder composed of Set Partitioning In Hierarchical Trees (SPIHT) [5] layer and Arithmetic Coding (RC) layer.", "startOffset": 109, "endOffset": 112}, {"referenceID": 2, "context": "[6] proposed a scalable and energy efficient EEG compression scheme based on Discret Wavelet Transform (DWT) and Compressive Sensing (CS) in wireless sensors.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "In [7], authors applied CS technique for EEG signal compression.", "startOffset": 3, "endOffset": 6}, {"referenceID": 4, "context": "Thus, the recovery problem becomes row-sparse and solved through Bregman algorithm [8].", "startOffset": 83, "endOffset": 86}, {"referenceID": 5, "context": "[9] argued that CS is not efficient for EEG compression because there is no sparsifying basis that fulfills the requirements of incoherence and sparsity.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[10].", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "[11] proposed a multimodal deep ar X iv :1 70 3.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "[12] built a multimodal deep belief network [13] to learn multimodal representation from image and text data for image annotation and retrieval tasks.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "[12] built a multimodal deep belief network [13] to learn multimodal representation from image and text data for image annotation and retrieval tasks.", "startOffset": 44, "endOffset": 48}, {"referenceID": 10, "context": "In [14], authors designed a deep Boltzmann machine [15] based architecture to extract a meaningful representation from multimodal data for classification and information re-", "startOffset": 3, "endOffset": 7}, {"referenceID": 11, "context": "In [14], authors designed a deep Boltzmann machine [15] based architecture to extract a meaningful representation from multimodal data for classification and information re-", "startOffset": 51, "endOffset": 55}, {"referenceID": 12, "context": "[16] proposed a multimodal autoencoder [17] approach for video classification based on audio, image and text data where the intra-modality semantic for each data is separately learning by a stacked autoencoder.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[16] proposed a multimodal autoencoder [17] approach for video classification based on audio, image and text data where the intra-modality semantic for each data is separately learning by a stacked autoencoder.", "startOffset": 39, "endOffset": 43}, {"referenceID": 14, "context": "In [18], Yann Ollivier proved that there is a strong relationship between minimizing the code length of the data and minimizing reconstruction error that an autoencoder seeks.", "startOffset": 3, "endOffset": 7}, {"referenceID": 15, "context": "[19] used a stacked autoencoder for mammogram image compression.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "In [20], authors applied the autoencoder for Electrocardiogram (ECG) compression.", "startOffset": 3, "endOffset": 7}, {"referenceID": 17, "context": "SAE is trained via a greedy layer-wise training [21].", "startOffset": 48, "endOffset": 52}, {"referenceID": 7, "context": "This strategy, inspired from Nigiam et al [11], follows the denoising autoencoder paradigm [22] and is justified by twofold:", "startOffset": 42, "endOffset": 46}, {"referenceID": 18, "context": "This strategy, inspired from Nigiam et al [11], follows the denoising autoencoder paradigm [22] and is justified by twofold:", "startOffset": 91, "endOffset": 95}, {"referenceID": 19, "context": "The compressed data can be used for classification task, that is, to fine-tune the layers with respect to a supervised criterion by plugging the bottleneck layer to a softmax classifier [23]:", "startOffset": 186, "endOffset": 190}, {"referenceID": 20, "context": "These data are collected by a PDA and should be transmitted to a remote server handled by a medical entity [24].", "startOffset": 107, "endOffset": 111}, {"referenceID": 21, "context": "We conduct our experiments on the DEAP dataset [25].", "startOffset": 47, "endOffset": 51}, {"referenceID": 22, "context": "We compare our compression method with the Discrete Wavelet Transform (DWT) [26], Compressed Sensing (CS) [27] and the 2D compression approach which is based on SPIHT and FastICA [28].", "startOffset": 106, "endOffset": 110}, {"referenceID": 23, "context": "We compare our compression method with the Discrete Wavelet Transform (DWT) [26], Compressed Sensing (CS) [27] and the 2D compression approach which is based on SPIHT and FastICA [28].", "startOffset": 179, "endOffset": 183}, {"referenceID": 21, "context": "We follow the same approach as in [25]: video ratings are thresholded", "startOffset": 34, "endOffset": 38}, {"referenceID": 11, "context": "We compare our approach with twolayer SAE and Deep Boltzmann Machine (DBM) architectures [15] with the softmax classifier on top of them.", "startOffset": 89, "endOffset": 93}], "year": 2017, "abstractText": "In this paper, we present a joint compression and classification approach of EEG and EMG signals using a deep learning approach. Specifically, we build our system based on the deep autoencoder architecture which is designed not only to extract discriminant features in the multimodal data representation but also to reconstruct the data from the latent representation using encoder-decoder layers. Since autoencoder can be seen as a compression approach, we extend it to handle multimodal data at the encoder layer, reconstructed and retrieved at the decoder layer. We show through experimental results, that exploiting both multimodal data intercorellation and intracorellation 1) Significantly reduces signal distortion particularly for high compression levels 2) Achieves better accuracy in classifying EEG and EMG signals recorded and labeled according to the sentiments of the volunteer.", "creator": "LaTeX with hyperref package"}}}