{"id": "1703.09370", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Mar-2017", "title": "Ensembles of Deep LSTM Learners for Activity Recognition using Wearables", "abstract": "Recently, deep learning (DL) methods have been introduced very successfully into human activity recognition (HAR) scenarios in ubiquitous and wearable computing. Especially the prospect of overcoming the need for manual feature design combined with superior classification capabilities render deep neural networks very attractive for real-life HAR application. Even though DL-based approaches now outperform the state-of-the-art in a number of recognitions tasks of the field, yet substantial challenges remain. Most prominently, issues with real-life datasets, typically including imbalanced datasets and problematic data quality, still limit the effectiveness of activity recognition using wearables. In this paper we tackle such challenges through Ensembles of deep Long Short Term Memory (LSTM) networks. We have developed modified training procedures for LSTM networks and combine sets of diverse LSTM learners into classifier collectives. We demonstrate, both formally and empirically, that Ensembles of deep LSTM learners outperform the individual LSTM networks. Through an extensive experimental evaluation on three standard benchmarks (Opportunity, PAMAP2, Skoda) we demonstrate the excellent recognition capabilities of our approach and its potential for real-life applications of human activity recognition.", "histories": [["v1", "Tue, 28 Mar 2017 02:00:47 GMT  (2656kb,D)", "http://arxiv.org/abs/1703.09370v1", "accepted for publication in ACM IMWUT (Ubicomp) 2017"]], "COMMENTS": "accepted for publication in ACM IMWUT (Ubicomp) 2017", "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.CV", "authors": ["yu guan", "thomas ploetz"], "accepted": false, "id": "1703.09370"}, "pdf": {"name": "1703.09370.pdf", "metadata": {"source": "CRF", "title": "Ensembles of Deep LSTM Learners for Activity Recognition using Wearables", "authors": ["Yu Guan", "Thomas Pl\u00f6tz"], "emails": ["yu.guan@newcastle.ac.uk;", "thomas.ploetz@gatech.edu"], "sections": [{"heading": null, "text": "Ensembles of the Deep LSTM Learners for Activity Recognition using Wearables Yu Guan, Open Lab, Newcastle upon Tyne, UK Thomas Ploetz, School of Interactive Computing, Georgia Institute of Technology, Atlanta, USARecently, deep learning (DL) methods have been very successfully introduced into the recognition of human activity (HAR) scenarios in ubiquitous and wearable computing. In particular, the prospect of overcoming the need for manual feature design combined with superior classification capabilities make deep neural networks very attractive for real HAR applications. Although DL-based approaches now surpass the state of the art in a number of recognition tasks, significant challenges remain."}, {"heading": "1. INTRODUCTION", "text": "In fact, most of them are able to survive on their own and on their own."}, {"heading": "2. BACKGROUND", "text": "We strive to develop methods for robust detection of human activity (HAR) using ubiquitous and portable sensor modalities. Most prominently, but without limiting ourselves, we aim at inertial measurement units (IMUs). HAR has a long history in the ubiquitous and portable computing community. Over the years, a variety of methods have been developed that enable an amazing variety of applications. HAR has become one of the pillars of the third generation of computation of ACM Journal Name, Vol. 0, No. 0, Article 0, Release Date: 2017. [Schmidt et al. 1999] and it is more than likely that future developments will depend on robust and reliable activity detection also from sensor data [Abowd 2016]. In order to achieve precision, we refrain from repetition of summaries of the general state of the art in activity detection. We argue that HAR can now surely be regarded as generally known and therefore refer to forward-looking documents such as 2012 bulletin papers et."}, {"heading": "2.1 Deep Learning for Human Activity Recognition", "text": "Consistent with their massive success and popularity in many application areas, deep learning processes [LeCun et al] seem to be successful. 2015 is also about revolutionizing the methods of detecting human activity in the field of ubiquitous and portable computing systems. The attraction of deep learning processes stems not only from the fact that the complex models with large capacities come in terms of classification tasks, but also from significantly reducing the need for feature engineering, since they are used very effectively, rich representations of input data. Early deeper learning applications in ubiquitous and wearable computing processes are primarily a challenge for the aspect of representation. In [Ploetz et al.] deep faith in networks, especially generative Restricted Boltzmann Machines (RBMs) have been used for feature learning. The following work has examined the effectiveness of pre-trained, fully networked RBM networks, for example for automated assessments of disease conditions in Hammermann's patients [in combination with traditional RBM networks]."}, {"heading": "2.2 Ensembles of Classifiers", "text": "The majority of overall learning outcomes are geared towards the development of effective classification methods that can be applied at various levels."}, {"heading": "3. ENSEMBLES OF DEEP LSTM LEARNERS FOR ACTIVITY RECOGNITION", "text": "In fact, most of us are able to play by the rules that they have imposed on themselves, and they are able to play by the rules that they have imposed on themselves, \"he told the Deutsche Presse-Agentur.\" We have to play by the rules, \"he said.\" We have to play by the rules that we have imposed on ourselves, \"he said.\" We have to play by the rules. \""}, {"heading": "3.1 Motivation for Fusing LSTM Learners", "text": "This year it has come to the point where it will be able to put itself at the top, \"he said.\" We have to put ourselves at the top, \"he said.\" We have to put ourselves at the top, \"he said.\" We have to put ourselves at the top, \"he said.\" We have to put ourselves at the top. \""}, {"heading": "3.2 Modified Training for LSTM Models", "text": "It is not only the way in which we move, but also the way in which we behave. (...) It is also the way in which we behave. \"(S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S."}, {"heading": "3.3 Combining Multiple LSTMs into HAR Ensembles", "text": "In this context, it should be noted that this is not a purely formal decision, but a purely formal decision, which depends primarily on the interests of the individual."}, {"heading": "4. EXPERIMENTAL EVALUATION", "text": "To confirm the effectiveness of our HAR framework, we conducted an experimental evaluation using detection experiments on three benchmark data sets, which are standard in the ACM Journal Name, Vol. 0, No. 0, Article 0, Release Date: 2017 and are therefore widely used in the literature. In the following, we will first describe our training and evaluation methodology, followed by a summary of the details of the data sets used for the evaluation study, and finally present and discuss our results."}, {"heading": "4.1 Model Training, and Evaluation Protocol", "text": "All experiments were conducted within the framework we have introduced in this paper. As such, we share a set of common parameters described in the following areas, each covering general model configurations, and the way we present the results of tests and evaluation methods as described below. Data of specific modifications - if any - are discussed in the subsections of the dataset description. Apart from possible substanstamping and modality tests, sensor data is used \"as is,\" that is, without the use of methods to analyze human activity, it will be based on heuristics. 2010; Bulling et al. 2014] or on more sophisticated transformations [Hammerla et al. 2013], which are consistent with the majority of recent deep learning-based methods in the field of human activity recognition. 4.1.1 Model configuration for all experiments using our LSTM learners, i.e."}, {"heading": "4.2 Datasets", "text": "This year it is more than ever before in the history of the city."}, {"heading": "4.3 Results", "text": "This year it has come to the point that it has never come as far as this year."}, {"heading": "5. DISCUSSION", "text": "This year it is more than ever before in the history of the city."}, {"heading": "A. REDUCING LOSS IN LSTM ENSEMBLES", "text": "We have integrated a number of LSTM models as basic learners into an ensemble system in which we have predicted the probability of classification into a class. (D) We have shown how this approach leads to significantly improved robustness and thus to improved classification performance. (D) We have an exemplary and more formal prediction of why LSTM learners lead to improved classification performance. (D) We have a sequential model in which LSTM shows a current signal but no loss of generality. (D) Based on the example of the reduction of entropy losses (relative to CE), we argue that the most popular loss functions in the field are likely. (D) corresponds to the negative logarithmic loss of the predicted probability for the target class k and thus explicitly to the predicted class."}, {"heading": "Acknowledgements", "text": "We would like to thank the School of Computing Science at Newcastle University for providing the computing capacity (GPU NVIDIA Tesla K40) and the anonymous reviewers for their constructive comments, which have contributed to improving the manuscript of this work."}], "references": [{"title": "Beyond Weiser \u2013 From Ubiquitous to Collective Computing", "author": ["Gregory D Abowd."], "venue": "IEEE Computer 49, 1 (2016), 17\u201323. M A Alsheikh, A Selim, D Niyato, L Doyle, S Lin, and et al. 2016. Deep Activity Recognition Models with Triaxial Accelerometers.", "citeRegEx": "Abowd.,? 2016", "shortCiteRegEx": "Abowd.", "year": 2016}, {"title": "Activity Recognition Using Inertial Sensing for Healthcare, Wellbeing and Sports Applications: A Survey", "author": ["Akin Avci", "Stephan Bosch", "Mihai Marin-Perianu", "Raluca Marin-Perianu", "Paul Havinga."], "venue": "Proc. ARCS.", "citeRegEx": "Avci et al\\.,? 2010a", "shortCiteRegEx": "Avci et al\\.", "year": 2010}, {"title": "Activity Recognition Using Inertial Sensing for Healthcare, Wellbeing and Sports Applications: A Survey", "author": ["Akin Avci", "Stephan Bosch", "Mihai Marin-Perianu", "Raluca Marin-Perianu", "Paul Havinga."], "venue": "Proc. Int. Conf. Architecture of Compu. Systems.", "citeRegEx": "Avci et al\\.,? 2010b", "shortCiteRegEx": "Avci et al\\.", "year": 2010}, {"title": "Wearable assistant for Parkinson\u2019s disease patients with the freezing of gait symptom", "author": ["Marc Bachlin", "Meir Plotnik", "Daniel Roggen", "Inbal Maidan", "Jeffrey M Hausdorff", "Nir Giladi", "Gerhard Troster."], "venue": "IEEE Transactions on Information Technology in Biomedicine 14, 2 (2010), 436\u2013446.", "citeRegEx": "Bachlin et al\\.,? 2010", "shortCiteRegEx": "Bachlin et al\\.", "year": 2010}, {"title": "Sparsification and Separation of Deep Learning Layers for Constrained Resource Inference on Wearables", "author": ["S Bhattacharya", "N D Lane."], "venue": "Proc. SenSys.", "citeRegEx": "Bhattacharya and Lane.,? 2016", "shortCiteRegEx": "Bhattacharya and Lane.", "year": 2016}, {"title": "Large-Scale Machine Learning with Stochastic Gradient Descent", "author": ["L\u00e9on Bottou."], "venue": "Prco. COMPSTAT.", "citeRegEx": "Bottou.,? 2010", "shortCiteRegEx": "Bottou.", "year": 2010}, {"title": "Bagging predictors", "author": ["Leo Breiman."], "venue": "Machine Learning 24 (1996), 123\u2013140.", "citeRegEx": "Breiman.,? 1996", "shortCiteRegEx": "Breiman.", "year": 1996}, {"title": "Random Forests", "author": ["Leo Breiman."], "venue": "Mach. Learn. (2001), 5\u201332.", "citeRegEx": "Breiman.,? 2001", "shortCiteRegEx": "Breiman.", "year": 2001}, {"title": "Bagging, Boosting and Ensemble Methods", "author": ["Peter B\u00fchlmann."], "venue": "Springer Berlin Heidelberg, 985\u20131022.", "citeRegEx": "B\u00fchlmann.,? 2012", "shortCiteRegEx": "B\u00fchlmann.", "year": 2012}, {"title": "A tutorial on human activity recognition using body-worn inertial sensors", "author": ["Andreas Bulling", "Ulf Blanke", "Bernt Schiele."], "venue": "Comput. Surveys 46, 3 (Jan. 2014), 1\u201333.", "citeRegEx": "Bulling et al\\.,? 2014", "shortCiteRegEx": "Bulling et al\\.", "year": 2014}, {"title": "The Opportunity challenge: A benchmark database for on-body sensor-based activity recognition", "author": ["Ricardo Chavarriaga", "Hesam Sagha", "Alberto Calatroni", "Sundara Tejaswi Digumarti", "Gerhard Tr\u00f6ster", "Jos\u00e9 Del R Mill\u00e1n", "Daniel Roggen."], "venue": "Pattern Recognition Letters 34, 15 (Nov. 2013), 2033\u20132042.", "citeRegEx": "Chavarriaga et al\\.,? 2013", "shortCiteRegEx": "Chavarriaga et al\\.", "year": 2013}, {"title": "Sensor-Based Activity Recognition", "author": ["L Chen", "J Hoey", "C D Nugent", "D J Cook", "Z Yu."], "venue": "IEEE Trans. on Systems, Man, and Cybernetics \u2013 Part C: Applications and Reviews 42, 6 (2012), 790\u2013808.", "citeRegEx": "Chen et al\\.,? 2012", "shortCiteRegEx": "Chen et al\\.", "year": 2012}, {"title": "Optimizing the F-Measure in Multi-Label Classification: Plug-in Rule Approach versus Structured Loss Minimization", "author": ["K Dembczynski", "A Jachnik", "W Kotlowski", "W Waegeman"], "venue": "In Proc. ICML", "citeRegEx": "Dembczynski et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Dembczynski et al\\.", "year": 2013}, {"title": "Ensemble deep learning for speech recognition", "author": ["L Deng", "J C Platt"], "venue": "In Proc. INTERSPEECH", "citeRegEx": "Deng and Platt.,? \\Q2014\\E", "shortCiteRegEx": "Deng and Platt.", "year": 2014}, {"title": "PD Disease State Assessment in Naturalistic Environments using Deep Learning", "author": ["Nils Hammerla", "James Fisher", "Peter Andras", "Lynn Rochester", "Richard Walker", "Thomas Ploetz."], "venue": "Proc. AAAI.", "citeRegEx": "Hammerla et al\\.,? 2015", "shortCiteRegEx": "Hammerla et al\\.", "year": 2015}, {"title": "Deep, Convolutional, and Recurrent Models for Human Activity Recognition using Wearables", "author": ["Nils Hammerla", "Shane Halloran", "Thomas Ploetz."], "venue": "Proc. IJCAI.", "citeRegEx": "Hammerla et al\\.,? 2016", "shortCiteRegEx": "Hammerla et al\\.", "year": 2016}, {"title": "On Preserving Statistical Characteristics of Accelerometry Data using their Empirical Cumulative Distribution", "author": ["Nils Hammerla", "Reuben Kirkham", "Peter Andras", "Thomas Ploetz."], "venue": "Proc. Int. Symp. Wearable Computing (ISWC).", "citeRegEx": "Hammerla et al\\.,? 2013", "shortCiteRegEx": "Hammerla et al\\.", "year": 2013}, {"title": "Let\u2019s (not) Stick Together: Pairwise Similarity Biases Cross-Validation in Activity Recognition", "author": ["Nils Y. Hammerla", "Thomas Ploetz."], "venue": "Proc. Int. Conf. Ubiquitous Comp. (Ubicomp).", "citeRegEx": "Hammerla and Ploetz.,? 2015", "shortCiteRegEx": "Hammerla and Ploetz.", "year": 2015}, {"title": "The Elements of Statistical Learning", "author": ["Trevor Hastie", "Robert Tibshirani", "Jerome Friedman."], "venue": "Springer.", "citeRegEx": "Hastie et al\\.,? 2009", "shortCiteRegEx": "Hastie et al\\.", "year": 2009}, {"title": "Long Short-Term Memory", "author": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber."], "venue": "Neural computation 9, 8 (Nov. 1997), 1735\u20131780.", "citeRegEx": "Hochreiter and Schmidhuber.,? 1997", "shortCiteRegEx": "Hochreiter and Schmidhuber.", "year": 1997}, {"title": "Rapid specification and automated generation of prompting systems to assist people with dementia", "author": ["Jesse Hoey", "Thomas Ploetz", "Dan Jackson", "Andrew Monk", "Cuong Pham", "Patrick Olivier."], "venue": "Pervasive and Mobile Computing (PMC) 7, 3 (2011), 299\u2013318.", "citeRegEx": "Hoey et al\\.,? 2011", "shortCiteRegEx": "Hoey et al\\.", "year": 2011}, {"title": "Maximum Expected F-measure Training of Logistic Regression Models", "author": ["Martin Jansche."], "venue": "Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing.", "citeRegEx": "Jansche.,? 2005", "shortCiteRegEx": "Jansche.", "year": 2005}, {"title": "Beyond Activity Recognition: Skill Assessment from Accelerometer Data", "author": ["Aftab Khan", "Sebastian Mellor", "Eugen Berlin", "Robin Thompson", "Roisin McNaney", "Patrick Olivier", "Thomas Ploetz."], "venue": "Proc. Ubicomp.", "citeRegEx": "Khan et al\\.,? 2015", "shortCiteRegEx": "Khan et al\\.", "year": 2015}, {"title": "Digits: freehand 3D interactions anywhere using a wrist-worn gloveless sensor", "author": ["David Kim", "Otmar Hilliges", "Shahram Izadi", "Alex D Butler", "Jiawen Chen", "Iason Oikonomidis", "Patrick Olivier."], "venue": "Proc. UIST.", "citeRegEx": "Kim et al\\.,? 2012", "shortCiteRegEx": "Kim et al\\.", "year": 2012}, {"title": "Constructing support vector machine ensemble", "author": ["Hyun-Chul Kim", "Shaoning Pang", "Hong-Mo Je", "Daijin Kim", "Sung Yang Bang."], "venue": "Pattern Recognition 36, 12 (Dec. 2003), 2757\u20132767.", "citeRegEx": "Kim et al\\.,? 2003", "shortCiteRegEx": "Kim et al\\.", "year": 2003}, {"title": "Adam: A method for stochastic optimization", "author": ["D Kingma", "J Ba."], "venue": "Proc. ICLR.", "citeRegEx": "Kingma and Ba.,? 2014", "shortCiteRegEx": "Kingma and Ba.", "year": 2014}, {"title": "On Combining Classifiers", "author": ["Josef Kittler", "Mohamad Hatef", "Robert P W Duin", "Jiri Matas."], "venue": "IEEE Trans. Pattern Analysis and Machine Intelligence (TPAMI) 20, 3 (1998), 226\u2013239.", "citeRegEx": "Kittler et al\\.,? 1998", "shortCiteRegEx": "Kittler et al\\.", "year": 1998}, {"title": "The mobile fitness coach: Towards individualized skill assessment using personalized mobile devices", "author": ["Matthias Kranz", "Andreas Moeller", "Nils Hammerla", "Stefan Diewald", "Luis Roalter", "Thomas Ploetz", "Patrick Olivier."], "venue": "Pervasive and Mobile Computing (PMC) (2012).", "citeRegEx": "Kranz et al\\.,? 2012", "shortCiteRegEx": "Kranz et al\\.", "year": 2012}, {"title": "Combining pattern classifiers: methods and algorithms", "author": ["Ludmila Kuncheva."], "venue": "John Wiley & Sons.", "citeRegEx": "Kuncheva.,? 2004", "shortCiteRegEx": "Kuncheva.", "year": 2004}, {"title": "ClimbAX: Skill Assessment for Climbing Enthusiasts", "author": ["Cassim Ladha", "Nils Hammerla", "Patrick Olivier", "Thomas Ploetz."], "venue": "Proc. Int. Conf. Ubiquitous Comp. (UbiComp).", "citeRegEx": "Ladha et al\\.,? 2013", "shortCiteRegEx": "Ladha et al\\.", "year": 2013}, {"title": "DeepEar: robust smartphone audio sensing in unconstrained acoustic environments using deep learning", "author": ["Nicholas D Lane", "Petko Georgiev", "Lorena Qendro."], "venue": "Proc. Ubicomp.", "citeRegEx": "Lane et al\\.,? 2015", "shortCiteRegEx": "Lane et al\\.", "year": 2015}, {"title": "Deep learning", "author": ["Yann LeCun", "Yoshua Bengio", "Geoffrey Hinton."], "venue": "Nature 521, 7553 (May 2015), 436\u2013444.", "citeRegEx": "LeCun et al\\.,? 2015", "shortCiteRegEx": "LeCun et al\\.", "year": 2015}, {"title": "Parallel distributed processing", "author": ["J L McClelland", "D E Rumelhart."], "venue": "MIT Press.", "citeRegEx": "McClelland and Rumelhart.,? 1986", "shortCiteRegEx": "McClelland and Rumelhart.", "year": 1986}, {"title": "Deep convolutional feature transfer across mobile activity recognition domains, sensor modalities and locations", "author": ["Francisco Javier Ord\u00f3\u00f1ez Morales", "Daniel Roggen."], "venue": "Proc. ISWC.", "citeRegEx": "Morales and Roggen.,? 2016", "shortCiteRegEx": "Morales and Roggen.", "year": 2016}, {"title": "Deep Convolutional and LSTM Recurrent Neural Networks for Multimodal Wearable Activity Recognition", "author": ["Francisco Ord\u00f3\u00f1ez", "Daniel Roggen."], "venue": "Sensors 16, 1 (Jan. 2016), 115.", "citeRegEx": "Ord\u00f3\u00f1ez and Roggen.,? 2016", "shortCiteRegEx": "Ord\u00f3\u00f1ez and Roggen.", "year": 2016}, {"title": "Feature Learning for Activity Recognition in Ubiquitous Computing", "author": ["Thomas Ploetz", "Nils Hammerla", "Patrick Olivier."], "venue": "Proc. IJCAI.", "citeRegEx": "Ploetz et al\\.,? 2011", "shortCiteRegEx": "Ploetz et al\\.", "year": 2011}, {"title": "Automatic Assessment of Problem Behavior in Individuals with Developmental Disabilities", "author": ["Thomas Ploetz", "Nils Hammerla", "Agata Rozga", "Andrea Reavis", "Nathan Call", "Gregory D Abowd."], "venue": "Proc. UbiComp (2012).", "citeRegEx": "Ploetz et al\\.,? 2012", "shortCiteRegEx": "Ploetz et al\\.", "year": 2012}, {"title": "Activity Recognition and Healthier Food Preparation", "author": ["T Ploetz", "P Moynihan", "Cuong Pham", "P Olivier."], "venue": "Activity Recognition in Pervasive Intelligent Environments (2010).", "citeRegEx": "Ploetz et al\\.,? 2010", "shortCiteRegEx": "Ploetz et al\\.", "year": 2010}, {"title": "When Ensemble Learning Meets Deep Learning: a New Deep Support Vector Machine for Classification", "author": ["Zhiquan Qi", "Bo Wang", "Yingjie Tian", "Peng Zhang."], "venue": "Knowledge-Based Systems 107 (Sept. 2016), 54\u201360.", "citeRegEx": "Qi et al\\.,? 2016", "shortCiteRegEx": "Qi et al\\.", "year": 2016}, {"title": "Convolutional Neural Network for Stereotypical Motor Movement Detection in Autism", "author": ["N M Rad", "A Bizzego", "S M Kia", "G Jurman"], "venue": null, "citeRegEx": "Rad et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Rad et al\\.", "year": 2015}, {"title": "Introducing a New Benchmarked Dataset for Activity Monitoring", "author": ["Attila Reiss", "Didier Stricker."], "venue": "Proc. ISWC.", "citeRegEx": "Reiss and Stricker.,? 2012", "shortCiteRegEx": "Reiss and Stricker.", "year": 2012}, {"title": "Evaluation of deep convolutional neural network architectures for human activity recognition with smartphone sensors", "author": ["C A Ronaoo", "S B Cho."], "venue": "Proc. KIISE Korea Computer Congress.", "citeRegEx": "Ronaoo and Cho.,? 2015", "shortCiteRegEx": "Ronaoo and Cho.", "year": 2015}, {"title": "The strength of weak learnability", "author": ["R E Schapire."], "venue": "Machine Learning (1990), 197\u2013227.", "citeRegEx": "Schapire.,? 1990", "shortCiteRegEx": "Schapire.", "year": 1990}, {"title": "There is more to Context than Location", "author": ["Albrecht Schmidt", "Michael Beigl", "Hans W Gellersen."], "venue": "Computer & Graphics 23, 6 (1999), 893\u2013901.", "citeRegEx": "Schmidt et al\\.,? 1999", "shortCiteRegEx": "Schmidt et al\\.", "year": 1999}, {"title": "Ensemble of Deep Long Short Term Memory Networks for Labelling Origin of Replication Sequences", "author": ["Urminder Singh", "Sucheta Chauhan", "A. Krishnamachari", "Lovekesh Vig."], "venue": "Proc. Int. Conf. Data Science and Advanced Analytics (DSAA).", "citeRegEx": "Singh et al\\.,? 2015", "shortCiteRegEx": "Singh et al\\.", "year": 2015}, {"title": "Diversity encouraged learning of unsupervised LSTM ensemble for neural activity video prediction", "author": ["Yilin Song", "Jonathan Viventi", "Yao Wang."], "venue": "arXiv preprint 1611.04899v (cs.CV) (2016).", "citeRegEx": "Song et al\\.,? 2016", "shortCiteRegEx": "Song et al\\.", "year": 2016}, {"title": "The Cauchy-Schwarz Master Class: An Introduction to the Art of Mathematical Inequalities", "author": ["J. Michael Steele."], "venue": "Cambridge University Press, New York, NY, USA.", "citeRegEx": "Steele.,? 2004", "shortCiteRegEx": "Steele.", "year": 2004}, {"title": "Wearable activity tracking in car manufacturing", "author": ["Thomas Stiefmeier", "Daniel Roggen", "Gerhard Tr\u00f6ster", "Georg Ogris", "Paul Lukowicz."], "venue": "IEEE Pervasive Computing 7, 2 (March 2008), 42\u201350.", "citeRegEx": "Stiefmeier et al\\.,? 2008", "shortCiteRegEx": "Stiefmeier et al\\.", "year": 2008}, {"title": "Bias-Variance Analysis of Support Vector Machines for the Development of SVM-Based Ensemble Methods", "author": ["Giorgio Valentini", "Thomas G. Dietterich."], "venue": "J. Mach. Learn. Res. 5 (2004), 725\u2013775.", "citeRegEx": "Valentini and Dietterich.,? 2004", "shortCiteRegEx": "Valentini and Dietterich.", "year": 2004}, {"title": "The Computer for the 21st Century", "author": ["Mark Weiser."], "venue": "Scientific American (1991).", "citeRegEx": "Weiser.,? 1991", "shortCiteRegEx": "Weiser.", "year": 1991}, {"title": "Deep Convolutional Neural Networks on Multichannel Time Series for Human Activity Recognition", "author": ["Jianbo Yang", "Minh Nhut Nguyen", "Phyo Phyo San", "Xiaoli Li", "Shonali Krishnaswamy"], "venue": "In Proc. IJCAI", "citeRegEx": "Yang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Yang et al\\.", "year": 2015}, {"title": "Convolutional Neural Networks for Human Activity Recognition using Mobile Sensors", "author": ["Ming Zeng", "Le T Nguyen", "Bo Yu", "Ole J Mengshoel", "Joy Zhang."], "venue": "Proc. MobiCASE (2014).", "citeRegEx": "Zeng et al\\.,? 2014", "shortCiteRegEx": "Zeng et al\\.", "year": 2014}, {"title": "Human activity recognition with HMM-DNN model", "author": ["Licheng Zhang", "Xihong Wu", "Dingsheng Luo"], "venue": "In Proc. ICCI", "citeRegEx": "Zhang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2015}, {"title": "Ensembling neural networks: Many could be better than all", "author": ["Zhi-Hua Zhou", "Jianxin Wu", "Wei Tang."], "venue": "Artificial Intelligence 137, 1 (2002), 239 \u2013 263.", "citeRegEx": "Zhou et al\\.,? 2002", "shortCiteRegEx": "Zhou et al\\.", "year": 2002}], "referenceMentions": [{"referenceID": 23, "context": "Related work now covers an enormous variety of innovative sensing and analysis approaches that target a plethora of application areas, including but not limited to novel interaction techniques [Kim et al. 2012], situated support in smart environments [Hoey et al.", "startOffset": 193, "endOffset": 210}, {"referenceID": 20, "context": "2012], situated support in smart environments [Hoey et al. 2011], automated health [Ploetz et al.", "startOffset": 46, "endOffset": 64}, {"referenceID": 36, "context": "2011], automated health [Ploetz et al. 2012] and wellbeing assessments [Kranz et al.", "startOffset": 24, "endOffset": 44}, {"referenceID": 27, "context": "2012] and wellbeing assessments [Kranz et al. 2012], health care automation [Avci et al.", "startOffset": 32, "endOffset": 51}, {"referenceID": 1, "context": "2012], health care automation [Avci et al. 2010a], sports tracking and coaching [Ladha et al.", "startOffset": 30, "endOffset": 49}, {"referenceID": 29, "context": "2010a], sports tracking and coaching [Ladha et al. 2013] to name but a few.", "startOffset": 37, "endOffset": 56}, {"referenceID": 22, "context": ", [Khan et al. 2015]).", "startOffset": 2, "endOffset": 20}, {"referenceID": 35, "context": "Early feature learning methods in Ubicomp utilised restricted Boltzmann machines (RBM), that is, generative deep learners for deriving task agnostic feature representations [Ploetz et al. 2011; Hammerla et al. 2015].", "startOffset": 173, "endOffset": 215}, {"referenceID": 14, "context": "Early feature learning methods in Ubicomp utilised restricted Boltzmann machines (RBM), that is, generative deep learners for deriving task agnostic feature representations [Ploetz et al. 2011; Hammerla et al. 2015].", "startOffset": 173, "endOffset": 215}, {"referenceID": 9, "context": "A popular way of using deep learning methods for activity recognition purposes is by modifying the \u201dstandard\u201d processing workflow as it has been widely adopted by the community [Bulling et al. 2014].", "startOffset": 177, "endOffset": 198}, {"referenceID": 10, "context": "As it stands, deep learning based systems outperform alternatives on standard, challenging activity recognition benchmarks such as Opportunity [Chavarriaga et al. 2013].", "startOffset": 143, "endOffset": 168}, {"referenceID": 15, "context": ", [Ord\u00f3\u00f1ez and Roggen 2016; Hammerla et al. 2016].", "startOffset": 2, "endOffset": 49}, {"referenceID": 15, "context": "We substantially extend our previous work where we have alleviated the sliding window paradigm of sensor data processing [Hammerla et al. 2016].", "startOffset": 121, "endOffset": 143}, {"referenceID": 10, "context": "We evaluate our method on three standard benchmark datasets, namely the Opportunity challenge [Chavarriaga et al. 2013], PAMAP2 [Reiss and Stricker 2012], and the Skoda dataset [Stiefmeier et al.", "startOffset": 94, "endOffset": 119}, {"referenceID": 47, "context": "2013], PAMAP2 [Reiss and Stricker 2012], and the Skoda dataset [Stiefmeier et al. 2008].", "startOffset": 63, "endOffset": 87}, {"referenceID": 43, "context": "[Schmidt et al. 1999] and it is more than likely that future developments will depend on robust and reliable activity recognition from sensor data as well [Abowd 2016].", "startOffset": 0, "endOffset": 21}, {"referenceID": 9, "context": "We argue that HAR can now safely be considered common knowledge and thus refer to seminal papers and tutorials such as [Bulling et al. 2014; Chen et al. 2012; Avci et al. 2010b].", "startOffset": 119, "endOffset": 177}, {"referenceID": 11, "context": "We argue that HAR can now safely be considered common knowledge and thus refer to seminal papers and tutorials such as [Bulling et al. 2014; Chen et al. 2012; Avci et al. 2010b].", "startOffset": 119, "endOffset": 177}, {"referenceID": 2, "context": "We argue that HAR can now safely be considered common knowledge and thus refer to seminal papers and tutorials such as [Bulling et al. 2014; Chen et al. 2012; Avci et al. 2010b].", "startOffset": 119, "endOffset": 177}, {"referenceID": 31, "context": "1 Deep Learning for Human Activity Recognition In line with its massive success and popularity in many application domains, deep learning [LeCun et al. 2015] is also about to revolutionise human activity recognition methods in the field of ubiquitous and wearable computing.", "startOffset": 138, "endOffset": 157}, {"referenceID": 35, "context": "In [Ploetz et al. 2011] deep belief networks, specifically generative Restricted Boltzmann Machines (RBMs) were employed for feature learning.", "startOffset": 3, "endOffset": 23}, {"referenceID": 14, "context": "Based on this, subsequent works explored the effectiveness of pre-trained, fully-connected RBM networks, for example, for automated assessments of disease states in Parkinson\u2019s patients [Hammerla et al. 2015], in combination with more traditional sequence models (HMMs) [Zhang et al.", "startOffset": 186, "endOffset": 208}, {"referenceID": 52, "context": "2015], in combination with more traditional sequence models (HMMs) [Zhang et al. 2015; Alsheikh et al. 2016], and very successfully for auditory scene analysis in Ubicomp applications [Lane et al.", "startOffset": 67, "endOffset": 108}, {"referenceID": 30, "context": "2016], and very successfully for auditory scene analysis in Ubicomp applications [Lane et al. 2015].", "startOffset": 81, "endOffset": 99}, {"referenceID": 51, "context": "A multitude of applications are based on CNNs, including but not limited to [Zeng et al. 2014; Ronaoo and Cho 2015; Yang et al. 2015; Rad et al. 2015].", "startOffset": 76, "endOffset": 150}, {"referenceID": 50, "context": "A multitude of applications are based on CNNs, including but not limited to [Zeng et al. 2014; Ronaoo and Cho 2015; Yang et al. 2015; Rad et al. 2015].", "startOffset": 76, "endOffset": 150}, {"referenceID": 39, "context": "A multitude of applications are based on CNNs, including but not limited to [Zeng et al. 2014; Ronaoo and Cho 2015; Yang et al. 2015; Rad et al. 2015].", "startOffset": 76, "endOffset": 150}, {"referenceID": 9, "context": "The de-facto standard workflow for activity recognition in ubiquitous and wearable computing [Bulling et al. 2014] treats individual frames of sensor data as statistically independent, that is, isolated portions of data are converted into feature vectors that are then presented to a classifier without further temporal context.", "startOffset": 93, "endOffset": 114}, {"referenceID": 15, "context": "Through large scale experimentation in [Hammerla et al. 2016] appropriate training procedures have been analysed for a number of deep learning approaches to HAR including deep LSTM networks.", "startOffset": 39, "endOffset": 61}, {"referenceID": 15, "context": "In all of previous work, including our own [Hammerla et al. 2016], single LSTM models have been used and standard training procedures have been employed for parameter estimation.", "startOffset": 43, "endOffset": 65}, {"referenceID": 15, "context": "As such this paper is the first that pushes beyond optimisation of individual models (as demonstrated, for example, in the meta-study in [Hammerla et al. 2016]), which leads to significantly improved recognition performance and robustness.", "startOffset": 137, "endOffset": 159}, {"referenceID": 51, "context": "(a) [CNN for frame-based HAR (c/o [Zeng et al. 2014]).", "startOffset": 34, "endOffset": 52}, {"referenceID": 15, "context": "(b) Deep LSTM networks for HAR (c/o [Hammerla et al. 2016]).", "startOffset": 36, "endOffset": 58}, {"referenceID": 26, "context": "In addition to this, in recent years the combination of multiple learners into meta-classifiers has gained popularity as it has been shown that such classifier Ensembles can be very beneficial for the analysis of complex datasets [Kittler et al. 1998].", "startOffset": 230, "endOffset": 251}, {"referenceID": 24, "context": ", [Kim et al. 2003]).", "startOffset": 2, "endOffset": 19}, {"referenceID": 38, "context": "Examples of deep learning Ensembles include the combination of Support Vector Machines (SVM) into classifier Ensembles [Qi et al. 2016].", "startOffset": 119, "endOffset": 135}, {"referenceID": 15, "context": "Specifically we focus on LSTM networks as base learners given their superior performance in challenging HAR benchmarks [Ord\u00f3\u00f1ez and Roggen 2016; Hammerla et al. 2016].", "startOffset": 119, "endOffset": 166}, {"referenceID": 45, "context": "Most related to our work, [Song et al. 2016] have described a system that utilises Ensembles of LSTM learners for predicting actions from video data.", "startOffset": 26, "endOffset": 44}, {"referenceID": 44, "context": "For example, [Singh et al. 2015] employed three variants of LSTM networks (vanilla deep LSTM, and two variants of bi-directional LSTMs) in parallel for biological sequence analysis and then applied majority voting for final classification.", "startOffset": 13, "endOffset": 32}, {"referenceID": 26, "context": "Whilst this approach touches upon the general idea of classifier Ensembles [Kittler et al. 1998], it does so in a very constrained way, which leaves substantial room for improvement.", "startOffset": 75, "endOffset": 96}, {"referenceID": 15, "context": ", [Hammerla et al. 2016; Morales and Roggen 2016]) deep, recurrent neural networks, i.", "startOffset": 2, "endOffset": 49}, {"referenceID": 15, "context": ", [Ord\u00f3\u00f1ez and Roggen 2016; Hammerla et al. 2016]) we employ a specific variant, namely deep, recurrent networks based on Long Short Term Memory (LSTM) units [Hochreiter and Schmidhuber 1997].", "startOffset": 2, "endOffset": 49}, {"referenceID": 9, "context": "The majority of related work in HAR utilises (variants of) the well established sliding-window, frame-based analysis approach [Bulling et al. 2014].", "startOffset": 126, "endOffset": 147}, {"referenceID": 18, "context": "Real world recognition systems need to find a compromise / define a tradeoff between bias and variance, and the classifiers may suffer from under- (high bias) or overfitting (high variance) \u2013 depending on representativeness of training data and classifier complexity [Hastie et al. 2009].", "startOffset": 267, "endOffset": 287}, {"referenceID": 53, "context": "The most popular strong base learners include decision trees [Breiman 2001], neural networks [Zhou et al. 2002], or kernel methods [Valentini and Dietterich 2004], and the corresponding variances are significantly reduced through bagging, yielding improved generalisation capabilities.", "startOffset": 93, "endOffset": 111}, {"referenceID": 26, "context": ", [Kittler et al. 1998; Kuncheva 2004]).", "startOffset": 2, "endOffset": 38}, {"referenceID": 15, "context": "The method presented here extends our previous work [Hammerla et al. 2016].", "startOffset": 52, "endOffset": 74}, {"referenceID": 15, "context": "In order to construct diverse yet usable mini-batches for training models for time series analysis, in our previous work we have randomly chosen B different start positions {q 0}b=1 for generating B frames of contiguous portions of sensor data along the whole training sequence [Hammerla et al. 2016].", "startOffset": 278, "endOffset": 300}, {"referenceID": 15, "context": "(16) This procedure was originally referred to as \u201dwrapping around\u201d procedure [Hammerla et al. 2016].", "startOffset": 78, "endOffset": 100}, {"referenceID": 12, "context": "[Dembczynski et al. 2013] for a general introduction).", "startOffset": 0, "endOffset": 25}, {"referenceID": 26, "context": "Independent of the cause for diversity in base classifiers (in our case LSTMs) the meta-optimisation objective for classifier Ensembles is to generate classifiers that are diverse and minimally correlated [Kittler et al. 1998].", "startOffset": 205, "endOffset": 226}, {"referenceID": 37, "context": "Apart from potential subsampling and modality fusion, sensor data are used \u201das is\u201d that is without employing feature extraction methods be it based on heuristics [Ploetz et al. 2010; Bulling et al. 2014] or on more sophisticated transformations [Hammerla et al.", "startOffset": 162, "endOffset": 203}, {"referenceID": 9, "context": "Apart from potential subsampling and modality fusion, sensor data are used \u201das is\u201d that is without employing feature extraction methods be it based on heuristics [Ploetz et al. 2010; Bulling et al. 2014] or on more sophisticated transformations [Hammerla et al.", "startOffset": 162, "endOffset": 203}, {"referenceID": 16, "context": "2014] or on more sophisticated transformations [Hammerla et al. 2013], which is in line with the majority of recent, Deep Learning based analysis methods in the field of human activity recognition using wearable sensing platforms.", "startOffset": 47, "endOffset": 69}, {"referenceID": 15, "context": "Extending previous work where random starting points have been used for each epoch [Hammerla et al. 2016], during training we dynamically determined mini-batch size B\u0302 and frame lengths L\u0302 randomly within a given range (see Tab.", "startOffset": 83, "endOffset": 105}, {"referenceID": 15, "context": "Note that we report sample-wise prediction results, which is according to our overall motivation and in line with previous work [Hammerla et al. 2016] but different to frame-wise results as, for example, reported in [Ord\u00f3\u00f1ez and Roggen 2016].", "startOffset": 128, "endOffset": 150}, {"referenceID": 3, "context": ", [Bachlin et al. 2010]).", "startOffset": 2, "endOffset": 23}, {"referenceID": 36, "context": "Another related example from the literature is the automated assessment of problem behaviour in individuals with Autism, where aggressive behaviours do occur frequently yet they typically represent the minority of everyday activities thus resulting in imbalanced datasets [Ploetz et al. 2012].", "startOffset": 272, "endOffset": 292}, {"referenceID": 47, "context": "Finally, the Skoda dataset [Stiefmeier et al. 2008] shows a reasonably well balanced class distribution for the activities of interest (Fig.", "startOffset": 27, "endOffset": 51}, {"referenceID": 10, "context": "The Opportunity dataset is the result of a concerted effort towards collecting a benchmark dataset for human activity recognition using body-worn sensors [Chavarriaga et al. 2013].", "startOffset": 154, "endOffset": 179}, {"referenceID": 15, "context": "We replicate the training, validation, and test protocol from [Hammerla et al. 2016].", "startOffset": 62, "endOffset": 84}, {"referenceID": 15, "context": "Again replicating the protocol from [Hammerla et al. 2016], we used runs 1 and 2 for participant 5 for validation, and runs 1 and 2 from the sixth participant as test.", "startOffset": 36, "endOffset": 58}, {"referenceID": 47, "context": "Specifically, it covers the problem of recognising activities of assembly-line workers in a car production environment [Stiefmeier et al. 2008].", "startOffset": 119, "endOffset": 143}, {"referenceID": 26, "context": "By mixing learners that were trained with different loss functions we further increase the variability as it is of importance for any classifier Ensemble approach [Kittler et al. 1998].", "startOffset": 163, "endOffset": 184}, {"referenceID": 15, "context": "These reference experiments are based on implementations as described in the particular original papers thereby in part making use of the source code provided by the authors and replicating the model configurations used there [Hochreiter and Schmidhuber 1997; Hammerla et al. 2016; Ord\u00f3\u00f1ez and Roggen 2016].", "startOffset": 226, "endOffset": 306}, {"referenceID": 15, "context": "to [Hammerla et al. 2016]) 0.", "startOffset": 3, "endOffset": 25}], "year": 2017, "abstractText": "Recently, deep learning (DL) methods have been introduced very successfully into human activity recognition (HAR) scenarios in ubiquitous and wearable computing. Especially the prospect of overcoming the need for manual feature design combined with superior classification capabilities render deep neural networks very attractive for real-life HAR applications. Even though DL-based approaches now outperform the state-of-the-art in a number of recognition tasks, still substantial challenges remain. Most prominently, issues with real-life datasets, typically including imbalanced datasets and problematic data quality, still limit the effectiveness of activity recognition using wearables. In this paper we tackle such challenges through Ensembles of deep Long Short Term Memory (LSTM) networks. LSTM networks currently represent the state-of-the-art with superior classification performance on relevant HAR benchmark datasets. We have developed modified training procedures for LSTM networks and combine sets of diverse LSTM learners into classifier collectives. We demonstrate that Ensembles of deep LSTM learners outperform individual LSTM networks and thus push the state-of-the-art in human activity recognition using wearables. Through an extensive experimental evaluation on three standard benchmarks (Opportunity, PAMAP2, Skoda) we demonstrate the excellent recognition capabilities of our approach and its potential for real-life applications of human activity recognition.", "creator": "TeX"}}}