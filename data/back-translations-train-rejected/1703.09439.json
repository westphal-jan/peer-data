{"id": "1703.09439", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Mar-2017", "title": "A practical approach to dialogue response generation in closed domains", "abstract": "We describe a prototype dialogue response generation model for the customer service domain at Amazon. The model, which is trained in a weakly supervised fashion, measures the similarity between customer questions and agent answers using a dual encoder network, a Siamese-like neural network architecture. Answer templates are extracted from embeddings derived from past agent answers, without turn-by-turn annotations. Responses to customer inquiries are generated by selecting the best template from the final set of templates. We show that, in a closed domain like customer service, the selected templates cover $&gt;$70\\% of past customer inquiries. Furthermore, the relevance of the model-selected templates is significantly higher than templates selected by a standard tf-idf baseline.", "histories": [["v1", "Tue, 28 Mar 2017 07:47:27 GMT  (142kb,D)", "http://arxiv.org/abs/1703.09439v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.NE", "authors": ["yichao lu", "phillip keung", "shaonan zhang", "jason sun", "vikas bhardwaj"], "accepted": false, "id": "1703.09439"}, "pdf": {"name": "1703.09439.pdf", "metadata": {"source": "CRF", "title": "A practical approach to dialogue response generation in closed domains", "authors": ["Yichao Lu", "Phillip Keung", "Shaonan Zhang", "Jason Sun", "Vikas Bhardwaj"], "emails": ["yichaolu@amazon.com,", "keung@amazon.com"], "sections": [{"heading": null, "text": "Amazon's customer service domain model. The model, which is poorly monitored, measures the similarity between customer questions and agent responses using a dual encoder network, a Siamese neural network architecture. Reply templates are derived from embeddings derived from previous agent responses, with no turn-by-turn annotations. Replies to customer queries are generated by selecting the best template from the final set of templates. We show that the selected templates in a closed domain such as customer service cover > 70% of past customer queries. In addition, the relevance of the model-selected templates is significantly higher than templates selected by a standard tf-idf baseline. Index terms: dialogue word generation, human-computer interaction, call agents"}, {"heading": "1. Introduction", "text": "Most customers will contact Amazon by phone, which is a particularly labor-intensive form of communication. The need for agent work is very seasonal, and hiring more agents requires a significant replenishment time for customer training. In addition, Amazon can significantly increase the volume of orders over years, making the scaling of customer service more sublinear. To this end, we present the first steps toward a handy dialog system for Amazon's customer service domain."}, {"heading": "2. Related Work", "text": "In recent years, we have solved a number of problems that we need to solve. In recent years, the number of newcomers who are able to respond to the so-called bAbI tasks has multiplied [4]. Last year, Google launched Smart Reply, an email recommendation system that recommends short answers for 10% of the Gmail volume in its inbox. [5] In this paper, we have found an answer to this question."}, {"heading": "3. Models for Response Generation", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1. Dataset", "text": "We used one year of Amazon Customer Service chat logs on item delivery issues from 09 / 2015 - 09 / 2016 to create training data. The raw text is split into agent and customer contacts, tokenized, filtered by sensitive customer information (e.g. names, credit card numbers, etc.), and converted into lowercase letters. The data needed to train the dual encoder network are pairs of customer questions and agent contacts with binary labels, whether it is a match or not. To extract meaningful question and answer pairs, we select each customer contact that ends with a question mark; the agent turns around after it is considered the correct answer. These matching pairs represent our positive examples. To create non-matching pairs (i.e. negative samples), we use the same set of customer questions, but for each question we randomly select an overall positive contact from one of our 3.1 million school contacts, which was followed by a small negative one out of 3.1."}, {"heading": "3.2. Dual Encoder Network", "text": "Figure 1 shows the circuit diagram for the network.Our dual encoder network takes a customer question (e.g., \"Do I get a new tracking number?\") and an answer (e.g., \"Yes we'll have it email to you.\") as input. Question and answer are fed into two separate LSTM [9] encoders, which generate low-dimensional embedding for the question and answer. The embedding is then linked and passed on to a multi-layer Perceptron (MLP), which indicates the likelihood that the question and answer match.LSTM networks have been widely used to encrypt sentences into low-dimensional embedding for various NL pre-made tasks. [10] showed that LSTMs achieved state-of-the-art performance can be used in various sequential classification tasks. Currently, LSTM-based standard baselines are used for text classification tasks [12] that we can apply to different STM's classification tasks."}, {"heading": "3.3. Response Template Extraction and Prediction", "text": "The other key idea of the system is the pool of ready-made response templates. An ideal pool would contain all of the Common Agent's responses to article delivery problems; if the corresponding answers are not in the pool, the system cannot recommend a reasonable answer. On the other hand, the pool size cannot be too large due to the computational costs. While a pool of 10k randomly sampled responses from the agent would cover almost all common questions about article delivery at the time of prediction, the dual encoder network would have to receive 10k question-answer pairs for each customer survey. As a first step, we will cover randomly sampled 400k responses from the agent from historical article delivery chats and generate embedding for them by using the trained response giver (Figure 1). Our analysis shows that the embedding is capable of capturing semantic similarity beyond simple vocabulary overlaps (Table 3)."}, {"heading": "4. Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1. Selected Examples", "text": "The dual encoder produces two sets of embedding: one for customer questions and another for agent answers. Table 3 shows the 5 closest neighbors for a few selected questions in that embedding space. We also present the 5 closest neighbors for some selected answers. In contrast to the closest neighbors found with tf-idf vectorization, LSTM embedding seems to have more semantic similarity, since tf-idf is essentially based on overlapping search terms. For example, LSTM embedding finds different types of responses to customer greetings, even if the search terms don't overlap too much (e.g. the model finds both \"A pleasure to meet you!\" and \"Nice to hear that!\"), while tf-idf only finds those that have tokens in common."}, {"heading": "4.2. Answer Ranking", "text": "We compare the dual encoder network with the tf-idf baseline using an answer ranking task. In this task, we pair 10k randomly selected customer questions with the correct answer and 9 randomly selected wrong answers. In this task, the \"right answer\" is simply the agent's answer, which is not checked. For each question, the 10 answers were ranked based on the likely output of the dual encoder network. This ranking was compared with the sum of tf-idfterm weights. We compare the mean reciprocal rank and precision @ 3 for both algorithms in Table 5. For all metrics, the dual encoder network clearly exceeds the tf-idf baseline. We also present examples of customer questions and the appropriate answers in Table 4. The tf-idf baseline does not perform well in this task, because even if the vocabulary overlaps contain the signal to retrieve the answer (e.g. the question \"contains no overlap\")."}, {"heading": "4.3. End-to-end Human Evaluation", "text": "We have recruited a rotating pool of agents to assess how well the system works end-to-end. We randomly selected 100 questions and assigned each answer a relevance value of 1 to 3, with 3 being very relevant, 2 somewhat relevant and 1 irrelevant. Ratings for both algorithms are based on the same 100 questions. Note that there may be more than one appropriate answer to a question. Answers such as \"I'm sorry you can't\" and \"Yes, you can cancel it from your order page\" are both very relevant answers to the question \"Can I cancel the order because it's too late?.\" Table 4 shows sample model-based answers to questions, and Figure 2 shows that the distribution of human evaluation results is very relevant to the relevance distribution for both our system and tf-Metidf."}, {"heading": "5. Conclusion and Future Work", "text": "We have shown that a template-based approach to dialog word generation works well in customer service. We show that, despite the lack of a fully automated dialog system, it is possible to select highly relevant answers to customer questions, which can result in a reduction in the time per customer contact. Although we are currently testing this system for online chats, we believe that the template-based approach would naturally extend to a voice-controlled system for telephone calls. There are a number of future instructions that we will follow to make the system more complete. We want to determine the correct polarity for a given template based on the state of a customer's orders. For example, if a customer asks for a delivery that has not yet arrived, we can reply that the delivery should be on time or late from internal delivery dates."}, {"heading": "6. Acknowledgments", "text": "The authors would like to thank Kevin Small for the helpful discussions and support in reviewing the designs, as well as the support staff who helped us evaluate our system and gave area-specific feedback on its design."}, {"heading": "7. References", "text": "[1] O. Vinyals and Q. Le, \"A neural conversations model,\" ICMLDeep Learning Workshop, 2015. [2] I. Serban, A. Sordoni, Y. Bengio, A. Courville, and J. Pineau Moore, \"Hierarchical neural network generative models for movie dialogues,\" S. Sukhbaatar, A. Sukhbaatar, A. Szlam, J. Weston, and R. Fergus, \"Weakly supervised memory networks,\" arXiv, 2015. [4] J. Weston, A. Bordes, S. Chopra, A. M. Rush, B. van Merrie nboer, A. Joulin, and T. Mikolov. \""}], "references": [{"title": "A neural conversational model", "author": ["O. Vinyals", "Q. Le"], "venue": "ICML Deep Learning Workshop, 2015.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2015}, {"title": "Hierarchical neural network generative models for movie dialogues", "author": ["I. Serban", "A. Sordoni", "Y. Bengio", "A. Courville", "J. Pineau"], "venue": "arXiv, 2015.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2015}, {"title": "Weakly supervised memory networks", "author": ["S. Sukhbaatar", "A. Szlam", "J. Weston", "R. Fergus"], "venue": "arXiv, 2015.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}, {"title": "Towards ai-complete question answering: A set of prerequisite toy tasks", "author": ["J. Weston", "A. Bordes", "S. Chopra", "A.M. Rush", "B. van Merri\u00ebnboer", "A. Joulin", "T. Mikolov"], "venue": "arXiv, 2015.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2015}, {"title": "Memory networks", "author": ["J. Weston", "S. Chopra", "A. Bordes"], "venue": "arXiv, 2014.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2014}, {"title": "Smart reply: Automated response suggestion for email", "author": ["A. Kannan", "K. Kurach", "S. Ravi", "T. Kaufmann", "A. Tomkins", "B. Miklos", "G. Corrado", "L. Luk\u00e1cs", "M. Ganea", "P. Young"], "venue": "KDD, 2016.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2016}, {"title": "Signature verification using a \u201dsiamese\u201d time delay neural network", "author": ["J. Bromley", "J.W. Bentz", "L. Bottou", "I. Guyon", "Y. LeCun", "C. Moore", "E. S\u00e4ckinger", "R. Shah"], "venue": "IJPRAI, 1993.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1993}, {"title": "The ubuntu dialogue corpus: A large dataset for research in unstructure multi-turn dialogue systems", "author": ["R. Lowe", "N. Pow", "I. Serban", "J. Pineau"], "venue": "SIGDial, 2015.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2015}, {"title": "Long short-term memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural computation, 1997.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1997}, {"title": "Supervised Sequence Labelling with Recurrent Neural Networks, ser", "author": ["A. Graves"], "venue": "Studies in Computational Intelligence. Springer,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2012}, {"title": "Sequence to sequence learning with neural networks", "author": ["I. Sutskever", "O. Vinyals", "Q.V. Le"], "venue": "NIPS, 2014.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2014}, {"title": "Skip-thought vectors", "author": ["R. Kiros", "Y. Zhu", "R.R. Salakhutdinov", "R. Zemel", "R. Urtasun", "A. Torralba", "S. Fidler"], "venue": "NIPS, 2015.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2015}, {"title": "Towards universal paraphrastic sentence embeddings", "author": ["J. Wieting", "M. Bansal", "K. Gimpel", "K. Livescu"], "venue": "ICLR, 2015.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2015}, {"title": "Theano: A cpu and gpu math compiler in python", "author": ["J. Bergstra", "O. Breuleux", "F. Bastien", "P. Lamblin", "R. Pascanu", "G. Desjardins", "J. Turian", "D. Warde-Farley", "Y. Bengio"], "venue": "Proc. 9th Python in Science Conf, 2010.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2010}, {"title": "Adam: A method for stochastic optimization", "author": ["D. Kingma", "J. Ba"], "venue": "ICLR, 2015.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2015}, {"title": "Web-scale k-means clustering", "author": ["D. Sculley"], "venue": "WWW, 2010.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2010}, {"title": "k-means++: The advantages of careful seeding", "author": ["D. Arthur", "S. Vassilvitskii"], "venue": "Proceedings of the eighteenth annual ACM- SIAM symposium on Discrete algorithms, 2007.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2007}, {"title": "The dialog state tracking challenge", "author": ["J. Williams", "A. Raux", "D. Ramachandran", "A. Black"], "venue": "SIGDIAL, 2013.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "In dialogue systems, Vinyals et al [1] and Serban et al [2] demonstrated that encoder-decoder networks with LSTM units can generate dialogue based on IT help desk and movie script corpuses.", "startOffset": 35, "endOffset": 38}, {"referenceID": 1, "context": "In dialogue systems, Vinyals et al [1] and Serban et al [2] demonstrated that encoder-decoder networks with LSTM units can generate dialogue based on IT help desk and movie script corpuses.", "startOffset": 56, "endOffset": 59}, {"referenceID": 2, "context": "For question answering problems, Sukhbaatar et al [3] are able to achieve competitive performance on the so-called bAbI tasks [4] with memory networks and limited supervision [5].", "startOffset": 50, "endOffset": 53}, {"referenceID": 3, "context": "For question answering problems, Sukhbaatar et al [3] are able to achieve competitive performance on the so-called bAbI tasks [4] with memory networks and limited supervision [5].", "startOffset": 126, "endOffset": 129}, {"referenceID": 4, "context": "For question answering problems, Sukhbaatar et al [3] are able to achieve competitive performance on the so-called bAbI tasks [4] with memory networks and limited supervision [5].", "startOffset": 175, "endOffset": 178}, {"referenceID": 5, "context": "Last year, Google launched Smart Reply, an email response recommendation system that recommends short replies for 10% of Gmail volume in their Inbox mobile application [6].", "startOffset": 168, "endOffset": 171}, {"referenceID": 6, "context": "In this paper, we applied a Siamese-like network [7] with 2 encoders to build a response generation system for a subset of customer service chats related to item delivery problems.", "startOffset": 49, "endOffset": 52}, {"referenceID": 7, "context": ") In the context of information retrieval, Lowe et al [8] also used a similar network to retrieve the next reply from a corpus of Ubuntu technical help IRC chats.", "startOffset": 54, "endOffset": 57}, {"referenceID": 8, "context": "The question and answer are fed into two separate LSTM [9] encoders.", "startOffset": 55, "endOffset": 58}, {"referenceID": 9, "context": "[10] showed that LSTM\u2019s achieved state-ofthe-art performance on various sequential classification tasks.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[11] applied LSTM\u2019s to create sentence embeddings for machine translation.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[12] and [13] showed that LSTM-based embeddings can be used for transfer learning across diverse tasks, including semantic relatedness, paraphrase extraction, and information retrieval.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[12] and [13] showed that LSTM-based embeddings can be used for transfer learning across diverse tasks, including semantic relatedness, paraphrase extraction, and information retrieval.", "startOffset": 9, "endOffset": 13}, {"referenceID": 13, "context": "We trained the dual encoder model with Keras and Theano [14].", "startOffset": 56, "endOffset": 60}, {"referenceID": 14, "context": "We used Adam [15] to perform the stochastic optimization of the network parameters.", "startOffset": 13, "endOffset": 17}, {"referenceID": 15, "context": "We applied mini-batch k-means with k-means++ initializations [16, 17] to cluster the 400k answer embeddings into 500 clusters.", "startOffset": 61, "endOffset": 69}, {"referenceID": 16, "context": "We applied mini-batch k-means with k-means++ initializations [16, 17] to cluster the 400k answer embeddings into 500 clusters.", "startOffset": 61, "endOffset": 69}, {"referenceID": 17, "context": "A common example of this would be prewritten dialogue combined with state tracking, which is used in IVR systems in travel and restaurant reservation applications [18].", "startOffset": 163, "endOffset": 167}], "year": 2017, "abstractText": "We describe a prototype dialogue response generation model for the customer service domain at Amazon. The model, which is trained in a weakly supervised fashion, measures the similarity between customer questions and agent answers using a dual encoder network, a Siamese-like neural network architecture. Answer templates are extracted from embeddings derived from past agent answers, without turn-by-turn annotations. Responses to customer inquiries are generated by selecting the best template from the final set of templates. We show that, in a closed domain like customer service, the selected templates cover >70% of past customer inquiries. Furthermore, the relevance of the model-selected templates is significantly higher than templates selected by a standard tf-idf baseline.", "creator": "LaTeX with hyperref package"}}}