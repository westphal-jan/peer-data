{"id": "1703.09752", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Mar-2017", "title": "Collective Anomaly Detection based on Long Short Term Memory Recurrent Neural Network", "abstract": "Intrusion detection for computer network systems becomes one of the most critical tasks for network administrators today. It has an important role for organizations, governments and our society due to its valuable resources on computer networks. Traditional misuse detection strategies are unable to detect new and unknown intrusion. Besides, anomaly detection in network security is aim to distinguish between illegal or malicious events and normal behavior of network systems. Anomaly detection can be considered as a classification problem where it builds models of normal network behavior, which it uses to detect new patterns that significantly deviate from the model. Most of the cur- rent research on anomaly detection is based on the learning of normally and anomaly behaviors. They do not take into account the previous, re- cent events to detect the new incoming one. In this paper, we propose a real time collective anomaly detection model based on neural network learning and feature operating. Normally a Long Short Term Memory Recurrent Neural Network (LSTM RNN) is trained only on normal data and it is capable of predicting several time steps ahead of an input. In our approach, a LSTM RNN is trained with normal time series data before performing a live prediction for each time step. Instead of considering each time step separately, the observation of prediction errors from a certain number of time steps is now proposed as a new idea for detecting collective anomalies. The prediction errors from a number of the latest time steps above a threshold will indicate a collective anomaly. The model is built on a time series version of the KDD 1999 dataset. The experiments demonstrate that it is possible to offer reliable and efficient for collective anomaly detection.", "histories": [["v1", "Tue, 28 Mar 2017 19:04:11 GMT  (454kb)", "http://arxiv.org/abs/1703.09752v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.CR", "authors": ["loic bontemps", "van loi cao", "james mcdermott", "nhien-an le-khac"], "accepted": false, "id": "1703.09752"}, "pdf": {"name": "1703.09752.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["ie@ucd.ie", "an.lekhac@ucd.ie"], "sections": [{"heading": null, "text": "In fact, the fact is that most of them are able to survive themselves, and that they are able to survive themselves, \"he said in an interview with the\" New York Times, \"\" I don't think they are able to survive me. \""}], "references": [{"title": "A survey of network anomaly detection techniques", "author": ["M. Ahmed", "A.N. Mahmood", "J. Hu"], "venue": "Journal of Network and Computer Applications 60, 19\u201331", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2016}, {"title": "Network anomaly detection: A machine learning perspective", "author": ["D.K. Bhattacharyya", "J.K. Kalita"], "venue": "CRC Press", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2013}, {"title": "Anomaly detection: A survey", "author": ["V. Chandola", "A. Banerjee", "V. Kumar"], "venue": "ACM computing surveys (CSUR) 41(3), 15", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2009}, {"title": "V-detector algorithm with tree-based structures", "author": ["A. Chmielewski", "S.T. Wierzchon"], "venue": "Proc. of the International Multiconference on Computer Science and Information Technology, Wis/la (Poland). pp. 9\u201314. Citeseer", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2006}, {"title": "Outlier detection using replicator neural networks", "author": ["S. Hawkins", "H. He", "G. Williams", "R. Baxter"], "venue": "International Conference on Data Warehousing and Knowledge Discovery. pp. 170\u2013180. Springer", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2002}, {"title": "Long short-term memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural computation 9(8), 1735\u20131780", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1997}, {"title": "A framework for constructing features and models for intrusion detection systems", "author": ["W. Lee", "S.J. Stolfo"], "venue": "ACM transactions on Information and system security (TiSSEC) 3(4), 227\u2013261", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2000}, {"title": "Network anomaly detection based on wavelet analysis", "author": ["W. Lu", "A.A. Ghorbani"], "venue": "EURASIP Journal on Advances in Signal Processing 2009, 4", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2009}, {"title": "Long short term memory networks for anomaly detection in time series", "author": ["P. Malhotra", "L. Vig", "G. Shroff", "P. Agarwal"], "venue": "Proceedings. p. 89. Presses universitaires de Louvain", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2015}, {"title": "A novel approach for automatic acoustic novelty detection using a denoising autoencoder with bidirectional lstm neural networks", "author": ["E. Marchi", "F. Vesperini", "F. Eyben", "S. Squartini", "B. Schuller"], "venue": "2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). pp. 1996\u20132000. IEEE", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2015}, {"title": "Non-linear prediction with lstm recurrent neural networks for acoustic novelty detection", "author": ["E. Marchi", "F. Vesperini", "F. Weninger", "F. Eyben", "S. Squartini", "B. Schuller"], "venue": "2015 International Joint Conference on Neural Networks (IJCNN). pp. 1\u20137. IEEE", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2015}, {"title": "A probabilistic approach to aggregating anomalies for unsupervised anomaly detection with industrial applications", "author": ["T. Olsson", "A. Holst"], "venue": "FLAIRS Conference. pp. 434\u2013439", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2015}, {"title": "Hybrid intelligent intrusion detection scheme", "author": ["M.A. Salama", "H.F. Eid", "R.A. Ramadan", "A. Darwish", "A.E. Hassanien"], "venue": "Soft computing in industrial applications, pp. 293\u2013303. Springer", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2011}], "referenceMentions": [{"referenceID": 1, "context": "Keywords: Long Short-Term Memory, Recurrent Neural Network, Collective Anomaly Detection 1 Introduction Network anomaly detection refers to the problem of detecting illegal or malicious activities or events from normal connections or expected behavior of network systems [4, 5].", "startOffset": 271, "endOffset": 277}, {"referenceID": 2, "context": "Keywords: Long Short-Term Memory, Recurrent Neural Network, Collective Anomaly Detection 1 Introduction Network anomaly detection refers to the problem of detecting illegal or malicious activities or events from normal connections or expected behavior of network systems [4, 5].", "startOffset": 271, "endOffset": 277}, {"referenceID": 0, "context": "Over the last three decades, machine learning techniques are known as a common approach for developing network anomaly detection models [3, 4].", "startOffset": 136, "endOffset": 142}, {"referenceID": 1, "context": "Over the last three decades, machine learning techniques are known as a common approach for developing network anomaly detection models [3, 4].", "startOffset": 136, "endOffset": 142}, {"referenceID": 2, "context": "Network anomaly detection is usually posed as a type of classification problem: given a dataset representing normal and anomalous examples, the goal is to build a learning classifier which is capable of signaling when a new anomalous data sample is encountered [5].", "startOffset": 261, "endOffset": 264}, {"referenceID": 3, "context": "However, most of the existing approaches consider an anomaly as a single point: cases when they occur \u201cindividually\u201d and \u201cseparately\u201d [6, 7, 16].", "startOffset": 134, "endOffset": 144}, {"referenceID": 4, "context": "However, most of the existing approaches consider an anomaly as a single point: cases when they occur \u201cindividually\u201d and \u201cseparately\u201d [6, 7, 16].", "startOffset": 134, "endOffset": 144}, {"referenceID": 12, "context": "However, most of the existing approaches consider an anomaly as a single point: cases when they occur \u201cindividually\u201d and \u201cseparately\u201d [6, 7, 16].", "startOffset": 134, "endOffset": 144}, {"referenceID": 6, "context": "In network security, some kinds of attacks, Denial of Service (DoS), usually occur for a long period of time (several minutes) [10], and are often represented by a set of single points.", "startOffset": 127, "endOffset": 131}, {"referenceID": 2, "context": "In this work, we aim to build an anomaly detection model for this kinds of attacks (known as collective anomaly mentioned in [5]).", "startOffset": 125, "endOffset": 128}, {"referenceID": 2, "context": "Collective anomaly is the term to refer to a collection of related anomalous data instances with respect to the whole dataset [5].", "startOffset": 126, "endOffset": 129}, {"referenceID": 8, "context": "Long Short Term Memory Recurrent Neural Network (LSTM RNN) is known as one of powerful techniques to represent the relationship between current event and previous events, and handles time series problems [12, 14].", "startOffset": 204, "endOffset": 212}, {"referenceID": 10, "context": "Long Short Term Memory Recurrent Neural Network (LSTM RNN) is known as one of powerful techniques to represent the relationship between current event and previous events, and handles time series problems [12, 14].", "startOffset": 204, "endOffset": 212}, {"referenceID": 5, "context": "In this paper, we will propose a collective anomaly detection model by using the predictive power of LSTM RNN [8].", "startOffset": 110, "endOffset": 113}, {"referenceID": 8, "context": "In this section, we briefly describe work related applying LSTM RNN to time series and collective anomaly detection problems [12, 14, 15].", "startOffset": 125, "endOffset": 137}, {"referenceID": 10, "context": "In this section, we briefly describe work related applying LSTM RNN to time series and collective anomaly detection problems [12, 14, 15].", "startOffset": 125, "endOffset": 137}, {"referenceID": 11, "context": "In this section, we briefly describe work related applying LSTM RNN to time series and collective anomaly detection problems [12, 14, 15].", "startOffset": 125, "endOffset": 137}, {"referenceID": 11, "context": "[15] proposed an unsupervised approach for detecting collective anomaly.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "In [12], Malhotra et al.", "startOffset": 3, "endOffset": 7}, {"referenceID": 10, "context": "[14, 13] presented a novel approach by combining non-linear predictive denoising autoencoders (DA) with LSTM for identifying abnormal acoustic signals.", "startOffset": 0, "endOffset": 8}, {"referenceID": 9, "context": "[14, 13] presented a novel approach by combining non-linear predictive denoising autoencoders (DA) with LSTM for identifying abnormal acoustic signals.", "startOffset": 0, "endOffset": 8}, {"referenceID": 10, "context": "The idea is also used in a practical acoustic example [14, 13], where LSTM RNNs are used to predict short-term frames.", "startOffset": 54, "endOffset": 62}, {"referenceID": 9, "context": "The idea is also used in a practical acoustic example [14, 13], where LSTM RNNs are used to predict short-term frames.", "startOffset": 54, "endOffset": 62}, {"referenceID": 11, "context": "Then, we will use a classifier inspired by [15] to rate the level of anomaly of each time sample.", "startOffset": 43, "endOffset": 47}, {"referenceID": 5, "context": "[8] in 1997, and has already proven as a powerful technique for addressing the problem of time series prediction.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "1 LSTM RNN as a predictive vector The first step inspires the idea presented in [12]: when trained correctly, LSTM RNNs have the ability to impregnate themselves with the behavior of a training set.", "startOffset": 80, "endOffset": 84}, {"referenceID": 8, "context": "In our work, we will use a simple LSTM RNN, in opposition to stacked LSTM in [12].", "startOffset": 77, "endOffset": 81}, {"referenceID": 7, "context": "This method is a development of the proposed transformation in [11] that acts directly on the tcpdump to obtain real time statistics of the data.", "startOffset": 63, "endOffset": 67}, {"referenceID": 9, "context": "-E occurrence=f -i netstat -f tcp[13]==12 > Thursday2.", "startOffset": 33, "endOffset": 37}, {"referenceID": 9, "context": "If we aim to detect Neptune attack, the thark command can be implemented with the \u00ad\u2212i netstat \u00ad\u2212f tcp[13] == 2 filter, so only SYN ACK packets from servers are counted.", "startOffset": 101, "endOffset": 105}, {"referenceID": 8, "context": "We first focus on how many inputs will influence the prediction of an LSTM [12].", "startOffset": 75, "endOffset": 79}], "year": 2017, "abstractText": "Intrusion detection for computer network systems becomes one of the most critical tasks for network administrators today. It has an important role for organizations, governments and our society due to its valuable resources on computer networks. Traditional misuse detection strategies are unable to detect new and unknown intrusion. Besides, anomaly detection in network security is aim to distinguish between illegal or malicious events and normal behavior of network systems. Anomaly detection can be considered as a classification problem where it builds models of normal network behavior, which it uses to detect new patterns that significantly deviate from the model. Most of the current research on anomaly detection is based on the learning of normally and anomaly behaviors. They do not take into account the previous, recent events to detect the new incoming one. In this paper, we propose a real time collective anomaly detection model based on neural network learning and feature operating. Normally a Long Short-Term Memory Recurrent Neural Network (LSTM RNN) is trained only on normal data and it is capable of predicting several time steps ahead of an input. In our approach, a LSTM RNN is trained with normal time series data before performing a live prediction for each time step. Instead of considering each time step separately, the observation of prediction errors from a certain number of time steps is now proposed as a new idea for detecting collective anomalies. The prediction errors from a number of the latest time steps above a threshold will indicate a collective anomaly. The model is built on a time series version of the KDD 1999 dataset. The experiments demonstrate that it is possible to offer reliable and efficient for collective anomaly detection.", "creator": "Word"}}}