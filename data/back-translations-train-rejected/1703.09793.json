{"id": "1703.09793", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Mar-2017", "title": "Deceiving Google's Cloud Video Intelligence API Built for Summarizing Videos", "abstract": "Despite the rapid progress of the techniques for image classification, video annotation has remained a challenging task. Automated video annotation would be a breakthrough technology, enabling users to search within the videos. Recently, Google introduced the Cloud Video Intelligence API for video analysis. As per the website, the system \"separates signal from noise, by retrieving relevant information at the video, shot or per frame.\" A demonstration website has been also launched, which allows anyone to select a video for annotation. The API then detects the video labels (objects within the video) as well as shot labels (description of the video events over time). In this paper, we examine the usability of the Google's Cloud Video Intelligence API in adversarial environments. In particular, we investigate whether an adversary can manipulate a video in such a way that the API will return only the adversary-desired labels. For this, we select an image that is different from the content of the Video and insert it, periodically and at a very low rate, into the video. We found that if we insert one image every two seconds, the API is deceived into annotating the entire video as if it only contains the inserted image. Note that the modification to the video is hardly noticeable as, for instance, for a typical frame rate of 25, we insert only one image per 50 video frames. We also found that, by inserting one image per second, all the shot labels returned by the API are related to the inserted image. We perform the experiments on the sample videos provided by the API demonstration website and show that our attack is successful with different videos and images.", "histories": [["v1", "Sun, 26 Mar 2017 20:52:43 GMT  (3250kb,D)", "http://arxiv.org/abs/1703.09793v1", null], ["v2", "Fri, 31 Mar 2017 05:25:36 GMT  (3252kb,D)", "http://arxiv.org/abs/1703.09793v2", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["hossein hosseini", "baicen xiao", "radha poovendran"], "accepted": false, "id": "1703.09793"}, "pdf": {"name": "1703.09793.pdf", "metadata": {"source": "CRF", "title": "Deceiving Google\u2019s Cloud Video Intelligence API Built for Summarizing Videos", "authors": ["Hossein Hosseini", "Baicen Xiao", "Radha Poovendran"], "emails": ["rp3}@uw.edu"], "sections": [{"heading": null, "text": "In this post, we examine the ease of use of Google's Cloud Video Intelligence API in adversarial environments by selecting an image that differs from the content of the video, and inserting it periodically into the video at very low speeds. We found that if we insert an image every two seconds, the API is fooled into commenting on the entire video as if it contained only the inserted image. Note that the change in the video is barely noticeable, for example, at a typical frame rate of 25 frames per 50 video frames. We also found that by inserting one image per second, all recordings returned by the API correlate to the inserted image. We conduct the experiments on the sample videos provided by the API demonstration website, and show that our attack with different videos and images is successful."}, {"heading": "1. Introduction", "text": "In recent years, machine learning methods have been extensively tailored to the needs of users, particularly to detect the content of videos. However, using machine learning to annotate videos remains a challenge. Automatic video annotation allows you to search for a specific event that is useful in many areas, such as video surveillance or restoring search results. It can also be used to present videos, such as YouTube and Facebook, where the distribution of illegal content is not allowed."}, {"heading": "2. Google\u2019s Cloud Video Intelligence API", "text": "Google's Cloud Video Intelligence API is designed to understand and analyze video, enabling developers to easily browse and discover video content by retrieving information about entities (nouns or verbs) in the video and when they occur within the video. [6] It noted that the system \"separates signals from noise by retrieving relevant information in the video, in the recording, or per frame.\" The API uses deep learning models that are built using frameworks such as TensorFlow and applied to major media platforms such as YouTube [7] to help major media companies better understand the unstructured video data, and for media companies and consumer technology companies that want to build their media catalogs or find easy ways to manage crowd-sourced content. [7] The underlying technology can also be used to improve video recommendations by enabling search engines to search video content beyond metadata such as comments [8]."}, {"heading": "3. The Image Insertion Attack", "text": "In this area, we are in a position to outdo ourselves."}, {"heading": "4. Discussion", "text": "Many applications can benefit from automated video search and summary. For example, video surveillance requires many hours of searching for videos for a specific event. Also, some Internet platforms, such as YouTube and Facebook, need to process huge amounts of video files every day to better distribute the relevant content among people and block videos with illegal content.Google's Cloud Video Intelligence API is designed to allow developers to quickly search through the video content, just like text documents, so it has the potential to transform the video analysis field so that users search for a specific event and the associated videos along with the precise timing of events within the video. However, we have shown that the API has certain security weaknesses. Specifically, an adversary can insert an image into the video at a regular interval and at a very low rate, in such a way that all generated images obscure the inserted image."}, {"heading": "5. Conclusion", "text": "In this article, we showed that Google's current Cloud Video Intelligence API can easily be deceived by an adversary without compromising the system or having knowledge of the specific details of the algorithms used. Essentially, an adversary can easily manipulate a video by periodically inserting an image so that the API returns only the labels associated with the inserted image. The success of the insertion attack shows how important it is to design the system to work equally well in adverse environments."}, {"heading": "Acknowledgments", "text": "This work was supported by ONR grants N00014-14-10029 and N00014-16-1-2710, ARO grants W911NF-16-10485 and NSF grants CNS-1446866."}], "references": [{"title": "Pattern recognition and machine learning (information science and statistics), 1st edn. 2006. corr. 2nd printing edn", "author": ["C. Bishop"], "venue": "Springer, New York, 2007.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2007}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "Advances in neural information processing systems, pp. 1097\u20131105, 2012.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2012}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["K. Simonyan", "A. Zisserman"], "venue": "arXiv preprint arXiv:1409.1556, 2014.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2014}, {"title": "Assistive tagging: A survey of multimedia tagging with humancomputer joint exploration", "author": ["M. Wang", "B. Ni", "X.-S. Hua", "T.-S. Chua"], "venue": "ACM Computing Surveys (CSUR), vol. 44, no. 4, p. 25, 2012.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2012}, {"title": "Utility data annotation with amazon mechanical turk", "author": ["A. Sorokin", "D. Forsyth"], "venue": "Computer Vision and Pattern Recognition Workshops, 2008. CVPRW\u201908. IEEE Computer Society Conference on, pp. 1\u20138, IEEE, 2008.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2008}], "referenceMentions": [{"referenceID": 0, "context": "In recent years, machine learning techniques have been extensively deployed for computer vision tasks, particularly recognizing objects in images [1\u20133].", "startOffset": 146, "endOffset": 151}, {"referenceID": 1, "context": "In recent years, machine learning techniques have been extensively deployed for computer vision tasks, particularly recognizing objects in images [1\u20133].", "startOffset": 146, "endOffset": 151}, {"referenceID": 2, "context": "In recent years, machine learning techniques have been extensively deployed for computer vision tasks, particularly recognizing objects in images [1\u20133].", "startOffset": 146, "endOffset": 151}, {"referenceID": 3, "context": "understanding the video contents rely on manual tagging or combining humans and computers for more accurate and efficient tagging [4,5].", "startOffset": 130, "endOffset": 135}, {"referenceID": 4, "context": "understanding the video contents rely on manual tagging or combining humans and computers for more accurate and efficient tagging [4,5].", "startOffset": 130, "endOffset": 135}], "year": 2017, "abstractText": "Despite the rapid progress of the techniques for image classification, video annotation has remained a challenging task. Automated video annotation would be a breakthrough technology, enabling users to search within the videos. Recently, Google introduced the Cloud Video Intelligence API for video analysis. As per the website, the system \u201cseparates signal from noise, by retrieving relevant information at the video, shot or per frame.\u201d A demonstration website has been also launched, which allows anyone to select a video for annotation. The API then detects the video labels (objects within the video) as well as shot labels (description of the video events over time). In this paper, we examine the usability of the Google\u2019s Cloud Video Intelligence API in adversarial environments. In particular, we investigate whether an adversary can manipulate a video in such a way that the API will return only the adversary-desired labels. For this, we select an image that is different from the content of the Video and insert it, periodically and at a very low rate, into the video. We found that if we insert one image every two seconds, the API is deceived into annotating the entire video as if it only contains the inserted image. Note that the modification to the video is hardly noticeable as, for instance, for a typical frame rate of 25, we insert only one image per 50 video frames. We also found that, by inserting one image per second, all the shot labels returned by the API are related to the inserted image. We perform the experiments on the sample videos provided by the API demonstration website and show that our attack is successful with different videos and images.", "creator": "LaTeX with hyperref package"}}}