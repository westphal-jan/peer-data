{"id": "1703.10356", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Mar-2017", "title": "Simplified End-to-End MMI Training and Voting for ASR", "abstract": "An hybrid of a hidden Markov model (HMM) and a deep neural network (DNN) is considered. End-to-end training using gradient descent is suggested, similarly to the training of connectionist temporal classification (CTC). We use a maximum a-posteriori (MAP) criterion with a simple language model in the training stage, and a standard HMM decoder without approximations. Recognition results are presented using speech databases. Our method compares favorably to CTC in terms of performance, robustness and quality of alignments.", "histories": [["v1", "Thu, 30 Mar 2017 08:40:19 GMT  (876kb,D)", "http://arxiv.org/abs/1703.10356v1", "Submitted to Interspeech 2017"], ["v2", "Sun, 16 Jul 2017 15:12:39 GMT  (1184kb,D)", "http://arxiv.org/abs/1703.10356v2", null]], "COMMENTS": "Submitted to Interspeech 2017", "reviews": [], "SUBJECTS": "cs.LG cs.CL cs.NE", "authors": ["lior fritz", "david burshtein"], "accepted": false, "id": "1703.10356"}, "pdf": {"name": "1703.10356.pdf", "metadata": {"source": "CRF", "title": "End-to-End MAP Training of a Hybrid HMM-DNN Model", "authors": ["Lior Fritz", "David Burshtein"], "emails": ["lior.fritz@gmail.com,", "burstyn@eng.tau.ac.il"], "sections": [{"heading": "1. Introduction", "text": "A major advantage of connectionist time classification (CTC) [1] over a hybrid of a hidden Markov model (HMM) and a deep neural network (DNN) [2] lies in the simplicity of training and its scalability. However, there are some problems with CTC. Firstly, exact decoding is mathematically insoluble, and some approximation is needed [1]. In addition, CTC is not characterized by good alignment between input and output sequences, which presents challenges in some applications [3, 4]. We propose a novel training method for an HMM-DNN hybrid. Similar to CTC, we use end-to-end training, but unlike CTC, our derivation is formulated using the maximum a-posteriori (MAP) approach with a simple language model (LM) in the training phase."}, {"heading": "2. The Model", "text": "This is a sentence in which each word is represented from left to right (HMM = j = j sentence), the states of which are the basic elements of the word (1) (1), such as the sequence of letters (1). As an example, we consider the sentence \"it\" and assume a character-based modeling. Then, the sequence of letters is between words, and we reserve two states for the beginning and end of the sentence."}, {"heading": "2.1. Training Procedure", "text": "Applicable (6) is the calculation of P (o) and P (o) k (o) k (q). By (4) and since we can, as explained, set A = 1, the first term, P (o), is calculated by adding up all possible state sequences as follows: P (o) = s (T) (T) t (1 pst \u2212 1, st) \u00b7 exp {T (o) t (8) 1The basis of all logarithms in this paper is where we yt, st) = yt, st (st) st \u2212 st. The transition probabilities are given by (2). To calculate P (o), we use P (o) s (o) s) (T) (T) t = 1 pst \u2212 1, st)."}, {"heading": "2.2. Decoding", "text": "To integrate our model with an LM, we use the WFST approach. A WFST is a finite state machine in which each transition has an input symbol, an output symbol and a weight. Our WFST is implemented with the FST library OpenFST [11] and is based on the decoding method of EESEN [10]. We first create separate WFSTs for the LM (grammar), the lexicon and the HMM labels. An example of the grammar WFST, G, with two possible sentences is shown in Figure 2a. The lexicon WFST, L, encodes sequences of lexicon units (e.g. cats or characters) to words. It forces the occurrence of blank labels between words and, and, for phoneme labels, also between identical labels."}, {"heading": "2.3. Numerical Issues", "text": "For HMMs and CTC, the calculation of forward and backward variables is usually performed on the log scale (as in [9,10]. Another possibility is to apply the normalization techniques in [12]. In our implementation, it was necessary to combine both approaches and then subtract the maximum value of the forward (backward) variables in [12], as we now describe it, from each forward (backward) variable. A simpler variant of the above is to perform the subtraction only in certain units of time. To simplify, we describe our method on the linear scale, for P (o) and its derivatives. Adaptation to the calculation of P (o), o) and its derivatives is simple."}, {"heading": "2.4. Implementation", "text": "We have implemented our model in Tensorflow [13]. Our loss function is implemented in C + +, where the samples are computed in mini-batch on different cores of the CPU in parallel. We have integrated the feature extraction methods of EESEN (which uses Kaldis scripts [14]) and [15, 16], the NN methods of Tensorflow and the WFSTs decoding methods of EESEN. Since the computing time required by the NN is dominant, the training process takes only 5% to 8% longer when using our loss function compared to CTC."}, {"heading": "3. Experiments", "text": "We conducted experiments at the Wall Street Journal (WSJ) Corpus [7]. The training data consists of 81 hours of transcribed speech. We use almost the same training process and NN architecture as in [10]. We extract 95% of the training set for training and 5% for cross validation. The NN input is a 40-dimensional filter bank with delta and delta delta coefficients. Characteristics are normalized by mean and variance on the loudspeaker basis. We work on a phonematic system, with 72 labels. The expressions in the training set are sorted by their lengths. The mini-batch size is set to 30. We use the ADAM optimizer with an initial learning rate of 0.001. We use gradient clipping [18] with a value of 50 grams. The learning rate decays and the stop criteria are determined on the basis of validation WHO (optimization for each method)."}, {"heading": "4. Conclusions", "text": "We have presented a novel end-to-end MAP training method of an HMM-DNN hybrid that compares favorably to CTC on the WSJ corpus. We also believe that our method is more robust in the following sense: In [21], using CTC, it was found that the prediction of the network blank label was too dominant during decoding; the authors suggested a blank prediction-reducing method by subtracting a high prediction from the network blank prediction; in [10], another Priors normalization method was proposed that also reduces the blank prediction; however, the formulation of the CTC model does not justify Priors normalization; in [22] it was shown that the Priors subtraction method in [10] may even worsen the WHO in some cases; in future work, we plan to further investigate the effects of the LM sequence used in the training process, and to apply our sequence to other important tasks in the model."}, {"heading": "5. Acknowledgements", "text": "This research was supported by the Yitzhak and Chaya Weinstein Research Institute for Signal Processing. A Tesla K40c GPU used in this research was donated by NVIDIA Corporation."}, {"heading": "6. References", "text": "[1] A. Graves, S. Fern\u00e1ndez, F. Gomez, and J. Schmidhuber. [1] Connectionist temporal classification: labeling unsegmented sequence data with recurrent neural networks, \"in Proceedings of the 23rd international conference on Machine learning. ACM, 2006, pp. 369-376. [2] G. Hinton, L. Deng, D. Yu, G. E. Dahl, A.-R. Mohamed, N. Jaitly, A. Senior, V. Vanhoucke, P. Nguyen, T. N. Sainath et al.,\" Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups, \"IEEE Signal Processing Magazine, vol. 29, pp. 82-97, 2012. [3] Y. Wang, X. Deng, S. Pu, and Z. Huang,\" Residual convolutional CTC networks for automatic speech recognition. \""}], "references": [{"title": "Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks,", "author": ["A. Graves", "S. Fern\u00e1ndez", "F. Gomez", "J. Schmidhuber"], "venue": "Proceedings of the 23rd international conference on Machine learning", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2006}, {"title": "Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups,", "author": ["G. Hinton", "L. Deng", "D. Yu", "G.E. Dahl", "A.-r. Mohamed", "N. Jaitly", "A. Senior", "V. Vanhoucke", "P. Nguyen", "T.N. Sainath"], "venue": "IEEE Signal Processing Magazine,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "Residual convolutional CTC networks for automatic speech recognition,", "author": ["Y. Wang", "X. Deng", "S. Pu", "Z. Huang"], "venue": "arXiv preprint arXiv:1702.07793,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2017}, {"title": "Robust end-to-end deep audiovisual speech recognition,", "author": ["R. Sanabria", "F. Metze", "F. De La Torre"], "venue": "arXiv preprint arXiv:1611.06986,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2016}, {"title": "Weighted finitestate transducers in speech recognition,", "author": ["M. Mohri", "F. Pereira", "M. Riley"], "venue": "Computer Speech & Language,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2002}, {"title": "The design for the Wall Street Journal-based CSR corpus,", "author": ["D.B. Paul", "J.M. Baker"], "venue": "Proceedings of the workshop on Speech and Natural Language. Association for Computational Linguistics,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1992}, {"title": "A tutorial on hidden Markov models and selected applications in speech recognition,", "author": ["R.L. Rabiner"], "venue": "Proceedings of the IEEE,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1989}, {"title": "Deep speech: scaling up end-to-end speech recognition,", "author": ["A.Y. Hannun", "C. Case", "J. Casper", "B.C. Catanzaro", "G. Diamos", "E. Elsen", "R. Prenger", "S. Satheesh", "S. Sengupta", "A. Coates", "A.Y. Ng"], "venue": "CoRR, vol. abs/1412.5567,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "EESEN: Endto-end speech recognition using deep RNN models and WFST-based decoding,", "author": ["Y. Miao", "M. Gowayyed", "F. Metze"], "venue": "IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU),", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2015}, {"title": "OpenFst: A general and efficient weighted finite-state transducer library", "author": ["C. Allauzen", "M. Riley", "J. Schalkwyk", "W. Skut", "M. Mohri"], "venue": "Implementation and Application of Automata,\u201d", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2007}, {"title": "Fundamentals of Speech Recognition", "author": ["L.R. Rabiner", "B.-H. Juang"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1993}, {"title": "Tensorflow: Large-scale machine learning on heterogeneous distributed systems,", "author": ["M. Abadi", "A. Agarwal", "P. Barham", "E. Brevdo", "Z. Chen", "C. Citro", "G.S. Corrado", "A. Davis", "J. Dean", "M. Devin"], "venue": "arXiv preprint arXiv:1603.04467,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2016}, {"title": "The Kaldi speech recognition toolkit,", "author": ["D. Povey", "A. Ghoshal", "G. Boulianne", "L. Burget", "O. Glembek", "N. Goel", "M. Hannemann", "P. Motlicek", "Y. Qian", "P. Schwarz"], "venue": "IEEE 2011 workshop on automatic speech recognition and understanding,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1925}, {"title": "Kaldi+ pdnn: building dnn-based asr systems with kaldi and pdnn,", "author": ["Y. Miao"], "venue": "arXiv preprint arXiv:1401.6984,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2014}, {"title": "Kaldi with TensorFlow Neural Net,", "author": ["V. Renkens"], "venue": "https: //github.com/vrenkens/tfkaldi,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2016}, {"title": "ADAM: A method for stochastic optimization,", "author": ["D. Kingma", "J. Ba"], "venue": "arXiv preprint arXiv:1412.6980,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2014}, {"title": "On the difficulty of training recurrent neural networks,", "author": ["R. Pascanu", "T. Mikolov", "Y. Bengio"], "venue": "International Conference on Machine Learning (ICML),", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2013}, {"title": "Long short-term memory,", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural computation,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1997}, {"title": "Learning precise timing with LSTM recurrent networks,", "author": ["F.A. Gers", "N.N. Schraudolph", "J. Schmidhuber"], "venue": "Journal of machine learning research,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2002}, {"title": "Learning acoustic frame labeling for speech recognition with recurrent neural networks,", "author": ["H. Sak", "A. Senior", "K. Rao", "O. Irsoy", "A. Graves", "F. Beaufays", "J. Schalkwyk"], "venue": "IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2015}, {"title": "Maximum a posteriori based decoding for CTC acoustic models,", "author": ["N. Kanda", "X. Lu", "H. Kawai"], "venue": "Interspeech 2016,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2016}], "referenceMentions": [{"referenceID": 0, "context": "Introduction A major advantage of connectionist temporal classification (CTC) [1] over a hybrid of a hidden Markov model (HMM) and a deep neural network (DNN) [2] lies in the simplicity of the training and its scalability.", "startOffset": 78, "endOffset": 81}, {"referenceID": 1, "context": "Introduction A major advantage of connectionist temporal classification (CTC) [1] over a hybrid of a hidden Markov model (HMM) and a deep neural network (DNN) [2] lies in the simplicity of the training and its scalability.", "startOffset": 159, "endOffset": 162}, {"referenceID": 0, "context": "First, exact decoding is computationally intractable, and one needs to use some approximation [1].", "startOffset": 94, "endOffset": 97}, {"referenceID": 2, "context": "In addition, CTC does not excel in providing a good alignment between the input and output sequences, posing challenges in some applications [3, 4].", "startOffset": 141, "endOffset": 147}, {"referenceID": 3, "context": "In addition, CTC does not excel in providing a good alignment between the input and output sequences, posing challenges in some applications [3, 4].", "startOffset": 141, "endOffset": 147}, {"referenceID": 4, "context": "We use the weighted finite state transducer (WFST) approach [6] and discuss some implementation issues.", "startOffset": 60, "endOffset": 63}, {"referenceID": 5, "context": "Speech recognition results on the Wall Street Journal (WSJ) corpus [7] compare favorably with CTC.", "startOffset": 67, "endOffset": 70}, {"referenceID": 6, "context": "The Model Consider a sentence where each word is represented by a left to right hidden Markov model (HMM) [8] whose states are the basic elements of the word (termed labels), such as the character spelling or the phonetic transcription of the word as in [9, 10].", "startOffset": 106, "endOffset": 109}, {"referenceID": 7, "context": "The Model Consider a sentence where each word is represented by a left to right hidden Markov model (HMM) [8] whose states are the basic elements of the word (termed labels), such as the character spelling or the phonetic transcription of the word as in [9, 10].", "startOffset": 254, "endOffset": 261}, {"referenceID": 8, "context": "The Model Consider a sentence where each word is represented by a left to right hidden Markov model (HMM) [8] whose states are the basic elements of the word (termed labels), such as the character spelling or the phonetic transcription of the word as in [9, 10].", "startOffset": 254, "endOffset": 261}, {"referenceID": 9, "context": "Our WFST is implemented with the FST library OpenFST [11], and is based on the decoding method of EESEN [10].", "startOffset": 53, "endOffset": 57}, {"referenceID": 8, "context": "Our WFST is implemented with the FST library OpenFST [11], and is based on the decoding method of EESEN [10].", "startOffset": 104, "endOffset": 108}, {"referenceID": 7, "context": "Numerical Issues For HMMs and CTC, the calculations of the forward and backward variables are usually performed in log-scale, as in [9,10].", "startOffset": 132, "endOffset": 138}, {"referenceID": 8, "context": "Numerical Issues For HMMs and CTC, the calculations of the forward and backward variables are usually performed in log-scale, as in [9,10].", "startOffset": 132, "endOffset": 138}, {"referenceID": 10, "context": "Another possibility is to use the normalization technique in [12].", "startOffset": 61, "endOffset": 65}, {"referenceID": 10, "context": "In our implementation it was necessary to combine both approaches, with some modification of the method in [12], as we now describe.", "startOffset": 107, "endOffset": 111}, {"referenceID": 8, "context": "Model WER% validation eval92 dev93 CTC, EESEN [10] 7.", "startOffset": 46, "endOffset": 50}, {"referenceID": 8, "context": "87 Hybrid HMM-DNN [10] 7.", "startOffset": 18, "endOffset": 22}, {"referenceID": 11, "context": "We implemented our model in Tensorflow [13].", "startOffset": 39, "endOffset": 43}, {"referenceID": 12, "context": "We have integrated the feature extraction procedures from EESEN (which uses Kaldi\u2019s scripts [14]) and [15, 16], the NN procedures from Tensorflow and the WFSTs decoding procedures from EESEN.", "startOffset": 92, "endOffset": 96}, {"referenceID": 13, "context": "We have integrated the feature extraction procedures from EESEN (which uses Kaldi\u2019s scripts [14]) and [15, 16], the NN procedures from Tensorflow and the WFSTs decoding procedures from EESEN.", "startOffset": 102, "endOffset": 110}, {"referenceID": 14, "context": "We have integrated the feature extraction procedures from EESEN (which uses Kaldi\u2019s scripts [14]) and [15, 16], the NN procedures from Tensorflow and the WFSTs decoding procedures from EESEN.", "startOffset": 102, "endOffset": 110}, {"referenceID": 5, "context": "We conducted experiments on the Wall Street Journal (WSJ) corpus [7].", "startOffset": 65, "endOffset": 68}, {"referenceID": 8, "context": "We use almost the same training process and NN architecture as in [10].", "startOffset": 66, "endOffset": 70}, {"referenceID": 15, "context": "We use the ADAM optimizer [17] with an initial learning rate of 0.", "startOffset": 26, "endOffset": 30}, {"referenceID": 16, "context": "We use gradient clipping [18] with a value of 50.", "startOffset": 25, "endOffset": 29}, {"referenceID": 8, "context": "We use the standard pruned trigram LM of WSJ, as in [10].", "startOffset": 52, "endOffset": 56}, {"referenceID": 17, "context": "We use a RNN architecture of 4 layers of 320 bi-directional LSTM cells [19] without peephole connections [20].", "startOffset": 71, "endOffset": 75}, {"referenceID": 18, "context": "We use a RNN architecture of 4 layers of 320 bi-directional LSTM cells [19] without peephole connections [20].", "startOffset": 105, "endOffset": 109}, {"referenceID": 8, "context": "Decoding with CTC is performed using the TLG WFST and the prior normalization method in [10].", "startOffset": 88, "endOffset": 92}, {"referenceID": 8, "context": "Our CTC model obtains comparable results with the ones reported in [10].", "startOffset": 67, "endOffset": 71}, {"referenceID": 19, "context": "In [21], using CTC, it was found that the network\u2019s prediction of the blank label was too dominant during decoding.", "startOffset": 3, "endOffset": 7}, {"referenceID": 8, "context": "In [10] a different priors normalization method was proposed, which also diminishes the blank predictions.", "startOffset": 3, "endOffset": 7}, {"referenceID": 20, "context": "In [22] it has been shown that the priors subtraction method in [10] might even degrade the WER in some cases.", "startOffset": 3, "endOffset": 7}, {"referenceID": 8, "context": "In [22] it has been shown that the priors subtraction method in [10] might even degrade the WER in some cases.", "startOffset": 64, "endOffset": 68}], "year": 2017, "abstractText": "An hybrid of a hidden Markov model (HMM) and a deep neural network (DNN) is considered. End-to-end training using gradient descent is suggested, similarly to the training of connectionist temporal classification (CTC). We use a maximum a-posteriori (MAP) criterion with a simple language model in the training stage, and a standard HMM decoder without approximations. Recognition results are presented using speech databases. Our method compares favorably to CTC in terms of performance, robustness and quality of alignments.", "creator": "LaTeX with hyperref package"}}}