{"id": "1703.10669", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Feb-2017", "title": "QoS-Aware Multi-Armed Bandits", "abstract": "Motivated by runtime verification of QoS requirements in self-adaptive and self-organizing systems that are able to reconfigure their structure and behavior in response to runtime data, we propose a QoS-aware variant of Thompson sampling for multi-armed bandits. It is applicable in settings where QoS satisfaction of an arm has to be ensured with high confidence efficiently, rather than finding the optimal arm while minimizing regret. Preliminary experimental results encourage further research in the field of QoS-aware decision making.", "histories": [["v1", "Tue, 28 Feb 2017 15:01:51 GMT  (297kb,D)", "http://arxiv.org/abs/1703.10669v1", "Accepted at IEEE Workshop on Quality Assurance for Self-adaptive Self-organising Systems, FAS* 2016"]], "COMMENTS": "Accepted at IEEE Workshop on Quality Assurance for Self-adaptive Self-organising Systems, FAS* 2016", "reviews": [], "SUBJECTS": "cs.LG cs.SE", "authors": ["lenz belzner", "thomas gabor"], "accepted": false, "id": "1703.10669"}, "pdf": {"name": "1703.10669.pdf", "metadata": {"source": "CRF", "title": "QoS-Aware Multi-Armed Bandits", "authors": ["Lenz Belzner", "Thomas Gabor"], "emails": [], "sections": [{"heading": null, "text": "I. INTRODUCTION We look at the problem of exploration and exploitation under uncertainty and QoS requirements. Imagine an intelligent factory control system that is capable of providing potential reconfigurations in response to change events, such as the failure detection of a particular machine. In quality-critical environments, such a situation can lead to downtime until QoS requirements are restored. For example, a factory is required to create products with a guaranteed maximum failure rate. At the same time, confidence in this failure rate should be built up as quickly as possible. One way to enable the verification of QoS requirements at runtime is to perform statistical model verification of the system by using a simulation of the system and its application domain. In this case, i.i.d. Monte Carlo simulations of system execution are performed until satisfaction or violation of a specific requirement is proven that this requirement is functioning up to a given trust ratio. In the face of a number of potential reconfigured QoS in a new situation, two run-time objectives are pursued."}, {"heading": "II. MULTI ARMED BANDITS", "text": "For the sake of simplicity, we limit ourselves to Bernoulli distributions, which result in a value of one with a probability of p, and zero others.A typical task is to identify the optimal arm and at the same time maximize its payment.In the case of Bernoulli bandits, the optimal arm i is the one with the maximum pi. A state-of-the-art approach to the bandit problem is Thompson sampling [3], [4]. It builds up a distribution over possible values, the pi for each arm, which represents the uncertainty of decision-makers (or convictions) about the distribution parameters based on his observations of certain uncertainties. For Bernoulli bandits, a convenient choice for modelling the parameter uncertainty is the beta distribution with the parameters \u03b1 and \u03b2 [5].It is the conjugates before the Bernoulli distributions parameters, which are uncertainties for the selection of uncertainties."}, {"heading": "III. QOS-AWARE THOMPSON SAMPLING", "text": "A basic form of the QoS-conscious Thompson sample (QATS) can be realized by determining the probabilities of QoS injury and satisfaction from the faith distributions of the arms. In fact, we are interested in the probability pv = P (X > p) of the true parameter that violates the QoS requirement q [0, 1]. This property can easily be derived from the cumulative density function of the faith distribution.The probability pu = P (X > p \u00b2 i) = 1 \u2212 P (X \u2264 p \u00b2 i) that a sampled probability p \u00b2 i from a faith distribution underestimates the true parameter of an arm is also derived from the cumulative density function of the faith distribution.To solve the exploration vs. exploitation dilemma in a QoSaware maneuvre, QATS maximizes the probabilities of underestimation vs. QoS injury."}, {"heading": "IV. CONCLUSION", "text": "Motivated by the run-time verification of QoS requirements in self-adaptive and self-organizing systems that are able to configure their structure and behavior in response to run-time data, we proposed QoS-conscious Thompson sampling (QATS) for multi-armed bandits. QATS is applicable in situations where the QoS satisfaction of an arm needs to be efficiently ensured rather than finding the optimal arm while minimizing remorse. Preliminary experimental results are promising and encourage further research in the field of QoS-conscious decision making. It would be interesting to investigate the theoretical properties of QoS-conscious decision algorithms. Another direction would be the integration of risk measures (as in financial decision-making) into Thompson sampling. See [6] for a similar approach based on frequency-based confidence limits."}, {"heading": "ACKNOWLEDGMENT", "text": "The authors would like to thank Matthias Ho \u00be lzl and Martin Wirsing for their insightful discussions."}], "references": [{"title": "Statistical runtime checking of probabilistic properties", "author": ["I. Lee", "O. Sokolsky", "J. Regehr"], "venue": "International Workshop on Runtime Verification. Springer, 2007, pp. 164\u2013175.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2007}, {"title": "Regret analysis of stochastic and nonstochastic multi-armed bandit problems", "author": ["S. Bubeck", "N. Cesa-Bianchi"], "venue": "arXiv preprint arXiv:1204.5721, 2012.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2012}, {"title": "An empirical evaluation of thompson sampling", "author": ["O. Chapelle", "L. Li"], "venue": "Advances in neural information processing systems, 2011, pp. 2249\u2013 2257.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2011}, {"title": "Analysis of thompson sampling for the multiarmed bandit problem.", "author": ["S. Agrawal", "N. Goyal"], "venue": "COLT,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2012}, {"title": "Bayesian statistics: principles, models, and applications", "author": ["S.J. Press", "J.S. Press"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1989}, {"title": "Exploration vs exploitation vs safety: Risk-aware multi-armed bandits.", "author": ["N. Galichet", "M. Sebag", "O. Teytaud"], "venue": "ACML,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2013}, {"title": "Bayesian mixture modelling and inference based thompson sampling in monte-carlo tree search", "author": ["A. Bai", "F. Wu", "X. Chen"], "venue": "Advances in Neural Information Processing Systems, 2013, pp. 1646\u20131654.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "One way to enable verification of QoS requirements at runtime is by performing statistical model checking of the system by using a simulation of the system and its application domain [1].", "startOffset": 183, "endOffset": 186}, {"referenceID": 1, "context": "exploitation in decision making [2].", "startOffset": 32, "endOffset": 35}, {"referenceID": 2, "context": "A state-of-the-art baseline approach to the bandit problem is Thompson sampling [3], [4].", "startOffset": 80, "endOffset": 83}, {"referenceID": 3, "context": "A state-of-the-art baseline approach to the bandit problem is Thompson sampling [3], [4].", "startOffset": 85, "endOffset": 88}, {"referenceID": 4, "context": "For Bernoulli bandits, a convenient choice for modeling parameter uncertainty is the Beta distribution with parameters \u03b1 and \u03b2 [5].", "startOffset": 127, "endOffset": 130}, {"referenceID": 4, "context": "It is the conjugate prior of the Bernoulli distribution, allowing for efficient posterior computation and analysis [5].", "startOffset": 115, "endOffset": 118}, {"referenceID": 2, "context": "state-of-the-art bandit approaches such as UCB [3], [4].", "startOffset": 47, "endOffset": 50}, {"referenceID": 3, "context": "state-of-the-art bandit approaches such as UCB [3], [4].", "startOffset": 52, "endOffset": 55}, {"referenceID": 0, "context": "In fact, we are interested in the probability pv = P (X \u2264 q) of the true parameter violating the QoS requirement q \u2208 [0, 1].", "startOffset": 117, "endOffset": 123}, {"referenceID": 5, "context": "See [6] for a similar approach based on frequentist confidence bounds.", "startOffset": 4, "endOffset": 7}, {"referenceID": 6, "context": "See [7] for an application of Thompson sampling in Monte Carlo Tree Search.", "startOffset": 4, "endOffset": 7}], "year": 2017, "abstractText": "Motivated by runtime verification of QoS requirements in self-adaptive and self-organizing systems that are able to reconfigure their structure and behavior in response to runtime data, we propose a QoS-aware variant of Thompson sampling for multi-armed bandits. It is applicable in settings where QoS satisfaction of an arm has to be ensured with high confidence efficiently, rather than finding the optimal arm while minimizing regret. Preliminary experimental results encourage further research in the field of QoS-aware decision making.", "creator": "LaTeX with hyperref package"}}}