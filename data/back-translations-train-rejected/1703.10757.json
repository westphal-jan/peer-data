{"id": "1703.10757", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-Mar-2017", "title": "Diabetic Retinopathy Detection via Deep Convolutional Networks for Discriminative Localization and Visual Explanation", "abstract": "We proposed a deep learning method for interpretable diabetic retinopathy (DR) detection. The visual-interpretable feature of the proposed method is achieved by adding the regression activation map (RAM) after the global averaging pooling layer of the convolutional networks (CNN). With RAM, the proposed model can localize the discriminative regions of an retina image to show the specific region of interest in terms of its severity level. We believe this advantage of the proposed deep learning model is highly desired for DR detection because in practice, users are not only interested with high prediction performance, but also keen to understand the insights of DR detection and why the adopted learning model works. In the experiments conducted on a large scale of retina image dataset, we show that the proposed CNN model can achieve high performance on DR detection compared with the state-of-the-art while achieving the merits of providing the RAM to highlight the salient regions of the input image.", "histories": [["v1", "Fri, 31 Mar 2017 05:10:56 GMT  (9185kb,D)", "http://arxiv.org/abs/1703.10757v1", null], ["v2", "Mon, 3 Apr 2017 16:44:23 GMT  (9185kb,D)", "http://arxiv.org/abs/1703.10757v2", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG cs.NE", "authors": ["zhiguang wang", "jianbo yang"], "accepted": false, "id": "1703.10757"}, "pdf": {"name": "1703.10757.pdf", "metadata": {"source": "CRF", "title": "Diabetic Retinopathy Detection via Deep Convolutional Networks for Disciminative Localization and Visual Explanation", "authors": ["Zhiguang Wang", "Jianbo Yang"], "emails": ["jianbo.yang}@ge.com"], "sections": [{"heading": "1. Introduction", "text": "It is a widespread disease in the world, and by 2014 around 422 million people worldwide had identified it. Diabetic retinopathy (DR) is an eye disease caused by long-standing diabetes. Basically, the treatment of blood vessels in light-sensitive tissue (i.e. the retina) is very demanding, so it is the leading cause of visual impairment and blindness in today's world, so it is highly desirable that this disease can be detected in practice. Unfortunately, the current DR detection solution is almost impossible to meet this requirement, and the authors contribute equally to this work. 1http: / / www.who.int / factsheets / fs312 / current solution."}, {"heading": "2. Related Work", "text": "However, the two-step (i.e., feature extraction and prediction) automated DR detection approaches dominated the field of DR detection for many years. Given the color-fundus photography, these approaches were often used to extract visual features from the images on the parts of the blood vessels, fovea and optical disc [13, 20]. The generic feature extraction methods that were developed in the computer vision area were widely used here, for example, hough transform, gabor filters and intensity variations. With the extracted properties, an object detection or object detection algorithm such as support vector machines and k-NN were used to identify and locate exudate and bleeding. [15, 16] As mentioned above, this type of approach is not as effective as the recent deep-learning approaches, such as [2, 10, 14, 18] all of these deep-learning approaches have adopted the standard architecture of building on these Net-based learning steps as well as Google's Alexa."}, {"heading": "3. Regression Activation Maps (RAM)", "text": "It is well known that the revolutionary units of the individual layers of CNN act as visual concept detectors to identify low concepts such as textures or materials that make it difficult to identify the significance of each layer for the identification of each layer."}, {"heading": "4. Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1. Datasets", "text": "The color retinal images are downloaded from the Kaggle website3. The training dataset contains 35126 high-resolution images under various imaging conditions. These retinal images were created by a group of subjects, and for each subject two images were created for the left and right eye, respectively. Labels were provided by physicians who rated the presence of diabetic retinopathy in each image on a scale of \"0, 1, 2, 3, 4,\" representing \"no DR,\" \"mild,\" \"moderate,\" \"severe\" and \"proliferative DR.\" As mentioned in the dataset description, the images in the dataset come from various models and camera types that can influence the visual appearance of left3https: / / www.kaggle.com / c / diabetic-retinopathy-detection / data. \""}, {"heading": "4.2. Benchmark method", "text": "We consider the publicly available method [2] to be the benchmark method that took second place in the Kaggle Competition. This method cuts away the entire background and resizes the images to squares of 128, 256 and 512 pixels. Interested readers can refer to [2] for more detailed settings of the baseline method. We summarize the main features of the baseline methods as follows: Resampling First, all classes are selected so that all classes 0 1 2 3 4 Scales0500010000150002000025000C o u n tsi n tra inin g da taInitialization and pretraining Orthogonal Initialization is used to initialize weights and distortions. First, smaller networks are trained on 128 pixel images. Then, the trained weights are used to initialize medium networks (partially) for training on 256 pixel images."}, {"heading": "4.3. Experimental Settings", "text": "We trained our revolutionary neural network in Table 1 on a single Tesla-P100 GPU. For non-linearity, we use leaky (0.01) rectifier units after each revolutionary layer. The networks are trained with the Nesterov impulse, with a fixed timetable over 250 epochs. For the networks on 256 and 128 pixel images, we stop training after 200 epochs. L2 weight decay with factor 0.0005 is applied to all layers. Since we treat the problem as a regression problem, the loss function is a rectangular error. The revolutionary networks have unbound distortions. The batch size is set to 32 for all networks. 4. After the evaluation setting [1], the square weighted Kappa score is assumed as a power metric of the prediction. Specifically, the predicted regression values at the thresholds (0.5, 1.5, 2.5, 3.5) are set to be discredited to obtain values for the calculation of the integral values."}, {"heading": "4.4. Performance of Kappa Score", "text": "Below [2] we divide 35126 images into training and validation data sets at a ratio of 9 to 1 for local evaluation purposes, and we forward our prediction results on the test data set to Kaggle to obtain the Kappa Score. Table 2 summarizes the performance of both the benchmark and our approach on the test data set. By simply replacing the fully connected layer with the global average pooling layer, our networks achieved a very competitive Kappa Score compared to the benchmark, while reducing the parameter size by approximately 21.8% and accelerating training by 11.8% -13.1%. As mentioned in Section 4.2, a feature blending strategy was applied. Thus, the final Kappa Score is an average of six per patient blends for the two revolutionary network architectures and three different sets of trained weights. Considering that the key signals of our 7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x7x"}, {"heading": "4.5. Discriminative Localization by RAM", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.5.1 Network settings for RAM", "text": "To generate RAM, we used Net-5 with the 128 and 256 pixel images as input. In addition, for each input size, we removed several twisted layers of Net-5 to increase the resolution of the RAM, since the localization ability of the RAM can be significantly improved if the last twisted layer before GAP had a higher spatial resolution [24]. Specifically, for Net-5 on the 128 pixel images, we removed the layers after Conv-11 and all steps except Maxpool-8, resulting in a mapping resolution of 54 x 54. For Net-5 on the 256 pixel images, we removed the layers after Conv-15 and the last two maximum pooling layers, resulting in a mapping resolution of 56 x 56. Each of these networks was then fine-tuned to the training data."}, {"heading": "4.5.2 Fusion of multiple RAMs", "text": "Figure 4 (a) and (b) show the RAM from the input images of the size 128 and 256 pixels, respectively, and the corresponding kappa values of 5.06 and 4.63, respectively. We noticed that these RAMs reflect different ROIs, both of which can contribute to the final kappa score prediction. Therefore, we consider 5Train to be similarly powerful from the ground up, but somewhat slower. The merging of the RAM (a) and (b), i.e. the average of the values in RAM matrices, is shown in Figure 4 (c). By referring to the original image shown in Figure 4 (d), we argue that Figure 4 (c) can better capture the ROI of the original image. We found the similar phonomania from other examples as well. We therefore conclude that merging different RAMs from different resolutions is simple and effective in order to represent the comprehensive ROI, so that the merged RAM is only reported in the following analysis."}, {"heading": "4.5.3 Analysis on RAM", "text": "For the mildly conditioned patients, RAM has learned to detect the narrowing of the retinal arteries with reduced retinal blood flow (Figure 5 (d), where the vessel is dark red. Dysfunction of the neurons of the inner retina, followed by changes in the function of the outer retina are shown in Figure 5 (c), as if such dysfunction protects the retina from many substances in the blood (including toxins and immune cells) that lead to the leakage of blood stores into the retina. If the patients belong to the next stage (severe), the basement membrane of the retina is separated from the digestive diktate."}, {"heading": "5. Conclusions", "text": "In practice, clinicians can identify DR by the presence of lesions associated with vascular abnormalities caused by the disease. Although this approach is effective, its resource requirements are high. As part of this work, we have developed an in-depth learning model that includes regression activation maps (RAM).The RAM layer can provide the robust interpretability of the proposed detection model by monitoring pathogenesis so that the proposed model can be used as an assistant for clinicians.With this feature, the proposed model can still provide the competitive performance of DR detection compared to the most advanced methods. In the future, we would consider extending the proposed method to other medical application problems."}], "references": [{"title": "Kaggle Diabetic Retinopathy Detection", "author": ["M. Antony", "S. Brggemann"], "venue": "Team o O solution,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2015}, {"title": "Self-taught object alization with deep networks", "author": ["L. Bazzani", "A. Bergamo", "D. Anguelov", "L. Torresani"], "venue": "IEEE Winter Conference on Applications of Computer Vision (WACV),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2016}, {"title": "Learning deep architectures for AI", "author": ["Y. Bengio"], "venue": "Found. Trends Mach. Learn.,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2009}, {"title": "A tutorial survey of architectures, algorithms, and applications for deep learning", "author": ["L. Deng"], "venue": "APSIPA Transactions on Signal and Information Processing,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "Inverting visual representations with convolutional networks", "author": ["A. Dosovitskiy", "T.Brox"], "venue": "In CVPR,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2016}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "In NIPS,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2012}, {"title": "Backpropagation applied to handwritten zip code recognition", "author": ["Y. LeCun", "B. Boser", "J.S. Denker", "D. Henderson", "R.E. Howard", "W. Hubbard", "L.D. Jackel"], "venue": "Neural Computation,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1989}, {"title": "Efficient backprop. Neural Networks: Tricks of the trade, pages", "author": ["Y. LeCun", "L. Bottou", "G. Orr", "K. Muller"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1998}, {"title": "Transformed representations for convolutional neural networks in diabetic retinopathy screening", "author": ["G. Lim", "M.L. Lee", "W. Hsu", "T.Y. Wong"], "venue": "In AAAI Workshop on Modern Artificial Intelligence for Health Analytics (MAIHA),", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "Understanding deep image representations by inverting them", "author": ["A. Mahendran", "A. Vedaldi"], "venue": "In CVPR,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2015}, {"title": "Learning and transferring mid-level image representations using convolutional neural networks", "author": ["M. Oquab", "L. Bottou", "I. Laptev", "J. Sivic"], "venue": "In CVPR,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2014}, {"title": "Mapping the human retina", "author": ["A. Pinz", "S. Bernogger", "P. Datlinger", "A. Kruger"], "venue": "IEEE Transactions on Medical Imaging,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1998}, {"title": "Convolutional neural networks for diabetic retinopathy", "author": ["H. Pratta", "F. Coenenb", "D.M. Broadbentc", "S.P. Hardinga", "Y. Zheng"], "venue": "In International Conference On Medical Imaging Understanding and Analysis (MIUA),", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2016}, {"title": "Case for automated detection of diabetic retinopathy", "author": ["N. Silberman", "K. Ahrlich", "R. Fergus", "L. Subramanian"], "venue": "In AAAI Spring Symposium: Artificial Intelligence for Development. AAAI,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2010}, {"title": "Automatic exudate detection from non-dilated diabetic retinopathy retinal images using fuzzy c-means clustering", "author": ["A. Sopharak", "B. Uyyanonvara", "S. Barman"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2009}, {"title": "Going deeper with convolutions", "author": ["C. Szegedy", "W. Liu", "Y. Jia", "P. Sermanet", "S. Reed", "D. Anguelov", "D. Erhan", "V. Vanhoucke", "A. Rabinovich"], "venue": "In CVPR,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2015}, {"title": "Hierarchical retinal blood vessel segmentation based on feature and ensemble learning", "author": ["S. Wang", "Y. Yin", "G. Cao", "B. Wei", "Y. Zheng", "G. Yang"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2015}, {"title": "Time series classification from scratch with deep neural networks: A strong baseline", "author": ["Z. Wang", "W. Yan", "T. Oates"], "venue": "arXiv preprint arXiv:1611.06455,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2016}, {"title": "On the adaptive detection of blood vessels in retinal images", "author": ["D. Wu", "M. Zhang", "J.-C. Liu", "W. Bauman"], "venue": "IEEE Transactions on Biomedical Engineering,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2006}, {"title": "Deep convolutional neural networks on multichannel time series for human activity recognition", "author": ["J.B. Yang", "M.N. Nguyen", "P.P. San", "X.L. Li", "S. Krishnaswamy"], "venue": "In IJCAI,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2015}, {"title": "Visualizing and understanding convolutional networks", "author": ["M.D. Zeiler", "R. Fergus"], "venue": "In ECCV,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2014}, {"title": "Object detectors emerge in deep scene cnns", "author": ["B. Zhou", "A. Khosla", "\u00c0. Lapedriza", "A. Oliva", "A. Torralba"], "venue": "In ICLR,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2015}, {"title": "Learning deep features for discriminative localization", "author": ["B. Zhou", "A. Khosla", "\u00c0. Lapedriza", "A. Oliva", "A. Torralba"], "venue": "In CVPR,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2016}], "referenceMentions": [{"referenceID": 13, "context": "It becomes the leading cause of vision impairment and blindness for working-age adults in the world today[15], and around half of Americans with diabetes have this disease to some extent.", "startOffset": 105, "endOffset": 109}, {"referenceID": 11, "context": "Most of previous automated solutions consists of two parts: feature extraction and detection/prediction algorithm [13, 15, 16, 20].", "startOffset": 114, "endOffset": 130}, {"referenceID": 13, "context": "Most of previous automated solutions consists of two parts: feature extraction and detection/prediction algorithm [13, 15, 16, 20].", "startOffset": 114, "endOffset": 130}, {"referenceID": 14, "context": "Most of previous automated solutions consists of two parts: feature extraction and detection/prediction algorithm [13, 15, 16, 20].", "startOffset": 114, "endOffset": 130}, {"referenceID": 18, "context": "Most of previous automated solutions consists of two parts: feature extraction and detection/prediction algorithm [13, 15, 16, 20].", "startOffset": 114, "endOffset": 130}, {"referenceID": 2, "context": "It can model high-level abstractions in data relative to specific prediction task [4, 5, 8, 9, 21].", "startOffset": 82, "endOffset": 98}, {"referenceID": 3, "context": "It can model high-level abstractions in data relative to specific prediction task [4, 5, 8, 9, 21].", "startOffset": 82, "endOffset": 98}, {"referenceID": 6, "context": "It can model high-level abstractions in data relative to specific prediction task [4, 5, 8, 9, 21].", "startOffset": 82, "endOffset": 98}, {"referenceID": 7, "context": "It can model high-level abstractions in data relative to specific prediction task [4, 5, 8, 9, 21].", "startOffset": 82, "endOffset": 98}, {"referenceID": 19, "context": "It can model high-level abstractions in data relative to specific prediction task [4, 5, 8, 9, 21].", "startOffset": 82, "endOffset": 98}, {"referenceID": 11, "context": "Given color fundus photography, this type of approaches often extracted visual features from the images on the parts of blood vessels, fovea and optic disc [13, 20].", "startOffset": 156, "endOffset": 164}, {"referenceID": 18, "context": "Given color fundus photography, this type of approaches often extracted visual features from the images on the parts of blood vessels, fovea and optic disc [13, 20].", "startOffset": 156, "endOffset": 164}, {"referenceID": 13, "context": "With the extracted features, an object detection or object registration algorithm like support vector machines and k-NN were used to identify and localize exudates and hemorrhages [15, 16].", "startOffset": 180, "endOffset": 188}, {"referenceID": 14, "context": "With the extracted features, an object detection or object registration algorithm like support vector machines and k-NN were used to identify and localize exudates and hemorrhages [15, 16].", "startOffset": 180, "endOffset": 188}, {"referenceID": 0, "context": "As mentioned before, this type of approaches are not as effective as the recent deep learning approaches, such as [2, 10, 14, 18].", "startOffset": 114, "endOffset": 129}, {"referenceID": 8, "context": "As mentioned before, this type of approaches are not as effective as the recent deep learning approaches, such as [2, 10, 14, 18].", "startOffset": 114, "endOffset": 129}, {"referenceID": 12, "context": "As mentioned before, this type of approaches are not as effective as the recent deep learning approaches, such as [2, 10, 14, 18].", "startOffset": 114, "endOffset": 129}, {"referenceID": 16, "context": "As mentioned before, this type of approaches are not as effective as the recent deep learning approaches, such as [2, 10, 14, 18].", "startOffset": 114, "endOffset": 129}, {"referenceID": 20, "context": "A deconvolutional networks approach was proposed to visualize activated pattern in each hidden unit [22].", "startOffset": 100, "endOffset": 104}, {"referenceID": 1, "context": "The work [3, 12, 23] and the reference therein include the objection location task besides the conventional object classification problem, so their CNN can predict the label of an image and also identify the region of the object related to the class label.", "startOffset": 9, "endOffset": 20}, {"referenceID": 10, "context": "The work [3, 12, 23] and the reference therein include the objection location task besides the conventional object classification problem, so their CNN can predict the label of an image and also identify the region of the object related to the class label.", "startOffset": 9, "endOffset": 20}, {"referenceID": 21, "context": "The work [3, 12, 23] and the reference therein include the objection location task besides the conventional object classification problem, so their CNN can predict the label of an image and also identify the region of the object related to the class label.", "startOffset": 9, "endOffset": 20}, {"referenceID": 4, "context": "Recently, [6, 11] have presented the methods to invert the representation of images in each layer of the CNN.", "startOffset": 10, "endOffset": 17}, {"referenceID": 9, "context": "Recently, [6, 11] have presented the methods to invert the representation of images in each layer of the CNN.", "startOffset": 10, "endOffset": 17}, {"referenceID": 22, "context": "The most work most related to our method is [24] in which class activation map is proposed to characterize the weighted activation maps after global average pooling or global maximum pooling layer.", "startOffset": 44, "endOffset": 48}, {"referenceID": 17, "context": "This idea has recently been generalized to time series analysis to localize the significant regions in the raw data [19].", "startOffset": 116, "endOffset": 120}, {"referenceID": 22, "context": "In this paper, we extend the method [24] from a classification to a regression setting and shed light on DR detection problem.", "startOffset": 36, "endOffset": 40}, {"referenceID": 22, "context": "Inspired by [24], we present in this section the idea of generating the RAM of an input image to localize the discriminative region towards the regression outcomes.", "startOffset": 12, "endOffset": 16}, {"referenceID": 5, "context": "The key difference between our neural network and conventional neural networks like AlexNet [7] and GoogLeNet [17] lie in that our network uses global averaging pooling (GAP) layer to connect the last convolutional layer and the output layer, instead of using fully-connected layers.", "startOffset": 92, "endOffset": 95}, {"referenceID": 15, "context": "The key difference between our neural network and conventional neural networks like AlexNet [7] and GoogLeNet [17] lie in that our network uses global averaging pooling (GAP) layer to connect the last convolutional layer and the output layer, instead of using fully-connected layers.", "startOffset": 110, "endOffset": 114}, {"referenceID": 0, "context": "We consider the publicly-available method [2] as the benchmark method, which was ranked as the second place in the Kaggle competition.", "startOffset": 42, "endOffset": 45}, {"referenceID": 0, "context": "The interested readers may refer to [2] for more detailed settings of the baseline method.", "startOffset": 36, "endOffset": 39}, {"referenceID": 0, "context": "Following [2], we split 35126 images into training and validation datasets in a ratio of 9 to 1 for local evaluation purpose, and we also submit our prediction results on the test dataset to Kaggle to obtain the Kappa score.", "startOffset": 10, "endOffset": 13}, {"referenceID": 22, "context": "We also removed several convolutional layers of Net-5 for each input size to increase the resolution of RAM, since the localization ability of RAM can be significantly improved when the last convolutional layer before GAP had a higher spatial resolution [24].", "startOffset": 254, "endOffset": 258}], "year": 2017, "abstractText": "We proposed a deep learning method for interpretable diabetic retinopathy (DR) detection. The visualinterpretable feature of the proposed method is achieved by adding the regression activation map (RAM) after the global averaging pooling layer of the convolutional networks (CNN). With RAM, the proposed model can localize the discriminative regions of an retina image to show the specific region of interest in terms of its severity level. We believe this advantage of the proposed deep learning model is highly desired for DR detection because in practice, users are not only interested with high prediction performance, but also keen to understand the insights of DR detection and why the adopted learning model works. In the experiments conducted on a large scale of retina image dataset, we show that the proposed CNN model can achieve high performance on DR detection compared with the state-ofthe-art while achieving the merits of providing the RAM to highlight the salient regions of the input image.", "creator": "LaTeX with hyperref package"}}}