{"id": "1704.00045", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Mar-2017", "title": "Comparison of ontology alignment algorithms across single matching task via the McNemar test", "abstract": "Ontology alignment is widely used to find the correspondences between different ontologies in diverse fields. After discovering the alignment by methods, several performance scores are available to evaluate them. The scores require the produced alignment by a method and the reference alignment containing the underlying actual correspondences of the given ontologies. The current trend in alignment evaluation is to put forward a new score and to compare various alignments by juxtaposing their performance scores. However, it is substantially provocative to select one performance score among others for comparison. On top of that, claiming if one method has a better performance than one another can not be substantiated by solely comparing the scores. In this paper, we propose the statistical procedures which enable us to theoretically favor one method over one another. The McNemar test is considered as a reliable and suitable means for comparing two ontology alignment methods over one matching task. The test applies to a 2 x 2 contingency table which can be constructed in two different ways based on the alignments, each of which has their own merits/pitfalls. The ways of the contingency table construction and various apposite statistics from the McNemar test are elaborated in minute detail. In the case of having more than two alignment methods for comparison, the family-wise error rate is expected to happen. Thus, the ways of preventing such an error are also discussed. A directed graph visualizes the outcome of the McNemar test in the presence of multiple alignment methods. From this graph, it is readily understood if one method is better than one another or if their differences are imperceptible. Our investigation on the methods participated in the anatomy track of OAEI 2016 demonstrates that AML and CroMatcher are the top two methods and DKP-AOM and Alin are the bottom two ones.", "histories": [["v1", "Wed, 29 Mar 2017 15:20:01 GMT  (387kb)", "http://arxiv.org/abs/1704.00045v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["majid mohammadi", "amir ahooye atashin", "wout hofman", "yaohua tan"], "accepted": false, "id": "1704.00045"}, "pdf": {"name": "1704.00045.pdf", "metadata": {"source": "META", "title": "Comparison of ontology alignment algorithms across single matching task via the McNemar test", "authors": [], "emails": [], "sections": [{"heading": null, "text": "In fact, most people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to"}, {"heading": "1 INTRODUCTION", "text": "In fact, it is not the case that one sees oneself in a position to outdo oneself, but that one outdoes oneself, by outdoing oneself, by outdoing oneself, by outdoing oneself, by outdoing oneself, by outdoing oneself, by outdoing oneself, by outdoing oneself, by outdoing oneself, by outdoing oneself, by outdoing oneself, by outdoing oneself, by outdoing oneself, by outdoing oneself, by overdoing oneself, by outdoing oneself, by outdoing oneself, by outdoing oneself, by outdoing oneself, by outdoing oneself, by outdoing oneself, by outdoing oneself, by outdoing oneself, by outdoing oneself, by outdoing oneself, by outdoing onesoneself, by outdoing onesonesonesonesoneself, by overdoing onesonesonesonesonesonesonesoneself, by outdoing onesonesonesonesonesonesonesonesonesonesoneself, by overdoing, by overdoing onesonesonesonesonesonesonesonesonesonesonesonesonesonesonesonesonesonesoneself, by overdoing, by overdoing, by overdoing, by outdoing onesonesonesonesonesonesonesonesonesonesonesonesonesonesonesonesonesonesonesonesonesonesoneself, by overdoing, by outdoing, by outdoing, by outdoing onesonesonesonesonesonesonesonesonesonesonesonesonesonesonesonesonesonesonesonesonesonesonesonesonesoneself, in overdoing, in overdoing, by outdoing, by outdoing onesonesonesonesonesonesonesonesonesonesonesonesonesonesonesonesonesonesonesonesing, by"}, {"heading": "2 CONTINGENCY TABLE CONSTRUCTION", "text": "This year it is more than ever before."}, {"heading": "3 MCNEMAR TEST", "text": "After creating the random table, it is time to perform the McNemar test. Before we elaborate the McNemar test, we pull off a list to explain the test of the null hypothesis. To use a statistical test, the null and alternative hypotheses are required. However, the null hypothesis H0 states that the difference between two populations is insigni cant and not random. To reject or maintain H0, we must calculate the p value and compare it to the signi cant level \u03b1, which must be determined before the test. e p value is the probability of obtaining a result that is equal to or even more extreme than the observations (Sheskin 2003). If the p value of the population is lower than the nominal signal level."}, {"heading": "3.1 The asymptotic McNemar test", "text": "The easymptoticMcNemar test assumes that n01 is distributed binomically with p = 0.5 and the parameters n = n01 + n10 below the null hypothesis (McNemar 1947). e asymptotic McNemar test statistic\u03c72 = (n01 \u2212 n10) 2n01 \u2212 n10 is distributed with a degree of freedom according to \u03c72. is test is unde ned for n01 = n10 = 0. To refute the null hypothesis, this test requires a certain number of data (n01 + n10 \u2265 25) as it could violate the nominal signal level \u03b1 for the small sample size."}, {"heading": "3.2 The McNemar exact test", "text": "In this test, n01 is compared with a binomial distribution using the parameters ACM Transactions on Knowledge Discovery from Data, Vol. 0, No. 0, Article 0. Release date: 2017.n = n01 + n10 and p = 0.5. us, the p-value for this test is multiplied as the exact p-value = n \u2211 x = n01 (nx) (12) 2e one-sided p-value by two to obtain the double-sided p-value."}, {"heading": "3.3 The asymptotic McNemar test with continuity correction", "text": "The main disadvantage of the McNemar test is conservatism, although it maintains the nominal signal edge level: it generates unnecessarily large p-values, so that the null hypothesis cannot be discarded. Edwards (Edwards 1948) approached the exact p-value as a remedy against conservatism through the following continuity correction of statistical classification.2 = (| b \u2212 c | \u2212 1) 2b + can, which comes with a degree of liberty. is test is also unned for n01 = n10 = 0."}, {"heading": "3.4 The McNemar mid-p test", "text": "The method of continuity correction is not as conservative as the McNemar test, but it does not guarantee the maintenance of the nominal signal edge level (Lancaster 1961). Therefore, a simple modification is required to obtain the mean p-value: the mean p-value corresponds to the exact p-value minus half the point probability of the observed test statistics (Fagerland et al. 2013). Therefore, the p-value asmid-p-value = 2-sided exact p-value \u2212 (nn01) 0.5n. e The McNemar mid-p test resolves the conservatism of the exact test, but does not theoretically guarantee the maintenance of the nominal signal edge level. However, in a recent study it is investigated that the mean p-test has a low error of type I and does not violate the signal comparison, but it shows the high test edge level, the high continuity test has a high error of type I."}, {"heading": "4 FAMILY-WISE ERROR RATE AND P-VALUE ADJUSTMENT", "text": "If there are two comparison methods, the null hypothesis is discarded if the p-value obtained is below the nominal error rate \u03b1. If more than two alignment algorithms are available for comparison, the known familial error rate (FWER) could occur. FWER refers to increasing the probability of a type I error that is likely to violate the nominal error threshold \u03b1 if multiple populations are to be compared. To explain what FWER is, assume that there are 5 comparison methods and the error threshold is \u03b1 = 0.05. If all paired comparisons are desired, then there are k = 5 x 4 / 2 = 10 hypotheses in total. For each of the zero hypotheses, the probability of rejection without occurrence of the type I error is equal to 1 \u2212 \u03b1 = 0.95. For all comparisons, however, the probability of having no type I error is zero."}, {"heading": "4.1 Controlling FWER in N \u00d7 1 comparison", "text": "When a new alignment method is proposed, it is usually compared with other state-of-the-art alignments. In order to compare n methods (including the proposed method), in this case k = n \u2212 1 comparison must be performed. These are four methods that can control the familial error rate in N \u00b7 1 comparison. These methods can be regarded as p-value alignment procedures that modify p values in such a way that the adjusted p-values (APV) can be directly compared with the signal edge level, while the nominal signal level is also conserved. A zero hypothesis is rejected if their corresponding p-values are below the nominal value. LetHi, i = 1, k are all hypotheses for nMethods andpi, i = 1..., k is their corresponding p-valuations. e Bonferronis Method (Dunn 1961) is the easiest way to prevent FER."}, {"heading": "4.2 Controlling FWER in N \u00d7 N comparison", "text": "For conducting all paired comparisons, if n methods are available, there are k = n (n \u2212 1) / 2 hypotheses altogether not applicable. e Nemenyi's method (Nemenyi 1963) is the Bonferroni's method when there is a comparison with the N \u00b7 N methods, i.e. k = n (n \u2212 1) / 2. to us, it has a high type II error that causes the hypotheses to not be recognized in the population when there is a comparation. e same approach of k must be applied to other methods so that they are suitable for N \u00b7 N comparisons. ere is also another sequential-rejective zero hypothesis that is suitable for N \u00b7 N comparison and ACM transactions on data, Vol. 0, No. 0. Release date: 2017.takes into account the logical relationships between hypotheses. Sha er (Sha 1986) discovered that the Holm method could be improved if hypotheses are logically related to each other."}, {"heading": "5 RESULTS", "text": "In this section, the above-mentioned statistical methods are applied to the anatomy paths of OAEI 2016, and the corresponding results are reported. Furthermore, the measurements of string similarity are compared and sorted according to the number of correct discoveries. We have two ways to obtain the contingency table, four McNemar tests, and four ways to FWER.erefore, there are a total of 32 states for comparison. For reasons of simplicity (and probably because of the exclusion of duplication), we consider only four states: the two ways of constructing the contingency table compared to the McNemar mid-p test, and the control of FWER by Nemenyi's and Bergmann's correction, the most conservative and robust methods behind the mid-p test selection is that it is not as conservative as the accurate test and is less likely to violate the nominal signal plane."}, {"heading": "6 CONCLUSION", "text": "The current approach to alignment comparison is to first select a performance score and then compare two methods by obtaining their performance scores for a reference alignment task. In this article, the alignment created by two methods and the reference alignment are indicated, and the result is when two methods are signal-like dierent. Output is not a score, but in order / not to declare agreement between two ontology matching algorithms. Furthermore, ways to avoid familial error rates that are likely to occur when comparing multiple (> 2) alignment methods. e proposed methods are applied to the anatomy gauge of Ontology Alignment Initiative Assessments (OAEI) 2016."}], "references": [{"title": "2016a. Results of the Ontology Alignment Evaluation Initiative 2016", "author": ["Valentina Ivanova", "others"], "venue": "In 11th ISWC workshop on ontology", "citeRegEx": "Ivanova and others.,? \\Q2016\\E", "shortCiteRegEx": "Ivanova and others.", "year": 2016}, {"title": "2016b. Results of the Ontology Alignment Evaluation Initiative 2016", "author": ["Valentina Ivanova", "others"], "venue": "In 11th ISWC workshop on ontology", "citeRegEx": "Ivanova and others.,? \\Q2016\\E", "shortCiteRegEx": "Ivanova and others.", "year": 2016}, {"title": "Decision trees in automatic ontology matching", "author": ["Siham Amrouch", "Sihem Mostefai", "Muhammad Fahad"], "venue": null, "citeRegEx": "Amrouch et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Amrouch et al\\.", "year": 2016}, {"title": "Multiple Hypothesenpr\u00fcfung/Multiple Hypotheses Testing", "author": ["William Cohen", "Pradeep Ravikumar", "Stephen Fienberg"], "venue": "Kdd", "citeRegEx": "Cohen et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Cohen et al\\.", "year": 2003}, {"title": "ALIN Results for OAEI 2016", "author": ["Warith Eddine Djeddi", "Mohammed Tarek Khadir"], "venue": "workshop on data cleaning and object consolidation,", "citeRegEx": "Djeddi and Khadir.,? \\Q2016\\E", "shortCiteRegEx": "Djeddi and Khadir.", "year": 2016}, {"title": "Multiple comparisons among means", "author": ["Olive Jean Dunn"], "venue": "Machine and Web Intelligence (ICMWI),", "citeRegEx": "Dunn.,? \\Q2010\\E", "shortCiteRegEx": "Dunn.", "year": 2010}, {"title": "Ontology mapping\u2013an integrated approach", "author": ["Marc Ehrig", "York Sure"], "venue": "Psychometrika 13,", "citeRegEx": "Ehrig and Sure.,? \\Q1948\\E", "shortCiteRegEx": "Ehrig and Sure.", "year": 1948}, {"title": "be\u008aer than exact conditional", "author": ["Daniel Faria", "Catia Pesquita", "Emanuel Santos", "Ma\u008aeo Palmonari", "Isabel F Cruz", "Francisco M Couto"], "venue": "BMC medical research methodology 13,", "citeRegEx": "Faria et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Faria et al\\.", "year": 2013}, {"title": "On a monotonicity problem in step-down multiple test procedures", "author": ["M. Mohammadi"], "venue": "Finner", "citeRegEx": "Mohammadi,? \\Q1993\\E", "shortCiteRegEx": "Mohammadi", "year": 1993}, {"title": "A simple sequentially rejective multiple test procedure. Scandinavian journal of statistics", "author": ["417\u2013423. Sture Holm"], "venue": null, "citeRegEx": "Holm.,? \\Q1979\\E", "shortCiteRegEx": "Holm.", "year": 1979}, {"title": "Ma\u008ahew A Jaro", "author": ["Ernesto Jim\u00e9nez-Ruiz", "Bernardo Cuenca Grau"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews) 42,", "citeRegEx": "Jim\u00e9nez.Ruiz and Grau.,? \\Q2012\\E", "shortCiteRegEx": "Jim\u00e9nez.Ruiz and Grau.", "year": 2012}, {"title": "Signi\u0080cance tests in discrete distributions", "author": ["115\u2013126. HO Lancaster"], "venue": "J. Amer. Statist. Assoc", "citeRegEx": "Lancaster.,? \\Q1961\\E", "shortCiteRegEx": "Lancaster.", "year": 1961}, {"title": "Managing uncertainty in schema matcher ensembles", "author": ["707\u2013710. Anan Marie", "Avigdor Gal"], "venue": "In International Conference on Scalable Uncertainty", "citeRegEx": "Marie and Gal.,? \\Q2007\\E", "shortCiteRegEx": "Marie and Gal.", "year": 2007}, {"title": "Shiva: A Framework for Graph Based Ontology Matching", "author": ["Management. Springer", "60\u201373. Iti Mathur", "Nisheeth Joshi", "Hemant Darbari", "Ajai Kumar"], "venue": null, "citeRegEx": "Springer et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Springer et al\\.", "year": 2014}, {"title": "LPHOM results for OAEI 2016", "author": ["Imen Megdiche", "Olivier Teste", "Cassia Trojahn"], "venue": "Ontology Matching", "citeRegEx": "Megdiche et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Megdiche et al\\.", "year": 2016}, {"title": "Dssim-ontology mapping with uncertainty", "author": ["Miklos Nagy", "Maria Vargas-Vera", "Enrico Mo\u008aa"], "venue": null, "citeRegEx": "Nagy et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Nagy et al\\.", "year": 2006}, {"title": "Distribution-free multiple comparisons", "author": ["Dominique Ritze", "Heiko Paulheim", "Kai Eckert"], "venue": "Journal of molecular biology 48,", "citeRegEx": "Ritze et al\\.,? \\Q1970\\E", "shortCiteRegEx": "Ritze et al\\.", "year": 1970}, {"title": "Modi\u0080ed sequentially rejective multiple test procedures", "author": ["Press. Giorgos Stoilos", "Giorgos Stamou", "Stefanos Kollias"], "venue": "International Semantic Web Conference", "citeRegEx": "Stoilos et al\\.,? \\Q1986\\E", "shortCiteRegEx": "Stoilos et al\\.", "year": 1986}, {"title": "\u008ce 2 x 2 matched-pairs trial: Exact unconditional design and analysis", "author": ["Springer", "624\u2013637. Samy Suissa", "Jonathan J Shuster"], "venue": "Biometrics", "citeRegEx": "Springer et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Springer et al\\.", "year": 1991}, {"title": "\u008ce lack of a priori distinctions between learning algorithms", "author": ["Citeseer. David H Wolpert."], "venue": "Neural computation 8, 7 (1996), 1341\u20131390. David H Wolpert. 2012. What the no free lunch theorems really mean; how to improve search algorithms. In Santa fe Institute Working", "citeRegEx": "Wolpert.,? 1996", "shortCiteRegEx": "Wolpert.", "year": 1996}, {"title": "No free lunch theorems for optimization", "author": ["Paper. 12. David H Wolpert", "William G Macready"], "venue": "IEEE transactions on evolutionary computation", "citeRegEx": "Wolpert and Macready.,? \\Q1997\\E", "shortCiteRegEx": "Wolpert and Macready.", "year": 1997}, {"title": "FCA-Map Results for OAEI 2016", "author": ["Mengyi Zhao", "Songmao Zhang"], "venue": "Ontology Matching", "citeRegEx": "Zhao and Zhang.,? \\Q1997\\E", "shortCiteRegEx": "Zhao and Zhang.", "year": 1997}], "referenceMentions": [{"referenceID": 3, "context": "\u008ce \u0080rst category is the string-based measure which only considers the text of concepts to declare their similarities (Cohen et al. 2003; Levenshtein 1966; Stoilos et al. 2005).", "startOffset": 117, "endOffset": 175}, {"referenceID": 15, "context": "However, this focus has moved to take advantages of various similarity measures and try to reason the correspondences based on outcomes of di\u0082erent similarity measures (Jan et al. 2012; Nagy et al. 2006).", "startOffset": 168, "endOffset": 203}, {"referenceID": 7, "context": "We select 10 methods participated in OAEI 2016 for conducting the comparison: Alin (da Silva 2016), AML (Faria et al. 2013), CroMatcher (Achichi et al.", "startOffset": 104, "endOffset": 123}, {"referenceID": 2, "context": "2016a), DKP-AOM (Amrouch et al. 2016), FCA-Map (Zhao and Zhang 2016), Lily (Wang and Xu 2008), LogMapLite (Jim\u00e9nez-Ruiz and Grau 2011), LPHOM (Megdiche et al.", "startOffset": 16, "endOffset": 37}, {"referenceID": 14, "context": "2016), FCA-Map (Zhao and Zhang 2016), Lily (Wang and Xu 2008), LogMapLite (Jim\u00e9nez-Ruiz and Grau 2011), LPHOM (Megdiche et al. 2016), LYAM (Achichi et al.", "startOffset": 110, "endOffset": 132}], "year": 2017, "abstractText": "Ontology alignment is widely used to \u0080nd the correspondences between di\u0082erent ontologies in diverse \u0080elds. A\u0089er discovering the alignment by methods, several performance scores are available to evaluate them. \u008ce scores require the produced alignment by amethod and the reference alignment containing the underlying actual correspondences of the given ontologies. \u008ce current trend in alignment evaluation is to put forward a new score and to compare various alignments by juxtaposing their performance scores. However, it is substantially provocative to select one performance score among others for comparison. On top of that, claiming if one method has a be\u008aer performance than one another can not be substantiated by solely comparing the scores. In this paper, we propose the statistical procedures which enable us to theoretically favor one method over one another. \u008ce McNemar test is considered as a reliable and suitable means for comparing two ontology alignment methods over one matching task. \u008ce test applies to a 2 \u00d7 2 contingency table which can be constructed in two di\u0082erent ways based on the alignments, each of which has their own merits/pitfalls. \u008ce ways of the contingency table construction and various apposite statistics from the McNemar test are elaborated in minute detail. In the case of having more than two alignment methods for comparison, the family-wise error rate is expected to happen. \u008cus, the ways of preventing such an error are also discussed. A directed graph visualizes the outcome of the McNemar test in the presence of multiple alignment methods. From this graph, it is readily understood if one method is be\u008aer than one another or if their di\u0082erences are imperceptible. Our investigation on the methods participated in the anatomy track of OAEI 2016 demonstrates that AML and CroMatcher are the top two methods and DKP-AOM and Alin are the bo\u008aom two ones. Moreover, the Levenstein and N-gram string-based distances discover the most correspondences while SMOA and Hamming distance are the ones with the least found correspondences.", "creator": "LaTeX with hyperref package"}}}