{"id": "1704.00108", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Apr-2017", "title": "Assortment Optimization under Unknown MultiNomial Logit Choice Models", "abstract": "Motivated by e-commerce, we study the online assortment optimization problem. The seller offers an assortment, i.e. a subset of products, to each arriving customer, who then purchases one or no product from her offered assortment. A customer's purchase decision is governed by the underlying MultiNomial Logit (MNL) choice model. The seller aims to maximize the total revenue in a finite sales horizon, subject to resource constraints and uncertainty in the MNL choice model. We first propose an efficient online policy which incurs a regret $\\tilde{O}(T^{2/3})$, where $T$ is the number of customers in the sales horizon. Then, we propose a UCB policy that achieves a regret $\\tilde{O}(T^{1/2})$. Both regret bounds are sublinear in the number of assortments.", "histories": [["v1", "Sat, 1 Apr 2017 02:37:53 GMT  (43kb)", "http://arxiv.org/abs/1704.00108v1", "16 pages, 2 figures"]], "COMMENTS": "16 pages, 2 figures", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["wang chi cheung", "david simchi-levi"], "accepted": false, "id": "1704.00108"}, "pdf": {"name": "1704.00108.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 170 4.00 108v 1 [cs.L G] 1A pr2 01O (T 2 / 3), where T is the number of customers in the sales horizon. Then, we propose a UCB policy that achieves a repentance O (T 1 / 2). Both limits of repentance are sublinear in the number of ranges."}, {"heading": "1 Introduction", "text": "During an online sale, a salesperson offers an incoming customer a hand-picked assortment, i.e. a subset of products, and the customer's decision to buy depends crucially on the assortment they offer. It first reviews all the products in the assortment and then decides which product it regrets the most. Afterwards, it either buys its favorite or does not buy anything if its willingness to pay is below the price of its favorite. Such selection behavior is captured by the underlying selection model, which has been extensively studied by economic and operations research communities [Ben-Akiva and Lerman, 1985]. To maximize the total turnover of an online sale, the salesperson needs to know the underlying selection model, but the model is often not known in practice, which motivates the salesperson to maximize his income and learn the underlying selection model at the same time."}, {"heading": "2 Literature Review and Our Contributions", "text": "In fact, it is that most people are able to understand themselves and themselves. (...) It is not that they are able to understand themselves. \"(...)\" It is as if. \"(...)\" It is as if. \"(...)\" It is as if. \"(...)\" It is as if. \"(...)\" It is as if. \"(...)\" It is as if. \"(...)\" It is as if. \"(...)\" It is as if. \"(...)\" It is as if. \"(...)\" It is as if. \"(...)\" It is as if. \"(...)\" It is. \"(...)\" It is as if. \"(...)\" It is. \"(...)\" It is as if. \"(...)\" It is. \"(...\" It is. \"It is.\" (...) \"It is as if.\" (... \"It is.\" It is. \"It is.\" It is. (... \"It is.\" It is. \"It is.\" It is. (... \"It is.\" It is. \"It is.\" It is. \"It is. (...\" It is. \"It is.\" It is. \"It is.\" It is. (... \"It is.\" It is. \"It is.\" It is. (... \"It is.\" It is. \"It is. (...\" It. \"It is.\" It. \"It is.\" It is. \"It.\" It is. \"It. (...\" It. \"It is.\" It is. \"It is.\" It is. \"It is.\" It. (.... \"It.\" It is. \"It is.\"). \"It is.\" It is. \"It is.\" It is. (.... \"It.\""}, {"heading": "3 Problem Definition", "text": "We formulate the online assortment optimization problem with an unknown MultiNomial Logit (MNL) that offers the purchased product. The seller has a series of products (v = 1), but he uses a (i, k) amount of resources (K = 1,.., K) to assemble the products. The sale of a product generates a turnover of r (i), 1), but the sellers start with C (k) = Tc (k), 1) units of the resource for each customer. Product 0 is the \"no-purchase\" product; r (0) = 0 = a (0) for all k-K. The seller starts with C (k) = Tc (k) + units of the resource for the period 1.,.,., T, the following sequence of six events occurs."}, {"heading": "4 Online policy ONLINE(\u03c4)", "text": "For the duration of the learning phase, the following performance guarantee applies: Theorem 4.1. Suppose that adoption 4.2. The ONLINE (\u03c4) policy meets all resource constraints and leads to regret in the learning phase + O (TRB). Suppose that the learning phase (TRB) n (TRB) n (TRB) n (TRB) n (TRB) n (TRB) 2 / 3 minimizes regret that is tied to a constant factor, resulting in tied learning ability (TRB) 2 / 3N1 / 3). Our regret is sublinear. In N, B, in deep contrast to regret, we [Badanidiyuru et al., 2013] [Agrawal and Devanur, 2014] which are linear in the learning phase."}, {"heading": "5 Overview of the Proof for Theorem 4.1", "text": "To begin the proof, consider the period tlast of the last sale. Either ABORT is tlast at the end of the period, or tlast = T. It is a random variable depending on the resource consumption in the sales horizon. Denote (4) as BOUND (Celsius). We analyze the regret using the following examples: P [REG \u2264 BOUND (Celsius)); P [TOPT (v \u00b2) \u2212 tstop \u00b2 s = 1r (It) \u2264 BOUND (Celsius)]; P [TOPT (v \u00b2) \u2212 T \u00b2 s = 1r (Es)."}, {"heading": "6 Numerical Experiments", "text": "We evaluate the performance of ONLINE (T 2 / 3) with synthetic data, with different model parameters. According to Theorem 4.1, this results in a regret O (T 2 / 3RB \u221a N). We define a class uple as (S, N, K, R) and consider random problems defined on the basis of (S1) 3i = 1 and 8 sales horizontal lengths {T (q)} 8q = 1 defined below: (S1 (6), 10, 5, 3), (S1 (9), 15, 6, 5), (S1 (15), 25, 8, 7), T = [250, 500, 1000, 2000, 5000, 10000]. Here we refer to S1 (B) = {S \u00b2 N: | S | \u2264 B}. The tuples are arranged with increasing difficulty."}, {"heading": "7 Conclusion and Future Directions", "text": "We propose online strategies where the limits of regret are sublinear in the number of time periods and ranges. There are many interesting areas of research to be explored. Firstly, it is not known whether the limits of regret can be reached under [Agrawal et al., 2016]. Secondly, the inclusion of contextual information, similar to [Chu et al., 2011], [Agrawal et Devanur, 2016], is an exciting topic."}, {"heading": "A A Discussion on Assumption 4.2", "text": "We point out that the decisions of \u03c4 = T 2 / 3R2 / 3B2 / 3N1 / 3 and \u03c4 = T 2 / 3 are sufficient assuming 4.2 if T is sufficiently large. In fact, assumption 4.2 (i, ii) is equivalent to T \u2265 R 2B2c (k) 3 log3 / 24NK \u03b4, T \u2265 512R2B2N c (k) 3 log3 / 2 4N \u03b4for all k-K. Assumption 4.2 (i, ii) is equivalent to T \u2265 1c (k) 3 log3 / 2 4NK \u03b4, T \u2265 512B3R3N3 / 2c (k) 3 log3 / 24N\u0441for all k-K. Also in the case of T = T 2 / 3, our numerical results in \u00a7 6 show that ONLINE (strain) is effective even if the assumption is violated."}, {"heading": "B Proofs for the Lemmas in Section 5", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "B.1 Proof of Lemma 5.1", "text": "Let us recall the definition of Li (v) in (6). Consider the variable change e\u03b8 = v, and let us leave Li (\u03b8) = Li (e\u03b8). We haveLi (\u03b8) = n (i) log [1 + e \u2212 \u03b8] + (\u03c4N \u2212 n (i) log [1 + e\u03b8].Denote."}, {"heading": "B.2 Proof of Lemma 5.2", "text": "Consider the function f: [0, 1] \u2192 R defined by f: (3) = (3) i: (4) i: (4) i: (4) i: (4) i: (4) i: (4) i: (5) i: (5) i: (5) i: (5) i: (5) i: (5) i: (5) i: (5) i: (5) i: (5) i: (5) i: (5) i: (5) i: (5) i: (5) i: (5). Note that (5) = (5) and (5) = (5)."}, {"heading": "B.3 Proof of Lemma 5.3", "text": "Consider the following linear program S-LP: max."}, {"heading": "B.4 Proof of Lemma 5.4", "text": "We remember the short-term (REGRET) as follows: (REGRET) (REGRET) (REGRET) (REGRET) (REGRET) (REGRET) (REGRET) (REGRET). (22) Inequality (21) is defined by Lemma 5.3. We decompose the term (REGRET) as follows: (REGRET) we have the term (REGRET). (REGRET) We have the term (REGRET). (REGRET) we have the term (REGRET) as follows: (REGRET) we have the term (REGRET). (REGRET) We have the term (REGRET). (REGRET) we have the term (REGRET). (REGRET) we have the term (REGREGRET)."}, {"heading": "B.5 Proof of Lemma 5.5", "text": "Similar to the proof for Lemma 5,4, we decompose the sum between k and k for each k for each k for each k and k for each k for each k."}, {"heading": "C Additional Simulation Results", "text": "We evaluate the performance of ONLINE (T 2 / 3) with synthetic data when the family of permissible collations is a partition matroid. Remember that a class uple (S, N, K, R) is a family. Define the notation S2 (p,.Np) = {S, N: | S, Nj | \u2264 b for all 1 \u2264 j \u2264 p}, which denotes a partition matroid range family. (So we implicitly assume that N,.. Np} is a partition of N in p equal subsets, where Nj = (N (j \u2212 1) / p) + 1,., Nj / p}. (So we assume that N,. Np) is a partition of P: [Davis et al.], the optimization problem maxS, (p, b) R: (S, b) R: (S, 5) max."}, {"heading": "1, and achieves a regret of", "text": "The assumption of \u03c9 < 1 ensures that the sales horizon is long enough to learn sufficiently. We explain further the reasons behind the assumption in the analyses. It is that while the regret for the UCB policy (algorithm 3) has a better dependence on T than ONLINE, the former has a worse dependence on R, B, N than the latter. It is because the UCB policy has the underlying usage parameters with a stream of assortments S1, S2,. (and the corresponding purchase results I1, I2,.) the UCB policy must therefore resolve the dependence between different products in the assortments offered during the estimate. This situation is in contrast to ONLINE (2), which estimates an inference of individual items (and the corresponding purchase result)."}, {"heading": "E.1 Proving Theorem E.3", "text": "We prove Theorem E.3 by establishing a confidence bound to estimate v-1, using correlated samples (S-S, I-S, I-S, I-S, I-S, I-S, I-S, I-S, I-S, I-S, I-S, I-S, I-S), with U-T being the randomness used to generate S-T in line 8Theorem E.4. Consider the sale process (S-S, I-S, I-S, I-S, I-S, I-S, I-S, II-S, I-S, I-S, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II,"}, {"heading": "F Proof of Theorem E.4", "text": "Remember that Lt \u2212 1 (v) is in theory the negative probability among the samples. \u2212 n (n) This is the following variable change and transformation in the probability function: For all i (n) applies (i) = log v (i), Lt (v) = log v (i), Log v (i), Log v (i), Log v (i), Log v (i), Log v (i), Log v (i), Log v (i), Log v (i), Log v (i), and Log v (i), and Log v (i). \u2212 n (i) Ni))) Ni = 1. By Taylor approximation we know that such a thatLt (0) exists."}, {"heading": "G Proofs of Lemmas E.1, E.2", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "G.1 Proof of Lemma E.1", "text": "To limit regret, we must first consider the following: (1 \u2212 V) (T \u2212 N) (T \u2212 N) (T \u2212 N) (T \u2212 N) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () ()) () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () (() () (() () () () (() () () () () () (() () () (() () () () (() () () () () () () () () () () (() () (() () () () (() () () () ("}, {"heading": "H Proof of Claim G.1", "text": "Let y be an optimal solution for LP (v \u00b2), and consider the solution y \u00b2 = (1 \u00b2) y \u00b2 (1 \u00b2) y \u00b2 (S) = (1 \u00b2) y \u00b2 (S \u00b2) for S \u00b2 (1 \u00b2) and y \u00b2 (1 \u00b2) y \u00b2 (S) + \u03c9 (S). Firstly, it is clear that y \u00b2 is feasible for UCB-LP (v \u00b2 t, n \u00b2 t \u2212 1 \u00b2). Secondly, for each resource we have k \u00b2 K \u00b2 s (i \u00b2 t \u00b2 i \u00b2 Sa (i, k \u00b2 n \u00b2 Sa (S | v \u00b2 t) \u2212 t \u00b2 (n) \u2212 t \u00b2 (n \u00b2 t \u00b2 t) quality (n \u00b2 t (n \u00b2 t \u00b2 t \u00b2 S) quality (n \u00b2 t \u00b2 t \u00b2 S) y \u00b2 t (S) y \u00b2 t (S) y \u00b2 t (S) y \u00b2 t (S) y \u00b2 t \u00b2 t (S)."}, {"heading": "H.1 Proof of Lemma E.2", "text": "II II II II II II II II II II II II II II II II (II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II II"}], "references": [{"title": "Improved algorithms for linear stochastic bandits", "author": ["Yasin Abbasi-yadkori", "D\u00e1vid P\u00e1l", "Csaba Szepesv\u00e1ri"], "venue": "NIPS.", "citeRegEx": "Abbasi.yadkori et al.. 2011", "shortCiteRegEx": null, "year": 2011}, {"title": "Bandits with concave rewards and convex knapsacks", "author": ["Shipra Agrawal", "Nikhil R Devanur"], "venue": "ACM Conference on Economics and Computation,", "citeRegEx": "Agrawal and Devanur. 2014", "shortCiteRegEx": null, "year": 2014}, {"title": "Linear contextual bandits with knapsacks", "author": ["Agrawal", "Devanur", "2016] Shipra Agrawal", "Nikhil R. Devanur"], "venue": "In Advances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing Systems 2016,", "citeRegEx": "Agrawal et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Agrawal et al\\.", "year": 2016}, {"title": "A near-optimal exploration-exploitation approach for assortment selection", "author": ["Agrawal et al", "2016] Shipra Agrawal", "Vashist Avadhanula", "Vineet Goyal", "Assaf Zeevi"], "venue": "In Proceedings of the 2016 ACM Conference on Economics and Computation,", "citeRegEx": "al. et al\\.,? \\Q2016\\E", "shortCiteRegEx": "al. et al\\.", "year": 2016}, {"title": "In 54th Annual IEEE Symposium on Foundations of Computer Science", "author": ["Ashwinkumar Badanidiyuru", "Robert Kleinberg", "Aleksandrs Slivkins. Bandits with knapsacks"], "venue": "2013, 26-29 October, 2013, Berkeley, CA, USA, pages 207\u2013216,", "citeRegEx": "Badanidiyuru et al.. 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "Discrete Choice Analysis: Theory and Application to Travel Demand", "author": ["Moshe Ben-Akiva", "Steven Lerman"], "venue": "MIT Press Series in Transportation Studies. MIT Press,", "citeRegEx": "Ben.Akiva and Lerman. 1985", "shortCiteRegEx": null, "year": 1985}, {"title": "Manufacturing & Service Operations Management", "author": ["Fernando Bernstein", "A. G\u00fcrhan K\u00f6k", "Lei Xie. Dynamic assortment customization with limited inventories"], "venue": "17(4):538\u2013553,", "citeRegEx": "Bernstein et al.. 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "12:1655\u20131695", "author": ["S\u00e9bastien Bubeck", "R\u00e9mi Munos", "Gilles Stoltz", "Csaba Szepesv\u00e1ri. X-armed bandits. J. Mach. Learn. Res."], "venue": "July", "citeRegEx": "Bubeck et al.. 2011", "shortCiteRegEx": null, "year": 2011}, {"title": "Combinatorial multi-armed bandit: General framework", "author": ["Wei Chen", "Yajun Wang", "Yang Yuan"], "venue": "results and applications. ICML,", "citeRegEx": "Chen et al.. 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "In Advances in Neural Information Processing Systems 29", "author": ["Wei Chen", "Wei Hu", "Fu Li", "Jian Li", "Yu Liu", "Pinyan Lu. Combinatorial multi-armed bandit with general reward functions"], "venue": "pages 1659\u20131667.", "citeRegEx": "Chen et al.. 2016", "shortCiteRegEx": null, "year": 2016}, {"title": "volume 15", "author": ["Wei Chu", "Lihong Li", "Lev Reyzin", "Robert E. Schapire. Contextual bandits with linear payoff functions"], "venue": "pages 208\u2013214,", "citeRegEx": "Chu et al.. 2011", "shortCiteRegEx": null, "year": 2011}, {"title": "Combinatorial network optimization with unknown variables: Multi-armed bandits with linear rewards and individual observations", "author": ["Yi Gai", "Bhaskar Krishnamachari", "Rahul Jain"], "venue": "IEEE/ACM Transactions on Networking (TON), 20(5):1466\u20131478,", "citeRegEx": "Gai et al.. 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "Tight regret bounds for stochastic combinatorial semi-bandits", "author": ["Branislav Kveton", "Zheng Wen", "Azin Ashkan", "Csaba Szepesvari"], "venue": "AISTATS,", "citeRegEx": "Kveton et al.. 2014", "shortCiteRegEx": null, "year": 2014}, {"title": "Cascading bandits: Learning to rank in the cascade model", "author": ["Branislav Kveton", "Csaba Szepesvari", "Zheng Wen", "Azin Ashkan"], "venue": "ICML-15,", "citeRegEx": "Kveton et al.. 2015a", "shortCiteRegEx": null, "year": 2015}, {"title": "In Proceedings of the 28th International Conference on Neural Information Processing Systems", "author": ["Branislav Kveton", "Zheng Wen", "Azin Ashkan", "Csaba Szepesv\u00e1ri. Combinatorial cascading bandits"], "venue": "NIPS\u201915, pages 1450\u20131458,", "citeRegEx": "Kveton et al.. 2015b", "shortCiteRegEx": null, "year": 2015}, {"title": "Manufacturing & Service Operations Management", "author": ["Qian Liu", "Garrett van Ryzin. On the choice-based linear programming model for network revenue management"], "venue": "10(2), April", "citeRegEx": "Liu and van Ryzin. 2008", "shortCiteRegEx": null, "year": 2008}, {"title": "pages 105\u2013142", "author": ["Daniel McFadden. Conditional Logit Analysis of Qualitative Choice Behavior. In Frontiers in Econometrics"], "venue": "Academic Press,", "citeRegEx": "McFadden. 1974", "shortCiteRegEx": null, "year": 1974}, {"title": "Learning diverse rankings with multi-armed bandits", "author": ["Filip Radlinski", "Robert Kleinberg", "Thorsten Joachims"], "venue": "ICML,", "citeRegEx": "Radlinski et al.. 2008", "shortCiteRegEx": null, "year": 2008}, {"title": "Operations Research", "author": ["Paat Rusmevichientong", "Zuo-Jun Max Shen", "David B. Shmoys. Dynamic assortment optimization with a multinomial logit choice model", "capacity constraint"], "venue": "58(6):1666\u20131680,", "citeRegEx": "Rusmevichientong et al.. 2010", "shortCiteRegEx": null, "year": 2010}, {"title": "Manufacturing & Service Operations Management", "author": ["Denis Saure", "Assaf Zeevi. Optimal dynamic assortment planning with demand learning"], "venue": "15(3):387\u2013404,", "citeRegEx": "Saure and Zeevi. 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "Management Science", "author": ["Kalyan T. Talluri", "Garrett J. van Ryzin. Revenue management under a general discrete choice model of consumer behavior"], "venue": "50(1):15\u201333,", "citeRegEx": "Talluri and van Ryzin. 2004", "shortCiteRegEx": null, "year": 2004}, {"title": "Epsilon-first policies for budget-limited multi-armed bandits", "author": ["Long Tran-Thanh", "Archie C. Chapman", "Enrique Munoz de Cote", "Alex Rogers", "Nicholas R. Jennings"], "venue": "AAAI,", "citeRegEx": "Tran.Thanh et al.. 2010", "shortCiteRegEx": null, "year": 2010}, {"title": "Knapsack based optimal policies for budget-limited multi-armed bandits", "author": ["Tran-Thanh et al", "2012] Long Tran-Thanh", "Archie C. Chapman", "Alex Rogers", "Nicholas R. Jennings"], "venue": "In Proceedings of the Twenty-Sixth AAAI Conference on Artificial Intelligence,", "citeRegEx": "al. et al\\.,? \\Q2012\\E", "shortCiteRegEx": "al. et al\\.", "year": 2012}, {"title": "In Proceedings of The 7th Asian Conference on Machine Learning", "author": ["Yingce Xia", "Wenkui Ding", "Xu-Dong Zhang", "Nenghai Yu", "Tao Qin. Budgeted bandit problems with continuous random costs"], "venue": "ACML 2015, Hong Kong, November 20-22,", "citeRegEx": "Xia et al.. 2015a", "shortCiteRegEx": null, "year": 2015}, {"title": "Thompson sampling for budgeted multi-armed bandits", "author": ["Xia et al", "2015b] Yingce Xia", "Haifang Li", "Tao Qin", "Nenghai Yu", "Tie-Yan Liu"], "venue": "In Proceedings of the Twenty-Fourth International Joint Conference on Artificial Intelligence,", "citeRegEx": "al. et al\\.,? \\Q2015\\E", "shortCiteRegEx": "al. et al\\.", "year": 2015}, {"title": "Budgeted multi-armed bandits", "author": ["Xia et al", "2016] Yingce Xia", "Tao Qin", "Weidong Ma", "Nenghai Yu", "Tie-Yan Liu"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2016\\E", "shortCiteRegEx": "al. et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 5, "context": "Such choice behavior is captured by the underlying choice model, which has been under intense study by the economics and operations research communities [Ben-Akiva and Lerman, 1985].", "startOffset": 153, "endOffset": 181}, {"referenceID": 16, "context": "TheMNL choice model is a fundamental model proposed by [McFadden, 1974], and it has been the building block for many other existing choice models [Ben-Akiva and Lerman, 1985].", "startOffset": 55, "endOffset": 71}, {"referenceID": 5, "context": "TheMNL choice model is a fundamental model proposed by [McFadden, 1974], and it has been the building block for many other existing choice models [Ben-Akiva and Lerman, 1985].", "startOffset": 146, "endOffset": 174}, {"referenceID": 20, "context": "Assuming the knowledge of the underlying MNL choice model, [Talluri and van Ryzin, 2004] propose an efficient algorithm for computing an optimal assortment when there is no resource constraint; [Liu and van Ryzin, 2008] propose an efficient algorithm for computing a mixture of assortments that achieves asymptotic optimality under resource constraints.", "startOffset": 59, "endOffset": 88}, {"referenceID": 15, "context": "Assuming the knowledge of the underlying MNL choice model, [Talluri and van Ryzin, 2004] propose an efficient algorithm for computing an optimal assortment when there is no resource constraint; [Liu and van Ryzin, 2008] propose an efficient algorithm for computing a mixture of assortments that achieves asymptotic optimality under resource constraints.", "startOffset": 194, "endOffset": 219}, {"referenceID": 6, "context": "[Bernstein et al., 2015] offer insights into the optimal assortment planning policy under resource constraints, when the product prices are equal but there are multiple types of customers.", "startOffset": 0, "endOffset": 24}, {"referenceID": 18, "context": "Assuming uncertainty in the MNL choice model, [Rusmevichientong et al., 2010] propose an online policy that incurs an instance-dependent O(log T ) regret.", "startOffset": 46, "endOffset": 77}, {"referenceID": 19, "context": "[Saure and Zeevi, 2013] generalize [Rusmevichientong et al.", "startOffset": 0, "endOffset": 23}, {"referenceID": 18, "context": "[Saure and Zeevi, 2013] generalize [Rusmevichientong et al., 2010] by proposing online policies with instance-dependent O(log T ) regret bounds for a wider class of choice models.", "startOffset": 35, "endOffset": 66}, {"referenceID": 2, "context": "Recently, [Agrawal et al., 2016] provide a instance-independent regret \u00d5( \u221a T ) under an uncertain MNL choice model.", "startOffset": 10, "endOffset": 32}, {"referenceID": 21, "context": "For budget bandit problems, [Tran-Thanh et al., 2010] provide an instance-indepenedent regret bound with a resource constraint; [Tran-Thanh et al.", "startOffset": 28, "endOffset": 53}, {"referenceID": 23, "context": ", 2012] and [Xia et al., 2015a] provide instance-dependent regret bounds for the cases of discrete and continuous resource consumption costs.", "startOffset": 12, "endOffset": 31}, {"referenceID": 4, "context": "[Badanidiyuru et al., 2013], [Agrawal and Devanur, 2014] provide optimal instanceindependent regret bounds for the problem with general resource constraints.", "startOffset": 0, "endOffset": 27}, {"referenceID": 1, "context": ", 2013], [Agrawal and Devanur, 2014] provide optimal instanceindependent regret bounds for the problem with general resource constraints.", "startOffset": 9, "endOffset": 36}, {"referenceID": 4, "context": "A direct application of [Badanidiyuru et al., 2013] or [Agrawal and Devanur, 2014] to our problem yields a regret linear in the number of assortments, which is often larger than the number of customers.", "startOffset": 24, "endOffset": 51}, {"referenceID": 1, "context": ", 2013] or [Agrawal and Devanur, 2014] to our problem yields a regret linear in the number of assortments, which is often larger than the number of customers.", "startOffset": 11, "endOffset": 38}, {"referenceID": 11, "context": "[Gai et al., 2012] study the combinatorial bandit problem with linear reward (i.", "startOffset": 0, "endOffset": 18}, {"referenceID": 8, "context": "a super arm\u2019s reward is the sum of its basic arms\u2019 reward), which is subsequently generalized and refined by [Chen et al., 2013] to the case with non-linear reward.", "startOffset": 109, "endOffset": 128}, {"referenceID": 12, "context": "The optimal regret bound is obtained by [Kveton et al., 2014] in the case of linear reward.", "startOffset": 40, "endOffset": 61}, {"referenceID": 9, "context": "[Chen et al., 2016] consider the generalized case when the expected reward under a super arm depends on certain random variables associated with its basic arms.", "startOffset": 0, "endOffset": 19}, {"referenceID": 17, "context": "Recent works [Radlinski et al., 2008], [Kveton et al.", "startOffset": 13, "endOffset": 37}, {"referenceID": 13, "context": ", 2008], [Kveton et al., 2015a], [Kveton et al.", "startOffset": 9, "endOffset": 31}, {"referenceID": 14, "context": ", 2015a], [Kveton et al., 2015b] consider the problem in the cascading-feedback setting.", "startOffset": 10, "endOffset": 32}, {"referenceID": 16, "context": "A customer\u2019s purchase decision is governed by the MNL choice probability function \u03c6(\u00b7, \u00b7|v\u2217) [McFadden, 1974].", "startOffset": 93, "endOffset": 109}, {"referenceID": 4, "context": "The benchmark TOPT(LP(v)) upper bounds the expected optimum [Badanidiyuru et al., 2013]: Theorem 3.", "startOffset": 60, "endOffset": 87}, {"referenceID": 4, "context": "1 ([Badanidiyuru et al., 2013]).", "startOffset": 3, "endOffset": 30}, {"referenceID": 4, "context": "Our regret bound is sublinear inN,B, in deep contrast with the regret bounds by applying [Badanidiyuru et al., 2013], [Agrawal and Devanur, 2014], which are linear in |S| = \u0398(N).", "startOffset": 89, "endOffset": 116}, {"referenceID": 1, "context": ", 2013], [Agrawal and Devanur, 2014], which are linear in |S| = \u0398(N).", "startOffset": 9, "endOffset": 36}, {"referenceID": 15, "context": "Fortunately, by [Liu and van Ryzin, 2008], LP(v\u0302) can be efficiently solved by the Column Generation algorithm (CG).", "startOffset": 16, "endOffset": 41}, {"referenceID": 18, "context": "The reduced problem is polynomial time solvable for many choices of S, such as S = {S : |S| \u2264 B} [Rusmevichientong et al., 2010].", "startOffset": 97, "endOffset": 128}, {"referenceID": 2, "context": "First, it is not known if the regret lower bound by [Agrawal et al., 2016] can be attained.", "startOffset": 52, "endOffset": 74}, {"referenceID": 10, "context": "Second, the incorporation of contextual information, similar to [Chu et al., 2011], [Agrawal and Devanur, 2016], is an exciting topic.", "startOffset": 64, "endOffset": 82}, {"referenceID": 1, "context": "The incorporation of confidence bounds into UCBLP(vt, nt\u22121, \u03c9) is inspired by [Agrawal and Devanur, 2014] as well as the primal-dual algorithm in [Badanidiyuru et al.", "startOffset": 78, "endOffset": 105}, {"referenceID": 4, "context": "The incorporation of confidence bounds into UCBLP(vt, nt\u22121, \u03c9) is inspired by [Agrawal and Devanur, 2014] as well as the primal-dual algorithm in [Badanidiyuru et al., 2013].", "startOffset": 146, "endOffset": 173}, {"referenceID": 1, "context": "As remarked in the design of ONLINE(\u03c4), We cannot afford to learn all the choice probabilities {\u03c6(i, S|v)}i\u2208N ,S\u2208S individually, which would be the case if we just directly apply [Agrawal and Devanur, 2014][Badanidiyuru et al.", "startOffset": 179, "endOffset": 206}, {"referenceID": 4, "context": "As remarked in the design of ONLINE(\u03c4), We cannot afford to learn all the choice probabilities {\u03c6(i, S|v)}i\u2208N ,S\u2208S individually, which would be the case if we just directly apply [Agrawal and Devanur, 2014][Badanidiyuru et al., 2013].", "startOffset": 206, "endOffset": 233}, {"referenceID": 0, "context": "5 ([Abbasi-yadkori et al., 2011],[Bubeck et al.", "startOffset": 3, "endOffset": 32}, {"referenceID": 7, "context": ", 2011],[Bubeck et al., 2011]).", "startOffset": 8, "endOffset": 29}, {"referenceID": 7, "context": "The Lemma follows from either the application of Doob\u2019s Optional Sampling Theorem with Azuma-Hoeffding inequality (for example see the proof of Lemma 15 in [Bubeck et al., 2011]), or from the theory of selfnormalizing processes (for example, see Lemma 6 in [Abbasi-yadkori et al.", "startOffset": 156, "endOffset": 177}, {"referenceID": 0, "context": ", 2011]), or from the theory of selfnormalizing processes (for example, see Lemma 6 in [Abbasi-yadkori et al., 2011]) In particular, Theorem E.", "startOffset": 87, "endOffset": 116}], "year": 2017, "abstractText": "Motivated by e-commerce, we study the online assortment optimization problem. The seller offers an assortment, i.e. a subset of products, to each arriving customer, who then purchases one or no product from her offered assortment. A customer\u2019s purchase decision is governed by the underlyingMultiNomial Logit (MNL) choice model. The seller aims to maximize the total revenue in a finite sales horizon, subject to resource constraints and uncertainty in the MNL choice model. We first propose an efficient online policy which incurs a regret \u00d5(T ), where T is the number of customers in the sales horizon. Then, we propose a UCB policy that achieves a regret \u00d5(T ). Both regret bounds are sublinear in the number of assortments.", "creator": "LaTeX with hyperref package"}}}