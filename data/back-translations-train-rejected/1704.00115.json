{"id": "1704.00115", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Apr-2017", "title": "Ontological Multidimensional Data Models and Contextual Data Qality", "abstract": "Data quality assessment and data cleaning are context-dependent activities. Motivated by this observation, we propose the Ontological Multidimensional Data Model (OMD model), which can be used to model and represent contexts as logic-based ontologies. The data under assessment is mapped into the context, for additional analysis, processing, and quality data extraction. The resulting contexts allow for the representation of dimensions, and multidimensional data quality assessment becomes possible. At the core of a multidimensional context we include a generalized multidimensional data model and a Datalog+/- ontology with provably good properties in terms of query answering. These main components are used to represent dimension hierarchies, dimensional constraints, dimensional rules, and define predicates for quality data specification. Query answering relies upon and triggers navigation through dimension hierarchies, and becomes the basic tool for the extraction of quality data. The OMD model is interesting per se, beyond applications to data quality. It allows for a logic-based, and computationally tractable representation of multidimensional data, extending previous multidimensional data models with additional expressive power and functionalities.", "histories": [["v1", "Sat, 1 Apr 2017 03:50:53 GMT  (1097kb,D)", "https://arxiv.org/abs/1704.00115v1", "Journal submission. Extended version of RuleML'15 paper"], ["v2", "Sun, 13 Aug 2017 21:11:37 GMT  (1103kb,D)", "http://arxiv.org/abs/1704.00115v2", "Journal submission (revised version addressing reviewers' observations) Extended version of RuleML'15 paper"]], "COMMENTS": "Journal submission. Extended version of RuleML'15 paper", "reviews": [], "SUBJECTS": "cs.DB cs.AI", "authors": ["leopoldo bertossi", "mostafa milani"], "accepted": false, "id": "1704.00115"}, "pdf": {"name": "1704.00115.pdf", "metadata": {"source": "META", "title": "Ontological Multidimensional Data Models and Contextual Data Quality", "authors": ["LEOPOLDO BERTOSSI", "MOSTAFA MILANI"], "emails": [], "sections": [{"heading": null, "text": "1 Ontological Multidimensional Data Models and Context Data alityLEOPOLDO BERTOSSI, Carleton University MOSTAFA MILANI, McMaster UniversityData Quality Assessment and Data Purification are context-dependent activities. Motivated by this observation, we propose the Ontological Multidimensional Data Model (OMD Model), which can be used to model and represent contexts as logical ontologies. At the core of a multidimensional context, we refer to a generalized Multidimensional Data Model and a Datalog \u00b1 Ontology with demonstrably good properties in terms of query answering. the resulting contexts enable the representation of dimensions and multidimensional data quality evaluation."}, {"heading": "1 INTRODUCTION", "text": "The reason for this is that the data does not stand in a uniform context, but in several dimensions. Some of them are able to recognize the validity and integrity of data that are usually reconciled with the satisfaction of integrity limitations. (2) It is about identifying the current values of companies that are located in a database. (3) It is about answering questions of integrity of companies. (3) It is about answering questions of integrity of companies. (3) It is about answering questions in relation to answering questions in relation to answering questions relating to the quality of data by answering questions of answering questions of answering the answer of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of questions. (4) It is about answering questions of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of questions. (4) It is about answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of"}, {"heading": "2 BACKGROUND", "text": "In this section we review relational databases and the multidimensional data model."}, {"heading": "2.1 Relational Databases", "text": "We always begin with a relational scheme R with two separate areas: C, with possibly many constants, and N, of which there are many. (F) F, F, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E,"}, {"heading": "2.2 Datalog\u00b1", "text": "The Datalog extension of the Datalog. e \"+\" stands for the extension, and the \"\u2212 Q\" instance is for some syntactical constraints on the program that guarantee some good arithmetic properties. We refer to some of these constraints in Section 4 and (9). A Datalog + program can contain, in addition to (non-existential) data rules, existential rules of the form (7), and the constraints of the forms (8) and (9). A Datalog + program has, Vol. 1, No. 1, Article 1. Release date: March 2017.an extensional database D. In a Datalog + program extension, unlike simple datalogs, predictions are not necessarily divided into extended and intentional predictions: each predictor can appear in the head of a rule."}, {"heading": "2.3 The Hurtado-Mendelzon Multidimensional Data Model", "text": "According to Hurtado-Mendelzon, a multidimensional data model (in short, the HMmodel) [53], a dimension scheme, H = < K, \u0432\u043e >, consists of a nite set K of categories and an insane exive, binary relationship, called the child-parent relationship, between categories (the first category is a child and the second category is a parent). e transitive and re exive closure of children is through a partial order (a la ice) with a top category, all accessible from any other category: K-All members, for each category K members are a unique base category, Kb members that has no abbreviations. \"i.e. If K-K members do not exist, there is no category K members, di erent of K members, with K-K members."}, {"heading": "3 THE ONTOLOGICAL MULTIDIMENSIONAL DATA MODEL", "text": "In this section, we present the OMD model as an ontological, Datalog + -based extension of the HM model. (In this section, we refer to the working example from Section 1, which extends it along the path, if necessary, to represent elements of the OMD model.) An OMD model has a database schema RM = H-Rc, where H is a multi-dimensional relational schema whose categorical relationships can be seen as extensions of the fact tables in the HM models, and sets L of binary, child-parent predicates (cf. Section 2.3); and Rc is a set of categorical predicates, whose categorical relationships can be regarded as extensions of the fact tables in the HM models. (A) Predicates of categorical predicates are either categorical, whose values are members of dimensional categories, or non-categorical, the values of domains."}, {"heading": "W4 Sep/5/2016 Cathy Noon", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "W3 Aug/21/2016 Sara Noon", "text": "A general tgd of form (18) can be used for an upward or downward movement (or, more precisely, an upward or downward movement), depending on how the body behaves."}, {"heading": "4 COMPUTATIONAL PROPERTIES OF THE OMDMODEL", "text": "As already mentioned, the conjunctive query answering (CQA) of Datalog + programs can also be undecidable without limitations [27]. Accordingly, it is important to identify classes of programs for which CQA is decidable, and hopefully in polynomial time in terms of the size of the underlying database, i.e. in terms of data complexity. Some classes of this type have been identified. Later in this section, we present some of them that are particularly relevant to our research. We show that these classes belong to these classes under natural assumptions or OMD ontologies. Generally, these program classes have no limitations. At the end of the section, we consider their presence in terms of their impact on QA."}, {"heading": "4.1 Weakly-Acyclic, Sticky and Weakly-Sticky Programs", "text": "The question that arises is whether this is a real diagram whose vertices are the positions of the scheme. (a) Create an edge from p to p in the head (b) Create an edge from p to position p in the head (c) Create an edge to position p. \"(c) Create an edge to position p.\" (c) Create an edge from p to position p. \"(c) Create an edge to position p.\" (c) Create an edge to position p. \"(c) Create an edge to position p.\" (c) Create an edge to position p. \"(c) Create a variable z in the position of an existential variable in the position of the rule head. (b) Create a special edge in position p.\" (c) Create a special edge in position p. \"(c), in which a variable z appears in the position of an existential variable in the position of the rule head. (c) Create a special edge in the position p.\""}, {"heading": "4.2 OMD Ontologies as Weakly-Sticky Datalog\u00b1 Programs", "text": "In this section we will examine the ontologies used by the OMD models as a datalog. (...) We start by looking at only their subontologies, which are analyzed by their tgds.e effects on the constraints set in OM. It turns out that the MD ontologies are only weak-sticky. Intuitively, the main reason is that the variables joined in the dimensional tgds can be invented in the categorical positions, where many members of the dimensions may occur during hunting, because no existential variables (variable) occur in a categorical position; therefore, no new values are invented in them positions during the categorical tgds. MD-ontologies are weak-sticky datalog \u00b1 program.Proof Proposition 4.4: e tgds are of the form (18): R1 (x-1), Rn x-1; y-1)."}, {"heading": "4.3 OMD Ontologies with Constraints", "text": "In order to get a grip on the effects of the crisis, we have to deal with the question of how we can get a grip on the crisis. (...) We have to deal with the question of how we can get a grip on the crisis. (...) We have to deal with the question of how we can get a grip on the crisis. (...) We have to deal with the question of how we can get a grip on the crisis. (...) We have to deal with the question of how we can get a grip on the crisis. (...) We have to deal with the question of how we want to solve it. \"(...) We have to deal with the question of how we want to solve it.\" (...)"}, {"heading": "5 CONTEXTUAL DATA QUALITY SPECIFICATION AND EXTRACTION", "text": "It is not that we use a running example, which we refer to in sections 1 and 3. On the other side of this section, we detail the components and use of an MD context in a high-quality context, for which we refer to Figure 5. For motivation and illustration, we use a running example, which refers to sections 1 and 3. On the other side of this section, we refer to a database instance, D, for a relational scheme R = {R1, Rn}. e goal is to specify and extract high-quality data from D."}, {"heading": "5.1 Computational Properties of the Contextual Ontology", "text": "In Section 4, we examined the computational properties of MD ontologies, without additional rules for quality predicates and quality versions of tables in D. In this context, it may happen that the combination of datalog ontologies with good computational properties can be an ontology without such properties [8, 9]. In our case, contextual ontology may not preserve the syntactic properties of central MD ontology. Example 5.3. (Example 4.5 and 5.2 cont.) To the WSMD ontology, which contains the dimensional rules, we can add a non-recursive datalog rule that contains a quality predicate SameShi (Ward, Day; Nurse1, Nurse2) stating that Nurse1 and Nurse2 contain the same shi s on the same station and on the same day: \u03c33: Shi s (w, d; n, Shi) predication properties."}, {"heading": "5.2 ery-Based Extraction of ality Data", "text": "In this section we present a method for obtaining qualitative data about the context in which the QQ-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q"}, {"heading": "6 DISCUSSION AND CONCLUSIONS", "text": "In fact, it is in such a way that we are able to go to another world, in which we go to another world, in which we go to another world, in which we go to another world, in which we go to another world, in which we go to another world, in which we go to another world, in which we go to another world, in which we go to another world, in which we go to another world, in which we go to a world, in which we live in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, we live in which we live, in which we live, in which we live in which we live, in which we live, in which we live, in which we live, in which we live, in which we live in which we live, in which we live, in which we live, in which we live in which we live, in which we live, in which we live, we live, in which we live, in which we live in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, we live, in which we live, in which we live, we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we, in which we, in which we live, in which we, in which we live, in which we live, we, in which we live, in which we, in which"}, {"heading": "6.1 Categorical Keys", "text": "In our ongoing example, the categorical relationship WorkSchedules (Unit, Day; Nurse, Speciality), does not have {Unit, Day} as key: several nurses could have work schedules in the same unit and on the same day. However, in many applications it may be useful to have the categorical keys that form a key for a categorical relationship. (For example, in the HM model, the non-categorical response to a categorical form of a key.) is not required by the basic OMD model, and such a key condition must be addressed. If we assume that in a categorical relationship R (C1, Cn; A1, Am), {Cn} is a key for R, we must include egds in the MD ontology, one for each pair yi."}, {"heading": "6.2 Inconsistent MD Ontologies", "text": "In Section 4.3 we discussed the presence of dimensional ncs and egds, which can lead to an inconsistent MD ontology (see Section 2.2), in which case the ontology can be repaired according to an inconsistent semantics so that it provides semantically meaningful and non-trivial answers to questions of inconsistency. A common approach for DL or Datalog \u00b1 ontological repair is to repair the extended database in the case of Datalog \u00b1 [65] and the A-Box in the case of DL [20, 21, 61, 62, 85] ontologies. According to this semantics, a repair of an inconsistent ontology O, including an extended instance I, is a consistent ontology with the same rules and limitations as O, but with an extended instance I \u2032 that is maximum contained in I, consistent responses to a query put to O."}, {"heading": "6.3 ality Data Extraction as Inconsistency Handling", "text": "As explained in Section 1, context-based data extraction is reminiscent of database repair and consistent query response [14, 17]. In fact, from our context-based approach to data cleanup, we can reproduce a scenario in which cleanup can be considered consistent query response., Volume 1, No. 1, Article 1. Release Date: March 2017.e The original database D may not be subject to integrity limitations. 24 However, as we can see in Example 5.2, rule (31) could be considered a paraphrase of query Q (t, p, v, n): temperatures (t, p, v, n) that are performed to obtain the consistent responses (or consistent content of temperatures in this case)."}, {"heading": "6.4 Categorical Value Invention and Closed Predicates", "text": "We assumed in Section 3 that tgds do not have existential quantities on variables for categorical and categorical ributes. it has two important consequences. Firstly, the OMD programs become weak-stifling (cf. proposition 4.4); secondly, we can apply the CWA to categories and categorical criteria (in fact, without existential quantities on categorical criteria) so that the CWA or the OWA can not ma er be applied to CQA. Relativising this condition has two direct effects on MD ontology: (a) We can no longer turn the CWA into dimension categories (and categorical attributes) (without violating the ncs in 16); and (b) a number of tgds of an OMD ontology can not be weak."}, {"heading": "6.5 Related Work", "text": "In fact, most of them will be able to play by the rules they have set for their policies."}], "references": [{"title": "Polynomial Datalog Rewritings for Ontology Mediated \u008beries with Closed Predicates", "author": ["S. Ahmetaj", "M. Ortiz", "M. \u0160imkus"], "venue": "In Proc. of the Alberto Mendelzon International Workshop on Foundations of Data Management (AMW), CEUR-WS Proc", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2016}, {"title": "Disjunctive Datalog with Existential \u008banti\u0080ers: Semantics, Decidability, and Complexity Issues", "author": ["M. Alviano", "W. Faber", "N. Leone", "M. Manna"], "venue": "\u008aeory and Practice of Logic Programming (TPLP),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2012}, {"title": "Magic-Sets for Datalog with Existential \u008banti\u0080ers", "author": ["M. Alviano", "N. Leone", "M. Manna", "G. Terracina", "P. Veltri"], "venue": "In Proc. of the Int. Conference on Datalog in Academia and Industry", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2012}, {"title": "Contextualization as an Independent Abstraction Mechanism for Conceptual Modeling", "author": ["A. Anality", "M. \u008ceodorakis", "N. Spyratos", "P. Constantopoulos"], "venue": "Information Systems,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2007}, {"title": "Structural Repairs of Multidimensional Databases", "author": ["S. Ariyan", "L. Bertossi"], "venue": "In Proc. of the Alberto Mendelzon International WS of Foundations of Data Management (AMW),", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2011}, {"title": "A Multidimensional Data Model with Subcategories for Flexibly Capturing Summarizability", "author": ["S. Ariyan", "L. Bertossi"], "venue": "In Proc. of the International Conference on Scienti\u0080c and Statistical Database Management (SSDBM),", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2013}, {"title": "On Rules with Existential Variables: Walking the Decidability Line", "author": ["J.F. Baget", "M. Lecl\u00e9re", "M.L. Mugnier", "E. Salvat"], "venue": "Arti\u0080cial Intelligence,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2011}, {"title": "Combining Existential Rules and Transitivity: Next Steps", "author": ["J.F. Baget", "M. Bienvenu", "M.L. Mugnier", "S. Rocher"], "venue": "In Proc. of the International Joint Conference on Arti\u0080cial Intelligence (IJCAI),", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2015}, {"title": "Declarative Entity Resolution via Matching Dependencies and Answer Set Programs", "author": ["Z. Bahmani", "L. Bertossi", "S. Kolahi", "L. Lakshmanan"], "venue": "In Proc. of the International Conference on Principles of Knowledge Represena\u0088ion and Reasoning (KR),", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2012}, {"title": "Logical Foundations of Relational Data Exchange", "author": ["P. Barcelo"], "venue": "ACM SIGMOD Record,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2009}, {"title": "Data \u0089ality: Concepts, Methodologies and Techniques", "author": ["C. Batini", "M. Scannapieco"], "venue": "Second edition,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2016}, {"title": "\u008ce Implication Problem for Data Dependencies", "author": ["C. Beeri", "M.Y. Vardi"], "venue": "In Proc. of the Colloquium on Automata, Languages and Programming (ICALP),", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1981}, {"title": "Consistent \u008bery Answering in Databases", "author": ["L. Bertossi"], "venue": "ACM Sigmod Record,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2006}, {"title": "Consistent \u008bery Answering in Data Warehouses", "author": ["L. Bertossi", "L. Bravo", "M. Caniupan"], "venue": "In Proc. of the Alberto Mendelzon International Workshop on Foundations of Data Management (AMW),", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2009}, {"title": "Data \u008bality is Context Dependent", "author": ["L. Bertossi", "F. Rizzolo", "J. Lei"], "venue": "In Proc. of the Workshop on Enabling Real-Time Business Intelligence (BIRTE) Collocated with the International Conference on Very Large Data Bases (VLDB), Springer LNBIP", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2011}, {"title": "Database Repairing and Consistent \u0089ery Answering", "author": ["L. Bertossi"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2011}, {"title": "Generic and Declarative Approaches to Data \u008bality Management", "author": ["L. Bertossi", "L. Bravo"], "venue": "In Handbook of Data \u0089ality - Research and Practice,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2013}, {"title": "Contexts and Data \u008bality Assessment", "author": ["L. Bertossi", "F. Rizzolo"], "venue": "Corr Arxiv Paper cs.DB/1608.04142,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2016}, {"title": "\u008berying Inconsistent Description Logic Knowledge Bases under Preferred Repair Semantics", "author": ["Bienvenu M", "C. Bourgaux", "F. Goasdou\u00e8"], "venue": "In Proc. of the National Conference on Arti\u0080cial Intelligence (AAAI),", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2014}, {"title": "Explaining Inconsistency-tolerant \u008bery Answering over Description Logic Knowledge Bases", "author": ["Bienvenu M", "C. Bourgaux", "F. Goasdou\u00e8"], "venue": "In Proc. of the National Conference on Arti\u0080cial Intelligence (AAAI),", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2016}, {"title": "A Data-Oriented Survey of Context Models", "author": ["C. Bolchini", "C.A. Curino", "E. \u008bintarelli", "F.A. Schreiber", "L. Tanca"], "venue": "ACM SIGMOD Record,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2007}, {"title": "Using Context for the Extraction of Relational Views", "author": ["C. Bolchini", "E. \u008bintarelli", "R. Rossato", "L. Tanca"], "venue": "In Proc. of the International and Interdisciplinary Conference on Modeling and Using Context,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2007}, {"title": "Context Information for Knowledge Reshaping", "author": ["C. Bolchini", "C.A. Curino", "E. \u008bintarelli", "F.A. Schreiber", "L. Tanca"], "venue": "International Journal of Web Engineering and Technology,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2009}, {"title": "CARVE: Context-Aware Automatic View De\u0080nition over Relational Databases", "author": ["C. Bolchini", "E. \u008bintarelli", "L. Tanca"], "venue": "Information Systems,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2013}, {"title": "Guarded-Based Disjunctive Tuple-Generating Dependencies", "author": ["P. Bourhis", "M. Manna", "M. Morak", "A. Pieris"], "venue": "ACM Trans. Database Syst.,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2016}, {"title": "On the Decidability and Complexity of \u008bery Answering over Inconsistent and Incomplete Databases", "author": ["A. Cal\u0300\u0131", "D. Lembo", "R. Rosati"], "venue": "In Proc. of the ACM SIGMOD-SIGACT Symposium on Principles of Database Systems (PODS),", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2003}, {"title": "Datalog\u00b1: A Uni\u0080ed Approach to Ontologies and Integrity Constraints", "author": ["A. Cal\u0300\u0131", "G. Go\u008alob", "T. Lukasiewicz"], "venue": "In Proc. of the International Conference on Database \u008aeory (ICDT),", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2009}, {"title": "Towards More Expressive Ontology Languages: \u008ce \u008bery Answering Problem", "author": ["A. Cal\u0300\u0131", "G. Go\u008alob", "A. Pieris"], "venue": "Arti\u0080cial Intelligence,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2012}, {"title": "On Separability of Ontological Constraints", "author": ["A. Cal\u0300\u0131", "M. Console", "R. Frosini"], "venue": "In Proc. of the Alberto Mendelzon International Workshop on Foundations of Data Management (AMW),", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2012}, {"title": "Taming the In\u0080nite Chase: \u008bery Answering under Expressive Relational Constraints", "author": ["A. Cal\u0300\u0131", "G. Go\u008alob", "M. Kifer"], "venue": "Journal of Arti\u0080cial Intelligence Research (JAIR),", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2013}, {"title": "\u008ce Consistency Extractor System: Answer Set Programs for Consistent \u008bery Answering in Databases", "author": ["M. Caniupan-Marileo", "L. Bertossi"], "venue": "Data & Knowledge Engineering,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2010}, {"title": "\u008ce Implication Problem for Functional and Inclusion Dependencies", "author": ["A.K. Chandra", "M.Y. Vardi"], "venue": "SIAM Journal of Computing,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 1985}, {"title": "Data \u008bality and the Bo\u008aom Line: Achieving Business Success \u008crough a Commitment to High \u008bality Data", "author": ["W. Eckerson"], "venue": "Report of the Data Warehousing Institute,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2002}, {"title": "A Mathematical Introduction to Logic. 2nd Edition", "author": ["H.B. Enderton"], "venue": null, "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2001}, {"title": "Data Exchange: Semantics and \u008bery Answering", "author": ["R. Fagin", "P.G. Kolaitis", "R.J. Miller", "L. Popa"], "venue": "\u008aeoretical Computer Science (TCS),", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2005}, {"title": "Dependencies Revisited for Improving Data \u008bality", "author": ["W. Fan"], "venue": "In Proc. of the ACM SIGMOD-SIGACT Symposium on Principles of Database Systems (PODS),", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2008}, {"title": "Foundations of Data \u0089ality Management", "author": ["W. Fan", "F. Geerts"], "venue": null, "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2012}, {"title": "Data \u008bality: From \u008ceory to Practice", "author": ["W. Fan"], "venue": "Article 1. Publication date: March 2017", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2015}, {"title": "Reasoning about Record Matching Rules", "author": ["W. Fan", "X. Jia", "J. Li", "S. Ma"], "venue": "In Proc. VLDB Endowment (PVLDB),", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2009}, {"title": "Dynamic Constraints for Record Matching", "author": ["W. Fan", "H. Gao", "X. Ji", "J. Li", "S. Ma"], "venue": "\u008ae International Journal on Very Large Data Bases (VLDBJ),", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2009}, {"title": "A DataWarehouse Conceptual Data Model for Multidimensional Aggregation", "author": ["E. Franconi", "I. Sa\u008aler"], "venue": "In Proc. of the International Workshop on Design and Management of Data Warehouses (DMDW),", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 1999}, {"title": "\u008bery Answering with DBoxes is Hard", "author": ["E. Franconi", "Y. Garcia", "I. Seylan"], "venue": "Electronic Notes in \u008aeoretical Computer Science (ENTCS),", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2011}, {"title": "Model \u008ceoretic Semantics for Information Integration", "author": ["C. Ghidini", "L. Sera\u0080ni"], "venue": "In Proc. of the International Conference on Arti\u0080cial Intelligence, Methodology, Systems, and Applications (AIMSA),", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 1998}, {"title": "Local Models Semantics, or Contextual Reasoning = Locality + Compatibility", "author": ["C. Ghidini", "F. Giunchiglia"], "venue": "Arti\u0080cial Intelligence,", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 2001}, {"title": "Multi-Context Logics - A General Introduction", "author": ["C. Ghidini", "L. Sera\u0080ni"], "venue": "In Context in Computing,", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 2014}, {"title": "Multilanguage Hierarchical Logics, or: How We Can Do without Modal Logics", "author": ["F. Giunchiglia", "L. Sera\u0080ni"], "venue": "Arti\u0080cial Intelligence,", "citeRegEx": "48", "shortCiteRegEx": "48", "year": 1994}, {"title": "Ontological \u008beries: Rewriting and Optimization", "author": ["G. Go\u008alob", "G. Orsi", "A. Pieris"], "venue": "In Proc. of the International Conference on Data Engineering (ICDE),", "citeRegEx": "49", "shortCiteRegEx": "49", "year": 2011}, {"title": "Recent Advances in Datalog\u00b1", "author": ["G. Go\u008alob", "M. Morak", "A. Pieris"], "venue": "Reasoning Web 2015, Springer LNCS 9203,", "citeRegEx": "50", "shortCiteRegEx": "50", "year": 2015}, {"title": "A Description Logic with Transitive and Inverse Roles and Role Hierarchies", "author": ["I. Horrocks", "S. Sa\u008aler"], "venue": "ACM Transactions on Database Systems (TODS),", "citeRegEx": "52", "shortCiteRegEx": "52", "year": 1999}, {"title": "OLAP Dimension Constraints", "author": ["C. Hurtado", "A. Mendelzon"], "venue": "In Proc. of the ACM SIGMOD-SIGACT Symposium on Principles of Database Systems (PODS),", "citeRegEx": "53", "shortCiteRegEx": "53", "year": 2002}, {"title": "Capturing Summarizability with Integrity Constraints in OLAP", "author": ["C. Hurtado", "C. Gutierrez", "A. Mendelzon"], "venue": "ACM Transactions on Database Systems (TODS),", "citeRegEx": "54", "shortCiteRegEx": "54", "year": 2005}, {"title": "Incomplete Information in Relational Databases", "author": ["T. Imielinski", "W. Lipski"], "venue": "Journal of the ACM,", "citeRegEx": "55", "shortCiteRegEx": "55", "year": 1984}, {"title": "Multidimensional Databases and Data Warehousing", "author": ["Jensen", "Ch. S", "T. Bach Pedersen", "\u008comsen", "Ch"], "venue": null, "citeRegEx": "56", "shortCiteRegEx": "56", "year": 2010}, {"title": "Towards a Compositional Semantic Account of Data \u008bality A\u008aributes", "author": ["L. Jiang", "A. Borgida", "J. Mylopoulos"], "venue": "In Proc. International Conference on Conceptual Modeling (ER),", "citeRegEx": "57", "shortCiteRegEx": "57", "year": 2008}, {"title": "Testing Containment of Conjunctive \u008beries under Functional and Inclusion Dependencies", "author": ["D.S. Johnson", "A. Klug"], "venue": "In Proc. of the ACM SIGMOD-SIGACT Symposium on Principles of Database Systems (PODS),", "citeRegEx": "58", "shortCiteRegEx": "58", "year": 1984}, {"title": "Juran\u2019s \u0089ality Handbook, Fi\u0087h Edition", "author": ["J.M. Juran", "A.M. Godfrey"], "venue": null, "citeRegEx": "59", "shortCiteRegEx": "59", "year": 1999}, {"title": "\u008ce Complexity of Data Exchange", "author": ["P.G. Kolaitis", "W.C. Tan", "J. Pan\u008aaja"], "venue": "In Proc. of the ACM SIGMOD-SIGACT Symposium on Principles of Database Systems (PODS),", "citeRegEx": "60", "shortCiteRegEx": "60", "year": 2006}, {"title": "Inconsistency-Tolerant Semantics for Description Logics", "author": ["D. Lembo", "Lenzerini M", "R. Rosati", "M. Ruzzi", "D.F. Savo"], "venue": "In Proc. of the International Conference on Web Reasoning and Rule Systems (RR),", "citeRegEx": "61", "shortCiteRegEx": "61", "year": 2010}, {"title": "Inconsistency-tolerant \u008bery Answering in Ontology- Based Data Access", "author": ["D. Lembo", "Lenzerini M", "R. Rosati", "M. Ruzzi", "D.F. Savo"], "venue": "Journal of Web Semantics,", "citeRegEx": "62", "shortCiteRegEx": "62", "year": 2015}, {"title": "Data Integration: A \u008ceoretical Perspective", "author": ["M. Lenzerini"], "venue": "In Proc. of the ACM SIGMOD-SIGACT Symposium on Principles of Database Systems (PODS),", "citeRegEx": "63", "shortCiteRegEx": "63", "year": 2002}, {"title": "Inconsistency Handling in Datalog+/- Ontologies", "author": ["T. Lukasiewicz", "M. Martinez", "A. Pieris", "G. Simari"], "venue": "In Proc. of the European Conference on Arti\u0080cial Intelligence (ECAI),", "citeRegEx": "65", "shortCiteRegEx": "65", "year": 2012}, {"title": "From Classical to Consistent \u008bery Answering under Existential Rules", "author": ["T. Lukasiewicz", "M. Martinez", "A. Pieris", "G. Simari"], "venue": "In Proc. of the National Conference on Arti\u0080cial Intelligence (AAAI),", "citeRegEx": "66", "shortCiteRegEx": "66", "year": 2015}, {"title": "Ontology-Based Data Access with Closed Predicates is Inherently Intractable (Sometimes)", "author": ["C. Lutz", "I. Seylan", "F. Wolter"], "venue": "In Proc. of the International Joint Conference on Arti\u0080cial Intelligence (IJCAI),", "citeRegEx": "67", "shortCiteRegEx": "67", "year": 2013}, {"title": "Ontology-Mediated \u008beries with Closed Predicates", "author": ["C. Lutz", "I. Seylan", "F. Wolter"], "venue": "In Proc. of the International Joint Conference on Arti\u0080cial Intelligence (IJCAI),", "citeRegEx": "68", "shortCiteRegEx": "68", "year": 2015}, {"title": "Multidimensional Contexts for Data \u008bality Assessment", "author": ["A. Malaki", "L. Bertossi", "F. Rizzolo"], "venue": "In Proc. of the Alberto Mendelzon International Workshop on Foundations of Data Management (AMW),", "citeRegEx": "69", "shortCiteRegEx": "69", "year": 2012}, {"title": "Testing Implications of Data Dependencies", "author": ["D. Maier", "A. Mendelzon", "Y. Sagiv"], "venue": "ACM Transactions on Database Systems (TODS),", "citeRegEx": "70", "shortCiteRegEx": "70", "year": 1979}, {"title": "Taxonomy-Based Relaxation of \u008bery Answering in Relational Databases", "author": ["D. Martinenghi", "R. Torlone"], "venue": "\u008ae International Journal on Very Large Data Bases (VLDBJ),", "citeRegEx": "71", "shortCiteRegEx": "71", "year": 2014}, {"title": "\u008ce Implication Problem for Functional and Inclusion Dependencies", "author": ["J. Mitchell"], "venue": "Information and Control,", "citeRegEx": "72", "shortCiteRegEx": "72", "year": 1983}, {"title": "Ontology-Based Multidimensional Contexts with Applications to \u008bality Data Speci\u0080cation and Extraction", "author": ["M. Milani", "L. Bertossi"], "venue": "In Proc. of the International Symposium on Rules and Rule Markup Languages for the Semantic Web (RuleML),", "citeRegEx": "73", "shortCiteRegEx": "73", "year": 2015}, {"title": "Extending Weakly-Sticky Datalog\u00b1: \u008bery-Answering Tractability and Optimizations", "author": ["M. Milani", "L. Bertossi"], "venue": "In Proc. of the International Conference on Web Reasoning and Rule Systems (RR), Springer LNCS", "citeRegEx": "74", "shortCiteRegEx": "74", "year": 2016}, {"title": "A Hybrid Approach to \u008bery Answering under Expressive Datalog\u00b1", "author": ["M. Milani", "L. Bertossi", "A. Cal\u0300\u0131"], "venue": "In Proc. of the International Conference on Web Reasoning and Rule Systems (RR), Springer LNCS", "citeRegEx": "75", "shortCiteRegEx": "75", "year": 2016}, {"title": "Multidimensional Ontologies for Contextual \u0089ality Data Speci\u0080cation and Extraction", "author": ["M. Milani"], "venue": "PhD in Computer Science \u008cesis, Carleton University,", "citeRegEx": "76", "shortCiteRegEx": "76", "year": 2017}, {"title": "\u008ae Impact of Disjunction on Reasoning under Existential Rules", "author": ["M. Morak"], "venue": "PhD in Computer Science \u008cesis, University of Oxford,", "citeRegEx": "77", "shortCiteRegEx": "77", "year": 2015}, {"title": "An Integrating View on the Viewing Abstraction: Contexts and Perspectives in So\u0089ware Development, AI, and Databases", "author": ["R. Motschnig-Pitrik"], "venue": "Systems Integration,", "citeRegEx": "78", "shortCiteRegEx": "78", "year": 1995}, {"title": "A Generic Framework for the Modeling of Contexts and its Applications", "author": ["R. Motschnig-Pitrik"], "venue": "Data & Knowledge Engineering,", "citeRegEx": "79", "shortCiteRegEx": "79", "year": 2000}, {"title": "Contextual Database Preferences", "author": ["E. Pitoura", "K. Stefanidis", "P. Vassiliadis"], "venue": "IEE Data Engineering Bulletin,", "citeRegEx": "80", "shortCiteRegEx": "80", "year": 2011}, {"title": "Linking Data to Ontologies", "author": ["A. Poggi", "D. Lembo", "D. Calvanese", "G. De Giacomo", "M. Lenzerini", "R. Rosati"], "venue": "Data Semantics,", "citeRegEx": "81", "shortCiteRegEx": "81", "year": 2008}, {"title": "A Simple Method for Undecidability Proofs and Some Applications", "author": ["M.O. Rabin"], "venue": "In Logic, Methodology and Philosophy of Science, Proceedings of the 1964 International Congress, Bar-Hillel, Y. (ed.). Studies in Logic and the Foundations of Mathematics", "citeRegEx": "82", "shortCiteRegEx": "82", "year": 1965}, {"title": "\u008ce Impact of Poor Data \u008bality on the Typical Enterprise", "author": ["T. Redman"], "venue": "Communications of the ACM,", "citeRegEx": "83", "shortCiteRegEx": "83", "year": 1998}, {"title": "Towards a Logical Reconstruction of Relational Database \u008ceory", "author": ["R. Reiter"], "venue": "In On Conceptual Modelling,", "citeRegEx": "84", "shortCiteRegEx": "84", "year": 1984}, {"title": "On the Complexity of Dealing with Inconsistency in Description Logic Ontologies", "author": ["R. Rosati"], "venue": "In Proc. of the International Joint Conference on Arti\u0080cial Intelligence (IJCAI),", "citeRegEx": "85", "shortCiteRegEx": "85", "year": 2011}, {"title": "Towards a Context-Aware Relational Model", "author": ["Y. Rousoss", "Y. Stavrakas", "V. Pavlaki"], "venue": "In Proc. International Workshop on Context Representation and Reasoning,", "citeRegEx": "86", "shortCiteRegEx": "86", "year": 2005}, {"title": "E\u0082ective \u008bery Rewriting with Ontologies over DBoxes", "author": ["I. Seylan", "E. Franconi", "J. De Bruijn"], "venue": "In Proc. of the International Joint Conference on Arti\u0080cial Intelligence (IJCAI),", "citeRegEx": "87", "shortCiteRegEx": "87", "year": 2009}, {"title": "Beyond Accuracy: What Data \u008bality Means to Data Consumers", "author": ["Y. Wang R", "M. Strong D"], "venue": "Journal of Management Information Systems,", "citeRegEx": "90", "shortCiteRegEx": "90", "year": 1996}, {"title": "Repair-Oriented Relational Schemas for Multidimensional Databases", "author": ["M. Yaghmaie", "L. Bertossi", "S. Ariyan"], "venue": "In Proc. of the International Conference on Extending Database Technology (EDBT),", "citeRegEx": "91", "shortCiteRegEx": "91", "year": 2012}], "referenceMentions": [{"referenceID": 10, "context": "Assessing the quality of data and performing data cleaning when the data are not up to the expected standards of quality have been and will continue being common, di\u0081cult and costly problems in data management [12, 35, 83].", "startOffset": 210, "endOffset": 222}, {"referenceID": 32, "context": "Assessing the quality of data and performing data cleaning when the data are not up to the expected standards of quality have been and will continue being common, di\u0081cult and costly problems in data management [12, 35, 83].", "startOffset": 210, "endOffset": 222}, {"referenceID": 78, "context": "Assessing the quality of data and performing data cleaning when the data are not up to the expected standards of quality have been and will continue being common, di\u0081cult and costly problems in data management [12, 35, 83].", "startOffset": 210, "endOffset": 222}, {"referenceID": 10, "context": "Some of them are [12]: (1) Consistency, which refers to the validity and integrity of data representing real-world entities, typically identi\u0080ed with satisfaction of integrity constraints.", "startOffset": 17, "endOffset": 21}, {"referenceID": 36, "context": "also [39, 40, 57] for more on quality dimensions.", "startOffset": 5, "endOffset": 17}, {"referenceID": 37, "context": "also [39, 40, 57] for more on quality dimensions.", "startOffset": 5, "endOffset": 17}, {"referenceID": 53, "context": "also [39, 40, 57] for more on quality dimensions.", "startOffset": 5, "endOffset": 17}, {"referenceID": 10, "context": ") In this work we consider data quality as referring to the degree to which the data \u0080ts or ful\u0080lls a form of usage [12], relating our data quality concerns to the production and the use of data.", "startOffset": 116, "endOffset": 120}, {"referenceID": 14, "context": "In this work, building upon and considerably extending the framework in [16, 19], context-based data quality assessment, quality data extraction and data cleaning on a relational database D for a relational schema R are approached by creating a context model where D is the theory T above (it could be expressed as a logical theory [84]), the theory T c is a (logical) ontology Oc ; and, considering that we are using theories around data, the mappings can be logical mappings as used in virtual data integration [63] or data exchange [11].", "startOffset": 72, "endOffset": 80}, {"referenceID": 17, "context": "In this work, building upon and considerably extending the framework in [16, 19], context-based data quality assessment, quality data extraction and data cleaning on a relational database D for a relational schema R are approached by creating a context model where D is the theory T above (it could be expressed as a logical theory [84]), the theory T c is a (logical) ontology Oc ; and, considering that we are using theories around data, the mappings can be logical mappings as used in virtual data integration [63] or data exchange [11].", "startOffset": 72, "endOffset": 80}, {"referenceID": 79, "context": "In this work, building upon and considerably extending the framework in [16, 19], context-based data quality assessment, quality data extraction and data cleaning on a relational database D for a relational schema R are approached by creating a context model where D is the theory T above (it could be expressed as a logical theory [84]), the theory T c is a (logical) ontology Oc ; and, considering that we are using theories around data, the mappings can be logical mappings as used in virtual data integration [63] or data exchange [11].", "startOffset": 332, "endOffset": 336}, {"referenceID": 59, "context": "In this work, building upon and considerably extending the framework in [16, 19], context-based data quality assessment, quality data extraction and data cleaning on a relational database D for a relational schema R are approached by creating a context model where D is the theory T above (it could be expressed as a logical theory [84]), the theory T c is a (logical) ontology Oc ; and, considering that we are using theories around data, the mappings can be logical mappings as used in virtual data integration [63] or data exchange [11].", "startOffset": 513, "endOffset": 517}, {"referenceID": 9, "context": "In this work, building upon and considerably extending the framework in [16, 19], context-based data quality assessment, quality data extraction and data cleaning on a relational database D for a relational schema R are approached by creating a context model where D is the theory T above (it could be expressed as a logical theory [84]), the theory T c is a (logical) ontology Oc ; and, considering that we are using theories around data, the mappings can be logical mappings as used in virtual data integration [63] or data exchange [11].", "startOffset": 535, "endOffset": 539}, {"referenceID": 77, "context": "to obtain (un)decidability results [82].", "startOffset": 35, "endOffset": 39}, {"referenceID": 51, "context": "A more relaxed alternative consists in considering as quality data those that are obtained as certain answers to queries posed to D, but answered through \u0089al(D,Oc ): \u008ce query is posed to each of the instances in \u0089al(D,Oc ) (which essentially have the same schema as D), but only those answers that are shared by those instances are considered to be certain [55].", "startOffset": 357, "endOffset": 361}, {"referenceID": 52, "context": "\u008cey are the basic elements in multidimensional databases and data warehouses [56], where we usually \u0080nd time, location, product, as three dimensions that give context to numerical data, e.", "startOffset": 77, "endOffset": 81}, {"referenceID": 26, "context": "\u008ce language of choice for the contextual ontologies will be Datalog\u00b1 [28].", "startOffset": 69, "endOffset": 73}, {"referenceID": 27, "context": "One of those good classes is that of weakly-sticky Datalog\u00b1 [29].", "startOffset": 60, "endOffset": 64}, {"referenceID": 49, "context": "Programs in that class allow us to represent a logic-based, relational reconstruction and extension of the Hurtado-Mendelzon multidimensional data model [53, 54], which allows us to bring data dimensions into contexts.", "startOffset": 153, "endOffset": 161}, {"referenceID": 50, "context": "Programs in that class allow us to represent a logic-based, relational reconstruction and extension of the Hurtado-Mendelzon multidimensional data model [53, 54], which allows us to bring data dimensions into contexts.", "startOffset": 153, "endOffset": 161}, {"referenceID": 12, "context": "2 \u008cose familiar with database repairs and consistent query answering [14, 17], would notice that both can be formulated in this general ste\u008aing.", "startOffset": 69, "endOffset": 77}, {"referenceID": 15, "context": "2 \u008cose familiar with database repairs and consistent query answering [14, 17], would notice that both can be formulated in this general ste\u008aing.", "startOffset": 69, "endOffset": 77}, {"referenceID": 30, "context": "Instance D would be the inconsistent database, the ontology would provide the integrity constraints and the speci\u0080cation of repairs, say in answer set programming [32], the class \u0089al(D, Oc ) would contain the repairs, and the general certain answers would become the consistent answers.", "startOffset": 163, "endOffset": 167}, {"referenceID": 14, "context": "3 Data dimensions were not considered in [16, 19].", "startOffset": 41, "endOffset": 49}, {"referenceID": 17, "context": "3 Data dimensions were not considered in [16, 19].", "startOffset": 41, "endOffset": 49}, {"referenceID": 76, "context": "about indirectly accessing underlying data through queries posed to the interface and elements of an ontology [81].", "startOffset": 110, "endOffset": 114}, {"referenceID": 10, "context": "\u008ce promising application of the OMD model that we investigate in this work is related to data quality concerns as pertaining to the use and production of data [12].", "startOffset": 159, "endOffset": 163}, {"referenceID": 83, "context": "For example, in [90] contextual data quality dimensions are described as those quality dimensions that are relevant to the context of data usage.", "startOffset": 16, "endOffset": 20}, {"referenceID": 55, "context": "In [51] and [59], quality is characterized as \u201c\u0080tness for use\u201d.", "startOffset": 12, "endOffset": 16}, {"referenceID": 10, "context": "From this point of view, we are implicitly addressing a problem of incomplete data, one of the common data quality dimensions [12].", "startOffset": 126, "endOffset": 130}, {"referenceID": 27, "context": "(B) We establish that, under natural assumptions that MD ontologies belong to the class of weaklysticky (WS) Datalog\u00b1 programs [29], for which conjunctive QA is tractable (in data).", "startOffset": 127, "endOffset": 131}, {"referenceID": 27, "context": "\u008ce class of WS programs is an extension of sticky Datalog\u00b1[29] and weakly-acyclic programs [37].", "startOffset": 58, "endOffset": 62}, {"referenceID": 34, "context": "\u008ce class of WS programs is an extension of sticky Datalog\u00b1[29] and weakly-acyclic programs [37].", "startOffset": 91, "endOffset": 95}, {"referenceID": 34, "context": "Actually, WS Datalog\u00b1 is de\u0080ned through restrictions on join variables occurring in in\u0080nite-rank positions, as introduced in [37].", "startOffset": 125, "endOffset": 129}, {"referenceID": 69, "context": "However, in [74] a practical algorithm was proposed, together with a methodology for magic-setbased query optimization.", "startOffset": 12, "endOffset": 16}, {"referenceID": 8, "context": "5 In the case of duplicate records in a data source, the context could contain an answer set program or a Datalog program to enforce matching dependencies for entity resolution [10].", "startOffset": 177, "endOffset": 181}, {"referenceID": 14, "context": "Of course, di\u0082erent distance measures may be used for this purpose [16, 19].", "startOffset": 67, "endOffset": 75}, {"referenceID": 17, "context": "Of course, di\u0082erent distance measures may be used for this purpose [16, 19].", "startOffset": 67, "endOffset": 75}, {"referenceID": 25, "context": "Most importantly, the combination of constraints that are equality-generating dependencies (egds) and the rules, which are tuple-generating dependencies (tgds) [27], may lead to undecidability of QA.", "startOffset": 160, "endOffset": 164}, {"referenceID": 27, "context": "Separability [29] is a semantic condition on egds and tgds that guarantees the interaction between them does not harm the tractability of QA.", "startOffset": 13, "endOffset": 17}, {"referenceID": 66, "context": "\u008ce closest work related to our OMD model can be found in the dimensional relational algebra proposed in [71], which is subsumed by the OMD model [76, chap.", "startOffset": 104, "endOffset": 108}, {"referenceID": 23, "context": "\u008ce contextual and dimensional data representation framework in [25] is also close to our OMD model in that it uses dimensions for modeling context.", "startOffset": 63, "endOffset": 67}, {"referenceID": 68, "context": "\u008cis paper considerably extends results previously reported in [73].", "startOffset": 62, "endOffset": 66}, {"referenceID": 79, "context": "In the former case, one makes the meta-level assumption, the so-called closed-world-assumption (CWA) [1, 84], that the only positive ground atoms that are true w.", "startOffset": 101, "endOffset": 108}, {"referenceID": 11, "context": "8 Without any syntactic restrictions on the program, and even for programs without constraints, conjunctive query answering (CQA) may be undecidable [13].", "startOffset": 149, "endOffset": 153}, {"referenceID": 65, "context": "However, the chase procedure [70] can be used to generate a single, possibly in\u0080nite, instance that represents the class Mod(\u03a0,D) for this purpose.", "startOffset": 29, "endOffset": 33}, {"referenceID": 29, "context": "However, it is possible to de\u0080ne a canonical chase procedure that determines a canonical sequence of chase steps, and consequently, a canonical chase instance [31].", "startOffset": 159, "endOffset": 163}, {"referenceID": 34, "context": "Given a program \u03a0 and extensional database D, its chase (instance) is a universal model [37]: For every I \u2208 Mod(\u03a0,D), there is a homomorphism from the chase into I .", "startOffset": 88, "endOffset": 92}, {"referenceID": 34, "context": "For this reason, the (certain) answers to a CQ Q under \u03a0 and D can be computed by evaluating Q over the chase instance (and discarding the answers containing nulls) [37].", "startOffset": 165, "endOffset": 169}, {"referenceID": 29, "context": "checking if a tuple is an answer to a CQ query, can be reduced to BCQ answering as shown in [31], and they have the same data complexity.", "startOffset": 92, "endOffset": 96}, {"referenceID": 29, "context": "If \u03a0 has egds, they are expected to be satis\u0080ed by a modi\u0080ed (canonical) chase [31] that also enforces the egds.", "startOffset": 79, "endOffset": 83}, {"referenceID": 49, "context": "According to the Hurtado-Mendelzon multidimensional data model (in short, the HMmodel) [53], a dimension schema, H = \u3008K ,\u2197\u3009, consists of a \u0080nite set K of categories, and an irre\u0083exive, binary relation\u2197, called the child-parent relation, between categories (the \u0080rst category is a child and the second category is a parent).", "startOffset": 87, "endOffset": 91}, {"referenceID": 0, "context": "For example, the following IDs: WardUnit[1] \u2286 Ward[1], and WardUnit[2] \u2286 Unit[1].", "startOffset": 67, "endOffset": 70}, {"referenceID": 0, "context": "Accordingly, if child-parent predicate P \u2208 L is associated to category predicates K ,K \u2032 \u2208 K , in this order, we introduce IDs P[1] \u2286 K[1] and P[2] \u2286 K \u2032[1]), as ncs: P(x ,x \u2032),\u00acK(x) \u2192 \u22a5, and P(x ,x \u2032),\u00acK \u2032(x \u2032) \u2192 \u22a5.", "startOffset": 144, "endOffset": 147}, {"referenceID": 0, "context": ", which is captured by the IDs WorkSchedules[1] \u2286 Unit[1], and WorkSchedules[2] \u2286 Day[1].", "startOffset": 76, "endOffset": 79}, {"referenceID": 0, "context": "For the Hospital dimension, one of the two IDs for the child-parent predicate WardUnit is WardUnit[2] \u2286 Unit[1], which is expressed by an nc of the form (14):", "startOffset": 98, "endOffset": 101}, {"referenceID": 29, "context": "that is not intertwined with recursion, is considered in [31].", "startOffset": 57, "endOffset": 61}, {"referenceID": 25, "context": "As mentioned before, without any restrictions Datalog programs conjunctive query answering (CQA) may be undecidable, even without constraints [27].", "startOffset": 142, "endOffset": 146}, {"referenceID": 34, "context": "1 Weakly-Acyclic, Sticky and Weakly-Sticky Programs Weakly-acyclicDatalog\u00b1 programs (without constraints) form a syntactic class of Datalog programs that is de\u0080ned appealing to the notion of dependency graph [37].", "startOffset": 208, "endOffset": 212}, {"referenceID": 0, "context": "P[2] R[1]", "startOffset": 1, "endOffset": 4}, {"referenceID": 0, "context": "R[2] U [1]", "startOffset": 1, "endOffset": 4}, {"referenceID": 0, "context": "R[2] and P[2] have rank 1.", "startOffset": 1, "endOffset": 4}, {"referenceID": 0, "context": "R[2] and P[2] have rank 1.", "startOffset": 10, "endOffset": 13}, {"referenceID": 0, "context": "\u008cen, \u03c0F (\u03a0) = {U [1],R[1], P[1],R[2], P[2]}, and \u03a0 is WA.", "startOffset": 33, "endOffset": 36}, {"referenceID": 0, "context": "\u008cen, \u03c0F (\u03a0) = {U [1],R[1], P[1],R[2], P[2]}, and \u03a0 is WA.", "startOffset": 39, "endOffset": 42}, {"referenceID": 34, "context": "\u008ce chase for these programs stops in polynomial time in the size of the extensional data, making CQA ptime-complete in data complexity [37], but 2exptime-complete in combined complexity, i.", "startOffset": 135, "endOffset": 139}, {"referenceID": 56, "context": "in the combined size of the program, query and data [60].", "startOffset": 52, "endOffset": 56}, {"referenceID": 27, "context": "[29] and [74] for a more detailed discussion).", "startOffset": 0, "endOffset": 4}, {"referenceID": 69, "context": "[29] and [74] for a more detailed discussion).", "startOffset": 9, "endOffset": 13}, {"referenceID": 27, "context": "(It is exptime-complete in combined complexity [29].", "startOffset": 47, "endOffset": 51}, {"referenceID": 46, "context": ") Even more, CQA over sticky programs enjoys \u0080rst-order rewritable [49], that is, a CQ posed to the program can be rewri\u008aen into an FO query that can be evaluated directly on the extensional data.", "startOffset": 67, "endOffset": 71}, {"referenceID": 0, "context": "Now, \u03c0F (\u03a0\u2032) = \u2205, and the marked join variable y in the second rule appears in R[1] and R[2], both non-\u0080nite (i.", "startOffset": 89, "endOffset": 92}, {"referenceID": 69, "context": "[74] for a discussion).", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "CQA is tractable, but ptime-complete in data, and 2exptime-complete in combined complexity [29].", "startOffset": 91, "endOffset": 95}, {"referenceID": 2, "context": ") For the MD ontology with \u03c31 and \u03c32, WorkSchedules[4] and Shi\u0087s[4] have in\u0080nite rank; and all the other positions have \u0080nite rank.", "startOffset": 51, "endOffset": 54}, {"referenceID": 2, "context": ") For the MD ontology with \u03c31 and \u03c32, WorkSchedules[4] and Shi\u0087s[4] have in\u0080nite rank; and all the other positions have \u0080nite rank.", "startOffset": 64, "endOffset": 67}, {"referenceID": 27, "context": "\u008ce tractability (in data) of CQA under WS programs was established in [29] on theoretical grounds, without providing a practical algorithm.", "startOffset": 70, "endOffset": 74}, {"referenceID": 69, "context": "An implementable, polynomial-time algorithm for CQA under WS programs is presented in [74].", "startOffset": 86, "endOffset": 90}, {"referenceID": 2, "context": "Actually, the algorithm can be applied to a class that not only extends WS, but is also closed under magic-set rewriting of Datalog programs [4], which allows for query-dependent optimizations of the program [74].", "startOffset": 141, "endOffset": 144}, {"referenceID": 69, "context": "Actually, the algorithm can be applied to a class that not only extends WS, but is also closed under magic-set rewriting of Datalog programs [4], which allows for query-dependent optimizations of the program [74].", "startOffset": 208, "endOffset": 212}, {"referenceID": 70, "context": "However, a hybrid algorithm is proposed in [75].", "startOffset": 43, "endOffset": 47}, {"referenceID": 29, "context": "When the (combined) chase does not fail, the result is a possibly in\u0080nite universal model that satis\u0080es both the tgds and egds [31].", "startOffset": 127, "endOffset": 131}, {"referenceID": 25, "context": "\u008ce interaction of tgds and egds may lead to undecidability of CQA [27, 34, 58, 72].", "startOffset": 66, "endOffset": 82}, {"referenceID": 31, "context": "\u008ce interaction of tgds and egds may lead to undecidability of CQA [27, 34, 58, 72].", "startOffset": 66, "endOffset": 82}, {"referenceID": 54, "context": "\u008ce interaction of tgds and egds may lead to undecidability of CQA [27, 34, 58, 72].", "startOffset": 66, "endOffset": 82}, {"referenceID": 67, "context": "\u008ce interaction of tgds and egds may lead to undecidability of CQA [27, 34, 58, 72].", "startOffset": 66, "endOffset": 82}, {"referenceID": 27, "context": "However, a separability property of the combination of egds and tgds guarantees a harmless interaction that makes CQA decidable and preserves CQA [29]: For a program \u03a0 with extensional database D, a set of tgds \u03a0R , and a set of egds \u03a0C , \u03a0R and \u03a0C are separable if either (a) the chase with \u03a0 fails, or (b) for any BCQ Q, \u03a0 |= Q if and only if \u03a0R \u222a D |= Q.", "startOffset": 146, "endOffset": 150}, {"referenceID": 28, "context": "However, separability is undecidable [30].", "startOffset": 37, "endOffset": 41}, {"referenceID": 29, "context": "Such a condition has been identi\u0080ed for egds that are key constraints [31]; it is that of non-con\u0083icting interaction.", "startOffset": 70, "endOffset": 74}, {"referenceID": 27, "context": "15 \u008ce notion has been extended to FDs in [29]: A set of tgds \u03a0R and a set \u03a0C of FDs are non-con\u0083icting if, for every tgd \u03c3 , with set U\u03c3 of non-existential(lly quanti\u0080ed variables for) a\u008aributes in head(\u03c3 ), and FD \u03b5 of the form R : \u0100\u2192 B\u0304 , at least one of the following holds: (a) head(\u03c3 ) is not an R-atom, (b) U\u03c3 + \u0100, or (c) U\u03c3 = \u0100 and each \u2203-variable in \u03c3 occurs just once in the head of \u03c3 .", "startOffset": 41, "endOffset": 45}, {"referenceID": 14, "context": "\u008ce use of the OMD model for quality data speci\u0080cation and extraction generalizes a previous approach to- and work on context-based data quality assessment and extraction [16, 19], which was brie\u0083y described in Section 1.", "startOffset": 170, "endOffset": 178}, {"referenceID": 17, "context": "\u008ce use of the OMD model for quality data speci\u0080cation and extraction generalizes a previous approach to- and work on context-based data quality assessment and extraction [16, 19], which was brie\u0083y described in Section 1.", "startOffset": 170, "endOffset": 178}, {"referenceID": 14, "context": "18 E could represent data brought from external sources, possible at query answering time [16, 19].", "startOffset": 90, "endOffset": 98}, {"referenceID": 17, "context": "18 E could represent data brought from external sources, possible at query answering time [16, 19].", "startOffset": 90, "endOffset": 98}, {"referenceID": 6, "context": "In this regard, it may happen that the combination of Datalog\u00b1 ontologies that enjoy good computational properties may be an ontology without such properties [8, 9].", "startOffset": 158, "endOffset": 164}, {"referenceID": 7, "context": "In this regard, it may happen that the combination of Datalog\u00b1 ontologies that enjoy good computational properties may be an ontology without such properties [8, 9].", "startOffset": 158, "endOffset": 164}, {"referenceID": 2, "context": "Now, \u03a3 = {\u03c31,\u03c32,\u03c33} is not WS since variable s in the body of \u03c33 is a repeated marked body variable only appearing in in\u0080nite-rank position Shi\u0087s[4].", "startOffset": 145, "endOffset": 148}, {"referenceID": 69, "context": "If it is a weaklysticky Datalog\u00b1 ontology, we can use the chase-based algorithm introduced in [74].", "startOffset": 94, "endOffset": 98}, {"referenceID": 69, "context": "20Actually the algorithm applies to a larger class of Datalog\u00b1 ontologies, that of join-weakly-sticky programs that is closed under magic-sets optimizations [74].", "startOffset": 157, "endOffset": 161}, {"referenceID": 69, "context": "Finally, at Step 4 of \u0083alityQA, QM is answered as a CQ over OM and database D \u2032,22 using, for example, the QA algorithms in [74, 75].", "startOffset": 124, "endOffset": 132}, {"referenceID": 70, "context": "Finally, at Step 4 of \u0083alityQA, QM is answered as a CQ over OM and database D \u2032,22 using, for example, the QA algorithms in [74, 75].", "startOffset": 124, "endOffset": 132}, {"referenceID": 14, "context": "For that, we followed and extended the approach in [16, 19], by proposing ontological contexts, and embedding multidimensional (MD) data models in them.", "startOffset": 51, "endOffset": 59}, {"referenceID": 17, "context": "For that, we followed and extended the approach in [16, 19], by proposing ontological contexts, and embedding multidimensional (MD) data models in them.", "startOffset": 51, "endOffset": 59}, {"referenceID": 49, "context": "For the la\u008aer, we took advantage of our relational reconstruction of the HM data model [53, 54].", "startOffset": 87, "endOffset": 95}, {"referenceID": 50, "context": "For the la\u008aer, we took advantage of our relational reconstruction of the HM data model [53, 54].", "startOffset": 87, "endOffset": 95}, {"referenceID": 71, "context": "[76]), it is possible to include in the ontological contexts semantic constraints usually present in the HM model, such as strictness and homogeneity,23 which guarantee summarizability (or aggregation) for the correct computation of cube views [53].", "startOffset": 0, "endOffset": 4}, {"referenceID": 49, "context": "[76]), it is possible to include in the ontological contexts semantic constraints usually present in the HM model, such as strictness and homogeneity,23 which guarantee summarizability (or aggregation) for the correct computation of cube views [53].", "startOffset": 244, "endOffset": 248}, {"referenceID": 16, "context": "Our approach to quality data speci\u0080cation and extraction is declarative [18, 39].", "startOffset": 72, "endOffset": 80}, {"referenceID": 36, "context": "Our approach to quality data speci\u0080cation and extraction is declarative [18, 39].", "startOffset": 72, "endOffset": 80}, {"referenceID": 69, "context": "\u008ce algorithm and its optimization is based on our work on QA under WS programs [74, 75].", "startOffset": 79, "endOffset": 87}, {"referenceID": 70, "context": "\u008ce algorithm and its optimization is based on our work on QA under WS programs [74, 75].", "startOffset": 79, "endOffset": 87}, {"referenceID": 60, "context": "A common approach to DL or Datalog\u00b1 ontology repair has been based on repairing the extensional database in the case of Datalog\u00b1 [65], and the A-Box in the case of DL [20, 21, 61, 62, 85] ontologies.", "startOffset": 129, "endOffset": 133}, {"referenceID": 18, "context": "A common approach to DL or Datalog\u00b1 ontology repair has been based on repairing the extensional database in the case of Datalog\u00b1 [65], and the A-Box in the case of DL [20, 21, 61, 62, 85] ontologies.", "startOffset": 167, "endOffset": 187}, {"referenceID": 19, "context": "A common approach to DL or Datalog\u00b1 ontology repair has been based on repairing the extensional database in the case of Datalog\u00b1 [65], and the A-Box in the case of DL [20, 21, 61, 62, 85] ontologies.", "startOffset": 167, "endOffset": 187}, {"referenceID": 57, "context": "A common approach to DL or Datalog\u00b1 ontology repair has been based on repairing the extensional database in the case of Datalog\u00b1 [65], and the A-Box in the case of DL [20, 21, 61, 62, 85] ontologies.", "startOffset": 167, "endOffset": 187}, {"referenceID": 58, "context": "A common approach to DL or Datalog\u00b1 ontology repair has been based on repairing the extensional database in the case of Datalog\u00b1 [65], and the A-Box in the case of DL [20, 21, 61, 62, 85] ontologies.", "startOffset": 167, "endOffset": 187}, {"referenceID": 80, "context": "A common approach to DL or Datalog\u00b1 ontology repair has been based on repairing the extensional database in the case of Datalog\u00b1 [65], and the A-Box in the case of DL [20, 21, 61, 62, 85] ontologies.", "startOffset": 167, "endOffset": 187}, {"referenceID": 58, "context": "QA under this semantics is np-hard in the size of I , already for DL [62] or Datalog\u00b1 ontologies [65, 66] with relatively low expressive power.", "startOffset": 69, "endOffset": 73}, {"referenceID": 60, "context": "QA under this semantics is np-hard in the size of I , already for DL [62] or Datalog\u00b1 ontologies [65, 66] with relatively low expressive power.", "startOffset": 97, "endOffset": 105}, {"referenceID": 61, "context": "QA under this semantics is np-hard in the size of I , already for DL [62] or Datalog\u00b1 ontologies [65, 66] with relatively low expressive power.", "startOffset": 97, "endOffset": 105}, {"referenceID": 4, "context": "Repairs and consistent answers from MD databases have been investigated in [6, 7, 15], and also in [91], which proposes the path schema for MD databases as a be\u008aer relational schema for dealing with the kinds of inconsistencies that appear in them.", "startOffset": 75, "endOffset": 85}, {"referenceID": 5, "context": "Repairs and consistent answers from MD databases have been investigated in [6, 7, 15], and also in [91], which proposes the path schema for MD databases as a be\u008aer relational schema for dealing with the kinds of inconsistencies that appear in them.", "startOffset": 75, "endOffset": 85}, {"referenceID": 13, "context": "Repairs and consistent answers from MD databases have been investigated in [6, 7, 15], and also in [91], which proposes the path schema for MD databases as a be\u008aer relational schema for dealing with the kinds of inconsistencies that appear in them.", "startOffset": 75, "endOffset": 85}, {"referenceID": 84, "context": "Repairs and consistent answers from MD databases have been investigated in [6, 7, 15], and also in [91], which proposes the path schema for MD databases as a be\u008aer relational schema for dealing with the kinds of inconsistencies that appear in them.", "startOffset": 99, "endOffset": 103}, {"referenceID": 12, "context": "As pointed out in Section 1, context-based quality data extraction is reminiscent of database repairing and consistent query answering [14, 17].", "startOffset": 135, "endOffset": 143}, {"referenceID": 15, "context": "As pointed out in Section 1, context-based quality data extraction is reminiscent of database repairing and consistent query answering [14, 17].", "startOffset": 135, "endOffset": 143}, {"referenceID": 15, "context": "\u008ce rewriting re\u0083ects a repair semantics based on deletions of tuples from Temperatures\u2032 when the constraint is not satis\u0080ed [17].", "startOffset": 124, "endOffset": 128}, {"referenceID": 58, "context": "However, this has been a predominant approach to OBDA with inconsistent ontologies [62, 65, 66]: the ontology is repaired by repairing the extensional instance and considering the intersection of its repairs (cf.", "startOffset": 83, "endOffset": 95}, {"referenceID": 60, "context": "However, this has been a predominant approach to OBDA with inconsistent ontologies [62, 65, 66]: the ontology is repaired by repairing the extensional instance and considering the intersection of its repairs (cf.", "startOffset": 83, "endOffset": 95}, {"referenceID": 61, "context": "However, this has been a predominant approach to OBDA with inconsistent ontologies [62, 65, 66]: the ontology is repaired by repairing the extensional instance and considering the intersection of its repairs (cf.", "startOffset": 83, "endOffset": 95}, {"referenceID": 79, "context": "\u008cis interpretation of quanti\u0080ers is possible if we have a metalevel CWA assumption or a domain closure axioms [84] over (some) predicates, none of which is part of Datalog\u00b1.", "startOffset": 110, "endOffset": 114}, {"referenceID": 0, "context": "Recent work in OBDA addresses this problem, allowing the combination of open and closed predicates in Datalog\u00b1 ontologies, but previously tractable CQA may become intractable [2].", "startOffset": 175, "endOffset": 178}, {"referenceID": 41, "context": "Similar extensions and results hold for light-weight DLs [44, 67, 68, 87].", "startOffset": 57, "endOffset": 73}, {"referenceID": 62, "context": "Similar extensions and results hold for light-weight DLs [44, 67, 68, 87].", "startOffset": 57, "endOffset": 73}, {"referenceID": 63, "context": "Similar extensions and results hold for light-weight DLs [44, 67, 68, 87].", "startOffset": 57, "endOffset": 73}, {"referenceID": 82, "context": "Similar extensions and results hold for light-weight DLs [44, 67, 68, 87].", "startOffset": 57, "endOffset": 73}, {"referenceID": 1, "context": "As an alternative to existential categorical variables as choices from given (possibly closed) sets of values, we could think of using disjunctive Datalog\u00b1, with disjunctive tgds [3, 26], in particular for downward navigation.", "startOffset": 179, "endOffset": 186}, {"referenceID": 24, "context": "As an alternative to existential categorical variables as choices from given (possibly closed) sets of values, we could think of using disjunctive Datalog\u00b1, with disjunctive tgds [3, 26], in particular for downward navigation.", "startOffset": 179, "endOffset": 186}, {"referenceID": 47, "context": "However, CQA under disjunctive sticky-Datalog\u00b1 may be undecidable in some cases [50, 77].", "startOffset": 80, "endOffset": 88}, {"referenceID": 72, "context": "However, CQA under disjunctive sticky-Datalog\u00b1 may be undecidable in some cases [50, 77].", "startOffset": 80, "endOffset": 88}, {"referenceID": 40, "context": "As a logical extension of a multidimensional data model, our model is similar in spirit to the data warehouse conceptual data model [43] that extends the entity-relationship data model with dimensions by means of the expressive description logic (DL) ALCFI [52].", "startOffset": 132, "endOffset": 136}, {"referenceID": 48, "context": "As a logical extension of a multidimensional data model, our model is similar in spirit to the data warehouse conceptual data model [43] that extends the entity-relationship data model with dimensions by means of the expressive description logic (DL) ALCFI [52].", "startOffset": 257, "endOffset": 261}, {"referenceID": 64, "context": "In [69], preliminary work motivated by data quality on specifying MD ontologies in light-weight DLs is reported, without going much into quality aspects or query answering.", "startOffset": 3, "endOffset": 7}, {"referenceID": 16, "context": "\u008ce existing declarative approaches to data quality [18] mostly use classic ICs, such as FDs and IDs, and denial constraints (i.", "startOffset": 51, "endOffset": 55}, {"referenceID": 35, "context": "Newer classes of dependencies have been introduced to capture data quality conditions and directly support data cleaning processes [38].", "startOffset": 131, "endOffset": 135}, {"referenceID": 38, "context": "Examples are conditional dependencies (conditional FDs and IDs), and matching dependencies [41, 42].", "startOffset": 91, "endOffset": 99}, {"referenceID": 39, "context": "Examples are conditional dependencies (conditional FDs and IDs), and matching dependencies [41, 42].", "startOffset": 91, "endOffset": 99}, {"referenceID": 20, "context": "Models of context [22] have been proposed and investigated in the data management and knowledge representation literature.", "startOffset": 18, "endOffset": 22}, {"referenceID": 45, "context": "Multi Context Systems (MCS) [48] and Local Models Semantics (LMS) [46, 47] are related logicbased frameworks for formalizing contexts and reasoning with them.", "startOffset": 28, "endOffset": 32}, {"referenceID": 43, "context": "Multi Context Systems (MCS) [48] and Local Models Semantics (LMS) [46, 47] are related logicbased frameworks for formalizing contexts and reasoning with them.", "startOffset": 66, "endOffset": 74}, {"referenceID": 44, "context": "Multi Context Systems (MCS) [48] and Local Models Semantics (LMS) [46, 47] are related logicbased frameworks for formalizing contexts and reasoning with them.", "startOffset": 66, "endOffset": 74}, {"referenceID": 73, "context": "In [78, 79], a general framework is proposed based on the concept of viewing for decomposing information bases into possibly overlapping fragments, called contexts, in order to be able to be\u008aer manage and customize information.", "startOffset": 3, "endOffset": 11}, {"referenceID": 74, "context": "In [78, 79], a general framework is proposed based on the concept of viewing for decomposing information bases into possibly overlapping fragments, called contexts, in order to be able to be\u008aer manage and customize information.", "startOffset": 3, "endOffset": 11}, {"referenceID": 3, "context": "In [5, 89], a model of contexts in information bases is proposed.", "startOffset": 3, "endOffset": 10}, {"referenceID": 42, "context": "In [45], ideas from [46], specially LMS, are applied to information integration and federated database management, where each database may have its own local semantics.", "startOffset": 3, "endOffset": 7}, {"referenceID": 43, "context": "In [45], ideas from [46], specially LMS, are applied to information integration and federated database management, where each database may have its own local semantics.", "startOffset": 20, "endOffset": 24}, {"referenceID": 22, "context": "Context-aware data tailoring [24] proposes context dimension trees (CDTs) for modeling multidimensional aspects of context.", "startOffset": 29, "endOffset": 33}, {"referenceID": 21, "context": "\u008cis user\u2019s view is computed by combining the sub-views linked to dimension values [23, 25].", "startOffset": 82, "endOffset": 90}, {"referenceID": 23, "context": "\u008cis user\u2019s view is computed by combining the sub-views linked to dimension values [23, 25].", "startOffset": 82, "endOffset": 90}, {"referenceID": 66, "context": "In [71] dimensions, as in multidimensional databases, are used for modeling contexts.", "startOffset": 3, "endOffset": 7}, {"referenceID": 75, "context": "In [80, 88] contexts are used in preference database systems to support context-aware queries whose results depend on the context at the time of their submission.", "startOffset": 3, "endOffset": 11}, {"referenceID": 81, "context": "\u008ce context relational model (CR) model [86] extends the relational model with contexts, which are treated as \u0080rst-class citizens, at the level of database models and query languages.", "startOffset": 39, "endOffset": 43}], "year": 2017, "abstractText": "Data quality assessment and data cleaning are context-dependent activities. Motivated by this observation, we propose the Ontological Multidimensional Data Model (OMD model), which can be used to model and represent contexts as logic-based ontologies. \u008ce data under assessment is mapped into the context, for additional analysis, processing, and quality data extraction. \u008ce resulting contexts allow for the representation of dimensions, and multidimensional data quality assessment becomes possible. At the core of a multidimensional context we include a generalized multidimensional data model and a Datalog\u00b1 ontology with provably good properties in terms of query answering. \u008cese main components are used to represent dimension hierarchies, dimensional constraints, dimensional rules, and de\u0080ne predicates for quality data speci\u0080cation. \u008bery answering relies upon and triggers navigation through dimension hierarchies, and becomes the basic tool for the extraction of quality data. \u008ce OMD model is interesting per se, beyond applications to data quality. It allows for a logic-based, and computationally tractable representation of multidimensional data, extending previous multidimensional data models with additional expressive power and functionalities.", "creator": "LaTeX with hyperref package"}}}