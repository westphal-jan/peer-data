{"id": "1704.00177", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Apr-2017", "title": "Sentiment Analysis of Citations Using Word2vec", "abstract": "Citation sentiment analysis is an important task in scientific paper analysis. Existing machine learning techniques for citation sentiment analysis are focusing on labor-intensive feature engineering, which requires large annotated corpus. As an automatic feature extraction tool, word2vec has been successfully applied to sentiment analysis of short texts. In this work, I conducted empirical research with the question: how well does word2vec work on the sentiment analysis of citations? The proposed method constructed sentence vectors (sent2vec) by averaging the word embeddings, which were learned from Anthology Collections (ACL-Embeddings). I also investigated polarity-specific word embeddings (PS-Embeddings) for classifying positive and negative citations. The sentence vectors formed a feature space, to which the examined citation sentence was mapped to. Those features were input into classifiers (support vector machines) for supervised classification. Using 10-cross-validation scheme, evaluation was conducted on a set of annotated citations. The results showed that word embeddings are effective on classifying positive and negative citations. However, hand-crafted features performed better for the overall classification.", "histories": [["v1", "Sat, 1 Apr 2017 14:53:54 GMT  (19kb)", "http://arxiv.org/abs/1704.00177v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["haixia liu"], "accepted": false, "id": "1704.00177"}, "pdf": {"name": "1704.00177.pdf", "metadata": {"source": "CRF", "title": "Sentiment Analysis of Citations Using Word2vec", "authors": ["Haixia Liu"], "emails": ["khyx3lhi@nottingham.edu.my"], "sections": [{"heading": null, "text": "ar Xiv: 170 4.00 177v 1 [cs.C L] 1A prKeywords: mood analysis, word2vec"}, {"heading": "1 Introduction", "text": "The development of scientific ideas occurs when old ideas are replaced by new ones. Researchers usually conduct scientific experiments on the basis of previous publications. They either use other methods to solve their specific problem, or they improve the results documented in previous publications by introducing new solutions. I refer to the former as positive quotations and the later negative quotations. They are shown in Table 1.Sentiment analysis of quotations that play an important role in the creation of scientific ideas."}, {"heading": "2 Related Work", "text": "Mikolov et al. introduced the word2vec technique [4], which can be obtained by creating a text corpus of word vectors. word2vec (word embeddings) originated from the concept of distributed representation of words [6]. The common method of deriving the vectors is the use of a neural probabilistic language model [7]. Word embeddings proved to be effective representations in the tasks of sentiment analysis [5, 8, 9] and text classification [10]. Sadeghian and Sharafat [11] extended word embeddings to sentence embeddings by transferring the word vectors into a sentiment review statement. Their results showed that word embeddings exceeded the sentiment model in sentiment classification. In this work, my work aimed at evaluating word embeddings for sentiment analysis of quotations. The research questions are: 1. How do general negates work vevec 2. do word-specific classification work?"}, {"heading": "3 Methodology", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Pre-processing", "text": "The SentenceModel provided by LingPipe was used to segment raw text into its constituent parts 3. The data I train the vectors with has noise. For example, incomplete sentences are incorrectly detected (e.g., release year).3 To solve this problem, I eliminated sentences with less than three words.3 http: / / alias-i.com / lingpipe / docs / api / com / aliasi / sentences / SentenceModel.html"}, {"heading": "3.2 Overall Sent2vec Training", "text": "In the work, I constructed sentence embeddings based on word embeddings. I simply determined the vectors of the words in a sentence to obtain sentence embeddings (sent2vec). The main process in this step is to learn the word embeddings matrix Ww: Vsent2vec (w) = 1n \u2211 W xiw (1), where Ww (w = < w1, x2,... wn >) is the word embeddings for word xi that could be learned through the classic word2vec algorithm [4]. The parameters with which I trained the word embeddings are the same as in the work of Sadeghian and Sharafat."}, {"heading": "3.3 Polarity-Specific Word Representation Training", "text": "To improve the results of the classification of sentiment citations, I trained polarity-specific word embeddings (PS embeddings) inspired by sentiment-specific word embedding [5]. After receiving the PS embeddings, I used the same scheme to cross the vectors in one sentence according to the sent2vec model."}, {"heading": "4 Experiment", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Training Dataset", "text": "The ACL embeddings (300 and 100 dimensions) from the ACL collection have been trained. ACL Anthology Reference Corpus 4 contains the canonical 10,921 computer linguistic works from which, after filtering out lower quality sentences, I generated 622,144 sentences. To train polarity-specific word embeddings (PS embeddings, 100 dimensions), I selected 17,538 sentences (8,769 positive and 8,769 negative) from the ACL collection by comparing sentences with the polar phrases. Preschooled Brown embeddings (100 dimensions) from the Brown corpus were also used for comparison.4 http: / / acl \u2212 arc.comp.nus.edu.sg / 5 http: / / cl.awaisathar.com / citation-sentiment-corpus / 6 https: / / en.wikipedia.org / wiki / BrownCorpus"}, {"heading": "4.2 Test Dataset", "text": "To evaluate sent2vec's performance in detecting citations, I conducted experiments with three sets of data: The first (Dataset-Basic) was originally from the ACL Anthology [12]. Athar and Awais [3] commented on 8,736 citations from 310 publications in the ACL Anthology manually. I used all marked sentences (830 positive, 280 negative, and 7,626 objective) for testing purposes. 7The second dataset (Dataset-Implicit) was used to evaluate implicit citation classification and contained 200,222 excluded (x), 282 positive (p), 419 negative (n), and 2,880 objective (o) commented sentences. Any sentence that contains no direct or indirect mention of the quote is designated as excluded (x). The third dataset (dataset-pn) is a subset of datasets-Basic containing 828 positive and 280 negative citations."}, {"heading": "4.3 Evaluation Strategy", "text": "A-Vs-The-Rest strategy was adopted for the task of multi-class classification 9, and I reported on F-Score, Micro-F, Macro-F, and Weighted-F scores with 10-fold cross-validation. The F1 score is a weighted average of precision and recall. In multi-class cases, this is the weighted average of each class's F1 score. There are several types of averages that are performed on the basis of the data: Micro-F calculates the metrics globally by counting the total true positives, false negatives, and false positives. Macro-F calculates the metrics for each label and finds its unweighted mean. Macro-F does not consider the imbalance of the labels. Weighted-F calculates the metrics for each label and finds its average, weighted by support (the number of true instances for each label)."}, {"heading": "4.4 Results", "text": "The results of the classification of positive and negative quotes were shown in Table 4. In order to compare with the results of the work of [3] 11, I selected two records from their results: the best (on characteristics n-gram + dependencies + negation) and the baseline (on the basis of 1-3 grams). From Table 2, I can see that the characteristics taken from [3] were much better than word embeddings, in terms of macro-F (their best macro-F is 0.90, the best in this work is 0.33), the higher micro-F value in this work is 0.88, hers is 0.78), and the weighted F values showed that this method can perform better when evaluations are performed on a balanced dataset."}, {"heading": "5 Discussion and Conclusion", "text": "The results of the binary classification in Table 4 showed that word2vec is a promising tool for distinguishing positive and negative quotes. I can see from Table 4 that there is not much difference between the values generated by ACL100 and Brown100, although they have different vocabulary sizes (ACL100 has 14,325 words, Brown100 56,057 words), the polarity-specific word embeddings did not show their strength in the task of binary classification. In the task of classifying implicit quotations (Table 3) sent2vec (macro-F 0.44) was generally comparable to the baseline (macro-F 0.47) and it was effective in detecting objective sentences (F-score 0.84) as well as in separating X sentences from the rest (F-score 0.997), but it did not work well in distinguishing positive quotes from the rest. In the overall classification (F-score 0.84), this technique was not capable of capturing the characteristics of the SAT."}], "references": [{"title": "Purpose and polarity of citation: Towards nlp-based bibliometrics.", "author": ["A. Abu-Jbara", "J. Ezra", "D.R. Radev"], "venue": "in HLT-NAACL,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2013}, {"title": "Improving citation polarity classification with product reviews.", "author": ["C. Jochim", "H. Sch\u00fctze"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2014}, {"title": "Sentiment analysis of citations using sentence structure-based features,", "author": ["A. Athar"], "venue": "Proceedings of the ACL 2011 student session. Association for Computational Linguistics,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2011}, {"title": "Efficient estimation of word representations in vector space,", "author": ["T. Mikolov", "K. Chen", "G. Corrado", "J. Dean"], "venue": "arXiv preprint arXiv:1301.3781,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2013}, {"title": "Learning sentimentspecific word embedding for twitter sentiment classification,", "author": ["D. Tang", "F. Wei", "N. Yang", "M. Zhou", "T. Liu", "B. Qin"], "venue": "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "Janvin, \u201cA neural probabilistic language model,", "author": ["Y. Bengio", "R. Ducharme", "P. Vincent"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2003}, {"title": "A study on sentiment computing and classification of sina weibo with word2vec,", "author": ["B. Xue", "C. Fu", "Z. Shaobin"], "venue": "Big Data (BigData Congress),", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}, {"title": "Chinese comments sentiment classification based on word2vec and svm perf,", "author": ["D. Zhang", "H. Xu", "Z. Su", "Y. Xu"], "venue": "Expert Systems with Applications,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2015}, {"title": "Support vector machines and word2vec for text classification with semantic features,", "author": ["J. Lilleberg", "Y. Zhu", "Y. Zhang"], "venue": "Cognitive Informatics & Cognitive Computing (ICCI* CC),", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2015}, {"title": "The acl anthology reference corpus: A reference dataset for bibliographic research in computational linguistics.", "author": ["S. Bird", "R. Dale", "B.J. Dorr", "B.R. Gibson", "M. Joseph", "M.-Y. Kan", "D. Lee", "B. Powley", "D.R. Radev", "Y.F. Tan"], "venue": "LREC,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2008}, {"title": "Detection of implicit citations for sentiment detection,", "author": ["A. Athar", "S. Teufel"], "venue": "Proceedings of the Workshop on Detecting Structure in Scholarly Discourse, ser. ACL \u201912. Stroudsburg, PA, USA: Association for Computational Linguistics,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}], "referenceMentions": [{"referenceID": 0, "context": "For example, [1] extracted several features for citation purpose and polarity classification, such as reference count, contrary expression and dependency relations.", "startOffset": 13, "endOffset": 16}, {"referenceID": 1, "context": "tried to improve the result by using unigram and bigram features [2].", "startOffset": 65, "endOffset": 68}, {"referenceID": 2, "context": "[3] used word level features, contextual polarity features, and sentence structure based features to detect sentiment citations.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "An important advance in this area is the development of the word2vec technique [4], which has proved to be an effective approach in Twitter sentiment classification [5].", "startOffset": 79, "endOffset": 82}, {"referenceID": 4, "context": "An important advance in this area is the development of the word2vec technique [4], which has proved to be an effective approach in Twitter sentiment classification [5].", "startOffset": 165, "endOffset": 168}, {"referenceID": 3, "context": "introduced word2vec technique [4] that can obtain word vectors by training text corpus.", "startOffset": 30, "endOffset": 33}, {"referenceID": 5, "context": "The common method to derive the vectors is using neural probabilistic language model [7].", "startOffset": 85, "endOffset": 88}, {"referenceID": 4, "context": "Word embeddings proved to be effective representations in the tasks of sentiment analysis [5, 8, 9] and text classification [10].", "startOffset": 90, "endOffset": 99}, {"referenceID": 6, "context": "Word embeddings proved to be effective representations in the tasks of sentiment analysis [5, 8, 9] and text classification [10].", "startOffset": 90, "endOffset": 99}, {"referenceID": 7, "context": "Word embeddings proved to be effective representations in the tasks of sentiment analysis [5, 8, 9] and text classification [10].", "startOffset": 90, "endOffset": 99}, {"referenceID": 8, "context": "Word embeddings proved to be effective representations in the tasks of sentiment analysis [5, 8, 9] and text classification [10].", "startOffset": 124, "endOffset": 128}, {"referenceID": 3, "context": "wn >) is the word embedding for word xi, which could be learned by the classical word2vec algorithm [4].", "startOffset": 100, "endOffset": 103}, {"referenceID": 4, "context": "To improve sentiment citation classification results, I trained polarity specific word embeddings (PS-Embeddings), which were inspired by the Sentiment-Specific Word Embedding [5].", "startOffset": 176, "endOffset": 179}, {"referenceID": 9, "context": "The first one (dataset-basic) was originally taken from ACL Anthology [12].", "startOffset": 70, "endOffset": 74}, {"referenceID": 2, "context": "Athar and Awais [3] manually annotated 8,736 citations from 310 publications in the ACL Anthology.", "startOffset": 16, "endOffset": 19}, {"referenceID": 2, "context": "7 In [3]\u2019s work, they used 244 negative, 743 positive and 6277 objective citations for testing.", "startOffset": 5, "endOffset": 8}, {"referenceID": 2, "context": "To compare with the outcomes in the work of [3] , I selected two records from their results: the best one (based on features n-gram + dependencies + negation) and the baseline (based on 1-3 grams).", "startOffset": 44, "endOffset": 47}, {"referenceID": 2, "context": "From Table 2 I can see that the features extracted by [3] performed far better than word embeddings, in terms of macro-F (their best macro-F is 0.", "startOffset": 54, "endOffset": 57}, {"referenceID": 10, "context": "The method in this experiment had a poor performance on detecting positive citations, but it was comparable with both the baseline and sentence structure method [13] for the category of objective citations.", "startOffset": 161, "endOffset": 165}, {"referenceID": 2, "context": "11 The test dataset is slightly larger than [3]\u2019s test dataset.", "startOffset": 44, "endOffset": 47}, {"referenceID": 4, "context": "However, unlike the outcomes in the paper of [5], where they concluded that sentiment specific word embeddings performed best, integrating polarity information did not improve the result in this experiment.", "startOffset": 45, "endOffset": 48}], "year": 2017, "abstractText": "Citation sentiment analysis is an important task in scientific paper analysis. Existing machine learning techniques for citation sentiment analysis are focusing on labor-intensive feature engineering, which requires large annotated corpus. As an automatic feature extraction tool, word2vec has been successfully applied to sentiment analysis of short texts. In this work, I conducted empirical research with the question: how well does word2vec work on the sentiment analysis of citations? The proposed method constructed sentence vectors (sent2vec) by averaging the word embeddings, which were learned from Anthology Collections (ACL-Embeddings). I also investigated polarity-specific word embeddings (PS-Embeddings) for classifying positive and negative citations. The sentence vectors formed a feature space, to which the examined citation sentence was mapped to. Those features were input into classifiers (support vector machines) for supervised classification. Using 10-cross-validation scheme, evaluation was conducted on a set of annotated citations. The results showed that word embeddings are effective on classifying positive and negative citations. However, hand-crafted features performed better for the overall classification.", "creator": "dvips(k) 5.996 Copyright 2016 Radical Eye Software"}}}