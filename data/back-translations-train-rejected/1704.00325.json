{"id": "1704.00325", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Apr-2017", "title": "Structured Parallel Programming for Monte Carlo Tree Search", "abstract": "In this paper, we present a new algorithm for parallel Monte Carlo tree search (MCTS). It is based on the pipeline pattern and allows flexible management of the control flow of the operations in parallel MCTS. The pipeline pattern provides for the first structured parallel programming approach to MCTS. Moreover, we propose a new lock-free tree data structure for parallel MCTS which removes synchronization overhead. The Pipeline Pattern for Parallel MCTS algorithm (called 3PMCTS), scales very well to higher numbers of cores when compared to the existing methods.", "histories": [["v1", "Sun, 2 Apr 2017 16:22:31 GMT  (1857kb)", "http://arxiv.org/abs/1704.00325v1", "9 pages"]], "COMMENTS": "9 pages", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["s ali mirsoleimani", "aske plaat", "jaap van den herik", "jos vermaseren"], "accepted": false, "id": "1704.00325"}, "pdf": {"name": "1704.00325.pdf", "metadata": {"source": "CRF", "title": "Structured Parallel Programming for Monte Carlo Tree Search", "authors": ["S. Ali Mirsoleimani", "Aske Plaat", "Jaap van den Herik"], "emails": [], "sections": [{"heading": null, "text": "In fact, we are able to set out in search of new paths that will lead us into the future."}, {"heading": "A. MCTS", "text": "Figure 1 shows a flow chart of MCTS [1]. The MCTS algorithm iteratively repeats four steps to create a search tree until a predefined arithmetic budget (i.e. time or iteration constraints) is reached. 1) SELECT: Starting from the root node, a path of nodes within the search tree is selected until a non-terminal node with unvisited children is reached. Each of the nodes is selected on the basis of a selection policy. Among the proposed selection guidelines, the upper trust limits for trees (UCT) are one of the most commonly used guidelines [2], [12]. A child node j is selected to maximize: UCT = Xj + Cp \u221a ln (n) nj (1), where Xj = wj nj is the average reward from the child j, wj the reward value from the child j, nj the number of visits from the child, the number of the node from the current number of times the node was selected."}, {"heading": "B. Tree Parallelization", "text": "In tree parallelization, a search tree is divided by multiple threads searching at the same time [5]. The biggest challenge with this method is preventing data corruption. A lock-based method uses fine-grained locks to protect shared data. However, this approach suffers from synchronization efforts due to thread disputes and does not scale well [5]. A lock-free implementation solves the problem and scales better [13]. However, the method in [13] does not guarantee the computational consistency of the multithreaded program with the single-threaded program. Figure 2 shows tree parallelization without locks."}, {"heading": "C. TBB", "text": "TBB is a C + + template library developed by Intel for writing software programs that use a multicore processor [14]. TBB implementation of pipelines uses a technique that allows greedy planning, but greed must be limited to bound memory usage. [14] The user sets the constraint as the maximum number of items allowed to flow through the pipeline simultaneously [14].III. DESIGN OF 3PMCTSIn this section, we describe our structured parallel programming approach to MCTS. In Section III-A, we explain how to break MCTS into tasks. In Section III-B, we examine what types of data dependencies exist between these tasks. Section III-C describes how the pipeline pattern is applied in MCTS. Finally, Section III-D provides our design for the 3PMCTS algorithm."}, {"heading": "A. Decomposition into Tasks", "text": "The first step in developing our 3PMCTS algorithm is to find concurrent tasks in MCTS. There are two levels of task division in MCTS.1) Iteration Tasks (IL): In MCTS, the calculation associated with each SELECT EXPAND PLAYOUTBACKUP iteration is independent, so these are candidates for task division by mapping each iteration to a task. 2) Operational Tasks (OL): Task division for MCTS takes place within each iteration. Each of the four MCTS steps can be treated as a separate task."}, {"heading": "B. Data Dependencies", "text": "Therefore, there are two levels of data dependency.1) Iteration level dependencies (IL): Strictly speaking, iteration level (IL) has a soft dependency on the previous iteration.2 A parallel MCTS can ignore IL dependencies and simply suffers from the search effort. 3) Operational level dependencies (OL): Each of the fouo operations in MCTS has a hard dependency on the previous iteration.4 For example, extending a path cannot begin until the selection operation is complete."}, {"heading": "C. Pipeline Pattern", "text": "In this section, we focus on the pipeline pattern in MCTS using OL tasks. The pipeline pattern is the easiest way to enforce the required sequence among the OL tasks. Below, we explain two possible pipeline types for MCTS.1) Linear pipeline: Figure 3a shows a linear MCTS pipeline with the selected paths within the search tree; from one step to the next, buffers get a path when operation is complete. 2) Non-linear pipeline: Figure 3b shows a non-linear MCTS pipeline with two parallel PLAYOUT stages. Both PLAYOUT stages take paths generated by the EXPAND stage of the pipeline."}, {"heading": "D. Parallelism of a Pipeline", "text": "Existing parallel methods, such as tree parallelization, use IL tasks. There are only IL dependencies when performing 2i.e., a violation of the IL dependency has no effect on the correctness of the algorithm. 3This occurs when a parallel implementation in a search algorithm searches for more nodes of the search space than the sequential version; for example, because the information to conduct the search is not yet available. 4That is, a violation of the OL dependency leads to an incorrect algorithm. IL parallelism is exploited by assigning each of the IL tasks to a separate processing element and these work on separate processors."}, {"heading": "A. Token", "text": "A token represents a path within the search tree during the search. Algorithm 1 represents the definition for the type token. It has four fields. (1) id represents a unique identifier for a token, (2) v represents the current node in the tree, (3) s represents the search state of the current node, and (4) \u2206 represents the reward value of the state. In our implementation for 3PMCTS, each stage (task) performs its operation on a token. We can also specify the number of tokens during the flight. 5If the operations of the different stages are all about the same computationally intensive. algorithm 1: Type definition for tokens 1 type 2 type 2 type id: int; 3 type v: node *; 4 type s: state *; 5 type: int; 6 token; algorithm 2: Serial implementation of MCTS, with stages SELECT, EXPAND, PLAOUCTUUT = 0.00; 0.00 TL = 0.00; 0.00 TACTL = 0.00; 0.00 TACCH = 0.00; 0.00 TL = 0.00; 0.00 TL = 0.00; 0.00 TL = 0.00 TL; 0.00 TLAUCTUNT = 0.00; 0.00 TACCH = 0.00; 0.00 TARCH = 0.00; 0.00 TL = 0.00; 0.00 TACCH = 0.00; 0.00 TL = 0.00; 0.00 TL = 0.00"}, {"heading": "B. TBB Implementation", "text": "The pseudo-code of MCTS is represented in algorithm 2. A data structure of type State describes the search state of the current node in the tree and a data structure of type Node shows the current node being searched within the tree. The functions of the MCTS algorithm are defined in algorithm 3. Each function represents a stage of the non-linear pipeline in 3PMCTS. There are two approaches to the parallel implementation of a non-linear pipeline [16]: \u2022 Bind-to-stage: A processing element (e.g. thread) is bound to a stage and processes as they arrive. If the stage is parallel, it may have several processing elements attached to it. \u2022 Bind-to-item: A processing element guides the token through the pipeline. If the processing element completes the last stage, it goes to the first stage for another token.Our implementation for a Bind-PMCTS algorithm-based Bitem."}, {"heading": "A. Case Study", "text": "Horner's rule is an algorithm for polynomial data structure.1 type 2 type false type: false type: false type: false type: false 4 type: false 4 type: false 4 type: http: / / www.mythos-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-3-3-3-3-3-3-3-3-3-3-3-2-2-2-2-2-2-2-2-2-2-2-3-3-3-3-3-3-3-3-3-3-3-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-3-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-3-2-2-2-2-2-2-2-2-2-2-2-2-2-2-3-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-3-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-"}, {"heading": "B. Hardware", "text": "Our experiments were carried out on an Intel dual-socket computer with 2 Intel Xeon E5-2596v2 2.4 GHz CPUs. Each CPU has 12 cores, 24 hyperthreads and 30 MB L3 cache. Each physical core has 256KB L2 cache. The maximum TurboBoost frequency is 3.2 GHz. The computer has 192GB of physical memory. We compiled the code with the Intel C + + compiler with a -O3 flag."}, {"heading": "C. Performance Metrics", "text": "This year, the time has come for such a process, such a process, to take place as never before."}], "references": [{"title": "Efficient Selectivity and Backup Operators in Monte-Carlo Tree Search", "author": ["R. Coulom"], "venue": "Proceedings of the 5th International Conference on Computers and Games, ser. CG\u201906, vol. 4630. Springer-Verlag, may 2006, pp. 72\u201383.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2006}, {"title": "Bandit based Monte-Carlo Planning Levente", "author": ["L. Kocsis", "C. Szepesv\u00e1ri"], "venue": "ECML\u201906 Proceedings of the 17th European conference on Machine Learning, ser. Lecture Notes in Computer Science, J. F\u00fcrnkranz, T. Scheffer, and M. Spiliopoulou, Eds., vol. 4212. Springer Berlin Heidelberg, sep 2006, pp. 282\u2013293.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2006}, {"title": "Improving Multivariate Horner Schemes with Monte Carlo Tree Search", "author": ["J. Kuipers", "A. Plaat", "J. Vermaseren", "J. van den Herik"], "venue": "Computer Physics Communications, vol. 184, no. 11, pp. 2391\u20132395, nov 2013.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2013}, {"title": "Deep Learning, ser. Adaptive Computation and Machine Learning Series. MIT Press, 2016", "author": ["I. Goodfellow", "Y. Bengio", "A. Courville"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2016}, {"title": "Parallel Monte-Carlo Tree Search", "author": ["G. Chaslot", "M. Winands", "J. van den Herik"], "venue": "the 6th Internatioal Conference on Computers and Games, vol. 5131. Springer Berlin Heidelberg, 2008, pp. 60\u201371.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2008}, {"title": "Scalable Distributed Monte-Carlo Tree Search", "author": ["K. Yoshizoe", "A. Kishimoto", "T. Kaneko", "H. Yoshimoto", "Y. Ishikawa"], "venue": "Fourth Annual Symposium on Combinatorial Search, may 2011, pp. 180\u2013187.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "Ensemble Monte-Carlo Planning: An Empirical Study.", "author": ["A. Fern", "P. Lewis"], "venue": "ICAPS,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2011}, {"title": "Distributed Monte-Carlo Tree Search : A Novel Technique and its Application to Computer Go", "author": ["L. Schaefers", "M. Platzner"], "venue": "IEEE Transactions on Computational Intelligence and AI in Games, vol. 6, no. 3, pp. 1\u201315, 2014.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "Parallel Monte Carlo Tree Search from Multi-core to Many-core Processors", "author": ["S.A. Mirsoleimani", "A. Plaat", "J. van den Herik", "J. Vermaseren"], "venue": "ISPA 2015 : The 13th IEEE International Symposium on Parallel and Distributed Processing with Applications (ISPA), Helsinki, 2015, pp. 77\u201383.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2015}, {"title": "Scaling Monte Carlo Tree Search on Intel Xeon Phi", "author": ["\u2014\u2014"], "venue": "Parallel and Distributed Systems (ICPADS), 2015 20th IEEE International Conference on, 2015, pp. 666\u2013673.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2015}, {"title": "A Survey of Monte Carlo Tree Search Methods", "author": ["C.B. Browne", "E. Powley", "D. Whitehouse", "S.M. Lucas", "P.I. Cowling", "P. Rohlfshagen", "S. Tavener", "D. Perez", "S. Samothrakis", "S. Colton"], "venue": "Computational Intelligence and AI in Games, IEEE Transactions on, vol. 4, no. 1, pp. 1\u201343, 2012.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2012}, {"title": "A lock-free multithreaded Monte-Carlo tree search algorithm", "author": ["M. Enzenberger", "M. M\u00fcller"], "venue": "Advances in Computer Games, vol. 6048, pp. 14\u201320, 2010.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2010}, {"title": "Intel threading building blocks: outfitting C++ for multicore processor parallelism", "author": ["J. Reinders"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2007}, {"title": "Programming Parallel Applications in Cilk", "author": ["C.E. Leiserson", "A. Plaat"], "venue": "SINEWS: SIAM News, vol. 31, no. 4, pp. 6\u20137, 1998.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1998}, {"title": "Structured Parallel Programming: Patterns for Efficient Computation", "author": ["M. McCool", "J. Reinders", "A. Robison"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2012}, {"title": "FuegoAn Open- Source Framework for Board Games and Go Engine Based on Monte Carlo Tree Search", "author": ["M. Enzenberger", "M. Muller", "B. Arneson", "R. Segal"], "venue": "IEEE Transactions on Computational Intelligence and AI in Games, vol. 2, no. 4, pp. 259\u2013270, dec 2010.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2010}, {"title": "Concurrency in Action: Practical Multithreading", "author": ["C A. Williams"], "venue": "ser. Manning Pubs Co Series. Manning,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2012}, {"title": "Transposition Table Driven Work Scheduling in Distributed Search", "author": ["J. Romein", "A. Plaat", "H.E. Bal", "J. Schaeffer"], "venue": "In 16th National Conference on Artificial Intelligence (AAAI\u201999), 1999, pp. 725\u2013731.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1999}, {"title": "Evaluating Root Parallelization in Go", "author": ["Y. Soejima", "A. Kishimoto", "O. Watanabe"], "venue": "IEEE Transactions on Computational Intelligence and AI in Games, vol. 2, no. 4, pp. 278\u2013287, dec 2010.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2010}], "referenceMentions": [{"referenceID": 0, "context": "In recent years there has been much interest in the Monte Carlo tree search (MCTS) algorithm, at that time a new, adaptive, randomized optimization algorithm [1], [2].", "startOffset": 158, "endOffset": 161}, {"referenceID": 1, "context": "In recent years there has been much interest in the Monte Carlo tree search (MCTS) algorithm, at that time a new, adaptive, randomized optimization algorithm [1], [2].", "startOffset": 163, "endOffset": 166}, {"referenceID": 2, "context": "In fields as diverse as Artificial Intelligence, Operations Research, and High Energy Physics, research has established that MCTS can find valuable approximate answers without domain-dependent heuristics [3].", "startOffset": 204, "endOffset": 207}, {"referenceID": 3, "context": "The strength of the MCTS algorithm is that it provides answers with a random amount of error for any fixed computational budget [4].", "startOffset": 128, "endOffset": 131}, {"referenceID": 4, "context": "Indeed, there is a full array of different parallel MCTS algorithms [5]\u2013[10].", "startOffset": 68, "endOffset": 71}, {"referenceID": 9, "context": "Indeed, there is a full array of different parallel MCTS algorithms [5]\u2013[10].", "startOffset": 72, "endOffset": 76}, {"referenceID": 4, "context": "They assign each iteration to a separate processing element (thread) for execution on separate processors [5], [8], [9].", "startOffset": 106, "endOffset": 109}, {"referenceID": 7, "context": "They assign each iteration to a separate processing element (thread) for execution on separate processors [5], [8], [9].", "startOffset": 111, "endOffset": 114}, {"referenceID": 8, "context": "They assign each iteration to a separate processing element (thread) for execution on separate processors [5], [8], [9].", "startOffset": 116, "endOffset": 119}, {"referenceID": 0, "context": "Figure 1 shows a flowchart of MCTS [1].", "startOffset": 35, "endOffset": 38}, {"referenceID": 1, "context": "Among the proposed selection policies, the Upper Confidence Bounds for Trees (UCT) is one of the most commonly used policies [2], [12].", "startOffset": 125, "endOffset": 128}, {"referenceID": 10, "context": "Among the proposed selection policies, the Upper Confidence Bounds for Trees (UCT) is one of the most commonly used policies [2], [12].", "startOffset": 130, "endOffset": 134}, {"referenceID": 10, "context": "The first term in the UCT equation is for exploitation of known parts of the tree and the second term is for exploration of unknown parts [12].", "startOffset": 138, "endOffset": 142}, {"referenceID": 10, "context": "4) BACKUP: In the selected path, each node\u2019s visit count n is incremented by 1 and its reward value w updated according to \u2206 [12].", "startOffset": 125, "endOffset": 129}, {"referenceID": 4, "context": "In tree parallelization, one search tree is shared among several threads that are performing simultaneous searches [5].", "startOffset": 115, "endOffset": 118}, {"referenceID": 4, "context": "However, this approach suffers from synchronization overhead due to thread contentions and does not scale well [5].", "startOffset": 111, "endOffset": 114}, {"referenceID": 11, "context": "A lock-free implementation of addresses the problem and scales better [13].", "startOffset": 70, "endOffset": 74}, {"referenceID": 11, "context": "However, the method in [13] does not guarantee the computational consistency of the multithreaded program with the single-threaded program.", "startOffset": 23, "endOffset": 27}, {"referenceID": 12, "context": "TBB is a C++ template library developed by Intel for writing software programs that take advantage of a multicore processor [14].", "startOffset": 124, "endOffset": 128}, {"referenceID": 12, "context": "The user specifies the constraint as a maximum number of items allowed to flow simultaneously through the pipeline [14].", "startOffset": 115, "endOffset": 119}, {"referenceID": 4, "context": "So far IL parallelism is investigated quite extensively [5], [8]\u2013[10], [13].", "startOffset": 56, "endOffset": 59}, {"referenceID": 7, "context": "So far IL parallelism is investigated quite extensively [5], [8]\u2013[10], [13].", "startOffset": 61, "endOffset": 64}, {"referenceID": 9, "context": "So far IL parallelism is investigated quite extensively [5], [8]\u2013[10], [13].", "startOffset": 65, "endOffset": 69}, {"referenceID": 11, "context": "So far IL parallelism is investigated quite extensively [5], [8]\u2013[10], [13].", "startOffset": 71, "endOffset": 75}, {"referenceID": 12, "context": ", TBB [14] or Cilk [15]).", "startOffset": 6, "endOffset": 10}, {"referenceID": 13, "context": ", TBB [14] or Cilk [15]).", "startOffset": 19, "endOffset": 23}, {"referenceID": 14, "context": "There are two approaches for parallel implementation of a non-linear pipeline [16]:", "startOffset": 78, "endOffset": 82}, {"referenceID": 12, "context": "Figure 4 depicts a five-stage pipeline for 3PMCTS that can be implemented using TBB tbb::parallel pipeline template [14].", "startOffset": 116, "endOffset": 120}, {"referenceID": 14, "context": "A race condition occurs when concurrent threads perform operations on the same memory location without proper synchronization, and one of the memory operations is a write [16].", "startOffset": 171, "endOffset": 175}, {"referenceID": 15, "context": "assign to each thread an own memory array for creating a list of new children [17].", "startOffset": 78, "endOffset": 82}, {"referenceID": 16, "context": "In order to avoid the race conditions, the ordering between the memory accesses in the threads has to be enforced [18].", "startOffset": 114, "endOffset": 118}, {"referenceID": 2, "context": "EXPERIMENTAL SETUP The performance of 3PMCTS is measured by using a High Energy Physics (HEP) expression simplification problem [3].", "startOffset": 128, "endOffset": 131}, {"referenceID": 2, "context": "Our setup follows closely [3].", "startOffset": 26, "endOffset": 29}, {"referenceID": 2, "context": "The MCTS is used to find an order of the variables that gives efficient Horner schemes [3].", "startOffset": 87, "endOffset": 90}, {"referenceID": 4, "context": "The two major parallelization methods for MCTS are root parallelization and tree parallelization [5].", "startOffset": 97, "endOffset": 100}, {"referenceID": 4, "context": "frequently encountered techniques, such as leaf parallelization [5] and approaches based on transposition table driven work scheduling (TDS) [6], [19].", "startOffset": 64, "endOffset": 67}, {"referenceID": 5, "context": "frequently encountered techniques, such as leaf parallelization [5] and approaches based on transposition table driven work scheduling (TDS) [6], [19].", "startOffset": 141, "endOffset": 144}, {"referenceID": 17, "context": "frequently encountered techniques, such as leaf parallelization [5] and approaches based on transposition table driven work scheduling (TDS) [6], [19].", "startOffset": 146, "endOffset": 150}, {"referenceID": 15, "context": "It is used in FUEGO, a well-known open source Go program [17].", "startOffset": 57, "endOffset": 61}, {"referenceID": 4, "context": "In tree parallelization one MCTS tree is shared among several threads that are performing simultaneous searches [5].", "startOffset": 112, "endOffset": 115}, {"referenceID": 4, "context": "It is shown in [5] that the playout-speedup of tree parallelization with virtual loss does not scale perfectly up to 16 threads.", "startOffset": 15, "endOffset": 18}, {"referenceID": 4, "context": "[5] report that root parallelization shows perfect playout-speedup up to 16 threads.", "startOffset": 0, "endOffset": 3}, {"referenceID": 18, "context": "[20] analyzed the performance of root parallelization in detail.", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "Fern and Lewis [7] thoroughly investigated an Ensemble UCT approach in which multiple instances of UCT were run independently.", "startOffset": 15, "endOffset": 18}, {"referenceID": 9, "context": "This is also shown in [10].", "startOffset": 22, "endOffset": 26}], "year": 2017, "abstractText": "In this paper, we present a new algorithm for parallel Monte Carlo tree search (MCTS). It is based on the pipeline pattern and allows flexible management of the control flow of the operations in parallel MCTS. The pipeline pattern provides for the first structured parallel programming approach to MCTS. Moreover, we propose a new lock-free tree data structure for parallel MCTS which removes synchronization overhead. The Pipeline Pattern for Parallel MCTS algorithm (called 3PMCTS), scales very well to higher numbers of cores when compared to the existing methods.", "creator": "LaTeX with hyperref package"}}}