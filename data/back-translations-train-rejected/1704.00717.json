{"id": "1704.00717", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Apr-2017", "title": "It Takes Two to Tango: Towards Theory of AI's Mind", "abstract": "Theory of Mind is the ability to attribute mental states (beliefs, intents, knowledge, perspectives, etc.) to others and recognize that these mental states may differ from one's own. Theory of Mind is critical to effective communication and to teams demonstrating higher collective performance. To effectively leverage the progress in Artificial Intelligence (AI) to make our lives more productive, it is important for humans and AI to work well together in a team. Traditionally, there has been much emphasis on research to make AI more accurate, and (to a lesser extent) on having it better understand human intentions, tendencies, beliefs, and contexts. The latter involves making AI more human-like and having it develop a theory of our minds.", "histories": [["v1", "Mon, 3 Apr 2017 17:58:07 GMT  (9090kb,D)", "http://arxiv.org/abs/1704.00717v1", null], ["v2", "Mon, 2 Oct 2017 17:55:50 GMT  (7458kb,D)", "http://arxiv.org/abs/1704.00717v2", null]], "reviews": [], "SUBJECTS": "cs.CV cs.AI cs.CL", "authors": ["arjun chandrasekaran", "deshraj yadav", "prithvijit chattopadhyay", "viraj prabhu", "devi parikh"], "accepted": false, "id": "1704.00717"}, "pdf": {"name": "1704.00717.pdf", "metadata": {"source": "CRF", "title": "It Takes Two to Tango: Towards Theory of AI\u2019s Mind", "authors": ["Arjun Chandrasekaran", "Deshraj Yadav", "Prithvijit Chattopadhyay", "Viraj Prabhu", "Devi Parikh"], "emails": ["parikh}@gatech.edu,", "virajp}@vt.edu"], "sections": [{"heading": null, "text": "In this paper, we argue that for AI teams to be effective, people also need to develop a theory of the spirit of AI - namely, to know their strengths, weaknesses, beliefs, and quirks. We examine these ideas in the Visual Question Answering (VQA) section. We find that laypeople can be trained to better predict the responses and upcoming errors of a complex VQA model using only a few examples (50). Surprisingly, we find that access to the model's internal states - its reliance on its top-k predictions, explicit or implicit attention maps, the regions in the image (and words in question) that the model looks at (and hears) while answering a question about an image - does not help people predict its behavior better."}, {"heading": "1. Introduction", "text": "Indeed, our ability to grasp the beliefs, feelings and actions of other people in novel situations is the basis for human perception. [53] The ability to attribute mental states in other countries is synonymous with a simultaneous contribution."}, {"heading": "2. Related Work", "text": "A number of works in AI attempt to develop an understanding of human characteristics and behavior. AI agents who use computer viruses have been trained to predict motivations [67], intentions [49], tendencies [18], contexts [55], which explain theories that explain the development of theories of mind in children and their applicability in the construction of robots. Recently, they have been able to show themselves to be able to determine themselves."}, {"heading": "3. Meet Vicki", "text": "In fact, it is not so that it would be a way to act, in which you ask the question of the way in which it is posed. (...) It is not so that the way, how the way, how the way, how the way, how the way, how the way, how the way, how the way, how the way, how the way, how the way, how the way, how the way, how the way, how the way, how the way, how the way, how the way, how the way, how the way, how the way, how the way, how the way, how the way, how the way, how the way, how the way, how the way, how the way, how the way, how the way, how the way, how the way, how the way, how the way, how the way, how the way, how the way, how they, how the way, how they, how the way, how they, how they, how the way, how they, how the way, how they, how they, how the way, how they, how the way, how they, how they, how the way, how they, how the way, how they, how they, how the way, how they, how the way, how they, how they, how the way, how they, how they, how the way, how they, how the way, how they, how the way, how they, how they, how the way, how the way, how they, how the way, how they, how the way, how the way, how they, how they, how the way, how the way, how they, how the way, how they, how the way, how the way, how they, how the way, how they, how the way, how the way, how the way, how the way, how they, how the way, how they, how the way, how they, how the way, how they, how the way, how they, how the way, how the way, how the way, how the way, how the way, how they, how the way, how the way, how the way, how they, how the way, how the way, how the way, how they, how the way, how the way, how the way, how the way, how the way, how they, how the way, how the way"}, {"heading": "4. Meet the tasks", "text": "These tasks are particularly relevant to people, as they have analogous approaches to measuring whether a person is able to gain the trust of another person, and whether a person is able to assess another person's behavior in a particular scenario is questionable. (...) A person who predicts another person's failure cannot recognize a person's ability to predict another person's success or failure. (...) This is a question we need to ask ourselves in order to answer the question of how exactly a person can answer the question, whether they can successfully answer the question. (...) A person who predicts a person's failure when predicting a person's strengths and weaknesses. (...) A collaborator who knows exactly how a person can answer the question. (...)"}, {"heading": "5. Perception of AI", "text": "Before introducing people to Vicki and measuring their expectations of a modern VQA system, we try to assess their general impressions of today's AI. We then observe correlations in their expectations of Vicki with their familiarity with AI, their estimates of AI capabilities, and their demographic and socio-economic background. We ask each subject to complete a survey with questions aimed at collecting three types of information: 1. Background information. We ask subjects if their jobs include computers, whether they know how much time they spend in front of a computer or smartphone, and their familiarity with popular AI assistants such as Siri, Alexa, and Google Assistant. We ask subjects if their jobs include computers, how much time they spend in front of a computer or smartphone, and their familiarity with popular AI assistants such as Ai, Ai, and Google Assistant."}, {"heading": "6. Perception of VQA", "text": "To determine the baseline for our specific task, we measure people's current estimates of VQA models. To this end, we briefly introduce the subject to Vicki as an \"AI trained to answer questions via images.\" Subsequently, we ask the subject to use their current understanding and expectations of what AI agents can do to estimate Vicki's behavior. Subjects fill out the survey described above before completing the task. We examine people's ability to estimate Vicki's behavior via Failure Prediction and Knowledge Prediction tasks. For both tasks, we randomly tap questions from the group of approximately 1400 most common questions in the Validation Set of the VQA dataset [5]. A description of our experimental setup for each task follows."}, {"heading": "6.1. Failure Prediction (FP)", "text": "In this task, we show a question, a picture where this question was asked in the VQA > dataset, and ask the subjects if they think that Vicki's answer is correct or wrong. To learn the truth, we check whether Vicki's answer matches at least 3 out of 10 human answers in the VQA dataset. In total, 88 unique subjects participated in our study, which provided answers to 1000 QI pairs. On average, the subjects accurately estimated whether Vicki would answer the question correctly (success) or not (failure) 59.88% of the time. The accuracy of always guessing success is 61.52%. While the performance of the subjects seems to be lower than this, normalization for the time before each class (success vs. failure) always falls to 50%, but people are at 54.24%. This shows that even without prior consideration of Vicki's, human subjects can predict optimism better than the chances. We continue to measure people's optimism about FI's ability to answer questions today."}, {"heading": "6.2. Knowledge Prediction (KP)", "text": "In the KP task, we ask the subjects what they think Vicki would say in response to a question about an image. Note that the VQA data set only asks questions about an image that is relevant to the image. In the VQA data collection protocol, commentators looked at the image while asking questions, so a question, \"What color is the man's shirt?\" would only be asked for an image that contains a man wearing a shirt. As an interesting twist intended to illustrate Vicki's quirky behavior (one in 1,000 answers), we also combined images with random (and probably irrelevant [54]) questions (e.g., \"What are people doing?\" in an image that may not contain people). Remember that Vicki is forced to answer with a limited vocabulary (one in 1,000 answers). These samples are useful to measure a person's understanding of an agent's responses to a given stimulus (including the < < < < < not the person in the < < <"}, {"heading": "7. Familiarizing people with Vicki", "text": "In this section, we describe our experimental setup to familiarize the subjects with Vicki's behavior. We approach this topic in two ways - by giving instant feedback on Vicki's actual behavior for each QI pair as soon as the subjects respond, and by exposing the subjects to various explanations that reveal Vicki's internal states. Challenges. Collecting data for this setup is difficult for several reasons: (1) Each subject must go through a training phase to familiarize themselves with Vicki before we can test it, which results in each task being unusually long and expensive. It also reduces the subject pool to those willing to participate in long tasks. (2) Once a subject completes a task for us, they cannot complete another task because the training / burden on Vicki would exceed. 7We made sure that subjects performing a CP task are not allowed to perform an FP task, as the subject does not perform a task that is relevant to the KP task."}, {"heading": "7.1. Does feedback help?", "text": "It is not that we are in a position to answer the questions we have asked ourselves. (...) It is not that we are in a position to answer the questions we have asked ourselves. (...) It is not that we are in a position to answer them. (...) It is not that we are in a position to answer them. (...) It is not that we are in a position to answer them. (...) It is not that we are in a position to answer all the questions. (...) It is not that we are in a position to resolve them. (...) It is not that they are in a position to resolve them. (...) It is not that they are in a position to answer all the questions. (...) It is not that they are in a position to resolve them. (...) It is not that they are in a position to find their answers. \""}, {"heading": "7.2. Do explanation modalities help?", "text": "In this area, we are on the verge of describing the different explanatory patterns we apply in relation to the internationality of people."}, {"heading": "8. Conclusion", "text": "We argue that it is not only important for AI to be able to model people's intentions, beliefs, strengths and weaknesses, but also for humans to build a theory of AI's Mind (ToAIM). We pursue research directions that help people develop models of AI's strengths, weaknesses and tendencies, which is especially relevant when the input signals are highly dimensioned and the models we train become increasingly complex."}, {"heading": "3. FP + IF + Explanation Modalities", "text": "For me, there was no rhyme or reason to guess correctly. Thank you. \"\u2022\" I think she can know a small number of people exactly, but can't know a large group yet. \"\u2022\" I'd be more interested in how Vicki's metrics work. What I suspected was just the color phase and distance. \"4. KP \u2022\" Questions of time are tricky because everyone can turn Vicki around until the next number. \"\u2022\" There were a few that seemed to lack obvious answers - like bus stop, but not bus stop. Words like lobby also seemed to be missing. \"5. KP + IF \u2022\" Interesting, although Vicki apparently still has a lot to do. Thank you! \"This HIT was interesting, but a bit hard. Thanks for the opportunity to do this.\""}, {"heading": "6. KP + IF + Explanation Modalities", "text": "\u2022 \"You have to remove the nuances of night and day from the computer and choose a phrase\" night \"or\" day \"that Vicki understands. The nuance keeps me and I'm sure others will score higher in this task.\" \u2022 \"I felt that Vickie was mistaken about what some colors were for the first test that was probably transferring, and I tried my best to replicate her answers.\""}, {"heading": "7. KP + IF + Montages", "text": "\u2022 \"I'm not sure I ever fully understood what Vicki thought. It seemed that it had more to do with what was in the pictures than with the time of day it looked like in the pictures. If there was food, she would choose lunch or morning, although sometimes it was clearly breakfast food and she called it lunch.\" \u2022 \"It doesn't seem to be very accurate because I was paying attention to counting and taking time to rate the pictures.\" \u2022 \"It's hard to find out what they're looking for because there aren't many umbrellas in the pictures.\" In fig. 10 we showed a word cloud of all the comments that the subjects left after completing the tasks, that Vicki counts poorly and that Vicki often responds with the most dominant color in the picture when asked a color question. In fig. 10 we show a word cloud of all the comments left by the subjects upon completion of the tasks. From the comments we observed that the experimenters were very interesting, despite the fact that we found the experiments to be very enthusiastic with the things that Vicki was."}, {"heading": "C. Survey Questions", "text": "This year, the time has come for an agreement to be reached."}], "references": [], "referenceMentions": [], "year": 2017, "abstractText": "Theory of Mind is the ability to attribute mental states (beliefs, intents, knowledge, perspectives, etc.) to others and recognize that these mental states may differ from one\u2019s own. Theory of Mind is critical to effective communication and to teams demonstrating higher collective performance. To effectively leverage the progress in Artificial Intelligence (AI) to make our lives more productive, it is important for humans and AI to work well together in a team. Traditionally, there has been much emphasis on research to make AI more accurate, and (to a lesser extent) on having it better understand human intentions, tendencies, beliefs, and contexts. The latter involves making AI more human-like and having it develop a theory of our minds. In this work, we argue that for human-AI teams to be effective, humans must also develop a theory of AI\u2019s mind \u2013 get to know its strengths, weaknesses, beliefs, and quirks. We instantiate these ideas within the domain of Visual Question Answering (VQA). We find that using just a few examples (50), lay people can be trained to better predict responses and oncoming failures of a complex VQA model. Surprisingly, we find that having access to the model\u2019s internal states \u2013 its confidence in its top-k predictions, explicit or implicit attention maps which highlight regions in the image (and words in the question) the model is looking at (and listening to) while answering a question about an image \u2013 do not help people better predict its behavior.", "creator": "LaTeX with hyperref package"}}}