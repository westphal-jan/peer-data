{"id": "1704.00898", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Apr-2017", "title": "Interpretation of Semantic Tweet Representations", "abstract": "Research in analysis of microblogging platforms is experiencing a renewed surge with a large number of works applying representation learning models for applications like sentiment analysis, semantic textual similarity computation, hashtag prediction, etc. Although the performance of the representation learning models has been better than the traditional baselines for such tasks, little is known about the elementary properties of a tweet encoded within these representations, or why particular representations work better for certain tasks. Our work presented here constitutes the first step in opening the black-box of vector embeddings for tweets. Traditional feature engineering methods for high-level applications have exploited various elementary properties of tweets. We believe that a tweet representation is effective for an application because it meticulously encodes the application-specific elementary properties of tweets. To understand the elementary properties encoded in a tweet representation, we evaluate the representations on the accuracy to which they can model each of those properties such as tweet length, presence of particular words, hashtags, mentions, capitalization, etc. Our systematic extensive study of nine supervised and four unsupervised tweet representations against most popular eight textual and five social elementary properties reveal that Bi-directional LSTMs (BLSTMs) and Skip-Thought Vectors (STV) best encode the textual and social properties of tweets respectively. FastText is the best model for low resource settings, providing very little degradation with reduction in embedding size. Finally, we draw interesting insights by correlating the model performance obtained for elementary property prediction tasks with the high-level downstream applications.", "histories": [["v1", "Tue, 4 Apr 2017 07:24:15 GMT  (3817kb,D)", "http://arxiv.org/abs/1704.00898v1", "Under review at ASONAM 2017; Initial version presented at NIPS 2016 workshop can be found atarXiv:1611.04887"], ["v2", "Wed, 21 Jun 2017 06:59:17 GMT  (3824kb,D)", "http://arxiv.org/abs/1704.00898v2", "Accepted at ASONAM 2017; Initial version presented at NIPS 2016 workshop can be found atarXiv:1611.04887"]], "COMMENTS": "Under review at ASONAM 2017; Initial version presented at NIPS 2016 workshop can be found atarXiv:1611.04887", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["j ganesh", "manish gupta", "vasudeva varma"], "accepted": false, "id": "1704.00898"}, "pdf": {"name": "1704.00898.pdf", "metadata": {"source": "CRF", "title": "Interpretation of Semantic Tweet Representations", "authors": ["Ganesh J", "Manish Gupta", "Vasudeva Varma"], "emails": ["ganesh.j@research.iiit.ac.in;", "manish.gupta@iiit.ac.in", "vv@iiit.ac.in", "gmanish@microsoft.com"], "sections": [{"heading": null, "text": "We have focused on different types of business applications, such as opinion mining, semantic text similarity, user profiling, hashtag identification, microblog retrieval, etc. Central to the performance of these applications [10] is the question of tweet representation: How can you best capture the essential meaning of a tweet in an understandable format? Challenges such as short length, informal words, misspellings and unusual grammar make it difficult to capture these aspects of text. In addition, tweets also have social network-oriented properties, so good representation should also capture social aspects. Traditionally, tweets have been modeled with Bag-Of-Words (BOW) and latent dirichlet allocation (LDA)."}, {"heading": "II. RELATED WORK", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Summary of Existing Models", "text": "Tables I and II summarize the basic idea or architecture of the existing unattended or monitored models. Based on the network architecture, neural network models can be divided into one or more of the following categories: Feed Forward, Word2Vec, Encoder Decoder, Siam, Convolutional Neural Network (CNN), Recurrent Neural Network (RNN), and Recursive Neural Network (ReNN). ReNNs work with parse trees and are therefore poorly suited for displaying tweets, since the structure of parse trees is not only computationally intensive, but also expects the input sentences to be grammatically well formed, unlike most tweets."}, {"heading": "B. Understanding Sentence Representations", "text": "In a recent paper, Hill et al. [6] perform a comparison of different sentence representation models by evaluating them for various high-level semantic tasks such as paraphrase identification, mood classification, etc. Our work differs from their work in two ways: (1) They analyze sentences while we are working with tweets. Of course, they ignore social aspects. (2) They study representations and their effectiveness for different applications; while we analyze and try to estimate their effectiveness for different applications, the most relevant work for us is that of [17], which examines three sentence properties by comparing two models: average values of word vectors and LSTM auto encoders. Our work differs from their work in two ways: (1) While focusing on sentences, we focus on tweets that present the challenge of understanding how well these representations display several tweet-specific prominent textual properties such as slang words, hash tag and unreliable capitalization (2) and how they capture different social characteristics (and how they only for different conversations)."}, {"heading": "III. ELEMENTARY PROPERTY PREDICTION TASKS", "text": "In this section, we list the proposed tasks to test the properties of a tweet embed. These properties correspond to the most popular properties used in several papers that use feature engineering for various microblog applications. Since tweets are pieces of text in the network context, we naturally categorize the properties into two types: textual and social. Note that we use a neural network to create the classifier for elementary property prediction, which has the following two layers: the representation layer and the softmax layer above it, the size of which varies according to the specific task."}, {"heading": "A. Textual Tasks", "text": "This task measures the extent to which the tweet representation encodes the length of the tweet (3-6), which we do not observe much change in the results, hence we show results for bin size set as 4. (b) Content Task: Words in a tweet is a useful feature for detecting tweet tweets, tweet-worthy tweets, etc. This task measures the extent to which the tweet representation encodes the length of the tweet. (3-6), which we do not observe much change in the results, hence we show results for bin size set as 4. (b) Content Task: Words in a tweet is a useful feature for sensation analysis, paraphrase prediction, etc. This task measures the extent to which the tweet representation encodes the representation of the words."}, {"heading": "B. Social Tasks", "text": "In addition to the textual properties, a good representation should be able to explain the following social properties of tweets. (i) Mention the number of mentions it contains. Mention the number of mentions in a tweet, the task is to predict the number of mentions (words beginning with the letter \"@\") in the tweet. We use the raw frequency of the conversation and present it as a classification problem. (j) Mention task: Mention position is a useful feature in tasks such as sensation analysis, response prediction, etc. This task measures the extent to which the representation encodes the position of the first user mentioned in the tweet. (k) Answer task: This task measures the extent to which the tweet representation encodes the outstanding properties of a reply tweet."}, {"heading": "IV. REPRESENTATION LEARNING MODELS", "text": "In this section, we list popular models for learning tweet representations."}, {"heading": "A. Unsupervised Models", "text": "We are experimenting with the following unattended presentation learning models. These models require an additional classifier to do the final classification. \u2022 Bag Of Words (BOW) [11] - This simple presentation captures the TF-IDF value of an n-gram. We select Top 50K n-grams, with the value of \"n'going upto 5. \u2022 Latent Dirichlet Allocation (LDA) [11] - We use the topic distribution by running the LDA with a number of topics than 200, such as the tweet representation. We varied the number of topics as 100, 200, 500 but found the best results at 200. \u2022 Bag Of Means (BOM) - We take the average of word embedding, which is vW by running the GloVe [22] model with 2B tweets with embedding size as 200 1. We varied the embedding size as 25, 50, 100, 200, 200 (as these are the available sizes)."}, {"heading": "B. Supervised Models", "text": "Below we list a number of models that we use for end-to-end classification. \u2022 Convolutional Neural Network (CNN) - This is a simple CNN suggested in [15]. \u2022 Long Short Term Memory Network (LSTM) [7] - This is a vanilla LSTM-based recurring model that is applied from start to finish of a tweet, and the last hidden vector is used as a tweet representation. We use the optimal hyperparameter settings as in [13].1http: / / nlp.stanford.edu / projects / glove / 2https: / / www.microsoft.com / en-us / research / project / dssm / 3https: / / github.com / ryankiros / skip thoughts-4https: / / github.com / bdhingra / tweet2vec \u2022 Bi-directional LSTM (BLM) [7] This is a hidden LSTM architecture, each one FTM-hidden architecture."}, {"heading": "V. EXPERIMENTS", "text": "Essentially, we examine each model (with optimal settings given in the corresponding work) with respect to the following perspectives. (1) Accuracy of the task for predicting properties - If the accuracy of the model for a property is high, it is more likely to encode the property. This test identifies the model with the best F1score for each elementary prediction task. (a) Best model: Tasks where this model has outperformed all other monitored models. (2) Best unattended model: Tasks where this model has outperformed all other unattended models. (b) Best unattended model: Tasks where this model has outperformed all other monitored models. (2) Property prediction task Accuracy versus Tweet length: Some representation learning models tend to model shorter or longer tweets. This test helps to compare the performance of the model for shorter or longer tweets. (a) Positively increases the accuracy of the prediction task relative to the task (the task length)."}, {"heading": "VI. RESULTS AND ANALYSIS", "text": "Detailed analyses of various monitored and unattended models discussed in Section IV, across various dimensions (1, 2 and 3) discussed in Section V, are presented in Table IV. For example, the column entry \"Task Accuracy (1)\" for STV tells us that STV is \"the best model (a)\" for Content, Mention Count, Is Reply, Is Reply, Word Repeat Tasks and \"Best Unsupervised Model (b)\" for Content, Capt. Count, Mention Count, Mention Pos., Is Reply, Word Repeat Tasks, which are discussed in detail in this section. We have published the code at http: / / tinyurl.com / mysteriousTweetReps. In this section, we analyze the results in detail."}, {"heading": "A. Property Prediction Task Accuracy", "text": "We summarize the results of all property prediction tasks in Table V. For textual tasks, we mainly observe the following points: (1) Length prediction proves to be a difficult task for most models. Models based on the recurring architectures such as LSTM, STV, T2V have sufficient capacity to model the length of the tweet well. (2) BLSTM performs the worst results due to the simple Word2Vec structure of this complex task. (3) BLSTM is the best in modeling slang words. BLSTM outperforms the LSTM variant in all tasks except \"content,\" meaning that the power of using information flowing from both directions of the tweet. (3) STV tops in modeling the content. This is due to the very large embedding size used for each tweet."}, {"heading": "B. Sensitivity to Tweet Length", "text": "For tasks such as \"Word Order,\" \"Mention Position,\" and \"Capitalization Count,\" we see a negative correlation between the performance of all models (Figure 2) and the tweet length. On the other hand, there is no correlation between the tweet length and the performance of all models for tasks such as \"Slang Words,\" \"Content,\" \"Hashtag,\" \"Named Entities,\" \"Informative Capitalization,\" and \"Is Reply.\" In the task \"Is Reply,\" we see a positive correlation between the tweet length and the performance of all models (Figure 2), but there is no such correlation for other social tasks such as \"Reply Time\" and \"Word Repetition.\""}, {"heading": "C. Sensitivity to Representation Size", "text": "A small embedding size leads to poor model performance, as the model does not have sufficient capacities (\"underfits\") to store information. On the other hand, a high embedding size also leads to poor performance, since the model has redundant information bits (\"overfits\") that have a negative effect. The optimal strategy is usually to search for the size that leads to superior performance. In particular, we build models with the embedding size of {10, 25, 50, 100, 200}. Figure 3 shows the diagrams for all models for this setup. We find that the performance of all monitored models except FT is positively correlated to the representation size for most of the prediction tasks. We discover that FT, which is based on a simple operation of the word vector average to represent a tweet, is invariant to the representation size. This result is surprising, as FT yields good performance with such a small embedding size of 10 (which is actually the optimal hyperresource, as suggested by the authors) using less centimetric (as we strongly for FT)."}, {"heading": "D. Connections with the performance on downstream applications", "text": "In this subsection, we will attempt to establish the correlation between the performance of the model in the various basic tasks of predicting characteristics and the performance of the model in the various real-world applications.Sentiment Analysis: Giachanou et al. [14] showed that sentiment analysis is typically supported by features such as content, slang words, mentions, hashtags, and designated units. We observe that STV is the only unattended model that encodes all five task-specific relevant characteristics, significantly outperforming the other models for this task. On the other hand, PV encodes relatively few relevant characteristics and thus performs worse than BOW (as we will see later) for this task. We note that most of the monitored models (without FastText) capture the task-specific characteristics well. Hashtag prediction: The outstanding characteristics for hashtag prediction [23] include length, slang words, and hashtag prediction itself."}, {"heading": "E. A Case Study of BOW vs Paragraph2Vec", "text": "Table V shows that Paragraph 2Vec is not good at encoding elementary Tweet properties. To confirm this in relation to high-level applications, we compare Paragraph 2Vec with BOW for a variety of Twitter applications. Specifically, we evaluate the models for five applications: (1) predict whether the mood of the tweet is positive, negative or neutral (SA) [26], (2) predict which company the tweet belongs to (EI) [27], (3) predict the priority of the topic to which the tweet belongs (TP) [27], (4) predict the day of the weather referred to in Tweet 5 (W), and (5) predict the type of weather referred to in the tweet (K). Table VI gives the values of the best performing paragraph 2Vec with the variant (BOW or distributed memory) and the representation size ({10, 25, 50, 100, 200} on the performance of the different BOW models we can determine from the results that BOW has shown for the various raphs."}, {"heading": "F. Overall Insights", "text": "Our extensive experiments with a large number of models for important textual and social networking characteristics of tweets provide the following insights. \u2022 Length prediction is the most difficult textual task, while content prediction is the simplest. Word repetition is the simplest social task, while response time prediction is the most complicated. \u2022 Bidirectional LSTMs and Skip Thought Vectors (STV) encode the textual or social characteristics of tweets best. Paragraph2Vec performs the word.5https: / / www.kaggle.com / c / crowdflower-weather-twitter \u2022 FastText is the best model for low-resource applications that offer very little degradation with a reduction in embedding size. \u2022 The relative performance of the models does not change due to the tweet length. All models behave the same behavior as variations in the tweet length."}, {"heading": "VII. CONCLUSION", "text": "In this paper, we tried to interpret multiple tweet representations in terms of the accuracy with which they encode elementary tweet properties (both textual and social), which helped us understand the weaknesses and strengths of such representations in an application-independent, fine-grained way. Based on such an assessment, we conclude that bi-directional LSTMs (BLSTMs) and Skip-Thought Vectors (STV) encode the textual and social characteristics of tweets best. In addition, FastText, with huge information encoded in its small representation, is the best model for resource-poor applications. In the future, we plan to work on interpreting distributed representations of nodes in a network with various interesting networking properties."}], "references": [{"title": "A Latent Semantic Model with Convolutional-Pooling Structure for Information Retrieval", "author": ["Y. Shen", "X. He", "J. Gao", "L. Deng", "G. Mesnil"], "venue": "CIKM, 2014, pp. 101\u2013110.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2014}, {"title": "Distributed Representations of Sentences and Documents", "author": ["Q.V. Le", "T. Mikolov"], "venue": "ICML, 2014, pp. 1188\u20131196.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2014}, {"title": "Sentiment Embeddings with Applications to Sentiment Analysis", "author": ["D. Tang", "F. Wei", "B. Qin", "N. Yang", "T. Liu", "M. Zhou"], "venue": "TKDE, vol. 28, no. 2, pp. 496\u2013509, 2016.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2016}, {"title": "Skip-Thought Vectors", "author": ["R. Kiros", "Y. Zhu", "R. Salakhutdinov", "R.S. Zemel", "R. Urtasun", "A. Torralba", "S. Fidler"], "venue": "NIPS, 2015, pp. 3294\u2013 3302.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning Distributed Representations of Sentences from Unlabelled Data", "author": ["F. Hill", "K. Cho", "A. Korhonen"], "venue": "NAACL-HLT, 2016, pp. 1367\u20131377.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2016}, {"title": "Speech Recognition with Deep Recurrent Neural Networks", "author": ["A. Graves", "A. Mohamed", "G.E. Hinton"], "venue": "ICASSP, 2013, pp. 6645\u20136649.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "Siamese CBOW: Optimizing Word Embeddings for Sentence Representations", "author": ["T. Kenter", "A. Borisov", "M. de Rijke"], "venue": "ACL, 2016.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2016}, {"title": "Tweet2Vec: Character-Based Distributed Representations for Social Media", "author": ["B. Dhingra", "Z. Zhou", "D. Fitzpatrick", "M. Muehl", "W.W. Cohen"], "venue": "ACL, 2016.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2016}, {"title": "Representation Learning: A Review and New Perspectives", "author": ["Y. Bengio", "A.C. Courville", "P. Vincent"], "venue": "TPAMI, vol. 35, no. 8, pp. 1798\u20131828, 2013.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1828}, {"title": "CSE: conceptual sentence embeddings based on attention model", "author": ["Y. Wang", "H. Huang", "C. Feng", "Q. Zhou", "J. Gu", "X. Gao"], "venue": "ACL, 2016, pp. 505\u2013515.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2016}, {"title": "Distributed Representations of Words and Phrases and Their Compositionality", "author": ["T. Mikolov", "I. Sutskever", "K. Chen", "G. Corrado", "J. Dean"], "venue": "NIPS, 2013, pp. 3111\u20133119.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2013}, {"title": "Improved semantic representations from tree-structured long short-term memory networks", "author": ["K.S. Tai", "R. Socher", "C.D. Manning"], "venue": "ACL, 2015, pp. 1556\u20131566.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2015}, {"title": "Like it or not: A Survey of Twitter Sentiment Analysis Methods", "author": ["A. Giachanou", "F. Crestani"], "venue": "CSUR, vol. 49, no. 2, pp. 28:1\u201328:41, 2016.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2016}, {"title": "Convolutional Neural Networks for Sentence Classification", "author": ["Y. Kim"], "venue": "EMNLP, 2014, pp. 1746\u20131751.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2014}, {"title": "Bag of Tricks for Efficient Text Classification", "author": ["A. Joulin", "E. Grave", "P. Bojanowski", "T. Mikolov"], "venue": "CoRR, vol. abs/1607.01759, 2016.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2016}, {"title": "Finegrained Analysis of Sentence Embeddings Using Auxiliary Prediction Tasks", "author": ["Y. Adi", "E. Kermany", "Y. Belinkov", "O. Lavi", "Y. Goldberg"], "venue": "CoRR, vol. abs/1608.04207, 2016.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2016}, {"title": "Twitter Sentiment Classification using Distant Supervision", "author": ["A. Go", "R. Bhayani", "L. Huang"], "venue": "Technical Report, Stanford, 2009.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2009}, {"title": "Weakly Supervised User Profile Extraction from Twitter", "author": ["J. Li", "A. Ritter", "E.H. Hovy"], "venue": "ACL, 2014, pp. 165\u2013174.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "Named Entity Recognition in Tweets: An Experimental Study", "author": ["A. Ritter", "S. Clark", "Mausam", "O. Etzioni"], "venue": "EMNLP, 2011, pp. 1524\u20131534.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2011}, {"title": "Unsupervised Modeling of Twitter Conversations", "author": ["A. Ritter", "C. Cherry", "B. Dolan"], "venue": "NAACL-HLT, 2010, pp. 172\u2013180.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2010}, {"title": "GloVe: Global Vectors for Word Representation", "author": ["J. Pennington", "R. Socher", "C.D. Manning"], "venue": "EMNLP, 2014, pp. 1532\u20131543.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2014}, {"title": "What\u2019s in a Hashtag?: Content based Prediction of the Spread of Ideas in Microblogging Communities", "author": ["O. Tsur", "A. Rappoport"], "venue": "WSDM. ACM, 2012, pp. 643\u2013652.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2012}, {"title": "Keyphrase Extraction using Deep Recurrent Neural Networks on Twitter", "author": ["Q. Zhang", "Y. Wang", "Y. Gong", "X. Huang"], "venue": "EMNLP, 2016, pp. 836\u2013845.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2016}, {"title": "Predicting Responses to Microblog Posts", "author": ["Y. Artzi", "P. Pantel", "M. Gamon"], "venue": "NAACL-HLT, 2012, pp. 602\u2013606.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2012}, {"title": "SemEval-2016 Task 4: Sentiment Analysis in Twitter", "author": ["P. Nakov", "A. Ritter", "S. Rosenthal", "F. Sebastiani", "V. Stoyanov"], "venue": "SemEval, 2016.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2016}, {"title": "Overview of RepLab 2014: Author Profiling and Reputation Dimensions for Online Reputation Management", "author": ["E. Amig\u00f3", "J. Carrillo de Albornoz", "I. Chugur", "A. Corujo", "J. Gonzalo", "E. Meij", "M. de Rijke", "D. Spina"], "venue": "CLEF, 2014, pp. 307\u2013322.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 8, "context": "Central to the performance of these applications [10] is the question of tweet representation: How to best capture the essential meaning of a tweet in a machine-understandable format (or \u201crepresentation\u201d)? Challenges like short length, informal words, misspellings and unusual grammar make it difficult to obtain a good representation to capture these text aspects.", "startOffset": 49, "endOffset": 53}, {"referenceID": 9, "context": "Traditionally, tweets have been modeled using Bag-Of-Words (BOW) [11] and Latent Dirichlet Allocation (LDA) [11].", "startOffset": 65, "endOffset": 69}, {"referenceID": 9, "context": "Traditionally, tweets have been modeled using Bag-Of-Words (BOW) [11] and Latent Dirichlet Allocation (LDA) [11].", "startOffset": 108, "endOffset": 112}, {"referenceID": 10, "context": "Recently there has been a paradigm shift in machine learning towards using distributed representations for words [12] and sentences [3], [6], [13].", "startOffset": 113, "endOffset": 117}, {"referenceID": 1, "context": "Recently there has been a paradigm shift in machine learning towards using distributed representations for words [12] and sentences [3], [6], [13].", "startOffset": 132, "endOffset": 135}, {"referenceID": 4, "context": "Recently there has been a paradigm shift in machine learning towards using distributed representations for words [12] and sentences [3], [6], [13].", "startOffset": 137, "endOffset": 140}, {"referenceID": 11, "context": "Recently there has been a paradigm shift in machine learning towards using distributed representations for words [12] and sentences [3], [6], [13].", "startOffset": 142, "endOffset": 146}, {"referenceID": 2, "context": "Researchers in Twitter analytics have found these representation learning models to be very effective for several critical tasks such as sentiment analysis [4], [14], semantic textual similarity computation [8], hashtag identification [9], etc.", "startOffset": 156, "endOffset": 159}, {"referenceID": 12, "context": "Researchers in Twitter analytics have found these representation learning models to be very effective for several critical tasks such as sentiment analysis [4], [14], semantic textual similarity computation [8], hashtag identification [9], etc.", "startOffset": 161, "endOffset": 165}, {"referenceID": 6, "context": "Researchers in Twitter analytics have found these representation learning models to be very effective for several critical tasks such as sentiment analysis [4], [14], semantic textual similarity computation [8], hashtag identification [9], etc.", "startOffset": 207, "endOffset": 210}, {"referenceID": 7, "context": "Researchers in Twitter analytics have found these representation learning models to be very effective for several critical tasks such as sentiment analysis [4], [14], semantic textual similarity computation [8], hashtag identification [9], etc.", "startOffset": 235, "endOffset": 238}, {"referenceID": 0, "context": "Model Architecture Core Idea Applications Considered in the Paper DSSM [1] Deep Feed Forward network Learn a common mapping for query and document Document ranking CDSSM [2] Deep Feed Forward Convolutional network Learn a common mapping for query and document Document ranking", "startOffset": 170, "endOffset": 173}, {"referenceID": 1, "context": "Paragraph2Vec [3] Word2Vec network Learn document embedding which are good in predicting the words within it Sentiment analysis, Document retrieval", "startOffset": 14, "endOffset": 17}, {"referenceID": 2, "context": "SSWE [4] Simple Feed Forward network Learn sentiment specific word embeddings using distant supervision (emoticons) Sentiment analysis", "startOffset": 5, "endOffset": 8}, {"referenceID": 3, "context": "Skip-Thought vectors [5] Gated Recurrent Unit Encoder-Decoder network Learn sentence embedding which are good in predicting the surrounding sentences (sentential context) Semantic relatedness, Paraphrase detection, Image-sentence ranking, Sentence classification including sentiment analysis SDAE [6] LSTM [7] Encoder-Decoder network Predict the source sentence given the corrupted version of the source sentence Semantic relatedness, Sentence classification tasks used in Skip thought vectors FastSent [6] Word2Vec network Learn sentence embedding which are good in predicting the surrounding sentences (sentential context) Semantic relatedness, Sentence classification tasks used in Skip thought vectors Siamese CBOW [8] Siamese network Learn sentence embedding which are good in predicting the surrounding sentences (sentential context) Semantic relatedness", "startOffset": 21, "endOffset": 24}, {"referenceID": 4, "context": "Skip-Thought vectors [5] Gated Recurrent Unit Encoder-Decoder network Learn sentence embedding which are good in predicting the surrounding sentences (sentential context) Semantic relatedness, Paraphrase detection, Image-sentence ranking, Sentence classification including sentiment analysis SDAE [6] LSTM [7] Encoder-Decoder network Predict the source sentence given the corrupted version of the source sentence Semantic relatedness, Sentence classification tasks used in Skip thought vectors FastSent [6] Word2Vec network Learn sentence embedding which are good in predicting the surrounding sentences (sentential context) Semantic relatedness, Sentence classification tasks used in Skip thought vectors Siamese CBOW [8] Siamese network Learn sentence embedding which are good in predicting the surrounding sentences (sentential context) Semantic relatedness", "startOffset": 297, "endOffset": 300}, {"referenceID": 5, "context": "Skip-Thought vectors [5] Gated Recurrent Unit Encoder-Decoder network Learn sentence embedding which are good in predicting the surrounding sentences (sentential context) Semantic relatedness, Paraphrase detection, Image-sentence ranking, Sentence classification including sentiment analysis SDAE [6] LSTM [7] Encoder-Decoder network Predict the source sentence given the corrupted version of the source sentence Semantic relatedness, Sentence classification tasks used in Skip thought vectors FastSent [6] Word2Vec network Learn sentence embedding which are good in predicting the surrounding sentences (sentential context) Semantic relatedness, Sentence classification tasks used in Skip thought vectors Siamese CBOW [8] Siamese network Learn sentence embedding which are good in predicting the surrounding sentences (sentential context) Semantic relatedness", "startOffset": 306, "endOffset": 309}, {"referenceID": 4, "context": "Skip-Thought vectors [5] Gated Recurrent Unit Encoder-Decoder network Learn sentence embedding which are good in predicting the surrounding sentences (sentential context) Semantic relatedness, Paraphrase detection, Image-sentence ranking, Sentence classification including sentiment analysis SDAE [6] LSTM [7] Encoder-Decoder network Predict the source sentence given the corrupted version of the source sentence Semantic relatedness, Sentence classification tasks used in Skip thought vectors FastSent [6] Word2Vec network Learn sentence embedding which are good in predicting the surrounding sentences (sentential context) Semantic relatedness, Sentence classification tasks used in Skip thought vectors Siamese CBOW [8] Siamese network Learn sentence embedding which are good in predicting the surrounding sentences (sentential context) Semantic relatedness", "startOffset": 503, "endOffset": 506}, {"referenceID": 6, "context": "Skip-Thought vectors [5] Gated Recurrent Unit Encoder-Decoder network Learn sentence embedding which are good in predicting the surrounding sentences (sentential context) Semantic relatedness, Paraphrase detection, Image-sentence ranking, Sentence classification including sentiment analysis SDAE [6] LSTM [7] Encoder-Decoder network Predict the source sentence given the corrupted version of the source sentence Semantic relatedness, Sentence classification tasks used in Skip thought vectors FastSent [6] Word2Vec network Learn sentence embedding which are good in predicting the surrounding sentences (sentential context) Semantic relatedness, Sentence classification tasks used in Skip thought vectors Siamese CBOW [8] Siamese network Learn sentence embedding which are good in predicting the surrounding sentences (sentential context) Semantic relatedness", "startOffset": 719, "endOffset": 722}, {"referenceID": 7, "context": "Tweet2Vec [9] Bi-GRU Encoder network Learn tweet embedding directly from characters using hashtags for supervision Hashtag prediction", "startOffset": 10, "endOffset": 13}, {"referenceID": 4, "context": "[6] perform a comparison of different sentence representation models by evaluating them for different high-level semantic tasks such as paraphrase identification, sentiment classification, etc.", "startOffset": 0, "endOffset": 3}, {"referenceID": 15, "context": "The most relevant work to ours is that of [17], which investigates three sentence properties in comparing two models: average of words vectors and LSTM auto-encoders.", "startOffset": 42, "endOffset": 46}, {"referenceID": 13, "context": "Model Architecture Core Idea Applications Considered in the Paper CNN [15] Simple CNN Classify using a CNN on top of pre-trained word vectors Sentiment analysis, Question classification Tree-LSTM [13] Recursive Network Generalization of LSTMs to model recursive nature of sentences Semantic relatedness, Sentiment classification FastText [16] Simple Feed Forward Network Classify using the average of word vectors Sentiment analysis, Tag prediction", "startOffset": 70, "endOffset": 74}, {"referenceID": 11, "context": "Model Architecture Core Idea Applications Considered in the Paper CNN [15] Simple CNN Classify using a CNN on top of pre-trained word vectors Sentiment analysis, Question classification Tree-LSTM [13] Recursive Network Generalization of LSTMs to model recursive nature of sentences Semantic relatedness, Sentiment classification FastText [16] Simple Feed Forward Network Classify using the average of word vectors Sentiment analysis, Tag prediction", "startOffset": 196, "endOffset": 200}, {"referenceID": 14, "context": "Model Architecture Core Idea Applications Considered in the Paper CNN [15] Simple CNN Classify using a CNN on top of pre-trained word vectors Sentiment analysis, Question classification Tree-LSTM [13] Recursive Network Generalization of LSTMs to model recursive nature of sentences Semantic relatedness, Sentiment classification FastText [16] Simple Feed Forward Network Classify using the average of word vectors Sentiment analysis, Tag prediction", "startOffset": 338, "endOffset": 342}, {"referenceID": 16, "context": "Task Dataset name Dataset size Length Sentiment140 [18] 1,98,440 Content Sentiment140 [18] 1,98,083 Word Order Sentiment140 [18] 1,94,720 Slang Words https://noisy-text.", "startOffset": 51, "endOffset": 55}, {"referenceID": 16, "context": "Task Dataset name Dataset size Length Sentiment140 [18] 1,98,440 Content Sentiment140 [18] 1,98,083 Word Order Sentiment140 [18] 1,94,720 Slang Words https://noisy-text.", "startOffset": 86, "endOffset": 90}, {"referenceID": 16, "context": "Task Dataset name Dataset size Length Sentiment140 [18] 1,98,440 Content Sentiment140 [18] 1,98,083 Word Order Sentiment140 [18] 1,94,720 Slang Words https://noisy-text.", "startOffset": 124, "endOffset": 128}, {"referenceID": 17, "context": "html 3,120 Hashtag User Profiling [19] 2,00,000 Named Entities Twitter NER [20] 2,394 Cap.", "startOffset": 34, "endOffset": 38}, {"referenceID": 18, "context": "html 3,120 Hashtag User Profiling [19] 2,00,000 Named Entities Twitter NER [20] 2,394 Cap.", "startOffset": 75, "endOffset": 79}, {"referenceID": 17, "context": "Count User Profiling [19] 2,00,000 Informative Cap.", "startOffset": 21, "endOffset": 25}, {"referenceID": 18, "context": "Twitter NER [20] 400 Mention Count User Profiling [19] 2,00,000 Mention Position User Profiling [19] 2,00,000 Is Reply Conversation [21] 75,008 Reply Time Conversation [21] 31,669 Word Repetition in Conversation Conversation [21] 37,504", "startOffset": 12, "endOffset": 16}, {"referenceID": 17, "context": "Twitter NER [20] 400 Mention Count User Profiling [19] 2,00,000 Mention Position User Profiling [19] 2,00,000 Is Reply Conversation [21] 75,008 Reply Time Conversation [21] 31,669 Word Repetition in Conversation Conversation [21] 37,504", "startOffset": 50, "endOffset": 54}, {"referenceID": 17, "context": "Twitter NER [20] 400 Mention Count User Profiling [19] 2,00,000 Mention Position User Profiling [19] 2,00,000 Is Reply Conversation [21] 75,008 Reply Time Conversation [21] 31,669 Word Repetition in Conversation Conversation [21] 37,504", "startOffset": 96, "endOffset": 100}, {"referenceID": 19, "context": "Twitter NER [20] 400 Mention Count User Profiling [19] 2,00,000 Mention Position User Profiling [19] 2,00,000 Is Reply Conversation [21] 75,008 Reply Time Conversation [21] 31,669 Word Repetition in Conversation Conversation [21] 37,504", "startOffset": 132, "endOffset": 136}, {"referenceID": 19, "context": "Twitter NER [20] 400 Mention Count User Profiling [19] 2,00,000 Mention Position User Profiling [19] 2,00,000 Is Reply Conversation [21] 75,008 Reply Time Conversation [21] 31,669 Word Repetition in Conversation Conversation [21] 37,504", "startOffset": 168, "endOffset": 172}, {"referenceID": 19, "context": "Twitter NER [20] 400 Mention Count User Profiling [19] 2,00,000 Mention Position User Profiling [19] 2,00,000 Is Reply Conversation [21] 75,008 Reply Time Conversation [21] 31,669 Word Repetition in Conversation Conversation [21] 37,504", "startOffset": 225, "endOffset": 229}, {"referenceID": 9, "context": "\u2022 Bag Of Words (BOW) [11] - This simple representation captures the TF-IDF value of an n-gram.", "startOffset": 21, "endOffset": 25}, {"referenceID": 9, "context": "\u2022 Latent Dirichlet Allocation (LDA) [11] - We use the topic distribution resulting by running LDA with number of topics as 200, as the tweet representation.", "startOffset": 36, "endOffset": 40}, {"referenceID": 20, "context": "\u2022 Bag Of Means (BOM) - We take the average of the word embeddings obtained by running the GloVe [22] model on 2B tweets with embedding size as 200 1.", "startOffset": 96, "endOffset": 100}, {"referenceID": 0, "context": "\u2022 Convolutional DSSM (CDSSM) [2] - This is the convolutional variant of DSSM.", "startOffset": 29, "endOffset": 32}, {"referenceID": 1, "context": "\u2022 Paragraph2Vec (PV) [3] - This model based on Word2Vec [12] learns embedding for a document which is good in predicting the words within it.", "startOffset": 21, "endOffset": 24}, {"referenceID": 10, "context": "\u2022 Paragraph2Vec (PV) [3] - This model based on Word2Vec [12] learns embedding for a document which is good in predicting the words within it.", "startOffset": 56, "endOffset": 60}, {"referenceID": 3, "context": "\u2022 Skip-Thought Vectors (STV) [5] - This is a Gated Recurrent Unit (GRU) encoder trained to predict adjacent sentences in a books corpus.", "startOffset": 29, "endOffset": 32}, {"referenceID": 7, "context": "\u2022 Tweet2Vec (T2V) [9] - This is a character composition model working directly on the character sequences to predict the user-annotated hashtags in a tweet.", "startOffset": 18, "endOffset": 21}, {"referenceID": 6, "context": "\u2022 Siamese CBOW (SCBOW) [8] - This model uses averaging of word vectors to represent a sentence, and the objective and data used here is same as that for STV.", "startOffset": 23, "endOffset": 26}, {"referenceID": 13, "context": "\u2022 Convolutional Neural Network (CNN) - This is a simple CNN proposed in [15].", "startOffset": 72, "endOffset": 76}, {"referenceID": 5, "context": "\u2022 Long Short Term Memory Network (LSTM) [7] - This is a vanilla LSTM based recurrent model, applied from start to the end of a tweet, and the last hidden vector is used as tweet representation.", "startOffset": 40, "endOffset": 43}, {"referenceID": 11, "context": "We use the optimal hyperparameter settings as proposed in [13].", "startOffset": 58, "endOffset": 62}, {"referenceID": 5, "context": "com/bdhingra/tweet2vec \u2022 Bi-directional LSTM (BLSTM) [7] - This extends LSTM by using two LSTM networks, processing a tweet left-toright and right-to-left respectively.", "startOffset": 53, "endOffset": 56}, {"referenceID": 11, "context": "We use the optimal hyper-parameter settings proposed in [13].", "startOffset": 56, "endOffset": 60}, {"referenceID": 14, "context": "\u2022 FastText (FT) [16] - This is a simple architecture which averages the n-gram vectors to represent a tweet, followed by the softmax in the final layer.", "startOffset": 16, "endOffset": 20}, {"referenceID": 15, "context": "The superior performance of all the models for the \u2018Content\u2019 task in particular is unlike the relatively lower performance reported in [17], mainly because of the short length of the tweets.", "startOffset": 135, "endOffset": 139}, {"referenceID": 12, "context": "[14] showed that sentiment analysis is typically aided by features such as content, slang words, mention count, hashtags and named entities.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "Hashtag Prediction: The salient features for hashtag prediction [23] include length, slang words and hashtag itself.", "startOffset": 64, "endOffset": 68}, {"referenceID": 18, "context": "Named Entity Recognition: This task is benefitted by features such as slang words and capitalization [20].", "startOffset": 101, "endOffset": 105}, {"referenceID": 22, "context": "The recurrent models are able to capture both features successfully and clearly explains why these models are the state-of-theart [24] for this task.", "startOffset": 130, "endOffset": 134}, {"referenceID": 23, "context": "Response Prediction: This is a social task to identify if a given tweet can receive a response [25].", "startOffset": 95, "endOffset": 99}, {"referenceID": 24, "context": "Specifically, we evaluate the models for five applications: (1) predict whether the sentiment of tweet is positive, negative or neutral (SA) [26], (2) predict the entity the tweet belongs to (EI) [27], (3) predict the priority of the topic the tweet belongs to (TP) [27],", "startOffset": 141, "endOffset": 145}, {"referenceID": 25, "context": "Specifically, we evaluate the models for five applications: (1) predict whether the sentiment of tweet is positive, negative or neutral (SA) [26], (2) predict the entity the tweet belongs to (EI) [27], (3) predict the priority of the topic the tweet belongs to (TP) [27],", "startOffset": 196, "endOffset": 200}, {"referenceID": 25, "context": "Specifically, we evaluate the models for five applications: (1) predict whether the sentiment of tweet is positive, negative or neutral (SA) [26], (2) predict the entity the tweet belongs to (EI) [27], (3) predict the priority of the topic the tweet belongs to (TP) [27],", "startOffset": 266, "endOffset": 270}], "year": 2017, "abstractText": "Research in analysis of microblogging platforms is experiencing a renewed surge with a large number of works applying representation learning models for applications like sentiment analysis, semantic textual similarity computation, hashtag prediction, etc. Although the performance of the representation learning models has been better than the traditional baselines for such tasks, little is known about the elementary properties of a tweet encoded within these representations, or why particular representations work better for certain tasks. Our work presented here constitutes the first step in opening the black-box of vector embeddings for tweets. Traditional feature engineering methods for high-level applications have exploited various elementary properties of tweets. We believe that a tweet representation is effective for an application because it meticulously encodes the application-specific elementary properties of tweets. To understand the elementary properties encoded in a tweet representation, we evaluate the representations on the accuracy to which they can model each of those properties such as tweet length, presence of particular words, hashtags, mentions, capitalization, etc. Our systematic extensive study of nine supervised and four unsupervised tweet representations against most popular eight textual and five social elementary properties reveal that Bi-directional LSTMs (BLSTMs) and Skip-Thought Vectors (STV) best encode the textual and social properties of tweets respectively. FastText is the best model for low resource settings, providing very little degradation with reduction in embedding size. Finally, we draw interesting insights by correlating the model performance obtained for elementary property prediction tasks with the highlevel downstream applications.", "creator": "LaTeX with hyperref package"}}}