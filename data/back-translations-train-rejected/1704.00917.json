{"id": "1704.00917", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Apr-2017", "title": "Deriving Probability Density Functions from Probabilistic Functional Programs", "abstract": "The probability density function of a probability distribution is a fundamental concept in probability theory and a key ingredient in various widely used machine learning methods. However, the necessary framework for compiling probabilistic functional programs to density functions has only recently been developed. In this work, we present a density compiler for a probabilistic language with failure and both discrete and continuous distributions, and provide a proof of its soundness. The compiler greatly reduces the development effort of domain experts, which we demonstrate by solving inference problems from various scientific applications, such as modelling the global carbon cycle, using a standard Markov chain Monte Carlo framework.", "histories": [["v1", "Tue, 4 Apr 2017 08:27:21 GMT  (68kb,D)", "http://arxiv.org/abs/1704.00917v1", null], ["v2", "Thu, 29 Jun 2017 19:47:20 GMT  (69kb,D)", "http://arxiv.org/abs/1704.00917v2", null]], "reviews": [], "SUBJECTS": "cs.PL cs.AI", "authors": ["sooraj bhat", "johannes borgstr\\\"om", "andrew d gordon", "claudio russo"], "accepted": false, "id": "1704.00917"}, "pdf": {"name": "1704.00917.pdf", "metadata": {"source": "CRF", "title": "DERIVING PROBABILITY DENSITY FUNCTIONS FROM PROBABILISTIC FUNCTIONAL PROGRAMS", "authors": ["CLAUDIO RUSSO"], "emails": [], "sections": [{"heading": "1. INTRODUCTION", "text": "In fact, most of them will be able to play by the rules that they need for their work."}, {"heading": "2. LANGUAGES", "text": "To describe the density compiler, we first specify its input (source) and output (target) languages. Both languages are variants of a simple first-order functional language, in which the results of partial calculations can be bound to variables using a let construct.2.1. Fun: Probabilistic Expressions (Review). Our source language is a version of the Fun core calculation (Borgstro \u00bc m et al., 2011), without observation. To mark certain program points as impossible, we add a fail construct (Kiselyov and Shan, 2009). Fun is a first-order functional language without recursion that extends the language of Ramsey and Pfeffer (2002), and this version has a natural semantics in the substance probability monade. Our implementation efficiently supports a richer language with data sets and fixed types of arrays and arrays that can have a constant of integers."}, {"heading": "Types of Fun:", "text": "We assume a collection of total deterministic functions for these types, including arithmetic and logical operators. Each operation op of arity n has a form valley signature op: t1; \u00b7 \u0445 tn \u2192 tn + 1. We also assume standard families of primitive probability distributions, including the following. Distributions: Dist: (t1; \u00b7 \u0445 tn) \u2192 t Bernoulli: (real) \u2192 bool Poisson: (real) int Gauss: (real; real; real; real; real; real; real; real; real; real; real; real; real; real; real; real; real; real; real; real; real; real; real; real; real; real; real; real; real; real; real; real; real; real; real; real; real; real; real; real; real; real; real; real; real; real; (real; real; real; real; real; real; real; real; real; real; real; real; real; real; real; real; real; real; real; real; real; real; real; real; real; real; real)."}, {"heading": "Expressions of Fun:", "text": "In fact, most people who are able to bind their variables (x, x1, x2), we will be able to write in N. (M) The primitive distribution that is able to bind their variables (x, x2). We will identify expressions up to alpharenaming of bound variables. (M) The primitive distribution that is able to bind these variables. (M) We will identify expressions up to alpharenaming of bound variables that are able to bind inl (or inr) generates a value that corresponds to the left (or right) branch of a sum. Values of the sum type are deconstructed by the pure branch. (top, inlu V) The left sum constructor inrt V (right sum constructorM, N)."}, {"heading": "Selected Typing Rules: \u0393 `M : t", "text": "(FUN INL).............................................................................................................................................................................................................................................................."}, {"heading": "Typing Rules for Closed Value Substitutions: \u0393 ` \u03c3", "text": "(SUBST EMPTY). (SUBST VAR). (SUBST EMPTY). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S. (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S. (S). (S). (S). (S. (S). (S). (S). (S). (S). (S). (S). (S). (S). (S. (S). (S). (S). (S). (S). (S. (S). (S). (S). (S). (S. (S). (S). (S)."}, {"heading": "PDF.", "text": "In order to convert the expressions into density functions, we first need a way of interpreting a closed fun expression M as a sub-probability measurement variable PM via its return type. Open fail-free fun expressions have a simple semantics (Ramsey and Pfeffer, 2002) as a calculation in the probability monad (Giry, 1982). To treat the failure of the primitives, we use an existing extension (Gordon et al., 2013) of the semantics of Ramsey and Pfeffer (2002) to a richer monad: the subprobability monad (Panangaden, 1999) 3. To understand the operations of the probability monad, the sub-probability monad must additionally add a zero constant that assumes zero, the carrier set is expanded from probability measures to sub-probability measures, i.e."}, {"heading": "Typing Rule for Integration: \u0393 ` E : t", "text": "(TARGET INT). (TARGET INT INT). (TARGET INT INT INT INT.). (TARGET INT INT INT INT INT INT INT INT INT INT INT INT INT INT INT INT INT.). (TARGET INT INT INT INT INT INT INT INT INT INT INT INT INT INT INT INT INT INT INT INT INT INT.). (TARGET INT INT INT INT INT. (TI). (I). (I). (I). (I). (I). (I). (I). (I). (I). (I). \"(I). (I). (I). (I). (I). (I). (I). (I). (I). (I). (I). (I). (I). (I). (I). (I). (I). (I). (I). (I). (I). (I). (I). (I). (I). (I).). (I.). (I.). (I.). (I.). (I.).). (). (I.). (I.). ().). (I. ().).). (I. ().). (). (). ().). ().). (I. ().).). ().). (.). (.).). (.). (.).).). (.).). (.).). (.). (.).). (.).). (.).). (.).)."}, {"heading": "3. THE DENSITY COMPILER", "text": "This year, it will be able to leave the country to save it."}, {"heading": "Probability Context: \u03d2", "text": "The probability context in line 7 of Figure 1 is 7: = branch, temperature, result = temperature + mB, which contains two random variables and one deterministic variable. In order for a probability context to be well formed, it must be well thought out and well typed."}, {"heading": "Well-formed probability context: \u0393 ` \u03d2 wf", "text": "ENV. ENV. ENV. ENV. ENAR. ENV. ENAR. ENV. ENAR. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV. ENV."}, {"heading": "Inductively Defined Judgments of the Compiler:", "text": "The expression F gives the density of the variables in XWe starts the description of the actual compiler with the following assessment of the limit density, which calculates an expression for the common limit PDF of the random variables in its argument. The variables in the argument are free in the calculated expression. In the following, we write x1,..., xn\\ Y for the tuple of variables resulting from x1,..., xn by deleting all variables in Y and dual for x1,..., xn\\ Y."}, {"heading": "Marginal Density: \u03d2;E `marg(X)\u21d2 F", "text": "D D D (D D) D (D D) D (D) D (D) D (D D) D (D) D (D) D (D) D (D) D (D) D (D). D (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D) D D D (D D). D D D (D D). D (D) D (D D D) D (D D) D D D D (D) D D D D D (D D D D) D (D) D D D D D (D) D D D D D D (D D D D D D) D (D D D D D D D) D (D D D D D D D) D (D D D D D D D D D) D (D D D D D D D) D (D D D D D D D D D D D D D (D D D D D D D D D D D D D D D D D D D D D D D D D D D (D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D (D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D D"}, {"heading": "Derived rules for if statements", "text": "(IF). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F. (F). (F). (. (F). (F). (F). (F). (F). (. (F). (F). (F). (. (. (F. (F. (. (F). (.). (F). (.). (.). (.). (F). (. (.).). (.). (.). (. (F.).). ("}, {"heading": "Proof.", "text": "(1) By inversion of (MARGINAL), F = 1,..., yk. By inversion of (MARGINAL), F = 1,..., yk. By inversion of (MARGINAL), F = 1,..., yk. By inversion of (MARGINAL), F = 1,..., yk. By inversion of (MARGINAL), F = 1,..., yk. By inversion of (MARGINAL) and (MARGINAL), F = 1,..., yk. By inversion of (MARGINAL), F = y1,..., yk."}, {"heading": "Proof.", "text": "(1) The (MARGINAL) rule is deterministic. (2) By induction to M, use (1). In any case, at most one compilation rule is applicable. (2) We also need a technical problem with respect to pure expressions with their respective counterparameters. (2) If M is pure and the density function is actually characterized by the density compiler (via stock integration), the distribution of M is given by monadic semantics. Theorem 1 (Soundness) asserts that, for all closed expressions M, the density function is given by the density compiler, the distribution of M is actually given by monadic semantics. (1) Theory (M)."}, {"heading": "4. EVALUATION", "text": "We evaluate the compiler using several synthetic textbook examples and several real-life examples from scientific applications. We want to confirm that the density compiler handles these examples, and understand how much the compiler reduces the burden on developers and their impact on performance. 4.1. Implementation. Since Fun is a sublanguage of F #, we implement our models as F # programs and use the offer mechanism of F # to capture their syntax trees. Running the F # program is equivalent to collecting data from the model. To calculate the PDF, the compiler takes the syntax tree (F # Expr type) of the model and produces another expr corresponding to a deterministic F # program as output. We then use runtime code generation to compile the generated expr to MSIL byte code, which is computed just-in-time to executable machine code when called, as well as static generated code #."}, {"heading": "Code Examples.", "text": "To illustrate the implementation, here is the actual F # code expressing a mixture of Gaussians (a variant of our introductory example): type W = {bias: double; mean: double []; sd: double []} [< Fun >] let prior () = {bias = random ()))) mean = [| for i in 0.. 1 \u2192 random (\u2212 bias: double []; sd = [for i in 0.. 1 ()).is sd = [for i in 0.. 1 \u2192 random (uniform (100.0, 500.0) |]} let xs = [for i in 1.. 100 \u2192 random () [< Fun >] let code = [< sd = [for i in 0.. 1 \u2192 random (w.bias)."}, {"heading": "5. RELATED WORK", "text": "An abbreviated version of this paper appears as Bhat et al. (2013). Proof of correctness (for a version of the source language without pure latte and general agreement) was recently mechanized in Isabelle von Eberl et al. (2015). This paper builds on the work of Bhat et al. (2012), which develops a theoretical framework for calculating PDFs but does not describe implementation or proof of correctness. Section 3 \"s density compiler has a simpler presentation, with two judgments compared to five, and has rules for pure lots and operations on integers. Our paper also uses a richer framework for calculating languages (Fun) that fail, match and are general when (and for performance reasons, left pure).Gordon et al al al. (2013) describe a naive calculation routine for Fun without random runs; this sublanguage does not cover many useful classes of models such as hierarchical and mixtures."}, {"heading": "6. CONCLUSIONS AND FUTURE WORK", "text": "We have described a compiler for the automatic calculation of probability density functions for programs from a rich Bayean probabilistic programming language, proven the algorithm to be correct, and demonstrated its applicability to real scientific models. Incorporating fail into the language appears useful for scientific models, which provides an easy way to exclude branches that are scientifically impossible. However, further research is needed to clarify this assertion. A disadvantage of the compiler is that terms of the composite type must either have a PDF or be pure, which excludes terms such as (0.0, random (uniform). One possibility for future work would be to refine the expression types with determination information and use this additional information to allow for more common distributions (see (TUPLE VAR))."}, {"heading": "ACKNOWLEDGMENTS", "text": "We thank Manuel Eberl and Tobias Nipkow for helpful comments, especially on the semantics of the integration operator."}, {"heading": "APPENDIX A. SPECIES DISTRIBUTION (MCINERNY AND PURVES, 2011)", "text": "let Nspecies = 20 let Ntypes = 2000type W = {Topt: double []] Tb = (double []] Terr: double Ttrue: double [] type Y = {Tobs: double []; Y: double []] let CalcSpProb w t sp = (t \u2212 w.Topt. [sp] / w.Tbreadth. [sp] w.MaxProb. [sp]; exp (\u2212 z) let prior () [< Fun >] let () = {Topt = [for j in 0.. Nspecies \u2212 Tr \u2212 random (Uniform (0,1, 50.0) | Tbreadth = [for j in 0.. Nspecies \u2212.1 \u2192 random (Uniform (0,1, 50.0)))."}], "references": [{"title": "The change of variables formula using matrix volume", "author": ["A. Ben-Israel"], "venue": "SIAM Journal of Matrix Analysis,", "citeRegEx": "Ben.Israel.,? \\Q1999\\E", "shortCiteRegEx": "Ben.Israel.", "year": 1999}, {"title": "A type theory for probability density functions", "author": ["S. Bhat", "A. Agarwal", "R.W. Vuduc", "A.G. Gray"], "venue": "In J. Field and M. Hicks, editors,", "citeRegEx": "Bhat et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Bhat et al\\.", "year": 2012}, {"title": "Deriving probability density functions from probabilistic functional programs. In Tools and Algorithms for the Construction and Analysis of Systems, 19th International Conference", "author": ["S. Bhat", "J. Borgstr\u00f6m", "A.D. Gordon", "C. Russo"], "venue": "TACAS 2013,", "citeRegEx": "Bhat et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bhat et al\\.", "year": 2013}, {"title": "Pattern Recognition and Machine Learning", "author": ["C.M. Bishop"], "venue": null, "citeRegEx": "Bishop.,? \\Q2006\\E", "shortCiteRegEx": "Bishop.", "year": 2006}, {"title": "Measure transformer semantics for Bayesian machine learning", "author": ["J. Borgstr\u00f6m", "A.D. Gordon", "M. Greenberg", "J. Margetson", "J. Van Gael"], "venue": "In European Symposium on Programming (ESOP\u201911),", "citeRegEx": "Borgstr\u00f6m et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Borgstr\u00f6m et al\\.", "year": 2011}, {"title": "Probabilistic inductive logic programming, pages 92\u2013117", "author": ["P. Domingos", "S. Kok", "D. Lowd", "H. Poon", "M. Richardson", "P. Singla"], "venue": null, "citeRegEx": "Domingos et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Domingos et al\\.", "year": 2008}, {"title": "A verified compiler for probability density functions", "author": ["M. Eberl", "J. H\u00f6lzl", "T. Nipkow"], "venue": "24th European Symposium on Programming: ESOP 2015,", "citeRegEx": "Eberl et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Eberl et al\\.", "year": 2015}, {"title": "A language and program for complex Bayesian modelling", "author": ["W.R. Gilks", "A. Thomas", "D.J. Spiegelhalter"], "venue": "The Statistician,", "citeRegEx": "Gilks et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Gilks et al\\.", "year": 1994}, {"title": "A categorical approach to probability theory", "author": ["M. Giry"], "venue": null, "citeRegEx": "Giry.,? \\Q1982\\E", "shortCiteRegEx": "Giry.", "year": 1982}, {"title": "Church: a language for generative models", "author": ["N. Goodman", "V.K. Mansinghka", "D.M. Roy", "K. Bonawitz", "J.B. Tenenbaum"], "venue": "In Uncertainty in Artificial Intelligence", "citeRegEx": "Goodman et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Goodman et al\\.", "year": 2008}, {"title": "A model-learner pattern for Bayesian reasoning", "author": ["A.D. Gordon", "M. Aizatulin", "J. Borgstr\u00f6m", "G. Claret", "T. Graepel", "A. Nori", "S. Rajamani", "C. Russo"], "venue": "In POPL,", "citeRegEx": "Gordon et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Gordon et al\\.", "year": 2013}, {"title": "Evaluating Derivatives: Principles and Techniques of Algorithmic Differentiation", "author": ["A. Griewank", "A. Walther"], "venue": "SIAM, 2nd edition,", "citeRegEx": "Griewank and Walther.,? \\Q2008\\E", "shortCiteRegEx": "Griewank and Walther.", "year": 2008}, {"title": "Embedded probabilistic programming", "author": ["O. Kiselyov", "C. Shan"], "venue": "In Domain-Specific Languages,", "citeRegEx": "Kiselyov and Shan.,? \\Q2009\\E", "shortCiteRegEx": "Kiselyov and Shan.", "year": 2009}, {"title": "Fine-scale environmental variation in species distribution modelling: regression dilution, latent variables and neighbourly advice", "author": ["G. McInerny", "D. Purves"], "venue": "Methods in Ecology and Evolution,", "citeRegEx": "McInerny and Purves.,? \\Q2011\\E", "shortCiteRegEx": "McInerny and Purves.", "year": 2011}, {"title": "Probabilistic inference using Markov chain Monte Carlo methods", "author": ["R.M. Neal"], "venue": "Technical Report CRG-TR-93-1, Dept. of Computer Science,", "citeRegEx": "Neal.,? \\Q1993\\E", "shortCiteRegEx": "Neal.", "year": 1993}, {"title": "The category of Markov kernels", "author": ["P. Panangaden"], "venue": "Electronic Notes in Theoretical Computer Science,", "citeRegEx": "Panangaden.,? \\Q1999\\E", "shortCiteRegEx": "Panangaden.", "year": 1999}, {"title": "Stochastic lambda calculus and monads of probability distributions", "author": ["N. Ramsey", "A. Pfeffer"], "venue": "In POPL,", "citeRegEx": "Ramsey and Pfeffer.,? \\Q2002\\E", "shortCiteRegEx": "Ramsey and Pfeffer.", "year": 2002}, {"title": "AutoBayes program synthesis system users manual", "author": ["J. Schumann", "T. Pressburger", "E. Denney", "W. Buntine", "B. Fischer"], "venue": "Technical Report NASA/TM\u20132008\u2013215366, NASA Ames Research Center,", "citeRegEx": "Schumann et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Schumann et al\\.", "year": 2008}, {"title": "Parametric Statistical Modeling by Minimum Integrated Square", "author": ["D. Scott"], "venue": "Error. Technometrics,", "citeRegEx": "Scott.,? \\Q2001\\E", "shortCiteRegEx": "Scott.", "year": 2001}, {"title": "The climate dependence of the terrestrial carbon cycle; including parameter and structural uncertainties", "author": ["M.J. Smith", "M.C. Vanderwel", "V. Lyutsarev", "S. Emmott", "D.W. Purves"], "venue": "Biogeosciences Discussions,", "citeRegEx": "Smith et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Smith et al\\.", "year": 2012}, {"title": "A model of set-theory in which every set of reals is Lebesgue measurable", "author": ["R.M. Solovay"], "venue": "The Annals of Mathematics, Second Series,", "citeRegEx": "Solovay.,? \\Q1970\\E", "shortCiteRegEx": "Solovay.", "year": 1970}, {"title": "Lightweight implementations of probabilistic programming languages via transformational compilation", "author": ["D. Wingate", "A. Stuhlmueller", "N. Goodman"], "venue": "In Proceedings of the 14th Intl. Conf. on Artificial Intelligence and Statistics,", "citeRegEx": "Wingate et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Wingate et al\\.", "year": 2011}], "referenceMentions": [{"referenceID": 18, "context": "Such techniques include maximum likelihood or maximum a posteriori estimation, L2 estimation, importance sampling, and Markov chain Monte Carlo (MCMC) methods (Scott, 2001; Bishop, 2006).", "startOffset": 159, "endOffset": 186}, {"referenceID": 3, "context": "Such techniques include maximum likelihood or maximum a posteriori estimation, L2 estimation, importance sampling, and Markov chain Monte Carlo (MCMC) methods (Scott, 2001; Bishop, 2006).", "startOffset": 159, "endOffset": 186}, {"referenceID": 16, "context": "However, despite their utility, density functions have been largely absent from the literature on probabilistic functional programming (Ramsey and Pfeffer, 2002; Goodman et al., 2008; Kiselyov and Shan, 2009).", "startOffset": 135, "endOffset": 208}, {"referenceID": 9, "context": "However, despite their utility, density functions have been largely absent from the literature on probabilistic functional programming (Ramsey and Pfeffer, 2002; Goodman et al., 2008; Kiselyov and Shan, 2009).", "startOffset": 135, "endOffset": 208}, {"referenceID": 12, "context": "However, despite their utility, density functions have been largely absent from the literature on probabilistic functional programming (Ramsey and Pfeffer, 2002; Goodman et al., 2008; Kiselyov and Shan, 2009).", "startOffset": 135, "endOffset": 208}, {"referenceID": 2, "context": "An abridged version of this paper was published as (Bhat et al., 2013).", "startOffset": 51, "endOffset": 70}, {"referenceID": 4, "context": "Consider for example a simple mixture of Gaussians, here written in Fun (Borgstr\u00f6m et al., 2011), a probabilistic functional language embedded within F# (Syme et al.", "startOffset": 72, "endOffset": 96}, {"referenceID": 1, "context": "Details and examples are given by Bhat et al. (2012), who provide the theory for addressing this problem, which we extend and implement in this work.", "startOffset": 34, "endOffset": 53}, {"referenceID": 3, "context": "Bishop provides an excellent account of Bayesian learning (Bishop, 2006).", "startOffset": 58, "endOffset": 72}, {"referenceID": 14, "context": "Neal (1993) gives an excellent review of MCMC methods.", "startOffset": 0, "endOffset": 12}, {"referenceID": 1, "context": "Specifically: \u2022 We provide the first implementation of a density compiler based on the specification by Bhat et al. (2012). We compile programs in the probabilistic language Fun (described in Section 2.", "startOffset": 104, "endOffset": 123}, {"referenceID": 4, "context": "Our source language is a version of the core calculus Fun (Borgstr\u00f6m et al., 2011), without observation.", "startOffset": 58, "endOffset": 82}, {"referenceID": 12, "context": "To mark certain program points as impossible, we add a fail construct (Kiselyov and Shan, 2009).", "startOffset": 70, "endOffset": 95}, {"referenceID": 4, "context": "Our source language is a version of the core calculus Fun (Borgstr\u00f6m et al., 2011), without observation. To mark certain program points as impossible, we add a fail construct (Kiselyov and Shan, 2009). Fun is a first-order functional language without recursion that extends the language of Ramsey and Pfeffer (2002), and this version has a natural semantics in the sub-probability monad.", "startOffset": 59, "endOffset": 316}, {"referenceID": 20, "context": "Indeed, the power of the axiom of choice is needed to construct a non-measurable set (Solovay, 1970).", "startOffset": 85, "endOffset": 100}, {"referenceID": 16, "context": "Open fail-free Fun expressions have a straightforward semantics (Ramsey and Pfeffer, 2002) as computations in the probability monad (Giry, 1982).", "startOffset": 64, "endOffset": 90}, {"referenceID": 8, "context": "Open fail-free Fun expressions have a straightforward semantics (Ramsey and Pfeffer, 2002) as computations in the probability monad (Giry, 1982).", "startOffset": 132, "endOffset": 144}, {"referenceID": 10, "context": "In order to treat the fail primitive, we use an existing extension (Gordon et al., 2013) of the semantics of Ramsey and Pfeffer (2002) to a richer monad: the subprobability monad (Panangaden, 1999)3.", "startOffset": 67, "endOffset": 88}, {"referenceID": 15, "context": ", 2013) of the semantics of Ramsey and Pfeffer (2002) to a richer monad: the subprobability monad (Panangaden, 1999)3.", "startOffset": 98, "endOffset": 116}, {"referenceID": 8, "context": "Open fail-free Fun expressions have a straightforward semantics (Ramsey and Pfeffer, 2002) as computations in the probability monad (Giry, 1982). In order to treat the fail primitive, we use an existing extension (Gordon et al., 2013) of the semantics of Ramsey and Pfeffer (2002) to a richer monad: the subprobability monad (Panangaden, 1999)3.", "startOffset": 133, "endOffset": 281}, {"referenceID": 8, "context": "Open fail-free Fun expressions have a straightforward semantics (Ramsey and Pfeffer, 2002) as computations in the probability monad (Giry, 1982). In order to treat the fail primitive, we use an existing extension (Gordon et al., 2013) of the semantics of Ramsey and Pfeffer (2002) to a richer monad: the subprobability monad (Panangaden, 1999)3. Compared to the operations of the probability monad, the sub-probability monad additionally admits a zero constant, yielding the zero measure. To accommodate the zero measure, the carrier set is extended from probability measures to sub-probability measures, i.e., admitting all \u03bc with |\u03bc| \u2264 1. Below we recapitulate the semantics of Fun by Gordon et al. (2013). Here \u03c3 is a closed value substitution whose domain contains all the free variables of M, and detOp(M) ranges over op(M), fst M, snd M, inl M and inr M.", "startOffset": 133, "endOffset": 708}, {"referenceID": 1, "context": "Our compilation is based on that of Bhat et al. (2012), with modifications to treat fail statements, match (and general if) statements, pure (i.", "startOffset": 36, "endOffset": 55}, {"referenceID": 1, "context": "4Joint marginal densities for tuples of expressions can be computed if those expressions are conditionally independent (Bhat et al., 2012).", "startOffset": 119, "endOffset": 138}, {"referenceID": 0, "context": ", (PLUS RND) below), we instead use the matrix volume of the Jacobian matrix of the inverse operation (Ben-Israel, 1999).", "startOffset": 102, "endOffset": 120}, {"referenceID": 13, "context": "Species distribution (McInerny and Purves, 2011).", "startOffset": 21, "endOffset": 48}, {"referenceID": 19, "context": "(Smith et al., 2012).", "startOffset": 0, "endOffset": 20}, {"referenceID": 1, "context": "An abridged version of this paper appears as Bhat et al. (2013). The correctness proof (for a version of the source language without pure let and general match) was recently mechanized in Isabelle by Eberl et al.", "startOffset": 45, "endOffset": 64}, {"referenceID": 1, "context": "An abridged version of this paper appears as Bhat et al. (2013). The correctness proof (for a version of the source language without pure let and general match) was recently mechanized in Isabelle by Eberl et al. (2015). This paper builds on work by Bhat et al.", "startOffset": 45, "endOffset": 220}, {"referenceID": 1, "context": "An abridged version of this paper appears as Bhat et al. (2013). The correctness proof (for a version of the source language without pure let and general match) was recently mechanized in Isabelle by Eberl et al. (2015). This paper builds on work by Bhat et al. (2012) who develop a theoretical framework for computing PDFs, but describe no implementation nor correctness proof.", "startOffset": 45, "endOffset": 269}, {"referenceID": 1, "context": "An abridged version of this paper appears as Bhat et al. (2013). The correctness proof (for a version of the source language without pure let and general match) was recently mechanized in Isabelle by Eberl et al. (2015). This paper builds on work by Bhat et al. (2012) who develop a theoretical framework for computing PDFs, but describe no implementation nor correctness proof. The density compiler of Section 3 has a simpler presentation, with two judgments compared to five, and has rules for pure lets and operations on integers. Our paper also uses a richer language (Fun), which adds fail, match and general if (and for performance reasons, pure let). Gordon et al. (2013) describe a naive density calculation routine for Fun without random lets; this sublanguage does not cover many useful classes of models such as hierarchical and mixture models.", "startOffset": 45, "endOffset": 679}, {"referenceID": 7, "context": "The BUGS system computes densities from declaratively specified models to perform Gibbs sampling (Gilks et al., 1994).", "startOffset": 97, "endOffset": 117}, {"referenceID": 17, "context": "The AutoBayes system also computes densities for deriving maximum likelihood and Bayesian estimators for a significant class of statistical models (Schumann et al., 2008).", "startOffset": 147, "endOffset": 170}, {"referenceID": 11, "context": "Stan employs automatic differentiation (Griewank and Walther, 2008) of log posteriors in order to apply gradientbased Hamiltonian MCMC algorithms.", "startOffset": 39, "endOffset": 67}, {"referenceID": 21, "context": "Inference for the Church language also uses MCMC, but works with distributions over runs of a program instead of over its return value (Wingate et al., 2011), circumventing the need for a PDF.", "startOffset": 135, "endOffset": 157}, {"referenceID": 16, "context": "Several languages only provide support for finite, discrete distributions, but provide access to the probability mass function (Ramsey and Pfeffer, 2002; Kiselyov and Shan, 2009).", "startOffset": 127, "endOffset": 178}, {"referenceID": 12, "context": "Several languages only provide support for finite, discrete distributions, but provide access to the probability mass function (Ramsey and Pfeffer, 2002; Kiselyov and Shan, 2009).", "startOffset": 127, "endOffset": 178}, {"referenceID": 5, "context": "Probabilistic logic languages like Markov Logic (Domingos et al., 2008) do not have generative semantics but instead have semantics in undirected graphical models which are equipped with potential functions that are analogous to density functions.", "startOffset": 48, "endOffset": 71}], "year": 2017, "abstractText": "The probability density function of a probability distribution is a fundamental concept in probability theory and a key ingredient in various widely used machine learning methods. However, the necessary framework for compiling probabilistic functional programs to density functions has only recently been developed. In this work, we present a density compiler for a probabilistic language with failure and both discrete and continuous distributions, and provide a proof of its soundness. The compiler greatly reduces the development effort of domain experts, which we demonstrate by solving inference problems from various scientific applications, such as modelling the global carbon cycle, using a standard Markov chain Monte Carlo framework.", "creator": "LaTeX with hyperref package"}}}