{"id": "1704.00939", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Apr-2017", "title": "Fortia-FBK at SemEval-2017 Task 5: Bullish or Bearish? Inferring Sentiment towards Brands from Financial News Headlines", "abstract": "In this paper, we describe a methodology to infer Bullish or Bearish sentiment towards companies/brands. More specifically, our approach leverages affective lexica and word embeddings in combination with convolutional neural networks to infer the sentiment of financial news headlines towards a target company. Such architecture was used and evaluated in the context of the SemEval 2017 challenge (task 5, subtask 2), in which it obtained the best performance.", "histories": [["v1", "Tue, 4 Apr 2017 10:01:47 GMT  (52kb,D)", "http://arxiv.org/abs/1704.00939v1", "6 pages, 1 figure; accepted for publication at the International Workshop on Semantic Evaluation (SemEval-2017) to be held in conjunction with ACL 2017"]], "COMMENTS": "6 pages, 1 figure; accepted for publication at the International Workshop on Semantic Evaluation (SemEval-2017) to be held in conjunction with ACL 2017", "reviews": [], "SUBJECTS": "cs.CL cs.CY", "authors": ["youness mansar", "lorenzo gatti", "sira ferradans", "marco guerini", "jacopo staiano"], "accepted": false, "id": "1704.00939"}, "pdf": {"name": "1704.00939.pdf", "metadata": {"source": "CRF", "title": "Fortia-FBK at SemEval-2017 Task 5: Bullish or Bearish? Inferring Sentiment towards Brands from Financial News Headlines", "authors": ["Youness Mansar", "Lorenzo Gatti", "Sira Ferradans", "Marco Guerini", "Jacopo Staiano", "Bruno Kessler"], "emails": ["youness.mansar@fortia.fr", "sira.ferradans@fortia.fr", "jacopo.staiano@fortia.fr", "l.gatti@fbk.eu", "guerini@fbk.eu"], "sections": [{"heading": "1 Introduction", "text": "The explosive growth of the financial technology industry (fintech) continued in 2016, in part due to the current interest in the market for artificial intelligence-based technologies. In such a context, granular access to the opinions of an important section of the population can be crucial for any public and private actor in the financial sector (e.g. increase or fall in share value) or for the economy as a whole (e.g. the Greek sovereign debt crisis).In such a context, it is necessary to develop machine learning methods that make it possible to turn unstructured text into information that can be managed and exploited. 1F. Desai, \"The Age of Artificial Intelligence in Fintech\" http: / / www.forbes.com / sites / falgunidesai / 2016 / 06 / 30 / the-age-ofartificial-intelligence-in-fintechS Delventhal Word-Association, Global Fintech \"High-Fintech\" article of 2016:"}, {"heading": "2 Related Works", "text": "While image and sound are accompanied by a natural high-dimensional embedding, the topic of which is the best representation of a variety of different tasks is still an open research problem in the context of natural language and text. It goes beyond the scope of this paper to provide a thorough overview of word representations, for which we refer the reader to the excellent evaluation provided by (Mandelbaum and Shalev, 2016). Here we will present only the most important representations relating to the proposed methodology. Word embedding shows great progress in relation to n-grams. (Bengio et al., 2003), the authors present a statistical language model calculated in an unverified training context using flat neural networks. The aim was to predict the following word, given the previous context, which shows great progress in relation to n-grams. (Collobert et al., 2011) empirically superimposed use of a full neural network."}, {"heading": "3 Data", "text": "The data consists of a series of financial news headlines that have been searched by several online stores such as Yahoo Finance, where each sentence contains one or more company names / brands. Each tuple (headline, company) is commented with a sentiment score ranging from -1 (very negative, bearish) to 1 (very positive, bullish). The training / test kits offered contain 1142 and 491 commented sentences, respectively. A sample example is reported below: Headline: \"Morrisons book second quarter of sales growth\" Company name: \"Morrisons\" Sentiment Score: 0.43"}, {"heading": "4 Method", "text": "Figure 1 shows the overall architecture of our model."}, {"heading": "4.1 Sentence representation and preprocessing", "text": "In our approach, minimal pre-processing was chosen: we replaced the name of the target company with a fixed word < company > and numbers with < number >, and the sentences were then symbolized with spaces as separators and punctuation symbols as separate symbols.Sentence representation. since we cannot directly represent the words as fixed length vectors (provided in GloVe) resulting from the concatenation of the # PoS-based representation available in DepecheMood and DepecheMood (Staiano and Guerini, 2014), we converted the latter into token form, using exactly the same methodology, but with two differences: We started from a larger data set (51.9K news articles instead of 25.3K) and used a frequency interruption, i.e. the retention of only those symbols that occur least in the word representation, although with two differences: We set the word ADER in the first-VER representation (VER)."}, {"heading": "4.2 Architectural Details", "text": "The filters are used to learn useful translation-invariant representations of the sequential input data, and the activation function between layers is then applied via the sequence for each filter output.The activation function between layers is ReLU (Nair and Hinton, 2010) except for the output layer in which tanh is used to map the output to the global max pooling and output of VADER.Activation functions.The activation function used between layers is ReLU (Nair and Hinton, 2010) except for the output layer in which tanh is used to map the output to the [-1, 1] range. 2Our tests have shown that the larger datasets improve both the precision on the SemEval2007 Affective Text Task and Mihalcea, 2007) datasets originally used for evaluating DepecheMood."}, {"heading": "5 Results", "text": "In this section, we report on the results of our model according to the official challenge evaluation metric, based on cosine similarity, described in (Ghosh et al., 2015); the results are reported for three different configurations: (i) the complete system; (ii) the system without word embedding (i.e. Glove and DepecheMood); and (iii) the system without pre-processing. In Table 1, we show the performance of the model on the challenge training data in a 5x cross-validation setting. In addition, the final performance achieved with our approach to the challenge test group is presented in Table 2. In accordance with the cross-validation performance previously shown, we observe the beneficial effects of word representations and basic pre-processing."}, {"heading": "6 Conclusions", "text": "In this paper, we presented the network architecture used in the Fortia FBK template for the Semeval 2017 Task 5, Subtask 2 challenge to predict positive (bullish) or negative (bearish) attitudes toward a target marker based on financial news headlines. In this challenge, the proposed system ranked first. Our approach is based on 1d turns and uses fine-tuning of unguarded word representations and a rules-based mood model in its inputs. We demonstrated that the use of pre-calculated word representations enables to reduce overfits and achieve a much better generalization, while some basic pre-processing was needed to further improve performance."}], "references": [{"title": "SentiWordNet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining", "author": ["S. Baccianella", "A. Esuli", "F. Sebastiani"], "venue": "In Proceedings of LREC", "citeRegEx": "Baccianella et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Baccianella et al\\.", "year": 2010}, {"title": "A neural probabilistic language model", "author": ["Yoshua Bengio", "R\u00e9jean Ducharme", "Pascal Vincent", "Christian Jauvin."], "venue": "Journal of machine learning research 3(Feb):1137\u20131155.", "citeRegEx": "Bengio et al\\.,? 2003", "shortCiteRegEx": "Bengio et al\\.", "year": 2003}, {"title": "Affective norms for English words (ANEW): Instruction manual and affective ratings", "author": ["M.M. Bradley", "P.J. Lang."], "venue": "Technical Report C-1, University of Florida .", "citeRegEx": "Bradley and Lang.,? 1999", "shortCiteRegEx": "Bradley and Lang.", "year": 1999}, {"title": "Sentic computing", "author": ["Erik Cambria", "Amir Hussain."], "venue": "Springer.", "citeRegEx": "Cambria and Hussain.,? 2012", "shortCiteRegEx": "Cambria and Hussain.", "year": 2012}, {"title": "Natural language processing (almost) from scratch", "author": ["Ronan Collobert", "Jason Weston", "L\u00e9on Bottou", "Michael Karlen", "Koray Kavukcuoglu", "Pavel Kuksa."], "venue": "Journal of Machine Learning Research 12(Aug):2493\u20132537.", "citeRegEx": "Collobert et al\\.,? 2011", "shortCiteRegEx": "Collobert et al\\.", "year": 2011}, {"title": "SentiWordNet: A publicly available lexical resource for opinion mining", "author": ["A. Esuli", "F. Sebastiani."], "venue": "Proceedings of LREC 2006. Genova, IT, pages 417\u2013422.", "citeRegEx": "Esuli and Sebastiani.,? 2006", "shortCiteRegEx": "Esuli and Sebastiani.", "year": 2006}, {"title": "SentiWords: Deriving a high precision and high coverage lexicon for sentiment analysis", "author": ["Lorenzo Gatti", "Marco Guerini", "Marco Turchi."], "venue": "IEEE Transactions on Affective Computing 7(4):409\u2013421.", "citeRegEx": "Gatti et al\\.,? 2016", "shortCiteRegEx": "Gatti et al\\.", "year": 2016}, {"title": "Semeval-2015 task 11: Sentiment analysis of figurative language in twitter", "author": ["Aniruddha Ghosh", "Guofu Li", "Tony Veale", "Paolo Rosso", "Ekaterina Shutova", "John Barnden", "Antonio Reyes."], "venue": "Proceedings of the 9th International Workshop on Se-", "citeRegEx": "Ghosh et al\\.,? 2015", "shortCiteRegEx": "Ghosh et al\\.", "year": 2015}, {"title": "The volatility of the stock market and news", "author": ["Rohitha Goonatilake", "Susantha Herath."], "venue": "International Research Journal of Finance and Economics 3(11):53\u201365.", "citeRegEx": "Goonatilake and Herath.,? 2007", "shortCiteRegEx": "Goonatilake and Herath.", "year": 2007}, {"title": "Deep feelings: A massive cross-lingual study on the relation between emotions and virality", "author": ["Marco Guerini", "Jacopo Staiano."], "venue": "Proceedings of WWW 2015. pages 299\u2013305.", "citeRegEx": "Guerini and Staiano.,? 2015", "shortCiteRegEx": "Guerini and Staiano.", "year": 2015}, {"title": "Vader: A parsimonious rule-based model for sentiment analysis of social media text", "author": ["C.J. Hutto", "Eric Gilbert."], "venue": "Proceedings of ICWSM 2014.", "citeRegEx": "Hutto and Gilbert.,? 2014", "shortCiteRegEx": "Hutto and Gilbert.", "year": 2014}, {"title": "Convolutional neural networks for sentence classification", "author": ["Yoon Kim."], "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, EMNLP 2014. pages 1746\u20131751.", "citeRegEx": "Kim.,? 2014", "shortCiteRegEx": "Kim.", "year": 2014}, {"title": "Adam: A method for stochastic optimization", "author": ["Diederik P. Kingma", "Jimmy Ba."], "venue": "CoRR abs/1412.6980. http://arxiv.org/abs/1412.6980.", "citeRegEx": "Kingma and Ba.,? 2014", "shortCiteRegEx": "Kingma and Ba.", "year": 2014}, {"title": "Word embeddings and their use in sentence classification tasks", "author": ["Amit Mandelbaum", "Adi Shalev."], "venue": "arXiv preprint arXiv:1610.08229 .", "citeRegEx": "Mandelbaum and Shalev.,? 2016", "shortCiteRegEx": "Mandelbaum and Shalev.", "year": 2016}, {"title": "Efficient estimation of word representations in vector space", "author": ["Tomas Mikolov", "Kai Chen", "Greg Corrado", "Jeffrey Dean."], "venue": "arXiv preprint arXiv:1301.3781 .", "citeRegEx": "Mikolov et al\\.,? 2013", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Crowdsourcing a word\u2013emotion association lexicon", "author": ["Saif M Mohammad", "Peter D Turney."], "venue": "Computational Intelligence 29(3):436\u2013465.", "citeRegEx": "Mohammad and Turney.,? 2013", "shortCiteRegEx": "Mohammad and Turney.", "year": 2013}, {"title": "Rectified linear units improve restricted Boltzmann machines", "author": ["Vinod Nair", "Geoffrey E. Hinton"], "venue": null, "citeRegEx": "Nair and Hinton.,? \\Q2010\\E", "shortCiteRegEx": "Nair and Hinton.", "year": 2010}, {"title": "Textual affect sensing for sociable and expressive online communication", "author": ["Alena Neviarouskaya", "Helmut Prendinger", "Mitsuru Ishizuka."], "venue": "Affective Computing and Intelligent Interaction, Springer Berlin Heidelberg, volume 4738, pages 218\u2013229.", "citeRegEx": "Neviarouskaya et al\\.,? 2007", "shortCiteRegEx": "Neviarouskaya et al\\.", "year": 2007}, {"title": "GloVe: Global vectors for word representation", "author": ["Jeffrey Pennington", "Richard Socher", "Christopher D Manning."], "venue": "Proceedings of EMNLP 2014. volume 14, pages 1532\u201343.", "citeRegEx": "Pennington et al\\.,? 2014", "shortCiteRegEx": "Pennington et al\\.", "year": 2014}, {"title": "Dropout: a simple way to prevent neural networks from overfitting", "author": ["Nitish Srivastava", "Geoffrey E Hinton", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan Salakhutdinov."], "venue": "Journal of Machine Learning Research 15(1):1929\u20131958.", "citeRegEx": "Srivastava et al\\.,? 2014", "shortCiteRegEx": "Srivastava et al\\.", "year": 2014}, {"title": "Depeche Mood: a lexicon for emotion analysis from crowd annotated news", "author": ["Jacopo Staiano", "Marco Guerini."], "venue": "Proceedings of ACL 2014. The Association for Computer Linguistics, volume 2, pages 427\u2013433.", "citeRegEx": "Staiano and Guerini.,? 2014", "shortCiteRegEx": "Staiano and Guerini.", "year": 2014}, {"title": "The General Inquirer: A Computer Approach to Content Analysis", "author": ["P.J. Stone", "D.C. Dunphy", "M.S. Smith."], "venue": "MIT press.", "citeRegEx": "Stone et al\\.,? 1966", "shortCiteRegEx": "Stone et al\\.", "year": 1966}, {"title": "WordNetAffect: an affective extension of WordNet", "author": ["C. Strapparava", "A. Valitutti."], "venue": "Proceedings of LREC 2004. Lisbon, pages 1083 \u2013 1086.", "citeRegEx": "Strapparava and Valitutti.,? 2004", "shortCiteRegEx": "Strapparava and Valitutti.", "year": 2004}, {"title": "Semeval2007 task 14: Affective text", "author": ["Carlo Strapparava", "Rada Mihalcea."], "venue": "Proceedings of the 4th International Workshop on Semantic Evaluations. Association for Computational Linguistics, pages 70\u201374.", "citeRegEx": "Strapparava and Mihalcea.,? 2007", "shortCiteRegEx": "Strapparava and Mihalcea.", "year": 2007}, {"title": "Affect analysis of text using fuzzy semantic typing", "author": ["Pero Subasic", "Alison Huettner."], "venue": "Fuzzy Systems, IEEE Transactions on 9(4):483\u2013496.", "citeRegEx": "Subasic and Huettner.,? 2001", "shortCiteRegEx": "Subasic and Huettner.", "year": 2001}, {"title": "Lexicon-based methods for sentiment analysis", "author": ["M. Taboada", "J. Brooke", "M. Tofiloski", "K. Voll", "M. Stede."], "venue": "Computational linguistics 37(2):267\u2013307.", "citeRegEx": "Taboada et al\\.,? 2011", "shortCiteRegEx": "Taboada et al\\.", "year": 2011}, {"title": "Norms of valence, arousal, and dominance for 13,915 English lemmas", "author": ["Amy Beth Warriner", "Victor Kuperman", "Marc Brysbaert."], "venue": "Behavior research methods 45(4):1191\u20131207.", "citeRegEx": "Warriner et al\\.,? 2013", "shortCiteRegEx": "Warriner et al\\.", "year": 2013}, {"title": "Recognizing contextual polarity in phrase-level sentiment analysis", "author": ["T. Wilson", "J. Wiebe", "P. Hoffmann."], "venue": "Proceedings of the conference on HLT/EMNLP 2005. Vancouver, Canada.", "citeRegEx": "Wilson et al\\.,? 2005", "shortCiteRegEx": "Wilson et al\\.", "year": 2005}], "referenceMentions": [{"referenceID": 8, "context": "Previous research (Goonatilake and Herath, 2007) has highlighted the association between news items and market fluctiations; hence, in the financial domain, sentiment analysis can be used as a proxy for bullish (i.", "startOffset": 18, "endOffset": 48}, {"referenceID": 13, "context": "It is beyond the scope of this paper to do a thorough overview of word representations, for this we refer the interest reader to the excellent review provided by (Mandelbaum and Shalev, 2016).", "startOffset": 162, "endOffset": 191}, {"referenceID": 1, "context": "In the seminal paper (Bengio et al., 2003), the authors introduce a statistical language model computed in an unsupervised training context using shallow neural networks.", "startOffset": 21, "endOffset": 42}, {"referenceID": 4, "context": "(Collobert et al., 2011) empirically proved ar X iv :1 70 4.", "startOffset": 0, "endOffset": 24}, {"referenceID": 14, "context": "(Mikolov et al., 2013) proposed a simplified model (word2vec) that allows to train on larger corpora, and showed how semantic relationships emerge from this training.", "startOffset": 0, "endOffset": 22}, {"referenceID": 18, "context": "(Pennington et al., 2014), with the GloVe approach, maintain the semantic capacity of word2vec while introducing the statistical information from latent semantic analysis (LSA) showing that they can improve in semantic and syntactic tasks.", "startOffset": 0, "endOffset": 25}, {"referenceID": 5, "context": "For instance, regarding sentiment lexica, SentiWordNet (Esuli and Sebastiani, 2006), (Baccianella et al.", "startOffset": 55, "endOffset": 83}, {"referenceID": 0, "context": "For instance, regarding sentiment lexica, SentiWordNet (Esuli and Sebastiani, 2006), (Baccianella et al., 2010), associates each entry with the numerical scores, ranging from 0 (negative) to 1 (positive); following this approach, it has been possible to automatically obtain a list of 155k words, compensating a low precision with a high coverage (Gatti et al.", "startOffset": 85, "endOffset": 111}, {"referenceID": 6, "context": ", 2010), associates each entry with the numerical scores, ranging from 0 (negative) to 1 (positive); following this approach, it has been possible to automatically obtain a list of 155k words, compensating a low precision with a high coverage (Gatti et al., 2016).", "startOffset": 243, "endOffset": 263}, {"referenceID": 2, "context": "On the other side of the spectrum, we have methods such as (Bradley and Lang, 1999), (Taboada et al.", "startOffset": 59, "endOffset": 83}, {"referenceID": 25, "context": "On the other side of the spectrum, we have methods such as (Bradley and Lang, 1999), (Taboada et al., 2011), (Warriner et al.", "startOffset": 85, "endOffset": 107}, {"referenceID": 26, "context": ", 2011), (Warriner et al., 2013) with low coverage (from 1k to 14k words), but for which the precision is maximized.", "startOffset": 9, "endOffset": 32}, {"referenceID": 25, "context": "These scores were manually assigned by multiple annotators, and in some cases validated by crowdsourcing (Taboada et al., 2011).", "startOffset": 105, "endOffset": 127}, {"referenceID": 21, "context": "Finally, a binary sentiment score is provided in the General Inquirer lexicon (Stone et al., 1966), covering 4k sentiment-bearing words, and expanded to 6k words by (Wilson et al.", "startOffset": 78, "endOffset": 98}, {"referenceID": 27, "context": ", 1966), covering 4k sentiment-bearing words, and expanded to 6k words by (Wilson et al., 2005).", "startOffset": 74, "endOffset": 95}, {"referenceID": 22, "context": "Turning to affective lexica, where multiple dimensions of affect are taken into account, we mention WordNetAffect (Strapparava and Valitutti, 2004), which provides manual affective annotations of WordNet synsets (ANGER, JOY, FEAR, etc.", "startOffset": 114, "endOffset": 147}, {"referenceID": 3, "context": "AffectNet (Cambria and Hussain, 2012), contains 10k words taken from ConceptNet and aligned with WordNetAffect, and extends the latter to concepts like \u2018have breakfast\u2019.", "startOffset": 10, "endOffset": 37}, {"referenceID": 24, "context": "Fuzzy Affect Lexicon (Subasic and Huettner, 2001) contains roughly 4k lemma#PoS manually annotated by one linguist using 80 emotion labels.", "startOffset": 21, "endOffset": 49}, {"referenceID": 15, "context": "EmoLex (Mohammad and Turney, 2013) contains almost 10k lemmas annotated with an intensity label for each emotion using Mechanical Turk.", "startOffset": 7, "endOffset": 34}, {"referenceID": 17, "context": "Finally, Affect database is an extension of SentiFul (Neviarouskaya et al., 2007) and contains 2.", "startOffset": 53, "endOffset": 81}, {"referenceID": 20, "context": "In this work, we exploit the DepecheMood affective lexicon proposed by (Staiano and Guerini, 2014): this resource has been built in a completely unsupervised fashion, from affective scores assigned by readers to news articles; notably, due to its automated crowd-sourcing-based approach, DepecheMood allows for both high-coverage and high-precision.", "startOffset": 71, "endOffset": 98}, {"referenceID": 20, "context": "We refer the reader to (Staiano and Guerini, 2014; Guerini and Staiano, 2015) for more details.", "startOffset": 23, "endOffset": 77}, {"referenceID": 9, "context": "We refer the reader to (Staiano and Guerini, 2014; Guerini and Staiano, 2015) for more details.", "startOffset": 23, "endOffset": 77}, {"referenceID": 4, "context": "A modification of (Collobert et al., 2011) was proposed by Kim (Kim, 2014) for sentence classification, showing how a simple model together with pre-trained word representations can be highly performing.", "startOffset": 18, "endOffset": 42}, {"referenceID": 11, "context": ", 2011) was proposed by Kim (Kim, 2014) for sentence classification, showing how a simple model together with pre-trained word representations can be highly performing.", "startOffset": 28, "endOffset": 39}, {"referenceID": 10, "context": "Further, we took advantage of the rule-based sentiment analyser VADER (Hutto and Gilbert, 2014) (for Valence Aware Dictionary for sEntiment Reasoning), which builds upon a sentiment lexicon and a predefined set of simple rules.", "startOffset": 70, "endOffset": 95}, {"referenceID": 20, "context": "The words are represented as fixed length vectors ui resulting from the concatenation of GloVe pre-trained embeddings and DepecheMood (Staiano and Guerini, 2014) lexicon representation.", "startOffset": 134, "endOffset": 161}, {"referenceID": 16, "context": "The activation function used between layers is ReLU (Nair and Hinton, 2010) except for the out layer where tanh is used to map the output into [-1, 1] range.", "startOffset": 52, "endOffset": 75}, {"referenceID": 23, "context": "Our tests showed that: (i) the larger dataset allowed improving both precision on the SemEval2007 Affective Text Task (Strapparava and Mihalcea, 2007) dataset, originally used for the evaluation of DepecheMood, and coverage (from the initial 183K unique tokens we went to 292K entries) of the lexicon; (ii) we found no significant difference in performance between lemma#PoS and token versions built starting from the same dataset.", "startOffset": 118, "endOffset": 150}, {"referenceID": 19, "context": "Dropout (Srivastava et al., 2014) was used to avoid over-fitting to the training data: it prevents the co-adaptation of the neurones and it also provides an inexpensive way to average an exponential number of networks.", "startOffset": 8, "endOffset": 33}, {"referenceID": 12, "context": "Even though stochastic optimization methods like Adam (Kingma and Ba, 2014) are usually applied to loss functions that are written as a sum of persample loss, which is not the case for the cosine, it converges to an acceptable solution.", "startOffset": 54, "endOffset": 75}, {"referenceID": 7, "context": "In this section, we report the results obtained by our model according to challenge official evaluation metric, which is based cosine-similarity and described in (Ghosh et al., 2015).", "startOffset": 162, "endOffset": 182}], "year": 2017, "abstractText": "In this paper, we describe a methodology to infer Bullish or Bearish sentiment towards companies/brands. More specifically, our approach leverages affective lexica and word embeddings in combination with convolutional neural networks to infer the sentiment of financial news headlines towards a target company. Such architecture was used and evaluated in the context of the SemEval 2017 challenge (task 5, subtask 2), in which it obtained the best performance.", "creator": "LaTeX with hyperref package"}}}