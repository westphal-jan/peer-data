{"id": "1704.01344", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Apr-2017", "title": "Not All Pixels Are Equal: Difficulty-aware Semantic Segmentation via Deep Layer Cascade", "abstract": "We propose a novel deep layer cascade (LC) method to improve the accuracy and speed of semantic segmentation. Unlike the conventional model cascade (MC) that is composed of multiple independent models, LC treats a single deep model as a cascade of several sub-models. Earlier sub-models are trained to handle easy and confident regions, and they progressively feed-forward harder regions to the next sub-model for processing. Convolutions are only calculated on these regions to reduce computations. The proposed method possesses several advantages. First, LC classifies most of the easy regions in the shallow stage and makes deeper stage focuses on a few hard regions. Such an adaptive and 'difficulty-aware' learning improves segmentation performance. Second, LC accelerates both training and testing of deep network thanks to early decisions in the shallow stage. Third, in comparison to MC, LC is an end-to-end trainable framework, allowing joint learning of all sub-models. We evaluate our method on PASCAL VOC and Cityscapes datasets, achieving state-of-the-art performance and fast speed.", "histories": [["v1", "Wed, 5 Apr 2017 09:58:51 GMT  (3280kb,D)", "http://arxiv.org/abs/1704.01344v1", "To appear in CVPR 2017 as a spotlight paper"]], "COMMENTS": "To appear in CVPR 2017 as a spotlight paper", "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["xiaoxiao li", "ziwei liu", "ping luo", "chen change loy", "xiaoou tang"], "accepted": false, "id": "1704.01344"}, "pdf": {"name": "1704.01344.pdf", "metadata": {"source": "CRF", "title": "Not All Pixels Are Equal: Difficulty-Aware Semantic Segmentation via Deep Layer Cascade", "authors": ["Xiaoxiao Li", "Ziwei Liu", "Ping Luo", "Chen Change Loy", "Xiaoou Tang"], "emails": ["lx015@ie.cuhk.edu.hk", "lz013@ie.cuhk.edu.hk", "pluo@ie.cuhk.edu.hk", "ccloy@ie.cuhk.edu.hk", "xtang@ie.cuhk.edu.hk"], "sections": [{"heading": "1. Introduction", "text": "This year it has come to the point that it has never come as far as this year."}, {"heading": "2. Related Work", "text": "While early efforts focused on structural models with handmade features, network architectures have been removed. [15, 16, 34, 38] Recent studies have used deep Convolutionary Neural Networks (CNN) to learn strong representation that significantly improves segmentation accuracy [3, 22, 23, 25, 40]. Thus, Long et al. [25] transformed fully interconnected layers of CNN into revolutionary layers, enabling precise per-pixel classification using the contemporary CNN architectures pre-schooled on ImageNet [7]. [3], Zheng et al. [40], and Liu et al. [22, 23] further demonstrated that the feedback and inference of Markov Random Field (MRF) can be integrated into CNN. Although these models achieve high accuracy, they generally have high compression costs and prevent them from being used in real time."}, {"heading": "3. Deep Layer Cascade (LC)", "text": "In paragraph 3.1, the example of Inception-ResNet-v2 [32] illustrates how to make LC from a deep model. It is easy to generalize the approach to the other deep networks. In paragraph 3.3, the LC training algorithm is introduced."}, {"heading": "3.1. Turning a Deep Model into LC", "text": "To illustrate the effectiveness of LC, we choose Inception-ResNet-v2, a system specific to the ImageNet dataset, as a strong baseline, referred to as IRNet, exceeding ResNet-101 by 1.2%. However, experiments show that LC is able to achieve a 1.7% improvement on this competitive basis. Figure 2 (a) illustrates the architecture of IRNet, which has six different components, including \"Stem,\" IRNetA / B / C, \"and\" Reduction-A / B. \"Different components have different configurations of layers, such as convolution, pooling, and concatenation layer. The right column of Fig. 2 shows the structures of\" Stem \"and\" IRNet-A / B / C, \"including layer-typical layer sizes, and the number of channels (in brackets)."}, {"heading": "3.2. Region Convolution", "text": "As shown above, levels 2 and -3 calculate only coils on those pixels propagated forward. Figure 3 (b) illustrates this regional folding (RC) compared to the traditional folding in (a), which is applied to an entire characteristic map. RC filters cover only one region of interest designated as M and ignore the other region, greatly reducing the calculations. The values of the other region are set directly as zeros. M can be implemented as a binary mask where the pixels within M are equal to one, otherwise zero. Specifically, (c) shows how to apply RC to a residual module that can be represented as h (I) = I + conv (I), in which feature h is achieved by an identity mapping [13] of I and a folding over I. We replace the conventional folding with an RC as introduced above, and feature h (I) is the elementary sum between the output of this feature I and that feature."}, {"heading": "3.3. Training IRNet-LC", "text": "The parameters of IRNet are initialized by pre-training in ImageNet. Since IRNet-LC has additional revolutionary layers stacked in front of each loss function, its parameters are initialized by sampling from a normal distribution. Given a number of images and their per-pixel label cards, IRNetLC is learned in two steps, the first aimed at initial training and the second at cascade training. Initial training. This step is comparable to deeply monitored network (DSN) [17], which has several identical loss functions in different layers of the network. Its objectivity is to prepare IRNet for the task of image segmentation by classifying a thousand image categories in ImageNet. It learns discriminatory and robust functions. In IRNet-LC, each step is trained to minimize a pixel-wise softmax loss function, reducing the discrepancies between the predicted label card and the basic map of the entire image."}, {"heading": "3.4. Relations with Previous Models", "text": "The relationships and differences between LC and MC were discussed in paragraph 1. LC also refers to Deeply Monitored Networks (DSN) [17] and Dropout [30]. DSN. Similar to DSN, LC adds supervision to each level. However, to enable adaptive processing of hard / simple regions, LC uses different supervisions for different levels. In contrast, the supervision used in each level of DSN remains the same. Specifically, the step-by-step supervision in LC is determined by the estimated difficulty of each pixel. In this way, each step in LC is able to focus on regions of similar difficulty. Dropout. LC combines with Dropout in the sense that both methods discard some regions in the characteristic maps, but are essentially different. LC drops those pixels with high reliability and propagates difficult pixels only at subsequent levels."}, {"heading": "4. Experiments", "text": "Settings. We evaluate our method using the PASCAL VOC 2012 (VOC12) [8] and Cityscapes [5] datasets. The VOC12 dataset is a general object segmentation benchmark with 21 classes. After previous work, we also use the additional annotations of [12], which contain 10,582 images for training, 1,449 images for validation, and 1,456 images for the test. However, the Cityscapes dataset focuses on segmentation of street scenes and contains 19 categories. In our experiments, we only use images with fine annotations at pixel level. There are 2975 training sessions, 500 validations, and 1,525 test images. This is consistent with existing studies [19, 4]."}, {"heading": "4.1. Ablation Study", "text": "In this section, we examine the effects of adjusting the probability threshold in LC and show the merits of LC by comparing it with other counterparts. All performance is reported at the validation level of VOC12. Therefore, probability thresholds are used at each level of LC to represent a pixel-by-pixel probability of the Softmax layer to represent the reliability of the prediction. By choosing an appropriate probability threshold, we can separate the individual regions, temperate regions and extremely hard regions for adaptive processing. As discussed in Sec. 3.1, how many simple and extremely hard pixels are discarded at each stage. Table 1 lists the percentage of processed pixels at level 1 & -2 and the overall performance as such is varied. If we degenerate to DSN, which is slightly better than fully revolutionary. If we lose weight, simpler regions are classified at early stages, while hard regions are progressively handled by later stages."}, {"heading": "4.2. Stage-wise Analysis", "text": "In this section, we show how LC allows adaptive processing for different classes and illustrates the regions treated by different regions. Stage by stage label distribution. First, we offer label distribution analysis over different levels. Here, we take the 20 classes (without \"background\") in VOC12 as an example. Fig. 5 (a) shows how the number of pixels changes with respect to each class in levels 2 and -3. For example, the upper histogram shows a ratio for each class that is achieved by dividing the number of pixels in level 2 by those in level 1. Ratios greater than one show that level 2 is more focused on the corresponding classes than level 1. We note that all ratios have increased and belong in the range of 1 to 1.4. It is because level 1 already handles the simple regions (i.e. \"background\") and the hard regions (i.e. \"foreground\") than level 3. \""}, {"heading": "4.3. Performance and Speed Analysis", "text": "To highlight the trade-off between performance and speed, the proposed LC model is compared with two representative state-of-the-art methods: DeepLab-v2 [4] and SegNet [1]. Performance is reported on VOC12 and summarized in Table 3. Runtime speed is measured on a single Titan X GPU. To ensure a fair comparison, we evaluate DeepLabv2 and SegNet without pre- and post-processing, e.g. training with additional data, multiple fusion or contingent random field smoothing (CRF). DeepLab-v2 achieves an acceptable performance of 70.42. Nevertheless, it uses an ultra-deep ResNet 101 model as a Thebackbone network, so its speed of inference is slow (7.1 FPS). On the other hand, SegNet is faster due to a smaller model size, but its accuracy is severely compromised."}, {"heading": "4.4. Benchmark", "text": "In this section, we show that LC can achieve state-of-the-art data sets based on standard benchmarks such as VOC12 [8] and Cityscapes [5]. Following [4], atomic spatial pyramid pools [4], three-scale tests, and dense CRF [16] are used. VOC12. Table 4 lists the per-class and total mean IoU based on VOC12. Approaches prepared for COCO [20] are marked \u2020. LC achieves an mIoU of 80.3 and improves the mIoU to 82.7 with training on COCO, which is the most powerful method based on VOC12. Upon closer inspection, we find that LC wins 16 of 20 foreground classes. LC also achieves competitive performance for other 4 classes."}, {"heading": "4.5. More Comparisons between IRNet-LC and", "text": "In Table 6 we compare the settings of various best performing methods on the VOC12 [8] test set, including CRFRNN [40], DPN [22] and DeepLab-v2 [4]. These methods are summarized in terms such as \"backbone network,\" \"number of parameters,\" \"pre-trained using MS COCO,\" \"multi-scale training / test,\" \"MRF / CRF,\" \"frame per second (FPS)\" and \"mIOU.\" Note that \"-\" the relevant information was not disclosed in previous papers. IRNet-LC uses Inception-ResNet-v2 (IRNet) [32] as a backbone network smaller than ResNet-101 (35.5M vs. 44.5M). Following DeepLab-v2 [4], spatial pyramid pooling is applied in IRNet-LC."}, {"heading": "4.6. Visual Quality Comparison", "text": "Figure 8 illustrates the comparisons of LC with DPN [22] and DeepLab-v2 [4]. We use the publicly published model to regenerate label maps of DeepLab-v2, while the results of DPN are downloaded from their project page. LC generally makes more accurate predictions. Further examples of LC label maps on Cityscapes dataset [5] are included in Figure 9."}, {"heading": "5. Conclusion", "text": "The Deep Layer Cascade (LC) is proposed in this paper to simultaneously improve the accuracy and speed of semantic image segmentation. It has three advantages over earlier approaches. First, LC applies a \"difficulty-conscious\" learning paradigm, where earlier phases are trained to handle simple and confident regions, and hard regions are progressively passed on to later phases. Second, since each phase processes only a portion of the input, LC can accelerate both training and testing by using regional convolution. Third, LC is a consistent traceable framework that collectively optimizes feature learning for different regions, achieving state-of-the-art performance on both PASCAL VOC and Cityscapes datasets. LC is able to run in real time, but still achieve competitive accuracies."}], "references": [{"title": "Segnet: A deep convolutional encoder-decoder architecture for image segmentation", "author": ["V. Badrinarayanan", "A. Kendall", "R. Cipolla"], "venue": "arXiv preprint arXiv:1511.00561", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning complexity-aware cascades for deep pedestrian detection", "author": ["Z. Cai", "M. Saberian", "N. Vasconcelos"], "venue": "ICCV, pages 3361\u20133369", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2015}, {"title": "Semantic image segmentation with deep convolutional nets and fully connected crfs", "author": ["L.-C. Chen", "G. Papandreou", "I. Kokkinos", "K. Murphy", "A.L. Yuille"], "venue": "ICLR", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}, {"title": "Deeplab: Semantic image segmentation with deep convolutional nets", "author": ["L.-C. Chen", "G. Papandreou", "I. Kokkinos", "K. Murphy", "A.L. Yuille"], "venue": "atrous convolution, and fully connected crfs. arXiv:1606.00915", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2016}, {"title": "The cityscapes dataset for semantic urban scene understanding", "author": ["M. Cordts", "M. Omran", "S. Ramos", "T. Rehfeld", "M. Enzweiler", "R. Benenson", "U. Franke", "S. Roth", "B. Schiele"], "venue": "CVPR", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2016}, {"title": "Boxsup: Exploiting bounding boxes to supervise convolutional networks for semantic segmentation", "author": ["J. Dai", "K. He", "J. Sun"], "venue": "arXiv:1503.01640v2", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "Imagenet: A large-scale hierarchical image database", "author": ["J. Deng", "W. Dong", "R. Socher", "L.-J. Li", "K. Li", "L. Fei- Fei"], "venue": "CVPR, pages 248\u2013255", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2009}, {"title": "The pascal visual object classes (voc) challenge", "author": ["M. Everingham", "L. Van Gool", "C.K. Williams", "J. Winn", "A. Zisserman"], "venue": "IJCV, 88(2):303\u2013338", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2010}, {"title": "Learning hierarchical features for scene labeling", "author": ["C. Farabet", "C. Couprie", "L. Najman", "Y. LeCun"], "venue": "PAMI, 35(8):1915\u2013 1929", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2013}, {"title": "Are we ready for autonomous driving? the kitti vision benchmark suite", "author": ["A. Geiger", "P. Lenz", "R. Urtasun"], "venue": "CVPR, pages 3354\u20133361", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}, {"title": "Rich feature hierarchies for accurate object detection and semantic segmentation", "author": ["R. Girshick", "J. Donahue", "T. Darrell", "J. Malik"], "venue": "CVPR, pages 580\u2013587", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2014}, {"title": "Semantic contours from inverse detectors", "author": ["B. Hariharan", "P. Arbel\u00e1ez", "L. Bourdev", "S. Maji", "J. Malik"], "venue": "ICCV, pages 991\u2013998", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2011}, {"title": "Deep residual learning for image recognition", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "arXiv preprint arXiv:1512.03385", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2015}, {"title": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "author": ["S. Ioffe", "C. Szegedy"], "venue": "arXiv preprint arXiv:1502.03167", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2015}, {"title": "Augmenting crfs with boltzmann machine shape priors for image labeling", "author": ["A. Kae", "K. Sohn", "H. Lee", "E. Learned-Miller"], "venue": "CVPR, pages 2019\u20132026", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2013}, {"title": "Efficient inference in fully connected crfs with gaussian edge potentials", "author": ["P. Kr\u00e4henb\u00fchl", "V. Koltun"], "venue": "NIPS", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2011}, {"title": "Deeplysupervised nets", "author": ["C.-Y. Lee", "S. Xie", "P. Gallagher", "Z. Zhang", "Z. Tu"], "venue": "AISTATS, volume 2, page 6", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2015}, {"title": "A convolutional neural network cascade for face detection", "author": ["H. Li", "Z. Lin", "X. Shen", "J. Brandt", "G. Hua"], "venue": "CVPR, pages 5325\u20135334", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2015}, {"title": "Efficient piecewise training of deep structured models for semantic segmentation", "author": ["G. Lin", "C. Shen", "I. Reid", "A. Hengel"], "venue": "arXiv:1504.01013v2,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2015}, {"title": "Microsoft coco: Common objects in context", "author": ["T.-Y. Lin", "M. Maire", "S. Belongie", "J. Hays", "P. Perona", "D. Ramanan", "P. Doll\u00e1r", "C.L. Zitnick"], "venue": "In ECCV,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2014}, {"title": "Learning dynamic hierarchical models for anytime scene labeling", "author": ["B. Liu", "X. He"], "venue": "ECCV, pages 650\u2013666. Springer", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2016}, {"title": "Semantic image segmentation via deep parsing network", "author": ["Z. Liu", "X. Li", "P. Luo", "C.-C. Loy", "X. Tang"], "venue": "ICCV, pages 1377\u20131385", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep learning markov random field for semantic segmentation", "author": ["Z. Liu", "X. Li", "P. Luo", "C.C. Loy", "X. Tang"], "venue": "arXiv preprint arXiv:1606.07230", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2016}, {"title": "Fashion landmark detection in the wild", "author": ["Z. Liu", "S. Yan", "P. Luo", "X. Wang", "X. Tang"], "venue": "ECCV, pages 229\u2013245", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2016}, {"title": "Fully convolutional networks for semantic segmentation", "author": ["J. Long", "E. Shelhamer", "T. Darrell"], "venue": "CVPR, pages 3431\u2013 3440", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep decision network for multi-class image classification", "author": ["V.N. Murthy", "V. Singh", "T. Chen", "R. Manmatha", "D. Comaniciu"], "venue": "CVPR", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2016}, {"title": "Enet: A deep neural network architecture for real-time semantic segmentation", "author": ["A. Paszke", "A. Chaurasia", "S. Kim", "E. Culurciello"], "venue": "arXiv preprint arXiv:1606.02147", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2016}, {"title": "Training regionbased object detectors with online hard example mining", "author": ["A. Shrivastava", "A. Gupta", "R. Girshick"], "venue": "CVPR, pages 761\u2013769", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2016}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["K. Simonyan", "A. Zisserman"], "venue": "ICLR", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2015}, {"title": "Dropout: a simple way to prevent neural  (a) input image (b) ground truth (c) LC Figure 9: Visual quality of LC label maps: (a) input image (b) ground truth (white labels indicating ambiguous regions) and (c) LC", "author": ["N. Srivastava", "G.E. Hinton", "A. Krizhevsky", "I. Sutskever", "R. Salakhutdinov"], "venue": "networks from overfitting. JMLR, 15(1):1929\u20131958", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2014}, {"title": "Deep convolutional network cascade for facial point detection", "author": ["Y. Sun", "X. Wang", "X. Tang"], "venue": "CVPR, pages 3476\u2013 3483", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2013}, {"title": "Inception-v4", "author": ["C. Szegedy", "S. Ioffe", "V. Vanhoucke"], "venue": "inception-resnet and the impact of residual connections on learning. arXiv preprint arXiv:1602.07261", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2016}, {"title": "Deeppose: Human pose estimation via deep neural networks", "author": ["A. Toshev", "C. Szegedy"], "venue": "CVPR, pages 1653\u20131660", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2014}, {"title": "Filter-based meanfield inference for random fields with higher-order terms and product label-spaces", "author": ["V. Vineet", "J. Warrell", "P.H. Torr"], "venue": "In ECCV,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2012}, {"title": "Rapid object detection using a boosted cascade of simple features", "author": ["P. Viola", "M. Jones"], "venue": "CVPR, pages I\u2013511", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2001}, {"title": "Temporal segment networks: Towards good practices for deep action recognition", "author": ["L. Wang", "Y. Xiong", "Z. Wang", "Y. Qiao", "D. Lin", "X. Tang", "L. Val Gool"], "venue": "ECCV", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2016}, {"title": "and A", "author": ["Z. Wu", "C. Shen"], "venue": "v. d. Hengel. High-performance semantic segmentation using very deep fully convolutional networks. arXiv preprint arXiv:1604.04339", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2016}, {"title": "Context driven scene parsing with attention to rare classes", "author": ["J. Yang", "B. Price", "S. Cohen", "M.-H. Yang"], "venue": "CVPR, pages 3294\u20133301", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2014}, {"title": "Multi-scale context aggregation by dilated convolutions", "author": ["F. Yu", "V. Koltun"], "venue": "arXiv preprint arXiv:1511.07122", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2015}, {"title": "Conditional random fields as recurrent neural networks. arXiv:1502.03240v2", "author": ["S. Zheng", "S. Jayasumana", "B. Romera-Paredes", "V. Vineet", "Z. Su", "D. Du", "C. Huang", "P. Torr"], "venue": null, "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2015}], "referenceMentions": [{"referenceID": 8, "context": "Semantic image segmentation enjoys wide applications, such as video surveillance [9, 36] and autonomous driving [10, 5].", "startOffset": 81, "endOffset": 88}, {"referenceID": 35, "context": "Semantic image segmentation enjoys wide applications, such as video surveillance [9, 36] and autonomous driving [10, 5].", "startOffset": 81, "endOffset": 88}, {"referenceID": 9, "context": "Semantic image segmentation enjoys wide applications, such as video surveillance [9, 36] and autonomous driving [10, 5].", "startOffset": 112, "endOffset": 119}, {"referenceID": 4, "context": "Semantic image segmentation enjoys wide applications, such as video surveillance [9, 36] and autonomous driving [10, 5].", "startOffset": 112, "endOffset": 119}, {"referenceID": 12, "context": "Recent advanced deep architectures, such as the residual network (ResNet) [13] and Inception [32], significantly improve the accuracy of image segmentation by increasing the depth and number of parameters in deep models.", "startOffset": 74, "endOffset": 78}, {"referenceID": 31, "context": "Recent advanced deep architectures, such as the residual network (ResNet) [13] and Inception [32], significantly improve the accuracy of image segmentation by increasing the depth and number of parameters in deep models.", "startOffset": 93, "endOffset": 97}, {"referenceID": 28, "context": "For example, ResNet-101 is six times deeper than VGG-16 [29] network, with the former outperforms the latter by 4 percent on the challenging PASCAL VOC 2012 image segmentation benchmark [8].", "startOffset": 56, "endOffset": 60}, {"referenceID": 7, "context": "For example, ResNet-101 is six times deeper than VGG-16 [29] network, with the former outperforms the latter by 4 percent on the challenging PASCAL VOC 2012 image segmentation benchmark [8].", "startOffset": 186, "endOffset": 189}, {"referenceID": 17, "context": "Layer Cascade inherits the advantage of the conventional model cascade (MC) [18, 35], which has multiple stages and usually trains one classifier in each stage.", "startOffset": 76, "endOffset": 84}, {"referenceID": 34, "context": "Layer Cascade inherits the advantage of the conventional model cascade (MC) [18, 35], which has multiple stages and usually trains one classifier in each stage.", "startOffset": 76, "endOffset": 84}, {"referenceID": 31, "context": "After applying LC on Inception-ResNet-v2 (IRNet) [32], its speed and accuracy are improved by 42.", "startOffset": 49, "endOffset": 53}, {"referenceID": 16, "context": "(3) Connections between LC and previous models such as model cascade, deeply supervised network [17], and dropout [30] are clearly presented.", "startOffset": 96, "endOffset": 100}, {"referenceID": 29, "context": "(3) Connections between LC and previous models such as model cascade, deeply supervised network [17], and dropout [30] are clearly presented.", "startOffset": 114, "endOffset": 118}, {"referenceID": 14, "context": "While early efforts focused on structural models with handcrafted features [15, 16, 34, 38], recent studies employ deep convolutional neural network (CNN) to learning strong representation, which improves segmentation accuracy significantly [3, 22, 23, 25, 40].", "startOffset": 75, "endOffset": 91}, {"referenceID": 15, "context": "While early efforts focused on structural models with handcrafted features [15, 16, 34, 38], recent studies employ deep convolutional neural network (CNN) to learning strong representation, which improves segmentation accuracy significantly [3, 22, 23, 25, 40].", "startOffset": 75, "endOffset": 91}, {"referenceID": 33, "context": "While early efforts focused on structural models with handcrafted features [15, 16, 34, 38], recent studies employ deep convolutional neural network (CNN) to learning strong representation, which improves segmentation accuracy significantly [3, 22, 23, 25, 40].", "startOffset": 75, "endOffset": 91}, {"referenceID": 37, "context": "While early efforts focused on structural models with handcrafted features [15, 16, 34, 38], recent studies employ deep convolutional neural network (CNN) to learning strong representation, which improves segmentation accuracy significantly [3, 22, 23, 25, 40].", "startOffset": 75, "endOffset": 91}, {"referenceID": 2, "context": "While early efforts focused on structural models with handcrafted features [15, 16, 34, 38], recent studies employ deep convolutional neural network (CNN) to learning strong representation, which improves segmentation accuracy significantly [3, 22, 23, 25, 40].", "startOffset": 241, "endOffset": 260}, {"referenceID": 21, "context": "While early efforts focused on structural models with handcrafted features [15, 16, 34, 38], recent studies employ deep convolutional neural network (CNN) to learning strong representation, which improves segmentation accuracy significantly [3, 22, 23, 25, 40].", "startOffset": 241, "endOffset": 260}, {"referenceID": 22, "context": "While early efforts focused on structural models with handcrafted features [15, 16, 34, 38], recent studies employ deep convolutional neural network (CNN) to learning strong representation, which improves segmentation accuracy significantly [3, 22, 23, 25, 40].", "startOffset": 241, "endOffset": 260}, {"referenceID": 24, "context": "While early efforts focused on structural models with handcrafted features [15, 16, 34, 38], recent studies employ deep convolutional neural network (CNN) to learning strong representation, which improves segmentation accuracy significantly [3, 22, 23, 25, 40].", "startOffset": 241, "endOffset": 260}, {"referenceID": 39, "context": "While early efforts focused on structural models with handcrafted features [15, 16, 34, 38], recent studies employ deep convolutional neural network (CNN) to learning strong representation, which improves segmentation accuracy significantly [3, 22, 23, 25, 40].", "startOffset": 241, "endOffset": 260}, {"referenceID": 24, "context": "[25] transformed fully-connected layers of CNN into convolutional layers, making accurate per-pixel classification possible using the contemporary CNN architectures that were pre-trained on ImageNet [7].", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "[25] transformed fully-connected layers of CNN into convolutional layers, making accurate per-pixel classification possible using the contemporary CNN architectures that were pre-trained on ImageNet [7].", "startOffset": 199, "endOffset": 202}, {"referenceID": 2, "context": "[3], Zheng et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 39, "context": "[40], and Liu et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "[22, 23] further showed that back-propagation and inference of Markov Random Field (MRF) can be incorporated into CNN.", "startOffset": 0, "endOffset": 8}, {"referenceID": 22, "context": "[22, 23] further showed that back-propagation and inference of Markov Random Field (MRF) can be incorporated into CNN.", "startOffset": 0, "endOffset": 8}, {"referenceID": 0, "context": "Another line of research [1, 21, 27] alleviates this problem by using lightweight network architectures.", "startOffset": 25, "endOffset": 36}, {"referenceID": 20, "context": "Another line of research [1, 21, 27] alleviates this problem by using lightweight network architectures.", "startOffset": 25, "endOffset": 36}, {"referenceID": 26, "context": "Another line of research [1, 21, 27] alleviates this problem by using lightweight network architectures.", "startOffset": 25, "endOffset": 36}, {"referenceID": 0, "context": "For example, SegNet [1] adopted a convolutional encoder-decoder and removed unnecessary layers to reduce the number of parameters.", "startOffset": 20, "endOffset": 23}, {"referenceID": 26, "context": "ENet [27] utilized a bottleneck module to reduce computation of convolutions.", "startOffset": 5, "endOffset": 9}, {"referenceID": 1, "context": "Network cascades [2, 18, 26, 33, 24] have been studied to improve the performance in classification [26], detection [18], and pose estimation [33].", "startOffset": 17, "endOffset": 36}, {"referenceID": 17, "context": "Network cascades [2, 18, 26, 33, 24] have been studied to improve the performance in classification [26], detection [18], and pose estimation [33].", "startOffset": 17, "endOffset": 36}, {"referenceID": 25, "context": "Network cascades [2, 18, 26, 33, 24] have been studied to improve the performance in classification [26], detection [18], and pose estimation [33].", "startOffset": 17, "endOffset": 36}, {"referenceID": 32, "context": "Network cascades [2, 18, 26, 33, 24] have been studied to improve the performance in classification [26], detection [18], and pose estimation [33].", "startOffset": 17, "endOffset": 36}, {"referenceID": 23, "context": "Network cascades [2, 18, 26, 33, 24] have been studied to improve the performance in classification [26], detection [18], and pose estimation [33].", "startOffset": 17, "endOffset": 36}, {"referenceID": 25, "context": "Network cascades [2, 18, 26, 33, 24] have been studied to improve the performance in classification [26], detection [18], and pose estimation [33].", "startOffset": 100, "endOffset": 104}, {"referenceID": 17, "context": "Network cascades [2, 18, 26, 33, 24] have been studied to improve the performance in classification [26], detection [18], and pose estimation [33].", "startOffset": 116, "endOffset": 120}, {"referenceID": 32, "context": "Network cascades [2, 18, 26, 33, 24] have been studied to improve the performance in classification [26], detection [18], and pose estimation [33].", "startOffset": 142, "endOffset": 146}, {"referenceID": 25, "context": "For example, Deep Decision Network [26] improved the image classification performance by dividing easy data from the", "startOffset": 35, "endOffset": 39}, {"referenceID": 17, "context": "[18] used CNN cascade for face detection, which rejects false detections quickly in early stages and carefully refines detections in later stages.", "startOffset": 0, "endOffset": 4}, {"referenceID": 32, "context": "DeepPose [33] employed a divide-and-conquer strategy and designed a cascaded deep regression framework for human pose estimation.", "startOffset": 9, "endOffset": 13}, {"referenceID": 31, "context": "1 takes Inception-ResNet-v2 [32] as an example to illustrate how one could turn a deep model into LC.", "startOffset": 28, "endOffset": 32}, {"referenceID": 31, "context": "Similar network structure as IRNet has achieved great success in image recognition [32].", "startOffset": 83, "endOffset": 87}, {"referenceID": 2, "context": "We also replace convolutions in \u2018IRNet-B/C\u2019 by the dilated convolutions similar to [3].", "startOffset": 83, "endOffset": 86}, {"referenceID": 13, "context": "8), making the batch normalization (BN) layers [14] unstable (as which need to estimate sample mean and variance from the data in a mini-batch).", "startOffset": 47, "endOffset": 51}, {"referenceID": 17, "context": "The number of stages is three, which is a common setting in previous cascade methods [18, 31, 33].", "startOffset": 85, "endOffset": 97}, {"referenceID": 30, "context": "The number of stages is three, which is a common setting in previous cascade methods [18, 31, 33].", "startOffset": 85, "endOffset": 97}, {"referenceID": 32, "context": "The number of stages is three, which is a common setting in previous cascade methods [18, 31, 33].", "startOffset": 85, "endOffset": 97}, {"referenceID": 12, "context": "Specifically, (c) shows how to apply RC on a residual module, which can be represented as h(I) = I + conv(I), where feature h is attained by an identity mapping [13] of I and a convolution over I .", "startOffset": 161, "endOffset": 165}, {"referenceID": 16, "context": "This step is similar to deeply supervised network (DSN) [17], which has multiple identical loss functions in different layers of the network.", "startOffset": 56, "endOffset": 60}, {"referenceID": 16, "context": "LC also relates to deeply supervised nets (DSN) [17] and dropout [30].", "startOffset": 48, "endOffset": 52}, {"referenceID": 29, "context": "LC also relates to deeply supervised nets (DSN) [17] and dropout [30].", "startOffset": 65, "endOffset": 69}, {"referenceID": 7, "context": "We evaluate our method on the PASCAL VOC 2012 (VOC12) [8] and Cityscapes [5] datasets.", "startOffset": 54, "endOffset": 57}, {"referenceID": 4, "context": "We evaluate our method on the PASCAL VOC 2012 (VOC12) [8] and Cityscapes [5] datasets.", "startOffset": 73, "endOffset": 76}, {"referenceID": 11, "context": "Following previous works, we also use the extra annotations provided by [12], which contains 10, 582 images for training, 1, 449 images for validation, and 1, 456 images for testing.", "startOffset": 72, "endOffset": 76}, {"referenceID": 18, "context": "This is consistent with existing studies [19, 4].", "startOffset": 41, "endOffset": 48}, {"referenceID": 3, "context": "This is consistent with existing studies [19, 4].", "startOffset": 41, "endOffset": 48}, {"referenceID": 31, "context": "IRNet [32] 72.", "startOffset": 6, "endOffset": 10}, {"referenceID": 16, "context": "22 DSN [17] 72.", "startOffset": 7, "endOffset": 11}, {"referenceID": 16, "context": "70 DSN [17] + Dropout [30] 72.", "startOffset": 7, "endOffset": 11}, {"referenceID": 29, "context": "70 DSN [17] + Dropout [30] 72.", "startOffset": 22, "endOffset": 26}, {"referenceID": 10, "context": "as hard negative mining [11, 28] which improves the performance.", "startOffset": 24, "endOffset": 32}, {"referenceID": 27, "context": "as hard negative mining [11, 28] which improves the performance.", "startOffset": 24, "endOffset": 32}, {"referenceID": 31, "context": "\u2022 IRNet [32]: We use the model describe in Sec.", "startOffset": 8, "endOffset": 12}, {"referenceID": 16, "context": "\u2022 DSN [17]: By setting \u03c1 = 1, we make LC degenerate to a DSN, where each stage process all regions and has full supervision as the final target.", "startOffset": 6, "endOffset": 10}, {"referenceID": 16, "context": "\u2022 DSN [17] + Dropout [30]: To distinguish our method from dropout, LC is compared against DSN equipped with random label dropout in each stage.", "startOffset": 6, "endOffset": 10}, {"referenceID": 29, "context": "\u2022 DSN [17] + Dropout [30]: To distinguish our method from dropout, LC is compared against DSN equipped with random label dropout in each stage.", "startOffset": 21, "endOffset": 25}, {"referenceID": 24, "context": "in semantic segmentation [25], which effectively prevents gradients exploding or vanishing, it renders the advantages of deeply supervision marginal.", "startOffset": 25, "endOffset": 29}, {"referenceID": 3, "context": "To highlight the trade-off between performance and speed, we compare the proposed LC model with two representative state-ofthe-art methods, DeepLab-v2 [4] and SegNet [1].", "startOffset": 151, "endOffset": 154}, {"referenceID": 0, "context": "To highlight the trade-off between performance and speed, we compare the proposed LC model with two representative state-ofthe-art methods, DeepLab-v2 [4] and SegNet [1].", "startOffset": 166, "endOffset": 169}, {"referenceID": 3, "context": "DeepLab-v2 [4] 70.", "startOffset": 11, "endOffset": 14}, {"referenceID": 0, "context": "1 SegNet [1] 59.", "startOffset": 9, "endOffset": 12}, {"referenceID": 19, "context": "Approaches pre-trained on COCO [20] are marked with \u2020.", "startOffset": 31, "endOffset": 35}, {"referenceID": 24, "context": "FCN [25] 76.", "startOffset": 4, "endOffset": 8}, {"referenceID": 2, "context": "2 DeepLab [3] 84.", "startOffset": 10, "endOffset": 13}, {"referenceID": 39, "context": "6 RNN [40] 87.", "startOffset": 6, "endOffset": 10}, {"referenceID": 36, "context": "0 Adelaide [37] 91.", "startOffset": 11, "endOffset": 15}, {"referenceID": 39, "context": "1 RNN\u2020 [40] 90.", "startOffset": 7, "endOffset": 11}, {"referenceID": 5, "context": "7 BoxSup\u2020 [6] 89.", "startOffset": 10, "endOffset": 13}, {"referenceID": 21, "context": "2 DPN\u2020 [22] 89.", "startOffset": 7, "endOffset": 11}, {"referenceID": 3, "context": "5 DeepLab-v2\u2020 [4] 92.", "startOffset": 14, "endOffset": 17}, {"referenceID": 39, "context": "RNN [40] 2 96.", "startOffset": 4, "endOffset": 8}, {"referenceID": 2, "context": "5 DeepLab [3] 2 97.", "startOffset": 10, "endOffset": 13}, {"referenceID": 24, "context": "1 FCN [25] no 97.", "startOffset": 6, "endOffset": 10}, {"referenceID": 21, "context": "3 DPN [22] no 97.", "startOffset": 6, "endOffset": 10}, {"referenceID": 38, "context": "8 Dilation10 [39] no 97.", "startOffset": 13, "endOffset": 17}, {"referenceID": 3, "context": "1 DeepLab-v2 [4] no 97.", "startOffset": 13, "endOffset": 16}, {"referenceID": 18, "context": "4 Adelaide [19] no 98.", "startOffset": 11, "endOffset": 15}, {"referenceID": 7, "context": "In this section, we show that LC can achieve state-of-theart performance on standard benchmarks like VOC12 [8] and Cityscapes [5] datasets.", "startOffset": 107, "endOffset": 110}, {"referenceID": 4, "context": "In this section, we show that LC can achieve state-of-theart performance on standard benchmarks like VOC12 [8] and Cityscapes [5] datasets.", "startOffset": 126, "endOffset": 129}, {"referenceID": 3, "context": "Following [4], atrous spatial pyramid pooling [4], three-scale testing and dense CRF [16] are employed.", "startOffset": 10, "endOffset": 13}, {"referenceID": 3, "context": "Following [4], atrous spatial pyramid pooling [4], three-scale testing and dense CRF [16] are employed.", "startOffset": 46, "endOffset": 49}, {"referenceID": 15, "context": "Following [4], atrous spatial pyramid pooling [4], three-scale testing and dense CRF [16] are employed.", "startOffset": 85, "endOffset": 89}, {"referenceID": 19, "context": "The approaches pre-trained on COCO [20] are marked with \u2020.", "startOffset": 35, "endOffset": 39}, {"referenceID": 18, "context": "[19]\u2019s performance is slightly better than ours, however, LC still wins on 9 out of 19 classes.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "It is noticed that [19] used a deeper backbonenetwork and explored richer contextual information.", "startOffset": 19, "endOffset": 23}, {"referenceID": 7, "context": "In Table 6, we compare the settings of different bestperforming methods on VOC12 [8] test set, including CRFRNN [40], DPN [22] and DeepLab-v2 [4].", "startOffset": 81, "endOffset": 84}, {"referenceID": 39, "context": "In Table 6, we compare the settings of different bestperforming methods on VOC12 [8] test set, including CRFRNN [40], DPN [22] and DeepLab-v2 [4].", "startOffset": 112, "endOffset": 116}, {"referenceID": 21, "context": "In Table 6, we compare the settings of different bestperforming methods on VOC12 [8] test set, including CRFRNN [40], DPN [22] and DeepLab-v2 [4].", "startOffset": 122, "endOffset": 126}, {"referenceID": 3, "context": "In Table 6, we compare the settings of different bestperforming methods on VOC12 [8] test set, including CRFRNN [40], DPN [22] and DeepLab-v2 [4].", "startOffset": 142, "endOffset": 145}, {"referenceID": 31, "context": "IRNet-LC uses Inception-ResNet-v2(IRNet) [32] as backbone network, which is smaller than ResNet-101 (35.", "startOffset": 41, "endOffset": 45}, {"referenceID": 3, "context": "Following DeepLab-v2 [4], atrous spatial pyramid pooling is employed in IRNet-LC.", "startOffset": 21, "endOffset": 24}, {"referenceID": 39, "context": "CRF-RNN [40] VGG [29] 134.", "startOffset": 8, "endOffset": 12}, {"referenceID": 28, "context": "CRF-RNN [40] VGG [29] 134.", "startOffset": 17, "endOffset": 21}, {"referenceID": 21, "context": "7 DPN [22] VGG [29] 134.", "startOffset": 6, "endOffset": 10}, {"referenceID": 28, "context": "7 DPN [22] VGG [29] 134.", "startOffset": 15, "endOffset": 19}, {"referenceID": 3, "context": "5 DeepLab-v2 [4] ResNet-101 [13] 44.", "startOffset": 13, "endOffset": 16}, {"referenceID": 12, "context": "5 DeepLab-v2 [4] ResNet-101 [13] 44.", "startOffset": 28, "endOffset": 32}, {"referenceID": 31, "context": "IRNet-LC IRNet [32] 35.", "startOffset": 15, "endOffset": 19}, {"referenceID": 31, "context": "2 IRNet-LC IRNet [32] 35.", "startOffset": 17, "endOffset": 21}, {"referenceID": 31, "context": "5 IRNet-LC IRNet [32] 35.", "startOffset": 17, "endOffset": 21}, {"referenceID": 19, "context": "without pre-training on MS COCO [20], demonstrating the effectiveness of the Layer Cascade framework.", "startOffset": 32, "endOffset": 36}, {"referenceID": 21, "context": "8 demonstrates the comparisons of LC with DPN [22] and DeepLab-v2 [4].", "startOffset": 46, "endOffset": 50}, {"referenceID": 3, "context": "8 demonstrates the comparisons of LC with DPN [22] and DeepLab-v2 [4].", "startOffset": 66, "endOffset": 69}, {"referenceID": 4, "context": "We also include more examples of LC label maps on Cityscapes dataset [5] in Fig.", "startOffset": 69, "endOffset": 72}], "year": 2017, "abstractText": "We propose a novel deep layer cascade (LC) method to improve the accuracy and speed of semantic segmentation. Unlike the conventional model cascade (MC) that is composed of multiple independent models, LC treats a single deep model as a cascade of several sub-models. Earlier sub-models are trained to handle easy and confident regions, and they progressively feed-forward harder regions to the next sub-model for processing. Convolutions are only calculated on these regions to reduce computations. The proposed method possesses several advantages. First, LC classifies most of the easy regions in the shallow stage and makes deeper stage focuses on a few hard regions. Such an adaptive and \u2018difficulty-aware\u2019 learning improves segmentation performance. Second, LC accelerates both training and testing of deep network thanks to early decisions in the shallow stage. Third, in comparison to MC, LC is an endto-end trainable framework, allowing joint learning of all sub-models. We evaluate our method on PASCAL VOC and Cityscapes datasets, achieving state-of-the-art performance and fast speed.", "creator": "LaTeX with hyperref package"}}}