{"id": "1704.01938", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Apr-2017", "title": "The Interplay of Semantics and Morphology in Word Embeddings", "abstract": "We explore the ability of word embeddings to capture both semantic and morphological similarity, as affected by the different types of linguistic properties (surface form, lemma, morphological tag) used to compose the representation of each word. We train several models, where each uses a different subset of these properties to compose its representations. By evaluating the models on semantic and morphological measures, we reveal some useful insights on the relationship between semantics and morphology.", "histories": [["v1", "Thu, 6 Apr 2017 17:07:40 GMT  (35kb)", "http://arxiv.org/abs/1704.01938v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["oded avraham", "yoav goldberg"], "accepted": false, "id": "1704.01938"}, "pdf": {"name": "1704.01938.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["oavraham1@gmail.com", "yoav.goldberg@gmail.com"], "sections": [{"heading": null, "text": "ar Xiv: 170 4.01 938v 1 [cs.C L] 6A pr2 017dings to capture both semantic and morphological similarity depending on which linguistic characteristics (surface shape, lemmas, morphological markings) are used to compose the representation of each word. We train several models in which each uses a different subset of these characteristics to compose its representations. By evaluating the models on semantic and morphological measures, we reveal some useful insights about the relationship between semantics and morphology."}, {"heading": "1 Introduction", "text": "This year, it has reached the point where it will be able to retaliate."}, {"heading": "2 Models", "text": "Our model form is a generalization of the fastText model (Bojanowski et al., 2016), which in turn extends the Skip-gram model of Mikolov et al (2013).The Skip-gram model increases a sequence of words w1,..., wT and a function s to (word, context) pairs and maximizesT \u2211 t = 1, wc, ct (s (wt, wc)) + 0, w \u2032 c, Nt (\u2212 s (wt, w \u2032 c)), where the log sigmoid loss function, Ct is a set of context words, and Nt is a set of negative examples derived from the vocabulary. s (wt, wc) is defined as s (wt, wc) = properties of the log sigmoid loss function, Ct is a set of context words, and Nt is a set of negative examples."}, {"heading": "3 Experiments and Results", "text": "\"We have written ourselves on the banners,\" he says, \"and we have written ourselves on the banners.\" (\"We\"), \"we.\" (\"We\"), \"we.\" (\"We\"), \"we.\" (\"We\"), \"we.\" (\"We\"), \"we.\" (\"We\"), \"we.\" (\"We\"), \"we.\" (\"We\"), \"we.\" (\"We\"), \"we.\" (\"We\"), \"we.\" (\"We\"). \"(\" We. \"(\" We. \"(\" We. \"(\"). \"We.\" (\"We.\" (\").\" We. \"(\" We. \"(\"). \"We.\" (\"We.\"). \"We.\" (\"We.\"). \"We.\" (\"We.\" (\").\" We. \"(\" We. \").\" We. \"(\" We. \"(\" We. \").\" We. \"(\" We. \").\" We. \"(\" We. \"(\" We. \").\" We. \"(\" We. \"(\"). \"We.\" (\"We.\"). \"(\" We. \"(\"). \"We.\" (\").\" We. \"(\" We. \"(\"). \"We.\" (\").\" (\"We.\" (\").\" (\"We.\" (\").\" We. \"(\"). \"We.\" (\"(\"). \"(\" We. \").\" (\"We.\"). \"We.\" (\").\" (\"(\"). \"We.\" (\"We.\" (\").\"). (\"We. (\"). (\"We.\"). (\"We.\" (\"). (\" We. \"). (\" We. (\"). (\"). (\"We.\"). (\"We.\"). (\"We.\" (\"We. (\"). (\").\" We. (\"We. (\"). (\"We.\"). \"(\""}, {"heading": "4 Conclusions", "text": "Our core message is that users of morphology-driven models should consider the trade-off between the various components of their representations. Since the goal of most work is to:"}, {"heading": "WM 0.687 0.528 0.907 1", "text": "Morphology-driven models should improve semantic similarity, the configurations used (combining both semantic and morphological components) were probably not the best choice: we show that the use of the Lemma component (either alone or together with the surface shape) is better. In fact, excluding the morphological component leads to a decrease in morphological similarity, but it is not necessarily a problem for every task. One should include the morphological component in embedding only for tasks where morphological similarity is required and cannot be handled by other means. Future work may consist of performing an extrinsic evaluation of the various models in various downstream applications, which could show which types of tasks benefit from morphological information and which can be better accomplished by a purely semantic model."}, {"heading": "Acknowledgements", "text": "The work was supported by the Israeli Science Foundation (grant number 1555 / 15)."}], "references": [{"title": "Hebrew morphological disambiguation: An unsupervised stochastic wordbased approach", "author": ["Menahem Meni Adler."], "venue": "Ph.D. thesis, Ben-Gurion University of the Negev.", "citeRegEx": "Adler.,? 2007", "shortCiteRegEx": "Adler.", "year": 2007}, {"title": "Improving reliability of word similarity evaluation by redesigning annotation task and performancemeasure", "author": ["Oded Avraham", "Yoav Goldberg."], "venue": "Proceedings of the 1st Workshop on Evaluating Vector-Space Representations for NLP, pages", "citeRegEx": "Avraham and Goldberg.,? 2016", "shortCiteRegEx": "Avraham and Goldberg.", "year": 2016}, {"title": "A critique of word similarity as a method for evaluating distributional semantic models", "author": ["Miroslav Batchkarov", "Thomas Kober", "Jeremy Reffin", "Julie Weeds", "David Weir."], "venue": "Proceedings of the 1st", "citeRegEx": "Batchkarov et al\\.,? 2016", "shortCiteRegEx": "Batchkarov et al\\.", "year": 2016}, {"title": "Enriching word vectors with subword information", "author": ["Piotr Bojanowski", "Edouard Grave", "Armand Joulin", "Tomas Mikolov."], "venue": "arXiv preprint arXiv:1607.04606.", "citeRegEx": "Bojanowski et al\\.,? 2016", "shortCiteRegEx": "Bojanowski et al\\.", "year": 2016}, {"title": "Compositional morphology for word representations and language modelling", "author": ["Jan A. Botha", "Phil Blunsom."], "venue": "ICML, pages 1899\u20131907.", "citeRegEx": "Botha and Blunsom.,? 2014", "shortCiteRegEx": "Botha and Blunsom.", "year": 2014}, {"title": "Morphological word-embeddings", "author": ["Ryan Cotterell", "Hinrich Sch\u00fctze."], "venue": "Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 1287\u20131292,", "citeRegEx": "Cotterell and Sch\u00fctze.,? 2015", "shortCiteRegEx": "Cotterell and Sch\u00fctze.", "year": 2015}, {"title": "Morphological smoothing and extrapolation of word embeddings", "author": ["Ryan Cotterell", "Hinrich Sch\u00fctze", "Jason Eisner."], "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages", "citeRegEx": "Cotterell et al\\.,? 2016", "shortCiteRegEx": "Cotterell et al\\.", "year": 2016}, {"title": "Problems with evaluation of word embeddings using word similarity tasks", "author": ["Manaal Faruqui", "Yulia Tsvetkov", "Pushpendre Rastogi", "Chris Dyer."], "venue": "Proceedings of the 1st Workshop on Evaluating Vector-Space Representations for NLP, pages 30\u2013", "citeRegEx": "Faruqui et al\\.,? 2016", "shortCiteRegEx": "Faruqui et al\\.", "year": 2016}, {"title": "Placing search in context: The concept revisited", "author": ["Lev Finkelstein", "Evgeniy Gabrilovich", "Yossi Matias", "Ehud Rivlin", "Zach Solan", "Gadi Wolfman", "Eytan Ruppin."], "venue": "Proceedings of the 10th international conference on World Wide Web, pages 406\u2013", "citeRegEx": "Finkelstein et al\\.,? 2001", "shortCiteRegEx": "Finkelstein et al\\.", "year": 2001}, {"title": "Simlex-999: Evaluating semantic models with (genuine) similarity estimation", "author": ["Felix Hill", "Roi Reichart", "Anna Korhonen."], "venue": "Computational Linguistics, 41(4).", "citeRegEx": "Hill et al\\.,? 2015", "shortCiteRegEx": "Hill et al\\.", "year": 2015}, {"title": "Language resources for Hebrew", "author": ["Alon Itai", "Shuly Wintner."], "venue": "Language Resources and Evaluation, 42(1):75\u201398, March.", "citeRegEx": "Itai and Wintner.,? 2008", "shortCiteRegEx": "Itai and Wintner.", "year": 2008}, {"title": "Compositionally derived representations of morphologically complex words in distributional semantics", "author": ["Angeliki Lazaridou", "Marco Marelli", "Roberto Zamparelli", "Marco Baroni."], "venue": "Proceedings of the 51st Annual Meeting of the Association", "citeRegEx": "Lazaridou et al\\.,? 2013", "shortCiteRegEx": "Lazaridou et al\\.", "year": 2013}, {"title": "Issues in evaluating semantic spaces using word analogies", "author": ["Tal Linzen."], "venue": "Proceedings of the 1st Workshop on Evaluating Vector-Space Representations for NLP, pages 13\u201318, Berlin, Germany, August. Association for Computational Linguistics.", "citeRegEx": "Linzen.,? 2016", "shortCiteRegEx": "Linzen.", "year": 2016}, {"title": "Better word representations with recursive neural networks for morphology", "author": ["Thang Luong", "Richard Socher", "Christopher Manning."], "venue": "Proceedings of the Seventeenth Conference on Computational Natural Language Learning, pages 104\u2013113,", "citeRegEx": "Luong et al\\.,? 2013", "shortCiteRegEx": "Luong et al\\.", "year": 2013}, {"title": "Efficient estimation of word representations in vector space", "author": ["Tomas Mikolov", "Kai Chen", "Greg Corrado", "Jeffrey Dean."], "venue": "arXiv preprint arXiv:1301.3781.", "citeRegEx": "Mikolov et al\\.,? 2013", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Co-learning of word representations and morpheme representations", "author": ["Siyu Qiu", "Qing Cui", "Jiang Bian", "Bin Gao", "Tie-Yan Liu."], "venue": "Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers, pages", "citeRegEx": "Qiu et al\\.,? 2014", "shortCiteRegEx": "Qiu et al\\.", "year": 2014}, {"title": "Unsupervised morphology induction using word embeddings", "author": ["Radu Soricut", "Franz Och."], "venue": "Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technolo-", "citeRegEx": "Soricut and Och.,? 2015", "shortCiteRegEx": "Soricut and Och.", "year": 2015}], "referenceMentions": [{"referenceID": 11, "context": "The works differ in the way they acquire morphological knowledge (from using linguistically derived morphological analyzers on one end, to approximating morphology using substrings while relying on the concatenative nature of morphology, on the other) and in the model form (cDSMs (Lazaridou et al., 2013), RNN (Luong et al.", "startOffset": 281, "endOffset": 305}, {"referenceID": 13, "context": ", 2013), RNN (Luong et al., 2013), LBL (Botha and Blunsom, 2014), CBOW (Qiu et al.", "startOffset": 13, "endOffset": 33}, {"referenceID": 4, "context": ", 2013), LBL (Botha and Blunsom, 2014), CBOW (Qiu et al.", "startOffset": 13, "endOffset": 38}, {"referenceID": 15, "context": ", 2013), LBL (Botha and Blunsom, 2014), CBOW (Qiu et al., 2014), SkipGram (Soricut and Och, 2015; Bojanowski et al.", "startOffset": 45, "endOffset": 63}, {"referenceID": 16, "context": ", 2014), SkipGram (Soricut and Och, 2015; Bojanowski et al., 2016), GGM (Cotterell et al.", "startOffset": 18, "endOffset": 66}, {"referenceID": 3, "context": ", 2014), SkipGram (Soricut and Och, 2015; Bojanowski et al., 2016), GGM (Cotterell et al.", "startOffset": 18, "endOffset": 66}, {"referenceID": 6, "context": ", 2016), GGM (Cotterell et al., 2016)).", "startOffset": 13, "endOffset": 37}, {"referenceID": 1, "context": "We build on a recently introduced evaluation dataset for semantic similarity in Modern Hebrew (Avraham and Goldberg, 2016), which we further extend with a collection of rare words.", "startOffset": 94, "endOffset": 122}, {"referenceID": 3, "context": "Our model form is a generalization of the fastText model (Bojanowski et al., 2016), which in turn extends the skip-gram model of Mikolov et al (2013).", "startOffset": 57, "endOffset": 82}, {"referenceID": 3, "context": "Our model form is a generalization of the fastText model (Bojanowski et al., 2016), which in turn extends the skip-gram model of Mikolov et al (2013). The skip-gram model takes a sequence of words w1, .", "startOffset": 58, "endOffset": 150}, {"referenceID": 5, "context": "word, from which its inflectional affixes are derived (a similar approach was taken by Cotterell and Sch\u00fctze (2015)).", "startOffset": 87, "endOffset": 116}, {"referenceID": 3, "context": "brary (Bojanowski et al., 2016), which we modify as described above.", "startOffset": 6, "endOffset": 31}, {"referenceID": 10, "context": "We use the morphological disambiguator of Adler (2007) to assign words with their morphological tags, and the inflection dictionary of MILA (Itai and Wintner, 2008) to find their lemmas.", "startOffset": 140, "endOffset": 164}, {"referenceID": 0, "context": "We use the morphological disambiguator of Adler (2007) to assign words with their morphological tags, and the inflection dictionary of MILA (Itai and Wintner, 2008) to find their lemmas.", "startOffset": 42, "endOffset": 55}, {"referenceID": 1, "context": "previous work (Avraham and Goldberg, 2016) (AG).", "startOffset": 14, "endOffset": 42}, {"referenceID": 8, "context": ", WordSim353 (Finkelstein et al., 2001), RW (Luong et al.", "startOffset": 13, "endOffset": 39}, {"referenceID": 13, "context": ", 2001), RW (Luong et al., 2013) and SimLex999 (Hill et al.", "startOffset": 12, "endOffset": 32}, {"referenceID": 9, "context": ", 2013) and SimLex999 (Hill et al., 2015) An AG dataset is a collection of target-groups,", "startOffset": 22, "endOffset": 41}, {"referenceID": 1, "context": "We use this method on two datasets: the AG dataset from (Avraham and Goldberg, 2016) (SemanticSim, containing 1819 triples), and a new dataset we created in order to evaluate the models on rare words (similar to RW (Luong et al.", "startOffset": 56, "endOffset": 84}, {"referenceID": 13, "context": "We use this method on two datasets: the AG dataset from (Avraham and Goldberg, 2016) (SemanticSim, containing 1819 triples), and a new dataset we created in order to evaluate the models on rare words (similar to RW (Luong et al., 2013)).", "startOffset": 215, "endOffset": 235}], "year": 2017, "abstractText": "We explore the ability of word embeddings to capture both semantic and morphological similarity, as affected by the different types of linguistic properties (surface form, lemma, morphological tag) used to compose the representation of each word. We train several models, where each uses a different subset of these properties to compose its representations. By evaluating the models on semantic and morphological measures, we reveal some useful insights on the relationship between semantics and morphology.", "creator": "dvips(k) 5.996 Copyright 2016 Radical Eye Software"}}}