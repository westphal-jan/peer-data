{"id": "1704.02263", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Apr-2017", "title": "NILC-USP at SemEval-2017 Task 4: A Multi-view Ensemble for Twitter Sentiment Analysis", "abstract": "This paper describes our multi-view ensemble approach to SemEval-2017 Task 4 on Sentiment Analysis in Twitter, specifically, the Message Polarity Classification subtask for English (subtask A). Our system is a voting ensemble, where each base classifier is trained in a different feature space. The first space is a bag-of-words model and has a Linear SVM as base classifier. The second and third spaces are two different strategies of combining word embeddings to represent sentences and use a Linear SVM and a Logistic Regressor as base classifiers. The proposed system was ranked 18th out of 38 systems considering F1 score and 20th considering recall.", "histories": [["v1", "Fri, 7 Apr 2017 15:27:10 GMT  (22kb)", "http://arxiv.org/abs/1704.02263v1", "Published in Proceedings of SemEval-2017, 5 pages"]], "COMMENTS": "Published in Proceedings of SemEval-2017, 5 pages", "reviews": [], "SUBJECTS": "cs.CL cs.LG", "authors": ["edilson a corr\\^ea jr", "vanessa queiroz marinho", "leandro borges dos santos"], "accepted": false, "id": "1704.02263"}, "pdf": {"name": "1704.02263.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Vanessa Queiroz Marinho", "Leandro Borges dos Santos"], "emails": ["edilsonacjr@usp.br", "vanessaqm@usp.br", "leandrobs@usp.br"], "sections": [{"heading": null, "text": "ar Xiv: 170 4.02 263v 1 [cs.C L] 7A pr2 017semble approach to SemEval-2017 Task 4 on Sentiment Analysis in Twitter, in particular the Message Polarity Classification subtask for English (Subtask A). Our system is a voting ensemble in which each basic classifier is trained in a different feature space. The first room is a bag-of-words model and has a linear SVM as the base classifier. The second and third room are two different strategies to combine word embedding to represent sentences and use a linear SVM and a logistic regressor as the base classifier. The proposed system ranked 18th out of 38 systems that take into account the value of Formula 1 and 20th place taking into account the recall."}, {"heading": "1 Introduction", "text": "Twitter is a microblogging service that has 313 million monthly active users 1. In this social media platform, users interact via short messages, so-called tweets. The company estimates that over 500 million tweets are sent every day 2. Despite their size of 140 characters or less, these messages provide rich data because users generally write about their thoughts, opinions and feelings. Therefore, applications in several areas, such as commercial (Jansen et al., 2009) and political (Tumasjan et al., 2010; Wang et al., 2012), can benefit from the automatic classification of mood in tweets. In this paper, we show that a multi-layered ensemble approach using simple text representations can achieve good results in classifying message polarity. The proposed system consists of three basic classifiers, each section 1https: / about.twitter.com / company 2https: / / business.twitter.com / en / basics.htmlwith a specific text representation technique (Bagttwords or)."}, {"heading": "2 System Description", "text": "The proposed system consists of a multi-view ensemble with three base classifiers with different text rendering techniques (feature spaces), i.e. all base classifiers are trained on the same data set but with a different representation or feature space. The first is a linear SVM and the tweets are represented by bag-of-words (Section 2.1.1); the second is another linear SVM and the tweets are represented by an averaging of the word embeddings (Section 2.1.2); the third is a logistic regressor and the tweets are represented by an averaging of the weighted word embeddings (Section 2.1.2). In these systems, a class of a given instance is decided as a class that maximizes the sums of the predicted probabilities (Soft Voting).The idea of a multi-view ensemble is to explore different feature spaces without having to combine all the features in the same room, as this does not allow for direct insertion."}, {"heading": "2.1 Text representations", "text": "In this paper, tweets are modelled on three types of text representation: the first is a sack-of-words model weighted by tf-idf (term frequency - inverse document frequency) (Section 2.1.1); the second is a sentence by averaging the word embedding of all words (in the sentence); and the third is a sentence by averaging the weighted word embedding of all words; the weight of a word is given by tf-idf (Section 2.1.2)."}, {"heading": "2.1.1 Bag-of-words", "text": "The Sack-of-Words model is a popular approach to representing text (documents, sentences, queries, and others) in the Natural Language Processing and Information Retrieval. In this model, a text is represented by its word volume, which representation can be binary, where a word receives 1 when it is in the text, or 0 otherwise, taking into account a predefined vocabulary. An alternative is a representation weighted by specific information, such as frequency. The representation used in this work is the Sack-of-Words weighted by tfidf (Salton, 1989), where each tweet is presented as Tweeti = (ai1, ai2,..., target), where aij is given by the frequency of the term tj in the tweet i weighted by the total number of tweets divided by the number of tweets containing the term tj."}, {"heading": "2.1.2 Word embeddings", "text": "Word embedding, a concept introduced by Bengio et al. (2003), is a distributional representation of words in which each word is represented by a dense, real-valued vector, which is learned by neural networks3https: / / github.com / edilsonacjr / semeval2017in speech modeling (Bengio et al., 2003) or similar tasks (Collobert et al., 2011; Mikolov et al., 2013a, b). In this work, the Word2Vec model (Mikolov et al., 2013a, b) is used, in which the vectors are learned by training the neural network to predict context (Skip-gram) or word (CBOW). In addition to collecting syntactical and semantic information, the vectors produced by Word2Vec are incorporated by geometric properties such as compositionality (Mikolov et, the larger word sultans, 2013b)."}, {"heading": "2.2 Classifiers", "text": "For both classifiers we used the well-known Scikit Learn implementation (Pedregosa et al., 2011) (with standard parameters)."}, {"heading": "2.2.1 Logistic Regression", "text": "Logistic regression is a linear classifier that predicts the class probabilities of a binary classification problem. It is also called Logit regression because a sigmoid function prints the class probabilities. To solve multi-class problems, the training algorithm uses the one-vs-rest approach (Murphy, 2012)."}, {"heading": "2.2.2 Support Vector Machines", "text": "Supported Vector Machine Classifiers (SVMs) find the decision limit that maximizes the margin between two classes. However, if data is inherently non-linear, SVM classifiers cannot properly separate the classes. A possible solution is to map the data points into a higher-dimensional attribute space, making the data linearly separable (Murphy, 2012). To apply the algorithm to our multiclass problem, we used the one-on-one approach."}, {"heading": "3 Data", "text": "To evaluate our system, we used the training and development datasets of the SemEval2017 competition (specifically Twitter2016-train and Twitter2016-dev) and a new dataset (Twitter2017test) was provided in addition to the previous year's test datasets (Twitter2016-test, SMS2013, Tw2014-sarcasm, LiveJournal2014) for testing. A summary of the datasets can be found in Table 1.Data Preprocessing. prior to the feature extraction, the tweets were pre-processed, taking into account HTML tags, mentions / usernames, URLs, numbers, words (including hyphenation) and emoticons with lowercase letters and stopwords (words with low semantic value such as prepositions and articles), punctuation / usernames, URLs, numbers, words (including hyphenation) and emoticons. Subsequently, the text was removed from the username value and punctuation inserts (such as hash and words)."}, {"heading": "4 Results", "text": "In order to evaluate, compare and classify the participating systems, the organizers chose the F1 score (average), the recall (average) and the accuracy. Our system ranked 18th out of 38 systems with an F1 score of 0.595 in the Twitter2017 test, 20th place in terms of recall (0.612) and 16th place in terms of accuracy with 0.617. The complete ranking and other details of the competition can be found in Rosenthal et al. (2017). In the Twitter2016 test evaluation, we chose only the Twitter2016-train and Twitter2016-dev in training. In the rest of the evaluations, Twitter2016-train, Twitter2016-dev, Twitter2016 test was used. Despite the availability of other data sets for training, we chose only the three. The results obtained by our system are summarized in Table 2.From the results it is possible to determine that the system is affected in data sets of different origin, such as SMS2013, this may occur due to a specific word or other case, although it is not stable."}, {"heading": "5 Conclusion and Future Work", "text": "In this paper, we presented a multi-view approach to classifying message polarity that participated in the SemEval-2017 Task 4 on Sentiment Analysis in Twitter (Subtask A English). Our system ranked 18th out of 38 participants. Results showed that a multi-view approach that uses simple representations of texts can achieve good results in the task of message polarity classification without intervention or special pre-processing. In our approach, we plan to combine our model with other techniques that take into account the order of words, such as word grammes. In the future, we also plan to use approaches to normalizing informal texts to capture specifics of the language of social media. In informal texts, words or a sequence of words can be intentionally replaced as they are used intentionally and not used as a sentiment."}, {"heading": "Acknowledgments", "text": "E.A.C.J. recognizes financial support from Google (Google Research Awards in Latin America grant) and CAPES (Coordination for the Improvement of Higher Education Personnel). V.Q.M. recognizes financial support from FAPESP (grant no. 15 / 05676-8). L.B.S. recognizes financial support from Google (Google Research Awards in Latin America grant) and CNPq (National Council for Scientific and Technological Development, Brazil)."}], "references": [{"title": "Vectorslu: A continuous word vector approach to answer selection in community question answering systems", "author": ["Yonatan Belinkov", "Mitra Mohtarami", "Scott Cyphers", "James Glass."], "venue": "Proceedings of the 9th International Workshop on Semantic Eval-", "citeRegEx": "Belinkov et al\\.,? 2015", "shortCiteRegEx": "Belinkov et al\\.", "year": 2015}, {"title": "A neural probabilistic language model", "author": ["Yoshua Bengio", "R\u00e9jean Ducharme", "Pascal Vincent", "Christian Jauvin."], "venue": "Journal of Machine Learning Research 3(Feb):1137\u20131155.", "citeRegEx": "Bengio et al\\.,? 2003", "shortCiteRegEx": "Bengio et al\\.", "year": 2003}, {"title": "Natural language processing", "author": ["Ronan Collobert", "Jason Weston", "L\u00e9on Bottou", "Michael Karlen", "Koray Kavukcuoglu", "Pavel Kuksa"], "venue": null, "citeRegEx": "Collobert et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Collobert et al\\.", "year": 2011}, {"title": "Embeddings for word sense disambiguation: An evaluation study", "author": ["Ignacio Iacobacci", "Mohammad Taher Pilehvar", "Roberto Navigli."], "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics. volume 1, pages", "citeRegEx": "Iacobacci et al\\.,? 2016", "shortCiteRegEx": "Iacobacci et al\\.", "year": 2016}, {"title": "Twitter power: Tweets as electronic word of mouth", "author": ["Bernard J. Jansen", "Mimi Zhang", "Kate Sobel", "Abdur Chowdury."], "venue": "Journal of the American Society for Information Science and Technology 60(11):2169\u20132188.", "citeRegEx": "Jansen et al\\.,? 2009", "shortCiteRegEx": "Jansen et al\\.", "year": 2009}, {"title": "Efficient estimation of word representations in vector space", "author": ["Tomas Mikolov", "Kai Chen", "Greg Corrado", "Jeffrey Dean."], "venue": "arXiv preprint arXiv:1301.3781 .", "citeRegEx": "Mikolov et al\\.,? 2013a", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean."], "venue": "Advances in neural information processing systems. pages 3111\u20133119.", "citeRegEx": "Mikolov et al\\.,? 2013b", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Machine Learning: A Probabilistic Perspective", "author": ["Kevin P. Murphy."], "venue": "The MIT Press.", "citeRegEx": "Murphy.,? 2012", "shortCiteRegEx": "Murphy.", "year": 2012}, {"title": "Scikit-learn: Machine learning in python", "author": ["Fabian Pedregosa", "Ga\u00ebl Varoquaux", "Alexandre Gramfort", "Vincent Michel", "Bertrand Thirion", "Olivier Grisel", "Mathieu Blondel", "Peter Prettenhofer", "Ron Weiss", "Vincent Dubourg"], "venue": "Journal of Machine", "citeRegEx": "Pedregosa et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Pedregosa et al\\.", "year": 2011}, {"title": "SemEval-2017 task 4: Sentiment analysis in Twitter", "author": ["Sara Rosenthal", "Noura Farra", "Preslav Nakov."], "venue": "Proceedings of the 11th International Workshop on Semantic Evaluation. Association for Computational Linguistics, Vancouver, Canada, SemEval", "citeRegEx": "Rosenthal et al\\.,? 2017", "shortCiteRegEx": "Rosenthal et al\\.", "year": 2017}, {"title": "Automatic text processing: The transformation, analysis, and retrieval of", "author": ["Gerard Salton."], "venue": "Reading: Addison-Wesley .", "citeRegEx": "Salton.,? 1989", "shortCiteRegEx": "Salton.", "year": 1989}, {"title": "Recursive deep models for semantic compositionality over a sentiment treebank", "author": ["Richard Socher", "Alex Perelygin", "Jean Y Wu", "Jason Chuang", "Christopher D Manning", "Andrew Y Ng", "Christopher Potts"], "venue": "In Proceedings of the conference on", "citeRegEx": "Socher et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Socher et al\\.", "year": 2013}, {"title": "Dls@ cu: Sentence similarity from word alignment and semantic vector composition", "author": ["Md Arafat Sultan", "Steven Bethard", "Tamara Sumner."], "venue": "Proceedings of the 9th International Workshop on Semantic Evaluation. pages 148\u2013153.", "citeRegEx": "Sultan et al\\.,? 2015", "shortCiteRegEx": "Sultan et al\\.", "year": 2015}, {"title": "Predicting elections with twitter: What 140 characters reveal about political sentiment", "author": ["Andranik Tumasjan", "Timm O. Sprenger", "Philipp G. Sandner", "Isabell M. Welpe."], "venue": "Proceedings of the", "citeRegEx": "Tumasjan et al\\.,? 2010", "shortCiteRegEx": "Tumasjan et al\\.", "year": 2010}, {"title": "A system for real-time twitter sentiment analysis of 2012 u.s. presidential election cycle", "author": ["Hao Wang", "Dogan Can", "Abe Kazemzadeh", "Fran\u00e7ois Bar", "Shrikanth Narayanan"], "venue": "In Proceedings of the ACL 2012 System Demonstrations", "citeRegEx": "Wang et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2012}, {"title": "A survey on multi-view learning", "author": ["Chang Xu", "Dacheng Tao", "Chao Xu."], "venue": "arXiv preprint arXiv:1304.5634 .", "citeRegEx": "Xu et al\\.,? 2013", "shortCiteRegEx": "Xu et al\\.", "year": 2013}, {"title": "Ecnu: Using traditional similarity measurements and word embedding for semantic textual similarity estimation", "author": ["Jiang Zhao", "Man Lan", "Jun Feng Tian."], "venue": "Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015). page", "citeRegEx": "Zhao et al\\.,? 2015", "shortCiteRegEx": "Zhao et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 4, "context": "Therefore, applications in several domains, such as commercial (Jansen et al., 2009) and political (Tumasjan et al.", "startOffset": 63, "endOffset": 84}, {"referenceID": 13, "context": ", 2009) and political (Tumasjan et al., 2010; Wang et al., 2012), may benefit from the automatic classification of sentiment in tweets.", "startOffset": 22, "endOffset": 64}, {"referenceID": 14, "context": ", 2009) and political (Tumasjan et al., 2010; Wang et al., 2012), may benefit from the automatic classification of sentiment in tweets.", "startOffset": 22, "endOffset": 64}, {"referenceID": 15, "context": "Other important aspect of this technique is the possibility of assigning different weights to each pair of classifier/features (view) or even learn the weights by a regression method (Xu et al., 2013).", "startOffset": 183, "endOffset": 200}, {"referenceID": 10, "context": "The representation adopted by this work is the bag-of-words weighted by tfidf (Salton, 1989), where each tweet is represented as tweeti = (ai1, ai2, .", "startOffset": 78, "endOffset": 92}, {"referenceID": 1, "context": "Word embeddings, a concept introduced by Bengio et al. (2003), is a distributional representation of words, where each word is", "startOffset": 41, "endOffset": 62}, {"referenceID": 1, "context": "com/edilsonacjr/semeval2017 trained in language modeling (Bengio et al., 2003) or similar tasks (Collobert et al.", "startOffset": 57, "endOffset": 78}, {"referenceID": 6, "context": "In addition to capture syntactic and semantic information, the vectors produced by Word2Vec have geometric properties such as compositionality (Mikolov et al., 2013b), which allow larger blocks of information (such as sentences and paragraphs) to be represented by the combination of the embeddings of the words contained in the block.", "startOffset": 143, "endOffset": 166}, {"referenceID": 0, "context": "This approach has been adopted by a considerable number of works in several areas, such as question answering (Belinkov et al., 2015), semantic textual similarity (Sultan et al.", "startOffset": 110, "endOffset": 133}, {"referenceID": 12, "context": ", 2015), semantic textual similarity (Sultan et al., 2015), word sense disambiguation (Iacobacci et al.", "startOffset": 37, "endOffset": 58}, {"referenceID": 3, "context": ", 2015), word sense disambiguation (Iacobacci et al., 2016) and even sentiment analysis (Socher et al.", "startOffset": 35, "endOffset": 59}, {"referenceID": 11, "context": ", 2016) and even sentiment analysis (Socher et al., 2013).", "startOffset": 36, "endOffset": 57}, {"referenceID": 16, "context": "A similar approach has been used in Zhao et al. (2015).", "startOffset": 36, "endOffset": 55}, {"referenceID": 8, "context": "Scikit-learn (Pedregosa et al., 2011) implementa-", "startOffset": 13, "endOffset": 37}, {"referenceID": 7, "context": "To tackle multiclass problems, the training algorithm uses the one-vs-rest approach (Murphy, 2012).", "startOffset": 84, "endOffset": 98}, {"referenceID": 7, "context": "By doing so, the data becomes linearly separable (Murphy, 2012).", "startOffset": 49, "endOffset": 63}, {"referenceID": 9, "context": "The full ranking and other details of the competition may be found in Rosenthal et al. (2017).", "startOffset": 70, "endOffset": 94}], "year": 2017, "abstractText": "This paper describes our multi-view ensemble approach to SemEval-2017 Task 4 on Sentiment Analysis in Twitter, specifically, the Message Polarity Classification subtask for English (subtask A). Our system is a voting ensemble, where each base classifier is trained in a different feature space. The first space is a bag-of-words model and has a Linear SVM as base classifier. The second and third spaces are two different strategies of combining word embeddings to represent sentences and use a Linear SVM and a Logistic Regressor as base classifiers. The proposed system was ranked 18th out of 38 systems considering F1 score and 20th considering recall.", "creator": "LaTeX with hyperref package"}}}