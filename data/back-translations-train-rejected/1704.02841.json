{"id": "1704.02841", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Apr-2017", "title": "From Modal to Multimodal Ambiguities: a Classification Approach", "abstract": "This paper deals with classifying ambiguities for Multimodal Languages. It evolves the classifications and the methods of the literature on ambiguities for Natural Language and Visual Language, empirically defining an original classification of ambiguities for multimodal interaction using a linguistic perspective. This classification distinguishes between Semantic and Syntactic multimodal ambiguities and their subclasses, which are intercepted using a rule-based method implemented in a software module. The experimental results have achieved an accuracy of the obtained classification compared to the expected one, which are defined by the human judgment, of 94.6% for the semantic ambiguities classes, and 92.1% for the syntactic ambiguities classes.", "histories": [["v1", "Tue, 4 Apr 2017 12:06:51 GMT  (1016kb)", "http://arxiv.org/abs/1704.02841v1", "23 pages"]], "COMMENTS": "23 pages", "reviews": [], "SUBJECTS": "cs.HC cs.CL", "authors": ["maria chiara caschera", "fernando ferri", "patrizia grifoni"], "accepted": false, "id": "1704.02841"}, "pdf": {"name": "1704.02841.pdf", "metadata": {"source": "CRF", "title": "From Modal to Multimodal Ambiguities: a Classification Approach", "authors": ["Chiara Caschera"], "emails": ["mc.caschera@irpps.cnr.it", "fernando.ferri@irpps.cnr.it", "patrizia.grifoni@irpps.cnr.it"], "sections": [{"heading": null, "text": "Classifications and the methodologies of the literature on ambiguities for natural language and visual language, and empirically define an original classification of ambiguities for multimodal interaction using a linguistic perspective. This classification distinguishes between semantic and syntactic multimodal ambiguities and their subclasses, which are intercepted using a rules-based method implemented in a software module. Experimental results achieved an accuracy of the classification obtained compared to the expected classification defined by human judgment of 94.6% for the classes of semantic ambiguities and 92.1% for the classes of syntactical ambiguities. Keywords: Human Computer Interaction, Language Ambiguity, Multimodal Language"}, {"heading": "1. Introduction", "text": "In fact, most of them will be able to put themselves in a situation in which they are able to survive on their own and in which they are unable to solve their problems."}, {"heading": "2. Related work on Languages Ambiguities Classification", "text": "A communication process involves sharing common meanings for communication acts (such as a sentence for NL or more generally a message) involving different actors. If there is a gap between the intended meaning of the sender's message and the meaning given by the recipient of the message, an error or ambiguity can occur. A discussion of some of the most relevant studies of ambiguity dealing with NL, visual communication and VL will be presented in the next section."}, {"heading": "2.1. Ambiguity classes in Natural and Visual Languages", "text": "In fact, most people who are able to identify themselves also act as if they were doing it. (...) It's not as if they were doing it. (...) It's as if they were doing it. (...) It's as if they were doing it. (...) It's as if they were doing it. (...) It's as if they were doing it. \"(...) It's as if they were doing it. (...) It's as if they were doing it. (...) It's as if they were doing it.\" (...) It's as if they were doing it. \"(...) It's as if they were doing it.\""}, {"heading": "3. Multimodality: Main Concepts", "text": "Based on the hypothesis of adopting a linguistic approach, this section defines the main concepts used to classify and present multimodal ambiguities. Discussion of multimodal ambiguities is based on the definition of multimodal attribute grammar combined with linear logic [24], which expands classical logic [25] to include the concept of resource and the concept of formulas as a resource. Linear logic loosens the monotonous constraints of classical logic and models changes over time. These characteristics of linear logic satisfy some needs closely linked to multimodality and its characteristic in terms of time change."}, {"heading": "3.1. Multimodal Attribute Grammar", "text": "Multimodal attribute grammar is a context-free and advanced attribute-based grammar [13] that allows the calculation of derived attributes of non-terminal symbols using calculations embedded in grammar productions. It is defined as follows: Def.1 Multimodal attribute grammar is triple grammar (G, A, R), where \u2022 G is a context-free grammar defined as quadruple grammar (T, N, P, S), where T is the set of terminal symbols, N the set of non-terminal symbols, P is the set of production rules, and S N is the start symbol; \u2022 A is the collection of attributes of terminal and non-terminal symbols; \u2022 R is the collection of semantic rules."}, {"heading": "3.2. Production rules of the Multimodal Attribute Grammar", "text": "The production rules of multimodal attribute grammar can be divided into: rules relating to the construction of the syntax of the grammar Pg; rules on the context Pc; and temporal rules Pt. Therefore, the sentence P of the production rules was chosen: P = {Pg, Pc, Pt}. In order to define the production rules of the proposed method, which will deal with both syntax and semantics of multimodal language, linear logic was chosen. An exhaustive description of linear logic is not included in this essay, and the multiplicative intuitionist fragment of linear logic, which uses the multiplicative connecting \"\" (conjunction of hypotheses) and linear implication, \"is sufficient for our purpose. In particular, this work deals with the multimodal thesis and its interpretation in NL. Therefore, this work uses the production rules of the NL, the production rules of the syngram control rules described in [13], according to their scope."}, {"heading": "3.3. From Terminal Element to the Multimodal Language Definition", "text": "The set of terminal symbols T, belonging to the Multimodal Attribute Grammar = Def. 1, contains the components of the multimodal language. These symbols are the terminal elements of multimodal phrases for the multimodal language. A terminal element contains information about: the modality used to specify the element; the representation of the element in the specific modality; the time interval associated with the element in which the first number represents the start time and the second number the end time; the syntactical role that the element plays in the multimodal set; the semantic definition of the element taking into account its representation with respect to modality. In particular, the semantic meaning of the element is given taking into account a domain ontology that provides the conceptual structure of the context. Therefore, a terminal element egg is defined in [14] as: A terminal element egg is a 5-element (a tuple)."}, {"heading": "4. The Multimodal Ambiguities Classification Method", "text": "Based on the ambiguities classification previously described for NL and VLs, this section gives a classification of ambiguities characterizing multimodal interaction processes. This classification was empirically defined on the basis of a set of 520 multimodal sentences (both ambiguous and unambiguous).There were sentences known and classified by the literature with unimodal ambiguities and sentences with multimodal ambiguities (a total of 480), and 40 unambiguous sentences, which, after a tutorial phase, were needed to see and hear how each multimodal sentence of the sentence and comment if it was ambiguous in their opinion. In this case, it was necessary to annotorize the type of ambiguity (selected between the classes that were proposed for VLs and NL), or two of the possible interpretations."}, {"heading": "4.1. Semantic Ambiguities", "text": "This section describes the ambiguities of a multimodal sentence taking into account its different meanings. In detail, semantic ambiguities are distinguished into lexical, temporal-semantic and purposeful ambiguities."}, {"heading": "4.1.1. Lexical Ambiguity", "text": "Egg \"nEi\" n, nEi sasd hacu \"c, nEi sasds hacu\" i, nEi sasds hacu \"c\" i \"i\" nEi, \"nEi\" i \"nEi,\" nEi \"nEi,\" nEi, \"nEi,\" \",\" \",\" \"\", \"\" \"\", \"\" \"\" \"\" \"\" \",\" \"\" \"\" \"\" \"\" \"\", \"\" \"\" \"\", \"\" \"\" \"\", \"\" \"\" \",\" \"\" \",\" \"\" \"\", \"\" \"\" \"\", \"\" \"\" \"\", \"\" \"\" \"\", \"\" \",\" \"\" \",\" \"\", \"\" \",\" \",\" \",\" \",\" \",\" \"\", \"\" \"\", \"\" \",\" \"\", \"\" \",\" \"\", \"\", \"\" \"\", \"\" \"\", \"\" \"\", \"\", \"\", \"\" \"\", \"\" \"\" \",\" \"\" \",\" \"\", \"\" \"\", \"\" \"\" \",\" \"\", \"\" \"\" \",\" \"\" \"\", \"\" \",\" \"\" \",\" \"\" \",\" \"\" \",\" \"\" \"\", \"\" \"\" \",\" \"\", \"\" \"\", \"\" \"\", \"\" \"\" \"\" \",\" \",\" \"\" \",\" \"\" \"\" \"\", \"\" \"\", \"\" \"\" \",\" \"\" \"\", \"\" \"\" \",\" \"\" \"\" \",\" \"\" \",\" \"\" \"\" \"\" \",\" \"\" \"\" \",\" \"\" \"\" \",\" \"\" \"\" \",\" \"\" \"\" \"\" \"\", \"\" \"\" \"\" \"\" \",\" \"\" \"\" \"\" \"\" \",\" \"\" \"\", \"\" \"\" \"\" \"\" \"\" \"\" \"\", \"\" \"\" \",\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\""}, {"heading": "4.1.2. Temporal-Semantic Ambiguity", "text": "A temporal-semantic ambiguity occurs when two different concepts of two different elements are associated with two different input modalities (E3mod = speech) (with a non-empty time interval section or time intervals that are closer to a threshold) having the same syntactic role. Therefore, these different elements are terminal nodes that have the same parent node in the syntax graph. Let's give the example of the multimodal sentence (E1mod = speech) where the user says through speech: \"This is a flow,\" while she / he draws the following sketch. \"The elements defined by the language modality are: E1 is! (E1mod = speech) E1repetr = (E1time = (E1concept = (deictic))))))! (E1role = (dt = (dt) E2 is!"}, {"heading": "4.1.3. Target Ambiguity", "text": "Finally, the variety of targets appears when the focus of the user is not clear. In particular, it appears when at least two elements can be identified as the user's target, and they share the same role in the structure of the multimodal sentence. Let's assume that the user interacts with an interactive map through language and sketches. (The target audience appears because the user selects two different elements (\"hotel\" and \"restaurant\") with sketchiness (Figure 8)."}, {"heading": "4.2. Syntactic Ambiguities", "text": "Syntactical ambiguities deal with the structure of a multimodal sentence and occur when alternative structures are created for a given set of elements during the interpretation process. If these ambiguities occur, the role that an element of the language plays is not uniquely defined, and the elements of a multimodal sentence (input) can be syntactically combined in more than one way. Considering the syntax graph, this class of ambiguities occurs when a terminal node is not fully defined, or when more than one path on the syntax graph makes it possible to reach the same terminal node. Syntactical ambiguities include gaps, analytical ambiguities, and attachments, which are detailed in the following subsections."}, {"heading": "4.2.1. Gap Ambiguity", "text": "This section begins by analyzing the gap ambiguity that arises when an element of the multimodal sentence is omitted. (As indicated by Futrelle [16], gap ambiguity is often present in diagrams when labels are omitted. Gap ambiguities can be intercepted with both rules on the grammar of language and rules on the context. (Some examples of gap ambiguity appear when the user specifies an action without specifying the object of the action. Moreover, let us assume that context rules associate deictic of the multimodal sentence to a multimodal element!) Let a user interact with a map and say by showing the time intervals in Figure 10, she / he draws the sketch \"referring to a lake."}, {"heading": "4.2.2. Analytic Ambiguity", "text": "Another class of syntactic ambiguities is analytic. It arises when the role of an element is not clearly defined in the multimodal sentence. In this case, the element has more than one possible syntactic role in the multimodal phrase. An example of this ambiguity (widely used in literature for NL) is given by the sentence \"The Tibetan History Teacher\" [15]; it can be interpreted as \"(Tibetan History) Teacher,\" i.e. \"the teacher of Tibetan History,\" or \"the Tibetan Teacher of History.\" Here, a similar example is presented in a map-based context. Let's assume that the multimodal sentence includes sketch and handwriting modalities and the user says that the Italian flow \"and immediately after it writes the word\" syntax of synthesis modality (see Figure 12).This multimodal phrase defines the following syntax graph in Table 2 (c)."}, {"heading": "4.2.3. Attachment Ambiguity", "text": "Given the ambiguity of the appendix, it appears when a prepositional phrase (pp) (pp) can legally be bound to two different parts of the given sentence. Let's consider an example of attachment ambiguity for a multimodal sentence. Let's assume that the user interacts with a map by using the syntax graph in Table 3 (c). The speech demodality elements are: E1 is! (E1mod = speech)! (E1repr) modality (Figure 13). This multimodal sentence defines the syntax graph in Table 3 (c).The speech demodality elements are: E1 is! (E1mod = speech)."}, {"heading": "4.3. Summary of the Multimodal Ambiguities Classification Method", "text": "The characteristics of the different classes of multimodal ambiguities are summarized by the decision tree in Figure 14. Other inductive learning algorithms, such as rule-based induction and Bayesian networks, could have been used in the classification process, but we chose decision tree methods because they allow the recursive division of data into subgroups, the selection of an attribute, and the formulation of a logical test on the attribute. The decision tree represents a classifier of multimodal ambiguities that divides the set of multimodal ambiguities into six subgroups (classes) that are considered attributes: the paths on the syntax graph and the attributes Eimod, Egg-r, Eirole, and Eiconcept.Table 4 provides an overview of the classes of multimodal ambiguities, a brief description of how they can be recognized on the syntax of the multimodal unit, and rules to interpret them."}, {"heading": "5. Multimodal Ambiguities Classifier", "text": "Determining the ambiguity class for a multimodal sentence is the basis for simplifying the ambiguity solution and optimizing the interpretation process. Based on the defined classification, a software module (the Multimodal Ambiguities Classifier Module of Figure 1) was implemented, an internal module of the overall architecture of the Multimodal Language Processing Framework (M2LP) [29], a platform for controlling multimodal communication processes between people and computer systems. The Multimodal Ambiguities Classifier Module identifies the ambiguity classes associated with the ambiguous multimodal sentences based on the rules defined in Section 4.1."}, {"heading": "5.1. Usage of Multimodal Ambiguities Classifier", "text": "This section describes an example of the use of the multimodal ambiguity classifier, taking the example of lexical ambiguity into account. It is entered through an XML file (as shown in Figure 15), which represents a multimodal sentence transmitted by the multimodal loader input. For each ambiguous multimodal sentence, the system starts analyzing the multimodal input. The syntax classifier generates the syntax graph associated with the selected ambiguous multimodal input, and returns the ambiguity class (in this case, the lexical ambiguity class). Figure 16 shows the recognized ambiguity class, the syntax graph, and the specific problem to solve. In the example shown in Figure 16, the NN element has the two different meanings (street and flow) according to the given context; in fact, there is a node of the syntaxgraph that has two successors that relate to the two different concepts of street and ambiguity."}, {"heading": "6. Evaluation of Multimodal Ambiguities Classifier Performance", "text": "The evaluation process of the Multimodal Ambiguities Classifier consists of the analysis of its performance in correctly assigning a multimodal sentence to the ambiguity class. The test set of 520 multimodal sentences used to evaluate the Multimodal Ambiguities Classifier consists of 480 ambiguous multimodal sentences and 40 ambiguous multimodal sentences used for both the syntactical and the semantic test group. A set of unique sentences was introduced to test the system for its inconsistency; the set of 480 ambiguous multimodal sentences consists of: 240 multimodal sentences representing a semantic multimodal ambiguity (80 lexical, 80 temporal-semantic, and 80 ambiguous ambiguities)."}, {"heading": "7. Conclusion", "text": "This paper deals with the problem of ambiguity that characterizes multimodal communication processes from a linguistic perspective and proposes their classification. Critical questions that characterize ambiguities and methods provided by the literature have been identified. In particular, an overview of some relevant studies on ambiguities related to the NL and VLs has been conducted and the most relevant results of these studies have been empirically expanded for multimodal languages. A set of rules has been defined to typify the classes of multimodal ambiguities related to the terms multimodal attribute grammar, terminal elements of the multimodal attribute grammar, multimodal phrase and multimodal language. The proposed set of rules has been defined on the basis of: 1) existing studies on ambiguities, ambiguities, ambiguities, ambiguities, ambiguities and ambiguities."}, {"heading": "8. References", "text": "[1] Coutaz, J., Nigay, L., Salber, D., Blandford, A., May, J. & Young, R., \"Four Easy Pieces forAssessing the Usability of Multimodal Interaction: The CARE Properties.\" in Proceedings of INTERACT '95, Chapman & Hall, pp.115-120, 1995. [2] Oviatt, S. \"Ten Myths of Multimodal Interaction.\" Communication of the ACM. Vol.42 No.11, pp. 74-8, 1999. [3] K\u00f6nig, W.A., R\u00e4dle, R., Reiterer, H. \"Interactive design of multimodal user interfaces.\""}], "references": [{"title": "Four Easy Pieces for Assessing the Usability of Multimodal Interaction: The CARE Properties", "author": ["J. Coutaz", "L. Nigay", "D. Salber", "A. Blandford", "J. May", "R. Young"], "venue": "in Proc. of INTERACT'95, Chapman&Hall,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1995}, {"title": "Interactive design of multimodal user interfaces", "author": ["W.A. K\u00f6nig", "R. R\u00e4dle", "H. Reiterer"], "venue": "Journal on Multimodal User Interfaces. Vol.3 No.3,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2010}, {"title": "A Generic Framework for the Inference of User States in Human Computer Interaction: How patterns of low level communicational cues support complex affective states", "author": ["S. Scherer", "M. Glodek", "M Schels"], "venue": "In Journal on Multimodal User Interfaces, special issue on: Conceptual frameworks for Multimodal Social Signal Processing", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2012}, {"title": "Human Factors and Design Issues in Multimodal (Speech/Gesture) Interface", "author": ["C.J. Lim", "Y. Pan", "J. Lee"], "venue": "JDCTA,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2008}, {"title": "The Medium Is the Massage", "author": ["M. McLuhan", "Q. Fiore"], "venue": "New York: Random House", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1967}, {"title": "Against Ambiguity", "author": ["M. Stacey", "C. Eckert"], "venue": "Computer Supported Cooperative Work 12:", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2003}, {"title": "Making Space for Stories: Ambiguity in the Design of Personal Communication Systems", "author": ["Aoki P. M", "A. Woodruff"], "venue": "Proc. CHI 2005:", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2005}, {"title": "An Implementation of Multimodal User Interface using Speech, Image and EOG", "author": ["Lee", "K.-B", "Jin", "S.-H", "Hong", "K.-S"], "venue": "IJEI,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2011}, {"title": "An Approach for Managing Ambiguities in Multimodal Interaction", "author": ["M.C. Caschera", "F. Ferri", "P. Grifoni"], "venue": "OTM 2007 Ws, Part I,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2007}, {"title": "A design space for multimodal systems: concurrent processing and data fusion", "author": ["L. Nigay", "J. Coutaz"], "venue": "Human Factors in Computing Systems, INTERCHI", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1993}, {"title": "Multimodal Language Specification for Human Adaptive Mechatronics", "author": ["F. Ferri", "A. D\u2019Ulizia", "P. Grifoni"], "venue": "JNIT,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2012}, {"title": "Generating Multimodal Grammars for Multimodal Dialogue Processing", "author": ["A. D\u2019Ulizia", "F. Ferri", "P. Grifoni"], "venue": "IEEE Transactions on Systems, Man and Cybernetics, Part A: Systems and Humans, Vol 40", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2010}, {"title": "InteSe: An Integrated Model for Resolving Ambiguities in Multimodal Sentences", "author": ["M.C. Caschera", "F. Ferri", "P. Grifoni"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics: Systems,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2013}, {"title": "From Contract Drafting to Software Specification: Linguistic Sources of Ambiguity", "author": ["D.M. Berry", "E. Kamsties", "D.G. Kay", "M.M. Krieger"], "venue": "Technical Report,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2001}, {"title": "Ambiguity in Visual Language Theory and its Role in Diagram Parsing", "author": ["R.P. Futrelle"], "venue": "IEEE Symposium on Visual Languages,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1999}, {"title": "Ambiguity detection in multimodal systems", "author": ["M.C. Caschera", "F. Ferri", "P. Grifoni"], "venue": "AVI 2008 - Proceedings of the working conference on Advanced Visual Interfaces May 28-30,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2008}, {"title": "When nouns surface as verbs", "author": ["E.V. Clark", "H.H. Clark"], "venue": "Language, 55,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1979}, {"title": "Three generative, lexicalised models for statistical parsing", "author": ["M. Collins"], "venue": "In Proceedings of the 35th Meeting of the Association for Computational Linguistics and the 7th Conference of the European Chapter of the ACL,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1997}, {"title": "Objects and attention: The state of the art", "author": ["B.J. Scholl"], "venue": "Cognition, 80(1-2),", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2001}, {"title": "About Ambiguities in Visual GIS Query Languages: a Taxonomy and Solutions", "author": ["Favetta", "M.A.F. Aufaure-Portier"], "venue": "Proceedings of the 4th International Conference on Advances in Visual Information Systems,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2000}, {"title": "Formalizing Visual Languages", "author": ["P. Bottoni", "M.F. Costabile", "S. Levialdi", "P. Mussio"], "venue": null, "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1995}, {"title": "The Management of ambiguities\u201d. Visual Languages for Interactive Computing: Definitions and Formalizations", "author": ["M.C. Caschera", "F. Ferri", "P. Grifoni"], "venue": "IGI Publishing", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2007}, {"title": "Linear logic", "author": ["Girard", "J.-Y"], "venue": "Theoretical Computer Science,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1987}, {"title": "Logical form in natural language", "author": ["W. Lycan"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1984}, {"title": "Multimodal interaction systems: information and time features", "author": ["M.C. Caschera", "F. Ferri", "P. Grifoni"], "venue": "International Journal of Web and Grid Services IJWGS,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2007}, {"title": "Toward the Development of an Integrative Framework for Multimodal Dialogue Processing", "author": ["A D'Ulizia", "F. Ferri", "P. Grifoni"], "venue": "OTM 2008 Workshops Proceedings,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2008}], "referenceMentions": [{"referenceID": 0, "context": "Toward this direction, multimodal interaction enables combining different kinds of information, such as visual information involving images, texts, sketches and so on - with voice, gestures and other typical modalities of human-human interaction [1].", "startOffset": 246, "endOffset": 249}, {"referenceID": 1, "context": "[3] provide an approach to support interaction design, while in [4] a generic framework that overcomes many difficulties associated with real world user behaviors analysis, e.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] provide an approach to support interaction design, while in [4] a generic framework that overcomes many difficulties associated with real world user behaviors analysis, e.", "startOffset": 64, "endOffset": 67}, {"referenceID": 3, "context": "The importance of human factors\u2019 role in multimodal interface design is analysed in [5].", "startOffset": 84, "endOffset": 87}, {"referenceID": 4, "context": "Ambiguity is frequently used in an active manner: to negotiate an intended meaning; to identify problems and their solutions; and, afterwards, to refine them [6], [7], [8], making processes more flexible and natural.", "startOffset": 158, "endOffset": 161}, {"referenceID": 5, "context": "Ambiguity is frequently used in an active manner: to negotiate an intended meaning; to identify problems and their solutions; and, afterwards, to refine them [6], [7], [8], making processes more flexible and natural.", "startOffset": 163, "endOffset": 166}, {"referenceID": 6, "context": "Ambiguity is frequently used in an active manner: to negotiate an intended meaning; to identify problems and their solutions; and, afterwards, to refine them [6], [7], [8], making processes more flexible and natural.", "startOffset": 168, "endOffset": 171}, {"referenceID": 7, "context": "in [9].", "startOffset": 3, "endOffset": 6}, {"referenceID": 8, "context": "Our perspective focuses on ambiguities produced both by the propagation at a multimodal level of ambiguities arising by the recognition process of single modality, and by the combination of unambiguous modal information generating contrasting concepts at a multimodal level [10].", "startOffset": 274, "endOffset": 278}, {"referenceID": 9, "context": "Therefore, considering the taxonomy on data fusion methods provided by Nigay and Coutaz [11] on multimodal systems, this paper focuses on ambiguities (at a multimodal level) that arise in systems based on syntactic and semantic fusion.", "startOffset": 88, "endOffset": 92}, {"referenceID": 10, "context": "As shown in Figure 1, the user multimodal inputs are processed by unimodal recognition modules (speech, handwriting, sketch, and so on), and the recognized signals for the various modalities are integrated (Fusion module) [12] and interpreted (Multimodal Interpreter module) according to a multimodal grammar [13].", "startOffset": 222, "endOffset": 226}, {"referenceID": 11, "context": "As shown in Figure 1, the user multimodal inputs are processed by unimodal recognition modules (speech, handwriting, sketch, and so on), and the recognized signals for the various modalities are integrated (Fusion module) [12] and interpreted (Multimodal Interpreter module) according to a multimodal grammar [13].", "startOffset": 309, "endOffset": 313}, {"referenceID": 12, "context": "Then, information about the classified ambiguous input and the set of candidate interpretations are transferred to the Multimodal Ambiguities Solution module; to solve ambiguities it was adopted the module InteSe [14], which selects only one interpretation.", "startOffset": 213, "endOffset": 217}, {"referenceID": 13, "context": "This paper discusses the classification step proposing a new classification that extends and reformulates the ambiguity classifications presented for Natural Language (NL) [15] and Visual Languages (VLs) [16] and evolves previous work on multimodal ambiguities [17].", "startOffset": 172, "endOffset": 176}, {"referenceID": 14, "context": "This paper discusses the classification step proposing a new classification that extends and reformulates the ambiguity classifications presented for Natural Language (NL) [15] and Visual Languages (VLs) [16] and evolves previous work on multimodal ambiguities [17].", "startOffset": 204, "endOffset": 208}, {"referenceID": 15, "context": "This paper discusses the classification step proposing a new classification that extends and reformulates the ambiguity classifications presented for Natural Language (NL) [15] and Visual Languages (VLs) [16] and evolves previous work on multimodal ambiguities [17].", "startOffset": 261, "endOffset": 265}, {"referenceID": 13, "context": "[15] introduced four classes of linguistic ambiguities for NL: lexical, syntactic, semantic and pragmatic ambiguities.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "Homonymy occurs when two words have the same representation but different meanings, while polysemy occurs when a word has different meanings connected to each other, and the process of extension of similar meanings clearly arises [18].", "startOffset": 230, "endOffset": 234}, {"referenceID": 17, "context": "The syntactic structure of the sentence in NL can be represented by a parse tree [19] according to a given formal grammar.", "startOffset": 81, "endOffset": 85}, {"referenceID": 13, "context": ", [15] are classified in: analytic, attachment, coordination and gap ambiguities.", "startOffset": 2, "endOffset": 6}, {"referenceID": 13, "context": "Analytic ambiguities arise when some syntactic role in a sentence is not clearly identified, as for example in the sentence \u201cTibetan history teacher\u201d where two possible interpretations are \u201c(Tibetan history) teacher\u201d and \u201chistory (Tibetan teacher)\u201d [15].", "startOffset": 249, "endOffset": 253}, {"referenceID": 13, "context": "An example of attachment ambiguity is given by the sentence \u201cthe police shot the rioters with guns\u201d that can have two possible interpretations: \u201cthe police shot (the rioters) with guns\u201d and \u201cthe police shot (the rioters with guns)\u201d [15].", "startOffset": 232, "endOffset": 236}, {"referenceID": 13, "context": "As an example, the sentence \u201cPerot knows a richer man than Trump\u201d could have two different meanings: \u201cPerot knows a man who is richer than Trump is\u201d and \u201cPerot knows a man who is richer than any man Trump knows\u201d [15].", "startOffset": 212, "endOffset": 216}, {"referenceID": 13, "context": "Semantic ambiguities appear when a sentence has more than one interpretation, even if neither lexical nor syntactic ambiguities appear in the sentence [15].", "startOffset": 151, "endOffset": 155}, {"referenceID": 13, "context": "\u201cAll linguists prefer a theory\u201d [15]; this sentence can be read either as \u201call linguists love the same one theory\u201d or \u201ceach linguist loves a, perhaps different, theory\u201d.", "startOffset": 32, "endOffset": 36}, {"referenceID": 14, "context": "A classification for VL, which is similar to the classification presented for ambiguities in NL, is provided by Futrelle [16].", "startOffset": 121, "endOffset": 125}, {"referenceID": 18, "context": "The concept of ambiguity for visual information was widely implied in the cultural debate on the Gestalt theory [20].", "startOffset": 112, "endOffset": 116}, {"referenceID": 14, "context": "Futrelle [16] distinguishes between lexical and syntactic ambiguities for VLs, with the meaning previously introduced for NL.", "startOffset": 9, "endOffset": 13}, {"referenceID": 19, "context": "Favetta and Aufaure-Portier [21] defined taxonomy of ambiguities for Visual GIS query languages.", "startOffset": 28, "endOffset": 32}, {"referenceID": 20, "context": "[22].", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "displays) and interprets a Visual Sentence, defined as the composition of simple visual elements (graphemes) [22]; these visual elements can be grouped to form structured visual sentences according to the user\u2019s actions performed to formulate them.", "startOffset": 109, "endOffset": 113}, {"referenceID": 21, "context": "Examples of those classes of visual ambiguities are provided in [23].", "startOffset": 64, "endOffset": 68}, {"referenceID": 22, "context": "The discussion about multimodal ambiguities is based on the definition of Multimodal Attribute Grammar combined with Linear Logic [24], which extends the Classical Logic [25] with the notion of resource and the concept of formulas as resource.", "startOffset": 130, "endOffset": 134}, {"referenceID": 23, "context": "The discussion about multimodal ambiguities is based on the definition of Multimodal Attribute Grammar combined with Linear Logic [24], which extends the Classical Logic [25] with the notion of resource and the concept of formulas as resource.", "startOffset": 170, "endOffset": 174}, {"referenceID": 11, "context": "A Multimodal Attribute Grammar is a context-free and an advanced attribute-based grammar [13], which allows computing derived attributes of non-terminal symbols using computation embedded into the grammar productions.", "startOffset": 89, "endOffset": 93}, {"referenceID": 11, "context": "Therefore, according to its scope, this work uses the production rules of NL, described in [13], for defining the production rules of the syntax of the grammar Pg.", "startOffset": 91, "endOffset": 95}, {"referenceID": 12, "context": "Therefore, a terminal element Ei is defined in [14] as:", "startOffset": 47, "endOffset": 51}, {"referenceID": 24, "context": "their associated temporal intervals have at least a common point or they are separated by a number of points less than an established threshold - [27].", "startOffset": 146, "endOffset": 150}, {"referenceID": 24, "context": "their temporal intervals have common points, according to the definition provided in [27].", "startOffset": 85, "endOffset": 89}, {"referenceID": 24, "context": "The two elements of the previous example are complementary because they are in the CloseBy relation and they define two different concepts that must be used to define a specific target concept [27].", "startOffset": 193, "endOffset": 197}, {"referenceID": 14, "context": "As stated by Futrelle [16], gap ambiguity is frequent in diagrams when labels are omitted.", "startOffset": 22, "endOffset": 26}, {"referenceID": 13, "context": "An example of this ambiguity (widely used in literature for NL) is given by the sentence \u201cThe Tibetan history teacher\u201d [15]; it can be interpreted as \u201c(Tibetan history) teacher\u201d, i.", "startOffset": 119, "endOffset": 123}, {"referenceID": 25, "context": "It is an internal module of the overall architecture of the MultiModal Language Processing framework (M2LP) [29], which is a platform that aims at managing multimodal communication processes between people and computational systems.", "startOffset": 108, "endOffset": 112}, {"referenceID": 12, "context": "The information about the ambiguous sentence, the classified ambiguity and the associated syntaxgraph are transferred to the Multimodal Ambiguities Solution module [14], as Figure 1 shows, in order to provide an unambiguous interpretation of the multimodal sentence.", "startOffset": 164, "endOffset": 168}], "year": 2013, "abstractText": "This paper deals with classifying ambiguities for Multimodal Languages. It evolves the classifications and the methods of the literature on ambiguities for Natural Language and Visual Language, empirically defining an original classification of ambiguities for multimodal interaction using a linguistic perspective. This classification distinguishes between Semantic and Syntactic multimodal ambiguities and their subclasses, which are intercepted using a rule-based method implemented in a software module. The experimental results have achieved an accuracy of the obtained classification compared to the expected one, which are defined by the human judgment, of 94.6% for the semantic ambiguities classes, and 92.1% for the syntactic ambiguities classes.", "creator": "Adobe Acrobat Pro 9.0.0"}}}