{"id": "1704.03016", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Apr-2017", "title": "Automatic semantic role labeling on non-revised syntactic trees of journalistic texts", "abstract": "Semantic Role Labeling (SRL) is a Natural Language Processing task that enables the detection of events described in sentences and the participants of these events. For Brazilian Portuguese (BP), there are two studies recently concluded that perform SRL in journalistic texts. [1] obtained F1-measure scores of 79.6, using the PropBank.Br corpus, which has syntactic trees manually revised, [8], without using a treebank for training, obtained F1-measure scores of 68.0 for the same corpus. However, the use of manually revised syntactic trees for this task does not represent a real scenario of application. The goal of this paper is to evaluate the performance of SRL on revised and non-revised syntactic trees using a larger and balanced corpus of BP journalistic texts. First, we have shown that [1]'s system also performs better than [8]'s system on the larger corpus. Second, the SRL system trained on non-revised syntactic trees performs better over non-revised trees than a system trained on gold-standard data.", "histories": [["v1", "Mon, 10 Apr 2017 19:02:18 GMT  (31kb)", "http://arxiv.org/abs/1704.03016v1", "PROPOR International Conference on the Computational Processing of Portuguese, 2016, 8 pages"]], "COMMENTS": "PROPOR International Conference on the Computational Processing of Portuguese, 2016, 8 pages", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["nathan siegle hartmann", "magali sanches duran", "sandra maria alu\\'isio"], "accepted": false, "id": "1704.03016"}, "pdf": {"name": "1704.03016.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 170 4.03 016v 1 [cs.C L] 10 Apr 201 7the detection of events described in sentences and the participants of these events. Brazilian Portuguese (BP) has two studies that recently concluded that SRL is performed in journalistic texts. [1] obtained F1 readings of 79.6 using the corpus PropBank.Br, which manually revised syntactic trees. [8] The aim of this work is to evaluate the performance of SRLon revised and unrevised syntactic trees against a larger and balanced corpus of BP journalistic texts. First, we have shown that [1] the system also works better than [8] the system of SRLon revised and unrevised syntactic trees using a larger and balanced corpus of BP journalistic texts."}, {"heading": "1 Introduction", "text": "The events are held by predictors such as verbs and eventive names (some nouns, adjectives and adverbs) and the participants are referred to as arguments. This work focuses on verbs. To automatically annotate a text with semantic roles, most current SRL systems use machine learning (ML) techniques. When using ML, the SRL task is generally performed on syntatic trees, due to the extensive set of features identified in the syntactic structure of a sentence as presented by most current SRL systems."}, {"heading": "2 Selection of the Corpora", "text": "In this context, it should be noted that this is a very complex matter."}, {"heading": "3 Manual Annotation of the PB-Br.v2", "text": "In fact, it is such that most of them will be able to move to another world, in which they are able to move to another world, in which they are able to move to another world, in which they are able to move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they, in which they live, in which they live, in which they, in which they, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they, in which they live, in which they live, in which they live, in which they, in which they, in which they live, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they live, in which they, in which they, in which they, in which they, in which they, in which they, live, in which they, in which they, in which they, live, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, live, in which they, in which they, in which they, in which they, in fact, in fact, in fact, are able to put themselves, are able to put themselves, in"}, {"heading": "4 SRL Systems", "text": "Fonseca [8] developed a system for annotating semantic roles in Brazilian Portuguese, avoiding dependence on external NLP tools such as the syntactic parser. His results on revised syntactic trees of the PB-Br.v1 corpus were an F1 measure of 68.0. System performance on revised syntactical trees of the PB-Br.v1 corpus was an F1 measure of 79.6. The main difference between the systems is the use of syntactical features (the former does not use them). Furthermore, none of the systems rated their performance on unrevised syntactic trees of the PB-Br.v1 corpus. The main difference between the systems is the use of syntactical features (the former does not use them)."}, {"heading": "5 Experiments", "text": "In fact, the fact is that most of them will be able to move to another world, in which they are able, in which they are able to integrate, and in which they are able, in which they are able to change the world."}, {"heading": "6 Conclusions", "text": "The results obtained show that an SFL system that responds to syntactical errors and is trained on noisy data (non-revised syntactic trees) performs a better SFL on noisy data than when trained on revised trees (tree bank). We also found that the SFL system achieves better results when tested on the set in which there was full agreement between annotators and lower results when tested on the set in which there were discrepancies between annotators. We did not include a comment mark in PB-Br.v2 to distinguish well-shaped parse trees from those that contained errors in parsing. Therefore, it was not possible to verify whether the presence of parse tactics is correlated to the decrease in annotator agreement rates. However, during the adjustment process we realized that this correlation probably exists and that it would be worth examining this hypothesis in future work."}, {"heading": "Acknowledgments", "text": "Part of the research developed for this work was sponsored by Samsung Eletro Nica da Amazo Nica Ltda. under the terms of Brazilian Federal Law No. 8.248 / 91. Part of the results presented in this paper were obtained through research activities within the framework of the project entitled \"Semantic Processing of Brazilian Portuguese Texts,\" sponsored by Samsung Eletro Nica da Amazo Nica Ltda. under the terms of Brazilian Federal Law No. 8.248 / 91."}], "references": [{"title": "Semantic role labeling for brazilian portuguese: A benchmark", "author": ["F.E. Alva-Manchego", "J.L.G. Rosa"], "venue": "Advances in Artificial Intelligence \u2013 IBERAMIA 2012, Lecture Notes in Computer Science, vol. 7637, pp. 481\u2013490. Springer Berlin Heidelberg", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "The Parsing System \u201cPalavras\u201d: Automatic Grammatical Analysis of Portuguese in a Constraint Grammar Framework", "author": ["E. Bick"], "venue": "Aarhus University Press Aarhus", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2000}, {"title": "Anota\u00e7\u00e3o Ling\u01d8\u0131stica em XML do Corpus PLN-BR", "author": ["M. Bruckschen", "F. Muniz", "J. Souza", "J. Fuchs", "K. Infante", "M. Muniz", "P. Gon\u00e7alves", "R. Vieira", "S. Al\u00fa\u0131sio"], "venue": "NILC\u2013TR\u201309\u201308. Tech. rep., University of S\u00e3o Paulo, Brazil", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2008}, {"title": "Salto \u2013 a versatile multi-level annotation tool", "author": ["A. Burchardt", "K. Erk", "A. Frank", "A. Kowalski", "S. Pado"], "venue": "Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC-2006). pp. 517\u2013520", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2006}, {"title": "Assessing agreement on classification tasks: The kappa statistic", "author": ["J. Carletta"], "venue": "Computacional Linguistics 22(2), 249\u2013254", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1996}, {"title": "Propbank-br: a brazilian treebank annotated with semantic role labels", "author": ["M.S. Duran", "S.M. Al\u00fa\u0131sio"], "venue": "Proceedings of the International Conference on Language Resources and Evaluation (LREC-2012). pp. 1862\u20131867", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2012}, {"title": "Sele\u00e7\u00e3o de senten\u00e7as do c\u00f3rpus PLN-Br para compor o c\u00f3rpus de anota\u00e7\u00e3o de pap\u00e9is sem\u00e2nticos Propbank-Br.v2", "author": ["M.S. Duran", "L. Sep\u00falveda-Torres", "M.C. Viviani", "N.S. Hartmann", "S.M. Al\u00fa\u0131sio"], "venue": "NILC-TR-14-07. Tech. rep.,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "A two-step convolutional neural network approach for semantic role labeling", "author": ["E.R. Fonseca", "J.L.G. Rosa"], "venue": "Neural Networks (IJCNN), The 2013 International Joint Conference on Neural Networks. pp. 1\u20137", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2013}, {"title": "The measurement of observer agreement for categorical data", "author": ["J.R. Landis", "G.G. Koch"], "venue": "Biometrics 33(1), pp. 159\u2013174", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1977}, {"title": "The proposition bank: An annotated corpus of semantic roles", "author": ["M. Palmer", "D. Gildea", "P. Kingsbury"], "venue": "Computational Linguistics 31(1), 71\u2013106", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2005}, {"title": "Semantic role Labeling, Synthesis Lectures on Human Language Technologies, vol", "author": ["M. Palmer", "D. Gildea", "N. Xue"], "venue": "3. Morgan & Claypool Publishers", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2010}, {"title": "A global joint model for semantic role labeling", "author": ["K. Toutanova", "A. Haghighi", "C.D. Manning"], "venue": "Computational Linguistics 34(2), 161\u2013191", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2008}], "referenceMentions": [{"referenceID": 0, "context": "[1] obtained F1-measure scores of 79.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "manually revised; [8], without using a treebank for training, obtained F1-measure scores of 68.", "startOffset": 18, "endOffset": 21}, {"referenceID": 0, "context": "First, we have shown that [1]\u2019s system also performs better than [8]\u2019s system on the larger", "startOffset": 26, "endOffset": 29}, {"referenceID": 7, "context": "First, we have shown that [1]\u2019s system also performs better than [8]\u2019s system on the larger", "startOffset": 65, "endOffset": 68}, {"referenceID": 10, "context": "Semantic Role Labelling (SRL) is a Natural Language Processing (NLP) task responsible for detecting events described in sentences and the participants of these events [11].", "startOffset": 167, "endOffset": 171}, {"referenceID": 10, "context": "When using ML, the SRL task is generally performed on syntatic trees due to the extensive set of features that have been identified in the syntactic structure of a sentence, such as those presented by [11].", "startOffset": 201, "endOffset": 205}, {"referenceID": 0, "context": "For Brazilian Portuguese SRL, the best performance was obtained by [1], with F1-measure scores of 79.", "startOffset": 67, "endOffset": 70}, {"referenceID": 7, "context": "In this sense, Fonseca\u2019s work [8], following an approach that does not use syntactic features, obtained F1-measure scores of 68.", "startOffset": 30, "endOffset": 33}, {"referenceID": 1, "context": "The syntactic trees of both corpora were generated by the PALAVRAS parser [2].", "startOffset": 74, "endOffset": 77}, {"referenceID": 5, "context": "1 [6], referred to as PB-Br.", "startOffset": 2, "endOffset": 5}, {"referenceID": 2, "context": "v1 and a selection of the PLN-Br, corpus of texts from Folha de S\u00e3o Paulo [3], referred to as PB-Br.", "startOffset": 74, "endOffset": 77}, {"referenceID": 6, "context": "v2 can be found in [7].", "startOffset": 19, "endOffset": 22}, {"referenceID": 9, "context": "v2, following the annotation of the PropBank project [10], but based on annotation guidelines customized to the Portuguese language enriched with wrong syntactic trees annotation process.", "startOffset": 53, "endOffset": 57}, {"referenceID": 3, "context": "Furthermore, Tiger XML syntactic trees can be processed with the SALTO tool [4] that was used in annotating the corpus in question.", "startOffset": 76, "endOffset": 79}, {"referenceID": 4, "context": "After concluding the annotation, we calculated the Kappa statistics [5].", "startOffset": 68, "endOffset": 71}, {"referenceID": 8, "context": "The set of verbs that require clausal complements obtained important Kappa results, considered almost perfect by the Kappa scale of Landis and Koch [9].", "startOffset": 148, "endOffset": 151}, {"referenceID": 7, "context": "Fonseca [8] developed a system for annotation of semantic roles for Brazilian Portuguese, avoiding dependence on external NLP tools, such as syntactic parser.", "startOffset": 8, "endOffset": 11}, {"referenceID": 0, "context": "The work of Alva-Manchego [1], which uses the PB-Br.", "startOffset": 26, "endOffset": 29}, {"referenceID": 0, "context": "We used Alva-Manchego\u2019s system [1] in most experiments because it is the state-of-art system in SRL for Brazilian Portuguese.", "startOffset": 31, "endOffset": 34}, {"referenceID": 7, "context": "We also used Fonseca\u2019s system [8] in a final experiment to contrast its performance with the one of Alva-Manchego\u2019s system.", "startOffset": 30, "endOffset": 33}, {"referenceID": 9, "context": "0 F1 scores between a system trained on revised trees and on non-revised trees has already been investigated by [10] and [12] for the English language.", "startOffset": 112, "endOffset": 116}, {"referenceID": 11, "context": "0 F1 scores between a system trained on revised trees and on non-revised trees has already been investigated by [10] and [12] for the English language.", "startOffset": 121, "endOffset": 125}, {"referenceID": 7, "context": "We also noted that Fonseca\u2019s system [8] performs a SRL inferior to Alva-Manchego\u2019s [1], even in an unfavorable scenario for the latter system.", "startOffset": 36, "endOffset": 39}, {"referenceID": 0, "context": "We also noted that Fonseca\u2019s system [8] performs a SRL inferior to Alva-Manchego\u2019s [1], even in an unfavorable scenario for the latter system.", "startOffset": 83, "endOffset": 86}], "year": 2017, "abstractText": "Semantic Role Labeling (SRL) is a Natural Language Processing task that enables the detection of events described in sentences and the participants of these events. For Brazilian Portuguese (BP), there are two studies recently concluded that perform SRL in journalistic texts. [1] obtained F1-measure scores of 79.6, using the PropBank.Br corpus, which has syntactic trees manually revised; [8], without using a treebank for training, obtained F1-measure scores of 68.0 for the same corpus. However, the use of manually revised syntactic trees for this task does not represent a real scenario of application. The goal of this paper is to evaluate the performance of SRL on revised and non-revised syntactic trees using a larger and balanced corpus of BP journalistic texts. First, we have shown that [1]\u2019s system also performs better than [8]\u2019s system on the larger corpus. Second, the SRL system trained on non-revised syntactic trees performs better over nonrevised trees than a system trained on gold-standard data.", "creator": "LaTeX with hyperref package"}}}