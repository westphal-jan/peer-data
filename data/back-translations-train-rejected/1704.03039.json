{"id": "1704.03039", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Apr-2017", "title": "Semantically Consistent Regularization for Zero-Shot Recognition", "abstract": "The role of semantics in zero-shot learning is considered. The effectiveness of previous approaches is analyzed according to the form of supervision provided. While some learn semantics independently, others only supervise the semantic subspace explained by training classes. Thus, the former is able to constrain the whole space but lacks the ability to model semantic correlations. The latter addresses this issue but leaves part of the semantic space unsupervised. This complementarity is exploited in a new convolutional neural network (CNN) framework, which proposes the use of semantics as constraints for recognition.Although a CNN trained for classification has no transfer ability, this can be encouraged by learning an hidden semantic layer together with a semantic code for classification. Two forms of semantic constraints are then introduced. The first is a loss-based regularizer that introduces a generalization constraint on each semantic predictor. The second is a codeword regularizer that favors semantic-to-class mappings consistent with prior semantic knowledge while allowing these to be learned from data. Significant improvements over the state-of-the-art are achieved on several datasets.", "histories": [["v1", "Mon, 10 Apr 2017 19:59:33 GMT  (1689kb,D)", "http://arxiv.org/abs/1704.03039v1", "Accepted to CVPR 2017"]], "COMMENTS": "Accepted to CVPR 2017", "reviews": [], "SUBJECTS": "cs.CV cs.AI cs.LG", "authors": ["pedro morgado", "nuno vasconcelos"], "accepted": false, "id": "1704.03039"}, "pdf": {"name": "1704.03039.pdf", "metadata": {"source": "CRF", "title": "Semantically Consistent Regularization for Zero-Shot Recognition", "authors": ["Pedro Morgado", "Nuno Vasconcelos"], "emails": ["pmaravil@ucsd.edu", "nuno@ucsd.edu"], "sections": [{"heading": "1. Introduction", "text": "The main limitation of this approach is the effort required to 1) collect and comment on millions of images necessary to train these models, and 2) describe the complexity of training a CNN from scratch. Indeed, there is an interest in transfer learning techniques, for which this work was funded by graduates of the Fellowship. SFRH / BD / 109135 / 2015 from the Portuguese Ministry of Science and Education and NRI grants IIS-1208522 and IIS-1637941 from the National Science Foundation.a model is used to identify object classes that are not represented in it."}, {"heading": "2. Previous Work", "text": "Semantics semantics are visual descriptions that convey a meaning over an image x-X, and can include any measurable visual property: discrete or continuous, numerical or categorical. In the face of a semantic vocabulary V = {v1,.., SVQ}, a semantic attribute space S is defined as a Cartesian product of vector spaces containing visual attributes, e.g. V [furry, has legs, is brown, etc.}, is usually defined along with their corresponding vector spaces. As an example of animal recognition, a semantic vocabulary is used that contains visual attributes, e.g. V {furry, has legs, is brown, etc.}, which is defined along with their corresponding vector spaces. In this case, since all semantics are binary, Sk = R, where large positive values indicate the attribute presence and large negative values indicate their absence is recognized as early image classes for [to be used]."}, {"heading": "3. Semantics and deep learning", "text": "We will now discuss the CNN implementation of RIS and RULE. For simplicity, we will start with attribute semantics. Sections 5 and 6 extend the treatment to other concepts. For quick consultation, Table 1 summarizes important notations used in the rest of the essay."}, {"heading": "3.1. Deep-RIS", "text": "Under the assumption of independence underlying the RIS, the CNN implementation is reduced to Q-independent attribute predictors. Inspired by the success of multitasking learning, it is advantageous to share CNN parameters across attributes and to rely on a common trait that the parameter extractor \u03b8 (x; \u044b) extracts, which can be implemented with one of the popular CNNs in literature. Thus, each attribute predictor ak of Deep-RIS takes the fork (x; tk, \u044b) = \u03c3 (tTk) (x; \u044b) (2), where \u03c3 (\u00b7) is the sigmoid function and tk is a parameter vector. In the face of a training set D = {(x (i), s (i) Ni = 1}, with s (s (i) 1,."}, {"heading": "3.2. Deep-RULE", "text": "The implementation of RULE results directly from the bilinear form of (1). Note that \u03c6 (y) is a fixed mapping from the space of the attributes to the space of the class labels. For example, if there are Q binary attributes and C class labels, \u03c6 (y) is a Q dimensional vector indicating the presence / absence of the Q attributes in the class y\u03c6k (y) = {1 if class y contains the attribute k, \u2212 1 if class y lacks the attribute k. (4) We denote \u03c6 (y) the semantic code of class y. To translate (1) into a CNN, it is sufficient to use one of the popular models to calculate the inequality (x), typically add a completely connected layer of Q units and parameters T, so that a (x) = TT terminal (x; \u0432) is a vector of the attribute values, define the Tputsh, and the Tputa class (T) (x)."}, {"heading": "3.3. Relationships", "text": "Both Deep-RIS and Deep-RULE have advantages and disadvantages, which can be observed by comparing the risks of (3) and (6). Since the attributes ak (x) are the quantities of interest to ZSL, it is useful to understand how the two methods monitor the space A of the attributes. Of (3), Deep-RIS monitors the individual attributes ak (x). Since ak (\u00b7) = 1Tk a (\u00b7), where 1k is the kste vector in the Canonic base (1 in the Definitions Position and 0 elsewhere), the supervision along the Canonical directions of A. On the other hand, (5) - (6) only the attributes Ta (x) is the kste vector in the Canonical base (\u00b7) (Definitions), the definitions of definitions of definitions of definitions of definitions of definitions of definitions of definitions of definitions of definitions of definitions of definitions of definitions of definitions of definitions of definitions of definitions of definitions of definitions of definitions of definitions of definitions of definitions of definitions of definitions of definitions of definitions of definitions of definitions of definitions of definitions of definitions of definitions of (\u00b7)."}, {"heading": "4. Semantically consistent regularization", "text": "In this section we present the Semantically COnsistent REgularizer (SCoRe) architecture."}, {"heading": "4.1. Attributes as regularization constraints", "text": "In the previous section, we have seen that the relative performance of Deep-RIS and Deep-RULE depends on the alignment between the sub-ranges of A \"that define the education and ZS classes, A\" T and A \"ZS. Ideally, A\" T = A \"and so \u03c6ZS (c)\" A \"T for each ZS class c. However, this is unlikely to happen for records of tractable size, and the sub-sets A\" T and A \"ZS are most likely not in agreement. In this scenario, Deep-RIS and Deep-RULE complement each other. While Deep-RULE places primary constraints on the statistics of individual attributes, Deep-RULE forces second-order constraints by limiting the statistics of linear attribute combinations. When the two strategies are combined, Deep-RULE can explain the attribute dependencies that occur on both the US and on the ZS-LE assignment of the ZS and RULE-RULE assignments."}, {"heading": "4.2. Recognition and regularization", "text": "An object recognition system maps an image x in a classically complex form in which it is a vector of confidence values for the mapping of x to each class, the function h (x) = (h1 (x),.., hC (x) being a vector of confidence values for the mapping of x to each class, and y) the class prediction. The score function h (\u00b7) is usually learned by minimizing an empirical risk RE [h] under a complexity constraint in order to improve generalization, i.e., the function h = arg min h RE [h] + (8), which is a lagrange multiplier, and a regulator, which favors score functions of low complexity. Frequent uses of scores [\u00b7 h] include shrinkage [22], sparse representations [11] or weight degradation [29], as all of these approaches are easy to adapt to the low complexity of the object."}, {"heading": "4.3. Codeword regularization", "text": "The first mechanism takes advantage of the fact that the score functions of (7) always depend on the formhc (x) = = < wc, f (x) >, (9) where < \u00b7, \u00b7 > denotes an internal product, f (\u00b7) denotes a predictor, and (w1,.., wC) denotes a set of code words of the positive / negative class. We refer to wc as classification code of class C. In binary classification, for example, algorithms such as the increase [15] or SVM [12] simply rely on 1 / \u2212 1 as codewords of the positive / negative class. Similarly, for C-ary classification we use neural networks [33] or multi-class SVMs [59] on one-hot encodings that lead to the typical decision rule y-1."}, {"heading": "4.4. Loss-based regularization", "text": "The second mechanism, loss-based regularization, aims to limit attributes beyond A \u2032 T and provides explicit regularization for attribute predictions. It is implemented by introducing an auxiliary risk RA [f] into optimization, i.e. replacing RE [h] in (8) with RE [h] + \u03bbRA [f], where RA [f] is the sum of the attribute predictive risks of (3)."}, {"heading": "4.5. SCoRe", "text": "Faced with a training set of images x (\u03b2 Re), attribute markers (s (i) 1,.., s (i) Q) and class markers y (i), the regulators of the preceding sections are combined to form the SCoRe objective minimize., T, W \u2211 i L (h (x (i); W, T, HB), y (i) + \u03bb i-K Lb (fk (x (i); tk, i), s (i) k) + \u03b2 [W], (13), where h (\u00b7) by (10), fk (x; tk) = tTk \u03b8 (x) is the lowest semantic predictor. [W] is the code wording regulator of (11) and \u03b2Lagrange multipliers controlling the tightness of the regulatory restrictions."}, {"heading": "5. Semantics", "text": "In this section we discuss the encoding of different semantics within the SCoRe framework."}, {"heading": "5.1. Attributes", "text": "Until now, we assumed semantics to be binary attributes; each attribute is mapped to an entry in the semantic code according to (4), which is used to represent each class, i.e. \u03c6 (y) = concat (\u03c61 (y),..., \u03c6Q (y)). (14) To support a different degree of security with respect to class / attribute associations, continuous attributes can also be easily implemented by making \u03c6k (y) \u0432 [\u2212 1, 1]."}, {"heading": "5.2. Beyond binary semantics", "text": "In this case, it is that it is a semantic system, in which the individual persons are able to identify themselves. (...) It is also that it is a system in which the individual persons are able to identify themselves. (...) It is as if it is a system in which the individual persons are able to identify themselves. (...) It is as if it is a system, as if it is a system. (...) It is as if it is a system, as if it is a system, as if it is a system, as if it is a system, as if it is a system. \"(...) It is as if it is a system.\" (...) It is as if it is a system, as if it is a system. \""}, {"heading": "6. Deep-SCoRe", "text": "Deep-SCoRe implements (10) using a CNN to calculate \u03b8 (x; x). Re-Q (Q) for all states (SE) are learned from (13), using a semantic code that combines various semantic statecodeword sentences V (k), which may be relative to attributes, taxonomy nodes, Word2Vec mappings, or any other semantic encoding. Of (9), decompose class results intohc (x) = CNN h (k) c (x). (k) sck (k) sck) sck (x) > (16), where sck is the state of k th semantic class c, w (k) sck the corresponding codeword, and fk (\u00b7) the corresponding subspace of f (\u00b7). Semantic predictions are achieved by computing dot-productsu (x) i (x)."}, {"heading": "7. Experiments", "text": "In this section we will discuss several experiments performed to evaluate the ZSL performance of DeepSCoRe. Source code is available at https: / / github.com / pedro-morgado / score-zeroshot."}, {"heading": "7.1. Experimental setup", "text": "Datasets: Three datasets were considered: Animals with attributes [31] (AwA) (AwA), Caltech-UCSD Birds 200-2011 [57] (CUB), and a subset of the Imaging FlowCytobot [52] (IFCB) dataset. Table 2 summarizes their statistics. On AwA and CUB, the division into source and target classes for ZSL is given as by [31] and [2] respectively. On IFCB, which is now used for the first time for ZSL, classes were randomly divided. A separate set of validation classes (10 / 50 / 6 for the AwA / CUB / IFCB datasets were also randomly drawn to tune SCoRe parameters. Image representation: Images were reduced to 256 \u00d7 256 pixels, with the exception of IFCB, where image formats were kept on WFCB."}, {"heading": "7.2. Results", "text": "The importance of the two regulators was assessed separately on all datasets with visual attributes and GoogLeNet. In both cases, we measured the gains over deep-RULE in which the classification codewords are set to wc = \u03c6 (c) and \u03bb = 0. Losses-based regulation gains were assessed by increasing the number of classes, while classification classes were converted to \u03b2 = 0. In this case, classification convergence converts to deep-RIS in limiting the number of words in which the codeword regulations were measured. Conversely, gains in codeword regulation were measured by increasing \u03b2-values, while classification classes are converted to \u03b2 = 0 and to deep-RULE. Figure 4 presents the absolute improvement in ZS class accuracy (ZS-MCA) as a function of lagrange multipliers.Both results are achieved by high gains."}, {"heading": "8. Conclusion", "text": "The complementarity between class and semantic supervision led to the introduction of a new ZSL method called SCoRe, in which a CNN is learned along with a semantic codeword set and two forms of semantic constraints: loss-based and codeword regulation. State-of-the-art zero-shot performance was achieved in various datasets."}], "references": [{"title": "Multicue zero-shot learning with strong supervision", "author": ["Z. Akata", "M. Malinowski", "M. Fritz", "B. Schiele"], "venue": "Computer Vision and Pattern Recognition (CVPR), IEEE Conf. on", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2016}, {"title": "Labelembedding for attribute-based classification", "author": ["Z. Akata", "F. Perronnin", "Z. Harchaoui", "C. Schmid"], "venue": "Computer Vision and Pattern Recognition (CVPR), IEEE Conf. on", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2013}, {"title": "Labelembedding for image classification", "author": ["Z. Akata", "F. Perronnin", "Z. Harchaoui", "C. Schmid"], "venue": "Pattern Analysis and Machine Intelligence (TPAMI), IEEE Trans. on, 38(7):1425\u2013 1438", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2016}, {"title": "Evaluation of output embeddings for fine-grained image classification", "author": ["Z. Akata", "S. Reed", "D. Walter", "H. Lee", "B. Schiele"], "venue": "Computer Vision and Pattern Recognition (CVPR), IEEE Conf. on", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2015}, {"title": "How to transfer? Zeroshot object recognition via hierarchical transfer of semantic attributes", "author": ["Z. Al-Halah", "R. Stiefelhagen"], "venue": "Applications of Computer Vision, IEEE Winter Conf. on", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2015}, {"title": "Recovering the missing link: Predicting class-attribute associations for unsupervised zero-shot learning", "author": ["Z. Al-Halah", "M. Tapaswi", "R. Stiefelhagen"], "venue": "Computer Vision and Pattern Recognition (CVPR), IEEE Conf. on", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2016}, {"title": "Phytopedia - the phytoplankton encyclpaedia project", "author": ["D. Cassis"], "venue": "Available at: http://www.eos.ubc.ca/research/ phytoplankton/", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2015}, {"title": "Synthesized classifiers for zero-shot learning", "author": ["S. Changpinyo", "W.-L. Chao", "B. Gong", "F. Sha"], "venue": "Computer Vision and Pattern Recognition (CVPR), IEEE Conf. on", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2016}, {"title": "Inferring analogous attributes", "author": ["C.-Y. Chen", "K. Grauman"], "venue": "Computer Vision and Pattern Recognition (CVPR), IEEE Conf. on", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Describing clothing by semantic attributes", "author": ["H. Chen", "A. Gallagher", "B. Girod"], "venue": "Computer Vision (ECCV), European Conf. on", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}, {"title": "Sparse representation", "author": ["H. Cheng"], "venue": "modeling and learning in visual recognition. Springer", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2015}, {"title": "Support-vector networks", "author": ["C. Cortes", "V. Vapnik"], "venue": "Machine learning, 20(3):273\u2013297", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1995}, {"title": "ImageNet: A large-scale hierarchical image database", "author": ["J. Deng", "W. Dong", "R. Socher", "L.-J. Li", "K. Li", "L. Fei- Fei"], "venue": "Computer Vision and Pattern Recognition (CVPR), IEEE Conf. on", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2009}, {"title": "Describing objects by their attributes", "author": ["A. Farhadi", "I. Endres", "D. Hoiem", "D. Forsyth"], "venue": "Computer Vision and Pattern Recognition (CVPR), IEEE Conf. on", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2009}, {"title": "A desicion-theoretic generalization of on-line learning and an application to boosting", "author": ["Y. Freund", "R.E. Schapire"], "venue": "Computational Learning Theory, European Conf. on. Springer", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1995}, {"title": "et al", "author": ["A. Frome", "G.S. Corrado", "J. Shlens", "S. Bengio", "J. Dean", "T. Mikolov"], "venue": "Devise: A deep visual-semantic embedding model. In Advances in Neural Information Processing Systems (NIPS)", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2013}, {"title": "Transductive multi-view zero-shot recognition and annotation", "author": ["Y. Fu", "T.M. Hospedales", "T. Xiang", "S. Gong"], "venue": "Computer Vision (ECCV), European Conf. on", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2014}, {"title": "Transductive multi-view zero-shot learning", "author": ["Y. Fu", "T.M. Hospedales", "T. Xiang", "S. Gong"], "venue": "Pattern Analysis and Machine Intelligence (TPAMI), IEEE Trans. on, 37(11):2332\u2013 2345", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2015}, {"title": "Semi-supervised vocabulary-informed learning", "author": ["Y. Fu", "L. Sigal"], "venue": "Computer Vision and Pattern Recognition (CVPR), IEEE Conf. on", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2016}, {"title": "Zero-shot object recognition by semantic manifold distance", "author": ["Z. Fu", "T. Xiang", "E. Kodirov", "S. Gong"], "venue": "Computer Vision and Pattern Recognition (CVPR), IEEE Conf. on", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning attributes equals multi-source domain generalization", "author": ["C. Gan", "T. Yang", "B. Gong"], "venue": "Computer Vision and Pattern Recognition (CVPR), IEEE Conf. on", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2016}, {"title": "Improving Efficiency by Shrinkage: The James\u2013 Stein and Ridge Regression Estimators", "author": ["M. Gruber"], "venue": "volume 156. CRC Press", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1998}, {"title": "Learning hypergraph-regularized attribute predictors", "author": ["S. Huang", "M. Elhoseiny", "A. Elgammal", "D. Yang"], "venue": "arXiv", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2015}, {"title": "Sharing features between objects and their attributes", "author": ["S.J. Hwang", "F. Sha", "K. Grauman"], "venue": "Computer Vision and Pattern Recognition (CVPR), IEEE Conf. on, pages 1761\u2013 1768", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2011}, {"title": "Zero-shot recognition with unreliable attributes", "author": ["D. Jayaraman", "K. Grauman"], "venue": "Advances in Neural Information Processing Systems (NIPS)", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2014}, {"title": "Caffe: Convolutional architecture for fast feature embedding", "author": ["Y. Jia", "E. Shelhamer", "J. Donahue", "S. Karayev", "J. Long", "R. Girshick", "S. Guadarrama", "T. Darrell"], "venue": "arXiv:1408.5093", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2014}, {"title": "Unsupervised domain adaptation for zero-shot learning", "author": ["E. Kodirov", "T. Xiang", "Z. Fu", "S. Gong"], "venue": "Computer Vision and Pattern Recognition (CVPR), IEEE Conf. on", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2015}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "Advances in Neural Information Processing Systems (NIPS)", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2012}, {"title": "A simple weight decay can improve generalization", "author": ["A. Krogh", "J.A. Hertz"], "venue": "Advances in Neural Information Processing Systems (NIPS)", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1991}, {"title": "Attribute and simile classifiers for face verification", "author": ["N. Kumar", "A.C. Berg", "P.N. Belhumeur", "S.K. Nayar"], "venue": "Computer Vision (ICCV), IEEE International Conf. on", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2009}, {"title": "Learning to detect unseen object classes by between-class attribute transfer", "author": ["C.H. Lampert", "H. Nickisch", "S. Harmeling"], "venue": "Computer Vision and Pattern Recognition (CVPR), IEEE Conf. on", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2009}, {"title": "Attributebased classification for zero-shot visual object categorization", "author": ["C.H. Lampert", "H. Nickisch", "S. Harmeling"], "venue": "Pattern Analysis and Machine Intelligence (TPAMI), IEEE Trans. on, 36(3)", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2013}, {"title": "Convolutional networks for images", "author": ["Y. LeCun", "Y. Bengio"], "venue": "speech, and time series. The handbook of brain theory and neural networks, 3361(10)", "citeRegEx": "33", "shortCiteRegEx": null, "year": 1995}, {"title": "Object bank: A high-level image representation for scene classification & semantic feature sparsification", "author": ["L.-J. Li", "H. Su", "L. Fei-Fei", "E.P. Xing"], "venue": "Advances in Neural Information Processing Systems (NIPS)", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2010}, {"title": "Max-margin zero-shot learning for multiclass classification", "author": ["X. Li", "Y. Guo"], "venue": "Artificial Intelligence and Statistics (ICAIS), International Conf. on", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2015}, {"title": "Semi-supervised zero-shot classification with label representation learning", "author": ["X. Li", "Y. Guo", "D. Schuurmans"], "venue": "Computer Vision (ICCV), IEEE International Conf. on", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2015}, {"title": "A unified multiplicative framework for attribute learning", "author": ["K. Liang", "H. Chang", "S. Shan", "X. Chen"], "venue": "Computer Vision (ICCV), IEEE International Conf. on", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2015}, {"title": "World Register of Marine Species (WoRMS)", "author": ["J. Mees", "G. Boxshall", "M. Costello"], "venue": "Available at: http://www. marinespecies.org", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2016}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["T. Mikolov", "I. Sutskever", "K. Chen", "G.S. Corrado", "J. Dean"], "venue": "Advances in Neural Information Processing Systems (NIPS)", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2013}, {"title": "WordNet: A lexical database for English", "author": ["G.A. Miller"], "venue": "Communications of the ACM, 38(11):39\u201341", "citeRegEx": "40", "shortCiteRegEx": null, "year": 1995}, {"title": "Zero-shot learning by convex combination of semantic embeddings", "author": ["M. Norouzi", "T. Mikolov", "S. Bengio", "Y. Singer", "J. Shlens", "A. Frome", "G.S. Corrado", "J. Dean"], "venue": "arXiv:1312.5650", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2013}, {"title": "Relative attributes", "author": ["D. Parikh", "K. Grauman"], "venue": "Computer Vision (ICCV), IEEE International Conf. on", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2011}, {"title": "and A", "author": ["R. Qiao", "L. Liu", "C. Shen"], "venue": "v. d. Hengel. Less is more: zero-shot learning from online textual documents with noise suppression. In Computer Vision and Pattern Recognition (CVPR), IEEE Conf. on", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2016}, {"title": "Bridging the gap: Query by semantic example", "author": ["N. Rasiwasia", "P.J. Moreno", "N. Vasconcelos"], "venue": "Multimedia, IEEE Trans. on, 9(5):923\u2013938", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2007}, {"title": "Holistic context models for visual recognition", "author": ["N. Rasiwasia", "N. Vasconcelos"], "venue": "Pattern Analysis and Machine Intelligence (TPAMI), IEEE Trans. on, 34(5):902\u2013917", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2012}, {"title": "Attribute discovery via predictable discriminative binary codes", "author": ["M. Rastegari", "A. Farhadi", "D. Forsyth"], "venue": "Computer Vision (ECCV), European Conf. on", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2012}, {"title": "Learning deep representations of fine-grained visual descriptions", "author": ["S. Reed", "Z. Akata", "B. Schiele", "H. Lee"], "venue": "Computer Vision and Pattern Recognition (CVPR), IEEE Conf. on", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2016}, {"title": "Evaluating knowledge transfer and zero-shot learning in a large-scale setting", "author": ["M. Rohrbach", "M. Stark", "B. Schiele"], "venue": "Computer Vision and Pattern Recognition (CVPR), IEEE Conf. on", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2011}, {"title": "An embarrassingly simple approach to zero-shot learning", "author": ["B. Romera-Paredes", "P. Torr"], "venue": "Machine Learning (ICCV), International Conf. on, pages 2152\u20132161", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2015}, {"title": "Multiclass boosting: Theory and algorithms", "author": ["M.J. Saberian", "N. Vasconcelos"], "venue": "Advances in Neural Information Processing Systems (NIPS)", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2011}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["K. Simonyan", "A. Zisserman"], "venue": "arXiv preprint arXiv:1409.1556", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2014}, {"title": "Automated taxonomic classification of phytoplankton sampled with imaging-in-flow cytometry", "author": ["H.M. Sosik", "R.J. Olson"], "venue": "Limnology and Oceanography: Methods, 5(6):204\u2013 216", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2007}, {"title": "Improving object classification using semantic attributes", "author": ["Y. Su", "M. Allan", "F. Jurie"], "venue": "British Machine Vision Conference (BMVC)", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2010}, {"title": "Going deeper with convolutions", "author": ["C. Szegedy", "W. Liu", "Y. Jia", "P. Sermanet", "S. Reed", "D. Anguelov", "D. Erhan", "V. Vanhoucke", "A. Rabinovich"], "venue": "arXiv preprint arXiv:1409.4842", "citeRegEx": "54", "shortCiteRegEx": null, "year": 2014}, {"title": "Efficient object category recognition using classemes", "author": ["L. Torresani", "M. Szummer", "A. Fitzgibbon"], "venue": "Computer Vision (ECCV), European Conf. on", "citeRegEx": "55", "shortCiteRegEx": null, "year": 2010}, {"title": "Semantic modeling of natural scenes for content-based image retrieval", "author": ["J. Vogel", "B. Schiele"], "venue": "Computer Vision, International Journal of, 72(2):133\u2013157", "citeRegEx": "56", "shortCiteRegEx": null, "year": 2007}, {"title": "The Caltech-UCSD Birds-200-2011 Dataset", "author": ["C. Wah", "S. Branson", "P. Welinder", "P. Perona", "S. Belongie"], "venue": "Technical Report CNS-TR-2011-001, California Institute of Technology", "citeRegEx": "57", "shortCiteRegEx": null, "year": 2011}, {"title": "A unified probabilistic approach modeling relationships between attributes and objects", "author": ["X. Wang", "Q. Ji"], "venue": "Computer Vision (ICCV), IEEE International Conf. on", "citeRegEx": "58", "shortCiteRegEx": null, "year": 2013}, {"title": "Multi-class support vector machines", "author": ["J. Weston", "C. Watkins"], "venue": "Technical report, Citeseer", "citeRegEx": "59", "shortCiteRegEx": null, "year": 1998}, {"title": "Latent embeddings for zero-shot classification", "author": ["Y. Xian", "Z. Akata", "G. Sharma", "Q. Nguyen", "M. Hein", "B. Schiele"], "venue": "Computer Vision and Pattern Recognition (CVPR), IEEE Conf. on", "citeRegEx": "60", "shortCiteRegEx": null, "year": 2016}, {"title": "Zero-shot learning via semantic similarity embedding", "author": ["Z. Zhang", "V. Saligrama"], "venue": "Computer Vision and Pattern Recognition (CVPR), IEEE Conf. on", "citeRegEx": "61", "shortCiteRegEx": null, "year": 2015}], "referenceMentions": [{"referenceID": 27, "context": "In fact, most recent computer vision papers use or adapt a small set of popular models, such as AlexNet [28], GoogLeNet [54], and VGG [51], learned from the Imagenet dataset [13].", "startOffset": 104, "endOffset": 108}, {"referenceID": 53, "context": "In fact, most recent computer vision papers use or adapt a small set of popular models, such as AlexNet [28], GoogLeNet [54], and VGG [51], learned from the Imagenet dataset [13].", "startOffset": 120, "endOffset": 124}, {"referenceID": 50, "context": "In fact, most recent computer vision papers use or adapt a small set of popular models, such as AlexNet [28], GoogLeNet [54], and VGG [51], learned from the Imagenet dataset [13].", "startOffset": 134, "endOffset": 138}, {"referenceID": 12, "context": "In fact, most recent computer vision papers use or adapt a small set of popular models, such as AlexNet [28], GoogLeNet [54], and VGG [51], learned from the Imagenet dataset [13].", "startOffset": 174, "endOffset": 178}, {"referenceID": 33, "context": "This has motivated the introduction of semantic representations for object recognition [34, 44, 45, 55, 56], which rely on a predefined vocabulary of visual concepts to define a semantic space S and a set of classifiers to map each image into that space.", "startOffset": 87, "endOffset": 107}, {"referenceID": 43, "context": "This has motivated the introduction of semantic representations for object recognition [34, 44, 45, 55, 56], which rely on a predefined vocabulary of visual concepts to define a semantic space S and a set of classifiers to map each image into that space.", "startOffset": 87, "endOffset": 107}, {"referenceID": 44, "context": "This has motivated the introduction of semantic representations for object recognition [34, 44, 45, 55, 56], which rely on a predefined vocabulary of visual concepts to define a semantic space S and a set of classifiers to map each image into that space.", "startOffset": 87, "endOffset": 107}, {"referenceID": 54, "context": "This has motivated the introduction of semantic representations for object recognition [34, 44, 45, 55, 56], which rely on a predefined vocabulary of visual concepts to define a semantic space S and a set of classifiers to map each image into that space.", "startOffset": 87, "endOffset": 107}, {"referenceID": 55, "context": "This has motivated the introduction of semantic representations for object recognition [34, 44, 45, 55, 56], which rely on a predefined vocabulary of visual concepts to define a semantic space S and a set of classifiers to map each image into that space.", "startOffset": 87, "endOffset": 107}, {"referenceID": 1, "context": "This is known as zeroshot learning (ZSL) [2, 4, 14, 31, 48, 49].", "startOffset": 41, "endOffset": 63}, {"referenceID": 3, "context": "This is known as zeroshot learning (ZSL) [2, 4, 14, 31, 48, 49].", "startOffset": 41, "endOffset": 63}, {"referenceID": 13, "context": "This is known as zeroshot learning (ZSL) [2, 4, 14, 31, 48, 49].", "startOffset": 41, "endOffset": 63}, {"referenceID": 30, "context": "This is known as zeroshot learning (ZSL) [2, 4, 14, 31, 48, 49].", "startOffset": 41, "endOffset": 63}, {"referenceID": 47, "context": "This is known as zeroshot learning (ZSL) [2, 4, 14, 31, 48, 49].", "startOffset": 41, "endOffset": 63}, {"referenceID": 48, "context": "This is known as zeroshot learning (ZSL) [2, 4, 14, 31, 48, 49].", "startOffset": 41, "endOffset": 63}, {"referenceID": 13, "context": "This motivated the collection of datasets containing images annotated with respect to semantics such as visual attributes [14,31].", "startOffset": 122, "endOffset": 129}, {"referenceID": 30, "context": "This motivated the collection of datasets containing images annotated with respect to semantics such as visual attributes [14,31].", "startOffset": 122, "endOffset": 129}, {"referenceID": 33, "context": "The first, recognition using independent semantics (RIS), consists of learning an independent classifier per semantic [34, 55, 56].", "startOffset": 118, "endOffset": 130}, {"referenceID": 54, "context": "The first, recognition using independent semantics (RIS), consists of learning an independent classifier per semantic [34, 55, 56].", "startOffset": 118, "endOffset": 130}, {"referenceID": 55, "context": "The first, recognition using independent semantics (RIS), consists of learning an independent classifier per semantic [34, 55, 56].", "startOffset": 118, "endOffset": 130}, {"referenceID": 13, "context": "Due to its simplicity, RIS became widely popular in the attribute recognition literature [14,31,42,48,53,58].", "startOffset": 89, "endOffset": 108}, {"referenceID": 30, "context": "Due to its simplicity, RIS became widely popular in the attribute recognition literature [14,31,42,48,53,58].", "startOffset": 89, "endOffset": 108}, {"referenceID": 41, "context": "Due to its simplicity, RIS became widely popular in the attribute recognition literature [14,31,42,48,53,58].", "startOffset": 89, "endOffset": 108}, {"referenceID": 47, "context": "Due to its simplicity, RIS became widely popular in the attribute recognition literature [14,31,42,48,53,58].", "startOffset": 89, "endOffset": 108}, {"referenceID": 52, "context": "Due to its simplicity, RIS became widely popular in the attribute recognition literature [14,31,42,48,53,58].", "startOffset": 89, "endOffset": 108}, {"referenceID": 57, "context": "Due to its simplicity, RIS became widely popular in the attribute recognition literature [14,31,42,48,53,58].", "startOffset": 89, "endOffset": 108}, {"referenceID": 8, "context": "Notwithstanding efforts in discriminant attribute discovery [9, 14, 30, 42, 46] or modeling of uncertainty [25,31,58], learning semantics independently proved too weak to guarantee reliable ZS predictions.", "startOffset": 60, "endOffset": 79}, {"referenceID": 13, "context": "Notwithstanding efforts in discriminant attribute discovery [9, 14, 30, 42, 46] or modeling of uncertainty [25,31,58], learning semantics independently proved too weak to guarantee reliable ZS predictions.", "startOffset": 60, "endOffset": 79}, {"referenceID": 29, "context": "Notwithstanding efforts in discriminant attribute discovery [9, 14, 30, 42, 46] or modeling of uncertainty [25,31,58], learning semantics independently proved too weak to guarantee reliable ZS predictions.", "startOffset": 60, "endOffset": 79}, {"referenceID": 41, "context": "Notwithstanding efforts in discriminant attribute discovery [9, 14, 30, 42, 46] or modeling of uncertainty [25,31,58], learning semantics independently proved too weak to guarantee reliable ZS predictions.", "startOffset": 60, "endOffset": 79}, {"referenceID": 45, "context": "Notwithstanding efforts in discriminant attribute discovery [9, 14, 30, 42, 46] or modeling of uncertainty [25,31,58], learning semantics independently proved too weak to guarantee reliable ZS predictions.", "startOffset": 60, "endOffset": 79}, {"referenceID": 24, "context": "Notwithstanding efforts in discriminant attribute discovery [9, 14, 30, 42, 46] or modeling of uncertainty [25,31,58], learning semantics independently proved too weak to guarantee reliable ZS predictions.", "startOffset": 107, "endOffset": 117}, {"referenceID": 30, "context": "Notwithstanding efforts in discriminant attribute discovery [9, 14, 30, 42, 46] or modeling of uncertainty [25,31,58], learning semantics independently proved too weak to guarantee reliable ZS predictions.", "startOffset": 107, "endOffset": 117}, {"referenceID": 57, "context": "Notwithstanding efforts in discriminant attribute discovery [9, 14, 30, 42, 46] or modeling of uncertainty [25,31,58], learning semantics independently proved too weak to guarantee reliable ZS predictions.", "startOffset": 107, "endOffset": 117}, {"referenceID": 43, "context": "This motivated a shift to the second strategy, which ties the design of S to the goal of recognition, by learning a single multi-class classifier that optimally discriminates between all training classes [44, 45].", "startOffset": 204, "endOffset": 212}, {"referenceID": 44, "context": "This motivated a shift to the second strategy, which ties the design of S to the goal of recognition, by learning a single multi-class classifier that optimally discriminates between all training classes [44, 45].", "startOffset": 204, "endOffset": 212}, {"referenceID": 1, "context": "[2] proposed an effective solution to this problem by noting that there is a fixed linear transformation, or embedding, between the semantics of interest and the class labels, which can be specified by hand, even for ZS classes.", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "Recently, various works have proposed variations on this approach [1,4,35,43,47,49].", "startOffset": 66, "endOffset": 83}, {"referenceID": 3, "context": "Recently, various works have proposed variations on this approach [1,4,35,43,47,49].", "startOffset": 66, "endOffset": 83}, {"referenceID": 34, "context": "Recently, various works have proposed variations on this approach [1,4,35,43,47,49].", "startOffset": 66, "endOffset": 83}, {"referenceID": 42, "context": "Recently, various works have proposed variations on this approach [1,4,35,43,47,49].", "startOffset": 66, "endOffset": 83}, {"referenceID": 46, "context": "Recently, various works have proposed variations on this approach [1,4,35,43,47,49].", "startOffset": 66, "endOffset": 83}, {"referenceID": 48, "context": "Recently, various works have proposed variations on this approach [1,4,35,43,47,49].", "startOffset": 66, "endOffset": 83}, {"referenceID": 44, "context": "Early approaches to semantic recognition [45] used the set of image classes to be recognized as the semantic vocabulary.", "startOffset": 41, "endOffset": 45}, {"referenceID": 43, "context": "The rationale is to create a feature space with a high-level abstraction, where operations such as image search [44] or classification [34, 45] can be performed more robustly.", "startOffset": 112, "endOffset": 116}, {"referenceID": 33, "context": "The rationale is to create a feature space with a high-level abstraction, where operations such as image search [44] or classification [34, 45] can be performed more robustly.", "startOffset": 135, "endOffset": 143}, {"referenceID": 44, "context": "The rationale is to create a feature space with a high-level abstraction, where operations such as image search [44] or classification [34, 45] can be performed more robustly.", "startOffset": 135, "endOffset": 143}, {"referenceID": 13, "context": "Attributes were introduced in [14, 31] and quickly adopted in many other works [2,8,21,23\u201325,27,48,53,58,60].", "startOffset": 30, "endOffset": 38}, {"referenceID": 30, "context": "Attributes were introduced in [14, 31] and quickly adopted in many other works [2,8,21,23\u201325,27,48,53,58,60].", "startOffset": 30, "endOffset": 38}, {"referenceID": 1, "context": "Attributes were introduced in [14, 31] and quickly adopted in many other works [2,8,21,23\u201325,27,48,53,58,60].", "startOffset": 79, "endOffset": 108}, {"referenceID": 7, "context": "Attributes were introduced in [14, 31] and quickly adopted in many other works [2,8,21,23\u201325,27,48,53,58,60].", "startOffset": 79, "endOffset": 108}, {"referenceID": 20, "context": "Attributes were introduced in [14, 31] and quickly adopted in many other works [2,8,21,23\u201325,27,48,53,58,60].", "startOffset": 79, "endOffset": 108}, {"referenceID": 22, "context": "Attributes were introduced in [14, 31] and quickly adopted in many other works [2,8,21,23\u201325,27,48,53,58,60].", "startOffset": 79, "endOffset": 108}, {"referenceID": 23, "context": "Attributes were introduced in [14, 31] and quickly adopted in many other works [2,8,21,23\u201325,27,48,53,58,60].", "startOffset": 79, "endOffset": 108}, {"referenceID": 24, "context": "Attributes were introduced in [14, 31] and quickly adopted in many other works [2,8,21,23\u201325,27,48,53,58,60].", "startOffset": 79, "endOffset": 108}, {"referenceID": 26, "context": "Attributes were introduced in [14, 31] and quickly adopted in many other works [2,8,21,23\u201325,27,48,53,58,60].", "startOffset": 79, "endOffset": 108}, {"referenceID": 47, "context": "Attributes were introduced in [14, 31] and quickly adopted in many other works [2,8,21,23\u201325,27,48,53,58,60].", "startOffset": 79, "endOffset": 108}, {"referenceID": 52, "context": "Attributes were introduced in [14, 31] and quickly adopted in many other works [2,8,21,23\u201325,27,48,53,58,60].", "startOffset": 79, "endOffset": 108}, {"referenceID": 57, "context": "Attributes were introduced in [14, 31] and quickly adopted in many other works [2,8,21,23\u201325,27,48,53,58,60].", "startOffset": 79, "endOffset": 108}, {"referenceID": 59, "context": "Attributes were introduced in [14, 31] and quickly adopted in many other works [2,8,21,23\u201325,27,48,53,58,60].", "startOffset": 79, "endOffset": 108}, {"referenceID": 1, "context": "Semantic concepts extracted from hierarchies/taxonomies were later explored in [2,4,48,60], and vector representations for words/entities in [4, 8, 16, 18, 20, 41, 43, 47, 60].", "startOffset": 79, "endOffset": 90}, {"referenceID": 3, "context": "Semantic concepts extracted from hierarchies/taxonomies were later explored in [2,4,48,60], and vector representations for words/entities in [4, 8, 16, 18, 20, 41, 43, 47, 60].", "startOffset": 79, "endOffset": 90}, {"referenceID": 47, "context": "Semantic concepts extracted from hierarchies/taxonomies were later explored in [2,4,48,60], and vector representations for words/entities in [4, 8, 16, 18, 20, 41, 43, 47, 60].", "startOffset": 79, "endOffset": 90}, {"referenceID": 59, "context": "Semantic concepts extracted from hierarchies/taxonomies were later explored in [2,4,48,60], and vector representations for words/entities in [4, 8, 16, 18, 20, 41, 43, 47, 60].", "startOffset": 79, "endOffset": 90}, {"referenceID": 3, "context": "Semantic concepts extracted from hierarchies/taxonomies were later explored in [2,4,48,60], and vector representations for words/entities in [4, 8, 16, 18, 20, 41, 43, 47, 60].", "startOffset": 141, "endOffset": 175}, {"referenceID": 7, "context": "Semantic concepts extracted from hierarchies/taxonomies were later explored in [2,4,48,60], and vector representations for words/entities in [4, 8, 16, 18, 20, 41, 43, 47, 60].", "startOffset": 141, "endOffset": 175}, {"referenceID": 15, "context": "Semantic concepts extracted from hierarchies/taxonomies were later explored in [2,4,48,60], and vector representations for words/entities in [4, 8, 16, 18, 20, 41, 43, 47, 60].", "startOffset": 141, "endOffset": 175}, {"referenceID": 17, "context": "Semantic concepts extracted from hierarchies/taxonomies were later explored in [2,4,48,60], and vector representations for words/entities in [4, 8, 16, 18, 20, 41, 43, 47, 60].", "startOffset": 141, "endOffset": 175}, {"referenceID": 19, "context": "Semantic concepts extracted from hierarchies/taxonomies were later explored in [2,4,48,60], and vector representations for words/entities in [4, 8, 16, 18, 20, 41, 43, 47, 60].", "startOffset": 141, "endOffset": 175}, {"referenceID": 40, "context": "Semantic concepts extracted from hierarchies/taxonomies were later explored in [2,4,48,60], and vector representations for words/entities in [4, 8, 16, 18, 20, 41, 43, 47, 60].", "startOffset": 141, "endOffset": 175}, {"referenceID": 42, "context": "Semantic concepts extracted from hierarchies/taxonomies were later explored in [2,4,48,60], and vector representations for words/entities in [4, 8, 16, 18, 20, 41, 43, 47, 60].", "startOffset": 141, "endOffset": 175}, {"referenceID": 46, "context": "Semantic concepts extracted from hierarchies/taxonomies were later explored in [2,4,48,60], and vector representations for words/entities in [4, 8, 16, 18, 20, 41, 43, 47, 60].", "startOffset": 141, "endOffset": 175}, {"referenceID": 59, "context": "Semantic concepts extracted from hierarchies/taxonomies were later explored in [2,4,48,60], and vector representations for words/entities in [4, 8, 16, 18, 20, 41, 43, 47, 60].", "startOffset": 141, "endOffset": 175}, {"referenceID": 30, "context": "One of the most popular among these is the direct attribute prediction (DAP) method [31], which learns attributes independently using SVMs and infers ZS predictions by a maximum a posteriori rule that assumes attribute independence.", "startOffset": 84, "endOffset": 88}, {"referenceID": 9, "context": "by using CRFs to model attribute/class correlations [10], directed Bayesian networks to merge attribute predictions into class scores [58], or random forests learned so as to mitigate the effect of unreliable attributes [25].", "startOffset": 52, "endOffset": 56}, {"referenceID": 57, "context": "by using CRFs to model attribute/class correlations [10], directed Bayesian networks to merge attribute predictions into class scores [58], or random forests learned so as to mitigate the effect of unreliable attributes [25].", "startOffset": 134, "endOffset": 138}, {"referenceID": 24, "context": "by using CRFs to model attribute/class correlations [10], directed Bayesian networks to merge attribute predictions into class scores [58], or random forests learned so as to mitigate the effect of unreliable attributes [25].", "startOffset": 220, "endOffset": 224}, {"referenceID": 36, "context": "More recently, [37] proposed a multiplicative framework that enables class-specific attribute classifiers, and [5] learns independent attributes which were previously discovered from Word2Vec representations.", "startOffset": 15, "endOffset": 19}, {"referenceID": 4, "context": "More recently, [37] proposed a multiplicative framework that enables class-specific attribute classifiers, and [5] learns independent attributes which were previously discovered from Word2Vec representations.", "startOffset": 111, "endOffset": 114}, {"referenceID": 1, "context": "In the first implementation of RULE for ZSL [2], T is learned by a variant of the structured SVM.", "startOffset": 44, "endOffset": 47}, {"referenceID": 42, "context": "Several variants have been proposed, such as the addition of different regularization terms [43,49], the use of least-squares losses for faster training [49], or improved semantic representations of objects learned from multiple text sources [1, 47].", "startOffset": 92, "endOffset": 99}, {"referenceID": 48, "context": "Several variants have been proposed, such as the addition of different regularization terms [43,49], the use of least-squares losses for faster training [49], or improved semantic representations of objects learned from multiple text sources [1, 47].", "startOffset": 92, "endOffset": 99}, {"referenceID": 48, "context": "Several variants have been proposed, such as the addition of different regularization terms [43,49], the use of least-squares losses for faster training [49], or improved semantic representations of objects learned from multiple text sources [1, 47].", "startOffset": 153, "endOffset": 157}, {"referenceID": 0, "context": "Several variants have been proposed, such as the addition of different regularization terms [43,49], the use of least-squares losses for faster training [49], or improved semantic representations of objects learned from multiple text sources [1, 47].", "startOffset": 242, "endOffset": 249}, {"referenceID": 46, "context": "Several variants have been proposed, such as the addition of different regularization terms [43,49], the use of least-squares losses for faster training [49], or improved semantic representations of objects learned from multiple text sources [1, 47].", "startOffset": 242, "endOffset": 249}, {"referenceID": 21, "context": "Common usages of \u03a9[\u00b7] include shrinkage [22], sparse representations [11] or weight decay [29].", "startOffset": 40, "endOffset": 44}, {"referenceID": 10, "context": "Common usages of \u03a9[\u00b7] include shrinkage [22], sparse representations [11] or weight decay [29].", "startOffset": 69, "endOffset": 73}, {"referenceID": 28, "context": "Common usages of \u03a9[\u00b7] include shrinkage [22], sparse representations [11] or weight decay [29].", "startOffset": 90, "endOffset": 94}, {"referenceID": 48, "context": "For ZSL, this type of regularization has indeed been used to control the variance of 1) semantic scores or 2) backward projections of object embeddings into the feature space [49], as well as to suppress noisy semantics [43].", "startOffset": 175, "endOffset": 179}, {"referenceID": 42, "context": "For ZSL, this type of regularization has indeed been used to control the variance of 1) semantic scores or 2) backward projections of object embeddings into the feature space [49], as well as to suppress noisy semantics [43].", "startOffset": 220, "endOffset": 224}, {"referenceID": 14, "context": "For example, in binary classification, algorithms such as boosting [15] or SVM [12] simply choose 1/ \u2212 1 as the codewords of the positive/negative class.", "startOffset": 67, "endOffset": 71}, {"referenceID": 11, "context": "For example, in binary classification, algorithms such as boosting [15] or SVM [12] simply choose 1/ \u2212 1 as the codewords of the positive/negative class.", "startOffset": 79, "endOffset": 83}, {"referenceID": 32, "context": "Similarly, for C-ary classification, neural networks [33] or multi-class SVMs [59] rely on one-hot encodings that lead to the typical decision rule y\u2217 = arg maxj\u2208{1,.", "startOffset": 53, "endOffset": 57}, {"referenceID": 58, "context": "Similarly, for C-ary classification, neural networks [33] or multi-class SVMs [59] rely on one-hot encodings that lead to the typical decision rule y\u2217 = arg maxj\u2208{1,.", "startOffset": 78, "endOffset": 82}, {"referenceID": 49, "context": "In this work, since no semantic information is available beyond the taxonomy itself, we rely on the maximally separated codeword sets of [50].", "startOffset": 137, "endOffset": 141}, {"referenceID": 38, "context": "[39].", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "These supervisory signals and the semantic codes \u03c6(y) are used to compute the Lagrangian risk of (13), and all parameters are optimized by back-propagation using Caffe toolbox [26].", "startOffset": 176, "endOffset": 180}, {"referenceID": 30, "context": "Datasets: Three datasets were considered: Animals with Attributes [31] (AwA), Caltech-UCSD Birds 200-2011 [57] (CUB), and a subset of the Imaging FlowCytobot [52] (IFCB) dataset.", "startOffset": 66, "endOffset": 70}, {"referenceID": 56, "context": "Datasets: Three datasets were considered: Animals with Attributes [31] (AwA), Caltech-UCSD Birds 200-2011 [57] (CUB), and a subset of the Imaging FlowCytobot [52] (IFCB) dataset.", "startOffset": 106, "endOffset": 110}, {"referenceID": 51, "context": "Datasets: Three datasets were considered: Animals with Attributes [31] (AwA), Caltech-UCSD Birds 200-2011 [57] (CUB), and a subset of the Imaging FlowCytobot [52] (IFCB) dataset.", "startOffset": 158, "endOffset": 162}, {"referenceID": 30, "context": "On AwA and CUB, the partition into source and target classes for ZSL is as specified by [31] and [2], respectively.", "startOffset": 88, "endOffset": 92}, {"referenceID": 1, "context": "On AwA and CUB, the partition into source and target classes for ZSL is as specified by [31] and [2], respectively.", "startOffset": 97, "endOffset": 100}, {"referenceID": 27, "context": "Three CNN architectures were used to implement \u03b8(x): AlexNet [28] (layer fc7), GoogLeNet [54] (layer pool5) and VGG19 [51] (layer fc7).", "startOffset": 61, "endOffset": 65}, {"referenceID": 53, "context": "Three CNN architectures were used to implement \u03b8(x): AlexNet [28] (layer fc7), GoogLeNet [54] (layer pool5) and VGG19 [51] (layer fc7).", "startOffset": 89, "endOffset": 93}, {"referenceID": 50, "context": "Three CNN architectures were used to implement \u03b8(x): AlexNet [28] (layer fc7), GoogLeNet [54] (layer pool5) and VGG19 [51] (layer fc7).", "startOffset": 118, "endOffset": 122}, {"referenceID": 6, "context": "On IFCB, where no attributes were defined previously, a list of 35 visual attributes was assembled and annotated by an expert with binary labels, using several sources from the oceanographic community [7, 38].", "startOffset": 201, "endOffset": 208}, {"referenceID": 37, "context": "On IFCB, where no attributes were defined previously, a list of 35 visual attributes was assembled and annotated by an expert with binary labels, using several sources from the oceanographic community [7, 38].", "startOffset": 201, "endOffset": 208}, {"referenceID": 39, "context": "Taxonomies were created by pruning the WordNet tree [40] for the training and ZS classes, and eliminating dummy nodes containing a single child.", "startOffset": 52, "endOffset": 56}, {"referenceID": 39, "context": "AwA 30,475 40/10 85 WordNet [40]", "startOffset": 28, "endOffset": 32}, {"referenceID": 39, "context": "CUB 11,788 150/50 312 WordNet [40]", "startOffset": 30, "endOffset": 34}, {"referenceID": 27, "context": "A - AlexNet [28]; G - GoogLeNet [54]; V - VGG19 [51].", "startOffset": 12, "endOffset": 16}, {"referenceID": 53, "context": "A - AlexNet [28]; G - GoogLeNet [54]; V - VGG19 [51].", "startOffset": 32, "endOffset": 36}, {"referenceID": 50, "context": "A - AlexNet [28]; G - GoogLeNet [54]; V - VGG19 [51].", "startOffset": 48, "endOffset": 52}, {"referenceID": 31, "context": "DAP [32] 45.", "startOffset": 4, "endOffset": 8}, {"referenceID": 3, "context": "6\u2021 SJE [4] 61.", "startOffset": 7, "endOffset": 10}, {"referenceID": 48, "context": "1 ES-ZSL\u00a7 [49] 53.", "startOffset": 10, "endOffset": 14}, {"referenceID": 22, "context": "[23] 45.", "startOffset": 0, "endOffset": 4}, {"referenceID": 36, "context": "[37] 48.", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "[8] - 72.", "startOffset": 0, "endOffset": 3}, {"referenceID": 59, "context": "[60] - 72.", "startOffset": 0, "endOffset": 4}, {"referenceID": 60, "context": "[61] - - 76.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "[21] - - 73.", "startOffset": 0, "endOffset": 4}, {"referenceID": 36, "context": "[37].", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "[6].", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "Methods that use alternative semantics [1, 19, 43, 47] or that use unlabeled images from ZS classes for training [17,18,27,36] were disregarded for this comparison.", "startOffset": 39, "endOffset": 54}, {"referenceID": 18, "context": "Methods that use alternative semantics [1, 19, 43, 47] or that use unlabeled images from ZS classes for training [17,18,27,36] were disregarded for this comparison.", "startOffset": 39, "endOffset": 54}, {"referenceID": 42, "context": "Methods that use alternative semantics [1, 19, 43, 47] or that use unlabeled images from ZS classes for training [17,18,27,36] were disregarded for this comparison.", "startOffset": 39, "endOffset": 54}, {"referenceID": 46, "context": "Methods that use alternative semantics [1, 19, 43, 47] or that use unlabeled images from ZS classes for training [17,18,27,36] were disregarded for this comparison.", "startOffset": 39, "endOffset": 54}, {"referenceID": 16, "context": "Methods that use alternative semantics [1, 19, 43, 47] or that use unlabeled images from ZS classes for training [17,18,27,36] were disregarded for this comparison.", "startOffset": 113, "endOffset": 126}, {"referenceID": 17, "context": "Methods that use alternative semantics [1, 19, 43, 47] or that use unlabeled images from ZS classes for training [17,18,27,36] were disregarded for this comparison.", "startOffset": 113, "endOffset": 126}, {"referenceID": 26, "context": "Methods that use alternative semantics [1, 19, 43, 47] or that use unlabeled images from ZS classes for training [17,18,27,36] were disregarded for this comparison.", "startOffset": 113, "endOffset": 126}, {"referenceID": 35, "context": "Methods that use alternative semantics [1, 19, 43, 47] or that use unlabeled images from ZS classes for training [17,18,27,36] were disregarded for this comparison.", "startOffset": 113, "endOffset": 126}, {"referenceID": 4, "context": "DAP results reported in [5].", "startOffset": 24, "endOffset": 27}, {"referenceID": 30, "context": "Figure 5 compares Deep-SCoRe and its variants to popular RIS and RULE approaches in the literature: DAP [31] (RIS), SJE [4] and ES-ZSL [49] (RULE).", "startOffset": 104, "endOffset": 108}, {"referenceID": 3, "context": "Figure 5 compares Deep-SCoRe and its variants to popular RIS and RULE approaches in the literature: DAP [31] (RIS), SJE [4] and ES-ZSL [49] (RULE).", "startOffset": 120, "endOffset": 123}, {"referenceID": 48, "context": "Figure 5 compares Deep-SCoRe and its variants to popular RIS and RULE approaches in the literature: DAP [31] (RIS), SJE [4] and ES-ZSL [49] (RULE).", "startOffset": 135, "endOffset": 139}, {"referenceID": 2, "context": "First, as shown in [3, 8, 60], attributes enable by far the most effective transfer.", "startOffset": 19, "endOffset": 29}, {"referenceID": 7, "context": "First, as shown in [3, 8, 60], attributes enable by far the most effective transfer.", "startOffset": 19, "endOffset": 29}, {"referenceID": 59, "context": "First, as shown in [3, 8, 60], attributes enable by far the most effective transfer.", "startOffset": 19, "endOffset": 29}], "year": 2017, "abstractText": "The role of semantics in zero-shot learning is considered. The effectiveness of previous approaches is analyzed according to the form of supervision provided. While some learn semantics independently, others only supervise the semantic subspace explained by training classes. Thus, the former is able to constrain the whole space but lacks the ability to model semantic correlations. The latter addresses this issue but leaves part of the semantic space unsupervised. This complementarity is exploited in a new convolutional neural network (CNN) framework, which proposes the use of semantics as constraints for recognition.Although a CNN trained for classification has no transfer ability, this can be encouraged by learning an hidden semantic layer together with a semantic code for classification. Two forms of semantic constraints are then introduced. The first is a loss-based regularizer that introduces a generalization constraint on each semantic predictor. The second is a codeword regularizer that favors semantic-to-class mappings consistent with prior semantic knowledge while allowing these to be learned from data. Significant improvements over the state-of-the-art are achieved on several datasets.", "creator": "LaTeX with hyperref package"}}}